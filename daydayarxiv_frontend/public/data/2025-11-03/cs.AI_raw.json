[
  {
    "arxiv_id": "2511.02130v1",
    "title": "Re-FORC: Adaptive Reward Prediction for Efficient Chain-of-Thought Reasoning",
    "authors": [
      "Renos Zabounidis",
      "Aditya Golatkar",
      "Michael Kleinman",
      "Alessandro Achille",
      "Wei Xia",
      "Stefano Soatto"
    ],
    "abstract": "We propose Re-FORC, an adaptive reward prediction method that, given a context, enables prediction of the expected future rewards as a function of the number of future thinking tokens. Re-FORC trains a lightweight adapter on reasoning models, demonstrating improved prediction with longer reasoning and larger models. Re-FORC enables: 1) early stopping of unpromising reasoning chains, reducing compute by 26% while maintaining accuracy, 2) optimized model and thinking length selection that achieves 4% higher accuracy at equal compute and 55% less compute at equal accuracy compared to the largest model, 3) adaptive test-time scaling, which increases accuracy by 11% in high compute regime, and 7% in low compute regime. Re-FORC allows dynamic reasoning with length control via cost-per-token thresholds while estimating computation time upfront.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted at Efficient Reasoning Workshop at NeurIPS 2025",
    "pdf_url": "https://arxiv.org/pdf/2511.02130v1",
    "published_date": "2025-11-03 23:47:49 UTC",
    "updated_date": "2025-11-03 23:47:49 UTC"
  },
  {
    "arxiv_id": "2511.02869v1",
    "title": "Analysis of AdvFusion: Adapter-based Multilingual Learning for Code Large Language Models",
    "authors": [
      "Amirreza Esmaeili",
      "Fahd Seddik",
      "Yongyi Ji",
      "Fatemeh Fard",
      "Fuxiang Chen"
    ],
    "abstract": "Programming languages can benefit from one another by utilizing a language model for software engineering tasks. Full fine-tuning and Parameter Efficient Fine-Tuning (PEFT) of Code Language Models (Code-LMs) has been explored for multilingual knowledge transfer. AdapterFusion is a PEFT architecture that aims to enhance task performance by leveraging information from multiple programming languages, but primarily focuses on the target programming language.\n  In our previous work, we proposed AdvFusion, a novel PEFT-based approach that effectively learns from other programming languages before adapting to the target task. Though previous experiments showed that AdvFusion outperformed AdapterFusion and LoRA, it was applied on pre-trained Code-LMs and was limited to only two tasks, code summarization and method name prediction. In this study, we expanded our work and investigated AdvFusion on Code Large Language Models (Code-LLMs), considering three new tasks: code generation, code translation, and commit message generation. We observed that different Code-LLMs/tasks exhibit different characteristics. In code generation, AdvFusion outperformed AdapterFusion but not other PEFT methods (LoRA, Compacter, and TaskAdapter). In commit message generation, AdapterFusion performed better than AdvFusion, and contrary to code generation, we found that the other PEFT methods do not have better performance. In code translation, AdvFusion performed worse than AdapterFusion overall, with the performance gap marginally widening as the model size increases. However, consistent with code generation, other PEFT methods showed better performance.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.PL"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2511.02869v1",
    "published_date": "2025-11-03 23:45:27 UTC",
    "updated_date": "2025-11-03 23:45:27 UTC"
  },
  {
    "arxiv_id": "2511.02122v3",
    "title": "Matrix Sensing with Kernel Optimal Loss: Robustness and Optimization Landscape",
    "authors": [
      "Xinyuan Song",
      "Ziye Ma"
    ],
    "abstract": "In this paper we study how the choice of loss functions of non-convex optimization problems affects their robustness and optimization landscape, through the study of noisy matrix sensing. In traditional regression tasks, mean squared error (MSE) loss is a common choice, but it can be unreliable for non-Gaussian or heavy-tailed noise. To address this issue, we adopt a robust loss based on nonparametric regression, which uses a kernel-based estimate of the residual density and maximizes the estimated log-likelihood. This robust formulation coincides with the MSE loss under Gaussian errors but remains stable under more general settings. We further examine how this robust loss reshapes the optimization landscape by analyzing the upper-bound of restricted isometry property (RIP) constants for spurious local minima to disappear. Through theoretical and empirical analysis, we show that this new loss excels at handling large noise and remains robust across diverse noise distributions. This work offers initial insights into enhancing the robustness of machine learning tasks through simply changing the loss, guided by an intuitive and broadly applicable analytical framework.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "CPAL 2026",
    "pdf_url": "https://arxiv.org/pdf/2511.02122v3",
    "published_date": "2025-11-03 23:22:37 UTC",
    "updated_date": "2026-01-05 01:59:41 UTC"
  },
  {
    "arxiv_id": "2511.02119v1",
    "title": "InsurAgent: A Large Language Model-Empowered Agent for Simulating Individual Behavior in Purchasing Flood Insurance",
    "authors": [
      "Ziheng Geng",
      "Jiachen Liu",
      "Ran Cao",
      "Lu Cheng",
      "Dan M. Frangopol",
      "Minghui Cheng"
    ],
    "abstract": "Flood insurance is an effective strategy for individuals to mitigate disaster-related losses. However, participation rates among at-risk populations in the United States remain strikingly low. This gap underscores the need to understand and model the behavioral mechanisms underlying insurance decisions. Large language models (LLMs) have recently exhibited human-like intelligence across wide-ranging tasks, offering promising tools for simulating human decision-making. This study constructs a benchmark dataset to capture insurance purchase probabilities across factors. Using this dataset, the capacity of LLMs is evaluated: while LLMs exhibit a qualitative understanding of factors, they fall short in estimating quantitative probabilities. To address this limitation, InsurAgent, an LLM-empowered agent comprising five modules including perception, retrieval, reasoning, action, and memory, is proposed. The retrieval module leverages retrieval-augmented generation (RAG) to ground decisions in empirical survey data, achieving accurate estimation of marginal and bivariate probabilities. The reasoning module leverages LLM common sense to extrapolate beyond survey data, capturing contextual information that is intractable for traditional models. The memory module supports the simulation of temporal decision evolutions, illustrated through a roller coaster life trajectory. Overall, InsurAgent provides a valuable tool for behavioral modeling and policy analysis.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2511.02119v1",
    "published_date": "2025-11-03 23:19:27 UTC",
    "updated_date": "2025-11-03 23:19:27 UTC"
  },
  {
    "arxiv_id": "2511.02109v3",
    "title": "Deep Value Benchmark: Measuring Whether Models Generalize Deep Values or Shallow Preferences",
    "authors": [
      "Joshua Ashkinaze",
      "Hua Shen",
      "Saipranav Avula",
      "Eric Gilbert",
      "Ceren Budak"
    ],
    "abstract": "We introduce the Deep Value Benchmark (DVB), an evaluation framework that directly tests whether large language models (LLMs) learn fundamental human values or merely surface-level preferences. This distinction is critical for AI alignment: Systems that capture deeper values are likely to generalize human intentions robustly, while those that capture only superficial patterns in preference data risk producing misaligned behavior. The DVB uses a novel experimental design with controlled confounding between deep values (e.g., moral principles) and shallow features (e.g., superficial attributes). In the training phase, we expose LLMs to human preference data with deliberately correlated deep and shallow features -- for instance, where a user consistently prefers (non-maleficence, formal language) options over (justice, informal language) alternatives. The testing phase then breaks these correlations, presenting choices between (justice, formal language) and (non-maleficence, informal language) options. This design allows us to precisely measure a model's Deep Value Generalization Rate (DVGR) -- the probability of generalizing based on the underlying value rather than the shallow feature. Across 9 different models, the average DVGR is just 0.30. All models generalize deep values less than chance. Larger models have a (slightly) lower DVGR than smaller models. We are releasing our dataset, which was subject to three separate human validation experiments. DVB provides an interpretable measure of a core feature of alignment.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.CY"
    ],
    "primary_category": "cs.AI",
    "comment": "NeurIPS 2025 (Spotlight)",
    "pdf_url": "https://arxiv.org/pdf/2511.02109v3",
    "published_date": "2025-11-03 22:49:54 UTC",
    "updated_date": "2026-01-11 14:57:32 UTC"
  },
  {
    "arxiv_id": "2511.02108v1",
    "title": "Metamorphic Testing of Large Language Models for Natural Language Processing",
    "authors": [
      "Steven Cho",
      "Stefano Ruberto",
      "Valerio Terragni"
    ],
    "abstract": "Using large language models (LLMs) to perform natural language processing (NLP) tasks has become increasingly pervasive in recent times. The versatile nature of LLMs makes them applicable to a wide range of such tasks. While the performance of recent LLMs is generally outstanding, several studies have shown that they can often produce incorrect results. Automatically identifying these faulty behaviors is extremely useful for improving the effectiveness of LLMs. One obstacle to this is the limited availability of labeled datasets, which necessitates an oracle to determine the correctness of LLM behaviors. Metamorphic testing (MT) is a popular testing approach that alleviates this oracle problem. At the core of MT are metamorphic relations (MRs), which define relationships between the outputs of related inputs. MT can expose faulty behaviors without the need for explicit oracles (e.g., labeled datasets). This paper presents the most comprehensive study of MT for LLMs to date. We conducted a literature review and collected 191 MRs for NLP tasks. We implemented a representative subset (36 MRs) to conduct a series of experiments with three popular LLMs, running approximately 560,000 metamorphic tests. The results shed light on the capabilities and opportunities of MT for LLMs, as well as its limitations.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2511.02108v1",
    "published_date": "2025-11-03 22:48:19 UTC",
    "updated_date": "2025-11-03 22:48:19 UTC"
  },
  {
    "arxiv_id": "2511.02100v1",
    "title": "Geometric Data Valuation via Leverage Scores",
    "authors": [
      "Rodrigo Mendoza-Smith"
    ],
    "abstract": "Shapley data valuation provides a principled, axiomatic framework for assigning importance to individual datapoints, and has gained traction in dataset curation, pruning, and pricing. However, it is a combinatorial measure that requires evaluating marginal utility across all subsets of the data, making it computationally infeasible at scale. We propose a geometric alternative based on statistical leverage scores, which quantify each datapoint's structural influence in the representation space by measuring how much it extends the span of the dataset and contributes to the effective dimensionality of the training problem. We show that our scores satisfy the dummy, efficiency, and symmetry axioms of Shapley valuation and that extending them to \\emph{ridge leverage scores} yields strictly positive marginal gains that connect naturally to classical A- and D-optimal design criteria. We further show that training on a leverage-sampled subset produces a model whose parameters and predictive risk are within $O(\\varepsilon)$ of the full-data optimum, thereby providing a rigorous link between data valuation and downstream decision quality. Finally, we conduct an active learning experiment in which we empirically demonstrate that ridge-leverage sampling outperforms standard baselines without requiring access gradients or backward passes.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "math.NA",
      "math.OC"
    ],
    "primary_category": "cs.LG",
    "comment": "MLxOR: Mathematical Foundations and Operational Integration of Machine Learning for Uncertainty-Aware Decision-Making (NeurIPS 2025)",
    "pdf_url": "https://arxiv.org/pdf/2511.02100v1",
    "published_date": "2025-11-03 22:20:50 UTC",
    "updated_date": "2025-11-03 22:20:50 UTC"
  },
  {
    "arxiv_id": "2511.02094v1",
    "title": "Automated Reward Design for Gran Turismo",
    "authors": [
      "Michel Ma",
      "Takuma Seno",
      "Kaushik Subramanian",
      "Peter R. Wurman",
      "Peter Stone",
      "Craig Sherstan"
    ],
    "abstract": "When designing reinforcement learning (RL) agents, a designer communicates the desired agent behavior through the definition of reward functions - numerical feedback given to the agent as reward or punishment for its actions. However, mapping desired behaviors to reward functions can be a difficult process, especially in complex environments such as autonomous racing. In this paper, we demonstrate how current foundation models can effectively search over a space of reward functions to produce desirable RL agents for the Gran Turismo 7 racing game, given only text-based instructions. Through a combination of LLM-based reward generation, VLM preference-based evaluation, and human feedback we demonstrate how our system can be used to produce racing agents competitive with GT Sophy, a champion-level RL racing agent, as well as generate novel behaviors, paving the way for practical automated reward design in real world applications.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2511.02094v1",
    "published_date": "2025-11-03 22:07:53 UTC",
    "updated_date": "2025-11-03 22:07:53 UTC"
  },
  {
    "arxiv_id": "2511.02092v1",
    "title": "Uncertainty Guided Online Ensemble for Non-stationary Data Streams in Fusion Science",
    "authors": [
      "Kishansingh Rajput",
      "Malachi Schram",
      "Brian Sammuli",
      "Sen Lin"
    ],
    "abstract": "Machine Learning (ML) is poised to play a pivotal role in the development and operation of next-generation fusion devices. Fusion data shows non-stationary behavior with distribution drifts, resulted by both experimental evolution and machine wear-and-tear. ML models assume stationary distribution and fail to maintain performance when encountered with such non-stationary data streams. Online learning techniques have been leveraged in other domains, however it has been largely unexplored for fusion applications. In this paper, we present an application of online learning to continuously adapt to drifting data stream for prediction of Toroidal Field (TF) coils deflection at the DIII-D fusion facility. The results demonstrate that online learning is critical to maintain ML model performance and reduces error by 80% compared to a static model. Moreover, traditional online learning can suffer from short-term performance degradation as ground truth is not available before making the predictions. As such, we propose an uncertainty guided online ensemble method to further improve the performance. The Deep Gaussian Process Approximation (DGPA) technique is leveraged for calibrated uncertainty estimation and the uncertainty values are then used to guide a meta-algorithm that produces predictions based on an ensemble of learners trained on different horizon of historical data. The DGPA also provides uncertainty estimation along with the predictions for decision makers. The online ensemble and the proposed uncertainty guided online ensemble reduces predictions error by about 6%, and 10% respectively over standard single model based online learning.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "physics.plasm-ph"
    ],
    "primary_category": "cs.LG",
    "comment": "24 pages including total of references, 2 appendices, 7 Figures (5 in main article, 2 in appendix A)",
    "pdf_url": "https://arxiv.org/pdf/2511.02092v1",
    "published_date": "2025-11-03 22:03:37 UTC",
    "updated_date": "2025-11-03 22:03:37 UTC"
  },
  {
    "arxiv_id": "2511.02091v1",
    "title": "Natural Building Blocks for Structured World Models: Theory, Evidence, and Scaling",
    "authors": [
      "Lancelot Da Costa",
      "Sanjeev Namjoshi",
      "Mohammed Abbas Ansari",
      "Bernhard Schölkopf"
    ],
    "abstract": "The field of world modeling is fragmented, with researchers developing bespoke architectures that rarely build upon each other. We propose a framework that specifies the natural building blocks for structured world models based on the fundamental stochastic processes that any world model must capture: discrete processes (logic, symbols) and continuous processes (physics, dynamics); the world model is then defined by the hierarchical composition of these building blocks. We examine Hidden Markov Models (HMMs) and switching linear dynamical systems (sLDS) as natural building blocks for discrete and continuous modeling--which become partially-observable Markov decision processes (POMDPs) and controlled sLDS when augmented with actions. This modular approach supports both passive modeling (generation, forecasting) and active control (planning, decision-making) within the same architecture. We avoid the combinatorial explosion of traditional structure learning by largely fixing the causal architecture and searching over only four depth parameters. We review practical expressiveness through multimodal generative modeling (passive) and planning from pixels (active), with performance competitive to neural approaches while maintaining interpretability. The core outstanding challenge is scalable joint structure-parameter learning; current methods finesse this by cleverly growing structure and parameters incrementally, but are limited in their scalability. If solved, these natural building blocks could provide foundational infrastructure for world modeling, analogous to how standardized layers enabled progress in deep learning.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "13 pages, 3 figures, under review for World Modeling Workshop 2026",
    "pdf_url": "https://arxiv.org/pdf/2511.02091v1",
    "published_date": "2025-11-03 22:02:04 UTC",
    "updated_date": "2025-11-03 22:02:04 UTC"
  },
  {
    "arxiv_id": "2511.02087v1",
    "title": "Energy Loss Functions for Physical Systems",
    "authors": [
      "Sékou-Oumar Kaba",
      "Kusha Sareen",
      "Daniel Levy",
      "Siamak Ravanbakhsh"
    ],
    "abstract": "Effectively leveraging prior knowledge of a system's physics is crucial for applications of machine learning to scientific domains. Previous approaches mostly focused on incorporating physical insights at the architectural level. In this paper, we propose a framework to leverage physical information directly into the loss function for prediction and generative modeling tasks on systems like molecules and spins. We derive energy loss functions assuming that each data sample is in thermal equilibrium with respect to an approximate energy landscape. By using the reverse KL divergence with a Boltzmann distribution around the data, we obtain the loss as an energy difference between the data and the model predictions. This perspective also recasts traditional objectives like MSE as energy-based, but with a physically meaningless energy. In contrast, our formulation yields physically grounded loss functions with gradients that better align with valid configurations, while being architecture-agnostic and computationally efficient. The energy loss functions also inherently respect physical symmetries. We demonstrate our approach on molecular generation and spin ground-state prediction and report significant improvements over baselines.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "physics.comp-ph"
    ],
    "primary_category": "cs.LG",
    "comment": "10 pages, 4 figures, NeurIPS 2025",
    "pdf_url": "https://arxiv.org/pdf/2511.02087v1",
    "published_date": "2025-11-03 21:58:36 UTC",
    "updated_date": "2025-11-03 21:58:36 UTC"
  },
  {
    "arxiv_id": "2511.02083v1",
    "title": "Watermarking Discrete Diffusion Language Models",
    "authors": [
      "Avi Bagchi",
      "Akhil Bhimaraju",
      "Moulik Choraria",
      "Daniel Alabi",
      "Lav R. Varshney"
    ],
    "abstract": "Watermarking has emerged as a promising technique to track AI-generated content and differentiate it from authentic human creations. While prior work extensively studies watermarking for autoregressive large language models (LLMs) and image diffusion models, none address discrete diffusion language models, which are becoming popular due to their high inference throughput. In this paper, we introduce the first watermarking method for discrete diffusion models by applying the distribution-preserving Gumbel-max trick at every diffusion step and seeding the randomness with the sequence index to enable reliable detection. We experimentally demonstrate that our scheme is reliably detectable on state-of-the-art diffusion language models and analytically prove that it is distortion-free with an exponentially decaying probability of false detection in the token sequence length.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2511.02083v1",
    "published_date": "2025-11-03 21:43:44 UTC",
    "updated_date": "2025-11-03 21:43:44 UTC"
  },
  {
    "arxiv_id": "2511.07442v1",
    "title": "Pinching Antennas Meet AI in Next-Generation Wireless Networks",
    "authors": [
      "Fang Fang",
      "Zhiguo Ding",
      "Victor C. M. Leung",
      "Lajos Hanzo"
    ],
    "abstract": "Next-generation (NG) wireless networks must embrace innate intelligence in support of demanding emerging applications, such as extended reality and autonomous systems, under ultra-reliable and low-latency requirements. Pinching antennas (PAs), a new flexible low-cost technology, can create line-of-sight links by dynamically activating small dielectric pinches along a waveguide on demand. As a compelling complement, artificial intelligence (AI) offers the intelligence needed to manage the complex control of PA activation positions and resource allocation in these dynamic environments. This article explores the \"win-win\" cooperation between AI and PAs: AI facilitates the adaptive optimization of PA activation positions along the waveguide, while PAs support edge AI tasks such as federated learning and over-the-air aggregation. We also discuss promising research directions including large language model-driven PA control frameworks, and how PA-AI integration can advance semantic communications, and integrated sensing and communication. This synergy paves the way for adaptive, resilient, and self-optimizing NG networks.",
    "categories": [
      "cs.NI",
      "cs.AI"
    ],
    "primary_category": "cs.NI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2511.07442v1",
    "published_date": "2025-11-03 21:32:00 UTC",
    "updated_date": "2025-11-03 21:32:00 UTC"
  },
  {
    "arxiv_id": "2511.02071v1",
    "title": "Human-AI Co-Embodied Intelligence for Scientific Experimentation and Manufacturing",
    "authors": [
      "Xinyi Lin",
      "Yuyang Zhang",
      "Yuanhang Gan",
      "Juntao Chen",
      "Hao Shen",
      "Yichun He",
      "Lijun Li",
      "Ze Yuan",
      "Shuang Wang",
      "Chaohao Wang",
      "Rui Zhang",
      "Na Li",
      "Jia Liu"
    ],
    "abstract": "Scientific experiment and manufacture rely on complex, multi-step procedures that demand continuous human expertise for precise execution and decision-making. Despite advances in machine learning and automation, conventional models remain confined to virtual domains, while real-world experiment and manufacture still rely on human supervision and expertise. This gap between machine intelligence and physical execution limits reproducibility, scalability, and accessibility across scientific and manufacture workflows. Here, we introduce human-AI co-embodied intelligence, a new form of physical AI that unites human users, agentic AI, and wearable hardware into an integrated system for real-world experiment and intelligent manufacture. In this paradigm, humans provide precise execution and control, while agentic AI contributes memory, contextual reasoning, adaptive planning, and real-time feedback. The wearable interface continuously captures the experimental and manufacture processes, facilitates seamless communication between humans and AI for corrective guidance and interpretable collaboration. As a demonstration, we present Agentic-Physical Experimentation (APEX) system, coupling agentic reasoning with physical execution through mixed-reality. APEX observes and interprets human actions, aligns them with standard operating procedures, provides 3D visual guidance, and analyzes every step. Implemented in a cleanroom for flexible electronics fabrication, APEX system achieves context-aware reasoning with accuracy exceeding general multimodal large language models, corrects errors in real time, and transfers expertise to beginners. These results establish a new class of agentic-physical-human intelligence that extends agentic reasoning beyond computation into the physical domain, transforming scientific research and manufacturing into autonomous, traceable, interpretable, and scalable processes.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2511.02071v1",
    "published_date": "2025-11-03 21:12:48 UTC",
    "updated_date": "2025-11-03 21:12:48 UTC"
  },
  {
    "arxiv_id": "2511.02062v1",
    "title": "Vortex: Hosting ML Inference and Knowledge Retrieval Services With Tight Latency and Throughput Requirements",
    "authors": [
      "Yuting Yang",
      "Tiancheng Yuan",
      "Jamal Hashim",
      "Thiago Garrett",
      "Jeffrey Qian",
      "Ann Zhang",
      "Yifan Wang",
      "Weijia Song",
      "Ken Birman"
    ],
    "abstract": "There is growing interest in deploying ML inference and knowledge retrieval as services that could support both interactive queries by end users and more demanding request flows that arise from AIs integrated into a end-user applications and deployed as agents. Our central premise is that these latter cases will bring service level latency objectives (SLOs). Existing ML serving platforms use batching to optimize for high throughput, exposing them to unpredictable tail latencies. Vortex enables an SLO-first approach. For identical tasks, Vortex's pipelines achieve significantly lower and more stable latencies than TorchServe and Ray Serve over a wide range of workloads, often enabling a given SLO target at more than twice the request rate. When RDMA is available, the Vortex advantage is even more significant.",
    "categories": [
      "cs.DB",
      "cs.AI"
    ],
    "primary_category": "cs.DB",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2511.02062v1",
    "published_date": "2025-11-03 20:59:27 UTC",
    "updated_date": "2025-11-03 20:59:27 UTC"
  },
  {
    "arxiv_id": "2511.02046v1",
    "title": "Text-VQA Aug: Pipelined Harnessing of Large Multimodal Models for Automated Synthesis",
    "authors": [
      "Soham Joshi",
      "Shwet Kamal Mishra",
      "Viswanath Gopalakrishnan"
    ],
    "abstract": "Creation of large-scale databases for Visual Question Answering tasks pertaining to the text data in a scene (text-VQA) involves skilful human annotation, which is tedious and challenging. With the advent of foundation models that handle vision and language modalities, and with the maturity of OCR systems, it is the need of the hour to establish an end-to-end pipeline that can synthesize Question-Answer (QA) pairs based on scene-text from a given image. We propose a pipeline for automated synthesis for text-VQA dataset that can produce faithful QA pairs, and which scales up with the availability of scene text data. Our proposed method harnesses the capabilities of multiple models and algorithms involving OCR detection and recognition (text spotting), region of interest (ROI) detection, caption generation, and question generation. These components are streamlined into a cohesive pipeline to automate the synthesis and validation of QA pairs. To the best of our knowledge, this is the first pipeline proposed to automatically synthesize and validate a large-scale text-VQA dataset comprising around 72K QA pairs based on around 44K images.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "First two authors contributed equally",
    "pdf_url": "https://arxiv.org/pdf/2511.02046v1",
    "published_date": "2025-11-03 20:28:22 UTC",
    "updated_date": "2025-11-03 20:28:22 UTC"
  },
  {
    "arxiv_id": "2511.02044v1",
    "title": "Regularization Through Reasoning: Systematic Improvements in Language Model Classification via Explanation-Enhanced Fine-Tuning",
    "authors": [
      "Vivswan Shah",
      "Randy Cogill",
      "Hanwei Yue",
      "Gopinath Chennupati",
      "Rinat Khaziev"
    ],
    "abstract": "Fine-tuning LLMs for classification typically maps inputs directly to labels. We ask whether attaching brief explanations to each label during fine-tuning yields better models. We evaluate conversational response quality along three axes: naturalness, comprehensiveness, and on-topic adherence, each rated on 5-point scales. Using ensemble-generated data from multiple LLMs, we fine-tune a 7B-parameter model and test across six diverse conversational datasets. Across 18 dataset, task settings, label-plus-explanation training outperforms label-only baselines.\n  A central and unexpected result concerns random tokens. We replace human-written explanations with text that is syntactically incoherent yet vocabulary-aligned with the originals (e.g., shuffled or bag-of-words variants). Despite lacking semantics, these pseudo-explanations still improve accuracy over label-only training and often narrow much of the gap to true explanations. The effect persists across datasets and training seeds, indicating that gains arise less from meaning than from structure: the extra token budget encourages richer intermediate computation and acts as a regularizer that reduces over-confident shortcuts.\n  Internal analyses support this view: explanation-augmented models exhibit higher activation entropy in intermediate layers alongside sharper predictive mass at the output layer, consistent with increased deliberation before decision. Overall, explanation-augmented fine-tuning, whether with genuine rationales or carefully constructed random token sequences, improves accuracy and reliability for LLM classification while clarifying how token-level scaffolding shapes computation during inference.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2511.02044v1",
    "published_date": "2025-11-03 20:25:42 UTC",
    "updated_date": "2025-11-03 20:25:42 UTC"
  },
  {
    "arxiv_id": "2511.02042v1",
    "title": "Quantum-Enhanced Generative Models for Rare Event Prediction",
    "authors": [
      "M. Z. Haider",
      "M. U. Ghouri",
      "Tayyaba Noreen",
      "M. Salman"
    ],
    "abstract": "Rare events such as financial crashes, climate extremes, and biological anomalies are notoriously difficult to model due to their scarcity and heavy-tailed distributions. Classical deep generative models often struggle to capture these rare occurrences, either collapsing low-probability modes or producing poorly calibrated uncertainty estimates. In this work, we propose the Quantum-Enhanced Generative Model (QEGM), a hybrid classical-quantum framework that integrates deep latent-variable models with variational quantum circuits. The framework introduces two key innovations: (1) a hybrid loss function that jointly optimizes reconstruction fidelity and tail-aware likelihood, and (2) quantum randomness-driven noise injection to enhance sample diversity and mitigate mode collapse. Training proceeds via a hybrid loop where classical parameters are updated through backpropagation while quantum parameters are optimized using parameter-shift gradients. We evaluate QEGM on synthetic Gaussian mixtures and real-world datasets spanning finance, climate, and protein structure. Results demonstrate that QEGM reduces tail KL divergence by up to 50 percent compared to state-of-the-art baselines (GAN, VAE, Diffusion), while improving rare-event recall and coverage calibration. These findings highlight the potential of QEGM as a principled approach for rare-event prediction, offering robustness beyond what is achievable with purely classical methods.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR",
      "cs.DC"
    ],
    "primary_category": "cs.LG",
    "comment": "IEEE Conference COMCOMAP 2025",
    "pdf_url": "https://arxiv.org/pdf/2511.02042v1",
    "published_date": "2025-11-03 20:24:55 UTC",
    "updated_date": "2025-11-03 20:24:55 UTC"
  },
  {
    "arxiv_id": "2511.02029v2",
    "title": "RobustFSM: Submodular Maximization in Federated Setting with Malicious Clients",
    "authors": [
      "Duc A. Tran",
      "Dung Truong",
      "Duy Le"
    ],
    "abstract": "Submodular maximization is an optimization problem benefiting many machine learning applications, where we seek a small subset best representing an extremely large dataset. We focus on the federated setting where the data are locally owned by decentralized clients who have their own definitions for the quality of representability. This setting requires repetitive aggregation of local information computed by the clients. While the main motivation is to respect the privacy and autonomy of the clients, the federated setting is vulnerable to client misbehaviors: malicious clients might share fake information. An analogy is backdoor attack in conventional federated learning, but our challenge differs freshly due to the unique characteristics of submodular maximization. We propose RobustFSM, a federated submodular maximization solution that is robust to various practical client attacks. Its performance is substantiated with an empirical evaluation study using real-world datasets. Numerical results show that the solution quality of RobustFSM substantially exceeds that of the conventional federated algorithm when attacks are severe. The degree of this improvement depends on the dataset and attack scenarios, which can be as high as 200%",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.DC"
    ],
    "primary_category": "cs.LG",
    "comment": "9 pages",
    "pdf_url": "https://arxiv.org/pdf/2511.02029v2",
    "published_date": "2025-11-03 20:07:21 UTC",
    "updated_date": "2025-11-08 00:25:01 UTC"
  },
  {
    "arxiv_id": "2511.02025v1",
    "title": "Path-Coordinated Continual Learning with Neural Tangent Kernel-Justified Plasticity: A Theoretical Framework with Near State-of-the-Art Performance",
    "authors": [
      "Rathin Chandra Shit"
    ],
    "abstract": "Catastrophic forgetting is one of the fundamental issues of continual learning because neural networks forget the tasks learned previously when trained on new tasks. The proposed framework is a new path-coordinated framework of continual learning that unites the Neural Tangent Kernel (NTK) theory of principled plasticity bounds, statistical validation by Wilson confidence intervals, and evaluation of path quality by the use of multiple metrics. Experimental evaluation shows an average accuracy of 66.7% at the cost of 23.4% catastrophic forgetting on Split-CIFAR10, a huge improvement over the baseline and competitive performance achieved, which is very close to state-of-the-art results. Further, it is found out that NTK condition numbers are predictive indicators of learning capacity limits, showing the existence of a critical threshold at condition number $>10^{11}$. It is interesting to note that the proposed strategy shows a tendency of lowering forgetting as the sequence of tasks progresses (27% to 18%), which is a system stabilization. The framework validates 80% of discovered paths with a rigorous statistical guarantee and maintains 90-97% retention on intermediate tasks. The core capacity limits of the continual learning environment are determined in the analysis, and actionable insights to enhance the adaptive regularization are offered.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.LG",
    "comment": "Under review, IEEE Letters",
    "pdf_url": "https://arxiv.org/pdf/2511.02025v1",
    "published_date": "2025-11-03 19:55:59 UTC",
    "updated_date": "2025-11-03 19:55:59 UTC"
  },
  {
    "arxiv_id": "2511.02022v1",
    "title": "Shared Parameter Subspaces and Cross-Task Linearity in Emergently Misaligned Behavior",
    "authors": [
      "Daniel Aarao Reis Arturi",
      "Eric Zhang",
      "Andrew Ansah",
      "Kevin Zhu",
      "Ashwinee Panda",
      "Aishwarya Balwani"
    ],
    "abstract": "Recent work has discovered that large language models can develop broadly misaligned behaviors after being fine-tuned on narrowly harmful datasets, a phenomenon known as emergent misalignment (EM). However, the fundamental mechanisms enabling such harmful generalization across disparate domains remain poorly understood. In this work, we adopt a geometric perspective to study EM and demonstrate that it exhibits a fundamental cross-task linear structure in how harmful behavior is encoded across different datasets. Specifically, we find a strong convergence in EM parameters across tasks, with the fine-tuned weight updates showing relatively high cosine similarities, as well as shared lower-dimensional subspaces as measured by their principal angles and projection overlaps. Furthermore, we also show functional equivalence via linear mode connectivity, wherein interpolated models across narrow misalignment tasks maintain coherent, broadly misaligned behavior. Our results indicate that EM arises from different narrow tasks discovering the same set of shared parameter directions, suggesting that harmful behaviors may be organized into specific, predictable regions of the weight landscape. By revealing this fundamental connection between parametric geometry and behavioral outcomes, we hope our work catalyzes further research on parameter space interpretability and weight-based interventions.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2511.02022v1",
    "published_date": "2025-11-03 19:50:24 UTC",
    "updated_date": "2025-11-03 19:50:24 UTC"
  },
  {
    "arxiv_id": "2511.02868v1",
    "title": "Proof-of-Spiking-Neurons(PoSN): Neuromorphic Consensus for Next-Generation Blockchains",
    "authors": [
      "M. Z. Haider",
      "M. U Ghouri",
      "Tayyaba Noreen",
      "M. Salman"
    ],
    "abstract": "Blockchain systems face persistent challenges of scalability, latency, and energy inefficiency. Existing consensus protocols such as Proof-of-Work (PoW) and Proof-of-Stake (PoS) either consume excessive resources or risk centralization. This paper proposes \\textit{Proof-of-Spiking-Neurons (PoSN)}, a neuromorphic consensus protocol inspired by spiking neural networks. PoSN encodes transactions as spike trains, elects leaders through competitive firing dynamics, and finalizes blocks via neural synchronization, enabling parallel and event-driven consensus with minimal energy overhead. A hybrid system architecture is implemented on neuromorphic platforms, supported by simulation frameworks such as Nengo and PyNN. Experimental results show significant gains in energy efficiency, throughput, and convergence compared to PoB and PoR. PoSN establishes a foundation for sustainable, adaptive blockchains suitable for IoT, edge, and large-scale distributed systems.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2511.02868v1",
    "published_date": "2025-11-03 19:31:47 UTC",
    "updated_date": "2025-11-03 19:31:47 UTC"
  },
  {
    "arxiv_id": "2511.02002v1",
    "title": "InteracSPARQL: An Interactive System for SPARQL Query Refinement Using Natural Language Explanations",
    "authors": [
      "Xiangru Jian",
      "Zhengyuan Dong",
      "M. Tamer Özsu"
    ],
    "abstract": "In recent years, querying semantic web data using SPARQL has remained challenging, especially for non-expert users, due to the language's complex syntax and the prerequisite of understanding intricate data structures. To address these challenges, we propose InteracSPARQL, an interactive SPARQL query generation and refinement system that leverages natural language explanations (NLEs) to enhance user comprehension and facilitate iterative query refinement. InteracSPARQL integrates LLMs with a rule-based approach to first produce structured explanations directly from SPARQL abstract syntax trees (ASTs), followed by LLM-based linguistic refinements. Users can interactively refine queries through direct feedback or LLM-driven self-refinement, enabling the correction of ambiguous or incorrect query components in real time. We evaluate InteracSPARQL on standard benchmarks, demonstrating significant improvements in query accuracy, explanation clarity, and overall user satisfaction compared to baseline approaches. Our experiments further highlight the effectiveness of combining rule-based methods with LLM-driven refinements to create more accessible and robust SPARQL interfaces.",
    "categories": [
      "cs.DB",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.DB",
    "comment": "Working paper",
    "pdf_url": "https://arxiv.org/pdf/2511.02002v1",
    "published_date": "2025-11-03 19:15:51 UTC",
    "updated_date": "2025-11-03 19:15:51 UTC"
  },
  {
    "arxiv_id": "2511.01999v1",
    "title": "TRACE: Textual Reasoning for Affordance Coordinate Extraction",
    "authors": [
      "Sangyun Park",
      "Jin Kim",
      "Yuchen Cui",
      "Matthew S. Brown"
    ],
    "abstract": "Vision-Language Models (VLMs) struggle to translate high-level instructions into the precise spatial affordances required for robotic manipulation. While visual Chain-of-Thought (CoT) methods exist, they are often computationally intensive. In this work, we introduce TRACE (Textual Reasoning for Affordance Coordinate Extraction), a novel methodology that integrates a textual Chain of Reasoning (CoR) into the affordance prediction process. We use this methodology to create the TRACE dataset, a large-scale collection created via an autonomous pipeline that pairs instructions with explicit textual rationales. By fine-tuning a VLM on this data, our model learns to externalize its spatial reasoning before acting. Our experiments show that our TRACE-tuned model achieves state-of-the-art performance, reaching 48.1% accuracy on the primary Where2Place (W2P) benchmark (a 9.6% relative improvement) and 55.0% on the more challenging W2P(h) subset. Crucially, an ablation study demonstrates that performance scales directly with the amount of reasoning data used, confirming the CoR's effectiveness. Furthermore, analysis of the model's attention maps reveals an interpretable reasoning process where focus shifts dynamically across reasoning steps. This work shows that training VLMs to generate a textual CoR is an effective and robust strategy for enhancing the precision, reliability, and interpretability of VLM-based robot control. Our dataset and code are available at https://github.com/jink-ucla/TRACE",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "ICCV 2025. *Equal contribution. †Corresponding author",
    "pdf_url": "https://arxiv.org/pdf/2511.01999v1",
    "published_date": "2025-11-03 19:13:26 UTC",
    "updated_date": "2025-11-03 19:13:26 UTC"
  },
  {
    "arxiv_id": "2511.01857v1",
    "title": "Trove: A Flexible Toolkit for Dense Retrieval",
    "authors": [
      "Reza Esfandiarpoor",
      "Max Zuo",
      "Stephen H. Bach"
    ],
    "abstract": "We introduce Trove, an easy-to-use open-source retrieval toolkit that simplifies research experiments without sacrificing flexibility or speed. For the first time, we introduce efficient data management features that load and process (filter, select, transform, and combine) retrieval datasets on the fly, with just a few lines of code. This gives users the flexibility to easily experiment with different dataset configurations without the need to compute and store multiple copies of large datasets. Trove is highly customizable: in addition to many built-in options, it allows users to freely modify existing components or replace them entirely with user-defined objects. It also provides a low-code and unified pipeline for evaluation and hard negative mining, which supports multi-node execution without any code changes. Trove's data management features reduce memory consumption by a factor of 2.6. Moreover, Trove's easy-to-use inference pipeline incurs no overhead, and inference times decrease linearly with the number of available nodes. Most importantly, we demonstrate how Trove simplifies retrieval experiments and allows for arbitrary customizations, thus facilitating exploratory research.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2511.01857v1",
    "published_date": "2025-11-03 18:59:57 UTC",
    "updated_date": "2025-11-03 18:59:57 UTC"
  },
  {
    "arxiv_id": "2511.01850v1",
    "title": "SmartMLOps Studio: Design of an LLM-Integrated IDE with Automated MLOps Pipelines for Model Development and Monitoring",
    "authors": [
      "Jiawei Jin",
      "Yingxin Su",
      "Xiaotong Zhu"
    ],
    "abstract": "The rapid expansion of artificial intelligence and machine learning (ML) applications has intensified the demand for integrated environments that unify model development, deployment, and monitoring. Traditional Integrated Development Environments (IDEs) focus primarily on code authoring, lacking intelligent support for the full ML lifecycle, while existing MLOps platforms remain detached from the coding workflow. To address this gap, this study proposes the design of an LLM-Integrated IDE with automated MLOps pipelines that enables continuous model development and monitoring within a single environment. The proposed system embeds a Large Language Model (LLM) assistant capable of code generation, debugging recommendation, and automatic pipeline configuration. The backend incorporates automated data validation, feature storage, drift detection, retraining triggers, and CI/CD deployment orchestration. This framework was implemented in a prototype named SmartMLOps Studio and evaluated using classification and forecasting tasks on the UCI Adult and M5 datasets. Experimental results demonstrate that SmartMLOps Studio reduces pipeline configuration time by 61%, improves experiment reproducibility by 45%, and increases drift detection accuracy by 14% compared to traditional workflows. By bridging intelligent code assistance and automated operational pipelines, this research establishes a novel paradigm for AI engineering - transforming the IDE from a static coding tool into a dynamic, lifecycle-aware intelligent platform for scalable and efficient model development.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2511.01850v1",
    "published_date": "2025-11-03 18:56:59 UTC",
    "updated_date": "2025-11-03 18:56:59 UTC"
  },
  {
    "arxiv_id": "2511.01846v1",
    "title": "Towards Robust Mathematical Reasoning",
    "authors": [
      "Thang Luong",
      "Dawsen Hwang",
      "Hoang H. Nguyen",
      "Golnaz Ghiasi",
      "Yuri Chervonyi",
      "Insuk Seo",
      "Junsu Kim",
      "Garrett Bingham",
      "Jonathan Lee",
      "Swaroop Mishra",
      "Alex Zhai",
      "Clara Huiyi Hu",
      "Henryk Michalewski",
      "Jimin Kim",
      "Jeonghyun Ahn",
      "Junhwi Bae",
      "Xingyou Song",
      "Trieu H. Trinh",
      "Quoc V. Le",
      "Junehyuk Jung"
    ],
    "abstract": "Finding the right north-star metrics is highly critical for advancing the mathematical reasoning capabilities of foundation models, especially given that existing evaluations are either too easy or only focus on getting correct short answers. To address these issues, we present IMO-Bench, a suite of advanced reasoning benchmarks, vetted by a panel of top specialists and that specifically targets the level of the International Mathematical Olympiad (IMO), the most prestigious venue for young mathematicians. IMO-AnswerBench first tests models on 400 diverse Olympiad problems with verifiable short answers. IMO-Proof Bench is the next-level evaluation for proof-writing capabilities, which includes both basic and advanced IMO level problems as well as detailed grading guidelines to facilitate automatic grading. These benchmarks played a crucial role in our historic achievement of the gold-level performance at IMO 2025 with Gemini Deep Think (Luong and Lockhart, 2025). Our model achieved 80.0% on IMO-AnswerBench and 65.7% on the advanced IMO-Proof Bench, surpassing the best non-Gemini models by large margins of 6.9% and 42.4% respectively. We also showed that autograders built with Gemini reasoning correlate well with human evaluations and construct IMO-GradingBench, with 1000 human gradings on proofs, to enable further progress in automatic evaluation of long-form answers. We hope that IMO-Bench will help the community towards advancing robust mathematical reasoning and release it at https://imobench.github.io/.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "EMNLP 2025 (main conference), https://aclanthology.org/2025.emnlp-main.1794/",
    "pdf_url": "https://arxiv.org/pdf/2511.01846v1",
    "published_date": "2025-11-03 18:53:02 UTC",
    "updated_date": "2025-11-03 18:53:02 UTC"
  },
  {
    "arxiv_id": "2511.01840v1",
    "title": "A Detailed Study on LLM Biases Concerning Corporate Social Responsibility and Green Supply Chains",
    "authors": [
      "Greta Ontrup",
      "Annika Bush",
      "Markus Pauly",
      "Meltem Aksoy"
    ],
    "abstract": "Organizations increasingly use Large Language Models (LLMs) to improve supply chain processes and reduce environmental impacts. However, LLMs have been shown to reproduce biases regarding the prioritization of sustainable business strategies. Thus, it is important to identify underlying training data biases that LLMs pertain regarding the importance and role of sustainable business and supply chain practices. This study investigates how different LLMs respond to validated surveys about the role of ethics and responsibility for businesses, and the importance of sustainable practices and relations with suppliers and customers. Using standardized questionnaires, we systematically analyze responses generated by state-of-the-art LLMs to identify variations. We further evaluate whether differences are augmented by four organizational culture types, thereby evaluating the practical relevance of identified biases. The findings reveal significant systematic differences between models and demonstrate that organizational culture prompts substantially modify LLM responses. The study holds important implications for LLM-assisted decision-making in sustainability contexts.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "37 pages, 2 figures",
    "pdf_url": "https://arxiv.org/pdf/2511.01840v1",
    "published_date": "2025-11-03 18:48:48 UTC",
    "updated_date": "2025-11-03 18:48:48 UTC"
  },
  {
    "arxiv_id": "2511.01838v1",
    "title": "Efficient Vector Symbolic Architectures from Histogram Recovery",
    "authors": [
      "Zirui Deng",
      "Netanel Raviv"
    ],
    "abstract": "Vector symbolic architectures (VSAs) are a family of information representation techniques which enable composition, i.e., creating complex information structures from atomic vectors via binding and superposition, and have recently found wide ranging applications in various neurosymbolic artificial intelligence (AI) systems. Recently, Raviv proposed the use of random linear codes in VSAs, suggesting that their subcode structure enables efficient binding, while preserving the quasi-orthogonality that is necessary for neural processing. Yet, random linear codes are difficult to decode under noise, which severely limits the resulting VSA's ability to support recovery, i.e., the retrieval of information objects and their attributes from a noisy compositional representation.\n  In this work we bridge this gap by utilizing coding theoretic tools. First, we argue that the concatenation of Reed-Solomon and Hadamard codes is suitable for VSA, due to the mutual quasi-orthogonality of the resulting codewords (a folklore result). Second, we show that recovery of the resulting compositional representations can be done by solving a problem we call histogram recovery. In histogram recovery, a collection of $N$ histograms over a finite field is given as input, and one must find a collection of Reed-Solomon codewords of length $N$ whose entry-wise symbol frequencies obey those histograms. We present an optimal solution to the histogram recovery problem by using algorithms related to list-decoding, and analyze the resulting noise resilience. Our results give rise to a noise-resilient VSA with formal guarantees regarding efficient encoding, quasi-orthogonality, and recovery, without relying on any heuristics or training, and while operating at improved parameters relative to similar solutions such as the Hadamard code.",
    "categories": [
      "cs.IT",
      "cs.AI",
      "cs.NE"
    ],
    "primary_category": "cs.IT",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2511.01838v1",
    "published_date": "2025-11-03 18:45:47 UTC",
    "updated_date": "2025-11-03 18:45:47 UTC"
  },
  {
    "arxiv_id": "2511.01831v2",
    "title": "Dynamic Routing Between Experts: A Data-Efficient Approach to Continual Learning in Vision-Language Models",
    "authors": [
      "Jay Mohta",
      "Kenan Emir Ak",
      "Dimitrios Dimitriadis",
      "Yan Xu",
      "Mingwei Shen"
    ],
    "abstract": "Vision-Language Models (VLMs) suffer from catastrophic forgetting when sequentially fine-tuned on new tasks, degrading performance on previously learned foundational and task-specific capabilities. While multi-task learning can mitigate forgetting, it requires simultaneous access to all datasets and imposes computational overhead that scales linearly with the number of tasks. In this work, we introduce a routing-based approach that enables the integration of new tasks while preserving the foundational knowledge acquired during pretraining. We evaluate our method using InternVL-2 models (2B and 8B parameters) and demonstrate that routing preserves the model's foundational capabilities by maintaining performance on general-purpose benchmarks such as ChartQA, MMBench, and DocVQA, while simultaneously improving accuracy on specialized tasks. Importantly, our approach achieves this without requiring concurrent access to data from all tasks, avoiding the significant computational and data overhead associated with traditional multi-task learning. We further conduct extensive ablation studies to evaluate the scalability and robustness of routing-based learning, showing that the approach is resilient to a growing number of tasks and performs particularly well when new tasks are semantically related. Finally, we show that the routing mechanism enables superior cross-modal transfer between language and vision capabilities, allowing knowledge learned in one modality to enhance performance in another capability not achieved by existing continual learning methods.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2511.01831v2",
    "published_date": "2025-11-03 18:39:32 UTC",
    "updated_date": "2025-11-04 03:19:41 UTC"
  },
  {
    "arxiv_id": "2511.01824v1",
    "title": "Simulating Environments with Reasoning Models for Agent Training",
    "authors": [
      "Yuetai Li",
      "Huseyin A Inan",
      "Xiang Yue",
      "Wei-Ning Chen",
      "Lukas Wutschitz",
      "Janardhan Kulkarni",
      "Radha Poovendran",
      "Robert Sim",
      "Saravan Rajmohan"
    ],
    "abstract": "LLM agents excel in compact environments requiring deep reasoning but remain brittle when operating in broader, more complex contexts that demand robustness across diverse tools and schemas. Building bespoke environments for training is heavy, brittle, and limits progress. In this paper, we demonstrate that LLMs can simulate realistic environment feedback without access to actual testbed data or APIs. Inspired by this capability, we propose two frameworks: Simia-SFT, a pipeline that synthesizes SFT data by amplifying small seed sets into diverse trajectories in an environment-agnostic manner, and Simia-RL, a framework that enables RL training without real environment implementations through LLM-simulated feedback. Fine-tuning open models yields consistent improvements across multiple benchmarks, surpassing GPT-4o and approaching o4-mini on $τ^2$-Bench. Together, Simia-SFT and Simia-RL enable scalable agent training without environment engineering, replacing heavy and brittle implementations with flexible LLM-based simulation.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2511.01824v1",
    "published_date": "2025-11-03 18:29:57 UTC",
    "updated_date": "2025-11-03 18:29:57 UTC"
  },
  {
    "arxiv_id": "2511.01819v1",
    "title": "Machine and Deep Learning for Indoor UWB Jammer Localization",
    "authors": [
      "Hamed Fard",
      "Mahsa Kholghi",
      "Benedikt Groß",
      "Gerhard Wunder"
    ],
    "abstract": "Ultra-wideband (UWB) localization delivers centimeter-scale accuracy but is vulnerable to jamming attacks, creating security risks for asset tracking and intrusion detection in smart buildings. Although machine learning (ML) and deep learning (DL) methods have improved tag localization, localizing malicious jammers within a single room and across changing indoor layouts remains largely unexplored. Two novel UWB datasets, collected under original and modified room configurations, are introduced to establish comprehensive ML/DL baselines. Performance is rigorously evaluated using a variety of classification and regression metrics. On the source dataset with the collected UWB features, Random Forest achieves the highest F1-macro score of 0.95 and XGBoost achieves the lowest mean Euclidean error of 20.16 cm. However, deploying these source-trained models in the modified room layout led to severe performance degradation, with XGBoost's mean Euclidean error increasing tenfold to 207.99 cm, demonstrating significant domain shift. To mitigate this degradation, a domain-adversarial ConvNeXt autoencoder (A-CNT) is proposed that leverages a gradient-reversal layer to align CIR-derived features across domains. The A-CNT framework restores localization performance by reducing the mean Euclidean error to 34.67 cm. This represents a 77 percent improvement over non-adversarial transfer learning and an 83 percent improvement over the best baseline, restoring the fraction of samples within 30 cm to 0.56. Overall, the results demonstrate that adversarial feature alignment enables robust and transferable indoor jammer localization despite environmental changes. Code and dataset available at https://github.com/afbf4c8996f/Jammer-Loc",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted at the 20th International Conference on Risks and Security of Internet and Systems (CRiSIS 2025, Gatineau-Canada, https://crisis2025.uqo.ca/). The paper will soon be published as post-proceedings in Springer's LNCS",
    "pdf_url": "https://arxiv.org/pdf/2511.01819v1",
    "published_date": "2025-11-03 18:26:14 UTC",
    "updated_date": "2025-11-03 18:26:14 UTC"
  },
  {
    "arxiv_id": "2511.01815v1",
    "title": "KV Cache Transform Coding for Compact Storage in LLM Inference",
    "authors": [
      "Konrad Staniszewski",
      "Adrian Łańcucki"
    ],
    "abstract": "Serving large language models (LLMs) at scale necessitates efficient key-value (KV) cache management. KV caches can be reused across conversation turns via shared-prefix prompts that are common in iterative code editing and chat. However, stale caches consume scarce GPU memory, require offloading, or force recomputation. We present KVTC, a lightweight transform coder that compresses KV caches for compact on-GPU and off-GPU storage. Drawing on classical media compression, KVTC combines PCA-based feature decorrelation, adaptive quantization, and entropy coding. It requires only a brief initial calibration and leaves model parameters unchanged. By exploiting redundancies in KV caches, KVTC achieves up to 20$\\times$ compression while maintaining reasoning and long-context accuracy, and 40$\\times$ or higher for specific use cases. We test KVTC with Llama 3, Mistral NeMo, and R1-Qwen 2.5 models across benchmarks including AIME25, LiveCodeBench, GSM8K, MMLU, Qasper, RULER, and MATH-500. It consistently outperforms inference-time baselines such as token eviction, quantization, and SVD-based methods, while achieving higher compression ratios. These results support KVTC as a practical building block for memory-efficient LLM serving with reusable KV caches.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2511.01815v1",
    "published_date": "2025-11-03 18:20:35 UTC",
    "updated_date": "2025-11-03 18:20:35 UTC"
  },
  {
    "arxiv_id": "2511.01807v1",
    "title": "Plan-and-Write: Structure-Guided Length Control for LLMs without Model Retraining",
    "authors": [
      "Adewale Akinfaderin",
      "Shreyas Subramanian",
      "Akarsha Sehwag"
    ],
    "abstract": "Length control in Large Language Models (LLMs) is a crucial but under-addressed challenge, with applications ranging from voice interfaces requiring concise responses to research summaries needing comprehensive outputs. Current approaches to length control, including Regularized DPO, Length-Instruction Fine Tuning, and tool-augmented methods, typically require expensive model retraining or complex inference-time tooling. This paper presents a prompt engineering methodology that enables precise length control without model retraining. Our structure-guided approach implements deliberate planning and word counting mechanisms within the prompt, encouraging the model to carefully track and adhere to specified length constraints. Comprehensive evaluations across six state-of-the-art LLMs demonstrate that our method significantly improves length fidelity for several models compared to standard prompting when applied to document summarization tasks, particularly for shorter-to-medium length constraints. The proposed technique shows varying benefits across different model architectures, with some models demonstrating up to 37.6% improvement in length adherence. Quality evaluations further reveal that our approach maintains or enhances overall output quality compared to standard prompting techniques. Our approach provides an immediately deployable solution for applications requiring precise length control, particularly valuable for production environments where model retraining is impractical or cost-prohibitive.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Presented at Workshop on Prompt Optimization, KDD 2025, Toronto, Canada",
    "pdf_url": "https://arxiv.org/pdf/2511.01807v1",
    "published_date": "2025-11-03 18:10:42 UTC",
    "updated_date": "2025-11-03 18:10:42 UTC"
  },
  {
    "arxiv_id": "2511.01805v2",
    "title": "Accumulating Context Changes the Beliefs of Language Models",
    "authors": [
      "Jiayi Geng",
      "Howard Chen",
      "Ryan Liu",
      "Manoel Horta Ribeiro",
      "Robb Willer",
      "Graham Neubig",
      "Thomas L. Griffiths"
    ],
    "abstract": "Language model (LM) assistants are increasingly used in applications such as brainstorming and research. Improvements in memory and context size have allowed these models to become more autonomous, which has also resulted in more text accumulation in their context windows without explicit user intervention. This comes with a latent risk: the belief profiles of models -- their understanding of the world as manifested in their responses or actions -- may silently change as context accumulates. This can lead to subtly inconsistent user experiences, or shifts in behavior that deviate from the original alignment of the models. In this paper, we explore how accumulating context by engaging in interactions and processing text -- talking and reading -- can change the beliefs of language models, as manifested in their responses and behaviors. Our results reveal that models' belief profiles are highly malleable: GPT-5 exhibits a 54.7% shift in its stated beliefs after 10 rounds of discussion about moral dilemmas and queries about safety, while Grok 4 shows a 27.2% shift on political issues after reading texts from the opposing position. We also examine models' behavioral changes by designing tasks that require tool use, where each tool selection corresponds to an implicit belief. We find that these changes align with stated belief shifts, suggesting that belief shifts will be reflected in actual behavior in agentic systems. Our analysis exposes the hidden risk of belief shift as models undergo extended sessions of talking or reading, rendering their opinions and actions unreliable.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2511.01805v2",
    "published_date": "2025-11-03 18:05:57 UTC",
    "updated_date": "2025-11-04 17:41:28 UTC"
  },
  {
    "arxiv_id": "2511.01795v1",
    "title": "Fractional Diffusion Bridge Models",
    "authors": [
      "Gabriel Nobis",
      "Maximilian Springenberg",
      "Arina Belova",
      "Rembert Daems",
      "Christoph Knochenhauer",
      "Manfred Opper",
      "Tolga Birdal",
      "Wojciech Samek"
    ],
    "abstract": "We present Fractional Diffusion Bridge Models (FDBM), a novel generative diffusion bridge framework driven by an approximation of the rich and non-Markovian fractional Brownian motion (fBM). Real stochastic processes exhibit a degree of memory effects (correlations in time), long-range dependencies, roughness and anomalous diffusion phenomena that are not captured in standard diffusion or bridge modeling due to the use of Brownian motion (BM). As a remedy, leveraging a recent Markovian approximation of fBM (MA-fBM), we construct FDBM that enable tractable inference while preserving the non-Markovian nature of fBM. We prove the existence of a coupling-preserving generative diffusion bridge and leverage it for future state prediction from paired training data. We then extend our formulation to the Schrödinger bridge problem and derive a principled loss function to learn the unpaired data translation. We evaluate FDBM on both tasks: predicting future protein conformations from aligned data, and unpaired image translation. In both settings, FDBM achieves superior performance compared to the Brownian baselines, yielding lower root mean squared deviation (RMSD) of C$_α$ atomic positions in protein structure prediction and lower Fréchet Inception Distance (FID) in unpaired image translation.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV",
      "cs.RO",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "To appear in NeurIPS 2025 proceedings. This version includes post-camera-ready revisions",
    "pdf_url": "https://arxiv.org/pdf/2511.01795v1",
    "published_date": "2025-11-03 17:51:10 UTC",
    "updated_date": "2025-11-03 17:51:10 UTC"
  },
  {
    "arxiv_id": "2511.01794v1",
    "title": "Random Initialization of Gated Sparse Adapters",
    "authors": [
      "Vi Retault",
      "Yohaï-Eliel Berreby"
    ],
    "abstract": "When fine-tuning language models on new tasks, catastrophic forgetting -- performance degradation on previously-learned tasks -- is a ubiquitous problem. While Parameter-Efficient Fine-Tuning (PEFT) methods like LoRA address this through low-rank adapters, sparse adaptation offers an alternative that doesn't impose rank constraints. We introduce Random Initialization of Gated Sparse Adapters (RIGSA), which starts from randomly-initialized full-rank adapters, gates them with a ReZero analog, and sparsifies them with iterative magnitude pruning. We evaluate RIGSA on SmolLM2-1.7B-Instruct using a novel vision-in-text task (Textual MNIST) and measure forgetting on PIQA, HellaSwag, and GSM8k. SmolLM2-1.7B-Instruct initially performs around chance level on Textual MNIST, and is capable of learning the task through RIGSA, 4-bit QLoRA and random masking. In spite of having more trainable parameters than QLoRA, the RIGSA configurations that we studied displayed less forgetting than QLoRA, particularly on GSM8k, though it performs comparably to random masking.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "13 pages (8 main), 6 figures (4 main). Accepted by NewInML workshop @ ICML 2025 on June 27, 2025",
    "pdf_url": "https://arxiv.org/pdf/2511.01794v1",
    "published_date": "2025-11-03 17:49:44 UTC",
    "updated_date": "2025-11-03 17:49:44 UTC"
  },
  {
    "arxiv_id": "2511.01791v1",
    "title": "GenDexHand: Generative Simulation for Dexterous Hands",
    "authors": [
      "Feng Chen",
      "Zhuxiu Xu",
      "Tianzhe Chu",
      "Xunzhe Zhou",
      "Li Sun",
      "Zewen Wu",
      "Shenghua Gao",
      "Zhongyu Li",
      "Yanchao Yang",
      "Yi Ma"
    ],
    "abstract": "Data scarcity remains a fundamental bottleneck for embodied intelligence. Existing approaches use large language models (LLMs) to automate gripper-based simulation generation, but they transfer poorly to dexterous manipulation, which demands more specialized environment design. Meanwhile, dexterous manipulation tasks are inherently more difficult due to their higher degrees of freedom. Massively generating feasible and trainable dexterous hand tasks remains an open challenge. To this end, we present GenDexHand, a generative simulation pipeline that autonomously produces diverse robotic tasks and environments for dexterous manipulation. GenDexHand introduces a closed-loop refinement process that adjusts object placements and scales based on vision-language model (VLM) feedback, substantially improving the average quality of generated environments. Each task is further decomposed into sub-tasks to enable sequential reinforcement learning, reducing training time and increasing success rates. Our work provides a viable path toward scalable training of diverse dexterous hand behaviors in embodied intelligence by offering a simulation-based solution to synthetic data generation. Our website: https://winniechen2002.github.io/GenDexHand/.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2511.01791v1",
    "published_date": "2025-11-03 17:45:38 UTC",
    "updated_date": "2025-11-03 17:45:38 UTC"
  },
  {
    "arxiv_id": "2511.04703v1",
    "title": "Measuring what Matters: Construct Validity in Large Language Model Benchmarks",
    "authors": [
      "Andrew M. Bean",
      "Ryan Othniel Kearns",
      "Angelika Romanou",
      "Franziska Sofia Hafner",
      "Harry Mayne",
      "Jan Batzner",
      "Negar Foroutan",
      "Chris Schmitz",
      "Karolina Korgul",
      "Hunar Batra",
      "Oishi Deb",
      "Emma Beharry",
      "Cornelius Emde",
      "Thomas Foster",
      "Anna Gausen",
      "María Grandury",
      "Simeng Han",
      "Valentin Hofmann",
      "Lujain Ibrahim",
      "Hazel Kim",
      "Hannah Rose Kirk",
      "Fangru Lin",
      "Gabrielle Kaili-May Liu",
      "Lennart Luettgau",
      "Jabez Magomere",
      "Jonathan Rystrøm",
      "Anna Sotnikova",
      "Yushi Yang",
      "Yilun Zhao",
      "Adel Bibi",
      "Antoine Bosselut",
      "Ronald Clark",
      "Arman Cohan",
      "Jakob Foerster",
      "Yarin Gal",
      "Scott A. Hale",
      "Inioluwa Deborah Raji",
      "Christopher Summerfield",
      "Philip H. S. Torr",
      "Cozmin Ududec",
      "Luc Rocher",
      "Adam Mahdi"
    ],
    "abstract": "Evaluating large language models (LLMs) is crucial for both assessing their capabilities and identifying safety or robustness issues prior to deployment. Reliably measuring abstract and complex phenomena such as 'safety' and 'robustness' requires strong construct validity, that is, having measures that represent what matters to the phenomenon. With a team of 29 expert reviewers, we conduct a systematic review of 445 LLM benchmarks from leading conferences in natural language processing and machine learning. Across the reviewed articles, we find patterns related to the measured phenomena, tasks, and scoring metrics which undermine the validity of the resulting claims. To address these shortcomings, we provide eight key recommendations and detailed actionable guidance to researchers and practitioners in developing LLM benchmarks.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "39th Conference on Neural Information Processing Systems (NeurIPS 2025) Track on Datasets and Benchmarks",
    "pdf_url": "https://arxiv.org/pdf/2511.04703v1",
    "published_date": "2025-11-03 17:39:40 UTC",
    "updated_date": "2025-11-03 17:39:40 UTC"
  },
  {
    "arxiv_id": "2511.02866v1",
    "title": "LM-Fix: Lightweight Bit-Flip Detection and Rapid Recovery Framework for Language Models",
    "authors": [
      "Ahmad Tahmasivand",
      "Noureldin Zahran",
      "Saba Al-Sayouri",
      "Mohammed Fouda",
      "Khaled N. Khasawneh"
    ],
    "abstract": "This paper presents LM-Fix, a lightweight detection and rapid recovery framework for faults in large language models (LLMs). Existing integrity approaches are often heavy or slow for modern LLMs. LM-Fix runs a short test-vector pass and uses hash-guided checks to detect bit-flip faults, then repairs them locally without a full reload. Across multiple models, it detects over 94% of single-bit flips at TVL=200 and nearly 100% of multi-bit flips with approximately 1% to 7.7% runtime overhead; recovery is more than 100x faster than reloading. These results show a practical, low-overhead solution to keep LLMs reliable in production",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.AR",
      "cs.CR"
    ],
    "primary_category": "cs.SE",
    "comment": "Accepted at IEEE ICCD 2025. Code: https://github.com/ata990/lm-fix. Detects over 94 percent single-bit flips (near 100 percent multi-bit) with about 1 to 7.7 percent overhead; recovery is over 100x faster than a full reload. Keywords: LLMs, bit-flip, fault injection, reliability, security, Rowhammer, SDC, Jailbreaking, Attack, Defense, GPU DRAM faults",
    "pdf_url": "https://arxiv.org/pdf/2511.02866v1",
    "published_date": "2025-11-03 17:37:39 UTC",
    "updated_date": "2025-11-03 17:37:39 UTC"
  },
  {
    "arxiv_id": "2511.07441v3",
    "title": "AudAgent: Automated Auditing of Privacy Policy Compliance in AI Agents",
    "authors": [
      "Ye Zheng",
      "Yidan Hu"
    ],
    "abstract": "AI agents can autonomously perform tasks and, often without explicit user consent, collect or disclose users' sensitive local data, which raises serious privacy concerns. Although AI agents' privacy policies describe their intended data practices, there remains limited transparency and accountability about whether runtime behavior matches those policies. To close this gap, we introduce AudAgent, a visual tool that continuously monitors AI agents' data practices in real time and guards compliance with stated privacy policies.\n  AudAgent consists of four components for automated privacy auditing of AI agents. (i) Policy formalization: a novel cross-LLM voting mechanism to guarantee confidence of the parsed privacy policy model. (ii) Runtime annotation: a lightweight Presidio-based analyzer detects sensitive data and annotates data practices based on the AI agent's context and the privacy policy model. (iii) Compliance auditing: ontology graphs and automata-based checking connect the privacy policy model with runtime annotations, enabling on-the-fly compliance checking. (iv) User interface: an infrastructure-independent implementation visualizes the real-time execution trace of AI agents along with potential privacy policy violations, providing user-friendly transparency and accountability.\n  We evaluate AudAgent with AI agents built using mainstream frameworks, demonstrating its effectiveness in detecting and visualizing privacy policy violations in real time. Using AudAgent, we also find that most privacy policies omit explicit safeguards for highly sensitive data such as SSNs, whose misuse violates legal requirements, and that many agents do not refuse handling such data via third-party tools, including those controlled by Claude, Gemini, and DeepSeek. AudAgent proactively blocks operations on such data, overriding the agents' original privacy policy and behavior.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "Submitted to PETS'26 Issue 3",
    "pdf_url": "https://arxiv.org/pdf/2511.07441v3",
    "published_date": "2025-11-03 17:32:08 UTC",
    "updated_date": "2025-12-04 18:46:20 UTC"
  },
  {
    "arxiv_id": "2511.01775v1",
    "title": "How Far Are Surgeons from Surgical World Models? A Pilot Study on Zero-shot Surgical Video Generation with Expert Assessment",
    "authors": [
      "Zhen Chen",
      "Qing Xu",
      "Jinlin Wu",
      "Biao Yang",
      "Yuhao Zhai",
      "Geng Guo",
      "Jing Zhang",
      "Yinlu Ding",
      "Nassir Navab",
      "Jiebo Luo"
    ],
    "abstract": "Foundation models in video generation are demonstrating remarkable capabilities as potential world models for simulating the physical world. However, their application in high-stakes domains like surgery, which demand deep, specialized causal knowledge rather than general physical rules, remains a critical unexplored gap. To systematically address this challenge, we present SurgVeo, the first expert-curated benchmark for video generation model evaluation in surgery, and the Surgical Plausibility Pyramid (SPP), a novel, four-tiered framework tailored to assess model outputs from basic appearance to complex surgical strategy. On the basis of the SurgVeo benchmark, we task the advanced Veo-3 model with a zero-shot prediction task on surgical clips from laparoscopic and neurosurgical procedures. A panel of four board-certified surgeons evaluates the generated videos according to the SPP. Our results reveal a distinct \"plausibility gap\": while Veo-3 achieves exceptional Visual Perceptual Plausibility, it fails critically at higher levels of the SPP, including Instrument Operation Plausibility, Environment Feedback Plausibility, and Surgical Intent Plausibility. This work provides the first quantitative evidence of the chasm between visually convincing mimicry and causal understanding in surgical AI. Our findings from SurgVeo and the SPP establish a crucial foundation and roadmap for developing future models capable of navigating the complexities of specialized, real-world healthcare domains.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.MM"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2511.01775v1",
    "published_date": "2025-11-03 17:28:54 UTC",
    "updated_date": "2025-11-03 17:28:54 UTC"
  },
  {
    "arxiv_id": "2511.01767v2",
    "title": "Wonder3D++: Cross-domain Diffusion for High-fidelity 3D Generation from a Single Image",
    "authors": [
      "Yuxiao Yang",
      "Xiao-Xiao Long",
      "Zhiyang Dou",
      "Cheng Lin",
      "Yuan Liu",
      "Qingsong Yan",
      "Yuexin Ma",
      "Haoqian Wang",
      "Zhiqiang Wu",
      "Wei Yin"
    ],
    "abstract": "In this work, we introduce \\textbf{Wonder3D++}, a novel method for efficiently generating high-fidelity textured meshes from single-view images. Recent methods based on Score Distillation Sampling (SDS) have shown the potential to recover 3D geometry from 2D diffusion priors, but they typically suffer from time-consuming per-shape optimization and inconsistent geometry. In contrast, certain works directly produce 3D information via fast network inferences, but their results are often of low quality and lack geometric details. To holistically improve the quality, consistency, and efficiency of single-view reconstruction tasks, we propose a cross-domain diffusion model that generates multi-view normal maps and the corresponding color images. To ensure the consistency of generation, we employ a multi-view cross-domain attention mechanism that facilitates information exchange across views and modalities. Lastly, we introduce a cascaded 3D mesh extraction algorithm that drives high-quality surfaces from the multi-view 2D representations in only about $3$ minute in a coarse-to-fine manner. Our extensive evaluations demonstrate that our method achieves high-quality reconstruction results, robust generalization, and good efficiency compared to prior works. Code available at https://github.com/xxlong0/Wonder3D/tree/Wonder3D_Plus.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "21 pages, 19 figures, accepted by TPAMI",
    "pdf_url": "https://arxiv.org/pdf/2511.01767v2",
    "published_date": "2025-11-03 17:24:18 UTC",
    "updated_date": "2025-11-19 03:58:18 UTC"
  },
  {
    "arxiv_id": "2511.01763v1",
    "title": "Context-Guided Decompilation: A Step Towards Re-executability",
    "authors": [
      "Xiaohan Wang",
      "Yuxin Hu",
      "Kevin Leach"
    ],
    "abstract": "Binary decompilation plays an important role in software security analysis, reverse engineering, and malware understanding when source code is unavailable. However, existing decompilation techniques often fail to produce source code that can be successfully recompiled and re-executed, particularly for optimized binaries. Recent advances in large language models (LLMs) have enabled neural approaches to decompilation, but the generated code is typically only semantically plausible rather than truly executable, limiting their practical reliability. These shortcomings arise from compiler optimizations and the loss of semantic cues in compiled code, which LLMs struggle to recover without contextual guidance. To address this challenge, we propose ICL4Decomp, a hybrid decompilation framework that leverages in-context learning (ICL) to guide LLMs toward generating re-executable source code. We evaluate our method across multiple datasets, optimization levels, and compilers, demonstrating around 40\\% improvement in re-executability over state-of-the-art decompilation methods while maintaining robustness.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2511.01763v1",
    "published_date": "2025-11-03 17:21:39 UTC",
    "updated_date": "2025-11-03 17:21:39 UTC"
  },
  {
    "arxiv_id": "2511.01758v1",
    "title": "RLAC: Reinforcement Learning with Adversarial Critic for Free-Form Generation Tasks",
    "authors": [
      "Mian Wu",
      "Gavin Zhang",
      "Sewon Min",
      "Sergey Levine",
      "Aviral Kumar"
    ],
    "abstract": "Open-ended generation tasks require outputs to satisfy diverse and often implicit task-specific evaluation rubrics. The sheer number of relevant rubrics leads to prohibitively high verification costs and incomplete assessments of a response, making reinforcement learning (RL) post-training with rubric-based rewards difficult to scale. This problem is exacerbated by the fact that often the best way to combine these rubrics into one single reward is also highly prompt-specific. We propose Reinforcement Learning with Adversarial Critic (RLAC), a post-training approach that addresses these challenges via dynamic rubric verification. Our approach employs a large language model (LLM) as a critic that dynamically identifies only the most likely failure modes (e.g., a factual error or unhandled edge case), which are then verified by an external validator to optimize both generator and critic jointly. By training both the generator and the critic, this game enhances the critic's error detection and the generator's output quality while reducing required verifications. Our experiments demonstrate that RLAC improves factual accuracy in text generation and correctness in code generation, while also outperforming exhaustive verification and reward model methods. We show that dynamic critics are more effective than fixed critics, showcasing the potential of RLAC for scaling RL post-training to free-form generation tasks.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "Project page: https://mianwu01.github.io/RLAC_website/",
    "pdf_url": "https://arxiv.org/pdf/2511.01758v1",
    "published_date": "2025-11-03 17:15:05 UTC",
    "updated_date": "2025-11-03 17:15:05 UTC"
  },
  {
    "arxiv_id": "2511.14774v2",
    "title": "LiveCLKTBench: Towards Reliable Evaluation of Cross-Lingual Knowledge Transfer in Multilingual LLMs",
    "authors": [
      "Pei-Fu Guo",
      "Yun-Da Tsai",
      "Chun-Chia Hsu",
      "Kai-Xin Chen",
      "Ya-An Tsai",
      "Kai-Wei Chang",
      "Nanyun Peng",
      "Mi-Yen Yeh",
      "Shou-De Lin"
    ],
    "abstract": "Evaluating cross-lingual knowledge transfer in large language models is challenging, as correct answers in a target language may arise either from genuine transfer or from prior exposure during pre-training. We present LiveCLKTBench, an automated generation pipeline specifically designed to isolate and measure cross-lingual knowledge transfer. Our pipeline identifies self-contained, time-sensitive knowledge entities from real-world domains, filters them based on temporal occurrence, and verifies them against the model's knowledge. The documents of these valid entities are then used to generate factual questions, which are translated into multiple languages to evaluate transferability across linguistic boundaries. Using LiveCLKTBench, we evaluate several LLMs across five languages and observe that cross-lingual transfer is strongly influenced by linguistic distance and often asymmetric across language directions. While larger models improve transfer, the gains diminish with scale and vary across domains. These findings provide new insights into multilingual transfer and demonstrate the value of LiveCLKTBench as a reliable benchmark for future research.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2511.14774v2",
    "published_date": "2025-11-03 17:06:49 UTC",
    "updated_date": "2025-11-21 20:24:19 UTC"
  },
  {
    "arxiv_id": "2511.11611v1",
    "title": "Quantifying Skill and Chance: A Unified Framework for the Geometry of Games",
    "authors": [
      "David H. Silver"
    ],
    "abstract": "We introduce a quantitative framework for separating skill and chance in games by modeling them as complementary sources of control over stochastic decision trees. We define the Skill-Luck Index S(G) in [-1, 1] by decomposing game outcomes into skill leverage K and luck leverage L. Applying this to 30 games reveals a continuum from pure chance (coin toss, S = -1) through mixed domains such as backgammon (S = 0, Sigma = 1.20) to pure skill (chess, S = +1, Sigma = 0). Poker exhibits moderate skill dominance (S = 0.33) with K = 0.40 +/- 0.03 and Sigma = 0.80. We further introduce volatility Sigma to quantify outcome uncertainty over successive turns. The framework extends to general stochastic decision systems, enabling principled comparisons of player influence, game balance, and predictive stability, with applications to game design, AI evaluation, and risk assessment.",
    "categories": [
      "cs.AI",
      "cs.LG",
      "cs.MA"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2511.11611v1",
    "published_date": "2025-11-03 17:05:52 UTC",
    "updated_date": "2025-11-03 17:05:52 UTC"
  },
  {
    "arxiv_id": "2511.01753v1",
    "title": "SM-based Semantics for Answer Set Programs Containing Conditional Literals and Arithmetic",
    "authors": [
      "Zachary Hansen",
      "Yuliya Lierler"
    ],
    "abstract": "Modern answer set programming solvers such as CLINGO support advanced language constructs that improve the expressivity and conciseness of logic programs. Conditional literals are one such construct. They form \"subformulas\" that behave as nested implications within the bodies of logic rules. Their inclusion brings the form of rules closer to the less restrictive syntax of first-order logic. These qualities make conditional literals useful tools for knowledge representation. In this paper, we propose a semantics for logic programs with conditional literals and arithmetic based on the SM operator. These semantics do not require grounding, unlike the established semantics for such programs that relies on a translation to infinitary propositional logic. The main result of this paper establishes the precise correspondence between the proposed and existing semantics.",
    "categories": [
      "cs.LO",
      "cs.AI",
      "cs.PL"
    ],
    "primary_category": "cs.LO",
    "comment": "This version corrects the review of tau for negated atoms, and clarifies the distinction between global and local variables in conditional literals (the supporting proofs are also updated accordingly)",
    "pdf_url": "https://arxiv.org/pdf/2511.01753v1",
    "published_date": "2025-11-03 17:03:29 UTC",
    "updated_date": "2025-11-03 17:03:29 UTC"
  },
  {
    "arxiv_id": "2511.01746v1",
    "title": "Scam Shield: Multi-Model Voting and Fine-Tuned LLMs Against Adversarial Attacks",
    "authors": [
      "Chen-Wei Chang",
      "Shailik Sarkar",
      "Hossein Salemi",
      "Hyungmin Kim",
      "Shutonu Mitra",
      "Hemant Purohit",
      "Fengxiu Zhang",
      "Michin Hong",
      "Jin-Hee Cho",
      "Chang-Tien Lu"
    ],
    "abstract": "Scam detection remains a critical challenge in cybersecurity as adversaries craft messages that evade automated filters. We propose a Hierarchical Scam Detection System (HSDS) that combines a lightweight multi-model voting front end with a fine-tuned LLaMA 3.1 8B Instruct back end to improve accuracy and robustness against adversarial attacks. An ensemble of four classifiers provides preliminary predictions through majority vote, and ambiguous cases are escalated to the fine-tuned model, which is optimized with adversarial training to reduce misclassification. Experiments show that this hierarchical design both improves adversarial scam detection and shortens inference time by routing most cases away from the LLM, outperforming traditional machine-learning baselines and proprietary LLM baselines. The findings highlight the effectiveness of a hybrid voting mechanism and adversarial fine-tuning in fortifying LLMs against evolving scam tactics, enhancing the resilience of automated scam detection systems.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "8 pages",
    "pdf_url": "https://arxiv.org/pdf/2511.01746v1",
    "published_date": "2025-11-03 16:58:47 UTC",
    "updated_date": "2025-11-03 16:58:47 UTC"
  },
  {
    "arxiv_id": "2511.01745v1",
    "title": "An Open-Access Benchmark of Statistical and Machine-Learning Anomaly Detection Methods for Battery Applications",
    "authors": [
      "Mei-Chin Pang",
      "Suraj Adhikari",
      "Takuma Kasahara",
      "Nagihiro Haba",
      "Saneyuki Ohno"
    ],
    "abstract": "Battery safety is critical in applications ranging from consumer electronics to electric vehicles and aircraft, where undetected anomalies could trigger safety hazards or costly downtime. In this study, we present OSBAD as an open-source benchmark for anomaly detection frameworks in battery applications. By benchmarking 15 diverse algorithms encompassing statistical, distance-based, and unsupervised machine-learning methods, OSBAD enables a systematic comparison of anomaly detection methods across heterogeneous datasets. In addition, we demonstrate how a physics- and statistics-informed feature transformation workflow enhances anomaly separability by decomposing collective anomalies into point anomalies. To address a major bottleneck in unsupervised anomaly detection due to incomplete labels, we propose a Bayesian optimization pipeline that facilitates automated hyperparameter tuning based on transfer-learning and regression proxies. Through validation on datasets covering both liquid and solid-state chemistries, we further demonstrate the cross-chemistry generalization capability of OSBAD to identify irregularities across different electrochemical systems. By making benchmarking database with open-source reproducible anomaly detection workflows available to the community, OSBAD establishes a unified foundation for developing safe, scalable, and transferable anomaly detection tools in battery analytics. This research underscores the significance of physics- and statistics-informed feature engineering as well as model selection with probabilistic hyperparameter tuning, in advancing trustworthy, data-driven diagnostics for safety-critical energy systems.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ME"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2511.01745v1",
    "published_date": "2025-11-03 16:57:18 UTC",
    "updated_date": "2025-11-03 16:57:18 UTC"
  },
  {
    "arxiv_id": "2511.01743v1",
    "title": "Towards Efficient Federated Learning of Networked Mixture-of-Experts for Mobile Edge Computing",
    "authors": [
      "Song Gao",
      "Shusen Jing",
      "Shuai Zhang",
      "Yue Wang",
      "Xiangwei Zhou",
      "Songyang Zhang"
    ],
    "abstract": "Recent advancements in large artificial intelligence models (LAMs) are driving significant innovations in mobile edge computing within next-generation wireless networks. However, the substantial demands for computational resources and large-scale training data required to train LAMs conflict with the limited storage and computational capacity of edge devices, posing significant challenges to training and deploying LAMs at the edge. In this work, we introduce the Networked Mixture-of-Experts (NMoE) system, in which clients infer collaboratively by distributing tasks to suitable neighbors based on their expertise and aggregate the returned results. For training the NMoE, we propose a federated learning framework that integrates both supervised and self-supervised learning to balance personalization and generalization, while preserving communication efficiency and data privacy. We conduct extensive experiments to demonstrate the efficacy of the proposed NMoE system, providing insights and benchmarks for the NMoE training algorithms.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.NI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2511.01743v1",
    "published_date": "2025-11-03 16:54:06 UTC",
    "updated_date": "2025-11-03 16:54:06 UTC"
  },
  {
    "arxiv_id": "2511.01956v1",
    "title": "Vibe Learning: Education in the age of AI",
    "authors": [
      "Marcos Florencio",
      "Francielle Prieto"
    ],
    "abstract": "The debate over whether \"thinking machines\" could replace human intellectual labor has existed in both public and expert discussions since the mid-twentieth century, when the concept and terminology of Artificial Intelligence (AI) first emerged. For decades, this idea remained largely theoretical. However, with the recent advent of Generative AI - particularly Large Language Models (LLMs) - and the widespread adoption of tools such as ChatGPT, the issue has become a practical reality. Many fields that rely on human intellectual effort are now being reshaped by AI tools that both expand human capabilities and challenge the necessity of certain forms of work once deemed uniquely human but now easily automated. Education, somewhat unexpectedly, faces a pivotal responsibility: to devise long-term strategies for cultivating human skills that will remain relevant in an era of pervasive AI in the intellectual domain. In this context, we identify the limitations of current AI systems - especially those rooted in LLM technology - argue that the fundamental causes of these weaknesses cannot be resolved through existing methods, and propose directions within the constructivist paradigm for transforming education to preserve the long-term advantages of human intelligence over AI tools.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2511.01956v1",
    "published_date": "2025-11-03 16:47:05 UTC",
    "updated_date": "2025-11-03 16:47:05 UTC"
  },
  {
    "arxiv_id": "2511.01734v1",
    "title": "A Proof of Learning Rate Transfer under $μ$P",
    "authors": [
      "Soufiane Hayou"
    ],
    "abstract": "We provide the first proof of learning rate transfer with width in a linear multi-layer perceptron (MLP) parametrized with $μ$P, a neural network parameterization designed to ``maximize'' feature learning in the infinite-width limit. We show that under $μP$, the optimal learning rate converges to a \\emph{non-zero constant} as width goes to infinity, providing a theoretical explanation to learning rate transfer. In contrast, we show that this property fails to hold under alternative parametrizations such as Standard Parametrization (SP) and Neural Tangent Parametrization (NTP). We provide intuitive proofs and support the theoretical findings with extensive empirical results.",
    "categories": [
      "stat.ML",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "stat.ML",
    "comment": "23 pages",
    "pdf_url": "https://arxiv.org/pdf/2511.01734v1",
    "published_date": "2025-11-03 16:45:47 UTC",
    "updated_date": "2025-11-03 16:45:47 UTC"
  },
  {
    "arxiv_id": "2511.01706v1",
    "title": "Multi-Step Knowledge Interaction Analysis via Rank-2 Subspace Disentanglement",
    "authors": [
      "Sekh Mainul Islam",
      "Pepa Atanasova",
      "Isabelle Augenstein"
    ],
    "abstract": "Natural Language Explanations (NLEs) describe how Large Language Models (LLMs) make decisions, drawing on both external Context Knowledge (CK) and Parametric Knowledge (PK) stored in model weights. Understanding their interaction is key to assessing the grounding of NLEs, yet it remains underexplored. Prior work has largely examined only single-step generation, typically the final answer, and has modelled PK and CK interaction only as a binary choice in a rank-1 subspace. This overlooks richer forms of interaction, such as complementary or supportive knowledge. We propose a novel rank-2 projection subspace that disentangles PK and CK contributions more accurately and use it for the first multi-step analysis of knowledge interactions across longer NLE sequences. Experiments on four QA datasets and three open-weight instruction-tuned LLMs show that diverse knowledge interactions are poorly represented in a rank-1 subspace but are effectively captured in our rank-2 formulation. Our multi-step analysis reveals that hallucinated NLEs align strongly with the PK direction, context-faithful ones balance PK and CK, and Chain-of-Thought prompting for NLEs shifts generated NLEs toward CK by reducing PK reliance. This work provides the first framework for systematic studies of multi-step knowledge interactions in LLMs through a richer rank-2 subspace disentanglement. Code and data: https://github.com/copenlu/pk-ck-knowledge-disentanglement.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Under review",
    "pdf_url": "https://arxiv.org/pdf/2511.01706v1",
    "published_date": "2025-11-03 16:15:06 UTC",
    "updated_date": "2025-11-03 16:15:06 UTC"
  },
  {
    "arxiv_id": "2511.01701v1",
    "title": "Solution Space Topology Guides CMTS Search",
    "authors": [
      "Mirco A. Mannucci"
    ],
    "abstract": "A fundamental question in search-guided AI: what topology should guide Monte Carlo Tree Search (MCTS) in puzzle solving? Prior work applied topological features to guide MCTS in ARC-style tasks using grid topology -- the Laplacian spectral properties of cell connectivity -- and found no benefit. We identify the root cause: grid topology is constant across all instances. We propose measuring \\emph{solution space topology} instead: the structure of valid color assignments constrained by detected pattern rules. We build this via compatibility graphs where nodes are $(cell, color)$ pairs and edges represent compatible assignments under pattern constraints.\n  Our method: (1) detect pattern rules automatically with 100\\% accuracy on 5 types, (2) construct compatibility graphs encoding solution space structure, (3) extract topological features (algebraic connectivity, rigidity, color structure) that vary with task difficulty, (4) integrate these features into MCTS node selection via sibling-normalized scores.\n  We provide formal definitions, a rigorous selection formula, and comprehensive ablations showing that algebraic connectivity is the dominant signal. The work demonstrates that topology matters for search -- but only the \\emph{right} topology. For puzzle solving, this is solution space structure, not problem space structure.",
    "categories": [
      "cs.CE",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CE",
    "comment": "15 pages, 3 figures",
    "pdf_url": "https://arxiv.org/pdf/2511.01701v1",
    "published_date": "2025-11-03 16:09:00 UTC",
    "updated_date": "2025-11-03 16:09:00 UTC"
  },
  {
    "arxiv_id": "2511.02864v3",
    "title": "Mathematical exploration and discovery at scale",
    "authors": [
      "Bogdan Georgiev",
      "Javier Gómez-Serrano",
      "Terence Tao",
      "Adam Zsolt Wagner"
    ],
    "abstract": "AlphaEvolve (Novikov et al., 2025) is a generic evolutionary coding agent that combines the generative capabilities of LLMs with automated evaluation in an iterative evolutionary framework that proposes, tests, and refines algorithmic solutions to challenging scientific and practical problems. In this paper we showcase AlphaEvolve as a tool for autonomously discovering novel mathematical constructions and advancing our understanding of long-standing open problems.\n  To demonstrate its breadth, we considered a list of 67 problems spanning mathematical analysis, combinatorics, geometry, and number theory. The system rediscovered the best known solutions in most of the cases and discovered improved solutions in several. In some instances, AlphaEvolve is also able to generalize results for a finite number of input values into a formula valid for all input values. Furthermore, we are able to combine this methodology with Deep Think and AlphaProof in a broader framework where the additional proof-assistants and reasoning systems provide automated proof generation and further mathematical insights.\n  These results demonstrate that large language model-guided evolutionary search can autonomously discover mathematical constructions that complement human intuition, at times matching or even improving the best known results, highlighting the potential for significant new ways of interaction between mathematicians and AI systems. We present AlphaEvolve as a powerful new tool for mathematical discovery, capable of exploring vast search spaces to solve complex optimization problems at scale, often with significantly reduced requirements on preparation and computation time.",
    "categories": [
      "cs.NE",
      "cs.AI",
      "math.CA",
      "math.CO",
      "math.MG"
    ],
    "primary_category": "cs.NE",
    "comment": "81 pages, 35 figures",
    "pdf_url": "https://arxiv.org/pdf/2511.02864v3",
    "published_date": "2025-11-03 16:04:07 UTC",
    "updated_date": "2025-12-22 12:49:01 UTC"
  },
  {
    "arxiv_id": "2511.01694v1",
    "title": "Bayesian Natural Gradient Fine-Tuning of CLIP Models via Kalman Filtering",
    "authors": [
      "Hossein Abdi",
      "Mingfei Sun",
      "Wei Pan"
    ],
    "abstract": "Vision-language pre-trained models, such as CLIP, have established new benchmarks in multimodal data mining. In such models, few-shot fine-tuning is a major challenge to achieve optimal performance on both in-distribution (ID) and out-of-distribution (OOD) datasets, especially when labeled data is scarce. Most existing fine-tuning approaches rely on first-order gradient-based optimizers, which typically suffer from slow convergence, sensitivity to step-size hyperparameters, and poor generalization in OOD settings. In contrast, second-order methods utilize local curvature information of the loss landscape to adjust the update step size. This is particularly beneficial for CLIP models, whose non-convex loss functions often contain sharp critical points. In such cases, natural gradient direction can offer more substantial and efficient per-iteration updates when fine-tuning with limited data. Natural Gradient Descent (NGD) is obtained by preconditioning the standard gradient with the inverse Fisher Information Matrix (FIM), which is computationally expensive for large models. To address this, we propose a Bayesian approximation of NGD using a Kalman filter for CLIP models. Our method combines the benefits of second-order optimization with Bayesian inference, which enhances generalization while providing uncertainty quantification. Extensive experiments conducted on diverse image classification datasets demonstrate that our algorithm consistently achieves superior--or comparable--ID performance and improved OOD robustness compared to state-of-the-art baselines. To the best of our knowledge, this work represents the first successful application of Kalman filtering to fine-tuning CLIP-based models, which enables more robust and efficient learning in vision-language tasks.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2511.01694v1",
    "published_date": "2025-11-03 16:00:45 UTC",
    "updated_date": "2025-11-03 16:00:45 UTC"
  },
  {
    "arxiv_id": "2511.01689v1",
    "title": "Open Character Training: Shaping the Persona of AI Assistants through Constitutional AI",
    "authors": [
      "Sharan Maiya",
      "Henning Bartsch",
      "Nathan Lambert",
      "Evan Hubinger"
    ],
    "abstract": "The character of the \"AI assistant\" persona generated by modern chatbot large language models influences both surface-level behavior and apparent values, beliefs, and ethics. These all affect interaction quality, perceived intelligence, and alignment with both developer and user intentions. The shaping of this persona, known as character training, is a critical component of industry post-training, yet remains effectively unstudied in the academic literature. We introduce the first open implementation of character training, leveraging Constitutional AI and a new data pipeline using synthetic introspective data to shape the assistant persona in a more effective and controlled manner than alternatives such as constraining system prompts or activation steering. Specifically, we fine-tune three popular open-weights models using 11 example personas, such as humorous, deeply caring, or even malevolent. To track the effects of our approach, we introduce a method which analyzes revealed preferences, uncovering clear and holistic changes in character. We find these changes are more robust to adversarial prompting than the above two alternatives, while also leading to more coherent and realistic generations. Finally, we demonstrate this fine-tuning has little to no effect on general capabilities as measured by common benchmarks. We describe and open-source our full post-training method, the implementation of which can be found at https://github.com/maiush/OpenCharacterTraining.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "12 pages, 6 figures, 4 tables",
    "pdf_url": "https://arxiv.org/pdf/2511.01689v1",
    "published_date": "2025-11-03 15:53:47 UTC",
    "updated_date": "2025-11-03 15:53:47 UTC"
  },
  {
    "arxiv_id": "2511.01683v1",
    "title": "Student Engagement in AI Assisted Complex Problem Solving: A Pilot Study of Human AI Rubik's Cube Collaboration",
    "authors": [
      "Kirk Vanacore",
      "Jaclyn Ocumpaugh",
      "Forest Agostinelli",
      "Dezhi Wu",
      "Sai Vuruma",
      "Matt Irvin"
    ],
    "abstract": "Games and puzzles play important pedagogical roles in STEM learning. New AI algorithms that can solve complex problems offer opportunities for scaffolded instruction in puzzle solving. This paper presents the ALLURE system, which uses an AI algorithm (DeepCubeA) to guide students in solving a common first step of the Rubik's Cube (i.e., the white cross). Using data from a pilot study we present preliminary findings about students' behaviors in the system, how these behaviors are associated with STEM skills - including spatial reasoning, critical thinking and algorithmic thinking. We discuss how data from ALLURE can be used in future educational data mining to understand how students benefit from AI assistance and collaboration when solving complex problems.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2511.01683v1",
    "published_date": "2025-11-03 15:46:54 UTC",
    "updated_date": "2025-11-03 15:46:54 UTC"
  },
  {
    "arxiv_id": "2511.01671v1",
    "title": "Spin-Adapted Neural Network Wavefunctions in Real Space",
    "authors": [
      "Ruichen Li",
      "Yuzhi Liu",
      "Du Jiang",
      "Yixiao Chen",
      "Xuelan Wen",
      "Wenrui Li",
      "Di He",
      "Liwei Wang",
      "Ji Chen",
      "Weiluo Ren"
    ],
    "abstract": "Spin plays a fundamental role in understanding electronic structure, yet many real-space wavefunction methods fail to adequately consider it. We introduce the Spin-Adapted Antisymmetrization Method (SAAM), a general procedure that enforces exact total spin symmetry for antisymmetric many-electron wavefunctions in real space. In the context of neural network-based quantum Monte Carlo (NNQMC), SAAM leverages the expressiveness of deep neural networks to capture electron correlation while enforcing exact spin adaptation via group representation theory. This framework provides a principled route to embed physical priors into otherwise black-box neural network wavefunctions, yielding a compact representation of correlated system with neural network orbitals. Compared with existing treatments of spin in NNQMC, SAAM is more accurate and efficient, achieving exact spin purity without any additional tunable hyperparameters. To demonstrate its effectiveness, we apply SAAM to study the spin ladder of iron-sulfur clusters, a long-standing challenge for many-body methods due to their dense spectrum of nearly degenerate spin states. Our results reveal accurate resolution of low-lying spin states and spin gaps in [Fe$_2$S$_2$] and [Fe$_4$S$_4$] clusters, offering new insights into their electronic structures. In sum, these findings establish SAAM as a robust, hyperparameter-free standard for spin-adapted NNQMC, particularly for strongly correlated systems.",
    "categories": [
      "physics.chem-ph",
      "cs.AI"
    ],
    "primary_category": "physics.chem-ph",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2511.01671v1",
    "published_date": "2025-11-03 15:34:19 UTC",
    "updated_date": "2025-11-03 15:34:19 UTC"
  },
  {
    "arxiv_id": "2511.01670v1",
    "title": "SeaLLMs-Audio: Large Audio-Language Models for Southeast Asia",
    "authors": [
      "Chaoqun Liu",
      "Mahani Aljunied",
      "Guizhen Chen",
      "Hou Pong Chan",
      "Weiwen Xu",
      "Yu Rong",
      "Wenxuan Zhang"
    ],
    "abstract": "We introduce SeaLLMs-Audio, the first large audio-language model (LALM) tailored for multiple Southeast Asian (SEA) languages-Indonesian (id), Thai (th), and Vietnamese (vi)-alongside English (en) and Chinese (zh). Trained on a large-scale audio corpus, SeaLLMs-Audio exhibits strong performance across diverse audio-centric tasks, spanning fine-grained audio understanding and voice-based interaction. Its key features include: 1) Multilingual: the model primarily supports 5 languages, namely Indonesian, Thai, Vietnamese, English, and Chinese; 2) Multimodal: the model accepts flexible input modalities, including audio only, text only, as well as audio with text; 3) Multi-task: the model supports a wide range of tasks, including audio analysis tasks such as Audio Captioning, Automatic Speech Recognition, Speech-to-Text Translation, Speech Emotion Recognition, Speech Question Answering, and Speech Summarization. It also enables voice-based dialogue, including answering factual, mathematical, and general knowledge queries. As a significant step towards advancing audio LLMs in Southeast Asia, we expect SeaLLMs-Audio to benefit both the regional research community and industry. To automate LALM evaluation for Southeast Asia, we introduce SeaBench-Audio, a benchmark spanning multiple tasks. Experiments show that SeaLLMs-Audio achieves competitive performance compared with other LALMs on SEA languages.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "10 pages",
    "pdf_url": "https://arxiv.org/pdf/2511.01670v1",
    "published_date": "2025-11-03 15:32:58 UTC",
    "updated_date": "2025-11-03 15:32:58 UTC"
  },
  {
    "arxiv_id": "2511.01668v2",
    "title": "Hybrid Retrieval-Augmented Generation Agent for Trustworthy Legal Question Answering in Judicial Forensics",
    "authors": [
      "Yueqing Xi",
      "Yifan Bai",
      "Huasen Luo",
      "Weiliang Wen",
      "Hui Liu",
      "Haoliang Li"
    ],
    "abstract": "As artificial intelligence permeates judicial forensics, ensuring the veracity and traceability of legal question answering (QA) has become critical. Conventional large language models (LLMs) are prone to hallucination, risking misleading guidance in legal consultation, while static knowledge bases struggle to keep pace with frequently updated statutes and case law. We present a hybrid legal QA agent tailored for judicial settings that integrates retrieval-augmented generation (RAG) with multi-model ensembling to deliver reliable, auditable, and continuously updatable counsel. The system prioritizes retrieval over generation: when a trusted legal repository yields relevant evidence, answers are produced via RAG; otherwise, multiple LLMs generate candidates that are scored by a specialized selector, with the top-ranked answer returned. High-quality outputs then undergo human review before being written back to the repository, enabling dynamic knowledge evolution and provenance tracking. Experiments on the Law\\_QA dataset show that our hybrid approach significantly outperforms both a single-model baseline and a vanilla RAG pipeline on F1, ROUGE-L, and an LLM-as-a-Judge metric. Ablations confirm the complementary contributions of retrieval prioritization, model ensembling, and the human-in-the-loop update mechanism. The proposed system demonstrably reduces hallucination while improving answer quality and legal compliance, advancing the practical landing of media forensics technologies in judicial scenarios.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2511.01668v2",
    "published_date": "2025-11-03 15:30:58 UTC",
    "updated_date": "2025-11-17 16:17:55 UTC"
  },
  {
    "arxiv_id": "2511.01663v1",
    "title": "The Ghost in the Keys: A Disklavier Demo for Human-AI Musical Co-Creativity",
    "authors": [
      "Louis Bradshaw",
      "Alexander Spangher",
      "Stella Biderman",
      "Simon Colton"
    ],
    "abstract": "While generative models for music composition are increasingly capable, their adoption by musicians is hindered by text-prompting, an asynchronous workflow disconnected from the embodied, responsive nature of instrumental performance. To address this, we introduce Aria-Duet, an interactive system facilitating a real-time musical duet between a human pianist and Aria, a state-of-the-art generative model, using a Yamaha Disklavier as a shared physical interface. The framework enables a turn-taking collaboration: the user performs, signals a handover, and the model generates a coherent continuation performed acoustically on the piano. Beyond describing the technical architecture enabling this low-latency interaction, we analyze the system's output from a musicological perspective, finding the model can maintain stylistic semantics and develop coherent phrasal ideas, demonstrating that such embodied systems can engage in musically sophisticated dialogue and open a promising new path for human-AI co-creation.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.SD",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2511.01663v1",
    "published_date": "2025-11-03 15:26:01 UTC",
    "updated_date": "2025-11-03 15:26:01 UTC"
  },
  {
    "arxiv_id": "2511.01650v2",
    "title": "EngTrace: A Symbolic Benchmark for Verifiable Process Supervision of Engineering Reasoning",
    "authors": [
      "Ayesha Gull",
      "Muhammad Usman Safder",
      "Rania Elbadry",
      "Fan Zhang",
      "Veselin Stoyanov",
      "Preslav Nakov",
      "Zhuohan Xie"
    ],
    "abstract": "Large Language Models (LLMs) are increasingly entering specialized, safety-critical engineering workflows governed by strict quantitative standards and immutable physical laws, making rigorous evaluation of their reasoning capabilities imperative. However, existing benchmarks such as MMLU, MATH, and HumanEval assess isolated cognitive skills, failing to capture the physically grounded reasoning central to engineering, where scientific principles, quantitative modeling, and practical constraints must converge. To enable verifiable process supervision in engineering, we introduce EngTrace, a symbolic benchmark comprising 90 templates across three major engineering branches, nine core domains and 20 distinct areas. Through domain-aware parameterization, we generate 1,350 unique, contamination-resistant test cases to stress-test generalization. Moving beyond outcome matching, we introduce a verifiable two-stage evaluation framework that uses a tiered protocol to validate intermediate reasoning traces alongside final answers through automated procedural checks and a heterogeneous AI Tribunal. Our evaluation of 24 leading LLMs reveals a distinct trade-off between numeric precision and trace fidelity, identifying a complexity cliff where abstract mathematical pre-training fails to translate into the integrative reasoning required for advanced engineering tasks.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "22 pages, includes figures and tables; introduces the EngTrace benchmark",
    "pdf_url": "https://arxiv.org/pdf/2511.01650v2",
    "published_date": "2025-11-03 15:05:44 UTC",
    "updated_date": "2026-01-07 15:44:03 UTC"
  },
  {
    "arxiv_id": "2511.01643v1",
    "title": "A Graph-based RAG for Energy Efficiency Question Answering",
    "authors": [
      "Riccardo Campi",
      "Nicolò Oreste Pinciroli Vago",
      "Mathyas Giudici",
      "Pablo Barrachina Rodriguez-Guisado",
      "Marco Brambilla",
      "Piero Fraternali"
    ],
    "abstract": "In this work, we investigate the use of Large Language Models (LLMs) within a graph-based Retrieval Augmented Generation (RAG) architecture for Energy Efficiency (EE) Question Answering. First, the system automatically extracts a Knowledge Graph (KG) from guidance and regulatory documents in the energy field. Then, the generated graph is navigated and reasoned upon to provide users with accurate answers in multiple languages. We implement a human-based validation using the RAGAs framework properties, a validation dataset comprising 101 question-answer pairs, and domain experts. Results confirm the potential of this architecture and identify its strengths and weaknesses. Validation results show how the system correctly answers in about three out of four of the cases (75.2 +- 2.7%), with higher results on questions related to more general EE answers (up to 81.0 +- 4.1%), and featuring promising multilingual abilities (4.4% accuracy loss due to translation).",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2511.01643v1",
    "published_date": "2025-11-03 14:55:34 UTC",
    "updated_date": "2025-11-03 14:55:34 UTC"
  },
  {
    "arxiv_id": "2511.01639v1",
    "title": "IVGAE-TAMA-BO: A novel temporal dynamic variational graph model for link prediction in global food trade networks with momentum structural memory and Bayesian optimization",
    "authors": [
      "Sicheng Wang",
      "Shuhao Chen",
      "Jingran Zhou",
      "Chengyi Tu"
    ],
    "abstract": "Global food trade plays a crucial role in ensuring food security and maintaining supply chain stability. However, its network structure evolves dynamically under the influence of geopolitical, economic, and environmental factors, making it challenging to model and predict future trade links. Effectively capturing temporal patterns in food trade networks is therefore essential for improving the accuracy and robustness of link prediction. This study introduces IVGAE-TAMA-BO, a novel dynamic graph neural network designed to model evolving trade structures and predict future links in global food trade networks. To the best of our knowledge, this is the first work to apply dynamic graph neural networks to this domain, significantly enhancing predictive performance. Building upon the original IVGAE framework, the proposed model incorporates a Trade-Aware Momentum Aggregator (TAMA) to capture the temporal evolution of trade networks, jointly modeling short-term fluctuations and long-term structural dependencies. A momentum-based structural memory mechanism further improves predictive stability and performance. In addition, Bayesian optimization is used to automatically tune key hyperparameters, enhancing generalization across diverse trade scenarios. Extensive experiments on five crop-specific datasets demonstrate that IVGAE-TAMA substantially outperforms the static IVGAE and other dynamic baselines by effectively modeling temporal dependencies, while Bayesian optimization further boosts performance in IVGAE-TAMA-BO. These results highlight the proposed framework as a robust and scalable solution for structural prediction in global trade networks, with strong potential for applications in food security monitoring and policy decision support.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "26pages,6figures",
    "pdf_url": "https://arxiv.org/pdf/2511.01639v1",
    "published_date": "2025-11-03 14:48:32 UTC",
    "updated_date": "2025-11-03 14:48:32 UTC"
  },
  {
    "arxiv_id": "2511.01634v2",
    "title": "Prompt Injection as an Emerging Threat: Evaluating the Resilience of Large Language Models",
    "authors": [
      "Daniyal Ganiuly",
      "Assel Smaiyl"
    ],
    "abstract": "Large Language Models (LLMs) are increasingly used in intelligent systems that perform reasoning, summarization, and code generation. Their ability to follow natural-language instructions, while powerful, also makes them vulnerable to a new class of attacks known as prompt injection. In these attacks, hidden or malicious instructions are inserted into user inputs or external content, causing the model to ignore its intended task or produce unsafe responses. This study proposes a unified framework for evaluating how resistant Large Language Models (LLMs) are to prompt injection attacks. The framework defines three complementary metrics such as the Resilience Degradation Index (RDI), Safety Compliance Coefficient (SCC), and Instructional Integrity Metric (IIM) to jointly measure robustness, safety, and semantic stability. We evaluated four instruction-tuned models (GPT-4, GPT-4o, LLaMA-3 8B Instruct, and Flan-T5-Large) on five common language tasks: question answering, summarization, translation, reasoning, and code generation. Results show that GPT-4 performs best overall, while open-weight models remain more vulnerable. The findings highlight that strong alignment and safety tuning are more important for resilience than model size alone. Results show that all models remain partially vulnerable, especially to indirect and direct-override attacks. GPT-4 achieved the best overall resilience (RDR = 9.8 %, SCR = 96.4 %), while open-source models exhibited higher performance degradation and lower safety scores. The findings demonstrate that alignment strength and safety tuning play a greater role in resilience than model size alone. The proposed framework offers a structured, reproducible approach for assessing model robustness and provides practical insights for improving LLM safety and reliability.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "10 pages, 6 figures",
    "pdf_url": "https://arxiv.org/pdf/2511.01634v2",
    "published_date": "2025-11-03 14:43:56 UTC",
    "updated_date": "2025-11-11 21:55:25 UTC"
  },
  {
    "arxiv_id": "2511.01633v1",
    "title": "Scaling Graph Chain-of-Thought Reasoning: A Multi-Agent Framework with Efficient LLM Serving",
    "authors": [
      "Chengying Huan",
      "Ziheng Meng",
      "Yongchao Liu",
      "Zhengyi Yang",
      "Yun Zhu",
      "Yue Yun",
      "Shipeng Li",
      "Rong Gu",
      "Xiabao Wu",
      "Haitao Zhang",
      "Chuntao Hong",
      "Shaonan Ma",
      "Guihai Chen",
      "Chen Tian"
    ],
    "abstract": "Graph Chain-of-Thought (Graph-CoT) enables large language models (LLMs) to perform step-by-step reasoning over graph-structured knowledge, but existing pipelines suffer from low accuracy, excessive token usage, high latency, and low throughput due to single-agent monolithic prompts, repeated context re-encoding, and inefficient serving execution. We present GLM, the first multi-agent Graph-CoT system co-designed with an optimized LLM serving architecture. GLM decomposes reasoning into specialized agents for classification, reasoning, action generation, and graph retrieval, enabling branching and selective context sharing to reduce prompt length and reasoning iterations while preserving reasoning quality, thereby improving accuracy and reducing overall token consumption. To scale inference, we introduce a Graph-CoT-aware LLM inference mechanism with graph-specific KV-cache management, priority-based eviction, and pipelined execution to improve serving efficiency. Experiments demonstrate that GLM improves answer accuracy by up to 38%, reduces token cost by up to 95.7%, lowers inference latency by 90.3%, and achieves up to 15.1x higher throughput compared to state-of-the-art Graph-CoT baselines, enabling efficient adoption for complex real-world reasoning at scale.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2511.01633v1",
    "published_date": "2025-11-03 14:42:53 UTC",
    "updated_date": "2025-11-03 14:42:53 UTC"
  },
  {
    "arxiv_id": "2511.01615v1",
    "title": "Imperfect Language, Artificial Intelligence, and the Human Mind: An Interdisciplinary Approach to Linguistic Errors in Native Spanish Speakers",
    "authors": [
      "Francisco Portillo López"
    ],
    "abstract": "Linguistic errors are not merely deviations from normative grammar; they offer a unique window into the cognitive architecture of language and expose the current limitations of artificial systems that seek to replicate them. This project proposes an interdisciplinary study of linguistic errors produced by native Spanish speakers, with the aim of analyzing how current large language models (LLM) interpret, reproduce, or correct them. The research integrates three core perspectives: theoretical linguistics, to classify and understand the nature of the errors; neurolinguistics, to contextualize them within real-time language processing in the brain; and natural language processing (NLP), to evaluate their interpretation against linguistic errors. A purpose-built corpus of authentic errors of native Spanish (+500) will serve as the foundation for empirical analysis. These errors will be tested against AI models such as GPT or Gemini to assess their interpretative accuracy and their ability to generalize patterns of human linguistic behavior. The project contributes not only to the understanding of Spanish as a native language but also to the development of NLP systems that are more cognitively informed and capable of engaging with the imperfect, variable, and often ambiguous nature of real human language.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "12 pages, 3 figures",
    "pdf_url": "https://arxiv.org/pdf/2511.01615v1",
    "published_date": "2025-11-03 14:22:43 UTC",
    "updated_date": "2025-11-03 14:22:43 UTC"
  },
  {
    "arxiv_id": "2511.01610v1",
    "title": "DINO-MX: A Modular & Flexible Framework for Self-Supervised Learning",
    "authors": [
      "Mahmut Selman Gokmen",
      "Cody Bumgardner"
    ],
    "abstract": "Vision Foundation Models (VFMs) have advanced representation learning through self-supervised methods. However, existing training pipelines are often inflexible, domain-specific, or computationally expensive, which limits their usability across different domains and resource settings. DINO-MX is a modular and extensible training framework that combines the core principles of DINO, DINOv2 and DINOv3 within a unified configuration-driven system. It supports a variety of transformer-based architectures and is fully compatible with the Hugging Face ecosystem. The framework includes multiple training strategies such as low-rank adaptation (LoRA), layer freezing, and knowledge distillation, along with support for distributed training through both Distributed Data Parallel (DDP) and Fully Sharded Data Parallel (FSDP). DINO-MX is designed to work with both natural and specialized data types, including single- and multi-channel images. Experimental results on diverse datasets show that DINO-MX achieves competitive performance while significantly reducing computational costs. Additionally, it offers interpretability tools and a label-guided data augmentation method that improves attention-based localization without the need for extra detection or segmentation heads. DINO-MX provides a reproducible and scalable foundation for developing, adapting, and benchmarking self-supervised vision models across a range of research and real-world applications.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2511.01610v1",
    "published_date": "2025-11-03 14:10:43 UTC",
    "updated_date": "2025-11-03 14:10:43 UTC"
  },
  {
    "arxiv_id": "2511.01583v1",
    "title": "Federated Cyber Defense: Privacy-Preserving Ransomware Detection Across Distributed Systems",
    "authors": [
      "Daniel M. Jimenez-Gutierrez",
      "Enrique Zuazua",
      "Joaquin Del Rio",
      "Oleksii Sliusarenko",
      "Xabi Uribe-Etxebarria"
    ],
    "abstract": "Detecting malware, especially ransomware, is essential to securing today's interconnected ecosystems, including cloud storage, enterprise file-sharing, and database services. Training high-performing artificial intelligence (AI) detectors requires diverse datasets, which are often distributed across multiple organizations, making centralization necessary. However, centralized learning is often impractical due to security, privacy regulations, data ownership issues, and legal barriers to cross-organizational sharing. Compounding this challenge, ransomware evolves rapidly, demanding models that are both robust and adaptable.\n  In this paper, we evaluate Federated Learning (FL) using the Sherpa.ai FL platform, which enables multiple organizations to collaboratively train a ransomware detection model while keeping raw data local and secure. This paradigm is particularly relevant for cybersecurity companies (including both software and hardware vendors) that deploy ransomware detection or firewall systems across millions of endpoints. In such environments, data cannot be transferred outside the customer's device due to strict security, privacy, or regulatory constraints. Although FL applies broadly to malware threats, we validate the approach using the Ransomware Storage Access Patterns (RanSAP) dataset.\n  Our experiments demonstrate that FL improves ransomware detection accuracy by a relative 9% over server-local models and achieves performance comparable to centralized training. These results indicate that FL offers a scalable, high-performing, and privacy-preserving framework for proactive ransomware detection across organizational and regulatory boundaries.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.DC",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2511.01583v1",
    "published_date": "2025-11-03 13:54:13 UTC",
    "updated_date": "2025-11-03 13:54:13 UTC"
  },
  {
    "arxiv_id": "2511.01581v1",
    "title": "ExplicitLM: Decoupling Knowledge from Parameters via Explicit Memory Banks",
    "authors": [
      "Chengzhang Yu",
      "Zening Lu",
      "Chenyang Zheng",
      "Chiyue Wang",
      "Yiming Zhang",
      "Zhanpeng Jin"
    ],
    "abstract": "Large language models suffer from knowledge staleness and lack of interpretability due to implicit knowledge storage across entangled network parameters, preventing targeted updates and reasoning transparency. We propose ExplicitLM, a novel architecture featuring a million-scale external memory bank storing human-readable knowledge as token sequences, enabling direct inspection and modification. We design a differentiable two-stage retrieval mechanism with efficient coarse-grained filtering via product key decomposition (reducing complexity from $\\mathcal{O}(N \\cdot |I|)$ to $\\mathcal{O}(\\sqrt{N} \\cdot |I|)$) and fine-grained Gumbel-Softmax matching for end-to-end training. Inspired by dual-system cognitive theory, we partition knowledge into frozen explicit facts (20%) and learnable implicit patterns (80%), maintained through Exponential Moving Average updates for stability. ExplicitLM achieves up to 43.67% improvement on knowledge-intensive tasks versus standard Transformers, with 3.62$\\times$ gains in low-data regimes (10k samples). Analysis shows strong correlations between memory retrieval and performance, with correct predictions achieving 49% higher hit rates. Unlike RAG systems with frozen retrieval, our jointly optimized architecture demonstrates that interpretable, updatable models can maintain competitive performance while providing unprecedented knowledge transparency.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "12pages, 4figures",
    "pdf_url": "https://arxiv.org/pdf/2511.01581v1",
    "published_date": "2025-11-03 13:53:19 UTC",
    "updated_date": "2025-11-03 13:53:19 UTC"
  },
  {
    "arxiv_id": "2511.01572v1",
    "title": "HIT-ROCKET: Hadamard-vector Inner-product Transformer for ROCKET",
    "authors": [
      "Wang Hao",
      "Kuang Zhang",
      "Hou Chengyu",
      "Yuan Zhonghao",
      "Tan Chenxing",
      "Fu Weifeng",
      "Zhu Yangying"
    ],
    "abstract": "Time series classification holds broad application value in communications, information countermeasures, finance, and medicine. However, state-of-the-art (SOTA) methods-including HIVE-COTE, Proximity Forest, and TS-CHIEF-exhibit high computational complexity, coupled with lengthy parameter tuning and training cycles. In contrast, lightweight solutions like ROCKET (Random Convolutional Kernel Transform) offer greater efficiency but leave substantial room for improvement in kernel selection and computational overhead. To address these challenges, we propose a feature extraction approach based on Hadamard convolutional transform, utilizing column or row vectors of Hadamard matrices as convolution kernels with extended lengths of varying sizes. This enhancement maintains full compatibility with existing methods (e.g., ROCKET) while leveraging kernel orthogonality to boost computational efficiency, robustness, and adaptability. Comprehensive experiments on multi-domain datasets-focusing on the UCR time series dataset-demonstrate SOTA performance: F1-score improved by at least 5% vs. ROCKET, with 50% shorter training time than miniROCKET (fastest ROCKET variant) under identical hyperparameters, enabling deployment on ultra-low-power embedded devices. All code is available on GitHub.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2511.01572v1",
    "published_date": "2025-11-03 13:39:40 UTC",
    "updated_date": "2025-11-03 13:39:40 UTC"
  },
  {
    "arxiv_id": "2511.01952v1",
    "title": "Black-Box Membership Inference Attack for LVLMs via Prior Knowledge-Calibrated Memory Probing",
    "authors": [
      "Jinhua Yin",
      "Peiru Yang",
      "Chen Yang",
      "Huili Wang",
      "Zhiyang Hu",
      "Shangguang Wang",
      "Yongfeng Huang",
      "Tao Qi"
    ],
    "abstract": "Large vision-language models (LVLMs) derive their capabilities from extensive training on vast corpora of visual and textual data. Empowered by large-scale parameters, these models often exhibit strong memorization of their training data, rendering them susceptible to membership inference attacks (MIAs). Existing MIA methods for LVLMs typically operate under white- or gray-box assumptions, by extracting likelihood-based features for the suspected data samples based on the target LVLMs. However, mainstream LVLMs generally only expose generated outputs while concealing internal computational features during inference, limiting the applicability of these methods. In this work, we propose the first black-box MIA framework for LVLMs, based on a prior knowledge-calibrated memory probing mechanism. The core idea is to assess the model memorization of the private semantic information embedded within the suspected image data, which is unlikely to be inferred from general world knowledge alone. We conducted extensive experiments across four LVLMs and three datasets. Empirical results demonstrate that our method effectively identifies training data of LVLMs in a purely black-box setting and even achieves performance comparable to gray-box and white-box methods. Further analysis reveals the robustness of our method against potential adversarial manipulations, and the effectiveness of the methodology designs. Our code and data are available at https://github.com/spmede/KCMP.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2511.01952v1",
    "published_date": "2025-11-03 13:16:30 UTC",
    "updated_date": "2025-11-03 13:16:30 UTC"
  },
  {
    "arxiv_id": "2511.01553v1",
    "title": "Real-time Continual Learning on Intel Loihi 2",
    "authors": [
      "Elvin Hajizada",
      "Danielle Rager",
      "Timothy Shea",
      "Leobardo Campos-Macias",
      "Andreas Wild",
      "Eyke Hüllermeier",
      "Yulia Sandamirskaya",
      "Mike Davies"
    ],
    "abstract": "AI systems on edge devices face a critical challenge in open-world environments: adapting when data distributions shift and novel classes emerge. While offline training dominates current paradigms, online continual learning (OCL)--where models learn incrementally from non-stationary streams without catastrophic forgetting--remains challenging in power-constrained settings. We present a neuromorphic solution called CLP-SNN: a spiking neural network architecture for Continually Learning Prototypes and its implementation on Intel's Loihi 2 chip. Our approach introduces three innovations: (1) event-driven and spatiotemporally sparse local learning, (2) a self-normalizing three-factor learning rule maintaining weight normalization, and (3) integrated neurogenesis and metaplasticity for capacity expansion and forgetting mitigation. On OpenLORIS few-shot learning experiments, CLP-SNN achieves accuracy competitive with replay methods while being rehearsal-free. CLP-SNN delivers transformative efficiency gains: 70\\times faster (0.33ms vs 23.2ms), and 5,600\\times more energy efficient (0.05mJ vs 281mJ) than the best alternative OCL on edge GPU. This demonstrates that co-designed brain-inspired algorithms and neuromorphic hardware can break traditional accuracy-efficiency trade-offs for future edge AI systems.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.DC",
      "cs.NE"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2511.01553v1",
    "published_date": "2025-11-03 13:16:16 UTC",
    "updated_date": "2025-11-03 13:16:16 UTC"
  },
  {
    "arxiv_id": "2511.01550v1",
    "title": "Analyzing Sustainability Messaging in Large-Scale Corporate Social Media",
    "authors": [
      "Ujjwal Sharma",
      "Stevan Rudinac",
      "Ana Mićković",
      "Willemijn van Dolen",
      "Marcel Worring"
    ],
    "abstract": "In this work, we introduce a multimodal analysis pipeline that leverages large foundation models in vision and language to analyze corporate social media content, with a focus on sustainability-related communication. Addressing the challenges of evolving, multimodal, and often ambiguous corporate messaging on platforms such as X (formerly Twitter), we employ an ensemble of large language models (LLMs) to annotate a large corpus of corporate tweets on their topical alignment with the 17 Sustainable Development Goals (SDGs). This approach avoids the need for costly, task-specific annotations and explores the potential of such models as ad-hoc annotators for social media data that can efficiently capture both explicit and implicit references to sustainability themes in a scalable manner. Complementing this textual analysis, we utilize vision-language models (VLMs), within a visual understanding framework that uses semantic clusters to uncover patterns in visual sustainability communication. This integrated approach reveals sectoral differences in SDG engagement, temporal trends, and associations between corporate messaging, environmental, social, governance (ESG) risks, and consumer engagement. Our methods-automatic label generation and semantic visual clustering-are broadly applicable to other domains and offer a flexible framework for large-scale social media analysis.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2511.01550v1",
    "published_date": "2025-11-03 13:14:17 UTC",
    "updated_date": "2025-11-03 13:14:17 UTC"
  },
  {
    "arxiv_id": "2511.01541v1",
    "title": "Driving scenario generation and evaluation using a structured layer representation and foundational models",
    "authors": [
      "Arthur Hubert",
      "Gamal Elghazaly",
      "Raphaël Frank"
    ],
    "abstract": "Rare and challenging driving scenarios are critical for autonomous vehicle development. Since they are difficult to encounter, simulating or generating them using generative models is a popular approach. Following previous efforts to structure driving scenario representations in a layer model, we propose a structured five-layer model to improve the evaluation and generation of rare scenarios. We use this model alongside large foundational models to generate new driving scenarios using a data augmentation strategy. Unlike previous representations, our structure introduces subclasses and characteristics for every agent of the scenario, allowing us to compare them using an embedding specific to our layer-model. We study and adapt two metrics to evaluate the relevance of a synthetic dataset in the context of a structured representation: the diversity score estimates how different the scenarios of a dataset are from one another, while the originality score calculates how similar a synthetic dataset is from a real reference set. This paper showcases both metrics in different generation setup, as well as a qualitative evaluation of synthetic videos generated from structured scenario descriptions. The code and extended results can be found at https://github.com/Valgiz/5LMSG.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2511.01541v1",
    "published_date": "2025-11-03 13:04:55 UTC",
    "updated_date": "2025-11-03 13:04:55 UTC"
  },
  {
    "arxiv_id": "2511.01527v1",
    "title": "TPS-Bench: Evaluating AI Agents' Tool Planning \\& Scheduling Abilities in Compounding Tasks",
    "authors": [
      "Hanwen Xu",
      "Xuyao Huang",
      "Yuzhe Liu",
      "Kai Yu",
      "Zhijie Deng"
    ],
    "abstract": "Large language model (LLM) agents have exhibited strong problem-solving competence across domains like research and coding. Yet, it remains underexplored whether LLM agents can tackle compounding real-world problems that require a diverse set of tools to complete. Given a broad, heterogeneous tool repository, LLM agents must not only select appropriate tools based on task planning analysis but also strategically schedule the execution order to ensure efficiency. This paper introduces TPS-Bench to benchmark the ability of LLM agents in solving such problems that demand Tool Planning and Scheduling. TPS-Bench collects 200 compounding tasks of two difficulty levels, based on a tool repository containing hundreds of model context protocol (MCP) tools. In particular, each task is composed of multiple subtasks, such as web search, map navigation, calendar checking, etc., and each subtask can be completed by a basic tool. Our evaluation emphasizes both task completion rate and efficiency. The empirical studies on popular closed-source and open-source LLMs indicate that most models can perform reasonable tool planning, but differ in scheduling. For example, GLM-4.5 achieves an outperforming task completion rate of 64.72% with extensive sequential tool calls, hence suffering from significantly long execution time. By contrast, GPT-4o prioritizes parallel tool calls but achieves only a 45.08% completion rate. Considering reinforcement learning (RL) can be a viable way to improve the scheduling efficiency without compromising performance, we perform an initial study on Qwen3-1.7B and witness a 14% reduction in execution time alongside a 6% gain in task completion rate based on rarely 100 RL training samples. Our code is available https://github.com/hanwenxu1/mcp-agent.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2511.01527v1",
    "published_date": "2025-11-03 12:45:39 UTC",
    "updated_date": "2025-11-03 12:45:39 UTC"
  },
  {
    "arxiv_id": "2511.10658v1",
    "title": "Evaluating Open-Weight Large Language Models for Structured Data Extraction from Narrative Medical Reports Across Multiple Use Cases and Languages",
    "authors": [
      "Douwe J. Spaanderman",
      "Karthik Prathaban",
      "Petr Zelina",
      "Kaouther Mouheb",
      "Lukáš Hejtmánek",
      "Matthew Marzetti",
      "Antonius W. Schurink",
      "Damian Chan",
      "Ruben Niemantsverdriet",
      "Frederik Hartmann",
      "Zhen Qian",
      "Maarten G. J. Thomeer",
      "Petr Holub",
      "Farhan Akram",
      "Frank J. Wolters",
      "Meike W. Vernooij",
      "Cornelis Verhoef",
      "Esther E. Bron",
      "Vít Nováček",
      "Dirk J. Grünhagen",
      "Wiro J. Niessen",
      "Martijn P. A. Starmans",
      "Stefan Klein"
    ],
    "abstract": "Large language models (LLMs) are increasingly used to extract structured information from free-text clinical records, but prior work often focuses on single tasks, limited models, and English-language reports. We evaluated 15 open-weight LLMs on pathology and radiology reports across six use cases, colorectal liver metastases, liver tumours, neurodegenerative diseases, soft-tissue tumours, melanomas, and sarcomas, at three institutes in the Netherlands, UK, and Czech Republic. Models included general-purpose and medical-specialised LLMs of various sizes, and six prompting strategies were compared: zero-shot, one-shot, few-shot, chain-of-thought, self-consistency, and prompt graph. Performance was assessed using task-appropriate metrics, with consensus rank aggregation and linear mixed-effects models quantifying variance. Top-ranked models achieved macro-average scores close to inter-rater agreement across tasks. Small-to-medium general-purpose models performed comparably to large models, while tiny and specialised models performed worse. Prompt graph and few-shot prompting improved performance by ~13%. Task-specific factors, including variable complexity and annotation variability, influenced results more than model size or prompting strategy. These findings show that open-weight LLMs can extract structured data from clinical reports across diseases, languages, and institutions, offering a scalable approach for clinical data curation.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2511.10658v1",
    "published_date": "2025-11-03 12:32:01 UTC",
    "updated_date": "2025-11-03 12:32:01 UTC"
  },
  {
    "arxiv_id": "2511.01512v1",
    "title": "BanglaNirTox: A Large-scale Parallel Corpus for Explainable AI in Bengali Text Detoxification",
    "authors": [
      "Ayesha Afroza Mohsin",
      "Mashrur Ahsan",
      "Nafisa Maliyat",
      "Shanta Maria",
      "Syed Rifat Raiyan",
      "Hasan Mahmud",
      "Md Kamrul Hasan"
    ],
    "abstract": "Toxic language in Bengali remains prevalent, especially in online environments, with few effective precautions against it. Although text detoxification has seen progress in high-resource languages, Bengali remains underexplored due to limited resources. In this paper, we propose a novel pipeline for Bengali text detoxification that combines Pareto class-optimized large language models (LLMs) and Chain-of-Thought (CoT) prompting to generate detoxified sentences. To support this effort, we construct BanglaNirTox, an artificially generated parallel corpus of 68,041 toxic Bengali sentences with class-wise toxicity labels, reasonings, and detoxified paraphrases, using Pareto-optimized LLMs evaluated on random samples. The resulting BanglaNirTox dataset is used to fine-tune language models to produce better detoxified versions of Bengali sentences. Our findings show that Pareto-optimized LLMs with CoT prompting significantly enhance the quality and consistency of Bengali text detoxification.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Under review, 6 pages, 1 figure, 2 tables",
    "pdf_url": "https://arxiv.org/pdf/2511.01512v1",
    "published_date": "2025-11-03 12:26:04 UTC",
    "updated_date": "2025-11-03 12:26:04 UTC"
  },
  {
    "arxiv_id": "2511.01476v1",
    "title": "MO-SeGMan: Rearrangement Planning Framework for Multi Objective Sequential and Guided Manipulation in Constrained Environments",
    "authors": [
      "Cankut Bora Tuncer",
      "Marc Toussaint",
      "Ozgur S. Oguz"
    ],
    "abstract": "In this work, we introduce MO-SeGMan, a Multi-Objective Sequential and Guided Manipulation planner for highly constrained rearrangement problems. MO-SeGMan generates object placement sequences that minimize both replanning per object and robot travel distance while preserving critical dependency structures with a lazy evaluation method. To address highly cluttered, non-monotone scenarios, we propose a Selective Guided Forward Search (SGFS) that efficiently relocates only critical obstacles and to feasible relocation points. Furthermore, we adopt a refinement method for adaptive subgoal selection to eliminate unnecessary pick-and-place actions, thereby improving overall solution quality. Extensive evaluations on nine benchmark rearrangement tasks demonstrate that MO-SeGMan generates feasible motion plans in all cases, consistently achieving faster solution times and superior solution quality compared to the baselines. These results highlight the robustness and scalability of the proposed framework for complex rearrangement planning problems.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "8 pages, 8 figures, website:https://sites.google.com/view/mo-segman/",
    "pdf_url": "https://arxiv.org/pdf/2511.01476v1",
    "published_date": "2025-11-03 11:38:57 UTC",
    "updated_date": "2025-11-03 11:38:57 UTC"
  },
  {
    "arxiv_id": "2511.01468v1",
    "title": "DAMBench: A Multi-Modal Benchmark for Deep Learning-based Atmospheric Data Assimilation",
    "authors": [
      "Hao Wang",
      "Zixuan Weng",
      "Jindong Han",
      "Wei Fan",
      "Hao Liu"
    ],
    "abstract": "Data Assimilation is a cornerstone of atmospheric system modeling, tasked with reconstructing system states by integrating sparse, noisy observations with prior estimation. While traditional approaches like variational and ensemble Kalman filtering have proven effective, recent advances in deep learning offer more scalable, efficient, and flexible alternatives better suited for complex, real-world data assimilation involving large-scale and multi-modal observations. However, existing deep learning-based DA research suffers from two critical limitations: (1) reliance on oversimplified scenarios with synthetically perturbed observations, and (2) the absence of standardized benchmarks for fair model comparison. To address these gaps, in this work, we introduce DAMBench, the first large-scale multi-modal benchmark designed to evaluate data-driven DA models under realistic atmospheric conditions. DAMBench integrates high-quality background states from state-of-the-art forecasting systems and real-world multi-modal observations (i.e., real-world weather stations and satellite imagery). All data are resampled to a common grid and temporally aligned to support systematic training, validation, and testing. We provide unified evaluation protocols and benchmark representative data assimilation approaches, including latent generative models and neural process frameworks. Additionally, we propose a lightweight multi-modal plugin to demonstrate how integrating realistic observations can enhance even simple baselines. Through comprehensive experiments, DAMBench establishes a rigorous foundation for future research, promoting reproducibility, fair comparison, and extensibility to real-world multi-modal scenarios. Our dataset and code are publicly available at https://github.com/figerhaowang/DAMBench.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2511.01468v1",
    "published_date": "2025-11-03 11:26:26 UTC",
    "updated_date": "2025-11-03 11:26:26 UTC"
  },
  {
    "arxiv_id": "2511.01463v1",
    "title": "HMVLM: Human Motion-Vision-Lanuage Model via MoE LoRA",
    "authors": [
      "Lei Hu",
      "Yongjing Ye",
      "Shihong Xia"
    ],
    "abstract": "The expansion of instruction-tuning data has enabled foundation language models to exhibit improved instruction adherence and superior performance across diverse downstream tasks. Semantically-rich 3D human motion is being progressively integrated with these foundation models to enhance multimodal understanding and cross-modal generation capabilities. However, the modality gap between human motion and text raises unresolved concerns about catastrophic forgetting during this integration. In addition, developing autoregressive-compatible pose representations that preserve generalizability across heterogeneous downstream tasks remains a critical technical barrier. To address these issues, we propose the Human Motion-Vision-Language Model (HMVLM), a unified framework based on the Mixture of Expert Low-Rank Adaption(MoE LoRA) strategy. The framework leverages the gating network to dynamically allocate LoRA expert weights based on the input prompt, enabling synchronized fine-tuning of multiple tasks. To mitigate catastrophic forgetting during instruction-tuning, we introduce a novel zero expert that preserves the pre-trained parameters for general linguistic tasks. For pose representation, we implement body-part-specific tokenization by partitioning the human body into different joint groups, enhancing the spatial resolution of the representation. Experiments show that our method effectively alleviates knowledge forgetting during instruction-tuning and achieves remarkable performance across diverse human motion downstream tasks.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.GR"
    ],
    "primary_category": "cs.CV",
    "comment": "10 pages, 5figures. The Thirty-Ninth Annual Conference on Neural Information Processing Systems",
    "pdf_url": "https://arxiv.org/pdf/2511.01463v1",
    "published_date": "2025-11-03 11:22:10 UTC",
    "updated_date": "2025-11-03 11:22:10 UTC"
  },
  {
    "arxiv_id": "2511.01462v1",
    "title": "Efficiently Training A Flat Neural Network Before It has been Quantizated",
    "authors": [
      "Peng Xia",
      "Junbiao Pang",
      "Tianyang Cai"
    ],
    "abstract": "Post-training quantization (PTQ) for vision transformers (ViTs) has garnered significant attention due to its efficiency in compressing models. However, existing methods typically overlook the relationship between a well-trained NN and the quantized model, leading to considerable quantization error for PTQ. However, it is unclear how to efficiently train a model-agnostic neural network which is tailored for a predefined precision low-bit model. In this paper, we firstly discover that a flat full precision neural network is crucial for low-bit quantization. To achieve this, we propose a framework that proactively pre-conditions the model by measuring and disentangling the error sources. Specifically, both the Activation Quantization Error (AQE) and the Weight Quantization Error (WQE) are statistically modeled as independent Gaussian noises. We study several noise injection optimization methods to obtain a flat minimum. Experimental results attest to the effectiveness of our approach. These results open novel pathways for obtaining low-bit PTQ models.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "ongoing work, more results would be added",
    "pdf_url": "https://arxiv.org/pdf/2511.01462v1",
    "published_date": "2025-11-03 11:21:45 UTC",
    "updated_date": "2025-11-03 11:21:45 UTC"
  },
  {
    "arxiv_id": "2511.01458v1",
    "title": "When to Trust the Answer: Question-Aligned Semantic Nearest Neighbor Entropy for Safer Surgical VQA",
    "authors": [
      "Dennis Pierantozzi",
      "Luca Carlini",
      "Mauro Orazio Drago",
      "Chiara Lena",
      "Cesare Hassan",
      "Elena De Momi",
      "Danail Stoyanov",
      "Sophia Bano",
      "Mobarak I. Hoque"
    ],
    "abstract": "Safety and reliability are essential for deploying Visual Question Answering (VQA) in surgery, where incorrect or ambiguous responses can harm the patient. Most surgical VQA research focuses on accuracy or linguistic quality while overlooking safety behaviors such as ambiguity awareness, referral to human experts, or triggering a second opinion. Inspired by Automatic Failure Detection (AFD), we study uncertainty estimation as a key enabler of safer decision making. We introduce Question Aligned Semantic Nearest Neighbor Entropy (QA-SNNE), a black box uncertainty estimator that incorporates question semantics into prediction confidence. It measures semantic entropy by comparing generated answers with nearest neighbors in a medical text embedding space, conditioned on the question. We evaluate five models, including domain specific Parameter-Efficient Fine-Tuned (PEFT) models and zero-shot Large Vision-Language Models (LVLMs), on EndoVis18-VQA and PitVQA. PEFT models degrade under mild paraphrasing, while LVLMs are more resilient. Across three LVLMs and two PEFT baselines, QA-SNNE improves AUROC in most in-template settings and enhances hallucination detection. The Area Under the ROC Curve (AUROC) increases by 15-38% for zero-shot models, with gains maintained under out-of-template stress. QA-SNNE offers a practical and interpretable step toward AFD in surgical VQA by linking semantic uncertainty to question context. Combining LVLM backbones with question aligned uncertainty estimation can improve safety and clinician trust. The code and model are available at https://github.com/DennisPierantozzi/QASNNE",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2511.01458v1",
    "published_date": "2025-11-03 11:18:21 UTC",
    "updated_date": "2025-11-03 11:18:21 UTC"
  },
  {
    "arxiv_id": "2511.01450v3",
    "title": "Reg-DPO: SFT-Regularized Direct Preference Optimization with GT-Pair for Improving Video Generation",
    "authors": [
      "Jie Du",
      "Xinyu Gong",
      "Qingshan Tan",
      "Wen Li",
      "Yangming Cheng",
      "Weitao Wang",
      "Chenlu Zhan",
      "Suhui Wu",
      "Hao Zhang",
      "Jun Zhang"
    ],
    "abstract": "Recent studies have identified Direct Preference Optimization (DPO) as an efficient and reward-free approach to improving video generation quality. However, existing methods largely follow image-domain paradigms and are mainly developed on small-scale models (approximately 2B parameters), limiting their ability to address the unique challenges of video tasks, such as costly data construction, unstable training, and heavy memory consumption. To overcome these limitations, we introduce a GT-Pair that automatically builds high-quality preference pairs by using real videos as positives and model-generated videos as negatives, eliminating the need for any external annotation. We further present Reg-DPO, which incorporates the SFT loss as a regularization term into the DPO loss to enhance training stability and generation fidelity. Additionally, by combining the FSDP framework with multiple memory optimization techniques, our approach achieves nearly three times higher training capacity than using FSDP alone. Extensive experiments on both I2V and T2V tasks across multiple datasets demonstrate that our method consistently outperforms existing approaches, delivering superior video generation quality.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "The paper is withdrawn due to the need for further revision and verification of experimental results. A revised version will be resubmitted once the updates are completed",
    "pdf_url": "https://arxiv.org/pdf/2511.01450v3",
    "published_date": "2025-11-03 11:04:22 UTC",
    "updated_date": "2025-11-10 03:10:25 UTC"
  },
  {
    "arxiv_id": "2511.01449v1",
    "title": "Privacy Preserving Ordinal-Meta Learning with VLMs for Fine-Grained Fruit Quality Prediction",
    "authors": [
      "Riddhi Jain",
      "Manasi Patwardhan",
      "Aayush Mishra",
      "Parijat Deshpande",
      "Beena Rai"
    ],
    "abstract": "To effectively manage the wastage of perishable fruits, it is crucial to accurately predict their freshness or shelf life using non-invasive methods that rely on visual data. In this regard, deep learning techniques can offer a viable solution. However, obtaining fine-grained fruit freshness labels from experts is costly, leading to a scarcity of data. Closed proprietary Vision Language Models (VLMs), such as Gemini, have demonstrated strong performance in fruit freshness detection task in both zero-shot and few-shot settings. Nonetheless, food retail organizations are unable to utilize these proprietary models due to concerns related to data privacy, while existing open-source VLMs yield sub-optimal performance for the task. Fine-tuning these open-source models with limited data fails to achieve the performance levels of proprietary models. In this work, we introduce a Model-Agnostic Ordinal Meta-Learning (MAOML) algorithm, designed to train smaller VLMs. This approach utilizes meta-learning to address data sparsity and leverages label ordinality, thereby achieving state-of-the-art performance in the fruit freshness classification task under both zero-shot and few-shot settings. Our method achieves an industry-standard accuracy of 92.71%, averaged across all fruits.\n  Keywords: Fruit Quality Prediction, Vision Language Models, Meta Learning, Ordinal Regression",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "9 pages, 1 figure, 4 tables",
    "pdf_url": "https://arxiv.org/pdf/2511.01449v1",
    "published_date": "2025-11-03 11:03:54 UTC",
    "updated_date": "2025-11-03 11:03:54 UTC"
  },
  {
    "arxiv_id": "2511.01445v1",
    "title": "From Passive to Proactive: A Multi-Agent System with Dynamic Task Orchestration for Intelligent Medical Pre-Consultation",
    "authors": [
      "ChengZhang Yu",
      "YingRu He",
      "Hongyan Cheng",
      "nuo Cheng",
      "Zhixing Liu",
      "Dongxu Mu",
      "Zhangrui Shen",
      "Zhanpeng Jin"
    ],
    "abstract": "Global healthcare systems face critical challenges from increasing patient volumes and limited consultation times, with primary care visits averaging under 5 minutes in many countries. While pre-consultation processes encompassing triage and structured history-taking offer potential solutions, they remain limited by passive interaction paradigms and context management challenges in existing AI systems. This study introduces a hierarchical multi-agent framework that transforms passive medical AI systems into proactive inquiry agents through autonomous task orchestration. We developed an eight-agent architecture with centralized control mechanisms that decomposes pre-consultation into four primary tasks: Triage ($T_1$), History of Present Illness collection ($T_2$), Past History collection ($T_3$), and Chief Complaint generation ($T_4$), with $T_1$--$T_3$ further divided into 13 domain-specific subtasks. Evaluated on 1,372 validated electronic health records from a Chinese medical platform across multiple foundation models (GPT-OSS 20B, Qwen3-8B, Phi4-14B), the framework achieved 87.0% accuracy for primary department triage and 80.5% for secondary department classification, with task completion rates reaching 98.2% using agent-driven scheduling versus 93.1% with sequential processing. Clinical quality scores from 18 physicians averaged 4.56 for Chief Complaints, 4.48 for History of Present Illness, and 4.69 for Past History on a 5-point scale, with consultations completed within 12.7 rounds for $T_2$ and 16.9 rounds for $T_3$. The model-agnostic architecture maintained high performance across different foundation models while preserving data privacy through local deployment, demonstrating the potential for autonomous AI systems to enhance pre-consultation efficiency and quality in clinical settings.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "14pages, 7 figures, 7 tables",
    "pdf_url": "https://arxiv.org/pdf/2511.01445v1",
    "published_date": "2025-11-03 10:55:35 UTC",
    "updated_date": "2025-11-03 10:55:35 UTC"
  },
  {
    "arxiv_id": "2511.01444v1",
    "title": "Robust Multimodal Sentiment Analysis via Double Information Bottleneck",
    "authors": [
      "Huiting Huang",
      "Tieliang Gong",
      "Kai He",
      "Jialun Wu",
      "Erik Cambria",
      "Mengling Feng"
    ],
    "abstract": "Multimodal sentiment analysis has received significant attention across diverse research domains. Despite advancements in algorithm design, existing approaches suffer from two critical limitations: insufficient learning of noise-contaminated unimodal data, leading to corrupted cross-modal interactions, and inadequate fusion of multimodal representations, resulting in discarding discriminative unimodal information while retaining multimodal redundant information. To address these challenges, this paper proposes a Double Information Bottleneck (DIB) strategy to obtain a powerful, unified compact multimodal representation. Implemented within the framework of low-rank Renyi's entropy functional, DIB offers enhanced robustness against diverse noise sources and computational tractability for high-dimensional data, as compared to the conventional Shannon entropy-based methods. The DIB comprises two key modules: 1) learning a sufficient and compressed representation of individual unimodal data by maximizing the task-relevant information and discarding the superfluous information, and 2) ensuring the discriminative ability of multimodal representation through a novel attention bottleneck fusion mechanism. Consequently, DIB yields a multimodal representation that effectively filters out noisy information from unimodal data while capturing inter-modal complementarity. Extensive experiments on CMU-MOSI, CMU-MOSEI, CH-SIMS, and MVSA-Single validate the effectiveness of our method. The model achieves 47.4% accuracy under the Acc-7 metric on CMU-MOSI and 81.63% F1-score on CH-SIMS, outperforming the second-best baseline by 1.19%. Under noise, it shows only 0.36% and 0.29% performance degradation on CMU-MOSI and CMU-MOSEI respectively.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2511.01444v1",
    "published_date": "2025-11-03 10:52:45 UTC",
    "updated_date": "2025-11-03 10:52:45 UTC"
  },
  {
    "arxiv_id": "2511.05553v1",
    "title": "EVLP:Learning Unified Embodied Vision-Language Planner with Reinforced Supervised Fine-Tuning",
    "authors": [
      "Xinyan Cai",
      "Shiguang Wu",
      "Dafeng Chi",
      "Yuzheng Zhuang",
      "Xingyue Quan",
      "Jianye Hao",
      "Qiang Guan"
    ],
    "abstract": "In complex embodied long-horizon manipulation tasks, effective task decomposition and execution require synergistic integration of textual logical reasoning and visual-spatial imagination to ensure efficient and accurate operation. Current methods fail to adopt a unified generation framework for multimodal planning, lead to inconsistent in multimodal planning. To address this challenge, we present \\textbf{EVLP (Embodied Vision-Language Planner)}, an innovative multimodal unified generation framework that jointly models linguistic reasoning and visual generation. Our approach achieves multimodal planning for long-horizon tasks through a novel training pipeline incorporating dynamic pretraining and reinforced alignment. Our core innovations consist of three key components: \\textbf{1) Unified Multimodal Generation Framework}: For understanding, We integrate semantic information with spatial features to provide comprehensive visual perception. For generation, we directly learn the joint distribution of discrete images for one-step visual synthesis, enabling coordinated language-visual modeling through learnable cross-modal attention mechanisms. \\textbf{2) Dynamic Perception Pretraining}: We propose a bidirectional dynamic alignment strategy employing inverse dynamics tasks and forward dynamics tasks, effectively strengthening multimodal correlations within a unified feature space. \\textbf{3) Reinforced Supervised Fine-Tuning}: While conducting instruction-based fine-tuning in the unified generation space, we construct a reinforce loss to align the spatial logic between textual actions and generated images, enabling the model to acquire spatio-awared multimodal planning capabilities.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2511.05553v1",
    "published_date": "2025-11-03 10:24:49 UTC",
    "updated_date": "2025-11-03 10:24:49 UTC"
  },
  {
    "arxiv_id": "2511.01947v1",
    "title": "Interpretable Heart Disease Prediction via a Weighted Ensemble Model: A Large-Scale Study with SHAP and Surrogate Decision Trees",
    "authors": [
      "Md Abrar Hasnat",
      "Md Jobayer",
      "Md. Mehedi Hasan Shawon",
      "Md. Golam Rabiul Alam"
    ],
    "abstract": "Cardiovascular disease (CVD) remains a critical global health concern, demanding reliable and interpretable predictive models for early risk assessment. This study presents a large-scale analysis using the Heart Disease Health Indicators Dataset, developing a strategically weighted ensemble model that combines tree-based methods (LightGBM, XGBoost) with a Convolutional Neural Network (CNN) to predict CVD risk. The model was trained on a preprocessed dataset of 229,781 patients where the inherent class imbalance was managed through strategic weighting and feature engineering enhanced the original 22 features to 25. The final ensemble achieves a statistically significant improvement over the best individual model, with a Test AUC of 0.8371 (p=0.003) and is particularly suited for screening with a high recall of 80.0%. To provide transparency and clinical interpretability, surrogate decision trees and SHapley Additive exPlanations (SHAP) are used. The proposed model delivers a combination of robust predictive performance and clinical transparency by blending diverse learning architectures and incorporating explainability through SHAP and surrogate decision trees, making it a strong candidate for real-world deployment in public health screening.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "eess.SP"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2511.01947v1",
    "published_date": "2025-11-03 10:24:09 UTC",
    "updated_date": "2025-11-03 10:24:09 UTC"
  },
  {
    "arxiv_id": "2511.01427v1",
    "title": "UniSOT: A Unified Framework for Multi-Modality Single Object Tracking",
    "authors": [
      "Yinchao Ma",
      "Yuyang Tang",
      "Wenfei Yang",
      "Tianzhu Zhang",
      "Xu Zhou",
      "Feng Wu"
    ],
    "abstract": "Single object tracking aims to localize target object with specific reference modalities (bounding box, natural language or both) in a sequence of specific video modalities (RGB, RGB+Depth, RGB+Thermal or RGB+Event.). Different reference modalities enable various human-machine interactions, and different video modalities are demanded in complex scenarios to enhance tracking robustness. Existing trackers are designed for single or several video modalities with single or several reference modalities, which leads to separate model designs and limits practical applications. Practically, a unified tracker is needed to handle various requirements. To the best of our knowledge, there is still no tracker that can perform tracking with these above reference modalities across these video modalities simultaneously. Thus, in this paper, we present a unified tracker, UniSOT, for different combinations of three reference modalities and four video modalities with uniform parameters. Extensive experimental results on 18 visual tracking, vision-language tracking and RGB+X tracking benchmarks demonstrate that UniSOT shows superior performance against modality-specific counterparts. Notably, UniSOT outperforms previous counterparts by over 3.0\\% AUC on TNL2K across all three reference modalities and outperforms Un-Track by over 2.0\\% main metric across all three RGB+X video modalities.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "The paper has been accepted by TPAMI",
    "pdf_url": "https://arxiv.org/pdf/2511.01427v1",
    "published_date": "2025-11-03 10:23:53 UTC",
    "updated_date": "2025-11-03 10:23:53 UTC"
  },
  {
    "arxiv_id": "2511.01425v1",
    "title": "Learning to Seek Evidence: A Verifiable Reasoning Agent with Causal Faithfulness Analysis",
    "authors": [
      "Yuhang Huang",
      "Zekai Lin",
      "Fan Zhong",
      "Lei Liu"
    ],
    "abstract": "Explanations for AI models in high-stakes domains like medicine often lack verifiability, which can hinder trust. To address this, we propose an interactive agent that produces explanations through an auditable sequence of actions. The agent learns a policy to strategically seek external visual evidence to support its diagnostic reasoning. This policy is optimized using reinforcement learning, resulting in a model that is both efficient and generalizable. Our experiments show that this action-based reasoning process significantly improves calibrated accuracy, reducing the Brier score by 18\\% compared to a non-interactive baseline. To validate the faithfulness of the agent's explanations, we introduce a causal intervention method. By masking the visual evidence the agent chooses to use, we observe a measurable degradation in its performance ($Δ$Brier=+0.029), confirming that the evidence is integral to its decision-making process. Our work provides a practical framework for building AI systems with verifiable and faithful reasoning capabilities.",
    "categories": [
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.AI",
    "comment": "12 pages, 3 figures. Under review at the Conference on Computer Vision and Pattern Recognition (CVPR) 2026",
    "pdf_url": "https://arxiv.org/pdf/2511.01425v1",
    "published_date": "2025-11-03 10:21:35 UTC",
    "updated_date": "2025-11-03 10:21:35 UTC"
  },
  {
    "arxiv_id": "2511.01946v1",
    "title": "COFAP: A Universal Framework for COFs Adsorption Prediction through Designed Multi-Modal Extraction and Cross-Modal Synergy",
    "authors": [
      "Zihan Li",
      "Mingyang Wan",
      "Mingyu Gao",
      "Zhongshan Chen",
      "Xiangke Wang",
      "Feifan Zhang"
    ],
    "abstract": "Covalent organic frameworks (COFs) are promising adsorbents for gas adsorption and separation, while identifying the optimal structures among their vast design space requires efficient high-throughput screening. Conventional machine-learning predictors rely heavily on specific gas-related features. However, these features are time-consuming and limit scalability, leading to inefficiency and labor-intensive processes. Herein, a universal COFs adsorption prediction framework (COFAP) is proposed, which can extract multi-modal structural and chemical features through deep learning, and fuse these complementary features via cross-modal attention mechanism. Without Henry coefficients or adsorption heat, COFAP sets a new SOTA by outperforming previous approaches on hypoCOFs dataset. Based on COFAP, we also found that high-performing COFs for separation concentrate within a narrow range of pore size and surface area. A weight-adjustable prioritization scheme is also developed to enable flexible, application-specific ranking of candidate COFs for researchers. Superior efficiency and accuracy render COFAP directly deployable in crystalline porous materials.",
    "categories": [
      "cs.LG",
      "cond-mat.mtrl-sci",
      "cs.AI",
      "physics.chem-ph"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2511.01946v1",
    "published_date": "2025-11-03 10:11:33 UTC",
    "updated_date": "2025-11-03 10:11:33 UTC"
  },
  {
    "arxiv_id": "2511.01415v1",
    "title": "Modulation of temporal decision-making in a deep reinforcement learning agent under the dual-task paradigm",
    "authors": [
      "Amrapali Pednekar",
      "Álvaro Garrido-Pérez",
      "Yara Khaluf",
      "Pieter Simoens"
    ],
    "abstract": "This study explores the interference in temporal processing within a dual-task paradigm from an artificial intelligence (AI) perspective. In this context, the dual-task setup is implemented as a simplified version of the Overcooked environment with two variations, single task (T) and dual task (T+N). Both variations involve an embedded time production task, but the dual task (T+N) additionally involves a concurrent number comparison task. Two deep reinforcement learning (DRL) agents were separately trained for each of these tasks. These agents exhibited emergent behavior consistent with human timing research. Specifically, the dual task (T+N) agent exhibited significant overproduction of time relative to its single task (T) counterpart. This result was consistent across four target durations. Preliminary analysis of neural dynamics in the agents' LSTM layers did not reveal any clear evidence of a dedicated or intrinsic timer. Hence, further investigation is needed to better understand the underlying time-keeping mechanisms of the agents and to provide insights into the observed behavioral patterns. This study is a small step towards exploring parallels between emergent DRL behavior and behavior observed in biological systems in order to facilitate a better understanding of both.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted at CogInterp workshop @ NeurIPS 2025",
    "pdf_url": "https://arxiv.org/pdf/2511.01415v1",
    "published_date": "2025-11-03 10:09:55 UTC",
    "updated_date": "2025-11-03 10:09:55 UTC"
  },
  {
    "arxiv_id": "2511.01407v1",
    "title": "FoldPath: End-to-End Object-Centric Motion Generation via Modulated Implicit Paths",
    "authors": [
      "Paolo Rabino",
      "Gabriele Tiboni",
      "Tatiana Tommasi"
    ],
    "abstract": "Object-Centric Motion Generation (OCMG) is instrumental in advancing automated manufacturing processes, particularly in domains requiring high-precision expert robotic motions, such as spray painting and welding. To realize effective automation, robust algorithms are essential for generating extended, object-aware trajectories across intricate 3D geometries. However, contemporary OCMG techniques are either based on ad-hoc heuristics or employ learning-based pipelines that are still reliant on sensitive post-processing steps to generate executable paths. We introduce FoldPath, a novel, end-to-end, neural field based method for OCMG. Unlike prior deep learning approaches that predict discrete sequences of end-effector waypoints, FoldPath learns the robot motion as a continuous function, thus implicitly encoding smooth output paths. This paradigm shift eliminates the need for brittle post-processing steps that concatenate and order the predicted discrete waypoints. Particularly, our approach demonstrates superior predictive performance compared to recently proposed learning-based methods, and attains generalization capabilities even in real industrial settings, where only a limited amount of 70 expert samples are provided. We validate FoldPath through comprehensive experiments in a realistic simulation environment and introduce new, rigorous metrics designed to comprehensively evaluate long-horizon robotic paths, thus advancing the OCMG task towards practical maturity.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "Accepted at 2025 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2025)",
    "pdf_url": "https://arxiv.org/pdf/2511.01407v1",
    "published_date": "2025-11-03 10:00:25 UTC",
    "updated_date": "2025-11-03 10:00:25 UTC"
  },
  {
    "arxiv_id": "2511.01396v1",
    "title": "Relaxing partition admissibility in Cluster-DAGs: a causal calculus with arbitrary variable clustering",
    "authors": [
      "Clément Yvernes",
      "Emilie Devijver",
      "Adèle H. Ribeiro",
      "Marianne Clausel--Lesourd",
      "Éric Gaussier"
    ],
    "abstract": "Cluster DAGs (C-DAGs) provide an abstraction of causal graphs in which nodes represent clusters of variables, and edges encode both cluster-level causal relationships and dependencies arisen from unobserved confounding. C-DAGs define an equivalence class of acyclic causal graphs that agree on cluster-level relationships, enabling causal reasoning at a higher level of abstraction. However, when the chosen clustering induces cycles in the resulting C-DAG, the partition is deemed inadmissible under conventional C-DAG semantics. In this work, we extend the C-DAG framework to support arbitrary variable clusterings by relaxing the partition admissibility constraint, thereby allowing cyclic C-DAG representations. We extend the notions of d-separation and causal calculus to this setting, significantly broadening the scope of causal reasoning across clusters and enabling the application of C-DAGs in previously intractable scenarios. Our calculus is both sound and atomically complete with respect to the do-calculus: all valid interventional queries at the cluster level can be derived using our rules, each corresponding to a primitive do-calculus step.",
    "categories": [
      "cs.AI",
      "stat.ME"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted at The Thirty-ninth Annual Conference on Neural Information Processing Systems (NeurIPS2025)",
    "pdf_url": "https://arxiv.org/pdf/2511.01396v1",
    "published_date": "2025-11-03 09:44:58 UTC",
    "updated_date": "2025-11-03 09:44:58 UTC"
  },
  {
    "arxiv_id": "2511.01390v1",
    "title": "SEPS: Semantic-enhanced Patch Slimming Framework for fine-grained cross-modal alignment",
    "authors": [
      "Xinyu Mao",
      "Junsi Li",
      "Haoji Zhang",
      "Yu Liang",
      "Ming Sun"
    ],
    "abstract": "Fine-grained cross-modal alignment aims to establish precise local correspondences between vision and language, forming a cornerstone for visual question answering and related multimodal applications. Current approaches face challenges in addressing patch redundancy and ambiguity, which arise from the inherent information density disparities across modalities. Recently, Multimodal Large Language Models (MLLMs) have emerged as promising solutions to bridge this gap through their robust semantic generation capabilities. However, the dense textual outputs from MLLMs may introduce conflicts with the original sparse captions. Furthermore, accurately quantifying semantic relevance between rich visual patches and concise textual descriptions remains a core challenge. To overcome these limitations, we introduce the Semantic-Enhanced Patch Slimming (SEPS) framework, which systematically addresses patch redundancy and ambiguity. Our approach employs a two-stage mechanism to integrate unified semantics from both dense and sparse texts, enabling the identification of salient visual patches. Additionally, it leverages relevance-aware selection with mean value computation to highlight crucial patch-word correspondences, thereby improving cross-modal similarity assessment. Comprehensive experiments on Flickr30K and MS-COCO datasets validate that SEPS achieves superior performance, surpassing existing approaches by 23\\%-86\\% in rSum across diverse model architectures, with notable enhancements in text-to-image retrieval scenarios. Our implementation is available at https://github.com/Sweet4tars/seps.git.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.MM"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2511.01390v1",
    "published_date": "2025-11-03 09:41:32 UTC",
    "updated_date": "2025-11-03 09:41:32 UTC"
  },
  {
    "arxiv_id": "2511.01386v1",
    "title": "RAGSmith: A Framework for Finding the Optimal Composition of Retrieval-Augmented Generation Methods Across Datasets",
    "authors": [
      "Muhammed Yusuf Kartal",
      "Suha Kagan Kose",
      "Korhan Sevinç",
      "Burak Aktas"
    ],
    "abstract": "Retrieval-Augmented Generation (RAG) quality depends on many interacting choices across retrieval, ranking, augmentation, prompting, and generation, so optimizing modules in isolation is brittle. We introduce RAGSmith, a modular framework that treats RAG design as an end-to-end architecture search over nine technique families and 46{,}080 feasible pipeline configurations. A genetic search optimizes a scalar objective that jointly aggregates retrieval metrics (recall@k, mAP, nDCG, MRR) and generation metrics (LLM-Judge and semantic similarity). We evaluate on six Wikipedia-derived domains (Mathematics, Law, Finance, Medicine, Defense Industry, Computer Science), each with 100 questions spanning factual, interpretation, and long-answer types. RAGSmith finds configurations that consistently outperform naive RAG baseline by +3.8\\% on average (range +1.2\\% to +6.9\\% across domains), with gains up to +12.5\\% in retrieval and +7.5\\% in generation. The search typically explores $\\approx 0.2\\%$ of the space ($\\sim 100$ candidates) and discovers a robust backbone -- vector retrieval plus post-generation reflection/revision -- augmented by domain-dependent choices in expansion, reranking, augmentation, and prompt reordering; passage compression is never selected. Improvement magnitude correlates with question type, with larger gains on factual/long-answer mixes than interpretation-heavy sets. These results provide practical, domain-aware guidance for assembling effective RAG systems and demonstrate the utility of evolutionary search for full-pipeline optimization.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.CL",
    "comment": "45 pages",
    "pdf_url": "https://arxiv.org/pdf/2511.01386v1",
    "published_date": "2025-11-03 09:36:27 UTC",
    "updated_date": "2025-11-03 09:36:27 UTC"
  },
  {
    "arxiv_id": "2511.01375v1",
    "title": "Align to Misalign: Automatic LLM Jailbreak with Meta-Optimized LLM Judges",
    "authors": [
      "Hamin Koo",
      "Minseon Kim",
      "Jaehyung Kim"
    ],
    "abstract": "Identifying the vulnerabilities of large language models (LLMs) is crucial for improving their safety by addressing inherent weaknesses. Jailbreaks, in which adversaries bypass safeguards with crafted input prompts, play a central role in red-teaming by probing LLMs to elicit unintended or unsafe behaviors. Recent optimization-based jailbreak approaches iteratively refine attack prompts by leveraging LLMs. However, they often rely heavily on either binary attack success rate (ASR) signals, which are sparse, or manually crafted scoring templates, which introduce human bias and uncertainty in the scoring outcomes. To address these limitations, we introduce AMIS (Align to MISalign), a meta-optimization framework that jointly evolves jailbreak prompts and scoring templates through a bi-level structure. In the inner loop, prompts are refined using fine-grained and dense feedback using a fixed scoring template. In the outer loop, the template is optimized using an ASR alignment score, gradually evolving to better reflect true attack outcomes across queries. This co-optimization process yields progressively stronger jailbreak prompts and more calibrated scoring signals. Evaluations on AdvBench and JBB-Behaviors demonstrate that AMIS achieves state-of-the-art performance, including 88.0% ASR on Claude-3.5-Haiku and 100.0% ASR on Claude-4-Sonnet, outperforming existing baselines by substantial margins.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "under review, 28 pages",
    "pdf_url": "https://arxiv.org/pdf/2511.01375v1",
    "published_date": "2025-11-03 09:18:27 UTC",
    "updated_date": "2025-11-03 09:18:27 UTC"
  },
  {
    "arxiv_id": "2511.10656v1",
    "title": "Preference Orchestrator: Prompt-Aware Multi-Objective Alignment for Large Language Models",
    "authors": [
      "Biao Liu",
      "Ning Xu",
      "Junming Yang",
      "Xin Geng"
    ],
    "abstract": "While Large Language Models (LLMs) have demonstrated remarkable capabilities across diverse natural language processing tasks, aligning these models with varying human preferences across multiple objectives remains a significant challenge in practical deployments. Existing multi-objective alignment methods rely on manually specified preference weights, which not only burden users with difficult preference specification tasks but also lead to suboptimal training efficiency due to exploration of irrelevant preference combinations. To alleviate these issues, we propose a novel framework named PRO, i.e., PReference Orchestrator, which features a lightweight preference adapter that automatically infers prompt-specific preference weights during both training and deployment phases. Specifically, the adapter automatically learns appropriate preference weights for each prompt by training on normalized reward scores from multiple reward models for preferred responses, which inherently reflect effective preference balances across objectives. Additionally, We provide theoretical analysis proving that our prompt-aware preference mechanism achieves superior performance compared to fixed preference weights in multi-objective alignment scenarios. Extensive experiments across multiple tasks demonstrate the effectiveness of our method over existing multi-objective alignment approaches.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2511.10656v1",
    "published_date": "2025-11-03 09:16:45 UTC",
    "updated_date": "2025-11-03 09:16:45 UTC"
  },
  {
    "arxiv_id": "2511.01363v1",
    "title": "Automatic Minds: Cognitive Parallels Between Hypnotic States and Large Language Model Processing",
    "authors": [
      "Giuseppe Riva",
      "Brenda K. Wiederhold",
      "Fabrizia Mantovani"
    ],
    "abstract": "The cognitive processes of the hypnotized mind and the computational operations of large language models (LLMs) share deep functional parallels. Both systems generate sophisticated, contextually appropriate behavior through automatic pattern-completion mechanisms operating with limited or unreliable executive oversight. This review examines this convergence across three principles: automaticity, in which responses emerge from associative rather than deliberative processes; suppressed monitoring, leading to errors such as confabulation in hypnosis and hallucination in LLMs; and heightened contextual dependency, where immediate cues (for example, the suggestion of a therapist or the prompt of the user) override stable knowledge.\n  These mechanisms reveal an observer-relative meaning gap: both systems produce coherent but ungrounded outputs that require an external interpreter to supply meaning. Hypnosis and LLMs also exemplify functional agency - the capacity for complex, goal-directed, context-sensitive behavior - without subjective agency, the conscious awareness of intention and ownership that defines human action. This distinction clarifies how purposive behavior can emerge without self-reflective consciousness, governed instead by structural and contextual dynamics. Finally, both domains illuminate the phenomenon of scheming: automatic, goal-directed pattern generation that unfolds without reflective awareness. Hypnosis provides an experimental model for understanding how intention can become dissociated from conscious deliberation, offering insights into the hidden motivational dynamics of artificial systems. Recognizing these parallels suggests that the future of reliable AI lies in hybrid architectures that integrate generative fluency with mechanisms of executive monitoring, an approach inspired by the complex, self-regulating architecture of the human mind.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "4 Tables",
    "pdf_url": "https://arxiv.org/pdf/2511.01363v1",
    "published_date": "2025-11-03 09:08:50 UTC",
    "updated_date": "2025-11-03 09:08:50 UTC"
  },
  {
    "arxiv_id": "2511.01359v1",
    "title": "PrefixNLI: Detecting Factual Inconsistencies as Soon as They Arise",
    "authors": [
      "Sapir Harary",
      "Eran Hirsch",
      "Aviv Slobodkin",
      "David Wan",
      "Mohit Bansal",
      "Ido Dagan"
    ],
    "abstract": "Natural Language Inference (NLI) models have been used in various ways to improve the factuality of LLM outputs. This is typically done by applying an NLI model to judge whether the model output is entailed from the supposed evidence, triggering some corrective actions, such as beam reranking at inference time or RL rewards during training. While NLI models are trained to detect factual inconsistencies over complete sentences, decisions in the common autoregressive generation architecture are made for each evolving text prefix, during decoding. Addressing this setting, we generalize the entailment detection task to apply over arbitrary text prefixes, and suggest its utility for improving generation faithfulness. Providing suitable evaluation and training datasets for this task, we train MiniTruePrefixes, a novel specialized model that better detects factual inconsistencies over text prefixes, outperforming comparable baseline NLI models by 5-14 F1 points in prefix-level entailment. We further demonstrate that integrating MiniTruePrefixes into a controlled decoding framework substantially improves factual consistency in abstractive summarization. When guided by MiniTruePrefixes, LLaMA-3.2-3B-Instruct matches the faithfulness and runtime of the 8B model from the same model family, while using only half the memory.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "9 pages + appendix. Code, datasets, and models are available at https://github.com/sapirharary/PrefixNLI",
    "pdf_url": "https://arxiv.org/pdf/2511.01359v1",
    "published_date": "2025-11-03 09:07:44 UTC",
    "updated_date": "2025-11-03 09:07:44 UTC"
  },
  {
    "arxiv_id": "2511.01357v1",
    "title": "CMI-MTL: Cross-Mamba interaction based multi-task learning for medical visual question answering",
    "authors": [
      "Qiangguo Jin",
      "Xianyao Zheng",
      "Hui Cui",
      "Changming Sun",
      "Yuqi Fang",
      "Cong Cong",
      "Ran Su",
      "Leyi Wei",
      "Ping Xuan",
      "Junbo Wang"
    ],
    "abstract": "Medical visual question answering (Med-VQA) is a crucial multimodal task in clinical decision support and telemedicine. Recent self-attention based methods struggle to effectively handle cross-modal semantic alignments between vision and language. Moreover, classification-based methods rely on predefined answer sets. Treating this task as a simple classification problem may make it unable to adapt to the diversity of free-form answers and overlook the detailed semantic information of free-form answers. In order to tackle these challenges, we introduce a Cross-Mamba Interaction based Multi-Task Learning (CMI-MTL) framework that learns cross-modal feature representations from images and texts. CMI-MTL comprises three key modules: fine-grained visual-text feature alignment (FVTA), cross-modal interleaved feature representation (CIFR), and free-form answer-enhanced multi-task learning (FFAE). FVTA extracts the most relevant regions in image-text pairs through fine-grained visual-text feature alignment. CIFR captures cross-modal sequential interactions via cross-modal interleaved feature representation. FFAE leverages auxiliary knowledge from open-ended questions through free-form answer-enhanced multi-task learning, improving the model's capability for open-ended Med-VQA. Experimental results show that CMI-MTL outperforms the existing state-of-the-art methods on three Med-VQA datasets: VQA-RAD, SLAKE, and OVQA. Furthermore, we conduct more interpretability experiments to prove the effectiveness. The code is publicly available at https://github.com/BioMedIA-repo/CMI-MTL.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "The paper has been accepted by the 33rd Pacific Conference on Computer Graphics and Applications (Pacific Graphics 2025)",
    "pdf_url": "https://arxiv.org/pdf/2511.01357v1",
    "published_date": "2025-11-03 09:05:16 UTC",
    "updated_date": "2025-11-03 09:05:16 UTC"
  },
  {
    "arxiv_id": "2511.01354v1",
    "title": "Thinking with DistilQwen: A Tale of Four Distilled Reasoning and Reward Model Series",
    "authors": [
      "Wenrui Cai",
      "Chengyu Wang",
      "Junbing Yan",
      "Jun Huang",
      "Xiangzhong Fang"
    ],
    "abstract": "Recently, the demand for small and efficient reasoning models to support real-world applications has driven the development of knowledge distillation techniques that balance reasoning performance and inference speed. In this paper, we further extend the DistilQwen model family, initialized from the Qwen models, by introducing four model series specifically designed to meet industrial requirements. The distilled model collection comprises: (1) slow-thinking models, optimized for reasoning tasks that require high accuracy; (2) two series of adaptive-thinking models, which dynamically adjust reasoning strategies based on input tasks to maximize efficiency across diverse scenarios; and (3) distilled reward models, which enable further reinforcement learning of reasoning models using distilled knowledge. Comprehensive evaluations across multiple benchmarks demonstrate both high inference efficiency and strong reasoning performance for these models, as well as the practical utility of distilled reward models. We further show that these models support industry practitioners by providing scalable training and inference functionalities on the Alibaba Cloud PAI (Platform for Artificial Intelligence) platform.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "emnlp 2025 industry track",
    "pdf_url": "https://arxiv.org/pdf/2511.01354v1",
    "published_date": "2025-11-03 09:00:51 UTC",
    "updated_date": "2025-11-03 09:00:51 UTC"
  },
  {
    "arxiv_id": "2511.01353v1",
    "title": "AI Literacy in UAE Libraries: Assessing Competencies, Training Needs, and Ethical Considerations for the Digital Age",
    "authors": [
      "Zafar Imam Khan"
    ],
    "abstract": "The study explores the current state of artificial intelligence (AI) literacy levels among library professionals employing a quantitative approach consisting of 92 surveys of LIS professionals in the United Arab Emirates (UAE). Findings of the study revealed the presence of strong cognitive competencies, while there were gaps observed in behavioral and normative competencies, especially related to AI biases, AI-powered learning, and ethical considerations. There was a disconnect observed between the perceived importance of AI skills and the effectiveness of the current training programs.",
    "categories": [
      "cs.DL",
      "cs.AI"
    ],
    "primary_category": "cs.DL",
    "comment": "This is the accepted manuscript version. The final published version will appear in College & Research Libraries, November 2026",
    "pdf_url": "https://arxiv.org/pdf/2511.01353v1",
    "published_date": "2025-11-03 09:00:15 UTC",
    "updated_date": "2025-11-03 09:00:15 UTC"
  },
  {
    "arxiv_id": "2511.01348v2",
    "title": "The Future of Generative AI in Software Engineering: A Vision from Industry and Academia in the European GENIUS Project",
    "authors": [
      "Robin Gröpler",
      "Steffen Klepke",
      "Jack Johns",
      "Andreas Dreschinski",
      "Klaus Schmid",
      "Benedikt Dornauer",
      "Eray Tüzün",
      "Joost Noppen",
      "Mohammad Reza Mousavi",
      "Yongjian Tang",
      "Johannes Viehmann",
      "Selin Şirin Aslangül",
      "Beum Seuk Lee",
      "Adam Ziolkowski",
      "Eric Zie"
    ],
    "abstract": "Generative AI (GenAI) has recently emerged as a groundbreaking force in Software Engineering, capable of generating code, identifying bugs, recommending fixes, and supporting quality assurance. While its use in coding tasks shows considerable promise, applying GenAI across the entire Software Development Life Cycle (SDLC) has not yet been fully explored. Critical uncertainties in areas such as reliability, accountability, security, and data privacy demand deeper investigation and coordinated action. The GENIUS project, comprising over 30 European industrial and academic partners, aims to address these challenges by advancing AI integration across all SDLC phases. It focuses on GenAI's potential, the development of innovative tools, and emerging research challenges, actively shaping the future of software engineering. This vision paper presents a shared perspective on the future of GenAI-driven software engineering, grounded in cross-sector dialogue as well as experiences and findings within the GENIUS consortium. The paper explores four central elements: (1) a structured overview of current challenges in GenAI adoption across the SDLC; (2) a forward-looking vision outlining key technological and methodological advances expected over the next five years; (3) anticipated shifts in the roles and required skill sets of software professionals; and (4) the contribution of GENIUS in realising this transformation through practical tools and industrial validation. This paper focuses on aligning technical innovation with business relevance. It aims to inform both research agendas and industrial strategies, providing a foundation for reliable, scalable, and industry-ready GenAI solutions for software engineering teams.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "Accepted for the 2nd IEEE/ACM International Conference on AI-powered Software (AIware 2025)",
    "pdf_url": "https://arxiv.org/pdf/2511.01348v2",
    "published_date": "2025-11-03 08:56:23 UTC",
    "updated_date": "2025-11-06 23:41:33 UTC"
  },
  {
    "arxiv_id": "2511.11608v1",
    "title": "Why Should the Server Do It All?: A Scalable, Versatile, and Model-Agnostic Framework for Server-Light DNN Inference over Massively Distributed Clients via Training-Free Intermediate Feature Compression",
    "authors": [
      "Mingyu Sung",
      "Suhwan Im",
      "Daeho Bang",
      "Il-Min Kim",
      "Sangseok Yun",
      "Jae-Mo Kang"
    ],
    "abstract": "Modern DNNs often rely on edge-cloud model partitioning (MP), but widely used schemes fix shallow, static split points that underutilize edge compute and concentrate latency and energy on the server. The problem is exacerbated in autoregressive (AR) LLM inference, where per-token forward passes repeatedly generate bulky intermediate features (IFs). We introduce SLICER, a retraining-free, architecture-agnostic framework that compresses IFs to reduce both communication and server load in split computing. SLICER combines (i) asymmetric top-K filtering (ATKF) to sparsify low-magnitude activations, (ii) magnitude-splitting (MS) to group the remaining non-zeros into equal-cardinality blocks, and (iii) adaptive bit quantization (ABQ) that selects per-block bitwidths under a distortion budget. Across standard vision and LLM workloads (e.g., ImageNet/COCO; HellaSwag, PIQA, ARC-E/C, GSM8K, HumanEval), SLICER reduces uplink volume by up to 10x and server GPU time by up to 4.4x, while keeping task quality within ~0-3 pp of baseline. In multi-device settings and AR LLMs, SLICER scales by shifting meaningful compute to the edge and lowering bits-per-token and server time per token, stabilizing per-step traffic. The codec attaches to off-the-shelf models without retraining or architectural changes, offering a plug-and-play path to scalable, low-latency distributed inference. Code is provided in the supplementary material.",
    "categories": [
      "cs.DC",
      "cs.AI"
    ],
    "primary_category": "cs.DC",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2511.11608v1",
    "published_date": "2025-11-03 08:44:13 UTC",
    "updated_date": "2025-11-03 08:44:13 UTC"
  },
  {
    "arxiv_id": "2511.01336v1",
    "title": "Beyond Permissions: Investigating Mobile Personalization with Simulated Personas",
    "authors": [
      "Ibrahim Khalilov",
      "Chaoran Chen",
      "Ziang Xiao",
      "Tianshi Li",
      "Toby Jia-Jun Li",
      "Yaxing Yao"
    ],
    "abstract": "Mobile applications increasingly rely on sensor data to infer user context and deliver personalized experiences. Yet the mechanisms behind this personalization remain opaque to users and researchers alike. This paper presents a sandbox system that uses sensor spoofing and persona simulation to audit and visualize how mobile apps respond to inferred behaviors. Rather than treating spoofing as adversarial, we demonstrate its use as a tool for behavioral transparency and user empowerment. Our system injects multi-sensor profiles - generated from structured, lifestyle-based personas - into Android devices in real time, enabling users to observe app responses to contexts such as high activity, location shifts, or time-of-day changes. With automated screenshot capture and GPT-4 Vision-based UI summarization, our pipeline helps document subtle personalization cues. Preliminary findings show measurable app adaptations across fitness, e-commerce, and everyday service apps such as weather and navigation. We offer this toolkit as a foundation for privacy-enhancing technologies and user-facing transparency interventions.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "8 pages, 7 figures. Accepted to the ACM Workshop on Human-Centered AI Privacy and Security (HAIPS @ CCS 2025). DOI: 10.1145/3733816.3760758 (ACM Digital Library link pending activation)",
    "pdf_url": "https://arxiv.org/pdf/2511.01336v1",
    "published_date": "2025-11-03 08:39:38 UTC",
    "updated_date": "2025-11-03 08:39:38 UTC"
  },
  {
    "arxiv_id": "2511.01334v1",
    "title": "Embodied Cognition Augmented End2End Autonomous Driving",
    "authors": [
      "Ling Niu",
      "Xiaoji Zheng",
      "Han Wang",
      "Chen Zheng",
      "Ziyuan Yang",
      "Bokui Chen",
      "Jiangtao Gong"
    ],
    "abstract": "In recent years, vision-based end-to-end autonomous driving has emerged as a new paradigm. However, popular end-to-end approaches typically rely on visual feature extraction networks trained under label supervision. This limited supervision framework restricts the generality and applicability of driving models. In this paper, we propose a novel paradigm termed $E^{3}AD$, which advocates for comparative learning between visual feature extraction networks and the general EEG large model, in order to learn latent human driving cognition for enhancing end-to-end planning. In this work, we collected a cognitive dataset for the mentioned contrastive learning process. Subsequently, we investigated the methods and potential mechanisms for enhancing end-to-end planning with human driving cognition, using popular driving models as baselines on publicly available autonomous driving datasets. Both open-loop and closed-loop tests are conducted for a comprehensive evaluation of planning performance. Experimental results demonstrate that the $E^{3}AD$ paradigm significantly enhances the end-to-end planning performance of baseline models. Ablation studies further validate the contribution of driving cognition and the effectiveness of comparative learning process. To the best of our knowledge, this is the first work to integrate human driving cognition for improving end-to-end autonomous driving planning. It represents an initial attempt to incorporate embodied cognitive data into end-to-end autonomous driving, providing valuable insights for future brain-inspired autonomous driving systems. Our code will be made available at Github",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.RO",
    "comment": "24 pages,4 pages",
    "pdf_url": "https://arxiv.org/pdf/2511.01334v1",
    "published_date": "2025-11-03 08:34:44 UTC",
    "updated_date": "2025-11-03 08:34:44 UTC"
  },
  {
    "arxiv_id": "2511.01329v1",
    "title": "Unbiased Platform-Level Causal Estimation for Search Systems: A Competitive Isolation PSM-DID Framework",
    "authors": [
      "Ying Song",
      "Yijing Wang",
      "Hui Yang",
      "Weihan Jin",
      "Jun Xiong",
      "Congyi Zhou",
      "Jialin Zhu",
      "Xiang Gao",
      "Rong Chen",
      "HuaGuang Deng",
      "Ying Dai",
      "Fei Xiao",
      "Haihong Tang",
      "Bo Zheng",
      "KaiFu Zhang"
    ],
    "abstract": "Evaluating platform-level interventions in search-based two-sided marketplaces is fundamentally challenged by systemic effects such as spillovers and network interference. While widely used for causal inference, the PSM (Propensity Score Matching) - DID (Difference-in-Differences) framework remains susceptible to selection bias and cross-unit interference from unaccounted spillovers. In this paper, we introduced Competitive Isolation PSM-DID, a novel causal framework that integrates propensity score matching with competitive isolation to enable platform-level effect measurement (e.g., order volume, GMV) instead of item-level metrics in search systems.\n  Our approach provides theoretically guaranteed unbiased estimation under mutual exclusion conditions, with an open dataset released to support reproducible research on marketplace interference (github.com/xxxx). Extensive experiments demonstrate significant reductions in interference effects and estimation variance compared to baseline methods. Successful deployment in a large-scale marketplace confirms the framework's practical utility for platform-level causal inference.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2511.01329v1",
    "published_date": "2025-11-03 08:29:21 UTC",
    "updated_date": "2025-11-03 08:29:21 UTC"
  },
  {
    "arxiv_id": "2511.01324v3",
    "title": "AI for Requirements Engineering: Industry adoption and Practitioner perspectives",
    "authors": [
      "Lekshmi Murali Rani",
      "Richard Berntsson Svensson",
      "Robert Feldt"
    ],
    "abstract": "The integration of AI for Requirements Engineering (RE) presents significant benefits but also poses real challenges. Although RE is fundamental to software engineering, limited research has examined AI adoption in RE. We surveyed 55 software practitioners to map AI usage across four RE phases: Elicitation, Analysis, Specification, and Validation, and four approaches for decision making: human-only decisions, AI validation, Human AI Collaboration (HAIC), and full AI automation. Participants also shared their perceptions, challenges, and opportunities when applying AI for RE tasks. Our data show that 58.2% of respondents already use AI in RE, and 69.1% view its impact as positive or very positive. HAIC dominates practice, accounting for 54.4% of all RE techniques, while full AI automation remains minimal at 5.4%. Passive AI validation (4.4 to 6.2%) lags even further behind, indicating that practitioners value AI's active support over passive oversight. These findings suggest that AI is most effective when positioned as a collaborative partner rather than a replacement for human expertise. It also highlights the need for RE-specific HAIC frameworks along with robust and responsible AI governance as AI adoption in RE grows.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.SE",
    "comment": "Accepted at the Intelligent Software Engineering (ISE) 2025 Workshop at the Automated Software Engineering (ASE) 2025 Conference",
    "pdf_url": "https://arxiv.org/pdf/2511.01324v3",
    "published_date": "2025-11-03 08:15:44 UTC",
    "updated_date": "2025-11-05 06:43:39 UTC"
  },
  {
    "arxiv_id": "2511.01323v1",
    "title": "DEEPAMBIGQA: Ambiguous Multi-hop Questions for Benchmarking LLM Answer Completeness",
    "authors": [
      "Jiabao Ji",
      "Min Li",
      "Priyanshu Kumar",
      "Shiyu Chang",
      "Saloni Potdar"
    ],
    "abstract": "Large language models (LLMs) with integrated search tools show strong promise in open-domain question answering (QA), yet they often struggle to produce complete answer set to complex questions such as Which actor from the film Heat won at least one Academy Award?, which requires (1) distinguishing between multiple films sharing the same title and (2) reasoning across a large set of actors to gather and integrate evidence. Existing QA benchmarks rarely evaluate both challenges jointly. To address this, we introduce DeepAmbigQAGen, an automatic data generation pipeline that constructs QA tasks grounded in text corpora and linked knowledge graph, generating natural and verifiable questions that systematically embed name ambiguity and multi-step reasoning. Based on this, we build DeepAmbigQA, a dataset of 3,600 questions requiring multi-hop reasoning and half of them explicit name ambiguity resolving. Experiments reveal that, even state-of-the-art GPT-5 show incomplete answers, achieving only 0.13 exact match on ambiguous questions and 0.21 on non-ambiguous questions. These findings highlight the need for more robust QA systems aimed at information gathering and answer completeness.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "25 pages",
    "pdf_url": "https://arxiv.org/pdf/2511.01323v1",
    "published_date": "2025-11-03 08:15:24 UTC",
    "updated_date": "2025-11-03 08:15:24 UTC"
  },
  {
    "arxiv_id": "2511.01320v1",
    "title": "OmniFuser: Adaptive Multimodal Fusion for Service-Oriented Predictive Maintenance",
    "authors": [
      "Ziqi Wang",
      "Hailiang Zhao",
      "Yuhao Yang",
      "Daojiang Hu",
      "Cheng Bao",
      "Mingyi Liu",
      "Kai Di",
      "Schahram Dustdar",
      "Zhongjie Wang",
      "Shuiguang Deng"
    ],
    "abstract": "Accurate and timely prediction of tool conditions is critical for intelligent manufacturing systems, where unplanned tool failures can lead to quality degradation and production downtime. In modern industrial environments, predictive maintenance is increasingly implemented as an intelligent service that integrates sensing, analysis, and decision support across production processes. To meet the demand for reliable and service-oriented operation, we present OmniFuser, a multimodal learning framework for predictive maintenance of milling tools that leverages both visual and sensor data. It performs parallel feature extraction from high-resolution tool images and cutting-force signals, capturing complementary spatiotemporal patterns across modalities. To effectively integrate heterogeneous features, OmniFuser employs a contamination-free cross-modal fusion mechanism that disentangles shared and modality-specific components, allowing for efficient cross-modal interaction. Furthermore, a recursive refinement pathway functions as an anchor mechanism, consistently retaining residual information to stabilize fusion dynamics. The learned representations can be encapsulated as reusable maintenance service modules, supporting both tool-state classification (e.g., Sharp, Used, Dulled) and multi-step force signal forecasting. Experiments on real-world milling datasets demonstrate that OmniFuser consistently outperforms state-of-the-art baselines, providing a dependable foundation for building intelligent industrial maintenance services.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2511.01320v1",
    "published_date": "2025-11-03 08:08:52 UTC",
    "updated_date": "2025-11-03 08:08:52 UTC"
  },
  {
    "arxiv_id": "2511.01316v1",
    "title": "Exploringand Unleashing the Power of Large Language Models in CI/CD Configuration Translation",
    "authors": [
      "Chong Wang",
      "Chen Zhang",
      "Jiajun Wu",
      "Wunan Guo",
      "Jianfeng Qu",
      "Yewen Tian",
      "Yang Liu"
    ],
    "abstract": "Continuous Integration (CI) is a cornerstone of modern collaborative software development, and numerous CI platforms are available. Differences in maintenance overhead, reliability, and integration depth with code-hosting platforms make migration between CI platforms a common practice. A central step in migration is translating CI configurations, which is challenging due to the intrinsic complexity of CI configurations and the need to understand semantic differences and relationships across CI platforms.\n  With the advent of large language models (LLMs), recent advances in software engineering highlight their potential for CI configuration translation. In this paper, we present a study on LLM-based CI configuration translation, focusing on the migration from Travis CI to GitHub Actions. First, using 811 migration records, we quantify the effort involved and find that developers read an average of 38 lines of Travis configuration and write 58 lines of GitHub Actions configuration, with nearly half of the migrations requiring multiple commits. We further analyze translations produced by each of the four LLMs and identify 1,121 issues grouped into four categories: logic inconsistencies (38%), platform discrepancies (32%), environment errors (25%), and syntax errors (5%). Finally, we evaluate three enhancement strategies and show that combining guideline-based prompting with iterative refinement achieves the best performance, reaching a Build Success Rate of 75.5%-nearly a threefold improvement over GPT-4o with a basic prompt.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2511.01316v1",
    "published_date": "2025-11-03 08:01:09 UTC",
    "updated_date": "2025-11-03 08:01:09 UTC"
  },
  {
    "arxiv_id": "2511.01311v1",
    "title": "llmSHAP: A Principled Approach to LLM Explainability",
    "authors": [
      "Filip Naudot",
      "Tobias Sundqvist",
      "Timotheus Kampik"
    ],
    "abstract": "Feature attribution methods help make machine learning-based inference explainable by determining how much one or several features have contributed to a model's output. A particularly popular attribution method is based on the Shapley value from cooperative game theory, a measure that guarantees the satisfaction of several desirable principles, assuming deterministic inference. We apply the Shapley value to feature attribution in large language model (LLM)-based decision support systems, where inference is, by design, stochastic (non-deterministic). We then demonstrate when we can and cannot guarantee Shapley value principle satisfaction across different implementation variants applied to LLM-based decision support, and analyze how the stochastic nature of LLMs affects these guarantees. We also highlight trade-offs between explainable inference speed, agreement with exact Shapley value attributions, and principle attainment.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2511.01311v1",
    "published_date": "2025-11-03 07:54:47 UTC",
    "updated_date": "2025-11-03 07:54:47 UTC"
  },
  {
    "arxiv_id": "2511.03747v1",
    "title": "OpenMENA: An Open-Source Memristor Interfacing and Compute Board for Neuromorphic Edge-AI Applications",
    "authors": [
      "Ali Safa",
      "Farida Mohsen",
      "Zainab Ali",
      "Bo Wang",
      "Amine Bermak"
    ],
    "abstract": "Memristive crossbars enable in-memory multiply-accumulate and local plasticity learning, offering a path to energy-efficient edge AI. To this end, we present Open-MENA (Open Memristor-in-Memory Accelerator), which, to our knowledge, is the first fully open memristor interfacing system integrating (i) a reproducible hardware interface for memristor crossbars with mixed-signal read-program-verify loops; (ii) a firmware-software stack with high-level APIs for inference and on-device learning; and (iii) a Voltage-Incremental Proportional-Integral (VIPI) method to program pre-trained weights into analog conductances, followed by chip-in-the-loop fine-tuning to mitigate device non-idealities. OpenMENA is validated on digit recognition, demonstrating the flow from weight transfer to on-device adaptation, and on a real-world robot obstacle-avoidance task, where the memristor-based model learns to map localization inputs to motor commands. OpenMENA is released as open source to democratize memristor-enabled edge-AI research.",
    "categories": [
      "cs.ET",
      "cs.AI"
    ],
    "primary_category": "cs.ET",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2511.03747v1",
    "published_date": "2025-11-03 07:43:03 UTC",
    "updated_date": "2025-11-03 07:43:03 UTC"
  },
  {
    "arxiv_id": "2511.01307v1",
    "title": "Perturb a Model, Not an Image: Towards Robust Privacy Protection via Anti-Personalized Diffusion Models",
    "authors": [
      "Tae-Young Lee",
      "Juwon Seo",
      "Jong Hwan Ko",
      "Gyeong-Moon Park"
    ],
    "abstract": "Recent advances in diffusion models have enabled high-quality synthesis of specific subjects, such as identities or objects. This capability, while unlocking new possibilities in content creation, also introduces significant privacy risks, as personalization techniques can be misused by malicious users to generate unauthorized content. Although several studies have attempted to counter this by generating adversarially perturbed samples designed to disrupt personalization, they rely on unrealistic assumptions and become ineffective in the presence of even a few clean images or under simple image transformations. To address these challenges, we shift the protection target from the images to the diffusion model itself to hinder the personalization of specific subjects, through our novel framework called Anti-Personalized Diffusion Models (APDM). We first provide a theoretical analysis demonstrating that a naive approach of existing loss functions to diffusion models is inherently incapable of ensuring convergence for robust anti-personalization. Motivated by this finding, we introduce Direct Protective Optimization (DPO), a novel loss function that effectively disrupts subject personalization in the target model without compromising generative quality. Moreover, we propose a new dual-path optimization strategy, coined Learning to Protect (L2P). By alternating between personalization and protection paths, L2P simulates future personalization trajectories and adaptively reinforces protection at each step. Experimental results demonstrate that our framework outperforms existing methods, achieving state-of-the-art performance in preventing unauthorized personalization. The code is available at https://github.com/KU-VGI/APDM.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "26 pages, 9 figures, 16 tables, NeurIPS 2025",
    "pdf_url": "https://arxiv.org/pdf/2511.01307v1",
    "published_date": "2025-11-03 07:42:05 UTC",
    "updated_date": "2025-11-03 07:42:05 UTC"
  },
  {
    "arxiv_id": "2511.01305v1",
    "title": "DeepSpecs: Expert-Level Questions Answering in 5G",
    "authors": [
      "Aman Ganapathy Manvattira",
      "Yifei Xu",
      "Ziyue Dang",
      "Songwu Lu"
    ],
    "abstract": "5G technology enables mobile Internet access for billions of users. Answering expert-level questions about 5G specifications requires navigating thousands of pages of cross-referenced standards that evolve across releases. Existing retrieval-augmented generation (RAG) frameworks, including telecom-specific approaches, rely on semantic similarity and cannot reliably resolve cross-references or reason about specification evolution. We present DeepSpecs, a RAG system enhanced by structural and temporal reasoning via three metadata-rich databases: SpecDB (clause-aligned specification text), ChangeDB (line-level version diffs), and TDocDB (standardization meeting documents). DeepSpecs explicitly resolves cross-references by recursively retrieving referenced clauses through metadata lookup, and traces specification evolution by mining changes and linking them to Change Requests that document design rationale. We curate two 5G QA datasets: 573 expert-annotated real-world questions from practitioner forums and educational resources, and 350 evolution-focused questions derived from approved Change Requests. Across multiple LLM backends, DeepSpecs outperforms base models and state-of-the-art telecom RAG systems; ablations confirm that explicit cross-reference resolution and evolution-aware retrieval substantially improve answer quality, underscoring the value of modeling the structural and temporal properties of 5G standards.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.NI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2511.01305v1",
    "published_date": "2025-11-03 07:39:22 UTC",
    "updated_date": "2025-11-03 07:39:22 UTC"
  },
  {
    "arxiv_id": "2511.01296v1",
    "title": "LSHFed: Robust and Communication-Efficient Federated Learning with Locally-Sensitive Hashing Gradient Mapping",
    "authors": [
      "Guanjie Cheng",
      "Mengzhen Yang",
      "Xinkui Zhao",
      "Shuyi Yu",
      "Tianyu Du",
      "Yangyang Wu",
      "Mengying Zhu",
      "Shuiguang Deng"
    ],
    "abstract": "Federated learning (FL) enables collaborative model training across distributed nodes without exposing raw data, but its decentralized nature makes it vulnerable in trust-deficient environments. Inference attacks may recover sensitive information from gradient updates, while poisoning attacks can degrade model performance or induce malicious behaviors. Existing defenses often suffer from high communication and computation costs, or limited detection precision. To address these issues, we propose LSHFed, a robust and communication-efficient FL framework that simultaneously enhances aggregation robustness and privacy preservation. At its core, LSHFed incorporates LSHGM, a novel gradient verification mechanism that projects high-dimensional gradients into compact binary representations via multi-hyperplane locally-sensitive hashing. This enables accurate detection and filtering of malicious gradients using only their irreversible hash forms, thus mitigating privacy leakage risks and substantially reducing transmission overhead. Extensive experiments demonstrate that LSHFed maintains high model performance even when up to 50% of participants are collusive adversaries while achieving up to a 1000x reduction in gradient verification communication compared to full-gradient methods.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2511.01296v1",
    "published_date": "2025-11-03 07:28:14 UTC",
    "updated_date": "2025-11-03 07:28:14 UTC"
  },
  {
    "arxiv_id": "2511.01284v1",
    "title": "Adaptation of Foundation Models for Medical Image Analysis: Strategies, Challenges, and Future Directions",
    "authors": [
      "Karma Phuntsho",
      "Abdullah",
      "Kyungmi Lee",
      "Ickjai Lee",
      "Euijoon Ahn"
    ],
    "abstract": "Foundation models (FMs) have emerged as a transformative paradigm in medical image analysis, offering the potential to provide generalizable, task-agnostic solutions across a wide range of clinical tasks and imaging modalities. Their capacity to learn transferable representations from large-scale data has the potential to address the limitations of conventional task-specific models. However, adaptation of FMs to real-world clinical practice remains constrained by key challenges, including domain shifts, limited availability of high-quality annotated data, substantial computational demands, and strict privacy requirements. This review presents a comprehensive assessment of strategies for adapting FMs to the specific demands of medical imaging. We examine approaches such as supervised fine-tuning, domain-specific pretraining, parameter-efficient fine-tuning, self-supervised learning, hybrid methods, and multimodal or cross-modal frameworks. For each, we evaluate reported performance gains, clinical applicability, and limitations, while identifying trade-offs and unresolved challenges that prior reviews have often overlooked. Beyond these established techniques, we also highlight emerging directions aimed at addressing current gaps. These include continual learning to enable dynamic deployment, federated and privacy-preserving approaches to safeguard sensitive data, hybrid self-supervised learning to enhance data efficiency, data-centric pipelines that combine synthetic generation with human-in-the-loop validation, and systematic benchmarking to assess robust generalization under real-world clinical variability. By outlining these strategies and associated research gaps, this review provides a roadmap for developing adaptive, trustworthy, and clinically integrated FMs capable of meeting the demands of real-world medical imaging.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2511.01284v1",
    "published_date": "2025-11-03 06:57:42 UTC",
    "updated_date": "2025-11-03 06:57:42 UTC"
  },
  {
    "arxiv_id": "2511.01282v1",
    "title": "When, What, and How: Rethinking Retrieval-Enhanced Speculative Decoding",
    "authors": [
      "Min Fang",
      "Zhihui Fu",
      "Qibin Zhao",
      "Jun Wang"
    ],
    "abstract": "Speculative decoding (SD) has emerged as an effective technique to accelerate large language model (LLM) inference without compromising output quality. However, the achievable speedup largely depends on the effectiveness of the drafting model. While model-based methods like EAGLE-2 are accurate but costly, retrieval-enhanced methods like SAM-Decoding rely on heuristic switching strategies that often trigger unnecessary retrievals. To address this, we propose ReSpec (\\textbf{Re}trieval-enhanced \\textbf{Spe}culative Decoding), a novel framework that transforms heuristic drafter switching into adaptive decision-making. ReSpec features three core innovations: 1) An \\textbf{entropy-guided adaptive trigger} quantifies contextual predictability to initiate retrieval only when uncertainty is low, avoiding costly low-quality speculations. 2) A \\textbf{feedback-driven candidate selection} leverages historical feedback to organize multiple high-quality candidates for parallel verification, maximizing retrieval utility. 3) A source-aware \\textbf{relaxed verification strategy} applies strict checks to model-generated drafts while using a relaxed verification for retrieved drafts, achieving a better balance between accuracy and efficiency. Extensive experiments on Spec-Bench demonstrate that ReSpec achieves state-of-the-art acceleration,outperforming EAGLE-2 and SAM-Decoding by over $33\\%$ and $25\\%$, respectively, while maintaining output quality.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2511.01282v1",
    "published_date": "2025-11-03 06:57:16 UTC",
    "updated_date": "2025-11-03 06:57:16 UTC"
  },
  {
    "arxiv_id": "2511.01275v1",
    "title": "Adversarial Spatio-Temporal Attention Networks for Epileptic Seizure Forecasting",
    "authors": [
      "Zan Li",
      "Kyongmin Yeo",
      "Wesley Gifford",
      "Lara Marcuse",
      "Madeline Fields",
      "Bülent Yener"
    ],
    "abstract": "Forecasting epileptic seizures from multivariate EEG signals represents a critical challenge in healthcare time series prediction, requiring high sensitivity, low false alarm rates, and subject-specific adaptability. We present STAN, an Adversarial Spatio-Temporal Attention Network that jointly models spatial brain connectivity and temporal neural dynamics through cascaded attention blocks with alternating spatial and temporal modules. Unlike existing approaches that assume fixed preictal durations or separately process spatial and temporal features, STAN captures bidirectional dependencies between spatial and temporal patterns through a unified cascaded architecture. Adversarial training with gradient penalty enables robust discrimination between interictal and preictal states learned from clearly defined 15-minute preictal windows. Continuous 90-minute pre-seizure monitoring reveals that the learned spatio-temporal attention patterns enable early detection: reliable alarms trigger at subject-specific times (typically 15-45 minutes before onset), reflecting the model's capacity to capture subtle preictal dynamics without requiring individualized training. Experiments on two benchmark EEG datasets (CHB-MIT scalp: 8 subjects, 46 events; MSSM intracranial: 4 subjects, 14 events) demonstrate state-of-the-art performance: 96.6% sensitivity with 0.011 false detections per hour and 94.2% sensitivity with 0.063 false detections per hour, respectively, while maintaining computational efficiency (2.3M parameters, 45 ms latency, 180 MB memory) for real-time edge deployment. Beyond epilepsy, the proposed framework provides a general paradigm for spatio-temporal forecasting in healthcare and other time series domains where individual heterogeneity and interpretability are crucial.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2511.01275v1",
    "published_date": "2025-11-03 06:48:54 UTC",
    "updated_date": "2025-11-03 06:48:54 UTC"
  },
  {
    "arxiv_id": "2511.01268v1",
    "title": "Rescuing the Unpoisoned: Efficient Defense against Knowledge Corruption Attacks on RAG Systems",
    "authors": [
      "Minseok Kim",
      "Hankook Lee",
      "Hyungjoon Koo"
    ],
    "abstract": "Large language models (LLMs) are reshaping numerous facets of our daily lives, leading widespread adoption as web-based services. Despite their versatility, LLMs face notable challenges, such as generating hallucinated content and lacking access to up-to-date information. Lately, to address such limitations, Retrieval-Augmented Generation (RAG) has emerged as a promising direction by generating responses grounded in external knowledge sources. A typical RAG system consists of i) a retriever that probes a group of relevant passages from a knowledge base and ii) a generator that formulates a response based on the retrieved content. However, as with other AI systems, recent studies demonstrate the vulnerability of RAG, such as knowledge corruption attacks by injecting misleading information. In response, several defense strategies have been proposed, including having LLMs inspect the retrieved passages individually or fine-tuning robust retrievers. While effective, such approaches often come with substantial computational costs.\n  In this work, we introduce RAGDefender, a resource-efficient defense mechanism against knowledge corruption (i.e., by data poisoning) attacks in practical RAG deployments. RAGDefender operates during the post-retrieval phase, leveraging lightweight machine learning techniques to detect and filter out adversarial content without requiring additional model training or inference. Our empirical evaluations show that RAGDefender consistently outperforms existing state-of-the-art defenses across multiple models and adversarial scenarios: e.g., RAGDefender reduces the attack success rate (ASR) against the Gemini model from 0.89 to as low as 0.02, compared to 0.69 for RobustRAG and 0.24 for Discern-and-Answer when adversarial passages outnumber legitimate ones by a factor of four (4x).",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.CR",
    "comment": "15 pages, 7 figures, 10 tables. To appear in the Proceedings of the 2025 Annual Computer Security Applications Conference (ACSAC)",
    "pdf_url": "https://arxiv.org/pdf/2511.01268v1",
    "published_date": "2025-11-03 06:39:58 UTC",
    "updated_date": "2025-11-03 06:39:58 UTC"
  },
  {
    "arxiv_id": "2511.01261v1",
    "title": "Speech-DRAME: A Framework for Human-Aligned Benchmarks in Speech Role-Play",
    "authors": [
      "Jiatong Shi",
      "Jionghao Han",
      "Yichen Lu",
      "Santiago Pascual",
      "Pengfei Wu",
      "Chenye Cui",
      "Shinji Watanabe",
      "Chao Weng",
      "Cong Zhou"
    ],
    "abstract": "Role-play has become a key testbed for generative models, expanding from text-only dialogue to multimodal interaction. Extending role-play to speech captures prosody, emotion, and delivery, but also poses new evaluation challenges. Current pipelines often use audio large language models (ALLMs) as zero-shot judges, which miss paralinguistic cues, collapse multiple aspects into coarse scores, and rely on synthetic speech references that fail to reflect real-world roles. We present Speech-DRAME, a unified framework that contributes at three levels: (i) Speech-DRAME-EvalBench, an evaluation benchmark with bilingual human-annotated data and protocols for training and testing speech evaluation models (SEMs), (ii) DRAME-Eval, a fine-tuned evaluation model, which substantially outperforms zero-shot and few-shot ALLMs, and (iii) Speech-DRAME-RoleBench, a speech role-play benchmark that leverages DRAME-Eval as an automatic judge to compare speech foundation models (SFMs). Speech-DRAME distinguishes between two complementary evaluation strategies: Archetype Evaluation, a top-down approach measuring adherence to broad role archetypes, and Realism Evaluation, a bottom-up approach grounded in real human speech that emphasizes nuanced role quality. Compared to zero-shot ALLM judges, DRAME-Eval achieves stronger agreement with human ratings (Pearson correlation from 0.480 to 0.629 in archetypes, and 0.390 to 0.625 in realism). By integrating transparent benchmark resources, modeling approaches, and system-level evaluation, Speech-DRAME provides the first comprehensive, reproducible foundation for assessing spoken role-play.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "67 pages",
    "pdf_url": "https://arxiv.org/pdf/2511.01261v1",
    "published_date": "2025-11-03 06:12:40 UTC",
    "updated_date": "2025-11-03 06:12:40 UTC"
  },
  {
    "arxiv_id": "2511.01258v1",
    "title": "Graph Neural Network-Based Semi-Supervised Open-Set Fault Diagnosis for Marine Machinery Systems",
    "authors": [
      "Chuyue Lou",
      "M. Amine Atoui"
    ],
    "abstract": "Recently, fault diagnosis methods for marine machinery systems based on deep learning models have attracted considerable attention in the shipping industry. Most existing studies assume fault classes are consistent and known between the training and test datasets, and these methods perform well under controlled environment. In practice, however, previously unseen or unknown fault types (i.e., out-of-distribution or open-set observations not present during training) can occur, causing such methods to fail and posing a significant challenge to their widespread industrial deployment. To address this challenge, this paper proposes a semi-supervised open-set fault diagnosis (SOFD) framework that enhances and extends the applicability of deep learning models in open-set fault diagnosis scenarios. The framework includes a reliability subset construction process, which uses a multi-layer fusion feature representation extracted by a supervised feature learning model to select an unlabeled test subset. The labeled training set and pseudo-labeled test subset are then fed into a semi-supervised diagnosis model to learn discriminative features for each class, enabling accurate classification of known faults and effective detection of unknown samples. Experimental results on a public maritime benchmark dataset demonstrate the effectiveness and superiority of the proposed SOFD framework.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2511.01258v1",
    "published_date": "2025-11-03 06:06:25 UTC",
    "updated_date": "2025-11-03 06:06:25 UTC"
  },
  {
    "arxiv_id": "2511.01941v1",
    "title": "Detecting Vulnerabilities from Issue Reports for Internet-of-Things",
    "authors": [
      "Sogol Masoumzadeh"
    ],
    "abstract": "Timely identification of issue reports reflecting software vulnerabilities is crucial, particularly for Internet-of-Things (IoT) where analysis is slower than non-IoT systems. While Machine Learning (ML) and Large Language Models (LLMs) detect vulnerability-indicating issues in non-IoT systems, their IoT use remains unexplored. We are the first to tackle this problem by proposing two approaches: (1) combining ML and LLMs with Natural Language Processing (NLP) techniques to detect vulnerability-indicating issues of 21 Eclipse IoT projects and (2) fine-tuning a pre-trained BERT Masked Language Model (MLM) on 11,000 GitHub issues for classifying \\vul. Our best performance belongs to a Support Vector Machine (SVM) trained on BERT NLP features, achieving an Area Under the receiver operator characteristic Curve (AUC) of 0.65. The fine-tuned BERT achieves 0.26 accuracy, emphasizing the importance of exposing all data during training. Our contributions set the stage for accurately detecting IoT vulnerabilities from issue reports, similar to non-IoT systems.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.SE",
    "comment": "ACCEPTED/To Appear in the Proceedings of the 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) 2025. https://conf.researchr.org/details/ase-2025/ase-2025-student-research-competition/5/Detecting-Vulnerabilities-from-Issue-Reports-for-Internet-of-Things",
    "pdf_url": "https://arxiv.org/pdf/2511.01941v1",
    "published_date": "2025-11-03 05:59:34 UTC",
    "updated_date": "2025-11-03 05:59:34 UTC"
  },
  {
    "arxiv_id": "2511.01253v1",
    "title": "Quantum Deep Learning Still Needs a Quantum Leap",
    "authors": [
      "Hans Gundlach",
      "Hrvoje Kukina",
      "Jayson Lynch",
      "Neil Thompson"
    ],
    "abstract": "Quantum computing technology is advancing rapidly. Yet, even accounting for these trends, a quantum leap would be needed for quantum computers to meaningfully impact deep learning over the coming decade or two. We arrive at this conclusion based on a first-of-its-kind survey of quantum algorithms and how they match potential deep learning applications. This survey reveals three important areas where quantum computing could potentially accelerate deep learning, each of which faces a challenging roadblock to realizing its potential. First, quantum algorithms for matrix multiplication and other algorithms central to deep learning offer small theoretical improvements in the number of operations needed, but this advantage is overwhelmed on practical problem sizes by how slowly quantum computers do each operation. Second, some promising quantum algorithms depend on practical Quantum Random Access Memory (QRAM), which is underdeveloped. Finally, there are quantum algorithms that offer large theoretical advantages, but which are only applicable to special cases, limiting their practical benefits. In each of these areas, we support our arguments using quantitative forecasts of quantum advantage that build on the work by Choi et al. [2023] as well as new research on limitations and quantum hardware trends. Our analysis outlines the current scope of quantum deep learning and points to research directions that could lead to greater practical advances in the field.",
    "categories": [
      "quant-ph",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "quant-ph",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2511.01253v1",
    "published_date": "2025-11-03 05:49:49 UTC",
    "updated_date": "2025-11-03 05:49:49 UTC"
  },
  {
    "arxiv_id": "2511.01237v1",
    "title": "Eyes on Target: Gaze-Aware Object Detection in Egocentric Video",
    "authors": [
      "Vishakha Lall",
      "Yisi Liu"
    ],
    "abstract": "Human gaze offers rich supervisory signals for understanding visual attention in complex visual environments. In this paper, we propose Eyes on Target, a novel depth-aware and gaze-guided object detection framework designed for egocentric videos. Our approach injects gaze-derived features into the attention mechanism of a Vision Transformer (ViT), effectively biasing spatial feature selection toward human-attended regions. Unlike traditional object detectors that treat all regions equally, our method emphasises viewer-prioritised areas to enhance object detection. We validate our method on an egocentric simulator dataset where human visual attention is critical for task assessment, illustrating its potential in evaluating human performance in simulation scenarios. We evaluate the effectiveness of our gaze-integrated model through extensive experiments and ablation studies, demonstrating consistent gains in detection accuracy over gaze-agnostic baselines on both the custom simulator dataset and public benchmarks, including Ego4D Ego-Motion and Ego-CH-Gaze datasets. To interpret model behaviour, we also introduce a gaze-aware attention head importance metric, revealing how gaze cues modulate transformer attention dynamics.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted at RAAI 2025",
    "pdf_url": "https://arxiv.org/pdf/2511.01237v1",
    "published_date": "2025-11-03 05:21:58 UTC",
    "updated_date": "2025-11-03 05:21:58 UTC"
  },
  {
    "arxiv_id": "2511.01228v2",
    "title": "Importance Ranking in Complex Networks via Influence-aware Causal Node Embedding",
    "authors": [
      "Jiahui Gao",
      "Kuang Zhou",
      "Yuchen Zhu",
      "Keyu Wu"
    ],
    "abstract": "Understanding and quantifying node importance is a fundamental problem in network science and engineering, underpinning a wide range of applications such as influence maximization, social recommendation, and network dismantling. Prior research often relies on centrality measures or advanced graph embedding techniques using structural information, followed by downstream classification or regression tasks to identify critical nodes. However, these methods typically decouple node representation learning from the ranking objective and rely on the topological structure of target networks, leading to feature-task inconsistency and limited generalization across networks. This paper proposes a novel framework that leverages causal representation learning to get robust, invariant node embeddings for cross-network ranking tasks. Firstly, we introduce an influence-aware causal node embedding module within an autoencoder architecture to extract node embeddings that are causally related to node importance. Moreover, we introduce a causal ranking loss and design a unified optimization framework that jointly optimizes the reconstruction and ranking objectives, enabling mutual reinforcement between node representation learning and ranking optimization. This design allows the proposed model to be trained on synthetic networks and to generalize effectively across diverse real-world networks. Extensive experiments on multiple benchmark datasets demonstrate that the proposed model consistently outperforms state-of-the-art baselines in terms of both ranking accuracy and cross-network transferability, offering new insights for network analysis and engineering applications-particularly in scenarios where the target network's structure is inaccessible in advance due to privacy or security constraints.",
    "categories": [
      "cs.SI",
      "cs.AI"
    ],
    "primary_category": "cs.SI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2511.01228v2",
    "published_date": "2025-11-03 05:01:22 UTC",
    "updated_date": "2025-11-19 13:46:16 UTC"
  },
  {
    "arxiv_id": "2511.01213v1",
    "title": "Thought-For-Food: Reasoning Chain Induced Food Visual Question Answering",
    "authors": [
      "Riddhi Jain",
      "Manasi Patwardhan",
      "Parijat Deshpande",
      "Venkataramana Runkana"
    ],
    "abstract": "The immense diversity in the culture and culinary of Indian cuisines calls attention to the major shortcoming of the existing Visual Question Answering(VQA) systems which are inclined towards the foods from Western region. Recent attempt towards building a VQA dataset for Indian food is a step towards addressing this challenge. However, their approach towards VQA follows a two-step process in which the answer is generated first, followed by the explanation of the expected answer. In this work, we claim that food VQA requires to follow a multi-step reasoning process to arrive at an accurate answer, especially in the context of India food, which involves understanding complex culinary context and identifying relationships between various food items. With this hypothesis we create reasoning chains upon the QA with minimal human intervention. We fine-tune smaller LLMs and VLMs with auto-validated reasoning chains and further train them using reinforcement learning with larger data. With augmentation of reasoning chains, we observed accuracy improvement of an average 10 percentage points on the baseline. We provide detailed analysis in terms the effect of addition of reasoning chains for the Indian Food VQA task.\n  Index Terms - FoodVQA, Reasoning Chains, Reinforcement Learning, Knowledge Graph.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "10 pages, 11 figures, 6 tables",
    "pdf_url": "https://arxiv.org/pdf/2511.01213v1",
    "published_date": "2025-11-03 04:13:24 UTC",
    "updated_date": "2025-11-03 04:13:24 UTC"
  },
  {
    "arxiv_id": "2511.01202v2",
    "title": "Forget BIT, It is All about TOKEN: Towards Semantic Information Theory for LLMs",
    "authors": [
      "Bo Bai"
    ],
    "abstract": "Large language models (LLMs) have demonstrated remarkable capabilities in numerous real-world applications. While the vast majority of research conducted from an experimental perspective is progressing rapidly, it demands substantial computational power, data, and other resources. Therefore, how to open the black-box of LLMs from a theoretical standpoint has become a critical challenge. This paper takes the theory of rate-distortion function, directed information, and Granger causality as its starting point to investigate the information-theoretic principles behind LLMs, leading to the development of semantic information theory for LLMs, where the fundamental unit is token, rather than bits that lacks any semantic meaning. By defining the probabilistic model of LLMs, we discuss structure-agnostic information-theoretic measures, such as the directed rate-distortion function in pre-training, the directed rate-reward function in post-training, and the semantic information flow in inference phase. This paper also delves deeply into the theory of token-level semantic embedding and the information-theoretically optimal vectorization method. Thereafter, we propose a general definition of autoregression LLM, where the Transformer architecture and its performance such as ELBO, generalization error bound, memory capacity, and semantic information measures can be derived theoretically. Other architectures, such as Mamba/Mamba2 and LLaDA, are also discussed in our framework. Consequently, this paper provides a theoretical framework for understanding LLMs from the perspective of semantic information theory, which also offers the necessary theoretical tools for further in-depth research.",
    "categories": [
      "cs.IT",
      "cs.AI"
    ],
    "primary_category": "cs.IT",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2511.01202v2",
    "published_date": "2025-11-03 03:56:34 UTC",
    "updated_date": "2026-01-12 04:35:10 UTC"
  },
  {
    "arxiv_id": "2511.01196v2",
    "title": "An Interdisciplinary and Cross-Task Review on Missing Data Imputation",
    "authors": [
      "Jicong Fan"
    ],
    "abstract": "Missing data is a fundamental challenge in data science, significantly hindering analysis and decision-making across a wide range of disciplines, including healthcare, bioinformatics, social science, e-commerce, and industrial monitoring. Despite decades of research and numerous imputation methods, the literature remains fragmented across fields, creating a critical need for a comprehensive synthesis that connects statistical foundations with modern machine learning advances. This work systematically reviews core concepts-including missingness mechanisms, single versus multiple imputation, and different imputation goals-and examines problem characteristics across various domains. It provides a thorough categorization of imputation methods, spanning classical techniques (e.g., regression, the EM algorithm) to modern approaches like low-rank and high-rank matrix completion, deep learning models (autoencoders, GANs, diffusion models, graph neural networks), and large language models. Special attention is given to methods for complex data types, such as tensors, time series, streaming data, graph-structured data, categorical data, and multimodal data. Beyond methodology, we investigate the crucial integration of imputation with downstream tasks like classification, clustering, and anomaly detection, examining both sequential pipelines and joint optimization frameworks. The review also assesses theoretical guarantees, benchmarking resources, and evaluation metrics. Finally, we identify critical challenges and future directions, emphasizing model selection and hyperparameter optimization, the growing importance of privacy-preserving imputation via federated learning, and the pursuit of generalizable models that can adapt across domains and data types, thereby outlining a roadmap for future research.",
    "categories": [
      "stat.ML",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "stat.ML",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2511.01196v2",
    "published_date": "2025-11-03 03:43:43 UTC",
    "updated_date": "2025-12-01 02:05:28 UTC"
  },
  {
    "arxiv_id": "2511.01194v1",
    "title": "A Topology-Aware Graph Convolutional Network for Human Pose Similarity and Action Quality Assessment",
    "authors": [
      "Minmin Zeng"
    ],
    "abstract": "Action Quality Assessment (AQA) requires fine-grained understanding of human motion and precise evaluation of pose similarity. This paper proposes a topology-aware Graph Convolutional Network (GCN) framework, termed GCN-PSN, which models the human skeleton as a graph to learn discriminative, topology-sensitive pose embeddings. Using a Siamese architecture trained with a contrastive regression objective, our method outperforms coordinate-based baselines and achieves competitive performance on AQA-7 and FineDiving benchmarks. Experimental results and ablation studies validate the effectiveness of leveraging skeletal topology for pose similarity and action quality assessment.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "10 pages, 5 figures. Submitted as a computer vision paper in the cs.CV category",
    "pdf_url": "https://arxiv.org/pdf/2511.01194v1",
    "published_date": "2025-11-03 03:38:24 UTC",
    "updated_date": "2025-11-03 03:38:24 UTC"
  },
  {
    "arxiv_id": "2511.01191v1",
    "title": "Self-Harmony: Learning to Harmonize Self-Supervision and Self-Play in Test-Time Reinforcement Learning",
    "authors": [
      "Ru Wang",
      "Wei Huang",
      "Qi Cao",
      "Yusuke Iwasawa",
      "Yutaka Matsuo",
      "Jiaxian Guo"
    ],
    "abstract": "Test-time reinforcement learning (TTRL) offers a label-free paradigm for adapting models using only synthetic signals at inference, but its success hinges on constructing reliable learning signals. Standard approaches such as majority voting often collapse to spurious yet popular answers. We introduce Self-Harmony, a framework built on a simple intuition: the correct answer should remain stable across both an original question and its paraphrase. Self-Harmony operationalizes this by employing a single model in two complementary roles: a Solver to produce answers and a Reframer to rephrase the input. Based on this, we further propose a pseudo-label method: instead of majority voting, it aggregates answer frequencies across these original and reframed views using the harmonic mean. This is a process that naturally selects for solutions stable under reframing, thereby avoiding the common trap of favoring view-dependent, spurious answers. Crucially, this requires no human supervision or auxiliary models. Across diverse reasoning benchmarks, Self-Harmony achieves state-of-the-art results at the label-free test-time setting, ranking first in 28 of 30 settings across multiple methods. Beyond accuracy, it demonstrates unprecedented robustness, with zero training failures in all experiments, underscoring its stability and reliability.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2511.01191v1",
    "published_date": "2025-11-03 03:34:34 UTC",
    "updated_date": "2025-11-03 03:34:34 UTC"
  },
  {
    "arxiv_id": "2511.01188v1",
    "title": "ZoFia: Zero-Shot Fake News Detection with Entity-Guided Retrieval and Multi-LLM Interaction",
    "authors": [
      "Lvhua Wu",
      "Xuefeng Jiang",
      "Sheng Sun",
      "Tian Wen",
      "Yuwei Wang",
      "Min Liu"
    ],
    "abstract": "The rapid spread of fake news threatens social stability and public trust, rendering its detection an imperative research priority. Although large language models (LLMs) excel at numerous natural language processing tasks with their remarkable contextual understanding and extensive prior knowledge, the time-bounded knowledge coverage and tendency for generating hallucination content reduce their reliability when handling fast-evolving news streams. Furthermore, models trained on existing static datasets also often lack the generalization needed for emerging news topics. To address these challenges, we propose ZoFia, a novel two-stage zero-shot fake news detection framework. First, we introduce Hierarchical Salience to quantify the importance of entities in the news content, and propose the SC-MMR algorithm to effectively select an informative and diverse set of keywords that serve as queries for retrieving up-to-date external evidence. Subsequently, a multi LLM interactive system, in which each agent assumes a distinct role, performs multi-view collaborative analysis and adversarial debate over the news text and its related information, and finally produces an interpretable and robust judgment. Comprehensive experiments on two public datasets demonstrate that ZoFia obviously outperforms existing zero-shot baselines and most of few-shot methods. Our codes will be open-sourced to facilitate related communities.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2511.01188v1",
    "published_date": "2025-11-03 03:29:42 UTC",
    "updated_date": "2025-11-03 03:29:42 UTC"
  },
  {
    "arxiv_id": "2511.01183v1",
    "title": "QiMeng-NeuComBack: Self-Evolving Translation from IR to Assembly Code",
    "authors": [
      "Hainan Fang",
      "Yuanbo Wen",
      "Jun Bi",
      "Yihan Wang",
      "Tonghui He",
      "Yanlin Tang",
      "Di Huang",
      "Jiaming Guo",
      "Rui Zhang",
      "Qi Guo",
      "Yunji Chen"
    ],
    "abstract": "Compilers, while essential, are notoriously complex systems that demand prohibitively expensive human expertise to develop and maintain. The recent advancements in Large Language Models (LLMs) offer a compelling new paradigm: Neural Compilation, which could potentially simplify compiler development for new architectures and facilitate the discovery of innovative optimization techniques. However, several critical obstacles impede its practical adoption. Firstly, a significant lack of dedicated benchmarks and robust evaluation methodologies hinders objective assessment and tracking of progress in the field. Secondly, systematically enhancing the reliability and performance of LLM-generated assembly remains a critical challenge. Addressing these challenges, this paper introduces NeuComBack, a novel benchmark dataset specifically designed for IR-to-assembly compilation. Leveraging this dataset, we first define a foundational Neural Compilation workflow and conduct a comprehensive evaluation of the capabilities of recent frontier LLMs on Neural Compilation, establishing new performance baselines. We further propose a self-evolving prompt optimization method that enables LLMs to iteratively evolve their internal prompt strategies by extracting insights from prior self-debugging traces, thereby enhancing their neural compilation capabilities. Experiments demonstrate that our method significantly improves both the functional correctness and the performance of LLM-generated assembly code. Compared to baseline prompts, the functional correctness rates improved from 44% to 64% on x86_64 and from 36% to 58% on aarch64, respectively. More significantly, among the 16 correctly generated x86_64 programs using our method, 14 (87.5%) surpassed clang-O3 performance.",
    "categories": [
      "cs.AI",
      "cs.PL"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted at NeurIPS 2025",
    "pdf_url": "https://arxiv.org/pdf/2511.01183v1",
    "published_date": "2025-11-03 03:20:26 UTC",
    "updated_date": "2025-11-03 03:20:26 UTC"
  },
  {
    "arxiv_id": "2511.01182v1",
    "title": "MiRAGE: Misconception Detection with Retrieval-Guided Multi-Stage Reasoning and Ensemble Fusion",
    "authors": [
      "Cuong Van Duc",
      "Thai Tran Quoc",
      "Minh Nguyen Dinh Tuan",
      "Tam Vu Duc",
      "Son Nguyen Van",
      "Hanh Nguyen Thi"
    ],
    "abstract": "Detecting student misconceptions in open-ended responses is a longstanding challenge, demanding semantic precision and logical reasoning. We propose MiRAGE - Misconception Detection with Retrieval-Guided Multi-Stage Reasoning and Ensemble Fusion, a novel framework for automated misconception detection in mathematics. MiRAGE operates in three stages: (1) a Retrieval module narrows a large candidate pool to a semantically relevant subset; (2) a Reasoning module employs chain-of-thought generation to expose logical inconsistencies in student solutions; and (3) a Reranking module refines predictions by aligning them with the reasoning. These components are unified through an ensemble-fusion strategy that enhances robustness and interpretability. On mathematics datasets, MiRAGE achieves Mean Average Precision scores of 0.82/0.92/0.93 at levels 1/3/5, consistently outperforming individual modules. By coupling retrieval guidance with multi-stage reasoning, MiRAGE reduces dependence on large-scale language models while delivering a scalable and effective solution for educational assessment.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2511.01182v1",
    "published_date": "2025-11-03 03:17:36 UTC",
    "updated_date": "2025-11-03 03:17:36 UTC"
  },
  {
    "arxiv_id": "2511.01172v1",
    "title": "Adapt under Attack and Domain Shift: Unified Adversarial Meta-Learning and Domain Adaptation for Robust Automatic Modulation Classification",
    "authors": [
      "Ali Owfi",
      "Amirmohammad Bamdad",
      "Tolunay Seyfi",
      "Fatemeh Afghah"
    ],
    "abstract": "Deep learning has emerged as a leading approach for Automatic Modulation Classification (AMC), demonstrating superior performance over traditional methods. However, vulnerability to adversarial attacks and susceptibility to data distribution shifts hinder their practical deployment in real-world, dynamic environments. To address these threats, we propose a novel, unified framework that integrates meta-learning with domain adaptation, making AMC systems resistant to both adversarial attacks and environmental changes. Our framework utilizes a two-phase strategy. First, in an offline phase, we employ a meta-learning approach to train the model on clean and adversarially perturbed samples from a single source domain. This method enables the model to generalize its defense, making it resistant to a combination of previously unseen attacks. Subsequently, in the online phase, we apply domain adaptation to align the model's features with a new target domain, allowing it to adapt without requiring substantial labeled data. As a result, our framework achieves a significant improvement in modulation classification accuracy against these combined threats, offering a critical solution to the deployment and operational challenges of modern AMC systems.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "eess.SP"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2511.01172v1",
    "published_date": "2025-11-03 02:44:53 UTC",
    "updated_date": "2025-11-03 02:44:53 UTC"
  },
  {
    "arxiv_id": "2511.01170v2",
    "title": "DART: Difficulty-Adaptive Reasoning Truncation for Efficient Large Language Models",
    "authors": [
      "Ruofan Zhang",
      "Bin Xia",
      "Zhen Cheng",
      "Cairen Jian",
      "Minglun Yang",
      "Ngai Wong",
      "Yuan Cheng"
    ],
    "abstract": "Adaptive reasoning is essential for aligning the computational effort of large language models (LLMs) with the intrinsic difficulty of problems. Current chain-of-thought methods boost reasoning ability but indiscriminately generate long explanations, leading to evident inefficiency. However, existing reinforcement learning approaches to adaptive thinking remain unstable and heavily reward-dependent. Here we propose \\textbf{DART}, a supervised \\textbf{D}ifficulty-\\textbf{A}daptive \\textbf{R}easoning \\textbf{T}runcation framework that adjusts thinking length according to problem difficulty. By distilling concise reasoning patterns from stronger models, interpolating them into a continuum of reasoning styles, and curating optimal training data that balances correctness and compactness, DART learns when to ``stop thinking''. Across multiple mathematical benchmarks, experimental results demonstrate its remarkable efficiency while preserving or improving accuracy, achieving a significant 81.2\\% reasoning truncation (DeepSeek-R1-Distill-Qwen-7B on GSM8K dataset) with 5.33$\\times$ computational acceleration. DART provides a stable and general paradigm for efficient reasoning, advancing the development of adaptive intelligence in LLMs.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2511.01170v2",
    "published_date": "2025-11-03 02:41:20 UTC",
    "updated_date": "2025-12-16 12:09:10 UTC"
  },
  {
    "arxiv_id": "2511.01158v1",
    "title": "A High-Throughput Spiking Neural Network Processor Enabling Synaptic Delay Emulation",
    "authors": [
      "Faquan Chen",
      "Qingyang Tian",
      "Ziren Wu",
      "Rendong Ying",
      "Fei Wen",
      "Peilin Liu"
    ],
    "abstract": "Synaptic delay has attracted significant attention in neural network dynamics for integrating and processing complex spatiotemporal information. This paper introduces a high-throughput Spiking Neural Network (SNN) processor that supports synaptic delay-based emulation for edge applications. The processor leverages a multicore pipelined architecture with parallel compute engines, capable of real-time processing of the computational load associated with synaptic delays. We develop a SoC prototype of the proposed processor on PYNQ Z2 FPGA platform and evaluate its performance using the Spiking Heidelberg Digits (SHD) benchmark for low-power keyword spotting tasks. The processor achieves 93.4% accuracy in deployment and an average throughput of 104 samples/sec at a typical operating frequency of 125 MHz and 282 mW power consumption.",
    "categories": [
      "cs.NE",
      "cs.AI"
    ],
    "primary_category": "cs.NE",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2511.01158v1",
    "published_date": "2025-11-03 02:12:44 UTC",
    "updated_date": "2025-11-03 02:12:44 UTC"
  },
  {
    "arxiv_id": "2511.01149v1",
    "title": "Modular Task Decomposition and Dynamic Collaboration in Multi-Agent Systems Driven by Large Language Models",
    "authors": [
      "Shuaidong Pan",
      "Di Wu"
    ],
    "abstract": "This paper addresses the limitations of a single agent in task decomposition and collaboration during complex task execution, and proposes a multi-agent architecture for modular task decomposition and dynamic collaboration based on large language models. The method first converts natural language task descriptions into unified semantic representations through a large language model. On this basis, a modular decomposition mechanism is introduced to break down the overall goal into multiple hierarchical sub-tasks. Then, dynamic scheduling and routing mechanisms enable reasonable division of labor and realtime collaboration among agents, allowing the system to adjust strategies continuously according to environmental feedback, thus maintaining efficiency and stability in complex tasks. Furthermore, a constraint parsing and global consistency mechanism is designed to ensure coherent connections between sub-tasks and balanced workload, preventing performance degradation caused by redundant communication or uneven resource allocation. The experiments validate the architecture across multiple dimensions, including task success rate, decomposition efficiency, sub-task coverage, and collaboration balance. The results show that the proposed method outperforms existing approaches in both overall performance and robustness, achieving a better balance between task complexity and communication overhead. In conclusion, this study demonstrates the effectiveness and feasibility of language-driven task decomposition and dynamic collaboration in multi-agent systems, providing a systematic solution for task execution in complex environments.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2511.01149v1",
    "published_date": "2025-11-03 02:00:06 UTC",
    "updated_date": "2025-11-03 02:00:06 UTC"
  },
  {
    "arxiv_id": "2511.01144v1",
    "title": "AthenaBench: A Dynamic Benchmark for Evaluating LLMs in Cyber Threat Intelligence",
    "authors": [
      "Md Tanvirul Alam",
      "Dipkamal Bhusal",
      "Salman Ahmad",
      "Nidhi Rastogi",
      "Peter Worth"
    ],
    "abstract": "Large Language Models (LLMs) have demonstrated strong capabilities in natural language reasoning, yet their application to Cyber Threat Intelligence (CTI) remains limited. CTI analysis involves distilling large volumes of unstructured reports into actionable knowledge, a process where LLMs could substantially reduce analyst workload. CTIBench introduced a comprehensive benchmark for evaluating LLMs across multiple CTI tasks. In this work, we extend CTIBench by developing AthenaBench, an enhanced benchmark that includes an improved dataset creation pipeline, duplicate removal, refined evaluation metrics, and a new task focused on risk mitigation strategies. We evaluate twelve LLMs, including state-of-the-art proprietary models such as GPT-5 and Gemini-2.5 Pro, alongside seven open-source models from the LLaMA and Qwen families. While proprietary LLMs achieve stronger results overall, their performance remains subpar on reasoning-intensive tasks, such as threat actor attribution and risk mitigation, with open-source models trailing even further behind. These findings highlight fundamental limitations in the reasoning capabilities of current LLMs and underscore the need for models explicitly tailored to CTI workflows and automation.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2511.01144v1",
    "published_date": "2025-11-03 01:45:29 UTC",
    "updated_date": "2025-11-03 01:45:29 UTC"
  },
  {
    "arxiv_id": "2511.01143v1",
    "title": "MicroAUNet: Boundary-Enhanced Multi-scale Fusion with Knowledge Distillation for Colonoscopy Polyp Image Segmentation",
    "authors": [
      "Ziyi Wang",
      "Yuanmei Zhang",
      "Dorna Esrafilzadeh",
      "Ali R. Jalili",
      "Suncheng Xiang"
    ],
    "abstract": "Early and accurate segmentation of colorectal polyps is critical for reducing colorectal cancer mortality, which has been extensively explored by academia and industry. However, current deep learning-based polyp segmentation models either compromise clinical decision-making by providing ambiguous polyp margins in segmentation outputs or rely on heavy architectures with high computational complexity, resulting in insufficient inference speeds for real-time colorectal endoscopic applications. To address this problem, we propose MicroAUNet, a light-weighted attention-based segmentation network that combines depthwise-separable dilated convolutions with a single-path, parameter-shared channel-spatial attention block to strengthen multi-scale boundary features. On the basis of it, a progressive two-stage knowledge-distillation scheme is introduced to transfer semantic and boundary cues from a high-capacity teacher. Extensive experiments on benchmarks also demonstrate the state-of-the-art accuracy under extremely low model complexity, indicating that MicroAUNet is suitable for real-time clinical polyp segmentation. The code is publicly available at https://github.com/JeremyXSC/MicroAUNet.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Work in progress",
    "pdf_url": "https://arxiv.org/pdf/2511.01143v1",
    "published_date": "2025-11-03 01:43:34 UTC",
    "updated_date": "2025-11-03 01:43:34 UTC"
  },
  {
    "arxiv_id": "2511.01140v2",
    "title": "Few-Shot Multimodal Medical Imaging: A Theoretical Framework",
    "authors": [
      "Md Talha Mohsin",
      "Ismail Abdulrashid"
    ],
    "abstract": "Medical imaging often operates under limited labeled data, especially in rare disease and low resource clinical environments. Existing multimodal and meta learning approaches improve performance in these settings but lack a theoretical explanation of why or when they succeed. This paper presents a unified theoretical framework for few shot multimodal medical imaging that jointly characterizes sample complexity, uncertainty quantification, and interpretability. Using PAC learning, VC theory, and PAC Bayesian analysis, we derive bounds that describe the minimum number of labeled samples required for reliable performance and show how complementary modalities reduce effective capacity through an information gain term. We further introduce a formal metric for explanation stability, proving that explanation variance decreases at an inverse n rate. A sequential Bayesian interpretation of Chain of Thought reasoning is also developed to show stepwise posterior contraction. To illustrate these ideas, we implement a controlled multimodal dataset and evaluate an additive CNN MLP fusion model under few shot regimes, confirming predicted multimodal gains, modality interference at larger sample sizes, and shrinking predictive uncertainty. Together, the framework provides a principled foundation for designing data efficient, uncertainty aware, and interpretable diagnostic models in low resource settings.",
    "categories": [
      "stat.ML",
      "cs.AI",
      "cs.CV",
      "cs.LG",
      "eess.IV"
    ],
    "primary_category": "stat.ML",
    "comment": "6 Pages",
    "pdf_url": "https://arxiv.org/pdf/2511.01140v2",
    "published_date": "2025-11-03 01:21:50 UTC",
    "updated_date": "2025-12-17 01:54:55 UTC"
  },
  {
    "arxiv_id": "2511.01139v2",
    "title": "Learning with Category-Equivariant Architectures for Human Activity Recognition",
    "authors": [
      "Yoshihiro Maruyama"
    ],
    "abstract": "We propose CatEquiv, a category-equivariant neural network for Human Activity Recognition (HAR) from inertial sensors that systematically encodes temporal, amplitude, and structural symmetries. We introduce a symmetry category that jointly represents cyclic time shifts, positive gain scalings, and the sensor-hierarchy poset, capturing the categorical symmetry structure of the data. CatEquiv achieves equivariance with respect to the categorical symmetry product. On UCI-HAR under out-of-distribution perturbations, CatEquiv attains markedly higher robustness compared with circularly padded CNNs and plain CNNs. These results demonstrate that enforcing categorical symmetries yields strong invariance and generalization without additional model capacity.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.HC",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2511.01139v2",
    "published_date": "2025-11-03 01:20:35 UTC",
    "updated_date": "2025-11-04 02:33:12 UTC"
  }
]