[
  {
    "arxiv_id": "2409.00873v1",
    "title": "Equitable Skin Disease Prediction Using Transfer Learning and Domain Adaptation",
    "authors": [
      "Sajib Acharjee Dip",
      "Kazi Hasan Ibn Arif",
      "Uddip Acharjee Shuvo",
      "Ishtiaque Ahmed Khan",
      "Na Meng"
    ],
    "abstract": "In the realm of dermatology, the complexity of diagnosing skin conditions\nmanually necessitates the expertise of dermatologists. Accurate identification\nof various skin ailments, ranging from cancer to inflammatory diseases, is\nparamount. However, existing artificial intelligence (AI) models in dermatology\nface challenges, particularly in accurately diagnosing diseases across diverse\nskin tones, with a notable performance gap in darker skin. Additionally, the\nscarcity of publicly available, unbiased datasets hampers the development of\ninclusive AI diagnostic tools. To tackle the challenges in accurately\npredicting skin conditions across diverse skin tones, we employ a\ntransfer-learning approach that capitalizes on the rich, transferable knowledge\nfrom various image domains. Our method integrates multiple pre-trained models\nfrom a wide range of sources, including general and specific medical images, to\nimprove the robustness and inclusiveness of the skin condition predictions. We\nrigorously evaluated the effectiveness of these models using the Diverse\nDermatology Images (DDI) dataset, which uniquely encompasses both\nunderrepresented and common skin tones, making it an ideal benchmark for\nassessing our approach. Among all methods, Med-ViT emerged as the top performer\ndue to its comprehensive feature representation learned from diverse image\nsources. To further enhance performance, we conducted domain adaptation using\nadditional skin image datasets such as HAM10000. This adaptation significantly\nimproved model performance across all models.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.00873v1",
    "published_date": "2024-09-01 23:48:26 UTC",
    "updated_date": "2024-09-01 23:48:26 UTC"
  },
  {
    "arxiv_id": "2409.00861v1",
    "title": "Harnessing the Power of Semi-Structured Knowledge and LLMs with Triplet-Based Prefiltering for Question Answering",
    "authors": [
      "Derian Boer",
      "Fabian Koch",
      "Stefan Kramer"
    ],
    "abstract": "Large Language Models (LLMs) frequently lack domain-specific knowledge and\neven fine-tuned models tend to hallucinate. Hence, more reliable models that\ncan include external knowledge are needed. We present a pipeline, 4StepFocus,\nand specifically a preprocessing step, that can substantially improve the\nanswers of LLMs. This is achieved by providing guided access to external\nknowledge making use of the model's ability to capture relational context and\nconduct rudimentary reasoning by themselves. The method narrows down\npotentially correct answers by triplets-based searches in a semi-structured\nknowledge base in a direct, traceable fashion, before switching to latent\nrepresentations for ranking those candidates based on unstructured data. This\ndistinguishes it from related methods that are purely based on latent\nrepresentations. 4StepFocus consists of the steps: 1) Triplet generation for\nextraction of relational data by an LLM, 2) substitution of variables in those\ntriplets to narrow down answer candidates employing a knowledge graph, 3)\nsorting remaining candidates with a vector similarity search involving\nassociated non-structured data, 4) reranking the best candidates by the LLM\nwith background data provided. Experiments on a medical, a product\nrecommendation, and an academic paper search test set demonstrate that this\napproach is indeed a powerful augmentation. It not only adds relevant traceable\nbackground information from information retrieval, but also improves\nperformance considerably in comparison to state-of-the-art methods. This paper\npresents a novel, largely unexplored direction and therefore provides a wide\nrange of future work opportunities. Used source code is available at\nhttps://github.com/kramerlab/4StepFocus.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG",
      "cs.LO"
    ],
    "primary_category": "cs.CL",
    "comment": "9 pages, published at IJCLR 2024",
    "pdf_url": "http://arxiv.org/pdf/2409.00861v1",
    "published_date": "2024-09-01 22:43:27 UTC",
    "updated_date": "2024-09-01 22:43:27 UTC"
  },
  {
    "arxiv_id": "2409.02130v2",
    "title": "From Predictive Importance to Causality: Which Machine Learning Model Reflects Reality?",
    "authors": [
      "Muhammad Arbab Arshad",
      "Pallavi Kandanur",
      "Saurabh Sonawani",
      "Laiba Batool",
      "Muhammad Umar Habib"
    ],
    "abstract": "This study analyzes the Ames Housing Dataset using CatBoost and LightGBM\nmodels to explore feature importance and causal relationships in housing price\nprediction. We examine the correlation between SHAP values and EconML\npredictions, achieving high accuracy in price forecasting. Our analysis reveals\na moderate Spearman rank correlation of 0.48 between SHAP-based feature\nimportance and causally significant features, highlighting the complexity of\naligning predictive modeling with causal understanding in housing market\nanalysis. Through extensive causal analysis, including heterogeneity\nexploration and policy tree interpretation, we provide insights into how\nspecific features like porches impact housing prices across various scenarios.\nThis work underscores the need for integrated approaches that combine\npredictive power with causal insights in real estate valuation, offering\nvaluable guidance for stakeholders in the industry.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.02130v2",
    "published_date": "2024-09-01 22:37:47 UTC",
    "updated_date": "2024-09-24 17:06:31 UTC"
  },
  {
    "arxiv_id": "2409.09058v1",
    "title": "Redefining Data-Centric Design: A New Approach with a Domain Model and Core Data Ontology for Computational Systems",
    "authors": [
      "William Johnson",
      "James Davis",
      "Tara Kelly"
    ],
    "abstract": "This paper presents an innovative data-centric paradigm for designing\ncomputational systems by introducing a new informatics domain model. The\nproposed model moves away from the conventional node-centric framework and\nfocuses on data-centric categorization, using a multimodal approach that\nincorporates objects, events, concepts, and actions. By drawing on\ninterdisciplinary research and establishing a foundational ontology based on\nthese core elements, the model promotes semantic consistency and secure data\nhandling across distributed ecosystems. We also explore the implementation of\nthis model as an OWL 2 ontology, discuss its potential applications, and\noutline its scalability and future directions for research. This work aims to\nserve as a foundational guide for system designers and data architects in\ndeveloping more secure, interoperable, and scalable data systems.",
    "categories": [
      "cs.DC",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.DC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.09058v1",
    "published_date": "2024-09-01 22:34:12 UTC",
    "updated_date": "2024-09-01 22:34:12 UTC"
  },
  {
    "arxiv_id": "2409.00858v2",
    "title": "Trustworthy Human-AI Collaboration: Reinforcement Learning with Human Feedback and Physics Knowledge for Safe Autonomous Driving",
    "authors": [
      "Zilin Huang",
      "Zihao Sheng",
      "Sikai Chen"
    ],
    "abstract": "In the field of autonomous driving, developing safe and trustworthy\nautonomous driving policies remains a significant challenge. Recently,\nReinforcement Learning with Human Feedback (RLHF) has attracted substantial\nattention due to its potential to enhance training safety and sampling\nefficiency. Nevertheless, existing RLHF-enabled methods often falter when faced\nwith imperfect human demonstrations, potentially leading to training\noscillations or even worse performance than rule-based approaches. Inspired by\nthe human learning process, we propose Physics-enhanced Reinforcement Learning\nwith Human Feedback (PE-RLHF). This novel framework synergistically integrates\nhuman feedback (e.g., human intervention and demonstration) and physics\nknowledge (e.g., traffic flow model) into the training loop of reinforcement\nlearning. The key advantage of PE-RLHF is its guarantee that the learned policy\nwill perform at least as well as the given physics-based policy, even when\nhuman feedback quality deteriorates, thus ensuring trustworthy safety\nimprovements. PE-RLHF introduces a Physics-enhanced Human-AI (PE-HAI)\ncollaborative paradigm for dynamic action selection between human and\nphysics-based actions, employs a reward-free approach with a proxy value\nfunction to capture human preferences, and incorporates a minimal intervention\nmechanism to reduce the cognitive load on human mentors. Extensive experiments\nacross diverse driving scenarios demonstrate that PE-RLHF significantly\noutperforms traditional methods, achieving state-of-the-art (SOTA) performance\nin safety, efficiency, and generalizability, even with varying quality of human\nfeedback. The philosophy behind PE-RLHF not only advances autonomous driving\ntechnology but can also offer valuable insights for other safety-critical\ndomains. Demo video and code are available at:\n\\https://zilin-huang.github.io/PE-RLHF-website/",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.HC",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "33 pages, 20 figures",
    "pdf_url": "http://arxiv.org/pdf/2409.00858v2",
    "published_date": "2024-09-01 22:20:32 UTC",
    "updated_date": "2024-09-05 08:07:27 UTC"
  },
  {
    "arxiv_id": "2409.00856v1",
    "title": "Benchmarking LLM Code Generation for Audio Programming with Visual Dataflow Languages",
    "authors": [
      "William Zhang",
      "Maria Leon",
      "Ryan Xu",
      "Adrian Cardenas",
      "Amelia Wissink",
      "Hanna Martin",
      "Maya Srikanth",
      "Kaya Dorogi",
      "Christian Valadez",
      "Pedro Perez",
      "Citlalli Grijalva",
      "Corey Zhang",
      "Mark Santolucito"
    ],
    "abstract": "Node-based programming languages are increasingly popular in media arts\ncoding domains. These languages are designed to be accessible to users with\nlimited coding experience, allowing them to achieve creative output without an\nextensive programming background. Using LLM-based code generation to further\nlower the barrier to creative output is an exciting opportunity. However, the\nbest strategy for code generation for visual node-based programming languages\nis still an open question. In particular, such languages have multiple levels\nof representation in text, each of which may be used for code generation. In\nthis work, we explore the performance of LLM code generation in audio\nprogramming tasks in visual programming languages at multiple levels of\nrepresentation. We explore code generation through metaprogramming code\nrepresentations for these languages (i.e., coding the language using a\ndifferent high-level text-based programming language), as well as through\ndirect node generation with JSON. We evaluate code generated in this way for\ntwo visual languages for audio programming on a benchmark set of coding\nproblems. We measure both correctness and complexity of the generated code. We\nfind that metaprogramming results in more semantically correct generated code,\ngiven that the code is well-formed (i.e., is syntactically correct and runs).\nWe also find that prompting for richer metaprogramming using randomness and\nloops led to more complex code.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.CL",
      "cs.PL"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.00856v1",
    "published_date": "2024-09-01 22:11:23 UTC",
    "updated_date": "2024-09-01 22:11:23 UTC"
  },
  {
    "arxiv_id": "2409.00853v1",
    "title": "JaxLife: An Open-Ended Agentic Simulator",
    "authors": [
      "Chris Lu",
      "Michael Beukman",
      "Michael Matthews",
      "Jakob Foerster"
    ],
    "abstract": "Human intelligence emerged through the process of natural selection and\nevolution on Earth. We investigate what it would take to re-create this process\nin silico. While past work has often focused on low-level processes (such as\nsimulating physics or chemistry), we instead take a more targeted approach,\naiming to evolve agents that can accumulate open-ended culture and technologies\nacross generations. Towards this, we present JaxLife: an artificial life\nsimulator in which embodied agents, parameterized by deep neural networks, must\nlearn to survive in an expressive world containing programmable systems. First,\nwe describe the environment and show that it can facilitate meaningful\nTuring-complete computation. We then analyze the evolved emergent agents'\nbehavior, such as rudimentary communication protocols, agriculture, and tool\nuse. Finally, we investigate how complexity scales with the amount of compute\nused. We believe JaxLife takes a step towards studying evolved behavior in more\nopen-ended simulations. Our code is available at\nhttps://github.com/luchris429/JaxLife",
    "categories": [
      "cs.AI",
      "cs.NE"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.00853v1",
    "published_date": "2024-09-01 22:05:02 UTC",
    "updated_date": "2024-09-01 22:05:02 UTC"
  },
  {
    "arxiv_id": "2409.00847v3",
    "title": "The Design of an LLM-powered Unstructured Analytics System",
    "authors": [
      "Eric Anderson",
      "Jonathan Fritz",
      "Austin Lee",
      "Bohou Li",
      "Mark Lindblad",
      "Henry Lindeman",
      "Alex Meyer",
      "Parth Parmar",
      "Tanvi Ranade",
      "Mehul A. Shah",
      "Benjamin Sowell",
      "Dan Tecuci",
      "Vinayak Thapliyal",
      "Matt Welsh"
    ],
    "abstract": "LLMs demonstrate an uncanny ability to process unstructured data, and as\nsuch, have the potential to go beyond search and run complex, semantic analyses\nat scale. We describe the design of an unstructured analytics system, Aryn, and\nthe tenets and use cases that motivate its design. With Aryn, users specify\nqueries in natural language and the system automatically determines a semantic\nplan and executes it to compute an answer from a large collection of\nunstructured documents. At the core of Aryn is Sycamore, a declarative document\nprocessing engine, that provides a reliable distributed abstraction called\nDocSets. Sycamore allows users to analyze, enrich, and transform complex\ndocuments at scale. Aryn includes Luna, a query planner that translates natural\nlanguage queries to Sycamore scripts, and DocParse, which takes raw PDFs and\ndocument images, and converts them to DocSets for downstream processing. We\nshow how these pieces come together to achieve better accuracy than RAG on\nanalytics queries over real world reports from the National Transportation\nSafety Board (NTSB). Also, given current limitations of LLMs, we argue that an\nanalytics system must provide explainability to be practical, and show how\nAryn's user interface does this to help build trust.",
    "categories": [
      "cs.DB",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.DB",
    "comment": "Included in the proceedings of The Conference on Innovative Data\n  Systems Research (CIDR) 2025",
    "pdf_url": "http://arxiv.org/pdf/2409.00847v3",
    "published_date": "2024-09-01 21:30:14 UTC",
    "updated_date": "2024-12-28 05:14:14 UTC"
  },
  {
    "arxiv_id": "2409.00844v1",
    "title": "Report Cards: Qualitative Evaluation of Language Models Using Natural Language Summaries",
    "authors": [
      "Blair Yang",
      "Fuyang Cui",
      "Keiran Paster",
      "Jimmy Ba",
      "Pashootan Vaezipoor",
      "Silviu Pitis",
      "Michael R. Zhang"
    ],
    "abstract": "The rapid development and dynamic nature of large language models (LLMs) make\nit difficult for conventional quantitative benchmarks to accurately assess\ntheir capabilities. We propose report cards, which are human-interpretable,\nnatural language summaries of model behavior for specific skills or topics. We\ndevelop a framework to evaluate report cards based on three criteria:\nspecificity (ability to distinguish between models), faithfulness (accurate\nrepresentation of model capabilities), and interpretability (clarity and\nrelevance to humans). We also propose an iterative algorithm for generating\nreport cards without human supervision and explore its efficacy by ablating\nvarious design choices. Through experimentation with popular LLMs, we\ndemonstrate that report cards provide insights beyond traditional benchmarks\nand can help address the need for a more interpretable and holistic evaluation\nof LLMs.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "11 pages, 8 figures",
    "pdf_url": "http://arxiv.org/pdf/2409.00844v1",
    "published_date": "2024-09-01 21:18:14 UTC",
    "updated_date": "2024-09-01 21:18:14 UTC"
  },
  {
    "arxiv_id": "2409.00839v1",
    "title": "Entropy Loss: An Interpretability Amplifier of 3D Object Detection Network for Intelligent Driving",
    "authors": [
      "Haobo Yang",
      "Shiyan Zhang",
      "Zhuoyi Yang",
      "Xinyu Zhang",
      "Li Wang",
      "Yifan Tang",
      "Jilong Guo",
      "Jun Li"
    ],
    "abstract": "With the increasing complexity of the traffic environment, the significance\nof safety perception in intelligent driving is intensifying. Traditional\nmethods in the field of intelligent driving perception rely on deep learning,\nwhich suffers from limited interpretability, often described as a \"black box.\"\nThis paper introduces a novel type of loss function, termed \"Entropy Loss,\"\nalong with an innovative training strategy. Entropy Loss is formulated based on\nthe functionality of feature compression networks within the perception model.\nDrawing inspiration from communication systems, the information transmission\nprocess in a feature compression network is expected to demonstrate steady\nchanges in information volume and a continuous decrease in information entropy.\nBy modeling network layer outputs as continuous random variables, we construct\na probabilistic model that quantifies changes in information volume. Entropy\nLoss is then derived based on these expectations, guiding the update of network\nparameters to enhance network interpretability. Our experiments indicate that\nthe Entropy Loss training strategy accelerates the training process. Utilizing\nthe same 60 training epochs, the accuracy of 3D object detection models using\nEntropy Loss on the KITTI test set improved by up to 4.47\\% compared to models\nwithout Entropy Loss, underscoring the method's efficacy. The implementation\ncode is available at\n\\url{https://github.com/yhbcode000/Eloss-Interpretability}.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.IT",
      "math.IT"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.00839v1",
    "published_date": "2024-09-01 20:55:50 UTC",
    "updated_date": "2024-09-01 20:55:50 UTC"
  },
  {
    "arxiv_id": "2409.00837v1",
    "title": "You-Only-Randomize-Once: Shaping Statistical Properties in Constraint-based PCG",
    "authors": [
      "Jediah Katz",
      "Bahar Bateni",
      "Adam M. Smith"
    ],
    "abstract": "In procedural content generation, modeling the generation task as a\nconstraint satisfaction problem lets us define local and global constraints on\nthe generated output. However, a generator's perceived quality often involves\nstatistics rather than just hard constraints. For example, we may desire that\ngenerated outputs use design elements with a similar distribution to that of\nreference designs. However, such statistical properties cannot be expressed\ndirectly as a hard constraint on the generation of any one output. In contrast,\nmethods which do not use a general-purpose constraint solver, such as Gumin's\nimplementation of the WaveFunctionCollapse (WFC) algorithm, can control output\nstatistics but have limited constraint propagation ability and cannot express\nnon-local constraints. In this paper, we introduce You-Only-Randomize-Once\n(YORO) pre-rolling, a method for crafting a decision variable ordering for a\nconstraint solver that encodes desired statistics in a constraint-based\ngenerator. Using a solver-based WFC as an example, we show that this technique\neffectively controls the statistics of tile-grid outputs generated by several\noff-the-shelf SAT solvers, while still enforcing global constraints on the\noutputs.1 Our approach is immediately applicable to WFC-like generation\nproblems and it offers a conceptual starting point for controlling the design\nelement statistics in other constraint-based generators.",
    "categories": [
      "cs.AI",
      "cs.LO"
    ],
    "primary_category": "cs.AI",
    "comment": "Published in Foundations of Digital Games (FDG) 2024. 10 pages, 6\n  figures",
    "pdf_url": "http://arxiv.org/pdf/2409.00837v1",
    "published_date": "2024-09-01 20:43:55 UTC",
    "updated_date": "2024-09-01 20:43:55 UTC"
  },
  {
    "arxiv_id": "2409.03717v1",
    "title": "Sample-Efficient Diffusion for Text-To-Speech Synthesis",
    "authors": [
      "Justin Lovelace",
      "Soham Ray",
      "Kwangyoun Kim",
      "Kilian Q. Weinberger",
      "Felix Wu"
    ],
    "abstract": "This work introduces Sample-Efficient Speech Diffusion (SESD), an algorithm\nfor effective speech synthesis in modest data regimes through latent diffusion.\nIt is based on a novel diffusion architecture, that we call U-Audio Transformer\n(U-AT), that efficiently scales to long sequences and operates in the latent\nspace of a pre-trained audio autoencoder. Conditioned on character-aware\nlanguage model representations, SESD achieves impressive results despite\ntraining on less than 1k hours of speech - far less than current\nstate-of-the-art systems. In fact, it synthesizes more intelligible speech than\nthe state-of-the-art auto-regressive model, VALL-E, while using less than 2%\nthe training data.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.SD",
    "comment": "Interspeech 2024",
    "pdf_url": "http://arxiv.org/pdf/2409.03717v1",
    "published_date": "2024-09-01 20:34:36 UTC",
    "updated_date": "2024-09-01 20:34:36 UTC"
  },
  {
    "arxiv_id": "2409.00830v1",
    "title": "Building FKG.in: a Knowledge Graph for Indian Food",
    "authors": [
      "Saransh Kumar Gupta",
      "Lipika Dey",
      "Partha Pratim Das",
      "Ramesh Jain"
    ],
    "abstract": "This paper presents an ontology design along with knowledge engineering, and\nmultilingual semantic reasoning techniques to build an automated system for\nassimilating culinary information for Indian food in the form of a knowledge\ngraph. The main focus is on designing intelligent methods to derive ontology\ndesigns and capture all-encompassing knowledge about food, recipes,\ningredients, cooking characteristics, and most importantly, nutrition, at\nscale. We present our ongoing work in this workshop paper, describe in some\ndetail the relevant challenges in curating knowledge of Indian food, and\npropose our high-level ontology design. We also present a novel workflow that\nuses AI, LLM, and language technology to curate information from recipe blog\nsites in the public domain to build knowledge graphs for Indian food. The\nmethods for knowledge curation proposed in this paper are generic and can be\nreplicated for any domain. The design is application-agnostic and can be used\nfor AI-driven smart analysis, building recommendation systems for Personalized\nDigital Health, and complementing the knowledge graph for Indian food with\ncontextual information such as user information, food biochemistry, geographic\ninformation, agricultural information, etc.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.IR"
    ],
    "primary_category": "cs.AI",
    "comment": "14 pages, 3 figures, 25 references, Formal Ontology in Information\n  Systems Conference 2024 - Integrated Food Ontology Workshop",
    "pdf_url": "http://arxiv.org/pdf/2409.00830v1",
    "published_date": "2024-09-01 20:18:36 UTC",
    "updated_date": "2024-09-01 20:18:36 UTC"
  },
  {
    "arxiv_id": "2409.00824v1",
    "title": "Accelerating Hybrid Agent-Based Models and Fuzzy Cognitive Maps: How to Combine Agents who Think Alike?",
    "authors": [
      "Philippe J. Giabbanelli",
      "Jack T. Beerman"
    ],
    "abstract": "While Agent-Based Models can create detailed artificial societies based on\nindividual differences and local context, they can be computationally\nintensive. Modelers may offset these costs through a parsimonious use of the\nmodel, for example by using smaller population sizes (which limits analyses in\nsub-populations), running fewer what-if scenarios, or accepting more\nuncertainty by performing fewer simulations. Alternatively, researchers may\naccelerate simulations via hardware solutions (e.g., GPU parallelism) or\napproximation approaches that operate a tradeoff between accuracy and compute\ntime. In this paper, we present an approximation that combines agents who\n`think alike', thus reducing the population size and the compute time. Our\ninnovation relies on representing agent behaviors as networks of rules (Fuzzy\nCognitive Maps) and empirically evaluating different measures of distance\nbetween these networks. Then, we form groups of think-alike agents via\ncommunity detection and simplify them to a representative agent. Case studies\nshow that our simplifications remain accuracy.",
    "categories": [
      "cs.AI",
      "cs.MA"
    ],
    "primary_category": "cs.AI",
    "comment": "To appear at the 2024 Winter Simulation Conference",
    "pdf_url": "http://arxiv.org/pdf/2409.00824v1",
    "published_date": "2024-09-01 19:45:15 UTC",
    "updated_date": "2024-09-01 19:45:15 UTC"
  },
  {
    "arxiv_id": "2409.00815v3",
    "title": "Serialized Speech Information Guidance with Overlapped Encoding Separation for Multi-Speaker Automatic Speech Recognition",
    "authors": [
      "Hao Shi",
      "Yuan Gao",
      "Zhaoheng Ni",
      "Tatsuya Kawahara"
    ],
    "abstract": "Serialized output training (SOT) attracts increasing attention due to its\nconvenience and flexibility for multi-speaker automatic speech recognition\n(ASR). However, it is not easy to train with attention loss only. In this\npaper, we propose the overlapped encoding separation (EncSep) to fully utilize\nthe benefits of the connectionist temporal classification (CTC) and attention\nhybrid loss. This additional separator is inserted after the encoder to extract\nthe multi-speaker information with CTC losses. Furthermore, we propose the\nserialized speech information guidance SOT (GEncSep) to further utilize the\nseparated encodings. The separated streams are concatenated to provide\nsingle-speaker information to guide attention during decoding. The experimental\nresults on LibriMix show that the single-speaker encoding can be separated from\nthe overlapped encoding. The CTC loss helps to improve the encoder\nrepresentation under complex scenarios. GEncSep further improved performance.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.00815v3",
    "published_date": "2024-09-01 19:07:34 UTC",
    "updated_date": "2024-09-11 02:33:17 UTC"
  },
  {
    "arxiv_id": "2409.10547v1",
    "title": "NoPhish: Efficient Chrome Extension for Phishing Detection Using Machine Learning Techniques",
    "authors": [
      "Leand Thaqi",
      "Arbnor Halili",
      "Kamer Vishi",
      "Blerim Rexha"
    ],
    "abstract": "The growth of digitalization services via web browsers has simplified our\ndaily routine of doing business. But at the same time, it has made the web\nbrowser very attractive for several cyber-attacks. Web phishing is a well-known\ncyberattack that is used by attackers camouflaging as trustworthy web servers\nto obtain sensitive user information such as credit card numbers, bank\ninformation, personal ID, social security number, and username and passwords.\nIn recent years many techniques have been developed to identify the authentic\nweb pages that users visit and warn them when the webpage is phishing. In this\npaper, we have developed an extension for Chrome the most favorite web browser,\nthat will serve as a middleware between the user and phishing websites. The\nChrome extension named \"NoPhish\" shall identify a phishing webpage based on\nseveral Machine Learning techniques. We have used the training dataset from\n\"PhishTank\" and extracted the 22 most popular features as rated by the Alexa\ndatabase. The training algorithms used are Random Forest, Support Vector\nMachine, and k-Nearest Neighbor. The performance results show that Random\nForest delivers the best precision.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "21 pages, 13 figures, 5 listings, 1 table",
    "pdf_url": "http://arxiv.org/pdf/2409.10547v1",
    "published_date": "2024-09-01 18:59:14 UTC",
    "updated_date": "2024-09-01 18:59:14 UTC"
  },
  {
    "arxiv_id": "2409.00810v2",
    "title": "A Novel Self-Attention-Enabled Weighted Ensemble-Based Convolutional Neural Network Framework for Distributed Denial of Service Attack Classification",
    "authors": [
      "Kanthimathi S",
      "Shravan Venkatraman",
      "Jayasankar K S",
      "Pranay Jiljith T",
      "Jashwanth R"
    ],
    "abstract": "Distributed Denial of Service (DDoS) attacks are a major concern in network\nsecurity, as they overwhelm systems with excessive traffic, compromise\nsensitive data, and disrupt network services. Accurately detecting these\nattacks is crucial to protecting network infrastructure. Traditional\napproaches, such as single Convolutional Neural Networks (CNNs) or conventional\nMachine Learning (ML) algorithms like Decision Trees (DTs) and Support Vector\nMachines (SVMs), struggle to extract the diverse features needed for precise\nclassification, resulting in suboptimal performance. This research addresses\nthis gap by introducing a novel approach for DDoS attack detection. The\nproposed method combines three distinct CNN architectures: SA-Enabled CNN with\nXGBoost, SA-Enabled CNN with LSTM, and SA-Enabled CNN with Random Forest. Each\nmodel extracts features at multiple scales, while self-attention mechanisms\nenhance feature integration and relevance. The weighted ensemble approach\nensures that both prominent and subtle features contribute to the final\nclassification, improving adaptability to evolving attack patterns and novel\nthreats. The proposed method achieves a precision of 98.71%, an F1-score of\n98.66%, a recall of 98.63%, and an accuracy of 98.69%, outperforming\ntraditional methods and setting a new benchmark in DDoS attack detection. This\ninnovative approach addresses critical limitations in current models and\nadvances the state of the art in network security.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.LG",
      "I.2.6"
    ],
    "primary_category": "cs.CR",
    "comment": "19 pages, 3 tables, 9 figures",
    "pdf_url": "http://arxiv.org/pdf/2409.00810v2",
    "published_date": "2024-09-01 18:58:33 UTC",
    "updated_date": "2024-10-12 09:51:53 UTC"
  },
  {
    "arxiv_id": "2409.00807v1",
    "title": "Diffusion based multi-domain neuroimaging harmonization method with preservation of anatomical details",
    "authors": [
      "Haoyu Lan",
      "Bino A. Varghese",
      "Nasim Sheikh-Bahaei",
      "Farshid Sepehrband",
      "Arthur W Toga",
      "Jeiran Choupan"
    ],
    "abstract": "Multi-center neuroimaging studies face technical variability due to batch\ndifferences across sites, which potentially hinders data aggregation and\nimpacts study reliability.Recent efforts in neuroimaging harmonization have\naimed to minimize these technical gaps and reduce technical variability across\nbatches. While Generative Adversarial Networks (GAN) has been a prominent\nmethod for addressing image harmonization tasks, GAN-harmonized images suffer\nfrom artifacts or anatomical distortions. Given the advancements of denoising\ndiffusion probabilistic model which produces high-fidelity images, we have\nassessed the efficacy of the diffusion model for neuroimaging harmonization. we\nhave demonstrated the diffusion model's superior capability in harmonizing\nimages from multiple domains, while GAN-based methods are limited to\nharmonizing images between two domains per model. Our experiments highlight\nthat the learned domain invariant anatomical condition reinforces the model to\naccurately preserve the anatomical details while differentiating batch\ndifferences at each diffusion step. Our proposed method has been tested on two\npublic neuroimaging dataset ADNI1 and ABIDE II, yielding harmonization results\nwith consistent anatomy preservation and superior FID score compared to the\nGAN-based methods. We have conducted multiple analysis including extensive\nquantitative and qualitative evaluations against the baseline models, ablation\nstudy showcasing the benefits of the learned conditions, and improvements in\nthe consistency of perivascular spaces (PVS) segmentation through\nharmonization.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "eess.IV"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.00807v1",
    "published_date": "2024-09-01 18:54:00 UTC",
    "updated_date": "2024-09-01 18:54:00 UTC"
  },
  {
    "arxiv_id": "2409.00787v1",
    "title": "The Dark Side of Human Feedback: Poisoning Large Language Models via User Inputs",
    "authors": [
      "Bocheng Chen",
      "Hanqing Guo",
      "Guangjing Wang",
      "Yuanda Wang",
      "Qiben Yan"
    ],
    "abstract": "Large Language Models (LLMs) have demonstrated great capabilities in natural\nlanguage understanding and generation, largely attributed to the intricate\nalignment process using human feedback. While alignment has become an essential\ntraining component that leverages data collected from user queries, it\ninadvertently opens up an avenue for a new type of user-guided poisoning\nattacks. In this paper, we present a novel exploration into the latent\nvulnerabilities of the training pipeline in recent LLMs, revealing a subtle yet\neffective poisoning attack via user-supplied prompts to penetrate alignment\ntraining protections. Our attack, even without explicit knowledge about the\ntarget LLMs in the black-box setting, subtly alters the reward feedback\nmechanism to degrade model performance associated with a particular keyword,\nall while remaining inconspicuous. We propose two mechanisms for crafting\nmalicious prompts: (1) the selection-based mechanism aims at eliciting toxic\nresponses that paradoxically score high rewards, and (2) the generation-based\nmechanism utilizes optimizable prefixes to control the model output. By\ninjecting 1\\% of these specially crafted prompts into the data, through\nmalicious users, we demonstrate a toxicity score up to two times higher when a\nspecific trigger word is used. We uncover a critical vulnerability, emphasizing\nthat irrespective of the reward model, rewards applied, or base language model\nemployed, if training harnesses user-generated prompts, a covert compromise of\nthe LLMs is not only feasible but potentially inevitable.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CR",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.00787v1",
    "published_date": "2024-09-01 17:40:04 UTC",
    "updated_date": "2024-09-01 17:40:04 UTC"
  },
  {
    "arxiv_id": "2409.02128v1",
    "title": "The Application of Artificial Neural Network Model to Predicting the Acid Mine Drainage from Long-Term Lab Scale Kinetic Test",
    "authors": [
      "Muhammad Sonny Abfertiawan",
      "Muchammad Daniyal Kautsar",
      "Faiz Hasan",
      "Yoseph Palinggi",
      "Kris Pranoto"
    ],
    "abstract": "Acid mine drainage (AMD) is one of the common environmental problems in the\ncoal mining industry that was formed by the oxidation of sulfide minerals in\nthe overburden or waste rock. The prediction of acid generation through AMD is\nimportant to do in overburden management and planning the post-mining land use.\nOne of the methods used to predict AMD is a lab-scale kinetic test to determine\nthe rate of acid formation over time using representative samples in the field.\nHowever, this test requires a long-time procedure and large amount of chemical\nreagents lead to inefficient cost. On the other hand, there is potential for\nmachine learning to learn the pattern behind the lab-scale kinetic test data.\nThis study describes an approach to use artificial neural network (ANN)\nmodeling to predict the result from lab-scale kinetic tests. Various ANN model\nis used based on 83 weeks experiments of lab-scale kinetic tests with 100\\%\npotential acid-forming rock. The model approaches the monitoring of pH, ORP,\nconductivity, TDS, sulfate, and heavy metals (Fe and Mn). The overall\nNash-Sutcliffe Efficiency (NSE) obtained in this study was 0.99 on training and\nvalidation data, indicating a strong correlation and accurate prediction\ncompared to the actual lab-scale kinetic tests data. This show the ANN ability\nto learn patterns, trends, and seasonality from past data for accurate\nforecasting, thereby highlighting its significant contribution to solving AMD\nproblems. This research is also expected to establish the foundation for a new\napproach to predict AMD, with time efficient, accurate, and cost-effectiveness\nin future applications.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "The 7th Environmental Technology and Management Conference (ETMC\n  2023)",
    "pdf_url": "http://arxiv.org/pdf/2409.02128v1",
    "published_date": "2024-09-01 16:39:37 UTC",
    "updated_date": "2024-09-01 16:39:37 UTC"
  },
  {
    "arxiv_id": "2409.00755v3",
    "title": "Trusted Unified Feature-Neighborhood Dynamics for Multi-View Classification",
    "authors": [
      "Haojian Huang",
      "Chuanyu Qin",
      "Zhe Liu",
      "Kaijing Ma",
      "Jin Chen",
      "Han Fang",
      "Chao Ban",
      "Hao Sun",
      "Zhongjiang He"
    ],
    "abstract": "Multi-view classification (MVC) faces inherent challenges due to domain gaps\nand inconsistencies across different views, often resulting in uncertainties\nduring the fusion process. While Evidential Deep Learning (EDL) has been\neffective in addressing view uncertainty, existing methods predominantly rely\non the Dempster-Shafer combination rule, which is sensitive to conflicting\nevidence and often neglects the critical role of neighborhood structures within\nmulti-view data. To address these limitations, we propose a Trusted Unified\nFeature-NEighborhood Dynamics (TUNED) model for robust MVC. This method\neffectively integrates local and global feature-neighborhood (F-N) structures\nfor robust decision-making. Specifically, we begin by extracting local F-N\nstructures within each view. To further mitigate potential uncertainties and\nconflicts in multi-view fusion, we employ a selective Markov random field that\nadaptively manages cross-view neighborhood dependencies. Additionally, we\nemploy a shared parameterized evidence extractor that learns global consensus\nconditioned on local F-N structures, thereby enhancing the global integration\nof multi-view features. Experiments on benchmark datasets show that our method\nimproves accuracy and robustness over existing approaches, particularly in\nscenarios with high uncertainty and conflicting views. The code will be made\navailable at https://github.com/JethroJames/TUNED.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted to AAAI 2025",
    "pdf_url": "http://arxiv.org/pdf/2409.00755v3",
    "published_date": "2024-09-01 15:48:20 UTC",
    "updated_date": "2024-12-13 02:10:35 UTC"
  },
  {
    "arxiv_id": "2409.00754v1",
    "title": "Cooperative Path Planning with Asynchronous Multiagent Reinforcement Learning",
    "authors": [
      "Jiaming Yin",
      "Weixiong Rao",
      "Yu Xiao",
      "Keshuang Tang"
    ],
    "abstract": "In this paper, we study the shortest path problem (SPP) with multiple\nsource-destination pairs (MSD), namely MSD-SPP, to minimize average travel time\nof all shortest paths. The inherent traffic capacity limits within a road\nnetwork contributes to the competition among vehicles. Multi-agent\nreinforcement learning (MARL) model cannot offer effective and efficient path\nplanning cooperation due to the asynchronous decision making setting in\nMSD-SPP, where vehicles (a.k.a agents) cannot simultaneously complete routing\nactions in the previous time step. To tackle the efficiency issue, we propose\nto divide an entire road network into multiple sub-graphs and subsequently\nexecute a two-stage process of inter-region and intra-region route planning. To\naddress the asynchronous issue, in the proposed asyn-MARL framework, we first\ndesign a global state, which exploits a low-dimensional vector to implicitly\nrepresent the joint observations and actions of multi-agents. Then we develop a\nnovel trajectory collection mechanism to decrease the redundancy in training\ntrajectories. Additionally, we design a novel actor network to facilitate the\ncooperation among vehicles towards the same or close destinations and a\nreachability graph aimed at preventing infinite loops in routing paths. On both\nsynthetic and real road networks, our evaluation result demonstrates that our\napproach outperforms state-of-the-art planning approaches.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.00754v1",
    "published_date": "2024-09-01 15:48:14 UTC",
    "updated_date": "2024-09-01 15:48:14 UTC"
  },
  {
    "arxiv_id": "2409.00750v3",
    "title": "MaskGCT: Zero-Shot Text-to-Speech with Masked Generative Codec Transformer",
    "authors": [
      "Yuancheng Wang",
      "Haoyue Zhan",
      "Liwei Liu",
      "Ruihong Zeng",
      "Haotian Guo",
      "Jiachen Zheng",
      "Qiang Zhang",
      "Xueyao Zhang",
      "Shunsi Zhang",
      "Zhizheng Wu"
    ],
    "abstract": "The recent large-scale text-to-speech (TTS) systems are usually grouped as\nautoregressive and non-autoregressive systems. The autoregressive systems\nimplicitly model duration but exhibit certain deficiencies in robustness and\nlack of duration controllability. Non-autoregressive systems require explicit\nalignment information between text and speech during training and predict\ndurations for linguistic units (e.g. phone), which may compromise their\nnaturalness. In this paper, we introduce Masked Generative Codec Transformer\n(MaskGCT), a fully non-autoregressive TTS model that eliminates the need for\nexplicit alignment information between text and speech supervision, as well as\nphone-level duration prediction. MaskGCT is a two-stage model: in the first\nstage, the model uses text to predict semantic tokens extracted from a speech\nself-supervised learning (SSL) model, and in the second stage, the model\npredicts acoustic tokens conditioned on these semantic tokens. MaskGCT follows\nthe mask-and-predict learning paradigm. During training, MaskGCT learns to\npredict masked semantic or acoustic tokens based on given conditions and\nprompts. During inference, the model generates tokens of a specified length in\na parallel manner. Experiments with 100K hours of in-the-wild speech\ndemonstrate that MaskGCT outperforms the current state-of-the-art zero-shot TTS\nsystems in terms of quality, similarity, and intelligibility. Audio samples are\navailable at https://maskgct.github.io/. We release our code and model\ncheckpoints at\nhttps://github.com/open-mmlab/Amphion/blob/main/models/tts/maskgct.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.LG",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.00750v3",
    "published_date": "2024-09-01 15:26:30 UTC",
    "updated_date": "2024-10-20 14:25:49 UTC"
  },
  {
    "arxiv_id": "2409.02127v1",
    "title": "Enabling Trustworthy Federated Learning in Industrial IoT: Bridging the Gap Between Interpretability and Robustness",
    "authors": [
      "Senthil Kumar Jagatheesaperumal",
      "Mohamed Rahouti",
      "Ali Alfatemi",
      "Nasir Ghani",
      "Vu Khanh Quy",
      "Abdellah Chehri"
    ],
    "abstract": "Federated Learning (FL) represents a paradigm shift in machine learning,\nallowing collaborative model training while keeping data localized. This\napproach is particularly pertinent in the Industrial Internet of Things (IIoT)\ncontext, where data privacy, security, and efficient utilization of distributed\nresources are paramount. The essence of FL in IIoT lies in its ability to learn\nfrom diverse, distributed data sources without requiring central data storage,\nthus enhancing privacy and reducing communication overheads. However, despite\nits potential, several challenges impede the widespread adoption of FL in IIoT,\nnotably in ensuring interpretability and robustness. This article focuses on\nenabling trustworthy FL in IIoT by bridging the gap between interpretability\nand robustness, which is crucial for enhancing trust, improving\ndecision-making, and ensuring compliance with regulations. Moreover, the design\nstrategies summarized in this article ensure that FL systems in IIoT are\ntransparent and reliable, vital in industrial settings where decisions have\nsignificant safety and economic impacts. The case studies in the IIoT\nenvironment driven by trustworthy FL models are provided, wherein the practical\ninsights of trustworthy communications between IIoT systems and their end users\nare highlighted.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "68Txx",
      "I.2.6"
    ],
    "primary_category": "cs.LG",
    "comment": "7 pages, 2 figures",
    "pdf_url": "http://arxiv.org/pdf/2409.02127v1",
    "published_date": "2024-09-01 15:13:39 UTC",
    "updated_date": "2024-09-01 15:13:39 UTC"
  },
  {
    "arxiv_id": "2409.00743v1",
    "title": "Interpretable Clustering: A Survey",
    "authors": [
      "Lianyu Hu",
      "Mudi Jiang",
      "Junjie Dong",
      "Xinying Liu",
      "Zengyou He"
    ],
    "abstract": "In recent years, much of the research on clustering algorithms has primarily\nfocused on enhancing their accuracy and efficiency, frequently at the expense\nof interpretability. However, as these methods are increasingly being applied\nin high-stakes domains such as healthcare, finance, and autonomous systems, the\nneed for transparent and interpretable clustering outcomes has become a\ncritical concern. This is not only necessary for gaining user trust but also\nfor satisfying the growing ethical and regulatory demands in these fields.\nEnsuring that decisions derived from clustering algorithms can be clearly\nunderstood and justified is now a fundamental requirement. To address this\nneed, this paper provides a comprehensive and structured review of the current\nstate of explainable clustering algorithms, identifying key criteria to\ndistinguish between various methods. These insights can effectively assist\nresearchers in making informed decisions about the most suitable explainable\nclustering methods for specific application contexts, while also promoting the\ndevelopment and adoption of clustering algorithms that are both efficient and\ntransparent.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "11 pages, 2 figures",
    "pdf_url": "http://arxiv.org/pdf/2409.00743v1",
    "published_date": "2024-09-01 15:09:51 UTC",
    "updated_date": "2024-09-01 15:09:51 UTC"
  },
  {
    "arxiv_id": "2409.00742v1",
    "title": "Simulation of Social Media-Driven Bubble Formation in Financial Markets using an Agent-Based Model with Hierarchical Influence Network",
    "authors": [
      "Gonzalo Bohorquez",
      "John Cartlidge"
    ],
    "abstract": "We propose that a tree-like hierarchical structure represents a simple and\neffective way to model the emergent behaviour of financial markets, especially\nmarkets where there exists a pronounced intersection between social media\ninfluences and investor behaviour. To explore this hypothesis, we introduce an\nagent-based model of financial markets, where trading agents are embedded in a\nhierarchical network of communities, and communities influence the strategies\nand opinions of traders. Empirical analysis of the model shows that its\nbehaviour conforms to several stylized facts observed in real financial\nmarkets; and the model is able to realistically simulate the effects that\nsocial media-driven phenomena, such as echo chambers and pump-and-dump schemes,\nhave on financial markets.",
    "categories": [
      "cs.MA",
      "cs.AI",
      "q-fin.TR",
      "I.2.11"
    ],
    "primary_category": "cs.MA",
    "comment": "11 pages, 7 figures, To appear in Proceedings of 36th European\n  Modeling and Simulation Symposium (EMSS), 21st International\n  Multidisciplinary Modelling and Simulation Multiconference (I3M), Tenerife,\n  Spain, Sep. 2024",
    "pdf_url": "http://arxiv.org/pdf/2409.00742v1",
    "published_date": "2024-09-01 15:09:35 UTC",
    "updated_date": "2024-09-01 15:09:35 UTC"
  },
  {
    "arxiv_id": "2409.00735v1",
    "title": "AgGym: An agricultural biotic stress simulation environment for ultra-precision management planning",
    "authors": [
      "Mahsa Khosravi",
      "Matthew Carroll",
      "Kai Liang Tan",
      "Liza Van der Laan",
      "Joscif Raigne",
      "Daren S. Mueller",
      "Arti Singh",
      "Aditya Balu",
      "Baskar Ganapathysubramanian",
      "Asheesh Kumar Singh",
      "Soumik Sarkar"
    ],
    "abstract": "Agricultural production requires careful management of inputs such as\nfungicides, insecticides, and herbicides to ensure a successful crop that is\nhigh-yielding, profitable, and of superior seed quality. Current\nstate-of-the-art field crop management relies on coarse-scale crop management\nstrategies, where entire fields are sprayed with pest and disease-controlling\nchemicals, leading to increased cost and sub-optimal soil and crop management.\nTo overcome these challenges and optimize crop production, we utilize machine\nlearning tools within a virtual field environment to generate localized\nmanagement plans for farmers to manage biotic threats while maximizing profits.\nSpecifically, we present AgGym, a modular, crop and stress agnostic simulation\nframework to model the spread of biotic stresses in a field and estimate yield\nlosses with and without chemical treatments. Our validation with real data\nshows that AgGym can be customized with limited data to simulate yield outcomes\nunder various biotic stress conditions. We further demonstrate that deep\nreinforcement learning (RL) policies can be trained using AgGym for designing\nultra-precise biotic stress mitigation strategies with potential to increase\nyield recovery with less chemicals and lower cost. Our proposed framework\nenables personalized decision support that can transform biotic stress\nmanagement from being schedule based and reactive to opportunistic and\nprescriptive. We also release the AgGym software implementation as a community\nresource and invite experts to contribute to this open-sourced publicly\navailable modular environment framework. The source code can be accessed at:\nhttps://github.com/SCSLabISU/AgGym.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.00735v1",
    "published_date": "2024-09-01 14:55:45 UTC",
    "updated_date": "2024-09-01 14:55:45 UTC"
  },
  {
    "arxiv_id": "2409.00727v1",
    "title": "Hound: Hunting Supervision Signals for Few and Zero Shot Node Classification on Text-attributed Graph",
    "authors": [
      "Yuxiang Wang",
      "Xiao Yan",
      "Shiyu Jin",
      "Quanqing Xu",
      "Chuanhui Yang",
      "Yuanyuan Zhu",
      "Chuang Hu",
      "Bo Du",
      "Jiawei Jiang"
    ],
    "abstract": "Text-attributed graph (TAG) is an important type of graph structured data\nwith text descriptions for each node. Few- and zero-shot node classification on\nTAGs have many applications in fields such as academia and social networks.\nHowever, the two tasks are challenging due to the lack of supervision signals,\nand existing methods only use the contrastive loss to align graph-based node\nembedding and language-based text embedding. In this paper, we propose Hound to\nimprove accuracy by introducing more supervision signals, and the core idea is\nto go beyond the node-text pairs that come with data. Specifically, we design\nthree augmentation techniques, i.e., node perturbation, text matching, and\nsemantics negation to provide more reference nodes for each text and vice\nversa. Node perturbation adds/drops edges to produce diversified node\nembeddings that can be matched with a text. Text matching retrieves texts with\nsimilar embeddings to match with a node. Semantics negation uses a negative\nprompt to construct a negative text with the opposite semantics, which is\ncontrasted with the original node and text. We evaluate Hound on 5 datasets and\ncompare with 13 state-of-the-art baselines. The results show that Hound\nconsistently outperforms all baselines, and its accuracy improvements over the\nbest-performing baseline are usually over 5%.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.IR"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.00727v1",
    "published_date": "2024-09-01 14:20:01 UTC",
    "updated_date": "2024-09-01 14:20:01 UTC"
  },
  {
    "arxiv_id": "2409.00726v1",
    "title": "LPUWF-LDM: Enhanced Latent Diffusion Model for Precise Late-phase UWF-FA Generation on Limited Dataset",
    "authors": [
      "Zhaojie Fang",
      "Xiao Yu",
      "Guanyu Zhou",
      "Ke Zhuang",
      "Yifei Chen",
      "Ruiquan Ge",
      "Changmiao Wang",
      "Gangyong Jia",
      "Qing Wu",
      "Juan Ye",
      "Maimaiti Nuliqiman",
      "Peifang Xu",
      "Ahmed Elazab"
    ],
    "abstract": "Ultra-Wide-Field Fluorescein Angiography (UWF-FA) enables precise\nidentification of ocular diseases using sodium fluorescein, which can be\npotentially harmful. Existing research has developed methods to generate UWF-FA\nfrom Ultra-Wide-Field Scanning Laser Ophthalmoscopy (UWF-SLO) to reduce the\nadverse reactions associated with injections. However, these methods have been\nless effective in producing high-quality late-phase UWF-FA, particularly in\nlesion areas and fine details. Two primary challenges hinder the generation of\nhigh-quality late-phase UWF-FA: the scarcity of paired UWF-SLO and\nearly/late-phase UWF-FA datasets, and the need for realistic generation at\nlesion sites and potential blood leakage regions. This study introduces an\nimproved latent diffusion model framework to generate high-quality late-phase\nUWF-FA from limited paired UWF images. To address the challenges as mentioned\nearlier, our approach employs a module utilizing Cross-temporal Regional\nDifference Loss, which encourages the model to focus on the differences between\nearly and late phases. Additionally, we introduce a low-frequency enhanced\nnoise strategy in the diffusion forward process to improve the realism of\nmedical images. To further enhance the mapping capability of the variational\nautoencoder module, especially with limited datasets, we implement a Gated\nConvolutional Encoder to extract additional information from conditional\nimages. Our Latent Diffusion Model for Ultra-Wide-Field Late-Phase Fluorescein\nAngiography (LPUWF-LDM) effectively reconstructs fine details in late-phase\nUWF-FA and achieves state-of-the-art results compared to other existing methods\nwhen working with limited datasets. Our source code is available at:\nhttps://github.com/Tinysqua/****.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "13 pages, 7 figures",
    "pdf_url": "http://arxiv.org/pdf/2409.00726v1",
    "published_date": "2024-09-01 14:09:00 UTC",
    "updated_date": "2024-09-01 14:09:00 UTC"
  },
  {
    "arxiv_id": "2409.00724v1",
    "title": "BUET Multi-disease Heart Sound Dataset: A Comprehensive Auscultation Dataset for Developing Computer-Aided Diagnostic Systems",
    "authors": [
      "Shams Nafisa Ali",
      "Afia Zahin",
      "Samiul Based Shuvo",
      "Nusrat Binta Nizam",
      "Shoyad Ibn Sabur Khan Nuhash",
      "Sayeed Sajjad Razin",
      "S. M. Sakeef Sani",
      "Farihin Rahman",
      "Nawshad Binta Nizam",
      "Farhat Binte Azam",
      "Rakib Hossen",
      "Sumaiya Ohab",
      "Nawsabah Noor",
      "Taufiq Hasan"
    ],
    "abstract": "Cardiac auscultation, an integral tool in diagnosing cardiovascular diseases\n(CVDs), often relies on the subjective interpretation of clinicians, presenting\na limitation in consistency and accuracy. Addressing this, we introduce the\nBUET Multi-disease Heart Sound (BMD-HS) dataset - a comprehensive and\nmeticulously curated collection of heart sound recordings. This dataset,\nencompassing 864 recordings across five distinct classes of common heart\nsounds, represents a broad spectrum of valvular heart diseases, with a focus on\ndiagnostically challenging cases. The standout feature of the BMD-HS dataset is\nits innovative multi-label annotation system, which captures a diverse range of\ndiseases and unique disease states. This system significantly enhances the\ndataset's utility for developing advanced machine learning models in automated\nheart sound classification and diagnosis. By bridging the gap between\ntraditional auscultation practices and contemporary data-driven diagnostic\nmethods, the BMD-HS dataset is poised to revolutionize CVD diagnosis and\nmanagement, providing an invaluable resource for the advancement of cardiac\nhealth research. The dataset is publicly available at this link:\nhttps://github.com/mHealthBuet/BMD-HS-Dataset.",
    "categories": [
      "eess.SP",
      "cs.AI",
      "cs.LG",
      "cs.SD",
      "eess.AS"
    ],
    "primary_category": "eess.SP",
    "comment": "14 pages, 13 figures",
    "pdf_url": "http://arxiv.org/pdf/2409.00724v1",
    "published_date": "2024-09-01 13:55:04 UTC",
    "updated_date": "2024-09-01 13:55:04 UTC"
  },
  {
    "arxiv_id": "2409.00721v1",
    "title": "Who Would Chatbots Vote For? Political Preferences of ChatGPT and Gemini in the 2024 European Union Elections",
    "authors": [
      "Michael Haman",
      "Milan kolnk"
    ],
    "abstract": "This study examines the political bias of chatbots powered by large language\nmodels, namely ChatGPT and Gemini, in the context of the 2024 European\nParliament elections. The research focused on the evaluation of political\nparties represented in the European Parliament across 27 EU Member States by\nthese generative artificial intelligence (AI) systems. The methodology involved\ndaily data collection through standardized prompts on both platforms. The\nresults revealed a stark contrast: while Gemini mostly refused to answer\npolitical questions, ChatGPT provided consistent ratings. The analysis showed a\nsignificant bias in ChatGPT in favor of left-wing and centrist parties, with\nthe highest ratings for the Greens/European Free Alliance. In contrast,\nright-wing parties, particularly the Identity and Democracy group, received the\nlowest ratings. The study identified key factors influencing the ratings,\nincluding attitudes toward European integration and perceptions of democratic\nvalues. The findings highlight the need for a critical approach to information\nprovided by generative AI systems in a political context and call for more\ntransparency and regulation in this area.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.CL",
      "cs.HC"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.00721v1",
    "published_date": "2024-09-01 13:40:13 UTC",
    "updated_date": "2024-09-01 13:40:13 UTC"
  },
  {
    "arxiv_id": "2409.00718v1",
    "title": "Multiscale Color Guided Attention Ensemble Classifier for Age-Related Macular Degeneration using Concurrent Fundus and Optical Coherence Tomography Images",
    "authors": [
      "Pragya Gupta",
      "Subhamoy Mandal",
      "Debashree Guha",
      "Debjani Chakraborty"
    ],
    "abstract": "Automatic diagnosis techniques have evolved to identify age-related macular\ndegeneration (AMD) by employing single modality Fundus images or optical\ncoherence tomography (OCT). To classify ocular diseases, fundus and OCT images\nare the most crucial imaging modalities used in the clinical setting. Most deep\nlearning-based techniques are established on a single imaging modality, which\ncontemplates the ocular disorders to a specific extent and disregards other\nmodality that comprises exhaustive information among distinct imaging\nmodalities. This paper proposes a modality-specific multiscale color space\nembedding integrated with the attention mechanism based on transfer learning\nfor classification (MCGAEc), which can efficiently extract the distinct\nmodality information at various scales using the distinct color spaces. In this\nwork, we first introduce the modality-specific multiscale color space encoder\nmodel, which includes diverse feature representations by integrating distinct\ncharacteristic color spaces on a multiscale into a unified framework. The\nextracted features from the prior encoder module are incorporated with the\nattention mechanism to extract the global features representation, which is\nintegrated with the prior extracted features and transferred to the random\nforest classifier for the classification of AMD. To analyze the performance of\nthe proposed MCGAEc method, a publicly available multi-modality dataset from\nProject Macula for AMD is utilized and compared with the existing models.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "27th International Conference on Pattern Recognition (ICPR) 2024",
    "pdf_url": "http://arxiv.org/pdf/2409.00718v1",
    "published_date": "2024-09-01 13:17:45 UTC",
    "updated_date": "2024-09-01 13:17:45 UTC"
  },
  {
    "arxiv_id": "2409.00717v3",
    "title": "Preference-Based Multi-Agent Reinforcement Learning: Data Coverage and Algorithmic Techniques",
    "authors": [
      "Natalia Zhang",
      "Xinqi Wang",
      "Qiwen Cui",
      "Runlong Zhou",
      "Sham M. Kakade",
      "Simon S. Du"
    ],
    "abstract": "We initiate the study of Preference-Based Multi-Agent Reinforcement Learning\n(PbMARL), exploring both theoretical foundations and empirical validations. We\ndefine the task as identifying the Nash equilibrium from a preference-only\noffline dataset in general-sum games, a problem marked by the challenge of\nsparse feedback signals. Our theory establishes the upper complexity bounds for\nNash Equilibrium in effective PbMARL, demonstrating that single-policy coverage\nis inadequate and highlighting the importance of unilateral dataset coverage.\nThese theoretical insights are verified through comprehensive experiments. To\nenhance the practical performance, we further introduce two algorithmic\ntechniques. (1) We propose a Mean Squared Error (MSE) regularization along the\ntime axis to achieve a more uniform reward distribution and improve reward\nlearning outcomes. (2) We propose an additional penalty based on the\ndistribution of the dataset to incorporate pessimism, improving stability and\neffectiveness during training. Our findings underscore the multifaceted\napproach required for PbMARL, paving the way for effective preference-based\nmulti-agent systems.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.GT",
      "cs.MA"
    ],
    "primary_category": "cs.LG",
    "comment": "9 pages",
    "pdf_url": "http://arxiv.org/pdf/2409.00717v3",
    "published_date": "2024-09-01 13:14:41 UTC",
    "updated_date": "2025-01-09 11:24:44 UTC"
  },
  {
    "arxiv_id": "2409.00707v1",
    "title": "ReMOVE: A Reference-free Metric for Object Erasure",
    "authors": [
      "Aditya Chandrasekar",
      "Goirik Chakrabarty",
      "Jai Bardhan",
      "Ramya Hebbalaguppe",
      "Prathosh AP"
    ],
    "abstract": "We introduce $\\texttt{ReMOVE}$, a novel reference-free metric for assessing\nobject erasure efficacy in diffusion-based image editing models\npost-generation. Unlike existing measures such as LPIPS and CLIPScore,\n$\\texttt{ReMOVE}$ addresses the challenge of evaluating inpainting without a\nreference image, common in practical scenarios. It effectively distinguishes\nbetween object removal and replacement. This is a key issue in diffusion models\ndue to stochastic nature of image generation. Traditional metrics fail to align\nwith the intuitive definition of inpainting, which aims for (1) seamless object\nremoval within masked regions (2) while preserving the background continuity.\n$\\texttt{ReMOVE}$ not only correlates with state-of-the-art metrics and aligns\nwith human perception but also captures the nuanced aspects of the inpainting\nprocess, providing a finer-grained evaluation of the generated outputs.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted at The First Workshop on the Evaluation of Generative\n  Foundation Models (EvGENFM) at CVPR 2024",
    "pdf_url": "http://arxiv.org/pdf/2409.00707v1",
    "published_date": "2024-09-01 12:26:14 UTC",
    "updated_date": "2024-09-01 12:26:14 UTC"
  },
  {
    "arxiv_id": "2409.00706v1",
    "title": "Abstaining Machine Learning -- Philosophical Considerations",
    "authors": [
      "Daniela Schuster"
    ],
    "abstract": "This paper establishes a connection between the fields of machine learning\n(ML) and philosophy concerning the phenomenon of behaving neutrally. It\ninvestigates a specific class of ML systems capable of delivering a neutral\nresponse to a given task, referred to as abstaining machine learning systems,\nthat has not yet been studied from a philosophical perspective. The paper\nintroduces and explains various abstaining machine learning systems, and\ncategorizes them into distinct types. An examination is conducted on how\nabstention in the different machine learning system types aligns with the\nepistemological counterpart of suspended judgment, addressing both the nature\nof suspension and its normative profile. Additionally, a philosophical analysis\nis suggested on the autonomy and explainability of the abstaining response. It\nis argued, specifically, that one of the distinguished types of abstaining\nsystems is preferable as it aligns more closely with our criteria for suspended\njudgment. Moreover, it is better equipped to autonomously generate abstaining\noutputs and offer explanations for abstaining outputs when compared to the\nother type.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Part of the published PhD Thesis: Daniela Schuster. Suspension of\n  Judgment in Artificial Intelligence-Uncovering Uncertainty in Data-Based and\n  Logic-Based Systems. PhD thesis, University of Konstanz, 2024.\n  http://nbn-resolving.de/urn:nbn:de:bsz:352-2-1r3gwq4l5jlwr2",
    "pdf_url": "http://arxiv.org/pdf/2409.00706v1",
    "published_date": "2024-09-01 12:25:06 UTC",
    "updated_date": "2024-09-01 12:25:06 UTC"
  },
  {
    "arxiv_id": "2409.10542v3",
    "title": "SAM4MLLM: Enhance Multi-Modal Large Language Model for Referring Expression Segmentation",
    "authors": [
      "Yi-Chia Chen",
      "Wei-Hua Li",
      "Cheng Sun",
      "Yu-Chiang Frank Wang",
      "Chu-Song Chen"
    ],
    "abstract": "We introduce SAM4MLLM, an innovative approach which integrates the Segment\nAnything Model (SAM) with Multi-Modal Large Language Models (MLLMs) for\npixel-aware tasks. Our method enables MLLMs to learn pixel-level location\ninformation without requiring excessive modifications to the existing model\narchitecture or adding specialized tokens. We introduce an inquiry-based\napproach that can effectively find prompt points for SAM to perform\nsegmentation based on MLLM. It combines detailed visual information with the\npowerful expressive capabilities of large language models in a unified\nlanguage-based manner without additional computational overhead in learning.\nExperimental results on pubic benchmarks demonstrate the effectiveness of our\napproach.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.CV"
    ],
    "primary_category": "cs.AI",
    "comment": "ECCV 2024",
    "pdf_url": "http://arxiv.org/pdf/2409.10542v3",
    "published_date": "2024-09-01 12:09:33 UTC",
    "updated_date": "2024-12-14 03:18:34 UTC"
  },
  {
    "arxiv_id": "2409.00700v1",
    "title": "Seeing Your Speech Style: A Novel Zero-Shot Identity-Disentanglement Face-based Voice Conversion",
    "authors": [
      "Yan Rong",
      "Li Liu"
    ],
    "abstract": "Face-based Voice Conversion (FVC) is a novel task that leverages facial\nimages to generate the target speaker's voice style. Previous work has two\nshortcomings: (1) suffering from obtaining facial embeddings that are\nwell-aligned with the speaker's voice identity information, and (2) inadequacy\nin decoupling content and speaker identity information from the audio input. To\naddress these issues, we present a novel FVC method, Identity-Disentanglement\nFace-based Voice Conversion (ID-FaceVC), which overcomes the above two\nlimitations. More precisely, we propose an Identity-Aware Query-based\nContrastive Learning (IAQ-CL) module to extract speaker-specific facial\nfeatures, and a Mutual Information-based Dual Decoupling (MIDD) module to\npurify content features from audio, ensuring clear and high-quality voice\nconversion. Besides, unlike prior works, our method can accept either audio or\ntext inputs, offering controllable speech generation with adjustable emotional\ntone and speed. Extensive experiments demonstrate that ID-FaceVC achieves\nstate-of-the-art performance across various metrics, with qualitative and user\nstudy results confirming its effectiveness in naturalness, similarity, and\ndiversity. Project website with audio samples and code can be found at\nhttps://id-facevc.github.io.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.CV",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.00700v1",
    "published_date": "2024-09-01 11:51:18 UTC",
    "updated_date": "2024-09-01 11:51:18 UTC"
  },
  {
    "arxiv_id": "2409.00696v3",
    "title": "Polyrating: A Cost-Effective and Bias-Aware Rating System for LLM Evaluation",
    "authors": [
      "Jasper Dekoninck",
      "Maximilian Baader",
      "Martin Vechev"
    ],
    "abstract": "Rating-based human evaluation has become an essential tool to accurately\nevaluate the impressive performance of large language models (LLMs). However,\ncurrent rating systems suffer from several important limitations: first, they\nfail to account for biases that significantly influence evaluation results,\nsecond, they require large and expensive preference datasets to obtain accurate\nratings, and third, they do not facilitate meaningful comparisons of model\nratings across different tasks. To address these issues, we introduce\nPolyrating, an expressive and flexible rating system based on maximum a\nposteriori estimation that enables a more nuanced and thorough analysis of\nmodel performance at lower costs. Polyrating can detect and quantify biases\naffecting human preferences, ensuring fairer model comparisons. Further,\nPolyrating can reduce the cost of human evaluations by up to $41\\%$ for new\nmodels and up to $77\\%$ for new tasks by leveraging existing benchmark scores.\nLastly, Polyrating enables direct comparisons of ratings across different\ntasks, providing a comprehensive understanding of an LLMs' strengths,\nweaknesses, and relative performance across different applications.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.00696v3",
    "published_date": "2024-09-01 11:24:54 UTC",
    "updated_date": "2025-02-11 12:21:13 UTC"
  },
  {
    "arxiv_id": "2409.00695v1",
    "title": "Curriculum Prompting Foundation Models for Medical Image Segmentation",
    "authors": [
      "Xiuqi Zheng",
      "Yuhang Zhang",
      "Haoran Zhang",
      "Hongrui Liang",
      "Xueqi Bao",
      "Zhuqing Jiang",
      "Qicheng Lao"
    ],
    "abstract": "Adapting large pre-trained foundation models, e.g., SAM, for medical image\nsegmentation remains a significant challenge. A crucial step involves the\nformulation of a series of specialized prompts that incorporate specific\nclinical instructions. Past works have been heavily reliant on a singular type\nof prompt for each instance, necessitating manual input of an ideally correct\nprompt, which is less efficient. To tackle this issue, we propose to utilize\nprompts of different granularity, which are sourced from original images to\nprovide a broader scope of clinical insights. However, combining prompts of\nvarying types can pose a challenge due to potential conflicts. In response, we\nhave designed a coarse-to-fine mechanism, referred to as curriculum prompting,\nthat progressively integrates prompts of different types. Through extensive\nexperiments on three public medical datasets across various modalities, we\ndemonstrate the effectiveness of our proposed approach, which not only\nautomates the prompt generation process but also yields superior performance\ncompared to other SAM-based medical image segmentation methods. Code is\navailable at: https://github.com/AnnaZzz-zxq/Curriculum-Prompting.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted by MICCAI 2024",
    "pdf_url": "http://arxiv.org/pdf/2409.00695v1",
    "published_date": "2024-09-01 11:00:18 UTC",
    "updated_date": "2024-09-01 11:00:18 UTC"
  },
  {
    "arxiv_id": "2409.00687v1",
    "title": "When Heterophily Meets Heterogeneous Graphs: Latent Graphs Guided Unsupervised Representation Learning",
    "authors": [
      "Zhixiang Shen",
      "Zhao Kang"
    ],
    "abstract": "Unsupervised heterogeneous graph representation learning (UHGRL) has gained\nincreasing attention due to its significance in handling practical graphs\nwithout labels. However, heterophily has been largely ignored, despite its\nubiquitous presence in real-world heterogeneous graphs. In this paper, we\ndefine semantic heterophily and propose an innovative framework called Latent\nGraphs Guided Unsupervised Representation Learning (LatGRL) to handle this\nproblem. First, we develop a similarity mining method that couples global\nstructures and attributes, enabling the construction of fine-grained homophilic\nand heterophilic latent graphs to guide the representation learning. Moreover,\nwe propose an adaptive dual-frequency semantic fusion mechanism to address the\nproblem of node-level semantic heterophily. To cope with the massive scale of\nreal-world data, we further design a scalable implementation. Extensive\nexperiments on benchmark datasets validate the effectiveness and efficiency of\nour proposed framework. The source code and datasets have been made available\nat https://github.com/zxlearningdeep/LatGRL.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.SI"
    ],
    "primary_category": "cs.LG",
    "comment": "14 pages",
    "pdf_url": "http://arxiv.org/pdf/2409.00687v1",
    "published_date": "2024-09-01 10:25:06 UTC",
    "updated_date": "2024-09-01 10:25:06 UTC"
  },
  {
    "arxiv_id": "2409.10541v1",
    "title": "Adapting to the AI Disruption: Reshaping the IT Landscape and Educational Paradigms",
    "authors": [
      "Murat Ozer",
      "Yasin Kose",
      "Goksel Kucukkaya",
      "Assel Mukasheva",
      "Kazim Ciris"
    ],
    "abstract": "Artificial intelligence (AI) signals the beginning of a revolutionary period\nwhere technological advancement and social change interact to completely\nreshape economies, work paradigms, and industries worldwide. This essay\naddresses the opportunities and problems brought about by the AI-driven economy\nas it examines the effects of AI disruption on the IT sector and information\ntechnology education. By comparing the current AI revolution to previous\nindustrial revolutions, we investigate the significant effects of AI\ntechnologies on workforce dynamics, employment, and organizational procedures.\nHuman-centered design principles and ethical considerations become crucial\nrequirements for the responsible development and implementation of AI systems\nin the face of the field's rapid advancements. IT education programs must\nchange to meet the changing demands of the AI era and give students the skills\nand competencies they need to succeed in a digital world that is changing\nquickly. In light of AI-driven automation, we also examine the possible\nadvantages and difficulties of moving to a shorter workweek, emphasizing\nchances to improve worker productivity, well-being, and work-life balance. We\ncan build a more incslusive and sustainable future for the IT industry and\nbeyond, enhancing human capabilities, advancing collective well-being, and\nfostering a society where AI serves as a force for good by embracing the\nopportunities presented by AI while proactively addressing its challenges.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "Submitted and accepted for CSCE'24: July 22-25, 2024",
    "pdf_url": "http://arxiv.org/pdf/2409.10541v1",
    "published_date": "2024-09-01 09:39:25 UTC",
    "updated_date": "2024-09-01 09:39:25 UTC"
  },
  {
    "arxiv_id": "2409.00667v1",
    "title": "Comprehensive Botnet Detection by Mitigating Adversarial Attacks, Navigating the Subtleties of Perturbation Distances and Fortifying Predictions with Conformal Layers",
    "authors": [
      "Rahul Yumlembam",
      "Biju Issac",
      "Seibu Mary Jacob",
      "Longzhi Yang"
    ],
    "abstract": "Botnets are computer networks controlled by malicious actors that present\nsignificant cybersecurity challenges. They autonomously infect, propagate, and\ncoordinate to conduct cybercrimes, necessitating robust detection methods. This\nresearch addresses the sophisticated adversarial manipulations posed by\nattackers, aiming to undermine machine learning-based botnet detection systems.\nWe introduce a flow-based detection approach, leveraging machine learning and\ndeep learning algorithms trained on the ISCX and ISOT datasets. The detection\nalgorithms are optimized using the Genetic Algorithm and Particle Swarm\nOptimization to obtain a baseline detection method. The Carlini & Wagner (C&W)\nattack and Generative Adversarial Network (GAN) generate deceptive data with\nsubtle perturbations, targeting each feature used for classification while\npreserving their semantic and syntactic relationships, which ensures that the\nadversarial samples retain meaningfulness and realism. An in-depth analysis of\nthe required L2 distance from the original sample for the malware sample to\nmisclassify is performed across various iteration checkpoints, showing\ndifferent levels of misclassification at different L2 distances of the Pertrub\nsample from the original sample. Our work delves into the vulnerability of\nvarious models, examining the transferability of adversarial examples from a\nNeural Network surrogate model to Tree-based algorithms. Subsequently, models\nthat initially misclassified the perturbed samples are retrained, enhancing\ntheir resilience and detection capabilities. In the final phase, a conformal\nprediction layer is integrated, significantly rejecting incorrect predictions,\nof 58.20 % in the ISCX dataset and 98.94 % in the ISOT dataset.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "46 pages",
    "pdf_url": "http://arxiv.org/pdf/2409.00667v1",
    "published_date": "2024-09-01 08:53:21 UTC",
    "updated_date": "2024-09-01 08:53:21 UTC"
  },
  {
    "arxiv_id": "2409.00658v1",
    "title": "Nasdaq-100 Companies' Hiring Insights: A Topic-based Classification Approach to the Labor Market",
    "authors": [
      "Seyed Mohammad Ali Jafari",
      "Ehsan Chitsaz"
    ],
    "abstract": "The emergence of new and disruptive technologies makes the economy and labor\nmarket more unstable. To overcome this kind of uncertainty and to make the\nlabor market more comprehensible, we must employ labor market intelligence\ntechniques, which are predominantly based on data analysis. Companies use job\nposting sites to advertise their job vacancies, known as online job vacancies\n(OJVs). LinkedIn is one of the most utilized websites for matching the supply\nand demand sides of the labor market; companies post their job vacancies on\ntheir job pages, and LinkedIn recommends these jobs to job seekers who are\nlikely to be interested. However, with the vast number of online job vacancies,\nit becomes challenging to discern overarching trends in the labor market. In\nthis paper, we propose a data mining-based approach for job classification in\nthe modern online labor market. We employed structural topic modeling as our\nmethodology and used the NASDAQ-100 indexed companies' online job vacancies on\nLinkedIn as the input data. We discover that among all 13 job categories,\nMarketing, Branding, and Sales; Software Engineering; Hardware Engineering;\nIndustrial Engineering; and Project Management are the most frequently posted\njob classifications. This study aims to provide a clearer understanding of job\nmarket trends, enabling stakeholders to make informed decisions in a rapidly\nevolving employment landscape.",
    "categories": [
      "econ.GN",
      "cs.AI",
      "q-fin.EC"
    ],
    "primary_category": "econ.GN",
    "comment": "17 pages, 4 figures, 1 table. Presented at the International\n  Conference on Optimization and Data Science in Industrial Engineering (ODSIE\n  2023)",
    "pdf_url": "http://arxiv.org/pdf/2409.00658v1",
    "published_date": "2024-09-01 08:18:56 UTC",
    "updated_date": "2024-09-01 08:18:56 UTC"
  },
  {
    "arxiv_id": "2409.00639v1",
    "title": "Artificial Intelligence in Gastrointestinal Bleeding Analysis for Video Capsule Endoscopy: Insights, Innovations, and Prospects (2008-2023)",
    "authors": [
      "Tanisha Singh",
      "Shreshtha Jha",
      "Nidhi Bhatt",
      "Palak Handa",
      "Nidhi Goel",
      "Sreedevi Indu"
    ],
    "abstract": "The escalating global mortality and morbidity rates associated with\ngastrointestinal (GI) bleeding, compounded by the complexities and limitations\nof traditional endoscopic methods, underscore the urgent need for a critical\nreview of current methodologies used for addressing this condition. With an\nestimated 300,000 annual deaths worldwide, the demand for innovative diagnostic\nand therapeutic strategies is paramount. The introduction of Video Capsule\nEndoscopy (VCE) has marked a significant advancement, offering a comprehensive,\nnon-invasive visualization of the digestive tract that is pivotal for detecting\nbleeding sources unattainable by traditional methods. Despite its benefits, the\nefficacy of VCE is hindered by diagnostic challenges, including time-consuming\nanalysis and susceptibility to human error. This backdrop sets the stage for\nexploring Machine Learning (ML) applications in automating GI bleeding\ndetection within capsule endoscopy, aiming to enhance diagnostic accuracy,\nreduce manual labor, and improve patient outcomes. Through an exhaustive\nanalysis of 113 papers published between 2008 and 2023, this review assesses\nthe current state of ML methodologies in bleeding detection, highlighting their\neffectiveness, challenges, and prospective directions. It contributes an\nin-depth examination of AI techniques in VCE frame analysis, offering insights\ninto open-source datasets, mathematical performance metrics, and technique\ncategorization. The paper sets a foundation for future research to overcome\nexisting challenges, advancing gastrointestinal diagnostics through\ninterdisciplinary collaboration and innovation in ML applications.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.00639v1",
    "published_date": "2024-09-01 07:13:28 UTC",
    "updated_date": "2024-09-01 07:13:28 UTC"
  },
  {
    "arxiv_id": "2409.02124v1",
    "title": "TrajWeaver: Trajectory Recovery with State Propagation Diffusion Model",
    "authors": [
      "Jinming Wang",
      "Hai Wang",
      "Hongkai Wen",
      "Geyong Min",
      "Man Luo"
    ],
    "abstract": "With the proliferation of location-aware devices, large amount of\ntrajectories have been generated when agents such as people, vehicles and goods\nflow around the urban environment. These raw trajectories, typically collected\nfrom various sources such as GPS in cars, personal mobile devices, and public\ntransport, are often sparse and fragmented due to limited sampling rates,\ninfrastructure coverage and data loss. In this context, trajectory recovery\naims to reconstruct such sparse raw trajectories into their dense and\ncontinuous counterparts, so that fine-grained movement of agents across space\nand time can be captured faithfully. Existing trajectory recovery approaches\ntypically rely on the prior knowledge of travel mode or motion patterns, and\noften fail in densely populated urban areas where accurate maps are absent. In\nthis paper, we present a new recovery framework called TrajWeaver based on\nprobabilistic diffusion models, which is able to recover dense and refined\ntrajectories from the sparse raw ones, conditioned on various auxiliary\nfeatures such as Areas of Interest along the way, user identity and waybill\ninformation. The core of TrajWeaver is a novel State Propagation Diffusion\nModel (SPDM), which introduces a new state propagation mechanism on top of the\nstandard diffusion models, so that knowledge computed in earlier diffusion\nsteps can be reused later, improving the recovery performance while reducing\nthe number of steps needed. Extensive experiments show that the proposed\nTrajWeaver can recover from raw trajectories of various lengths, sparsity\nlevels and heterogeneous travel modes, and outperform the state-of-the-art\nbaselines significantly in recovery accuracy. Our code is available at:\nhttps://anonymous.4open.science/r/TrajWeaver/",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "First submission, extended to 10 pages include ref",
    "pdf_url": "http://arxiv.org/pdf/2409.02124v1",
    "published_date": "2024-09-01 06:42:19 UTC",
    "updated_date": "2024-09-01 06:42:19 UTC"
  },
  {
    "arxiv_id": "2409.02123v2",
    "title": "PuYun: Medium-Range Global Weather Forecasting Using Large Kernel Attention Convolutional Networks",
    "authors": [
      "Shengchen Zhu",
      "Yiming Chen",
      "Peiying Yu",
      "Xiang Qu",
      "Yuxiao Zhou",
      "Yiming Ma",
      "Zhizhan Zhao",
      "Yukai Liu",
      "Hao Mi",
      "Bin Wang"
    ],
    "abstract": "Accurate weather forecasting is essential for understanding and mitigating\nweather-related impacts. In this paper, we present PuYun, an autoregressive\ncascade model that leverages large kernel attention convolutional networks. The\nmodel's design inherently supports extended weather prediction horizons while\nbroadening the effective receptive field. The integration of large kernel\nattention mechanisms within the convolutional layers enhances the model's\ncapacity to capture fine-grained spatial details, thereby improving its\npredictive accuracy for meteorological phenomena.\n  We introduce PuYun, comprising PuYun-Short for 0-5 day forecasts and\nPuYun-Medium for 5-10 day predictions. This approach enhances the accuracy of\n10-day weather forecasting. Through evaluation, we demonstrate that PuYun-Short\nalone surpasses the performance of both GraphCast and FuXi-Short in generating\naccurate 10-day forecasts. Specifically, on the 10th day, PuYun-Short reduces\nthe RMSE for Z500 to 720 $m^2/s^2$, compared to 732 $m^2/s^2$ for GraphCast and\n740 $m^2/s^2$ for FuXi-Short. Additionally, the RMSE for T2M is reduced to 2.60\nK, compared to 2.63 K for GraphCast and 2.65 K for FuXi-Short. Furthermore,\nwhen employing a cascaded approach by integrating PuYun-Short and PuYun-Medium,\nour method achieves superior results compared to the combined performance of\nFuXi-Short and FuXi-Medium. On the 10th day, the RMSE for Z500 is further\nreduced to 638 $m^2/s^2$, compared to 641 $m^2/s^2$ for FuXi. These findings\nunderscore the effectiveness of our model ensemble in advancing medium-range\nweather prediction. Our training code and model will be open-sourced.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "physics.ao-ph"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.02123v2",
    "published_date": "2024-09-01 06:25:35 UTC",
    "updated_date": "2024-09-12 06:08:03 UTC"
  },
  {
    "arxiv_id": "2409.02122v1",
    "title": "Deep Knowledge-Infusion For Explainable Depression Detection",
    "authors": [
      "Sumit Dalal",
      "Sarika Jain",
      "Mayank Dave"
    ],
    "abstract": "Discovering individuals depression on social media has become increasingly\nimportant. Researchers employed ML/DL or lexicon-based methods for automated\ndepression detection. Lexicon based methods, explainable and easy to implement,\nmatch words from user posts in a depression dictionary without considering\ncontexts. While the DL models can leverage contextual information, their\nblack-box nature limits their adoption in the domain. Though surrogate models\nlike LIME and SHAP can produce explanations for DL models, the explanations are\nsuitable for the developer and of limited use to the end user. We propose a\nKnolwedge-infused Neural Network (KiNN) incorporating domain-specific knowledge\nfrom DepressionFeature ontology (DFO) in a neural network to endow the model\nwith user-level explainability regarding concepts and processes the clinician\nunderstands. Further, commonsense knowledge from the Commonsense Transformer\n(COMET) trained on ATOMIC is also infused to consider the generic emotional\naspects of user posts in depression detection. The model is evaluated on three\nexpertly curated datasets related to depression. We observed the model to have\na statistically significant (p<0.1) boost in performance over the best\ndomain-specific model, MentalBERT, across CLEF e-Risk (25% MCC increase, 12% F1\nincrease). A similar trend is observed across the PRIMATE dataset, where the\nproposed model performed better than MentalBERT (2.5% MCC increase, 19% F1\nincrease). The observations confirm the generated explanations to be\ninformative for MHPs compared to post hoc model explanations. Results\ndemonstrated that the user-level explainability of KiNN also surpasses the\nperformance of baseline models and can provide explanations where other\nbaselines fall short. Infusing the domain and commonsense knowledge in KiNN\nenhances the ability of models like GPT-3.5 to generate application-relevant\nexplanations.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "13 pages, 2 figures",
    "pdf_url": "http://arxiv.org/pdf/2409.02122v1",
    "published_date": "2024-09-01 06:13:55 UTC",
    "updated_date": "2024-09-01 06:13:55 UTC"
  },
  {
    "arxiv_id": "2409.00625v2",
    "title": "Entity-Aware Biaffine Attention Model for Improved Constituent Parsing with Reduced Entity Violations",
    "authors": [
      "Xinyi Bai"
    ],
    "abstract": "Constituency parsing involves analyzing a sentence by breaking it into\nsub-phrases, or constituents. While many deep neural models have achieved\nstate-of-the-art performance in this task, they often overlook the\nentity-violating issue, where an entity fails to form a complete sub-tree in\nthe resultant parsing tree. To address this, we propose an entity-aware\nbiaffine attention model for constituent parsing. This model incorporates\nentity information into the biaffine attention mechanism by using additional\nentity role vectors for potential phrases, which enhances the parsing accuracy.\nWe introduce a new metric, the Entity Violating Rate (EVR), to quantify the\nextent of entity violations in parsing results. Experiments on three popular\ndatasets-ONTONOTES, PTB, and CTB-demonstrate that our model achieves the lowest\nEVR while maintaining high precision, recall, and F1-scores comparable to\nexisting models. Further evaluation in downstream tasks, such as sentence\nsentiment analysis, highlights the effectiveness of our model and the validity\nof the proposed EVR metric.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.00625v2",
    "published_date": "2024-09-01 05:59:54 UTC",
    "updated_date": "2024-11-12 01:47:40 UTC"
  },
  {
    "arxiv_id": "2409.00622v1",
    "title": "Roundabout Dilemma Zone Data Mining and Forecasting with Trajectory Prediction and Graph Neural Networks",
    "authors": [
      "Manthan Chelenahalli Satish",
      "Duo Lu",
      "Bharatesh Chakravarthi",
      "Mohammad Farhadi",
      "Yezhou Yang"
    ],
    "abstract": "Traffic roundabouts, as complex and critical road scenarios, pose significant\nsafety challenges for autonomous vehicles. In particular, the encounter of a\nvehicle with a dilemma zone (DZ) at a roundabout intersection is a pivotal\nconcern. This paper presents an automated system that leverages trajectory\nforecasting to predict DZ events, specifically at traffic roundabouts. Our\nsystem aims to enhance safety standards in both autonomous and manual\ntransportation. The core of our approach is a modular, graph-structured\nrecurrent model that forecasts the trajectories of diverse agents, taking into\naccount agent dynamics and integrating heterogeneous data, such as semantic\nmaps. This model, based on graph neural networks, aids in predicting DZ events\nand enhances traffic management decision-making. We evaluated our system using\na real-world dataset of traffic roundabout intersections. Our experimental\nresults demonstrate that our dilemma forecasting system achieves a high\nprecision with a low false positive rate of 0.1. This research represents an\nadvancement in roundabout DZ data mining and forecasting, contributing to the\nassurance of intersection safety in the era of autonomous vehicles.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.00622v1",
    "published_date": "2024-09-01 05:47:58 UTC",
    "updated_date": "2024-09-01 05:47:58 UTC"
  },
  {
    "arxiv_id": "2409.00620v1",
    "title": "Enhancing Vectorized Map Perception with Historical Rasterized Maps",
    "authors": [
      "Xiaoyu Zhang",
      "Guangwei Liu",
      "Zihao Liu",
      "Ningyi Xu",
      "Yunhui Liu",
      "Ji Zhao"
    ],
    "abstract": "In autonomous driving, there is growing interest in end-to-end online\nvectorized map perception in bird's-eye-view (BEV) space, with an expectation\nthat it could replace traditional high-cost offline high-definition (HD) maps.\nHowever, the accuracy and robustness of these methods can be easily compromised\nin challenging conditions, such as occlusion or adverse weather, when relying\nonly on onboard sensors. In this paper, we propose HRMapNet, leveraging a\nlow-cost Historical Rasterized Map to enhance online vectorized map perception.\nThe historical rasterized map can be easily constructed from past predicted\nvectorized results and provides valuable complementary information. To fully\nexploit a historical map, we propose two novel modules to enhance BEV features\nand map element queries. For BEV features, we employ a feature aggregation\nmodule to encode features from both onboard images and the historical map. For\nmap element queries, we design a query initialization module to endow queries\nwith priors from the historical map. The two modules contribute to leveraging\nmap information in online perception. Our HRMapNet can be integrated with most\nonline vectorized map perception methods. We integrate it in two\nstate-of-the-art methods, significantly improving their performance on both the\nnuScenes and Argoverse 2 datasets. The source code is released at\nhttps://github.com/HXMap/HRMapNet.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted by ECCV 2024",
    "pdf_url": "http://arxiv.org/pdf/2409.00620v1",
    "published_date": "2024-09-01 05:22:33 UTC",
    "updated_date": "2024-09-01 05:22:33 UTC"
  },
  {
    "arxiv_id": "2409.00617v1",
    "title": "Does Knowledge Localization Hold True? Surprising Differences Between Entity and Relation Perspectives in Language Models",
    "authors": [
      "Yifan Wei",
      "Xiaoyan Yu",
      "Yixuan Weng",
      "Huanhuan Ma",
      "Yuanzhe Zhang",
      "Jun Zhao",
      "Kang Liu"
    ],
    "abstract": "Large language models encapsulate knowledge and have demonstrated superior\nperformance on various natural language processing tasks. Recent studies have\nlocalized this knowledge to specific model parameters, such as the MLP weights\nin intermediate layers. This study investigates the differences between entity\nand relational knowledge through knowledge editing. Our findings reveal that\nentity and relational knowledge cannot be directly transferred or mapped to\neach other. This result is unexpected, as logically, modifying the entity or\nthe relation within the same knowledge triplet should yield equivalent\noutcomes. To further elucidate the differences between entity and relational\nknowledge, we employ causal analysis to investigate how relational knowledge is\nstored in pre-trained models. Contrary to prior research suggesting that\nknowledge is stored in MLP weights, our experiments demonstrate that relational\nknowledge is also significantly encoded in attention modules. This insight\nhighlights the multifaceted nature of knowledge storage in language models,\nunderscoring the complexity of manipulating specific types of knowledge within\nthese models.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "CIKM 2024",
    "pdf_url": "http://arxiv.org/pdf/2409.00617v1",
    "published_date": "2024-09-01 05:09:11 UTC",
    "updated_date": "2024-09-01 05:09:11 UTC"
  },
  {
    "arxiv_id": "2409.00614v1",
    "title": "DAMe: Personalized Federated Social Event Detection with Dual Aggregation Mechanism",
    "authors": [
      "Xiaoyan Yu",
      "Yifan Wei",
      "Pu Li",
      "Shuaishuai Zhou",
      "Hao Peng",
      "Li Sun",
      "Liehuang Zhu",
      "Philip S. Yu"
    ],
    "abstract": "Training social event detection models through federated learning (FedSED)\naims to improve participants' performance on the task. However, existing\nfederated learning paradigms are inadequate for achieving FedSED's objective\nand exhibit limitations in handling the inherent heterogeneity in social data.\nThis paper proposes a personalized federated learning framework with a dual\naggregation mechanism for social event detection, namely DAMe. We present a\nnovel local aggregation strategy utilizing Bayesian optimization to incorporate\nglobal knowledge while retaining local characteristics. Moreover, we introduce\na global aggregation strategy to provide clients with maximum external\nknowledge of their preferences. In addition, we incorporate a global-local\nevent-centric constraint to prevent local overfitting and ``client-drift''.\nExperiments within a realistic simulation of a natural federated setting,\nutilizing six social event datasets spanning six languages and two social media\nplatforms, along with an ablation study, have demonstrated the effectiveness of\nthe proposed framework. Further robustness analyses have shown that DAMe is\nresistant to injection attacks.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "CIKM 2024",
    "pdf_url": "http://arxiv.org/pdf/2409.00614v1",
    "published_date": "2024-09-01 04:56:41 UTC",
    "updated_date": "2024-09-01 04:56:41 UTC"
  },
  {
    "arxiv_id": "2409.00592v3",
    "title": "Hyper-Compression: Model Compression via Hyperfunction",
    "authors": [
      "Fenglei Fan",
      "Juntong Fan",
      "Dayang Wang",
      "Jingbo Zhang",
      "Zelin Dong",
      "Shijun Zhang",
      "Ge Wang",
      "Tieyong Zeng"
    ],
    "abstract": "The rapid growth of large models' size has far outpaced that of computing\nresources. To bridge this gap, encouraged by the parsimonious relationship\nbetween genotype and phenotype in the brain's growth and development, we\npropose the so-called hyper-compression that turns the model compression into\nthe issue of parameter representation via a hyperfunction. Specifically, it is\nknown that the trajectory of some low-dimensional dynamic systems can fill the\nhigh-dimensional space eventually. Thus, hyper-compression, using these dynamic\nsystems as the hyperfunctions, represents the parameters of the target network\nby their corresponding composition number or trajectory length. This suggests a\nnovel mechanism for model compression, substantially different from the\nexisting pruning, quantization, distillation, and decomposition. Along this\ndirection, we methodologically identify a suitable dynamic system with the\nirrational winding as the hyperfunction and theoretically derive its associated\nerror bound. Next, guided by our theoretical insights, we propose several\nengineering twists to make the hyper-compression pragmatic and effective.\nLastly, systematic and comprehensive experiments confirm that hyper-compression\nenjoys the following \\textbf{PNAS} merits: 1) \\textbf{P}referable compression\nratio; 2) \\textbf{N}o post-hoc retraining; 3) \\textbf{A}ffordable inference\ntime; and 4) \\textbf{S}hort compression time. It compresses LLaMA2-7B in an\nhour and achieves close-to-int4-quantization performance, without retraining\nand with a performance drop of less than 1\\%. We have open-sourced our code in\nhttps://github.com/Juntongkuki/Hyper-Compression.git for free download and\nevaluation.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.ET"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.00592v3",
    "published_date": "2024-09-01 02:57:41 UTC",
    "updated_date": "2025-04-02 13:58:50 UTC"
  },
  {
    "arxiv_id": "2409.00584v1",
    "title": "FastBO: Fast HPO and NAS with Adaptive Fidelity Identification",
    "authors": [
      "Jiantong Jiang",
      "Ajmal Mian"
    ],
    "abstract": "Hyperparameter optimization (HPO) and neural architecture search (NAS) are\npowerful in attaining state-of-the-art machine learning models, with Bayesian\noptimization (BO) standing out as a mainstream method. Extending BO into the\nmulti-fidelity setting has been an emerging research topic, but faces the\nchallenge of determining an appropriate fidelity for each hyperparameter\nconfiguration to fit the surrogate model. To tackle the challenge, we propose a\nmulti-fidelity BO method named FastBO, which adaptively decides the fidelity\nfor each configuration and efficiently offers strong performance. The\nadvantages are achieved based on the novel concepts of efficient point and\nsaturation point for each configuration.We also show that our adaptive fidelity\nidentification strategy provides a way to extend any single-fidelity method to\nthe multi-fidelity setting, highlighting its generality and applicability.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "The 18th European Conference on Computer Vision ECCV 2024 Women in\n  Computer Vision Workshop",
    "pdf_url": "http://arxiv.org/pdf/2409.00584v1",
    "published_date": "2024-09-01 02:40:04 UTC",
    "updated_date": "2024-09-01 02:40:04 UTC"
  },
  {
    "arxiv_id": "2409.00571v1",
    "title": "Enhancing Source Code Security with LLMs: Demystifying The Challenges and Generating Reliable Repairs",
    "authors": [
      "Nafis Tanveer Islam",
      "Joseph Khoury",
      "Andrew Seong",
      "Elias Bou-Harb",
      "Peyman Najafirad"
    ],
    "abstract": "With the recent unprecedented advancements in Artificial Intelligence (AI)\ncomputing, progress in Large Language Models (LLMs) is accelerating rapidly,\npresenting challenges in establishing clear guidelines, particularly in the\nfield of security. That being said, we thoroughly identify and describe three\nmain technical challenges in the security and software engineering literature\nthat spans the entire LLM workflow, namely; \\textbf{\\textit{(i)}} Data\nCollection and Labeling; \\textbf{\\textit{(ii)}} System Design and Learning; and\n\\textbf{\\textit{(iii)}} Performance Evaluation. Building upon these challenges,\nthis paper introduces \\texttt{SecRepair}, an instruction-based LLM system\ndesigned to reliably \\textit{identify}, \\textit{describe}, and automatically\n\\textit{repair} vulnerable source code. Our system is accompanied by a list of\nactionable guides on \\textbf{\\textit{(i)}} Data Preparation and Augmentation\nTechniques; \\textbf{\\textit{(ii)}} Selecting and Adapting state-of-the-art LLM\nModels; \\textbf{\\textit{(iii)}} Evaluation Procedures. \\texttt{SecRepair} uses\na reinforcement learning-based fine-tuning with a semantic reward that caters\nto the functionality and security aspects of the generated code. Our empirical\nanalysis shows that \\texttt{SecRepair} achieves a \\textit{12}\\% improvement in\nsecurity code repair compared to other LLMs when trained using reinforcement\nlearning. Furthermore, we demonstrate the capabilities of \\texttt{SecRepair} in\ngenerating reliable, functional, and compilable security code repairs against\nreal-world test cases using automated evaluation metrics.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.00571v1",
    "published_date": "2024-09-01 00:41:40 UTC",
    "updated_date": "2024-09-01 00:41:40 UTC"
  }
]