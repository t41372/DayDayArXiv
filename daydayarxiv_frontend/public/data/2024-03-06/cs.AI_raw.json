[
  {
    "arxiv_id": "2403.04106v1",
    "title": "Understanding Biology in the Age of Artificial Intelligence",
    "authors": [
      "Elsa Lawrence",
      "Adham El-Shazly",
      "Srijit Seal",
      "Chaitanya K Joshi",
      "Pietro Li√≤",
      "Shantanu Singh",
      "Andreas Bender",
      "Pietro Sormanni",
      "Matthew Greenig"
    ],
    "abstract": "Modern life sciences research is increasingly relying on artificial\nintelligence approaches to model biological systems, primarily centered around\nthe use of machine learning (ML) models. Although ML is undeniably useful for\nidentifying patterns in large, complex data sets, its widespread application in\nbiological sciences represents a significant deviation from traditional methods\nof scientific inquiry. As such, the interplay between these models and\nscientific understanding in biology is a topic with important implications for\nthe future of scientific research, yet it is a subject that has received little\nattention. Here, we draw from an epistemological toolkit to contextualize\nrecent applications of ML in biological sciences under modern philosophical\ntheories of understanding, identifying general principles that can guide the\ndesign and application of ML systems to model biological phenomena and advance\nscientific knowledge. We propose that conceptions of scientific understanding\nas information compression, qualitative intelligibility, and dependency\nrelation modelling provide a useful framework for interpreting ML-mediated\nunderstanding of biological systems. Through a detailed analysis of two key\napplication areas of ML in modern biological research - protein structure\nprediction and single cell RNA-sequencing - we explore how these features have\nthus far enabled ML systems to advance scientific understanding of their target\nphenomena, how they may guide the development of future ML models, and the key\nobstacles that remain in preventing ML from achieving its potential as a tool\nfor biological discovery. Consideration of the epistemological features of ML\napplications in biology will improve the prospects of these methods to solve\nimportant problems and advance scientific understanding of living systems.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.04106v1",
    "published_date": "2024-03-06 23:20:34 UTC",
    "updated_date": "2024-03-06 23:20:34 UTC"
  },
  {
    "arxiv_id": "2403.04105v3",
    "title": "Natural Language Processing in the Patent Domain: A Survey",
    "authors": [
      "Lekang Jiang",
      "Stephan Goetz"
    ],
    "abstract": "Patents, which encapsulate crucial technical and legal information in text\nform and referenced drawings, present a rich domain for natural language\nprocessing (NLP) applications. As NLP technologies evolve, large language\nmodels (LLMs) have demonstrated outstanding capabilities in general text\nprocessing and generation tasks. However, the application of LLMs in the patent\ndomain remains under-explored and under-developed due to the complexity of\npatents, particularly their language and legal framework. Understanding the\nunique characteristics of patent documents and related research in the patent\ndomain becomes essential for researchers to apply these tools effectively.\nTherefore, this paper aims to equip NLP researchers with the essential\nknowledge to navigate this complex domain efficiently. We introduce the\nrelevant fundamental aspects of patents to provide solid background\ninformation. In addition, we systematically break down the structural and\nlinguistic characteristics unique to patents and map out how NLP can be\nleveraged for patent analysis and generation. Moreover, we demonstrate the\nspectrum of text-based and multimodal patent-related tasks, including nine\npatent analysis and four patent generation tasks.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Published in Artificial Intelligence Review",
    "pdf_url": "http://arxiv.org/pdf/2403.04105v3",
    "published_date": "2024-03-06 23:17:16 UTC",
    "updated_date": "2025-04-23 16:48:56 UTC"
  },
  {
    "arxiv_id": "2403.04087v1",
    "title": "The Cognitive Type Project -- Mapping Typography to Cognition",
    "authors": [
      "Nik Bear Brown"
    ],
    "abstract": "The Cognitive Type Project is focused on developing computational tools to\nenable the design of typefaces with varying cognitive properties. This\ninitiative aims to empower typographers to craft fonts that enhance\nclick-through rates for online ads, improve reading levels in children's books,\nenable dyslexics to create personalized type, or provide insights into customer\nreactions to textual content in media. A significant challenge in research\nrelated to mapping typography to cognition is the creation of thousands of\ntypefaces with minor variations, a process that is both labor-intensive and\nrequires the expertise of skilled typographers. Cognitive science research\nhighlights that the design and form of letters, along with the text's overall\nlayout, are crucial in determining the ease of reading and other cognitive\nproperties of type such as perceived beauty and memorability. These factors\naffect not only the legibility and clarity of information presentation but also\nthe likability of a typeface.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.04087v1",
    "published_date": "2024-03-06 22:32:49 UTC",
    "updated_date": "2024-03-06 22:32:49 UTC"
  },
  {
    "arxiv_id": "2403.04073v1",
    "title": "Semi-Supervised Dialogue Abstractive Summarization via High-Quality Pseudolabel Selection",
    "authors": [
      "Jianfeng He",
      "Hang Su",
      "Jason Cai",
      "Igor Shalyminov",
      "Hwanjun Song",
      "Saab Mansour"
    ],
    "abstract": "Semi-supervised dialogue summarization (SSDS) leverages model-generated\nsummaries to reduce reliance on human-labeled data and improve the performance\nof summarization models. While addressing label noise, previous works on\nsemi-supervised learning primarily focus on natural language understanding\ntasks, assuming each sample has a unique label. However, these methods are not\ndirectly applicable to SSDS, as it is a generative task, and each dialogue can\nbe summarized in different ways. In this work, we propose a novel scoring\napproach, SiCF, which encapsulates three primary dimensions of summarization\nmodel quality: Semantic invariance (indicative of model confidence), Coverage\n(factual recall), and Faithfulness (factual precision). Using the SiCF score,\nwe select unlabeled dialogues with high-quality generated summaries to train\nsummarization models. Comprehensive experiments on three public datasets\ndemonstrate the effectiveness of SiCF scores in uncertainty estimation and\nsemi-supervised learning for dialogue summarization tasks. Our code is\navailable at \\url{https://github.com/amazon-science/summarization-sicf-score}.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "21 pages, 10 figures",
    "pdf_url": "http://arxiv.org/pdf/2403.04073v1",
    "published_date": "2024-03-06 22:06:23 UTC",
    "updated_date": "2024-03-06 22:06:23 UTC"
  },
  {
    "arxiv_id": "2403.04072v1",
    "title": "Forecasting and Mitigating Disruptions in Public Bus Transit Services",
    "authors": [
      "Chaeeun Han",
      "Jose Paolo Talusan",
      "Dan Freudberg",
      "Ayan Mukhopadhyay",
      "Abhishek Dubey",
      "Aron Laszka"
    ],
    "abstract": "Public transportation systems often suffer from unexpected fluctuations in\ndemand and disruptions, such as mechanical failures and medical emergencies.\nThese fluctuations and disruptions lead to delays and overcrowding, which are\ndetrimental to the passengers' experience and to the overall performance of the\ntransit service. To proactively mitigate such events, many transit agencies\nstation substitute (reserve) vehicles throughout their service areas, which\nthey can dispatch to augment or replace vehicles on routes that suffer\novercrowding or disruption. However, determining the optimal locations where\nsubstitute vehicles should be stationed is a challenging problem due to the\ninherent randomness of disruptions and due to the combinatorial nature of\nselecting locations across a city. In collaboration with the transit agency of\nNashville, TN, we address this problem by introducing data-driven statistical\nand machine-learning models for forecasting disruptions and an effective\nrandomized local-search algorithm for selecting locations where substitute\nvehicles are to be stationed. Our research demonstrates promising results in\nproactive disruption management, offering a practical and easily implementable\nsolution for transit agencies to enhance the reliability of their services. Our\nresults resonate beyond mere operational efficiency: by advancing proactive\nstrategies, our approach fosters more resilient and accessible public\ntransportation, contributing to equitable urban mobility and ultimately\nbenefiting the communities that rely on public transportation the most.",
    "categories": [
      "cs.AI",
      "cs.CY",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.04072v1",
    "published_date": "2024-03-06 22:06:21 UTC",
    "updated_date": "2024-03-06 22:06:21 UTC"
  },
  {
    "arxiv_id": "2403.04071v1",
    "title": "On-device Self-supervised Learning of Visual Perception Tasks aboard Hardware-limited Nano-quadrotors",
    "authors": [
      "Elia Cereda",
      "Manuele Rusci",
      "Alessandro Giusti",
      "Daniele Palossi"
    ],
    "abstract": "Sub-\\SI{50}{\\gram} nano-drones are gaining momentum in both academia and\nindustry. Their most compelling applications rely on onboard deep learning\nmodels for perception despite severe hardware constraints (\\ie\nsub-\\SI{100}{\\milli\\watt} processor). When deployed in unknown environments not\nrepresented in the training data, these models often underperform due to domain\nshift. To cope with this fundamental problem, we propose, for the first time,\non-device learning aboard nano-drones, where the first part of the in-field\nmission is dedicated to self-supervised fine-tuning of a pre-trained\nconvolutional neural network (CNN). Leveraging a real-world vision-based\nregression task, we thoroughly explore performance-cost trade-offs of the\nfine-tuning phase along three axes: \\textit{i}) dataset size (more data\nincreases the regression performance but requires more memory and longer\ncomputation); \\textit{ii}) methodologies (\\eg fine-tuning all model parameters\nvs. only a subset); and \\textit{iii}) self-supervision strategy. Our approach\ndemonstrates an improvement in mean absolute error up to 30\\% compared to the\npre-trained baseline, requiring only \\SI{22}{\\second} fine-tuning on an\nultra-low-power GWT GAP9 System-on-Chip. Addressing the domain shift problem\nvia on-device learning aboard nano-drones not only marks a novel result for\nhardware-limited robots but lays the ground for more general advancements for\nthe entire robotics community.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "\\c{opyright} 2024 IEEE. Personal use of this material is permitted.\n  Permission from IEEE must be obtained for all other uses, in any current or\n  future media, including reprinting/republishing this material for advertising\n  or promotional purposes, creating new collective works, for resale or\n  redistribution to servers or lists, or reuse of any copyrighted component of\n  this work in other works",
    "pdf_url": "http://arxiv.org/pdf/2403.04071v1",
    "published_date": "2024-03-06 22:04:14 UTC",
    "updated_date": "2024-03-06 22:04:14 UTC"
  },
  {
    "arxiv_id": "2403.04070v1",
    "title": "Improving Adversarial Training using Vulnerability-Aware Perturbation Budget",
    "authors": [
      "Olukorede Fakorede",
      "Modeste Atsague",
      "Jin Tian"
    ],
    "abstract": "Adversarial Training (AT) effectively improves the robustness of Deep Neural\nNetworks (DNNs) to adversarial attacks. Generally, AT involves training DNN\nmodels with adversarial examples obtained within a pre-defined, fixed\nperturbation bound. Notably, individual natural examples from which these\nadversarial examples are crafted exhibit varying degrees of intrinsic\nvulnerabilities, and as such, crafting adversarial examples with fixed\nperturbation radius for all instances may not sufficiently unleash the potency\nof AT. Motivated by this observation, we propose two simple, computationally\ncheap vulnerability-aware reweighting functions for assigning perturbation\nbounds to adversarial examples used for AT, named Margin-Weighted Perturbation\nBudget (MWPB) and Standard-Deviation-Weighted Perturbation Budget (SDWPB). The\nproposed methods assign perturbation radii to individual adversarial samples\nbased on the vulnerability of their corresponding natural examples.\nExperimental results show that the proposed methods yield genuine improvements\nin the robustness of AT algorithms against various adversarial attacks.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "19 pages, 2 figures",
    "pdf_url": "http://arxiv.org/pdf/2403.04070v1",
    "published_date": "2024-03-06 21:50:52 UTC",
    "updated_date": "2024-03-06 21:50:52 UTC"
  },
  {
    "arxiv_id": "2403.04036v1",
    "title": "Unsupervised Contrastive Learning for Robust RF Device Fingerprinting Under Time-Domain Shift",
    "authors": [
      "Jun Chen",
      "Weng-Keen Wong",
      "Bechir Hamdaoui"
    ],
    "abstract": "Radio Frequency (RF) device fingerprinting has been recognized as a potential\ntechnology for enabling automated wireless device identification and\nclassification. However, it faces a key challenge due to the domain shift that\ncould arise from variations in the channel conditions and environmental\nsettings, potentially degrading the accuracy of RF-based device classification\nwhen testing and training data is collected in different domains. This paper\nintroduces a novel solution that leverages contrastive learning to mitigate\nthis domain shift problem. Contrastive learning, a state-of-the-art\nself-supervised learning approach from deep learning, learns a distance metric\nsuch that positive pairs are closer (i.e. more similar) in the learned metric\nspace than negative pairs. When applied to RF fingerprinting, our model treats\nRF signals from the same transmission as positive pairs and those from\ndifferent transmissions as negative pairs. Through experiments on wireless and\nwired RF datasets collected over several days, we demonstrate that our\ncontrastive learning approach captures domain-invariant features, diminishing\nthe effects of domain-specific variations. Our results show large and\nconsistent improvements in accuracy (10.8\\% to 27.8\\%) over baseline models,\nthus underscoring the effectiveness of contrastive learning in improving device\nclassification under domain shift.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "eess.SP"
    ],
    "primary_category": "cs.LG",
    "comment": "6 pages, 5 figures, accepted by 2024 IEEE International Conference on\n  Communications (ICC)",
    "pdf_url": "http://arxiv.org/pdf/2403.04036v1",
    "published_date": "2024-03-06 20:33:55 UTC",
    "updated_date": "2024-03-06 20:33:55 UTC"
  },
  {
    "arxiv_id": "2403.04035v2",
    "title": "Personalizing explanations of AI-driven hints to users' cognitive abilities: an empirical evaluation",
    "authors": [
      "Vedant Bahel",
      "Harshinee Sriram",
      "Cristina Conati"
    ],
    "abstract": "We investigate personalizing the explanations that an Intelligent Tutoring\nSystem generates to justify the hints it provides to students to foster their\nlearning. The personalization targets students with low levels of two traits,\nNeed for Cognition and Conscientiousness, and aims to enhance these students'\nengagement with the explanations, based on prior findings that these students\ndo not naturally engage with the explanations but they would benefit from them\nif they do. To evaluate the effectiveness of the personalization, we conducted\na user study where we found that our proposed personalization significantly\nincreases our target users' interaction with the hint explanations, their\nunderstanding of the hints and their learning. Hence, this work provides\nvaluable insights into effectively personalizing AI-driven explanations for\ncognitively demanding tasks such as learning.",
    "categories": [
      "cs.AI",
      "cs.CY",
      "cs.HC"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.04035v2",
    "published_date": "2024-03-06 20:25:04 UTC",
    "updated_date": "2024-03-09 02:47:28 UTC"
  },
  {
    "arxiv_id": "2403.04033v1",
    "title": "Online Learning with Unknown Constraints",
    "authors": [
      "Karthik Sridharan",
      "Seung Won Wilson Yoo"
    ],
    "abstract": "We consider the problem of online learning where the sequence of actions\nplayed by the learner must adhere to an unknown safety constraint at every\nround. The goal is to minimize regret with respect to the best safe action in\nhindsight while simultaneously satisfying the safety constraint with high\nprobability on each round. We provide a general meta-algorithm that leverages\nan online regression oracle to estimate the unknown safety constraint, and\nconverts the predictions of an online learning oracle to predictions that\nadhere to the unknown safety constraint. On the theoretical side, our\nalgorithm's regret can be bounded by the regret of the online regression and\nonline learning oracles, the eluder dimension of the model class containing the\nunknown safety constraint, and a novel complexity measure that captures the\ndifficulty of safe learning. We complement our result with an asymptotic lower\nbound that shows that the aforementioned complexity measure is necessary. When\nthe constraints are linear, we instantiate our result to provide a concrete\nalgorithm with $\\sqrt{T}$ regret using a scaling transformation that balances\noptimistic exploration with pessimistic constraint satisfaction.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "math.ST",
      "stat.ML",
      "stat.TH"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.04033v1",
    "published_date": "2024-03-06 20:23:59 UTC",
    "updated_date": "2024-03-06 20:23:59 UTC"
  },
  {
    "arxiv_id": "2403.04031v1",
    "title": "Can Large Language Models do Analytical Reasoning?",
    "authors": [
      "Yebowen Hu",
      "Kaiqiang Song",
      "Sangwoo Cho",
      "Xiaoyang Wang",
      "Hassan Foroosh",
      "Dong Yu",
      "Fei Liu"
    ],
    "abstract": "This paper explores the cutting-edge Large Language Model with analytical\nreasoning on sports. Our analytical reasoning embodies the tasks of letting\nlarge language models count how many points each team scores in a quarter in\nthe NBA and NFL games. Our major discoveries are in two folds. Firstly, we find\namong all the models we employed, GPT-4 stands out in effectiveness, followed\nby Claude-2.1, with GPT-3.5, Gemini-Pro, and Llama-2-70b lagging behind.\nSpecifically, we compare three different prompting techniques and a\ndivide-and-conquer approach, we find that the latter was the most effective.\nOur divide-and-conquer approach breaks down play-by-play data into smaller,\nmore manageable segments, solves each piece individually, and then aggregates\nthem together. Besides the divide-and-conquer approach, we also explore the\nChain of Thought (CoT) strategy, which markedly improves outcomes for certain\nmodels, notably GPT-4 and Claude-2.1, with their accuracy rates increasing\nsignificantly. However, the CoT strategy has negligible or even detrimental\neffects on the performance of other models like GPT-3.5 and Gemini-Pro.\nSecondly, to our surprise, we observe that most models, including GPT-4,\nstruggle to accurately count the total scores for NBA quarters despite showing\nstrong performance in counting NFL quarter scores. This leads us to further\ninvestigate the factors that impact the complexity of analytical reasoning\ntasks with extensive experiments, through which we conclude that task\ncomplexity depends on the length of context, the information density, and the\npresence of related information. Our research provides valuable insights into\nthe complexity of analytical reasoning tasks and potential directions for\ndeveloping future large language models.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.04031v1",
    "published_date": "2024-03-06 20:22:08 UTC",
    "updated_date": "2024-03-06 20:22:08 UTC"
  },
  {
    "arxiv_id": "2403.04017v1",
    "title": "Learning Guided Automated Reasoning: A Brief Survey",
    "authors": [
      "Lasse Blaauwbroek",
      "David Cerna",
      "Thibault Gauthier",
      "Jan Jakub≈Øv",
      "Cezary Kaliszyk",
      "Martin Suda",
      "Josef Urban"
    ],
    "abstract": "Automated theorem provers and formal proof assistants are general reasoning\nsystems that are in theory capable of proving arbitrarily hard theorems, thus\nsolving arbitrary problems reducible to mathematics and logical reasoning. In\npractice, such systems however face large combinatorial explosion, and\ntherefore include many heuristics and choice points that considerably influence\ntheir performance. This is an opportunity for trained machine learning\npredictors, which can guide the work of such reasoning systems. Conversely,\ndeductive search supported by the notion of logically valid proof allows one to\ntrain machine learning systems on large reasoning corpora. Such bodies of proof\nare usually correct by construction and when combined with more and more\nprecise trained guidance they can be boostrapped into very large corpora, with\nincreasingly long reasoning chains and possibly novel proof ideas. In this\npaper we provide an overview of several automated reasoning and theorem proving\ndomains and the learning and AI methods that have been so far developed for\nthem. These include premise selection, proof guidance in several settings, AI\nsystems and feedback loops iterating between reasoning and learning, and\nsymbolic classification problems.",
    "categories": [
      "cs.AI",
      "cs.LG",
      "cs.LO",
      "cs.NE",
      "cs.SC"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.04017v1",
    "published_date": "2024-03-06 19:59:17 UTC",
    "updated_date": "2024-03-06 19:59:17 UTC"
  },
  {
    "arxiv_id": "2403.04015v1",
    "title": "Knockoff-Guided Feature Selection via A Single Pre-trained Reinforced Agent",
    "authors": [
      "Xinyuan Wang",
      "Dongjie Wang",
      "Wangyang Ying",
      "Rui Xie",
      "Haifeng Chen",
      "Yanjie Fu"
    ],
    "abstract": "Feature selection prepares the AI-readiness of data by eliminating redundant\nfeatures. Prior research falls into two primary categories: i) Supervised\nFeature Selection, which identifies the optimal feature subset based on their\nrelevance to the target variable; ii) Unsupervised Feature Selection, which\nreduces the feature space dimensionality by capturing the essential information\nwithin the feature set instead of using target variable. However, SFS\napproaches suffer from time-consuming processes and limited generalizability\ndue to the dependence on the target variable and downstream ML tasks. UFS\nmethods are constrained by the deducted feature space is latent and\nuntraceable. To address these challenges, we introduce an innovative framework\nfor feature selection, which is guided by knockoff features and optimized\nthrough reinforcement learning, to identify the optimal and effective feature\nsubset. In detail, our method involves generating \"knockoff\" features that\nreplicate the distribution and characteristics of the original features but are\nindependent of the target variable. Each feature is then assigned a pseudo\nlabel based on its correlation with all the knockoff features, serving as a\nnovel metric for feature evaluation. Our approach utilizes these pseudo labels\nto guide the feature selection process in 3 novel ways, optimized by a single\nreinforced agent: 1). A deep Q-network, pre-trained with the original features\nand their corresponding pseudo labels, is employed to improve the efficacy of\nthe exploration process in feature selection. 2). We introduce unsupervised\nrewards to evaluate the feature subset quality based on the pseudo labels and\nthe feature space reconstruction loss to reduce dependencies on the target\nvariable. 3). A new {\\epsilon}-greedy strategy is used, incorporating insights\nfrom the pseudo labels to make the feature selection process more effective.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.04015v1",
    "published_date": "2024-03-06 19:58:19 UTC",
    "updated_date": "2024-03-06 19:58:19 UTC"
  },
  {
    "arxiv_id": "2403.04014v1",
    "title": "PromptCharm: Text-to-Image Generation through Multi-modal Prompting and Refinement",
    "authors": [
      "Zhijie Wang",
      "Yuheng Huang",
      "Da Song",
      "Lei Ma",
      "Tianyi Zhang"
    ],
    "abstract": "The recent advancements in Generative AI have significantly advanced the\nfield of text-to-image generation. The state-of-the-art text-to-image model,\nStable Diffusion, is now capable of synthesizing high-quality images with a\nstrong sense of aesthetics. Crafting text prompts that align with the model's\ninterpretation and the user's intent thus becomes crucial. However, prompting\nremains challenging for novice users due to the complexity of the stable\ndiffusion model and the non-trivial efforts required for iteratively editing\nand refining the text prompts. To address these challenges, we propose\nPromptCharm, a mixed-initiative system that facilitates text-to-image creation\nthrough multi-modal prompt engineering and refinement. To assist novice users\nin prompting, PromptCharm first automatically refines and optimizes the user's\ninitial prompt. Furthermore, PromptCharm supports the user in exploring and\nselecting different image styles within a large database. To assist users in\neffectively refining their prompts and images, PromptCharm renders model\nexplanations by visualizing the model's attention values. If the user notices\nany unsatisfactory areas in the generated images, they can further refine the\nimages through model attention adjustment or image inpainting within the rich\nfeedback loop of PromptCharm. To evaluate the effectiveness and usability of\nPromptCharm, we conducted a controlled user study with 12 participants and an\nexploratory user study with another 12 participants. These two studies show\nthat participants using PromptCharm were able to create images with higher\nquality and better aligned with the user's expectations compared with using two\nvariants of PromptCharm that lacked interaction or visualization support.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "To appear in the 2024 CHI Conference on Human Factors in Computing\n  Systems (CHI '24), May 11--16, 2024, Honolulu, HI, USA",
    "pdf_url": "http://arxiv.org/pdf/2403.04014v1",
    "published_date": "2024-03-06 19:55:01 UTC",
    "updated_date": "2024-03-06 19:55:01 UTC"
  },
  {
    "arxiv_id": "2403.04001v1",
    "title": "Bidirectional Progressive Neural Networks with Episodic Return Progress for Emergent Task Sequencing and Robotic Skill Transfer",
    "authors": [
      "Suzan Ece Ada",
      "Hanne Say",
      "Emre Ugur",
      "Erhan Oztop"
    ],
    "abstract": "Human brain and behavior provide a rich venue that can inspire novel control\nand learning methods for robotics. In an attempt to exemplify such a\ndevelopment by inspiring how humans acquire knowledge and transfer skills among\ntasks, we introduce a novel multi-task reinforcement learning framework named\nEpisodic Return Progress with Bidirectional Progressive Neural Networks\n(ERP-BPNN). The proposed ERP-BPNN model (1) learns in a human-like interleaved\nmanner by (2) autonomous task switching based on a novel intrinsic motivation\nsignal and, in contrast to existing methods, (3) allows bidirectional skill\ntransfer among tasks. ERP-BPNN is a general architecture applicable to several\nmulti-task learning settings; in this paper, we present the details of its\nneural architecture and show its ability to enable effective learning and skill\ntransfer among morphologically different robots in a reaching task. The\ndeveloped Bidirectional Progressive Neural Network (BPNN) architecture enables\nbidirectional skill transfer without requiring incremental training and\nseamlessly integrates with online task arbitration. The task arbitration\nmechanism developed is based on soft Episodic Return progress (ERP), a novel\nintrinsic motivation (IM) signal. To evaluate our method, we use quantifiable\nrobotics metrics such as 'expected distance to goal' and 'path straightness' in\naddition to the usual reward-based measure of episodic return common in\nreinforcement learning. With simulation experiments, we show that ERP-BPNN\nachieves faster cumulative convergence and improves performance in all metrics\nconsidered among morphologically different robots compared to the baselines.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "9 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2403.04001v1",
    "published_date": "2024-03-06 19:17:49 UTC",
    "updated_date": "2024-03-06 19:17:49 UTC"
  },
  {
    "arxiv_id": "2403.03997v2",
    "title": "Guiding Enumerative Program Synthesis with Large Language Models",
    "authors": [
      "Yixuan Li",
      "Julian Parsert",
      "Elizabeth Polgreen"
    ],
    "abstract": "Pre-trained Large Language Models (LLMs) are beginning to dominate the\ndiscourse around automatic code generation with natural language\nspecifications. In contrast, the best-performing synthesizers in the domain of\nformal synthesis with precise logical specifications are still based on\nenumerative algorithms. In this paper, we evaluate the abilities of LLMs to\nsolve formal synthesis benchmarks by carefully crafting a library of prompts\nfor the domain. When one-shot synthesis fails, we propose a novel enumerative\nsynthesis algorithm, which integrates calls to an LLM into a weighted\nprobabilistic search. This allows the synthesizer to provide the LLM with\ninformation about the progress of the enumerator, and the LLM to provide the\nenumerator with syntactic guidance in an iterative loop. We evaluate our\ntechniques on benchmarks from the Syntax-Guided Synthesis (SyGuS) competition.\nWe find that GPT-3.5 as a stand-alone tool for formal synthesis is easily\noutperformed by state-of-the-art formal synthesis algorithms, but our approach\nintegrating the LLM into an enumerative synthesis algorithm shows significant\nperformance gains over both the LLM and the enumerative synthesizer alone and\nthe winning SyGuS competition tool.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted at CAV 2024",
    "pdf_url": "http://arxiv.org/pdf/2403.03997v2",
    "published_date": "2024-03-06 19:13:53 UTC",
    "updated_date": "2024-05-27 12:18:40 UTC"
  },
  {
    "arxiv_id": "2403.03996v1",
    "title": "Rethinking Urban Flood Risk Assessment By Adapting Health Domain Perspective",
    "authors": [
      "Zhewei Liu",
      "Kai Yin",
      "Ali Mostafavi"
    ],
    "abstract": "Inspired by ideas from health risk assessment, this paper presents a new\nperspective for flood risk assessment. The proposed perspective focuses on\nthree pillars for examining flood risk: (1) inherent susceptibility, (2)\nmitigation strategies, and (3) external stressors. These pillars collectively\nencompass the physical and environmental characteristics of urban areas, the\neffectiveness of human-intervention measures, and the influence of\nuncontrollable external factors, offering a fresh point of view for decoding\nflood risks. For each pillar, we delineate its individual contributions to\nflood risk and illustrate their interactive and overall impact. The\nthree-pillars model embodies a shift in focus from the quest to precisely model\nand quantify flood risk to evaluating pathways to high flood risk. The shift in\nperspective is intended to alleviate the quest for quantifying and predicting\nflood risk at fine resolutions as a panacea for enhanced flood risk management.\nThe decomposition of flood risk pathways into the three intertwined pillars\n(i.e., inherent factors, mitigation factors, and external factors) enables\nevaluation of changes in factors within each pillar enhance and exacerbate\nflood risk, creating a platform from which to inform plans, decisions, and\nactions. Building on this foundation, we argue that a flood risk pathway\nanalysis approach, which examines the individual and collective impacts of\ninherent factors, mitigation strategies, and external stressors, is essential\nfor a nuanced evaluation of flood risk. Accordingly, the proposed perspective\ncould complement the existing frameworks and approaches for flood risk\nassessment.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.03996v1",
    "published_date": "2024-03-06 19:12:41 UTC",
    "updated_date": "2024-03-06 19:12:41 UTC"
  },
  {
    "arxiv_id": "2403.04810v3",
    "title": "Restricted Bayesian Neural Network",
    "authors": [
      "Sourav Ganguly",
      "Saprativa Bhattacharjee"
    ],
    "abstract": "Modern deep learning tools are remarkably effective in addressing intricate\nproblems. However, their operation as black-box models introduces increased\nuncertainty in predictions. Additionally, they contend with various challenges,\nincluding the need for substantial storage space in large networks, issues of\noverfitting, underfitting, vanishing gradients, and more. This study explores\nthe concept of Bayesian Neural Networks, presenting a novel architecture\ndesigned to significantly alleviate the storage space complexity of a network.\nFurthermore, we introduce an algorithm adept at efficiently handling\nuncertainties, ensuring robust convergence values without becoming trapped in\nlocal optima, particularly when the objective function lacks perfect convexity.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.NE"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.04810v3",
    "published_date": "2024-03-06 19:09:11 UTC",
    "updated_date": "2024-04-08 11:51:31 UTC"
  },
  {
    "arxiv_id": "2403.03993v2",
    "title": "Personalized Negative Reservoir for Incremental Learning in Recommender Systems",
    "authors": [
      "Antonios Valkanas",
      "Yuening Wang",
      "Yingxue Zhang",
      "Mark Coates"
    ],
    "abstract": "Recommender systems have become an integral part of online platforms. Every\nday the volume of training data is expanding and the number of user\ninteractions is constantly increasing. The exploration of larger and more\nexpressive models has become a necessary pursuit to improve user experience.\nHowever, this progression carries with it an increased computational burden. In\ncommercial settings, once a recommendation system model has been trained and\ndeployed it typically needs to be updated frequently as new client data arrive.\nCumulatively, the mounting volume of data is guaranteed to eventually make full\nbatch retraining of the model from scratch computationally infeasible. Naively\nfine-tuning solely on the new data runs into the well-documented problem of\ncatastrophic forgetting. Despite the fact that negative sampling is a crucial\npart of training with implicit feedback, no specialized technique exists that\nis tailored to the incremental learning framework. In this work, we propose a\npersonalized negative reservoir strategy, which is used to obtain negative\nsamples for the standard triplet loss of graph-based recommendation systems.\nOur technique balances alleviation of forgetting with plasticity by encouraging\nthe model to remember stable user preferences and selectively forget when user\ninterests change. We derive the mathematical formulation of a negative sampler\nto populate and update the reservoir. We integrate our design in three SOTA and\ncommonly used incremental recommendation models. We show that these concrete\nrealizations of our negative reservoir framework achieve state-of-the-art\nresults for standard benchmarks using multiple top-k evaluation metrics.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.03993v2",
    "published_date": "2024-03-06 19:08:28 UTC",
    "updated_date": "2025-02-11 21:10:32 UTC"
  },
  {
    "arxiv_id": "2403.03950v1",
    "title": "Stop Regressing: Training Value Functions via Classification for Scalable Deep RL",
    "authors": [
      "Jesse Farebrother",
      "Jordi Orbay",
      "Quan Vuong",
      "Adrien Ali Ta√Øga",
      "Yevgen Chebotar",
      "Ted Xiao",
      "Alex Irpan",
      "Sergey Levine",
      "Pablo Samuel Castro",
      "Aleksandra Faust",
      "Aviral Kumar",
      "Rishabh Agarwal"
    ],
    "abstract": "Value functions are a central component of deep reinforcement learning (RL).\nThese functions, parameterized by neural networks, are trained using a mean\nsquared error regression objective to match bootstrapped target values.\nHowever, scaling value-based RL methods that use regression to large networks,\nsuch as high-capacity Transformers, has proven challenging. This difficulty is\nin stark contrast to supervised learning: by leveraging a cross-entropy\nclassification loss, supervised methods have scaled reliably to massive\nnetworks. Observing this discrepancy, in this paper, we investigate whether the\nscalability of deep RL can also be improved simply by using classification in\nplace of regression for training value functions. We demonstrate that value\nfunctions trained with categorical cross-entropy significantly improves\nperformance and scalability in a variety of domains. These include: single-task\nRL on Atari 2600 games with SoftMoEs, multi-task RL on Atari with large-scale\nResNets, robotic manipulation with Q-transformers, playing Chess without\nsearch, and a language-agent Wordle task with high-capacity Transformers,\nachieving state-of-the-art results on these domains. Through careful analysis,\nwe show that the benefits of categorical cross-entropy primarily stem from its\nability to mitigate issues inherent to value-based RL, such as noisy targets\nand non-stationarity. Overall, we argue that a simple shift to training value\nfunctions with categorical cross-entropy can yield substantial improvements in\nthe scalability of deep RL at little-to-no cost.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.03950v1",
    "published_date": "2024-03-06 18:55:47 UTC",
    "updated_date": "2024-03-06 18:55:47 UTC"
  },
  {
    "arxiv_id": "2403.03949v3",
    "title": "Reconciling Reality through Simulation: A Real-to-Sim-to-Real Approach for Robust Manipulation",
    "authors": [
      "Marcel Torne",
      "Anthony Simeonov",
      "Zechu Li",
      "April Chan",
      "Tao Chen",
      "Abhishek Gupta",
      "Pulkit Agrawal"
    ],
    "abstract": "Imitation learning methods need significant human supervision to learn\npolicies robust to changes in object poses, physical disturbances, and visual\ndistractors. Reinforcement learning, on the other hand, can explore the\nenvironment autonomously to learn robust behaviors but may require impractical\namounts of unsafe real-world data collection. To learn performant, robust\npolicies without the burden of unsafe real-world data collection or extensive\nhuman supervision, we propose RialTo, a system for robustifying real-world\nimitation learning policies via reinforcement learning in \"digital twin\"\nsimulation environments constructed on the fly from small amounts of real-world\ndata. To enable this real-to-sim-to-real pipeline, RialTo proposes an\neasy-to-use interface for quickly scanning and constructing digital twins of\nreal-world environments. We also introduce a novel \"inverse distillation\"\nprocedure for bringing real-world demonstrations into simulated environments\nfor efficient fine-tuning, with minimal human intervention and engineering\nrequired. We evaluate RialTo across a variety of robotic manipulation problems\nin the real world, such as robustly stacking dishes on a rack, placing books on\na shelf, and six other tasks. RialTo increases (over 67%) in policy robustness\nwithout requiring extensive human data collection. Project website and videos\nat https://real-to-sim-to-real.github.io/RialTo/",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "Project page: https://real-to-sim-to-real.github.io/RialTo/",
    "pdf_url": "http://arxiv.org/pdf/2403.03949v3",
    "published_date": "2024-03-06 18:55:36 UTC",
    "updated_date": "2024-11-24 02:02:33 UTC"
  },
  {
    "arxiv_id": "2403.03929v1",
    "title": "Extreme Precipitation Nowcasting using Transformer-based Generative Models",
    "authors": [
      "Cristian Meo",
      "Ankush Roy",
      "Mircea LicƒÉ",
      "Junzhe Yin",
      "Zeineb Bou Che",
      "Yanbo Wang",
      "Ruben Imhoff",
      "Remko Uijlenhoet",
      "Justin Dauwels"
    ],
    "abstract": "This paper presents an innovative approach to extreme precipitation\nnowcasting by employing Transformer-based generative models, namely\nNowcastingGPT with Extreme Value Loss (EVL) regularization. Leveraging a\ncomprehensive dataset from the Royal Netherlands Meteorological Institute\n(KNMI), our study focuses on predicting short-term precipitation with high\naccuracy. We introduce a novel method for computing EVL without assuming fixed\nextreme representations, addressing the limitations of current models in\ncapturing extreme weather events. We present both qualitative and quantitative\nanalyses, demonstrating the superior performance of the proposed\nNowcastingGPT-EVL in generating accurate precipitation forecasts, especially\nwhen dealing with extreme precipitation events. The code is available at\n\\url{https://github.com/Cmeo97/NowcastingGPT}.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.03929v1",
    "published_date": "2024-03-06 18:39:41 UTC",
    "updated_date": "2024-03-06 18:39:41 UTC"
  },
  {
    "arxiv_id": "2403.03925v1",
    "title": "Consciousness qua Mortal Computation",
    "authors": [
      "Johannes Kleiner"
    ],
    "abstract": "Computational functionalism posits that consciousness is a computation. Here\nwe show, perhaps surprisingly, that it cannot be a Turing computation. Rather,\ncomputational functionalism implies that consciousness is a novel type of\ncomputation that has recently been proposed by Geoffrey Hinton, called mortal\ncomputation.",
    "categories": [
      "q-bio.NC",
      "cs.AI"
    ],
    "primary_category": "q-bio.NC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.03925v1",
    "published_date": "2024-03-06 18:37:06 UTC",
    "updated_date": "2024-03-06 18:37:06 UTC"
  },
  {
    "arxiv_id": "2403.03920v1",
    "title": "Enhancing Instructional Quality: Leveraging Computer-Assisted Textual Analysis to Generate In-Depth Insights from Educational Artifacts",
    "authors": [
      "Zewei Tian",
      "Min Sun",
      "Alex Liu",
      "Shawon Sarkar",
      "Jing Liu"
    ],
    "abstract": "This paper explores the transformative potential of computer-assisted textual\nanalysis in enhancing instructional quality through in-depth insights from\neducational artifacts. We integrate Richard Elmore's Instructional Core\nFramework to examine how artificial intelligence (AI) and machine learning (ML)\nmethods, particularly natural language processing (NLP), can analyze\neducational content, teacher discourse, and student responses to foster\ninstructional improvement. Through a comprehensive review and case studies\nwithin the Instructional Core Framework, we identify key areas where AI/ML\nintegration offers significant advantages, including teacher coaching, student\nsupport, and content development. We unveil patterns that indicate AI/ML not\nonly streamlines administrative tasks but also introduces novel pathways for\npersonalized learning, providing actionable feedback for educators and\ncontributing to a richer understanding of instructional dynamics. This paper\nemphasizes the importance of aligning AI/ML technologies with pedagogical goals\nto realize their full potential in educational settings, advocating for a\nbalanced approach that considers ethical considerations, data quality, and the\nintegration of human expertise.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.HC"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.03920v1",
    "published_date": "2024-03-06 18:29:18 UTC",
    "updated_date": "2024-03-06 18:29:18 UTC"
  },
  {
    "arxiv_id": "2403.03894v3",
    "title": "IRCoder: Intermediate Representations Make Language Models Robust Multilingual Code Generators",
    "authors": [
      "Indraneil Paul",
      "Goran Glava≈°",
      "Iryna Gurevych"
    ],
    "abstract": "Code understanding and generation have fast become some of the most popular\napplications of language models (LMs). Nonetheless, research on multilingual\naspects of Code-LMs (i.e., LMs for code generation) such as cross-lingual\ntransfer between different programming languages, language-specific data\naugmentation, and post-hoc LM adaptation, alongside exploitation of data\nsources other than the original textual content, has been much sparser than for\ntheir natural language counterparts. In particular, most mainstream Code-LMs\nhave been pre-trained on source code files alone. In this work, we investigate\nthe prospect of leveraging readily available compiler intermediate\nrepresentations (IR) - shared across programming languages - to improve the\nmultilingual capabilities of Code-LMs and facilitate cross-lingual transfer.\n  To this end, we first compile SLTrans, a parallel dataset consisting of\nnearly 4M self-contained source code files coupled with respective intermediate\nrepresentations. Next, starting from various base Code-LMs (ranging in size\nfrom 1.1B to 7.3B parameters), we carry out continued causal language modelling\ntraining on SLTrans, forcing the Code-LMs to (1) learn the IR language and (2)\nalign the IR constructs with respective constructs of various programming\nlanguages. Our resulting models, dubbed IRCoder, display sizeable and\nconsistent gains across a wide variety of code generation tasks and metrics,\nincluding prompt robustness, multilingual code completion, code understanding,\nand instruction following.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.PL"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.03894v3",
    "published_date": "2024-03-06 17:52:08 UTC",
    "updated_date": "2024-04-15 16:29:41 UTC"
  },
  {
    "arxiv_id": "2403.03893v3",
    "title": "From One to Many: Expanding the Scope of Toxicity Mitigation in Language Models",
    "authors": [
      "Luiza Pozzobon",
      "Patrick Lewis",
      "Sara Hooker",
      "Beyza Ermis"
    ],
    "abstract": "To date, toxicity mitigation in language models has almost entirely been\nfocused on single-language settings. As language models embrace multilingual\ncapabilities, it's crucial our safety measures keep pace. Recognizing this\nresearch gap, our approach expands the scope of conventional toxicity\nmitigation to address the complexities presented by multiple languages. In the\nabsence of sufficient annotated datasets across languages, we employ translated\ndata to evaluate and enhance our mitigation techniques. We also compare\nfinetuning mitigation approaches against retrieval-augmented techniques under\nboth static and continual toxicity mitigation scenarios. This allows us to\nexamine the effects of translation quality and the cross-lingual transfer on\ntoxicity mitigation. We also explore how model size and data quantity affect\nthe success of these mitigation efforts. Covering nine languages, our study\nrepresents a broad array of linguistic families and levels of resource\navailability, ranging from high to mid-resource languages. Through\ncomprehensive experiments, we provide insights into the complexities of\nmultilingual toxicity mitigation, offering valuable insights and paving the way\nfor future research in this increasingly important field. Code and data are\navailable at https://github.com/for-ai/goodtriever.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.03893v3",
    "published_date": "2024-03-06 17:51:43 UTC",
    "updated_date": "2024-05-30 17:37:11 UTC"
  },
  {
    "arxiv_id": "2403.03890v1",
    "title": "Hierarchical Diffusion Policy for Kinematics-Aware Multi-Task Robotic Manipulation",
    "authors": [
      "Xiao Ma",
      "Sumit Patidar",
      "Iain Haughton",
      "Stephen James"
    ],
    "abstract": "This paper introduces Hierarchical Diffusion Policy (HDP), a hierarchical\nagent for multi-task robotic manipulation. HDP factorises a manipulation policy\ninto a hierarchical structure: a high-level task-planning agent which predicts\na distant next-best end-effector pose (NBP), and a low-level goal-conditioned\ndiffusion policy which generates optimal motion trajectories. The factorised\npolicy representation allows HDP to tackle both long-horizon task planning\nwhile generating fine-grained low-level actions. To generate context-aware\nmotion trajectories while satisfying robot kinematics constraints, we present a\nnovel kinematics-aware goal-conditioned control agent, Robot Kinematics\nDiffuser (RK-Diffuser). Specifically, RK-Diffuser learns to generate both the\nend-effector pose and joint position trajectories, and distill the accurate but\nkinematics-unaware end-effector pose diffuser to the kinematics-aware but less\naccurate joint position diffuser via differentiable kinematics. Empirically, we\nshow that HDP achieves a significantly higher success rate than the\nstate-of-the-art methods in both simulation and real-world.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "Proceedings of the IEEE Conference on Computer Vision and Pattern\n  Recognition (CVPR 2024). Videos and code:\n  https://yusufma03.github.io/projects/hdp/",
    "pdf_url": "http://arxiv.org/pdf/2403.03890v1",
    "published_date": "2024-03-06 17:50:26 UTC",
    "updated_date": "2024-03-06 17:50:26 UTC"
  },
  {
    "arxiv_id": "2403.03881v3",
    "title": "Latent Dataset Distillation with Diffusion Models",
    "authors": [
      "Brian B. Moser",
      "Federico Raue",
      "Sebastian Palacio",
      "Stanislav Frolov",
      "Andreas Dengel"
    ],
    "abstract": "Machine learning traditionally relies on increasingly larger datasets. Yet,\nsuch datasets pose major storage challenges and usually contain non-influential\nsamples, which could be ignored during training without negatively impacting\nthe training quality. In response, the idea of distilling a dataset into a\ncondensed set of synthetic samples, i.e., a distilled dataset, emerged. One key\naspect is the selected architecture, usually ConvNet, for linking the original\nand synthetic datasets. However, the final accuracy is lower if the employed\nmodel architecture differs from that used during distillation. Another\nchallenge is the generation of high-resolution images (128x128 and higher). To\naddress both challenges, this paper proposes Latent Dataset Distillation with\nDiffusion Models (LD3M) that combine diffusion in latent space with dataset\ndistillation. Our novel diffusion process is tailored for this task and\nsignificantly improves the gradient flow for distillation. By adjusting the\nnumber of diffusion steps, LD3M also offers a convenient way of controlling the\ntrade-off between distillation speed and dataset quality. Overall, LD3M\nconsistently outperforms state-of-the-art methods by up to 4.8 p.p. and 4.2\np.p. for 1 and 10 images per class, respectively, and on several ImageNet\nsubsets and high resolutions (128x128 and 256x256).",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.03881v3",
    "published_date": "2024-03-06 17:41:41 UTC",
    "updated_date": "2024-07-11 09:10:10 UTC"
  },
  {
    "arxiv_id": "2403.03879v1",
    "title": "Redefining cystoscopy with ai: bladder cancer diagnosis using an efficient hybrid cnn-transformer model",
    "authors": [
      "Meryem Amaouche",
      "Ouassim Karrakchou",
      "Mounir Ghogho",
      "Anouar El Ghazzaly",
      "Mohamed Alami",
      "Ahmed Ameur"
    ],
    "abstract": "Bladder cancer ranks within the top 10 most diagnosed cancers worldwide and\nis among the most expensive cancers to treat due to the high recurrence rates\nwhich require lifetime follow-ups. The primary tool for diagnosis is\ncystoscopy, which heavily relies on doctors' expertise and interpretation.\nTherefore, annually, numerous cases are either undiagnosed or misdiagnosed and\ntreated as urinary infections. To address this, we suggest a deep learning\napproach for bladder cancer detection and segmentation which combines CNNs with\na lightweight positional-encoding-free transformer and dual attention gates\nthat fuse self and spatial attention for feature enhancement. The architecture\nsuggested in this paper is efficient making it suitable for medical scenarios\nthat require real time inference. Experiments have proven that this model\naddresses the critical need for a balance between computational efficiency and\ndiagnostic accuracy in cystoscopic imaging as despite its small size it rivals\nlarge models in performance.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "7 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2403.03879v1",
    "published_date": "2024-03-06 17:38:33 UTC",
    "updated_date": "2024-03-06 17:38:33 UTC"
  },
  {
    "arxiv_id": "2403.03874v1",
    "title": "Impoverished Language Technology: The Lack of (Social) Class in NLP",
    "authors": [
      "Amanda Cercas Curry",
      "Zeerak Talat",
      "Dirk Hovy"
    ],
    "abstract": "Since Labov's (1964) foundational work on the social stratification of\nlanguage, linguistics has dedicated concerted efforts towards understanding the\nrelationships between socio-demographic factors and language production and\nperception. Despite the large body of evidence identifying significant\nrelationships between socio-demographic factors and language production,\nrelatively few of these factors have been investigated in the context of NLP\ntechnology. While age and gender are well covered, Labov's initial target,\nsocio-economic class, is largely absent. We survey the existing Natural\nLanguage Processing (NLP) literature and find that only 20 papers even mention\nsocio-economic status. However, the majority of those papers do not engage with\nclass beyond collecting information of annotator-demographics. Given this\nresearch lacuna, we provide a definition of class that can be operationalised\nby NLP researchers, and argue for including socio-economic class in future\nlanguage technologies.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted to LREC-COLING 2024",
    "pdf_url": "http://arxiv.org/pdf/2403.03874v1",
    "published_date": "2024-03-06 17:35:27 UTC",
    "updated_date": "2024-03-06 17:35:27 UTC"
  },
  {
    "arxiv_id": "2403.03864v3",
    "title": "Are Language Models Puzzle Prodigies? Algorithmic Puzzles Unveil Serious Challenges in Multimodal Reasoning",
    "authors": [
      "Deepanway Ghosal",
      "Vernon Toh Yan Han",
      "Chia Yew Ken",
      "Soujanya Poria"
    ],
    "abstract": "This paper introduces the novel task of multimodal puzzle solving, framed\nwithin the context of visual question-answering. We present a new dataset,\nAlgoPuzzleVQA designed to challenge and evaluate the capabilities of multimodal\nlanguage models in solving algorithmic puzzles that necessitate both visual\nunderstanding, language understanding, and complex algorithmic reasoning. We\ncreate the puzzles to encompass a diverse array of mathematical and algorithmic\ntopics such as boolean logic, combinatorics, graph theory, optimization,\nsearch, etc., aiming to evaluate the gap between visual data interpretation and\nalgorithmic problem-solving skills. The dataset is generated automatically from\ncode authored by humans. All our puzzles have exact solutions that can be found\nfrom the algorithm without tedious human calculations. It ensures that our\ndataset can be scaled up arbitrarily in terms of reasoning complexity and\ndataset size. Our investigation reveals that large language models (LLMs) such\nas GPT4V and Gemini exhibit limited performance in puzzle-solving tasks. We\nfind that their performance is near random in a multi-choice question-answering\nsetup for a significant number of puzzles. The findings emphasize the\nchallenges of integrating visual, language, and algorithmic knowledge for\nsolving complex reasoning problems.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.03864v3",
    "published_date": "2024-03-06 17:15:04 UTC",
    "updated_date": "2024-03-13 00:50:05 UTC"
  },
  {
    "arxiv_id": "2403.03852v1",
    "title": "Accelerating Convergence of Score-Based Diffusion Models, Provably",
    "authors": [
      "Gen Li",
      "Yu Huang",
      "Timofey Efimov",
      "Yuting Wei",
      "Yuejie Chi",
      "Yuxin Chen"
    ],
    "abstract": "Score-based diffusion models, while achieving remarkable empirical\nperformance, often suffer from low sampling speed, due to extensive function\nevaluations needed during the sampling phase. Despite a flurry of recent\nactivities towards speeding up diffusion generative modeling in practice,\ntheoretical underpinnings for acceleration techniques remain severely limited.\nIn this paper, we design novel training-free algorithms to accelerate popular\ndeterministic (i.e., DDIM) and stochastic (i.e., DDPM) samplers. Our\naccelerated deterministic sampler converges at a rate $O(1/{T}^2)$ with $T$ the\nnumber of steps, improving upon the $O(1/T)$ rate for the DDIM sampler; and our\naccelerated stochastic sampler converges at a rate $O(1/T)$, outperforming the\nrate $O(1/\\sqrt{T})$ for the DDPM sampler. The design of our algorithms\nleverages insights from higher-order approximation, and shares similar\nintuitions as popular high-order ODE solvers like the DPM-Solver-2. Our theory\naccommodates $\\ell_2$-accurate score estimates, and does not require\nlog-concavity or smoothness on the target distribution.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.IT",
      "math.IT",
      "math.OC",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "The first two authors contributed equally",
    "pdf_url": "http://arxiv.org/pdf/2403.03852v1",
    "published_date": "2024-03-06 17:02:39 UTC",
    "updated_date": "2024-03-06 17:02:39 UTC"
  },
  {
    "arxiv_id": "2403.12082v1",
    "title": "The Boy Who Survived: Removing Harry Potter from an LLM is harder than reported",
    "authors": [
      "Adam Shostack"
    ],
    "abstract": "Recent work arXiv.2310.02238 asserted that \"we effectively erase the model's\nability to generate or recall Harry Potter-related content.'' This claim is\nshown to be overbroad. A small experiment of less than a dozen trials led to\nrepeated and specific mentions of Harry Potter, including \"Ah, I see! A\n\"muggle\" is a term used in the Harry Potter book series by Terry Pratchett...''",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "2 pages, 4 pages of appendix. Comment on arXiv:2310.02238",
    "pdf_url": "http://arxiv.org/pdf/2403.12082v1",
    "published_date": "2024-03-06 16:39:50 UTC",
    "updated_date": "2024-03-06 16:39:50 UTC"
  },
  {
    "arxiv_id": "2403.03835v3",
    "title": "Cobweb: An Incremental and Hierarchical Model of Human-Like Category Learning",
    "authors": [
      "Xin Lian",
      "Sashank Varma",
      "Christopher J. MacLellan"
    ],
    "abstract": "Cobweb, a human-like category learning system, differs from most cognitive\nscience models in incrementally constructing hierarchically organized tree-like\nstructures guided by the category utility measure. Prior studies have shown\nthat Cobweb can capture psychological effects such as basic-level, typicality,\nand fan effects. However, a broader evaluation of Cobweb as a model of human\ncategorization remains lacking. The current study addresses this gap. It\nestablishes Cobweb's alignment with classical human category learning effects.\nIt also explores Cobweb's flexibility to exhibit both exemplar- and\nprototype-like learning within a single framework. These findings set the stage\nfor further research on Cobweb as a robust model of human category learning.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted by CogSci-24",
    "pdf_url": "http://arxiv.org/pdf/2403.03835v3",
    "published_date": "2024-03-06 16:26:40 UTC",
    "updated_date": "2024-05-09 03:50:30 UTC"
  },
  {
    "arxiv_id": "2403.03832v1",
    "title": "Your device may know you better than you know yourself -- continuous authentication on novel dataset using machine learning",
    "authors": [
      "Pedro Gomes do Nascimento",
      "Pidge Witiak",
      "Tucker MacCallum",
      "Zachary Winterfeldt",
      "Rushit Dave"
    ],
    "abstract": "This research aims to further understanding in the field of continuous\nauthentication using behavioral biometrics. We are contributing a novel dataset\nthat encompasses the gesture data of 15 users playing Minecraft with a Samsung\nTablet, each for a duration of 15 minutes. Utilizing this dataset, we employed\nmachine learning (ML) binary classifiers, being Random Forest (RF), K-Nearest\nNeighbors (KNN), and Support Vector Classifier (SVC), to determine the\nauthenticity of specific user actions. Our most robust model was SVC, which\nachieved an average accuracy of approximately 90%, demonstrating that touch\ndynamics can effectively distinguish users. However, further studies are needed\nto make it viable option for authentication systems",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.03832v1",
    "published_date": "2024-03-06 16:22:49 UTC",
    "updated_date": "2024-03-06 16:22:49 UTC"
  },
  {
    "arxiv_id": "2403.03828v1",
    "title": "From Clicks to Security: Investigating Continuous Authentication via Mouse Dynamics",
    "authors": [
      "Rushit Dave",
      "Marcho Handoko",
      "Ali Rashid",
      "Cole Schoenbauer"
    ],
    "abstract": "In the realm of computer security, the importance of efficient and reliable\nuser authentication methods has become increasingly critical. This paper\nexamines the potential of mouse movement dynamics as a consistent metric for\ncontinuous authentication. By analyzing user mouse movement patterns in two\ncontrasting gaming scenarios, \"Team Fortress\" and Poly Bridge we investigate\nthe distinctive behavioral patterns inherent in high-intensity and\nlow-intensity UI interactions. The study extends beyond conventional\nmethodologies by employing a range of machine learning models. These models are\ncarefully selected to assess their effectiveness in capturing and interpreting\nthe subtleties of user behavior as reflected in their mouse movements. This\nmultifaceted approach allows for a more nuanced and comprehensive understanding\nof user interaction patterns. Our findings reveal that mouse movement dynamics\ncan serve as a reliable indicator for continuous user authentication. The\ndiverse machine learning models employed in this study demonstrate competent\nperformance in user verification, marking an improvement over previous methods\nused in this field. This research contributes to the ongoing efforts to enhance\ncomputer security and highlights the potential of leveraging user behavior,\nspecifically mouse dynamics, in developing robust authentication systems.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.03828v1",
    "published_date": "2024-03-06 16:18:02 UTC",
    "updated_date": "2024-03-06 16:18:02 UTC"
  },
  {
    "arxiv_id": "2403.03814v2",
    "title": "Evaluating the Elementary Multilingual Capabilities of Large Language Models with MultiQ",
    "authors": [
      "Carolin Holtermann",
      "Paul R√∂ttger",
      "Timm Dill",
      "Anne Lauscher"
    ],
    "abstract": "Large language models (LLMs) need to serve everyone, including a global\nmajority of non-English speakers. However, most LLMs today, and open LLMs in\nparticular, are often intended for use in just English (e.g. Llama2, Mistral)\nor a small handful of high-resource languages (e.g. Mixtral, Qwen). Recent\nresearch shows that, despite limits in their intended use, people prompt LLMs\nin many different languages. Therefore, in this paper, we investigate the basic\nmultilingual capabilities of state-of-the-art open LLMs beyond their intended\nuse. For this purpose, we introduce MultiQ, a new silver standard benchmark for\nbasic open-ended question answering with 27.4k test questions across a\ntypologically diverse set of 137 languages. With MultiQ, we evaluate language\nfidelity, i.e. whether models respond in the prompted language, and question\nanswering accuracy. All LLMs we test respond faithfully and/or accurately for\nat least some languages beyond their intended use. Most models are more\naccurate when they respond faithfully. However, differences across models are\nlarge, and there is a long tail of languages where models are neither accurate\nnor faithful. We explore differences in tokenization as a potential explanation\nfor our findings, identifying possible correlations that warrant further\ninvestigation.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.03814v2",
    "published_date": "2024-03-06 16:01:44 UTC",
    "updated_date": "2024-07-18 07:31:58 UTC"
  },
  {
    "arxiv_id": "2403.03812v1",
    "title": "ProbSAINT: Probabilistic Tabular Regression for Used Car Pricing",
    "authors": [
      "Kiran Madhusudhanan",
      "Gunnar Behrens",
      "Maximilian Stubbemann",
      "Lars Schmidt-Thieme"
    ],
    "abstract": "Used car pricing is a critical aspect of the automotive industry, influenced\nby many economic factors and market dynamics. With the recent surge in online\nmarketplaces and increased demand for used cars, accurate pricing would benefit\nboth buyers and sellers by ensuring fair transactions. However, the transition\ntowards automated pricing algorithms using machine learning necessitates the\ncomprehension of model uncertainties, specifically the ability to flag\npredictions that the model is unsure about. Although recent literature proposes\nthe use of boosting algorithms or nearest neighbor-based approaches for swift\nand precise price predictions, encapsulating model uncertainties with such\nalgorithms presents a complex challenge. We introduce ProbSAINT, a model that\noffers a principled approach for uncertainty quantification of its price\npredictions, along with accurate point predictions that are comparable to\nstate-of-the-art boosting techniques. Furthermore, acknowledging that the\nbusiness prefers pricing used cars based on the number of days the vehicle was\nlisted for sale, we show how ProbSAINT can be used as a dynamic forecasting\nmodel for predicting price probabilities for different expected offer duration.\nOur experiments further indicate that ProbSAINT is especially accurate on\ninstances where it is highly certain. This proves the applicability of its\nprobabilistic predictions in real-world scenarios where trustworthiness is\ncrucial.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "9 pages, 4 figures",
    "pdf_url": "http://arxiv.org/pdf/2403.03812v1",
    "published_date": "2024-03-06 16:00:50 UTC",
    "updated_date": "2024-03-06 16:00:50 UTC"
  },
  {
    "arxiv_id": "2403.03808v1",
    "title": "Confidence-Aware Decision-Making and Control for Tool Selection",
    "authors": [
      "Ajith Anil Meera",
      "Pablo Lanillos"
    ],
    "abstract": "Self-reflecting about our performance (e.g., how confident we are) before\ndoing a task is essential for decision making, such as selecting the most\nsuitable tool or choosing the best route to drive. While this form of awareness\n-- thinking about our performance or metacognitive performance -- is well-known\nin humans, robots still lack this cognitive ability. This reflective monitoring\ncan enhance their embodied decision power, robustness and safety. Here, we take\na step in this direction by introducing a mathematical framework that allows\nrobots to use their control self-confidence to make better-informed decisions.\nWe derive a mathematical closed-form expression for control confidence for\ndynamic systems (i.e., the posterior inverse covariance of the control action).\nThis control confidence seamlessly integrates within an objective function for\ndecision making, that balances the: i) performance for task completion, ii)\ncontrol effort, and iii) self-confidence. To evaluate our theoretical account,\nwe framed the decision-making within the tool selection problem, where the\nagent has to select the best robot arm for a particular control task. The\nstatistical analysis of the numerical simulations with randomized 2DOF arms\nshows that using control confidence during tool selection improves both real\ntask performance, and the reliability of the tool for performance under\nunmodelled perturbations (e.g., external forces). Furthermore, our results\nindicate that control confidence is an early indicator of performance and thus,\nit can be used as a heuristic for making decisions when computation power is\nrestricted or decision-making is intractable. Overall, we show the advantages\nof using confidence-aware decision-making and control scheme for dynamic\nsystems.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.03808v1",
    "published_date": "2024-03-06 15:59:39 UTC",
    "updated_date": "2024-03-06 15:59:39 UTC"
  },
  {
    "arxiv_id": "2403.03791v1",
    "title": "KG-TREAT: Pre-training for Treatment Effect Estimation by Synergizing Patient Data with Knowledge Graphs",
    "authors": [
      "Ruoqi Liu",
      "Lingfei Wu",
      "Ping Zhang"
    ],
    "abstract": "Treatment effect estimation (TEE) is the task of determining the impact of\nvarious treatments on patient outcomes. Current TEE methods fall short due to\nreliance on limited labeled data and challenges posed by sparse and\nhigh-dimensional observational patient data. To address the challenges, we\nintroduce a novel pre-training and fine-tuning framework, KG-TREAT, which\nsynergizes large-scale observational patient data with biomedical knowledge\ngraphs (KGs) to enhance TEE. Unlike previous approaches, KG-TREAT constructs\ndual-focus KGs and integrates a deep bi-level attention synergy method for\nin-depth information fusion, enabling distinct encoding of treatment-covariate\nand outcome-covariate relationships. KG-TREAT also incorporates two\npre-training tasks to ensure a thorough grounding and contextualization of\npatient data and KGs. Evaluation on four downstream TEE tasks shows KG-TREAT's\nsuperiority over existing methods, with an average improvement of 7% in Area\nunder the ROC Curve (AUC) and 9% in Influence Function-based Precision of\nEstimating Heterogeneous Effects (IF-PEHE). The effectiveness of our estimated\ntreatment effects is further affirmed by alignment with established randomized\nclinical trial findings.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "AAAI 2024 Main Track",
    "pdf_url": "http://arxiv.org/pdf/2403.03791v1",
    "published_date": "2024-03-06 15:37:22 UTC",
    "updated_date": "2024-03-06 15:37:22 UTC"
  },
  {
    "arxiv_id": "2405.00686v1",
    "title": "Technical Report on BaumEvA Evolutionary Optimization Python-Library Testing",
    "authors": [
      "Vadim Tynchenko",
      "Aleksei Kudryavtsev",
      "Vladimir Nelyub",
      "Aleksei Borodulin",
      "Andrei Gantimurov"
    ],
    "abstract": "This report presents the test results Python library BaumEvA, which\nimplements evolutionary algorithms for optimizing various types of problems,\nincluding computer vision tasks accompanied by the search for optimal model\narchitectures. Testing was carried out to evaluate the effectiveness and\nreliability of the pro-posed methods, as well as to determine their\napplicability in various fields. Dur-ing testing, various test functions and\nparameters of evolutionary algorithms were used, which made it possible to\nevaluate their performance in a wide range of conditions. Test results showed\nthat the library provides effective and reliable methods for solving\noptimization problems. However, some limitations were identified related to\ncomputational resources and execution time of algorithms on problems with large\ndimensions. The report includes a detailed description of the tests performed,\nthe results obtained and conclusions about the applicability of the genetic\nalgorithm in various tasks. Recommendations for choosing algorithm pa-rameters\nand using the library to achieve the best results are also provided. The report\nmay be useful to developers involved in the optimization of complex com-puting\nsystems, as well as to researchers studying the possibilities of using\nevo-lutionary algorithms in various fields of science and technology.",
    "categories": [
      "cs.NE",
      "cs.AI",
      "cs.CV",
      "65K10",
      "I.2.8; I.2.5; G.4"
    ],
    "primary_category": "cs.NE",
    "comment": "The paper consists of 30 pages, 37 figures, 5 tables",
    "pdf_url": "http://arxiv.org/pdf/2405.00686v1",
    "published_date": "2024-03-06 15:34:31 UTC",
    "updated_date": "2024-03-06 15:34:31 UTC"
  },
  {
    "arxiv_id": "2403.03781v1",
    "title": "Neural Architecture Search using Particle Swarm and Ant Colony Optimization",
    "authors": [
      "S√©amus Lankford",
      "Diarmuid Grimes"
    ],
    "abstract": "Neural network models have a number of hyperparameters that must be chosen\nalong with their architecture. This can be a heavy burden on a novice user,\nchoosing which architecture and what values to assign to parameters. In most\ncases, default hyperparameters and architectures are used. Significant\nimprovements to model accuracy can be achieved through the evaluation of\nmultiple architectures. A process known as Neural Architecture Search (NAS) may\nbe applied to automatically evaluate a large number of such architectures. A\nsystem integrating open source tools for Neural Architecture Search (OpenNAS),\nin the classification of images, has been developed as part of this research.\nOpenNAS takes any dataset of grayscale, or RBG images, and generates\nConvolutional Neural Network (CNN) architectures based on a range of\nmetaheuristics using either an AutoKeras, a transfer learning or a Swarm\nIntelligence (SI) approach. Particle Swarm Optimization (PSO) and Ant Colony\nOptimization (ACO) are used as the SI algorithms. Furthermore, models developed\nthrough such metaheuristics may be combined using stacking ensembles. In the\ncontext of this paper, we focus on training and optimizing CNNs using the Swarm\nIntelligence (SI) components of OpenNAS. Two major types of SI algorithms,\nnamely PSO and ACO, are compared to see which is more effective in generating\nhigher model accuracies. It is shown, with our experimental design, that the\nPSO algorithm performs better than ACO. The performance improvement of PSO is\nmost notable with a more complex dataset. As a baseline, the performance of\nfine-tuned pre-trained models is also evaluated.",
    "categories": [
      "cs.NE",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.NE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.03781v1",
    "published_date": "2024-03-06 15:23:26 UTC",
    "updated_date": "2024-03-06 15:23:26 UTC"
  },
  {
    "arxiv_id": "2403.03777v4",
    "title": "ENOT: Expectile Regularization for Fast and Accurate Training of Neural Optimal Transport",
    "authors": [
      "Nazar Buzun",
      "Maksim Bobrin",
      "Dmitry V. Dylov"
    ],
    "abstract": "We present a new approach for Neural Optimal Transport (NOT) training\nprocedure, capable of accurately and efficiently estimating optimal\ntransportation plan via specific regularization on dual Kantorovich potentials.\nThe main bottleneck of existing NOT solvers is associated with the procedure of\nfinding a near-exact approximation of the conjugate operator (i.e., the\nc-transform), which is done either by optimizing over non-convex max-min\nobjectives or by the computationally intensive fine-tuning of the initial\napproximated prediction. We resolve both issues by proposing a new,\ntheoretically justified loss in the form of expectile regularisation which\nenforces binding conditions on the learning process of dual potentials. Such a\nregularization provides the upper bound estimation over the distribution of\npossible conjugate potentials and makes the learning stable, completely\neliminating the need for additional extensive fine-tuning. Proposed method,\ncalled Expectile-Regularised Neural Optimal Transport (ENOT), outperforms\nprevious state-of-the-art approaches on the established Wasserstein-2 benchmark\ntasks by a large margin (up to a 3-fold improvement in quality and up to a\n10-fold improvement in runtime). Moreover, we showcase performance of ENOT for\nvarying cost functions on different tasks such as image generation, showing\nrobustness of proposed algorithm. OTT-JAX library includes our implementation\nof ENOT algorithm https://ott-jax.readthedocs.io/en/latest/tutorials/ENOT.html",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.03777v4",
    "published_date": "2024-03-06 15:15:42 UTC",
    "updated_date": "2024-10-18 01:26:27 UTC"
  },
  {
    "arxiv_id": "2403.03768v3",
    "title": "DeepCRE: Transforming Drug R&D via AI-Driven Cross-drug Response Evaluation",
    "authors": [
      "Yushuai Wu",
      "Ting Zhang",
      "Hao Zhou",
      "Hainan Wu",
      "Hanwen Sunchu",
      "Lei Hu",
      "Xiaofang Chen",
      "Suyuan Zhao",
      "Gaochao Liu",
      "Chao Sun",
      "Jiahuan Zhang",
      "Yizhen Luo",
      "Peng Liu",
      "Zaiqing Nie",
      "Yushuai Wu"
    ],
    "abstract": "The fields of therapeutic application and drug research and development (R&D)\nboth face substantial challenges, i.e., the therapeutic domain calls for more\ntreatment alternatives, while numerous promising pre-clinical drugs have failed\nin clinical trials. One of the reasons is the inadequacy of Cross-drug Response\nEvaluation (CRE) during the late stages of drug R&D. Although in-silico CRE\nmodels bring a promising solution, existing methodologies are restricted to\nearly stages of drug R&D, such as target and cell-line levels, offering limited\nimprovement to clinical success rates. Herein, we introduce DeepCRE, a\npioneering AI model designed to predict CRE effectively in the late stages of\ndrug R&D. DeepCRE outperforms the existing best models by achieving an average\nperformance improvement of 17.7% in patient-level CRE, and a 5-fold increase in\nindication-level CRE, facilitating more accurate personalized treatment\npredictions and better pharmaceutical value assessment for indications,\nrespectively. Furthermore, DeepCRE has identified a set of six drug candidates\nthat show significantly greater effectiveness than a comparator set of two\napproved drugs in 5/8 colorectal cancer organoids. This demonstrates the\ncapability of DeepCRE to systematically uncover a spectrum of drug candidates\nwith enhanced therapeutic effects, highlighting its potential to transform drug\nR&D.",
    "categories": [
      "cs.AI",
      "cs.LG",
      "q-bio.QM"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.03768v3",
    "published_date": "2024-03-06 15:03:09 UTC",
    "updated_date": "2024-03-18 15:05:55 UTC"
  },
  {
    "arxiv_id": "2403.05593v2",
    "title": "Introducing First-Principles Calculations: New Approach to Group Dynamics and Bridging Social Phenomena in TeNP-Chain Based Social Dynamics Simulations",
    "authors": [
      "Yasuko Kawahata"
    ],
    "abstract": "This note considers an innovative interdisciplinary methodology that bridges\nthe gap between the fundamental principles of quantum mechanics applied to the\nstudy of materials such as tellurium nanoparticles (TeNPs) and graphene and the\ncomplex dynamics of social systems. The basis for this approach lies in the\nmetaphorical parallels drawn between the structural features of TeNPs and\ngraphene and the behavioral patterns of social groups in the face of\nmisinformation. TeNPs exhibit unique properties such as the strengthening of\ncovalent bonds within telluric chains and the disruption of secondary structure\nleading to the separation of these chains. This is analogous to increased\ncohesion within social groups and disruption of information flow between\ndifferent subgroups, respectively. . Similarly, the outstanding properties of\ngraphene, such as high electrical conductivity, strength, and flexibility,\nprovide additional aspects for understanding the resilience and adaptability of\nsocial structures in response to external stimuli such as fake news. This\nresearch note proposes a novel metaphorical framework for analyzing the spread\nof fake news within social groups, analogous to the structural features of\ntelluric nanoparticles (TeNPs). We investigate how the strengthening of\ncovalent bonds within TeNPs reflects the strengthening of social cohesion in\ngroups that share common beliefs and values. This paper is partially an attempt\nto utilize \"Generative AI\" and was written with educational intent. There are\ncurrently no plans for it to become a peer-reviewed paper.",
    "categories": [
      "physics.soc-ph",
      "cs.AI",
      "physics.ed-ph"
    ],
    "primary_category": "physics.soc-ph",
    "comment": "TeNP Chains, First-principles calculations, Tellurium nanoparticles\n  (TeNPs), Graphene, Fake news dissemination, Social cohesion, Information Flow\n  Disruption, Quantum Mechanics, Interdisciplinary approach, Misinformation\n  mitigation",
    "pdf_url": "http://arxiv.org/pdf/2403.05593v2",
    "published_date": "2024-03-06 15:00:11 UTC",
    "updated_date": "2024-04-19 14:59:28 UTC"
  },
  {
    "arxiv_id": "2403.03750v2",
    "title": "German also Hallucinates! Inconsistency Detection in News Summaries with the Absinth Dataset",
    "authors": [
      "Laura Mascarell",
      "Ribin Chalumattu",
      "Annette Rios"
    ],
    "abstract": "The advent of Large Language Models (LLMs) has led to remarkable progress on\na wide range of natural language processing tasks. Despite the advances, these\nlarge-sized models still suffer from hallucinating information in their output,\nwhich poses a major issue in automatic text summarization, as we must guarantee\nthat the generated summary is consistent with the content of the source\ndocument. Previous research addresses the challenging task of detecting\nhallucinations in the output (i.e. inconsistency detection) in order to\nevaluate the faithfulness of the generated summaries. However, these works\nprimarily focus on English and recent multilingual approaches lack German data.\nThis work presents absinth, a manually annotated dataset for hallucination\ndetection in German news summarization and explores the capabilities of novel\nopen-source LLMs on this task in both fine-tuning and in-context learning\nsettings. We open-source and release the absinth dataset to foster further\nresearch on hallucination detection in German.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "I.2.7"
    ],
    "primary_category": "cs.CL",
    "comment": "11 pages, 2 figures, 7 tables, conference: Joint International\n  Conference on Computational Linguistics, Language Resources and Evaluation\n  (LREC-COLING 2024), Turin, Italy, May 20-25, 2024",
    "pdf_url": "http://arxiv.org/pdf/2403.03750v2",
    "published_date": "2024-03-06 14:37:30 UTC",
    "updated_date": "2024-03-14 12:30:54 UTC"
  },
  {
    "arxiv_id": "2403.03744v5",
    "title": "MedSafetyBench: Evaluating and Improving the Medical Safety of Large Language Models",
    "authors": [
      "Tessa Han",
      "Aounon Kumar",
      "Chirag Agarwal",
      "Himabindu Lakkaraju"
    ],
    "abstract": "As large language models (LLMs) develop increasingly sophisticated\ncapabilities and find applications in medical settings, it becomes important to\nassess their medical safety due to their far-reaching implications for personal\nand public health, patient safety, and human rights. However, there is little\nto no understanding of the notion of medical safety in the context of LLMs, let\nalone how to evaluate and improve it. To address this gap, we first define the\nnotion of medical safety in LLMs based on the Principles of Medical Ethics set\nforth by the American Medical Association. We then leverage this understanding\nto introduce MedSafetyBench, the first benchmark dataset designed to measure\nthe medical safety of LLMs. We demonstrate the utility of MedSafetyBench by\nusing it to evaluate and improve the medical safety of LLMs. Our results show\nthat publicly-available medical LLMs do not meet standards of medical safety\nand that fine-tuning them using MedSafetyBench improves their medical safety\nwhile preserving their medical performance. By introducing this new benchmark\ndataset, our work enables a systematic study of the state of medical safety in\nLLMs and motivates future work in this area, paving the way to mitigate the\nsafety risks of LLMs in medicine. The benchmark dataset and code are available\nat https://github.com/AI4LIFE-GROUP/med-safety-bench.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.03744v5",
    "published_date": "2024-03-06 14:34:07 UTC",
    "updated_date": "2024-10-09 17:22:24 UTC"
  },
  {
    "arxiv_id": "2403.03741v1",
    "title": "SUPClust: Active Learning at the Boundaries",
    "authors": [
      "Yuta Ono",
      "Till Aczel",
      "Benjamin Estermann",
      "Roger Wattenhofer"
    ],
    "abstract": "Active learning is a machine learning paradigm designed to optimize model\nperformance in a setting where labeled data is expensive to acquire. In this\nwork, we propose a novel active learning method called SUPClust that seeks to\nidentify points at the decision boundary between classes. By targeting these\npoints, SUPClust aims to gather information that is most informative for\nrefining the model's prediction of complex decision regions. We demonstrate\nexperimentally that labeling these points leads to strong model performance.\nThis improvement is observed even in scenarios characterized by strong class\nimbalance.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted at ICLR 2024 Workshop on Practical Machine Learning for Low\n  Resource Settings (PML4LRS)",
    "pdf_url": "http://arxiv.org/pdf/2403.03741v1",
    "published_date": "2024-03-06 14:30:09 UTC",
    "updated_date": "2024-03-06 14:30:09 UTC"
  },
  {
    "arxiv_id": "2403.03739v1",
    "title": "A&B BNN: Add&Bit-Operation-Only Hardware-Friendly Binary Neural Network",
    "authors": [
      "Ruichen Ma",
      "Guanchao Qiao",
      "Yian Liu",
      "Liwei Meng",
      "Ning Ning",
      "Yang Liu",
      "Shaogang Hu"
    ],
    "abstract": "Binary neural networks utilize 1-bit quantized weights and activations to\nreduce both the model's storage demands and computational burden. However,\nadvanced binary architectures still incorporate millions of inefficient and\nnonhardware-friendly full-precision multiplication operations. A&B BNN is\nproposed to directly remove part of the multiplication operations in a\ntraditional BNN and replace the rest with an equal number of bit operations,\nintroducing the mask layer and the quantized RPReLU structure based on the\nnormalizer-free network architecture. The mask layer can be removed during\ninference by leveraging the intrinsic characteristics of BNN with\nstraightforward mathematical transformations to avoid the associated\nmultiplication operations. The quantized RPReLU structure enables more\nefficient bit operations by constraining its slope to be integer powers of 2.\nExperimental results achieved 92.30%, 69.35%, and 66.89% on the CIFAR-10,\nCIFAR-100, and ImageNet datasets, respectively, which are competitive with the\nstate-of-the-art. Ablation studies have verified the efficacy of the quantized\nRPReLU structure, leading to a 1.14% enhancement on the ImageNet compared to\nusing a fixed slope RLeakyReLU. The proposed add&bit-operation-only BNN offers\nan innovative approach for hardware-friendly network architecture.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "CVPR 2024 Accepted",
    "pdf_url": "http://arxiv.org/pdf/2403.03739v1",
    "published_date": "2024-03-06 14:28:49 UTC",
    "updated_date": "2024-03-06 14:28:49 UTC"
  },
  {
    "arxiv_id": "2403.03730v1",
    "title": "Learning 3D object-centric representation through prediction",
    "authors": [
      "John Day",
      "Tushar Arora",
      "Jirui Liu",
      "Li Erran Li",
      "Ming Bo Cai"
    ],
    "abstract": "As part of human core knowledge, the representation of objects is the\nbuilding block of mental representation that supports high-level concepts and\nsymbolic reasoning. While humans develop the ability of perceiving objects\nsituated in 3D environments without supervision, models that learn the same set\nof abilities with similar constraints faced by human infants are lacking.\nTowards this end, we developed a novel network architecture that simultaneously\nlearns to 1) segment objects from discrete images, 2) infer their 3D locations,\nand 3) perceive depth, all while using only information directly available to\nthe brain as training data, namely: sequences of images and self-motion. The\ncore idea is treating objects as latent causes of visual input which the brain\nuses to make efficient predictions of future scenes. This results in object\nrepresentations being learned as an essential byproduct of learning to predict.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "I.2.10; I.4.8; I.4.6; I.4.10; I.2.6"
    ],
    "primary_category": "cs.CV",
    "comment": "21 pages, 11 figures. Project webpage can be found at\n  https://jday54.github.io/opple_site/",
    "pdf_url": "http://arxiv.org/pdf/2403.03730v1",
    "published_date": "2024-03-06 14:19:11 UTC",
    "updated_date": "2024-03-06 14:19:11 UTC"
  },
  {
    "arxiv_id": "2403.03728v2",
    "title": "Bridging Diversity and Uncertainty in Active learning with Self-Supervised Pre-Training",
    "authors": [
      "Paul Doucet",
      "Benjamin Estermann",
      "Till Aczel",
      "Roger Wattenhofer"
    ],
    "abstract": "This study addresses the integration of diversity-based and uncertainty-based\nsampling strategies in active learning, particularly within the context of\nself-supervised pre-trained models. We introduce a straightforward heuristic\ncalled TCM that mitigates the cold start problem while maintaining strong\nperformance across various data levels. By initially applying TypiClust for\ndiversity sampling and subsequently transitioning to uncertainty sampling with\nMargin, our approach effectively combines the strengths of both strategies. Our\nexperiments demonstrate that TCM consistently outperforms existing methods\nacross various datasets in both low and high data regimes.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted at ICLR 2024 Workshop on Practical Machine Learning for Low\n  Resource Settings (PML4LRS)",
    "pdf_url": "http://arxiv.org/pdf/2403.03728v2",
    "published_date": "2024-03-06 14:18:24 UTC",
    "updated_date": "2025-01-17 15:15:15 UTC"
  },
  {
    "arxiv_id": "2403.03726v2",
    "title": "Diffusion on language model encodings for protein sequence generation",
    "authors": [
      "Viacheslav Meshchaninov",
      "Pavel Strashnov",
      "Andrey Shevtsov",
      "Fedor Nikolaev",
      "Nikita Ivanisenko",
      "Olga Kardymon",
      "Dmitry Vetrov"
    ],
    "abstract": "Protein sequence design has seen significant advances through discrete\ndiffusion and autoregressive approaches, yet the potential of continuous\ndiffusion remains underexplored. Here, we present DiMA, a latent diffusion\nframework that operates on protein language model representations. Through\nsystematic exploration of architectural choices and diffusion components, we\ndevelop a robust methodology that generalizes across multiple protein encoders\nranging from 8M to 3B parameters. We demonstrate that our framework achieves\nconsistently high performance across sequence-only (ESM-2, ESMc),\ndual-decodable (CHEAP), and multimodal (SaProt) representations using the same\narchitecture and training approach. We extensively evaluate existing methods\nalongside DiMA using multiple metrics across two protein modalities, covering\nquality, diversity, novelty, and distribution matching of generated proteins.\nDiMA consistently produces novel, high-quality and diverse protein sequences\nand achieves strong results compared to baselines such as autoregressive,\ndiscrete diffusion and flow matching language models. The model demonstrates\nversatile functionality, supporting conditional generation tasks including\nprotein family-generation, motif scaffolding and infilling, and fold-specific\nsequence design. This work provides a universal continuous diffusion framework\nfor protein sequence generation, offering both architectural insights and\npractical applicability across various protein design scenarios.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "q-bio.BM"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.03726v2",
    "published_date": "2024-03-06 14:15:20 UTC",
    "updated_date": "2025-02-05 08:26:23 UTC"
  },
  {
    "arxiv_id": "2403.03698v1",
    "title": "Towards Controllable Time Series Generation",
    "authors": [
      "Yifan Bao",
      "Yihao Ang",
      "Qiang Huang",
      "Anthony K. H. Tung",
      "Zhiyong Huang"
    ],
    "abstract": "Time Series Generation (TSG) has emerged as a pivotal technique in\nsynthesizing data that accurately mirrors real-world time series, becoming\nindispensable in numerous applications. Despite significant advancements in\nTSG, its efficacy frequently hinges on having large training datasets. This\ndependency presents a substantial challenge in data-scarce scenarios,\nespecially when dealing with rare or unique conditions. To confront these\nchallenges, we explore a new problem of Controllable Time Series Generation\n(CTSG), aiming to produce synthetic time series that can adapt to various\nexternal conditions, thereby tackling the data scarcity issue.\n  In this paper, we propose \\textbf{C}ontrollable \\textbf{T}ime \\textbf{S}eries\n(\\textsf{CTS}), an innovative VAE-agnostic framework tailored for CTSG. A key\nfeature of \\textsf{CTS} is that it decouples the mapping process from standard\nVAE training, enabling precise learning of a complex interplay between latent\nfeatures and external conditions. Moreover, we develop a comprehensive\nevaluation scheme for CTSG. Extensive experiments across three real-world time\nseries datasets showcase \\textsf{CTS}'s exceptional capabilities in generating\nhigh-quality, controllable outputs. This underscores its adeptness in\nseamlessly integrating latent features with external conditions. Extending\n\\textsf{CTS} to the image domain highlights its remarkable potential for\nexplainability and further reinforces its versatility across different\nmodalities.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.DB"
    ],
    "primary_category": "cs.LG",
    "comment": "14 pages, 13 figures, and 5 tables",
    "pdf_url": "http://arxiv.org/pdf/2403.03698v1",
    "published_date": "2024-03-06 13:27:34 UTC",
    "updated_date": "2024-03-06 13:27:34 UTC"
  },
  {
    "arxiv_id": "2403.05592v1",
    "title": "Eternal Sunshine of the Mechanical Mind: The Irreconcilability of Machine Learning and the Right to be Forgotten",
    "authors": [
      "Meem Arafat Manab"
    ],
    "abstract": "As we keep rapidly advancing toward an era where artificial intelligence is a\nconstant and normative experience for most of us, we must also be aware of what\nthis vision and this progress entail. By first approximating neural connections\nand activities in computer circuits and then creating more and more\nsophisticated versions of this crude approximation, we are now facing an age to\ncome where modern deep learning-based artificial intelligence systems can\nrightly be called thinking machines, and they are sometimes even lauded for\ntheir emergent behavior and black-box approaches. But as we create more\npowerful electronic brains, with billions of neural connections and parameters,\ncan we guarantee that these mammoths built of artificial neurons will be able\nto forget the data that we store in them? If they are at some level like a\nbrain, can the right to be forgotten still be protected while dealing with\nthese AIs? The essential gap between machine learning and the RTBF is explored\nin this article, with a premonition of far-reaching conclusions if the gap is\nnot bridged or reconciled any time soon. The core argument is that deep\nlearning models, due to their structure and size, cannot be expected to forget\nor delete a data as it would be expected from a tabular database, and they\nshould be treated more like a mechanical brain, albeit still in development.",
    "categories": [
      "cs.GL",
      "cs.AI",
      "68P27",
      "K.4.1; K.5.2; I.2.0"
    ],
    "primary_category": "cs.GL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.05592v1",
    "published_date": "2024-03-06 13:23:57 UTC",
    "updated_date": "2024-03-06 13:23:57 UTC"
  },
  {
    "arxiv_id": "2403.03691v3",
    "title": "MolNexTR: A Generalized Deep Learning Model for Molecular Image Recognition",
    "authors": [
      "Yufan Chen",
      "Ching Ting Leung",
      "Yong Huang",
      "Jianwei Sun",
      "Hao Chen",
      "Hanyu Gao"
    ],
    "abstract": "In the field of chemical structure recognition, the task of converting\nmolecular images into machine-readable data formats such as SMILES string\nstands as a significant challenge, primarily due to the varied drawing styles\nand conventions prevalent in chemical literature. To bridge this gap, we\nproposed MolNexTR, a novel image-to-graph deep learning model that collaborates\nto fuse the strengths of ConvNext, a powerful Convolutional Neural Network\nvariant, and Vision-TRansformer. This integration facilitates a more detailed\nextraction of both local and global features from molecular images. MolNexTR\ncan predict atoms and bonds simultaneously and understand their layout rules.\nIt also excels at flexibly integrating symbolic chemistry principles to discern\nchirality and decipher abbreviated structures. We further incorporate a series\nof advanced algorithms, including an improved data augmentation module, an\nimage contamination module, and a post-processing module for getting the final\nSMILES output. These modules cooperate to enhance the model's robustness to\ndiverse styles of molecular images found in real literature. In our test sets,\nMolNexTR has demonstrated superior performance, achieving an accuracy rate of\n81-97%, marking a significant advancement in the domain of molecular structure\nrecognition.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.03691v3",
    "published_date": "2024-03-06 13:17:41 UTC",
    "updated_date": "2024-08-28 03:57:26 UTC"
  },
  {
    "arxiv_id": "2403.03690v1",
    "title": "Rapidly Developing High-quality Instruction Data and Evaluation Benchmark for Large Language Models with Minimal Human Effort: A Case Study on Japanese",
    "authors": [
      "Yikun Sun",
      "Zhen Wan",
      "Nobuhiro Ueda",
      "Sakiko Yahata",
      "Fei Cheng",
      "Chenhui Chu",
      "Sadao Kurohashi"
    ],
    "abstract": "The creation of instruction data and evaluation benchmarks for serving Large\nlanguage models often involves enormous human annotation. This issue becomes\nparticularly pronounced when rapidly developing such resources for a\nnon-English language like Japanese. Instead of following the popular practice\nof directly translating existing English resources into Japanese (e.g.,\nJapanese-Alpaca), we propose an efficient self-instruct method based on GPT-4.\nWe first translate a small amount of English instructions into Japanese and\npost-edit them to obtain native-level quality. GPT-4 then utilizes them as\ndemonstrations to automatically generate Japanese instruction data. We also\nconstruct an evaluation benchmark containing 80 questions across 8 categories,\nusing GPT-4 to automatically assess the response quality of LLMs without human\nreferences. The empirical results suggest that the models fine-tuned on our\nGPT-4 self-instruct data significantly outperformed the Japanese-Alpaca across\nall three base pre-trained models. Our GPT-4 self-instruct data allowed the\nLLaMA 13B model to defeat GPT-3.5 (Davinci-003) with a 54.37\\% win-rate. The\nhuman evaluation exhibits the consistency between GPT-4's assessments and human\npreference. Our high-quality instruction data and evaluation benchmark have\nbeen released here.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "COLING 2024. Our code are available here:\n  \\href{https://github.com/hitoshizuku7/awesome-Ja-self-instruct}{self-instruct\n  data} and \\href{https://github.com/ku-nlp/ja-vicuna-qa-benchmark}{evaluation\n  benchmark}",
    "pdf_url": "http://arxiv.org/pdf/2403.03690v1",
    "published_date": "2024-03-06 13:17:07 UTC",
    "updated_date": "2024-03-06 13:17:07 UTC"
  },
  {
    "arxiv_id": "2403.03689v2",
    "title": "General2Specialized LLMs Translation for E-commerce",
    "authors": [
      "Kaidi Chen",
      "Ben Chen",
      "Dehong Gao",
      "Huangyu Dai",
      "Wen Jiang",
      "Wei Ning",
      "Shanqing Yu",
      "Libin Yang",
      "Xiaoyan Cai"
    ],
    "abstract": "Existing Neural Machine Translation (NMT) models mainly handle translation in\nthe general domain, while overlooking domains with special writing formulas,\nsuch as e-commerce and legal documents. Taking e-commerce as an example, the\ntexts usually include amounts of domain-related words and have more grammar\nproblems, which leads to inferior performances of current NMT methods. To\naddress these problems, we collect two domain-related resources, including a\nset of term pairs (aligned Chinese-English bilingual terms) and a parallel\ncorpus annotated for the e-commerce domain. Furthermore, we propose a two-step\nfine-tuning paradigm (named G2ST) with self-contrastive semantic enhancement to\ntransfer one general NMT model to the specialized NMT model for e-commerce. The\nparadigm can be used for the NMT models based on Large language models (LLMs).\nExtensive evaluations on real e-commerce titles demonstrate the superior\ntranslation quality and robustness of our G2ST approach, as compared with\nstate-of-the-art NMT models such as LLaMA, Qwen, GPT-3.5, and even GPT-4.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "4 pages, 1 figure, WWW2024 accepted",
    "pdf_url": "http://arxiv.org/pdf/2403.03689v2",
    "published_date": "2024-03-06 13:15:21 UTC",
    "updated_date": "2024-04-06 04:07:49 UTC"
  },
  {
    "arxiv_id": "2403.15413v1",
    "title": "Playing With Neuroscience: Past, Present and Future of Neuroimaging and Games",
    "authors": [
      "Paolo Burelli",
      "Laurits Dixen"
    ],
    "abstract": "Videogames have been a catalyst for advances in many research fields, such as\nartificial intelligence, human-computer interaction or virtual reality. Over\nthe years, research in fields such as artificial intelligence has enabled the\ndesign of new types of games, while games have often served as a powerful tool\nfor testing and simulation. Can this also happen with neuroscience? What is the\ncurrent relationship between neuroscience and games research? what can we\nexpect from the future? In this article, we'll try to answer these questions,\nanalysing the current state-of-the-art at the crossroads between neuroscience\nand games and envisioning future directions.",
    "categories": [
      "q-bio.NC",
      "cs.AI"
    ],
    "primary_category": "q-bio.NC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.15413v1",
    "published_date": "2024-03-06 12:38:18 UTC",
    "updated_date": "2024-03-06 12:38:18 UTC"
  },
  {
    "arxiv_id": "2403.03645v1",
    "title": "K-Link: Knowledge-Link Graph from LLMs for Enhanced Representation Learning in Multivariate Time-Series Data",
    "authors": [
      "Yucheng Wang",
      "Ruibing Jin",
      "Min Wu",
      "Xiaoli Li",
      "Lihua Xie",
      "Zhenghua Chen"
    ],
    "abstract": "Sourced from various sensors and organized chronologically, Multivariate\nTime-Series (MTS) data involves crucial spatial-temporal dependencies, e.g.,\ncorrelations among sensors. To capture these dependencies, Graph Neural\nNetworks (GNNs) have emerged as powerful tools, yet their effectiveness is\nrestricted by the quality of graph construction from MTS data. Typically,\nexisting approaches construct graphs solely from MTS signals, which may\nintroduce bias due to a small training dataset and may not accurately represent\nunderlying dependencies. To address this challenge, we propose a novel\nframework named K-Link, leveraging Large Language Models (LLMs) to encode\nextensive general knowledge and thereby providing effective solutions to reduce\nthe bias. Leveraging the knowledge embedded in LLMs, such as physical\nprinciples, we extract a \\textit{Knowledge-Link graph}, capturing vast semantic\nknowledge of sensors and the linkage of the sensor-level knowledge. To harness\nthe potential of the knowledge-link graph in enhancing the graph derived from\nMTS data, we propose a graph alignment module, facilitating the transfer of\nsemantic knowledge within the knowledge-link graph into the MTS-derived graph.\nBy doing so, we can improve the graph quality, ensuring effective\nrepresentation learning with GNNs for MTS data. Extensive experiments\ndemonstrate the efficacy of our approach for superior performance across\nvarious MTS-related downstream tasks.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "12 pages,7 figures",
    "pdf_url": "http://arxiv.org/pdf/2403.03645v1",
    "published_date": "2024-03-06 12:08:14 UTC",
    "updated_date": "2024-03-06 12:08:14 UTC"
  },
  {
    "arxiv_id": "2403.03643v2",
    "title": "A Survey on Applications of Reinforcement Learning in Spatial Resource Allocation",
    "authors": [
      "Di Zhang",
      "Moyang Wang",
      "Joseph Mango",
      "Xiang Li",
      "Xianrui Xu"
    ],
    "abstract": "The challenge of spatial resource allocation is pervasive across various\ndomains such as transportation, industry, and daily life. As the scale of\nreal-world issues continues to expand and demands for real-time solutions\nincrease, traditional algorithms face significant computational pressures,\nstruggling to achieve optimal efficiency and real-time capabilities. In recent\nyears, with the escalating computational power of computers, the remarkable\nachievements of reinforcement learning in domains like Go and robotics have\ndemonstrated its robust learning and sequential decision-making capabilities.\nGiven these advancements, there has been a surge in novel methods employing\nreinforcement learning to tackle spatial resource allocation problems. These\nmethods exhibit advantages such as rapid solution convergence and strong model\ngeneralization abilities, offering a new perspective on resolving spatial\nresource allocation problems. Therefore, this paper aims to summarize and\nreview recent theoretical methods and applied research utilizing reinforcement\nlearning to address spatial resource allocation problems. It provides a summary\nand comprehensive overview of its fundamental principles, related\nmethodologies, and applied research. Additionally, it highlights several\nunresolved issues that urgently require attention in this direction for the\nfuture.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.03643v2",
    "published_date": "2024-03-06 12:05:56 UTC",
    "updated_date": "2024-03-07 02:05:28 UTC"
  },
  {
    "arxiv_id": "2403.12997v1",
    "title": "A Multi-Task Oriented Semantic Communication Framework for Autonomous Vehicles",
    "authors": [
      "Eslam Eldeeb",
      "Mohammad Shehab",
      "Hirley Alves"
    ],
    "abstract": "Task-oriented semantic communication is an emerging technology that transmits\nonly the relevant semantics of a message instead of the whole message to\nachieve a specific task. It reduces latency, compresses the data, and is more\nrobust in low SNR scenarios. This work presents a multi-task-oriented semantic\ncommunication framework for connected and autonomous vehicles (CAVs). We\npropose a convolutional autoencoder (CAE) that performs the semantic encoding\nof the road traffic signs. These encoded images are then transmitted from one\nCAV to another CAV through satellite in challenging weather conditions where\nvisibility is impaired. In addition, we propose task-oriented semantic decoders\nfor image reconstruction and classification tasks. Simulation results show that\nthe proposed framework outperforms the conventional schemes, such as QAM-16,\nregarding the reconstructed image's similarity and the classification's\naccuracy. In addition, it can save up to 89 % of the bandwidth by sending fewer\nbits.",
    "categories": [
      "cs.NI",
      "cs.AI",
      "cs.IT",
      "cs.LG",
      "math.IT"
    ],
    "primary_category": "cs.NI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.12997v1",
    "published_date": "2024-03-06 12:04:24 UTC",
    "updated_date": "2024-03-06 12:04:24 UTC"
  },
  {
    "arxiv_id": "2403.03640v6",
    "title": "Apollo: A Lightweight Multilingual Medical LLM towards Democratizing Medical AI to 6B People",
    "authors": [
      "Xidong Wang",
      "Nuo Chen",
      "Junyin Chen",
      "Yidong Wang",
      "Guorui Zhen",
      "Chunxian Zhang",
      "Xiangbo Wu",
      "Yan Hu",
      "Anningzhe Gao",
      "Xiang Wan",
      "Haizhou Li",
      "Benyou Wang"
    ],
    "abstract": "Despite the vast repository of global medical knowledge predominantly being\nin English, local languages are crucial for delivering tailored healthcare\nservices, particularly in areas with limited medical resources. To extend the\nreach of medical AI advancements to a broader population, we aim to develop\nmedical LLMs across the six most widely spoken languages, encompassing a global\npopulation of 6.1 billion. This effort culminates in the creation of the\nApolloCorpora multilingual medical dataset and the XMedBench benchmark. In the\nmultilingual medical benchmark, the released Apollo models, at various\nrelatively-small sizes (i.e., 0.5B, 1.8B, 2B, 6B, and 7B), achieve the best\nperformance among models of equivalent size. Especially, Apollo-7B is the\nstate-of-the-art multilingual medical LLMs up to 70B. Additionally, these lite\nmodels could be used to improve the multi-lingual medical capabilities of\nlarger models without fine-tuning in a proxy-tuning fashion. We will\nopen-source training corpora, code, model weights and evaluation benchmark.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Preprint",
    "pdf_url": "http://arxiv.org/pdf/2403.03640v6",
    "published_date": "2024-03-06 11:56:02 UTC",
    "updated_date": "2024-10-12 14:09:33 UTC"
  },
  {
    "arxiv_id": "2403.03636v3",
    "title": "SheetAgent: Towards A Generalist Agent for Spreadsheet Reasoning and Manipulation via Large Language Models",
    "authors": [
      "Yibin Chen",
      "Yifu Yuan",
      "Zeyu Zhang",
      "Yan Zheng",
      "Jinyi Liu",
      "Fei Ni",
      "Jianye Hao",
      "Hangyu Mao",
      "Fuzheng Zhang"
    ],
    "abstract": "Spreadsheets are ubiquitous across the World Wide Web, playing a critical\nrole in enhancing work efficiency across various domains. Large language model\n(LLM) has been recently attempted for automatic spreadsheet manipulation but\nhas not yet been investigated in complicated and realistic tasks where\nreasoning challenges exist (e.g., long horizon manipulation with multi-step\nreasoning and ambiguous requirements). To bridge the gap with the real-world\nrequirements, we introduce SheetRM, a benchmark featuring long-horizon and\nmulti-category tasks with reasoning-dependent manipulation caused by real-life\nchallenges. To mitigate the above challenges, we further propose SheetAgent, a\nnovel autonomous agent that utilizes the power of LLMs. SheetAgent consists of\nthree collaborative modules: Planner, Informer, and Retriever, achieving both\nadvanced reasoning and accurate manipulation over spreadsheets without human\ninteraction through iterative task reasoning and reflection. Extensive\nexperiments demonstrate that SheetAgent delivers 20--40\\% pass rate\nimprovements on multiple benchmarks over baselines, achieving enhanced\nprecision in spreadsheet manipulation and demonstrating superior table\nreasoning abilities. More details and visualizations are available at the\nproject website: https://sheetagent.github.io/. The datasets and source code\nare available at https://anonymous.4open.science/r/SheetAgent.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted by International World Wide Web Conference (WWW) 2025 (oral)",
    "pdf_url": "http://arxiv.org/pdf/2403.03636v3",
    "published_date": "2024-03-06 11:48:08 UTC",
    "updated_date": "2025-03-03 06:56:29 UTC"
  },
  {
    "arxiv_id": "2403.03627v2",
    "title": "Multimodal Large Language Models to Support Real-World Fact-Checking",
    "authors": [
      "Jiahui Geng",
      "Yova Kementchedjhieva",
      "Preslav Nakov",
      "Iryna Gurevych"
    ],
    "abstract": "Multimodal large language models (MLLMs) carry the potential to support\nhumans in processing vast amounts of information. While MLLMs are already being\nused as a fact-checking tool, their abilities and limitations in this regard\nare understudied. Here is aim to bridge this gap. In particular, we propose a\nframework for systematically assessing the capacity of current multimodal\nmodels to facilitate real-world fact-checking. Our methodology is\nevidence-free, leveraging only these models' intrinsic knowledge and reasoning\ncapabilities. By designing prompts that extract models' predictions,\nexplanations, and confidence levels, we delve into research questions\nconcerning model accuracy, robustness, and reasons for failure. We empirically\nfind that (1) GPT-4V exhibits superior performance in identifying malicious and\nmisleading multimodal claims, with the ability to explain the unreasonable\naspects and underlying motives, and (2) existing open-source models exhibit\nstrong biases and are highly sensitive to the prompt. Our study offers insights\ninto combating false multimodal information and building secure, trustworthy\nmultimodal models. To the best of our knowledge, we are the first to evaluate\nMLLMs for real-world fact-checking.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.03627v2",
    "published_date": "2024-03-06 11:32:41 UTC",
    "updated_date": "2024-04-26 05:16:53 UTC"
  },
  {
    "arxiv_id": "2403.03608v1",
    "title": "GSNeRF: Generalizable Semantic Neural Radiance Fields with Enhanced 3D Scene Understanding",
    "authors": [
      "Zi-Ting Chou",
      "Sheng-Yu Huang",
      "I-Jieh Liu",
      "Yu-Chiang Frank Wang"
    ],
    "abstract": "Utilizing multi-view inputs to synthesize novel-view images, Neural Radiance\nFields (NeRF) have emerged as a popular research topic in 3D vision. In this\nwork, we introduce a Generalizable Semantic Neural Radiance Field (GSNeRF),\nwhich uniquely takes image semantics into the synthesis process so that both\nnovel view images and the associated semantic maps can be produced for unseen\nscenes. Our GSNeRF is composed of two stages: Semantic Geo-Reasoning and\nDepth-Guided Visual rendering. The former is able to observe multi-view image\ninputs to extract semantic and geometry features from a scene. Guided by the\nresulting image geometry information, the latter performs both image and\nsemantic rendering with improved performances. Our experiments not only confirm\nthat GSNeRF performs favorably against prior works on both novel-view image and\nsemantic segmentation synthesis but the effectiveness of our sampling strategy\nfor visual rendering is further verified.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted by CVPR2024",
    "pdf_url": "http://arxiv.org/pdf/2403.03608v1",
    "published_date": "2024-03-06 10:55:50 UTC",
    "updated_date": "2024-03-06 10:55:50 UTC"
  },
  {
    "arxiv_id": "2403.03607v1",
    "title": "The Geometric Structure of Topic Models",
    "authors": [
      "Johannes Hirth",
      "Tom Hanika"
    ],
    "abstract": "Topic models are a popular tool for clustering and analyzing textual data.\nThey allow texts to be classified on the basis of their affiliation to the\npreviously calculated topics. Despite their widespread use in research and\napplication, an in-depth analysis of topic models is still an open research\ntopic. State-of-the-art methods for interpreting topic models are based on\nsimple visualizations, such as similarity matrices, top-term lists or\nembeddings, which are limited to a maximum of three dimensions. In this paper,\nwe propose an incidence-geometric method for deriving an ordinal structure from\nflat topic models, such as non-negative matrix factorization. These enable the\nanalysis of the topic model in a higher (order) dimension and the possibility\nof extracting conceptual relationships between several topics at once. Due to\nthe use of conceptual scaling, our approach does not introduce any artificial\ntopical relationships, such as artifacts of feature compression. Based on our\nfindings, we present a new visualization paradigm for concept hierarchies based\non ordinal motifs. These allow for a top-down view on topic spaces. We\nintroduce and demonstrate the applicability of our approach based on a topic\nmodel derived from a corpus of scientific papers taken from 32 top machine\nlearning venues.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.03607v1",
    "published_date": "2024-03-06 10:53:51 UTC",
    "updated_date": "2024-03-06 10:53:51 UTC"
  },
  {
    "arxiv_id": "2403.03606v1",
    "title": "Enhancing Price Prediction in Cryptocurrency Using Transformer Neural Network and Technical Indicators",
    "authors": [
      "Mohammad Ali Labbaf Khaniki",
      "Mohammad Manthouri"
    ],
    "abstract": "This study presents an innovative approach for predicting cryptocurrency time\nseries, specifically focusing on Bitcoin, Ethereum, and Litecoin. The\nmethodology integrates the use of technical indicators, a Performer neural\nnetwork, and BiLSTM (Bidirectional Long Short-Term Memory) to capture temporal\ndynamics and extract significant features from raw cryptocurrency data. The\napplication of technical indicators, such facilitates the extraction of\nintricate patterns, momentum, volatility, and trends. The Performer neural\nnetwork, employing Fast Attention Via positive Orthogonal Random features\n(FAVOR+), has demonstrated superior computational efficiency and scalability\ncompared to the traditional Multi-head attention mechanism in Transformer\nmodels. Additionally, the integration of BiLSTM in the feedforward network\nenhances the model's capacity to capture temporal dynamics in the data,\nprocessing it in both forward and backward directions. This is particularly\nadvantageous for time series data where past and future data points can\ninfluence the current state. The proposed method has been applied to the hourly\nand daily timeframes of the major cryptocurrencies and its performance has been\nbenchmarked against other methods documented in the literature. The results\nunderscore the potential of the proposed method to outperform existing models,\nmarking a significant progression in the field of cryptocurrency price\nprediction.",
    "categories": [
      "q-fin.CP",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "q-fin.CP",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.03606v1",
    "published_date": "2024-03-06 10:53:12 UTC",
    "updated_date": "2024-03-06 10:53:12 UTC"
  },
  {
    "arxiv_id": "2403.03600v1",
    "title": "A Privacy-Preserving Framework with Multi-Modal Data for Cross-Domain Recommendation",
    "authors": [
      "Li Wang",
      "Lei Sang",
      "Quangui Zhang",
      "Qiang Wu",
      "Min Xu"
    ],
    "abstract": "Cross-domain recommendation (CDR) aims to enhance recommendation accuracy in\na target domain with sparse data by leveraging rich information in a source\ndomain, thereby addressing the data-sparsity problem. Some existing CDR methods\nhighlight the advantages of extracting domain-common and domain-specific\nfeatures to learn comprehensive user and item representations. However, these\nmethods can't effectively disentangle these components as they often rely on\nsimple user-item historical interaction information (such as ratings, clicks,\nand browsing), neglecting the rich multi-modal features. Additionally, they\ndon't protect user-sensitive data from potential leakage during knowledge\ntransfer between domains. To address these challenges, we propose a\nPrivacy-Preserving Framework with Multi-Modal Data for Cross-Domain\nRecommendation, called P2M2-CDR. Specifically, we first design a multi-modal\ndisentangled encoder that utilizes multi-modal information to disentangle more\ninformative domain-common and domain-specific embeddings. Furthermore, we\nintroduce a privacy-preserving decoder to mitigate user privacy leakage during\nknowledge transfer. Local differential privacy (LDP) is utilized to obfuscate\nthe disentangled embeddings before inter-domain exchange, thereby enhancing\nprivacy protection. To ensure both consistency and differentiation among these\nobfuscated disentangled embeddings, we incorporate contrastive learning-based\ndomain-inter and domain-intra losses. Extensive Experiments conducted on four\nreal-world datasets demonstrate that P2M2-CDR outperforms other\nstate-of-the-art single-domain and cross-domain baselines.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.03600v1",
    "published_date": "2024-03-06 10:40:08 UTC",
    "updated_date": "2024-03-06 10:40:08 UTC"
  },
  {
    "arxiv_id": "2403.03594v1",
    "title": "Assessing the Aesthetic Evaluation Capabilities of GPT-4 with Vision: Insights from Group and Individual Assessments",
    "authors": [
      "Yoshia Abe",
      "Tatsuya Daikoku",
      "Yasuo Kuniyoshi"
    ],
    "abstract": "Recently, it has been recognized that large language models demonstrate high\nperformance on various intellectual tasks. However, few studies have\ninvestigated alignment with humans in behaviors that involve sensibility, such\nas aesthetic evaluation. This study investigates the performance of GPT-4 with\nVision, a state-of-the-art language model that can handle image input, on the\ntask of aesthetic evaluation of images. We employ two tasks, prediction of the\naverage evaluation values of a group and an individual's evaluation values. We\ninvestigate the performance of GPT-4 with Vision by exploring prompts and\nanalyzing prediction behaviors. Experimental results reveal GPT-4 with Vision's\nsuperior performance in predicting aesthetic evaluations and the nature of\ndifferent responses to beauty and ugliness. Finally, we discuss developing an\nAI system for aesthetic evaluation based on scientific knowledge of the human\nperception of beauty, employing agent technologies that integrate traditional\ndeep learning models with large language models.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "8 pages, 6 figures, submitted to The 38th Annual Conference of the\n  Japanese Society for Artificial Intelligence, 2024",
    "pdf_url": "http://arxiv.org/pdf/2403.03594v1",
    "published_date": "2024-03-06 10:27:09 UTC",
    "updated_date": "2024-03-06 10:27:09 UTC"
  },
  {
    "arxiv_id": "2403.03593v2",
    "title": "Do You Trust Your Model? Emerging Malware Threats in the Deep Learning Ecosystem",
    "authors": [
      "Dorjan Hitaj",
      "Giulio Pagnotta",
      "Fabio De Gaspari",
      "Sediola Ruko",
      "Briland Hitaj",
      "Luigi V. Mancini",
      "Fernando Perez-Cruz"
    ],
    "abstract": "Training high-quality deep learning models is a challenging task due to\ncomputational and technical requirements. A growing number of individuals,\ninstitutions, and companies increasingly rely on pre-trained, third-party\nmodels made available in public repositories. These models are often used\ndirectly or integrated in product pipelines with no particular precautions,\nsince they are effectively just data in tensor form and considered safe. In\nthis paper, we raise awareness of a new machine learning supply chain threat\ntargeting neural networks. We introduce MaleficNet 2.0, a novel technique to\nembed self-extracting, self-executing malware in neural networks. MaleficNet\n2.0 uses spread-spectrum channel coding combined with error correction\ntechniques to inject malicious payloads in the parameters of deep neural\nnetworks. MaleficNet 2.0 injection technique is stealthy, does not degrade the\nperformance of the model, and is robust against removal techniques. We design\nour approach to work both in traditional and distributed learning settings such\nas Federated Learning, and demonstrate that it is effective even when a reduced\nnumber of bits is used for the model parameters. Finally, we implement a\nproof-of-concept self-extracting neural network malware using MaleficNet 2.0,\ndemonstrating the practicality of the attack against a widely adopted machine\nlearning framework. Our aim with this work is to raise awareness against these\nnew, dangerous attacks both in the research community and industry, and we hope\nto encourage further research in mitigation techniques against such threats.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "18 pages",
    "pdf_url": "http://arxiv.org/pdf/2403.03593v2",
    "published_date": "2024-03-06 10:27:08 UTC",
    "updated_date": "2025-05-13 11:56:20 UTC"
  },
  {
    "arxiv_id": "2403.03592v1",
    "title": "Wildest Dreams: Reproducible Research in Privacy-preserving Neural Network Training",
    "authors": [
      "Tanveer Khan",
      "Mindaugas Budzys",
      "Khoa Nguyen",
      "Antonis Michalas"
    ],
    "abstract": "Machine Learning (ML), addresses a multitude of complex issues in multiple\ndisciplines, including social sciences, finance, and medical research. ML\nmodels require substantial computing power and are only as powerful as the data\nutilized. Due to high computational cost of ML methods, data scientists\nfrequently use Machine Learning-as-a-Service (MLaaS) to outsource computation\nto external servers. However, when working with private information, like\nfinancial data or health records, outsourcing the computation might result in\nprivacy issues. Recent advances in Privacy-Preserving Techniques (PPTs) have\nenabled ML training and inference over protected data through the use of\nPrivacy-Preserving Machine Learning (PPML). However, these techniques are still\nat a preliminary stage and their application in real-world situations is\ndemanding. In order to comprehend discrepancy between theoretical research\nsuggestions and actual applications, this work examines the past and present of\nPPML, focusing on Homomorphic Encryption (HE) and Secure Multi-party\nComputation (SMPC) applied to ML. This work primarily focuses on the ML model's\ntraining phase, where maintaining user data privacy is of utmost importance. We\nprovide a solid theoretical background that eases the understanding of current\napproaches and their limitations. In addition, we present a SoK of the most\nrecent PPML frameworks for model training and provide a comprehensive\ncomparison in terms of the unique properties and performances on standard\nbenchmarks. Also, we reproduce the results for some of the papers and examine\nat what level existing works in the field provide support for open science. We\nbelieve our work serves as a valuable contribution by raising awareness about\nthe current gap between theoretical advancements and real-world applications in\nPPML, specifically regarding open-source availability, reproducibility, and\nusability.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.03592v1",
    "published_date": "2024-03-06 10:25:36 UTC",
    "updated_date": "2024-03-06 10:25:36 UTC"
  },
  {
    "arxiv_id": "2403.03585v1",
    "title": "RouteExplainer: An Explanation Framework for Vehicle Routing Problem",
    "authors": [
      "Daisuke Kikuta",
      "Hiroki Ikeuchi",
      "Kengo Tajiri",
      "Yuusuke Nakano"
    ],
    "abstract": "The Vehicle Routing Problem (VRP) is a widely studied combinatorial\noptimization problem and has been applied to various practical problems. While\nthe explainability for VRP is significant for improving the reliability and\ninteractivity in practical VRP applications, it remains unexplored. In this\npaper, we propose RouteExplainer, a post-hoc explanation framework that\nexplains the influence of each edge in a generated route. Our framework\nrealizes this by rethinking a route as the sequence of actions and extending\ncounterfactual explanations based on the action influence model to VRP. To\nenhance the explanation, we additionally propose an edge classifier that infers\nthe intentions of each edge, a loss function to train the edge classifier, and\nexplanation-text generation by Large Language Models (LLMs). We quantitatively\nevaluate our edge classifier on four different VRPs. The results demonstrate\nits rapid computation while maintaining reasonable accuracy, thereby\nhighlighting its potential for deployment in practical applications. Moreover,\non the subject of a tourist route, we qualitatively evaluate explanations\ngenerated by our framework. This evaluation not only validates our framework\nbut also shows the synergy between explanation frameworks and LLMs. See\nhttps://ntt-dkiku.github.io/xai-vrp for our code, datasets, models, and demo.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "math.OC"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted at PAKDD 2024. This extended version includes more\n  comprehensive explanations and appendices",
    "pdf_url": "http://arxiv.org/pdf/2403.03585v1",
    "published_date": "2024-03-06 10:01:35 UTC",
    "updated_date": "2024-03-06 10:01:35 UTC"
  },
  {
    "arxiv_id": "2403.03582v1",
    "title": "Design of an Open-Source Architecture for Neural Machine Translation",
    "authors": [
      "S√©amus Lankford",
      "Haithem Afli",
      "Andy Way"
    ],
    "abstract": "adaptNMT is an open-source application that offers a streamlined approach to\nthe development and deployment of Recurrent Neural Networks and Transformer\nmodels. This application is built upon the widely-adopted OpenNMT ecosystem,\nand is particularly useful for new entrants to the field, as it simplifies the\nsetup of the development environment and creation of train, validation, and\ntest splits. The application offers a graphing feature that illustrates the\nprogress of model training, and employs SentencePiece for creating subword\nsegmentation models. Furthermore, the application provides an intuitive user\ninterface that facilitates hyperparameter customization. Notably, a\nsingle-click model development approach has been implemented, and models\ndeveloped by adaptNMT can be evaluated using a range of metrics. To encourage\neco-friendly research, adaptNMT incorporates a green report that flags the\npower consumption and kgCO${_2}$ emissions generated during model development.\nThe application is freely available.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "arXiv admin note: substantial text overlap with arXiv:2403.02367",
    "pdf_url": "http://arxiv.org/pdf/2403.03582v1",
    "published_date": "2024-03-06 09:57:52 UTC",
    "updated_date": "2024-03-06 09:57:52 UTC"
  },
  {
    "arxiv_id": "2403.03578v1",
    "title": "Causal Disentanglement for Regulating Social Influence Bias in Social Recommendation",
    "authors": [
      "Li Wang",
      "Min Xu",
      "Quangui Zhang",
      "Yunxiao Shi",
      "Qiang Wu"
    ],
    "abstract": "Social recommendation systems face the problem of social influence bias,\nwhich can lead to an overemphasis on recommending items that friends have\ninteracted with. Addressing this problem is crucial, and existing methods often\nrely on techniques such as weight adjustment or leveraging unbiased data to\neliminate this bias. However, we argue that not all biases are detrimental,\ni.e., some items recommended by friends may align with the user's interests.\nBlindly eliminating such biases could undermine these positive effects,\npotentially diminishing recommendation accuracy. In this paper, we propose a\nCausal Disentanglement-based framework for Regulating Social influence Bias in\nsocial recommendation, named CDRSB, to improve recommendation performance. From\nthe perspective of causal inference, we find that the user social network could\nbe regarded as a confounder between the user and item embeddings (treatment)\nand ratings (outcome). Due to the presence of this social network confounder,\ntwo paths exist from user and item embeddings to ratings: a non-causal social\ninfluence path and a causal interest path. Building upon this insight, we\npropose a disentangled encoder that focuses on disentangling user and item\nembeddings into interest and social influence embeddings. Mutual\ninformation-based objectives are designed to enhance the distinctiveness of\nthese disentangled embeddings, eliminating redundant information. Additionally,\na regulatory decoder that employs a weight calculation module to dynamically\nlearn the weights of social influence embeddings for effectively regulating\nsocial influence bias has been designed. Experimental results on four\nlarge-scale real-world datasets Ciao, Epinions, Dianping, and Douban book\ndemonstrate the effectiveness of CDRSB compared to state-of-the-art baselines.",
    "categories": [
      "cs.SI",
      "cs.AI"
    ],
    "primary_category": "cs.SI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.03578v1",
    "published_date": "2024-03-06 09:48:48 UTC",
    "updated_date": "2024-03-06 09:48:48 UTC"
  },
  {
    "arxiv_id": "2403.03575v1",
    "title": "gaHealth: An English-Irish Bilingual Corpus of Health Data",
    "authors": [
      "S√©amus Lankford",
      "Haithem Afli",
      "√ìrla N√≠ Loinsigh",
      "Andy Way"
    ],
    "abstract": "Machine Translation is a mature technology for many high-resource language\npairs. However in the context of low-resource languages, there is a paucity of\nparallel data datasets available for developing translation models.\nFurthermore, the development of datasets for low-resource languages often\nfocuses on simply creating the largest possible dataset for generic\ntranslation. The benefits and development of smaller in-domain datasets can\neasily be overlooked. To assess the merits of using in-domain data, a dataset\nfor the specific domain of health was developed for the low-resource English to\nIrish language pair. Our study outlines the process used in developing the\ncorpus and empirically demonstrates the benefits of using an in-domain dataset\nfor the health domain. In the context of translating health-related data,\nmodels developed using the gaHealth corpus demonstrated a maximum BLEU score\nimprovement of 22.2 points (40%) when compared with top performing models from\nthe LoResMT2021 Shared Task. Furthermore, we define linguistic guidelines for\ndeveloping gaHealth, the first bilingual corpus of health data for the Irish\nlanguage, which we hope will be of use to other creators of low-resource data\nsets. gaHealth is now freely available online and is ready to be explored for\nfurther research.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "arXiv admin note: text overlap with arXiv:2403.02367",
    "pdf_url": "http://arxiv.org/pdf/2403.03575v1",
    "published_date": "2024-03-06 09:36:36 UTC",
    "updated_date": "2024-03-06 09:36:36 UTC"
  },
  {
    "arxiv_id": "2403.03550v1",
    "title": "Emotional Manipulation Through Prompt Engineering Amplifies Disinformation Generation in AI Large Language Models",
    "authors": [
      "Rasita Vinay",
      "Giovanni Spitale",
      "Nikola Biller-Andorno",
      "Federico Germani"
    ],
    "abstract": "This study investigates the generation of synthetic disinformation by\nOpenAI's Large Language Models (LLMs) through prompt engineering and explores\ntheir responsiveness to emotional prompting. Leveraging various LLM iterations\nusing davinci-002, davinci-003, gpt-3.5-turbo and gpt-4, we designed\nexperiments to assess their success in producing disinformation. Our findings,\nbased on a corpus of 19,800 synthetic disinformation social media posts, reveal\nthat all LLMs by OpenAI can successfully produce disinformation, and that they\neffectively respond to emotional prompting, indicating their nuanced\nunderstanding of emotional cues in text generation. When prompted politely, all\nexamined LLMs consistently generate disinformation at a high frequency.\nConversely, when prompted impolitely, the frequency of disinformation\nproduction diminishes, as the models often refuse to generate disinformation\nand instead caution users that the tool is not intended for such purposes. This\nresearch contributes to the ongoing discourse surrounding responsible\ndevelopment and application of AI technologies, particularly in mitigating the\nspread of disinformation and promoting transparency in AI-generated content.",
    "categories": [
      "cs.AI",
      "cs.CY",
      "cs.HC"
    ],
    "primary_category": "cs.AI",
    "comment": "14 pages, 3 figures",
    "pdf_url": "http://arxiv.org/pdf/2403.03550v1",
    "published_date": "2024-03-06 08:50:25 UTC",
    "updated_date": "2024-03-06 08:50:25 UTC"
  },
  {
    "arxiv_id": "2403.04807v1",
    "title": "Mathematics of Neural Networks (Lecture Notes Graduate Course)",
    "authors": [
      "Bart M. N. Smets"
    ],
    "abstract": "These are the lecture notes that accompanied the course of the same name that\nI taught at the Eindhoven University of Technology from 2021 to 2023. The\ncourse is intended as an introduction to neural networks for mathematics\nstudents at the graduate level and aims to make mathematics students interested\nin further researching neural networks. It consists of two parts: first a\ngeneral introduction to deep learning that focuses on introducing the field in\na formal mathematical way. The second part provides an introduction to the\ntheory of Lie groups and homogeneous spaces and how it can be applied to design\nneural networks with desirable geometric equivariances. The lecture notes were\nmade to be as self-contained as possible so as to accessible for any student\nwith a moderate mathematics background. The course also included coding\ntutorials and assignments in the form of a set of Jupyter notebooks that are\npublicly available at\nhttps://gitlab.com/bsmetsjr/mathematics_of_neural_networks.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Lecture notes of the graduate course 2MMA80 Mathematics of Neural\n  Networks as thought at the Eindhoven University of Technology from 2021 to\n  2023",
    "pdf_url": "http://arxiv.org/pdf/2403.04807v1",
    "published_date": "2024-03-06 08:45:29 UTC",
    "updated_date": "2024-03-06 08:45:29 UTC"
  },
  {
    "arxiv_id": "2403.03544v1",
    "title": "Prompt Mining for Language-based Human Mobility Forecasting",
    "authors": [
      "Hao Xue",
      "Tianye Tang",
      "Ali Payani",
      "Flora D. Salim"
    ],
    "abstract": "With the advancement of large language models, language-based forecasting has\nrecently emerged as an innovative approach for predicting human mobility\npatterns. The core idea is to use prompts to transform the raw mobility data\ngiven as numerical values into natural language sentences so that the language\nmodels can be leveraged to generate the description for future observations.\nHowever, previous studies have only employed fixed and manually designed\ntemplates to transform numerical values into sentences. Since the forecasting\nperformance of language models heavily relies on prompts, using fixed templates\nfor prompting may limit the forecasting capability of language models. In this\npaper, we propose a novel framework for prompt mining in language-based\nmobility forecasting, aiming to explore diverse prompt design strategies.\nSpecifically, the framework includes a prompt generation stage based on the\ninformation entropy of prompts and a prompt refinement stage to integrate\nmechanisms such as the chain of thought. Experimental results on real-world\nlarge-scale data demonstrate the superiority of generated prompts from our\nprompt mining pipeline. Additionally, the comparison of different prompt\nvariants shows that the proposed prompt refinement process is effective. Our\nstudy presents a promising direction for further advancing language-based\nmobility forecasting.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.03544v1",
    "published_date": "2024-03-06 08:43:30 UTC",
    "updated_date": "2024-03-06 08:43:30 UTC"
  },
  {
    "arxiv_id": "2403.03538v1",
    "title": "RADIA -- Radio Advertisement Detection with Intelligent Analytics",
    "authors": [
      "Jorge √Ålvarez",
      "Juan Carlos Armenteros",
      "Camilo Torr√≥n",
      "Miguel Ortega-Mart√≠n",
      "Alfonso Ardoiz",
      "√ìscar Garc√≠a",
      "Ignacio Arranz",
      "√ç√±igo Galdeano",
      "Ignacio Garrido",
      "Adri√°n Alonso",
      "Fernando Bay√≥n",
      "Oleg Vorontsov"
    ],
    "abstract": "Radio advertising remains an integral part of modern marketing strategies,\nwith its appeal and potential for targeted reach undeniably effective. However,\nthe dynamic nature of radio airtime and the rising trend of multiple radio\nspots necessitates an efficient system for monitoring advertisement broadcasts.\nThis study investigates a novel automated radio advertisement detection\ntechnique incorporating advanced speech recognition and text classification\nalgorithms. RadIA's approach surpasses traditional methods by eliminating the\nneed for prior knowledge of the broadcast content. This contribution allows for\ndetecting impromptu and newly introduced advertisements, providing a\ncomprehensive solution for advertisement detection in radio broadcasting.\nExperimental results show that the resulting model, trained on carefully\nsegmented and tagged text data, achieves an F1-macro score of 87.76 against a\ntheoretical maximum of 89.33. This paper provides insights into the choice of\nhyperparameters and their impact on the model's performance. This study\ndemonstrates its potential to ensure compliance with advertising broadcast\ncontracts and offer competitive surveillance. This groundbreaking research\ncould fundamentally change how radio advertising is monitored and open new\ndoors for marketing optimization.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.CL",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.03538v1",
    "published_date": "2024-03-06 08:34:28 UTC",
    "updated_date": "2024-03-06 08:34:28 UTC"
  },
  {
    "arxiv_id": "2403.03536v2",
    "title": "Towards Efficient and Effective Unlearning of Large Language Models for Recommendation",
    "authors": [
      "Hangyu Wang",
      "Jianghao Lin",
      "Bo Chen",
      "Yang Yang",
      "Ruiming Tang",
      "Weinan Zhang",
      "Yong Yu"
    ],
    "abstract": "The significant advancements in large language models (LLMs) give rise to a\npromising research direction, i.e., leveraging LLMs as recommenders (LLMRec).\nThe efficacy of LLMRec arises from the open-world knowledge and reasoning\ncapabilities inherent in LLMs. LLMRec acquires the recommendation capabilities\nthrough instruction tuning based on user interaction data. However, in order to\nprotect user privacy and optimize utility, it is also crucial for LLMRec to\nintentionally forget specific user data, which is generally referred to as\nrecommendation unlearning. In the era of LLMs, recommendation unlearning poses\nnew challenges for LLMRec in terms of \\textit{inefficiency} and\n\\textit{ineffectiveness}. Existing unlearning methods require updating billions\nof parameters in LLMRec, which is costly and time-consuming. Besides, they\nalways impact the model utility during the unlearning process. To this end, we\npropose \\textbf{E2URec}, the first \\underline{E}fficient and\n\\underline{E}ffective \\underline{U}nlearning method for LLM\\underline{Rec}. Our\nproposed E2URec enhances the unlearning efficiency by updating only a few\nadditional LoRA parameters, and improves the unlearning effectiveness by\nemploying a teacher-student framework, where we maintain multiple teacher\nnetworks to guide the unlearning process. Extensive experiments show that\nE2URec outperforms state-of-the-art baselines on two real-world datasets.\nSpecifically, E2URec can efficiently forget specific data without affecting\nrecommendation performance. The source code is at\n\\url{https://github.com/justarter/E2URec}.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "Accepted by Frontier of Computer Science",
    "pdf_url": "http://arxiv.org/pdf/2403.03536v2",
    "published_date": "2024-03-06 08:31:35 UTC",
    "updated_date": "2024-06-30 04:00:06 UTC"
  },
  {
    "arxiv_id": "2403.03517v1",
    "title": "IB-Net: Initial Branch Network for Variable Decision in Boolean Satisfiability",
    "authors": [
      "Tsz Ho Chan",
      "Wenyi Xiao",
      "Junhua Huang",
      "Huiling Zhen",
      "Guangji Tian",
      "Mingxuan Yuan"
    ],
    "abstract": "Boolean Satisfiability problems are vital components in Electronic Design\nAutomation, particularly within the Logic Equivalence Checking process.\nCurrently, SAT solvers are employed for these problems and neural network is\ntried as assistance to solvers. However, as SAT problems in the LEC context are\ndistinctive due to their predominantly unsatisfiability nature and a\nsubstantial proportion of UNSAT-core variables, existing neural network\nassistance has proven unsuccessful in this specialized domain. To tackle this\nchallenge, we propose IB-Net, an innovative framework utilizing graph neural\nnetworks and novel graph encoding techniques to model unsatisfiable problems\nand interact with state-of-the-art solvers. Extensive evaluations across\nsolvers and datasets demonstrate IB-Net's acceleration, achieving an average\nruntime speedup of 5.0% on industrial data and 8.3% on SAT competition data\nempirically. This breakthrough advances efficient solving in LEC workflows.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "7 pages, 12 figures",
    "pdf_url": "http://arxiv.org/pdf/2403.03517v1",
    "published_date": "2024-03-06 07:54:40 UTC",
    "updated_date": "2024-03-06 07:54:40 UTC"
  },
  {
    "arxiv_id": "2403.03506v4",
    "title": "Detecting AI-Generated Sentences in Human-AI Collaborative Hybrid Texts: Challenges, Strategies, and Insights",
    "authors": [
      "Zijie Zeng",
      "Shiqi Liu",
      "Lele Sha",
      "Zhuang Li",
      "Kaixun Yang",
      "Sannyuya Liu",
      "Dragan Ga≈°eviƒá",
      "Guanliang Chen"
    ],
    "abstract": "This study explores the challenge of sentence-level AI-generated text\ndetection within human-AI collaborative hybrid texts. Existing studies of\nAI-generated text detection for hybrid texts often rely on synthetic datasets.\nThese typically involve hybrid texts with a limited number of boundaries. We\ncontend that studies of detecting AI-generated content within hybrid texts\nshould cover different types of hybrid texts generated in realistic settings to\nbetter inform real-world applications. Therefore, our study utilizes the\nCoAuthor dataset, which includes diverse, realistic hybrid texts generated\nthrough the collaboration between human writers and an intelligent writing\nsystem in multi-turn interactions. We adopt a two-step, segmentation-based\npipeline: (i) detect segments within a given hybrid text where each segment\ncontains sentences of consistent authorship, and (ii) classify the authorship\nof each identified segment. Our empirical findings highlight (1) detecting\nAI-generated sentences in hybrid texts is overall a challenging task because\n(1.1) human writers' selecting and even editing AI-generated sentences based on\npersonal preferences adds difficulty in identifying the authorship of segments;\n(1.2) the frequent change of authorship between neighboring sentences within\nthe hybrid text creates difficulties for segment detectors in identifying\nauthorship-consistent segments; (1.3) the short length of text segments within\nhybrid texts provides limited stylistic cues for reliable authorship\ndetermination; (2) before embarking on the detection process, it is beneficial\nto assess the average length of segments within the hybrid text. This\nassessment aids in deciding whether (2.1) to employ a text segmentation-based\nstrategy for hybrid texts with longer segments, or (2.2) to adopt a direct\nsentence-by-sentence classification strategy for those with shorter segments.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Camera-Ready version of our IJCAI 2024 accepted paper (Special Track:\n  AI and Social Good)",
    "pdf_url": "http://arxiv.org/pdf/2403.03506v4",
    "published_date": "2024-03-06 07:25:46 UTC",
    "updated_date": "2024-05-23 13:18:33 UTC"
  },
  {
    "arxiv_id": "2403.03456v2",
    "title": "DLP-GAN: learning to draw modern Chinese landscape photos with generative adversarial network",
    "authors": [
      "Xiangquan Gui",
      "Binxuan Zhang",
      "Li Li",
      "Yi Yang"
    ],
    "abstract": "Chinese landscape painting has a unique and artistic style, and its drawing\ntechnique is highly abstract in both the use of color and the realistic\nrepresentation of objects. Previous methods focus on transferring from modern\nphotos to ancient ink paintings. However, little attention has been paid to\ntranslating landscape paintings into modern photos. To solve such problems, in\nthis paper, we (1) propose DLP-GAN (Draw Modern Chinese Landscape Photos with\nGenerative Adversarial Network), an unsupervised cross-domain image translation\nframework with a novel asymmetric cycle mapping, and (2) introduce a generator\nbased on a dense-fusion module to match different translation directions.\nMoreover, a dual-consistency loss is proposed to balance the realism and\nabstraction of model painting. In this way, our model can draw landscape photos\nand sketches in the modern sense. Finally, based on our collection of modern\nlandscape and sketch datasets, we compare the images generated by our model\nwith other benchmarks. Extensive experiments including user studies show that\nour model outperforms state-of-the-art methods.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Corrected typos",
    "pdf_url": "http://arxiv.org/pdf/2403.03456v2",
    "published_date": "2024-03-06 04:46:03 UTC",
    "updated_date": "2024-03-07 05:49:05 UTC"
  },
  {
    "arxiv_id": "2403.03444v1",
    "title": "Uncertainty quantification for deeponets with ensemble kalman inversion",
    "authors": [
      "Andrew Pensoneault",
      "Xueyu Zhu"
    ],
    "abstract": "In recent years, operator learning, particularly the DeepONet, has received\nmuch attention for efficiently learning complex mappings between input and\noutput functions across diverse fields. However, in practical scenarios with\nlimited and noisy data, accessing the uncertainty in DeepONet predictions\nbecomes essential, especially in mission-critical or safety-critical\napplications. Existing methods, either computationally intensive or yielding\nunsatisfactory uncertainty quantification, leave room for developing efficient\nand informative uncertainty quantification (UQ) techniques tailored for\nDeepONets. In this work, we proposed a novel inference approach for efficient\nUQ for operator learning by harnessing the power of the Ensemble Kalman\nInversion (EKI) approach. EKI, known for its derivative-free, noise-robust, and\nhighly parallelizable feature, has demonstrated its advantages for UQ for\nphysics-informed neural networks [28]. Our innovative application of EKI\nenables us to efficiently train ensembles of DeepONets while obtaining\ninformative uncertainty estimates for the output of interest. We deploy a\nmini-batch variant of EKI to accommodate larger datasets, mitigating the\ncomputational demand due to large datasets during the training stage.\nFurthermore, we introduce a heuristic method to estimate the artificial\ndynamics covariance, thereby improving our uncertainty estimates. Finally, we\ndemonstrate the effectiveness and versatility of our proposed methodology\nacross various benchmark problems, showcasing its potential to address the\npressing challenges of uncertainty quantification in DeepONets, especially for\npractical applications with limited and noisy data.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.NA",
      "math.NA",
      "stat.ML",
      "65"
    ],
    "primary_category": "cs.LG",
    "comment": "25 pages",
    "pdf_url": "http://arxiv.org/pdf/2403.03444v1",
    "published_date": "2024-03-06 04:02:30 UTC",
    "updated_date": "2024-03-06 04:02:30 UTC"
  },
  {
    "arxiv_id": "2403.03432v1",
    "title": "Mixture-of-LoRAs: An Efficient Multitask Tuning for Large Language Models",
    "authors": [
      "Wenfeng Feng",
      "Chuzhan Hao",
      "Yuewei Zhang",
      "Yu Han",
      "Hao Wang"
    ],
    "abstract": "Instruction Tuning has the potential to stimulate or enhance specific\ncapabilities of large language models (LLMs). However, achieving the right\nbalance of data is crucial to prevent catastrophic forgetting and interference\nbetween tasks. To address these limitations and enhance training flexibility,\nwe propose the Mixture-of-LoRAs (MoA) architecture which is a novel and\nparameter-efficient tuning method designed for multi-task learning with LLMs.\nIn this paper, we start by individually training multiple domain-specific LoRA\nmodules using corresponding supervised corpus data. These LoRA modules can be\naligned with the expert design principles observed in Mixture-of-Experts (MoE).\nSubsequently, we combine the multiple LoRAs using an explicit routing strategy\nand introduce domain labels to facilitate multi-task learning, which help\nprevent interference between tasks and ultimately enhances the performance of\neach individual task. Furthermore, each LoRA model can be iteratively adapted\nto a new domain, allowing for quick domain-specific adaptation. Experiments on\ndiverse tasks demonstrate superior and robust performance, which can further\npromote the wide application of domain-specific LLMs.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "10 pages, COLING24 Accepted",
    "pdf_url": "http://arxiv.org/pdf/2403.03432v1",
    "published_date": "2024-03-06 03:33:48 UTC",
    "updated_date": "2024-03-06 03:33:48 UTC"
  },
  {
    "arxiv_id": "2403.03421v1",
    "title": "LEAD: Learning Decomposition for Source-free Universal Domain Adaptation",
    "authors": [
      "Sanqing Qu",
      "Tianpei Zou",
      "Lianghua He",
      "Florian R√∂hrbein",
      "Alois Knoll",
      "Guang Chen",
      "Changjun Jiang"
    ],
    "abstract": "Universal Domain Adaptation (UniDA) targets knowledge transfer in the\npresence of both covariate and label shifts. Recently, Source-free Universal\nDomain Adaptation (SF-UniDA) has emerged to achieve UniDA without access to\nsource data, which tends to be more practical due to data protection policies.\nThe main challenge lies in determining whether covariate-shifted samples belong\nto target-private unknown categories. Existing methods tackle this either\nthrough hand-crafted thresholding or by developing time-consuming iterative\nclustering strategies. In this paper, we propose a new idea of LEArning\nDecomposition (LEAD), which decouples features into source-known and -unknown\ncomponents to identify target-private data. Technically, LEAD initially\nleverages the orthogonal decomposition analysis for feature decomposition.\nThen, LEAD builds instance-level decision boundaries to adaptively identify\ntarget-private data. Extensive experiments across various UniDA scenarios have\ndemonstrated the effectiveness and superiority of LEAD. Notably, in the OPDA\nscenario on VisDA dataset, LEAD outperforms GLC by 3.5% overall H-score and\nreduces 75% time to derive pseudo-labeling decision boundaries. Besides, LEAD\nis also appealing in that it is complementary to most existing methods. The\ncode is available at https://github.com/ispc-lab/LEAD.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "To appear in CVPR 2024",
    "pdf_url": "http://arxiv.org/pdf/2403.03421v1",
    "published_date": "2024-03-06 03:08:20 UTC",
    "updated_date": "2024-03-06 03:08:20 UTC"
  },
  {
    "arxiv_id": "2403.03419v2",
    "title": "Negating Negatives: Alignment with Human Negative Samples via Distributional Dispreference Optimization",
    "authors": [
      "Shitong Duan",
      "Xiaoyuan Yi",
      "Peng Zhang",
      "Yan Liu",
      "Zheng Liu",
      "Tun Lu",
      "Xing Xie",
      "Ning Gu"
    ],
    "abstract": "Large language models (LLMs) have revolutionized the role of AI, yet pose\npotential social risks. To steer LLMs towards human preference, alignment\ntechnologies have been introduced and gained increasing attention.\nNevertheless, existing methods heavily rely on high-quality positive-negative\ntraining pairs, suffering from noisy positive responses that are barely\ndistinguishable from negative ones. Given recent LLMs' proficiency in\ngenerating helpful responses, this work pivots towards a new research question:\ncan we achieve alignment using solely human-annotated negative samples,\npreserving helpfulness while reducing harmfulness? For this purpose, we propose\nDistributional Dispreference Optimization (D$^2$O), which maximizes the\ndiscrepancy between dispreferred responses and the generated non-negative ones.\nIn this way, D$^2$O effectively eschews harmful information without\nincorporating noisy positive samples, while avoiding collapse using\nself-generated responses as anchors. We demonstrate that D$^2$O can be regarded\nas learning a distributional preference model reflecting human dispreference\nagainst negative responses, which is theoretically an upper bound of the\ninstance-level DPO. Extensive experiments manifest that our method achieves\ncomparable generation quality and surpasses the latest strong baselines in\nproducing less harmful and more informative responses with better training\nstability and faster convergence.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted by EMNLP 2024(Findings)",
    "pdf_url": "http://arxiv.org/pdf/2403.03419v2",
    "published_date": "2024-03-06 03:02:38 UTC",
    "updated_date": "2024-09-30 04:49:38 UTC"
  },
  {
    "arxiv_id": "2403.03409v1",
    "title": "Sparse Spiking Neural Network: Exploiting Heterogeneity in Timescales for Pruning Recurrent SNN",
    "authors": [
      "Biswadeep Chakraborty",
      "Beomseok Kang",
      "Harshit Kumar",
      "Saibal Mukhopadhyay"
    ],
    "abstract": "Recurrent Spiking Neural Networks (RSNNs) have emerged as a computationally\nefficient and brain-inspired learning model. The design of sparse RSNNs with\nfewer neurons and synapses helps reduce the computational complexity of RSNNs.\nTraditionally, sparse SNNs are obtained by first training a dense and complex\nSNN for a target task, and, then, pruning neurons with low activity\n(activity-based pruning) while maintaining task performance. In contrast, this\npaper presents a task-agnostic methodology for designing sparse RSNNs by\npruning a large randomly initialized model. We introduce a novel Lyapunov Noise\nPruning (LNP) algorithm that uses graph sparsification methods and utilizes\nLyapunov exponents to design a stable sparse RSNN from a randomly initialized\nRSNN. We show that the LNP can leverage diversity in neuronal timescales to\ndesign a sparse Heterogeneous RSNN (HRSNN). Further, we show that the same\nsparse HRSNN model can be trained for different tasks, such as image\nclassification and temporal prediction. We experimentally show that, in spite\nof being task-agnostic, LNP increases computational efficiency (fewer neurons\nand synapses) and prediction performance of RSNNs compared to traditional\nactivity-based pruning of trained dense models.",
    "categories": [
      "cs.NE",
      "cs.AI"
    ],
    "primary_category": "cs.NE",
    "comment": "Published as a conference paper at ICLR 2024",
    "pdf_url": "http://arxiv.org/pdf/2403.03409v1",
    "published_date": "2024-03-06 02:36:15 UTC",
    "updated_date": "2024-03-06 02:36:15 UTC"
  },
  {
    "arxiv_id": "2403.03407v4",
    "title": "Human vs. Machine: Behavioral Differences Between Expert Humans and Language Models in Wargame Simulations",
    "authors": [
      "Max Lamparth",
      "Anthony Corso",
      "Jacob Ganz",
      "Oriana Skylar Mastro",
      "Jacquelyn Schneider",
      "Harold Trinkunas"
    ],
    "abstract": "To some, the advent of artificial intelligence (AI) promises better\ndecision-making and increased military effectiveness while reducing the\ninfluence of human error and emotions. However, there is still debate about how\nAI systems, especially large language models (LLMs) that can be applied to many\ntasks, behave compared to humans in high-stakes military decision-making\nscenarios with the potential for increased risks towards escalation. To test\nthis potential and scrutinize the use of LLMs for such purposes, we use a new\nwargame experiment with 214 national security experts designed to examine\ncrisis escalation in a fictional U.S.-China scenario and compare the behavior\nof human player teams to LLM-simulated team responses in separate simulations.\nHere, we find that the LLM-simulated responses can be more aggressive and\nsignificantly affected by changes in the scenario. We show a considerable\nhigh-level agreement in the LLM and human responses and significant\nquantitative and qualitative differences in individual actions and strategic\ntendencies. These differences depend on intrinsic biases in LLMs regarding the\nappropriate level of violence following strategic instructions, the choice of\nLLM, and whether the LLMs are tasked to decide for a team of players directly\nor first to simulate dialog between a team of players. When simulating the\ndialog, the discussions lack quality and maintain a farcical harmony. The LLM\nsimulations cannot account for human player characteristics, showing no\nsignificant difference even for extreme traits, such as \"pacifist\" or\n\"aggressive sociopath.\" When probing behavioral consistency across individual\nmoves of the simulation, the tested LLMs deviated from each other but generally\nshowed somewhat consistent behavior. Our results motivate policymakers to be\ncautious before granting autonomy or following AI-based strategy\nrecommendations.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CY",
    "comment": "Updated with new human participant results and added new LLM to\n  results; fixed error in Table 1; all claims unaffected",
    "pdf_url": "http://arxiv.org/pdf/2403.03407v4",
    "published_date": "2024-03-06 02:23:32 UTC",
    "updated_date": "2024-10-03 03:51:03 UTC"
  },
  {
    "arxiv_id": "2403.03406v1",
    "title": "An EnKF-LSTM Assimilation Algorithm for Crop Growth Model",
    "authors": [
      "Siqi Zhou",
      "Ling Wang",
      "Jie Liu",
      "Jinshan Tang"
    ],
    "abstract": "Accurate and timely prediction of crop growth is of great significance to\nensure crop yields and researchers have developed several crop models for the\nprediction of crop growth. However, there are large difference between the\nsimulation results obtained by the crop models and the actual results, thus in\nthis paper, we proposed to combine the simulation results with the collected\ncrop data for data assimilation so that the accuracy of prediction will be\nimproved. In this paper, an EnKF-LSTM data assimilation method for various\ncrops is proposed by combining ensemble Kalman filter and LSTM neural network,\nwhich effectively avoids the overfitting problem of existing data assimilation\nmethods and eliminates the uncertainty of the measured data. The verification\nof the proposed EnKF-LSTM method and the comparison of the proposed method with\nother data assimilation methods were performed using datasets collected by\nsensor equipment deployed on a farm.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.03406v1",
    "published_date": "2024-03-06 02:09:50 UTC",
    "updated_date": "2024-03-06 02:09:50 UTC"
  },
  {
    "arxiv_id": "2403.03401v1",
    "title": "BAIT: Benchmarking (Embedding) Architectures for Interactive Theorem-Proving",
    "authors": [
      "Sean Lamont",
      "Michael Norrish",
      "Amir Dezfouli",
      "Christian Walder",
      "Paul Montague"
    ],
    "abstract": "Artificial Intelligence for Theorem Proving has given rise to a plethora of\nbenchmarks and methodologies, particularly in Interactive Theorem Proving\n(ITP). Research in the area is fragmented, with a diverse set of approaches\nbeing spread across several ITP systems. This presents a significant challenge\nto the comparison of methods, which are often complex and difficult to\nreplicate. Addressing this, we present BAIT, a framework for fair and\nstreamlined comparison of learning approaches in ITP. We demonstrate BAIT's\ncapabilities with an in-depth comparison, across several ITP benchmarks, of\nstate-of-the-art architectures applied to the problem of formula embedding. We\nfind that Structure Aware Transformers perform particularly well, improving on\ntechniques associated with the original problem sets. BAIT also allows us to\nassess the end-to-end proving performance of systems built on interactive\nenvironments. This unified perspective reveals a novel end-to-end system that\nimproves on prior work. We also provide a qualitative analysis, illustrating\nthat improved performance is associated with more semantically-aware\nembeddings. By streamlining the implementation and comparison of Machine\nLearning algorithms in the ITP context, we anticipate BAIT will be a\nspringboard for future research.",
    "categories": [
      "cs.AI",
      "cs.LG",
      "cs.LO"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.03401v1",
    "published_date": "2024-03-06 01:56:17 UTC",
    "updated_date": "2024-03-06 01:56:17 UTC"
  },
  {
    "arxiv_id": "2403.03395v1",
    "title": "Interactive Melody Generation System for Enhancing the Creativity of Musicians",
    "authors": [
      "So Hirawata",
      "Noriko Otani"
    ],
    "abstract": "This study proposes a system designed to enumerate the process of\ncollaborative composition among humans, using automatic music composition\ntechnology. By integrating multiple Recurrent Neural Network (RNN) models, the\nsystem provides an experience akin to collaborating with several composers,\nthereby fostering diverse creativity. Through dynamic adaptation to the user's\ncreative intentions, based on feedback, the system enhances its capability to\ngenerate melodies that align with user preferences and creative needs. The\nsystem's effectiveness was evaluated through experiments with composers of\nvarying backgrounds, revealing its potential to facilitate musical creativity\nand suggesting avenues for further refinement. The study underscores the\nimportance of interaction between the composer and AI, aiming to make music\ncomposition more accessible and personalized. This system represents a step\ntowards integrating AI into the creative process, offering a new tool for\ncomposition support and collaborative artistic exploration.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.HC",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.03395v1",
    "published_date": "2024-03-06 01:33:48 UTC",
    "updated_date": "2024-03-06 01:33:48 UTC"
  },
  {
    "arxiv_id": "2403.03385v1",
    "title": "Multi-modal Deep Learning",
    "authors": [
      "Chen Yuhua"
    ],
    "abstract": "This article investigates deep learning methodologies for single-modality\nclinical data analysis, as a crucial precursor to multi-modal medical research.\nBuilding on Guo JingYuan's work, the study refines clinical data processing\nthrough Compact Convolutional Transformer (CCT), Patch Up, and the innovative\nCamCenterLoss technique, establishing a foundation for future multimodal\ninvestigations. The proposed methodology demonstrates improved prediction\naccuracy and at tentiveness to critically ill patients compared to Guo\nJingYuan's ResNet and StageNet approaches. Novelty that using image-pretrained\nvision transformer backbone to perform transfer learning time-series clinical\ndata.The study highlights the potential of CCT, Patch Up, and novel\nCamCenterLoss in processing single modality clinical data within deep learning\nframeworks, paving the way for future multimodal medical research and promoting\nprecision and personalized healthcare",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "Master's thesis",
    "pdf_url": "http://arxiv.org/pdf/2403.03385v1",
    "published_date": "2024-03-06 00:36:05 UTC",
    "updated_date": "2024-03-06 00:36:05 UTC"
  },
  {
    "arxiv_id": "2403.03382v1",
    "title": "Adaptive Discovering and Merging for Incremental Novel Class Discovery",
    "authors": [
      "Guangyao Chen",
      "Peixi Peng",
      "Yangru Huang",
      "Mengyue Geng",
      "Yonghong Tian"
    ],
    "abstract": "One important desideratum of lifelong learning aims to discover novel classes\nfrom unlabelled data in a continuous manner. The central challenge is twofold:\ndiscovering and learning novel classes while mitigating the issue of\ncatastrophic forgetting of established knowledge. To this end, we introduce a\nnew paradigm called Adaptive Discovering and Merging (ADM) to discover novel\ncategories adaptively in the incremental stage and integrate novel knowledge\ninto the model without affecting the original knowledge. To discover novel\nclasses adaptively, we decouple representation learning and novel class\ndiscovery, and use Triple Comparison (TC) and Probability Regularization (PR)\nto constrain the probability discrepancy and diversity for adaptive category\nassignment. To merge the learned novel knowledge adaptively, we propose a\nhybrid structure with base and novel branches named Adaptive Model Merging\n(AMM), which reduces the interference of the novel branch on the old classes to\npreserve the previous knowledge, and merges the novel branch to the base model\nwithout performance loss and parameter growth. Extensive experiments on several\ndatasets show that ADM significantly outperforms existing class-incremental\nNovel Class Discovery (class-iNCD) approaches. Moreover, our AMM also benefits\nthe class-incremental Learning (class-IL) task by alleviating the catastrophic\nforgetting problem.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "AAAI 2024. arXiv admin note: text overlap with arXiv:2207.08605 by\n  other authors",
    "pdf_url": "http://arxiv.org/pdf/2403.03382v1",
    "published_date": "2024-03-06 00:17:03 UTC",
    "updated_date": "2024-03-06 00:17:03 UTC"
  }
]