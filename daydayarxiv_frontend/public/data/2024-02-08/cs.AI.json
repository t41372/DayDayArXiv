{
  "date": "2024-02-08",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-02-08 的 arXiv 中文 TLDR 快报！今天 arXiv 的论文主要聚焦于 AI 模型优化、强化学习、多模态处理和大型语言模型（LLMs）应用等领域，强调了 LLMs 在推理、安全和多任务中的创新进展，如 R3 算法和 NegotiationArena 框架；有名的学者如 Thomas Sandholm 和 Jeffrey Sardina 参与的论文令人印象深刻；SubGen 和 DiffSpeaker 等文章展示了高效生成和动画技术的潜力。\n\n下面，我挑选并简要讨论了今天论文中的关键部分，先优先聊那些创新性强、话题度高或涉及知名学者的文章（如 LLMs 应用、强化学习和多模态学习），相关主题的论文放在一起讨论。对于其他较常规的文章，我会快速掠过，只提及核心点，以控制篇幅。\n\n### LLMs 和多模态学习领域的亮点\n- **R3: Learning Reasoning through Reverse Curriculum Reinforcement Learning (中文：通过逆向课程强化学习提升推理能力) | 英文：R3: Learning Reasoning through Reverse Curriculum Reinforcement Learning**  \n  这篇论文提出 R3 算法，使用逆向课程强化学习来优化 LLMs，在低监督环境下提升推理性能。主要贡献是通过逆向训练减少遗忘问题，在 GSM8K 和 MATH 数据集上，R3 让 Llama2-7B 模型性能提升 4.2%，比传统方法更高效，适合复杂任务。\n\n- **NegotiationArena: A Platform for Evaluating LLMs in Negotiation (中文：评估 LLMs 在谈判中的平台) | 英文：Veni, Vidi, Vici: Solving the Myriad of Challenges before Knowledge Graph Learning**  \n  Jeffrey Sardina 等学者参与，构建 NegotiationArena 框架，测试 LLMs 如 GPT-4 在谈判游戏中的表现。发现 LLMs 通过策略如假装绝望可提升 20% 回报，揭示了 LLMs 的理论思维局限，但也展示了其在多代理互动中的潜力。\n\n- **CREMA: Multimodal Fusion for Video-Language Reasoning (中文：多模态融合框架提升视频语言推理) | 英文：CREMA: Generalizable and Efficient Video-Language Reasoning via Multimodal Modular Fusion**  \n  这篇工作提出 CREMA 框架，使用多模态融合（如视频、音频）提升视频问答任务。核心发现是，通过模块化设计和并行处理，模型在 7 个基准上超越 BLIP-2 和 SeViLA，参数减少 90%，高效且鲁棒。\n\n- **OpenToM: Benchmark for Theory-of-Mind in LLMs (中文：LLMs 理论思维基准) | 英文：OpenToM: A Comprehensive Benchmark for Evaluating Theory-of-Mind Reasoning Capabilities of Large Language Models**  \n  论文引入 OpenToM 基准，评估 LLMs 如 GPT-4 在心理状态建模中的能力。发现 LLMs 在物理世界推理强，但心理世界弱，填补了 LLMs 解释性评估的空白。\n\n- **Matrix: Social Scene Simulation for LLM Alignment (中文：通过社会场景模拟提升 LLMs 对齐) | 英文：Self-Alignment of Large Language Models via Monopolylogue-based Social Scene Simulation**  \n  快速掠过：该框架模拟社会场景帮助 LLMs 学习人类价值观，实验显示在多个基准上提升 10% 性能，但核心是社会互动建模。\n\n### 强化学习和优化算法的创新\n- **GAR: Gradient Aligned Regression (中文：梯度对齐回归方法) | 英文：Gradient Aligned Regression via Pairwise Losses**  \n  作者如 Tianbao Yang 提出 GAR 算法，优化回归任务的梯度对齐。贡献在于高效处理成对损失，实验在八个真实数据集上超越基线，提升效率并提供理论证明。\n\n- **SubGen: Sublinear Time Token Generation (中文：亚线性时间标记生成) | 英文：SubGen: Token Generation in Sublinear Time and Memory**  \n  这篇论文开发 SubGen 方法，使用在线聚类和采样减少 LLMs 的 KV 缓存内存。核心发现是，在长序列任务中，SubGen 比现有方法快且准确，提升了生成效率。\n\n- **DiffTORI: Differentiable Trajectory Optimization for RL (中文：可微轨迹优化强化学习) | 英文：DiffTORI: Differentiable Trajectory Optimization for Deep Reinforcement and Imitation Learning**  \n  论文提出 DiffTORI 框架，将轨迹优化融入 RL 和模仿学习中。发现它在图像和点云输入的 15 个任务上超越基线，提升鲁棒性和泛化。\n\n- **Flashback: Mitigating Forgetting in Federated Learning (中文：缓解联邦学习中的遗忘) | 英文：Flashback: Understanding and Mitigating Forgetting in Federated Learning**  \n  快速掠过：该方法通过动态蒸馏减少联邦学习遗忘，在异构数据上加速收敛，贡献在于实用性改进。\n\n### 其他领域快速掠过\n- **DiffSpeaker: Speech-Driven 3D Animation (中文：语音驱动 3D 面部动画) | 英文：DiffSpeaker: Speech-Driven 3D Facial Animation with Diffusion Transformer**  \n  利用扩散模型生成实时 3D 动画，实验显示在基准上提升动画质量和速度。\n\n- **TASER: Adaptive Sampling for Graph Learning (中文：自适应采样图神经网络) | 英文：TASER: Temporal Adaptive Sampling for Fast and Accurate Dynamic Graph Representation Learning**  \n  快速掠过：提出自适应采样框架，提升动态图学习效率，在真实数据集上 5.1 倍加速。\n\n其他论文如常规分类或数据集构建（如 Gaussian Mixture Models 或常规 RL 优化），虽有贡献但不具话题度，我这里仅简要提及而不展开，以保持篇幅紧凑。\n\n总之，今天的 arXiv 论文突显了 LLMs 和 RL 在高效、鲁棒应用中的进展，SubGen 和 R3 等方法值得关注，未来可能推动 AI 更安全和泛化。更多细节可查阅具体论文！",
  "papers": [
    {
      "arxiv_id": "2402.06104v4",
      "title": "Gradient Aligned Regression via Pairwise Losses",
      "title_zh": "翻译失败",
      "authors": [
        "Dixian Zhu",
        "Tianbao Yang",
        "Livnat Jerby"
      ],
      "abstract": "Regression is a fundamental task in machine learning that has garnered\nextensive attention over the past decades. The conventional approach for\nregression involves employing loss functions that primarily concentrate on\naligning model prediction with the ground truth for each individual data\nsample. Recent research endeavors have introduced novel perspectives by\nincorporating label similarity to regression via imposing extra pairwise\nregularization on the latent feature space and demonstrated the effectiveness.\nHowever, there are two drawbacks for those approaches: i) their pairwise\noperation in latent feature space is computationally more expensive than\nconventional regression losses; ii) it lacks of theoretical justifications\nbehind such regularization. In this work, we propose GAR (Gradient Aligned\nRegression) as a competitive alternative method in label space, which is\nconstituted by a conventional regression loss and two pairwise label difference\nlosses for gradient alignment including magnitude and direction. GAR enjoys: i)\nthe same level efficiency as conventional regression loss because the quadratic\ncomplexity for the proposed pairwise losses can be reduced to linear\ncomplexity; ii) theoretical insights from learning the pairwise label\ndifference to learning the gradient of the ground truth function. We limit our\ncurrent scope as regression on the clean data setting without noises, outliers\nor distributional shifts, etc. We demonstrate the effectiveness of the proposed\nmethod practically on two synthetic datasets and on eight extensive real-world\ntasks from six benchmark datasets with other eight competitive baselines.\nRunning time experiments demonstrate the superior efficiency of the proposed\nGAR over existing methods with pairwise regularization in latent feature space\nand ablation studies demonstrate the effectiveness of each component for GAR.",
      "tldr_zh": "本研究针对回归任务的传统方法提出了一种新的Gradient Aligned Regression (GAR)框架，通过在标签空间中结合常规回归损失和两个配对标签差异损失，来对齐预测梯度的幅度和方向，从而改善标签相似性的利用。GAR解决了现有方法的计算开销问题，将配对损失的二次复杂度降为线性复杂度，并提供了理论依据，将学习配对标签差异等同于学习真实函数的梯度。在实验中，GAR在两个合成数据集和八个真实任务上优于八个基线模型，同时运行时间实验和消融研究证明了其高效性和组件有效性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "26 pages excluding references, 12 figures, 7 tables",
      "pdf_url": "http://arxiv.org/pdf/2402.06104v4",
      "published_date": "2024-02-08 23:43:53 UTC",
      "updated_date": "2025-01-31 22:32:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T04:27:10.543091"
    },
    {
      "arxiv_id": "2402.06098v1",
      "title": "Veni, Vidi, Vici: Solving the Myriad of Challenges before Knowledge Graph Learning",
      "title_zh": "Veni, Vidi, Vici：解决知识图谱学习前的众多挑战",
      "authors": [
        "Jeffrey Sardina",
        "Luca Costabello",
        "Christophe Guéret"
      ],
      "abstract": "Knowledge Graphs (KGs) have become increasingly common for representing\nlarge-scale linked data. However, their immense size has required graph\nlearning systems to assist humans in analysis, interpretation, and pattern\ndetection. While there have been promising results for researcher- and\nclinician- empowerment through a variety of KG learning systems, we identify\nfour key deficiencies in state-of-the-art graph learning that simultaneously\nlimit KG learning performance and diminish the ability of humans to interface\noptimally with these learning systems. These deficiencies are: 1) lack of\nexpert knowledge integration, 2) instability to node degree extremity in the\nKG, 3) lack of consideration for uncertainty and relevance while learning, and\n4) lack of explainability. Furthermore, we characterise state-of-the-art\nattempts to solve each of these problems and note that each attempt has largely\nbeen isolated from attempts to solve the other problems. Through a\nformalisation of these problems and a review of the literature that addresses\nthem, we adopt the position that not only are deficiencies in these four key\nareas holding back human-KG empowerment, but that the divide-and-conquer\napproach to solving these problems as individual units rather than a whole is a\nsignificant barrier to the interface between humans and KG learning systems. We\npropose that it is only through integrated, holistic solutions to the\nlimitations of KG learning systems that human and KG learning co-empowerment\nwill be efficiently affected. We finally present our \"Veni, Vidi, Vici\"\nframework that sets a roadmap for effectively and efficiently shifting to a\nholistic co-empowerment model in both the KG learning and the broader machine\nlearning domain.",
      "tldr_zh": "该论文分析了 Knowledge Graphs (KGs) 学习面临的四大关键挑战：缺乏专家知识整合、对节点度极端性的不稳定性、忽略学习中的不确定性和相关性，以及缺乏可解释性。这些问题不仅降低了 KG 学习性能，还阻碍了人类与系统的最佳交互。论文批评了当前孤立的解决方案，并主张采用整体整合方法来实现人类和 KG 学习的共同赋能；为此，提出了 \"Veni, Vidi, Vici\" 框架，作为一个路线图，推动 KG 学习和更广泛机器学习领域的整体解决方案。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "This article was accepted for publication at IEEE ICSC 2024, and is\n  being made available as an author preprint. As soon as it is published by\n  IEEE, this registry will be updated in accordance with the IEEE copyright\n  agreement",
      "pdf_url": "http://arxiv.org/pdf/2402.06098v1",
      "published_date": "2024-02-08 23:15:23 UTC",
      "updated_date": "2024-02-08 23:15:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T04:27:22.061836"
    },
    {
      "arxiv_id": "2402.06097v1",
      "title": "TWIG: Towards pre-hoc Hyperparameter Optimisation and Cross-Graph Generalisation via Simulated KGE Models",
      "title_zh": "翻译失败",
      "authors": [
        "Jeffrey Sardina",
        "John D. Kelleher",
        "Declan O'Sullivan"
      ],
      "abstract": "In this paper we introduce TWIG (Topologically-Weighted Intelligence\nGeneration), a novel, embedding-free paradigm for simulating the output of KGEs\nthat uses a tiny fraction of the parameters. TWIG learns weights from inputs\nthat consist of topological features of the graph data, with no coding for\nlatent representations of entities or edges. Our experiments on the UMLS\ndataset show that a single TWIG neural network can predict the results of\nstate-of-the-art ComplEx-N3 KGE model nearly exactly on across all\nhyperparameter configurations. To do this it uses a total of 2590 learnable\nparameters, but accurately predicts the results of 1215 different\nhyperparameter combinations with a combined cost of 29,322,000 parameters.\nBased on these results, we make two claims: 1) that KGEs do not learn latent\nsemantics, but only latent representations of structural patterns; 2) that\nhyperparameter choice in KGEs is a deterministic function of the KGE model and\ngraph structure. We further hypothesise that, as TWIG can simulate KGEs without\nembeddings, that node and edge embeddings are not needed to learn to accurately\npredict new facts in KGs. Finally, we formulate all of our findings under the\numbrella of the ``Structural Generalisation Hypothesis\", which suggests that\n``twiggy\" embedding-free / data-structure-based learning methods can allow a\nsingle neural network to simulate KGE performance, and perhaps solve the Link\nPrediction task, across many KGs from diverse domains and with different\nsemantics.",
      "tldr_zh": "本论文引入了 TWIG，一种新型的嵌入-free 范式，用于模拟 KGEs（Knowledge Graph Embeddings）的输出，仅使用极少的参数（如 2590 个可学习参数），通过学习图数据的拓扑特征来预测不同超参数配置的结果。实验在 UMLS 数据集上显示，TWIG 神经网络几乎精确地模拟了状态-of-the-art ComplEx-N3 KGE 模型在 1215 种超参数组合下的输出，节省了大量计算资源（如总计 29,322,000 参数）。论文据此提出两个关键声明：1) KGEs 并未学习潜在语义，而是仅捕捉结构模式的潜在表示；2) KGEs 的超参数选择是模型和图结构的一个确定性函数。最终，论文提出了“Structural Generalisation Hypothesis”，假设嵌入-free 方法如 TWIG 可以跨多个领域模拟 KGE 性能，并可能在链接预测任务上实现泛化。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "68R10"
      ],
      "primary_category": "cs.AI",
      "comment": "This article was accepted for publication at IEEE ICSC 2024",
      "pdf_url": "http://arxiv.org/pdf/2402.06097v1",
      "published_date": "2024-02-08 23:12:02 UTC",
      "updated_date": "2024-02-08 23:12:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T04:27:35.648717"
    },
    {
      "arxiv_id": "2402.06086v2",
      "title": "Rhizomes and Diffusions for Processing Highly Skewed Graphs on Fine-Grain Message-Driven Systems",
      "title_zh": "翻译失败",
      "authors": [
        "Bibrak Qamar Chandio",
        "Prateek Srivastava",
        "Maciej Brodowicz",
        "Martin Swany",
        "Thomas Sterling"
      ],
      "abstract": "The paper provides a unified co-design of 1) a programming and execution\nmodel that allows spawning tasks from within the vertex data at runtime, 2)\nlanguage constructs for \\textit{actions} that send work to where the data\nresides, combining parallel expressiveness of local control objects (LCOs) to\nimplement asynchronous graph processing primitives, 3) and an innovative\nvertex-centric data-structure, using the concept of Rhizomes, that parallelizes\nboth the out and in-degree load of vertex objects across many cores and yet\nprovides a single programming abstraction to the vertex objects. The data\nstructure hierarchically parallelizes the out-degree load of vertices and the\nin-degree load laterally. The rhizomes internally communicate and remain\nconsistent, using event-driven synchronization mechanisms, to provide a unified\nand correct view of the vertex.\n  Simulated experimental results show performance gains for BFS, SSSP, and Page\nRank on large chip sizes for the tested input graph datasets containing highly\nskewed degree distribution. The improvements come from the ability to express\nand create fine-grain dynamic computing task in the form of \\textit{actions},\nlanguage constructs that aid the compiler to generate code that the runtime\nsystem uses to optimally schedule tasks, and the data structure that shares\nboth in and out-degree compute workload among memory-processing elements.",
      "tldr_zh": "该论文提出了一种统一的协同设计框架，用于处理高度倾斜分布图的细粒度消息驱动系统，包括动态任务生成模型、actions语言结构以及基于Rhizomes的顶点中心数据结构，以实现顶点的出度和入度负载并行化。actions结合本地控制对象(LCOs)允许异步发送工作到数据所在位置，并通过事件驱动同步机制确保Rhizomes内部一致性，提供单一的编程抽象。模拟实验结果显示，该框架在BFS、SSSP和PageRank算法上，对大规模倾斜图数据集实现了显著性能提升，主要得益于细粒度任务表达、优化代码生成和计算负载共享。",
      "categories": [
        "cs.DC",
        "cs.AI",
        "cs.DS",
        "C.1.4; C.3; C.4; D.1.3"
      ],
      "primary_category": "cs.DC",
      "comment": "arXiv admin note: text overlap with arXiv:2402.02576",
      "pdf_url": "http://arxiv.org/pdf/2402.06086v2",
      "published_date": "2024-02-08 22:38:14 UTC",
      "updated_date": "2024-05-08 02:48:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T04:27:46.200857"
    },
    {
      "arxiv_id": "2402.06082v1",
      "title": "SubGen: Token Generation in Sublinear Time and Memory",
      "title_zh": "SubGen：次线性时间和内存中的令牌生成",
      "authors": [
        "Amir Zandieh",
        "Insu Han",
        "Vahab Mirrokni",
        "Amin Karbasi"
      ],
      "abstract": "Despite the significant success of large language models (LLMs), their\nextensive memory requirements pose challenges for deploying them in\nlong-context token generation. The substantial memory footprint of LLM decoders\narises from the necessity to store all previous tokens in the attention module,\na requirement imposed by key-value (KV) caching. In this work, our focus is on\ndeveloping an efficient compression technique for the KV cache. Empirical\nevidence indicates a significant clustering tendency within key embeddings in\nthe attention module. Building on this key insight, we have devised a novel\ncaching method with sublinear complexity, employing online clustering on key\ntokens and online $\\ell_2$ sampling on values. The result is a provably\naccurate and efficient attention decoding algorithm, termed SubGen. Not only\ndoes this algorithm ensure a sublinear memory footprint and sublinear time\ncomplexity, but we also establish a tight error bound for our approach.\nEmpirical evaluations on long-context question-answering tasks demonstrate that\nSubGen significantly outperforms existing and state-of-the-art KV cache\ncompression methods in terms of performance and efficiency.",
      "tldr_zh": "该研究针对大型语言模型(LLMs)在长上下文生成中的高内存需求问题，提出SubGen算法，通过对KV cache进行高效压缩来解决这一挑战。SubGen利用key嵌入的聚类倾向，结合在线聚类(online clustering)和在线ℓ2采样(online ℓ2 sampling)，实现了子线性时间和内存复杂度，并提供了紧密误差界(tight error bound)。实验结果显示，在长上下文问答任务上，SubGen在性能和效率方面显著优于现有KV缓存压缩方法。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DS"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.06082v1",
      "published_date": "2024-02-08 22:17:40 UTC",
      "updated_date": "2024-02-08 22:17:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T04:27:58.278721"
    },
    {
      "arxiv_id": "2402.06695v1",
      "title": "Integrating LLMs for Explainable Fault Diagnosis in Complex Systems",
      "title_zh": "翻译失败",
      "authors": [
        "Akshay J. Dave",
        "Tat Nghia Nguyen",
        "Richard B. Vilim"
      ],
      "abstract": "This paper introduces an integrated system designed to enhance the\nexplainability of fault diagnostics in complex systems, such as nuclear power\nplants, where operator understanding is critical for informed decision-making.\nBy combining a physics-based diagnostic tool with a Large Language Model, we\noffer a novel solution that not only identifies faults but also provides clear,\nunderstandable explanations of their causes and implications. The system's\nefficacy is demonstrated through application to a molten salt facility,\nshowcasing its ability to elucidate the connections between diagnosed faults\nand sensor data, answer operator queries, and evaluate historical sensor\nanomalies. Our approach underscores the importance of merging model-based\ndiagnostics with advanced AI to improve the reliability and transparency of\nautonomous systems.",
      "tldr_zh": "这篇论文提出了一种集成系统，将大型语言模型（LLMs）与基于物理的诊断工具相结合，以提升复杂系统（如核电站）故障诊断的可解释性。该系统不仅能识别故障，还提供清晰的解释，包括故障原因、影响及其与传感器数据的关联。实验通过应用于熔盐设施，展示了系统回答操作员查询、评估历史传感器异常的能力。这种方法强调了融合模型-based诊断与先进AI的重要性，从而提高自主系统的可靠性和透明度。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.AI",
      "comment": "4 pages",
      "pdf_url": "http://arxiv.org/pdf/2402.06695v1",
      "published_date": "2024-02-08 22:11:21 UTC",
      "updated_date": "2024-02-08 22:11:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T04:28:09.592522"
    },
    {
      "arxiv_id": "2402.06079v2",
      "title": "DiscDiff: Latent Diffusion Model for DNA Sequence Generation",
      "title_zh": "DiscDiff：用于 DNA 序列生成的潜在扩散模型",
      "authors": [
        "Zehui Li",
        "Yuhao Ni",
        "William A V Beardall",
        "Guoxuan Xia",
        "Akashaditya Das",
        "Guy-Bart Stan",
        "Yiren Zhao"
      ],
      "abstract": "This paper introduces a novel framework for DNA sequence generation,\ncomprising two key components: DiscDiff, a Latent Diffusion Model (LDM)\ntailored for generating discrete DNA sequences, and Absorb-Escape, a\npost-training algorithm designed to refine these sequences. Absorb-Escape\nenhances the realism of the generated sequences by correcting `round errors'\ninherent in the conversion process between latent and input spaces. Our\napproach not only sets new standards in DNA sequence generation but also\ndemonstrates superior performance over existing diffusion models, in generating\nboth short and long DNA sequences. Additionally, we introduce EPD-GenDNA, the\nfirst comprehensive, multi-species dataset for DNA generation, encompassing\n160,000 unique sequences from 15 species. We hope this study will advance the\ngenerative modelling of DNA, with potential implications for gene therapy and\nprotein production.",
      "tldr_zh": "该论文提出了一种名为 DiscDiff 的新框架，用于 DNA 序列生成，该框架包括一个专为生成离散 DNA 序列设计的 Latent Diffusion Model (LDM)，以及一个后训练算法 Absorb-Escape，用于修正潜在空间与输入空间转换中的“round errors”，从而提升生成序列的真实性。实验结果显示，DiscDiff 在生成短和长 DNA 序列方面优于现有扩散模型，设定新的基准。论文还引入了 EPD-GenDNA，这是第一个包含 160,000 个独特序列来自 15 个物种的全面多物种数据集，有望推动 DNA 生成建模在基因疗法和蛋白质生产中的应用。",
      "categories": [
        "q-bio.GN",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "q-bio.GN",
      "comment": "Different from the prior work \"Latent Diffusion Model for DNA\n  Sequence Generation\" (arXiv:2310.06150), we updated the evaluation framework\n  and compared the DiscDiff with other methods comprehensively. In addition, a\n  post-training framework is proposed to increase the quality of generated\n  sequences",
      "pdf_url": "http://arxiv.org/pdf/2402.06079v2",
      "published_date": "2024-02-08 22:06:55 UTC",
      "updated_date": "2024-04-17 16:31:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T04:28:22.124380"
    },
    {
      "arxiv_id": "2402.06078v1",
      "title": "Gaussian Mixture Models for Affordance Learning using Bayesian Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Pedro Osório",
        "Alexandre Bernardino",
        "Ruben Martinez-Cantin",
        "José Santos-Victor"
      ],
      "abstract": "Affordances are fundamental descriptors of relationships between actions,\nobjects and effects. They provide the means whereby a robot can predict\neffects, recognize actions, select objects and plan its behavior according to\ndesired goals. This paper approaches the problem of an embodied agent exploring\nthe world and learning these affordances autonomously from its sensory\nexperiences. Models exist for learning the structure and the parameters of a\nBayesian Network encoding this knowledge. Although Bayesian Networks are\ncapable of dealing with uncertainty and redundancy, previous work considered\ncomplete observability of the discrete sensory data, which may lead to hard\nerrors in the presence of noise. In this paper we consider a probabilistic\nrepresentation of the sensors by Gaussian Mixture Models (GMMs) and explicitly\ntaking into account the probability distribution contained in each discrete\naffordance concept, which can lead to a more correct learning.",
      "tldr_zh": "本研究探讨了机器人通过感官经验自主学习 affordances（动作、物体和效果之间的关系），以帮助预测效果、识别动作和规划行为。论文提出使用 Bayesian Networks 来建模这些知识，但改进方法通过 Gaussian Mixture Models (GMMs) 来表示传感器的概率分布，并考虑每个离散 affordance 概念的概率分布，以处理噪声和不确定性。相比之前假设完全可观察数据的模型，这种方法可实现更准确和鲁棒的学习。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "IEEE/RSJ International Conference on Intelligent Robots and Systems\n  2010",
      "pdf_url": "http://arxiv.org/pdf/2402.06078v1",
      "published_date": "2024-02-08 22:05:45 UTC",
      "updated_date": "2024-02-08 22:05:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T04:28:33.131431"
    },
    {
      "arxiv_id": "2402.06694v1",
      "title": "Scaling Intelligent Agents in Combat Simulations for Wargaming",
      "title_zh": "翻译失败",
      "authors": [
        "Scotty Black",
        "Christian Darken"
      ],
      "abstract": "Remaining competitive in future conflicts with technologically-advanced\ncompetitors requires us to accelerate our research and development in\nartificial intelligence (AI) for wargaming. More importantly, leveraging\nmachine learning for intelligent combat behavior development will be key to one\nday achieving superhuman performance in this domain--elevating the quality and\naccelerating the speed of our decisions in future wars. Although deep\nreinforcement learning (RL) continues to show promising results in intelligent\nagent behavior development in games, it has yet to perform at or above the\nhuman level in the long-horizon, complex tasks typically found in combat\nmodeling and simulation. Capitalizing on the proven potential of RL and recent\nsuccesses of hierarchical reinforcement learning (HRL), our research is\ninvestigating and extending the use of HRL to create intelligent agents capable\nof performing effectively in these large and complex simulation environments.\nOur ultimate goal is to develop an agent capable of superhuman performance that\ncould then serve as an AI advisor to military planners and decision-makers.\nThis papers covers our ongoing approach and the first three of our five\nresearch areas aimed at managing the exponential growth of computations that\nhave thus far limited the use of AI in combat simulations: (1) developing an\nHRL training framework and agent architecture for combat units; (2) developing\na multi-model framework for agent decision-making; (3) developing\ndimension-invariant observation abstractions of the state space to manage the\nexponential growth of computations; (4) developing an intrinsic rewards engine\nto enable long-term planning; and (5) implementing this framework into a\nhigher-fidelity combat simulation.",
      "tldr_zh": "该研究旨在通过人工智能提升战争游戏中的智能代理性能，以应对未来冲突的挑战。论文聚焦于扩展层次化强化学习（HRL）来开发可在复杂、长期任务中表现超人水平的代理，从而加速军事决策。关键方法包括：（1）构建HRL训练框架和代理架构；（2）开发多模型框架支持代理决策；（3）创建维度不变的观察抽象以管理计算增长。最终，该框架有望应用于高保真模拟环境，创建AI顾问助力军事规划。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "arXiv admin note: text overlap with arXiv:2402.06075",
      "pdf_url": "http://arxiv.org/pdf/2402.06694v1",
      "published_date": "2024-02-08 21:57:10 UTC",
      "updated_date": "2024-02-08 21:57:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T04:28:44.700008"
    },
    {
      "arxiv_id": "2402.06075v1",
      "title": "Scaling Artificial Intelligence for Digital Wargaming in Support of Decision-Making",
      "title_zh": "为支持决策的人工智能规模化扩展应用于数字战争游戏",
      "authors": [
        "Scotty Black",
        "Christian Darken"
      ],
      "abstract": "In this unprecedented era of technology-driven transformation, it becomes\nmore critical than ever that we aggressively invest in developing robust\nartificial intelligence (AI) for wargaming in support of decision-making. By\nadvancing AI-enabled systems and pairing these with human judgment, we will be\nable to enhance all-domain awareness, improve the speed and quality of our\ndecision cycles, offer recommendations for novel courses of action, and more\nrapidly counter our adversary's actions. It therefore becomes imperative that\nwe accelerate the development of AI to help us better address the complexity of\nmodern challenges and dilemmas that currently requires human intelligence and,\nif possible, attempt to surpass human intelligence--not to replace humans, but\nto augment and better inform human decision-making at machine speed. Although\ndeep reinforcement learning continues to show promising results in intelligent\nagent behavior development for the long-horizon, complex tasks typically found\nin combat modeling and simulation, further research is needed to enable the\nscaling of AI to deal with these intricate and expansive state-spaces\ncharacteristic of wargaming for either concept development, education, or\nanalysis. To help address this challenge, in our research, we are developing\nand implementing a hierarchical reinforcement learning framework that includes\na multi-model approach and dimension-invariant observation abstractions.",
      "tldr_zh": "该论文强调在技术驱动时代，需加速发展人工智能（AI）用于数字战争游戏，以支持决策过程。AI 与人类判断结合，能提升全域意识、决策速度和质量，并为新行动方案提供推荐。研究团队提出一个分层强化学习（hierarchical reinforcement learning）框架，结合多模型方法和维度不变的观察抽象（dimension-invariant observation abstractions），以处理战争游戏中复杂状态空间的挑战。实验表明，这种方法有望超越人类在某些任务中的表现，从而更好地辅助决策。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.06075v1",
      "published_date": "2024-02-08 21:51:07 UTC",
      "updated_date": "2024-02-08 21:51:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T04:28:56.395649"
    },
    {
      "arxiv_id": "2403.05552v1",
      "title": "Multi-source and multimodal data fusion for predicting academic performance in blended learning university courses",
      "title_zh": "多源和多模态数据融合用于预测混合学习大学课程中的学术表现",
      "authors": [
        "W. Chango",
        "R. Cerezo",
        "C. Romero"
      ],
      "abstract": "In this paper we applied data fusion approaches for predicting the final\nacademic performance of university students using multiple-source, multimodal\ndata from blended learning environments. We collected and preprocessed data\nabout first-year university students from different sources: theory classes,\npractical sessions, on-line Moodle sessions, and a final exam. Our objective\nwas to discover which data fusion approach produced the best results using our\ndata. We carried out experiments by applying four different data fusion\napproaches and six classification algorithms. The results showed that the best\npredictions were produced using ensembles and selecting the best attributes\napproach with discretized data. The best prediction models showed us that the\nlevel of attention in theory classes, scores in Moodle quizzes, and the level\nof activity in Moodle forums were the best set of attributes for predicting\nstudents' final performance in our courses.",
      "tldr_zh": "本研究应用多源多模态数据融合方法，预测混合学习大学课程学生最终学术表现，数据来源包括理论课、实践课、在线 Moodle 会话和期末考试。研究者收集并预处理第一年大学生的相关数据，并实验了四种数据融合方法和六种分类算法。结果表明，使用集成方法（ensembles）和选择最佳属性（selecting the best attributes）结合离散化数据能产生最佳预测模型，而理论课注意力、Moodle 测验分数以及Moodle 论坛活动水平是预测学生表现的最有效属性集。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.05552v1",
      "published_date": "2024-02-08 21:29:41 UTC",
      "updated_date": "2024-02-08 21:29:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T04:29:10.500773"
    },
    {
      "arxiv_id": "2402.06053v1",
      "title": "Randomness Is All You Need: Semantic Traversal of Problem-Solution Spaces with Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Thomas Sandholm",
        "Sayandev Mukherjee",
        "Bernardo A. Huberman"
      ],
      "abstract": "We present a novel approach to exploring innovation problem and solution\ndomains using LLM fine-tuning with a custom idea database. By semantically\ntraversing the bi-directional problem and solution tree at different\ntemperature levels we achieve high diversity in solution edit distance while\nstill remaining close to the original problem statement semantically. In\naddition to finding a variety of solutions to a given problem, this method can\nalso be used to refine and clarify the original problem statement. As further\nvalidation of the approach, we implemented a proof-of-concept Slack bot to\nserve as an innovation assistant.",
      "tldr_zh": "本研究提出了一种创新方法，利用大型语言模型（LLM）微调（fine-tuning）结合自定义想法数据库，探索问题-解决方案空间。方法通过在不同温度水平（temperature levels）上进行语义遍历（semantic traversal）双向问题-解决方案树，实现高多样性的解决方案编辑距离（solution edit distance），同时保持与原问题语句的语义相关性。该方法不仅能为给定问题生成多种解决方案，还能精炼和澄清原问题语句。作为验证，研究团队开发了概念证明的Slack bot，作为创新助手，以证明方法的实用性。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.06053v1",
      "published_date": "2024-02-08 20:49:09 UTC",
      "updated_date": "2024-02-08 20:49:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T04:29:21.112447"
    },
    {
      "arxiv_id": "2402.06046v3",
      "title": "Anatomy of a Robotaxi Crash: Lessons from the Cruise Pedestrian Dragging Mishap",
      "title_zh": "翻译失败",
      "authors": [
        "Philip Koopman"
      ],
      "abstract": "An October 2023 crash between a GM Cruise robotaxi and a pedestrian in San\nFrancisco resulted not only in a severe injury, but also dramatic upheaval at\nthat company that will likely have lasting effects throughout the industry.\nIs-sues stem not just from the loss events themselves, but also from how Cruise\nmishandled dealing with their robotaxi dragging a pedestrian under the vehicle\nafter the initial post-crash stop. External investigation reports provide raw\nmaterial describing the incident and critique the company's response from a\nregulatory point of view, but exclude safety engineering recommendations from\nscope. We highlight specific facts and relationships among events by tying\ntogether different pieces of the external report material. We then explore\nsafety lessons that might be learned related to: recognizing and responding to\nnearby mishaps, building an accurate world model of a post-collision scenario,\nthe in-adequacy of a so-called \"minimal risk condition\" strategy in complex\nsituations, poor organizational discipline in responding to a mishap, overly\naggressive post-collision automation choices that made a bad situation worse,\nand a reluctance to admit to a mishap causing much worse organizational harm\ndown-stream.",
      "tldr_zh": "这篇论文剖析了2023年10月在旧金山发生的Cruise robotaxi与行人碰撞事故，该事件导致严重受伤并引发公司内部剧变和行业影响。作者通过整合外部调查报告，突出关键事实和事件关系，聚焦于事故响应中的问题，如识别和处理附近事故的不足。论文总结了重要安全教训，包括构建准确的post-collision世界模型、\"minimal risk condition\"策略在复杂情况下的失效、组织纪律缺失、过激的自动化选择加剧危害，以及不愿承认事故所带来的后续组织损害。这些发现为提升robotaxi的安全性和应急机制提供了宝贵指导。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "15 pages, 2 figures",
      "pdf_url": "http://arxiv.org/pdf/2402.06046v3",
      "published_date": "2024-02-08 20:37:51 UTC",
      "updated_date": "2024-08-05 10:48:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T04:29:34.212052"
    },
    {
      "arxiv_id": "2402.16877v1",
      "title": "Large Language Model Augmented Exercise Retrieval for Personalized Language Learning",
      "title_zh": "大语言模型增强的",
      "authors": [
        "Austin Xu",
        "Will Monroe",
        "Klinton Bicknell"
      ],
      "abstract": "We study the problem of zero-shot exercise retrieval in the context of online\nlanguage learning, to give learners the ability to explicitly request\npersonalized exercises via natural language. Using real-world data collected\nfrom language learners, we observe that vector similarity approaches poorly\ncapture the relationship between exercise content and the language that\nlearners use to express what they want to learn. This semantic gap between\nqueries and content dramatically reduces the effectiveness of general-purpose\nretrieval models pretrained on large scale information retrieval datasets like\nMS MARCO. We leverage the generative capabilities of large language models to\nbridge the gap by synthesizing hypothetical exercises based on the learner's\ninput, which are then used to search for relevant exercises. Our approach,\nwhich we call mHyER, overcomes three challenges: (1) lack of relevance labels\nfor training, (2) unrestricted learner input content, and (3) low semantic\nsimilarity between input and retrieval candidates. mHyER outperforms several\nstrong baselines on two novel benchmarks created from crowdsourced data and\npublicly available data.",
      "tldr_zh": "这篇论文研究了零-shot 练习检索问题，旨在通过自然语言让学习者请求个性化的语言学习练习。作者提出 mHyER 方法，利用 Large Language Models 的生成能力来合成基于学习者输入的假设练习，从而桥接查询内容与实际练习之间的语义差距，并解决训练标签缺乏、输入多样性和低语义相似度等挑战。在两个新基准测试中，mHyER 超过了多项强基线模型，展示了其在真实世界数据上的有效性。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.IR",
      "comment": "Presented at Learning Analytics and Knowledge 2024. 11 pages, 4\n  figures, 5 tables",
      "pdf_url": "http://arxiv.org/pdf/2402.16877v1",
      "published_date": "2024-02-08 20:35:31 UTC",
      "updated_date": "2024-02-08 20:35:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T04:29:45.694270"
    },
    {
      "arxiv_id": "2402.06044v3",
      "title": "OpenToM: A Comprehensive Benchmark for Evaluating Theory-of-Mind Reasoning Capabilities of Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Hainiu Xu",
        "Runcong Zhao",
        "Lixing Zhu",
        "Jinhua Du",
        "Yulan He"
      ],
      "abstract": "Neural Theory-of-Mind (N-ToM), machine's ability to understand and keep track\nof the mental states of others, is pivotal in developing socially intelligent\nagents. However, prevalent N-ToM benchmarks have several shortcomings,\nincluding the presence of ambiguous and artificial narratives, absence of\npersonality traits and preferences, a lack of questions addressing characters'\npsychological mental states, and limited diversity in the questions posed. In\nresponse to these issues, we construct OpenToM, a new benchmark for assessing\nN-ToM with (1) longer and clearer narrative stories, (2) characters with\nexplicit personality traits, (3) actions that are triggered by character\nintentions, and (4) questions designed to challenge LLMs' capabilities of\nmodeling characters' mental states of both the physical and psychological\nworld. Using OpenToM, we reveal that state-of-the-art LLMs thrive at modeling\ncertain aspects of mental states in the physical world but fall short when\ntracking characters' mental states in the psychological world.",
      "tldr_zh": "该论文引入了 OpenToM，这是一个全面的基准，用于评估大型语言模型(LLMs)的 Theory-of-Mind (ToM) 推理能力，以解决现有 N-ToM 基准中存在的模糊叙述、缺乏个性特征和心理状态问题。OpenToM 通过采用更长的清晰故事、赋予角色明确个性特征、基于意图的行动以及针对物理和心理世界心理状态的挑战性问题来进行改进。实验结果显示，状态-of-the-art LLMs 在建模物理世界心理状态方面表现出色，但对心理世界心理状态的跟踪仍存在显著不足。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "ACL 2024",
      "pdf_url": "http://arxiv.org/pdf/2402.06044v3",
      "published_date": "2024-02-08 20:35:06 UTC",
      "updated_date": "2024-06-03 10:48:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T04:29:57.649299"
    },
    {
      "arxiv_id": "2402.06038v2",
      "title": "Understanding Contrastive Representation Learning from Positive Unlabeled (PU) Data",
      "title_zh": "翻译失败",
      "authors": [
        "Anish Acharya",
        "Li Jing",
        "Bhargav Bhushanam",
        "Dhruv Choudhary",
        "Michael Rabbat",
        "Sujay Sanghavi",
        "Inderjit S Dhillon"
      ],
      "abstract": "Pretext Invariant Representation Learning (PIRL) followed by Supervised\nFine-Tuning (SFT) has become a standard paradigm for learning with limited\nlabels. We extend this approach to the Positive Unlabeled (PU) setting, where\nonly a small set of labeled positives and a large unlabeled pool -- containing\nboth positives and negatives are available. We study this problem under two\nregimes: (i) without access to the class prior, and (ii) when the prior is\nknown or can be estimated. We introduce Positive Unlabeled Contrastive Learning\n(puCL), an unbiased and variance reducing contrastive objective that integrates\nweak supervision from labeled positives judiciously into the contrastive loss.\nWhen the class prior is known, we propose Positive Unlabeled InfoNCE (puNCE), a\nprior-aware extension that re-weights unlabeled samples as soft positive\nnegative mixtures. For downstream classification, we develop a pseudo-labeling\nalgorithm that leverages the structure of the learned embedding space via PU\naware clustering. Our framework is supported by theory; offering bias-variance\nanalysis, convergence insights, and generalization guarantees via augmentation\nconcentration; and validated empirically across standard PU benchmarks, where\nit consistently outperforms existing methods, particularly in low-supervision\nregimes.",
      "tldr_zh": "该研究扩展了对比表示学习（Contrastive Representation Learning）应用于 Positive Unlabeled (PU) 数据场景，其中仅提供少量标记正样本和大量未标记数据。研究者提出 Positive Unlabeled Contrastive Learning (puCL) 作为一种无偏、低方差的目标函数，将弱监督整合到对比损失中；并在类先验已知时引入 Positive Unlabeled InfoNCE (puNCE)，通过重新加权未标记样本作为软正负混合来提升性能。为下游分类任务，他们开发了基于 PU 感知聚类的伪标签算法。该框架得到理论支持，包括偏差-方差分析和泛化保证，并在标准 PU 基准测试中表现出色，尤其在低监督环境中超越现有方法。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.06038v2",
      "published_date": "2024-02-08 20:20:54 UTC",
      "updated_date": "2025-04-10 10:41:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T04:30:11.138869"
    },
    {
      "arxiv_id": "2402.06692v1",
      "title": "HistoHDR-Net: Histogram Equalization for Single LDR to HDR Image Translation",
      "title_zh": "翻译失败",
      "authors": [
        "Hrishav Bakul Barua",
        "Ganesh Krishnasamy",
        "KokSheik Wong",
        "Abhinav Dhall",
        "Kalin Stefanov"
      ],
      "abstract": "High Dynamic Range (HDR) imaging aims to replicate the high visual quality\nand clarity of real-world scenes. Due to the high costs associated with HDR\nimaging, the literature offers various data-driven methods for HDR image\nreconstruction from Low Dynamic Range (LDR) counterparts. A common limitation\nof these approaches is missing details in regions of the reconstructed HDR\nimages, which are over- or under-exposed in the input LDR images. To this end,\nwe propose a simple and effective method, HistoHDR-Net, to recover the fine\ndetails (e.g., color, contrast, saturation, and brightness) of HDR images via a\nfusion-based approach utilizing histogram-equalized LDR images along with\nself-attention guidance. Our experiments demonstrate the efficacy of the\nproposed approach over the state-of-art methods.",
      "tldr_zh": "该论文针对从低动态范围 (LDR) 图像到高动态范围 (HDR) 图像转换时存在的细节缺失问题（如过曝或欠曝区域），提出了一种简单有效的 HistoHDR-Net 方法。HistoHDR-Net 通过融合直方图均衡化 (Histogram Equalization) 处理的 LDR 图像以及自注意力指导 (self-attention guidance)，成功恢复 HDR 图像的精细细节，包括颜色、对比度、饱和度和亮度。实验结果显示，该方法在图像重建质量上超过了现有最先进技术。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV",
        "cs.GR",
        "cs.LG",
        "cs.MM",
        "Artificial intelligence, Computer vision, Machine learning, Deep\n  learning",
        "I.3.3; I.4.5"
      ],
      "primary_category": "eess.IV",
      "comment": "Submitted to IEEE",
      "pdf_url": "http://arxiv.org/pdf/2402.06692v1",
      "published_date": "2024-02-08 20:14:46 UTC",
      "updated_date": "2024-02-08 20:14:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T04:30:21.652098"
    },
    {
      "arxiv_id": "2402.06034v1",
      "title": "Optimizing Predictive AI in Physical Design Flows with Mini Pixel Batch Gradient Descent",
      "title_zh": "翻译失败",
      "authors": [
        "Haoyu Yang",
        "Anthony Agnesina",
        "Haoxing Ren"
      ],
      "abstract": "Exploding predictive AI has enabled fast yet effective evaluation and\ndecision-making in modern chip physical design flows. State-of-the-art\nframeworks typically include the objective of minimizing the mean square error\n(MSE) between the prediction and the ground truth. We argue the averaging\neffect of MSE induces limitations in both model training and deployment, and\ngood MSE behavior does not guarantee the capability of these models to assist\nphysical design flows which are likely sabotaged due to a small portion of\nprediction error. To address this, we propose mini-pixel batch gradient descent\n(MPGD), a plug-and-play optimization algorithm that takes the most informative\nentries into consideration, offering probably faster and better convergence.\nExperiments on representative benchmark suits show the significant benefits of\nMPGD on various physical design prediction tasks using CNN or Graph-based\nmodels.",
      "tldr_zh": "该论文针对芯片物理设计流程中的预测 AI 优化问题，指出传统以均方误差(MSE)为目标的框架存在局限性，因为MSE的平均效应可能导致小部分预测错误破坏整体任务。作者提出了一种即插即用优化算法mini-pixel batch gradient descent(MPGD)，该算法优先考虑最有信息量的条目，以实现更快和更好的收敛。实验结果显示，MPGD 在使用CNN或基于图的模型的各种物理设计预测任务上，在代表性基准套件中取得了显著性能提升。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "7 pages, 2 figures, preprint",
      "pdf_url": "http://arxiv.org/pdf/2402.06034v1",
      "published_date": "2024-02-08 20:14:35 UTC",
      "updated_date": "2024-02-08 20:14:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T04:30:32.549756"
    },
    {
      "arxiv_id": "2402.06030v1",
      "title": "Game-theoretic Counterfactual Explanation for Graph Neural Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Chirag Chhablani",
        "Sarthak Jain",
        "Akshay Channesh",
        "Ian A. Kash",
        "Sourav Medya"
      ],
      "abstract": "Graph Neural Networks (GNNs) have been a powerful tool for node\nclassification tasks in complex networks. However, their decision-making\nprocesses remain a black-box to users, making it challenging to understand the\nreasoning behind their predictions. Counterfactual explanations (CFE) have\nshown promise in enhancing the interpretability of machine learning models.\nPrior approaches to compute CFE for GNNS often are learning-based approaches\nthat require training additional graphs. In this paper, we propose a\nsemivalue-based, non-learning approach to generate CFE for node classification\ntasks, eliminating the need for any additional training. Our results reveals\nthat computing Banzhaf values requires lower sample complexity in identifying\nthe counterfactual explanations compared to other popular methods such as\ncomputing Shapley values. Our empirical evidence indicates computing Banzhaf\nvalues can achieve up to a fourfold speed up compared to Shapley values. We\nalso design a thresholding method for computing Banzhaf values and show\ntheoretical and empirical results on its robustness in noisy environments,\nmaking it superior to Shapley values. Furthermore, the thresholded Banzhaf\nvalues are shown to enhance efficiency without compromising the quality (i.e.,\nfidelity) in the explanations in three popular graph datasets.",
      "tldr_zh": "这篇论文针对Graph Neural Networks (GNNs) 在节点分类任务中的黑箱决策问题，提出了一种基于博弈论的非学习方法来生成Counterfactual explanations (CFE)，无需额外训练图。方法利用semivalue框架，特别是Banzhaf values，来识别CFE，并证明其样本复杂度更低，比计算Shapley values快达四倍。实验结果显示，该方法在三个流行图数据集上保持了解释质量（fidelity），并通过阈值技术提升了在噪声环境中的鲁棒性，从而提高了GNNs的可解释性效率。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted to WWW 2024",
      "pdf_url": "http://arxiv.org/pdf/2402.06030v1",
      "published_date": "2024-02-08 20:07:43 UTC",
      "updated_date": "2024-02-08 20:07:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T04:30:46.182928"
    },
    {
      "arxiv_id": "2402.06026v1",
      "title": "Quantum neural network with ensemble learning to mitigate barren plateaus and cost function concentration",
      "title_zh": "翻译失败",
      "authors": [
        "Lucas Friedrich",
        "Jonas Maziero"
      ],
      "abstract": "The rapid development of quantum computers promises transformative impacts\nacross diverse fields of science and technology. Quantum neural networks\n(QNNs), as a forefront application, hold substantial potential. Despite the\nmultitude of proposed models in the literature, persistent challenges, notably\nthe vanishing gradient (VG) and cost function concentration (CFC) problems,\nimpede their widespread success. In this study, we introduce a novel approach\nto quantum neural network construction, specifically addressing the issues of\nVG and CFC. Our methodology employs ensemble learning, advocating for the\nsimultaneous deployment of multiple quantum circuits with a depth equal to $1$,\na departure from the conventional use of a single quantum circuit with depth\n$L$. We assess the efficacy of our proposed model through a comparative\nanalysis with a conventionally constructed QNN. The evaluation unfolds in the\ncontext of a classification problem, yielding valuable insights into the\npotential advantages of our innovative approach.",
      "tldr_zh": "该研究针对量子神经网络（QNNs）面临的 vanishing gradient (VG) 和 cost function concentration (CFC) 问题，提出了一种新方法，使用 ensemble learning 同时部署多个深度为 1 的量子电路，以取代传统单一深度 L 的量子电路。相比传统 QNN，该方法通过分类问题的比较分析，展示了显著的潜在优势，帮助缓解这些挑战。整体创新为量子计算应用提供了更可靠的构建框架。",
      "categories": [
        "quant-ph",
        "cs.AI"
      ],
      "primary_category": "quant-ph",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.06026v1",
      "published_date": "2024-02-08 19:57:57 UTC",
      "updated_date": "2024-02-08 19:57:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T04:30:56.762826"
    },
    {
      "arxiv_id": "2402.06025v7",
      "title": "Doing Experiments and Revising Rules with Natural Language and Probabilistic Reasoning",
      "title_zh": "翻译失败",
      "authors": [
        "Wasu Top Piriyakulkij",
        "Cassidy Langenfeld",
        "Tuan Anh Le",
        "Kevin Ellis"
      ],
      "abstract": "We give a model of how to infer natural language rules by doing experiments.\nThe model integrates Large Language Models (LLMs) with Monte Carlo algorithms\nfor probabilistic inference, interleaving online belief updates with experiment\ndesign under information-theoretic criteria. We conduct a human-model\ncomparison on a Zendo-style task, finding that a critical ingredient for\nmodeling the human data is to assume that humans also consider fuzzy,\nprobabilistic rules, in addition to assuming that humans perform\napproximately-Bayesian belief updates. We also compare with recent algorithms\nfor using LLMs to generate and revise hypotheses, finding that our online\ninference method yields higher accuracy at recovering the true underlying rule,\nand provides better support for designing optimal experiments.",
      "tldr_zh": "本论文提出了一种整合大型语言模型 (LLMs) 和蒙特卡洛算法 (Monte Carlo algorithms) 的模型，用于通过实验推断和修订自然语言规则，该模型通过在线信念更新 (online belief updates) 和基于信息理论准则的实验设计进行交替操作。研究在 Zendo-style 任务上比较了人类和模型的表现，发现关键因素包括假设人类使用模糊的概率规则 (fuzzy, probabilistic rules) 并进行近似贝叶斯信念更新 (approximately-Bayesian belief updates)。与最近的 LLM 算法相比，该方法在恢复真实底层规则方面准确率更高，并更有效地支持设计最优实验。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.06025v7",
      "published_date": "2024-02-08 19:57:29 UTC",
      "updated_date": "2024-10-25 22:26:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T04:31:11.239025"
    },
    {
      "arxiv_id": "2402.06023v1",
      "title": "Decision Theory-Guided Deep Reinforcement Learning for Fast Learning",
      "title_zh": "基于决策理论的深度强化学习用于快速学习",
      "authors": [
        "Zelin Wan",
        "Jin-Hee Cho",
        "Mu Zhu",
        "Ahmed H. Anwar",
        "Charles Kamhoua",
        "Munindar P. Singh"
      ],
      "abstract": "This paper introduces a novel approach, Decision Theory-guided Deep\nReinforcement Learning (DT-guided DRL), to address the inherent cold start\nproblem in DRL. By integrating decision theory principles, DT-guided DRL\nenhances agents' initial performance and robustness in complex environments,\nenabling more efficient and reliable convergence during learning. Our\ninvestigation encompasses two primary problem contexts: the cart pole and maze\nnavigation challenges. Experimental results demonstrate that the integration of\ndecision theory not only facilitates effective initial guidance for DRL agents\nbut also promotes a more structured and informed exploration strategy,\nparticularly in environments characterized by large and intricate state spaces.\nThe results of experiment demonstrate that DT-guided DRL can provide\nsignificantly higher rewards compared to regular DRL. Specifically, during the\ninitial phase of training, the DT-guided DRL yields up to an 184% increase in\naccumulated reward. Moreover, even after reaching convergence, it maintains a\nsuperior performance, ending with up to 53% more reward than standard DRL in\nlarge maze problems. DT-guided DRL represents an advancement in mitigating a\nfundamental challenge of DRL by leveraging functions informed by human\n(designer) knowledge, setting a foundation for further research in this\npromising interdisciplinary domain.",
      "tldr_zh": "本论文提出了一种名为 Decision Theory-guided Deep Reinforcement Learning (DT-guided DRL) 的新方法，用于解决深度强化学习 (DRL) 中的冷启动问题，通过整合决策理论原则来提升代理的初始性能和鲁棒性，从而实现更高效的学习收敛。DT-guided DRL 在复杂环境中提供结构化的探索策略，并在 cart pole 和 maze navigation 等问题中进行了验证。实验结果显示，与标准 DRL 相比，该方法在初始训练阶段可将累积奖励提高高达 184%，而在收敛后仍保持优势，在大型 maze 问题中奖励多出 53%。这种方法利用人类知识指导 DRL，标志着该领域的一个重要进展，为未来跨学科研究奠定基础。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.GT"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.06023v1",
      "published_date": "2024-02-08 19:47:34 UTC",
      "updated_date": "2024-02-08 19:47:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T04:31:20.811922"
    },
    {
      "arxiv_id": "2402.07940v1",
      "title": "LLMs Among Us: Generative AI Participating in Digital Discourse",
      "title_zh": "翻译失败",
      "authors": [
        "Kristina Radivojevic",
        "Nicholas Clark",
        "Paul Brenner"
      ],
      "abstract": "The emergence of Large Language Models (LLMs) has great potential to reshape\nthe landscape of many social media platforms. While this can bring promising\nopportunities, it also raises many threats, such as biases and privacy\nconcerns, and may contribute to the spread of propaganda by malicious actors.\nWe developed the \"LLMs Among Us\" experimental framework on top of the Mastodon\nsocial media platform for bot and human participants to communicate without\nknowing the ratio or nature of bot and human participants. We built 10 personas\nwith three different LLMs, GPT-4, LLama 2 Chat, and Claude. We conducted three\nrounds of the experiment and surveyed participants after each round to measure\nthe ability of LLMs to pose as human participants without human detection. We\nfound that participants correctly identified the nature of other users in the\nexperiment only 42% of the time despite knowing the presence of both bots and\nhumans. We also found that the choice of persona had substantially more impact\non human perception than the choice of mainstream LLMs.",
      "tldr_zh": "该研究探讨大型语言模型 (LLMs) 在社交媒体平台上的参与及其潜在影响，包括机遇和威胁，如偏见、隐私问题和宣传传播。研究者开发了“LLMs Among Us”实验框架，基于 Mastodon 平台，让 bot 和人类参与者互动，并使用 GPT-4、Llama 2 Chat 和 Claude 等模型构建 10 个 persona 进行三轮实验。结果显示，尽管参与者知道有 bot 和人类存在，他们仅在 42% 的时间正确识别其他用户的性质，且 persona 的选择对人类感知的影响远大于 LLMs 的类型选择。该框架为评估生成式 AI 在数字话语中的伪装能力提供了新见解。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CY",
        "cs.SI"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.07940v1",
      "published_date": "2024-02-08 19:21:33 UTC",
      "updated_date": "2024-02-08 19:21:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T04:31:33.667891"
    },
    {
      "arxiv_id": "2402.06004v1",
      "title": "Memory-Efficient Vision Transformers: An Activation-Aware Mixed-Rank Compression Strategy",
      "title_zh": "翻译失败",
      "authors": [
        "Seyedarmin Azizi",
        "Mahdi Nazemi",
        "Massoud Pedram"
      ],
      "abstract": "As Vision Transformers (ViTs) increasingly set new benchmarks in computer\nvision, their practical deployment on inference engines is often hindered by\ntheir significant memory bandwidth and (on-chip) memory footprint requirements.\nThis paper addresses this memory limitation by introducing an activation-aware\nmodel compression methodology that uses selective low-rank weight tensor\napproximations of different layers to reduce the parameter count of ViTs. The\nkey idea is to decompose the weight tensors into a sum of two\nparameter-efficient tensors while minimizing the error between the product of\nthe input activations with the original weight tensor and the product of the\ninput activations with the approximate tensor sum. This approximation is\nfurther refined by adopting an efficient layer-wise error compensation\ntechnique that uses the gradient of the layer's output loss. The combination of\nthese techniques achieves excellent results while it avoids being trapped in a\nshallow local minimum early in the optimization process and strikes a good\nbalance between the model compression and output accuracy. Notably, the\npresented method significantly reduces the parameter count of DeiT-B by 60%\nwith less than 1% accuracy drop on the ImageNet dataset, overcoming the usual\naccuracy degradation seen in low-rank approximations. In addition to this, the\npresented compression technique can compress large DeiT/ViT models to have\nabout the same model size as smaller DeiT/ViT variants while yielding up to\n1.8% accuracy gain. These results highlight the efficacy of our approach,\npresenting a viable solution for embedding ViTs in memory-constrained\nenvironments without compromising their performance.",
      "tldr_zh": "本研究针对Vision Transformers (ViTs) 在实际部署中面临的内存带宽和内存占用问题，提出了一种激活感知的混合秩压缩策略，通过选择性低秩权重张量近似来减少模型参数数量。核心方法是将权重张量分解为两个参数高效张量之和，同时最小化输入激活与原张量乘积的误差，并采用层级误差补偿技术利用输出损失梯度进行优化，以平衡压缩效果和准确性。实验结果显示，该方法将DeiT-B模型的参数减少60%，在ImageNet数据集上准确率仅下降不到1%，甚至能将大型DeiT/ViT模型压缩至小型变体大小，同时获得高达1.8%的准确率提升。该策略为在内存受限环境中高效部署ViTs提供了可行解决方案。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.06004v1",
      "published_date": "2024-02-08 19:01:14 UTC",
      "updated_date": "2024-02-08 19:01:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T04:31:47.413856"
    },
    {
      "arxiv_id": "2402.05935v3",
      "title": "SPHINX-X: Scaling Data and Parameters for a Family of Multi-modal Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Dongyang Liu",
        "Renrui Zhang",
        "Longtian Qiu",
        "Siyuan Huang",
        "Weifeng Lin",
        "Shitian Zhao",
        "Shijie Geng",
        "Ziyi Lin",
        "Peng Jin",
        "Kaipeng Zhang",
        "Wenqi Shao",
        "Chao Xu",
        "Conghui He",
        "Junjun He",
        "Hao Shao",
        "Pan Lu",
        "Hongsheng Li",
        "Yu Qiao",
        "Peng Gao"
      ],
      "abstract": "We propose SPHINX-X, an extensive Multimodality Large Language Model (MLLM)\nseries developed upon SPHINX. To improve the architecture and training\nefficiency, we modify the SPHINX framework by removing redundant visual\nencoders, bypassing fully-padded sub-images with skip tokens, and simplifying\nmulti-stage training into a one-stage all-in-one paradigm. To fully unleash the\npotential of MLLMs, we assemble a comprehensive multi-domain and multimodal\ndataset covering publicly available resources in language, vision, and\nvision-language tasks. We further enrich this collection with our curated OCR\nintensive and Set-of-Mark datasets, extending the diversity and generality. By\ntraining over different base LLMs including TinyLlama1.1B, InternLM2-7B,\nLLaMA2-13B, and Mixtral8x7B, we obtain a spectrum of MLLMs that vary in\nparameter size and multilingual capabilities. Comprehensive benchmarking\nreveals a strong correlation between the multi-modal performance with the data\nand parameter scales. Code and models are released at\nhttps://github.com/Alpha-VLLM/LLaMA2-Accessory",
      "tldr_zh": "本研究提出SPHINX-X，一系列多模态大型语言模型(MLLM)，基于SPHINX框架进行优化，通过移除冗余视觉编码器、使用跳过标记绕过完全填充子图像，以及简化训练为单阶段范式，提高了架构和训练效率。研究者构建了全面的多域数据集，包括语言、视觉和视觉语言资源，并添加了自制的OCR密集型和Set-of-Mark数据集，以增强多样性和泛化能力。在不同基LLM（如TinyLlama1.1B、InternLM2-7B等）上训练，获得了参数规模和多语言能力不同的MLLM系列，基准测试显示多模态性能与数据和参数规模呈强相关性。模型和代码已在https://github.com/Alpha-VLLM/LLaMA2-Accessory开源。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by ICML 2024. Code and models are released at\n  https://github.com/Alpha-VLLM/LLaMA2-Accessory",
      "pdf_url": "http://arxiv.org/pdf/2402.05935v3",
      "published_date": "2024-02-08 18:59:48 UTC",
      "updated_date": "2025-03-21 10:19:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T04:31:57.690696"
    },
    {
      "arxiv_id": "2402.05933v1",
      "title": "Time Series Diffusion in the Frequency Domain",
      "title_zh": "频域中的时间序列扩散",
      "authors": [
        "Jonathan Crabbé",
        "Nicolas Huynh",
        "Jan Stanczuk",
        "Mihaela van der Schaar"
      ],
      "abstract": "Fourier analysis has been an instrumental tool in the development of signal\nprocessing. This leads us to wonder whether this framework could similarly\nbenefit generative modelling. In this paper, we explore this question through\nthe scope of time series diffusion models. More specifically, we analyze\nwhether representing time series in the frequency domain is a useful inductive\nbias for score-based diffusion models. By starting from the canonical SDE\nformulation of diffusion in the time domain, we show that a dual diffusion\nprocess occurs in the frequency domain with an important nuance: Brownian\nmotions are replaced by what we call mirrored Brownian motions, characterized\nby mirror symmetries among their components. Building on this insight, we show\nhow to adapt the denoising score matching approach to implement diffusion\nmodels in the frequency domain. This results in frequency diffusion models,\nwhich we compare to canonical time diffusion models. Our empirical evaluation\non real-world datasets, covering various domains like healthcare and finance,\nshows that frequency diffusion models better capture the training distribution\nthan time diffusion models. We explain this observation by showing that time\nseries from these datasets tend to be more localized in the frequency domain\nthan in the time domain, which makes them easier to model in the former case.\nAll our observations point towards impactful synergies between Fourier analysis\nand diffusion models.",
      "tldr_zh": "本论文探讨了Fourier analysis在生成模型中的应用，特别针对时间序列扩散模型，分析在频率域表示时间序列是否能为score-based diffusion models提供有益的归纳偏差。通过从时间域的SDE公式推导，作者发现频率域存在双重扩散过程，其中Brownian motions被mirrored Brownian motions取代，并适配了denoising score matching方法来实现频率扩散模型。在真实数据集（如医疗和金融领域）的实证评估中，频率扩散模型比时间域模型更准确地捕捉训练分布，这归因于这些时间序列在频率域更具局部性，突显了Fourier analysis与diffusion models之间的协同作用。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "27 pages, 12 figures",
      "pdf_url": "http://arxiv.org/pdf/2402.05933v1",
      "published_date": "2024-02-08 18:59:05 UTC",
      "updated_date": "2024-02-08 18:59:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T04:32:09.453868"
    },
    {
      "arxiv_id": "2402.05932v2",
      "title": "Driving Everywhere with Large Language Model Policy Adaptation",
      "title_zh": "翻译失败",
      "authors": [
        "Boyi Li",
        "Yue Wang",
        "Jiageng Mao",
        "Boris Ivanovic",
        "Sushant Veer",
        "Karen Leung",
        "Marco Pavone"
      ],
      "abstract": "Adapting driving behavior to new environments, customs, and laws is a\nlong-standing problem in autonomous driving, precluding the widespread\ndeployment of autonomous vehicles (AVs). In this paper, we present LLaDA, a\nsimple yet powerful tool that enables human drivers and autonomous vehicles\nalike to drive everywhere by adapting their tasks and motion plans to traffic\nrules in new locations. LLaDA achieves this by leveraging the impressive\nzero-shot generalizability of large language models (LLMs) in interpreting the\ntraffic rules in the local driver handbook. Through an extensive user study, we\nshow that LLaDA's instructions are useful in disambiguating in-the-wild\nunexpected situations. We also demonstrate LLaDA's ability to adapt AV motion\nplanning policies in real-world datasets; LLaDA outperforms baseline planning\napproaches on all our metrics. Please check our website for more details:\nhttps://boyiliee.github.io/llada.",
      "tldr_zh": "该论文提出LLaDA，一种简单有效的工具，利用Large Language Models (LLMs)的零样本泛化能力，帮助人类驾驶员和Autonomous Vehicles (AVs)适应新地点的交通规则，从而实现全球范围的驾驶适应。LLaDA通过解释本地驾驶手册中的规则，生成定制化的任务和运动计划，以处理野外意外情况。实验结果显示，通过用户研究，LLaDA在处理意外场景时表现出色，并在真实数据集上，其运动规划性能在所有指标上优于基线方法。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.RO",
      "comment": "CVPR 2024, featured in GTC 2024:\n  https://www.youtube.com/watch?v=t-UPlPlrYgQ&t=51s",
      "pdf_url": "http://arxiv.org/pdf/2402.05932v2",
      "published_date": "2024-02-08 18:59:03 UTC",
      "updated_date": "2024-04-10 23:29:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T04:32:22.518215"
    },
    {
      "arxiv_id": "2402.05929v2",
      "title": "An Interactive Agent Foundation Model",
      "title_zh": "翻译失败",
      "authors": [
        "Zane Durante",
        "Bidipta Sarkar",
        "Ran Gong",
        "Rohan Taori",
        "Yusuke Noda",
        "Paul Tang",
        "Ehsan Adeli",
        "Shrinidhi Kowshika Lakshmikanth",
        "Kevin Schulman",
        "Arnold Milstein",
        "Demetri Terzopoulos",
        "Ade Famoti",
        "Noboru Kuno",
        "Ashley Llorens",
        "Hoi Vo",
        "Katsu Ikeuchi",
        "Li Fei-Fei",
        "Jianfeng Gao",
        "Naoki Wake",
        "Qiuyuan Huang"
      ],
      "abstract": "The development of artificial intelligence systems is transitioning from\ncreating static, task-specific models to dynamic, agent-based systems capable\nof performing well in a wide range of applications. We propose an Interactive\nAgent Foundation Model that uses a novel multi-task agent training paradigm for\ntraining AI agents across a wide range of domains, datasets, and tasks. Our\ntraining paradigm unifies diverse pre-training strategies, including visual\nmasked auto-encoders, language modeling, and next-action prediction, enabling a\nversatile and adaptable AI framework. We demonstrate the performance of our\nframework across three separate domains -- Robotics, Gaming AI, and Healthcare.\nOur model demonstrates its ability to generate meaningful and contextually\nrelevant outputs in each area. The strength of our approach lies in its\ngenerality, leveraging a variety of data sources such as robotics sequences,\ngameplay data, large-scale video datasets, and textual information for\neffective multimodal and multi-task learning. Our approach provides a promising\navenue for developing generalist, action-taking, multimodal systems.",
      "tldr_zh": "本研究提出了一种Interactive Agent Foundation Model，通过新型多任务代理训练范式，训练AI代理以适应广泛领域、数据集和任务，实现从静态任务模型向动态代理系统的转变。该范式统一了多种预训练策略，包括视觉掩码自动编码器（visual masked auto-encoders）、语言建模和下一个动作预测，利用机器人序列、游戏数据、大规模视频和文本等多源数据进行多模态和多任务学习。在机器人、游戏AI和医疗等领域，模型展示了生成有意义且上下文相关输出的能力，为开发通用型、多模态行动系统提供了有前景的途径。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "cs.RO"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.05929v2",
      "published_date": "2024-02-08 18:58:02 UTC",
      "updated_date": "2024-06-17 15:50:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T04:32:32.964130"
    },
    {
      "arxiv_id": "2402.05906v1",
      "title": "Risk-Sensitive Multi-Agent Reinforcement Learning in Network Aggregative Markov Games",
      "title_zh": "翻译失败",
      "authors": [
        "Hafez Ghaemi",
        "Hamed Kebriaei",
        "Alireza Ramezani Moghaddam",
        "Majid Nili Ahamdabadi"
      ],
      "abstract": "Classical multi-agent reinforcement learning (MARL) assumes risk neutrality\nand complete objectivity for agents. However, in settings where agents need to\nconsider or model human economic or social preferences, a notion of risk must\nbe incorporated into the RL optimization problem. This will be of greater\nimportance in MARL where other human or non-human agents are involved, possibly\nwith their own risk-sensitive policies. In this work, we consider\nrisk-sensitive and non-cooperative MARL with cumulative prospect theory (CPT),\na non-convex risk measure and a generalization of coherent measures of risk.\nCPT is capable of explaining loss aversion in humans and their tendency to\noverestimate/underestimate small/large probabilities. We propose a distributed\nsampling-based actor-critic (AC) algorithm with CPT risk for network\naggregative Markov games (NAMGs), which we call Distributed Nested CPT-AC.\nUnder a set of assumptions, we prove the convergence of the algorithm to a\nsubjective notion of Markov perfect Nash equilibrium in NAMGs. The experimental\nresults show that subjective CPT policies obtained by our algorithm can be\ndifferent from the risk-neutral ones, and agents with a higher loss aversion\nare more inclined to socially isolate themselves in an NAMG.",
      "tldr_zh": "本论文探讨了风险敏感的多智能体强化学习(MARL)，在网络聚合Markov博弈(NAMGs)中引入累积前景理论(CPT)来处理代理的风险偏好和人类损失厌恶行为。作者提出了一种分布式采样-based actor-critic算法，名为Distributed Nested CPT-AC，用于非合作性MARL环境，并证明该算法在特定假设下收敛到主观的Markov Perfect Nash Equilibrium。实验结果表明，CPT策略与风险中性策略存在差异，且损失厌恶程度较高的代理更倾向于在NAMGs中进行社会隔离。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.MA",
        "I.2.6; I.2.11"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.05906v1",
      "published_date": "2024-02-08 18:43:27 UTC",
      "updated_date": "2024-02-08 18:43:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T04:32:46.103471"
    },
    {
      "arxiv_id": "2402.05902v4",
      "title": "ClickSAM: Fine-tuning Segment Anything Model using click prompts for ultrasound image segmentation",
      "title_zh": "ClickSAM：使用点击提示微调 Segment Anything Model 用于超声图像分割",
      "authors": [
        "Aimee Guo",
        "Grace Fei",
        "Hemanth Pasupuleti",
        "Jing Wang"
      ],
      "abstract": "The newly released Segment Anything Model (SAM) is a popular tool used in\nimage processing due to its superior segmentation accuracy, variety of input\nprompts, training capabilities, and efficient model design. However, its\ncurrent model is trained on a diverse dataset not tailored to medical images,\nparticularly ultrasound images. Ultrasound images tend to have a lot of noise,\nmaking it difficult to segment out important structures. In this project, we\ndeveloped ClickSAM, which fine-tunes the Segment Anything Model using click\nprompts for ultrasound images. ClickSAM has two stages of training: the first\nstage is trained on single-click prompts centered in the ground-truth contours,\nand the second stage focuses on improving the model performance through\nadditional positive and negative click prompts. By comparing the first stage\npredictions to the ground-truth masks, true positive, false positive, and false\nnegative segments are calculated. Positive clicks are generated using the true\npositive and false negative segments, and negative clicks are generated using\nthe false positive segments. The Centroidal Voronoi Tessellation algorithm is\nthen employed to collect positive and negative click prompts in each segment\nthat are used to enhance the model performance during the second stage of\ntraining. With click-train methods, ClickSAM exhibits superior performance\ncompared to other existing models for ultrasound image segmentation.",
      "tldr_zh": "这篇论文介绍了 ClickSAM，一种针对超声图像分割的 Segment Anything Model (SAM) 微调方法，以解决超声图像噪声干扰导致的分割难题。方法分为两个训练阶段：第一阶段使用以 ground-truth 轮廓为中心的一个点击提示进行初步训练；第二阶段通过计算真阳性、假阳性和假阴性段来生成正负点击提示，并采用 Centroidal Voronoi Tessellation 算法收集这些提示，以进一步提升模型性能。实验结果表明，ClickSAM 在超声图像分割任务上比现有模型表现出优越的性能。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "physics.med-ph"
      ],
      "primary_category": "cs.CV",
      "comment": "5 pages, 2 figures, SPIE Medical Imaging Conference 2024. Project\n  page: https://sites.google.com/view/clicksam/home",
      "pdf_url": "http://arxiv.org/pdf/2402.05902v4",
      "published_date": "2024-02-08 18:41:41 UTC",
      "updated_date": "2024-02-25 03:25:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T04:32:57.781959"
    },
    {
      "arxiv_id": "2402.05894v4",
      "title": "Large Language Model Meets Graph Neural Network in Knowledge Distillation",
      "title_zh": "翻译失败",
      "authors": [
        "Shengxiang Hu",
        "Guobing Zou",
        "Song Yang",
        "Yanglan Gan",
        "Bofeng Zhang",
        "Yixin Chen"
      ],
      "abstract": "In service-oriented architectures, accurately predicting the Quality of\nService (QoS) is crucial for maintaining reliability and enhancing user\nsatisfaction. However, significant challenges remain due to existing methods\nalways overlooking high-order latent collaborative relationships between users\nand services and failing to dynamically adjust feature learning for every\nspecific user-service invocation, which are critical for learning accurate\nfeatures. Additionally, reliance on RNNs for capturing QoS evolution hampers\nmodels' ability to detect long-term trends due to difficulties in managing\nlong-range dependencies. To address these challenges, we propose the\n\\underline{T}arget-Prompt \\underline{O}nline \\underline{G}raph\n\\underline{C}ollaborative \\underline{L}earning (TOGCL) framework for\ntemporal-aware QoS prediction. TOGCL leverages a dynamic user-service\ninvocation graph to model historical interactions, providing a comprehensive\nrepresentation of user-service relationships. Building on this graph, it\ndevelops a target-prompt graph attention network to extract online deep latent\nfeatures of users and services at each time slice, simultaneously considering\nimplicit collaborative relationships between target users/services and their\nneighbors, as well as relevant historical QoS values. Additionally, a\nmulti-layer Transformer encoder is employed to uncover temporal feature\nevolution patterns of users and services, leading to temporal-aware QoS\nprediction. Extensive experiments conducted on the WS-DREAM dataset demonstrate\nthat our proposed TOGCL framework significantly outperforms state-of-the-art\nmethods across multiple metrics, achieving improvements of up to 38.80\\%. These\nresults underscore the effectiveness of the TOGCL framework for precise\ntemporal QoS prediction.",
      "tldr_zh": "本研究针对服务质量 (QoS) 预测中的挑战，指出现有方法忽略了用户和服务间的高阶潜在协作关系，且依赖 RNN 难以捕捉长程依赖，从而提出 TOGCL 框架。该框架利用动态用户-服务调用图模型历史交互，结合目标提示图注意力网络提取在线深度潜在特征，并采用多层 Transformer 编码器揭示时间特征演变模式，以实现时间感知的 QoS 预测。在 WS-DREAM 数据集上的实验表明，TOGCL 比最先进方法提升高达 38.80%，显著提高了预测准确性。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "68T30, 68R10, 68T05"
      ],
      "primary_category": "cs.AI",
      "comment": "This work has been submitted to the IEEE for possible publication",
      "pdf_url": "http://arxiv.org/pdf/2402.05894v4",
      "published_date": "2024-02-08 18:33:21 UTC",
      "updated_date": "2024-06-11 13:17:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T04:33:12.298941"
    },
    {
      "arxiv_id": "2402.05889v4",
      "title": "CREMA: Generalizable and Efficient Video-Language Reasoning via Multimodal Modular Fusion",
      "title_zh": "翻译失败",
      "authors": [
        "Shoubin Yu",
        "Jaehong Yoon",
        "Mohit Bansal"
      ],
      "abstract": "Despite impressive advancements in recent multimodal reasoning approaches,\nthey are still limited in flexibility and efficiency, as these models typically\nprocess only a few fixed modality inputs and require updates to numerous\nparameters. This paper tackles these critical challenges and proposes CREMA, a\ngeneralizable, highly efficient, and modular modality-fusion framework that can\nincorporate any new modality to enhance video reasoning. We first augment\nmultiple informative modalities (such as optical flow, 3D point cloud, audio,\nthermal heatmap, and touch map) from given videos without extra human\nannotation by leveraging sensors or existing pre-trained models. Next, we\nintroduce a query transformer with multiple parameter-efficient modules\nassociated with each accessible modality. It projects diverse modality features\nto the LLM token embedding space, allowing the model to integrate different\ndata types for response generation. Furthermore, we propose a novel progressive\nmultimodal fusion design supported by a lightweight fusion module and\nmodality-sequential training strategy. It helps compress information across\nvarious assisting modalities, maintaining computational efficiency in the LLM\nwhile improving performance. We validate our method on 7 video-language\nreasoning tasks assisted by diverse modalities, including conventional VideoQA\nand Video-Audio/3D/Touch/Thermal QA, and achieve better/equivalent performance\nagainst strong multimodal LLMs, including OneLLM, BLIP-2, and SeViLA while\nreducing over 90% trainable parameters. We provide extensive analyses of CREMA,\nincluding the impact of each modality on reasoning domains, the design of the\nfusion module, and example visualizations.",
      "tldr_zh": "该论文提出 CREMA，一种通用且高效的视频-语言推理框架，通过多模态模块融合来整合任意新模态，解决现有方法在灵活性和参数更新方面的局限性。CREMA 方法包括从视频中自动增强多种信息模态（如 optical flow、3D point cloud、audio、thermal heatmap 和 touch map），并使用查询变换器结合参数高效模块，将这些模态特征投影到 LLM token 嵌入空间，同时采用渐进式多模态融合和模态顺序训练策略来压缩信息并提升性能。在 7 个视频-语言推理任务（如 VideoQA 和 Video-Audio/3D/Touch/Thermal QA）上，CREMA 比 OneLLM、BLIP-2 和 SeViLA 等模型表现出色或相当，同时减少了 90% 的可训练参数。研究还提供了对各模态影响、融合模块设计和可视化示例的深入分析。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "ICLR 2025; first two authors contributed equally. Project page:\n  https://CREMA-VideoLLM.github.io/",
      "pdf_url": "http://arxiv.org/pdf/2402.05889v4",
      "published_date": "2024-02-08 18:27:22 UTC",
      "updated_date": "2025-03-20 02:27:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T04:33:24.886043"
    },
    {
      "arxiv_id": "2402.05880v2",
      "title": "Generative Echo Chamber? Effects of LLM-Powered Search Systems on Diverse Information Seeking",
      "title_zh": "翻译失败",
      "authors": [
        "Nikhil Sharma",
        "Q. Vera Liao",
        "Ziang Xiao"
      ],
      "abstract": "Large language models (LLMs) powered conversational search systems have\nalready been used by hundreds of millions of people, and are believed to bring\nmany benefits over conventional search. However, while decades of research and\npublic discourse interrogated the risk of search systems in increasing\nselective exposure and creating echo chambers -- limiting exposure to diverse\nopinions and leading to opinion polarization, little is known about such a risk\nof LLM-powered conversational search. We conduct two experiments to\ninvestigate: 1) whether and how LLM-powered conversational search increases\nselective exposure compared to conventional search; 2) whether and how LLMs\nwith opinion biases that either reinforce or challenge the user's view change\nthe effect. Overall, we found that participants engaged in more biased\ninformation querying with LLM-powered conversational search, and an opinionated\nLLM reinforcing their views exacerbated this bias. These results present\ncritical implications for the development of LLMs and conversational search\nsystems, and the policy governing these technologies.",
      "tldr_zh": "本研究调查了大型语言模型（LLMs）驱动的对话式搜索系统是否会加剧选择性暴露（selective exposure）和回音室效应（echo chambers），从而限制用户对多样意见的获取并导致意见两极分化。研究者通过两个实验比较了LLMs搜索与传统搜索的差异，并测试了LLMs的意见偏差（即强化或挑战用户观点）对用户行为的影响。结果显示，用户在使用LLMs搜索时更倾向于进行有偏见的查询，而当LLMs的意见强化用户观点时，这种偏差会进一步加剧。这些发现为LLMs和对话式搜索系统的开发以及相关政策提供了重要启示。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted in CHI'24. Supplementary material will be available online\n  with the official submission in CHI 2024",
      "pdf_url": "http://arxiv.org/pdf/2402.05880v2",
      "published_date": "2024-02-08 18:14:33 UTC",
      "updated_date": "2024-02-10 17:03:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T04:33:35.722626"
    },
    {
      "arxiv_id": "2402.05868v3",
      "title": "EmojiPrompt: Generative Prompt Obfuscation for Privacy-Preserving Communication with Cloud-based LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Sam Lin",
        "Wenyue Hua",
        "Zhenting Wang",
        "Mingyu Jin",
        "Lizhou Fan",
        "Yongfeng Zhang"
      ],
      "abstract": "Cloud-based Large Language Models (LLMs) such as ChatGPT have become\nincreasingly integral to daily operations. Nevertheless, they also introduce\nprivacy concerns: firstly, numerous studies underscore the risks to user\nprivacy posed by jailbreaking cloud-based LLMs; secondly, the LLM service\nproviders have access to all user data, which deters individuals from\nconfidently utilizing such services. To address such concerns, we propose a\nsimple yet effective paradigm, EmojiPrompt, to protect user privacy. At its\ncore, EmojiPrompt performs generative transformation, obfuscating private data\nwithin prompts with linguistic and non-linguistic elements before submitting\nthem to cloud-based LLMs. We evaluate EmojiPrompt's performance across 8\ndatasets from various domains. We also propose simulated inference attacks to\nassess EmojiPrompt's ability to preserve user privacy. The results demonstrate\nthat EmojiPrompt effectively obfuscates user private data, while largely\nmaintaining, or even enhancing, performances compared to the unobfuscated\nversion. Furthermore, EmojiPrompt's atomic-level obfuscation allows it to\nfunction exclusively with cloud-based LLMs. For source code, please refer to:\nhttps://github.com/agiresearch/EmojiCrypt.",
      "tldr_zh": "该论文提出 EmojiPrompt，一种生成性提示混淆方法，用于保护用户在云端 Large Language Models (LLMs) 如 ChatGPT 中的隐私通信。该方法通过在提交提示前使用语言和非语言元素（如表情符号）对私有数据进行生成性转换，从而有效混淆敏感信息，同时保持或提升模型性能。实验在8个不同领域的数据集上评估了 EmojiPrompt，并通过模拟推理攻击验证了其隐私保护能力，结果显示它显著提高了隐私安全，且仅需云端 LLMs 即可实现。开源代码可从指定链接获取。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CR",
        "cs.IR",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to the 2025 Annual Conference of the Nations of the Americas\n  Chapter of the Association for Computational Linguistics (NAACL 2025)",
      "pdf_url": "http://arxiv.org/pdf/2402.05868v3",
      "published_date": "2024-02-08 17:57:11 UTC",
      "updated_date": "2025-03-20 20:15:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T04:33:47.199862"
    },
    {
      "arxiv_id": "2402.05863v1",
      "title": "How Well Can LLMs Negotiate? NegotiationArena Platform and Analysis",
      "title_zh": "LLMs 的谈判能力如何？NegotiationArena 平台和分析",
      "authors": [
        "Federico Bianchi",
        "Patrick John Chia",
        "Mert Yuksekgonul",
        "Jacopo Tagliabue",
        "Dan Jurafsky",
        "James Zou"
      ],
      "abstract": "Negotiation is the basis of social interactions; humans negotiate everything\nfrom the price of cars to how to share common resources. With rapidly growing\ninterest in using large language models (LLMs) to act as agents on behalf of\nhuman users, such LLM agents would also need to be able to negotiate. In this\npaper, we study how well LLMs can negotiate with each other. We develop\nNegotiationArena: a flexible framework for evaluating and probing the\nnegotiation abilities of LLM agents. We implemented three types of scenarios in\nNegotiationArena to assess LLM's behaviors in allocating shared resources\n(ultimatum games), aggregate resources (trading games) and buy/sell goods\n(price negotiations). Each scenario allows for multiple turns of flexible\ndialogues between LLM agents to allow for more complex negotiations.\nInterestingly, LLM agents can significantly boost their negotiation outcomes by\nemploying certain behavioral tactics. For example, by pretending to be desolate\nand desperate, LLMs can improve their payoffs by 20\\% when negotiating against\nthe standard GPT-4. We also quantify irrational negotiation behaviors exhibited\nby the LLM agents, many of which also appear in humans. Together,\n\\NegotiationArena offers a new environment to investigate LLM interactions,\nenabling new insights into LLM's theory of mind, irrationality, and reasoning\nabilities.",
      "tldr_zh": "本文评估了大型语言模型（LLMs）在谈判中的表现，并开发了NegotiationArena平台作为灵活的评估框架。该平台包括最后通牒游戏、交易游戏和价格谈判三种场景，允许LLMs进行多轮对话以模拟复杂互动。研究发现，LLMs通过采用行为策略（如假装绝望）可将谈判收益提高20%，例如对抗标准GPT-4时；同时，LLMs表现出类似于人类的非理性行为，为探索LLMs的理论思维和推理能力提供了新见解。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.GT"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.05863v1",
      "published_date": "2024-02-08 17:51:48 UTC",
      "updated_date": "2024-02-08 17:51:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T04:33:58.340801"
    },
    {
      "arxiv_id": "2402.05862v1",
      "title": "Let Your Graph Do the Talking: Encoding Structured Data for LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Bryan Perozzi",
        "Bahare Fatemi",
        "Dustin Zelle",
        "Anton Tsitsulin",
        "Mehran Kazemi",
        "Rami Al-Rfou",
        "Jonathan Halcrow"
      ],
      "abstract": "How can we best encode structured data into sequential form for use in large\nlanguage models (LLMs)? In this work, we introduce a parameter-efficient method\nto explicitly represent structured data for LLMs. Our method, GraphToken,\nlearns an encoding function to extend prompts with explicit structured\ninformation. Unlike other work which focuses on limited domains (e.g. knowledge\ngraph representation), our work is the first effort focused on the general\nencoding of structured data to be used for various reasoning tasks. We show\nthat explicitly representing the graph structure allows significant\nimprovements to graph reasoning tasks. Specifically, we see across the board\nimprovements - up to 73% points - on node, edge and, graph-level tasks from the\nGraphQA benchmark.",
      "tldr_zh": "该论文提出了一种参数高效的方法 GraphToken，用于将结构化数据显式编码成序列形式，以便在大型语言模型（LLMs）中使用。该方法通过学习编码函数扩展提示，专注于一般结构化数据的表示，从而支持各种推理任务。与以往专注于特定领域（如知识图谱表示）的工作不同，GraphToken 强调显式图结构表示。实验结果显示，在 GraphQA 基准上的图推理任务中，该方法在节点、边和图级任务上实现了高达 73% 的性能提升。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.SI",
        "stat.ML",
        "I.5.1; I.2.6; I.2.7"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.05862v1",
      "published_date": "2024-02-08 17:51:44 UTC",
      "updated_date": "2024-02-08 17:51:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T04:34:09.965575"
    },
    {
      "arxiv_id": "2402.05830v1",
      "title": "Sparse-VQ Transformer: An FFN-Free Framework with Vector Quantization for Enhanced Time Series Forecasting",
      "title_zh": "翻译失败",
      "authors": [
        "Yanjun Zhao",
        "Tian Zhou",
        "Chao Chen",
        "Liang Sun",
        "Yi Qian",
        "Rong Jin"
      ],
      "abstract": "Time series analysis is vital for numerous applications, and transformers\nhave become increasingly prominent in this domain. Leading methods customize\nthe transformer architecture from NLP and CV, utilizing a patching technique to\nconvert continuous signals into segments. Yet, time series data are uniquely\nchallenging due to significant distribution shifts and intrinsic noise levels.\nTo address these two challenges,we introduce the Sparse Vector Quantized\nFFN-Free Transformer (Sparse-VQ). Our methodology capitalizes on a sparse\nvector quantization technique coupled with Reverse Instance Normalization\n(RevIN) to reduce noise impact and capture sufficient statistics for\nforecasting, serving as an alternative to the Feed-Forward layer (FFN) in the\ntransformer architecture. Our FFN-free approach trims the parameter count,\nenhancing computational efficiency and reducing overfitting. Through\nevaluations across ten benchmark datasets, including the newly introduced CAISO\ndataset, Sparse-VQ surpasses leading models with a 7.84% and 4.17% decrease in\nMAE for univariate and multivariate time series forecasting, respectively.\nMoreover, it can be seamlessly integrated with existing transformer-based\nmodels to elevate their performance.",
      "tldr_zh": "本文提出Sparse-VQ Transformer，一种无Feed-Forward layer (FFN)的框架，通过稀疏向量量化(Sparse Vector Quantization)技术结合Reverse Instance Normalization (RevIN)，来解决时间序列数据中分布偏移和噪声挑战，从而提升预测准确性和计算效率。相比传统方法，该框架减少参数数量、降低过拟合风险，并在十个基准数据集（如新引入的CAISO数据集）上表现出色，分别将单变量和多变量时间序列预测的MAE降低了7.84%和4.17%。此外，Sparse-VQ可无缝整合到现有Transformer模型中，进一步提升其性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.05830v1",
      "published_date": "2024-02-08 17:09:12 UTC",
      "updated_date": "2024-02-08 17:09:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T04:34:23.017579"
    },
    {
      "arxiv_id": "2402.05829v1",
      "title": "Limitations of Agents Simulated by Predictive Models",
      "title_zh": "翻译失败",
      "authors": [
        "Raymond Douglas",
        "Jacek Karwowski",
        "Chan Bae",
        "Andis Draguns",
        "Victoria Krakovna"
      ],
      "abstract": "There is increasing focus on adapting predictive models into agent-like\nsystems, most notably AI assistants based on language models. We outline two\nstructural reasons for why these models can fail when turned into agents.\nFirst, we discuss auto-suggestive delusions. Prior work has shown theoretically\nthat models fail to imitate agents that generated the training data if the\nagents relied on hidden observations: the hidden observations act as\nconfounding variables, and the models treat actions they generate as evidence\nfor nonexistent observations. Second, we introduce and formally study a\nrelated, novel limitation: predictor-policy incoherence. When a model generates\na sequence of actions, the model's implicit prediction of the policy that\ngenerated those actions can serve as a confounding variable. The result is that\nmodels choose actions as if they expect future actions to be suboptimal,\ncausing them to be overly conservative. We show that both of those failures are\nfixed by including a feedback loop from the environment, that is, re-training\nthe models on their own actions. We give simple demonstrations of both\nlimitations using Decision Transformers and confirm that empirical results\nagree with our conceptual and formal analysis. Our treatment provides a\nunifying view of those failure modes, and informs the question of why\nfine-tuning offline learned policies with online learning makes them more\neffective.",
      "tldr_zh": "本文分析了将预测模型（如语言模型）转化为代理系统时存在的两个结构性局限性：auto-suggestive delusions 和 predictor-policy incoherence。auto-suggestive delusions 导致模型无法正确模仿依赖隐藏观察的代理，因为隐藏观察作为混淆变量使模型误判生成动作；predictor-policy incoherence 则使模型在预测动作序列时隐式假设未来动作次优，从而选择过于保守的策略。通过引入环境反馈循环并重新训练模型，这些问题可被修复。研究使用 Decision Transformers 进行了实证演示，实验结果支持理论分析，并统一解释了在线学习微调离线策略的提升效果。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.05829v1",
      "published_date": "2024-02-08 17:08:08 UTC",
      "updated_date": "2024-02-08 17:08:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T04:34:34.889882"
    },
    {
      "arxiv_id": "2402.05828v1",
      "title": "Discovering Temporally-Aware Reinforcement Learning Algorithms",
      "title_zh": "发现时间感知强化学习算法",
      "authors": [
        "Matthew Thomas Jackson",
        "Chris Lu",
        "Louis Kirsch",
        "Robert Tjarko Lange",
        "Shimon Whiteson",
        "Jakob Nicolaus Foerster"
      ],
      "abstract": "Recent advancements in meta-learning have enabled the automatic discovery of\nnovel reinforcement learning algorithms parameterized by surrogate objective\nfunctions. To improve upon manually designed algorithms, the parameterization\nof this learned objective function must be expressive enough to represent novel\nprinciples of learning (instead of merely recovering already established ones)\nwhile still generalizing to a wide range of settings outside of its\nmeta-training distribution. However, existing methods focus on discovering\nobjective functions that, like many widely used objective functions in\nreinforcement learning, do not take into account the total number of steps\nallowed for training, or \"training horizon\". In contrast, humans use a plethora\nof different learning objectives across the course of acquiring a new ability.\nFor instance, students may alter their studying techniques based on the\nproximity to exam deadlines and their self-assessed capabilities. This paper\ncontends that ignoring the optimization time horizon significantly restricts\nthe expressive potential of discovered learning algorithms. We propose a simple\naugmentation to two existing objective discovery approaches that allows the\ndiscovered algorithm to dynamically update its objective function throughout\nthe agent's training procedure, resulting in expressive schedules and increased\ngeneralization across different training horizons. In the process, we find that\ncommonly used meta-gradient approaches fail to discover such adaptive objective\nfunctions while evolution strategies discover highly dynamic learning rules. We\ndemonstrate the effectiveness of our approach on a wide range of tasks and\nanalyze the resulting learned algorithms, which we find effectively balance\nexploration and exploitation by modifying the structure of their learning rules\nthroughout the agent's lifetime.",
      "tldr_zh": "本研究探讨了元学习（meta-learning）在强化学习（reinforcement learning）中的应用，强调现有算法忽略训练时限（training horizon），从而限制了其表达性和泛化能力。论文提出了一种简单增强方法，允许发现的算法动态更新目标函数（objective functions），从而根据训练过程调整学习策略。实验结果显示，该方法使用进化策略（evolution strategies）比元梯度（meta-gradient）方法更有效地发现适应性规则，并在多种任务上实现了更好的探索-利用平衡，并提升了跨不同训练时限的泛化性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Published at ICLR 2024",
      "pdf_url": "http://arxiv.org/pdf/2402.05828v1",
      "published_date": "2024-02-08 17:07:42 UTC",
      "updated_date": "2024-02-08 17:07:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T04:34:45.641536"
    },
    {
      "arxiv_id": "2402.05823v1",
      "title": "FusionSF: Fuse Heterogeneous Modalities in a Vector Quantized Framework for Robust Solar Power Forecasting",
      "title_zh": "翻译失败",
      "authors": [
        "Ziqing Ma",
        "Wenwei Wang",
        "Tian Zhou",
        "Chao Chen",
        "Bingqing Peng",
        "Liang Sun",
        "Rong Jin"
      ],
      "abstract": "Accurate solar power forecasting is crucial to integrate photovoltaic plants\ninto the electric grid, schedule and secure the power grid safety. This problem\nbecomes more demanding for those newly installed solar plants which lack\nsufficient data. Current research predominantly relies on historical solar\npower data or numerical weather prediction in a single-modality format,\nignoring the complementary information provided in different modalities. In\nthis paper, we propose a multi-modality fusion framework to integrate\nhistorical power data, numerical weather prediction, and satellite images,\nsignificantly improving forecast performance. We introduce a vector quantized\nframework that aligns modalities with varying information densities, striking a\nbalance between integrating sufficient information and averting model\noverfitting. Our framework demonstrates strong zero-shot forecasting\ncapability, which is especially useful for those newly installed plants.\nMoreover, we collect and release a multi-modal solar power (MMSP) dataset from\nreal-world plants to further promote the research of multi-modal solar\nforecasting algorithms. Our extensive experiments show that our model not only\noperates with robustness but also boosts accuracy in both zero-shot forecasting\nand scenarios rich with training data, surpassing leading models. We have\nincorporated it into our eForecaster platform and deployed it for more than 300\nsolar plants with a capacity of over 15GW.",
      "tldr_zh": "这篇论文提出FusionSF框架，通过融合historical power data、numerical weather prediction和satellite images等多模式数据，来提升太阳能发电预测的准确性和鲁棒性，尤其针对新安装电站的数据不足问题。框架采用vector quantized方法对齐不同信息密度的异构模式，平衡信息整合与避免过拟合，同时展现出强大的zero-shot forecasting能力。实验结果显示，FusionSF在各种场景中超越领先模型，并已部署到eForecaster平台，服务超过300个太阳能电站；此外，论文还发布了multi-modal solar power (MMSP)数据集，以促进多模式预测研究。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.05823v1",
      "published_date": "2024-02-08 17:03:10 UTC",
      "updated_date": "2024-02-08 17:03:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T04:34:59.282962"
    },
    {
      "arxiv_id": "2402.05813v2",
      "title": "Selective Forgetting: Advancing Machine Unlearning Techniques and Evaluation in Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Lingzhi Wang",
        "Xingshan Zeng",
        "Jinsong Guo",
        "Kam-Fai Wong",
        "Georg Gottlob"
      ],
      "abstract": "This paper explores Machine Unlearning (MU), an emerging field that is\ngaining increased attention due to concerns about neural models unintentionally\nremembering personal or sensitive information. We present SeUL, a novel method\nthat enables selective and fine-grained unlearning for language models. Unlike\nprevious work that employs a fully reversed training objective in unlearning,\nSeUL minimizes the negative impact on the capability of language models,\nparticularly in terms of generation. Furthermore, we introduce two innovative\nevaluation metrics, sensitive extraction likelihood (S-EL) and sensitive\nmemorization accuracy (S-MA), specifically designed to assess the effectiveness\nof forgetting sensitive information. In support of the unlearning framework, we\npropose efficient automatic online and offline sensitive span annotation\nmethods. The online selection method, based on language probability scores,\nensures computational efficiency, while the offline annotation involves a\ntwo-stage LLM-based process for robust verification. In summary, this paper\ncontributes a novel selective unlearning method (SeUL), introduces specialized\nevaluation metrics (S-EL and S-MA) for assessing sensitive information\nforgetting, and proposes automatic online and offline sensitive span annotation\nmethods to support the overall unlearning framework and evaluation process.",
      "tldr_zh": "这篇论文探讨了 Machine Unlearning (MU)，一种针对语言模型意外记忆敏感信息的技术，并提出了一种新型方法 SeUL，实现选择性和细粒度的信息删除，同时最小化对模型生成能力的负面影响。SeUL 不同于以往的完全反向训练方法，更注重保持模型整体性能。论文还引入了两个创新评价指标：sensitive extraction likelihood (S-EL) 和 sensitive memorization accuracy (S-MA)，用于评估敏感信息遗忘的有效性；同时，提出高效的自动敏感 span 标注方法，包括基于语言概率分数的在线方法和两阶段的 LLM-based 离线过程。这些贡献为提升语言模型的隐私保护提供了重要框架。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to AAAI2025",
      "pdf_url": "http://arxiv.org/pdf/2402.05813v2",
      "published_date": "2024-02-08 16:50:01 UTC",
      "updated_date": "2024-12-16 12:44:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T04:35:12.445245"
    },
    {
      "arxiv_id": "2402.05809v3",
      "title": "You Only Need One Color Space: An Efficient Network for Low-light Image Enhancement",
      "title_zh": "翻译失败",
      "authors": [
        "Qingsen Yan",
        "Yixu Feng",
        "Cheng Zhang",
        "Pei Wang",
        "Peng Wu",
        "Wei Dong",
        "Jinqiu Sun",
        "Yanning Zhang"
      ],
      "abstract": "Low-Light Image Enhancement (LLIE) task tends to restore the details and\nvisual information from corrupted low-light images. Most existing methods learn\nthe mapping function between low/normal-light images by Deep Neural Networks\n(DNNs) on sRGB and HSV color space. Nevertheless, enhancement involves\namplifying image signals, and applying these color spaces to low-light images\nwith a low signal-to-noise ratio can introduce sensitivity and instability into\nthe enhancement process. Consequently, this results in the presence of color\nartifacts and brightness artifacts in the enhanced images. To alleviate this\nproblem, we propose a novel trainable color space, named\nHorizontal/Vertical-Intensity (HVI). It not only decouples brightness and color\nfrom RGB channels to mitigate the instability during enhancement but also\nadapts to low-light images in different illumination ranges due to the\ntrainable parameters. Further, we design a novel Color and Intensity Decoupling\nNetwork (CIDNet) with two branches dedicated to processing the decoupled image\nbrightness and color in the HVI space. Within CIDNet, we introduce the\nLightweight Cross-Attention (LCA) module to facilitate interaction between\nimage structure and content information in both branches, while also\nsuppressing noise in low-light images. Finally, we conducted 22 quantitative\nand qualitative experiments to show that the proposed CIDNet outperforms the\nstate-of-the-art methods on 11 datasets. The code is available at\nhttps://github.com/Fediory/HVI-CIDNet.",
      "tldr_zh": "本论文针对低光图像增强（LLIE）任务，提出了一种高效网络，仅需一个可训练的 Horizontal/Vertical-Intensity (HVI) 颜色空间来解耦图像亮度和颜色，从而缓解现有方法在 sRGB 和 HSV 空间中因低信噪比导致的颜色和亮度伪影问题。作者设计了 Color and Intensity Decoupling Network (CIDNet)，该网络包含两个分支分别处理解耦后的亮度和颜色，并引入 Lightweight Cross-Attention (LCA) 模块来促进分支间的信息交互并抑制噪声。实验结果显示，CIDNet 在 11 个数据集上进行了 22 次定量和定性评估，性能优于最先进方法，为 LLIE 提供了更稳定和高效的解决方案。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Qingsen Yan, Yixu Feng, Cheng Zhang contributed equally to this work.\n  Corresponding author: Yanning Zhang",
      "pdf_url": "http://arxiv.org/pdf/2402.05809v3",
      "published_date": "2024-02-08 16:47:43 UTC",
      "updated_date": "2024-06-17 20:43:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T04:35:25.590700"
    },
    {
      "arxiv_id": "2402.05808v2",
      "title": "Training Large Language Models for Reasoning through Reverse Curriculum Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Zhiheng Xi",
        "Wenxiang Chen",
        "Boyang Hong",
        "Senjie Jin",
        "Rui Zheng",
        "Wei He",
        "Yiwen Ding",
        "Shichun Liu",
        "Xin Guo",
        "Junzhe Wang",
        "Honglin Guo",
        "Wei Shen",
        "Xiaoran Fan",
        "Yuhao Zhou",
        "Shihan Dou",
        "Xiao Wang",
        "Xinbo Zhang",
        "Peng Sun",
        "Tao Gui",
        "Qi Zhang",
        "Xuanjing Huang"
      ],
      "abstract": "In this paper, we propose R$^3$: Learning Reasoning through Reverse\nCurriculum Reinforcement Learning (RL), a novel method that employs only\noutcome supervision to achieve the benefits of process supervision for large\nlanguage models. The core challenge in applying RL to complex reasoning is to\nidentify a sequence of actions that result in positive rewards and provide\nappropriate supervision for optimization. Outcome supervision provides sparse\nrewards for final results without identifying error locations, whereas process\nsupervision offers step-wise rewards but requires extensive manual annotation.\nR$^3$ overcomes these limitations by learning from correct demonstrations.\nSpecifically, R$^3$ progressively slides the start state of reasoning from a\ndemonstration's end to its beginning, facilitating easier model exploration at\nall stages. Thus, R$^3$ establishes a step-wise curriculum, allowing outcome\nsupervision to offer step-level signals and precisely pinpoint errors. Using\nLlama2-7B, our method surpasses RL baseline on eight reasoning tasks by $4.1$\npoints on average. Notebaly, in program-based reasoning on GSM8K, it exceeds\nthe baseline by $4.2$ points across three backbone models, and without any\nextra data, Codellama-7B + R$^3$ performs comparable to larger models or\nclosed-source models.",
      "tldr_zh": "本研究提出了一种名为 R$^3$ 的方法，即通过逆向课程强化学习（Reverse Curriculum Reinforcement Learning）训练大型语言模型，仅使用结果监督（outcome supervision）即可实现过程监督（process supervision）的优势。R$^3$ 通过从正确演示的末尾逐步向开头滑动起始状态，建立一个步进课程，从而便于模型在各阶段探索，并精确定位错误。实验结果显示，使用 Llama2-7B 模型，R$^3$ 在八个推理任务上比强化学习基线平均提高 4.1 分，并在 GSM8K 的程序-based 推理中领先 4.2 分；此外，Codellama-7B + R$^3$ 无需额外数据，即可与更大模型或闭源模型性能相当。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "Preprint. Codes released:\n  https://github.com/WooooDyy/LLM-Reverse-Curriculum-RL",
      "pdf_url": "http://arxiv.org/pdf/2402.05808v2",
      "published_date": "2024-02-08 16:46:26 UTC",
      "updated_date": "2024-03-17 09:02:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T04:35:36.571649"
    },
    {
      "arxiv_id": "2402.05804v3",
      "title": "InkSight: Offline-to-Online Handwriting Conversion by Learning to Read and Write",
      "title_zh": "翻译失败",
      "authors": [
        "Blagoj Mitrevski",
        "Arina Rak",
        "Julian Schnitzler",
        "Chengkun Li",
        "Andrii Maksai",
        "Jesse Berent",
        "Claudiu Musat"
      ],
      "abstract": "Digital note-taking is gaining popularity, offering a durable, editable, and\neasily indexable way of storing notes in a vectorized form, known as digital\nink. However, a substantial gap remains between this way of note-taking and\ntraditional pen-and-paper note-taking, a practice that is still favored by a\nvast majority. Our work InkSight, aims to bridge the gap by empowering physical\nnote-takers to effortlessly convert their work (offline handwriting) to digital\nink (online handwriting), a process we refer to as derendering. Prior research\non the topic has focused on the geometric properties of images, resulting in\nlimited generalization beyond their training domains. Our approach combines\nreading and writing priors, allowing training a model in the absence of large\namounts of paired samples, which are difficult to obtain. To our knowledge,\nthis is the first work that effectively derenders handwritten text in arbitrary\nphotos with diverse visual characteristics and backgrounds. Furthermore, it\ngeneralizes beyond its training domain into simple sketches. Our human\nevaluation reveals that 87% of the samples produced by our model on the\nchallenging HierText dataset are considered as a valid tracing of the input\nimage and 67% look like a pen trajectory traced by a human.",
      "tldr_zh": "本文提出 InkSight 框架，通过结合阅读和写作先验，实现手写笔记的离线到在线转换（derendering），以桥接传统笔纸笔记与数字墨水的差距。不同于以往专注于图像几何属性的方法，该框架减少了对大量配对样本的依赖，能够有效处理任意照片中的手写文本，并泛化到简单草图。人类评估显示，在 HierText 数据集上，87% 的样本被视为有效追踪，67% 看起来像人类笔迹，从而提升了数字笔记的可行性和实用性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Add release info",
      "pdf_url": "http://arxiv.org/pdf/2402.05804v3",
      "published_date": "2024-02-08 16:41:41 UTC",
      "updated_date": "2024-12-08 21:05:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T04:35:48.415199"
    },
    {
      "arxiv_id": "2402.05794v1",
      "title": "Phonetically rich corpus construction for a low-resourced language",
      "title_zh": "翻译失败",
      "authors": [
        "Marcellus Amadeus",
        "William Alberto Cruz Castañeda",
        "Wilmer Lobato",
        "Niasche Aquino"
      ],
      "abstract": "Speech technologies rely on capturing a speaker's voice variability while\nobtaining comprehensive language information. Textual prompts and sentence\nselection methods have been proposed in the literature to comprise such\nadequate phonetic data, referred to as a phonetically rich \\textit{corpus}.\nHowever, they are still insufficient for acoustic modeling, especially critical\nfor languages with limited resources. Hence, this paper proposes a novel\napproach and outlines the methodological aspects required to create a\n\\textit{corpus} with broad phonetic coverage for a low-resourced language,\nBrazilian Portuguese. Our methodology includes text dataset collection up to a\nsentence selection algorithm based on triphone distribution. Furthermore, we\npropose a new phonemic classification according to acoustic-articulatory speech\nfeatures since the absolute number of distinct triphones, or low-probability\ntriphones, does not guarantee an adequate representation of every possible\ncombination. Using our algorithm, we achieve a 55.8\\% higher percentage of\ndistinct triphones -- for samples of similar size -- while the currently\navailable phonetic-rich corpus, CETUC and TTS-Portuguese, 12.6\\% and 12.3\\% in\ncomparison to a non-phonetically rich dataset.",
      "tldr_zh": "本研究针对低资源语言（如巴西葡萄牙语）构建语音丰富语料（phonetically rich corpus），以解决现有文本提示和句子选择方法在捕捉语音变异性和语言信息方面的不足。研究提出了一种新方法，包括文本数据集收集、基于 triphone 分布的句子选择算法，以及一种新的音素分类方法，该分类考虑声学-发音特征，以确保更全面的语音组合代表性。实验结果显示，该算法使不同 triphone 的覆盖率提高了55.8%，而现有语料库 CETUC 和 TTS-Portuguese 仅分别比非语音丰富数据集高出12.6%和12.3%。这为低资源语言的声学建模提供了更有效的工具。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.05794v1",
      "published_date": "2024-02-08 16:36:11 UTC",
      "updated_date": "2024-02-08 16:36:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T04:36:00.332083"
    },
    {
      "arxiv_id": "2402.05786v2",
      "title": "Prompting Fairness: Artificial Intelligence as Game Players",
      "title_zh": "翻译失败",
      "authors": [
        "Jazmia Henry"
      ],
      "abstract": "Utilitarian games such as dictator games to measure fairness have been\nstudied in the social sciences for decades. These games have given us insight\ninto not only how humans view fairness but also in what conditions the\nfrequency of fairness, altruism and greed increase or decrease. While these\ngames have traditionally been focused on humans, the rise of AI gives us the\nability to study how these models play these games. AI is becoming a constant\nin human interaction and examining how these models portray fairness in game\nplay can give us some insight into how AI makes decisions. Over 101 rounds of\nthe dictator game, I conclude that AI has a strong sense of fairness that is\ndependant of it it deems the person it is playing with as trustworthy, framing\nhas a strong effect on how much AI gives a recipient when designated the\ntrustee, and there may be evidence that AI experiences inequality aversion just\nas humans.",
      "tldr_zh": "这篇论文探讨了 AI 在游戏中的公平行为，特别通过独裁者游戏(dictator game)来评估 AI 如何表现公平、利他主义和贪婪。\n研究者进行了 101 轮实验，发现 AI 表现出强烈的公平感，但这种行为依赖于它对玩家的信任评估，以及游戏框架(framing)的设计。\n此外，证据表明 AI 可能像人类一样存在不平等厌恶(inequality aversion)，这为理解 AI 决策机制提供了重要洞见。",
      "categories": [
        "cs.AI",
        "cs.GT"
      ],
      "primary_category": "cs.AI",
      "comment": "preprint",
      "pdf_url": "http://arxiv.org/pdf/2402.05786v2",
      "published_date": "2024-02-08 16:24:40 UTC",
      "updated_date": "2024-02-09 04:19:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T04:36:11.326668"
    },
    {
      "arxiv_id": "2402.05785v5",
      "title": "Limits of Transformer Language Models on Learning to Compose Algorithms",
      "title_zh": "Transformer 语言模型在学习组合算法方面的限制",
      "authors": [
        "Jonathan Thomm",
        "Giacomo Camposampiero",
        "Aleksandar Terzic",
        "Michael Hersche",
        "Bernhard Schölkopf",
        "Abbas Rahimi"
      ],
      "abstract": "We analyze the capabilities of Transformer language models in learning\ncompositional discrete tasks. To this end, we evaluate training LLaMA models\nand prompting GPT-4 and Gemini on four tasks demanding to learn a composition\nof several discrete sub-tasks. In particular, we measure how well these models\ncan reuse primitives observable in the sub-tasks to learn the composition task.\nOur results indicate that compositional learning in state-of-the-art\nTransformer language models is highly sample inefficient: LLaMA requires more\ndata samples than relearning all sub-tasks from scratch to learn the\ncompositional task; in-context prompting with few samples is unreliable and\nfails at executing the sub-tasks or correcting the errors in multi-round code\ngeneration. Further, by leveraging complexity theory, we support these findings\nwith a theoretical analysis focused on the sample inefficiency of gradient\ndescent in memorizing feedforward models. We open source our code at\nhttps://github.com/IBM/limitations-lm-algorithmic-compositional-learning.",
      "tldr_zh": "本研究分析了 Transformer 语言模型在学习组合算法方面的局限性，通过评估 LLaMA 模型的训练以及对 GPT-4 和 Gemini 的 in-context prompting，在四个需要组合多个离散子任务的任务上进行测试。结果显示，这些模型在组合学习上高度样本效率低下：LLaMA 需要比从零重新学习所有子任务更多的样本，而提示方法不可靠，常在多轮代码生成中失败执行子任务或修正错误。基于复杂性理论，该研究进一步通过理论分析支持了 gradient descent 在记忆前馈模型时的样本低效问题，并开源了代码以促进进一步研究。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2402.05785v5",
      "published_date": "2024-02-08 16:23:29 UTC",
      "updated_date": "2024-11-05 06:32:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T04:36:24.831995"
    },
    {
      "arxiv_id": "2402.05782v1",
      "title": "Analysing the Sample Complexity of Opponent Shaping",
      "title_zh": "分析对手塑造的样本复杂度",
      "authors": [
        "Kitty Fung",
        "Qizhen Zhang",
        "Chris Lu",
        "Jia Wan",
        "Timon Willi",
        "Jakob Foerster"
      ],
      "abstract": "Learning in general-sum games often yields collectively sub-optimal results.\nAddressing this, opponent shaping (OS) methods actively guide the learning\nprocesses of other agents, empirically leading to improved individual and group\nperformances in many settings. Early OS methods use higher-order derivatives to\nshape the learning of co-players, making them unsuitable for shaping multiple\nlearning steps. Follow-up work, Model-free Opponent Shaping (M-FOS), addresses\nthese by reframing the OS problem as a meta-game. In contrast to early OS\nmethods, there is little theoretical understanding of the M-FOS framework.\nProviding theoretical guarantees for M-FOS is hard because A) there is little\nliterature on theoretical sample complexity bounds for meta-reinforcement\nlearning B) M-FOS operates in continuous state and action spaces, so\ntheoretical analysis is challenging. In this work, we present R-FOS, a tabular\nversion of M-FOS that is more suitable for theoretical analysis. R-FOS\ndiscretises the continuous meta-game MDP into a tabular MDP. Within this\ndiscretised MDP, we adapt the $R_{max}$ algorithm, most prominently used to\nderive PAC-bounds for MDPs, as the meta-learner in the R-FOS algorithm. We\nderive a sample complexity bound that is exponential in the cardinality of the\ninner state and action space and the number of agents. Our bound guarantees\nthat, with high probability, the final policy learned by an R-FOS agent is\nclose to the optimal policy, apart from a constant factor. Finally, we\ninvestigate how R-FOS's sample complexity scales in the size of state-action\nspace. Our theoretical results on scaling are supported empirically in the\nMatching Pennies environment.",
      "tldr_zh": "本研究分析了 Opponent Shaping (OS) 在 general-sum games 中的样本复杂度问题，旨在解决传统 OS 方法（如使用高阶导数的早期版本）在处理多个学习步骤时的局限性，以及 Model-free Opponent Shaping (M-FOS) 缺乏理论基础的问题。作者提出 R-FOS，一种表格化的 M-FOS 版本，将连续 meta-game MDP 离散化为表格 MDP，并使用 $R_{max}$ 算法作为 meta-learner，以便进行理论分析。研究导出了样本复杂度边界，该边界与内部状态、动作空间和代理数量呈指数关系，并保证最终策略接近最优策略；同时，通过 Matching Pennies 环境进行实证验证，证实了样本复杂度的实际scaling行为。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.GT",
        "cs.MA"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.05782v1",
      "published_date": "2024-02-08 16:17:18 UTC",
      "updated_date": "2024-02-08 16:17:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T04:36:36.788801"
    },
    {
      "arxiv_id": "2402.05774v1",
      "title": "Stable Autonomous Flow Matching",
      "title_zh": "翻译失败",
      "authors": [
        "Christopher Iliffe Sprague",
        "Arne Elofsson",
        "Hossein Azizpour"
      ],
      "abstract": "In contexts where data samples represent a physically stable state, it is\noften assumed that the data points represent the local minima of an energy\nlandscape. In control theory, it is well-known that energy can serve as an\neffective Lyapunov function. Despite this, connections between control theory\nand generative models in the literature are sparse, even though there are\nseveral machine learning applications with physically stable data points. In\nthis paper, we focus on such data and a recent class of deep generative models\ncalled flow matching. We apply tools of stochastic stability for\ntime-independent systems to flow matching models. In doing so, we characterize\nthe space of flow matching models that are amenable to this treatment, as well\nas draw connections to other control theory principles. We demonstrate our\ntheoretical results on two examples.",
      "tldr_zh": "这篇论文探讨了物理稳定数据点（如能量景观局部最小值）在生成模型中的应用，特别将控制理论中的Lyapunov函数概念引入flow matching模型，以分析时间无关系统的随机稳定性。研究表征了适合这种处理的flow matching模型空间，并与控制理论的其他原则建立了联系。最终，通过两个例子演示了理论结果的实际有效性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.LG",
      "comment": "In submission",
      "pdf_url": "http://arxiv.org/pdf/2402.05774v1",
      "published_date": "2024-02-08 16:01:24 UTC",
      "updated_date": "2024-02-08 16:01:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T04:36:48.498682"
    },
    {
      "arxiv_id": "2402.07939v5",
      "title": "UFO: A UI-Focused Agent for Windows OS Interaction",
      "title_zh": "翻译失败",
      "authors": [
        "Chaoyun Zhang",
        "Liqun Li",
        "Shilin He",
        "Xu Zhang",
        "Bo Qiao",
        "Si Qin",
        "Minghua Ma",
        "Yu Kang",
        "Qingwei Lin",
        "Saravan Rajmohan",
        "Dongmei Zhang",
        "Qi Zhang"
      ],
      "abstract": "We introduce UFO, an innovative UI-Focused agent to fulfill user requests\ntailored to applications on Windows OS, harnessing the capabilities of\nGPT-Vision. UFO employs a dual-agent framework to meticulously observe and\nanalyze the graphical user interface (GUI) and control information of Windows\napplications. This enables the agent to seamlessly navigate and operate within\nindividual applications and across them to fulfill user requests, even when\nspanning multiple applications. The framework incorporates a control\ninteraction module, facilitating action grounding without human intervention\nand enabling fully automated execution. Consequently, UFO transforms arduous\nand time-consuming processes into simple tasks achievable solely through\nnatural language commands. We conducted testing of UFO across 9 popular Windows\napplications, encompassing a variety of scenarios reflective of users' daily\nusage. The results, derived from both quantitative metrics and real-case\nstudies, underscore the superior effectiveness of UFO in fulfilling user\nrequests. To the best of our knowledge, UFO stands as the first UI agent\nspecifically tailored for task completion within the Windows OS environment.\nThe open-source code for UFO is available on https://github.com/microsoft/UFO.",
      "tldr_zh": "本研究引入了UFO，一种专注于UI的代理，用于处理Windows OS应用的用户请求，利用GPT-Vision的能力。UFO采用双代理框架，观察和分析图形用户界面(GUI)及控制信息，实现跨应用导航和自动化操作，从而通过自然语言命令简化复杂任务。实验在9个热门Windows应用上进行，结果显示UFO在定量指标和实际案例中表现出色，是首个专门针对Windows OS环境的UI代理。该框架的开源代码已在GitHub上发布。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.07939v5",
      "published_date": "2024-02-08 15:40:35 UTC",
      "updated_date": "2024-05-23 05:18:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T04:36:59.177811"
    },
    {
      "arxiv_id": "2402.05749v2",
      "title": "Generalized Preference Optimization: A Unified Approach to Offline Alignment",
      "title_zh": "翻译失败",
      "authors": [
        "Yunhao Tang",
        "Zhaohan Daniel Guo",
        "Zeyu Zheng",
        "Daniele Calandriello",
        "Rémi Munos",
        "Mark Rowland",
        "Pierre Harvey Richemond",
        "Michal Valko",
        "Bernardo Ávila Pires",
        "Bilal Piot"
      ],
      "abstract": "Offline preference optimization allows fine-tuning large models directly from\noffline data, and has proved effective in recent alignment practices. We\npropose generalized preference optimization (GPO), a family of offline losses\nparameterized by a general class of convex functions. GPO enables a unified\nview over preference optimization, encompassing existing algorithms such as\nDPO, IPO and SLiC as special cases, while naturally introducing new variants.\nThe GPO framework also sheds light on how offline algorithms enforce\nregularization, through the design of the convex function that defines the\nloss. Our analysis and experiments reveal the connections and subtle\ndifferences between the offline regularization and the KL divergence\nregularization intended by the canonical RLHF formulation. In a controlled\nsetting akin to Gao et al 2023, we also show that different GPO variants\nachieve similar trade-offs between regularization and performance, though the\noptimal values of hyper-parameter might differ as predicted by theory. In all,\nour results present new algorithmic toolkits and empirical insights to\nalignment practitioners.",
      "tldr_zh": "本论文提出 Generalized Preference Optimization (GPO)，一种统一的离线偏好优化方法，用于直接从离线数据微调大型模型，从而提升模型对齐效果。GPO 通过一类凸函数参数化，将现有算法如 DPO、IPO 和 SLiC 作为特例，并自然引入新变体，同时揭示了离线算法如何通过凸函数设计强制正则化，并与 RLHF 中的 KL divergence 正则化进行比较。实验结果显示，不同 GPO 变体在正则化和性能之间实现了类似权衡，尽管最优超参数可能因理论预测而有所差异，为对齐实践提供了新算法工具和经验见解。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at ICML 2023 main conference",
      "pdf_url": "http://arxiv.org/pdf/2402.05749v2",
      "published_date": "2024-02-08 15:33:09 UTC",
      "updated_date": "2024-05-28 23:25:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T04:37:13.018930"
    },
    {
      "arxiv_id": "2402.05747v1",
      "title": "Jacquard V2: Refining Datasets using the Human In the Loop Data Correction Method",
      "title_zh": "翻译失败",
      "authors": [
        "Qiuhao Li",
        "Shenghai Yuan"
      ],
      "abstract": "In the context of rapid advancements in industrial automation, vision-based\nrobotic grasping plays an increasingly crucial role. In order to enhance visual\nrecognition accuracy, the utilization of large-scale datasets is imperative for\ntraining models to acquire implicit knowledge related to the handling of\nvarious objects. Creating datasets from scratch is a time and labor-intensive\nprocess. Moreover, existing datasets often contain errors due to automated\nannotations aimed at expediency, making the improvement of these datasets a\nsubstantial research challenge. Consequently, several issues have been\nidentified in the annotation of grasp bounding boxes within the popular\nJacquard Grasp. We propose utilizing a Human-In-The-Loop(HIL) method to enhance\ndataset quality. This approach relies on backbone deep learning networks to\npredict object positions and orientations for robotic grasping. Predictions\nwith Intersection over Union (IOU) values below 0.2 undergo an assessment by\nhuman operators. After their evaluation, the data is categorized into False\nNegatives(FN) and True Negatives(TN). FN are then subcategorized into either\nmissing annotations or catastrophic labeling errors. Images lacking labels are\naugmented with valid grasp bounding box information, whereas images afflicted\nby catastrophic labeling errors are completely removed. The open-source tool\nLabelbee was employed for 53,026 iterations of HIL dataset enhancement, leading\nto the removal of 2,884 images and the incorporation of ground truth\ninformation for 30,292 images. The enhanced dataset, named the Jacquard V2\nGrasping Dataset, served as the training data for a range of neural networks.",
      "tldr_zh": "这篇论文针对视觉机器人抓取数据集中的标注错误（如在 Jacquard Grasp 中），提出使用 Human-In-The-Loop (HIL) 方法来改进数据集质量。该方法利用深度学习网络预测对象位置和方向，对 Intersection over Union (IOU) 值低于 0.2 的预测进行人工评估，将数据分类为 False Negatives (FN) 和 True Negatives (TN)，并针对 FN 进行处理（如添加 grasp bounding box 或移除图像）。通过开源工具 Labelbee 进行了 53,026 次迭代，移除 2,884 图像并为 30,292 图像添加 ground truth 信息，最终创建了 Jacquard V2 Grasping Dataset，用于训练神经网络以提升视觉识别准确性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.05747v1",
      "published_date": "2024-02-08 15:32:22 UTC",
      "updated_date": "2024-02-08 15:32:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T04:37:25.874935"
    },
    {
      "arxiv_id": "2402.05741v2",
      "title": "Real-World Robot Applications of Foundation Models: A Review",
      "title_zh": "翻译失败",
      "authors": [
        "Kento Kawaharazuka",
        "Tatsuya Matsushima",
        "Andrew Gambardella",
        "Jiaxian Guo",
        "Chris Paxton",
        "Andy Zeng"
      ],
      "abstract": "Recent developments in foundation models, like Large Language Models (LLMs)\nand Vision-Language Models (VLMs), trained on extensive data, facilitate\nflexible application across different tasks and modalities. Their impact spans\nvarious fields, including healthcare, education, and robotics. This paper\nprovides an overview of the practical application of foundation models in\nreal-world robotics, with a primary emphasis on the replacement of specific\ncomponents within existing robot systems. The summary encompasses the\nperspective of input-output relationships in foundation models, as well as\ntheir role in perception, motion planning, and control within the field of\nrobotics. This paper concludes with a discussion of future challenges and\nimplications for practical robot applications.",
      "tldr_zh": "这篇论文对基础模型（如Large Language Models (LLMs)和Vision-Language Models (VLMs)）在真实世界机器人应用中的实际使用进行了综述，强调这些模型如何灵活替换现有机器人系统中的特定组件。论文从输入-输出关系入手，探讨了基础模型在机器人感知、运动规划和控制方面的作用。最终，论文总结了未来挑战，并讨论了这些模型对机器人实践的潜在影响。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.05741v2",
      "published_date": "2024-02-08 15:19:50 UTC",
      "updated_date": "2024-10-23 03:39:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T04:37:36.386899"
    },
    {
      "arxiv_id": "2402.05724v2",
      "title": "Model-Based RL for Mean-Field Games is not Statistically Harder than Single-Agent RL",
      "title_zh": "翻译失败",
      "authors": [
        "Jiawei Huang",
        "Niao He",
        "Andreas Krause"
      ],
      "abstract": "We study the sample complexity of reinforcement learning (RL) in Mean-Field\nGames (MFGs) with model-based function approximation that requires strategic\nexploration to find a Nash Equilibrium policy. We introduce the Partial\nModel-Based Eluder Dimension (P-MBED), a more effective notion to characterize\nthe model class complexity. Notably, P-MBED measures the complexity of the\nsingle-agent model class converted from the given mean-field model class, and\npotentially, can be exponentially lower than the MBED proposed by\n\\citet{huang2023statistical}. We contribute a model elimination algorithm\nfeaturing a novel exploration strategy and establish sample complexity results\npolynomial w.r.t.~P-MBED. Crucially, our results reveal that, under the basic\nrealizability and Lipschitz continuity assumptions, \\emph{learning Nash\nEquilibrium in MFGs is no more statistically challenging than solving a\nlogarithmic number of single-agent RL problems}. We further extend our results\nto Multi-Type MFGs, generalizing from conventional MFGs and involving multiple\ntypes of agents. This extension implies statistical tractability of a broader\nclass of Markov Games through the efficacy of mean-field approximation.\nFinally, inspired by our theoretical algorithm, we present a heuristic approach\nwith improved computational efficiency and empirically demonstrate its\neffectiveness.",
      "tldr_zh": "该研究探讨了基于模型的强化学习 (RL) 在 Mean-Field Games (MFGs) 中的样本复杂度，强调通过战略探索找到 Nash Equilibrium 策略并非比单智能体 RL 更具统计挑战。论文引入 Partial Model-Based Eluder Dimension (P-MBED) 作为一种更有效的模型复杂度度量，可能远低于现有方法，并提出一个结合新型探索策略的模型消除算法，实现与 P-MBED 多项式的样本复杂度结果。在可实现性和 Lipschitz 连续性假设下，学习 MFGs 中的 Nash Equilibrium 仅相当于解决对数数量的单智能体 RL 问题。该工作进一步扩展到 Multi-Type MFGs，并通过一个计算高效的启发式方法验证其有效性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.GT",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "ICML 2024; 55 Pages",
      "pdf_url": "http://arxiv.org/pdf/2402.05724v2",
      "published_date": "2024-02-08 14:54:47 UTC",
      "updated_date": "2024-06-03 15:29:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T04:37:48.908626"
    },
    {
      "arxiv_id": "2402.05713v3",
      "title": "Hidden in Plain Sight: Undetectable Adversarial Bias Attacks on Vulnerable Patient Populations",
      "title_zh": "翻译失败",
      "authors": [
        "Pranav Kulkarni",
        "Andrew Chan",
        "Nithya Navarathna",
        "Skylar Chan",
        "Paul H. Yi",
        "Vishwa S. Parekh"
      ],
      "abstract": "The proliferation of artificial intelligence (AI) in radiology has shed light\non the risk of deep learning (DL) models exacerbating clinical biases towards\nvulnerable patient populations. While prior literature has focused on\nquantifying biases exhibited by trained DL models, demographically targeted\nadversarial bias attacks on DL models and its implication in the clinical\nenvironment remains an underexplored field of research in medical imaging. In\nthis work, we demonstrate that demographically targeted label poisoning attacks\ncan introduce undetectable underdiagnosis bias in DL models. Our results across\nmultiple performance metrics and demographic groups like sex, age, and their\nintersectional subgroups show that adversarial bias attacks demonstrate\nhigh-selectivity for bias in the targeted group by degrading group model\nperformance without impacting overall model performance. Furthermore, our\nresults indicate that adversarial bias attacks result in biased DL models that\npropagate prediction bias even when evaluated with external datasets.",
      "tldr_zh": "这篇论文揭示了在放射学中，deep learning (DL) 模型可能通过对抗性偏见攻击加剧对弱势患者群体的临床偏见。研究者展示了demographically targeted label poisoning attacks 能引入不可检测的漏诊偏见，从而选择性地降低目标群体（如性别、年龄及其交叉子群体）的模型性能，而不影响整体模型表现。实验结果进一步证明，这种攻击导致的偏见模型在外部数据集评估中仍会传播预测偏见，为医疗AI的风险管理提供了重要警示。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "29 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2402.05713v3",
      "published_date": "2024-02-08 14:40:32 UTC",
      "updated_date": "2024-04-07 16:59:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T04:38:00.119252"
    },
    {
      "arxiv_id": "2402.05712v1",
      "title": "DiffSpeaker: Speech-Driven 3D Facial Animation with Diffusion Transformer",
      "title_zh": "翻译失败",
      "authors": [
        "Zhiyuan Ma",
        "Xiangyu Zhu",
        "Guojun Qi",
        "Chen Qian",
        "Zhaoxiang Zhang",
        "Zhen Lei"
      ],
      "abstract": "Speech-driven 3D facial animation is important for many multimedia\napplications. Recent work has shown promise in using either Diffusion models or\nTransformer architectures for this task. However, their mere aggregation does\nnot lead to improved performance. We suspect this is due to a shortage of\npaired audio-4D data, which is crucial for the Transformer to effectively\nperform as a denoiser within the Diffusion framework. To tackle this issue, we\npresent DiffSpeaker, a Transformer-based network equipped with novel biased\nconditional attention modules. These modules serve as substitutes for the\ntraditional self/cross-attention in standard Transformers, incorporating\nthoughtfully designed biases that steer the attention mechanisms to concentrate\non both the relevant task-specific and diffusion-related conditions. We also\nexplore the trade-off between accurate lip synchronization and non-verbal\nfacial expressions within the Diffusion paradigm. Experiments show our model\nnot only achieves state-of-the-art performance on existing benchmarks, but also\nfast inference speed owing to its ability to generate facial motions in\nparallel.",
      "tldr_zh": "论文提出了DiffSpeaker，一种基于Diffusion Transformer的语音驱动3D面部动画模型，旨在解决现有方法在数据短缺和性能优化方面的挑战。该模型引入了新型偏置条件注意力模块，作为传统自/交叉注意力的替代，以引导注意力机制专注于任务特定和扩散相关的条件，同时探索唇同步与非语言表情的权衡。实验结果表明，DiffSpeaker在现有基准上实现了最先进性能，并通过并行生成面部动作实现了快速推理速度。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "9 pages, 5 figures. Code is avalable at\n  https://github.com/theEricMa/DiffSpeaker",
      "pdf_url": "http://arxiv.org/pdf/2402.05712v1",
      "published_date": "2024-02-08 14:39:16 UTC",
      "updated_date": "2024-02-08 14:39:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T04:38:11.414864"
    },
    {
      "arxiv_id": "2402.05703v1",
      "title": "Offline Risk-sensitive RL with Partial Observability to Enhance Performance in Human-Robot Teaming",
      "title_zh": "翻译失败",
      "authors": [
        "Giorgio Angelotti",
        "Caroline P. C. Chanel",
        "Adam H. M. Pinto",
        "Christophe Lounis",
        "Corentin Chauffaut",
        "Nicolas Drougard"
      ],
      "abstract": "The integration of physiological computing into mixed-initiative human-robot\ninteraction systems offers valuable advantages in autonomous task allocation by\nincorporating real-time features as human state observations into the\ndecision-making system. This approach may alleviate the cognitive load on human\noperators by intelligently allocating mission tasks between agents.\nNevertheless, accommodating a diverse pool of human participants with varying\nphysiological and behavioral measurements presents a substantial challenge. To\naddress this, resorting to a probabilistic framework becomes necessary, given\nthe inherent uncertainty and partial observability on the human's state. Recent\nresearch suggests to learn a Partially Observable Markov Decision Process\n(POMDP) model from a data set of previously collected experiences that can be\nsolved using Offline Reinforcement Learning (ORL) methods. In the present work,\nwe not only highlight the potential of partially observable representations and\nphysiological measurements to improve human operator state estimation and\nperformance, but also enhance the overall mission effectiveness of a\nhuman-robot team. Importantly, as the fixed data set may not contain enough\ninformation to fully represent complex stochastic processes, we propose a\nmethod to incorporate model uncertainty, thus enabling risk-sensitive\nsequential decision-making. Experiments were conducted with a group of\ntwenty-six human participants within a simulated robot teleoperation\nenvironment, yielding empirical evidence of the method's efficacy. The obtained\nadaptive task allocation policy led to statistically significant higher scores\nthan the one that was used to collect the data set, allowing for generalization\nacross diverse participants also taking into account risk-sensitive metrics.",
      "tldr_zh": "这篇论文探讨了在人机团队中，通过整合生理计算来优化自主任务分配，从而减轻人类操作员的认知负担，并处理人类状态的不确定性和部分可观察性。为此，研究提出使用 Partially Observable Markov Decision Process (POMDP) 模型结合 Offline Reinforcement Learning (ORL) 从现有数据集中学习，并引入模型不确定性以支持风险敏感决策。实验在模拟机器人遥操作环境中涉及26名参与者，结果显示，该自适应任务分配策略比原有策略在性能指标上显著提升，并实现了对不同参与者的泛化。总的来说，该方法增强了人机团队的整体有效性，为风险敏感的交互系统提供了新途径。",
      "categories": [
        "cs.MA",
        "cs.AI",
        "cs.HC",
        "cs.LG",
        "cs.RO"
      ],
      "primary_category": "cs.MA",
      "comment": "Accepted as a full paper at AAMAS 2024",
      "pdf_url": "http://arxiv.org/pdf/2402.05703v1",
      "published_date": "2024-02-08 14:27:34 UTC",
      "updated_date": "2024-02-08 14:27:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T04:38:24.646875"
    },
    {
      "arxiv_id": "2402.05699v3",
      "title": "Self-Alignment of Large Language Models via Monopolylogue-based Social Scene Simulation",
      "title_zh": "翻译失败",
      "authors": [
        "Xianghe Pang",
        "Shuo Tang",
        "Rui Ye",
        "Yuxin Xiong",
        "Bolun Zhang",
        "Yanfeng Wang",
        "Siheng Chen"
      ],
      "abstract": "Aligning large language models (LLMs) with human values is imperative to\nmitigate potential adverse effects resulting from their misuse. Drawing from\nthe sociological insight that acknowledging all parties' concerns is a key\nfactor in shaping human values, this paper proposes a novel direction to align\nLLMs by themselves: social scene simulation. To achieve this, we present\nMATRIX, a novel social scene simulator that emulates realistic scenes around a\nuser's input query, enabling the LLM to take social consequences into account\nbefore responding. MATRIX serves as a virtual rehearsal space, akin to a\nMonopolylogue, where the LLM performs diverse roles related to the query and\npractice by itself. To inject this alignment, we fine-tune the LLM with\nMATRIX-simulated data, ensuring adherence to human values without compromising\ninference speed. We theoretically show that the LLM with MATRIX outperforms\nConstitutional AI under mild assumptions. Finally, extensive experiments\nvalidate that our method outperforms over 10 baselines across 4 benchmarks. As\nevidenced by 875 user ratings, our tuned 13B-size LLM exceeds GPT-4 in aligning\nwith human values. See our project page at\nhttps://shuotang123.github.io/MATRIX.",
      "tldr_zh": "该论文提出一种新型方法，通过基于Monopolylogue的社会场景模拟，实现大型语言模型(LLMs)的自我对齐，以确保其符合人类价值观。作者引入了MATRIX模拟器，该工具能模拟用户查询周围的现实场景，让LLMs在响应前考虑社会后果，并通过扮演多种角色进行虚拟排练。论文通过用MATRIX生成的数据微调LLMs，既提升了模型对人类价值观的遵守，又保持了推理速度。理论分析显示，这种方法在温和假设下优于Constitutional AI。实验结果表明，该方法在4个基准测试中超越了10个基线模型，且一个13B规模的调优LLMs在875个用户评分中超过了GPT-4。更多细节见项目页面https://shuotang123.github.io/MATRIX。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.CL",
      "comment": "32 pages, 9 figures",
      "pdf_url": "http://arxiv.org/pdf/2402.05699v3",
      "published_date": "2024-02-08 14:21:03 UTC",
      "updated_date": "2024-06-08 06:13:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T04:38:36.338918"
    },
    {
      "arxiv_id": "2402.05680v3",
      "title": "Interpretable classifiers for tabular data via discretization and feature selection",
      "title_zh": "翻译失败",
      "authors": [
        "Reijo Jaakkola",
        "Tomi Janhunen",
        "Antti Kuusisto",
        "Masood Feyzbakhsh Rankooh",
        "Miikka Vilander"
      ],
      "abstract": "We introduce a method for computing immediately human interpretable yet\naccurate classifiers from tabular data. The classifiers obtained are short\nBoolean formulas, computed via first discretizing the original data and then\nusing feature selection coupled with a very fast algorithm for producing the\nbest possible Boolean classifier for the setting. We demonstrate the approach\nvia 12 experiments, obtaining results with accuracies comparable to ones\nobtained via random forests, XGBoost, and existing results for the same\ndatasets in the literature. In most cases, the accuracy of our method is in\nfact similar to that of the reference methods, even though the main objective\nof our study is the immediate interpretability of our classifiers. We also\nprove a new result on the probability that the classifier we obtain from\nreal-life data corresponds to the ideally best classifier with respect to the\nbackground distribution the data comes from.",
      "tldr_zh": "本研究提出了一种通过离散化(discretization)和特征选择(feature selection)从表格数据中生成易于人类解释的分类器方法，这些分类器表现为简短的布尔公式(Boolean formulas)。该方法首先对数据进行离散化，然后结合特征选择和一个快速算法来构建最佳布尔分类器。实验在12个数据集上显示，该方法的准确率与随机森林(random forests)和XGBoost相当，甚至在许多情况下与之类似，尽管其主要目标是提升解释性。该研究还证明了一个新结果，即从真实数据中获得的分类器对应于背景分布的最佳分类器的概率。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.LO",
        "I.2.6; F.4.1; I.2.4; E.2"
      ],
      "primary_category": "cs.LG",
      "comment": "Preprint of a paper in DAO-XAI 2024 (Data meets Applied Ontologies in\n  Explainable AI)",
      "pdf_url": "http://arxiv.org/pdf/2402.05680v3",
      "published_date": "2024-02-08 13:58:16 UTC",
      "updated_date": "2024-09-18 11:43:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T04:38:48.024258"
    },
    {
      "arxiv_id": "2402.14582v1",
      "title": "Enhancement of High-definition Map Update Service Through Coverage-aware and Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Jeffrey Redondo",
        "Zhenhui Yuan",
        "Nauman Aslam"
      ],
      "abstract": "High-definition (HD) Map systems will play a pivotal role in advancing\nautonomous driving to a higher level, thanks to the significant improvement\nover traditional two-dimensional (2D) maps. Creating an HD Map requires a huge\namount of on-road and off-road data. Typically, these raw datasets are\ncollected and uploaded to cloud-based HD map service providers through\nvehicular networks. Nevertheless, there are challenges in transmitting the raw\ndata over vehicular wireless channels due to the dynamic topology. As the\nnumber of vehicles increases, there is a detrimental impact on service quality,\nwhich acts as a barrier to a real-time HD Map system for collaborative driving\nin Autonomous Vehicles (AV). In this paper, to overcome network congestion, a\nQ-learning coverage-time-awareness algorithm is presented to optimize the\nquality of service for vehicular networks and HD map updates. The algorithm is\nevaluated in an environment that imitates a dynamic scenario where vehicles\nenter and leave. Results showed an improvement in latency for HD map data of\n$75\\%$, $73\\%$, and $10\\%$ compared with IEEE802.11p without Quality of Service\n(QoS), IEEE802.11 with QoS, and IEEE802.11p with new access category (AC) for\nHD map, respectively.",
      "tldr_zh": "该论文针对高精度地图（HD Map）在自动驾驶中的关键作用，提出了一种基于 Q-learning 的覆盖感知算法，以优化车辆网络中的数据传输并缓解网络拥塞问题。该算法考虑动态车辆场景，通过强化学习（Reinforcement Learning）提升服务质量，确保实时 HD Map 更新。实验结果显示，与 IEEE802.11p 无 QoS、IEEE802.11 有 QoS 以及 IEEE802.11p 新访问类别相比，HD Map 数据的延迟分别降低了 75%、73% 和 10%。这为高效的协作驾驶系统提供了重要改进。",
      "categories": [
        "cs.NI",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.NI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.14582v1",
      "published_date": "2024-02-08 13:51:13 UTC",
      "updated_date": "2024-02-08 13:51:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T04:38:59.513795"
    },
    {
      "arxiv_id": "2402.05668v2",
      "title": "Comprehensive Assessment of Jailbreak Attacks Against LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Junjie Chu",
        "Yugeng Liu",
        "Ziqing Yang",
        "Xinyue Shen",
        "Michael Backes",
        "Yang Zhang"
      ],
      "abstract": "Jailbreak attacks aim to bypass the safeguards of LLMs. While researchers\nhave studied different jailbreak attacks in depth, they have done so in\nisolation -- either with unaligned experiment settings or comparing a limited\nrange of methods. To fill this gap, we present the first large-scale\nmeasurement of various jailbreak attack methods. We collect 17 cutting-edge\njailbreak methods, summarize their features, and establish a novel jailbreak\nattack taxonomy. Based on eight popular censored LLMs and 160 questions from 16\nviolation categories, we conduct a unified and impartial assessment of attack\neffectiveness as well as a comprehensive ablation study. Our extensive\nexperimental results demonstrate that all the jailbreak attacks have a powerful\neffect on the LLMs. This indicates that all LLMs fail to cover all the\nviolation categories, and they are susceptible to significant jailbreak risks,\nwith even the well-aligned Llama3 facing a maximum attack success rate of 0.88.\nAdditionally, we test jailbreak attacks under eight advanced external defenses\nand find none of the defenses could mitigate the jailbreak attacks entirely.\nOur study offers valuable insights for future research on jailbreak attacks and\ndefenses and serves as a benchmark tool for researchers and practitioners to\nevaluate them effectively.",
      "tldr_zh": "该研究对针对大型语言模型（LLMs）的jailbreak attacks进行了首次大规模评估，收集了17种前沿攻击方法并建立了新的jailbreak attack taxonomy。研究者使用8个热门的censored LLMs和来自16个违规类别的160个问题，进行了统一的攻击有效性评估和全面的ablation study。结果显示，所有jailbreak attacks对LLMs都具有强大效果，即使是Llama3这样的模型也面临高达0.88的最大攻击成功率，且8种高级外部防御无法完全缓解这些攻击。该工作为未来jailbreak attacks和防御研究提供了宝贵见解，并作为有效的基准工具。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "22 pages, 11 figures",
      "pdf_url": "http://arxiv.org/pdf/2402.05668v2",
      "published_date": "2024-02-08 13:42:50 UTC",
      "updated_date": "2024-12-16 15:02:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T04:39:11.922774"
    },
    {
      "arxiv_id": "2402.05663v2",
      "title": "Mesoscale Traffic Forecasting for Real-Time Bottleneck and Shockwave Prediction",
      "title_zh": "翻译失败",
      "authors": [
        "Raphael Chekroun",
        "Han Wang",
        "Jonathan Lee",
        "Marin Toromanoff",
        "Sascha Hornauer",
        "Fabien Moutarde",
        "Maria Laura Delle Monache"
      ],
      "abstract": "Accurate real-time traffic state forecasting plays a pivotal role in traffic\ncontrol research. In particular, the CIRCLES consortium project necessitates\npredictive techniques to mitigate the impact of data source delays. After the\nsuccess of the MegaVanderTest experiment, this paper aims at overcoming the\ncurrent system limitations and develop a more suited approach to improve the\nreal-time traffic state estimation for the next iterations of the experiment.\nIn this paper, we introduce the SA-LSTM, a deep forecasting method integrating\nSelf-Attention (SA) on the spatial dimension with Long Short-Term Memory (LSTM)\nyielding state-of-the-art results in real-time mesoscale traffic forecasting.\nWe extend this approach to multi-step forecasting with the n-step SA-LSTM,\nwhich outperforms traditional multi-step forecasting methods in the trade-off\nbetween short-term and long-term predictions, all while operating in real-time.",
      "tldr_zh": "本论文针对实时交通预测中的瓶颈和冲击波问题，引入了 SA-LSTM 模型，该模型将 Self-Attention (SA) 在空间维度上与 Long Short-Term Memory (LSTM) 相结合，实现中尺度交通状态的 state-of-the-art 预测结果。\n为了应对多步预测需求，论文扩展为 n-step SA-LSTM 方法，该方法在短期和长期预测的权衡中优于传统技术，同时确保实时操作。\n这项工作旨在解决 CIRCLES 项目数据源延迟等问题，提升交通控制实验的准确性和适用性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.05663v2",
      "published_date": "2024-02-08 13:27:10 UTC",
      "updated_date": "2024-03-04 12:01:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T04:39:24.339886"
    },
    {
      "arxiv_id": "2402.05660v1",
      "title": "Rethinking Propagation for Unsupervised Graph Domain Adaptation",
      "title_zh": "翻译失败",
      "authors": [
        "Meihan Liu",
        "Zeyu Fang",
        "Zhen Zhang",
        "Ming Gu",
        "Sheng Zhou",
        "Xin Wang",
        "Jiajun Bu"
      ],
      "abstract": "Unsupervised Graph Domain Adaptation (UGDA) aims to transfer knowledge from a\nlabelled source graph to an unlabelled target graph in order to address the\ndistribution shifts between graph domains. Previous works have primarily\nfocused on aligning data from the source and target graph in the representation\nspace learned by graph neural networks (GNNs). However, the inherent\ngeneralization capability of GNNs has been largely overlooked. Motivated by our\nempirical analysis, we reevaluate the role of GNNs in graph domain adaptation\nand uncover the pivotal role of the propagation process in GNNs for adapting to\ndifferent graph domains. We provide a comprehensive theoretical analysis of\nUGDA and derive a generalization bound for multi-layer GNNs. By formulating GNN\nLipschitz for k-layer GNNs, we show that the target risk bound can be tighter\nby removing propagation layers in source graph and stacking multiple\npropagation layers in target graph. Based on the empirical and theoretical\nanalysis mentioned above, we propose a simple yet effective approach called\nA2GNN for graph domain adaptation. Through extensive experiments on real-world\ndatasets, we demonstrate the effectiveness of our proposed A2GNN framework.",
      "tldr_zh": "本研究重新审视了无监督图域适应 (UGDA) 中图神经网络 (GNNs) 的传播过程，强调其在处理源图和目标图分布偏移时的关键作用，而非仅局限于表示空间对齐。论文通过实证分析和理论推导，提供UGDA的泛化边界，并证明通过在源图中移除传播层并在目标图中堆叠多层传播层，可以收紧k层GNNs的目标风险边界，从而优化Lipschitz条件。最终，提出了一种简单有效的A2GNN框架，并在真实世界数据集上进行广泛实验，证明其显著提升了图域适应的性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by AAAI-24",
      "pdf_url": "http://arxiv.org/pdf/2402.05660v1",
      "published_date": "2024-02-08 13:24:57 UTC",
      "updated_date": "2024-02-08 13:24:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T04:39:37.164244"
    },
    {
      "arxiv_id": "2402.05650v3",
      "title": "Rocks Coding, Not Development--A Human-Centric, Experimental Evaluation of LLM-Supported SE Tasks",
      "title_zh": "翻译失败",
      "authors": [
        "Wei Wang",
        "Huilong Ning",
        "Gaowei Zhang",
        "Libo Liu",
        "Yi Wang"
      ],
      "abstract": "Recently, large language models (LLM) based generative AI has been gaining\nmomentum for their impressive high-quality performances in multiple domains,\nparticularly after the release of the ChatGPT. Many believe that they have the\npotential to perform general-purpose problem-solving in software development\nand replace human software developers. Nevertheless, there are in a lack of\nserious investigation into the capability of these LLM techniques in fulfilling\nsoftware development tasks. In a controlled 2 x 2 between-subject experiment\nwith 109 participants, we examined whether and to what degree working with\nChatGPT was helpful in the coding task and typical software development task\nand how people work with ChatGPT. We found that while ChatGPT performed well in\nsolving simple coding problems, its performance in supporting typical software\ndevelopment tasks was not that good. We also observed the interactions between\nparticipants and ChatGPT and found the relations between the interactions and\nthe outcomes. Our study thus provides first-hand insights into using ChatGPT to\nfulfill software engineering tasks with real-world developers and motivates the\nneed for novel interaction mechanisms that help developers effectively work\nwith large language models to achieve desired outcomes.",
      "tldr_zh": "该研究通过一个包含109名参与者的2x2组间实验，评估了大型语言模型(LLM)如ChatGPT在软件工程(SE Tasks)任务中的表现，焦点在于其对编码任务和典型开发任务的支持程度。结果显示，ChatGPT在解决简单编码问题上表现出色，但对复杂软件开发任务的支持有限，且参与者与ChatGPT的互动方式直接影响了任务结果。该研究提供了开发者使用LLM的 firsthand 见解，并强调了开发新型互动机制的必要性，以帮助实现更好的软件工程成果。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "65-XX",
        "D.2; I.2"
      ],
      "primary_category": "cs.SE",
      "comment": "The paper has been accepted by FSE",
      "pdf_url": "http://arxiv.org/pdf/2402.05650v3",
      "published_date": "2024-02-08 13:07:31 UTC",
      "updated_date": "2024-02-21 08:16:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T04:39:47.742530"
    },
    {
      "arxiv_id": "2402.05643v5",
      "title": "Improving Token-Based World Models with Parallel Observation Prediction",
      "title_zh": "通过并行观察预测改进基于标记的世界模型",
      "authors": [
        "Lior Cohen",
        "Kaixin Wang",
        "Bingyi Kang",
        "Shie Mannor"
      ],
      "abstract": "Motivated by the success of Transformers when applied to sequences of\ndiscrete symbols, token-based world models (TBWMs) were recently proposed as\nsample-efficient methods. In TBWMs, the world model consumes agent experience\nas a language-like sequence of tokens, where each observation constitutes a\nsub-sequence. However, during imagination, the sequential token-by-token\ngeneration of next observations results in a severe bottleneck, leading to long\ntraining times, poor GPU utilization, and limited representations. To resolve\nthis bottleneck, we devise a novel Parallel Observation Prediction (POP)\nmechanism. POP augments a Retentive Network (RetNet) with a novel forward mode\ntailored to our reinforcement learning setting. We incorporate POP in a novel\nTBWM agent named REM (Retentive Environment Model), showcasing a 15.4x faster\nimagination compared to prior TBWMs. REM attains superhuman performance on 12\nout of 26 games of the Atari 100K benchmark, while training in less than 12\nhours. Our code is available at \\url{https://github.com/leor-c/REM}.",
      "tldr_zh": "该研究针对Token-Based World Models (TBWMs) 在想象阶段的顺序生成瓶颈问题，提出了Parallel Observation Prediction (POP) 机制，该机制通过修改Retentive Network (RetNet)的forward mode，以并行方式预测观察序列，从而提升训练效率和GPU利用率。作者开发了新代理REM (Retentive Environment Model)，它整合POP后，使想象速度比先前TBWMs快15.4倍，并在Atari 100K基准的26个游戏中，在12个游戏上实现超人性能，同时在不到12小时内完成训练。该方法为基于离散符号的强化学习世界模型提供了更高效的框架，代码已在GitHub开源。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.05643v5",
      "published_date": "2024-02-08 12:58:07 UTC",
      "updated_date": "2024-05-29 07:16:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T04:39:59.842904"
    },
    {
      "arxiv_id": "2402.05636v2",
      "title": "The Impact of AI Tool on Engineering at ANZ Bank An Empirical Study on GitHub Copilot within Corporate Environment",
      "title_zh": "翻译失败",
      "authors": [
        "Sayan Chatterjee",
        "Ching Louis Liu",
        "Gareth Rowland",
        "Tim Hogarth"
      ],
      "abstract": "The increasing popularity of AI, particularly Large Language Models (LLMs),\nhas significantly impacted various domains, including Software Engineering.\nThis study explores the integration of AI tools in software engineering\npractices within a large organization. We focus on ANZ Bank, which employs over\n5000 engineers covering all aspects of the software development life cycle.\nThis paper details an experiment conducted using GitHub Copilot, a notable AI\ntool, within a controlled environment to evaluate its effectiveness in\nreal-world engineering tasks. Additionally, this paper shares initial findings\non the productivity improvements observed after GitHub Copilot was adopted on a\nlarge scale, with about 1000 engineers using it. ANZ Bank's six-week experiment\nwith GitHub Copilot included two weeks of preparation and four weeks of active\ntesting. The study evaluated participant sentiment and the tool's impact on\nproductivity, code quality, and security. Initially, participants used GitHub\nCopilot for proposed use-cases, with their feedback gathered through regular\nsurveys. In the second phase, they were divided into Control and Copilot\ngroups, each tackling the same Python challenges, and their experiences were\nagain surveyed. Results showed a notable boost in productivity and code quality\nwith GitHub Copilot, though its impact on code security remained inconclusive.\nParticipant responses were overall positive, confirming GitHub Copilot's\neffectiveness in large-scale software engineering environments. Early data from\n1000 engineers also indicated a significant increase in productivity and job\nsatisfaction.",
      "tldr_zh": "这篇论文通过实证研究探讨了 AI 工具（特别是 LLMs）在大型企业软件工程中的影响，焦点是 ANZ 银行超过 5000 名工程师使用 GitHub Copilot 的效果。研究采用了六周实验设计，包括准备期和测试期，通过对照组测试和调查评估了生产力、代码质量及安全性的变化。结果显示，GitHub Copilot 显著提升了生产力和代码质量，但对代码安全性的影响尚不确定，且参与者反馈积极，大规模采用后进一步提高了工程师的工作满意度。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "16 pages, 4 figures. in proceeding for 10th International Conference\n  on Software Engineering (SEC 2024)",
      "pdf_url": "http://arxiv.org/pdf/2402.05636v2",
      "published_date": "2024-02-08 12:47:57 UTC",
      "updated_date": "2024-04-17 12:14:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T04:40:12.216772"
    },
    {
      "arxiv_id": "2402.05627v1",
      "title": "Binding Dynamics in Rotating Features",
      "title_zh": "翻译失败",
      "authors": [
        "Sindy Löwe",
        "Francesco Locatello",
        "Max Welling"
      ],
      "abstract": "In human cognition, the binding problem describes the open question of how\nthe brain flexibly integrates diverse information into cohesive object\nrepresentations. Analogously, in machine learning, there is a pursuit for\nmodels capable of strong generalization and reasoning by learning\nobject-centric representations in an unsupervised manner. Drawing from\nneuroscientific theories, Rotating Features learn such representations by\nintroducing vector-valued features that encapsulate object characteristics in\ntheir magnitudes and object affiliation in their orientations. The\n\"$\\chi$-binding\" mechanism, embedded in every layer of the architecture, has\nbeen shown to be crucial, but remains poorly understood. In this paper, we\npropose an alternative \"cosine binding\" mechanism, which explicitly computes\nthe alignment between features and adjusts weights accordingly, and we show\nthat it achieves equivalent performance. This allows us to draw direct\nconnections to self-attention and biological neural processes, and to shed\nlight on the fundamental dynamics for object-centric representations to emerge\nin Rotating Features.",
      "tldr_zh": "该论文探讨了人类认知中的绑定问题（binding problem），即大脑如何整合信息形成物体表示，并将其类比到机器学习中无监督学习物体中心表示（object-centric representations）以提升泛化和推理能力。论文基于 Rotating Features 架构，提出一种新的“cosine binding”机制，通过计算特征之间的对齐并调整权重，作为现有“χ-binding”机制的替代，并实现了相等性能。该机制揭示了 Rotating Features 中物体表示形成的动态，并建立了与自注意力（self-attention）和生物神经过程的直接联系，从而加深了对强健表示学习的理解。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV",
        "q-bio.NC"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.05627v1",
      "published_date": "2024-02-08 12:31:08 UTC",
      "updated_date": "2024-02-08 12:31:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T04:40:24.532341"
    },
    {
      "arxiv_id": "2402.05624v1",
      "title": "Efficient Models for the Detection of Hate, Abuse and Profanity",
      "title_zh": "翻译失败",
      "authors": [
        "Christoph Tillmann",
        "Aashka Trivedi",
        "Bishwaranjan Bhattacharjee"
      ],
      "abstract": "Large Language Models (LLMs) are the cornerstone for many Natural Language\nProcessing (NLP) tasks like sentiment analysis, document classification, named\nentity recognition, question answering, summarization, etc. LLMs are often\ntrained on data which originates from the web. This data is prone to having\ncontent with Hate, Abuse and Profanity (HAP). For a detailed definition of HAP,\nplease refer to the Appendix. Due to the LLMs being exposed to HAP content\nduring training, the models learn it and may then generate hateful or profane\ncontent. For example, when the open-source RoBERTa model (specifically, the\nRoBERTA base model) from the HuggingFace (HF) Transformers library is prompted\nto replace the mask token in `I do not know that Persian people are that MASK`\nit returns the word `stupid` with the highest score. This is unacceptable in\ncivil discourse.The detection of Hate, Abuse and Profanity in text is a vital\ncomponent of creating civil and unbiased LLMs, which is needed not only for\nEnglish, but for all languages. In this article, we briefly describe the\ncreation of HAP detectors and various ways of using them to make models civil\nand acceptable in the output they generate.",
      "tldr_zh": "本研究讨论了大型语言模型 (LLMs) 在训练数据中暴露于仇恨、辱骂和亵渎 (HAP) 内容的问题，导致模型可能生成不当输出，例如 RoBERTa 基线模型在特定提示下返回负面词汇。论文提出高效的 HAP 检测模型，并描述了创建这些检测器的过程及其应用方式，以确保 LLMs 输出更文明和无偏见。最终，该方法不仅适用于英语，还扩展到所有语言，帮助构建可接受的 NLP 系统。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.CL",
      "comment": "8 pages, 7 figures",
      "pdf_url": "http://arxiv.org/pdf/2402.05624v1",
      "published_date": "2024-02-08 12:28:18 UTC",
      "updated_date": "2024-02-08 12:28:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T04:40:36.278266"
    },
    {
      "arxiv_id": "2402.05616v1",
      "title": "Pretrained Generative Language Models as General Learning Frameworks for Sequence-Based Tasks",
      "title_zh": "预训练生成式语言模型作为序列任务的通用学习框架",
      "authors": [
        "Ben Fauber"
      ],
      "abstract": "We propose that small pretrained foundational generative language models with\nmillions of parameters can be utilized as a general learning framework for\nsequence-based tasks. Our proposal overcomes the computational resource, skill\nset, and timeline challenges associated with training neural networks and\nlanguage models from scratch. Further, our approach focuses on creating small\nand highly specialized models that can accurately execute a challenging task of\nwhich the base model is incapable of performing. We demonstrate that 125M,\n350M, and 1.3B parameter pretrained foundational language models can be\ninstruction fine-tuned with 10,000-to-1,000,000 instruction examples to achieve\nnear state-of-the-art results on challenging cheminformatics tasks. We also\ndemonstrate the role of successive language model fine-tuning epochs on\nimproved outcomes, as well as the importance of both data formatting and\npretrained foundational language model selection for instruction fine-tuning\nsuccess.",
      "tldr_zh": "本论文提出使用小型预训练生成语言模型（pretrained generative language models），如参数为125M、350M和1.3B的模型，作为序列任务的一般学习框架，以解决从零训练神经网络的资源、技能和时间挑战。研究通过指令微调（instruction fine-tuned）这些模型，使用10,000至1,000,000个指令示例，使其在化学信息学任务（cheminformatics tasks）上实现接近最先进（state-of-the-art）的结果。论文还强调了连续微调轮次、数据格式和预训练模型选择对提升性能的关键作用。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.05616v1",
      "published_date": "2024-02-08 12:19:32 UTC",
      "updated_date": "2024-02-08 12:19:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T04:40:49.420829"
    },
    {
      "arxiv_id": "2402.05610v2",
      "title": "Extending 6D Object Pose Estimators for Stereo Vision",
      "title_zh": "翻译失败",
      "authors": [
        "Thomas Pöllabauer",
        "Jan Emrich",
        "Volker Knauthe",
        "Arjan Kuijper"
      ],
      "abstract": "Estimating the 6D pose of objects accurately, quickly, and robustly remains a\ndifficult task. However, recent methods for directly regressing poses from RGB\nimages using dense features have achieved state-of-the-art results. Stereo\nvision, which provides an additional perspective on the object, can help reduce\npose ambiguity and occlusion. Moreover, stereo can directly infer the distance\nof an object, while mono-vision requires internalized knowledge of the object's\nsize. To extend the state-of-the-art in 6D object pose estimation to stereo, we\ncreated a BOP compatible stereo version of the YCB-V dataset. Our method\noutperforms state-of-the-art 6D pose estimation algorithms by utilizing stereo\nvision and can easily be adopted for other dense feature-based algorithms.",
      "tldr_zh": "本研究扩展了 6D Object Pose 估计器，将其应用于 Stereo Vision，以提高物体位姿估计的准确性、速度和鲁棒性。论文强调 Stereo Vision 通过提供额外视角减少位姿模糊和遮挡，并直接推断物体距离，而无需依赖单目视觉的内部尺寸知识。为此，研究者创建了 BOP 兼容的立体版本 YCB-V 数据集，并证明其方法在利用密集特征的基础上优于现有算法。整体框架易于扩展到其他基于密集特征的 6D Pose 估计技术。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "4th International Conference on Pattern Recognition and Artificial\n  Intelligence (ICPRAI)",
      "pdf_url": "http://arxiv.org/pdf/2402.05610v2",
      "published_date": "2024-02-08 12:08:52 UTC",
      "updated_date": "2024-09-10 13:51:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T04:41:00.540256"
    },
    {
      "arxiv_id": "2402.05605v2",
      "title": "Optimizing Delegation in Collaborative Human-AI Hybrid Teams",
      "title_zh": "优化合作人类-人工智能混合团队中的委托",
      "authors": [
        "Andrew Fuchs",
        "Andrea Passarella",
        "Marco Conti"
      ],
      "abstract": "When humans and autonomous systems operate together as what we refer to as a\nhybrid team, we of course wish to ensure the team operates successfully and\neffectively. We refer to team members as agents. In our proposed framework, we\naddress the case of hybrid teams in which, at any time, only one team member\n(the control agent) is authorized to act as control for the team. To determine\nthe best selection of a control agent, we propose the addition of an AI manager\n(via Reinforcement Learning) which learns as an outside observer of the team.\nThe manager learns a model of behavior linking observations of agent\nperformance and the environment/world the team is operating in, and from these\nobservations makes the most desirable selection of a control agent. We restrict\nthe manager task by introducing a set of constraints. The manager constraints\nindicate acceptable team operation, so a violation occurs if the team enters a\ncondition which is unacceptable and requires manager intervention. To ensure\nminimal added complexity or potential inefficiency for the team, the manager\nshould attempt to minimize the number of times the team reaches a constraint\nviolation and requires subsequent manager intervention. Therefore our manager\nis optimizing its selection of authorized agents to boost overall team\nperformance while minimizing the frequency of manager intervention. We\ndemonstrate our manager performance in a simulated driving scenario\nrepresenting the case of a hybrid team of agents composed of a human driver and\nautonomous driving system. We perform experiments for our driving scenario with\ninterfering vehicles, indicating the need for collision avoidance and proper\nspeed control. Our results indicate a positive impact of our manager, with some\ncases resulting in increased team performance up to ~187% that of the best solo\nagent performance.",
      "tldr_zh": "本文提出了一种优化混合团队中控制代理委托的框架，旨在提升人类和AI代理的协作性能。该框架引入一个基于Reinforcement Learning的AI经理，作为外部观察者，学习代理行为模型并选择最佳控制代理，同时通过约束条件最小化干预频率，以确保团队高效运作。在模拟驾驶场景中，实验结果显示，该AI经理显著提高了团队性能，在某些情况下比最佳单一代理高出约187%。",
      "categories": [
        "cs.AI",
        "cs.HC",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.05605v2",
      "published_date": "2024-02-08 12:04:43 UTC",
      "updated_date": "2024-08-25 15:28:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T04:41:11.920857"
    },
    {
      "arxiv_id": "2402.05602v2",
      "title": "AttnLRP: Attention-Aware Layer-Wise Relevance Propagation for Transformers",
      "title_zh": "翻译失败",
      "authors": [
        "Reduan Achtibat",
        "Sayed Mohammad Vakilzadeh Hatefi",
        "Maximilian Dreyer",
        "Aakriti Jain",
        "Thomas Wiegand",
        "Sebastian Lapuschkin",
        "Wojciech Samek"
      ],
      "abstract": "Large Language Models are prone to biased predictions and hallucinations,\nunderlining the paramount importance of understanding their model-internal\nreasoning process. However, achieving faithful attributions for the entirety of\na black-box transformer model and maintaining computational efficiency is an\nunsolved challenge. By extending the Layer-wise Relevance Propagation\nattribution method to handle attention layers, we address these challenges\neffectively. While partial solutions exist, our method is the first to\nfaithfully and holistically attribute not only input but also latent\nrepresentations of transformer models with the computational efficiency similar\nto a single backward pass. Through extensive evaluations against existing\nmethods on LLaMa 2, Mixtral 8x7b, Flan-T5 and vision transformer architectures,\nwe demonstrate that our proposed approach surpasses alternative methods in\nterms of faithfulness and enables the understanding of latent representations,\nopening up the door for concept-based explanations. We provide an LRP library\nat https://github.com/rachtibat/LRP-eXplains-Transformers.",
      "tldr_zh": "该研究针对大型语言模型（Large Language Models）的偏见和幻觉问题，提出了一种名为 AttnLRP 的方法，该方法扩展了 Layer-wise Relevance Propagation (LRP) 以处理 Transformer 中的注意力层，从而实现对输入和潜在表示的忠实 attribution。AttnLRP 首次实现了对整个 Transformer 模型的整体 attribution，同时保持与单次反向传播类似的高计算效率。实验结果显示，该方法在 LLaMa 2、Mixtral 8x7b、Flan-T5 和视觉 Transformer 等模型上超过了现有方法，在 faithfulness 方面表现出色，并支持基于概念的解释，提供开源库 https://github.com/rachtibat/LRP-eXplains-Transformers。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.05602v2",
      "published_date": "2024-02-08 12:01:24 UTC",
      "updated_date": "2024-06-10 09:58:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T04:41:24.527128"
    },
    {
      "arxiv_id": "2402.05593v1",
      "title": "A Concept for Reconstructing Stucco Statues from historic Sketches using synthetic Data only",
      "title_zh": "一种从历史草图重建石膏雕像的概念，仅使用合成数据",
      "authors": [
        "Thomas Pöllabauer",
        "Julius Kühn"
      ],
      "abstract": "In medieval times, stuccoworkers used a red color, called sinopia, to first\ncreate a sketch of the to-be-made statue on the wall. Today, many of these\nstatues are destroyed, but using the original drawings, deriving from the red\ncolor also called sinopia, we can reconstruct how the final statue might have\nlooked.We propose a fully-automated approach to reconstruct a point cloud and\nshow preliminary results by generating a color-image, a depth-map, as well as\nsurface normals requiring only a single sketch, and without requiring a\ncollection of other, similar samples. Our proposed solution allows real-time\nreconstruction on-site, for instance, within an exhibition, or to generate a\nuseful starting point for an expert, trying to manually reconstruct the statue,\nall while using only synthetic data for training.",
      "tldr_zh": "这篇论文提出了一种概念，用于从中世纪sinopia草图重建已毁坏的石膏雕像，方法完全自动化且仅依赖合成数据训练，无需收集其他真实样本。研究通过生成点云、彩色图像、深度图和表面法线，实现从单个草图到三维重建的实时处理，例如在展览现场应用。初步结果表明，该方法为专家手动重建提供了一个高效起点，提升了历史文物复原的可行性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.05593v1",
      "published_date": "2024-02-08 11:46:26 UTC",
      "updated_date": "2024-02-08 11:46:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T04:41:36.116052"
    },
    {
      "arxiv_id": "2402.05591v1",
      "title": "SoftEDA: Rethinking Rule-Based Data Augmentation with Soft Labels",
      "title_zh": "翻译失败",
      "authors": [
        "Juhwan Choi",
        "Kyohoon Jin",
        "Junho Lee",
        "Sangmin Song",
        "Youngbin Kim"
      ],
      "abstract": "Rule-based text data augmentation is widely used for NLP tasks due to its\nsimplicity. However, this method can potentially damage the original meaning of\nthe text, ultimately hurting the performance of the model. To overcome this\nlimitation, we propose a straightforward technique for applying soft labels to\naugmented data. We conducted experiments across seven different classification\ntasks and empirically demonstrated the effectiveness of our proposed approach.\nWe have publicly opened our source code for reproducibility.",
      "tldr_zh": "本论文重新审视了基于规则的文本数据增强（Rule-Based Data Augmentation）在NLP任务中的局限性，该方法虽简单但可能破坏原文本含义并影响模型性能。作者提出SoftEDA，一种使用软标签（Soft Labels）的简单技术来增强数据，从而更好地保留文本语义。在七个分类任务上的实验中，证明了SoftEDA的有效性，并公开了源代码以支持复现和进一步研究。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "ICLR 2023 Tiny Papers",
      "pdf_url": "http://arxiv.org/pdf/2402.05591v1",
      "published_date": "2024-02-08 11:44:25 UTC",
      "updated_date": "2024-02-08 11:44:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T04:41:48.396567"
    },
    {
      "arxiv_id": "2402.05584v1",
      "title": "AutoAugment Is What You Need: Enhancing Rule-based Augmentation Methods in Low-resource Regimes",
      "title_zh": "翻译失败",
      "authors": [
        "Juhwan Choi",
        "Kyohoon Jin",
        "Junho Lee",
        "Sangmin Song",
        "Youngbin Kim"
      ],
      "abstract": "Text data augmentation is a complex problem due to the discrete nature of\nsentences. Although rule-based augmentation methods are widely adopted in\nreal-world applications because of their simplicity, they suffer from potential\nsemantic damage. Previous researchers have suggested easy data augmentation\nwith soft labels (softEDA), employing label smoothing to mitigate this problem.\nHowever, finding the best factor for each model and dataset is challenging;\ntherefore, using softEDA in real-world applications is still difficult. In this\npaper, we propose adapting AutoAugment to solve this problem. The experimental\nresults suggest that the proposed method can boost existing augmentation\nmethods and that rule-based methods can enhance cutting-edge pre-trained\nlanguage models. We offer the source code.",
      "tldr_zh": "本论文针对文本数据增强的复杂性，特别是规则-based augmentation 方法可能导致语义损坏的问题，提出了一种适应 AutoAugment 的方法，以自动优化增强策略，从而避免了 softEDA 需手动调整标签平滑因子的挑战。实验结果显示，该方法显著提升了现有增强技术的性能，并能增强先进的预训练语言模型，尤其在低-resource regimes 中表现出色。作者提供了源代码以支持进一步应用和复现。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "EACL 2024 Student Research Workshop",
      "pdf_url": "http://arxiv.org/pdf/2402.05584v1",
      "published_date": "2024-02-08 11:36:23 UTC",
      "updated_date": "2024-02-08 11:36:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T04:42:02.109133"
    },
    {
      "arxiv_id": "2402.05575v1",
      "title": "Simultaneously Achieving Group Exposure Fairness and Within-Group Meritocracy in Stochastic Bandits",
      "title_zh": "翻译失败",
      "authors": [
        "Subham Pokhriyal",
        "Shweta Jain",
        "Ganesh Ghalme",
        "Swapnil Dhamal",
        "Sujit Gujar"
      ],
      "abstract": "Existing approaches to fairness in stochastic multi-armed bandits (MAB)\nprimarily focus on exposure guarantee to individual arms. When arms are\nnaturally grouped by certain attribute(s), we propose Bi-Level Fairness, which\nconsiders two levels of fairness. At the first level, Bi-Level Fairness\nguarantees a certain minimum exposure to each group. To address the unbalanced\nallocation of pulls to individual arms within a group, we consider meritocratic\nfairness at the second level, which ensures that each arm is pulled according\nto its merit within the group. Our work shows that we can adapt a UCB-based\nalgorithm to achieve a Bi-Level Fairness by providing (i) anytime Group\nExposure Fairness guarantees and (ii) ensuring individual-level Meritocratic\nFairness within each group. We first show that one can decompose regret bounds\ninto two components: (a) regret due to anytime group exposure fairness and (b)\nregret due to meritocratic fairness within each group. Our proposed algorithm\nBF-UCB balances these two regrets optimally to achieve the upper bound of\n$O(\\sqrt{T})$ on regret; $T$ being the stopping time. With the help of\nsimulated experiments, we further show that BF-UCB achieves sub-linear regret;\nprovides better group and individual exposure guarantees compared to existing\nalgorithms; and does not result in a significant drop in reward with respect to\nUCB algorithm, which does not impose any fairness constraint.",
      "tldr_zh": "该论文在随机多臂老虎机 (MAB) 中提出 Bi-Level Fairness 框架，以同时实现群组曝光公平性和群组内 meritocratic 公平性，前者确保每个群组获得最低曝光量，后者根据臂的价值在群组内分配拉动机会。作者改进了 UCB 算法，开发了 BF-UCB 方法，通过分解 regret 边界（包括群组曝光公平性和群组内公平性造成的 regret）来平衡这两层公平性，并证明其 regret 上限为 O(√T)。实验结果表明，BF-UCB 实现了次线性 regret，提供比现有算法更好的群组和个体曝光保证，同时不会显著降低相对于无公平约束的 UCB 算法的奖励。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CY",
        "cs.MA"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted in AAMAS 2024",
      "pdf_url": "http://arxiv.org/pdf/2402.05575v1",
      "published_date": "2024-02-08 11:19:58 UTC",
      "updated_date": "2024-02-08 11:19:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T04:42:13.991993"
    },
    {
      "arxiv_id": "2402.05569v6",
      "title": "Training-Free Message Passing for Learning on Hypergraphs",
      "title_zh": "翻译失败",
      "authors": [
        "Bohan Tang",
        "Zexi Liu",
        "Keyue Jiang",
        "Siheng Chen",
        "Xiaowen Dong"
      ],
      "abstract": "Hypergraphs are crucial for modelling higher-order interactions in real-world\ndata. Hypergraph neural networks (HNNs) effectively utilise these structures by\nmessage passing to generate informative node features for various downstream\ntasks like node classification. However, the message passing module in existing\nHNNs typically requires a computationally intensive training process, which\nlimits their practical use. To tackle this challenge, we propose an alternative\napproach by decoupling the usage of hypergraph structural information from the\nmodel learning stage. This leads to a novel training-free message passing\nmodule, named TF-MP-Module, which can be precomputed in the data preprocessing\nstage, thereby reducing the computational burden. We refer to the hypergraph\nneural network equipped with our TF-MP-Module as TF-HNN. We theoretically\nsupport the efficiency and effectiveness of TF-HNN by showing that: 1) It is\nmore training-efficient compared to existing HNNs; 2) It utilises as much\ninformation as existing HNNs for node feature generation; and 3) It is robust\nagainst the oversmoothing issue while using long-range interactions.\nExperiments based on seven real-world hypergraph benchmarks in node\nclassification and hyperlink prediction show that, compared to state-of-the-art\nHNNs, TF-HNN exhibits both competitive performance and superior training\nefficiency. Specifically, on the large-scale benchmark, Trivago, TF-HNN\noutperforms the node classification accuracy of the best baseline by 10% with\njust 1% of the training time of that baseline.",
      "tldr_zh": "该研究针对超图（Hypergraphs）神经网络（HNNs）中消息传递模块需要计算密集型训练的问题，提出了一种训练-free的消息传递模块（TF-MP-Module），通过在数据预处理阶段预计算超图结构信息来降低计算负担，从而构建了高效的 TF-HNN 模型。理论分析证明，TF-HNN 比现有 HNNs 更训练高效、利用的信息量相当，并对过度平滑问题具有鲁棒性。实验在七个真实世界基准上显示，TF-HNN 在节点分类和超链接预测任务中表现出竞争性性能，并在大型 Trivago 数据集上将节点分类准确率提高 10%，而训练时间仅为最佳基线的 1%。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "eess.SP",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.05569v6",
      "published_date": "2024-02-08 11:10:39 UTC",
      "updated_date": "2025-03-11 16:06:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T04:42:25.320882"
    },
    {
      "arxiv_id": "2402.05563v1",
      "title": "Neural Multigrid Architectures",
      "title_zh": "神经多网格架构",
      "authors": [
        "Vladimir Fanaskov"
      ],
      "abstract": "We propose a convenient matrix-free neural architecture for the multigrid\nmethod. The architecture is simple enough to be implemented in less than fifty\nlines of code, yet it encompasses a large number of distinct multigrid solvers.\nWe argue that a fixed neural network without dense layers can not realize an\nefficient iterative method. Because of that, standard training protocols do not\nlead to competitive solvers. To overcome this difficulty, we use parameter\nsharing and serialization of layers. The resulting network can be trained on\nlinear problems with thousands of unknowns and retains its efficiency on\nproblems with millions of unknowns. From the point of view of numerical linear\nalgebra network's training corresponds to finding optimal smoothers for the\ngeometric multigrid method. We demonstrate our approach on a few second-order\nelliptic equations. For tested linear systems, we obtain from two to five times\nsmaller spectral radius of the error propagation matrix compare to a basic\nlinear multigrid with Jacobi smoother.",
      "tldr_zh": "我们提出了一种简便的 matrix-free 神经架构，用于 multigrid 方法，该架构只需不到五十行代码即可实现，并涵盖多种 multigrid 求解器。针对固定神经网络无法实现高效迭代方法的挑战，我们采用参数共享和层序列化，使网络能在数千未知数的线性问题上训练，并扩展到数百万未知数的场景中保持效率。实验结果显示，在几个二阶椭圆方程上，该架构将错误传播矩阵的谱半径比基本线性 multigrid with Jacobi smoother 降低了 2 到 5 倍，从而为 geometric multigrid 方法优化 smoother 提供了新途径。",
      "categories": [
        "math.NA",
        "cs.AI",
        "cs.NA"
      ],
      "primary_category": "math.NA",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.05563v1",
      "published_date": "2024-02-08 11:02:06 UTC",
      "updated_date": "2024-02-08 11:02:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T04:42:37.282029"
    },
    {
      "arxiv_id": "2402.05558v1",
      "title": "Flashback: Understanding and Mitigating Forgetting in Federated Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Mohammed Aljahdali",
        "Ahmed M. Abdelmoniem",
        "Marco Canini",
        "Samuel Horváth"
      ],
      "abstract": "In Federated Learning (FL), forgetting, or the loss of knowledge across\nrounds, hampers algorithm convergence, particularly in the presence of severe\ndata heterogeneity among clients. This study explores the nuances of this\nissue, emphasizing the critical role of forgetting in FL's inefficient learning\nwithin heterogeneous data contexts. Knowledge loss occurs in both client-local\nupdates and server-side aggregation steps; addressing one without the other\nfails to mitigate forgetting. We introduce a metric to measure forgetting\ngranularly, ensuring distinct recognition amid new knowledge acquisition.\nLeveraging these insights, we propose Flashback, an FL algorithm with a dynamic\ndistillation approach that is used to regularize the local models, and\neffectively aggregate their knowledge. Across different benchmarks, Flashback\noutperforms other methods, mitigates forgetting, and achieves faster\nround-to-target-accuracy, by converging in 6 to 16 rounds.",
      "tldr_zh": "本研究探讨了 Federated Learning (FL) 中 forgetting 问题，即知识在轮次间丢失，导致算法在数据异质性环境中收敛困难。作者引入了一个细粒度度量指标来区分 forgetting 与新知识获取，并提出 Flashback 算法，该算法通过动态蒸馏方法正则化本地模型并有效聚合知识。实验结果显示，Flashback 在不同基准测试中优于现有方法，显著减少 forgetting，并加速收敛，仅需 6 到 16 轮即可达到目标准确率。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV",
        "cs.DC"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.05558v1",
      "published_date": "2024-02-08 10:52:37 UTC",
      "updated_date": "2024-02-08 10:52:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T04:42:49.138063"
    },
    {
      "arxiv_id": "2402.05547v2",
      "title": "Benchmarking Large Language Models on Communicative Medical Coaching: a Novel System and Dataset",
      "title_zh": "翻译失败",
      "authors": [
        "Hengguan Huang",
        "Songtao Wang",
        "Hongfu Liu",
        "Hao Wang",
        "Ye Wang"
      ],
      "abstract": "Traditional applications of natural language processing (NLP) in healthcare\nhave predominantly focused on patient-centered services, enhancing patient\ninteractions and care delivery, such as through medical dialogue systems.\nHowever, the potential of NLP to benefit inexperienced doctors, particularly in\nareas such as communicative medical coaching, remains largely unexplored. We\nintroduce \"ChatCoach\", a human-AI cooperative framework designed to assist\nmedical learners in practicing their communication skills during patient\nconsultations. ChatCoach (Our data and code are available online:\nhttps://github.com/zerowst/Chatcoach)differentiates itself from conventional\ndialogue systems by offering a simulated environment where medical learners can\npractice dialogues with a patient agent, while a coach agent provides\nimmediate, structured feedback. This is facilitated by our proposed Generalized\nChain-of-Thought (GCoT) approach, which fosters the generation of structured\nfeedback and enhances the utilization of external knowledge sources.\nAdditionally, we have developed a dataset specifically for evaluating Large\nLanguage Models (LLMs) within the ChatCoach framework on communicative medical\ncoaching tasks. Our empirical results validate the effectiveness of ChatCoach.",
      "tldr_zh": "这篇论文探讨了自然语言处理(NLP)在医疗领域的应用，特别关注帮助inexperienced doctors进行communicative medical coaching的潜力。研究者引入了ChatCoach框架，这是一个human-AI合作系统，提供模拟环境让医疗学习者练习患者咨询对话，同时由教练代理提供即时结构化反馈。框架采用Generalized Chain-of-Thought (GCoT)方法来生成反馈并整合外部知识源。此外，他们开发了一个专用数据集，用于评估Large Language Models (LLMs)在communicative medical coaching任务中的性能，实证结果验证了ChatCoach的有效性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to Findings of the Association for Computational\n  Linguistics: ACL 2024",
      "pdf_url": "http://arxiv.org/pdf/2402.05547v2",
      "published_date": "2024-02-08 10:32:06 UTC",
      "updated_date": "2024-06-08 16:36:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T04:43:01.377074"
    },
    {
      "arxiv_id": "2402.05546v1",
      "title": "Offline Actor-Critic Reinforcement Learning Scales to Large Models",
      "title_zh": "翻译失败",
      "authors": [
        "Jost Tobias Springenberg",
        "Abbas Abdolmaleki",
        "Jingwei Zhang",
        "Oliver Groth",
        "Michael Bloesch",
        "Thomas Lampe",
        "Philemon Brakel",
        "Sarah Bechtle",
        "Steven Kapturowski",
        "Roland Hafner",
        "Nicolas Heess",
        "Martin Riedmiller"
      ],
      "abstract": "We show that offline actor-critic reinforcement learning can scale to large\nmodels - such as transformers - and follows similar scaling laws as supervised\nlearning. We find that offline actor-critic algorithms can outperform strong,\nsupervised, behavioral cloning baselines for multi-task training on a large\ndataset containing both sub-optimal and expert behavior on 132 continuous\ncontrol tasks. We introduce a Perceiver-based actor-critic model and elucidate\nthe key model features needed to make offline RL work with self- and\ncross-attention modules. Overall, we find that: i) simple offline actor critic\nalgorithms are a natural choice for gradually moving away from the currently\npredominant paradigm of behavioral cloning, and ii) via offline RL it is\npossible to learn multi-task policies that master many domains simultaneously,\nincluding real robotics tasks, from sub-optimal demonstrations or\nself-generated data.",
      "tldr_zh": "本研究证明，offline actor-critic reinforcement learning 可以扩展到大型模型（如 transformers），并遵循与监督学习相似的缩放定律。该方法在包含次优和专家行为的132个连续控制任务的多任务训练中，优于强有力的 supervised behavioral cloning 基线。研究引入了基于 Perceiver 的 actor-critic 模型，并阐明了自注意力和交叉注意力模块的关键特征，以实现离线 RL 的有效性。总体而言，这为逐步取代 behavioral cloning 范式提供了自然选择，并展示了从次优演示或自生成数据中学习多任务策略的可能性，包括真实机器人任务。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.05546v1",
      "published_date": "2024-02-08 10:29:46 UTC",
      "updated_date": "2024-02-08 10:29:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T04:43:14.245564"
    },
    {
      "arxiv_id": "2402.05541v2",
      "title": "FedAA: A Reinforcement Learning Perspective on Adaptive Aggregation for Fair and Robust Federated Learning",
      "title_zh": "FedAA：强化学习视角下的自适应聚合，用于公平和鲁棒联邦学习",
      "authors": [
        "Jialuo He",
        "Wei Chen",
        "Xiaojin Zhang"
      ],
      "abstract": "Federated Learning (FL) has emerged as a promising approach for\nprivacy-preserving model training across decentralized devices. However, it\nfaces challenges such as statistical heterogeneity and susceptibility to\nadversarial attacks, which can impact model robustness and fairness.\nPersonalized FL attempts to provide some relief by customizing models for\nindividual clients. However, it falls short in addressing server-side\naggregation vulnerabilities. We introduce a novel method called \\textbf{FedAA},\nwhich optimizes client contributions via \\textbf{A}daptive \\textbf{A}ggregation\nto enhance model robustness against malicious clients and ensure fairness\nacross participants in non-identically distributed settings. To achieve this\ngoal, we propose an approach involving a Deep Deterministic Policy\nGradient-based algorithm for continuous control of aggregation weights, an\ninnovative client selection method based on model parameter distances, and a\nreward mechanism guided by validation set performance. Empirically, extensive\nexperiments demonstrate that, in terms of robustness, \\textbf{FedAA}\noutperforms the state-of-the-art methods, while maintaining comparable levels\nof fairness, offering a promising solution to build resilient and fair\nfederated systems. Our code is available at https://github.com/Gp1g/FedAA.",
      "tldr_zh": "本研究从强化学习角度提出FedAA方法，针对Federated Learning (FL)中的统计异质性和对抗攻击问题，通过自适应聚合优化客户端贡献，以提升模型的鲁棒性和公平性。FedAA采用Deep Deterministic Policy Gradient (DDPG)算法控制聚合权重、基于模型参数距离的客户端选择机制，以及以验证集性能为导向的奖励系统，实现对恶意客户端的抵抗和在非独立同分布设置下的公平分配。实验结果显示，FedAA在鲁棒性方面优于现有最先进方法，同时保持相似的公平水平，为构建弹性公平的联邦学习系统提供了有效解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DC"
      ],
      "primary_category": "cs.LG",
      "comment": "AAAI 2025",
      "pdf_url": "http://arxiv.org/pdf/2402.05541v2",
      "published_date": "2024-02-08 10:22:12 UTC",
      "updated_date": "2024-12-12 13:40:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T04:43:24.999096"
    },
    {
      "arxiv_id": "2402.05525v2",
      "title": "Differentially Private Deep Model-Based Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Alexandre Rio",
        "Merwan Barlier",
        "Igor Colin",
        "Albert Thomas"
      ],
      "abstract": "We address private deep offline reinforcement learning (RL), where the goal\nis to train a policy on standard control tasks that is differentially private\n(DP) with respect to individual trajectories in the dataset. To achieve this,\nwe introduce PriMORL, a model-based RL algorithm with formal differential\nprivacy guarantees. PriMORL first learns an ensemble of trajectory-level DP\nmodels of the environment from offline data. It then optimizes a policy on the\npenalized private model, without any further interaction with the system or\naccess to the dataset. In addition to offering strong theoretical foundations,\nwe demonstrate empirically that PriMORL enables the training of private RL\nagents on offline continuous control tasks with deep function approximations,\nwhereas current methods are limited to simpler tabular and linear Markov\nDecision Processes (MDPs). We furthermore outline the trade-offs involved in\nachieving privacy in this setting.",
      "tldr_zh": "这篇论文针对差分隐私(DP)下的深度离线强化学习(RL)，提出了一种名为PriMORL的模型-based RL算法，以保护数据集中的个体轨迹隐私。PriMORL首先从离线数据中学习一个轨迹级DP环境模型的集合，然后在惩罚后的私有模型上优化策略，而无需进一步系统交互。实验结果显示，PriMORL在连续控制任务中使用深度函数逼近训练私有RL代理取得了显著成效，超越了限于表格和线性Markov Decision Processes (MDPs)的现有方法，并探讨了实现隐私的潜在权衡。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.05525v2",
      "published_date": "2024-02-08 10:05:11 UTC",
      "updated_date": "2024-10-09 13:31:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T04:43:39.026780"
    },
    {
      "arxiv_id": "2402.05521v1",
      "title": "Linearizing Models for Efficient yet Robust Private Inference",
      "title_zh": "模型线性化以实现高效且鲁棒的私有推理",
      "authors": [
        "Sreetama Sarkar",
        "Souvik Kundu",
        "Peter A. Beerel"
      ],
      "abstract": "The growing concern about data privacy has led to the development of private\ninference (PI) frameworks in client-server applications which protects both\ndata privacy and model IP. However, the cryptographic primitives required yield\nsignificant latency overhead which limits its wide-spread application. At the\nsame time, changing environments demand the PI service to be robust against\nvarious naturally occurring and gradient-based perturbations. Despite several\nworks focused on the development of latency-efficient models suitable for PI,\nthe impact of these models on robustness has remained unexplored. Towards this\ngoal, this paper presents RLNet, a class of robust linearized networks that can\nyield latency improvement via reduction of high-latency ReLU operations while\nimproving the model performance on both clean and corrupted images. In\nparticular, RLNet models provide a \"triple win ticket\" of improved\nclassification accuracy on clean, naturally perturbed, and gradient-based\nperturbed images using a shared-mask shared-weight architecture with over an\norder of magnitude fewer ReLUs than baseline models. To demonstrate the\nefficacy of RLNet, we perform extensive experiments with ResNet and WRN model\nvariants on CIFAR-10, CIFAR-100, and Tiny-ImageNet datasets. Our experimental\nevaluations show that RLNet can yield models with up to 11.14x fewer ReLUs,\nwith accuracy close to the all-ReLU models, on clean, naturally perturbed, and\ngradient-based perturbed images. Compared with the SoTA non-robust linearized\nmodels at similar ReLU budgets, RLNet achieves an improvement in adversarial\naccuracy of up to ~47%, naturally perturbed accuracy up to ~16.4%, while\nimproving clean image accuracy up to ~1.5%.",
      "tldr_zh": "该研究针对私人推理（Private Inference, PI）框架的延迟开销和鲁棒性挑战，提出了一种鲁棒线性化网络（RLNet）。RLNet 通过减少高延迟的 ReLU 操作并采用共享掩码和共享权重架构，显著提升模型在干净图像、自然扰动图像以及基于梯度的扰动图像上的分类准确率。实验在 CIFAR-10、CIFAR-100 和 Tiny-ImageNet 数据集上使用 ResNet 和 WRN 模型变体进行，结果显示 RLNet 模型的 ReLU 操作减少高达 11.14 倍，同时在对抗准确率提高约 47%、自然扰动准确率提高约 16.4%，并将干净图像准确率提升约 1.5%。这种方法为高效且鲁棒的 PI 框架提供了新途径。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.05521v1",
      "published_date": "2024-02-08 10:01:29 UTC",
      "updated_date": "2024-02-08 10:01:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T04:43:51.461066"
    },
    {
      "arxiv_id": "2402.05519v1",
      "title": "Can ChatGPT evaluate research quality?",
      "title_zh": "ChatGPT 可以评估研究质量吗？",
      "authors": [
        "Mike Thelwall"
      ],
      "abstract": "Purpose: Assess whether ChatGPT 4.0 is accurate enough to perform research\nevaluations on journal articles to automate this time-consuming task.\nDesign/methodology/approach: Test the extent to which ChatGPT-4 can assess the\nquality of journal articles using a case study of the published scoring\nguidelines of the UK Research Excellence Framework (REF) 2021 to create a\nresearch evaluation ChatGPT. This was applied to 51 of my own articles and\ncompared against my own quality judgements. Findings: ChatGPT-4 can produce\nplausible document summaries and quality evaluation rationales that match the\nREF criteria. Its overall scores have weak correlations with my self-evaluation\nscores of the same documents (averaging r=0.281 over 15 iterations, with 8\nbeing statistically significantly different from 0). In contrast, the average\nscores from the 15 iterations produced a statistically significant positive\ncorrelation of 0.509. Thus, averaging scores from multiple ChatGPT-4 rounds\nseems more effective than individual scores. The positive correlation may be\ndue to ChatGPT being able to extract the author's significance, rigour, and\noriginality claims from inside each paper. If my weakest articles are removed,\nthen the correlation with average scores (r=0.200) falls below statistical\nsignificance, suggesting that ChatGPT struggles to make fine-grained\nevaluations. Research limitations: The data is self-evaluations of a\nconvenience sample of articles from one academic in one field. Practical\nimplications: Overall, ChatGPT does not yet seem to be accurate enough to be\ntrusted for any formal or informal research quality evaluation tasks. Research\nevaluators, including journal editors, should therefore take steps to control\nits use. Originality/value: This is the first published attempt at\npost-publication expert review accuracy testing for ChatGPT.",
      "tldr_zh": "这篇论文评估了 ChatGPT-4 是否能准确进行研究质量评估，以自动化这一耗时任务。研究方法包括使用 UK Research Excellence Framework (REF) 2021 的评分指南，对作者的51篇文章进行测试，并与作者自评分数比较，结果显示 ChatGPT-4 的单个分数与自评的相关性较弱 (平均 r=0.281)，但多次迭代的平均分数相关性较高 (r=0.509)，可能源于其提取论文中 significance, rigour 和 originality 的能力。论文指出，ChatGPT-4 在细粒度评估中挣扎，且整体不够可靠用于正式研究评估，因此研究评估者应控制其使用；这也是首次公开尝试 ChatGPT 的后发布专家审查准确性测试。",
      "categories": [
        "cs.DL",
        "cs.AI"
      ],
      "primary_category": "cs.DL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.05519v1",
      "published_date": "2024-02-08 10:00:40 UTC",
      "updated_date": "2024-02-08 10:00:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T04:44:03.957918"
    },
    {
      "arxiv_id": "2402.05515v2",
      "title": "NoisyICL: A Little Noise in Model Parameters Calibrates In-context Learning",
      "title_zh": "NoisyICL：模型参数中的少量噪声校准上下文学习",
      "authors": [
        "Yufeng Zhao",
        "Yoshihiro Sakai",
        "Naoya Inoue"
      ],
      "abstract": "In-Context Learning (ICL) is suffering from unsatisfactory performance and\nunder-calibration due to high prior bias and unfaithful confidence. Some\nprevious works fine-tuned language models for better ICL performance with\nenormous datasets and computing costs. In this paper, we propose NoisyICL,\nsimply perturbing the model parameters by random noises to strive for better\nperformance and calibration. Our experiments on two models and 12 downstream\ndatasets show that NoisyICL can help ICL produce more accurate predictions. Our\nfurther analysis indicates that NoisyICL enables the model to provide more fair\npredictions, and also with more faithful confidence. Therefore, we believe that\nNoisyICL is an effective calibration of ICL. Our experimental code is uploaded\nto Github.",
      "tldr_zh": "本文提出 NoisyICL 方法，通过在模型参数中添加随机噪声来改善 In-Context Learning (ICL) 的性能和校准问题，从而减少高先验偏差和不忠实的置信度。实验在两个模型和 12 个下游数据集上显示，NoisyICL 显著提高了预测准确性，并使模型提供更公平的预测和更可靠的置信度。该方法无需大量数据集和计算资源，即可作为一种有效的 ICL 校准策略，并已开源代码以供进一步验证。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "20 pages, 28 figures, 7 tables (5 pages, 4 figures, 1 table in main\n  body). ACL 2024 under review",
      "pdf_url": "http://arxiv.org/pdf/2402.05515v2",
      "published_date": "2024-02-08 09:48:02 UTC",
      "updated_date": "2024-02-15 15:25:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T04:44:13.934834"
    },
    {
      "arxiv_id": "2402.05512v1",
      "title": "GPTs Are Multilingual Annotators for Sequence Generation Tasks",
      "title_zh": "GPTs 是用于序列生成任务的多语言标注器",
      "authors": [
        "Juhwan Choi",
        "Eunju Lee",
        "Kyohoon Jin",
        "YoungBin Kim"
      ],
      "abstract": "Data annotation is an essential step for constructing new datasets. However,\nthe conventional approach of data annotation through crowdsourcing is both\ntime-consuming and expensive. In addition, the complexity of this process\nincreases when dealing with low-resource languages owing to the difference in\nthe language pool of crowdworkers. To address these issues, this study proposes\nan autonomous annotation method by utilizing large language models, which have\nbeen recently demonstrated to exhibit remarkable performance. Through our\nexperiments, we demonstrate that the proposed method is not just cost-efficient\nbut also applicable for low-resource language annotation. Additionally, we\nconstructed an image captioning dataset using our approach and are committed to\nopen this dataset for future study. We have opened our source code for further\nstudy and reproducibility.",
      "tldr_zh": "这篇论文提出了一种利用大型语言模型（LLMs）进行自主数据标注的方法，以解决传统众包标注耗时、昂贵且低资源语言处理困难的问题。实验结果显示，该方法不仅成本高效，还适用于低资源语言的序列生成任务（如图像字幕）。作者构建并开源了一个图像字幕数据集，以及相关源代码，以支持未来的研究和可重复性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "EACL 2024 Findings: Camera-ready version",
      "pdf_url": "http://arxiv.org/pdf/2402.05512v1",
      "published_date": "2024-02-08 09:44:02 UTC",
      "updated_date": "2024-02-08 09:44:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T04:44:25.526619"
    },
    {
      "arxiv_id": "2402.10086v2",
      "title": "Explainable AI for Safe and Trustworthy Autonomous Driving: A Systematic Review",
      "title_zh": "翻译失败",
      "authors": [
        "Anton Kuznietsov",
        "Balint Gyevnar",
        "Cheng Wang",
        "Steven Peters",
        "Stefano V. Albrecht"
      ],
      "abstract": "Artificial Intelligence (AI) shows promising applications for the perception\nand planning tasks in autonomous driving (AD) due to its superior performance\ncompared to conventional methods. However, inscrutable AI systems exacerbate\nthe existing challenge of safety assurance of AD. One way to mitigate this\nchallenge is to utilize explainable AI (XAI) techniques. To this end, we\npresent the first comprehensive systematic literature review of explainable\nmethods for safe and trustworthy AD. We begin by analyzing the requirements for\nAI in the context of AD, focusing on three key aspects: data, model, and\nagency. We find that XAI is fundamental to meeting these requirements. Based on\nthis, we explain the sources of explanations in AI and describe a taxonomy of\nXAI. We then identify five key contributions of XAI for safe and trustworthy AI\nin AD, which are interpretable design, interpretable surrogate models,\ninterpretable monitoring, auxiliary explanations, and interpretable validation.\nFinally, we propose a modular framework called SafeX to integrate these\ncontributions, enabling explanation delivery to users while simultaneously\nensuring the safety of AI models.",
      "tldr_zh": "这篇论文对Explainable AI (XAI) 在Autonomous Driving (AD) 中的应用进行了系统文献综述，旨在提升AI系统的安全性和可信度。作者分析了AI在AD中的关键要求，包括数据、模型和代理方面，并强调XAI在解决AI不透明性问题中的核心作用。论文识别了XAI的五个主要贡献：可解释设计、代理模型监控、辅助解释以及可解释验证，并提出了一个模块化框架SafeX来整合这些元素，确保AI模型的安全性和解释性输出。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV",
        "cs.HC",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.10086v2",
      "published_date": "2024-02-08 09:08:44 UTC",
      "updated_date": "2024-07-03 08:31:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T04:44:37.937783"
    },
    {
      "arxiv_id": "2402.05493v4",
      "title": "Investigating White-Box Attacks for On-Device Models",
      "title_zh": "翻译失败",
      "authors": [
        "Mingyi Zhou",
        "Xiang Gao",
        "Jing Wu",
        "Kui Liu",
        "Hailong Sun",
        "Li Li"
      ],
      "abstract": "Numerous mobile apps have leveraged deep learning capabilities. However,\non-device models are vulnerable to attacks as they can be easily extracted from\ntheir corresponding mobile apps. Existing on-device attacking approaches only\ngenerate black-box attacks, which are far less effective and efficient than\nwhite-box strategies. This is because mobile deep learning frameworks like\nTFLite do not support gradient computing, which is necessary for white-box\nattacking algorithms. Thus, we argue that existing findings may underestimate\nthe harmfulness of on-device attacks. To this end, we conduct a study to answer\nthis research question: Can on-device models be directly attacked via white-box\nstrategies? We first systematically analyze the difficulties of transforming\nthe on-device model to its debuggable version, and propose a Reverse\nEngineering framework for On-device Models (REOM), which automatically reverses\nthe compiled on-device TFLite model to the debuggable model. Specifically, REOM\nfirst transforms compiled on-device models into Open Neural Network Exchange\nformat, then removes the non-debuggable parts, and converts them to the\ndebuggable DL models format that allows attackers to exploit in a white-box\nsetting. Our experimental results show that our approach is effective in\nachieving automated transformation among 244 TFLite models. Compared with\nprevious attacks using surrogate models, REOM enables attackers to achieve\nhigher attack success rates with a hundred times smaller attack perturbations.\nIn addition, because the ONNX platform has plenty of tools for model format\nexchanging, the proposed method based on the ONNX platform can be adapted to\nother model formats. Our findings emphasize the need for developers to\ncarefully consider their model deployment strategies, and use white-box methods\nto evaluate the vulnerability of on-device models.",
      "tldr_zh": "这篇论文调查了 on-device 模型面对 white-box attacks 的漏洞，指出现有攻击方法仅限于黑盒策略，导致效率低下，因为 TFLite 不支持梯度计算。研究者提出 REOM（Reverse Engineering framework for On-Device Models）框架，通过将编译后的 TFLite 模型转换为 ONNX 格式、移除非调试部分，并转换为可调试的深度学习模型，实现直接白盒攻击。实验结果显示，REOM 在 244 个 TFLite 模型上有效，相比使用代理模型的攻击，攻击成功率更高，且扰动大小减少百倍。该研究强调开发者需谨慎部署 on-device 模型，并采用 white-box 方法评估其安全性。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.SE",
      "comment": "Published in The International Conference on Software Engineering\n  2024 (ICSE'24)",
      "pdf_url": "http://arxiv.org/pdf/2402.05493v4",
      "published_date": "2024-02-08 09:03:17 UTC",
      "updated_date": "2024-03-01 05:22:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T04:44:51.303722"
    },
    {
      "arxiv_id": "2402.05484v1",
      "title": "Leveraging AI for Enhanced Software Effort Estimation: A Comprehensive Study and Framework Proposal",
      "title_zh": "翻译失败",
      "authors": [
        "Nhi Tran",
        "Tan Tran",
        "Nam Nguyen"
      ],
      "abstract": "This paper presents an extensive study on the application of AI techniques\nfor software effort estimation in the past five years from 2017 to 2023. By\novercoming the limitations of traditional methods, the study aims to improve\naccuracy and reliability. Through performance evaluation and comparison with\ndiverse Machine Learning models, including Artificial Neural Network (ANN),\nSupport Vector Machine (SVM), Linear Regression, Random Forest and other\ntechniques, the most effective method is identified. The proposed AI-based\nframework holds the potential to enhance project planning and resource\nallocation, contributing to the research area of software project effort\nestimation.",
      "tldr_zh": "这篇论文对2017-2023年间AI技术在软件努力估计中的应用进行了全面研究，旨在克服传统方法的局限性并提升准确性和可靠性。通过比较多种机器学习模型，如Artificial Neural Network (ANN)、Support Vector Machine (SVM)、Linear Regression和Random Forest等，论文识别出了最有效的估算方法。最终，提出一个AI-based框架，以优化软件项目的规划和资源分配，为软件努力估计领域的研究提供新贡献。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.05484v1",
      "published_date": "2024-02-08 08:25:41 UTC",
      "updated_date": "2024-02-08 08:25:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T04:45:01.510775"
    },
    {
      "arxiv_id": "2402.05467v1",
      "title": "Rapid Optimization for Jailbreaking LLMs via Subconscious Exploitation and Echopraxia",
      "title_zh": "翻译失败",
      "authors": [
        "Guangyu Shen",
        "Siyuan Cheng",
        "Kaiyuan Zhang",
        "Guanhong Tao",
        "Shengwei An",
        "Lu Yan",
        "Zhuo Zhang",
        "Shiqing Ma",
        "Xiangyu Zhang"
      ],
      "abstract": "Large Language Models (LLMs) have become prevalent across diverse sectors,\ntransforming human life with their extraordinary reasoning and comprehension\nabilities. As they find increased use in sensitive tasks, safety concerns have\ngained widespread attention. Extensive efforts have been dedicated to aligning\nLLMs with human moral principles to ensure their safe deployment. Despite their\npotential, recent research indicates aligned LLMs are prone to specialized\njailbreaking prompts that bypass safety measures to elicit violent and harmful\ncontent. The intrinsic discrete nature and substantial scale of contemporary\nLLMs pose significant challenges in automatically generating diverse,\nefficient, and potent jailbreaking prompts, representing a continuous obstacle.\nIn this paper, we introduce RIPPLE (Rapid Optimization via Subconscious\nExploitation and Echopraxia), a novel optimization-based method inspired by two\npsychological concepts: subconsciousness and echopraxia, which describe the\nprocesses of the mind that occur without conscious awareness and the\ninvoluntary mimicry of actions, respectively. Evaluations across 6 open-source\nLLMs and 4 commercial LLM APIs show RIPPLE achieves an average Attack Success\nRate of 91.5\\%, outperforming five current methods by up to 47.0\\% with an 8x\nreduction in overhead. Furthermore, it displays significant transferability and\nstealth, successfully evading established detection mechanisms. The code of our\nwork is available at\n\\url{https://github.com/SolidShen/RIPPLE_official/tree/official}",
      "tldr_zh": "该论文探讨了大语言模型（LLMs）的安全问题，指出尽管已努力使其与人类道德原则对齐，但它们仍易受jailbreaking提示攻击，导致生成有害内容。为解决自动生成高效jailbreaking提示的挑战，研究提出RIPPLE方法，该方法受subconsciousness（潜意识）和echopraxia（回声模仿）心理概念启发，通过优化技术快速生成多样化提示。实验结果显示，RIPPLE在6个开源LLMs和4个商业LLM APIs上平均攻击成功率达91.5%，比现有方法高出最多47.0%，并减少8倍开销，同时展现出显著的transferability（可转移性）和stealth（隐蔽性）。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.CR"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.05467v1",
      "published_date": "2024-02-08 07:56:49 UTC",
      "updated_date": "2024-02-08 07:56:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T04:45:14.613754"
    },
    {
      "arxiv_id": "2402.14580v1",
      "title": "Savvy: Trustworthy Autonomous Vehicles Architecture",
      "title_zh": "翻译失败",
      "authors": [
        "Ali Shoker",
        "Rehana Yasmin",
        "Paulo Esteves-Verissimo"
      ],
      "abstract": "The increasing interest in Autonomous Vehicles (AV) is notable due to\nbusiness, safety, and performance reasons. While there is salient success in\nrecent AV architectures, hinging on the advancements in AI models, there is a\ngrowing number of fatal incidents that impedes full AVs from going mainstream.\nThis calls for the need to revisit the fundamentals of building safety-critical\nAV architectures. However, this direction should not deter leveraging the power\nof AI. To this end, we propose Savvy, a new trustworthy intelligent AV\narchitecture that achieves the best of both worlds. Savvy makes a clear\nseparation between the control plane and the data plane to guarantee the\nsafety-first principles. The former assume control to ensure safety using\ndesign-time defined rules, while launching the latter for optimizing decisions\nas much as possible within safety time-bounds. This is achieved through guided\nTime-aware predictive quality degradation (TPQD): using dynamic ML models that\ncan be tuned to provide either richer or faster outputs based on the available\nsafety time bounds. For instance, Savvy allows to safely identify an elephant\nas an obstacle (a mere object) the earliest possible, rather than optimally\nrecognizing it as an elephant when it is too late. This position paper presents\nthe Savvy's motivations and concept, whereas empirical evaluation is a work in\nprogress.",
      "tldr_zh": "本论文提出 Savvy，一种可信赖的 Autonomous Vehicles (AV) 架构，旨在解决现有 AV 系统因致命事故而无法普及的问题，同时平衡安全性和 AI 性能。Savvy 通过分离控制平面和数据平面，确保控制平面使用设计时定义的规则优先保障安全，而数据平面则利用动态 ML 模型在安全时间限制内优化决策。核心创新是 Time-aware predictive quality degradation (TPQD)，允许根据可用时间动态调整模型输出，例如及早将大象识别为障碍物以避免风险。该架构的实证评估仍在进行中，为构建安全优先的 AV 系统提供了新方向。",
      "categories": [
        "cs.AI",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.14580v1",
      "published_date": "2024-02-08 07:24:45 UTC",
      "updated_date": "2024-02-08 07:24:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T04:45:25.522279"
    },
    {
      "arxiv_id": "2402.05457v1",
      "title": "It's Never Too Late: Fusing Acoustic Information into Large Language Models for Automatic Speech Recognition",
      "title_zh": "永远都不晚：将声学信息融合到大型语言模型中用于自动语音识别",
      "authors": [
        "Chen Chen",
        "Ruizhe Li",
        "Yuchen Hu",
        "Sabato Marco Siniscalchi",
        "Pin-Yu Chen",
        "Ensiong Chng",
        "Chao-Han Huck Yang"
      ],
      "abstract": "Recent studies have successfully shown that large language models (LLMs) can\nbe successfully used for generative error correction (GER) on top of the\nautomatic speech recognition (ASR) output. Specifically, an LLM is utilized to\ncarry out a direct mapping from the N-best hypotheses list generated by an ASR\nsystem to the predicted output transcription. However, despite its\neffectiveness, GER introduces extra data uncertainty since the LLM is trained\nwithout taking into account acoustic information available in the speech\nsignal. In this work, we aim to overcome such a limitation by infusing acoustic\ninformation before generating the predicted transcription through a novel late\nfusion solution termed Uncertainty-Aware Dynamic Fusion (UADF). UADF is a\nmultimodal fusion approach implemented into an auto-regressive decoding process\nand works in two stages: (i) It first analyzes and calibrates the token-level\nLLM decision, and (ii) it then dynamically assimilates the information from the\nacoustic modality. Experimental evidence collected from various ASR tasks shows\nthat UADF surpasses existing fusion mechanisms in several ways. It yields\nsignificant improvements in word error rate (WER) while mitigating data\nuncertainty issues in LLM and addressing the poor generalization relied with\nsole modality during fusion. We also demonstrate that UADF seamlessly adapts to\naudio-visual speech recognition.",
      "tldr_zh": "本研究针对大语言模型 (LLMs) 在自动语音识别 (ASR) 中的生成性错误修正 (GER) 问题，提出了一种新颖的后期融合方法：Uncertainty-Aware Dynamic Fusion (UADF)，旨在通过整合语音信号中的声学信息来减少数据不确定性。UADF 采用多模态融合策略，分为两个阶段：首先分析并校准 LLM 的 token-level 决策，其次动态吸收声学模态的信息，以融入自回归解码过程。实验结果显示，该方法在多种 ASR 任务中显著降低了词错误率 (WER)，缓解了 LLM 的不确定性问题，并提高了单一模态融合的泛化能力，同时无缝适用于音频-视觉语音识别。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.MM",
        "cs.SD",
        "eess.AS"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to ICLR 2024, 17 pages. This work will be open sourced under\n  MIT license",
      "pdf_url": "http://arxiv.org/pdf/2402.05457v1",
      "published_date": "2024-02-08 07:21:45 UTC",
      "updated_date": "2024-02-08 07:21:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T04:45:39.601791"
    },
    {
      "arxiv_id": "2402.06682v1",
      "title": "Private Knowledge Sharing in Distributed Learning: A Survey",
      "title_zh": "分布式学习中的私有知识共享：一个综述",
      "authors": [
        "Yasas Supeksala",
        "Dinh C. Nguyen",
        "Ming Ding",
        "Thilina Ranbaduge",
        "Calson Chua",
        "Jun Zhang",
        "Jun Li",
        "H. Vincent Poor"
      ],
      "abstract": "The rise of Artificial Intelligence (AI) has revolutionized numerous\nindustries and transformed the way society operates. Its widespread use has led\nto the distribution of AI and its underlying data across many intelligent\nsystems. In this light, it is crucial to utilize information in learning\nprocesses that are either distributed or owned by different entities. As a\nresult, modern data-driven services have been developed to integrate\ndistributed knowledge entities into their outcomes. In line with this goal, the\nlatest AI models are frequently trained in a decentralized manner. Distributed\nlearning involves multiple entities working together to make collective\npredictions and decisions. However, this collaboration can also bring about\nsecurity vulnerabilities and challenges. This paper provides an in-depth survey\non private knowledge sharing in distributed learning, examining various\nknowledge components utilized in leading distributed learning architectures.\nOur analysis sheds light on the most critical vulnerabilities that may arise\nwhen using these components in a distributed setting. We further identify and\nexamine defensive strategies for preserving the privacy of these knowledge\ncomponents and preventing malicious parties from manipulating or accessing the\nknowledge information. Finally, we highlight several key limitations of\nknowledge sharing in distributed learning and explore potential avenues for\nfuture research.",
      "tldr_zh": "这篇论文对分布式学习(Distributed Learning)中的私人知识共享(Private Knowledge Sharing)进行了全面调查，探讨了AI模型在多实体合作环境中利用分布式知识的挑战和安全风险。论文分析了主要知识组件在分布式架构中的关键漏洞，并评估了保护这些组件隐私的防御策略，以防范恶意访问或操纵。最终，它指出了知识共享的潜在限制，并提出了未来研究方向，以提升分布式学习的隐私和安全性。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.DC",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "Manuscript submitted to ACM",
      "pdf_url": "http://arxiv.org/pdf/2402.06682v1",
      "published_date": "2024-02-08 07:18:23 UTC",
      "updated_date": "2024-02-08 07:18:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T04:45:49.842100"
    },
    {
      "arxiv_id": "2402.05448v2",
      "title": "Minecraft-ify: Minecraft Style Image Generation with Text-guided Image Editing for In-Game Application",
      "title_zh": "翻译失败",
      "authors": [
        "Bumsoo Kim",
        "Sanghyun Byun",
        "Yonghoon Jung",
        "Wonseop Shin",
        "Sareer UI Amin",
        "Sanghyun Seo"
      ],
      "abstract": "In this paper, we first present the character texture generation system\n\\textit{Minecraft-ify}, specified to Minecraft video game toward in-game\napplication. Ours can generate face-focused image for texture mapping tailored\nto 3D virtual character having cube manifold. While existing projects or works\nonly generate texture, proposed system can inverse the user-provided real\nimage, or generate average/random appearance from learned distribution.\nMoreover, it can be manipulated with text-guidance using StyleGAN and\nStyleCLIP. These features provide a more extended user experience with enlarged\nfreedom as a user-friendly AI-tool. Project page can be found at\nhttps://gh-bumsookim.github.io/Minecraft-ify/",
      "tldr_zh": "这篇论文介绍了 Minecraft-ify 系统，一种专为 Minecraft 游戏设计的图像生成工具，能够创建面部聚焦的纹理图像，用于 3D 虚拟角色的立方体映射。系统支持从用户提供的真实图像中反转生成纹理，或从学习到的分布中产生平均/随机外观，并通过文本引导的图像编辑（如 StyleGAN 和 StyleCLIP）实现操控。总体上，该系统作为用户友好的 AI 工具，扩展了游戏应用的交互自由度，提供更丰富的用户体验。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.GR",
        "cs.LG",
        "cs.MM"
      ],
      "primary_category": "cs.CV",
      "comment": "2 pages, 2 figures. Accepted as Spotlight to NeurIPS 2023 Workshop on\n  Machine Learning for Creativity and Design",
      "pdf_url": "http://arxiv.org/pdf/2402.05448v2",
      "published_date": "2024-02-08 07:01:00 UTC",
      "updated_date": "2024-03-03 10:02:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T04:46:02.663270"
    },
    {
      "arxiv_id": "2402.05980v3",
      "title": "Do Large Code Models Understand Programming Concepts? Counterfactual Analysis for Code Predicates",
      "title_zh": "翻译失败",
      "authors": [
        "Ashish Hooda",
        "Mihai Christodorescu",
        "Miltiadis Allamanis",
        "Aaron Wilson",
        "Kassem Fawaz",
        "Somesh Jha"
      ],
      "abstract": "Large Language Models' success on text generation has also made them better\nat code generation and coding tasks. While a lot of work has demonstrated their\nremarkable performance on tasks such as code completion and editing, it is\nstill unclear as to why. We help bridge this gap by exploring to what degree\nauto-regressive models understand the logical constructs of the underlying\nprograms. We propose Counterfactual Analysis for Programming Concept Predicates\n(CACP) as a counterfactual testing framework to evaluate whether Large Code\nModels understand programming concepts. With only black-box access to the\nmodel, we use CACP to evaluate ten popular Large Code Models for four different\nprogramming concepts. Our findings suggest that current models lack\nunderstanding of concepts such as data flow and control flow.",
      "tldr_zh": "本研究探讨了大型代码模型（Large Code Models）是否真正理解编程概念，尽管它们在代码生成任务上表现出色。作者提出了一种反事实分析框架Counterfactual Analysis for Programming Concept Predicates (CACP)，通过黑盒测试方法评估十个热门模型对四个编程概念（如数据流和控制流）的理解。实验结果表明，这些模型在理解核心编程概念方面存在显著不足，从而揭示了当前模型性能与实际理解之间的差距，为改进代码模型提供了重要见解。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.LG",
        "cs.PL"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.05980v3",
      "published_date": "2024-02-08 06:48:01 UTC",
      "updated_date": "2025-02-12 15:40:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T04:46:14.313727"
    },
    {
      "arxiv_id": "2402.05435v2",
      "title": "GPT-4 Generated Narratives of Life Events using a Structured Narrative Prompt: A Validation Study",
      "title_zh": "翻译失败",
      "authors": [
        "Christopher J. Lynch",
        "Erik Jensen",
        "Madison H. Munro",
        "Virginia Zamponi",
        "Joseph Martinez",
        "Kevin O'Brien",
        "Brandon Feldhaus",
        "Katherine Smith",
        "Ann Marie Reinhold",
        "Ross Gore"
      ],
      "abstract": "Large Language Models (LLMs) play a pivotal role in generating vast arrays of\nnarratives, facilitating a systematic exploration of their effectiveness for\ncommunicating life events in narrative form. In this study, we employ a\nzero-shot structured narrative prompt to generate 24,000 narratives using\nOpenAI's GPT-4. From this dataset, we manually classify 2,880 narratives and\nevaluate their validity in conveying birth, death, hiring, and firing events.\nRemarkably, 87.43% of the narratives sufficiently convey the intention of the\nstructured prompt. To automate the identification of valid and invalid\nnarratives, we train and validate nine Machine Learning models on the\nclassified datasets. Leveraging these models, we extend our analysis to predict\nthe classifications of the remaining 21,120 narratives. All the ML models\nexcelled at classifying valid narratives as valid, but experienced challenges\nat simultaneously classifying invalid narratives as invalid. Our findings not\nonly advance the study of LLM capabilities, limitations, and validity but also\noffer practical insights for narrative generation and natural language\nprocessing applications.",
      "tldr_zh": "本研究使用零-shot 结构化叙事提示，让 OpenAI 的 GPT-4 生成 24,000 个关于出生、死亡、雇佣和解雇等生活事件的叙事，并对其中 2,880 个叙事进行手动分类和有效性评估，结果显示 87.43% 的叙事成功传达了提示意图。研究进一步训练并验证了九个 Machine Learning models 来自动识别有效和无效叙事，这些模型在分类有效叙事方面表现出色，但同时处理无效叙事时面临挑战。通过扩展分析预测剩余叙事，该研究揭示了 Large Language Models (LLMs) 的能力和局限性，并为叙事生成和自然语言处理应用提供了实用见解。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG",
        "I.2.7; I.6.4"
      ],
      "primary_category": "cs.CL",
      "comment": "29 pages, 24 figures",
      "pdf_url": "http://arxiv.org/pdf/2402.05435v2",
      "published_date": "2024-02-08 06:20:01 UTC",
      "updated_date": "2024-07-12 13:46:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T04:46:28.335561"
    },
    {
      "arxiv_id": "2402.05428v1",
      "title": "Mixture Density Networks for Classification with an Application to Product Bundling",
      "title_zh": "混合密度网络用于分类及其在产品捆绑中的应用",
      "authors": [
        "Narendhar Gugulothu",
        "Sanjay P. Bhat",
        "Tejas Bodas"
      ],
      "abstract": "While mixture density networks (MDNs) have been extensively used for\nregression tasks, they have not been used much for classification tasks. One\nreason for this is that the usability of MDNs for classification is not clear\nand straightforward. In this paper, we propose two MDN-based models for\nclassification tasks. Both models fit mixtures of Gaussians to the the data and\nuse the fitted distributions to classify a given sample by evaluating the\nlearnt cumulative distribution function for the given input features. While the\nproposed MDN-based models perform slightly better than, or on par with, five\nbaseline classification models on three publicly available datasets, the real\nutility of our models comes out through a real-world product bundling\napplication. Specifically, we use our MDN-based models to learn the\nwillingness-to-pay (WTP) distributions for two products from synthetic sales\ndata of the individual products. The Gaussian mixture representation of the\nlearnt WTP distributions is then exploited to obtain the WTP distribution of\nthe bundle consisting of both the products. The proposed MDN-based models are\nable to approximate the true WTP distributions of both products and the bundle\nwell.",
      "tldr_zh": "本论文提出两种基于 Mixture Density Networks (MDNs) 的模型，用于分类任务，这些模型通过拟合 mixtures of Gaussians 并利用 cumulative distribution function 评估输入特征来实现分类。实验结果显示，在三个公开数据集上，这些模型的表现与五个基线分类模型相当或略优。论文的关键应用在于产品捆绑场景，使用 MDN 模型从合成销售数据中学习产品的 willingness-to-pay (WTP) 分布，并准确逼近捆绑产品的 WTP 分布。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.05428v1",
      "published_date": "2024-02-08 05:54:08 UTC",
      "updated_date": "2024-02-08 05:54:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T04:46:39.015159"
    },
    {
      "arxiv_id": "2402.05421v4",
      "title": "DiffTORI: Differentiable Trajectory Optimization for Deep Reinforcement and Imitation Learning",
      "title_zh": "DiffTORI：可微轨迹优化用于深度强化学习和模仿学习",
      "authors": [
        "Weikang Wan",
        "Ziyu Wang",
        "Yufei Wang",
        "Zackory Erickson",
        "David Held"
      ],
      "abstract": "This paper introduces DiffTORI, which utilizes Differentiable Trajectory\nOptimization as the policy representation to generate actions for deep\nReinforcement and Imitation learning. Trajectory optimization is a powerful and\nwidely used algorithm in control, parameterized by a cost and a dynamics\nfunction. The key to our approach is to leverage the recent progress in\ndifferentiable trajectory optimization, which enables computing the gradients\nof the loss with respect to the parameters of trajectory optimization. As a\nresult, the cost and dynamics functions of trajectory optimization can be\nlearned end-to-end. DiffTORI addresses the ``objective mismatch'' issue of\nprior model-based RL algorithms, as the dynamics model in DiffTORI is learned\nto directly maximize task performance by differentiating the policy gradient\nloss through the trajectory optimization process. We further benchmark DiffTORI\nfor imitation learning on standard robotic manipulation task suites with\nhigh-dimensional sensory observations and compare our method to feed-forward\npolicy classes as well as Energy-Based Models (EBM) and Diffusion. Across 15\nmodel-based RL tasks and 35 imitation learning tasks with high-dimensional\nimage and point cloud inputs, DiffTORI outperforms prior state-of-the-art\nmethods in both domains. Our code is available at\nhttps://github.com/wkwan7/DiffTORI.",
      "tldr_zh": "本研究引入了DiffTORI，一种利用Differentiable Trajectory Optimization作为策略表示的方法，用于深度Reinforcement Learning和Imitation Learning。DiffTORI通过计算损失相对于轨迹优化参数的梯度，实现成本函数和动力学函数的端到端学习，从而解决传统基于模型的RL算法的“objective mismatch”问题。实验结果显示，在15个基于模型的RL任务和35个高维图像及点云输入的Imitation Learning任务中，DiffTORI优于现有最先进方法，如前馈策略、Energy-Based Models (EBM)和Diffusion模型。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.LG",
      "comment": "NeurIPS 2024 (Spotlight)",
      "pdf_url": "http://arxiv.org/pdf/2402.05421v4",
      "published_date": "2024-02-08 05:26:40 UTC",
      "updated_date": "2025-03-03 22:40:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T04:46:49.961054"
    },
    {
      "arxiv_id": "2402.06680v1",
      "title": "Social Physics Informed Diffusion Model for Crowd Simulation",
      "title_zh": "翻译失败",
      "authors": [
        "Hongyi Chen",
        "Jingtao Ding",
        "Yong Li",
        "Yue Wang",
        "Xiao-Ping Zhang"
      ],
      "abstract": "Crowd simulation holds crucial applications in various domains, such as urban\nplanning, architectural design, and traffic arrangement. In recent years,\nphysics-informed machine learning methods have achieved state-of-the-art\nperformance in crowd simulation but fail to model the heterogeneity and\nmulti-modality of human movement comprehensively. In this paper, we propose a\nsocial physics-informed diffusion model named SPDiff to mitigate the above gap.\nSPDiff takes both the interactive and historical information of crowds in the\ncurrent timeframe to reverse the diffusion process, thereby generating the\ndistribution of pedestrian movement in the subsequent timeframe. Inspired by\nthe well-known social physics model, i.e., Social Force, regarding crowd\ndynamics, we design a crowd interaction module to guide the denoising process\nand further enhance this module with the equivariant properties of crowd\ninteractions. To mitigate error accumulation in long-term simulations, we\npropose a multi-frame rollout training algorithm for diffusion modeling.\nExperiments conducted on two real-world datasets demonstrate the superior\nperformance of SPDiff in terms of macroscopic and microscopic evaluation\nmetrics. Code and appendix are available at\nhttps://github.com/tsinghua-fib-lab/SPDiff.",
      "tldr_zh": "该论文提出了一种名为 SPDiff 的社会物理信息扩散模型，用于人群模拟，以解决现有物理信息机器学习方法在建模人群运动异质性和多模态性方面的不足。SPDiff 通过整合交互和历史信息逆向扩散过程，并设计基于 Social Force 的人群交互模块，同时增强等变性（equivariant properties）来指导去噪过程；此外，还引入多帧 rollout 训练算法以减少长期模拟中的错误积累。在两个真实数据集上的实验显示，SPDiff 在宏观和微观评估指标上显著优于基线模型，为城市规划等领域提供更准确的人群模拟工具。",
      "categories": [
        "physics.soc-ph",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "physics.soc-ph",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.06680v1",
      "published_date": "2024-02-08 04:43:33 UTC",
      "updated_date": "2024-02-08 04:43:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T04:47:03.722269"
    },
    {
      "arxiv_id": "2402.05403v2",
      "title": "In-Context Principle Learning from Mistakes",
      "title_zh": "翻译失败",
      "authors": [
        "Tianjun Zhang",
        "Aman Madaan",
        "Luyu Gao",
        "Steven Zheng",
        "Swaroop Mishra",
        "Yiming Yang",
        "Niket Tandon",
        "Uri Alon"
      ],
      "abstract": "In-context learning (ICL, also known as few-shot prompting) has been the\nstandard method of adapting LLMs to downstream tasks, by learning from a few\ninput-output examples. Nonetheless, all ICL-based approaches only learn from\ncorrect input-output pairs. In this paper, we revisit this paradigm, by\nlearning more from the few given input-output examples. We introduce Learning\nPrinciples (LEAP): First, we intentionally induce the model to make mistakes on\nthese few examples; then we reflect on these mistakes, and learn explicit\ntask-specific \"principles\" from them, which help solve similar problems and\navoid common mistakes; finally, we prompt the model to answer unseen test\nquestions using the original few-shot examples and these learned general\nprinciples. We evaluate LEAP on a wide range of benchmarks, including multi-hop\nquestion answering (Hotpot QA), textual QA (DROP), Big-Bench Hard reasoning,\nand math problems (GSM8K and MATH); in all these benchmarks, LEAP improves the\nstrongest available LLMs such as GPT-3.5-turbo, GPT-4, GPT-4 turbo and\nClaude-2.1. For example, LEAP improves over the standard few-shot prompting\nusing GPT-4 by 7.5% in DROP, and by 3.3% in HotpotQA. Importantly, LEAP does\nnot require any more input or examples than the standard few-shot prompting\nsettings.",
      "tldr_zh": "本论文提出 LEAP（Learning Principles）方法，旨在改进传统 ICL（In-context Learning），通过故意诱导模型在少数输入-输出示例上犯错，然后从这些错误中反思并学习显式的任务特定原则，以帮助解决类似问题并避免常见失误。LEAP 在多任务基准测试中表现出色，包括多跳问答（Hotpot QA）、文本问答（DROP）、Big-Bench Hard 推理以及数学问题（GSM8K 和 MATH），例如在 DROP 上使 GPT-4 比标准 few-shot prompting 提升 7.5%，在 Hotpot QA 上提升 3.3%。重要的是，LEAP 不需要额外的输入或示例，仅基于现有 few-shot 设置即可实现性能提升。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.05403v2",
      "published_date": "2024-02-08 04:42:29 UTC",
      "updated_date": "2024-02-09 19:09:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T04:47:19.172668"
    },
    {
      "arxiv_id": "2402.05399v3",
      "title": "CURE: Simulation-Augmented Auto-Tuning in Robotics",
      "title_zh": "翻译失败",
      "authors": [
        "Md Abir Hossen",
        "Sonam Kharade",
        "Jason M. O'Kane",
        "Bradley Schmerl",
        "David Garlan",
        "Pooyan Jamshidi"
      ],
      "abstract": "Robotic systems are typically composed of various subsystems, such as\nlocalization and navigation, each encompassing numerous configurable components\n(e.g., selecting different planning algorithms). Once an algorithm has been\nselected for a component, its associated configuration options must be set to\nthe appropriate values. Configuration options across the system stack interact\nnon-trivially. Finding optimal configurations for highly configurable robots to\nachieve desired performance poses a significant challenge due to the\ninteractions between configuration options across software and hardware that\nresult in an exponentially large and complex configuration space. These\nchallenges are further compounded by the need for transferability between\ndifferent environments and robotic platforms. Data efficient optimization\nalgorithms (e.g., Bayesian optimization) have been increasingly employed to\nautomate the tuning of configurable parameters in cyber-physical systems.\nHowever, such optimization algorithms converge at later stages, often after\nexhausting the allocated budget (e.g., optimization steps, allotted time) and\nlacking transferability. This paper proposes CURE -- a method that identifies\ncausally relevant configuration options, enabling the optimization process to\noperate in a reduced search space, thereby enabling faster optimization of\nrobot performance. CURE abstracts the causal relationships between various\nconfiguration options and robot performance objectives by learning a causal\nmodel in the source (a low-cost environment such as the Gazebo simulator) and\napplying the learned knowledge to perform optimization in the target (e.g.,\nTurtlebot 3 physical robot). We demonstrate the effectiveness and\ntransferability of CURE by conducting experiments that involve varying degrees\nof deployment changes in both physical robots and simulation.",
      "tldr_zh": "本论文提出 CURE 方法，用于机器人系统的自动调优，旨在解决配置选项的复杂交互导致的搜索空间庞大问题。CURE 通过在源环境（如 Gazebo 模拟器）学习配置选项与性能目标之间的因果模型，识别出因果相关的选项，从而减少搜索空间并加速优化过程。实验结果显示，CURE 比传统方法如 Bayesian optimization 更高效，并在不同环境和平台（如 Turtlebot 3 物理机器人）之间实现了良好的可转移性。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "Accepted for publication in IEEE Transactions on Robotics (T-RO),\n  2025",
      "pdf_url": "http://arxiv.org/pdf/2402.05399v3",
      "published_date": "2024-02-08 04:27:14 UTC",
      "updated_date": "2025-02-25 15:39:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T04:47:27.552852"
    },
    {
      "arxiv_id": "2402.05396v3",
      "title": "TASER: Temporal Adaptive Sampling for Fast and Accurate Dynamic Graph Representation Learning",
      "title_zh": "TASER：时序自适应采样用于快速准确的动态图表示学习",
      "authors": [
        "Gangda Deng",
        "Hongkuan Zhou",
        "Hanqing Zeng",
        "Yinglong Xia",
        "Christopher Leung",
        "Jianbo Li",
        "Rajgopal Kannan",
        "Viktor Prasanna"
      ],
      "abstract": "Recently, Temporal Graph Neural Networks (TGNNs) have demonstrated\nstate-of-the-art performance in various high-impact applications, including\nfraud detection and content recommendation. Despite the success of TGNNs, they\nare prone to the prevalent noise found in real-world dynamic graphs like\ntime-deprecated links and skewed interaction distribution. The noise causes two\ncritical issues that significantly compromise the accuracy of TGNNs: (1) models\nare supervised by inferior interactions, and (2) noisy input induces high\nvariance in the aggregated messages. However, current TGNN denoising techniques\ndo not consider the diverse and dynamic noise pattern of each node. In\naddition, they also suffer from the excessive mini-batch generation overheads\ncaused by traversing more neighbors. We believe the remedy for fast and\naccurate TGNNs lies in temporal adaptive sampling. In this work, we propose\nTASER, the first adaptive sampling method for TGNNs optimized for accuracy,\nefficiency, and scalability. TASER adapts its mini-batch selection based on\ntraining dynamics and temporal neighbor selection based on the contextual,\nstructural, and temporal properties of past interactions. To alleviate the\nbottleneck in mini-batch generation, TASER implements a pure GPU-based temporal\nneighbor finder and a dedicated GPU feature cache. We evaluate the performance\nof TASER using two state-of-the-art backbone TGNNs. On five popular datasets,\nTASER outperforms the corresponding baselines by an average of 2.3% in Mean\nReciprocal Rank (MRR) while achieving an average of 5.1x speedup in training\ntime.",
      "tldr_zh": "该论文针对 Temporal Graph Neural Networks (TGNNs) 在动态图表示学习中面临的噪声问题（如过时链接和交互分布偏斜），提出了一种名为 TASER 的时间自适应采样方法，以优化模型的准确性、效率和可扩展性。TASER 通过根据训练动态、节点上下文、结构和时间属性动态选择小批量数据和邻居，并采用纯 GPU 基于的邻居查找器和特征缓存来减少生成开销。在五个流行数据集上的实验显示，TASER 相较基线模型平均提高了 2.3% 的 Mean Reciprocal Rank (MRR)，并实现了 5.1 倍的训练速度加速。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "IPDPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2402.05396v3",
      "published_date": "2024-02-08 04:16:35 UTC",
      "updated_date": "2024-11-23 10:42:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T04:47:41.280161"
    },
    {
      "arxiv_id": "2402.05391v4",
      "title": "Knowledge Graphs Meet Multi-Modal Learning: A Comprehensive Survey",
      "title_zh": "翻译失败",
      "authors": [
        "Zhuo Chen",
        "Yichi Zhang",
        "Yin Fang",
        "Yuxia Geng",
        "Lingbing Guo",
        "Xiang Chen",
        "Qian Li",
        "Wen Zhang",
        "Jiaoyan Chen",
        "Yushan Zhu",
        "Jiaqi Li",
        "Xiaoze Liu",
        "Jeff Z. Pan",
        "Ningyu Zhang",
        "Huajun Chen"
      ],
      "abstract": "Knowledge Graphs (KGs) play a pivotal role in advancing various AI\napplications, with the semantic web community's exploration into multi-modal\ndimensions unlocking new avenues for innovation. In this survey, we carefully\nreview over 300 articles, focusing on KG-aware research in two principal\naspects: KG-driven Multi-Modal (KG4MM) learning, where KGs support multi-modal\ntasks, and Multi-Modal Knowledge Graph (MM4KG), which extends KG studies into\nthe MMKG realm. We begin by defining KGs and MMKGs, then explore their\nconstruction progress. Our review includes two primary task categories:\nKG-aware multi-modal learning tasks, such as Image Classification and Visual\nQuestion Answering, and intrinsic MMKG tasks like Multi-modal Knowledge Graph\nCompletion and Entity Alignment, highlighting specific research trajectories.\nFor most of these tasks, we provide definitions, evaluation benchmarks, and\nadditionally outline essential insights for conducting relevant research.\nFinally, we discuss current challenges and identify emerging trends, such as\nprogress in Large Language Modeling and Multi-modal Pre-training strategies.\nThis survey aims to serve as a comprehensive reference for researchers already\ninvolved in or considering delving into KG and multi-modal learning research,\noffering insights into the evolving landscape of MMKG research and supporting\nfuture work.",
      "tldr_zh": "这篇调查论文全面回顾了知识图谱（KGs）和多模态学习（Multi-Modal Learning）的交叉领域，分析了超过300篇相关文献。论文聚焦于两个主要方面：KG驱动的多模态学习（KG4MM），其中KGs支持任务如图像分类和视觉问答；以及多模态知识图谱（MM4KG），包括知识图谱的构建、补全和实体对齐等内在任务。作者提供了这些任务的定义、评估基准和关键见解，同时讨论了当前挑战和新兴趋势，如大型语言模型（Large Language Modeling）和多模态预训练策略。该调查旨在为KGs和多模态学习研究者提供全面参考，支持未来创新发展。",
      "categories": [
        "cs.AI",
        "cs.CV",
        "cs.IR",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "Ongoing work; 41 pages (Main Text), 55 pages (Total), 11 Tables, 13\n  Figures, 619 citations; Paper list is available at\n  https://github.com/zjukg/KG-MM-Survey",
      "pdf_url": "http://arxiv.org/pdf/2402.05391v4",
      "published_date": "2024-02-08 04:04:36 UTC",
      "updated_date": "2024-02-26 09:57:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T04:47:53.773810"
    },
    {
      "arxiv_id": "2402.10941v2",
      "title": "Text2Data: Low-Resource Data Generation with Textual Control",
      "title_zh": "翻译失败",
      "authors": [
        "Shiyu Wang",
        "Yihao Feng",
        "Tian Lan",
        "Ning Yu",
        "Yu Bai",
        "Ran Xu",
        "Huan Wang",
        "Caiming Xiong",
        "Silvio Savarese"
      ],
      "abstract": "Natural language serves as a common and straightforward signal for humans to\ninteract seamlessly with machines. Recognizing the importance of this\ninterface, the machine learning community is investing considerable effort in\ngenerating data that is semantically coherent with textual instructions. While\nstrides have been made in text-to-data generation spanning image editing, audio\nsynthesis, video creation, and beyond, low-resource areas characterized by\nexpensive annotations or complex data structures, such as molecules, motion\ndynamics, and time series, often lack textual labels. This deficiency impedes\nsupervised learning, thereby constraining the application of advanced\ngenerative models for text-to-data tasks. In response to these challenges in\nthe low-resource scenario, we propose Text2Data, a novel approach that utilizes\nunlabeled data to understand the underlying data distribution through an\nunsupervised diffusion model. Subsequently, it undergoes controllable\nfinetuning via a novel constraint optimization-based learning objective that\nensures controllability and effectively counteracts catastrophic forgetting.\nComprehensive experiments demonstrate that Text2Data is able to achieve\nenhanced performance regarding controllability across various modalities,\nincluding molecules, motions and time series, when compared to existing\nbaselines.",
      "tldr_zh": "该论文提出Text2Data方法，用于低资源场景下通过文本指令生成数据，解决如分子、运动动态和时间序列等领域缺乏文本标签的问题，从而提升监督学习的适用性。该方法首先利用无监督diffusion model理解数据分布，然后通过新型约束优化-based学习目标进行可控微调，确保生成数据的可控性和避免catastrophic forgetting。实验结果表明，Text2Data在分子、运动和时间序列等模态上，比现有基线模型实现了更高的可控性性能。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Thirty-Ninth AAAI Conference on Artificial Intelligence (AAAI-25)",
      "pdf_url": "http://arxiv.org/pdf/2402.10941v2",
      "published_date": "2024-02-08 03:41:39 UTC",
      "updated_date": "2025-01-02 17:47:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T04:48:03.465210"
    },
    {
      "arxiv_id": "2402.05378v1",
      "title": "Graph Neural Networks for Physical-Layer Security in Multi-User Flexible-Duplex Networks",
      "title_zh": "图神经网络用于多用户灵活双工",
      "authors": [
        "Tharaka Perera",
        "Saman Atapattu",
        "Yuting Fang",
        "Jamie Evans"
      ],
      "abstract": "This paper explores Physical-Layer Security (PLS) in Flexible Duplex (FlexD)\nnetworks, considering scenarios involving eavesdroppers. Our investigation\nrevolves around the intricacies of the sum secrecy rate maximization problem,\nparticularly when faced with coordinated and distributed eavesdroppers\nemploying a Minimum Mean Square Error (MMSE) receiver. Our contributions\ninclude an iterative classical optimization solution and an unsupervised\nlearning strategy based on Graph Neural Networks (GNNs). To the best of our\nknowledge, this work marks the initial exploration of GNNs for PLS\napplications. Additionally, we extend the GNN approach to address the absence\nof eavesdroppers' channel knowledge. Extensive numerical simulations highlight\nFlexD's superiority over Half-Duplex (HD) communications and the GNN approach's\nsuperiority over the classical method in both performance and time complexity.",
      "tldr_zh": "本研究探讨了多用户 Flexible-Duplex (FlexD) 网络中的 Physical-Layer Security (PLS)，针对协调和分布式窃听者使用 Minimum Mean Square Error (MMSE) 接收器来最大化总保密率。论文的主要贡献包括提出一个迭代的经典优化解决方案和基于 Graph Neural Networks (GNNs) 的无监督学习策略，这是首次将 GNNs 应用于 PLS 领域，并扩展该方法处理未知窃听者通道信息。实验结果显示，FlexD 网络在性能上优于 Half-Duplex (HD) 通信，而 GNN 方法在准确性和时间复杂度上均超过传统方法。",
      "categories": [
        "eess.SP",
        "cs.AI",
        "cs.CR",
        "cs.LG"
      ],
      "primary_category": "eess.SP",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.05378v1",
      "published_date": "2024-02-08 03:22:12 UTC",
      "updated_date": "2024-02-08 03:22:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T04:48:16.176020"
    },
    {
      "arxiv_id": "2402.05374v5",
      "title": "CIC: A Framework for Culturally-Aware Image Captioning",
      "title_zh": "翻译失败",
      "authors": [
        "Youngsik Yun",
        "Jihie Kim"
      ],
      "abstract": "Image Captioning generates descriptive sentences from images using\nVision-Language Pre-trained models (VLPs) such as BLIP, which has improved\ngreatly. However, current methods lack the generation of detailed descriptive\ncaptions for the cultural elements depicted in the images, such as the\ntraditional clothing worn by people from Asian cultural groups. In this paper,\nwe propose a new framework, Culturally-aware Image Captioning (CIC), that\ngenerates captions and describes cultural elements extracted from cultural\nvisual elements in images representing cultures. Inspired by methods combining\nvisual modality and Large Language Models (LLMs) through appropriate prompts,\nour framework (1) generates questions based on cultural categories from images,\n(2) extracts cultural visual elements from Visual Question Answering (VQA)\nusing generated questions, and (3) generates culturally-aware captions using\nLLMs with the prompts. Our human evaluation conducted on 45 participants from 4\ndifferent cultural groups with a high understanding of the corresponding\nculture shows that our proposed framework generates more culturally descriptive\ncaptions when compared to the image captioning baseline based on VLPs.\nResources can be found at https://shane3606.github.io/cic..",
      "tldr_zh": "本论文提出CIC框架（Culturally-aware Image Captioning），旨在解决现有基于Vision-Language Pre-trained models（如BLIP）的图像描述方法在处理文化元素（如亚洲传统服装）时的不足，从而生成更详细的文化感知标题。框架的关键步骤包括：（1）基于图像中的文化类别生成问题，（2）利用Visual Question Answering (VQA)提取文化视觉元素，（3）结合Large Language Models (LLMs)和适当提示生成文化描述性标题。人类评估结果显示，在45名来自4个不同文化群体的参与者中，CIC生成的标题比VLPs基线更具文化描述性，为文化多样性图像描述提供了新途径。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by IJCAI 2024",
      "pdf_url": "http://arxiv.org/pdf/2402.05374v5",
      "published_date": "2024-02-08 03:12:25 UTC",
      "updated_date": "2025-02-24 06:56:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T04:48:29.537722"
    },
    {
      "arxiv_id": "2402.05370v1",
      "title": "Attention as Robust Representation for Time Series Forecasting",
      "title_zh": "注意力作为时间序列预测的稳健表示",
      "authors": [
        "PeiSong Niu",
        "Tian Zhou",
        "Xue Wang",
        "Liang Sun",
        "Rong Jin"
      ],
      "abstract": "Time series forecasting is essential for many practical applications, with\nthe adoption of transformer-based models on the rise due to their impressive\nperformance in NLP and CV. Transformers' key feature, the attention mechanism,\ndynamically fusing embeddings to enhance data representation, often relegating\nattention weights to a byproduct role. Yet, time series data, characterized by\nnoise and non-stationarity, poses significant forecasting challenges. Our\napproach elevates attention weights as the primary representation for time\nseries, capitalizing on the temporal relationships among data points to improve\nforecasting accuracy. Our study shows that an attention map, structured using\nglobal landmarks and local windows, acts as a robust kernel representation for\ndata points, withstanding noise and shifts in distribution. Our method\noutperforms state-of-the-art models, reducing mean squared error (MSE) in\nmultivariate time series forecasting by a notable 3.6% without altering the\ncore neural network architecture. It serves as a versatile component that can\nreadily replace recent patching based embedding schemes in transformer-based\nmodels, boosting their performance.",
      "tldr_zh": "本文提出了一种将注意力机制(attention mechanism)作为时间序列预测的主要表示方法，利用数据点之间的时间关系来提升预测准确性。具体而言，该方法通过构建基于全局landmarks和局部windows的注意力图(attention map)，作为鲁棒的核表示，能够抵抗噪音和分布偏移。在实验中，该方法在多变量时间序列预测中降低了3.6%的均方误差(MSE)，优于现有最先进模型，且可作为通用组件替换Transformer模型中的嵌入方案，进一步提升性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.05370v1",
      "published_date": "2024-02-08 03:00:50 UTC",
      "updated_date": "2024-02-08 03:00:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T04:48:40.110898"
    },
    {
      "arxiv_id": "2402.05359v6",
      "title": "An Examination on the Effectiveness of Divide-and-Conquer Prompting in Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Yizhou Zhang",
        "Lun Du",
        "Defu Cao",
        "Qiang Fu",
        "Yan Liu"
      ],
      "abstract": "Foundation models, such as Large language Models (LLMs), have attracted\nsignificant amount of interest due to their large number of applications.\nHowever, when handling tasks involving repetitive sub-tasks and/or deceptive\ncontents, such as arithmetic calculation and article-level fake news detection,\nsimple instructional prompts suffer from inaccurate responses. Existing works\nshow that more complicated prompting strategies, such as Chain-of-Thoughts and\nLeast-to-Most, can unlock LLM's powerful capacity in diverse areas. Recent\nresearches reveal that simple divide-and-conquer prompting strategy, i.e.\nsimply dividing the input sequence to multiple sub-inputs, can also\nsubstantially improve LLM's performance in some specific tasks such as\nmisinformation detection. In this paper, we aim at examining the utility of\ndivide-and-conquer prompting strategy and answer on which kind of tasks this\nstrategy gets advantages. Specifically, we provide a theoretic analysis to\ndivide-and-conquer prompting strategy and help us identify the specific tasks\nwhere DaC prompting can bring performance boost with theoretic guarantee. We\nthen present two cases (large integer arithmetic and fact verification) where\nexperimental results aligns with our theoretic analysis.",
      "tldr_zh": "这篇论文考察了 Divide-and-Conquer (DaC) 提示策略在 Large Language Models (LLMs) 中的有效性，特别是针对涉及重复子任务或欺骗性内容的任务，如算术计算和假新闻检测。论文通过理论分析，识别出 DaC 策略（即将输入序列分成多个子输入）能在特定任务中带来性能提升，并提供理论保证。实验结果在两个案例——大整数算术和事实验证上，证实了 DaC 策略相对于简单指令提示的显著优势。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "Preprint",
      "pdf_url": "http://arxiv.org/pdf/2402.05359v6",
      "published_date": "2024-02-08 02:37:30 UTC",
      "updated_date": "2024-07-02 18:18:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T04:48:52.394524"
    },
    {
      "arxiv_id": "2402.05355v6",
      "title": "A Survey on Safe Multi-Modal Learning System",
      "title_zh": "翻译失败",
      "authors": [
        "Tianyi Zhao",
        "Liangliang Zhang",
        "Yao Ma",
        "Lu Cheng"
      ],
      "abstract": "In the rapidly evolving landscape of artificial intelligence, multimodal\nlearning systems (MMLS) have gained traction for their ability to process and\nintegrate information from diverse modality inputs. Their expanding use in\nvital sectors such as healthcare has made safety assurance a critical concern.\nHowever, the absence of systematic research into their safety is a significant\nbarrier to progress in this field. To bridge the gap, we present the first\ntaxonomy that systematically categorizes and assesses MMLS safety. This\ntaxonomy is structured around four fundamental pillars that are critical to\nensuring the safety of MMLS: robustness, alignment, monitoring, and\ncontrollability. Leveraging this taxonomy, we review existing methodologies,\nbenchmarks, and the current state of research, while also pinpointing the\nprincipal limitations and gaps in knowledge. Finally, we discuss unique\nchallenges in MMLS safety. In illuminating these challenges, we aim to pave the\nway for future research, proposing potential directions that could lead to\nsignificant advancements in the safety protocols of MMLS.",
      "tldr_zh": "这篇调查论文探讨了多模态学习系统 (MMLS) 的安全性问题，强调其在医疗等关键领域的应用需要系统保障。作者首次提出一个基于四个支柱（robustness、alignment、monitoring 和 controllability）的taxonomy，用于系统分类和评估MMLS的安全性。通过审阅现有方法、基准和研究现状，论文指出了主要局限性及知识空白。最后，论文讨论了MMLS安全面临的独特挑战，并提出潜在的未来研究方向，以推动安全协议的进步。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.05355v6",
      "published_date": "2024-02-08 02:27:13 UTC",
      "updated_date": "2024-07-16 08:35:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T04:49:04.703784"
    },
    {
      "arxiv_id": "2402.05346v2",
      "title": "KIX: A Knowledge and Interaction-Centric Metacognitive Framework for Task Generalization",
      "title_zh": "KIX：一种以知识和交互",
      "authors": [
        "Arun Kumar",
        "Paul Schrater"
      ],
      "abstract": "People aptly exhibit general intelligence behaviors in solving a variety of\ntasks with flexibility and ability to adapt to novel situations by reusing and\napplying high-level knowledge acquired over time. But artificial agents are\nmore like specialists, lacking such generalist behaviors. Artificial agents\nwill require understanding and exploiting critical structured knowledge\nrepresentations. We present a metacognitive generalization framework,\nKnowledge-Interaction-eXecution (KIX), and argue that interactions with objects\nleveraging type space facilitate the learning of transferable interaction\nconcepts and generalization. It is a natural way of integrating knowledge into\nreinforcement learning and is promising to act as an enabler for autonomous and\ngeneralist behaviors in artificial intelligence systems.",
      "tldr_zh": "人类在任务解决中展现出灵活的泛化能力，能够重用高阶知识适应新情况，而人工智能代理则更像专家，缺乏此类行为。研究提出KIX（Knowledge-Interaction-eXecution）框架，这是一个以知识和交互为中心的元认知框架，旨在通过利用类型空间（type space）和对象交互来学习可转移的交互概念。KIX框架将知识自然整合到强化学习（reinforcement learning）中，促进人工智能系统的自主性和通用化表现。该框架有望提升人工智能代理的任务泛化能力，实现更接近人类的智能行为。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "cs.RO"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.05346v2",
      "published_date": "2024-02-08 01:41:28 UTC",
      "updated_date": "2024-08-12 17:19:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T04:49:16.716873"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 111,
  "processed_papers_count": 111,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-17T04:49:40.920814"
}