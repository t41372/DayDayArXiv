{
  "date": "2024-01-18",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-01-18 的 arXiv 中文 TLDR 快报！\n\n今天 arXiv 的论文主要聚焦 AI 创新、机器学习优化和多模态处理等领域，强调大型语言模型（LLM）的性能提升（如 ChatQA 超越 GPT-4）和强化学习在实际应用的潜力，令人印象深刻的文章包括 ChatQA 和 Self-Rewarding Language Models，由知名学者如 Jason Weston 等参与，展示了 AI 在对话生成、图像处理和联邦学习中的突破。\n\n### 重点论文讨论\n我们挑选了最具话题度和影响力的论文，首先聊聊 AI 和 LLM 相关的内容，这些直接推动了当前 AI 热潮；接着简要覆盖机器学习和图像处理领域；其他论文如生物医学或交通应用若非核心，则快速掠过。\n\n**论文标题（中文）：ChatQA：超越 GPT-4 的对话问答和检索增强生成  英文：ChatQA: Surpassing GPT-4 on Conversational QA and RAG**  \n这篇论文是今日亮点，利用两阶段指令微调提升 LLM 在对话问答和检索增强生成（RAG）上的性能。核心贡献是通过改进检索和生成机制，ChatQA-1.0-70B 基于 Llama2 模型超越 GPT-4，在 ChatRAG Bench 上达到 54.14 分，并开源模型权重。该工作揭示了 LLM 在多轮对话中的潜力，适用于复杂对话应用。\n\n**论文标题（中文）：Self-Rewarding Language Models：LLM 的自我奖励机制  英文：Self-Rewarding Language Models**  \n作者包括 Jason Weston 等知名学者，提出一种 LLM 自我奖励框架，使用 LLM 作为评判器进行迭代训练。关键发现是，该方法在低渗透率下提升模型性能，如在 AlpacaEval 2.0 上超过 GPT-4，实现持续改进。该论文强调 LLM 自我优化的可能性，推动了 AI 自主学习方向。\n\n**论文标题（中文）：DiffusionGPT：LLM 驱动的文本到图像生成系统  英文：DiffusionGPT: LLM-Driven Text-to-Image Generation System**  \n这篇探索 LLM 与扩散模型的结合，通过构建领域特定树结构和人类反馈数据库，实现多样化提示解析和模型选择。贡献在于生成高质量图像，同时缓解输入约束，实验显示在多领域任务中提升生成效果，适用于图像合成应用。\n\n**论文标题（中文）：R-Judge：基准测试 LLM 代理的安全风险意识  英文：R-Judge: Benchmarking Safety Risk Awareness for LLM Agents**  \n论文提出 R-Judge 基准，评估 LLM 在交互记录中的安全风险识别能力。核心发现是当前 LLM 在风险感知上仍有不足，GPT-4o 仅达 74.42% 的准确率。该工作为 LLM 安全评估提供新工具，强调了 AI 伦理的重要性。\n\n**论文标题（中文）：Evolutionary Multi-Objective Optimization of Large Language Model Prompts  英文：Evolutionary Multi-Objective Optimization of Large Language Models Prompts**  \n利用进化算法优化 LLM 提示，针对情感平衡任务。贡献是通过多目标优化生成平衡情感的提示，实验显示显著提升生成质量。该论文展示了进化算法在提示工程中的应用潜力。\n\n**论文标题（中文）：Generalized Nested Rollout Policy Adaptation with Limited Repetitions  英文：Generalized Nested Rollout Policy Adaptation with Limited Repetitions**  \n作者 Tristan Cazenave 提出改进 Monte Carlo 搜索算法，避免重复序列。核心发现是通过限制重复，提升算法在 RNA Folding 和 TSP 等组合问题上的性能，适用于优化搜索任务。\n\n**论文标题（中文）：Distribution Consistency based Self-Training for Graph Neural Networks  英文：Distribution Consistency based Self-Training for Graph Neural Networks with Sparse Labels**  \n论文针对少样本节点分类，提出 DC-GST 框架，强调分布一致性。贡献在于通过可微优化减少分布偏移，在基准数据集上超越基线，适用于 GNN 的半监督学习。\n\n**论文标题（中文）：Agricultural Object Detection with You Look Only Once (YOLO)  英文：Agricultural Object Detection with You Look Only Once (YOLO) Algorithm**  \n系统回顾 YOLO 在农业中的应用，包括文献分析和任务特定修改。核心发现是 YOLO 在实时监测中提升资源效率，文献综述了 257 篇论文，提供农业 AI 部署指导。\n\n**论文标题（中文）：Towards Principled Graph Transformers  英文：Towards Principled Graph Transformers**  \n作者 Christopher Morris 等提出 Edge Transformer，提升图神经网络的理论表达性。贡献在于不依赖位置编码就达到 3-WL 级别，在图任务上表现优异，填补了理论与实践的空白。\n\n**论文标题（中文）：ELRT: Efficient Low-Rank Training for Compact CNNs  英文：ELRT: Efficient Low-Rank Training for Compact Convolutional Neural Networks**  \n论文提出 ELRT 方法，从零训练低秩 CNN。核心发现是减少参数同时维持准确性，在多种数据集上提升效率，适用于资源受限的边缘计算。\n\n其他论文如联邦学习、交通优化或医学图像处理（如 Hierarchical Federated Learning、Veagle）虽有创新，但相对常规，我们快速掠过：这些工作主要优化了分布式训练和图像分割，但未有突破性贡献；例如，联邦学习论文强调了移动性对收敛的影响，而医学图像论文如 SEINE 提升了核分割精度，但细节较琐碎，不再展开。\n\n总之，今天的 arXiv 突显 AI 领域的快速迭代，LLM 相关论文尤其值得关注，助力读者快速筛选感兴趣内容！如果有特定主题，欢迎深入探索。",
  "papers": [
    {
      "arxiv_id": "2401.10420v1",
      "title": "Generalized Nested Rollout Policy Adaptation with Limited Repetitions",
      "title_zh": "翻译失败",
      "authors": [
        "Tristan Cazenave"
      ],
      "abstract": "Generalized Nested Rollout Policy Adaptation (GNRPA) is a Monte Carlo search\nalgorithm for optimizing a sequence of choices. We propose to improve on GNRPA\nby avoiding too deterministic policies that find again and again the same\nsequence of choices. We do so by limiting the number of repetitions of the best\nsequence found at a given level. Experiments show that it improves the\nalgorithm for three different combinatorial problems: Inverse RNA Folding, the\nTraveling Salesman Problem with Time Windows and the Weak Schur problem.",
      "tldr_zh": "该论文提出了一种改进的 Generalized Nested Rollout Policy Adaptation (GNRPA) 算法，通过限制最佳序列的重复次数来避免策略过于确定性，从而优化序列选择过程。改进方法旨在增加算法的多样性，防止反复找到相同的序列。实验结果显示，该优化在 Inverse RNA Folding、Traveling Salesman Problem with Time Windows 和 Weak Schur problem 等三个组合问题上显著提升了算法性能。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.10420v1",
      "published_date": "2024-01-18 23:19:47 UTC",
      "updated_date": "2024-01-18 23:19:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:31:38.379982"
    },
    {
      "arxiv_id": "2401.10415v2",
      "title": "Can Large Language Model Summarizers Adapt to Diverse Scientific Communication Goals?",
      "title_zh": "翻译失败",
      "authors": [
        "Marcio Fonseca",
        "Shay B. Cohen"
      ],
      "abstract": "In this work, we investigate the controllability of large language models\n(LLMs) on scientific summarization tasks. We identify key stylistic and content\ncoverage factors that characterize different types of summaries such as paper\nreviews, abstracts, and lay summaries. By controlling stylistic features, we\nfind that non-fine-tuned LLMs outperform humans in the MuP review generation\ntask, both in terms of similarity to reference summaries and human preferences.\nAlso, we show that we can improve the controllability of LLMs with\nkeyword-based classifier-free guidance (CFG) while achieving lexical overlap\ncomparable to strong fine-tuned baselines on arXiv and PubMed. However, our\nresults also indicate that LLMs cannot consistently generate long summaries\nwith more than 8 sentences. Furthermore, these models exhibit limited capacity\nto produce highly abstractive lay summaries. Although LLMs demonstrate strong\ngeneric summarization competency, sophisticated content control without costly\nfine-tuning remains an open problem for domain-specific applications.",
      "tldr_zh": "本研究探讨了大型语言模型 (LLMs) 在科学总结任务中的可控性，重点识别不同类型总结（如论文评论、摘要和通俗总结）的风格和内容覆盖因素。结果显示，非微调的 LLMs 在 MuP 评论生成任务中超过了人类表现，并在相似性和偏好上表现出色；同时，通过基于关键词的分类器自由指导 (CFG)，LLMs 实现了与 arXiv 和 PubMed 上的强微调基线相当的词汇重叠。然而，LLMs 无法一致生成超过 8 句的长总结，且在产生高度抽象的通俗总结方面能力有限，表明在领域特定应用中，复杂内容控制仍需进一步改进。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "ACL 2024 camera ready",
      "pdf_url": "http://arxiv.org/pdf/2401.10415v2",
      "published_date": "2024-01-18 23:00:54 UTC",
      "updated_date": "2024-06-27 04:00:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:31:52.754738"
    },
    {
      "arxiv_id": "2401.10394v1",
      "title": "Distribution Consistency based Self-Training for Graph Neural Networks with Sparse Labels",
      "title_zh": "翻译失败",
      "authors": [
        "Fali Wang",
        "Tianxiang Zhao",
        "Suhang Wang"
      ],
      "abstract": "Few-shot node classification poses a significant challenge for Graph Neural\nNetworks (GNNs) due to insufficient supervision and potential distribution\nshifts between labeled and unlabeled nodes. Self-training has emerged as a\nwidely popular framework to leverage the abundance of unlabeled data, which\nexpands the training set by assigning pseudo-labels to selected unlabeled\nnodes. Efforts have been made to develop various selection strategies based on\nconfidence, information gain, etc. However, none of these methods takes into\naccount the distribution shift between the training and testing node sets. The\npseudo-labeling step may amplify this shift and even introduce new ones,\nhindering the effectiveness of self-training. Therefore, in this work, we\nexplore the potential of explicitly bridging the distribution shift between the\nexpanded training set and test set during self-training. To this end, we\npropose a novel Distribution-Consistent Graph Self-Training (DC-GST) framework\nto identify pseudo-labeled nodes that are both informative and capable of\nredeeming the distribution discrepancy and formulate it as a differentiable\noptimization task. A distribution-shift-aware edge predictor is further adopted\nto augment the graph and increase the model's generalizability in assigning\npseudo labels. We evaluate our proposed method on four publicly available\nbenchmark datasets and extensive experiments demonstrate that our framework\nconsistently outperforms state-of-the-art baselines.",
      "tldr_zh": "这篇论文针对Graph Neural Networks (GNNs) 在少样本节点分类中的标签稀疏和分布偏移问题，提出了一种新的Distribution-Consistent Graph Self-Training (DC-GST) 框架，以桥接训练集和测试集之间的分布差异。DC-GST 通过将伪标签节点的选取表述为可微优化任务，确保选择的节点既信息丰富又能减少分布偏移，同时引入一个分布偏移感知的边预测器来增强图结构，提高模型泛化性。实验在四个公开基准数据集上验证了该框架的表现，显著优于现有基线方法。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "F.2.2; I.2.7"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by WSDM 2024",
      "pdf_url": "http://arxiv.org/pdf/2401.10394v1",
      "published_date": "2024-01-18 22:07:48 UTC",
      "updated_date": "2024-01-18 22:07:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:32:04.293933"
    },
    {
      "arxiv_id": "2401.10393v3",
      "title": "Natural Mitigation of Catastrophic Interference: Continual Learning in Power-Law Learning Environments",
      "title_zh": "灾难性干扰的自然缓解：幂律学习环境中的持续学习",
      "authors": [
        "Atith Gandhi",
        "Raj Sanjay Shah",
        "Vijay Marupudi",
        "Sashank Varma"
      ],
      "abstract": "Neural networks often suffer from catastrophic interference (CI): performance\non previously learned tasks drops off significantly when learning a new task.\nThis contrasts strongly with humans, who can continually learn new tasks\nwithout appreciably forgetting previous tasks. Prior work has explored various\ntechniques for mitigating CI and promoting continual learning such as\nregularization, rehearsal, generative replay, and context-specific components.\nThis paper takes a different approach, one guided by cognitive science research\nshowing that in naturalistic environments, the probability of encountering a\ntask decreases as a power-law of the time since it was last performed. We argue\nthat techniques for mitigating CI should be compared against the intrinsic\nmitigation in simulated naturalistic learning environments. Thus, we evaluate\nthe extent of the natural mitigation of CI when training models in power-law\nenvironments, similar to those humans face. Our results show that natural\nrehearsal environments are better at mitigating CI than existing methods,\ncalling for the need for better evaluation processes. The benefits of this\nenvironment include simplicity, rehearsal that is agnostic to both tasks and\nmodels, and the lack of a need for extra neural circuitry. In addition, we\nexplore popular mitigation techniques in power-law environments to create new\nbaselines for continual learning research.",
      "tldr_zh": "该研究探讨了神经网络在持续学习（continual learning）中面临的灾难性干扰（Catastrophic Interference）问题，通过模拟认知科学中的功率定律（power-law）学习环境，评估自然缓解策略的效果。论文发现，在这种环境模拟下，任务的自然复现机制比现有方法（如正则化、rehearsal 和生成 replay）更有效地减少干扰，且无需额外神经结构或任务特定调整。结果表明，这种方法为持续学习研究提供了更简单的基准，并呼吁改进评估过程以更好地反映真实场景。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.10393v3",
      "published_date": "2024-01-18 22:06:38 UTC",
      "updated_date": "2024-08-26 23:10:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:32:15.827619"
    },
    {
      "arxiv_id": "2401.10379v1",
      "title": "Agricultural Object Detection with You Look Only Once (YOLO) Algorithm: A Bibliometric and Systematic Literature Review",
      "title_zh": "使用 You Look Only Once (YOLO) 算法的农业物体检测：文献计量学和系统文献综述",
      "authors": [
        "Chetan M Badgujar",
        "Alwin Poulose",
        "Hao Gan"
      ],
      "abstract": "Vision is a major component in several digital technologies and tools used in\nagriculture. The object detector, You Look Only Once (YOLO), has gained\npopularity in agriculture in a relatively short span due to its\nstate-of-the-art performance. YOLO offers real-time detection with good\naccuracy and is implemented in various agricultural tasks, including\nmonitoring, surveillance, sensing, automation, and robotics. The research and\napplication of YOLO in agriculture are accelerating rapidly but are fragmented\nand multidisciplinary. Moreover, the performance characteristics (i.e.,\naccuracy, speed, computation) of the object detector influence the rate of\ntechnology implementation and adoption in agriculture. Thus, the study aims to\ncollect extensive literature to document and critically evaluate the advances\nand application of YOLO for agricultural object recognition. First, we\nconducted a bibliometric review of 257 articles to understand the scholarly\nlandscape of YOLO in agricultural domain. Secondly, we conducted a systematic\nreview of 30 articles to identify current knowledge, gaps, and modifications in\nYOLO for specific agricultural tasks. The study critically assesses and\nsummarizes the information on YOLO's end-to-end learning approach, including\ndata acquisition, processing, network modification, integration, and\ndeployment. We also discussed task-specific YOLO algorithm modification and\nintegration to meet the agricultural object or environment-specific challenges.\nIn general, YOLO-integrated digital tools and technologies show the potential\nfor real-time, automated monitoring, surveillance, and object handling to\nreduce labor, production cost, and environmental impact while maximizing\nresource efficiency. The study provides detailed documentation and\nsignificantly advances the existing knowledge on applying YOLO in agriculture,\nwhich can greatly benefit the scientific community.",
      "tldr_zh": "本研究通过文献综述方法，分析了You Look Only Once (YOLO)算法在农业物体检测中的应用，包括对257篇论文的bibliometric review和30篇论文的systematic review，以揭示YOLO在监控、监视和自动化等农业任务中的进展和挑战。研究评估了YOLO的端到端学习方法，如数据获取、网络修改和集成，强调针对农业特定环境进行的算法优化，以提升准确性、速度和计算效率。结果显示，YOLO整合的数字工具可实现实时自动化，降低劳动成本和环境影响，同时识别出知识空白，为未来农业技术应用提供宝贵指导。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.10379v1",
      "published_date": "2024-01-18 21:04:25 UTC",
      "updated_date": "2024-01-18 21:04:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:32:27.318890"
    },
    {
      "arxiv_id": "2401.10372v1",
      "title": "MutaBot: A Mutation Testing Approach for Chatbots",
      "title_zh": "MutaBot：一种针对聊天机器人的突变测试方法",
      "authors": [
        "Michael Ferdinando Urrico",
        "Diego Clerissi",
        "Leonardo Mariani"
      ],
      "abstract": "Mutation testing is a technique aimed at assessing the effectiveness of test\nsuites by seeding artificial faults into programs. Although available for many\nplatforms and languages, no mutation testing tool is currently available for\nconversational chatbots, which represent an increasingly popular solution to\ndesign systems that can interact with users through a natural language\ninterface. Note that since conversations must be explicitly engineered by the\ndevelopers of conversational chatbots, these systems are exposed to specific\ntypes of faults not supported by existing mutation testing tools.\n  In this paper, we present MutaBot, a mutation testing tool for conversational\nchatbots. MutaBot addresses mutations at multiple levels, including\nconversational flows, intents, and contexts. We designed the tool to\npotentially target multiple platforms, while we implemented initial support for\nGoogle Dialogflow chatbots. We assessed the tool with three Dialogflow chatbots\nand test cases generated with Botium, revealing weaknesses in the test suites.",
      "tldr_zh": "本论文提出 MutaBot，一种针对对话式 chatbots 的 mutation testing 方法，用于评估测试套件的有效性，以解决现有工具无法处理 chatbots 独特错误类型的问题。MutaBot 在 conversational flows、intents 和 contexts 等层面注入人工突变，并设计为支持多个平台，初始实现针对 Google Dialogflow。实验评估通过三个 Dialogflow chatbots 和 Botium 生成的测试用例，揭示了测试套件的弱点，从而提升了 chatbots 的测试质量和可靠性。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "5 pages, 2 figures, 2024 IEEE/ACM 46th International Conference on\n  Software Engineering: Companion Proceedings (ICSE-Companion '24)",
      "pdf_url": "http://arxiv.org/pdf/2401.10372v1",
      "published_date": "2024-01-18 20:38:27 UTC",
      "updated_date": "2024-01-18 20:38:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:32:40.168024"
    },
    {
      "arxiv_id": "2401.10361v1",
      "title": "Hierarchical Federated Learning in Multi-hop Cluster-Based VANETs",
      "title_zh": "多跳基于聚类的 VANETs 中的层次联邦学习",
      "authors": [
        "M. Saeid HaghighiFard",
        "Sinem Coleri"
      ],
      "abstract": "The usage of federated learning (FL) in Vehicular Ad hoc Networks (VANET) has\ngarnered significant interest in research due to the advantages of reducing\ntransmission overhead and protecting user privacy by communicating local\ndataset gradients instead of raw data. However, implementing FL in VANETs faces\nchallenges, including limited communication resources, high vehicle mobility,\nand the statistical diversity of data distributions. In order to tackle these\nissues, this paper introduces a novel framework for hierarchical federated\nlearning (HFL) over multi-hop clustering-based VANET. The proposed method\nutilizes a weighted combination of the average relative speed and cosine\nsimilarity of FL model parameters as a clustering metric to consider both data\ndiversity and high vehicle mobility. This metric ensures convergence with\nminimum changes in cluster heads while tackling the complexities associated\nwith non-independent and identically distributed (non-IID) data scenarios.\nAdditionally, the framework includes a novel mechanism to manage seamless\ntransitions of cluster heads (CHs), followed by transferring the most recent FL\nmodel parameter to the designated CH. Furthermore, the proposed approach\nconsiders the option of merging CHs, aiming to reduce their count and,\nconsequently, mitigate associated overhead. Through extensive simulations, the\nproposed hierarchical federated learning over clustered VANET has been\ndemonstrated to improve accuracy and convergence time significantly while\nmaintaining an acceptable level of packet overhead compared to previously\nproposed clustering algorithms and non-clustered VANET.",
      "tldr_zh": "这篇论文针对车辆自组网(VANETs)中联邦学习(FL)的挑战，包括有限通信资源、高车辆移动性和数据分布多样性，提出了一种层次联邦学习(HFL)框架，基于多跳集群机制。框架采用平均相对速度和FL模型参数余弦相似度的加权组合作为聚类指标，以处理非独立同分布(non-IID)数据并最小化集群头变化，同时引入集群头无缝过渡和合并机制来减少开销。实验模拟显示，该方法显著提高了模型准确性和收敛速度，同时保持可接受的包开销水平。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DC",
        "cs.NI",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.10361v1",
      "published_date": "2024-01-18 20:05:34 UTC",
      "updated_date": "2024-01-18 20:05:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:32:52.129822"
    },
    {
      "arxiv_id": "2401.10359v1",
      "title": "Keeping Deep Learning Models in Check: A History-Based Approach to Mitigate Overfitting",
      "title_zh": "翻译失败",
      "authors": [
        "Hao Li",
        "Gopi Krishnan Rajbahadur",
        "Dayi Lin",
        "Cor-Paul Bezemer",
        "Zhen Ming",
        "Jiang"
      ],
      "abstract": "In software engineering, deep learning models are increasingly deployed for\ncritical tasks such as bug detection and code review. However, overfitting\nremains a challenge that affects the quality, reliability, and trustworthiness\nof software systems that utilize deep learning models. Overfitting can be (1)\nprevented (e.g., using dropout or early stopping) or (2) detected in a trained\nmodel (e.g., using correlation-based approaches). Both overfitting detection\nand prevention approaches that are currently used have constraints (e.g.,\nrequiring modification of the model structure, and high computing resources).\nIn this paper, we propose a simple, yet powerful approach that can both detect\nand prevent overfitting based on the training history (i.e., validation\nlosses). Our approach first trains a time series classifier on training\nhistories of overfit models. This classifier is then used to detect if a\ntrained model is overfit. In addition, our trained classifier can be used to\nprevent overfitting by identifying the optimal point to stop a model's\ntraining. We evaluate our approach on its ability to identify and prevent\noverfitting in real-world samples. We compare our approach against\ncorrelation-based detection approaches and the most commonly used prevention\napproach (i.e., early stopping). Our approach achieves an F1 score of 0.91\nwhich is at least 5% higher than the current best-performing non-intrusive\noverfitting detection approach. Furthermore, our approach can stop training to\navoid overfitting at least 32% of the times earlier than early stopping and has\nthe same or a better rate of returning the best model.",
      "tldr_zh": "本文提出了一种基于训练历史（validation losses）的方法，用于检测和预防深度学习模型的overfitting问题，以提升软件系统如bug检测和代码审查的可靠性和可信度。该方法训练一个时间序列分类器来分析过拟合模型的训练历史，从而实现对overfitting的检测，并通过识别最佳停止点来预防overfitting。与现有方法相比，该方法在真实样本上达到F1 score 0.91，比最佳非侵入式检测方法高5%，并在32%的情况下比early stopping更早停止训练，同时保持或提升返回最佳模型的性能。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.10359v1",
      "published_date": "2024-01-18 19:56:27 UTC",
      "updated_date": "2024-01-18 19:56:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:33:03.801798"
    },
    {
      "arxiv_id": "2401.10348v1",
      "title": "Exploring General Intelligence via Gated Graph Transformer in Functional Connectivity Studies",
      "title_zh": "通过门控图变换器在功能连接研究中探索一般智能",
      "authors": [
        "Gang Qu",
        "Anton Orlichenko",
        "Junqi Wang",
        "Gemeng Zhang",
        "Li Xiao",
        "Aiying Zhang",
        "Zhengming Ding",
        "Yu-Ping Wang"
      ],
      "abstract": "Functional connectivity (FC) as derived from fMRI has emerged as a pivotal\ntool in elucidating the intricacies of various psychiatric disorders and\ndelineating the neural pathways that underpin cognitive and behavioral dynamics\ninherent to the human brain. While Graph Neural Networks (GNNs) offer a\nstructured approach to represent neuroimaging data, they are limited by their\nneed for a predefined graph structure to depict associations between brain\nregions, a detail not solely provided by FCs. To bridge this gap, we introduce\nthe Gated Graph Transformer (GGT) framework, designed to predict cognitive\nmetrics based on FCs. Empirical validation on the Philadelphia\nNeurodevelopmental Cohort (PNC) underscores the superior predictive prowess of\nour model, further accentuating its potential in identifying pivotal neural\nconnectivities that correlate with human cognitive processes.",
      "tldr_zh": "本研究探讨了通过 Gated Graph Transformer (GGT) 框架在功能连接（Functional Connectivity, FC）研究中探索一般智能的问题。GGT 旨在解决 Graph Neural Networks (GNNs) 的局限性，即依赖预定义图结构的问题，通过直接基于 FC 数据预测认知指标。实验在 Philadelphia Neurodevelopmental Cohort (PNC) 数据集上验证了 GGT 的优越预测性能，并突出了其在识别与人类认知相关的关键神经连接方面的潜力。",
      "categories": [
        "q-bio.NC",
        "cs.AI"
      ],
      "primary_category": "q-bio.NC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.10348v1",
      "published_date": "2024-01-18 19:28:26 UTC",
      "updated_date": "2024-01-18 19:28:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:33:15.463909"
    },
    {
      "arxiv_id": "2401.10341v1",
      "title": "ELRT: Efficient Low-Rank Training for Compact Convolutional Neural Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Yang Sui",
        "Miao Yin",
        "Yu Gong",
        "Jinqi Xiao",
        "Huy Phan",
        "Bo Yuan"
      ],
      "abstract": "Low-rank compression, a popular model compression technique that produces\ncompact convolutional neural networks (CNNs) with low rankness, has been\nwell-studied in the literature. On the other hand, low-rank training, as an\nalternative way to train low-rank CNNs from scratch, has been exploited little\nyet. Unlike low-rank compression, low-rank training does not need pre-trained\nfull-rank models, and the entire training phase is always performed on the\nlow-rank structure, bringing attractive benefits for practical applications.\nHowever, the existing low-rank training solutions still face several\nchallenges, such as a considerable accuracy drop and/or still needing to update\nfull-size models during the training. In this paper, we perform a systematic\ninvestigation on low-rank CNN training. By identifying the proper low-rank\nformat and performance-improving strategy, we propose ELRT, an efficient\nlow-rank training solution for high-accuracy, high-compactness, low-rank CNN\nmodels. Our extensive evaluation results for training various CNNs on different\ndatasets demonstrate the effectiveness of ELRT.",
      "tldr_zh": "该论文探讨了 low-rank training 作为一种从零开始训练紧凑卷积神经网络（CNNs）的替代方法，与 low-rank compression 相比，它无需预训练全秩模型，并在低秩结构上进行整个训练过程，从而更适合实际应用。论文识别了合适的低秩格式和性能改进策略，提出 ELRT，这是一种高效的 low-rank training 解决方案，能显著减少准确率下降并避免更新全尺寸模型。实验结果显示，ELRT 在多种 CNN 和数据集上表现出色，实现了高准确率和高紧凑性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.10341v1",
      "published_date": "2024-01-18 19:09:47 UTC",
      "updated_date": "2024-01-18 19:09:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:33:27.718437"
    },
    {
      "arxiv_id": "2401.10337v3",
      "title": "Noise Contrastive Estimation-based Matching Framework for Low-Resource Security Attack Pattern Recognition",
      "title_zh": "基于噪声对比估计的匹配框架，用于低资源安全攻击模式识别",
      "authors": [
        "Tu Nguyen",
        "Nedim Šrndić",
        "Alexander Neth"
      ],
      "abstract": "Tactics, Techniques and Procedures (TTPs) represent sophisticated attack\npatterns in the cybersecurity domain, described encyclopedically in textual\nknowledge bases. Identifying TTPs in cybersecurity writing, often called TTP\nmapping, is an important and challenging task. Conventional learning approaches\noften target the problem in the classical multi-class or multilabel\nclassification setting. This setting hinders the learning ability of the model\ndue to a large number of classes (i.e., TTPs), the inevitable skewness of the\nlabel distribution and the complex hierarchical structure of the label space.\nWe formulate the problem in a different learning paradigm, where the assignment\nof a text to a TTP label is decided by the direct semantic similarity between\nthe two, thus reducing the complexity of competing solely over the large\nlabeling space. To that end, we propose a neural matching architecture with an\neffective sampling-based learn-to-compare mechanism, facilitating the learning\nprocess of the matching model despite constrained resources.",
      "tldr_zh": "该研究针对网络安全领域识别 TTPs（Tactics, Techniques and Procedures）攻击模式的挑战，提出了一种基于 Noise Contrastive Estimation 的匹配框架，以解决传统多类或多标签分类方法面临的问题，如标签数量多、分布不均和层次结构复杂。框架通过计算文本与 TTP 标签之间的直接语义相似度，将问题转化为匹配任务，并采用采样-based learn-to-compare 机制，在低资源环境下提升模型的学习效率。该方法显著降低了标签空间的竞争复杂性，有望改善 TTP 映射的准确性和实用性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.CR"
      ],
      "primary_category": "cs.LG",
      "comment": "accepted at EACL 2024, in ARR October 2023",
      "pdf_url": "http://arxiv.org/pdf/2401.10337v3",
      "published_date": "2024-01-18 19:02:00 UTC",
      "updated_date": "2024-01-30 11:40:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:33:40.511536"
    },
    {
      "arxiv_id": "2401.10316v1",
      "title": "Improving One-class Recommendation with Multi-tasking on Various Preference Intensities",
      "title_zh": "翻译失败",
      "authors": [
        "Chu-Jen Shao",
        "Hao-Ming Fu",
        "Pu-Jen Cheng"
      ],
      "abstract": "In the one-class recommendation problem, it's required to make\nrecommendations basing on users' implicit feedback, which is inferred from\ntheir action and inaction. Existing works obtain representations of users and\nitems by encoding positive and negative interactions observed from training\ndata. However, these efforts assume that all positive signals from implicit\nfeedback reflect a fixed preference intensity, which is not realistic.\nConsequently, representations learned with these methods usually fail to\ncapture informative entity features that reflect various preference\nintensities.\n  In this paper, we propose a multi-tasking framework taking various preference\nintensities of each signal from implicit feedback into consideration.\nRepresentations of entities are required to satisfy the objective of each\nsubtask simultaneously, making them more robust and generalizable. Furthermore,\nwe incorporate attentive graph convolutional layers to explore high-order\nrelationships in the user-item bipartite graph and dynamically capture the\nlatent tendencies of users toward the items they interact with. Experimental\nresults show that our method performs better than state-of-the-art methods by a\nlarge margin on three large-scale real-world benchmark datasets.",
      "tldr_zh": "本论文针对one-class recommendation问题，指出现有方法假设隐式反馈中的所有正信号具有固定preference intensities，这导致实体表示无法捕捉各种偏好强度。\n作者提出一个multi-tasking框架，通过考虑不同偏好强度，让实体表示同时满足多个子任务目标，从而提升鲁棒性和泛化性。\n此外，该框架整合注意力图卷积层，探索用户-物品二分图中的高阶关系，并动态捕捉用户潜在倾向。\n实验结果显示，该方法在三个大型真实数据集上，比最先进方法有显著提升。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.IR",
      "comment": "RecSys 2020 (ACM Conference on Recommender Systems 2020)",
      "pdf_url": "http://arxiv.org/pdf/2401.10316v1",
      "published_date": "2024-01-18 18:59:55 UTC",
      "updated_date": "2024-01-18 18:59:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:33:52.790740"
    },
    {
      "arxiv_id": "2401.10225v5",
      "title": "ChatQA: Surpassing GPT-4 on Conversational QA and RAG",
      "title_zh": "翻译失败",
      "authors": [
        "Zihan Liu",
        "Wei Ping",
        "Rajarshi Roy",
        "Peng Xu",
        "Chankyu Lee",
        "Mohammad Shoeybi",
        "Bryan Catanzaro"
      ],
      "abstract": "In this work, we introduce ChatQA, a suite of models that outperform GPT-4 on\nretrieval-augmented generation (RAG) and conversational question answering\n(QA). To enhance generation, we propose a two-stage instruction tuning method\nthat significantly boosts the performance of RAG. For effective retrieval, we\nintroduce a dense retriever optimized for conversational QA, which yields\nresults comparable to the alternative state-of-the-art query rewriting models,\nwhile substantially reducing deployment costs. We also present the ChatRAG\nBench, which encompasses ten datasets covering comprehensive evaluations on\nRAG, table-related QA, arithmetic calculations, and scenarios involving\nunanswerable questions. Our ChatQA-1.0-70B (score: 54.14), built on Llama2, a\nweaker foundation model than GPT-4, can slightly outperform GPT-4-0613 (score:\n53.90) and GPT-4-Turbo-2024-04-09 (score: 54.03) on the ChatRAG Bench, without\nrelying on any synthetic data from OpenAI GPT models. Notably, the\nLlama3-ChatQA-1.5-70B model surpasses the accuracy of GPT-4-Turbo-2024-04-09,\nachieving a 4.4% improvement. To advance research in this field, we\nopen-sourced the model weights, instruction tuning data, ChatRAG Bench, and\nretriever for the community: https://chatqa-project.github.io/.",
      "tldr_zh": "本研究引入ChatQA系列模型，在检索增强生成(RAG)和对话式问答(Conversational QA)上超越GPT-4。研究提出两阶段指令微调方法以提升RAG性能，并开发优化对话式QA的密集检索器(dense retriever)，其效果与最先进查询重写模型相当，但显著降低部署成本。同时，构建ChatRAG Bench基准，包括10个数据集，覆盖RAG、表格相关QA、算术计算和无法回答问题场景。实验结果显示，基于Llama2的ChatQA-1.0-70B在ChatRAG Bench上略超GPT-4，且Llama3-ChatQA-1.5-70B较GPT-4-Turbo提高4.4%；为促进研究，该项目开源了模型权重、指令微调数据和检索器。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted at NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2401.10225v5",
      "published_date": "2024-01-18 18:59:11 UTC",
      "updated_date": "2024-10-30 02:58:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:34:06.089857"
    },
    {
      "arxiv_id": "2401.10222v2",
      "title": "Supervised Fine-tuning in turn Improves Visual Foundation Models",
      "title_zh": "监督微调进而改善视觉基础模型",
      "authors": [
        "Xiaohu Jiang",
        "Yixiao Ge",
        "Yuying Ge",
        "Dachuan Shi",
        "Chun Yuan",
        "Ying Shan"
      ],
      "abstract": "Image-text training like CLIP has dominated the pretraining of vision\nfoundation models in recent years. Subsequent efforts have been made to\nintroduce region-level visual learning into CLIP's pretraining but face\nscalability challenges due to the lack of large-scale region-level datasets.\nDrawing inspiration from supervised fine-tuning (SFT) in natural language\nprocessing such as instruction tuning, we explore the potential of fine-grained\nSFT in enhancing the generation of vision foundation models after their\npretraining. Thus a two-stage method ViSFT (Vision SFT) is proposed to unleash\nthe fine-grained knowledge of vision foundation models. In ViSFT, the vision\nfoundation model is enhanced by performing visual joint learning on some\nin-domain tasks and then tested on out-of-domain benchmarks. With updating\nusing ViSFT on 8 V100 GPUs in less than 2 days, a vision transformer with over\n4.4B parameters shows improvements across various out-of-domain benchmarks\nincluding vision and vision-linguistic scenarios.",
      "tldr_zh": "该研究探讨了受自然语言处理中Supervised Fine-tuning (SFT)启发，在视觉基础模型预训练后进行细粒度SFT，以提升其性能。作者提出了一种两阶段方法ViSFT（Vision SFT），首先在特定领域任务上进行视觉联合学习，然后在领域外基准上评估。实验结果显示，使用ViSFT在8个V100 GPU上更新一个超过4.4B参数的Vision Transformer，仅需不到2天时间，即在各种视觉和视觉语言场景的基准测试中实现了显著改进。总的来说，这一方法为增强视觉基础模型的细粒度知识提供了可行途径。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "23 pages, 3 figures, Project page:\n  https://github.com/TencentARC/ViSFT/tree/main",
      "pdf_url": "http://arxiv.org/pdf/2401.10222v2",
      "published_date": "2024-01-18 18:58:54 UTC",
      "updated_date": "2024-04-11 17:59:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:34:17.715889"
    },
    {
      "arxiv_id": "2401.10314v2",
      "title": "LangProp: A code optimization framework using Large Language Models applied to driving",
      "title_zh": "LangProp：一个使用大型语言模型应用于驾驶的代码优化框架",
      "authors": [
        "Shu Ishida",
        "Gianluca Corrado",
        "George Fedoseev",
        "Hudson Yeo",
        "Lloyd Russell",
        "Jamie Shotton",
        "João F. Henriques",
        "Anthony Hu"
      ],
      "abstract": "We propose LangProp, a framework for iteratively optimizing code generated by\nlarge language models (LLMs), in both supervised and reinforcement learning\nsettings. While LLMs can generate sensible coding solutions zero-shot, they are\noften sub-optimal. Especially for code generation tasks, it is likely that the\ninitial code will fail on certain edge cases. LangProp automatically evaluates\nthe code performance on a dataset of input-output pairs, catches any\nexceptions, and feeds the results back to the LLM in the training loop, so that\nthe LLM can iteratively improve the code it generates. By adopting a metric-\nand data-driven training paradigm for this code optimization procedure, one\ncould easily adapt findings from traditional machine learning techniques such\nas imitation learning, DAgger, and reinforcement learning. We show LangProp's\napplicability to general domains such as Sudoku and CartPole, as well as\ndemonstrate the first proof of concept of automated code optimization for\nautonomous driving in CARLA. We show that LangProp can generate interpretable\nand transparent policies that can be verified and improved in a metric- and\ndata-driven way. Our code is available at\nhttps://github.com/shuishida/LangProp.",
      "tldr_zh": "论文提出 LangProp 框架，利用 Large Language Models (LLMs) 进行代码迭代优化，适用于监督学习和 reinforcement learning 场景，以解决 LLMs 生成代码可能存在的子优性和边缘案例失败问题。框架通过自动评估代码在数据集上的性能、捕捉异常并将结果反馈给 LLM，实现数据驱动的持续改进，同时借鉴传统机器学习技术如 imitation learning 和 DAgger。实验结果显示，LangProp 在 Sudoku、CartPole 和 CARLA 自动驾驶领域表现出色，能够生成可解释、可验证的政策，并提供开源代码以促进进一步应用。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.LG",
        "cs.RO"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.10314v2",
      "published_date": "2024-01-18 18:52:06 UTC",
      "updated_date": "2024-05-03 16:15:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:34:30.336663"
    },
    {
      "arxiv_id": "2401.10207v1",
      "title": "Eclectic Rule Extraction for Explainability of Deep Neural Network based Intrusion Detection Systems",
      "title_zh": "翻译失败",
      "authors": [
        "Jesse Ables",
        "Nathaniel Childers",
        "William Anderson",
        "Sudip Mittal",
        "Shahram Rahimi",
        "Ioana Banicescu",
        "Maria Seale"
      ],
      "abstract": "This paper addresses trust issues created from the ubiquity of black box\nalgorithms and surrogate explainers in Explainable Intrusion Detection Systems\n(X-IDS). While Explainable Artificial Intelligence (XAI) aims to enhance\ntransparency, black box surrogate explainers, such as Local Interpretable\nModel-Agnostic Explanation (LIME) and SHapley Additive exPlanation (SHAP), are\ndifficult to trust. The black box nature of these surrogate explainers makes\nthe process behind explanation generation opaque and difficult to understand.\nTo avoid this problem, one can use transparent white box algorithms such as\nRule Extraction (RE). There are three types of RE algorithms: pedagogical,\ndecompositional, and eclectic. Pedagogical methods offer fast but untrustworthy\nwhite-box explanations, while decompositional RE provides trustworthy\nexplanations with poor scalability. This work explores eclectic rule\nextraction, which strikes a balance between scalability and trustworthiness. By\ncombining techniques from pedagogical and decompositional approaches, eclectic\nrule extraction leverages the advantages of both, while mitigating some of\ntheir drawbacks. The proposed Hybrid X-IDS architecture features eclectic RE as\na white box surrogate explainer for black box Deep Neural Networks (DNN). The\npresented eclectic RE algorithm extracts human-readable rules from hidden\nlayers, facilitating explainable and trustworthy rulesets. Evaluations on\nUNSW-NB15 and CIC-IDS-2017 datasets demonstrate the algorithm's ability to\ngenerate rulesets with 99.9% accuracy, mimicking DNN outputs. The contributions\nof this work include the hybrid X-IDS architecture, the eclectic rule\nextraction algorithm applicable to intrusion detection datasets, and a thorough\nanalysis of performance and explainability, demonstrating the trade-offs\ninvolved in rule extraction speed and accuracy.",
      "tldr_zh": "这篇论文针对Explainable Intrusion Detection Systems (X-IDS)中黑盒算法和代理解释器（如LIME和SHAP）导致的信任问题，提出使用Eclectic Rule Extraction方法作为解决方案。Eclectic Rule Extraction结合pedagogical和decompositional技术，从Deep Neural Networks (DNN)的隐藏层提取可读规则，从而平衡可伸缩性和可信度。研究开发了Hybrid X-IDS架构，将该算法作为白盒代理解释器，应用于入侵检测任务。在UNSW-NB15和CIC-IDS-2017数据集上，算法生成的规则集准确率高达99.9%，成功模仿DNN输出。主要贡献包括Hybrid X-IDS架构、适用于入侵检测的Eclectic RE算法，以及对规则提取速度和准确度权衡的全面分析。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.10207v1",
      "published_date": "2024-01-18 18:45:29 UTC",
      "updated_date": "2024-01-18 18:45:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:34:42.808922"
    },
    {
      "arxiv_id": "2401.10189v4",
      "title": "Chem-FINESE: Validating Fine-Grained Few-shot Entity Extraction through Text Reconstruction",
      "title_zh": "Chem-FINESE：通过文本重构验证细粒度少样本实体抽取",
      "authors": [
        "Qingyun Wang",
        "Zixuan Zhang",
        "Hongxiang Li",
        "Xuan Liu",
        "Jiawei Han",
        "Huimin Zhao",
        "Heng Ji"
      ],
      "abstract": "Fine-grained few-shot entity extraction in the chemical domain faces two\nunique challenges. First, compared with entity extraction tasks in the general\ndomain, sentences from chemical papers usually contain more entities. Moreover,\nentity extraction models usually have difficulty extracting entities of\nlong-tailed types. In this paper, we propose Chem-FINESE, a novel\nsequence-to-sequence (seq2seq) based few-shot entity extraction approach, to\naddress these two challenges. Our Chem-FINESE has two components: a seq2seq\nentity extractor to extract named entities from the input sentence and a\nseq2seq self-validation module to reconstruct the original input sentence from\nextracted entities. Inspired by the fact that a good entity extraction system\nneeds to extract entities faithfully, our new self-validation module leverages\nentity extraction results to reconstruct the original input sentence. Besides,\nwe design a new contrastive loss to reduce excessive copying during the\nextraction process. Finally, we release ChemNER+, a new fine-grained chemical\nentity extraction dataset that is annotated by domain experts with the ChemNER\nschema. Experiments in few-shot settings with both ChemNER+ and CHEMET datasets\nshow that our newly proposed framework has contributed up to 8.26% and 6.84%\nabsolute F1-score gains respectively.",
      "tldr_zh": "本研究针对化学领域细粒度少样本实体提取（fine-grained few-shot entity extraction）面临的挑战——句子中实体数量多且长尾类型实体提取困难——提出了一种新型 seq2seq 框架 Chem-FINESE。框架包括 seq2seq 实体提取器用于从输入句子中提取命名实体，以及 seq2seq 自验证模块通过利用提取实体重建原始句子，确保提取的忠实性和准确性。同时，引入了新的对比损失（contrastive loss）来减少过度复制问题。作者还发布了新的数据集 ChemNER+，由领域专家标注，并在少样本设置下实验显示，Chem-FINESE 在 ChemNER+ 和 CHEMET 数据集上分别提升了 8.26% 和 6.84% 的 F1-score。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "16 pages. Accepted by Findings of the Association for Computational\n  Linguistics: EACL 2024. Code and resources are available at\n  https://github.com/EagleW/Chem-FINESE",
      "pdf_url": "http://arxiv.org/pdf/2401.10189v4",
      "published_date": "2024-01-18 18:20:15 UTC",
      "updated_date": "2024-05-29 18:24:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:34:53.855577"
    },
    {
      "arxiv_id": "2401.12996v1",
      "title": "A Comparison of Veterans with Problematic Opioid Use Identified through Natural Language Processing of Clinical Notes versus Using Diagnostic Codes",
      "title_zh": "翻译失败",
      "authors": [
        "Terri Elizabeth Workman",
        "Joel Kupersmith",
        "Phillip Ma",
        "Christopher Spevak",
        "Friedhelm Sandbrink",
        "Yan Cheng Qing Zeng-Treitler"
      ],
      "abstract": "Background: Electronic health records (EHRs) are a data source for opioid\nresearch. Opioid use disorder is known to be under-coded as a diagnosis, yet\nproblematic opioid use can be documented in clinical notes.\n  Objectives: Our goals were 1) to identify problematic opioid use from a full\nrange of clinical notes; and 2) to compare the characteristics of patients\nidentified as having problematic opioid use, exclusively documented in clinical\nnotes, to those having documented ICD opioid use disorder diagnostic codes.\n  Materials and Methods: We developed and applied a natural language processing\n(NLP) tool to the clinical notes of a patient cohort (n=222,371) from two\nVeteran Affairs service regions to identify patients with problematic opioid\nuse. We also used a set of ICD diagnostic codes to identify patients with\nopioid use disorder from the same cohort. We compared the demographic and\nclinical characteristics of patients identified only through NLP, to those of\npatients identified through ICD codes.\n  Results: NLP exclusively identified 57,331 patients; 6,997 patients had\npositive ICD code identifications. Patients exclusively identified through NLP\nwere more likely to be women. Those identified through ICD codes were more\nlikely to be male, younger, have concurrent benzodiazepine prescriptions, more\ncomorbidities, more care encounters, and less likely to be married. Patients in\nthe NLP and ICD groups had substantially elevated comorbidity levels compared\nto patients not documented as experiencing problematic opioid use.\n  Conclusions: NLP is a feasible approach for identifying problematic opioid\nuse not otherwise recorded by ICD codes. Clinicians may be reluctant to code\nfor opioid use disorder. It is therefore incumbent on the healthcare team to\nsearch for documentation of opioid concerns within clinical notes.",
      "tldr_zh": "这篇论文比较了使用自然语言处理(NLP)分析临床笔记与使用ICD诊断代码来识别退伍军人问题性阿片类药物使用的方法。研究团队开发了NLP工具，应用于超过22万名患者的临床笔记中，发现NLP独家识别了57,331名患者，这些患者更倾向于女性，而ICD代码仅识别了6,997名患者，且这些患者更可能是男性、更年轻、有更多合并症和就诊记录。结果显示，NLP组和ICD组患者均比无记录组有更高合并症水平，结论强调NLP是补充ICD代码的可靠方式，以捕捉未编码的问题性阿片使用。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG",
        "J.3"
      ],
      "primary_category": "cs.CL",
      "comment": "17 pages, 4 figures, 8 tables",
      "pdf_url": "http://arxiv.org/pdf/2401.12996v1",
      "published_date": "2024-01-18 18:08:16 UTC",
      "updated_date": "2024-01-18 18:08:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:35:06.752687"
    },
    {
      "arxiv_id": "2401.10178v1",
      "title": "Neural Echos: Depthwise Convolutional Filters Replicate Biological Receptive Fields",
      "title_zh": "翻译失败",
      "authors": [
        "Zahra Babaiee",
        "Peyman M. Kiasari",
        "Daniela Rus",
        "Radu Grosu"
      ],
      "abstract": "In this study, we present evidence suggesting that depthwise convolutional\nkernels are effectively replicating the structural intricacies of the\nbiological receptive fields observed in the mammalian retina. We provide\nanalytics of trained kernels from various state-of-the-art models\nsubstantiating this evidence. Inspired by this intriguing discovery, we propose\nan initialization scheme that draws inspiration from the biological receptive\nfields. Experimental analysis of the ImageNet dataset with multiple CNN\narchitectures featuring depthwise convolutions reveals a marked enhancement in\nthe accuracy of the learned model when initialized with biologically derived\nweights. This underlies the potential for biologically inspired computational\nmodels to further our understanding of vision processing systems and to improve\nthe efficacy of convolutional networks.",
      "tldr_zh": "本研究发现，depthwise convolutional filters 有效地复制了哺乳动物视网膜中的 biological receptive fields 的结构，通过分析各种最先进模型的训练核来提供证据。基于这一发现，研究者提出了一种受生物感受野启发的初始化方案，用于 CNN 架构。实验在 ImageNet 数据集上进行，结果显示，使用生物启发的权重初始化显著提高了模型准确性。这突显了生物启发计算模型在深化视觉处理系统理解和提升卷积网络效能方面的潜力。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.NE"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.10178v1",
      "published_date": "2024-01-18 18:06:22 UTC",
      "updated_date": "2024-01-18 18:06:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:35:15.711912"
    },
    {
      "arxiv_id": "2401.10148v2",
      "title": "Explicitly Disentangled Representations in Object-Centric Learning",
      "title_zh": "对象中心学习中的显式解耦表示",
      "authors": [
        "Riccardo Majellaro",
        "Jonathan Collu",
        "Aske Plaat",
        "Thomas M. Moerland"
      ],
      "abstract": "Extracting structured representations from raw visual data is an important\nand long-standing challenge in machine learning. Recently, techniques for\nunsupervised learning of object-centric representations have raised growing\ninterest. In this context, enhancing the robustness of the latent features can\nimprove the efficiency and effectiveness of the training of downstream tasks. A\npromising step in this direction is to disentangle the factors that cause\nvariation in the data. Previously, Invariant Slot Attention disentangled\nposition, scale, and orientation from the remaining features. Extending this\napproach, we focus on separating the shape and texture components. In\nparticular, we propose a novel architecture that biases object-centric models\ntoward disentangling shape and texture components into two non-overlapping\nsubsets of the latent space dimensions. These subsets are known a priori, hence\nbefore the training process. Experiments on a range of object-centric\nbenchmarks reveal that our approach achieves the desired disentanglement while\nalso numerically improving baseline performance in most cases. In addition, we\nshow that our method can generate novel textures for a specific object or\ntransfer textures between objects with distinct shapes.",
      "tldr_zh": "本文研究了在 object-centric learning 中，从原始视觉数据中提取结构化表示的挑战，特别关注于显式分离影响数据的因素。作者提出了一种新架构，基于 Invariant Slot Attention 的扩展，将形状和纹理组件预先分配到两个不重叠的潜空间子集，从而实现形状和纹理的明确分离。在多种 object-centric 基准实验中，该方法不仅实现了预期的 disentangled representations，还在大多数情况下提升了基线性能，并展示了生成新纹理或在不同形状对象之间转移纹理的能力。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Published in TMLR",
      "pdf_url": "http://arxiv.org/pdf/2401.10148v2",
      "published_date": "2024-01-18 17:22:11 UTC",
      "updated_date": "2025-01-23 10:22:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:35:29.115896"
    },
    {
      "arxiv_id": "2401.10139v1",
      "title": "Model Compression Techniques in Biometrics Applications: A Survey",
      "title_zh": "翻译失败",
      "authors": [
        "Eduarda Caldeira",
        "Pedro C. Neto",
        "Marco Huber",
        "Naser Damer",
        "Ana F. Sequeira"
      ],
      "abstract": "The development of deep learning algorithms has extensively empowered\nhumanity's task automatization capacity. However, the huge improvement in the\nperformance of these models is highly correlated with their increasing level of\ncomplexity, limiting their usefulness in human-oriented applications, which are\nusually deployed in resource-constrained devices. This led to the development\nof compression techniques that drastically reduce the computational and memory\ncosts of deep learning models without significant performance degradation. This\npaper aims to systematize the current literature on this topic by presenting a\ncomprehensive survey of model compression techniques in biometrics\napplications, namely quantization, knowledge distillation and pruning. We\nconduct a critical analysis of the comparative value of these techniques,\nfocusing on their advantages and disadvantages and presenting suggestions for\nfuture work directions that can potentially improve the current methods.\nAdditionally, we discuss and analyze the link between model bias and model\ncompression, highlighting the need to direct compression research toward model\nfairness in future works.",
      "tldr_zh": "这篇论文对模型压缩技术在生物识别(biometrics)应用中的应用进行了全面调查，旨在解决深度学习模型复杂度高、难以部署在资源受限设备上的问题。调查重点分析了quantization、knowledge distillation和pruning等技术，评估了它们的优缺点，并提供了未来改进建议。论文还讨论了模型压缩与model bias之间的关联，强调未来研究应优先考虑model fairness，以提升模型的公平性和可靠性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Under review at IEEE Journal",
      "pdf_url": "http://arxiv.org/pdf/2401.10139v1",
      "published_date": "2024-01-18 17:06:21 UTC",
      "updated_date": "2024-01-18 17:06:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:35:41.652285"
    },
    {
      "arxiv_id": "2401.10119v4",
      "title": "Towards Principled Graph Transformers",
      "title_zh": "翻译失败",
      "authors": [
        "Luis Müller",
        "Daniel Kusuma",
        "Blai Bonet",
        "Christopher Morris"
      ],
      "abstract": "Graph learning architectures based on the k-dimensional Weisfeiler-Leman\n(k-WL) hierarchy offer a theoretically well-understood expressive power.\nHowever, such architectures often fail to deliver solid predictive performance\non real-world tasks, limiting their practical impact. In contrast, global\nattention-based models such as graph transformers demonstrate strong\nperformance in practice, but comparing their expressive power with the k-WL\nhierarchy remains challenging, particularly since these architectures rely on\npositional or structural encodings for their expressivity and predictive\nperformance. To address this, we show that the recently proposed Edge\nTransformer, a global attention model operating on node pairs instead of nodes,\nhas at least 3-WL expressive power. Empirically, we demonstrate that the Edge\nTransformer surpasses other theoretically aligned architectures regarding\npredictive performance while not relying on positional or structural encodings.\nOur code is available at https://github.com/luis-mueller/towards-principled-gts",
      "tldr_zh": "本研究探讨了图学习架构的表现力问题，指出基于 k-WL hierarchy 的模型虽理论上强大，但实际预测性能较差，而 graph transformers 等全球注意力模型在实践中表现出色，却依赖位置或结构编码。论文证明了 Edge Transformer（一种在节点对上操作的全球注意力模型）至少具有 3-WL 的表现力，且无需额外编码。实验结果显示，Edge Transformer 在预测性能上超过了其他理论对齐的架构，为更可靠的图变换器设计提供了原则性指导。代码已在 GitHub 上公开。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2401.10119v4",
      "published_date": "2024-01-18 16:50:55 UTC",
      "updated_date": "2024-11-08 10:06:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:35:54.049003"
    },
    {
      "arxiv_id": "2401.10101v2",
      "title": "Bayesian Networks for Causal Analysis in Socioecological Systems",
      "title_zh": "贝叶斯网络在社会生态系统中的因果分析",
      "authors": [
        "Rafael Cabañas",
        "Ana D. Maldonado",
        "María Morales",
        "Pedro A. Aguilera",
        "Antonio Salmerón"
      ],
      "abstract": "Causal and counterfactual reasoning are emerging directions in data science\nthat allow us to reason about hypothetical scenarios. This is particularly\nuseful in fields like environmental and ecological sciences, where\ninterventional data are usually not available. Structural causal models are\nprobabilistic models for causal analysis that simplify this kind of reasoning\ndue to their graphical representation. They can be regarded as extensions of\nthe so-called Bayesian networks, a well known modeling tool commonly used in\nenvironmental and ecological problems. The main contribution of this paper is\nto analyze the relations of necessity and sufficiency between the variables of\na socioecological system using counterfactual reasoning with Bayesian networks.\nIn particular, we consider a case study involving socioeconomic factors and\nland-uses in southern Spain. In addition, this paper aims to be a coherent\noverview of the fundamental concepts for applying counterfactual reasoning, so\nthat environmental researchers with a background in Bayesian networks can\neasily take advantage of the structural causal model formalism.",
      "tldr_zh": "这篇论文探讨了在社会生态系统中应用 Bayesian Networks 进行因果分析，特别强调反事实推理（Counterfactual Reasoning）来处理假设场景，尤其在缺乏干预数据的环境和生态科学领域。论文的主要贡献是使用结构因果模型（Structural Causal Models）扩展 Bayesian Networks，以分析变量之间的必要性和充分性，并通过西班牙南部社会经济因素和土地使用的案例研究进行验证。此外，该研究为有 Bayesian Networks 背景的环境研究者提供了连贯的概述，帮助他们轻松采用这些方法进行因果推理。",
      "categories": [
        "cs.AI",
        "math.PR",
        "stat.AP"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.10101v2",
      "published_date": "2024-01-18 16:10:07 UTC",
      "updated_date": "2024-12-05 10:06:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:36:06.490787"
    },
    {
      "arxiv_id": "2401.10310v1",
      "title": "Mathematical Algorithm Design for Deep Learning under Societal and Judicial Constraints: The Algorithmic Transparency Requirement",
      "title_zh": "基于社会和司法约束的深度学习数学算法设计：算法透明度要求",
      "authors": [
        "Holger Boche",
        "Adalbert Fono",
        "Gitta Kutyniok"
      ],
      "abstract": "Deep learning still has drawbacks in terms of trustworthiness, which\ndescribes a comprehensible, fair, safe, and reliable method. To mitigate the\npotential risk of AI, clear obligations associated to trustworthiness have been\nproposed via regulatory guidelines, e.g., in the European AI Act. Therefore, a\ncentral question is to what extent trustworthy deep learning can be realized.\nEstablishing the described properties constituting trustworthiness requires\nthat the factors influencing an algorithmic computation can be retraced, i.e.,\nthe algorithmic implementation is transparent. Motivated by the observation\nthat the current evolution of deep learning models necessitates a change in\ncomputing technology, we derive a mathematical framework which enables us to\nanalyze whether a transparent implementation in a computing model is feasible.\nWe exemplarily apply our trustworthiness framework to analyze deep learning\napproaches for inverse problems in digital and analog computing models\nrepresented by Turing and Blum-Shub-Smale Machines, respectively. Based on\nprevious results, we find that Blum-Shub-Smale Machines have the potential to\nestablish trustworthy solvers for inverse problems under fairly general\nconditions, whereas Turing machines cannot guarantee trustworthiness to the\nsame degree.",
      "tldr_zh": "这篇论文探讨了在社会和司法约束（如欧盟 AI Act）下设计深度学习算法的需求，强调算法透明性以提升其可信度，包括可理解性、公平性、安全性和可靠性。作者提出一个数学框架，用于分析深度学习算法在不同计算模型中是否可实现透明实现。该框架应用于逆问题求解，比较了 Turing Machines 和 Blum-Shub-Smale Machines，结果显示 Blum-Shub-Smale Machines 在一般条件下能更好地保证可信度，而 Turing Machines 无法达到相同水平。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CC"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.10310v1",
      "published_date": "2024-01-18 15:32:38 UTC",
      "updated_date": "2024-01-18 15:32:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:36:18.871847"
    },
    {
      "arxiv_id": "2401.10061v1",
      "title": "DiffusionGPT: LLM-Driven Text-to-Image Generation System",
      "title_zh": "DiffusionGPT：LLM驱动的文本到图像生成系统",
      "authors": [
        "Jie Qin",
        "Jie Wu",
        "Weifeng Chen",
        "Yuxi Ren",
        "Huixia Li",
        "Hefeng Wu",
        "Xuefeng Xiao",
        "Rui Wang",
        "Shilei Wen"
      ],
      "abstract": "Diffusion models have opened up new avenues for the field of image\ngeneration, resulting in the proliferation of high-quality models shared on\nopen-source platforms. However, a major challenge persists in current\ntext-to-image systems are often unable to handle diverse inputs, or are limited\nto single model results. Current unified attempts often fall into two\northogonal aspects: i) parse Diverse Prompts in input stage; ii) activate\nexpert model to output. To combine the best of both worlds, we propose\nDiffusionGPT, which leverages Large Language Models (LLM) to offer a unified\ngeneration system capable of seamlessly accommodating various types of prompts\nand integrating domain-expert models. DiffusionGPT constructs domain-specific\nTrees for various generative models based on prior knowledge. When provided\nwith an input, the LLM parses the prompt and employs the Trees-of-Thought to\nguide the selection of an appropriate model, thereby relaxing input constraints\nand ensuring exceptional performance across diverse domains. Moreover, we\nintroduce Advantage Databases, where the Tree-of-Thought is enriched with human\nfeedback, aligning the model selection process with human preferences. Through\nextensive experiments and comparisons, we demonstrate the effectiveness of\nDiffusionGPT, showcasing its potential for pushing the boundaries of image\nsynthesis in diverse domains.",
      "tldr_zh": "本研究提出 DiffusionGPT，一种由大型语言模型(LLM)驱动的文本到图像生成系统，旨在解决现有 Diffusion models 在处理多样提示(Diverse Prompts)和整合专家模型(expert model)方面的局限性。系统通过构建领域特定树(domain-specific Trees)和使用 Trees-of-Thought 解析输入提示，并指导适当模型的选择，从而实现对各种类型提示的 seamless 适应和卓越性能。此外，DiffusionGPT 引入 Advantage Databases，利用人类反馈丰富决策过程，确保模型选择更符合用户偏好。实验证明，该系统在多样领域显著提升图像合成效果，展示了其推动图像生成边界的技术潜力。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.10061v1",
      "published_date": "2024-01-18 15:30:58 UTC",
      "updated_date": "2024-01-18 15:30:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:36:30.954935"
    },
    {
      "arxiv_id": "2401.10040v1",
      "title": "Large Language Models for Scientific Information Extraction: An Empirical Study for Virology",
      "title_zh": "翻译失败",
      "authors": [
        "Mahsa Shamsabadi",
        "Jennifer D'Souza",
        "Sören Auer"
      ],
      "abstract": "In this paper, we champion the use of structured and semantic content\nrepresentation of discourse-based scholarly communication, inspired by tools\nlike Wikipedia infoboxes or structured Amazon product descriptions. These\nrepresentations provide users with a concise overview, aiding scientists in\nnavigating the dense academic landscape. Our novel automated approach leverages\nthe robust text generation capabilities of LLMs to produce structured scholarly\ncontribution summaries, offering both a practical solution and insights into\nLLMs' emergent abilities.\n  For LLMs, the prime focus is on improving their general intelligence as\nconversational agents. We argue that these models can also be applied\neffectively in information extraction (IE), specifically in complex IE tasks\nwithin terse domains like Science. This paradigm shift replaces the traditional\nmodular, pipelined machine learning approach with a simpler objective expressed\nthrough instructions. Our results show that finetuned FLAN-T5 with 1000x fewer\nparameters than the state-of-the-art GPT-davinci is competitive for the task.",
      "tldr_zh": "本研究探讨了大型语言模型（LLMs）在科学信息提取（IE）领域的应用，特别针对病毒学，通过结构化和语义化内容表示（如 Wikipedia infoboxes）来提供学术摘要，帮助科学家快速导航复杂文献。研究提出了一种新方法，利用 LLMs 的文本生成能力，通过简单指令驱动自动生成结构化的学术贡献摘要，取代传统的模块化机器学习管道。实验结果显示，微调后的 FLAN-T5（参数比 GPT-davinci 少 1000 倍）在任务表现上与最先进模型相当，证明了 LLMs 在科学 IE 任务中的有效性和潜力。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.DL",
        "cs.IT",
        "math.IT"
      ],
      "primary_category": "cs.CL",
      "comment": "8 pages, 6 figures, Accepted as Findings of the ACL: EACL 2024",
      "pdf_url": "http://arxiv.org/pdf/2401.10040v1",
      "published_date": "2024-01-18 15:04:55 UTC",
      "updated_date": "2024-01-18 15:04:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:36:41.810906"
    },
    {
      "arxiv_id": "2401.10036v2",
      "title": "LOCALINTEL: Generating Organizational Threat Intelligence from Global and Local Cyber Knowledge",
      "title_zh": "LOCALINTEL：从全球和本地网络知识生成组织威胁情报",
      "authors": [
        "Shaswata Mitra",
        "Subash Neupane",
        "Trisha Chakraborty",
        "Sudip Mittal",
        "Aritran Piplai",
        "Manas Gaur",
        "Shahram Rahimi"
      ],
      "abstract": "Security Operations Center (SoC) analysts gather threat reports from openly\naccessible global threat repositories and tailor the information to their\norganization's needs, such as developing threat intelligence and security\npolicies. They also depend on organizational internal repositories, which act\nas private local knowledge database. These local knowledge databases store\ncredible cyber intelligence, critical operational and infrastructure details.\nSoCs undertake a manual labor-intensive task of utilizing these global threat\nrepositories and local knowledge databases to create both organization-specific\nthreat intelligence and mitigation policies. Recently, Large Language Models\n(LLMs) have shown the capability to process diverse knowledge sources\nefficiently. We leverage this ability to automate this organization-specific\nthreat intelligence generation. We present LocalIntel, a novel automated threat\nintelligence contextualization framework that retrieves zero-day vulnerability\nreports from the global threat repositories and uses its local knowledge\ndatabase to determine implications and mitigation strategies to alert and\nassist the SoC analyst. LocalIntel comprises two key phases: knowledge\nretrieval and contextualization. Quantitative and qualitative assessment has\nshown effectiveness in generating up to 93% accurate organizational threat\nintelligence with 64% inter-rater agreement.",
      "tldr_zh": "本研究提出 LocalIntel 框架，利用 Large Language Models (LLMs) 自动化生成组织特定的威胁情报，通过整合全球威胁仓库和本地知识数据库来解决 Security Operations Center (SoC) 分析师的手动劳动密集型任务。框架包括知识检索阶段（从全球仓库获取零日漏洞报告）和语境化阶段（利用本地数据库评估影响并制定缓解策略）。实验评估显示，LocalIntel 在生成威胁情报方面达到93%的准确率，并获得64%的评级者间一致性，为高效的网络安全情报管理提供了可扩展解决方案。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.IR",
        "cs.LO"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.10036v2",
      "published_date": "2024-01-18 15:00:01 UTC",
      "updated_date": "2025-02-09 20:56:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:36:53.738981"
    },
    {
      "arxiv_id": "2401.10034v3",
      "title": "Evolutionary Computation in the Era of Large Language Model: Survey and Roadmap",
      "title_zh": "进化计算在大语言模型时代：综述和路线图",
      "authors": [
        "Xingyu Wu",
        "Sheng-hao Wu",
        "Jibin Wu",
        "Liang Feng",
        "Kay Chen Tan"
      ],
      "abstract": "Large language models (LLMs) have not only revolutionized natural language\nprocessing but also extended their prowess to various domains, marking a\nsignificant stride towards artificial general intelligence. The interplay\nbetween LLMs and evolutionary algorithms (EAs), despite differing in objectives\nand methodologies, share a common pursuit of applicability in complex problems.\nMeanwhile, EA can provide an optimization framework for LLM's further\nenhancement under black-box settings, empowering LLM with flexible global\nsearch capacities. On the other hand, the abundant domain knowledge inherent in\nLLMs could enable EA to conduct more intelligent searches. Furthermore, the\ntext processing and generative capabilities of LLMs would aid in deploying EAs\nacross a wide range of tasks. Based on these complementary advantages, this\npaper provides a thorough review and a forward-looking roadmap, categorizing\nthe reciprocal inspiration into two main avenues: LLM-enhanced EA and\nEA-enhanced LLM. Some integrated synergy methods are further introduced to\nexemplify the complementarity between LLMs and EAs in diverse scenarios,\nincluding code generation, software engineering, neural architecture search,\nand various generation tasks. As the first comprehensive review focused on the\nEA research in the era of LLMs, this paper provides a foundational stepping\nstone for understanding the collaborative potential of LLMs and EAs. The\nidentified challenges and future directions offer guidance for researchers and\npractitioners to unlock the full potential of this innovative collaboration in\npropelling advancements in optimization and artificial intelligence. We have\ncreated a GitHub repository to index the relevant papers:\nhttps://github.com/wuxingyu-ai/LLM4EC.",
      "tldr_zh": "这篇论文对大型语言模型（LLMs）时代下的进化算法（EAs）进行了全面综述和路线图规划，探讨了二者互补的优势：EAs可作为优化框架提升LLMs的全局搜索能力，而LLMs的领域知识和生成能力能增强EAs的智能搜索。论文将互动分类为LLM-enhanced EA和EA-enhanced LLM两大类，并通过示例展示了它们在代码生成、软件工程、神经架构搜索等任务中的协同应用。最终，该综述指出了当前挑战和未来方向，为推动优化与人工智能领域的创新合作提供了基础指导，并附上了相关论文的GitHub仓库。",
      "categories": [
        "cs.NE",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.NE",
      "comment": "evolutionary algorithm (EA), large language model (LLM), optimization\n  problem, prompt engineering, algorithm generation, neural architecture search",
      "pdf_url": "http://arxiv.org/pdf/2401.10034v3",
      "published_date": "2024-01-18 14:58:17 UTC",
      "updated_date": "2024-05-29 09:00:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:37:08.029261"
    },
    {
      "arxiv_id": "2401.10032v1",
      "title": "FreGrad: Lightweight and Fast Frequency-aware Diffusion Vocoder",
      "title_zh": "FreGrad：轻量级且快速的频率感知扩散声码器",
      "authors": [
        "Tan Dat Nguyen",
        "Ji-Hoon Kim",
        "Youngjoon Jang",
        "Jaehun Kim",
        "Joon Son Chung"
      ],
      "abstract": "The goal of this paper is to generate realistic audio with a lightweight and\nfast diffusion-based vocoder, named FreGrad. Our framework consists of the\nfollowing three key components: (1) We employ discrete wavelet transform that\ndecomposes a complicated waveform into sub-band wavelets, which helps FreGrad\nto operate on a simple and concise feature space, (2) We design a\nfrequency-aware dilated convolution that elevates frequency awareness,\nresulting in generating speech with accurate frequency information, and (3) We\nintroduce a bag of tricks that boosts the generation quality of the proposed\nmodel. In our experiments, FreGrad achieves 3.7 times faster training time and\n2.2 times faster inference speed compared to our baseline while reducing the\nmodel size by 0.6 times (only 1.78M parameters) without sacrificing the output\nquality. Audio samples are available at:\nhttps://mm.kaist.ac.kr/projects/FreGrad.",
      "tldr_zh": "这篇论文提出了一种轻量级且快速的基于扩散的语音编码器FreGrad，旨在生成逼真的音频。FreGrad的关键组件包括使用discrete wavelet transform将波形分解成子带小波以简化特征空间、设计frequency-aware dilated convolution提升频率感知能力，以及引入一系列优化技巧来提高生成质量。实验结果显示，与基线模型相比，FreGrad的训练时间快3.7倍、推理速度快2.2倍，且模型大小仅为1.78M参数，同时不牺牲输出质量。",
      "categories": [
        "eess.AS",
        "cs.AI",
        "eess.SP"
      ],
      "primary_category": "eess.AS",
      "comment": "Accepted to ICASSP 2024",
      "pdf_url": "http://arxiv.org/pdf/2401.10032v1",
      "published_date": "2024-01-18 14:57:25 UTC",
      "updated_date": "2024-01-18 14:57:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:37:18.434935"
    },
    {
      "arxiv_id": "2401.10020v3",
      "title": "Self-Rewarding Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Weizhe Yuan",
        "Richard Yuanzhe Pang",
        "Kyunghyun Cho",
        "Xian Li",
        "Sainbayar Sukhbaatar",
        "Jing Xu",
        "Jason Weston"
      ],
      "abstract": "We posit that to achieve superhuman agents, future models require superhuman\nfeedback in order to provide an adequate training signal. Current approaches\ncommonly train reward models from human preferences, which may then be\nbottlenecked by human performance level, and secondly these separate frozen\nreward models cannot then learn to improve during LLM training. In this work,\nwe study Self-Rewarding Language Models, where the language model itself is\nused via LLM-as-a-Judge prompting to provide its own rewards during training.\nWe show that during Iterative DPO training that not only does instruction\nfollowing ability improve, but also the ability to provide high-quality rewards\nto itself. Fine-tuning Llama 2 70B on three iterations of our approach yields a\nmodel that outperforms many existing systems on the AlpacaEval 2.0 leaderboard,\nincluding Claude 2, Gemini Pro, and GPT-4 0613. While there is much left still\nto explore, this work opens the door to the possibility of models that can\ncontinually improve in both axes.",
      "tldr_zh": "本研究提出Self-Rewarding Language Models的概念，旨在通过让语言模型自身使用LLM-as-a-Judge提示提供反馈，从而克服传统奖励模型依赖人类偏好训练的瓶颈问题。该方法结合Iterative DPO训练，不仅提升了模型的指令遵循能力，还使模型能够生成更高质量的自我奖励。在对Llama 2 70B进行三轮微调后，该模型在AlpacaEval 2.0排行榜上超越了Claude 2、Gemini Pro和GPT-4 0613等系统，这为语言模型实现持续双向改进（指令遵循和奖励质量）打开了新可能性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "ICML 2024",
      "pdf_url": "http://arxiv.org/pdf/2401.10020v3",
      "published_date": "2024-01-18 14:43:47 UTC",
      "updated_date": "2025-03-28 00:06:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:37:30.782759"
    },
    {
      "arxiv_id": "2401.10019v3",
      "title": "R-Judge: Benchmarking Safety Risk Awareness for LLM Agents",
      "title_zh": "翻译失败",
      "authors": [
        "Tongxin Yuan",
        "Zhiwei He",
        "Lingzhong Dong",
        "Yiming Wang",
        "Ruijie Zhao",
        "Tian Xia",
        "Lizhen Xu",
        "Binglin Zhou",
        "Fangqi Li",
        "Zhuosheng Zhang",
        "Rui Wang",
        "Gongshen Liu"
      ],
      "abstract": "Large language models (LLMs) have exhibited great potential in autonomously\ncompleting tasks across real-world applications. Despite this, these LLM agents\nintroduce unexpected safety risks when operating in interactive environments.\nInstead of centering on the harmlessness of LLM-generated content in most prior\nstudies, this work addresses the imperative need for benchmarking the\nbehavioral safety of LLM agents within diverse environments. We introduce\nR-Judge, a benchmark crafted to evaluate the proficiency of LLMs in judging and\nidentifying safety risks given agent interaction records. R-Judge comprises 569\nrecords of multi-turn agent interaction, encompassing 27 key risk scenarios\namong 5 application categories and 10 risk types. It is of high-quality\ncuration with annotated safety labels and risk descriptions. Evaluation of 11\nLLMs on R-Judge shows considerable room for enhancing the risk awareness of\nLLMs: The best-performing model, GPT-4o, achieves 74.42% while no other models\nsignificantly exceed the random. Moreover, we reveal that risk awareness in\nopen agent scenarios is a multi-dimensional capability involving knowledge and\nreasoning, thus challenging for LLMs. With further experiments, we find that\nfine-tuning on safety judgment significantly improve model performance while\nstraightforward prompting mechanisms fail. R-Judge is publicly available at\nhttps://github.com/Lordog/R-Judge.",
      "tldr_zh": "这篇论文引入了 R-Judge 基准，用于评估大型语言模型 (LLMs) 代理在互动环境中的安全风险意识，重点关注代理行为而非内容无害性。R-Judge 包含 569 条多轮代理互动记录，涵盖 27 个关键风险场景、5 个应用类别和 10 个风险类型，并附带高质量的标注标签和风险描述。对 11 个 LLMs 的评估显示，GPT-4o 表现最佳，得分 74.42%，而其他模型接近随机水平，揭示风险意识涉及知识和推理等多维能力。实验进一步证明，通过 fine-tuning 可以显著提升模型性能，而简单的提示机制无效。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "EMNLP Findings 2024",
      "pdf_url": "http://arxiv.org/pdf/2401.10019v3",
      "published_date": "2024-01-18 14:40:46 UTC",
      "updated_date": "2024-10-05 06:50:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:37:44.624557"
    },
    {
      "arxiv_id": "2401.10016v1",
      "title": "Gender Bias in Machine Translation and The Era of Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Eva Vanmassenhove"
      ],
      "abstract": "This chapter examines the role of Machine Translation in perpetuating gender\nbias, highlighting the challenges posed by cross-linguistic settings and\nstatistical dependencies. A comprehensive overview of relevant existing work\nrelated to gender bias in both conventional Neural Machine Translation\napproaches and Generative Pretrained Transformer models employed as Machine\nTranslation systems is provided. Through an experiment using ChatGPT (based on\nGPT-3.5) in an English-Italian translation context, we further assess ChatGPT's\ncurrent capacity to address gender bias. The findings emphasize the ongoing\nneed for advancements in mitigating bias in Machine Translation systems and\nunderscore the importance of fostering fairness and inclusivity in language\ntechnologies.",
      "tldr_zh": "这篇论文探讨了机器翻译（Machine Translation）在延续性别偏见中的作用，特别是在跨语言设置和统计依赖性带来的挑战。论文提供了对传统Neural Machine Translation和Generative Pretrained Transformer模型（如GPT系列）相关研究的全面概述，并通过实验评估ChatGPT（基于GPT-3.5）在英语-意大利语翻译情境下的性别偏见处理能力。结果表明，ChatGPT在减轻偏见方面仍存在不足，强调了在Machine Translation系统中推进公平性和包容性的迫切需求。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.CL",
      "comment": "24 pages",
      "pdf_url": "http://arxiv.org/pdf/2401.10016v1",
      "published_date": "2024-01-18 14:34:49 UTC",
      "updated_date": "2024-01-18 14:34:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:37:55.375639"
    },
    {
      "arxiv_id": "2401.09987v2",
      "title": "Adaptive Kalman-Informed Transformer",
      "title_zh": "翻译失败",
      "authors": [
        "Nadav Cohen",
        "Itzik Klein"
      ],
      "abstract": "The extended Kalman filter (EKF) is a widely adopted method for sensor fusion\nin navigation applications. A crucial aspect of the EKF is the online\ndetermination of the process noise covariance matrix reflecting the model\nuncertainty. While common EKF implementation assumes a constant process noise,\nin real-world scenarios, the process noise varies, leading to inaccuracies in\nthe estimated state and potentially causing the filter to diverge. Model-based\nadaptive EKF methods were proposed and demonstrated performance improvements to\ncope with such situations, highlighting the need for a robust adaptive\napproach. In this paper, we derive an adaptive Kalman-informed transformer\n(A-KIT) designed to learn the varying process noise covariance online. Built\nupon the foundations of the EKF, A-KIT utilizes the well-known capabilities of\nset transformers, including inherent noise reduction and the ability to capture\nnonlinear behavior in the data. This approach is suitable for any application\ninvolving the EKF. In a case study, we demonstrate the effectiveness of A-KIT\nin nonlinear fusion between a Doppler velocity log and inertial sensors. This\nis accomplished using real data recorded from sensors mounted on an autonomous\nunderwater vehicle operating in the Mediterranean Sea. We show that A-KIT\noutperforms the conventional EKF by more than 49.5% and model-based adaptive\nEKF by an average of 35.4% in terms of position accuracy.",
      "tldr_zh": "本文提出了一种自适应卡尔曼信息 Transformer (A-KIT)，用于在线学习扩展卡尔曼滤波器 (EKF) 中的变化过程噪声协方差矩阵，以解决真实场景下模型不确定性导致的估计 inaccuracies 和滤波器发散问题。A-KIT 构建于 EKF 基础上，结合 Set Transformers 的噪声减少和非线性捕捉能力，适用于任何涉及 EKF 的导航应用。在地中海自主水下车辆的实际案例中，A-KIT 在 Doppler velocity log 和 inertial sensors 的非线性融合中，相比传统 EKF 提高了 49.5% 的位置准确率，并比基于模型的自适应 EKF 平均提升 35.4%。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.09987v2",
      "published_date": "2024-01-18 14:04:51 UTC",
      "updated_date": "2025-03-07 19:48:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:38:09.488735"
    },
    {
      "arxiv_id": "2401.09986v2",
      "title": "Improving Local Training in Federated Learning via Temperature Scaling",
      "title_zh": "通过温度缩放改善联邦学习中的本地训练",
      "authors": [
        "Kichang Lee",
        "Songkuk Kim",
        "JeongGil Ko"
      ],
      "abstract": "Federated learning is inherently hampered by data heterogeneity: non-i.i.d.\ntraining data over local clients. We propose a novel model training approach\nfor federated learning, FLex&Chill, which exploits the Logit Chilling method.\nThrough extensive evaluations, we demonstrate that, in the presence of\nnon-i.i.d. data characteristics inherent in federated learning systems, this\napproach can expedite model convergence and improve inference accuracy.\nQuantitatively, from our experiments, we observe up to 6X improvement in the\nglobal federated learning model convergence time, and up to 3.37% improvement\nin inference accuracy.",
      "tldr_zh": "这篇论文针对 Federated Learning 中的数据异质性（non-i.i.d.）问题，提出了一种新训练方法 FLex&Chill，利用 Logit Chilling 技术来优化本地训练过程。通过广泛实验评估，该方法在 non-i.i.d. 数据环境下，能加速全球模型收敛时间高达 6 倍，并将推理准确性提高至多 3.37%。这项创新有助于提升 Federated Learning 的整体效率和性能。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "68",
        "I.2.11"
      ],
      "primary_category": "cs.LG",
      "comment": "24 pages",
      "pdf_url": "http://arxiv.org/pdf/2401.09986v2",
      "published_date": "2024-01-18 14:02:23 UTC",
      "updated_date": "2024-06-26 10:16:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:38:18.512509"
    },
    {
      "arxiv_id": "2401.09983v1",
      "title": "Multiobjective Optimization Analysis for Finding Infrastructure-as-Code Deployment Configurations",
      "title_zh": "翻译失败",
      "authors": [
        "Eneko Osaba",
        "Josu Diaz-de-Arcaya",
        "Juncal Alonso",
        "Jesus L. Lobo",
        "Gorka Benguria",
        "Iñaki Etxaniz"
      ],
      "abstract": "Multiobjective optimization is a hot topic in the artificial intelligence and\noperations research communities. The design and development of multiobjective\nmethods is a frequent task for researchers and practitioners. As a result of\nthis vibrant activity, a myriad of techniques have been proposed in the\nliterature to date, demonstrating a significant effectiveness for dealing with\nsituations coming from a wide range of real-world areas. This paper is focused\non a multiobjective problem related to optimizing Infrastructure-as-Code\ndeployment configurations. The system implemented for solving this problem has\nbeen coined as IaC Optimizer Platform (IOP). Despite the fact that a\nprototypical version of the IOP has been introduced in the literature before, a\ndeeper analysis focused on the resolution of the problem is needed, in order to\ndetermine which is the most appropriate multiobjective method for embedding in\nthe IOP. The main motivation behind the analysis conducted in this work is to\nenhance the IOP performance as much as possible. This is a crucial aspect of\nthis system, deeming that it will be deployed in a real environment, as it is\nbeing developed as part of a H2020 European project. Going deeper, we resort in\nthis paper to nine different evolutionary computation-based multiobjective\nalgorithms. For assessing the quality of the considered solvers, 12 different\nproblem instances have been generated based on real-world settings. Results\nobtained by each method after 10 independent runs have been compared using\nFriedman's non-parametric tests. Findings reached from the tests carried out\nlad to the creation of a multi-algorithm system, capable of applying different\ntechniques according to the user's needs.",
      "tldr_zh": "这篇论文分析了多目标优化（Multiobjective Optimization）在优化 Infrastructure-as-Code (IaC) 部署配置中的应用，旨在提升 IaC Optimizer Platform (IOP) 的性能。研究团队使用九种基于进化计算（Evolutionary Computation）的算法，对12个基于真实设置的问题实例进行10次独立运行，并通过 Friedman's 非参数测试比较结果。最终发现表明，通过整合多种算法，IOP 可以根据用户需求动态选择最合适的优化技术，从而为真实环境部署提供更有效的解决方案。",
      "categories": [
        "cs.NE",
        "cs.AI"
      ],
      "primary_category": "cs.NE",
      "comment": "9 pages, 1 figure, 4 tables. Paper presented in the 11th\n  International Conference on Computer and Communications Management (ICCCM\n  2023)",
      "pdf_url": "http://arxiv.org/pdf/2401.09983v1",
      "published_date": "2024-01-18 13:55:32 UTC",
      "updated_date": "2024-01-18 13:55:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:38:31.361127"
    },
    {
      "arxiv_id": "2401.09966v3",
      "title": "Towards Generative Abstract Reasoning: Completing Raven's Progressive Matrix via Rule Abstraction and Selection",
      "title_zh": "迈向生成式抽象推理：通过规则抽象和",
      "authors": [
        "Fan Shi",
        "Bin Li",
        "Xiangyang Xue"
      ],
      "abstract": "Endowing machines with abstract reasoning ability has been a long-term\nresearch topic in artificial intelligence. Raven's Progressive Matrix (RPM) is\nwidely used to probe abstract visual reasoning in machine intelligence, where\nmodels will analyze the underlying rules and select one image from candidates\nto complete the image matrix. Participators of RPM tests can show powerful\nreasoning ability by inferring and combining attribute-changing rules and\nimagining the missing images at arbitrary positions of a matrix. However,\nexisting solvers can hardly manifest such an ability in realistic RPM tests. In\nthis paper, we propose a deep latent variable model for answer generation\nproblems through Rule AbstractIon and SElection (RAISE). RAISE can encode image\nattributes into latent concepts and abstract atomic rules that act on the\nlatent concepts. When generating answers, RAISE selects one atomic rule out of\nthe global knowledge set for each latent concept to constitute the underlying\nrule of an RPM. In the experiments of bottom-right and arbitrary-position\nanswer generation, RAISE outperforms the compared solvers in most\nconfigurations of realistic RPM datasets. In the odd-one-out task and two\nheld-out configurations, RAISE can leverage acquired latent concepts and atomic\nrules to find the rule-breaking image in a matrix and handle problems with\nunseen combinations of rules and attributes.",
      "tldr_zh": "该研究针对机器抽象推理能力，提出RAISE模型，用于完成Raven's Progressive Matrix (RPM)测试中的答案生成问题。RAISE通过编码图像属性为latent concepts并抽象atomic rules，来分析和组合规则，从而生成缺失图像。实验显示，RAISE在底部右边和任意位置答案生成任务中优于现有模型，并在odd-one-out任务和未见规则组合中表现出色，证明了其泛化能力。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.09966v3",
      "published_date": "2024-01-18 13:28:44 UTC",
      "updated_date": "2024-04-14 10:53:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:38:42.812852"
    },
    {
      "arxiv_id": "2401.09964v1",
      "title": "When Neural Code Completion Models Size up the Situation: Attaining Cheaper and Faster Completion through Dynamic Model Inference",
      "title_zh": "翻译失败",
      "authors": [
        "Zhensu Sun",
        "Xiaoning Du",
        "Fu Song",
        "Shangwen Wang",
        "Li Li"
      ],
      "abstract": "Leveraging recent advancements in large language models, modern neural code\ncompletion models have demonstrated the capability to generate highly accurate\ncode suggestions. However, their massive size poses challenges in terms of\ncomputational costs and environmental impact, hindering their widespread\nadoption in practical scenarios. Dynamic inference emerges as a promising\nsolution, as it allocates minimal computation during inference while\nmaintaining the model's performance. In this research, we explore dynamic\ninference within the context of code completion. Initially, we conducted an\nempirical investigation on GPT-2, focusing on the inference capabilities of\nintermediate layers for code completion. We found that 54.4% of tokens can be\naccurately generated using just the first layer, signifying significant\ncomputational savings potential. Moreover, despite using all layers, the model\nstill fails to predict 14.5% of tokens correctly, and the subsequent\ncompletions continued from them are rarely considered helpful, with only a 4.2%\nAcceptance Rate. These findings motivate our exploration of dynamic inference\nin code completion and inspire us to enhance it with a decision-making\nmechanism that stops the generation of incorrect code. We thus propose a novel\ndynamic inference method specifically tailored for code completion models. This\nmethod aims not only to produce correct predictions with largely reduced\ncomputation but also to prevent incorrect predictions proactively. Our\nextensive evaluation shows that it can averagely skip 1.7 layers out of 16\nlayers in the models, leading to an 11.2% speedup with only a marginal 1.1%\nreduction in ROUGE-L.",
      "tldr_zh": "该研究探讨了神经代码补全模型（如基于大型语言模型的系统）在计算成本和环境影响方面的挑战，提出通过动态推理（Dynamic Inference）实现更高效的代码生成。研究者首先对 GPT-2 进行实证分析，发现54.4%的标记可仅用第一层准确生成，而14.5%的标记预测失败且后续补全接受率仅4.2%，这启发了他们开发一种新方法，该方法包括决策机制来主动停止错误预测。实验结果显示，该方法平均跳过1.7层（在16层模型中），实现11.2%的加速，同时仅以1.1%的ROUGE-L分数降低为代价，从而提升了代码补全的实用性和可持续性。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "Accepted to ICSE24",
      "pdf_url": "http://arxiv.org/pdf/2401.09964v1",
      "published_date": "2024-01-18 13:26:53 UTC",
      "updated_date": "2024-01-18 13:26:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:38:56.237723"
    },
    {
      "arxiv_id": "2401.09944v1",
      "title": "WindSeer: Real-time volumetric wind prediction over complex terrain aboard a small UAV",
      "title_zh": "翻译失败",
      "authors": [
        "Florian Achermann",
        "Thomas Stastny",
        "Bogdan Danciu",
        "Andrey Kolobov",
        "Jen Jen Chung",
        "Roland Siegwart",
        "Nicholas Lawrance"
      ],
      "abstract": "Real-time high-resolution wind predictions are beneficial for various\napplications including safe manned and unmanned aviation. Current weather\nmodels require too much compute and lack the necessary predictive capabilities\nas they are valid only at the scale of multiple kilometers and hours - much\nlower spatial and temporal resolutions than these applications require. Our\nwork, for the first time, demonstrates the ability to predict low-altitude wind\nin real-time on limited-compute devices, from only sparse measurement data. We\ntrain a neural network, WindSeer, using only synthetic data from computational\nfluid dynamics simulations and show that it can successfully predict real wind\nfields over terrain with known topography from just a few noisy and spatially\nclustered wind measurements. WindSeer can generate accurate predictions at\ndifferent resolutions and domain sizes on previously unseen topography without\nretraining. We demonstrate that the model successfully predicts historical wind\ndata collected by weather stations and wind measured onboard drones.",
      "tldr_zh": "本文提出WindSeer，一种神经网络模型，用于在计算资源有限的小型无人机上，从稀疏嘈杂的风测量数据实时预测复杂地形上的低空风场。模型仅使用计算流体动力学(CFD)模拟的合成数据进行训练，便能生成不同分辨率和域大小的准确预测，且适用于未见过的地形，无需重新训练。实验结果显示，WindSeer成功预测了历史气象站数据和无人机测量的风场，填补了现有天气模型在空间和时间分辨率上的不足，为安全航空等应用提供了高效解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.09944v1",
      "published_date": "2024-01-18 12:46:26 UTC",
      "updated_date": "2024-01-18 12:46:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:39:08.985944"
    },
    {
      "arxiv_id": "2403.08773v2",
      "title": "Veagle: Advancements in Multimodal Representation Learning",
      "title_zh": "Veagle：多模态表示学习进展",
      "authors": [
        "Rajat Chawla",
        "Arkajit Datta",
        "Tushar Verma",
        "Adarsh Jha",
        "Anmol Gautam",
        "Ayush Vatsal",
        "Sukrit Chaterjee",
        "Mukunda NS",
        "Ishaan Bhola"
      ],
      "abstract": "Lately, researchers in artificial intelligence have been really interested in\nhow language and vision come together, giving rise to the development of\nmultimodal models that aim to seamlessly integrate textual and visual\ninformation. Multimodal models, an extension of Large Language Models (LLMs),\nhave exhibited remarkable capabilities in addressing a diverse array of tasks,\nranging from image captioning and visual question answering (VQA) to visual\ngrounding. While these models have showcased significant advancements,\nchallenges persist in accurately interpreting images and answering the\nquestion, a common occurrence in real-world scenarios. This paper introduces a\nnovel approach to enhance the multimodal capabilities of existing models. In\nresponse to the limitations observed in current Vision Language Models (VLMs)\nand Multimodal Large Language Models (MLLMs), our proposed model Veagle,\nincorporates a unique mechanism inspired by the successes and insights of\nprevious works. Veagle leverages a dynamic mechanism to project encoded visual\ninformation directly into the language model. This dynamic approach allows for\na more nuanced understanding of intricate details present in visual contexts.\nTo validate the effectiveness of Veagle, we conduct comprehensive experiments\non benchmark datasets, emphasizing tasks such as visual question answering and\nimage understanding. Our results indicate a improvement of 5-6 \\% in\nperformance, with Veagle outperforming existing models by a notable margin. The\noutcomes underscore the model's versatility and applicability beyond\ntraditional benchmarks.",
      "tldr_zh": "本文介绍了Veagle，一种旨在提升多模态表示学习的新模型，针对现有Vision Language Models (VLMs) 和Multimodal Large Language Models (MLLMs) 在整合文本和视觉信息时存在的挑战，如图像解释和问答准确性问题。Veagle 通过一个动态机制将编码的视觉信息直接投影到语言模型中，实现对视觉细节的更细致理解。实验结果显示，在视觉问答和图像理解等基准任务上，Veagle 比现有模型提高了5-6%的性能，并证明了其在超越传统基准的广泛适用性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.MM"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.08773v2",
      "published_date": "2024-01-18 12:45:25 UTC",
      "updated_date": "2024-10-27 06:01:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:39:21.125200"
    },
    {
      "arxiv_id": "2401.09942v1",
      "title": "Multi-task Learning for Joint Re-identification, Team Affiliation, and Role Classification for Sports Visual Tracking",
      "title_zh": "翻译失败",
      "authors": [
        "Amir M. Mansourian",
        "Vladimir Somers",
        "Christophe De Vleeschouwer",
        "Shohreh Kasaei"
      ],
      "abstract": "Effective tracking and re-identification of players is essential for\nanalyzing soccer videos. But, it is a challenging task due to the non-linear\nmotion of players, the similarity in appearance of players from the same team,\nand frequent occlusions. Therefore, the ability to extract meaningful\nembeddings to represent players is crucial in developing an effective tracking\nand re-identification system. In this paper, a multi-purpose part-based person\nrepresentation method, called PRTreID, is proposed that performs three tasks of\nrole classification, team affiliation, and re-identification, simultaneously.\nIn contrast to available literature, a single network is trained with\nmulti-task supervision to solve all three tasks, jointly. The proposed joint\nmethod is computationally efficient due to the shared backbone. Also, the\nmulti-task learning leads to richer and more discriminative representations, as\ndemonstrated by both quantitative and qualitative results. To demonstrate the\neffectiveness of PRTreID, it is integrated with a state-of-the-art tracking\nmethod, using a part-based post-processing module to handle long-term tracking.\nThe proposed tracking method outperforms all existing tracking methods on the\nchallenging SoccerNet tracking dataset.",
      "tldr_zh": "这篇论文提出了一种多任务学习方法 PRTreID，用于体育视觉跟踪，旨在同时处理玩家的再识别（Re-identification）、团队归属（Team Affiliation）和角色分类（Role Classification），以应对足球视频中非线性运动、相似外观和遮挡等挑战。PRTreID 通过一个共享主干网络的多任务监督训练，生成更丰富且区分性强的玩家表示，从而提升计算效率。实验结果显示，该方法整合到先进的跟踪系统中后，在 SoccerNet 数据集上优于现有跟踪方法，提供更有效的跟踪和分析性能。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.09942v1",
      "published_date": "2024-01-18 12:45:14 UTC",
      "updated_date": "2024-01-18 12:45:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:39:31.853229"
    },
    {
      "arxiv_id": "2401.10304v2",
      "title": "On the Readiness of Scientific Data for a Fair and Transparent Use in Machine Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Joan Giner-Miguelez",
        "Abel Gómez",
        "Jordi Cabot"
      ],
      "abstract": "To ensure the fairness and trustworthiness of machine learning (ML) systems,\nrecent legislative initiatives and relevant research in the ML community have\npointed out the need to document the data used to train ML models. Besides,\ndata-sharing practices in many scientific domains have evolved in recent years\nfor reproducibility purposes. In this sense, academic institutions' adoption of\nthese practices has encouraged researchers to publish their data and technical\ndocumentation in peer-reviewed publications such as data papers. In this study,\nwe analyze how this broader scientific data documentation meets the needs of\nthe ML community and regulatory bodies for its use in ML technologies. We\nexamine a sample of 4041 data papers of different domains, assessing their\ncompleteness, coverage of the requested dimensions, and trends in recent years.\nWe focus on the most and least documented dimensions and compare the results\nwith those of an ML-focused venue (NeurIPS D&B track) publishing papers\ndescribing datasets. As a result, we propose a set of recommendation guidelines\nfor data creators and scientific data publishers to increase their data's\npreparedness for its transparent and fairer use in ML technologies.",
      "tldr_zh": "本研究评估了科学数据文档是否满足机器学习(ML)系统公平和透明使用的需求，通过分析4041篇跨领域数据论文，检查其完整性、维度覆盖以及最近趋势，并与NeurIPS D&B track的论文进行比较。结果显示，大多数数据论文在某些维度（如数据共享实践）记录较充分，但其他维度（如公平性相关信息）存在不足。作者据此提出了一套推荐指南，针对数据创建者和科学数据出版者，以提升数据在ML技术中的准备度。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.10304v2",
      "published_date": "2024-01-18 12:11:27 UTC",
      "updated_date": "2024-12-17 16:34:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:39:45.249836"
    },
    {
      "arxiv_id": "2401.09900v1",
      "title": "XAI-Enhanced Semantic Segmentation Models for Visual Quality Inspection",
      "title_zh": "XAI 增强的语义分割模型用于视觉质量",
      "authors": [
        "Tobias Clement",
        "Truong Thanh Hung Nguyen",
        "Mohamed Abdelaal",
        "Hung Cao"
      ],
      "abstract": "Visual quality inspection systems, crucial in sectors like manufacturing and\nlogistics, employ computer vision and machine learning for precise, rapid\ndefect detection. However, their unexplained nature can hinder trust, error\nidentification, and system improvement. This paper presents a framework to\nbolster visual quality inspection by using CAM-based explanations to refine\nsemantic segmentation models. Our approach consists of 1) Model Training, 2)\nXAI-based Model Explanation, 3) XAI Evaluation, and 4) Annotation Augmentation\nfor Model Enhancement, informed by explanations and expert insights.\nEvaluations show XAI-enhanced models surpass original DeepLabv3-ResNet101\nmodels, especially in intricate object segmentation.",
      "tldr_zh": "该论文提出了一种XAI（可解释AI）增强的语义分割模型框架，用于视觉质量检查系统，以解决传统模型的可解释性不足问题。该框架包括四个关键步骤：模型训练、基于CAM（Class Activation Maps）的模型解释、XAI评估以及利用解释和专家见解进行标注增强，从而改进模型性能。实验结果显示，XAI增强后的模型在复杂对象分割任务上超过了原DeepLabv3-ResNet101模型，提高了缺陷检测的准确性和可靠性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "IEEE ICCE 2024",
      "pdf_url": "http://arxiv.org/pdf/2401.09900v1",
      "published_date": "2024-01-18 11:26:20 UTC",
      "updated_date": "2024-01-18 11:26:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:39:55.799728"
    },
    {
      "arxiv_id": "2401.09886v2",
      "title": "Cooperative Edge Caching Based on Elastic Federated and Multi-Agent Deep Reinforcement Learning in Next-Generation Network",
      "title_zh": "翻译失败",
      "authors": [
        "Qiong Wu",
        "Wenhua Wang",
        "Pingyi Fan",
        "Qiang Fan",
        "Huiling Zhu",
        "Khaled B. Letaief"
      ],
      "abstract": "Edge caching is a promising solution for next-generation networks by\nempowering caching units in small-cell base stations (SBSs), which allows user\nequipments (UEs) to fetch users' requested contents that have been pre-cached\nin SBSs. It is crucial for SBSs to predict accurate popular contents through\nlearning while protecting users' personal information. Traditional federated\nlearning (FL) can protect users' privacy but the data discrepancies among UEs\ncan lead to a degradation in model quality. Therefore, it is necessary to train\npersonalized local models for each UE to predict popular contents accurately.\nIn addition, the cached contents can be shared among adjacent SBSs in\nnext-generation networks, thus caching predicted popular contents in different\nSBSs may affect the cost to fetch contents. Hence, it is critical to determine\nwhere the popular contents are cached cooperatively. To address these issues,\nwe propose a cooperative edge caching scheme based on elastic federated and\nmulti-agent deep reinforcement learning (CEFMR) to optimize the cost in the\nnetwork. We first propose an elastic FL algorithm to train the personalized\nmodel for each UE, where adversarial autoencoder (AAE) model is adopted for\ntraining to improve the prediction accuracy, then {a popular} content\nprediction algorithm is proposed to predict the popular contents for each SBS\nbased on the trained AAE model. Finally, we propose a multi-agent deep\nreinforcement learning (MADRL) based algorithm to decide where the predicted\npopular contents are collaboratively cached among SBSs. Our experimental\nresults demonstrate the superiority of our proposed scheme to existing baseline\ncaching schemes.",
      "tldr_zh": "本文提出了一种合作边缘缓存方案（Cooperative Edge Caching Scheme Based on Elastic Federated and Multi-Agent Deep Reinforcement Learning, CEFMR），旨在优化下一代网络中的内容缓存成本，同时保护用户隐私并处理数据差异问题。该方案首先采用弹性 Federated Learning (FL) 算法结合 Adversarial Autoencoder (AAE) 模型，为每个用户设备 (UE) 训练个性化模型，以提高热门内容预测的准确性。随后，利用 Multi-Agent Deep Reinforcement Learning (MADRL) 算法，实现相邻小基站 (SBSs) 之间的协作决策，确定热门内容的缓存位置。实验结果显示，该方案在预测准确性和网络成本优化方面优于现有基线方案。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "This paper has been submitted to IEEE TNSM. The source code has been\n  released at:\n  https://github.com/qiongwu86/Edge-Caching-Based-on-Multi-Agent-Deep-Reinforcement-Learning-and-Federated-Learning",
      "pdf_url": "http://arxiv.org/pdf/2401.09886v2",
      "published_date": "2024-01-18 10:59:18 UTC",
      "updated_date": "2024-06-05 00:35:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:40:10.575756"
    },
    {
      "arxiv_id": "2401.10946v1",
      "title": "Self context-aware emotion perception on human-robot interaction",
      "title_zh": "翻译失败",
      "authors": [
        "Zihan Lin",
        "Francisco Cruz",
        "Eduardo Benitez Sandoval"
      ],
      "abstract": "Emotion recognition plays a crucial role in various domains of human-robot\ninteraction. In long-term interactions with humans, robots need to respond\ncontinuously and accurately, however, the mainstream emotion recognition\nmethods mostly focus on short-term emotion recognition, disregarding the\ncontext in which emotions are perceived. Humans consider that contextual\ninformation and different contexts can lead to completely different emotional\nexpressions. In this paper, we introduce self context-aware model (SCAM) that\nemploys a two-dimensional emotion coordinate system for anchoring and\nre-labeling distinct emotions. Simultaneously, it incorporates its distinctive\ninformation retention structure and contextual loss. This approach has yielded\nsignificant improvements across audio, video, and multimodal. In the auditory\nmodality, there has been a notable enhancement in accuracy, rising from 63.10%\nto 72.46%. Similarly, the visual modality has demonstrated improved accuracy,\nincreasing from 77.03% to 80.82%. In the multimodal, accuracy has experienced\nan elevation from 77.48% to 78.93%. In the future, we will validate the\nreliability and usability of SCAM on robots through psychology experiments.",
      "tldr_zh": "本文提出了一种自上下文感知模型(SCAM)，旨在解决人机交互中情感识别的上下文忽略问题，该模型使用二维情感坐标系统进行情感锚定和重新标记，并结合独特的信息保留结构和上下文损失，以提升长期情感感知的准确性。在实验中，SCAM 在音频模态的准确率从63.10%提高到72.46%，视频模态从77.03%提高到80.82%，多模态从77.48%提高到78.93%。未来，该模型将通过心理学实验在机器人上验证其可靠性和可用性。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "Australasian Conference on Robotics and Automation (ACRA). 2023",
      "pdf_url": "http://arxiv.org/pdf/2401.10946v1",
      "published_date": "2024-01-18 10:58:27 UTC",
      "updated_date": "2024-01-18 10:58:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:40:22.821656"
    },
    {
      "arxiv_id": "2401.09880v1",
      "title": "Attention-Based Recurrent Neural Network For Automatic Behavior Laying Hen Recognition",
      "title_zh": "翻译失败",
      "authors": [
        "Fréjus A. A. Laleye",
        "Mikaël A. Mousse"
      ],
      "abstract": "One of the interests of modern poultry farming is the vocalization of laying\nhens which contain very useful information on health behavior. This information\nis used as health and well-being indicators that help breeders better monitor\nlaying hens, which involves early detection of problems for rapid and more\neffective intervention. In this work, we focus on the sound analysis for the\nrecognition of the types of calls of the laying hens in order to propose a\nrobust system of characterization of their behavior for a better monitoring. To\ndo this, we first collected and annotated laying hen call signals, then\ndesigned an optimal acoustic characterization based on the combination of time\nand frequency domain features. We then used these features to build the\nmulti-label classification models based on recurrent neural network to assign a\nsemantic class to the vocalization that characterize the laying hen behavior.\nThe results show an overall performance with our model based on the combination\nof time and frequency domain features that obtained the highest F1-score\n(F1=92.75) with a gain of 17% on the models using the frequency domain features\nand of 8% on the compared approaches from the litterature.",
      "tldr_zh": "本研究聚焦于通过母鸡叫声分析自动识别其行为类型，以提升家禽养殖中的健康监测和早期问题干预。首先，研究团队收集并标注了母鸡叫声信号，并设计了基于时间和频率域特征的声学表征。然后，使用基于Recurrent Neural Network (RNN)的多标签分类模型，对叫声进行语义分类，以表征母鸡行为。结果表明，该模型取得了最高的F1-score（92.75%），比仅使用频率域特征的模型提高了17%，并比文献中的方法高出8%。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.CL",
        "cs.LG",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.09880v1",
      "published_date": "2024-01-18 10:52:46 UTC",
      "updated_date": "2024-01-18 10:52:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:40:33.361796"
    },
    {
      "arxiv_id": "2401.09870v2",
      "title": "Reconciling Spatial and Temporal Abstractions for Goal Representation",
      "title_zh": "调和空间抽象与时间抽象用于目标表示",
      "authors": [
        "Mehdi Zadem",
        "Sergio Mover",
        "Sao Mai Nguyen"
      ],
      "abstract": "Goal representation affects the performance of Hierarchical Reinforcement\nLearning (HRL) algorithms by decomposing the complex learning problem into\neasier subtasks. Recent studies show that representations that preserve\ntemporally abstract environment dynamics are successful in solving difficult\nproblems and provide theoretical guarantees for optimality. These methods\nhowever cannot scale to tasks where environment dynamics increase in complexity\ni.e. the temporally abstract transition relations depend on larger number of\nvariables. On the other hand, other efforts have tried to use spatial\nabstraction to mitigate the previous issues. Their limitations include\nscalability to high dimensional environments and dependency on prior knowledge.\n  In this paper, we propose a novel three-layer HRL algorithm that introduces,\nat different levels of the hierarchy, both a spatial and a temporal goal\nabstraction. We provide a theoretical study of the regret bounds of the learned\npolicies. We evaluate the approach on complex continuous control tasks,\ndemonstrating the effectiveness of spatial and temporal abstractions learned by\nthis approach. Find open-source code at https://github.com/cosynus-lix/STAR.",
      "tldr_zh": "该论文探讨了目标表示在分层强化学习 (HRL) 中的作用，旨在通过整合时间抽象和空间抽象来解决复杂任务的挑战。作者提出了一种新型三层 HRL 算法，在不同层次引入空间和时间目标抽象，以提升算法在高复杂度环境下的可扩展性和性能。该方法提供了 regret bounds 的理论分析，并在复杂连续控制任务上进行评估，证明了其有效性。开源代码可从 https://github.com/cosynus-lix/STAR 获取。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.09870v2",
      "published_date": "2024-01-18 10:33:30 UTC",
      "updated_date": "2024-06-30 09:02:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:40:43.688748"
    },
    {
      "arxiv_id": "2401.09865v1",
      "title": "Improving fine-grained understanding in image-text pre-training",
      "title_zh": "改进图像-文本预训练中的细粒度理解",
      "authors": [
        "Ioana Bica",
        "Anastasija Ilić",
        "Matthias Bauer",
        "Goker Erdogan",
        "Matko Bošnjak",
        "Christos Kaplanis",
        "Alexey A. Gritsenko",
        "Matthias Minderer",
        "Charles Blundell",
        "Razvan Pascanu",
        "Jovana Mitrović"
      ],
      "abstract": "We introduce SPARse Fine-grained Contrastive Alignment (SPARC), a simple\nmethod for pretraining more fine-grained multimodal representations from\nimage-text pairs. Given that multiple image patches often correspond to single\nwords, we propose to learn a grouping of image patches for every token in the\ncaption. To achieve this, we use a sparse similarity metric between image\npatches and language tokens and compute for each token a language-grouped\nvision embedding as the weighted average of patches. The token and\nlanguage-grouped vision embeddings are then contrasted through a fine-grained\nsequence-wise loss that only depends on individual samples and does not require\nother batch samples as negatives. This enables more detailed information to be\nlearned in a computationally inexpensive manner. SPARC combines this\nfine-grained loss with a contrastive loss between global image and text\nembeddings to learn representations that simultaneously encode global and local\ninformation. We thoroughly evaluate our proposed method and show improved\nperformance over competing approaches both on image-level tasks relying on\ncoarse-grained information, e.g. classification, as well as region-level tasks\nrelying on fine-grained information, e.g. retrieval, object detection, and\nsegmentation. Moreover, SPARC improves model faithfulness and captioning in\nfoundational vision-language models.",
      "tldr_zh": "该论文提出了 SPARse Fine-grained Contrastive Alignment (SPARC)，一种简单方法，用于从图像-文本对中预训练更细粒度的多模态表示。SPARC 通过稀疏相似性 metric 计算每个语言标记对应的图像 patch 分组，并生成语言-grouped vision embedding，然后使用 fine-grained sequence-wise loss 对比这些嵌入，以学习更详细的信息，同时结合全局图像和文本嵌入的对比损失。相比传统方法，该框架在计算上更高效，能同时编码全局和局部信息。实验结果显示，SPARC 在图像级任务（如分类）和区域级任务（如检索、对象检测和分割）上性能优于竞争方法，并提高了模型的忠实度和图像描述能力。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "26 pages",
      "pdf_url": "http://arxiv.org/pdf/2401.09865v1",
      "published_date": "2024-01-18 10:28:45 UTC",
      "updated_date": "2024-01-18 10:28:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:40:58.252769"
    },
    {
      "arxiv_id": "2401.09862v1",
      "title": "Evolutionary Multi-Objective Optimization of Large Language Model Prompts for Balancing Sentiments",
      "title_zh": "翻译失败",
      "authors": [
        "Jill Baumann",
        "Oliver Kramer"
      ],
      "abstract": "The advent of large language models (LLMs) such as ChatGPT has attracted\nconsiderable attention in various domains due to their remarkable performance\nand versatility. As the use of these models continues to grow, the importance\nof effective prompt engineering has come to the fore. Prompt optimization\nemerges as a crucial challenge, as it has a direct impact on model performance\nand the extraction of relevant information. Recently, evolutionary algorithms\n(EAs) have shown promise in addressing this issue, paving the way for novel\noptimization strategies. In this work, we propose a evolutionary\nmulti-objective (EMO) approach specifically tailored for prompt optimization\ncalled EMO-Prompts, using sentiment analysis as a case study. We use sentiment\nanalysis capabilities as our experimental targets. Our results demonstrate that\nEMO-Prompts effectively generates prompts capable of guiding the LLM to produce\ntexts embodying two conflicting emotions simultaneously.",
      "tldr_zh": "这篇论文提出了一种进化多目标优化（Evolutionary Multi-Objective Optimization）方法，名为 EMO-Prompts，用于优化大型语言模型（LLMs）的提示工程，以情感分析为例。方法利用进化算法（EAs）来处理提示优化面临的挑战，确保模型能够平衡并生成体现两种冲突情感的文本。实验结果表明，EMO-Prompts 有效提升了 LLM 在情感平衡任务中的性能，为提示优化提供了新策略。",
      "categories": [
        "cs.NE",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.NE",
      "comment": "Accepted in EvoApps at EvoStar 2024",
      "pdf_url": "http://arxiv.org/pdf/2401.09862v1",
      "published_date": "2024-01-18 10:21:15 UTC",
      "updated_date": "2024-01-18 10:21:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:41:08.582791"
    },
    {
      "arxiv_id": "2401.09861v1",
      "title": "Temporal Insight Enhancement: Mitigating Temporal Hallucination in Multimodal Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Li Sun",
        "Liuan Wang",
        "Jun Sun",
        "Takayuki Okatani"
      ],
      "abstract": "Recent advancements in Multimodal Large Language Models (MLLMs) have\nsignificantly enhanced the comprehension of multimedia content, bringing\ntogether diverse modalities such as text, images, and videos. However, a\ncritical challenge faced by these models, especially when processing video\ninputs, is the occurrence of hallucinations - erroneous perceptions or\ninterpretations, particularly at the event level. This study introduces an\ninnovative method to address event-level hallucinations in MLLMs, focusing on\nspecific temporal understanding in video content. Our approach leverages a\nnovel framework that extracts and utilizes event-specific information from both\nthe event query and the provided video to refine MLLMs' response. We propose a\nunique mechanism that decomposes on-demand event queries into iconic actions.\nSubsequently, we employ models like CLIP and BLIP2 to predict specific\ntimestamps for event occurrences. Our evaluation, conducted using the\nCharades-STA dataset, demonstrates a significant reduction in temporal\nhallucinations and an improvement in the quality of event-related responses.\nThis research not only provides a new perspective in addressing a critical\nlimitation of MLLMs but also contributes a quantitatively measurable method for\nevaluating MLLMs in the context of temporal-related questions.",
      "tldr_zh": "本研究针对 Multimodal Large Language Models (MLLMs) 在处理视频时存在的 temporal hallucination（时间幻觉）问题，提出了一种创新框架来提升事件级别的时间理解。方法包括从事件查询和视频中提取特定信息，将查询分解成 iconic actions，并利用 CLIP 和 BLIP2 模型预测事件发生的精确时间戳。通过在 Charades-STA 数据集上的评估，该框架显著减少了 temporal hallucinations，提高了事件相关响应的质量，并提供了一种可量化的评估方法。研究为解决 MLLMs 的关键局限性提供了新视角。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "7 pages, 7 figures",
      "pdf_url": "http://arxiv.org/pdf/2401.09861v1",
      "published_date": "2024-01-18 10:18:48 UTC",
      "updated_date": "2024-01-18 10:18:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:41:20.926994"
    },
    {
      "arxiv_id": "2401.09852v1",
      "title": "Enhancing the Fairness and Performance of Edge Cameras with Explainable AI",
      "title_zh": "翻译失败",
      "authors": [
        "Truong Thanh Hung Nguyen",
        "Vo Thanh Khang Nguyen",
        "Quoc Hung Cao",
        "Van Binh Truong",
        "Quoc Khanh Nguyen",
        "Hung Cao"
      ],
      "abstract": "The rising use of Artificial Intelligence (AI) in human detection on Edge\ncamera systems has led to accurate but complex models, challenging to interpret\nand debug. Our research presents a diagnostic method using Explainable AI (XAI)\nfor model debugging, with expert-driven problem identification and solution\ncreation. Validated on the Bytetrack model in a real-world office Edge network,\nwe found the training dataset as the main bias source and suggested model\naugmentation as a solution. Our approach helps identify model biases, essential\nfor achieving fair and trustworthy models.",
      "tldr_zh": "这篇论文提出了一种基于 Explainable AI (XAI) 的诊断方法，用于提升边缘摄像头系统在人类检测中的公平性和性能，从而解决模型复杂性带来的解释和调试挑战。该方法通过专家驱动的方式识别模型偏见，并在真实办公室边缘网络上验证了 Bytetrack 模型。研究发现，训练数据集是主要偏见来源，并建议采用模型增强作为解决方案。这种方法有助于识别和缓解模型偏见，最终实现更公平且可信赖的 AI 系统。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "IEEE ICCE 2024",
      "pdf_url": "http://arxiv.org/pdf/2401.09852v1",
      "published_date": "2024-01-18 10:08:24 UTC",
      "updated_date": "2024-01-18 10:08:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:41:31.785227"
    },
    {
      "arxiv_id": "2401.09851v4",
      "title": "Next-Generation Simulation Illuminates Scientific Problems of Organised Complexity",
      "title_zh": "下一代模拟阐明有组织的复杂性科学问题",
      "authors": [
        "Cheng Wang",
        "Chuwen Wang",
        "Wang Zhang",
        "Shirong Zeng",
        "Yu Zhao",
        "Ronghui Ning",
        "Changjun Jiang"
      ],
      "abstract": "As artificial intelligence becomes increasingly prevalent in scientific\nresearch, data-driven methodologies appear to overshadow traditional approaches\nin resolving scientific problems. In this Perspective, we revisit a classic\nclassification of scientific problems and acknowledge that a series of\nunresolved problems remain. Throughout the history of researching scientific\nproblems, scientists have continuously formed new paradigms facilitated by\nadvances in data, algorithms, and computational power. To better tackle\nunresolved problems, especially those of organised complexity, a novel paradigm\nis necessitated. While recognising that the strengths of new paradigms have\nexpanded the scope of resolvable scientific problems, we aware that the\ncontinued advancement of data, algorithms, and computational power alone is\nhardly to bring a new paradigm. We posit that the integration of paradigms,\nwhich capitalises on the strengths of each, represents a promising approach.\nSpecifically, we focus on next-generation simulation (NGS), which can serve as\na platform to integrate methods from different paradigms. We propose a\nmethodology, sophisticated behavioural simulation (SBS), to realise it. SBS\nrepresents a higher level of paradigms integration based on foundational models\nto simulate complex systems, such as social systems involving sophisticated\nhuman strategies and behaviours. NGS extends beyond the capabilities of\ntraditional mathematical modelling simulations and agent-based modelling\nsimulations, and therefore, positions itself as a potential solution to\nproblems of organised complexity in complex systems.",
      "tldr_zh": "本论文回顾了科学问题的经典分类，指出尽管人工智能和数据驱动方法在研究中日益主导，但诸如“organised complexity”的复杂系统问题仍未得到充分解决。作者强调，仅依赖数据、算法和计算能力的进步不足以形成新范式，而是需要整合多种范式来应对这些挑战。具体地，论文提出“Next-Generation Simulation (NGS)”作为整合平台，并引入“Sophisticated Behavioural Simulation (SBS)”方法，利用基础模型模拟复杂系统，如涉及人类策略的社会系统。实验和理论分析显示，NGS 超越了传统数学建模和基于代理的模拟，能够有效解决复杂系统的“organised complexity”问题，从而为科学研究的创新提供新路径。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.09851v4",
      "published_date": "2024-01-18 10:05:52 UTC",
      "updated_date": "2024-06-14 11:31:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:41:44.597015"
    },
    {
      "arxiv_id": "2401.09833v1",
      "title": "Slicer Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Hang Zhang",
        "Xiang Chen",
        "Rongguang Wang",
        "Renjiu Hu",
        "Dongdong Liu",
        "Gaolei Li"
      ],
      "abstract": "In medical imaging, scans often reveal objects with varied contrasts but\nconsistent internal intensities or textures. This characteristic enables the\nuse of low-frequency approximations for tasks such as segmentation and\ndeformation field estimation. Yet, integrating this concept into neural network\narchitectures for medical image analysis remains underexplored. In this paper,\nwe propose the Slicer Network, a novel architecture designed to leverage these\ntraits. Comprising an encoder utilizing models like vision transformers for\nfeature extraction and a slicer employing a learnable bilateral grid, the\nSlicer Network strategically refines and upsamples feature maps via a\nsplatting-blurring-slicing process. This introduces an edge-preserving\nlow-frequency approximation for the network outcome, effectively enlarging the\neffective receptive field. The enhancement not only reduces computational\ncomplexity but also boosts overall performance. Experiments across different\nmedical imaging applications, including unsupervised and keypoints-based image\nregistration and lesion segmentation, have verified the Slicer Network's\nimproved accuracy and efficiency.",
      "tldr_zh": "本研究针对医疗成像中对象内部强度一致的特性，提出了一种新型Slicer Network架构，以利用低频近似提升任务性能，如图像分割和变形场估计。Slicer Network包括使用vision transformers的编码器提取特征，以及一个基于可学习bilateral grid的slicer模块，通过splatting-blurring-slicing过程细化并上采样特征图，实现边沿保留的低频近似，从而扩大有效感受野并降低计算复杂性。实验结果显示，该架构在无监督和关键点-based image registration以及lesion segmentation等应用中，显著提高了准确性和效率。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "8 figures and 3 tables",
      "pdf_url": "http://arxiv.org/pdf/2401.09833v1",
      "published_date": "2024-01-18 09:50:26 UTC",
      "updated_date": "2024-01-18 09:50:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:41:57.245884"
    },
    {
      "arxiv_id": "2401.09819v2",
      "title": "PPNet: A Two-Stage Neural Network for End-to-end Path Planning",
      "title_zh": "PPNet：一种两阶段神经网络用于端到端路径规划",
      "authors": [
        "Qinglong Meng",
        "Chongkun Xia",
        "Xueqian Wang",
        "Songping Mai",
        "Bin Liang"
      ],
      "abstract": "The classical path planners, such as sampling-based path planners, can\nprovide probabilistic completeness guarantees in the sense that the probability\nthat the planner fails to return a solution if one exists, decays to zero as\nthe number of samples approaches infinity. However, finding a near-optimal\nfeasible solution in a given period is challenging in many applications such as\nthe autonomous vehicle. To achieve an end-to-end near-optimal path planner, we\nfirst divide the path planning problem into two subproblems, which are path\nspace segmentation and waypoints generation in the given path's space. We\nfurther propose a two-stage neural network named Path Planning Network (PPNet)\neach stage solves one of the subproblems abovementioned. Moreover, we propose a\nnovel efficient data generation method for path planning named EDaGe-PP.\nEDaGe-PP can generate data with continuous-curvature paths with analytical\nexpression while satisfying the clearance requirement. The results show the\ntotal computation time of generating random 2D path planning data is less than\n1/33 and the success rate of PPNet trained by the dataset that is generated by\nEDaGe-PP is about 2 times compared to other methods. We validate PPNet against\nstate-of-the-art path planning methods. The results show that PPNet can find a\nnear-optimal solution in 15.3ms, which is much shorter than the\nstate-of-the-art path planners.",
      "tldr_zh": "该论文提出 PPNet，一种两阶段神经网络，用于端到端的路径规划，旨在解决传统采样-based 方法在实时应用（如自动驾驶）中难以快速找到近优解的问题。PPNet 将路径规划问题分为路径空间分割和路径点生成两个子问题，每个阶段分别由神经网络处理，同时引入 EDaGe-PP 一种高效数据生成方法，能生成满足连续曲率和间距要求的路径数据。实验结果显示，EDaGe-PP 的数据生成时间不到其他方法的1/33，PPNet 的成功率提高约2倍，并在15.3ms 内找到近优解，显著优于现有路径规划方法。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.09819v2",
      "published_date": "2024-01-18 09:20:27 UTC",
      "updated_date": "2024-04-23 09:21:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:42:09.808190"
    },
    {
      "arxiv_id": "2402.01673v1",
      "title": "Legal and ethical implications of applications based on agreement technologies: the case of auction-based road intersections",
      "title_zh": "基于协议技术的应用的法律和伦理含义：拍卖式道路交叉口的案例",
      "authors": [
        "José-Antonio Santos",
        "Alberto Fernández",
        "Mar Moreno-Rebato",
        "Holger Billhardt",
        "José-A. Rodríguez-García",
        "Sascha Ossowski"
      ],
      "abstract": "Agreement Technologies refer to a novel paradigm for the construction of\ndistributed intelligent systems, where autonomous software agents negotiate to\nreach agreements on behalf of their human users. Smart Cities are a key\napplication domain for Agreement Technologies. While several proofs of concept\nand prototypes exist, such systems are still far from ready for being deployed\nin the real-world. In this paper we focus on a novel method for managing\nelements of smart road infrastructures of the future, namely the case of\nauction-based road intersections. We show that, even though the key\ntechnological elements for such methods are already available, there are\nmultiple non-technical issues that need to be tackled before they can be\napplied in practice. For this purpose, we analyse legal and ethical\nimplications of auction-based road intersections in the context of\ninternational regulations and from the standpoint of the Spanish legislation.\nFrom this exercise, we extract a set of required modifications, of both\ntechnical and legal nature, which need to be addressed so as to pave the way\nfor the potential real-world deployment of such systems in a future that may\nnot be too far away.",
      "tldr_zh": "这篇论文探讨了 Agreement Technologies（一种基于自治代理协商的分布式智能系统）在智能城市中的应用，特别针对基于拍卖的道路交叉口管理所带来的法律和伦理挑战。尽管相关技术已基本成熟，但作者通过分析国际法规和西班牙立法的视角，识别了多项非技术障碍，包括潜在的法律合规和道德问题。论文的主要贡献是提出了一系列技术和法律修改建议，以消除这些障碍，并为这类系统的实际部署铺平道路。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "I.2.1"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.01673v1",
      "published_date": "2024-01-18 09:12:48 UTC",
      "updated_date": "2024-01-18 09:12:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:42:19.497801"
    },
    {
      "arxiv_id": "2402.05115v1",
      "title": "Unsupervised Motion Retargeting for Human-Robot Imitation",
      "title_zh": "翻译失败",
      "authors": [
        "Louis Annabi",
        "Ziqi Ma",
        "Sao Mai Nguyen"
      ],
      "abstract": "This early-stage research work aims to improve online human-robot imitation\nby translating sequences of joint positions from the domain of human motions to\na domain of motions achievable by a given robot, thus constrained by its\nembodiment. Leveraging the generalization capabilities of deep learning\nmethods, we address this problem by proposing an encoder-decoder neural network\nmodel performing domain-to-domain translation. In order to train such a model,\none could use pairs of associated robot and human motions. Though, such paired\ndata is extremely rare in practice, and tedious to collect. Therefore, we turn\ntowards deep learning methods for unpaired domain-to-domain translation, that\nwe adapt in order to perform human-robot imitation.",
      "tldr_zh": "这篇论文提出了一种Unsupervised Motion Retargeting方法，用于改善在线人-机器人模仿，通过将人类动作的关节位置序列翻译到机器人身体结构限制下的可执行动作领域。研究团队设计了一个encoder-decoder neural network模型，利用深度学习的泛化能力，实现无监督的domain-to-domain translation，从而避免了稀缺的配对数据收集需求。该方法为早期研究阶段的创新尝试，旨在增强机器人对人类动作的模仿效率和实用性。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "Companion of the 2024 ACM/IEEE International Conference on\n  Human-Robot Interactio, Mar 2024, Boulder (CO), United States",
      "pdf_url": "http://arxiv.org/pdf/2402.05115v1",
      "published_date": "2024-01-18 09:03:33 UTC",
      "updated_date": "2024-01-18 09:03:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:42:34.135692"
    },
    {
      "arxiv_id": "2402.01672v1",
      "title": "Prerequisite Structure Discovery in Intelligent Tutoring Systems",
      "title_zh": "翻译失败",
      "authors": [
        "Louis Annabi",
        "Sao Mai Nguyen"
      ],
      "abstract": "This paper addresses the importance of Knowledge Structure (KS) and Knowledge\nTracing (KT) in improving the recommendation of educational content in\nintelligent tutoring systems. The KS represents the relations between different\nKnowledge Components (KCs), while KT predicts a learner's success based on her\npast history. The contribution of this research includes proposing a KT model\nthat incorporates the KS as a learnable parameter, enabling the discovery of\nthe underlying KS from learner trajectories. The quality of the uncovered KS is\nassessed by using it to recommend content and evaluating the recommendation\nalgorithm with simulated students.",
      "tldr_zh": "这篇论文探讨了 Knowledge Structure (KS) 和 Knowledge Tracing (KT) 在智能辅导系统中的作用，KS 用于表示不同 Knowledge Components (KCs) 之间的关系，而 KT 则基于学习者的历史轨迹预测成功可能性。主要贡献是提出一个将 KS 作为可学习参数整合进 KT 模型的框架，从而从学习者轨迹中自动发现潜在的 KS。该方法通过使用发现的 KS 进行教育内容推荐，并以模拟学生评估推荐算法的质量，验证了其有效性。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.01672v1",
      "published_date": "2024-01-18 09:01:49 UTC",
      "updated_date": "2024-01-18 09:01:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:42:44.597944"
    },
    {
      "arxiv_id": "2401.10300v2",
      "title": "A Hierarchical Framework with Spatio-Temporal Consistency Learning for Emergence Detection in Complex Adaptive Systems",
      "title_zh": "一种具有时空一致性学习的层次框架，用于复杂适应系统中的涌现检测",
      "authors": [
        "Siyuan Chen",
        "Xin Du",
        "Jiahai Wang"
      ],
      "abstract": "Emergence, a global property of complex adaptive systems (CASs) constituted\nby interactive agents, is prevalent in real-world dynamic systems, e.g.,\nnetwork-level traffic congestions. Detecting its formation and evaporation\nhelps to monitor the state of a system, allowing to issue a warning signal for\nharmful emergent phenomena. Since there is no centralized controller of CAS,\ndetecting emergence based on each agent's local observation is desirable but\nchallenging. Existing works are unable to capture emergence-related spatial\npatterns, and fail to model the nonlinear relationships among agents. This\npaper proposes a hierarchical framework with spatio-temporal consistency\nlearning to solve these two problems by learning the system representation and\nagent representations, respectively. Spatio-temporal encoders composed of\nspatial and temporal transformers are designed to capture agents' nonlinear\nrelationships and the system's complex evolution. Agents' and the system's\nrepresentations are learned to preserve the spatio-temporal consistency by\nminimizing the spatial and temporal dissimilarities in a self-supervised manner\nin the latent space. Our method achieves more accurate detection than\ntraditional methods and deep learning methods on three datasets with well-known\nyet hard-to-detect emergent behaviors. Notably, our hierarchical framework is\ngeneric in incorporating other deep learning methods for agent-level and\nsystem-level detection.",
      "tldr_zh": "该论文提出一个分层框架，用于检测复杂适应系统 (Complex Adaptive Systems) 中的涌现 (Emergence)，通过时空一致性学习 (Spatio-Temporal Consistency Learning) 解决现有方法在捕捉空间模式和代理间非线性关系方面的不足。框架包括时空编码器（由空间和时间变换器组成），用于学习代理的非线性互动和系统的复杂演化，并通过自监督方式最小化潜在空间中的空间和时间差异，以保持代理和系统表示的一致性。在三个数据集上的实验显示，该方法比传统方法和深度学习方法更准确地检测涌现行为，且框架具有通用性，可整合其他深度学习技术。",
      "categories": [
        "cs.MA",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.MA",
      "comment": "23 pages, accepted by IEEE TNNLS",
      "pdf_url": "http://arxiv.org/pdf/2401.10300v2",
      "published_date": "2024-01-18 08:55:05 UTC",
      "updated_date": "2024-10-28 03:33:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:42:56.255125"
    },
    {
      "arxiv_id": "2401.09798v3",
      "title": "All in How You Ask for It: Simple Black-Box Method for Jailbreak Attacks",
      "title_zh": "翻译失败",
      "authors": [
        "Kazuhiro Takemoto"
      ],
      "abstract": "Large Language Models (LLMs), such as ChatGPT, encounter `jailbreak'\nchallenges, wherein safeguards are circumvented to generate ethically harmful\nprompts. This study introduces a straightforward black-box method for\nefficiently crafting jailbreak prompts, addressing the significant complexity\nand computational costs associated with conventional methods. Our technique\niteratively transforms harmful prompts into benign expressions directly\nutilizing the target LLM, predicated on the hypothesis that LLMs can\nautonomously generate expressions that evade safeguards. Through experiments\nconducted with ChatGPT (GPT-3.5 and GPT-4) and Gemini-Pro, our method\nconsistently achieved an attack success rate exceeding 80% within an average of\nfive iterations for forbidden questions and proved robust against model\nupdates. The jailbreak prompts generated were not only naturally-worded and\nsuccinct but also challenging to defend against. These findings suggest that\nthe creation of effective jailbreak prompts is less complex than previously\nbelieved, underscoring the heightened risk posed by black-box jailbreak\nattacks.",
      "tldr_zh": "这篇论文提出了一种简单黑盒方法，用于高效创建绕过大型语言模型(LLMs)安全机制的jailbreak攻击提示，旨在解决传统方法复杂度高和计算成本大的问题。该方法通过迭代地将有害提示转化为无害表达，直接利用目标LLM生成规避性内容，基于LLMs能自主产生这类表达的假设。在实验中，该方法在ChatGPT (GPT-3.5和GPT-4)以及Gemini-Pro上实现了超过80%的攻击成功率，平均只需五次迭代，且生成的提示自然简洁、难以防御。这些发现强调了黑盒jailbreak攻击的潜在风险，表明创建有效攻击远比预期简单。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.CL",
      "comment": "12 pages, 4 figures, 3 tables",
      "pdf_url": "http://arxiv.org/pdf/2401.09798v3",
      "published_date": "2024-01-18 08:36:54 UTC",
      "updated_date": "2024-02-12 02:29:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:43:08.441934"
    },
    {
      "arxiv_id": "2401.09795v1",
      "title": "A Comparative Analysis on Metaheuristic Algorithms Based Vision Transformer Model for Early Detection of Alzheimer's Disease",
      "title_zh": "翻译失败",
      "authors": [
        "Anuvab Sen",
        "Udayon Sen",
        "Subhabrata Roy"
      ],
      "abstract": "A number of life threatening neuro-degenerative disorders had degraded the\nquality of life for the older generation in particular. Dementia is one such\nsymptom which may lead to a severe condition called Alzheimer's disease if not\ndetected at an early stage. It has been reported that the progression of such\ndisease from a normal stage is due to the change in several parameters inside\nthe human brain. In this paper, an innovative metaheuristic algorithms based\nViT model has been proposed for the identification of dementia at different\nstage. A sizeable number of test data have been utilized for the validation of\nthe proposed scheme. It has also been demonstrated that our model exhibits\nsuperior performance in terms of accuracy, precision, recall as well as\nF1-score.",
      "tldr_zh": "本文通过比较分析，提出了一种基于metaheuristic algorithms的Vision Transformer (ViT) 模型，用于阿尔茨海默病(Alzheimer's disease)的早期检测，旨在识别痴呆(dementia)不同阶段。模型利用大量测试数据进行验证，展示了在准确率(accuracy)、精确率(precision)、召回率(recall)以及F1-score方面的优越性能。该研究为神经退行性疾病的早期干预提供了创新性解决方案。",
      "categories": [
        "cs.NE",
        "cs.AI"
      ],
      "primary_category": "cs.NE",
      "comment": "2023 IEEE 15th International Conference on Computational Intelligence\n  and Communication Networks (CICN). arXiv admin note: text overlap with\n  arXiv:2309.16796",
      "pdf_url": "http://arxiv.org/pdf/2401.09795v1",
      "published_date": "2024-01-18 08:31:38 UTC",
      "updated_date": "2024-01-18 08:31:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:43:21.053061"
    },
    {
      "arxiv_id": "2401.09789v1",
      "title": "A Semantic Approach for Big Data Exploration in Industry 4.0",
      "title_zh": "翻译失败",
      "authors": [
        "Idoia Berges",
        "Víctor Julio Ramírez-Durán",
        "Arantza Illarramendi"
      ],
      "abstract": "The growing trends in automation, Internet of Things, big data and cloud\ncomputing technologies have led to the fourth industrial revolution (Industry\n4.0), where it is possible to visualize and identify patterns and insights,\nwhich results in a better understanding of the data and can improve the\nmanufacturing process. However, many times, the task of data exploration\nresults difficult for manufacturing experts because they might be interested in\nanalyzing also data that does not appear in pre-designed visualizations and\ntherefore they must be assisted by Information Technology experts. In this\npaper, we present a proposal materialized in a semantic-based visual query\nsystem developed for a real Industry 4.0 scenario that allows domain experts to\nexplore and visualize data in a friendly way. The main novelty of the system is\nthe combined use that it makes of captured data that are semantically annotated\nfirst, and a 2D customized digital representation of a machine that is also\nlinked with semantic descriptions. Those descriptions are expressed using terms\nof an ontology, where, among others, the sensors that are used to capture\nindicators about the performance of a machine that belongs to a Industry 4.0\nscenario have been modeled. Moreover, this semantic description allows to:\nformulate queries at a higher level of abstraction, provide customized\ngraphical visualizations of the results based on the format and nature of the\ndata, and download enriched data enabling further types of analysis.",
      "tldr_zh": "本研究针对 Industry 4.0 中的大数据探索问题，指出制造业专家难以分析未在预设可视化中的数据，常需依赖 Information Technology 专家协助。论文提出一个 semantic-based visual query 系统，通过对数据进行语义注解（semantically annotated）和使用 ontology 来链接机器的2D自定义数字表示，从而让领域专家以友好方式探索数据。该系统的主要创新在于支持更高抽象级别的查询、提供定制图形可视化以及下载增强数据，进而提升制造业过程的理解和优化。",
      "categories": [
        "cs.AI",
        "cs.DB"
      ],
      "primary_category": "cs.AI",
      "comment": "Published version of paper: Idoia Berges, V\\'ictor Julio\n  Ram\\'irez-Dur\\'an, Arantza Illarramendi: A Semantic Approach for Big Data\n  Exploration in Industry 4.0. Big Data Res. 25: 100222 (2021). DOI:\n  10.1016/j.bdr.2021.100222",
      "pdf_url": "http://arxiv.org/pdf/2401.09789v1",
      "published_date": "2024-01-18 08:20:19 UTC",
      "updated_date": "2024-01-18 08:20:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:43:33.339761"
    },
    {
      "arxiv_id": "2401.09787v2",
      "title": "Querying Easily Flip-flopped Samples for Deep Active Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Seong Jin Cho",
        "Gwangsu Kim",
        "Junghyun Lee",
        "Jinwoo Shin",
        "Chang D. Yoo"
      ],
      "abstract": "Active learning is a machine learning paradigm that aims to improve the\nperformance of a model by strategically selecting and querying unlabeled data.\nOne effective selection strategy is to base it on the model's predictive\nuncertainty, which can be interpreted as a measure of how informative a sample\nis. The sample's distance to the decision boundary is a natural measure of\npredictive uncertainty, but it is often intractable to compute, especially for\ncomplex decision boundaries formed in multiclass classification tasks. To\naddress this issue, this paper proposes the {\\it least disagree metric} (LDM),\ndefined as the smallest probability of disagreement of the predicted label, and\nan estimator for LDM proven to be asymptotically consistent under mild\nassumptions. The estimator is computationally efficient and can be easily\nimplemented for deep learning models using parameter perturbation. The\nLDM-based active learning is performed by querying unlabeled data with the\nsmallest LDM. Experimental results show that our LDM-based active learning\nalgorithm obtains state-of-the-art overall performance on all considered\ndatasets and deep architectures.",
      "tldr_zh": "该论文针对主动学习（active learning）中的样本选择问题，提出了一种基于 least disagree metric (LDM) 的新策略，其中 LDM 定义为预测标签最小分歧概率，用以衡量模型的不确定性。作者开发了一个渐进一致的 LDM 估计器，通过参数扰动在 deep learning 模型中高效实现，从而优先查询不确定性最高的未标注样本。实验结果表明，该 LDM-based 主动学习算法在多种数据集和深度架构上达到了 state-of-the-art 整体性能。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "34 pages, 17 figures, 5 tables. Accepted to the 12th International\n  Conference on Learning Representations (ICLR 2024) (ver2: fixed some typos\n  and improved some parts of the writing)",
      "pdf_url": "http://arxiv.org/pdf/2401.09787v2",
      "published_date": "2024-01-18 08:12:23 UTC",
      "updated_date": "2024-05-16 08:36:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:43:45.987112"
    },
    {
      "arxiv_id": "2401.09786v5",
      "title": "Adaptive Self-training Framework for Fine-grained Scene Graph Generation",
      "title_zh": "细粒度场景图生成的适应性自我训练框架",
      "authors": [
        "Kibum Kim",
        "Kanghoon Yoon",
        "Yeonjun In",
        "Jinyoung Moon",
        "Donghyun Kim",
        "Chanyoung Park"
      ],
      "abstract": "Scene graph generation (SGG) models have suffered from inherent problems\nregarding the benchmark datasets such as the long-tailed predicate distribution\nand missing annotation problems. In this work, we aim to alleviate the\nlong-tailed problem of SGG by utilizing unannotated triplets. To this end, we\nintroduce a Self-Training framework for SGG (ST-SGG) that assigns pseudo-labels\nfor unannotated triplets based on which the SGG models are trained. While there\nhas been significant progress in self-training for image recognition, designing\na self-training framework for the SGG task is more challenging due to its\ninherent nature such as the semantic ambiguity and the long-tailed distribution\nof predicate classes. Hence, we propose a novel pseudo-labeling technique for\nSGG, called Class-specific Adaptive Thresholding with Momentum (CATM), which is\na model-agnostic framework that can be applied to any existing SGG models.\nFurthermore, we devise a graph structure learner (GSL) that is beneficial when\nadopting our proposed self-training framework to the state-of-the-art\nmessage-passing neural network (MPNN)-based SGG models. Our extensive\nexperiments verify the effectiveness of ST-SGG on various SGG models,\nparticularly in enhancing the performance on fine-grained predicate classes.",
      "tldr_zh": "本文提出了一种自训练框架 ST-SGG，用于解决场景图生成 (SGG) 模型中的长尾谓词分布和缺失标注问题，通过为未标注的三元组分配伪标签来增强模型训练。框架的核心创新包括 Class-specific Adaptive Thresholding with Momentum (CATM) 技术，这是一种模型无关的方法，能适应 SGG 的语义模糊性和长尾分布；此外，还设计了 graph structure learner (GSL) 以优化基于 message-passing neural network (MPNN) 的 SGG 模型。实验验证表明，ST-SGG 显著提高了各种 SGG 模型在细粒度谓词类别的性能。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "9 pages; ICLR 2024",
      "pdf_url": "http://arxiv.org/pdf/2401.09786v5",
      "published_date": "2024-01-18 08:10:34 UTC",
      "updated_date": "2024-08-02 01:22:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:43:59.170219"
    },
    {
      "arxiv_id": "2401.09773v2",
      "title": "SEINE: Structure Encoding and Interaction Network for Nuclei Instance Segmentation",
      "title_zh": "SEINE：结构编码与交互网络用于核实例分割",
      "authors": [
        "Ye Zhang",
        "Linghan Cai",
        "Ziyue Wang",
        "Yongbing Zhang"
      ],
      "abstract": "Nuclei instance segmentation in histopathological images is of great\nimportance for biological analysis and cancer diagnosis but remains challenging\nfor two reasons. (1) Similar visual presentation of intranuclear and\nextranuclear regions of chromophobe nuclei often causes under-segmentation, and\n(2) current methods lack the exploration of nuclei structure, resulting in\nfragmented instance predictions. To address these problems, this paper proposes\na structure encoding and interaction network, termed SEINE, which develops the\nstructure modeling scheme of nuclei and exploits the structure similarity\nbetween nuclei to improve the integrality of each segmented instance.\nConcretely, SEINE introduces a contour-based structure encoding (SE) that\nconsiders the correlation between nuclei structure and semantics, realizing a\nreasonable representation of the nuclei structure. Based on the encoding, we\npropose a structure-guided attention (SGA) module that takes the clear nuclei\nas prototypes to enhance the structure learning for the fuzzy nuclei. To\nstrengthen the structural learning ability, a semantic feature fusion (SFF) is\npresented to boost the semantic consistency of semantic and structure branches.\nFurthermore, a position enhancement (PE) method is applied to suppress\nincorrect nuclei boundary predictions. Extensive experiments demonstrate the\nsuperiority of our approaches, and SEINE achieves state-of-the-art (SOTA)\nperformance on four datasets. The code is available at\nhttps://github.com/zhangye-zoe/SEINE.",
      "tldr_zh": "本论文提出 SEINE 网络，用于病理图像中核实例分割，针对核内部和外部区域视觉相似导致的欠分割问题，以及当前方法缺乏结构探索导致的实例碎片化问题。SEINE 引入 contour-based structure encoding (SE) 来表示核结构与语义的相关性，structure-guided attention (SGA) 模块利用清晰核作为原型增强模糊核的结构学习，并通过 semantic feature fusion (SFF) 提升语义一致性，以及 position enhancement (PE) 抑制边界预测错误。实验结果显示，SEINE 在四个数据集上达到了 state-of-the-art (SOTA) 性能，证明了其有效性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "10 pages, 12 figures, 6 tables, submitted to TMI",
      "pdf_url": "http://arxiv.org/pdf/2401.09773v2",
      "published_date": "2024-01-18 07:44:04 UTC",
      "updated_date": "2024-02-09 03:14:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:44:11.488885"
    },
    {
      "arxiv_id": "2401.09769v4",
      "title": "A Survey on Learning from Graphs with Heterophily: Recent Advances and Future Directions",
      "title_zh": "翻译失败",
      "authors": [
        "Chenghua Gong",
        "Yao Cheng",
        "Jianxiang Yu",
        "Can Xu",
        "Caihua Shan",
        "Siqiang Luo",
        "Xiang Li"
      ],
      "abstract": "Graphs are structured data that models complex relations between real-world\nentities. Heterophilic graphs, where linked nodes are prone to be with\ndifferent labels or dissimilar features, have recently attracted significant\nattention and found many real-world applications. Meanwhile, increasing efforts\nhave been made to advance learning from graphs with heterophily. Various graph\nheterophily measures, benchmark datasets, and learning paradigms are emerging\nrapidly. In this survey, we comprehensively review existing works on learning\nfrom graphs with heterophily. First, we overview over 500 publications, of\nwhich more than 340 are directly related to heterophilic graphs. After that, we\nsurvey existing metrics of graph heterophily and list recent benchmark\ndatasets. Further, we systematically categorize existing methods based on a\nhierarchical taxonomy including GNN models, learning paradigms and practical\napplications. In addition, broader topics related to graph heterophily are also\nincluded. Finally, we discuss the primary challenges of existing studies and\nhighlight promising avenues for future research.",
      "tldr_zh": "这篇调查论文回顾了异质图（heterophily）学习领域的最新进展，分析了超过500篇出版物，其中超过340篇直接与异质图相关。论文系统地总结了图异质性度量指标、基准数据集，并对现有方法进行分层分类，包括GNN模型、学习范式和实际应用，同时涵盖了更广泛的相关主题。最终，它指出了当前研究的首要挑战，并提出了未来研究的方向，如改进方法和扩展应用。",
      "categories": [
        "cs.SI",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.SI",
      "comment": "64 pages",
      "pdf_url": "http://arxiv.org/pdf/2401.09769v4",
      "published_date": "2024-01-18 07:36:38 UTC",
      "updated_date": "2024-09-30 05:56:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:44:21.996812"
    },
    {
      "arxiv_id": "2401.09763v1",
      "title": "CLIP Model for Images to Textual Prompts Based on Top-k Neighbors",
      "title_zh": "翻译失败",
      "authors": [
        "Xin Zhang",
        "Xin Zhang",
        "YeMing Cai",
        "Tianzhi Jia"
      ],
      "abstract": "Text-to-image synthesis, a subfield of multimodal generation, has gained\nsignificant attention in recent years. We propose a cost-effective approach for\nimage-to-prompt generation that leverages generative models to generate textual\nprompts without the need for large amounts of annotated data. We divide our\nmethod into two stages: online stage and offline stage. We use a combination of\nthe CLIP model and K-nearest neighbors (KNN) algorithm. The proposed system\nconsists of two main parts: an offline task and an online task. Our method owns\nthe highest metric 0.612 among these models, which is 0.013, 0.055, 0.011\nhigher than Clip, Clip + KNN(top 10) respectively.",
      "tldr_zh": "本论文提出了一种基于 CLIP 模型和 Top-k Neighbors 的图像到文本提示生成方法，旨在实现成本有效的文本合成，而无需大量标注数据。该方法分为在线和离线阶段，结合 K-nearest neighbors (KNN) 算法，通过 CLIP 模型进行图像特征提取和最近邻匹配。实验结果显示，该系统在相关指标上达到 0.612，比 CLIP 和 CLIP + KNN(top 10) 模型分别高出 0.013 和 0.055，为多模态生成任务提供了高效的改进方案。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "CLIP model, KNN, image-to-prompts",
      "pdf_url": "http://arxiv.org/pdf/2401.09763v1",
      "published_date": "2024-01-18 07:28:17 UTC",
      "updated_date": "2024-01-18 07:28:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:44:33.738917"
    },
    {
      "arxiv_id": "2401.09757v1",
      "title": "Cooperative Tri-Point Model-Based Ground-to-Air Coverage Extension in Beyond 5G Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Ziwei Cai",
        "Min Sheng",
        "Junju Liu",
        "Chenxi Zhao",
        "Jiandong Li"
      ],
      "abstract": "The utilization of existing terrestrial infrastructures to provide coverage\nfor aerial users is a potentially low-cost solution. However, the already\ndeployed terrestrial base stations (TBSs) result in weak ground-to-air (G2A)\ncoverage due to the down-tilted antennas. Furthermore, achieving optimal\ncoverage across the entire airspace through antenna adjustment is challenging\ndue to the complex signal coverage requirements in three-dimensional space,\nespecially in the vertical direction. In this paper, we propose a cooperative\ntri-point (CoTP) model-based method that utilizes cooperative beams to enhance\nthe G2A coverage extension. To utilize existing TBSs for establishing effective\ncooperation, we prove that the cooperation among three TBSs can ensure G2A\ncoverage with a minimum coverage overlap, and design the CoTP model to analyze\nthe G2A coverage extension. Using the model, a cooperative coverage structure\nbased on Delaunay triangulation is designed to divide triangular prism-shaped\nsubspaces and corresponding TBS cooperation sets. To enable TBSs in the\ncooperation set to cover different height subspaces while maintaining ground\ncoverage, we design a cooperative beam generation algorithm to maximize the\ncoverage in the triangular prism-shaped airspace. The simulation results and\nfield trials demonstrate that the proposed method can efficiently enhance the\nG2A coverage extension while guaranteeing ground coverage.",
      "tldr_zh": "该论文针对Beyond 5G Networks中地面基站(TBSs)天线向下倾斜导致的地面到空中(G2A)覆盖不足问题，提出了一种基于Cooperative Tri-Point (CoTP)模型的方法，利用三个TBSs的合作波束来扩展G2A覆盖。研究证明，这种合作能最小化覆盖重叠，并设计了CoTP模型结合Delaunay triangulation构建三角柱形子空间和TBS合作集，以有效划分空域。论文还开发了合作波束生成算法，用于最大化三角柱形空域的覆盖，同时保持地面覆盖；模拟结果和现场试验显示，该方法显著提升了G2A覆盖扩展效果。",
      "categories": [
        "cs.IT",
        "cs.AI",
        "math.IT"
      ],
      "primary_category": "cs.IT",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.09757v1",
      "published_date": "2024-01-18 07:07:44 UTC",
      "updated_date": "2024-01-18 07:07:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:44:47.251985"
    },
    {
      "arxiv_id": "2401.09756v1",
      "title": "Explaining Drift using Shapley Values",
      "title_zh": "翻译失败",
      "authors": [
        "Narayanan U. Edakunni",
        "Utkarsh Tekriwal",
        "Anukriti Jain"
      ],
      "abstract": "Machine learning models often deteriorate in their performance when they are\nused to predict the outcomes over data on which they were not trained. These\nscenarios can often arise in real world when the distribution of data changes\ngradually or abruptly due to major events like a pandemic. There have been many\nattempts in machine learning research to come up with techniques that are\nresilient to such Concept drifts. However, there is no principled framework to\nidentify the drivers behind the drift in model performance. In this paper, we\npropose a novel framework - DBShap that uses Shapley values to identify the\nmain contributors of the drift and quantify their respective contributions. The\nproposed framework not only quantifies the importance of individual features in\ndriving the drift but also includes the change in the underlying relation\nbetween the input and output as a possible driver. The explanation provided by\nDBShap can be used to understand the root cause behind the drift and use it to\nmake the model resilient to the drift.",
      "tldr_zh": "机器学习模型在数据分布发生渐变或突发变化（如疫情）时，往往会因概念漂移（Concept drifts）而性能下降。论文提出了一种新框架 DBShap，利用 Shapley values 来识别和量化漂移的主要驱动因素，包括单个特征的重要性以及输入和输出之间关系的改变。该框架不仅提供详细解释，帮助理解漂移的根因，还可用于增强模型对漂移的弹性，使其更具适应性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.09756v1",
      "published_date": "2024-01-18 07:07:42 UTC",
      "updated_date": "2024-01-18 07:07:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:44:57.000791"
    },
    {
      "arxiv_id": "2401.10299v1",
      "title": "An attempt to generate new bridge types from latent space of generative flow",
      "title_zh": "从生成流的潜在空间生成新桥梁类型的尝试",
      "authors": [
        "Hongjun Zhang"
      ],
      "abstract": "Through examples of coordinate and probability transformation between\ndifferent distributions, the basic principle of normalizing flow is introduced\nin a simple and concise manner. From the perspective of the distribution of\nrandom variable function, the essence of probability transformation is\nexplained, and the scaling factor Jacobian determinant of probability\ntransformation is introduced. Treating the dataset as a sample from the\npopulation, obtaining normalizing flow is essentially through sampling surveys\nto statistically infer the numerical features of the population, and then the\nloss function is established by using the maximum likelihood estimation method.\nThis article introduces how normalizing flow cleverly solves the two major\napplication challenges of high-dimensional matrix determinant calculation and\nneural network reversible transformation. Using symmetric structured image\ndataset of three-span beam bridge, arch bridge, cable-stayed bridge and\nsuspension bridge, constructing and training normalizing flow based on the Glow\nAPI in the TensorFlow Probability library. The model can smoothly transform the\ncomplex distribution of the bridge dataset into a standard normal distribution,\nand from the obtained latent space sampling, it can generate new bridge types\nthat are different from the training dataset.",
      "tldr_zh": "这篇论文简要介绍了 normalizing flow 的基本原理，包括坐标和概率变换，以及 Jacobian determinant 在概率变换中的作用，并通过最大似然估计方法建立损失函数。作者使用三跨梁桥、拱桥、悬索桥和斜拉桥的图像数据集，基于 TensorFlow Probability 中的 Glow API 构建并训练 normalizing flow 模型。实验结果表明，该模型能将桥数据集的复杂分布转化为标准正态分布，并从 latent space 中采样生成不同于训练集的新桥类型，展示了在生成新桥设计方面的潜力。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "10 pages, 11 figures",
      "pdf_url": "http://arxiv.org/pdf/2401.10299v1",
      "published_date": "2024-01-18 06:26:44 UTC",
      "updated_date": "2024-01-18 06:26:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:45:10.399930"
    },
    {
      "arxiv_id": "2401.09748v1",
      "title": "Bootstrapping OTS-Funcimg Pre-training Model (Botfip) -- A Comprehensive Symbolic Regression Framework",
      "title_zh": "翻译失败",
      "authors": [
        "Tianhao Chen",
        "Pengbo Xu",
        "Haibiao Zheng"
      ],
      "abstract": "In the field of scientific computing, many problem-solving approaches tend to\nfocus only on the process and final outcome, even in AI for science, there is a\nlack of deep multimodal information mining behind the data, missing a\nmultimodal framework akin to that in the image-text domain. In this paper, we\ntake Symbolic Regression(SR) as our focal point and, drawing inspiration from\nthe BLIP model in the image-text domain, propose a scientific computing\nmultimodal framework based on Function Images (Funcimg) and Operation Tree\nSequence (OTS), named Bootstrapping OTS-Funcimg Pre-training Model (Botfip). In\nSR experiments, we validate the advantages of Botfip in low-complexity SR\nproblems, showcasing its potential. As a MED framework, Botfip holds promise\nfor future applications in a broader range of scientific computing problems.",
      "tldr_zh": "该论文指出，科学计算领域常忽略数据背后的多模态信息挖掘，类似于图像文本领域的BLIP模型，因此提出了一种全面的Symbolic Regression (SR)框架——Bootstrapping OTS-Funcimg Pre-training Model (Botfip)。该框架基于Function Images (Funcimg)和Operation Tree Sequence (OTS)构建多模态预训练模型，旨在提升SR任务的性能。实验结果显示，Botfip在低复杂度SR问题上表现出显著优势，并有望扩展应用于更广泛的科学计算场景中。",
      "categories": [
        "cs.SC",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.SC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.09748v1",
      "published_date": "2024-01-18 06:19:05 UTC",
      "updated_date": "2024-01-18 06:19:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:45:21.609499"
    },
    {
      "arxiv_id": "2401.09717v1",
      "title": "Parameter Selection for Analyzing Conversations with Autism Spectrum Disorder",
      "title_zh": "用于分析自闭症谱系障碍对话的参数选择",
      "authors": [
        "Tahiya Chowdhury",
        "Veronica Romero",
        "Amanda Stent"
      ],
      "abstract": "The diagnosis of autism spectrum disorder (ASD) is a complex, challenging\ntask as it depends on the analysis of interactional behaviors by psychologists\nrather than the use of biochemical diagnostics. In this paper, we present a\nmodeling approach to ASD diagnosis by analyzing acoustic/prosodic and\nlinguistic features extracted from diagnostic conversations between a\npsychologist and children who either are typically developing (TD) or have ASD.\nWe compare the contributions of different features across a range of\nconversation tasks. We focus on finding a minimal set of parameters that\ncharacterize conversational behaviors of children with ASD. Because ASD is\ndiagnosed through conversational interaction, in addition to analyzing the\nbehavior of the children, we also investigate whether the psychologist's\nconversational behaviors vary across diagnostic groups. Our results can\nfacilitate fine-grained analysis of conversation data for children with ASD to\nsupport diagnosis and intervention.",
      "tldr_zh": "本研究提出了一种基于参数选择的建模方法，用于分析自闭谱系障碍（ASD）诊断对话中的声学/韵律（acoustic/prosodic）和语言（linguistic）特征，以辅助ASD诊断。该方法比较不同特征在各种对话任务中的贡献，并识别出最小参数集来表征ASD儿童的对话行为。同时，研究还考察了心理学家在ASD和典型发育（TD）儿童诊断组间的对话行为差异。结果显示，此方法可支持对ASD儿童对话数据的细粒度分析，从而提升诊断和干预的有效性。",
      "categories": [
        "eess.AS",
        "cs.AI",
        "cs.SD"
      ],
      "primary_category": "eess.AS",
      "comment": "5 pages, 4 tables, Proceedings of INTERSPEECH 2023",
      "pdf_url": "http://arxiv.org/pdf/2401.09717v1",
      "published_date": "2024-01-18 04:28:56 UTC",
      "updated_date": "2024-01-18 04:28:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:45:33.146050"
    },
    {
      "arxiv_id": "2401.09716v1",
      "title": "HCVP: Leveraging Hierarchical Contrastive Visual Prompt for Domain Generalization",
      "title_zh": "HCVP：利用分层对比视觉提示进行领域泛化",
      "authors": [
        "Guanglin Zhou",
        "Zhongyi Han",
        "Shiming Chen",
        "Biwei Huang",
        "Liming Zhu",
        "Tongliang Liu",
        "Lina Yao",
        "Kun Zhang"
      ],
      "abstract": "Domain Generalization (DG) endeavors to create machine learning models that\nexcel in unseen scenarios by learning invariant features. In DG, the prevalent\npractice of constraining models to a fixed structure or uniform\nparameterization to encapsulate invariant features can inadvertently blend\nspecific aspects. Such an approach struggles with nuanced differentiation of\ninter-domain variations and may exhibit bias towards certain domains, hindering\nthe precise learning of domain-invariant features. Recognizing this, we\nintroduce a novel method designed to supplement the model with domain-level and\ntask-specific characteristics. This approach aims to guide the model in more\neffectively separating invariant features from specific characteristics,\nthereby boosting the generalization. Building on the emerging trend of visual\nprompts in the DG paradigm, our work introduces the novel \\textbf{H}ierarchical\n\\textbf{C}ontrastive \\textbf{V}isual \\textbf{P}rompt (HCVP) methodology. This\nrepresents a significant advancement in the field, setting itself apart with a\nunique generative approach to prompts, alongside an explicit model structure\nand specialized loss functions. Differing from traditional visual prompts that\nare often shared across entire datasets, HCVP utilizes a hierarchical prompt\ngeneration network enhanced by prompt contrastive learning. These generative\nprompts are instance-dependent, catering to the unique characteristics inherent\nto different domains and tasks. Additionally, we devise a prompt modulation\nnetwork that serves as a bridge, effectively incorporating the generated visual\nprompts into the vision transformer backbone. Experiments conducted on five DG\ndatasets demonstrate the effectiveness of HCVP, outperforming both established\nDG algorithms and adaptation protocols.",
      "tldr_zh": "这篇论文针对 Domain Generalization (DG) 的挑战，提出了一种新方法，以更好地学习不变特征并减少领域偏见。论文引入了 Hierarchical Contrastive Visual Prompt (HCVP)，这是一种基于层次提示生成网络和提示对比学习的框架，能够生成实例相关的视觉提示，并通过提示调制网络将其整合到视觉Transformer骨干中，从而有效分离不变特征和特定特性。在五个 DG 数据集上的实验显示，HCVP 超过了现有算法和适应协议，显著提升了模型的泛化性能。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.09716v1",
      "published_date": "2024-01-18 04:23:21 UTC",
      "updated_date": "2024-01-18 04:23:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:45:46.460110"
    },
    {
      "arxiv_id": "2401.09699v1",
      "title": "Curriculum Recommendations Using Transformer Base Model with InfoNCE Loss And Language Switching Method",
      "title_zh": "翻译失败",
      "authors": [
        "Xiaonan Xu",
        "Bin Yuan",
        "Yongyao Mo",
        "Tianbo Song",
        "Shulin Li"
      ],
      "abstract": "The Curriculum Recommendations paradigm is dedicated to fostering learning\nequality within the ever-evolving realms of educational technology and\ncurriculum development. In acknowledging the inherent obstacles posed by\nexisting methodologies, such as content conflicts and disruptions from language\ntranslation, this paradigm aims to confront and overcome these challenges.\nNotably, it addresses content conflicts and disruptions introduced by language\ntranslation, hindrances that can impede the creation of an all-encompassing and\npersonalized learning experience. The paradigm's objective is to cultivate an\neducational environment that not only embraces diversity but also customizes\nlearning experiences to suit the distinct needs of each learner. To overcome\nthese challenges, our approach builds upon notable contributions in curriculum\ndevelopment and personalized learning, introducing three key innovations. These\ninclude the integration of Transformer Base Model to enhance computational\nefficiency, the implementation of InfoNCE Loss for accurate content-topic\nmatching, and the adoption of a language switching strategy to alleviate\ntranslation-related ambiguities. Together, these innovations aim to\ncollectively tackle inherent challenges and contribute to forging a more\nequitable and effective learning journey for a diverse range of learners.\nCompetitive cross-validation scores underscore the efficacy of\nsentence-transformers/LaBSE, achieving 0.66314, showcasing our methodology's\neffectiveness in diverse linguistic nuances for content alignment prediction.\nIndex Terms-Curriculum Recommendation, Transformer model with InfoNCE Loss,\nLanguage Switching.",
      "tldr_zh": "该论文针对课程推荐系统中的内容冲突和语言翻译干扰问题，提出了一种旨在提升学习平等和个性化体验的范式。研究引入三个关键创新：使用 Transformer Base Model 来提高计算效率、采用 InfoNCE Loss 实现准确的内容主题匹配，以及实施 Language Switching 策略来减少翻译相关歧义。这些方法结合后，通过 sentence-transformers/LaBSE 模型的交叉验证分数达到 0.66314，证明了其在处理多语言细微差异方面的有效性。该方法为构建更公平高效的课程推荐系统提供了新途径。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "68T50"
      ],
      "primary_category": "cs.CL",
      "comment": "4pages, 2 figures, ICAICA2023",
      "pdf_url": "http://arxiv.org/pdf/2401.09699v1",
      "published_date": "2024-01-18 03:09:06 UTC",
      "updated_date": "2024-01-18 03:09:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:45:57.823891"
    },
    {
      "arxiv_id": "2401.09695v2",
      "title": "Should ChatGPT Write Your Breakup Text? Exploring the Role of AI in Relationship Dissolution",
      "title_zh": "翻译失败",
      "authors": [
        "Yue Fu",
        "Yixin Chen",
        "Zelia Gomes Da Costa Lai",
        "Alexis Hiniker"
      ],
      "abstract": "Relationships are essential to our happiness and wellbeing, yet their\ndissolution-the final stage of a relationship's lifecycle-is among the most\nstressful events individuals can experience, often leading to profound and\nlasting impacts. With the breakup process increasingly facilitated by\ntechnology, such as computer-mediated communication, and the likely future\ninfluence of generative AI (GenAI) tools, we conducted a semi-structured\ninterview study with 21 participants. We aim to understand: 1) the current role\nof technology in the breakup process, 2) the needs and support individuals seek\nduring this time, and 3) how GenAI might address or undermine these needs. Our\nfindings show that people have distinct needs at various stages of breakups.\nWhile currently technology plays an important role, it falls short in\nsupporting users' unmet needs. Participants envision that GenAI could: 1) aid\nin prompting self-reflection, providing neutral second opinions, and assisting\nwith planning leading up to a breakup; 2) serve as a communication mediator,\nsupporting wording and tone to facilitate emotional expression during breakup\nconversations; and 3) support personal growth and offer companionship after a\nbreakup. However, our findings also reveal participants' concerns about\ninvolving GenAI in this process. Based on our results, we discuss the potential\nopportunities, design considerations, and harms of GenAI tools in facilitating\npeople's relationship dissolution.",
      "tldr_zh": "本研究探讨了AI（如ChatGPT）在关系解体中的作用，通过对21名参与者的半结构化访谈，分析了技术在分手过程中的当前角色、个体需求以及GenAI的潜在影响。结果显示，人们在分手不同阶段有独特需求，但现有技术无法充分满足；GenAI可能帮助自省、提供中立意见、辅助沟通规划、表达情感以及后续个人成长和陪伴。研究同时强调了使用GenAI的潜在风险，并讨论了其设计机会、考虑因素和可能带来的危害。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.09695v2",
      "published_date": "2024-01-18 02:53:36 UTC",
      "updated_date": "2024-10-31 18:59:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:46:09.294741"
    },
    {
      "arxiv_id": "2401.09691v2",
      "title": "Imitation Learning Inputting Image Feature to Each Layer of Neural Network",
      "title_zh": "翻译失败",
      "authors": [
        "Koki Yamane",
        "Sho Sakaino",
        "Toshiaki Tsuji"
      ],
      "abstract": "Imitation learning enables robots to learn and replicate human behavior from\ntraining data. Recent advances in machine learning enable end-to-end learning\napproaches that directly process high-dimensional observation data, such as\nimages. However, these approaches face a critical challenge when processing\ndata from multiple modalities, inadvertently ignoring data with a lower\ncorrelation to the desired output, especially when using short sampling\nperiods. This paper presents a useful method to address this challenge, which\namplifies the influence of data with a relatively low correlation to the output\nby inputting the data into each neural network layer. The proposed approach\neffectively incorporates diverse data sources into the learning process.\nThrough experiments using a simple pick-and-place operation with raw images and\njoint information as input, significant improvements in success rates are\ndemonstrated even when dealing with data from short sampling periods.",
      "tldr_zh": "这篇论文针对Imitation Learning在处理多模态数据时的挑战，提出了一种创新方法，将图像特征输入到神经网络的每个层，从而放大与输出相关性较低的数据的影响。该方法能够有效整合多样数据源，提升学习过程的鲁棒性。在实验中，使用原始图像和关节信息进行简单捡取和放置操作，即使在短采样周期下，也实现了成功率的显著改善。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "6 pages, 4 figures, Accepted at AMC2024",
      "pdf_url": "http://arxiv.org/pdf/2401.09691v2",
      "published_date": "2024-01-18 02:44:18 UTC",
      "updated_date": "2024-01-19 12:43:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:46:22.621984"
    },
    {
      "arxiv_id": "2401.09680v2",
      "title": "Tiny Multi-Agent DRL for Twins Migration in UAV Metaverses: A Multi-Leader Multi-Follower Stackelberg Game Approach",
      "title_zh": "翻译失败",
      "authors": [
        "Jiawen Kang",
        "Yue Zhong",
        "Minrui Xu",
        "Jiangtian Nie",
        "Jinbo Wen",
        "Hongyang Du",
        "Dongdong Ye",
        "Xumin Huang",
        "Dusit Niyato",
        "Shengli Xie"
      ],
      "abstract": "The synergy between Unmanned Aerial Vehicles (UAVs) and metaverses is giving\nrise to an emerging paradigm named UAV metaverses, which create a unified\necosystem that blends physical and virtual spaces, transforming drone\ninteraction and virtual exploration. UAV Twins (UTs), as the digital twins of\nUAVs that revolutionize UAV applications by making them more immersive,\nrealistic, and informative, are deployed and updated on ground base stations,\ne.g., RoadSide Units (RSUs), to offer metaverse services for UAV Metaverse\nUsers (UMUs). Due to the dynamic mobility of UAVs and limited communication\ncoverages of RSUs, it is essential to perform real-time UT migration to ensure\nseamless immersive experiences for UMUs. However, selecting appropriate RSUs\nand optimizing the required bandwidth is challenging for achieving reliable and\nefficient UT migration. To address the challenges, we propose a tiny machine\nlearning-based Stackelberg game framework based on pruning techniques for\nefficient UT migration in UAV metaverses. Specifically, we formulate a\nmulti-leader multi-follower Stackelberg model considering a new immersion\nmetric of UMUs in the utilities of UAVs. Then, we design a Tiny Multi-Agent\nDeep Reinforcement Learning (Tiny MADRL) algorithm to obtain the tiny networks\nrepresenting the optimal game solution. Specifically, the actor-critic network\nleverages the pruning techniques to reduce the number of network parameters and\nachieve model size and computation reduction, allowing for efficient\nimplementation of Tiny MADRL. Numerical results demonstrate that our proposed\nschemes have better performance than traditional schemes.",
      "tldr_zh": "本文提出了一种针对 UAV 元宇宙中 UAV Twins (UTs) 迁移的微型多智能体深度强化学习 (Tiny MADRL) 框架，采用多领导者多跟随者 Stackelberg 游戏模型，以优化 RSU 选择和带宽分配，确保用户沉浸体验。框架考虑了 UMUs 的新沉浸度指标，并通过网络修剪技术减少模型参数，实现高效的实时 UT 迁移。实验结果表明，该方案在性能上优于传统方法，提供更可靠的 UAV 元宇宙服务。",
      "categories": [
        "cs.AI",
        "cs.GT"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.09680v2",
      "published_date": "2024-01-18 02:14:13 UTC",
      "updated_date": "2024-04-08 12:31:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:46:34.999489"
    },
    {
      "arxiv_id": "2401.09671v2",
      "title": "Towards Identifiable Unsupervised Domain Translation: A Diversified Distribution Matching Approach",
      "title_zh": "翻译失败",
      "authors": [
        "Sagar Shrestha",
        "Xiao Fu"
      ],
      "abstract": "Unsupervised domain translation (UDT) aims to find functions that convert\nsamples from one domain (e.g., sketches) to another domain (e.g., photos)\nwithout changing the high-level semantic meaning (also referred to as\n``content''). The translation functions are often sought by probability\ndistribution matching of the transformed source domain and target domain.\nCycleGAN stands as arguably the most representative approach among this line of\nwork. However, it was noticed in the literature that CycleGAN and variants\ncould fail to identify the desired translation functions and produce\ncontent-misaligned translations. This limitation arises due to the presence of\nmultiple translation functions -- referred to as ``measure-preserving\nautomorphism\" (MPA) -- in the solution space of the learning criteria. Despite\nawareness of such identifiability issues, solutions have remained elusive. This\nstudy delves into the core identifiability inquiry and introduces an MPA\nelimination theory. Our analysis shows that MPA is unlikely to exist, if\nmultiple pairs of diverse cross-domain conditional distributions are matched by\nthe learning function. Our theory leads to a UDT learner using distribution\nmatching over auxiliary variable-induced subsets of the domains -- other than\nover the entire data domains as in the classical approaches. The proposed\nframework is the first to rigorously establish translation identifiability\nunder reasonable UDT settings, to our best knowledge. Experiments corroborate\nwith our theoretical claims.",
      "tldr_zh": "本论文针对Unsupervised Domain Translation (UDT)的问题，提出了一种多样化分布匹配方法，以解决现有方法如CycleGAN因“measure-preserving automorphism” (MPA)而导致的内容不匹配和翻译函数不可识别的局限性。研究引入MPA消除理论，证明通过匹配多个多样化的跨域条件分布（如在辅助变量诱导的子集上进行distribution matching），可以显著提高翻译的可识别性。实验结果验证了这一理论主张，为UDT框架提供了可靠的改进基础。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.09671v2",
      "published_date": "2024-01-18 01:07:00 UTC",
      "updated_date": "2024-01-21 07:27:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:46:46.583577"
    },
    {
      "arxiv_id": "2401.09666v1",
      "title": "Traffic Smoothing Controllers for Autonomous Vehicles Using Deep Reinforcement Learning and Real-World Trajectory Data",
      "title_zh": "针对自动驾驶车辆的交通平滑控制器：使用深度强化学习",
      "authors": [
        "Nathan Lichtlé",
        "Kathy Jang",
        "Adit Shah",
        "Eugene Vinitsky",
        "Jonathan W. Lee",
        "Alexandre M. Bayen"
      ],
      "abstract": "Designing traffic-smoothing cruise controllers that can be deployed onto\nautonomous vehicles is a key step towards improving traffic flow, reducing\ncongestion, and enhancing fuel efficiency in mixed autonomy traffic. We bypass\nthe common issue of having to carefully fine-tune a large traffic\nmicrosimulator by leveraging real-world trajectory data from the I-24 highway\nin Tennessee, replayed in a one-lane simulation. Using standard deep\nreinforcement learning methods, we train energy-reducing wave-smoothing\npolicies. As an input to the agent, we observe the speed and distance of only\nthe vehicle in front, which are local states readily available on most recent\nvehicles, as well as non-local observations about the downstream state of the\ntraffic. We show that at a low 4% autonomous vehicle penetration rate, we\nachieve significant fuel savings of over 15% on trajectories exhibiting many\nstop-and-go waves. Finally, we analyze the smoothing effect of the controllers\nand demonstrate robustness to adding lane-changing into the simulation as well\nas the removal of downstream information.",
      "tldr_zh": "该研究设计了基于深度强化学习（Deep Reinforcement Learning）的交通平滑控制器，用于自动驾驶车辆（Autonomous Vehicles），以改善混合交通流量、减少拥堵并提升燃油效率。他们利用真实世界轨迹数据从田纳西州 I-24 高速公路进行单车道模拟训练，代理输入包括前方车辆的速度、距离等本地状态以及下游交通的非本地观察。在 4% 的自动驾驶车辆渗透率（penetration rate）下，该控制器在存在频繁启停波浪（stop-and-go waves）的轨迹上实现了超过 15% 的燃油节约，并证明了对添加变道行为和移除下游信息的鲁棒性。",
      "categories": [
        "eess.SY",
        "cs.AI",
        "cs.MA",
        "cs.SY"
      ],
      "primary_category": "eess.SY",
      "comment": "Accepted to be published as part of the 26th IEEE International\n  Conference on Intelligent Transportation Systems (ITSC) 2023, Bilbao, Spain,\n  September 24-28, 2023",
      "pdf_url": "http://arxiv.org/pdf/2401.09666v1",
      "published_date": "2024-01-18 00:50:41 UTC",
      "updated_date": "2024-01-18 00:50:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:46:59.727915"
    },
    {
      "arxiv_id": "2401.09656v1",
      "title": "Mobility Accelerates Learning: Convergence Analysis on Hierarchical Federated Learning in Vehicular Networks",
      "title_zh": "移动性加速学习：车辆网络中分层联邦学习的收敛分析",
      "authors": [
        "Tan Chen",
        "Jintao Yan",
        "Yuxuan Sun",
        "Sheng Zhou",
        "Deniz Gündüz",
        "Zhisheng Niu"
      ],
      "abstract": "Hierarchical federated learning (HFL) enables distributed training of models\nacross multiple devices with the help of several edge servers and a cloud edge\nserver in a privacy-preserving manner. In this paper, we consider HFL with\nhighly mobile devices, mainly targeting at vehicular networks. Through\nconvergence analysis, we show that mobility influences the convergence speed by\nboth fusing the edge data and shuffling the edge models. While mobility is\nusually considered as a challenge from the perspective of communication, we\nprove that it increases the convergence speed of HFL with edge-level\nheterogeneous data, since more diverse data can be incorporated. Furthermore,\nwe demonstrate that a higher speed leads to faster convergence, since it\naccelerates the fusion of data. Simulation results show that mobility increases\nthe model accuracy of HFL by up to 15.1% when training a convolutional neural\nnetwork on the CIFAR-10 dataset.",
      "tldr_zh": "本论文通过收敛分析探讨了移动性对分层联邦学习 (HFL) 在车辆网络中的影响，证明移动性可通过融合边缘数据和洗牌边缘模型来加速模型收敛速度。研究表明，尽管移动性通常被视为通信挑战，但它能提升 HFL 在边缘级异构数据下的性能，因为融入了更多样化的数据，且速度越高，收敛越快。模拟结果显示，在 CIFAR-10 数据集上训练卷积神经网络 (CNN) 时，移动性可将模型准确率提高多达 15.1%。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DC"
      ],
      "primary_category": "cs.LG",
      "comment": "Submitted to IEEE for possible publication",
      "pdf_url": "http://arxiv.org/pdf/2401.09656v1",
      "published_date": "2024-01-18 00:09:54 UTC",
      "updated_date": "2024-01-18 00:09:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:47:10.583314"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 78,
  "processed_papers_count": 78,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-16T22:47:31.972720"
}