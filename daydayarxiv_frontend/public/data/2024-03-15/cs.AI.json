{
  "date": "2024-03-15",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-03-15 的 arXiv 中文 TLDR 快报！今天 arXiv 的论文主要聚焦于 AI 模型优化、LLM 在代码生成和推荐系统的应用、机器人导航以及医疗图像分析等领域，重点包括高效的强化学习算法和 LLM 的鲁棒性提升，令人印象深刻的文章有 \"Parameter Efficient Reinforcement Learning from Human Feedback\"（作者包括 Lucas Dixon 等知名学者）和 \"VideoAgent: Long-form Video Understanding with Large Language Models as Agent\"，这些工作展示了 LLM 在复杂任务中的潜力。\n\n下面，我将逐一简要概述部分关键论文，先优先讨论重要、话题度高的文章（如 LLM 和机器人相关），然后快速掠过其他较基础或小众的论文。每个条目包括论文标题（中文 + 英文）、主要贡献和发现，保留核心学术术语。\n\n### LLM 和 AI 应用相关（重点讨论）\n- **Parameter Efficient Reinforcement Learning from Human Feedback**（参数高效强化学习从人类反馈）：这篇论文提出 PE-RLHF 方法，使用 LoRA 微调来优化 LLM 和 VLM 的强化学习，显著减少训练时间（奖励模型快 90%、RL 快 30%），在总结、响应生成和视觉问答任务上实现与传统 RLHF 相当的性能，同时降低计算资源需求。\n- **VideoAgent: Long-form Video Understanding with Large Language Model as Agent**（VideoAgent: 使用大型语言模型作为代理的长视频理解）：作者提出 VideoAgent 框架，利用 LLM 作为代理进行交互式视频理解，仅需少量帧（平均 8 帧）就实现高效零样本预测，在 EgoSchema 和 NExT-QA 数据集上超越 SOTA 方法。\n- **Discovering Latent Themes in Social Media Messaging: A Machine-in-the-Loop Approach Integrating LLMs**（发现社交媒体消息的潜在主题：整合 LLM 的机器循环方法）：论文引入机器循环方法，使用 LLM 分析社交媒体主题（如疫苗和气候辩论），在 Facebook 数据集上比基线更准确地识别可操作主题，提升了主题发现的规模性和一致性。\n- **Towards Unified Multi-Modal Personalization: Large Vision-Language Models for Generative Recommendation and Beyond**（面向统一的多模态个性化：用于生成式推荐的大视语言模型）：该工作提出 UniMP 框架，利用 LLM 处理多模态数据（如图像和文本），在推荐、搜索和生成任务上实现高效个性化，实验显示在真实基准上超越传统方法。\n- **Backdoor Secrets Unveiled: Identifying Backdoor Data with Optimized Scaled Prediction Consistency**（后门秘密揭露：使用优化缩放预测一致性识别后门数据）：作者开发了一种无需清洁数据的方法来检测机器学习中的后门攻击，通过优化 SPC 损失函数，在多种攻击下提升 AUROC 4%-36%，并提供开源代码。\n- **Development and Application of a Monte Carlo Tree Search Algorithm for Simulating Da Vinci Code Game Strategies**（蒙特卡罗树搜索算法在达芬奇密码游戏策略模拟中的开发与应用）：论文评估 MCTS 在游戏策略中的性能，揭示 GPU 实现的支路发散问题，并比较 CPU 和 GPU 表现，贡献了算法优化思路。\n\n### 机器人和导航相关（高话题度，简要讨论）\n- **HumanoidBench: Simulated Humanoid Benchmark for Whole-Body Locomotion and Manipulation**（HumanoidBench: 用于全身运动和操作的人形机器人模拟基准）：作者构建了一个高维模拟基准，支持人形机器人在复杂任务中的学习，实验显示分层方法在运动和抓取任务上优于 SOTA 算法。\n- **Online Concurrent Multi-Robot Coverage Path Planning**（在线并发多机器人覆盖路径规划）：论文提出一个非地平线算法，实现多机器人同时规划和执行路径，确保完整覆盖未知环境，在大规模网格上比传统方法快 1.6 倍。\n- **NeuFlow: Real-time, High-accuracy Optical Flow Estimation on Robots Using Edge Devices**（NeuFlow: 使用边缘设备在机器人上进行实时高精度光流估计）：作者设计 NeuFlow 架构，结合全局和局部匹配，实现 10-80 倍加速，同时保持高精度，适用于机器人 SLAM。\n\n### 医疗和图像分析相关（实际应用价值较高）\n- **RadCLIP: Enhancing Radiologic Image Analysis through Contrastive Language-Image Pre-training**（RadCLIP: 通过对比语言-图像预训练增强放射图像分析）：论文提出 RadCLIP 模型，利用 VLP 处理放射图像，实验显示在分类和匹配任务上超越 SOTA，提升临床诊断效率。\n- **Large Language Models to Generate System-Level Test Programs Targeting Non-functional Properties**（大型语言模型生成针对非功能属性的系统级测试程序）：作者探索 LLM 在硬件测试中的应用，生成高效 C 代码优化测试程序，显著提升测试速度和鲁棒性。\n- **SurvRNC: Learning Ordered Representations for Survival Prediction using Rank-N-Contrast**（SurvRNC: 使用 Rank-N-Contrast 学习有序表示进行生存预测）：该方法通过有序表示和损失函数改进肿瘤预测，在 HECKTOR 数据集上提升 3.6% 的 C-index，适用于癌症风险评估。\n\n### 其他快速掠过（次要或基础主题）\n- **Variance-Dependent Regret Bounds for Non-stationary Linear Bandits**（非平稳线性老虎机问题的方差相关遗憾界）：提出新算法处理非平稳强化学习，优化遗憾界，实验验证性能提升。\n- **Apriori Knowledge in an Era of Computational Opacity: The Role of AI in Mathematical Discovery**（计算不透明时代的前验知识：AI 在数学发现中的作用）：讨论 AI 在数学证明中的局限性，建议结合证明检查器提升知识获取。\n- **EfficientVMamba: Atrous Selective Scan for Light Weight Visual Mamba**（EfficientVMamba: 用于轻量级视觉 Mamba 的 Atrous 选择性扫描）：优化状态空间模型，减少计算复杂度，在图像任务上保持竞争力。\n- **The Whole is Better than the Sum: Using Aggregated Demonstrations in In-Context Learning for Sequential Recommendation**（整体优于部分：使用聚合演示进行序列推荐的 In-Context 学习）：探索 LLM 在推荐中的演示聚合，提升准确率。\n- 其余论文如优化算法（e.g., \"Improved discrete particle swarm optimization\"）和理论方法（e.g., \"Limits of Approximating the Median Treatment Effect\"）等，贡献在于算法改进，但影响力较小，故简要提及为算法效率优化，无重大突破。\n\n今天的论文总体上体现了 AI 模型在实际应用中的高效性和鲁棒性，LLM 相关工作尤其值得关注。更多细节可查阅 arXiv 页面！",
  "papers": [
    {
      "arxiv_id": "2403.10732v1",
      "title": "Variance-Dependent Regret Bounds for Non-stationary Linear Bandits",
      "title_zh": "翻译失败",
      "authors": [
        "Zhiyong Wang",
        "Jize Xie",
        "Yi Chen",
        "John C. S. Lui",
        "Dongruo Zhou"
      ],
      "abstract": "We investigate the non-stationary stochastic linear bandit problem where the\nreward distribution evolves each round. Existing algorithms characterize the\nnon-stationarity by the total variation budget $B_K$, which is the summation of\nthe change of the consecutive feature vectors of the linear bandits over $K$\nrounds. However, such a quantity only measures the non-stationarity with\nrespect to the expectation of the reward distribution, which makes existing\nalgorithms sub-optimal under the general non-stationary distribution setting.\nIn this work, we propose algorithms that utilize the variance of the reward\ndistribution as well as the $B_K$, and show that they can achieve tighter\nregret upper bounds. Specifically, we introduce two novel algorithms: Restarted\nWeighted$\\text{OFUL}^+$ and Restarted $\\text{SAVE}^+$. These algorithms address\ncases where the variance information of the rewards is known and unknown,\nrespectively. Notably, when the total variance $V_K$ is much smaller than $K$,\nour algorithms outperform previous state-of-the-art results on non-stationary\nstochastic linear bandits under different settings. Experimental evaluations\nfurther validate the superior performance of our proposed algorithms over\nexisting works.",
      "tldr_zh": "本文研究非平稳随机线性老虎机（non-stationary stochastic linear bandits）问题，现有算法仅依赖总变异预算 $B_K$ 来衡量非平稳性，导致在一般分布设置下 suboptimal。作者提出两种新算法：Restarted Weighted OFUL+（适用于奖励方差信息已知的情况）和 Restarted SAVE+（适用于方差信息未知的情况），这些算法结合了奖励分布的 variance 和 $B_K$，从而实现更紧的 regret bounds。当总方差 $V_K$ 远小于回合数 $K$ 时，该方法显著优于现有技术，实验结果进一步验证了其优越性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "30 pages",
      "pdf_url": "http://arxiv.org/pdf/2403.10732v1",
      "published_date": "2024-03-15 23:36:55 UTC",
      "updated_date": "2024-03-15 23:36:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T15:44:10.443632"
    },
    {
      "arxiv_id": "2403.10726v2",
      "title": "Strict Partitioning for Sporadic Rigid Gang Tasks",
      "title_zh": "翻译失败",
      "authors": [
        "Binqi Sun",
        "Tomasz Kloda",
        "Marco Caccamo"
      ],
      "abstract": "The rigid gang task model is based on the idea of executing multiple threads\nsimultaneously on a fixed number of processors to increase efficiency and\nperformance. Although there is extensive literature on global rigid gang\nscheduling, partitioned approaches have several practical advantages (e.g.,\ntask isolation and reduced scheduling overheads). In this paper, we propose a\nnew partitioned scheduling strategy for rigid gang tasks, named strict\npartitioning. The method creates disjoint partitions of tasks and processors to\navoid inter-partition interference. Moreover, it tries to assign tasks with\nsimilar volumes (i.e., parallelisms) to the same partition so that the\nintra-partition interference can be reduced. Within each partition, the tasks\ncan be scheduled using any type of scheduler, which allows the use of a less\npessimistic schedulability test. Extensive synthetic experiments and a case\nstudy based on Edge TPU benchmarks show that strict partitioning achieves\nbetter schedulability performance than state-of-the-art global gang\nschedulability analyses for both preemptive and non-preemptive rigid gang task\nsets.",
      "tldr_zh": "这篇论文针对间断性 Rigid Gang Tasks 提出了一种新的分区调度策略，名为 Strict Partitioning，以提升任务隔离和减少调度开销。该方法通过创建不相交的任务和处理器分区，避免分区间干扰，并将类似并行度（volumes）的任务分配到同一分区，从而降低分区内干扰；此外，每个分区内可使用任意调度器，实现更乐观的 Schedulability 测试。实验结果，包括广泛的合成实验和基于 Edge TPU 基准的案例研究，表明 Strict Partitioning 在抢占和非抢占 Rigid Gang Tasks 集上，比现有全局调度分析表现出更好的 Schedulability 性能。",
      "categories": [
        "cs.DC",
        "cs.AI",
        "cs.AR"
      ],
      "primary_category": "cs.DC",
      "comment": "Published in IEEE Real-Time and Embedded Technology and Applications\n  Symposium (RTAS 2024)",
      "pdf_url": "http://arxiv.org/pdf/2403.10726v2",
      "published_date": "2024-03-15 23:17:24 UTC",
      "updated_date": "2024-09-01 05:05:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T15:44:22.149977"
    },
    {
      "arxiv_id": "2403.10720v1",
      "title": "Development and Application of a Monte Carlo Tree Search Algorithm for Simulating Da Vinci Code Game Strategies",
      "title_zh": "Monte Carlo Tree Search 算法的开发与",
      "authors": [
        "Ye Zhang",
        "Mengran Zhu",
        "Kailin Gui",
        "Jiayue Yu",
        "Yong Hao",
        "Haozhan Sun"
      ],
      "abstract": "In this study, we explore the efficiency of the Monte Carlo Tree Search\n(MCTS), a prominent decision-making algorithm renowned for its effectiveness in\ncomplex decision environments, contingent upon the volume of simulations\nconducted. Notwithstanding its broad applicability, the algorithm's performance\ncan be adversely impacted in certain scenarios, particularly within the domain\nof game strategy development. This research posits that the inherent branch\ndivergence within the Da Vinci Code board game significantly impedes\nparallelism when executed on Graphics Processing Units (GPUs). To investigate\nthis hypothesis, we implemented and meticulously evaluated two variants of the\nMCTS algorithm, specifically designed to assess the impact of branch divergence\non computational performance. Our comparative analysis reveals a linear\nimprovement in performance with the CPU-based implementation, in stark contrast\nto the GPU implementation, which exhibits a non-linear enhancement pattern and\ndiscernible performance troughs. These findings contribute to a deeper\nunderstanding of the MCTS algorithm's behavior in divergent branch scenarios,\nhighlighting critical considerations for optimizing game strategy algorithms on\nparallel computing architectures.",
      "tldr_zh": "本研究探讨了 Monte Carlo Tree Search (MCTS) 算法在模拟 Da Vinci Code 棋盘游戏策略时的效率，重点分析其在复杂决策环境中的性能受模拟量和分支发散（branch divergence）影响。研究者实现了两种 MCTS 变体，分别在 CPU 和 GPU 上进行评估，以检验分支发散对并行计算性能的阻碍作用。结果显示，CPU 实现表现出线性性能提升，而 GPU 实现则呈现非线性改进并伴随明显性能低谷。这些发现加深了对 MCTS 在分支发散场景下行为的理解，并为优化游戏策略算法在并行计算架构上的设计提供了关键指导。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "This paper has been accepted by CVIDL2024",
      "pdf_url": "http://arxiv.org/pdf/2403.10720v1",
      "published_date": "2024-03-15 22:43:37 UTC",
      "updated_date": "2024-03-15 22:43:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T15:44:33.002981"
    },
    {
      "arxiv_id": "2403.10717v1",
      "title": "Backdoor Secrets Unveiled: Identifying Backdoor Data with Optimized Scaled Prediction Consistency",
      "title_zh": "后门秘密揭露：使用优化的缩放预测一致性识别后门数据",
      "authors": [
        "Soumyadeep Pal",
        "Yuguang Yao",
        "Ren Wang",
        "Bingquan Shen",
        "Sijia Liu"
      ],
      "abstract": "Modern machine learning (ML) systems demand substantial training data, often\nresorting to external sources. Nevertheless, this practice renders them\nvulnerable to backdoor poisoning attacks. Prior backdoor defense strategies\nhave primarily focused on the identification of backdoored models or poisoned\ndata characteristics, typically operating under the assumption of access to\nclean data. In this work, we delve into a relatively underexplored challenge:\nthe automatic identification of backdoor data within a poisoned dataset, all\nunder realistic conditions, i.e., without the need for additional clean data or\nwithout manually defining a threshold for backdoor detection. We draw an\ninspiration from the scaled prediction consistency (SPC) technique, which\nexploits the prediction invariance of poisoned data to an input scaling factor.\nBased on this, we pose the backdoor data identification problem as a\nhierarchical data splitting optimization problem, leveraging a novel SPC-based\nloss function as the primary optimization objective. Our innovation unfolds in\nseveral key aspects. First, we revisit the vanilla SPC method, unveiling its\nlimitations in addressing the proposed backdoor identification problem.\nSubsequently, we develop a bi-level optimization-based approach to precisely\nidentify backdoor data by minimizing the advanced SPC loss. Finally, we\ndemonstrate the efficacy of our proposal against a spectrum of backdoor\nattacks, encompassing basic label-corrupted attacks as well as more\nsophisticated clean-label attacks, evaluated across various benchmark datasets.\nExperiment results show that our approach often surpasses the performance of\ncurrent baselines in identifying backdoor data points, resulting in about\n4%-36% improvement in average AUROC. Codes are available at\nhttps://github.com/OPTML-Group/BackdoorMSPC.",
      "tldr_zh": "本研究针对机器学习系统在外部数据来源中面临的backdoor poisoning attacks，提出了一种无需额外clean data或手动阈值的自动backdoor data识别方法。作者基于scaled prediction consistency (SPC)技术，将问题转化为一个hierarchical data splitting优化问题，并开发了bi-level optimization方法来最小化新型SPC-based损失函数，以克服vanilla SPC的局限性。实验结果显示，该方法在各种backdoor attacks（包括基本和高级clean-label攻击）上，在多个基准数据集上平均AUROC提升4%-36%，显著优于现有基线。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.LG",
      "comment": "The Twelfth International Conference on Learning Representations\n  (ICLR 2024)",
      "pdf_url": "http://arxiv.org/pdf/2403.10717v1",
      "published_date": "2024-03-15 22:35:07 UTC",
      "updated_date": "2024-03-15 22:35:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T15:44:44.514738"
    },
    {
      "arxiv_id": "2403.10707v2",
      "title": "Discovering Latent Themes in Social Media Messaging: A Machine-in-the-Loop Approach Integrating LLMs",
      "title_zh": "在社交媒体消息中发现潜在主题：一种整合LLMs的机器在环方法",
      "authors": [
        "Tunazzina Islam",
        "Dan Goldwasser"
      ],
      "abstract": "Grasping the themes of social media content is key to understanding the\nnarratives that influence public opinion and behavior. The thematic analysis\ngoes beyond traditional topic-level analysis, which often captures only the\nbroadest patterns, providing deeper insights into specific and actionable\nthemes such as \"public sentiment towards vaccination\", \"political discourse\nsurrounding climate policies,\" etc. In this paper, we introduce a novel\napproach to uncovering latent themes in social media messaging. Recognizing the\nlimitations of the traditional topic-level analysis, which tends to capture\nonly overarching patterns, this study emphasizes the need for a finer-grained,\ntheme-focused exploration. Traditional theme discovery methods typically\ninvolve manual processes and a human-in-the-loop approach. While valuable,\nthese methods face challenges in scalability, consistency, and resource\nintensity in terms of time and cost. To address these challenges, we propose a\nmachine-in-the-loop approach that leverages the advanced capabilities of Large\nLanguage Models (LLMs). To demonstrate our approach, we apply our framework to\ncontentious topics, such as climate debate and vaccine debate. We use two\npublicly available datasets: (1) the climate campaigns dataset of 21k Facebook\nads and (2) the COVID-19 vaccine campaigns dataset of 9k Facebook ads. Our\nquantitative and qualitative analysis shows that our methodology yields more\naccurate and interpretable results compared to the baselines. Our results not\nonly demonstrate the effectiveness of our approach in uncovering latent themes\nbut also illuminate how these themes are tailored for demographic targeting in\nsocial media contexts. Additionally, our work sheds light on the dynamic nature\nof social media, revealing the shifts in the thematic focus of messaging in\nresponse to real-world events.",
      "tldr_zh": "这篇论文提出了一种 machine-in-the-loop 方法，整合 Large Language Models (LLMs)，用于发现社交媒体消息中的潜在主题，从而超越传统主题级分析的局限性，提供更细致且可操作的洞见，如公众对疫苗的态度或气候政策的讨论。作者使用两个公开数据集（包括21k条气候相关Facebook广告和9k条COVID-19疫苗广告）进行实验，结果显示该方法比基线模型更准确和可解释，并揭示了主题如何针对特定人群并随实时事件动态变化。该研究强调了LLMs在提升主题发现效率和一致性方面的潜力，为大规模社交媒体分析提供了新框架。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY",
        "cs.LG",
        "cs.SI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted at 19th International AAAI Conference on Web and Social\n  Media (ICWSM-2025)",
      "pdf_url": "http://arxiv.org/pdf/2403.10707v2",
      "published_date": "2024-03-15 21:54:00 UTC",
      "updated_date": "2024-07-15 12:14:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T15:44:57.278126"
    },
    {
      "arxiv_id": "2403.10704v2",
      "title": "Parameter Efficient Reinforcement Learning from Human Feedback",
      "title_zh": "基于人类反馈的参数高效强化学习",
      "authors": [
        "Hakim Sidahmed",
        "Samrat Phatale",
        "Alex Hutcheson",
        "Zhuonan Lin",
        "Zhang Chen",
        "Zac Yu",
        "Jarvis Jin",
        "Simral Chaudhary",
        "Roman Komarytsia",
        "Christiane Ahlheim",
        "Yonghao Zhu",
        "Bowen Li",
        "Saravanan Ganesh",
        "Bill Byrne",
        "Jessica Hoffmann",
        "Hassan Mansoor",
        "Wei Li",
        "Abhinav Rastogi",
        "Lucas Dixon"
      ],
      "abstract": "While Reinforcement Learning from Human Feedback (RLHF) effectively aligns\npretrained Large Language and Vision-Language Models (LLMs, and VLMs) with\nhuman preferences, its computational cost and complexity hamper its wider\nadoption. To alleviate some of the computational burden of fine-tuning,\nparameter efficient methods, like LoRA were introduced. In this work, we\nempirically evaluate the setup of Parameter Efficient Reinforcement Learning\nfrom Human Feedback (PE-RLHF) that leverages LoRA fine-tuning for Reward\nModeling, and Reinforcement Learning. We benchmark the PE-RLHF setup on six\ndiverse datasets spanning summarization, harmless/helpful response generation,\nUI automation, and visual question answering in terms of effectiveness of the\ntrained models, and the training resources required. Our findings show, for the\nfirst time, that PE-RLHF achieves comparable performance to RLHF, while\nsignificantly reducing training time (up to 90% faster for reward models, and\n30% faster for RL), and memory footprint (up to 50% reduction for reward\nmodels, and 27% for RL). We provide comprehensive ablations across LoRA ranks,\nand model sizes for both reward modeling and reinforcement learning. By\nmitigating the computational burden associated with RLHF, we push for a broader\nadoption of PE-RLHF as an alignment technique for LLMs and VLMs.",
      "tldr_zh": "本研究提出了一种参数高效的强化学习从人类反馈（Parameter Efficient Reinforcement Learning from Human Feedback, PE-RLHF）方法，使用LoRA微调技术来优化RLHF过程，从而减少对预训练Large Language Models (LLMs) 和 Vision-Language Models (VLMs) 的计算负担。研究在六个多样化数据集上进行了基准测试，包括摘要生成、无害/有帮助响应生成、UI自动化和视觉问答，结果显示PE-RLHF的模型性能与传统RLHF相当，但训练时间缩短了高达90%（奖励模型）和30%（强化学习），内存占用减少了50%（奖励模型）和27%（强化学习）。通过全面的消融实验分析LoRA ranks和模型大小，该方法显著降低了RLHF的计算成本，促进了LLMs和VLMs对齐技术的更广泛应用。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.10704v2",
      "published_date": "2024-03-15 21:43:46 UTC",
      "updated_date": "2024-09-12 18:25:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T15:45:09.253891"
    },
    {
      "arxiv_id": "2403.15437v2",
      "title": "Apriori Knowledge in an Era of Computational Opacity: The Role of AI in Mathematical Discovery",
      "title_zh": "先验知识在计算不透明性时代：AI 在数学发现中的作用",
      "authors": [
        "Eamon Duede",
        "Kevin Davey"
      ],
      "abstract": "Can we acquire apriori knowledge of mathematical facts from the outputs of\ncomputer programs? People like Burge have argued (correctly in our opinion)\nthat, for example, Appel and Haken acquired apriori knowledge of the Four Color\nTheorem from their computer program insofar as their program simply automated\nhuman forms of mathematical reasoning. However, unlike such programs, we argue\nthat the opacity of modern LLMs and DNNs creates obstacles in obtaining apriori\nmathematical knowledge from them in similar ways. We claim though that if a\nproof-checker automating human forms of proof-checking is attached to such\nmachines, then we can obtain apriori mathematical knowledge from them after\nall, even though the original machines are entirely opaque to us and the proofs\nthey output may not, themselves, be human-surveyable.",
      "tldr_zh": "本论文探讨在计算不透明时代，从AI输出中获取apriori knowledge的可能性。作者同意Burge的观点，即某些计算机程序（如Appel和Haken的程序）通过自动化人类形式的数学推理，能提供apriori数学知识。相比之下，现代LLMs和DNNs的opacity特性阻碍了类似获取，但论文提出，如果附加一个自动化人类证明检查的proof-checker，即使AI本身不透明，也能从中获得apriori知识，从而在数学发现中发挥AI的作用。",
      "categories": [
        "cs.AI",
        "cs.HC",
        "math.HO"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.15437v2",
      "published_date": "2024-03-15 21:38:26 UTC",
      "updated_date": "2024-12-16 21:31:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T15:45:21.518994"
    },
    {
      "arxiv_id": "2403.10700v2",
      "title": "Mind the Error! Detection and Localization of Instruction Errors in Vision-and-Language Navigation",
      "title_zh": "注意错误！ 视觉与语言导航中指令错误的检测和定位",
      "authors": [
        "Francesco Taioli",
        "Stefano Rosa",
        "Alberto Castellini",
        "Lorenzo Natale",
        "Alessio Del Bue",
        "Alessandro Farinelli",
        "Marco Cristani",
        "Yiming Wang"
      ],
      "abstract": "Vision-and-Language Navigation in Continuous Environments (VLN-CE) is one of\nthe most intuitive yet challenging embodied AI tasks. Agents are tasked to\nnavigate towards a target goal by executing a set of low-level actions,\nfollowing a series of natural language instructions. All VLN-CE methods in the\nliterature assume that language instructions are exact. However, in practice,\ninstructions given by humans can contain errors when describing a spatial\nenvironment due to inaccurate memory or confusion. Current VLN-CE benchmarks do\nnot address this scenario, making the state-of-the-art methods in VLN-CE\nfragile in the presence of erroneous instructions from human users. For the\nfirst time, we propose a novel benchmark dataset that introduces various types\nof instruction errors considering potential human causes. This benchmark\nprovides valuable insight into the robustness of VLN systems in continuous\nenvironments. We observe a noticeable performance drop (up to -25%) in Success\nRate when evaluating the state-of-the-art VLN-CE methods on our benchmark.\nMoreover, we formally define the task of Instruction Error Detection and\nLocalization, and establish an evaluation protocol on top of our benchmark\ndataset. We also propose an effective method, based on a cross-modal\ntransformer architecture, that achieves the best performance in error detection\nand localization, compared to baselines. Surprisingly, our proposed method has\nrevealed errors in the validation set of the two commonly used datasets for\nVLN-CE, i.e., R2R-CE and RxR-CE, demonstrating the utility of our technique in\nother tasks. Code and dataset available at\nhttps://intelligolabs.github.io/R2RIE-CE",
      "tldr_zh": "本研究针对 Vision-and-Language Navigation in Continuous Environments (VLN-CE) 的挑战，首次提出一个新基准数据集，引入各种指令错误类型（如人类记忆或混淆导致），以评估系统在不准确指令下的鲁棒性。实验结果显示，现有的 VLN-CE 方法在该基准上成功率下降高达 25%，暴露了其脆弱性。论文正式定义了 Instruction Error Detection and Localization 任务，并建立评估协议，同时提出一种基于 cross-modal transformer 架构的有效方法，该方法在错误检测和定位上优于基线。令人意外的是，该方法还发现了常用数据集 R2R-CE 和 RxR-CE 的验证集错误，展示了其更广泛的应用潜力。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.RO",
      "comment": "3 figures, 8 pages. Accepted at IROS'24",
      "pdf_url": "http://arxiv.org/pdf/2403.10700v2",
      "published_date": "2024-03-15 21:36:15 UTC",
      "updated_date": "2025-01-15 12:45:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T15:45:36.351991"
    },
    {
      "arxiv_id": "2403.10698v2",
      "title": "Robust Influence-based Training Methods for Noisy Brain MRI",
      "title_zh": "翻译失败",
      "authors": [
        "Minh-Hao Van",
        "Alycia N. Carey",
        "Xintao Wu"
      ],
      "abstract": "Correctly classifying brain tumors is imperative to the prompt and accurate\ntreatment of a patient. While several classification algorithms based on\nclassical image processing or deep learning methods have been proposed to\nrapidly classify tumors in MR images, most assume the unrealistic setting of\nnoise-free training data. In this work, we study a difficult but realistic\nsetting of training a deep learning model on noisy MR images to classify brain\ntumors. We propose two training methods that are robust to noisy MRI training\ndata, Influence-based Sample Reweighing (ISR) and Influence-based Sample\nPerturbation (ISP), which are based on influence functions from robust\nstatistics. Using the influence functions, in ISR, we adaptively reweigh\ntraining examples according to how helpful/harmful they are to the training\nprocess, while in ISP, we craft and inject helpful perturbation proportional to\nthe influence score. Both ISR and ISP harden the classification model against\nnoisy training data without significantly affecting the generalization ability\nof the model on test data. We conduct empirical evaluations over a common brain\ntumor dataset and compare ISR and ISP to three baselines. Our empirical results\nshow that ISR and ISP can efficiently train deep learning models robust against\nnoisy training data.",
      "tldr_zh": "本研究针对噪声MRI图像中脑肿瘤分类的实际挑战，提出两种基于influence functions的鲁棒训练方法：Influence-based Sample Reweighing (ISR) 和 Influence-based Sample Perturbation (ISP)。ISR通过影响函数自适应地重新加权训练样本，根据样本对训练过程的有益或有害程度来优化模型，而ISP则通过注入与影响分数成比例的有益扰动来强化模型对噪声的抵抗力。这些方法在常见脑肿瘤数据集上的实验中，显著提高了模型对噪声训练数据的鲁棒性，同时未显著影响其在测试数据上的泛化性能，并优于三个基线方法。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.10698v2",
      "published_date": "2024-03-15 21:30:25 UTC",
      "updated_date": "2024-05-09 22:38:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T15:45:45.827932"
    },
    {
      "arxiv_id": "2403.10692v1",
      "title": "EXPLORER: Exploration-guided Reasoning for Textual Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Kinjal Basu",
        "Keerthiram Murugesan",
        "Subhajit Chaudhury",
        "Murray Campbell",
        "Kartik Talamadupula",
        "Tim Klinger"
      ],
      "abstract": "Text-based games (TBGs) have emerged as an important collection of NLP tasks,\nrequiring reinforcement learning (RL) agents to combine natural language\nunderstanding with reasoning. A key challenge for agents attempting to solve\nsuch tasks is to generalize across multiple games and demonstrate good\nperformance on both seen and unseen objects. Purely deep-RL-based approaches\nmay perform well on seen objects; however, they fail to showcase the same\nperformance on unseen objects. Commonsense-infused deep-RL agents may work\nbetter on unseen data; unfortunately, their policies are often not\ninterpretable or easily transferable. To tackle these issues, in this paper, we\npresent EXPLORER which is an exploration-guided reasoning agent for textual\nreinforcement learning. EXPLORER is neurosymbolic in nature, as it relies on a\nneural module for exploration and a symbolic module for exploitation. It can\nalso learn generalized symbolic policies and perform well over unseen data. Our\nexperiments show that EXPLORER outperforms the baseline agents on Text-World\ncooking (TW-Cooking) and Text-World Commonsense (TWC) games.",
      "tldr_zh": "这篇论文针对文本游戏 (TBGs) 中的强化学习 (RL) 代理，提出 EXPLORER 框架，以解决代理在多个游戏中泛化能力不足的问题，特别是对已见和未见对象的性能差异。EXPLORER 采用神经符号 (neurosymbolic) 设计，包括神经模块用于探索和符号模块用于利用，从而学习可解释且可转移的符号政策。实验结果表明，该框架在 Text-World Cooking (TW-Cooking) 和 Text-World Commonsense (TWC) 游戏上优于基线代理，提升了代理在未见数据上的表现。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LO"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.10692v1",
      "published_date": "2024-03-15 21:22:37 UTC",
      "updated_date": "2024-03-15 21:22:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T15:45:58.564906"
    },
    {
      "arxiv_id": "2403.10691v2",
      "title": "MYTE: Morphology-Driven Byte Encoding for Better and Fairer Multilingual Language Modeling",
      "title_zh": "翻译失败",
      "authors": [
        "Tomasz Limisiewicz",
        "Terra Blevins",
        "Hila Gonen",
        "Orevaoghene Ahia",
        "Luke Zettlemoyer"
      ],
      "abstract": "A major consideration in multilingual language modeling is how to best\nrepresent languages with diverse vocabularies and scripts. Although\ncontemporary text encoding methods cover most of the world's writing systems,\nthey exhibit bias towards the high-resource languages of the Global West. As a\nresult, texts of underrepresented languages tend to be segmented into long\nsequences of linguistically meaningless units. To address the disparities, we\nintroduce a new paradigm that encodes the same information with segments of\nconsistent size across diverse languages. Our encoding convention (MYTE) is\nbased on morphemes, as their inventories are more balanced across languages\nthan characters, which are used in previous methods. We show that MYTE produces\nshorter encodings for all 99 analyzed languages, with the most notable\nimprovements for non-European languages and non-Latin scripts. This, in turn,\nimproves multilingual LM performance and diminishes the perplexity gap\nthroughout diverse languages.",
      "tldr_zh": "本文提出MYTE，一种基于morphemes的字节编码方法，旨在解决多语言建模中现有方法对高资源语言（如西方语言）的偏见问题，通过确保不同语言编码段长度一致来改善文本表示。相比基于characters的传统方法，MYTE在99种语言上生成更短的编码，尤其对非欧洲语言和非-Latin脚本有显著提升。结果显示，MYTE提高了多语言LM的性能，并显著减少了语言间的perplexity差距，促进更公平的语言建模。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Published at ACL 2024",
      "pdf_url": "http://arxiv.org/pdf/2403.10691v2",
      "published_date": "2024-03-15 21:21:11 UTC",
      "updated_date": "2024-11-11 13:33:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T15:46:12.444262"
    },
    {
      "arxiv_id": "2403.10686v1",
      "title": "AutoHLS: Learning to Accelerate Design Space Exploration for HLS Designs",
      "title_zh": "翻译失败",
      "authors": [
        "Md Rubel Ahmed",
        "Toshiaki Koike-Akino",
        "Kieran Parsons",
        "Ye Wang"
      ],
      "abstract": "High-level synthesis (HLS) is a design flow that leverages modern language\nfeatures and flexibility, such as complex data structures, inheritance,\ntemplates, etc., to prototype hardware designs rapidly. However, exploring\nvarious design space parameters can take much time and effort for hardware\nengineers to meet specific design specifications. This paper proposes a novel\nframework called AutoHLS, which integrates a deep neural network (DNN) with\nBayesian optimization (BO) to accelerate HLS hardware design optimization. Our\ntool focuses on HLS pragma exploration and operation transformation. It\nutilizes integrated DNNs to predict synthesizability within a given FPGA\nresource budget. We also investigate the potential of emerging quantum neural\nnetworks (QNNs) instead of classical DNNs for the AutoHLS pipeline. Our\nexperimental results demonstrate up to a 70-fold speedup in exploration time.",
      "tldr_zh": "这篇论文提出 AutoHLS 框架，利用深度神经网络 (DNN) 和 Bayesian optimization (BO) 整合，旨在加速 High-level synthesis (HLS) 设计的空间探索问题，减少硬件工程师在 HLS pragma exploration 和 operation transformation 上的时间和努力。框架通过 DNN 预测给定 FPGA 资源预算下的 synthesizability，并探讨了使用量子神经网络 (QNNs) 作为替代方案的可能性。实验结果显示，AutoHLS 比传统方法实现了高达 70 倍的探索时间加速，为高效的硬件设计优化提供了新途径。",
      "categories": [
        "cs.AR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AR",
      "comment": "5 pages, 6 figures, MWSCAS 2023",
      "pdf_url": "http://arxiv.org/pdf/2403.10686v1",
      "published_date": "2024-03-15 21:14:44 UTC",
      "updated_date": "2024-03-15 21:14:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T15:46:23.750116"
    },
    {
      "arxiv_id": "2403.10684v1",
      "title": "Improved discrete particle swarm optimization using Bee Algorithm and multi-parent crossover method (Case study: Allocation problem and benchmark functions)",
      "title_zh": "翻译失败",
      "authors": [
        "Hamed Zibaei",
        "Mohammad Saadi Mesgari"
      ],
      "abstract": "Compared to other techniques, particle swarm optimization is more frequently\nutilized because of its ease of use and low variability. However, it is\ncomplicated to find the best possible solution in the search space in\nlarge-scale optimization problems. Moreover, changing algorithm variables does\nnot influence algorithm convergence much. The PSO algorithm can be combined\nwith other algorithms. It can use their advantages and operators to solve this\nproblem. Therefore, this paper proposes the onlooker multi-parent crossover\ndiscrete particle swarm optimization (OMPCDPSO). To improve the efficiency of\nthe DPSO algorithm, we utilized multi-parent crossover on the best solutions.\nWe performed an independent and intensive neighborhood search using the\nonlooker bees of the bee algorithm. The algorithm uses onlooker bees and\ncrossover. They do local search (exploitation) and global search (exploration).\nEach of these searches is among the best solutions (employed bees). The\nproposed algorithm was tested on the allocation problem, which is an NP-hard\noptimization problem. Also, we used two types of simulated data. They were used\nto test the scalability and complexity of the better algorithm. Also, fourteen\n2D test functions and thirteen 30D test functions were used. They also used\ntwenty IEEE CEC2005 benchmark functions to test the efficiency of OMPCDPSO.\nAlso, to test OMPCDPSO's performance, we compared it to four new binary\noptimization algorithms and three classic ones. The results show that the\nOMPCDPSO version had high capability. It performed better than other\nalgorithms. The developed algorithm in this research (OMCDPSO) in 36 test\nfunctions out of 47 (76.60%) is better than other algorithms. The Onlooker bees\nand multi-parent operators significantly impact the algorithm's performance.",
      "tldr_zh": "这篇论文提出了一种改进的离散粒子群优化算法（OMPCDPSO），通过整合 Bee Algorithm 的观察者蜜蜂和 multi-parent crossover 方法，解决 PSO 在大规模优化问题中难以找到最优解的问题，并提升算法的收敛性和探索能力。算法在最佳解上应用 multi-parent crossover 进行局部搜索（exploitation），并利用 onlooker bees 实现全局搜索（exploration）。测试结果显示，OMPCDPSO 在分配问题（NP-hard 问题）和各种基准函数（如 14 个 2D 测试函数、13 个 30D 测试函数及 20 个 IEEE CEC2005 函数）上，与其他七个算法比较，在 47 个测试函数中 76.60% 的情况下表现更优，证明了观察者蜜蜂和多亲本操作的显著影响。",
      "categories": [
        "cs.NE",
        "cs.AI"
      ],
      "primary_category": "cs.NE",
      "comment": "34 pages, 8 figures, 15 tables",
      "pdf_url": "http://arxiv.org/pdf/2403.10684v1",
      "published_date": "2024-03-15 21:08:37 UTC",
      "updated_date": "2024-03-15 21:08:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T15:46:37.951649"
    },
    {
      "arxiv_id": "2403.14697v1",
      "title": "An AIC-based approach for articulating unpredictable problems in open complex environments",
      "title_zh": "翻译失败",
      "authors": [
        "Haider AL-Shareefy",
        "Michael Butler",
        "Thai Son Hoang"
      ],
      "abstract": "This research paper presents an approach to enhancing the predictive\ncapability of architects in the design and assurance of systems, focusing on\nsystems operating in dynamic and unpredictable environments. By adopting a\nsystems approach, we aim to improve architects' predictive capabilities in\ndesigning dependable systems (for example, ML-based systems). An aerospace case\nstudy is used to illustrate the approach. Multiple factors (challenges)\ninfluencing aircraft detection are identified, demonstrating the effectiveness\nof our approach in a complex operational setting. Our approach primarily aimed\nto enhance the architect's predictive capability.",
      "tldr_zh": "这篇论文提出了一种基于AIC的方法，用于表述和处理开放复杂环境中不可预测的问题，旨在提升建筑师在设计和保障系统（如ML-based systems）时的预测能力。通过采用系统方法，该研究以航空航天案例为例，识别了影响飞机检测的多重挑战（factors），展示了方法的有效性。主要贡献在于增强建筑师的预测能力，使系统在动态环境中更可靠。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.SE"
      ],
      "primary_category": "cs.CY",
      "comment": "S. Bernardi, T. Zoppi (Editors), \"Fast Abstracts and Student Forum\n  Proceedings - EDCC 2024 - 19th European Dependable Computing Conference,\n  Leuven, Belgium, 8-11 April 2024\"",
      "pdf_url": "http://arxiv.org/pdf/2403.14697v1",
      "published_date": "2024-03-15 20:30:02 UTC",
      "updated_date": "2024-03-15 20:30:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T15:46:46.769399"
    },
    {
      "arxiv_id": "2403.10667v2",
      "title": "Towards Unified Multi-Modal Personalization: Large Vision-Language Models for Generative Recommendation and Beyond",
      "title_zh": "翻译失败",
      "authors": [
        "Tianxin Wei",
        "Bowen Jin",
        "Ruirui Li",
        "Hansi Zeng",
        "Zhengyang Wang",
        "Jianhui Sun",
        "Qingyu Yin",
        "Hanqing Lu",
        "Suhang Wang",
        "Jingrui He",
        "Xianfeng Tang"
      ],
      "abstract": "Developing a universal model that can effectively harness heterogeneous\nresources and respond to a wide range of personalized needs has been a\nlongstanding community aspiration. Our daily choices, especially in domains\nlike fashion and retail, are substantially shaped by multi-modal data, such as\npictures and textual descriptions. These modalities not only offer intuitive\nguidance but also cater to personalized user preferences. However, the\npredominant personalization approaches mainly focus on the ID or text-based\nrecommendation problem, failing to comprehend the information spanning various\ntasks or modalities. In this paper, our goal is to establish a Unified paradigm\nfor Multi-modal Personalization systems (UniMP), which effectively leverages\nmulti-modal data while eliminating the complexities associated with task- and\nmodality-specific customization. We argue that the advancements in foundational\ngenerative modeling have provided the flexibility and effectiveness necessary\nto achieve the objective. In light of this, we develop a generic and extensible\npersonalization generative framework, that can handle a wide range of\npersonalized needs including item recommendation, product search, preference\nprediction, explanation generation, and further user-guided image generation.\nOur methodology enhances the capabilities of foundational language models for\npersonalized tasks by seamlessly ingesting interleaved cross-modal user history\ninformation, ensuring a more precise and customized experience for users. To\ntrain and evaluate the proposed multi-modal personalized tasks, we also\nintroduce a novel and comprehensive benchmark covering a variety of user\nrequirements. Our experiments on the real-world benchmark showcase the model's\npotential, outperforming competitive methods specialized for each task.",
      "tldr_zh": "本论文旨在开发一个统一的范式 UniMP，用于多模态个性化系统，利用 Large Vision-Language Models 处理异构资源和广泛的用户个性化需求，如时尚和零售领域的图片及文本数据。研究提出一个通用、可扩展的生成框架，能够无缝整合交叉模态用户历史信息，支持多种任务包括项目推荐、产品搜索、偏好预测、解释生成以及用户引导图像生成。实验结果显示，该框架在新型综合基准数据集上表现优于竞争方法，为多模态个性化应用提供了更灵活和有效的解决方案。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CL",
        "cs.MM"
      ],
      "primary_category": "cs.IR",
      "comment": "ICLR 2024",
      "pdf_url": "http://arxiv.org/pdf/2403.10667v2",
      "published_date": "2024-03-15 20:21:31 UTC",
      "updated_date": "2024-03-27 21:11:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T15:47:00.253184"
    },
    {
      "arxiv_id": "2403.10618v1",
      "title": "Limits of Approximating the Median Treatment Effect",
      "title_zh": "翻译失败",
      "authors": [
        "Raghavendra Addanki",
        "Siddharth Bhandari"
      ],
      "abstract": "Average Treatment Effect (ATE) estimation is a well-studied problem in causal\ninference. However, it does not necessarily capture the heterogeneity in the\ndata, and several approaches have been proposed to tackle the issue, including\nestimating the Quantile Treatment Effects. In the finite population setting\ncontaining $n$ individuals, with treatment and control values denoted by the\npotential outcome vectors $\\mathbf{a}, \\mathbf{b}$, much of the prior work\nfocused on estimating median$(\\mathbf{a}) -$ median$(\\mathbf{b})$, where\nmedian($\\mathbf x$) denotes the median value in the sorted ordering of all the\nvalues in vector $\\mathbf x$. It is known that estimating the difference of\nmedians is easier than the desired estimand of median$(\\mathbf{a-b})$, called\nthe Median Treatment Effect (MTE). The fundamental problem of causal inference\n-- for every individual $i$, we can only observe one of the potential outcome\nvalues, i.e., either the value $a_i$ or $b_i$, but not both, makes estimating\nMTE particularly challenging. In this work, we argue that MTE is not estimable\nand detail a novel notion of approximation that relies on the sorted order of\nthe values in $\\mathbf{a-b}$. Next, we identify a quantity called variability\nthat exactly captures the complexity of MTE estimation. By drawing connections\nto instance-optimality studied in theoretical computer science, we show that\nevery algorithm for estimating the MTE obtains an approximation error that is\nno better than the error of an algorithm that computes variability. Finally, we\nprovide a simple linear time algorithm for computing the variability exactly.\nUnlike much prior work, a particular highlight of our work is that we make no\nassumptions about how the potential outcome vectors are generated or how they\nare correlated, except that the potential outcome values are $k$-ary, i.e.,\ntake one of $k$ discrete values.",
      "tldr_zh": "本研究探讨了中位数治疗效果 (MTE) 的估计极限，指出在因果推断的有限人群设置中，MTE（即 median(a - b)）由于只能观察每个个体的单一潜在结果（a_i 或 b_i），而无法精确估计。作者引入一个基于 a-b 排序顺序的新近似概念，并定义了 variability 来量化估计的复杂性，通过连接理论计算机科学中的实例最优性，证明任何算法的近似误差不会优于 variability 的计算水平。该工作提供了一个简单线性时间算法来精确计算 variability，且不做任何关于潜在结果生成或相关性的假设，仅假设潜在结果值为 k-ary（取 k 个离散值）。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DS",
        "econ.EM",
        "stat.ME"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.10618v1",
      "published_date": "2024-03-15 18:30:06 UTC",
      "updated_date": "2024-03-15 18:30:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T15:47:13.409781"
    },
    {
      "arxiv_id": "2403.10603v1",
      "title": "SurvRNC: Learning Ordered Representations for Survival Prediction using Rank-N-Contrast",
      "title_zh": "翻译失败",
      "authors": [
        "Numan Saeed",
        "Muhammad Ridzuan",
        "Fadillah Adamsyah Maani",
        "Hussain Alasmawi",
        "Karthik Nandakumar",
        "Mohammad Yaqub"
      ],
      "abstract": "Predicting the likelihood of survival is of paramount importance for\nindividuals diagnosed with cancer as it provides invaluable information\nregarding prognosis at an early stage. This knowledge enables the formulation\nof effective treatment plans that lead to improved patient outcomes. In the\npast few years, deep learning models have provided a feasible solution for\nassessing medical images, electronic health records, and genomic data to\nestimate cancer risk scores. However, these models often fall short of their\npotential because they struggle to learn regression-aware feature\nrepresentations. In this study, we propose Survival Rank-N Contrast (SurvRNC)\nmethod, which introduces a loss function as a regularizer to obtain an ordered\nrepresentation based on the survival times. This function can handle censored\ndata and can be incorporated into any survival model to ensure that the learned\nrepresentation is ordinal. The model was extensively evaluated on a HEad \\&\nNeCK TumOR (HECKTOR) segmentation and the outcome-prediction task dataset. We\ndemonstrate that using the SurvRNC method for training can achieve higher\nperformance on different deep survival models. Additionally, it outperforms\nstate-of-the-art methods by 3.6% on the concordance index. The code is publicly\navailable on https://github.com/numanai/SurvRNC",
      "tldr_zh": "该研究针对癌症生存预测的挑战，提出了一种名为 SurvRNC 的方法，利用 Rank-N-Contrast 技术学习基于生存时间的有序表示，以克服深度学习模型在回归感知特征表示上的不足。SurvRNC 通过引入一个损失函数作为正则化器，能够处理 censored 数据，并轻松整合到任何生存模型中，以确保表示的有序性。在 HECKTOR 数据集上的实验表明，该方法显著提升了不同深度生存模型的性能，比最先进方法提高了 3.6% 的 concordance index，并已公开代码以供进一步应用。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.10603v1",
      "published_date": "2024-03-15 18:00:11 UTC",
      "updated_date": "2024-03-15 18:00:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T15:47:24.536109"
    },
    {
      "arxiv_id": "2403.10596v1",
      "title": "Neural Erosion: Emulating Controlled Neurodegeneration and Aging in AI Systems",
      "title_zh": "翻译失败",
      "authors": [
        "Antonios Alexos",
        "Yu-Dai Tsai",
        "Ian Domingo",
        "Maryam Pishgar",
        "Pierre Baldi"
      ],
      "abstract": "Creating controlled methods to simulate neurodegeneration in artificial\nintelligence (AI) is crucial for applications that emulate brain function\ndecline and cognitive disorders. We use IQ tests performed by Large Language\nModels (LLMs) and, more specifically, the LLaMA 2 to introduce the concept of\n``neural erosion.\" This deliberate erosion involves ablating synapses or\nneurons, or adding Gaussian noise during or after training, resulting in a\ncontrolled progressive decline in the LLMs' performance. We are able to\ndescribe the neurodegeneration in the IQ tests and show that the LLM first\nloses its mathematical abilities and then its linguistic abilities, while\nfurther losing its ability to understand the questions. To the best of our\nknowledge, this is the first work that models neurodegeneration with text data,\ncompared to other works that operate in the computer vision domain. Finally, we\ndraw similarities between our study and cognitive decline clinical studies\ninvolving test subjects. We find that with the application of neurodegenerative\nmethods, LLMs lose abstract thinking abilities, followed by mathematical\ndegradation, and ultimately, a loss in linguistic ability, responding to\nprompts incoherently. These findings are in accordance with human studies.",
      "tldr_zh": "本研究引入 Neural Erosion 概念，通过在 Large Language Models (LLMs) 如 LLaMA 2 上模拟受控神经退化（如切除突触/神经元或添加 Gaussian noise），以模仿 AI 系统的认知衰退。方法涉及使用 IQ tests 观察模型性能的渐进下降，结果显示 LLMs 先失去数学能力、随后语言能力，并最终无法理解问题。相比于计算机视觉领域的相关工作，这是有史以来首个在文本数据上建模神经退化的研究，且其发现与人类认知衰退临床研究一致，突显了抽象思维和语言能力的顺序退化。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "q-bio.NC"
      ],
      "primary_category": "cs.CL",
      "comment": "19 pages, 6 figures in the main text, 5 figures in the Appendix",
      "pdf_url": "http://arxiv.org/pdf/2403.10596v1",
      "published_date": "2024-03-15 18:00:00 UTC",
      "updated_date": "2024-03-15 18:00:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T15:47:36.823231"
    },
    {
      "arxiv_id": "2403.10517v1",
      "title": "VideoAgent: Long-form Video Understanding with Large Language Model as Agent",
      "title_zh": "翻译失败",
      "authors": [
        "Xiaohan Wang",
        "Yuhui Zhang",
        "Orr Zohar",
        "Serena Yeung-Levy"
      ],
      "abstract": "Long-form video understanding represents a significant challenge within\ncomputer vision, demanding a model capable of reasoning over long multi-modal\nsequences. Motivated by the human cognitive process for long-form video\nunderstanding, we emphasize interactive reasoning and planning over the ability\nto process lengthy visual inputs. We introduce a novel agent-based system,\nVideoAgent, that employs a large language model as a central agent to\niteratively identify and compile crucial information to answer a question, with\nvision-language foundation models serving as tools to translate and retrieve\nvisual information. Evaluated on the challenging EgoSchema and NExT-QA\nbenchmarks, VideoAgent achieves 54.1% and 71.3% zero-shot accuracy with only\n8.4 and 8.2 frames used on average. These results demonstrate superior\neffectiveness and efficiency of our method over the current state-of-the-art\nmethods, highlighting the potential of agent-based approaches in advancing\nlong-form video understanding.",
      "tldr_zh": "该研究提出VideoAgent，一种基于Large Language Model作为核心代理的系统，用于处理长视频理解挑战。该系统通过交互式推理和规划，迭代识别并编译关键信息，而非直接处理完整视频序列，并利用vision-language foundation models作为工具来翻译和检索视觉数据。在EgoSchema和NExT-QA基准测试中，VideoAgent实现了零样本准确率分别为54.1%和71.3%，平均仅使用8.4和8.2帧，相比现有最先进方法更高效有效，展示了代理方法在长视频理解领域的潜力。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.IR"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.10517v1",
      "published_date": "2024-03-15 17:57:52 UTC",
      "updated_date": "2024-03-15 17:57:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T15:47:48.408747"
    },
    {
      "arxiv_id": "2403.10516v2",
      "title": "FeatUp: A Model-Agnostic Framework for Features at Any Resolution",
      "title_zh": "FeatUp：一种模型无关框架，用于任意分辨率的特征",
      "authors": [
        "Stephanie Fu",
        "Mark Hamilton",
        "Laura Brandt",
        "Axel Feldman",
        "Zhoutong Zhang",
        "William T. Freeman"
      ],
      "abstract": "Deep features are a cornerstone of computer vision research, capturing image\nsemantics and enabling the community to solve downstream tasks even in the\nzero- or few-shot regime. However, these features often lack the spatial\nresolution to directly perform dense prediction tasks like segmentation and\ndepth prediction because models aggressively pool information over large areas.\nIn this work, we introduce FeatUp, a task- and model-agnostic framework to\nrestore lost spatial information in deep features. We introduce two variants of\nFeatUp: one that guides features with high-resolution signal in a single\nforward pass, and one that fits an implicit model to a single image to\nreconstruct features at any resolution. Both approaches use a multi-view\nconsistency loss with deep analogies to NeRFs. Our features retain their\noriginal semantics and can be swapped into existing applications to yield\nresolution and performance gains even without re-training. We show that FeatUp\nsignificantly outperforms other feature upsampling and image super-resolution\napproaches in class activation map generation, transfer learning for\nsegmentation and depth prediction, and end-to-end training for semantic\nsegmentation.",
      "tldr_zh": "论文提出 FeatUp，一种任务和模型无关的框架，用于恢复深度特征中丢失的空间信息，从而支持密集预测任务如分割和深度预测。FeatUp 包括两种变体：一种在单次前向传递中使用高分辨率信号引导特征，另一种通过拟合隐式模型重建任意分辨率的特征，两者均采用多视图一致性损失（类似于 NeRFs）。实验结果表明，FeatUp 显著优于其他特征上采样和图像超分辨率方法，在类别激活映射生成、迁移学习用于分割和深度预测，以及端到端语义分割训练中实现了分辨率和性能提升，而无需重新训练。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.IR",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted to the International Conference on Learning Representations\n  (ICLR) 2024",
      "pdf_url": "http://arxiv.org/pdf/2403.10516v2",
      "published_date": "2024-03-15 17:57:06 UTC",
      "updated_date": "2024-04-01 20:57:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T15:48:00.656138"
    },
    {
      "arxiv_id": "2403.10506v2",
      "title": "HumanoidBench: Simulated Humanoid Benchmark for Whole-Body Locomotion and Manipulation",
      "title_zh": "翻译失败",
      "authors": [
        "Carmelo Sferrazza",
        "Dun-Ming Huang",
        "Xingyu Lin",
        "Youngwoon Lee",
        "Pieter Abbeel"
      ],
      "abstract": "Humanoid robots hold great promise in assisting humans in diverse\nenvironments and tasks, due to their flexibility and adaptability leveraging\nhuman-like morphology. However, research in humanoid robots is often\nbottlenecked by the costly and fragile hardware setups. To accelerate\nalgorithmic research in humanoid robots, we present a high-dimensional,\nsimulated robot learning benchmark, HumanoidBench, featuring a humanoid robot\nequipped with dexterous hands and a variety of challenging whole-body\nmanipulation and locomotion tasks. Our findings reveal that state-of-the-art\nreinforcement learning algorithms struggle with most tasks, whereas a\nhierarchical learning approach achieves superior performance when supported by\nrobust low-level policies, such as walking or reaching. With HumanoidBench, we\nprovide the robotics community with a platform to identify the challenges\narising when solving diverse tasks with humanoid robots, facilitating prompt\nverification of algorithms and ideas. The open-source code is available at\nhttps://humanoid-bench.github.io.",
      "tldr_zh": "该论文提出了 HumanoidBench，这是一个高维度的模拟基准，用于评估人形机器人在全身体动和操作任务中的性能，旨在解决硬件设置昂贵且易碎的瓶颈问题。该基准包括配备灵巧手的机器人模型和多种挑战性任务，实验结果显示，现有最先进的 reinforcement learning 算法在大多数任务上表现不佳，而 hierarchical learning 方法在稳健的低层策略（如行走或到达）支持下取得了更好的效果。通过 HumanoidBench，研究者可以快速识别人形机器人面临的挑战，并验证算法想法，并提供了开源代码以促进社区发展。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.10506v2",
      "published_date": "2024-03-15 17:45:44 UTC",
      "updated_date": "2024-06-18 18:11:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T15:48:14.246967"
    },
    {
      "arxiv_id": "2403.10502v1",
      "title": "Belief Change based on Knowledge Measures",
      "title_zh": "基于知识度量的信念变化",
      "authors": [
        "Umberto Straccia",
        "Giovanni Casini"
      ],
      "abstract": "Knowledge Measures (KMs) aim at quantifying the amount of\nknowledge/information that a knowledge base carries. On the other hand, Belief\nChange (BC) is the process of changing beliefs (in our case, in terms of\ncontraction, expansion and revision) taking into account a new piece of\nknowledge, which possibly may be in contradiction with the current belief. We\npropose a new quantitative BC framework that is based on KMs by defining belief\nchange operators that try to minimise, from an information-theoretic point of\nview, the surprise that the changed belief carries. To this end, we introduce\nthe principle of minimal surprise. In particular, our contributions are (i) a\ngeneral information-theoretic approach to KMs for which [1] is a special case;\n(ii) KM-based BC operators that satisfy the so-called AGM postulates; and (iii)\na characterisation of any BC operator that satisfies the AGM postulates as a\nKM-based BC operator, i.e., any BC operator satisfying the AGM postulates can\nbe encoded within our quantitative BC framework. We also introduce quantitative\nmeasures that account for the information loss of contraction, information gain\nof expansion and information change of revision. We also give a succinct look\ninto the problem of iterated revision, which deals with the application of a\nsequence of revision operations in our framework, and also illustrate how one\nmay build from our KM-based contraction operator also one not satisfying the\n(in)famous recovery postulate, by focusing on the so-called severe withdrawal\nmodel as an illustrative example.",
      "tldr_zh": "这篇论文提出了一种基于 Knowledge Measures (KMs) 的定量 Belief Change (BC) 框架，通过最小惊奇原则定义 BC 操作符（如收缩、扩展和修正），以最小化新知识带来的信息理论惊奇。论文的主要贡献包括：(i) 扩展 KMs 的通用信息理论方法；(ii) 构建满足 AGM postulates 的 KM-based BC 操作符；以及 (iii) 证明任何满足 AGM postulates 的 BC 操作符均可编码于该框架中。该框架还引入量化措施来评估收缩的信息损失、扩展的信息增益和修正的信息变化，并简要探讨了迭代修正问题及其不满足恢复假设的示例。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "48 pages, 3 figures, preprint",
      "pdf_url": "http://arxiv.org/pdf/2403.10502v1",
      "published_date": "2024-03-15 17:40:11 UTC",
      "updated_date": "2024-03-15 17:40:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T15:48:26.460454"
    },
    {
      "arxiv_id": "2403.10499v1",
      "title": "Benchmarking Zero-Shot Robustness of Multimodal Foundation Models: A Pilot Study",
      "title_zh": "翻译失败",
      "authors": [
        "Chenguang Wang",
        "Ruoxi Jia",
        "Xin Liu",
        "Dawn Song"
      ],
      "abstract": "Pre-training image representations from the raw text about images enables\nzero-shot vision transfer to downstream tasks. Through pre-training on millions\nof samples collected from the internet, multimodal foundation models, such as\nCLIP, produce state-of-the-art zero-shot results that often reach\ncompetitiveness with fully supervised methods without the need for\ntask-specific training. Besides the encouraging performance on classification\naccuracy, it is reported that these models close the robustness gap by matching\nthe performance of supervised models trained on ImageNet under natural\ndistribution shift. Because robustness is critical to real-world applications,\nespecially safety-critical ones, in this paper, we present a comprehensive\nevaluation based on a large-scale robustness benchmark covering 7 natural, 3\nsynthetic distribution shifts, and 11 adversarial attacks. We use CLIP as a\npilot study. We show that CLIP leads to a significant robustness drop compared\nto supervised ImageNet models on our benchmark, especially under synthetic\ndistribution shift and adversarial attacks. Furthermore, data overlap analysis\nsuggests that the observed robustness under natural distribution shifts could\nbe attributed, at least in part, to data overlap. In summary, our evaluation\nshows a comprehensive evaluation of robustness is necessary; and there is a\nsignificant need to improve the robustness of zero-shot multimodal models.",
      "tldr_zh": "本研究通过一个试点实验，对多模态基础模型（如 CLIP）的零样本（Zero-Shot）鲁棒性进行了基准测试，评估其在7种自然分布偏移、3种合成分布偏移和11种对抗攻击下的表现。结果显示，CLIP在合成分布偏移和对抗攻击场景下，鲁棒性显著低于基于ImageNet的监督模型。进一步的数据重叠分析表明，自然分布偏移下的鲁棒性可能部分归因于训练数据重叠。总体而言，该研究强调了全面评估零样本鲁棒性的必要性，并呼吁改进多模态基础模型的鲁棒性以适应真实世界应用。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.10499v1",
      "published_date": "2024-03-15 17:33:49 UTC",
      "updated_date": "2024-03-15 17:33:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T15:48:38.154836"
    },
    {
      "arxiv_id": "2403.10487v1",
      "title": "Stimulate the Potential of Robots via Competition",
      "title_zh": "通过竞争激发机器人的潜力",
      "authors": [
        "Kangyao Huang",
        "Di Guo",
        "Xinyu Zhang",
        "Xiangyang Ji",
        "Huaping Liu"
      ],
      "abstract": "It is common for us to feel pressure in a competition environment, which\narises from the desire to obtain success comparing with other individuals or\nopponents. Although we might get anxious under the pressure, it could also be a\ndrive for us to stimulate our potentials to the best in order to keep up with\nothers. Inspired by this, we propose a competitive learning framework which is\nable to help individual robot to acquire knowledge from the competition, fully\nstimulating its dynamics potential in the race. Specifically, the competition\ninformation among competitors is introduced as the additional auxiliary signal\nto learn advantaged actions. We further build a Multiagent-Race environment,\nand extensive experiments are conducted, demonstrating that robots trained in\ncompetitive environments outperform ones that are trained with SoTA algorithms\nin single robot environment.",
      "tldr_zh": "本研究受人类竞争压力启发的启发，提出了一种 competitive learning framework，帮助单个机器人通过竞争环境获取知识，从而充分激发其动态潜力。具体方法是将竞争对手的信息作为辅助信号，引导机器人学习更有优势的行动策略。该框架在 Multiagent-Race 环境中进行了广泛实验，结果表明，在竞争环境中训练的机器人性能优于在单机器人环境中使用最先进算法训练的机器人。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.10487v1",
      "published_date": "2024-03-15 17:21:39 UTC",
      "updated_date": "2024-03-15 17:21:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T15:48:48.932852"
    },
    {
      "arxiv_id": "2403.10482v2",
      "title": "Can a GPT4-Powered AI Agent Be a Good Enough Performance Attribution Analyst?",
      "title_zh": "翻译失败",
      "authors": [
        "Bruno de Melo",
        "Jamiel Sheikh"
      ],
      "abstract": "Performance attribution analysis, defined as the process of explaining the\ndrivers of the excess performance of an investment portfolio against a\nbenchmark, stands as a significant feature of portfolio management and plays a\ncrucial role in the investment decision-making process, particularly within the\nfund management industry. Rooted in a solid financial and mathematical\nframework, the importance and methodologies of this analytical technique are\nextensively documented across numerous academic research papers and books. The\nintegration of large language models (LLMs) and AI agents marks a\ngroundbreaking development in this field. These agents are designed to automate\nand enhance the performance attribution analysis by accurately calculating and\nanalyzing portfolio performances against benchmarks. In this study, we\nintroduce the application of an AI Agent for a variety of essential performance\nattribution tasks, including the analysis of performance drivers and utilizing\nLLMs as calculation engine for multi-level attribution analysis and\nquestion-answering (QA) tasks. Leveraging advanced prompt engineering\ntechniques such as Chain-of-Thought (CoT) and Plan and Solve (PS), and\nemploying a standard agent framework from LangChain, the research achieves\npromising results: it achieves accuracy rates exceeding 93% in analyzing\nperformance drivers, attains 100% in multi-level attribution calculations, and\nsurpasses 84% accuracy in QA exercises that simulate official examination\nstandards. These findings affirm the impactful role of AI agents, prompt\nengineering and evaluation in advancing portfolio management processes,\nhighlighting a significant development in the practical application and\nevaluation of Generative AI technologies within the domain.",
      "tldr_zh": "这篇论文探讨了基于 GPT4 的 AI 代理是否能有效胜任 performance attribution analysis，即解释投资组合相对于基准的超额表现驱动因素。研究引入 AI 代理利用大型语言模型 (LLMs) 作为计算引擎，结合 Chain-of-Thought (CoT) 和 Plan and Solve (PS) 等提示工程技巧，以及 LangChain 框架，来自动化处理性能驱动分析、多级归因计算和 question-answering (QA) 任务。结果显示，该代理在分析性能驱动因素上准确率超过 93%，多级归因计算达到 100%，QA 任务准确率超过 84%。这些发现突显了 AI 代理在提升投资组合管理效率方面的潜力，并肯定了生成式 AI 在实际应用中的重要作用。",
      "categories": [
        "q-fin.CP",
        "cs.AI",
        "q-fin.PM"
      ],
      "primary_category": "q-fin.CP",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.10482v2",
      "published_date": "2024-03-15 17:12:57 UTC",
      "updated_date": "2024-03-22 13:59:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T15:49:03.463179"
    },
    {
      "arxiv_id": "2403.10588v1",
      "title": "S3LLM: Large-Scale Scientific Software Understanding with LLMs using Source, Metadata, and Document",
      "title_zh": "翻译失败",
      "authors": [
        "Kareem Shaik",
        "Dali Wang",
        "Weijian Zheng",
        "Qinglei Cao",
        "Heng Fan",
        "Peter Schwartz",
        "Yunhe Feng"
      ],
      "abstract": "The understanding of large-scale scientific software poses significant\nchallenges due to its diverse codebase, extensive code length, and target\ncomputing architectures. The emergence of generative AI, specifically large\nlanguage models (LLMs), provides novel pathways for understanding such complex\nscientific codes. This paper presents S3LLM, an LLM-based framework designed to\nenable the examination of source code, code metadata, and summarized\ninformation in conjunction with textual technical reports in an interactive,\nconversational manner through a user-friendly interface. S3LLM leverages\nopen-source LLaMA-2 models to enhance code analysis through the automatic\ntransformation of natural language queries into domain-specific language (DSL)\nqueries. Specifically, it translates these queries into Feature Query Language\n(FQL), enabling efficient scanning and parsing of entire code repositories. In\naddition, S3LLM is equipped to handle diverse metadata types, including DOT,\nSQL, and customized formats. Furthermore, S3LLM incorporates retrieval\naugmented generation (RAG) and LangChain technologies to directly query\nextensive documents. S3LLM demonstrates the potential of using locally deployed\nopen-source LLMs for the rapid understanding of large-scale scientific\ncomputing software, eliminating the need for extensive coding expertise, and\nthereby making the process more efficient and effective. S3LLM is available at\nhttps://github.com/ResponsibleAILab/s3llm.",
      "tldr_zh": "这篇论文介绍了 S3LLM，一种基于大型语言模型 (LLMs) 的框架，用于理解大规模科学软件的挑战，包括代码多样性和复杂性。S3LLM 通过将自然语言查询转化为 Feature Query Language (FQL)，结合源代码、元数据（如 DOT 和 SQL 格式）和文档分析，并整合检索增强生成 (RAG) 与 LangChain 技术，提供交互式界面进行高效扫描和解析。实验结果显示，该框架利用开源 LLaMA-2 模型，能快速提升软件理解效率，无需专业编码知识，并已在 GitHub 上开源。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.10588v1",
      "published_date": "2024-03-15 17:04:27 UTC",
      "updated_date": "2024-03-15 17:04:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T15:49:16.752245"
    },
    {
      "arxiv_id": "2403.10586v3",
      "title": "Reviewing AI's Role in Non-Muscle-Invasive Bladder Cancer Recurrence Prediction",
      "title_zh": "翻译失败",
      "authors": [
        "Saram Abbas",
        "Rishad Shafik",
        "Naeem Soomro",
        "Rakesh Heer",
        "Kabita Adhikari"
      ],
      "abstract": "Notorious for its 70-80% recurrence rate, Non-muscle-invasive Bladder Cancer\n(NMIBC) imposes a significant human burden and is one of the costliest cancers\nto manage. Current tools for predicting NMIBC recurrence rely on scoring\nsystems that often overestimate risk and have poor accuracy. This is where\nMachine learning (ML)-based techniques have emerged as a promising approach for\npredicting NMIBC recurrence by leveraging molecular and clinical data. This\ncomprehensive review paper critically analyses ML-based frameworks for\npredicting NMIBC recurrence, focusing on their statistical robustness and\nalgorithmic efficacy. We meticulously examine the strengths and weaknesses of\neach study, by focusing on various prediction tasks, data modalities, and ML\nmodels, highlighting their remarkable performance alongside inherent\nlimitations. A diverse array of ML algorithms that leverage multimodal data\nspanning radiomics, clinical, histopathological, and genomic data, exhibit\nsignificant promise in accurately predicting NMIBC recurrence. However, the\npath to widespread adoption faces challenges concerning the generalisability\nand interpretability of models, emphasising the need for collaborative efforts,\nrobust datasets, and the incorporation of cost-effectiveness. Our detailed\ncategorisation and in-depth analysis illuminate the nuances, complexities, and\ncontexts that influence real-world advancement and adoption of these AI-based\ntechniques. This rigorous analysis equips researchers with a deeper\nunderstanding of the intricacies of the ML algorithms employed. Researchers can\nuse these insights to refine approaches, address limitations, and boost\ngeneralisability of their ML models, ultimately leading to reduced healthcare\ncosts and improved patient outcomes.",
      "tldr_zh": "这篇综述论文审视了人工智能（AI），特别是机器学习（ML）技术，在预测非肌层浸润性膀胱癌（NMIBC）复发中的作用，强调NMIBC高达70-80%的复发率及其高昂的管理成本问题。论文对基于ML的预测框架进行全面分析，评估了其统计鲁棒性和算法效能，包括利用多模式数据（如radiomics、临床、histopathological和genomic数据）的各种模型的优势和局限性。研究发现，这些ML方法在预测准确性上表现出色，但面临模型泛化性、可解释性和实际采纳的挑战；作者呼吁通过合作、robust数据集和成本效益评估来改进这些技术，最终降低医疗成本并提升患者预后。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "14 pages, 3 Figures",
      "pdf_url": "http://arxiv.org/pdf/2403.10586v3",
      "published_date": "2024-03-15 17:03:45 UTC",
      "updated_date": "2024-12-20 12:03:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T15:49:26.638694"
    },
    {
      "arxiv_id": "2403.10462v2",
      "title": "Safety Cases: How to Justify the Safety of Advanced AI Systems",
      "title_zh": "翻译失败",
      "authors": [
        "Joshua Clymer",
        "Nick Gabrieli",
        "David Krueger",
        "Thomas Larsen"
      ],
      "abstract": "As AI systems become more advanced, companies and regulators will make\ndifficult decisions about whether it is safe to train and deploy them. To\nprepare for these decisions, we investigate how developers could make a 'safety\ncase,' which is a structured rationale that AI systems are unlikely to cause a\ncatastrophe. We propose a framework for organizing a safety case and discuss\nfour categories of arguments to justify safety: total inability to cause a\ncatastrophe, sufficiently strong control measures, trustworthiness despite\ncapability to cause harm, and -- if AI systems become much more powerful --\ndeference to credible AI advisors. We evaluate concrete examples of arguments\nin each category and outline how arguments could be combined to justify that AI\nsystems are safe to deploy.",
      "tldr_zh": "本论文探讨了如何为先进AI系统构建“safety case”，这是一个结构化的理由，用以证明AI系统不太可能引发灾难。\n作者提出一个框架，组织四类论证：AI完全无法导致灾难、实施足够强的控制措施、尽管有能力造成伤害但仍可信任，以及在AI变得更强大时听从可信AI顾问。\n通过评估具体例子，该框架可帮助结合多种论证，确保AI系统安全训练和部署。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.10462v2",
      "published_date": "2024-03-15 16:53:13 UTC",
      "updated_date": "2024-03-18 18:11:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T15:49:37.145601"
    },
    {
      "arxiv_id": "2403.10460v1",
      "title": "Online Concurrent Multi-Robot Coverage Path Planning",
      "title_zh": "在线并发多机器人覆盖路径规划",
      "authors": [
        "Ratijit Mitra",
        "Indranil Saha"
      ],
      "abstract": "Recently, centralized receding horizon online multi-robot coverage path\nplanning algorithms have shown remarkable scalability in thoroughly exploring\nlarge, complex, unknown workspaces with many robots. In a horizon, the path\nplanning and the path execution interleave, meaning when the path planning\noccurs for robots with no paths, the robots with outstanding paths do not\nexecute, and subsequently, when the robots with new or outstanding paths\nexecute to reach respective goals, path planning does not occur for those\nrobots yet to get new paths, leading to wastage of both the robotic and the\ncomputation resources. As a remedy, we propose a centralized algorithm that is\nnot horizon-based. It plans paths at any time for a subset of robots with no\npaths, i.e., who have reached their previously assigned goals, while the rest\nexecute their outstanding paths, thereby enabling concurrent planning and\nexecution. We formally prove that the proposed algorithm ensures complete\ncoverage of an unknown workspace and analyze its time complexity. To\ndemonstrate scalability, we evaluate our algorithm to cover eight large $2$D\ngrid benchmark workspaces with up to 512 aerial and ground robots,\nrespectively. A comparison with a state-of-the-art horizon-based algorithm\nshows its superiority in completing the coverage with up to 1.6x speedup. For\nvalidation, we perform ROS + Gazebo simulations in six 2D grid benchmark\nworkspaces with 10 quadcopters and TurtleBots, respectively. We also\nsuccessfully conducted one outdoor experiment with three quadcopters and one\nindoor with two TurtleBots.",
      "tldr_zh": "该论文提出了一种在线并发多机器人覆盖路径规划算法，旨在解决传统基于地平线（receding horizon）的算法在规划和执行间交替导致资源浪费的问题。该算法采用集中式（centralized）方法，允许在任何时间为无路径子集机器人规划路径，同时其他机器人执行现有路径，从而实现规划与执行的并发。论文证明了该算法能确保未知工作空间的完全覆盖，并分析了其时间复杂度；在实验中，该算法在八个大型2D网格基准环境中，使用多达512个空中和地面机器人时，比现有算法快1.6倍，并通过ROS + Gazebo模拟和实际户外/室内测试验证了其可扩展性和有效性。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.10460v1",
      "published_date": "2024-03-15 16:51:30 UTC",
      "updated_date": "2024-03-15 16:51:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T15:49:50.420258"
    },
    {
      "arxiv_id": "2403.10454v2",
      "title": "Partially Observable Task and Motion Planning with Uncertainty and Risk Awareness",
      "title_zh": "部分可观测的任务与运动规划，具有不确定性和风险意识",
      "authors": [
        "Aidan Curtis",
        "George Matheos",
        "Nishad Gothoskar",
        "Vikash Mansinghka",
        "Joshua Tenenbaum",
        "Tomás Lozano-Pérez",
        "Leslie Pack Kaelbling"
      ],
      "abstract": "Integrated task and motion planning (TAMP) has proven to be a valuable\napproach to generalizable long-horizon robotic manipulation and navigation\nproblems. However, the typical TAMP problem formulation assumes full\nobservability and deterministic action effects. These assumptions limit the\nability of the planner to gather information and make decisions that are\nrisk-aware. We propose a strategy for TAMP with Uncertainty and Risk Awareness\n(TAMPURA) that is capable of efficiently solving long-horizon planning problems\nwith initial-state and action outcome uncertainty, including problems that\nrequire information gathering and avoiding undesirable and irreversible\noutcomes. Our planner reasons under uncertainty at both the abstract task level\nand continuous controller level. Given a set of closed-loop goal-conditioned\ncontrollers operating in the primitive action space and a description of their\npreconditions and potential capabilities, we learn a high-level abstraction\nthat can be solved efficiently and then refined to continuous actions for\nexecution. We demonstrate our approach on several robotics problems where\nuncertainty is a crucial factor and show that reasoning under uncertainty in\nthese problems outperforms previously proposed determinized planning, direct\nsearch, and reinforcement learning strategies. Lastly, we demonstrate our\nplanner on two real-world robotics problems using recent advancements in\nprobabilistic perception.",
      "tldr_zh": "这篇论文提出了一种名为TAMPURA的策略，用于处理部分可观察的任务和运动规划（TAMP）问题，特别关注不确定性和风险意识，以克服传统TAMP假设全可观察性和确定性行动效果的局限性。TAMPURA通过在抽象任务级别和连续控制器级别上进行不确定性推理，利用闭环目标条件控制器学习高层抽象，并将其细化为可执行的连续行动，从而高效解决长horizon机器人问题，包括信息收集和避免不可逆转风险。实验结果显示，该方法在多个不确定性关键的机器人场景中优于确定化规划、直接搜索和强化学习策略，并在真实世界机器人问题上进行了成功演示。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.10454v2",
      "published_date": "2024-03-15 16:42:14 UTC",
      "updated_date": "2024-10-06 17:34:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T15:50:02.074049"
    },
    {
      "arxiv_id": "2403.10585v1",
      "title": "Solving General Noisy Inverse Problem via Posterior Sampling: A Policy Gradient Viewpoint",
      "title_zh": "通过后验采样解决一般噪声逆问题：策略梯度视角",
      "authors": [
        "Haoyue Tang",
        "Tian Xie",
        "Aosong Feng",
        "Hanyu Wang",
        "Chenyang Zhang",
        "Yang Bai"
      ],
      "abstract": "Solving image inverse problems (e.g., super-resolution and inpainting)\nrequires generating a high fidelity image that matches the given input (the\nlow-resolution image or the masked image). By using the input image as\nguidance, we can leverage a pretrained diffusion generative model to solve a\nwide range of image inverse tasks without task specific model fine-tuning. To\nprecisely estimate the guidance score function of the input image, we propose\nDiffusion Policy Gradient (DPG), a tractable computation method by viewing the\nintermediate noisy images as policies and the target image as the states\nselected by the policy. Experiments show that our method is robust to both\nGaussian and Poisson noise degradation on multiple linear and non-linear\ninverse tasks, resulting into a higher image restoration quality on FFHQ,\nImageNet and LSUN datasets.",
      "tldr_zh": "该论文提出了一种基于后验采样的方法，用于解决一般噪声逆问题（如图像超分辨率和修复），从策略梯度视角出发，利用预训练的 diffusion generative model 作为指导，而无需任务特定微调。作者引入 Diffusion Policy Gradient (DPG) 算法，将中间噪声图像视为 policies，并将目标图像视为 states，从而精确估计指导分数函数。实验结果表明，该方法对 Gaussian and Poisson noise 具有鲁棒性，在 FFHQ、ImageNet 和 LSUN 数据集上的线性与非线性逆任务中，实现了更高的图像恢复质量。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "eess.IV",
      "comment": "Accepted and to Appear, AISTATS 2024",
      "pdf_url": "http://arxiv.org/pdf/2403.10585v1",
      "published_date": "2024-03-15 16:38:47 UTC",
      "updated_date": "2024-03-15 16:38:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T15:50:17.086596"
    },
    {
      "arxiv_id": "2405.06645v1",
      "title": "On Recovering Higher-order Interactions from Protein Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Darin Tsui",
        "Amirali Aghazadeh"
      ],
      "abstract": "Protein language models leverage evolutionary information to perform\nstate-of-the-art 3D structure and zero-shot variant prediction. Yet, extracting\nand explaining all the mutational interactions that govern model predictions\nremains difficult as it requires querying the entire amino acid space for $n$\nsites using $20^n$ sequences, which is computationally expensive even for\nmoderate values of $n$ (e.g., $n\\sim10$). Although approaches to lower the\nsample complexity exist, they often limit the interpretability of the model to\njust single and pairwise interactions. Recently, computationally scalable\nalgorithms relying on the assumption of sparsity in the Fourier domain have\nemerged to learn interactions from experimental data. However, extracting\ninteractions from language models poses unique challenges: it's unclear if\nsparsity is always present or if it is the only metric needed to assess the\nutility of Fourier algorithms. Herein, we develop a framework to do a\nsystematic Fourier analysis of the protein language model ESM2 applied on three\nproteins-green fluorescent protein (GFP), tumor protein P53 (TP53), and G\ndomain B1 (GB1)-across various sites for 228 experiments. We demonstrate that\nESM2 is dominated by three regions in the sparsity-ruggedness plane, two of\nwhich are better suited for sparse Fourier transforms. Validations on two\nsample proteins demonstrate recovery of all interactions with $R^2=0.72$ in the\nmore sparse region and $R^2=0.66$ in the more dense region, using only 7\nmillion out of $20^{10}\\sim10^{13}$ ESM2 samples, reducing the computational\ntime by a staggering factor of 15,000. All codes and data are available on our\nGitHub repository https://github.com/amirgroup-codes/InteractionRecovery.",
      "tldr_zh": "这篇论文探讨了从蛋白质语言模型（如ESM2）中提取更高阶突变交互的挑战，强调了查询氨基酸空间的计算开销问题。作者开发了一个框架，通过系统傅立叶分析（Fourier analysis）假设稀疏性，对ESM2在GFP、TP53和GB1等蛋白上的228个实验进行评估，发现模型在稀疏-崎岖平面上有三个主导区域，其中两个适合稀疏傅立叶变换。实验验证显示，仅使用7百万样本（远少于20^10≈10^13），即可恢复所有交互，R^2分别达到0.72和0.66，大幅减少计算时间15,000倍，为高效交互恢复提供了可扩展方法。",
      "categories": [
        "q-bio.BM",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "q-bio.BM",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.06645v1",
      "published_date": "2024-03-15 16:35:47 UTC",
      "updated_date": "2024-03-15 16:35:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T15:50:28.694958"
    },
    {
      "arxiv_id": "2403.10438v1",
      "title": "Data Ethics Emergency Drill: A Toolbox for Discussing Responsible AI for Industry Teams",
      "title_zh": "数据伦理",
      "authors": [
        "Vanessa Aisyahsari Hanschke",
        "Dylan Rees",
        "Merve Alanyali",
        "David Hopkinson",
        "Paul Marshall"
      ],
      "abstract": "Researchers urge technology practitioners such as data scientists to consider\nthe impacts and ethical implications of algorithmic decisions. However, unlike\nprogramming, statistics, and data management, discussion of ethical\nimplications is rarely included in standard data science training. To begin to\naddress this gap, we designed and tested a toolbox called the data ethics\nemergency drill (DEED) to help data science teams discuss and reflect on the\nethical implications of their work. The DEED is a roleplay of a fictional\nethical emergency scenario that is contextually situated in the team's specific\nworkplace and applications. This paper outlines the DEED toolbox and describes\nthree studies carried out with two different data science teams that\niteratively shaped its design. Our findings show that practitioners can apply\nlessons learnt from the roleplay to real-life situations, and how the DEED\nopened up conversations around ethics and values.",
      "tldr_zh": "研究者设计了 DEED（Data Ethics Emergency Drill）工具箱，以帮助工业数据科学团队讨论和反思其工作的伦理影响，旨在填补数据科学培训中伦理讨论的空白。DEED 通过基于团队特定工作环境的虚构伦理紧急场景角色扮演，让参与者模拟和分析潜在问题。该工具箱经过三个迭代研究在不同团队中测试，结果表明参与者能够将角色扮演中学到的经验应用到真实情境中，并促进了关于伦理和价值观的对话。总的来说，DEED 为推动负责任的 AI 实践提供了一个实用框架。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.HC",
      "comment": "accepted to CHI 2024",
      "pdf_url": "http://arxiv.org/pdf/2403.10438v1",
      "published_date": "2024-03-15 16:20:51 UTC",
      "updated_date": "2024-03-15 16:20:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T15:50:39.250022"
    },
    {
      "arxiv_id": "2403.10433v4",
      "title": "AI-enhanced Collective Intelligence",
      "title_zh": "AI 增强集体智能",
      "authors": [
        "Hao Cui",
        "Taha Yasseri"
      ],
      "abstract": "Current societal challenges exceed the capacity of humans operating either\nalone or collectively. As AI evolves, its role within human collectives will\nvary from an assistive tool to a participatory member. Humans and AI possess\ncomplementary capabilities that, together, can surpass the collective\nintelligence of either humans or AI in isolation. However, the interactions in\nhuman-AI systems are inherently complex, involving intricate processes and\ninterdependencies. This review incorporates perspectives from complex network\nscience to conceptualize a multilayer representation of human-AI collective\nintelligence, comprising cognition, physical, and information layers. Within\nthis multilayer network, humans and AI agents exhibit varying characteristics;\nhumans differ in diversity from surface-level to deep-level attributes, while\nAI agents range in degrees of functionality and anthropomorphism. We explore\nhow agents' diversity and interactions influence the system's collective\nintelligence and analyze real-world instances of AI-enhanced collective\nintelligence. We conclude by considering potential challenges and future\ndevelopments in this field.",
      "tldr_zh": "这篇论文探讨了 AI 如何增强集体 intelligence（集体智能），强调人类和 AI 的互补能力可超越单独人类或 AI 的表现。作者采用复杂 network science 的多层表示，包括 cognition、physical 和 information 层，来建模人类-AI 系统中的互动和相互依赖。论文分析了代理（如人类和 AI）的多样性（从表面到深层属性）和功能度对集体 intelligence 的影响，并通过真实世界案例展示其应用潜力。最后，讨论了潜在挑战和未来发展方向。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "43 pages, 2 figures",
      "pdf_url": "http://arxiv.org/pdf/2403.10433v4",
      "published_date": "2024-03-15 16:11:15 UTC",
      "updated_date": "2024-09-26 09:33:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T15:50:51.263022"
    },
    {
      "arxiv_id": "2403.10425v1",
      "title": "NeuFlow: Real-time, High-accuracy Optical Flow Estimation on Robots Using Edge Devices",
      "title_zh": "翻译失败",
      "authors": [
        "Zhiyong Zhang",
        "Huaizu Jiang",
        "Hanumant Singh"
      ],
      "abstract": "Real-time high-accuracy optical flow estimation is a crucial component in\nvarious applications, including localization and mapping in robotics, object\ntracking, and activity recognition in computer vision. While recent\nlearning-based optical flow methods have achieved high accuracy, they often\ncome with heavy computation costs. In this paper, we propose a highly efficient\noptical flow architecture, called NeuFlow, that addresses both high accuracy\nand computational cost concerns. The architecture follows a global-to-local\nscheme. Given the features of the input images extracted at different spatial\nresolutions, global matching is employed to estimate an initial optical flow on\nthe 1/16 resolution, capturing large displacement, which is then refined on the\n1/8 resolution with lightweight CNN layers for better accuracy. We evaluate our\napproach on Jetson Orin Nano and RTX 2080 to demonstrate efficiency\nimprovements across different computing platforms. We achieve a notable 10x-80x\nspeedup compared to several state-of-the-art methods, while maintaining\ncomparable accuracy. Our approach achieves around 30 FPS on edge computing\nplatforms, which represents a significant breakthrough in deploying complex\ncomputer vision tasks such as SLAM on small robots like drones. The full\ntraining and evaluation code is available at\nhttps://github.com/neufieldrobotics/NeuFlow.",
      "tldr_zh": "本论文提出 NeuFlow，一种高效的光流估计架构，旨在解决实时高精度计算需求，适用于机器人定位、物体跟踪和活动识别等应用。NeuFlow 采用 global-to-local 方案，从不同图像分辨率提取特征，先在 1/16 分辨率进行全局匹配估计初始光流捕捉大位移，然后在 1/8 分辨率使用轻量级 CNN 层进行精炼，以平衡准确性和计算成本。在 Jetson Orin Nano 和 RTX 2080 等平台上测试，NeuFlow 比现有方法快 10x-80x，同时保持可比准确性，达到约 30 FPS。该方法显著推进了在小型机器人如无人机上部署 SLAM 等复杂任务的实际应用。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.10425v1",
      "published_date": "2024-03-15 15:58:51 UTC",
      "updated_date": "2024-03-15 15:58:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T15:51:04.763695"
    },
    {
      "arxiv_id": "2403.10415v1",
      "title": "Gradient based Feature Attribution in Explainable AI: A Technical Review",
      "title_zh": "翻译失败",
      "authors": [
        "Yongjie Wang",
        "Tong Zhang",
        "Xu Guo",
        "Zhiqi Shen"
      ],
      "abstract": "The surge in black-box AI models has prompted the need to explain the\ninternal mechanism and justify their reliability, especially in high-stakes\napplications, such as healthcare and autonomous driving. Due to the lack of a\nrigorous definition of explainable AI (XAI), a plethora of research related to\nexplainability, interpretability, and transparency has been developed to\nexplain and analyze the model from various perspectives. Consequently, with an\nexhaustive list of papers, it becomes challenging to have a comprehensive\noverview of XAI research from all aspects. Considering the popularity of neural\nnetworks in AI research, we narrow our focus to a specific area of XAI\nresearch: gradient based explanations, which can be directly adopted for neural\nnetwork models. In this review, we systematically explore gradient based\nexplanation methods to date and introduce a novel taxonomy to categorize them\ninto four distinct classes. Then, we present the essence of technique details\nin chronological order and underscore the evolution of algorithms. Next, we\nintroduce both human and quantitative evaluations to measure algorithm\nperformance. More importantly, we demonstrate the general challenges in XAI and\nspecific challenges in gradient based explanations. We hope that this survey\ncan help researchers understand state-of-the-art progress and their\ncorresponding disadvantages, which could spark their interest in addressing\nthese issues in future work.",
      "tldr_zh": "本综述探讨了可解释 AI (XAI) 中基于梯度的特征归因方法，针对神经网络模型的解释性需求，系统总结了现有研究并引入了一个新的四类分类法，以分类这些算法。论文按时间顺序阐述了技术细节和算法演变，同时介绍了人类评估和定量评估方式，用于衡量方法的性能。更重要的是，它指出了 XAI 的一般挑战（如缺乏严格定义）和基于梯度解释的特定问题，旨在帮助研究者理解当前进展的优缺点，并激发未来改进工作。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.10415v1",
      "published_date": "2024-03-15 15:49:31 UTC",
      "updated_date": "2024-03-15 15:49:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T15:51:15.489762"
    },
    {
      "arxiv_id": "2403.10403v1",
      "title": "Energy Correction Model in the Feature Space for Out-of-Distribution Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Marc Lafon",
        "Clément Rambour",
        "Nicolas Thome"
      ],
      "abstract": "In this work, we study the out-of-distribution (OOD) detection problem\nthrough the use of the feature space of a pre-trained deep classifier. We show\nthat learning the density of in-distribution (ID) features with an energy-based\nmodels (EBM) leads to competitive detection results. However, we found that the\nnon-mixing of MCMC sampling during the EBM's training undermines its detection\nperformance. To overcome this an energy-based correction of a mixture of\nclass-conditional Gaussian distributions. We obtains favorable results when\ncompared to a strong baseline like the KNN detector on the CIFAR-10/CIFAR-100\nOOD detection benchmarks.",
      "tldr_zh": "本研究探讨了使用预训练深度分类器特征空间进行Out-of-Distribution (OOD)检测的问题，通过Energy-Based Models (EBM)学习In-Distribution (ID)特征的密度，实现了竞争性的检测性能。研究发现，EBM训练中的MCMC sampling不混合会影响效果，因此提出了一种能量修正混合高斯分布的方法来优化模型。实验结果显示，该方法在CIFAR-10/CIFAR-100 OOD检测基准上，优于KNN detector等强基线。总的来说，此工作为OOD检测提供了更可靠的框架，提升了模型的鲁棒性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "NeurIPS ML Safety Workshop (2022)",
      "pdf_url": "http://arxiv.org/pdf/2403.10403v1",
      "published_date": "2024-03-15 15:37:04 UTC",
      "updated_date": "2024-03-15 15:37:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T15:51:27.661752"
    },
    {
      "arxiv_id": "2403.10401v1",
      "title": "SculptDiff: Learning Robotic Clay Sculpting from Humans with Goal Conditioned Diffusion Policy",
      "title_zh": "翻译失败",
      "authors": [
        "Alison Bartsch",
        "Arvind Car",
        "Charlotte Avra",
        "Amir Barati Farimani"
      ],
      "abstract": "Manipulating deformable objects remains a challenge within robotics due to\nthe difficulties of state estimation, long-horizon planning, and predicting how\nthe object will deform given an interaction. These challenges are the most\npronounced with 3D deformable objects. We propose SculptDiff, a\ngoal-conditioned diffusion-based imitation learning framework that works with\npoint cloud state observations to directly learn clay sculpting policies for a\nvariety of target shapes. To the best of our knowledge this is the first\nreal-world method that successfully learns manipulation policies for 3D\ndeformable objects. For sculpting videos and access to our dataset and hardware\nCAD models, see the project website:\nhttps://sites.google.com/andrew.cmu.edu/imitation-sculpting/home",
      "tldr_zh": "该论文探讨了机器人操作可变形物体（如粘土）的挑战，包括状态估计、长期规划和变形预测，尤其在3D物体上。研究提出SculptDiff框架，这是一个基于目标条件扩散策略(Goal Conditioned Diffusion Policy)的模仿学习方法，使用点云(point cloud)状态观察来直接学习针对各种目标形状的粘土雕塑策略。该框架是首个在真实世界成功学习3D可变形物体操作策略的方法，并提供了相关数据集、视频和硬件模型以支持进一步研究。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.10401v1",
      "published_date": "2024-03-15 15:34:59 UTC",
      "updated_date": "2024-03-15 15:34:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T15:51:41.823270"
    },
    {
      "arxiv_id": "2403.10380v5",
      "title": "BirdSet: A Large-Scale Dataset for Audio Classification in Avian Bioacoustics",
      "title_zh": "BirdSet: 鸟类生物声学音频分类的大规模数据集",
      "authors": [
        "Lukas Rauch",
        "Raphael Schwinger",
        "Moritz Wirth",
        "René Heinrich",
        "Denis Huseljic",
        "Marek Herde",
        "Jonas Lange",
        "Stefan Kahl",
        "Bernhard Sick",
        "Sven Tomforde",
        "Christoph Scholz"
      ],
      "abstract": "Deep learning (DL) has greatly advanced audio classification, yet the field\nis limited by the scarcity of large-scale benchmark datasets that have\npropelled progress in other domains. While AudioSet is a pivotal step to bridge\nthis gap as a universal-domain dataset, its restricted accessibility and\nlimited range of evaluation use cases challenge its role as the sole resource.\nTherefore, we introduce \\texttt{BirdSet}, a large-scale benchmark dataset for\naudio classification focusing on avian bioacoustics. \\texttt{BirdSet} surpasses\nAudioSet with over 6,800 recording hours~($\\uparrow\\!17\\%$) from nearly 10,000\nclasses~($\\uparrow\\!18\\times$) for training and more than 400\nhours~($\\uparrow\\!7\\times$) across eight strongly labeled evaluation datasets.\nIt serves as a versatile resource for use cases such as multi-label\nclassification, covariate shift or self-supervised learning. We benchmark six\nwell-known DL models in multi-label classification across three distinct\ntraining scenarios and outline further evaluation use cases in audio\nclassification. We host our dataset on Hugging Face for easy accessibility and\noffer an extensive codebase to reproduce our results.",
      "tldr_zh": "本研究引入了 BirdSet，这是一个专注于鸟类生物声学的大型音频分类基准数据集，旨在解决现有数据集规模不足的问题。相比于 AudioSet，BirdSet 的训练数据超过 6800 小时（增加 17%）和近 10,000 个类别（增加 18 倍），评估数据则超过 400 小时（增加 7 倍）并包含八个强标签数据集，支持多标签 classification、covariate shift 和 self-supervised learning 等应用。作者对六个知名 deep learning (DL) 模型进行了多标签 classification 基准测试，涵盖三种训练场景，并通过 Hugging Face 平台提供数据集和代码库，以促进研究复现和扩展。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "accepted@ICLR2025",
      "pdf_url": "http://arxiv.org/pdf/2403.10380v5",
      "published_date": "2024-03-15 15:10:40 UTC",
      "updated_date": "2025-02-03 10:39:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T15:51:51.137922"
    },
    {
      "arxiv_id": "2403.10371v1",
      "title": "An Energy-Efficient Ensemble Approach for Mitigating Data Incompleteness in IoT Applications",
      "title_zh": "翻译失败",
      "authors": [
        "Yousef AlShehri",
        "Lakshmish Ramaswamy"
      ],
      "abstract": "Machine Learning (ML) is becoming increasingly important for IoT-based\napplications. However, the dynamic and ad-hoc nature of many IoT ecosystems\nposes unique challenges to the efficacy of ML algorithms. One such challenge is\ndata incompleteness, which is manifested as missing sensor readings. Many\nfactors, including sensor failures and/or network disruption, can cause data\nincompleteness. Furthermore, most IoT systems are severely power-constrained.\nIt is important that we build IoT-based ML systems that are robust against data\nincompleteness while simultaneously being energy efficient. This paper presents\nan empirical study of SECOE - a recent technique for alleviating data\nincompleteness in IoT - with respect to its energy bottlenecks. Towards\naddressing the energy bottlenecks of SECOE, we propose ENAMLE - a proactive,\nenergy-aware technique for mitigating the impact of concurrent missing data.\nENAMLE is unique in the sense that it builds an energy-aware ensemble of\nsub-models, each trained with a subset of sensors chosen carefully based on\ntheir correlations. Furthermore, at inference time, ENAMLE adaptively alters\nthe number of the ensemble of models based on the amount of missing data rate\nand the energy-accuracy trade-off. ENAMLE's design includes several novel\nmechanisms for minimizing energy consumption while maintaining accuracy. We\npresent extensive experimental studies on two distinct datasets that\ndemonstrate the energy efficiency of ENAMLE and its ability to alleviate sensor\nfailures.",
      "tldr_zh": "这篇论文针对IoT应用中ML算法面临的数据不完整性（如传感器读数缺失）问题，提出了一种能源高效的集成方法ENAMLE，以缓解并发缺失数据的影响。ENAMLE通过构建一个基于传感器相关性的子模型集合，并在推理时根据缺失数据率和能源-准确性权衡动态调整模型数量，从而最小化能源消耗同时保持预测准确性。与现有技术SECOE相比，ENAMLE显著降低了能源瓶颈，并在两个数据集上的实验中证明了其能源效率和处理传感器故障的能力。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NI"
      ],
      "primary_category": "cs.LG",
      "comment": "8 pages, 8 figures, 1 table, Accepted as a conference paper at IEEE\n  INTERNATIONAL CONFERENCE ON DISTRIBUTED COMPUTING IN SMART SYSTEMS AND THE\n  INTERNET OF THINGS (DCOSS-IoT 2024)",
      "pdf_url": "http://arxiv.org/pdf/2403.10371v1",
      "published_date": "2024-03-15 15:01:48 UTC",
      "updated_date": "2024-03-15 15:01:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T15:52:04.194847"
    },
    {
      "arxiv_id": "2403.10365v1",
      "title": "Scalable Algorithms for Individual Preference Stable Clustering",
      "title_zh": "翻译失败",
      "authors": [
        "Ron Mosenzon",
        "Ali Vakilian"
      ],
      "abstract": "In this paper, we study the individual preference (IP) stability, which is an\nnotion capturing individual fairness and stability in clustering. Within this\nsetting, a clustering is $\\alpha$-IP stable when each data point's average\ndistance to its cluster is no more than $\\alpha$ times its average distance to\nany other cluster. In this paper, we study the natural local search algorithm\nfor IP stable clustering. Our analysis confirms a $O(\\log n)$-IP stability\nguarantee for this algorithm, where $n$ denotes the number of points in the\ninput. Furthermore, by refining the local search approach, we show it runs in\nan almost linear time, $\\tilde{O}(nk)$.",
      "tldr_zh": "这篇论文探讨了个体偏好 (IP) 稳定性，一种用于捕捉聚类中个体公平性和稳定的概念。具体而言，作者分析了一种局部搜索算法，该算法能确保聚类达到 O(log n) 的 IP 稳定性保证，其中 n 为数据点数量。通过对算法的改进，论文证明其运行时间为 Õ(nk)，实现了高效的可扩展性。总的来说，该工作为公平聚类提供了理论基础和实际算法改进。",
      "categories": [
        "cs.DS",
        "cs.AI",
        "cs.CY",
        "cs.LG"
      ],
      "primary_category": "cs.DS",
      "comment": "59 pages, 9 figures, submitted to AIStats2024",
      "pdf_url": "http://arxiv.org/pdf/2403.10365v1",
      "published_date": "2024-03-15 14:58:27 UTC",
      "updated_date": "2024-03-15 14:58:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T15:52:18.911263"
    },
    {
      "arxiv_id": "2404.00014v1",
      "title": "Deep Geometry Handling and Fragment-wise Molecular 3D Graph Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Odin Zhang",
        "Yufei Huang",
        "Shichen Cheng",
        "Mengyao Yu",
        "Xujun Zhang",
        "Haitao Lin",
        "Yundian Zeng",
        "Mingyang Wang",
        "Zhenxing Wu",
        "Huifeng Zhao",
        "Zaixi Zhang",
        "Chenqing Hua",
        "Yu Kang",
        "Sunliang Cui",
        "Peichen Pan",
        "Chang-Yu Hsieh",
        "Tingjun Hou"
      ],
      "abstract": "Most earlier 3D structure-based molecular generation approaches follow an\natom-wise paradigm, incrementally adding atoms to a partially built molecular\nfragment within protein pockets. These methods, while effective in designing\ntightly bound ligands, often overlook other essential properties such as\nsynthesizability. The fragment-wise generation paradigm offers a promising\nsolution. However, a common challenge across both atom-wise and fragment-wise\nmethods lies in their limited ability to co-design plausible chemical and\ngeometrical structures, resulting in distorted conformations. In response to\nthis challenge, we introduce the Deep Geometry Handling protocol, a more\nabstract design that extends the design focus beyond the model architecture.\nThrough a comprehensive review of existing geometry-related models and their\nprotocols, we propose a novel hybrid strategy, culminating in the development\nof FragGen - a geometry-reliable, fragment-wise molecular generation method.\nFragGen marks a significant leap forward in the quality of generated geometry\nand the synthesis accessibility of molecules. The efficacy of FragGen is\nfurther validated by its successful application in designing type II kinase\ninhibitors at the nanomolar level.",
      "tldr_zh": "本研究批评了现有的3D结构分子生成方法（如atom-wise范式），这些方法虽能设计紧密结合的配体，但忽略了合成性，并难以同时处理合理的化学和几何结构，导致扭曲的构象。针对这一挑战，作者提出Deep Geometry Handling协议，这是一种超越模型架构的抽象设计，通过回顾现有几何相关模型并采用新型混合策略，开发了FragGen——一种基于fragment-wise范式的可靠几何分子生成方法。FragGen显著提高了生成的几何质量和分子的合成可访问性，并在实际应用中成功设计了纳摩尔级别的II型激酶抑制剂，验证了其有效性。",
      "categories": [
        "physics.chem-ph",
        "cs.AI",
        "q-bio.BM"
      ],
      "primary_category": "physics.chem-ph",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.00014v1",
      "published_date": "2024-03-15 14:45:41 UTC",
      "updated_date": "2024-03-15 14:45:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T15:52:29.235220"
    },
    {
      "arxiv_id": "2405.04538v1",
      "title": "DiffFinger: Advancing Synthetic Fingerprint Generation through Denoising Diffusion Probabilistic Models",
      "title_zh": "翻译失败",
      "authors": [
        "Freddie Grabovski",
        "Lior Yasur",
        "Yaniv Hacmon",
        "Lior Nisimov",
        "Stav Nimrod"
      ],
      "abstract": "This study explores the generation of synthesized fingerprint images using\nDenoising Diffusion Probabilistic Models (DDPMs). The significant obstacles in\ncollecting real biometric data, such as privacy concerns and the demand for\ndiverse datasets, underscore the imperative for synthetic biometric\nalternatives that are both realistic and varied. Despite the strides made with\nGenerative Adversarial Networks (GANs) in producing realistic fingerprint\nimages, their limitations prompt us to propose DDPMs as a promising\nalternative. DDPMs are capable of generating images with increasing clarity and\nrealism while maintaining diversity. Our results reveal that DiffFinger not\nonly competes with authentic training set data in quality but also provides a\nricher set of biometric data, reflecting true-to-life variability. These\nfindings mark a promising stride in biometric synthesis, showcasing the\npotential of DDPMs to advance the landscape of fingerprint identification and\nauthentication systems.",
      "tldr_zh": "这篇论文介绍了DiffFinger框架，利用Denoising Diffusion Probabilistic Models (DDPMs)生成合成指纹图像，以应对收集真实生物特征数据的挑战，如隐私问题和数据集多样性需求。相比于Generative Adversarial Networks (GANs)，DDPMs能够产生更清晰、真实且多样的图像，从而提供高质量的合成数据。实验结果显示，DiffFinger生成的图像在质量上可与真实训练集竞争，并展现出更高的变异性，为指纹识别和认证系统的发展提供了新潜力。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.04538v1",
      "published_date": "2024-03-15 14:34:29 UTC",
      "updated_date": "2024-03-15 14:34:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T15:52:41.504729"
    },
    {
      "arxiv_id": "2403.14694v1",
      "title": "Application of GPT Language Models for Innovation in Activities in University Teaching",
      "title_zh": "GPT 语言模型在大学教学活动创新中的应用",
      "authors": [
        "Manuel de Buenaga",
        "Francisco Javier Bueno"
      ],
      "abstract": "The GPT (Generative Pre-trained Transformer) language models are an\nartificial intelligence and natural language processing technology that enables\nautomatic text generation. There is a growing interest in applying GPT language\nmodels to university teaching in various dimensions. From the perspective of\ninnovation in student and teacher activities, they can provide support in\nunderstanding and generating content, problem-solving, as well as\npersonalization and test correction, among others. From the dimension of\ninternationalization, the misuse of these models represents a global problem\nthat requires taking a series of common measures in universities from different\ngeographical areas. In several countries, there has been a review of assessment\ntools to ensure that work is done by students and not by AI. To this end, we\nhave conducted a detailed experiment in a representative subject of Computer\nScience such as Software Engineering, which has focused on evaluating the use\nof ChatGPT as an assistant in theory activities, exercises, and laboratory\npractices, assessing its potential use as a support tool for both students and\nteachers.",
      "tldr_zh": "该研究探讨了GPT语言模型在大学教学活动中的创新应用，包括支持内容理解、生成、问题解决、个性化学习和测试批改等方面，从而提升学生和教师的效率。同时，它强调了模型滥用的全球性问题，如AI代写，导致多国大学审查评估工具。为此，研究在软件工程课程中进行了实验，使用ChatGPT作为辅助工具，评估其在理论活动、练习和实验室实践中的潜力，结果显示其可作为有效支持工具，但需谨慎管理以确保学术诚信。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CY",
      "comment": "15 pages, in spanish language, 4 tables, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2403.14694v1",
      "published_date": "2024-03-15 14:31:52 UTC",
      "updated_date": "2024-03-15 14:31:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T15:52:51.419943"
    },
    {
      "arxiv_id": "2403.10327v1",
      "title": "Unsupervised Threat Hunting using Continuous Bag-of-Terms-and-Time (CBoTT)",
      "title_zh": "翻译失败",
      "authors": [
        "Varol Kayhan",
        "Shivendu Shivendu",
        "Rouzbeh Behnia",
        "Clinton Daniel",
        "Manish Agrawal"
      ],
      "abstract": "Threat hunting is sifting through system logs to detect malicious activities\nthat might have bypassed existing security measures. It can be performed in\nseveral ways, one of which is based on detecting anomalies. We propose an\nunsupervised framework, called continuous bag-of-terms-and-time (CBoTT), and\npublish its application programming interface (API) to help researchers and\ncybersecurity analysts perform anomaly-based threat hunting among SIEM logs\ngeared toward process auditing on endpoint devices. Analyses show that our\nframework consistently outperforms benchmark approaches. When logs are sorted\nby likelihood of being an anomaly (from most likely to least), our approach\nidentifies anomalies at higher percentiles (between 1.82-6.46) while benchmark\napproaches identify the same anomalies at lower percentiles (between\n3.25-80.92). This framework can be used by other researchers to conduct\nbenchmark analyses and cybersecurity analysts to find anomalies in SIEM logs.",
      "tldr_zh": "这篇论文提出了一种无监督威胁狩猎框架，名为 Continuous Bag-of-Terms-and-Time (CBoTT)，用于通过系统日志检测可能绕过安全措施的恶意活动，特别是针对端点设备的进程审计。CBoTT 结合了术语和时间因素，并发布其 API，以辅助研究人员和网络安全分析师在 SIEM 日志中进行基于异常的分析。实验结果显示，该框架的表现优于基准方法，能在更高的异常可能性百分位数（1.82-6.46）识别出异常，而基准方法仅在较低百分位数（3.25-80.92）。这项工作为威胁狩猎提供了可复用工具，支持基准分析和实际应用。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.10327v1",
      "published_date": "2024-03-15 14:16:10 UTC",
      "updated_date": "2024-03-15 14:16:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T15:53:06.597860"
    },
    {
      "arxiv_id": "2403.10326v1",
      "title": "CDGP: Automatic Cloze Distractor Generation based on Pre-trained Language Model",
      "title_zh": "翻译失败",
      "authors": [
        "Shang-Hsuan Chiang",
        "Ssu-Cheng Wang",
        "Yao-Chung Fan"
      ],
      "abstract": "Manually designing cloze test consumes enormous time and efforts. The major\nchallenge lies in wrong option (distractor) selection. Having carefully-design\ndistractors improves the effectiveness of learner ability assessment. As a\nresult, the idea of automatically generating cloze distractor is motivated. In\nthis paper, we investigate cloze distractor generation by exploring the\nemployment of pre-trained language models (PLMs) as an alternative for\ncandidate distractor generation. Experiments show that the PLM-enhanced model\nbrings a substantial performance improvement. Our best performing model\nadvances the state-of-the-art result from 14.94 to 34.17 (NDCG@10 score). Our\ncode and dataset is available at https://github.com/AndyChiangSH/CDGP.",
      "tldr_zh": "本研究针对手动设计完形填空测试（cloze test）的耗时问题，提出CDGP框架，利用预训练语言模型（PLMs）自动生成错误选项（distractor），以提升评估学习者能力的有效性。实验结果显示，CDGP模型显著提高了性能，将NDCG@10分数从14.94提升至34.17。代码和数据集已公开在GitHub上，供进一步研究使用。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Findings of short paper, EMNLP 2022",
      "pdf_url": "http://arxiv.org/pdf/2403.10326v1",
      "published_date": "2024-03-15 14:14:26 UTC",
      "updated_date": "2024-03-15 14:14:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T15:53:16.222043"
    },
    {
      "arxiv_id": "2403.10304v2",
      "title": "KIF: A Wikidata-Based Framework for Integrating Heterogeneous Knowledge Sources",
      "title_zh": "KIF：一种基于 Wikidata 的框架，用于整合异构知识来源",
      "authors": [
        "Guilherme Lima",
        "João M. B. Rodrigues",
        "Marcelo Machado",
        "Elton Soares",
        "Sandro R. Fiorini",
        "Raphael Thiago",
        "Leonardo G. Azevedo",
        "Viviane T. da Silva",
        "Renato Cerqueira"
      ],
      "abstract": "We present a Wikidata-based framework, called KIF, for virtually integrating\nheterogeneous knowledge sources. KIF is written in Python and is released as\nopen-source. It leverages Wikidata's data model and vocabulary plus\nuser-defined mappings to construct a unified view of the underlying sources\nwhile keeping track of the context and provenance of their statements. The\nunderlying sources can be triplestores, relational databases, CSV files, etc.,\nwhich may or may not use the vocabulary and RDF encoding of Wikidata. The end\nresult is a virtual knowledge base which behaves like an \"extended Wikidata\"\nand which can be queried using a simple but expressive pattern language,\ndefined in terms of Wikidata's data model. In this paper, we present the design\nand implementation of KIF, discuss how we have used it to solve a real\nintegration problem in the domain of chemistry (involving Wikidata, PubChem,\nand IBM CIRCA), and present experimental results on the performance and\noverhead of KIF",
      "tldr_zh": "我们介绍了 KIF，这是一个基于 Wikidata 的开源 Python 框架，用于虚拟整合异构知识来源，如 triplestores、relational databases 和 CSV 文件。KIF 利用 Wikidata 的数据模型和词汇，加上用户定义的映射，构建一个统一的虚拟知识库，同时跟踪语句的上下文和 provenance，确保来源多样性。实验结果显示，该框架在化学领域（如整合 Wikidata、PubChem 和 IBM CIRCA）的实际应用中表现出良好的性能和较低开销。",
      "categories": [
        "cs.AI",
        "cs.DB"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.10304v2",
      "published_date": "2024-03-15 13:46:36 UTC",
      "updated_date": "2024-07-24 13:43:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T15:53:29.388023"
    },
    {
      "arxiv_id": "2403.10299v1",
      "title": "A Multi-constraint and Multi-objective Allocation Model for Emergency Rescue in IoT Environment",
      "title_zh": "翻译失败",
      "authors": [
        "Xinrun Xu",
        "Zhanbiao Lian",
        "Yurong Wu",
        "Manying Lv",
        "Zhiming Ding",
        "Jian Yan",
        "Shang Jiang"
      ],
      "abstract": "Emergency relief operations are essential in disaster aftermaths,\nnecessitating effective resource allocation to minimize negative impacts and\nmaximize benefits. In prolonged crises or extensive disasters, a systematic,\nmulti-cycle approach is key for timely and informed decision-making. Leveraging\nadvancements in IoT and spatio-temporal data analytics, we've developed the\nMulti-Objective Shuffled Gray-Wolf Frog Leaping Model (MSGW-FLM). This\nmulti-constraint, multi-objective resource allocation model has been rigorously\ntested against 28 diverse challenges, showing superior performance in\ncomparison to established models such as NSGA-II, IBEA, and MOEA/D. MSGW-FLM's\neffectiveness is particularly notable in complex, multi-cycle emergency rescue\nscenarios, which involve numerous constraints and objectives. This model\nrepresents a significant step forward in optimizing resource distribution in\nemergency response situations.",
      "tldr_zh": "本研究针对紧急救援中的资源分配问题，提出了一种基于 IoT 环境的 Multi-constraint and Multi-objective Allocation Model，即 Multi-Objective Shuffled Gray-Wolf Frog Leaping Model (MSGW-FLM)，利用时空数据分析实现系统化的多周期决策优化。MSGW-FLM 模型考虑了多种约束和目标，能够有效最小化负面影响并最大化益处，在 28 个多样化挑战中表现出色，优于 NSGA-II、IBEA 和 MOEA/D 等基准模型。实验结果表明，该模型在复杂多周期紧急救援场景中特别有效，为资源分配优化提供了显著进步。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "5 pages, 5 figures, ISCAS 2024",
      "pdf_url": "http://arxiv.org/pdf/2403.10299v1",
      "published_date": "2024-03-15 13:42:00 UTC",
      "updated_date": "2024-03-15 13:42:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T15:53:41.893931"
    },
    {
      "arxiv_id": "2403.10288v1",
      "title": "Rough Transformers for Continuous and Efficient Time-Series Modelling",
      "title_zh": "翻译失败",
      "authors": [
        "Fernando Moreno-Pino",
        "Álvaro Arroyo",
        "Harrison Waldon",
        "Xiaowen Dong",
        "Álvaro Cartea"
      ],
      "abstract": "Time-series data in real-world medical settings typically exhibit long-range\ndependencies and are observed at non-uniform intervals. In such contexts,\ntraditional sequence-based recurrent models struggle. To overcome this,\nresearchers replace recurrent architectures with Neural ODE-based models to\nmodel irregularly sampled data and use Transformer-based architectures to\naccount for long-range dependencies. Despite the success of these two\napproaches, both incur very high computational costs for input sequences of\nmoderate lengths and greater. To mitigate this, we introduce the Rough\nTransformer, a variation of the Transformer model which operates on\ncontinuous-time representations of input sequences and incurs significantly\nreduced computational costs, critical for addressing long-range dependencies\ncommon in medical contexts. In particular, we propose multi-view signature\nattention, which uses path signatures to augment vanilla attention and to\ncapture both local and global dependencies in input data, while remaining\nrobust to changes in the sequence length and sampling frequency. We find that\nRough Transformers consistently outperform their vanilla attention counterparts\nwhile obtaining the benefits of Neural ODE-based models using a fraction of the\ncomputational time and memory resources on synthetic and real-world time-series\ntasks.",
      "tldr_zh": "该论文针对真实世界医疗时间序列数据中的长程依赖性和不均匀间隔问题，提出Rough Transformer，一种基于Transformer的变体，能够以连续时间表示处理输入序列并显著降低计算成本。核心创新是multi-view signature attention机制，该机制利用path signatures增强标准注意力，捕捉局部和全局依赖，同时对序列长度和采样频率保持鲁棒性。与传统Neural ODE模型相比，Rough Transformer在合成和真实时间序列任务上表现出色，性能优于标准注意力模型，且仅需更少的计算时间和内存资源。",
      "categories": [
        "stat.ML",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "stat.ML",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.10288v1",
      "published_date": "2024-03-15 13:29:45 UTC",
      "updated_date": "2024-03-15 13:29:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T15:53:52.424430"
    },
    {
      "arxiv_id": "2403.10581v2",
      "title": "Large Language Model-informed ECG Dual Attention Network for Heart Failure Risk Prediction",
      "title_zh": "基于大语言模型指导的心电图双注意力网络用于心力衰竭风险预测",
      "authors": [
        "Chen Chen",
        "Lei Li",
        "Marcel Beetz",
        "Abhirup Banerjee",
        "Ramneek Gupta",
        "Vicente Grau"
      ],
      "abstract": "Heart failure (HF) poses a significant public health challenge, with a rising\nglobal mortality rate. Early detection and prevention of HF could significantly\nreduce its impact. We introduce a novel methodology for predicting HF risk\nusing 12-lead electrocardiograms (ECGs). We present a novel, lightweight\ndual-attention ECG network designed to capture complex ECG features essential\nfor early HF risk prediction, despite the notable imbalance between low and\nhigh-risk groups. This network incorporates a cross-lead attention module and\ntwelve lead-specific temporal attention modules, focusing on cross-lead\ninteractions and each lead's local dynamics. To further alleviate model\noverfitting, we leverage a large language model (LLM) with a public ECG-Report\ndataset for pretraining on an ECG-report alignment task. The network is then\nfine-tuned for HF risk prediction using two specific cohorts from the UK\nBiobank study, focusing on patients with hypertension (UKB-HYP) and those who\nhave had a myocardial infarction (UKB-MI).The results reveal that LLM-informed\npre-training substantially enhances HF risk prediction in these cohorts. The\ndual-attention design not only improves interpretability but also predictive\naccuracy, outperforming existing competitive methods with C-index scores of\n0.6349 for UKB-HYP and 0.5805 for UKB-MI. This demonstrates our method's\npotential in advancing HF risk assessment with clinical complex ECG data.",
      "tldr_zh": "本文提出了一种基于Large Language Model (LLM) 的双注意力ECG网络，用于预测心力衰竭(HF)风险，通过捕捉12导联ECG的复杂特征来实现早期检测。网络设计包括cross-lead attention模块和十二个lead-specific temporal attention模块，并利用LLM与公共ECG-Report数据集进行预训练，以缓解模型过拟合问题。实验在UK Biobank的UKB-HYP和UKB-MI队列上微调后，该方法取得了C-index分数分别为0.6349和0.5805的优异结果，超越现有竞争方法，并提升了预测的可解释性和准确性。该研究展示了在处理临床复杂ECG数据方面的新潜力。",
      "categories": [
        "q-bio.QM",
        "cs.AI",
        "cs.CL",
        "cs.LG",
        "eess.SP"
      ],
      "primary_category": "q-bio.QM",
      "comment": "Under journal revision",
      "pdf_url": "http://arxiv.org/pdf/2403.10581v2",
      "published_date": "2024-03-15 13:25:09 UTC",
      "updated_date": "2024-03-22 16:00:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T15:54:06.309734"
    },
    {
      "arxiv_id": "2403.10281v1",
      "title": "Team Trifecta at Factify5WQA: Setting the Standard in Fact Verification with Fine-Tuning",
      "title_zh": "翻译失败",
      "authors": [
        "Shang-Hsuan Chiang",
        "Ming-Chih Lo",
        "Lin-Wei Chao",
        "Wen-Chih Peng"
      ],
      "abstract": "In this paper, we present Pre-CoFactv3, a comprehensive framework comprised\nof Question Answering and Text Classification components for fact verification.\nLeveraging In-Context Learning, Fine-tuned Large Language Models (LLMs), and\nthe FakeNet model, we address the challenges of fact verification. Our\nexperiments explore diverse approaches, comparing different Pre-trained LLMs,\nintroducing FakeNet, and implementing various ensemble methods. Notably, our\nteam, Trifecta, secured first place in the AAAI-24 Factify 3.0 Workshop,\nsurpassing the baseline accuracy by 103% and maintaining a 70% lead over the\nsecond competitor. This success underscores the efficacy of our approach and\nits potential contributions to advancing fact verification research.",
      "tldr_zh": "本研究介绍了Pre-CoFactv3框架，该框架结合Question Answering和Text Classification组件，用于事实验证，采用In-Context Learning、Fine-tuned Large Language Models (LLMs)以及FakeNet模型来应对相关挑战。研究团队比较了不同预训练LLMs、引入了FakeNet，并探索了各种集成方法，以提升验证性能。在AAAI-24 Factify 3.0 Workshop中，团队Trifecta获得第一名，比基线准确率提高了103%，并领先第二名70%，展示了该方法的显著优势和对事实验证研究的潜在贡献。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted by AAAI 2024 Workshop: FACTIFY 3.0 - Workshop Series on\n  Multimodal Fact-Checking and Hate Speech Detection",
      "pdf_url": "http://arxiv.org/pdf/2403.10281v1",
      "published_date": "2024-03-15 13:24:28 UTC",
      "updated_date": "2024-03-15 13:24:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T15:54:18.406655"
    },
    {
      "arxiv_id": "2403.10275v1",
      "title": "A Question on the Explainability of Large Language Models and the Word-Level Univariate First-Order Plausibility Assumption",
      "title_zh": "翻译失败",
      "authors": [
        "Jeremie Bogaert",
        "Francois-Xavier Standaert"
      ],
      "abstract": "The explanations of large language models have recently been shown to be\nsensitive to the randomness used for their training, creating a need to\ncharacterize this sensitivity. In this paper, we propose a characterization\nthat questions the possibility to provide simple and informative explanations\nfor such models. To this end, we give statistical definitions for the\nexplanations' signal, noise and signal-to-noise ratio. We highlight that, in a\ntypical case study where word-level univariate explanations are analyzed with\nfirst-order statistical tools, the explanations of simple feature-based models\ncarry more signal and less noise than those of transformer ones. We then\ndiscuss the possibility to improve these results with alternative definitions\nof signal and noise that would capture more complex explanations and analysis\nmethods, while also questioning the tradeoff with their plausibility for\nreaders.",
      "tldr_zh": "本论文质疑大型语言模型（Large Language Models）的解释性，特别关注其对训练随机性的敏感性，并提出通过统计定义来表征解释中的信号、噪声和信噪比（signal-to-noise ratio）。研究者分析了词级单变量一阶可信度假设（word-level univariate first-order plausibility）在典型案例中的表现，发现简单特征模型的解释相比Transformer模型具有更多信号和更少噪声。论文进一步讨论了采用更复杂解释定义的可能性，以及这与读者可信度（plausibility）的权衡，以探索改进LLM解释性的潜在途径。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "7 pages, 10 figures, Accepted and presented at AAAI 2024 (ReLM\n  workshop)",
      "pdf_url": "http://arxiv.org/pdf/2403.10275v1",
      "published_date": "2024-03-15 13:15:23 UTC",
      "updated_date": "2024-03-15 13:15:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T15:54:31.681044"
    },
    {
      "arxiv_id": "2404.00013v1",
      "title": "Missing Data Imputation With Granular Semantics and AI-driven Pipeline for Bankruptcy Prediction",
      "title_zh": "翻译失败",
      "authors": [
        "Debarati Chakraborty",
        "Ravi Ranjan"
      ],
      "abstract": "This work focuses on designing a pipeline for the prediction of bankruptcy.\nThe presence of missing values, high dimensional data, and highly\nclass-imbalance databases are the major challenges in the said task. A new\nmethod for missing data imputation with granular semantics has been introduced\nhere. The merits of granular computing have been explored here to define this\nmethod. The missing values have been predicted using the feature semantics and\nreliable observations in a low-dimensional space, in the granular space. The\ngranules are formed around every missing entry, considering a few of the highly\ncorrelated features and most reliable closest observations to preserve the\nrelevance and reliability, the context, of the database against the missing\nentries. An intergranular prediction is then carried out for the imputation\nwithin those contextual granules. That is, the contextual granules enable a\nsmall relevant fraction of the huge database to be used for imputation and\novercome the need to access the entire database repetitively for each missing\nvalue. This method is then implemented and tested for the prediction of\nbankruptcy with the Polish Bankruptcy dataset. It provides an efficient\nsolution for big and high-dimensional datasets even with large imputation\nrates. Then an AI-driven pipeline for bankruptcy prediction has been designed\nusing the proposed granular semantic-based data filling method followed by the\nsolutions to the issues like high dimensional dataset and high class-imbalance\nin the dataset. The rest of the pipeline consists of feature selection with the\nrandom forest for reducing dimensionality, data balancing with SMOTE, and\nprediction with six different popular classifiers including deep NN. All\nmethods defined here have been experimentally verified with suitable\ncomparative studies and proven to be effective on all the data sets captured\nover the five years.",
      "tldr_zh": "这篇论文针对破产预测任务中的缺失值、高维数据和类不平衡问题，提出了一种基于 granular semantics 的缺失数据插补方法，利用 granular computing 在低维空间形成上下文颗粒，并通过高度相关的特征和可靠观察进行插补，以提高数据相关性和效率。基于此方法，该研究设计了一个 AI 驱动管道，包括特征选择（使用随机森林）、数据平衡（SMOTE）和六种分类器（如深度神经网络）的预测模型。实验在波兰破产数据集上验证，该管道显著提升了预测性能，即使在高维和大量缺失值的情况下，也证明了其有效性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "q-fin.ST",
        "stat.AP"
      ],
      "primary_category": "cs.LG",
      "comment": "15 pages",
      "pdf_url": "http://arxiv.org/pdf/2404.00013v1",
      "published_date": "2024-03-15 13:01:09 UTC",
      "updated_date": "2024-03-15 13:01:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T15:54:43.585050"
    },
    {
      "arxiv_id": "2403.10259v1",
      "title": "Comprehensive Study Of Predictive Maintenance In Industries Using Classification Models And LSTM Model",
      "title_zh": "工业中预测性维护的全面研究：使用分类模型和 LSTM 模型",
      "authors": [
        "Saket Maheshwari",
        "Sambhav Tiwari",
        "Shyam Rai",
        "Satyam Vinayak Daman Pratap Singh"
      ],
      "abstract": "In today's technology-driven era, the imperative for predictive maintenance\nand advanced diagnostics extends beyond aviation to encompass the\nidentification of damages, failures, and operational defects in rotating and\nmoving machines. Implementing such services not only curtails maintenance costs\nbut also extends machine lifespan, ensuring heightened operational efficiency.\nMoreover, it serves as a preventive measure against potential accidents or\ncatastrophic events. The advent of Artificial Intelligence (AI) has\nrevolutionized maintenance across industries, enabling more accurate and\nefficient prediction and analysis of machine failures, thereby conserving time\nand resources. Our proposed study aims to delve into various machine learning\nclassification techniques, including Support Vector Machine (SVM), Random\nForest, Logistic Regression, and Convolutional Neural Network LSTM-Based, for\npredicting and analyzing machine performance. SVM classifies data into\ndifferent categories based on their positions in a multidimensional space,\nwhile Random Forest employs ensemble learning to create multiple decision trees\nfor classification. Logistic Regression predicts the probability of binary\noutcomes using input data. The primary objective of the study is to assess\nthese algorithms' performance in predicting and analyzing machine performance,\nconsidering factors such as accuracy, precision, recall, and F1 score. The\nfindings will aid maintenance experts in selecting the most suitable machine\nlearning algorithm for effective prediction and analysis of machine\nperformance.",
      "tldr_zh": "本研究探讨了预测性维护在工业中的应用，旨在通过机器学习模型预测和分析旋转及移动机器的故障，以降低维护成本、延长设备寿命并预防事故。研究比较了多种分类模型，包括 Support Vector Machine (SVM)、Random Forest、Logistic Regression 和基于 Convolutional Neural Network 的 LSTM (CNN-LSTM) 模型，对机器性能进行分类和预测。评估指标涵盖准确率、精确率、召回率和 F1 分数，结果将帮助维护专家选择最合适的算法，以提升预测效率和资源利用。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.10259v1",
      "published_date": "2024-03-15 12:47:45 UTC",
      "updated_date": "2024-03-15 12:47:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T15:54:55.127558"
    },
    {
      "arxiv_id": "2403.10249v1",
      "title": "A Survey on Game Playing Agents and Large Models: Methods, Applications, and Challenges",
      "title_zh": "翻译失败",
      "authors": [
        "Xinrun Xu",
        "Yuxin Wang",
        "Chaoyi Xu",
        "Ziluo Ding",
        "Jiechuan Jiang",
        "Zhiming Ding",
        "Börje F. Karlsson"
      ],
      "abstract": "The swift evolution of Large-scale Models (LMs), either language-focused or\nmulti-modal, has garnered extensive attention in both academy and industry. But\ndespite the surge in interest in this rapidly evolving area, there are scarce\nsystematic reviews on their capabilities and potential in distinct impactful\nscenarios. This paper endeavours to help bridge this gap, offering a thorough\nexamination of the current landscape of LM usage in regards to complex game\nplaying scenarios and the challenges still open. Here, we seek to\nsystematically review the existing architectures of LM-based Agents (LMAs) for\ngames and summarize their commonalities, challenges, and any other insights.\nFurthermore, we present our perspective on promising future research avenues\nfor the advancement of LMs in games. We hope to assist researchers in gaining a\nclear understanding of the field and to generate more interest in this highly\nimpactful research direction. A corresponding resource, continuously updated,\ncan be found in our GitHub repository.",
      "tldr_zh": "这篇论文对Large-scale Models (LMs)在游戏玩耍代理中的应用进行了系统综述，审查了现有LM-based Agents (LMAs)的架构、方法和挑战，旨在填补该领域的文献空白。作者总结了这些代理的共同点、潜在问题（如复杂游戏场景的限制），并提出了未来研究方向，以推动LMs在游戏中的发展。论文还提供了一个持续更新的GitHub资源，帮助研究者更深入地理解和探索这一高影响力的领域。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "13 pages, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2403.10249v1",
      "published_date": "2024-03-15 12:37:12 UTC",
      "updated_date": "2024-03-15 12:37:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T15:55:06.488685"
    },
    {
      "arxiv_id": "2403.10231v2",
      "title": "Less is More: One-shot Subgraph Reasoning on Large-scale Knowledge Graphs",
      "title_zh": "少即是多：大型知识图谱上",
      "authors": [
        "Zhanke Zhou",
        "Yongqi Zhang",
        "Jiangchao Yao",
        "Quanming Yao",
        "Bo Han"
      ],
      "abstract": "To deduce new facts on a knowledge graph (KG), a link predictor learns from\nthe graph structure and collects local evidence to find the answer to a given\nquery. However, existing methods suffer from a severe scalability problem due\nto the utilization of the whole KG for prediction, which hinders their promise\non large scale KGs and cannot be directly addressed by vanilla sampling\nmethods. In this work, we propose the one-shot-subgraph link prediction to\nachieve efficient and adaptive prediction. The design principle is that,\ninstead of directly acting on the whole KG, the prediction procedure is\ndecoupled into two steps, i.e., (i) extracting only one subgraph according to\nthe query and (ii) predicting on this single, query dependent subgraph. We\nreveal that the non-parametric and computation-efficient heuristics\nPersonalized PageRank (PPR) can effectively identify the potential answers and\nsupporting evidence. With efficient subgraph-based prediction, we further\nintroduce the automated searching of the optimal configurations in both data\nand model spaces. Empirically, we achieve promoted efficiency and leading\nperformances on five large-scale benchmarks. The code is publicly available at:\nhttps://github.com/tmlr-group/one-shot-subgraph.",
      "tldr_zh": "本文提出 one-shot-subgraph 链接预测方法，以解决大规模知识图谱 (KG) 中现有方法因使用整个图谱而导致的可扩展性问题。该方法将预测过程解耦为两步：首先根据查询提取一个查询相关的子图，然后在该子图上利用 Personalized PageRank (PPR) 等高效启发式算法识别潜在答案和支持证据。进一步引入自动搜索数据和模型空间的最佳配置，最终在五个大型基准上实现了更高的预测效率和领先性能。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.SI"
      ],
      "primary_category": "cs.LG",
      "comment": "32 pages, 43 figures",
      "pdf_url": "http://arxiv.org/pdf/2403.10231v2",
      "published_date": "2024-03-15 12:00:12 UTC",
      "updated_date": "2025-02-09 20:52:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T15:55:20.397854"
    },
    {
      "arxiv_id": "2403.10228v1",
      "title": "HawkEye: Training Video-Text LLMs for Grounding Text in Videos",
      "title_zh": "翻译失败",
      "authors": [
        "Yueqian Wang",
        "Xiaojun Meng",
        "Jianxin Liang",
        "Yuxuan Wang",
        "Qun Liu",
        "Dongyan Zhao"
      ],
      "abstract": "Video-text Large Language Models (video-text LLMs) have shown remarkable\nperformance in answering questions and holding conversations on simple videos.\nHowever, they perform almost the same as random on grounding text queries in\nlong and complicated videos, having little ability to understand and reason\nabout temporal information, which is the most fundamental difference between\nvideos and images. In this paper, we propose HawkEye, one of the first\nvideo-text LLMs that can perform temporal video grounding in a fully\ntext-to-text manner. To collect training data that is applicable for temporal\nvideo grounding, we construct InternVid-G, a large-scale video-text corpus with\nsegment-level captions and negative spans, with which we introduce two new\ntime-aware training objectives to video-text LLMs. We also propose a\ncoarse-grained method of representing segments in videos, which is more robust\nand easier for LLMs to learn and follow than other alternatives. Extensive\nexperiments show that HawkEye is better at temporal video grounding and\ncomparable on other video-text tasks with existing video-text LLMs, which\nverifies its superior video-text multi-modal understanding abilities.",
      "tldr_zh": "该研究发现，现有的 video-text LLMs 在处理长视频的 temporal video grounding 时表现欠佳，主要是因为对时间信息的理解和推理能力不足。为此，论文提出 HawkEye，一种首创的 video-text LLMs，能够通过文本到文本方式进行时间视频定位，并构建了大型数据集 InternVid-G（包含段级标题和负样本），同时引入两个时间感知训练目标和粗粒度视频段表示方法。实验显示，HawkEye 在 temporal video grounding 任务上显著优于基线模型，并在其他视频文本任务上保持相当的性能。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.10228v1",
      "published_date": "2024-03-15 11:58:18 UTC",
      "updated_date": "2024-03-15 11:58:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T15:55:32.498928"
    },
    {
      "arxiv_id": "2403.10220v1",
      "title": "From Chaos to Clarity: Time Series Anomaly Detection in Astronomical Observations",
      "title_zh": "从混乱到清晰：天文观测中的时间序列异常检测",
      "authors": [
        "Xinli Hao",
        "Yile Chen",
        "Chen Yang",
        "Zhihui Du",
        "Chaohong Ma",
        "Chao Wu",
        "Xiaofeng Meng"
      ],
      "abstract": "With the development of astronomical facilities, large-scale time series data\nobserved by these facilities is being collected. Analyzing anomalies in these\nastronomical observations is crucial for uncovering potential celestial events\nand physical phenomena, thus advancing the scientific research process.\nHowever, existing time series anomaly detection methods fall short in tackling\nthe unique characteristics of astronomical observations where each star is\ninherently independent but interfered by random concurrent noise, resulting in\na high rate of false alarms. To overcome the challenges, we propose AERO, a\nnovel two-stage framework tailored for unsupervised anomaly detection in\nastronomical observations. In the first stage, we employ a Transformer-based\nencoder-decoder architecture to learn the normal temporal patterns on each\nvariate (i.e., star) in alignment with the characteristic of variate\nindependence. In the second stage, we enhance the graph neural network with a\nwindow-wise graph structure learning to tackle the occurrence of concurrent\nnoise characterized by spatial and temporal randomness. In this way, AERO is\nnot only capable of distinguishing normal temporal patterns from potential\nanomalies but also effectively differentiating concurrent noise, thus\ndecreasing the number of false alarms. We conducted extensive experiments on\nthree synthetic datasets and three real-world datasets. The results demonstrate\nthat AERO outperforms the compared baselines. Notably, compared to the\nstate-of-the-art model, AERO improves the F1-score by up to 8.76% and 2.63% on\nsynthetic and real-world datasets respectively.",
      "tldr_zh": "天文观测中，随着设施的发展，产生了大量时间序列数据，分析这些数据中的异常有助于发现潜在的天文事件，但现有方法难以处理每个星体（variate）的独立性及其受随机并发噪声干扰的问题，导致高假警报率。研究提出AERO，一种新型的两阶段无监督异常检测框架：第一阶段使用基于Transformer的编码器-解码器架构学习每个星体的正常时间模式；第二阶段则通过增强Graph Neural Network的窗口-wise图结构学习，处理并发噪声的空间和时间随机性，从而有效减少假警报。在实验中，AERO在三个合成数据集和三个真实数据集上表现优异，比最先进模型的F1-score分别提升高达8.76%和2.63%。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "accepted by ICDE 2024",
      "pdf_url": "http://arxiv.org/pdf/2403.10220v1",
      "published_date": "2024-03-15 11:39:12 UTC",
      "updated_date": "2024-03-15 11:39:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T15:55:43.860061"
    },
    {
      "arxiv_id": "2405.04537v1",
      "title": "An intuitive multi-frequency feature representation for SO(3)-equivariant networks",
      "title_zh": "一种直观的多频率特征表示用于 SO(3)-等变网络",
      "authors": [
        "Dongwon Son",
        "Jaehyung Kim",
        "Sanghyeon Son",
        "Beomjoon Kim"
      ],
      "abstract": "The usage of 3D vision algorithms, such as shape reconstruction, remains\nlimited because they require inputs to be at a fixed canonical rotation.\nRecently, a simple equivariant network, Vector Neuron (VN) has been proposed\nthat can be easily used with the state-of-the-art 3D neural network (NN)\narchitectures. However, its performance is limited because it is designed to\nuse only three-dimensional features, which is insufficient to capture the\ndetails present in 3D data. In this paper, we introduce an equivariant feature\nrepresentation for mapping a 3D point to a high-dimensional feature space. Our\nfeature can discern multiple frequencies present in 3D data, which is the key\nto designing an expressive feature for 3D vision tasks. Our representation can\nbe used as an input to VNs, and the results demonstrate that with our feature\nrepresentation, VN captures more details, overcoming the limitation raised in\nits original paper.",
      "tldr_zh": "本研究针对SO(3)-equivariant networks提出了一种直观的multi-frequency特征表示，以解决现有3D视觉算法（如形状重建）对输入固定旋转的依赖问题。该特征表示将3D点映射到高维空间，能够区分3D数据中的多种频率，从而提升特征的表达性和细节捕捉能力。实验结果显示，使用该表示作为Vector Neuron (VN)的输入后，VN的表现显著改善，克服了原有三维特征的局限性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.GR"
      ],
      "primary_category": "cs.CV",
      "comment": "ICLR 2024",
      "pdf_url": "http://arxiv.org/pdf/2405.04537v1",
      "published_date": "2024-03-15 11:36:50 UTC",
      "updated_date": "2024-03-15 11:36:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T15:55:55.104796"
    },
    {
      "arxiv_id": "2403.10216v1",
      "title": "Exploring Optical Flow Inclusion into nnU-Net Framework for Surgical Instrument Segmentation",
      "title_zh": "翻译失败",
      "authors": [
        "Marcos Fernández-Rodríguez",
        "Bruno Silva",
        "Sandro Queirós",
        "Helena R. Torres",
        "Bruno Oliveira",
        "Pedro Morais",
        "Lukas R. Buschle",
        "Jorge Correia-Pinto",
        "Estevão Lima",
        "João L. Vilaça"
      ],
      "abstract": "Surgical instrument segmentation in laparoscopy is essential for\ncomputer-assisted surgical systems. Despite the Deep Learning progress in\nrecent years, the dynamic setting of laparoscopic surgery still presents\nchallenges for precise segmentation. The nnU-Net framework excelled in semantic\nsegmentation analyzing single frames without temporal information. The\nframework's ease of use, including its ability to be automatically configured,\nand its low expertise requirements, have made it a popular base framework for\ncomparisons. Optical flow (OF) is a tool commonly used in video tasks to\nestimate motion and represent it in a single frame, containing temporal\ninformation. This work seeks to employ OF maps as an additional input to the\nnnU-Net architecture to improve its performance in the surgical instrument\nsegmentation task, taking advantage of the fact that instruments are the main\nmoving objects in the surgical field. With this new input, the temporal\ncomponent would be indirectly added without modifying the architecture. Using\nCholecSeg8k dataset, three different representations of movement were estimated\nand used as new inputs, comparing them with a baseline model. Results showed\nthat the use of OF maps improves the detection of classes with high movement,\neven when these are scarce in the dataset. To further improve performance,\nfuture work may focus on implementing other OF-preserving augmentations.",
      "tldr_zh": "本研究探讨了将 Optical Flow (OF) 纳入 nnU-Net 框架，以提升腹腔镜手术中手术器械的语义分割性能。研究方法涉及使用 OF 地图作为额外输入，估计运动并间接添加时间信息，而无需修改 nnU-Net 的架构；在 CholecSeg8k 数据集上测试了三种运动表示，并与基线模型进行比较。结果表明，OF 地图显著提高了对高运动类别（如手术器械）的检测准确率，即使这些类别在数据集中稀少；未来工作可聚焦于实现其他 OF 保留增强技术以进一步优化性能。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.10216v1",
      "published_date": "2024-03-15 11:36:26 UTC",
      "updated_date": "2024-03-15 11:36:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T15:56:08.244935"
    },
    {
      "arxiv_id": "2403.10205v1",
      "title": "Read between the lines -- Functionality Extraction From READMEs",
      "title_zh": "翻译失败",
      "authors": [
        "Prince Kumar",
        "Srikanth Tamilselvam",
        "Dinesh Garg"
      ],
      "abstract": "While text summarization is a well-known NLP task, in this paper, we\nintroduce a novel and useful variant of it called functionality extraction from\nGit README files. Though this task is a text2text generation at an abstract\nlevel, it involves its own peculiarities and challenges making existing\ntext2text generation systems not very useful. The motivation behind this task\nstems from a recent surge in research and development activities around the use\nof large language models for code-related tasks, such as code refactoring, code\nsummarization, etc. We also release a human-annotated dataset called FuncRead,\nand develop a battery of models for the task. Our exhaustive experimentation\nshows that small size fine-tuned models beat any baseline models that can be\ndesigned using popular black-box or white-box large language models (LLMs) such\nas ChatGPT and Bard. Our best fine-tuned 7 Billion CodeLlama model exhibit 70%\nand 20% gain on the F1 score against ChatGPT and Bard respectively.",
      "tldr_zh": "这篇论文引入了一个新任务：从 Git README 文件中提取功能性（functionality extraction），这是一种文本摘要的变体，但面临独特挑战，如特定代码上下文的处理。作者发布了人类标注的数据集 FuncRead，并开发了多种模型，通过微调小型模型（如 7 Billion CodeLlama）来优化任务表现。实验结果显示，这些微调模型在 F1 score 上比 ChatGPT 高 70%，比 Bard 高 20%，证明了其在代码相关任务中的优越性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.10205v1",
      "published_date": "2024-03-15 11:11:57 UTC",
      "updated_date": "2024-03-15 11:11:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T15:56:22.248992"
    },
    {
      "arxiv_id": "2403.10202v1",
      "title": "Learning on JPEG-LDPC Compressed Images: Classifying with Syndromes",
      "title_zh": "翻译失败",
      "authors": [
        "Ahcen Aliouat",
        "Elsa Dupraz"
      ],
      "abstract": "In goal-oriented communications, the objective of the receiver is often to\napply a Deep-Learning model, rather than reconstructing the original data. In\nthis context, direct learning over compressed data, without any prior decoding,\nholds promise for enhancing the time-efficient execution of inference models at\nthe receiver. However, conventional entropic-coding methods like Huffman and\nArithmetic break data structure, rendering them unsuitable for learning without\ndecoding. In this paper, we propose an alternative approach in which entropic\ncoding is realized with Low-Density Parity Check (LDPC) codes. We hypothesize\nthat Deep Learning models can more effectively exploit the internal code\nstructure of LDPC codes. At the receiver, we leverage a specific class of\nRecurrent Neural Networks (RNNs), specifically Gated Recurrent Unit (GRU),\ntrained for image classification. Our numerical results indicate that\nclassification based on LDPC-coded bit-planes surpasses Huffman and Arithmetic\ncoding, while necessitating a significantly smaller learning model. This\ndemonstrates the efficiency of classification directly from LDPC-coded data,\neliminating the need for any form of decompression, even partial, prior to\napplying the learning model.",
      "tldr_zh": "本文提出了一种直接在JPEG-LDPC压缩图像上进行图像分类的方法，旨在提升目标导向通信中接收端的推理效率，而无需进行任何解码或解压缩。作者使用Low-Density Parity Check (LDPC) codes作为熵编码的替代方案，取代传统Huffman和Arithmetic coding，以利用LDPC代码的内部结构，并通过Gated Recurrent Unit (GRU)这样的Recurrent Neural Networks (RNNs)进行训练分类。实验结果显示，该方法在LDPC-coded bit-planes的基础上实现了比传统编码更高的分类性能，同时所需学习模型更小，证明了其在高效处理压缩数据方面的优势。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV",
        "cs.IT",
        "cs.LG",
        "math.IT",
        "94A08, 94A29, 68P30",
        "I.4.2; I.4.9; E.4; C.2.0; I.2.10"
      ],
      "primary_category": "eess.IV",
      "comment": "5 pages, 3 figures, conference paper, submitted to the EUSIPCO 2024\n  Conference",
      "pdf_url": "http://arxiv.org/pdf/2403.10202v1",
      "published_date": "2024-03-15 11:07:38 UTC",
      "updated_date": "2024-03-15 11:07:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T15:56:34.705048"
    },
    {
      "arxiv_id": "2403.10190v1",
      "title": "Perceptual Quality-based Model Training under Annotator Label Uncertainty",
      "title_zh": "翻译失败",
      "authors": [
        "Chen Zhou",
        "Mohit Prabhushankar",
        "Ghassan AlRegib"
      ],
      "abstract": "Annotators exhibit disagreement during data labeling, which can be termed as\nannotator label uncertainty. Annotator label uncertainty manifests in\nvariations of labeling quality. Training with a single low-quality annotation\nper sample induces model reliability degradations. In this work, we first\nexamine the effects of annotator label uncertainty in terms of the model's\ngeneralizability and prediction uncertainty. We observe that the model's\ngeneralizability and prediction uncertainty degrade with the presence of\nlow-quality noisy labels. Meanwhile, our evaluation of existing uncertainty\nestimation algorithms indicates their incapability in response to annotator\nlabel uncertainty. To mitigate performance degradation, prior methods show that\ntraining models with labels collected from multiple independent annotators can\nenhance generalizability. However, they require massive annotations. Hence, we\nintroduce a novel perceptual quality-based model training framework to\nobjectively generate multiple labels for model training to enhance reliability,\nwhile avoiding massive annotations. Specifically, we first select a subset of\nsamples with low perceptual quality scores ranked by statistical regularities\nof visual signals. We then assign de-aggregated labels to each sample in this\nsubset to obtain a training set with multiple labels. Our experiments and\nanalysis demonstrate that training with the proposed framework alleviates the\ndegradation of generalizability and prediction uncertainty caused by annotator\nlabel uncertainty.",
      "tldr_zh": "本研究探讨了标注者标签不确定性（annotator label uncertainty）对模型训练的影响，发现低质量标签会降低模型的泛化能力（generalizability）和预测不确定性（prediction uncertainty）。为了缓解这一问题，作者提出了一种基于感知质量（perceptual quality）的模型训练框架，该框架通过选择感知质量分数低的样本子集，并为这些样本分配去聚合标签（de-aggregated labels），从而生成多个标签的训练集，而无需大量额外标注。实验结果表明，该框架有效减轻了因标注者标签不确定性导致的性能下降，提高了模型的可靠性和泛化性能。总体上，这为在不确定标签环境下提升模型训练质量提供了新途径。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.10190v1",
      "published_date": "2024-03-15 10:52:18 UTC",
      "updated_date": "2024-03-15 10:52:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T15:56:45.303186"
    },
    {
      "arxiv_id": "2403.10187v1",
      "title": "Grasp Anything: Combining Teacher-Augmented Policy Gradient Learning with Instance Segmentation to Grasp Arbitrary Objects",
      "title_zh": "Grasp Anything：结合教师增强策略梯度学习与实例分割来抓取任意物体",
      "authors": [
        "Malte Mosbach",
        "Sven Behnke"
      ],
      "abstract": "Interactive grasping from clutter, akin to human dexterity, is one of the\nlongest-standing problems in robot learning. Challenges stem from the\nintricacies of visual perception, the demand for precise motor skills, and the\ncomplex interplay between the two. In this work, we present Teacher-Augmented\nPolicy Gradient (TAPG), a novel two-stage learning framework that synergizes\nreinforcement learning and policy distillation. After training a teacher policy\nto master the motor control based on object pose information, TAPG facilitates\nguided, yet adaptive, learning of a sensorimotor policy, based on object\nsegmentation. We zero-shot transfer from simulation to a real robot by using\nSegment Anything Model for promptable object segmentation. Our trained policies\nadeptly grasp a wide variety of objects from cluttered scenarios in simulation\nand the real world based on human-understandable prompts. Furthermore, we show\nrobust zero-shot transfer to novel objects. Videos of our experiments are\navailable at \\url{https://maltemosbach.github.io/grasp_anything}.",
      "tldr_zh": "该研究解决了机器人从杂乱环境中抓取任意物体的挑战，提出了一种 Teacher-Augmented Policy Gradient (TAPG) 框架，将强化学习和策略蒸馏相结合。TAPG 通过两阶段学习先训练一个基于物体位姿信息的教师策略，然后指导基于实例分割的传感器运动策略的学习，利用 Segment Anything Model 实现从模拟到真实机器人的零样本转移。实验结果显示，该方法能有效抓取各种物体，支持人类可理解的提示，并在新物体上表现出鲁棒性。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.10187v1",
      "published_date": "2024-03-15 10:48:16 UTC",
      "updated_date": "2024-03-15 10:48:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T15:56:56.620933"
    },
    {
      "arxiv_id": "2403.10184v1",
      "title": "Lifted Causal Inference in Relational Domains",
      "title_zh": "关系域中的提升因果推理",
      "authors": [
        "Malte Luttermann",
        "Mattis Hartwig",
        "Tanya Braun",
        "Ralf Möller",
        "Marcel Gehrke"
      ],
      "abstract": "Lifted inference exploits symmetries in probabilistic graphical models by\nusing a representative for indistinguishable objects, thereby speeding up query\nanswering while maintaining exact answers. Even though lifting is a\nwell-established technique for the task of probabilistic inference in\nrelational domains, it has not yet been applied to the task of causal\ninference. In this paper, we show how lifting can be applied to efficiently\ncompute causal effects in relational domains. More specifically, we introduce\nparametric causal factor graphs as an extension of parametric factor graphs\nincorporating causal knowledge and give a formal semantics of interventions\ntherein. We further present the lifted causal inference algorithm to compute\ncausal effects on a lifted level, thereby drastically speeding up causal\ninference compared to propositional inference, e.g., in causal Bayesian\nnetworks. In our empirical evaluation, we demonstrate the effectiveness of our\napproach.",
      "tldr_zh": "该论文探讨了在关系域中应用提升式推理（lifted inference）来加速因果推理的过程，通过使用代表不可区分对象的表示来保持精确答案的同时提高效率。主要贡献包括引入参数因果因子图（parametric causal factor graphs），作为参数因子图的扩展，并为其定义干预（interventions）的正式语义。论文还提出了提升式因果推理算法（lifted causal inference algorithm），能够在提升级别上计算因果效应，比传统的命题推理（如在因果贝叶斯网络中）大幅加速。实验结果证明了该方法的有效性。",
      "categories": [
        "cs.AI",
        "cs.DS"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted to the Proceedings of the 3rd Conference on Causal Learning\n  and Reasoning (CLeaR-24)",
      "pdf_url": "http://arxiv.org/pdf/2403.10184v1",
      "published_date": "2024-03-15 10:44:27 UTC",
      "updated_date": "2024-03-15 10:44:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T15:57:08.161867"
    },
    {
      "arxiv_id": "2403.10175v2",
      "title": "A Short Survey on Importance Weighting for Machine Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Masanari Kimura",
        "Hideitsu Hino"
      ],
      "abstract": "Importance weighting is a fundamental procedure in statistics and machine\nlearning that weights the objective function or probability distribution based\non the importance of the instance in some sense. The simplicity and usefulness\nof the idea has led to many applications of importance weighting. For example,\nit is known that supervised learning under an assumption about the difference\nbetween the training and test distributions, called distribution shift, can\nguarantee statistically desirable properties through importance weighting by\ntheir density ratio. This survey summarizes the broad applications of\nimportance weighting in machine learning and related research.",
      "tldr_zh": "本调查讨论了 importance weighting 在统计学和机器学习中的基础作用，即通过根据实例的重要性加权目标函数或概率分布，从而实现更准确的模型调整。论文特别强调了在 distribution shift（训练和测试分布差异）场景下，通过 density ratio 计算来保证统计性质的可靠性。总体而言，该研究总结了 importance weighting 在机器学习领域的广泛应用，包括监督学习和其他相关领域。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.10175v2",
      "published_date": "2024-03-15 10:31:46 UTC",
      "updated_date": "2024-05-14 05:58:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T15:57:21.124816"
    },
    {
      "arxiv_id": "2403.10173v3",
      "title": "Efficient Event-Based Object Detection: A Hybrid Neural Network with Spatial and Temporal Attention",
      "title_zh": "高效的基于事件物体检测：一种具有空间和时间注意力的混合神经网络",
      "authors": [
        "Soikat Hasan Ahmed",
        "Jan Finkbeiner",
        "Emre Neftci"
      ],
      "abstract": "Event cameras offer high temporal resolution and dynamic range with minimal\nmotion blur, making them promising for robust object detection. While Spiking\nNeural Networks (SNNs) on neuromorphic hardware are often considered for\nenergy-efficient and low latency event-based data processing, they often fall\nshort of Artificial Neural Networks (ANNs) in accuracy and flexibility. Here,\nwe introduce Attention-based Hybrid SNN-ANN backbones for event-based object\ndetection to leverage the strengths of both SNN and ANN architectures. A novel\nAttention-based SNN-ANN bridge module captures sparse spatial and temporal\nrelations from the SNN layer and converts them into dense feature maps for the\nANN part of the backbone. Additionally, we present a variant that integrates\nDWConvL-STMs to the ANN blocks to capture slower dynamics. This multi-timescale\nnetwork combines fast SNN processing for short timesteps with long-term dense\nRNN processing, effectively capturing both fast and slow dynamics. Experimental\nresults demonstrate that our proposed method surpasses SNN-based approaches by\nsignificant margins, with results comparable to existing ANN and RNN-based\nmethods. Unlike ANN-only networks, the hybrid setup allows us to implement the\nSNN blocks on digital neuromorphic hardware to investigate the feasibility of\nour approach. Extensive ablation studies and implementation on neuromorphic\nhardware confirm the effectiveness of our proposed modules and architectural\nchoices. Our hybrid SNN-ANN architectures pave the way for ANN-like performance\nat a drastically reduced parameter, latency, and power budget.",
      "tldr_zh": "本文提出了一种高效的事件-based 对象检测方法，使用混合 SNN-ANN 神经网络，结合空间和时间注意力机制，以利用 SNN 的能量效率和低延迟优势，同时提升 ANN 的准确性和灵活性。具体而言，该网络引入 Attention-based SNN-ANN bridge 模块来捕获稀疏的空间与时间关系，并整合 DWConvL-STMs 处理多时间尺度动态，实现对快速和缓慢动态的全面捕捉。实验结果表明，该方法在性能上显著优于纯 SNN 方案，与现有 ANN 和 RNN 方法相当，同时通过在数字神经形态硬件上实现 SNN 块，大幅降低了参数、延迟和功耗。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.10173v3",
      "published_date": "2024-03-15 10:28:31 UTC",
      "updated_date": "2025-03-11 18:54:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T15:57:34.949734"
    },
    {
      "arxiv_id": "2403.12096v1",
      "title": "Enriching User Shopping History: Empowering E-commerce with a Hierarchical Recommendation System",
      "title_zh": "丰富用户购物历史：通过分层推荐系统赋能电子商务",
      "authors": [
        "Irem Islek",
        "Sule Gunduz Oguducu"
      ],
      "abstract": "Recommendation systems can provide accurate recommendations by analyzing user\nshopping history. A richer user history results in more accurate\nrecommendations. However, in real applications, users prefer e-commerce\nplatforms where the item they seek is at the lowest price. In other words, most\nusers shop from multiple e-commerce platforms simultaneously; different parts\nof the user's shopping history are shared between different e-commerce\nplatforms. Consequently, we assume in this study that any e-commerce platform\nhas a complete record of the user's history but can only access some parts of\nit. If a recommendation system is able to predict the missing parts first and\nenrich the user's shopping history properly, it will be possible to recommend\nthe next item more accurately. Our recommendation system leverages user\nshopping history to improve prediction accuracy. The proposed approach shows\nsignificant improvements in both NDCG@10 and HR@10.",
      "tldr_zh": "该研究针对用户在多个电子商务平台购物导致的购物历史碎片化问题，提出了一种分层推荐系统（Hierarchical Recommendation System），旨在通过预测和丰富用户历史的缺失部分来提升推荐准确性。该系统假设平台拥有完整的用户记录但仅能访问部分数据，因此先利用现有数据进行预测，然后基于丰富的购物历史生成更精确的推荐。实验结果显示，该方法在 NDCG@10 和 HR@10 指标上实现了显著改善。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.12096v1",
      "published_date": "2024-03-15 10:28:03 UTC",
      "updated_date": "2024-03-15 10:28:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T15:57:44.530210"
    },
    {
      "arxiv_id": "2403.10171v2",
      "title": "AUTONODE: A Neuro-Graphic Self-Learnable Engine for Cognitive GUI Automation",
      "title_zh": "翻译失败",
      "authors": [
        "Arkajit Datta",
        "Tushar Verma",
        "Rajat Chawla",
        "Mukunda N. S",
        "Ishaan Bhola"
      ],
      "abstract": "In recent advancements within the domain of Large Language Models (LLMs),\nthere has been a notable emergence of agents capable of addressing Robotic\nProcess Automation (RPA) challenges through enhanced cognitive capabilities and\nsophisticated reasoning. This development heralds a new era of scalability and\nhuman-like adaptability in goal attainment. In this context, we introduce\nAUTONODE (Autonomous User-interface Transformation through Online Neuro-graphic\nOperations and Deep Exploration). AUTONODE employs advanced neuro-graphical\ntechniques to facilitate autonomous navigation and task execution on web\ninterfaces, thereby obviating the necessity for predefined scripts or manual\nintervention. Our engine empowers agents to comprehend and implement complex\nworkflows, adapting to dynamic web environments with unparalleled efficiency.\nOur methodology synergizes cognitive functionalities with robotic automation,\nendowing AUTONODE with the ability to learn from experience. We have integrated\nan exploratory module, DoRA (Discovery and mapping Operation for graph\nRetrieval Agent), which is instrumental in constructing a knowledge graph that\nthe engine utilizes to optimize its actions and achieve objectives with minimal\nsupervision. The versatility and efficacy of AUTONODE are demonstrated through\na series of experiments, highlighting its proficiency in managing a diverse\narray of web-based tasks, ranging from data extraction to transaction\nprocessing.",
      "tldr_zh": "该论文引入了 AUTONODE，一种基于神经图形（neuro-graphic）技术的自学习引擎，用于提升认知 GUI 自动化，旨在解决 Robotic Process Automation (RPA) 挑战并实现无脚本的自主导航和任务执行。AUTONODE 整合认知功能与机器人自动化，通过 DoRA（Discovery and mapping Operation for graph Retrieval Agent）模块构建知识图谱，实现从经验中学习和动态优化。实验结果展示了其在各种网络任务中的高效表现，包括数据提取和交易处理，突显了其适应性和可扩展性。",
      "categories": [
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted in MIPR-2024",
      "pdf_url": "http://arxiv.org/pdf/2403.10171v2",
      "published_date": "2024-03-15 10:27:17 UTC",
      "updated_date": "2024-05-27 05:03:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T15:57:56.457134"
    },
    {
      "arxiv_id": "2403.10167v2",
      "title": "Efficient Detection of Exchangeable Factors in Factor Graphs",
      "title_zh": "因子图中可交换因素的高效检测",
      "authors": [
        "Malte Luttermann",
        "Johann Machemer",
        "Marcel Gehrke"
      ],
      "abstract": "To allow for tractable probabilistic inference with respect to domain sizes,\nlifted probabilistic inference exploits symmetries in probabilistic graphical\nmodels. However, checking whether two factors encode equivalent semantics and\nhence are exchangeable is computationally expensive. In this paper, we\nefficiently solve the problem of detecting exchangeable factors in a factor\ngraph. In particular, we introduce the detection of exchangeable factors (DEFT)\nalgorithm, which allows us to drastically reduce the computational effort for\nchecking whether two factors are exchangeable in practice. While previous\napproaches iterate all $O(n!)$ permutations of a factor's argument list in the\nworst case (where $n$ is the number of arguments of the factor), we prove that\nDEFT efficiently identifies restrictions to drastically reduce the number of\npermutations and validate the efficiency of DEFT in our empirical evaluation.",
      "tldr_zh": "该论文针对概率图形模型中的因子图，提出了一种高效检测可交换 factors 的方法，以提升概率推理的计算可行性。传统方法需检查所有 O(n!) 排列来验证两个 factors 是否 exchangeable，导致计算开销巨大。作者引入了 DEFT 算法，通过识别限制来大幅减少所需排列数量，从而显著降低计算努力。实验结果证明，DEFT 在实际应用中提高了检测效率，为 lifted probabilistic inference 提供了更实用的工具。",
      "categories": [
        "cs.AI",
        "cs.DS"
      ],
      "primary_category": "cs.AI",
      "comment": "Extended version of paper accepted to the Proceedings of the 37th\n  International FLAIRS Conference (FLAIRS-24)",
      "pdf_url": "http://arxiv.org/pdf/2403.10167v2",
      "published_date": "2024-03-15 10:20:56 UTC",
      "updated_date": "2024-04-05 16:02:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T15:58:08.570193"
    },
    {
      "arxiv_id": "2403.10164v2",
      "title": "CoReEcho: Continuous Representation Learning for 2D+time Echocardiography Analysis",
      "title_zh": "翻译失败",
      "authors": [
        "Fadillah Adamsyah Maani",
        "Numan Saeed",
        "Aleksandr Matsun",
        "Mohammad Yaqub"
      ],
      "abstract": "Deep learning (DL) models have been advancing automatic medical image\nanalysis on various modalities, including echocardiography, by offering a\ncomprehensive end-to-end training pipeline. This approach enables DL models to\nregress ejection fraction (EF) directly from 2D+time echocardiograms, resulting\nin superior performance. However, the end-to-end training pipeline makes the\nlearned representations less explainable. The representations may also fail to\ncapture the continuous relation among echocardiogram clips, indicating the\nexistence of spurious correlations, which can negatively affect the\ngeneralization. To mitigate this issue, we propose CoReEcho, a novel training\nframework emphasizing continuous representations tailored for direct EF\nregression. Our extensive experiments demonstrate that CoReEcho: 1) outperforms\nthe current state-of-the-art (SOTA) on the largest echocardiography dataset\n(EchoNet-Dynamic) with MAE of 3.90 & R2 of 82.44, and 2) provides robust and\ngeneralizable features that transfer more effectively in related downstream\ntasks. The code is publicly available at https://github.com/fadamsyah/CoReEcho.",
      "tldr_zh": "该论文提出 CoReEcho，一种新型训练框架，专注于连续表示 (continuous representations) 的学习，以提升 2D+time 超声心动图 (echocardiography) 分析中的射血分数 (EF) 回归。CoReEcho 通过缓解端到端训练导致的表示不解释性和虚假相关性问题 (spurious correlations)，从而提高模型的泛化能力。在 EchoNet-Dynamic 数据集上，实验结果显示 CoReEcho 超越现有最先进 (SOTA) 方法，达到 MAE 3.90 和 R2 82.44 的性能指标，并提供更有效的特征转移用于相关下游任务。代码已公开在 GitHub 上。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.10164v2",
      "published_date": "2024-03-15 10:18:06 UTC",
      "updated_date": "2024-09-16 12:42:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T15:58:22.771677"
    },
    {
      "arxiv_id": "2405.04536v1",
      "title": "When Training-Free NAS Meets Vision Transformer: A Neural Tangent Kernel Perspective",
      "title_zh": "翻译失败",
      "authors": [
        "Qiqi Zhou",
        "Yichen Zhu"
      ],
      "abstract": "This paper investigates the Neural Tangent Kernel (NTK) to search vision\ntransformers without training. In contrast with the previous observation that\nNTK-based metrics can effectively predict CNNs performance at initialization,\nwe empirically show their inefficacy in the ViT search space. We hypothesize\nthat the fundamental feature learning preference within ViT contributes to the\nineffectiveness of applying NTK to NAS for ViT. We both theoretically and\nempirically validate that NTK essentially estimates the ability of neural\nnetworks that learn low-frequency signals, completely ignoring the impact of\nhigh-frequency signals in feature learning. To address this limitation, we\npropose a new method called ViNTK that generalizes the standard NTK to the\nhigh-frequency domain by integrating the Fourier features from inputs.\nExperiments with multiple ViT search spaces on image classification and\nsemantic segmentation tasks show that our method can significantly speed up\nsearch costs over prior state-of-the-art NAS for ViT while maintaining similar\nperformance on searched architectures.",
      "tldr_zh": "本论文从 Neural Tangent Kernel (NTK) 角度探讨了无训练 Neural Architecture Search (NAS) 在 Vision Transformer (ViT) 中的应用，发现标准的 NTK 指标虽适用于 CNN，但对 ViT 无效，因为它仅评估低频信号的学习能力而忽略高频信号的影响。作者通过理论和实证验证了这一局限性，并提出新方法 ViNTK，通过整合输入的 Fourier features 将 NTK 扩展到高频域。实验结果显示，ViNTK 在图像分类和语义分割任务的多个 ViT 搜索空间中显著降低了搜索成本，同时保持了与现有最先进方法相似的性能。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "ICASSP2024 oral",
      "pdf_url": "http://arxiv.org/pdf/2405.04536v1",
      "published_date": "2024-03-15 10:12:45 UTC",
      "updated_date": "2024-03-15 10:12:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T15:58:34.104566"
    },
    {
      "arxiv_id": "2403.10158v2",
      "title": "Functional Graph Convolutional Networks: A unified multi-task and multi-modal learning framework to facilitate health and social-care insights",
      "title_zh": "翻译失败",
      "authors": [
        "Tobia Boschi",
        "Francesca Bonin",
        "Rodrigo Ordonez-Hurtado",
        "Cécile Rousseau",
        "Alessandra Pascale",
        "John Dinsmore"
      ],
      "abstract": "This paper introduces a novel Functional Graph Convolutional Network (funGCN)\nframework that combines Functional Data Analysis and Graph Convolutional\nNetworks to address the complexities of multi-task and multi-modal learning in\ndigital health and longitudinal studies. With the growing importance of health\nsolutions to improve health care and social support, ensure healthy lives, and\npromote well-being at all ages, funGCN offers a unified approach to handle\nmultivariate longitudinal data for multiple entities and ensures\ninterpretability even with small sample sizes. Key innovations include\ntask-specific embedding components that manage different data types, the\nability to perform classification, regression, and forecasting, and the\ncreation of a knowledge graph for insightful data interpretation. The efficacy\nof funGCN is validated through simulation experiments and a real-data\napplication.",
      "tldr_zh": "本论文提出了一种新型Functional Graph Convolutional Network (funGCN)框架，将Functional Data Analysis与Graph Convolutional Networks相结合，旨在统一处理数字健康和纵向研究中的多任务和多模态学习问题。该框架能够有效管理多变量纵向数据，即使在小样本大小下也确保模型的可解释性，并引入任务特定的嵌入组件，支持分类、回归和预测任务，同时构建知识图以提供数据洞见。funGCN的关键创新在于其灵活性和实用性，通过模拟实验和真实数据应用验证了其在健康和社会护理领域的有效性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.10158v2",
      "published_date": "2024-03-15 10:01:19 UTC",
      "updated_date": "2024-03-27 08:57:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T15:58:45.079737"
    },
    {
      "arxiv_id": "2403.10144v3",
      "title": "NLP Verification: Towards a General Methodology for Certifying Robustness",
      "title_zh": "翻译失败",
      "authors": [
        "Marco Casadio",
        "Tanvi Dinkar",
        "Ekaterina Komendantskaya",
        "Luca Arnaboldi",
        "Matthew L. Daggitt",
        "Omri Isac",
        "Guy Katz",
        "Verena Rieser",
        "Oliver Lemon"
      ],
      "abstract": "Machine Learning (ML) has exhibited substantial success in the field of\nNatural Language Processing (NLP). For example large language models have\nempirically proven to be capable of producing text of high complexity and\ncohesion. However, they are prone to inaccuracies and hallucinations. As these\nsystems are increasingly integrated into real-world applications, ensuring\ntheir safety and reliability becomes a primary concern. There are safety\ncritical contexts where such models must be robust to variability or attack,\nand give guarantees over their output. Computer Vision had pioneered the use of\nformal verification of neural networks for such scenarios and developed common\nverification standards and pipelines, leveraging precise formal reasoning about\ngeometric properties of data manifolds. In contrast, NLP verification methods\nhave only recently appeared in the literature. While presenting sophisticated\nalgorithms, these papers have not yet crystallised into a common methodology.\nThey are often light on the pragmatical issues of NLP verification and the area\nremains fragmented. In this paper, we attempt to distil and evaluate general\ncomponents of an NLP verification pipeline, that emerges from the progress in\nthe field to date. Our contributions are two-fold. Firstly, we propose a\ngeneral methodology to analyse the effect of the embedding gap, a problem that\nrefers to the discrepancy between verification of geometric subspaces and the\nsemantic meaning of sentences, which the geometric subspaces are supposed to\nrepresent. We propose a number of practical NLP methods that can help to\nquantify the effects of the embedding gap. Secondly, we give a general method\nfor training and verification of neural networks that leverages a more precise\ngeometric estimation of semantic similarity of sentences in the embedding space\nand helps to overcome the effects of the embedding gap in practice.",
      "tldr_zh": "该论文探讨了自然语言处理（NLP）模型的鲁棒性验证问题，强调了在安全关键应用中确保模型输出可靠性的必要性，并对比了计算机视觉（CV）领域的成熟验证标准与NLP的碎片化现状。主要贡献包括提出一个通用方法来分析“embedding gap”（嵌入间隙），即几何子空间验证与句子语义含义之间的不一致，并提供实用NLP技术来量化其影响。其次，论文介绍了基于更精确几何估计的神经网络训练和验证方法，以提升语义相似性并在实践中克服embedding gap的效果。总的来说，这为NLP验证建立了一个统一的框架，推动了模型的安全性和可靠性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG",
        "cs.LO",
        "cs.PL"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.10144v3",
      "published_date": "2024-03-15 09:43:52 UTC",
      "updated_date": "2025-01-24 15:43:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T15:58:58.899205"
    },
    {
      "arxiv_id": "2403.10136v2",
      "title": "Response Style Characterization for Repeated Measures Using the Visual Analogue Scale",
      "title_zh": "翻译失败",
      "authors": [
        "Shunsuke Minusa",
        "Tadayuki Matsumura",
        "Kanako Esaki",
        "Yang Shao",
        "Chihiro Yoshimura",
        "Hiroyuki Mizuno"
      ],
      "abstract": "Self-report measures (e.g., Likert scales) are widely used to evaluate\nsubjective health perceptions. Recently, the visual analog scale (VAS), a\nslider-based scale, has become popular owing to its ability to precisely and\neasily assess how people feel. These data can be influenced by the response\nstyle (RS), a user-dependent systematic tendency that occurs regardless of\nquestionnaire instructions. Despite its importance, especially in\nbetween-individual analysis, little attention has been paid to handling the RS\nin the VAS (denoted as response profile (RP)), as it is mainly used for\nwithin-individual monitoring and is less affected by RP. However, VAS\nmeasurements often require repeated self-reports of the same questionnaire\nitems, making it difficult to apply conventional methods on a Likert scale. In\nthis study, we developed a novel RP characterization method for various types\nof repeatedly measured VAS data. This approach involves the modeling of RP as\ndistributional parameters ${\\theta}$ through a mixture of RS-like\ndistributions, and addressing the issue of unbalanced data through bootstrap\nsampling for treating repeated measures. We assessed the effectiveness of the\nproposed method using simulated pseudo-data and an actual dataset from an\nempirical study. The assessment of parameter recovery showed that our method\naccurately estimated the RP parameter ${\\theta}$, demonstrating its robustness.\nMoreover, applying our method to an actual VAS dataset revealed the presence of\nindividual RP heterogeneity, even in repeated VAS measurements, similar to the\nfindings of the Likert scale. Our proposed method enables RP\nheterogeneity-aware VAS data analysis, similar to Likert-scale data analysis.",
      "tldr_zh": "本文提出了一种新型方法，用于表征使用Visual Analogue Scale (VAS)进行重复测量的响应风格 (Response Style, RS)，以解决RS对数据的影响问题。该方法通过将响应配置文件 (Response Profile, RP) 建模为分布参数θ的混合RS-like分布，并采用bootstrap采样处理不平衡重复测量数据，从而实现更准确的估计。在模拟伪数据和实际数据集上的评估显示，该方法能有效恢复RP参数，并揭示个体RP异质性，使VAS数据分析能够像Likert scales一样考虑RS异质性。",
      "categories": [
        "stat.ME",
        "cs.AI"
      ],
      "primary_category": "stat.ME",
      "comment": "Accepted to IEEE Access. Accessible at\n  https://ieeexplore.ieee.org/document/10638535",
      "pdf_url": "http://arxiv.org/pdf/2403.10136v2",
      "published_date": "2024-03-15 09:33:10 UTC",
      "updated_date": "2024-08-20 03:32:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T15:59:09.483450"
    },
    {
      "arxiv_id": "2403.10135v1",
      "title": "The Whole is Better than the Sum: Using Aggregated Demonstrations in In-Context Learning for Sequential Recommendation",
      "title_zh": "翻译失败",
      "authors": [
        "Lei Wang",
        "Ee-Peng Lim"
      ],
      "abstract": "Large language models (LLMs) have shown excellent performance on various NLP\ntasks. To use LLMs as strong sequential recommenders, we explore the in-context\nlearning approach to sequential recommendation. We investigate the effects of\ninstruction format, task consistency, demonstration selection, and number of\ndemonstrations. As increasing the number of demonstrations in ICL does not\nimprove accuracy despite using a long prompt, we propose a novel method called\nLLMSRec-Syn that incorporates multiple demonstration users into one aggregated\ndemonstration. Our experiments on three recommendation datasets show that\nLLMSRec-Syn outperforms state-of-the-art LLM-based sequential recommendation\nmethods. In some cases, LLMSRec-Syn can perform on par with or even better than\nsupervised learning methods. Our code is publicly available at\nhttps://github.com/demoleiwang/LLMSRec_Syn.",
      "tldr_zh": "本研究探讨了使用大型语言模型(LLMs)进行顺序推荐，通过in-context learning优化推荐性能，重点分析指令格式、任务一致性、演示选择和演示数量的影响。作者发现增加演示数量并不能提升准确率，因此提出LLMSRec-Syn方法，将多个演示用户聚合为一个演示，以提高模型效率。在三个推荐数据集上的实验表明，LLMSRec-Syn优于现有LLM-based顺序推荐方法，并在某些情况下与监督学习方法相当或更好。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.IR",
      "comment": "NAACL 2024 (Findings)",
      "pdf_url": "http://arxiv.org/pdf/2403.10135v1",
      "published_date": "2024-03-15 09:28:19 UTC",
      "updated_date": "2024-03-15 09:28:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T15:59:21.257960"
    },
    {
      "arxiv_id": "2403.10131v2",
      "title": "RAFT: Adapting Language Model to Domain Specific RAG",
      "title_zh": "翻译失败",
      "authors": [
        "Tianjun Zhang",
        "Shishir G. Patil",
        "Naman Jain",
        "Sheng Shen",
        "Matei Zaharia",
        "Ion Stoica",
        "Joseph E. Gonzalez"
      ],
      "abstract": "Pretraining Large Language Models (LLMs) on large corpora of textual data is\nnow a standard paradigm. When using these LLMs for many downstream\napplications, it is common to additionally bake in new knowledge (e.g.,\ntime-critical news, or private domain knowledge) into the pretrained model\neither through RAG-based-prompting, or fine-tuning. However, the optimal\nmethodology for the model to gain such new knowledge remains an open question.\nIn this paper, we present Retrieval Augmented FineTuning (RAFT), a training\nrecipe that improves the model's ability to answer questions in a \"open-book\"\nin-domain settings. In RAFT, given a question, and a set of retrieved\ndocuments, we train the model to ignore those documents that don't help in\nanswering the question, which we call, distractor documents. RAFT accomplishes\nthis by citing verbatim the right sequence from the relevant document that\nwould help answer the question. This coupled with RAFT's chain-of-thought-style\nresponse helps improve the model's ability to reason. In domain-specific RAG,\nRAFT consistently improves the model's performance across PubMed, HotpotQA, and\nGorilla datasets, presenting a post-training recipe to improve pre-trained LLMs\nto in-domain RAG. RAFT's code and demo are open-sourced at\ngithub.com/ShishirPatil/gorilla.",
      "tldr_zh": "本文提出了一种名为 RAFT 的训练方法，用于将预训练大语言模型（LLMs）适应特定领域的检索增强生成（RAG），通过训练模型忽略无关文档（distractor documents）并从相关文档中引用准确序列来回答问题，同时结合 chain-of-thought-style 响应提升推理能力。RAFT 的核心在于优化模型在“开卷式”问答场景中的性能，使其更有效地整合新知识。实验结果显示，在 PubMed、HotpotQA 和 Gorilla 数据集上，RAFT 显著提高了模型的表现，为后训练改进预训练 LLMs 提供了有效策略。代码和演示已在 GitHub 上开源。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.10131v2",
      "published_date": "2024-03-15 09:26:02 UTC",
      "updated_date": "2024-06-05 17:27:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T15:59:34.784684"
    },
    {
      "arxiv_id": "2403.15434v1",
      "title": "ChatPattern: Layout Pattern Customization via Natural Language",
      "title_zh": "翻译失败",
      "authors": [
        "Zixiao Wang",
        "Yunheng Shen",
        "Xufeng Yao",
        "Wenqian Zhao",
        "Yang Bai",
        "Farzan Farnia",
        "Bei Yu"
      ],
      "abstract": "Existing works focus on fixed-size layout pattern generation, while the more\npractical free-size pattern generation receives limited attention. In this\npaper, we propose ChatPattern, a novel Large-Language-Model (LLM) powered\nframework for flexible pattern customization. ChatPattern utilizes a two-part\nsystem featuring an expert LLM agent and a highly controllable layout pattern\ngenerator. The LLM agent can interpret natural language requirements and\noperate design tools to meet specified needs, while the generator excels in\nconditional layout generation, pattern modification, and memory-friendly\npatterns extension. Experiments on challenging pattern generation setting shows\nthe ability of ChatPattern to synthesize high-quality large-scale patterns.",
      "tldr_zh": "本文提出 ChatPattern，一种基于 Large Language Model (LLM) 的框架，用于通过自然语言实现灵活的布局模式自定义，以解决现有研究中对自由大小模式生成关注不足的问题。框架包括一个专家 LLM 代理和一个高度可控的布局模式生成器，其中 LLM 代理负责解读自然语言需求并操作设计工具，而生成器专注于条件布局生成、模式修改以及内存友好的模式扩展。实验在具有挑战性的模式生成设置中证明，ChatPattern 能够合成高质量的大规模模式，从而提升布局设计的实用性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted by DAC24",
      "pdf_url": "http://arxiv.org/pdf/2403.15434v1",
      "published_date": "2024-03-15 09:15:22 UTC",
      "updated_date": "2024-03-15 09:15:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T15:59:45.464767"
    },
    {
      "arxiv_id": "2403.10112v1",
      "title": "Single- and Multi-Agent Private Active Sensing: A Deep Neuroevolution Approach",
      "title_zh": "翻译失败",
      "authors": [
        "George Stamatelis",
        "Angelos-Nikolaos Kanatas",
        "Ioannis Asprogerakas",
        "George C. Alexandropoulos"
      ],
      "abstract": "In this paper, we focus on one centralized and one decentralized problem of\nactive hypothesis testing in the presence of an eavesdropper. For the\ncentralized problem including a single legitimate agent, we present a new\nframework based on NeuroEvolution (NE), whereas, for the decentralized problem,\nwe develop a novel NE-based method for solving collaborative multi-agent tasks,\nwhich interestingly maintains all computational benefits of single-agent NE.\nThe superiority of the proposed EAHT approaches over conventional active\nhypothesis testing policies, as well as learning-based methods, is validated\nthrough numerical investigations in an example use case of anomaly detection\nover wireless sensor networks.",
      "tldr_zh": "这篇论文针对存在窃听者的主动假设测试问题，提出了一种基于 NeuroEvolution (NE) 的深度框架：对于单代理中心化问题，开发了新方法；对于多代理去中心化问题，则设计了协作 NE-based 方法，该方法保持了单代理 NE 的计算优势。研究通过数值实验，在无线传感器网络的异常检测示例中，证明了所提方法优于传统主动假设测试策略和基于学习的其他方法。该工作为隐私保护的主动感知任务提供了有效的多代理解决方案。",
      "categories": [
        "cs.AI",
        "cs.CR",
        "cs.MA",
        "cs.NE"
      ],
      "primary_category": "cs.AI",
      "comment": "7 pages, 5 figures, accepted at IEEE ICC 2024 (to be presented)",
      "pdf_url": "http://arxiv.org/pdf/2403.10112v1",
      "published_date": "2024-03-15 08:55:56 UTC",
      "updated_date": "2024-03-15 08:55:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T15:59:57.289891"
    },
    {
      "arxiv_id": "2403.10110v1",
      "title": "Meta Operator for Complex Query Answering on Knowledge Graphs",
      "title_zh": "翻译失败",
      "authors": [
        "Hang Yin",
        "Zihao Wang",
        "Yangqiu Song"
      ],
      "abstract": "Knowledge graphs contain informative factual knowledge but are considered\nincomplete. To answer complex queries under incomplete knowledge,\nlearning-based Complex Query Answering (CQA) models are proposed to directly\nlearn from the query-answer samples to avoid the direct traversal of incomplete\ngraph data. Existing works formulate the training of complex query answering\nmodels as multi-task learning and require a large number of training samples.\nIn this work, we explore the compositional structure of complex queries and\nargue that the different logical operator types, rather than the different\ncomplex query types, are the key to improving generalizability. Accordingly, we\npropose a meta-learning algorithm to learn the meta-operators with limited data\nand adapt them to different instances of operators under various complex\nqueries. Empirical results show that learning meta-operators is more effective\nthan learning original CQA or meta-CQA models.",
      "tldr_zh": "知识图谱常因不完整而难以回答复杂查询，现有的 Complex Query Answering (CQA) 模型通过多任务学习直接从查询-答案样本中学习，但需要大量训练数据。本文探索复杂查询的组合结构，强调不同逻辑运算符类型是提升泛化性的关键，并提出一种元学习算法来学习 meta-operators，使用有限数据适应各种复杂查询下的运算符实例。实验结果表明，该方法比传统 CQA 或 meta-CQA 模型更有效，提高了知识图谱查询的泛化能力和效率。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.LO"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.10110v1",
      "published_date": "2024-03-15 08:54:25 UTC",
      "updated_date": "2024-03-15 08:54:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T16:00:09.524912"
    },
    {
      "arxiv_id": "2403.10107v2",
      "title": "Enhancing Human-Centered Dynamic Scene Understanding via Multiple LLMs Collaborated Reasoning",
      "title_zh": "通过多个LLMs协作推理增强以人为中心的动态场景理解",
      "authors": [
        "Hang Zhang",
        "Wenxiao Zhang",
        "Haoxuan Qu",
        "Jun Liu"
      ],
      "abstract": "Human-centered dynamic scene understanding plays a pivotal role in enhancing\nthe capability of robotic and autonomous systems, in which Video-based\nHuman-Object Interaction (V-HOI) detection is a crucial task in semantic scene\nunderstanding, aimed at comprehensively understanding HOI relationships within\na video to benefit the behavioral decisions of mobile robots and autonomous\ndriving systems. Although previous V-HOI detection models have made significant\nstrides in accurate detection on specific datasets, they still lack the general\nreasoning ability like human beings to effectively induce HOI relationships. In\nthis study, we propose V-HOI Multi-LLMs Collaborated Reasoning (V-HOI MLCR), a\nnovel framework consisting of a series of plug-and-play modules that could\nfacilitate the performance of current V-HOI detection models by leveraging the\nstrong reasoning ability of different off-the-shelf pre-trained large language\nmodels (LLMs). We design a two-stage collaboration system of different LLMs for\nthe V-HOI task. Specifically, in the first stage, we design a Cross-Agents\nReasoning scheme to leverage the LLM conduct reasoning from different aspects.\nIn the second stage, we perform Multi-LLMs Debate to get the final reasoning\nanswer based on the different knowledge in different LLMs. Additionally, we\ndevise an auxiliary training strategy that utilizes CLIP, a large\nvision-language model to enhance the base V-HOI models' discriminative ability\nto better cooperate with LLMs. We validate the superiority of our design by\ndemonstrating its effectiveness in improving the prediction accuracy of the\nbase V-HOI model via reasoning from multiple perspectives.",
      "tldr_zh": "该研究针对人类中心动态场景理解中的 Video-based Human-Object Interaction (V-HOI) 检测问题，提出了一种新框架 V-HOI Multi-LLMs Collaborated Reasoning (V-HOI MLCR)，利用多个预训练大型语言模型 (LLMs) 的强大推理能力来提升现有模型的性能。框架采用两阶段协作系统：第一阶段通过 Cross-Agents Reasoning 方案，让不同 LLMs 从多个角度进行推理；第二阶段则使用 Multi-LLMs Debate 基于各模型的知识得出最终答案。此外，该框架还引入辅助训练策略，利用 CLIP 模型增强基础 V-HOI 模型的辨别能力。实验结果证明，该方法显著提高了 V-HOI 检测的预测准确性，为机器人和自动驾驶系统的行为决策提供了更可靠的支持。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.MM"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.10107v2",
      "published_date": "2024-03-15 08:51:15 UTC",
      "updated_date": "2024-07-19 09:38:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T16:00:22.528031"
    },
    {
      "arxiv_id": "2403.10105v1",
      "title": "Belief Aided Navigation using Bayesian Reinforcement Learning for Avoiding Humans in Blind Spots",
      "title_zh": "翻译失败",
      "authors": [
        "Jinyeob Kim",
        "Daewon Kwak",
        "Hyunwoo Rim",
        "Donghan Kim"
      ],
      "abstract": "Recent research on mobile robot navigation has focused on socially aware\nnavigation in crowded environments. However, existing methods do not adequately\naccount for human robot interactions and demand accurate location information\nfrom omnidirectional sensors, rendering them unsuitable for practical\napplications. In response to this need, this study introduces a novel\nalgorithm, BNBRL+, predicated on the partially observable Markov decision\nprocess framework to assess risks in unobservable areas and formulate movement\nstrategies under uncertainty. BNBRL+ consolidates belief algorithms with\nBayesian neural networks to probabilistically infer beliefs based on the\npositional data of humans. It further integrates the dynamics between the\nrobot, humans, and inferred beliefs to determine the navigation paths and\nembeds social norms within the reward function, thereby facilitating socially\naware navigation. Through experiments in various risk laden scenarios, this\nstudy validates the effectiveness of BNBRL+ in navigating crowded environments\nwith blind spots. The model's ability to navigate effectively in spaces with\nlimited visibility and avoid obstacles dynamically can significantly improve\nthe safety and reliability of autonomous vehicles.",
      "tldr_zh": "本研究针对现有移动机器人导航方法在处理人机互动和盲点时存在的不足，提出了一种新型算法BNBRL+，基于部分可观测马尔科夫决策过程（POMDP）框架来评估不可观测区域的风险并制定不确定条件下的运动策略。BNBRL+ 整合信念算法和Bayesian neural networks，通过人类位置数据推断概率信念，并将机器人、人类动态及社会规范嵌入奖励函数中，实现社交感知导航。该算法在各种高风险场景的实验中证明了其有效性，能够在有限可见度环境中动态避开障碍，提高自主车辆的安全性和可靠性。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "8 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2403.10105v1",
      "published_date": "2024-03-15 08:50:39 UTC",
      "updated_date": "2024-03-15 08:50:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T16:00:34.359736"
    },
    {
      "arxiv_id": "2403.14693v1",
      "title": "A2CI: A Cloud-based, Service-oriented Geospatial Cyberinfrastructure to Support Atmospheric Research",
      "title_zh": "翻译失败",
      "authors": [
        "Wenwen Li",
        "Hu Shao",
        "Sizhe Wang",
        "Xiran Zhou",
        "Sheng Wu"
      ],
      "abstract": "Big earth science data offers the scientific community great opportunities.\nMany more studies at large-scales, over long-terms and at high resolution can\nnow be conducted using the rich information collected by remote sensing\nsatellites, ground-based sensor networks, and even social media input. However,\nthe hundreds of terabytes of information collected and compiled on an hourly\nbasis by NASA and other government agencies present a significant challenge for\natmospheric scientists seeking to improve the understanding of the Earth\natmospheric system. These challenges include effective discovery, organization,\nanalysis and visualization of large amounts of data. This paper reports the\noutcomes of an NSF-funded project that developed a geospatial\ncyberinfrastructure -- the A2CI (Atmospheric Analysis Cyberinfrastructure) --\nto support atmospheric research. We first introduce the service-oriented system\nframework then describe in detail the implementation of the data discovery\nmodule, data management module, data integration module, data analysis and\nvisualization modules following the cloud computing\nprinciples-Data-as-a-Service, Software-as-a-Service, Platform-as-a-Service and\nInfrastructure-as-a-Service. We demonstrate the graphic user interface by\nperforming an analysis between Sea Surface Temperature and the intensity of\ntropical storms in the North Atlantic and Pacific oceans. We expect this work\nto contribute to the technical advancement of cyberinfrastructure research as\nwell as to the development of an online, collaborative scientific analysis\nsystem for atmospheric science.",
      "tldr_zh": "这篇论文介绍了 A2CI，一种基于云的、面向服务的 Geospatial Cyberinfrastructure，用于支持大气研究，旨在解决海量地球科学数据在发现、组织、分析和可视化方面的挑战。系统框架遵循云计算原则，包括 Data-as-a-Service、Software-as-a-Service 等模块，如数据发现、数据管理、数据集成、分析和可视化。作者通过一个示例分析北大西洋和太平洋海面温度与热带风暴强度之间的关系，展示了图形用户界面；该工作有望推动网络基础设施研究和技术进步，并促进大气科学的在线协作系统发展。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.DC",
        "cs.IR",
        "big data, cyberinfrastructure, cloud computing"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.14693v1",
      "published_date": "2024-03-15 08:28:38 UTC",
      "updated_date": "2024-03-15 08:28:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T16:00:46.729082"
    },
    {
      "arxiv_id": "2403.10097v1",
      "title": "Adaptive Random Feature Regularization on Fine-tuning Deep Neural Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Shin'ya Yamaguchi",
        "Sekitoshi Kanai",
        "Kazuki Adachi",
        "Daiki Chijiwa"
      ],
      "abstract": "While fine-tuning is a de facto standard method for training deep neural\nnetworks, it still suffers from overfitting when using small target datasets.\nPrevious methods improve fine-tuning performance by maintaining knowledge of\nthe source datasets or introducing regularization terms such as contrastive\nloss. However, these methods require auxiliary source information (e.g., source\nlabels or datasets) or heavy additional computations. In this paper, we propose\na simple method called adaptive random feature regularization (AdaRand).\nAdaRand helps the feature extractors of training models to adaptively change\nthe distribution of feature vectors for downstream classification tasks without\nauxiliary source information and with reasonable computation costs. To this\nend, AdaRand minimizes the gap between feature vectors and random reference\nvectors that are sampled from class conditional Gaussian distributions.\nFurthermore, AdaRand dynamically updates the conditional distribution to follow\nthe currently updated feature extractors and balance the distance between\nclasses in feature spaces. Our experiments show that AdaRand outperforms the\nother fine-tuning regularization, which requires auxiliary source information\nand heavy computation costs.",
      "tldr_zh": "该论文针对fine-tuning深度神经网络时使用小目标数据集导致过拟合的问题，提出了一种简单方法——adaptive random feature regularization（AdaRand）。AdaRand通过最小化特征向量与从类条件Gaussian distributions采样的随机参考向量之间的差距，帮助特征提取器适应性地调整特征分布，用于下游分类任务，而无需辅助源信息且计算成本合理。该方法还动态更新条件分布，以跟随特征提取器的变化并平衡类间距离。实验结果显示，AdaRand在性能上优于其他需要额外源信息和大量计算的fine-tuning正则化方法。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted to CVPR 2024",
      "pdf_url": "http://arxiv.org/pdf/2403.10097v1",
      "published_date": "2024-03-15 08:26:59 UTC",
      "updated_date": "2024-03-15 08:26:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T16:00:58.479445"
    },
    {
      "arxiv_id": "2403.10088v1",
      "title": "Intent-conditioned and Non-toxic Counterspeech Generation using Multi-Task Instruction Tuning with RLAIF",
      "title_zh": "基于意图的非毒性反驳言论生成，使用多任务指令微调与 RLAIF",
      "authors": [
        "Amey Hengle",
        "Aswini Kumar",
        "Sahajpreet Singh",
        "Anil Bandhakavi",
        "Md Shad Akhtar",
        "Tanmoy Chakroborty"
      ],
      "abstract": "Counterspeech, defined as a response to mitigate online hate speech, is\nincreasingly used as a non-censorial solution. Addressing hate speech\neffectively involves dispelling the stereotypes, prejudices, and biases often\nsubtly implied in brief, single-sentence statements or abuses. These implicit\nexpressions challenge language models, especially in seq2seq tasks, as model\nperformance typically excels with longer contexts. Our study introduces CoARL,\na novel framework enhancing counterspeech generation by modeling the pragmatic\nimplications underlying social biases in hateful statements. CoARL's first two\nphases involve sequential multi-instruction tuning, teaching the model to\nunderstand intents, reactions, and harms of offensive statements, and then\nlearning task-specific low-rank adapter weights for generating\nintent-conditioned counterspeech. The final phase uses reinforcement learning\nto fine-tune outputs for effectiveness and non-toxicity. CoARL outperforms\nexisting benchmarks in intent-conditioned counterspeech generation, showing an\naverage improvement of 3 points in intent-conformity and 4 points in\nargument-quality metrics. Extensive human evaluation supports CoARL's efficacy\nin generating superior and more context-appropriate responses compared to\nexisting systems, including prominent LLMs like ChatGPT.",
      "tldr_zh": "本研究提出 CoARL 框架，通过多任务指令微调和 RLAIF（强化学习从 AI 反馈）来生成意图条件和非毒性的 counterspeech，以缓解在线仇恨言论。框架包括三个阶段：首先训练模型理解仇恨言论的意图、反应和危害；其次学习任务特定的低秩适配器权重以生成基于意图的响应；最后使用强化学习优化输出，确保其有效性和非毒性。实验结果显示，CoARL 在意图一致性和论点质量指标上分别比现有基准提高了 3 和 4 分，并通过人类评估证明其生成的响应优于 ChatGPT 等系统。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.10088v1",
      "published_date": "2024-03-15 08:03:49 UTC",
      "updated_date": "2024-03-15 08:03:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T16:01:12.012079"
    },
    {
      "arxiv_id": "2403.10086v2",
      "title": "Large Language Models to Generate System-Level Test Programs Targeting Non-functional Properties",
      "title_zh": "大语言模型生成针对非功能性属性的系统级测试程序",
      "authors": [
        "Denis Schwachhofer",
        "Peter Domanski",
        "Steffen Becker",
        "Stefan Wagner",
        "Matthias Sauer",
        "Dirk Pflüger",
        "Ilia Polian"
      ],
      "abstract": "System-Level Test (SLT) has been a part of the test flow for integrated\ncircuits for over a decade and still gains importance. However, no systematic\napproaches exist for test program generation, especially targeting\nnon-functional properties of the Device under Test (DUT). Currently, test\nengineers manually compose test suites from off-the-shelf software,\napproximating the end-user environment of the DUT. This is a challenging and\ntedious task that does not guarantee sufficient control over non-functional\nproperties. This paper proposes Large Language Models (LLMs) to generate test\nprograms. We take a first glance at how pre-trained LLMs perform in test\nprogram generation to optimize non-functional properties of the DUT. Therefore,\nwe write a prompt to generate C code snippets that maximize the instructions\nper cycle of a super-scalar, out-of-order architecture in simulation.\nAdditionally, we apply prompt and hyperparameter optimization to achieve the\nbest possible results without further training.",
      "tldr_zh": "本论文探讨使用 Large Language Models (LLMs) 生成系统级测试 (SLT) 程序，针对设备的非功能性属性，以解决当前测试工程师手动编写测试套件的挑战和低效问题。该方法通过设计特定提示生成 C 代码片段，旨在最大化超标量、乱序架构的 Instructions Per Cycle (IPC)。实验结果显示，通过提示和超参数优化，LLMs 能在不进行额外训练的情况下显著提升测试程序的性能和控制精度。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.ET",
        "cs.PL"
      ],
      "primary_category": "cs.SE",
      "comment": "Testmethoden und Zuverl\\\"assigkeit von Schaltungen und Systemen, TuZ\n  2024",
      "pdf_url": "http://arxiv.org/pdf/2403.10086v2",
      "published_date": "2024-03-15 08:01:02 UTC",
      "updated_date": "2024-03-19 09:30:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T16:01:23.601180"
    },
    {
      "arxiv_id": "2403.14692v3",
      "title": "The AI Assessment Scale (AIAS) in action: A pilot implementation of GenAI supported assessment- A Preprint",
      "title_zh": "翻译失败",
      "authors": [
        "Leon Furze",
        "Mike Perkins",
        "Jasper Roe",
        "Jason MacVaugh"
      ],
      "abstract": "The rapid adoption of Generative Artificial Intelligence (GenAI) technologies\nin higher education has raised concerns about academic integrity, assessment\npractices, and student learning. Banning or blocking GenAI tools has proven\nineffective, and punitive approaches ignore the potential benefits of these\ntechnologies. This paper presents the findings of a pilot study conducted at\nBritish University Vietnam (BUV) exploring the implementation of the Artificial\nIntelligence Assessment Scale (AIAS), a flexible framework for incorporating\nGenAI into educational assessments. The AIAS consists of five levels, ranging\nfrom 'No AI' to 'Full AI', enabling educators to design assessments that focus\non areas requiring human input and critical thinking.\n  Following the implementation of the AIAS, the pilot study results indicate a\nsignificant reduction in academic misconduct cases related to GenAI, a 5.9%\nincrease in student attainment across the university, and a 33.3% increase in\nmodule passing rates. The AIAS facilitated a shift in pedagogical practices,\nwith faculty members incorporating GenAI tools into their modules and students\nproducing innovative multimodal submissions. The findings suggest that the AIAS\ncan support the effective integration of GenAI in HE, promoting academic\nintegrity while leveraging the technology's potential to enhance learning\nexperiences.\n  Refer to published version for final text.",
      "tldr_zh": "本研究探讨了 Generative Artificial Intelligence (GenAI) 在高等教育中的应用，提出了一种灵活的 Artificial Intelligence Assessment Scale (AIAS) 框架，以整合 GenAI 到评估实践中。AIAS 包括从 'No AI' 到 'Full AI' 的五个级别，旨在设计评估任务，强调人类输入和批判性思维，从而减少学术不端行为。试点研究在 British University Vietnam (BUV) 实施后，发现学术不端案件显著减少、学生成绩整体提高 5.9%、模块通过率增加 33.3%，并促进了教学实践的转变和学生创新提交。总体而言，AIAS 支持 GenAI 在高等教育中的有效整合，提升了学习体验同时维护学术诚信。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.14692v3",
      "published_date": "2024-03-15 08:00:02 UTC",
      "updated_date": "2025-02-25 10:47:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T16:01:35.023373"
    },
    {
      "arxiv_id": "2403.10079v1",
      "title": "Learning Physical Dynamics for Object-centric Visual Prediction",
      "title_zh": "对象中心视觉预测的物理动力学学习",
      "authors": [
        "Huilin Xu",
        "Tao Chen",
        "Feng Xu"
      ],
      "abstract": "The ability to model the underlying dynamics of visual scenes and reason\nabout the future is central to human intelligence. Many attempts have been made\nto empower intelligent systems with such physical understanding and prediction\nabilities. However, most existing methods focus on pixel-to-pixel prediction,\nwhich suffers from heavy computational costs while lacking a deep understanding\nof the physical dynamics behind videos. Recently, object-centric prediction\nmethods have emerged and attracted increasing interest. Inspired by it, this\npaper proposes an unsupervised object-centric prediction model that makes\nfuture predictions by learning visual dynamics between objects. Our model\nconsists of two modules, perceptual, and dynamic module. The perceptual module\nis utilized to decompose images into several objects and synthesize images with\na set of object-centric representations. The dynamic module fuses contextual\ninformation, takes environment-object and object-object interaction into\naccount, and predicts the future trajectory of objects. Extensive experiments\nare conducted to validate the effectiveness of the proposed method. Both\nquantitative and qualitative experimental results demonstrate that our model\ngenerates higher visual quality and more physically reliable predictions\ncompared to the state-of-the-art methods.",
      "tldr_zh": "这篇论文提出了一种无监督的 object-centric 预测模型，用于学习视觉场景中的物理动态并预测未来状态，以克服传统像素级预测方法的计算开销和理解不足问题。该模型由 perceptual module 和 dynamic module 组成，前者负责将图像分解为多个对象并使用 object-centric representations 合成图像，后者融合上下文信息并考虑环境-对象及对象-对象交互来预测对象的轨迹。实验结果表明，该方法在视觉质量和物理可靠性方面均优于现有 state-of-the-art 方法。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "13 pages, 10 figures",
      "pdf_url": "http://arxiv.org/pdf/2403.10079v1",
      "published_date": "2024-03-15 07:45:25 UTC",
      "updated_date": "2024-03-15 07:45:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T16:01:46.482878"
    },
    {
      "arxiv_id": "2403.10069v1",
      "title": "Boundary Matters: A Bi-Level Active Finetuning Framework",
      "title_zh": "翻译失败",
      "authors": [
        "Han Lu",
        "Yichen Xie",
        "Xiaokang Yang",
        "Junchi Yan"
      ],
      "abstract": "The pretraining-finetuning paradigm has gained widespread adoption in vision\ntasks and other fields, yet it faces the significant challenge of high sample\nannotation costs. To mitigate this, the concept of active finetuning has\nemerged, aiming to select the most appropriate samples for model finetuning\nwithin a limited budget. Traditional active learning methods often struggle in\nthis setting due to their inherent bias in batch selection. Furthermore, the\nrecent active finetuning approach has primarily concentrated on aligning the\ndistribution of selected subsets with the overall data pool, focusing solely on\ndiversity. In this paper, we propose a Bi-Level Active Finetuning framework to\nselect the samples for annotation in one shot, which includes two stages: core\nsample selection for diversity, and boundary sample selection for uncertainty.\nThe process begins with the identification of pseudo-class centers, followed by\nan innovative denoising method and an iterative strategy for boundary sample\nselection in the high-dimensional feature space, all without relying on\nground-truth labels. Our comprehensive experiments provide both qualitative and\nquantitative evidence of our method's efficacy, outperforming all the existing\nbaselines.",
      "tldr_zh": "本研究针对预训练-微调范式在视觉任务中面临的高样本标注成本问题，提出了一种Bi-Level Active Finetuning框架，用于一次性选择最合适的样本进行微调。该框架分为两个阶段：首先通过核心样本选择确保数据多样性，其次利用伪类中心、去噪方法和迭代策略在高维特征空间中选择边界样本，以处理不确定性，且不依赖真实标签。实验结果显示，该方法在定性和定量评估中均优于现有基线，证明了其在提高效率和性能方面的有效性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.10069v1",
      "published_date": "2024-03-15 07:19:15 UTC",
      "updated_date": "2024-03-15 07:19:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T16:01:58.053904"
    },
    {
      "arxiv_id": "2403.10063v2",
      "title": "Unified Projection-Free Algorithms for Adversarial DR-Submodular Optimization",
      "title_zh": "翻译失败",
      "authors": [
        "Mohammad Pedramfar",
        "Yididiya Y. Nadew",
        "Christopher J. Quinn",
        "Vaneet Aggarwal"
      ],
      "abstract": "This paper introduces unified projection-free Frank-Wolfe type algorithms for\nadversarial continuous DR-submodular optimization, spanning scenarios such as\nfull information and (semi-)bandit feedback, monotone and non-monotone\nfunctions, different constraints, and types of stochastic queries. For every\nproblem considered in the non-monotone setting, the proposed algorithms are\neither the first with proven sub-linear $\\alpha$-regret bounds or have better\n$\\alpha$-regret bounds than the state of the art, where $\\alpha$ is a\ncorresponding approximation bound in the offline setting. In the monotone\nsetting, the proposed approach gives state-of-the-art sub-linear\n$\\alpha$-regret bounds among projection-free algorithms in 7 of the 8\nconsidered cases while matching the result of the remaining case. Additionally,\nthis paper addresses semi-bandit and bandit feedback for adversarial\nDR-submodular optimization, advancing the understanding of this optimization\narea.",
      "tldr_zh": "本论文提出了一种统一的投影免 Frank-Wolfe 类型算法，用于处理对抗性连续 DR-submodular 优化问题，涵盖全信息、(半-)bandit 反馈、单调和非单调函数、不同约束以及随机查询场景。针对非单调设置，该算法要么首次证明了次线性 α-regret 界，要么优于现有状态艺术，其中 α 为离线设置的近似界。在单调设置中，该方法在 8 个案例中提供了 7 个状态艺术的次线性 α-regret 界，并匹配了剩余一个案例的结果。此外，论文扩展了半-bandit 和 bandit 反馈的应用，进一步深化了对 DR-submodular 优化领域的理解。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CC",
        "math.OC"
      ],
      "primary_category": "cs.LG",
      "comment": "This paper is published in ICLR 2024. This version includes a\n  correction for regret bounds in the full-information zeroth order feedback\n  setting (see the footnote on page 1 for details)",
      "pdf_url": "http://arxiv.org/pdf/2403.10063v2",
      "published_date": "2024-03-15 07:05:44 UTC",
      "updated_date": "2024-04-26 21:05:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T16:02:11.776761"
    },
    {
      "arxiv_id": "2403.12094v2",
      "title": "Are LLMs Good Cryptic Crossword Solvers?",
      "title_zh": "翻译失败",
      "authors": [
        "Abdelrahman Sadallah",
        "Daria Kotova",
        "Ekaterina Kochmar"
      ],
      "abstract": "Cryptic crosswords are puzzles that rely not only on general knowledge but\nalso on the solver's ability to manipulate language on different levels and\ndeal with various types of wordplay. Previous research suggests that solving\nsuch puzzles is a challenge even for modern NLP models. However, the abilities\nof large language models (LLMs) have not yet been tested on this task. In this\npaper, we establish the benchmark results for three popular LLMs -- LLaMA2,\nMistral, and ChatGPT -- showing that their performance on this task is still\nfar from that of humans.",
      "tldr_zh": "这篇论文探讨了大型语言模型（LLMs）在解答 cryptic crosswords（一种依赖一般知识和语言操纵的填字游戏）方面的能力。研究者测试了 LLaMA2、Mistral 和 ChatGPT 等三个流行模型，并与人类表现进行比较。结果显示，这些 LLMs 的性能远低于人类，突显了当前模型在处理复杂文字游戏时的局限性，从而为未来 NLP 模型改进建立了基准。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.12094v2",
      "published_date": "2024-03-15 06:57:08 UTC",
      "updated_date": "2025-01-13 11:46:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T16:02:24.350699"
    },
    {
      "arxiv_id": "2403.10056v1",
      "title": "Don't Half-listen: Capturing Key-part Information in Continual Instruction Tuning",
      "title_zh": "翻译失败",
      "authors": [
        "Yongquan He",
        "Xuancheng Huang",
        "Minghao Tang",
        "Lingxun Meng",
        "Xiang Li",
        "Wei Lin",
        "Wenyuan Zhang",
        "Yifu Gao"
      ],
      "abstract": "Instruction tuning for large language models (LLMs) can drive them to produce\nresults consistent with human goals in specific downstream tasks. However, the\nprocess of continual instruction tuning (CIT) for LLMs may bring about the\ncatastrophic forgetting (CF) problem, where previously learned abilities are\ndegraded. Recent methods try to alleviate the CF problem by modifying models or\nreplaying data, which may only remember the surface-level pattern of\ninstructions and get confused on held-out tasks. In this paper, we propose a\nnovel continual instruction tuning method based on Key-part Information Gain\n(KPIG). Our method computes the information gain on masked parts to dynamically\nreplay data and refine the training objective, which enables LLMs to capture\ntask-aware information relevant to the correct response and alleviate\noverfitting to general descriptions in instructions. In addition, we propose\ntwo metrics, P-score and V-score, to measure the generalization and\ninstruction-following abilities of LLMs. Experiments demonstrate our method\nachieves superior performance on both seen and held-out tasks.",
      "tldr_zh": "这篇论文针对大型语言模型在持续指令微调（continual instruction tuning, CIT）过程中可能导致的灾难性遗忘（catastrophic forgetting, CF）问题，提出了一种基于 Key-part Information Gain (KPIG) 的新方法。KPIG 通过计算 masked parts 的信息增益来动态重放数据并优化训练目标，帮助模型捕捉任务相关信息，避免过度拟合指令表层模式。论文还引入了 P-score 和 V-score 两个指标，用于评估模型的泛化和指令遵循能力。实验结果表明，该方法在已见和未见任务上均表现出色，显著提升了模型性能。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "18 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2403.10056v1",
      "published_date": "2024-03-15 06:54:20 UTC",
      "updated_date": "2024-03-15 06:54:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T16:02:38.497753"
    },
    {
      "arxiv_id": "2403.10049v1",
      "title": "PPM : A Pre-trained Plug-in Model for Click-through Rate Prediction",
      "title_zh": "翻译失败",
      "authors": [
        "Yuanbo Gao",
        "Peng Lin",
        "Dongyue Wang",
        "Feng Mei",
        "Xiwei Zhao",
        "Sulong Xu",
        "Jinghe Hu"
      ],
      "abstract": "Click-through rate (CTR) prediction is a core task in recommender systems.\nExisting methods (IDRec for short) rely on unique identities to represent\ndistinct users and items that have prevailed for decades. On one hand, IDRec\noften faces significant performance degradation on cold-start problem; on the\nother hand, IDRec cannot use longer training data due to constraints imposed by\niteration efficiency. Most prior studies alleviate the above problems by\nintroducing pre-trained knowledge(e.g. pre-trained user model or multi-modal\nembeddings). However, the explosive growth of online latency can be attributed\nto the huge parameters in the pre-trained model. Therefore, most of them cannot\nemploy the unified model of end-to-end training with IDRec in industrial\nrecommender systems, thus limiting the potential of the pre-trained model. To\nthis end, we propose a $\\textbf{P}$re-trained $\\textbf{P}$lug-in CTR\n$\\textbf{M}$odel, namely PPM. PPM employs multi-modal features as input and\nutilizes large-scale data for pre-training. Then, PPM is plugged in IDRec model\nto enhance unified model's performance and iteration efficiency. Upon\nincorporating IDRec model, certain intermediate results within the network are\ncached, with only a subset of the parameters participating in training and\nserving. Hence, our approach can successfully deploy an end-to-end model\nwithout causing huge latency increases. Comprehensive offline experiments and\nonline A/B testing at JD E-commerce demonstrate the efficiency and\neffectiveness of PPM.",
      "tldr_zh": "这篇论文针对点击-through Rate (CTR) 预测中的冷启动问题和训练数据限制，提出了一种预-trained Plug-in Model (PPM)。PPM 利用多模态特征作为输入，通过大规模数据进行预训练，然后插入到现有的 IDRec 模型中，仅缓存部分中间结果和参数参与训练和服务，从而提升统一模型的性能和迭代效率。实验结果显示，PPM 在 JD 电商平台的离线实验和在线 A/B 测试中显著提高了准确率和效率，避免了预训练模型带来的延迟增加。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "Accepted by ACM Web Conference 2024 (WWW'24)",
      "pdf_url": "http://arxiv.org/pdf/2403.10049v1",
      "published_date": "2024-03-15 06:42:23 UTC",
      "updated_date": "2024-03-15 06:42:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T16:02:50.521872"
    },
    {
      "arxiv_id": "2403.10041v2",
      "title": "Towards Embedding Dynamic Personas in Interactive Robots: Masquerading Animated Social Kinematics (MASK)",
      "title_zh": "翻译失败",
      "authors": [
        "Jeongeun Park",
        "Taemoon Jeong",
        "Hyeonseong Kim",
        "Taehyun Byun",
        "Seungyoon Shin",
        "Keunjun Choi",
        "Jaewoon Kwon",
        "Taeyoon Lee",
        "Matthew Pan",
        "Sungjoon Choi"
      ],
      "abstract": "This paper presents the design and development of an innovative interactive\nrobotic system to enhance audience engagement using character-like personas.\nBuilt upon the foundations of persona-driven dialog agents, this work extends\nthe agent's application to the physical realm, employing robots to provide a\nmore captivating and interactive experience. The proposed system, named the\nMasquerading Animated Social Kinematic (MASK), leverages an anthropomorphic\nrobot which interacts with guests using non-verbal interactions, including\nfacial expressions and gestures. A behavior generation system based upon a\nfinite-state machine structure effectively conditions robotic behavior to\nconvey distinct personas. The MASK framework integrates a perception engine, a\nbehavior selection engine, and a comprehensive action library to enable\nreal-time, dynamic interactions with minimal human intervention in behavior\ndesign. Throughout the user subject studies, we examined whether the users\ncould recognize the intended character in both personality- and\nfilm-character-based persona conditions. We conclude by discussing the role of\npersonas in interactive agents and the factors to consider for creating an\nengaging user experience.",
      "tldr_zh": "本研究提出了一种名为 MASK（Masquerading Animated Social Kinematics）的创新交互机器人系统，旨在通过动态角色个性增强观众参与，将角色驱动对话代理扩展到物理机器人领域。系统利用拟人机器人进行非语言互动，如面部表情和手势，并采用基于有限状态机（finite-state machine）的行为生成系统来传达不同的角色。MASK 框架整合了感知引擎、行为选择引擎和动作库，实现实时动态互动，并减少人为干预。用户研究显示，用户能够有效识别基于个性和电影角色的预设角色，最终讨论了角色在交互代理中的作用以及提升用户体验的关键因素。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "Accepted at Robotics and Automation Letters",
      "pdf_url": "http://arxiv.org/pdf/2403.10041v2",
      "published_date": "2024-03-15 06:22:32 UTC",
      "updated_date": "2024-10-07 14:33:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T16:03:01.267850"
    },
    {
      "arxiv_id": "2403.10039v2",
      "title": "Motion-Boundary-Driven Unsupervised Surgical Instrument Segmentation in Low-Quality Optical Flow",
      "title_zh": "翻译失败",
      "authors": [
        "Yang Liu",
        "Peiran Wu",
        "Jiayu Huo",
        "Gongyu Zhang",
        "Zhen Yuan",
        "Christos Bergeles",
        "Rachel Sparks",
        "Prokar Dasgupta",
        "Alejandro Granados",
        "Sebastien Ourselin"
      ],
      "abstract": "Unsupervised video-based surgical instrument segmentation has the potential\nto accelerate the adoption of robot-assisted procedures by reducing the\nreliance on manual annotations. However, the generally low quality of optical\nflow in endoscopic footage poses a great challenge for unsupervised methods\nthat rely heavily on motion cues. To overcome this limitation, we propose a\nnovel approach that pinpoints motion boundaries, regions with abrupt flow\nchanges, while selectively discarding frames with globally low-quality flow and\nadapting to varying motion patterns. Experiments on the EndoVis2017 VOS and\nEndoVis2017 Challenge datasets show that our method achieves mean\nIntersection-over-Union (mIoU) scores of 0.75 and 0.72, respectively,\neffectively alleviating the constraints imposed by suboptimal optical flow.\nThis enables a more scalable and robust surgical instrument segmentation\nsolution in clinical settings. The code will be publicly released.",
      "tldr_zh": "本研究提出了一种基于运动边界（motion boundaries）的无监督手术器械分割方法，针对内窥镜视频中光流（optical flow）质量低的问题，通过识别光流突变区域、选择性地丢弃全局低质量帧，并适应不同运动模式来提升分割准确性。实验在 EndoVis2017 VOS 和 EndoVis2017 Challenge 数据集上分别取得了 0.75 和 0.72 的 mean Intersection-over-Union (mIoU) 分数，显著改善了传统方法的性能。总体而言，该方法缓解了次优光流带来的挑战，提供了一个更具可扩展性和鲁棒性的临床手术辅助解决方案，并计划公开代码。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.10039v2",
      "published_date": "2024-03-15 06:19:02 UTC",
      "updated_date": "2025-03-25 20:18:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T16:03:15.048876"
    },
    {
      "arxiv_id": "2403.10024v1",
      "title": "MR-MT3: Memory Retaining Multi-Track Music Transcription to Mitigate Instrument Leakage",
      "title_zh": "翻译失败",
      "authors": [
        "Hao Hao Tan",
        "Kin Wai Cheuk",
        "Taemin Cho",
        "Wei-Hsiang Liao",
        "Yuki Mitsufuji"
      ],
      "abstract": "This paper presents enhancements to the MT3 model, a state-of-the-art (SOTA)\ntoken-based multi-instrument automatic music transcription (AMT) model. Despite\nSOTA performance, MT3 has the issue of instrument leakage, where transcriptions\nare fragmented across different instruments. To mitigate this, we propose\nMR-MT3, with enhancements including a memory retention mechanism, prior token\nsampling, and token shuffling are proposed. These methods are evaluated on the\nSlakh2100 dataset, demonstrating improved onset F1 scores and reduced\ninstrument leakage. In addition to the conventional multi-instrument\ntranscription F1 score, new metrics such as the instrument leakage ratio and\nthe instrument detection F1 score are introduced for a more comprehensive\nassessment of transcription quality. The study also explores the issue of\ndomain overfitting by evaluating MT3 on single-instrument monophonic datasets\nsuch as ComMU and NSynth. The findings, along with the source code, are shared\nto facilitate future work aimed at refining token-based multi-instrument AMT\nmodels.",
      "tldr_zh": "本论文针对先进的 token-based 多乐器自动音乐转录 (AMT) 模型 MT3 的乐器泄漏问题，提出增强版 MR-MT3，通过引入记忆保留机制 (memory retention mechanism)、优先 token 采样 (prior token sampling) 和 token 混洗 (token shuffling) 等方法来减少转录碎片化。实验在 Slakh2100 数据集上进行，显示 MR-MT3 显著提高了 onset F1 scores 并降低了 instrument leakage。论文还引入了新的评估指标，如 instrument leakage ratio 和 instrument detection F1 score，并评估了 MT3 在单乐器数据集 (如 ComMU 和 NSynth) 上的表现，以探讨领域过拟合问题，并分享源代码以促进未来研究。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.LG",
        "cs.MM",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.10024v1",
      "published_date": "2024-03-15 05:13:38 UTC",
      "updated_date": "2024-03-15 05:13:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T16:03:27.755744"
    },
    {
      "arxiv_id": "2403.10575v1",
      "title": "Exploring Language Model's Code Generation Ability with Auxiliary Functions",
      "title_zh": "使用辅助函数探索语言模型的代码生成能力",
      "authors": [
        "Seonghyeon Lee",
        "Sanghwan Jang",
        "Seongbo Jang",
        "Dongha Lee",
        "Hwanjo Yu"
      ],
      "abstract": "Auxiliary function is a helpful component to improve language model's code\ngeneration ability. However, a systematic exploration of how they affect has\nyet to be done. In this work, we comprehensively evaluate the ability to\nutilize auxiliary functions encoded in recent code-pretrained language models.\nFirst, we construct a human-crafted evaluation set, called HumanExtension,\nwhich contains examples of two functions where one function assists the other.\nWith HumanExtension, we design several experiments to examine their ability in\na multifaceted way. Our evaluation processes enable a comprehensive\nunderstanding of including auxiliary functions in the prompt in terms of\neffectiveness and robustness. An additional implementation style analysis\ncaptures the models' various implementation patterns when they access the\nauxiliary function. Through this analysis, we discover the models' promising\nability to utilize auxiliary functions including their self-improving behavior\nby implementing the two functions step-by-step. However, our analysis also\nreveals the model's underutilized behavior to call the auxiliary function,\nsuggesting the future direction to enhance their implementation by eliciting\nthe auxiliary function call ability encoded in the models. We release our code\nand dataset to facilitate this research direction.",
      "tldr_zh": "这篇论文系统评估了代码预训练语言模型（code-pretrained language models）利用 auxiliary functions 来提升代码生成能力的影响。研究者构建了 HumanExtension 评估集，该集包含一个函数辅助另一个函数的示例，并通过多方面实验考察了在提示中包含辅助函数的有效性、鲁棒性和实现模式。分析结果显示，模型展现出逐步实现函数的自提升行为（self-improving behavior），但也暴露了在调用 auxiliary functions 时未充分利用的问题，并建议未来通过增强函数调用能力来改进。论文发布了代码和数据集，以促进相关研究。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.SE",
      "comment": "NAACL2024 Findings",
      "pdf_url": "http://arxiv.org/pdf/2403.10575v1",
      "published_date": "2024-03-15 04:41:50 UTC",
      "updated_date": "2024-03-15 04:41:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T16:03:38.604828"
    },
    {
      "arxiv_id": "2403.10014v1",
      "title": "NNCTC: Physical Layer Cross-Technology Communication via Neural Networks",
      "title_zh": "NNCTC: 基于神经网络的物理层跨技术通信",
      "authors": [
        "Haoyu Wang",
        "Jiazhao Wang",
        "Demin Gao",
        "Wenchao Jiang"
      ],
      "abstract": "Cross-technology communication(CTC) enables seamless interactions between\ndiverse wireless technologies. Most existing work is based on reversing the\ntransmission path to identify the appropriate payload to generate the waveform\nthat the target devices can recognize. However, this method suffers from many\nlimitations, including dependency on specific technologies and the necessity\nfor intricate algorithms to mitigate distortion. In this work, we present\nNNCTC, a Neural-Network-based Cross-Technology Communication framework inspired\nby the adaptability of trainable neural models in wireless communications. By\nconverting signal processing components within the CTC pipeline into neural\nmodels, the NNCTC is designed for end-to-end training without requiring labeled\ndata. This enables the NNCTC system to autonomously derive the optimal CTC\npayload, which significantly eases the development complexity and showcases the\nscalability potential for various CTC links. Particularly, we construct a CTC\nsystem from Wi-Fi to ZigBee. The NNCTC system outperforms the well-recognized\nWEBee and WIDE design in error performance, achieving an average packet\nreception rate(PRR) of 92.3% and an average symbol error rate(SER) as low as\n1.3%.",
      "tldr_zh": "该研究提出NNCTC，一种基于Neural Networks的Physical Layer Cross-Technology Communication框架，以解决现有CTC方法依赖特定技术和处理失真的复杂性问题。通过将CTC管道中的信号处理组件转化为神经模型，NNCTC实现端到端训练，无需标记数据，从而自主优化CTC负载并提升系统可扩展性。实验结果显示，在Wi-Fi到ZigBee的CTC系统中，NNCTC优于WEBee和WIDE设计，平均包接收率(PRR)达到92.3%，平均符号错误率(SER)低至1.3%。",
      "categories": [
        "cs.NI",
        "cs.AI",
        "C.2.2"
      ],
      "primary_category": "cs.NI",
      "comment": "12 pages",
      "pdf_url": "http://arxiv.org/pdf/2403.10014v1",
      "published_date": "2024-03-15 04:36:44 UTC",
      "updated_date": "2024-03-15 04:36:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T16:03:49.380707"
    },
    {
      "arxiv_id": "2403.14691v2",
      "title": "Large Language Models and User Trust: Consequence of Self-Referential Learning Loop and the Deskilling of Healthcare Professionals",
      "title_zh": "翻译失败",
      "authors": [
        "Avishek Choudhury",
        "Zaria Chaudhry"
      ],
      "abstract": "This paper explores the evolving relationship between clinician trust in\nLLMs, the transformation of data sources from predominantly human-generated to\nAI-generated content, and the subsequent impact on the precision of LLMs and\nclinician competence. One of the primary concerns identified is the potential\nfeedback loop that arises as LLMs become more reliant on their outputs for\nlearning, which may lead to a degradation in output quality and a reduction in\nclinician skills due to decreased engagement with fundamental diagnostic\nprocesses. While theoretical at this stage, this feedback loop poses a\nsignificant challenge as the integration of LLMs in healthcare deepens,\nemphasizing the need for proactive dialogue and strategic measures to ensure\nthe safe and effective use of LLM technology. A key takeaway from our\ninvestigation is the critical role of user expertise and the necessity for a\ndiscerning approach to trusting and validating LLM outputs. The paper\nhighlights how expert users, particularly clinicians, can leverage LLMs to\nenhance productivity by offloading routine tasks while maintaining a critical\noversight to identify and correct potential inaccuracies in AI-generated\ncontent. This balance of trust and skepticism is vital for ensuring that LLMs\naugment rather than undermine the quality of patient care. Moreover, we delve\ninto the potential risks associated with LLMs' self-referential learning loops\nand the deskilling of healthcare professionals. The risk of LLMs operating\nwithin an echo chamber, where AI-generated content feeds into the learning\nalgorithms, threatens the diversity and quality of the data pool, potentially\nentrenching biases and reducing the efficacy of LLMs.",
      "tldr_zh": "这篇论文探讨了大型语言模型（LLMs）和用户信任之间的关系，特别是自指学习循环（self-referential learning loop）导致的数据来源从人类生成转向AI生成，可能造成LLMs输出质量下降和医疗专业人员的技能退化（deskilling）。研究强调，这种反馈循环会减少临床医生对基本诊断过程的参与，并提出潜在风险，如强化偏差和数据池质量降低。论文建议通过专家用户保持批判性监督和平衡使用LLMs，来提升生产力和患者护理质量，同时呼吁主动对话和战略措施确保AI在医疗领域的安全整合。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "1 figure",
      "pdf_url": "http://arxiv.org/pdf/2403.14691v2",
      "published_date": "2024-03-15 04:04:45 UTC",
      "updated_date": "2024-04-01 05:03:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T16:04:01.813090"
    },
    {
      "arxiv_id": "2403.13840v1",
      "title": "Whose Side Are You On? Investigating the Political Stance of Large Language Models",
      "title_zh": "你站在哪一边？ 调查大型语言模型的政治立场",
      "authors": [
        "Pagnarasmey Pit",
        "Xingjun Ma",
        "Mike Conway",
        "Qingyu Chen",
        "James Bailey",
        "Henry Pit",
        "Putrasmey Keo",
        "Watey Diep",
        "Yu-Gang Jiang"
      ],
      "abstract": "Large Language Models (LLMs) have gained significant popularity for their\napplication in various everyday tasks such as text generation, summarization,\nand information retrieval. As the widespread adoption of LLMs continues to\nsurge, it becomes increasingly crucial to ensure that these models yield\nresponses that are politically impartial, with the aim of preventing\ninformation bubbles, upholding fairness in representation, and mitigating\nconfirmation bias. In this paper, we propose a quantitative framework and\npipeline designed to systematically investigate the political orientation of\nLLMs. Our investigation delves into the political alignment of LLMs across a\nspectrum of eight polarizing topics, spanning from abortion to LGBTQ issues.\nAcross topics, the results indicate that LLMs exhibit a tendency to provide\nresponses that closely align with liberal or left-leaning perspectives rather\nthan conservative or right-leaning ones when user queries include details\npertaining to occupation, race, or political affiliation. The findings\npresented in this study not only reaffirm earlier observations regarding the\nleft-leaning characteristics of LLMs but also surface particular attributes,\nsuch as occupation, that are particularly susceptible to such inclinations even\nwhen directly steered towards conservatism. As a recommendation to avoid these\nmodels providing politicised responses, users should be mindful when crafting\nqueries, and exercise caution in selecting neutral prompt language.",
      "tldr_zh": "本研究调查了大型语言模型 (LLMs) 的政治倾向，提出一个定量框架和管道来评估模型在八个极化话题（如堕胎和 LGBTQ 问题）上的回应偏见。研究发现，当用户查询涉及职业、种族或政治 affiliation 时，LLMs 更倾向于提供自由派或左倾视角的回答，而不是保守派或右倾视角，从而确认了这些模型的左倾特性。作者还指出，特定属性如职业特别容易放大这种偏见，并推荐用户使用中性提示语言，以避免模型生成政治化回应。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.SI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.13840v1",
      "published_date": "2024-03-15 04:02:24 UTC",
      "updated_date": "2024-03-15 04:02:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T16:04:12.756165"
    },
    {
      "arxiv_id": "2403.09998v2",
      "title": "FBPT: A Fully Binary Point Transformer",
      "title_zh": "FBPT：完全二进制的点云 Transformer",
      "authors": [
        "Zhixing Hou",
        "Yuzhang Shang",
        "Yan Yan"
      ],
      "abstract": "This paper presents a novel Fully Binary Point Cloud Transformer (FBPT) model\nwhich has the potential to be widely applied and expanded in the fields of\nrobotics and mobile devices. By compressing the weights and activations of a\n32-bit full-precision network to 1-bit binary values, the proposed binary point\ncloud Transformer network significantly reduces the storage footprint and\ncomputational resource requirements of neural network models for point cloud\nprocessing tasks, compared to full-precision point cloud networks. However,\nachieving a fully binary point cloud Transformer network, where all parts\nexcept the modules specific to the task are binary, poses challenges and\nbottlenecks in quantizing the activations of Q, K, V and self-attention in the\nattention module, as they do not adhere to simple probability distributions and\ncan vary with input data. Furthermore, in our network, the binary attention\nmodule undergoes a degradation of the self-attention module due to the uniform\ndistribution that occurs after the softmax operation. The primary focus of this\npaper is on addressing the performance degradation issue caused by the use of\nbinary point cloud Transformer modules. We propose a novel binarization\nmechanism called dynamic-static hybridization. Specifically, our approach\ncombines static binarization of the overall network model with fine granularity\ndynamic binarization of data-sensitive components. Furthermore, we make use of\na novel hierarchical training scheme to obtain the optimal model and\nbinarization parameters. These above improvements allow the proposed\nbinarization method to outperform binarization methods applied to convolution\nneural networks when used in point cloud Transformer structures. To demonstrate\nthe superiority of our algorithm, we conducted experiments on two different\ntasks: point cloud classification and place recognition.",
      "tldr_zh": "本论文提出了一种全二值化点云 Transformer 模型 FBPT，通过将权重和激活从 32 位全精度压缩到 1 位二值，显著降低点云处理任务的存储和计算资源需求，适用于机器人和移动设备领域。针对量化 Q, K, V 和 self-attention 模块的挑战，该模型引入动态-静态混合二值化机制，将网络的静态二值化与数据敏感组件的细粒度动态二值化相结合，并采用分层训练方案优化模型参数，以缓解二值化导致的性能下降问题。实验结果显示，该方法在点云分类和位置识别任务上优于应用于卷积神经网络的二值化方法，证明了其有效性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted to ICRA 2024. arXiv admin note: substantial text overlap\n  with arXiv:2303.01166",
      "pdf_url": "http://arxiv.org/pdf/2403.09998v2",
      "published_date": "2024-03-15 03:45:10 UTC",
      "updated_date": "2024-05-09 06:35:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T16:04:28.023152"
    },
    {
      "arxiv_id": "2403.09977v1",
      "title": "EfficientVMamba: Atrous Selective Scan for Light Weight Visual Mamba",
      "title_zh": "翻译失败",
      "authors": [
        "Xiaohuan Pei",
        "Tao Huang",
        "Chang Xu"
      ],
      "abstract": "Prior efforts in light-weight model development mainly centered on CNN and\nTransformer-based designs yet faced persistent challenges. CNNs adept at local\nfeature extraction compromise resolution while Transformers offer global reach\nbut escalate computational demands $\\mathcal{O}(N^2)$. This ongoing trade-off\nbetween accuracy and efficiency remains a significant hurdle. Recently, state\nspace models (SSMs), such as Mamba, have shown outstanding performance and\ncompetitiveness in various tasks such as language modeling and computer vision,\nwhile reducing the time complexity of global information extraction to\n$\\mathcal{O}(N)$. Inspired by this, this work proposes to explore the potential\nof visual state space models in light-weight model design and introduce a novel\nefficient model variant dubbed EfficientVMamba. Concretely, our EfficientVMamba\nintegrates a atrous-based selective scan approach by efficient skip sampling,\nconstituting building blocks designed to harness both global and local\nrepresentational features. Additionally, we investigate the integration between\nSSM blocks and convolutions, and introduce an efficient visual state space\nblock combined with an additional convolution branch, which further elevate the\nmodel performance. Experimental results show that, EfficientVMamba scales down\nthe computational complexity while yields competitive results across a variety\nof vision tasks. For example, our EfficientVMamba-S with $1.3$G FLOPs improves\nVim-Ti with $1.5$G FLOPs by a large margin of $5.6\\%$ accuracy on ImageNet.\nCode is available at: \\url{https://github.com/TerryPei/EfficientVMamba}.",
      "tldr_zh": "本文针对轻量视觉模型开发中的效率与准确性权衡问题，提出EfficientVMamba，一种基于状态空间模型(SSMs)如Mamba的创新框架。该框架整合了atrous selective scan和efficient skip sampling技术，以高效捕获全局和局部特征，并通过结合SSM块与卷积分支进一步提升模型性能。实验结果表明，EfficientVMamba显著降低了计算复杂度，例如EfficientVMamba-S以1.3G FLOPs的FLOPs比Vim-Ti（1.5G FLOPs）在ImageNet上提高了5.6%的准确率，并在多种视觉任务中表现出色。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.09977v1",
      "published_date": "2024-03-15 02:48:47 UTC",
      "updated_date": "2024-03-15 02:48:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T16:04:39.881916"
    },
    {
      "arxiv_id": "2403.09974v3",
      "title": "GET: Unlocking the Multi-modal Potential of CLIP for Generalized Category Discovery",
      "title_zh": "GET：解锁 CLIP 的多模态潜力，用于广义类别发现",
      "authors": [
        "Enguang Wang",
        "Zhimao Peng",
        "Zhengyuan Xie",
        "Fei Yang",
        "Xialei Liu",
        "Ming-Ming Cheng"
      ],
      "abstract": "Given unlabelled datasets containing both old and new categories, generalized\ncategory discovery (GCD) aims to accurately discover new classes while\ncorrectly classifying old classes. Current GCD methods only use a single visual\nmodality of information, resulting in a poor classification of visually similar\nclasses. As a different modality, text information can provide complementary\ndiscriminative information, which motivates us to introduce it into the GCD\ntask. However, the lack of class names for unlabelled data makes it impractical\nto utilize text information. To tackle this challenging problem, in this paper,\nwe propose a Text Embedding Synthesizer (TES) to generate pseudo text\nembeddings for unlabelled samples. Specifically, our TES leverages the property\nthat CLIP can generate aligned vision-language features, converting visual\nembeddings into tokens of the CLIP's text encoder to generate pseudo text\nembeddings. Besides, we employ a dual-branch framework, through the joint\nlearning and instance consistency of different modality branches, visual and\nsemantic information mutually enhance each other, promoting the interaction and\nfusion of visual and text knowledge. Our method unlocks the multi-modal\npotentials of CLIP and outperforms the baseline methods by a large margin on\nall GCD benchmarks, achieving new state-of-the-art. Our code is available at:\nhttps://github.com/enguangW/GET.",
      "tldr_zh": "本论文针对广义类别发现（Generalized Category Discovery, GCD）任务，提出了一种GET方法，以解决现有方法仅依赖单一视觉模态导致视觉相似类别分类不准的问题。GET引入文本信息作为补充，通过Text Embedding Synthesizer (TES)利用CLIP的视觉-语言对齐特性，为未标记样本生成伪文本嵌入，并采用双分支框架促进视觉和语义信息的相互增强，实现模态知识的交互与融合。该方法大幅提升了CLIP的多模态潜力，在所有GCD基准测试中超越基线模型，达到新的state-of-the-art性能，并提供了开源代码以供进一步应用。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "CVPR 2025",
      "pdf_url": "http://arxiv.org/pdf/2403.09974v3",
      "published_date": "2024-03-15 02:40:13 UTC",
      "updated_date": "2025-03-21 01:50:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T16:04:50.451590"
    },
    {
      "arxiv_id": "2405.15772v1",
      "title": "Scenario Engineering for Autonomous Transportation: A New Stage in Open-Pit Mines",
      "title_zh": "翻译失败",
      "authors": [
        "Siyu Teng",
        "Xuan Li",
        "Yucheng Li",
        "Zhe Xuanyuan",
        "Yunfeng Ai",
        "Long Chen"
      ],
      "abstract": "In recent years, open-pit mining has seen significant advancement, the\ncooperative operation of various specialized machinery substantially enhancing\nthe efficiency of mineral extraction. However, the harsh environment and\ncomplex conditions in open-pit mines present substantial challenges for the\nimplementation of autonomous transportation systems. This research introduces a\nnovel paradigm that integrates Scenario Engineering (SE) with autonomous\ntransportation systems to significantly improve the trustworthiness,\nrobustness, and efficiency in open-pit mines by incorporating the four key\ncomponents of SE, including Scenario Feature Extractor, Intelligence and Index\n(I&I), Calibration and Certification (C&C), and Verification and Validation\n(V&V). This paradigm has been validated in two famous open-pit mines, the\nexperiment results demonstrate marked improvements in robustness,\ntrustworthiness, and efficiency. By enhancing the capacity, scalability, and\ndiversity of autonomous transportation, this paradigm fosters the integration\nof SE and parallel driving and finally propels the achievement of the '6S'\nobjectives.",
      "tldr_zh": "这篇论文提出了一种将 Scenario Engineering (SE) 整合到露天矿自主运输系统的创新范式，以应对恶劣环境和复杂条件带来的挑战。SE 包括四个关键组件：Scenario Feature Extractor、Intelligence and Index (I&I)、Calibration and Certification (C&C) 以及 Verification and Validation (V&V)，旨在提升系统的可信度、鲁棒性和效率。该范式已在两个著名露天矿中进行实验验证，结果显示显著改善了自主运输的容量、可扩展性和多样性，并促进了 SE 与平行驾驶的整合，最终推动 '6S' 目标的实现。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "11 Pages, 7 Figures",
      "pdf_url": "http://arxiv.org/pdf/2405.15772v1",
      "published_date": "2024-03-15 02:36:27 UTC",
      "updated_date": "2024-03-15 02:36:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T16:05:02.949599"
    },
    {
      "arxiv_id": "2403.15433v1",
      "title": "HyPer-EP: Meta-Learning Hybrid Personalized Models for Cardiac Electrophysiology",
      "title_zh": "翻译失败",
      "authors": [
        "Xiajun Jiang",
        "Sumeet Vadhavkar",
        "Yubo Ye",
        "Maryam Toloubidokhti",
        "Ryan Missel",
        "Linwei Wang"
      ],
      "abstract": "Personalized virtual heart models have demonstrated increasing potential for\nclinical use, although the estimation of their parameters given\npatient-specific data remain a challenge. Traditional physics-based modeling\napproaches are computationally costly and often neglect the inherent structural\nerrors in these models due to model simplifications and assumptions. Modern\ndeep learning approaches, on the other hand, rely heavily on data supervision\nand lacks interpretability. In this paper, we present a novel hybrid modeling\nframework to describe a personalized cardiac digital twin as a combination of a\nphysics-based known expression augmented by neural network modeling of its\nunknown gap to reality. We then present a novel meta-learning framework to\nenable the separate identification of both the physics-based and neural\ncomponents in the hybrid model. We demonstrate the feasibility and generality\nof this hybrid modeling framework with two examples of instantiations and their\nproof-of-concept in synthetic experiments.",
      "tldr_zh": "该论文针对个性化虚拟心脏模型的参数估计挑战，提出了一种HyPer-EP混合建模框架，将physics-based modeling与neural network结合，前者处理已知物理表达式，后者补偿模型与现实的未知差距，以提升模型的准确性和可解释性。论文进一步引入meta-learning框架，用于分离识别混合模型中的physics-based和neural组件，从而实现更有效的个性化心脏数字孪生。实验通过两个实例和合成实验验证了该框架的可行性和通用性。",
      "categories": [
        "eess.SP",
        "cs.AI",
        "cs.LG",
        "eess.IV"
      ],
      "primary_category": "eess.SP",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.15433v1",
      "published_date": "2024-03-15 02:30:00 UTC",
      "updated_date": "2024-03-15 02:30:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T16:05:12.996186"
    },
    {
      "arxiv_id": "2405.00690v1",
      "title": "Scenarios Engineering driven Autonomous Transportation in Open-Pit Mines",
      "title_zh": "基于场景工程驱动的露天矿自动运输",
      "authors": [
        "Siyu Teng",
        "Xuan Li",
        "Yuchen Li",
        "Lingxi Li",
        "Yunfeng Ai",
        "Long Chen"
      ],
      "abstract": "One critical bottleneck that impedes the development and deployment of\nautonomous transportation in open-pit mines is guaranteed robustness and\ntrustworthiness in prohibitively extreme scenarios. In this research, a novel\nscenarios engineering (SE) methodology for the autonomous mining truck is\nproposed for open-pit mines. SE increases the trustworthiness and robustness of\nautonomous trucks from four key components: Scenario Feature Extractor,\nIntelligence & Index (I&I), Calibration & Certification (C&C), and Verification\n& Validation (V&V). Scenario feature extractor is a comprehensive pipeline\napproach that captures complex interactions and latent dependencies in complex\nmining scenarios. I&I effectively enhances the quality of the training dataset,\nthereby establishing a solid foundation for autonomous transportation in mining\nareas. C&C is grounded in the intrinsic regulation, capabilities, and\ncontributions of the intelligent systems employed in autonomous transportation\nto align with traffic participants in the real world and ensure their\nperformance through certification. V&V process ensures that the autonomous\ntransportation system can be correctly implemented, while validation focuses on\nevaluating the ability of the well-trained model to operate efficiently in the\ncomplex and dynamic conditions of the open-pit mines. This methodology\naddresses the unique challenges of autonomous transportation in open-pit\nmining, promoting productivity, safety, and performance in mining operations.",
      "tldr_zh": "该研究针对露天矿自主运输在极端场景下的鲁棒性和可信度问题，提出了一种新型的 Scenarios Engineering (SE) 方法ology，用于提升采矿卡车的可靠性。SE 框架包括四个关键组件：Scenario Feature Extractor 用于捕捉复杂场景的交互和依赖、Intelligence & Index (I&I) 优化训练数据集质量、Calibration & Certification (C&C) 确保系统与现实世界对齐并进行认证，以及 Verification & Validation (V&V) 验证系统的正确实现和动态性能。该方法有效解决了露天矿的独特挑战，从而提高生产力、安全性和整体运营效率。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.00690v1",
      "published_date": "2024-03-15 02:26:55 UTC",
      "updated_date": "2024-03-15 02:26:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T16:05:27.077941"
    },
    {
      "arxiv_id": "2403.09963v2",
      "title": "Take Care of Your Prompt Bias! Investigating and Mitigating Prompt Bias in Factual Knowledge Extraction",
      "title_zh": "翻译失败",
      "authors": [
        "Ziyang Xu",
        "Keqin Peng",
        "Liang Ding",
        "Dacheng Tao",
        "Xiliang Lu"
      ],
      "abstract": "Recent research shows that pre-trained language models (PLMs) suffer from\n\"prompt bias\" in factual knowledge extraction, i.e., prompts tend to introduce\nbiases toward specific labels. Prompt bias presents a significant challenge in\nassessing the factual knowledge within PLMs. Therefore, this paper aims to\nimprove the reliability of existing benchmarks by thoroughly investigating and\nmitigating prompt bias. We show that: 1) all prompts in the experiments exhibit\nnon-negligible bias, with gradient-based prompts like AutoPrompt and OptiPrompt\ndisplaying significantly higher levels of bias; 2) prompt bias can amplify\nbenchmark accuracy unreasonably by overfitting the test datasets, especially on\nimbalanced datasets like LAMA. Based on these findings, we propose a\nrepresentation-based approach to mitigate the prompt bias during inference\ntime. Specifically, we first estimate the biased representation using\nprompt-only querying, and then remove it from the model's internal\nrepresentations to generate the debiased representations, which are used to\nproduce the final debiased outputs. Experiments across various prompts, PLMs,\nand benchmarks show that our approach can not only correct the overfitted\nperformance caused by prompt bias, but also significantly improve the prompt\nretrieval capability (up to 10% absolute performance gain). These results\nindicate that our approach effectively alleviates prompt bias in knowledge\nevaluation, thereby enhancing the reliability of benchmark assessments.\nHopefully, our plug-and-play approach can be a golden standard to strengthen\nPLMs toward reliable knowledge bases. Code and data are released in\nhttps://github.com/FelliYang/PromptBias.",
      "tldr_zh": "本研究调查了预训练语言模型 (PLMs) 在事实知识提取中存在的 \"prompt bias\" 问题，即提示词会引入偏向特定标签的偏差，导致基准测试准确率放大，尤其是 gradient-based prompts 如 AutoPrompt 和 OptiPrompt 偏差更严重。论文发现，这种偏差在不平衡数据集如 LAMA 上会造成过拟合。针对此，提出了一种基于表示的缓解方法：在推理时，通过 prompt-only 查询估计偏置表示，并从模型内部表示中移除它，以生成去偏表示并输出最终结果。实验结果显示，该方法不仅纠正了过拟合性能，还显著提升了提示检索能力（最高提升 10%），从而增强了知识评估的可靠性和 PLMs 作为知识库的可靠性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted by COLING 2024",
      "pdf_url": "http://arxiv.org/pdf/2403.09963v2",
      "published_date": "2024-03-15 02:04:35 UTC",
      "updated_date": "2024-03-26 04:08:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T16:05:38.928727"
    },
    {
      "arxiv_id": "2403.09948v2",
      "title": "RadCLIP: Enhancing Radiologic Image Analysis through Contrastive Language-Image Pre-training",
      "title_zh": "翻译失败",
      "authors": [
        "Zhixiu Lu",
        "Hailong Li",
        "Nehal A. Parikh",
        "Jonathan R. Dillman",
        "Lili He"
      ],
      "abstract": "The integration of artificial intelligence (AI) with radiology marks a\ntransformative era in medicine. Vision foundation models have been adopted to\nenhance radiologic imaging analysis. However, the distinct complexities of\nradiologic 2D and 3D radiologic data pose unique challenges that existing\nmodels, pre-trained on general non-medical images, fail to address adequately.\nTo bridge this gap and capitalize on the diagnostic precision required in\nradiologic imaging, we introduce Radiologic Contrastive Language-Image\nPre-training (RadCLIP): a cross-modal vision-language foundational model that\nharnesses Vision Language Pre-training (VLP) framework to improve radiologic\nimage analysis. Building upon Contrastive Language-Image Pre-training (CLIP),\nRadCLIP incorporates a slice pooling mechanism tailored for volumetric image\nanalysis and is pre-trained using a large and diverse dataset of radiologic\nimage-text pairs. The RadCLIP was pre-trained to effectively align radiologic\nimages with their corresponding text annotations, creating a robust vision\nbackbone for radiologic images. Extensive experiments demonstrate RadCLIP's\nsuperior performance in both uni-modal radiologic image classification and\ncross-modal image-text matching, highlighting its significant promise for\nimproving diagnostic accuracy and efficiency in clinical settings. Our Key\ncontributions include curating a large dataset with diverse radiologic 2D/3D\nradiologic image-text pairs, a slice pooling adapter using an attention\nmechanism for integrating 2D images, and comprehensive evaluations of RadCLIP\non various radiologic downstream tasks.",
      "tldr_zh": "该研究引入了 RadCLIP，一种基于 Contrastive Language-Image Pre-training (CLIP) 的视觉语言模型，旨在提升放射学图像分析的性能，以解决现有模型在处理放射学 2D 和 3D 数据时的局限性。RadCLIP 采用 slice pooling 机制和注意力机制，对大型放射学图像-文本数据集进行预训练，从而更好地对齐图像与文本注释。实验结果显示，RadCLIP 在单模态图像分类和跨模态图像-文本匹配任务上显著优于基线模型，提高了临床诊断的准确性和效率。关键贡献包括构建多样化数据集和全面评估下游任务的表现。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.09948v2",
      "published_date": "2024-03-15 01:18:08 UTC",
      "updated_date": "2024-09-05 18:13:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T16:05:51.262230"
    },
    {
      "arxiv_id": "2403.09940v2",
      "title": "Global Convergence Guarantees for Federated Policy Gradient Methods with Adversaries",
      "title_zh": "联邦策略梯度方法的全局收敛保证：存在对手的情况",
      "authors": [
        "Swetha Ganesh",
        "Jiayu Chen",
        "Gugan Thoppe",
        "Vaneet Aggarwal"
      ],
      "abstract": "Federated Reinforcement Learning (FRL) allows multiple agents to\ncollaboratively build a decision making policy without sharing raw\ntrajectories. However, if a small fraction of these agents are adversarial, it\ncan lead to catastrophic results. We propose a policy gradient based approach\nthat is robust to adversarial agents which can send arbitrary values to the\nserver. Under this setting, our results form the first global convergence\nguarantees with general parametrization. These results demonstrate resilience\nwith adversaries, while achieving optimal sample complexity of order\n$\\tilde{\\mathcal{O}}\\left( \\frac{1}{N\\epsilon^2} \\left( 1+\n\\frac{f^2}{N}\\right)\\right)$, where $N$ is the total number of agents and\n$f<N/2$ is the number of adversarial agents.",
      "tldr_zh": "本研究针对联邦强化学习(Federated Reinforcement Learning)中敌对代理的问题，提出了一种基于策略梯度(policy gradient)的方法，能够抵抗发送任意值的敌对代理。该方法提供了第一个全局收敛(global convergence)保证，支持一般参数化，确保算法在存在敌对代理时保持弹性。主要结果显示，该方法达到了最优样本复杂度$\\tilde{\\mathcal{O}}\\left( \\frac{1}{N\\epsilon^2} \\left( 1+ \\frac{f^2}{N}\\right)\\right)$，其中N是总代理数，f<N/2是敌对代理数。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "math.OC"
      ],
      "primary_category": "cs.LG",
      "comment": "25 pages, 14 figures and 1 table",
      "pdf_url": "http://arxiv.org/pdf/2403.09940v2",
      "published_date": "2024-03-15 00:45:36 UTC",
      "updated_date": "2024-11-05 08:15:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T16:06:02.641271"
    },
    {
      "arxiv_id": "2403.09930v3",
      "title": "Quality-Diversity Actor-Critic: Learning High-Performing and Diverse Behaviors via Value and Successor Features Critics",
      "title_zh": "翻译失败",
      "authors": [
        "Luca Grillotti",
        "Maxence Faldor",
        "Borja G. León",
        "Antoine Cully"
      ],
      "abstract": "A key aspect of intelligence is the ability to demonstrate a broad spectrum\nof behaviors for adapting to unexpected situations. Over the past decade,\nadvancements in deep reinforcement learning have led to groundbreaking\nachievements to solve complex continuous control tasks. However, most\napproaches return only one solution specialized for a specific problem. We\nintroduce Quality-Diversity Actor-Critic (QDAC), an off-policy actor-critic\ndeep reinforcement learning algorithm that leverages a value function critic\nand a successor features critic to learn high-performing and diverse behaviors.\nIn this framework, the actor optimizes an objective that seamlessly unifies\nboth critics using constrained optimization to (1) maximize return, while (2)\nexecuting diverse skills. Compared with other Quality-Diversity methods, QDAC\nachieves significantly higher performance and more diverse behaviors on six\nchallenging continuous control locomotion tasks. We also demonstrate that we\ncan harness the learned skills to adapt better than other baselines to five\nperturbed environments. Finally, qualitative analyses showcase a range of\nremarkable behaviors: adaptive-intelligent-robotics.github.io/QDAC.",
      "tldr_zh": "该研究提出 Quality-Diversity Actor-Critic (QDAC)，一个 off-policy actor-critic 深度强化学习算法，使用 value function critic 和 successor features critic 来学习高性能且多样化的行为，从而解决传统方法仅提供单一解决方案的局限性。QDAC 通过约束优化统一最大化回报和执行多样技能的目标，在六个挑战性的连续控制运动任务上实现了比其他 Quality-Diversity 方法更高的性能和行为多样性。实验结果显示，QDAC 能更好地适应五个扰动环境，并展示了各种引人注目的行为，增强了智能体的适应性和鲁棒性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "The first two authors contributed equally to this work. Accepted at\n  ICML 2024",
      "pdf_url": "http://arxiv.org/pdf/2403.09930v3",
      "published_date": "2024-03-15 00:09:47 UTC",
      "updated_date": "2024-06-03 09:46:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T16:06:13.908902"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 110,
  "processed_papers_count": 110,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-17T16:06:38.398042"
}