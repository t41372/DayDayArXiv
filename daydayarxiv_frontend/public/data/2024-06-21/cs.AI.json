{
  "date": "2024-06-21",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-06-21 的 arXiv 中文 TLDR 快报！今天 arXiv 更新了 98 篇论文，主要聚焦于 AI 模型优化、多模态学习和实际应用，如 LLM 的自校正能力、生成模型的创新以及医疗和自动驾驶领域的基准与方法，其中令人印象深刻的包括 Large Language Models have Intrinsic Self-Correction Ability 这篇探讨 LLM 内在机制的论文，以及多个 NeurIPS 相关工作如 TorchSpatial 和 NAVSIM，它们展示了 AI 在空间表示和模拟领域的潜力。\n\n下面，我将挑选并讨论今天更重要的论文，先从 LLM 和多模态学习等高话题度文章入手，再快速掠过其他次要内容。每个条目列出论文标题（中文 + 英文），并简要概述主要贡献和发现。\n\n### 重点论文讨论\n\n**Large Language Models have Intrinsic Self-Correction Ability（大型语言模型具有内在自校正能力）**  \n这篇论文由 Dancheng Liu 等作者发布，探讨了 LLM（如 GPT 系列）的自校正机制。贡献在于通过理论分析和实验证明，LLM 在零温度和公平提示下能有效减少幻觉（hallucinations），发现即使不依赖外部知识，LLM 也能提升输出质量，这对 LLM 鲁棒性有重要启示。\n\n**LongRAG: Enhancing Retrieval-Augmented Generation with Long-context LLMs（LongRAG：通过长上下文 LLM 增强检索增强生成）**  \nZiyan Jiang 等作者的工作扩展了 RAG 框架，贡献是通过长上下文处理（如处理整个 Wikipedia 语料），显著提升了检索效率和准确性。发现 LongRAG 在 NQ 和 HotpotQA 数据集上实现了与全训练模型相当的性能，同时减少了计算负担。\n\n**Multimodal Task Vectors Enable Many-Shot Multimodal In-Context Learning（多模态任务向量实现多样本多模态上下文学习）**  \nBrandon Huang 等作者提出了一种多模态任务向量方法，贡献在于压缩多模态数据以支持大样本上下文学习。发现这种方法能提升模型泛化性，并在 NeurIPS 2024 发表，展示了 LLM 在图像和文本结合任务中的潜力。\n\n**TorchSpatial: A Location Encoding Framework and Benchmark for Spatial Representation Learning（TorchSpatial：空间表示学习的定位编码框架和基准）**  \nNemin Wu 等作者开发了 TorchSpatial 框架，贡献是整合 15 种定位编码器并提出 LocBench 基准，评估空间数据（如点和图像）的表示。发现该框架能减少地理偏差，提升 GeoAI 任务性能，并在 NeurIPS 2024 数据集基准中表现出色。\n\n**NAVSIM: Data-Driven Non-Reactive Autonomous Vehicle Simulation and Benchmarking（NAVSIM：数据驱动的非反应式自动驾驶车辆模拟和基准）**  \nDaniel Dauner 等作者构建了 NAVSIM 系统，贡献是通过非反应式模拟评估自动驾驶策略，减少计算需求。发现它在 CVPR 2024 竞赛中表现突出，能提升模型在真实场景下的泛化能力。\n\n**GenoTEX: An LLM Agent Benchmark for Automated Gene Expression Data Analysis（GenoTEX：用于自动化基因表达数据分析的 LLM 代理基准）**  \nHaoyang Liu 等作者引入 GenoTEX 基准，贡献是提供基因数据分析任务集，并开发 GenoAgent 代理进行多步骤编程。发现 LLM 在生物信息学任务中表现出色，但仍有改进空间。\n\n**Image Conductor: Precision Control for Interactive Video Synthesis（Image Conductor：交互式视频合成的精确控制）**  \nYaowei Li 等作者提出 Image Conductor 方法，贡献是通过 LoRA 和相机引导技术实现视频生成中的精确运动控制。发现它能生成高质量交互视频，提升视频合成应用的实用性。\n\n**Physics Informed Machine Learning (PIML) methods for estimating the remaining useful lifetime (RUL) of aircraft engines（用于估计飞机引擎剩余使用寿命的物理信息机器学习方法）**  \nSriram Nagaraj 和 Truman Hickok 的论文贡献了 PIML 框架，结合随机微分方程和 LSTM 模型预测引擎 RUL。发现该方法优于传统深度学习，提升了航空维护的准确性。\n\n**Automated radiotherapy treatment planning guided by GPT-4Vision（基于 GPT-4Vision 的自动放射治疗规划）**  \nSheng Liu 等作者开发了 GPT-RadPlan 系统，贡献是通过 GPT-4Vision 指导治疗参数优化。发现它在前列腺和头颈癌计划中减少了器官辐射剂量，提高了临床效率。\n\n**Sketch-GNN: Scalable Graph Neural Networks with Sublinear Training Complexity（Sketch-GNN：具有亚线性训练复杂度的可扩展图神经网络）**  \nMucong Ding 等作者提出 Sketch-GNN 方法，贡献是通过图草图技术减少训练复杂性。发现它在大型图数据上实现了高效扩展，并在 NeurIPS 2022 中验证。\n\n### 其他论文快速掠过\n今天还有许多论文探讨了次要主题，如医疗诊断、生成模型和安全问题。例如，**Shortcomings of LLMs for Low-Resource Translation（LLM 在低资源翻译中的不足）** 揭示了 LLM 在低资源语言翻译中的局限性，主要发现是检索和理解问题影响性能。**Marrying Compressed Sensing and Deep Signal Separation（结合压缩感知和深度信号分离）** 则在信号处理中融合了深度学习，贡献了压缩信号分离管道，但影响较局部。**Bug In the Code Stack（代码堆栈中的错误）** 评估了 LLM 在代码错误检测中的表现，发现高资源语言更易处理。其他如基因数据分析、视频生成和安全基准等论文虽有创新，但未有突破性发现，故从简提及。\n\n总之，今天的 arXiv 更新突显了 AI 模型在实际应用中的进展，LLM 和多模态领域的优化尤为值得关注。感兴趣的读者可查阅具体论文深入探索！",
  "papers": [
    {
      "arxiv_id": "2406.16961v1",
      "title": "Anime Popularity Prediction Before Huge Investments: a Multimodal Approach Using Deep Learning",
      "title_zh": "在巨额投资之前预测 Anime 流行度：一种使用深度学习的多模态方法",
      "authors": [
        "Jesús Armenta-Segura",
        "Grigori Sidorov"
      ],
      "abstract": "In the japanese anime industry, predicting whether an upcoming product will\nbe popular is crucial. This paper presents a dataset and methods on predicting\nanime popularity using a multimodal textimage dataset constructed exclusively\nfrom freely available internet sources. The dataset was built following\nrigorous standards based on real-life investment experiences. A deep neural\nnetwork architecture leveraging GPT-2 and ResNet-50 to embed the data was\nemployed to investigate the correlation between the multimodal text-image input\nand a popularity score, discovering relevant strengths and weaknesses in the\ndataset. To measure the accuracy of the model, mean squared error (MSE) was\nused, obtaining a best result of 0.011 when considering all inputs and the full\nversion of the deep neural network, compared to the benchmark MSE 0.412\nobtained with traditional TF-IDF and PILtotensor vectorizations. This is the\nfirst proposal to address such task with multimodal datasets, revealing the\nsubstantial benefit of incorporating image information, even when a relatively\nsmall model (ResNet-50) was used to embed them.",
      "tldr_zh": "本文提出了一种多模态方法，使用深度学习预测日本动漫的受欢迎程度，以帮助避免巨额投资风险。该方法基于一个从免费互联网来源构建的文本-图像数据集，遵循真实投资经验的标准，并采用GPT-2和ResNet-50嵌入数据构建深度神经网络，分析多模态输入与受欢迎分数的相关性。实验结果显示，模型的均方误差(MSE)达到最佳值0.011，显著优于基准模型的0.412(TF-IDF和PILtotensor)。这项研究首次使用多模态数据集解决此任务，证明了加入图像信息即使在较小模型如ResNet-50下也能带来实质性益处。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "13 pages, 6 figures, 11 tables",
      "pdf_url": "http://arxiv.org/pdf/2406.16961v1",
      "published_date": "2024-06-21 23:12:59 UTC",
      "updated_date": "2024-06-21 23:12:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T23:08:26.297456"
    },
    {
      "arxiv_id": "2406.15676v1",
      "title": "Inferring Pluggable Types with Machine Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Kazi Amanul Islam Siddiqui",
        "Martin Kellogg"
      ],
      "abstract": "Pluggable type systems allow programmers to extend the type system of a\nprogramming language to enforce semantic properties defined by the programmer.\nPluggable type systems are difficult to deploy in legacy codebases because they\nrequire programmers to write type annotations manually. This paper investigates\nhow to use machine learning to infer type qualifiers automatically. We propose\na novel representation, NaP-AST, that encodes minimal dataflow hints for the\neffective inference of type qualifiers. We evaluate several model architectures\nfor inferring type qualifiers, including Graph Transformer Network, Graph\nConvolutional Network and Large Language Model. We further validated these\nmodels by applying them to 12 open-source programs from a prior evaluation of\nthe NullAway pluggable typechecker, lowering warnings in all but one\nunannotated project. We discovered that GTN shows the best performance, with a\nrecall of .89 and precision of 0.6. Furthermore, we conduct a study to estimate\nthe number of Java classes needed for good performance of the trained model.\nFor our feasibility study, performance improved around 16k classes, and\ndeteriorated due to overfitting around 22k classes.",
      "tldr_zh": "这篇论文探讨了使用机器学习自动推断 Pluggable type systems 中的类型限定符，以解决部署到遗留代码库时需要手动添加注解的难题。研究者提出了一种新表示 NaP-AST，用于编码最小的数据流提示，以提升类型限定符的推理效率，并评估了 Graph Transformer Network (GTN)、Graph Convolutional Network (GCN) 和 Large Language Model 等模型架构。在 12 个开源 Java 项目上进行验证，这些模型显著降低了警告，且 GTN 表现出色，recall 为 0.89 和 precision 为 0.6；此外，研究发现训练数据规模约为 16k 类时模型性能最佳，但超过 22k 类时会因过拟合而下降。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.15676v1",
      "published_date": "2024-06-21 22:32:42 UTC",
      "updated_date": "2024-06-21 22:32:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T23:08:39.559951"
    },
    {
      "arxiv_id": "2406.15675v3",
      "title": "Combining Neural Networks and Symbolic Regression for Analytical Lyapunov Function Discovery",
      "title_zh": "结合神经网络和符号回归用于解析李亚普诺夫函数的发现",
      "authors": [
        "Jie Feng",
        "Haohan Zou",
        "Yuanyuan Shi"
      ],
      "abstract": "We propose CoNSAL (Combining Neural networks and Symbolic regression for\nAnalytical Lyapunov function) to construct analytical Lyapunov functions for\nnonlinear dynamic systems. This framework contains a neural Lyapunov function\nand a symbolic regression component, where symbolic regression is applied to\ndistill the neural network to precise analytical forms. Our approach utilizes\nsymbolic regression not only as a tool for translation but also as a means to\nuncover counterexamples. This procedure terminates when no counterexamples are\nfound in the analytical formulation. Compared with previous results, CoNSAL\ndirectly produces an analytical form of the Lyapunov function with improved\ninterpretability in both the learning process and the final results. We apply\nCoNSAL to 2-D inverted pendulum, path following, Van Der Pol Oscillator, 3-D\ntrig dynamics, 4-D rotating wheel pendulum, 6-D 3-bus power system, and\ndemonstrate that our algorithm successfully finds their valid Lyapunov\nfunctions. Code examples are available at https://github.com/HaohanZou/CoNSAL.",
      "tldr_zh": "本文提出CoNSAL框架，通过结合neural networks和symbolic regression来构建非线性动态系统的analytical Lyapunov functions，其中symbolic regression用于提炼神经网络为精确分析形式，并通过发现反例确保函数的有效性。相比以往方法，CoNSAL直接生成更具可解释性的Lyapunov函数形式。实验在2-D inverted pendulum、Van Der Pol Oscillator等系统中成功验证了该框架的性能，并提供了开源代码示例。",
      "categories": [
        "eess.SY",
        "cs.AI",
        "cs.SC",
        "cs.SY"
      ],
      "primary_category": "eess.SY",
      "comment": "Workshop paper, accepted by Workshop on Foundations of Reinforcement\n  Learning and Control at the 41st International Conference on Machine\n  Learning, Vienna, Austria",
      "pdf_url": "http://arxiv.org/pdf/2406.15675v3",
      "published_date": "2024-06-21 22:31:06 UTC",
      "updated_date": "2024-07-12 20:08:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T23:08:49.015834"
    },
    {
      "arxiv_id": "2406.15673v2",
      "title": "Large Language Models have Intrinsic Self-Correction Ability",
      "title_zh": "大型语言模型具有内在自校正能力",
      "authors": [
        "Dancheng Liu",
        "Amir Nassereldine",
        "Ziming Yang",
        "Chenhui Xu",
        "Yuting Hu",
        "Jiajie Li",
        "Utkarsh Kumar",
        "Changjae Lee",
        "Ruiyang Qin",
        "Yiyu Shi",
        "Jinjun Xiong"
      ],
      "abstract": "Large language models (LLMs) have attracted significant attention for their\nexceptional abilities in various natural language processing tasks, but they\nsuffer from hallucinations that will cause performance degradation. One\npromising solution to improve the LLMs' performance is to ask LLMs to revise\ntheir answer after generation, a technique known as self-correction. Among the\ntwo types of self-correction, intrinsic self-correction is considered a\npromising direction because it does not utilize external knowledge. However,\nrecent works doubt the validity of LLM's ability to conduct intrinsic\nself-correction. In this paper, we present a novel perspective on the intrinsic\nself-correction capabilities of LLMs through theoretical analyses and empirical\nexperiments. In addition, we identify two critical factors for successful\nself-correction: zero temperature and fair prompts. Leveraging these factors,\nwe demonstrate that intrinsic self-correction ability is exhibited across\nmultiple existing LLMs. Our findings offer insights into the fundamental\ntheories underlying the self-correction behavior of LLMs and remark on the\nimportance of unbiased prompts and zero temperature settings in harnessing\ntheir full potential.",
      "tldr_zh": "本文证明了大语言模型(LLMs)具有内在自校正(intrinsic self-correction)能力，能够在不依赖外部知识的情况下改进其生成的答案，从而缓解幻觉问题导致的性能下降。研究通过理论分析和实证实验，识别了两个关键因素：零温度(zero temperature)和公平提示(fair prompts)，这些因素有助于激活LLMs的自校正潜力。实验结果显示，这种能力在多个现有LLMs中得到体现，为更好地利用LLMs提供了重要洞见，并强调了无偏提示和适当设置的重要性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "in submission",
      "pdf_url": "http://arxiv.org/pdf/2406.15673v2",
      "published_date": "2024-06-21 22:29:40 UTC",
      "updated_date": "2024-12-23 06:03:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T23:09:01.846207"
    },
    {
      "arxiv_id": "2406.15662v2",
      "title": "Matching Problems to Solutions: An Explainable Way of Solving Machine Learning Problems",
      "title_zh": "翻译失败",
      "authors": [
        "Lokman Saleh",
        "Hafedh Mili",
        "Mounir Boukadoum",
        "Abderrahmane Leshob"
      ],
      "abstract": "Domain experts from all fields are called upon, working with data scientists,\nto explore the use of ML techniques to solve their problems. Starting from a\ndomain problem/question, ML-based problem-solving typically involves three\nsteps: (1) formulating the business problem (problem domain) as a data analysis\nproblem (solution domain), (2) sketching a high-level ML-based solution\npattern, given the domain requirements and the properties of the available\ndata, and (3) designing and refining the different components of the solution\npattern. There has to be a substantial body of ML problem solving knowledge\nthat ML researchers agree on, and that ML practitioners routinely apply to\nsolve the most common problems. Our work deals with capturing this body of\nknowledge, and embodying it in a ML problem solving workbench to helps domain\nspecialists who are not ML experts to explore the ML solution space. This paper\nfocuses on: 1) the representation of domain problems, ML problems, and the main\nML solution artefacts, and 2) a heuristic matching function that helps identify\nthe ML algorithm family that is most appropriate for the domain problem at\nhand, given the domain (expert) requirements, and the characteristics of the\ntraining data. We review related work and outline our strategy for validating\nthe workbench",
      "tldr_zh": "本文提出了一种可解释的 Machine Learning (ML) 问题解决方法，帮助非 ML 专家的领域专家将业务问题转化为数据分析问题，并探索合适的 ML 解决方案。方法包括三个关键步骤：问题公式化、高层次解决方案设计，以及组件的细化设计；同时引入一个启发式匹配函数(heuristic matching function)，根据领域要求和数据特性匹配最合适的 ML 算法家族。论文通过捕捉 ML 问题解决知识并构建一个工作台(workbench)，回顾相关工作并概述验证策略，以提升 ML 应用的解释性和可访问性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.15662v2",
      "published_date": "2024-06-21 21:39:34 UTC",
      "updated_date": "2024-09-18 19:31:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T23:09:13.888848"
    },
    {
      "arxiv_id": "2406.15658v3",
      "title": "TorchSpatial: A Location Encoding Framework and Benchmark for Spatial Representation Learning",
      "title_zh": "TorchSpatial：位置编码框架和基准，用于空间表示学习",
      "authors": [
        "Nemin Wu",
        "Qian Cao",
        "Zhangyu Wang",
        "Zeping Liu",
        "Yanlin Qi",
        "Jielu Zhang",
        "Joshua Ni",
        "Xiaobai Yao",
        "Hongxu Ma",
        "Lan Mu",
        "Stefano Ermon",
        "Tanuja Ganu",
        "Akshay Nambi",
        "Ni Lao",
        "Gengchen Mai"
      ],
      "abstract": "Spatial representation learning (SRL) aims at learning general-purpose neural\nnetwork representations from various types of spatial data (e.g., points,\npolylines, polygons, networks, images, etc.) in their native formats. Learning\ngood spatial representations is a fundamental problem for various downstream\napplications such as species distribution modeling, weather forecasting,\ntrajectory generation, geographic question answering, etc. Even though SRL has\nbecome the foundation of almost all geospatial artificial intelligence (GeoAI)\nresearch, we have not yet seen significant efforts to develop an extensive deep\nlearning framework and benchmark to support SRL model development and\nevaluation. To fill this gap, we propose TorchSpatial, a learning framework and\nbenchmark for location (point) encoding, which is one of the most fundamental\ndata types of spatial representation learning. TorchSpatial contains three key\ncomponents: 1) a unified location encoding framework that consolidates 15\ncommonly recognized location encoders, ensuring scalability and reproducibility\nof the implementations; 2) the LocBench benchmark tasks encompassing 7\ngeo-aware image classification and 10 geo-aware image regression datasets; 3) a\ncomprehensive suite of evaluation metrics to quantify geo-aware model's overall\nperformance as well as their geographic bias, with a novel Geo-Bias Score\nmetric. Finally, we provide a detailed analysis and insights into the model\nperformance and geographic bias of different location encoders. We believe\nTorchSpatial will foster future advancement of spatial representation learning\nand spatial fairness in GeoAI research. The TorchSpatial model framework and\nLocBench benchmark are available at https://github.com/seai-lab/TorchSpatial,\nand the Geo-Bias Score evaluation framework is available at\nhttps://github.com/seai-lab/PyGBS.",
      "tldr_zh": "这篇论文提出了 TorchSpatial，一个用于空间表示学习(SRL)的位置编码框架和基准，旨在从各种空间数据（如点、线、多边形等）学习通用神经网络表示，以支持下游任务如物种分布建模和天气预报。框架整合了 15 个常用位置编码器，确保实现的可扩展性和可重复性，并引入 LocBench 基准任务，包括 7 个地理感知图像分类和 10 个地理感知图像回归数据集。论文还开发了全面的评估指标，如新型 Geo-Bias Score，用于量化模型的整体性能和地理偏差。通过实验分析，论文提供了不同位置编码器的性能洞察和偏差评估，促进了 SRL 和 GeoAI 研究中的空间公平性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "10 pages, 2 figures. Accepted by NeurIPS 2024 Datasets and Benchmarks\n  Track",
      "pdf_url": "http://arxiv.org/pdf/2406.15658v3",
      "published_date": "2024-06-21 21:33:16 UTC",
      "updated_date": "2025-01-19 22:25:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T23:09:27.335307"
    },
    {
      "arxiv_id": "2406.15625v3",
      "title": "Shortcomings of LLMs for Low-Resource Translation: Retrieval and Understanding are Both the Problem",
      "title_zh": "LLM 在低资源翻译中的不足",
      "authors": [
        "Sara Court",
        "Micha Elsner"
      ],
      "abstract": "This work investigates the in-context learning abilities of pretrained large\nlanguage models (LLMs) when instructed to translate text from a low-resource\nlanguage into a high-resource language as part of an automated machine\ntranslation pipeline. We conduct a set of experiments translating Southern\nQuechua to Spanish and examine the informativity of various types of context\nretrieved from a constrained database of digitized pedagogical materials\n(dictionaries and grammar lessons) and parallel corpora. Using both automatic\nand human evaluation of model output, we conduct ablation studies that\nmanipulate (1) context type (morpheme translations, grammar descriptions, and\ncorpus examples), (2) retrieval methods (automated vs. manual), and (3) model\ntype. Our results suggest that even relatively small LLMs are capable of\nutilizing prompt context for zero-shot low-resource translation when provided a\nminimally sufficient amount of relevant linguistic information. However, the\nvariable effects of context type, retrieval method, model type, and\nlanguage-specific factors highlight the limitations of using even the best LLMs\nas translation systems for the majority of the world's 7,000+ languages and\ntheir speakers.",
      "tldr_zh": "这项研究探讨了大型语言模型 (LLMs) 在低资源语言翻译中的不足，特别是检索和理解方面的挑战，通过 Southern Quechua 到 Spanish 的翻译实验进行评估。研究者使用各种上下文类型（如词素翻译、语法描述和语料例子）、检索方法（自动 vs. 手动）和不同模型类型进行消融研究，结果显示即使较小的 LLMs 也能在零样本 (zero-shot) 场景下利用相关语言信息进行翻译，但效果因上下文类型、检索方法和语言特定因素而异。最终，该工作突显了 LLMs 在服务全球 7000+ 语言中的大多数时的局限性，强调了其作为翻译系统的可靠性问题。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Presented at the Ninth Conference on Machine Translation (WMT24)",
      "pdf_url": "http://arxiv.org/pdf/2406.15625v3",
      "published_date": "2024-06-21 20:02:22 UTC",
      "updated_date": "2024-10-24 22:24:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T23:09:37.674785"
    },
    {
      "arxiv_id": "2406.15623v1",
      "title": "Marrying Compressed Sensing and Deep Signal Separation",
      "title_zh": "翻译失败",
      "authors": [
        "Truman Hickok",
        "Sriram Nagaraj"
      ],
      "abstract": "Blind signal separation (BSS) is an important and challenging signal\nprocessing task. Given an observed signal which is a superposition of a\ncollection of unknown (hidden/latent) signals, BSS aims at recovering the\nseparate, underlying signals from only the observed mixed signal. As an\nunderdetermined problem, BSS is notoriously difficult to solve in general, and\nmodern deep learning has provided engineers with an effective set of tools to\nsolve this problem. For example, autoencoders learn a low-dimensional hidden\nencoding of the input data which can then be used to perform signal separation.\nIn real-time systems, a common bottleneck is the transmission of data\n(communications) to a central command in order to await decisions. Bandwidth\nlimits dictate the frequency and resolution of the data being transmitted. To\novercome this, compressed sensing (CS) technology allows for the direct\nacquisition of compressed data with a near optimal reconstruction guarantee.\nThis paper addresses the question: can compressive acquisition be combined with\ndeep learning for BSS to provide a complete acquire-separate-predict pipeline?\nIn other words, the aim is to perform BSS on a compressively acquired signal\ndirectly without ever having to decompress the signal. We consider image data\n(MNIST and E-MNIST) and show how our compressive autoencoder approach solves\nthe problem of compressive BSS. We also provide some theoretical insights into\nthe problem.",
      "tldr_zh": "本论文探讨了将压缩感知(Compressed Sensing, CS)与深度信号分离相结合，以解决盲信号分离(Blind Signal Separation, BSS)这一欠定信号处理难题。作者提出了一种压缩自编码器方法，实现直接在压缩获取的信号上进行分离和预测，从而构建一个完整的获取-分离-预测管道，而无需信号解压缩。实验在MNIST和E-MNIST图像数据集上验证了该方法的有效性，并提供了理论见解，展示了其在实时系统中的潜力。",
      "categories": [
        "math.NA",
        "cs.AI",
        "cs.NA",
        "68T07 68T07"
      ],
      "primary_category": "math.NA",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.15623v1",
      "published_date": "2024-06-21 20:00:34 UTC",
      "updated_date": "2024-06-21 20:00:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T23:09:48.288230"
    },
    {
      "arxiv_id": "2406.15619v1",
      "title": "Physics Informed Machine Learning (PIML) methods for estimating the remaining useful lifetime (RUL) of aircraft engines",
      "title_zh": "基于物理信息的机器学习 (PIML) 方法用于估计飞机引擎的剩余可用寿命 (RUL)",
      "authors": [
        "Sriram Nagaraj",
        "Truman Hickok"
      ],
      "abstract": "This paper is aimed at using the newly developing field of physics informed\nmachine learning (PIML) to develop models for predicting the remaining useful\nlifetime (RUL) aircraft engines. We consider the well-known benchmark NASA\nCommercial Modular Aero-Propulsion System Simulation (C-MAPSS) data as the main\ndata for this paper, which consists of sensor outputs in a variety of different\noperating modes. C-MAPSS is a well-studied dataset with much existing work in\nthe literature that address RUL prediction with classical and deep learning\nmethods. In the absence of published empirical physical laws governing the\nC-MAPSS data, our approach first uses stochastic methods to estimate the\ngoverning physics models from the noisy time series data. In our approach, we\nmodel the various sensor readings as being governed by stochastic differential\nequations, and we estimate the corresponding transition density mean and\nvariance functions of the underlying processes. We then augment LSTM\n(long-short term memory) models with the learned mean and variance functions\nduring training and inferencing. Our PIML based approach is different from\nprevious methods, and we use the data to first learn the physics. Our results\nindicate that PIML discovery and solutions methods are well suited for this\nproblem and outperform previous data-only deep learning methods for this data\nset and task. Moreover, the framework developed herein is flexible, and can be\nadapted to other situations (other sensor modalities or combined multi-physics\nenvironments), including cases where the underlying physics is only partially\nobserved or known.",
      "tldr_zh": "这篇论文提出了一种基于Physics Informed Machine Learning (PIML)的方法，用于预测飞机引擎的剩余可用寿命 (RUL)，以NASA的C-MAPSS数据集为基础，该数据集包含不同操作模式下的传感器输出。研究首先使用随机方法从噪声时间序列数据中估计出潜在的物理模型，包括建模传感器读数为stochastic differential equations并计算底层过程的均值和方差函数，随后将这些函数整合到LSTM (Long-Short Term Memory)模型中进行训练和推理。与传统的纯数据驱动深度学习方法不同，这种PIML方法先学习物理模型，并展示了在C-MAPSS数据集上的优越性能。实验结果表明，该框架在RUL预测任务中比现有方法表现更好，且具有灵活性，可扩展到其他传感器模式或多物理环境。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NA",
        "math.NA",
        "65C20 65C20 65C20"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.15619v1",
      "published_date": "2024-06-21 19:55:34 UTC",
      "updated_date": "2024-06-21 19:55:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T23:10:02.336740"
    },
    {
      "arxiv_id": "2406.15609v3",
      "title": "Automated radiotherapy treatment planning guided by GPT-4Vision",
      "title_zh": "基于 GPT-4Vision 的自动化放射治疗计划制定",
      "authors": [
        "Sheng Liu",
        "Oscar Pastor-Serrano",
        "Yizheng Chen",
        "Matthew Gopaulchan",
        "Weixing Liang",
        "Mark Buyyounouski",
        "Erqi Pollom",
        "Quynh-Thu Le",
        "Michael Gensheimer",
        "Peng Dong",
        "Yong Yang",
        "James Zou",
        "Lei Xing"
      ],
      "abstract": "Objective: Radiotherapy treatment planning is a time-consuming and\npotentially subjective process that requires the iterative adjustment of model\nparameters to balance multiple conflicting objectives. Recent advancements in\nfrontier Artificial Intelligence (AI) models offer promising avenues for\naddressing the challenges in planning and clinical decision-making. This study\nintroduces GPT-RadPlan, an automated treatment planning framework that\nintegrates radiation oncology knowledge with the reasoning capabilities of\nlarge multi-modal models, such as GPT-4Vision (GPT-4V) from OpenAI.\n  Approach: Via in-context learning, we incorporate clinical requirements and a\nfew (3 in our experiments) approved clinical plans with their optimization\nsettings, enabling GPT-4V to acquire treatment planning domain knowledge. The\nresulting GPT-RadPlan system is integrated into our in-house inverse treatment\nplanning system through an application programming interface (API). For a given\npatient, GPT-RadPlan acts as both plan evaluator and planner, first assessing\ndose distributions and dose-volume histograms (DVHs), and then providing\ntextual feedback on how to improve the plan to match the physician's\nrequirements. In this manner, GPT-RadPlan iteratively refines the plan by\nadjusting planning parameters, such as weights and dose objectives, based on\nits suggestions.\n  Main results: The efficacy of the automated planning system is showcased\nacross 17 prostate cancer and 13 head and neck cancer VMAT plans with\nprescribed doses of 70.2 Gy and 72 Gy, respectively, where we compared\nGPT-RadPlan results to clinical plans produced by human experts. In all cases,\nGPT-RadPlan either outperformed or matched the clinical plans, demonstrating\nsuperior target coverage and reducing organ-at-risk doses by 5 Gy on average\n(15 percent for prostate and 10-15 percent for head and neck).",
      "tldr_zh": "这篇论文介绍了 GPT-RadPlan，一种由 GPT-4Vision 指导的自动化放射治疗规划框架，旨在解决传统规划过程的耗时性和主观性问题。框架通过 in-context learning 整合辐射肿瘤学知识、临床要求和少量批准计划，使 GPT-4V 能够评估剂量分布（dose distributions）和剂量体积直方图（DVHs），并迭代调整参数如权重和剂量目标以优化治疗方案。在实验中，GPT-RadPlan 在 17 个前列腺癌和 13 个头颈癌 VMAT 计划上优于或匹配临床计划，提高了目标覆盖并平均减少器官风险剂量 5 Gy（前列腺 15%，头颈 10-15%）。",
      "categories": [
        "physics.med-ph",
        "cs.AI"
      ],
      "primary_category": "physics.med-ph",
      "comment": "12 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2406.15609v3",
      "published_date": "2024-06-21 19:23:03 UTC",
      "updated_date": "2025-04-08 00:19:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T23:10:14.660058"
    },
    {
      "arxiv_id": "2407.00075v5",
      "title": "Logicbreaks: A Framework for Understanding Subversion of Rule-based Inference",
      "title_zh": "翻译失败",
      "authors": [
        "Anton Xue",
        "Avishree Khare",
        "Rajeev Alur",
        "Surbhi Goel",
        "Eric Wong"
      ],
      "abstract": "We study how to subvert large language models (LLMs) from following\nprompt-specified rules. We first formalize rule-following as inference in\npropositional Horn logic, a mathematical system in which rules have the form\n\"if $P$ and $Q$, then $R$\" for some propositions $P$, $Q$, and $R$. Next, we\nprove that although small transformers can faithfully follow such rules,\nmaliciously crafted prompts can still mislead both theoretical constructions\nand models learned from data. Furthermore, we demonstrate that popular attack\nalgorithms on LLMs find adversarial prompts and induce attention patterns that\nalign with our theory. Our novel logic-based framework provides a foundation\nfor studying LLMs in rule-based settings, enabling a formal analysis of tasks\nlike logical reasoning and jailbreak attacks.",
      "tldr_zh": "这篇论文提出了Logicbreaks框架，用于分析如何破坏大型语言模型(LLMs)遵守提示规则的机制。具体地，他们将规则遵守形式化为命题 Horn logic，并证明尽管小型transformer模型能遵循此类规则，恶意设计的对抗性提示(adversarial prompts)仍可误导模型和理论构建。实验结果显示，流行攻击算法诱导的注意力模式与该理论一致，为LLMs在逻辑推理和越狱攻击(jailbreak attacks)等任务的正式分析提供了基础。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.CR",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.00075v5",
      "published_date": "2024-06-21 19:18:16 UTC",
      "updated_date": "2025-02-28 17:50:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T23:10:27.113563"
    },
    {
      "arxiv_id": "2406.15599v2",
      "title": "Pareto-Optimal Learning from Preferences with Hidden Context",
      "title_zh": "翻译失败",
      "authors": [
        "Ryan Bahlous-Boldi",
        "Li Ding",
        "Lee Spector",
        "Scott Niekum"
      ],
      "abstract": "Ensuring AI models align with human values is essential for their safety and\nfunctionality. Reinforcement learning from human feedback (RLHF) leverages\nhuman preferences to achieve this alignment. However, when preferences are\nsourced from diverse populations, point estimates of reward can result in\nsuboptimal performance or be unfair to specific groups. We propose Pareto\nOptimal Preference Learning (POPL), which enables pluralistic alignment by\nframing discrepant group preferences as objectives with potential trade-offs,\naiming for policies that are Pareto-optimal on the preference dataset. POPL\nutilizes lexicase selection, an iterative process that selects diverse and\nPareto-optimal solutions. Our theoretical and empirical evaluations demonstrate\nthat POPL surpasses baseline methods in learning sets of reward functions and\npolicies, effectively catering to distinct groups without access to group\nnumbers or membership labels. We verify the performance of POPL on a stateless\npreference learning setting, a Minigrid RL domain, Metaworld robotics\nbenchmarks, as well as large language model (LLM) fine-tuning. We illustrate\nthat POPL can also serve as a foundation for techniques optimizing specific\nnotions of group fairness, ensuring safe and equitable AI model alignment.",
      "tldr_zh": "该研究针对强化学习从人类反馈（RLHF）中存在的偏好多样性问题，提出Pareto Optimal Preference Learning (POPL) 方法，以处理隐藏上下文下的群体偏好差异，确保AI模型与人类价值观的公平对齐。POPL 通过将不同群体的偏好视为可能权衡的目标，并采用lexicase selection的迭代过程，选择多样性和Pareto-optimal的奖励函数和策略，从而避免次优性能或不公平现象。实验结果显示，POPL 在无状态偏好学习、Minigrid RL域、Metaworld机器人基准以及LLM微调等场景中，优于基线方法，并在不需群体标签的情况下提升AI模型的安全性和公平性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.15599v2",
      "published_date": "2024-06-21 18:57:38 UTC",
      "updated_date": "2025-02-07 17:29:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T23:10:40.796007"
    },
    {
      "arxiv_id": "2406.15575v1",
      "title": "Sketch-GNN: Scalable Graph Neural Networks with Sublinear Training Complexity",
      "title_zh": "Sketch",
      "authors": [
        "Mucong Ding",
        "Tahseen Rabbani",
        "Bang An",
        "Evan Z Wang",
        "Furong Huang"
      ],
      "abstract": "Graph Neural Networks (GNNs) are widely applied to graph learning problems\nsuch as node classification. When scaling up the underlying graphs of GNNs to a\nlarger size, we are forced to either train on the complete graph and keep the\nfull graph adjacency and node embeddings in memory (which is often infeasible)\nor mini-batch sample the graph (which results in exponentially growing\ncomputational complexities with respect to the number of GNN layers). Various\nsampling-based and historical-embedding-based methods are proposed to avoid\nthis exponential growth of complexities. However, none of these solutions\neliminates the linear dependence on graph size. This paper proposes a\nsketch-based algorithm whose training time and memory grow sublinearly with\nrespect to graph size by training GNNs atop a few compact sketches of graph\nadjacency and node embeddings. Based on polynomial tensor-sketch (PTS) theory,\nour framework provides a novel protocol for sketching non-linear activations\nand graph convolution matrices in GNNs, as opposed to existing methods that\nsketch linear weights or gradients in neural networks. In addition, we develop\na locality-sensitive hashing (LSH) technique that can be trained to improve the\nquality of sketches. Experiments on large-graph benchmarks demonstrate the\nscalability and competitive performance of our Sketch-GNNs versus their\nfull-size GNN counterparts.",
      "tldr_zh": "这篇论文提出了 Sketch-GNN，一种可扩展的 Graph Neural Networks (GNNs)，通过使用 sketch 技术使训练时间和内存复杂度以次线性方式增长，解决了传统 GNNs 在处理大规模图时面临的内存和计算挑战。该框架基于 polynomial tensor-sketch (PTS) 理论，对非线性激活和图卷积矩阵进行创新性 sketch 处理，并引入 locality-sensitive hashing (LSH) 技术来优化 sketch 质量。实验结果显示，Sketch-GNN 在大型图基准上表现出色，与全尺寸 GNN 相比保持了竞争性性能，同时显著提升了可扩展性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "NeurIPS 2022",
      "pdf_url": "http://arxiv.org/pdf/2406.15575v1",
      "published_date": "2024-06-21 18:22:11 UTC",
      "updated_date": "2024-06-21 18:22:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T23:10:52.527135"
    },
    {
      "arxiv_id": "2406.15567v1",
      "title": "SAIL: Self-Improving Efficient Online Alignment of Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Mucong Ding",
        "Souradip Chakraborty",
        "Vibhu Agrawal",
        "Zora Che",
        "Alec Koppel",
        "Mengdi Wang",
        "Amrit Bedi",
        "Furong Huang"
      ],
      "abstract": "Reinforcement Learning from Human Feedback (RLHF) is a key method for\naligning large language models (LLMs) with human preferences. However, current\noffline alignment approaches like DPO, IPO, and SLiC rely heavily on fixed\npreference datasets, which can lead to sub-optimal performance. On the other\nhand, recent literature has focused on designing online RLHF methods but still\nlacks a unified conceptual formulation and suffers from distribution shift\nissues. To address this, we establish that online LLM alignment is underpinned\nby bilevel optimization. By reducing this formulation to an efficient\nsingle-level first-order method (using the reward-policy equivalence), our\napproach generates new samples and iteratively refines model alignment by\nexploring responses and regulating preference labels. In doing so, we permit\nalignment methods to operate in an online and self-improving manner, as well as\ngeneralize prior online RLHF methods as special cases. Compared to\nstate-of-the-art iterative RLHF methods, our approach significantly improves\nalignment performance on open-sourced datasets with minimal computational\noverhead.",
      "tldr_zh": "本研究提出SAIL，一种自改进的在线对齐框架，用于优化大语言模型(LLMs)的Reinforcement Learning from Human Feedback (RLHF)。针对现有离线方法如DPO、IPO和SLiC依赖固定偏好数据集导致的次优性能，以及在线RLHF方法存在的分布偏移问题，SAIL基于bilevel optimization框架，并将其简化为高效的单层一阶方法，通过生成新样本和迭代调节偏好标签来探索响应并改进模型对齐。实验结果显示，SAIL在开源数据集上显著提升了对齐性能，同时保持了最低的计算开销，将先前的在线RLHF方法作为特例。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "24 pages, 6 figures, 3 tables",
      "pdf_url": "http://arxiv.org/pdf/2406.15567v1",
      "published_date": "2024-06-21 18:05:35 UTC",
      "updated_date": "2024-06-21 18:05:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T23:11:03.881123"
    },
    {
      "arxiv_id": "2406.15349v2",
      "title": "NAVSIM: Data-Driven Non-Reactive Autonomous Vehicle Simulation and Benchmarking",
      "title_zh": "NAVSIM：数据驱动的非反应式自动驾驶车辆模拟和基准测试",
      "authors": [
        "Daniel Dauner",
        "Marcel Hallgarten",
        "Tianyu Li",
        "Xinshuo Weng",
        "Zhiyu Huang",
        "Zetong Yang",
        "Hongyang Li",
        "Igor Gilitschenski",
        "Boris Ivanovic",
        "Marco Pavone",
        "Andreas Geiger",
        "Kashyap Chitta"
      ],
      "abstract": "Benchmarking vision-based driving policies is challenging. On one hand,\nopen-loop evaluation with real data is easy, but these results do not reflect\nclosed-loop performance. On the other, closed-loop evaluation is possible in\nsimulation, but is hard to scale due to its significant computational demands.\nFurther, the simulators available today exhibit a large domain gap to real\ndata. This has resulted in an inability to draw clear conclusions from the\nrapidly growing body of research on end-to-end autonomous driving. In this\npaper, we present NAVSIM, a middle ground between these evaluation paradigms,\nwhere we use large datasets in combination with a non-reactive simulator to\nenable large-scale real-world benchmarking. Specifically, we gather\nsimulation-based metrics, such as progress and time to collision, by unrolling\nbird's eye view abstractions of the test scenes for a short simulation horizon.\nOur simulation is non-reactive, i.e., the evaluated policy and environment do\nnot influence each other. As we demonstrate empirically, this decoupling allows\nopen-loop metric computation while being better aligned with closed-loop\nevaluations than traditional displacement errors. NAVSIM enabled a new\ncompetition held at CVPR 2024, where 143 teams submitted 463 entries, resulting\nin several new insights. On a large set of challenging scenarios, we observe\nthat simple methods with moderate compute requirements such as TransFuser can\nmatch recent large-scale end-to-end driving architectures such as UniAD. Our\nmodular framework can potentially be extended with new datasets, data curation\nstrategies, and metrics, and will be continually maintained to host future\nchallenges. Our code is available at\nhttps://github.com/autonomousvision/navsim.",
      "tldr_zh": "本文提出 NAVSIM，一种数据驱动的非反应性自动驾驶车辆模拟和基准测试框架，旨在弥合开放循环评估与闭环评估的差距，通过结合大型数据集和鸟瞰视图抽象进行短时模拟，计算指标如进度和碰撞时间，同时避免政策与环境相互影响。实验结果显示，该框架在 CVPR 2024 竞赛中支持 143 支队伍提交 463 项参赛作品，并发现简单方法如 TransFuser 可与大型端到端架构如 UniAD 在挑战场景中匹敌。NAVSIM 的模块化设计可扩展至新数据集和指标，并持续维护以推动未来自动驾驶研究。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "NeurIPS 2024 Datasets and Benchmarks",
      "pdf_url": "http://arxiv.org/pdf/2406.15349v2",
      "published_date": "2024-06-21 17:59:02 UTC",
      "updated_date": "2024-10-31 17:58:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T23:11:16.592848"
    },
    {
      "arxiv_id": "2406.15346v1",
      "title": "Privacy Preserved Blood Glucose Level Cross-Prediction: An Asynchronous Decentralized Federated Learning Approach",
      "title_zh": "隐私保护的血糖水平跨预测：一种异步去中心化联邦学习方法",
      "authors": [
        "Chengzhe Piao",
        "Taiyu Zhu",
        "Yu Wang",
        "Stephanie E Baldeweg",
        "Paul Taylor",
        "Pantelis Georgiou",
        "Jiahao Sun",
        "Jun Wang",
        "Kezhi Li"
      ],
      "abstract": "Newly diagnosed Type 1 Diabetes (T1D) patients often struggle to obtain\neffective Blood Glucose (BG) prediction models due to the lack of sufficient BG\ndata from Continuous Glucose Monitoring (CGM), presenting a significant \"cold\nstart\" problem in patient care. Utilizing population models to address this\nchallenge is a potential solution, but collecting patient data for training\npopulation models in a privacy-conscious manner is challenging, especially\ngiven that such data is often stored on personal devices. Considering the\nprivacy protection and addressing the \"cold start\" problem in diabetes care, we\npropose \"GluADFL\", blood Glucose prediction by Asynchronous Decentralized\nFederated Learning. We compared GluADFL with eight baseline methods using four\ndistinct T1D datasets, comprising 298 participants, which demonstrated its\nsuperior performance in accurately predicting BG levels for cross-patient\nanalysis. Furthermore, patients' data might be stored and shared across various\ncommunication networks in GluADFL, ranging from highly interconnected (e.g.,\nrandom, performs the best among others) to more structured topologies (e.g.,\ncluster and ring), suitable for various social networks. The asynchronous\ntraining framework supports flexible participation. By adjusting the ratios of\ninactive participants, we found it remains stable if less than 70% are\ninactive. Our results confirm that GluADFL offers a practical,\nprivacy-preserving solution for BG prediction in T1D, significantly enhancing\nthe quality of diabetes management.",
      "tldr_zh": "本研究针对新诊断的Type 1 Diabetes (T1D) 患者因Continuous Glucose Monitoring (CGM) 数据不足而面临的Blood Glucose (BG) 预测“冷启动”问题，提出了一种隐私保护的GluADFL方法，该方法采用Asynchronous Decentralized Federated Learning 框架，实现跨患者数据协作训练。实验使用四个T1D数据集（涉及298名参与者）与八种基线方法比较，结果显示GluADFL在BG水平跨预测准确性上表现出色。GluADFL支持多种通信网络拓扑（如random、cluster和ring），并通过异步训练允许灵活参与，即使70%的参与者不活跃，系统仍保持稳定。该方法为T1D患者提供了一个实用、隐私保护的BG预测解决方案，提升了糖尿病管理质量。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.15346v1",
      "published_date": "2024-06-21 17:57:39 UTC",
      "updated_date": "2024-06-21 17:57:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T23:11:28.766270"
    },
    {
      "arxiv_id": "2406.15341v3",
      "title": "GenoTEX: An LLM Agent Benchmark for Automated Gene Expression Data Analysis",
      "title_zh": "翻译失败",
      "authors": [
        "Haoyang Liu",
        "Shuyu Chen",
        "Ye Zhang",
        "Haohan Wang"
      ],
      "abstract": "Recent advancements in machine learning have significantly improved the\nidentification of disease-associated genes from gene expression datasets.\nHowever, these processes often require extensive expertise and manual effort,\nlimiting their scalability. Large Language Model (LLM)-based agents have shown\npromise in automating these tasks due to their increasing problem-solving\nabilities. To support the evaluation and development of such methods, we\nintroduce GenoTEX, a benchmark dataset for the automated analysis of gene\nexpression data. GenoTEX provides analysis code and results for solving a wide\nrange of gene-trait association problems, encompassing dataset selection,\npreprocessing, and statistical analysis, in a pipeline that follows\ncomputational genomics standards. The benchmark includes expert-curated\nannotations from bioinformaticians to ensure accuracy and reliability. To\nprovide baselines for these tasks, we present GenoAgent, a team of LLM-based\nagents that adopt a multi-step programming workflow with flexible\nself-correction, to collaboratively analyze gene expression datasets. Our\nexperiments demonstrate the potential of LLM-based methods in analyzing genomic\ndata, while error analysis highlights the challenges and areas for future\nimprovement. We propose GenoTEX as a promising resource for benchmarking and\nenhancing automated methods for gene expression data analysis. The benchmark is\navailable at https://github.com/Liu-Hy/GenoTEX.",
      "tldr_zh": "本研究引入了GenoTEX，这是一个用于自动化基因表达数据分析的基准数据集，旨在解决传统方法依赖专业知识和手动努力的局限性。GenoTEX提供分析代码、结果和专家注释，涵盖数据集选择、预处理以及统计分析等步骤，遵循计算基因组学标准。同时，研究提出GenoAgent，一个基于Large Language Model (LLM)的代理团队，通过多步编程工作流和灵活自校正机制协作处理基因特质关联问题。实验结果显示LLM方法在基因表达数据分析中具有潜力，但也突出了错误分析中的挑战，为未来改进提供指导。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "q-bio.GN"
      ],
      "primary_category": "cs.LG",
      "comment": "31 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2406.15341v3",
      "published_date": "2024-06-21 17:55:24 UTC",
      "updated_date": "2025-04-08 17:09:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T23:11:39.171583"
    },
    {
      "arxiv_id": "2406.15339v1",
      "title": "Image Conductor: Precision Control for Interactive Video Synthesis",
      "title_zh": "Image Conductor: 交互式视频合成的精确控制",
      "authors": [
        "Yaowei Li",
        "Xintao Wang",
        "Zhaoyang Zhang",
        "Zhouxia Wang",
        "Ziyang Yuan",
        "Liangbin Xie",
        "Yuexian Zou",
        "Ying Shan"
      ],
      "abstract": "Filmmaking and animation production often require sophisticated techniques\nfor coordinating camera transitions and object movements, typically involving\nlabor-intensive real-world capturing. Despite advancements in generative AI for\nvideo creation, achieving precise control over motion for interactive video\nasset generation remains challenging. To this end, we propose Image Conductor,\na method for precise control of camera transitions and object movements to\ngenerate video assets from a single image. An well-cultivated training strategy\nis proposed to separate distinct camera and object motion by camera LoRA\nweights and object LoRA weights. To further address cinematographic variations\nfrom ill-posed trajectories, we introduce a camera-free guidance technique\nduring inference, enhancing object movements while eliminating camera\ntransitions. Additionally, we develop a trajectory-oriented video motion data\ncuration pipeline for training. Quantitative and qualitative experiments\ndemonstrate our method's precision and fine-grained control in generating\nmotion-controllable videos from images, advancing the practical application of\ninteractive video synthesis. Project webpage available at\nhttps://liyaowei-stu.github.io/project/ImageConductor/",
      "tldr_zh": "该论文提出 Image Conductor，一种从单张图像生成交互式视频资产的方法，实现对相机转换和物体运动的精确控制，以解决电影制作中劳动密集型问题的挑战。具体而言，该方法采用相机 LoRA 权重和物体 LoRA 权重来分离不同运动，并引入 camera-free guidance 技术来增强物体运动并消除不必要的相机转换，同时开发了 trajectory-oriented 视频运动数据整理管道。实验结果显示，Image Conductor 在定性和定量评估中表现出色的精确性和细粒度控制，提升了交互式视频合成的实用性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.MM"
      ],
      "primary_category": "cs.CV",
      "comment": "Project webpage available at\n  https://liyaowei-stu.github.io/project/ImageConductor/",
      "pdf_url": "http://arxiv.org/pdf/2406.15339v1",
      "published_date": "2024-06-21 17:55:05 UTC",
      "updated_date": "2024-06-21 17:55:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T23:11:52.267703"
    },
    {
      "arxiv_id": "2406.15334v3",
      "title": "Multimodal Task Vectors Enable Many-Shot Multimodal In-Context Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Brandon Huang",
        "Chancharik Mitra",
        "Assaf Arbelle",
        "Leonid Karlinsky",
        "Trevor Darrell",
        "Roei Herzig"
      ],
      "abstract": "The recent success of interleaved Large Multimodal Models (LMMs) in few-shot\nlearning suggests that in-context learning (ICL) with many examples can be\npromising for learning new tasks. However, this many-shot multimodal ICL\nsetting has one crucial problem: it is fundamentally limited by the model's\ncontext length set at pretraining. The problem is especially prominent in the\nmultimodal domain, which processes both text and images, requiring additional\ntokens. This motivates the need for a multimodal method to compress many shots\ninto fewer tokens without finetuning. In this work, we enable LMMs to perform\nmultimodal, many-shot in-context learning by leveraging Multimodal Task Vectors\n(MTV) -- compact implicit representations of in-context examples compressed in\nthe model's attention heads. Specifically, we first demonstrate the existence\nof such MTV in LMMs and then leverage these extracted MTV to enable many-shot\nin-context learning for various vision-and-language tasks. Our experiments\nsuggest that MTV can scale in performance with the number of compressed shots\nand generalize to similar out-of-domain tasks without additional context length\nfor inference. Code: https://github.com/Brandon3964/MultiModal-Task-Vector",
      "tldr_zh": "该研究解决了大型多模态模型 (LMMs) 在多样本 (many-shot) 多模态 In-Context Learning (ICL) 中的上下文长度限制问题，特别是处理文本和图像时。作者提出 Multimodal Task Vectors (MTV)，一种紧凑的隐式表示方法，通过压缩注意力头中的上下文示例，实现无需微调的示例压缩。实验结果表明，MTV 能随着压缩样本数量的增加而提升性能，并泛化到相似的领域外任务，而不需额外上下文长度。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Published in NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.15334v3",
      "published_date": "2024-06-21 17:50:02 UTC",
      "updated_date": "2024-12-20 01:24:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T23:12:03.154602"
    },
    {
      "arxiv_id": "2406.15330v2",
      "title": "Enhancing Large Language Model Performance with Gradient-Based Parameter Selection",
      "title_zh": "翻译失败",
      "authors": [
        "Haoling Li",
        "Xin Zhang",
        "Xiao Liu",
        "Yeyun Gong",
        "Yifan Wang",
        "Qi Chen",
        "Peng Cheng"
      ],
      "abstract": "Large language models (LLMs) have revolutionized lots of fields of research.\nAlthough it is well-known that fine-tuning is essential for enhancing the\ncapabilities of LLMs, existing research suggests that there is potential\nredundancy in the fine-tuning process and therefore proposes to update only a\nsubset of parameters. However, these methods fail to leverage the task-specific\ninformation to identify important parameters during training. Based on the\ninsight that gradients inherently contain information on task-specific data, we\npropose Gradient-Mask Tuning (GMT), a method that selectively updates\nparameters during training based on their gradient information. Specifically,\nwe compute the absolute values of the gradients and apply masking to those with\nrelatively smaller magnitudes. Our empirical results across various tasks\ndemonstrate that GMT not only outperforms traditional fine-tuning methods but\nalso elevates the upper limits of LLM performance. Further analysis indicates\nthat GMT exhibits insensitivity to mask ratio and possesses computational\nefficiency comparable to vanilla SFT.",
      "tldr_zh": "该研究针对大型语言模型（LLMs）的微调过程冗余问题，提出了一种基于梯度信息的参数选择方法Gradient-Mask Tuning (GMT)，它利用任务特定梯度数据来选择性地更新参数。GMT的具体机制是计算梯度的绝对值，并对较小梯度参数应用掩码，从而避免不必要的更新。实验结果显示，GMT在各种任务上优于传统fine-tuning方法，并显著提升了LLMs的性能上限。此外，该方法对掩码比例不敏感，且计算效率与标准SFT相当。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted by AAAI 2025",
      "pdf_url": "http://arxiv.org/pdf/2406.15330v2",
      "published_date": "2024-06-21 17:42:52 UTC",
      "updated_date": "2025-02-13 13:06:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T23:12:16.170312"
    },
    {
      "arxiv_id": "2406.15329v1",
      "title": "An End-to-End, Segmentation-Free, Arabic Handwritten Recognition Model on KHATT",
      "title_zh": "端到端的、无分割的、基于 KHATT 的阿拉伯语手写识别模型",
      "authors": [
        "Sondos Aabed",
        "Ahmad Khairaldin"
      ],
      "abstract": "An end-to-end, segmentation-free, deep learning model trained from scratch is\nproposed, leveraging DCNN for feature extraction, alongside Bidirectional\nLong-Short Term Memory (BLSTM) for sequence recognition and Connectionist\nTemporal Classification (CTC) loss function on the KHATT database. The training\nphase yields remarkable results 84% recognition rate on the test dataset at the\ncharacter level and 71% on the word level, establishing an image-based sequence\nrecognition framework that operates without segmentation only at the line\nlevel. The analysis and preprocessing of the KFUPM Handwritten Arabic TexT\n(KHATT) database are also presented. Finally, advanced image processing\ntechniques, including filtering, transformation, and line segmentation are\nimplemented. The importance of this work is highlighted by its wide-ranging\napplications. Including digitizing, documentation, archiving, and text\ntranslation in fields such as banking. Moreover, AHR serves as a pivotal tool\nfor making images searchable, enhancing information retrieval capabilities, and\nenabling effortless editing. This functionality significantly reduces the time\nand effort required for tasks such as Arabic data organization and\nmanipulation.",
      "tldr_zh": "本研究提出一个端到端的、无需分割的深度学习模型，用于阿拉伯手写体识别（AHR），其利用 DCNN 进行特征提取、BLSTM 进行序列识别，并采用 CTC 损失函数，在 KHATT 数据库上从零训练。模型在测试集上实现了 84% 的字符级识别率和 71% 的单词级识别率，仅在行级进行分割，从而简化了图像序列识别过程。该方法通过高级图像处理技术（如过滤和变换）提升了效率，并具有广泛应用，如数字化、文档归档、文本翻译和信息检索，尤其在银行业领域。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.15329v1",
      "published_date": "2024-06-21 17:42:07 UTC",
      "updated_date": "2024-06-21 17:42:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T23:12:30.716903"
    },
    {
      "arxiv_id": "2406.15325v1",
      "title": "Bug In the Code Stack: Can LLMs Find Bugs in Large Python Code Stacks",
      "title_zh": "翻译失败",
      "authors": [
        "Hokyung Lee",
        "Sumanyu Sharma",
        "Bing Hu"
      ],
      "abstract": "Recent research in Needle-in-a-Haystack (NIAH) benchmarks has explored the\ncapabilities of Large Language Models (LLMs) in retrieving contextual\ninformation from large text documents. However, as LLMs become increasingly\nintegrated into software development processes, it is crucial to evaluate their\nperformance in code-based environments. As LLMs are further developed for\nprogram synthesis, we need to ensure that LLMs can understand syntax and write\nsyntactically correct code. As a step in ensuring LLMs understand syntax, LLMs\ncan be evaluated in their ability to find and detect syntax bugs. Our\nbenchmark, Bug In The Code Stack (BICS), is designed to assess the ability of\nLLMs to identify simple syntax bugs within large source code. Our findings\nreveal three key insights: (1) code-based environments pose significantly more\nchallenge compared to text-based environments for retrieval tasks, (2) there is\na substantial performance disparity among different models, and (3) there is a\nnotable correlation between longer context lengths and performance degradation,\nthough the extent of this degradation varies between models.",
      "tldr_zh": "本研究探讨了大型语言模型（LLMs）在代码环境中的性能，特别针对其识别大型 Python 代码堆栈中简单语法错误的能力，并引入了新的基准测试 Bug In The Code Stack (BICS)。BICS 基于 Needle-in-a-Haystack (NIAH) 概念，评估 LLMs 在代码检索任务中的表现，相比文本环境更具挑战。研究发现：(1) 代码环境显著增加难度，(2) 不同模型间存在明显性能差距，(3) 更长的上下文长度通常导致性能下降，但程度因模型而异。",
      "categories": [
        "cs.AI",
        "cs.SE",
        "68T50",
        "I.2.7; D.2.5"
      ],
      "primary_category": "cs.AI",
      "comment": "8 pages",
      "pdf_url": "http://arxiv.org/pdf/2406.15325v1",
      "published_date": "2024-06-21 17:37:10 UTC",
      "updated_date": "2024-06-21 17:37:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T23:12:41.773946"
    },
    {
      "arxiv_id": "2406.15319v3",
      "title": "LongRAG: Enhancing Retrieval-Augmented Generation with Long-context LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Ziyan Jiang",
        "Xueguang Ma",
        "Wenhu Chen"
      ],
      "abstract": "In traditional RAG framework, the basic retrieval units are normally short.\nThe common retrievers like DPR normally work with 100-word Wikipedia\nparagraphs. Such a design forces the retriever to search over a large corpus to\nfind the `needle' unit. In contrast, the readers only need to generate answers\nfrom the short retrieved units. The imbalanced `heavy' retriever and `light'\nreader design can lead to sub-optimal performance. The loss of contextual\ninformation in the short, chunked units may increase the likelihood of\nintroducing hard negatives during the retrieval stage. Additionally, the reader\nmight not fully leverage the capabilities of recent advancements in LLMs. In\norder to alleviate the imbalance, we propose a new framework LongRAG,\nconsisting of a `long retriever' and a `long reader'. In the two\nWikipedia-based datasets, NQ and HotpotQA, LongRAG processes the entire\nWikipedia corpus into 4K-token units by grouping related documents. By\nincreasing the unit size, we significantly reduce the total number of units.\nThis greatly reduces the burden on the retriever, resulting in strong retrieval\nperformance with only a few (less than 8) top units. Without requiring any\ntraining, LongRAG achieves an EM of 62.7% on NQ and 64.3% on HotpotQA, which\nare on par with the (fully-trained) SoTA model. Furthermore, we test on two\nnon-Wikipedia-based datasets, Qasper and MultiFieldQA-en. LongRAG processes\neach individual document as a single (long) unit rather than chunking them into\nsmaller units. By doing so, we achieve an F1 score of 25.9% on Qasper and 57.5%\non MultiFieldQA-en. Our study offers insights into the future roadmap for\ncombining RAG with long-context LLMs.",
      "tldr_zh": "该论文指出，传统 RAG 框架中检索单位过短（如 100 字段落）会导致检索负担过重、上下文信息丢失和性能不佳，因此提出 LongRAG 框架，使用长上下文 LLMs 构建“长检索器”和“长读者”。LongRAG 通过将文档分组成 4K-token 单位，减少检索单位数量，并在 NQ 和 HotpotQA 数据集上无需训练即达到 62.7% 和 64.3% EM，与最先进模型相当；在 Qasper 和 MultiFieldQA-en 数据集上，分别获得 25.9% 和 57.5% F1 分数。研究为结合 RAG 与长上下文 LLMs 的未来发展提供了重要见解。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Technical Report",
      "pdf_url": "http://arxiv.org/pdf/2406.15319v3",
      "published_date": "2024-06-21 17:23:21 UTC",
      "updated_date": "2024-09-01 17:21:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T23:12:55.303893"
    },
    {
      "arxiv_id": "2406.15537v1",
      "title": "R&B -- Rhythm and Brain: Cross-subject Decoding of Music from Human Brain Activity",
      "title_zh": "翻译失败",
      "authors": [
        "Matteo Ferrante",
        "Matteo Ciferri",
        "Nicola Toschi"
      ],
      "abstract": "Music is a universal phenomenon that profoundly influences human experiences\nacross cultures. This study investigates whether music can be decoded from\nhuman brain activity measured with functional MRI (fMRI) during its perception.\nLeveraging recent advancements in extensive datasets and pre-trained\ncomputational models, we construct mappings between neural data and latent\nrepresentations of musical stimuli. Our approach integrates functional and\nanatomical alignment techniques to facilitate cross-subject decoding,\naddressing the challenges posed by the low temporal resolution and\nsignal-to-noise ratio (SNR) in fMRI data. Starting from the GTZan fMRI dataset,\nwhere five participants listened to 540 musical stimuli from 10 different\ngenres while their brain activity was recorded, we used the CLAP (Contrastive\nLanguage-Audio Pretraining) model to extract latent representations of the\nmusical stimuli and developed voxel-wise encoding models to identify brain\nregions responsive to these stimuli. By applying a threshold to the association\nbetween predicted and actual brain activity, we identified specific regions of\ninterest (ROIs) which can be interpreted as key players in music processing.\nOur decoding pipeline, primarily retrieval-based, employs a linear map to\nproject brain activity to the corresponding CLAP features. This enables us to\npredict and retrieve the musical stimuli most similar to those that originated\nthe fMRI data. Our results demonstrate state-of-the-art identification\naccuracy, with our methods significantly outperforming existing approaches. Our\nfindings suggest that neural-based music retrieval systems could enable\npersonalized recommendations and therapeutic applications. Future work could\nuse higher temporal resolution neuroimaging and generative models to improve\ndecoding accuracy and explore the neural underpinnings of music perception and\nemotion.",
      "tldr_zh": "这篇论文探讨了从 fMRI 测量的人类脑活动解码音乐的可能性，实现了跨-subject decoding，以理解音乐感知的神经机制。研究利用 CLAP 模型提取音乐刺激的潜在表示，并结合功能和解剖对齐技术、以及基于检索的线性映射管道，从 GTZan fMRI 数据集（涉及5名参与者听540首音乐）中识别关键脑区。结果显示，该方法显著优于现有方法，实现了最先进的音乐识别准确率。未来，这可应用于神经音乐检索系统的个性化推荐和治疗，并通过更高分辨率成像进一步提升。",
      "categories": [
        "q-bio.NC",
        "cs.AI",
        "cs.SD",
        "eess.AS"
      ],
      "primary_category": "q-bio.NC",
      "comment": "The first two authors contributed equally to this work",
      "pdf_url": "http://arxiv.org/pdf/2406.15537v1",
      "published_date": "2024-06-21 17:11:45 UTC",
      "updated_date": "2024-06-21 17:11:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T23:13:08.514261"
    },
    {
      "arxiv_id": "2406.15293v1",
      "title": "Grants4Companies: Applying Declarative Methods for Recommending and Reasoning About Business Grants in the Austrian Public Administration (System Description)",
      "title_zh": "翻译失败",
      "authors": [
        "Björn Lellmann",
        "Philipp Marek",
        "Markus Triska"
      ],
      "abstract": "We describe the methods and technologies underlying the application\nGrants4Companies. The application uses a logic-based expert system to display a\nlist of business grants suitable for the logged-in business. To evaluate\nsuitability of the grants, formal representations of their conditions are\nevaluated against properties of the business, taken from the registers of the\nAustrian public administration. The logical language for the representations of\nthe grant conditions is based on S-expressions. We further describe a Proof of\nConcept implementation of reasoning over the formalised grant conditions. The\nproof of concept is implemented in Common Lisp and interfaces with a reasoning\nengine implemented in Scryer Prolog. The application has recently gone live and\nis provided as part of the Business Service Portal by the Austrian Federal\nMinistry of Finance.",
      "tldr_zh": "这篇论文介绍了 Grants4Companies 系统，该系统应用声明式方法（declarative methods）来推荐和推理奥地利公共管理部门的商业资助，针对登录企业的属性进行匹配。系统使用逻辑-based 专家系统和基于 S-expressions 的正式语言，评估企业从公共注册中提取的属性是否符合资助条件。论文还描述了 Proof of Concept 的实现，利用 Common Lisp 和 Scryer Prolog 引擎进行推理，最终该应用已上线，作为奥地利联邦财政部商业服务门户的一部分。",
      "categories": [
        "cs.LO",
        "cs.AI"
      ],
      "primary_category": "cs.LO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.15293v1",
      "published_date": "2024-06-21 16:38:02 UTC",
      "updated_date": "2024-06-21 16:38:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T23:13:17.267183"
    },
    {
      "arxiv_id": "2406.15279v2",
      "title": "Safe Inputs but Unsafe Output: Benchmarking Cross-modality Safety Alignment of Large Vision-Language Model",
      "title_zh": "翻译失败",
      "authors": [
        "Siyin Wang",
        "Xingsong Ye",
        "Qinyuan Cheng",
        "Junwen Duan",
        "Shimin Li",
        "Jinlan Fu",
        "Xipeng Qiu",
        "Xuanjing Huang"
      ],
      "abstract": "As Artificial General Intelligence (AGI) becomes increasingly integrated into\nvarious facets of human life, ensuring the safety and ethical alignment of such\nsystems is paramount. Previous studies primarily focus on single-modality\nthreats, which may not suffice given the integrated and complex nature of\ncross-modality interactions. We introduce a novel safety alignment challenge\ncalled Safe Inputs but Unsafe Output (SIUO) to evaluate cross-modality safety\nalignment. Specifically, it considers cases where single modalities are safe\nindependently but could potentially lead to unsafe or unethical outputs when\ncombined. To empirically investigate this problem, we developed the SIUO, a\ncross-modality benchmark encompassing 9 critical safety domains, such as\nself-harm, illegal activities, and privacy violations. Our findings reveal\nsubstantial safety vulnerabilities in both closed- and open-source LVLMs, such\nas GPT-4V and LLaVA, underscoring the inadequacy of current models to reliably\ninterpret and respond to complex, real-world scenarios.",
      "tldr_zh": "该研究针对大型视觉语言模型(LVLMs)的跨模态安全对齐问题，引入了Safe Inputs but Unsafe Output (SIUO)挑战，以评估单个模态输入安全但组合后可能导致不安全输出的风险。研究者开发了一个跨模态基准，涵盖9个关键安全领域，如自残、非法活动和隐私侵犯。实验结果显示，现有模型如GPT-4V和LLaVA存在显著安全漏洞，无法可靠地处理复杂现实场景，从而凸显了提升AGI安全性的迫切需求。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.15279v2",
      "published_date": "2024-06-21 16:14:15 UTC",
      "updated_date": "2025-02-17 03:38:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T23:13:29.239946"
    },
    {
      "arxiv_id": "2406.15268v1",
      "title": "Towards Robust Training Datasets for Machine Learning with Ontologies: A Case Study for Emergency Road Vehicle Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Lynn Vonderhaar",
        "Timothy Elvira",
        "Tyler Procko",
        "Omar Ochoa"
      ],
      "abstract": "Countless domains rely on Machine Learning (ML) models, including\nsafety-critical domains, such as autonomous driving, which this paper focuses\non. While the black box nature of ML is simply a nuisance in some domains, in\nsafety-critical domains, this makes ML models difficult to trust. To fully\nutilize ML models in safety-critical domains, it would be beneficial to have a\nmethod to improve trust in model robustness and accuracy without human experts\nchecking each decision. This research proposes a method to increase trust in ML\nmodels used in safety-critical domains by ensuring the robustness and\ncompleteness of the model's training dataset. Because ML models embody what\nthey are trained with, ensuring the completeness of training datasets can help\nto increase the trust in the training of ML models. To this end, this paper\nproposes the use of a domain ontology and an image quality characteristic\nontology to validate the domain completeness and image quality robustness of a\ntraining dataset. This research also presents an experiment as a proof of\nconcept for this method, where ontologies are built for the emergency road\nvehicle domain.",
      "tldr_zh": "该研究针对安全关键领域（如自动驾驶）的Machine Learning (ML)模型，提出一种方法来提升对模型鲁棒性和准确性的信任，通过确保训练数据集的完整性和鲁棒性，而非依赖人类专家手动检查。主要方法涉及使用领域本体（domain ontology）和图像质量特征本体（image quality characteristic ontology）来验证数据集的领域完整性和图像质量稳定性。作为概念证明，该论文在紧急道路车辆检测领域构建了相关本体，并展示了该方法的可行性，有助于在安全关键应用中增强对ML模型的信任。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.15268v1",
      "published_date": "2024-06-21 16:03:38 UTC",
      "updated_date": "2024-06-21 16:03:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T23:13:40.377973"
    },
    {
      "arxiv_id": "2406.15259v2",
      "title": "V-RECS, a Low-Cost LLM4VIS Recommender with Explanations, Captioning and Suggestions",
      "title_zh": "翻译失败",
      "authors": [
        "Luca Podo",
        "Marco Angelini",
        "Paola Velardi"
      ],
      "abstract": "NL2VIS (natural language to visualization) is a promising and recent research\narea that involves interpreting natural language queries and translating them\ninto visualizations that accurately represent the underlying data. As we\nnavigate the era of big data, NL2VIS holds considerable application potential\nsince it greatly facilitates data exploration by non-expert users. Following\nthe increasingly widespread usage of generative AI in NL2VIS applications, in\nthis paper we present V-RECS, the first LLM-based Visual Recommender augmented\nwith explanations(E), captioning(C), and suggestions(S) for further data\nexploration. V-RECS' visualization narratives facilitate both response\nverification and data exploration by non-expert users. Furthermore, our\nproposed solution mitigates computational, controllability, and cost issues\nassociated with using powerful LLMs by leveraging a methodology to effectively\nfine-tune small models. To generate insightful visualization narratives, we use\nChain-of-Thoughts (CoT), a prompt engineering technique to help LLM identify\nand generate the logical steps to produce a correct answer. Since CoT is\nreported to perform poorly with small LLMs, we adopted a strategy in which a\nlarge LLM (GPT-4), acting as a Teacher, generates CoT-based instructions to\nfine-tune a small model, Llama-2-7B, which plays the role of a Student.\nExtensive experiments-based on a framework for the quantitative evaluation of\nAI-based visualizations and on manual assessment by a group of\nparticipants-show that V-RECS achieves performance scores comparable to GPT-4,\nat a much lower cost. The efficacy of the V-RECS teacher-student paradigm is\nalso demonstrated by the fact that the un-tuned Llama fails to perform the task\nin the vast majority of test cases. We release V-RECS for the visualization\ncommunity to assist visualization designers throughout the entire visualization\ngeneration process.",
      "tldr_zh": "本文提出 V-RECS，一种基于 LLM 的低成本可视化推荐系统，用于 NL2VIS（自然语言到可视化）任务，提供了解释（E）、标题（C）和建议（S），以帮助非专家用户验证响应和探索数据。系统采用 Chain-of-Thoughts (CoT) 提示工程技术，并通过 Teacher-Student 策略，使用 GPT-4 作为老师生成指令来微调小模型 Llama-2-7B，从而降低计算成本和提高可控性。实验显示，V-RECS 的性能与 GPT-4 相当，但成本显著降低，且已开源以支持可视化社区的发展。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.15259v2",
      "published_date": "2024-06-21 15:50:10 UTC",
      "updated_date": "2024-07-31 11:39:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T23:13:54.485121"
    },
    {
      "arxiv_id": "2406.15252v3",
      "title": "VideoScore: Building Automatic Metrics to Simulate Fine-grained Human Feedback for Video Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Xuan He",
        "Dongfu Jiang",
        "Ge Zhang",
        "Max Ku",
        "Achint Soni",
        "Sherman Siu",
        "Haonan Chen",
        "Abhranil Chandra",
        "Ziyan Jiang",
        "Aaran Arulraj",
        "Kai Wang",
        "Quy Duc Do",
        "Yuansheng Ni",
        "Bohan Lyu",
        "Yaswanth Narsupalli",
        "Rongqi Fan",
        "Zhiheng Lyu",
        "Yuchen Lin",
        "Wenhu Chen"
      ],
      "abstract": "The recent years have witnessed great advances in video generation. However,\nthe development of automatic video metrics is lagging significantly behind.\nNone of the existing metric is able to provide reliable scores over generated\nvideos. The main barrier is the lack of large-scale human-annotated dataset. In\nthis paper, we release VideoFeedback, the first large-scale dataset containing\nhuman-provided multi-aspect score over 37.6K synthesized videos from 11\nexisting video generative models. We train VideoScore (initialized from Mantis)\nbased on VideoFeedback to enable automatic video quality assessment.\nExperiments show that the Spearman correlation between VideoScore and humans\ncan reach 77.1 on VideoFeedback-test, beating the prior best metrics by about\n50 points. Further result on other held-out EvalCrafter, GenAI-Bench, and\nVBench show that VideoScore has consistently much higher correlation with human\njudges than other metrics. Due to these results, we believe VideoScore can\nserve as a great proxy for human raters to (1) rate different video models to\ntrack progress (2) simulate fine-grained human feedback in Reinforcement\nLearning with Human Feedback (RLHF) to improve current video generation models.",
      "tldr_zh": "该论文指出，视频生成技术取得了重大进展，但自动评估指标仍不完善，导致无法可靠地评分合成视频。研究者发布了首个大规模数据集VideoFeedback，包含37.6K个来自11个视频生成模型的合成视频及其人类多方面评分。基于此数据集，他们训练了VideoScore（从Mantis初始化），实现了自动视频质量评估。实验结果显示，VideoScore的Spearman相关性达77.1%，比现有最佳指标高出约50点，并在其他数据集如EvalCrafter和GenAI-Bench上表现出色，可作为人类评估的代理，用于跟踪模型进展和RLHF中的反馈模拟。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.15252v3",
      "published_date": "2024-06-21 15:43:46 UTC",
      "updated_date": "2024-10-14 04:08:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T23:14:06.441039"
    },
    {
      "arxiv_id": "2406.15231v4",
      "title": "Synthetic Lyrics Detection Across Languages and Genres",
      "title_zh": "翻译失败",
      "authors": [
        "Yanis Labrak",
        "Markus Frohmann",
        "Gabriel Meseguer-Brocal",
        "Elena V. Epure"
      ],
      "abstract": "In recent years, the use of large language models (LLMs) to generate music\ncontent, particularly lyrics, has gained in popularity. These advances provide\nvaluable tools for artists and enhance their creative processes, but they also\nraise concerns about copyright violations, consumer satisfaction, and content\nspamming. Previous research has explored content detection in various domains.\nHowever, no work has focused on the text modality, lyrics, in music. To address\nthis gap, we curated a diverse dataset of real and synthetic lyrics from\nmultiple languages, music genres, and artists. The generation pipeline was\nvalidated using both humans and automated methods. We performed a thorough\nevaluation of existing synthetic text detection approaches on lyrics, a\npreviously unexplored data type. We also investigated methods to adapt the\nbest-performing features to lyrics through unsupervised domain adaptation.\nFollowing both music and industrial constraints, we examined how well these\napproaches generalize across languages, scale with data availability, handle\nmultilingual language content, and perform on novel genres in few-shot\nsettings. Our findings show promising results that could inform policy\ndecisions around AI-generated music and enhance transparency for users.",
      "tldr_zh": "本研究探讨了大型语言模型（LLMs）生成歌词的流行性及其潜在问题，如版权侵犯、消费者满意度和内容垃圾，并填补了歌词合成检测领域的空白。研究者构建了一个多样化的数据集，包括真实和合成歌词，覆盖多种语言、音乐类型和艺术家，并通过人类和自动化方法验证生成管道。然后，他们评估了现有合成文本检测方法在歌词上的表现，并使用无监督领域适应技术来优化这些方法。实验结果显示，这些方法在跨语言、数据规模、多语种内容和新类型（少样本场景）上具有良好的泛化能力，为AI生成音乐的政策决策和用户透明度提供了有价值的见解。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Published in the TrustNLP Workshop at NAACL 2025",
      "pdf_url": "http://arxiv.org/pdf/2406.15231v4",
      "published_date": "2024-06-21 15:19:21 UTC",
      "updated_date": "2025-04-24 07:21:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T23:14:18.551347"
    },
    {
      "arxiv_id": "2406.15225v1",
      "title": "Deep UAV Path Planning with Assured Connectivity in Dense Urban Setting",
      "title_zh": "翻译失败",
      "authors": [
        "Jiyong Oh",
        "Syed M. Raza",
        "Lusungu J. Mwasinga",
        "Moonseong Kim",
        "Hyunseung Choo"
      ],
      "abstract": "Unmanned Ariel Vehicle (UAV) services with 5G connectivity is an emerging\nfield with numerous applications. Operator-controlled UAV flights and manual\nstatic flight configurations are major limitations for the wide adoption of\nscalability of UAV services. Several services depend on excellent UAV\nconnectivity with a cellular network and maintaining it is challenging in\npredetermined flight paths. This paper addresses these limitations by proposing\na Deep Reinforcement Learning (DRL) framework for UAV path planning with\nassured connectivity (DUPAC). During UAV flight, DUPAC determines the best\nroute from a defined source to the destination in terms of distance and signal\nquality. The viability and performance of DUPAC are evaluated under simulated\nreal-world urban scenarios using the Unity framework. The results confirm that\nDUPAC achieves an autonomous UAV flight path similar to base method with only\n2% increment while maintaining an average 9% better connection quality\nthroughout the flight.",
      "tldr_zh": "这篇论文针对密集城市环境中无人机的路径规划问题，提出了一种基于Deep Reinforcement Learning (DRL) 的框架DUPAC，以确保5G连接性并克服操作员控制和手动配置的局限性。DUPAC通过优化从源点到目的地的飞行路线，兼顾距离和信号质量，在Unity框架的模拟真实场景中进行了评估。结果表明，DUPAC的路径仅比基准方法增加2%，但平均连接质量提高了9%，为可扩展的无人机服务提供了更可靠的解决方案。",
      "categories": [
        "cs.AI",
        "cs.RO",
        "eess.SP"
      ],
      "primary_category": "cs.AI",
      "comment": "5 pages, 4 figures, Published in the 2024 IEEE Network Operations and\n  Management Symposium (NOMS 2024)",
      "pdf_url": "http://arxiv.org/pdf/2406.15225v1",
      "published_date": "2024-06-21 15:10:25 UTC",
      "updated_date": "2024-06-21 15:10:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T23:14:31.610158"
    },
    {
      "arxiv_id": "2406.15213v2",
      "title": "Backdooring Bias into Text-to-Image Models",
      "title_zh": "翻译失败",
      "authors": [
        "Ali Naseh",
        "Jaechul Roh",
        "Eugene Bagdasaryan",
        "Amir Houmansadr"
      ],
      "abstract": "Text-conditional diffusion models, i.e. text-to-image, produce eye-catching\nimages that represent descriptions given by a user. These images often depict\nbenign concepts but could also carry other purposes. Specifically, visual\ninformation is easy to comprehend and could be weaponized for propaganda -- a\nserious challenge given widespread usage and deployment of generative models.\nIn this paper, we show that an adversary can add an arbitrary bias through a\nbackdoor attack that would affect even benign users generating images. While a\nuser could inspect a generated image to comply with the given text description,\nour attack remains stealthy as it preserves semantic information given in the\ntext prompt. Instead, a compromised model modifies other unspecified features\nof the image to add desired biases (that increase by 4-8x). Furthermore, we\nshow how the current state-of-the-art generative models make this attack both\ncheap and feasible for any adversary, with costs ranging between $12-$18. We\nevaluate our attack over various types of triggers, adversary objectives, and\nbiases and discuss mitigations and future work. Our code is available at\nhttps://github.com/jrohsc/Backdororing_Bias.",
      "tldr_zh": "这篇论文探讨了如何通过后门攻击（backdoor attack）向文本到图像模型（text-to-image models）注入任意偏见（bias），使生成的图像在保留文本提示语义信息的同时，悄然增强预设的偏见效果，导致偏见强度增加4-8倍。攻击者可以利用当前先进的生成模型，以低成本（仅12-18美元）实现这一操作，即使对无辜用户也产生影响。研究评估了各种触发器（triggers）、攻击目标和偏见类型，并讨论了潜在的缓解策略和未来工作，以提升模型的安全性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.15213v2",
      "published_date": "2024-06-21 14:53:19 UTC",
      "updated_date": "2024-10-10 21:21:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T23:14:44.507992"
    },
    {
      "arxiv_id": "2406.15211v1",
      "title": "How Effective is GPT-4 Turbo in Generating School-Level Questions from Textbooks Based on Bloom's Revised Taxonomy?",
      "title_zh": "基于布鲁姆修订分类法，GPT-4 Turbo 在从教科书中生成学校级别问题的有效性如何？",
      "authors": [
        "Subhankar Maity",
        "Aniket Deroy",
        "Sudeshna Sarkar"
      ],
      "abstract": "We evaluate the effectiveness of GPT-4 Turbo in generating educational\nquestions from NCERT textbooks in zero-shot mode. Our study highlights GPT-4\nTurbo's ability to generate questions that require higher-order thinking\nskills, especially at the \"understanding\" level according to Bloom's Revised\nTaxonomy. While we find a notable consistency between questions generated by\nGPT-4 Turbo and those assessed by humans in terms of complexity, there are\noccasional differences. Our evaluation also uncovers variations in how humans\nand machines evaluate question quality, with a trend inversely related to\nBloom's Revised Taxonomy levels. These findings suggest that while GPT-4 Turbo\nis a promising tool for educational question generation, its efficacy varies\nacross different cognitive levels, indicating a need for further refinement to\nfully meet educational standards.",
      "tldr_zh": "本研究评估了 GPT-4 Turbo 在零样本模式下从 NCERT 教科书中生成学校级教育问题的有效性，重点基于 Bloom's Revised Taxonomy。结果显示，GPT-4 Turbo 能生成需要更高阶思考技能的问题，尤其在 \"understanding\" 水平上，与人类评估在复杂性方面表现出显著一致性。研究还发现，人类和机器在问题质量评估上存在差异，这种差异与 Bloom's Revised Taxonomy 的认知水平呈反向趋势，表明 GPT-4 Turbo 虽有潜力，但需进一步优化以适应教育标准。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted at Learnersourcing: Student-Generated Content @ Scale 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.15211v1",
      "published_date": "2024-06-21 14:52:37 UTC",
      "updated_date": "2024-06-21 14:52:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T23:14:55.996916"
    },
    {
      "arxiv_id": "2406.15198v1",
      "title": "Exploring the Efficacy of Robotic Assistants with ChatGPT and Claude in Enhancing ADHD Therapy: Innovating Treatment Paradigms",
      "title_zh": "翻译失败",
      "authors": [
        "Santiago Berrezueta-Guzman",
        "Mohanad Kandil",
        "María-Luisa Martín-Ruiz",
        "Iván Pau-de-la-Cruz",
        "Stephan Krusche"
      ],
      "abstract": "Attention Deficit Hyperactivity Disorder (ADHD) is a neurodevelopmental\ncondition characterized by inattention, hyperactivity, and impulsivity, which\ncan significantly impact an individual's daily functioning and quality of life.\nOccupational therapy plays a crucial role in managing ADHD by fostering the\ndevelopment of skills needed for daily living and enhancing an individual's\nability to participate fully in school, home, and social situations. Recent\nstudies highlight the potential of integrating Large Language Models (LLMs)\nlike ChatGPT and Socially Assistive Robots (SAR) to improve psychological\ntreatments. This integration aims to overcome existing limitations in mental\nhealth therapy by providing tailored support and adapting to the unique needs\nof this sensitive group. However, there remains a significant gap in research\nexploring the combined use of these advanced technologies in ADHD therapy,\nsuggesting an opportunity for novel therapeutic approaches.\n  Thus, we integrated two advanced language models, ChatGPT-4 Turbo and\nClaude-3 Opus, into a robotic assistant to explore how well each model performs\nin robot-assisted interactions. Additionally, we have compared their\nperformance in a simulated therapy scenario to gauge their effectiveness\nagainst a clinically validated customized model. The results of this study show\nthat ChatGPT-4 Turbo excelled in performance and responsiveness, making it\nsuitable for time-sensitive applications. Claude-3 Opus, on the other hand,\nshowed strengths in understanding, coherence, and ethical considerations,\nprioritizing safe and engaging interactions. Both models demonstrated\ninnovation and adaptability, but ChatGPT-4 Turbo offered greater ease of\nintegration and broader language support. The selection between them hinges on\nthe specific demands of ADHD therapy.",
      "tldr_zh": "这篇论文探讨了使用大型语言模型（LLMs）如 ChatGPT-4 Turbo 和 Claude-3 Opus 与机器人助手（SAR）整合，以提升 ADHD 治疗的效果，旨在克服传统心理治疗的局限性。研究方法包括将这些模型嵌入机器人助手中，并通过模拟治疗场景与临床验证的自定义模型进行比较。结果显示，ChatGPT-4 Turbo 在性能和响应性方面表现出色，适合时间敏感应用，而 Claude-3 Opus 更强在理解、一致性和伦理考虑上；最终模型选择取决于 ADHD 治疗的具体需求。该研究为创新治疗范式提供了新见解，填补了相关领域的技术整合空白。",
      "categories": [
        "cs.AI",
        "cs.HC",
        "cs.SE"
      ],
      "primary_category": "cs.AI",
      "comment": "Paper accepted at the 20th International Conference on Intelligent\n  Environments",
      "pdf_url": "http://arxiv.org/pdf/2406.15198v1",
      "published_date": "2024-06-21 14:38:25 UTC",
      "updated_date": "2024-06-21 14:38:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T23:15:10.185900"
    },
    {
      "arxiv_id": "2406.15187v2",
      "title": "UDA: A Benchmark Suite for Retrieval Augmented Generation in Real-world Document Analysis",
      "title_zh": "翻译失败",
      "authors": [
        "Yulong Hui",
        "Yao Lu",
        "Huanchen Zhang"
      ],
      "abstract": "The use of Retrieval-Augmented Generation (RAG) has improved Large Language\nModels (LLMs) in collaborating with external data, yet significant challenges\nexist in real-world scenarios. In areas such as academic literature and finance\nquestion answering, data are often found in raw text and tables in HTML or PDF\nformats, which can be lengthy and highly unstructured. In this paper, we\nintroduce a benchmark suite, namely Unstructured Document Analysis (UDA), that\ninvolves 2,965 real-world documents and 29,590 expert-annotated Q&A pairs. We\nrevisit popular LLM- and RAG-based solutions for document analysis and evaluate\nthe design choices and answer qualities across multiple document domains and\ndiverse query types. Our evaluation yields interesting findings and highlights\nthe importance of data parsing and retrieval. We hope our benchmark can shed\nlight and better serve real-world document analysis applications. The benchmark\nsuite and code can be found at https://github.com/qinchuanhui/UDA-Benchmark.",
      "tldr_zh": "这篇论文引入了UDA基准套件，用于评估Retrieval-Augmented Generation (RAG)在真实世界文档分析中的性能，针对LLM (Large Language Models) 处理原始文本和表格（如HTML或PDF格式）时的挑战。UDA包含2,965个真实文档和29,590个专家标注的Q&A对，并对流行LLM和RAG解决方案的设计选择和答案质量进行了全面评估，涵盖多个文档领域和查询类型。研究发现数据解析和检索至关重要，并希望这一基准能为真实世界的文档分析应用提供指导和改进方向。",
      "categories": [
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.15187v2",
      "published_date": "2024-06-21 14:29:39 UTC",
      "updated_date": "2024-10-31 10:10:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T23:15:20.281571"
    },
    {
      "arxiv_id": "2406.15175v1",
      "title": "Enhancing Idiomatic Representation in Multiple Languages via an Adaptive Contrastive Triplet Loss",
      "title_zh": "通过自适应对比三元组损失增强多种语言中的习语表示",
      "authors": [
        "Wei He",
        "Marco Idiart",
        "Carolina Scarton",
        "Aline Villavicencio"
      ],
      "abstract": "Accurately modeling idiomatic or non-compositional language has been a\nlongstanding challenge in Natural Language Processing (NLP). This is partly\nbecause these expressions do not derive their meanings solely from their\nconstituent words, but also due to the scarcity of relevant data resources, and\ntheir impact on the performance of downstream tasks such as machine translation\nand simplification. In this paper we propose an approach to model idiomaticity\neffectively using a triplet loss that incorporates the asymmetric contribution\nof components words to an idiomatic meaning for training language models by\nusing adaptive contrastive learning and resampling miners to build an\nidiomatic-aware learning objective. Our proposed method is evaluated on a\nSemEval challenge and outperforms previous alternatives significantly in many\nmetrics.",
      "tldr_zh": "本文针对自然语言处理(NLP)中建模习语性(idiomatic or non-compositional language)的长期挑战，提出了一种新方法，利用adaptive contrastive triplet loss来捕捉组成单词对习语含义的不对称贡献。方法通过自适应对比学习和重采样挖掘器(resampling miners)构建了一个专注于习语的训练目标，从而提升语言模型在多语言环境下的表现。在SemEval challenge的评估中，该方法在多个指标上显著优于现有替代方案。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.15175v1",
      "published_date": "2024-06-21 14:21:41 UTC",
      "updated_date": "2024-06-21 14:21:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T23:15:31.741586"
    },
    {
      "arxiv_id": "2406.15173v1",
      "title": "Évaluation des capacités de réponse de larges modèles de langage (LLM) pour des questions d'historiens",
      "title_zh": "翻译失败",
      "authors": [
        "Mathieu Chartier",
        "Nabil Dakkoune",
        "Guillaume Bourgeois",
        "Stéphane Jean"
      ],
      "abstract": "Large Language Models (LLMs) like ChatGPT or Bard have revolutionized\ninformation retrieval and captivated the audience with their ability to\ngenerate custom responses in record time, regardless of the topic. In this\narticle, we assess the capabilities of various LLMs in producing reliable,\ncomprehensive, and sufficiently relevant responses about historical facts in\nFrench. To achieve this, we constructed a testbed comprising numerous\nhistory-related questions of varying types, themes, and levels of difficulty.\nOur evaluation of responses from ten selected LLMs reveals numerous\nshortcomings in both substance and form. Beyond an overall insufficient\naccuracy rate, we highlight uneven treatment of the French language, as well as\nissues related to verbosity and inconsistency in the responses provided by\nLLMs.",
      "tldr_zh": "本研究评估了大型语言模型(LLMs)如ChatGPT和Bard在回答历史相关问题时的能力，焦点在于生成可靠、全面且相关的法语响应。研究者构建了一个测试集，包含各种类型、主题和难度的历史问题，并对十个LLMs的响应进行了分析。结果显示，LLMs存在整体准确率不足、对法语处理不均匀、响应冗长以及不一致等问题，突显了这些模型在历史事实检索中的局限性。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "in French language",
      "pdf_url": "http://arxiv.org/pdf/2406.15173v1",
      "published_date": "2024-06-21 14:19:57 UTC",
      "updated_date": "2024-06-21 14:19:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T23:15:42.629109"
    },
    {
      "arxiv_id": "2406.15534v1",
      "title": "Geneverse: A collection of Open-source Multimodal Large Language Models for Genomic and Proteomic Research",
      "title_zh": "翻译失败",
      "authors": [
        "Tianyu Liu",
        "Yijia Xiao",
        "Xiao Luo",
        "Hua Xu",
        "W. Jim Zheng",
        "Hongyu Zhao"
      ],
      "abstract": "The applications of large language models (LLMs) are promising for biomedical\nand healthcare research. Despite the availability of open-source LLMs trained\nusing a wide range of biomedical data, current research on the applications of\nLLMs to genomics and proteomics is still limited. To fill this gap, we propose\na collection of finetuned LLMs and multimodal LLMs (MLLMs), known as Geneverse,\nfor three novel tasks in genomic and proteomic research. The models in\nGeneverse are trained and evaluated based on domain-specific datasets, and we\nuse advanced parameter-efficient finetuning techniques to achieve the model\nadaptation for tasks including the generation of descriptions for gene\nfunctions, protein function inference from its structure, and marker gene\nselection from spatial transcriptomic data. We demonstrate that adapted LLMs\nand MLLMs perform well for these tasks and may outperform closed-source\nlarge-scale models based on our evaluations focusing on both truthfulness and\nstructural correctness. All of the training strategies and base models we used\nare freely accessible.",
      "tldr_zh": "该论文提出 Geneverse，这是一个开源的 Multimodal Large Language Models (MLLMs) 集合，旨在填补大型语言模型 (LLMs) 在基因组和蛋白质组研究中的应用空白。研究团队使用先进的参数高效微调技术，对模型进行适应性训练，针对三个新任务：生成基因功能描述、从蛋白结构推断功能，以及从空间转录组数据中选择标记基因。实验评估显示，Geneverse 的模型在真实性和结构正确性方面表现出色，甚至可能优于封闭源大型模型，且所有训练策略和基础模型均免费可访问。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "q-bio.QM"
      ],
      "primary_category": "cs.LG",
      "comment": "8 pages",
      "pdf_url": "http://arxiv.org/pdf/2406.15534v1",
      "published_date": "2024-06-21 14:19:10 UTC",
      "updated_date": "2024-06-21 14:19:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T23:15:56.743237"
    },
    {
      "arxiv_id": "2406.15168v2",
      "title": "This actually looks like that: Proto-BagNets for local and global interpretability-by-design",
      "title_zh": "翻译失败",
      "authors": [
        "Kerol Djoumessi",
        "Bubacarr Bah",
        "Laura Kühlewein",
        "Philipp Berens",
        "Lisa Koch"
      ],
      "abstract": "Interpretability is a key requirement for the use of machine learning models\nin high-stakes applications, including medical diagnosis. Explaining black-box\nmodels mostly relies on post-hoc methods that do not faithfully reflect the\nmodel's behavior. As a remedy, prototype-based networks have been proposed, but\ntheir interpretability is limited as they have been shown to provide coarse,\nunreliable, and imprecise explanations. In this work, we introduce\nProto-BagNets, an interpretable-by-design prototype-based model that combines\nthe advantages of bag-of-local feature models and prototype learning to provide\nmeaningful, coherent, and relevant prototypical parts needed for accurate and\ninterpretable image classification tasks. We evaluated the Proto-BagNet for\ndrusen detection on publicly available retinal OCT data. The Proto-BagNet\nperformed comparably to the state-of-the-art interpretable and\nnon-interpretable models while providing faithful, accurate, and clinically\nmeaningful local and global explanations. The code is available at\nhttps://github.com/kdjoumessi/Proto-BagNets.",
      "tldr_zh": "本文提出 Proto-BagNets，一种可解释性设计的原型模型，旨在解决黑箱模型的解释性问题，如 post-hoc methods 带来的不忠实解释。Proto-BagNets 结合 bag-of-local feature models 和 prototype learning 的优势，提供有意义的、连贯的原型部分，支持准确的图像分类任务。实验在公开视网膜 OCT 数据上评估了该模型用于 drusen 检测，结果显示其性能与最先进的可解释和不可解释模型相当，同时提供忠实、准确且临床相关的局部和全局解释。代码已在 GitHub 上开源。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.15168v2",
      "published_date": "2024-06-21 14:12:15 UTC",
      "updated_date": "2024-06-24 08:13:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T23:16:08.865715"
    },
    {
      "arxiv_id": "2406.15156v2",
      "title": "Reconsidering Faithfulness in Regular, Self-Explainable and Domain Invariant GNNs",
      "title_zh": "翻译失败",
      "authors": [
        "Steve Azzolin",
        "Antonio Longa",
        "Stefano Teso",
        "Andrea Passerini"
      ],
      "abstract": "As Graph Neural Networks (GNNs) become more pervasive, it becomes paramount\nto build reliable tools for explaining their predictions. A core desideratum is\nthat explanations are \\textit{faithful}, \\ie that they portray an accurate\npicture of the GNN's reasoning process. However, a number of different\nfaithfulness metrics exist, begging the question of what is faithfulness\nexactly and how to achieve it. We make three key contributions. We begin by\nshowing that \\textit{existing metrics are not interchangeable} -- \\ie\nexplanations attaining high faithfulness according to one metric may be\nunfaithful according to others -- and can systematically ignore important\nproperties of explanations. We proceed to show that, surprisingly,\n\\textit{optimizing for faithfulness is not always a sensible design goal}.\nSpecifically, we prove that for injective regular GNN architectures, perfectly\nfaithful explanations are completely uninformative. This does not apply to\nmodular GNNs, such as self-explainable and domain-invariant architectures,\nprompting us to study the relationship between architectural choices and\nfaithfulness. Finally, we show that \\textit{faithfulness is tightly linked to\nout-of-distribution generalization}, in that simply ensuring that a GNN can\ncorrectly recognize the domain-invariant subgraph, as prescribed by the\nliterature, does not guarantee that it is invariant unless this subgraph is\nalso faithful.The code is publicly available on GitHub",
      "tldr_zh": "该研究重新审视了图神经网络(GNNs)中解释的忠实性(faithfulness)，指出现有 faithfulness 指标并非互换，且可能忽略关键属性。研究证明，对于可注入的常规 GNN 架构，优化 faithfulness 可能导致解释完全缺乏信息量，而 modular GNNs 如 self-explainable 和 domain-invariant 架构则能更好地实现此目标。最终，论文揭示 faithfulness 与 out-of-distribution 泛化密切相关，仅确保 GNN 识别 domain-invariant 子图不足以实现不变性，除非该子图本身是 faithful。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Uploading ICLR25 camera ready version",
      "pdf_url": "http://arxiv.org/pdf/2406.15156v2",
      "published_date": "2024-06-21 14:01:23 UTC",
      "updated_date": "2025-04-10 08:55:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T23:16:20.353198"
    },
    {
      "arxiv_id": "2406.15152v3",
      "title": "Generative Topological Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Alona Levy-Jurgenson",
        "Zohar Yakhini"
      ],
      "abstract": "Generative methods have recently seen significant improvements by generating\nin a lower-dimensional latent representation of the data. However, many of the\ngenerative methods applied in the latent space remain complex and difficult to\ntrain. Further, it is not entirely clear why transitioning to a\nlower-dimensional latent space can improve generative quality. In this work, we\nintroduce a new and simple generative method grounded in topology theory --\nGenerative Topological Networks (GTNs) -- which also provides insights into why\nlower-dimensional latent-space representations might be better-suited for data\ngeneration. GTNs are simple to train -- they employ a standard supervised\nlearning approach and do not suffer from common generative pitfalls such as\nmode collapse, posterior collapse or the need to pose constraints on the neural\nnetwork architecture. We demonstrate the use of GTNs on several datasets,\nincluding MNIST, CelebA, CIFAR-10 and the Hands and Palm Images dataset by\ntraining GTNs on a lower-dimensional latent representation of the data. We show\nthat GTNs can improve upon VAEs and that they are quick to converge, generating\nrealistic samples in early epochs. Further, we use the topological\nconsiderations behind the development of GTNs to offer insights into why\ngenerative models may benefit from operating on a lower-dimensional latent\nspace, highlighting the important link between the intrinsic dimension of the\ndata and the dimension in which the data is generated. Particularly, we\ndemonstrate that generating in high dimensional ambient spaces may be a\ncontributing factor to out-of-distribution samples generated by diffusion\nmodels. We also highlight other topological properties that are important to\nconsider when using and designing generative models. Our code is available at:\nhttps://github.com/alonalj/GTN",
      "tldr_zh": "本研究引入了Generative Topological Networks (GTNs)，一种基于拓扑理论的简单生成方法，通过在低维潜在空间中生成数据来提升生成质量，并避免了传统生成模型常见的模式崩溃（mode collapse）和后验崩溃（posterior collapse）等问题。GTNs采用标准监督学习训练，易于实现，并在MNIST、CelebA、CIFAR-10和Hands and Palm Images数据集上表现优于VAEs，能够快速收敛并生成逼真样本。论文还通过拓扑分析解释了低维潜在空间的优势，指出高维环境可能导致扩散模型生成分布外样本，并强调数据内在维度在生成过程中的关键作用。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.15152v3",
      "published_date": "2024-06-21 13:55:34 UTC",
      "updated_date": "2025-01-21 14:38:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T23:16:32.630827"
    },
    {
      "arxiv_id": "2406.15149v2",
      "title": "Gaussian Splatting to Real World Flight Navigation Transfer with Liquid Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Alex Quach",
        "Makram Chahine",
        "Alexander Amini",
        "Ramin Hasani",
        "Daniela Rus"
      ],
      "abstract": "Simulators are powerful tools for autonomous robot learning as they offer\nscalable data generation, flexible design, and optimization of trajectories.\nHowever, transferring behavior learned from simulation data into the real world\nproves to be difficult, usually mitigated with compute-heavy domain\nrandomization methods or further model fine-tuning. We present a method to\nimprove generalization and robustness to distribution shifts in sim-to-real\nvisual quadrotor navigation tasks. To this end, we first build a simulator by\nintegrating Gaussian Splatting with quadrotor flight dynamics, and then, train\nrobust navigation policies using Liquid neural networks. In this way, we obtain\na full-stack imitation learning protocol that combines advances in 3D Gaussian\nsplatting radiance field rendering, crafty programming of expert demonstration\ntraining data, and the task understanding capabilities of Liquid networks.\nThrough a series of quantitative flight tests, we demonstrate the robust\ntransfer of navigation skills learned in a single simulation scene directly to\nthe real world. We further show the ability to maintain performance beyond the\ntraining environment under drastic distribution and physical environment\nchanges. Our learned Liquid policies, trained on single target manoeuvres\ncurated from a photorealistic simulated indoor flight only, generalize to\nmulti-step hikes onboard a real hardware platform outdoors.",
      "tldr_zh": "本研究提出了一种方法，通过整合 Gaussian Splatting 与四旋翼飞行动力学构建模拟器，并使用 Liquid neural networks 训练鲁棒的导航策略，以改善 sim-to-real 视觉导航任务的泛化性和鲁棒性。该方法结合了 3D Gaussian Splatting 辐射场渲染、专家演示训练数据编程以及 Liquid 网络的任务理解能力，形成一个完整的模仿学习协议。实验结果显示，训练于单一模拟场景的导航政策能够直接转移到真实世界，并在剧烈的分布和物理环境变化下（如从室内模拟到室外多步飞行）保持高性能。总的来说，此方法为自主机器人学习提供了更高效的真实世界应用路径。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV",
        "68T40, 68U20, 93C85",
        "I.2.9; I.2.6"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.15149v2",
      "published_date": "2024-06-21 13:48:37 UTC",
      "updated_date": "2024-10-16 19:28:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T23:16:45.661004"
    },
    {
      "arxiv_id": "2406.15130v1",
      "title": "Assessing Good, Bad and Ugly Arguments Generated by ChatGPT: a New Dataset, its Methodology and Associated Tasks",
      "title_zh": "翻译失败",
      "authors": [
        "Victor Hugo Nascimento Rocha",
        "Igor Cataneo Silveira",
        "Paulo Pirozelli",
        "Denis Deratani Mauá",
        "Fabio Gagliardi Cozman"
      ],
      "abstract": "The recent success of Large Language Models (LLMs) has sparked concerns about\ntheir potential to spread misinformation. As a result, there is a pressing need\nfor tools to identify ``fake arguments'' generated by such models. To create\nthese tools, examples of texts generated by LLMs are needed. This paper\nintroduces a methodology to obtain good, bad and ugly arguments from\nargumentative essays produced by ChatGPT, OpenAI's LLM. We then describe a\nnovel dataset containing a set of diverse arguments, ArGPT. We assess the\neffectiveness of our dataset and establish baselines for several\nargumentation-related tasks. Finally, we show that the artificially generated\ndata relates well to human argumentation and thus is useful as a tool to train\nand test systems for the defined tasks.",
      "tldr_zh": "这篇论文针对大型语言模型(LLMs)生成的错误信息问题，提出了一种方法从ChatGPT的论说文中提取good, bad and ugly arguments，以创建识别“假arguments”的工具。研究者开发了一个新数据集ArGPT，包含多样化的arguments，并为argumentation-related tasks建立了基线模型。实验结果显示，ArGPT与人类论证高度相关，因此可有效用于训练和测试相关系统。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.15130v1",
      "published_date": "2024-06-21 13:27:10 UTC",
      "updated_date": "2024-06-21 13:27:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T23:16:57.930129"
    },
    {
      "arxiv_id": "2406.15128v1",
      "title": "A Wavelet Guided Attention Module for Skin Cancer Classification with Gradient-based Feature Fusion",
      "title_zh": "翻译失败",
      "authors": [
        "Ayush Roy",
        "Sujan Sarkar",
        "Sohom Ghosal",
        "Dmitrii Kaplun",
        "Asya Lyanova",
        "Ram Sarkar"
      ],
      "abstract": "Skin cancer is a highly dangerous type of cancer that requires an accurate\ndiagnosis from experienced physicians. To help physicians diagnose skin cancer\nmore efficiently, a computer-aided diagnosis (CAD) system can be very helpful.\nIn this paper, we propose a novel model, which uses a novel attention mechanism\nto pinpoint the differences in features across the spatial dimensions and\nsymmetry of the lesion, thereby focusing on the dissimilarities of various\nclasses based on symmetry, uniformity in texture and color, etc. Additionally,\nto take into account the variations in the boundaries of the lesions for\ndifferent classes, we employ a gradient-based fusion of wavelet and soft\nattention-aided features to extract boundary information of skin lesions. We\nhave tested our model on the multi-class and highly class-imbalanced dataset,\ncalled HAM10000, and achieved promising results, with a 91.17\\% F1-score and\n90.75\\% accuracy. The code is made available at:\nhttps://github.com/AyushRoy2001/WAGF-Fusion.",
      "tldr_zh": "本研究针对皮肤癌诊断的准确性需求，提出了一种基于小波引导注意力模块(Wavelet Guided Attention Module)的计算机辅助诊断(CAD)系统，该模块通过关注特征在空间维度和对称性的差异，聚焦于不同类别间的纹理、颜色均匀性和边界变化。系统进一步采用基于梯度的特征融合(Gradient-based Feature Fusion)方法，将小波和小波软注意力辅助特征整合，以精确提取皮肤病变的边界信息。在HAM10000多类不平衡数据集上测试，该模型取得了91.17%的F1分数和90.75%的准确率，展示了其在辅助医生诊断中的潜力。代码已开源，可从指定仓库获取。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.15128v1",
      "published_date": "2024-06-21 13:21:44 UTC",
      "updated_date": "2024-06-21 13:21:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T23:17:18.510712"
    },
    {
      "arxiv_id": "2406.15119v1",
      "title": "Speech Emotion Recognition under Resource Constraints with Data Distillation",
      "title_zh": "翻译失败",
      "authors": [
        "Yi Chang",
        "Zhao Ren",
        "Zhonghao Zhao",
        "Thanh Tam Nguyen",
        "Kun Qian",
        "Tanja Schultz",
        "Björn W. Schuller"
      ],
      "abstract": "Speech emotion recognition (SER) plays a crucial role in human-computer\ninteraction. The emergence of edge devices in the Internet of Things (IoT)\npresents challenges in constructing intricate deep learning models due to\nconstraints in memory and computational resources. Moreover, emotional speech\ndata often contains private information, raising concerns about privacy leakage\nduring the deployment of SER models. To address these challenges, we propose a\ndata distillation framework to facilitate efficient development of SER models\nin IoT applications using a synthesised, smaller, and distilled dataset. Our\nexperiments demonstrate that the distilled dataset can be effectively utilised\nto train SER models with fixed initialisation, achieving performances\ncomparable to those developed using the original full emotional speech dataset.",
      "tldr_zh": "语音情感识别（Speech Emotion Recognition, SER）在人机交互中至关重要，但受限于物联网（IoT）边缘设备的内存和计算资源，以及情感语音数据的隐私泄露风险。论文提出了一种数据蒸馏框架，通过合成一个更小、更精简的数据集，实现SER模型的高效开发。实验结果表明，使用该蒸馏数据集训练的模型（固定初始化）性能与使用完整数据集相当，为资源受限环境下的SER应用提供了可行解决方案。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.15119v1",
      "published_date": "2024-06-21 13:10:46 UTC",
      "updated_date": "2024-06-21 13:10:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T23:17:19.855522"
    },
    {
      "arxiv_id": "2406.15117v1",
      "title": "FA-Net: A Fuzzy Attention-aided Deep Neural Network for Pneumonia Detection in Chest X-Rays",
      "title_zh": "FA-Net：一种模糊注意力辅助的深度神经网络，用于胸部X光片中的肺炎检测",
      "authors": [
        "Ayush Roy",
        "Anurag Bhattacharjee",
        "Diego Oliva",
        "Oscar Ramos-Soto",
        "Francisco J. Alvarez-Padilla",
        "Ram Sarkar"
      ],
      "abstract": "Pneumonia is a respiratory infection caused by bacteria, fungi, or viruses.\nIt affects many people, particularly those in developing or underdeveloped\nnations with high pollution levels, unhygienic living conditions, overcrowding,\nand insufficient medical infrastructure. Pneumonia can cause pleural effusion,\nwhere fluids fill the lungs, leading to respiratory difficulty. Early diagnosis\nis crucial to ensure effective treatment and increase survival rates. Chest\nX-ray imaging is the most commonly used method for diagnosing pneumonia.\nHowever, visual examination of chest X-rays can be difficult and subjective. In\nthis study, we have developed a computer-aided diagnosis system for automatic\npneumonia detection using chest X-ray images. We have used DenseNet-121 and\nResNet50 as the backbone for the binary class (pneumonia and normal) and\nmulti-class (bacterial pneumonia, viral pneumonia, and normal) classification\ntasks, respectively. We have also implemented a channel-specific spatial\nattention mechanism, called Fuzzy Channel Selective Spatial Attention Module\n(FCSSAM), to highlight the specific spatial regions of relevant channels while\nremoving the irrelevant channels of the extracted features by the backbone. We\nevaluated the proposed approach on a publicly available chest X-ray dataset,\nusing binary and multi-class classification setups. Our proposed method\nachieves accuracy rates of 97.15\\% and 79.79\\% for the binary and multi-class\nclassification setups, respectively. The results of our proposed method are\nsuperior to state-of-the-art (SOTA) methods. The code of the proposed model\nwill be available at: https://github.com/AyushRoy2001/FA-Net.",
      "tldr_zh": "本文提出 FA-Net，一种结合模糊注意力的深度神经网络，用于胸部 X 光图像中肺炎的自动检测，以解决手动诊断的主观性和困难问题。该网络使用 DenseNet-121 作为二分类（pneumonia 和 normal）的骨干，以及 ResNet50 作为多分类（bacterial pneumonia、viral pneumonia 和 normal）的骨干，并引入 Fuzzy Channel Selective Spatial Attention Module (FCSSAM) 来突出相关特征通道并去除无关信息。在公开数据集上，FA-Net 实现了 97.15% 的二分类准确率和 79.79% 的多分类准确率，优于现有 SOTA 方法，为临床肺炎诊断提供高效的计算机辅助工具。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.15117v1",
      "published_date": "2024-06-21 13:08:40 UTC",
      "updated_date": "2024-06-21 13:08:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T23:17:34.951856"
    },
    {
      "arxiv_id": "2406.15113v1",
      "title": "A Dual Attention-aided DenseNet-121 for Classification of Glaucoma from Fundus Images",
      "title_zh": "翻译失败",
      "authors": [
        "Soham Chakraborty",
        "Ayush Roy",
        "Payel Pramanik",
        "Daria Valenkova",
        "Ram Sarkar"
      ],
      "abstract": "Deep learning and computer vision methods are nowadays predominantly used in\nthe field of ophthalmology. In this paper, we present an attention-aided\nDenseNet-121 for classifying normal and glaucomatous eyes from fundus images.\nIt involves the convolutional block attention module to highlight relevant\nspatial and channel features extracted by DenseNet-121. The channel\nrecalibration module further enriches the features by utilizing edge\ninformation along with the statistical features of the spatial dimension. For\nthe experiments, two standard datasets, namely RIM-ONE and ACRIMA, have been\nused. Our method has shown superior results than state-of-the-art models. An\nablation study has also been conducted to show the effectiveness of each of the\ncomponents. The code of the proposed work is available at:\nhttps://github.com/Soham2004GitHub/DADGC.",
      "tldr_zh": "本研究提出了一种基于 DenseNet-121 的双注意力机制模型，用于从眼底图像（fundus images）中分类正常眼和青光眼（glaucoma）。该模型整合了 Convolutional Block Attention Module 来突出 DenseNet-121 提取的相关空间和通道特征，并通过通道重新校准模块利用边缘信息和空间统计特征来丰富特征。实验在 RIM-ONE 和 ACRIMA 数据集上显示，该方法优于现有最先进模型，并通过消融研究证实了各组件的有效性。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.15113v1",
      "published_date": "2024-06-21 13:00:46 UTC",
      "updated_date": "2024-06-21 13:00:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T23:17:46.251294"
    },
    {
      "arxiv_id": "2406.15111v2",
      "title": "Investigating the impact of 2D gesture representation on co-speech gesture generation",
      "title_zh": "翻译失败",
      "authors": [
        "Teo Guichoux",
        "Laure Soulier",
        "Nicolas Obin",
        "Catherine Pelachaud"
      ],
      "abstract": "Co-speech gestures play a crucial role in the interactions between humans and\nembodied conversational agents (ECA). Recent deep learning methods enable the\ngeneration of realistic, natural co-speech gestures synchronized with speech,\nbut such approaches require large amounts of training data. \"In-the-wild\"\ndatasets, which compile videos from sources such as YouTube through human pose\ndetection models, offer a solution by providing 2D skeleton sequences that are\npaired with speech. Concurrently, innovative lifting models have emerged,\ncapable of transforming these 2D pose sequences into their 3D counterparts,\nleading to large and diverse datasets of 3D gestures. However, the derived 3D\npose estimation is essentially a pseudo-ground truth, with the actual ground\ntruth being the 2D motion data. This distinction raises questions about the\nimpact of gesture representation dimensionality on the quality of generated\nmotions, a topic that, to our knowledge, remains largely unexplored. In this\nwork, we evaluate the impact of the dimensionality of the training data, 2D or\n3D joint coordinates, on the performance of a multimodal speech-to-gesture deep\ngenerative model. We use a lifting model to convert 2D-generated sequences of\nbody pose to 3D. Then, we compare the sequence of gestures generated directly\nin 3D to the gestures generated in 2D and lifted to 3D as post-processing.",
      "tldr_zh": "这篇论文探讨了2D手势表示对伴随言语手势(co-speech gestures)生成的影响，特别是在人类与具身对话代理(ECA)互动中的应用。研究评估了使用2D或3D关节坐标训练的多模态语音到手势深度生成模型的性能，通过lifting模型将2D生成序列转换为3D，并比较直接在3D生成的手势与先在2D生成后提升到3D的手势质量。该工作揭示了训练数据维度对生成手势真实性和多样性的潜在影响，为基于“in-the-wild”数据集的深度学习方法提供了新的见解。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.CV"
      ],
      "primary_category": "cs.AI",
      "comment": "8 pages. Paper accepted at WACAI 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.15111v2",
      "published_date": "2024-06-21 12:59:20 UTC",
      "updated_date": "2024-06-24 08:19:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T23:17:59.673605"
    },
    {
      "arxiv_id": "2406.15098v1",
      "title": "How Intermodal Interaction Affects the Performance of Deep Multimodal Fusion for Mixed-Type Time Series",
      "title_zh": "翻译失败",
      "authors": [
        "Simon Dietz",
        "Thomas Altstidl",
        "Dario Zanca",
        "Björn Eskofier",
        "An Nguyen"
      ],
      "abstract": "Mixed-type time series (MTTS) is a bimodal data type that is common in many\ndomains, such as healthcare, finance, environmental monitoring, and social\nmedia. It consists of regularly sampled continuous time series and irregularly\nsampled categorical event sequences. The integration of both modalities through\nmultimodal fusion is a promising approach for processing MTTS. However, the\nquestion of how to effectively fuse both modalities remains open. In this\npaper, we present a comprehensive evaluation of several deep multimodal fusion\napproaches for MTTS forecasting. Our comparison includes three fusion types\n(early, intermediate, and late) and five fusion methods (concatenation,\nweighted mean, weighted mean with correlation, gating, and feature sharing). We\nevaluate these fusion approaches on three distinct datasets, one of which was\ngenerated using a novel framework. This framework allows for the control of key\ndata properties, such as the strength and direction of intermodal interactions,\nmodality imbalance, and the degree of randomness in each modality, providing a\nmore controlled environment for testing fusion approaches. Our findings show\nthat the performance of different fusion approaches can be substantially\ninfluenced by the direction and strength of intermodal interactions. The study\nreveals that early and intermediate fusion approaches excel at capturing\nfine-grained and coarse-grained cross-modal features, respectively. These\nfindings underscore the crucial role of intermodal interactions in determining\nthe most effective fusion strategy for MTTS forecasting.",
      "tldr_zh": "这篇论文探讨了多模态融合在 Mixed-type time series (MTTS) 预测中的性能如何受 intermodal interactions 影响，MTTS 包括连续时间序列和不规则分类事件序列。作者对三种融合类型（early, intermediate, late）和五种融合方法（concatenation, weighted mean, weighted mean with correlation, gating, feature sharing）进行了全面评估，并在三个数据集上测试，其中一个数据集通过新框架生成，以控制 intermodal interactions 的强度、方向、模态不平衡和随机性。结果表明，早融合（early fusion）擅长捕捉细粒度跨模态特征，而中融合（intermediate fusion）更适合粗粒度特征，这些发现突出了 intermodal interactions 在选择最佳融合策略中的关键作用。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.15098v1",
      "published_date": "2024-06-21 12:26:48 UTC",
      "updated_date": "2024-06-21 12:26:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T23:18:11.790778"
    },
    {
      "arxiv_id": "2407.04722v1",
      "title": "A GPT-based Code Review System for Programming Language Learning",
      "title_zh": "一种基于 GPT 的代码审查系统，用于编程语言学习",
      "authors": [
        "Lee Dong-Kyu"
      ],
      "abstract": "The increasing demand for programming language education and growing class\nsizes require immediate and personalized feedback. However, traditional code\nreview methods have limitations in providing this level of feedback. As the\ncapabilities of Large Language Models (LLMs) like GPT for generating accurate\nsolutions and timely code reviews are verified, this research proposes a system\nthat employs GPT-4 to offer learner-friendly code reviews and minimize the risk\nof AI-assist cheating.\n  To provide learner-friendly code reviews, a dataset was collected from an\nonline judge system, and this dataset was utilized to develop and enhance the\nsystem's prompts. In addition, to minimize AI-assist cheating, the system flow\nwas designed to provide code reviews only for code submitted by a learner, and\na feature that highlights code lines to fix was added. After the initial system\nwas deployed on the web, software education experts conducted usability test.\nBased on the results, improvement strategies were developed to improve code\nreview and code correctness check module, thereby enhancing the system.\n  The improved system underwent evaluation by software education experts based\non four criteria: strict code correctness checks, response time, lower API call\ncosts, and the quality of code reviews. The results demonstrated a performance\nto accurately identify error types, shorten response times, lower API call\ncosts, and maintain high-quality code reviews without major issues. Feedback\nfrom participants affirmed the tool's suitability for teaching programming to\nprimary and secondary school students. Given these benefits, the system is\nanticipated to be a efficient learning tool in programming language learning\nfor educational settings.",
      "tldr_zh": "这篇论文提出了一种基于GPT-4的代码审查系统，旨在为编程语言学习提供即时个性化反馈，同时减少AI作弊风险，以应对传统方法的局限性。系统通过从在线评判系统收集数据集来优化提示设计，并仅针对学习者提交的代码进行审查，添加了突出错误代码行的功能，以提升用户友好性。实验结果显示，该系统在代码正确性检查、响应时间、API调用成本和审查质量方面表现出色，并获得软件教育专家认可，适合用于中小学编程教育。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "11 pages, 14 figures",
      "pdf_url": "http://arxiv.org/pdf/2407.04722v1",
      "published_date": "2024-06-21 12:16:01 UTC",
      "updated_date": "2024-06-21 12:16:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T23:18:21.984879"
    },
    {
      "arxiv_id": "2407.11205v1",
      "title": "Impact on clinical guideline adherence of Orient-COVID, a CDSS based on dynamic medical decision trees for COVID19 management: a randomized simulation trial",
      "title_zh": "Orient-COVID 对临床指南遵守度的",
      "authors": [
        "Mouin Jammal",
        "Antoine Saab",
        "Cynthia Abi Khalil",
        "Charbel Mourad",
        "Rosy Tsopra",
        "Melody Saikali",
        "Jean-Baptiste Lamy"
      ],
      "abstract": "Background: The adherence of clinicians to clinical practice guidelines is\nknown to be low, including for the management of COVID-19, due to their\ndifficult use at the point of care and their complexity. Clinical decision\nsupport systems have been proposed to implement guidelines and improve\nadherence. One approach is to permit the navigation inside the recommendations,\npresented as a decision tree, but the size of the tree often limits this\napproach and may cause erroneous navigation, especially when it does not fit in\na single screen. Methods: We proposed an innovative visual interface to allow\nclinicians easily navigating inside decision trees for the management of\nCOVID-19 patients. It associates a multi-path tree model with the use of the\nfisheye visual technique, allowing the visualization of large decision trees in\na single screen. To evaluate the impact of this tool on guideline adherence, we\nconducted a randomized controlled trial in a near-real simulation setting,\ncomparing the decisions taken by medical students using Orient-COVID with those\ntaken with paper guidelines or without guidance, when performing on six\nrealistic clinical cases. Results: The results show that paper guidelines had\nno impact (p=0.97), while Orient-COVID significantly improved the guideline\nadherence compared to both other groups (p<0.0003). A significant impact of\nOrient-COVID was identified on several key points during the management of\nCOVID-19: ordering troponin lab tests, prescribing anticoagulant and oxygen\ntherapy. A multifactor analysis showed no difference between male and female\nparticipants. Conclusions: The use of an interactive decision tree for the\nmanagement of COVID-19 significantly improved the clinician adherence to\nguidelines. Future works will focus on the integration of the system to\nelectronic health records and on the adaptation of the system to other clinical\nconditions.",
      "tldr_zh": "本文评估了Orient-COVID，一个基于动态医疗决策树的临床决策支持系统(CDSS)，旨在提升COVID-19管理指南遵守率，通过多路径树模型和fisheye视觉技术实现大型决策树的单屏导航。研究采用随机对照试验，在模拟环境中比较医学生使用Orient-COVID、纸质指南或无指南时的决策，结果显示Orient-COVID显著提高了遵守率（p<0.0003），尤其在订购troponin实验室测试、处方anticoagulant和oxygen therapy等关键点上。性别因素对效果无显著影响。未来工作将聚焦于将系统集成到电子健康记录并扩展至其他临床场景。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CY",
        "92C50 (Primary), 68U35 (Secondary)"
      ],
      "primary_category": "cs.HC",
      "comment": "8 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2407.11205v1",
      "published_date": "2024-06-21 11:50:50 UTC",
      "updated_date": "2024-06-21 11:50:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T23:18:36.473043"
    },
    {
      "arxiv_id": "2406.15073v1",
      "title": "KnobTree: Intelligent Database Parameter Configuration via Explainable Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Jiahan Chen",
        "Shuhan Qi",
        "Yifan Li",
        "Zeyu Dong",
        "Mingfeng Ding",
        "Yulin Wu",
        "Xuan Wang"
      ],
      "abstract": "Databases are fundamental to contemporary information systems, yet\ntraditional rule-based configuration methods struggle to manage the complexity\nof real-world applications with hundreds of tunable parameters. Deep\nreinforcement learning (DRL), which combines perception and decision-making,\npresents a potential solution for intelligent database configuration tuning.\nHowever, due to black-box property of RL-based method, the generated database\ntuning strategies still face the urgent problem of lack explainability.\nBesides, the redundant parameters in large scale database always make the\nstrategy learning become unstable. This paper proposes KnobTree, an\ninterpertable framework designed for the optimization of database parameter\nconfiguration. In this framework, an interpertable database tuning algorithm\nbased on RL-based differentatial tree is proposed, which building a transparent\ntree-based model to generate explainable database tuning strategies. To address\nthe problem of large-scale parameters, We also introduce a explainable method\nfor parameter importance assessment, by utilizing Shapley Values to identify\nparameters that have significant impacts on database performance. Experiments\nconducted on MySQL and Gbase8s databases have verified exceptional transparency\nand interpretability of the KnobTree model. The good property makes generated\nstrategies can offer practical guidance to algorithm designers and database\nadministrators. Moreover, our approach also slightly outperforms the existing\nRL-based tuning algorithms in aspects such as throughput, latency, and\nprocessing time.",
      "tldr_zh": "本论文提出KnobTree框架，利用可解释的强化学习（Deep Reinforcement Learning, DRL）来优化数据库参数配置，解决传统方法在处理数百个参数时的复杂性和缺乏解释性问题。框架的核心是基于RL-based differential tree的算法，构建透明的树状模型生成可解释的调优策略，同时引入Shapley Values评估参数重要性，以稳定大规模参数的学习过程。在MySQL和Gbase8s数据库上的实验显示，KnobTree不仅提供实际指导的透明策略，还在吞吐量、延迟和处理时间等方面略优于现有RL-based算法。",
      "categories": [
        "cs.AI",
        "cs.DB"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.15073v1",
      "published_date": "2024-06-21 11:40:55 UTC",
      "updated_date": "2024-06-21 11:40:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T23:18:46.559025"
    },
    {
      "arxiv_id": "2406.15050v1",
      "title": "Tri-VQA: Triangular Reasoning Medical Visual Question Answering for Multi-Attribute Analysis",
      "title_zh": "翻译失败",
      "authors": [
        "Lin Fan",
        "Xun Gong",
        "Cenyang Zheng",
        "Yafei Ou"
      ],
      "abstract": "The intersection of medical Visual Question Answering (Med-VQA) is a\nchallenging research topic with advantages including patient engagement and\nclinical expert involvement for second opinions. However, existing Med-VQA\nmethods based on joint embedding fail to explain whether their provided results\nare based on correct reasoning or coincidental answers, which undermines the\ncredibility of VQA answers. In this paper, we investigate the construction of a\nmore cohesive and stable Med-VQA structure. Motivated by causal effect, we\npropose a novel Triangular Reasoning VQA (Tri-VQA) framework, which constructs\nreverse causal questions from the perspective of \"Why this answer?\" to\nelucidate the source of the answer and stimulate more reasonable forward\nreasoning processes. We evaluate our method on the Endoscopic Ultrasound (EUS)\nmulti-attribute annotated dataset from five centers, and test it on medical VQA\ndatasets. Experimental results demonstrate the superiority of our approach over\nexisting methods. Our codes and pre-trained models are available at\nhttps://anonymous.4open.science/r/Tri_VQA.",
      "tldr_zh": "该论文提出 Tri-VQA 框架，用于医疗视觉问答 (Med-VQA) 的多属性分析，旨在解决现有基于联合嵌入的方法在答案解释性和可信度上的不足。  \nTri-VQA 通过三角推理机制，构建反向因果问题（如 \"Why this answer?\"）来阐明答案来源，并刺激更合理的正向推理过程。  \n在 Endoscopic Ultrasound (EUS) 多属性数据集和其他医疗 VQA 数据集上的实验结果显示，该方法优于现有方法，提供更可靠的答案。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.CV",
        "I.2.7; I.2.10; J.3"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.15050v1",
      "published_date": "2024-06-21 10:50:55 UTC",
      "updated_date": "2024-06-21 10:50:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T23:19:09.184811"
    },
    {
      "arxiv_id": "2406.15044v1",
      "title": "From Overfitting to Robustness: Quantity, Quality, and Variety Oriented Negative Sample Selection in Graph Contrastive Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Adnan Ali",
        "Jinlong Li",
        "Huanhuan Chen",
        "Ali Kashif Bashir"
      ],
      "abstract": "Graph contrastive learning (GCL) aims to contrast positive-negative\ncounterparts to learn the node embeddings, whereas graph data augmentation\nmethods are employed to generate these positive-negative samples. The\nvariation, quantity, and quality of negative samples compared to positive\nsamples play crucial roles in learning meaningful embeddings for node\nclassification downstream tasks. Less variation, excessive quantity, and\nlow-quality negative samples cause the model to be overfitted for particular\nnodes, resulting in less robust models. To solve the overfitting problem in the\nGCL paradigm, this study proposes a novel Cumulative Sample Selection (CSS)\nalgorithm by comprehensively considering negative samples' quality, variations,\nand quantity. Initially, three negative sample pools are constructed: easy,\nmedium, and hard negative samples, which contain 25%, 50%, and 25% of the total\navailable negative samples, respectively. Then, 10% negative samples are\nselected from each of these three negative sample pools for training the model.\nAfter that, a decision agent module evaluates model training results and\ndecides whether to explore more negative samples from three negative sample\npools by increasing the ratio or keep exploiting the current sampling ratio.\nThe proposed algorithm is integrated into a proposed graph contrastive learning\nframework named NegAmplify. NegAmplify is compared with the SOTA methods on\nnine graph node classification datasets, with seven achieving better node\nclassification accuracy with up to 2.86% improvement.",
      "tldr_zh": "这篇论文针对图对比学习 (GCL) 中的过拟合问题，提出了一种新的 Cumulative Sample Selection (CSS) 算法，通过综合考虑负样本的质量、变异性和数量来提升模型鲁棒性。CSS 算法首先构建 easy、medium 和 hard 负样本池（分别占总负样本的 25%、50% 和 25%），然后从每个池中选择 10% 的样本进行训练，并使用决策代理模块动态调整采样比例以优化训练过程。该算法被整合到名为 NegAmplify 的 GCL 框架中，并在九个图节点分类数据集上与 SOTA 方法比较，实现了七个数据集的准确率提升，高达 2.86%。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.15044v1",
      "published_date": "2024-06-21 10:47:26 UTC",
      "updated_date": "2024-06-21 10:47:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T23:19:23.600384"
    },
    {
      "arxiv_id": "2406.15042v1",
      "title": "Behaviour Distillation",
      "title_zh": "行为蒸馏",
      "authors": [
        "Andrei Lupu",
        "Chris Lu",
        "Jarek Liesen",
        "Robert Tjarko Lange",
        "Jakob Foerster"
      ],
      "abstract": "Dataset distillation aims to condense large datasets into a small number of\nsynthetic examples that can be used as drop-in replacements when training new\nmodels. It has applications to interpretability, neural architecture search,\nprivacy, and continual learning. Despite strong successes in supervised\ndomains, such methods have not yet been extended to reinforcement learning,\nwhere the lack of a fixed dataset renders most distillation methods unusable.\nFilling the gap, we formalize behaviour distillation, a setting that aims to\ndiscover and then condense the information required for training an expert\npolicy into a synthetic dataset of state-action pairs, without access to expert\ndata. We then introduce Hallucinating Datasets with Evolution Strategies\n(HaDES), a method for behaviour distillation that can discover datasets of just\nfour state-action pairs which, under supervised learning, train agents to\ncompetitive performance levels in continuous control tasks. We show that these\ndatasets generalize out of distribution to training policies with a wide range\nof architectures and hyperparameters. We also demonstrate application to a\ndownstream task, namely training multi-task agents in a zero-shot fashion.\nBeyond behaviour distillation, HaDES provides significant improvements in\nneuroevolution for RL over previous approaches and achieves SoTA results on one\nstandard supervised dataset distillation task. Finally, we show that\nvisualizing the synthetic datasets can provide human-interpretable task\ninsights.",
      "tldr_zh": "本文形式化了behavior distillation，一种针对强化学习（RL）的技术，旨在无需专家数据就生成合成状态-动作对数据集，以浓缩训练专家策略所需的信息。作者引入了HaDES（Hallucinating Datasets with Evolution Strategies）方法，通过进化策略（Evolution Strategies）创建仅需四个状态-动作对的数据集，这些数据集能在监督学习下训练代理达到竞争性性能，并泛化到不同神经架构和超参数。实验结果显示，HaDES显著提升了RL中的神经进化表现，实现了监督数据集蒸馏任务的SOTA结果，并通过可视化合成数据集提供可解释的任务洞见。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Published as a conference paper at ICLR 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.15042v1",
      "published_date": "2024-06-21 10:45:43 UTC",
      "updated_date": "2024-06-21 10:45:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T23:19:23.916703"
    },
    {
      "arxiv_id": "2406.15038v1",
      "title": "Online detection and infographic explanation of spam reviews with data drift adaptation",
      "title_zh": "翻译失败",
      "authors": [
        "Francisco de Arriba-Pérez",
        "Silvia García-Méndez",
        "Fátima Leal",
        "Benedita Malheiro",
        "J. C. Burguillo"
      ],
      "abstract": "Spam reviews are a pervasive problem on online platforms due to its\nsignificant impact on reputation. However, research into spam detection in data\nstreams is scarce. Another concern lies in their need for transparency.\nConsequently, this paper addresses those problems by proposing an online\nsolution for identifying and explaining spam reviews, incorporating data drift\nadaptation. It integrates (i) incremental profiling, (ii) data drift detection\n& adaptation, and (iii) identification of spam reviews employing Machine\nLearning. The explainable mechanism displays a visual and textual prediction\nexplanation in a dashboard. The best results obtained reached up to 87 % spam\nF-measure.",
      "tldr_zh": "本论文针对在线平台上垃圾评论对声誉的负面影响，提出了一种结合数据 drift adaptation 的在线检测和解释解决方案，以解决数据流中检测稀缺和透明性不足的问题。该方法整合了(i) 增量 profiling、(ii) 数据 drift detection 与 adaptation，以及(iii) 机器学习识别垃圾评论的机制。通过仪表板提供视觉和文本预测解释，确保了系统的可解释性。实验结果显示，该方案在垃圾评论检测上达到了高达87%的F-measure。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.SI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.15038v1",
      "published_date": "2024-06-21 10:35:46 UTC",
      "updated_date": "2024-06-21 10:35:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T23:19:35.115750"
    },
    {
      "arxiv_id": "2406.15032v1",
      "title": "GiusBERTo: A Legal Language Model for Personal Data De-identification in Italian Court of Auditors Decisions",
      "title_zh": "翻译失败",
      "authors": [
        "Giulio Salierno",
        "Rosamaria Bertè",
        "Luca Attias",
        "Carla Morrone",
        "Dario Pettazzoni",
        "Daniela Battisti"
      ],
      "abstract": "Recent advances in Natural Language Processing have demonstrated the\neffectiveness of pretrained language models like BERT for a variety of\ndownstream tasks. We present GiusBERTo, the first BERT-based model specialized\nfor anonymizing personal data in Italian legal documents. GiusBERTo is trained\non a large dataset of Court of Auditors decisions to recognize entities to\nanonymize, including names, dates, locations, while retaining contextual\nrelevance. We evaluate GiusBERTo on a held-out test set and achieve 97%\ntoken-level accuracy. GiusBERTo provides the Italian legal community with an\naccurate and tailored BERT model for de-identification, balancing privacy and\ndata protection.",
      "tldr_zh": "该研究引入了GiusBERTo，这是一个基于BERT的语言模型，专门用于在意大利审计法院决定中匿名化个人信息，如姓名、日期和位置，同时保留上下文相关性。模型通过在大量法院决定数据集上进行训练，实现了实体识别和去识别任务，并在测试集上达到了97%的token-level准确率。作为意大利法律社区的首选工具，GiusBERTo有效平衡了隐私保护与数据利用需求。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "14 pages, 4 figures, 6 Tables",
      "pdf_url": "http://arxiv.org/pdf/2406.15032v1",
      "published_date": "2024-06-21 10:25:26 UTC",
      "updated_date": "2024-06-21 10:25:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T23:19:46.534424"
    },
    {
      "arxiv_id": "2406.15016v1",
      "title": "Evolution of Rewards for Food and Motor Action by Simulating Birth and Death",
      "title_zh": "翻译失败",
      "authors": [
        "Yuji Kanagawa",
        "Kenji Doya"
      ],
      "abstract": "The reward system is one of the fundamental drivers of animal behaviors and\nis critical for survival and reproduction. Despite its importance, the problem\nof how the reward system has evolved is underexplored. In this paper, we try to\nreplicate the evolution of biologically plausible reward functions and\ninvestigate how environmental conditions affect evolved rewards' shape. For\nthis purpose, we developed a population-based decentralized evolutionary\nsimulation framework, where agents maintain their energy level to live longer\nand produce more children. Each agent inherits its reward function from its\nparent subject to mutation and learns to get rewards via reinforcement learning\nthroughout its lifetime. Our results show that biologically reasonable positive\nrewards for food acquisition and negative rewards for motor action can evolve\nfrom randomly initialized ones. However, we also find that the rewards for\nmotor action diverge into two modes: largely positive and slightly negative.\nThe emergence of positive motor action rewards is surprising because it can\nmake agents too active and inefficient in foraging. In environments with poor\nand poisonous foods, the evolution of rewards for less important foods tends to\nbe unstable, while rewards for normal foods are still stable. These results\ndemonstrate the usefulness of our simulation environment and energy-dependent\nbirth and death model for further studies of the origin of reward systems.",
      "tldr_zh": "这篇论文通过一个基于种群的去中心化 evolutionary simulation framework，模拟了奖励系统的进化，代理通过强化学习（reinforcement learning）从随机初始化的奖励函数演变为生物学合理的模式，以维持能量水平并实现繁殖。结果显示，代理发展出对食物获取的正奖励和对运动动作的负奖励，但运动奖励可能演变为正的，导致代理过于活跃并降低觅食效率。在环境条件如不良或有毒食物存在时，奖励的进化稳定性降低，这为进一步研究奖励系统的起源提供了有价值的工具。",
      "categories": [
        "cs.NE",
        "cs.AI"
      ],
      "primary_category": "cs.NE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.15016v1",
      "published_date": "2024-06-21 09:44:56 UTC",
      "updated_date": "2024-06-21 09:44:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T23:19:58.771056"
    },
    {
      "arxiv_id": "2406.15015v1",
      "title": "GraLMatch: Matching Groups of Entities with Graphs and Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Fernando De Meer Pardo",
        "Claude Lehmann",
        "Dennis Gehrig",
        "Andrea Nagy",
        "Stefano Nicoli",
        "Branka Hadji Misheva",
        "Martin Braschler",
        "Kurt Stockinger"
      ],
      "abstract": "In this paper, we present an end-to-end multi-source Entity Matching problem,\nwhich we call entity group matching, where the goal is to assign to the same\ngroup, records originating from multiple data sources but representing the same\nreal-world entity. We focus on the effects of transitively matched records,\ni.e. the records connected by paths in the graph G = (V,E) whose nodes and\nedges represent the records and whether they are a match or not. We present a\nreal-world instance of this problem, where the challenge is to match records of\ncompanies and financial securities originating from different data providers.\nWe also introduce two new multi-source benchmark datasets that present similar\nmatching challenges as real-world records. A distinctive characteristic of\nthese records is that they are regularly updated following real-world events,\nbut updates are not applied uniformly across data sources. This phenomenon\nmakes the matching of certain groups of records only possible through the use\nof transitive information.\n  In our experiments, we illustrate how considering transitively matched\nrecords is challenging since a limited amount of false positive pairwise match\npredictions can throw off the group assignment of large quantities of records.\nThus, we propose GraLMatch, a method that can partially detect and remove false\npositive pairwise predictions through graph-based properties. Finally, we\nshowcase how fine-tuning a Transformer-based model (DistilBERT) on a reduced\nnumber of labeled samples yields a better final entity group matching than\ntraining on more samples and/or incorporating fine-tuning optimizations,\nillustrating how precision becomes the deciding factor in the entity group\nmatching of large volumes of records.",
      "tldr_zh": "本文提出 GraLMatch 方法，用于解决多源实体组匹配问题（entity group matching），即将来自不同数据来源但代表同一真实世界实体的记录，通过图 G = (V, E) 和传递匹配分配到同一组。GraLMatch 通过图-based 属性检测并移除假阳性配对预测，从而减少错误传播。实验在两个新多源基准数据集上表明，微调 DistilBERT 模型在较少标记样本上训练即可获得更优的最终匹配结果，突显精确性在处理大规模记录时的关键作用。",
      "categories": [
        "cs.DB",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.DB",
      "comment": "12 pages, 4 figures, accepted as research paper at EDBT 2025",
      "pdf_url": "http://arxiv.org/pdf/2406.15015v1",
      "published_date": "2024-06-21 09:44:16 UTC",
      "updated_date": "2024-06-21 09:44:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T23:20:22.281974"
    },
    {
      "arxiv_id": "2406.15009v2",
      "title": "Fair, Manipulation-Robust, and Transparent Sortition",
      "title_zh": "翻译失败",
      "authors": [
        "Carmel Baharav",
        "Bailey Flanigan"
      ],
      "abstract": "Sortition, the random selection of political representatives, is increasingly\nbeing used around the world to choose participants of deliberative processes\nlike Citizens' Assemblies. Motivated by sortition's practical importance, there\nhas been a recent flurry of research on sortition algorithms, whose task it is\nto select a panel from among a pool of volunteers. This panel must satisfy\nquotas enforcing representation of key population subgroups. Past work has\ncontributed an algorithmic approach for fulfilling this task while ensuring\nthat volunteers' chances of selection are maximally equal, as measured by any\nconvex equality objective. The question, then, is: which equality objective is\nthe right one? Past work has mainly studied the objectives Minimax and Leximin,\nwhich respectively minimize the maximum and maximize the minimum chance of\nselection given to any volunteer. Recent work showed that both of these\nobjectives have key weaknesses: Minimax is highly robust to manipulation but is\narbitrarily unfair; oppositely, Leximin is highly fair but arbitrarily\nmanipulable.\n  In light of this gap, we propose a new equality objective, Goldilocks, that\naims to achieve these ideals simultaneously by ensuring that no volunteer\nreceives too little or too much chance of selection. We theoretically bound the\nextent to which Goldilocks achieves these ideals, finding that in an important\nsense, Goldilocks recovers among the best available solutions in a given\ninstance. We then extend our bounds to the case where the output of Goldilocks\nis transformed to achieve a third goal, Transparency. Our empirical analysis of\nGoldilocks in real data is even more promising: we find that this objective\nachieves nearly instance-optimal minimum and maximum selection probabilities\nsimultaneously in most real instances -- an outcome not even guaranteed to be\npossible for any algorithm.",
      "tldr_zh": "本论文探讨了抽签（Sortition）机制在选择政治代表（如公民大会参与者）时的公平性、抗操纵性和透明性问题。过去的方法如 Minimax 和 Leximin 分别强调最小化最大选择概率或最大化最小选择概率，但存在抗操纵性弱或不公平的缺点。为此，论文提出了一种新平等目标 Goldilocks，它确保志愿者的选择概率不过低也不过高，从而同时实现这些理想。理论分析证明 Goldilocks 在给定实例中提供最佳平衡方案，而实证研究显示它在实际数据中几乎同时优化了最小和最大选择概率，即使这种优化并非总有可能。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.15009v2",
      "published_date": "2024-06-21 09:38:03 UTC",
      "updated_date": "2024-06-26 16:26:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T23:20:24.091884"
    },
    {
      "arxiv_id": "2406.15007v3",
      "title": "RouteFinder: Towards Foundation Models for Vehicle Routing Problems",
      "title_zh": "翻译失败",
      "authors": [
        "Federico Berto",
        "Chuanbo Hua",
        "Nayeli Gast Zepeda",
        "André Hottung",
        "Niels Wouda",
        "Leon Lan",
        "Junyoung Park",
        "Kevin Tierney",
        "Jinkyoo Park"
      ],
      "abstract": "This paper introduces RouteFinder, a comprehensive foundation model framework\nto tackle different Vehicle Routing Problem (VRP) variants. Our core idea is\nthat a foundation model for VRPs should be able to represent variants by\ntreating each as a subset of a generalized problem equipped with different\nattributes. We propose a unified VRP environment capable of efficiently\nhandling any attribute combination. The RouteFinder model leverages a modern\ntransformer-based encoder and global attribute embeddings to improve task\nrepresentation. Additionally, we introduce two reinforcement learning\ntechniques to enhance multi-task performance: mixed batch training, which\nenables training on different variants at once, and multi-variant reward\nnormalization to balance different reward scales. Finally, we propose efficient\nadapter layers that enable fine-tuning for new variants with unseen attributes.\nExtensive experiments on 48 VRP variants show RouteFinder outperforms recent\nstate-of-the-art learning methods. Code: https://github.com/ai4co/routefinder.",
      "tldr_zh": "该论文引入 RouteFinder，一种基础模型框架，旨在处理各种 Vehicle Routing Problem (VRP) 变体，将它们视为通用问题子集以统一表示。框架采用统一的 VRP 环境、Transformer-based 编码器和全局属性嵌入来提升任务表示，并通过混合批训练和多变体奖励归一化等强化学习技术优化多任务性能。此外，论文提出高效的适配器层，支持对新变体进行快速微调。实验结果显示，RouteFinder 在 48 个 VRP 变体上优于现有最先进的学习方法。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "A version of this work has been presented as an Oral at the ICML 2024\n  FM-Wild Workshop",
      "pdf_url": "http://arxiv.org/pdf/2406.15007v3",
      "published_date": "2024-06-21 09:34:26 UTC",
      "updated_date": "2025-02-05 09:27:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T23:20:38.406135"
    },
    {
      "arxiv_id": "2406.15000v1",
      "title": "Unveiling the Impact of Multi-Modal Interactions on User Engagement: A Comprehensive Evaluation in AI-driven Conversations",
      "title_zh": "揭示多模态交互对用户参与度的影响：AI驱动对话中的全面评估",
      "authors": [
        "Lichao Zhang",
        "Jia Yu",
        "Shuai Zhang",
        "Long Li",
        "Yangyang Zhong",
        "Guanbao Liang",
        "Yuming Yan",
        "Qing Ma",
        "Fangsheng Weng",
        "Fayu Pan",
        "Jing Li",
        "Renjun Xu",
        "Zhenzhong Lan"
      ],
      "abstract": "Large Language Models (LLMs) have significantly advanced user-bot\ninteractions, enabling more complex and coherent dialogues. However, the\nprevalent text-only modality might not fully exploit the potential for\neffective user engagement. This paper explores the impact of multi-modal\ninteractions, which incorporate images and audio alongside text, on user\nengagement in chatbot conversations. We conduct a comprehensive analysis using\na diverse set of chatbots and real-user interaction data, employing metrics\nsuch as retention rate and conversation length to evaluate user engagement. Our\nfindings reveal a significant enhancement in user engagement with multi-modal\ninteractions compared to text-only dialogues. Notably, the incorporation of a\nthird modality significantly amplifies engagement beyond the benefits observed\nwith just two modalities. These results suggest that multi-modal interactions\noptimize cognitive processing and facilitate richer information comprehension.\nThis study underscores the importance of multi-modality in chatbot design,\noffering valuable insights for creating more engaging and immersive AI\ncommunication experiences and informing the broader AI community about the\nbenefits of multi-modal interactions in enhancing user engagement.",
      "tldr_zh": "本研究探讨了多模态互动（包括图像、音频和文本）对AI驱动对话中用户参与度的影响，旨在解决Large Language Models (LLMs)基于文本-only模式的局限性。通过使用多样聊天机器人和真实用户交互数据，采用保留率和对话长度等指标进行全面评估，结果显示多模态互动显著提升了用户参与度，特别是添加第三个模态后效果更佳。这些发现表明多模态优化了认知处理和信息理解，为聊天机器人设计提供宝贵见解，推动更具沉浸感的AI通信体验。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.15000v1",
      "published_date": "2024-06-21 09:26:55 UTC",
      "updated_date": "2024-06-21 09:26:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T23:20:59.313293"
    },
    {
      "arxiv_id": "2407.18363v1",
      "title": "KI-Bilder und die Widerständigkeit der Medienkonvergenz: Von primärer zu sekundärer Intermedialität?",
      "title_zh": "翻译失败",
      "authors": [
        "Lukas R. A. Wilde"
      ],
      "abstract": "The article presents some current observations (as of April 10, 2024) on the\nintegration of AI-generated images within processes of media convergence. It\ndraws on two different concepts of intermediality. Primary intermediality\nconcepts are motivated by the object when a new type of technology develops the\npotential to become socially relevant as a media form and thus a socially,\npolitically, or culturally important communicative factor. Due to their\nuncertain 'measurements' within the wider media ecology, however, the new,\nstill potential media form appears hybrid. The \"inter-\" or \"between-\" of this\ninitial intermediality moment thus refers to the questionable \"site\" and the\nquestionable description of the potential media form between already existing\ntechnologies and cultural forms and their conceptual measurements. For\nsecondary concepts of intermediality, in contrast, it can be assumed that the\nboundaries of media forms and their application have already been drawn and are\nreasonably undisputed. This then raises the question of intentional and staged\nreferences to AI imagery within other media forms and pictures. The article\ndiscusses indicators of both intermediality moments using current examples and\ncontroversies surrounding AI images. The thesis is that there can be no talk of\na seamless 'integration' of AI images into the wider media landscape at the\nmoment (within films, comic books, or video games, for example) - as one of\ncountless other image production techniques - and that the medial 'site' of AI\nimage circulation - at least where it is not a matter of deception, but rather\ntheir conscious use as AI images - especially in social media communication and\nin fan cultures, but with repercussions for the more general media ecology and\nimage interpretation, insofar as the suspicion that an image could be\nAI-generated is now increasingly present as a \"hermeneutics of suspicion\".",
      "tldr_zh": "这篇文章探讨了截至2024年4月10日的观察，焦点是AI生成图像（KI-Bilder）在媒体融合（Medienkonvergenz）过程中的整合问题，运用初级和次级Intermedialität概念进行分析。\n初级Intermedialität强调新技术的混合状态，介于现有技术和文化形式之间，而次级Intermedialität则关注已确立媒体边界内的有意引用。\n作者通过当前例子和争议论证，指出AI图像尚未无缝融入媒体景观（如电影、漫画或视频游戏），并在社交媒体和粉丝文化中引发了对图像真实性的“hermeneutics of suspicion”怀疑，从而影响更广泛的媒体生态和图像解读。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.CV",
        "cs.MM"
      ],
      "primary_category": "cs.CY",
      "comment": "in German language",
      "pdf_url": "http://arxiv.org/pdf/2407.18363v1",
      "published_date": "2024-06-21 09:15:19 UTC",
      "updated_date": "2024-06-21 09:15:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T23:21:04.739999"
    },
    {
      "arxiv_id": "2406.14990v2",
      "title": "Learning Variable Compliance Control From a Few Demonstrations for Bimanual Robot with Haptic Feedback Teleoperation System",
      "title_zh": "翻译失败",
      "authors": [
        "Tatsuya Kamijo",
        "Cristian C. Beltran-Hernandez",
        "Masashi Hamaya"
      ],
      "abstract": "Automating dexterous, contact-rich manipulation tasks using rigid robots is a\nsignificant challenge in robotics. Rigid robots, defined by their actuation\nthrough position commands, face issues of excessive contact forces due to their\ninability to adapt to contact with the environment, potentially causing damage.\nWhile compliance control schemes have been introduced to mitigate these issues\nby controlling forces via external sensors, they are hampered by the need for\nfine-tuning task-specific controller parameters. Learning from Demonstrations\n(LfD) offers an intuitive alternative, allowing robots to learn manipulations\nthrough observed actions. In this work, we introduce a novel system to enhance\nthe teaching of dexterous, contact-rich manipulations to rigid robots. Our\nsystem is twofold: firstly, it incorporates a teleoperation interface utilizing\nVirtual Reality (VR) controllers, designed to provide an intuitive and\ncost-effective method for task demonstration with haptic feedback. Secondly, we\npresent Comp-ACT (Compliance Control via Action Chunking with Transformers), a\nmethod that leverages the demonstrations to learn variable compliance control\nfrom a few demonstrations. Our methods have been validated across various\ncomplex contact-rich manipulation tasks using single-arm and bimanual robot\nsetups in simulated and real-world environments, demonstrating the\neffectiveness of our system in teaching robots dexterous manipulations with\nenhanced adaptability and safety. Code available at:\nhttps://github.com/omron-sinicx/CompACT",
      "tldr_zh": "本论文针对刚性机器人进行灵巧、接触丰富的操作任务时存在的过大接触力问题，提出了一种新型系统，包括基于Virtual Reality (VR) 控制器的遥操作接口，以提供直观的触觉反馈 (Haptic Feedback) 演示。该系统还引入Comp-ACT方法，利用Transformer从少量Learning from Demonstrations (LfD) 中学习可变的Compliance Control，从而实现机器人对环境的适应性控制。在模拟和真实环境中，实验验证了该方法在单臂和双臂机器人上的有效性，显著提升了操作任务的适应性和安全性。代码可在GitHub获取。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "Accepted to IROS 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.14990v2",
      "published_date": "2024-06-21 09:03:37 UTC",
      "updated_date": "2024-09-26 05:51:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T23:21:23.123351"
    },
    {
      "arxiv_id": "2406.14988v1",
      "title": "Introducing the Biomechanics-Function Relationship in Glaucoma: Improved Visual Field Loss Predictions from intraocular pressure-induced Neural Tissue Strains",
      "title_zh": "翻译失败",
      "authors": [
        "Thanadet Chuangsuwanich",
        "Monisha E. Nongpiur",
        "Fabian A. Braeu",
        "Tin A. Tun",
        "Alexandre Thiery",
        "Shamira Perera",
        "Ching Lin Ho",
        "Martin Buist",
        "George Barbastathis",
        "Tin Aung",
        "Michaël J. A. Girard"
      ],
      "abstract": "Objective. (1) To assess whether neural tissue structure and biomechanics\ncould predict functional loss in glaucoma; (2) To evaluate the importance of\nbiomechanics in making such predictions. Design, Setting and Participants. We\nrecruited 238 glaucoma subjects. For one eye of each subject, we imaged the\noptic nerve head (ONH) using spectral-domain OCT under the following\nconditions: (1) primary gaze and (2) primary gaze with acute IOP elevation.\nMain Outcomes: We utilized automatic segmentation of optic nerve head (ONH)\ntissues and digital volume correlation (DVC) analysis to compute intraocular\npressure (IOP)-induced neural tissue strains. A robust geometric deep learning\napproach, known as Point-Net, was employed to predict the full Humphrey 24-2\npattern standard deviation (PSD) maps from ONH structural and biomechanical\ninformation. For each point in each PSD map, we predicted whether it exhibited\nno defect or a PSD value of less than 5%. Predictive performance was evaluated\nusing 5-fold cross-validation and the F1-score. We compared the model's\nperformance with and without the inclusion of IOP-induced strains to assess the\nimpact of biomechanics on prediction accuracy. Results: Integrating\nbiomechanical (IOP-induced neural tissue strains) and structural (tissue\nmorphology and neural tissues thickness) information yielded a significantly\nbetter predictive model (F1-score: 0.76+-0.02) across validation subjects, as\nopposed to relying only on structural information, which resulted in a\nsignificantly lower F1-score of 0.71+-0.02 (p < 0.05). Conclusion: Our study\nhas shown that the integration of biomechanical data can significantly improve\nthe accuracy of visual field loss predictions. This highlights the importance\nof the biomechanics-function relationship in glaucoma, and suggests that\nbiomechanics may serve as a crucial indicator for the development and\nprogression of glaucoma.",
      "tldr_zh": "这篇论文探讨了青光眼中生物力学与功能关系的引入，旨在通过眼内压（IOP）诱导的神经组织应变来改善视觉场损失预测。研究招募了238名青光眼患者，使用光谱域OCT成像视神经头（ONH），并结合数字体积相关（DVC）分析计算IOP诱导的神经组织应变。采用Point-Net几何深度学习方法，从ONH的结构（如组织形态和厚度）和生物力学信息预测Humphrey 24-2模式标准偏差（PSD）地图，并通过5折交叉验证评估模型性能。结果表明，整合生物力学信息后，模型的F1-score显著提升至0.76±0.02，比仅使用结构信息（0.71±0.02）的模型高（p<0.05），突显了生物力学在预测青光眼视觉场损失中的关键作用。",
      "categories": [
        "eess.IV",
        "cs.AI"
      ],
      "primary_category": "eess.IV",
      "comment": "19 pages, 2 figures",
      "pdf_url": "http://arxiv.org/pdf/2406.14988v1",
      "published_date": "2024-06-21 09:00:46 UTC",
      "updated_date": "2024-06-21 09:00:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T23:21:28.549052"
    },
    {
      "arxiv_id": "2406.14986v2",
      "title": "Do Large Language Models Exhibit Cognitive Dissonance? Studying the Difference Between Revealed Beliefs and Stated Answers",
      "title_zh": "翻译失败",
      "authors": [
        "Manuel Mondal",
        "Ljiljana Dolamic",
        "Gérôme Bovet",
        "Philippe Cudré-Mauroux",
        "Julien Audiffren"
      ],
      "abstract": "Prompting and Multiple Choices Questions (MCQ) have become the preferred\napproach to assess the capabilities of Large Language Models (LLMs), due to\ntheir ease of manipulation and evaluation. Such experimental appraisals have\npointed toward the LLMs' apparent ability to perform causal reasoning or to\ngrasp uncertainty. In this paper, we investigate whether these abilities are\nmeasurable outside of tailored prompting and MCQ by reformulating these issues\nas direct text completion - the foundation of LLMs. To achieve this goal, we\ndefine scenarios with multiple possible outcomes and we compare the prediction\nmade by the LLM through prompting (their Stated Answer) to the probability\ndistributions they compute over these outcomes during next token prediction\n(their Revealed Belief). Our findings suggest that the Revealed Belief of LLMs\nsignificantly differs from their Stated Answer and hint at multiple biases and\nmisrepresentations that their beliefs may yield in many scenarios and outcomes.\nAs text completion is at the core of LLMs, these results suggest that common\nevaluation methods may only provide a partial picture and that more research is\nneeded to assess the extent and nature of their capabilities.",
      "tldr_zh": "这篇论文探讨大型语言模型 (LLMs) 是否表现出认知失调现象，通过比较其在提示下的显性回答 (Stated Answer) 与文本完成任务中的隐性概率分布 (Revealed Belief)。研究方法涉及设计多结果场景，直接评估 LLMs 在非结构化文本生成中的实际预测，而非依赖传统的提示或多项选择题 (MCQ)。结果显示，Revealed Belief 与 Stated Answer 存在显著差异，可能导致偏见和误导，表明当前评估方法仅提供部分图像，需要更多研究来全面评估 LLMs 的能力。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.14986v2",
      "published_date": "2024-06-21 08:56:35 UTC",
      "updated_date": "2024-07-02 14:02:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T23:21:37.581040"
    },
    {
      "arxiv_id": "2407.00072v5",
      "title": "Pistis-RAG: Enhancing Retrieval-Augmented Generation with Human Feedback",
      "title_zh": "Pistis-RAG：利用人类反馈增强检索增强生成",
      "authors": [
        "Yu Bai",
        "Yukai Miao",
        "Li Chen",
        "Dawei Wang",
        "Dan Li",
        "Yanyu Ren",
        "Hongtao Xie",
        "Ce Yang",
        "Xuhui Cai"
      ],
      "abstract": "RAG systems face limitations when semantic relevance alone does not guarantee\nimproved generation quality. This issue becomes particularly evident due to the\nsensitivity of large language models (LLMs) to the ordering of few-shot\nprompts, which can affect model performance. To address this challenge,\naligning LLM outputs with human preferences using structured feedback, such as\noptions to copy, regenerate, or dislike, offers a promising method for\nimprovement. This feedback is applied to the entire list of inputs rather than\ngiving specific ratings for individual documents, making it a Listwide Labels\nLearning-to-Rank task.\n  To address this task, we propose Pistis-RAG, a new RAG framework designed\nwith a content-centric approach to better align LLMs with human preferences.\nPistis-RAG effectively utilizes human feedback, enhancing content ranking and\ngeneration quality. To validate our framework, we use public datasets to\nsimulate human feedback, allowing us to evaluate and refine our method\neffectively. Experimental results indicate that Pistis-RAG improves alignment\nwith human preferences relative to the baseline RAG system, showing a 6.06%\nincrease in MMLU (English) and a 7.08% increase in C-EVAL (Chinese) accuracy\nmetrics. These results highlight Pistis-RAG's effectiveness in overcoming the\nlimitations associated with traditional RAG approaches.",
      "tldr_zh": "该论文探讨了RAG（Retrieval-Augmented Generation）系统的局限性，即语义相关性无法保证生成质量，且LLMs（Large Language Models）对few-shot prompts顺序高度敏感。为解决此问题，研究提出Pistis-RAG框架，该框架采用内容为中心的方法，利用结构化人类反馈（如copy, regenerate或dislike）进行Listwide Labels Learning-to-Rank任务，从而提升内容排名和生成质量。实验结果显示，Pistis-RAG相对于基线RAG系统在人类偏好对齐上显著改善，MMLU（English）准确率提高6.06%，C-EVAL（Chinese）准确率提高7.08%。这为更可靠的RAG应用提供了新途径。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.00072v5",
      "published_date": "2024-06-21 08:52:11 UTC",
      "updated_date": "2024-10-31 08:35:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T23:21:51.821885"
    },
    {
      "arxiv_id": "2406.14981v1",
      "title": "Human-AI collectives produce the most accurate differential diagnoses",
      "title_zh": "人类-AI 集体产生最准确的鉴别诊断",
      "authors": [
        "N. Zöller",
        "J. Berger",
        "I. Lin",
        "N. Fu",
        "J. Komarneni",
        "G. Barabucci",
        "K. Laskowski",
        "V. Shia",
        "B. Harack",
        "E. A. Chu",
        "V. Trianni",
        "R. H. J. M. Kurvers",
        "S. M. Herzog"
      ],
      "abstract": "Artificial intelligence systems, particularly large language models (LLMs),\nare increasingly being employed in high-stakes decisions that impact both\nindividuals and society at large, often without adequate safeguards to ensure\nsafety, quality, and equity. Yet LLMs hallucinate, lack common sense, and are\nbiased - shortcomings that may reflect LLMs' inherent limitations and thus may\nnot be remedied by more sophisticated architectures, more data, or more human\nfeedback. Relying solely on LLMs for complex, high-stakes decisions is\ntherefore problematic. Here we present a hybrid collective intelligence system\nthat mitigates these risks by leveraging the complementary strengths of human\nexperience and the vast information processed by LLMs. We apply our method to\nopen-ended medical diagnostics, combining 40,762 differential diagnoses made by\nphysicians with the diagnoses of five state-of-the art LLMs across 2,133\nmedical cases. We show that hybrid collectives of physicians and LLMs\noutperform both single physicians and physician collectives, as well as single\nLLMs and LLM ensembles. This result holds across a range of medical specialties\nand professional experience, and can be attributed to humans' and LLMs'\ncomplementary contributions that lead to different kinds of errors. Our\napproach highlights the potential for collective human and machine intelligence\nto improve accuracy in complex, open-ended domains like medical diagnostics.",
      "tldr_zh": "该研究指出，大型语言模型（LLMs）在高风险决策中存在幻觉、缺乏常识和偏见等固有局限性，因此提出了一种混合集体智能系统，结合人类经验和LLMs的信息处理能力来缓解这些问题。在医疗诊断领域，该系统将40,762个医生对2,133个病例的鉴别诊断与五个先进LLMs的诊断相结合。结果显示，人类和LLMs的混合集体在准确性上优于单一医生、医生集体、单一LLMs或LLM集合，这种优势归因于双方互补的错误类型，并适用于多种医疗专业。整体方法突出了集体人类和机器智能在复杂领域如医疗诊断中提升准确性的潜力。",
      "categories": [
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.14981v1",
      "published_date": "2024-06-21 08:46:30 UTC",
      "updated_date": "2024-06-21 08:46:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T23:22:13.389002"
    },
    {
      "arxiv_id": "2406.14977v2",
      "title": "Trustworthy Enhanced Multi-view Multi-modal Alzheimer's Disease Prediction with Brain-wide Imaging Transcriptomics Data",
      "title_zh": "翻译失败",
      "authors": [
        "Shan Cong",
        "Zhoujie Fan",
        "Hongwei Liu",
        "Yinghan Zhang",
        "Xin Wang",
        "Haoran Luo",
        "Xiaohui Yao"
      ],
      "abstract": "Brain transcriptomics provides insights into the molecular mechanisms by\nwhich the brain coordinates its functions and processes. However, existing\nmultimodal methods for predicting Alzheimer's disease (AD) primarily rely on\nimaging and sometimes genetic data, often neglecting the transcriptomic basis\nof brain. Furthermore, while striving to integrate complementary information\nbetween modalities, most studies overlook the informativeness disparities\nbetween modalities. Here, we propose TMM, a trusted multiview multimodal graph\nattention framework for AD diagnosis, using extensive brain-wide\ntranscriptomics and imaging data. First, we construct view-specific brain\nregional co-function networks (RRIs) from transcriptomics and multimodal\nradiomics data to incorporate interaction information from both biomolecular\nand imaging perspectives. Next, we apply graph attention (GAT) processing to\neach RRI network to produce graph embeddings and employ cross-modal attention\nto fuse transcriptomics-derived embedding with each imagingderived embedding.\nFinally, a novel true-false-harmonized class probability (TFCP) strategy is\ndesigned to assess and adaptively adjust the prediction confidence of each\nmodality for AD diagnosis. We evaluate TMM using the AHBA database with\nbrain-wide transcriptomics data and the ADNI database with three imaging\nmodalities (AV45-PET, FDG-PET, and VBM-MRI). The results demonstrate the\nsuperiority of our method in identifying AD, EMCI, and LMCI compared to\nstate-of-the-arts. Code and data are available at\nhttps://github.com/Yaolab-fantastic/TMM.",
      "tldr_zh": "该研究提出 TMM 框架，一种可信的多视图多模态图注意力方法，用于利用脑部转录组学和成像数据预测阿尔茨海默病 (AD)，以解决现有方法忽略转录组学基础和模态信息差异的问题。框架首先从转录组学和多模态放射组学数据构建视图特定的脑区域共功能网络 (RRIs)，然后应用图注意力 (GAT) 处理生成图嵌入，并通过跨模态注意力融合转录组学嵌入与成像嵌入。最终，引入 true-false-harmonized class probability (TFCP) 策略来评估和调整每个模态的预测置信度；在 AHBA 和 ADNI 数据库上的实验显示，TMM 在识别 AD、EMCI 和 LMCI 方面优于现有方法。",
      "categories": [
        "cs.AI",
        "eess.IV"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.14977v2",
      "published_date": "2024-06-21 08:39:24 UTC",
      "updated_date": "2025-04-02 10:56:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T23:22:14.311808"
    },
    {
      "arxiv_id": "2406.14971v1",
      "title": "Domain Adaptation of Llama3-70B-Instruct through Continual Pre-Training and Model Merging: A Comprehensive Evaluation",
      "title_zh": "Llama3-70B-Instruct 的领域适应：通过持续预训练和模型合并的全面评估",
      "authors": [
        "Shamane Siriwardhana",
        "Mark McQuade",
        "Thomas Gauthier",
        "Lucas Atkins",
        "Fernando Fernandes Neto",
        "Luke Meyers",
        "Anneketh Vij",
        "Tyler Odenthal",
        "Charles Goddard",
        "Mary MacCarthy",
        "Jacob Solawetz"
      ],
      "abstract": "We conducted extensive experiments on domain adaptation of the\nMeta-Llama-3-70B-Instruct model on SEC data, exploring its performance on both\ngeneral and domain-specific benchmarks. Our focus included continual\npre-training (CPT) and model merging, aiming to enhance the model's\ndomain-specific capabilities while mitigating catastrophic forgetting. Through\nthis study, we evaluated the impact of integrating financial regulatory data\ninto a robust language model and examined the effectiveness of our model\nmerging techniques in preserving and improving the model's instructive\nabilities. The model is accessible at hugging face:\nhttps://huggingface.co/arcee-ai/Llama-3-SEC-Base, arcee-ai/Llama-3-SEC-Base.\nThis is an intermediate checkpoint of our final model, which has seen 20B\ntokens so far. The full model is still in the process of training. This is a\npreprint technical report with thorough evaluations to understand the entire\nprocess.",
      "tldr_zh": "本研究对 Llama3-70B-Instruct 模型进行了全面领域适应实验，聚焦于 SEC 数据，通过 continual pre-training (CPT) 和 model merging 方法，提升了模型的领域特定能力，同时缓解了灾难性遗忘。实验评估了整合金融监管数据对模型性能的影响，并证明了这些技术在保持和改进模型指令能力方面的有效性。最终，模型的中间检查点已发布在 Hugging Face 上（https://huggingface.co/arcee-ai/Llama-3-SEC-Base），这是一份预印本技术报告，提供深入的训练过程评估。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "8 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2406.14971v1",
      "published_date": "2024-06-21 08:29:31 UTC",
      "updated_date": "2024-06-21 08:29:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T23:22:26.812229"
    },
    {
      "arxiv_id": "2406.14969v2",
      "title": "Uni-Mol2: Exploring Molecular Pretraining Model at Scale",
      "title_zh": "翻译失败",
      "authors": [
        "Xiaohong Ji",
        "Zhen Wang",
        "Zhifeng Gao",
        "Hang Zheng",
        "Linfeng Zhang",
        "Guolin Ke",
        "Weinan E"
      ],
      "abstract": "In recent years, pretraining models have made significant advancements in the\nfields of natural language processing (NLP), computer vision (CV), and life\nsciences. The significant advancements in NLP and CV are predominantly driven\nby the expansion of model parameters and data size, a phenomenon now recognized\nas the scaling laws. However, research exploring scaling law in molecular\npretraining models remains unexplored. In this work, we present Uni-Mol2 , an\ninnovative molecular pretraining model that leverages a two-track transformer\nto effectively integrate features at the atomic level, graph level, and\ngeometry structure level. Along with this, we systematically investigate the\nscaling law within molecular pretraining models, characterizing the power-law\ncorrelations between validation loss and model size, dataset size, and\ncomputational resources. Consequently, we successfully scale Uni-Mol2 to 1.1\nbillion parameters through pretraining on 800 million conformations, making it\nthe largest molecular pretraining model to date. Extensive experiments show\nconsistent improvement in the downstream tasks as the model size grows. The\nUni-Mol2 with 1.1B parameters also outperforms existing methods, achieving an\naverage 27% improvement on the QM9 and 14% on COMPAS-1D dataset.",
      "tldr_zh": "本研究提出Uni-Mol2，一种基于两轨道Transformer的分子预训练模型，能够有效整合原子级别、图级别和几何结构级别的特征，以探索分子预训练的scaling law。该模型系统分析了验证损失与模型大小、数据集大小以及计算资源的幂律相关性，并成功扩展到11亿参数，通过在8亿构象上预训练，成为目前最大的分子预训练模型。实验结果显示，随着模型规模增加，下游任务性能持续提升，Uni-Mol2在QM9数据集上平均改善27%，在COMPAS-1D数据集上改善14%，优于现有方法。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.14969v2",
      "published_date": "2024-06-21 08:28:54 UTC",
      "updated_date": "2024-07-01 09:08:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T23:22:39.798177"
    },
    {
      "arxiv_id": "2406.14953v2",
      "title": "Deep Imbalanced Regression to Estimate Vascular Age from PPG Data: a Novel Digital Biomarker for Cardiovascular Health",
      "title_zh": "翻译失败",
      "authors": [
        "Guangkun Nie",
        "Qinghao Zhao",
        "Gongzheng Tang",
        "Jun Li",
        "Shenda Hong"
      ],
      "abstract": "Photoplethysmography (PPG) is emerging as a crucial tool for monitoring human\nhemodynamics, with recent studies highlighting its potential in assessing\nvascular aging through deep learning. However, real-world age distributions are\noften imbalanced, posing significant challenges for deep learning models. In\nthis paper, we introduce a novel, simple, and effective loss function named the\nDist Loss to address deep imbalanced regression tasks. We trained a\none-dimensional convolutional neural network (Net1D) incorporating the Dist\nLoss on the extensive UK Biobank dataset (n=502,389) to estimate vascular age\nfrom PPG signals and validate its efficacy in characterizing cardiovascular\nhealth. The model's performance was validated on a 40% held-out test set,\nachieving state-of-the-art results, especially in regions with small sample\nsizes. Furthermore, we divided the population into three subgroups based on the\ndifference between predicted vascular age and chronological age: less than -10\nyears, between -10 and 10 years, and greater than 10 years. We analyzed the\nrelationship between predicted vascular age and several cardiovascular events\nover a follow-up period of up to 10 years, including death, coronary heart\ndisease, and heart failure. Our results indicate that the predicted vascular\nage has significant potential to reflect an individual's cardiovascular health\nstatus. Our code will be available at https://github.com/Ngk03/AI-vascular-age.",
      "tldr_zh": "本文提出了一种名为 Dist Loss 的新损失函数，用于解决深度学习中不平衡回归问题，旨在从 PPG 数据估计血管年龄作为心血管健康的数字生物标志物。研究利用一维卷积神经网络 (Net1D) 在 UK Biobank 数据集（n=502,389）上训练模型，并在40% 的保留测试集上取得了最先进的结果，尤其在样本量小的区域表现突出。通过将人群基于预测血管年龄与实际年龄的差异分为三组，分析显示预测血管年龄与心血管事件（如死亡、心脏病和心力衰竭）密切相关，为临床应用提供了潜在价值。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "eess.SP"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.14953v2",
      "published_date": "2024-06-21 08:04:12 UTC",
      "updated_date": "2024-07-02 11:22:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T23:23:04.118750"
    },
    {
      "arxiv_id": "2406.14951v2",
      "title": "An Idiosyncrasy of Time-discretization in Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Kris De Asis",
        "Richard S. Sutton"
      ],
      "abstract": "Many reinforcement learning algorithms are built on an assumption that an\nagent interacts with an environment over fixed-duration, discrete time steps.\nHowever, physical systems are continuous in time, requiring a choice of\ntime-discretization granularity when digitally controlling them. Furthermore,\nsuch systems do not wait for decisions to be made before advancing the\nenvironment state, necessitating the study of how the choice of discretization\nmay affect a reinforcement learning algorithm. In this work, we consider the\nrelationship between the definitions of the continuous-time and discrete-time\nreturns. Specifically, we acknowledge an idiosyncrasy with naively applying a\ndiscrete-time algorithm to a discretized continuous-time environment, and note\nhow a simple modification can better align the return definitions. This\nobservation is of practical consideration when dealing with environments where\ntime-discretization granularity is a choice, or situations where such\ngranularity is inherently stochastic.",
      "tldr_zh": "本论文探讨了强化学习(Reinforcement Learning)中时间离散化(Time-discretization)的怪异之处，即算法通常假设固定时间步，而物理系统是连续的，选择离散化粒度会影响环境状态和决策过程。论文分析了连续时间和离散时间回报的定义差异，指出简单应用离散时间算法可能导致回报不对齐的问题，并提出通过简单修改来更好地对齐这些定义。这样的观察在时间离散化粒度可选择或随机的环境中具有实际意义，能改进算法的适用性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "I.2.6; I.2.9"
      ],
      "primary_category": "cs.LG",
      "comment": "RLC 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.14951v2",
      "published_date": "2024-06-21 08:03:25 UTC",
      "updated_date": "2024-09-02 04:13:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T23:23:04.214882"
    },
    {
      "arxiv_id": "2406.14949v2",
      "title": "CEASEFIRE: An AI-powered system for combatting illicit firearms trafficking",
      "title_zh": "翻译失败",
      "authors": [
        "Jorgen Cani",
        "Ioannis Mademlis",
        "Marina Mancuso",
        "Caterina Paternoster",
        "Emmanouil Adamakis",
        "George Margetis",
        "Sylvie Chambon",
        "Alain Crouzil",
        "Loubna Lechelek",
        "Georgia Dede",
        "Spyridon Evangelatos",
        "George Lalas",
        "Franck Mignet",
        "Pantelis Linardatos",
        "Konstantinos Kentrotis",
        "Henryk Gierszal",
        "Piotr Tyczka",
        "Sophia Karagiorgou",
        "George Pantelis",
        "Georgios Stavropoulos",
        "Konstantinos Votis",
        "Georgios Th. Papadopoulos"
      ],
      "abstract": "Modern technologies have led illicit firearms trafficking to partially merge\nwith cybercrime, while simultaneously permitting its off-line aspects to become\nmore sophisticated. Law enforcement officers face difficult challenges that\nrequire hi-tech solutions. This article presents a real-world system, powered\nby advanced Artificial Intelligence, for facilitating them in their everyday\nwork.",
      "tldr_zh": "该研究探讨了现代技术如何使非法枪支贩运（illicit firearms trafficking）与网络犯罪部分融合，并使其离线方面变得更复杂，导致执法人员面临严峻挑战。该文提出一个名为CEASEFIRE的真实世界系统，由先进的人工智能（Artificial Intelligence）驱动，旨在为执法人员提供高科技解决方案。该系统通过AI辅助日常工作，帮助打击枪支贩运的复杂形式，并提升执法效率。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.14949v2",
      "published_date": "2024-06-21 08:02:25 UTC",
      "updated_date": "2024-11-30 20:40:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T23:23:14.565085"
    },
    {
      "arxiv_id": "2406.14938v1",
      "title": "Towards Retrieval Augmented Generation over Large Video Libraries",
      "title_zh": "翻译失败",
      "authors": [
        "Yannis Tevissen",
        "Khalil Guetari",
        "Frédéric Petitpont"
      ],
      "abstract": "Video content creators need efficient tools to repurpose content, a task that\noften requires complex manual or automated searches. Crafting a new video from\nlarge video libraries remains a challenge. In this paper we introduce the task\nof Video Library Question Answering (VLQA) through an interoperable\narchitecture that applies Retrieval Augmented Generation (RAG) to video\nlibraries. We propose a system that uses large language models (LLMs) to\ngenerate search queries, retrieving relevant video moments indexed by speech\nand visual metadata. An answer generation module then integrates user queries\nwith this metadata to produce responses with specific video timestamps. This\napproach shows promise in multimedia content retrieval, and AI-assisted video\ncontent creation.",
      "tldr_zh": "这篇论文介绍了 Video Library Question Answering (VLQA) 任务，并提出了一种基于 Retrieval Augmented Generation (RAG) 的架构，用于处理大型视频库中的内容检索和重用问题。系统利用 large language models (LLMs) 生成搜索查询，从视频库中检索相关时刻（基于语音和视觉元数据），然后整合用户查询生成包含具体视频时间戳的响应。该方法展示了在多媒体内容检索和 AI 辅助视频内容创建方面的显著潜力。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted in IEEE HSI 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.14938v1",
      "published_date": "2024-06-21 07:52:01 UTC",
      "updated_date": "2024-06-21 07:52:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T23:23:28.054124"
    },
    {
      "arxiv_id": "2406.14928v2",
      "title": "Autonomous Agents for Collaborative Task under Information Asymmetry",
      "title_zh": "在信息不对称条件下用于协作任务的自治代理",
      "authors": [
        "Wei Liu",
        "Chenxi Wang",
        "Yifei Wang",
        "Zihao Xie",
        "Rennai Qiu",
        "Yufan Dang",
        "Zhuoyun Du",
        "Weize Chen",
        "Cheng Yang",
        "Chen Qian"
      ],
      "abstract": "Large Language Model Multi-Agent Systems (LLM-MAS) have achieved great\nprogress in solving complex tasks. It performs communication among agents\nwithin the system to collaboratively solve tasks, under the premise of shared\ninformation. However, when agents' collaborations are leveraged to perform\nmulti-person tasks, a new challenge arises due to information asymmetry, since\neach agent can only access the information of its human user. Previous MAS\nstruggle to complete tasks under this condition. To address this, we propose a\nnew MAS paradigm termed iAgents, which denotes Informative Multi-Agent Systems.\nIn iAgents, the human social network is mirrored in the agent network, where\nagents proactively exchange human information necessary for task resolution,\nthereby overcoming information asymmetry. iAgents employs a novel agent\nreasoning mechanism, InfoNav, to navigate agents' communication toward\neffective information exchange. Together with InfoNav, iAgents organizes human\ninformation in a mixed memory to provide agents with accurate and comprehensive\ninformation for exchange. Additionally, we introduce InformativeBench, the\nfirst benchmark tailored for evaluating LLM agents' task-solving ability under\ninformation asymmetry. Experimental results show that iAgents can collaborate\nwithin a social network of 140 individuals and 588 relationships, autonomously\ncommunicate over 30 turns, and retrieve information from nearly 70,000 messages\nto complete tasks within 3 minutes.",
      "tldr_zh": "该论文探讨了在信息不对称条件下，LLM-MAS（Large Language Model Multi-Agent Systems）代理如何进行协作任务的问题，提出了一种新范式iAgents（Informative Multi-Agent Systems）。iAgents通过镜像人类社交网络，让代理主动交换必要信息，并引入InfoNav推理机制来指导通信，以及混合记忆系统来组织信息，从而克服信息不对称的挑战。实验结果显示，在InformativeBench基准上，iAgents能在140个个体和588个关系的网络中，自主通信超过30轮，从近70,000条消息中检索信息，并在3分钟内完成任务。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.HC",
        "cs.MA",
        "cs.SI"
      ],
      "primary_category": "cs.AI",
      "comment": "32 pages, 12 figures, 6 tables, accepted by NeurIPS 2024, see detail\n  at https://thinkwee.top/iagents",
      "pdf_url": "http://arxiv.org/pdf/2406.14928v2",
      "published_date": "2024-06-21 07:37:19 UTC",
      "updated_date": "2024-10-17 10:30:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T23:23:40.541722"
    },
    {
      "arxiv_id": "2406.14925v1",
      "title": "Extraction of 3D trajectories of mandibular condyles from 2D real-time MRI",
      "title_zh": "翻译失败",
      "authors": [
        "Karyna Isaieva",
        "Justine Leclère",
        "Guillaume Paillart",
        "Guillaume Drouot",
        "Jacques Felblinger",
        "Xavier Dubernard",
        "Pierre-André Vuissoz"
      ],
      "abstract": "Computing the trajectories of mandibular condyles directly from MRI could\nprovide a comprehensive examination, allowing for the extraction of both\nanatomical and kinematic details. This study aimed to investigate the\nfeasibility of extracting 3D condylar trajectories from 2D real-time MRI and to\nassess their precision.Twenty healthy subjects underwent real-time MRI while\nopening and closing their jaws. One axial and two sagittal slices were\nsegmented using a U-Net-based algorithm. The centers of mass of the resulting\nmasks were projected onto the coordinate system based on anatomical markers and\ntemporally adjusted using a common projection. The quality of the computed\ntrajectories was evaluated using metrics designed to estimate movement\nreproducibility, head motion, and slice placement symmetry.The segmentation of\nthe axial slices demonstrated good-to-excellent quality; however, the\nsegmentation of the sagittal slices required some fine-tuning. The movement\nreproducibility was acceptable for most cases; nevertheless, head motion\ndisplaced the trajectories by 1 mm on average. The difference in the\nsuperior-inferior coordinate of the condyles in the closed jaw position was 1.7\nmm on average.Despite limitations in precision, real-time MRI enables the\nextraction of condylar trajectories with sufficient accuracy for evaluating\nclinically relevant parameters such as condyle displacement, trajectories\naspect, and symmetry.",
      "tldr_zh": "本研究探讨了从2D实时MRI中提取下颌关节（mandibular condyles）的3D轨迹的可行性，以同时获取解剖和运动细节。研究中，20名健康受试者在下颌开合过程中进行MRI扫描，使用U-Net-based算法对一个轴向切片和两个矢状切片进行分割，并通过质心计算、投影到解剖标记坐标系统和时间调整来生成轨迹。评估结果显示，轴向切片分割质量良好，但矢状切片需微调，运动再现性多数可接受，头部运动导致轨迹平均偏移1 mm，下颌闭合位置的上下坐标差异为平均1.7 mm。尽管精度有限，该方法能以足够准确度提取轨迹，用于评估临床参数如关节位移、轨迹方面和对称性。",
      "categories": [
        "eess.IV",
        "cs.AI"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.14925v1",
      "published_date": "2024-06-21 07:35:40 UTC",
      "updated_date": "2024-06-21 07:35:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T23:23:53.237754"
    },
    {
      "arxiv_id": "2406.14917v1",
      "title": "LLM2FEA: Discover Novel Designs with Generative Evolutionary Multitasking",
      "title_zh": "LLM2FEA：通过生成式进化多任务发现新颖设计",
      "authors": [
        "Melvin Wong",
        "Jiao Liu",
        "Thiago Rios",
        "Stefan Menzel",
        "Yew Soon Ong"
      ],
      "abstract": "The rapid research and development of generative artificial intelligence has\nenabled the generation of high-quality images, text, and 3D models from text\nprompts. This advancement impels an inquiry into whether these models can be\nleveraged to create digital artifacts for both creative and engineering\napplications. Drawing on innovative designs from other domains may be one\nanswer to this question, much like the historical practice of ``bionics\", where\nhumans have sought inspiration from nature's exemplary designs. This raises the\nintriguing possibility of using generative models to simultaneously tackle\ndesign tasks across multiple domains, facilitating cross-domain learning and\nresulting in a series of innovative design solutions. In this paper, we propose\nLLM2FEA as the first attempt to discover novel designs in generative models by\ntransferring knowledge across multiple domains. By utilizing a multi-factorial\nevolutionary algorithm (MFEA) to drive a large language model, LLM2FEA\nintegrates knowledge from various fields to generate prompts that guide the\ngenerative model in discovering novel and practical objects. Experimental\nresults in the context of 3D aerodynamic design verify the discovery\ncapabilities of the proposed LLM2FEA. The designs generated by LLM2FEA not only\nsatisfy practicality requirements to a certain degree but also feature novel\nand aesthetically pleasing shapes, demonstrating the potential applications of\nLLM2FEA in discovery tasks.",
      "tldr_zh": "该论文提出 LLM2FEA，一种创新框架，利用生成式进化多任务方法，通过跨领域知识转移来发现新型设计，旨在将生成式 AI 应用于创意和工程领域。方法结合多因子进化算法 (MFEA) 驱动大型语言模型 (LLM)，整合多领域知识生成提示，指导生成模型创建实用且创新的物体。实验结果在 3D 空气动力学设计中验证了 LLM2FEA 的发现能力，所生成的设计不仅满足实用性要求，还具备新颖和美观的形状，展示了其在跨领域创新任务中的潜力。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.CV",
        "cs.LG",
        "cs.NE"
      ],
      "primary_category": "cs.AI",
      "comment": "This work has been submitted to the IEEE for possible publication",
      "pdf_url": "http://arxiv.org/pdf/2406.14917v1",
      "published_date": "2024-06-21 07:20:51 UTC",
      "updated_date": "2024-06-21 07:20:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T23:24:04.488770"
    },
    {
      "arxiv_id": "2406.14916v1",
      "title": "Demonstrating the Efficacy of Kolmogorov-Arnold Networks in Vision Tasks",
      "title_zh": "翻译失败",
      "authors": [
        "Minjong Cheon"
      ],
      "abstract": "In the realm of deep learning, the Kolmogorov-Arnold Network (KAN) has\nemerged as a potential alternative to multilayer projections (MLPs). However,\nits applicability to vision tasks has not been extensively validated. In our\nstudy, we demonstrated the effectiveness of KAN for vision tasks through\nmultiple trials on the MNIST, CIFAR10, and CIFAR100 datasets, using a training\nbatch size of 32. Our results showed that while KAN outperformed the original\nMLP-Mixer on CIFAR10 and CIFAR100, it performed slightly worse than the\nstate-of-the-art ResNet-18. These findings suggest that KAN holds significant\npromise for vision tasks, and further modifications could enhance its\nperformance in future evaluations.Our contributions are threefold: first, we\nshowcase the efficiency of KAN-based algorithms for visual tasks; second, we\nprovide extensive empirical assessments across various vision benchmarks,\ncomparing KAN's performance with MLP-Mixer, CNNs, and Vision Transformers\n(ViT); and third, we pioneer the use of natural KAN layers in visual tasks,\naddressing a gap in previous research. This paper lays the foundation for\nfuture studies on KANs, highlighting their potential as a reliable alternative\nfor image classification tasks.",
      "tldr_zh": "本研究验证了 Kolmogorov-Arnold Networks (KAN) 在视觉任务中的有效性，通过在 MNIST、CIFAR10 和 CIFAR100 数据集上进行实验（批量大小为 32），并与 MLP-Mixer、CNNs 和 Vision Transformers (ViT) 进行比较。结果显示，KAN 在 CIFAR10 和 CIFAR100 上超过了原始 MLP-Mixer，但略逊于 ResNet-18，这表明 KAN 在图像分类任务中具有显著潜力。研究的主要贡献包括：展示了 KAN 的效率、提供了广泛的实证评估，以及首次在视觉任务中使用自然 KAN 层，为未来改进奠定基础。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.14916v1",
      "published_date": "2024-06-21 07:20:34 UTC",
      "updated_date": "2024-06-21 07:20:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T23:24:16.592925"
    },
    {
      "arxiv_id": "2406.14909v2",
      "title": "MoA: Mixture of Sparse Attention for Automatic Large Language Model Compression",
      "title_zh": "翻译失败",
      "authors": [
        "Tianyu Fu",
        "Haofeng Huang",
        "Xuefei Ning",
        "Genghan Zhang",
        "Boju Chen",
        "Tianqi Wu",
        "Hongyi Wang",
        "Zixiao Huang",
        "Shiyao Li",
        "Shengen Yan",
        "Guohao Dai",
        "Huazhong Yang",
        "Yu Wang"
      ],
      "abstract": "Sparse attention can effectively mitigate the significant memory and\nthroughput demands of Large Language Models (LLMs) in long contexts. Existing\nmethods typically employ a uniform sparse attention mask, applying the same\nsparse pattern across different attention heads and input lengths. However,\nthis uniform approach fails to capture the diverse attention patterns inherent\nin LLMs, ignoring their distinct accuracy-latency trade-offs. To address this\nchallenge, we propose the Mixture of Attention (MoA), which automatically\ntailors distinct sparse attention configurations to different heads and layers.\nMoA constructs and navigates a search space of various attention patterns and\ntheir scaling rules relative to input sequence lengths. It profiles the model,\nevaluates potential configurations, and pinpoints the optimal sparse attention\ncompression plan. MoA adapts to varying input sizes, revealing that some\nattention heads expand their focus to accommodate longer sequences, while other\nheads consistently concentrate on fixed-length local contexts. Experiments show\nthat MoA increases the effective context length by $3.9\\times$ with the same\naverage attention span, boosting retrieval accuracy by $1.5-7.1\\times$ over the\nuniform-attention baseline across Vicuna-{7B,13B}, and Llama3-{8B,70B} models.\nMoreover, MoA narrows the capability gaps between sparse and dense models,\nreducing the maximum relative performance drop from $9\\%-36\\%$ to within $5\\%$\nacross two long-context understanding benchmarks. MoA achieves a\n$1.2-1.4\\times$ GPU memory reduction, boosting decode throughput by\n$6.6-8.2\\times$ and $1.7-1.9\\times$ compared to FlashAttention2 and vLLM, with\nminimal impact on performance. Our code is available at\n\\url{https://github.com/thu-nics/MoA}.",
      "tldr_zh": "本研究提出MoA（Mixture of Attention），一种自动为大语言模型(LLMs)定制稀疏注意力的方法，以解决现有统一稀疏注意力掩码忽略不同头和层多样性的问题。MoA通过构建注意力模式搜索空间、模型剖析和评估，针对不同输入长度为各注意力头动态配置最优稀疏策略，从而适应长上下文需求。实验结果显示，MoA在Vicuna-7B/13B和Llama3-8B/70B模型上，将有效上下文长度提升3.9倍，检索准确率提高1.5-7.1倍，同时减少GPU内存1.2-1.4倍、提升解码吞吐量6.6-8.2倍，并将稀疏模型与密集模型的性能差距缩小至5%以内。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "I.2.7"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.14909v2",
      "published_date": "2024-06-21 06:58:37 UTC",
      "updated_date": "2024-11-01 02:26:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T23:24:28.785939"
    },
    {
      "arxiv_id": "2406.14903v2",
      "title": "GIEBench: Towards Holistic Evaluation of Group Identity-based Empathy for Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Leyan Wang",
        "Yonggang Jin",
        "Tianhao Shen",
        "Tianyu Zheng",
        "Xinrun Du",
        "Chenchen Zhang",
        "Wenhao Huang",
        "Jiaheng Liu",
        "Shi Wang",
        "Ge Zhang",
        "Liuyu Xiang",
        "Zhaofeng He"
      ],
      "abstract": "As large language models (LLMs) continue to develop and gain widespread\napplication, the ability of LLMs to exhibit empathy towards diverse group\nidentities and understand their perspectives is increasingly recognized as\ncritical. Most existing benchmarks for empathy evaluation of LLMs focus\nprimarily on universal human emotions, such as sadness and pain, often\noverlooking the context of individuals' group identities. To address this gap,\nwe introduce GIEBench, a comprehensive benchmark that includes 11 identity\ndimensions, covering 97 group identities with a total of 999 single-choice\nquestions related to specific group identities. GIEBench is designed to\nevaluate the empathy of LLMs when presented with specific group identities such\nas gender, age, occupation, and race, emphasizing their ability to respond from\nthe standpoint of the identified group. This supports the ongoing development\nof empathetic LLM applications tailored to users with different identities. Our\nevaluation of 23 LLMs revealed that while these LLMs understand different\nidentity standpoints, they fail to consistently exhibit equal empathy across\nthese identities without explicit instructions to adopt those perspectives.\nThis highlights the need for improved alignment of LLMs with diverse values to\nbetter accommodate the multifaceted nature of human identities. Our datasets\nare available at https://github.com/GIEBench/GIEBench.",
      "tldr_zh": "本研究引入了 GIEBench，这是一个全面基准，用于评估大型语言模型 (LLMs) 对不同群体身份的移情能力，填补了现有基准忽略群体身份上下文的空白。GIEBench 涵盖 11 个身份维度（如性别、年龄、职业和种族），包括 97 个群体身份和总计 999 个单选题，旨在测试 LLMs 从特定群体视角回应的能力。评估 23 个 LLMs 后，发现这些模型能理解不同身份立场，但未获明确指令时，无法一致表现出平等的移情，这突显了需要改进 LLMs 以更好地适应多样化人类身份的需求。该基准的数据集已公开在 GitHub 上，以支持相关研究的推进。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.14903v2",
      "published_date": "2024-06-21 06:50:42 UTC",
      "updated_date": "2024-06-24 14:57:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T23:24:42.483929"
    },
    {
      "arxiv_id": "2406.14894v2",
      "title": "Talking the Talk Does Not Entail Walking the Walk: On the Limits of Large Language Models in Lexical Entailment Recognition",
      "title_zh": "翻译失败",
      "authors": [
        "Candida M. Greco",
        "Lucio La Cava",
        "Andrea Tagarelli"
      ],
      "abstract": "Verbs form the backbone of language, providing the structure and meaning to\nsentences. Yet, their intricate semantic nuances pose a longstanding challenge.\nUnderstanding verb relations through the concept of lexical entailment is\ncrucial for comprehending sentence meanings and grasping verb dynamics. This\nwork investigates the capabilities of eight Large Language Models in\nrecognizing lexical entailment relations among verbs through differently\ndevised prompting strategies and zero-/few-shot settings over verb pairs from\ntwo lexical databases, namely WordNet and HyperLex. Our findings unveil that\nthe models can tackle the lexical entailment recognition task with moderately\ngood performance, although at varying degree of effectiveness and under\ndifferent conditions. Also, utilizing few-shot prompting can enhance the\nmodels' performance. However, perfectly solving the task arises as an unmet\nchallenge for all examined LLMs, which raises an emergence for further research\ndevelopments on this topic.",
      "tldr_zh": "这篇论文探讨了大型语言模型（LLMs）在识别动词词汇蕴涵（lexical entailment）关系方面的局限性，强调理解动词语义细微差别的重要性。研究者通过不同提示策略（prompting strategies）和零/少样本设置（zero-/few-shot settings），测试了八个 LLMs 在 WordNet 和 HyperLex 数据库的动词对上的表现。结果显示，LLMs 可以中等程度地处理任务，使用 few-shot prompting 可提升效果，但无模型能完美解决此挑战，这突出了进一步研究的紧迫性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY",
        "cs.IR",
        "physics.soc-ph"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted for publication at The 2024 Conference on Empirical Methods\n  in Natural Language Processing (EMNLP-2024) - Findings",
      "pdf_url": "http://arxiv.org/pdf/2406.14894v2",
      "published_date": "2024-06-21 06:30:16 UTC",
      "updated_date": "2024-11-07 18:15:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T23:24:54.069043"
    },
    {
      "arxiv_id": "2406.14876v1",
      "title": "Training Greedy Policy for Proposal Batch Selection in Expensive Multi-Objective Combinatorial Optimization",
      "title_zh": "翻译失败",
      "authors": [
        "Deokjae Lee",
        "Hyun Oh Song",
        "Kyunghyun Cho"
      ],
      "abstract": "Active learning is increasingly adopted for expensive multi-objective\ncombinatorial optimization problems, but it involves a challenging subset\nselection problem, optimizing the batch acquisition score that quantifies the\ngoodness of a batch for evaluation. Due to the excessively large search space\nof the subset selection problem, prior methods optimize the batch acquisition\non the latent space, which has discrepancies with the actual space, or optimize\nindividual acquisition scores without considering the dependencies among\ncandidates in a batch instead of directly optimizing the batch acquisition. To\nmanage the vast search space, a simple and effective approach is the greedy\nmethod, which decomposes the problem into smaller subproblems, yet it has\ndifficulty in parallelization since each subproblem depends on the outcome from\nthe previous ones. To this end, we introduce a novel greedy-style subset\nselection algorithm that optimizes batch acquisition directly on the\ncombinatorial space by sequential greedy sampling from the greedy policy,\nspecifically trained to address all greedy subproblems concurrently. Notably,\nour experiments on the red fluorescent proteins design task show that our\nproposed method achieves the baseline performance in 1.69x fewer queries,\ndemonstrating its efficiency.",
      "tldr_zh": "该论文针对昂贵的多目标组合优化（Multi-Objective Combinatorial Optimization）问题中的子集选择挑战，提出了一种训练贪婪策略（Greedy Policy）的算法，用于优化批次获取分数（Batch Acquisition Score），以解决现有方法在潜在空间优化或忽略候选项依赖性的局限性。该算法通过顺序贪婪采样在组合空间直接优化批次获取，同时处理所有贪婪子问题，确保高效并行化。实验结果显示，在红荧光蛋白设计任务上，该方法比基线性能在减少1.69倍查询的情况下实现相同效果，显著提升了活跃学习（Active Learning）的效率。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "ICML 2024; Codes at https://github.com/snu-mllab/GreedyPolicyForMOCO",
      "pdf_url": "http://arxiv.org/pdf/2406.14876v1",
      "published_date": "2024-06-21 05:57:08 UTC",
      "updated_date": "2024-06-21 05:57:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T23:25:05.924006"
    },
    {
      "arxiv_id": "2406.14871v2",
      "title": "I don't trust you (anymore)! -- The effect of students' LLM use on Lecturer-Student-Trust in Higher Education",
      "title_zh": "翻译失败",
      "authors": [
        "Simon Kloker",
        "Matthew Bazanya",
        "Twaha Kateete"
      ],
      "abstract": "Trust plays a pivotal role in Lecturer-Student-Collaboration, encompassing\nteaching and research aspects. The advent of Large Language Models (LLMs) in\nplatforms like Open AI's ChatGPT, coupled with their cost-effectiveness and\nhigh-quality results, has led to their rapid adoption among university\nstudents. However, discerning genuine student input from LLM-generated output\nposes a challenge for lecturers. This dilemma jeopardizes the trust\nrelationship between lecturers and students, potentially impacting university\ndownstream activities, particularly collaborative research initiatives. Despite\nattempts to establish guidelines for student LLM use, a clear framework\nmutually beneficial for lecturers and students in higher education remains\nelusive. This study addresses the research question: How does the use of LLMs\nby students impact Informational and Procedural Justice, influencing Team Trust\nand Expected Team Performance? Methodically, we applied a quantitative\nconstruct-based survey, evaluated using techniques of Structural Equation\nModelling (PLS- SEM) to examine potential relationships among these constructs.\nOur findings based on 23 valid respondents from Ndejje University indicate that\nlecturers are less concerned about the fairness of LLM use per se but are more\nfocused on the transparency of student utilization, which significantly\ninfluences Team Trust positively. This research contributes to the global\ndiscourse on integrating and regulating LLMs and subsequent models in\neducation. We propose that guidelines should support LLM use while enforcing\ntransparency in Lecturer-Student- Collaboration to foster Team Trust and\nPerformance. The study contributes valuable insights for shaping policies\nenabling ethical and transparent LLMs usage in education to ensure\neffectiveness of collaborative learning environments.",
      "tldr_zh": "这篇论文探讨了学生使用 Large Language Models (LLMs) 如 ChatGPT 如何影响高等教育中讲师与学生的信任关系，特别关注其对 Informational and Procedural Justice、Team Trust 和 Expected Team Performance 的潜在影响。研究采用定量调查和 Structural Equation Modelling (PLS-SEM) 方法，基于 Ndejje University 的 23 名有效受访者数据，发现讲师更注重学生使用 LLMs 的透明度，而非公平性，且透明度显著正向提升 Team Trust。该研究为全球教育政策提供见解，建议制定指导方针以支持 LLMs 的伦理使用并强调透明度，从而促进协作学习环境的有效性。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.ET",
        "cs.HC",
        "cs.LG",
        "K.3.1; K.4.2; K.4.3; J.4; H.0; I.2.0"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.14871v2",
      "published_date": "2024-06-21 05:35:57 UTC",
      "updated_date": "2025-02-18 10:39:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T23:25:18.830875"
    },
    {
      "arxiv_id": "2406.14867v2",
      "title": "Investigating the Transferability of Code Repair for Low-Resource Programming Languages",
      "title_zh": "调查代码修复在低资源编程语言中的可转移性",
      "authors": [
        "Kyle Wong",
        "Alfonso Amayuelas",
        "Liangming Pan",
        "William Yang Wang"
      ],
      "abstract": "Large language models (LLMs) have shown remarkable performance on code\ngeneration tasks. A recent use case is iterative code repair, where an LLM\nfixes an incorrect program by rationalizing about errors and generating new\ncode. Recent works augment the code repair process by integrating modern\ntechniques such as chain-of-thought reasoning or distillation, but only study\ntheir benefits on high-resource languages like Python, and ignore low-resource\nlanguages like Perl. To address this gap of knowledge, we investigate the\nbenefits of distilling code repair for both high and low resource languages to\ndetermine if the techniques that are effective in a high resource setting are\nalso applicable in a low resource setting. Our evaluation shows that distilling\nthe ability to repair code has language dependent benefits. To explain this\nbehavior, we perform a further analysis and find that contrary to preexisting\nbeliefs, the correlation between reasoning ability and code correction ability\nis weak. We hypothesize this weak correlation is magnified in low-resource\nsettings where base models lack deep knowledge of a programming language,\nleading to wavering benefits of code repair.",
      "tldr_zh": "本研究调查了代码修复技术的转移性，探讨大型语言模型(LLMs)是否能将迭代代码修复能力从高资源编程语言（如Python）有效转移到低资源语言（如Perl），以填补现有研究的知识空白。通过整合蒸馏(distillation)技术并进行评估，研究发现代码修复的益处高度依赖于语言类型。进一步分析显示，推理能力与代码修正能力之间的相关性较弱，这种弱相关性在低资源语言环境中被放大，导致修复效果不稳定，从而为LLMs在不同语言设置下的优化提供了新见解。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.14867v2",
      "published_date": "2024-06-21 05:05:39 UTC",
      "updated_date": "2024-10-16 05:03:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T23:25:30.597777"
    },
    {
      "arxiv_id": "2406.14866v1",
      "title": "AI-based Anomaly Detection for Clinical-Grade Histopathological Diagnostics",
      "title_zh": "翻译失败",
      "authors": [
        "Jonas Dippel",
        "Niklas Prenißl",
        "Julius Hense",
        "Philipp Liznerski",
        "Tobias Winterhoff",
        "Simon Schallenberg",
        "Marius Kloft",
        "Oliver Buchstab",
        "David Horst",
        "Maximilian Alber",
        "Lukas Ruff",
        "Klaus-Robert Müller",
        "Frederick Klauschen"
      ],
      "abstract": "While previous studies have demonstrated the potential of AI to diagnose\ndiseases in imaging data, clinical implementation is still lagging behind. This\nis partly because AI models require training with large numbers of examples\nonly available for common diseases. In clinical reality, however, only few\ndiseases are common, whereas the majority of diseases are less frequent\n(long-tail distribution). Current AI models overlook or misclassify these\ndiseases. We propose a deep anomaly detection approach that only requires\ntraining data from common diseases to detect also all less frequent diseases.\nWe collected two large real-world datasets of gastrointestinal biopsies, which\nare prototypical of the problem. Herein, the ten most common findings account\nfor approximately 90% of cases, whereas the remaining 10% contained 56 disease\nentities, including many cancers. 17 million histological images from 5,423\ncases were used for training and evaluation. Without any specific training for\nthe diseases, our best-performing model reliably detected a broad spectrum of\ninfrequent (\"anomalous\") pathologies with 95.0% (stomach) and 91.0% (colon)\nAUROC and generalized across scanners and hospitals. By design, the proposed\nanomaly detection can be expected to detect any pathological alteration in the\ndiagnostic tail of gastrointestinal biopsies, including rare primary or\nmetastatic cancers. This study establishes the first effective clinical\napplication of AI-based anomaly detection in histopathology that can flag\nanomalous cases, facilitate case prioritization, reduce missed diagnoses and\nenhance the general safety of AI models, thereby driving AI adoption and\nautomation in routine diagnostics and beyond.",
      "tldr_zh": "本文提出了一种基于AI的深度异常检测方法，仅使用常见疾病的训练数据，即可有效识别罕见疾病（长尾分布），以解决现有AI模型在组织病理学诊断中的局限性。研究利用两个大型真实世界数据集（包括胃肠活检的1700万图像和5423个病例），模型在不进行特定训练的情况下，检测罕见病变时分别达到胃部95.0%和结肠91.0% AUROC，并展现出跨扫描仪和医院的泛化能力。该方法能标记异常病例、优先处理、减少漏诊，并提升AI模型的安全性，从而推动AI在常规诊断中的采用和自动化。",
      "categories": [
        "cs.AI",
        "eess.IV"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.14866v1",
      "published_date": "2024-06-21 04:59:19 UTC",
      "updated_date": "2024-06-21 04:59:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T23:25:43.647058"
    },
    {
      "arxiv_id": "2406.14859v1",
      "title": "From LLMs to MLLMs: Exploring the Landscape of Multimodal Jailbreaking",
      "title_zh": "翻译失败",
      "authors": [
        "Siyuan Wang",
        "Zhuohan Long",
        "Zhihao Fan",
        "Zhongyu Wei"
      ],
      "abstract": "The rapid development of Large Language Models (LLMs) and Multimodal Large\nLanguage Models (MLLMs) has exposed vulnerabilities to various adversarial\nattacks. This paper provides a comprehensive overview of jailbreaking research\ntargeting both LLMs and MLLMs, highlighting recent advancements in evaluation\nbenchmarks, attack techniques and defense strategies. Compared to the more\nadvanced state of unimodal jailbreaking, multimodal domain remains\nunderexplored. We summarize the limitations and potential research directions\nof multimodal jailbreaking, aiming to inspire future research and further\nenhance the robustness and security of MLLMs.",
      "tldr_zh": "这篇论文探讨了 Large Language Models (LLMs) 和 Multimodal Large Language Models (MLLMs) 在越狱(jailbreaking)方面的漏洞，提供了一个全面概述，包括评估基准、攻击技术和防御策略。相比于单模态越狱研究，多模态领域仍未充分探索，论文总结了其局限性，如模型鲁棒性不足，并提出潜在研究方向。最终目标是激发未来工作，提升 MLLMs 的安全性和整体可靠性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.14859v1",
      "published_date": "2024-06-21 04:33:48 UTC",
      "updated_date": "2024-06-21 04:33:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T23:25:53.752910"
    },
    {
      "arxiv_id": "2406.14854v2",
      "title": "PEANO-ViT: Power-Efficient Approximations of Non-Linearities in Vision Transformers",
      "title_zh": "PEANO-ViT：视觉Transformer中非线性函数的功率高效近似",
      "authors": [
        "Mohammad Erfan Sadeghi",
        "Arash Fayyazi",
        "Seyedarmin Azizi",
        "Massoud Pedram"
      ],
      "abstract": "The deployment of Vision Transformers (ViTs) on hardware platforms, specially\nField-Programmable Gate Arrays (FPGAs), presents many challenges, which are\nmainly due to the substantial computational and power requirements of their\nnon-linear functions, notably layer normalization, softmax, and Gaussian Error\nLinear Unit (GELU). These critical functions pose significant obstacles to\nefficient hardware implementation due to their complex mathematical operations\nand the inherent resource count and architectural limitations of FPGAs.\nPEANO-ViT offers a novel approach to streamlining the implementation of the\nlayer normalization layer by introducing a division-free technique that\nsimultaneously approximates the division and square root function.\nAdditionally, PEANO-ViT provides a multi-scale division strategy to eliminate\ndivision operations in the softmax layer, aided by a Pade-based approximation\nfor the exponential function. Finally, PEANO-ViT introduces a piece-wise linear\napproximation for the GELU function, carefully designed to bypass the\ncomputationally intensive operations associated with GELU. In our comprehensive\nevaluations, PEANO-ViT exhibits minimal accuracy degradation (<= 0.5% for\nDeiT-B) while significantly enhancing power efficiency, achieving improvements\nof 1.91x, 1.39x, 8.01x for layer normalization, softmax, and GELU,\nrespectively. This improvement is achieved through substantial reductions in\nDSP, LUT, and register counts for these non-linear operations. Consequently,\nPEANO-ViT enables efficient deployment of Vision Transformers on resource- and\npower-constrained FPGA platforms.",
      "tldr_zh": "本研究提出 PEANO-ViT，一种针对 Vision Transformers (ViTs) 的功耗优化框架，旨在通过近似非线性函数来解决其在 Field-Programmable Gate Arrays (FPGA) 上的高计算和功耗挑战。具体方法包括使用无除法技术同时近似 layer normalization 中的除法和平方根、采用多尺度策略消除 softmax 中的除法并结合 Pade-based 近似处理指数函数，以及为 Gaussian Error Linear Unit (GELU) 引入分段线性近似以绕过计算密集操作。在评估中，PEANO-ViT 仅导致 DeiT-B 模型准确性下降 ≤0.5%，同时分别将 layer normalization、softmax 和 GELU 的功耗效率提升 1.91x、1.39x 和 8.01x，从而实现 ViTs 在资源受限 FPGA 平台的高效部署。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "eess.IV"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.14854v2",
      "published_date": "2024-06-21 03:54:10 UTC",
      "updated_date": "2024-08-16 06:47:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T23:26:08.754042"
    },
    {
      "arxiv_id": "2406.14852v2",
      "title": "Is A Picture Worth A Thousand Words? Delving Into Spatial Reasoning for Vision Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Jiayu Wang",
        "Yifei Ming",
        "Zhenmei Shi",
        "Vibhav Vineet",
        "Xin Wang",
        "Yixuan Li",
        "Neel Joshi"
      ],
      "abstract": "Large language models (LLMs) and vision-language models (VLMs) have\ndemonstrated remarkable performance across a wide range of tasks and domains.\nDespite this promise, spatial understanding and reasoning -- a fundamental\ncomponent of human cognition -- remains under-explored. We propose SpatialEval,\na novel benchmark that covers diverse aspects of spatial reasoning such as\nrelationship understanding, navigation, and counting. We conduct a\ncomprehensive evaluation of competitive language and vision-language models.\nOur findings reveal several counter-intuitive insights that have been\noverlooked in the literature: (1) Spatial reasoning poses significant\nchallenges where competitive models can fall behind random guessing; (2)\nDespite additional visual input, VLMs often under-perform compared to their LLM\ncounterparts; (3) When both textual and visual information is available,\nmulti-modal language models become less reliant on visual information if\nsufficient textual clues are provided. Additionally, we demonstrate that\nleveraging redundancy between vision and text can significantly enhance model\nperformance. We hope our study will inform the development of multimodal models\nto improve spatial intelligence and further close the gap with human\nintelligence.",
      "tldr_zh": "本研究探讨了视觉语言模型（VLMs）和大型语言模型（LLMs）在空间推理方面的不足，尽管它们在其他任务上表现出色。作者提出了一种新基准SpatialEval，涵盖关系理解、导航和计数等空间推理方面，并对竞争模型进行了全面评估。评估结果揭示了几个反直觉见解：空间推理对模型构成重大挑战，甚至落后于随机猜测；VLMs尽管有视觉输入，往往不如LLMs表现；多模态模型在有足够文本线索时，较少依赖视觉信息。最终，研究证明利用视觉和文本之间的冗余可显著提升性能，并呼吁开发更先进的多模态模型，以缩小与人类智能的差距。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted to NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.14852v2",
      "published_date": "2024-06-21 03:53:37 UTC",
      "updated_date": "2024-11-04 21:51:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T23:26:19.576263"
    },
    {
      "arxiv_id": "2406.14844v1",
      "title": "DN-CL: Deep Symbolic Regression against Noise via Contrastive Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Jingyi Liu",
        "Yanjie Li",
        "Lina Yu",
        "Min Wu",
        "Weijun Li",
        "Wenqiang Li",
        "Meilan Hao",
        "Yusong Deng",
        "Shu Wei"
      ],
      "abstract": "Noise ubiquitously exists in signals due to numerous factors including\nphysical, electronic, and environmental effects. Traditional methods of\nsymbolic regression, such as genetic programming or deep learning models, aim\nto find the most fitting expressions for these signals. However, these methods\noften overlook the noise present in real-world data, leading to reduced fitting\naccuracy. To tackle this issue, we propose \\textit{\\textbf{D}eep Symbolic\nRegression against \\textbf{N}oise via \\textbf{C}ontrastive \\textbf{L}earning\n(DN-CL)}. DN-CL employs two parameter-sharing encoders to embed data points\nfrom various data transformations into feature shields against noise. This\nmodel treats noisy data and clean data as different views of the ground-truth\nmathematical expressions. Distances between these features are minimized,\nutilizing contrastive learning to distinguish between 'positive'\nnoise-corrected pairs and 'negative' contrasting pairs. Our experiments\nindicate that DN-CL demonstrates superior performance in handling both noisy\nand clean data, presenting a promising method of symbolic regression.",
      "tldr_zh": "这篇论文针对噪声对符号回归的影响，提出了一种名为 DN-CL 的新方法，通过 Contrastive Learning 提升模型在噪声环境下的鲁棒性。DN-CL 使用两个参数共享的编码器，将数据点从各种转换嵌入到抗噪声的特征空间中，并将噪声数据和干净数据视为地面真实数学表达式的不同视图。实验结果显示，DN-CL 在处理噪声和干净数据时表现出色，显著优于传统符号回归方法，如遗传编程或深度学习模型。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.14844v1",
      "published_date": "2024-06-21 03:13:40 UTC",
      "updated_date": "2024-06-21 03:13:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T23:26:30.049596"
    },
    {
      "arxiv_id": "2406.14840v1",
      "title": "Automated architectural space layout planning using a physics-inspired generative design framework",
      "title_zh": "利用受物理启发的生成式设计框架的自动建筑空间布局规划",
      "authors": [
        "Zhipeng Li",
        "Sichao Li",
        "Geoff Hinchcliffe",
        "Noam Maitless",
        "Nick Birbilis"
      ],
      "abstract": "The determination of space layout is one of the primary activities in the\nschematic design stage of an architectural project. The initial layout planning\ndefines the shape, dimension, and circulation pattern of internal spaces; which\ncan also affect performance and cost of the construction. When carried out\nmanually, space layout planning can be complicated, repetitive and time\nconsuming. In this work, a generative design framework for the automatic\ngeneration of spatial architectural layout has been developed. The proposed\napproach integrates a novel physics-inspired parametric model for space layout\nplanning and an evolutionary optimisation metaheuristic. Results revealed that\nsuch a generative design framework can generate a wide variety of design\nsuggestions at the schematic design stage, applicable to complex design\nproblems.",
      "tldr_zh": "这篇论文针对建筑项目示意设计阶段的空间布局规划问题，提出了一种自动生成方法，以解决手动过程的复杂性、重复性和耗时性。论文开发了一个 \"generative design framework\"，它整合了 \"physics-inspired parametric model\" 用于参数化空间规划，以及 \"evolutionary optimisation metaheuristic\" 进行优化。结果显示，该框架能在示意设计阶段生成多样化的设计建议，适用于复杂设计问题，从而提升建筑性能和成本效率。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.14840v1",
      "published_date": "2024-06-21 02:50:52 UTC",
      "updated_date": "2024-06-21 02:50:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T23:26:45.889957"
    },
    {
      "arxiv_id": "2407.01712v2",
      "title": "A Survey of Retrieval Algorithms in Ad and Content Recommendation Systems",
      "title_zh": "广告和内容推荐系统中的检索算法",
      "authors": [
        "Yu Zhao",
        "Fang Liu"
      ],
      "abstract": "This survey examines the most effective retrieval algorithms utilized in ad\nrecommendation and content recommendation systems. Ad targeting algorithms rely\non detailed user profiles and behavioral data to deliver personalized\nadvertisements, thereby driving revenue through targeted placements.\nConversely, organic retrieval systems aim to improve user experience by\nrecommending content that matches user preferences. This paper compares these\ntwo applications and explains the most effective methods employed in each.",
      "tldr_zh": "这篇调查论文审视了检索算法在广告推荐和内容推荐系统中的应用。广告推荐算法依赖于详细的用户profiles和behavioral data来提供个性化广告，从而通过精准投放提升收入。内容推荐系统则专注于匹配用户偏好，以改善用户体验。论文比较了这两类系统，并阐述了每种应用中最有效的retrieval algorithms。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.01712v2",
      "published_date": "2024-06-21 02:31:03 UTC",
      "updated_date": "2024-07-19 04:16:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T23:26:55.957802"
    },
    {
      "arxiv_id": "2406.14826v2",
      "title": "Self-supervised Brain Lesion Generation for Effective Data Augmentation of Medical Images",
      "title_zh": "自监督脑部病变生成用于医学图像的有效数据增强",
      "authors": [
        "Jiayu Huo",
        "Sebastien Ourselin",
        "Rachel Sparks"
      ],
      "abstract": "Accurate brain lesion delineation is important for planning neurosurgical\ntreatment. Automatic brain lesion segmentation methods based on convolutional\nneural networks have demonstrated remarkable performance. However, neural\nnetwork performance is constrained by the lack of large-scale well-annotated\ntraining datasets. In this manuscript, we propose a comprehensive framework to\nefficiently generate new samples for training a brain lesion segmentation\nmodel. We first train a lesion generator, based on an adversarial autoencoder,\nin a self-supervised manner. Next, we utilize a novel image composition\nalgorithm, Soft Poisson Blending, to seamlessly combine synthetic lesions and\nbrain images to obtain training samples. Finally, to effectively train the\nbrain lesion segmentation model with augmented images we introduce a new\nprototype consistence regularization to align real and synthetic features. Our\nframework is validated by extensive experiments on two public brain lesion\nsegmentation datasets: ATLAS v2.0 and Shift MS. Our method outperforms existing\nbrain image data augmentation schemes. For instance, our method improves the\nDice from 50.36% to 60.23% compared to the U-Net with conventional data\naugmentation techniques for the ATLAS v2.0 dataset.",
      "tldr_zh": "该论文提出了一种自监督(Self-supervised)脑部病变生成框架，用于有效增强医疗图像数据，以解决神经网络训练数据不足的问题。该框架首先利用基于对抗自编码器(Adversarial Autoencoder)的生成器在自监督方式下创建合成病变，然后通过Soft Poisson Blending算法无缝地将这些病变整合到脑部图像中生成训练样本，最后引入原型一致性正则化(Prototype Consistence Regularization)来对齐真实和合成特征，从而优化脑部病变分割模型的训练。在ATLAS v2.0和Shift MS数据集上的实验验证显示，该方法显著优于现有数据增强方案，例如将U-Net的Dice分数从50.36%提高到60.23%。",
      "categories": [
        "eess.IV",
        "cs.AI"
      ],
      "primary_category": "eess.IV",
      "comment": "11 pages, 7 figures, 8 tables",
      "pdf_url": "http://arxiv.org/pdf/2406.14826v2",
      "published_date": "2024-06-21 01:53:12 UTC",
      "updated_date": "2024-08-18 14:15:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T23:27:08.601073"
    },
    {
      "arxiv_id": "2406.14815v4",
      "title": "Latent diffusion models for parameterization and data assimilation of facies-based geomodels",
      "title_zh": "潜在扩散模型用于基于相的地球模型参数化和数据同化",
      "authors": [
        "Guido Di Federico",
        "Louis J. Durlofsky"
      ],
      "abstract": "Geological parameterization entails the representation of a geomodel using a\nsmall set of latent variables and a mapping from these variables to grid-block\nproperties such as porosity and permeability. Parameterization is useful for\ndata assimilation (history matching), as it maintains geological realism while\nreducing the number of variables to be determined. Diffusion models are a new\nclass of generative deep-learning procedures that have been shown to outperform\nprevious methods, such as generative adversarial networks, for image generation\ntasks. Diffusion models are trained to \"denoise\", which enables them to\ngenerate new geological realizations from input fields characterized by random\nnoise. Latent diffusion models, which are the specific variant considered in\nthis study, provide dimension reduction through use of a low-dimensional latent\nvariable. The model developed in this work includes a variational autoencoder\nfor dimension reduction and a U-net for the denoising process. Our application\ninvolves conditional 2D three-facies (channel-levee-mud) systems. The latent\ndiffusion model is shown to provide realizations that are visually consistent\nwith samples from geomodeling software. Quantitative metrics involving spatial\nand flow-response statistics are evaluated, and general agreement between the\ndiffusion-generated models and reference realizations is observed. Stability\ntests are performed to assess the smoothness of the parameterization method.\nThe latent diffusion model is then used for ensemble-based data assimilation.\nTwo synthetic \"true\" models are considered. Significant uncertainty reduction,\nposterior P$_{10}$-P$_{90}$ forecasts that generally bracket observed data, and\nconsistent posterior geomodels, are achieved in both cases.",
      "tldr_zh": "这篇论文提出使用潜在扩散模型（latent diffusion models）对基于相位的地质模型进行参数化和数据同化，通过减少潜在变量数量来保持地质真实性并提升效率。方法结合了变分自动编码器（variational autoencoder）用于维度减少，以及 U-net 用于去噪过程，在条件 2D 三相系统（channel-levee-mud）中生成视觉一致的地质实现。实验结果显示，模型在空间和流响应统计上与参考样本高度一致，并通过稳定性测试验证了参数化方法的平滑性。在数据同化应用中，该模型实现了显著的不确定性减少，后验预测范围（P$_{10}$-P$_{90}$）括住观测数据，并产出一致的后验地质模型。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CE",
        "cs.LG",
        "physics.geo-ph"
      ],
      "primary_category": "cs.CV",
      "comment": "- Replaced Figure 11 with more spaced-out plots",
      "pdf_url": "http://arxiv.org/pdf/2406.14815v4",
      "published_date": "2024-06-21 01:32:03 UTC",
      "updated_date": "2024-10-14 18:14:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T23:27:20.322605"
    },
    {
      "arxiv_id": "2406.14804v1",
      "title": "Securing the Future: Proactive Threat Hunting for Sustainable IoT Ecosystems",
      "title_zh": "翻译失败",
      "authors": [
        "Saeid Ghasemshirazi",
        "Ghazaleh Shirvani"
      ],
      "abstract": "In the rapidly evolving landscape of the IoT, the security of connected\ndevices has become a paramount concern. This paper explores the concept of\nproactive threat hunting as a pivotal strategy for enhancing the security and\nsustainability of IoT systems. Proactive threat hunting is an alternative to\ntraditional reactive security measures that analyses IoT networks continuously\nand in advance to find and eliminate threats before they occure. By improving\nthe security posture of IoT devices this approach significantly contributes to\nextending IoT operational lifespan and reduces environmental impact. By\nintegrating security metrics similar to the Common Vulnerability Scoring System\n(CVSS) into consumer platforms, this paper argues that proactive threat hunting\ncan elevate user awareness about the security of IoT devices. This has the\npotential to impact consumer choices and encourage a security-conscious mindset\nin both the manufacturing and user communities. Through a comprehensive\nanalysis, this study demonstrates how proactive threat hunting can contribute\nto the development of a more secure, sustainable, and user-aware IoT ecosystem.",
      "tldr_zh": "这篇论文探讨了主动威胁狩猎(Proactive Threat Hunting)作为提升IoT生态系统安全性和可持续性的关键策略，以应对快速演变的IoT设备安全挑战。不同于传统的反应式安全措施，该方法通过持续分析IoT网络提前发现并消除潜在威胁，从而延长设备使用寿命、减少环境影响，并将CVSS等安全指标整合到消费者平台中以提高用户意识。研究结果表明，这种主动方法能影响消费者选择，推动制造者和用户社区形成更注重安全的思维，最终构建一个更安全、可持续的IoT生态系统。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.14804v1",
      "published_date": "2024-06-21 00:44:17 UTC",
      "updated_date": "2024-06-21 00:44:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T23:27:31.815796"
    },
    {
      "arxiv_id": "2406.14798v2",
      "title": "Probabilistic Emulation of a Global Climate Model with Spherical DYffusion",
      "title_zh": "翻译失败",
      "authors": [
        "Salva Rühling Cachay",
        "Brian Henn",
        "Oliver Watt-Meyer",
        "Christopher S. Bretherton",
        "Rose Yu"
      ],
      "abstract": "Data-driven deep learning models are transforming global weather forecasting.\nIt is an open question if this success can extend to climate modeling, where\nthe complexity of the data and long inference rollouts pose significant\nchallenges. Here, we present the first conditional generative model that\nproduces accurate and physically consistent global climate ensemble simulations\nby emulating a coarse version of the United States' primary operational global\nforecast model, FV3GFS. Our model integrates the dynamics-informed diffusion\nframework (DYffusion) with the Spherical Fourier Neural Operator (SFNO)\narchitecture, enabling stable 100-year simulations at 6-hourly timesteps while\nmaintaining low computational overhead compared to single-step deterministic\nbaselines. The model achieves near gold-standard performance for climate model\nemulation, outperforming existing approaches and demonstrating promising\nensemble skill. This work represents a significant advance towards efficient,\ndata-driven climate simulations that can enhance our understanding of the\nclimate system and inform adaptation strategies.",
      "tldr_zh": "本文提出了一种基于 Spherical DYffusion 的概率生成模型，用于仿真美国的首要操作全球预测模型 FV3GFS，从而实现准确且物理一致的全球气候集合模拟。该模型整合了 dynamics-informed diffusion framework (DYffusion) 和 Spherical Fourier Neural Operator (SFNO) 架构，能够稳定运行 100 年的 6 小时时间步模拟，同时保持较低的计算开销。实验结果显示，该模型在气候模拟性能上接近金标准，并优于现有方法，在集合模拟方面表现出色。该研究推动了高效的数据驱动气候模拟的发展，有助于加深对气候系统的理解并制定适应策略。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "physics.ao-ph",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "NeurIPS 2024; Code is available at\n  https://github.com/Rose-STL-Lab/spherical-dyffusion",
      "pdf_url": "http://arxiv.org/pdf/2406.14798v2",
      "published_date": "2024-06-21 00:16:55 UTC",
      "updated_date": "2024-11-13 01:36:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T23:27:43.636206"
    },
    {
      "arxiv_id": "2406.14797v1",
      "title": "Camera-Invariant Meta-Learning Network for Single-Camera-Training Person Re-identification",
      "title_zh": "翻译失败",
      "authors": [
        "Jiangbo Pei",
        "Zhuqing Jiang",
        "Aidong Men",
        "Haiying Wang",
        "Haiyong Luo",
        "Shiping Wen"
      ],
      "abstract": "Single-camera-training person re-identification (SCT re-ID) aims to train a\nre-ID model using SCT datasets where each person appears in only one camera.\nThe main challenge of SCT re-ID is to learn camera-invariant feature\nrepresentations without cross-camera same-person (CCSP) data as supervision.\nPrevious methods address it by assuming that the most similar person should be\nfound in another camera. However, this assumption is not guaranteed to be\ncorrect. In this paper, we propose a Camera-Invariant Meta-Learning Network\n(CIMN) for SCT re-ID. CIMN assumes that the camera-invariant feature\nrepresentations should be robust to camera changes. To this end, we split the\ntraining data into meta-train set and meta-test set based on camera IDs and\nperform a cross-camera simulation via meta-learning strategy, aiming to enforce\nthe representations learned from the meta-train set to be robust to the\nmeta-test set. With the cross-camera simulation, CIMN can learn\ncamera-invariant and identity-discriminative representations even there are no\nCCSP data. However, this simulation also causes the separation of the\nmeta-train set and the meta-test set, which ignores some beneficial relations\nbetween them. Thus, we introduce three losses: meta triplet loss, meta\nclassification loss, and meta camera alignment loss, to leverage the ignored\nrelations. The experiment results demonstrate that our method achieves\ncomparable performance with and without CCSP data, and outperforms the\nstate-of-the-art methods on SCT re-ID benchmarks. In addition, it is also\neffective in improving the domain generalization ability of the model.",
      "tldr_zh": "本论文针对 Single-Camera-Training Person Re-identification (SCT re-ID) 问题，提出 Camera-Invariant Meta-Learning Network (CIMN)，旨在在没有跨摄像头同身份 (CCSP) 数据的情况下学习摄像头无关的特征表示。CIMN 通过元学习 (meta-learning) 策略将训练数据分成 meta-train 和 meta-test 集，并模拟跨摄像头场景，以确保从 meta-train 集学到的表示在 meta-test 集上保持鲁棒性。论文引入 meta triplet loss、meta classification loss 和 meta camera alignment loss 来利用 meta-train 和 meta-test 集之间的潜在关系，从而提升身份辨别能力。实验结果显示，CIMN 在 SCT re-ID 基准测试中优于现有方法，并在没有 CCSP 数据时实现与有数据时相当的表现，同时提高了模型的领域泛化能力。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.14797v1",
      "published_date": "2024-06-21 00:15:32 UTC",
      "updated_date": "2024-06-21 00:15:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T23:27:56.073852"
    },
    {
      "arxiv_id": "2406.14796v2",
      "title": "MU-Bench: A Multitask Multimodal Benchmark for Machine Unlearning",
      "title_zh": "翻译失败",
      "authors": [
        "Jiali Cheng",
        "Hadi Amiri"
      ],
      "abstract": "Recent advancements in Machine Unlearning (MU) have introduced solutions to\nselectively remove certain training samples, such as those with outdated or\nsensitive information, from trained models. Despite these advancements,\nevaluation of MU methods have been inconsistent, employing different trained\nmodels and architectures, and sample removal strategies, which hampers accurate\ncomparison. In addition, prior MU approaches have mainly focused on singular\ntasks or modalities, which is not comprehensive. To address these limitations,\nwe develop MU-Bench, the first comprehensive benchmark for MU that (i) unifies\nthe sets of deleted samples and trained models, and (ii) provides broad\ncoverage of tasks and data modalities, including previously unexplored domains\nsuch as speech and video classification. Our evaluation show that RandLabel and\nSalUn are the most effective general MU approaches on MU-Bench, and BadT and\nSCRUB are capable of achieving random performance on the deletion set. We\nanalyze several under-investigated aspects of unlearning, including\nscalability, the impacts of parameter-efficient fine-tuning and curriculum\nlearning, and susceptibility to dataset biases. MU-Bench provides an\neasy-to-use package that includes dataset splits, models, and implementations,\ntogether with a leader board to enable unified and scalable MU research.",
      "tldr_zh": "该论文介绍了 MU-Bench，一种全面的多任务多模态基准，用于评估 Machine Unlearning (MU) 方法，以解决现有方法评估不一致和单一任务局限的问题。MU-Bench 统一了删除样本集和训练模型，并扩展到语音和视频分类等未探索领域，提供更广泛的任务覆盖。实验结果显示，RandLabel 和 SalUn 是最有效的通用 MU 策略，而 BadT 和 SCRUB 能在删除集上达到随机性能。该基准还分析了 MU 的可扩展性、参数高效微调的影响、课程学习的作用以及对数据集偏差的易感性，并提供易用包和排行榜以推动统一研究。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "SafeGenAI @ NeurIPS 2024. Project page:\n  https://clu-uml.github.io/MU-Bench-Project-Page/",
      "pdf_url": "http://arxiv.org/pdf/2406.14796v2",
      "published_date": "2024-06-21 00:13:17 UTC",
      "updated_date": "2024-12-22 23:47:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T23:28:07.608676"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 98,
  "processed_papers_count": 98,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-18T23:28:34.554795"
}