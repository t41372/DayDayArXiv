{
  "date": "2024-05-21",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-05-21 的 arXiv 中文 TLDR 快报！\n\n今天 arXiv 的论文主要聚焦于 AI 应用的多领域创新，包括 LLM 在教育和医疗中的潜力、AI 安全监控、机器人技术进步，以及知名学者如 Google 和 Stanford 团队的贡献。其中，令人印象深刻的文章有第 14 篇（教育 AI 基准）和第 7 篇（医疗 AI 可靠性评估），它们展示了 AI 如何在实际场景中提升准确性和伦理性，同时强调了 LLM 的局限性。\n\n下面，我将挑选并简要讨论部分关键论文，先优先聊那些重要、话题度高或涉及著名学者的文章（如 AI 安全、LLM 应用和机器人领域），相关主题的论文会放在一起讨论。对于其他较无聊或次要的论文（如纯理论模型或小众应用），我将快速掠过，只列出标题和核心要点。\n\n### AI 安全与伦理\n- **系统安全监控的临时度量预测 / System Safety Monitoring of Learned Components Using Temporal Metric Forecasting**（第 1 篇）：论文提出基于概率时间序列预测的安全监控方法，使用 Temporal Fusion Transformer 模型预测安全违规，针对自主航空和驾驶案例，显著提高了预测准确性和低延迟。\n- **多重实现性和深度学习的兴起 / Multiple Realizability and the Rise of Deep Learning**（第 4 篇）：作者 Sam Whitman McGrath 和 Jacob Russin 探讨深度学习模型如何支持多重实现性，挑战了认知科学中独立研究心智和实现的观点，强调深度神经网络在假设验证中的关键作用。\n- **AI 聊天机器人用于疾病预测的可靠性评估 / How Reliable AI Chatbots are for Disease Prediction from Patient Complaints**（第 7 篇）：研究评估 GPT-4.0 等模型在紧急医疗预测中的表现，发现它们准确性有限，需要人类监督；贡献在于使用少样本学习比较模型性能，突显 AI 在医疗决策中的潜在风险。\n- **AI 生成内容的伦理与政策 / Securing the Future of GenAI: Policy and Technology**（第 12 篇）：Google 和 Stanford 等机构合作，讨论生成 AI 的安全政策，提出技术与法规的平衡框架；这篇有话题度，强调了 AI 风险管理的重要性。\n\n这些论文共同揭示了 AI 安全的挑战，如模型幻觉和数据隐私问题，但它们在实际应用中（如医疗和政策）提供了可行的解决方案，值得关注。\n\n### LLM 和生成 AI 应用\n- **生成 AI 在教育中的负责任发展 / Towards Responsible Development of Generative AI for Education: An Evaluation-Driven Approach**（第 14 篇）：Google 和 Stanford 团队构建了教育基准和 LearnLM-Tutor 模型，通过量化评估提升 AI 教学能力；主要发现是 AI 可以个性化教育，但需严格验证以避免偏差。\n- **LLM 在数学建模中的作用 / LLMs for Mathematical Modeling: Towards Bridging the Gap between Natural and Mathematical Languages**（第 29 篇）：论文探索 LLM 在数学任务中的表现，发现大模型在复杂建模上更有效，但仍需改进；贡献在于提出 Mamo 基准数据集，展示了 LLM 的潜力。\n- **AI 在对话代理中的道德决策 / Skin-in-the-Game: Decision Making via Multi-Stakeholder Alignment in LLMs**（第 24 篇）：ACL 2024 论文，使用多利益相关者框架减少 LLM 毒性；发现通过强化学习可提升模型的道德推理，减少负面输出。\n- **快速掠过其他 LLM 相关**：如第 21 篇（能量秩对齐增强 LLM）、第 39 篇（LLM 在 NLP 的综述）等，它们扩展了 LLM 的应用，但细节较常规，仅强调 LLM 在跨领域迁移的进步。\n\nLLM 论文突出了其在教育、数学和道德决策中的潜力，但也暴露了 hallucination 和泛化问题，Google 等团队的参与增加了其影响力。\n\n### 机器人与计算机视觉\n- **单图像模仿学习 / One-Shot Imitation Learning with Invariance Matching for Robotic Manipulation**（第 13 篇）：RSS 2024 论文，提出 IMOP 算法，通过不变性匹配实现机器人单样本学习；主要发现是模型在新型任务上提升了 11.5% 的成功率，支持真实机器人转移。\n- **相机感知图像到视频生成 / CamViG: Camera Aware Image-to-Video Generation with Multimodal Transformers**（第 10 篇）：使用多模态 Transformer 条件生成视频，实现了精确的 3D 相机路径控制；贡献在于提升视频生成的质量和准确性。\n- **空间-时间图神经网络在脑网络中的应用 / Interpretable Spatio-Temporal Embedding for Brain Structural-Effective Network with Ordinary Differential Equation**（第 11 篇）：论文使用 STE-ODE 框架预测脑网络动态，在临床任务中优于现有方法；发现模型在 HCP 和 OASIS 数据集上表现出色。\n- **快速掠过其他机器人相关**：如第 5 篇（铁路地图组件识别）、第 8 篇（LiDAR 在交通中的应用）等，它们优化了特定场景，但影响力较小，仅提炼了如 Faster-RCNN 的性能提升。\n\n这些机器人论文展示了 AI 在实际操控和视觉生成中的进展，IMOP 等方法特别有话题度，因为它们支持高效的真实世界应用。\n\n其他论文如量子计算（第 9 篇，强化学习加速电路合成）、交通预测（第 18 篇，LiDAR 对象检测）和一般 AI 框架（第 33、38 篇）等，虽然有技术贡献，但相对次要，我这里仅快速提及核心：它们改善了效率和泛化，但未涉及重大突破。\n\n总之，今天的 arXiv 论文强调 AI 的实用性和挑战，LLM 在教育领域的创新（如第 14 篇）最值得关注。希望这个快报能帮助你快速筛选感兴趣的文章！",
  "papers": [
    {
      "arxiv_id": "2405.13254v3",
      "title": "System Safety Monitoring of Learned Components Using Temporal Metric Forecasting",
      "title_zh": "翻译失败",
      "authors": [
        "Sepehr Sharifi",
        "Andrea Stocco",
        "Lionel C. Briand"
      ],
      "abstract": "In learning-enabled autonomous systems, safety monitoring of learned\ncomponents is crucial to ensure their outputs do not lead to system safety\nviolations, given the operational context of the system. However, developing a\nsafety monitor for practical deployment in real-world applications is\nchallenging. This is due to limited access to internal workings and training\ndata of the learned component. Furthermore, safety monitors should predict\nsafety violations with low latency, while consuming a reasonable amount of\ncomputation. To address the challenges, we propose a safety monitoring method\nbased on probabilistic time series forecasting. Given the learned component\noutputs and an operational context, we empirically investigate different Deep\nLearning (DL)-based probabilistic forecasting to predict the objective measure\ncapturing the satisfaction or violation of a safety requirement (safety\nmetric). We empirically evaluate safety metric and violation prediction\naccuracy, and inference latency and resource usage of four state-of-the-art\nmodels, with varying horizons, using autonomous aviation and autonomous driving\ncase studies. Our results suggest that probabilistic forecasting of safety\nmetrics, given learned component outputs and scenarios, is effective for safety\nmonitoring. Furthermore, for both case studies, Temporal Fusion Transformer\n(TFT) was the most accurate model for predicting imminent safety violations,\nwith acceptable latency and resource consumption.",
      "tldr_zh": "该研究针对学习型自主系统中学习组件的安全监控问题，提出了一种基于概率时间序列预测的方法，以确保组件输出不会导致系统安全违反。该方法利用学习组件的输出和操作上下文，通过多种Deep Learning (DL)-based 概率预测模型来预测安全指标（safety metric），从而评估安全要求的满足或违反情况。在自主航空和自主驾驶案例研究中，实验评估了四种最先进模型的预测准确性、推理延迟和资源使用。结果显示，Temporal Fusion Transformer (TFT) 在预测即将来临的安全违反方面表现最佳，同时保持了可接受的延迟和资源消耗，为实际部署的安全监控提供了有效解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.RO",
        "cs.SE"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted for publication by ACM Transactions on Software Engineering\n  and Methodology (TOSEM)",
      "pdf_url": "http://arxiv.org/pdf/2405.13254v3",
      "published_date": "2024-05-21 23:48:26 UTC",
      "updated_date": "2024-12-20 03:10:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:00:13.885062"
    },
    {
      "arxiv_id": "2405.13245v2",
      "title": "A Survey of Robotic Language Grounding: Tradeoffs between Symbols and Embeddings",
      "title_zh": "翻译失败",
      "authors": [
        "Vanya Cohen",
        "Jason Xinyu Liu",
        "Raymond Mooney",
        "Stefanie Tellex",
        "David Watkins"
      ],
      "abstract": "With large language models, robots can understand language more flexibly and\nmore capable than ever before. This survey reviews and situates recent\nliterature into a spectrum with two poles: 1) mapping between language and some\nmanually defined formal representation of meaning, and 2) mapping between\nlanguage and high-dimensional vector spaces that translate directly to\nlow-level robot policy. Using a formal representation allows the meaning of the\nlanguage to be precisely represented, limits the size of the learning problem,\nand leads to a framework for interpretability and formal safety guarantees.\nMethods that embed language and perceptual data into high-dimensional spaces\navoid this manually specified symbolic structure and thus have the potential to\nbe more general when fed enough data but require more data and computing to\ntrain. We discuss the benefits and tradeoffs of each approach and finish by\nproviding directions for future work that achieves the best of both worlds.",
      "tldr_zh": "这篇调查论文探讨了机器人语言 grounding 在符号（symbols）和嵌入（embeddings）之间的权衡，审视了大型语言模型如何提升机器人的语言理解能力。论文将现有文献分为两极：一是将语言映射到手动定义的形式化表示，这能提供精确表示、减少学习问题规模，并支持可解释性和正式安全保证；二是将语言映射到高维向量空间，直接转化为机器人低级策略，这种方法更具泛化潜力但需要更多数据和计算资源。作者分析了每种方法的优势与缺点，并提出未来工作方向，旨在融合两者的优点以实现更高效的语言 grounding 系统。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.RO",
      "comment": "IJCAI 2024 Survey Track",
      "pdf_url": "http://arxiv.org/pdf/2405.13245v2",
      "published_date": "2024-05-21 23:12:03 UTC",
      "updated_date": "2024-06-22 13:03:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:00:26.010993"
    },
    {
      "arxiv_id": "2405.13242v3",
      "title": "Goals as Reward-Producing Programs",
      "title_zh": "目标作为产生奖励的程序",
      "authors": [
        "Guy Davidson",
        "Graham Todd",
        "Julian Togelius",
        "Todd M. Gureckis",
        "Brenden M. Lake"
      ],
      "abstract": "People are remarkably capable of generating their own goals, beginning with\nchild's play and continuing into adulthood. Despite considerable empirical and\ncomputational work on goals and goal-oriented behavior, models are still far\nfrom capturing the richness of everyday human goals. Here, we bridge this gap\nby collecting a dataset of human-generated playful goals (in the form of\nscorable, single-player games), modeling them as reward-producing programs, and\ngenerating novel human-like goals through program synthesis. Reward-producing\nprograms capture the rich semantics of goals through symbolic operations that\ncompose, add temporal constraints, and allow for program execution on\nbehavioral traces to evaluate progress. To build a generative model of goals,\nwe learn a fitness function over the infinite set of possible goal programs and\nsample novel goals with a quality-diversity algorithm. Human evaluators found\nthat model-generated goals, when sampled from partitions of program space\noccupied by human examples, were indistinguishable from human-created games. We\nalso discovered that our model's internal fitness scores predict games that are\nevaluated as more fun to play and more human-like.",
      "tldr_zh": "本文提出了一种将人类目标建模为reward-producing programs的方法，通过收集人类生成的可玩游戏数据集，捕捉目标的丰富语义，包括符号操作、时间约束和行为轨迹评估。研究构建了一个生成模型，利用程序合成和quality-diversity算法学习适应度函数，以从无限程序空间中采样新型目标。实验结果显示，模型生成的游戏在人类评估中与真实人类创建的游戏无法区分，且内部适应度分数能有效预测游戏的趣味性和人类相似度。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Project website and goal program viewer:\n  https://exps.gureckislab.org/guydav/goal_programs_viewer/main/",
      "pdf_url": "http://arxiv.org/pdf/2405.13242v3",
      "published_date": "2024-05-21 23:09:12 UTC",
      "updated_date": "2024-09-10 22:29:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:00:37.900736"
    },
    {
      "arxiv_id": "2405.13231v1",
      "title": "Multiple Realizability and the Rise of Deep Learning",
      "title_zh": "多重实现性与深度学习的兴起",
      "authors": [
        "Sam Whitman McGrath",
        "Jacob Russin"
      ],
      "abstract": "The multiple realizability thesis holds that psychological states may be\nimplemented in a diversity of physical systems. The deep learning revolution\nseems to be bringing this possibility to life, offering the most plausible\nexamples of man-made realizations of sophisticated cognitive functions to date.\nThis paper explores the implications of deep learning models for the multiple\nrealizability thesis. Among other things, it challenges the widely held view\nthat multiple realizability entails that the study of the mind can and must be\npursued independently of the study of its implementation in the brain or in\nartificial analogues. Although its central contribution is philosophical, the\npaper has substantial methodological upshots for contemporary cognitive\nscience, suggesting that deep neural networks may play a crucial role in\nformulating and evaluating hypotheses about cognition, even if they are\ninterpreted as implementation-level models. In the age of deep learning,\nmultiple realizability possesses a renewed significance.",
      "tldr_zh": "该论文探讨了“multiple realizability”论点，即心理状态可由多种物理系统实现，并分析深度学习革命如何提供人为实现复杂认知功能的实际例子。主要贡献在于挑战传统观点，即对心智的研究必须独立于大脑或人工模拟的实现研究，强调深度学习模型在认知科学中的重要性。论文建议，深度神经网络即使作为实现级模型，也能在制定和评估认知假设方面发挥关键作用，从而赋予“multiple realizability”在当代认知科学中新的意义。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.13231v1",
      "published_date": "2024-05-21 22:36:49 UTC",
      "updated_date": "2024-05-21 22:36:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:00:49.440559"
    },
    {
      "arxiv_id": "2405.13229v1",
      "title": "Transfer Learning Approach for Railway Technical Map (RTM) Component Identification",
      "title_zh": "翻译失败",
      "authors": [
        "Obadage Rochana Rumalshan",
        "Pramuka Weerasinghe",
        "Mohamed Shaheer",
        "Prabhath Gunathilake",
        "Erunika Dayaratna"
      ],
      "abstract": "The extreme popularity over the years for railway transportation urges the\nnecessity to maintain efficient railway management systems around the globe.\nEven though, at present, there exist a large collection of Computer Aided\nDesigned Railway Technical Maps (RTMs) but available only in the portable\ndocument format (PDF). Using Deep Learning and Optical Character Recognition\ntechniques, this research work proposes a generic system to digitize the\nrelevant map component data from a given input image and create a formatted\ntext file per image. Out of YOLOv3, SSD and Faster-RCNN object detection models\nused, Faster-RCNN yields the highest mean Average Precision (mAP) and the\nhighest F1 score values 0.68 and 0.76 respectively. Further it is proven from\nthe results obtained that, one can improve the results with OCR when the text\ncontaining image is being sent through a sophisticated pre-processing pipeline\nto remove distortions.",
      "tldr_zh": "这篇论文提出了一种基于转移学习的系统，用于从铁路技术地图 (RTM) 的图像中识别和数字化组件数据，以支持高效的铁路管理系统。系统结合了深度学习物体检测模型（如 YOLOv3、SSD 和 Faster-RCNN）和光学字符识别 (OCR) 技术，其中 Faster-RCNN 模型表现最佳，取得了 0.68 的 mean Average Precision (mAP) 和 0.76 的 F1 分数。实验结果还表明，通过先进的预处理管道去除图像失真，可以显著提升 OCR 的准确性，为 RTM 的数字化提供了一个通用解决方案。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.DL"
      ],
      "primary_category": "cs.CV",
      "comment": "9 pages, 8 figures",
      "pdf_url": "http://arxiv.org/pdf/2405.13229v1",
      "published_date": "2024-05-21 22:35:08 UTC",
      "updated_date": "2024-05-21 22:35:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:01:03.394906"
    },
    {
      "arxiv_id": "2405.13220v2",
      "title": "Paired Autoencoders for Likelihood-free Estimation in Inverse Problems",
      "title_zh": "翻译失败",
      "authors": [
        "Matthias Chung",
        "Emma Hart",
        "Julianne Chung",
        "Bas Peters",
        "Eldad Haber"
      ],
      "abstract": "We consider the solution of nonlinear inverse problems where the forward\nproblem is a discretization of a partial differential equation. Such problems\nare notoriously difficult to solve in practice and require minimizing a\ncombination of a data-fit term and a regularization term. The main\ncomputational bottleneck of typical algorithms is the direct estimation of the\ndata misfit. Therefore, likelihood-free approaches have become appealing\nalternatives. Nonetheless, difficulties in generalization and limitations in\naccuracy have hindered their broader utility and applicability. In this work,\nwe use a paired autoencoder framework as a likelihood-free estimator for\ninverse problems. We show that the use of such an architecture allows us to\nconstruct a solution efficiently and to overcome some known open problems when\nusing likelihood-free estimators. In particular, our framework can assess the\nquality of the solution and improve on it if needed. We demonstrate the\nviability of our approach using examples from full waveform inversion and\ninverse electromagnetic imaging.",
      "tldr_zh": "本文提出使用paired autoencoders框架作为无似然估计器（likelihood-free estimation），以解决非线性逆问题中的数据失配瓶颈，这些问题通常涉及偏微分方程（PDEs）的离散化。该框架允许高效构建解决方案，并能评估其质量并进行必要改进，从而克服传统无似然方法的泛化和准确性限制。在全波形反演（full waveform inversion）和逆电磁成像（inverse electromagnetic imaging）的示例中，实验证明了该方法的有效性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NA",
        "math.NA"
      ],
      "primary_category": "cs.LG",
      "comment": "18 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2405.13220v2",
      "published_date": "2024-05-21 22:00:34 UTC",
      "updated_date": "2024-12-03 16:00:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:01:13.697821"
    },
    {
      "arxiv_id": "2405.13219v1",
      "title": "How Reliable AI Chatbots are for Disease Prediction from Patient Complaints?",
      "title_zh": "AI 聊天机器人从患者投诉预测",
      "authors": [
        "Ayesha Siddika Nipu",
        "K M Sajjadul Islam",
        "Praveen Madiraju"
      ],
      "abstract": "Artificial Intelligence (AI) chatbots leveraging Large Language Models (LLMs)\nare gaining traction in healthcare for their potential to automate patient\ninteractions and aid clinical decision-making. This study examines the\nreliability of AI chatbots, specifically GPT 4.0, Claude 3 Opus, and Gemini\nUltra 1.0, in predicting diseases from patient complaints in the emergency\ndepartment. The methodology includes few-shot learning techniques to evaluate\nthe chatbots' effectiveness in disease prediction. We also fine-tune the\ntransformer-based model BERT and compare its performance with the AI chatbots.\nResults suggest that GPT 4.0 achieves high accuracy with increased few-shot\ndata, while Gemini Ultra 1.0 performs well with fewer examples, and Claude 3\nOpus maintains consistent performance. BERT's performance, however, is lower\nthan all the chatbots, indicating limitations due to limited labeled data.\nDespite the chatbots' varying accuracy, none of them are sufficiently reliable\nfor critical medical decision-making, underscoring the need for rigorous\nvalidation and human oversight. This study reflects that while AI chatbots have\npotential in healthcare, they should complement, not replace, human expertise\nto ensure patient safety. Further refinement and research are needed to improve\nAI-based healthcare applications' reliability for disease prediction.",
      "tldr_zh": "本研究评估了AI聊天机器人（如GPT 4.0、Claude 3 Opus和Gemini Ultra 1.0）在从患者投诉预测疾病时的可靠性，旨在探讨其在紧急部门的应用潜力。研究采用Few-shot learning技术对这些机器人进行评估，并与fine-tuned BERT模型进行比较，结果显示GPT 4.0在样本增加时准确率最高，Gemini Ultra 1.0在少样本场景下表现良好，而Claude 3 Opus保持稳定一致，但BERT的性能较低。总体而言，尽管聊天机器人显示出潜力，但其准确性不足以支持关键医疗决策，因此需要人类监督和进一步优化，以确保AI在医疗中的安全应用。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "24th IEEE International Conference on Information Reuse and\n  Integration (IEEE IRI 2024), San Jose, CA, USA",
      "pdf_url": "http://arxiv.org/pdf/2405.13219v1",
      "published_date": "2024-05-21 22:00:13 UTC",
      "updated_date": "2024-05-21 22:00:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:01:26.045364"
    },
    {
      "arxiv_id": "2405.13202v1",
      "title": "Empowering Urban Traffic Management: Elevated 3D LiDAR for Data Collection and Advanced Object Detection Analysis",
      "title_zh": "增强城市交通管理：用于数据收集和高级物体检测分析的升空 3D LiDAR",
      "authors": [
        "Nawfal Guefrachi",
        "Hakim Ghazzai",
        "Ahmad Alsharoa"
      ],
      "abstract": "The 3D object detection capabilities in urban environments have been\nenormously improved by recent developments in Light Detection and Range (LiDAR)\ntechnology. This paper presents a novel framework that transforms the detection\nand analysis of 3D objects in traffic scenarios by utilizing the power of\nelevated LiDAR sensors. We are presenting our methodology's remarkable capacity\nto collect complex 3D point cloud data, which allows us to accurately and in\ndetail capture the dynamics of urban traffic. Due to the limitation in\nobtaining real-world traffic datasets, we utilize the simulator to generate 3D\npoint cloud for specific scenarios. To support our experimental analysis, we\nfirstly simulate various 3D point cloud traffic-related objects. Then, we use\nthis dataset as a basis for training and evaluating our 3D object detection\nmodels, in identifying and monitoring both vehicles and pedestrians in\nsimulated urban traffic environments. Next, we fine tune the Point\nVoxel-Region-based Convolutional Neural Network (PV-RCNN) architecture, making\nit more suited to handle and understand the massive volumes of point cloud data\ngenerated by our urban traffic simulations. Our results show the effectiveness\nof the proposed solution in accurately detecting objects in traffic scenes and\nhighlight the role of LiDAR in improving urban safety and advancing intelligent\ntransportation systems.",
      "tldr_zh": "本研究提出了一种新框架，利用高位 3D LiDAR 传感器提升城市交通场景中的物体检测和分析能力，通过收集详细的 3D 点云数据来捕捉交通动态。鉴于获取真实数据受限，该方法采用模拟器生成交通相关物体的 3D 点云数据集，并以此为基础训练和评估微调后的 Point Voxel-Region-based Convolutional Neural Network (PV-RCNN) 模型，以精确识别车辆和行人。实验结果显示，该框架在模拟城市环境中显著提高了物体检测准确性，从而增强了城市安全并推动智能交通系统的进步。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.13202v1",
      "published_date": "2024-05-21 21:12:09 UTC",
      "updated_date": "2024-05-21 21:12:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:01:37.259251"
    },
    {
      "arxiv_id": "2405.13196v2",
      "title": "Practical and efficient quantum circuit synthesis and transpiling with Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "David Kremer",
        "Victor Villar",
        "Hanhee Paik",
        "Ivan Duran",
        "Ismael Faro",
        "Juan Cruz-Benito"
      ],
      "abstract": "This paper demonstrates the integration of Reinforcement Learning (RL) into\nquantum transpiling workflows, significantly enhancing the synthesis and\nrouting of quantum circuits. By employing RL, we achieve near-optimal synthesis\nof Linear Function, Clifford, and Permutation circuits, up to 9, 11 and 65\nqubits respectively, while being compatible with native device instruction sets\nand connectivity constraints, and orders of magnitude faster than optimization\nmethods such as SAT solvers. We also achieve significant reductions in\ntwo-qubit gate depth and count for circuit routing up to 133 qubits with\nrespect to other routing heuristics such as SABRE. We find the method to be\nefficient enough to be useful in practice in typical quantum transpiling\npipelines. Our results set the stage for further AI-powered enhancements of\nquantum computing workflows.",
      "tldr_zh": "该论文提出了一种利用 Reinforcement Learning (RL) 增强量子电路合成和 transpiling 的实用方法，能够高效处理电路路由和优化。RL 框架实现了 Linear Function、Clifford 和 Permutation 电路的近似最优合成，支持高达 9、11 和 65 量子比特，并与设备指令集和连接约束兼容，比 SAT solvers 等优化技术快几个数量级。在路由方面，该方法显著降低了双量子门深度和数量，支持高达 133 量子比特，比 SABRE 等启发式算法更高效。该研究证明了 RL 在实际量子 transpiling 管道中的实用性，并为 AI 驱动的量子计算工作流提供了新基础。",
      "categories": [
        "quant-ph",
        "cs.AI"
      ],
      "primary_category": "quant-ph",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.13196v2",
      "published_date": "2024-05-21 20:59:12 UTC",
      "updated_date": "2025-02-26 15:38:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:01:51.143842"
    },
    {
      "arxiv_id": "2405.13195v1",
      "title": "CamViG: Camera Aware Image-to-Video Generation with Multimodal Transformers",
      "title_zh": "翻译失败",
      "authors": [
        "Andrew Marmon",
        "Grant Schindler",
        "José Lezama",
        "Dan Kondratyuk",
        "Bryan Seybold",
        "Irfan Essa"
      ],
      "abstract": "We extend multimodal transformers to include 3D camera motion as a\nconditioning signal for the task of video generation. Generative video models\nare becoming increasingly powerful, thus focusing research efforts on methods\nof controlling the output of such models. We propose to add virtual 3D camera\ncontrols to generative video methods by conditioning generated video on an\nencoding of three-dimensional camera movement over the course of the generated\nvideo. Results demonstrate that we are (1) able to successfully control the\ncamera during video generation, starting from a single frame and a camera\nsignal, and (2) we demonstrate the accuracy of the generated 3D camera paths\nusing traditional computer vision methods.",
      "tldr_zh": "本文提出 CamViG，一种基于 Multimodal Transformers 的图像到视频生成方法，将 3D 相机运动作为条件信号，以增强视频生成的可控性。该方法通过编码三维相机运动来控制生成视频的相机路径，从单帧和相机信号出发，实现精确的视频合成。实验结果表明，CamViG 成功实现了相机控制，并使用传统计算机视觉方法验证了生成的 3D 相机路径的准确性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.13195v1",
      "published_date": "2024-05-21 20:54:27 UTC",
      "updated_date": "2024-05-21 20:54:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:02:02.106146"
    },
    {
      "arxiv_id": "2405.13190v1",
      "title": "Interpretable Spatio-Temporal Embedding for Brain Structural-Effective Network with Ordinary Differential Equation",
      "title_zh": "翻译失败",
      "authors": [
        "Haoteng Tang",
        "Guodong Liu",
        "Siyuan Dai",
        "Kai Ye",
        "Kun Zhao",
        "Wenlu Wang",
        "Carl Yang",
        "Lifang He",
        "Alex Leow",
        "Paul Thompson",
        "Heng Huang",
        "Liang Zhan"
      ],
      "abstract": "The MRI-derived brain network serves as a pivotal instrument in elucidating\nboth the structural and functional aspects of the brain, encompassing the\nramifications of diseases and developmental processes. However, prevailing\nmethodologies, often focusing on synchronous BOLD signals from functional MRI\n(fMRI), may not capture directional influences among brain regions and rarely\ntackle temporal functional dynamics. In this study, we first construct the\nbrain-effective network via the dynamic causal model. Subsequently, we\nintroduce an interpretable graph learning framework termed Spatio-Temporal\nEmbedding ODE (STE-ODE). This framework incorporates specifically designed\ndirected node embedding layers, aiming at capturing the dynamic interplay\nbetween structural and effective networks via an ordinary differential equation\n(ODE) model, which characterizes spatial-temporal brain dynamics. Our framework\nis validated on several clinical phenotype prediction tasks using two\nindependent publicly available datasets (HCP and OASIS). The experimental\nresults clearly demonstrate the advantages of our model compared to several\nstate-of-the-art methods.",
      "tldr_zh": "本文提出了一种可解释的图学习框架——Spatio-Temporal Embedding ODE (STE-ODE)，旨在通过普通微分方程 (ODE) 模型捕捉脑结构网络和有效网络之间的空间-时间动态交互，以解决传统 fMRI 方法在捕捉脑区定向影响和时间动态方面的局限性。研究首先利用动态因果模型构建脑有效网络，然后通过设计的定向节点嵌入层实现对脑动态的精确建模。在 HCP 和 OASIS 等公开数据集上的临床表型预测任务中，实验结果显示该框架比现有 state-of-the-art 方法表现出显著优势。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.13190v1",
      "published_date": "2024-05-21 20:37:07 UTC",
      "updated_date": "2024-05-21 20:37:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:02:15.314650"
    },
    {
      "arxiv_id": "2407.12999v1",
      "title": "Securing the Future of GenAI: Policy and Technology",
      "title_zh": "保障 GenAI 的未来：政策和技术",
      "authors": [
        "Mihai Christodorescu",
        "Ryan Craven",
        "Soheil Feizi",
        "Neil Gong",
        "Mia Hoffmann",
        "Somesh Jha",
        "Zhengyuan Jiang",
        "Mehrdad Saberi Kamarposhti",
        "John Mitchell",
        "Jessica Newman",
        "Emelia Probasco",
        "Yanjun Qi",
        "Khawaja Shams",
        "Matthew Turek"
      ],
      "abstract": "The rise of Generative AI (GenAI) brings about transformative potential\nacross sectors, but its dual-use nature also amplifies risks. Governments\nglobally are grappling with the challenge of regulating GenAI, balancing\ninnovation against safety. China, the United States (US), and the European\nUnion (EU) are at the forefront with initiatives like the Management of\nAlgorithmic Recommendations, the Executive Order, and the AI Act, respectively.\nHowever, the rapid evolution of GenAI capabilities often outpaces the\ndevelopment of comprehensive safety measures, creating a gap between regulatory\nneeds and technical advancements.\n  A workshop co-organized by Google, University of Wisconsin, Madison\n(UW-Madison), and Stanford University aimed to bridge this gap between GenAI\npolicy and technology. The diverse stakeholders of the GenAI space -- from the\npublic and governments to academia and industry -- make any safety measures\nunder consideration more complex, as both technical feasibility and regulatory\nguidance must be realized. This paper summarizes the discussions during the\nworkshop which addressed questions, such as: How regulation can be designed\nwithout hindering technological progress? How technology can evolve to meet\nregulatory standards? The interplay between legislation and technology is a\nvery vast topic, and we don't claim that this paper is a comprehensive\ntreatment on this topic. This paper is meant to capture findings based on the\nworkshop, and hopefully, can guide discussion on this topic.",
      "tldr_zh": "本论文探讨了生成式 AI (GenAI) 的双重性，包括其变革潜力与潜在风险，并分析了全球监管挑战。中国、美国和欧盟的举措（如 Management of Algorithmic Recommendations、Executive Order 和 AI Act）旨在平衡创新与安全，但技术进展往往快于政策制定。论文总结了一次由 Google、UW-Madison 和 Stanford 大学共同组织的研讨会，讨论了如何设计监管以不阻碍技术进步，以及如何使技术适应法规标准；这些见解旨在指导未来政策和技术互动。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.12999v1",
      "published_date": "2024-05-21 20:30:01 UTC",
      "updated_date": "2024-05-21 20:30:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:02:25.358084"
    },
    {
      "arxiv_id": "2405.13178v2",
      "title": "One-Shot Imitation Learning with Invariance Matching for Robotic Manipulation",
      "title_zh": "翻译失败",
      "authors": [
        "Xinyu Zhang",
        "Abdeslam Boularias"
      ],
      "abstract": "Learning a single universal policy that can perform a diverse set of\nmanipulation tasks is a promising new direction in robotics. However, existing\ntechniques are limited to learning policies that can only perform tasks that\nare encountered during training, and require a large number of demonstrations\nto learn new tasks. Humans, on the other hand, often can learn a new task from\na single unannotated demonstration. In this work, we propose the\nInvariance-Matching One-shot Policy Learning (IMOP) algorithm. In contrast to\nthe standard practice of learning the end-effector's pose directly, IMOP first\nlearns invariant regions of the state space for a given task, and then computes\nthe end-effector's pose through matching the invariant regions between\ndemonstrations and test scenes. Trained on the 18 RLBench tasks, IMOP achieves\na success rate that outperforms the state-of-the-art consistently, by 4.5% on\naverage over the 18 tasks. More importantly, IMOP can learn a novel task from a\nsingle unannotated demonstration, and without any fine-tuning, and achieves an\naverage success rate improvement of $11.5\\%$ over the state-of-the-art on 22\nnovel tasks selected across nine categories. IMOP can also generalize to new\nshapes and learn to manipulate objects that are different from those in the\ndemonstration. Further, IMOP can perform one-shot sim-to-real transfer using a\nsingle real-robot demonstration.",
      "tldr_zh": "该论文提出了一种名为 IMOP（Invariance-Matching One-shot Policy Learning）的算法，用于机器人机械臂操作的单次模仿学习（One-Shot Imitation Learning），旨在从单个无标注演示中学习新任务，而非依赖大量训练数据。IMOP 的核心方法是先学习任务的 invariant regions（不变区域），然后通过匹配这些区域来计算末端执行器的姿势，从而实现对多样化任务的泛化。实验结果显示，在 18 个 RLBench 任务上，IMOP 的成功率比最先进方法平均高 4.5%；在 22 个新任务上，从单个演示学习后，无需微调即平均提高 11.5%，并能扩展到新形状物体和模拟到真实转移。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "RSS 2024",
      "pdf_url": "http://arxiv.org/pdf/2405.13178v2",
      "published_date": "2024-05-21 20:01:03 UTC",
      "updated_date": "2024-06-05 01:11:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:02:38.310668"
    },
    {
      "arxiv_id": "2407.12687v2",
      "title": "Towards Responsible Development of Generative AI for Education: An Evaluation-Driven Approach",
      "title_zh": "翻译失败",
      "authors": [
        "Irina Jurenka",
        "Markus Kunesch",
        "Kevin R. McKee",
        "Daniel Gillick",
        "Shaojian Zhu",
        "Sara Wiltberger",
        "Shubham Milind Phal",
        "Katherine Hermann",
        "Daniel Kasenberg",
        "Avishkar Bhoopchand",
        "Ankit Anand",
        "Miruna Pîslar",
        "Stephanie Chan",
        "Lisa Wang",
        "Jennifer She",
        "Parsa Mahmoudieh",
        "Aliya Rysbek",
        "Wei-Jen Ko",
        "Andrea Huber",
        "Brett Wiltshire",
        "Gal Elidan",
        "Roni Rabin",
        "Jasmin Rubinovitz",
        "Amit Pitaru",
        "Mac McAllister",
        "Julia Wilkowski",
        "David Choi",
        "Roee Engelberg",
        "Lidan Hackmon",
        "Adva Levin",
        "Rachel Griffin",
        "Michael Sears",
        "Filip Bar",
        "Mia Mesar",
        "Mana Jabbour",
        "Arslan Chaudhry",
        "James Cohan",
        "Sridhar Thiagarajan",
        "Nir Levine",
        "Ben Brown",
        "Dilan Gorur",
        "Svetlana Grant",
        "Rachel Hashimshoni",
        "Laura Weidinger",
        "Jieru Hu",
        "Dawn Chen",
        "Kuba Dolecki",
        "Canfer Akbulut",
        "Maxwell Bileschi",
        "Laura Culp",
        "Wen-Xin Dong",
        "Nahema Marchal",
        "Kelsie Van Deman",
        "Hema Bajaj Misra",
        "Michael Duah",
        "Moran Ambar",
        "Avi Caciularu",
        "Sandra Lefdal",
        "Chris Summerfield",
        "James An",
        "Pierre-Alexandre Kamienny",
        "Abhinit Mohdi",
        "Theofilos Strinopoulous",
        "Annie Hale",
        "Wayne Anderson",
        "Luis C. Cobo",
        "Niv Efron",
        "Muktha Ananda",
        "Shakir Mohamed",
        "Maureen Heymans",
        "Zoubin Ghahramani",
        "Yossi Matias",
        "Ben Gomes",
        "Lila Ibrahim"
      ],
      "abstract": "A major challenge facing the world is the provision of equitable and\nuniversal access to quality education. Recent advances in generative AI (gen\nAI) have created excitement about the potential of new technologies to offer a\npersonal tutor for every learner and a teaching assistant for every teacher.\nThe full extent of this dream, however, has not yet materialised. We argue that\nthis is primarily due to the difficulties with verbalising pedagogical\nintuitions into gen AI prompts and the lack of good evaluation practices,\nreinforced by the challenges in defining excellent pedagogy. Here we present\nour work collaborating with learners and educators to translate high level\nprinciples from learning science into a pragmatic set of seven diverse\neducational benchmarks, spanning quantitative, qualitative, automatic and human\nevaluations; and to develop a new set of fine-tuning datasets to improve the\npedagogical capabilities of Gemini, introducing LearnLM-Tutor. Our evaluations\nshow that LearnLM-Tutor is consistently preferred over a prompt tuned Gemini by\neducators and learners on a number of pedagogical dimensions. We hope that this\nwork can serve as a first step towards developing a comprehensive educational\nevaluation framework, and that this can enable rapid progress within the AI and\nEdTech communities towards maximising the positive impact of gen AI in\neducation.",
      "tldr_zh": "该研究探讨了生成式 AI（generative AI）在教育领域的负责任开发，强调通过评估驱动的方法应对公平教育挑战。作者与学习者和教育者合作，将学习科学原则转化为七个多样化的教育基准，包括定量、定性、自动和人工评估，并开发新的微调数据集（fine-tuning datasets）来提升 Gemini 模型的教育能力，引入 LearnLM-Tutor。评估结果显示，LearnLM-Tutor 在多个教育维度上被教育者和学习者一致优先选择。该工作旨在为建立全面的教育评估框架奠定基础，促进 AI 和 EdTech 社区加速生成式 AI 在教育中的积极影响。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.12687v2",
      "published_date": "2024-05-21 19:27:59 UTC",
      "updated_date": "2024-07-19 14:03:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:02:51.699795"
    },
    {
      "arxiv_id": "2405.13166v2",
      "title": "FairLENS: Assessing Fairness in Law Enforcement Speech Recognition",
      "title_zh": "翻译失败",
      "authors": [
        "Yicheng Wang",
        "Mark Cusick",
        "Mohamed Laila",
        "Kate Puech",
        "Zhengping Ji",
        "Xia Hu",
        "Michael Wilson",
        "Noah Spitzer-Williams",
        "Bryan Wheeler",
        "Yasser Ibrahim"
      ],
      "abstract": "Automatic speech recognition (ASR) techniques have become powerful tools,\nenhancing efficiency in law enforcement scenarios. To ensure fairness for\ndemographic groups in different acoustic environments, ASR engines must be\ntested across a variety of speakers in realistic settings. However, describing\nthe fairness discrepancies between models with confidence remains a challenge.\nMeanwhile, most public ASR datasets are insufficient to perform a satisfying\nfairness evaluation. To address the limitations, we built FairLENS - a\nsystematic fairness evaluation framework. We propose a novel and adaptable\nevaluation method to examine the fairness disparity between different models.\nWe also collected a fairness evaluation dataset covering multiple scenarios and\ndemographic dimensions. Leveraging this framework, we conducted fairness\nassessments on 1 open-source and 11 commercially available state-of-the-art ASR\nmodels. Our results reveal that certain models exhibit more biases than others,\nserving as a fairness guideline for users to make informed choices when\nselecting ASR models for a given real-world scenario. We further explored model\nbiases towards specific demographic groups and observed that shifts in the\nacoustic domain can lead to the emergence of new biases.",
      "tldr_zh": "论文提出了 FairLENS 框架，用于评估 Automatic Speech Recognition (ASR) 在执法场景中的公平性问题，旨在解决现有模型在不同人口群体和声学环境下的偏差挑战。框架包括一种新颖且可适应的评估方法，以及一个覆盖多种场景和人口维度的数据集。研究对 1 个开源和 11 个商用 ASR 模型进行了系统评估，结果显示某些模型表现出更多偏差，而声学域的变化可能导致新偏差出现。该框架为用户提供公平性指导，帮助在真实场景中选择合适的 ASR 模型。",
      "categories": [
        "eess.AS",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "eess.AS",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.13166v2",
      "published_date": "2024-05-21 19:23:40 UTC",
      "updated_date": "2024-05-28 19:10:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:03:03.115156"
    },
    {
      "arxiv_id": "2405.13162v1",
      "title": "Non-autoregressive real-time Accent Conversion model with voice cloning",
      "title_zh": "非自回归实时口音转换模型结合语音克隆",
      "authors": [
        "Vladimir Nechaev",
        "Sergey Kosyakov"
      ],
      "abstract": "Currently, the development of Foreign Accent Conversion (FAC) models utilizes\ndeep neural network architectures, as well as ensembles of neural networks for\nspeech recognition and speech generation. The use of these models is limited by\narchitectural features, which does not allow flexible changes in the timbre of\nthe generated speech and requires the accumulation of context, leading to\nincreased delays in generation and makes these systems unsuitable for use in\nreal-time multi-user communication scenarios. We have developed the\nnon-autoregressive model for real-time accent conversion with voice cloning.\nThe model generates native-sounding L1 speech with minimal latency based on\ninput L2 accented speech. The model consists of interconnected modules for\nextracting accent, gender, and speaker embeddings, converting speech,\ngenerating spectrograms, and decoding the resulting spectrogram into an audio\nsignal. The model has the ability to save, clone and change the timbre, gender\nand accent of the speaker's voice in real time. The results of the objective\nassessment show that the model improves speech quality, leading to enhanced\nrecognition performance in existing ASR systems. The results of subjective\ntests show that the proposed accent and gender encoder improves the generation\nquality. The developed model demonstrates high-quality low-latency accent\nconversion, voice cloning, and speech enhancement capabilities, making it\nsuitable for real-time multi-user communication scenarios.",
      "tldr_zh": "本文提出了一种非自回归的实时口音转换模型，支持语音克隆，旨在解决现有深度神经网络模型的延迟和灵活性问题。该模型通过互联模块提取口音、性别和说话者嵌入，进行语音转换、频谱图生成及音频解码，实现对输入L2口音语音的快速处理，并能实时保存、克隆和改变说话者的音色、性别及口音。实验结果显示，该模型显著提高了语音质量，提升了ASR系统的识别性能，并在主观测试中证明了生成质量的改善，使其适用于实时多用户通信场景。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "8 pages, 6 figures, 3 tables",
      "pdf_url": "http://arxiv.org/pdf/2405.13162v1",
      "published_date": "2024-05-21 19:07:26 UTC",
      "updated_date": "2024-05-21 19:07:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:03:15.270034"
    },
    {
      "arxiv_id": "2405.17451v1",
      "title": "Green AI in Action: Strategic Model Selection for Ensembles in Production",
      "title_zh": "翻译失败",
      "authors": [
        "Nienke Nijkamp",
        "June Sallou",
        "Niels van der Heijden",
        "Luís Cruz"
      ],
      "abstract": "Integrating Artificial Intelligence (AI) into software systems has\nsignificantly enhanced their capabilities while escalating energy demands.\nEnsemble learning, combining predictions from multiple models to form a single\nprediction, intensifies this problem due to cumulative energy consumption. This\npaper presents a novel approach to model selection that addresses the challenge\nof balancing the accuracy of AI models with their energy consumption in a live\nAI ensemble system. We explore how reducing the number of models or improving\nthe efficiency of model usage within an ensemble during inference can reduce\nenergy demands without substantially sacrificing accuracy. This study\nintroduces and evaluates two model selection strategies, Static and Dynamic,\nfor optimizing ensemble learning systems performance while minimizing energy\nusage. Our results demonstrate that the Static strategy improves the F1 score\nbeyond the baseline, reducing average energy usage from 100\\% from the full\nensemble to 6\\2%. The Dynamic strategy further enhances F1 scores, using on\naverage 76\\% compared to 100% of the full ensemble. Moreover, we propose an\napproach that balances accuracy with resource consumption, significantly\nreducing energy usage without substantially impacting accuracy. This method\ndecreased the average energy usage of the Static strategy from approximately\n62\\% to 14\\%, and for the Dynamic strategy, from around 76\\% to 57\\%. Our field\nstudy of Green AI using an operational AI system developed by a large\nprofessional services provider shows the practical applicability of adopting\nenergy-conscious model selection strategies in live production environments.",
      "tldr_zh": "这篇论文探讨了在集成学习(Ensemble learning)中平衡AI模型准确性和能量消耗的问题，提出了一种新型模型选择策略，包括Static和Dynamic方法，以优化实时AI系统中的能量使用。结果显示，Static策略提高了F1 score，同时将平均能量消耗从100%降低到62%，进一步优化后降至14%；Dynamic策略则进一步提升F1 score，使用76%的能量，并优化至57%。通过在大型专业服务提供商的实际系统中进行的实地研究，证明了这些Green AI策略在生产环境中的实用性和有效性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CY",
        "cs.SE"
      ],
      "primary_category": "cs.LG",
      "comment": "9 pages. Accepted at the 1st ACM International Conference on\n  AI-powered Software (AIware), 2024",
      "pdf_url": "http://arxiv.org/pdf/2405.17451v1",
      "published_date": "2024-05-21 18:57:43 UTC",
      "updated_date": "2024-05-21 18:57:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:03:27.843300"
    },
    {
      "arxiv_id": "2405.13152v4",
      "title": "Interpretable Interaction Modeling for Trajectory Prediction via Agent Selection and Physical Coefficient",
      "title_zh": "翻译失败",
      "authors": [
        "Shiji Huang",
        "Lei Ye",
        "Min Chen",
        "Wenhai Luo",
        "Dihong Wang",
        "Chenqi Xu",
        "Deyuan Liang"
      ],
      "abstract": "A thorough understanding of the interaction between the target agent and\nsurrounding agents is a prerequisite for accurate trajectory prediction.\nAlthough many methods have been explored, they assign correlation coefficients\nto surrounding agents in a purely learning-based manner. In this study, we\npresent ASPILin, which manually selects interacting agents and replaces the\nattention scores in Transformer with a newly computed physical correlation\ncoefficient, enhancing the interpretability of interaction modeling.\nSurprisingly, these simple modifications can significantly improve prediction\nperformance and substantially reduce computational costs. We intentionally\nsimplified our model in other aspects, such as map encoding. Remarkably,\nexperiments conducted on the INTERACTION, highD, and CitySim datasets\ndemonstrate that our method is efficient and straightforward, outperforming\nother state-of-the-art methods.",
      "tldr_zh": "该论文提出 ASPILin 方法，用于轨迹预测的交互建模，通过手动选择交互代理并用物理相关系数替换 Transformer 中的注意力分数，提高了模型的可解释性。相比传统纯学习方式，该方法显著提升了预测性能，同时降低了计算成本，并有意简化了其他方面如地图编码。实验结果显示，在 INTERACTION、highD 和 CitySim 数据集上，ASPILin 高效且简单，优于其他最先进方法。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "code:https://github.com/kkk00714/ASPILin",
      "pdf_url": "http://arxiv.org/pdf/2405.13152v4",
      "published_date": "2024-05-21 18:45:18 UTC",
      "updated_date": "2025-03-04 13:07:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:03:38.456045"
    },
    {
      "arxiv_id": "2405.13144v3",
      "title": "LLMs for Mathematical Modeling: Towards Bridging the Gap between Natural and Mathematical Languages",
      "title_zh": "翻译失败",
      "authors": [
        "Xuhan Huang",
        "Qingning Shen",
        "Yan Hu",
        "Anningzhe Gao",
        "Benyou Wang"
      ],
      "abstract": "Large Language Models (LLMs) have demonstrated strong performance across\nvarious natural language processing tasks, yet their proficiency in\nmathematical reasoning remains a key challenge. Addressing the gap between\nnatural and mathematical language requires advanced reasoning capabilities,\napproaching those of Artificial General Intelligence (AGI). However, the\nevaluation remains challenging, as perfectly representing reality is inherently\nelusive, and traditional methods like manual or direct comparison of\nmathematical statements (Ramamonjison et al., 2023) are insufficient for\nassessing true modeling ability. We propose a process-oriented framework to\nevaluate LLMs' ability to construct mathematical models, using solvers to\ncompare outputs with ground truth. Introducing Mamo, a benchmark with 1,209\nquestions covering ordinary differential equations, linear programming, and\nmixed-integer linear programming, we enable automatic evaluation of modeling\naccuracy. The results show that existing LLMs struggle with complex\nmathematical modeling tasks, with larger models demonstrating superior\nperformance, while open-source models remain competitive in simpler cases but\nstill fall short of proprietary models in more challenging problems.",
      "tldr_zh": "本研究探讨Large Language Models (LLMs) 在数学建模中的性能，旨在桥接自然语言和数学语言之间的差距，因为LLMs 在数学推理方面仍面临挑战。作者提出一个过程导向的评估框架，使用求解器来比较模型输出与真实值，并引入Mamo 基准测试，该基准包含1209 个问题，覆盖ordinary differential equations、linear programming 和mixed-integer linear programming，以实现自动评估建模准确性。实验结果显示，现有的LLMs 在复杂数学建模任务上表现不佳，较大模型表现出色，而开源模型在简单任务中具有竞争力，但在更具挑战性的问题上落后于专有模型。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "Findings of NAACL2025. Project:\n  https://github.com/FreedomIntelligence/Mamo",
      "pdf_url": "http://arxiv.org/pdf/2405.13144v3",
      "published_date": "2024-05-21 18:29:54 UTC",
      "updated_date": "2025-02-15 13:45:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:03:50.292885"
    },
    {
      "arxiv_id": "2405.13127v1",
      "title": "Towards Retrieval-Augmented Architectures for Image Captioning",
      "title_zh": "翻译失败",
      "authors": [
        "Sara Sarto",
        "Marcella Cornia",
        "Lorenzo Baraldi",
        "Alessandro Nicolosi",
        "Rita Cucchiara"
      ],
      "abstract": "The objective of image captioning models is to bridge the gap between the\nvisual and linguistic modalities by generating natural language descriptions\nthat accurately reflect the content of input images. In recent years,\nresearchers have leveraged deep learning-based models and made advances in the\nextraction of visual features and the design of multimodal connections to\ntackle this task. This work presents a novel approach towards developing image\ncaptioning models that utilize an external kNN memory to improve the generation\nprocess. Specifically, we propose two model variants that incorporate a\nknowledge retriever component that is based on visual similarities, a\ndifferentiable encoder to represent input images, and a kNN-augmented language\nmodel to predict tokens based on contextual cues and text retrieved from the\nexternal memory. We experimentally validate our approach on COCO and nocaps\ndatasets and demonstrate that incorporating an explicit external memory can\nsignificantly enhance the quality of captions, especially with a larger\nretrieval corpus. This work provides valuable insights into retrieval-augmented\ncaptioning models and opens up new avenues for improving image captioning at a\nlarger scale.",
      "tldr_zh": "本论文旨在通过检索增强架构改进图像标题生成，桥接视觉和语言模态以产生更准确的图像描述。研究提出两种模型变体，包括基于视觉相似性的知识检索器、可微分编码器用于图像表示，以及kNN增强语言模型结合外部内存中的文本上下文来预测标记。在COCO和nocaps数据集上的实验验证显示，该方法显著提升了标题质量，尤其当检索语料库规模较大时，为大规模图像标题生成开辟了新途径。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.MM"
      ],
      "primary_category": "cs.CV",
      "comment": "ACM Transactions on Multimedia Computing, Communications and\n  Applications (2024)",
      "pdf_url": "http://arxiv.org/pdf/2405.13127v1",
      "published_date": "2024-05-21 18:02:07 UTC",
      "updated_date": "2024-05-21 18:02:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:04:02.212184"
    },
    {
      "arxiv_id": "2405.12961v2",
      "title": "Aligning Transformers with Continuous Feedback via Energy Rank Alignment",
      "title_zh": "翻译失败",
      "authors": [
        "Shriram Chennakesavalu",
        "Frank Hu",
        "Sebastian Ibarraran",
        "Grant M. Rotskoff"
      ],
      "abstract": "Searching through chemical space is an exceptionally challenging problem\nbecause the number of possible molecules grows combinatorially with the number\nof atoms. Large, autoregressive models trained on databases of chemical\ncompounds have yielded powerful generators, but we still lack robust strategies\nfor generating molecules with desired properties. This molecular search problem\nclosely resembles the \"alignment\" problem for large language models, though for\nmany chemical tasks we have a specific and easily evaluable reward function.\nHere, we introduce an algorithm called energy rank alignment (ERA) that\nleverages an explicit reward function to produce a gradient-based objective\nthat we use to optimize autoregressive policies. We show theoretically that\nthis algorithm is closely related to proximal policy optimization (PPO) and\ndirect preference optimization (DPO), but has a minimizer that converges to an\nideal Gibbs-Boltzmann distribution with the reward playing the role of an\nenergy function. Furthermore, this algorithm is highly scalable, does not\nrequire reinforcement learning, and performs well relative to DPO when the\nnumber of preference observations per pairing is small. We deploy this approach\nto align molecular transformers and protein language models to generate\nmolecules and protein sequences, respectively, with externally specified\nproperties and find that it does so robustly, searching through diverse parts\nof chemical space.",
      "tldr_zh": "该研究针对化学空间搜索的挑战，提出了一种名为 energy rank alignment (ERA) 的算法，用于优化自回归策略，以生成具有特定属性的分子。该算法利用显式奖励函数创建基于梯度的目标，与 proximal policy optimization (PPO) 和 direct preference optimization (DPO) 相关，但其最小化器收敛到一个理想的 Gibbs-Boltzmann 分布，且在偏好观察样本少时表现出色，同时无需强化学习。实验结果显示，ERA 成功应用于分子 transformer 和蛋白质语言模型，能够robustly 生成符合外部指定属性的分子和蛋白序列，并在多样化的化学空间中进行有效搜索。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "physics.chem-ph",
        "q-bio.QM"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.12961v2",
      "published_date": "2024-05-21 17:35:20 UTC",
      "updated_date": "2025-05-14 20:23:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:04:14.721088"
    },
    {
      "arxiv_id": "2405.12951v1",
      "title": "Strategic Deployment of Honeypots in Blockchain-based IoT Systems",
      "title_zh": "翻译失败",
      "authors": [
        "Daniel Commey",
        "Sena Hounsinou",
        "Garth V. Crosby"
      ],
      "abstract": "This paper addresses the challenge of enhancing cybersecurity in\nBlockchain-based Internet of Things (BIoTs) systems, which are increasingly\nvulnerable to sophisticated cyberattacks. It introduces an AI-powered system\nmodel for the dynamic deployment of honeypots, utilizing an Intrusion Detection\nSystem (IDS) integrated with smart contract functionalities on IoT nodes. This\nmodel enables the transformation of regular nodes into decoys in response to\nsuspicious activities, thereby strengthening the security of BIoT networks. The\npaper analyses strategic interactions between potential attackers and the\nAI-enhanced IDS through a game-theoretic model, specifically Bayesian games.\nThe model focuses on understanding and predicting sophisticated attacks that\nmay initially appear normal, emphasizing strategic decision-making, optimized\nhoneypot deployment, and adaptive strategies in response to evolving attack\npatterns.",
      "tldr_zh": "这篇论文针对 Blockchain-based IoT (BIoTs) 系统的网络安全挑战，提出了一种 AI 驱动的动态 honeypot 部署模型，以应对复杂的网络攻击。模型将 Intrusion Detection System (IDS) 与 smart contract 功能整合到 IoT 节点上，允许普通节点在检测到可疑活动时转化为诱骗节点，从而增强 BIoT 网络的防护能力。通过 game-theoretic model，特别是 Bayesian games，该研究分析了攻击者与 AI 增强 IDS 之间的战略互动，优化了 honeypot 部署策略并实现了对演变攻击模式的适应性响应。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.NI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.12951v1",
      "published_date": "2024-05-21 17:27:00 UTC",
      "updated_date": "2024-05-21 17:27:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:04:26.921671"
    },
    {
      "arxiv_id": "2405.17449v1",
      "title": "Image Based Character Recognition, Documentation System To Decode Inscription From Temple",
      "title_zh": "翻译失败",
      "authors": [
        "Velmathi G",
        "Shangavelan M",
        "Harish D",
        "Krithikshun M S"
      ],
      "abstract": "This project undertakes the training and analysis of optical character\nrecognition OCR methods applied to 10th century ancient Tamil inscriptions\ndiscovered on the walls of the Brihadeeswarar Temple.The chosen OCR methods\ninclude Tesseract,a widely used OCR engine,using modern ICR techniques to pre\nprocess the raw data and a box editing software to finetune our model.The\nanalysis with Tesseract aims to evaluate their effectiveness in accurately\ndeciphering the nuances of the ancient Tamil characters.The performance of our\nmodel for the dataset are determined by their accuracy rate where the evaluated\ndataset divided into training set and testing set.By addressing the unique\nchallenges posed by the script's historical context,this study seeks to\ncontribute valuable insights to the broader field of OCR,facilitating improved\npreservation and interpretation of ancient inscriptions",
      "tldr_zh": "本研究开发了一个基于图像的字符识别系统，用于解码 Brihadeeswarar Temple 墙壁上的 10 世纪古塔米尔语铭文。方法包括使用 Tesseract OCR 引擎结合 ICR 技术对原始数据进行预处理，并通过箱编辑软件微调模型，以提升对古字符的准确识别。模型性能通过准确率评估，数据集分为训练集和测试集，结果显示其在处理历史脚本挑战方面表现出色。该系统为 OCR 领域提供了宝贵见解，促进古铭文的保存和解释。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "This research paper is a part of capstone project submitted to VIT\n  Chennai, VIT University",
      "pdf_url": "http://arxiv.org/pdf/2405.17449v1",
      "published_date": "2024-05-21 17:20:35 UTC",
      "updated_date": "2024-05-21 17:20:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:04:39.056836"
    },
    {
      "arxiv_id": "2405.12933v2",
      "title": "Skin-in-the-Game: Decision Making via Multi-Stakeholder Alignment in LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Bilgehan Sel",
        "Priya Shanmugasundaram",
        "Mohammad Kachuee",
        "Kun Zhou",
        "Ruoxi Jia",
        "Ming Jin"
      ],
      "abstract": "Large Language Models (LLMs) have shown remarkable capabilities in tasks such\nas summarization, arithmetic reasoning, and question answering. However, they\nencounter significant challenges in the domain of moral reasoning and ethical\ndecision-making, especially in complex scenarios with multiple stakeholders.\nThis paper introduces the Skin-in-the-Game (SKIG) framework, aimed at enhancing\nmoral reasoning in LLMs by exploring decisions' consequences from multiple\nstakeholder perspectives. Central to SKIG's mechanism is simulating\naccountability for actions, which, alongside empathy exercises and risk\nassessment, is pivotal to its effectiveness. We validate SKIG's performance\nacross various moral reasoning benchmarks with proprietary and opensource LLMs,\nand investigate its crucial components through extensive ablation analyses.",
      "tldr_zh": "本研究探讨了大型语言模型（LLMs）在道德推理和伦理决策中的挑战，特别是涉及多利益相关者的复杂场景。论文引入了Skin-in-the-Game (SKIG)框架，通过模拟决策后果、责任感、移情练习和风险评估等机制，实现多利益相关者视角的协调，以提升LLMs的道德推理能力。该框架在各种道德推理基准上进行了验证，并在专有和开源LLMs上通过消融分析确认了其关键组件的有效性，最终为更可靠的AI决策提供新途径。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "ACL 2024, long paper",
      "pdf_url": "http://arxiv.org/pdf/2405.12933v2",
      "published_date": "2024-05-21 17:04:44 UTC",
      "updated_date": "2024-06-02 18:48:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:04:48.995969"
    },
    {
      "arxiv_id": "2405.13101v2",
      "title": "Evaluating AI-generated code for C++, Fortran, Go, Java, Julia, Matlab, Python, R, and Rust",
      "title_zh": "翻译失败",
      "authors": [
        "Patrick Diehl",
        "Noujoud Nader",
        "Steve Brandt",
        "Hartmut Kaiser"
      ],
      "abstract": "This study evaluates the capabilities of ChatGPT versions 3.5 and 4 in\ngenerating code across a diverse range of programming languages. Our objective\nis to assess the effectiveness of these AI models for generating scientific\nprograms. To this end, we asked ChatGPT to generate three distinct codes: a\nsimple numerical integration, a conjugate gradient solver, and a parallel 1D\nstencil-based heat equation solver. The focus of our analysis was on the\ncompilation, runtime performance, and accuracy of the codes. While both\nversions of ChatGPT successfully created codes that compiled and ran (with some\nhelp), some languages were easier for the AI to use than others (possibly\nbecause of the size of the training sets used). Parallel codes -- even the\nsimple example we chose to study here -- also difficult for the AI to generate\ncorrectly.",
      "tldr_zh": "这篇论文评估了 ChatGPT 版本 3.5 和 4 在生成 C++、Fortran、Go、Java、Julia、Matlab、Python、R 和 Rust 等多种编程语言的科学程序代码能力。\n研究方法包括要求 AI 生成三种代码：简单的数值积分、共轭梯度求解器和并行 1D stencil-based 热方程求解器，然后分析这些代码的编译、运行性能和准确性。\n结果表明，虽然 ChatGPT 能成功生成可编译和运行的代码（需部分人工辅助），但某些语言（如训练集较大的语言）更容易处理，而生成并行代码则特别困难。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "9 pages, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2405.13101v2",
      "published_date": "2024-05-21 17:04:37 UTC",
      "updated_date": "2024-07-05 18:04:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:05:04.137922"
    },
    {
      "arxiv_id": "2405.12926v3",
      "title": "Trusting Fair Data: Leveraging Quality in Fairness-Driven Data Removal Techniques",
      "title_zh": "信任公平数据：在以公平为驱动",
      "authors": [
        "Manh Khoi Duong",
        "Stefan Conrad"
      ],
      "abstract": "In this paper, we deal with bias mitigation techniques that remove specific\ndata points from the training set to aim for a fair representation of the\npopulation in that set. Machine learning models are trained on these\npre-processed datasets, and their predictions are expected to be fair. However,\nsuch approaches may exclude relevant data, making the attained subsets less\ntrustworthy for further usage. To enhance the trustworthiness of prior methods,\nwe propose additional requirements and objectives that the subsets must fulfill\nin addition to fairness: (1) group coverage, and (2) minimal data loss. While\nremoving entire groups may improve the measured fairness, this practice is very\nproblematic as failing to represent every group cannot be considered fair. In\nour second concern, we advocate for the retention of data while minimizing\ndiscrimination. By introducing a multi-objective optimization problem that\nconsiders fairness and data loss, we propose a methodology to find\nPareto-optimal solutions that balance these objectives. By identifying such\nsolutions, users can make informed decisions about the trade-off between\nfairness and data quality and select the most suitable subset for their\napplication. Our method is distributed as a Python package via PyPI under the\nname FairDo (https://github.com/mkduong-ai/fairdo).",
      "tldr_zh": "这篇论文探讨了通过移除训练集特定数据点来缓解机器学习模型偏见的公平性方法，但强调这些方法可能导致数据子集不信任的问题。作者提出额外要求，包括确保群组覆盖（group coverage）和最小数据损失（minimal data loss），以避免完全排除任何群组并保留更多数据。论文引入多目标优化（multi-objective optimization）问题，寻找Pareto-optimal solutions来平衡公平性和数据质量，帮助用户根据应用需求选择最佳子集；同时，提供了一个名为FairDo的Python包作为实现工具。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "The Version of Record of this contribution is published in Springer\n  LNCS 14912 and is available online at\n  https://doi.org/10.1007/978-3-031-68323-7_33",
      "pdf_url": "http://arxiv.org/pdf/2405.12926v3",
      "published_date": "2024-05-21 16:51:28 UTC",
      "updated_date": "2024-09-19 11:31:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:05:15.375081"
    },
    {
      "arxiv_id": "2405.12923v1",
      "title": "Panmodal Information Interaction",
      "title_zh": "翻译失败",
      "authors": [
        "Chirag Shah",
        "Ryen W. White"
      ],
      "abstract": "The emergence of generative artificial intelligence (GenAI) is transforming\ninformation interaction. For decades, search engines such as Google and Bing\nhave been the primary means of locating relevant information for the general\npopulation. They have provided search results in the same standard format (the\nso-called \"10 blue links\"). The recent ability to chat via natural language\nwith AI-based agents and have GenAI automatically synthesize answers in\nreal-time (grounded in top-ranked results) is changing how people interact with\nand consume information at massive scale. These two information interaction\nmodalities (traditional search and AI-powered chat) coexist in current search\nengines, either loosely coupled (e.g., as separate options/tabs) or tightly\ncoupled (e.g., integrated as a chat answer embedded directly within a\ntraditional search result page). We believe that the existence of these two\ndifferent modalities, and potentially many others, is creating an opportunity\nto re-imagine the search experience, capitalize on the strengths of many\nmodalities, and develop systems and strategies to support seamless flow between\nthem. We refer to these as panmodal experiences. Unlike monomodal experiences,\nwhere only one modality is available and/or used for the task at hand, panmodal\nexperiences make multiple modalities available to users (multimodal), directly\nsupport transitions between modalities (crossmodal), and seamlessly combine\nmodalities to tailor task assistance (transmodal). While our focus is search\nand chat, with learnings from insights from a survey of over 100 individuals\nwho have recently performed common tasks on these two modalities, we also\npresent a more general vision for the future of information interaction using\nmultiple modalities and the emergent capabilities of GenAI.",
      "tldr_zh": "这篇论文探讨了生成式人工智能(GenAI)如何变革信息交互，比较了传统搜索引擎（如Google和Bing的\"10 blue links\"）与AI聊天模式，并指出两者共存的机会。该研究提出\"panmodal experiences\"概念，包括multimodal（提供多种模式）、crossmodal（支持模式间切换）和transmodal（无缝结合模式），以优化搜索体验。通过对超过100个个体的调查，分析了常见任务在不同模式下的表现，并为信息交互的未来描绘了更广泛的愿景，利用GenAI的潜力提升任务辅助效率。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.12923v1",
      "published_date": "2024-05-21 16:49:14 UTC",
      "updated_date": "2024-05-21 16:49:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:05:26.049304"
    },
    {
      "arxiv_id": "2405.12910v3",
      "title": "Topic Classification of Case Law Using a Large Language Model and a New Taxonomy for UK Law: AI Insights into Summary Judgment",
      "title_zh": "翻译失败",
      "authors": [
        "Holli Sargeant",
        "Ahmed Izzidien",
        "Felix Steffek"
      ],
      "abstract": "This paper addresses a critical gap in legal analytics by developing and\napplying a novel taxonomy for topic classification of summary judgment cases in\nthe United Kingdom. Using a curated dataset of summary judgment cases, we use\nthe Large Language Model Claude 3 Opus to explore functional topics and trends.\nWe find that Claude 3 Opus correctly classified the topic with an accuracy of\n87.13% and an F1 score of 0.87. The analysis reveals distinct patterns in the\napplication of summary judgments across various legal domains. As case law in\nthe United Kingdom is not originally labelled with keywords or a topic\nfiltering option, the findings not only refine our understanding of the\nthematic underpinnings of summary judgments but also illustrate the potential\nof combining traditional and AI-driven approaches in legal classification.\nTherefore, this paper provides a new and general taxonomy for UK law. The\nimplications of this work serve as a foundation for further research and policy\ndiscussions in the field of judicial administration and computational legal\nresearch methodologies.",
      "tldr_zh": "这篇论文开发了一个新的UK法主题分类体系（taxonomy），并使用Large Language Model Claude 3 Opus对英国summary judgment案件进行主题分类分析。研究基于一个精选的summary judgment案件数据集，模型的准确率达到87.13%，F1 score为0.87，并揭示了这些案件在不同法律领域的应用模式。该工作不仅改进了对summary judgment主题基础的理解，还展示了传统方法与AI驱动方法结合的潜力，为司法管理和计算法律研究提供重要基础。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.12910v3",
      "published_date": "2024-05-21 16:30:25 UTC",
      "updated_date": "2025-02-27 10:56:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:05:38.726104"
    },
    {
      "arxiv_id": "2405.12900v1",
      "title": "Adversarial DPO: Harnessing Harmful Data for Reducing Toxicity with Minimal Impact on Coherence and Evasiveness in Dialogue Agents",
      "title_zh": "翻译失败",
      "authors": [
        "San Kim",
        "Gary Geunbae Lee"
      ],
      "abstract": "Recent advancements in open-domain dialogue systems have been propelled by\nthe emergence of high-quality large language models (LLMs) and various\neffective training methodologies. Nevertheless, the presence of toxicity within\nthese models presents a significant challenge that can potentially diminish the\nuser experience. In this study, we introduce an innovative training algorithm,\nan improvement upon direct preference optimization (DPO), called adversarial\nDPO (ADPO). The ADPO algorithm is designed to train models to assign higher\nprobability distributions to preferred responses and lower distributions to\nunsafe responses, which are self-generated using the toxic control token. We\ndemonstrate that ADPO enhances the model's resilience against harmful\nconversations while minimizing performance degradation. Furthermore, we\nillustrate that ADPO offers a more stable training procedure compared to the\ntraditional DPO. To the best of our knowledge, this is the first adaptation of\nthe DPO algorithm that directly incorporates harmful data into the generative\nmodel, thereby reducing the need to artificially create safe dialogue data.",
      "tldr_zh": "本研究针对大型语言模型(LLMs)驱动的对话系统中毒性问题，提出了一种改进的直接偏好优化(DPO)算法，即Adversarial DPO (ADPO)。ADPO通过利用有害数据自生成不安全响应，并训练模型为首选响应分配更高概率、为不安全响应分配更低概率，从而增强模型对有害对话的抵抗力，同时最小化对连贯性和回避性的负面影响。实验结果显示，ADPO提供更稳定的训练过程，并减少了对人工安全对话数据的依赖，为构建更安全可靠的对话代理奠定了基础。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "I.2.7"
      ],
      "primary_category": "cs.CL",
      "comment": "15 pages, 7 figures, accepted to NAACL findings 2024",
      "pdf_url": "http://arxiv.org/pdf/2405.12900v1",
      "published_date": "2024-05-21 16:14:55 UTC",
      "updated_date": "2024-05-21 16:14:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:05:50.737485"
    },
    {
      "arxiv_id": "2405.13100v1",
      "title": "Better Simulations for Validating Causal Discovery with the DAG-Adaptation of the Onion Method",
      "title_zh": "翻译失败",
      "authors": [
        "Bryan Andrews",
        "Erich Kummerfeld"
      ],
      "abstract": "The number of artificial intelligence algorithms for learning causal models\nfrom data is growing rapidly. Most ``causal discovery'' or ``causal structure\nlearning'' algorithms are primarily validated through simulation studies.\nHowever, no widely accepted simulation standards exist and publications often\nreport conflicting performance statistics -- even when only considering\npublications that simulate data from linear models. In response, several\nmanuscripts have criticized a popular simulation design for validating\nalgorithms in the linear case.\n  We propose a new simulation design for generating linear models for directed\nacyclic graphs (DAGs): the DAG-adaptation of the Onion (DaO) method. DaO\nsimulations are fundamentally different from existing simulations because they\nprioritize the distribution of correlation matrices rather than the\ndistribution of linear effects. Specifically, the DaO method uniformly samples\nthe space of all correlation matrices consistent with (i.e. Markov to) a DAG.\nWe also discuss how to sample DAGs and present methods for generating DAGs with\nscale-free in-degree or out-degree. We compare the DaO method against two\nalternative simulation designs and provide implementations of the DaO method in\nPython and R: https://github.com/bja43/DaO_simulation. We advocate for others\nto adopt DaO simulations as a fair universal benchmark.",
      "tldr_zh": "该论文针对因果发现（causal discovery）算法的验证问题，提出了一种新的模拟设计：DAG-adaptation of the Onion (DaO) 方法，以解决现有模拟标准缺失和结果不一致的问题。DaO 方法通过均匀采样与 DAG（Directed Acyclic Graphs）一致的相关矩阵（correlation matrices），优先关注相关矩阵的分布而非线性效应，并支持生成具有 scale-free in-degree 或 out-degree 的 DAG。实验比较显示，DaO 比现有模拟设计更公平，并提供 Python 和 R 实现，倡导其作为通用基准。",
      "categories": [
        "stat.ME",
        "cs.AI"
      ],
      "primary_category": "stat.ME",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.13100v1",
      "published_date": "2024-05-21 16:04:25 UTC",
      "updated_date": "2024-05-21 16:04:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:06:03.577807"
    },
    {
      "arxiv_id": "2405.12884v1",
      "title": "Investigating Persuasion Techniques in Arabic: An Empirical Study Leveraging Large Language Models",
      "title_zh": "调查阿拉伯语中的说服技巧：利用大型语言模型的实证研究",
      "authors": [
        "Abdurahmman Alzahrani",
        "Eyad Babkier",
        "Faisal Yanbaawi",
        "Firas Yanbaawi",
        "Hassan Alhuzali"
      ],
      "abstract": "In the current era of digital communication and widespread use of social\nmedia, it is crucial to develop an understanding of persuasive techniques\nemployed in written text. This knowledge is essential for effectively\ndiscerning accurate information and making informed decisions. To address this\nneed, this paper presents a comprehensive empirical study focused on\nidentifying persuasive techniques in Arabic social media content. To achieve\nthis objective, we utilize Pre-trained Language Models (PLMs) and leverage the\nArAlEval dataset, which encompasses two tasks: binary classification to\ndetermine the presence or absence of persuasion techniques, and multi-label\nclassification to identify the specific types of techniques employed in the\ntext. Our study explores three different learning approaches by harnessing the\npower of PLMs: feature extraction, fine-tuning, and prompt engineering\ntechniques. Through extensive experimentation, we find that the fine-tuning\napproach yields the highest results on the aforementioned dataset, achieving an\nf1-micro score of 0.865 and an f1-weighted score of 0.861. Furthermore, our\nanalysis sheds light on an interesting finding. While the performance of the\nGPT model is relatively lower compared to the other approaches, we have\nobserved that by employing few-shot learning techniques, we can enhance its\nresults by up to 20\\%. This offers promising directions for future research and\nexploration in this topic\\footnote{Upon Acceptance, the source code will be\nreleased on GitHub.}.",
      "tldr_zh": "这篇论文通过实证研究调查了阿拉伯社交媒体内容中的说服技巧，使用 Pre-trained Language Models (PLMs) 和 ArAlEval 数据集来进行二元分类（是否存在说服技巧）和多标签分类（具体类型）。研究探索了特征提取、fine-tuning 和 prompt engineering 三种学习方法，结果显示 fine-tuning 方法表现最佳，取得了 f1-micro 分数 0.865 和 f1-weighted 分数 0.861。值得注意的是，虽然 GPT 模型的初始性能较低，但通过 few-shot learning 技术可将其结果提升高达 20%，为未来在该领域的探索提供了有前景的方向。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.12884v1",
      "published_date": "2024-05-21 15:55:09 UTC",
      "updated_date": "2024-05-21 15:55:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:06:16.546227"
    },
    {
      "arxiv_id": "2405.12881v1",
      "title": "Explaining Expert Search and Team Formation Systems with ExES",
      "title_zh": "翻译失败",
      "authors": [
        "Kiarash Golzadeh",
        "Lukasz Golab",
        "Jaroslaw Szlichta"
      ],
      "abstract": "Expert search and team formation systems operate on collaboration networks,\nwith nodes representing individuals, labeled with their skills, and edges\ndenoting collaboration relationships. Given a keyword query corresponding to\nthe desired skills, these systems identify experts that best match the query.\nHowever, state-of-the-art solutions to this problem lack transparency. To\naddress this issue, we propose ExES, a tool designed to explain expert search\nand team formation systems using factual and counterfactual methods from the\nfield of explainable artificial intelligence (XAI). ExES uses factual\nexplanations to highlight important skills and collaborations, and\ncounterfactual explanations to suggest new skills and collaborations to\nincrease the likelihood of being identified as an expert. Towards a practical\ndeployment as an interactive explanation tool, we present and experimentally\nevaluate a suite of pruning strategies to speed up the explanation search. In\nmany cases, our pruning strategies make ExES an order of magnitude faster than\nexhaustive search, while still producing concise and actionable explanations.",
      "tldr_zh": "该论文针对专家搜索和团队形成系统存在的透明度问题，提出了一种名为 ExES 的解释工具，利用 XAI 中的 factual explanations 和 counterfactual explanations 来阐明系统决策。ExES 通过突出关键技能和协作关系，提供事实解释；同时，通过建议新技能和协作，进行反事实解释，以提升个体被识别为专家的可能性。为实现实际部署，该工具引入了一系列剪枝策略，显著加速解释搜索过程。实验结果表明，这些策略使 ExES 比穷举搜索快一个数量级，同时生成简洁且可操作的解释。",
      "categories": [
        "cs.DB",
        "cs.AI"
      ],
      "primary_category": "cs.DB",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.12881v1",
      "published_date": "2024-05-21 15:53:35 UTC",
      "updated_date": "2024-05-21 15:53:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:06:26.960548"
    },
    {
      "arxiv_id": "2405.12868v1",
      "title": "Equivariant Spatio-Temporal Attentive Graph Networks to Simulate Physical Dynamics",
      "title_zh": "等变时空注意力图网络用于模拟物理动力学",
      "authors": [
        "Liming Wu",
        "Zhichao Hou",
        "Jirui Yuan",
        "Yu Rong",
        "Wenbing Huang"
      ],
      "abstract": "Learning to represent and simulate the dynamics of physical systems is a\ncrucial yet challenging task. Existing equivariant Graph Neural Network (GNN)\nbased methods have encapsulated the symmetry of physics, \\emph{e.g.},\ntranslations, rotations, etc, leading to better generalization ability.\nNevertheless, their frame-to-frame formulation of the task overlooks the\nnon-Markov property mainly incurred by unobserved dynamics in the environment.\nIn this paper, we reformulate dynamics simulation as a spatio-temporal\nprediction task, by employing the trajectory in the past period to recover the\nNon-Markovian interactions. We propose Equivariant Spatio-Temporal Attentive\nGraph Networks (ESTAG), an equivariant version of spatio-temporal GNNs, to\nfulfill our purpose. At its core, we design a novel Equivariant Discrete\nFourier Transform (EDFT) to extract periodic patterns from the history frames,\nand then construct an Equivariant Spatial Module (ESM) to accomplish spatial\nmessage passing, and an Equivariant Temporal Module (ETM) with the forward\nattention and equivariant pooling mechanisms to aggregate temporal message. We\nevaluate our model on three real datasets corresponding to the molecular-,\nprotein- and macro-level. Experimental results verify the effectiveness of\nESTAG compared to typical spatio-temporal GNNs and equivariant GNNs.",
      "tldr_zh": "本研究将物理动态模拟重新表述为时空预测任务，以解决现有 Equivariant Graph Neural Network (GNN) 方法忽略非Markov性质的问题，从而更好地捕捉环境中的未观测交互。论文提出 Equivariant Spatio-Temporal Attentive Graph Networks (ESTAG)，核心包括 Equivariant Discrete Fourier Transform (EDFT) 用于提取历史帧的周期性模式、Equivariant Spatial Module (ESM) 实现空间消息传递，以及 Equivariant Temporal Module (ETM) 通过前向注意力（forward attention）和 equivariant pooling 机制聚合时间消息。实验在分子级、蛋白级和宏观级三个真实数据集上验证了 ESTAG 的有效性，其性能优于典型时空 GNN 和 equivariant GNN 方法。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "The paper has been published to the conference of NeurIPS 2023",
      "pdf_url": "http://arxiv.org/pdf/2405.12868v1",
      "published_date": "2024-05-21 15:33:21 UTC",
      "updated_date": "2024-05-21 15:33:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:06:41.227836"
    },
    {
      "arxiv_id": "2405.12862v2",
      "title": "Toward Constraint Compliant Goal Formulation and Planning",
      "title_zh": "翻译失败",
      "authors": [
        "Steven J. Jones",
        "Robert E. Wray"
      ],
      "abstract": "One part of complying with norms, rules, and preferences is incorporating\nconstraints (such as knowledge of ethics) into one's goal formulation and\nplanning processing. We explore in a simple domain how the encoding of\nknowledge in different ethical frameworks influences an agent's goal\nformulation and planning processing and demonstrate ability of an agent to\nsatisfy and satisfice when its collection of relevant constraints includes a\nmix of \"hard\" and \"soft\" constraints of various types. How the agent attempts\nto comply with ethical constraints depends on the ethical framing and we\ninvestigate tradeoffs between deontological framing and utilitarian framing for\ncomplying with an ethical norm. Representative scenarios highlight how\nperforming the same task with different framings of the same norm leads to\ndifferent behaviors. Our explorations suggest an important role for\nmetacognitive judgments in resolving ethical conflicts during goal formulation\nand planning.",
      "tldr_zh": "该论文探讨了如何将规范、规则和偏好（如伦理知识）整合到代理的目标制定和规划过程中，以确保遵守约束。研究在一个简单领域中比较了不同伦理框架（deontological framing 和 utilitarian framing）对代理行为的影响，并展示了代理处理混合“硬”和“软”约束的能力，能够实现满足（satisfy）或近似满足（satisfice）。实验场景表明，不同框架会导致相同任务的不同行为，并强调了元认知判断（metacognitive judgments）在解决伦理冲突中的关键作用。",
      "categories": [
        "cs.AI",
        "I.2.11; I.2.8"
      ],
      "primary_category": "cs.AI",
      "comment": "16 pages + refs. 5 figures, 2 tables. Minor revisions based on\n  reviewer feedback. Accepted for presentation at Advances in Cognitive Systems\n  (Jun 2024, Palermo)",
      "pdf_url": "http://arxiv.org/pdf/2405.12862v2",
      "published_date": "2024-05-21 15:26:06 UTC",
      "updated_date": "2024-06-10 19:26:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:06:51.113882"
    },
    {
      "arxiv_id": "2405.13099v1",
      "title": "The Role of Emotions in Informational Support Question-Response Pairs in Online Health Communities: A Multimodal Deep Learning Approach",
      "title_zh": "翻译失败",
      "authors": [
        "Mohsen Jozani",
        "Jason A. Williams",
        "Ahmed Aleroud",
        "Sarbottam Bhagat"
      ],
      "abstract": "This study explores the relationship between informational support seeking\nquestions, responses, and helpfulness ratings in online health communities. We\ncreated a labeled data set of question-response pairs and developed multimodal\nmachine learning and deep learning models to reliably predict informational\nsupport questions and responses. We employed explainable AI to reveal the\nemotions embedded in informational support exchanges, demonstrating the\nimportance of emotion in providing informational support. This complex\ninterplay between emotional and informational support has not been previously\nresearched. The study refines social support theory and lays the groundwork for\nthe development of user decision aids. Further implications are discussed.",
      "tldr_zh": "这项研究探讨了在线健康社区中信息支持问题-响应对与帮助评级之间的关系，特别强调了情感的作用。研究团队创建了标记数据集，并开发了多模态机器学习和深度学习模型来可靠预测信息支持问题和响应，同时利用explainable AI揭示情感在这些交换中的关键影响。该方法揭示了情感与信息支持的复杂互动，这是先前未被研究的领域。该研究完善了社会支持理论，并为开发用户决策辅助工具奠定了基础。",
      "categories": [
        "cs.AI",
        "cs.SI",
        "H.4.3; I.2.7"
      ],
      "primary_category": "cs.AI",
      "comment": "37 pages, 15 figures",
      "pdf_url": "http://arxiv.org/pdf/2405.13099v1",
      "published_date": "2024-05-21 15:15:08 UTC",
      "updated_date": "2024-05-21 15:15:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:07:04.942252"
    },
    {
      "arxiv_id": "2405.12849v2",
      "title": "Adaptive Robotic Arm Control with a Spiking Recurrent Neural Network on a Digital Accelerator",
      "title_zh": "翻译失败",
      "authors": [
        "Alejandro Linares-Barranco",
        "Luciano Prono",
        "Robert Lengenstein",
        "Giacomo Indiveri",
        "Charlotte Frenkel"
      ],
      "abstract": "With the rise of artificial intelligence, neural network simulations of\nbiological neuron models are being explored to reduce the footprint of learning\nand inference in resource-constrained task scenarios. A mainstream type of such\nnetworks are spiking neural networks (SNNs) based on simplified Integrate and\nFire models for which several hardware accelerators have emerged. Among them,\nthe ReckOn chip was introduced as a recurrent SNN allowing for both online\ntraining and execution of tasks based on arbitrary sensory modalities,\ndemonstrated for vision, audition, and navigation. As a fully digital and\nopen-source chip, we adapted ReckOn to be implemented on a Xilinx\nMultiprocessor System on Chip system (MPSoC), facilitating its deployment in\nembedded systems and increasing the setup flexibility. We present an overview\nof the system, and a Python framework to use it on a Pynq ZU platform. We\nvalidate the architecture and implementation in the new scenario of robotic arm\ncontrol, and show how the simulated accuracy is preserved with a peak\nperformance of 3.8M events processed per second.",
      "tldr_zh": "该研究探讨了使用 spiking neural networks (SNNs) 基于简化 Integrate and Fire 模型来减少资源受限任务中的神经网络学习和推理开销。研究团队将 ReckOn 芯片——一个支持在线训练和多模态任务（如视觉、听觉和导航）的 recurrent SNN——适应到 Xilinx MPSoC 系统上，并开发了一个 Python 框架，便于在 Pynq ZU 平台上部署和灵活应用。实验在机器人臂控制的新场景中验证了该架构，成功保留了模拟准确性，并实现了每秒处理 3.8M 事件的峰值性能，为嵌入式系统中的高效神经网络应用提供了新途径。",
      "categories": [
        "cs.AR",
        "cs.AI"
      ],
      "primary_category": "cs.AR",
      "comment": "Under review at ICECS'24",
      "pdf_url": "http://arxiv.org/pdf/2405.12849v2",
      "published_date": "2024-05-21 14:59:39 UTC",
      "updated_date": "2024-06-02 18:57:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:07:17.296921"
    },
    {
      "arxiv_id": "2406.01601v3",
      "title": "Backpropagation-Free Multi-modal On-Device Model Adaptation via Cloud-Device Collaboration",
      "title_zh": "翻译失败",
      "authors": [
        "Wei Ji",
        "Li Li",
        "Zheqi Lv",
        "Wenqiao Zhang",
        "Mengze Li",
        "Zhen Wan",
        "Wenqiang Lei",
        "Roger Zimmermann"
      ],
      "abstract": "In our increasingly interconnected world, where intelligent devices\ncontinually amass copious personalized multi-modal data, a pressing need arises\nto deliver high-quality, personalized device-aware services. However, this\nendeavor presents a multifaceted challenge to prevailing artificial\nintelligence (AI) systems primarily rooted in the cloud. As these systems\ngrapple with shifting data distributions between the cloud and devices, the\ntraditional approach of fine-tuning-based adaptation (FTA) exists the following\nissues: the costly and time-consuming data annotation required by FTA and the\nlooming risk of model overfitting. To surmount these challenges, we introduce a\nUniversal On-Device Multi-modal Model Adaptation Framework, revolutionizing\non-device model adaptation by striking a balance between efficiency and\neffectiveness. The framework features the Fast Domain Adaptor (FDA) hosted in\nthe cloud, providing tailored parameters for the Lightweight Multi-modal Model\non devices. To enhance adaptability across multi-modal tasks, the AnchorFrame\nDistribution Reasoner (ADR) minimizes communication costs. Our contributions,\nencapsulated in the Cloud-Device Collaboration Multi-modal Parameter Generation\n(CDC-MMPG) framework, represent a pioneering solution for on-Device Multi-modal\nModel Adaptation (DMMA). Extensive experiments validate the efficiency and\neffectiveness of our method, particularly in video question answering and\nretrieval tasks, driving forward the integration of intelligent devices into\nour daily lives.",
      "tldr_zh": "这篇论文提出了一种 Backpropagation-Free 的多模态模型适应框架，通过 Cloud-Device Collaboration 来解决智能设备上个性化多模态数据处理的挑战，避免了传统 Fine-Tuning-Based Adaptation (FTA) 的数据标注成本高和模型过拟合问题。框架的核心组件包括 Fast Domain Adaptor (FDA) 在云端提供定制参数，以及 AnchorFrame Distribution Reasoner (ADR) 来最小化通信成本，从而实现高效的 On-Device Multi-modal Model Adaptation (DMMA)。实验结果表明，该方法在视频问答和检索任务上显著提升了效率和效果，推动了智能设备在日常应用中的集成。",
      "categories": [
        "cs.DC",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.DC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.01601v3",
      "published_date": "2024-05-21 14:42:18 UTC",
      "updated_date": "2024-11-18 23:06:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:07:30.960828"
    },
    {
      "arxiv_id": "2405.12832v2",
      "title": "Wav-KAN: Wavelet Kolmogorov-Arnold Networks",
      "title_zh": "Wav-KAN：小波 Kolmogorov-Arnold 网络",
      "authors": [
        "Zavareh Bozorgasl",
        "Hao Chen"
      ],
      "abstract": "In this paper, we introduce Wav-KAN, an innovative neural network\narchitecture that leverages the Wavelet Kolmogorov-Arnold Networks (Wav-KAN)\nframework to enhance interpretability and performance. Traditional multilayer\nperceptrons (MLPs) and even recent advancements like Spl-KAN face challenges\nrelated to interpretability, training speed, robustness, computational\nefficiency, and performance. Wav-KAN addresses these limitations by\nincorporating wavelet functions into the Kolmogorov-Arnold network structure,\nenabling the network to capture both high-frequency and low-frequency\ncomponents of the input data efficiently. Wavelet-based approximations employ\northogonal or semi-orthogonal basis and maintain a balance between accurately\nrepresenting the underlying data structure and avoiding overfitting to the\nnoise. While continuous wavelet transform (CWT) has a lot of potentials, we\nalso employed discrete wavelet transform (DWT) for multiresolution analysis,\nwhich obviated the need for recalculation of the previous steps in finding the\ndetails. Analogous to how water conforms to the shape of its container, Wav-KAN\nadapts to the data structure, resulting in enhanced accuracy, faster training\nspeeds, and increased robustness compared to Spl-KAN and MLPs. Our results\nhighlight the potential of Wav-KAN as a powerful tool for developing\ninterpretable and high-performance neural networks, with applications spanning\nvarious fields. This work sets the stage for further exploration and\nimplementation of Wav-KAN in frameworks such as PyTorch and TensorFlow, aiming\nto make wavelets in KAN as widespread as activation functions like ReLU and\nsigmoid in universal approximation theory (UAT). The codes to replicate the\nsimulations are available at https://github.com/zavareh1/Wav-KAN.",
      "tldr_zh": "本文提出 Wav-KAN，一种基于 Wavelet Kolmogorov-Arnold Networks 的创新神经网络架构，旨在提升模型的可解释性、训练速度、鲁棒性和计算效率。Wav-KAN 通过整合小波函数（如利用 DWT 进行多分辨率分析）捕获输入数据的 高频和低频成分，同时平衡数据表示与避免过拟合。相比传统 MLPs 和 Spl-KAN，实验结果显示 Wav-KAN 实现了更高的准确率、更快训练速度和更强鲁棒性，并为各种领域提供可解释的高性能工具，代码已在 GitHub 上开源。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "eess.SP",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "Work in progress; codes are available at are available at\n  https://github.com/zavareh1/Wav-KAN",
      "pdf_url": "http://arxiv.org/pdf/2405.12832v2",
      "published_date": "2024-05-21 14:36:16 UTC",
      "updated_date": "2024-05-27 15:12:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:07:41.535836"
    },
    {
      "arxiv_id": "2405.12819v1",
      "title": "Large Language Models Meet NLP: A Survey",
      "title_zh": "翻译失败",
      "authors": [
        "Libo Qin",
        "Qiguang Chen",
        "Xiachong Feng",
        "Yang Wu",
        "Yongheng Zhang",
        "Yinghui Li",
        "Min Li",
        "Wanxiang Che",
        "Philip S. Yu"
      ],
      "abstract": "While large language models (LLMs) like ChatGPT have shown impressive\ncapabilities in Natural Language Processing (NLP) tasks, a systematic\ninvestigation of their potential in this field remains largely unexplored. This\nstudy aims to address this gap by exploring the following questions: (1) How\nare LLMs currently applied to NLP tasks in the literature? (2) Have traditional\nNLP tasks already been solved with LLMs? (3) What is the future of the LLMs for\nNLP? To answer these questions, we take the first step to provide a\ncomprehensive overview of LLMs in NLP. Specifically, we first introduce a\nunified taxonomy including (1) parameter-frozen application and (2)\nparameter-tuning application to offer a unified perspective for understanding\nthe current progress of LLMs in NLP. Furthermore, we summarize the new\nfrontiers and the associated challenges, aiming to inspire further\ngroundbreaking advancements. We hope this work offers valuable insights into\nthe {potential and limitations} of LLMs in NLP, while also serving as a\npractical guide for building effective LLMs in NLP.",
      "tldr_zh": "这篇调查论文探讨了大型语言模型 (LLMs) 在自然语言处理 (NLP) 领域的应用，通过分析文献回答了 LLMs 的当前使用、是否已解决传统 NLP 任务以及未来方向等问题。论文引入了一个统一的分类法，包括参数冻结应用 (parameter-frozen application) 和参数调整应用 (parameter-tuning application)，以系统概述 LLMs 在 NLP 的进展和挑战。最终，它总结了新前沿如潜力与限制，并为构建有效的 LLMs 提供实用指南。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.12819v1",
      "published_date": "2024-05-21 14:24:01 UTC",
      "updated_date": "2024-05-21 14:24:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:07:52.251893"
    },
    {
      "arxiv_id": "2405.17221v1",
      "title": "Efficient Orchestrated AI Workflows Execution on Scale-out Spatial Architecture",
      "title_zh": "高效编排 AI 工作流在可扩展空间架构上的执行",
      "authors": [
        "Jinyi Deng",
        "Xinru Tang",
        "Zhiheng Yue",
        "Guangyang Lu",
        "Qize Yang",
        "Jiahao Zhang",
        "Jinxi Li",
        "Chao Li",
        "Shaojun Wei",
        "Yang Hu",
        "Shouyi Yin"
      ],
      "abstract": "Given the increasing complexity of AI applications, traditional spatial\narchitectures frequently fall short. Our analysis identifies a pattern of\ninterconnected, multi-faceted tasks encompassing both AI and general\ncomputational processes. In response, we have conceptualized \"Orchestrated AI\nWorkflows,\" an approach that integrates various tasks with logic-driven\ndecisions into dynamic, sophisticated workflows. Specifically, we find that the\nintrinsic Dual Dynamicity of Orchestrated AI Workflows, namely dynamic\nexecution times and frequencies of Task Blocks, can be effectively represented\nusing the Orchestrated Workflow Graph. Furthermore, the intrinsic Dual\nDynamicity poses challenges to existing spatial architecture, namely\nIndiscriminate Resource Allocation, Reactive Load Rebalancing, and Contagious\nPEA Idleness.\n  To overcome these challenges, we present Octopus, a scale-out spatial\narchitecture and a suite of advanced scheduling strategies optimized for\nexecuting Orchestrated AI Workflows, such as the Discriminate Dual-Scheduling\nMechanism, Adaptive TBU Scheduling Strategy, and Proactive Cluster Scheduling\nStrategy. Our evaluations demonstrate that Octopus significantly outperforms\ntraditional architectures in handling the dynamic demands of Orchestrated AI\nWorkflows, and possesses robust scalability in large scale hardware such as\nwafer-scale chip.",
      "tldr_zh": "该论文分析了传统空间架构在处理复杂 AI 应用时的局限性，提出“Orchestrated AI Workflows”概念，将 AI 和计算任务整合成动态工作流，并使用 Orchestrated Workflow Graph 表示其内在 Dual Dynamicity（如动态执行时间和频率）。为了解决 Indiscriminate Resource Allocation、Reactive Load Rebalancing 和 Contagious PEA Idleness 等挑战，作者引入 Octopus，一个可扩展的空间架构及其优化调度策略，包括 Discriminate Dual-Scheduling Mechanism、Adaptive TBU Scheduling Strategy 和 Proactive Cluster Scheduling Strategy。实验结果表明，Octopus 在执行动态工作流方面显著优于传统架构，并在大规模硬件如晶圆级芯片上展示出强大的可扩展性。",
      "categories": [
        "cs.AI",
        "cs.AR"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.17221v1",
      "published_date": "2024-05-21 14:09:31 UTC",
      "updated_date": "2024-05-21 14:09:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:08:05.297968"
    },
    {
      "arxiv_id": "2405.12807v11",
      "title": "FAdam: Adam is a natural gradient optimizer using diagonal empirical Fisher information",
      "title_zh": "翻译失败",
      "authors": [
        "Dongseong Hwang"
      ],
      "abstract": "This paper establishes a mathematical foundation for the Adam optimizer,\nelucidating its connection to natural gradient descent through Riemannian and\ninformation geometry. We provide an accessible and detailed analysis of the\ndiagonal empirical Fisher information matrix (FIM) in Adam, clarifying all\ndetailed approximations and advocating for the use of log probability functions\nas loss, which should be based on discrete distributions, due to the\nlimitations of empirical FIM. Our analysis uncovers flaws in the original Adam\nalgorithm, leading to proposed corrections such as enhanced momentum\ncalculations, adjusted bias corrections, adaptive epsilon, and gradient\nclipping. We refine the weight decay term based on our theoretical framework.\nOur modified algorithm, Fisher Adam (FAdam), demonstrates superior performance\nacross diverse domains including LLM, ASR, and VQ-VAE, achieving\nstate-of-the-art results in ASR.",
      "tldr_zh": "这篇论文通过黎曼和信息几何建立了 Adam 优化器的数学基础，将其与自然梯度下降联系起来，并详细分析了 Adam 中的对角经验 Fisher information matrix (FIM)，强调使用基于离散分布的 log 概率函数作为损失以克服其局限性。作者指出了 Adam 算法的缺陷，如在动量计算和偏差修正方面的不足，并提出改进措施，包括 enhanced momentum calculations、adjusted bias corrections、自适应 epsilon 和梯度 clipping，同时优化了权重衰减项。改进后的算法 FAdam 在 LLM、ASR 和 VQ-VAE 等领域表现出色，在 ASR 中达到了 state-of-the-art 结果。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.IT",
        "math.IT"
      ],
      "primary_category": "cs.LG",
      "comment": "21 pages, 4 figures, 6 tables",
      "pdf_url": "http://arxiv.org/pdf/2405.12807v11",
      "published_date": "2024-05-21 13:58:17 UTC",
      "updated_date": "2024-09-03 21:00:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:08:19.099436"
    },
    {
      "arxiv_id": "2405.13095v1",
      "title": "Presentations are not always linear! GNN meets LLM for Document-to-Presentation Transformation with Attribution",
      "title_zh": "翻译失败",
      "authors": [
        "Himanshu Maheshwari",
        "Sambaran Bandyopadhyay",
        "Aparna Garimella",
        "Anandhavelu Natarajan"
      ],
      "abstract": "Automatically generating a presentation from the text of a long document is a\nchallenging and useful problem. In contrast to a flat summary, a presentation\nneeds to have a better and non-linear narrative, i.e., the content of a slide\ncan come from different and non-contiguous parts of the given document.\nHowever, it is difficult to incorporate such non-linear mapping of content to\nslides and ensure that the content is faithful to the document. LLMs are prone\nto hallucination and their performance degrades with the length of the input\ndocument. Towards this, we propose a novel graph based solution where we learn\na graph from the input document and use a combination of graph neural network\nand LLM to generate a presentation with attribution of content for each slide.\nWe conduct thorough experiments to show the merit of our approach compared to\ndirectly using LLMs for this task.",
      "tldr_zh": "该研究针对从长文档自动生成演示文稿的问题，提出了一种创新方法，以解决演示文稿的非线性叙事需求，即幻灯片内容可能来自文档的不同非连续部分。方法结合图神经网络(GNN)和大型语言模型(LLM)，通过从输入文档中学习图结构，并使用GNN与LLM协作生成带有内容归因的演示文稿，从而确保内容忠实于原文档。实验结果表明，该方法在性能上优于直接使用LLM的基线方案，为文档到演示文稿的自动转换提供了更可靠的解决方案。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "This paper is under review in a conference",
      "pdf_url": "http://arxiv.org/pdf/2405.13095v1",
      "published_date": "2024-05-21 13:52:33 UTC",
      "updated_date": "2024-05-21 13:52:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:08:29.036698"
    },
    {
      "arxiv_id": "2405.12785v1",
      "title": "Artificial Intelligence Approaches for Predictive Maintenance in the Steel Industry: A Survey",
      "title_zh": "翻译失败",
      "authors": [
        "Jakub Jakubowski",
        "Natalia Wojak-Strzelecka",
        "Rita P. Ribeiro",
        "Sepideh Pashami",
        "Szymon Bobek",
        "Joao Gama",
        "Grzegorz J Nalepa"
      ],
      "abstract": "Predictive Maintenance (PdM) emerged as one of the pillars of Industry 4.0,\nand became crucial for enhancing operational efficiency, allowing to minimize\ndowntime, extend lifespan of equipment, and prevent failures. A wide range of\nPdM tasks can be performed using Artificial Intelligence (AI) methods, which\noften use data generated from industrial sensors. The steel industry, which is\nan important branch of the global economy, is one of the potential\nbeneficiaries of this trend, given its large environmental footprint, the\nglobalized nature of the market, and the demanding working conditions. This\nsurvey synthesizes the current state of knowledge in the field of AI-based PdM\nwithin the steel industry and is addressed to researchers and practitioners. We\nidentified 219 articles related to this topic and formulated five research\nquestions, allowing us to gain a global perspective on current trends and the\nmain research gaps. We examined equipment and facilities subjected to PdM,\ndetermined common PdM approaches, and identified trends in the AI methods used\nto develop these solutions. We explored the characteristics of the data used in\nthe surveyed articles and assessed the practical implications of the research\npresented there. Most of the research focuses on the blast furnace or hot\nrolling, using data from industrial sensors. Current trends show increasing\ninterest in the domain, especially in the use of deep learning. The main\nchallenges include implementing the proposed methods in a production\nenvironment, incorporating them into maintenance plans, and enhancing the\naccessibility and reproducibility of the research.",
      "tldr_zh": "这篇调查论文总结了人工智能（AI）在钢铁行业预测性维护（PdM）中的应用现状，旨在为研究者和从业者提供全球视角。作者分析了219篇相关文章，探讨了设备类型（如高炉和热轧）、常用PdM方法、AI技术趋势（尤其是深度学习的使用）、数据特征（如工业传感器数据）以及实际影响。研究发现，虽然AI方法能提升效率并减少停机时间，但主要挑战包括将方案应用于生产环境、融入维护计划以及提升研究的可访问性和可重复性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Preprint submitted to Engineering Applications of Artificial\n  Intelligence",
      "pdf_url": "http://arxiv.org/pdf/2405.12785v1",
      "published_date": "2024-05-21 13:32:46 UTC",
      "updated_date": "2024-05-21 13:32:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:08:42.019883"
    },
    {
      "arxiv_id": "2405.12779v1",
      "title": "Transformer in Touch: A Survey",
      "title_zh": "翻译失败",
      "authors": [
        "Jing Gao",
        "Ning Cheng",
        "Bin Fang",
        "Wenjuan Han"
      ],
      "abstract": "The Transformer model, initially achieving significant success in the field\nof natural language processing, has recently shown great potential in the\napplication of tactile perception. This review aims to comprehensively outline\nthe application and development of Transformers in tactile technology. We first\nintroduce the two fundamental concepts behind the success of the Transformer:\nthe self-attention mechanism and large-scale pre-training. Then, we delve into\nthe application of Transformers in various tactile tasks, including but not\nlimited to object recognition, cross-modal generation, and object manipulation,\noffering a concise summary of the core methodologies, performance benchmarks,\nand design highlights. Finally, we suggest potential areas for further research\nand future work, aiming to generate more interest within the community, tackle\nexisting challenges, and encourage the use of Transformer models in the tactile\nfield.",
      "tldr_zh": "这篇调查综述了Transformer模型在触觉感知领域的应用和发展，强调了self-attention机制和大规模预训练作为其成功核心。论文详细探讨了Transformer在物体识别、跨模态生成和物体操作等触觉任务中的应用，总结了关键方法、性能基准和设计亮点。最终，它提出了未来研究方向，以解决现有挑战并鼓励Transformer在触觉领域的更广泛使用。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "27 pages, 2 tables, 5 figures, accepted by ICIC 2024",
      "pdf_url": "http://arxiv.org/pdf/2405.12779v1",
      "published_date": "2024-05-21 13:26:27 UTC",
      "updated_date": "2024-05-21 13:26:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:08:52.664572"
    },
    {
      "arxiv_id": "2405.12775v1",
      "title": "Unsupervised Multimodal Clustering for Semantics Discovery in Multimodal Utterances",
      "title_zh": "翻译失败",
      "authors": [
        "Hanlei Zhang",
        "Hua Xu",
        "Fei Long",
        "Xin Wang",
        "Kai Gao"
      ],
      "abstract": "Discovering the semantics of multimodal utterances is essential for\nunderstanding human language and enhancing human-machine interactions. Existing\nmethods manifest limitations in leveraging nonverbal information for discerning\ncomplex semantics in unsupervised scenarios. This paper introduces a novel\nunsupervised multimodal clustering method (UMC), making a pioneering\ncontribution to this field. UMC introduces a unique approach to constructing\naugmentation views for multimodal data, which are then used to perform\npre-training to establish well-initialized representations for subsequent\nclustering. An innovative strategy is proposed to dynamically select\nhigh-quality samples as guidance for representation learning, gauged by the\ndensity of each sample's nearest neighbors. Besides, it is equipped to\nautomatically determine the optimal value for the top-$K$ parameter in each\ncluster to refine sample selection. Finally, both high- and low-quality samples\nare used to learn representations conducive to effective clustering. We build\nbaselines on benchmark multimodal intent and dialogue act datasets. UMC shows\nremarkable improvements of 2-6\\% scores in clustering metrics over\nstate-of-the-art methods, marking the first successful endeavor in this domain.\nThe complete code and data are available at https://github.com/thuiar/UMC.",
      "tldr_zh": "这篇论文提出了一种无监督多模态聚类方法（UMC），旨在发现多模态话语中的语义，并解决现有方法在无监督场景下利用非语言信息识别复杂语义的局限性。UMC 通过构建增强视图（augmentation views）进行预训练，并动态选择基于最近邻居密度的高质量样本，同时自动优化每个聚类中的 top-K 参数，以指导表示学习并利用高低质量样本提升聚类效果。在基准多模态意图和对话行为数据集上，UMC 比最先进方法提高了 2-6% 的聚类指标，标志着该领域的首次成功尝试。",
      "categories": [
        "cs.MM",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.MM",
      "comment": "Accepted by ACL 2024, Main Conference, Long Paper",
      "pdf_url": "http://arxiv.org/pdf/2405.12775v1",
      "published_date": "2024-05-21 13:24:07 UTC",
      "updated_date": "2024-05-21 13:24:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:09:07.115144"
    },
    {
      "arxiv_id": "2405.12774v1",
      "title": "Blind Separation of Vibration Sources using Deep Learning and Deconvolution",
      "title_zh": "翻译失败",
      "authors": [
        "Igor Makienko",
        "Michael Grebshtein",
        "Eli Gildish"
      ],
      "abstract": "Vibrations of rotating machinery primarily originate from two sources, both\nof which are distorted by the machine's transfer function on their way to the\nsensor: the dominant gear-related vibrations and a low-energy signal linked to\nbearing faults. The proposed method facilitates the blind separation of\nvibration sources, eliminating the need for any information about the monitored\nequipment or external measurements. This method estimates both sources in two\nstages: initially, the gear signal is isolated using a dilated CNN, followed by\nthe estimation of the bearing fault signal using the squared log envelope of\nthe residual. The effect of the transfer function is removed from both sources\nusing a novel whitening-based deconvolution method (WBD). Both simulation and\nexperimental results demonstrate the method's ability to detect bearing\nfailures early when no additional information is available. This study\nconsiders both local and distributed bearing faults, assuming that the\nvibrations are recorded under stable operating conditions.",
      "tldr_zh": "这篇论文提出了一种盲分离振动源的方法，使用深度学习和去卷积技术，针对旋转机械中被传递函数扭曲的齿轮振动和轴承故障信号进行分离，无需设备信息或外部测量。方法分为两阶段：首先利用 dilated CNN 隔离主导的齿轮信号，然后通过残差的平方对数包络估计低能轴承故障信号，并采用 whitening-based deconvolution (WBD) 去除传递函数的影响。实验和模拟结果显示，该方法在稳定操作条件下能早期检测局部和分布式轴承故障，提高了故障诊断的准确性和可靠性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "eess.AS",
        "eess.SP"
      ],
      "primary_category": "cs.LG",
      "comment": "20 pages, 13 figures",
      "pdf_url": "http://arxiv.org/pdf/2405.12774v1",
      "published_date": "2024-05-21 13:24:05 UTC",
      "updated_date": "2024-05-21 13:24:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:09:17.812961"
    },
    {
      "arxiv_id": "2405.13094v1",
      "title": "KPG: Key Propagation Graph Generator for Rumor Detection based on Reinforcement Learning",
      "title_zh": "KPG：基于强化学习的谣言检测关键传播图生成器",
      "authors": [
        "Yusong Zhang",
        "Kun Xie",
        "Xingyi Zhang",
        "Xiangyu Dong",
        "Sibo Wang"
      ],
      "abstract": "The proliferation of rumors on social media platforms during significant\nevents, such as the US elections and the COVID-19 pandemic, has a profound\nimpact on social stability and public health. Existing approaches for rumor\ndetection primarily rely on propagation graphs to enhance model effectiveness.\nHowever, the presence of noisy and irrelevant structures during the propagation\nprocess limits the efficacy of these approaches. To tackle this issue,\ntechniques such as weight adjustment and data augmentation have been proposed.\nHowever, these techniques heavily depend on rich original propagation\nstructures, thus hindering performance when dealing with rumors that lack\nsufficient propagation information in the early propagation stages. In this\npaper, we propose Key Propagation Graph Generator (KPG), a novel reinforcement\nlearning-based rumor detection framework that generates contextually coherent\nand informative propagation patterns for events with insufficient topology\ninformation, while also identifies indicative substructures for events with\nredundant and noisy propagation structures. KPG consists of two key components:\nthe Candidate Response Generator (CRG) and the Ending Node Selector (ENS). CRG\nlearns the latent distribution from refined propagation patterns, filtering out\nnoise and generating new candidates for ENS. Simultaneously, ENS identifies the\nmost influential substructures within propagation graphs and generates training\ndata for CRG. Moreover, we introduce an end-to-end framework that utilizes\nrewards to guide the entire training process via a pre-trained graph neural\nnetwork. Extensive experiments conducted on four datasets demonstrate the\nsuperiority of our KPG compared to the state-of-the-art approaches.",
      "tldr_zh": "这篇论文针对社交媒体谣言检测中的挑战，提出了一种基于 Reinforcement Learning 的 Key Propagation Graph Generator (KPG) 框架，以处理传播图中的噪声和信息不足问题。KPG 包括两个核心组件：Candidate Response Generator (CRG) 用于从精炼的传播模式中学习潜在分布、过滤噪声并生成新候选，以及 Ending Node Selector (ENS) 用于识别传播图中的关键子结构并为 CRG 提供训练数据。该框架通过端到端的奖励机制和预训练的 Graph Neural Network 引导训练，在四个数据集上的实验显示，KPG 比现有最先进方法表现出色，提升了谣言检测的准确性和鲁棒性。",
      "categories": [
        "cs.SI",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.SI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.13094v1",
      "published_date": "2024-05-21 13:13:43 UTC",
      "updated_date": "2024-05-21 13:13:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:09:30.842115"
    },
    {
      "arxiv_id": "2405.12755v2",
      "title": "Progress Measures for Grokking on Real-world Tasks",
      "title_zh": "Grokking 在真实世界任务上的进展度量",
      "authors": [
        "Satvik Golechha"
      ],
      "abstract": "Grokking, a phenomenon where machine learning models generalize long after\noverfitting, has been primarily observed and studied in algorithmic tasks. This\npaper explores grokking in real-world datasets using deep neural networks for\nclassification under the cross-entropy loss. We challenge the prevalent\nhypothesis that the $L_2$ norm of weights is the primary cause of grokking by\ndemonstrating that grokking can occur outside the expected range of weight\nnorms. To better understand grokking, we introduce three new progress measures:\nactivation sparsity, absolute weight entropy, and approximate local circuit\ncomplexity. These measures are conceptually related to generalization and\ndemonstrate a stronger correlation with grokking in real-world datasets\ncompared to weight norms. Our findings suggest that while weight norms might\nusually correlate with grokking and our progress measures, they are not\ncausative, and our proposed measures provide a better understanding of the\ndynamics of grokking.",
      "tldr_zh": "这篇论文探讨了Grokking现象——机器学习模型在过拟合后很久才实现泛化——在真实世界数据集上的表现，使用深度神经网络和交叉熵损失进行分类。作者挑战了权重L2 norm作为Grokking主要原因的假设，证明了Grokking可能发生在权重范数预期范围之外，并引入了三个新进展指标：activation sparsity、absolute weight entropy和approximate local circuit complexity。实验结果显示，这些指标与Grokking在真实数据集中的相关性更强，提供了对Grokking动态的更深入理解，而非权重范数是因果因素。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "5 pages",
      "pdf_url": "http://arxiv.org/pdf/2405.12755v2",
      "published_date": "2024-05-21 13:06:41 UTC",
      "updated_date": "2024-06-20 07:39:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:09:41.974817"
    },
    {
      "arxiv_id": "2405.12754v3",
      "title": "Global-local Fourier Neural Operator for Accelerating Coronal Magnetic Field Model",
      "title_zh": "翻译失败",
      "authors": [
        "Yutao Du",
        "Qin Li",
        "Raghav Gnanasambandam",
        "Mengnan Du",
        "Haimin Wang",
        "Bo Shen"
      ],
      "abstract": "Exploring the outer atmosphere of the sun has remained a significant\nbottleneck in astrophysics, given the intricate magnetic formations that\nsignificantly influence diverse solar events. Magnetohydrodynamics (MHD)\nsimulations allow us to model the complex interactions between the sun's\nplasma, magnetic fields, and the surrounding environment. However, MHD\nsimulation is extremely time-consuming, taking days or weeks for simulation.\nThe goal of this study is to accelerate coronal magnetic field simulation using\ndeep learning, specifically, the Fourier Neural Operator (FNO). FNO has been\nproven to be an ideal tool for scientific computing and discovery in the\nliterature. In this paper, we proposed a global-local Fourier Neural Operator\n(GL-FNO) that contains two branches of FNOs: the global FNO branch takes\ndownsampled input to reconstruct global features while the local FNO branch\ntakes original resolution input to capture fine details. The performance of the\nGLFNO is compared with state-of-the-art deep learning methods, including FNO,\nU-NO, U-FNO, Vision Transformer, CNN-RNN, and CNN-LSTM, to demonstrate its\naccuracy, computational efficiency, and scalability. Furthermore, physics\nanalysis from domain experts is also performed to demonstrate the reliability\nof GL-FNO. The results demonstrate that GL-FNO not only accelerates the MHD\nsimulation (a few seconds for prediction, more than \\times 20,000 speed up) but\nalso provides reliable prediction capabilities, thus greatly contributing to\nthe understanding of space weather dynamics. Our code implementation is\navailable at https://github.com/Yutao-0718/GL-FNO",
      "tldr_zh": "本文提出 Global-local Fourier Neural Operator (GL-FNO) 方法，以加速 Magnetohydrodynamics (MHD) 模拟在日冕磁场建模中的应用，针对传统模拟耗时数日或数周的问题。GL-FNO 包含两个分支：全局 FNO 分支处理降采样输入以重建整体特征，以及局部 FNO 分支处理原始分辨率输入以捕捉精细细节，与 FNO、U-NO 等基准模型相比，它在准确性、计算效率和可扩展性上表现出色。实验结果显示，GL-FNO 将模拟时间缩短至几秒钟，实现超过 20,000 倍的加速，并经物理分析验证其可靠预测能力，从而有助于深化空间天气动态的研究。",
      "categories": [
        "astro-ph.SR",
        "cs.AI",
        "cs.LG",
        "physics.space-ph"
      ],
      "primary_category": "astro-ph.SR",
      "comment": "10 pages",
      "pdf_url": "http://arxiv.org/pdf/2405.12754v3",
      "published_date": "2024-05-21 13:04:53 UTC",
      "updated_date": "2024-09-08 15:28:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:09:55.424239"
    },
    {
      "arxiv_id": "2405.12750v2",
      "title": "Generative AI in Cybersecurity: A Comprehensive Review of LLM Applications and Vulnerabilities",
      "title_zh": "翻译失败",
      "authors": [
        "Mohamed Amine Ferrag",
        "Fatima Alwahedi",
        "Ammar Battah",
        "Bilel Cherif",
        "Abdechakour Mechri",
        "Norbert Tihanyi",
        "Tamas Bisztray",
        "Merouane Debbah"
      ],
      "abstract": "This paper provides a comprehensive review of the future of cybersecurity\nthrough Generative AI and Large Language Models (LLMs). We explore LLM\napplications across various domains, including hardware design security,\nintrusion detection, software engineering, design verification, cyber threat\nintelligence, malware detection, and phishing detection. We present an overview\nof LLM evolution and its current state, focusing on advancements in models such\nas GPT-4, GPT-3.5, Mixtral-8x7B, BERT, Falcon2, and LLaMA. Our analysis extends\nto LLM vulnerabilities, such as prompt injection, insecure output handling,\ndata poisoning, DDoS attacks, and adversarial instructions. We delve into\nmitigation strategies to protect these models, providing a comprehensive look\nat potential attack scenarios and prevention techniques. Furthermore, we\nevaluate the performance of 42 LLM models in cybersecurity knowledge and\nhardware security, highlighting their strengths and weaknesses. We thoroughly\nevaluate cybersecurity datasets for LLM training and testing, covering the\nlifecycle from data creation to usage and identifying gaps for future research.\nIn addition, we review new strategies for leveraging LLMs, including techniques\nlike Half-Quadratic Quantization (HQQ), Reinforcement Learning with Human\nFeedback (RLHF), Direct Preference Optimization (DPO), Quantized Low-Rank\nAdapters (QLoRA), and Retrieval-Augmented Generation (RAG). These insights aim\nto enhance real-time cybersecurity defenses and improve the sophistication of\nLLM applications in threat detection and response. Our paper provides a\nfoundational understanding and strategic direction for integrating LLMs into\nfuture cybersecurity frameworks, emphasizing innovation and robust model\ndeployment to safeguard against evolving cyber threats.",
      "tldr_zh": "这篇论文对生成式 AI 和大型语言模型 (LLMs) 在网络安全领域的应用与漏洞进行了全面综述，涵盖了 LLMs 在硬件设计安全、入侵检测、软件工程和恶意软件检测等领域的实际应用。论文分析了 LLMs 的演变（如 GPT-4、GPT-3.5 和 LLaMA 等模型的进展）以及潜在风险，包括提示注入、数据中毒和 DDoS 攻击，并提出了缓解策略如 Reinforcement Learning with Human Feedback (RLHF) 和 Retrieval-Augmented Generation (RAG)。此外，研究评估了 42 个 LLM 模型在网络安全知识和硬件安全中的性能，并审阅了相关数据集及其生命周期，识别了未来研究 gaps。总体上，该综述为整合 LLMs 到网络安全框架中提供了战略方向，提升了实时防御和威胁响应能力。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "52 pages, 8 figures",
      "pdf_url": "http://arxiv.org/pdf/2405.12750v2",
      "published_date": "2024-05-21 13:02:27 UTC",
      "updated_date": "2025-01-17 11:10:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:10:06.695945"
    },
    {
      "arxiv_id": "2405.13093v2",
      "title": "Graph neural networks informed locally by thermodynamics",
      "title_zh": "热力学局部指导的图神经网络",
      "authors": [
        "Alicia Tierz",
        "Iciar Alfaro",
        "David González",
        "Francisco Chinesta",
        "Elías Cueto"
      ],
      "abstract": "Thermodynamics-informed neural networks employ inductive biases for the\nenforcement of the first and second principles of thermodynamics. To construct\nthese biases, a metriplectic evolution of the system is assumed. This provides\nexcellent results, when compared to uninformed, black box networks. While the\ndegree of accuracy can be increased in one or two orders of magnitude, in the\ncase of graph networks, this requires assembling global Poisson and dissipation\nmatrices, which breaks the local structure of such networks. In order to avoid\nthis drawback, a local version of the metriplectic biases has been developed in\nthis work, which avoids the aforementioned matrix assembly, thus preserving the\nnode-by-node structure of the graph networks. We apply this framework for\nexamples in the fields of solid and fluid mechanics. Our approach demonstrates\nsignificant computational efficiency and strong generalization capabilities,\naccurately making inferences on examples significantly different from those\nencountered during training.",
      "tldr_zh": "这篇论文提出了一种局部thermodynamics-informed偏差，用于Graph neural networks，以强制执行热力学第一和第二定律，同时假设系统的metriplectic演化。不同于传统方法，该框架避免组装全局Poisson和dissipation矩阵，保留了图网络的节点级局部结构，从而提高了计算效率。实验结果显示，该方法在固体和流体力学领域的应用中，展现出强大的泛化能力，能够准确处理与训练数据显著不同的示例。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.13093v2",
      "published_date": "2024-05-21 12:57:10 UTC",
      "updated_date": "2025-01-20 11:03:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:10:19.058712"
    },
    {
      "arxiv_id": "2405.15812v2",
      "title": "Pseudo Channel: Time Embedding for Motor Imagery Decoding",
      "title_zh": "翻译失败",
      "authors": [
        "Zhengqing Miao",
        "Meirong Zhao"
      ],
      "abstract": "Motor imagery (MI) based EEG represents a frontier in enabling direct neural\ncontrol of external devices and advancing neural rehabilitation. This study\nintroduces a novel time embedding technique, termed traveling-wave based time\nembedding, utilized as a pseudo channel to enhance the decoding accuracy of\nMI-EEG signals across various neural network architectures. Unlike traditional\nneural network methods that fail to account for the temporal dynamics in MI-EEG\nin individual difference, our approach captures time-related changes for\ndifferent participants based on a priori knowledge. Through extensive\nexperimentation with multiple participants, we demonstrate that this method not\nonly improves classification accuracy but also exhibits greater adaptability to\nindividual differences compared to position encoding used in Transformer\narchitecture. Significantly, our results reveal that traveling-wave based time\nembedding crucially enhances decoding accuracy, particularly for participants\ntypically considered \"EEG-illiteracy\". As a novel direction in EEG research,\nthe traveling-wave based time embedding not only offers fresh insights for\nneural network decoding strategies but also expands new avenues for research\ninto attention mechanisms in neuroscience and a deeper understanding of EEG\nsignals.",
      "tldr_zh": "这项研究针对 Motor Imagery (MI) 基于 EEG 的信号解码，提出了一种新型 time embedding 技术，即基于行波的 traveling-wave based time embedding，作为 pseudo channel，用于增强神经网络对 MI-EEG 信号的处理，并考虑个体差异和时间动态。实验结果显示，该方法显著提高了分类准确率，尤其对“EEG-illiteracy”参与者效果突出，且比 Transformer 中的位置编码更具适应性。该创新不仅优化了神经网络解码策略，还为 EEG 研究中的注意力机制和信号理解开辟了新途径。",
      "categories": [
        "q-bio.NC",
        "cs.AI"
      ],
      "primary_category": "q-bio.NC",
      "comment": "13 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2405.15812v2",
      "published_date": "2024-05-21 12:55:11 UTC",
      "updated_date": "2024-08-23 11:53:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:10:31.931159"
    },
    {
      "arxiv_id": "2405.12716v1",
      "title": "Reinforcement Learning Enabled Peer-to-Peer Energy Trading for Dairy Farms",
      "title_zh": "翻译失败",
      "authors": [
        "Mian Ibad Ali Shah",
        "Enda Barrett",
        "Karl Mason"
      ],
      "abstract": "Farm businesses are increasingly adopting renewables to enhance energy\nefficiency and reduce reliance on fossil fuels and the grid. This shift aims to\ndecrease dairy farms' dependence on traditional electricity grids by enabling\nthe sale of surplus renewable energy in Peer-to-Peer markets. However, the\ndynamic nature of farm communities poses challenges, requiring specialized\nalgorithms for P2P energy trading. To address this, the Multi-Agent\nPeer-to-Peer Dairy Farm Energy Simulator (MAPDES) has been developed, providing\na platform to experiment with Reinforcement Learning techniques. The\nsimulations demonstrate significant cost savings, including a 43% reduction in\nelectricity expenses, a 42% decrease in peak demand, and a 1.91% increase in\nenergy sales compared to baseline scenarios lacking peer-to-peer energy trading\nor renewable energy sources.",
      "tldr_zh": "本研究探讨了利用Reinforcement Learning启用Peer-to-Peer (P2P) 能源交易，以帮助乳品农场减少对传统电网的依赖，并提升能源效率。研究开发了Multi-Agent Peer-to-Peer Dairy Farm Energy Simulator (MAPDES) 模拟器，作为实验Reinforcement Learning技术的平台。模拟结果显示，与无P2P交易或可再生能源的基线场景相比，电费减少43%，峰值需求降低42%，能源销售增加1.91%。这为农场社区的动态能源管理提供了可行的解决方案。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "cs.MA"
      ],
      "primary_category": "cs.AI",
      "comment": "Proc. of the Main Track of 22nd International Conference on Practical\n  Applications of Agents and Multi-Agent Systems, 26th-28th June, 2024,\n  https://www.paams.net/. Includes 6 figures, 1 table and 32 references",
      "pdf_url": "http://arxiv.org/pdf/2405.12716v1",
      "published_date": "2024-05-21 12:19:17 UTC",
      "updated_date": "2024-05-21 12:19:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:10:43.341245"
    },
    {
      "arxiv_id": "2405.13092v1",
      "title": "CausalPlayground: Addressing Data-Generation Requirements in Cutting-Edge Causality Research",
      "title_zh": "翻译失败",
      "authors": [
        "Andreas W M Sauter",
        "Erman Acar",
        "Aske Plaat"
      ],
      "abstract": "Research on causal effects often relies on synthetic data due to the scarcity\nof real-world datasets with ground-truth effects. Since current data-generating\ntools do not always meet all requirements for state-of-the-art research, ad-hoc\nmethods are often employed. This leads to heterogeneity among datasets and\ndelays research progress. We address the shortcomings of current\ndata-generating libraries by introducing CausalPlayground, a Python library\nthat provides a standardized platform for generating, sampling, and sharing\nstructural causal models (SCMs). CausalPlayground offers fine-grained control\nover SCMs, interventions, and the generation of datasets of SCMs for learning\nand quantitative research. Furthermore, by integrating with Gymnasium, the\nstandard framework for reinforcement learning (RL) environments, we enable\nonline interaction with the SCMs. Overall, by introducing CausalPlayground we\naim to foster more efficient and comparable research in the field. All code and\nAPI documentation is available at https://github.com/sa-and/CausalPlayground.",
      "tldr_zh": "该研究针对因果效应研究中合成数据生成工具的不足（如缺乏ground-truth effects和数据集异质性），引入了Python库CausalPlayground。该库提供了一个标准化平台，用于生成、采样和共享structural causal models (SCMs)，并允许对SCMs、interventions和数据集进行细粒度控制。此外，通过与Gymnasium框架集成，实现了与SCMs的在线交互，从而促进更高效和可比较的因果研究。代码和API文档可在GitHub上获取。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.13092v1",
      "published_date": "2024-05-21 12:08:48 UTC",
      "updated_date": "2024-05-21 12:08:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:10:54.737021"
    },
    {
      "arxiv_id": "2405.12712v1",
      "title": "From Human-to-Human to Human-to-Bot Conversations in Software Engineering",
      "title_zh": "翻译失败",
      "authors": [
        "Ranim Khojah",
        "Francisco Gomes de Oliveira Neto",
        "Philipp Leitner"
      ],
      "abstract": "Software developers use natural language to interact not only with other\nhumans, but increasingly also with chatbots. These interactions have different\nproperties and flow differently based on what goal the developer wants to\nachieve and who they interact with. In this paper, we aim to understand the\ndynamics of conversations that occur during modern software development after\nthe integration of AI and chatbots, enabling a deeper recognition of the\nadvantages and disadvantages of including chatbot interactions in addition to\nhuman conversations in collaborative work. We compile existing conversation\nattributes with humans and NLU-based chatbots and adapt them to the context of\nsoftware development. Then, we extend the comparison to include LLM-powered\nchatbots based on an observational study. We present similarities and\ndifferences between human-to-human and human-to-bot conversations, also\ndistinguishing between NLU- and LLM-based chatbots. Furthermore, we discuss how\nunderstanding the differences among the conversation styles guides the\ndeveloper on how to shape their expectations from a conversation and\nconsequently support the communication within a software team. We conclude that\nthe recent conversation styles that we observe with LLM-chatbots can not\nreplace conversations with humans due to certain attributes regarding social\naspects despite their ability to support productivity and decrease the\ndevelopers' mental load.",
      "tldr_zh": "本文研究软件工程中从 Human-to-Human 到 Human-to-Bot 对话的转变，探讨开发者与人类及聊天机器人（如 NLU-based 和 LLM-powered chatbots）互动的动态差异。作者通过编译现有对话属性、适应软件开发上下文并进行观察性研究，比较了这些对话的相似性和差异。结果显示，LLM-powered chatbots 能提高生产力和降低开发者心理负担，但由于缺乏社会属性，无法完全取代人类对话。最后，该研究指导开发者调整对话期望，从而优化团队沟通。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.CL",
        "cs.HC"
      ],
      "primary_category": "cs.SE",
      "comment": "Accepted at the 1st ACM International Conference on AI-powered\n  Software (AIware) 2024",
      "pdf_url": "http://arxiv.org/pdf/2405.12712v1",
      "published_date": "2024-05-21 12:04:55 UTC",
      "updated_date": "2024-05-21 12:04:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:11:08.419097"
    },
    {
      "arxiv_id": "2405.12711v2",
      "title": "A Masked Semi-Supervised Learning Approach for Otago Micro Labels Recognition",
      "title_zh": "翻译失败",
      "authors": [
        "Meng Shang",
        "Lenore Dedeyne",
        "Jolan Dupont",
        "Laura Vercauteren",
        "Nadjia Amini",
        "Laurence Lapauw",
        "Evelien Gielen",
        "Sabine Verschueren",
        "Carolina Varon",
        "Walter De Raedt",
        "Bart Vanrumste"
      ],
      "abstract": "The Otago Exercise Program (OEP) serves as a vital rehabilitation initiative\nfor older adults, aiming to enhance their strength and balance, and\nconsequently prevent falls. While Human Activity Recognition (HAR) systems have\nbeen widely employed in recognizing the activities of individuals, existing\nsystems focus on the duration of macro activities (i.e. a sequence of\nrepetitions of the same exercise), neglecting the ability to discern micro\nactivities (i.e. the individual repetitions of the exercises), in the case of\nOEP. This study presents a novel semi-supervised machine learning approach\naimed at bridging this gap in recognizing the micro activities of OEP. To\nmanage the limited dataset size, our model utilizes a Transformer encoder for\nfeature extraction, subsequently classified by a Temporal Convolutional Network\n(TCN). Simultaneously, the Transformer encoder is employed for masked\nunsupervised learning to reconstruct input signals. Results indicate that the\nmasked unsupervised learning task enhances the performance of the supervised\nlearning (classification task), as evidenced by f1-scores surpassing the\nclinically applicable threshold of 0.8. From the micro activities, two\nclinically relevant outcomes emerge: counting the number of repetitions of each\nexercise and calculating the velocity during chair rising. These outcomes\nenable the automatic monitoring of exercise intensity and difficulty in the\ndaily lives of older adults.",
      "tldr_zh": "本文提出了一种基于 Masked Semi-Supervised Learning 的方法，用于识别 Otago Exercise Program (OEP) 中的微观活动（即单个运动重复），以弥补现有 Human Activity Recognition (HAR) 系统仅关注宏观活动的局限性。方法结合 Transformer encoder 进行特征提取和信号重建（通过 masked unsupervised learning），随后由 Temporal Convolutional Network (TCN) 进行分类，结果显示 F1-scores 超过 0.8，显著提升了识别性能。通过微观活动识别，该方法能自动计算运动重复次数和椅子起立速度，实现对老年人群日常锻炼强度和难度的监测。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.12711v2",
      "published_date": "2024-05-21 12:00:01 UTC",
      "updated_date": "2024-05-22 19:35:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:11:20.093468"
    },
    {
      "arxiv_id": "2405.12701v3",
      "title": "OLAPH: Improving Factuality in Biomedical Long-form Question Answering",
      "title_zh": "OLAPH：改善生物医学长形式问答的事实性",
      "authors": [
        "Minbyul Jeong",
        "Hyeon Hwang",
        "Chanwoong Yoon",
        "Taewhoo Lee",
        "Jaewoo Kang"
      ],
      "abstract": "In the medical domain, numerous scenarios necessitate the long-form\ngeneration ability of large language models (LLMs). Specifically, when\naddressing patients' questions, it is essential that the model's response\nconveys factual claims, highlighting the need for an automated method to\nevaluate those claims. Thus, we introduce MedLFQA, a benchmark dataset\nreconstructed using long-form question-answering datasets related to the\nbiomedical domain. We use MedLFQA to facilitate a cost-effective automatic\nevaluations of factuality. We also propose OLAPH, a simple and novel framework\nthat utilizes cost-effective and multifaceted automatic evaluation to construct\na synthetic preference set and answers questions in our preferred manner. Our\nframework leads us to train LLMs step-by-step to reduce hallucinations and\ninclude crucial medical claims. We highlight that, even on evaluation metrics\nnot used during training, LLMs trained with our OLAPH framework demonstrate\nsignificant performance improvement in factuality. Our findings reveal that a\n7B LLM trained with our OLAPH framework can provide long answers comparable to\nthe medical experts' answers in terms of factuality. We believe that our work\ncould shed light on gauging the long-text generation ability of LLMs in the\nmedical domain. Our code and datasets are available.",
      "tldr_zh": "该论文针对生物医学领域的大语言模型（LLMs）在长形式问答中事实性不足的问题，引入了 MedLFQA 基准数据集，用于成本有效的自动事实性评估。作者提出 OLAPH 框架，这是一个简单的新颖方法，通过构建合成偏好集和多方面自动评估，逐步训练 LLMs 以减少 hallucinations 并包含关键医疗声明。实验结果显示，使用 OLAPH 框架训练的 7B LLM 在事实性指标上显著提升，甚至可与医疗专家的回答相媲美。该工作提供了代码和数据集，以推动医疗领域 LLMs 长文本生成能力的评估。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.12701v3",
      "published_date": "2024-05-21 11:50:16 UTC",
      "updated_date": "2024-10-15 14:21:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:11:32.105082"
    },
    {
      "arxiv_id": "2405.13090v2",
      "title": "FedASTA: Federated adaptive spatial-temporal attention for traffic flow prediction",
      "title_zh": "翻译失败",
      "authors": [
        "Kaiyuan Li",
        "Yihan Zhang",
        "Huandong Wang",
        "Yan Zhuo",
        "Xinlei Chen"
      ],
      "abstract": "Mobile devices and the Internet of Things (IoT) devices nowadays generate a\nlarge amount of heterogeneous spatial-temporal data. It remains a challenging\nproblem to model the spatial-temporal dynamics under privacy concern. Federated\nlearning (FL) has been proposed as a framework to enable model training across\ndistributed devices without sharing original data which reduce privacy concern.\nPersonalized federated learning (PFL) methods further address data heterogenous\nproblem. However, these methods don't consider natural spatial relations among\nnodes. For the sake of modeling spatial relations, Graph Neural Netowork (GNN)\nbased FL approach have been proposed. But dynamic spatial-temporal relations\namong edge nodes are not taken into account. Several approaches model\nspatial-temporal dynamics in a centralized environment, while less effort has\nbeen made under federated setting. To overcome these challeges, we propose a\nnovel Federated Adaptive Spatial-Temporal Attention (FedASTA) framework to\nmodel the dynamic spatial-temporal relations. On the client node, FedASTA\nextracts temporal relations and trend patterns from the decomposed terms of\noriginal time series. Then, on the server node, FedASTA utilize trend patterns\nfrom clients to construct adaptive temporal-spatial aware graph which captures\ndynamic correlation between clients. Besides, we design a masked spatial\nattention module with both static graph and constructed adaptive graph to model\nspatial dependencies among clients. Extensive experiments on five real-world\npublic traffic flow datasets demonstrate that our method achieves state-of-art\nperformance in federated scenario. In addition, the experiments made in\ncentralized setting show the effectiveness of our novel adaptive graph\nconstruction approach compared with other popular dynamic spatial-temporal\naware methods.",
      "tldr_zh": "这篇论文提出 FedASTA，一种基于 Federated Learning (FL) 的自适应时空注意力框架，用于解决隐私保护下交通流量预测中的异构时空动态建模问题。FedASTA 在客户端提取时间序列的时序关系和趋势模式，在服务器端构建自适应时空感知图，并通过 masked spatial attention 模块结合静态和动态图来捕捉客户端间的空间依赖。实验结果显示，该方法在五个真实交通流量数据集上实现了联邦场景下的最先进性能，并在集中式设置中验证了其自适应图构建方法的有效性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DC"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.13090v2",
      "published_date": "2024-05-21 11:44:07 UTC",
      "updated_date": "2024-11-04 02:10:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:11:43.577904"
    },
    {
      "arxiv_id": "2405.12689v2",
      "title": "Spotting AI's Touch: Identifying LLM-Paraphrased Spans in Text",
      "title_zh": "翻译失败",
      "authors": [
        "Yafu Li",
        "Zhilin Wang",
        "Leyang Cui",
        "Wei Bi",
        "Shuming Shi",
        "Yue Zhang"
      ],
      "abstract": "AI-generated text detection has attracted increasing attention as powerful\nlanguage models approach human-level generation. Limited work is devoted to\ndetecting (partially) AI-paraphrased texts. However, AI paraphrasing is\ncommonly employed in various application scenarios for text refinement and\ndiversity. To this end, we propose a novel detection framework, paraphrased\ntext span detection (PTD), aiming to identify paraphrased text spans within a\ntext. Different from text-level detection, PTD takes in the full text and\nassigns each of the sentences with a score indicating the paraphrasing degree.\nWe construct a dedicated dataset, PASTED, for paraphrased text span detection.\nBoth in-distribution and out-of-distribution results demonstrate the\neffectiveness of PTD models in identifying AI-paraphrased text spans.\nStatistical and model analysis explains the crucial role of the surrounding\ncontext of the paraphrased text spans. Extensive experiments show that PTD\nmodels can generalize to versatile paraphrasing prompts and multiple\nparaphrased text spans. We release our resources at\nhttps://github.com/Linzwcs/PASTED.",
      "tldr_zh": "这篇论文针对AI改写文本的检测问题，提出了一种新框架——paraphrased text span detection (PTD)，旨在识别文本中由LLM生成或改写的特定段落，并为每个句子分配表示改写程度的得分。研究构建了专用数据集PASTED，并通过实验证明PTD模型在分布内和分布外测试中有效识别AI改写内容，同时强调了周围上下文的关键作用。结果显示，该模型能泛化到多种改写提示和多个文本段落，为AI生成文本检测提供了实用工具。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "ACL 2024 Findings",
      "pdf_url": "http://arxiv.org/pdf/2405.12689v2",
      "published_date": "2024-05-21 11:22:27 UTC",
      "updated_date": "2024-05-29 07:09:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:11:55.001726"
    },
    {
      "arxiv_id": "2405.12658v1",
      "title": "Mitigating Overconfidence in Out-of-Distribution Detection by Capturing Extreme Activations",
      "title_zh": "翻译失败",
      "authors": [
        "Mohammad Azizmalayeri",
        "Ameen Abu-Hanna",
        "Giovanni Cinà"
      ],
      "abstract": "Detecting out-of-distribution (OOD) instances is crucial for the reliable\ndeployment of machine learning models in real-world scenarios. OOD inputs are\ncommonly expected to cause a more uncertain prediction in the primary task;\nhowever, there are OOD cases for which the model returns a highly confident\nprediction. This phenomenon, denoted as \"overconfidence\", presents a challenge\nto OOD detection. Specifically, theoretical evidence indicates that\noverconfidence is an intrinsic property of certain neural network\narchitectures, leading to poor OOD detection. In this work, we address this\nissue by measuring extreme activation values in the penultimate layer of neural\nnetworks and then leverage this proxy of overconfidence to improve on several\nOOD detection baselines. We test our method on a wide array of experiments\nspanning synthetic data and real-world data, tabular and image datasets,\nmultiple architectures such as ResNet and Transformer, different training loss\nfunctions, and include the scenarios examined in previous theoretical work.\nCompared to the baselines, our method often grants substantial improvements,\nwith double-digit increases in OOD detection AUC, and it does not damage\nperformance in any scenario.",
      "tldr_zh": "该研究针对机器学习模型在检测 out-of-distribution (OOD) 实例时的 overconfidence 问题提出了一种新方法，通过捕捉神经网络倒数第二层的 extreme activations 作为代理指标，来改进现有的 OOD 检测基线。作者分析了 overconfidence 的理论基础，并设计实验涵盖合成数据、真实数据、表格和图像数据集、ResNet 和 Transformer 等架构，以及多种训练损失函数。结果显示，该方法在 OOD 检测 AUC 上实现了双位数提升，且在所有场景中不会损害模型性能，为可靠的模型部署提供了重要改进。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted for the 40th Conference on Uncertainty in Artificial\n  Intelligence (UAI 2024)",
      "pdf_url": "http://arxiv.org/pdf/2405.12658v1",
      "published_date": "2024-05-21 10:14:50 UTC",
      "updated_date": "2024-05-21 10:14:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:12:07.051743"
    },
    {
      "arxiv_id": "2405.12656v1",
      "title": "Retrieval-Augmented Language Model for Extreme Multi-Label Knowledge Graph Link Prediction",
      "title_zh": "检索增强语言模型用于极端多标签",
      "authors": [
        "Yu-Hsiang Lin",
        "Huang-Ting Shieh",
        "Chih-Yu Liu",
        "Kuang-Ting Lee",
        "Hsiao-Cheng Chang",
        "Jing-Lun Yang",
        "Yu-Sheng Lin"
      ],
      "abstract": "Extrapolation in Large language models (LLMs) for open-ended inquiry\nencounters two pivotal issues: (1) hallucination and (2) expensive training\ncosts. These issues present challenges for LLMs in specialized domains and\npersonalized data, requiring truthful responses and low fine-tuning costs.\nExisting works attempt to tackle the problem by augmenting the input of a\nsmaller language model with information from a knowledge graph (KG). However,\nthey have two limitations: (1) failing to extract relevant information from a\nlarge one-hop neighborhood in KG and (2) applying the same augmentation\nstrategy for KGs with different characteristics that may result in low\nperformance. Moreover, open-ended inquiry typically yields multiple responses,\nfurther complicating extrapolation. We propose a new task, the extreme\nmulti-label KG link prediction task, to enable a model to perform extrapolation\nwith multiple responses using structured real-world knowledge. Our retriever\nidentifies relevant one-hop neighbors by considering entity, relation, and\ntextual data together. Our experiments demonstrate that (1) KGs with different\ncharacteristics require different augmenting strategies, and (2) augmenting the\nlanguage model's input with textual data improves task performance\nsignificantly. By incorporating the retrieval-augmented framework with KG, our\nframework, with a small parameter size, is able to extrapolate based on a given\nKG. The code can be obtained on GitHub:\nhttps://github.com/exiled1143/Retrieval-Augmented-Language-Model-for-Multi-Label-Knowledge-Graph-Link-Prediction.git",
      "tldr_zh": "这篇论文针对大型语言模型 (LLMs) 在开放式查询中的 hallucination 和高训练成本问题，提出了一种新的任务：extreme multi-label knowledge graph (KG) link prediction，以处理多个响应的知识外推。他们的方法包括一个 retrieval-augmented 框架，使用 retriever 结合实体、关系和文本数据从 KG 的庞大一跳邻居中提取相关信息，并针对不同 KG 特性采用定制增强策略。实验结果显示，这种框架显著提高了任务性能，且以小参数大小实现了高效的知识外推。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.12656v1",
      "published_date": "2024-05-21 10:10:56 UTC",
      "updated_date": "2024-05-21 10:10:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:12:20.627058"
    },
    {
      "arxiv_id": "2405.12654v1",
      "title": "Utilizing Description Logics for Global Explanations of Heterogeneous Graph Neural Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Dominik Köhler",
        "Stefan Heindorf"
      ],
      "abstract": "Graph Neural Networks (GNNs) are effective for node classification in\ngraph-structured data, but they lack explainability, especially at the global\nlevel. Current research mainly utilizes subgraphs of the input as local\nexplanations or generates new graphs as global explanations. However, these\ngraph-based methods are limited in their ability to explain classes with\nmultiple sufficient explanations. To provide more expressive explanations, we\npropose utilizing class expressions (CEs) from the field of description logic\n(DL). Our approach explains heterogeneous graphs with different types of nodes\nusing CEs in the EL description logic. To identify the best explanation among\nmultiple candidate explanations, we employ and compare two different scoring\nfunctions: (1) For a given CE, we construct multiple graphs, have the GNN make\na prediction for each graph, and aggregate the predicted scores. (2) We score\nthe CE in terms of fidelity, i.e., we compare the predictions of the GNN to the\npredictions by the CE on a separate validation set. Instead of subgraph-based\nexplanations, we offer CE-based explanations.",
      "tldr_zh": "这篇论文探讨了图神经网络 (GNNs) 在异构图节点分类中的全局解释问题，指出现有基于子图或新图的方法难以处理多重充分解释。作者提出一种新方法，使用描述逻辑 (DL) 中的类表达式 (CEs)，特别是 EL 描述逻辑，来为异构图提供更具表现力的全局解释。为选择最佳解释，他们比较了两种评分函数：一种通过构建多个图、聚合 GNN 的预测分数；另一种基于保真度 (fidelity)，即比较 GNN 和 CEs 在验证集上的预测结果。该方法超越了传统的子图-based 解释，为 GNNs 的可解释性提供了创新解决方案。",
      "categories": [
        "cs.AI",
        "cs.LO"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.12654v1",
      "published_date": "2024-05-21 10:07:29 UTC",
      "updated_date": "2024-05-21 10:07:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:12:32.507920"
    },
    {
      "arxiv_id": "2405.12648v1",
      "title": "Scene Graph Generation Strategy with Co-occurrence Knowledge and Learnable Term Frequency",
      "title_zh": "翻译失败",
      "authors": [
        "Hyeongjin Kim",
        "Sangwon Kim",
        "Dasom Ahn",
        "Jong Taek Lee",
        "Byoung Chul Ko"
      ],
      "abstract": "Scene graph generation (SGG) is an important task in image understanding\nbecause it represents the relationships between objects in an image as a graph\nstructure, making it possible to understand the semantic relationships between\nobjects intuitively. Previous SGG studies used a message-passing neural\nnetworks (MPNN) to update features, which can effectively reflect information\nabout surrounding objects. However, these studies have failed to reflect the\nco-occurrence of objects during SGG generation. In addition, they only\naddressed the long-tail problem of the training dataset from the perspectives\nof sampling and learning methods. To address these two problems, we propose\nCooK, which reflects the Co-occurrence Knowledge between objects, and the\nlearnable term frequency-inverse document frequency (TF-l-IDF) to solve the\nlong-tail problem. We applied the proposed model to the SGG benchmark dataset,\nand the results showed a performance improvement of up to 3.8% compared with\nexisting state-of-the-art models in SGGen subtask. The proposed method exhibits\ngeneralization ability from the results obtained, showing uniform performance\nimprovement for all MPNN models.",
      "tldr_zh": "本论文提出了一种改进的 Scene Graph Generation (SGG) 策略，引入 Co-occurrence Knowledge (CooK) 来反映图像中对象之间的共现关系，并使用 learnable Term Frequency-Inverse Document Frequency (TF-l-IDF) 来解决训练数据集的长尾问题。相比于传统的 Message-Passing Neural Networks (MPNN) 方法，该策略在 SGG 基准数据集上实现了 SGGen 子任务性能提升高达 3.8%。此外，该方法展示了良好的泛化能力，对所有 MPNN 模型均有统一的性能改进。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by ICML2024",
      "pdf_url": "http://arxiv.org/pdf/2405.12648v1",
      "published_date": "2024-05-21 09:56:48 UTC",
      "updated_date": "2024-05-21 09:56:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:12:43.283812"
    },
    {
      "arxiv_id": "2405.12633v1",
      "title": "Automating Attendance Management in Human Resources: A Design Science Approach Using Computer Vision and Facial Recognition",
      "title_zh": "人力资源中的考勤管理自动化：一种使用计算机视觉和面部识别的设计科学方法",
      "authors": [
        "Bao-Thien Nguyen-Tat",
        "Minh-Quoc Bui",
        "Vuong M. Ngo"
      ],
      "abstract": "Haar Cascade is a cost-effective and user-friendly machine learning-based\nalgorithm for detecting objects in images and videos. Unlike Deep Learning\nalgorithms, which typically require significant resources and expensive\ncomputing costs, it uses simple image processing techniques like edge detection\nand Haar features that are easy to comprehend and implement. By combining Haar\nCascade with OpenCV2 on an embedded computer like the NVIDIA Jetson Nano, this\nsystem can accurately detect and match faces in a database for attendance\ntracking. This system aims to achieve several specific objectives that set it\napart from existing solutions. It leverages Haar Cascade, enriched with\ncarefully selected Haar features, such as Haar-like wavelets, and employs\nadvanced edge detection techniques. These techniques enable precise face\ndetection and matching in both images and videos, contributing to high accuracy\nand robust performance. By doing so, it minimizes manual intervention and\nreduces errors, thereby strengthening accountability. Additionally, the\nintegration of OpenCV2 and the NVIDIA Jetson Nano optimizes processing\nefficiency, making it suitable for resource-constrained environments. This\nsystem caters to a diverse range of educational institutions, including\nschools, colleges, vocational training centers, and various workplace settings\nsuch as small businesses, offices, and factories. ... The system's\naffordability and efficiency democratize attendance management technology,\nmaking it accessible to a broader audience. Consequently, it has the potential\nto transform attendance tracking and management practices, ultimately leading\nto heightened productivity and accountability. In conclusion, this system\nrepresents a groundbreaking approach to attendance tracking and management...",
      "tldr_zh": "这篇论文采用设计科学方法，使用 Computer Vision 和 Facial Recognition 技术来自动化人力资源出勤管理。核心方法是基于 Haar Cascade 算法结合 OpenCV2 和 NVIDIA Jetson Nano，进行高效的面部检测和匹配，利用边缘检测和 Haar 特征来实现高准确率和低资源消耗。相比传统深度学习算法，该系统减少了手动干预和错误，提高了处理效率，适用于学校、工作场所等多样化环境。最终，该创新方案有望提升整体生产力和责任感，使出勤管理技术更易于推广。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.AR",
        "cs.HC",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.CV",
      "comment": "31 pages, accepted to publish by the International Journal of\n  Information Management Data Insights (IJIMDS) in 2024",
      "pdf_url": "http://arxiv.org/pdf/2405.12633v1",
      "published_date": "2024-05-21 09:38:56 UTC",
      "updated_date": "2024-05-21 09:38:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:12:57.414023"
    },
    {
      "arxiv_id": "2405.12630v2",
      "title": "Exploration of Masked and Causal Language Modelling for Text Generation",
      "title_zh": "掩码和因果语言建模在文本生成中的探索",
      "authors": [
        "Nicolo Micheletti",
        "Samuel Belkadi",
        "Lifeng Han",
        "Goran Nenadic"
      ],
      "abstract": "Large Language Models (LLMs) have revolutionised the field of Natural\nLanguage Processing (NLP) and have achieved state-of-the-art performance in\npractically every task in this field. However, the prevalent approach used in\ntext generation, Causal Language Modelling (CLM), which generates text\nsequentially from left to right, inherently limits the freedom of the model,\nwhich does not decide when and where each token is generated. In contrast,\nMasked Language Modelling (MLM), primarily used for language understanding\ntasks, can generate tokens anywhere in the text and any order. This paper\nconducts an extensive comparison of MLM and CLM approaches for text generation\ntasks. To do so, we pre-train several language models of comparable sizes on\nthree different datasets, namely 1) medical discharge summaries, 2) movie plot\nsynopses, and 3) authorship verification datasets. To assess the quality of the\ngenerations, we first employ quantitative metrics and then perform a\nqualitative human evaluation to analyse coherence and grammatical correctness.\nIn addition, we evaluate the usefulness of the generated texts by using them in\nthree different downstream tasks: 1) Entity Recognition, 2) Text\nClassification, and 3) Authorship Verification. The results show that MLM\nconsistently outperforms CLM in text generation across all datasets, with\nhigher quantitative scores and better coherence in the generated text. The\nstudy also finds \\textit{no strong correlation} between the quality of the\ngenerated text and the performance of the models in the downstream tasks. With\nthis study, we show that MLM for text generation has great potential for future\nresearch and provides direction for future studies in this area.",
      "tldr_zh": "本研究探讨了 Masked Language Modelling (MLM) 与 Causal Language Modelling (CLM) 在文本生成任务中的性能比较，指出 CLM 的左到右顺序生成限制了模型自由度，而 MLM 允许更灵活的 token 生成位置。研究者在三个数据集（医疗出院总结、电影情节概要和作者验证）上预训练了多个 Large Language Models (LLMs)，并通过定量指标、人类评估（包括连贯性和语法正确性）以及下游任务（如实体识别、文本分类和作者验证）来评估生成文本的质量。结果显示，MLM 在所有数据集上均优于 CLM，在定量分数和文本连贯性方面表现更好，但生成文本质量与下游任务性能之间无强相关性。该研究突显了 MLM 在文本生成领域的潜力，并为未来 Natural Language Processing (NLP) 研究提供新方向。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "working paper - under review",
      "pdf_url": "http://arxiv.org/pdf/2405.12630v2",
      "published_date": "2024-05-21 09:33:31 UTC",
      "updated_date": "2024-08-09 00:01:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:13:08.939165"
    },
    {
      "arxiv_id": "2405.12628v1",
      "title": "Play Everywhere: A Temporal Logic based Game Environment Independent Approach for Playing Soccer with Robots",
      "title_zh": "翻译失败",
      "authors": [
        "Vincenzo Suriani",
        "Emanuele Musumeci",
        "Daniele Nardi",
        "Domenico Daniele Bloisi"
      ],
      "abstract": "Robots playing soccer often rely on hard-coded behaviors that struggle to\ngeneralize when the game environment change. In this paper, we propose a\ntemporal logic based approach that allows robots' behaviors and goals to adapt\nto the semantics of the environment. In particular, we present a hierarchical\nrepresentation of soccer in which the robot selects the level of operation\nbased on the perceived semantic characteristics of the environment, thus\nmodifying dynamically the set of rules and goals to apply. The proposed\napproach enables the robot to operate in unstructured environments, just as it\nhappens when humans go from soccer played on an official field to soccer played\non a street. Three different use cases set in different scenarios are presented\nto demonstrate the effectiveness of the proposed approach.",
      "tldr_zh": "该论文针对机器人踢足球时依赖硬编码行为导致环境变化下泛化能力差的问题，提出了一种基于 Temporal Logic 的方法，使机器人行为和目标能动态适应环境的语义特性。方法采用分层表示，让机器人根据感知到的环境特征选择操作级别，从而实时修改规则和目标，实现从结构化场地到非结构化街头场景的灵活切换。论文通过三个不同场景的用例验证了该方法的有效性，展示了其在提升机器人适应性方面的潜力。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "RoboCup 2023: Robot World Cup XXVI Best Paper",
      "pdf_url": "http://arxiv.org/pdf/2405.12628v1",
      "published_date": "2024-05-21 09:30:47 UTC",
      "updated_date": "2024-05-21 09:30:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:13:18.515799"
    },
    {
      "arxiv_id": "2407.05426v1",
      "title": "AI in Manufacturing: Market Analysis and Opportunities",
      "title_zh": "人工智能在制造业：市场分析与机会",
      "authors": [
        "Mohamed Abdelaal"
      ],
      "abstract": "In this paper, we explore the transformative impact of Artificial\nIntelligence (AI) in the manufacturing sector, highlighting its potential to\nrevolutionize industry practices and enhance operational efficiency. We delve\ninto various applications of AI in manufacturing, with a particular emphasis on\nhuman-machine interfaces (HMI) and AI-powered milling machines, showcasing how\nthese technologies contribute to more intuitive operations and precision in\nproduction processes. Through rigorous market analysis, the paper presents\ninsightful data on AI adoption rates among German manufacturers, comparing\nthese figures with global trends and exploring the specific uses of AI in\nproduction, maintenance, customer service, and more. In addition, the paper\nexamines the emerging field of Generative AI and the potential applications of\nlarge language models in manufacturing processes. The findings indicate a\nsignificant increase in AI adoption from 6% in 2020 to 13.3% in 2023 among\nGerman companies, with a projection of substantial economic impact by 2030. The\nstudy also addresses the challenges faced by companies, such as data quality\nand integration hurdles, providing a balanced view of the opportunities and\nobstacles in AI implementation.",
      "tldr_zh": "这篇论文探讨了人工智能（AI）在制造业的变革性影响，强调其在提升操作效率方面的潜力，特别是通过人机界面（HMI）和AI-powered milling machines实现更直观的操作和精确生产。研究通过市场分析比较了德国制造商的AI采用率（从2020年的6%上升到2023年的13.3%）与全球趋势，并考察了Generative AI和大型语言模型在生产、维护和客户服务中的应用。论文预测AI将带来重大经济影响，但也指出了数据质量和整合等挑战，提供了一个平衡的机遇与障碍视角。",
      "categories": [
        "cs.AI",
        "cs.CY",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.05426v1",
      "published_date": "2024-05-21 09:26:52 UTC",
      "updated_date": "2024-05-21 09:26:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:13:30.911142"
    },
    {
      "arxiv_id": "2405.12621v2",
      "title": "Limits of Theory of Mind Modelling in Dialogue-Based Collaborative Plan Acquisition",
      "title_zh": "翻译失败",
      "authors": [
        "Matteo Bortoletto",
        "Constantin Ruhdorfer",
        "Adnen Abdessaied",
        "Lei Shi",
        "Andreas Bulling"
      ],
      "abstract": "Recent work on dialogue-based collaborative plan acquisition (CPA) has\nsuggested that Theory of Mind (ToM) modelling can improve missing knowledge\nprediction in settings with asymmetric skill-sets and knowledge. Although ToM\nwas claimed to be important for effective collaboration, its real impact on\nthis novel task remains under-explored. By representing plans as graphs and by\nexploiting task-specific constraints we show that, as performance on CPA nearly\ndoubles when predicting one's own missing knowledge, the improvements due to\nToM modelling diminish. This phenomenon persists even when evaluating existing\nbaseline methods. To better understand the relevance of ToM for CPA, we report\na principled performance comparison of models with and without ToM features.\nResults across different models and ablations consistently suggest that learned\nToM features are indeed more likely to reflect latent patterns in the data with\nno perceivable link to ToM. This finding calls for a deeper understanding of\nthe role of ToM in CPA and beyond, as well as new methods for modelling and\nevaluating mental states in computational collaborative agents.",
      "tldr_zh": "本研究探讨了 Theory of Mind (ToM) 建模在对话-based 协作计划获取 (CPA) 中的局限性，通过将计划表示为图并利用任务特定约束，实验发现预测自身缺失知识时性能近乎翻倍，而 ToM 建模带来的改善微乎其微。结果显示，现有模型中加入 ToM 特征后，其效果更可能反映数据中的潜在模式，而非真正的心理状态建模。这呼吁对 ToM 在 CPA 及更广泛协作代理中的作用进行更深入的理解，并开发新的建模和评估方法。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "ACL 2024",
      "pdf_url": "http://arxiv.org/pdf/2405.12621v2",
      "published_date": "2024-05-21 09:23:39 UTC",
      "updated_date": "2024-05-28 18:33:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:13:44.248619"
    },
    {
      "arxiv_id": "2405.12617v2",
      "title": "Quantifying Semantic Emergence in Language Models",
      "title_zh": "量化语言模型中的语义涌现",
      "authors": [
        "Hang Chen",
        "Xinyu Yang",
        "Jiaying Zhu",
        "Wenya Wang"
      ],
      "abstract": "Large language models (LLMs) are widely recognized for their exceptional\ncapacity to capture semantics meaning. Yet, there remains no established metric\nto quantify this capability. In this work, we introduce a quantitative metric,\nInformation Emergence (IE), designed to measure LLMs' ability to extract\nsemantics from input tokens. We formalize ``semantics'' as the meaningful\ninformation abstracted from a sequence of tokens and quantify this by comparing\nthe entropy reduction observed for a sequence of tokens (macro-level) and\nindividual tokens (micro-level). To achieve this, we design a lightweight\nestimator to compute the mutual information at each transformer layer, which is\nagnostic to different tasks and language model architectures. We apply IE in\nboth synthetic in-context learning (ICL) scenarios and natural sentence\ncontexts. Experiments demonstrate informativeness and patterns about semantics.\nWhile some of these patterns confirm the conventional prior linguistic\nknowledge, the rest are relatively unexpected, which may provide new insights.",
      "tldr_zh": "本研究引入了 Information Emergence (IE) 指标，用于量化大型语言模型 (LLMs) 从输入标记中提取语义的能力，填补了现有评估标准的空白。IE 通过比较序列级（宏观）和单个标记级（微观）的熵减少来形式化语义，并设计了一个轻量级估计器计算每个 Transformer 层的互信息，从而适用于不同任务和模型架构。研究在合成的情景学习 (ICL) 场景和自然句子上下文中应用 IE，实验结果揭示了各种语义模式，其中一些符合传统语言知识，而其他意外发现可能带来新见解。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "17 pages",
      "pdf_url": "http://arxiv.org/pdf/2405.12617v2",
      "published_date": "2024-05-21 09:12:20 UTC",
      "updated_date": "2024-12-18 03:03:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:13:55.088857"
    },
    {
      "arxiv_id": "2405.12612v1",
      "title": "Tagengo: A Multilingual Chat Dataset",
      "title_zh": "Tagengo：多语言聊天数据集",
      "authors": [
        "Peter Devine"
      ],
      "abstract": "Open source large language models (LLMs) have shown great improvements in\nrecent times. However, many of these models are focused solely on popular\nspoken languages. We present a high quality dataset of more than 70k\nprompt-response pairs in 74 languages which consist of human generated prompts\nand synthetic responses. We use this dataset to train a state-of-the-art open\nsource English LLM to chat multilingually. We evaluate our model on MT-Bench\nchat benchmarks in 6 languages, finding that our multilingual model outperforms\nprevious state-of-the-art open source LLMs across each language. We further\nfind that training on more multilingual data is beneficial to the performance\nin a chosen target language (Japanese) compared to simply training on only data\nin that language. These results indicate the necessity of training on large\namounts of high quality multilingual data to make a more accessible LLM.",
      "tldr_zh": "该论文介绍了Tagengo数据集，这是一个高质量的多语言聊天数据集，包含超过70k对人类生成提示和合成响应的prompt-response对，覆盖74种语言。作者使用该数据集训练一个开源英语LLM，使其支持多语言聊天，并在6种语言的MT-Bench基准测试中，该模型的表现超过了之前的开源LLM状态。研究进一步发现，训练时使用更多多语言数据比仅使用目标语言（如日语）数据更能提升性能，这强调了大量高质量多语言数据对提高LLM可访问性的重要性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.12612v1",
      "published_date": "2024-05-21 09:06:36 UTC",
      "updated_date": "2024-05-21 09:06:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:14:07.565868"
    },
    {
      "arxiv_id": "2405.12604v2",
      "title": "Tiny Refinements Elicit Resilience: Toward Efficient Prefix-Model Against LLM Red-Teaming",
      "title_zh": "翻译失败",
      "authors": [
        "Jiaxu Liu",
        "Xiangyu Yin",
        "Sihao Wu",
        "Jianhong Wang",
        "Meng Fang",
        "Xinping Yi",
        "Xiaowei Huang"
      ],
      "abstract": "With the proliferation of red-teaming strategies for Large Language Models\n(LLMs), the deficiency in the literature about improving the safety and\nrobustness of LLM defense strategies is becoming increasingly pronounced. This\npaper introduces the LLM-based \\textbf{sentinel} model as a plug-and-play\nprefix module designed to reconstruct the input prompt with just a few ($<30$)\nadditional tokens, effectively reducing toxicity in responses from target LLMs.\nThe sentinel model naturally overcomes the \\textit{parameter inefficiency} and\n\\textit{limited model accessibility} for fine-tuning large target models. We\nemploy an interleaved training regimen using Proximal Policy Optimization (PPO)\nto optimize both red team and sentinel models dynamically, incorporating a\nvalue head-sharing mechanism inspired by the multi-agent centralized critic to\nmanage the complex interplay between agents. Our extensive experiments across\ntext-to-text and text-to-image demonstrate the effectiveness of our approach in\nmitigating toxic outputs, even when dealing with larger models like\n\\texttt{Llama-2}, \\texttt{GPT-3.5} and \\texttt{Stable-Diffusion}, highlighting\nthe potential of our framework in enhancing safety and robustness in various\napplications.",
      "tldr_zh": "这篇论文提出了一种基于LLM的sentinel model，作为一个plug-and-play的前缀模块，通过添加少于30个tokens来重构输入提示，从而有效减少目标LLM在red-teaming攻击下的毒性响应。\n该方法克服了参数inefficiency和有限模型可访问性问题，采用Proximal Policy Optimization (PPO)进行交错训练，并引入value head-sharing机制来优化红队和sentinel模型之间的互动。\n实验在text-to-text和text-to-image任务上验证了其有效性，即使针对Llama-2、GPT-3.5和Stable-Diffusion等大型模型，也显著降低了毒性输出，并提升了整体安全性和鲁棒性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Preprint, 10 pages main with 10 pages appendix",
      "pdf_url": "http://arxiv.org/pdf/2405.12604v2",
      "published_date": "2024-05-21 08:57:44 UTC",
      "updated_date": "2024-06-17 18:52:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:14:22.480583"
    },
    {
      "arxiv_id": "2405.13085v1",
      "title": "Multi-domain Knowledge Graph Collaborative Pre-training and Prompt Tuning for Diverse Downstream Tasks",
      "title_zh": "多领域知识图谱协作预训练与提示微调，用于多样下游任务",
      "authors": [
        "Yichi Zhang",
        "Binbin Hu",
        "Zhuo Chen",
        "Lingbing Guo",
        "Ziqi Liu",
        "Zhiqiang Zhang",
        "Lei Liang",
        "Huajun Chen",
        "Wen Zhang"
      ],
      "abstract": "Knowledge graphs (KGs) provide reliable external knowledge for a wide variety\nof AI tasks in the form of structured triples. Knowledge graph pre-training\n(KGP) aims to pre-train neural networks on large-scale KGs and provide unified\ninterfaces to enhance different downstream tasks, which is a key direction for\nKG management, maintenance, and applications. Existing works often focus on\npurely research questions in open domains, or they are not open source due to\ndata security and privacy in real scenarios. Meanwhile, existing studies have\nnot explored the training efficiency and transferability of KGP models in\ndepth. To address these problems, We propose a framework MuDoK to achieve\nmulti-domain collaborative pre-training and efficient prefix prompt tuning to\nserve diverse downstream tasks like recommendation and text understanding. Our\ndesign is a plug-and-play prompt learning approach that can be flexibly adapted\nto different downstream task backbones. In response to the lack of open-source\nbenchmarks, we constructed a new multi-domain KGP benchmark called KPI with two\nlarge-scale KGs and six different sub-domain tasks to evaluate our method and\nopen-sourced it for subsequent research. We evaluated our approach based on\nconstructed KPI benchmarks using diverse backbone models in heterogeneous\ndownstream tasks. The experimental results show that our framework brings\nsignificant performance gains, along with its generality, efficiency, and\ntransferability.",
      "tldr_zh": "该论文提出MuDoK框架，用于多领域知识图谱(KGs)协作预训练和高效前缀提示调整，以增强各种下游任务如推荐和文本理解。该框架采用可插拔的提示学习方法，能够灵活适应不同任务骨干模型，同时解决现有KGP模型在训练效率和可转移性方面的不足。为此，作者构建了一个新的开源基准KPI，包括两个大规模KGs和六个子域任务，用于评估方法。实验结果显示，MuDoK在异构下游任务上显著提升性能，并展示了其泛化性、效率和可转移性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Work in progress. Code and data will be open-sourced at\n  https://github.com/zjukg/MuDoK",
      "pdf_url": "http://arxiv.org/pdf/2405.13085v1",
      "published_date": "2024-05-21 08:22:14 UTC",
      "updated_date": "2024-05-21 08:22:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:14:31.748169"
    },
    {
      "arxiv_id": "2407.17585v1",
      "title": "Quelle {é}thique pour quelle IA ?",
      "title_zh": "翻译失败",
      "authors": [
        "David Doat"
      ],
      "abstract": "This study proposes an analysis of the different types of ethical approaches\ninvolved in the ethics of AI, and situates their interests and limits. First,\nthe author introduces to the contemporary need for and meaning of ethics. He\ndistinguishes it from other registers of normativities and underlines its\ninadequacy to formalization. He then presents a cartography of the landscape of\nethical theories covered by moral philosophy, taking care to distinguish\nmeta-ethics, normative ethics and applied ethics. In drawing up this overview,\nthe author questions the relationship between ethics and artificial\nintelligence. The analysis focuses in particular on the main ethical currents\nthat have imposed themselves in the ways of doing digital ethics and AI in our\nWestern democracies. The author asks whether these practices of ethics, as they\nseem to crystallize today in a precise pattern, constitute a sufficient and\nsufficiently satisfactory response to our needs for ethics in AI. The study\nconcludes with a reflection on the reasons why a human ethics of AI based on a\npragmatic practice of contextual ethics remains necessary and irreducible to\nany formalization or automated treatment of the ethical questions that arise\nfor humans.",
      "tldr_zh": "本研究分析了人工智能（AI）伦理中的不同伦理方法，包括其优势和局限性。作者首先探讨了当代伦理需求，将其与规范性领域区分开来，并强调其无法完全形式化；随后呈现了道德哲学中的伦理理论地图，涵盖 meta-ethics、normative ethics 和 applied ethics，并审视这些理论与 AI 的关系。研究质疑当前数字伦理实践是否足够满足需求，并得出结论：基于语境的实用人类伦理对于 AI 问题而言是必要且不可取代的，无法通过形式化或自动化处理来替代。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "in French language. Workshop Ethique et Morale de la Chaire IA\n  Responsable, Nathalie Nevejans, May 2021, Distanciel, France",
      "pdf_url": "http://arxiv.org/pdf/2407.17585v1",
      "published_date": "2024-05-21 08:13:02 UTC",
      "updated_date": "2024-05-21 08:13:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:14:44.110243"
    },
    {
      "arxiv_id": "2405.13084v2",
      "title": "The 2nd FutureDial Challenge: Dialog Systems with Retrieval Augmented Generation (FutureDial-RAG)",
      "title_zh": "翻译失败",
      "authors": [
        "Yucheng Cai",
        "Si Chen",
        "Yuxuan Wu",
        "Yi Huang",
        "Junlan Feng",
        "Zhijian Ou"
      ],
      "abstract": "Recently, increasing research interests have focused on retrieval augmented\ngeneration (RAG) to mitigate hallucination for large language models (LLMs).\nFollowing this trend, we launch the FutureDial-RAG challenge at SLT 2024, which\naims at promoting the study of RAG for dialog systems. The challenge builds\nupon the MobileCS2 dataset, a real-life customer service datasets with nearly\n3000 high-quality dialogs containing annotations for knowledge base query and\ncorresponding results. Over the dataset, we define two tasks, track 1 for\nknowledge retrieval and track 2 for response generation, which are core\nresearch questions in dialog systems with RAG. We build baseline systems for\nthe two tracks and design metrics to measure whether the systems can perform\naccurate retrieval and generate informative and coherent response. The baseline\nresults show that it is very challenging to perform well on the two tasks,\nwhich encourages the participating teams and the community to study how to make\nbetter use of RAG for real-life dialog systems.",
      "tldr_zh": "该研究介绍了 FutureDial-RAG 挑战赛，这是 SLT 2024 的第二届比赛，旨在通过检索增强生成 (RAG) 技术缓解大型语言模型 (LLMs) 的幻觉问题，并推动其在对话系统中的应用。基于 MobileCS2 数据集，该挑战定义了两个核心任务：Track 1 专注于知识检索，Track 2 专注于响应生成，并提供了基线系统及评估指标来衡量检索准确性和响应信息性与连贯性。实验结果显示，基线系统在这些任务上表现具有挑战性，鼓励研究社区探索如何更好地利用 RAG 来提升真实对话系统的性能。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted by SLT 2024",
      "pdf_url": "http://arxiv.org/pdf/2405.13084v2",
      "published_date": "2024-05-21 07:35:21 UTC",
      "updated_date": "2024-09-15 15:03:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:14:55.022155"
    },
    {
      "arxiv_id": "2405.12543v2",
      "title": "Like Humans to Few-Shot Learning through Knowledge Permeation of Vision and Text",
      "title_zh": "翻译失败",
      "authors": [
        "Yuyu Jia",
        "Qing Zhou",
        "Wei Huang",
        "Junyu Gao",
        "Qi Wang"
      ],
      "abstract": "Few-shot learning aims to generalize the recognizer from seen categories to\nan entirely novel scenario. With only a few support samples, several advanced\nmethods initially introduce class names as prior knowledge for identifying\nnovel classes. However, obstacles still impede achieving a comprehensive\nunderstanding of how to harness the mutual advantages of visual and textual\nknowledge. In this paper, we propose a coherent Bidirectional Knowledge\nPermeation strategy called BiKop, which is grounded in a human intuition: A\nclass name description offers a general representation, whereas an image\ncaptures the specificity of individuals. BiKop primarily establishes a\nhierarchical joint general-specific representation through bidirectional\nknowledge permeation. On the other hand, considering the bias of joint\nrepresentation towards the base set, we disentangle base-class-relevant\nsemantics during training, thereby alleviating the suppression of potential\nnovel-class-relevant information. Experiments on four challenging benchmarks\ndemonstrate the remarkable superiority of BiKop. Our code will be publicly\navailable.",
      "tldr_zh": "本论文针对 Few-shot learning 的挑战，提出 BiKop（Bidirectional Knowledge Permeation）策略，模拟人类直觉通过类名提供一般表示和图像捕捉具体细节，实现视觉和文本知识的双向渗透。BiKop 建立层次化的联合一般-具体表示，并在训练中分离基础类相关语义，以缓解对新类信息的抑制。实验在四个挑战性基准上证明了 BiKop 的显著性能优势，代码将公开可用。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.12543v2",
      "published_date": "2024-05-21 07:18:26 UTC",
      "updated_date": "2024-05-22 14:08:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:15:06.940927"
    },
    {
      "arxiv_id": "2405.12541v1",
      "title": "DrHouse: An LLM-empowered Diagnostic Reasoning System through Harnessing Outcomes from Sensor Data and Expert Knowledge",
      "title_zh": "翻译失败",
      "authors": [
        "Bufang Yang",
        "Siyang Jiang",
        "Lilin Xu",
        "Kaiwei Liu",
        "Hai Li",
        "Guoliang Xing",
        "Hongkai Chen",
        "Xiaofan Jiang",
        "Zhenyu Yan"
      ],
      "abstract": "Large language models (LLMs) have the potential to transform digital\nhealthcare, as evidenced by recent advances in LLM-based virtual doctors.\nHowever, current approaches rely on patient's subjective descriptions of\nsymptoms, causing increased misdiagnosis. Recognizing the value of daily data\nfrom smart devices, we introduce a novel LLM-based multi-turn consultation\nvirtual doctor system, DrHouse, which incorporates three significant\ncontributions: 1) It utilizes sensor data from smart devices in the diagnosis\nprocess, enhancing accuracy and reliability. 2) DrHouse leverages continuously\nupdating medical databases such as Up-to-Date and PubMed to ensure our model\nremains at diagnostic standard's forefront. 3) DrHouse introduces a novel\ndiagnostic algorithm that concurrently evaluates potential diseases and their\nlikelihood, facilitating more nuanced and informed medical assessments. Through\nmulti-turn interactions, DrHouse determines the next steps, such as accessing\ndaily data from smart devices or requesting in-lab tests, and progressively\nrefines its diagnoses. Evaluations on three public datasets and our\nself-collected datasets show that DrHouse can achieve up to an 18.8% increase\nin diagnosis accuracy over the state-of-the-art baselines. The results of a\n32-participant user study show that 75% medical experts and 91.7% patients are\nwilling to use DrHouse.",
      "tldr_zh": "本研究提出DrHouse，一种基于LLM的诊断推理系统，通过整合智能设备传感器数据和专家知识，解决传统虚拟医生依赖患者主观症状导致误诊的问题。DrHouse的主要贡献包括：利用传感器数据提升诊断准确性和可靠性、接入Up-to-Date和PubMed等不断更新的医疗数据库保持前沿标准，以及引入新型诊断算法同时评估潜在疾病及其可能性。系统通过多轮交互动态决定下一步行动，如访问设备数据或要求实验室测试，以逐步优化诊断。实验结果显示，DrHouse在多个数据集上比现有方法提高诊断准确率高达18.8%，并在用户研究中获得75%的医疗专家和91.7%的患者认可。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.12541v1",
      "published_date": "2024-05-21 07:16:12 UTC",
      "updated_date": "2024-05-21 07:16:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:15:20.944944"
    },
    {
      "arxiv_id": "2405.13082v5",
      "title": "A Survey of Artificial Intelligence in Gait-Based Neurodegenerative Disease Diagnosis",
      "title_zh": "翻译失败",
      "authors": [
        "Haocong Rao",
        "Minlin Zeng",
        "Xuejiao Zhao",
        "Chunyan Miao"
      ],
      "abstract": "Recent years have witnessed an increasing global population affected by\nneurodegenerative diseases (NDs), which traditionally require extensive\nhealthcare resources and human effort for medical diagnosis and monitoring. As\na crucial disease-related motor symptom, human gait can be exploited to\ncharacterize different NDs. The current advances in artificial intelligence\n(AI) models enable automatic gait analysis for NDs identification and\nclassification, opening a new avenue to facilitate faster and more\ncost-effective diagnosis of NDs. In this paper, we provide a comprehensive\nsurvey on recent progress of machine learning and deep learning based AI\ntechniques applied to diagnosis of five typical NDs through gait. We provide an\noverview of the process of AI-assisted NDs diagnosis, and present a systematic\ntaxonomy of existing gait data and AI models. Meanwhile, a novel quality\nevaluation criterion is proposed to quantitatively assess the quality of\nexisting studies. Through an extensive review and analysis of 169 studies, we\npresent recent technical advancements, discuss existing challenges, potential\nsolutions, and future directions in this field. Finally, we envision the\nprospective utilization of 3D skeleton data for human gait representation and\nthe development of more efficient AI models for NDs diagnosis.",
      "tldr_zh": "这篇论文对人工智能（AI）在基于步态的神经退行性疾病（NDs）诊断中的应用进行了全面调查，强调了步态作为关键运动症状的作用，以及AI模型如何实现更快速和经济有效的诊断。作者概述了AI辅助NDs诊断的过程，系统分类了现有的步态数据和机器学习（machine learning）与深度学习（deep learning）模型，并提出了一种新颖的质量评估标准来量化相关研究的质量。通过分析169篇研究，论文总结了技术进展、现有挑战（如数据多样性和模型效率问题）、潜在解决方案，以及未来方向。最终，论文展望了利用3D skeleton data进行步态表示和开发更高效AI模型的前景，以提升NDs诊断的准确性和可及性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by Neurocomputing journal. Article: 57 pages, citing 290\n  papers. Appendix: 30 pages. A up-to-date resource (papers, data, etc.) of\n  this survey (AI4NDD) is provided at\n  https://github.com/minlinzeng/AI4NDD-Survey",
      "pdf_url": "http://arxiv.org/pdf/2405.13082v5",
      "published_date": "2024-05-21 06:44:40 UTC",
      "updated_date": "2025-02-06 13:34:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:15:32.780784"
    },
    {
      "arxiv_id": "2405.12523v3",
      "title": "Single Image Unlearning: Efficient Machine Unlearning in Multimodal Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Jiaqi Li",
        "Qianshan Wei",
        "Chuanyi Zhang",
        "Guilin Qi",
        "Miaozeng Du",
        "Yongrui Chen",
        "Sheng Bi",
        "Fan Liu"
      ],
      "abstract": "Machine unlearning empowers individuals with the `right to be forgotten' by\nremoving their private or sensitive information encoded in machine learning\nmodels. However, it remains uncertain whether MU can be effectively applied to\nMultimodal Large Language Models (MLLMs), particularly in scenarios of\nforgetting the leaked visual data of concepts. To overcome the challenge, we\npropose an efficient method, Single Image Unlearning (SIU), to unlearn the\nvisual recognition of a concept by fine-tuning a single associated image for\nfew steps. SIU consists of two key aspects: (i) Constructing Multifaceted\nfine-tuning data. We introduce four targets, based on which we construct\nfine-tuning data for the concepts to be forgotten; (ii) Jointly training loss.\nTo synchronously forget the visual recognition of concepts and preserve the\nutility of MLLMs, we fine-tune MLLMs through a novel Dual Masked KL-divergence\nLoss combined with Cross Entropy loss. Alongside our method, we establish\nMMUBench, a new benchmark for MU in MLLMs and introduce a collection of metrics\nfor its evaluation. Experimental results on MMUBench show that SIU completely\nsurpasses the performance of existing methods. Furthermore, we surprisingly\nfind that SIU can avoid invasive membership inference attacks and jailbreak\nattacks. To the best of our knowledge, we are the first to explore MU in MLLMs.\nWe will release the code and benchmark in the near future.",
      "tldr_zh": "这篇论文提出了 Single Image Unlearning (SIU)，一种高效的方法，用于在 Multimodal Large Language Models (MLLMs) 中实现 Machine Unlearning (MU)，以删除模型中特定概念的视觉识别信息。SIU 通过构建多方面微调数据（基于四个目标生成训练数据）和联合训练损失（结合 Dual Masked KL-divergence Loss 与 Cross Entropy loss）来同步忘记敏感视觉数据，同时保留模型的整体效用。研究者建立了新的基准 MMUBench 和相关评估指标，实验结果显示 SIU 显著优于现有方法，并能有效避免入侵性会员推断攻击和越狱攻击。该工作首次探索了 MU 在 MLLMs 中的应用，并计划发布代码和基准。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.12523v3",
      "published_date": "2024-05-21 06:27:12 UTC",
      "updated_date": "2025-03-28 04:13:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:15:45.344352"
    },
    {
      "arxiv_id": "2405.19347v3",
      "title": "Near-Field Spot Beamfocusing: A Correlation-Aware Transfer Learning Approach",
      "title_zh": "翻译失败",
      "authors": [
        "Mohammad Amir Fallah",
        "Mehdi Monemi",
        "Mehdi Rasti",
        "Matti Latva-Aho"
      ],
      "abstract": "Three-dimensional (3D) spot beamfocusing (SBF), in contrast to conventional\nangular-domain beamforming, concentrates radiating power within a very small\nvolume in both radial and angular domains in the near-field zone. Recently the\nimplementation of channel-state-information (CSI)-independent machine learning\n(ML)-based approaches have been developed for effective SBF using extremely\nlarge-scale programmable metasurface (ELPMs). These methods involve dividing\nthe ELPMs into subarrays and independently training them with Deep\nReinforcement Learning to jointly focus the beam at the desired focal point\n(DFP).\n  This paper explores near-field SBF using ELPMs, addressing challenges\nassociated with lengthy training times resulting from independent training of\nsubarrays. To achieve a faster CSI-independent solution, inspired by the\ncorrelation between the beamfocusing matrices of the subarrays, we leverage\ntransfer learning techniques. First, we introduce a novel similarity criterion\nbased on the phase distribution image (PDI) of subarray apertures. Then we\ndevise a subarray policy propagation scheme that transfers the knowledge from\ntrained to untrained subarrays. We further enhance learning by introducing\nquasi-liquid layers as a revised version of the adaptive policy reuse\ntechnique. We show through simulations that the proposed scheme improves the\ntraining speed about 5 times. Furthermore, for dynamic DFP management, we\ndevised a DFP policy blending process, which augments the convergence rate up\nto 8-fold.",
      "tldr_zh": "本研究提出了一种基于相关性的转移学习（Transfer Learning）方法，用于改进近场 Spot Beamfocusing (SBF)，以解决使用极大规模可编程超表面 (ELPMs) 时，子阵列独立训练导致的训练时间过长问题。方法包括引入基于相位分布图像 (PDI) 的新相似性标准，以及设计子阵列策略传播方案和 quasi-liquid layers 技术，来从训练过的子阵列向未训练的子阵列转移知识，从而加速整体学习过程。通过模拟实验，该方案将训练速度提高了约 5 倍；此外，针对动态 Desired Focal Point (DFP) 管理，开发的 DFP 策略混合过程进一步提升了收敛率高达 8 倍。总的来说，该方法为 CSI-independent 的 SBF 提供了更高效的 Deep Reinforcement Learning 框架。",
      "categories": [
        "eess.SP",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "eess.SP",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.19347v3",
      "published_date": "2024-05-21 06:27:07 UTC",
      "updated_date": "2024-12-16 05:56:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:15:58.451051"
    },
    {
      "arxiv_id": "2405.13081v1",
      "title": "Children's Mental Models of Generative Visual and Text Based AI Models",
      "title_zh": "翻译失败",
      "authors": [
        "Eliza Kosoy",
        "Soojin Jeong",
        "Anoop Sinha",
        "Alison Gopnik",
        "Tanya Kraljic"
      ],
      "abstract": "In this work we investigate how children ages 5-12 perceive, understand, and\nuse generative AI models such as a text-based LLMs ChatGPT and a visual-based\nmodel DALL-E. Generative AI is newly being used widely since chatGPT. Children\nare also building mental models of generative AI. Those haven't been studied\nbefore and it is also the case that the children's models are dynamic as they\nuse the tools, even with just very short usage. Upon surveying and\nexperimentally observing over 40 children ages 5-12, we found that children\ngenerally have a very positive outlook towards AI and are excited about the\nways AI may benefit and aid them in their everyday lives. In a forced choice,\nchildren robustly associated AI with positive adjectives versus negative ones.\nWe also categorize what children are querying AI models for and find that\nchildren search for more imaginative things that don't exist when using a\nvisual-based AI and not when using a text-based one. Our follow-up study\nmonitored children's responses and feelings towards AI before and after\ninteracting with GenAI models. We even find that children find AI to be less\nscary after interacting with it. We hope that these findings will shine a light\non children's mental models of AI and provide insight for how to design the\nbest possible tools for children who will inevitably be using AI in their\nlifetimes. The motivation of this work is to bridge the gap between\nHuman-Computer Interaction (HCI) and Psychology in an effort to study the\neffects of AI on society. We aim to identify the gaps in humans' mental models\nof what AI is and how it works. Previous work has investigated how both adults\nand children perceive various kinds of robots, computers, and other\ntechnological concepts. However, there is very little work investigating these\nconcepts for generative AI models and not simply embodied robots or physical\ntechnology.",
      "tldr_zh": "本研究调查了5-12岁儿童对生成式AI模型（如文本-based LLM ChatGPT和视觉-based DALL-E）的认知、理解和使用，通过对超过40名儿童的调查和实验观察来分析他们的心理模型。结果显示，儿童对AI持积极态度，更倾向于将AI与正面形容词关联，并在使用视觉-based AI时更频繁查询不存在的想象事物；此外，互动后儿童对AI的恐惧感显著减少。该工作桥接了Human-Computer Interaction (HCI)和心理学，旨在填补对生成式AI认知的研究空白，并为设计适合儿童的AI工具提供洞见。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "7 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2405.13081v1",
      "published_date": "2024-05-21 06:18:00 UTC",
      "updated_date": "2024-05-21 06:18:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:16:09.006836"
    },
    {
      "arxiv_id": "2405.12519v2",
      "title": "MAGE: Model-Level Graph Neural Networks Explanations via Motif-based Graph Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Zhaoning Yu",
        "Hongyang Gao"
      ],
      "abstract": "Graph Neural Networks (GNNs) have shown remarkable success in molecular\ntasks, yet their interpretability remains challenging. Traditional model-level\nexplanation methods like XGNN and GNNInterpreter often fail to identify valid\nsubstructures like rings, leading to questionable interpretability. This\nlimitation stems from XGNN's atom-by-atom approach and GNNInterpreter's\nreliance on average graph embeddings, which overlook the essential structural\nelements crucial for molecules. To address these gaps, we introduce an\ninnovative \\textbf{M}otif-b\\textbf{A}sed \\textbf{G}NN \\textbf{E}xplainer (MAGE)\nthat uses motifs as fundamental units for generating explanations. Our approach\nbegins with extracting potential motifs through a motif decomposition\ntechnique. Then, we utilize an attention-based learning method to identify\nclass-specific motifs. Finally, we employ a motif-based graph generator for\neach class to create molecular graph explanations based on these class-specific\nmotifs. This novel method not only incorporates critical substructures into the\nexplanations but also guarantees their validity, yielding results that are\nhuman-understandable. Our proposed method's effectiveness is demonstrated\nthrough quantitative and qualitative assessments conducted on six real-world\nmolecular datasets.",
      "tldr_zh": "该研究针对Graph Neural Networks (GNNs)在分子任务中的解释性挑战，指出传统方法如XGNN和GNNInterpreter无法有效识别关键子结构（如rings），导致解释结果不可靠。作者提出MAGE，一种基于motif的创新解释框架，包括通过motif decomposition提取潜在motifs、使用attention-based learning识别class-specific motifs，以及motif-based graph generator生成分子图解释，以确保解释的准确性和人类可理解性。在六个真实分子数据集上的定量和定性评估中，MAGE显著提升了GNNs的解释性能，证明了其有效性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "q-bio.QM"
      ],
      "primary_category": "cs.LG",
      "comment": "arXiv admin note: text overlap with arXiv:2405.08419 The Thirteenth\n  International Conference on Learning Representations 2025",
      "pdf_url": "http://arxiv.org/pdf/2405.12519v2",
      "published_date": "2024-05-21 06:12:24 UTC",
      "updated_date": "2025-04-24 06:35:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:16:20.957656"
    },
    {
      "arxiv_id": "2405.12514v4",
      "title": "Future You: A Conversation with an AI-Generated Future Self Reduces Anxiety, Negative Emotions, and Increases Future Self-Continuity",
      "title_zh": "Future You：与 AI 生成的未来自我对话减少焦虑、负面情绪",
      "authors": [
        "Pat Pataranutaporn",
        "Kavin Winson",
        "Peggy Yin",
        "Auttasak Lapapirojn",
        "Pichayoot Ouppaphan",
        "Monchai Lertsutthiwong",
        "Pattie Maes",
        "Hal Hershfield"
      ],
      "abstract": "We introduce \"Future You,\" an interactive, brief, single-session, digital\nchat intervention designed to improve future self-continuity--the degree of\nconnection an individual feels with a temporally distant future self--a\ncharacteristic that is positively related to mental health and wellbeing. Our\nsystem allows users to chat with a relatable yet AI-powered virtual version of\ntheir future selves that is tuned to their future goals and personal qualities.\nTo make the conversation realistic, the system generates a \"synthetic\nmemory\"--a unique backstory for each user--that creates a throughline between\nthe user's present age (between 18-30) and their life at age 60. The \"Future\nYou\" character also adopts the persona of an age-progressed image of the user's\npresent self. After a brief interaction with the \"Future You\" character, users\nreported decreased anxiety, and increased future self-continuity. This is the\nfirst study successfully demonstrating the use of personalized AI-generated\ncharacters to improve users' future self-continuity and wellbeing.",
      "tldr_zh": "本研究引入了“Future You”系统，这是一个互动式的单次数字聊天干预，旨在通过让用户与一个基于AI生成的虚拟未来自我对话，来提升未来自我连续性（future self-continuity），从而改善心理健康和福祉。该系统为每个用户创建独特的“synthetic memory”（合成记忆），连接其当前年龄（18-30岁）和60岁时的生活，并使用年龄进展图像使虚拟角色更具真实感。实验结果显示，用户在短暂互动后报告焦虑和负面情绪显著减少，同时未来自我连续性得到增强，这是首次成功利用个性化AI角色实现这一效果。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.12514v4",
      "published_date": "2024-05-21 06:00:51 UTC",
      "updated_date": "2024-10-01 09:00:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:16:33.089783"
    },
    {
      "arxiv_id": "2405.12512v1",
      "title": "Rethink Predicting the Optical Flow with the Kinetics Perspective",
      "title_zh": "翻译失败",
      "authors": [
        "Yuhao Cheng",
        "Siru Zhang",
        "Yiqiang Yan"
      ],
      "abstract": "Optical flow estimation is one of the fundamental tasks in low-level computer\nvision, which describes the pixel-wise displacement and can be used in many\nother tasks. From the apparent aspect, the optical flow can be viewed as the\ncorrelation between the pixels in consecutive frames, so continuously refining\nthe correlation volume can achieve an outstanding performance. However, it will\nmake the method have a catastrophic computational complexity. Not only that,\nthe error caused by the occlusion regions of the successive frames will be\namplified through the inaccurate warp operation. These challenges can not be\nsolved only from the apparent view, so this paper rethinks the optical flow\nestimation from the kinetics viewpoint.We propose a method combining the\napparent and kinetics information from this motivation. The proposed method\ndirectly predicts the optical flow from the feature extracted from images\ninstead of building the correlation volume, which will improve the efficiency\nof the whole network. Meanwhile, the proposed method involves a new\ndifferentiable warp operation that simultaneously considers the warping and\nocclusion. Moreover, the proposed method blends the kinetics feature with the\napparent feature through the novel self-supervised loss function. Furthermore,\ncomprehensive experiments and ablation studies prove that the proposed novel\ninsight into how to predict the optical flow can achieve the better performance\nof the state-of-the-art methods, and in some metrics, the proposed method\noutperforms the correlation-based method, especially in situations containing\nocclusion and fast moving. The code will be public.",
      "tldr_zh": "这篇论文从动力学（kinetics）视角重新审视光学流（optical flow）估计，旨在解决传统方法的高计算复杂度和遮挡区域错误放大问题。作者提出了一种结合表观（apparent）和动力学信息的创新方法，直接从图像特征预测光学流，而非构建相关性体积，从而提高网络效率，并引入新的可微分 warp operation 来同时处理 warping 和遮挡。实验结果表明，该方法在遮挡和快速移动场景中超越现有状态-of-the-art 方法，并在某些指标上表现出色，代码将公开。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.MM"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.12512v1",
      "published_date": "2024-05-21 05:47:42 UTC",
      "updated_date": "2024-05-21 05:47:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:16:45.026899"
    },
    {
      "arxiv_id": "2405.12502v3",
      "title": "EntropyStop: Unsupervised Deep Outlier Detection with Loss Entropy",
      "title_zh": "EntropyStop: 基于损失熵的无监督深度异常检测",
      "authors": [
        "Yihong Huang",
        "Yuang Zhang",
        "Liping Wang",
        "Fan Zhang",
        "Xuemin Lin"
      ],
      "abstract": "Unsupervised Outlier Detection (UOD) is an important data mining task. With\nthe advance of deep learning, deep Outlier Detection (OD) has received broad\ninterest. Most deep UOD models are trained exclusively on clean datasets to\nlearn the distribution of the normal data, which requires huge manual efforts\nto clean the real-world data if possible. Instead of relying on clean datasets,\nsome approaches directly train and detect on unlabeled contaminated datasets,\nleading to the need for methods that are robust to such conditions. Ensemble\nmethods emerged as a superior solution to enhance model robustness against\ncontaminated training sets. However, the training time is greatly increased by\nthe ensemble.\n  In this study, we investigate the impact of outliers on the training phase,\naiming to halt training on unlabeled contaminated datasets before performance\ndegradation. Initially, we noted that blending normal and anomalous data causes\nAUC fluctuations, a label-dependent measure of detection accuracy. To\ncircumvent the need for labels, we propose a zero-label entropy metric named\nLoss Entropy for loss distribution, enabling us to infer optimal stopping\npoints for training without labels. Meanwhile, we theoretically demonstrate\nnegative correlation between entropy metric and the label-based AUC. Based on\nthis, we develop an automated early-stopping algorithm, EntropyStop, which\nhalts training when loss entropy suggests the maximum model detection\ncapability. We conduct extensive experiments on ADBench (including 47 real\ndatasets), and the overall results indicate that AutoEncoder (AE) enhanced by\nour approach not only achieves better performance than ensemble AEs but also\nrequires under 2\\% of training time. Lastly, our proposed metric and\nearly-stopping approach are evaluated on other deep OD models, exhibiting their\nbroad potential applicability.",
      "tldr_zh": "本研究针对无监督异常检测(Unsupervised Outlier Detection, UOD)中的挑战，提出了一种基于损失熵(Loss Entropy)的自动早停算法EntropyStop，以解决现有深度OD模型在污染数据上训练时性能下降和训练时间过长的问题。研究发现，混合正常和异常数据会导致检测准确率(AUC)波动，因此通过理论证明损失熵与AUC呈负相关，并利用这一指标在无标签条件下推断最佳训练停止点。实验在ADBench（包括47个真实数据集）上显示，增强的AutoEncoder(AE)模型不仅比集成方法性能提升，还仅需不到2%的训练时间，这为鲁棒的深度OD模型提供了高效的适用框架。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.12502v3",
      "published_date": "2024-05-21 05:17:43 UTC",
      "updated_date": "2024-06-29 01:40:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:16:57.194383"
    },
    {
      "arxiv_id": "2405.12489v4",
      "title": "Exploring and Exploiting the Asymmetric Valley of Deep Neural Networks",
      "title_zh": "探索与利用深度神经网络的不对称谷",
      "authors": [
        "Xin-Chun Li",
        "Jin-Lin Tang",
        "Bo Zhang",
        "Lan Li",
        "De-Chuan Zhan"
      ],
      "abstract": "Exploring the loss landscape offers insights into the inherent principles of\ndeep neural networks (DNNs). Recent work suggests an additional asymmetry of\nthe valley beyond the flat and sharp ones, yet without thoroughly examining its\ncauses or implications. Our study methodically explores the factors affecting\nthe symmetry of DNN valleys, encompassing (1) the dataset, network\narchitecture, initialization, and hyperparameters that influence the\nconvergence point; and (2) the magnitude and direction of the noise for 1D\nvisualization. Our major observation shows that the {\\it degree of sign\nconsistency} between the noise and the convergence point is a critical\nindicator of valley symmetry. Theoretical insights from the aspects of ReLU\nactivation and softmax function could explain the interesting phenomenon. Our\ndiscovery propels novel understanding and applications in the scenario of Model\nFusion: (1) the efficacy of interpolating separate models significantly\ncorrelates with their sign consistency ratio, and (2) imposing sign alignment\nduring federated learning emerges as an innovative approach for model parameter\nalignment.",
      "tldr_zh": "本研究探索了深度神经网络(DNNs)损失景观中山谷的不对称性，通过系统分析数据集、网络架构、初始化、超参数以及噪声的大小和方向，揭示了噪声与收敛点之间的符号一致度(sign consistency)是山谷对称性的关键指标。理论上，该现象可从ReLU激活和softmax函数的角度进行解释。该发现的应用包括：在模型融合(Model Fusion)中，模型间的符号一致性比率与插值效力显著相关；以及在联邦学习(federated learning)中，通过强加符号对齐来创新性地对齐模型参数，从而提升模型性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2405.12489v4",
      "published_date": "2024-05-21 04:18:57 UTC",
      "updated_date": "2024-10-09 13:04:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:17:10.191213"
    },
    {
      "arxiv_id": "2405.12486v1",
      "title": "Time Matters: Enhancing Pre-trained News Recommendation Models with Robust User Dwell Time Injection",
      "title_zh": "翻译失败",
      "authors": [
        "Hao Jiang",
        "Chuanzhen Li",
        "Mingxiao An"
      ],
      "abstract": "Large Language Models (LLMs) have revolutionized text comprehension, leading\nto State-of-the-Art (SOTA) news recommendation models that utilize LLMs for\nin-depth news understanding. Despite this, accurately modeling user preferences\nremains challenging due to the inherent uncertainty of click behaviors.\nTechniques like multi-head attention in Transformers seek to alleviate this by\ncapturing interactions among clicks, yet they fall short in integrating\nexplicit feedback signals. User Dwell Time emerges as a powerful indicator,\noffering the potential to enhance the weak signals emanating from clicks.\nNonetheless, its real-world applicability is questionable, especially when\ndwell time data collection is subject to delays. To bridge this gap, this paper\nproposes two novel and robust dwell time injection strategies, namely Dwell\ntime Weight (DweW) and Dwell time Aware (DweA). Dwe} concentrates on refining\nEffective User Clicks through detailed analysis of dwell time, integrating with\ninitial behavioral inputs to construct a more robust user preference. DweA\nempowers the model with awareness of dwell time information, thereby\nfacilitating autonomous adjustment of attention values in user modeling. This\nenhancement sharpens the model's ability to accurately identify user\npreferences. In our experiment using the real-world news dataset from MSN\nwebsite, we validated that our two strategies significantly improve\nrecommendation performance, favoring high-quality news. Crucially, our\napproaches exhibit robustness to user dwell time information, maintaining their\nability to recommend high-quality content even in extreme cases where dwell\ntime data is entirely missing.",
      "tldr_zh": "这篇论文针对新闻推荐模型的挑战，提出通过注入用户停留时间 (Dwell Time) 来提升 Large Language Models (LLMs) 预训练模型的性能，以更好地捕捉用户偏好并减少点击行为的不确定性。作者开发了两种鲁棒策略：Dwell time Weight (DweW)，通过分析停留时间提炼有效用户点击并整合到用户偏好构建中；以及 Dwell time Aware (DweA)，使模型自主调整注意力值以增强用户建模的准确性。在 MSN 网站的真实数据集实验中，这两种策略显著提高了推荐性能，特别是针对高质量新闻，且即使停留时间数据缺失，模型仍保持鲁棒性。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "10 pages,5 figures",
      "pdf_url": "http://arxiv.org/pdf/2405.12486v1",
      "published_date": "2024-05-21 04:08:07 UTC",
      "updated_date": "2024-05-21 04:08:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:17:22.054992"
    },
    {
      "arxiv_id": "2405.12475v1",
      "title": "GASE: Graph Attention Sampling with Edges Fusion for Solving Vehicle Routing Problems",
      "title_zh": "翻译失败",
      "authors": [
        "Zhenwei Wang",
        "Ruibin Bai",
        "Fazlullah Khan",
        "Ender Ozcan",
        "Tiehua Zhang"
      ],
      "abstract": "Learning-based methods have become increasingly popular for solving vehicle\nrouting problems due to their near-optimal performance and fast inference\nspeed. Among them, the combination of deep reinforcement learning and graph\nrepresentation allows for the abstraction of node topology structures and\nfeatures in an encoder-decoder style. Such an approach makes it possible to\nsolve routing problems end-to-end without needing complicated heuristic\noperators designed by domain experts. Existing research studies have been\nfocusing on novel encoding and decoding structures via various neural network\nmodels to enhance the node embedding representation. Despite the sophisticated\napproaches applied, there is a noticeable lack of consideration for the\ngraph-theoretic properties inherent to routing problems. Moreover, the\npotential ramifications of inter-nodal interactions on the decision-making\nefficacy of the models have not been adequately explored. To bridge this gap,\nwe propose an adaptive Graph Attention Sampling with the Edges Fusion framework\n(GASE),where nodes' embedding is determined through attention calculation from\ncertain highly correlated neighbourhoods and edges, utilizing a filtered\nadjacency matrix. In detail, the selections of particular neighbours and\nadjacency edges are led by a multi-head attention mechanism, contributing\ndirectly to the message passing and node embedding in graph attention sampling\nnetworks. Furthermore, we incorporate an adaptive actor-critic algorithm with\npolicy improvements to expedite the training convergence. We then conduct\ncomprehensive experiments against baseline methods on learning-based VRP tasks\nfrom different perspectives. Our proposed model outperforms the existing\nmethods by 2.08\\%-6.23\\% and shows stronger generalization ability, achieving\nstate-of-the-art performance on randomly generated instances and real-world\ndatasets.",
      "tldr_zh": "这篇论文针对车辆路径问题 (Vehicle Routing Problems) 提出了一种新框架 GASE，即 Graph Attention Sampling with Edges Fusion，以解决现有学习方法忽略图论属性和节点间交互的问题。GASE 通过多头注意力机制从过滤的邻接矩阵中选择相关邻居和边，改进节点嵌入表示，并结合自适应 actor-critic 算法加速训练过程。实验结果显示，GASE 在各种 VRP 任务上比基线方法提高了 2.08%-6.23% 的性能，并展现出更强的泛化能力，在随机生成实例和真实数据集上达到了 state-of-the-art 水平。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "24 pages, 5figures, 4 tables",
      "pdf_url": "http://arxiv.org/pdf/2405.12475v1",
      "published_date": "2024-05-21 03:33:07 UTC",
      "updated_date": "2024-05-21 03:33:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:17:34.432924"
    },
    {
      "arxiv_id": "2405.12473v3",
      "title": "Learning Partially Aligned Item Representation for Cross-Domain Sequential Recommendation",
      "title_zh": "学习部分对齐的项目表示用于跨领域序列推荐",
      "authors": [
        "Mingjia Yin",
        "Hao Wang",
        "Wei Guo",
        "Yong Liu",
        "Zhi Li",
        "Sirui Zhao",
        "Zhen Wang",
        "Defu Lian",
        "Enhong Chen"
      ],
      "abstract": "Cross-domain sequential recommendation (CDSR) aims to uncover and transfer\nusers' sequential preferences across multiple recommendation domains. While\nsignificant endeavors have been made, they primarily concentrated on developing\nadvanced transfer modules and aligning user representations using\nself-supervised learning techniques. However, the problem of aligning item\nrepresentations has received limited attention, and misaligned item\nrepresentations can potentially lead to sub-optimal sequential modeling and\nuser representation alignment. To this end, we propose a model-agnostic\nframework called \\textbf{C}ross-domain item representation \\textbf{A}lignment\nfor \\textbf{C}ross-\\textbf{D}omain \\textbf{S}equential \\textbf{R}ecommendation\n(\\textbf{CA-CDSR}), which achieves sequence-aware generation and adaptively\npartial alignment for item representations. Specifically, we first develop a\nsequence-aware feature augmentation strategy, which captures both collaborative\nand sequential item correlations, thus facilitating holistic item\nrepresentation generation. Next, we conduct an empirical study to investigate\nthe partial representation alignment problem from a spectrum perspective. It\nmotivates us to devise an adaptive spectrum filter, achieving partial alignment\nadaptively. Furthermore, the aligned item representations can be fed into\ndifferent sequential encoders to obtain user representations. The entire\nframework is optimized in a multi-task learning paradigm with an annealing\nstrategy. Extensive experiments have demonstrated that CA-CDSR can surpass\nstate-of-the-art baselines by a significant margin and can effectively align\nitems in representation spaces to enhance performance.",
      "tldr_zh": "本论文针对跨域序列推荐（Cross-Domain Sequential Recommendation, CDSR）中物品表示对齐不足的问题，提出一个模型无关框架 CA-CDSR，以提升序列建模和用户表示对齐效果。具体而言，该框架采用序列感知特征增强策略（sequence-aware feature augmentation）捕捉协作和序列物品相关性生成全面物品表示，并通过自适应频谱过滤器（adaptive spectrum filter）实现自适应部分对齐，然后将对齐后的表示输入多任务学习范式中优化。实验结果表明，CA-CDSR 显著优于现有基线模型，提升了推荐性能，并在表示空间中有效对齐物品。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.12473v3",
      "published_date": "2024-05-21 03:25:32 UTC",
      "updated_date": "2024-08-21 06:31:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:17:45.739963"
    },
    {
      "arxiv_id": "2405.13077v2",
      "title": "GPT-4 Jailbreaks Itself with Near-Perfect Success Using Self-Explanation",
      "title_zh": "翻译失败",
      "authors": [
        "Govind Ramesh",
        "Yao Dou",
        "Wei Xu"
      ],
      "abstract": "Research on jailbreaking has been valuable for testing and understanding the\nsafety and security issues of large language models (LLMs). In this paper, we\nintroduce Iterative Refinement Induced Self-Jailbreak (IRIS), a novel approach\nthat leverages the reflective capabilities of LLMs for jailbreaking with only\nblack-box access. Unlike previous methods, IRIS simplifies the jailbreaking\nprocess by using a single model as both the attacker and target. This method\nfirst iteratively refines adversarial prompts through self-explanation, which\nis crucial for ensuring that even well-aligned LLMs obey adversarial\ninstructions. IRIS then rates and enhances the output given the refined prompt\nto increase its harmfulness. We find that IRIS achieves jailbreak success rates\nof 98% on GPT-4, 92% on GPT-4 Turbo, and 94% on Llama-3.1-70B in under 7\nqueries. It significantly outperforms prior approaches in automatic, black-box,\nand interpretable jailbreaking, while requiring substantially fewer queries,\nthereby establishing a new standard for interpretable jailbreaking methods.",
      "tldr_zh": "本研究提出了一种名为 IRIS（Iterative Refinement Induced Self-Jailbreak）的创新方法，利用大型语言模型（LLMs）的反射能力，通过自解释来实现高效的越狱（jailbreaking）。该方法仅需黑盒访问，便可迭代精炼对抗提示（adversarial prompts），让单一模型同时充当攻击者和目标，从而提升输出危害性并确保可解释性。实验结果显示，IRIS 在 GPT-4 上成功率达 98%、GPT-4 Turbo 为 92%、Llama-3.1-70B 为 94%，且只需少于 7 个查询，便显著超越现有方法，树立了可解释越狱的新标准。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CR",
      "comment": "Accepted to EMNLP 2024 Main Conference",
      "pdf_url": "http://arxiv.org/pdf/2405.13077v2",
      "published_date": "2024-05-21 03:16:35 UTC",
      "updated_date": "2024-10-15 22:50:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:17:57.353166"
    },
    {
      "arxiv_id": "2405.12463v1",
      "title": "Stochastic Learning of Computational Resource Usage as Graph Structured Multimarginal Schrödinger Bridge",
      "title_zh": "翻译失败",
      "authors": [
        "Georgiy A. Bondar",
        "Robert Gifford",
        "Linh Thi Xuan Phan",
        "Abhishek Halder"
      ],
      "abstract": "We propose to learn the time-varying stochastic computational resource usage\nof software as a graph structured Schr\\\"odinger bridge problem. In general,\nlearning the computational resource usage from data is challenging because\nresources such as the number of CPU instructions and the number of last level\ncache requests are both time-varying and statistically correlated. Our proposed\nmethod enables learning the joint time-varying stochasticity in computational\nresource usage from the measured profile snapshots in a nonparametric manner.\nThe method can be used to predict the most-likely time-varying distribution of\ncomputational resource availability at a desired time. We provide detailed\nalgorithms for stochastic learning in both single and multi-core cases, discuss\nthe convergence guarantees, computational complexities, and demonstrate their\npractical use in two case studies: a single-core nonlinear model predictive\ncontroller, and a synthetic multi-core software.",
      "tldr_zh": "本文提出了一种将软件计算资源使用（如 CPU instructions 和 last level cache requests）建模为图结构化的多边际 Schrödinger Bridge 的随机学习方法，以处理这些资源的时间变化和统计相关性。该方法采用非参数方式从测量数据快照中学习联合时间变化的随机性，并提供了单核和多核场景的详细算法，包括收敛保证和计算复杂性分析。实验结果显示，该方法能准确预测计算资源可用性的最可能分布，并在单核非线性模型预测控制器和多核软件案例中验证了其实际应用。",
      "categories": [
        "math.OC",
        "cs.AI",
        "cs.LG",
        "cs.SY",
        "eess.SY",
        "stat.ML"
      ],
      "primary_category": "math.OC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.12463v1",
      "published_date": "2024-05-21 02:39:45 UTC",
      "updated_date": "2024-05-21 02:39:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:18:09.359751"
    },
    {
      "arxiv_id": "2405.12462v4",
      "title": "Enhancing Transformer-based models for Long Sequence Time Series Forecasting via Structured Matrix",
      "title_zh": "翻译失败",
      "authors": [
        "Zhicheng Zhang",
        "Yong Wang",
        "Shaoqi Tan",
        "Bowei Xia",
        "Yujie Luo"
      ],
      "abstract": "Recently, Transformer-based models for long sequence time series forecasting\nhave demonstrated promising results. The self-attention mechanism as the core\ncomponent of these Transformer-based models exhibits great potential in\ncapturing various dependencies among data points. Despite these advancements,\nit has been a subject of concern to improve the efficiency of the\nself-attention mechanism. Unfortunately, current specific optimization methods\nare facing the challenges in applicability and scalability for the future\ndesign of long sequence time series forecasting models. Hence, in this article,\nwe propose a novel architectural framework that enhances Transformer-based\nmodels through the integration of Surrogate Attention Blocks (SAB) and\nSurrogate Feed-Forward Neural Network Blocks (SFB). The framework reduces both\ntime and space complexity by the replacement of the self-attention and\nfeed-forward layers with SAB and SFB while maintaining their expressive power\nand architectural advantages. The equivalence of this substitution is fully\ndemonstrated. The extensive experiments on 10 Transformer-based models across\nfive distinct time series tasks demonstrate an average performance improvement\nof 12.4%, alongside 61.3% reduction in parameter counts.",
      "tldr_zh": "该研究针对Transformer-based models在长序列时间序列预测中的效率问题，提出了一种新框架，通过整合Surrogate Attention Blocks (SAB)和Surrogate Feed-Forward Neural Network Blocks (SFB)来替换自注意力机制和前馈层，从而降低时间和空间复杂度，同时保持模型的表达能力和架构优势。作者证明了这种替换的等效性，以确保框架的适用性。实验结果显示，在10个Transformer-based模型和五种时间序列任务上，该框架实现了平均性能提升12.4%，并减少了61.3%的参数量。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.12462v4",
      "published_date": "2024-05-21 02:37:47 UTC",
      "updated_date": "2024-12-16 13:47:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:18:23.200922"
    },
    {
      "arxiv_id": "2405.12461v1",
      "title": "WorldAfford: Affordance Grounding based on Natural Language Instructions",
      "title_zh": "翻译失败",
      "authors": [
        "Changmao Chen",
        "Yuren Cong",
        "Zhen Kan"
      ],
      "abstract": "Affordance grounding aims to localize the interaction regions for the\nmanipulated objects in the scene image according to given instructions. A\ncritical challenge in affordance grounding is that the embodied agent should\nunderstand human instructions and analyze which tools in the environment can be\nused, as well as how to use these tools to accomplish the instructions. Most\nrecent works primarily supports simple action labels as input instructions for\nlocalizing affordance regions, failing to capture complex human objectives.\nMoreover, these approaches typically identify affordance regions of only a\nsingle object in object-centric images, ignoring the object context and\nstruggling to localize affordance regions of multiple objects in complex scenes\nfor practical applications. To address this concern, for the first time, we\nintroduce a new task of affordance grounding based on natural language\ninstructions, extending it from previously using simple labels for complex\nhuman instructions. For this new task, we propose a new framework, WorldAfford.\nWe design a novel Affordance Reasoning Chain-of-Thought Prompting to reason\nabout affordance knowledge from LLMs more precisely and logically.\nSubsequently, we use SAM and CLIP to localize the objects related to the\naffordance knowledge in the image. We identify the affordance regions of the\nobjects through an affordance region localization module. To benchmark this new\ntask and validate our framework, an affordance grounding dataset, LLMaFF, is\nconstructed. We conduct extensive experiments to verify that WorldAfford\nperforms state-of-the-art on both the previous AGD20K and the new LLMaFF\ndataset. In particular, WorldAfford can localize the affordance regions of\nmultiple objects and provide an alternative when objects in the environment\ncannot fully match the given instruction.",
      "tldr_zh": "该研究引入了一个新任务：基于自然语言指令的 Affordance Grounding，旨在根据人类指令定位场景中多个对象的交互区域，解决现有方法仅支持简单标签和单对象限制的问题。论文提出 WorldAfford 框架，利用 Affordance Reasoning Chain-of-Thought Prompting 从大型语言模型（LLMs）中精确推理 affordance 知识，并结合 SAM 和 CLIP 定位相关对象，以及一个 affordance 区域定位模块来识别交互区域。为此，构建了新的 LLMaFF 数据集，实验结果显示 WorldAfford 在 AGD20K 和 LLMaFF 数据集上达到 state-of-the-art 性能，能够处理多个对象并应对指令不完全匹配的情况。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.12461v1",
      "published_date": "2024-05-21 02:37:45 UTC",
      "updated_date": "2024-05-21 02:37:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:18:34.031663"
    },
    {
      "arxiv_id": "2405.12458v1",
      "title": "Studying Up Public Sector AI: How Networks of Power Relations Shape Agency Decisions Around AI Design and Use",
      "title_zh": "翻译失败",
      "authors": [
        "Anna Kawakami",
        "Amanda Coston",
        "Hoda Heidari",
        "Kenneth Holstein",
        "Haiyi Zhu"
      ],
      "abstract": "As public sector agencies rapidly introduce new AI tools in high-stakes\ndomains like social services, it becomes critical to understand how decisions\nto adopt these tools are made in practice. We borrow from the anthropological\npractice to ``study up'' those in positions of power, and reorient our study of\npublic sector AI around those who have the power and responsibility to make\ndecisions about the role that AI tools will play in their agency. Through\nsemi-structured interviews and design activities with 16 agency\ndecision-makers, we examine how decisions about AI design and adoption are\ninfluenced by their interactions with and assumptions about other actors within\nthese agencies (e.g., frontline workers and agency leaders), as well as those\nabove (legal systems and contracted companies), and below (impacted\ncommunities). By centering these networks of power relations, our findings shed\nlight on how infrastructural, legal, and social factors create barriers and\ndisincentives to the involvement of a broader range of stakeholders in\ndecisions about AI design and adoption. Agency decision-makers desired more\npractical support for stakeholder involvement around public sector AI to help\novercome the knowledge and power differentials they perceived between them and\nother stakeholders (e.g., frontline workers and impacted community members).\nBuilding on these findings, we discuss implications for future research and\npolicy around actualizing participatory AI approaches in public sector\ncontexts.",
      "tldr_zh": "本研究考察了权力关系网络如何影响公共部门机构在 AI 设计和采用方面的决策，特别关注高风险领域如社会服务。研究者通过对 16 名机构决策者的半结构化访谈和设计活动，分析了这些决策如何受内部（如前线工人和领导者）和外部（如法律系统、承包公司和受影响社区）互动的影响。发现显示，基础设施、法律和社会因素造成了更广泛利益相关者参与的障碍和消极激励，导致知识和权力差异。最终，该研究为未来研究和政策提供启示，以推动公共部门中的参与式 AI 参与式 AI 方法的实际应用。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.12458v1",
      "published_date": "2024-05-21 02:31:26 UTC",
      "updated_date": "2024-05-21 02:31:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:18:45.298313"
    },
    {
      "arxiv_id": "2405.12452v2",
      "title": "Prompt-Based Spatio-Temporal Graph Transfer Learning",
      "title_zh": "基于提示的时空图迁移学习",
      "authors": [
        "Junfeng Hu",
        "Xu Liu",
        "Zhencheng Fan",
        "Yifang Yin",
        "Shili Xiang",
        "Savitha Ramasamy",
        "Roger Zimmermann"
      ],
      "abstract": "Spatio-temporal graph neural networks have proven efficacy in capturing\ncomplex dependencies for urban computing tasks such as forecasting and kriging.\nYet, their performance is constrained by the reliance on extensive data for\ntraining on a specific task, thereby limiting their adaptability to new urban\ndomains with varied task demands. Although transfer learning has been proposed\nto remedy this problem by leveraging knowledge across domains, the cross-task\ngeneralization still remains under-explored in spatio-temporal graph transfer\nlearning due to the lack of a unified framework. To bridge the gap, we propose\nSpatio-Temporal Graph Prompting (STGP), a prompt-based framework capable of\nadapting to multi-diverse tasks in a data-scarce domain. Specifically, we first\nunify different tasks into a single template and introduce a task-agnostic\nnetwork architecture that aligns with this template. This approach enables\ncapturing dependencies shared across tasks. Furthermore, we employ learnable\nprompts to achieve domain and task transfer in a two-stage prompting pipeline,\nfacilitating the prompts to effectively capture domain knowledge and\ntask-specific properties. Our extensive experiments demonstrate that STGP\noutperforms state-of-the-art baselines in three tasks-forecasting, kriging, and\nextrapolation-achieving an improvement of up to 10.7%.",
      "tldr_zh": "该研究针对空间-时间图神经网络（Spatio-Temporal Graph Neural Networks）在城市计算任务（如预测和克里金插值）中的数据依赖问题，提出了一种基于提示的转移学习框架Spatio-Temporal Graph Prompting (STGP)。STGP将不同任务统一到一个模板，使用任务无关的网络架构捕捉跨任务共享依赖，并通过两阶段可学习prompts实现域和任务转移，从而在数据稀缺场景下提升适应性。实验结果显示，STGP在预测、克里金和外推三个任务上比最先进基线提高了高达10.7%的性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.12452v2",
      "published_date": "2024-05-21 02:06:40 UTC",
      "updated_date": "2024-11-07 06:41:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:18:57.536175"
    },
    {
      "arxiv_id": "2405.12450v2",
      "title": "PathOCL: Path-Based Prompt Augmentation for OCL Generation with GPT-4",
      "title_zh": "翻译失败",
      "authors": [
        "Seif Abukhalaf",
        "Mohammad Hamdaqa",
        "Foutse Khomh"
      ],
      "abstract": "The rapid progress of AI-powered programming assistants, such as GitHub\nCopilot, has facilitated the development of software applications. These\nassistants rely on large language models (LLMs), which are foundation models\n(FMs) that support a wide range of tasks related to understanding and\ngenerating language. LLMs have demonstrated their ability to express UML model\nspecifications using formal languages like the Object Constraint Language\n(OCL). However, the context size of the prompt is limited by the number of\ntokens an LLM can process. This limitation becomes significant as the size of\nUML class models increases. In this study, we introduce PathOCL, a novel\npath-based prompt augmentation technique designed to facilitate OCL generation.\nPathOCL addresses the limitations of LLMs, specifically their token processing\nlimit and the challenges posed by large UML class models. PathOCL is based on\nthe concept of chunking, which selectively augments the prompts with a subset\nof UML classes relevant to the English specification. Our findings demonstrate\nthat PathOCL, compared to augmenting the complete UML class model\n(UML-Augmentation), generates a higher number of valid and correct OCL\nconstraints using the GPT-4 model. Moreover, the average prompt size crafted\nusing PathOCL significantly decreases when scaling the size of the UML class\nmodels.",
      "tldr_zh": "该论文介绍了 PathOCL，一种基于路径的提示增强技术，旨在使用 GPT-4 生成 Object Constraint Language (OCL) 约束，以解决大型语言模型 (LLMs) 在处理 UML 类模型时面临的 token 处理限制问题。PathOCL 通过 chunking 方法选择性地添加与英语规范相关的 UML 类子集，从而优化提示内容。实验结果表明，与直接增强完整 UML 模型相比，PathOCL 生成的 OCL 约束数量更多且准确性更高，同时显著减少了提示大小。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "Updated affiliations. This paper has been accepted to be published in\n  the 2024 IEEE/ACM First International Conference on AI Foundation Models and\n  Software Engineering (Forge)",
      "pdf_url": "http://arxiv.org/pdf/2405.12450v2",
      "published_date": "2024-05-21 02:00:54 UTC",
      "updated_date": "2024-06-06 23:10:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:19:09.499825"
    },
    {
      "arxiv_id": "2405.12442v1",
      "title": "Learning Structure and Knowledge Aware Representation with Large Language Models for Concept Recommendation",
      "title_zh": "利用大型语言模型学习结构和知识感知表示以用于概念推荐",
      "authors": [
        "Qingyao Li",
        "Wei Xia",
        "Kounianhua Du",
        "Qiji Zhang",
        "Weinan Zhang",
        "Ruiming Tang",
        "Yong Yu"
      ],
      "abstract": "Concept recommendation aims to suggest the next concept for learners to study\nbased on their knowledge states and the human knowledge system. While knowledge\nstates can be predicted using knowledge tracing models, previous approaches\nhave not effectively integrated the human knowledge system into the process of\ndesigning these educational models. In the era of rapidly evolving Large\nLanguage Models (LLMs), many fields have begun using LLMs to generate and\nencode text, introducing external knowledge. However, integrating LLMs into\nconcept recommendation presents two urgent challenges: 1) How to construct text\nfor concepts that effectively incorporate the human knowledge system? 2) How to\nadapt non-smooth, anisotropic text encodings effectively for concept\nrecommendation? In this paper, we propose a novel Structure and Knowledge Aware\nRepresentation learning framework for concept Recommendation (SKarREC). We\nleverage factual knowledge from LLMs as well as the precedence and succession\nrelationships between concepts obtained from the knowledge graph to construct\ntextual representations of concepts. Furthermore, we propose a graph-based\nadapter to adapt anisotropic text embeddings to the concept recommendation\ntask. This adapter is pre-trained through contrastive learning on the knowledge\ngraph to get a smooth and structure-aware concept representation. Then, it's\nfine-tuned through the recommendation task, forming a\ntext-to-knowledge-to-recommendation adaptation pipeline, which effectively\nconstructs a structure and knowledge-aware concept representation. Our method\ndoes a better job than previous adapters in transforming text encodings for\napplication in concept recommendation. Extensive experiments on real-world\ndatasets demonstrate the effectiveness of the proposed approach.",
      "tldr_zh": "本文提出SKarREC框架，利用Large Language Models (LLMs) 和知识图谱中的概念关系（如precedence and succession），构建结构和知识感知的概念文本表示，以解决概念推荐中整合人类知识系统和适应各向异性文本编码的挑战。框架引入一个基于图的适配器，通过对比学习预训练并微调，将文本嵌入转化为平滑、结构感知的表示，形成text-to-knowledge-to-recommendation的适应管道。实验在真实数据集上证明，该方法比现有适配器更有效，提升了概念推荐的准确性和性能。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "11 pages, 8 figures",
      "pdf_url": "http://arxiv.org/pdf/2405.12442v1",
      "published_date": "2024-05-21 01:35:36 UTC",
      "updated_date": "2024-05-21 01:35:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:19:22.519722"
    },
    {
      "arxiv_id": "2405.12438v1",
      "title": "CoCo Matrix: Taxonomy of Cognitive Contributions in Co-writing with Intelligent Agents",
      "title_zh": "翻译失败",
      "authors": [
        "Ruyuan Wan",
        "Simret Gebreegziabhe",
        "Toby Jia-Jun Li",
        "Karla Badillo-Urquiola"
      ],
      "abstract": "In recent years, there has been a growing interest in employing intelligent\nagents in writing. Previous work emphasizes the evaluation of the quality of\nend product-whether it was coherent and polished, overlooking the journey that\nled to the product, which is an invaluable dimension of the creative process.\nTo understand how to recognize human efforts in co-writing with intelligent\nwriting systems, we adapt Flower and Hayes' cognitive process theory of writing\nand propose CoCo Matrix, a two-dimensional taxonomy of entropy and information\ngain, to depict the new human-agent co-writing model. We define four quadrants\nand situate thirty-four published systems within the taxonomy. Our research\nfound that low entropy and high information gain systems are under-explored,\nyet offer promising future directions in writing tasks that benefit from the\nagent's divergent planning and the human's focused translation. CoCo Matrix,\nnot only categorizes different writing systems but also deepens our\nunderstanding of the cognitive processes in human-agent co-writing. By\nanalyzing minimal changes in the writing process, CoCo Matrix serves as a proxy\nfor the writer's mental model, allowing writers to reflect on their\ncontributions. This reflection is facilitated through the measured metrics of\ninformation gain and entropy, which provide insights irrespective of the\nwriting system used.",
      "tldr_zh": "本文提出CoCo Matrix，这是一个二维分类法（基于熵和信息增益），用于分析人类与智能代理在协同写作中的认知贡献，适应了Flower和Hayes的认知过程写作理论。研究将34个已发表的写作系统分类到四个象限中，发现低熵和高信息增益的系统尚未充分探索，但具有潜力，能通过代理的发散规划和人类的专注翻译提升写作任务。CoCo Matrix不仅有助于分类写作系统，还通过信息增益和熵指标，帮助作家反思其在过程中的努力和心理模型。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.12438v1",
      "published_date": "2024-05-21 01:31:17 UTC",
      "updated_date": "2024-05-21 01:31:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:19:35.303018"
    },
    {
      "arxiv_id": "2405.12433v3",
      "title": "LLM+Reasoning+Planning for Supporting Incomplete User Queries in Presence of APIs",
      "title_zh": "翻译失败",
      "authors": [
        "Sudhir Agarwal",
        "Anu Sreepathy",
        "David H. Alonso",
        "Prarit Lamba"
      ],
      "abstract": "Recent availability of Large Language Models (LLMs) has led to the\ndevelopment of numerous LLM-based approaches aimed at providing natural\nlanguage interfaces for various end-user tasks. These end-user tasks in turn\ncan typically be accomplished by orchestrating a given set of APIs. In\npractice, natural language task requests (user queries) are often incomplete,\ni.e., they may not contain all the information required by the APIs. While LLMs\nexcel at natural language processing (NLP) tasks, they frequently hallucinate\non missing information or struggle with orchestrating the APIs. The key idea\nbehind our proposed approach is to leverage logical reasoning and classical AI\nplanning along with an LLM for accurately answering user queries including\nidentification and gathering of any missing information in these queries. Our\napproach uses an LLM and ASP (Answer Set Programming) solver to translate a\nuser query to a representation in Planning Domain Definition Language (PDDL)\nvia an intermediate representation in ASP. We introduce a special API\n\"get_info_api\" for gathering missing information. We model all the APIs as PDDL\nactions in a way that supports dataflow between the APIs. Our approach then\nuses a classical AI planner to generate an orchestration of API calls\n(including calls to get_info_api) to answer the user query. Our evaluation\nresults show that our approach significantly outperforms a pure LLM based\napproach by achieving over 95% success rate in most cases on a dataset\ncontaining complete and incomplete single goal and multi-goal queries where the\nmulti-goal queries may or may not require dataflow among the APIs.",
      "tldr_zh": "这篇论文提出了一种整合大型语言模型 (LLMs)、逻辑推理和经典 AI 规划的方法，用于处理存在 APIs 的不完整用户查询。方法通过 LLMs 和 Answer Set Programming (ASP) 将用户查询转化为 Planning Domain Definition Language (PDDL) 表示，并引入特殊的 \"get_info_api\" 来识别和收集缺失信息，同时将所有 APIs 建模为支持数据流的 PDDL 动作。接着，使用经典 AI 规划器生成 API 调用序列，以准确编排任务。实验结果表明，该方法在包含单目标和多目标查询的数据集上，成功率超过 95%，显著优于纯 LLMs 方案。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "In Proceedings ICLP 2024, arXiv:2502.08453",
      "pdf_url": "http://arxiv.org/pdf/2405.12433v3",
      "published_date": "2024-05-21 01:16:34 UTC",
      "updated_date": "2025-02-13 11:48:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:19:45.487757"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 98,
  "processed_papers_count": 98,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-18T10:20:07.869762"
}