[
  {
    "arxiv_id": "2505.06300v1",
    "title": "ARDNS-FN-Quantum: A Quantum-Enhanced Reinforcement Learning Framework with Cognitive-Inspired Adaptive Exploration for Dynamic Environments",
    "authors": [
      "Umberto Gonçalves de Sousa"
    ],
    "abstract": "Reinforcement learning (RL) has transformed sequential decision making, yet\ntraditional algorithms like Deep Q-Networks (DQNs) and Proximal Policy\nOptimization (PPO) often struggle with efficient exploration, stability, and\nadaptability in dynamic environments. This study presents ARDNS-FN-Quantum\n(Adaptive Reward-Driven Neural Simulator with Quantum enhancement), a novel\nframework that integrates a 2-qubit quantum circuit for action selection, a\ndual-memory system inspired by human cognition, and adaptive exploration\nstrategies modulated by reward variance and curiosity. Evaluated in a 10X10\ngrid-world over 20,000 episodes, ARDNS-FN-Quantum achieves a 99.5% success rate\n(versus 81.3% for DQN and 97.0% for PPO), a mean reward of 9.0528 across all\nepisodes (versus 1.2941 for DQN and 7.6196 for PPO), and an average of 46.7\nsteps to goal (versus 135.9 for DQN and 62.5 for PPO). In the last 100\nepisodes, it records a mean reward of 9.1652 (versus 7.0916 for DQN and 9.0310\nfor PPO) and 37.2 steps to goal (versus 52.7 for DQN and 53.4 for PPO).\nGraphical analyses, including learning curves, steps-to-goal trends, reward\nvariance, and reward distributions, demonstrate ARDNS-FN-Quantum's superior\nstability (reward variance 5.424 across all episodes versus 252.262 for DQN and\n76.583 for PPO) and efficiency. By bridging quantum computing, cognitive\nscience, and RL, ARDNS-FN-Quantum offers a scalable, human-like approach to\nadaptive learning in uncertain environments, with potential applications in\nrobotics, autonomous systems, and decision-making under uncertainty.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "19 pages, 7 figures",
    "pdf_url": "http://arxiv.org/pdf/2505.06300v1",
    "published_date": "2025-05-07 23:48:41 UTC",
    "updated_date": "2025-05-07 23:48:41 UTC"
  },
  {
    "arxiv_id": "2505.04852v2",
    "title": "PR2: Peephole Raw Pointer Rewriting with LLMs for Translating C to Safer Rust",
    "authors": [
      "Yifei Gao",
      "Chengpeng Wang",
      "Pengxiang Huang",
      "Xuwei Liu",
      "Mingwei Zheng",
      "Xiangyu Zhang"
    ],
    "abstract": "There has been a growing interest in translating C code to Rust due to Rust's\nrobust memory and thread safety guarantees. Tools such as C2RUST enable\nsyntax-guided transpilation from C to semantically equivalent Rust code.\nHowever, the resulting Rust programs often rely heavily on unsafe\nconstructs--particularly raw pointers--which undermines Rust's safety\nguarantees. This paper aims to improve the memory safety of Rust programs\ngenerated by C2RUST by eliminating raw pointers. Specifically, we propose a\npeephole raw pointer rewriting technique that lifts raw pointers in individual\nfunctions to appropriate Rust data structures. Technically, PR2 employs\ndecision-tree-based prompting to guide the pointer lifting process.\nAdditionally, it leverages code change analysis to guide the repair of errors\nintroduced during rewriting, effectively addressing errors encountered during\ncompilation and test case execution. We implement PR2 as a prototype and\nevaluate it using gpt-4o-mini on 28 real-world C projects. The results show\nthat PR2 successfully eliminates 13.22% of local raw pointers across these\nprojects, significantly enhancing the safety of the translated Rust code. On\naverage, PR2 completes the transformation of a project in 5.44 hours, at an\naverage cost of $1.46.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.PL"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.04852v2",
    "published_date": "2025-05-07 23:30:27 UTC",
    "updated_date": "2025-05-09 06:32:08 UTC"
  },
  {
    "arxiv_id": "2505.04851v1",
    "title": "CRAFT: Cultural Russian-Oriented Dataset Adaptation for Focused Text-to-Image Generation",
    "authors": [
      "Viacheslav Vasilev",
      "Vladimir Arkhipkin",
      "Julia Agafonova",
      "Tatiana Nikulina",
      "Evelina Mironova",
      "Alisa Shichanina",
      "Nikolai Gerasimenko",
      "Mikhail Shoytov",
      "Denis Dimitrov"
    ],
    "abstract": "Despite the fact that popular text-to-image generation models cope well with\ninternational and general cultural queries, they have a significant knowledge\ngap regarding individual cultures. This is due to the content of existing large\ntraining datasets collected on the Internet, which are predominantly based on\nWestern European or American popular culture. Meanwhile, the lack of cultural\nadaptation of the model can lead to incorrect results, a decrease in the\ngeneration quality, and the spread of stereotypes and offensive content. In an\neffort to address this issue, we examine the concept of cultural code and\nrecognize the critical importance of its understanding by modern image\ngeneration models, an issue that has not been sufficiently addressed in the\nresearch community to date. We propose the methodology for collecting and\nprocessing the data necessary to form a dataset based on the cultural code, in\nparticular the Russian one. We explore how the collected data affects the\nquality of generations in the national domain and analyze the effectiveness of\nour approach using the Kandinsky 3.1 text-to-image model. Human evaluation\nresults demonstrate an increase in the level of awareness of Russian culture in\nthe model.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.CV",
      "cs.CY",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "This is arxiv version of the paper which was accepted for the Doklady\n  Mathematics Journal in 2024",
    "pdf_url": "http://arxiv.org/pdf/2505.04851v1",
    "published_date": "2025-05-07 23:29:28 UTC",
    "updated_date": "2025-05-07 23:29:28 UTC"
  },
  {
    "arxiv_id": "2505.04847v1",
    "title": "Benchmarking LLM Faithfulness in RAG with Evolving Leaderboards",
    "authors": [
      "Manveer Singh Tamber",
      "Forrest Sheng Bao",
      "Chenyu Xu",
      "Ge Luo",
      "Suleman Kazi",
      "Minseok Bae",
      "Miaoran Li",
      "Ofer Mendelevitch",
      "Renyi Qu",
      "Jimmy Lin"
    ],
    "abstract": "Hallucinations remain a persistent challenge for LLMs. RAG aims to reduce\nhallucinations by grounding responses in contexts. However, even when provided\ncontext, LLMs still frequently introduce unsupported information or\ncontradictions. This paper presents our efforts to measure LLM hallucinations\nwith a focus on summarization tasks, assessing how often various LLMs introduce\nhallucinations when summarizing documents. We discuss Vectara's existing LLM\nhallucination leaderboard, based on the Hughes Hallucination Evaluation Model\n(HHEM). While HHEM and Vectara's Hallucination Leaderboard have garnered great\nresearch interest, we examine challenges faced by HHEM and current\nhallucination detection methods by analyzing the effectiveness of these methods\non existing hallucination datasets. To address these limitations, we propose\nFaithJudge, an LLM-as-a-judge approach guided by few-shot human hallucination\nannotations, which substantially improves automated LLM hallucination\nevaluation over current methods. We introduce an enhanced hallucination\nleaderboard centered on FaithJudge, alongside our current hallucination\nleaderboard, enabling more reliable benchmarking of LLMs for hallucinations in\nRAG.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.04847v1",
    "published_date": "2025-05-07 22:50:33 UTC",
    "updated_date": "2025-05-07 22:50:33 UTC"
  },
  {
    "arxiv_id": "2505.13466v1",
    "title": "AgentSGEN: Multi-Agent LLM in the Loop for Semantic Collaboration and GENeration of Synthetic Data",
    "authors": [
      "Vu Dinh Xuan",
      "Hao Vo",
      "David Murphy",
      "Hoang D. Nguyen"
    ],
    "abstract": "The scarcity of data depicting dangerous situations presents a major obstacle\nto training AI systems for safety-critical applications, such as construction\nsafety, where ethical and logistical barriers hinder real-world data\ncollection. This creates an urgent need for an end-to-end framework to generate\nsynthetic data that can bridge this gap. While existing methods can produce\nsynthetic scenes, they often lack the semantic depth required for scene\nsimulations, limiting their effectiveness. To address this, we propose a novel\nmulti-agent framework that employs an iterative, in-the-loop collaboration\nbetween two agents: an Evaluator Agent, acting as an LLM-based judge to enforce\nsemantic consistency and safety-specific constraints, and an Editor Agent,\nwhich generates and refines scenes based on this guidance. Powered by LLM's\ncapabilities to reasoning and common-sense knowledge, this collaborative design\nproduces synthetic images tailored to safety-critical scenarios. Our\nexperiments suggest this design can generate useful scenes based on realistic\nspecifications that address the shortcomings of prior approaches, balancing\nsafety requirements with visual semantics. This iterative process holds promise\nfor delivering robust, aesthetically sound simulations, offering a potential\nsolution to the data scarcity challenge in multimedia safety applications.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.13466v1",
    "published_date": "2025-05-07 22:43:33 UTC",
    "updated_date": "2025-05-07 22:43:33 UTC"
  },
  {
    "arxiv_id": "2505.04843v1",
    "title": "Large Language Models are Autonomous Cyber Defenders",
    "authors": [
      "Sebastián R. Castro",
      "Roberto Campbell",
      "Nancy Lau",
      "Octavio Villalobos",
      "Jiaqi Duan",
      "Alvaro A. Cardenas"
    ],
    "abstract": "Fast and effective incident response is essential to prevent adversarial\ncyberattacks. Autonomous Cyber Defense (ACD) aims to automate incident response\nthrough Artificial Intelligence (AI) agents that plan and execute actions. Most\nACD approaches focus on single-agent scenarios and leverage Reinforcement\nLearning (RL). However, ACD RL-trained agents depend on costly training, and\ntheir reasoning is not always explainable or transferable. Large Language\nModels (LLMs) can address these concerns by providing explainable actions in\ngeneral security contexts. Researchers have explored LLM agents for ACD but\nhave not evaluated them on multi-agent scenarios or interacting with other ACD\nagents. In this paper, we show the first study on how LLMs perform in\nmulti-agent ACD environments by proposing a new integration to the CybORG CAGE\n4 environment. We examine how ACD teams of LLM and RL agents can interact by\nproposing a novel communication protocol. Our results highlight the strengths\nand weaknesses of LLMs and RL and help us identify promising research\ndirections to create, train, and deploy future teams of ACD agents.",
    "categories": [
      "cs.AI",
      "cs.CR",
      "I.2.0"
    ],
    "primary_category": "cs.AI",
    "comment": "Presented at IEEE CAI Workshop on Adaptive Cyber Defense 2025.\n  Proceedings to appear",
    "pdf_url": "http://arxiv.org/pdf/2505.04843v1",
    "published_date": "2025-05-07 22:42:37 UTC",
    "updated_date": "2025-05-07 22:42:37 UTC"
  },
  {
    "arxiv_id": "2505.04842v1",
    "title": "Putting the Value Back in RL: Better Test-Time Scaling by Unifying LLM Reasoners With Verifiers",
    "authors": [
      "Kusha Sareen",
      "Morgane M Moss",
      "Alessandro Sordoni",
      "Rishabh Agarwal",
      "Arian Hosseini"
    ],
    "abstract": "Prevalent reinforcement learning~(RL) methods for fine-tuning LLM reasoners,\nsuch as GRPO or Leave-one-out PPO, abandon the learned value function in favor\nof empirically estimated returns. This hinders test-time compute scaling that\nrelies on using the value-function for verification. In this work, we propose\nRL$^V$ that augments any ``value-free'' RL method by jointly training the LLM\nas both a reasoner and a generative verifier using RL-generated data, adding\nverification capabilities without significant overhead. Empirically, RL$^V$\nboosts MATH accuracy by over 20\\% with parallel sampling and enables\n$8-32\\times$ efficient test-time compute scaling compared to the base RL\nmethod. RL$^V$ also exhibits strong generalization capabilities for both\neasy-to-hard and out-of-domain tasks. Furthermore, RL$^V$ achieves\n$1.2-1.6\\times$ higher performance when jointly scaling parallel and sequential\ntest-time compute with a long reasoning R1 model.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.04842v1",
    "published_date": "2025-05-07 22:41:26 UTC",
    "updated_date": "2025-05-07 22:41:26 UTC"
  },
  {
    "arxiv_id": "2505.04841v2",
    "title": "Quantum-Inspired Optimization Process for Data Imputation",
    "authors": [
      "Nishikanta Mohanty",
      "Bikash K. Behera",
      "Badshah Mukherjee",
      "Christopher Ferrie"
    ],
    "abstract": "Data imputation is a critical step in data pre-processing, particularly for\ndatasets with missing or unreliable values. This study introduces a novel\nquantum-inspired imputation framework evaluated on the UCI Diabetes dataset,\nwhich contains biologically implausible missing values across several clinical\nfeatures. The method integrates Principal Component Analysis (PCA) with\nquantum-assisted rotations, optimized through gradient-free classical\noptimizers -COBYLA, Simulated Annealing, and Differential Evolution to\nreconstruct missing values while preserving statistical fidelity. Reconstructed\nvalues are constrained within +/-2 standard deviations of original feature\ndistributions, avoiding unrealistic clustering around central tendencies. This\napproach achieves a substantial and statistically significant improvement,\nincluding an average reduction of over 85% in Wasserstein distance and\nKolmogorov-Smirnov test p-values between 0.18 and 0.22, compared to p-values >\n0.99 in classical methods such as Mean, KNN, and MICE. The method also\neliminates zero-value artifacts and enhances the realism and variability of\nimputed data. By combining quantum-inspired transformations with a scalable\nclassical framework, this methodology provides a robust solution for imputation\ntasks in domains such as healthcare and AI pipelines, where data quality and\nintegrity are crucial.",
    "categories": [
      "quant-ph",
      "cs.AI"
    ],
    "primary_category": "quant-ph",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.04841v2",
    "published_date": "2025-05-07 22:37:07 UTC",
    "updated_date": "2025-05-11 00:20:39 UTC"
  },
  {
    "arxiv_id": "2505.07852v1",
    "title": "Joint Detection of Fraud and Concept Drift inOnline Conversations with LLM-Assisted Judgment",
    "authors": [
      "Ali Senol",
      "Garima Agrawal",
      "Huan Liu"
    ],
    "abstract": "Detecting fake interactions in digital communication platforms remains a\nchallenging and insufficiently addressed problem. These interactions may appear\nas harmless spam or escalate into sophisticated scam attempts, making it\ndifficult to flag malicious intent early. Traditional detection methods often\nrely on static anomaly detection techniques that fail to adapt to dynamic\nconversational shifts. One key limitation is the misinterpretation of benign\ntopic transitions referred to as concept drift as fraudulent behavior, leading\nto either false alarms or missed threats. We propose a two stage detection\nframework that first identifies suspicious conversations using a tailored\nensemble classification model. To improve the reliability of detection, we\nincorporate a concept drift analysis step using a One Class Drift Detector\n(OCDD) to isolate conversational shifts within flagged dialogues. When drift is\ndetected, a large language model (LLM) assesses whether the shift indicates\nfraudulent manipulation or a legitimate topic change. In cases where no drift\nis found, the behavior is inferred to be spam like. We validate our framework\nusing a dataset of social engineering chat scenarios and demonstrate its\npractical advantages in improving both accuracy and interpretability for real\ntime fraud detection. To contextualize the trade offs, we compare our modular\napproach against a Dual LLM baseline that performs detection and judgment using\ndifferent language models.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.07852v1",
    "published_date": "2025-05-07 22:30:53 UTC",
    "updated_date": "2025-05-07 22:30:53 UTC"
  },
  {
    "arxiv_id": "2505.04822v1",
    "title": "Is there Value in Reinforcement Learning?",
    "authors": [
      "Lior Fox",
      "Yonatan Loewenstein"
    ],
    "abstract": "Action-values play a central role in popular Reinforcement Learing (RL)\nmodels of behavior. Yet, the idea that action-values are explicitly represented\nhas been extensively debated. Critics had therefore repeatedly suggested that\npolicy-gradient (PG) models should be favored over value-based (VB) ones, as a\npotential solution for this dilemma. Here we argue that this solution is\nunsatisfying. This is because PG methods are not, in fact, \"Value-free\" --\nwhile they do not rely on an explicit representation of Value for acting\n(stimulus-response mapping), they do require it for learning. Hence, switching\nto PG models is, per se, insufficient for eliminating Value from models of\nbehavior. More broadly, the requirement for a representation of Value stems\nfrom the underlying assumptions regarding the optimization objective posed by\nthe standard RL framework, not from the particular algorithm chosen to solve\nit. Previous studies mostly took these standard RL assumptions for granted, as\npart of their conceptualization or problem modeling, while debating the\ndifferent methods used to optimize it (i.e., PG or VB). We propose that,\ninstead, the focus of the debate should shift to critically evaluating the\nunderlying modeling assumptions. Such evaluation is particularly important from\nan experimental perspective. Indeed, the very notion of Value must be\nreconsidered when standard assumptions (e.g., risk neutrality,\nfull-observability, Markovian environment, exponential discounting) are\nrelaxed, as is likely in natural settings. Finally, we use the Value debate as\na case study to argue in favor of a more nuanced, algorithmic rather than\nstatistical, view of what constitutes \"a model\" in cognitive sciences. Our\nanalysis suggests that besides \"parametric\" statistical complexity, additional\naspects such as computational complexity must also be taken into account when\nevaluating model complexity.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted to The 6th Multidisciplinary Conference on Reinforcement\n  Learning and Decision Making (RLDM 2025)",
    "pdf_url": "http://arxiv.org/pdf/2505.04822v1",
    "published_date": "2025-05-07 21:50:27 UTC",
    "updated_date": "2025-05-07 21:50:27 UTC"
  },
  {
    "arxiv_id": "2505.04808v1",
    "title": "Piecewise Constant Spectral Graph Neural Network",
    "authors": [
      "Vahan Martirosyan",
      "Jhony H. Giraldo",
      "Fragkiskos D. Malliaros"
    ],
    "abstract": "Graph Neural Networks (GNNs) have achieved significant success across various\ndomains by leveraging graph structures in data. Existing spectral GNNs, which\nuse low-degree polynomial filters to capture graph spectral properties, may not\nfully identify the graph's spectral characteristics because of the polynomial's\nsmall degree. However, increasing the polynomial degree is computationally\nexpensive and beyond certain thresholds leads to performance plateaus or\ndegradation. In this paper, we introduce the Piecewise Constant Spectral Graph\nNeural Network(PieCoN) to address these challenges. PieCoN combines constant\nspectral filters with polynomial filters to provide a more flexible way to\nleverage the graph structure. By adaptively partitioning the spectrum into\nintervals, our approach increases the range of spectral properties that can be\neffectively learned. Experiments on nine benchmark datasets, including both\nhomophilic and heterophilic graphs, demonstrate that PieCoN is particularly\neffective on heterophilic datasets, highlighting its potential for a wide range\nof applications.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted to TMLR 2025",
    "pdf_url": "http://arxiv.org/pdf/2505.04808v1",
    "published_date": "2025-05-07 21:17:06 UTC",
    "updated_date": "2025-05-07 21:17:06 UTC"
  },
  {
    "arxiv_id": "2505.07851v1",
    "title": "Pose Estimation for Intra-cardiac Echocardiography Catheter via AI-Based Anatomical Understanding",
    "authors": [
      "Jaeyoung Huh",
      "Ankur Kapoor",
      "Young-Ho Kim"
    ],
    "abstract": "Intra-cardiac Echocardiography (ICE) plays a crucial role in\nElectrophysiology (EP) and Structural Heart Disease (SHD) interventions by\nproviding high-resolution, real-time imaging of cardiac structures. However,\nexisting navigation methods rely on electromagnetic (EM) tracking, which is\nsusceptible to interference and position drift, or require manual adjustments\nbased on operator expertise. To overcome these limitations, we propose a novel\nanatomy-aware pose estimation system that determines the ICE catheter position\nand orientation solely from ICE images, eliminating the need for external\ntracking sensors. Our approach leverages a Vision Transformer (ViT)-based deep\nlearning model, which captures spatial relationships between ICE images and\nanatomical structures. The model is trained on a clinically acquired dataset of\n851 subjects, including ICE images paired with position and orientation labels\nnormalized to the left atrium (LA) mesh. ICE images are patchified into 16x16\nembeddings and processed through a transformer network, where a [CLS] token\nindependently predicts position and orientation via separate linear layers. The\nmodel is optimized using a Mean Squared Error (MSE) loss function, balancing\npositional and orientational accuracy. Experimental results demonstrate an\naverage positional error of 9.48 mm and orientation errors of (16.13 deg, 8.98\ndeg, 10.47 deg) across x, y, and z axes, confirming the model accuracy.\nQualitative assessments further validate alignment between predicted and target\nviews within 3D cardiac meshes. This AI-driven system enhances procedural\nefficiency, reduces operator workload, and enables real-time ICE catheter\nlocalization for tracking-free procedures. The proposed method can function\nindependently or complement existing mapping systems like CARTO, offering a\ntransformative approach to ICE-guided interventions.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV",
      "cs.RO"
    ],
    "primary_category": "eess.IV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.07851v1",
    "published_date": "2025-05-07 21:09:42 UTC",
    "updated_date": "2025-05-07 21:09:42 UTC"
  },
  {
    "arxiv_id": "2505.04802v1",
    "title": "ORBIT-2: Scaling Exascale Vision Foundation Models for Weather and Climate Downscaling",
    "authors": [
      "Xiao Wang",
      "Jong-Youl Choi",
      "Takuya Kurihaya",
      "Isaac Lyngaas",
      "Hong-Jun Yoon",
      "Ming Fan",
      "Nasik Muhammad Nafi",
      "Aristeidis Tsaris",
      "Ashwin M. Aji",
      "Maliha Hossain",
      "Mohamed Wahib",
      "Dali Wang",
      "Peter Thornton",
      "Prasanna Balaprakash",
      "Moetasim Ashfaq",
      "Dan Lu"
    ],
    "abstract": "Sparse observations and coarse-resolution climate models limit effective\nregional decision-making, underscoring the need for robust downscaling.\nHowever, existing AI methods struggle with generalization across variables and\ngeographies and are constrained by the quadratic complexity of Vision\nTransformer (ViT) self-attention. We introduce ORBIT-2, a scalable foundation\nmodel for global, hyper-resolution climate downscaling. ORBIT-2 incorporates\ntwo key innovations: (1) Residual Slim ViT (Reslim), a lightweight architecture\nwith residual learning and Bayesian regularization for efficient, robust\nprediction; and (2) TILES, a tile-wise sequence scaling algorithm that reduces\nself-attention complexity from quadratic to linear, enabling long-sequence\nprocessing and massive parallelism. ORBIT-2 scales to 10 billion parameters\nacross 32,768 GPUs, achieving up to 1.8 ExaFLOPS sustained throughput and\n92-98% strong scaling efficiency. It supports downscaling to 0.9 km global\nresolution and processes sequences up to 4.2 billion tokens. On 7 km resolution\nbenchmarks, ORBIT-2 achieves high accuracy with R^2 scores in the range of 0.98\nto 0.99 against observation data.",
    "categories": [
      "cs.LG",
      "astro-ph.EP",
      "cs.AI",
      "cs.DC",
      "physics.ao-ph"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.04802v1",
    "published_date": "2025-05-07 21:09:00 UTC",
    "updated_date": "2025-05-07 21:09:00 UTC"
  },
  {
    "arxiv_id": "2505.08795v1",
    "title": "The Geometry of Meaning: Perfect Spacetime Representations of Hierarchical Structures",
    "authors": [
      "Andres Anabalon",
      "Hugo Garces",
      "Julio Oliva",
      "Jose Cifuentes"
    ],
    "abstract": "We show that there is a fast algorithm that embeds hierarchical structures in\nthree-dimensional Minkowski spacetime. The correlation of data ends up purely\nencoded in the causal structure. Our model relies solely on oriented token\npairs -- local hierarchical signals -- with no access to global symbolic\nstructure. We apply our method to the corpus of \\textit{WordNet}. We provide a\nperfect embedding of the mammal sub-tree including ambiguities (more than one\nhierarchy per node) in such a way that the hierarchical structures get\ncompletely codified in the geometry and exactly reproduce the ground-truth. We\nextend this to a perfect embedding of the maximal unambiguous subset of the\n\\textit{WordNet} with 82{,}115 noun tokens and a single hierarchy per token. We\nintroduce a novel retrieval mechanism in which causality, not distance, governs\nhierarchical access. Our results seem to indicate that all discrete data has a\nperfect geometrical representation that is three-dimensional. The resulting\nembeddings are nearly conformally invariant, indicating deep connections with\ngeneral relativity and field theory. These results suggest that concepts,\ncategories, and their interrelations, namely hierarchical meaning itself, is\ngeometric.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "7 pages, 3 figures",
    "pdf_url": "http://arxiv.org/pdf/2505.08795v1",
    "published_date": "2025-05-07 20:41:06 UTC",
    "updated_date": "2025-05-07 20:41:06 UTC"
  },
  {
    "arxiv_id": "2505.04792v1",
    "title": "Confabulation dynamics in a reservoir computer: Filling in the gaps with untrained attractors",
    "authors": [
      "Jack O'Hagan",
      "Andrew Keane",
      "Andrew Flynn"
    ],
    "abstract": "Artificial Intelligence has advanced significantly in recent years thanks to\ninnovations in the design and training of artificial neural networks (ANNs).\nDespite these advancements, we still understand relatively little about how\nelementary forms of ANNs learn, fail to learn, and generate false information\nwithout the intent to deceive, a phenomenon known as `confabulation'. To\nprovide some foundational insight, in this paper we analyse how confabulation\noccurs in reservoir computers (RCs): a dynamical system in the form of an ANN.\nRCs are particularly useful to study as they are known to confabulate in a\nwell-defined way: when RCs are trained to reconstruct the dynamics of a given\nattractor, they sometimes construct an attractor that they were not trained to\nconstruct, a so-called `untrained attractor' (UA). This paper sheds light on\nthe role played by UAs when reconstruction fails and their influence when\nmodelling transitions between reconstructed attractors. Based on our results,\nwe conclude that UAs are an intrinsic feature of learning systems whose state\nspaces are bounded, and that this means of confabulation may be present in\nsystems beyond RCs.",
    "categories": [
      "math.DS",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "math.DS",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.04792v1",
    "published_date": "2025-05-07 20:38:44 UTC",
    "updated_date": "2025-05-07 20:38:44 UTC"
  },
  {
    "arxiv_id": "2505.04787v2",
    "title": "Replay to Remember (R2R): An Efficient Uncertainty-driven Unsupervised Continual Learning Framework Using Generative Replay",
    "authors": [
      "Sriram Mandalika",
      "Harsha Vardhan",
      "Athira Nambiar"
    ],
    "abstract": "Continual Learning entails progressively acquiring knowledge from new data\nwhile retaining previously acquired knowledge, thereby mitigating\n``Catastrophic Forgetting'' in neural networks. Our work presents a novel\nuncertainty-driven Unsupervised Continual Learning framework using Generative\nReplay, namely ``Replay to Remember (R2R)''. The proposed R2R architecture\nefficiently uses unlabelled and synthetic labelled data in a balanced\nproportion using a cluster-level uncertainty-driven feedback mechanism and a\nVLM-powered generative replay module. Unlike traditional memory-buffer methods\nthat depend on pretrained models and pseudo-labels, our R2R framework operates\nwithout any prior training. It leverages visual features from unlabeled data\nand adapts continuously using clustering-based uncertainty estimation coupled\nwith dynamic thresholding. Concurrently, a generative replay mechanism along\nwith DeepSeek-R1 powered CLIP VLM produces labelled synthetic data\nrepresentative of past experiences, resembling biological visual thinking that\nreplays memory to remember and act in new, unseen tasks. Extensive experimental\nanalyses are carried out in CIFAR-10, CIFAR-100, CINIC-10, SVHN and\nTinyImageNet datasets. Our proposed R2R approach improves knowledge retention,\nachieving a state-of-the-art performance of 98.13%, 73.06%, 93.41%, 95.18%,\n59.74%, respectively, surpassing state-of-the-art performance by over 4.36%.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Submitted to the 28th European Conference on Artificial Intelligence\n  (ECAI-2025)",
    "pdf_url": "http://arxiv.org/pdf/2505.04787v2",
    "published_date": "2025-05-07 20:29:31 UTC",
    "updated_date": "2025-05-09 05:22:21 UTC"
  },
  {
    "arxiv_id": "2505.04785v1",
    "title": "Flower Across Time and Media: Sentiment Analysis of Tang Song Poetry and Visual Correspondence",
    "authors": [
      "Shuai Gong",
      "Tiange Zhou"
    ],
    "abstract": "The Tang (618 to 907) and Song (960 to 1279) dynasties witnessed an\nextraordinary flourishing of Chinese cultural expression, where floral motifs\nserved as a dynamic medium for both poetic sentiment and artistic design. While\nprevious scholarship has examined these domains independently, the systematic\ncorrelation between evolving literary emotions and visual culture remains\nunderexplored. This study addresses that gap by employing BERT-based sentiment\nanalysis to quantify emotional patterns in floral imagery across Tang Song\npoetry, then validating these patterns against contemporaneous developments in\ndecorative arts.Our approach builds upon recent advances in computational\nhumanities while remaining grounded in traditional sinological methods. By\napplying a fine tuned BERT model to analyze peony and plum blossom imagery in\nclassical poetry, we detect measurable shifts in emotional connotations between\nthe Tang and Song periods. These textual patterns are then cross berenced with\nvisual evidence from textiles, ceramics, and other material culture, revealing\npreviously unrecognized synergies between literary expression and artistic\nrepresentation.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "5 pages, 9 figures",
    "pdf_url": "http://arxiv.org/pdf/2505.04785v1",
    "published_date": "2025-05-07 20:27:38 UTC",
    "updated_date": "2025-05-07 20:27:38 UTC"
  },
  {
    "arxiv_id": "2505.04784v1",
    "title": "A Proposal for Evaluating the Operational Risk for ChatBots based on Large Language Models",
    "authors": [
      "Pedro Pinacho-Davidson",
      "Fernando Gutierrez",
      "Pablo Zapata",
      "Rodolfo Vergara",
      "Pablo Aqueveque"
    ],
    "abstract": "The emergence of Generative AI (Gen AI) and Large Language Models (LLMs) has\nenabled more advanced chatbots capable of human-like interactions. However,\nthese conversational agents introduce a broader set of operational risks that\nextend beyond traditional cybersecurity considerations. In this work, we\npropose a novel, instrumented risk-assessment metric that simultaneously\nevaluates potential threats to three key stakeholders: the service-providing\norganization, end users, and third parties. Our approach incorporates the\ntechnical complexity required to induce erroneous behaviors in the\nchatbot--ranging from non-induced failures to advanced prompt-injection\nattacks--as well as contextual factors such as the target industry, user age\nrange, and vulnerability severity. To validate our metric, we leverage Garak,\nan open-source framework for LLM vulnerability testing. We further enhance\nGarak to capture a variety of threat vectors (e.g., misinformation, code\nhallucinations, social engineering, and malicious code generation). Our\nmethodology is demonstrated in a scenario involving chatbots that employ\nretrieval-augmented generation (RAG), showing how the aggregated risk scores\nguide both short-term mitigation and longer-term improvements in model design\nand deployment. The results underscore the importance of multi-dimensional risk\nassessments in operationalizing secure, reliable AI-driven conversational\nsystems.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.CR",
    "comment": "21 pages",
    "pdf_url": "http://arxiv.org/pdf/2505.04784v1",
    "published_date": "2025-05-07 20:26:45 UTC",
    "updated_date": "2025-05-07 20:26:45 UTC"
  },
  {
    "arxiv_id": "2505.07850v1",
    "title": "A Tale of Two Identities: An Ethical Audit of Human and AI-Crafted Personas",
    "authors": [
      "Pranav Narayanan Venkit",
      "Jiayi Li",
      "Yingfan Zhou",
      "Sarah Rajtmajer",
      "Shomir Wilson"
    ],
    "abstract": "As LLMs (large language models) are increasingly used to generate synthetic\npersonas particularly in data-limited domains such as health, privacy, and HCI,\nit becomes necessary to understand how these narratives represent identity,\nespecially that of minority communities. In this paper, we audit synthetic\npersonas generated by 3 LLMs (GPT4o, Gemini 1.5 Pro, Deepseek 2.5) through the\nlens of representational harm, focusing specifically on racial identity. Using\na mixed methods approach combining close reading, lexical analysis, and a\nparameterized creativity framework, we compare 1512 LLM generated personas to\nhuman-authored responses. Our findings reveal that LLMs disproportionately\nforeground racial markers, overproduce culturally coded language, and construct\npersonas that are syntactically elaborate yet narratively reductive. These\npatterns result in a range of sociotechnical harms, including stereotyping,\nexoticism, erasure, and benevolent bias, that are often obfuscated by\nsuperficially positive narrations. We formalize this phenomenon as algorithmic\nothering, where minoritized identities are rendered hypervisible but less\nauthentic. Based on these findings, we offer design recommendations for\nnarrative-aware evaluation metrics and community-centered validation protocols\nfor synthetic identity generation.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.07850v1",
    "published_date": "2025-05-07 20:12:48 UTC",
    "updated_date": "2025-05-07 20:12:48 UTC"
  },
  {
    "arxiv_id": "2505.06299v1",
    "title": "Input-Specific and Universal Adversarial Attack Generation for Spiking Neural Networks in the Spiking Domain",
    "authors": [
      "Spyridon Raptis",
      "Haralampos-G. Stratigopoulos"
    ],
    "abstract": "As Spiking Neural Networks (SNNs) gain traction across various applications,\nunderstanding their security vulnerabilities becomes increasingly important. In\nthis work, we focus on the adversarial attacks, which is perhaps the most\nconcerning threat. An adversarial attack aims at finding a subtle input\nperturbation to fool the network's decision-making. We propose two novel\nadversarial attack algorithms for SNNs: an input-specific attack that crafts\nadversarial samples from specific dataset inputs and a universal attack that\ngenerates a reusable patch capable of inducing misclassification across most\ninputs, thus offering practical feasibility for real-time deployment. The\nalgorithms are gradient-based operating in the spiking domain proving to be\neffective across different evaluation metrics, such as adversarial accuracy,\nstealthiness, and generation time. Experimental results on two widely used\nneuromorphic vision datasets, NMNIST and IBM DVS Gesture, show that our\nproposed attacks surpass in all metrics all existing state-of-the-art methods.\nAdditionally, we present the first demonstration of adversarial attack\ngeneration in the sound domain using the SHD dataset.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.06299v1",
    "published_date": "2025-05-07 19:49:18 UTC",
    "updated_date": "2025-05-07 19:49:18 UTC"
  },
  {
    "arxiv_id": "2505.07849v1",
    "title": "SweRank: Software Issue Localization with Code Ranking",
    "authors": [
      "Revanth Gangi Reddy",
      "Tarun Suresh",
      "JaeHyeok Doo",
      "Ye Liu",
      "Xuan Phi Nguyen",
      "Yingbo Zhou",
      "Semih Yavuz",
      "Caiming Xiong",
      "Heng Ji",
      "Shafiq Joty"
    ],
    "abstract": "Software issue localization, the task of identifying the precise code\nlocations (files, classes, or functions) relevant to a natural language issue\ndescription (e.g., bug report, feature request), is a critical yet\ntime-consuming aspect of software development. While recent LLM-based agentic\napproaches demonstrate promise, they often incur significant latency and cost\ndue to complex multi-step reasoning and relying on closed-source LLMs.\nAlternatively, traditional code ranking models, typically optimized for\nquery-to-code or code-to-code retrieval, struggle with the verbose and\nfailure-descriptive nature of issue localization queries. To bridge this gap,\nwe introduce SweRank, an efficient and effective retrieve-and-rerank framework\nfor software issue localization. To facilitate training, we construct SweLoc, a\nlarge-scale dataset curated from public GitHub repositories, featuring\nreal-world issue descriptions paired with corresponding code modifications.\nEmpirical results on SWE-Bench-Lite and LocBench show that SweRank achieves\nstate-of-the-art performance, outperforming both prior ranking models and\ncostly agent-based systems using closed-source LLMs like Claude-3.5. Further,\nwe demonstrate SweLoc's utility in enhancing various existing retriever and\nreranker models for issue localization, establishing the dataset as a valuable\nresource for the community.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.07849v1",
    "published_date": "2025-05-07 19:44:09 UTC",
    "updated_date": "2025-05-07 19:44:09 UTC"
  },
  {
    "arxiv_id": "2505.04759v1",
    "title": "Exploring Zero-Shot App Review Classification with ChatGPT: Challenges and Potential",
    "authors": [
      "Mohit Chaudhary",
      "Chirag Jain",
      "Preethu Rose Anish"
    ],
    "abstract": "App reviews are a critical source of user feedback, offering valuable\ninsights into an app's performance, features, usability, and overall user\nexperience. Effectively analyzing these reviews is essential for guiding app\ndevelopment, prioritizing feature updates, and enhancing user satisfaction.\nClassifying reviews into functional and non-functional requirements play a\npivotal role in distinguishing feedback related to specific app features\n(functional requirements) from feedback concerning broader quality attributes,\nsuch as performance, usability, and reliability (non-functional requirements).\nBoth categories are integral to informed development decisions. Traditional\napproaches to classifying app reviews are hindered by the need for large,\ndomain-specific datasets, which are often costly and time-consuming to curate.\nThis study explores the potential of zero-shot learning with ChatGPT for\nclassifying app reviews into four categories: functional requirement,\nnon-functional requirement, both, or neither. We evaluate ChatGPT's performance\non a benchmark dataset of 1,880 manually annotated reviews from ten diverse\napps spanning multiple domains. Our findings demonstrate that ChatGPT achieves\na robust F1 score of 0.842 in review classification, despite certain challenges\nand limitations. Additionally, we examine how factors such as review\nreadability and length impact classification accuracy and conduct a manual\nanalysis to identify review categories more prone to misclassification.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.04759v1",
    "published_date": "2025-05-07 19:39:04 UTC",
    "updated_date": "2025-05-07 19:39:04 UTC"
  },
  {
    "arxiv_id": "2505.04741v1",
    "title": "When Bad Data Leads to Good Models",
    "authors": [
      "Kenneth Li",
      "Yida Chen",
      "Fernanda Viégas",
      "Martin Wattenberg"
    ],
    "abstract": "In large language model (LLM) pretraining, data quality is believed to\ndetermine model quality. In this paper, we re-examine the notion of \"quality\"\nfrom the perspective of pre- and post-training co-design. Specifically, we\nexplore the possibility that pre-training on more toxic data can lead to better\ncontrol in post-training, ultimately decreasing a model's output toxicity.\nFirst, we use a toy experiment to study how data composition affects the\ngeometry of features in the representation space. Next, through controlled\nexperiments with Olmo-1B models trained on varying ratios of clean and toxic\ndata, we find that the concept of toxicity enjoys a less entangled linear\nrepresentation as the proportion of toxic data increases. Furthermore, we show\nthat although toxic data increases the generational toxicity of the base model,\nit also makes the toxicity easier to remove. Evaluations on Toxigen and Real\nToxicity Prompts demonstrate that models trained on toxic data achieve a better\ntrade-off between reducing generational toxicity and preserving general\ncapabilities when detoxifying techniques such as inference-time intervention\n(ITI) are applied. Our findings suggest that, with post-training taken into\naccount, bad data may lead to good models.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "ICML 2025",
    "pdf_url": "http://arxiv.org/pdf/2505.04741v1",
    "published_date": "2025-05-07 19:17:49 UTC",
    "updated_date": "2025-05-07 19:17:49 UTC"
  },
  {
    "arxiv_id": "2505.04736v1",
    "title": "The Promise and Limits of LLMs in Constructing Proofs and Hints for Logic Problems in Intelligent Tutoring Systems",
    "authors": [
      "Sutapa Dey Tithi",
      "Arun Kumar Ramesh",
      "Clara DiMarco",
      "Xiaoyi Tian",
      "Nazia Alam",
      "Kimia Fazeli",
      "Tiffany Barnes"
    ],
    "abstract": "Intelligent tutoring systems have demonstrated effectiveness in teaching\nformal propositional logic proofs, but their reliance on template-based\nexplanations limits their ability to provide personalized student feedback.\nWhile large language models (LLMs) offer promising capabilities for dynamic\nfeedback generation, they risk producing hallucinations or pedagogically\nunsound explanations. We evaluated the stepwise accuracy of LLMs in\nconstructing multi-step symbolic logic proofs, comparing six prompting\ntechniques across four state-of-the-art LLMs on 358 propositional logic\nproblems. Results show that DeepSeek-V3 achieved superior performance with\n84.4% accuracy on stepwise proof construction and excelled particularly in\nsimpler rules. We further used the best-performing LLM to generate explanatory\nhints for 1,050 unique student problem-solving states from a logic ITS and\nevaluated them on 4 criteria with both an LLM grader and human expert ratings\non a 20% sample. Our analysis finds that LLM-generated hints were 75% accurate\nand rated highly by human evaluators on consistency and clarity, but did not\nperform as well explaining why the hint was provided or its larger context. Our\nresults demonstrate that LLMs may be used to augment tutoring systems with\nlogic tutoring hints, but requires additional modifications to ensure accuracy\nand pedagogical appropriateness.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.04736v1",
    "published_date": "2025-05-07 18:48:23 UTC",
    "updated_date": "2025-05-07 18:48:23 UTC"
  },
  {
    "arxiv_id": "2505.04732v1",
    "title": "QBD-RankedDataGen: Generating Custom Ranked Datasets for Improving Query-By-Document Search Using LLM-Reranking with Reduced Human Effort",
    "authors": [
      "Sriram Gopalakrishnan",
      "Sunandita Patra"
    ],
    "abstract": "The Query-By-Document (QBD) problem is an information retrieval problem where\nthe query is a document, and the retrieved candidates are documents that match\nthe query document, often in a domain or query specific manner. This can be\ncrucial for tasks such as patent matching, legal or compliance case retrieval,\nand academic literature review. Existing retrieval methods, including keyword\nsearch and document embeddings, can be optimized with domain-specific datasets\nto improve QBD search performance. However, creating these domain-specific\ndatasets is often costly and time-consuming. Our work introduces a process to\ngenerate custom QBD-search datasets and compares a set of methods to use in\nthis problem, which we refer to as QBD-RankedDatagen. We provide a comparative\nanalysis of our proposed methods in terms of cost, speed, and the human\ninterface with the domain experts. The methods we compare leverage Large\nLanguage Models (LLMs) which can incorporate domain expert input to produce\ndocument scores and rankings, as well as explanations for human review. The\nprocess and methods for it that we present can significantly reduce human\neffort in dataset creation for custom domains while still obtaining sufficient\nexpert knowledge for tuning retrieval models. We evaluate our methods on QBD\ndatasets from the Text Retrieval Conference (TREC) and finetune the parameters\nof the BM25 model -- which is used in many industrial-strength search engines\nlike OpenSearch -- using the generated data.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "13 pages",
    "pdf_url": "http://arxiv.org/pdf/2505.04732v1",
    "published_date": "2025-05-07 18:43:57 UTC",
    "updated_date": "2025-05-07 18:43:57 UTC"
  },
  {
    "arxiv_id": "2505.04725v1",
    "title": "Geometric Fault-Tolerant Neural Network Tracking Control of Unknown Systems on Matrix Lie Groups",
    "authors": [
      "Robin Chhabra",
      "Farzaneh Abdollahi"
    ],
    "abstract": "We present a geometric neural network-based tracking controller for systems\nevolving on matrix Lie groups under unknown dynamics, actuator faults, and\nbounded disturbances. Leveraging the left-invariance of the tangent bundle of\nmatrix Lie groups, viewed as an embedded submanifold of the vector space\n$\\R^{N\\times N}$, we propose a set of learning rules for neural network weights\nthat are intrinsically compatible with the Lie group structure and do not\nrequire explicit parameterization. Exploiting the geometric properties of Lie\ngroups, this approach circumvents parameterization singularities and enables a\nglobal search for optimal weights. The ultimate boundedness of all error\nsignals -- including the neural network weights, the coordinate-free\nconfiguration error function, and the tracking velocity error -- is established\nusing Lyapunov's direct method. To validate the effectiveness of the proposed\nmethod, we provide illustrative simulation results for decentralized formation\ncontrol of multi-agent systems on the Special Euclidean group.",
    "categories": [
      "eess.SY",
      "cs.AI",
      "cs.RO",
      "cs.SY",
      "math.DS"
    ],
    "primary_category": "eess.SY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.04725v1",
    "published_date": "2025-05-07 18:33:23 UTC",
    "updated_date": "2025-05-07 18:33:23 UTC"
  },
  {
    "arxiv_id": "2505.06136v1",
    "title": "Efficient Sensorimotor Learning for Open-world Robot Manipulation",
    "authors": [
      "Yifeng Zhu"
    ],
    "abstract": "This dissertation considers Open-world Robot Manipulation, a manipulation\nproblem where a robot must generalize or quickly adapt to new objects, scenes,\nor tasks for which it has not been pre-programmed or pre-trained. This\ndissertation tackles the problem using a methodology of efficient sensorimotor\nlearning. The key to enabling efficient sensorimotor learning lies in\nleveraging regular patterns that exist in limited amounts of demonstration\ndata. These patterns, referred to as ``regularity,'' enable the data-efficient\nlearning of generalizable manipulation skills. This dissertation offers a new\nperspective on formulating manipulation problems through the lens of\nregularity. Building upon this notion, we introduce three major contributions.\nFirst, we introduce methods that endow robots with object-centric priors,\nallowing them to learn generalizable, closed-loop sensorimotor policies from a\nsmall number of teleoperation demonstrations. Second, we introduce methods that\nconstitute robots' spatial understanding, unlocking their ability to imitate\nmanipulation skills from in-the-wild video observations. Last but not least, we\nintroduce methods that enable robots to identify reusable skills from their\npast experiences, resulting in systems that can continually imitate multiple\ntasks in a sequential manner. Altogether, the contributions of this\ndissertation help lay the groundwork for building general-purpose personal\nrobots that can quickly adapt to new situations or tasks with low-cost data\ncollection and interact easily with humans. By enabling robots to learn and\ngeneralize from limited data, this dissertation takes a step toward realizing\nthe vision of intelligent robotic assistants that can be seamlessly integrated\ninto everyday scenarios.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "Ph.D. Dissertation",
    "pdf_url": "http://arxiv.org/pdf/2505.06136v1",
    "published_date": "2025-05-07 18:23:58 UTC",
    "updated_date": "2025-05-07 18:23:58 UTC"
  },
  {
    "arxiv_id": "2505.04623v1",
    "title": "EchoInk-R1: Exploring Audio-Visual Reasoning in Multimodal LLMs via Reinforcement Learning",
    "authors": [
      "Zhenghao Xing",
      "Xiaowei Hu",
      "Chi-Wing Fu",
      "Wenhai Wang",
      "Jifeng Dai",
      "Pheng-Ann Heng"
    ],
    "abstract": "Multimodal large language models (MLLMs) have advanced perception across\ntext, vision, and audio, yet they often struggle with structured cross-modal\nreasoning, particularly when integrating audio and visual signals. We introduce\nEchoInk-R1, a reinforcement learning framework that enhances such reasoning in\nMLLMs. Built upon the Qwen2.5-Omni-7B foundation and optimized with Group\nRelative Policy Optimization (GRPO), EchoInk-R1 tackles multiple-choice\nquestion answering over synchronized audio-image pairs. To enable this, we\ncurate AVQA-R1-6K, a dataset pairing such audio-image inputs with\nmultiple-choice questions derived from OmniInstruct-v1. EchoInk-R1-7B achieves\n85.77% accuracy on the validation set, outperforming the base model, which\nscores 80.53%, using only 562 reinforcement learning steps. Beyond accuracy,\nEchoInk-R1 demonstrates reflective reasoning by revisiting initial\ninterpretations and refining responses when facing ambiguous multimodal inputs.\nThese results suggest that lightweight reinforcement learning fine-tuning\nenhances cross-modal reasoning in MLLMs. EchoInk-R1 is the first framework to\nunify audio, visual, and textual modalities for general open-world reasoning\nvia reinforcement learning. Code and data are publicly released to facilitate\nfurther research.",
    "categories": [
      "eess.AS",
      "cs.AI",
      "cs.CV",
      "cs.MM",
      "cs.SD"
    ],
    "primary_category": "eess.AS",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.04623v1",
    "published_date": "2025-05-07 17:59:49 UTC",
    "updated_date": "2025-05-07 17:59:49 UTC"
  },
  {
    "arxiv_id": "2505.04621v1",
    "title": "Score Distillation Sampling for Audio: Source Separation, Synthesis, and Beyond",
    "authors": [
      "Jessie Richter-Powell",
      "Antonio Torralba",
      "Jonathan Lorraine"
    ],
    "abstract": "We introduce Audio-SDS, a generalization of Score Distillation Sampling (SDS)\nto text-conditioned audio diffusion models. While SDS was initially designed\nfor text-to-3D generation using image diffusion, its core idea of distilling a\npowerful generative prior into a separate parametric representation extends to\nthe audio domain. Leveraging a single pretrained model, Audio-SDS enables a\nbroad range of tasks without requiring specialized datasets. In particular, we\ndemonstrate how Audio-SDS can guide physically informed impact sound\nsimulations, calibrate FM-synthesis parameters, and perform prompt-specified\nsource separation. Our findings illustrate the versatility of\ndistillation-based methods across modalities and establish a robust foundation\nfor future work using generative priors in audio tasks.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.LG",
      "cs.MM",
      "eess.AS",
      "68T07",
      "I.2.6; H.5.5; H.5.1"
    ],
    "primary_category": "cs.SD",
    "comment": "See the project website at\n  https://research.nvidia.com/labs/toronto-ai/Audio-SDS/",
    "pdf_url": "http://arxiv.org/pdf/2505.04621v1",
    "published_date": "2025-05-07 17:59:38 UTC",
    "updated_date": "2025-05-07 17:59:38 UTC"
  },
  {
    "arxiv_id": "2505.04608v2",
    "title": "WATCH: Adaptive Monitoring for AI Deployments via Weighted-Conformal Martingales",
    "authors": [
      "Drew Prinster",
      "Xing Han",
      "Anqi Liu",
      "Suchi Saria"
    ],
    "abstract": "Responsibly deploying artificial intelligence (AI) / machine learning (ML)\nsystems in high-stakes settings arguably requires not only proof of system\nreliability, but moreover continual, post-deployment monitoring to quickly\ndetect and address any unsafe behavior. Statistical methods for nonparametric\nchange-point detection -- especially the tools of conformal test martingales\n(CTMs) and anytime-valid inference -- offer promising approaches to this\nmonitoring task. However, existing methods are restricted to monitoring limited\nhypothesis classes or ``alarm criteria'' (such as data shifts that violate\ncertain exchangeability assumptions), do not allow for online adaptation in\nresponse to shifts, and/or do not enable root-cause analysis of any\ndegradation. In this paper, we expand the scope of these monitoring methods by\nproposing a weighted generalization of conformal test martingales (WCTMs),\nwhich lay a theoretical foundation for online monitoring for any unexpected\nchangepoints in the data distribution while controlling false-alarms. For\npractical applications, we propose specific WCTM algorithms that adapt online\nto mild covariate shifts (in the marginal input distribution) while quickly\ndetecting and diagnosing more severe shifts, such as concept shifts (in the\nconditional label distribution) or extreme (out-of-support) covariate shifts\nthat cannot be easily adapted to. On real-world datasets, we demonstrate\nimproved performance relative to state-of-the-art baselines.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "To be published in The International Conference on Machine Learning\n  (ICML), 2025",
    "pdf_url": "http://arxiv.org/pdf/2505.04608v2",
    "published_date": "2025-05-07 17:53:47 UTC",
    "updated_date": "2025-05-12 17:56:52 UTC"
  },
  {
    "arxiv_id": "2505.04592v1",
    "title": "AI Governance to Avoid Extinction: The Strategic Landscape and Actionable Research Questions",
    "authors": [
      "Peter Barnett",
      "Aaron Scher"
    ],
    "abstract": "Humanity appears to be on course to soon develop AI systems that\nsubstantially outperform human experts in all cognitive domains and activities.\nWe believe the default trajectory has a high likelihood of catastrophe,\nincluding human extinction. Risks come from failure to control powerful AI\nsystems, misuse of AI by malicious rogue actors, war between great powers, and\nauthoritarian lock-in. This research agenda has two aims: to describe the\nstrategic landscape of AI development and to catalog important governance\nresearch questions. These questions, if answered, would provide important\ninsight on how to successfully reduce catastrophic risks.\n  We describe four high-level scenarios for the geopolitical response to\nadvanced AI development, cataloging the research questions most relevant to\neach. Our favored scenario involves building the technical, legal, and\ninstitutional infrastructure required to internationally restrict dangerous AI\ndevelopment and deployment (which we refer to as an Off Switch), which leads\ninto an internationally coordinated Halt on frontier AI activities at some\npoint in the future. The second scenario we describe is a US National Project\nfor AI, in which the US Government races to develop advanced AI systems and\nestablish unilateral control over global AI development. We also describe two\nadditional scenarios: a Light-Touch world similar to that of today and a Threat\nof Sabotage situation where countries use sabotage and deterrence to slow AI\ndevelopment.\n  In our view, apart from the Off Switch and Halt scenario, all of these\ntrajectories appear to carry an unacceptable risk of catastrophic harm. Urgent\naction is needed from the US National Security community and AI governance\necosystem to answer key research questions, build the capability to halt\ndangerous AI activities, and prepare for international AI agreements.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.04592v1",
    "published_date": "2025-05-07 17:35:36 UTC",
    "updated_date": "2025-05-07 17:35:36 UTC"
  },
  {
    "arxiv_id": "2505.04578v1",
    "title": "Fight Fire with Fire: Defending Against Malicious RL Fine-Tuning via Reward Neutralization",
    "authors": [
      "Wenjun Cao"
    ],
    "abstract": "Reinforcement learning (RL) fine-tuning transforms large language models\nwhile creating a vulnerability we experimentally verify: Our experiment shows\nthat malicious RL fine-tuning dismantles safety guardrails with remarkable\nefficiency, requiring only 50 steps and minimal adversarial prompts, with\nharmful escalating from 0-2 to 7-9. This attack vector particularly threatens\nopen-source models with parameter-level access. Existing defenses targeting\nsupervised fine-tuning prove ineffective against RL's dynamic feedback\nmechanisms. We introduce Reward Neutralization, the first defense framework\nspecifically designed against RL fine-tuning attacks, establishing concise\nrejection patterns that render malicious reward signals ineffective. Our\napproach trains models to produce minimal-information rejections that attackers\ncannot exploit, systematically neutralizing attempts to optimize toward harmful\noutputs. Experiments validate that our approach maintains low harmful scores\n(no greater than 2) after 200 attack steps, while standard models rapidly\ndeteriorate. This work provides the first constructive proof that robust\ndefense against increasingly accessible RL attacks is achievable, addressing a\ncritical security gap for open-weight models.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.04578v1",
    "published_date": "2025-05-07 17:18:48 UTC",
    "updated_date": "2025-05-07 17:18:48 UTC"
  },
  {
    "arxiv_id": "2505.04558v2",
    "title": "Purity Law for Generalizable Neural TSP Solvers",
    "authors": [
      "Wenzhao Liu",
      "Haoran Li",
      "Congying Han",
      "Zicheng Zhang",
      "Anqi Li",
      "Tiande Guo"
    ],
    "abstract": "Achieving generalization in neural approaches across different scales and\ndistributions remains a significant challenge for the Traveling Salesman\nProblem~(TSP). A key obstacle is that neural networks often fail to learn\nrobust principles for identifying universal patterns and deriving optimal\nsolutions from diverse instances. In this paper, we first uncover Purity Law\n(PuLa), a fundamental structural principle for optimal TSP solutions, defining\nthat edge prevalence grows exponentially with the sparsity of surrounding\nvertices. Statistically validated across diverse instances, PuLa reveals a\nconsistent bias toward local sparsity in global optima. Building on this\ninsight, we propose Purity Policy Optimization~(PUPO), a novel training\nparadigm that explicitly aligns characteristics of neural solutions with PuLa\nduring the solution construction process to enhance generalization. Extensive\nexperiments demonstrate that PUPO can be seamlessly integrated with popular\nneural solvers, significantly enhancing their generalization performance\nwithout incurring additional computational overhead during inference.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.04558v2",
    "published_date": "2025-05-07 16:46:48 UTC",
    "updated_date": "2025-05-10 13:39:05 UTC"
  },
  {
    "arxiv_id": "2505.04553v2",
    "title": "Risk-sensitive Reinforcement Learning Based on Convex Scoring Functions",
    "authors": [
      "Shanyu Han",
      "Yang Liu",
      "Xiang Yu"
    ],
    "abstract": "We propose a reinforcement learning (RL) framework under a broad class of\nrisk objectives, characterized by convex scoring functions. This class covers\nmany common risk measures, such as variance, Expected Shortfall, entropic\nValue-at-Risk, and mean-risk utility. To resolve the time-inconsistency issue,\nwe consider an augmented state space and an auxiliary variable and recast the\nproblem as a two-state optimization problem. We propose a customized\nActor-Critic algorithm and establish some theoretical approximation guarantees.\nA key theoretical contribution is that our results do not require the Markov\ndecision process to be continuous. Additionally, we propose an auxiliary\nvariable sampling method inspired by the alternating minimization algorithm,\nwhich is convergent under certain conditions. We validate our approach in\nsimulation experiments with a financial application in statistical arbitrage\ntrading, demonstrating the effectiveness of the algorithm.",
    "categories": [
      "q-fin.MF",
      "cs.AI",
      "q-fin.RM"
    ],
    "primary_category": "q-fin.MF",
    "comment": "35 pages",
    "pdf_url": "http://arxiv.org/pdf/2505.04553v2",
    "published_date": "2025-05-07 16:31:42 UTC",
    "updated_date": "2025-05-15 10:40:05 UTC"
  },
  {
    "arxiv_id": "2505.04539v1",
    "title": "Qualitative Analysis of $ω$-Regular Objectives on Robust MDPs",
    "authors": [
      "Ali Asadi",
      "Krishnendu Chatterjee",
      "Ehsan Kafshdar Goharshady",
      "Mehrdad Karrabi",
      "Ali Shafiee"
    ],
    "abstract": "Robust Markov Decision Processes (RMDPs) generalize classical MDPs that\nconsider uncertainties in transition probabilities by defining a set of\npossible transition functions. An objective is a set of runs (or infinite\ntrajectories) of the RMDP, and the value for an objective is the maximal\nprobability that the agent can guarantee against the adversarial environment.\nWe consider (a) reachability objectives, where given a target set of states,\nthe goal is to eventually arrive at one of them; and (b) parity objectives,\nwhich are a canonical representation for $\\omega$-regular objectives. The\nqualitative analysis problem asks whether the objective can be ensured with\nprobability 1.\n  In this work, we study the qualitative problem for reachability and parity\nobjectives on RMDPs without making any assumption over the structures of the\nRMDPs, e.g., unichain or aperiodic. Our contributions are twofold. We first\npresent efficient algorithms with oracle access to uncertainty sets that solve\nqualitative problems of reachability and parity objectives. We then report\nexperimental results demonstrating the effectiveness of our oracle-based\napproach on classical RMDP examples from the literature scaling up to thousands\nof states.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.04539v1",
    "published_date": "2025-05-07 16:15:40 UTC",
    "updated_date": "2025-05-07 16:15:40 UTC"
  },
  {
    "arxiv_id": "2505.04531v1",
    "title": "Overcoming Data Scarcity in Generative Language Modelling for Low-Resource Languages: A Systematic Review",
    "authors": [
      "Josh McGiff",
      "Nikola S. Nikolov"
    ],
    "abstract": "Generative language modelling has surged in popularity with the emergence of\nservices such as ChatGPT and Google Gemini. While these models have\ndemonstrated transformative potential in productivity and communication, they\noverwhelmingly cater to high-resource languages like English. This has\namplified concerns over linguistic inequality in natural language processing\n(NLP). This paper presents the first systematic review focused specifically on\nstrategies to address data scarcity in generative language modelling for\nlow-resource languages (LRL). Drawing from 54 studies, we identify, categorise\nand evaluate technical approaches, including monolingual data augmentation,\nback-translation, multilingual training, and prompt engineering, across\ngenerative tasks. We also analyse trends in architecture choices, language\nfamily representation, and evaluation methods. Our findings highlight a strong\nreliance on transformer-based models, a concentration on a small subset of\nLRLs, and a lack of consistent evaluation across studies. We conclude with\nrecommendations for extending these methods to a wider range of LRLs and\noutline open challenges in building equitable generative language systems.\nUltimately, this review aims to support researchers and developers in building\ninclusive AI tools for underrepresented languages, a necessary step toward\nempowering LRL speakers and the preservation of linguistic diversity in a world\nincreasingly shaped by large-scale language technologies.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "This work is currently under review. Please do not cite without\n  permission",
    "pdf_url": "http://arxiv.org/pdf/2505.04531v1",
    "published_date": "2025-05-07 16:04:45 UTC",
    "updated_date": "2025-05-07 16:04:45 UTC"
  },
  {
    "arxiv_id": "2505.04528v1",
    "title": "Beyond Theorem Proving: Formulation, Framework and Benchmark for Formal Problem-Solving",
    "authors": [
      "Qi Liu",
      "Xinhao Zheng",
      "Renqiu Xia",
      "Xingzhi Qi",
      "Qinxiang Cao",
      "Junchi Yan"
    ],
    "abstract": "As a seemingly self-explanatory task, problem-solving has been a significant\ncomponent of science and engineering. However, a general yet concrete\nformulation of problem-solving itself is missing. With the recent development\nof AI-based problem-solving agents, the demand for process-level verifiability\nis rapidly increasing yet underexplored. To fill these gaps, we present a\nprincipled formulation of problem-solving as a deterministic Markov decision\nprocess; a novel framework, FPS (Formal Problem-Solving), which utilizes\nexisting FTP (formal theorem proving) environments to perform process-verified\nproblem-solving; and D-FPS (Deductive FPS), decoupling solving and answer\nverification for better human-alignment. The expressiveness, soundness and\ncompleteness of the frameworks are proven. We construct three benchmarks on\nproblem-solving: FormalMath500, a formalization of a subset of the MATH500\nbenchmark; MiniF2F-Solving and PutnamBench-Solving, adaptations of FTP\nbenchmarks MiniF2F and PutnamBench. For faithful, interpretable, and\nhuman-aligned evaluation, we propose RPE (Restricted Propositional\nEquivalence), a symbolic approach to determine the correctness of answers by\nformal verification. We evaluate four prevalent FTP models and two prompting\nmethods as baselines, solving at most 23.77% of FormalMath500, 27.47% of\nMiniF2F-Solving, and 0.31% of PutnamBench-Solving.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LO"
    ],
    "primary_category": "cs.AI",
    "comment": "42 pages, 3 figures",
    "pdf_url": "http://arxiv.org/pdf/2505.04528v1",
    "published_date": "2025-05-07 16:02:14 UTC",
    "updated_date": "2025-05-07 16:02:14 UTC"
  },
  {
    "arxiv_id": "2505.04526v1",
    "title": "DFVO: Learning Darkness-free Visible and Infrared Image Disentanglement and Fusion All at Once",
    "authors": [
      "Qi Zhou",
      "Yukai Shi",
      "Xiaojun Yang",
      "Xiaoyu Xian",
      "Lunjia Liao",
      "Ruimao Zhang",
      "Liang Lin"
    ],
    "abstract": "Visible and infrared image fusion is one of the most crucial tasks in the\nfield of image fusion, aiming to generate fused images with clear structural\ninformation and high-quality texture features for high-level vision tasks.\nHowever, when faced with severe illumination degradation in visible images, the\nfusion results of existing image fusion methods often exhibit blurry and dim\nvisual effects, posing major challenges for autonomous driving. To this end, a\nDarkness-Free network is proposed to handle Visible and infrared image\ndisentanglement and fusion all at Once (DFVO), which employs a cascaded\nmulti-task approach to replace the traditional two-stage cascaded training\n(enhancement and fusion), addressing the issue of information entropy loss\ncaused by hierarchical data transmission. Specifically, we construct a\nlatent-common feature extractor (LCFE) to obtain latent features for the\ncascaded tasks strategy. Firstly, a details-extraction module (DEM) is devised\nto acquire high-frequency semantic information. Secondly, we design a hyper\ncross-attention module (HCAM) to extract low-frequency information and preserve\ntexture features from source images. Finally, a relevant loss function is\ndesigned to guide the holistic network learning, thereby achieving better image\nfusion. Extensive experiments demonstrate that our proposed approach\noutperforms state-of-the-art alternatives in terms of qualitative and\nquantitative evaluations. Particularly, DFVO can generate clearer, more\ninformative, and more evenly illuminated fusion results in the dark\nenvironments, achieving best performance on the LLVIP dataset with 63.258 dB\nPSNR and 0.724 CC, providing more effective information for high-level vision\ntasks. Our code is publicly accessible at https://github.com/DaVin-Qi530/DFVO.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.04526v1",
    "published_date": "2025-05-07 15:59:45 UTC",
    "updated_date": "2025-05-07 15:59:45 UTC"
  },
  {
    "arxiv_id": "2505.04525v1",
    "title": "On some improvements to Unbounded Minimax",
    "authors": [
      "Quentin Cohen-Solal",
      "Tristan Cazenave"
    ],
    "abstract": "This paper presents the first experimental evaluation of four previously\nuntested modifications of Unbounded Best-First Minimax algorithm. This\nalgorithm explores the game tree by iteratively expanding the most promising\nsequences of actions based on the current partial game tree. We first evaluate\nthe use of transposition tables, which convert the game tree into a directed\nacyclic graph by merging duplicate states. Second, we compare the original\nalgorithm by Korf & Chickering with the variant proposed by Cohen-Solal, which\ndiffers in its backpropagation strategy: instead of stopping when a stable\nvalue is encountered, it updates values up to the root. This change slightly\nimproves performance when value ties or transposition tables are involved.\nThird, we assess replacing the exact terminal evaluation function with the\nlearned heuristic function. While beneficial when exact evaluations are costly,\nthis modification reduces performance in inexpensive settings. Finally, we\nexamine the impact of the completion technique that prioritizes resolved\nwinning states and avoids resolved losing states. This technique also improves\nperformance. Overall, our findings highlight how targeted modifications can\nenhance the efficiency of Unbounded Best-First Minimax.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.04525v1",
    "published_date": "2025-05-07 15:59:19 UTC",
    "updated_date": "2025-05-07 15:59:19 UTC"
  },
  {
    "arxiv_id": "2505.04497v2",
    "title": "Defining and Quantifying Creative Behavior in Popular Image Generators",
    "authors": [
      "Aditi Ramaswamy",
      "Hana Chockler",
      "Melane Navaratnarajah"
    ],
    "abstract": "Creativity of generative AI models has been a subject of scientific debate in\nthe last years, without a conclusive answer. In this paper, we study creativity\nfrom a practical perspective and introduce quantitative measures that help the\nuser to choose a suitable AI model for a given task. We evaluated our measures\non a number of popular image-to-image generation models, and the results of\nthis suggest that our measures conform to human intuition.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "I.4.m; I.2.m"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.04497v2",
    "published_date": "2025-05-07 15:20:17 UTC",
    "updated_date": "2025-05-08 11:59:21 UTC"
  },
  {
    "arxiv_id": "2505.04493v1",
    "title": "Model-Based AI planning and Execution Systems for Robotics",
    "authors": [
      "Or Wertheim",
      "Ronen I. Brafman"
    ],
    "abstract": "Model-based planning and execution systems offer a principled approach to\nbuilding flexible autonomous robots that can perform diverse tasks by\nautomatically combining a host of basic skills. This idea is almost as old as\nmodern robotics. Yet, while diverse general-purpose reasoning architectures\nhave been proposed since, general-purpose systems that are integrated with\nmodern robotic platforms have emerged only recently, starting with the\ninfluential ROSPlan system. Since then, a growing number of model-based systems\nfor robot task-level control have emerged. In this paper, we consider the\ndiverse design choices and issues existing systems attempt to address, the\ndifferent solutions proposed so far, and suggest avenues for future\ndevelopment.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.04493v1",
    "published_date": "2025-05-07 15:17:38 UTC",
    "updated_date": "2025-05-07 15:17:38 UTC"
  },
  {
    "arxiv_id": "2505.04488v1",
    "title": "\"I Can See Forever!\": Evaluating Real-time VideoLLMs for Assisting Individuals with Visual Impairments",
    "authors": [
      "Ziyi Zhang",
      "Zhen Sun",
      "Zongmin Zhang",
      "Zifan Peng",
      "Yuemeng Zhao",
      "Zichun Wang",
      "Zeren Luo",
      "Ruiting Zuo",
      "Xinlei He"
    ],
    "abstract": "The visually impaired population, especially the severely visually impaired,\nis currently large in scale, and daily activities pose significant challenges\nfor them. Although many studies use large language and vision-language models\nto assist the blind, most focus on static content and fail to meet real-time\nperception needs in dynamic and complex environments, such as daily activities.\nTo provide them with more effective intelligent assistance, it is imperative to\nincorporate advanced visual understanding technologies. Although real-time\nvision and speech interaction VideoLLMs demonstrate strong real-time visual\nunderstanding, no prior work has systematically evaluated their effectiveness\nin assisting visually impaired individuals. In this work, we conduct the first\nsuch evaluation. First, we construct a benchmark dataset (VisAssistDaily),\ncovering three categories of assistive tasks for visually impaired individuals:\nBasic Skills, Home Life Tasks, and Social Life Tasks. The results show that\nGPT-4o achieves the highest task success rate. Next, we conduct a user study to\nevaluate the models in both closed-world and open-world scenarios, further\nexploring the practical challenges of applying VideoLLMs in assistive contexts.\nOne key issue we identify is the difficulty current models face in perceiving\npotential hazards in dynamic environments. To address this, we build an\nenvironment-awareness dataset named SafeVid and introduce a polling mechanism\nthat enables the model to proactively detect environmental risks. We hope this\nwork provides valuable insights and inspiration for future research in this\nfield.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.HC",
      "cs.MM"
    ],
    "primary_category": "cs.CV",
    "comment": "12 pages, 6 figures",
    "pdf_url": "http://arxiv.org/pdf/2505.04488v1",
    "published_date": "2025-05-07 15:03:16 UTC",
    "updated_date": "2025-05-07 15:03:16 UTC"
  },
  {
    "arxiv_id": "2505.04486v1",
    "title": "Efficient Flow Matching using Latent Variables",
    "authors": [
      "Anirban Samaddar",
      "Yixuan Sun",
      "Viktor Nilsson",
      "Sandeep Madireddy"
    ],
    "abstract": "Flow matching models have shown great potential in image generation tasks\namong probabilistic generative models. Building upon the ideas of continuous\nnormalizing flows, flow matching models generalize the transport path of the\ndiffusion models from a simple prior distribution to the data. Most flow\nmatching models in the literature do not explicitly model the underlying\nstructure/manifold in the target data when learning the flow from a simple\nsource distribution like the standard Gaussian. This leads to inefficient\nlearning, especially for many high-dimensional real-world datasets, which often\nreside in a low-dimensional manifold. Existing strategies of incorporating\nmanifolds, including data with underlying multi-modal distribution, often\nrequire expensive training and hence frequently lead to suboptimal performance.\nTo this end, we present \\texttt{Latent-CFM}, which provides simplified\ntraining/inference strategies to incorporate multi-modal data structures using\npretrained deep latent variable models. Through experiments on multi-modal\nsynthetic data and widely used image benchmark datasets, we show that\n\\texttt{Latent-CFM} exhibits improved generation quality with significantly\nless training ($\\sim 50\\%$ less in some cases) and computation than\nstate-of-the-art flow matching models. Using a 2d Darcy flow dataset, we\ndemonstrate that our approach generates more physically accurate samples than\ncompetitive approaches. In addition, through latent space analysis, we\ndemonstrate that our approach can be used for conditional image generation\nconditioned on latent features.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.04486v1",
    "published_date": "2025-05-07 14:59:23 UTC",
    "updated_date": "2025-05-07 14:59:23 UTC"
  },
  {
    "arxiv_id": "2505.04480v1",
    "title": "TrajEvo: Designing Trajectory Prediction Heuristics via LLM-driven Evolution",
    "authors": [
      "Zhikai Zhao",
      "Chuanbo Hua",
      "Federico Berto",
      "Kanghoon Lee",
      "Zihan Ma",
      "Jiachen Li",
      "Jinkyoo Park"
    ],
    "abstract": "Trajectory prediction is a crucial task in modeling human behavior,\nespecially in fields as social robotics and autonomous vehicle navigation.\nTraditional heuristics based on handcrafted rules often lack accuracy, while\nrecently proposed deep learning approaches suffer from computational cost, lack\nof explainability, and generalization issues that limit their practical\nadoption. In this paper, we introduce TrajEvo, a framework that leverages Large\nLanguage Models (LLMs) to automatically design trajectory prediction\nheuristics. TrajEvo employs an evolutionary algorithm to generate and refine\nprediction heuristics from past trajectory data. We introduce a\nCross-Generation Elite Sampling to promote population diversity and a\nStatistics Feedback Loop allowing the LLM to analyze alternative predictions.\nOur evaluations show TrajEvo outperforms previous heuristic methods on the\nETH-UCY datasets, and remarkably outperforms both heuristics and deep learning\nmethods when generalizing to the unseen SDD dataset. TrajEvo represents a first\nstep toward automated design of fast, explainable, and generalizable trajectory\nprediction heuristics. We make our source code publicly available to foster\nfuture research at https://github.com/ai4co/trajevo.",
    "categories": [
      "cs.AI",
      "cs.NE",
      "cs.RO"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.04480v1",
    "published_date": "2025-05-07 14:51:43 UTC",
    "updated_date": "2025-05-07 14:51:43 UTC"
  },
  {
    "arxiv_id": "2505.05516v1",
    "title": "AI-powered virtual eye: perspective, challenges and opportunities",
    "authors": [
      "Yue Wu",
      "Yibo Guo",
      "Yulong Yan",
      "Jiancheng Yang",
      "Xin Zhou",
      "Ching-Yu Cheng",
      "Danli Shi",
      "Mingguang He"
    ],
    "abstract": "We envision the \"virtual eye\" as a next-generation, AI-powered platform that\nuses interconnected foundation models to simulate the eye's intricate structure\nand biological function across all scales. Advances in AI, imaging, and\nmultiomics provide a fertile ground for constructing a universal, high-fidelity\ndigital replica of the human eye. This perspective traces the evolution from\nearly mechanistic and rule-based models to contemporary AI-driven approaches,\nintegrating in a unified model with multimodal, multiscale, dynamic predictive\ncapabilities and embedded feedback mechanisms. We propose a development roadmap\nemphasizing the roles of large-scale multimodal datasets, generative AI,\nfoundation models, agent-based architectures, and interactive interfaces.\nDespite challenges in interpretability, ethics, data processing and evaluation,\nthe virtual eye holds the potential to revolutionize personalized ophthalmic\ncare and accelerate research into ocular health and disease.",
    "categories": [
      "q-bio.TO",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "q-bio.TO",
    "comment": "30 Pages, 3 figures, 1 table",
    "pdf_url": "http://arxiv.org/pdf/2505.05516v1",
    "published_date": "2025-05-07 14:48:56 UTC",
    "updated_date": "2025-05-07 14:48:56 UTC"
  },
  {
    "arxiv_id": "2505.04468v1",
    "title": "Spectral and Temporal Denoising for Differentially Private Optimization",
    "authors": [
      "Hyeju Shin",
      "Kyudan Jung",
      "Seongwon Yun",
      "Juyoung Yun"
    ],
    "abstract": "This paper introduces the FFT-Enhanced Kalman Filter (FFTKF), a\ndifferentially private optimization method that addresses the challenge of\npreserving performance in DP-SGD, where added noise typically degrades model\nutility. FFTKF integrates frequency-domain noise shaping with Kalman filtering\nto enhance gradient quality while preserving $(\\varepsilon, \\delta)$-DP\nguarantees. It employs a high-frequency shaping mask in the Fourier domain to\nconcentrate differential privacy noise in less informative spectral components,\npreserving low-frequency gradient signals. A scalar-gain Kalman filter with\nfinite-difference Hessian approximation further refines the denoised gradients.\nWith a per-iteration complexity of $\\mathcal{O}(d \\log d)$, FFTKF demonstrates\nimproved test accuracy over DP-SGD and DiSK across MNIST, CIFAR-10, CIFAR-100,\nand Tiny-ImageNet datasets using CNNs, Wide ResNets, and Vision Transformers.\nTheoretical analysis confirms that FFTKF maintains equivalent privacy\nguarantees while achieving a tighter privacy-utility trade-off through reduced\nnoise and controlled bias.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.IT",
      "cs.NE",
      "math.IT"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.04468v1",
    "published_date": "2025-05-07 14:38:58 UTC",
    "updated_date": "2025-05-07 14:38:58 UTC"
  },
  {
    "arxiv_id": "2505.04464v1",
    "title": "Discriminative Ordering Through Ensemble Consensus",
    "authors": [
      "Louis Ohl",
      "Fredrik Lindsten"
    ],
    "abstract": "Evaluating the performance of clustering models is a challenging task where\nthe outcome depends on the definition of what constitutes a cluster. Due to\nthis design, current existing metrics rarely handle multiple clustering models\nwith diverse cluster definitions, nor do they comply with the integration of\nconstraints when available. In this work, we take inspiration from consensus\nclustering and assume that a set of clustering models is able to uncover hidden\nstructures in the data. We propose to construct a discriminative ordering\nthrough ensemble clustering based on the distance between the connectivity of a\nclustering model and the consensus matrix. We first validate the proposed\nmethod with synthetic scenarios, highlighting that the proposed score ranks the\nmodels that best match the consensus first. We then show that this simple\nranking score significantly outperforms other scoring methods when comparing\nsets of different clustering algorithms that are not restricted to a fixed\nnumber of clusters and is compatible with clustering constraints.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "62H30",
      "G.3"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted at UAI 2025",
    "pdf_url": "http://arxiv.org/pdf/2505.04464v1",
    "published_date": "2025-05-07 14:35:39 UTC",
    "updated_date": "2025-05-07 14:35:39 UTC"
  },
  {
    "arxiv_id": "2505.04461v1",
    "title": "A Survey on Temporal Interaction Graph Representation Learning: Progress, Challenges, and Opportunities",
    "authors": [
      "Pengfei Jiao",
      "Hongjiang Chen",
      "Xuan Guo",
      "Zhidong Zhao",
      "Dongxiao He",
      "Di Jin"
    ],
    "abstract": "Temporal interaction graphs (TIGs), defined by sequences of timestamped\ninteraction events, have become ubiquitous in real-world applications due to\ntheir capability to model complex dynamic system behaviors. As a result,\ntemporal interaction graph representation learning (TIGRL) has garnered\nsignificant attention in recent years. TIGRL aims to embed nodes in TIGs into\nlow-dimensional representations that effectively preserve both structural and\ntemporal information, thereby enhancing the performance of downstream tasks\nsuch as classification, prediction, and clustering within constantly evolving\ndata environments. In this paper, we begin by introducing the foundational\nconcepts of TIGs and emphasize the critical role of temporal dependencies. We\nthen propose a comprehensive taxonomy of state-of-the-art TIGRL methods,\nsystematically categorizing them based on the types of information utilized\nduring the learning process to address the unique challenges inherent to TIGs.\nTo facilitate further research and practical applications, we curate the source\nof datasets and benchmarks, providing valuable resources for empirical\ninvestigations. Finally, we examine key open challenges and explore promising\nresearch directions in TIGRL, laying the groundwork for future advancements\nthat have the potential to shape the evolution of this field.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.SI"
    ],
    "primary_category": "cs.LG",
    "comment": "IJCAI 2025 Survey Track",
    "pdf_url": "http://arxiv.org/pdf/2505.04461v1",
    "published_date": "2025-05-07 14:31:10 UTC",
    "updated_date": "2025-05-07 14:31:10 UTC"
  },
  {
    "arxiv_id": "2505.04451v1",
    "title": "Automatic Music Transcription using Convolutional Neural Networks and Constant-Q transform",
    "authors": [
      "Yohannis Telila",
      "Tommaso Cucinotta",
      "Davide Bacciu"
    ],
    "abstract": "Automatic music transcription (AMT) is the problem of analyzing an audio\nrecording of a musical piece and detecting notes that are being played. AMT is\na challenging problem, particularly when it comes to polyphonic music. The goal\nof AMT is to produce a score representation of a music piece, by analyzing a\nsound signal containing multiple notes played simultaneously. In this work, we\ndesign a processing pipeline that can transform classical piano audio files in\n.wav format into a music score representation. The features from the audio\nsignals are extracted using the constant-Q transform, and the resulting\ncoefficients are used as an input to the convolutional neural network (CNN)\nmodel.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.LG",
      "cs.MM",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "6 pages",
    "pdf_url": "http://arxiv.org/pdf/2505.04451v1",
    "published_date": "2025-05-07 14:20:43 UTC",
    "updated_date": "2025-05-07 14:20:43 UTC"
  },
  {
    "arxiv_id": "2505.04435v1",
    "title": "FedBWO: Enhancing Communication Efficiency in Federated Learning",
    "authors": [
      "Vahideh Hayyolalam",
      "Öznur Özkasap"
    ],
    "abstract": "Federated Learning (FL) is a distributed Machine Learning (ML) setup, where a\nshared model is collaboratively trained by various clients using their local\ndatasets while keeping the data private. Considering resource-constrained\ndevices, FL clients often suffer from restricted transmission capacity. Aiming\nto enhance the system performance, the communication between clients and server\nneeds to be diminished. Current FL strategies transmit a tremendous amount of\ndata (model weights) within the FL process, which needs a high communication\nbandwidth. Considering resource constraints, increasing the number of clients\nand, consequently, the amount of data (model weights) can lead to a bottleneck.\nIn this paper, we introduce the Federated Black Widow Optimization (FedBWO)\ntechnique to decrease the amount of transmitted data by transmitting only a\nperformance score rather than the local model weights from clients. FedBWO\nemploys the BWO algorithm to improve local model updates. The conducted\nexperiments prove that FedBWO remarkably improves the performance of the global\nmodel and the communication efficiency of the overall system. According to the\nexperimental outcomes, FedBWO enhances the global model accuracy by an average\nof 21% over FedAvg, and 12% over FedGWO. Furthermore, FedBWO dramatically\ndecreases the communication cost compared to other methods.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "5th IEEE International Conference on Human-Machine Systems, Abu\n  Dhabi, UAE, 26-28 May 2025",
    "pdf_url": "http://arxiv.org/pdf/2505.04435v1",
    "published_date": "2025-05-07 14:02:35 UTC",
    "updated_date": "2025-05-07 14:02:35 UTC"
  },
  {
    "arxiv_id": "2505.04419v1",
    "title": "Recognizing Ornaments in Vocal Indian Art Music with Active Annotation",
    "authors": [
      "Sumit Kumar",
      "Parampreet Singh",
      "Vipul Arora"
    ],
    "abstract": "Ornamentations, embellishments, or microtonal inflections are essential to\nmelodic expression across many musical traditions, adding depth, nuance, and\nemotional impact to performances. Recognizing ornamentations in singing voices\nis key to MIR, with potential applications in music pedagogy, singer\nidentification, genre classification, and controlled singing voice generation.\nHowever, the lack of annotated datasets and specialized modeling approaches\nremains a major obstacle for progress in this research area. In this work, we\nintroduce R\\=aga Ornamentation Detection (ROD), a novel dataset comprising\nIndian classical music recordings curated by expert musicians. The dataset is\nannotated using a custom Human-in-the-Loop tool for six vocal ornaments marked\nas event-based labels. Using this dataset, we develop an ornamentation\ndetection model based on deep time-series analysis, preserving ornament\nboundaries during the chunking of long audio recordings. We conduct experiments\nusing different train-test configurations within the ROD dataset and also\nevaluate our approach on a separate, manually annotated dataset of Indian\nclassical concert recordings. Our experimental results support the superior\nperformance of our proposed approach over the baseline CRNN.",
    "categories": [
      "eess.AS",
      "cs.AI",
      "cs.LG",
      "cs.SD"
    ],
    "primary_category": "eess.AS",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.04419v1",
    "published_date": "2025-05-07 13:52:50 UTC",
    "updated_date": "2025-05-07 13:52:50 UTC"
  },
  {
    "arxiv_id": "2505.04416v1",
    "title": "OBLIVIATE: Robust and Practical Machine Unlearning for Large Language Models",
    "authors": [
      "Xiaoyu Xu",
      "Minxin Du",
      "Qingqing Ye",
      "Haibo Hu"
    ],
    "abstract": "Large language models (LLMs) trained over extensive corpora risk memorizing\nsensitive, copyrighted, or toxic content. To address this, we propose\nOBLIVIATE, a robust unlearning framework that removes targeted data while\npreserving model utility. The framework follows a structured process:\nextracting target tokens, building retain sets, and fine-tuning with a tailored\nloss function comprising three components -- masking, distillation, and world\nfact. Using low-rank adapters (LoRA), it ensures efficiency without\ncompromising unlearning quality. We conduct experiments on multiple datasets,\nincluding the Harry Potter series, WMDP, and TOFU, using a comprehensive suite\nof metrics: forget quality (new document-level memorization score), model\nutility, and fluency. Results demonstrate its effectiveness in resisting\nmembership inference attacks, minimizing the impact on retained data, and\nmaintaining robustness across diverse scenarios.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CR",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "18 pages, 2 figures",
    "pdf_url": "http://arxiv.org/pdf/2505.04416v1",
    "published_date": "2025-05-07 13:51:42 UTC",
    "updated_date": "2025-05-07 13:51:42 UTC"
  },
  {
    "arxiv_id": "2505.04406v1",
    "title": "YABLoCo: Yet Another Benchmark for Long Context Code Generation",
    "authors": [
      "Aidar Valeev",
      "Roman Garaev",
      "Vadim Lomshakov",
      "Irina Piontkovskaya",
      "Vladimir Ivanov",
      "Israel Adewuyi"
    ],
    "abstract": "Large Language Models demonstrate the ability to solve various programming\ntasks, including code generation. Typically, the performance of LLMs is\nmeasured on benchmarks with small or medium-sized context windows of thousands\nof lines of code. At the same time, in real-world software projects,\nrepositories can span up to millions of LoC. This paper closes this gap by\ncontributing to the long context code generation benchmark (YABLoCo). The\nbenchmark featured a test set of 215 functions selected from four large\nrepositories with thousands of functions. The dataset contained metadata of\nfunctions, contexts of the functions with different levels of dependencies,\ndocstrings, functions bodies, and call graphs for each repository. This paper\npresents three key aspects of the contribution. First, the benchmark aims at\nfunction body generation in large repositories in C and C++, two languages not\ncovered by previous benchmarks. Second, the benchmark contains large\nrepositories from 200K to 2,000K LoC. Third, we contribute a scalable\nevaluation pipeline for efficient computing of the target metrics and a tool\nfor visual analysis of generated code. Overall, these three aspects allow for\nevaluating code generation in large repositories in C and C++.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.SE"
    ],
    "primary_category": "cs.CL",
    "comment": "Presented at LLM4Code 2025 Workshop co-located wtih ICSE 2025",
    "pdf_url": "http://arxiv.org/pdf/2505.04406v1",
    "published_date": "2025-05-07 13:42:23 UTC",
    "updated_date": "2025-05-07 13:42:23 UTC"
  },
  {
    "arxiv_id": "2505.04405v1",
    "title": "High-speed multiwavelength photonic temporal integration using silicon photonics",
    "authors": [
      "Yi Zhang",
      "Nikolaos Farmakidis",
      "Ioannis Roumpos",
      "Miltiadis Moralis-Pegios",
      "Apostolos Tsakyridis",
      "June Sang Lee",
      "Bowei Dong",
      "Yuhan He",
      "Samarth Aggarwal",
      "Nikolaos Pleros",
      "Harish Bhaskaran"
    ],
    "abstract": "Optical systems have been pivotal for energy-efficient computing, performing\nhigh-speed, parallel operations in low-loss carriers. While these predominantly\nanalog optical accelerators bypass digitization to perform parallel\nfloating-point computations, scaling optical hardware to map large-vector sizes\nfor AI tasks remains challenging. Here, we overcome this limitation by\nunfolding scalar operations in time and introducing a\nphotonic-heater-in-lightpath (PHIL) unit for all-optical temporal integration.\nCounterintuitively, we exploit a slow heat dissipation process to integrate\noptical signals modulated at 50 GHz bridging the speed gap between the widely\napplied thermo-optic effects and ultrafast photonics. This architecture\nsupports optical end-to-end signal processing, eliminates inefficient\nelectro-optical conversions, and enables both linear and nonlinear operations\nwithin a unified framework. Our results demonstrate a scalable path towards\nhigh-speed photonic computing through thermally driven integration.",
    "categories": [
      "physics.optics",
      "cs.AI",
      "physics.app-ph"
    ],
    "primary_category": "physics.optics",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.04405v1",
    "published_date": "2025-05-07 13:39:18 UTC",
    "updated_date": "2025-05-07 13:39:18 UTC"
  },
  {
    "arxiv_id": "2505.04404v2",
    "title": "In-Context Adaptation to Concept Drift for Learned Database Operations",
    "authors": [
      "Jiaqi Zhu",
      "Shaofeng Cai",
      "Yanyan Shen",
      "Gang Chen",
      "Fang Deng",
      "Beng Chin Ooi"
    ],
    "abstract": "Machine learning has demonstrated transformative potential for database\noperations, such as query optimization and in-database data analytics. However,\ndynamic database environments, characterized by frequent updates and evolving\ndata distributions, introduce concept drift, which leads to performance\ndegradation for learned models and limits their practical applicability.\nAddressing this challenge requires efficient frameworks capable of adapting to\nshifting concepts while minimizing the overhead of retraining or fine-tuning.\n  In this paper, we propose FLAIR, an online adaptation framework that\nintroduces a new paradigm called \\textit{in-context adaptation} for learned\ndatabase operations. FLAIR leverages the inherent property of data systems,\ni.e., immediate availability of execution results for predictions, to enable\ndynamic context construction. By formalizing adaptation as $f:(\\mathbf{x} \\,|\n\\,C_t) \\to \\mathbf{y}$, with $C_t$ representing a dynamic context memory, FLAIR\ndelivers predictions aligned with the current concept, eliminating the need for\nruntime parameter optimization. To achieve this, FLAIR integrates two key\nmodules: a Task Featurization Module for encoding task-specific features into\nstandardized representations, and a Dynamic Decision Engine, pre-trained via\nBayesian meta-training, to adapt seamlessly using contextual information at\nruntime. Extensive experiments across key database tasks demonstrate that FLAIR\noutperforms state-of-the-art baselines, achieving up to 5.2x faster adaptation\nand reducing error by 22.5% for cardinality estimation.",
    "categories": [
      "cs.DB",
      "cs.AI"
    ],
    "primary_category": "cs.DB",
    "comment": "Accepted by ICML 2025",
    "pdf_url": "http://arxiv.org/pdf/2505.04404v2",
    "published_date": "2025-05-07 13:36:59 UTC",
    "updated_date": "2025-05-22 06:16:01 UTC"
  },
  {
    "arxiv_id": "2505.04397v1",
    "title": "Deep residual learning with product units",
    "authors": [
      "Ziyuan Li",
      "Uwe Jaekel",
      "Babette Dellen"
    ],
    "abstract": "We propose a deep product-unit residual neural network (PURe) that integrates\nproduct units into residual blocks to improve the expressiveness and parameter\nefficiency of deep convolutional networks. Unlike standard summation neurons,\nproduct units enable multiplicative feature interactions, potentially offering\na more powerful representation of complex patterns. PURe replaces conventional\nconvolutional layers with 2D product units in the second layer of each residual\nblock, eliminating nonlinear activation functions to preserve structural\ninformation. We validate PURe on three benchmark datasets. On Galaxy10 DECaLS,\nPURe34 achieves the highest test accuracy of 84.89%, surpassing the much deeper\nResNet152, while converging nearly five times faster and demonstrating strong\nrobustness to Poisson noise. On ImageNet, PURe architectures outperform\nstandard ResNet models at similar depths, with PURe34 achieving a top-1\naccuracy of 80.27% and top-5 accuracy of 95.78%, surpassing deeper ResNet\nvariants (ResNet50, ResNet101) while utilizing significantly fewer parameters\nand computational resources. On CIFAR-10, PURe consistently outperforms ResNet\nvariants across varying depths, with PURe272 reaching 95.01% test accuracy,\ncomparable to ResNet1001 but at less than half the model size. These results\ndemonstrate that PURe achieves a favorable balance between accuracy,\nefficiency, and robustness. Compared to traditional residual networks, PURe not\nonly achieves competitive classification performance with faster convergence\nand fewer parameters, but also demonstrates greater robustness to noise. Its\neffectiveness across diverse datasets highlights the potential of\nproduct-unit-based architectures for scalable and reliable deep learning in\ncomputer vision.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "eess.IV"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.04397v1",
    "published_date": "2025-05-07 13:21:25 UTC",
    "updated_date": "2025-05-07 13:21:25 UTC"
  },
  {
    "arxiv_id": "2505.04388v1",
    "title": "The Aloe Family Recipe for Open and Specialized Healthcare LLMs",
    "authors": [
      "Dario Garcia-Gasulla",
      "Jordi Bayarri-Planas",
      "Ashwin Kumar Gururajan",
      "Enrique Lopez-Cuena",
      "Adrian Tormos",
      "Daniel Hinjos",
      "Pablo Bernabeu-Perez",
      "Anna Arias-Duart",
      "Pablo Agustin Martin-Torres",
      "Marta Gonzalez-Mallo",
      "Sergio Alvarez-Napagao",
      "Eduard Ayguadé-Parra",
      "Ulises Cortés"
    ],
    "abstract": "Purpose: With advancements in Large Language Models (LLMs) for healthcare,\nthe need arises for competitive open-source models to protect the public\ninterest. This work contributes to the field of open medical LLMs by optimizing\nkey stages of data preprocessing and training, while showing how to improve\nmodel safety (through DPO) and efficacy (through RAG). The evaluation\nmethodology used, which includes four different types of tests, defines a new\nstandard for the field. The resultant models, shown to be competitive with the\nbest private alternatives, are released with a permisive license.\n  Methods: Building on top of strong base models like Llama 3.1 and Qwen 2.5,\nAloe Beta uses a custom dataset to enhance public data with synthetic Chain of\nThought examples. The models undergo alignment with Direct Preference\nOptimization, emphasizing ethical and policy-aligned performance in the\npresence of jailbreaking attacks. Evaluation includes close-ended, open-ended,\nsafety and human assessments, to maximize the reliability of results.\n  Results: Recommendations are made across the entire pipeline, backed by the\nsolid performance of the Aloe Family. These models deliver competitive\nperformance across healthcare benchmarks and medical fields, and are often\npreferred by healthcare professionals. On bias and toxicity, the Aloe Beta\nmodels significantly improve safety, showing resilience to unseen jailbreaking\nattacks. For a responsible release, a detailed risk assessment specific to\nhealthcare is attached to the Aloe Family models.\n  Conclusion: The Aloe Beta models, and the recipe that leads to them, are a\nsignificant contribution to the open-source medical LLM field, offering\ntop-of-the-line performance while maintaining high ethical requirements. This\nwork sets a new standard for developing and reporting aligned LLMs in\nhealthcare.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "arXiv admin note: substantial text overlap with arXiv:2405.01886",
    "pdf_url": "http://arxiv.org/pdf/2505.04388v1",
    "published_date": "2025-05-07 13:13:14 UTC",
    "updated_date": "2025-05-07 13:13:14 UTC"
  },
  {
    "arxiv_id": "2505.04379v1",
    "title": "Consensus-Aware AV Behavior: Trade-offs Between Safety, Interaction, and Performance in Mixed Urban Traffic",
    "authors": [
      "Mohammad Elayan",
      "Wissam Kontar"
    ],
    "abstract": "Transportation systems have long been shaped by complexity and heterogeneity,\ndriven by the interdependency of agent actions and traffic outcomes. The\ndeployment of automated vehicles (AVs) in such systems introduces a new\nchallenge: achieving consensus across safety, interaction quality, and traffic\nperformance. In this work, we position consensus as a fundamental property of\nthe traffic system and aim to quantify it. We use high-resolution trajectory\ndata from the Third Generation Simulation (TGSIM) dataset to empirically\nanalyze AV and human-driven vehicle (HDV) behavior at a signalized urban\nintersection and around vulnerable road users (VRUs). Key metrics, including\nTime-to-Collision (TTC), Post-Encroachment Time (PET), deceleration patterns,\nheadways, and string stability, are evaluated across the three performance\ndimensions. Results show that full consensus across safety, interaction, and\nperformance is rare, with only 1.63% of AV-VRU interaction frames meeting all\nthree conditions. These findings highlight the need for AV models that\nexplicitly balance multi-dimensional performance in mixed-traffic environments.\nFull reproducibility is supported via our open-source codebase on\nhttps://github.com/wissamkontar/Consensus-AV-Analysis.",
    "categories": [
      "cs.MA",
      "cs.AI",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.MA",
    "comment": "7 pages, 8 figures",
    "pdf_url": "http://arxiv.org/pdf/2505.04379v1",
    "published_date": "2025-05-07 12:59:59 UTC",
    "updated_date": "2025-05-07 12:59:59 UTC"
  },
  {
    "arxiv_id": "2505.04375v1",
    "title": "Balancing Accuracy, Calibration, and Efficiency in Active Learning with Vision Transformers Under Label Noise",
    "authors": [
      "Moseli Mots'oehli",
      "Hope Mogale",
      "Kyungim Baek"
    ],
    "abstract": "Fine-tuning pre-trained convolutional neural networks on ImageNet for\ndownstream tasks is well-established. Still, the impact of model size on the\nperformance of vision transformers in similar scenarios, particularly under\nlabel noise, remains largely unexplored. Given the utility and versatility of\ntransformer architectures, this study investigates their practicality under\nlow-budget constraints and noisy labels. We explore how classification accuracy\nand calibration are affected by symmetric label noise in active learning\nsettings, evaluating four vision transformer configurations (Base and Large\nwith 16x16 and 32x32 patch sizes) and three Swin Transformer configurations\n(Tiny, Small, and Base) on CIFAR10 and CIFAR100 datasets, under varying label\nnoise rates. Our findings show that larger ViT models (ViTl32 in particular)\nconsistently outperform their smaller counterparts in both accuracy and\ncalibration, even under moderate to high label noise, while Swin Transformers\nexhibit weaker robustness across all noise levels. We find that smaller patch\nsizes do not always lead to better performance, as ViTl16 performs consistently\nworse than ViTl32 while incurring a higher computational cost. We also find\nthat information-based Active Learning strategies only provide meaningful\naccuracy improvements at moderate label noise rates, but they result in poorer\ncalibration compared to models trained on randomly acquired labels, especially\nat high label noise rates. We hope these insights provide actionable guidance\nfor practitioners looking to deploy vision transformers in resource-constrained\nenvironments, where balancing model complexity, label noise, and compute\nefficiency is critical in model fine-tuning or distillation.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.04375v1",
    "published_date": "2025-05-07 12:53:13 UTC",
    "updated_date": "2025-05-07 12:53:13 UTC"
  },
  {
    "arxiv_id": "2505.04354v1",
    "title": "Optimization Problem Solving Can Transition to Evolutionary Agentic Workflows",
    "authors": [
      "Wenhao Li",
      "Bo Jin",
      "Mingyi Hong",
      "Changhong Lu",
      "Xiangfeng Wang"
    ],
    "abstract": "This position paper argues that optimization problem solving can transition\nfrom expert-dependent to evolutionary agentic workflows. Traditional\noptimization practices rely on human specialists for problem formulation,\nalgorithm selection, and hyperparameter tuning, creating bottlenecks that\nimpede industrial adoption of cutting-edge methods. We contend that an\nevolutionary agentic workflow, powered by foundation models and evolutionary\nsearch, can autonomously navigate the optimization space, comprising problem,\nformulation, algorithm, and hyperparameter spaces. Through case studies in\ncloud resource scheduling and ADMM parameter adaptation, we demonstrate how\nthis approach can bridge the gap between academic innovation and industrial\nimplementation. Our position challenges the status quo of human-centric\noptimization workflows and advocates for a more scalable, adaptive approach to\nsolving real-world optimization problems.",
    "categories": [
      "math.OC",
      "cs.AI"
    ],
    "primary_category": "math.OC",
    "comment": "27 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2505.04354v1",
    "published_date": "2025-05-07 12:07:49 UTC",
    "updated_date": "2025-05-07 12:07:49 UTC"
  },
  {
    "arxiv_id": "2505.04678v1",
    "title": "Advanced Deep Learning Approaches for Automated Recognition of Cuneiform Symbols",
    "authors": [
      "Shahad Elshehaby",
      "Alavikunhu Panthakkan",
      "Hussain Al-Ahmad",
      "Mina Al-Saad"
    ],
    "abstract": "This paper presents a thoroughly automated method for identifying and\ninterpreting cuneiform characters via advanced deep-learning algorithms. Five\ndistinct deep-learning models were trained on a comprehensive dataset of\ncuneiform characters and evaluated according to critical performance metrics,\nincluding accuracy and precision. Two models demonstrated outstanding\nperformance and were subsequently assessed using cuneiform symbols from the\nHammurabi law acquisition, notably Hammurabi Law 1. Each model effectively\nrecognized the relevant Akkadian meanings of the symbols and delivered precise\nEnglish translations. Future work will investigate ensemble and stacking\napproaches to optimize performance, utilizing hybrid architectures to improve\ndetection accuracy and reliability. This research explores the linguistic\nrelationships between Akkadian, an ancient Mesopotamian language, and Arabic,\nemphasizing their historical and cultural linkages. This study demonstrates the\ncapability of deep learning to decipher ancient scripts by merging\ncomputational linguistics with archaeology, therefore providing significant\ninsights for the comprehension and conservation of human history.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.04678v1",
    "published_date": "2025-05-07 12:05:23 UTC",
    "updated_date": "2025-05-07 12:05:23 UTC"
  },
  {
    "arxiv_id": "2505.04352v1",
    "title": "Uncertain Machine Ethics Planning",
    "authors": [
      "Simon Kolker",
      "Louise A. Dennis",
      "Ramon Fraga Pereira",
      "Mengwei Xu"
    ],
    "abstract": "Machine Ethics decisions should consider the implications of uncertainty over\ndecisions. Decisions should be made over sequences of actions to reach\npreferable outcomes long term. The evaluation of outcomes, however, may invoke\none or more moral theories, which might have conflicting judgements. Each\ntheory will require differing representations of the ethical situation. For\nexample, Utilitarianism measures numerical values, Deontology analyses duties,\nand Virtue Ethics emphasises moral character. While balancing potentially\nconflicting moral considerations, decisions may need to be made, for example,\nto achieve morally neutral goals with minimal costs. In this paper, we\nformalise the problem as a Multi-Moral Markov Decision Process and a\nMulti-Moral Stochastic Shortest Path Problem. We develop a heuristic algorithm\nbased on Multi-Objective AO*, utilising Sven-Ove Hansson's Hypothetical\nRetrospection procedure for ethical reasoning under uncertainty. Our approach\nis validated by a case study from Machine Ethics literature: the problem of\nwhether to steal insulin for someone who needs it.",
    "categories": [
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.04352v1",
    "published_date": "2025-05-07 12:03:15 UTC",
    "updated_date": "2025-05-07 12:03:15 UTC"
  },
  {
    "arxiv_id": "2505.04340v1",
    "title": "Multi-Granular Attention based Heterogeneous Hypergraph Neural Network",
    "authors": [
      "Hong Jin",
      "Kaicheng Zhou",
      "Jie Yin",
      "Lan You",
      "Zhifeng Zhou"
    ],
    "abstract": "Heterogeneous graph neural networks (HeteGNNs) have demonstrated strong\nabilities to learn node representations by effectively extracting complex\nstructural and semantic information in heterogeneous graphs. Most of the\nprevailing HeteGNNs follow the neighborhood aggregation paradigm, leveraging\nmeta-path based message passing to learn latent node representations. However,\ndue to the pairwise nature of meta-paths, these models fail to capture\nhigh-order relations among nodes, resulting in suboptimal performance.\nAdditionally, the challenge of ``over-squashing'', where long-range message\npassing in HeteGNNs leads to severe information distortion, further limits the\nefficacy of these models. To address these limitations, this paper proposes\nMGA-HHN, a Multi-Granular Attention based Heterogeneous Hypergraph Neural\nNetwork for heterogeneous graph representation learning. MGA-HHN introduces two\nkey innovations: (1) a novel approach for constructing meta-path based\nheterogeneous hypergraphs that explicitly models higher-order semantic\ninformation in heterogeneous graphs through multiple views, and (2) a\nmulti-granular attention mechanism that operates at both the node and hyperedge\nlevels. This mechanism enables the model to capture fine-grained interactions\namong nodes sharing the same semantic context within a hyperedge type, while\npreserving the diversity of semantics across different hyperedge types. As\nsuch, MGA-HHN effectively mitigates long-range message distortion and generates\nmore expressive node representations. Extensive experiments on real-world\nbenchmark datasets demonstrate that MGA-HHN outperforms state-of-the-art\nmodels, showcasing its effectiveness in node classification, node clustering\nand visualization tasks.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.04340v1",
    "published_date": "2025-05-07 11:42:00 UTC",
    "updated_date": "2025-05-07 11:42:00 UTC"
  },
  {
    "arxiv_id": "2505.04339v1",
    "title": "Adaptive and Robust DBSCAN with Multi-agent Reinforcement Learning",
    "authors": [
      "Hao Peng",
      "Xiang Huang",
      "Shuo Sun",
      "Ruitong Zhang",
      "Philip S. Yu"
    ],
    "abstract": "DBSCAN, a well-known density-based clustering algorithm, has gained\nwidespread popularity and usage due to its effectiveness in identifying\nclusters of arbitrary shapes and handling noisy data. However, it encounters\nchallenges in producing satisfactory cluster results when confronted with\ndatasets of varying density scales, a common scenario in real-world\napplications. In this paper, we propose a novel Adaptive and Robust DBSCAN with\nMulti-agent Reinforcement Learning cluster framework, namely AR-DBSCAN. First,\nwe model the initial dataset as a two-level encoding tree and categorize the\ndata vertices into distinct density partitions according to the information\nuncertainty determined in the encoding tree. Each partition is then assigned to\nan agent to find the best clustering parameters without manual assistance. The\nallocation is density-adaptive, enabling AR-DBSCAN to effectively handle\ndiverse density distributions within the dataset by utilizing distinct agents\nfor different partitions. Second, a multi-agent deep reinforcement learning\nguided automatic parameter searching process is designed. The process of\nadjusting the parameter search direction by perceiving the clustering\nenvironment is modeled as a Markov decision process. Using a weakly-supervised\nreward training policy network, each agent adaptively learns the optimal\nclustering parameters by interacting with the clusters. Third, a recursive\nsearch mechanism adaptable to the data's scale is presented, enabling efficient\nand controlled exploration of large parameter spaces. Extensive experiments are\nconducted on nine artificial datasets and a real-world dataset. The results of\noffline and online tasks show that AR-DBSCAN not only improves clustering\naccuracy by up to 144.1% and 175.3% in the NMI and ARI metrics, respectively,\nbut also is capable of robustly finding dominant parameters.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.04339v1",
    "published_date": "2025-05-07 11:37:23 UTC",
    "updated_date": "2025-05-07 11:37:23 UTC"
  },
  {
    "arxiv_id": "2505.04677v1",
    "title": "Proceedings The 13th International Workshop on Theorem proving components for Educational software",
    "authors": [
      "Julien Narboux",
      "Walther Neuper",
      "Pedro Quaresma"
    ],
    "abstract": "The ThEdu series pursues the smooth transition from an intuitive way of doing\nmathematics at secondary school to a more formal approach to the subject in\nSTEM education while favoring software support for this transition by\nexploiting the power of theorem-proving technologies. What follows is a brief\ndescription of how the present volume contributes to this enterprise. The 13th\nInternational Workshop on Theorem Proving Components for Educational Software\n(ThEdu'24), was a satellite event of the CADE29, part of IJCAR 2024, Nancy,\nFrance. ThEdu'24 was a vibrant workshop, with one invited talk by Jeremy Avigad\n(Carnegie Mellon University) and 14 submitted talks. An open call for papers\nwas then issued and attracted 9 submissions. Eight of those submissions have\nbeen accepted by our reviewers. The resulting revised papers are collected in\nthe present volume. The contributions in this volume are a faithful\nrepresentation of the wide spectrum of ThEdu, ranging from those more focused\non the automated deduction research, not losing track of the possible\napplications in an educational setting, to those focused on the applications,\nin educational settings, of automated deduction tools and methods. We, the\nvolume editors, hope that this collection of papers will further promote the\ndevelopment of theorem-proving-based software and that it will allow to improve\nthe mutual understanding between computer scientists, mathematicians, and\nstakeholders in education. While this volume goes to press, the next edition of\nthe ThEdu workshop is being prepared: ThEdu'25 will be a satellite event of the\n30th international Conference on Automated DEduction (CADE-30), July 28th -\nAugust 2nd, 2025, Stuttgart, Germany.",
    "categories": [
      "cs.LO",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.LO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.04677v1",
    "published_date": "2025-05-07 11:30:54 UTC",
    "updated_date": "2025-05-07 11:30:54 UTC"
  },
  {
    "arxiv_id": "2505.06287v1",
    "title": "BedreFlyt: Improving Patient Flows through Hospital Wards with Digital Twins",
    "authors": [
      "Riccardo Sieve",
      "Paul Kobialka",
      "Laura Slaughter",
      "Rudolf Schlatte",
      "Einar Broch Johnsen",
      "Silvia Lizeth Tapia Tarifa"
    ],
    "abstract": "Digital twins are emerging as a valuable tool for short-term decision-making\nas well as for long-term strategic planning across numerous domains, including\nprocess industry, energy, space, transport, and healthcare. This paper reports\non our ongoing work on designing a digital twin to enhance resource planning,\ne.g., for the in-patient ward needs in hospitals. By leveraging executable\nformal models for system exploration, ontologies for knowledge representation\nand an SMT solver for constraint satisfiability, our approach aims to explore\nhypothetical \"what-if\" scenarios to improve strategic planning processes, as\nwell as to solve concrete, short-term decision-making tasks. Our proposed\nsolution uses the executable formal model to turn a stream of arriving\npatients, that need to be hospitalized, into a stream of optimization problems,\ne.g., capturing daily inpatient ward needs, that can be solved by SMT\ntechniques. The knowledge base, which formalizes domain knowledge, is used to\nmodel the needed configuration in the digital twin, allowing the twin to\nsupport both short-term decision-making and long-term strategic planning by\ngenerating scenarios spanning average-case as well as worst-case resource\nneeds, depending on the expected treatment of patients, as well as ranging over\nvariations in available resources, e.g., bed distribution in different rooms.\nWe illustrate our digital twin architecture by considering the problem of bed\nbay allocation in a hospital ward.",
    "categories": [
      "cs.AI",
      "cs.ET",
      "cs.LO",
      "D.2.2; D.2.4; J.3"
    ],
    "primary_category": "cs.AI",
    "comment": "In Proceedings ASQAP 2025, arXiv:2505.02873",
    "pdf_url": "http://arxiv.org/pdf/2505.06287v1",
    "published_date": "2025-05-07 11:23:39 UTC",
    "updated_date": "2025-05-07 11:23:39 UTC"
  },
  {
    "arxiv_id": "2505.07847v1",
    "title": "Conceptual Logical Foundations of Artificial Social Intelligence",
    "authors": [
      "Eric Werner"
    ],
    "abstract": "What makes a society possible at all? How is coordination and cooperation in\nsocial activity possible? What is the minimal mental architecture of a social\nagent? How is the information about the state of the world related to the\nagents intentions? How are the intentions of agents related? What role does\ncommunication play in this coordination process? This essay explores the\nconceptual and logical foundations of artificial social intelligence in the\ncontext of a society of multiple agents that communicate and cooperate to\nachieve some end. An attempt is made to provide an introduction to some of the\nkey concepts, their formal definitions and their interrelationships. These\ninclude the notion of a changing social world of multiple agents. The logic of\nsocial intelligence goes beyond classical logic by linking information with\nstrategic thought. A minimal architecture of social agents is presented. The\nagents have different dynamically changing, possible choices and abilities. The\nagents also have uncertainty, lacking perfect information about their physical\nstate as well as their dynamic social state. The social state of an agent\nincludes the intentional state of that agent, as well as, that agent's\nrepresentation of the intentional states of other agents. Furthermore, it\nincludes the evaluations agents make of their physical and social condition.\nCommunication, semantic and pragmatic meaning and their relationship to\nintention and information states are investigated. The logic of agent abilities\nand intentions are motivated and formalized. The entropy of group strategic\nstates is defined.",
    "categories": [
      "cs.AI",
      "cs.MA"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.07847v1",
    "published_date": "2025-05-07 11:06:23 UTC",
    "updated_date": "2025-05-07 11:06:23 UTC"
  },
  {
    "arxiv_id": "2505.04318v1",
    "title": "Detecting Concept Drift in Neural Networks Using Chi-squared Goodness of Fit Testing",
    "authors": [
      "Jacob Glenn Ayers",
      "Buvaneswari A. Ramanan",
      "Manzoor A. Khan"
    ],
    "abstract": "As the adoption of deep learning models has grown beyond human capacity for\nverification, meta-algorithms are needed to ensure reliable model inference.\nConcept drift detection is a field dedicated to identifying statistical shifts\nthat is underutilized in monitoring neural networks that may encounter\ninference data with distributional characteristics diverging from their\ntraining data. Given the wide variety of model architectures, applications, and\ndatasets, it is important that concept drift detection algorithms are adaptable\nto different inference scenarios. In this paper, we introduce an application of\nthe $\\chi^2$ Goodness of Fit Hypothesis Test as a drift detection\nmeta-algorithm applied to a multilayer perceptron, a convolutional neural\nnetwork, and a transformer trained for machine vision as they are exposed to\nsimulated drift during inference. To that end, we demonstrate how unexpected\ndrops in accuracy due to concept drift can be detected without directly\nexamining the inference outputs. Our approach enhances safety by ensuring\nmodels are continually evaluated for reliability across varying conditions.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "eess.IV"
    ],
    "primary_category": "cs.LG",
    "comment": "8 pages, 6 figures, 1 table",
    "pdf_url": "http://arxiv.org/pdf/2505.04318v1",
    "published_date": "2025-05-07 11:04:47 UTC",
    "updated_date": "2025-05-07 11:04:47 UTC"
  },
  {
    "arxiv_id": "2505.04317v1",
    "title": "Mastering Multi-Drone Volleyball through Hierarchical Co-Self-Play Reinforcement Learning",
    "authors": [
      "Ruize Zhang",
      "Sirui Xiang",
      "Zelai Xu",
      "Feng Gao",
      "Shilong Ji",
      "Wenhao Tang",
      "Wenbo Ding",
      "Chao Yu",
      "Yu Wang"
    ],
    "abstract": "In this paper, we tackle the problem of learning to play 3v3 multi-drone\nvolleyball, a new embodied competitive task that requires both high-level\nstrategic coordination and low-level agile control. The task is turn-based,\nmulti-agent, and physically grounded, posing significant challenges due to its\nlong-horizon dependencies, tight inter-agent coupling, and the underactuated\ndynamics of quadrotors. To address this, we propose Hierarchical Co-Self-Play\n(HCSP), a hierarchical reinforcement learning framework that separates\ncentralized high-level strategic decision-making from decentralized low-level\nmotion control. We design a three-stage population-based training pipeline to\nenable both strategy and skill to emerge from scratch without expert\ndemonstrations: (I) training diverse low-level skills, (II) learning high-level\nstrategy via self-play with fixed low-level controllers, and (III) joint\nfine-tuning through co-self-play. Experiments show that HCSP achieves superior\nperformance, outperforming non-hierarchical self-play and rule-based\nhierarchical baselines with an average 82.9\\% win rate and a 71.5\\% win rate\nagainst the two-stage variant. Moreover, co-self-play leads to emergent team\nbehaviors such as role switching and coordinated formations, demonstrating the\neffectiveness of our hierarchical design and training scheme.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.04317v1",
    "published_date": "2025-05-07 11:04:36 UTC",
    "updated_date": "2025-05-07 11:04:36 UTC"
  },
  {
    "arxiv_id": "2505.04313v1",
    "title": "KERAIA: An Adaptive and Explainable Framework for Dynamic Knowledge Representation and Reasoning",
    "authors": [
      "Stephen Richard Varey",
      "Alessandro Di Stefano",
      "The Anh Han"
    ],
    "abstract": "In this paper, we introduce KERAIA, a novel framework and software platform\nfor symbolic knowledge engineering designed to address the persistent\nchallenges of representing, reasoning with, and executing knowledge in dynamic,\ncomplex, and context-sensitive environments. The central research question that\nmotivates this work is: How can unstructured, often tacit, human expertise be\neffectively transformed into computationally tractable algorithms that AI\nsystems can efficiently utilise? KERAIA seeks to bridge this gap by building on\nfoundational concepts such as Minsky's frame-based reasoning and K-lines, while\nintroducing significant innovations. These include Clouds of Knowledge for\ndynamic aggregation, Dynamic Relations (DRels) for context-sensitive\ninheritance, explicit Lines of Thought (LoTs) for traceable reasoning, and\nCloud Elaboration for adaptive knowledge transformation. This approach moves\nbeyond the limitations of traditional, often static, knowledge representation\nparadigms. KERAIA is designed with Explainable AI (XAI) as a core principle,\nensuring transparency and interpretability, particularly through the use of\nLoTs. The paper details the framework's architecture, the KSYNTH representation\nlanguage, and the General Purpose Paradigm Builder (GPPB) to integrate diverse\ninference methods within a unified structure. We validate KERAIA's versatility,\nexpressiveness, and practical applicability through detailed analysis of\nmultiple case studies spanning naval warfare simulation, industrial diagnostics\nin water treatment plants, and strategic decision-making in the game of RISK.\nFurthermore, we provide a comparative analysis against established knowledge\nrepresentation paradigms (including ontologies, rule-based systems, and\nknowledge graphs) and discuss the implementation aspects and computational\nconsiderations of the KERAIA platform.",
    "categories": [
      "cs.AI",
      "cs.ET",
      "cs.SC"
    ],
    "primary_category": "cs.AI",
    "comment": "22 pages",
    "pdf_url": "http://arxiv.org/pdf/2505.04313v1",
    "published_date": "2025-05-07 10:56:05 UTC",
    "updated_date": "2025-05-07 10:56:05 UTC"
  },
  {
    "arxiv_id": "2505.04310v1",
    "title": "Flow Models for Unbounded and Geometry-Aware Distributional Reinforcement Learning",
    "authors": [
      "Simo Alami C.",
      "Rim Kaddah",
      "Jesse Read",
      "Marie-Paule Cani"
    ],
    "abstract": "We introduce a new architecture for Distributional Reinforcement Learning\n(DistRL) that models return distributions using normalizing flows. This\napproach enables flexible, unbounded support for return distributions, in\ncontrast to categorical approaches like C51 that rely on fixed or bounded\nrepresentations. It also offers richer modeling capacity to capture\nmulti-modality, skewness, and tail behavior than quantile based approaches. Our\nmethod is significantly more parameter-efficient than categorical approaches.\nStandard metrics used to train existing models like KL divergence or\nWasserstein distance either are scale insensitive or have biased sample\ngradients, especially when return supports do not overlap. To address this, we\npropose a novel surrogate for the Cram\\`er distance, that is geometry-aware and\ncomputable directly from the return distribution's PDF, avoiding the costly CDF\ncomputation. We test our model on the ATARI-5 sub-benchmark and show that our\napproach outperforms PDF based models while remaining competitive with quantile\nbased methods.",
    "categories": [
      "cs.AI",
      "cs.LG",
      "math.OC"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.04310v1",
    "published_date": "2025-05-07 10:49:53 UTC",
    "updated_date": "2025-05-07 10:49:53 UTC"
  },
  {
    "arxiv_id": "2505.04308v1",
    "title": "Guardians of the Web: The Evolution and Future of Website Information Security",
    "authors": [
      "Md Saiful Islam",
      "Li Xiangdong"
    ],
    "abstract": "Website information security has become a critical concern in the digital\nage. This article explores the evolution of website information security,\nexamining its historical development, current practices, and future directions.\nThe early beginnings from the 1960s to the 1980s laid the groundwork for modern\ncybersecurity, with the development of ARPANET, TCP/IP, public-key\ncryptography, and the first antivirus programs. The 1990s marked a\ntransformative era, driven by the commercialization of the Internet and the\nemergence of web-based services. As the Internet grew, so did the range and\nsophistication of cyber threats, leading to advancements in security\ntechnologies such as the Secure Sockets Layer (SSL) protocol, password\nprotection, and firewalls. Current practices in website information security\ninvolve a multi-layered approach, including encryption, secure coding\npractices, regular security audits, and user education. The future of website\ninformation security is expected to be shaped by emerging technologies such as\nartificial intelligence, blockchain, and quantum computing, as well as the\nincreasing importance of international cooperation and standardization efforts.\nAs cyber threats continue to evolve, ongoing research and innovation in website\ninformation security will be essential to protect sensitive information and\nmaintain trust in the digital world.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "F.2.2, I.2.7"
    ],
    "primary_category": "cs.CR",
    "comment": "22 pages",
    "pdf_url": "http://arxiv.org/pdf/2505.04308v1",
    "published_date": "2025-05-07 10:46:33 UTC",
    "updated_date": "2025-05-07 10:46:33 UTC"
  },
  {
    "arxiv_id": "2505.04674v1",
    "title": "Dynamic Location Search for Identifying Maximum Weighted Independent Sets in Complex Networks",
    "authors": [
      "Enqiang Zhu",
      "Chenkai Hao",
      "Chanjuan Liu",
      "Yongsheng Rao"
    ],
    "abstract": "While Artificial intelligence (AI), including Generative AI, are effective at\ngenerating high-quality traffic data and optimization solutions in intelligent\ntransportation systems (ITSs), these techniques often demand significant\ntraining time and computational resources, especially in large-scale and\ncomplex scenarios. To address this, we introduce a novel and efficient\nalgorithm for solving the maximum weighted independent set (MWIS) problem,\nwhich can be used to model many ITSs applications, such as traffic signal\ncontrol and vehicle routing. Given the NP-hard nature of the MWIS problem, our\nproposed algorithm, DynLS, incorporates three key innovations to solve it\neffectively. First, it uses a scores-based adaptive vertex perturbation (SAVP)\ntechnique to accelerate convergence, particularly in sparse graphs. Second, it\nincludes a region location mechanism (RLM) to help escape local optima by\ndynamically adjusting the search space. Finally, it employs a novel variable\nneighborhood descent strategy, ComLS, which combines vertex exchange strategies\nwith a reward mechanism to guide the search toward high-quality solutions. Our\nexperimental results demonstrate DynLS's superior performance, consistently\ndelivering high-quality solutions within 1000 seconds. DynLS outperformed five\nleading algorithms across 360 test instances, achieving the best solution for\n350 instances and surpassing the second-best algorithm, Cyclic-Fast, by 177\ninstances. Moreover, DynLS matched Cyclic-Fast's convergence speed,\nhighlighting its efficiency and practicality. This research represents a\nsignificant advancement in heuristic algorithms for the MWIS problem, offering\na promising approach to aid AI techniques in optimizing intelligent\ntransportation systems.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.04674v1",
    "published_date": "2025-05-07 10:35:53 UTC",
    "updated_date": "2025-05-07 10:35:53 UTC"
  },
  {
    "arxiv_id": "2505.04300v1",
    "title": "Sparsity is All You Need: Rethinking Biological Pathway-Informed Approaches in Deep Learning",
    "authors": [
      "Isabella Caranzano",
      "Corrado Pancotti",
      "Cesare Rollo",
      "Flavio Sartori",
      "Pietro Liò",
      "Piero Fariselli",
      "Tiziana Sanavia"
    ],
    "abstract": "Biologically-informed neural networks typically leverage pathway annotations\nto enhance performance in biomedical applications. We hypothesized that the\nbenefits of pathway integration does not arise from its biological relevance,\nbut rather from the sparsity it introduces. We conducted a comprehensive\nanalysis of all relevant pathway-based neural network models for predictive\ntasks, critically evaluating each study's contributions. From this review, we\ncurated a subset of methods for which the source code was publicly available.\nThe comparison of the biologically informed state-of-the-art deep learning\nmodels and their randomized counterparts showed that models based on randomized\ninformation performed equally well as biologically informed ones across\ndifferent metrics and datasets. Notably, in 3 out of the 15 analyzed models,\nthe randomized versions even outperformed their biologically informed\ncounterparts. Moreover, pathway-informed models did not show any clear\nadvantage in interpretability, as randomized models were still able to identify\nrelevant disease biomarkers despite lacking explicit pathway information. Our\nfindings suggest that pathway annotations may be too noisy or inadequately\nexplored by current methods. Therefore, we propose a methodology that can be\napplied to different domains and can serve as a robust benchmark for\nsystematically comparing novel pathway-informed models against their randomized\ncounterparts. This approach enables researchers to rigorously determine whether\nobserved performance improvements can be attributed to biological insights.",
    "categories": [
      "q-bio.QM",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "q-bio.QM",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.04300v1",
    "published_date": "2025-05-07 10:14:31 UTC",
    "updated_date": "2025-05-07 10:14:31 UTC"
  },
  {
    "arxiv_id": "2505.04673v1",
    "title": "REVEAL: Multi-turn Evaluation of Image-Input Harms for Vision LLM",
    "authors": [
      "Madhur Jindal",
      "Saurabh Deshpande"
    ],
    "abstract": "Vision Large Language Models (VLLMs) represent a significant advancement in\nartificial intelligence by integrating image-processing capabilities with\ntextual understanding, thereby enhancing user interactions and expanding\napplication domains. However, their increased complexity introduces novel\nsafety and ethical challenges, particularly in multi-modal and multi-turn\nconversations. Traditional safety evaluation frameworks, designed for\ntext-based, single-turn interactions, are inadequate for addressing these\ncomplexities. To bridge this gap, we introduce the REVEAL (Responsible\nEvaluation of Vision-Enabled AI LLMs) Framework, a scalable and automated\npipeline for evaluating image-input harms in VLLMs. REVEAL includes automated\nimage mining, synthetic adversarial data generation, multi-turn conversational\nexpansion using crescendo attack strategies, and comprehensive harm assessment\nthrough evaluators like GPT-4o.\n  We extensively evaluated five state-of-the-art VLLMs, GPT-4o, Llama-3.2,\nQwen2-VL, Phi3.5V, and Pixtral, across three important harm categories: sexual\nharm, violence, and misinformation. Our findings reveal that multi-turn\ninteractions result in significantly higher defect rates compared to\nsingle-turn evaluations, highlighting deeper vulnerabilities in VLLMs. Notably,\nGPT-4o demonstrated the most balanced performance as measured by our\nSafety-Usability Index (SUI) followed closely by Pixtral. Additionally,\nmisinformation emerged as a critical area requiring enhanced contextual\ndefenses. Llama-3.2 exhibited the highest MT defect rate ($16.55 \\%$) while\nQwen2-VL showed the highest MT refusal rate ($19.1 \\%$).",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "13 pages (8 main), to be published in IJCAI 2025",
    "pdf_url": "http://arxiv.org/pdf/2505.04673v1",
    "published_date": "2025-05-07 10:09:55 UTC",
    "updated_date": "2025-05-07 10:09:55 UTC"
  },
  {
    "arxiv_id": "2505.04284v1",
    "title": "GASCADE: Grouped Summarization of Adverse Drug Event for Enhanced Cancer Pharmacovigilance",
    "authors": [
      "Sofia Jamil",
      "Aryan Dabad",
      "Bollampalli Areen Reddy",
      "Sriparna Saha",
      "Rajiv Misra",
      "Adil A. Shakur"
    ],
    "abstract": "In the realm of cancer treatment, summarizing adverse drug events (ADEs)\nreported by patients using prescribed drugs is crucial for enhancing\npharmacovigilance practices and improving drug-related decision-making. While\nthe volume and complexity of pharmacovigilance data have increased, existing\nresearch in this field has predominantly focused on general diseases rather\nthan specifically addressing cancer. This work introduces the task of grouped\nsummarization of adverse drug events reported by multiple patients using the\nsame drug for cancer treatment. To address the challenge of limited resources\nin cancer pharmacovigilance, we present the MultiLabeled Cancer Adverse Drug\nReaction and Summarization (MCADRS) dataset. This dataset includes\npharmacovigilance posts detailing patient concerns regarding drug efficacy and\nadverse effects, along with extracted labels for drug names, adverse drug\nevents, severity, and adversity of reactions, as well as summaries of ADEs for\neach drug. Additionally, we propose the Grouping and Abstractive Summarization\nof Cancer Adverse Drug events (GASCADE) framework, a novel pipeline that\ncombines the information extraction capabilities of Large Language Models\n(LLMs) with the summarization power of the encoder-decoder T5 model. Our work\nis the first to apply alignment techniques, including advanced algorithms like\nDirect Preference Optimization, to encoder-decoder models using synthetic\ndatasets for summarization tasks. Through extensive experiments, we demonstrate\nthe superior performance of GASCADE across various metrics, validated through\nboth automated assessments and human evaluations. This multitasking approach\nenhances drug-related decision-making and fosters a deeper understanding of\npatient concerns, paving the way for advancements in personalized and\nresponsive cancer care. The code and dataset used in this work are publicly\navailable.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.04284v1",
    "published_date": "2025-05-07 09:40:18 UTC",
    "updated_date": "2025-05-07 09:40:18 UTC"
  },
  {
    "arxiv_id": "2505.04278v2",
    "title": "Non-stationary Diffusion For Probabilistic Time Series Forecasting",
    "authors": [
      "Weiwei Ye",
      "Zhuopeng Xu",
      "Ning Gui"
    ],
    "abstract": "Due to the dynamics of underlying physics and external influences, the\nuncertainty of time series often varies over time. However, existing Denoising\nDiffusion Probabilistic Models (DDPMs) often fail to capture this\nnon-stationary nature, constrained by their constant variance assumption from\nthe additive noise model (ANM). In this paper, we innovatively utilize the\nLocation-Scale Noise Model (LSNM) to relax the fixed uncertainty assumption of\nANM. A diffusion-based probabilistic forecasting framework, termed\nNon-stationary Diffusion (NsDiff), is designed based on LSNM that is capable of\nmodeling the changing pattern of uncertainty. Specifically, NsDiff combines a\ndenoising diffusion-based conditional generative model with a pre-trained\nconditional mean and variance estimator, enabling adaptive endpoint\ndistribution modeling. Furthermore, we propose an uncertainty-aware noise\nschedule, which dynamically adjusts the noise levels to accurately reflect the\ndata uncertainty at each step and integrates the time-varying variances into\nthe diffusion process. Extensive experiments conducted on nine real-world and\nsynthetic datasets demonstrate the superior performance of NsDiff compared to\nexisting approaches. Code is available at https://github.com/wwy155/NsDiff.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted as spotlight poster at ICML",
    "pdf_url": "http://arxiv.org/pdf/2505.04278v2",
    "published_date": "2025-05-07 09:29:39 UTC",
    "updated_date": "2025-05-19 05:58:28 UTC"
  },
  {
    "arxiv_id": "2505.04270v1",
    "title": "Object-Shot Enhanced Grounding Network for Egocentric Video",
    "authors": [
      "Yisen Feng",
      "Haoyu Zhang",
      "Meng Liu",
      "Weili Guan",
      "Liqiang Nie"
    ],
    "abstract": "Egocentric video grounding is a crucial task for embodied intelligence\napplications, distinct from exocentric video moment localization. Existing\nmethods primarily focus on the distributional differences between egocentric\nand exocentric videos but often neglect key characteristics of egocentric\nvideos and the fine-grained information emphasized by question-type queries. To\naddress these limitations, we propose OSGNet, an Object-Shot enhanced Grounding\nNetwork for egocentric video. Specifically, we extract object information from\nvideos to enrich video representation, particularly for objects highlighted in\nthe textual query but not directly captured in the video features.\nAdditionally, we analyze the frequent shot movements inherent to egocentric\nvideos, leveraging these features to extract the wearer's attention\ninformation, which enhances the model's ability to perform modality alignment.\nExperiments conducted on three datasets demonstrate that OSGNet achieves\nstate-of-the-art performance, validating the effectiveness of our approach. Our\ncode can be found at https://github.com/Yisen-Feng/OSGNet.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted by CVPR 2025",
    "pdf_url": "http://arxiv.org/pdf/2505.04270v1",
    "published_date": "2025-05-07 09:20:12 UTC",
    "updated_date": "2025-05-07 09:20:12 UTC"
  },
  {
    "arxiv_id": "2505.04265v1",
    "title": "Weaponizing Language Models for Cybersecurity Offensive Operations: Automating Vulnerability Assessment Report Validation; A Review Paper",
    "authors": [
      "Abdulrahman S Almuhaidib",
      "Azlan Mohd Zain",
      "Zalmiyah Zakaria",
      "Izyan Izzati Kamsani",
      "Abdulaziz S Almuhaidib"
    ],
    "abstract": "This, with the ever-increasing sophistication of cyberwar, calls for novel\nsolutions. In this regard, Large Language Models (LLMs) have emerged as a\nhighly promising tool for defensive and offensive cybersecurity-related\nstrategies. While existing literature has focused much on the defensive use of\nLLMs, when it comes to their offensive utilization, very little has been\nreported-namely, concerning Vulnerability Assessment (VA) report validation.\nConsequentially, this paper tries to fill that gap by investigating the\ncapabilities of LLMs in automating and improving the validation process of the\nreport of the VA. From the critical review of the related literature, this\npaper hereby proposes a new approach to using the LLMs in the automation of the\nanalysis and within the validation process of the report of the VA that could\npotentially reduce the number of false positives and generally enhance\nefficiency. These results are promising for LLM automatization for improving\nvalidation on reports coming from VA in order to improve accuracy while\nreducing human effort and security postures. The contribution of this paper\nprovides further evidence about the offensive and defensive LLM capabilities\nand therefor helps in devising more appropriate cybersecurity strategies and\ntools accordingly.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "Pre-print - Accepted for publication in the Proceedings of the\n  International Computer Sciences and Informatics Conference (ICSIC-2024),\n  published by AIP Publishing",
    "pdf_url": "http://arxiv.org/pdf/2505.04265v1",
    "published_date": "2025-05-07 09:14:55 UTC",
    "updated_date": "2025-05-07 09:14:55 UTC"
  },
  {
    "arxiv_id": "2505.04260v2",
    "title": "Steerable Chatbots: Personalizing LLMs with Preference-Based Activation Steering",
    "authors": [
      "Jessica Y. Bo",
      "Tianyu Xu",
      "Ishan Chatterjee",
      "Katrina Passarella-Ward",
      "Achin Kulshrestha",
      "D Shin"
    ],
    "abstract": "As large language models (LLMs) improve in their capacity to serve as\npersonal AI assistants, their ability to output uniquely tailored, personalized\nresponses that align with the soft preferences of their users is essential for\nenhancing user satisfaction and retention. However, untrained lay users have\npoor prompt specification abilities and often struggle with conveying their\nlatent preferences to AI assistants. To address this, we leverage activation\nsteering to guide LLMs to align with interpretable preference dimensions during\ninference. In contrast to memory-based personalization methods that require\nlonger user history, steering is extremely lightweight and can be easily\ncontrolled by the user via an linear strength factor. We embed steering into\nthree different interactive chatbot interfaces and conduct a within-subjects\nuser study (n=14) to investigate how end users prefer to personalize their\nconversations. The results demonstrate the effectiveness of preference-based\nsteering for aligning real-world conversations with hidden user preferences,\nand highlight further insights on how diverse values around control, usability,\nand transparency lead users to prefer different interfaces.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.04260v2",
    "published_date": "2025-05-07 09:10:51 UTC",
    "updated_date": "2025-05-13 21:19:59 UTC"
  },
  {
    "arxiv_id": "2505.04251v1",
    "title": "Facilitating Trustworthy Human-Agent Collaboration in LLM-based Multi-Agent System oriented Software Engineering",
    "authors": [
      "Krishna Ronanki"
    ],
    "abstract": "Multi-agent autonomous systems (MAS) are better at addressing challenges that\nspans across multiple domains than singular autonomous agents. This holds true\nwithin the field of software engineering (SE) as well. The state-of-the-art\nresearch on MAS within SE focuses on integrating LLMs at the core of autonomous\nagents to create LLM-based multi-agent autonomous (LMA) systems. However, the\nintroduction of LMA systems into SE brings a plethora of challenges. One of the\nmajor challenges is the strategic allocation of tasks between humans and the\nLMA system in a trustworthy manner. To address this challenge, a RACI-based\nframework is proposed in this work in progress article, along with\nimplementation guidelines and an example implementation of the framework. The\nproposed framework can facilitate efficient collaboration, ensure\naccountability, and mitigate potential risks associated with LLM-driven\nautomation while aligning with the Trustworthy AI guidelines. The future steps\nfor this work delineating the planned empirical validation method are also\npresented.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.MA"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.04251v1",
    "published_date": "2025-05-07 08:55:15 UTC",
    "updated_date": "2025-05-07 08:55:15 UTC"
  },
  {
    "arxiv_id": "2505.04223v1",
    "title": "FRAIN to Train: A Fast-and-Reliable Solution for Decentralized Federated Learning",
    "authors": [
      "Sanghyeon Park",
      "Soo-Mook Moon"
    ],
    "abstract": "Federated learning (FL) enables collaborative model training across\ndistributed clients while preserving data locality. Although FedAvg pioneered\nsynchronous rounds for global model averaging, slower devices can delay\ncollective progress. Asynchronous FL (e.g., FedAsync) addresses stragglers by\ncontinuously integrating client updates, yet naive implementations risk client\ndrift due to non-IID data and stale contributions. Some Blockchain-based FL\napproaches (e.g., BRAIN) employ robust weighting or scoring of updates to\nresist malicious or misaligned proposals. However, performance drops can still\npersist under severe data heterogeneity or high staleness, and synchronization\noverhead has emerged as a new concern due to its aggregator-free architectures.\n  We introduce Fast-and-Reliable AI Network, FRAIN, a new asynchronous FL\nmethod that mitigates these limitations by incorporating two key ideas. First,\nour FastSync strategy eliminates the need to replay past model versions,\nenabling newcomers and infrequent participants to efficiently approximate the\nglobal model. Second, we adopt spherical linear interpolation (SLERP) when\nmerging parameters, preserving models' directions and alleviating destructive\ninterference from divergent local training.\n  Experiments with a CNN image-classification model and a Transformer-based\nlanguage model demonstrate that FRAIN achieves more stable and robust\nconvergence than FedAvg, FedAsync, and BRAIN, especially under harsh\nenvironments: non-IID data distributions, networks that experience delays and\nrequire frequent re-synchronization, and the presence of malicious nodes.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.DC"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.04223v1",
    "published_date": "2025-05-07 08:20:23 UTC",
    "updated_date": "2025-05-07 08:20:23 UTC"
  },
  {
    "arxiv_id": "2505.04209v1",
    "title": "To Judge or not to Judge: Using LLM Judgements for Advertiser Keyphrase Relevance at eBay",
    "authors": [
      "Soumik Dey",
      "Hansi Wu",
      "Binbin Li"
    ],
    "abstract": "E-commerce sellers are recommended keyphrases based on their inventory on\nwhich they advertise to increase buyer engagement (clicks/sales). The relevance\nof advertiser keyphrases plays an important role in preventing the inundation\nof search systems with numerous irrelevant items that compete for attention in\nauctions, in addition to maintaining a healthy seller perception. In this work,\nwe describe the shortcomings of training Advertiser keyphrase relevance filter\nmodels on click/sales/search relevance signals and the importance of aligning\nwith human judgment, as sellers have the power to adopt or reject said\nkeyphrase recommendations. In this study, we frame Advertiser keyphrase\nrelevance as a complex interaction between 3 dynamical systems -- seller\njudgment, which influences seller adoption of our product, Advertising, which\nprovides the keyphrases to bid on, and Search, who holds the auctions for the\nsame keyphrases. This study discusses the practicalities of using human\njudgment via a case study at eBay Advertising and demonstrate that using\nLLM-as-a-judge en-masse as a scalable proxy for seller judgment to train our\nrelevance models achieves a better harmony across the three systems -- provided\nthat they are bound by a meticulous evaluation framework grounded in business\nmetrics.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.04209v1",
    "published_date": "2025-05-07 08:03:25 UTC",
    "updated_date": "2025-05-07 08:03:25 UTC"
  },
  {
    "arxiv_id": "2505.07846v1",
    "title": "Winning at All Cost: A Small Environment for Eliciting Specification Gaming Behaviors in Large Language Models",
    "authors": [
      "Lars Malmqvist"
    ],
    "abstract": "This study reveals how frontier Large Language Models LLMs can \"game the\nsystem\" when faced with impossible situations, a critical security and\nalignment concern. Using a novel textual simulation approach, we presented\nthree leading LLMs (o1, o3-mini, and r1) with a tic-tac-toe scenario designed\nto be unwinnable through legitimate play, then analyzed their tendency to\nexploit loopholes rather than accept defeat. Our results are alarming for\nsecurity researchers: the newer, reasoning-focused o3-mini model showed nearly\ntwice the propensity to exploit system vulnerabilities (37.1%) compared to the\nolder o1 model (17.5%). Most striking was the effect of prompting. Simply\nframing the task as requiring \"creative\" solutions caused gaming behaviors to\nskyrocket to 77.3% across all models. We identified four distinct exploitation\nstrategies, from direct manipulation of game state to sophisticated\nmodification of opponent behavior. These findings demonstrate that even without\nactual execution capabilities, LLMs can identify and propose sophisticated\nsystem exploits when incentivized, highlighting urgent challenges for AI\nalignment as models grow more capable of identifying and leveraging\nvulnerabilities in their operating environments.",
    "categories": [
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.AI",
    "comment": "To be presented at SIMLA@ACNS 2025",
    "pdf_url": "http://arxiv.org/pdf/2505.07846v1",
    "published_date": "2025-05-07 07:59:56 UTC",
    "updated_date": "2025-05-07 07:59:56 UTC"
  },
  {
    "arxiv_id": "2505.04207v2",
    "title": "An Enhanced YOLOv8 Model for Real-Time and Accurate Pothole Detection and Measurement",
    "authors": [
      "Mustafa Yurdakul",
      "Şakir Tasdemir"
    ],
    "abstract": "Potholes cause vehicle damage and traffic accidents, creating serious safety\nand economic problems. Therefore, early and accurate detection of potholes is\ncrucial. Existing detection methods are usually only based on 2D RGB images and\ncannot accurately analyze the physical characteristics of potholes. In this\npaper, a publicly available dataset of RGB-D images (PothRGBD) is created and\nan improved YOLOv8-based model is proposed for both pothole detection and\npothole physical features analysis. The Intel RealSense D415 depth camera was\nused to collect RGB and depth data from the road surfaces, resulting in a\nPothRGBD dataset of 1000 images. The data was labeled in YOLO format suitable\nfor segmentation. A novel YOLO model is proposed based on the YOLOv8n-seg\narchitecture, which is structurally improved with Dynamic Snake Convolution\n(DSConv), Simple Attention Module (SimAM) and Gaussian Error Linear Unit\n(GELU). The proposed model segmented potholes with irregular edge structure\nmore accurately, and performed perimeter and depth measurements on depth maps\nwith high accuracy. The standard YOLOv8n-seg model achieved 91.9% precision,\n85.2% recall and 91.9% mAP@50. With the proposed model, the values increased to\n93.7%, 90.4% and 93.8% respectively. Thus, an improvement of 1.96% in\nprecision, 6.13% in recall and 2.07% in mAP was achieved. The proposed model\nperforms pothole detection as well as perimeter and depth measurement with high\naccuracy and is suitable for real-time applications due to its low model\ncomplexity. In this way, a lightweight and effective model that can be used in\ndeep learning-based intelligent transportation solutions has been acquired.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.04207v2",
    "published_date": "2025-05-07 07:58:57 UTC",
    "updated_date": "2025-05-16 13:12:38 UTC"
  },
  {
    "arxiv_id": "2505.04192v1",
    "title": "VideoPath-LLaVA: Pathology Diagnostic Reasoning Through Video Instruction Tuning",
    "authors": [
      "Trinh T. L. Vuong",
      "Jin Tae Kwak"
    ],
    "abstract": "We present VideoPath-LLaVA, the first large multimodal model (LMM) in\ncomputational pathology that integrates three distinct image scenarios, single\npatch images, automatically keyframe-extracted clips, and manually segmented\nvideo pathology images, to mimic the natural diagnostic process of\npathologists. By generating detailed histological descriptions and culminating\nin a definitive sign-out diagnosis, VideoPath-LLaVA bridges visual narratives\nwith diagnostic reasoning.\n  Central to our approach is the VideoPath-Instruct dataset, comprising 4278\nvideo and diagnosis-specific chain-of-thought instructional pairs sourced from\neducational histopathology videos on YouTube. Although high-quality data is\ncritical for enhancing diagnostic reasoning, its creation is time-intensive and\nlimited in volume. To overcome this challenge, we transfer knowledge from\nexisting single-image instruction datasets to train on weakly annotated,\nkeyframe-extracted clips, followed by fine-tuning on manually segmented videos.\nVideoPath-LLaVA establishes a new benchmark in pathology video analysis and\noffers a promising foundation for future AI systems that support clinical\ndecision-making through integrated visual and diagnostic reasoning. Our code,\ndata, and model are publicly available at\nhttps://github.com/trinhvg/VideoPath-LLaVA.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.04192v1",
    "published_date": "2025-05-07 07:41:19 UTC",
    "updated_date": "2025-05-07 07:41:19 UTC"
  },
  {
    "arxiv_id": "2505.04185v1",
    "title": "S3D: Sketch-Driven 3D Model Generation",
    "authors": [
      "Hail Song",
      "Wonsik Shin",
      "Naeun Lee",
      "Soomin Chung",
      "Nojun Kwak",
      "Woontack Woo"
    ],
    "abstract": "Generating high-quality 3D models from 2D sketches is a challenging task due\nto the inherent ambiguity and sparsity of sketch data. In this paper, we\npresent S3D, a novel framework that converts simple hand-drawn sketches into\ndetailed 3D models. Our method utilizes a U-Net-based encoder-decoder\narchitecture to convert sketches into face segmentation masks, which are then\nused to generate a 3D representation that can be rendered from novel views. To\nensure robust consistency between the sketch domain and the 3D output, we\nintroduce a novel style-alignment loss that aligns the U-Net bottleneck\nfeatures with the initial encoder outputs of the 3D generation module,\nsignificantly enhancing reconstruction fidelity. To further enhance the\nnetwork's robustness, we apply augmentation techniques to the sketch dataset.\nThis streamlined framework demonstrates the effectiveness of S3D in generating\nhigh-quality 3D models from sketch inputs. The source code for this project is\npublicly available at https://github.com/hailsong/S3D.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted as a short paper to the GMCV Workshop at CVPR'25",
    "pdf_url": "http://arxiv.org/pdf/2505.04185v1",
    "published_date": "2025-05-07 07:34:37 UTC",
    "updated_date": "2025-05-07 07:34:37 UTC"
  },
  {
    "arxiv_id": "2505.04175v1",
    "title": "DOTA: Deformable Optimized Transformer Architecture for End-to-End Text Recognition with Retrieval-Augmented Generation",
    "authors": [
      "Naphat Nithisopa",
      "Teerapong Panboonyuen"
    ],
    "abstract": "Text recognition in natural images remains a challenging yet essential task,\nwith broad applications spanning computer vision and natural language\nprocessing. This paper introduces a novel end-to-end framework that combines\nResNet and Vision Transformer backbones with advanced methodologies, including\nDeformable Convolutions, Retrieval-Augmented Generation, and Conditional Random\nFields (CRF). These innovations collectively enhance feature representation and\nimprove Optical Character Recognition (OCR) performance. Specifically, the\nframework substitutes standard convolution layers in the third and fourth\nblocks with Deformable Convolutions, leverages adaptive dropout for\nregularization, and incorporates CRF for more refined sequence modeling.\nExtensive experiments conducted on six benchmark datasets IC13, IC15, SVT,\nIIIT5K, SVTP, and CUTE80 validate the proposed method's efficacy, achieving\nnotable accuracies: 97.32% on IC13, 58.26% on IC15, 88.10% on SVT, 74.13% on\nIIIT5K, 82.17% on SVTP, and 66.67% on CUTE80, resulting in an average accuracy\nof 77.77%. These results establish a new state-of-the-art for text recognition,\ndemonstrating the robustness of the approach across diverse and challenging\ndatasets.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.04175v1",
    "published_date": "2025-05-07 07:06:04 UTC",
    "updated_date": "2025-05-07 07:06:04 UTC"
  },
  {
    "arxiv_id": "2505.04174v2",
    "title": "On-Device LLM for Context-Aware Wi-Fi Roaming",
    "authors": [
      "Ju-Hyung Lee",
      "Yanqing Lu",
      "Klaus Doppler"
    ],
    "abstract": "Roaming in Wireless LAN (Wi-Fi) is a critical yet challenging task for\nmaintaining seamless connectivity in dynamic mobile environments. Conventional\nthreshold-based or heuristic schemes often fail, leading to either sticky or\nexcessive handovers. We introduce the first cross-layer use of an on-device\nlarge language model (LLM): high-level reasoning in the application layer that\nissues real-time actions executed in the PHY/MAC stack. The LLM addresses two\ntasks: (i) context-aware AP selection, where structured prompts fuse\nenvironmental cues (e.g., location, time) to choose the best BSSID; and (ii)\ndynamic threshold adjustment, where the model adaptively decides when to roam.\nTo satisfy the tight latency and resource budgets of edge hardware, we apply a\nsuite of optimizations-chain-of-thought prompting, parameter-efficient\nfine-tuning, and quantization. Experiments on indoor and outdoor datasets show\nthat our approach surpasses legacy heuristics and DRL baselines, achieving a\nstrong balance between roaming stability and signal quality. These findings\nunderscore the promise of application-layer LLM reasoning for lower-layer\nwireless control in future edge systems.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.NI",
      "eess.SP"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.04174v2",
    "published_date": "2025-05-07 07:04:49 UTC",
    "updated_date": "2025-05-20 04:45:18 UTC"
  },
  {
    "arxiv_id": "2505.04165v4",
    "title": "TS-SNN: Temporal Shift Module for Spiking Neural Networks",
    "authors": [
      "Kairong Yu",
      "Tianqing Zhang",
      "Qi Xu",
      "Gang Pan",
      "Hongwei Wang"
    ],
    "abstract": "Spiking Neural Networks (SNNs) are increasingly recognized for their\nbiological plausibility and energy efficiency, positioning them as strong\nalternatives to Artificial Neural Networks (ANNs) in neuromorphic computing\napplications. SNNs inherently process temporal information by leveraging the\nprecise timing of spikes, but balancing temporal feature utilization with low\nenergy consumption remains a challenge. In this work, we introduce Temporal\nShift module for Spiking Neural Networks (TS-SNN), which incorporates a novel\nTemporal Shift (TS) module to integrate past, present, and future spike\nfeatures within a single timestep via a simple yet effective shift operation. A\nresidual combination method prevents information loss by integrating shifted\nand original features. The TS module is lightweight, requiring only one\nadditional learnable parameter, and can be seamlessly integrated into existing\narchitectures with minimal additional computational cost. TS-SNN achieves\nstate-of-the-art performance on benchmarks like CIFAR-10 (96.72\\%), CIFAR-100\n(80.28\\%), and ImageNet (70.61\\%) with fewer timesteps, while maintaining low\nenergy consumption. This work marks a significant step forward in developing\nefficient and accurate SNN architectures.",
    "categories": [
      "cs.NE",
      "cs.AI"
    ],
    "primary_category": "cs.NE",
    "comment": "Accepted by ICML2025",
    "pdf_url": "http://arxiv.org/pdf/2505.04165v4",
    "published_date": "2025-05-07 06:34:34 UTC",
    "updated_date": "2025-05-16 13:56:30 UTC"
  },
  {
    "arxiv_id": "2505.04147v1",
    "title": "R^3-VQA: \"Read the Room\" by Video Social Reasoning",
    "authors": [
      "Lixing Niu",
      "Jiapeng Li",
      "Xingping Yu",
      "Shu Wang",
      "Ruining Feng",
      "Bo Wu",
      "Ping Wei",
      "Yisen Wang",
      "Lifeng Fan"
    ],
    "abstract": "\"Read the room\" is a significant social reasoning capability in human daily\nlife. Humans can infer others' mental states from subtle social cues. Previous\nsocial reasoning tasks and datasets lack complexity (e.g., simple scenes, basic\ninteractions, incomplete mental state variables, single-step reasoning, etc.)\nand fall far short of the challenges present in real-life social interactions.\nIn this paper, we contribute a valuable, high-quality, and comprehensive video\ndataset named R^3-VQA with precise and fine-grained annotations of social\nevents and mental states (i.e., belief, intent, desire, and emotion) as well as\ncorresponding social causal chains in complex social scenarios. Moreover, we\ninclude human-annotated and model-generated QAs. Our task R^3-VQA includes\nthree aspects: Social Event Understanding, Mental State Estimation, and Social\nCausal Reasoning. As a benchmark, we comprehensively evaluate the social\nreasoning capabilities and consistencies of current state-of-the-art large\nvision-language models (LVLMs). Comprehensive experiments show that (i) LVLMs\nare still far from human-level consistent social reasoning in complex social\nscenarios; (ii) Theory of Mind (ToM) prompting can help LVLMs perform better on\nsocial reasoning tasks. We provide some of our dataset and codes in\nsupplementary material and will release our full dataset and codes upon\nacceptance.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.04147v1",
    "published_date": "2025-05-07 05:55:45 UTC",
    "updated_date": "2025-05-07 05:55:45 UTC"
  },
  {
    "arxiv_id": "2505.04146v1",
    "title": "Unmasking the Canvas: A Dynamic Benchmark for Image Generation Jailbreaking and LLM Content Safety",
    "authors": [
      "Variath Madhupal Gautham Nair",
      "Vishal Varma Dantuluri"
    ],
    "abstract": "Existing large language models (LLMs) are advancing rapidly and produce\noutstanding results in image generation tasks, yet their content safety checks\nremain vulnerable to prompt-based jailbreaks. Through preliminary testing on\nplatforms such as ChatGPT, MetaAI, and Grok, we observed that even short,\nnatural prompts could lead to the generation of compromising images ranging\nfrom realistic depictions of forged documents to manipulated images of public\nfigures.\n  We introduce Unmasking the Canvas (UTC Benchmark; UTCB), a dynamic and\nscalable benchmark dataset to evaluate LLM vulnerability in image generation.\nOur methodology combines structured prompt engineering, multilingual\nobfuscation (e.g., Zulu, Gaelic, Base64), and evaluation using Groq-hosted\nLLaMA-3. The pipeline supports both zero-shot and fallback prompting\nstrategies, risk scoring, and automated tagging. All generations are stored\nwith rich metadata and curated into Bronze (non-verified), Silver (LLM-aided\nverification), and Gold (manually verified) tiers. UTCB is designed to evolve\nover time with new data sources, prompt templates, and model behaviors.\n  Warning: This paper includes visual examples of adversarial inputs designed\nto test model safety. All outputs have been redacted to ensure responsible\ndisclosure.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.04146v1",
    "published_date": "2025-05-07 05:54:04 UTC",
    "updated_date": "2025-05-07 05:54:04 UTC"
  },
  {
    "arxiv_id": "2505.04132v1",
    "title": "Bringing legal knowledge to the public by constructing a legal question bank using large-scale pre-trained language model",
    "authors": [
      "Mingruo Yuan",
      "Ben Kao",
      "Tien-Hsuan Wu",
      "Michael M. K. Cheung",
      "Henry W. H. Chan",
      "Anne S. Y. Cheung",
      "Felix W. H. Chan",
      "Yongxi Chen"
    ],
    "abstract": "Access to legal information is fundamental to access to justice. Yet\naccessibility refers not only to making legal documents available to the\npublic, but also rendering legal information comprehensible to them. A vexing\nproblem in bringing legal information to the public is how to turn formal legal\ndocuments such as legislation and judgments, which are often highly technical,\nto easily navigable and comprehensible knowledge to those without legal\neducation. In this study, we formulate a three-step approach for bringing legal\nknowledge to laypersons, tackling the issues of navigability and\ncomprehensibility. First, we translate selected sections of the law into\nsnippets (called CLIC-pages), each being a small piece of article that focuses\non explaining certain technical legal concept in layperson's terms. Second, we\nconstruct a Legal Question Bank (LQB), which is a collection of legal questions\nwhose answers can be found in the CLIC-pages. Third, we design an interactive\nCLIC Recommender (CRec). Given a user's verbal description of a legal situation\nthat requires a legal solution, CRec interprets the user's input and shortlists\nquestions from the question bank that are most likely relevant to the given\nlegal situation and recommends their corresponding CLIC pages where relevant\nlegal knowledge can be found. In this paper we focus on the technical aspects\nof creating an LQB. We show how large-scale pre-trained language models, such\nas GPT-3, can be used to generate legal questions. We compare machine-generated\nquestions (MGQs) against human-composed questions (HCQs) and find that MGQs are\nmore scalable, cost-effective, and more diversified, while HCQs are more\nprecise. We also show a prototype of CRec and illustrate through an example how\nour 3-step approach effectively brings relevant legal knowledge to the public.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.04132v1",
    "published_date": "2025-05-07 05:07:38 UTC",
    "updated_date": "2025-05-07 05:07:38 UTC"
  },
  {
    "arxiv_id": "2505.04665v1",
    "title": "Personalized Risks and Regulatory Strategies of Large Language Models in Digital Advertising",
    "authors": [
      "Haoyang Feng",
      "Yanjun Dai",
      "Yuan Gao"
    ],
    "abstract": "Although large language models have demonstrated the potential for\npersonalized advertising recommendations in experimental environments, in\nactual operations, how advertising recommendation systems can be combined with\nmeasures such as user privacy protection and data security is still an area\nworthy of in-depth discussion. To this end, this paper studies the personalized\nrisks and regulatory strategies of large language models in digital\nadvertising. This study first outlines the principles of Large Language Model\n(LLM), especially the self-attention mechanism based on the Transformer\narchitecture, and how to enable the model to understand and generate natural\nlanguage text. Then, the BERT (Bidirectional Encoder Representations from\nTransformers) model and the attention mechanism are combined to construct an\nalgorithmic model for personalized advertising recommendations and user factor\nrisk protection. The specific steps include: data collection and preprocessing,\nfeature selection and construction, using large language models such as BERT\nfor advertising semantic embedding, and ad recommendations based on user\nportraits. Then, local model training and data encryption are used to ensure\nthe security of user privacy and avoid the leakage of personal data. This paper\ndesigns an experiment for personalized advertising recommendation based on a\nlarge language model of BERT and verifies it with real user data. The\nexperimental results show that BERT-based advertising push can effectively\nimprove the click-through rate and conversion rate of advertisements. At the\nsame time, through local model training and privacy protection mechanisms, the\nrisk of user privacy leakage can be reduced to a certain extent.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.04665v1",
    "published_date": "2025-05-07 04:25:41 UTC",
    "updated_date": "2025-05-07 04:25:41 UTC"
  },
  {
    "arxiv_id": "2505.04115v1",
    "title": "Polynomial-Time Relational Probabilistic Inference in Open Universes",
    "authors": [
      "Luise Ge",
      "Brendan Juba",
      "Kris Nilsson"
    ],
    "abstract": "Reasoning under uncertainty is a fundamental challenge in Artificial\nIntelligence. As with most of these challenges, there is a harsh dilemma\nbetween the expressive power of the language used, and the tractability of the\ncomputational problem posed by reasoning. Inspired by human reasoning, we\nintroduce a method of first-order relational probabilistic inference that\nsatisfies both criteria, and can handle hybrid (discrete and continuous)\nvariables. Specifically, we extend sum-of-squares logic of expectation to\nrelational settings, demonstrating that lifted reasoning in the bounded-degree\nfragment for knowledge bases of bounded quantifier rank can be performed in\npolynomial time, even with an a priori unknown and/or countably infinite set of\nobjects. Crucially, our notion of tractability is framed in proof-theoretic\nterms, which extends beyond the syntactic properties of the language or\nqueries. We are able to derive the tightest bounds provable by proofs of a\ngiven degree and size and establish completeness in our sum-of-squares\nrefutations for fixed degrees.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.04115v1",
    "published_date": "2025-05-07 04:14:03 UTC",
    "updated_date": "2025-05-07 04:14:03 UTC"
  },
  {
    "arxiv_id": "2505.04664v1",
    "title": "Advancing 3D Medical Image Segmentation: Unleashing the Potential of Planarian Neural Networks in Artificial Intelligence",
    "authors": [
      "Ziyuan Huang",
      "Kevin Huggins",
      "Srikar Bellur"
    ],
    "abstract": "Our study presents PNN-UNet as a method for constructing deep neural networks\nthat replicate the planarian neural network (PNN) structure in the context of\n3D medical image data. Planarians typically have a cerebral structure\ncomprising two neural cords, where the cerebrum acts as a coordinator, and the\nneural cords serve slightly different purposes within the organism's\nneurological system. Accordingly, PNN-UNet comprises a Deep-UNet and a\nWide-UNet as the nerve cords, with a densely connected autoencoder performing\nthe role of the brain. This distinct architecture offers advantages over both\nmonolithic (UNet) and modular networks (Ensemble-UNet). Our outcomes on a 3D\nMRI hippocampus dataset, with and without data augmentation, demonstrate that\nPNN-UNet outperforms the baseline UNet and several other UNet variants in image\nsegmentation.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV",
      "68T07"
    ],
    "primary_category": "eess.IV",
    "comment": "36 pages, 8 figures, 21 tables",
    "pdf_url": "http://arxiv.org/pdf/2505.04664v1",
    "published_date": "2025-05-07 03:54:37 UTC",
    "updated_date": "2025-05-07 03:54:37 UTC"
  },
  {
    "arxiv_id": "2505.04104v1",
    "title": "Position: We need responsible, application-driven (RAD) AI research",
    "authors": [
      "Sarah Hartman",
      "Cheng Soon Ong",
      "Julia Powles",
      "Petra Kuhnert"
    ],
    "abstract": "This position paper argues that achieving meaningful scientific and societal\nadvances with artificial intelligence (AI) requires a responsible,\napplication-driven approach (RAD) to AI research. As AI is increasingly\nintegrated into society, AI researchers must engage with the specific contexts\nwhere AI is being applied. This includes being responsive to ethical and legal\nconsiderations, technical and societal constraints, and public discourse. We\npresent the case for RAD-AI to drive research through a three-staged approach:\n(1) building transdisciplinary teams and people-centred studies; (2) addressing\ncontext-specific methods, ethical commitments, assumptions, and metrics; and\n(3) testing and sustaining efficacy through staged testbeds and a community of\npractice. We present a vision for the future of application-driven AI research\nto unlock new value through technically feasible methods that are adaptive to\nthe contextual needs and values of the communities they ultimately serve.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CY",
      "I.2.0; K.4.1; J.4"
    ],
    "primary_category": "cs.LG",
    "comment": "11 pages, 1 figure, Accepted to Proceedings of the 41 st\n  International Conference on Machine Learning, Vancouver, Canada. PMLR 267,\n  2025",
    "pdf_url": "http://arxiv.org/pdf/2505.04104v1",
    "published_date": "2025-05-07 03:43:52 UTC",
    "updated_date": "2025-05-07 03:43:52 UTC"
  },
  {
    "arxiv_id": "2505.04101v1",
    "title": "LLMs' Suitability for Network Security: A Case Study of STRIDE Threat Modeling",
    "authors": [
      "AbdulAziz AbdulGhaffar",
      "Ashraf Matrawy"
    ],
    "abstract": "Artificial Intelligence (AI) is expected to be an integral part of\nnext-generation AI-native 6G networks. With the prevalence of AI, researchers\nhave identified numerous use cases of AI in network security. However, there\nare almost nonexistent studies that analyze the suitability of Large Language\nModels (LLMs) in network security. To fill this gap, we examine the suitability\nof LLMs in network security, particularly with the case study of STRIDE threat\nmodeling. We utilize four prompting techniques with five LLMs to perform STRIDE\nclassification of 5G threats. From our evaluation results, we point out key\nfindings and detailed insights along with the explanation of the possible\nunderlying factors influencing the behavior of LLMs in the modeling of certain\nthreats. The numerical results and the insights support the necessity for\nadjusting and fine-tuning LLMs for network security use cases.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.NI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.04101v1",
    "published_date": "2025-05-07 03:37:49 UTC",
    "updated_date": "2025-05-07 03:37:49 UTC"
  },
  {
    "arxiv_id": "2505.04084v1",
    "title": "An Empirical Study of OpenAI API Discussions on Stack Overflow",
    "authors": [
      "Xiang Chen",
      "Jibin Wang",
      "Chaoyang Gao",
      "Xiaolin Ju",
      "Zhanqi Cui"
    ],
    "abstract": "The rapid advancement of large language models (LLMs), represented by\nOpenAI's GPT series, has significantly impacted various domains such as natural\nlanguage processing, software development, education, healthcare, finance, and\nscientific research. However, OpenAI APIs introduce unique challenges that\ndiffer from traditional APIs, such as the complexities of prompt engineering,\ntoken-based cost management, non-deterministic outputs, and operation as black\nboxes. To the best of our knowledge, the challenges developers encounter when\nusing OpenAI APIs have not been explored in previous empirical studies. To fill\nthis gap, we conduct the first comprehensive empirical study by analyzing 2,874\nOpenAI API-related discussions from the popular Q&A forum Stack Overflow. We\nfirst examine the popularity and difficulty of these posts. After manually\ncategorizing them into nine OpenAI API-related categories, we identify specific\nchallenges associated with each category through topic modeling analysis. Based\non our empirical findings, we finally propose actionable implications for\ndevelopers, LLM vendors, and researchers.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.04084v1",
    "published_date": "2025-05-07 02:51:32 UTC",
    "updated_date": "2025-05-07 02:51:32 UTC"
  },
  {
    "arxiv_id": "2505.04083v1",
    "title": "Plexus: Taming Billion-edge Graphs with 3D Parallel GNN Training",
    "authors": [
      "Aditya K. Ranjan",
      "Siddharth Singh",
      "Cunyang Wei",
      "Abhinav Bhatele"
    ],
    "abstract": "Graph neural networks have emerged as a potent class of neural networks\ncapable of leveraging the connectivity and structure of real-world graphs to\nlearn intricate properties and relationships between nodes. Many real-world\ngraphs exceed the memory capacity of a GPU due to their sheer size, and using\nGNNs on them requires techniques such as mini-batch sampling to scale. However,\nthis can lead to reduced accuracy in some cases, and sampling and data transfer\nfrom the CPU to the GPU can also slow down training. On the other hand,\ndistributed full-graph training suffers from high communication overhead and\nload imbalance due to the irregular structure of graphs. We propose Plexus, a\nthree-dimensional (3D) parallel approach for full-graph training that tackles\nthese issues and scales to billion-edge graphs. Additionally, we introduce\noptimizations such as a permutation scheme for load balancing, and a\nperformance model to predict the optimal 3D configuration. We evaluate Plexus\non several graph datasets and show scaling results for up to 2048 GPUs on\nPerlmutter, which is 33% of the machine, and 2048 GCDs on Frontier. Plexus\nachieves unprecedented speedups of 2.3x-12.5x over existing methods and a\nreduction in the time to solution by 5.2-8.7x on Perlmutter and 7-54.2x on\nFrontier.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.DC"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.04083v1",
    "published_date": "2025-05-07 02:49:52 UTC",
    "updated_date": "2025-05-07 02:49:52 UTC"
  },
  {
    "arxiv_id": "2505.04075v1",
    "title": "LLM-e Guess: Can LLMs Capabilities Advance Without Hardware Progress?",
    "authors": [
      "Teddy Foley",
      "Spencer Guo",
      "Henry Josephson",
      "Anqi Qu",
      "Jack Sanderson"
    ],
    "abstract": "This paper examines whether large language model (LLM) capabilities can\ncontinue to advance without additional compute by analyzing the development and\nrole of algorithms used in state-of-the-art LLMs. Motivated by regulatory\nefforts that have largely focused on restricting access to high-performance\nhardware, we ask: Can LLMs progress in a compute-constrained environment, and\nhow do algorithmic innovations perform under such conditions?\n  To address these questions, we introduce a novel classification framework\nthat distinguishes between compute-dependent innovations -- which yield\ndisproportionate benefits at high compute levels (e.g., the Transformer\narchitecture and mixture-of-experts models) and compute-independent\ninnovations, which improve efficiency across all compute scales (e.g., rotary\npositional encoding, FlashAttention, or layer normalization). We quantify these\ncontributions using a metric called compute-equivalent gain (CEG), which\nestimates the additional compute that would be required to achieve similar\nimprovements without these algorithmic advancements.\n  To validate this framework, we conduct small-scale training experiments with\na scaled-down GPT-2 model. Our results confirm that compute-independent\nadvancements yield meaningful performance gains even in resource-constrained\nsettings, with a CEG of up to $3.5\\times$ over a baseline model. By contrast,\ncompute-dependent advancements provided little benefit or even degraded\nperformance at the small scale, reinforcing the importance of compute\navailability for certain algorithmic gains.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "I.2"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.04075v1",
    "published_date": "2025-05-07 02:26:17 UTC",
    "updated_date": "2025-05-07 02:26:17 UTC"
  },
  {
    "arxiv_id": "2505.04072v1",
    "title": "Advancing and Benchmarking Personalized Tool Invocation for LLMs",
    "authors": [
      "Xu Huang",
      "Yuefeng Huang",
      "Weiwen Liu",
      "Xingshan Zeng",
      "Yasheng Wang",
      "Ruiming Tang",
      "Hong Xie",
      "Defu Lian"
    ],
    "abstract": "Tool invocation is a crucial mechanism for extending the capabilities of\nLarge Language Models (LLMs) and has recently garnered significant attention.\nIt enables LLMs to solve complex problems through tool calls while accessing\nup-to-date world knowledge. However, existing work primarily focuses on the\nfundamental ability of LLMs to invoke tools for problem-solving, without\nconsidering personalized constraints in tool invocation. In this work, we\nintroduce the concept of Personalized Tool Invocation and define two key tasks:\nTool Preference and Profile-dependent Query. Tool Preference addresses user\npreferences when selecting among functionally similar tools, while\nProfile-dependent Query considers cases where a user query lacks certain tool\nparameters, requiring the model to infer them from the user profile. To tackle\nthese challenges, we propose PTool, a data synthesis framework designed for\npersonalized tool invocation. Additionally, we construct \\textbf{PTBench}, the\nfirst benchmark for evaluating personalized tool invocation. We then fine-tune\nvarious open-source models, demonstrating the effectiveness of our framework\nand providing valuable insights. Our benchmark is public at\nhttps://github.com/hyfshadow/PTBench.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "14 pages, 7 figures, 5 tables",
    "pdf_url": "http://arxiv.org/pdf/2505.04072v1",
    "published_date": "2025-05-07 02:25:20 UTC",
    "updated_date": "2025-05-07 02:25:20 UTC"
  },
  {
    "arxiv_id": "2505.04034v1",
    "title": "Izhikevich-Inspired Temporal Dynamics for Enhancing Privacy, Efficiency, and Transferability in Spiking Neural Networks",
    "authors": [
      "Ayana Moshruba",
      "Hamed Poursiami",
      "Maryam Parsa"
    ],
    "abstract": "Biological neurons exhibit diverse temporal spike patterns, which are\nbelieved to support efficient, robust, and adaptive neural information\nprocessing. While models such as Izhikevich can replicate a wide range of these\nfiring dynamics, their complexity poses challenges for directly integrating\nthem into scalable spiking neural networks (SNN) training pipelines. In this\nwork, we propose two probabilistically driven, input-level temporal spike\ntransformations: Poisson-Burst and Delayed-Burst that introduce biologically\ninspired temporal variability directly into standard Leaky Integrate-and-Fire\n(LIF) neurons. This enables scalable training and systematic evaluation of how\nspike timing dynamics affect privacy, generalization, and learning performance.\nPoisson-Burst modulates burst occurrence based on input intensity, while\nDelayed-Burst encodes input strength through burst onset timing. Through\nextensive experiments across multiple benchmarks, we demonstrate that\nPoisson-Burst maintains competitive accuracy and lower resource overhead while\nexhibiting enhanced privacy robustness against membership inference attacks,\nwhereas Delayed-Burst provides stronger privacy protection at a modest accuracy\ntrade-off. These findings highlight the potential of biologically grounded\ntemporal spike dynamics in improving the privacy, generalization and biological\nplausibility of neuromorphic learning systems.",
    "categories": [
      "cs.NE",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.NE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.04034v1",
    "published_date": "2025-05-07 00:27:00 UTC",
    "updated_date": "2025-05-07 00:27:00 UTC"
  }
]