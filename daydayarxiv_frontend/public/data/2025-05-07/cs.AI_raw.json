[
  {
    "arxiv_id": "2505.04623v1",
    "title": "EchoInk-R1: Exploring Audio-Visual Reasoning in Multimodal LLMs via Reinforcement Learning",
    "authors": [
      "Zhenghao Xing",
      "Xiaowei Hu",
      "Chi-Wing Fu",
      "Wenhai Wang",
      "Jifeng Dai",
      "Pheng-Ann Heng"
    ],
    "abstract": "Multimodal large language models (MLLMs) have advanced perception across\ntext, vision, and audio, yet they often struggle with structured cross-modal\nreasoning, particularly when integrating audio and visual signals. We introduce\nEchoInk-R1, a reinforcement learning framework that enhances such reasoning in\nMLLMs. Built upon the Qwen2.5-Omni-7B foundation and optimized with Group\nRelative Policy Optimization (GRPO), EchoInk-R1 tackles multiple-choice\nquestion answering over synchronized audio-image pairs. To enable this, we\ncurate AVQA-R1-6K, a dataset pairing such audio-image inputs with\nmultiple-choice questions derived from OmniInstruct-v1. EchoInk-R1-7B achieves\n85.77% accuracy on the validation set, outperforming the base model, which\nscores 80.53%, using only 562 reinforcement learning steps. Beyond accuracy,\nEchoInk-R1 demonstrates reflective reasoning by revisiting initial\ninterpretations and refining responses when facing ambiguous multimodal inputs.\nThese results suggest that lightweight reinforcement learning fine-tuning\nenhances cross-modal reasoning in MLLMs. EchoInk-R1 is the first framework to\nunify audio, visual, and textual modalities for general open-world reasoning\nvia reinforcement learning. Code and data are publicly released to facilitate\nfurther research.",
    "categories": [
      "eess.AS",
      "cs.AI",
      "cs.CV",
      "cs.MM",
      "cs.SD"
    ],
    "primary_category": "eess.AS",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.04623v1",
    "published_date": "2025-05-07 17:59:49 UTC",
    "updated_date": "2025-05-07 17:59:49 UTC"
  },
  {
    "arxiv_id": "2505.04621v1",
    "title": "Score Distillation Sampling for Audio: Source Separation, Synthesis, and Beyond",
    "authors": [
      "Jessie Richter-Powell",
      "Antonio Torralba",
      "Jonathan Lorraine"
    ],
    "abstract": "We introduce Audio-SDS, a generalization of Score Distillation Sampling (SDS)\nto text-conditioned audio diffusion models. While SDS was initially designed\nfor text-to-3D generation using image diffusion, its core idea of distilling a\npowerful generative prior into a separate parametric representation extends to\nthe audio domain. Leveraging a single pretrained model, Audio-SDS enables a\nbroad range of tasks without requiring specialized datasets. In particular, we\ndemonstrate how Audio-SDS can guide physically informed impact sound\nsimulations, calibrate FM-synthesis parameters, and perform prompt-specified\nsource separation. Our findings illustrate the versatility of\ndistillation-based methods across modalities and establish a robust foundation\nfor future work using generative priors in audio tasks.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.LG",
      "cs.MM",
      "eess.AS",
      "68T07",
      "I.2.6; H.5.5; H.5.1"
    ],
    "primary_category": "cs.SD",
    "comment": "See the project website at\n  https://research.nvidia.com/labs/toronto-ai/Audio-SDS/",
    "pdf_url": "http://arxiv.org/pdf/2505.04621v1",
    "published_date": "2025-05-07 17:59:38 UTC",
    "updated_date": "2025-05-07 17:59:38 UTC"
  },
  {
    "arxiv_id": "2505.04608v1",
    "title": "WATCH: Weighted Adaptive Testing for Changepoint Hypotheses via Weighted-Conformal Martingales",
    "authors": [
      "Drew Prinster",
      "Xing Han",
      "Anqi Liu",
      "Suchi Saria"
    ],
    "abstract": "Responsibly deploying artificial intelligence (AI) / machine learning (ML)\nsystems in high-stakes settings arguably requires not only proof of system\nreliability, but moreover continual, post-deployment monitoring to quickly\ndetect and address any unsafe behavior. Statistical methods for nonparametric\nchange-point detection -- especially the tools of conformal test martingales\n(CTMs) and anytime-valid inference -- offer promising approaches to this\nmonitoring task. However, existing methods are restricted to monitoring limited\nhypothesis classes or ``alarm criteria,'' such as data shifts that violate\ncertain exchangeability assumptions, or do not allow for online adaptation in\nresponse to shifts. In this paper, we expand the scope of these monitoring\nmethods by proposing a weighted generalization of conformal test martingales\n(WCTMs), which lay a theoretical foundation for online monitoring for any\nunexpected changepoints in the data distribution while controlling\nfalse-alarms. For practical applications, we propose specific WCTM algorithms\nthat accommodate online adaptation to mild covariate shifts (in the marginal\ninput distribution) while raising alarms in response to more severe shifts,\nsuch as concept shifts (in the conditional label distribution) or extreme\n(out-of-support) covariate shifts that cannot be easily adapted to. On\nreal-world datasets, we demonstrate improved performance relative to\nstate-of-the-art baselines.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "To be published in The International Conference on Machine Learning\n  (ICML), 2025",
    "pdf_url": "http://arxiv.org/pdf/2505.04608v1",
    "published_date": "2025-05-07 17:53:47 UTC",
    "updated_date": "2025-05-07 17:53:47 UTC"
  },
  {
    "arxiv_id": "2505.04592v1",
    "title": "AI Governance to Avoid Extinction: The Strategic Landscape and Actionable Research Questions",
    "authors": [
      "Peter Barnett",
      "Aaron Scher"
    ],
    "abstract": "Humanity appears to be on course to soon develop AI systems that\nsubstantially outperform human experts in all cognitive domains and activities.\nWe believe the default trajectory has a high likelihood of catastrophe,\nincluding human extinction. Risks come from failure to control powerful AI\nsystems, misuse of AI by malicious rogue actors, war between great powers, and\nauthoritarian lock-in. This research agenda has two aims: to describe the\nstrategic landscape of AI development and to catalog important governance\nresearch questions. These questions, if answered, would provide important\ninsight on how to successfully reduce catastrophic risks.\n  We describe four high-level scenarios for the geopolitical response to\nadvanced AI development, cataloging the research questions most relevant to\neach. Our favored scenario involves building the technical, legal, and\ninstitutional infrastructure required to internationally restrict dangerous AI\ndevelopment and deployment (which we refer to as an Off Switch), which leads\ninto an internationally coordinated Halt on frontier AI activities at some\npoint in the future. The second scenario we describe is a US National Project\nfor AI, in which the US Government races to develop advanced AI systems and\nestablish unilateral control over global AI development. We also describe two\nadditional scenarios: a Light-Touch world similar to that of today and a Threat\nof Sabotage situation where countries use sabotage and deterrence to slow AI\ndevelopment.\n  In our view, apart from the Off Switch and Halt scenario, all of these\ntrajectories appear to carry an unacceptable risk of catastrophic harm. Urgent\naction is needed from the US National Security community and AI governance\necosystem to answer key research questions, build the capability to halt\ndangerous AI activities, and prepare for international AI agreements.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.04592v1",
    "published_date": "2025-05-07 17:35:36 UTC",
    "updated_date": "2025-05-07 17:35:36 UTC"
  },
  {
    "arxiv_id": "2505.04578v1",
    "title": "Fight Fire with Fire: Defending Against Malicious RL Fine-Tuning via Reward Neutralization",
    "authors": [
      "Wenjun Cao"
    ],
    "abstract": "Reinforcement learning (RL) fine-tuning transforms large language models\nwhile creating a vulnerability we experimentally verify: Our experiment shows\nthat malicious RL fine-tuning dismantles safety guardrails with remarkable\nefficiency, requiring only 50 steps and minimal adversarial prompts, with\nharmful escalating from 0-2 to 7-9. This attack vector particularly threatens\nopen-source models with parameter-level access. Existing defenses targeting\nsupervised fine-tuning prove ineffective against RL's dynamic feedback\nmechanisms. We introduce Reward Neutralization, the first defense framework\nspecifically designed against RL fine-tuning attacks, establishing concise\nrejection patterns that render malicious reward signals ineffective. Our\napproach trains models to produce minimal-information rejections that attackers\ncannot exploit, systematically neutralizing attempts to optimize toward harmful\noutputs. Experiments validate that our approach maintains low harmful scores\n(no greater than 2) after 200 attack steps, while standard models rapidly\ndeteriorate. This work provides the first constructive proof that robust\ndefense against increasingly accessible RL attacks is achievable, addressing a\ncritical security gap for open-weight models.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.04578v1",
    "published_date": "2025-05-07 17:18:48 UTC",
    "updated_date": "2025-05-07 17:18:48 UTC"
  },
  {
    "arxiv_id": "2505.04558v1",
    "title": "Purity Law for Generalizable Neural TSP Solvers",
    "authors": [
      "Wenzhao Liu",
      "Haoran Li",
      "Congying Han",
      "Zicheng Zhang",
      "Anqi Li",
      "Tiande Guo"
    ],
    "abstract": "Achieving generalization in neural approaches across different scales and\ndistributions remains a significant challenge for the Traveling Salesman\nProblem~(TSP). A key obstacle is that neural networks often fail to learn\nrobust principles for identifying universal patterns and deriving optimal\nsolutions from diverse instances. In this paper, we first uncover Purity Law\n(PuLa), a fundamental structural principle for optimal TSP solutions, defining\nthat edge prevalence grows exponentially with the sparsity of surrounding\nvertices. Statistically validated across diverse instances, PuLa reveals a\nconsistent bias toward local sparsity in global optima. Building on this\ninsight, we propose Purity Policy Optimization~(PUPO), a novel training\nparadigm that explicitly aligns characteristics of neural solutions with PuLa\nduring the solution construction process to enhance generalization. Extensive\nexperiments demonstrate that PUPO can be seamlessly integrated with popular\nneural solvers, significantly enhancing their generalization performance\nwithout incurring additional computational overhead during inference.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.04558v1",
    "published_date": "2025-05-07 16:46:48 UTC",
    "updated_date": "2025-05-07 16:46:48 UTC"
  },
  {
    "arxiv_id": "2505.04553v1",
    "title": "Risk-sensitive Reinforcement Learning Based on Convex Scoring Functions",
    "authors": [
      "Shanyu Han",
      "Yang Liu",
      "Xiang Yu"
    ],
    "abstract": "We propose a reinforcement learning (RL) framework under a broad class of\nrisk objectives, characterized by convex scoring functions. This class covers\nmany common risk measures, such as variance, Expected Shortfall, entropic\nValue-at-Risk, and mean-risk utility. To resolve the time-inconsistency issue,\nwe consider an augmented state space and an auxiliary variable and recast the\nproblem as a two-state optimization problem. We propose a customized\nActor-Critic algorithm and establish some theoretical approximation guarantees.\nA key theoretical contribution is that our results do not require the Markov\ndecision process to be continuous. Additionally, we propose an auxiliary\nvariable sampling method inspired by the alternating minimization algorithm,\nwhich is convergent under certain conditions. We validate our approach in\nsimulation experiments with a financial application in statistical arbitrage\ntrading, demonstrating the effectiveness of the algorithm.",
    "categories": [
      "q-fin.MF",
      "cs.AI",
      "q-fin.RM"
    ],
    "primary_category": "q-fin.MF",
    "comment": "35 pages",
    "pdf_url": "http://arxiv.org/pdf/2505.04553v1",
    "published_date": "2025-05-07 16:31:42 UTC",
    "updated_date": "2025-05-07 16:31:42 UTC"
  },
  {
    "arxiv_id": "2505.04539v1",
    "title": "Qualitative Analysis of $ω$-Regular Objectives on Robust MDPs",
    "authors": [
      "Ali Asadi",
      "Krishnendu Chatterjee",
      "Ehsan Kafshdar Goharshady",
      "Mehrdad Karrabi",
      "Ali Shafiee"
    ],
    "abstract": "Robust Markov Decision Processes (RMDPs) generalize classical MDPs that\nconsider uncertainties in transition probabilities by defining a set of\npossible transition functions. An objective is a set of runs (or infinite\ntrajectories) of the RMDP, and the value for an objective is the maximal\nprobability that the agent can guarantee against the adversarial environment.\nWe consider (a) reachability objectives, where given a target set of states,\nthe goal is to eventually arrive at one of them; and (b) parity objectives,\nwhich are a canonical representation for $\\omega$-regular objectives. The\nqualitative analysis problem asks whether the objective can be ensured with\nprobability 1.\n  In this work, we study the qualitative problem for reachability and parity\nobjectives on RMDPs without making any assumption over the structures of the\nRMDPs, e.g., unichain or aperiodic. Our contributions are twofold. We first\npresent efficient algorithms with oracle access to uncertainty sets that solve\nqualitative problems of reachability and parity objectives. We then report\nexperimental results demonstrating the effectiveness of our oracle-based\napproach on classical RMDP examples from the literature scaling up to thousands\nof states.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.04539v1",
    "published_date": "2025-05-07 16:15:40 UTC",
    "updated_date": "2025-05-07 16:15:40 UTC"
  },
  {
    "arxiv_id": "2505.04531v1",
    "title": "Overcoming Data Scarcity in Generative Language Modelling for Low-Resource Languages: A Systematic Review",
    "authors": [
      "Josh McGiff",
      "Nikola S. Nikolov"
    ],
    "abstract": "Generative language modelling has surged in popularity with the emergence of\nservices such as ChatGPT and Google Gemini. While these models have\ndemonstrated transformative potential in productivity and communication, they\noverwhelmingly cater to high-resource languages like English. This has\namplified concerns over linguistic inequality in natural language processing\n(NLP). This paper presents the first systematic review focused specifically on\nstrategies to address data scarcity in generative language modelling for\nlow-resource languages (LRL). Drawing from 54 studies, we identify, categorise\nand evaluate technical approaches, including monolingual data augmentation,\nback-translation, multilingual training, and prompt engineering, across\ngenerative tasks. We also analyse trends in architecture choices, language\nfamily representation, and evaluation methods. Our findings highlight a strong\nreliance on transformer-based models, a concentration on a small subset of\nLRLs, and a lack of consistent evaluation across studies. We conclude with\nrecommendations for extending these methods to a wider range of LRLs and\noutline open challenges in building equitable generative language systems.\nUltimately, this review aims to support researchers and developers in building\ninclusive AI tools for underrepresented languages, a necessary step toward\nempowering LRL speakers and the preservation of linguistic diversity in a world\nincreasingly shaped by large-scale language technologies.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "This work is currently under review. Please do not cite without\n  permission",
    "pdf_url": "http://arxiv.org/pdf/2505.04531v1",
    "published_date": "2025-05-07 16:04:45 UTC",
    "updated_date": "2025-05-07 16:04:45 UTC"
  },
  {
    "arxiv_id": "2505.04528v1",
    "title": "Beyond Theorem Proving: Formulation, Framework and Benchmark for Formal Problem-Solving",
    "authors": [
      "Qi Liu",
      "Xinhao Zheng",
      "Renqiu Xia",
      "Xingzhi Qi",
      "Qinxiang Cao",
      "Junchi Yan"
    ],
    "abstract": "As a seemingly self-explanatory task, problem-solving has been a significant\ncomponent of science and engineering. However, a general yet concrete\nformulation of problem-solving itself is missing. With the recent development\nof AI-based problem-solving agents, the demand for process-level verifiability\nis rapidly increasing yet underexplored. To fill these gaps, we present a\nprincipled formulation of problem-solving as a deterministic Markov decision\nprocess; a novel framework, FPS (Formal Problem-Solving), which utilizes\nexisting FTP (formal theorem proving) environments to perform process-verified\nproblem-solving; and D-FPS (Deductive FPS), decoupling solving and answer\nverification for better human-alignment. The expressiveness, soundness and\ncompleteness of the frameworks are proven. We construct three benchmarks on\nproblem-solving: FormalMath500, a formalization of a subset of the MATH500\nbenchmark; MiniF2F-Solving and PutnamBench-Solving, adaptations of FTP\nbenchmarks MiniF2F and PutnamBench. For faithful, interpretable, and\nhuman-aligned evaluation, we propose RPE (Restricted Propositional\nEquivalence), a symbolic approach to determine the correctness of answers by\nformal verification. We evaluate four prevalent FTP models and two prompting\nmethods as baselines, solving at most 23.77% of FormalMath500, 27.47% of\nMiniF2F-Solving, and 0.31% of PutnamBench-Solving.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LO"
    ],
    "primary_category": "cs.AI",
    "comment": "42 pages, 3 figures",
    "pdf_url": "http://arxiv.org/pdf/2505.04528v1",
    "published_date": "2025-05-07 16:02:14 UTC",
    "updated_date": "2025-05-07 16:02:14 UTC"
  },
  {
    "arxiv_id": "2505.04526v1",
    "title": "DFVO: Learning Darkness-free Visible and Infrared Image Disentanglement and Fusion All at Once",
    "authors": [
      "Qi Zhou",
      "Yukai Shi",
      "Xiaojun Yang",
      "Xiaoyu Xian",
      "Lunjia Liao",
      "Ruimao Zhang",
      "Liang Lin"
    ],
    "abstract": "Visible and infrared image fusion is one of the most crucial tasks in the\nfield of image fusion, aiming to generate fused images with clear structural\ninformation and high-quality texture features for high-level vision tasks.\nHowever, when faced with severe illumination degradation in visible images, the\nfusion results of existing image fusion methods often exhibit blurry and dim\nvisual effects, posing major challenges for autonomous driving. To this end, a\nDarkness-Free network is proposed to handle Visible and infrared image\ndisentanglement and fusion all at Once (DFVO), which employs a cascaded\nmulti-task approach to replace the traditional two-stage cascaded training\n(enhancement and fusion), addressing the issue of information entropy loss\ncaused by hierarchical data transmission. Specifically, we construct a\nlatent-common feature extractor (LCFE) to obtain latent features for the\ncascaded tasks strategy. Firstly, a details-extraction module (DEM) is devised\nto acquire high-frequency semantic information. Secondly, we design a hyper\ncross-attention module (HCAM) to extract low-frequency information and preserve\ntexture features from source images. Finally, a relevant loss function is\ndesigned to guide the holistic network learning, thereby achieving better image\nfusion. Extensive experiments demonstrate that our proposed approach\noutperforms state-of-the-art alternatives in terms of qualitative and\nquantitative evaluations. Particularly, DFVO can generate clearer, more\ninformative, and more evenly illuminated fusion results in the dark\nenvironments, achieving best performance on the LLVIP dataset with 63.258 dB\nPSNR and 0.724 CC, providing more effective information for high-level vision\ntasks. Our code is publicly accessible at https://github.com/DaVin-Qi530/DFVO.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.04526v1",
    "published_date": "2025-05-07 15:59:45 UTC",
    "updated_date": "2025-05-07 15:59:45 UTC"
  },
  {
    "arxiv_id": "2505.04525v1",
    "title": "On some improvements to Unbounded Minimax",
    "authors": [
      "Quentin Cohen-Solal",
      "Tristan Cazenave"
    ],
    "abstract": "This paper presents the first experimental evaluation of four previously\nuntested modifications of Unbounded Best-First Minimax algorithm. This\nalgorithm explores the game tree by iteratively expanding the most promising\nsequences of actions based on the current partial game tree. We first evaluate\nthe use of transposition tables, which convert the game tree into a directed\nacyclic graph by merging duplicate states. Second, we compare the original\nalgorithm by Korf & Chickering with the variant proposed by Cohen-Solal, which\ndiffers in its backpropagation strategy: instead of stopping when a stable\nvalue is encountered, it updates values up to the root. This change slightly\nimproves performance when value ties or transposition tables are involved.\nThird, we assess replacing the exact terminal evaluation function with the\nlearned heuristic function. While beneficial when exact evaluations are costly,\nthis modification reduces performance in inexpensive settings. Finally, we\nexamine the impact of the completion technique that prioritizes resolved\nwinning states and avoids resolved losing states. This technique also improves\nperformance. Overall, our findings highlight how targeted modifications can\nenhance the efficiency of Unbounded Best-First Minimax.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.04525v1",
    "published_date": "2025-05-07 15:59:19 UTC",
    "updated_date": "2025-05-07 15:59:19 UTC"
  },
  {
    "arxiv_id": "2505.04497v2",
    "title": "Defining and Quantifying Creative Behavior in Popular Image Generators",
    "authors": [
      "Aditi Ramaswamy",
      "Hana Chockler",
      "Melane Navaratnarajah"
    ],
    "abstract": "Creativity of generative AI models has been a subject of scientific debate in\nthe last years, without a conclusive answer. In this paper, we study creativity\nfrom a practical perspective and introduce quantitative measures that help the\nuser to choose a suitable AI model for a given task. We evaluated our measures\non a number of popular image-to-image generation models, and the results of\nthis suggest that our measures conform to human intuition.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "I.4.m; I.2.m"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.04497v2",
    "published_date": "2025-05-07 15:20:17 UTC",
    "updated_date": "2025-05-08 11:59:21 UTC"
  },
  {
    "arxiv_id": "2505.04493v1",
    "title": "Model-Based AI planning and Execution Systems for Robotics",
    "authors": [
      "Or Wertheim",
      "Ronen I. Brafman"
    ],
    "abstract": "Model-based planning and execution systems offer a principled approach to\nbuilding flexible autonomous robots that can perform diverse tasks by\nautomatically combining a host of basic skills. This idea is almost as old as\nmodern robotics. Yet, while diverse general-purpose reasoning architectures\nhave been proposed since, general-purpose systems that are integrated with\nmodern robotic platforms have emerged only recently, starting with the\ninfluential ROSPlan system. Since then, a growing number of model-based systems\nfor robot task-level control have emerged. In this paper, we consider the\ndiverse design choices and issues existing systems attempt to address, the\ndifferent solutions proposed so far, and suggest avenues for future\ndevelopment.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.04493v1",
    "published_date": "2025-05-07 15:17:38 UTC",
    "updated_date": "2025-05-07 15:17:38 UTC"
  },
  {
    "arxiv_id": "2505.04488v1",
    "title": "\"I Can See Forever!\": Evaluating Real-time VideoLLMs for Assisting Individuals with Visual Impairments",
    "authors": [
      "Ziyi Zhang",
      "Zhen Sun",
      "Zongmin Zhang",
      "Zifan Peng",
      "Yuemeng Zhao",
      "Zichun Wang",
      "Zeren Luo",
      "Ruiting Zuo",
      "Xinlei He"
    ],
    "abstract": "The visually impaired population, especially the severely visually impaired,\nis currently large in scale, and daily activities pose significant challenges\nfor them. Although many studies use large language and vision-language models\nto assist the blind, most focus on static content and fail to meet real-time\nperception needs in dynamic and complex environments, such as daily activities.\nTo provide them with more effective intelligent assistance, it is imperative to\nincorporate advanced visual understanding technologies. Although real-time\nvision and speech interaction VideoLLMs demonstrate strong real-time visual\nunderstanding, no prior work has systematically evaluated their effectiveness\nin assisting visually impaired individuals. In this work, we conduct the first\nsuch evaluation. First, we construct a benchmark dataset (VisAssistDaily),\ncovering three categories of assistive tasks for visually impaired individuals:\nBasic Skills, Home Life Tasks, and Social Life Tasks. The results show that\nGPT-4o achieves the highest task success rate. Next, we conduct a user study to\nevaluate the models in both closed-world and open-world scenarios, further\nexploring the practical challenges of applying VideoLLMs in assistive contexts.\nOne key issue we identify is the difficulty current models face in perceiving\npotential hazards in dynamic environments. To address this, we build an\nenvironment-awareness dataset named SafeVid and introduce a polling mechanism\nthat enables the model to proactively detect environmental risks. We hope this\nwork provides valuable insights and inspiration for future research in this\nfield.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.HC",
      "cs.MM"
    ],
    "primary_category": "cs.CV",
    "comment": "12 pages, 6 figures",
    "pdf_url": "http://arxiv.org/pdf/2505.04488v1",
    "published_date": "2025-05-07 15:03:16 UTC",
    "updated_date": "2025-05-07 15:03:16 UTC"
  },
  {
    "arxiv_id": "2505.04486v1",
    "title": "Efficient Flow Matching using Latent Variables",
    "authors": [
      "Anirban Samaddar",
      "Yixuan Sun",
      "Viktor Nilsson",
      "Sandeep Madireddy"
    ],
    "abstract": "Flow matching models have shown great potential in image generation tasks\namong probabilistic generative models. Building upon the ideas of continuous\nnormalizing flows, flow matching models generalize the transport path of the\ndiffusion models from a simple prior distribution to the data. Most flow\nmatching models in the literature do not explicitly model the underlying\nstructure/manifold in the target data when learning the flow from a simple\nsource distribution like the standard Gaussian. This leads to inefficient\nlearning, especially for many high-dimensional real-world datasets, which often\nreside in a low-dimensional manifold. Existing strategies of incorporating\nmanifolds, including data with underlying multi-modal distribution, often\nrequire expensive training and hence frequently lead to suboptimal performance.\nTo this end, we present \\texttt{Latent-CFM}, which provides simplified\ntraining/inference strategies to incorporate multi-modal data structures using\npretrained deep latent variable models. Through experiments on multi-modal\nsynthetic data and widely used image benchmark datasets, we show that\n\\texttt{Latent-CFM} exhibits improved generation quality with significantly\nless training ($\\sim 50\\%$ less in some cases) and computation than\nstate-of-the-art flow matching models. Using a 2d Darcy flow dataset, we\ndemonstrate that our approach generates more physically accurate samples than\ncompetitive approaches. In addition, through latent space analysis, we\ndemonstrate that our approach can be used for conditional image generation\nconditioned on latent features.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.04486v1",
    "published_date": "2025-05-07 14:59:23 UTC",
    "updated_date": "2025-05-07 14:59:23 UTC"
  },
  {
    "arxiv_id": "2505.04480v1",
    "title": "TrajEvo: Designing Trajectory Prediction Heuristics via LLM-driven Evolution",
    "authors": [
      "Zhikai Zhao",
      "Chuanbo Hua",
      "Federico Berto",
      "Kanghoon Lee",
      "Zihan Ma",
      "Jiachen Li",
      "Jinkyoo Park"
    ],
    "abstract": "Trajectory prediction is a crucial task in modeling human behavior,\nespecially in fields as social robotics and autonomous vehicle navigation.\nTraditional heuristics based on handcrafted rules often lack accuracy, while\nrecently proposed deep learning approaches suffer from computational cost, lack\nof explainability, and generalization issues that limit their practical\nadoption. In this paper, we introduce TrajEvo, a framework that leverages Large\nLanguage Models (LLMs) to automatically design trajectory prediction\nheuristics. TrajEvo employs an evolutionary algorithm to generate and refine\nprediction heuristics from past trajectory data. We introduce a\nCross-Generation Elite Sampling to promote population diversity and a\nStatistics Feedback Loop allowing the LLM to analyze alternative predictions.\nOur evaluations show TrajEvo outperforms previous heuristic methods on the\nETH-UCY datasets, and remarkably outperforms both heuristics and deep learning\nmethods when generalizing to the unseen SDD dataset. TrajEvo represents a first\nstep toward automated design of fast, explainable, and generalizable trajectory\nprediction heuristics. We make our source code publicly available to foster\nfuture research at https://github.com/ai4co/trajevo.",
    "categories": [
      "cs.AI",
      "cs.NE",
      "cs.RO"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.04480v1",
    "published_date": "2025-05-07 14:51:43 UTC",
    "updated_date": "2025-05-07 14:51:43 UTC"
  },
  {
    "arxiv_id": "2505.04468v1",
    "title": "Spectral and Temporal Denoising for Differentially Private Optimization",
    "authors": [
      "Hyeju Shin",
      "Kyudan Jung",
      "Seongwon Yun",
      "Juyoung Yun"
    ],
    "abstract": "This paper introduces the FFT-Enhanced Kalman Filter (FFTKF), a\ndifferentially private optimization method that addresses the challenge of\npreserving performance in DP-SGD, where added noise typically degrades model\nutility. FFTKF integrates frequency-domain noise shaping with Kalman filtering\nto enhance gradient quality while preserving $(\\varepsilon, \\delta)$-DP\nguarantees. It employs a high-frequency shaping mask in the Fourier domain to\nconcentrate differential privacy noise in less informative spectral components,\npreserving low-frequency gradient signals. A scalar-gain Kalman filter with\nfinite-difference Hessian approximation further refines the denoised gradients.\nWith a per-iteration complexity of $\\mathcal{O}(d \\log d)$, FFTKF demonstrates\nimproved test accuracy over DP-SGD and DiSK across MNIST, CIFAR-10, CIFAR-100,\nand Tiny-ImageNet datasets using CNNs, Wide ResNets, and Vision Transformers.\nTheoretical analysis confirms that FFTKF maintains equivalent privacy\nguarantees while achieving a tighter privacy-utility trade-off through reduced\nnoise and controlled bias.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.IT",
      "cs.NE",
      "math.IT"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.04468v1",
    "published_date": "2025-05-07 14:38:58 UTC",
    "updated_date": "2025-05-07 14:38:58 UTC"
  },
  {
    "arxiv_id": "2505.04464v1",
    "title": "Discriminative Ordering Through Ensemble Consensus",
    "authors": [
      "Louis Ohl",
      "Fredrik Lindsten"
    ],
    "abstract": "Evaluating the performance of clustering models is a challenging task where\nthe outcome depends on the definition of what constitutes a cluster. Due to\nthis design, current existing metrics rarely handle multiple clustering models\nwith diverse cluster definitions, nor do they comply with the integration of\nconstraints when available. In this work, we take inspiration from consensus\nclustering and assume that a set of clustering models is able to uncover hidden\nstructures in the data. We propose to construct a discriminative ordering\nthrough ensemble clustering based on the distance between the connectivity of a\nclustering model and the consensus matrix. We first validate the proposed\nmethod with synthetic scenarios, highlighting that the proposed score ranks the\nmodels that best match the consensus first. We then show that this simple\nranking score significantly outperforms other scoring methods when comparing\nsets of different clustering algorithms that are not restricted to a fixed\nnumber of clusters and is compatible with clustering constraints.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "62H30",
      "G.3"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted at UAI 2025",
    "pdf_url": "http://arxiv.org/pdf/2505.04464v1",
    "published_date": "2025-05-07 14:35:39 UTC",
    "updated_date": "2025-05-07 14:35:39 UTC"
  },
  {
    "arxiv_id": "2505.04461v1",
    "title": "A Survey on Temporal Interaction Graph Representation Learning: Progress, Challenges, and Opportunities",
    "authors": [
      "Pengfei Jiao",
      "Hongjiang Chen",
      "Xuan Guo",
      "Zhidong Zhao",
      "Dongxiao He",
      "Di Jin"
    ],
    "abstract": "Temporal interaction graphs (TIGs), defined by sequences of timestamped\ninteraction events, have become ubiquitous in real-world applications due to\ntheir capability to model complex dynamic system behaviors. As a result,\ntemporal interaction graph representation learning (TIGRL) has garnered\nsignificant attention in recent years. TIGRL aims to embed nodes in TIGs into\nlow-dimensional representations that effectively preserve both structural and\ntemporal information, thereby enhancing the performance of downstream tasks\nsuch as classification, prediction, and clustering within constantly evolving\ndata environments. In this paper, we begin by introducing the foundational\nconcepts of TIGs and emphasize the critical role of temporal dependencies. We\nthen propose a comprehensive taxonomy of state-of-the-art TIGRL methods,\nsystematically categorizing them based on the types of information utilized\nduring the learning process to address the unique challenges inherent to TIGs.\nTo facilitate further research and practical applications, we curate the source\nof datasets and benchmarks, providing valuable resources for empirical\ninvestigations. Finally, we examine key open challenges and explore promising\nresearch directions in TIGRL, laying the groundwork for future advancements\nthat have the potential to shape the evolution of this field.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.SI"
    ],
    "primary_category": "cs.LG",
    "comment": "IJCAI 2025 Survey Track",
    "pdf_url": "http://arxiv.org/pdf/2505.04461v1",
    "published_date": "2025-05-07 14:31:10 UTC",
    "updated_date": "2025-05-07 14:31:10 UTC"
  },
  {
    "arxiv_id": "2505.04451v1",
    "title": "Automatic Music Transcription using Convolutional Neural Networks and Constant-Q transform",
    "authors": [
      "Yohannis Telila",
      "Tommaso Cucinotta",
      "Davide Bacciu"
    ],
    "abstract": "Automatic music transcription (AMT) is the problem of analyzing an audio\nrecording of a musical piece and detecting notes that are being played. AMT is\na challenging problem, particularly when it comes to polyphonic music. The goal\nof AMT is to produce a score representation of a music piece, by analyzing a\nsound signal containing multiple notes played simultaneously. In this work, we\ndesign a processing pipeline that can transform classical piano audio files in\n.wav format into a music score representation. The features from the audio\nsignals are extracted using the constant-Q transform, and the resulting\ncoefficients are used as an input to the convolutional neural network (CNN)\nmodel.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.LG",
      "cs.MM",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "6 pages",
    "pdf_url": "http://arxiv.org/pdf/2505.04451v1",
    "published_date": "2025-05-07 14:20:43 UTC",
    "updated_date": "2025-05-07 14:20:43 UTC"
  },
  {
    "arxiv_id": "2505.04435v1",
    "title": "FedBWO: Enhancing Communication Efficiency in Federated Learning",
    "authors": [
      "Vahideh Hayyolalam",
      "Öznur Özkasap"
    ],
    "abstract": "Federated Learning (FL) is a distributed Machine Learning (ML) setup, where a\nshared model is collaboratively trained by various clients using their local\ndatasets while keeping the data private. Considering resource-constrained\ndevices, FL clients often suffer from restricted transmission capacity. Aiming\nto enhance the system performance, the communication between clients and server\nneeds to be diminished. Current FL strategies transmit a tremendous amount of\ndata (model weights) within the FL process, which needs a high communication\nbandwidth. Considering resource constraints, increasing the number of clients\nand, consequently, the amount of data (model weights) can lead to a bottleneck.\nIn this paper, we introduce the Federated Black Widow Optimization (FedBWO)\ntechnique to decrease the amount of transmitted data by transmitting only a\nperformance score rather than the local model weights from clients. FedBWO\nemploys the BWO algorithm to improve local model updates. The conducted\nexperiments prove that FedBWO remarkably improves the performance of the global\nmodel and the communication efficiency of the overall system. According to the\nexperimental outcomes, FedBWO enhances the global model accuracy by an average\nof 21% over FedAvg, and 12% over FedGWO. Furthermore, FedBWO dramatically\ndecreases the communication cost compared to other methods.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "5th IEEE International Conference on Human-Machine Systems, Abu\n  Dhabi, UAE, 26-28 May 2025",
    "pdf_url": "http://arxiv.org/pdf/2505.04435v1",
    "published_date": "2025-05-07 14:02:35 UTC",
    "updated_date": "2025-05-07 14:02:35 UTC"
  },
  {
    "arxiv_id": "2505.04419v1",
    "title": "Recognizing Ornaments in Vocal Indian Art Music with Active Annotation",
    "authors": [
      "Sumit Kumar",
      "Parampreet Singh",
      "Vipul Arora"
    ],
    "abstract": "Ornamentations, embellishments, or microtonal inflections are essential to\nmelodic expression across many musical traditions, adding depth, nuance, and\nemotional impact to performances. Recognizing ornamentations in singing voices\nis key to MIR, with potential applications in music pedagogy, singer\nidentification, genre classification, and controlled singing voice generation.\nHowever, the lack of annotated datasets and specialized modeling approaches\nremains a major obstacle for progress in this research area. In this work, we\nintroduce R\\=aga Ornamentation Detection (ROD), a novel dataset comprising\nIndian classical music recordings curated by expert musicians. The dataset is\nannotated using a custom Human-in-the-Loop tool for six vocal ornaments marked\nas event-based labels. Using this dataset, we develop an ornamentation\ndetection model based on deep time-series analysis, preserving ornament\nboundaries during the chunking of long audio recordings. We conduct experiments\nusing different train-test configurations within the ROD dataset and also\nevaluate our approach on a separate, manually annotated dataset of Indian\nclassical concert recordings. Our experimental results support the superior\nperformance of our proposed approach over the baseline CRNN.",
    "categories": [
      "eess.AS",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "eess.AS",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.04419v1",
    "published_date": "2025-05-07 13:52:50 UTC",
    "updated_date": "2025-05-07 13:52:50 UTC"
  },
  {
    "arxiv_id": "2505.04416v1",
    "title": "OBLIVIATE: Robust and Practical Machine Unlearning for Large Language Models",
    "authors": [
      "Xiaoyu Xu",
      "Minxin Du",
      "Qingqing Ye",
      "Haibo Hu"
    ],
    "abstract": "Large language models (LLMs) trained over extensive corpora risk memorizing\nsensitive, copyrighted, or toxic content. To address this, we propose\nOBLIVIATE, a robust unlearning framework that removes targeted data while\npreserving model utility. The framework follows a structured process:\nextracting target tokens, building retain sets, and fine-tuning with a tailored\nloss function comprising three components -- masking, distillation, and world\nfact. Using low-rank adapters (LoRA), it ensures efficiency without\ncompromising unlearning quality. We conduct experiments on multiple datasets,\nincluding the Harry Potter series, WMDP, and TOFU, using a comprehensive suite\nof metrics: forget quality (new document-level memorization score), model\nutility, and fluency. Results demonstrate its effectiveness in resisting\nmembership inference attacks, minimizing the impact on retained data, and\nmaintaining robustness across diverse scenarios.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CR",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "18 pages, 2 figures",
    "pdf_url": "http://arxiv.org/pdf/2505.04416v1",
    "published_date": "2025-05-07 13:51:42 UTC",
    "updated_date": "2025-05-07 13:51:42 UTC"
  },
  {
    "arxiv_id": "2505.04406v1",
    "title": "YABLoCo: Yet Another Benchmark for Long Context Code Generation",
    "authors": [
      "Aidar Valeev",
      "Roman Garaev",
      "Vadim Lomshakov",
      "Irina Piontkovskaya",
      "Vladimir Ivanov",
      "Israel Adewuyi"
    ],
    "abstract": "Large Language Models demonstrate the ability to solve various programming\ntasks, including code generation. Typically, the performance of LLMs is\nmeasured on benchmarks with small or medium-sized context windows of thousands\nof lines of code. At the same time, in real-world software projects,\nrepositories can span up to millions of LoC. This paper closes this gap by\ncontributing to the long context code generation benchmark (YABLoCo). The\nbenchmark featured a test set of 215 functions selected from four large\nrepositories with thousands of functions. The dataset contained metadata of\nfunctions, contexts of the functions with different levels of dependencies,\ndocstrings, functions bodies, and call graphs for each repository. This paper\npresents three key aspects of the contribution. First, the benchmark aims at\nfunction body generation in large repositories in C and C++, two languages not\ncovered by previous benchmarks. Second, the benchmark contains large\nrepositories from 200K to 2,000K LoC. Third, we contribute a scalable\nevaluation pipeline for efficient computing of the target metrics and a tool\nfor visual analysis of generated code. Overall, these three aspects allow for\nevaluating code generation in large repositories in C and C++.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.SE"
    ],
    "primary_category": "cs.CL",
    "comment": "Presented at LLM4Code 2025 Workshop co-located wtih ICSE 2025",
    "pdf_url": "http://arxiv.org/pdf/2505.04406v1",
    "published_date": "2025-05-07 13:42:23 UTC",
    "updated_date": "2025-05-07 13:42:23 UTC"
  },
  {
    "arxiv_id": "2505.04405v1",
    "title": "High-speed multiwavelength photonic temporal integration using silicon photonics",
    "authors": [
      "Yi Zhang",
      "Nikolaos Farmakidis",
      "Ioannis Roumpos",
      "Miltiadis Moralis-Pegios",
      "Apostolos Tsakyridis",
      "June Sang Lee",
      "Bowei Dong",
      "Yuhan He",
      "Samarth Aggarwal",
      "Nikolaos Pleros",
      "Harish Bhaskaran"
    ],
    "abstract": "Optical systems have been pivotal for energy-efficient computing, performing\nhigh-speed, parallel operations in low-loss carriers. While these predominantly\nanalog optical accelerators bypass digitization to perform parallel\nfloating-point computations, scaling optical hardware to map large-vector sizes\nfor AI tasks remains challenging. Here, we overcome this limitation by\nunfolding scalar operations in time and introducing a\nphotonic-heater-in-lightpath (PHIL) unit for all-optical temporal integration.\nCounterintuitively, we exploit a slow heat dissipation process to integrate\noptical signals modulated at 50 GHz bridging the speed gap between the widely\napplied thermo-optic effects and ultrafast photonics. This architecture\nsupports optical end-to-end signal processing, eliminates inefficient\nelectro-optical conversions, and enables both linear and nonlinear operations\nwithin a unified framework. Our results demonstrate a scalable path towards\nhigh-speed photonic computing through thermally driven integration.",
    "categories": [
      "physics.optics",
      "cs.AI",
      "physics.app-ph"
    ],
    "primary_category": "physics.optics",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.04405v1",
    "published_date": "2025-05-07 13:39:18 UTC",
    "updated_date": "2025-05-07 13:39:18 UTC"
  },
  {
    "arxiv_id": "2505.04404v1",
    "title": "In-Context Adaptation to Concept Drift for Learned Database Operations",
    "authors": [
      "Jiaqi Zhu",
      "Shaofeng Cai",
      "Yanyan Shen",
      "Gang Chen",
      "Fang Deng",
      "Beng Chin Ooi"
    ],
    "abstract": "Machine learning has demonstrated transformative potential for database\noperations, such as query optimization and in-database data analytics. However,\ndynamic database environments, characterized by frequent updates and evolving\ndata distributions, introduce concept drift, which leads to performance\ndegradation for learned models and limits their practical applicability.\nAddressing this challenge requires efficient frameworks capable of adapting to\nshifting concepts while minimizing the overhead of retraining or fine-tuning.\n  In this paper, we propose FLAIR, an online adaptation framework that\nintroduces a new paradigm called \\textit{in-context adaptation} for learned\ndatabase operations. FLAIR leverages the inherent property of data systems,\ni.e., immediate availability of execution results for predictions, to enable\ndynamic context construction. By formalizing adaptation as $f:(\\mathbf{x} \\,|\n\\,\\mathcal{C}_t) \\to \\mathbf{y}$, with $\\mathcal{C}_t$ representing a dynamic\ncontext memory, FLAIR delivers predictions aligned with the current concept,\neliminating the need for runtime parameter optimization. To achieve this, FLAIR\nintegrates two key modules: a Task Featurization Module for encoding\ntask-specific features into standardized representations, and a Dynamic\nDecision Engine, pre-trained via Bayesian meta-training, to adapt seamlessly\nusing contextual information at runtime. Extensive experiments across key\ndatabase tasks demonstrate that FLAIR outperforms state-of-the-art baselines,\nachieving up to 5.2x faster adaptation and reducing error by 22.5% for\ncardinality estimation.",
    "categories": [
      "cs.DB",
      "cs.AI"
    ],
    "primary_category": "cs.DB",
    "comment": "Accepted by ICML 2025",
    "pdf_url": "http://arxiv.org/pdf/2505.04404v1",
    "published_date": "2025-05-07 13:36:59 UTC",
    "updated_date": "2025-05-07 13:36:59 UTC"
  },
  {
    "arxiv_id": "2505.04397v1",
    "title": "Deep residual learning with product units",
    "authors": [
      "Ziyuan Li",
      "Uwe Jaekel",
      "Babette Dellen"
    ],
    "abstract": "We propose a deep product-unit residual neural network (PURe) that integrates\nproduct units into residual blocks to improve the expressiveness and parameter\nefficiency of deep convolutional networks. Unlike standard summation neurons,\nproduct units enable multiplicative feature interactions, potentially offering\na more powerful representation of complex patterns. PURe replaces conventional\nconvolutional layers with 2D product units in the second layer of each residual\nblock, eliminating nonlinear activation functions to preserve structural\ninformation. We validate PURe on three benchmark datasets. On Galaxy10 DECaLS,\nPURe34 achieves the highest test accuracy of 84.89%, surpassing the much deeper\nResNet152, while converging nearly five times faster and demonstrating strong\nrobustness to Poisson noise. On ImageNet, PURe architectures outperform\nstandard ResNet models at similar depths, with PURe34 achieving a top-1\naccuracy of 80.27% and top-5 accuracy of 95.78%, surpassing deeper ResNet\nvariants (ResNet50, ResNet101) while utilizing significantly fewer parameters\nand computational resources. On CIFAR-10, PURe consistently outperforms ResNet\nvariants across varying depths, with PURe272 reaching 95.01% test accuracy,\ncomparable to ResNet1001 but at less than half the model size. These results\ndemonstrate that PURe achieves a favorable balance between accuracy,\nefficiency, and robustness. Compared to traditional residual networks, PURe not\nonly achieves competitive classification performance with faster convergence\nand fewer parameters, but also demonstrates greater robustness to noise. Its\neffectiveness across diverse datasets highlights the potential of\nproduct-unit-based architectures for scalable and reliable deep learning in\ncomputer vision.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.04397v1",
    "published_date": "2025-05-07 13:21:25 UTC",
    "updated_date": "2025-05-07 13:21:25 UTC"
  },
  {
    "arxiv_id": "2505.04388v1",
    "title": "The Aloe Family Recipe for Open and Specialized Healthcare LLMs",
    "authors": [
      "Dario Garcia-Gasulla",
      "Jordi Bayarri-Planas",
      "Ashwin Kumar Gururajan",
      "Enrique Lopez-Cuena",
      "Adrian Tormos",
      "Daniel Hinjos",
      "Pablo Bernabeu-Perez",
      "Anna Arias-Duart",
      "Pablo Agustin Martin-Torres",
      "Marta Gonzalez-Mallo",
      "Sergio Alvarez-Napagao",
      "Eduard Ayguadé-Parra",
      "Ulises Cortés"
    ],
    "abstract": "Purpose: With advancements in Large Language Models (LLMs) for healthcare,\nthe need arises for competitive open-source models to protect the public\ninterest. This work contributes to the field of open medical LLMs by optimizing\nkey stages of data preprocessing and training, while showing how to improve\nmodel safety (through DPO) and efficacy (through RAG). The evaluation\nmethodology used, which includes four different types of tests, defines a new\nstandard for the field. The resultant models, shown to be competitive with the\nbest private alternatives, are released with a permisive license.\n  Methods: Building on top of strong base models like Llama 3.1 and Qwen 2.5,\nAloe Beta uses a custom dataset to enhance public data with synthetic Chain of\nThought examples. The models undergo alignment with Direct Preference\nOptimization, emphasizing ethical and policy-aligned performance in the\npresence of jailbreaking attacks. Evaluation includes close-ended, open-ended,\nsafety and human assessments, to maximize the reliability of results.\n  Results: Recommendations are made across the entire pipeline, backed by the\nsolid performance of the Aloe Family. These models deliver competitive\nperformance across healthcare benchmarks and medical fields, and are often\npreferred by healthcare professionals. On bias and toxicity, the Aloe Beta\nmodels significantly improve safety, showing resilience to unseen jailbreaking\nattacks. For a responsible release, a detailed risk assessment specific to\nhealthcare is attached to the Aloe Family models.\n  Conclusion: The Aloe Beta models, and the recipe that leads to them, are a\nsignificant contribution to the open-source medical LLM field, offering\ntop-of-the-line performance while maintaining high ethical requirements. This\nwork sets a new standard for developing and reporting aligned LLMs in\nhealthcare.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "arXiv admin note: substantial text overlap with arXiv:2405.01886",
    "pdf_url": "http://arxiv.org/pdf/2505.04388v1",
    "published_date": "2025-05-07 13:13:14 UTC",
    "updated_date": "2025-05-07 13:13:14 UTC"
  },
  {
    "arxiv_id": "2505.04379v1",
    "title": "Consensus-Aware AV Behavior: Trade-offs Between Safety, Interaction, and Performance in Mixed Urban Traffic",
    "authors": [
      "Mohammad Elayan",
      "Wissam Kontar"
    ],
    "abstract": "Transportation systems have long been shaped by complexity and heterogeneity,\ndriven by the interdependency of agent actions and traffic outcomes. The\ndeployment of automated vehicles (AVs) in such systems introduces a new\nchallenge: achieving consensus across safety, interaction quality, and traffic\nperformance. In this work, we position consensus as a fundamental property of\nthe traffic system and aim to quantify it. We use high-resolution trajectory\ndata from the Third Generation Simulation (TGSIM) dataset to empirically\nanalyze AV and human-driven vehicle (HDV) behavior at a signalized urban\nintersection and around vulnerable road users (VRUs). Key metrics, including\nTime-to-Collision (TTC), Post-Encroachment Time (PET), deceleration patterns,\nheadways, and string stability, are evaluated across the three performance\ndimensions. Results show that full consensus across safety, interaction, and\nperformance is rare, with only 1.63% of AV-VRU interaction frames meeting all\nthree conditions. These findings highlight the need for AV models that\nexplicitly balance multi-dimensional performance in mixed-traffic environments.\nFull reproducibility is supported via our open-source codebase on\nhttps://github.com/wissamkontar/Consensus-AV-Analysis.",
    "categories": [
      "cs.MA",
      "cs.AI",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.MA",
    "comment": "7 pages, 8 figures",
    "pdf_url": "http://arxiv.org/pdf/2505.04379v1",
    "published_date": "2025-05-07 12:59:59 UTC",
    "updated_date": "2025-05-07 12:59:59 UTC"
  },
  {
    "arxiv_id": "2505.04375v1",
    "title": "Balancing Accuracy, Calibration, and Efficiency in Active Learning with Vision Transformers Under Label Noise",
    "authors": [
      "Moseli Mots'oehli",
      "Hope Mogale",
      "Kyungim Baek"
    ],
    "abstract": "Fine-tuning pre-trained convolutional neural networks on ImageNet for\ndownstream tasks is well-established. Still, the impact of model size on the\nperformance of vision transformers in similar scenarios, particularly under\nlabel noise, remains largely unexplored. Given the utility and versatility of\ntransformer architectures, this study investigates their practicality under\nlow-budget constraints and noisy labels. We explore how classification accuracy\nand calibration are affected by symmetric label noise in active learning\nsettings, evaluating four vision transformer configurations (Base and Large\nwith 16x16 and 32x32 patch sizes) and three Swin Transformer configurations\n(Tiny, Small, and Base) on CIFAR10 and CIFAR100 datasets, under varying label\nnoise rates. Our findings show that larger ViT models (ViTl32 in particular)\nconsistently outperform their smaller counterparts in both accuracy and\ncalibration, even under moderate to high label noise, while Swin Transformers\nexhibit weaker robustness across all noise levels. We find that smaller patch\nsizes do not always lead to better performance, as ViTl16 performs consistently\nworse than ViTl32 while incurring a higher computational cost. We also find\nthat information-based Active Learning strategies only provide meaningful\naccuracy improvements at moderate label noise rates, but they result in poorer\ncalibration compared to models trained on randomly acquired labels, especially\nat high label noise rates. We hope these insights provide actionable guidance\nfor practitioners looking to deploy vision transformers in resource-constrained\nenvironments, where balancing model complexity, label noise, and compute\nefficiency is critical in model fine-tuning or distillation.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.04375v1",
    "published_date": "2025-05-07 12:53:13 UTC",
    "updated_date": "2025-05-07 12:53:13 UTC"
  },
  {
    "arxiv_id": "2505.04354v1",
    "title": "Optimization Problem Solving Can Transition to Evolutionary Agentic Workflows",
    "authors": [
      "Wenhao Li",
      "Bo Jin",
      "Mingyi Hong",
      "Changhong Lu",
      "Xiangfeng Wang"
    ],
    "abstract": "This position paper argues that optimization problem solving can transition\nfrom expert-dependent to evolutionary agentic workflows. Traditional\noptimization practices rely on human specialists for problem formulation,\nalgorithm selection, and hyperparameter tuning, creating bottlenecks that\nimpede industrial adoption of cutting-edge methods. We contend that an\nevolutionary agentic workflow, powered by foundation models and evolutionary\nsearch, can autonomously navigate the optimization space, comprising problem,\nformulation, algorithm, and hyperparameter spaces. Through case studies in\ncloud resource scheduling and ADMM parameter adaptation, we demonstrate how\nthis approach can bridge the gap between academic innovation and industrial\nimplementation. Our position challenges the status quo of human-centric\noptimization workflows and advocates for a more scalable, adaptive approach to\nsolving real-world optimization problems.",
    "categories": [
      "math.OC",
      "cs.AI"
    ],
    "primary_category": "math.OC",
    "comment": "27 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2505.04354v1",
    "published_date": "2025-05-07 12:07:49 UTC",
    "updated_date": "2025-05-07 12:07:49 UTC"
  },
  {
    "arxiv_id": "2505.04352v1",
    "title": "Uncertain Machine Ethics Planning",
    "authors": [
      "Simon Kolker",
      "Louise A. Dennis",
      "Ramon Fraga Pereira",
      "Mengwei Xu"
    ],
    "abstract": "Machine Ethics decisions should consider the implications of uncertainty over\ndecisions. Decisions should be made over sequences of actions to reach\npreferable outcomes long term. The evaluation of outcomes, however, may invoke\none or more moral theories, which might have conflicting judgements. Each\ntheory will require differing representations of the ethical situation. For\nexample, Utilitarianism measures numerical values, Deontology analyses duties,\nand Virtue Ethics emphasises moral character. While balancing potentially\nconflicting moral considerations, decisions may need to be made, for example,\nto achieve morally neutral goals with minimal costs. In this paper, we\nformalise the problem as a Multi-Moral Markov Decision Process and a\nMulti-Moral Stochastic Shortest Path Problem. We develop a heuristic algorithm\nbased on Multi-Objective AO*, utilising Sven-Ove Hansson's Hypothetical\nRetrospection procedure for ethical reasoning under uncertainty. Our approach\nis validated by a case study from Machine Ethics literature: the problem of\nwhether to steal insulin for someone who needs it.",
    "categories": [
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.04352v1",
    "published_date": "2025-05-07 12:03:15 UTC",
    "updated_date": "2025-05-07 12:03:15 UTC"
  },
  {
    "arxiv_id": "2505.04340v1",
    "title": "Multi-Granular Attention based Heterogeneous Hypergraph Neural Network",
    "authors": [
      "Hong Jin",
      "Kaicheng Zhou",
      "Jie Yin",
      "Lan You",
      "Zhifeng Zhou"
    ],
    "abstract": "Heterogeneous graph neural networks (HeteGNNs) have demonstrated strong\nabilities to learn node representations by effectively extracting complex\nstructural and semantic information in heterogeneous graphs. Most of the\nprevailing HeteGNNs follow the neighborhood aggregation paradigm, leveraging\nmeta-path based message passing to learn latent node representations. However,\ndue to the pairwise nature of meta-paths, these models fail to capture\nhigh-order relations among nodes, resulting in suboptimal performance.\nAdditionally, the challenge of ``over-squashing'', where long-range message\npassing in HeteGNNs leads to severe information distortion, further limits the\nefficacy of these models. To address these limitations, this paper proposes\nMGA-HHN, a Multi-Granular Attention based Heterogeneous Hypergraph Neural\nNetwork for heterogeneous graph representation learning. MGA-HHN introduces two\nkey innovations: (1) a novel approach for constructing meta-path based\nheterogeneous hypergraphs that explicitly models higher-order semantic\ninformation in heterogeneous graphs through multiple views, and (2) a\nmulti-granular attention mechanism that operates at both the node and hyperedge\nlevels. This mechanism enables the model to capture fine-grained interactions\namong nodes sharing the same semantic context within a hyperedge type, while\npreserving the diversity of semantics across different hyperedge types. As\nsuch, MGA-HHN effectively mitigates long-range message distortion and generates\nmore expressive node representations. Extensive experiments on real-world\nbenchmark datasets demonstrate that MGA-HHN outperforms state-of-the-art\nmodels, showcasing its effectiveness in node classification, node clustering\nand visualization tasks.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.04340v1",
    "published_date": "2025-05-07 11:42:00 UTC",
    "updated_date": "2025-05-07 11:42:00 UTC"
  },
  {
    "arxiv_id": "2505.04318v1",
    "title": "Detecting Concept Drift in Neural Networks Using Chi-squared Goodness of Fit Testing",
    "authors": [
      "Jacob Glenn Ayers",
      "Buvaneswari A. Ramanan",
      "Manzoor A. Khan"
    ],
    "abstract": "As the adoption of deep learning models has grown beyond human capacity for\nverification, meta-algorithms are needed to ensure reliable model inference.\nConcept drift detection is a field dedicated to identifying statistical shifts\nthat is underutilized in monitoring neural networks that may encounter\ninference data with distributional characteristics diverging from their\ntraining data. Given the wide variety of model architectures, applications, and\ndatasets, it is important that concept drift detection algorithms are adaptable\nto different inference scenarios. In this paper, we introduce an application of\nthe $\\chi^2$ Goodness of Fit Hypothesis Test as a drift detection\nmeta-algorithm applied to a multilayer perceptron, a convolutional neural\nnetwork, and a transformer trained for machine vision as they are exposed to\nsimulated drift during inference. To that end, we demonstrate how unexpected\ndrops in accuracy due to concept drift can be detected without directly\nexamining the inference outputs. Our approach enhances safety by ensuring\nmodels are continually evaluated for reliability across varying conditions.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "eess.IV"
    ],
    "primary_category": "cs.LG",
    "comment": "8 pages, 6 figures, 1 table",
    "pdf_url": "http://arxiv.org/pdf/2505.04318v1",
    "published_date": "2025-05-07 11:04:47 UTC",
    "updated_date": "2025-05-07 11:04:47 UTC"
  },
  {
    "arxiv_id": "2505.04317v1",
    "title": "Mastering Multi-Drone Volleyball through Hierarchical Co-Self-Play Reinforcement Learning",
    "authors": [
      "Ruize Zhang",
      "Sirui Xiang",
      "Zelai Xu",
      "Feng Gao",
      "Shilong Ji",
      "Wenhao Tang",
      "Wenbo Ding",
      "Chao Yu",
      "Yu Wang"
    ],
    "abstract": "In this paper, we tackle the problem of learning to play 3v3 multi-drone\nvolleyball, a new embodied competitive task that requires both high-level\nstrategic coordination and low-level agile control. The task is turn-based,\nmulti-agent, and physically grounded, posing significant challenges due to its\nlong-horizon dependencies, tight inter-agent coupling, and the underactuated\ndynamics of quadrotors. To address this, we propose Hierarchical Co-Self-Play\n(HCSP), a hierarchical reinforcement learning framework that separates\ncentralized high-level strategic decision-making from decentralized low-level\nmotion control. We design a three-stage population-based training pipeline to\nenable both strategy and skill to emerge from scratch without expert\ndemonstrations: (I) training diverse low-level skills, (II) learning high-level\nstrategy via self-play with fixed low-level controllers, and (III) joint\nfine-tuning through co-self-play. Experiments show that HCSP achieves superior\nperformance, outperforming non-hierarchical self-play and rule-based\nhierarchical baselines with an average 82.9\\% win rate and a 71.5\\% win rate\nagainst the two-stage variant. Moreover, co-self-play leads to emergent team\nbehaviors such as role switching and coordinated formations, demonstrating the\neffectiveness of our hierarchical design and training scheme.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.04317v1",
    "published_date": "2025-05-07 11:04:36 UTC",
    "updated_date": "2025-05-07 11:04:36 UTC"
  },
  {
    "arxiv_id": "2505.04313v1",
    "title": "KERAIA: An Adaptive and Explainable Framework for Dynamic Knowledge Representation and Reasoning",
    "authors": [
      "Stephen Richard Varey",
      "Alessandro Di Stefano",
      "The Anh Han"
    ],
    "abstract": "In this paper, we introduce KERAIA, a novel framework and software platform\nfor symbolic knowledge engineering designed to address the persistent\nchallenges of representing, reasoning with, and executing knowledge in dynamic,\ncomplex, and context-sensitive environments. The central research question that\nmotivates this work is: How can unstructured, often tacit, human expertise be\neffectively transformed into computationally tractable algorithms that AI\nsystems can efficiently utilise? KERAIA seeks to bridge this gap by building on\nfoundational concepts such as Minsky's frame-based reasoning and K-lines, while\nintroducing significant innovations. These include Clouds of Knowledge for\ndynamic aggregation, Dynamic Relations (DRels) for context-sensitive\ninheritance, explicit Lines of Thought (LoTs) for traceable reasoning, and\nCloud Elaboration for adaptive knowledge transformation. This approach moves\nbeyond the limitations of traditional, often static, knowledge representation\nparadigms. KERAIA is designed with Explainable AI (XAI) as a core principle,\nensuring transparency and interpretability, particularly through the use of\nLoTs. The paper details the framework's architecture, the KSYNTH representation\nlanguage, and the General Purpose Paradigm Builder (GPPB) to integrate diverse\ninference methods within a unified structure. We validate KERAIA's versatility,\nexpressiveness, and practical applicability through detailed analysis of\nmultiple case studies spanning naval warfare simulation, industrial diagnostics\nin water treatment plants, and strategic decision-making in the game of RISK.\nFurthermore, we provide a comparative analysis against established knowledge\nrepresentation paradigms (including ontologies, rule-based systems, and\nknowledge graphs) and discuss the implementation aspects and computational\nconsiderations of the KERAIA platform.",
    "categories": [
      "cs.AI",
      "cs.ET",
      "cs.SC"
    ],
    "primary_category": "cs.AI",
    "comment": "22 pages",
    "pdf_url": "http://arxiv.org/pdf/2505.04313v1",
    "published_date": "2025-05-07 10:56:05 UTC",
    "updated_date": "2025-05-07 10:56:05 UTC"
  },
  {
    "arxiv_id": "2505.04310v1",
    "title": "Flow Models for Unbounded and Geometry-Aware Distributional Reinforcement Learning",
    "authors": [
      "Simo Alami C.",
      "Rim Kaddah",
      "Jesse Read",
      "Marie-Paule Cani"
    ],
    "abstract": "We introduce a new architecture for Distributional Reinforcement Learning\n(DistRL) that models return distributions using normalizing flows. This\napproach enables flexible, unbounded support for return distributions, in\ncontrast to categorical approaches like C51 that rely on fixed or bounded\nrepresentations. It also offers richer modeling capacity to capture\nmulti-modality, skewness, and tail behavior than quantile based approaches. Our\nmethod is significantly more parameter-efficient than categorical approaches.\nStandard metrics used to train existing models like KL divergence or\nWasserstein distance either are scale insensitive or have biased sample\ngradients, especially when return supports do not overlap. To address this, we\npropose a novel surrogate for the Cram\\`er distance, that is geometry-aware and\ncomputable directly from the return distribution's PDF, avoiding the costly CDF\ncomputation. We test our model on the ATARI-5 sub-benchmark and show that our\napproach outperforms PDF based models while remaining competitive with quantile\nbased methods.",
    "categories": [
      "cs.AI",
      "math.OC"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.04310v1",
    "published_date": "2025-05-07 10:49:53 UTC",
    "updated_date": "2025-05-07 10:49:53 UTC"
  },
  {
    "arxiv_id": "2505.04308v1",
    "title": "Guardians of the Web: The Evolution and Future of Website Information Security",
    "authors": [
      "Md Saiful Islam",
      "Li Xiangdong"
    ],
    "abstract": "Website information security has become a critical concern in the digital\nage. This article explores the evolution of website information security,\nexamining its historical development, current practices, and future directions.\nThe early beginnings from the 1960s to the 1980s laid the groundwork for modern\ncybersecurity, with the development of ARPANET, TCP/IP, public-key\ncryptography, and the first antivirus programs. The 1990s marked a\ntransformative era, driven by the commercialization of the Internet and the\nemergence of web-based services. As the Internet grew, so did the range and\nsophistication of cyber threats, leading to advancements in security\ntechnologies such as the Secure Sockets Layer (SSL) protocol, password\nprotection, and firewalls. Current practices in website information security\ninvolve a multi-layered approach, including encryption, secure coding\npractices, regular security audits, and user education. The future of website\ninformation security is expected to be shaped by emerging technologies such as\nartificial intelligence, blockchain, and quantum computing, as well as the\nincreasing importance of international cooperation and standardization efforts.\nAs cyber threats continue to evolve, ongoing research and innovation in website\ninformation security will be essential to protect sensitive information and\nmaintain trust in the digital world.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "F.2.2, I.2.7"
    ],
    "primary_category": "cs.CR",
    "comment": "22 pages",
    "pdf_url": "http://arxiv.org/pdf/2505.04308v1",
    "published_date": "2025-05-07 10:46:33 UTC",
    "updated_date": "2025-05-07 10:46:33 UTC"
  },
  {
    "arxiv_id": "2505.04300v1",
    "title": "Sparsity is All You Need: Rethinking Biological Pathway-Informed Approaches in Deep Learning",
    "authors": [
      "Isabella Caranzano",
      "Corrado Pancotti",
      "Cesare Rollo",
      "Flavio Sartori",
      "Pietro Liò",
      "Piero Fariselli",
      "Tiziana Sanavia"
    ],
    "abstract": "Biologically-informed neural networks typically leverage pathway annotations\nto enhance performance in biomedical applications. We hypothesized that the\nbenefits of pathway integration does not arise from its biological relevance,\nbut rather from the sparsity it introduces. We conducted a comprehensive\nanalysis of all relevant pathway-based neural network models for predictive\ntasks, critically evaluating each study's contributions. From this review, we\ncurated a subset of methods for which the source code was publicly available.\nThe comparison of the biologically informed state-of-the-art deep learning\nmodels and their randomized counterparts showed that models based on randomized\ninformation performed equally well as biologically informed ones across\ndifferent metrics and datasets. Notably, in 3 out of the 15 analyzed models,\nthe randomized versions even outperformed their biologically informed\ncounterparts. Moreover, pathway-informed models did not show any clear\nadvantage in interpretability, as randomized models were still able to identify\nrelevant disease biomarkers despite lacking explicit pathway information. Our\nfindings suggest that pathway annotations may be too noisy or inadequately\nexplored by current methods. Therefore, we propose a methodology that can be\napplied to different domains and can serve as a robust benchmark for\nsystematically comparing novel pathway-informed models against their randomized\ncounterparts. This approach enables researchers to rigorously determine whether\nobserved performance improvements can be attributed to biological insights.",
    "categories": [
      "q-bio.QM",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "q-bio.QM",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.04300v1",
    "published_date": "2025-05-07 10:14:31 UTC",
    "updated_date": "2025-05-07 10:14:31 UTC"
  },
  {
    "arxiv_id": "2505.04284v1",
    "title": "GASCADE: Grouped Summarization of Adverse Drug Event for Enhanced Cancer Pharmacovigilance",
    "authors": [
      "Sofia Jamil",
      "Aryan Dabad",
      "Bollampalli Areen Reddy",
      "Sriparna Saha",
      "Rajiv Misra",
      "Adil A. Shakur"
    ],
    "abstract": "In the realm of cancer treatment, summarizing adverse drug events (ADEs)\nreported by patients using prescribed drugs is crucial for enhancing\npharmacovigilance practices and improving drug-related decision-making. While\nthe volume and complexity of pharmacovigilance data have increased, existing\nresearch in this field has predominantly focused on general diseases rather\nthan specifically addressing cancer. This work introduces the task of grouped\nsummarization of adverse drug events reported by multiple patients using the\nsame drug for cancer treatment. To address the challenge of limited resources\nin cancer pharmacovigilance, we present the MultiLabeled Cancer Adverse Drug\nReaction and Summarization (MCADRS) dataset. This dataset includes\npharmacovigilance posts detailing patient concerns regarding drug efficacy and\nadverse effects, along with extracted labels for drug names, adverse drug\nevents, severity, and adversity of reactions, as well as summaries of ADEs for\neach drug. Additionally, we propose the Grouping and Abstractive Summarization\nof Cancer Adverse Drug events (GASCADE) framework, a novel pipeline that\ncombines the information extraction capabilities of Large Language Models\n(LLMs) with the summarization power of the encoder-decoder T5 model. Our work\nis the first to apply alignment techniques, including advanced algorithms like\nDirect Preference Optimization, to encoder-decoder models using synthetic\ndatasets for summarization tasks. Through extensive experiments, we demonstrate\nthe superior performance of GASCADE across various metrics, validated through\nboth automated assessments and human evaluations. This multitasking approach\nenhances drug-related decision-making and fosters a deeper understanding of\npatient concerns, paving the way for advancements in personalized and\nresponsive cancer care. The code and dataset used in this work are publicly\navailable.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.04284v1",
    "published_date": "2025-05-07 09:40:18 UTC",
    "updated_date": "2025-05-07 09:40:18 UTC"
  },
  {
    "arxiv_id": "2505.04278v1",
    "title": "Non-stationary Diffusion For Probabilistic Time Series Forecasting",
    "authors": [
      "Weiwei Ye",
      "Zhuopeng Xu",
      "Ning Gui"
    ],
    "abstract": "Due to the dynamics of underlying physics and external influences, the\nuncertainty of time series often varies over time. However, existing Denoising\nDiffusion Probabilistic Models (DDPMs) often fail to capture this\nnon-stationary nature, constrained by their constant variance assumption from\nthe additive noise model (ANM). In this paper, we innovatively utilize the\nLocation-Scale Noise Model (LSNM) to relax the fixed uncertainty assumption of\nANM. A diffusion-based probabilistic forecasting framework, termed\nNon-stationary Diffusion (NsDiff), is designed based on LSNM that is capable of\nmodeling the changing pattern of uncertainty. Specifically, NsDiff combines a\ndenoising diffusion-based conditional generative model with a pre-trained\nconditional mean and variance estimator, enabling adaptive endpoint\ndistribution modeling. Furthermore, we propose an uncertainty-aware noise\nschedule, which dynamically adjusts the noise levels to accurately reflect the\ndata uncertainty at each step and integrates the time-varying variances into\nthe diffusion process. Extensive experiments conducted on nine real-world and\nsynthetic datasets demonstrate the superior performance of NsDiff compared to\nexisting approaches. Code is available at https://github.com/wwy155/NsDiff.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted as spotlight poster at ICML",
    "pdf_url": "http://arxiv.org/pdf/2505.04278v1",
    "published_date": "2025-05-07 09:29:39 UTC",
    "updated_date": "2025-05-07 09:29:39 UTC"
  },
  {
    "arxiv_id": "2505.04270v1",
    "title": "Object-Shot Enhanced Grounding Network for Egocentric Video",
    "authors": [
      "Yisen Feng",
      "Haoyu Zhang",
      "Meng Liu",
      "Weili Guan",
      "Liqiang Nie"
    ],
    "abstract": "Egocentric video grounding is a crucial task for embodied intelligence\napplications, distinct from exocentric video moment localization. Existing\nmethods primarily focus on the distributional differences between egocentric\nand exocentric videos but often neglect key characteristics of egocentric\nvideos and the fine-grained information emphasized by question-type queries. To\naddress these limitations, we propose OSGNet, an Object-Shot enhanced Grounding\nNetwork for egocentric video. Specifically, we extract object information from\nvideos to enrich video representation, particularly for objects highlighted in\nthe textual query but not directly captured in the video features.\nAdditionally, we analyze the frequent shot movements inherent to egocentric\nvideos, leveraging these features to extract the wearer's attention\ninformation, which enhances the model's ability to perform modality alignment.\nExperiments conducted on three datasets demonstrate that OSGNet achieves\nstate-of-the-art performance, validating the effectiveness of our approach. Our\ncode can be found at https://github.com/Yisen-Feng/OSGNet.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted by CVPR 2025",
    "pdf_url": "http://arxiv.org/pdf/2505.04270v1",
    "published_date": "2025-05-07 09:20:12 UTC",
    "updated_date": "2025-05-07 09:20:12 UTC"
  },
  {
    "arxiv_id": "2505.04265v1",
    "title": "Weaponizing Language Models for Cybersecurity Offensive Operations: Automating Vulnerability Assessment Report Validation; A Review Paper",
    "authors": [
      "Abdulrahman S Almuhaidib",
      "Azlan Mohd Zain",
      "Zalmiyah Zakaria",
      "Izyan Izzati Kamsani",
      "Abdulaziz S Almuhaidib"
    ],
    "abstract": "This, with the ever-increasing sophistication of cyberwar, calls for novel\nsolutions. In this regard, Large Language Models (LLMs) have emerged as a\nhighly promising tool for defensive and offensive cybersecurity-related\nstrategies. While existing literature has focused much on the defensive use of\nLLMs, when it comes to their offensive utilization, very little has been\nreported-namely, concerning Vulnerability Assessment (VA) report validation.\nConsequentially, this paper tries to fill that gap by investigating the\ncapabilities of LLMs in automating and improving the validation process of the\nreport of the VA. From the critical review of the related literature, this\npaper hereby proposes a new approach to using the LLMs in the automation of the\nanalysis and within the validation process of the report of the VA that could\npotentially reduce the number of false positives and generally enhance\nefficiency. These results are promising for LLM automatization for improving\nvalidation on reports coming from VA in order to improve accuracy while\nreducing human effort and security postures. The contribution of this paper\nprovides further evidence about the offensive and defensive LLM capabilities\nand therefor helps in devising more appropriate cybersecurity strategies and\ntools accordingly.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "Pre-print - Accepted for publication in the Proceedings of the\n  International Computer Sciences and Informatics Conference (ICSIC-2024),\n  published by AIP Publishing",
    "pdf_url": "http://arxiv.org/pdf/2505.04265v1",
    "published_date": "2025-05-07 09:14:55 UTC",
    "updated_date": "2025-05-07 09:14:55 UTC"
  },
  {
    "arxiv_id": "2505.04260v1",
    "title": "Steerable Chatbots: Personalizing LLMs with Preference-Based Activation Steering",
    "authors": [
      "Jessica Y. Bo",
      "Tianyu Xu",
      "Ishan Chatterjee",
      "Katrina Passarella-Ward",
      "Achin Kulshrestha",
      "D Shin"
    ],
    "abstract": "As large language models (LLMs) improve in their capacity to serve as\npersonal AI assistants, their ability to output uniquely tailored, personalized\nresponses that align with the soft preferences of their users is essential for\nenhancing user satisfaction and retention. However, untrained lay users have\npoor prompt specification abilities and often struggle with conveying their\nlatent preferences to AI assistants. To address this, we leverage activation\nsteering to guide LLMs to align with interpretable preference dimensions during\ninference. In contrast to memory-based personalization methods that require\nlonger user history, steering is extremely lightweight and can be easily\ncontrolled by the user via an linear strength factor. We embed steering into\nthree different interactive chatbot interfaces and conduct a within-subjects\nuser study (n=14) to investigate how end users prefer to personalize their\nconversations. The results demonstrate the effectiveness of preference-based\nsteering for aligning real-world conversations with hidden user preferences,\nand highlight further insights on how diverse values around control, usability,\nand transparency lead users to prefer different interfaces.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.04260v1",
    "published_date": "2025-05-07 09:10:51 UTC",
    "updated_date": "2025-05-07 09:10:51 UTC"
  },
  {
    "arxiv_id": "2505.04251v1",
    "title": "Facilitating Trustworthy Human-Agent Collaboration in LLM-based Multi-Agent System oriented Software Engineering",
    "authors": [
      "Krishna Ronanki"
    ],
    "abstract": "Multi-agent autonomous systems (MAS) are better at addressing challenges that\nspans across multiple domains than singular autonomous agents. This holds true\nwithin the field of software engineering (SE) as well. The state-of-the-art\nresearch on MAS within SE focuses on integrating LLMs at the core of autonomous\nagents to create LLM-based multi-agent autonomous (LMA) systems. However, the\nintroduction of LMA systems into SE brings a plethora of challenges. One of the\nmajor challenges is the strategic allocation of tasks between humans and the\nLMA system in a trustworthy manner. To address this challenge, a RACI-based\nframework is proposed in this work in progress article, along with\nimplementation guidelines and an example implementation of the framework. The\nproposed framework can facilitate efficient collaboration, ensure\naccountability, and mitigate potential risks associated with LLM-driven\nautomation while aligning with the Trustworthy AI guidelines. The future steps\nfor this work delineating the planned empirical validation method are also\npresented.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.MA"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.04251v1",
    "published_date": "2025-05-07 08:55:15 UTC",
    "updated_date": "2025-05-07 08:55:15 UTC"
  },
  {
    "arxiv_id": "2505.04223v1",
    "title": "FRAIN to Train: A Fast-and-Reliable Solution for Decentralized Federated Learning",
    "authors": [
      "Sanghyeon Park",
      "Soo-Mook Moon"
    ],
    "abstract": "Federated learning (FL) enables collaborative model training across\ndistributed clients while preserving data locality. Although FedAvg pioneered\nsynchronous rounds for global model averaging, slower devices can delay\ncollective progress. Asynchronous FL (e.g., FedAsync) addresses stragglers by\ncontinuously integrating client updates, yet naive implementations risk client\ndrift due to non-IID data and stale contributions. Some Blockchain-based FL\napproaches (e.g., BRAIN) employ robust weighting or scoring of updates to\nresist malicious or misaligned proposals. However, performance drops can still\npersist under severe data heterogeneity or high staleness, and synchronization\noverhead has emerged as a new concern due to its aggregator-free architectures.\n  We introduce Fast-and-Reliable AI Network, FRAIN, a new asynchronous FL\nmethod that mitigates these limitations by incorporating two key ideas. First,\nour FastSync strategy eliminates the need to replay past model versions,\nenabling newcomers and infrequent participants to efficiently approximate the\nglobal model. Second, we adopt spherical linear interpolation (SLERP) when\nmerging parameters, preserving models' directions and alleviating destructive\ninterference from divergent local training.\n  Experiments with a CNN image-classification model and a Transformer-based\nlanguage model demonstrate that FRAIN achieves more stable and robust\nconvergence than FedAvg, FedAsync, and BRAIN, especially under harsh\nenvironments: non-IID data distributions, networks that experience delays and\nrequire frequent re-synchronization, and the presence of malicious nodes.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.04223v1",
    "published_date": "2025-05-07 08:20:23 UTC",
    "updated_date": "2025-05-07 08:20:23 UTC"
  },
  {
    "arxiv_id": "2505.04209v1",
    "title": "To Judge or not to Judge: Using LLM Judgements for Advertiser Keyphrase Relevance at eBay",
    "authors": [
      "Soumik Dey",
      "Hansi Wu",
      "Binbin Li"
    ],
    "abstract": "E-commerce sellers are recommended keyphrases based on their inventory on\nwhich they advertise to increase buyer engagement (clicks/sales). The relevance\nof advertiser keyphrases plays an important role in preventing the inundation\nof search systems with numerous irrelevant items that compete for attention in\nauctions, in addition to maintaining a healthy seller perception. In this work,\nwe describe the shortcomings of training Advertiser keyphrase relevance filter\nmodels on click/sales/search relevance signals and the importance of aligning\nwith human judgment, as sellers have the power to adopt or reject said\nkeyphrase recommendations. In this study, we frame Advertiser keyphrase\nrelevance as a complex interaction between 3 dynamical systems -- seller\njudgment, which influences seller adoption of our product, Advertising, which\nprovides the keyphrases to bid on, and Search, who holds the auctions for the\nsame keyphrases. This study discusses the practicalities of using human\njudgment via a case study at eBay Advertising and demonstrate that using\nLLM-as-a-judge en-masse as a scalable proxy for seller judgment to train our\nrelevance models achieves a better harmony across the three systems -- provided\nthat they are bound by a meticulous evaluation framework grounded in business\nmetrics.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.04209v1",
    "published_date": "2025-05-07 08:03:25 UTC",
    "updated_date": "2025-05-07 08:03:25 UTC"
  },
  {
    "arxiv_id": "2505.04207v1",
    "title": "An Enhanced YOLOv8 Model for Real-Time and Accurate Pothole Detection and Measurement",
    "authors": [
      "Mustafa Yurdakul",
      "Şakir Tasdemir"
    ],
    "abstract": "Potholes cause vehicle damage and traffic accidents, creating serious safety\nand economic problems. Therefore, early and accurate detection of potholes is\ncrucial. Existing detection methods are usually only based on 2D RGB images and\ncannot accurately analyze the physical characteristics of potholes. In this\npaper, a publicly available dataset of RGB-D images (PothRGBD) is created and\nan improved YOLOv8-based model is proposed for both pothole detection and\npothole physical features analysis. The Intel RealSense D415 depth camera was\nused to collect RGB and depth data from the road surfaces, resulting in a\nPothRGBD dataset of 1000 images. The data was labeled in YOLO format suitable\nfor segmentation. A novel YOLO model is proposed based on the YOLOv8n-seg\narchitecture, which is structurally improved with Dynamic Snake Convolution\n(DSConv), Simple Attention Module (SimAM) and Gaussian Error Linear Unit\n(GELU). The proposed model segmented potholes with irregular edge structure\nmore accurately, and performed perimeter and depth measurements on depth maps\nwith high accuracy. The standard YOLOv8n-seg model achieved 91.9% precision,\n85.2% recall and 91.9% mAP@50. With the proposed model, the values increased to\n93.7%, 90.4% and 93.8% respectively. Thus, an improvement of 1.96% in\nprecision, 6.13% in recall and 2.07% in mAP was achieved. The proposed model\nperforms pothole detection as well as perimeter and depth measurement with high\naccuracy and is suitable for real-time applications due to its low model\ncomplexity. In this way, a lightweight and effective model that can be used in\ndeep learning-based intelligent transportation solutions has been acquired.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.04207v1",
    "published_date": "2025-05-07 07:58:57 UTC",
    "updated_date": "2025-05-07 07:58:57 UTC"
  },
  {
    "arxiv_id": "2505.04192v1",
    "title": "VideoPath-LLaVA: Pathology Diagnostic Reasoning Through Video Instruction Tuning",
    "authors": [
      "Trinh T. L. Vuong",
      "Jin Tae Kwak"
    ],
    "abstract": "We present VideoPath-LLaVA, the first large multimodal model (LMM) in\ncomputational pathology that integrates three distinct image scenarios, single\npatch images, automatically keyframe-extracted clips, and manually segmented\nvideo pathology images, to mimic the natural diagnostic process of\npathologists. By generating detailed histological descriptions and culminating\nin a definitive sign-out diagnosis, VideoPath-LLaVA bridges visual narratives\nwith diagnostic reasoning.\n  Central to our approach is the VideoPath-Instruct dataset, comprising 4278\nvideo and diagnosis-specific chain-of-thought instructional pairs sourced from\neducational histopathology videos on YouTube. Although high-quality data is\ncritical for enhancing diagnostic reasoning, its creation is time-intensive and\nlimited in volume. To overcome this challenge, we transfer knowledge from\nexisting single-image instruction datasets to train on weakly annotated,\nkeyframe-extracted clips, followed by fine-tuning on manually segmented videos.\nVideoPath-LLaVA establishes a new benchmark in pathology video analysis and\noffers a promising foundation for future AI systems that support clinical\ndecision-making through integrated visual and diagnostic reasoning. Our code,\ndata, and model are publicly available at\nhttps://github.com/trinhvg/VideoPath-LLaVA.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.04192v1",
    "published_date": "2025-05-07 07:41:19 UTC",
    "updated_date": "2025-05-07 07:41:19 UTC"
  },
  {
    "arxiv_id": "2505.04185v1",
    "title": "S3D: Sketch-Driven 3D Model Generation",
    "authors": [
      "Hail Song",
      "Wonsik Shin",
      "Naeun Lee",
      "Soomin Chung",
      "Nojun Kwak",
      "Woontack Woo"
    ],
    "abstract": "Generating high-quality 3D models from 2D sketches is a challenging task due\nto the inherent ambiguity and sparsity of sketch data. In this paper, we\npresent S3D, a novel framework that converts simple hand-drawn sketches into\ndetailed 3D models. Our method utilizes a U-Net-based encoder-decoder\narchitecture to convert sketches into face segmentation masks, which are then\nused to generate a 3D representation that can be rendered from novel views. To\nensure robust consistency between the sketch domain and the 3D output, we\nintroduce a novel style-alignment loss that aligns the U-Net bottleneck\nfeatures with the initial encoder outputs of the 3D generation module,\nsignificantly enhancing reconstruction fidelity. To further enhance the\nnetwork's robustness, we apply augmentation techniques to the sketch dataset.\nThis streamlined framework demonstrates the effectiveness of S3D in generating\nhigh-quality 3D models from sketch inputs. The source code for this project is\npublicly available at https://github.com/hailsong/S3D.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted as a short paper to the GMCV Workshop at CVPR'25",
    "pdf_url": "http://arxiv.org/pdf/2505.04185v1",
    "published_date": "2025-05-07 07:34:37 UTC",
    "updated_date": "2025-05-07 07:34:37 UTC"
  },
  {
    "arxiv_id": "2505.04175v1",
    "title": "DOTA: Deformable Optimized Transformer Architecture for End-to-End Text Recognition with Retrieval-Augmented Generation",
    "authors": [
      "Naphat Nithisopa",
      "Teerapong Panboonyuen"
    ],
    "abstract": "Text recognition in natural images remains a challenging yet essential task,\nwith broad applications spanning computer vision and natural language\nprocessing. This paper introduces a novel end-to-end framework that combines\nResNet and Vision Transformer backbones with advanced methodologies, including\nDeformable Convolutions, Retrieval-Augmented Generation, and Conditional Random\nFields (CRF). These innovations collectively enhance feature representation and\nimprove Optical Character Recognition (OCR) performance. Specifically, the\nframework substitutes standard convolution layers in the third and fourth\nblocks with Deformable Convolutions, leverages adaptive dropout for\nregularization, and incorporates CRF for more refined sequence modeling.\nExtensive experiments conducted on six benchmark datasets IC13, IC15, SVT,\nIIIT5K, SVTP, and CUTE80 validate the proposed method's efficacy, achieving\nnotable accuracies: 97.32% on IC13, 58.26% on IC15, 88.10% on SVT, 74.13% on\nIIIT5K, 82.17% on SVTP, and 66.67% on CUTE80, resulting in an average accuracy\nof 77.77%. These results establish a new state-of-the-art for text recognition,\ndemonstrating the robustness of the approach across diverse and challenging\ndatasets.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.04175v1",
    "published_date": "2025-05-07 07:06:04 UTC",
    "updated_date": "2025-05-07 07:06:04 UTC"
  },
  {
    "arxiv_id": "2505.04174v1",
    "title": "On-Device LLM for Context-Aware Wi-Fi Roaming",
    "authors": [
      "Ju-Hyung Lee",
      "Yanqing Lu"
    ],
    "abstract": "Wireless roaming is a critical yet challenging task for maintaining seamless\nconnectivity in dynamic mobile environments. Conventional threshold-based or\nheuristic schemes often fail, leading to either sticky or excessive handovers.\nWe introduce the first cross-layer use of an on-device large language model\n(LLM): high-level reasoning in the application layer that issues real-time\nactions executed in the PHY/MAC stack. The LLM addresses two tasks: (i)\ncontext-aware AP selection, where structured prompts fuse environmental cues\n(e.g., location, time) to choose the best BSSID; and (ii) dynamic threshold\nadjustment, where the model adaptively decides when to roam. To satisfy the\ntight latency and resource budgets of edge hardware, we apply a suite of\noptimizations-chain-of-thought prompting, parameter-efficient fine-tuning, and\nquantization. Experiments on indoor and outdoor datasets show that our approach\nsurpasses legacy heuristics and DRL baselines, achieving a strong balance\nbetween roaming stability and signal quality. These findings underscore the\npromise of application-layer LLM reasoning for lower-layer wireless control in\nfuture edge systems.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.NI",
      "eess.SP"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.04174v1",
    "published_date": "2025-05-07 07:04:49 UTC",
    "updated_date": "2025-05-07 07:04:49 UTC"
  },
  {
    "arxiv_id": "2505.04165v2",
    "title": "TS-SNN: Temporal Shift Module for Spiking Neural Networks",
    "authors": [
      "Kairong Yu",
      "Tianqing Zhang",
      "Qi Xu",
      "Gang Pan",
      "Hongwei Wang"
    ],
    "abstract": "Spiking Neural Networks (SNNs) are increasingly recognized for their\nbiological plausibility and energy efficiency, positioning them as strong\nalternatives to Artificial Neural Networks (ANNs) in neuromorphic computing\napplications. SNNs inherently process temporal information by leveraging the\nprecise timing of spikes, but balancing temporal feature utilization with low\nenergy consumption remains a challenge. In this work, we introduce Temporal\nShift module for Spiking Neural Networks (TS-SNN), which incorporates a novel\nTemporal Shift (TS) module to integrate past, present, and future spike\nfeatures within a single timestep via a simple yet effective shift operation. A\nresidual combination method prevents information loss by integrating shifted\nand original features. The TS module is lightweight, requiring only one\nadditional learnable parameter, and can be seamlessly integrated into existing\narchitectures with minimal additional computational cost. TS-SNN achieves\nstate-of-the-art performance on benchmarks like CIFAR-10 (96.72\\%), CIFAR-100\n(80.28\\%), and ImageNet (70.61\\%) with fewer timesteps, while maintaining low\nenergy consumption. This work marks a significant step forward in developing\nefficient and accurate SNN architectures.",
    "categories": [
      "cs.NE",
      "cs.AI"
    ],
    "primary_category": "cs.NE",
    "comment": "Accepted by ICML2025",
    "pdf_url": "http://arxiv.org/pdf/2505.04165v2",
    "published_date": "2025-05-07 06:34:34 UTC",
    "updated_date": "2025-05-08 08:17:59 UTC"
  },
  {
    "arxiv_id": "2505.04147v1",
    "title": "R^3-VQA: \"Read the Room\" by Video Social Reasoning",
    "authors": [
      "Lixing Niu",
      "Jiapeng Li",
      "Xingping Yu",
      "Shu Wang",
      "Ruining Feng",
      "Bo Wu",
      "Ping Wei",
      "Yisen Wang",
      "Lifeng Fan"
    ],
    "abstract": "\"Read the room\" is a significant social reasoning capability in human daily\nlife. Humans can infer others' mental states from subtle social cues. Previous\nsocial reasoning tasks and datasets lack complexity (e.g., simple scenes, basic\ninteractions, incomplete mental state variables, single-step reasoning, etc.)\nand fall far short of the challenges present in real-life social interactions.\nIn this paper, we contribute a valuable, high-quality, and comprehensive video\ndataset named R^3-VQA with precise and fine-grained annotations of social\nevents and mental states (i.e., belief, intent, desire, and emotion) as well as\ncorresponding social causal chains in complex social scenarios. Moreover, we\ninclude human-annotated and model-generated QAs. Our task R^3-VQA includes\nthree aspects: Social Event Understanding, Mental State Estimation, and Social\nCausal Reasoning. As a benchmark, we comprehensively evaluate the social\nreasoning capabilities and consistencies of current state-of-the-art large\nvision-language models (LVLMs). Comprehensive experiments show that (i) LVLMs\nare still far from human-level consistent social reasoning in complex social\nscenarios; (ii) Theory of Mind (ToM) prompting can help LVLMs perform better on\nsocial reasoning tasks. We provide some of our dataset and codes in\nsupplementary material and will release our full dataset and codes upon\nacceptance.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.04147v1",
    "published_date": "2025-05-07 05:55:45 UTC",
    "updated_date": "2025-05-07 05:55:45 UTC"
  },
  {
    "arxiv_id": "2505.04146v1",
    "title": "Unmasking the Canvas: A Dynamic Benchmark for Image Generation Jailbreaking and LLM Content Safety",
    "authors": [
      "Variath Madhupal Gautham Nair",
      "Vishal Varma Dantuluri"
    ],
    "abstract": "Existing large language models (LLMs) are advancing rapidly and produce\noutstanding results in image generation tasks, yet their content safety checks\nremain vulnerable to prompt-based jailbreaks. Through preliminary testing on\nplatforms such as ChatGPT, MetaAI, and Grok, we observed that even short,\nnatural prompts could lead to the generation of compromising images ranging\nfrom realistic depictions of forged documents to manipulated images of public\nfigures.\n  We introduce Unmasking the Canvas (UTC Benchmark; UTCB), a dynamic and\nscalable benchmark dataset to evaluate LLM vulnerability in image generation.\nOur methodology combines structured prompt engineering, multilingual\nobfuscation (e.g., Zulu, Gaelic, Base64), and evaluation using Groq-hosted\nLLaMA-3. The pipeline supports both zero-shot and fallback prompting\nstrategies, risk scoring, and automated tagging. All generations are stored\nwith rich metadata and curated into Bronze (non-verified), Silver (LLM-aided\nverification), and Gold (manually verified) tiers. UTCB is designed to evolve\nover time with new data sources, prompt templates, and model behaviors.\n  Warning: This paper includes visual examples of adversarial inputs designed\nto test model safety. All outputs have been redacted to ensure responsible\ndisclosure.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.04146v1",
    "published_date": "2025-05-07 05:54:04 UTC",
    "updated_date": "2025-05-07 05:54:04 UTC"
  },
  {
    "arxiv_id": "2505.04132v1",
    "title": "Bringing legal knowledge to the public by constructing a legal question bank using large-scale pre-trained language model",
    "authors": [
      "Mingruo Yuan",
      "Ben Kao",
      "Tien-Hsuan Wu",
      "Michael M. K. Cheung",
      "Henry W. H. Chan",
      "Anne S. Y. Cheung",
      "Felix W. H. Chan",
      "Yongxi Chen"
    ],
    "abstract": "Access to legal information is fundamental to access to justice. Yet\naccessibility refers not only to making legal documents available to the\npublic, but also rendering legal information comprehensible to them. A vexing\nproblem in bringing legal information to the public is how to turn formal legal\ndocuments such as legislation and judgments, which are often highly technical,\nto easily navigable and comprehensible knowledge to those without legal\neducation. In this study, we formulate a three-step approach for bringing legal\nknowledge to laypersons, tackling the issues of navigability and\ncomprehensibility. First, we translate selected sections of the law into\nsnippets (called CLIC-pages), each being a small piece of article that focuses\non explaining certain technical legal concept in layperson's terms. Second, we\nconstruct a Legal Question Bank (LQB), which is a collection of legal questions\nwhose answers can be found in the CLIC-pages. Third, we design an interactive\nCLIC Recommender (CRec). Given a user's verbal description of a legal situation\nthat requires a legal solution, CRec interprets the user's input and shortlists\nquestions from the question bank that are most likely relevant to the given\nlegal situation and recommends their corresponding CLIC pages where relevant\nlegal knowledge can be found. In this paper we focus on the technical aspects\nof creating an LQB. We show how large-scale pre-trained language models, such\nas GPT-3, can be used to generate legal questions. We compare machine-generated\nquestions (MGQs) against human-composed questions (HCQs) and find that MGQs are\nmore scalable, cost-effective, and more diversified, while HCQs are more\nprecise. We also show a prototype of CRec and illustrate through an example how\nour 3-step approach effectively brings relevant legal knowledge to the public.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.04132v1",
    "published_date": "2025-05-07 05:07:38 UTC",
    "updated_date": "2025-05-07 05:07:38 UTC"
  },
  {
    "arxiv_id": "2505.04115v1",
    "title": "Polynomial-Time Relational Probabilistic Inference in Open Universes",
    "authors": [
      "Luise Ge",
      "Brendan Juba",
      "Kris Nilsson"
    ],
    "abstract": "Reasoning under uncertainty is a fundamental challenge in Artificial\nIntelligence. As with most of these challenges, there is a harsh dilemma\nbetween the expressive power of the language used, and the tractability of the\ncomputational problem posed by reasoning. Inspired by human reasoning, we\nintroduce a method of first-order relational probabilistic inference that\nsatisfies both criteria, and can handle hybrid (discrete and continuous)\nvariables. Specifically, we extend sum-of-squares logic of expectation to\nrelational settings, demonstrating that lifted reasoning in the bounded-degree\nfragment for knowledge bases of bounded quantifier rank can be performed in\npolynomial time, even with an a priori unknown and/or countably infinite set of\nobjects. Crucially, our notion of tractability is framed in proof-theoretic\nterms, which extends beyond the syntactic properties of the language or\nqueries. We are able to derive the tightest bounds provable by proofs of a\ngiven degree and size and establish completeness in our sum-of-squares\nrefutations for fixed degrees.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.04115v1",
    "published_date": "2025-05-07 04:14:03 UTC",
    "updated_date": "2025-05-07 04:14:03 UTC"
  },
  {
    "arxiv_id": "2505.04101v1",
    "title": "LLMs' Suitability for Network Security: A Case Study of STRIDE Threat Modeling",
    "authors": [
      "AbdulAziz AbdulGhaffar",
      "Ashraf Matrawy"
    ],
    "abstract": "Artificial Intelligence (AI) is expected to be an integral part of\nnext-generation AI-native 6G networks. With the prevalence of AI, researchers\nhave identified numerous use cases of AI in network security. However, there\nare almost nonexistent studies that analyze the suitability of Large Language\nModels (LLMs) in network security. To fill this gap, we examine the suitability\nof LLMs in network security, particularly with the case study of STRIDE threat\nmodeling. We utilize four prompting techniques with five LLMs to perform STRIDE\nclassification of 5G threats. From our evaluation results, we point out key\nfindings and detailed insights along with the explanation of the possible\nunderlying factors influencing the behavior of LLMs in the modeling of certain\nthreats. The numerical results and the insights support the necessity for\nadjusting and fine-tuning LLMs for network security use cases.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.NI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.04101v1",
    "published_date": "2025-05-07 03:37:49 UTC",
    "updated_date": "2025-05-07 03:37:49 UTC"
  },
  {
    "arxiv_id": "2505.04084v1",
    "title": "An Empirical Study of OpenAI API Discussions on Stack Overflow",
    "authors": [
      "Xiang Chen",
      "Jibin Wang",
      "Chaoyang Gao",
      "Xiaolin Ju",
      "Zhanqi Cui"
    ],
    "abstract": "The rapid advancement of large language models (LLMs), represented by\nOpenAI's GPT series, has significantly impacted various domains such as natural\nlanguage processing, software development, education, healthcare, finance, and\nscientific research. However, OpenAI APIs introduce unique challenges that\ndiffer from traditional APIs, such as the complexities of prompt engineering,\ntoken-based cost management, non-deterministic outputs, and operation as black\nboxes. To the best of our knowledge, the challenges developers encounter when\nusing OpenAI APIs have not been explored in previous empirical studies. To fill\nthis gap, we conduct the first comprehensive empirical study by analyzing 2,874\nOpenAI API-related discussions from the popular Q&A forum Stack Overflow. We\nfirst examine the popularity and difficulty of these posts. After manually\ncategorizing them into nine OpenAI API-related categories, we identify specific\nchallenges associated with each category through topic modeling analysis. Based\non our empirical findings, we finally propose actionable implications for\ndevelopers, LLM vendors, and researchers.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.04084v1",
    "published_date": "2025-05-07 02:51:32 UTC",
    "updated_date": "2025-05-07 02:51:32 UTC"
  },
  {
    "arxiv_id": "2505.04083v1",
    "title": "Plexus: Taming Billion-edge Graphs with 3D Parallel GNN Training",
    "authors": [
      "Aditya K. Ranjan",
      "Siddharth Singh",
      "Cunyang Wei",
      "Abhinav Bhatele"
    ],
    "abstract": "Graph neural networks have emerged as a potent class of neural networks\ncapable of leveraging the connectivity and structure of real-world graphs to\nlearn intricate properties and relationships between nodes. Many real-world\ngraphs exceed the memory capacity of a GPU due to their sheer size, and using\nGNNs on them requires techniques such as mini-batch sampling to scale. However,\nthis can lead to reduced accuracy in some cases, and sampling and data transfer\nfrom the CPU to the GPU can also slow down training. On the other hand,\ndistributed full-graph training suffers from high communication overhead and\nload imbalance due to the irregular structure of graphs. We propose Plexus, a\nthree-dimensional (3D) parallel approach for full-graph training that tackles\nthese issues and scales to billion-edge graphs. Additionally, we introduce\noptimizations such as a permutation scheme for load balancing, and a\nperformance model to predict the optimal 3D configuration. We evaluate Plexus\non several graph datasets and show scaling results for up to 2048 GPUs on\nPerlmutter, which is 33% of the machine, and 2048 GCDs on Frontier. Plexus\nachieves unprecedented speedups of 2.3x-12.5x over existing methods and a\nreduction in the time to solution by 5.2-8.7x on Perlmutter and 7-54.2x on\nFrontier.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.DC"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.04083v1",
    "published_date": "2025-05-07 02:49:52 UTC",
    "updated_date": "2025-05-07 02:49:52 UTC"
  },
  {
    "arxiv_id": "2505.04075v1",
    "title": "LLM-e Guess: Can LLMs Capabilities Advance Without Hardware Progress?",
    "authors": [
      "Teddy Foley",
      "Spencer Guo",
      "Henry Josephson",
      "Anqi Qu",
      "Jack Sanderson"
    ],
    "abstract": "This paper examines whether large language model (LLM) capabilities can\ncontinue to advance without additional compute by analyzing the development and\nrole of algorithms used in state-of-the-art LLMs. Motivated by regulatory\nefforts that have largely focused on restricting access to high-performance\nhardware, we ask: Can LLMs progress in a compute-constrained environment, and\nhow do algorithmic innovations perform under such conditions?\n  To address these questions, we introduce a novel classification framework\nthat distinguishes between compute-dependent innovations -- which yield\ndisproportionate benefits at high compute levels (e.g., the Transformer\narchitecture and mixture-of-experts models) and compute-independent\ninnovations, which improve efficiency across all compute scales (e.g., rotary\npositional encoding, FlashAttention, or layer normalization). We quantify these\ncontributions using a metric called compute-equivalent gain (CEG), which\nestimates the additional compute that would be required to achieve similar\nimprovements without these algorithmic advancements.\n  To validate this framework, we conduct small-scale training experiments with\na scaled-down GPT-2 model. Our results confirm that compute-independent\nadvancements yield meaningful performance gains even in resource-constrained\nsettings, with a CEG of up to $3.5\\times$ over a baseline model. By contrast,\ncompute-dependent advancements provided little benefit or even degraded\nperformance at the small scale, reinforcing the importance of compute\navailability for certain algorithmic gains.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "I.2"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.04075v1",
    "published_date": "2025-05-07 02:26:17 UTC",
    "updated_date": "2025-05-07 02:26:17 UTC"
  },
  {
    "arxiv_id": "2505.04072v1",
    "title": "Advancing and Benchmarking Personalized Tool Invocation for LLMs",
    "authors": [
      "Xu Huang",
      "Yuefeng Huang",
      "Weiwen Liu",
      "Xingshan Zeng",
      "Yasheng Wang",
      "Ruiming Tang",
      "Hong Xie",
      "Defu Lian"
    ],
    "abstract": "Tool invocation is a crucial mechanism for extending the capabilities of\nLarge Language Models (LLMs) and has recently garnered significant attention.\nIt enables LLMs to solve complex problems through tool calls while accessing\nup-to-date world knowledge. However, existing work primarily focuses on the\nfundamental ability of LLMs to invoke tools for problem-solving, without\nconsidering personalized constraints in tool invocation. In this work, we\nintroduce the concept of Personalized Tool Invocation and define two key tasks:\nTool Preference and Profile-dependent Query. Tool Preference addresses user\npreferences when selecting among functionally similar tools, while\nProfile-dependent Query considers cases where a user query lacks certain tool\nparameters, requiring the model to infer them from the user profile. To tackle\nthese challenges, we propose PTool, a data synthesis framework designed for\npersonalized tool invocation. Additionally, we construct \\textbf{PTBench}, the\nfirst benchmark for evaluating personalized tool invocation. We then fine-tune\nvarious open-source models, demonstrating the effectiveness of our framework\nand providing valuable insights. Our benchmark is public at\nhttps://github.com/hyfshadow/PTBench.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "14 pages, 7 figures, 5 tables",
    "pdf_url": "http://arxiv.org/pdf/2505.04072v1",
    "published_date": "2025-05-07 02:25:20 UTC",
    "updated_date": "2025-05-07 02:25:20 UTC"
  },
  {
    "arxiv_id": "2505.04034v1",
    "title": "Izhikevich-Inspired Temporal Dynamics for Enhancing Privacy, Efficiency, and Transferability in Spiking Neural Networks",
    "authors": [
      "Ayana Moshruba",
      "Hamed Poursiami",
      "Maryam Parsa"
    ],
    "abstract": "Biological neurons exhibit diverse temporal spike patterns, which are\nbelieved to support efficient, robust, and adaptive neural information\nprocessing. While models such as Izhikevich can replicate a wide range of these\nfiring dynamics, their complexity poses challenges for directly integrating\nthem into scalable spiking neural networks (SNN) training pipelines. In this\nwork, we propose two probabilistically driven, input-level temporal spike\ntransformations: Poisson-Burst and Delayed-Burst that introduce biologically\ninspired temporal variability directly into standard Leaky Integrate-and-Fire\n(LIF) neurons. This enables scalable training and systematic evaluation of how\nspike timing dynamics affect privacy, generalization, and learning performance.\nPoisson-Burst modulates burst occurrence based on input intensity, while\nDelayed-Burst encodes input strength through burst onset timing. Through\nextensive experiments across multiple benchmarks, we demonstrate that\nPoisson-Burst maintains competitive accuracy and lower resource overhead while\nexhibiting enhanced privacy robustness against membership inference attacks,\nwhereas Delayed-Burst provides stronger privacy protection at a modest accuracy\ntrade-off. These findings highlight the potential of biologically grounded\ntemporal spike dynamics in improving the privacy, generalization and biological\nplausibility of neuromorphic learning systems.",
    "categories": [
      "cs.NE",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.NE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.04034v1",
    "published_date": "2025-05-07 00:27:00 UTC",
    "updated_date": "2025-05-07 00:27:00 UTC"
  }
]