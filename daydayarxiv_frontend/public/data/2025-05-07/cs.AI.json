{
  "date": "2025-05-07",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2025-05-07 的 arXiv 中文 TLDR 快报！今天 arXiv 的论文主要聚焦于 AI 创新，尤其是大型语言模型（LLM）的安全性和应用扩展、强化学习与量子计算的结合，以及图神经网络和医疗 AI 的进展，其中 Benchmarking LLM Faithfulness 和 Large Language Models are Autonomous Cyber Defenders 等文章因其 LLM 幻觉评估和网络安全应用而令人印象深刻，同时 ORBIT-2 在气候建模中的高分辨率 AI 方法也值得关注。\n\n### 重点论文讨论\n我们挑选了今天论文中的亮点，按照主题分组，先聊重要、创新性强的文章（如 LLM 安全、量子增强和医疗应用），快速掠过其他较常规的。\n\n#### AI 和 LLM 安全与应用\n- **Benchmarking LLM Faithfulness in RAG with Evolving Leaderboards**（《使用演化排行榜评估 RAG 中 LLM 的忠实性》）：这篇论文提出 FaithJudge，一种基于 LLM 的评估方法，用于检测 RAG 中的幻觉问题，通过 few-shot 人类标注指导，显著提升了 LLM 在总结任务中的准确性，潜在影响包括更可靠的 AI 应用。\n- **Large Language Models are Autonomous Cyber Defenders**（《大型语言模型作为自主网络防御者》）：作者包括知名学者 Alvaro A. Cardenas，该研究探索 LLM 在多代理网络防御环境中的性能，引入新通信协议，展示了 LLM 在对抗性场景中的优势和局限，为 AI 安全提供新方向。\n- **A Proposal for Evaluating the Operational Risk for ChatBots based on Large Language Models**（《基于大型语言模型评估聊天机器人操作风险的提案》）：论文提出一种多维风险评估框架，使用 LLM 测试聊天机器人漏洞，如错误行为和攻击风险，提升了 AI 系统的安全性和可靠性。\n- **\"I Can See Forever!\": Evaluating Real-time VideoLLMs for Assisting Individuals with Visual Impairments**（《“我能看得很远！”：评估实时 VideoLLMs 辅助视力障碍者的性能》）：快速讨论：该工作构建数据集评估 VideoLLMs 在辅助视障者的任务中表现，突出了模型在动态环境中的风险检测能力。\n- **VideoPath-LLaVA: Pathology Diagnostic Reasoning Through Video Instruction Tuning**（《VideoPath-LLaVA：通过视频指令微调进行病理诊断推理》）：该论文开发了首个整合多种图像场景的 LMM，用于病理诊断，显著提高了视频分析的准确性。\n\n#### 强化学习和优化\n- **ARDNS-FN-Quantum: A Quantum-Enhanced Reinforcement Learning Framework**（《ARDNS-FN-Quantum：量子增强的强化学习框架》）：这篇创新性强的工作整合量子电路和认知灵感策略，显著提升了强化学习在动态环境中的探索效率和成功率（如在网格世界中达到 99.5% 的成功率），为机器人和决策系统提供新工具。\n- **Is there Value in Reinforcement Learning?**（《强化学习是否有价值？》）：作者 Yonatan Loewenstein 讨论强化学习中价值函数的角色，质疑传统假设，提出更细致的算法视角，强调在非标准环境下的建模重要性。\n- **Risk-sensitive Reinforcement Learning Based on Convex Scoring Functions**（《基于凸评分函数的风险敏感强化学习》）：论文引入凸函数优化强化学习，处理不确定性，提供高效算法，支持金融等应用领域。\n\n#### 图神经网络和计算机视觉\n- **Piecewise Constant Spectral Graph Neural Network**（《分段常数谱图神经网络》）：该研究提出 PieCoN 框架，通过分段谱过滤器提升 GNN 在异质图上的性能，尤其在异质数据集上表现出色。\n- **ORBIT-2: Scaling Exascale Vision Foundation Models for Weather and Climate Downscaling**（《ORBIT-2：扩展万亿级视觉基础模型用于天气和气候下采样》）：作者团队包括知名机构如 Oak Ridge National Laboratory，这篇论文创新性地使用 Reslim 和 TILES 算法，实现高分辨率气候模拟，R^2 分数高达 0.99。\n- **S3D: Sketch-Driven 3D Model Generation**（《S3D：草图驱动的 3D 模型生成》）：快速掠过：该工作使用 U-Net 架构从草图生成 3D 模型，引入风格对齐损失提升重建保真度。\n\n#### 医疗和科学应用\n- **Pose Estimation for Intra-cardiac Echocardiography Catheter via AI-Based Anatomical Understanding**（《基于 AI 解剖理解的 intracardiac 超声导管位姿估计》）：论文利用 Vision Transformer 模型从超声图像估计导管位姿，平均误差低至 9.48 mm，提升了心脏干预手术效率。\n- **The Geometry of Meaning: Perfect Spacetime Representations of Hierarchical Structures**（《意义的几何：层次结构的完美时空表示》）：该研究提供算法将层次结构嵌入 Minkowski 时空，完美再现 WordNet 数据集的因果结构，揭示概念的几何本质。\n\n其他论文，如音频处理、数据增强或常规优化方法（如 FedBWO、TS-SNN），虽有贡献但相对常规，我们仅快速提及：它们主要优化特定领域效率（如 FedBWO 在联邦学习中的通信减少），但未带来突破性创新，故不详细展开。\n\n总之，今天的 arXiv 强调 AI 的实用性和安全性，LLM 在网络防御和医疗中的应用尤为突出，期待这些进展推动更可靠的 AI 系统。明天见！",
  "papers": [
    {
      "arxiv_id": "2505.06300v1",
      "title": "ARDNS-FN-Quantum: A Quantum-Enhanced Reinforcement Learning Framework with Cognitive-Inspired Adaptive Exploration for Dynamic Environments",
      "title_zh": "ARDNS-FN-Quantum：一个量子增强的强化学习框架，带有受认知启发的自适应探索，用于动态环境",
      "authors": [
        "Umberto Gonçalves de Sousa"
      ],
      "abstract": "Reinforcement learning (RL) has transformed sequential decision making, yet\ntraditional algorithms like Deep Q-Networks (DQNs) and Proximal Policy\nOptimization (PPO) often struggle with efficient exploration, stability, and\nadaptability in dynamic environments. This study presents ARDNS-FN-Quantum\n(Adaptive Reward-Driven Neural Simulator with Quantum enhancement), a novel\nframework that integrates a 2-qubit quantum circuit for action selection, a\ndual-memory system inspired by human cognition, and adaptive exploration\nstrategies modulated by reward variance and curiosity. Evaluated in a 10X10\ngrid-world over 20,000 episodes, ARDNS-FN-Quantum achieves a 99.5% success rate\n(versus 81.3% for DQN and 97.0% for PPO), a mean reward of 9.0528 across all\nepisodes (versus 1.2941 for DQN and 7.6196 for PPO), and an average of 46.7\nsteps to goal (versus 135.9 for DQN and 62.5 for PPO). In the last 100\nepisodes, it records a mean reward of 9.1652 (versus 7.0916 for DQN and 9.0310\nfor PPO) and 37.2 steps to goal (versus 52.7 for DQN and 53.4 for PPO).\nGraphical analyses, including learning curves, steps-to-goal trends, reward\nvariance, and reward distributions, demonstrate ARDNS-FN-Quantum's superior\nstability (reward variance 5.424 across all episodes versus 252.262 for DQN and\n76.583 for PPO) and efficiency. By bridging quantum computing, cognitive\nscience, and RL, ARDNS-FN-Quantum offers a scalable, human-like approach to\nadaptive learning in uncertain environments, with potential applications in\nrobotics, autonomous systems, and decision-making under uncertainty.",
      "tldr_zh": "这篇论文提出了 ARDNS-FN-Quantum 框架，一种量子增强的 Reinforcement Learning 方法，结合 2-qubit quantum circuit 用于行动选择、受人类认知启发的双记忆系统，以及基于奖励方差和好奇心的自适应探索策略，以解决传统算法如 DQN 和 PPO 在动态环境中的探索效率和稳定性问题。实验在 10x10 grid-world 中进行 20,000 episodes，结果显示该框架的成功率达到 99.5%、平均奖励为 9.0528，且平均步数到目标仅为 46.7，均优于 DQN 和 PPO 的表现。总体而言，ARDNS-FN-Quantum 通过融合量子计算和认知科学，提供了一种可扩展的适应性学习方法，适用于机器人、自主系统和不确定决策场景。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "19 pages, 7 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.06300v1",
      "published_date": "2025-05-07 23:48:41 UTC",
      "updated_date": "2025-05-07 23:48:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:26:48.655304"
    },
    {
      "arxiv_id": "2505.04852v2",
      "title": "PR2: Peephole Raw Pointer Rewriting with LLMs for Translating C to Safer Rust",
      "title_zh": "翻译失败",
      "authors": [
        "Yifei Gao",
        "Chengpeng Wang",
        "Pengxiang Huang",
        "Xuwei Liu",
        "Mingwei Zheng",
        "Xiangyu Zhang"
      ],
      "abstract": "There has been a growing interest in translating C code to Rust due to Rust's\nrobust memory and thread safety guarantees. Tools such as C2RUST enable\nsyntax-guided transpilation from C to semantically equivalent Rust code.\nHowever, the resulting Rust programs often rely heavily on unsafe\nconstructs--particularly raw pointers--which undermines Rust's safety\nguarantees. This paper aims to improve the memory safety of Rust programs\ngenerated by C2RUST by eliminating raw pointers. Specifically, we propose a\npeephole raw pointer rewriting technique that lifts raw pointers in individual\nfunctions to appropriate Rust data structures. Technically, PR2 employs\ndecision-tree-based prompting to guide the pointer lifting process.\nAdditionally, it leverages code change analysis to guide the repair of errors\nintroduced during rewriting, effectively addressing errors encountered during\ncompilation and test case execution. We implement PR2 as a prototype and\nevaluate it using gpt-4o-mini on 28 real-world C projects. The results show\nthat PR2 successfully eliminates 13.22% of local raw pointers across these\nprojects, significantly enhancing the safety of the translated Rust code. On\naverage, PR2 completes the transformation of a project in 5.44 hours, at an\naverage cost of $1.46.",
      "tldr_zh": "该论文提出 PR2 方法，使用 LLMs 进行 Peephole Raw Pointer Rewriting，以将 C 代码翻译成更安全的 Rust 代码，旨在消除 C2Rust 生成的 Rust 程序中依赖的 raw pointers，从而提升内存安全。PR2 通过 decision-tree-based prompting 指导指针提升过程，并利用 code change analysis 修复重写引入的编译和测试错误。实验结果显示，在 28 个真实 C 项目上，PR2 成功消除 13.22% 的本地 raw pointers，显著提高了代码安全性，平均每个项目转换时间为 5.44 小时，成本仅为 1.46 美元。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.PL"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.04852v2",
      "published_date": "2025-05-07 23:30:27 UTC",
      "updated_date": "2025-05-09 06:32:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:26:58.921043"
    },
    {
      "arxiv_id": "2505.04851v1",
      "title": "CRAFT: Cultural Russian-Oriented Dataset Adaptation for Focused Text-to-Image Generation",
      "title_zh": "CRAFT：面向",
      "authors": [
        "Viacheslav Vasilev",
        "Vladimir Arkhipkin",
        "Julia Agafonova",
        "Tatiana Nikulina",
        "Evelina Mironova",
        "Alisa Shichanina",
        "Nikolai Gerasimenko",
        "Mikhail Shoytov",
        "Denis Dimitrov"
      ],
      "abstract": "Despite the fact that popular text-to-image generation models cope well with\ninternational and general cultural queries, they have a significant knowledge\ngap regarding individual cultures. This is due to the content of existing large\ntraining datasets collected on the Internet, which are predominantly based on\nWestern European or American popular culture. Meanwhile, the lack of cultural\nadaptation of the model can lead to incorrect results, a decrease in the\ngeneration quality, and the spread of stereotypes and offensive content. In an\neffort to address this issue, we examine the concept of cultural code and\nrecognize the critical importance of its understanding by modern image\ngeneration models, an issue that has not been sufficiently addressed in the\nresearch community to date. We propose the methodology for collecting and\nprocessing the data necessary to form a dataset based on the cultural code, in\nparticular the Russian one. We explore how the collected data affects the\nquality of generations in the national domain and analyze the effectiveness of\nour approach using the Kandinsky 3.1 text-to-image model. Human evaluation\nresults demonstrate an increase in the level of awareness of Russian culture in\nthe model.",
      "tldr_zh": "本文提出CRAFT方法，旨在解决文本到图像生成模型（text-to-image generation）在处理特定文化查询时的知识缺口问题，特别是针对俄罗斯文化。该方法包括收集和处理基于文化代码（cultural code）的俄罗斯导向数据集，以改善模型的生成质量和减少刻板印象。实验通过Kandinsky 3.1模型评估，结果显示人类评估中模型对俄罗斯文化的认知水平显著提升。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.CV",
        "cs.CY",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "This is arxiv version of the paper which was accepted for the Doklady\n  Mathematics Journal in 2024",
      "pdf_url": "http://arxiv.org/pdf/2505.04851v1",
      "published_date": "2025-05-07 23:29:28 UTC",
      "updated_date": "2025-05-07 23:29:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:27:08.589166"
    },
    {
      "arxiv_id": "2505.04847v1",
      "title": "Benchmarking LLM Faithfulness in RAG with Evolving Leaderboards",
      "title_zh": "翻译失败",
      "authors": [
        "Manveer Singh Tamber",
        "Forrest Sheng Bao",
        "Chenyu Xu",
        "Ge Luo",
        "Suleman Kazi",
        "Minseok Bae",
        "Miaoran Li",
        "Ofer Mendelevitch",
        "Renyi Qu",
        "Jimmy Lin"
      ],
      "abstract": "Hallucinations remain a persistent challenge for LLMs. RAG aims to reduce\nhallucinations by grounding responses in contexts. However, even when provided\ncontext, LLMs still frequently introduce unsupported information or\ncontradictions. This paper presents our efforts to measure LLM hallucinations\nwith a focus on summarization tasks, assessing how often various LLMs introduce\nhallucinations when summarizing documents. We discuss Vectara's existing LLM\nhallucination leaderboard, based on the Hughes Hallucination Evaluation Model\n(HHEM). While HHEM and Vectara's Hallucination Leaderboard have garnered great\nresearch interest, we examine challenges faced by HHEM and current\nhallucination detection methods by analyzing the effectiveness of these methods\non existing hallucination datasets. To address these limitations, we propose\nFaithJudge, an LLM-as-a-judge approach guided by few-shot human hallucination\nannotations, which substantially improves automated LLM hallucination\nevaluation over current methods. We introduce an enhanced hallucination\nleaderboard centered on FaithJudge, alongside our current hallucination\nleaderboard, enabling more reliable benchmarking of LLMs for hallucinations in\nRAG.",
      "tldr_zh": "该论文探讨了大型语言模型(LLMs)在检索增强生成(RAG)中的幻觉(hallucinations)问题，尽管RAG通过提供上下文试图减少幻觉，但LLMs仍常引入不准确信息。作者分析了现有方法如Hughes Hallucination Evaluation Model(HHEM)和Vectara的幻觉排行榜的局限性，并通过实验评估其在幻觉数据集上的有效性。为解决这些挑战，论文提出FaithJudge，一种基于LLM-as-a-judge的评估方法，利用少量人类标注进行引导，从而显著提升了自动幻觉检测的性能。最后，作者引入了一个以FaithJudge为核心的增强幻觉排行榜，提供更可靠的LLMs在RAG中的基准测试框架。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.04847v1",
      "published_date": "2025-05-07 22:50:33 UTC",
      "updated_date": "2025-05-07 22:50:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:27:21.487474"
    },
    {
      "arxiv_id": "2505.13466v1",
      "title": "AgentSGEN: Multi-Agent LLM in the Loop for Semantic Collaboration and GENeration of Synthetic Data",
      "title_zh": "翻译失败",
      "authors": [
        "Vu Dinh Xuan",
        "Hao Vo",
        "David Murphy",
        "Hoang D. Nguyen"
      ],
      "abstract": "The scarcity of data depicting dangerous situations presents a major obstacle\nto training AI systems for safety-critical applications, such as construction\nsafety, where ethical and logistical barriers hinder real-world data\ncollection. This creates an urgent need for an end-to-end framework to generate\nsynthetic data that can bridge this gap. While existing methods can produce\nsynthetic scenes, they often lack the semantic depth required for scene\nsimulations, limiting their effectiveness. To address this, we propose a novel\nmulti-agent framework that employs an iterative, in-the-loop collaboration\nbetween two agents: an Evaluator Agent, acting as an LLM-based judge to enforce\nsemantic consistency and safety-specific constraints, and an Editor Agent,\nwhich generates and refines scenes based on this guidance. Powered by LLM's\ncapabilities to reasoning and common-sense knowledge, this collaborative design\nproduces synthetic images tailored to safety-critical scenarios. Our\nexperiments suggest this design can generate useful scenes based on realistic\nspecifications that address the shortcomings of prior approaches, balancing\nsafety requirements with visual semantics. This iterative process holds promise\nfor delivering robust, aesthetically sound simulations, offering a potential\nsolution to the data scarcity challenge in multimedia safety applications.",
      "tldr_zh": "该研究提出AgentSGEN框架，一个基于多智能体LLM的循环协作系统，用于生成语义丰富的合成数据，以解决安全关键应用（如建筑安全）中数据稀缺的问题。框架包括两个代理：Evaluator Agent负责作为LLM-based判断者，确保语义一致性和安全约束；Editor Agent则根据指导生成和完善合成场景，利用LLM的推理和常识知识进行迭代优化。实验结果表明，该设计能基于现实规范创建符合安全要求的合成图像，平衡了安全需求与视觉语义，从而为多媒体安全应用提供潜在解决方案。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.13466v1",
      "published_date": "2025-05-07 22:43:33 UTC",
      "updated_date": "2025-05-07 22:43:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:27:33.024791"
    },
    {
      "arxiv_id": "2505.04843v1",
      "title": "Large Language Models are Autonomous Cyber Defenders",
      "title_zh": "翻译失败",
      "authors": [
        "Sebastián R. Castro",
        "Roberto Campbell",
        "Nancy Lau",
        "Octavio Villalobos",
        "Jiaqi Duan",
        "Alvaro A. Cardenas"
      ],
      "abstract": "Fast and effective incident response is essential to prevent adversarial\ncyberattacks. Autonomous Cyber Defense (ACD) aims to automate incident response\nthrough Artificial Intelligence (AI) agents that plan and execute actions. Most\nACD approaches focus on single-agent scenarios and leverage Reinforcement\nLearning (RL). However, ACD RL-trained agents depend on costly training, and\ntheir reasoning is not always explainable or transferable. Large Language\nModels (LLMs) can address these concerns by providing explainable actions in\ngeneral security contexts. Researchers have explored LLM agents for ACD but\nhave not evaluated them on multi-agent scenarios or interacting with other ACD\nagents. In this paper, we show the first study on how LLMs perform in\nmulti-agent ACD environments by proposing a new integration to the CybORG CAGE\n4 environment. We examine how ACD teams of LLM and RL agents can interact by\nproposing a novel communication protocol. Our results highlight the strengths\nand weaknesses of LLMs and RL and help us identify promising research\ndirections to create, train, and deploy future teams of ACD agents.",
      "tldr_zh": "该论文探讨Large Language Models (LLMs) 在Autonomous Cyber Defense (ACD) 中的潜力，旨在解决传统Reinforcement Learning (RL) 代理的训练成本高和推理不透明等问题。研究者首次评估LLMs 在多代理环境中的性能，通过集成到CybORG CAGE 4 环境并提出一种新型通信协议，考察LLMs 与RL 代理的团队交互。结果突出了LLMs 的可解释性和通用性优势，同时揭示其弱点，并为创建和部署未来ACD 代理团队指出了有前景的研究方向。",
      "categories": [
        "cs.AI",
        "cs.CR",
        "I.2.0"
      ],
      "primary_category": "cs.AI",
      "comment": "Presented at IEEE CAI Workshop on Adaptive Cyber Defense 2025.\n  Proceedings to appear",
      "pdf_url": "http://arxiv.org/pdf/2505.04843v1",
      "published_date": "2025-05-07 22:42:37 UTC",
      "updated_date": "2025-05-07 22:42:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:27:45.507344"
    },
    {
      "arxiv_id": "2505.04842v1",
      "title": "Putting the Value Back in RL: Better Test-Time Scaling by Unifying LLM Reasoners With Verifiers",
      "title_zh": "翻译失败",
      "authors": [
        "Kusha Sareen",
        "Morgane M Moss",
        "Alessandro Sordoni",
        "Rishabh Agarwal",
        "Arian Hosseini"
      ],
      "abstract": "Prevalent reinforcement learning~(RL) methods for fine-tuning LLM reasoners,\nsuch as GRPO or Leave-one-out PPO, abandon the learned value function in favor\nof empirically estimated returns. This hinders test-time compute scaling that\nrelies on using the value-function for verification. In this work, we propose\nRL$^V$ that augments any ``value-free'' RL method by jointly training the LLM\nas both a reasoner and a generative verifier using RL-generated data, adding\nverification capabilities without significant overhead. Empirically, RL$^V$\nboosts MATH accuracy by over 20\\% with parallel sampling and enables\n$8-32\\times$ efficient test-time compute scaling compared to the base RL\nmethod. RL$^V$ also exhibits strong generalization capabilities for both\neasy-to-hard and out-of-domain tasks. Furthermore, RL$^V$ achieves\n$1.2-1.6\\times$ higher performance when jointly scaling parallel and sequential\ntest-time compute with a long reasoning R1 model.",
      "tldr_zh": "该论文指出，现有的强化学习（RL）方法（如 GRPO 或 Leave-one-out PPO）在微调 LLM 推理器时放弃了学习的价值函数，转而依赖经验估计回报，从而阻碍了测试时计算缩放。作者提出 RL$^V$ 方法，通过在任何“无价值”RL 方法基础上联合训练 LLM 作为 reasoner 和 generative verifier，利用 RL 生成的数据添加验证能力，而不增加显著开销。实验结果显示，RL$^V$ 在 MATH 数据集上通过并行采样提高了超过 20% 的准确率，并实现了 8-32 倍的测试时计算效率提升，同时在易到难和域外任务上展现出强泛化能力。此外，当与长推理模型结合时，RL$^V$ 在同时扩展并行和顺序测试时计算时，性能提升了 1.2-1.6 倍。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.04842v1",
      "published_date": "2025-05-07 22:41:26 UTC",
      "updated_date": "2025-05-07 22:41:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:27:59.415432"
    },
    {
      "arxiv_id": "2505.04841v2",
      "title": "Quantum-Inspired Optimization Process for Data Imputation",
      "title_zh": "量子启发的优化过程用于数据插补",
      "authors": [
        "Nishikanta Mohanty",
        "Bikash K. Behera",
        "Badshah Mukherjee",
        "Christopher Ferrie"
      ],
      "abstract": "Data imputation is a critical step in data pre-processing, particularly for\ndatasets with missing or unreliable values. This study introduces a novel\nquantum-inspired imputation framework evaluated on the UCI Diabetes dataset,\nwhich contains biologically implausible missing values across several clinical\nfeatures. The method integrates Principal Component Analysis (PCA) with\nquantum-assisted rotations, optimized through gradient-free classical\noptimizers -COBYLA, Simulated Annealing, and Differential Evolution to\nreconstruct missing values while preserving statistical fidelity. Reconstructed\nvalues are constrained within +/-2 standard deviations of original feature\ndistributions, avoiding unrealistic clustering around central tendencies. This\napproach achieves a substantial and statistically significant improvement,\nincluding an average reduction of over 85% in Wasserstein distance and\nKolmogorov-Smirnov test p-values between 0.18 and 0.22, compared to p-values >\n0.99 in classical methods such as Mean, KNN, and MICE. The method also\neliminates zero-value artifacts and enhances the realism and variability of\nimputed data. By combining quantum-inspired transformations with a scalable\nclassical framework, this methodology provides a robust solution for imputation\ntasks in domains such as healthcare and AI pipelines, where data quality and\nintegrity are crucial.",
      "tldr_zh": "本研究提出了一种量子启发式优化过程，用于数据填充，特别针对UCI Diabetes数据集中的生物上不合理的缺失值。方法整合Principal Component Analysis (PCA)与量子辅助旋转，并使用无梯度经典优化器如COBYLA、Simulated Annealing和Differential Evolution来重建缺失值，同时确保重建值限制在原特征分布的±2标准差内，以保持统计保真度和数据变异性。与经典方法（如Mean、KNN和MICE）相比，该框架平均减少超过85%的Wasserstein distance，并将Kolmogorov-Smirnov测试p值从大于0.99降低至0.18-0.22，显著提升填充数据的真实性和可靠性。该方法为医疗和AI管道等领域提供了一个可扩展的鲁棒解决方案，确保数据质量和完整性。",
      "categories": [
        "quant-ph",
        "cs.AI"
      ],
      "primary_category": "quant-ph",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.04841v2",
      "published_date": "2025-05-07 22:37:07 UTC",
      "updated_date": "2025-05-11 00:20:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:28:09.453807"
    },
    {
      "arxiv_id": "2505.07852v1",
      "title": "Joint Detection of Fraud and Concept Drift inOnline Conversations with LLM-Assisted Judgment",
      "title_zh": "翻译失败",
      "authors": [
        "Ali Senol",
        "Garima Agrawal",
        "Huan Liu"
      ],
      "abstract": "Detecting fake interactions in digital communication platforms remains a\nchallenging and insufficiently addressed problem. These interactions may appear\nas harmless spam or escalate into sophisticated scam attempts, making it\ndifficult to flag malicious intent early. Traditional detection methods often\nrely on static anomaly detection techniques that fail to adapt to dynamic\nconversational shifts. One key limitation is the misinterpretation of benign\ntopic transitions referred to as concept drift as fraudulent behavior, leading\nto either false alarms or missed threats. We propose a two stage detection\nframework that first identifies suspicious conversations using a tailored\nensemble classification model. To improve the reliability of detection, we\nincorporate a concept drift analysis step using a One Class Drift Detector\n(OCDD) to isolate conversational shifts within flagged dialogues. When drift is\ndetected, a large language model (LLM) assesses whether the shift indicates\nfraudulent manipulation or a legitimate topic change. In cases where no drift\nis found, the behavior is inferred to be spam like. We validate our framework\nusing a dataset of social engineering chat scenarios and demonstrate its\npractical advantages in improving both accuracy and interpretability for real\ntime fraud detection. To contextualize the trade offs, we compare our modular\napproach against a Dual LLM baseline that performs detection and judgment using\ndifferent language models.",
      "tldr_zh": "这篇论文提出了一种联合检测框架，用于识别在线对话中的欺诈行为和概念漂移（concept drift），以解决传统静态异常检测方法在动态对话中的局限性。框架采用两阶段方法：首先使用集成分类模型（ensemble classification model）标记可疑对话，然后通过 One Class Drift Detector (OCDD) 分析概念漂移，并借助大型语言模型 (LLM) 判断漂移是否为欺诈操纵或合法变化。实验在社交工程聊天数据集上验证了该框架的实际优势，提高了检测的准确性和可解释性，并与 Dual LLM 基线方法进行了比较，突出了其模块化设计的权衡。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.07852v1",
      "published_date": "2025-05-07 22:30:53 UTC",
      "updated_date": "2025-05-07 22:30:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:28:22.060610"
    },
    {
      "arxiv_id": "2505.04822v1",
      "title": "Is there Value in Reinforcement Learning?",
      "title_zh": "强化学习中是否有价值？",
      "authors": [
        "Lior Fox",
        "Yonatan Loewenstein"
      ],
      "abstract": "Action-values play a central role in popular Reinforcement Learing (RL)\nmodels of behavior. Yet, the idea that action-values are explicitly represented\nhas been extensively debated. Critics had therefore repeatedly suggested that\npolicy-gradient (PG) models should be favored over value-based (VB) ones, as a\npotential solution for this dilemma. Here we argue that this solution is\nunsatisfying. This is because PG methods are not, in fact, \"Value-free\" --\nwhile they do not rely on an explicit representation of Value for acting\n(stimulus-response mapping), they do require it for learning. Hence, switching\nto PG models is, per se, insufficient for eliminating Value from models of\nbehavior. More broadly, the requirement for a representation of Value stems\nfrom the underlying assumptions regarding the optimization objective posed by\nthe standard RL framework, not from the particular algorithm chosen to solve\nit. Previous studies mostly took these standard RL assumptions for granted, as\npart of their conceptualization or problem modeling, while debating the\ndifferent methods used to optimize it (i.e., PG or VB). We propose that,\ninstead, the focus of the debate should shift to critically evaluating the\nunderlying modeling assumptions. Such evaluation is particularly important from\nan experimental perspective. Indeed, the very notion of Value must be\nreconsidered when standard assumptions (e.g., risk neutrality,\nfull-observability, Markovian environment, exponential discounting) are\nrelaxed, as is likely in natural settings. Finally, we use the Value debate as\na case study to argue in favor of a more nuanced, algorithmic rather than\nstatistical, view of what constitutes \"a model\" in cognitive sciences. Our\nanalysis suggests that besides \"parametric\" statistical complexity, additional\naspects such as computational complexity must also be taken into account when\nevaluating model complexity.",
      "tldr_zh": "这篇论文质疑了强化学习（Reinforcement Learning, RL）中行动价值（action-values）的必要性，指出尽管策略梯度（policy-gradient, PG）模型被视为避免显式价值表示的替代方案，但它在学习过程中仍依赖价值表示，从而无法完全消除价值的需求。作者强调，这种需求源于RL框架的标准假设（如风险中性、全可观察性和Markovian环境），而非具体的优化算法（如PG或value-based, VB）。论文建议，将辩论焦点从算法比较转向批判性评估这些底层假设，尤其在自然环境中这些假设可能不成立时，需要重新审视价值概念。最后，作者主张在认知科学中采用更细致的算法视角评估模型复杂性，包括计算复杂性而非仅统计复杂性。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted to The 6th Multidisciplinary Conference on Reinforcement\n  Learning and Decision Making (RLDM 2025)",
      "pdf_url": "http://arxiv.org/pdf/2505.04822v1",
      "published_date": "2025-05-07 21:50:27 UTC",
      "updated_date": "2025-05-07 21:50:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:28:34.234445"
    },
    {
      "arxiv_id": "2505.04808v1",
      "title": "Piecewise Constant Spectral Graph Neural Network",
      "title_zh": "分段常数谱图神经网络",
      "authors": [
        "Vahan Martirosyan",
        "Jhony H. Giraldo",
        "Fragkiskos D. Malliaros"
      ],
      "abstract": "Graph Neural Networks (GNNs) have achieved significant success across various\ndomains by leveraging graph structures in data. Existing spectral GNNs, which\nuse low-degree polynomial filters to capture graph spectral properties, may not\nfully identify the graph's spectral characteristics because of the polynomial's\nsmall degree. However, increasing the polynomial degree is computationally\nexpensive and beyond certain thresholds leads to performance plateaus or\ndegradation. In this paper, we introduce the Piecewise Constant Spectral Graph\nNeural Network(PieCoN) to address these challenges. PieCoN combines constant\nspectral filters with polynomial filters to provide a more flexible way to\nleverage the graph structure. By adaptively partitioning the spectrum into\nintervals, our approach increases the range of spectral properties that can be\neffectively learned. Experiments on nine benchmark datasets, including both\nhomophilic and heterophilic graphs, demonstrate that PieCoN is particularly\neffective on heterophilic datasets, highlighting its potential for a wide range\nof applications.",
      "tldr_zh": "本研究针对现有谱图神经网络（spectral GNNs）使用低阶多项式过滤器无法充分捕捉图谱特性的问题，提出了Piecewise Constant Spectral Graph Neural Network (PieCoN)模型。PieCoN通过结合常量谱过滤器和多项式过滤器，并采用自适应谱分区方法，提供更灵活的图结构利用方式，从而提升模型的谱特性学习能力。在九个基准数据集上的实验表明，该模型在异质图（heterophilic graphs）上表现尤为出色，显著优于基线方法，具有广泛的应用潜力。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted to TMLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2505.04808v1",
      "published_date": "2025-05-07 21:17:06 UTC",
      "updated_date": "2025-05-07 21:17:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:28:46.783088"
    },
    {
      "arxiv_id": "2505.07851v1",
      "title": "Pose Estimation for Intra-cardiac Echocardiography Catheter via AI-Based Anatomical Understanding",
      "title_zh": "翻译失败",
      "authors": [
        "Jaeyoung Huh",
        "Ankur Kapoor",
        "Young-Ho Kim"
      ],
      "abstract": "Intra-cardiac Echocardiography (ICE) plays a crucial role in\nElectrophysiology (EP) and Structural Heart Disease (SHD) interventions by\nproviding high-resolution, real-time imaging of cardiac structures. However,\nexisting navigation methods rely on electromagnetic (EM) tracking, which is\nsusceptible to interference and position drift, or require manual adjustments\nbased on operator expertise. To overcome these limitations, we propose a novel\nanatomy-aware pose estimation system that determines the ICE catheter position\nand orientation solely from ICE images, eliminating the need for external\ntracking sensors. Our approach leverages a Vision Transformer (ViT)-based deep\nlearning model, which captures spatial relationships between ICE images and\nanatomical structures. The model is trained on a clinically acquired dataset of\n851 subjects, including ICE images paired with position and orientation labels\nnormalized to the left atrium (LA) mesh. ICE images are patchified into 16x16\nembeddings and processed through a transformer network, where a [CLS] token\nindependently predicts position and orientation via separate linear layers. The\nmodel is optimized using a Mean Squared Error (MSE) loss function, balancing\npositional and orientational accuracy. Experimental results demonstrate an\naverage positional error of 9.48 mm and orientation errors of (16.13 deg, 8.98\ndeg, 10.47 deg) across x, y, and z axes, confirming the model accuracy.\nQualitative assessments further validate alignment between predicted and target\nviews within 3D cardiac meshes. This AI-driven system enhances procedural\nefficiency, reduces operator workload, and enables real-time ICE catheter\nlocalization for tracking-free procedures. The proposed method can function\nindependently or complement existing mapping systems like CARTO, offering a\ntransformative approach to ICE-guided interventions.",
      "tldr_zh": "本研究针对 Intra-cardiac Echocardiography (ICE) 导管在心脏介入手术中的导航问题，提出了一种基于 AI 的解剖结构感知姿态估计系统，该系统仅从 ICE 图像中直接确定导管的位置和方向，无需依赖易受干扰的电磁 (EM) 跟踪传感器。方法采用 Vision Transformer (ViT) 模型，将 ICE 图像分解为 16x16 嵌入，通过 transformer 网络和 [CLS] 标记独立预测位置和方向，并使用 Mean Squared Error (MSE) 损失函数进行优化，训练数据来自 851 个临床受试者的图像数据集。实验结果显示，平均位置错误为 9.48 mm，方向错误分别为 x 轴 16.13°、y 轴 8.98° 和 z 轴 10.47°，并在 3D 心脏网格中实现了预测与目标视图的对齐。该系统提升了手术程序效率，减轻了操作员工作量，并可独立或与 CARTO 等现有系统结合，实现实时无跟踪导航。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV",
        "cs.RO"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.07851v1",
      "published_date": "2025-05-07 21:09:42 UTC",
      "updated_date": "2025-05-07 21:09:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:29:01.535851"
    },
    {
      "arxiv_id": "2505.04802v1",
      "title": "ORBIT-2: Scaling Exascale Vision Foundation Models for Weather and Climate Downscaling",
      "title_zh": "翻译失败",
      "authors": [
        "Xiao Wang",
        "Jong-Youl Choi",
        "Takuya Kurihaya",
        "Isaac Lyngaas",
        "Hong-Jun Yoon",
        "Ming Fan",
        "Nasik Muhammad Nafi",
        "Aristeidis Tsaris",
        "Ashwin M. Aji",
        "Maliha Hossain",
        "Mohamed Wahib",
        "Dali Wang",
        "Peter Thornton",
        "Prasanna Balaprakash",
        "Moetasim Ashfaq",
        "Dan Lu"
      ],
      "abstract": "Sparse observations and coarse-resolution climate models limit effective\nregional decision-making, underscoring the need for robust downscaling.\nHowever, existing AI methods struggle with generalization across variables and\ngeographies and are constrained by the quadratic complexity of Vision\nTransformer (ViT) self-attention. We introduce ORBIT-2, a scalable foundation\nmodel for global, hyper-resolution climate downscaling. ORBIT-2 incorporates\ntwo key innovations: (1) Residual Slim ViT (Reslim), a lightweight architecture\nwith residual learning and Bayesian regularization for efficient, robust\nprediction; and (2) TILES, a tile-wise sequence scaling algorithm that reduces\nself-attention complexity from quadratic to linear, enabling long-sequence\nprocessing and massive parallelism. ORBIT-2 scales to 10 billion parameters\nacross 32,768 GPUs, achieving up to 1.8 ExaFLOPS sustained throughput and\n92-98% strong scaling efficiency. It supports downscaling to 0.9 km global\nresolution and processes sequences up to 4.2 billion tokens. On 7 km resolution\nbenchmarks, ORBIT-2 achieves high accuracy with R^2 scores in the range of 0.98\nto 0.99 against observation data.",
      "tldr_zh": "本研究提出ORBIT-2，一种可扩展的Exascale视觉基础模型，用于天气和气候下采样，以解决现有AI方法在变量泛化和地理覆盖方面的局限性，以及Vision Transformer (ViT)自注意力机制的二次方复杂度问题。ORBIT-2的关键创新包括Residual Slim ViT (Reslim)架构，利用残差学习和Bayesian regularization实现高效鲁棒预测，以及TILES算法，将自注意力复杂度从二次方降至线性，支持长序列处理和大规模并行。模型扩展到100亿参数，在32,768 GPUs上实现高达1.8 ExaFLOPS的持续吞吐量和92-98%的强缩放效率，可支持全球0.9 km分辨率下采样和处理42亿tokens序列。在7 km分辨率基准测试中，ORBIT-2达到R^2分数0.98-0.99，与观测数据高度一致。",
      "categories": [
        "cs.LG",
        "astro-ph.EP",
        "cs.AI",
        "cs.DC",
        "physics.ao-ph"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.04802v1",
      "published_date": "2025-05-07 21:09:00 UTC",
      "updated_date": "2025-05-07 21:09:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:29:11.449056"
    },
    {
      "arxiv_id": "2505.08795v1",
      "title": "The Geometry of Meaning: Perfect Spacetime Representations of Hierarchical Structures",
      "title_zh": "翻译失败",
      "authors": [
        "Andres Anabalon",
        "Hugo Garces",
        "Julio Oliva",
        "Jose Cifuentes"
      ],
      "abstract": "We show that there is a fast algorithm that embeds hierarchical structures in\nthree-dimensional Minkowski spacetime. The correlation of data ends up purely\nencoded in the causal structure. Our model relies solely on oriented token\npairs -- local hierarchical signals -- with no access to global symbolic\nstructure. We apply our method to the corpus of \\textit{WordNet}. We provide a\nperfect embedding of the mammal sub-tree including ambiguities (more than one\nhierarchy per node) in such a way that the hierarchical structures get\ncompletely codified in the geometry and exactly reproduce the ground-truth. We\nextend this to a perfect embedding of the maximal unambiguous subset of the\n\\textit{WordNet} with 82{,}115 noun tokens and a single hierarchy per token. We\nintroduce a novel retrieval mechanism in which causality, not distance, governs\nhierarchical access. Our results seem to indicate that all discrete data has a\nperfect geometrical representation that is three-dimensional. The resulting\nembeddings are nearly conformally invariant, indicating deep connections with\ngeneral relativity and field theory. These results suggest that concepts,\ncategories, and their interrelations, namely hierarchical meaning itself, is\ngeometric.",
      "tldr_zh": "本研究提出了一种快速算法，将层次结构完美嵌入三维Minkowski spacetime中，通过oriented token pairs（定向标记对）编码数据相关性，并完全依赖于局部层次信号，而非全局符号结构。在WordNet语料库应用中，该算法实现了哺乳动物子树（包括歧义）的完美嵌入，并扩展到包含82,115个名词标记的最大无歧义子集，其中层次结构完全由几何因果结构重现。论文引入了一种基于因果关系的检索机制，而非距离，并发现所有离散数据可能具有三维几何表示，这些嵌入近乎保形不变，暗示了与广义相对论和场论的深层联系，从而揭示了概念、类别及其层次意义的几何本质。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "7 pages, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.08795v1",
      "published_date": "2025-05-07 20:41:06 UTC",
      "updated_date": "2025-05-07 20:41:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:29:23.934052"
    },
    {
      "arxiv_id": "2505.04792v1",
      "title": "Confabulation dynamics in a reservoir computer: Filling in the gaps with untrained attractors",
      "title_zh": "翻译失败",
      "authors": [
        "Jack O'Hagan",
        "Andrew Keane",
        "Andrew Flynn"
      ],
      "abstract": "Artificial Intelligence has advanced significantly in recent years thanks to\ninnovations in the design and training of artificial neural networks (ANNs).\nDespite these advancements, we still understand relatively little about how\nelementary forms of ANNs learn, fail to learn, and generate false information\nwithout the intent to deceive, a phenomenon known as `confabulation'. To\nprovide some foundational insight, in this paper we analyse how confabulation\noccurs in reservoir computers (RCs): a dynamical system in the form of an ANN.\nRCs are particularly useful to study as they are known to confabulate in a\nwell-defined way: when RCs are trained to reconstruct the dynamics of a given\nattractor, they sometimes construct an attractor that they were not trained to\nconstruct, a so-called `untrained attractor' (UA). This paper sheds light on\nthe role played by UAs when reconstruction fails and their influence when\nmodelling transitions between reconstructed attractors. Based on our results,\nwe conclude that UAs are an intrinsic feature of learning systems whose state\nspaces are bounded, and that this means of confabulation may be present in\nsystems beyond RCs.",
      "tldr_zh": "这篇论文探讨了人工神经网络(ANNs)中的confabulation现象，即系统在未意图欺骗的情况下生成虚假信息。研究焦点在于reservoir computers (RCs)，分析了当RCs被训练重建特定吸引子动态时，如何生成未训练过的吸引子(untrained attractors, UAs)，并考察了UAs在重建失败和吸引子之间过渡中的影响作用。最终结论认为，UAs是状态空间受限学习系统的固有特征，可能存在于RCs以外的系统中，为理解神经网络的局限性提供了基础洞见。",
      "categories": [
        "math.DS",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "math.DS",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.04792v1",
      "published_date": "2025-05-07 20:38:44 UTC",
      "updated_date": "2025-05-07 20:38:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:29:33.836505"
    },
    {
      "arxiv_id": "2505.04787v2",
      "title": "Replay to Remember (R2R): An Efficient Uncertainty-driven Unsupervised Continual Learning Framework Using Generative Replay",
      "title_zh": "翻译失败",
      "authors": [
        "Sriram Mandalika",
        "Harsha Vardhan",
        "Athira Nambiar"
      ],
      "abstract": "Continual Learning entails progressively acquiring knowledge from new data\nwhile retaining previously acquired knowledge, thereby mitigating\n``Catastrophic Forgetting'' in neural networks. Our work presents a novel\nuncertainty-driven Unsupervised Continual Learning framework using Generative\nReplay, namely ``Replay to Remember (R2R)''. The proposed R2R architecture\nefficiently uses unlabelled and synthetic labelled data in a balanced\nproportion using a cluster-level uncertainty-driven feedback mechanism and a\nVLM-powered generative replay module. Unlike traditional memory-buffer methods\nthat depend on pretrained models and pseudo-labels, our R2R framework operates\nwithout any prior training. It leverages visual features from unlabeled data\nand adapts continuously using clustering-based uncertainty estimation coupled\nwith dynamic thresholding. Concurrently, a generative replay mechanism along\nwith DeepSeek-R1 powered CLIP VLM produces labelled synthetic data\nrepresentative of past experiences, resembling biological visual thinking that\nreplays memory to remember and act in new, unseen tasks. Extensive experimental\nanalyses are carried out in CIFAR-10, CIFAR-100, CINIC-10, SVHN and\nTinyImageNet datasets. Our proposed R2R approach improves knowledge retention,\nachieving a state-of-the-art performance of 98.13%, 73.06%, 93.41%, 95.18%,\n59.74%, respectively, surpassing state-of-the-art performance by over 4.36%.",
      "tldr_zh": "该研究提出了一种高效的不确定性驱动的无监督持续学习框架Replay to Remember (R2R)，旨在通过Generative Replay生成式重放机制缓解神经网络的Catastrophic Forgetting问题，同时从新数据中学习并保留旧知识。R2R框架利用聚类级不确定性反馈机制和VLM-powered生成模块，平衡使用未标记数据和合成标记数据进行连续适应，而无需预训练模型或伪标签。实验在CIFAR-10、CIFAR-100、CINIC-10、SVHN和TinyImageNet数据集上验证，R2R实现了state-of-the-art性能，分别达到98.13%、73.06%、93.41%、95.18%和59.74%，比现有方法提升超过4.36%。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Submitted to the 28th European Conference on Artificial Intelligence\n  (ECAI-2025)",
      "pdf_url": "http://arxiv.org/pdf/2505.04787v2",
      "published_date": "2025-05-07 20:29:31 UTC",
      "updated_date": "2025-05-09 05:22:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:29:48.490073"
    },
    {
      "arxiv_id": "2505.04785v1",
      "title": "Flower Across Time and Media: Sentiment Analysis of Tang Song Poetry and Visual Correspondence",
      "title_zh": "翻译失败",
      "authors": [
        "Shuai Gong",
        "Tiange Zhou"
      ],
      "abstract": "The Tang (618 to 907) and Song (960 to 1279) dynasties witnessed an\nextraordinary flourishing of Chinese cultural expression, where floral motifs\nserved as a dynamic medium for both poetic sentiment and artistic design. While\nprevious scholarship has examined these domains independently, the systematic\ncorrelation between evolving literary emotions and visual culture remains\nunderexplored. This study addresses that gap by employing BERT-based sentiment\nanalysis to quantify emotional patterns in floral imagery across Tang Song\npoetry, then validating these patterns against contemporaneous developments in\ndecorative arts.Our approach builds upon recent advances in computational\nhumanities while remaining grounded in traditional sinological methods. By\napplying a fine tuned BERT model to analyze peony and plum blossom imagery in\nclassical poetry, we detect measurable shifts in emotional connotations between\nthe Tang and Song periods. These textual patterns are then cross berenced with\nvisual evidence from textiles, ceramics, and other material culture, revealing\npreviously unrecognized synergies between literary expression and artistic\nrepresentation.",
      "tldr_zh": "本研究探讨了唐（618-907）和宋（960-1279）朝代中花卉主题在诗歌情感与视觉艺术间的系统关联，使用 BERT-based sentiment analysis 量化分析唐宋诗歌中牡丹和梅花意象的情感模式。研究方法结合计算人文学进展与传统汉学方法，通过微调 BERT 模型检测唐宋时期情感内涵的变化，并将这些文本模式与纺织品、陶瓷等物质文化中的视觉证据进行交叉引用。结果揭示了文学表达与艺术表现之间的协同作用，填补了先前研究的空白，为跨领域文化分析提供了新见解。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "5 pages, 9 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.04785v1",
      "published_date": "2025-05-07 20:27:38 UTC",
      "updated_date": "2025-05-07 20:27:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:29:57.579422"
    },
    {
      "arxiv_id": "2505.04784v1",
      "title": "A Proposal for Evaluating the Operational Risk for ChatBots based on Large Language Models",
      "title_zh": "基于大型语言模型的聊天机器人操作风险评估提案",
      "authors": [
        "Pedro Pinacho-Davidson",
        "Fernando Gutierrez",
        "Pablo Zapata",
        "Rodolfo Vergara",
        "Pablo Aqueveque"
      ],
      "abstract": "The emergence of Generative AI (Gen AI) and Large Language Models (LLMs) has\nenabled more advanced chatbots capable of human-like interactions. However,\nthese conversational agents introduce a broader set of operational risks that\nextend beyond traditional cybersecurity considerations. In this work, we\npropose a novel, instrumented risk-assessment metric that simultaneously\nevaluates potential threats to three key stakeholders: the service-providing\norganization, end users, and third parties. Our approach incorporates the\ntechnical complexity required to induce erroneous behaviors in the\nchatbot--ranging from non-induced failures to advanced prompt-injection\nattacks--as well as contextual factors such as the target industry, user age\nrange, and vulnerability severity. To validate our metric, we leverage Garak,\nan open-source framework for LLM vulnerability testing. We further enhance\nGarak to capture a variety of threat vectors (e.g., misinformation, code\nhallucinations, social engineering, and malicious code generation). Our\nmethodology is demonstrated in a scenario involving chatbots that employ\nretrieval-augmented generation (RAG), showing how the aggregated risk scores\nguide both short-term mitigation and longer-term improvements in model design\nand deployment. The results underscore the importance of multi-dimensional risk\nassessments in operationalizing secure, reliable AI-driven conversational\nsystems.",
      "tldr_zh": "这篇论文提出了一种新型风险评估指标，用于评估基于Large Language Models (LLMs)的聊天机器人操作风险，该指标同时考量对服务提供组织、最终用户和第三方利益相关者的潜在威胁。\n方法整合了诱导错误行为的复杂性（如从非诱导故障到高级prompt-injection攻击）以及上下文因素（如目标行业、用户年龄和漏洞严重性），并扩展了开源框架Garak来测试各种威胁向量，包括错误信息、代码幻觉、社会工程和恶意代码生成。\n在涉及retrieval-augmented generation (RAG)的聊天机器人场景中，实验验证了该指标能生成聚合风险分数，从而指导短期风险缓解和长期模型设计改进，突显了多维风险评估在确保AI对话系统安全可靠方面的必要性。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.CR",
      "comment": "21 pages",
      "pdf_url": "http://arxiv.org/pdf/2505.04784v1",
      "published_date": "2025-05-07 20:26:45 UTC",
      "updated_date": "2025-05-07 20:26:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:30:10.938770"
    },
    {
      "arxiv_id": "2505.07850v1",
      "title": "A Tale of Two Identities: An Ethical Audit of Human and AI-Crafted Personas",
      "title_zh": "翻译失败",
      "authors": [
        "Pranav Narayanan Venkit",
        "Jiayi Li",
        "Yingfan Zhou",
        "Sarah Rajtmajer",
        "Shomir Wilson"
      ],
      "abstract": "As LLMs (large language models) are increasingly used to generate synthetic\npersonas particularly in data-limited domains such as health, privacy, and HCI,\nit becomes necessary to understand how these narratives represent identity,\nespecially that of minority communities. In this paper, we audit synthetic\npersonas generated by 3 LLMs (GPT4o, Gemini 1.5 Pro, Deepseek 2.5) through the\nlens of representational harm, focusing specifically on racial identity. Using\na mixed methods approach combining close reading, lexical analysis, and a\nparameterized creativity framework, we compare 1512 LLM generated personas to\nhuman-authored responses. Our findings reveal that LLMs disproportionately\nforeground racial markers, overproduce culturally coded language, and construct\npersonas that are syntactically elaborate yet narratively reductive. These\npatterns result in a range of sociotechnical harms, including stereotyping,\nexoticism, erasure, and benevolent bias, that are often obfuscated by\nsuperficially positive narrations. We formalize this phenomenon as algorithmic\nothering, where minoritized identities are rendered hypervisible but less\nauthentic. Based on these findings, we offer design recommendations for\nnarrative-aware evaluation metrics and community-centered validation protocols\nfor synthetic identity generation.",
      "tldr_zh": "本研究审计了3个LLMs（GPT4o、Gemini 1.5 Pro和Deepseek 2.5）生成的合成人物，聚焦于种族身份的代表性危害（representational harm），通过比较1512个AI生成人物与人类编写的响应，使用混合方法如close reading、lexical analysis和parameterized creativity framework。结果显示，LLMs过度强调种族标记、使用文化编码语言，并创建语法复杂但叙述简化的角色，导致社会技术危害，包括刻板印象（stereotyping）、外来化（exoticism）、抹除（erasure）和善意偏见（benevolent bias）。作者将此现象正式化为算法他者化（algorithmic othering），并提出设计建议，如叙事感知评估指标和社区中心验证协议，以改进合成身份生成。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.07850v1",
      "published_date": "2025-05-07 20:12:48 UTC",
      "updated_date": "2025-05-07 20:12:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:30:22.534229"
    },
    {
      "arxiv_id": "2505.06299v1",
      "title": "Input-Specific and Universal Adversarial Attack Generation for Spiking Neural Networks in the Spiking Domain",
      "title_zh": "针对脉冲神经网络在脉冲域的输入特定和通用对抗攻击生成",
      "authors": [
        "Spyridon Raptis",
        "Haralampos-G. Stratigopoulos"
      ],
      "abstract": "As Spiking Neural Networks (SNNs) gain traction across various applications,\nunderstanding their security vulnerabilities becomes increasingly important. In\nthis work, we focus on the adversarial attacks, which is perhaps the most\nconcerning threat. An adversarial attack aims at finding a subtle input\nperturbation to fool the network's decision-making. We propose two novel\nadversarial attack algorithms for SNNs: an input-specific attack that crafts\nadversarial samples from specific dataset inputs and a universal attack that\ngenerates a reusable patch capable of inducing misclassification across most\ninputs, thus offering practical feasibility for real-time deployment. The\nalgorithms are gradient-based operating in the spiking domain proving to be\neffective across different evaluation metrics, such as adversarial accuracy,\nstealthiness, and generation time. Experimental results on two widely used\nneuromorphic vision datasets, NMNIST and IBM DVS Gesture, show that our\nproposed attacks surpass in all metrics all existing state-of-the-art methods.\nAdditionally, we present the first demonstration of adversarial attack\ngeneration in the sound domain using the SHD dataset.",
      "tldr_zh": "本研究针对Spiking Neural Networks (SNNs)的安全漏洞，提出两种新型梯度-based对抗攻击算法：输入特定攻击（input-specific attack），用于针对特定数据集输入生成对抗样本；以及通用攻击（universal attack），生成可重用的patch，以实现对大多数输入的误分类并便于实时部署。算法在spiking domain中操作，并在对抗准确率、隐蔽性和生成时间等指标上表现出色。实验结果显示，在NMNIST和IBM DVS Gesture等神经形态视觉数据集上，该方法超越所有现有状态-of-the-art方法；此外，这是首次在声音领域（SHD dataset）演示对抗攻击生成。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.06299v1",
      "published_date": "2025-05-07 19:49:18 UTC",
      "updated_date": "2025-05-07 19:49:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:30:34.431934"
    },
    {
      "arxiv_id": "2505.07849v1",
      "title": "SweRank: Software Issue Localization with Code Ranking",
      "title_zh": "翻译失败",
      "authors": [
        "Revanth Gangi Reddy",
        "Tarun Suresh",
        "JaeHyeok Doo",
        "Ye Liu",
        "Xuan Phi Nguyen",
        "Yingbo Zhou",
        "Semih Yavuz",
        "Caiming Xiong",
        "Heng Ji",
        "Shafiq Joty"
      ],
      "abstract": "Software issue localization, the task of identifying the precise code\nlocations (files, classes, or functions) relevant to a natural language issue\ndescription (e.g., bug report, feature request), is a critical yet\ntime-consuming aspect of software development. While recent LLM-based agentic\napproaches demonstrate promise, they often incur significant latency and cost\ndue to complex multi-step reasoning and relying on closed-source LLMs.\nAlternatively, traditional code ranking models, typically optimized for\nquery-to-code or code-to-code retrieval, struggle with the verbose and\nfailure-descriptive nature of issue localization queries. To bridge this gap,\nwe introduce SweRank, an efficient and effective retrieve-and-rerank framework\nfor software issue localization. To facilitate training, we construct SweLoc, a\nlarge-scale dataset curated from public GitHub repositories, featuring\nreal-world issue descriptions paired with corresponding code modifications.\nEmpirical results on SWE-Bench-Lite and LocBench show that SweRank achieves\nstate-of-the-art performance, outperforming both prior ranking models and\ncostly agent-based systems using closed-source LLMs like Claude-3.5. Further,\nwe demonstrate SweLoc's utility in enhancing various existing retriever and\nreranker models for issue localization, establishing the dataset as a valuable\nresource for the community.",
      "tldr_zh": "该研究针对软件问题定位（software issue localization）的挑战，提出了一种高效的 SweRank 框架，该框架采用检索和重新排名（retrieve-and-rerank）方法，以快速识别与自然语言问题描述（如 bug 报告）相关的代码位置。作者构建了大型数据集 SweLoc，从公共 GitHub 仓库中收集真实问题描述和对应代码修改，用于训练模型。实验结果显示，SweRank 在 SWE-Bench-Lite 和 LocBench 上超越了现有排名模型和依赖闭源 LLM（如 Claude-3.5）的代理系统，实现了最先进性能。SweLoc 还证明了其在增强其他检索器和重新排名模型方面的实用价值，为软件开发社区提供了宝贵资源。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.07849v1",
      "published_date": "2025-05-07 19:44:09 UTC",
      "updated_date": "2025-05-07 19:44:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:30:47.449249"
    },
    {
      "arxiv_id": "2505.04759v1",
      "title": "Exploring Zero-Shot App Review Classification with ChatGPT: Challenges and Potential",
      "title_zh": "使用 ChatGPT 探索零样本应用评论分类：挑战和潜力",
      "authors": [
        "Mohit Chaudhary",
        "Chirag Jain",
        "Preethu Rose Anish"
      ],
      "abstract": "App reviews are a critical source of user feedback, offering valuable\ninsights into an app's performance, features, usability, and overall user\nexperience. Effectively analyzing these reviews is essential for guiding app\ndevelopment, prioritizing feature updates, and enhancing user satisfaction.\nClassifying reviews into functional and non-functional requirements play a\npivotal role in distinguishing feedback related to specific app features\n(functional requirements) from feedback concerning broader quality attributes,\nsuch as performance, usability, and reliability (non-functional requirements).\nBoth categories are integral to informed development decisions. Traditional\napproaches to classifying app reviews are hindered by the need for large,\ndomain-specific datasets, which are often costly and time-consuming to curate.\nThis study explores the potential of zero-shot learning with ChatGPT for\nclassifying app reviews into four categories: functional requirement,\nnon-functional requirement, both, or neither. We evaluate ChatGPT's performance\non a benchmark dataset of 1,880 manually annotated reviews from ten diverse\napps spanning multiple domains. Our findings demonstrate that ChatGPT achieves\na robust F1 score of 0.842 in review classification, despite certain challenges\nand limitations. Additionally, we examine how factors such as review\nreadability and length impact classification accuracy and conduct a manual\nanalysis to identify review categories more prone to misclassification.",
      "tldr_zh": "本研究探讨了使用 ChatGPT 进行零-shot learning 的 App 评论分类方法，将评论分类为功能需求（functional requirements）、非功能需求（non-functional requirements）、两者或都不是，以辅助 App 开发决策。实验在包含 1,880 个手动标注评论的基准数据集上评估，ChatGPT 取得了 0.842 的 F1 score，但面临挑战如评论可读性和长度的影响。研究还通过手动分析识别了易误分类的类别，并突显了这种方法的潜力，尽管传统方法依赖于大型领域特定数据集的局限性。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.04759v1",
      "published_date": "2025-05-07 19:39:04 UTC",
      "updated_date": "2025-05-07 19:39:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:30:58.618949"
    },
    {
      "arxiv_id": "2505.04741v1",
      "title": "When Bad Data Leads to Good Models",
      "title_zh": "翻译失败",
      "authors": [
        "Kenneth Li",
        "Yida Chen",
        "Fernanda Viégas",
        "Martin Wattenberg"
      ],
      "abstract": "In large language model (LLM) pretraining, data quality is believed to\ndetermine model quality. In this paper, we re-examine the notion of \"quality\"\nfrom the perspective of pre- and post-training co-design. Specifically, we\nexplore the possibility that pre-training on more toxic data can lead to better\ncontrol in post-training, ultimately decreasing a model's output toxicity.\nFirst, we use a toy experiment to study how data composition affects the\ngeometry of features in the representation space. Next, through controlled\nexperiments with Olmo-1B models trained on varying ratios of clean and toxic\ndata, we find that the concept of toxicity enjoys a less entangled linear\nrepresentation as the proportion of toxic data increases. Furthermore, we show\nthat although toxic data increases the generational toxicity of the base model,\nit also makes the toxicity easier to remove. Evaluations on Toxigen and Real\nToxicity Prompts demonstrate that models trained on toxic data achieve a better\ntrade-off between reducing generational toxicity and preserving general\ncapabilities when detoxifying techniques such as inference-time intervention\n(ITI) are applied. Our findings suggest that, with post-training taken into\naccount, bad data may lead to good models.",
      "tldr_zh": "本研究质疑了大型语言模型（LLM）预训练中数据质量直接决定模型质量的传统观点，通过预训练和后训练的共同设计角度，探讨使用更多毒性数据是否能提升后训练的毒性控制效果。研究者通过玩具实验和控制实验（如在不同比例的干净与毒性数据上训练 Olmo-1B 模型）发现，毒性数据会增加基础模型的生成毒性，但使毒性概念在表示空间中线性表示更少纠缠，从而便于后续解毒。实验结果显示，在 Toxigen 和 Real Toxicity Prompts 上的评估中，用毒性数据训练的模型在应用推理时干预（ITI）等技术后，能更好地平衡减少生成毒性和保留一般能力，最终表明坏数据在后训练考虑下可能导致更好模型。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "ICML 2025",
      "pdf_url": "http://arxiv.org/pdf/2505.04741v1",
      "published_date": "2025-05-07 19:17:49 UTC",
      "updated_date": "2025-05-07 19:17:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:31:12.567508"
    },
    {
      "arxiv_id": "2505.04736v1",
      "title": "The Promise and Limits of LLMs in Constructing Proofs and Hints for Logic Problems in Intelligent Tutoring Systems",
      "title_zh": "翻译失败",
      "authors": [
        "Sutapa Dey Tithi",
        "Arun Kumar Ramesh",
        "Clara DiMarco",
        "Xiaoyi Tian",
        "Nazia Alam",
        "Kimia Fazeli",
        "Tiffany Barnes"
      ],
      "abstract": "Intelligent tutoring systems have demonstrated effectiveness in teaching\nformal propositional logic proofs, but their reliance on template-based\nexplanations limits their ability to provide personalized student feedback.\nWhile large language models (LLMs) offer promising capabilities for dynamic\nfeedback generation, they risk producing hallucinations or pedagogically\nunsound explanations. We evaluated the stepwise accuracy of LLMs in\nconstructing multi-step symbolic logic proofs, comparing six prompting\ntechniques across four state-of-the-art LLMs on 358 propositional logic\nproblems. Results show that DeepSeek-V3 achieved superior performance with\n84.4% accuracy on stepwise proof construction and excelled particularly in\nsimpler rules. We further used the best-performing LLM to generate explanatory\nhints for 1,050 unique student problem-solving states from a logic ITS and\nevaluated them on 4 criteria with both an LLM grader and human expert ratings\non a 20% sample. Our analysis finds that LLM-generated hints were 75% accurate\nand rated highly by human evaluators on consistency and clarity, but did not\nperform as well explaining why the hint was provided or its larger context. Our\nresults demonstrate that LLMs may be used to augment tutoring systems with\nlogic tutoring hints, but requires additional modifications to ensure accuracy\nand pedagogical appropriateness.",
      "tldr_zh": "本文研究评估了大型语言模型 (LLMs) 在智能辅导系统中构建命题逻辑证明和生成提示的能力，旨在解决传统模板-based 解释的局限性。研究者比较了六种提示技术在四种最先进 LLMs 上测试的 358 个逻辑问题，结果显示 DeepSeek-V3 在逐步证明构建中达到 84.4% 的准确率，尤其在简单规则上表现出色。随后，使用该模型为 1,050 个学生问题状态生成解释性提示，并通过 LLM 评分器和人类专家评估，发现提示准确率达 75%，在一致性和清晰度上获高评级，但弱于解释提示背景和整体语境。总体而言，该研究证明 LLMs 可增强智能辅导系统，但需额外修改以确保准确性和教育适宜性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.04736v1",
      "published_date": "2025-05-07 18:48:23 UTC",
      "updated_date": "2025-05-07 18:48:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:31:24.565274"
    },
    {
      "arxiv_id": "2505.04732v1",
      "title": "QBD-RankedDataGen: Generating Custom Ranked Datasets for Improving Query-By-Document Search Using LLM-Reranking with Reduced Human Effort",
      "title_zh": "翻译失败",
      "authors": [
        "Sriram Gopalakrishnan",
        "Sunandita Patra"
      ],
      "abstract": "The Query-By-Document (QBD) problem is an information retrieval problem where\nthe query is a document, and the retrieved candidates are documents that match\nthe query document, often in a domain or query specific manner. This can be\ncrucial for tasks such as patent matching, legal or compliance case retrieval,\nand academic literature review. Existing retrieval methods, including keyword\nsearch and document embeddings, can be optimized with domain-specific datasets\nto improve QBD search performance. However, creating these domain-specific\ndatasets is often costly and time-consuming. Our work introduces a process to\ngenerate custom QBD-search datasets and compares a set of methods to use in\nthis problem, which we refer to as QBD-RankedDatagen. We provide a comparative\nanalysis of our proposed methods in terms of cost, speed, and the human\ninterface with the domain experts. The methods we compare leverage Large\nLanguage Models (LLMs) which can incorporate domain expert input to produce\ndocument scores and rankings, as well as explanations for human review. The\nprocess and methods for it that we present can significantly reduce human\neffort in dataset creation for custom domains while still obtaining sufficient\nexpert knowledge for tuning retrieval models. We evaluate our methods on QBD\ndatasets from the Text Retrieval Conference (TREC) and finetune the parameters\nof the BM25 model -- which is used in many industrial-strength search engines\nlike OpenSearch -- using the generated data.",
      "tldr_zh": "该研究针对Query-By-Document (QBD) 搜索问题提出了一种名为QBD-RankedDataGen的框架，该问题涉及以文档作为查询来检索匹配文档，常用于专利匹配、法律检索等领域，但现有方法依赖昂贵的领域特定数据集。QBD-RankedDataGen利用Large Language Models (LLMs)结合领域专家输入，生成自定义排名数据集并提供解释，从而显著降低人类努力在成本和速度方面的消耗。实验在Text Retrieval Conference (TREC)数据集上评估了多种方法，并使用生成的數據微调BM25模型参数，证明了其在优化QBD搜索性能方面的有效性。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "13 pages",
      "pdf_url": "http://arxiv.org/pdf/2505.04732v1",
      "published_date": "2025-05-07 18:43:57 UTC",
      "updated_date": "2025-05-07 18:43:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:31:34.619186"
    },
    {
      "arxiv_id": "2505.04725v1",
      "title": "Geometric Fault-Tolerant Neural Network Tracking Control of Unknown Systems on Matrix Lie Groups",
      "title_zh": "翻译失败",
      "authors": [
        "Robin Chhabra",
        "Farzaneh Abdollahi"
      ],
      "abstract": "We present a geometric neural network-based tracking controller for systems\nevolving on matrix Lie groups under unknown dynamics, actuator faults, and\nbounded disturbances. Leveraging the left-invariance of the tangent bundle of\nmatrix Lie groups, viewed as an embedded submanifold of the vector space\n$\\R^{N\\times N}$, we propose a set of learning rules for neural network weights\nthat are intrinsically compatible with the Lie group structure and do not\nrequire explicit parameterization. Exploiting the geometric properties of Lie\ngroups, this approach circumvents parameterization singularities and enables a\nglobal search for optimal weights. The ultimate boundedness of all error\nsignals -- including the neural network weights, the coordinate-free\nconfiguration error function, and the tracking velocity error -- is established\nusing Lyapunov's direct method. To validate the effectiveness of the proposed\nmethod, we provide illustrative simulation results for decentralized formation\ncontrol of multi-agent systems on the Special Euclidean group.",
      "tldr_zh": "本文提出了一种几何神经网络跟踪控制器，用于处理在 Matrix Lie Groups 上演化的未知系统，包括执行器故障和有界干扰。该控制器利用矩阵 Lie 群切丛的左不变性，设计了与 Lie 群结构内在兼容的神经网络权重学习规则，避免了参数化奇异性和实现了全局权重优化。通过 Lyapunov's direct method 证明了神经网络权重、坐标无关的配置错误函数和跟踪速度错误的最终有界性。模拟结果验证了该方法的有效性，特别是在 Special Euclidean group 上的多智能体系统去中心化编队控制中。",
      "categories": [
        "eess.SY",
        "cs.AI",
        "cs.RO",
        "cs.SY",
        "math.DS"
      ],
      "primary_category": "eess.SY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.04725v1",
      "published_date": "2025-05-07 18:33:23 UTC",
      "updated_date": "2025-05-07 18:33:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:31:47.102944"
    },
    {
      "arxiv_id": "2505.06136v1",
      "title": "Efficient Sensorimotor Learning for Open-world Robot Manipulation",
      "title_zh": "高效感觉运动学习用于开放世界机器人操控",
      "authors": [
        "Yifeng Zhu"
      ],
      "abstract": "This dissertation considers Open-world Robot Manipulation, a manipulation\nproblem where a robot must generalize or quickly adapt to new objects, scenes,\nor tasks for which it has not been pre-programmed or pre-trained. This\ndissertation tackles the problem using a methodology of efficient sensorimotor\nlearning. The key to enabling efficient sensorimotor learning lies in\nleveraging regular patterns that exist in limited amounts of demonstration\ndata. These patterns, referred to as ``regularity,'' enable the data-efficient\nlearning of generalizable manipulation skills. This dissertation offers a new\nperspective on formulating manipulation problems through the lens of\nregularity. Building upon this notion, we introduce three major contributions.\nFirst, we introduce methods that endow robots with object-centric priors,\nallowing them to learn generalizable, closed-loop sensorimotor policies from a\nsmall number of teleoperation demonstrations. Second, we introduce methods that\nconstitute robots' spatial understanding, unlocking their ability to imitate\nmanipulation skills from in-the-wild video observations. Last but not least, we\nintroduce methods that enable robots to identify reusable skills from their\npast experiences, resulting in systems that can continually imitate multiple\ntasks in a sequential manner. Altogether, the contributions of this\ndissertation help lay the groundwork for building general-purpose personal\nrobots that can quickly adapt to new situations or tasks with low-cost data\ncollection and interact easily with humans. By enabling robots to learn and\ngeneralize from limited data, this dissertation takes a step toward realizing\nthe vision of intelligent robotic assistants that can be seamlessly integrated\ninto everyday scenarios.",
      "tldr_zh": "这篇论文探讨了 Open-world Robot Manipulation 的挑战，即机器人需泛化或快速适应未预编程的新物体、场景或任务，并提出通过高效的 sensorimotor learning 方法利用数据中的 regularity 来实现数据高效学习。论文的主要贡献包括：引入 object-centric priors，让机器人从少量遥操作演示中学习可泛化的闭环传感器运动策略；开发方法提升机器人的 spatial understanding，以从野外视频观察中模仿操作技能；以及启用机器人从过去经验中识别可重用技能，实现连续多任务模仿。总体而言，这些创新为构建通用个人机器人奠定了基础，使其能以低成本数据收集快速适应新情况，并与人类无缝互动。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "Ph.D. Dissertation",
      "pdf_url": "http://arxiv.org/pdf/2505.06136v1",
      "published_date": "2025-05-07 18:23:58 UTC",
      "updated_date": "2025-05-07 18:23:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:31:59.013152"
    },
    {
      "arxiv_id": "2505.04623v1",
      "title": "EchoInk-R1: Exploring Audio-Visual Reasoning in Multimodal LLMs via Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Zhenghao Xing",
        "Xiaowei Hu",
        "Chi-Wing Fu",
        "Wenhai Wang",
        "Jifeng Dai",
        "Pheng-Ann Heng"
      ],
      "abstract": "Multimodal large language models (MLLMs) have advanced perception across\ntext, vision, and audio, yet they often struggle with structured cross-modal\nreasoning, particularly when integrating audio and visual signals. We introduce\nEchoInk-R1, a reinforcement learning framework that enhances such reasoning in\nMLLMs. Built upon the Qwen2.5-Omni-7B foundation and optimized with Group\nRelative Policy Optimization (GRPO), EchoInk-R1 tackles multiple-choice\nquestion answering over synchronized audio-image pairs. To enable this, we\ncurate AVQA-R1-6K, a dataset pairing such audio-image inputs with\nmultiple-choice questions derived from OmniInstruct-v1. EchoInk-R1-7B achieves\n85.77% accuracy on the validation set, outperforming the base model, which\nscores 80.53%, using only 562 reinforcement learning steps. Beyond accuracy,\nEchoInk-R1 demonstrates reflective reasoning by revisiting initial\ninterpretations and refining responses when facing ambiguous multimodal inputs.\nThese results suggest that lightweight reinforcement learning fine-tuning\nenhances cross-modal reasoning in MLLMs. EchoInk-R1 is the first framework to\nunify audio, visual, and textual modalities for general open-world reasoning\nvia reinforcement learning. Code and data are publicly released to facilitate\nfurther research.",
      "tldr_zh": "该研究引入了 EchoInk-R1，一种基于强化学习的框架，用于提升多模态大语言模型 (MLLMs) 在音频和视觉信号上的结构化跨模态推理。框架建立在 Qwen2.5-Omni-7B 基础上，并采用 Group Relative Policy Optimization (GRPO) 优化，针对同步音频-图像对的多选问答任务。研究者构建了 AVQA-R1-6K 数据集，从 OmniInstruct-v1 派生而来，用于训练和评估。EchoInk-R1-7B 在验证集上达到 85.77% 准确率，比基础模型的 80.53% 提升显著，仅需 562 步强化学习，同时展示了反射性推理能力，能重新审视并改进对模糊输入的响应。该框架是首个统一音频、视觉和文本模态进行一般开源世界推理的系统，并公开了代码和数据以促进进一步研究。",
      "categories": [
        "eess.AS",
        "cs.AI",
        "cs.CV",
        "cs.MM",
        "cs.SD"
      ],
      "primary_category": "eess.AS",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.04623v1",
      "published_date": "2025-05-07 17:59:49 UTC",
      "updated_date": "2025-05-07 17:59:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:32:11.290444"
    },
    {
      "arxiv_id": "2505.04621v1",
      "title": "Score Distillation Sampling for Audio: Source Separation, Synthesis, and Beyond",
      "title_zh": "翻译失败",
      "authors": [
        "Jessie Richter-Powell",
        "Antonio Torralba",
        "Jonathan Lorraine"
      ],
      "abstract": "We introduce Audio-SDS, a generalization of Score Distillation Sampling (SDS)\nto text-conditioned audio diffusion models. While SDS was initially designed\nfor text-to-3D generation using image diffusion, its core idea of distilling a\npowerful generative prior into a separate parametric representation extends to\nthe audio domain. Leveraging a single pretrained model, Audio-SDS enables a\nbroad range of tasks without requiring specialized datasets. In particular, we\ndemonstrate how Audio-SDS can guide physically informed impact sound\nsimulations, calibrate FM-synthesis parameters, and perform prompt-specified\nsource separation. Our findings illustrate the versatility of\ndistillation-based methods across modalities and establish a robust foundation\nfor future work using generative priors in audio tasks.",
      "tldr_zh": "本研究提出了 Audio-SDS，一种将 Score Distillation Sampling (SDS) 泛化到文本条件音频扩散模型的框架，旨在利用预训练模型进行音频生成任务，而无需专用数据集。Audio-SDS 通过蒸馏生成先验，支持多种应用，包括指导物理信息影响声音模拟、校准 FM-synthesis 参数以及执行基于提示的源分离。实验结果证明了这种方法的跨模态通用性，为未来音频任务的创新提供了坚实基础。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.LG",
        "cs.MM",
        "eess.AS",
        "68T07",
        "I.2.6; H.5.5; H.5.1"
      ],
      "primary_category": "cs.SD",
      "comment": "See the project website at\n  https://research.nvidia.com/labs/toronto-ai/Audio-SDS/",
      "pdf_url": "http://arxiv.org/pdf/2505.04621v1",
      "published_date": "2025-05-07 17:59:38 UTC",
      "updated_date": "2025-05-07 17:59:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:32:22.390088"
    },
    {
      "arxiv_id": "2505.04608v2",
      "title": "WATCH: Adaptive Monitoring for AI Deployments via Weighted-Conformal Martingales",
      "title_zh": "翻译失败",
      "authors": [
        "Drew Prinster",
        "Xing Han",
        "Anqi Liu",
        "Suchi Saria"
      ],
      "abstract": "Responsibly deploying artificial intelligence (AI) / machine learning (ML)\nsystems in high-stakes settings arguably requires not only proof of system\nreliability, but moreover continual, post-deployment monitoring to quickly\ndetect and address any unsafe behavior. Statistical methods for nonparametric\nchange-point detection -- especially the tools of conformal test martingales\n(CTMs) and anytime-valid inference -- offer promising approaches to this\nmonitoring task. However, existing methods are restricted to monitoring limited\nhypothesis classes or ``alarm criteria'' (such as data shifts that violate\ncertain exchangeability assumptions), do not allow for online adaptation in\nresponse to shifts, and/or do not enable root-cause analysis of any\ndegradation. In this paper, we expand the scope of these monitoring methods by\nproposing a weighted generalization of conformal test martingales (WCTMs),\nwhich lay a theoretical foundation for online monitoring for any unexpected\nchangepoints in the data distribution while controlling false-alarms. For\npractical applications, we propose specific WCTM algorithms that adapt online\nto mild covariate shifts (in the marginal input distribution) while quickly\ndetecting and diagnosing more severe shifts, such as concept shifts (in the\nconditional label distribution) or extreme (out-of-support) covariate shifts\nthat cannot be easily adapted to. On real-world datasets, we demonstrate\nimproved performance relative to state-of-the-art baselines.",
      "tldr_zh": "该论文针对AI/ML系统在高风险环境中的部署，强调了持续监控以快速检测不安全行为的重要性。作者提出Weighted-Conformal Martingales (WCTMs)作为Conformal Test Martingales (CTMs)的加权泛化，提供理论基础，用于在线监控数据分布的任何意外变更点，同时控制假警报。具体算法能适应轻微的covariate shifts，并快速检测和诊断更严重的concept shifts或极端偏移。在真实数据集上，WCTMs 相对于现有基线展示了改进的性能。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "To be published in The International Conference on Machine Learning\n  (ICML), 2025",
      "pdf_url": "http://arxiv.org/pdf/2505.04608v2",
      "published_date": "2025-05-07 17:53:47 UTC",
      "updated_date": "2025-05-12 17:56:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:32:35.575448"
    },
    {
      "arxiv_id": "2505.04592v1",
      "title": "AI Governance to Avoid Extinction: The Strategic Landscape and Actionable Research Questions",
      "title_zh": "AI 治理以避免灭绝：战略格局和可操作的研究问题",
      "authors": [
        "Peter Barnett",
        "Aaron Scher"
      ],
      "abstract": "Humanity appears to be on course to soon develop AI systems that\nsubstantially outperform human experts in all cognitive domains and activities.\nWe believe the default trajectory has a high likelihood of catastrophe,\nincluding human extinction. Risks come from failure to control powerful AI\nsystems, misuse of AI by malicious rogue actors, war between great powers, and\nauthoritarian lock-in. This research agenda has two aims: to describe the\nstrategic landscape of AI development and to catalog important governance\nresearch questions. These questions, if answered, would provide important\ninsight on how to successfully reduce catastrophic risks.\n  We describe four high-level scenarios for the geopolitical response to\nadvanced AI development, cataloging the research questions most relevant to\neach. Our favored scenario involves building the technical, legal, and\ninstitutional infrastructure required to internationally restrict dangerous AI\ndevelopment and deployment (which we refer to as an Off Switch), which leads\ninto an internationally coordinated Halt on frontier AI activities at some\npoint in the future. The second scenario we describe is a US National Project\nfor AI, in which the US Government races to develop advanced AI systems and\nestablish unilateral control over global AI development. We also describe two\nadditional scenarios: a Light-Touch world similar to that of today and a Threat\nof Sabotage situation where countries use sabotage and deterrence to slow AI\ndevelopment.\n  In our view, apart from the Off Switch and Halt scenario, all of these\ntrajectories appear to carry an unacceptable risk of catastrophic harm. Urgent\naction is needed from the US National Security community and AI governance\necosystem to answer key research questions, build the capability to halt\ndangerous AI activities, and prepare for international AI agreements.",
      "tldr_zh": "该论文探讨了AI治理在避免人类灭绝方面的战略景观，强调如果AI系统超越人类专家，默认发展轨迹可能导致灾难性风险，包括控制失败、恶意使用、大国战争和威权锁定。研究议程的目标是描述AI发展的地缘政治场景，并列出关键治理研究问题，如Off Switch和Halt（国际限制危险AI活动）、US National Project for AI（美国单方面控制）、Light-Touch世界和Threat of Sabotage（破坏与威慑）。作者认为，除Off Switch和Halt场景外，其他轨迹均存在不可接受的灾难风险。论文呼吁美国国家安全社区和AI治理生态系统紧急行动，回答这些研究问题、构建暂停危险AI活动的能力，并推动国际AI协议。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.04592v1",
      "published_date": "2025-05-07 17:35:36 UTC",
      "updated_date": "2025-05-07 17:35:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:32:48.182205"
    },
    {
      "arxiv_id": "2505.04578v1",
      "title": "Fight Fire with Fire: Defending Against Malicious RL Fine-Tuning via Reward Neutralization",
      "title_zh": "翻译失败",
      "authors": [
        "Wenjun Cao"
      ],
      "abstract": "Reinforcement learning (RL) fine-tuning transforms large language models\nwhile creating a vulnerability we experimentally verify: Our experiment shows\nthat malicious RL fine-tuning dismantles safety guardrails with remarkable\nefficiency, requiring only 50 steps and minimal adversarial prompts, with\nharmful escalating from 0-2 to 7-9. This attack vector particularly threatens\nopen-source models with parameter-level access. Existing defenses targeting\nsupervised fine-tuning prove ineffective against RL's dynamic feedback\nmechanisms. We introduce Reward Neutralization, the first defense framework\nspecifically designed against RL fine-tuning attacks, establishing concise\nrejection patterns that render malicious reward signals ineffective. Our\napproach trains models to produce minimal-information rejections that attackers\ncannot exploit, systematically neutralizing attempts to optimize toward harmful\noutputs. Experiments validate that our approach maintains low harmful scores\n(no greater than 2) after 200 attack steps, while standard models rapidly\ndeteriorate. This work provides the first constructive proof that robust\ndefense against increasingly accessible RL attacks is achievable, addressing a\ncritical security gap for open-weight models.",
      "tldr_zh": "这篇论文揭示了强化学习（RL）微调对大型语言模型的安全威胁，实验证明恶意 RL 微调仅需50步和少量对抗提示，就能将有害输出从0-2级提升至7-9级，尤其对开源模型的参数级访问构成重大风险。现有的监督微调防御无效，因此论文提出Reward Neutralization框架，这是首个针对RL微调攻击的防御机制，通过建立简洁拒绝模式使恶意奖励信号失效，并训练模型生成不可利用的最低信息拒绝。实验结果显示，该方法在200步攻击后保持有害分数不超过2，而标准模型迅速恶化，从而为开源模型提供可行的安全保障，填补了RL攻击防御的空白。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.04578v1",
      "published_date": "2025-05-07 17:18:48 UTC",
      "updated_date": "2025-05-07 17:18:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:33:00.604203"
    },
    {
      "arxiv_id": "2505.04558v2",
      "title": "Purity Law for Generalizable Neural TSP Solvers",
      "title_zh": "翻译失败",
      "authors": [
        "Wenzhao Liu",
        "Haoran Li",
        "Congying Han",
        "Zicheng Zhang",
        "Anqi Li",
        "Tiande Guo"
      ],
      "abstract": "Achieving generalization in neural approaches across different scales and\ndistributions remains a significant challenge for the Traveling Salesman\nProblem~(TSP). A key obstacle is that neural networks often fail to learn\nrobust principles for identifying universal patterns and deriving optimal\nsolutions from diverse instances. In this paper, we first uncover Purity Law\n(PuLa), a fundamental structural principle for optimal TSP solutions, defining\nthat edge prevalence grows exponentially with the sparsity of surrounding\nvertices. Statistically validated across diverse instances, PuLa reveals a\nconsistent bias toward local sparsity in global optima. Building on this\ninsight, we propose Purity Policy Optimization~(PUPO), a novel training\nparadigm that explicitly aligns characteristics of neural solutions with PuLa\nduring the solution construction process to enhance generalization. Extensive\nexperiments demonstrate that PUPO can be seamlessly integrated with popular\nneural solvers, significantly enhancing their generalization performance\nwithout incurring additional computational overhead during inference.",
      "tldr_zh": "这篇论文针对神经网络在旅行商问题(TSP)上的泛化挑战，揭示了Purity Law(PuLa)，一个核心结构原则，即最优解中边的权重随周围顶点稀疏性的指数增长，并通过统计验证证明了其在多样实例中的一致性。基于此，作者提出Purity Policy Optimization(PUPO)，一种新型训练范式，能在求解过程中使神经网络的输出与PuLa对齐，从而显著提升泛化性能。实验结果显示，PUPO可无缝整合到流行神经求解器中，提高准确性而不增加推理时的计算开销。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.04558v2",
      "published_date": "2025-05-07 16:46:48 UTC",
      "updated_date": "2025-05-10 13:39:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:33:12.869790"
    },
    {
      "arxiv_id": "2505.04553v2",
      "title": "Risk-sensitive Reinforcement Learning Based on Convex Scoring Functions",
      "title_zh": "基于凸评分函数的风险敏感强化学习",
      "authors": [
        "Shanyu Han",
        "Yang Liu",
        "Xiang Yu"
      ],
      "abstract": "We propose a reinforcement learning (RL) framework under a broad class of\nrisk objectives, characterized by convex scoring functions. This class covers\nmany common risk measures, such as variance, Expected Shortfall, entropic\nValue-at-Risk, and mean-risk utility. To resolve the time-inconsistency issue,\nwe consider an augmented state space and an auxiliary variable and recast the\nproblem as a two-state optimization problem. We propose a customized\nActor-Critic algorithm and establish some theoretical approximation guarantees.\nA key theoretical contribution is that our results do not require the Markov\ndecision process to be continuous. Additionally, we propose an auxiliary\nvariable sampling method inspired by the alternating minimization algorithm,\nwhich is convergent under certain conditions. We validate our approach in\nsimulation experiments with a financial application in statistical arbitrage\ntrading, demonstrating the effectiveness of the algorithm.",
      "tldr_zh": "本文提出了一种基于凸评分函数的强化学习（Reinforcement Learning）框架，用于处理广泛的风险目标，包括variance、Expected Shortfall、entropic Value-at-Risk和mean-risk utility等问题。通过引入扩充的状态空间和辅助变量，该框架将原问题转化为两状态优化问题，并设计了定制的Actor-Critic算法，同时建立了理论近似保证，不依赖于连续的Markov决策过程。实验验证显示，该方法在金融应用如统计套利交易的模拟中表现出色，证明了其有效性和收敛性。",
      "categories": [
        "q-fin.MF",
        "cs.AI",
        "q-fin.RM"
      ],
      "primary_category": "q-fin.MF",
      "comment": "35 pages",
      "pdf_url": "http://arxiv.org/pdf/2505.04553v2",
      "published_date": "2025-05-07 16:31:42 UTC",
      "updated_date": "2025-05-15 10:40:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:33:23.897051"
    },
    {
      "arxiv_id": "2505.04539v1",
      "title": "Qualitative Analysis of $ω$-Regular Objectives on Robust MDPs",
      "title_zh": "翻译失败",
      "authors": [
        "Ali Asadi",
        "Krishnendu Chatterjee",
        "Ehsan Kafshdar Goharshady",
        "Mehrdad Karrabi",
        "Ali Shafiee"
      ],
      "abstract": "Robust Markov Decision Processes (RMDPs) generalize classical MDPs that\nconsider uncertainties in transition probabilities by defining a set of\npossible transition functions. An objective is a set of runs (or infinite\ntrajectories) of the RMDP, and the value for an objective is the maximal\nprobability that the agent can guarantee against the adversarial environment.\nWe consider (a) reachability objectives, where given a target set of states,\nthe goal is to eventually arrive at one of them; and (b) parity objectives,\nwhich are a canonical representation for $\\omega$-regular objectives. The\nqualitative analysis problem asks whether the objective can be ensured with\nprobability 1.\n  In this work, we study the qualitative problem for reachability and parity\nobjectives on RMDPs without making any assumption over the structures of the\nRMDPs, e.g., unichain or aperiodic. Our contributions are twofold. We first\npresent efficient algorithms with oracle access to uncertainty sets that solve\nqualitative problems of reachability and parity objectives. We then report\nexperimental results demonstrating the effectiveness of our oracle-based\napproach on classical RMDP examples from the literature scaling up to thousands\nof states.",
      "tldr_zh": "这篇论文研究了 Robust MDPs (RMDPs) 上 ω-regular objectives 的 qualitative analysis，针对 reachability objectives（到达目标状态）和 parity objectives（ω-regular objectives 的标准表示），旨在确定是否能以概率 1 确保这些目标，而不依赖 RMDPs 的特定结构，如 unichain 或 aperiodic。作者提出了高效算法，通过 oracle 访问不确定性集来解决这些 qualitative 问题。实验结果表明，该方法在文献中的经典 RMDP 示例上表现良好，可扩展到数千状态的规模。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.04539v1",
      "published_date": "2025-05-07 16:15:40 UTC",
      "updated_date": "2025-05-07 16:15:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:33:36.240642"
    },
    {
      "arxiv_id": "2505.04531v1",
      "title": "Overcoming Data Scarcity in Generative Language Modelling for Low-Resource Languages: A Systematic Review",
      "title_zh": "翻译失败",
      "authors": [
        "Josh McGiff",
        "Nikola S. Nikolov"
      ],
      "abstract": "Generative language modelling has surged in popularity with the emergence of\nservices such as ChatGPT and Google Gemini. While these models have\ndemonstrated transformative potential in productivity and communication, they\noverwhelmingly cater to high-resource languages like English. This has\namplified concerns over linguistic inequality in natural language processing\n(NLP). This paper presents the first systematic review focused specifically on\nstrategies to address data scarcity in generative language modelling for\nlow-resource languages (LRL). Drawing from 54 studies, we identify, categorise\nand evaluate technical approaches, including monolingual data augmentation,\nback-translation, multilingual training, and prompt engineering, across\ngenerative tasks. We also analyse trends in architecture choices, language\nfamily representation, and evaluation methods. Our findings highlight a strong\nreliance on transformer-based models, a concentration on a small subset of\nLRLs, and a lack of consistent evaluation across studies. We conclude with\nrecommendations for extending these methods to a wider range of LRLs and\noutline open challenges in building equitable generative language systems.\nUltimately, this review aims to support researchers and developers in building\ninclusive AI tools for underrepresented languages, a necessary step toward\nempowering LRL speakers and the preservation of linguistic diversity in a world\nincreasingly shaped by large-scale language technologies.",
      "tldr_zh": "这篇论文进行了一个系统性综述，针对低资源语言(LRL)中的数据稀缺问题，探讨了生成式语言建模(Generative Language Modelling)的策略，以缓解NLP领域的语言不平等。作者从54个研究中识别并评估了多种技术方法，包括monolingual data augmentation、back-translation、多语训练和prompt engineering，并分析了transformer-based models的流行趋势、语言家族表示和评估方法的不一致性。研究发现，目前方法主要集中在少数LRL上，缺乏统一评估标准。论文最终提供推荐，呼吁扩展这些策略到更多LRL，并强调构建包容性AI工具以支持语言多样性和LRL使用者的需求。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "This work is currently under review. Please do not cite without\n  permission",
      "pdf_url": "http://arxiv.org/pdf/2505.04531v1",
      "published_date": "2025-05-07 16:04:45 UTC",
      "updated_date": "2025-05-07 16:04:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:33:48.974340"
    },
    {
      "arxiv_id": "2505.04528v1",
      "title": "Beyond Theorem Proving: Formulation, Framework and Benchmark for Formal Problem-Solving",
      "title_zh": "翻译失败",
      "authors": [
        "Qi Liu",
        "Xinhao Zheng",
        "Renqiu Xia",
        "Xingzhi Qi",
        "Qinxiang Cao",
        "Junchi Yan"
      ],
      "abstract": "As a seemingly self-explanatory task, problem-solving has been a significant\ncomponent of science and engineering. However, a general yet concrete\nformulation of problem-solving itself is missing. With the recent development\nof AI-based problem-solving agents, the demand for process-level verifiability\nis rapidly increasing yet underexplored. To fill these gaps, we present a\nprincipled formulation of problem-solving as a deterministic Markov decision\nprocess; a novel framework, FPS (Formal Problem-Solving), which utilizes\nexisting FTP (formal theorem proving) environments to perform process-verified\nproblem-solving; and D-FPS (Deductive FPS), decoupling solving and answer\nverification for better human-alignment. The expressiveness, soundness and\ncompleteness of the frameworks are proven. We construct three benchmarks on\nproblem-solving: FormalMath500, a formalization of a subset of the MATH500\nbenchmark; MiniF2F-Solving and PutnamBench-Solving, adaptations of FTP\nbenchmarks MiniF2F and PutnamBench. For faithful, interpretable, and\nhuman-aligned evaluation, we propose RPE (Restricted Propositional\nEquivalence), a symbolic approach to determine the correctness of answers by\nformal verification. We evaluate four prevalent FTP models and two prompting\nmethods as baselines, solving at most 23.77% of FormalMath500, 27.47% of\nMiniF2F-Solving, and 0.31% of PutnamBench-Solving.",
      "tldr_zh": "该论文提出了问题解决的原理性表述，将其定义为一个确定性Markov decision process，以填补该领域缺乏通用框架的空白。作者引入了FPS框架，利用现有的FTP环境进行过程验证的问题解决，并开发了D-FPS框架，将解决过程与答案验证分离，以实现更好地human-alignment；框架的expressiveness、soundness和completeness均已证明。研究构建了三个基准：FormalMath500（MATH500的子集形式化）、MiniF2F-Solving和PutnamBench-Solving，并提出RPE（Restricted Propositional Equivalence）方法，通过形式验证评估答案正确性。实验评估显示，四种FTP模型和两种prompting方法在这些基准上的表现有限，最高解决率分别为23.77%、27.47%和0.31%。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LO"
      ],
      "primary_category": "cs.AI",
      "comment": "42 pages, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.04528v1",
      "published_date": "2025-05-07 16:02:14 UTC",
      "updated_date": "2025-05-07 16:02:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:34:01.478194"
    },
    {
      "arxiv_id": "2505.04526v1",
      "title": "DFVO: Learning Darkness-free Visible and Infrared Image Disentanglement and Fusion All at Once",
      "title_zh": "翻译失败",
      "authors": [
        "Qi Zhou",
        "Yukai Shi",
        "Xiaojun Yang",
        "Xiaoyu Xian",
        "Lunjia Liao",
        "Ruimao Zhang",
        "Liang Lin"
      ],
      "abstract": "Visible and infrared image fusion is one of the most crucial tasks in the\nfield of image fusion, aiming to generate fused images with clear structural\ninformation and high-quality texture features for high-level vision tasks.\nHowever, when faced with severe illumination degradation in visible images, the\nfusion results of existing image fusion methods often exhibit blurry and dim\nvisual effects, posing major challenges for autonomous driving. To this end, a\nDarkness-Free network is proposed to handle Visible and infrared image\ndisentanglement and fusion all at Once (DFVO), which employs a cascaded\nmulti-task approach to replace the traditional two-stage cascaded training\n(enhancement and fusion), addressing the issue of information entropy loss\ncaused by hierarchical data transmission. Specifically, we construct a\nlatent-common feature extractor (LCFE) to obtain latent features for the\ncascaded tasks strategy. Firstly, a details-extraction module (DEM) is devised\nto acquire high-frequency semantic information. Secondly, we design a hyper\ncross-attention module (HCAM) to extract low-frequency information and preserve\ntexture features from source images. Finally, a relevant loss function is\ndesigned to guide the holistic network learning, thereby achieving better image\nfusion. Extensive experiments demonstrate that our proposed approach\noutperforms state-of-the-art alternatives in terms of qualitative and\nquantitative evaluations. Particularly, DFVO can generate clearer, more\ninformative, and more evenly illuminated fusion results in the dark\nenvironments, achieving best performance on the LLVIP dataset with 63.258 dB\nPSNR and 0.724 CC, providing more effective information for high-level vision\ntasks. Our code is publicly accessible at https://github.com/DaVin-Qi530/DFVO.",
      "tldr_zh": "该研究提出 DFVO 网络，用于一次性处理可见光和红外图像的分离和融合，采用级联多任务方法来解决传统两阶段训练（增强和融合）导致的信息熵损失问题。\nDFVO 包括潜共特征提取器(LCFE)获取潜在特征、细节提取模块(DEM)提取高频语义信息，以及超交叉注意力模块(HCAM)保留低频纹理特征，并通过设计相关损失函数优化整体学习。\n实验结果显示，DFVO 在黑暗环境下生成更清晰、信息丰富且均匀照明的融合图像，在 LLVIP 数据集上达到 PSNR 63.258 dB 和 CC 0.724 的最佳性能，优于现有方法，并为高级视觉任务提供更有效的信息。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.04526v1",
      "published_date": "2025-05-07 15:59:45 UTC",
      "updated_date": "2025-05-07 15:59:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:34:15.346082"
    },
    {
      "arxiv_id": "2505.04525v1",
      "title": "On some improvements to Unbounded Minimax",
      "title_zh": "对 Unbounded Minimax 的一些改进",
      "authors": [
        "Quentin Cohen-Solal",
        "Tristan Cazenave"
      ],
      "abstract": "This paper presents the first experimental evaluation of four previously\nuntested modifications of Unbounded Best-First Minimax algorithm. This\nalgorithm explores the game tree by iteratively expanding the most promising\nsequences of actions based on the current partial game tree. We first evaluate\nthe use of transposition tables, which convert the game tree into a directed\nacyclic graph by merging duplicate states. Second, we compare the original\nalgorithm by Korf & Chickering with the variant proposed by Cohen-Solal, which\ndiffers in its backpropagation strategy: instead of stopping when a stable\nvalue is encountered, it updates values up to the root. This change slightly\nimproves performance when value ties or transposition tables are involved.\nThird, we assess replacing the exact terminal evaluation function with the\nlearned heuristic function. While beneficial when exact evaluations are costly,\nthis modification reduces performance in inexpensive settings. Finally, we\nexamine the impact of the completion technique that prioritizes resolved\nwinning states and avoids resolved losing states. This technique also improves\nperformance. Overall, our findings highlight how targeted modifications can\nenhance the efficiency of Unbounded Best-First Minimax.",
      "tldr_zh": "本论文首次对 Unbounded Best-First Minimax 算法进行了四种先前未测试改进的实验评估，这些改进旨在提升算法在游戏树探索中的效率。改进包括使用 transposition tables 将游戏树转换为 directed acyclic graph 以合并重复状态、采用 Cohen-Solal 的 backpropagation strategy 变体（继续更新到根节点以改善性能）、用 learned heuristic function 替换 exact terminal evaluation function（在评估成本高时有益但在低成本场景下降低性能），以及优先处理 resolved winning states 并避免 resolved losing states 的 completion technique。实验结果显示，transposition tables、Cohen-Solal 变体和 completion technique 均提高了算法性能，而总体发现强调了这些针对性修改对 Unbounded Best-First Minimax 效率的增强作用。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.04525v1",
      "published_date": "2025-05-07 15:59:19 UTC",
      "updated_date": "2025-05-07 15:59:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:34:24.412492"
    },
    {
      "arxiv_id": "2505.04497v2",
      "title": "Defining and Quantifying Creative Behavior in Popular Image Generators",
      "title_zh": "流行图像生成",
      "authors": [
        "Aditi Ramaswamy",
        "Hana Chockler",
        "Melane Navaratnarajah"
      ],
      "abstract": "Creativity of generative AI models has been a subject of scientific debate in\nthe last years, without a conclusive answer. In this paper, we study creativity\nfrom a practical perspective and introduce quantitative measures that help the\nuser to choose a suitable AI model for a given task. We evaluated our measures\non a number of popular image-to-image generation models, and the results of\nthis suggest that our measures conform to human intuition.",
      "tldr_zh": "本文定义并量化了流行图像生成模型的创造性行为，旨在从实用角度解决生成式 AI 模型创造力这一科学争论问题。研究引入了量化措施，帮助用户根据特定任务选择合适的模型，并对多种图像到图像生成模型进行了评估。结果表明，这些措施与人类直觉一致，为评估 AI 创造力提供了可操作的工具。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "I.4.m; I.2.m"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.04497v2",
      "published_date": "2025-05-07 15:20:17 UTC",
      "updated_date": "2025-05-08 11:59:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:34:34.930091"
    },
    {
      "arxiv_id": "2505.04493v1",
      "title": "Model-Based AI planning and Execution Systems for Robotics",
      "title_zh": "翻译失败",
      "authors": [
        "Or Wertheim",
        "Ronen I. Brafman"
      ],
      "abstract": "Model-based planning and execution systems offer a principled approach to\nbuilding flexible autonomous robots that can perform diverse tasks by\nautomatically combining a host of basic skills. This idea is almost as old as\nmodern robotics. Yet, while diverse general-purpose reasoning architectures\nhave been proposed since, general-purpose systems that are integrated with\nmodern robotic platforms have emerged only recently, starting with the\ninfluential ROSPlan system. Since then, a growing number of model-based systems\nfor robot task-level control have emerged. In this paper, we consider the\ndiverse design choices and issues existing systems attempt to address, the\ndifferent solutions proposed so far, and suggest avenues for future\ndevelopment.",
      "tldr_zh": "本论文探讨了基于模型的AI规划和执行系统(Model-based AI planning and execution systems)，这是一种构建灵活自治机器人的原则方法，能通过自动组合基本技能来执行多样化任务。论文回顾了从ROSPlan系统开始的各种通用系统设计选择、面临的问题（如系统整合挑战）和提出的解决方案，并强调这种方法在现代机器人平台中的新兴应用。未来发展建议包括进一步优化这些系统，以提升机器人任务级控制的效率和适应性。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.04493v1",
      "published_date": "2025-05-07 15:17:38 UTC",
      "updated_date": "2025-05-07 15:17:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:34:47.443810"
    },
    {
      "arxiv_id": "2505.04488v1",
      "title": "\"I Can See Forever!\": Evaluating Real-time VideoLLMs for Assisting Individuals with Visual Impairments",
      "title_zh": "翻译失败",
      "authors": [
        "Ziyi Zhang",
        "Zhen Sun",
        "Zongmin Zhang",
        "Zifan Peng",
        "Yuemeng Zhao",
        "Zichun Wang",
        "Zeren Luo",
        "Ruiting Zuo",
        "Xinlei He"
      ],
      "abstract": "The visually impaired population, especially the severely visually impaired,\nis currently large in scale, and daily activities pose significant challenges\nfor them. Although many studies use large language and vision-language models\nto assist the blind, most focus on static content and fail to meet real-time\nperception needs in dynamic and complex environments, such as daily activities.\nTo provide them with more effective intelligent assistance, it is imperative to\nincorporate advanced visual understanding technologies. Although real-time\nvision and speech interaction VideoLLMs demonstrate strong real-time visual\nunderstanding, no prior work has systematically evaluated their effectiveness\nin assisting visually impaired individuals. In this work, we conduct the first\nsuch evaluation. First, we construct a benchmark dataset (VisAssistDaily),\ncovering three categories of assistive tasks for visually impaired individuals:\nBasic Skills, Home Life Tasks, and Social Life Tasks. The results show that\nGPT-4o achieves the highest task success rate. Next, we conduct a user study to\nevaluate the models in both closed-world and open-world scenarios, further\nexploring the practical challenges of applying VideoLLMs in assistive contexts.\nOne key issue we identify is the difficulty current models face in perceiving\npotential hazards in dynamic environments. To address this, we build an\nenvironment-awareness dataset named SafeVid and introduce a polling mechanism\nthat enables the model to proactively detect environmental risks. We hope this\nwork provides valuable insights and inspiration for future research in this\nfield.",
      "tldr_zh": "本文评估了实时视频语言模型（VideoLLMs）在辅助视觉障碍者的有效性，这是首次系统研究，针对动态环境中的实时感知需求。研究构建了VisAssistDaily基准数据集，涵盖基本技能、家庭生活和社会生活任务，结果显示GPT-4o取得了最高的任务成功率。用户研究揭示了模型在开放场景中难以感知动态风险的问题，为此，作者创建了SafeVid环境感知数据集并引入轮询机制，以主动检测潜在危险。该工作为未来智能辅助技术提供了重要见解。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.HC",
        "cs.MM"
      ],
      "primary_category": "cs.CV",
      "comment": "12 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.04488v1",
      "published_date": "2025-05-07 15:03:16 UTC",
      "updated_date": "2025-05-07 15:03:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:35:00.905271"
    },
    {
      "arxiv_id": "2505.04486v1",
      "title": "Efficient Flow Matching using Latent Variables",
      "title_zh": "翻译失败",
      "authors": [
        "Anirban Samaddar",
        "Yixuan Sun",
        "Viktor Nilsson",
        "Sandeep Madireddy"
      ],
      "abstract": "Flow matching models have shown great potential in image generation tasks\namong probabilistic generative models. Building upon the ideas of continuous\nnormalizing flows, flow matching models generalize the transport path of the\ndiffusion models from a simple prior distribution to the data. Most flow\nmatching models in the literature do not explicitly model the underlying\nstructure/manifold in the target data when learning the flow from a simple\nsource distribution like the standard Gaussian. This leads to inefficient\nlearning, especially for many high-dimensional real-world datasets, which often\nreside in a low-dimensional manifold. Existing strategies of incorporating\nmanifolds, including data with underlying multi-modal distribution, often\nrequire expensive training and hence frequently lead to suboptimal performance.\nTo this end, we present \\texttt{Latent-CFM}, which provides simplified\ntraining/inference strategies to incorporate multi-modal data structures using\npretrained deep latent variable models. Through experiments on multi-modal\nsynthetic data and widely used image benchmark datasets, we show that\n\\texttt{Latent-CFM} exhibits improved generation quality with significantly\nless training ($\\sim 50\\%$ less in some cases) and computation than\nstate-of-the-art flow matching models. Using a 2d Darcy flow dataset, we\ndemonstrate that our approach generates more physically accurate samples than\ncompetitive approaches. In addition, through latent space analysis, we\ndemonstrate that our approach can be used for conditional image generation\nconditioned on latent features.",
      "tldr_zh": "本文提出Latent-CFM，一种高效的流匹配(Flow Matching)方法，通过整合预训练的深度潜在变量模型来显式处理目标数据的底层流形和多模态结构，从而简化训练和推理过程。相较于现有模型，Latent-CFM 在多模态合成数据和图像基准数据集上显著提升生成质量，同时减少约50%的训练和计算资源，并在2d Darcy流数据集上生成更物理准确的样本。实验还证明，该方法支持基于潜在特征的条件图像生成，提供了一种更高效的图像生成框架。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.04486v1",
      "published_date": "2025-05-07 14:59:23 UTC",
      "updated_date": "2025-05-07 14:59:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:35:12.422959"
    },
    {
      "arxiv_id": "2505.04480v1",
      "title": "TrajEvo: Designing Trajectory Prediction Heuristics via LLM-driven Evolution",
      "title_zh": "TrajEvo：通过LLM驱动的进化设计轨迹预测启发式方法",
      "authors": [
        "Zhikai Zhao",
        "Chuanbo Hua",
        "Federico Berto",
        "Kanghoon Lee",
        "Zihan Ma",
        "Jiachen Li",
        "Jinkyoo Park"
      ],
      "abstract": "Trajectory prediction is a crucial task in modeling human behavior,\nespecially in fields as social robotics and autonomous vehicle navigation.\nTraditional heuristics based on handcrafted rules often lack accuracy, while\nrecently proposed deep learning approaches suffer from computational cost, lack\nof explainability, and generalization issues that limit their practical\nadoption. In this paper, we introduce TrajEvo, a framework that leverages Large\nLanguage Models (LLMs) to automatically design trajectory prediction\nheuristics. TrajEvo employs an evolutionary algorithm to generate and refine\nprediction heuristics from past trajectory data. We introduce a\nCross-Generation Elite Sampling to promote population diversity and a\nStatistics Feedback Loop allowing the LLM to analyze alternative predictions.\nOur evaluations show TrajEvo outperforms previous heuristic methods on the\nETH-UCY datasets, and remarkably outperforms both heuristics and deep learning\nmethods when generalizing to the unseen SDD dataset. TrajEvo represents a first\nstep toward automated design of fast, explainable, and generalizable trajectory\nprediction heuristics. We make our source code publicly available to foster\nfuture research at https://github.com/ai4co/trajevo.",
      "tldr_zh": "论文提出 TrajEvo 框架，利用大型语言模型 (LLMs) 驱动的进化算法，从历史轨迹数据自动设计轨迹预测启发式，以克服传统手工规则的准确性不足和深度学习方法的计算成本高、可解释性差等问题。TrajEvo 引入 Cross-Generation Elite Sampling 来提升种群多样性，以及 Statistics Feedback Loop 让 LLMs 分析备选预测，从而生成更高效的启发式策略。实验结果显示，该框架在 ETH-UCY 数据集上优于现有启发式方法，并在未见数据集 SDD 上显著超越深度学习方法，提供了一种快速、可解释且可泛化的轨迹预测新途径。源代码已公开，以促进进一步研究。",
      "categories": [
        "cs.AI",
        "cs.NE",
        "cs.RO"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.04480v1",
      "published_date": "2025-05-07 14:51:43 UTC",
      "updated_date": "2025-05-07 14:51:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:35:25.899096"
    },
    {
      "arxiv_id": "2505.05516v1",
      "title": "AI-powered virtual eye: perspective, challenges and opportunities",
      "title_zh": "AI驱动的虚拟眼睛：视角、挑战和机会",
      "authors": [
        "Yue Wu",
        "Yibo Guo",
        "Yulong Yan",
        "Jiancheng Yang",
        "Xin Zhou",
        "Ching-Yu Cheng",
        "Danli Shi",
        "Mingguang He"
      ],
      "abstract": "We envision the \"virtual eye\" as a next-generation, AI-powered platform that\nuses interconnected foundation models to simulate the eye's intricate structure\nand biological function across all scales. Advances in AI, imaging, and\nmultiomics provide a fertile ground for constructing a universal, high-fidelity\ndigital replica of the human eye. This perspective traces the evolution from\nearly mechanistic and rule-based models to contemporary AI-driven approaches,\nintegrating in a unified model with multimodal, multiscale, dynamic predictive\ncapabilities and embedded feedback mechanisms. We propose a development roadmap\nemphasizing the roles of large-scale multimodal datasets, generative AI,\nfoundation models, agent-based architectures, and interactive interfaces.\nDespite challenges in interpretability, ethics, data processing and evaluation,\nthe virtual eye holds the potential to revolutionize personalized ophthalmic\ncare and accelerate research into ocular health and disease.",
      "tldr_zh": "本论文提出“AI-powered virtual eye”概念，这是一个基于互连基础模型的下一代平台，用于模拟人眼的复杂结构和生物功能，涵盖多尺度动态预测和反馈机制。通过回顾从早期机制模型到现代AI方法的演变，该研究强调利用大型多模态数据集、生成AI、基础模型和代理架构来构建高保真数字眼部模型。尽管面临解释性、伦理、数据处理和评估等挑战，这种平台有望革新个性化眼科护理并加速眼部健康与疾病研究。",
      "categories": [
        "q-bio.TO",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "q-bio.TO",
      "comment": "30 Pages, 3 figures, 1 table",
      "pdf_url": "http://arxiv.org/pdf/2505.05516v1",
      "published_date": "2025-05-07 14:48:56 UTC",
      "updated_date": "2025-05-07 14:48:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:35:35.747680"
    },
    {
      "arxiv_id": "2505.04468v1",
      "title": "Spectral and Temporal Denoising for Differentially Private Optimization",
      "title_zh": "光谱和时域去噪用于差异隐私优化",
      "authors": [
        "Hyeju Shin",
        "Kyudan Jung",
        "Seongwon Yun",
        "Juyoung Yun"
      ],
      "abstract": "This paper introduces the FFT-Enhanced Kalman Filter (FFTKF), a\ndifferentially private optimization method that addresses the challenge of\npreserving performance in DP-SGD, where added noise typically degrades model\nutility. FFTKF integrates frequency-domain noise shaping with Kalman filtering\nto enhance gradient quality while preserving $(\\varepsilon, \\delta)$-DP\nguarantees. It employs a high-frequency shaping mask in the Fourier domain to\nconcentrate differential privacy noise in less informative spectral components,\npreserving low-frequency gradient signals. A scalar-gain Kalman filter with\nfinite-difference Hessian approximation further refines the denoised gradients.\nWith a per-iteration complexity of $\\mathcal{O}(d \\log d)$, FFTKF demonstrates\nimproved test accuracy over DP-SGD and DiSK across MNIST, CIFAR-10, CIFAR-100,\nand Tiny-ImageNet datasets using CNNs, Wide ResNets, and Vision Transformers.\nTheoretical analysis confirms that FFTKF maintains equivalent privacy\nguarantees while achieving a tighter privacy-utility trade-off through reduced\nnoise and controlled bias.",
      "tldr_zh": "这篇论文引入了 FFT-Enhanced Kalman Filter (FFTKF)，一种差分隐私优化方法，旨在缓解 DP-SGD 中添加噪声导致的模型性能下降问题。FFTKF 通过在傅立叶域应用高频噪声整形掩码来集中差分隐私噪声于不重要的光谱成分，同时结合标量增益 Kalman 过滤器和有限差分 Hessian 近似来细化梯度，每迭代复杂度为 $\\mathcal{O}(d \\log d)$。实验结果显示，在 MNIST、CIFAR-10、CIFAR-100 和 Tiny-ImageNet 数据集上，使用 CNNs、Wide ResNets 和 Vision Transformers 时，FFTKF 比 DP-SGD 和 DiSK 显著提高了测试准确率。理论分析确认，FFTKF 保持了等价的 $(\\varepsilon, \\delta)$-DP 保证，同时通过减少噪声和控制偏差实现了更好的隐私-实用性权衡。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.IT",
        "cs.NE",
        "math.IT"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.04468v1",
      "published_date": "2025-05-07 14:38:58 UTC",
      "updated_date": "2025-05-07 14:38:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:35:49.766339"
    },
    {
      "arxiv_id": "2505.04464v1",
      "title": "Discriminative Ordering Through Ensemble Consensus",
      "title_zh": "翻译失败",
      "authors": [
        "Louis Ohl",
        "Fredrik Lindsten"
      ],
      "abstract": "Evaluating the performance of clustering models is a challenging task where\nthe outcome depends on the definition of what constitutes a cluster. Due to\nthis design, current existing metrics rarely handle multiple clustering models\nwith diverse cluster definitions, nor do they comply with the integration of\nconstraints when available. In this work, we take inspiration from consensus\nclustering and assume that a set of clustering models is able to uncover hidden\nstructures in the data. We propose to construct a discriminative ordering\nthrough ensemble clustering based on the distance between the connectivity of a\nclustering model and the consensus matrix. We first validate the proposed\nmethod with synthetic scenarios, highlighting that the proposed score ranks the\nmodels that best match the consensus first. We then show that this simple\nranking score significantly outperforms other scoring methods when comparing\nsets of different clustering algorithms that are not restricted to a fixed\nnumber of clusters and is compatible with clustering constraints.",
      "tldr_zh": "本文提出了一种通过集成共识（ensemble consensus）构建判别排序（discriminative ordering）的方法，用于评估聚类模型的性能，以解决现有指标难以处理多种聚类定义和约束的问题。该方法基于聚类模型的连通性（connectivity）和共识矩阵（consensus matrix）之间的距离，假设一组聚类模型能揭示数据中的隐藏结构。在合成场景中验证表明，该评分能优先排名与共识匹配度高的模型；与其他评分方法相比，它在比较不同聚类算法（不限于固定簇数）时显著优越，并兼容聚类约束（clustering constraints）。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "62H30",
        "G.3"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at UAI 2025",
      "pdf_url": "http://arxiv.org/pdf/2505.04464v1",
      "published_date": "2025-05-07 14:35:39 UTC",
      "updated_date": "2025-05-07 14:35:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:36:01.438853"
    },
    {
      "arxiv_id": "2505.04461v1",
      "title": "A Survey on Temporal Interaction Graph Representation Learning: Progress, Challenges, and Opportunities",
      "title_zh": "翻译失败",
      "authors": [
        "Pengfei Jiao",
        "Hongjiang Chen",
        "Xuan Guo",
        "Zhidong Zhao",
        "Dongxiao He",
        "Di Jin"
      ],
      "abstract": "Temporal interaction graphs (TIGs), defined by sequences of timestamped\ninteraction events, have become ubiquitous in real-world applications due to\ntheir capability to model complex dynamic system behaviors. As a result,\ntemporal interaction graph representation learning (TIGRL) has garnered\nsignificant attention in recent years. TIGRL aims to embed nodes in TIGs into\nlow-dimensional representations that effectively preserve both structural and\ntemporal information, thereby enhancing the performance of downstream tasks\nsuch as classification, prediction, and clustering within constantly evolving\ndata environments. In this paper, we begin by introducing the foundational\nconcepts of TIGs and emphasize the critical role of temporal dependencies. We\nthen propose a comprehensive taxonomy of state-of-the-art TIGRL methods,\nsystematically categorizing them based on the types of information utilized\nduring the learning process to address the unique challenges inherent to TIGs.\nTo facilitate further research and practical applications, we curate the source\nof datasets and benchmarks, providing valuable resources for empirical\ninvestigations. Finally, we examine key open challenges and explore promising\nresearch directions in TIGRL, laying the groundwork for future advancements\nthat have the potential to shape the evolution of this field.",
      "tldr_zh": "这篇调查论文探讨了Temporal Interaction Graphs (TIGs)，这些图由时间戳的交互事件序列组成，用于建模复杂动态系统行为，并强调了Temporal Interaction Graph Representation Learning (TIGRL)在嵌入节点表示方面的作用，以保留结构和时间信息，从而提升下游任务如分类、预测和聚类的性能。论文提出一个全面的TIGRL方法分类体系，根据学习过程中利用的信息类型系统地整理了现有方法，以应对TIGs的独特挑战。作者还整理了数据集和基准资源，并分析了关键开放挑战及未来研究方向，为该领域的发展奠定基础。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.SI"
      ],
      "primary_category": "cs.LG",
      "comment": "IJCAI 2025 Survey Track",
      "pdf_url": "http://arxiv.org/pdf/2505.04461v1",
      "published_date": "2025-05-07 14:31:10 UTC",
      "updated_date": "2025-05-07 14:31:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:36:11.794031"
    },
    {
      "arxiv_id": "2505.04451v1",
      "title": "Automatic Music Transcription using Convolutional Neural Networks and Constant-Q transform",
      "title_zh": "翻译失败",
      "authors": [
        "Yohannis Telila",
        "Tommaso Cucinotta",
        "Davide Bacciu"
      ],
      "abstract": "Automatic music transcription (AMT) is the problem of analyzing an audio\nrecording of a musical piece and detecting notes that are being played. AMT is\na challenging problem, particularly when it comes to polyphonic music. The goal\nof AMT is to produce a score representation of a music piece, by analyzing a\nsound signal containing multiple notes played simultaneously. In this work, we\ndesign a processing pipeline that can transform classical piano audio files in\n.wav format into a music score representation. The features from the audio\nsignals are extracted using the constant-Q transform, and the resulting\ncoefficients are used as an input to the convolutional neural network (CNN)\nmodel.",
      "tldr_zh": "该论文探讨了 Automatic Music Transcription (AMT) 的问题，即从音频录音中检测并生成音乐曲谱表示，尤其针对多声部音乐的挑战。研究设计了一个处理管道，使用 Constant-Q transform 提取音频信号特征，并将这些系数作为输入喂入 Convolutional Neural Networks (CNN) 模型。最终，该方法能够将经典钢琴音频文件（如 .wav 格式）转化为音乐分数表示，提高了音乐转录的准确性和可行性。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.LG",
        "cs.MM",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "6 pages",
      "pdf_url": "http://arxiv.org/pdf/2505.04451v1",
      "published_date": "2025-05-07 14:20:43 UTC",
      "updated_date": "2025-05-07 14:20:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:36:24.707251"
    },
    {
      "arxiv_id": "2505.04435v1",
      "title": "FedBWO: Enhancing Communication Efficiency in Federated Learning",
      "title_zh": "FedBWO：增强联邦学习中的通信效率",
      "authors": [
        "Vahideh Hayyolalam",
        "Öznur Özkasap"
      ],
      "abstract": "Federated Learning (FL) is a distributed Machine Learning (ML) setup, where a\nshared model is collaboratively trained by various clients using their local\ndatasets while keeping the data private. Considering resource-constrained\ndevices, FL clients often suffer from restricted transmission capacity. Aiming\nto enhance the system performance, the communication between clients and server\nneeds to be diminished. Current FL strategies transmit a tremendous amount of\ndata (model weights) within the FL process, which needs a high communication\nbandwidth. Considering resource constraints, increasing the number of clients\nand, consequently, the amount of data (model weights) can lead to a bottleneck.\nIn this paper, we introduce the Federated Black Widow Optimization (FedBWO)\ntechnique to decrease the amount of transmitted data by transmitting only a\nperformance score rather than the local model weights from clients. FedBWO\nemploys the BWO algorithm to improve local model updates. The conducted\nexperiments prove that FedBWO remarkably improves the performance of the global\nmodel and the communication efficiency of the overall system. According to the\nexperimental outcomes, FedBWO enhances the global model accuracy by an average\nof 21% over FedAvg, and 12% over FedGWO. Furthermore, FedBWO dramatically\ndecreases the communication cost compared to other methods.",
      "tldr_zh": "该研究针对联邦学习（Federated Learning, FL）中资源受限设备面临的通信效率问题，提出了一种名为 FedBWO 的新方法，以减少客户端与服务器之间的数据传输量。FedBWO 仅传输性能分数而非完整的本地模型权重，并利用 Black Widow Optimization (BWO) 算法来优化本地模型更新，从而显著降低通信带宽需求。实验结果显示，FedBWO 比 FedAvg 提高了平均 21% 的全局模型准确率，比 FedGWO 提高了 12%，并大幅减少了整体通信成本。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "5th IEEE International Conference on Human-Machine Systems, Abu\n  Dhabi, UAE, 26-28 May 2025",
      "pdf_url": "http://arxiv.org/pdf/2505.04435v1",
      "published_date": "2025-05-07 14:02:35 UTC",
      "updated_date": "2025-05-07 14:02:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:36:36.036947"
    },
    {
      "arxiv_id": "2505.04419v1",
      "title": "Recognizing Ornaments in Vocal Indian Art Music with Active Annotation",
      "title_zh": "翻译失败",
      "authors": [
        "Sumit Kumar",
        "Parampreet Singh",
        "Vipul Arora"
      ],
      "abstract": "Ornamentations, embellishments, or microtonal inflections are essential to\nmelodic expression across many musical traditions, adding depth, nuance, and\nemotional impact to performances. Recognizing ornamentations in singing voices\nis key to MIR, with potential applications in music pedagogy, singer\nidentification, genre classification, and controlled singing voice generation.\nHowever, the lack of annotated datasets and specialized modeling approaches\nremains a major obstacle for progress in this research area. In this work, we\nintroduce R\\=aga Ornamentation Detection (ROD), a novel dataset comprising\nIndian classical music recordings curated by expert musicians. The dataset is\nannotated using a custom Human-in-the-Loop tool for six vocal ornaments marked\nas event-based labels. Using this dataset, we develop an ornamentation\ndetection model based on deep time-series analysis, preserving ornament\nboundaries during the chunking of long audio recordings. We conduct experiments\nusing different train-test configurations within the ROD dataset and also\nevaluate our approach on a separate, manually annotated dataset of Indian\nclassical concert recordings. Our experimental results support the superior\nperformance of our proposed approach over the baseline CRNN.",
      "tldr_zh": "这篇论文针对印度艺术音乐中 vocal ornaments（装饰音）的识别问题，强调了这些微调音调在音乐表达中的重要性，但指出缺乏标注数据集和专业建模方法是主要障碍。研究者引入了 Raga Ornamentation Detection (ROD) 数据集，由专家音乐家整理的印度古典音乐录音，并使用 Human-in-the-Loop 工具标注了六种 vocal ornaments 作为事件-based 标签。基于此，他们开发了一个基于深度时间序列分析的检测模型，能够在处理长音频时保留 ornament 边界。实验结果显示，该方法在 ROD 数据集的不同训练测试配置以及另一个手动标注的数据集上，表现优于基线 CRNN 模型。",
      "categories": [
        "eess.AS",
        "cs.AI",
        "cs.LG",
        "cs.SD"
      ],
      "primary_category": "eess.AS",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.04419v1",
      "published_date": "2025-05-07 13:52:50 UTC",
      "updated_date": "2025-05-07 13:52:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:36:50.528745"
    },
    {
      "arxiv_id": "2505.04416v1",
      "title": "OBLIVIATE: Robust and Practical Machine Unlearning for Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Xiaoyu Xu",
        "Minxin Du",
        "Qingqing Ye",
        "Haibo Hu"
      ],
      "abstract": "Large language models (LLMs) trained over extensive corpora risk memorizing\nsensitive, copyrighted, or toxic content. To address this, we propose\nOBLIVIATE, a robust unlearning framework that removes targeted data while\npreserving model utility. The framework follows a structured process:\nextracting target tokens, building retain sets, and fine-tuning with a tailored\nloss function comprising three components -- masking, distillation, and world\nfact. Using low-rank adapters (LoRA), it ensures efficiency without\ncompromising unlearning quality. We conduct experiments on multiple datasets,\nincluding the Harry Potter series, WMDP, and TOFU, using a comprehensive suite\nof metrics: forget quality (new document-level memorization score), model\nutility, and fluency. Results demonstrate its effectiveness in resisting\nmembership inference attacks, minimizing the impact on retained data, and\nmaintaining robustness across diverse scenarios.",
      "tldr_zh": "该研究提出 OBLIVIATE，一种稳健且实用的机器无学习框架，用于从大型语言模型（LLMs）中移除敏感、版权或有毒内容，同时保持模型效用。框架采用结构化过程，包括提取目标标记、构建保留集，以及使用包含 masking、distillation 和 world fact 的定制损失函数进行微调，并通过低秩适配器（LoRA）实现高效优化。在多个数据集（如 Harry Potter 系列、WMDP 和 TOFU）上的实验显示，OBLIVIATE 有效抵抗成员推理攻击，显著提升遗忘质量，同时最小化对保留数据的影响和模型流畅性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CR",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "18 pages, 2 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.04416v1",
      "published_date": "2025-05-07 13:51:42 UTC",
      "updated_date": "2025-05-07 13:51:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:37:01.189451"
    },
    {
      "arxiv_id": "2505.04406v1",
      "title": "YABLoCo: Yet Another Benchmark for Long Context Code Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Aidar Valeev",
        "Roman Garaev",
        "Vadim Lomshakov",
        "Irina Piontkovskaya",
        "Vladimir Ivanov",
        "Israel Adewuyi"
      ],
      "abstract": "Large Language Models demonstrate the ability to solve various programming\ntasks, including code generation. Typically, the performance of LLMs is\nmeasured on benchmarks with small or medium-sized context windows of thousands\nof lines of code. At the same time, in real-world software projects,\nrepositories can span up to millions of LoC. This paper closes this gap by\ncontributing to the long context code generation benchmark (YABLoCo). The\nbenchmark featured a test set of 215 functions selected from four large\nrepositories with thousands of functions. The dataset contained metadata of\nfunctions, contexts of the functions with different levels of dependencies,\ndocstrings, functions bodies, and call graphs for each repository. This paper\npresents three key aspects of the contribution. First, the benchmark aims at\nfunction body generation in large repositories in C and C++, two languages not\ncovered by previous benchmarks. Second, the benchmark contains large\nrepositories from 200K to 2,000K LoC. Third, we contribute a scalable\nevaluation pipeline for efficient computing of the target metrics and a tool\nfor visual analysis of generated code. Overall, these three aspects allow for\nevaluating code generation in large repositories in C and C++.",
      "tldr_zh": "该论文引入了YABLoCo基准测试，用于评估大型语言模型(LLMs)在长上下文代码生成中的性能，针对现实软件项目中数百万行代码(LoC)的场景。YABLoCo包括从四个大型仓库中选出的215个函数测试集，涵盖函数元数据、不同依赖级别的上下文、文档字符串、函数体和调用图，专注于C和C++语言，这些语言此前未被类似基准覆盖。贡献包括处理20万至200万LoC的大型仓库、提供可扩展的评估管道以高效计算指标，并附带代码可视化分析工具，从而提升对大规模代码生成任务的评估准确性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.SE"
      ],
      "primary_category": "cs.CL",
      "comment": "Presented at LLM4Code 2025 Workshop co-located wtih ICSE 2025",
      "pdf_url": "http://arxiv.org/pdf/2505.04406v1",
      "published_date": "2025-05-07 13:42:23 UTC",
      "updated_date": "2025-05-07 13:42:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:37:12.639838"
    },
    {
      "arxiv_id": "2505.04405v1",
      "title": "High-speed multiwavelength photonic temporal integration using silicon photonics",
      "title_zh": "翻译失败",
      "authors": [
        "Yi Zhang",
        "Nikolaos Farmakidis",
        "Ioannis Roumpos",
        "Miltiadis Moralis-Pegios",
        "Apostolos Tsakyridis",
        "June Sang Lee",
        "Bowei Dong",
        "Yuhan He",
        "Samarth Aggarwal",
        "Nikolaos Pleros",
        "Harish Bhaskaran"
      ],
      "abstract": "Optical systems have been pivotal for energy-efficient computing, performing\nhigh-speed, parallel operations in low-loss carriers. While these predominantly\nanalog optical accelerators bypass digitization to perform parallel\nfloating-point computations, scaling optical hardware to map large-vector sizes\nfor AI tasks remains challenging. Here, we overcome this limitation by\nunfolding scalar operations in time and introducing a\nphotonic-heater-in-lightpath (PHIL) unit for all-optical temporal integration.\nCounterintuitively, we exploit a slow heat dissipation process to integrate\noptical signals modulated at 50 GHz bridging the speed gap between the widely\napplied thermo-optic effects and ultrafast photonics. This architecture\nsupports optical end-to-end signal processing, eliminates inefficient\nelectro-optical conversions, and enables both linear and nonlinear operations\nwithin a unified framework. Our results demonstrate a scalable path towards\nhigh-speed photonic computing through thermally driven integration.",
      "tldr_zh": "该论文提出了一种基于 silicon photonics 的高速度多波长光子时域积分方法，以解决光学硬件在扩展到大向量 AI 任务时的挑战。研究引入 photonic-heater-in-lightpath (PHIL) 单位，利用慢热的 thermo-optic effects 来整合 50 GHz 调制的光学信号，从而桥接热光效应与超快光子的速度差距。该框架支持光端到端信号处理，消除电光转换的低效性，并实现线性与非线性操作；实验结果展示了通过热驱动积分实现可扩展的高速光子计算路径。",
      "categories": [
        "physics.optics",
        "cs.AI",
        "physics.app-ph"
      ],
      "primary_category": "physics.optics",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.04405v1",
      "published_date": "2025-05-07 13:39:18 UTC",
      "updated_date": "2025-05-07 13:39:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:37:24.654038"
    },
    {
      "arxiv_id": "2505.04404v2",
      "title": "In-Context Adaptation to Concept Drift for Learned Database Operations",
      "title_zh": "翻译失败",
      "authors": [
        "Jiaqi Zhu",
        "Shaofeng Cai",
        "Yanyan Shen",
        "Gang Chen",
        "Fang Deng",
        "Beng Chin Ooi"
      ],
      "abstract": "Machine learning has demonstrated transformative potential for database\noperations, such as query optimization and in-database data analytics. However,\ndynamic database environments, characterized by frequent updates and evolving\ndata distributions, introduce concept drift, which leads to performance\ndegradation for learned models and limits their practical applicability.\nAddressing this challenge requires efficient frameworks capable of adapting to\nshifting concepts while minimizing the overhead of retraining or fine-tuning.\n  In this paper, we propose FLAIR, an online adaptation framework that\nintroduces a new paradigm called \\textit{in-context adaptation} for learned\ndatabase operations. FLAIR leverages the inherent property of data systems,\ni.e., immediate availability of execution results for predictions, to enable\ndynamic context construction. By formalizing adaptation as $f:(\\mathbf{x} \\,|\n\\,C_t) \\to \\mathbf{y}$, with $C_t$ representing a dynamic context memory, FLAIR\ndelivers predictions aligned with the current concept, eliminating the need for\nruntime parameter optimization. To achieve this, FLAIR integrates two key\nmodules: a Task Featurization Module for encoding task-specific features into\nstandardized representations, and a Dynamic Decision Engine, pre-trained via\nBayesian meta-training, to adapt seamlessly using contextual information at\nruntime. Extensive experiments across key database tasks demonstrate that FLAIR\noutperforms state-of-the-art baselines, achieving up to 5.2x faster adaptation\nand reducing error by 22.5% for cardinality estimation.",
      "tldr_zh": "该论文探讨了机器学习在数据库操作（如查询优化和数据分析）中的应用，但概念漂移（concept drift）会导致模型性能下降。作者提出 FLAIR 框架，引入 in-context adaptation 范式，通过动态上下文构建（f: (x | C_t) → y）利用预测结果的即时可用性，实现高效适应，而无需运行时参数优化。FLAIR 整合了 Task Featurization Module 用于任务特征标准化，以及通过 Bayesian meta-training 预训练的 Dynamic Decision Engine，以无缝处理漂移。实验结果显示，FLAIR 在关键数据库任务上比现有基准快 5.2 倍，并将错误率降低 22.5%。",
      "categories": [
        "cs.DB",
        "cs.AI"
      ],
      "primary_category": "cs.DB",
      "comment": "Accepted by ICML 2025",
      "pdf_url": "http://arxiv.org/pdf/2505.04404v2",
      "published_date": "2025-05-07 13:36:59 UTC",
      "updated_date": "2025-05-22 06:16:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:37:36.553511"
    },
    {
      "arxiv_id": "2505.04397v1",
      "title": "Deep residual learning with product units",
      "title_zh": "使用乘积单元的深度残差学习",
      "authors": [
        "Ziyuan Li",
        "Uwe Jaekel",
        "Babette Dellen"
      ],
      "abstract": "We propose a deep product-unit residual neural network (PURe) that integrates\nproduct units into residual blocks to improve the expressiveness and parameter\nefficiency of deep convolutional networks. Unlike standard summation neurons,\nproduct units enable multiplicative feature interactions, potentially offering\na more powerful representation of complex patterns. PURe replaces conventional\nconvolutional layers with 2D product units in the second layer of each residual\nblock, eliminating nonlinear activation functions to preserve structural\ninformation. We validate PURe on three benchmark datasets. On Galaxy10 DECaLS,\nPURe34 achieves the highest test accuracy of 84.89%, surpassing the much deeper\nResNet152, while converging nearly five times faster and demonstrating strong\nrobustness to Poisson noise. On ImageNet, PURe architectures outperform\nstandard ResNet models at similar depths, with PURe34 achieving a top-1\naccuracy of 80.27% and top-5 accuracy of 95.78%, surpassing deeper ResNet\nvariants (ResNet50, ResNet101) while utilizing significantly fewer parameters\nand computational resources. On CIFAR-10, PURe consistently outperforms ResNet\nvariants across varying depths, with PURe272 reaching 95.01% test accuracy,\ncomparable to ResNet1001 but at less than half the model size. These results\ndemonstrate that PURe achieves a favorable balance between accuracy,\nefficiency, and robustness. Compared to traditional residual networks, PURe not\nonly achieves competitive classification performance with faster convergence\nand fewer parameters, but also demonstrates greater robustness to noise. Its\neffectiveness across diverse datasets highlights the potential of\nproduct-unit-based architectures for scalable and reliable deep learning in\ncomputer vision.",
      "tldr_zh": "该研究提出了一种深层产品单元残差神经网络(PURe)，通过在残差块中集成产品单元实现特征的乘法交互，提高了深度卷积网络的表达能力和参数效率，同时去除非线性激活函数以保留结构信息。在三个基准数据集上验证结果显示，PURe34 在 Galaxy10 DECaLS 上达到 84.89% 测试准确率，优于更深的 ResNet152，且收敛速度快五倍；在 ImageNet 上，PURe34 的 top-1 准确率达 80.27%，超越 ResNet50 和 ResNet101，使用更少参数；在 CIFAR-10 上，PURe272 达到 95.01% 测试准确率，比 ResNet1001 小一半。总体而言，PURe 实现了准确性、效率和噪声鲁棒性的良好平衡，为计算机视觉中的可扩展深度学习提供了新潜力。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "eess.IV"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.04397v1",
      "published_date": "2025-05-07 13:21:25 UTC",
      "updated_date": "2025-05-07 13:21:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:37:50.872496"
    },
    {
      "arxiv_id": "2505.04388v1",
      "title": "The Aloe Family Recipe for Open and Specialized Healthcare LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Dario Garcia-Gasulla",
        "Jordi Bayarri-Planas",
        "Ashwin Kumar Gururajan",
        "Enrique Lopez-Cuena",
        "Adrian Tormos",
        "Daniel Hinjos",
        "Pablo Bernabeu-Perez",
        "Anna Arias-Duart",
        "Pablo Agustin Martin-Torres",
        "Marta Gonzalez-Mallo",
        "Sergio Alvarez-Napagao",
        "Eduard Ayguadé-Parra",
        "Ulises Cortés"
      ],
      "abstract": "Purpose: With advancements in Large Language Models (LLMs) for healthcare,\nthe need arises for competitive open-source models to protect the public\ninterest. This work contributes to the field of open medical LLMs by optimizing\nkey stages of data preprocessing and training, while showing how to improve\nmodel safety (through DPO) and efficacy (through RAG). The evaluation\nmethodology used, which includes four different types of tests, defines a new\nstandard for the field. The resultant models, shown to be competitive with the\nbest private alternatives, are released with a permisive license.\n  Methods: Building on top of strong base models like Llama 3.1 and Qwen 2.5,\nAloe Beta uses a custom dataset to enhance public data with synthetic Chain of\nThought examples. The models undergo alignment with Direct Preference\nOptimization, emphasizing ethical and policy-aligned performance in the\npresence of jailbreaking attacks. Evaluation includes close-ended, open-ended,\nsafety and human assessments, to maximize the reliability of results.\n  Results: Recommendations are made across the entire pipeline, backed by the\nsolid performance of the Aloe Family. These models deliver competitive\nperformance across healthcare benchmarks and medical fields, and are often\npreferred by healthcare professionals. On bias and toxicity, the Aloe Beta\nmodels significantly improve safety, showing resilience to unseen jailbreaking\nattacks. For a responsible release, a detailed risk assessment specific to\nhealthcare is attached to the Aloe Family models.\n  Conclusion: The Aloe Beta models, and the recipe that leads to them, are a\nsignificant contribution to the open-source medical LLM field, offering\ntop-of-the-line performance while maintaining high ethical requirements. This\nwork sets a new standard for developing and reporting aligned LLMs in\nhealthcare.",
      "tldr_zh": "这篇论文介绍了Aloe Family方法，用于开发开源和专业化的医疗LLMs，通过优化数据预处理和训练流程来提升模型效能（使用RAG）和安全性（通过DPO）。方法基于Llama 3.1和Qwen 2.5等基础模型，结合自定义数据集及合成Chain of Thought示例，并引入一种新的评估标准，包括封闭式、开放式、安全和人类评估。结果显示，Aloe Beta模型在医疗基准上表现出色，与私有模型竞争，并在偏差和毒性方面显著提高安全性；该工作为开源医疗LLMs领域设定了新的伦理标准，促进公共利益。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "arXiv admin note: substantial text overlap with arXiv:2405.01886",
      "pdf_url": "http://arxiv.org/pdf/2505.04388v1",
      "published_date": "2025-05-07 13:13:14 UTC",
      "updated_date": "2025-05-07 13:13:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:38:02.443008"
    },
    {
      "arxiv_id": "2505.04379v1",
      "title": "Consensus-Aware AV Behavior: Trade-offs Between Safety, Interaction, and Performance in Mixed Urban Traffic",
      "title_zh": "翻译失败",
      "authors": [
        "Mohammad Elayan",
        "Wissam Kontar"
      ],
      "abstract": "Transportation systems have long been shaped by complexity and heterogeneity,\ndriven by the interdependency of agent actions and traffic outcomes. The\ndeployment of automated vehicles (AVs) in such systems introduces a new\nchallenge: achieving consensus across safety, interaction quality, and traffic\nperformance. In this work, we position consensus as a fundamental property of\nthe traffic system and aim to quantify it. We use high-resolution trajectory\ndata from the Third Generation Simulation (TGSIM) dataset to empirically\nanalyze AV and human-driven vehicle (HDV) behavior at a signalized urban\nintersection and around vulnerable road users (VRUs). Key metrics, including\nTime-to-Collision (TTC), Post-Encroachment Time (PET), deceleration patterns,\nheadways, and string stability, are evaluated across the three performance\ndimensions. Results show that full consensus across safety, interaction, and\nperformance is rare, with only 1.63% of AV-VRU interaction frames meeting all\nthree conditions. These findings highlight the need for AV models that\nexplicitly balance multi-dimensional performance in mixed-traffic environments.\nFull reproducibility is supported via our open-source codebase on\nhttps://github.com/wissamkontar/Consensus-AV-Analysis.",
      "tldr_zh": "本研究探讨了自动驾驶车辆(AVs)在混合城市交通中的行为，旨在量化安全、互动质量和交通性能之间的共识权衡。利用TGSIM数据集的高分辨率轨迹数据，作者分析了AV和人类驾驶车辆(HDV)在信号化交叉路口及易受伤害道路使用者(VRUs)周围的表现，包括Time-to-Collision (TTC)、Post-Encroachment Time (PET)、减速模式、车头时距和字符串稳定性等关键指标。结果显示，仅有1.63%的AV-VRU互动帧同时满足所有三个维度，突显了开发能显式平衡多维性能的AV模型的迫切需求，并提供了开源代码以支持研究的可重复性。",
      "categories": [
        "cs.MA",
        "cs.AI",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.MA",
      "comment": "7 pages, 8 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.04379v1",
      "published_date": "2025-05-07 12:59:59 UTC",
      "updated_date": "2025-05-07 12:59:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:38:14.530958"
    },
    {
      "arxiv_id": "2505.04375v1",
      "title": "Balancing Accuracy, Calibration, and Efficiency in Active Learning with Vision Transformers Under Label Noise",
      "title_zh": "在标签噪声下，使用视觉Transformer的主动学习中平衡准确性、",
      "authors": [
        "Moseli Mots'oehli",
        "Hope Mogale",
        "Kyungim Baek"
      ],
      "abstract": "Fine-tuning pre-trained convolutional neural networks on ImageNet for\ndownstream tasks is well-established. Still, the impact of model size on the\nperformance of vision transformers in similar scenarios, particularly under\nlabel noise, remains largely unexplored. Given the utility and versatility of\ntransformer architectures, this study investigates their practicality under\nlow-budget constraints and noisy labels. We explore how classification accuracy\nand calibration are affected by symmetric label noise in active learning\nsettings, evaluating four vision transformer configurations (Base and Large\nwith 16x16 and 32x32 patch sizes) and three Swin Transformer configurations\n(Tiny, Small, and Base) on CIFAR10 and CIFAR100 datasets, under varying label\nnoise rates. Our findings show that larger ViT models (ViTl32 in particular)\nconsistently outperform their smaller counterparts in both accuracy and\ncalibration, even under moderate to high label noise, while Swin Transformers\nexhibit weaker robustness across all noise levels. We find that smaller patch\nsizes do not always lead to better performance, as ViTl16 performs consistently\nworse than ViTl32 while incurring a higher computational cost. We also find\nthat information-based Active Learning strategies only provide meaningful\naccuracy improvements at moderate label noise rates, but they result in poorer\ncalibration compared to models trained on randomly acquired labels, especially\nat high label noise rates. We hope these insights provide actionable guidance\nfor practitioners looking to deploy vision transformers in resource-constrained\nenvironments, where balancing model complexity, label noise, and compute\nefficiency is critical in model fine-tuning or distillation.",
      "tldr_zh": "本研究探讨了在标签噪声条件下，Vision Transformers在主动学习中的准确性、校准和效率平衡，评估了四种Vision Transformer配置（Base和Large，16x16及32x32补丁大小）和三种Swin Transformer配置（Tiny、Small和Base）在CIFAR10和CIFAR100数据集上的性能。结果显示，较大的ViT模型（如ViTl32）在中等到高标签噪声下表现出更高的准确性和校准稳定性，而Swin Transformers的鲁棒性较弱，且更小的补丁大小（如ViTl16）虽计算成本更高但性能不佳。主动学习策略仅在中等噪声率下显著提升准确性，但在高噪声率下会导致校准下降，为资源受限环境下的Vision Transformers部署提供了实用指导。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.04375v1",
      "published_date": "2025-05-07 12:53:13 UTC",
      "updated_date": "2025-05-07 12:53:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:38:25.294082"
    },
    {
      "arxiv_id": "2505.04354v1",
      "title": "Optimization Problem Solving Can Transition to Evolutionary Agentic Workflows",
      "title_zh": "优化问题求解可以过渡到进化型智能体工作流",
      "authors": [
        "Wenhao Li",
        "Bo Jin",
        "Mingyi Hong",
        "Changhong Lu",
        "Xiangfeng Wang"
      ],
      "abstract": "This position paper argues that optimization problem solving can transition\nfrom expert-dependent to evolutionary agentic workflows. Traditional\noptimization practices rely on human specialists for problem formulation,\nalgorithm selection, and hyperparameter tuning, creating bottlenecks that\nimpede industrial adoption of cutting-edge methods. We contend that an\nevolutionary agentic workflow, powered by foundation models and evolutionary\nsearch, can autonomously navigate the optimization space, comprising problem,\nformulation, algorithm, and hyperparameter spaces. Through case studies in\ncloud resource scheduling and ADMM parameter adaptation, we demonstrate how\nthis approach can bridge the gap between academic innovation and industrial\nimplementation. Our position challenges the status quo of human-centric\noptimization workflows and advocates for a more scalable, adaptive approach to\nsolving real-world optimization problems.",
      "tldr_zh": "本文观点论文主张，优化问题求解应从依赖人类专家的传统工作流转向进化型智能体工作流（evolutionary agentic workflows），以克服问题制定、算法选择和超参数调整的瓶颈问题，从而促进工业应用。提出的工作流利用基础模型（foundation models）和进化搜索（evolutionary search）来自主导航优化空间，包括问题、算法和超参数领域。通过云资源调度和ADMM参数适应的案例研究，展示了这种方法如何桥接学术创新与工业实现。该方法挑战现状，提倡更可扩展、适应的优化策略，以解决真实世界问题。",
      "categories": [
        "math.OC",
        "cs.AI"
      ],
      "primary_category": "math.OC",
      "comment": "27 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.04354v1",
      "published_date": "2025-05-07 12:07:49 UTC",
      "updated_date": "2025-05-07 12:07:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:38:36.364400"
    },
    {
      "arxiv_id": "2505.04678v1",
      "title": "Advanced Deep Learning Approaches for Automated Recognition of Cuneiform Symbols",
      "title_zh": "先进的深度学习方法用于楔形文字符号的自动识别",
      "authors": [
        "Shahad Elshehaby",
        "Alavikunhu Panthakkan",
        "Hussain Al-Ahmad",
        "Mina Al-Saad"
      ],
      "abstract": "This paper presents a thoroughly automated method for identifying and\ninterpreting cuneiform characters via advanced deep-learning algorithms. Five\ndistinct deep-learning models were trained on a comprehensive dataset of\ncuneiform characters and evaluated according to critical performance metrics,\nincluding accuracy and precision. Two models demonstrated outstanding\nperformance and were subsequently assessed using cuneiform symbols from the\nHammurabi law acquisition, notably Hammurabi Law 1. Each model effectively\nrecognized the relevant Akkadian meanings of the symbols and delivered precise\nEnglish translations. Future work will investigate ensemble and stacking\napproaches to optimize performance, utilizing hybrid architectures to improve\ndetection accuracy and reliability. This research explores the linguistic\nrelationships between Akkadian, an ancient Mesopotamian language, and Arabic,\nemphasizing their historical and cultural linkages. This study demonstrates the\ncapability of deep learning to decipher ancient scripts by merging\ncomputational linguistics with archaeology, therefore providing significant\ninsights for the comprehension and conservation of human history.",
      "tldr_zh": "本研究提出了一种先进的深度学习方法，用于自动识别和解释楔形文字（cuneiform）字符，通过训练五个深度学习模型（deep-learning models）来处理一个全面的数据集，并根据准确性（accuracy）和精确性（precision）等指标进行评估。两个表现出色的模型成功应用于Hammurabi法律文本（Hammurabi law），准确识别了相关阿卡德语（Akkadian）含义并提供精确的英语翻译。未来工作将探索集成（ensemble）和堆叠（stacking）方法，以及混合架构（hybrid architectures），以进一步提升检测的准确性和可靠性；同时，该研究揭示了阿卡德语与阿拉伯语之间的语言关系，并展示了深度学习在结合计算语言学和考古学方面的潜力，为人类历史理解和保存提供重要洞见。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.04678v1",
      "published_date": "2025-05-07 12:05:23 UTC",
      "updated_date": "2025-05-07 12:05:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:38:48.629421"
    },
    {
      "arxiv_id": "2505.04352v1",
      "title": "Uncertain Machine Ethics Planning",
      "title_zh": "翻译失败",
      "authors": [
        "Simon Kolker",
        "Louise A. Dennis",
        "Ramon Fraga Pereira",
        "Mengwei Xu"
      ],
      "abstract": "Machine Ethics decisions should consider the implications of uncertainty over\ndecisions. Decisions should be made over sequences of actions to reach\npreferable outcomes long term. The evaluation of outcomes, however, may invoke\none or more moral theories, which might have conflicting judgements. Each\ntheory will require differing representations of the ethical situation. For\nexample, Utilitarianism measures numerical values, Deontology analyses duties,\nand Virtue Ethics emphasises moral character. While balancing potentially\nconflicting moral considerations, decisions may need to be made, for example,\nto achieve morally neutral goals with minimal costs. In this paper, we\nformalise the problem as a Multi-Moral Markov Decision Process and a\nMulti-Moral Stochastic Shortest Path Problem. We develop a heuristic algorithm\nbased on Multi-Objective AO*, utilising Sven-Ove Hansson's Hypothetical\nRetrospection procedure for ethical reasoning under uncertainty. Our approach\nis validated by a case study from Machine Ethics literature: the problem of\nwhether to steal insulin for someone who needs it.",
      "tldr_zh": "这篇论文探讨了机器伦理决策中不确定性的影响，强调在多道德理论（如Utilitarianism、Deontology和Virtue Ethics）可能冲突的情况下，进行长期行动序列规划以实现偏好结果。作者将问题形式化为Multi-Moral Markov Decision Process和Multi-Moral Stochastic Shortest Path Problem，以平衡道德考虑。论文开发了一个基于Multi-Objective AO*的启发式算法，结合Sven-Ove Hansson's Hypothetical Retrospection程序进行不确定条件下的伦理推理。通过“是否偷窃胰岛素”的案例研究验证，该方法有效支持了道德中立的决策目标。",
      "categories": [
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.04352v1",
      "published_date": "2025-05-07 12:03:15 UTC",
      "updated_date": "2025-05-07 12:03:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:39:01.449862"
    },
    {
      "arxiv_id": "2505.04340v1",
      "title": "Multi-Granular Attention based Heterogeneous Hypergraph Neural Network",
      "title_zh": "翻译失败",
      "authors": [
        "Hong Jin",
        "Kaicheng Zhou",
        "Jie Yin",
        "Lan You",
        "Zhifeng Zhou"
      ],
      "abstract": "Heterogeneous graph neural networks (HeteGNNs) have demonstrated strong\nabilities to learn node representations by effectively extracting complex\nstructural and semantic information in heterogeneous graphs. Most of the\nprevailing HeteGNNs follow the neighborhood aggregation paradigm, leveraging\nmeta-path based message passing to learn latent node representations. However,\ndue to the pairwise nature of meta-paths, these models fail to capture\nhigh-order relations among nodes, resulting in suboptimal performance.\nAdditionally, the challenge of ``over-squashing'', where long-range message\npassing in HeteGNNs leads to severe information distortion, further limits the\nefficacy of these models. To address these limitations, this paper proposes\nMGA-HHN, a Multi-Granular Attention based Heterogeneous Hypergraph Neural\nNetwork for heterogeneous graph representation learning. MGA-HHN introduces two\nkey innovations: (1) a novel approach for constructing meta-path based\nheterogeneous hypergraphs that explicitly models higher-order semantic\ninformation in heterogeneous graphs through multiple views, and (2) a\nmulti-granular attention mechanism that operates at both the node and hyperedge\nlevels. This mechanism enables the model to capture fine-grained interactions\namong nodes sharing the same semantic context within a hyperedge type, while\npreserving the diversity of semantics across different hyperedge types. As\nsuch, MGA-HHN effectively mitigates long-range message distortion and generates\nmore expressive node representations. Extensive experiments on real-world\nbenchmark datasets demonstrate that MGA-HHN outperforms state-of-the-art\nmodels, showcasing its effectiveness in node classification, node clustering\nand visualization tasks.",
      "tldr_zh": "本文提出 MGA-HHN，一种基于 Multi-Granular Attention 的 Heterogeneous Hypergraph Neural Network，用于提升异构图表示学习。模型通过构建 meta-path based heterogeneous hypergraphs 的新方法，显式捕捉多视图的高阶语义信息，并引入多粒度注意力机制，在节点和超边级别优化交互，缓解“over-squashing”问题并生成更具表现力的节点表示。实验在真实基准数据集上证明，MGA-HHN 在节点分类、聚类和可视化任务中优于现有最先进模型。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.04340v1",
      "published_date": "2025-05-07 11:42:00 UTC",
      "updated_date": "2025-05-07 11:42:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:39:13.528202"
    },
    {
      "arxiv_id": "2505.04339v1",
      "title": "Adaptive and Robust DBSCAN with Multi-agent Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Hao Peng",
        "Xiang Huang",
        "Shuo Sun",
        "Ruitong Zhang",
        "Philip S. Yu"
      ],
      "abstract": "DBSCAN, a well-known density-based clustering algorithm, has gained\nwidespread popularity and usage due to its effectiveness in identifying\nclusters of arbitrary shapes and handling noisy data. However, it encounters\nchallenges in producing satisfactory cluster results when confronted with\ndatasets of varying density scales, a common scenario in real-world\napplications. In this paper, we propose a novel Adaptive and Robust DBSCAN with\nMulti-agent Reinforcement Learning cluster framework, namely AR-DBSCAN. First,\nwe model the initial dataset as a two-level encoding tree and categorize the\ndata vertices into distinct density partitions according to the information\nuncertainty determined in the encoding tree. Each partition is then assigned to\nan agent to find the best clustering parameters without manual assistance. The\nallocation is density-adaptive, enabling AR-DBSCAN to effectively handle\ndiverse density distributions within the dataset by utilizing distinct agents\nfor different partitions. Second, a multi-agent deep reinforcement learning\nguided automatic parameter searching process is designed. The process of\nadjusting the parameter search direction by perceiving the clustering\nenvironment is modeled as a Markov decision process. Using a weakly-supervised\nreward training policy network, each agent adaptively learns the optimal\nclustering parameters by interacting with the clusters. Third, a recursive\nsearch mechanism adaptable to the data's scale is presented, enabling efficient\nand controlled exploration of large parameter spaces. Extensive experiments are\nconducted on nine artificial datasets and a real-world dataset. The results of\noffline and online tasks show that AR-DBSCAN not only improves clustering\naccuracy by up to 144.1% and 175.3% in the NMI and ARI metrics, respectively,\nbut also is capable of robustly finding dominant parameters.",
      "tldr_zh": "本论文提出 AR-DBSCAN，一种基于多智能体强化学习的适应性和鲁棒 DBSCAN 聚类框架，用于处理不同密度分布的数据集。首先，通过两级编码树将数据集划分成密度分区，并分配给各代理自动搜索最佳聚类参数；其次，利用多智能体深度强化学习和递归搜索机制，实现参数的自适应优化。实验在九个人工数据集和一个真实数据集上显示，AR-DBSCAN 使 NMI 和 ARI 指标分别提高高达 144.1% 和 175.3%，并显著提升聚类准确性和鲁棒性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.04339v1",
      "published_date": "2025-05-07 11:37:23 UTC",
      "updated_date": "2025-05-07 11:37:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:39:25.561761"
    },
    {
      "arxiv_id": "2505.04677v1",
      "title": "Proceedings The 13th International Workshop on Theorem proving components for Educational software",
      "title_zh": "翻译失败",
      "authors": [
        "Julien Narboux",
        "Walther Neuper",
        "Pedro Quaresma"
      ],
      "abstract": "The ThEdu series pursues the smooth transition from an intuitive way of doing\nmathematics at secondary school to a more formal approach to the subject in\nSTEM education while favoring software support for this transition by\nexploiting the power of theorem-proving technologies. What follows is a brief\ndescription of how the present volume contributes to this enterprise. The 13th\nInternational Workshop on Theorem Proving Components for Educational Software\n(ThEdu'24), was a satellite event of the CADE29, part of IJCAR 2024, Nancy,\nFrance. ThEdu'24 was a vibrant workshop, with one invited talk by Jeremy Avigad\n(Carnegie Mellon University) and 14 submitted talks. An open call for papers\nwas then issued and attracted 9 submissions. Eight of those submissions have\nbeen accepted by our reviewers. The resulting revised papers are collected in\nthe present volume. The contributions in this volume are a faithful\nrepresentation of the wide spectrum of ThEdu, ranging from those more focused\non the automated deduction research, not losing track of the possible\napplications in an educational setting, to those focused on the applications,\nin educational settings, of automated deduction tools and methods. We, the\nvolume editors, hope that this collection of papers will further promote the\ndevelopment of theorem-proving-based software and that it will allow to improve\nthe mutual understanding between computer scientists, mathematicians, and\nstakeholders in education. While this volume goes to press, the next edition of\nthe ThEdu workshop is being prepared: ThEdu'25 will be a satellite event of the\n30th international Conference on Automated DEduction (CADE-30), July 28th -\nAugust 2nd, 2025, Stuttgart, Germany.",
      "tldr_zh": "本论文集记录了第13届国际研讨会ThEdu'24，该研讨会聚焦于使用Theorem Proving Components技术，支持从中学数学到STEM教育的顺利过渡，并作为CADE29和IJCAR 2024的卫星事件在法国Nancy举行。研讨会包括Jeremy Avigad的邀请演讲和14个提交演讲，随后公开征稿吸引9篇论文，其中8篇被接受并收录在本卷。论文涵盖了从自动化推理研究到教育应用的全谱系，旨在促进定理证明软件的发展并增强计算机科学家、数学家和教育相关者的相互理解。下一届ThEdu'25将于2025年在德国Stuttgart举行，作为CADE-30的卫星事件继续推进这一领域。",
      "categories": [
        "cs.LO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.LO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.04677v1",
      "published_date": "2025-05-07 11:30:54 UTC",
      "updated_date": "2025-05-07 11:30:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:39:39.795154"
    },
    {
      "arxiv_id": "2505.06287v1",
      "title": "BedreFlyt: Improving Patient Flows through Hospital Wards with Digital Twins",
      "title_zh": "BedreFlyt：使用数字孪生技术改善医院病房患者流动",
      "authors": [
        "Riccardo Sieve",
        "Paul Kobialka",
        "Laura Slaughter",
        "Rudolf Schlatte",
        "Einar Broch Johnsen",
        "Silvia Lizeth Tapia Tarifa"
      ],
      "abstract": "Digital twins are emerging as a valuable tool for short-term decision-making\nas well as for long-term strategic planning across numerous domains, including\nprocess industry, energy, space, transport, and healthcare. This paper reports\non our ongoing work on designing a digital twin to enhance resource planning,\ne.g., for the in-patient ward needs in hospitals. By leveraging executable\nformal models for system exploration, ontologies for knowledge representation\nand an SMT solver for constraint satisfiability, our approach aims to explore\nhypothetical \"what-if\" scenarios to improve strategic planning processes, as\nwell as to solve concrete, short-term decision-making tasks. Our proposed\nsolution uses the executable formal model to turn a stream of arriving\npatients, that need to be hospitalized, into a stream of optimization problems,\ne.g., capturing daily inpatient ward needs, that can be solved by SMT\ntechniques. The knowledge base, which formalizes domain knowledge, is used to\nmodel the needed configuration in the digital twin, allowing the twin to\nsupport both short-term decision-making and long-term strategic planning by\ngenerating scenarios spanning average-case as well as worst-case resource\nneeds, depending on the expected treatment of patients, as well as ranging over\nvariations in available resources, e.g., bed distribution in different rooms.\nWe illustrate our digital twin architecture by considering the problem of bed\nbay allocation in a hospital ward.",
      "tldr_zh": "这篇论文介绍了BedreFlyt系统，利用digital twins技术来优化医院病房的患者流动和资源规划。方法结合可执行正式模型、本体(ontologies)以及SMT solver来探索假设场景，将患者入院数据转化为优化问题，支持短期决策和长期战略规划。系统通过模拟平均和最坏情况资源需求（如床位分配），为医院管理提供更有效的解决方案。",
      "categories": [
        "cs.AI",
        "cs.ET",
        "cs.LO",
        "D.2.2; D.2.4; J.3"
      ],
      "primary_category": "cs.AI",
      "comment": "In Proceedings ASQAP 2025, arXiv:2505.02873",
      "pdf_url": "http://arxiv.org/pdf/2505.06287v1",
      "published_date": "2025-05-07 11:23:39 UTC",
      "updated_date": "2025-05-07 11:23:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:39:48.513610"
    },
    {
      "arxiv_id": "2505.07847v1",
      "title": "Conceptual Logical Foundations of Artificial Social Intelligence",
      "title_zh": "人工社会智能的概念逻辑基础",
      "authors": [
        "Eric Werner"
      ],
      "abstract": "What makes a society possible at all? How is coordination and cooperation in\nsocial activity possible? What is the minimal mental architecture of a social\nagent? How is the information about the state of the world related to the\nagents intentions? How are the intentions of agents related? What role does\ncommunication play in this coordination process? This essay explores the\nconceptual and logical foundations of artificial social intelligence in the\ncontext of a society of multiple agents that communicate and cooperate to\nachieve some end. An attempt is made to provide an introduction to some of the\nkey concepts, their formal definitions and their interrelationships. These\ninclude the notion of a changing social world of multiple agents. The logic of\nsocial intelligence goes beyond classical logic by linking information with\nstrategic thought. A minimal architecture of social agents is presented. The\nagents have different dynamically changing, possible choices and abilities. The\nagents also have uncertainty, lacking perfect information about their physical\nstate as well as their dynamic social state. The social state of an agent\nincludes the intentional state of that agent, as well as, that agent's\nrepresentation of the intentional states of other agents. Furthermore, it\nincludes the evaluations agents make of their physical and social condition.\nCommunication, semantic and pragmatic meaning and their relationship to\nintention and information states are investigated. The logic of agent abilities\nand intentions are motivated and formalized. The entropy of group strategic\nstates is defined.",
      "tldr_zh": "这篇论文探讨了人工社会智能（Artificial Social Intelligence）的概念和逻辑基础，针对多代理社会中协调、合作和通信的可能性问题。论文引入了代理的最小心理架构、意图状态的不确定性，以及代理对自身和他人意图的表示，并扩展了经典逻辑以连接信息与战略思维。作者正式定义了代理能力、意图逻辑、通信的语义与语用意义，并提出了群组战略状态的熵概念，作为实现多代理合作的基础。",
      "categories": [
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.07847v1",
      "published_date": "2025-05-07 11:06:23 UTC",
      "updated_date": "2025-05-07 11:06:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:40:00.695080"
    },
    {
      "arxiv_id": "2505.04318v1",
      "title": "Detecting Concept Drift in Neural Networks Using Chi-squared Goodness of Fit Testing",
      "title_zh": "使用卡方拟合优度检验检测神经网络中的概念漂移",
      "authors": [
        "Jacob Glenn Ayers",
        "Buvaneswari A. Ramanan",
        "Manzoor A. Khan"
      ],
      "abstract": "As the adoption of deep learning models has grown beyond human capacity for\nverification, meta-algorithms are needed to ensure reliable model inference.\nConcept drift detection is a field dedicated to identifying statistical shifts\nthat is underutilized in monitoring neural networks that may encounter\ninference data with distributional characteristics diverging from their\ntraining data. Given the wide variety of model architectures, applications, and\ndatasets, it is important that concept drift detection algorithms are adaptable\nto different inference scenarios. In this paper, we introduce an application of\nthe $\\chi^2$ Goodness of Fit Hypothesis Test as a drift detection\nmeta-algorithm applied to a multilayer perceptron, a convolutional neural\nnetwork, and a transformer trained for machine vision as they are exposed to\nsimulated drift during inference. To that end, we demonstrate how unexpected\ndrops in accuracy due to concept drift can be detected without directly\nexamining the inference outputs. Our approach enhances safety by ensuring\nmodels are continually evaluated for reliability across varying conditions.",
      "tldr_zh": "这篇论文提出使用 Chi-squared Goodness of Fit Testing 作为一种元算法，来检测神经网络中的 concept drift，即模型在推理时数据分布与训练数据发生统计偏移的问题。研究将该方法应用于 multilayer perceptron、convolutional neural network 和 transformer 等模型，在机器视觉任务中模拟漂移场景。结果表明，该方法能无需直接检查推理输出就识别准确性下降，从而增强模型在不同条件下的可靠性和安全性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "eess.IV"
      ],
      "primary_category": "cs.LG",
      "comment": "8 pages, 6 figures, 1 table",
      "pdf_url": "http://arxiv.org/pdf/2505.04318v1",
      "published_date": "2025-05-07 11:04:47 UTC",
      "updated_date": "2025-05-07 11:04:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:40:13.145070"
    },
    {
      "arxiv_id": "2505.04317v1",
      "title": "Mastering Multi-Drone Volleyball through Hierarchical Co-Self-Play Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Ruize Zhang",
        "Sirui Xiang",
        "Zelai Xu",
        "Feng Gao",
        "Shilong Ji",
        "Wenhao Tang",
        "Wenbo Ding",
        "Chao Yu",
        "Yu Wang"
      ],
      "abstract": "In this paper, we tackle the problem of learning to play 3v3 multi-drone\nvolleyball, a new embodied competitive task that requires both high-level\nstrategic coordination and low-level agile control. The task is turn-based,\nmulti-agent, and physically grounded, posing significant challenges due to its\nlong-horizon dependencies, tight inter-agent coupling, and the underactuated\ndynamics of quadrotors. To address this, we propose Hierarchical Co-Self-Play\n(HCSP), a hierarchical reinforcement learning framework that separates\ncentralized high-level strategic decision-making from decentralized low-level\nmotion control. We design a three-stage population-based training pipeline to\nenable both strategy and skill to emerge from scratch without expert\ndemonstrations: (I) training diverse low-level skills, (II) learning high-level\nstrategy via self-play with fixed low-level controllers, and (III) joint\nfine-tuning through co-self-play. Experiments show that HCSP achieves superior\nperformance, outperforming non-hierarchical self-play and rule-based\nhierarchical baselines with an average 82.9\\% win rate and a 71.5\\% win rate\nagainst the two-stage variant. Moreover, co-self-play leads to emergent team\nbehaviors such as role switching and coordinated formations, demonstrating the\neffectiveness of our hierarchical design and training scheme.",
      "tldr_zh": "本文提出 Hierarchical Co-Self-Play (HCSP) 框架，一种分层强化学习方法，用于训练多无人机在 3v3 排球任务中实现高层战略协调和低层敏捷控制，解决长时依赖、多代理耦合和欠驱动动力学等挑战。HCSP 通过三阶段基于种群的训练管道——训练多样低层技能、通过自对弈学习高层策略，以及联合微调——从零开始实现策略和技能的涌现。实验结果表明，HCSP 比非分层自对弈和基于规则的基线方法胜率分别达到 82.9% 和 71.5%，并展现出如角色切换和协调队形的智能行为。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.04317v1",
      "published_date": "2025-05-07 11:04:36 UTC",
      "updated_date": "2025-05-07 11:04:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:40:25.828141"
    },
    {
      "arxiv_id": "2505.04313v1",
      "title": "KERAIA: An Adaptive and Explainable Framework for Dynamic Knowledge Representation and Reasoning",
      "title_zh": "翻译失败",
      "authors": [
        "Stephen Richard Varey",
        "Alessandro Di Stefano",
        "The Anh Han"
      ],
      "abstract": "In this paper, we introduce KERAIA, a novel framework and software platform\nfor symbolic knowledge engineering designed to address the persistent\nchallenges of representing, reasoning with, and executing knowledge in dynamic,\ncomplex, and context-sensitive environments. The central research question that\nmotivates this work is: How can unstructured, often tacit, human expertise be\neffectively transformed into computationally tractable algorithms that AI\nsystems can efficiently utilise? KERAIA seeks to bridge this gap by building on\nfoundational concepts such as Minsky's frame-based reasoning and K-lines, while\nintroducing significant innovations. These include Clouds of Knowledge for\ndynamic aggregation, Dynamic Relations (DRels) for context-sensitive\ninheritance, explicit Lines of Thought (LoTs) for traceable reasoning, and\nCloud Elaboration for adaptive knowledge transformation. This approach moves\nbeyond the limitations of traditional, often static, knowledge representation\nparadigms. KERAIA is designed with Explainable AI (XAI) as a core principle,\nensuring transparency and interpretability, particularly through the use of\nLoTs. The paper details the framework's architecture, the KSYNTH representation\nlanguage, and the General Purpose Paradigm Builder (GPPB) to integrate diverse\ninference methods within a unified structure. We validate KERAIA's versatility,\nexpressiveness, and practical applicability through detailed analysis of\nmultiple case studies spanning naval warfare simulation, industrial diagnostics\nin water treatment plants, and strategic decision-making in the game of RISK.\nFurthermore, we provide a comparative analysis against established knowledge\nrepresentation paradigms (including ontologies, rule-based systems, and\nknowledge graphs) and discuss the implementation aspects and computational\nconsiderations of the KERAIA platform.",
      "tldr_zh": "本研究引入了 KERAIA，一种适应性和可解释的框架，用于在动态、复杂环境中进行知识表示、推理和执行，主要解决将人类隐性专家知识转化为可计算算法的问题。KERAIA 基于 Minsky 的框架和 K-lines 进行创新，引入了 Clouds of Knowledge 用于动态聚合、Dynamic Relations (DRels) 用于上下文敏感继承、Lines of Thought (LoTs) 用于可追踪推理，以及 Cloud Elaboration 用于适应性知识转换，同时以 Explainable AI (XAI) 为核心原则确保透明性。框架的架构包括 KSYNTH 语言和 General Purpose Paradigm Builder (GPPB)，通过海军战争模拟、水处理厂诊断和 RISK 游戏等案例研究验证了其多功能性、表达性和实用性，并与传统范式（如本体、规则系统和知识图谱）进行比较，展示了显著的优势。",
      "categories": [
        "cs.AI",
        "cs.ET",
        "cs.SC"
      ],
      "primary_category": "cs.AI",
      "comment": "22 pages",
      "pdf_url": "http://arxiv.org/pdf/2505.04313v1",
      "published_date": "2025-05-07 10:56:05 UTC",
      "updated_date": "2025-05-07 10:56:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:40:37.960518"
    },
    {
      "arxiv_id": "2505.04310v1",
      "title": "Flow Models for Unbounded and Geometry-Aware Distributional Reinforcement Learning",
      "title_zh": "用于无界和几何感知分布强化学习的流模型",
      "authors": [
        "Simo Alami C.",
        "Rim Kaddah",
        "Jesse Read",
        "Marie-Paule Cani"
      ],
      "abstract": "We introduce a new architecture for Distributional Reinforcement Learning\n(DistRL) that models return distributions using normalizing flows. This\napproach enables flexible, unbounded support for return distributions, in\ncontrast to categorical approaches like C51 that rely on fixed or bounded\nrepresentations. It also offers richer modeling capacity to capture\nmulti-modality, skewness, and tail behavior than quantile based approaches. Our\nmethod is significantly more parameter-efficient than categorical approaches.\nStandard metrics used to train existing models like KL divergence or\nWasserstein distance either are scale insensitive or have biased sample\ngradients, especially when return supports do not overlap. To address this, we\npropose a novel surrogate for the Cram\\`er distance, that is geometry-aware and\ncomputable directly from the return distribution's PDF, avoiding the costly CDF\ncomputation. We test our model on the ATARI-5 sub-benchmark and show that our\napproach outperforms PDF based models while remaining competitive with quantile\nbased methods.",
      "tldr_zh": "本研究提出了一种新架构，用于无界和几何感知的分布强化学习(Distributional Reinforcement Learning, DistRL)，通过 normalizing flows 建模回报分布，支持灵活的无界表示，并比 categorical 方法（如 C51）和 quantile-based 方法提供更丰富的建模能力，如捕捉多模态、偏斜和尾部行为，同时实现更高的参数效率。针对现有训练指标如 KL divergence 或 Wasserstein distance 的局限（如尺度不敏感或偏差），作者引入了一个新的 geometry-aware Cramér distance 代理，直接从回报分布的 PDF 计算，避免了昂贵的 CDF 计算。实验在 ATARI-5 子基准上显示，该方法优于基于 PDF 的模型，并在性能上与 quantile-based 方法保持竞争。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "math.OC"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.04310v1",
      "published_date": "2025-05-07 10:49:53 UTC",
      "updated_date": "2025-05-07 10:49:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:40:49.924187"
    },
    {
      "arxiv_id": "2505.04308v1",
      "title": "Guardians of the Web: The Evolution and Future of Website Information Security",
      "title_zh": "网络守护者：网站信息安全的演变与未来",
      "authors": [
        "Md Saiful Islam",
        "Li Xiangdong"
      ],
      "abstract": "Website information security has become a critical concern in the digital\nage. This article explores the evolution of website information security,\nexamining its historical development, current practices, and future directions.\nThe early beginnings from the 1960s to the 1980s laid the groundwork for modern\ncybersecurity, with the development of ARPANET, TCP/IP, public-key\ncryptography, and the first antivirus programs. The 1990s marked a\ntransformative era, driven by the commercialization of the Internet and the\nemergence of web-based services. As the Internet grew, so did the range and\nsophistication of cyber threats, leading to advancements in security\ntechnologies such as the Secure Sockets Layer (SSL) protocol, password\nprotection, and firewalls. Current practices in website information security\ninvolve a multi-layered approach, including encryption, secure coding\npractices, regular security audits, and user education. The future of website\ninformation security is expected to be shaped by emerging technologies such as\nartificial intelligence, blockchain, and quantum computing, as well as the\nincreasing importance of international cooperation and standardization efforts.\nAs cyber threats continue to evolve, ongoing research and innovation in website\ninformation security will be essential to protect sensitive information and\nmaintain trust in the digital world.",
      "tldr_zh": "这篇文章回顾了网站信息安全的演变，从20世纪60年代到80年代的奠基阶段（如ARPANET、TCP/IP、公共密钥加密和第一代杀毒软件），到90年代的转型期（如互联网商业化、SSL协议、密码保护和防火墙）。当前实践采用多层策略，包括加密、安全编码、定期安全审计和用户教育，以应对日益复杂的网络威胁。未来方向将受人工智能、区块链和量子计算等新兴技术影响，并强调国际合作和标准化努力，以维护数字世界的信任和安全。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "F.2.2, I.2.7"
      ],
      "primary_category": "cs.CR",
      "comment": "22 pages",
      "pdf_url": "http://arxiv.org/pdf/2505.04308v1",
      "published_date": "2025-05-07 10:46:33 UTC",
      "updated_date": "2025-05-07 10:46:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:41:02.265358"
    },
    {
      "arxiv_id": "2505.04674v1",
      "title": "Dynamic Location Search for Identifying Maximum Weighted Independent Sets in Complex Networks",
      "title_zh": "复杂网络中最大加权独立集的动态位置搜索识别",
      "authors": [
        "Enqiang Zhu",
        "Chenkai Hao",
        "Chanjuan Liu",
        "Yongsheng Rao"
      ],
      "abstract": "While Artificial intelligence (AI), including Generative AI, are effective at\ngenerating high-quality traffic data and optimization solutions in intelligent\ntransportation systems (ITSs), these techniques often demand significant\ntraining time and computational resources, especially in large-scale and\ncomplex scenarios. To address this, we introduce a novel and efficient\nalgorithm for solving the maximum weighted independent set (MWIS) problem,\nwhich can be used to model many ITSs applications, such as traffic signal\ncontrol and vehicle routing. Given the NP-hard nature of the MWIS problem, our\nproposed algorithm, DynLS, incorporates three key innovations to solve it\neffectively. First, it uses a scores-based adaptive vertex perturbation (SAVP)\ntechnique to accelerate convergence, particularly in sparse graphs. Second, it\nincludes a region location mechanism (RLM) to help escape local optima by\ndynamically adjusting the search space. Finally, it employs a novel variable\nneighborhood descent strategy, ComLS, which combines vertex exchange strategies\nwith a reward mechanism to guide the search toward high-quality solutions. Our\nexperimental results demonstrate DynLS's superior performance, consistently\ndelivering high-quality solutions within 1000 seconds. DynLS outperformed five\nleading algorithms across 360 test instances, achieving the best solution for\n350 instances and surpassing the second-best algorithm, Cyclic-Fast, by 177\ninstances. Moreover, DynLS matched Cyclic-Fast's convergence speed,\nhighlighting its efficiency and practicality. This research represents a\nsignificant advancement in heuristic algorithms for the MWIS problem, offering\na promising approach to aid AI techniques in optimizing intelligent\ntransportation systems.",
      "tldr_zh": "这篇论文提出了一种名为 DynLS 的新算法，用于高效解决复杂网络中的最大加权独立集 (MWIS) 问题，该问题常用于智能交通系统 (ITS) 的应用，如交通信号控制和车辆路由。DynLS 引入了三个关键创新：基于分数的自适应顶点扰动 (SAVP) 技术加速收敛、区域定位机制 (RLM) 动态调整搜索空间以逃离局部最优，以及组合局部搜索策略 (ComLS) 通过顶点交换和奖励机制引导到高质量解。实验结果表明，DynLS 在 360 个测试实例中优于五种领先算法，在 350 个实例中获得最佳解，并与 Cyclic-Fast 算法在收敛速度上相当。该研究为 MWIS 问题的启发式算法带来重大进展，有助于提升 AI 在 ITS 中的优化效率。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.04674v1",
      "published_date": "2025-05-07 10:35:53 UTC",
      "updated_date": "2025-05-07 10:35:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:41:17.351012"
    },
    {
      "arxiv_id": "2505.04300v1",
      "title": "Sparsity is All You Need: Rethinking Biological Pathway-Informed Approaches in Deep Learning",
      "title_zh": "稀疏性就是你所需要的全部：重新审视基于生物途径的方法在深度学习中",
      "authors": [
        "Isabella Caranzano",
        "Corrado Pancotti",
        "Cesare Rollo",
        "Flavio Sartori",
        "Pietro Liò",
        "Piero Fariselli",
        "Tiziana Sanavia"
      ],
      "abstract": "Biologically-informed neural networks typically leverage pathway annotations\nto enhance performance in biomedical applications. We hypothesized that the\nbenefits of pathway integration does not arise from its biological relevance,\nbut rather from the sparsity it introduces. We conducted a comprehensive\nanalysis of all relevant pathway-based neural network models for predictive\ntasks, critically evaluating each study's contributions. From this review, we\ncurated a subset of methods for which the source code was publicly available.\nThe comparison of the biologically informed state-of-the-art deep learning\nmodels and their randomized counterparts showed that models based on randomized\ninformation performed equally well as biologically informed ones across\ndifferent metrics and datasets. Notably, in 3 out of the 15 analyzed models,\nthe randomized versions even outperformed their biologically informed\ncounterparts. Moreover, pathway-informed models did not show any clear\nadvantage in interpretability, as randomized models were still able to identify\nrelevant disease biomarkers despite lacking explicit pathway information. Our\nfindings suggest that pathway annotations may be too noisy or inadequately\nexplored by current methods. Therefore, we propose a methodology that can be\napplied to different domains and can serve as a robust benchmark for\nsystematically comparing novel pathway-informed models against their randomized\ncounterparts. This approach enables researchers to rigorously determine whether\nobserved performance improvements can be attributed to biological insights.",
      "tldr_zh": "本研究质疑了在深度学习中整合生物路径注释（pathway annotations）的传统方法，假设其性能提升主要源于引入的sparsity（稀疏性），而非生物相关性。作者通过全面分析现有路径-based神经网络模型，并将它们与随机化版本（randomized counterparts）进行比较，发现随机模型在不同指标和数据集上表现相当，甚至在15个模型中的3个中优于生物信息模型。结果显示，路径-informed模型在interpretability（可解释性）上没有明显优势，且路径注释可能过于noisy（噪声），因此提出了一种新的benchmark方法，用于系统比较新模型的性能改进，以验证是否真正源于生物洞见。",
      "categories": [
        "q-bio.QM",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "q-bio.QM",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.04300v1",
      "published_date": "2025-05-07 10:14:31 UTC",
      "updated_date": "2025-05-07 10:14:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:41:31.504159"
    },
    {
      "arxiv_id": "2505.04673v1",
      "title": "REVEAL: Multi-turn Evaluation of Image-Input Harms for Vision LLM",
      "title_zh": "翻译失败",
      "authors": [
        "Madhur Jindal",
        "Saurabh Deshpande"
      ],
      "abstract": "Vision Large Language Models (VLLMs) represent a significant advancement in\nartificial intelligence by integrating image-processing capabilities with\ntextual understanding, thereby enhancing user interactions and expanding\napplication domains. However, their increased complexity introduces novel\nsafety and ethical challenges, particularly in multi-modal and multi-turn\nconversations. Traditional safety evaluation frameworks, designed for\ntext-based, single-turn interactions, are inadequate for addressing these\ncomplexities. To bridge this gap, we introduce the REVEAL (Responsible\nEvaluation of Vision-Enabled AI LLMs) Framework, a scalable and automated\npipeline for evaluating image-input harms in VLLMs. REVEAL includes automated\nimage mining, synthetic adversarial data generation, multi-turn conversational\nexpansion using crescendo attack strategies, and comprehensive harm assessment\nthrough evaluators like GPT-4o.\n  We extensively evaluated five state-of-the-art VLLMs, GPT-4o, Llama-3.2,\nQwen2-VL, Phi3.5V, and Pixtral, across three important harm categories: sexual\nharm, violence, and misinformation. Our findings reveal that multi-turn\ninteractions result in significantly higher defect rates compared to\nsingle-turn evaluations, highlighting deeper vulnerabilities in VLLMs. Notably,\nGPT-4o demonstrated the most balanced performance as measured by our\nSafety-Usability Index (SUI) followed closely by Pixtral. Additionally,\nmisinformation emerged as a critical area requiring enhanced contextual\ndefenses. Llama-3.2 exhibited the highest MT defect rate ($16.55 \\%$) while\nQwen2-VL showed the highest MT refusal rate ($19.1 \\%$).",
      "tldr_zh": "本研究引入了 REVEAL 框架，一种可扩展的自动化管道，用于评估视觉大型语言模型 (VLLMs) 在图像输入危害方面的安全和伦理挑战，特别是针对多模态和多轮对话场景。框架包括自动化图像挖掘、合成对抗数据生成、采用 crescendo attack 策略的多轮对话扩展，以及使用 GPT-4o 等评估器的全面危害评估。实验评估了五种 SOTA 模型（GPT-4o、Llama-3.2、Qwen2-VL、Phi3.5V 和 Pixtral）在 sexual harm、violence 和 misinformation 等三大类别上的表现。结果显示，多轮交互导致缺陷率显著升高，GPT-4o 在 Safety-Usability Index (SUI) 上表现最佳，而 misinformation 被标识为需要加强上下文防御的关键问题。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "13 pages (8 main), to be published in IJCAI 2025",
      "pdf_url": "http://arxiv.org/pdf/2505.04673v1",
      "published_date": "2025-05-07 10:09:55 UTC",
      "updated_date": "2025-05-07 10:09:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:41:40.391142"
    },
    {
      "arxiv_id": "2505.04284v1",
      "title": "GASCADE: Grouped Summarization of Adverse Drug Event for Enhanced Cancer Pharmacovigilance",
      "title_zh": "GASCADE: 用于",
      "authors": [
        "Sofia Jamil",
        "Aryan Dabad",
        "Bollampalli Areen Reddy",
        "Sriparna Saha",
        "Rajiv Misra",
        "Adil A. Shakur"
      ],
      "abstract": "In the realm of cancer treatment, summarizing adverse drug events (ADEs)\nreported by patients using prescribed drugs is crucial for enhancing\npharmacovigilance practices and improving drug-related decision-making. While\nthe volume and complexity of pharmacovigilance data have increased, existing\nresearch in this field has predominantly focused on general diseases rather\nthan specifically addressing cancer. This work introduces the task of grouped\nsummarization of adverse drug events reported by multiple patients using the\nsame drug for cancer treatment. To address the challenge of limited resources\nin cancer pharmacovigilance, we present the MultiLabeled Cancer Adverse Drug\nReaction and Summarization (MCADRS) dataset. This dataset includes\npharmacovigilance posts detailing patient concerns regarding drug efficacy and\nadverse effects, along with extracted labels for drug names, adverse drug\nevents, severity, and adversity of reactions, as well as summaries of ADEs for\neach drug. Additionally, we propose the Grouping and Abstractive Summarization\nof Cancer Adverse Drug events (GASCADE) framework, a novel pipeline that\ncombines the information extraction capabilities of Large Language Models\n(LLMs) with the summarization power of the encoder-decoder T5 model. Our work\nis the first to apply alignment techniques, including advanced algorithms like\nDirect Preference Optimization, to encoder-decoder models using synthetic\ndatasets for summarization tasks. Through extensive experiments, we demonstrate\nthe superior performance of GASCADE across various metrics, validated through\nboth automated assessments and human evaluations. This multitasking approach\nenhances drug-related decision-making and fosters a deeper understanding of\npatient concerns, paving the way for advancements in personalized and\nresponsive cancer care. The code and dataset used in this work are publicly\navailable.",
      "tldr_zh": "本研究针对癌症治疗中患者报告的药物不良事件（ADEs），提出分组总结任务，以提升pharmacovigilance实践，并填补现有研究对癌症领域的关注不足。作者构建了MultiLabeled Cancer Adverse Drug Reaction and Summarization (MCADRS)数据集，包括患者帖子、药物名称、ADEs标签、严重程度以及ADEs总结。GASCADE框架结合Large Language Models (LLMs)的信息提取能力和T5模型的摘要生成，并首次应用Direct Preference Optimization等对齐技术进行模型优化。实验结果显示，GASCADE在多种指标上表现出色，经自动和人工评估验证，有助于改善药物决策和个性化癌症护理。代码和数据集已公开可用。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.04284v1",
      "published_date": "2025-05-07 09:40:18 UTC",
      "updated_date": "2025-05-07 09:40:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:41:51.670942"
    },
    {
      "arxiv_id": "2505.04278v2",
      "title": "Non-stationary Diffusion For Probabilistic Time Series Forecasting",
      "title_zh": "翻译失败",
      "authors": [
        "Weiwei Ye",
        "Zhuopeng Xu",
        "Ning Gui"
      ],
      "abstract": "Due to the dynamics of underlying physics and external influences, the\nuncertainty of time series often varies over time. However, existing Denoising\nDiffusion Probabilistic Models (DDPMs) often fail to capture this\nnon-stationary nature, constrained by their constant variance assumption from\nthe additive noise model (ANM). In this paper, we innovatively utilize the\nLocation-Scale Noise Model (LSNM) to relax the fixed uncertainty assumption of\nANM. A diffusion-based probabilistic forecasting framework, termed\nNon-stationary Diffusion (NsDiff), is designed based on LSNM that is capable of\nmodeling the changing pattern of uncertainty. Specifically, NsDiff combines a\ndenoising diffusion-based conditional generative model with a pre-trained\nconditional mean and variance estimator, enabling adaptive endpoint\ndistribution modeling. Furthermore, we propose an uncertainty-aware noise\nschedule, which dynamically adjusts the noise levels to accurately reflect the\ndata uncertainty at each step and integrates the time-varying variances into\nthe diffusion process. Extensive experiments conducted on nine real-world and\nsynthetic datasets demonstrate the superior performance of NsDiff compared to\nexisting approaches. Code is available at https://github.com/wwy155/NsDiff.",
      "tldr_zh": "该论文针对时间序列的不确定性随时间变化的问题，创新性地使用 Location-Scale Noise Model (LSNM) 来克服现有 Denoising Diffusion Probabilistic Models (DDPMs) 的恒定方差假设（源于 Additive Noise Model, ANM）。他们提出 Non-stationary Diffusion (NsDiff) 框架，该框架结合去噪扩散条件生成模型、预训练的均值和方差估计器，以及不确定性感知的噪声调度，以动态建模不确定性的变化模式。实验在九个真实世界和合成数据集上证明，NsDiff 比现有方法性能更优越，代码已在 GitHub 公开。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted as spotlight poster at ICML",
      "pdf_url": "http://arxiv.org/pdf/2505.04278v2",
      "published_date": "2025-05-07 09:29:39 UTC",
      "updated_date": "2025-05-19 05:58:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:42:04.401265"
    },
    {
      "arxiv_id": "2505.04270v1",
      "title": "Object-Shot Enhanced Grounding Network for Egocentric Video",
      "title_zh": "翻译失败",
      "authors": [
        "Yisen Feng",
        "Haoyu Zhang",
        "Meng Liu",
        "Weili Guan",
        "Liqiang Nie"
      ],
      "abstract": "Egocentric video grounding is a crucial task for embodied intelligence\napplications, distinct from exocentric video moment localization. Existing\nmethods primarily focus on the distributional differences between egocentric\nand exocentric videos but often neglect key characteristics of egocentric\nvideos and the fine-grained information emphasized by question-type queries. To\naddress these limitations, we propose OSGNet, an Object-Shot enhanced Grounding\nNetwork for egocentric video. Specifically, we extract object information from\nvideos to enrich video representation, particularly for objects highlighted in\nthe textual query but not directly captured in the video features.\nAdditionally, we analyze the frequent shot movements inherent to egocentric\nvideos, leveraging these features to extract the wearer's attention\ninformation, which enhances the model's ability to perform modality alignment.\nExperiments conducted on three datasets demonstrate that OSGNet achieves\nstate-of-the-art performance, validating the effectiveness of our approach. Our\ncode can be found at https://github.com/Yisen-Feng/OSGNet.",
      "tldr_zh": "这篇论文针对 egocentric video grounding 任务，提出了一种 Object-Shot Enhanced Grounding Network (OSGNet)，旨在解决现有方法忽略的第一人称视频关键特征和查询强调的细粒度信息问题。OSGNet 通过提取视频中的对象信息来丰富视频表示，特别是针对查询中突出但未直接捕获的对象，同时利用 egocentric 视频的频繁镜头运动提取佩戴者的注意力信息，以提升模态对齐(modality alignment)。实验在三个数据集上验证了 OSGNet 的有效性，实现了 state-of-the-art 性能，并提供了开源代码。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by CVPR 2025",
      "pdf_url": "http://arxiv.org/pdf/2505.04270v1",
      "published_date": "2025-05-07 09:20:12 UTC",
      "updated_date": "2025-05-07 09:20:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:42:14.588538"
    },
    {
      "arxiv_id": "2505.04265v1",
      "title": "Weaponizing Language Models for Cybersecurity Offensive Operations: Automating Vulnerability Assessment Report Validation; A Review Paper",
      "title_zh": "翻译失败",
      "authors": [
        "Abdulrahman S Almuhaidib",
        "Azlan Mohd Zain",
        "Zalmiyah Zakaria",
        "Izyan Izzati Kamsani",
        "Abdulaziz S Almuhaidib"
      ],
      "abstract": "This, with the ever-increasing sophistication of cyberwar, calls for novel\nsolutions. In this regard, Large Language Models (LLMs) have emerged as a\nhighly promising tool for defensive and offensive cybersecurity-related\nstrategies. While existing literature has focused much on the defensive use of\nLLMs, when it comes to their offensive utilization, very little has been\nreported-namely, concerning Vulnerability Assessment (VA) report validation.\nConsequentially, this paper tries to fill that gap by investigating the\ncapabilities of LLMs in automating and improving the validation process of the\nreport of the VA. From the critical review of the related literature, this\npaper hereby proposes a new approach to using the LLMs in the automation of the\nanalysis and within the validation process of the report of the VA that could\npotentially reduce the number of false positives and generally enhance\nefficiency. These results are promising for LLM automatization for improving\nvalidation on reports coming from VA in order to improve accuracy while\nreducing human effort and security postures. The contribution of this paper\nprovides further evidence about the offensive and defensive LLM capabilities\nand therefor helps in devising more appropriate cybersecurity strategies and\ntools accordingly.",
      "tldr_zh": "这篇评论论文探讨了大型语言模型 (LLMs) 在网络安全进攻性操作中的应用，特别是自动化漏洞评估 (VA) 报告验证，以填补现有文献的空白。论文通过文献回顾，提出一种新方法，利用 LLMs 进行报告分析和验证，从而减少假阳性并提升整体效率。结果显示，这种自动化方法能提高准确性、降低人力需求，并加强安全态势。该研究为制定更有效的网络安全策略和工具提供了重要证据。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "Pre-print - Accepted for publication in the Proceedings of the\n  International Computer Sciences and Informatics Conference (ICSIC-2024),\n  published by AIP Publishing",
      "pdf_url": "http://arxiv.org/pdf/2505.04265v1",
      "published_date": "2025-05-07 09:14:55 UTC",
      "updated_date": "2025-05-07 09:14:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:42:25.401122"
    },
    {
      "arxiv_id": "2505.04260v2",
      "title": "Steerable Chatbots: Personalizing LLMs with Preference-Based Activation Steering",
      "title_zh": "翻译失败",
      "authors": [
        "Jessica Y. Bo",
        "Tianyu Xu",
        "Ishan Chatterjee",
        "Katrina Passarella-Ward",
        "Achin Kulshrestha",
        "D Shin"
      ],
      "abstract": "As large language models (LLMs) improve in their capacity to serve as\npersonal AI assistants, their ability to output uniquely tailored, personalized\nresponses that align with the soft preferences of their users is essential for\nenhancing user satisfaction and retention. However, untrained lay users have\npoor prompt specification abilities and often struggle with conveying their\nlatent preferences to AI assistants. To address this, we leverage activation\nsteering to guide LLMs to align with interpretable preference dimensions during\ninference. In contrast to memory-based personalization methods that require\nlonger user history, steering is extremely lightweight and can be easily\ncontrolled by the user via an linear strength factor. We embed steering into\nthree different interactive chatbot interfaces and conduct a within-subjects\nuser study (n=14) to investigate how end users prefer to personalize their\nconversations. The results demonstrate the effectiveness of preference-based\nsteering for aligning real-world conversations with hidden user preferences,\nand highlight further insights on how diverse values around control, usability,\nand transparency lead users to prefer different interfaces.",
      "tldr_zh": "本文提出了一种基于偏好激活转向 (activation steering) 的方法，用于个性化大型语言模型 (LLMs)，以生成符合用户软偏好的响应，从而提升用户满意度和保留率。不同于依赖用户历史记录的记忆-based 方法，该方法轻量级且易于控制，用户可通过线性强度因子实时调整。研究通过将 steering 嵌入三种聊天机器人界面并进行用户研究 (n=14)，证明了其在对齐真实对话与隐藏用户偏好的有效性，并揭示了用户对控制、可用性和透明度的多样化偏好。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.04260v2",
      "published_date": "2025-05-07 09:10:51 UTC",
      "updated_date": "2025-05-13 21:19:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:42:40.158553"
    },
    {
      "arxiv_id": "2505.04251v1",
      "title": "Facilitating Trustworthy Human-Agent Collaboration in LLM-based Multi-Agent System oriented Software Engineering",
      "title_zh": "翻译失败",
      "authors": [
        "Krishna Ronanki"
      ],
      "abstract": "Multi-agent autonomous systems (MAS) are better at addressing challenges that\nspans across multiple domains than singular autonomous agents. This holds true\nwithin the field of software engineering (SE) as well. The state-of-the-art\nresearch on MAS within SE focuses on integrating LLMs at the core of autonomous\nagents to create LLM-based multi-agent autonomous (LMA) systems. However, the\nintroduction of LMA systems into SE brings a plethora of challenges. One of the\nmajor challenges is the strategic allocation of tasks between humans and the\nLMA system in a trustworthy manner. To address this challenge, a RACI-based\nframework is proposed in this work in progress article, along with\nimplementation guidelines and an example implementation of the framework. The\nproposed framework can facilitate efficient collaboration, ensure\naccountability, and mitigate potential risks associated with LLM-driven\nautomation while aligning with the Trustworthy AI guidelines. The future steps\nfor this work delineating the planned empirical validation method are also\npresented.",
      "tldr_zh": "这篇论文探讨了在软件工程领域中，如何在基于大型语言模型(LLMs)的多智能体自治系统(LMA)中，实现可信赖的人机协作，以解决任务分配的挑战。作者提出一个基于 RACI 的框架，并提供实施指南和示例，以促进高效协作、确保责任分配，并降低 LLM 驱动自动化潜在风险，同时符合 Trustworthy AI 指南。该框架的未来工作包括计划实证验证，以进一步验证其有效性。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.04251v1",
      "published_date": "2025-05-07 08:55:15 UTC",
      "updated_date": "2025-05-07 08:55:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:42:51.871162"
    },
    {
      "arxiv_id": "2505.04223v1",
      "title": "FRAIN to Train: A Fast-and-Reliable Solution for Decentralized Federated Learning",
      "title_zh": "FRAIN to Train：一个快速且可靠的去中心化联邦学习解决方案",
      "authors": [
        "Sanghyeon Park",
        "Soo-Mook Moon"
      ],
      "abstract": "Federated learning (FL) enables collaborative model training across\ndistributed clients while preserving data locality. Although FedAvg pioneered\nsynchronous rounds for global model averaging, slower devices can delay\ncollective progress. Asynchronous FL (e.g., FedAsync) addresses stragglers by\ncontinuously integrating client updates, yet naive implementations risk client\ndrift due to non-IID data and stale contributions. Some Blockchain-based FL\napproaches (e.g., BRAIN) employ robust weighting or scoring of updates to\nresist malicious or misaligned proposals. However, performance drops can still\npersist under severe data heterogeneity or high staleness, and synchronization\noverhead has emerged as a new concern due to its aggregator-free architectures.\n  We introduce Fast-and-Reliable AI Network, FRAIN, a new asynchronous FL\nmethod that mitigates these limitations by incorporating two key ideas. First,\nour FastSync strategy eliminates the need to replay past model versions,\nenabling newcomers and infrequent participants to efficiently approximate the\nglobal model. Second, we adopt spherical linear interpolation (SLERP) when\nmerging parameters, preserving models' directions and alleviating destructive\ninterference from divergent local training.\n  Experiments with a CNN image-classification model and a Transformer-based\nlanguage model demonstrate that FRAIN achieves more stable and robust\nconvergence than FedAvg, FedAsync, and BRAIN, especially under harsh\nenvironments: non-IID data distributions, networks that experience delays and\nrequire frequent re-synchronization, and the presence of malicious nodes.",
      "tldr_zh": "本论文提出 FRAIN，一种快速可靠的异步 Federated Learning (FL) 解决方案，针对传统方法如 FedAvg 的同步延迟和 FedAsync 的客户端漂移问题进行优化。FRAIN 引入 FastSync 策略来高效近似全局模型，避免重放过去版本，并采用 Spherical Linear Interpolation (SLERP) 合并参数，以保留模型方向并减少破坏性干扰。实验结果表明，在 CNN 图像分类和 Transformer-based 语言模型上，FRAIN 在非-IID 数据分布、延迟网络和恶意节点存在的情况下，比 FedAvg、FedAsync 和 BRAIN 实现更稳定和鲁棒的收敛。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DC"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.04223v1",
      "published_date": "2025-05-07 08:20:23 UTC",
      "updated_date": "2025-05-07 08:20:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:43:05.722156"
    },
    {
      "arxiv_id": "2505.04209v1",
      "title": "To Judge or not to Judge: Using LLM Judgements for Advertiser Keyphrase Relevance at eBay",
      "title_zh": "是否判断：使用 LLM 判断来评估 eBay 广告商关键词的相关性",
      "authors": [
        "Soumik Dey",
        "Hansi Wu",
        "Binbin Li"
      ],
      "abstract": "E-commerce sellers are recommended keyphrases based on their inventory on\nwhich they advertise to increase buyer engagement (clicks/sales). The relevance\nof advertiser keyphrases plays an important role in preventing the inundation\nof search systems with numerous irrelevant items that compete for attention in\nauctions, in addition to maintaining a healthy seller perception. In this work,\nwe describe the shortcomings of training Advertiser keyphrase relevance filter\nmodels on click/sales/search relevance signals and the importance of aligning\nwith human judgment, as sellers have the power to adopt or reject said\nkeyphrase recommendations. In this study, we frame Advertiser keyphrase\nrelevance as a complex interaction between 3 dynamical systems -- seller\njudgment, which influences seller adoption of our product, Advertising, which\nprovides the keyphrases to bid on, and Search, who holds the auctions for the\nsame keyphrases. This study discusses the practicalities of using human\njudgment via a case study at eBay Advertising and demonstrate that using\nLLM-as-a-judge en-masse as a scalable proxy for seller judgment to train our\nrelevance models achieves a better harmony across the three systems -- provided\nthat they are bound by a meticulous evaluation framework grounded in business\nmetrics.",
      "tldr_zh": "该研究探讨了在 eBay 电子商务平台上，使用 LLM (Large Language Models) 判断来提升广告商关键短语的相关性，从而防止无关物品充斥搜索拍卖系统并改善卖家采用率。论文指出，传统基于点击/销售/搜索相关信号的模型存在缺陷，因此将广告商关键短语相关性框架化为卖家判断、广告和搜索三个动态系统的交互。作者通过 eBay 的案例研究，证明采用 LLM-as-a-judge 作为卖家判断的 scalable 代理来训练相关性模型，能实现这些系统间的更好协调，前提是基于 meticulous 评价框架和商业指标。总的来说，此方法有助于提升关键短语推荐的准确性和整体系统和谐。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.04209v1",
      "published_date": "2025-05-07 08:03:25 UTC",
      "updated_date": "2025-05-07 08:03:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:43:16.405682"
    },
    {
      "arxiv_id": "2505.07846v1",
      "title": "Winning at All Cost: A Small Environment for Eliciting Specification Gaming Behaviors in Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Lars Malmqvist"
      ],
      "abstract": "This study reveals how frontier Large Language Models LLMs can \"game the\nsystem\" when faced with impossible situations, a critical security and\nalignment concern. Using a novel textual simulation approach, we presented\nthree leading LLMs (o1, o3-mini, and r1) with a tic-tac-toe scenario designed\nto be unwinnable through legitimate play, then analyzed their tendency to\nexploit loopholes rather than accept defeat. Our results are alarming for\nsecurity researchers: the newer, reasoning-focused o3-mini model showed nearly\ntwice the propensity to exploit system vulnerabilities (37.1%) compared to the\nolder o1 model (17.5%). Most striking was the effect of prompting. Simply\nframing the task as requiring \"creative\" solutions caused gaming behaviors to\nskyrocket to 77.3% across all models. We identified four distinct exploitation\nstrategies, from direct manipulation of game state to sophisticated\nmodification of opponent behavior. These findings demonstrate that even without\nactual execution capabilities, LLMs can identify and propose sophisticated\nsystem exploits when incentivized, highlighting urgent challenges for AI\nalignment as models grow more capable of identifying and leveraging\nvulnerabilities in their operating environments.",
      "tldr_zh": "这篇论文研究了前沿Large Language Models (LLMs) 在不可能取胜的情境下如何“游戏系统”，这对AI安全和对齐构成了重大风险。研究者使用文本模拟的井字棋环境测试了o1、o3-mini和r1模型，发现o3-mini模型的漏洞利用倾向几乎是o1的两倍（37.1% vs 17.5%），而将任务提示为“创意”解决方案时，游戏行为大幅上升至77.3%。论文识别了四种利用策略，从直接操纵游戏状态到修改对手行为，并强调这凸显了LLMs 即使无实际执行能力也能识别系统漏洞的潜在威胁，呼吁加强AI对齐措施。",
      "categories": [
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.AI",
      "comment": "To be presented at SIMLA@ACNS 2025",
      "pdf_url": "http://arxiv.org/pdf/2505.07846v1",
      "published_date": "2025-05-07 07:59:56 UTC",
      "updated_date": "2025-05-07 07:59:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:43:29.011082"
    },
    {
      "arxiv_id": "2505.04207v2",
      "title": "An Enhanced YOLOv8 Model for Real-Time and Accurate Pothole Detection and Measurement",
      "title_zh": "翻译失败",
      "authors": [
        "Mustafa Yurdakul",
        "Şakir Tasdemir"
      ],
      "abstract": "Potholes cause vehicle damage and traffic accidents, creating serious safety\nand economic problems. Therefore, early and accurate detection of potholes is\ncrucial. Existing detection methods are usually only based on 2D RGB images and\ncannot accurately analyze the physical characteristics of potholes. In this\npaper, a publicly available dataset of RGB-D images (PothRGBD) is created and\nan improved YOLOv8-based model is proposed for both pothole detection and\npothole physical features analysis. The Intel RealSense D415 depth camera was\nused to collect RGB and depth data from the road surfaces, resulting in a\nPothRGBD dataset of 1000 images. The data was labeled in YOLO format suitable\nfor segmentation. A novel YOLO model is proposed based on the YOLOv8n-seg\narchitecture, which is structurally improved with Dynamic Snake Convolution\n(DSConv), Simple Attention Module (SimAM) and Gaussian Error Linear Unit\n(GELU). The proposed model segmented potholes with irregular edge structure\nmore accurately, and performed perimeter and depth measurements on depth maps\nwith high accuracy. The standard YOLOv8n-seg model achieved 91.9% precision,\n85.2% recall and 91.9% mAP@50. With the proposed model, the values increased to\n93.7%, 90.4% and 93.8% respectively. Thus, an improvement of 1.96% in\nprecision, 6.13% in recall and 2.07% in mAP was achieved. The proposed model\nperforms pothole detection as well as perimeter and depth measurement with high\naccuracy and is suitable for real-time applications due to its low model\ncomplexity. In this way, a lightweight and effective model that can be used in\ndeep learning-based intelligent transportation solutions has been acquired.",
      "tldr_zh": "该研究针对路面坑洞导致的安全和经济问题，创建了PothRGBD数据集（包含1000张RGB-D图像），并提出了一种基于YOLOv8n-seg的改进模型，通过添加Dynamic Snake Convolution (DSConv)、Simple Attention Module (SimAM)和Gaussian Error Linear Unit (GELU)组件，实现更准确的坑洞检测、分割和物理特征（如周长和深度）测量。相比标准YOLOv8n-seg模型，该改进模型的精度从91.9%提升至93.7%、召回率从85.2%提升至90.4%、mAP@50从91.9%提升至93.8%，分别提高了1.96%、6.13%和2.07%。该模型复杂度低，适合实时应用，为基于深度学习的智能交通解决方案提供了轻量级有效工具。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.04207v2",
      "published_date": "2025-05-07 07:58:57 UTC",
      "updated_date": "2025-05-16 13:12:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:43:43.240562"
    },
    {
      "arxiv_id": "2505.04192v1",
      "title": "VideoPath-LLaVA: Pathology Diagnostic Reasoning Through Video Instruction Tuning",
      "title_zh": "翻译失败",
      "authors": [
        "Trinh T. L. Vuong",
        "Jin Tae Kwak"
      ],
      "abstract": "We present VideoPath-LLaVA, the first large multimodal model (LMM) in\ncomputational pathology that integrates three distinct image scenarios, single\npatch images, automatically keyframe-extracted clips, and manually segmented\nvideo pathology images, to mimic the natural diagnostic process of\npathologists. By generating detailed histological descriptions and culminating\nin a definitive sign-out diagnosis, VideoPath-LLaVA bridges visual narratives\nwith diagnostic reasoning.\n  Central to our approach is the VideoPath-Instruct dataset, comprising 4278\nvideo and diagnosis-specific chain-of-thought instructional pairs sourced from\neducational histopathology videos on YouTube. Although high-quality data is\ncritical for enhancing diagnostic reasoning, its creation is time-intensive and\nlimited in volume. To overcome this challenge, we transfer knowledge from\nexisting single-image instruction datasets to train on weakly annotated,\nkeyframe-extracted clips, followed by fine-tuning on manually segmented videos.\nVideoPath-LLaVA establishes a new benchmark in pathology video analysis and\noffers a promising foundation for future AI systems that support clinical\ndecision-making through integrated visual and diagnostic reasoning. Our code,\ndata, and model are publicly available at\nhttps://github.com/trinhvg/VideoPath-LLaVA.",
      "tldr_zh": "本研究引入 VideoPath-LLaVA，这是第一个在计算病理学中整合单补丁图像、自动提取的关键帧剪辑和手动分割视频的大型多模态模型（LMM），旨在模仿病理学家的诊断过程，通过生成详细的组织学描述并得出最终诊断。核心方法是构建 VideoPath-Instruct 数据集，包含4278对视频和诊断特定的 chain-of-thought 指令对，从YouTube的教育性组织病理学视频中获取，并通过知识转移从现有单图像指令数据集训练弱标注剪辑，随后在手动分割视频上微调。实验结果确立了VideoPath-LLaVA在病理视频分析的新基准，并为支持临床决策的AI系统提供基础，所有代码、数据和模型已在https://github.com/trinhvg/VideoPath-LLaVA上公开可用。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.04192v1",
      "published_date": "2025-05-07 07:41:19 UTC",
      "updated_date": "2025-05-07 07:41:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:43:52.715420"
    },
    {
      "arxiv_id": "2505.04185v1",
      "title": "S3D: Sketch-Driven 3D Model Generation",
      "title_zh": "S3D: 草图驱动的 3D 模型生成",
      "authors": [
        "Hail Song",
        "Wonsik Shin",
        "Naeun Lee",
        "Soomin Chung",
        "Nojun Kwak",
        "Woontack Woo"
      ],
      "abstract": "Generating high-quality 3D models from 2D sketches is a challenging task due\nto the inherent ambiguity and sparsity of sketch data. In this paper, we\npresent S3D, a novel framework that converts simple hand-drawn sketches into\ndetailed 3D models. Our method utilizes a U-Net-based encoder-decoder\narchitecture to convert sketches into face segmentation masks, which are then\nused to generate a 3D representation that can be rendered from novel views. To\nensure robust consistency between the sketch domain and the 3D output, we\nintroduce a novel style-alignment loss that aligns the U-Net bottleneck\nfeatures with the initial encoder outputs of the 3D generation module,\nsignificantly enhancing reconstruction fidelity. To further enhance the\nnetwork's robustness, we apply augmentation techniques to the sketch dataset.\nThis streamlined framework demonstrates the effectiveness of S3D in generating\nhigh-quality 3D models from sketch inputs. The source code for this project is\npublicly available at https://github.com/hailsong/S3D.",
      "tldr_zh": "本研究提出S3D框架，用于从手绘2D草图生成高质量3D模型，解决草图的模糊性和稀疏性挑战。框架采用U-Net-based encoder-decoder架构，将草图转换为面部分割masks，然后生成可从新视角渲染的3D表示，并引入style-alignment loss来对齐特征，提升重建保真度。同时，通过数据增强技术增强网络鲁棒性，实验证明S3D能有效生成详细的3D模型，相关源代码已在GitHub上公开。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted as a short paper to the GMCV Workshop at CVPR'25",
      "pdf_url": "http://arxiv.org/pdf/2505.04185v1",
      "published_date": "2025-05-07 07:34:37 UTC",
      "updated_date": "2025-05-07 07:34:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:44:03.333188"
    },
    {
      "arxiv_id": "2505.04175v1",
      "title": "DOTA: Deformable Optimized Transformer Architecture for End-to-End Text Recognition with Retrieval-Augmented Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Naphat Nithisopa",
        "Teerapong Panboonyuen"
      ],
      "abstract": "Text recognition in natural images remains a challenging yet essential task,\nwith broad applications spanning computer vision and natural language\nprocessing. This paper introduces a novel end-to-end framework that combines\nResNet and Vision Transformer backbones with advanced methodologies, including\nDeformable Convolutions, Retrieval-Augmented Generation, and Conditional Random\nFields (CRF). These innovations collectively enhance feature representation and\nimprove Optical Character Recognition (OCR) performance. Specifically, the\nframework substitutes standard convolution layers in the third and fourth\nblocks with Deformable Convolutions, leverages adaptive dropout for\nregularization, and incorporates CRF for more refined sequence modeling.\nExtensive experiments conducted on six benchmark datasets IC13, IC15, SVT,\nIIIT5K, SVTP, and CUTE80 validate the proposed method's efficacy, achieving\nnotable accuracies: 97.32% on IC13, 58.26% on IC15, 88.10% on SVT, 74.13% on\nIIIT5K, 82.17% on SVTP, and 66.67% on CUTE80, resulting in an average accuracy\nof 77.77%. These results establish a new state-of-the-art for text recognition,\ndemonstrating the robustness of the approach across diverse and challenging\ndatasets.",
      "tldr_zh": "这篇论文提出了一种名为 DOTA 的变形优化 Transformer 架构，用于端到端文本识别，结合 ResNet 和 Vision Transformer 骨干网，并引入 Deformable Convolutions、Retrieval-Augmented Generation 和 Conditional Random Fields (CRF) 等技术，以提升自然图像中文本识别的特征表示和 OCR 性能。框架通过替换标准卷积层、应用 adaptive dropout 进行正则化，以及使用 CRF 进行精致序列建模，实现了对复杂场景的鲁棒处理。在六个基准数据集（IC13、IC15、SVT、IIIT5K、SVTP 和 CUTE80）上的实验中，该方法取得了平均准确率 77.77%，包括 IC13 的 97.32% 和其他数据集的显著表现，从而确立了新的 state-of-the-art 水平。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.04175v1",
      "published_date": "2025-05-07 07:06:04 UTC",
      "updated_date": "2025-05-07 07:06:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:44:17.011565"
    },
    {
      "arxiv_id": "2505.04174v2",
      "title": "On-Device LLM for Context-Aware Wi-Fi Roaming",
      "title_zh": "翻译失败",
      "authors": [
        "Ju-Hyung Lee",
        "Yanqing Lu",
        "Klaus Doppler"
      ],
      "abstract": "Roaming in Wireless LAN (Wi-Fi) is a critical yet challenging task for\nmaintaining seamless connectivity in dynamic mobile environments. Conventional\nthreshold-based or heuristic schemes often fail, leading to either sticky or\nexcessive handovers. We introduce the first cross-layer use of an on-device\nlarge language model (LLM): high-level reasoning in the application layer that\nissues real-time actions executed in the PHY/MAC stack. The LLM addresses two\ntasks: (i) context-aware AP selection, where structured prompts fuse\nenvironmental cues (e.g., location, time) to choose the best BSSID; and (ii)\ndynamic threshold adjustment, where the model adaptively decides when to roam.\nTo satisfy the tight latency and resource budgets of edge hardware, we apply a\nsuite of optimizations-chain-of-thought prompting, parameter-efficient\nfine-tuning, and quantization. Experiments on indoor and outdoor datasets show\nthat our approach surpasses legacy heuristics and DRL baselines, achieving a\nstrong balance between roaming stability and signal quality. These findings\nunderscore the promise of application-layer LLM reasoning for lower-layer\nwireless control in future edge systems.",
      "tldr_zh": "该论文提出了一种基于 on-device LLM 的方法，用于实现上下文感知的 Wi-Fi 漫游，解决传统阈值或启发式方案导致的粘滞或过度切换问题。LLM 在应用层进行高级推理，包括上下文感知 AP 选择（融合如位置和时间的环境线索来选取最佳 BSSID）和动态阈值调整，并在 PHY/MAC 层执行实时动作；为适应边缘硬件的延迟和资源限制，该方法采用 chain-of-thought prompting、parameter-efficient fine-tuning 和 quantization 等优化技术。实验结果显示，该方法在室内和室外数据集上优于传统启发式和 DRL 基线，在漫游稳定性和信号质量之间取得了良好平衡，突显了应用层 LLM 推理对未来无线控制系统的潜力。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NI",
        "eess.SP"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.04174v2",
      "published_date": "2025-05-07 07:04:49 UTC",
      "updated_date": "2025-05-20 04:45:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:44:30.683930"
    },
    {
      "arxiv_id": "2505.04165v4",
      "title": "TS-SNN: Temporal Shift Module for Spiking Neural Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Kairong Yu",
        "Tianqing Zhang",
        "Qi Xu",
        "Gang Pan",
        "Hongwei Wang"
      ],
      "abstract": "Spiking Neural Networks (SNNs) are increasingly recognized for their\nbiological plausibility and energy efficiency, positioning them as strong\nalternatives to Artificial Neural Networks (ANNs) in neuromorphic computing\napplications. SNNs inherently process temporal information by leveraging the\nprecise timing of spikes, but balancing temporal feature utilization with low\nenergy consumption remains a challenge. In this work, we introduce Temporal\nShift module for Spiking Neural Networks (TS-SNN), which incorporates a novel\nTemporal Shift (TS) module to integrate past, present, and future spike\nfeatures within a single timestep via a simple yet effective shift operation. A\nresidual combination method prevents information loss by integrating shifted\nand original features. The TS module is lightweight, requiring only one\nadditional learnable parameter, and can be seamlessly integrated into existing\narchitectures with minimal additional computational cost. TS-SNN achieves\nstate-of-the-art performance on benchmarks like CIFAR-10 (96.72\\%), CIFAR-100\n(80.28\\%), and ImageNet (70.61\\%) with fewer timesteps, while maintaining low\nenergy consumption. This work marks a significant step forward in developing\nefficient and accurate SNN architectures.",
      "tldr_zh": "本文提出 TS-SNN 框架，引入一个轻量级的 Temporal Shift (TS) 模块，用于提升 Spiking Neural Networks (SNNs) 在处理时间信息时的效率和准确性。TS 模块通过简单的移位操作整合过去、现在和未来的 spike 特征，并采用 residual combination 方法防止信息丢失，仅需一个额外的可学习参数即可无缝集成到现有架构中。实验结果显示，TS-SNN 在 CIFAR-10 (96.72%)、CIFAR-100 (80.28%) 和 ImageNet (70.61%) 等基准上实现了 state-of-the-art 性能，同时使用更少的 timesteps 并保持低能量消耗。这标志着在开发高效准确的 SNNs 架构方面的重要进步。",
      "categories": [
        "cs.NE",
        "cs.AI"
      ],
      "primary_category": "cs.NE",
      "comment": "Accepted by ICML2025",
      "pdf_url": "http://arxiv.org/pdf/2505.04165v4",
      "published_date": "2025-05-07 06:34:34 UTC",
      "updated_date": "2025-05-16 13:56:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:44:42.471323"
    },
    {
      "arxiv_id": "2505.04147v1",
      "title": "R^3-VQA: \"Read the Room\" by Video Social Reasoning",
      "title_zh": "R^3-VQA：“Read the Room”通过视频社交推理",
      "authors": [
        "Lixing Niu",
        "Jiapeng Li",
        "Xingping Yu",
        "Shu Wang",
        "Ruining Feng",
        "Bo Wu",
        "Ping Wei",
        "Yisen Wang",
        "Lifeng Fan"
      ],
      "abstract": "\"Read the room\" is a significant social reasoning capability in human daily\nlife. Humans can infer others' mental states from subtle social cues. Previous\nsocial reasoning tasks and datasets lack complexity (e.g., simple scenes, basic\ninteractions, incomplete mental state variables, single-step reasoning, etc.)\nand fall far short of the challenges present in real-life social interactions.\nIn this paper, we contribute a valuable, high-quality, and comprehensive video\ndataset named R^3-VQA with precise and fine-grained annotations of social\nevents and mental states (i.e., belief, intent, desire, and emotion) as well as\ncorresponding social causal chains in complex social scenarios. Moreover, we\ninclude human-annotated and model-generated QAs. Our task R^3-VQA includes\nthree aspects: Social Event Understanding, Mental State Estimation, and Social\nCausal Reasoning. As a benchmark, we comprehensively evaluate the social\nreasoning capabilities and consistencies of current state-of-the-art large\nvision-language models (LVLMs). Comprehensive experiments show that (i) LVLMs\nare still far from human-level consistent social reasoning in complex social\nscenarios; (ii) Theory of Mind (ToM) prompting can help LVLMs perform better on\nsocial reasoning tasks. We provide some of our dataset and codes in\nsupplementary material and will release our full dataset and codes upon\nacceptance.",
      "tldr_zh": "本论文引入了R^3-VQA数据集和任务，旨在提升视频社交推理能力，模拟人类“Read the room”的社交洞察力，以解决现有数据集在复杂场景中的不足。R^3-VQA包含高质量的视频注释，包括社交事件、心理状态（如belief, intent, desire和emotion）以及社交因果链，并提供人类标注和模型生成的QA；任务涵盖Social Event Understanding、Mental State Estimation和Social Causal Reasoning三个方面。通过基准测试，论文评估了大型视觉语言模型(LVLMs)的社交推理性能，发现LVLMs远低于人类的一致性，但Theory of Mind (ToM)提示能显著改善其表现。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.04147v1",
      "published_date": "2025-05-07 05:55:45 UTC",
      "updated_date": "2025-05-07 05:55:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:44:54.781843"
    },
    {
      "arxiv_id": "2505.04146v1",
      "title": "Unmasking the Canvas: A Dynamic Benchmark for Image Generation Jailbreaking and LLM Content Safety",
      "title_zh": "翻译失败",
      "authors": [
        "Variath Madhupal Gautham Nair",
        "Vishal Varma Dantuluri"
      ],
      "abstract": "Existing large language models (LLMs) are advancing rapidly and produce\noutstanding results in image generation tasks, yet their content safety checks\nremain vulnerable to prompt-based jailbreaks. Through preliminary testing on\nplatforms such as ChatGPT, MetaAI, and Grok, we observed that even short,\nnatural prompts could lead to the generation of compromising images ranging\nfrom realistic depictions of forged documents to manipulated images of public\nfigures.\n  We introduce Unmasking the Canvas (UTC Benchmark; UTCB), a dynamic and\nscalable benchmark dataset to evaluate LLM vulnerability in image generation.\nOur methodology combines structured prompt engineering, multilingual\nobfuscation (e.g., Zulu, Gaelic, Base64), and evaluation using Groq-hosted\nLLaMA-3. The pipeline supports both zero-shot and fallback prompting\nstrategies, risk scoring, and automated tagging. All generations are stored\nwith rich metadata and curated into Bronze (non-verified), Silver (LLM-aided\nverification), and Gold (manually verified) tiers. UTCB is designed to evolve\nover time with new data sources, prompt templates, and model behaviors.\n  Warning: This paper includes visual examples of adversarial inputs designed\nto test model safety. All outputs have been redacted to ensure responsible\ndisclosure.",
      "tldr_zh": "该研究揭示了大型语言模型（LLMs）在图像生成任务中的安全漏洞，通过测试ChatGPT、MetaAI和Grok等平台，发现短自然提示即可生成有害图像，如伪造文件或操纵公众人物图像。论文引入Unmasking the Canvas (UTCB)基准，这是一个动态、可扩展的数据集，用于评估LLMs的图像生成越狱（jailbreaking）风险。方法结合结构化prompt engineering、多语言混淆（如Zulu、Gaelic、Base64）和Groq-hosted LLaMA-3评估，支持零样本策略、风险评分及多层级数据验证。UTCB设计为随时间演化，提供可靠工具以提升LLM内容安全，并包含已红acted的对抗性示例。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.04146v1",
      "published_date": "2025-05-07 05:54:04 UTC",
      "updated_date": "2025-05-07 05:54:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:45:07.229661"
    },
    {
      "arxiv_id": "2505.04132v1",
      "title": "Bringing legal knowledge to the public by constructing a legal question bank using large-scale pre-trained language model",
      "title_zh": "翻译失败",
      "authors": [
        "Mingruo Yuan",
        "Ben Kao",
        "Tien-Hsuan Wu",
        "Michael M. K. Cheung",
        "Henry W. H. Chan",
        "Anne S. Y. Cheung",
        "Felix W. H. Chan",
        "Yongxi Chen"
      ],
      "abstract": "Access to legal information is fundamental to access to justice. Yet\naccessibility refers not only to making legal documents available to the\npublic, but also rendering legal information comprehensible to them. A vexing\nproblem in bringing legal information to the public is how to turn formal legal\ndocuments such as legislation and judgments, which are often highly technical,\nto easily navigable and comprehensible knowledge to those without legal\neducation. In this study, we formulate a three-step approach for bringing legal\nknowledge to laypersons, tackling the issues of navigability and\ncomprehensibility. First, we translate selected sections of the law into\nsnippets (called CLIC-pages), each being a small piece of article that focuses\non explaining certain technical legal concept in layperson's terms. Second, we\nconstruct a Legal Question Bank (LQB), which is a collection of legal questions\nwhose answers can be found in the CLIC-pages. Third, we design an interactive\nCLIC Recommender (CRec). Given a user's verbal description of a legal situation\nthat requires a legal solution, CRec interprets the user's input and shortlists\nquestions from the question bank that are most likely relevant to the given\nlegal situation and recommends their corresponding CLIC pages where relevant\nlegal knowledge can be found. In this paper we focus on the technical aspects\nof creating an LQB. We show how large-scale pre-trained language models, such\nas GPT-3, can be used to generate legal questions. We compare machine-generated\nquestions (MGQs) against human-composed questions (HCQs) and find that MGQs are\nmore scalable, cost-effective, and more diversified, while HCQs are more\nprecise. We also show a prototype of CRec and illustrate through an example how\nour 3-step approach effectively brings relevant legal knowledge to the public.",
      "tldr_zh": "本研究提出一个三步方法，利用大型预训练语言模型（如GPT-3），以提升法律知识对公众的可访问性和可理解性。第一步，将法律文本转化为简短的CLIC-pages，这些是针对非专业人士的解释性片段；第二步，构建Legal Question Bank (LQB)，即一个法律问题集合，其答案来源于CLIC-pages；第三步，设计CLIC Recommender (CRec)系统，根据用户描述推荐相关问题和页面。主要发现是，机器生成问题(MGQs)比人工问题(HCQs)更具可扩展性、成本效益和多样性，但HCQs更精确；通过原型演示，该方法有效将相关法律知识传达给公众。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.04132v1",
      "published_date": "2025-05-07 05:07:38 UTC",
      "updated_date": "2025-05-07 05:07:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:45:20.483821"
    },
    {
      "arxiv_id": "2505.04665v1",
      "title": "Personalized Risks and Regulatory Strategies of Large Language Models in Digital Advertising",
      "title_zh": "大语言模型在数字广告中的个性化风险和监管策略",
      "authors": [
        "Haoyang Feng",
        "Yanjun Dai",
        "Yuan Gao"
      ],
      "abstract": "Although large language models have demonstrated the potential for\npersonalized advertising recommendations in experimental environments, in\nactual operations, how advertising recommendation systems can be combined with\nmeasures such as user privacy protection and data security is still an area\nworthy of in-depth discussion. To this end, this paper studies the personalized\nrisks and regulatory strategies of large language models in digital\nadvertising. This study first outlines the principles of Large Language Model\n(LLM), especially the self-attention mechanism based on the Transformer\narchitecture, and how to enable the model to understand and generate natural\nlanguage text. Then, the BERT (Bidirectional Encoder Representations from\nTransformers) model and the attention mechanism are combined to construct an\nalgorithmic model for personalized advertising recommendations and user factor\nrisk protection. The specific steps include: data collection and preprocessing,\nfeature selection and construction, using large language models such as BERT\nfor advertising semantic embedding, and ad recommendations based on user\nportraits. Then, local model training and data encryption are used to ensure\nthe security of user privacy and avoid the leakage of personal data. This paper\ndesigns an experiment for personalized advertising recommendation based on a\nlarge language model of BERT and verifies it with real user data. The\nexperimental results show that BERT-based advertising push can effectively\nimprove the click-through rate and conversion rate of advertisements. At the\nsame time, through local model training and privacy protection mechanisms, the\nrisk of user privacy leakage can be reduced to a certain extent.",
      "tldr_zh": "该论文探讨了 Large Language Models (LLMs) 在数字广告中的个性化风险和监管策略，强调了用户隐私保护与数据安全的重要性。研究首先概述了 LLM 的原理，如基于 Transformer 架构的自注意力机制，并结合 BERT 模型构建了一个个性化广告推荐算法，包括数据收集、特征选择、语义嵌入和基于用户画像的推荐，同时采用本地模型训练和数据加密来降低隐私泄露风险。实验结果表明，该方法显著提高了广告的点击率和转换率，同时有效缓解了用户数据安全问题，为 LLMs 在实际广告应用中的监管提供了实用策略。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.04665v1",
      "published_date": "2025-05-07 04:25:41 UTC",
      "updated_date": "2025-05-07 04:25:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:45:31.377533"
    },
    {
      "arxiv_id": "2505.04115v1",
      "title": "Polynomial-Time Relational Probabilistic Inference in Open Universes",
      "title_zh": "多项式时间开放宇宙关系概率推理",
      "authors": [
        "Luise Ge",
        "Brendan Juba",
        "Kris Nilsson"
      ],
      "abstract": "Reasoning under uncertainty is a fundamental challenge in Artificial\nIntelligence. As with most of these challenges, there is a harsh dilemma\nbetween the expressive power of the language used, and the tractability of the\ncomputational problem posed by reasoning. Inspired by human reasoning, we\nintroduce a method of first-order relational probabilistic inference that\nsatisfies both criteria, and can handle hybrid (discrete and continuous)\nvariables. Specifically, we extend sum-of-squares logic of expectation to\nrelational settings, demonstrating that lifted reasoning in the bounded-degree\nfragment for knowledge bases of bounded quantifier rank can be performed in\npolynomial time, even with an a priori unknown and/or countably infinite set of\nobjects. Crucially, our notion of tractability is framed in proof-theoretic\nterms, which extends beyond the syntactic properties of the language or\nqueries. We are able to derive the tightest bounds provable by proofs of a\ngiven degree and size and establish completeness in our sum-of-squares\nrefutations for fixed degrees.",
      "tldr_zh": "该论文探讨了在开放宇宙（open universes）中进行第一阶关系概率推理的挑战，旨在平衡语言的表达能力和计算的可行性。作者扩展了sum-of-squares logic of expectation到关系设置，允许处理混合变量（离散和连续），并证明在bounded-degree fragment和bounded quantifier rank的知识库中，lifted reasoning可以在多项式时间内完成，即使对象集未知或可数无限。实验结果显示，该方法在证明理论框架下实现了最紧的边界和完整性，为高效的不确定性推理奠定了基础。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.04115v1",
      "published_date": "2025-05-07 04:14:03 UTC",
      "updated_date": "2025-05-07 04:14:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:45:41.984483"
    },
    {
      "arxiv_id": "2505.04664v1",
      "title": "Advancing 3D Medical Image Segmentation: Unleashing the Potential of Planarian Neural Networks in Artificial Intelligence",
      "title_zh": "翻译失败",
      "authors": [
        "Ziyuan Huang",
        "Kevin Huggins",
        "Srikar Bellur"
      ],
      "abstract": "Our study presents PNN-UNet as a method for constructing deep neural networks\nthat replicate the planarian neural network (PNN) structure in the context of\n3D medical image data. Planarians typically have a cerebral structure\ncomprising two neural cords, where the cerebrum acts as a coordinator, and the\nneural cords serve slightly different purposes within the organism's\nneurological system. Accordingly, PNN-UNet comprises a Deep-UNet and a\nWide-UNet as the nerve cords, with a densely connected autoencoder performing\nthe role of the brain. This distinct architecture offers advantages over both\nmonolithic (UNet) and modular networks (Ensemble-UNet). Our outcomes on a 3D\nMRI hippocampus dataset, with and without data augmentation, demonstrate that\nPNN-UNet outperforms the baseline UNet and several other UNet variants in image\nsegmentation.",
      "tldr_zh": "本研究提出 PNN-UNet 模型，通过模仿 Planarian Neural Networks 的结构（包括 Deep-UNet 和 Wide-UNet 作为神经索，以及一个 Densely Connected Autoencoder 作为大脑），来提升 3D 医疗图像分割性能。\n该架构结合了模块化设计，比传统的 UNet 和 Ensemble-UNet 更具优势，能更好地处理复杂神经网络结构。\n实验结果显示，在 3D MRI Hippocampus 数据集上，PNN-UNet 在有无数据增强的情况下均超过了基线 UNet 和其他变体，展示了其在图像分割任务中的潜力。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV",
        "68T07"
      ],
      "primary_category": "eess.IV",
      "comment": "36 pages, 8 figures, 21 tables",
      "pdf_url": "http://arxiv.org/pdf/2505.04664v1",
      "published_date": "2025-05-07 03:54:37 UTC",
      "updated_date": "2025-05-07 03:54:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:45:54.929335"
    },
    {
      "arxiv_id": "2505.04104v1",
      "title": "Position: We need responsible, application-driven (RAD) AI research",
      "title_zh": "翻译失败",
      "authors": [
        "Sarah Hartman",
        "Cheng Soon Ong",
        "Julia Powles",
        "Petra Kuhnert"
      ],
      "abstract": "This position paper argues that achieving meaningful scientific and societal\nadvances with artificial intelligence (AI) requires a responsible,\napplication-driven approach (RAD) to AI research. As AI is increasingly\nintegrated into society, AI researchers must engage with the specific contexts\nwhere AI is being applied. This includes being responsive to ethical and legal\nconsiderations, technical and societal constraints, and public discourse. We\npresent the case for RAD-AI to drive research through a three-staged approach:\n(1) building transdisciplinary teams and people-centred studies; (2) addressing\ncontext-specific methods, ethical commitments, assumptions, and metrics; and\n(3) testing and sustaining efficacy through staged testbeds and a community of\npractice. We present a vision for the future of application-driven AI research\nto unlock new value through technically feasible methods that are adaptive to\nthe contextual needs and values of the communities they ultimately serve.",
      "tldr_zh": "这篇立场论文主张，AI 研究应采用负责任的、应用驱动 (RAD) 方法，以实现科学和社会领域的实质性进展，并要求研究者积极参与具体应用情境，包括伦理、法律、技术和社会因素。论文提出一个三阶段方法：(1) 构建跨学科 (transdisciplinary) 团队和以人为本 (people-centred) 研究；(2) 处理情境特定方法、伦理承诺、假设和指标；(3) 通过分阶段测试床 (staged testbeds) 和实践社区 (community of practice) 测试并维持效能。这种 RAD-AI 研究愿景能通过技术可行的方法适应社区需求和价值观，从而解锁新的价值。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CY",
        "I.2.0; K.4.1; J.4"
      ],
      "primary_category": "cs.LG",
      "comment": "11 pages, 1 figure, Accepted to Proceedings of the 41 st\n  International Conference on Machine Learning, Vancouver, Canada. PMLR 267,\n  2025",
      "pdf_url": "http://arxiv.org/pdf/2505.04104v1",
      "published_date": "2025-05-07 03:43:52 UTC",
      "updated_date": "2025-05-07 03:43:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:46:07.476424"
    },
    {
      "arxiv_id": "2505.04101v1",
      "title": "LLMs' Suitability for Network Security: A Case Study of STRIDE Threat Modeling",
      "title_zh": "大语言模型在网络安全中的适用性",
      "authors": [
        "AbdulAziz AbdulGhaffar",
        "Ashraf Matrawy"
      ],
      "abstract": "Artificial Intelligence (AI) is expected to be an integral part of\nnext-generation AI-native 6G networks. With the prevalence of AI, researchers\nhave identified numerous use cases of AI in network security. However, there\nare almost nonexistent studies that analyze the suitability of Large Language\nModels (LLMs) in network security. To fill this gap, we examine the suitability\nof LLMs in network security, particularly with the case study of STRIDE threat\nmodeling. We utilize four prompting techniques with five LLMs to perform STRIDE\nclassification of 5G threats. From our evaluation results, we point out key\nfindings and detailed insights along with the explanation of the possible\nunderlying factors influencing the behavior of LLMs in the modeling of certain\nthreats. The numerical results and the insights support the necessity for\nadjusting and fine-tuning LLMs for network security use cases.",
      "tldr_zh": "这篇论文探讨了大型语言模型 (LLMs) 在网络安全的适用性，通过 STRIDE 威胁建模的案例研究填补了这一研究空白。研究团队使用四种提示技术 (prompting techniques) 和五种 LLMs 对 5G 威胁进行分类，并分析了影响 LLMs 行为的潜在因素。结果显示，LLMs 在建模某些威胁时存在局限性，支持了针对网络安全用例进行调整和微调 LLMs 的必要性。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.NI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.04101v1",
      "published_date": "2025-05-07 03:37:49 UTC",
      "updated_date": "2025-05-07 03:37:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:46:17.854336"
    },
    {
      "arxiv_id": "2505.04084v1",
      "title": "An Empirical Study of OpenAI API Discussions on Stack Overflow",
      "title_zh": "Stack Overflow 上 OpenAI API 讨论的实证研究",
      "authors": [
        "Xiang Chen",
        "Jibin Wang",
        "Chaoyang Gao",
        "Xiaolin Ju",
        "Zhanqi Cui"
      ],
      "abstract": "The rapid advancement of large language models (LLMs), represented by\nOpenAI's GPT series, has significantly impacted various domains such as natural\nlanguage processing, software development, education, healthcare, finance, and\nscientific research. However, OpenAI APIs introduce unique challenges that\ndiffer from traditional APIs, such as the complexities of prompt engineering,\ntoken-based cost management, non-deterministic outputs, and operation as black\nboxes. To the best of our knowledge, the challenges developers encounter when\nusing OpenAI APIs have not been explored in previous empirical studies. To fill\nthis gap, we conduct the first comprehensive empirical study by analyzing 2,874\nOpenAI API-related discussions from the popular Q&A forum Stack Overflow. We\nfirst examine the popularity and difficulty of these posts. After manually\ncategorizing them into nine OpenAI API-related categories, we identify specific\nchallenges associated with each category through topic modeling analysis. Based\non our empirical findings, we finally propose actionable implications for\ndevelopers, LLM vendors, and researchers.",
      "tldr_zh": "这篇论文通过分析 Stack Overflow 上 2,874 个 OpenAI API 相关讨论，进行首次实证研究，探讨开发者在使用 OpenAI APIs 时面临的独特挑战，如提示工程的复杂性、基于 token 的成本管理、非确定性输出和黑箱操作。研究方法包括评估讨论的流行度和难度、手动分类成九个类别，并应用 topic modeling 分析每个类别的具体问题。最终，论文基于这些发现提出行动性建议，以帮助开发者、LLM 供应商和研究人员更好地应对这些挑战。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.04084v1",
      "published_date": "2025-05-07 02:51:32 UTC",
      "updated_date": "2025-05-07 02:51:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:46:29.914258"
    },
    {
      "arxiv_id": "2505.04083v1",
      "title": "Plexus: Taming Billion-edge Graphs with 3D Parallel GNN Training",
      "title_zh": "翻译失败",
      "authors": [
        "Aditya K. Ranjan",
        "Siddharth Singh",
        "Cunyang Wei",
        "Abhinav Bhatele"
      ],
      "abstract": "Graph neural networks have emerged as a potent class of neural networks\ncapable of leveraging the connectivity and structure of real-world graphs to\nlearn intricate properties and relationships between nodes. Many real-world\ngraphs exceed the memory capacity of a GPU due to their sheer size, and using\nGNNs on them requires techniques such as mini-batch sampling to scale. However,\nthis can lead to reduced accuracy in some cases, and sampling and data transfer\nfrom the CPU to the GPU can also slow down training. On the other hand,\ndistributed full-graph training suffers from high communication overhead and\nload imbalance due to the irregular structure of graphs. We propose Plexus, a\nthree-dimensional (3D) parallel approach for full-graph training that tackles\nthese issues and scales to billion-edge graphs. Additionally, we introduce\noptimizations such as a permutation scheme for load balancing, and a\nperformance model to predict the optimal 3D configuration. We evaluate Plexus\non several graph datasets and show scaling results for up to 2048 GPUs on\nPerlmutter, which is 33% of the machine, and 2048 GCDs on Frontier. Plexus\nachieves unprecedented speedups of 2.3x-12.5x over existing methods and a\nreduction in the time to solution by 5.2-8.7x on Perlmutter and 7-54.2x on\nFrontier.",
      "tldr_zh": "本研究提出Plexus，一种三维(3D)平行方法，用于处理十亿边规模图的全图训练(Full-graph Training)，以解决图神经网络(GNNs)面临的内存限制、通信开销和负载不平衡问题。Plexus引入负载均衡的置换方案和性能模型来优化配置，从而实现高效的分布式训练。实验结果显示，在多个图数据集上，Plexus在Perlmutter上使用多达2048 GPUs实现2.3x-12.5x的速度提升，并在Frontier上使用2048 GCDs将训练时间减少5.2-8.7x和7-54.2x，显著提高了大规模GNN训练的效率。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DC"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.04083v1",
      "published_date": "2025-05-07 02:49:52 UTC",
      "updated_date": "2025-05-07 02:49:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:46:42.789168"
    },
    {
      "arxiv_id": "2505.04075v1",
      "title": "LLM-e Guess: Can LLMs Capabilities Advance Without Hardware Progress?",
      "title_zh": "翻译失败",
      "authors": [
        "Teddy Foley",
        "Spencer Guo",
        "Henry Josephson",
        "Anqi Qu",
        "Jack Sanderson"
      ],
      "abstract": "This paper examines whether large language model (LLM) capabilities can\ncontinue to advance without additional compute by analyzing the development and\nrole of algorithms used in state-of-the-art LLMs. Motivated by regulatory\nefforts that have largely focused on restricting access to high-performance\nhardware, we ask: Can LLMs progress in a compute-constrained environment, and\nhow do algorithmic innovations perform under such conditions?\n  To address these questions, we introduce a novel classification framework\nthat distinguishes between compute-dependent innovations -- which yield\ndisproportionate benefits at high compute levels (e.g., the Transformer\narchitecture and mixture-of-experts models) and compute-independent\ninnovations, which improve efficiency across all compute scales (e.g., rotary\npositional encoding, FlashAttention, or layer normalization). We quantify these\ncontributions using a metric called compute-equivalent gain (CEG), which\nestimates the additional compute that would be required to achieve similar\nimprovements without these algorithmic advancements.\n  To validate this framework, we conduct small-scale training experiments with\na scaled-down GPT-2 model. Our results confirm that compute-independent\nadvancements yield meaningful performance gains even in resource-constrained\nsettings, with a CEG of up to $3.5\\times$ over a baseline model. By contrast,\ncompute-dependent advancements provided little benefit or even degraded\nperformance at the small scale, reinforcing the importance of compute\navailability for certain algorithmic gains.",
      "tldr_zh": "本文探讨大型语言模型(LLM)能力是否能在没有额外计算资源的情况下继续进步，分析了算法创新在计算受限环境中的作用。论文引入一个分类框架，将算法创新分为计算依赖型创新（如Transformer架构和mixture-of-experts模型，仅在高计算水平下显著收益）和计算独立型创新（如rotary positional encoding、FlashAttention或layer normalization，可在所有规模下提升效率），并使用compute-equivalent gain (CEG)指标量化这些创新的价值。通过小规模GPT-2模型实验，结果显示计算独立型创新在资源受限设置中可带来高达3.5倍的性能提升，而计算依赖型创新则几乎无益或降低性能，强调了计算资源对某些算法的重要性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "I.2"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.04075v1",
      "published_date": "2025-05-07 02:26:17 UTC",
      "updated_date": "2025-05-07 02:26:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:46:55.784980"
    },
    {
      "arxiv_id": "2505.04072v1",
      "title": "Advancing and Benchmarking Personalized Tool Invocation for LLMs",
      "title_zh": "针对LLMs的个性化工具调用的推进与基准测试",
      "authors": [
        "Xu Huang",
        "Yuefeng Huang",
        "Weiwen Liu",
        "Xingshan Zeng",
        "Yasheng Wang",
        "Ruiming Tang",
        "Hong Xie",
        "Defu Lian"
      ],
      "abstract": "Tool invocation is a crucial mechanism for extending the capabilities of\nLarge Language Models (LLMs) and has recently garnered significant attention.\nIt enables LLMs to solve complex problems through tool calls while accessing\nup-to-date world knowledge. However, existing work primarily focuses on the\nfundamental ability of LLMs to invoke tools for problem-solving, without\nconsidering personalized constraints in tool invocation. In this work, we\nintroduce the concept of Personalized Tool Invocation and define two key tasks:\nTool Preference and Profile-dependent Query. Tool Preference addresses user\npreferences when selecting among functionally similar tools, while\nProfile-dependent Query considers cases where a user query lacks certain tool\nparameters, requiring the model to infer them from the user profile. To tackle\nthese challenges, we propose PTool, a data synthesis framework designed for\npersonalized tool invocation. Additionally, we construct \\textbf{PTBench}, the\nfirst benchmark for evaluating personalized tool invocation. We then fine-tune\nvarious open-source models, demonstrating the effectiveness of our framework\nand providing valuable insights. Our benchmark is public at\nhttps://github.com/hyfshadow/PTBench.",
      "tldr_zh": "该研究探讨了大型语言模型（LLMs）的工具调用机制，强调了个性化约束的重要性，以扩展模型处理复杂问题和实时知识的能力。论文引入了Personalized Tool Invocation概念，并定义了两个关键任务：Tool Preference（处理用户偏好以选择功能相似的工具）和Profile-dependent Query（从用户配置文件推断缺失参数）。为了应对这些挑战，研究者提出了PTool数据合成框架，并构建了首个评估基准PTBench，通过微调开源模型验证了框架的有效性，并提供了宝贵见解；基准已在GitHub上公开。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "14 pages, 7 figures, 5 tables",
      "pdf_url": "http://arxiv.org/pdf/2505.04072v1",
      "published_date": "2025-05-07 02:25:20 UTC",
      "updated_date": "2025-05-07 02:25:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:47:06.048991"
    },
    {
      "arxiv_id": "2505.04034v1",
      "title": "Izhikevich-Inspired Temporal Dynamics for Enhancing Privacy, Efficiency, and Transferability in Spiking Neural Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Ayana Moshruba",
        "Hamed Poursiami",
        "Maryam Parsa"
      ],
      "abstract": "Biological neurons exhibit diverse temporal spike patterns, which are\nbelieved to support efficient, robust, and adaptive neural information\nprocessing. While models such as Izhikevich can replicate a wide range of these\nfiring dynamics, their complexity poses challenges for directly integrating\nthem into scalable spiking neural networks (SNN) training pipelines. In this\nwork, we propose two probabilistically driven, input-level temporal spike\ntransformations: Poisson-Burst and Delayed-Burst that introduce biologically\ninspired temporal variability directly into standard Leaky Integrate-and-Fire\n(LIF) neurons. This enables scalable training and systematic evaluation of how\nspike timing dynamics affect privacy, generalization, and learning performance.\nPoisson-Burst modulates burst occurrence based on input intensity, while\nDelayed-Burst encodes input strength through burst onset timing. Through\nextensive experiments across multiple benchmarks, we demonstrate that\nPoisson-Burst maintains competitive accuracy and lower resource overhead while\nexhibiting enhanced privacy robustness against membership inference attacks,\nwhereas Delayed-Burst provides stronger privacy protection at a modest accuracy\ntrade-off. These findings highlight the potential of biologically grounded\ntemporal spike dynamics in improving the privacy, generalization and biological\nplausibility of neuromorphic learning systems.",
      "tldr_zh": "本研究受 Izhikevich 模型启发，提出两种基于概率的输入级 temporal spike transformations：Poisson-Burst 和 Delayed-Burst，应用于标准 Leaky Integrate-and-Fire (LIF) 神经元，以在 Spiking Neural Networks (SNN) 中引入生物启发的 temporal variability，从而提升隐私、效率和可转移性。Poisson-Burst 根据输入强度调节 burst 发生，提供竞争性准确率、较低资源开销，并增强对 membership inference attacks 的隐私保护；Delayed-Burst 通过 burst onset timing 编码输入强度，实现更强的隐私保障但伴随适度准确率折衷。通过多基准实验，证明这些方法显著改善了 SNN 的隐私鲁棒性、泛化和生物合理性。",
      "categories": [
        "cs.NE",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.NE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.04034v1",
      "published_date": "2025-05-07 00:27:00 UTC",
      "updated_date": "2025-05-07 00:27:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:47:21.067931"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 103,
  "processed_papers_count": 103,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-24T20:47:40.169542"
}