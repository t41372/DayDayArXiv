[
  {
    "arxiv_id": "2504.19047v1",
    "title": "AI Recommendations and Non-instrumental Image Concerns",
    "authors": [
      "David Almog"
    ],
    "abstract": "There is growing enthusiasm about the potential for humans and AI to\ncollaborate by leveraging their respective strengths. Yet in practice, this\npromise often falls short. This paper uses an online experiment to identify\nnon-instrumental image concerns as a key reason individuals underutilize AI\nrecommendations. I show that concerns about how one is perceived, even when\nthose perceptions carry no monetary consequences, lead participants to\ndisregard AI advice and reduce task performance.",
    "categories": [
      "econ.GN",
      "cs.AI",
      "cs.HC",
      "q-fin.EC"
    ],
    "primary_category": "econ.GN",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.19047v1",
    "published_date": "2025-04-26 22:52:33 UTC",
    "updated_date": "2025-04-26 22:52:33 UTC"
  },
  {
    "arxiv_id": "2504.19046v1",
    "title": "Enhancing Cochlear Implant Signal Coding with Scaled Dot-Product Attention",
    "authors": [
      "Billel Essaid",
      "Hamza Kheddar",
      "Noureddine Batel"
    ],
    "abstract": "Cochlear implants (CIs) play a vital role in restoring hearing for\nindividuals with severe to profound sensorineural hearing loss by directly\nstimulating the auditory nerve with electrical signals. While traditional\ncoding strategies, such as the advanced combination encoder (ACE), have proven\neffective, they are constrained by their adaptability and precision. This paper\ninvestigates the use of deep learning (DL) techniques to generate\nelectrodograms for CIs, presenting our model as an advanced alternative. We\ncompared the performance of our model with the ACE strategy by evaluating the\nintelligibility of reconstructed audio signals using the short-time objective\nintelligibility (STOI) metric. The results indicate that our model achieves a\nSTOI score of 0.6031, closely approximating the 0.6126 score of the ACE\nstrategy, and offers potential advantages in flexibility and adaptability. This\nstudy underscores the benefits of incorporating artificial intelligent (AI)\ninto CI technology, such as enhanced personalization and efficiency.",
    "categories": [
      "eess.AS",
      "cs.AI",
      "cs.SD"
    ],
    "primary_category": "eess.AS",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.19046v1",
    "published_date": "2025-04-26 22:49:08 UTC",
    "updated_date": "2025-04-26 22:49:08 UTC"
  },
  {
    "arxiv_id": "2504.19042v1",
    "title": "Generative Models for Fast Simulation of Cherenkov Detectors at the Electron-Ion Collider",
    "authors": [
      "James Giroux",
      "Michael Martinez",
      "Cristiano Fanelli"
    ],
    "abstract": "The integration of Deep Learning (DL) into experimental nuclear and particle\nphysics has driven significant progress in simulation and reconstruction\nworkflows. However, traditional simulation frameworks such as Geant4 remain\ncomputationally intensive, especially for Cherenkov detectors, where simulating\noptical photon transport through complex geometries and reflective surfaces\nintroduces a major bottleneck. To address this, we present an open, standalone\nfast simulation tool for Detection of Internally Reflected Cherenkov Light\n(DIRC) detectors, with a focus on the High-Performance DIRC (hpDIRC) at the\nfuture Electron-Ion Collider (EIC). Our framework incorporates a suite of\ngenerative models tailored to accelerate particle identification (PID) tasks by\noffering a scalable, GPU-accelerated alternative to full Geant4-based\nsimulations. Designed with accessibility in mind, our simulation package\nenables both DL researchers and physicists to efficiently generate\nhigh-fidelity large-scale datasets on demand, without relying on complex\ntraditional simulation stacks. This flexibility supports the development and\nbenchmarking of novel DL-driven PID methods. Moreover, this fast simulation\npipeline represents a critical step toward enabling EIC-wide PID strategies\nthat depend on virtually unlimited simulated samples, spanning the full\nacceptance of the hpDIRC.",
    "categories": [
      "physics.ins-det",
      "cs.AI",
      "cs.LG",
      "hep-ex",
      "nucl-ex"
    ],
    "primary_category": "physics.ins-det",
    "comment": "45 pages, 27 figures",
    "pdf_url": "http://arxiv.org/pdf/2504.19042v1",
    "published_date": "2025-04-26 22:33:08 UTC",
    "updated_date": "2025-04-26 22:33:08 UTC"
  },
  {
    "arxiv_id": "2504.19040v1",
    "title": "Improved Molecular Generation through Attribute-Driven Integrative Embeddings and GAN Selectivity",
    "authors": [
      "Nandan Joshi",
      "Erhan Guven"
    ],
    "abstract": "The growing demand for molecules with tailored properties in fields such as\ndrug discovery and chemical engineering has driven advancements in\ncomputational methods for molecular design. Machine learning-based approaches\nfor de-novo molecular generation have recently garnered significant attention.\nThis paper introduces a transformer-based vector embedding generator combined\nwith a modified Generative Adversarial Network (GAN) to generate molecules with\ndesired properties. The embedding generator utilizes a novel molecular\ndescriptor, integrating Morgan fingerprints with global molecular attributes,\nenabling the transformer to capture local functional groups and broader\nmolecular characteristics. Modifying the GAN generator loss function ensures\nthe generation of molecules with specific desired properties. The transformer\nachieves a reconversion accuracy of 94% while translating molecular descriptors\nback to SMILES strings, validating the utility of the proposed embeddings for\ngenerative tasks. The approach is validated by generating novel odorant\nmolecules using a labeled dataset of odorant and non-odorant compounds. With\nthe modified range-loss function, the GAN exclusively generates odorant\nmolecules. This work underscores the potential of combining novel vector\nembeddings with transformers and modified GAN architectures to accelerate the\ndiscovery of tailored molecules, offering a robust tool for diverse molecular\ndesign applications.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.19040v1",
    "published_date": "2025-04-26 22:15:25 UTC",
    "updated_date": "2025-04-26 22:15:25 UTC"
  },
  {
    "arxiv_id": "2504.19032v1",
    "title": "VISUALCENT: Visual Human Analysis using Dynamic Centroid Representation",
    "authors": [
      "Niaz Ahmad",
      "Youngmoon Lee",
      "Guanghui Wang"
    ],
    "abstract": "We introduce VISUALCENT, a unified human pose and instance segmentation\nframework to address generalizability and scalability limitations to multi\nperson visual human analysis. VISUALCENT leverages centroid based bottom up\nkeypoint detection paradigm and uses Keypoint Heatmap incorporating Disk\nRepresentation and KeyCentroid to identify the optimal keypoint coordinates.\nFor the unified segmentation task, an explicit keypoint is defined as a dynamic\ncentroid called MaskCentroid to swiftly cluster pixels to specific human\ninstance during rapid changes in human body movement or significantly occluded\nenvironment. Experimental results on COCO and OCHuman datasets demonstrate\nVISUALCENTs accuracy and real time performance advantages, outperforming\nexisting methods in mAP scores and execution frame rate per second. The\nimplementation is available on the project page.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.19032v1",
    "published_date": "2025-04-26 21:58:56 UTC",
    "updated_date": "2025-04-26 21:58:56 UTC"
  },
  {
    "arxiv_id": "2504.19030v1",
    "title": "Improving Pretrained YAMNet for Enhanced Speech Command Detection via Transfer Learning",
    "authors": [
      "Sidahmed Lachenani",
      "Hamza Kheddar",
      "Mohamed Ouldzmirli"
    ],
    "abstract": "This work addresses the need for enhanced accuracy and efficiency in speech\ncommand recognition systems, a critical component for improving user\ninteraction in various smart applications. Leveraging the robust pretrained\nYAMNet model and transfer learning, this study develops a method that\nsignificantly improves speech command recognition. We adapt and train a YAMNet\ndeep learning model to effectively detect and interpret speech commands from\naudio signals. Using the extensively annotated Speech Commands dataset\n(speech_commands_v0.01), our approach demonstrates the practical application of\ntransfer learning to accurately recognize a predefined set of speech commands.\nThe dataset is meticulously augmented, and features are strategically extracted\nto boost model performance. As a result, the final model achieved a recognition\naccuracy of 95.28%, underscoring the impact of advanced machine learning\ntechniques on speech command recognition. This achievement marks substantial\nprogress in audio processing technologies and establishes a new benchmark for\nfuture research in the field.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.19030v1",
    "published_date": "2025-04-26 21:57:11 UTC",
    "updated_date": "2025-04-26 21:57:11 UTC"
  },
  {
    "arxiv_id": "2504.19027v1",
    "title": "DiCE-Extended: A Robust Approach to Counterfactual Explanations in Machine Learning",
    "authors": [
      "Volkan Bakir",
      "Polat Goktas",
      "Sureyya Akyuz"
    ],
    "abstract": "Explainable artificial intelligence (XAI) has become increasingly important\nin decision-critical domains such as healthcare, finance, and law.\nCounterfactual (CF) explanations, a key approach in XAI, provide users with\nactionable insights by suggesting minimal modifications to input features that\nlead to different model outcomes. Despite significant advancements, existing CF\ngeneration methods often struggle to balance proximity, diversity, and\nrobustness, limiting their real-world applicability. A widely adopted\nframework, Diverse Counterfactual Explanations (DiCE), emphasizes diversity but\nlacks robustness, making CF explanations sensitive to perturbations and domain\nconstraints. To address these challenges, we introduce DiCE-Extended, an\nenhanced CF explanation framework that integrates multi-objective optimization\ntechniques to improve robustness while maintaining interpretability. Our\napproach introduces a novel robustness metric based on the Dice-Sorensen\ncoefficient, ensuring stability under small input variations. Additionally, we\nrefine CF generation using weighted loss components (lambda_p, lambda_d,\nlambda_r) to balance proximity, diversity, and robustness. We empirically\nvalidate DiCE-Extended on benchmark datasets (COMPAS, Lending Club, German\nCredit, Adult Income) across multiple ML backends (Scikit-learn, PyTorch,\nTensorFlow). Results demonstrate improved CF validity, stability, and alignment\nwith decision boundaries compared to standard DiCE-generated explanations. Our\nfindings highlight the potential of DiCE-Extended in generating more reliable\nand interpretable CFs for high-stakes applications. Future work will explore\nadaptive optimization techniques and domain-specific constraints to further\nenhance CF generation in real-world scenarios.",
    "categories": [
      "cs.AI",
      "cs.LG",
      "cs.NE",
      "I.2; K.4; H.4"
    ],
    "primary_category": "cs.AI",
    "comment": "MCO 2025, 5th International Conference on Modelling, Computation and\n  Optimization in Information Systems and Management Sciences",
    "pdf_url": "http://arxiv.org/pdf/2504.19027v1",
    "published_date": "2025-04-26 21:22:44 UTC",
    "updated_date": "2025-04-26 21:22:44 UTC"
  },
  {
    "arxiv_id": "2504.19023v1",
    "title": "GLaMoR: Consistency Checking of OWL Ontologies using Graph Language Models",
    "authors": [
      "Justin Mücke",
      "Ansgar Scherp"
    ],
    "abstract": "Semantic reasoning aims to infer new knowledge from existing knowledge, with\nOWL ontologies serving as a standardized framework for organizing information.\nA key challenge in semantic reasoning is verifying ontology consistency.\nHowever, state-of-the-art reasoners are computationally expensive, and their\nefficiency decreases as ontology sizes grow. While classical machine learning\nmodels have been explored for consistency checking, they struggle to capture\ncomplex relationships within ontologies. Large language models (LLMs) have\nshown promising results for simple reasoning tasks but perform poorly on\nstructured reasoning. The recently introduced Graph Language Model (GLM) offers\na way to simultaneously process graph-structured data and text. This paper\nproposes GLaMoR (Graph Language Model for Reasoning), a reasoning pipeline that\ntransforms OWL ontologies into graph-structured data and adapts the GLM\narchitecture for consistency checking. We evaluate GLaMoR on ontologies from\nthe NCBO BioPortal repository, converting them into triples suitable for model\ninput. Our results show that the GLM outperforms all baseline models, achieving\n$95\\%$ accuracy while being 20 times faster than classical reasoners.\n  The Code is accessible under: https://github.com/JustinMuecke/GLaMoR",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.19023v1",
    "published_date": "2025-04-26 21:20:29 UTC",
    "updated_date": "2025-04-26 21:20:29 UTC"
  },
  {
    "arxiv_id": "2504.19021v1",
    "title": "Advancing Scientific Text Classification: Fine-Tuned Models with Dataset Expansion and Hard-Voting",
    "authors": [
      "Zhyar Rzgar K Rostam",
      "Gábor Kertész"
    ],
    "abstract": "Efficient text classification is essential for handling the increasing volume\nof academic publications. This study explores the use of pre-trained language\nmodels (PLMs), including BERT, SciBERT, BioBERT, and BlueBERT, fine-tuned on\nthe Web of Science (WoS-46985) dataset for scientific text classification. To\nenhance performance, we augment the dataset by executing seven targeted queries\nin the WoS database, retrieving 1,000 articles per category aligned with\nWoS-46985's main classes. PLMs predict labels for this unlabeled data, and a\nhard-voting strategy combines predictions for improved accuracy and confidence.\nFine-tuning on the expanded dataset with dynamic learning rates and early\nstopping significantly boosts classification accuracy, especially in\nspecialized domains. Domain-specific models like SciBERT and BioBERT\nconsistently outperform general-purpose models such as BERT. These findings\nunderscore the efficacy of dataset augmentation, inference-driven label\nprediction, hard-voting, and fine-tuning techniques in creating robust and\nscalable solutions for automated academic text classification.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "6 pages, 1 figure, 8 tables",
    "pdf_url": "http://arxiv.org/pdf/2504.19021v1",
    "published_date": "2025-04-26 21:06:49 UTC",
    "updated_date": "2025-04-26 21:06:49 UTC"
  },
  {
    "arxiv_id": "2504.19019v1",
    "title": "Graph of Attacks: Improved Black-Box and Interpretable Jailbreaks for LLMs",
    "authors": [
      "Mohammad Akbar-Tajari",
      "Mohammad Taher Pilehvar",
      "Mohammad Mahmoody"
    ],
    "abstract": "The challenge of ensuring Large Language Models (LLMs) align with societal\nstandards is of increasing interest, as these models are still prone to\nadversarial jailbreaks that bypass their safety mechanisms. Identifying these\nvulnerabilities is crucial for enhancing the robustness of LLMs against such\nexploits. We propose Graph of ATtacks (GoAT), a method for generating\nadversarial prompts to test the robustness of LLM alignment using the Graph of\nThoughts framework [Besta et al., 2024]. GoAT excels at generating highly\neffective jailbreak prompts with fewer queries to the victim model than\nstate-of-the-art attacks, achieving up to five times better jailbreak success\nrate against robust models like Llama. Notably, GoAT creates high-quality,\nhuman-readable prompts without requiring access to the targeted model's\nparameters, making it a black-box attack. Unlike approaches constrained by\ntree-based reasoning, GoAT's reasoning is based on a more intricate graph\nstructure. By making simultaneous attack paths aware of each other's progress,\nthis dynamic framework allows a deeper integration and refinement of reasoning\npaths, significantly enhancing the collaborative exploration of adversarial\nvulnerabilities in LLMs. At a technical level, GoAT starts with a graph\nstructure and iteratively refines it by combining and improving thoughts,\nenabling synergy between different thought paths. The code for our\nimplementation can be found at: https://github.com/GoAT-pydev/Graph_of_Attacks.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.CL",
    "comment": "19 pages, 1 figure, 6 tables",
    "pdf_url": "http://arxiv.org/pdf/2504.19019v1",
    "published_date": "2025-04-26 21:06:03 UTC",
    "updated_date": "2025-04-26 21:06:03 UTC"
  },
  {
    "arxiv_id": "2504.19017v1",
    "title": "Sparks: Multi-Agent Artificial Intelligence Model Discovers Protein Design Principles",
    "authors": [
      "Alireza Ghafarollahi",
      "Markus J. Buehler"
    ],
    "abstract": "Advances in artificial intelligence (AI) promise autonomous discovery, yet\nmost systems still resurface knowledge latent in their training data. We\npresent Sparks, a multi-modal multi-agent AI model that executes the entire\ndiscovery cycle that includes hypothesis generation, experiment design and\niterative refinement to develop generalizable principles and a report without\nhuman intervention. Applied to protein science, Sparks uncovered two previously\nunknown phenomena: (i) a length-dependent mechanical crossover whereby\nbeta-sheet-biased peptides surpass alpha-helical ones in unfolding force beyond\n~80 residues, establishing a new design principle for peptide mechanics; and\n(ii) a chain-length/secondary-structure stability map revealing unexpectedly\nrobust beta-sheet-rich architectures and a \"frustration zone\" of high variance\nin mixed alpha/beta folds. These findings emerged from fully self-directed\nreasoning cycles that combined generative sequence design, high-accuracy\nstructure prediction and physics-aware property models, with paired\ngeneration-and-reflection agents enforcing self-correction and reproducibility.\nThe key result is that Sparks can independently conduct rigorous scientific\ninquiry and identify previously unknown scientific principles.",
    "categories": [
      "cs.AI",
      "cond-mat.mtrl-sci",
      "cond-mat.soft",
      "cs.LG",
      "q-bio.BM"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.19017v1",
    "published_date": "2025-04-26 20:43:28 UTC",
    "updated_date": "2025-04-26 20:43:28 UTC"
  },
  {
    "arxiv_id": "2505.03769v1",
    "title": "The Influence of Text Variation on User Engagement in Cross-Platform Content Sharing",
    "authors": [
      "Yibo Hu",
      "Yiqiao Jin",
      "Meng Ye",
      "Ajay Divakaran",
      "Srijan Kumar"
    ],
    "abstract": "In today's cross-platform social media landscape, understanding factors that\ndrive engagement for multimodal content, especially text paired with visuals,\nremains complex. This study investigates how rewriting Reddit post titles\nadapted from YouTube video titles affects user engagement. First, we build and\nanalyze a large dataset of Reddit posts sharing YouTube videos, revealing that\n21% of post titles are minimally modified. Statistical analysis demonstrates\nthat title rewrites measurably improve engagement. Second, we design a\ncontrolled, multi-phase experiment to rigorously isolate the effects of textual\nvariations by neutralizing confounding factors like video popularity, timing,\nand community norms. Comprehensive statistical tests reveal that effective\ntitle rewrites tend to feature emotional resonance, lexical richness, and\nalignment with community-specific norms. Lastly, pairwise ranking prediction\nexperiments using a fine-tuned BERT classifier achieves 74% accuracy,\nsignificantly outperforming near-random baselines, including GPT-4o. These\nresults validate that our controlled dataset effectively minimizes confounding\neffects, allowing advanced models to both learn and demonstrate the impact of\ntextual features on engagement. By bridging quantitative rigor with qualitative\ninsights, this study uncovers engagement dynamics and offers a robust framework\nfor future cross-platform, multimodal content strategies.",
    "categories": [
      "cs.SI",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.SI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.03769v1",
    "published_date": "2025-04-26 20:38:28 UTC",
    "updated_date": "2025-04-26 20:38:28 UTC"
  },
  {
    "arxiv_id": "2504.19013v3",
    "title": "$PINN - a Domain Decomposition Method for Bayesian Physics-Informed Neural Networks",
    "authors": [
      "Júlia Vicens Figueres",
      "Juliette Vanderhaeghen",
      "Federica Bragone",
      "Kateryna Morozovska",
      "Khemraj Shukla"
    ],
    "abstract": "Physics-Informed Neural Networks (PINNs) are a novel computational approach\nfor solving partial differential equations (PDEs) with noisy and sparse initial\nand boundary data. Although, efficient quantification of epistemic and\naleatoric uncertainties in big multi-scale problems remains challenging. We\npropose \\$PINN a novel method of computing global uncertainty in PDEs using a\nBayesian framework, by combining local Bayesian Physics-Informed Neural\nNetworks (BPINN) with domain decomposition. The solution continuity across\nsubdomains is obtained by imposing the flux continuity across the interface of\nneighboring subdomains. To demonstrate the effectiveness of \\$PINN, we conduct\na series of computational experiments on PDEs in 1D and 2D spatial domains.\nAlthough we have adopted conservative PINNs (cPINNs), the method can be\nseamlessly extended to other domain decomposition techniques. The results infer\nthat the proposed method recovers the global uncertainty by computing the local\nuncertainty exactly more efficiently as the uncertainty in each subdomain can\nbe computed concurrently. The robustness of \\$PINN is verified by adding\nuncorrelated random noise to the training data up to 15% and testing for\ndifferent domain sizes.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "math.AP"
    ],
    "primary_category": "cs.LG",
    "comment": "37 pages, 22 figures",
    "pdf_url": "http://arxiv.org/pdf/2504.19013v3",
    "published_date": "2025-04-26 19:58:21 UTC",
    "updated_date": "2025-05-01 09:26:03 UTC"
  },
  {
    "arxiv_id": "2504.20099v1",
    "title": "Decoding Latent Spaces: Assessing the Interpretability of Time Series Foundation Models for Visual Analytics",
    "authors": [
      "Inmaculada Santamaria-Valenzuela",
      "Victor Rodriguez-Fernandez",
      "Javier Huertas-Tato",
      "Jong Hyuk Park",
      "David Camacho"
    ],
    "abstract": "The present study explores the interpretability of latent spaces produced by\ntime series foundation models, focusing on their potential for visual analysis\ntasks. Specifically, we evaluate the MOMENT family of models, a set of\ntransformer-based, pre-trained architectures for multivariate time series tasks\nsuch as: imputation, prediction, classification, and anomaly detection. We\nevaluate the capacity of these models on five datasets to capture the\nunderlying structures in time series data within their latent space projection\nand validate whether fine tuning improves the clarity of the resulting\nembedding spaces. Notable performance improvements in terms of loss reduction\nwere observed after fine tuning. Visual analysis shows limited improvement in\nthe interpretability of the embeddings, requiring further work. Results suggest\nthat, although Time Series Foundation Models such as MOMENT are robust, their\nlatent spaces may require additional methodological refinements to be\nadequately interpreted, such as alternative projection techniques, loss\nfunctions, or data preprocessing strategies. Despite the limitations of MOMENT,\nfoundation models supose a big reduction in execution time and so a great\nadvance for interactive visual analytics.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "Currently under review at the International Journal of Interactive\n  Multimedia and Artificial Intelligence (IJIMAI)",
    "pdf_url": "http://arxiv.org/pdf/2504.20099v1",
    "published_date": "2025-04-26 17:24:41 UTC",
    "updated_date": "2025-04-26 17:24:41 UTC"
  },
  {
    "arxiv_id": "2504.18961v1",
    "title": "Feature Fusion Revisited: Multimodal CTR Prediction for MMCTR Challenge",
    "authors": [
      "Junjie Zhou"
    ],
    "abstract": "With the rapid advancement of Multimodal Large Language Models (MLLMs), an\nincreasing number of researchers are exploring their application in\nrecommendation systems. However, the high latency associated with large models\npresents a significant challenge for such use cases. The EReL@MIR workshop\nprovided a valuable opportunity to experiment with various approaches aimed at\nimproving the efficiency of multimodal representation learning for information\nretrieval tasks. As part of the competition's requirements, participants were\nmandated to submit a technical report detailing their methodologies and\nfindings. Our team was honored to receive the award for Task 2 - Winner\n(Multimodal CTR Prediction). In this technical report, we present our methods\nand key findings. Additionally, we propose several directions for future work,\nparticularly focusing on how to effectively integrate recommendation signals\ninto multimodal representations. The codebase for our implementation is\npublicly available at: https://github.com/Lattice-zjj/MMCTR_Code, and the\ntrained model weights can be accessed at:\nhttps://huggingface.co/FireFlyCourageous/MMCTR_DIN_MicroLens_1M_x1.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "A technical report for the MMCTR Challenge held by EReL@MIR Workshop\n  at WWW 2025",
    "pdf_url": "http://arxiv.org/pdf/2504.18961v1",
    "published_date": "2025-04-26 16:04:33 UTC",
    "updated_date": "2025-04-26 16:04:33 UTC"
  },
  {
    "arxiv_id": "2504.18954v1",
    "title": "Surgeons vs. Computer Vision: A comparative analysis on surgical phase recognition capabilities",
    "authors": [
      "Marco Mezzina",
      "Pieter De Backer",
      "Tom Vercauteren",
      "Matthew Blaschko",
      "Alexandre Mottrie",
      "Tinne Tuytelaars"
    ],
    "abstract": "Purpose: Automated Surgical Phase Recognition (SPR) uses Artificial\nIntelligence (AI) to segment the surgical workflow into its key events,\nfunctioning as a building block for efficient video review, surgical education\nas well as skill assessment. Previous research has focused on short and linear\nsurgical procedures and has not explored if temporal context influences\nexperts' ability to better classify surgical phases. This research addresses\nthese gaps, focusing on Robot-Assisted Partial Nephrectomy (RAPN) as a highly\nnon-linear procedure. Methods: Urologists of varying expertise were grouped and\ntasked to indicate the surgical phase for RAPN on both single frames and video\nsnippets using a custom-made web platform. Participants reported their\nconfidence levels and the visual landmarks used in their decision-making. AI\narchitectures without and with temporal context as trained and benchmarked on\nthe Cholec80 dataset were subsequently trained on this RAPN dataset. Results:\nVideo snippets and presence of specific visual landmarks improved phase\nclassification accuracy across all groups. Surgeons displayed high confidence\nin their classifications and outperformed novices, who struggled discriminating\nphases. The performance of the AI models is comparable to the surgeons in the\nsurvey, with improvements when temporal context was incorporated in both cases.\nConclusion: SPR is an inherently complex task for expert surgeons and computer\nvision, where both perform equally well when given the same context.\nPerformance increases when temporal information is provided. Surgical tools and\norgans form the key landmarks for human interpretation and are expected to\nshape the future of automated SPR.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.18954v1",
    "published_date": "2025-04-26 15:37:22 UTC",
    "updated_date": "2025-04-26 15:37:22 UTC"
  },
  {
    "arxiv_id": "2504.18953v1",
    "title": "Application of the Brain Drain Optimization Algorithm to the N-Queens Problem",
    "authors": [
      "Sahar Ramezani Jolfaei",
      "Sepehr Khodadadi Hossein Abadi"
    ],
    "abstract": "This paper introduces the application of the Brain Drain Optimization\nalgorithm -- a swarm-based metaheuristic inspired by the emigration of\nintellectual elites -- to the N-Queens problem. The N-Queens problem, a classic\ncombinatorial optimization problem, serves as a challenge for applying the\nBRADO. A designed cost function guides the search, and the configurations are\ntuned using a TOPSIS-based multicriteria decision making process. BRADO\nconsistently outperforms alternatives in terms of solution quality, achieving\nfewer threats and better objective function values. To assess BRADO's efficacy,\nit is benchmarked against several established metaheuristic algorithms,\nincluding Particle Swarm Optimization (PSO), Genetic Algorithm (GA),\nImperialist Competitive Algorithm (ICA), Iterated Local Search (ILS), and basic\nLocal Search (LS). The study highlights BRADO's potential as a general-purpose\nsolver for combinatorial problems, opening pathways for future applications in\nother domains of artificial intelligence.",
    "categories": [
      "cs.NE",
      "cs.AI"
    ],
    "primary_category": "cs.NE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.18953v1",
    "published_date": "2025-04-26 15:32:17 UTC",
    "updated_date": "2025-04-26 15:32:17 UTC"
  },
  {
    "arxiv_id": "2504.18948v1",
    "title": "Use of Metric Learning for the Recognition of Handwritten Digits, and its Application to Increase the Outreach of Voice-based Communication Platforms",
    "authors": [
      "Devesh Pant",
      "Dibyendu Talukder",
      "Deepak Kumar",
      "Rachit Pandey",
      "Aaditeshwar Seth",
      "Chetan Arora"
    ],
    "abstract": "Initiation, monitoring, and evaluation of development programmes can involve\nfield-based data collection about project activities. This data collection\nthrough digital devices may not always be feasible though, for reasons such as\nunaffordability of smartphones and tablets by field-based cadre, or shortfalls\nin their training and capacity building. Paper-based data collection has been\nargued to be more appropriate in several contexts, with automated digitization\nof the paper forms through OCR (Optical Character Recognition) and OMR (Optical\nMark Recognition) techniques. We contribute with providing a large dataset of\nhandwritten digits, and deep learning based models and methods built using this\ndata, that are effective in real-world environments. We demonstrate the\ndeployment of these tools in the context of a maternal and child health and\nnutrition awareness project, which uses IVR (Interactive Voice Response)\nsystems to provide awareness information to rural women SHG (Self Help Group)\nmembers in north India. Paper forms were used to collect phone numbers of the\nSHG members at scale, which were digitized using the OCR tools developed by us,\nand used to push almost 4 million phone calls. The data, model, and code have\nbeen released in the open-source domain.",
    "categories": [
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.AI",
    "comment": "10 Pages, 7 Figures, ACM COMPASS 2022",
    "pdf_url": "http://arxiv.org/pdf/2504.18948v1",
    "published_date": "2025-04-26 15:14:47 UTC",
    "updated_date": "2025-04-26 15:14:47 UTC"
  },
  {
    "arxiv_id": "2504.18943v1",
    "title": "GPU accelerated program synthesis: Enumerate semantics, not syntax!",
    "authors": [
      "Martin Berger",
      "Nathanaël Fijalkow",
      "Mojtaba Valizadeh"
    ],
    "abstract": "Program synthesis is an umbrella term for generating programs and logical\nformulae from specifications. With the remarkable performance improvements that\nGPUs enable for deep learning, a natural question arose: can we also implement\na search-based program synthesiser on GPUs to achieve similar performance\nimprovements? In this article we discuss our insights on this question, based\non recent works~. The goal is to build a synthesiser running on GPUs which\ntakes as input positive and negative example traces and returns a logical\nformula accepting the positive and rejecting the negative traces. With\nGPU-friendly programming techniques -- using the semantics of formulae to\nminimise data movement and reduce data-dependent branching -- our synthesiser\nscales to significantly larger synthesis problems, and operates much faster\nthan the previous CPU-based state-of-the-art. We believe the insights that make\nour approach GPU-friendly have wide potential for enhancing the performance of\nother formal methods (FM) workloads.",
    "categories": [
      "cs.PL",
      "cs.AI",
      "cs.LO",
      "68",
      "D.3"
    ],
    "primary_category": "cs.PL",
    "comment": "10 pages",
    "pdf_url": "http://arxiv.org/pdf/2504.18943v1",
    "published_date": "2025-04-26 15:06:37 UTC",
    "updated_date": "2025-04-26 15:06:37 UTC"
  },
  {
    "arxiv_id": "2504.18942v1",
    "title": "LawFlow : Collecting and Simulating Lawyers' Thought Processes",
    "authors": [
      "Debarati Das",
      "Khanh Chi Le",
      "Ritik Sachin Parkar",
      "Karin De Langis",
      "Brendan Madson",
      "Chad M. Berryman",
      "Robin M. Willis",
      "Daniel H. Moses",
      "Brett McDonnell",
      "Daniel Schwarcz",
      "Dongyeop Kang"
    ],
    "abstract": "Legal practitioners, particularly those early in their careers, face complex,\nhigh-stakes tasks that require adaptive, context-sensitive reasoning. While AI\nholds promise in supporting legal work, current datasets and models are\nnarrowly focused on isolated subtasks and fail to capture the end-to-end\ndecision-making required in real-world practice. To address this gap, we\nintroduce LawFlow, a dataset of complete end-to-end legal workflows collected\nfrom trained law students, grounded in real-world business entity formation\nscenarios. Unlike prior datasets focused on input-output pairs or linear chains\nof thought, LawFlow captures dynamic, modular, and iterative reasoning\nprocesses that reflect the ambiguity, revision, and client-adaptive strategies\nof legal practice. Using LawFlow, we compare human and LLM-generated workflows,\nrevealing systematic differences in structure, reasoning flexibility, and plan\nexecution. Human workflows tend to be modular and adaptive, while LLM workflows\nare more sequential, exhaustive, and less sensitive to downstream implications.\nOur findings also suggest that legal professionals prefer AI to carry out\nsupportive roles, such as brainstorming, identifying blind spots, and surfacing\nalternatives, rather than executing complex workflows end-to-end. Building on\nthese findings, we propose a set of design suggestions, rooted in empirical\nobservations, that align AI assistance with human goals of clarity,\ncompleteness, creativity, and efficiency, through hybrid planning, adaptive\nexecution, and decision-point support. Our results highlight both the current\nlimitations of LLMs in supporting complex legal workflows and opportunities for\ndeveloping more collaborative, reasoning-aware legal AI systems. All data and\ncode are available on our project page\n(https://minnesotanlp.github.io/LawFlow-website/).",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "submitted to COLM 2025",
    "pdf_url": "http://arxiv.org/pdf/2504.18942v1",
    "published_date": "2025-04-26 15:01:55 UTC",
    "updated_date": "2025-04-26 15:01:55 UTC"
  },
  {
    "arxiv_id": "2504.18932v1",
    "title": "AI Chatbots for Mental Health: Values and Harms from Lived Experiences of Depression",
    "authors": [
      "Dong Whi Yoo",
      "Jiayue Melissa Shi",
      "Violeta J. Rodriguez",
      "Koustuv Saha"
    ],
    "abstract": "Recent advancements in LLMs enable chatbots to interact with individuals on a\nrange of queries, including sensitive mental health contexts. Despite\nuncertainties about their effectiveness and reliability, the development of\nLLMs in these areas is growing, potentially leading to harms. To better\nidentify and mitigate these harms, it is critical to understand how the values\nof people with lived experiences relate to the harms. In this study, we\ndeveloped a technology probe, a GPT-4o based chatbot called Zenny, enabling\nparticipants to engage with depression self-management scenarios informed by\nprevious research. We used Zenny to interview 17 individuals with lived\nexperiences of depression. Our thematic analysis revealed key values:\ninformational support, emotional support, personalization, privacy, and crisis\nmanagement. This work explores the relationship between lived experience\nvalues, potential harms, and design recommendations for mental health AI\nchatbots, aiming to enhance self-management support while minimizing risks.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.18932v1",
    "published_date": "2025-04-26 14:17:25 UTC",
    "updated_date": "2025-04-26 14:17:25 UTC"
  },
  {
    "arxiv_id": "2504.18931v1",
    "title": "Advanced Longitudinal Control and Collision Avoidance for High-Risk Edge Cases in Autonomous Driving",
    "authors": [
      "Dianwei Chen",
      "Yaobang Gong",
      "Xianfeng Yang"
    ],
    "abstract": "Advanced Driver Assistance Systems (ADAS) and Advanced Driving Systems (ADS)\nare key to improving road safety, yet most existing implementations focus\nprimarily on the vehicle ahead, neglecting the behavior of following vehicles.\nThis shortfall often leads to chain reaction collisions in high speed, densely\nspaced traffic particularly when a middle vehicle suddenly brakes and trailing\nvehicles cannot respond in time. To address this critical gap, we propose a\nnovel longitudinal control and collision avoidance algorithm that integrates\nadaptive cruising with emergency braking. Leveraging deep reinforcement\nlearning, our method simultaneously accounts for both leading and following\nvehicles. Through a data preprocessing framework that calibrates real-world\nsensor data, we enhance the robustness and reliability of the training process,\nensuring the learned policy can handle diverse driving conditions. In simulated\nhigh risk scenarios (e.g., emergency braking in dense traffic), the algorithm\neffectively prevents potential pile up collisions, even in situations involving\nheavy duty vehicles. Furthermore, in typical highway scenarios where three\nvehicles decelerate, the proposed DRL approach achieves a 99% success rate far\nsurpassing the standard Federal Highway Administration speed concepts guide,\nwhich reaches only 36.77% success under the same conditions.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.18931v1",
    "published_date": "2025-04-26 14:17:06 UTC",
    "updated_date": "2025-04-26 14:17:06 UTC"
  },
  {
    "arxiv_id": "2505.00027v1",
    "title": "Extracting Abstraction Dimensions by Identifying Syntax Pattern from Texts",
    "authors": [
      "Jian Zhou",
      "Jiazheng Li",
      "Sirui Zhuge",
      "Hai Zhuge"
    ],
    "abstract": "This paper proposed an approach to automatically discovering subject\ndimension, action dimension, object dimension and adverbial dimension from\ntexts to efficiently operate texts and support query in natural language. The\nhigh quality of trees guarantees that all subjects, actions, objects and\nadverbials and their subclass relations within texts can be represented. The\nindependency of trees ensures that there is no redundant representation between\ntrees. The expressiveness of trees ensures that the majority of sentences can\nbe accessed from each tree and the rest of sentences can be accessed from at\nleast one tree so that the tree-based search mechanism can support querying in\nnatural language. Experiments show that the average precision, recall and\nF1-score of the abstraction trees constructed by the subclass relations of\nsubject, action, object and adverbial are all greater than 80%. The application\nof the proposed approach to supporting query in natural language demonstrates\nthat different types of question patterns for querying subject or object have\nhigh coverage of texts, and searching multiple trees on subject, action, object\nand adverbial according to the question pattern can quickly reduce search space\nto locate target sentences, which can support precise operation on texts.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "68T50 (Primary) 91F20 (Secondary)",
      "I.2.7; I.2.1"
    ],
    "primary_category": "cs.CL",
    "comment": "25pages, 3 figures, 8 tables",
    "pdf_url": "http://arxiv.org/pdf/2505.00027v1",
    "published_date": "2025-04-26 14:04:45 UTC",
    "updated_date": "2025-04-26 14:04:45 UTC"
  },
  {
    "arxiv_id": "2504.18929v1",
    "title": "Revisiting Transformers through the Lens of Low Entropy and Dynamic Sparsity",
    "authors": [
      "Ruifeng Ren",
      "Yong Liu"
    ],
    "abstract": "Compression has been a critical lens to understand the success of\nTransformers. In the past, we have typically taken the target distribution as a\ncriterion to evaluate a model's compression performance. Nevertheless,it often\nremains challenging to precisely assess how well the model achieves compression\nand to compare the information content of the learned distribution with that of\nthe target distribution during compression,as the target distribution is\ntypically unknown and entropy computation often incurs exponential cost. In\nthis work, we explore these issues under a controlled experimental setup. We\nfind that Transformers exhibit a unique inductive bias in data compression:\nbeyond approaching the target distribution, they tend to favor learning\nlower-entropy distributions, with this tendency becoming more pronounced as the\nmodel size increases. This preference prevents Transformers from perfectly\naligning with the target distribution, instead further compressing its\ninformation content. Furthermore, we show that the FFN module plays a critical\nrole in driving this bias. In addition, while models remove informational\nredundancy from data during compression, they also exhibit redundancy within\ntheir parameters, which enables compression and can be characterized through\ndynamic sparsity. However, the dynamic sparsity patterns in Transformers,\nparticularly in attention and FFN modules, demand further exploration. As for\nthis, we show that larger Transformers show stronger preferences for bypassing\nattention computations via residual connections and have lower proportion of\nactive neurons. Interestingly, we also find that training instability in larger\nmodels strongly correlates with sudden increases in dead neurons. Our work\ncontributes to a deeper understanding of Transformers from the lens of entropy\nand dynamic sparsity.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.18929v1",
    "published_date": "2025-04-26 14:02:07 UTC",
    "updated_date": "2025-04-26 14:02:07 UTC"
  },
  {
    "arxiv_id": "2504.18919v1",
    "title": "Clinical knowledge in LLMs does not translate to human interactions",
    "authors": [
      "Andrew M. Bean",
      "Rebecca Payne",
      "Guy Parsons",
      "Hannah Rose Kirk",
      "Juan Ciro",
      "Rafael Mosquera",
      "Sara Hincapié Monsalve",
      "Aruna S. Ekanayaka",
      "Lionel Tarassenko",
      "Luc Rocher",
      "Adam Mahdi"
    ],
    "abstract": "Global healthcare providers are exploring use of large language models (LLMs)\nto provide medical advice to the public. LLMs now achieve nearly perfect scores\non medical licensing exams, but this does not necessarily translate to accurate\nperformance in real-world settings. We tested if LLMs can assist members of the\npublic in identifying underlying conditions and choosing a course of action\n(disposition) in ten medical scenarios in a controlled study with 1,298\nparticipants. Participants were randomly assigned to receive assistance from an\nLLM (GPT-4o, Llama 3, Command R+) or a source of their choice (control). Tested\nalone, LLMs complete the scenarios accurately, correctly identifying conditions\nin 94.9% of cases and disposition in 56.3% on average. However, participants\nusing the same LLMs identified relevant conditions in less than 34.5% of cases\nand disposition in less than 44.2%, both no better than the control group. We\nidentify user interactions as a challenge to the deployment of LLMs for medical\nadvice. Standard benchmarks for medical knowledge and simulated patient\ninteractions do not predict the failures we find with human participants.\nMoving forward, we recommend systematic human user testing to evaluate\ninteractive capabilities prior to public deployments in healthcare.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.HC",
    "comment": "52 pages, 4 figures",
    "pdf_url": "http://arxiv.org/pdf/2504.18919v1",
    "published_date": "2025-04-26 13:32:49 UTC",
    "updated_date": "2025-04-26 13:32:49 UTC"
  },
  {
    "arxiv_id": "2504.18916v2",
    "title": "UnifyFL: Enabling Decentralized Cross-Silo Federated Learning",
    "authors": [
      "Sarang S",
      "Druva Dhakshinamoorthy",
      "Aditya Shiva Sharma",
      "Yuvraj Singh Bhadauria",
      "Siddharth Chaitra Vivek",
      "Arihant Bansal",
      "Arnab K. Paul"
    ],
    "abstract": "Federated Learning (FL) is a decentralized machine learning (ML) paradigm in\nwhich models are trained on private data across several devices called clients\nand combined at a single node called an aggregator rather than aggregating the\ndata itself. Many organizations employ FL to have better privacy-aware\nML-driven decision-making capabilities. However, organizations often operate\nindependently rather than collaborate to enhance their FL capabilities due to\nthe lack of an effective mechanism for collaboration. The challenge lies in\nbalancing trust and resource efficiency. One approach relies on trusting a\nthird-party aggregator to consolidate models from all organizations (multilevel\nFL), but this requires trusting an entity that may be biased or unreliable.\nAlternatively, organizations can bypass a third party by sharing their local\nmodels directly, which requires significant computational resources for\nvalidation. Both approaches reflect a fundamental trade-off between trust and\nresource constraints, with neither offering an ideal solution. In this work, we\ndevelop a trust-based cross-silo FL framework called UnifyFL, which uses\ndecentralized orchestration and distributed storage. UnifyFL provides\nflexibility to the participating organizations and presents synchronous and\nasynchronous modes to handle stragglers. Our evaluation on a diverse testbed\nshows that UnifyFL achieves a performance comparable to the ideal multilevel\ncentralized FL while allowing trust and optimal use of resources.",
    "categories": [
      "cs.DC",
      "cs.AI"
    ],
    "primary_category": "cs.DC",
    "comment": "12 pages, 7 figures, 7 tables. Accepted at the 26th ACM/IFIP\n  International Middleware Conference (MIDDLEWARE 2025)",
    "pdf_url": "http://arxiv.org/pdf/2504.18916v2",
    "published_date": "2025-04-26 13:15:40 UTC",
    "updated_date": "2025-05-06 03:37:38 UTC"
  },
  {
    "arxiv_id": "2504.18910v1",
    "title": "Kinship Verification through a Forest Neural Network",
    "authors": [
      "Ali Nazari",
      "Mohsen Ebrahimi Moghaddam",
      "Omidreza Borzoei"
    ],
    "abstract": "Early methods used face representations in kinship verification, which are\nless accurate than joint representations of parents' and children's facial\nimages learned from scratch. We propose an approach featuring graph neural\nnetwork concepts to utilize face representations and have comparable results to\njoint representation algorithms. Moreover, we designed the structure of the\nclassification module and introduced a new combination of losses to engage the\ncenter loss gradually in training our network. Additionally, we conducted\nexperiments on KinFaceW-I and II, demonstrating the effectiveness of our\napproach. We achieved the best result on KinFaceW-II, an average improvement of\nnearly 1.6 for all kinship types, and we were near the best on KinFaceW-I. The\ncode is available at https://github.com/ali-nazari/Kinship-Verification",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.18910v1",
    "published_date": "2025-04-26 12:50:12 UTC",
    "updated_date": "2025-04-26 12:50:12 UTC"
  },
  {
    "arxiv_id": "2504.18902v1",
    "title": "Transformer-Empowered Actor-Critic Reinforcement Learning for Sequence-Aware Service Function Chain Partitioning",
    "authors": [
      "Cyril Shih-Huan Hsu",
      "Anestis Dalgkitsis",
      "Chrysa Papagianni",
      "Paola Grosso"
    ],
    "abstract": "In the forthcoming era of 6G networks, characterized by unprecedented data\nrates, ultra-low latency, and extensive connectivity, effective management of\nVirtualized Network Functions (VNFs) is essential. VNFs are software-based\ncounterparts of traditional hardware devices that facilitate flexible and\nscalable service provisioning. Service Function Chains (SFCs), structured as\nordered sequences of VNFs, are pivotal in orchestrating complex network\nservices. Nevertheless, partitioning SFCs across multi-domain network\ninfrastructures presents substantial challenges due to stringent latency\nconstraints and limited resource availability. Conventional optimization-based\nmethods typically exhibit low scalability, whereas existing data-driven\napproaches often fail to adequately balance computational efficiency with the\ncapability to effectively account for dependencies inherent in SFCs. To\novercome these limitations, we introduce a Transformer-empowered actor-critic\nframework specifically designed for sequence-aware SFC partitioning. By\nutilizing the self-attention mechanism, our approach effectively models complex\ninter-dependencies among VNFs, facilitating coordinated and parallelized\ndecision-making processes. Additionally, we enhance training stability and\nconvergence using $\\epsilon$-LoPe exploration strategy as well as Asymptotic\nReturn Normalization. Comprehensive simulation results demonstrate that the\nproposed methodology outperforms existing state-of-the-art solutions in terms\nof long-term acceptance rates, resource utilization efficiency, and\nscalability, while achieving rapid inference. This study not only advances\nintelligent network orchestration by delivering a scalable and robust solution\nfor SFC partitioning within emerging 6G environments, but also bridging recent\nadvancements in Large Language Models (LLMs) with the optimization of\nnext-generation networks.",
    "categories": [
      "cs.NI",
      "cs.AI",
      "cs.LG",
      "cs.NE"
    ],
    "primary_category": "cs.NI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.18902v1",
    "published_date": "2025-04-26 12:18:57 UTC",
    "updated_date": "2025-04-26 12:18:57 UTC"
  },
  {
    "arxiv_id": "2504.18886v1",
    "title": "Exploiting Multiple Representations: 3D Face Biometrics Fusion with Application to Surveillance",
    "authors": [
      "Simone Maurizio La Cava",
      "Roberto Casula",
      "Sara Concas",
      "Giulia Orrù",
      "Ruben Tolosana",
      "Martin Drahansky",
      "Julian Fierrez",
      "Gian Luca Marcialis"
    ],
    "abstract": "3D face reconstruction (3DFR) algorithms are based on specific assumptions\ntailored to the limits and characteristics of the different application\nscenarios. In this study, we investigate how multiple state-of-the-art 3DFR\nalgorithms can be used to generate a better representation of subjects, with\nthe final goal of improving the performance of face recognition systems in\nchallenging uncontrolled scenarios. We also explore how different parametric\nand non-parametric score-level fusion methods can exploit the unique strengths\nof multiple 3DFR algorithms to enhance biometric recognition robustness. With\nthis goal, we propose a comprehensive analysis of several face recognition\nsystems across diverse conditions, such as varying distances and camera setups,\nintra-dataset and cross-dataset, to assess the robustness of the proposed\nensemble method. The results demonstrate that the distinct information provided\nby different 3DFR algorithms can alleviate the problem of generalizing over\nmultiple application scenarios. In addition, the present study highlights the\npotential of advanced fusion strategies to enhance the reliability of\n3DFR-based face recognition systems, providing the research community with key\ninsights to exploit them in real-world applications effectively. Although the\nexperiments are carried out in a specific face verification setup, our proposed\nfusion-based 3DFR methods may be applied to other tasks around face biometrics\nthat are not strictly related to identity recognition.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.18886v1",
    "published_date": "2025-04-26 10:21:46 UTC",
    "updated_date": "2025-04-26 10:21:46 UTC"
  },
  {
    "arxiv_id": "2505.00026v1",
    "title": "Theory of Mind in Large Language Models: Assessment and Enhancement",
    "authors": [
      "Ruirui Chen",
      "Weifeng Jiang",
      "Chengwei Qin",
      "Cheston Tan"
    ],
    "abstract": "Theory of Mind (ToM)-the ability to infer and reason about others' mental\nstates-is fundamental to human social intelligence. As Large Language Models\n(LLMs) become increasingly integrated into daily life, it is crucial to assess\nand enhance their capacity to interpret and respond to human mental states. In\nthis paper, we review LLMs' ToM capabilities by examining both evaluation\nbenchmarks and the strategies designed to improve them. We focus on widely\nadopted story-based benchmarks and provide an in-depth analysis of methods\naimed at enhancing ToM in LLMs. Furthermore, we outline promising future\nresearch directions informed by recent benchmarks and state-of-the-art\napproaches. Our survey serves as a valuable resource for researchers interested\nin advancing LLMs' ToM capabilities.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.00026v1",
    "published_date": "2025-04-26 10:17:48 UTC",
    "updated_date": "2025-04-26 10:17:48 UTC"
  },
  {
    "arxiv_id": "2504.18884v2",
    "title": "A Simple Ensemble Strategy for LLM Inference: Towards More Stable Text Classification",
    "authors": [
      "Junichiro Niimi"
    ],
    "abstract": "With the advance of large language models (LLMs), LLMs have been utilized for\nthe various tasks. However, the issues of variability and reproducibility of\nresults from each trial of LLMs have been largely overlooked in existing\nliterature while actual human annotation uses majority voting to resolve\ndisagreements among annotators. Therefore, this study introduces the\nstraightforward ensemble strategy to a sentiment analysis using LLMs. As the\nresults, we demonstrate that the ensemble of multiple inference using\nmedium-sized LLMs produces more robust and accurate results than using a large\nmodel with a single attempt with reducing RMSE by 18.6%.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "This manuscript has been accepted for the 30th International\n  Conference on Natural Language \\& Information Systems (NLDB 2025) and will\n  appear in Springer Lecture Notes in Computer Science (LNCS)",
    "pdf_url": "http://arxiv.org/pdf/2504.18884v2",
    "published_date": "2025-04-26 10:10:26 UTC",
    "updated_date": "2025-05-07 11:31:37 UTC"
  },
  {
    "arxiv_id": "2504.18882v1",
    "title": "SPD Learning for Covariance-Based Neuroimaging Analysis: Perspectives, Methods, and Challenges",
    "authors": [
      "Ce Ju",
      "Reinmar J. Kobler",
      "Antoine Collas",
      "Motoaki Kawanabe",
      "Cuntai Guan",
      "Bertrand Thirion"
    ],
    "abstract": "Neuroimaging provides a critical framework for characterizing brain activity\nby quantifying connectivity patterns and functional architecture across\nmodalities. While modern machine learning has significantly advanced our\nunderstanding of neural processing mechanisms through these datasets, decoding\ntask-specific signatures must contend with inherent neuroimaging constraints,\nfor example, low signal-to-noise ratios in raw electrophysiological recordings,\ncross-session non-stationarity, and limited sample sizes. This review focuses\non machine learning approaches for covariance-based neuroimaging data, where\noften symmetric positive definite (SPD) matrices under full-rank conditions\nencode inter-channel relationships. By equipping the space of SPD matrices with\nRiemannian metrics (e.g., affine-invariant or log-Euclidean), their space forms\na Riemannian manifold enabling geometric analysis. We unify methodologies\noperating on this manifold under the SPD learning framework, which\nsystematically leverages the SPD manifold's geometry to process covariance\nfeatures, thereby advancing brain imaging analytics.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "eess.IV",
      "q-bio.NC",
      "I.2.0"
    ],
    "primary_category": "cs.LG",
    "comment": "20 pages, 3 figures, 2 tables; This paper has been submitted for\n  possible publication, and currently under review",
    "pdf_url": "http://arxiv.org/pdf/2504.18882v1",
    "published_date": "2025-04-26 10:05:04 UTC",
    "updated_date": "2025-04-26 10:05:04 UTC"
  },
  {
    "arxiv_id": "2504.18880v1",
    "title": "Reshaping MOFs Text Mining with a Dynamic Multi-Agent Framework of Large Language Agents",
    "authors": [
      "Zuhong Lin",
      "Daoyuan Ren",
      "Kai Ran",
      "Sun Jing",
      "Xiaotiang Huang",
      "Haiyang He",
      "Pengxu Pan",
      "Xiaohang Zhang",
      "Ying Fang",
      "Tianying Wang",
      "Minli Wu",
      "Zhanglin Li",
      "Xiaochuan Zhang",
      "Haipu Li",
      "Jingjing Yao"
    ],
    "abstract": "The mining of synthesis conditions for metal-organic frameworks (MOFs) is a\nsignificant focus in materials science. However, identifying the precise\nsynthesis conditions for specific MOFs within the vast array of possibilities\npresents a considerable challenge. Large Language Models (LLMs) offer a\npromising solution to this problem. We leveraged the capabilities of LLMs,\nspecifically gpt-4o-mini, as core agents to integrate various MOF-related\nagents, including synthesis, attribute, and chemical information agents. This\nintegration culminated in the development of MOFh6, an LLM tool designed to\nstreamline the MOF synthesis process. MOFh6 allows users to query in multiple\nformats, such as submitting scientific literature, or inquiring about specific\nMOF codes or structural properties. The tool analyzes these queries to provide\noptimal synthesis conditions and generates model files for density functional\ntheory pre modeling. We believe MOFh6 will enhance efficiency in the MOF\nsynthesis of all researchers.",
    "categories": [
      "cs.AI",
      "cond-mat.mtrl-sci"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.18880v1",
    "published_date": "2025-04-26 09:55:04 UTC",
    "updated_date": "2025-04-26 09:55:04 UTC"
  },
  {
    "arxiv_id": "2504.18878v1",
    "title": "TSRM: A Lightweight Temporal Feature Encoding Architecture for Time Series Forecasting and Imputation",
    "authors": [
      "Robert Leppich",
      "Michael Stenger",
      "Daniel Grillmeyer",
      "Vanessa Borst",
      "Samuel Kounev"
    ],
    "abstract": "We introduce a temporal feature encoding architecture called Time Series\nRepresentation Model (TSRM) for multivariate time series forecasting and\nimputation. The architecture is structured around CNN-based representation\nlayers, each dedicated to an independent representation learning task and\ndesigned to capture diverse temporal patterns, followed by an attention-based\nfeature extraction layer and a merge layer, designed to aggregate extracted\nfeatures. The architecture is fundamentally based on a configuration that is\ninspired by a Transformer encoder, with self-attention mechanisms at its core.\nThe TSRM architecture outperforms state-of-the-art approaches on most of the\nseven established benchmark datasets considered in our empirical evaluation for\nboth forecasting and imputation tasks. At the same time, it significantly\nreduces complexity in the form of learnable parameters. The source code is\navailable at https://github.com/RobertLeppich/TSRM.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.18878v1",
    "published_date": "2025-04-26 09:53:20 UTC",
    "updated_date": "2025-04-26 09:53:20 UTC"
  },
  {
    "arxiv_id": "2504.18875v1",
    "title": "Generative to Agentic AI: Survey, Conceptualization, and Challenges",
    "authors": [
      "Johannes Schneider"
    ],
    "abstract": "Agentic Artificial Intelligence (AI) builds upon Generative AI (GenAI). It\nconstitutes the next major step in the evolution of AI with much stronger\nreasoning and interaction capabilities that enable more autonomous behavior to\ntackle complex tasks. Since the initial release of ChatGPT (3.5), Generative AI\nhas seen widespread adoption, giving users firsthand experience. However, the\ndistinction between Agentic AI and GenAI remains less well understood. To\naddress this gap, our survey is structured in two parts. In the first part, we\ncompare GenAI and Agentic AI using existing literature, discussing their key\ncharacteristics, how Agentic AI remedies limitations of GenAI, and the major\nsteps in GenAI's evolution toward Agentic AI. This section is intended for a\nbroad audience, including academics in both social sciences and engineering, as\nwell as industry professionals. It provides the necessary insights to\ncomprehend novel applications that are possible with Agentic AI but not with\nGenAI. In the second part, we deep dive into novel aspects of Agentic AI,\nincluding recent developments and practical concerns such as defining agents.\nFinally, we discuss several challenges that could serve as a future research\nagenda, while cautioning against risks that can emerge when exceeding human\nintelligence.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.18875v1",
    "published_date": "2025-04-26 09:47:00 UTC",
    "updated_date": "2025-04-26 09:47:00 UTC"
  },
  {
    "arxiv_id": "2505.09624v1",
    "title": "Neurophysiologically Realistic Environment for Comparing Adaptive Deep Brain Stimulation Algorithms in Parkinson Disease",
    "authors": [
      "Ekaterina Kuzmina",
      "Dmitrii Kriukov",
      "Mikhail Lebedev",
      "Dmitry V. Dylov"
    ],
    "abstract": "Adaptive deep brain stimulation (aDBS) has emerged as a promising treatment\nfor Parkinson disease (PD). In aDBS, a surgically placed electrode sends\ndynamically altered stimuli to the brain based on neurophysiological feedback:\nan invasive gadget that limits the amount of data one could collect for\noptimizing the control offline. As a consequence, a plethora of synthetic\nmodels of PD and those of the control algorithms have been proposed. Herein, we\nintroduce the first neurophysiologically realistic benchmark for comparing said\nmodels. Specifically, our methodology covers not only conventional basal\nganglia circuit dynamics and pathological oscillations, but also captures 15\npreviously dismissed physiological attributes, such as signal instabilities and\nnoise, neural drift, electrode conductance changes and individual variability -\nall modeled as spatially distributed and temporally registered features via\nbeta-band activity in the brain and a feedback. Furthermore, we purposely built\nour framework as a structured environment for training and evaluating deep\nreinforcement learning (RL) algorithms, opening new possibilities for\noptimizing aDBS control strategies and inviting the machine learning community\nto contribute to the emerging field of intelligent neurostimulation interfaces.",
    "categories": [
      "q-bio.NC",
      "cs.AI",
      "68T05"
    ],
    "primary_category": "q-bio.NC",
    "comment": "8 pages, 3 figures, submission to KDD",
    "pdf_url": "http://arxiv.org/pdf/2505.09624v1",
    "published_date": "2025-04-26 09:44:44 UTC",
    "updated_date": "2025-04-26 09:44:44 UTC"
  },
  {
    "arxiv_id": "2504.18858v1",
    "title": "Why you shouldn't fully trust ChatGPT: A synthesis of this AI tool's error rates across disciplines and the software engineering lifecycle",
    "authors": [
      "Vahid Garousi"
    ],
    "abstract": "Context: ChatGPT and other large language models (LLMs) are widely used\nacross healthcare, business, economics, engineering, and software engineering\n(SE). Despite their popularity, concerns persist about their reliability,\nespecially their error rates across domains and the software development\nlifecycle (SDLC).\n  Objective: This study synthesizes and quantifies ChatGPT's reported error\nrates across major domains and SE tasks aligned with SDLC phases. It provides\nan evidence-based view of where ChatGPT excels, where it fails, and how\nreliability varies by task, domain, and model version (GPT-3.5, GPT-4,\nGPT-4-turbo, GPT-4o).\n  Method: A Multivocal Literature Review (MLR) was conducted, gathering data\nfrom academic studies, reports, benchmarks, and grey literature up to 2025.\nFactual, reasoning, coding, and interpretive errors were considered. Data were\ngrouped by domain and SE phase and visualized using boxplots to show error\ndistributions.\n  Results: Error rates vary across domains and versions. In healthcare, rates\nranged from 8% to 83%. Business and economics saw error rates drop from ~50%\nwith GPT-3.5 to 15-20% with GPT-4. Engineering tasks averaged 20-30%.\nProgramming success reached 87.5%, though complex debugging still showed over\n50% errors. In SE, requirements and design phases showed lower error rates\n(~5-20%), while coding, testing, and maintenance phases had higher variability\n(10-50%). Upgrades from GPT-3.5 to GPT-4 improved reliability.\n  Conclusion: Despite improvements, ChatGPT still exhibits non-negligible error\nrates varying by domain, task, and SDLC phase. Full reliance without human\noversight remains risky, especially in critical settings. Continuous evaluation\nand critical validation are essential to ensure reliability and\ntrustworthiness.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.18858v1",
    "published_date": "2025-04-26 08:49:33 UTC",
    "updated_date": "2025-04-26 08:49:33 UTC"
  },
  {
    "arxiv_id": "2504.18857v1",
    "title": "Effective Length Extrapolation via Dimension-Wise Positional Embeddings Manipulation",
    "authors": [
      "Yi Lu",
      "Wanxu Zhao",
      "Xin Zhou",
      "Chenxin An",
      "Chenglong Wang",
      "Shuo Li",
      "Yuming Yang",
      "Jun Zhao",
      "Tao Ji",
      "Tao Gui",
      "Qi Zhang",
      "Xuanjing Huang"
    ],
    "abstract": "Large Language Models (LLMs) often struggle to process and generate coherent\ncontext when the number of input tokens exceeds the pre-trained length. Recent\nadvancements in long-context extension have significantly expanded the context\nwindow of LLMs but require expensive overhead to train the large-scale models\nwith longer context. In this work, we propose Dimension-Wise Positional\nEmbeddings Manipulation (DPE), a training-free framework to extrapolate the\ncontext window of LLMs by diving into RoPE's different hidden dimensions.\nInstead of manipulating all dimensions equally, DPE detects the effective\nlength for every dimension and finds the key dimensions for context extension.\nWe reuse the original position indices with their embeddings from the\npre-trained model and manipulate the key dimensions' position indices to their\nmost effective lengths. In this way, DPE adjusts the pre-trained models with\nminimal modifications while ensuring that each dimension reaches its optimal\nstate for extrapolation. DPE significantly surpasses well-known baselines such\nas YaRN and Self-Extend. DPE enables Llama3-8k 8B to support context windows of\n128k tokens without continual training and integrates seamlessly with Flash\nAttention 2. In addition to its impressive extrapolation capability, DPE also\ndramatically improves the models' performance within training length, such as\nLlama3.1 70B, by over 18 points on popular long-context benchmarks RULER. When\ncompared with commercial models, Llama 3.1 70B with DPE even achieves better\nperformance than GPT-4-128K.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.18857v1",
    "published_date": "2025-04-26 08:46:10 UTC",
    "updated_date": "2025-04-26 08:46:10 UTC"
  },
  {
    "arxiv_id": "2504.18854v1",
    "title": "Predicting Stress in Two-phase Random Materials and Super-Resolution Method for Stress Images by Embedding Physical Information",
    "authors": [
      "Tengfei Xing",
      "Xiaodan Ren",
      "Jie Li"
    ],
    "abstract": "Stress analysis is an important part of material design. For materials with\ncomplex microstructures, such as two-phase random materials (TRMs), material\nfailure is often accompanied by stress concentration. Phase interfaces in\ntwo-phase materials are critical for stress concentration. Therefore, the\nprediction error of stress at phase boundaries is crucial. In practical\nengineering, the pixels of the obtained material microstructure images are\nlimited, which limits the resolution of stress images generated by deep\nlearning methods, making it difficult to observe stress concentration regions.\nExisting Image Super-Resolution (ISR) technologies are all based on data-driven\nsupervised learning. However, stress images have natural physical constraints,\nwhich provide new ideas for new ISR technologies. In this study, we constructed\na stress prediction framework for TRMs. First, the framework uses a proposed\nMultiple Compositions U-net (MC U-net) to predict stress in low-resolution\nmaterial microstructures. By considering the phase interface information of the\nmicrostructure, the MC U-net effectively reduces the problem of excessive\nprediction errors at phase boundaries. Secondly, a Mixed Physics-Informed\nNeural Network (MPINN) based method for stress ISR (SRPINN) was proposed. By\nintroducing the constraints of physical information, the new method does not\nrequire paired stress images for training and can increase the resolution of\nstress images to any multiple. This enables a multiscale analysis of the stress\nconcentration regions at phase boundaries. Finally, we performed stress\nanalysis on TRMs with different phase volume fractions and loading states\nthrough transfer learning. The results show the proposed stress prediction\nframework has satisfactory accuracy and generalization ability.",
    "categories": [
      "cond-mat.mtrl-sci",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cond-mat.mtrl-sci",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.18854v1",
    "published_date": "2025-04-26 08:42:06 UTC",
    "updated_date": "2025-04-26 08:42:06 UTC"
  },
  {
    "arxiv_id": "2505.01438v1",
    "title": "Global Stress Generation and Spatiotemporal Super-Resolution Physics-Informed Operator under Dynamic Loading for Two-Phase Random Materials",
    "authors": [
      "Tengfei Xing",
      "Xiaodan Ren",
      "Jie Li"
    ],
    "abstract": "Material stress analysis is a critical aspect of material design and\nperformance optimization. Under dynamic loading, the global stress evolution in\nmaterials exhibits complex spatiotemporal characteristics, especially in\ntwo-phase random materials (TRMs). Such kind of material failure is often\nassociated with stress concentration, and the phase boundaries are key\nlocations where stress concentration occurs. In practical engineering\napplications, the spatiotemporal resolution of acquired microstructural data\nand its dynamic stress evolution is often limited. This poses challenges for\ndeep learning methods in generating high-resolution spatiotemporal stress\nfields, particularly for accurately capturing stress concentration regions. In\nthis study, we propose a framework for global stress generation and\nspatiotemporal super-resolution in TRMs under dynamic loading. First, we\nintroduce a diffusion model-based approach, named as Spatiotemporal Stress\nDiffusion (STS-diffusion), for generating global spatiotemporal stress data.\nThis framework incorporates Space-Time U-Net (STU-net), and we systematically\ninvestigate the impact of different attention positions on model accuracy.\nNext, we develop a physics-informed network for spatiotemporal\nsuper-resolution, termed as Spatiotemporal Super-Resolution Physics-Informed\nOperator (ST-SRPINN). The proposed ST-SRPINN is an unsupervised learning\nmethod. The influence of data-driven and physics-informed loss function weights\non model accuracy is explored in detail. Benefiting from physics-based\nconstraints, ST-SRPINN requires only low-resolution stress field data during\ntraining and can upscale the spatiotemporal resolution of stress fields to\narbitrary magnifications.",
    "categories": [
      "cs.LG",
      "cond-mat.mtrl-sci",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.01438v1",
    "published_date": "2025-04-26 08:37:29 UTC",
    "updated_date": "2025-04-26 08:37:29 UTC"
  },
  {
    "arxiv_id": "2504.18847v1",
    "title": "Imitation Learning for Autonomous Driving: Insights from Real-World Testing",
    "authors": [
      "Hidayet Ersin Dursun",
      "Yusuf Güven",
      "Tufan Kumbasar"
    ],
    "abstract": "This work focuses on the design of a deep learning-based autonomous driving\nsystem deployed and tested on the real-world MIT Racecar to assess its\neffectiveness in driving scenarios. The Deep Neural Network (DNN) translates\nraw image inputs into real-time steering commands in an end-to-end learning\nfashion, following the imitation learning framework. The key design challenge\nis to ensure that DNN predictions are accurate and fast enough, at a high\nsampling frequency, and result in smooth vehicle operation under different\noperating conditions. In this study, we design and compare various DNNs, to\nidentify the most effective approach for real-time autonomous driving. In\ndesigning the DNNs, we adopted an incremental design approach that involved\nenhancing the model capacity and dataset to address the challenges of\nreal-world driving scenarios. We designed a PD system, CNN, CNN-LSTM, and\nCNN-NODE, and evaluated their performance on the real-world MIT Racecar. While\nthe PD system handled basic lane following, it struggled with sharp turns and\nlighting variations. The CNN improved steering but lacked temporal awareness,\nwhich the CNN-LSTM addressed as it resulted in smooth driving performance. The\nCNN-NODE performed similarly to the CNN-LSTM in handling driving dynamics, yet\nwith slightly better driving performance. The findings of this research\nhighlight the importance of iterative design processes in developing robust\nDNNs for autonomous driving applications. The experimental video is available\nat https://www.youtube.com/watch?v=FNNYgU--iaY.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "In International Congress on Human-Computer Interaction, Optimization\n  and Robotic Applications, 2025",
    "pdf_url": "http://arxiv.org/pdf/2504.18847v1",
    "published_date": "2025-04-26 08:21:12 UTC",
    "updated_date": "2025-04-26 08:21:12 UTC"
  },
  {
    "arxiv_id": "2504.18845v1",
    "title": "Introducing Interval Neural Networks for Uncertainty-Aware System Identification",
    "authors": [
      "Mehmet Ali Ferah",
      "Tufan Kumbasar"
    ],
    "abstract": "System Identification (SysID) is crucial for modeling and understanding\ndynamical systems using experimental data. While traditional SysID methods\nemphasize linear models, their inability to fully capture nonlinear dynamics\nhas driven the adoption of Deep Learning (DL) as a more powerful alternative.\nHowever, the lack of uncertainty quantification (UQ) in DL-based models poses\nchallenges for reliability and safety, highlighting the necessity of\nincorporating UQ. This paper introduces a systematic framework for constructing\nand learning Interval Neural Networks (INNs) to perform UQ in SysID tasks. INNs\nare derived by transforming the learnable parameters (LPs) of pre-trained\nneural networks into interval-valued LPs without relying on probabilistic\nassumptions. By employing interval arithmetic throughout the network, INNs can\ngenerate Prediction Intervals (PIs) that capture target coverage effectively.\nWe extend Long Short-Term Memory (LSTM) and Neural Ordinary Differential\nEquations (Neural ODEs) into Interval LSTM (ILSTM) and Interval NODE (INODE)\narchitectures, providing the mathematical foundations for their application in\nSysID. To train INNs, we propose a DL framework that integrates a UQ loss\nfunction and parameterization tricks to handle constraints arising from\ninterval LPs. We introduce novel concept \"elasticity\" for underlying\nuncertainty causes and validate ILSTM and INODE in SysID experiments,\ndemonstrating their effectiveness.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "In International Congress on Human-Computer Interaction, Optimization\n  and Robotic Applications, 2025",
    "pdf_url": "http://arxiv.org/pdf/2504.18845v1",
    "published_date": "2025-04-26 08:16:46 UTC",
    "updated_date": "2025-04-26 08:16:46 UTC"
  },
  {
    "arxiv_id": "2504.18827v2",
    "title": "Test It Before You Trust It: Applying Software Testing for Trustworthy In-context Learning",
    "authors": [
      "Teeradaj Racharak",
      "Chaiyong Ragkhitwetsagul",
      "Chommakorn Sontesadisai",
      "Thanwadee Sunetnanta"
    ],
    "abstract": "In-context learning (ICL) has emerged as a powerful capability of large\nlanguage models (LLMs), enabling them to perform new tasks based on a few\nprovided examples without explicit fine-tuning. Despite their impressive\nadaptability, these models remain vulnerable to subtle adversarial\nperturbations and exhibit unpredictable behavior when faced with linguistic\nvariations. Inspired by software testing principles, we introduce a software\ntesting-inspired framework, called MMT4NL, for evaluating the trustworthiness\nof in-context learning by utilizing adversarial perturbations and software\ntesting techniques. It includes diverse evaluation aspects of linguistic\ncapabilities for testing the ICL capabilities of LLMs. MMT4NL is built around\nthe idea of crafting metamorphic adversarial examples from a test set in order\nto quantify and pinpoint bugs in the designed prompts of ICL. Our philosophy is\nto treat any LLM as software and validate its functionalities just like testing\nthe software. Finally, we demonstrate applications of MMT4NL on the sentiment\nanalysis and question-answering tasks. Our experiments could reveal various\nlinguistic bugs in state-of-the-art LLMs.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.18827v2",
    "published_date": "2025-04-26 07:29:12 UTC",
    "updated_date": "2025-05-07 09:29:45 UTC"
  },
  {
    "arxiv_id": "2504.18819v1",
    "title": "Preserving Seasonal and Trend Information: A Variational Autoencoder-Latent Space Arithmetic Based Approach for Non-stationary Learning",
    "authors": [
      "Hassan Wasswa",
      "Aziida Nanyonga",
      "Timothy Lynar"
    ],
    "abstract": "AI models have garnered significant research attention towards predictive\ntask automation. However, a stationary training environment is an underlying\nassumption for most models and such models simply do not work on non-stationary\ndata since a stationary relationship is learned. The existing solutions propose\nmaking data stationary prior to model training and evaluation. This leads to\nloss of trend and seasonal patterns which are vital components for learning\ntemporal dependencies of the system under study. This research aims to address\nthis limitation by proposing a method for enforcing stationary behaviour within\nthe latent space while preserving trend and seasonal information. The method\ndeploys techniques including Differencing, Time-series decomposition, and\nLatent Space Arithmetic (LSA), to learn information vital for efficient\napproximation of trend and seasonal information which is then stored as\nembeddings within the latent space of a Variational Autoencoder (VAE). The\napproach's ability to preserve trend and seasonal information was evaluated on\ntwo time-series non-stationary datasets. For predictive performance evaluation,\nfour deep learning models were trained on the latent vector representations of\nthe datasets after application of the proposed method and all models produced\ncompetitive results in comparison with state-of-the-art techniques using RMSE\nas the performance metric.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.18819v1",
    "published_date": "2025-04-26 06:29:06 UTC",
    "updated_date": "2025-04-26 06:29:06 UTC"
  },
  {
    "arxiv_id": "2505.02841v1",
    "title": "Snakemaker: Seamlessly transforming ad-hoc analyses into sustainable Snakemake workflows with generative AI",
    "authors": [
      "Marco Masera",
      "Alessandro Leone",
      "Johannes Köster",
      "Ivan Molineris"
    ],
    "abstract": "Reproducibility and sustainability present significant challenges in\nbioinformatics software development, where rapidly evolving tools and complex\nworkflows often result in short-lived or difficult-to-adapt pipelines. This\npaper introduces Snakemaker, a tool that leverages generative AI to facilitate\nresearchers build sustainable data analysis pipelines by converting\nunstructured code into well-defined Snakemake workflows. Snakemaker\nnon-invasively tracks the work performed in the terminal by the researcher,\nanalyzes execution patterns, and generates Snakemake workflows that can be\nintegrated into existing pipelines. Snakemaker also supports the transformation\nof monolithic Ipython Notebooks into modular Snakemake pipelines, resolving the\nglobal state of the notebook into discrete, file-based interactions between\nrules. An integrated chat assistant provides users with fine-grained control\nthrough natural language instructions. Snakemaker generates high-quality\nSnakemake workflows by adhering to the best practices, including Conda\nenvironment tracking, generic rule generation and loop unrolling. By lowering\nthe barrier between prototype and production-quality code, Snakemaker addresses\na critical gap in computational reproducibility for bioinformatics research.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.02841v1",
    "published_date": "2025-04-26 06:00:05 UTC",
    "updated_date": "2025-04-26 06:00:05 UTC"
  },
  {
    "arxiv_id": "2504.18814v2",
    "title": "Zero-Day Botnet Attack Detection in IoV: A Modular Approach Using Isolation Forests and Particle Swarm Optimization",
    "authors": [
      "Abdelaziz Amara Korba",
      "Nour Elislem Karabadji",
      "Yacine Ghamri-Doudane"
    ],
    "abstract": "The Internet of Vehicles (IoV) is transforming transportation by enhancing\nconnectivity and enabling autonomous driving. However, this increased\ninterconnectivity introduces new security vulnerabilities. Bot malware and\ncyberattacks pose significant risks to Connected and Autonomous Vehicles\n(CAVs), as demonstrated by real-world incidents involving remote vehicle system\ncompromise. To address these challenges, we propose an edge-based Intrusion\nDetection System (IDS) that monitors network traffic to and from CAVs. Our\ndetection model is based on a meta-ensemble classifier capable of recognizing\nknown (Nday) attacks and detecting previously unseen (zero-day) attacks. The\napproach involves training multiple Isolation Forest (IF) models on\nMulti-access Edge Computing (MEC) servers, with each IF specialized in\nidentifying a specific type of botnet attack. These IFs, either trained locally\nor shared by other MEC nodes, are then aggregated using a Particle Swarm\nOptimization (PSO) based stacking strategy to construct a robust\nmeta-classifier. The proposed IDS has been evaluated on a vehicular botnet\ndataset, achieving an average detection rate of 92.80% for N-day attacks and\n77.32% for zero-day attacks. These results highlight the effectiveness of our\nsolution in detecting both known and emerging threats, providing a scalable and\nadaptive defense mechanism for CAVs within the IoV ecosystem.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.18814v2",
    "published_date": "2025-04-26 05:57:03 UTC",
    "updated_date": "2025-05-01 20:46:08 UTC"
  },
  {
    "arxiv_id": "2504.18810v1",
    "title": "Audio-Driven Talking Face Video Generation with Joint Uncertainty Learning",
    "authors": [
      "Yifan Xie",
      "Fei Ma",
      "Yi Bin",
      "Ying He",
      "Fei Yu"
    ],
    "abstract": "Talking face video generation with arbitrary speech audio is a significant\nchallenge within the realm of digital human technology. The previous studies\nhave emphasized the significance of audio-lip synchronization and visual\nquality. Currently, limited attention has been given to the learning of visual\nuncertainty, which creates several issues in existing systems, including\ninconsistent visual quality and unreliable performance across different input\nconditions. To address the problem, we propose a Joint Uncertainty Learning\nNetwork (JULNet) for high-quality talking face video generation, which\nincorporates a representation of uncertainty that is directly related to visual\nerror. Specifically, we first design an uncertainty module to individually\npredict the error map and uncertainty map after obtaining the generated image.\nThe error map represents the difference between the generated image and the\nground truth image, while the uncertainty map is used to predict the\nprobability of incorrect estimates. Furthermore, to match the uncertainty\ndistribution with the error distribution through a KL divergence term, we\nintroduce a histogram technique to approximate the distributions. By jointly\noptimizing error and uncertainty, the performance and robustness of our model\ncan be enhanced. Extensive experiments demonstrate that our method achieves\nsuperior high-fidelity and audio-lip synchronization in talking face video\ngeneration compared to previous methods.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "10 pages, 7 figures",
    "pdf_url": "http://arxiv.org/pdf/2504.18810v1",
    "published_date": "2025-04-26 05:45:38 UTC",
    "updated_date": "2025-04-26 05:45:38 UTC"
  },
  {
    "arxiv_id": "2504.18807v1",
    "title": "Clones in the Machine: A Feminist Critique of Agency in Digital Cloning",
    "authors": [
      "Siân Brooke"
    ],
    "abstract": "This paper critiques digital cloning in academic research, highlighting how\nit exemplifies AI solutionism. Digital clones, which replicate user data to\nsimulate behavior, are often seen as scalable tools for behavioral insights.\nHowever, this framing obscures ethical concerns around consent, agency, and\nrepresentation. Drawing on feminist theories of agency, the paper argues that\ndigital cloning oversimplifies human complexity and risks perpetuating systemic\nbiases. To address these issues, it proposes decentralized data repositories\nand dynamic consent models, promoting ethical, context-aware AI practices that\nchallenge the reductionist logic of AI solutionism",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "ACM CHI Conference on Human Factors in Computing Systems 2025",
    "pdf_url": "http://arxiv.org/pdf/2504.18807v1",
    "published_date": "2025-04-26 05:24:35 UTC",
    "updated_date": "2025-04-26 05:24:35 UTC"
  },
  {
    "arxiv_id": "2504.18805v1",
    "title": "Stealing Creator's Workflow: A Creator-Inspired Agentic Framework with Iterative Feedback Loop for Improved Scientific Short-form Generation",
    "authors": [
      "Jong Inn Park",
      "Maanas Taneja",
      "Qianwen Wang",
      "Dongyeop Kang"
    ],
    "abstract": "Generating engaging, accurate short-form videos from scientific papers is\nchallenging due to content complexity and the gap between expert authors and\nreaders. Existing end-to-end methods often suffer from factual inaccuracies and\nvisual artifacts, limiting their utility for scientific dissemination. To\naddress these issues, we propose SciTalk, a novel multi-LLM agentic framework,\ngrounding videos in various sources, such as text, figures, visual styles, and\navatars. Inspired by content creators' workflows, SciTalk uses specialized\nagents for content summarization, visual scene planning, and text and layout\nediting, and incorporates an iterative feedback mechanism where video agents\nsimulate user roles to give feedback on generated videos from previous\niterations and refine generation prompts. Experimental evaluations show that\nSciTalk outperforms simple prompting methods in generating scientifically\naccurate and engaging content over the refined loop of video generation.\nAlthough preliminary results are still not yet matching human creators'\nquality, our framework provides valuable insights into the challenges and\nbenefits of feedback-driven video generation. Our code, data, and generated\nvideos will be publicly available.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Project page: https://minnesotanlp.github.io/scitalk-project-page/",
    "pdf_url": "http://arxiv.org/pdf/2504.18805v1",
    "published_date": "2025-04-26 05:22:35 UTC",
    "updated_date": "2025-04-26 05:22:35 UTC"
  },
  {
    "arxiv_id": "2504.18804v1",
    "title": "Can We Enhance Bug Report Quality Using LLMs?: An Empirical Study of LLM-Based Bug Report Generation",
    "authors": [
      "Jagrit Acharya",
      "Gouri Ginde"
    ],
    "abstract": "Bug reports contain the information developers need to triage and fix\nsoftware bugs. However, unclear, incomplete, or ambiguous information may lead\nto delays and excessive manual effort spent on bug triage and resolution. In\nthis paper, we explore whether Instruction fine-tuned Large Language Models\n(LLMs) can automatically transform casual, unstructured bug reports into\nhigh-quality, structured bug reports adhering to a standard template. We\nevaluate three open-source instruction-tuned LLMs (\\emph{Qwen 2.5, Mistral, and\nLlama 3.2}) against ChatGPT-4o, measuring performance on established metrics\nsuch as CTQRS, ROUGE, METEOR, and SBERT. Our experiments show that fine-tuned\nQwen 2.5 achieves a CTQRS score of \\textbf{77%}, outperforming both fine-tuned\nMistral (\\textbf{71%}), Llama 3.2 (\\textbf{63%}) and ChatGPT in 3-shot learning\n(\\textbf{75%}). Further analysis reveals that Llama 3.2 shows higher accuracy\nof detecting missing fields particularly Expected Behavior and Actual Behavior,\nwhile Qwen 2.5 demonstrates superior performance in capturing\nSteps-to-Reproduce, with an F1 score of 76%. Additional testing of the models\non other popular projects (e.g., Eclipse, GCC) demonstrates that our approach\ngeneralizes well, achieving up to \\textbf{70%} CTQRS in unseen projects' bug\nreports. These findings highlight the potential of instruction fine-tuning in\nautomating structured bug report generation, reducing manual effort for\ndevelopers and streamlining the software maintenance process.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.18804v1",
    "published_date": "2025-04-26 05:15:53 UTC",
    "updated_date": "2025-04-26 05:15:53 UTC"
  },
  {
    "arxiv_id": "2504.18800v1",
    "title": "Video CLIP Model for Multi-View Echocardiography Interpretation",
    "authors": [
      "Ryo Takizawa",
      "Satoshi Kodera",
      "Tempei Kabayama",
      "Ryo Matsuoka",
      "Yuta Ando",
      "Yuto Nakamura",
      "Haruki Settai",
      "Norihiko Takeda"
    ],
    "abstract": "Echocardiography involves recording videos of the heart using ultrasound,\nenabling clinicians to evaluate its condition. Recent advances in large-scale\nvision-language models (VLMs) have garnered attention for automating the\ninterpretation of echocardiographic videos. However, most existing VLMs\nproposed for medical interpretation thus far rely on single-frame (i.e., image)\ninputs. Consequently, these image-based models often exhibit lower diagnostic\naccuracy for conditions identifiable through cardiac motion. Moreover,\nechocardiographic videos are recorded from various views that depend on the\ndirection of ultrasound emission, and certain views are more suitable than\nothers for interpreting specific conditions. Incorporating multiple views could\npotentially yield further improvements in accuracy. In this study, we developed\na video-language model that takes five different views and full video sequences\nas input, training it on pairs of echocardiographic videos and clinical reports\nfrom 60,747 cases. Our experiments demonstrate that this expanded approach\nachieves higher interpretation accuracy than models trained with only\nsingle-view videos or with still images.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.18800v1",
    "published_date": "2025-04-26 05:11:15 UTC",
    "updated_date": "2025-04-26 05:11:15 UTC"
  },
  {
    "arxiv_id": "2504.18794v2",
    "title": "Hierarchical Reinforcement Learning in Multi-Goal Spatial Navigation with Autonomous Mobile Robots",
    "authors": [
      "Brendon Johnson",
      "Alfredo Weitzenfeld"
    ],
    "abstract": "Hierarchical reinforcement learning (HRL) is hypothesized to be able to take\nadvantage of the inherent hierarchy in robot learning tasks with sparse reward\nschemes, in contrast to more traditional reinforcement learning algorithms. In\nthis research, hierarchical reinforcement learning is evaluated and contrasted\nwith standard reinforcement learning in complex navigation tasks. We evaluate\nunique characteristics of HRL, including their ability to create sub-goals and\nthe termination function. We constructed experiments to test the differences\nbetween PPO and HRL, different ways of creating sub-goals, manual vs automatic\nsub-goal creation, and the effects of the frequency of termination on\nperformance. These experiments highlight the advantages of HRL and how it\nachieves these advantages.",
    "categories": [
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.18794v2",
    "published_date": "2025-04-26 04:30:10 UTC",
    "updated_date": "2025-05-05 17:21:55 UTC"
  },
  {
    "arxiv_id": "2504.18793v1",
    "title": "Building Scalable AI-Powered Applications with Cloud Databases: Architectures, Best Practices and Performance Considerations",
    "authors": [
      "Santosh Bhupathi"
    ],
    "abstract": "The rapid adoption of AI-powered applications demands high-performance,\nscalable, and efficient cloud database solutions, as traditional architectures\noften struggle with AI-driven workloads requiring real-time data access, vector\nsearch, and low-latency queries. This paper explores how cloud-native databases\nenable AI-driven applications by leveraging purpose-built technologies such as\nvector databases (pgvector), graph databases (AWS Neptune), NoSQL stores\n(Amazon DocumentDB, DynamoDB), and relational cloud databases (Aurora MySQL and\nPostgreSQL). It presents architectural patterns for integrating AI workloads\nwith cloud databases, including Retrieval-Augmented Generation (RAG) [1] with\nLLMs, real-time data pipelines, AI-driven query optimization, and\nembeddings-based search. Performance benchmarks, scalability considerations,\nand cost-efficient strategies are evaluated to guide the design of AI-enabled\napplications. Real-world case studies from industries such as healthcare,\nfinance, and customer experience illustrate how enterprises utilize cloud\ndatabases to enhance AI capabilities while ensuring security, governance, and\ncompliance with enterprise and regulatory standards. By providing a\ncomprehensive analysis of AI and cloud database integration, this paper serves\nas a practical guide for researchers, architects, and enterprises to build\nnext-generation AI applications that optimize performance, scalability, and\ncost efficiency in cloud environments.",
    "categories": [
      "cs.DB",
      "cs.AI",
      "97P30",
      "I.2.7; H.2.5"
    ],
    "primary_category": "cs.DB",
    "comment": "9 pages",
    "pdf_url": "http://arxiv.org/pdf/2504.18793v1",
    "published_date": "2025-04-26 04:17:46 UTC",
    "updated_date": "2025-04-26 04:17:46 UTC"
  },
  {
    "arxiv_id": "2504.21030v1",
    "title": "Advancing Multi-Agent Systems Through Model Context Protocol: Architecture, Implementation, and Applications",
    "authors": [
      "Naveen Krishnan"
    ],
    "abstract": "Multi-agent systems represent a significant advancement in artificial\nintelligence, enabling complex problem-solving through coordinated specialized\nagents. However, these systems face fundamental challenges in context\nmanagement, coordination efficiency, and scalable operation. This paper\nintroduces a comprehensive framework for advancing multi-agent systems through\nModel Context Protocol (MCP), addressing these challenges through standardized\ncontext sharing and coordination mechanisms. We extend previous work on AI\nagent architectures by developing a unified theoretical foundation, advanced\ncontext management techniques, and scalable coordination patterns. Through\ndetailed implementation case studies across enterprise knowledge management,\ncollaborative research, and distributed problem-solving domains, we demonstrate\nsignificant performance improvements compared to traditional approaches. Our\nevaluation methodology provides a systematic assessment framework with\nbenchmark tasks and datasets specifically designed for multi-agent systems. We\nidentify current limitations, emerging research opportunities, and potential\ntransformative applications across industries. This work contributes to the\nevolution of more capable, collaborative, and context-aware artificial\nintelligence systems that can effectively address complex real-world\nchallenges.",
    "categories": [
      "cs.MA",
      "cs.AI"
    ],
    "primary_category": "cs.MA",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.21030v1",
    "published_date": "2025-04-26 03:43:03 UTC",
    "updated_date": "2025-04-26 03:43:03 UTC"
  },
  {
    "arxiv_id": "2504.18781v1",
    "title": "IoT Botnet Detection: Application of Vision Transformer to Classification of Network Flow Traffic",
    "authors": [
      "Hassan Wasswa",
      "Timothy Lynar",
      "Aziida Nanyonga",
      "Hussein Abbass"
    ],
    "abstract": "Despite the demonstrated effectiveness of transformer models in NLP, and\nimage and video classification, the available tools for extracting features\nfrom captured IoT network flow packets fail to capture sequential patterns in\naddition to the absence of spatial patterns consequently limiting transformer\nmodel application. This work introduces a novel preprocessing method to adapt\ntransformer models, the vision transformer (ViT) in particular, for IoT botnet\nattack detection using network flow packets. The approach involves feature\nextraction from .pcap files and transforming each instance into a 1-channel 2D\nimage shape, enabling ViT-based classification. Also, the ViT model was\nenhanced to allow use any classifier besides Multilayer Perceptron (MLP) that\nwas deployed in the initial ViT paper. Models including the conventional feed\nforward Deep Neural Network (DNN), LSTM and Bidirectional-LSTM (BLSTM)\ndemonstrated competitive performance in terms of precision, recall, and\nF1-score for multiclass-based attack detection when evaluated on two IoT attack\ndatasets.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.18781v1",
    "published_date": "2025-04-26 03:19:19 UTC",
    "updated_date": "2025-04-26 03:19:19 UTC"
  },
  {
    "arxiv_id": "2504.18777v1",
    "title": "Evaluating AI-Driven Automated Map Digitization in QGIS",
    "authors": [
      "Diana Febrita"
    ],
    "abstract": "Map digitization is an important process that converts maps into digital\nformats that can be used for further analysis. This process typically requires\na deep human involvement because of the need for interpretation and\ndecision-making when translating complex features. With the advancement of\nartificial intelligence, there is an alternative to conducting map digitization\nwith the help of machine learning techniques. Deepness, or Deep Neural Remote\nSensing, is an advanced AI-driven tool designed and integrated as a plugin in\nQGIS application. This research focuses on assessing the effectiveness of\nDeepness in automated digitization. This study analyses AI-generated\ndigitization results from Google Earth imagery and compares them with digitized\noutputs from OpenStreetMap (OSM) to evaluate performance.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Submitted to 2025 Indiana Geographic Information Council (IGIC)\n  Conference",
    "pdf_url": "http://arxiv.org/pdf/2504.18777v1",
    "published_date": "2025-04-26 03:09:54 UTC",
    "updated_date": "2025-04-26 03:09:54 UTC"
  },
  {
    "arxiv_id": "2504.18770v1",
    "title": "PyViT-FUSE: A Foundation Model for Multi-Sensor Earth Observation Data",
    "authors": [
      "Manuel Weber",
      "Carly Beneke"
    ],
    "abstract": "We propose PyViT-FUSE, a foundation model for earth observation data\nexplicitly designed to handle multi-modal imagery by learning to fuse an\narbitrary number of mixed-resolution input bands into a single representation\nthrough an attention mechanism. The learned patch tokens are further processed\nby a stack of vision transformers with a novel pyramidal structure. We train\nthe model on a globally sampled dataset in a self-supervised manner, leveraging\ncore concepts of the SwAV algorithm. We show the interpretability of the fusion\nmechanism by visualization of the attention scores and the models applicability\nto downstream tasks.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "11 pages, 13 figures, Published at ICLR 2025 - Machine Learning for\n  Remote Sensing (ML4RS) Workshop",
    "pdf_url": "http://arxiv.org/pdf/2504.18770v1",
    "published_date": "2025-04-26 02:34:33 UTC",
    "updated_date": "2025-04-26 02:34:33 UTC"
  },
  {
    "arxiv_id": "2504.18766v1",
    "title": "Dynamic Action Interpolation: A Universal Approach for Accelerating Reinforcement Learning with Expert Guidance",
    "authors": [
      "Wenjun Cao"
    ],
    "abstract": "Reinforcement learning (RL) suffers from severe sample inefficiency,\nespecially during early training, requiring extensive environmental\ninteractions to perform competently. Existing methods tend to solve this by\nincorporating prior knowledge, but introduce significant architectural and\nimplementation complexity. We propose Dynamic Action Interpolation (DAI), a\nuniversal yet straightforward framework that interpolates expert and RL actions\nvia a time-varying weight $\\alpha(t)$, integrating into any Actor-Critic\nalgorithm with just a few lines of code and without auxiliary networks or\nadditional losses. Our theoretical analysis shows that DAI reshapes state\nvisitation distributions to accelerate value function learning while preserving\nconvergence guarantees. Empirical evaluations across MuJoCo continuous control\ntasks demonstrate that DAI improves early-stage performance by over 160\\% on\naverage and final performance by more than 50\\%, with the Humanoid task showing\na 4$\\times$ improvement early on and a 2$\\times$ gain at convergence. These\nresults challenge the assumption that complex architectural modifications are\nnecessary for sample-efficient reinforcement learning.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.18766v1",
    "published_date": "2025-04-26 02:12:02 UTC",
    "updated_date": "2025-04-26 02:12:02 UTC"
  },
  {
    "arxiv_id": "2504.18765v1",
    "title": "A Vision for Auto Research with LLM Agents",
    "authors": [
      "Chengwei Liu",
      "Chong Wang",
      "Jiayue Cao",
      "Jingquan Ge",
      "Kun Wang",
      "Lvye Zhang",
      "Ming-Ming Cheng",
      "Penghai Zhao",
      "Tianlin Li",
      "Xiaojun Jia",
      "Xiang Li",
      "Xinfeng Li",
      "Yang Liu",
      "Yebo Feng",
      "Yihao Huang",
      "Yijia Xu",
      "Yuqiang Sun",
      "Zhenhong Zhou",
      "Zhengzi Xu"
    ],
    "abstract": "This paper introduces Agent-Based Auto Research, a structured multi-agent\nframework designed to automate, coordinate, and optimize the full lifecycle of\nscientific research. Leveraging the capabilities of large language models\n(LLMs) and modular agent collaboration, the system spans all major research\nphases, including literature review, ideation, methodology planning,\nexperimentation, paper writing, peer review response, and dissemination. By\naddressing issues such as fragmented workflows, uneven methodological\nexpertise, and cognitive overload, the framework offers a systematic and\nscalable approach to scientific inquiry. Preliminary explorations demonstrate\nthe feasibility and potential of Auto Research as a promising paradigm for\nself-improving, AI-driven research processes.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.18765v1",
    "published_date": "2025-04-26 02:06:10 UTC",
    "updated_date": "2025-04-26 02:06:10 UTC"
  },
  {
    "arxiv_id": "2505.01437v1",
    "title": "Enhancing IoT-Botnet Detection using Variational Auto-encoder and Cost-Sensitive Learning: A Deep Learning Approach for Imbalanced Datasets",
    "authors": [
      "Hassan Wasswa",
      "Timothy Lynar",
      "Hussein Abbass"
    ],
    "abstract": "The Internet of Things (IoT) technology has rapidly gained popularity with\napplications widespread across a variety of industries. However, IoT devices\nhave been recently serving as a porous layer for many malicious attacks to both\npersonal and enterprise information systems with the most famous attacks being\nbotnet-related attacks. The work in this study leveraged Variational\nAuto-encoder (VAE) and cost-sensitive learning to develop lightweight, yet\neffective, models for IoT-botnet detection. The aim is to enhance the detection\nof minority class attack traffic instances which are often missed by machine\nlearning models. The proposed approach is evaluated on a multi-class problem\nsetting for the detection of traffic categories on highly imbalanced datasets.\nThe performance of two deep learning models including the standard feed forward\ndeep neural network (DNN), and Bidirectional-LSTM (BLSTM) was evaluated and\nboth recorded commendable results in terms of accuracy, precision, recall and\nF1-score for all traffic classes.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.01437v1",
    "published_date": "2025-04-26 02:04:30 UTC",
    "updated_date": "2025-04-26 02:04:30 UTC"
  },
  {
    "arxiv_id": "2504.21029v1",
    "title": "PICO: Secure Transformers via Robust Prompt Isolation and Cybersecurity Oversight",
    "authors": [
      "Ben Goertzel",
      "Paulos Yibelo"
    ],
    "abstract": "We propose a robust transformer architecture designed to prevent prompt\ninjection attacks and ensure secure, reliable response generation. Our PICO\n(Prompt Isolation and Cybersecurity Oversight) framework structurally separates\ntrusted system instructions from untrusted user inputs through dual channels\nthat are processed independently and merged only by a controlled, gated fusion\nmechanism. In addition, we integrate a specialized Security Expert Agent within\na Mixture-of-Experts (MoE) framework and incorporate a Cybersecurity Knowledge\nGraph (CKG) to supply domain-specific reasoning. Our training design further\nensures that the system prompt branch remains immutable while the rest of the\nnetwork learns to handle adversarial inputs safely. This PICO framework is\npresented via a general mathematical formulation, then elaborated in terms of\nthe specifics of transformer architecture, and fleshed out via hypothetical\ncase studies including Policy Puppetry attacks. While the most effective\nimplementation may involve training transformers in a PICO-based way from\nscratch, we also present a cost-effective fine-tuning approach.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.21029v1",
    "published_date": "2025-04-26 00:46:13 UTC",
    "updated_date": "2025-04-26 00:46:13 UTC"
  }
]