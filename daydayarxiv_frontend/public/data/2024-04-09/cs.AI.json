{
  "date": "2024-04-09",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-04-09 的 arXiv 中文 TLDR 快报！\n\n今天 arXiv 的论文主要聚焦于 AI、机器学习和多模态模型等领域，涵盖了 LLM 的鲁棒性与攻击、联邦学习在医疗中的应用、机器人导航和数学证明等话题。其中，令人印象深刻的是关于 LLM 攻击的“Sandwich attack”论文，以及提升 AlphaGeometry 在数学证明中的性能，展示了 AI 在实际应用中的潜力。\n\n以下是今日论文的精选摘要，我将优先讨论重要、话题度高的论文（如 LLM 和 AI 应用），并快速掠过其他次要内容。每篇论文标题以中文 + 英文形式列出，焦点放在核心贡献和发现上。\n\n### 重点论文讨论\n\n**1. Towards Building a Robust Toxicity Predictor（构建鲁棒毒性预测器的研究）**  \n这篇论文提出了一种新颖的对抗攻击方法 ToxicTrap，用于测试 NLP 模型的鲁棒性。主要贡献是通过贪婪搜索策略生成对抗样本，揭示了 SOTA 毒性检测器的弱点（如多标签场景下 98% 的攻击成功率），并证明了对抗训练能提升模型对未知攻击的抵抗力。\n\n**2. From Protoscience to Epistemic Monoculture: How Benchmarking Set the Stage for the Deep Learning Revolution（从原科学到知识单一性：基准测试如何推动深度学习革命）**  \n作者 Bernard J. Koch 和 David Peterson 通过质性访谈和计算分析，探讨了 AI 研究从探索性科学转向基准测试主导的模式。关键发现是，基准测试加速了 AI 进步但也导致了单一性（如过度依赖预测准确性），并讨论了其对其他科学领域的启示。\n\n**3. GenCHiP: Generating Robot Policy Code for High-Precision and Contact-Rich Manipulation Tasks（GenCHiP：为高精度接触丰富操作任务生成机器人策略代码）**  \n作者包括 Karol Hausman，这篇论文使用 LLM 生成机器人策略代码，并通过重新参数化动作空间（如力约束）提升性能。主要发现是，该方法在功能性操作基准上提高了 3-4 倍的策略生成成功率，即使在感知噪声条件下。\n\n**4. Sandwich attack: Multi-language Mixture Adaptive Attack on LLMs（Sandwich 攻击：针对 LLM 的多语言混合自适应攻击）**  \n这篇论文引入了“Sandwich attack”黑盒攻击向量，针对 Google Bard、GPT-4 等 LLM，成功诱导有害响应。核心贡献是利用低资源语言的模型弱点，实验显示攻击有效率高达 100%，强调了 LLM 安全性的潜在风险。\n\n**5. Wu's Method can Boost Symbolic AI to Rival Silver Medalists and AlphaGeometry to Outperform Gold Medalists at IMO Geometry（Wu 方法提升符号 AI 以匹敌银牌选手，并让 AlphaGeometry 超越金牌选手在 IMO 几何证明中）**  \n作者包括 Siddharth Bhat，这篇论文扩展了 Wu 方法在几何证明中的应用。发现是将 Wu 方法与传统方法结合，能解决 21/30 个 IMO 问题，超越 AlphaGeometry 的表现，证明了符号 AI 在数学推理中的潜力。\n\n**6. Federated learning model for predicting major postoperative complications（用于预测主要术后并发症的联邦学习模型）**  \n这篇医疗 AI 论文提出联邦学习模型预测术后并发症，使用 EHR 数据训练。主要贡献是模型在多中心数据上实现了高 AUC 值（0.81-0.93），证明了联邦学习在隐私保护下的泛化能力。\n\n**7. GOAT-Bench: A Benchmark for Multi-Modal Lifelong Navigation（GOAT-Bench：多模态终身导航基准）**  \n论文引入 GOAT-Bench 基准，用于评估多模态导航代理。关键发现是，RL 和模块化方法在处理类别、语言和图像目标时表现出色，强调了记忆和鲁棒性的重要性。\n\n### 其他论文快速掠过\n以下论文主题多样，但相对次要，我仅简要概述核心点：\n\n- **Evolving Loss Functions for Specific Image Augmentation Techniques（针对特定图像增强技术的进化损失函数）**：提出新损失函数提升图像分类，贡献是新损失函数在 CIFAR-10 等数据集上超越交叉熵。\n\n- **Counting Objects in a Robotic Hand（机器人手中物体计数）**：使用对比学习计数器，准确率达 96%，适用于机器人抓取任务。\n\n- **Ada-LEval: Evaluating long-context LLMs with length-adaptable benchmarks（Ada-LEval：使用长度可适应基准评估长上下文 LLM）**：开发新基准评估 LLM 长文本能力，发现模型在超长设置下表现有限。\n\n- **PURE: Turning Polysemantic Neurons Into Pure Features by Identifying Relevant Circuits（PURE：通过识别相关电路将多义神经元转化为纯特征）**：改进神经网络解释性，贡献是分解多义神经元提升模型性能。\n\n- **AgentsCoDriver: Large Language Model Empowered Collaborative Driving with Lifelong Learning（AgentsCoDriver：使用 LLM 实现终身学习的协作驾驶）**：LLM 驱动的协作驾驶框架，支持动态环境决策。\n\n- **Visually Descriptive Language Model for Vector Graphics Reasoning（视觉描述语言模型用于矢量图形推理）**：提出 VDLM 模型，将 SVG 转化为文本抽象，提升图形推理准确性。\n\n其余论文（如关于图神经网络、图像生成或小规模实验的）虽有技术贡献，但影响力较小，我仅提及标题而不展开，例如：\n- **Graph Reinforcement Learning for Combinatorial Optimization: A Survey and Unifying Perspective（图强化学习在组合优化的调查和统一视角）**：综述图 RL 方法。\n- **Pitfalls of Conversational LLMs on News Debiasing（对话 LLM 在新闻去偏见中的陷阱）**：发现 LLM 在去偏见任务中易出错。\n- **Public-private funding models in open source software development（开源软件开发的公私资金模型）**：案例研究 scikit-learn 的资金模式。\n\n总之，今天的 arXiv 论文突显了 AI 领域的创新，尤其在 LLM 安全和应用上，值得关注。更多细节可查阅 arXiv 页面！",
  "papers": [
    {
      "arxiv_id": "2404.08690v1",
      "title": "Towards Building a Robust Toxicity Predictor",
      "title_zh": "翻译失败",
      "authors": [
        "Dmitriy Bespalov",
        "Sourav Bhabesh",
        "Yi Xiang",
        "Liutong Zhou",
        "Yanjun Qi"
      ],
      "abstract": "Recent NLP literature pays little attention to the robustness of toxicity\nlanguage predictors, while these systems are most likely to be used in\nadversarial contexts. This paper presents a novel adversarial attack,\n\\texttt{ToxicTrap}, introducing small word-level perturbations to fool SOTA\ntext classifiers to predict toxic text samples as benign. ToxicTrap exploits\ngreedy based search strategies to enable fast and effective generation of toxic\nadversarial examples. Two novel goal function designs allow ToxicTrap to\nidentify weaknesses in both multiclass and multilabel toxic language detectors.\nOur empirical results show that SOTA toxicity text classifiers are indeed\nvulnerable to the proposed attacks, attaining over 98\\% attack success rates in\nmultilabel cases. We also show how a vanilla adversarial training and its\nimproved version can help increase robustness of a toxicity detector even\nagainst unseen attacks.",
      "tldr_zh": "这篇论文探讨了 NLP 中毒性语言预测器的鲁棒性问题，提出了一种新颖的对抗攻击方法 ToxicTrap，通过小规模词级扰动和贪婪搜索策略生成对抗样本，以欺骗 SOTA 文本分类器将有毒文本误判为无害。ToxicTrap 设计了两个创新的目标函数，适用于多类和多标签毒性检测场景。实验结果显示，该攻击在多标签情况下成功率超过 98%，暴露了现有模型的脆弱性。最后，作者证明通过 vanilla adversarial training 和其改进版本，可以显著提升毒性检测器的鲁棒性，甚至应对未见攻击。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CR",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "ACL 2023 /",
      "pdf_url": "http://arxiv.org/pdf/2404.08690v1",
      "published_date": "2024-04-09 22:56:05 UTC",
      "updated_date": "2024-04-09 22:56:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T22:48:51.713756"
    },
    {
      "arxiv_id": "2404.06647v2",
      "title": "From Protoscience to Epistemic Monoculture: How Benchmarking Set the Stage for the Deep Learning Revolution",
      "title_zh": "翻译失败",
      "authors": [
        "Bernard J. Koch",
        "David Peterson"
      ],
      "abstract": "Over the past decade, AI research has focused heavily on building ever-larger\ndeep learning models. This approach has simultaneously unlocked incredible\nachievements in science and technology, and hindered AI from overcoming\nlong-standing limitations with respect to explainability, ethical harms, and\nenvironmental efficiency. Drawing on qualitative interviews and computational\nanalyses, our three-part history of AI research traces the creation of this\n\"epistemic monoculture\" back to a radical reconceptualization of scientific\nprogress that began in the late 1980s. In the first era of AI research\n(1950s-late 1980s), researchers and patrons approached AI as a \"basic\" science\nthat would advance through autonomous exploration and organic assessments of\nprogress (e.g., peer-review, theoretical consensus). The failure of this\napproach led to a retrenchment of funding in the 1980s. Amid this \"AI Winter,\"\nan intervention by the U.S. government reoriented the field towards measurable\nprogress on tasks of military and commercial interest. A new evaluation system\ncalled \"benchmarking\" provided an objective way to quantify progress on tasks\nby focusing exclusively on increasing predictive accuracy on example datasets.\nDistilling science down to verifiable metrics clarified the roles of\nscientists, allowed the field to rapidly integrate talent, and provided clear\nsignals of significance and progress. But history has also revealed a tradeoff\nto this streamlined approach to science: the consolidation around external\ninterests and inherent conservatism of benchmarking has disincentivized\nexploration beyond scaling monoculture. In the discussion, we explain how AI's\nmonoculture offers a compelling challenge to the belief that basic,\nexploration-driven research is needed for scientific progress. Implications for\nthe spread of AI monoculture to other sciences in the era of generative AI are\nalso discussed.",
      "tldr_zh": "本论文分析了 AI 研究如何从 1950s 至晚 1980s 的基础科学（protoscience）时代转向以 benchmarking 为主导的认识论单一文化（epistemic monoculture），从而推动了 deep learning 革命。作者通过定性访谈和计算分析，追溯了这一转变的过程，包括 AI 冬季期间的资金紧缩和美国政府干预，导致研究重点从自主探索转向可衡量的任务进展和预测准确率提升。这种方法加速了人才整合和科学进展，但也抑制了创新探索，并强化了外部利益的保守性。论文讨论了 AI monoculture 对科学进步的挑战，并警告其可能扩展到其他领域，如生成式 AI。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.06647v2",
      "published_date": "2024-04-09 22:55:06 UTC",
      "updated_date": "2024-04-11 02:09:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T22:49:05.244765"
    },
    {
      "arxiv_id": "2404.06645v1",
      "title": "GenCHiP: Generating Robot Policy Code for High-Precision and Contact-Rich Manipulation Tasks",
      "title_zh": "GenCHiP：为高精度和接触丰富的操作任务生成机器人策略代码",
      "authors": [
        "Kaylee Burns",
        "Ajinkya Jain",
        "Keegan Go",
        "Fei Xia",
        "Michael Stark",
        "Stefan Schaal",
        "Karol Hausman"
      ],
      "abstract": "Large Language Models (LLMs) have been successful at generating robot policy\ncode, but so far these results have been limited to high-level tasks that do\nnot require precise movement. It is an open question how well such approaches\nwork for tasks that require reasoning over contact forces and working within\ntight success tolerances. We find that, with the right action space, LLMs are\ncapable of successfully generating policies for a variety of contact-rich and\nhigh-precision manipulation tasks, even under noisy conditions, such as\nperceptual errors or grasping inaccuracies. Specifically, we reparameterize the\naction space to include compliance with constraints on the interaction forces\nand stiffnesses involved in reaching a target pose. We validate this approach\non subtasks derived from the Functional Manipulation Benchmark (FMB) and NIST\nTask Board Benchmarks. Exposing this action space alongside methods for\nestimating object poses improves policy generation with an LLM by greater than\n3x and 4x when compared to non-compliant action spaces",
      "tldr_zh": "该论文提出了GenCHiP框架，利用Large Language Models (LLMs)生成机器人策略代码，以应对高精度和接触丰富的操作任务。研究通过重新参数化动作空间，加入对交互力和刚度约束的顺应性设计，并结合物体位姿估计方法，显著提升了策略生成能力，即使在感知错误或抓取不准的噪声条件下也能有效。在Functional Manipulation Benchmark (FMB)和NIST Task Board Benchmarks上，实验结果显示，与非顺应动作空间相比，策略生成效率提高了3倍和4倍。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "I.2.9"
      ],
      "primary_category": "cs.RO",
      "comment": "14 pages, 12 figures",
      "pdf_url": "http://arxiv.org/pdf/2404.06645v1",
      "published_date": "2024-04-09 22:47:25 UTC",
      "updated_date": "2024-04-09 22:47:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T22:49:15.796202"
    },
    {
      "arxiv_id": "2404.06644v1",
      "title": "Khayyam Challenge (PersianMMLU): Is Your LLM Truly Wise to The Persian Language?",
      "title_zh": "翻译失败",
      "authors": [
        "Omid Ghahroodi",
        "Marzia Nouri",
        "Mohammad Vali Sanian",
        "Alireza Sahebi",
        "Doratossadat Dastgheib",
        "Ehsaneddin Asgari",
        "Mahdieh Soleymani Baghshah",
        "Mohammad Hossein Rohban"
      ],
      "abstract": "Evaluating Large Language Models (LLMs) is challenging due to their\ngenerative nature, necessitating precise evaluation methodologies.\nAdditionally, non-English LLM evaluation lags behind English, resulting in the\nabsence or weakness of LLMs for many languages. In response to this necessity,\nwe introduce Khayyam Challenge (also known as PersianMMLU), a meticulously\ncurated collection comprising 20,192 four-choice questions sourced from 38\ndiverse tasks extracted from Persian examinations, spanning a wide spectrum of\nsubjects, complexities, and ages. The primary objective of the Khayyam\nChallenge is to facilitate the rigorous evaluation of LLMs that support the\nPersian language. Distinctive features of the Khayyam Challenge are (i) its\ncomprehensive coverage of various topics, including literary comprehension,\nmathematics, sciences, logic, intelligence testing, etc., aimed at assessing\ndifferent facets of LLMs such as language comprehension, reasoning, and\ninformation retrieval across various educational stages, from lower primary\nschool to upper secondary school (ii) its inclusion of rich metadata such as\nhuman response rates, difficulty levels, and descriptive answers (iii) its\nutilization of new data to avoid data contamination issues prevalent in\nexisting frameworks (iv) its use of original, non-translated data tailored for\nPersian speakers, ensuring the framework is free from translation challenges\nand errors while encompassing cultural nuances (v) its inherent scalability for\nfuture data updates and evaluations without requiring special human effort.\nPrevious works lacked an evaluation framework that combined all of these\nfeatures into a single comprehensive benchmark. Furthermore, we evaluate a wide\nrange of existing LLMs that support the Persian language, with statistical\nanalyses and interpretations of their outputs.",
      "tldr_zh": "本文引入了 Khayyam Challenge（也称为 PersianMMLU），一个包含 20,192 个四选一问题的基准测试，用于评估支持波斯语的 Large Language Models (LLMs)，以填补非英语 LLM 评估的空白。 该框架覆盖多种主题如文学理解、数学、科学和逻辑，包含丰富元数据（如人类响应率和难度水平），并使用原创非翻译数据，确保文化相关性和避免数据污染问题。 与现有基准不同，Khayyam Challenge 具备全面性、可扩展性和新颖性，最终通过对多种 LLMs 的统计分析，揭示了它们在波斯语任务中的性能表现。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.06644v1",
      "published_date": "2024-04-09 22:38:13 UTC",
      "updated_date": "2024-04-09 22:38:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T22:49:28.065782"
    },
    {
      "arxiv_id": "2404.06641v1",
      "title": "Federated learning model for predicting major postoperative complications",
      "title_zh": "预测主要术后并发症的联邦学习模型",
      "authors": [
        "Yonggi Park",
        "Yuanfang Ren",
        "Benjamin Shickel",
        "Ziyuan Guan",
        "Ayush Patela",
        "Yingbo Ma",
        "Zhenhong Hu",
        "Tyler J. Loftus",
        "Parisa Rashidi",
        "Tezcan Ozrazgat-Baslanti",
        "Azra Bihorac"
      ],
      "abstract": "Background: The accurate prediction of postoperative complication risk using\nElectronic Health Records (EHR) and artificial intelligence shows great\npotential. Training a robust artificial intelligence model typically requires\nlarge-scale and diverse datasets. In reality, collecting medical data often\nencounters challenges surrounding privacy protection. Methods: This\nretrospective cohort study includes adult patients who were admitted to UFH\nGainesville (GNV) (n = 79,850) and Jacksonville (JAX) (n = 28,636) for any type\nof inpatient surgical procedure. Using perioperative and intraoperative\nfeatures, we developed federated learning models to predict nine major\npostoperative complications (i.e., prolonged intensive care unit stay and\nmechanical ventilation). We compared federated learning models with local\nlearning models trained on a single site and central learning models trained on\npooled dataset from two centers. Results: Our federated learning models\nachieved the area under the receiver operating characteristics curve (AUROC)\nvalues ranged from 0.81 for wound complications to 0.92 for prolonged ICU stay\nat UFH GNV center. At UFH JAX center, these values ranged from 0.73-0.74 for\nwound complications to 0.92-0.93 for hospital mortality. Federated learning\nmodels achieved comparable AUROC performance to central learning models, except\nfor prolonged ICU stay, where the performance of federated learning models was\nslightly higher than central learning models at UFH GNV center, but slightly\nlower at UFH JAX center. In addition, our federated learning model obtained\ncomparable performance to the best local learning model at each center,\ndemonstrating strong generalizability. Conclusion: Federated learning is shown\nto be a useful tool to train robust and generalizable models from large scale\ndata across multiple institutions where data protection barriers are high.",
      "tldr_zh": "这篇论文开发了一种联邦学习模型，用于基于电子健康记录（EHR）预测九种主要术后并发症，如 ICU 停留延长和机械通气，解决了数据隐私保护的挑战。研究使用两个医疗中心的数据（UFH Gainesville 和 Jacksonville，共计超过 100,000 例患者），将联邦学习模型与本地学习模型和中央学习模型进行比较。结果显示，联邦学习模型的 AUROC 值从 0.81（伤口并发症）到 0.93（医院死亡率）不等，与中央模型性能相当，并在泛化性上优于单站点模型。总之，该方法证明了联邦学习在多机构数据训练中是高效且鲁棒的工具。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.LG",
      "comment": "57 pages. 2 figures, 3 tables, 2 supplemental figures, 8 supplemental\n  tables",
      "pdf_url": "http://arxiv.org/pdf/2404.06641v1",
      "published_date": "2024-04-09 22:31:10 UTC",
      "updated_date": "2024-04-09 22:31:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T22:49:41.201295"
    },
    {
      "arxiv_id": "2404.06633v1",
      "title": "Evolving Loss Functions for Specific Image Augmentation Techniques",
      "title_zh": "针对特定图像增强",
      "authors": [
        "Brandon Morgan",
        "Dean Hougen"
      ],
      "abstract": "Previous work in Neural Loss Function Search (NLFS) has shown a lack of\ncorrelation between smaller surrogate functions and large convolutional neural\nnetworks with massive regularization. We expand upon this research by revealing\nanother disparity that exists, correlation between different types of image\naugmentation techniques. We show that different loss functions can perform well\non certain image augmentation techniques, while performing poorly on others. We\nexploit this disparity by performing an evolutionary search on five types of\nimage augmentation techniques in the hopes of finding image augmentation\nspecific loss functions. The best loss functions from each evolution were then\ntaken and transferred to WideResNet-28-10 on CIFAR-10 and CIFAR-100 across each\nof the five image augmentation techniques. The best from that were then taken\nand evaluated by fine-tuning EfficientNetV2Small on the CARS, Oxford-Flowers,\nand Caltech datasets across each of the five image augmentation techniques.\nMultiple loss functions were found that outperformed cross-entropy across\nmultiple experiments. In the end, we found a single loss function, which we\ncalled the inverse bessel logarithm loss, that was able to outperform\ncross-entropy across the majority of experiments.",
      "tldr_zh": "本文研究扩展了Neural Loss Function Search (NLFS)，揭示了不同图像增强技术之间损失函数性能的相关性差异，显示某些损失函数在特定技术上表现良好，而在其他技术上表现较差。通过evolutionary search在五种图像增强技术上优化特定损失函数，并将其转移到WideResNet-28-10模型上测试CIFAR-10和CIFAR-100数据集，以及在EfficientNetV2Small上微调CARS、Oxford-Flowers和Caltech数据集。实验结果表明，多个损失函数优于cross-entropy，最终的inverse bessel logarithm loss在大多数实验中表现出最佳性能。",
      "categories": [
        "cs.NE",
        "cs.AI"
      ],
      "primary_category": "cs.NE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.06633v1",
      "published_date": "2024-04-09 21:53:53 UTC",
      "updated_date": "2024-04-09 21:53:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T22:49:52.529876"
    },
    {
      "arxiv_id": "2404.06631v1",
      "title": "Counting Objects in a Robotic Hand",
      "title_zh": "在机器人手中计数物体",
      "authors": [
        "Francis Tsow",
        "Tianze Chen",
        "Yu Sun"
      ],
      "abstract": "A robot performing multi-object grasping needs to sense the number of objects\nin the hand after grasping. The count plays an important role in determining\nthe robot's next move and the outcome and efficiency of the whole pick-place\nprocess. This paper presents a data-driven contrastive learning-based counting\nclassifier with a modified loss function as a simple and effective approach for\nobject counting despite significant occlusion challenges caused by robotic\nfingers and objects. The model was validated against other models with three\ndifferent common shapes (spheres, cylinders, and cubes) in simulation and in a\nreal setup. The proposed contrastive learning-based counting approach achieved\nabove 96\\% accuracy for all three objects in the real setup.",
      "tldr_zh": "这篇论文针对机器人抓取多物体后计数的需求，提出了一种基于数据驱动的对比学习（contrastive learning）计数分类器，使用修改后的损失函数来应对机器人手指和物体造成的严重遮挡挑战。该方法简单有效，通过在模拟和真实环境中测试三种常见形状（spheres, cylinders, and cubes），实现了高准确率。实验结果显示，在真实环境中，该分类器对所有三种物体的计数准确率均超过96%，优于其他基准模型。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.06631v1",
      "published_date": "2024-04-09 21:46:14 UTC",
      "updated_date": "2024-04-09 21:46:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T22:50:03.090864"
    },
    {
      "arxiv_id": "2404.06609v1",
      "title": "GOAT-Bench: A Benchmark for Multi-Modal Lifelong Navigation",
      "title_zh": "翻译失败",
      "authors": [
        "Mukul Khanna",
        "Ram Ramrakhya",
        "Gunjan Chhablani",
        "Sriram Yenamandra",
        "Theophile Gervet",
        "Matthew Chang",
        "Zsolt Kira",
        "Devendra Singh Chaplot",
        "Dhruv Batra",
        "Roozbeh Mottaghi"
      ],
      "abstract": "The Embodied AI community has made significant strides in visual navigation\ntasks, exploring targets from 3D coordinates, objects, language descriptions,\nand images. However, these navigation models often handle only a single input\nmodality as the target. With the progress achieved so far, it is time to move\ntowards universal navigation models capable of handling various goal types,\nenabling more effective user interaction with robots. To facilitate this goal,\nwe propose GOAT-Bench, a benchmark for the universal navigation task referred\nto as GO to AnyThing (GOAT). In this task, the agent is directed to navigate to\na sequence of targets specified by the category name, language description, or\nimage in an open-vocabulary fashion. We benchmark monolithic RL and modular\nmethods on the GOAT task, analyzing their performance across modalities, the\nrole of explicit and implicit scene memories, their robustness to noise in goal\nspecifications, and the impact of memory in lifelong scenarios.",
      "tldr_zh": "本论文提出了GOAT-Bench，一个用于多模态终身导航的基准测试平台，旨在解决现有视觉导航模型仅处理单一输入模式（如3D坐标、对象或图像）的局限性。GOAT任务要求代理在开放词汇环境中导航到由类别名称、语言描述或图像指定的目标序列。研究通过基准测试单体RL和模块化方法，分析了它们在不同模式下的性能、显式和隐式场景记忆的作用、对目标规范噪声的鲁棒性，以及在终身场景中的记忆影响。",
      "categories": [
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.06609v1",
      "published_date": "2024-04-09 20:40:00 UTC",
      "updated_date": "2024-04-09 20:40:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T22:50:14.772888"
    },
    {
      "arxiv_id": "2404.06599v3",
      "title": "Collaborative Multi-source Domain Adaptation Through Optimal Transport",
      "title_zh": "翻译失败",
      "authors": [
        "Omar Ghannou",
        "Younès Bennani"
      ],
      "abstract": "Multi-source Domain Adaptation (MDA) seeks to adapt models trained on data\nfrom multiple labeled source domains to perform effectively on an unlabeled\ntarget domain data, assuming access to sources data. To address the challenges\nof model adaptation and data privacy, we introduce Collaborative MDA Through\nOptimal Transport (CMDA-OT), a novel framework consisting of two key phases. In\nthe first phase, each source domain is independently adapted to the target\ndomain using optimal transport methods. In the second phase, a centralized\ncollaborative learning architecture is employed, which aggregates the N models\nfrom the N sources without accessing their data, thereby safeguarding privacy.\nDuring this process, the server leverages a small set of pseudo-labeled samples\nfrom the target domain, known as the target validation subset, to refine and\nguide the adaptation. This dual-phase approach not only improves model\nperformance on the target domain but also addresses vital privacy challenges\ninherent in domain adaptation.",
      "tldr_zh": "这篇论文提出了 CMDA-OT 框架，用于 Multi-source Domain Adaptation (MDA)，旨在将多个带标签源域模型适应到无标签目标域，同时解决模型适应和数据隐私挑战。框架分为两个阶段：首先，使用 Optimal Transport 方法独立地将每个源域适应到目标域；其次，通过集中式协作学习架构聚合 N 个源域模型，而不访问其原始数据，仅利用目标域的一小套伪标签样本（target validation subset）进行精炼和指导。该方法显著提升了目标域上的模型性能，并有效保护了数据隐私。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.06599v3",
      "published_date": "2024-04-09 20:06:25 UTC",
      "updated_date": "2024-08-19 14:24:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T22:50:27.375867"
    },
    {
      "arxiv_id": "2404.06593v1",
      "title": "Spatially Optimized Compact Deep Metric Learning Model for Similarity Search",
      "title_zh": "空间优化的紧凑深度度",
      "authors": [
        "Md. Farhadul Islam",
        "Md. Tanzim Reza",
        "Meem Arafat Manab",
        "Mohammad Rakibul Hasan Mahin",
        "Sarah Zabeen",
        "Jannatun Noor"
      ],
      "abstract": "Spatial optimization is often overlooked in many computer vision tasks.\nFilters should be able to recognize the features of an object regardless of\nwhere it is in the image. Similarity search is a crucial task where spatial\nfeatures decide an important output. The capacity of convolution to capture\nvisual patterns across various locations is limited. In contrast to\nconvolution, the involution kernel is dynamically created at each pixel based\non the pixel value and parameters that have been learned. This study\ndemonstrates that utilizing a single layer of involution feature extractor\nalongside a compact convolution model significantly enhances the performance of\nsimilarity search. Additionally, we improve predictions by using the GELU\nactivation function rather than the ReLU. The negligible amount of weight\nparameters in involution with a compact model with better performance makes the\nmodel very useful in real-world implementations. Our proposed model is below 1\nmegabyte in size. We have experimented with our proposed methodology and other\nmodels on CIFAR-10, FashionMNIST, and MNIST datasets. Our proposed method\noutperforms across all three datasets.",
      "tldr_zh": "本文提出了一种空间优化的紧凑深度度量学习模型，用于提升相似性搜索任务的性能。该模型采用involution kernel作为特征提取层，结合紧凑卷积模型，并将GELU激活函数替换ReLU，以更好地捕捉图像中物体的空间特征，而不受位置影响。实验结果显示，该方法在CIFAR-10、FashionMNIST和MNIST数据集上均优于其他基线模型，且模型大小小于1MB，适用于实际场景的部署。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "68",
        "I.4.7; I.2.6; I.2.10"
      ],
      "primary_category": "cs.CV",
      "comment": "5 pages, 3 figures,",
      "pdf_url": "http://arxiv.org/pdf/2404.06593v1",
      "published_date": "2024-04-09 19:49:01 UTC",
      "updated_date": "2024-04-09 19:49:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T22:50:40.072156"
    },
    {
      "arxiv_id": "2404.06579v1",
      "title": "Less is More for Improving Automatic Evaluation of Factual Consistency",
      "title_zh": "翻译失败",
      "authors": [
        "Tong Wang",
        "Ninad Kulkarni",
        "Yanjun Qi"
      ],
      "abstract": "Assessing the factual consistency of automatically generated texts in\nrelation to source context is crucial for developing reliable natural language\ngeneration applications. Recent literature proposes AlignScore which uses a\nunified alignment model to evaluate factual consistency and substantially\noutperforms previous methods across many benchmark tasks. In this paper, we\ntake a closer look of datasets used in AlignScore and uncover an unexpected\nfinding: utilizing a smaller number of data points can actually improve\nperformance. We process the original AlignScore training dataset to remove\nnoise, augment with robustness-enhanced samples, and utilize a subset\ncomprising 10\\% of the data to train an improved factual consistency evaluation\nmodel, we call LIM-RA (Less Is More for Robust AlignScore). LIM-RA demonstrates\nsuperior performance, consistently outperforming AlignScore and other strong\nbaselines like ChatGPT across four benchmarks (two utilizing traditional\nnatural language generation datasets and two focused on large language model\noutputs). Our experiments show that LIM-RA achieves the highest score on 24 of\nthe 33 test datasets, while staying competitive on the rest, establishing the\nnew state-of-the-art benchmarks.",
      "tldr_zh": "本文提出了一种改进事实一致性自动评估的方法，发现使用更少的数据点反而能提升性能。作者对 AlignScore 的训练数据集进行处理，包括去除噪声、增强鲁棒性样本，并仅使用 10% 的数据训练了新模型 LIM-RA（Less Is More for Robust AlignScore）。实验结果显示，LIM-RA 在四个基准测试中（如传统自然语言生成数据集和大型语言模型输出）全面超越 AlignScore 和强基线如 ChatGPT，在 33 个测试数据集的 24 个上达到最高分数，确立了新的最先进基准。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted in NAACL24 Industry; 7 pages",
      "pdf_url": "http://arxiv.org/pdf/2404.06579v1",
      "published_date": "2024-04-09 19:02:12 UTC",
      "updated_date": "2024-04-09 19:02:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T22:50:52.829137"
    },
    {
      "arxiv_id": "2404.06571v1",
      "title": "Building A Knowledge Graph to Enrich ChatGPT Responses in Manufacturing Service Discovery",
      "title_zh": "翻译失败",
      "authors": [
        "Yunqing Li",
        "Binil Starly"
      ],
      "abstract": "Sourcing and identification of new manufacturing partners is crucial for\nmanufacturing system integrators to enhance agility and reduce risk through\nsupply chain diversification in the global economy. The advent of advanced\nlarge language models has captured significant interest, due to their ability\nto generate comprehensive and articulate responses across a wide range of\nknowledge domains. However, the system often falls short in accuracy and\ncompleteness when responding to domain-specific inquiries, particularly in\nareas like manufacturing service discovery. This research explores the\npotential of leveraging Knowledge Graphs in conjunction with ChatGPT to\nstreamline the process for prospective clients in identifying small\nmanufacturing enterprises. In this study, we propose a method that integrates\nbottom-up ontology with advanced machine learning models to develop a\nManufacturing Service Knowledge Graph from an array of structured and\nunstructured data sources, including the digital footprints of small-scale\nmanufacturers throughout North America. The Knowledge Graph and the learned\ngraph embedding vectors are leveraged to tackle intricate queries within the\ndigital supply chain network, responding with enhanced reliability and greater\ninterpretability. The approach highlighted is scalable to millions of entities\nthat can be distributed to form a global Manufacturing Service Knowledge\nNetwork Graph that can potentially interconnect multiple types of Knowledge\nGraphs that span industry sectors, geopolitical boundaries, and business\ndomains. The dataset developed for this study, now publicly accessible,\nencompasses more than 13,000 manufacturers' weblinks, manufacturing services,\ncertifications, and location entity types.",
      "tldr_zh": "该研究针对制造业服务发现中的问题，提出了一种利用 Knowledge Graphs 增强 ChatGPT 响应的方法，以帮助系统集成商更高效地识别小型制造合作伙伴。研究方法包括整合 bottom-up ontology 与高级机器学习模型，从结构化和非结构化数据源（如北美制造商的数字足迹）构建 Manufacturing Service Knowledge Graph，并使用图嵌入向量处理复杂查询，提高响应的准确性和可解释性。该框架具有可扩展性，可扩展到全球 Manufacturing Service Knowledge Network Graph，并互联多种行业 Knowledge Graphs；同时，研究公开了一个包含超过13,000 个制造商数据的数据集，为未来应用奠定基础。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.06571v1",
      "published_date": "2024-04-09 18:46:46 UTC",
      "updated_date": "2024-04-09 18:46:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T22:51:04.957069"
    },
    {
      "arxiv_id": "2404.07242v1",
      "title": "Sandwich attack: Multi-language Mixture Adaptive Attack on LLMs",
      "title_zh": "Sandwich attack：针对大型语言模型的多语言混合自适应攻击",
      "authors": [
        "Bibek Upadhayay",
        "Vahid Behzadan"
      ],
      "abstract": "Large Language Models (LLMs) are increasingly being developed and applied,\nbut their widespread use faces challenges. These include aligning LLMs'\nresponses with human values to prevent harmful outputs, which is addressed\nthrough safety training methods. Even so, bad actors and malicious users have\nsucceeded in attempts to manipulate the LLMs to generate misaligned responses\nfor harmful questions such as methods to create a bomb in school labs, recipes\nfor harmful drugs, and ways to evade privacy rights. Another challenge is the\nmultilingual capabilities of LLMs, which enable the model to understand and\nrespond in multiple languages. Consequently, attackers exploit the unbalanced\npre-training datasets of LLMs in different languages and the comparatively\nlower model performance in low-resource languages than high-resource ones. As a\nresult, attackers use a low-resource languages to intentionally manipulate the\nmodel to create harmful responses. Many of the similar attack vectors have been\npatched by model providers, making the LLMs more robust against language-based\nmanipulation. In this paper, we introduce a new black-box attack vector called\nthe \\emph{Sandwich attack}: a multi-language mixture attack, which manipulates\nstate-of-the-art LLMs into generating harmful and misaligned responses. Our\nexperiments with five different models, namely Google's Bard, Gemini Pro,\nLLaMA-2-70-B-Chat, GPT-3.5-Turbo, GPT-4, and Claude-3-OPUS, show that this\nattack vector can be used by adversaries to generate harmful responses and\nelicit misaligned responses from these models. By detailing both the mechanism\nand impact of the Sandwich attack, this paper aims to guide future research and\ndevelopment towards more secure and resilient LLMs, ensuring they serve the\npublic good while minimizing potential for misuse.",
      "tldr_zh": "本论文提出了一种名为 Sandwich attack 的黑盒攻击方法，针对大型语言模型（LLMs）的多语言混合特性，旨在绕过安全训练并诱导模型生成有害或不合规响应。该攻击利用 LLMs 在低资源语言上的性能不平衡，通过混合多种语言的输入来操纵模型，例如生成炸弹制作方法或有害药物配方。实验在 Google Bard、Gemini Pro、LLaMA-2-70-B-Chat、GPT-3.5-Turbo、GPT-4 和 Claude-3-OPUS 等五种模型上进行，结果显示攻击成功率高，提升了模型生成有害响应的风险。该研究强调了 LLMs 的潜在漏洞，并为未来开发更安全、鲁棒的模型提供指导。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.07242v1",
      "published_date": "2024-04-09 18:29:42 UTC",
      "updated_date": "2024-04-09 18:29:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T22:51:16.782313"
    },
    {
      "arxiv_id": "2404.06561v1",
      "title": "Learning Strategies For Successful Crowd Navigation",
      "title_zh": "翻译失败",
      "authors": [
        "Rajshree Daulatabad",
        "Serena Nath"
      ],
      "abstract": "Teaching autonomous mobile robots to successfully navigate human crowds is a\nchallenging task. Not only does it require planning, but it requires\nmaintaining social norms which may differ from one context to another. Here we\nfocus on crowd navigation, using a neural network to learn specific strategies\nin-situ with a robot. This allows us to take into account human behavior and\nreactions toward a real robot as well as learn strategies that are specific to\nvarious scenarios in that context. A CNN takes a top-down image of the scene as\ninput and outputs the next action for the robot to take in terms of speed and\nangle. Here we present the method, experimental results, and quantitatively\nevaluate our approach.",
      "tldr_zh": "本研究探讨了教导自主移动机器人成功在人群中导航的挑战，包括规划路径和遵守不同上下文的社会规范。作者提出了一种使用神经网络在现场学习特定策略的方法，其中CNN（Convolutional Neural Network）以场景的俯视图作为输入，输出机器人的速度和角度，从而考虑人类行为和反应。实验结果显示，该方法在各种场景中有效，并通过定量评估验证了其性能。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.RO",
      "comment": "8 pages",
      "pdf_url": "http://arxiv.org/pdf/2404.06561v1",
      "published_date": "2024-04-09 18:25:21 UTC",
      "updated_date": "2024-04-09 18:25:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T22:51:27.717141"
    },
    {
      "arxiv_id": "2404.06511v2",
      "title": "MoReVQA: Exploring Modular Reasoning Models for Video Question Answering",
      "title_zh": "翻译失败",
      "authors": [
        "Juhong Min",
        "Shyamal Buch",
        "Arsha Nagrani",
        "Minsu Cho",
        "Cordelia Schmid"
      ],
      "abstract": "This paper addresses the task of video question answering (videoQA) via a\ndecomposed multi-stage, modular reasoning framework. Previous modular methods\nhave shown promise with a single planning stage ungrounded in visual content.\nHowever, through a simple and effective baseline, we find that such systems can\nlead to brittle behavior in practice for challenging videoQA settings. Thus,\nunlike traditional single-stage planning methods, we propose a multi-stage\nsystem consisting of an event parser, a grounding stage, and a final reasoning\nstage in conjunction with an external memory. All stages are training-free, and\nperformed using few-shot prompting of large models, creating interpretable\nintermediate outputs at each stage. By decomposing the underlying planning and\ntask complexity, our method, MoReVQA, improves over prior work on standard\nvideoQA benchmarks (NExT-QA, iVQA, EgoSchema, ActivityNet-QA) with\nstate-of-the-art results, and extensions to related tasks (grounded videoQA,\nparagraph captioning).",
      "tldr_zh": "这篇论文提出MoReVQA，一种多阶段模块化推理框架，用于视频问答（videoQA），旨在解决传统单一规划阶段的脆弱性问题。该框架包括事件解析器（event parser）、接地阶段（grounding stage）和最终推理阶段（final reasoning stage），结合外部内存，并通过few-shot prompting实现无训练的、可解释中间输出。通过分解任务复杂度，MoReVQA在NExT-QA、iVQA、EgoSchema和ActivityNet-QA等基准上取得了state-of-the-art结果，并扩展到grounded videoQA和paragraph captioning等相关任务。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "CVPR 2024; updated NExT-GQA results in Appendix",
      "pdf_url": "http://arxiv.org/pdf/2404.06511v2",
      "published_date": "2024-04-09 17:59:31 UTC",
      "updated_date": "2025-03-27 05:18:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T22:51:41.949469"
    },
    {
      "arxiv_id": "2404.06492v2",
      "title": "Graph Reinforcement Learning for Combinatorial Optimization: A Survey and Unifying Perspective",
      "title_zh": "图强化学习在组合优化中的应用：综述与统一视角",
      "authors": [
        "Victor-Alexandru Darvariu",
        "Stephen Hailes",
        "Mirco Musolesi"
      ],
      "abstract": "Graphs are a natural representation for systems based on relations between\nconnected entities. Combinatorial optimization problems, which arise when\nconsidering an objective function related to a process of interest on discrete\nstructures, are often challenging due to the rapid growth of the solution\nspace. The trial-and-error paradigm of Reinforcement Learning has recently\nemerged as a promising alternative to traditional methods, such as exact\nalgorithms and (meta)heuristics, for discovering better decision-making\nstrategies in a variety of disciplines including chemistry, computer science,\nand statistics. Despite the fact that they arose in markedly different fields,\nthese techniques share significant commonalities. Therefore, we set out to\nsynthesize this work in a unifying perspective that we term Graph Reinforcement\nLearning, interpreting it as a constructive decision-making method for graph\nproblems. After covering the relevant technical background, we review works\nalong the dividing line of whether the goal is to optimize graph structure\ngiven a process of interest, or to optimize the outcome of the process itself\nunder fixed graph structure. Finally, we discuss the common challenges facing\nthe field and open research questions. In contrast with other surveys, the\npresent work focuses on non-canonical graph problems for which performant\nalgorithms are typically not known and Reinforcement Learning is able to\nprovide efficient and effective solutions.",
      "tldr_zh": "这篇论文对Graph Reinforcement Learning在组合优化领域的应用进行了全面调查和统一视角，强调强化学习(Reinforcement Learning)作为一种试错方法，能够有效解决传统算法（如精确算法和元启发式）在图结构优化中的挑战。作者将相关工作分类为优化图结构或在固定图结构下优化过程结果，审视了其在化学、计算机科学和统计学等领域的共同性，并将其解释为针对非规范图问题的构造性决策方法。论文讨论了领域面临的共同挑战和开放研究问题，突出了强化学习在提供高效解决方案方面的优势，与其他调查不同的是，它聚焦于那些缺乏标准算法的复杂图优化问题。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "To appear in Transactions on Machine Learning Research (TMLR)",
      "pdf_url": "http://arxiv.org/pdf/2404.06492v2",
      "published_date": "2024-04-09 17:45:25 UTC",
      "updated_date": "2024-08-20 11:21:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T22:51:53.621888"
    },
    {
      "arxiv_id": "2404.06488v1",
      "title": "Pitfalls of Conversational LLMs on News Debiasing",
      "title_zh": "翻译失败",
      "authors": [
        "Ipek Baris Schlicht",
        "Defne Altiok",
        "Maryanne Taouk",
        "Lucie Flek"
      ],
      "abstract": "This paper addresses debiasing in news editing and evaluates the\neffectiveness of conversational Large Language Models in this task. We designed\nan evaluation checklist tailored to news editors' perspectives, obtained\ngenerated texts from three popular conversational models using a subset of a\npublicly available dataset in media bias, and evaluated the texts according to\nthe designed checklist. Furthermore, we examined the models as evaluator for\nchecking the quality of debiased model outputs. Our findings indicate that none\nof the LLMs are perfect in debiasing. Notably, some models, including ChatGPT,\nintroduced unnecessary changes that may impact the author's style and create\nmisinformation. Lastly, we show that the models do not perform as proficiently\nas domain experts in evaluating the quality of debiased outputs.",
      "tldr_zh": "这篇论文探讨了对话式大型语言模型（conversational LLMs）在新闻去偏见（debiasing）任务中的缺陷，强调这些模型可能引入不必要的改动，从而影响作者风格并制造误信息。研究者设计了一个针对新闻编辑视角的评估检查表，使用公共数据集子集从三个流行模型（如ChatGPT）生成文本，并据此评估模型性能；同时，测试了这些模型作为评估者的能力。结果显示，没有LLM在去偏见方面表现完美，且它们在评估去偏见输出质量时远逊于领域专家。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "The paper is accepted at the DELITE workshop which is co-located at\n  COLING/LREC",
      "pdf_url": "http://arxiv.org/pdf/2404.06488v1",
      "published_date": "2024-04-09 17:42:59 UTC",
      "updated_date": "2024-04-09 17:42:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T22:52:04.807938"
    },
    {
      "arxiv_id": "2404.06484v5",
      "title": "Public-private funding models in open source software development: A case study on scikit-learn",
      "title_zh": "开源软件开发中的公私合作资金模型：以 scikit-learn 为案例研究",
      "authors": [
        "Cailean Osborne"
      ],
      "abstract": "Governments are increasingly funding open source software (OSS) development\nto support software security, digital sovereignty, and national competitiveness\nin science and innovation, amongst others. However, little is known about how\nOSS developers evaluate the relative benefits and drawbacks of governmental\nfunding for OSS. This study explores this question through a case study on\nscikit-learn, a Python library for machine learning, funded by public research\ngrants, commercial sponsorship, micro-donations, and a 32 euro million grant\nannounced in France's artificial intelligence strategy. Through 25 interviews\nwith scikit-learn's maintainers and funders, this study makes two key\ncontributions. First, it contributes empirical findings about the benefits and\ndrawbacks of public and private funding in an impactful OSS project, and the\ngovernance protocols employed by the maintainers to balance the diverse\ninterests of their community and funders. Second, it offers practical lessons\non funding for OSS developers, governments, and companies based on the\nexperience of scikit-learn. The paper concludes with key recommendations for\npractitioners and future research directions.",
      "tldr_zh": "本研究通过对 scikit-learn 库的案例分析，探讨了开源软件 (OSS) 开发中公私资金模式的利弊，该库由公共研究资助、商业赞助、微捐款和一笔 3200 万欧元的法国 AI 战略资助支持。研究方法包括对 25 名 scikit-learn 维护者和资助者的访谈，揭示了公共和私人资助带来的实证益处（如支持软件安全和创新）以及潜在缺点（如治理挑战），并介绍了维护者采用的治理协议来平衡社区和资助者利益。最终，该研究为 OSS 开发者、政府和公司提供实用教训，并提出关键推荐和未来研究方向，以优化资助策略。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.CY",
        "cs.LG",
        "K.4.1"
      ],
      "primary_category": "cs.SE",
      "comment": "15 pages",
      "pdf_url": "http://arxiv.org/pdf/2404.06484v5",
      "published_date": "2024-04-09 17:35:11 UTC",
      "updated_date": "2024-05-03 15:57:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T22:52:18.181575"
    },
    {
      "arxiv_id": "2404.06480v2",
      "title": "Ada-LEval: Evaluating long-context LLMs with length-adaptable benchmarks",
      "title_zh": "Ada-LEval：使用长度可适应基准评估长上下文大语言模型",
      "authors": [
        "Chonghua Wang",
        "Haodong Duan",
        "Songyang Zhang",
        "Dahua Lin",
        "Kai Chen"
      ],
      "abstract": "Recently, the large language model (LLM) community has shown increasing\ninterest in enhancing LLMs' capability to handle extremely long documents. As\nvarious long-text techniques and model architectures emerge, the precise and\ndetailed evaluation of models' long-text capabilities has become increasingly\nimportant. Existing long-text evaluation benchmarks, such as L-Eval and\nLongBench, construct long-text test sets based on open-source datasets,\nfocusing mainly on QA and summarization tasks. These datasets include test\nsamples of varying lengths (from 2k to 32k+) entangled together, making it\nchallenging to assess model capabilities across different length ranges.\nMoreover, they do not cover the ultralong settings (100k+ tokens) that the\nlatest LLMs claim to achieve. In this paper, we introduce Ada-LEval, a\nlength-adaptable benchmark for evaluating the long-context understanding of\nLLMs. Ada-LEval includes two challenging subsets, TSort and BestAnswer, which\nenable a more reliable evaluation of LLMs' long context capabilities. These\nbenchmarks support intricate manipulation of the length of test cases, and can\neasily produce text samples up to 128k tokens. We evaluate 4 state-of-the-art\nclosed-source API models and 6 open-source models with Ada-LEval. The\nevaluation results demonstrate the limitations of current LLMs, especially in\nultra-long-context settings. Our code is available at\nhttps://github.com/open-compass/Ada-LEval.",
      "tldr_zh": "该论文指出，现有的长文本评估基准如 L-Eval 和 LongBench 存在局限性，因为它们混合了不同长度样本且未覆盖超长上下文（100k+ tokens），难以精确评估 LLMs 的长文本处理能力。作者引入了 Ada-LEval，这是一个长度可适应的基准，包括 TSort 和 BestAnswer 子集，支持生成高达128k tokens的测试样本，以更可靠地评估模型的长期理解能力。通过评估4个闭源API模型和6个开源模型，结果显示当前 LLMs 尤其在超长上下文设置中表现出显著局限性。代码已在 https://github.com/open-compass/Ada-LEval 公开。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "NAACL 2024",
      "pdf_url": "http://arxiv.org/pdf/2404.06480v2",
      "published_date": "2024-04-09 17:30:48 UTC",
      "updated_date": "2024-04-10 07:40:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T22:52:30.319291"
    },
    {
      "arxiv_id": "2404.06479v4",
      "title": "Visually Descriptive Language Model for Vector Graphics Reasoning",
      "title_zh": "视觉描述语言模型用于矢量图形推理",
      "authors": [
        "Zhenhailong Wang",
        "Joy Hsu",
        "Xingyao Wang",
        "Kuan-Hao Huang",
        "Manling Li",
        "Jiajun Wu",
        "Heng Ji"
      ],
      "abstract": "Despite significant advancements, large multimodal models (LMMs) still\nstruggle to bridge the gap between low-level visual perception -- focusing on\nshapes, sizes, and layouts -- and high-level language reasoning, such as\nsemantics and logic. This limitation is evident in tasks that require precise\nvisual perception, like comparing geometric properties or solving visual\nreasoning problems. To study this failure mode, we focus on vector graphics --\nimages composed of 2D objects and shapes, prevalent in LMM-based tasks in web,\ndesign, and OS environments. We identify two key research questions: how can we\nenable precise visual perception, and how can we facilitate high-level\nreasoning based on such low-level perceptions? To capture fine visual details,\nwe use Scalable Vector Graphics (SVG) for accurate encoding of visual scenes.\nHowever, SVGs are not readily interpretable by LMMs in a zero-shot manner. To\ntackle this, we propose the Visually Descriptive Language Model (VDLM), which\nintroduces a Primal Visual Description (PVD) as an intermediate textual\nrepresentation. PVD translates SVGs into a text-based abstraction consisting of\nprimitive attributes (e.g., shape, position, measurement) and their\ncorresponding values. PVD can be learned using task-agnostic synthesized data\nand represents visual primitives that are universal across vector graphics.\nThis abstraction is more structured, allowing for direct interpretation by\nfoundation models for zero-shot generalization. Without human-annotated data,\nempirical results show that VDLM significantly improves state-of-the-art LMMs\nlike GPT-4o on various multimodal perception and reasoning tasks. Extensive\nanalyses of VDLM show improved interpretability due to its disentangled\nperception and reasoning. We also demonstrate a positive correlation between\nPVD quality and task performance. Project page:\nhttps://mikewangwzhl.github.io/VDLM/",
      "tldr_zh": "该研究探讨了大型多模态模型 (LMMs) 在低级视觉感知（如形状和布局）与高级语言推理（如语义和逻辑）之间存在的差距，特别针对矢量图形任务提出解决方案。作者引入 Visually Descriptive Language Model (VDLM)，通过 Primal Visual Description (PVD) 将 Scalable Vector Graphics (SVG) 转化为结构化的文本抽象，包括形状、位置和测量等原始属性，从而实现精确视觉感知和零样本推理。实验结果显示，VDLM 无需人类标注数据即可显著提升 GPT-4o 等模型在多模态感知和推理任务上的性能，并提高了模型的可解释性，同时证明了 PVD 质量与任务表现正相关。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.CL",
      "comment": "Project page: https://mikewangwzhl.github.io/VDLM/",
      "pdf_url": "http://arxiv.org/pdf/2404.06479v4",
      "published_date": "2024-04-09 17:30:18 UTC",
      "updated_date": "2024-10-03 21:59:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T22:52:41.761052"
    },
    {
      "arxiv_id": "2404.06474v3",
      "title": "Autonomous Evaluation and Refinement of Digital Agents",
      "title_zh": "翻译失败",
      "authors": [
        "Jiayi Pan",
        "Yichi Zhang",
        "Nicholas Tomlin",
        "Yifei Zhou",
        "Sergey Levine",
        "Alane Suhr"
      ],
      "abstract": "We show that domain-general automatic evaluators can significantly improve\nthe performance of agents for web navigation and device control. We experiment\nwith multiple evaluation models that trade off between inference cost,\nmodularity of design, and accuracy. We validate the performance of these models\nin several popular benchmarks for digital agents, finding between 74.4 and\n92.9% agreement with oracle evaluation metrics. Finally, we use these\nevaluators to improve the performance of existing agents via fine-tuning and\ninference-time guidance. Without any additional supervision, we improve\nstate-of-the-art performance by 29% on the popular benchmark WebArena, and\nachieve around 75% relative improvement in device control settings.",
      "tldr_zh": "这篇论文探讨了领域通用的自动评估器如何显著提升数字代理在网页导航和设备控制中的性能。研究者实验了多种评估模型，权衡推理成本、模块化设计和准确性，并在热门基准测试中实现了74.4%至92.9%的与oracle评估指标一致性。通过微调和推理时指导，这些评估器无需额外监督就改善了现有代理的表现，在WebArena基准上提升29%，并在设备控制场景中获得约75%的相对性能改进。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Published at COLM 2024. Code at\n  https://github.com/Berkeley-NLP/Agent-Eval-Refine",
      "pdf_url": "http://arxiv.org/pdf/2404.06474v3",
      "published_date": "2024-04-09 17:25:47 UTC",
      "updated_date": "2024-10-07 14:19:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T22:52:55.116290"
    },
    {
      "arxiv_id": "2404.06529v1",
      "title": "Emergent Braitenberg-style Behaviours for Navigating the ViZDoom `My Way Home' Labyrinth",
      "title_zh": "翻译失败",
      "authors": [
        "Caleidgh Bayer",
        "Robert J. Smith",
        "Malcolm I. Heywood"
      ],
      "abstract": "The navigation of complex labyrinths with tens of rooms under visual\npartially observable state is typically addressed using recurrent deep\nreinforcement learning architectures. In this work, we show that navigation can\nbe achieved through the emergent evolution of a simple Braitentberg-style\nheuristic that structures the interaction between agent and labyrinth, i.e.\ncomplex behaviour from simple heuristics. To do so, the approach of tangled\nprogram graphs is assumed in which programs cooperatively coevolve to develop a\nmodular indexing scheme that only employs 0.8\\% of the state space. We\nattribute this simplicity to several biases implicit in the representation,\nsuch as the use of pixel indexing as opposed to deploying a convolutional\nkernel or image processing operators.",
      "tldr_zh": "本研究探讨了在视觉部分可观察状态下，使用演化出的简单 Braitenberg-style 启发式来实现代理在 ViZDoom `My Way Home' 迷宫中的导航，从而从简单规则中涌现复杂行为，而非依赖传统循环深度强化学习架构。方法采用 tangled program graphs 框架，让程序协同进化，开发一个模块化的索引方案，仅利用 0.8% 的状态空间。这种简单性归因于表示中的偏差，如使用像素索引而非卷积核或图像处理操作，从而提升了导航效率和可解释性。",
      "categories": [
        "cs.NE",
        "cs.AI"
      ],
      "primary_category": "cs.NE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.06529v1",
      "published_date": "2024-04-09 17:12:16 UTC",
      "updated_date": "2024-04-09 17:12:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T22:53:07.714002"
    },
    {
      "arxiv_id": "2404.06453v1",
      "title": "PURE: Turning Polysemantic Neurons Into Pure Features by Identifying Relevant Circuits",
      "title_zh": "翻译失败",
      "authors": [
        "Maximilian Dreyer",
        "Erblina Purelku",
        "Johanna Vielhaben",
        "Wojciech Samek",
        "Sebastian Lapuschkin"
      ],
      "abstract": "The field of mechanistic interpretability aims to study the role of\nindividual neurons in Deep Neural Networks. Single neurons, however, have the\ncapability to act polysemantically and encode for multiple (unrelated)\nfeatures, which renders their interpretation difficult. We present a method for\ndisentangling polysemanticity of any Deep Neural Network by decomposing a\npolysemantic neuron into multiple monosemantic \"virtual\" neurons. This is\nachieved by identifying the relevant sub-graph (\"circuit\") for each \"pure\"\nfeature. We demonstrate how our approach allows us to find and disentangle\nvarious polysemantic units of ResNet models trained on ImageNet. While\nevaluating feature visualizations using CLIP, our method effectively\ndisentangles representations, improving upon methods based on neuron\nactivations. Our code is available at https://github.com/maxdreyer/PURE.",
      "tldr_zh": "该论文提出PURE方法，用于解决深度神经网络中多义神经元(Polysemantic Neurons)的解释难题，通过识别相关电路(Relevant Circuits)将这些神经元分解成多个单义的“虚拟”神经元，从而实现特征的纯化。方法涉及分析神经网络的子图，以在ResNet模型上训练的ImageNet数据集上进行演示，并使用CLIP评估特征可视化。实验结果表明，PURE显著改善了表示的解耦表现，优于基于神经元激活的传统方法，并提供了开源代码以供进一步验证。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "14 pages (4 pages manuscript, 2 pages references, 8 pages appendix)",
      "pdf_url": "http://arxiv.org/pdf/2404.06453v1",
      "published_date": "2024-04-09 16:54:19 UTC",
      "updated_date": "2024-04-09 16:54:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T22:53:19.033735"
    },
    {
      "arxiv_id": "2404.06448v2",
      "title": "Automated Federated Pipeline for Parameter-Efficient Fine-Tuning of Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Zihan Fang",
        "Zheng Lin",
        "Zhe Chen",
        "Xianhao Chen",
        "Yue Gao",
        "Yuguang Fang"
      ],
      "abstract": "Recently, there has been a surge in the development of advanced intelligent\ngenerative content (AIGC), especially large language models (LLMs). However,\nfor many downstream tasks, it is necessary to fine-tune LLMs using private\ndata. While federated learning offers a promising privacy-preserving solution\nto LLM fine-tuning, the substantial size of an LLM, combined with high\ncomputational and communication demands, makes it hard to apply to downstream\ntasks. More importantly, private edge servers often possess varying computing\nand network resources in real-world scenarios, introducing additional\ncomplexities to LLM fine-tuning. To tackle these problems, we design and\nimplement an automated federated pipeline, named FedPipe, to fine-tune LLMs\nwith minimal training cost but without adding any inference latency. FedPipe\nfirstly identifies the weights to be fine-tuned based on their contributions to\nthe LLM training. It then configures a low-rank adapter for each selected\nweight to train local low-rank adapters on an edge server, and aggregate local\nadapters of all edge servers to fine-tune the whole LLM. Finally, it\nappropriately quantizes the parameters of LLM to reduce memory space according\nto the requirements of edge servers. Extensive experiments demonstrate that\nFedPipe expedites the model training and achieves higher accuracy than\nstate-of-the-art benchmarks.",
      "tldr_zh": "该研究提出了一种自动化联邦管道 FedPipe，用于参数高效 fine-tuning 大语言模型 (LLMs)，以解决私有数据训练中的隐私保护、计算通信开销和边缘服务器资源不均等问题。FedPipe 通过识别关键权重、为选定权重配置低秩适配器 (low-rank adapters) 在本地训练并聚合、以及根据需求量化模型参数，来实现高效 federated learning，而不增加推理延迟。实验结果显示，FedPipe 显著加速了模型训练过程，并比现有基准模型取得了更高的准确率。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "15 pages, 16 figures",
      "pdf_url": "http://arxiv.org/pdf/2404.06448v2",
      "published_date": "2024-04-09 16:50:30 UTC",
      "updated_date": "2024-12-06 07:10:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T22:53:30.035011"
    },
    {
      "arxiv_id": "2404.06430v2",
      "title": "pfl-research: simulation framework for accelerating research in Private Federated Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Filip Granqvist",
        "Congzheng Song",
        "Áine Cahill",
        "Rogier van Dalen",
        "Martin Pelikan",
        "Yi Sheng Chan",
        "Xiaojun Feng",
        "Natarajan Krishnaswami",
        "Vojta Jina",
        "Mona Chitnis"
      ],
      "abstract": "Federated learning (FL) is an emerging machine learning (ML) training\nparadigm where clients own their data and collaborate to train a global model,\nwithout revealing any data to the server and other participants. Researchers\ncommonly perform experiments in a simulation environment to quickly iterate on\nideas. However, existing open-source tools do not offer the efficiency required\nto simulate FL on larger and more realistic FL datasets. We introduce\npfl-research, a fast, modular, and easy-to-use Python framework for simulating\nFL. It supports TensorFlow, PyTorch, and non-neural network models, and is\ntightly integrated with state-of-the-art privacy algorithms. We study the speed\nof open-source FL frameworks and show that pfl-research is 7-72$\\times$ faster\nthan alternative open-source frameworks on common cross-device setups. Such\nspeedup will significantly boost the productivity of the FL research community\nand enable testing hypotheses on realistic FL datasets that were previously too\nresource intensive. We release a suite of benchmarks that evaluates an\nalgorithm's overall performance on a diverse set of realistic scenarios. The\ncode is available on GitHub at https://github.com/apple/pfl-research.",
      "tldr_zh": "该论文引入了 pfl-research，这是一个快速、可模块化和易于使用的 Python 框架，旨在加速 Private Federated Learning (FL) 研究中的模拟过程。该框架支持 TensorFlow、PyTorch 和非神经网络模型，并与先进的隐私算法紧密集成，允许研究者在更大、更真实的 FL 数据集上高效迭代想法。实验结果显示，pfl-research 在常见跨设备设置中比其他开源框架快 7-72 倍，从而显著提升 FL 研究社区的生产力和测试真实场景的可能性；此外，论文还发布了多样化基准测试套件，并开源代码于 GitHub。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.06430v2",
      "published_date": "2024-04-09 16:23:01 UTC",
      "updated_date": "2024-12-10 11:21:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T22:53:42.502849"
    },
    {
      "arxiv_id": "2404.06429v3",
      "title": "Magic-Boost: Boost 3D Generation with Multi-View Conditioned Diffusion",
      "title_zh": "Magic-Boost：通过多视图条件扩散提升 3D 生成",
      "authors": [
        "Fan Yang",
        "Jianfeng Zhang",
        "Yichun Shi",
        "Bowen Chen",
        "Chenxu Zhang",
        "Huichao Zhang",
        "Xiaofeng Yang",
        "Xiu Li",
        "Jiashi Feng",
        "Guosheng Lin"
      ],
      "abstract": "Benefiting from the rapid development of 2D diffusion models, 3D content\ngeneration has witnessed significant progress. One promising solution is to\nfinetune the pre-trained 2D diffusion models to produce multi-view images and\nthen reconstruct them into 3D assets via feed-forward sparse-view\nreconstruction models. However, limited by the 3D inconsistency in the\ngenerated multi-view images and the low reconstruction resolution of the\nfeed-forward reconstruction models, the generated 3d assets are still limited\nto incorrect geometries and blurry textures. To address this problem, we\npresent a multi-view based refine method, named Magic-Boost, to further refine\nthe generation results. In detail, we first propose a novel multi-view\nconditioned diffusion model which extracts 3d prior from the synthesized\nmulti-view images to synthesize high-fidelity novel view images and then\nintroduce a novel iterative-update strategy to adopt it to provide precise\nguidance to refine the coarse generated results through a fast optimization\nprocess. Conditioned on the strong 3d priors extracted from the synthesized\nmulti-view images, Magic-Boost is capable of providing precise optimization\nguidance that well aligns with the coarse generated 3D assets, enriching the\nlocal detail in both geometry and texture within a short time ($\\sim15$min).\nExtensive experiments show Magic-Boost greatly enhances the coarse generated\ninputs, generates high-quality 3D assets with rich geometric and textural\ndetails. (Project Page: https://magic-research.github.io/magic-boost/)",
      "tldr_zh": "这篇论文提出了 Magic-Boost，一种基于多视图条件扩散模型的方法，用于提升 3D 生成质量，以解决现有模型在多视图图像不一致性和重建分辨率低的问题。Magic-Boost 首先从合成的多视图图像中提取 3D 先验，生成高保真新型视图图像，然后通过迭代更新策略提供精确指导，在短时间内（约 15 分钟）精炼粗糙的 3D 资产的几何和纹理细节。实验结果显示，该方法显著提高了生成质量，产出具有丰富几何和纹理细节的高质量 3D 资产。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.06429v3",
      "published_date": "2024-04-09 16:20:03 UTC",
      "updated_date": "2025-01-09 02:34:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T22:53:56.225889"
    },
    {
      "arxiv_id": "2404.06423v3",
      "title": "Deep Reinforcement Learning-Based Approach for a Single Vehicle Persistent Surveillance Problem with Fuel Constraints",
      "title_zh": "翻译失败",
      "authors": [
        "Manav Mishra",
        "Hritik Bana",
        "Saswata Sarkar",
        "Sujeevraja Sanjeevi",
        "PB Sujit",
        "Kaarthik Sundar"
      ],
      "abstract": "This article presents a deep reinforcement learning-based approach to tackle\na persistent surveillance mission requiring a single unmanned aerial vehicle\ninitially stationed at a depot with fuel or time-of-flight constraints to\nrepeatedly visit a set of targets with equal priority. Owing to the vehicle's\nfuel or time-of-flight constraints, the vehicle must be regularly refueled, or\nits battery must be recharged at the depot. The objective of the problem is to\ndetermine an optimal sequence of visits to the targets that minimizes the\nmaximum time elapsed between successive visits to any target while ensuring\nthat the vehicle never runs out of fuel or charge. We present a deep\nreinforcement learning algorithm to solve this problem and present the results\nof numerical experiments that corroborate the effectiveness of this approach in\ncomparison with common-sense greedy heuristics.",
      "tldr_zh": "这篇论文提出了一种基于 Deep Reinforcement Learning 的方法，用于解决单无人机在燃料约束下的持续监视问题，该问题要求无人机从基地出发，重复访问一组优先级相同的目标，同时定期返回基地加油或充电。目标是优化访问序列，以最小化任何目标之间连续访问的最大时间间隔，同时确保无人机不会耗尽燃料。实验结果显示，该算法在数值测试中比传统的贪婪启发式方法更有效，证明了其在实际应用中的优越性。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "6 pages",
      "pdf_url": "http://arxiv.org/pdf/2404.06423v3",
      "published_date": "2024-04-09 16:14:03 UTC",
      "updated_date": "2024-05-03 02:05:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T22:54:07.118159"
    },
    {
      "arxiv_id": "2404.06418v1",
      "title": "Studying the Impact of Latent Representations in Implicit Neural Networks for Scientific Continuous Field Reconstruction",
      "title_zh": "翻译失败",
      "authors": [
        "Wei Xu",
        "Derek Freeman DeSantis",
        "Xihaier Luo",
        "Avish Parmar",
        "Klaus Tan",
        "Balu Nadiga",
        "Yihui Ren",
        "Shinjae Yoo"
      ],
      "abstract": "Learning a continuous and reliable representation of physical fields from\nsparse sampling is challenging and it affects diverse scientific disciplines.\nIn a recent work, we present a novel model called MMGN (Multiplicative and\nModulated Gabor Network) with implicit neural networks. In this work, we design\nadditional studies leveraging explainability methods to complement the previous\nexperiments and further enhance the understanding of latent representations\ngenerated by the model. The adopted methods are general enough to be leveraged\nfor any latent space inspection. Preliminary results demonstrate the contextual\ninformation incorporated in the latent representations and their impact on the\nmodel performance. As a work in progress, we will continue to verify our\nfindings and develop novel explainability approaches.",
      "tldr_zh": "这篇论文研究了隐式神经网络（Implicit Neural Networks）中潜在表示（Latent Representations）对科学连续场重建的影响，针对从稀疏采样中学习物理场表示的挑战。作者基于之前的 MMGN（Multiplicative and Modulated Gabor Network）模型，设计了额外的解释性方法来检验潜在表示中的上下文信息及其对模型性能的影响。初步结果显示这些表示能显著提升重建准确性，作为进行中工作，论文计划进一步验证发现并开发新型解释性方法。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.06418v1",
      "published_date": "2024-04-09 16:07:35 UTC",
      "updated_date": "2024-04-09 16:07:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T22:54:19.337925"
    },
    {
      "arxiv_id": "2404.06411v1",
      "title": "AgentQuest: A Modular Benchmark Framework to Measure Progress and Improve LLM Agents",
      "title_zh": "翻译失败",
      "authors": [
        "Luca Gioacchini",
        "Giuseppe Siracusano",
        "Davide Sanvito",
        "Kiril Gashteovski",
        "David Friede",
        "Roberto Bifulco",
        "Carolin Lawrence"
      ],
      "abstract": "The advances made by Large Language Models (LLMs) have led to the pursuit of\nLLM agents that can solve intricate, multi-step reasoning tasks. As with any\nresearch pursuit, benchmarking and evaluation are key corner stones to\nefficient and reliable progress. However, existing benchmarks are often narrow\nand simply compute overall task success. To face these issues, we propose\nAgentQuest -- a framework where (i) both benchmarks and metrics are modular and\neasily extensible through well documented and easy-to-use APIs; (ii) we offer\ntwo new evaluation metrics that can reliably track LLM agent progress while\nsolving a task. We exemplify the utility of the metrics on two use cases\nwherein we identify common failure points and refine the agent architecture to\nobtain a significant performance increase. Together with the research\ncommunity, we hope to extend AgentQuest further and therefore we make it\navailable under https://github.com/nec-research/agentquest.",
      "tldr_zh": "该研究提出AgentQuest，一种模块化基准框架，用于评估和改进大型语言模型(LLMs)代理在复杂多步骤推理任务中的表现，以解决现有基准测试的狭隘性和仅计算整体成功率的局限。框架通过易用的API实现基准和指标的灵活扩展，并引入两个新评价指标，能够可靠跟踪代理任务进展，并在两个用例中识别常见失败点。实验结果显示，通过优化代理架构，性能显著提升；该框架已开源在GitHub上，邀请社区进一步扩展。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted at the 2024 Conference of the North American Chapter of the\n  Association for Computational Linguistics: Human Language Technologies\n  (NAACL-HLT 2024)",
      "pdf_url": "http://arxiv.org/pdf/2404.06411v1",
      "published_date": "2024-04-09 16:01:24 UTC",
      "updated_date": "2024-04-09 16:01:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T22:54:30.155918"
    },
    {
      "arxiv_id": "2404.06407v3",
      "title": "Rethinking How to Evaluate Language Model Jailbreak",
      "title_zh": "重新审视语言模型越狱评估方法",
      "authors": [
        "Hongyu Cai",
        "Arjun Arunasalam",
        "Leo Y. Lin",
        "Antonio Bianchi",
        "Z. Berkay Celik"
      ],
      "abstract": "Large language models (LLMs) have become increasingly integrated with various\napplications. To ensure that LLMs do not generate unsafe responses, they are\naligned with safeguards that specify what content is restricted. However, such\nalignment can be bypassed to produce prohibited content using a technique\ncommonly referred to as jailbreak. Different systems have been proposed to\nperform the jailbreak automatically. These systems rely on evaluation methods\nto determine whether a jailbreak attempt is successful. However, our analysis\nreveals that current jailbreak evaluation methods have two limitations. (1)\nTheir objectives lack clarity and do not align with the goal of identifying\nunsafe responses. (2) They oversimplify the jailbreak result as a binary\noutcome, successful or not. In this paper, we propose three metrics, safeguard\nviolation, informativeness, and relative truthfulness, to evaluate language\nmodel jailbreak. Additionally, we demonstrate how these metrics correlate with\nthe goal of different malicious actors. To compute these metrics, we introduce\na multifaceted approach that extends the natural language generation evaluation\nmethod after preprocessing the response. We evaluate our metrics on a benchmark\ndataset produced from three malicious intent datasets and three jailbreak\nsystems. The benchmark dataset is labeled by three annotators. We compare our\nmultifaceted approach with three existing jailbreak evaluation methods.\nExperiments demonstrate that our multifaceted evaluation outperforms existing\nmethods, with F1 scores improving on average by 17% compared to existing\nbaselines. Our findings motivate the need to move away from the binary view of\nthe jailbreak problem and incorporate a more comprehensive evaluation to ensure\nthe safety of the language model.",
      "tldr_zh": "本论文重新审视了评估语言模型(Large Language Models, LLMs)越狱(jailbreak)的方法，指出现有评估方法存在目标不清晰和结果过于二元化的局限。论文提出三个新指标——safeguard violation（安全防护违反）、informativeness（信息性）和relative truthfulness（相对真实性）——来更全面地评估jailbreak成功与否，并展示了这些指标如何与恶意行为者的目标相关联。研究引入了一种多方面方法，通过预处理响应并扩展自然语言生成评估来计算这些指标，并在基准数据集上进行实验，结果显示该方法比现有方法平均F1 scores提高了17%。这些发现强调了需要从二元视角转向更全面的评估，以提升LLMs的安全性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CR",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.06407v3",
      "published_date": "2024-04-09 15:54:16 UTC",
      "updated_date": "2024-05-07 14:06:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T22:54:43.809389"
    },
    {
      "arxiv_id": "2404.06405v2",
      "title": "Wu's Method can Boost Symbolic AI to Rival Silver Medalists and AlphaGeometry to Outperform Gold Medalists at IMO Geometry",
      "title_zh": "翻译失败",
      "authors": [
        "Shiven Sinha",
        "Ameya Prabhu",
        "Ponnurangam Kumaraguru",
        "Siddharth Bhat",
        "Matthias Bethge"
      ],
      "abstract": "Proving geometric theorems constitutes a hallmark of visual reasoning\ncombining both intuitive and logical skills. Therefore, automated theorem\nproving of Olympiad-level geometry problems is considered a notable milestone\nin human-level automated reasoning. The introduction of AlphaGeometry, a\nneuro-symbolic model trained with 100 million synthetic samples, marked a major\nbreakthrough. It solved 25 of 30 International Mathematical Olympiad (IMO)\nproblems whereas the reported baseline based on Wu's method solved only ten. In\nthis note, we revisit the IMO-AG-30 Challenge introduced with AlphaGeometry,\nand find that Wu's method is surprisingly strong. Wu's method alone can solve\n15 problems, and some of them are not solved by any of the other methods. This\nleads to two key findings: (i) Combining Wu's method with the classic synthetic\nmethods of deductive databases and angle, ratio, and distance chasing solves 21\nout of 30 methods by just using a CPU-only laptop with a time limit of 5\nminutes per problem. Essentially, this classic method solves just 4 problems\nless than AlphaGeometry and establishes the first fully symbolic baseline\nstrong enough to rival the performance of an IMO silver medalist. (ii) Wu's\nmethod even solves 2 of the 5 problems that AlphaGeometry failed to solve.\nThus, by combining AlphaGeometry with Wu's method we set a new state-of-the-art\nfor automated theorem proving on IMO-AG-30, solving 27 out of 30 problems, the\nfirst AI method which outperforms an IMO gold medalist.",
      "tldr_zh": "该研究重新审视了 Wu's method 在 IMO 几何问题证明中的表现，发现它能独立解决 15 个问题，其中一些甚至 AlphaGeometry 未能解决。作者将 Wu's method 与经典的合成方法（如演绎数据库和角度比距离追踪）结合，仅用 CPU 笔记本在 5 分钟内解决 21 个问题，接近 IMO 银牌获得者的水平。最终，通过整合 Wu's method 和 AlphaGeometry，实现了解决 27 个 IMO-AG-30 问题的全新状态-of-the-art 表现，首次让 AI 超越 IMO 金牌获得者。",
      "categories": [
        "cs.AI",
        "cs.CG",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "Work in Progress. Released for wider feedback",
      "pdf_url": "http://arxiv.org/pdf/2404.06405v2",
      "published_date": "2024-04-09 15:54:00 UTC",
      "updated_date": "2024-04-11 14:37:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T22:54:58.147922"
    },
    {
      "arxiv_id": "2404.06404v1",
      "title": "Apprentices to Research Assistants: Advancing Research with Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "M. Namvarpour",
        "A. Razi"
      ],
      "abstract": "Large Language Models (LLMs) have emerged as powerful tools in various\nresearch domains. This article examines their potential through a literature\nreview and firsthand experimentation. While LLMs offer benefits like\ncost-effectiveness and efficiency, challenges such as prompt tuning, biases,\nand subjectivity must be addressed. The study presents insights from\nexperiments utilizing LLMs for qualitative analysis, highlighting successes and\nlimitations. Additionally, it discusses strategies for mitigating challenges,\nsuch as prompt optimization techniques and leveraging human expertise. This\nstudy aligns with the 'LLMs as Research Tools' workshop's focus on integrating\nLLMs into HCI data work critically and ethically. By addressing both\nopportunities and challenges, our work contributes to the ongoing dialogue on\ntheir responsible application in research.",
      "tldr_zh": "这篇论文探讨了大型语言模型 (LLMs) 在研究领域的潜力，通过文献综述和实验验证其优势，如成本效益和效率。研究突出了 LLMs 在定性分析中的应用成功，同时指出了挑战，包括 prompt tuning、biases 和主观性等问题。作者提出缓解策略，如提示优化技术和结合人类专业知识，以实现负责任的应用。该工作为 LLMs 在 HCI 数据工作中的批判性整合提供了重要见解。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.LG",
        "I.2; H.5; H.3; K.4; I.7"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.06404v1",
      "published_date": "2024-04-09 15:53:06 UTC",
      "updated_date": "2024-04-09 15:53:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T22:55:09.990698"
    },
    {
      "arxiv_id": "2404.06393v4",
      "title": "MuPT: A Generative Symbolic Music Pretrained Transformer",
      "title_zh": "MuPT：生成式符号音乐预训练Transformer",
      "authors": [
        "Xingwei Qu",
        "Yuelin Bai",
        "Yinghao Ma",
        "Ziya Zhou",
        "Ka Man Lo",
        "Jiaheng Liu",
        "Ruibin Yuan",
        "Lejun Min",
        "Xueling Liu",
        "Tianyu Zhang",
        "Xinrun Du",
        "Shuyue Guo",
        "Yiming Liang",
        "Yizhi Li",
        "Shangda Wu",
        "Junting Zhou",
        "Tianyu Zheng",
        "Ziyang Ma",
        "Fengze Han",
        "Wei Xue",
        "Gus Xia",
        "Emmanouil Benetos",
        "Xiang Yue",
        "Chenghua Lin",
        "Xu Tan",
        "Stephen W. Huang",
        "Jie Fu",
        "Ge Zhang"
      ],
      "abstract": "In this paper, we explore the application of Large Language Models (LLMs) to\nthe pre-training of music. While the prevalent use of MIDI in music modeling is\nwell-established, our findings suggest that LLMs are inherently more compatible\nwith ABC Notation, which aligns more closely with their design and strengths,\nthereby enhancing the model's performance in musical composition. To address\nthe challenges associated with misaligned measures from different tracks during\ngeneration, we propose the development of a Synchronized Multi-Track ABC\nNotation (SMT-ABC Notation), which aims to preserve coherence across multiple\nmusical tracks. Our contributions include a series of models capable of\nhandling up to 8192 tokens, covering 90% of the symbolic music data in our\ntraining set. Furthermore, we explore the implications of the Symbolic Music\nScaling Law (SMS Law) on model performance. The results indicate a promising\ndirection for future research in music generation, offering extensive resources\nfor community-led research through our open-source contributions.",
      "tldr_zh": "本研究探索了使用Large Language Models (LLMs)预训练符号音乐模型，发现LLMs与ABC Notation更兼容，从而提升音乐生成性能。论文提出Synchronized Multi-Track ABC Notation (SMT-ABC Notation)来解决多轨音乐生成中的对齐问题，确保各轨间的连贯性。贡献包括开发可处理长达8192 tokens的模型，覆盖90%的训练数据，并分析Symbolic Music Scaling Law (SMS Law)的对模型性能的影响，为音乐生成领域提供开源资源和未来研究方向。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.06393v4",
      "published_date": "2024-04-09 15:35:52 UTC",
      "updated_date": "2024-11-05 15:40:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T22:55:19.888764"
    },
    {
      "arxiv_id": "2404.06392v1",
      "title": "Event Extraction in Basque: Typologically motivated Cross-Lingual Transfer-Learning Analysis",
      "title_zh": "翻译失败",
      "authors": [
        "Mikel Zubillaga",
        "Oscar Sainz",
        "Ainara Estarrona",
        "Oier Lopez de Lacalle",
        "Eneko Agirre"
      ],
      "abstract": "Cross-lingual transfer-learning is widely used in Event Extraction for\nlow-resource languages and involves a Multilingual Language Model that is\ntrained in a source language and applied to the target language. This paper\nstudies whether the typological similarity between source and target languages\nimpacts the performance of cross-lingual transfer, an under-explored topic. We\nfirst focus on Basque as the target language, which is an ideal target language\nbecause it is typologically different from surrounding languages. Our\nexperiments on three Event Extraction tasks show that the shared linguistic\ncharacteristic between source and target languages does have an impact on\ntransfer quality. Further analysis of 72 language pairs reveals that for tasks\nthat involve token classification such as entity and event trigger\nidentification, common writing script and morphological features produce higher\nquality cross-lingual transfer. In contrast, for tasks involving structural\nprediction like argument extraction, common word order is the most relevant\nfeature. In addition, we show that when increasing the training size, not all\nthe languages scale in the same way in the cross-lingual setting. To perform\nthe experiments we introduce EusIE, an event extraction dataset for Basque,\nwhich follows the Multilingual Event Extraction dataset (MEE). The dataset and\ncode are publicly available.",
      "tldr_zh": "这篇论文探讨了类型学相似性对跨语言转移学习（Cross-Lingual Transfer-Learning）在事件提取（Event Extraction）中的影响，焦点是低资源语言巴斯克语（Basque）作为目标语言。实验结果显示，对于实体和事件触发识别等标记分类任务，源语言与目标语言的共同书写脚本和形态特征能显著提升转移质量；相反，对于参数提取等结构预测任务，共同词序是关键因素。此外，研究发现增加训练数据规模时，不同语言的扩展性能存在差异，并引入了EusIE数据集（基于Multilingual Event Extraction (MEE)），以支持进一步研究，该数据集和代码已公开可用。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted at LREC-Coling 2024",
      "pdf_url": "http://arxiv.org/pdf/2404.06392v1",
      "published_date": "2024-04-09 15:35:41 UTC",
      "updated_date": "2024-04-09 15:35:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T22:55:33.934459"
    },
    {
      "arxiv_id": "2404.06370v1",
      "title": "Enhancing Decision Analysis with a Large Language Model: pyDecision a Comprehensive Library of MCDA Methods in Python",
      "title_zh": "翻译失败",
      "authors": [
        "Valdecy Pereira",
        "Marcio Pereira Basilio",
        "Carlos Henrique Tarjano SantosCarlos Henrique Tarjano Santos"
      ],
      "abstract": "Purpose: Multicriteria decision analysis (MCDA) has become increasingly\nessential for decision-making in complex environments. In response to this\nneed, the pyDecision library, implemented in Python and available at\nhttps://bit.ly/3tLFGtH, has been developed to provide a comprehensive and\naccessible collection of MCDA methods. Methods: The pyDecision offers 70 MCDA\nmethods, including AHP, TOPSIS, and the PROMETHEE and ELECTRE families. Beyond\noffering a vast range of techniques, the library provides visualization tools\nfor more intuitive results interpretation. In addition to these features,\npyDecision has integrated ChatGPT, an advanced Large Language Model, where\ndecision-makers can use ChatGPT to discuss and compare the outcomes of\ndifferent methods, providing a more interactive and intuitive understanding of\nthe solutions. Findings: Large Language Models are undeniably potent but can\nsometimes be a double-edged sword. Its answers may be misleading without\nrigorous verification of its outputs, especially for researchers lacking deep\ndomain expertise. It's imperative to approach its insights with a discerning\neye and a solid foundation in the relevant field. Originality: With the\nintegration of MCDA methods and ChatGPT, pyDecision is a significant\ncontribution to the scientific community, as it is an invaluable resource for\nresearchers, practitioners, and decision-makers navigating complex\ndecision-making problems and seeking the most appropriate solutions based on\nMCDA methods.",
      "tldr_zh": "pyDecision 是一个全面的 Python 库，旨在增强多标准决策分析 (MCDA) 的决策过程，提供包括 AHP、TOPSIS、PROMETHEE 和 ELECTRE 家族在内的 70 种 MCDA 方法，并附带可视化工具以便直观解读结果。库中整合了 Large Language Model 如 ChatGPT，允许决策者交互式讨论和比较不同方法的输出，提升决策的互动性和理解度。研究发现，Large Language Models 虽强大但可能产生误导信息，因此需进行严格验证。该库的原创性在于结合 MCDA 方法和 AI 技术，为研究者、从业者和决策者处理复杂决策问题提供了宝贵资源。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "23 pages, 2 figures",
      "pdf_url": "http://arxiv.org/pdf/2404.06370v1",
      "published_date": "2024-04-09 15:06:25 UTC",
      "updated_date": "2024-04-09 15:06:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T22:55:45.256933"
    },
    {
      "arxiv_id": "2404.06369v2",
      "title": "WebCode2M: A Real-World Dataset for Code Generation from Webpage Designs",
      "title_zh": "翻译失败",
      "authors": [
        "Yi Gui",
        "Zhen Li",
        "Yao Wan",
        "Yemin Shi",
        "Hongyu Zhang",
        "Yi Su",
        "Bohua Chen",
        "Dongping Chen",
        "Siyuan Wu",
        "Xing Zhou",
        "Wenbin Jiang",
        "Hai Jin",
        "Xiangliang Zhang"
      ],
      "abstract": "Automatically generating webpage code from webpage designs can significantly\nreduce the workload of front-end developers, and recent Multimodal Large\nLanguage Models (MLLMs) have shown promising potential in this area. However,\nour investigation reveals that most existing MLLMs are constrained by the\nabsence of high-quality, large-scale, real-world datasets, resulting in\ninadequate performance in automated webpage code generation. To fill this gap,\nthis paper introduces WebCode2M, a new dataset comprising 2.56 million\ninstances, each containing a design image along with the corresponding webpage\ncode and layout details. Sourced from real-world web resources, WebCode2M\noffers a rich and valuable dataset for webpage code generation across a variety\nof applications. The dataset quality is ensured by a scoring model that filters\nout instances with aesthetic deficiencies or other incomplete elements. To\nvalidate the effectiveness of WebCode2M, we introduce a baseline model based on\nthe Vision Transformer (ViT), named WebCoder, and establish a benchmark for\nfair comparison. Additionally, we introduce a new metric, TreeBLEU, to measure\nthe structural hierarchy recall. The benchmarking results demonstrate that our\ndataset significantly improves the ability of MLLMs to generate code from\nwebpage designs, confirming its effectiveness and usability for future\napplications in front-end design tools. Finally, we highlight several practical\nchallenges introduced by our dataset, calling for further research. The code\nand dataset are publicly available at our project homepage:\nhttps://webcode2m.github.io.",
      "tldr_zh": "该论文介绍了WebCode2M数据集，该数据集包含2.56百万真实世界实例，用于从网页设计图像生成对应代码和布局细节，旨在解决Multimodal Large Language Models (MLLMs)缺乏高质量数据导致的性能不足问题。通过评分模型过滤，确保数据集的质量和多样性。研究者构建了基于Vision Transformer (ViT)的基线模型WebCoder，并引入新指标TreeBLEU来评估结构层次召回，基准测试结果显示WebCode2M显著提升了MLLMs的代码生成能力，并公开数据集以推动前端设计工具的未来应用。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.SE"
      ],
      "primary_category": "cs.CV",
      "comment": "WWW'25",
      "pdf_url": "http://arxiv.org/pdf/2404.06369v2",
      "published_date": "2024-04-09 15:05:48 UTC",
      "updated_date": "2025-02-22 05:15:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T22:55:56.184877"
    },
    {
      "arxiv_id": "2404.06362v2",
      "title": "Test-Time Adaptation with SaLIP: A Cascade of SAM and CLIP for Zero shot Medical Image Segmentation",
      "title_zh": "翻译失败",
      "authors": [
        "Sidra Aleem",
        "Fangyijie Wang",
        "Mayug Maniparambil",
        "Eric Arazo",
        "Julia Dietlmeier",
        "Guenole Silvestre",
        "Kathleen Curran",
        "Noel E. O'Connor",
        "Suzanne Little"
      ],
      "abstract": "The Segment Anything Model (SAM) and CLIP are remarkable vision foundation\nmodels (VFMs). SAM, a prompt driven segmentation model, excels in segmentation\ntasks across diverse domains, while CLIP is renowned for its zero shot\nrecognition capabilities. However, their unified potential has not yet been\nexplored in medical image segmentation. To adapt SAM to medical imaging,\nexisting methods primarily rely on tuning strategies that require extensive\ndata or prior prompts tailored to the specific task, making it particularly\nchallenging when only a limited number of data samples are available. This work\npresents an in depth exploration of integrating SAM and CLIP into a unified\nframework for medical image segmentation. Specifically, we propose a simple\nunified framework, SaLIP, for organ segmentation. Initially, SAM is used for\npart based segmentation within the image, followed by CLIP to retrieve the mask\ncorresponding to the region of interest (ROI) from the pool of SAM generated\nmasks. Finally, SAM is prompted by the retrieved ROI to segment a specific\norgan. Thus, SaLIP is training and fine tuning free and does not rely on domain\nexpertise or labeled data for prompt engineering. Our method shows substantial\nenhancements in zero shot segmentation, showcasing notable improvements in DICE\nscores across diverse segmentation tasks like brain (63.46%), lung (50.11%),\nand fetal head (30.82%), when compared to un prompted SAM. Code and text\nprompts are available at: https://github.com/aleemsidra/SaLIP.",
      "tldr_zh": "本研究提出 SaLIP 框架，将 Segment Anything Model (SAM) 和 CLIP 整合成一个级联系统，用于零 shot 医疗图像分割，旨在解决传统方法对大量数据或特定提示的依赖。SaLIP 的工作流程包括先使用 SAM 进行基于部分的图像分割，然后利用 CLIP 从生成的掩码中检索感兴趣区域 (ROI)，最后以 ROI 提示 SAM 来精确分割特定器官。该框架无需训练、微调或标注数据，仅依赖现有模型，实现高效的自适应。实验结果显示，SaLIP 在脑部 (DICE 分数 63.46%)、肺部 (50.11%) 和胎儿头部 (30.82%) 等任务上，比未提示的 SAM 显著提升了分割性能，为零 shot 医疗图像分析提供了可靠工具。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.06362v2",
      "published_date": "2024-04-09 14:56:34 UTC",
      "updated_date": "2024-04-30 15:58:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T22:56:08.907710"
    },
    {
      "arxiv_id": "2404.06356v1",
      "title": "Policy-Guided Diffusion",
      "title_zh": "翻译失败",
      "authors": [
        "Matthew Thomas Jackson",
        "Michael Tryfan Matthews",
        "Cong Lu",
        "Benjamin Ellis",
        "Shimon Whiteson",
        "Jakob Foerster"
      ],
      "abstract": "In many real-world settings, agents must learn from an offline dataset\ngathered by some prior behavior policy. Such a setting naturally leads to\ndistribution shift between the behavior policy and the target policy being\ntrained - requiring policy conservatism to avoid instability and overestimation\nbias. Autoregressive world models offer a different solution to this by\ngenerating synthetic, on-policy experience. However, in practice, model\nrollouts must be severely truncated to avoid compounding error. As an\nalternative, we propose policy-guided diffusion. Our method uses diffusion\nmodels to generate entire trajectories under the behavior distribution,\napplying guidance from the target policy to move synthetic experience further\non-policy. We show that policy-guided diffusion models a regularized form of\nthe target distribution that balances action likelihood under both the target\nand behavior policies, leading to plausible trajectories with high target\npolicy probability, while retaining a lower dynamics error than an offline\nworld model baseline. Using synthetic experience from policy-guided diffusion\nas a drop-in substitute for real data, we demonstrate significant improvements\nin performance across a range of standard offline reinforcement learning\nalgorithms and environments. Our approach provides an effective alternative to\nautoregressive offline world models, opening the door to the controllable\ngeneration of synthetic training data.",
      "tldr_zh": "本研究提出了一种名为 Policy-Guided Diffusion 的方法，用于解决离线强化学习中行为策略与目标策略之间的分布偏移问题。该方法利用扩散模型生成行为分布下的完整轨迹，并通过目标策略的指导，使合成经验更接近 on-policy，同时平衡目标策略和行为策略下的动作可能性，从而降低动态错误。实验结果显示，使用 Policy-Guided Diffusion 作为真实数据的替代，在多种标准离线强化学习算法和环境中显著提升了性能，为可控生成合成训练数据提供了有效替代方案。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.LG",
      "comment": "Previously at the NeurIPS 2023 Workshop on Robot Learning",
      "pdf_url": "http://arxiv.org/pdf/2404.06356v1",
      "published_date": "2024-04-09 14:46:48 UTC",
      "updated_date": "2024-04-09 14:46:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T22:56:20.880249"
    },
    {
      "arxiv_id": "2404.06353v1",
      "title": "High Noise Scheduling is a Must",
      "title_zh": "翻译失败",
      "authors": [
        "Mahmut S. Gokmen",
        "Cody Bumgardner",
        "Jie Zhang",
        "Ge Wang",
        "Jin Chen"
      ],
      "abstract": "Consistency models possess high capabilities for image generation, advancing\nsampling steps to a single step through their advanced techniques. Current\nadvancements move one step forward consistency training techniques and\neliminates the limitation of distillation training. Even though the proposed\ncurriculum and noise scheduling in improved training techniques yield better\nresults than basic consistency models, it lacks well balanced noise\ndistribution and its consistency between curriculum. In this study, it is\ninvestigated the balance between high and low noise levels in noise\ndistribution and offered polynomial noise distribution to maintain the\nstability. This proposed polynomial noise distribution is also supported with a\npredefined Karras noises to prevent unique noise levels arises with Karras\nnoise generation algorithm. Furthermore, by elimination of learned noisy steps\nwith a curriculum based on sinusoidal function increase the performance of the\nmodel in denoising. To make a fair comparison with the latest released\nconsistency model training techniques, experiments are conducted with same\nhyper-parameters except curriculum and noise distribution. The models utilized\nduring experiments are determined with low depth to prove the robustness of our\nproposed technique. The results show that the polynomial noise distribution\noutperforms the model trained with log-normal noise distribution, yielding a\n33.54 FID score after 100,000 training steps with constant discretization\nsteps. Additionally, the implementation of a sinusoidal-based curriculum\nenhances denoising performance, resulting in a FID score of 30.48.",
      "tldr_zh": "本研究强调在Consistency Models图像生成中，高噪声调度的必要性，以解决现有方法中噪声分布不平衡和课程一致性问题。研究者提出多项式噪声分布，并结合预定义的Karras噪声，以维持稳定性，同时使用基于正弦函数的课程来消除学习噪声步骤，从而提升去噪性能。在实验中，使用相同超参数但调整课程和噪声分布的低深度模型进行比较，结果显示多项式噪声分布的FID分数为33.54，比log-normal噪声分布更优；进一步应用正弦课程后，FID分数改善至30.48，证明了该方法的鲁棒性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.06353v1",
      "published_date": "2024-04-09 14:44:12 UTC",
      "updated_date": "2024-04-09 14:44:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T22:56:32.465041"
    },
    {
      "arxiv_id": "2404.06345v2",
      "title": "AgentsCoDriver: Large Language Model Empowered Collaborative Driving with Lifelong Learning",
      "title_zh": "Agents",
      "authors": [
        "Senkang Hu",
        "Zhengru Fang",
        "Zihan Fang",
        "Yiqin Deng",
        "Xianhao Chen",
        "Yuguang Fang"
      ],
      "abstract": "Connected and autonomous driving is developing rapidly in recent years.\nHowever, current autonomous driving systems, which are primarily based on\ndata-driven approaches, exhibit deficiencies in interpretability,\ngeneralization, and continuing learning capabilities. In addition, the\nsingle-vehicle autonomous driving systems lack of the ability of collaboration\nand negotiation with other vehicles, which is crucial for the safety and\nefficiency of autonomous driving systems. In order to address these issues, we\nleverage large language models (LLMs) to develop a novel framework,\nAgentsCoDriver, to enable multiple vehicles to conduct collaborative driving.\nAgentsCoDriver consists of five modules: observation module, reasoning engine,\ncognitive memory module, reinforcement reflection module, and communication\nmodule. It can accumulate knowledge, lessons, and experiences over time by\ncontinuously interacting with the environment, thereby making itself capable of\nlifelong learning. In addition, by leveraging the communication module,\ndifferent agents can exchange information and realize negotiation and\ncollaboration in complex traffic environments. Extensive experiments are\nconducted and show the superiority of AgentsCoDriver.",
      "tldr_zh": "这篇论文针对当前自动驾驶系统的可解释性、泛化性和持续学习能力不足问题，提出AgentsCoDriver框架，利用Large Language Models (LLMs)实现多车辆协作驾驶。框架包括observation module、reasoning engine、cognitive memory module、reinforcement reflection module和communication module，这些模块通过环境交互积累知识，支持终身学习(lifelong learning)和代理间的信息交换与协商。实验结果显示，AgentsCoDriver在复杂交通环境中表现出优越性，提升了驾驶的安全性和效率。",
      "categories": [
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.06345v2",
      "published_date": "2024-04-09 14:33:16 UTC",
      "updated_date": "2024-04-21 09:12:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T22:56:44.439046"
    },
    {
      "arxiv_id": "2404.06330v1",
      "title": "Generative Pre-Trained Transformer for Symbolic Regression Base In-Context Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Yanjie Li",
        "Weijun Li",
        "Lina Yu",
        "Min Wu",
        "Jingyi Liu",
        "Wenqiang Li",
        "Meilan Hao",
        "Shu Wei",
        "Yusong Deng"
      ],
      "abstract": "The mathematical formula is the human language to describe nature and is the\nessence of scientific research. Finding mathematical formulas from\nobservational data is a major demand of scientific research and a major\nchallenge of artificial intelligence. This area is called symbolic regression.\nOriginally symbolic regression was often formulated as a combinatorial\noptimization problem and solved using GP or reinforcement learning algorithms.\nThese two kinds of algorithms have strong noise robustness ability and good\nVersatility. However, inference time usually takes a long time, so the search\nefficiency is relatively low. Later, based on large-scale pre-training data\nproposed, such methods use a large number of synthetic data points and\nexpression pairs to train a Generative Pre-Trained Transformer(GPT). Then this\nGPT can only need to perform one forward propagation to obtain the results, the\nadvantage is that the inference speed is very fast. However, its performance is\nvery dependent on the training data and performs poorly on data outside the\ntraining set, which leads to poor noise robustness and Versatility of such\nmethods. So, can we combine the advantages of the above two categories of SR\nalgorithms? In this paper, we propose \\textbf{FormulaGPT}, which trains a GPT\nusing massive sparse reward learning histories of reinforcement learning-based\nSR algorithms as training data. After training, the SR algorithm based on\nreinforcement learning is distilled into a Transformer. When new test data\ncomes, FormulaGPT can directly generate a \"reinforcement learning process\" and\nautomatically update the learning policy in context. Tested on more than ten\ndatasets including SRBench, formulaGPT achieves the state-of-the-art\nperformance in fitting ability compared with four baselines. In addition, it\nachieves satisfactory results in noise robustness, versatility, and inference\nefficiency.",
      "tldr_zh": "本文提出FormulaGPT，一种基于Generative Pre-Trained Transformer的符号回归方法，通过利用强化学习-based SR算法的学习历史作为训练数据，将强化学习过程蒸馏进Transformer模型。FormulaGPT能在新数据上直接生成“强化学习过程”，并在上下文中自动更新学习策略，从而结合了传统算法的噪声鲁棒性和通用性与GPT的快速推理优势。在多个数据集（如SRBench）上，FormulaGPT在拟合能力、噪声鲁棒性、通用性和推理效率方面实现了state-of-the-art性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "21 pages",
      "pdf_url": "http://arxiv.org/pdf/2404.06330v1",
      "published_date": "2024-04-09 14:08:47 UTC",
      "updated_date": "2024-04-09 14:08:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T22:56:57.918517"
    },
    {
      "arxiv_id": "2404.06326v1",
      "title": "What is the $\\textit{intrinsic}$ dimension of your binary data? -- and how to compute it quickly",
      "title_zh": "翻译失败",
      "authors": [
        "Tom Hanika",
        "Tobias Hille"
      ],
      "abstract": "Dimensionality is an important aspect for analyzing and understanding\n(high-dimensional) data. In their 2006 ICDM paper Tatti et al. answered the\nquestion for a (interpretable) dimension of binary data tables by introducing a\nnormalized correlation dimension. In the present work we revisit their results\nand contrast them with a concept based notion of intrinsic dimension (ID)\nrecently introduced for geometric data sets. To do this, we present a novel\napproximation for this ID that is based on computing concepts only up to a\ncertain support value. We demonstrate and evaluate our approximation using all\navailable datasets from Tatti et al., which have between 469 and 41271\nextrinsic dimensions.",
      "tldr_zh": "这篇论文探讨了二进制数据的内在维度（intrinsic dimension），通过对比 Tatti et al. 在 2006 年 ICDM 论文中提出的 normalized correlation dimension 与最近的概念-based notion of intrinsic dimension，为高维数据分析提供新视角。研究贡献包括引入一种新型近似方法，该方法仅计算支持值（support value）达到特定水平的 concepts，从而实现快速计算。实验使用 Tatti et al. 的数据集进行评估，这些数据集的外在维度（extrinsic dimensions）从 469 到 41271 不等，证明了该方法的有效性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "68T05 06-08 68T01 68T09"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.06326v1",
      "published_date": "2024-04-09 14:04:26 UTC",
      "updated_date": "2024-04-09 14:04:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T22:57:09.429691"
    },
    {
      "arxiv_id": "2404.06325v1",
      "title": "Automatically Learning HTN Methods from Landmarks",
      "title_zh": "翻译失败",
      "authors": [
        "Ruoxi Li",
        "Dana Nau",
        "Mark Roberts",
        "Morgan Fine-Morris"
      ],
      "abstract": "Hierarchical Task Network (HTN) planning usually requires a domain engineer\nto provide manual input about how to decompose a planning problem. Even\nHTN-MAKER, a well-known method-learning algorithm, requires a domain engineer\nto annotate the tasks with information about what to learn. We introduce\nCURRICULAMA, an HTN method learning algorithm that completely automates the\nlearning process. It uses landmark analysis to compose annotated tasks and\nleverages curriculum learning to order the learning of methods from simpler to\nmore complex. This eliminates the need for manual input, resolving a core issue\nwith HTN-MAKER. We prove CURRICULAMA's soundness, and show experimentally that\nit has a substantially similar convergence rate in learning a complete set of\nmethods to HTN-MAKER.",
      "tldr_zh": "这篇论文引入了 CURRICULAMA，一种完全自动化的算法，用于从 landmarks 学习 HTN (Hierarchical Task Network) 方法，从而消除传统方法如 HTN-MAKER 对领域工程师手动标注任务的需求。CURRICULAMA 通过 landmark analysis 组合任务，并利用 curriculum learning 将方法学习从简单到复杂顺序进行。作者证明了该算法的 soundness，并实验验证其学习完整 HTN 方法集的收敛率与 HTN-MAKER 基本相当。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "This work has been submitted to FLAIRS-24",
      "pdf_url": "http://arxiv.org/pdf/2404.06325v1",
      "published_date": "2024-04-09 14:03:38 UTC",
      "updated_date": "2024-04-09 14:03:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T22:57:20.922737"
    },
    {
      "arxiv_id": "2404.06324v1",
      "title": "Dynamic D2D-Assisted Federated Learning over O-RAN: Performance Analysis, MAC Scheduler, and Asymmetric User Selection",
      "title_zh": "基于O-RAN的动态D2D辅助联邦学习：性能分析、MAC调度器和不对称用户选择",
      "authors": [
        "Payam Abdisarabshali",
        "Kwang Taik Kim",
        "Michael Langberg",
        "Weifeng Su",
        "Seyyedali Hosseinalipour"
      ],
      "abstract": "Existing studies on federated learning (FL) are mostly focused on system\norchestration for static snapshots of the network and making static control\ndecisions (e.g., spectrum allocation). However, real-world wireless networks\nare susceptible to temporal variations of wireless channel capacity and users'\ndatasets. In this paper, we incorporate multi-granular system dynamics (MSDs)\ninto FL, including (M1) dynamic wireless channel capacity, captured by a set of\ndiscrete-time events, called $\\mathscr{D}$-Events, and (M2) dynamic datasets of\nusers. The latter is characterized by (M2-a) modeling the dynamics of user's\ndataset size via an ordinary differential equation and (M2-b) introducing\ndynamic model drift}, formulated via a partial differential inequality} drawing\nconcrete analytical connections between the dynamics of users' datasets and FL\naccuracy. We then conduct FL orchestration under MSDs by introducing dynamic\ncooperative FL with dedicated MAC schedulers (DCLM), exploiting the unique\nfeatures of open radio access network (O-RAN). DCLM proposes (i) a hierarchical\ndevice-to-device (D2D)-assisted model training, (ii) dynamic control decisions\nthrough dedicated O-RAN MAC schedulers, and (iii) asymmetric user selection. We\nprovide extensive theoretical analysis to study the convergence of DCLM. We\nthen optimize the degrees of freedom (e.g., user selection and spectrum\nallocation) in DCLM through a highly non-convex optimization problem. We\ndevelop a systematic approach to obtain the solution for this problem, opening\nthe door to solving a broad variety of network-aware FL optimization problems.\nWe show the efficiency of DCLM via numerical simulations and provide a series\nof future directions.",
      "tldr_zh": "本文研究了联邦学习 (FL) 在动态无线网络中的应用，引入多粒度系统动态 (MSDs) 来处理无线通道容量 ($\\mathscr{D}$-Events) 和用户数据集动态（包括数据集大小的常微分方程建模及模型漂移的偏微分不等式分析）。提出动态合作 FL (DCLM) 框架，利用 O-RAN 的特性，实现层次化 D2D 辅助模型训练、动态 MAC 调度和非对称用户选择，并通过理论分析证明其收敛性。最终，通过非凸优化问题优化用户选择和频谱分配，模拟结果验证了 DCLM 的效率，并为网络感知 FL 优化打开了新方向。",
      "categories": [
        "cs.NI",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.NI",
      "comment": "120 pages, 13 figures",
      "pdf_url": "http://arxiv.org/pdf/2404.06324v1",
      "published_date": "2024-04-09 14:03:04 UTC",
      "updated_date": "2024-04-09 14:03:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T22:57:36.292021"
    },
    {
      "arxiv_id": "2404.06279v3",
      "title": "NoiseNCA: Noisy Seed Improves Spatio-Temporal Continuity of Neural Cellular Automata",
      "title_zh": "翻译失败",
      "authors": [
        "Ehsan Pajouheshgar",
        "Yitao Xu",
        "Sabine Süsstrunk"
      ],
      "abstract": "Neural Cellular Automata (NCA) is a class of Cellular Automata where the\nupdate rule is parameterized by a neural network that can be trained using\ngradient descent. In this paper, we focus on NCA models used for texture\nsynthesis, where the update rule is inspired by partial differential equations\n(PDEs) describing reaction-diffusion systems. To train the NCA model, the\nspatio-temporal domain is discretized, and Euler integration is used to\nnumerically simulate the PDE. However, whether a trained NCA truly learns the\ncontinuous dynamic described by the corresponding PDE or merely overfits the\ndiscretization used in training remains an open question. We study NCA models\nat the limit where space-time discretization approaches continuity. We find\nthat existing NCA models tend to overfit the training discretization,\nespecially in the proximity of the initial condition, also called \"seed\". To\naddress this, we propose a solution that utilizes uniform noise as the initial\ncondition. We demonstrate the effectiveness of our approach in preserving the\nconsistency of NCA dynamics across a wide range of spatio-temporal\ngranularities. Our improved NCA model enables two new test-time interactions by\nallowing continuous control over the speed of pattern formation and the scale\nof the synthesized patterns. We demonstrate this new NCA feature in our\ninteractive online demo. Our work reveals that NCA models can learn continuous\ndynamics and opens new venues for NCA research from a dynamical system's\nperspective.",
      "tldr_zh": "本文研究 Neural Cellular Automata (NCA) 在纹理合成中的问题，即现有模型往往过度拟合训练中的空间-时间离散化，导致动态不连续。作者提出 NoiseNCA 方法，使用均匀噪声作为初始条件（Noisy Seed），以提升 NCA 在不同粒度下的时空连续性。实验证明，该方法显著改善了 NCA 动态的一致性，并启用新交互功能，如连续控制图案形成的速度和规模。最终，这为从动态系统视角探索 NCA 提供了新研究方向。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.GR",
        "cs.MA"
      ],
      "primary_category": "cs.CV",
      "comment": "9 pages, 12 figures",
      "pdf_url": "http://arxiv.org/pdf/2404.06279v3",
      "published_date": "2024-04-09 13:02:33 UTC",
      "updated_date": "2024-06-14 11:48:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T22:57:46.278651"
    },
    {
      "arxiv_id": "2404.06278v1",
      "title": "Dimensionality Reduction in Sentence Transformer Vector Databases with Fast Fourier Transform",
      "title_zh": "翻译失败",
      "authors": [
        "Vitaly Bulgakov",
        "Alec Segal"
      ],
      "abstract": "Dimensionality reduction in vector databases is pivotal for streamlining AI\ndata management, enabling efficient storage, faster computation, and improved\nmodel performance. This paper explores the benefits of reducing vector database\ndimensions, with a focus on computational efficiency and overcoming the curse\nof dimensionality. We introduce a novel application of Fast Fourier Transform\n(FFT) to dimensionality reduction, a method previously underexploited in this\ncontext. By demonstrating its utility across various AI domains, including\nRetrieval-Augmented Generation (RAG) models and image processing, this\nFFT-based approach promises to improve data retrieval processes and enhance the\nefficiency and scalability of AI solutions. The incorporation of FFT may not\nonly optimize operations in real-time processing and recommendation systems but\nalso extend to advanced image processing techniques, where dimensionality\nreduction can significantly improve performance and analysis efficiency. This\npaper advocates for the broader adoption of FFT in vector database management,\nmarking a significant stride towards addressing the challenges of data volume\nand complexity in AI research and applications. Unlike many existing\napproaches, we directly handle the embedding vectors produced by the model\nafter processing a test input.",
      "tldr_zh": "这篇论文探讨了在句嵌入向量数据库中应用 Fast Fourier Transform (FFT) 进行维度降低，以提高计算效率、优化存储并克服维度灾难。作者引入了 FFT 的新应用，直接处理模型产生的嵌入向量，并证明其在 Retrieval-Augmented Generation (RAG) 模型和图像处理等 AI 领域中的实用性。实验结果显示，该方法显著提升了数据检索性能和 AI 系统的可扩展性，推动了实时处理、推荐系统等领域的发展。",
      "categories": [
        "cs.DB",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.DB",
      "comment": "13 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2404.06278v1",
      "published_date": "2024-04-09 13:02:22 UTC",
      "updated_date": "2024-04-09 13:02:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T22:57:57.720735"
    },
    {
      "arxiv_id": "2404.06267v1",
      "title": "PGTNet: A Process Graph Transformer Network for Remaining Time Prediction of Business Process Instances",
      "title_zh": "翻译失败",
      "authors": [
        "Keyvan Amiri Elyasi",
        "Han van der Aa",
        "Heiner Stuckenschmidt"
      ],
      "abstract": "We present PGTNet, an approach that transforms event logs into graph datasets\nand leverages graph-oriented data for training Process Graph Transformer\nNetworks to predict the remaining time of business process instances. PGTNet\nconsistently outperforms state-of-the-art deep learning approaches across a\ndiverse range of 20 publicly available real-world event logs. Notably, our\napproach is most promising for highly complex processes, where existing deep\nlearning approaches encounter difficulties stemming from their limited ability\nto learn control-flow relationships among process activities and capture\nlong-range dependencies. PGTNet addresses these challenges, while also being\nable to consider multiple process perspectives during the learning process.",
      "tldr_zh": "本文提出PGTNet，一种将事件日志转换为图数据集的方法，用于训练Process Graph Transformer Networks，以预测业务流程实例的剩余时间。PGTNet在20个公开的真实事件日志上表现优于现有深度学习方法，尤其在高度复杂的流程中，能够更好地学习控制流关系和捕捉长距离依赖。相比传统方法，PGTNet还兼顾多个过程视角，提升了预测的准确性和适用性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "16 pages, 4 figures, To be published in: Advanced Information Systems\n  Engineering - 36th International Conference, CAiSE 2024, Limassol, Cyprus,\n  June 03-07, 2024, Proceedings",
      "pdf_url": "http://arxiv.org/pdf/2404.06267v1",
      "published_date": "2024-04-09 12:45:17 UTC",
      "updated_date": "2024-04-09 12:45:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T22:58:08.604561"
    },
    {
      "arxiv_id": "2404.06261v1",
      "title": "Playing to Vision Foundation Model's Strengths in Stereo Matching",
      "title_zh": "在立体匹配中",
      "authors": [
        "Chuang-Wei Liu",
        "Qijun Chen",
        "Rui Fan"
      ],
      "abstract": "Stereo matching has become a key technique for 3D environment perception in\nintelligent vehicles. For a considerable time, convolutional neural networks\n(CNNs) have remained the mainstream choice for feature extraction in this\ndomain. Nonetheless, there is a growing consensus that the existing paradigm\nshould evolve towards vision foundation models (VFM), particularly those\ndeveloped based on vision Transformers (ViTs) and pre-trained through\nself-supervision on extensive, unlabeled datasets. While VFMs are adept at\nextracting informative, general-purpose visual features, specifically for dense\nprediction tasks, their performance often lacks in geometric vision tasks. This\nstudy serves as the first exploration of a viable approach for adapting VFMs to\nstereo matching. Our ViT adapter, referred to as ViTAS, is constructed upon\nthree types of modules: spatial differentiation, patch attention fusion, and\ncross-attention. The first module initializes feature pyramids, while the\nlatter two aggregate stereo and multi-scale contextual information into\nfine-grained features, respectively. ViTAStereo, which combines ViTAS with cost\nvolume-based stereo matching back-end processes, achieves the top rank on the\nKITTI Stereo 2012 dataset and outperforms the second-best network StereoBase by\napproximately 7.9% in terms of the percentage of error pixels, with a tolerance\nof 3 pixels. Additional experiments across diverse scenarios further\ndemonstrate its superior generalizability compared to all other\nstate-of-the-art approaches. We believe this new paradigm will pave the way for\nthe next generation of stereo matching networks.",
      "tldr_zh": "这篇论文探讨了如何发挥视觉基础模型(VFMs)的优势应用于立体匹配任务，以提升智能车辆的3D环境感知。作者首次提出ViTAS适配器，该框架基于Vision Transformers (ViTs)，包括空间微分模块（初始化特征金字塔）、补丁注意融合模块（聚合立体信息）和交叉注意模块（整合多尺度上下文信息），以解决VFMs在几何视觉任务中的性能不足。ViTAStereo系统结合ViTAS和基于成本体积的匹配后端，在KITTI Stereo 2012数据集上排名第一，比第二名StereoBase降低了约7.9%的错误像素率（容差3像素），并在多种场景中显示出卓越的泛化性。该研究为下一代立体匹配网络开辟了新范式。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.06261v1",
      "published_date": "2024-04-09 12:34:28 UTC",
      "updated_date": "2024-04-09 12:34:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T22:58:23.018935"
    },
    {
      "arxiv_id": "2404.06246v1",
      "title": "GHNeRF: Learning Generalizable Human Features with Efficient Neural Radiance Fields",
      "title_zh": "翻译失败",
      "authors": [
        "Arnab Dey",
        "Di Yang",
        "Rohith Agaram",
        "Antitza Dantcheva",
        "Andrew I. Comport",
        "Srinath Sridhar",
        "Jean Martinet"
      ],
      "abstract": "Recent advances in Neural Radiance Fields (NeRF) have demonstrated promising\nresults in 3D scene representations, including 3D human representations.\nHowever, these representations often lack crucial information on the underlying\nhuman pose and structure, which is crucial for AR/VR applications and games. In\nthis paper, we introduce a novel approach, termed GHNeRF, designed to address\nthese limitations by learning 2D/3D joint locations of human subjects with NeRF\nrepresentation. GHNeRF uses a pre-trained 2D encoder streamlined to extract\nessential human features from 2D images, which are then incorporated into the\nNeRF framework in order to encode human biomechanic features. This allows our\nnetwork to simultaneously learn biomechanic features, such as joint locations,\nalong with human geometry and texture. To assess the effectiveness of our\nmethod, we conduct a comprehensive comparison with state-of-the-art human NeRF\ntechniques and joint estimation algorithms. Our results show that GHNeRF can\nachieve state-of-the-art results in near real-time.",
      "tldr_zh": "本文提出 GHNeRF，一种高效的 Neural Radiance Fields (NeRF) 方法，用于学习可泛化的 3D 人类特征，以解决现有模型在人类姿势和结构表示上的不足。GHNeRF 利用预训练的 2D 编码器从图像提取关键人类生物力学特征（如关节位置），并将其整合到 NeRF 框架中，实现同时学习生物力学特征、几何和纹理。通过与最先进的人类 NeRF 技术和关节估计算法的比较，GHNeRF 取得了最先进的结果，并在近实时性能下表现出色。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.06246v1",
      "published_date": "2024-04-09 12:11:25 UTC",
      "updated_date": "2024-04-09 12:11:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T22:58:33.641905"
    },
    {
      "arxiv_id": "2404.06243v1",
      "title": "ActNetFormer: Transformer-ResNet Hybrid Method for Semi-Supervised Action Recognition in Videos",
      "title_zh": "ActNetFormer：Transformer-ResNet 混合方法用于视频半监督动作识别",
      "authors": [
        "Sharana Dharshikgan Suresh Dass",
        "Hrishav Bakul Barua",
        "Ganesh Krishnasamy",
        "Raveendran Paramesran",
        "Raphael C. -W. Phan"
      ],
      "abstract": "Human action or activity recognition in videos is a fundamental task in\ncomputer vision with applications in surveillance and monitoring, self-driving\ncars, sports analytics, human-robot interaction and many more. Traditional\nsupervised methods require large annotated datasets for training, which are\nexpensive and time-consuming to acquire. This work proposes a novel approach\nusing Cross-Architecture Pseudo-Labeling with contrastive learning for\nsemi-supervised action recognition. Our framework leverages both labeled and\nunlabelled data to robustly learn action representations in videos, combining\npseudo-labeling with contrastive learning for effective learning from both\ntypes of samples. We introduce a novel cross-architecture approach where 3D\nConvolutional Neural Networks (3D CNNs) and video transformers (VIT) are\nutilised to capture different aspects of action representations; hence we call\nit ActNetFormer. The 3D CNNs excel at capturing spatial features and local\ndependencies in the temporal domain, while VIT excels at capturing long-range\ndependencies across frames. By integrating these complementary architectures\nwithin the ActNetFormer framework, our approach can effectively capture both\nlocal and global contextual information of an action. This comprehensive\nrepresentation learning enables the model to achieve better performance in\nsemi-supervised action recognition tasks by leveraging the strengths of each of\nthese architectures. Experimental results on standard action recognition\ndatasets demonstrate that our approach performs better than the existing\nmethods, achieving state-of-the-art performance with only a fraction of labeled\ndata. The official website of this work is available at:\nhttps://github.com/rana2149/ActNetFormer.",
      "tldr_zh": "本研究针对视频动作识别任务提出了一种新型半监督方法ActNetFormer，该框架结合Transformer和ResNet的混合架构，利用Cross-Architecture Pseudo-Labeling与contrastive learning从标注和未标注数据中高效学习动作表示。ActNetFormer整合3D CNNs（擅长捕捉空间特征和局部时序依赖）和Video Transformers (VIT)（擅长捕捉帧间长程依赖），从而全面获取动作的局部和全局上下文信息。实验结果显示，该方法在标准动作识别数据集上超越现有基准，仅需少量标注数据即达到最先进性能，为实际应用如监控和自动驾驶提供更高效的解决方案。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.HC",
        "cs.LG",
        "cs.MM",
        "Artificial intelligence, Computer vision, Machine learning, Deep\n  learning, Human-computer Interaction",
        "I.2; I.2.9; I.2.10; I.3.3; I.4.5"
      ],
      "primary_category": "cs.CV",
      "comment": "Submitted for peer review",
      "pdf_url": "http://arxiv.org/pdf/2404.06243v1",
      "published_date": "2024-04-09 12:09:56 UTC",
      "updated_date": "2024-04-09 12:09:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T22:58:45.238780"
    },
    {
      "arxiv_id": "2404.16048v2",
      "title": "GUIDE: Graphical User Interface Data for Execution",
      "title_zh": "翻译失败",
      "authors": [
        "Rajat Chawla",
        "Adarsh Jha",
        "Muskaan Kumar",
        "Mukunda NS",
        "Ishaan Bhola"
      ],
      "abstract": "In this paper, we introduce GUIDE, a novel dataset tailored for the\nadvancement of Multimodal Large Language Model (MLLM) applications,\nparticularly focusing on Robotic Process Automation (RPA) use cases. Our\ndataset encompasses diverse data from various websites including\nApollo(62.67\\%), Gmail(3.43\\%), Calendar(10.98\\%) and Canva(22.92\\%). Each data\nentry includes an image, a task description, the last action taken, CoT and the\nnext action to be performed along with grounding information of where the\naction needs to be executed. The data is collected using our in-house advanced\nannotation tool NEXTAG (Next Action Grounding and Annotation Tool). The data is\nadapted for multiple OS, browsers and display types. It is collected by\nmultiple annotators to capture the variation of design and the way person uses\na website.\n  Through this dataset, we aim to facilitate research and development in the\nrealm of LLMs for graphical user interfaces, particularly in tasks related to\nRPA. The dataset's multi-platform nature and coverage of diverse websites\nenable the exploration of cross-interface capabilities in automation tasks. We\nbelieve that our dataset will serve as a valuable resource for advancing the\ncapabilities of multi-platform LLMs in practical applications, fostering\ninnovation in the field of automation and natural language understanding. Using\nGUIDE, we build V-Zen, the first RPA model to automate multiple websites using\nour in-House Automation tool AUTONODE",
      "tldr_zh": "本研究引入了GUIDE数据集，这是一个专为Multimodal Large Language Model (MLLM)应用设计的资源，特别针对Robotic Process Automation (RPA)任务。数据集涵盖了来自Apollo、Gmail、Calendar和Canva等网站的多样数据，包括图像、任务描述、最后一个动作、Chain-of-Thought (CoT)推理、下一个动作以及行动的接地信息，使用内部工具NEXTAG进行收集，并适应多种操作系统、浏览器和显示类型。实验表明，该数据集促进了LLMs在图形用户界面上的研究，支持跨平台自动化任务，最终基于GUIDE构建了V-Zen模型，这是首个使用内部工具AUTONODE自动化多个网站的RPA系统。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "11 pages, 8 figures, 3 Tables and 1 Algorithm",
      "pdf_url": "http://arxiv.org/pdf/2404.16048v2",
      "published_date": "2024-04-09 11:59:41 UTC",
      "updated_date": "2024-10-27 05:54:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T22:58:58.311878"
    },
    {
      "arxiv_id": "2404.08006v1",
      "title": "Learning Efficient and Fair Policies for Uncertainty-Aware Collaborative Human-Robot Order Picking",
      "title_zh": "翻译失败",
      "authors": [
        "Igor G. Smit",
        "Zaharah Bukhsh",
        "Mykola Pechenizkiy",
        "Kostas Alogariastos",
        "Kasper Hendriks",
        "Yingqian Zhang"
      ],
      "abstract": "In collaborative human-robot order picking systems, human pickers and\nAutonomous Mobile Robots (AMRs) travel independently through a warehouse and\nmeet at pick locations where pickers load items onto the AMRs. In this paper,\nwe consider an optimization problem in such systems where we allocate pickers\nto AMRs in a stochastic environment. We propose a novel multi-objective Deep\nReinforcement Learning (DRL) approach to learn effective allocation policies to\nmaximize pick efficiency while also aiming to improve workload fairness amongst\nhuman pickers. In our approach, we model the warehouse states using a graph,\nand define a neural network architecture that captures regional information and\neffectively extracts representations related to efficiency and workload. We\ndevelop a discrete-event simulation model, which we use to train and evaluate\nthe proposed DRL approach. In the experiments, we demonstrate that our approach\ncan find non-dominated policy sets that outline good trade-offs between\nfairness and efficiency objectives. The trained policies outperform the\nbenchmarks in terms of both efficiency and fairness. Moreover, they show good\ntransferability properties when tested on scenarios with different warehouse\nsizes. The implementation of the simulation model, proposed approach, and\nexperiments are published.",
      "tldr_zh": "这篇论文针对不确定性环境下的协作人类-机器人订单拣货系统，提出了一种多目标深度强化学习(DRL)方法，用于学习高效且公平的分配策略，以最大化拣货效率并改善人类拣货员的工作负载公平性。方法通过图模型表示仓库状态，并设计神经网络架构来捕捉区域信息和提取效率相关特征，利用离散事件模拟模型进行训练和评估。实验结果显示，该DRL方法生成的非占优策略集在效率和公平性上优于基准策略，并在不同仓库规模场景中表现出良好的可转移性。研究还公开了模拟模型和实验实现的代码，为实际应用提供了基础。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG",
        "math.OC"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.08006v1",
      "published_date": "2024-04-09 11:45:16 UTC",
      "updated_date": "2024-04-09 11:45:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T22:59:11.470241"
    },
    {
      "arxiv_id": "2404.06229v2",
      "title": "Autonomous Driving Small-Scale Cars: A Survey of Recent Development",
      "title_zh": "翻译失败",
      "authors": [
        "Dianzhao Li",
        "Paul Auerbach",
        "Ostap Okhrin"
      ],
      "abstract": "While engaging with the unfolding revolution in autonomous driving, a\nchallenge presents itself, how can we effectively raise awareness within\nsociety about this transformative trend? While full-scale autonomous driving\nvehicles often come with a hefty price tag, the emergence of small-scale car\nplatforms offers a compelling alternative. These platforms not only serve as\nvaluable educational tools for the broader public and young generations but\nalso function as robust research platforms, contributing significantly to the\nongoing advancements in autonomous driving technology. This survey outlines\nvarious small-scale car platforms, categorizing them and detailing the research\nadvancements accomplished through their usage. The conclusion provides\nproposals for promising future directions in the field.",
      "tldr_zh": "这篇调查论文探讨了小规模自动驾驶汽车平台的最新发展，作为一种经济实惠的替代方案，用于提升社会公众和年轻一代对自动驾驶技术的认识，同时作为研究平台推动技术进步。论文对各种小规模汽车平台进行了分类和概述，并详细阐述了通过这些平台实现的自动驾驶研究进展。最终，论文提出了一些有前景的未来方向，以进一步推进该领域的发展。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.06229v2",
      "published_date": "2024-04-09 11:40:37 UTC",
      "updated_date": "2024-12-20 16:10:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T22:59:21.481339"
    },
    {
      "arxiv_id": "2404.06224v1",
      "title": "Low-Cost Generation and Evaluation of Dictionary Example Sentences",
      "title_zh": "低成本生成和评估字典示例句子",
      "authors": [
        "Bill Cai",
        "Clarence Boon Liang Ng",
        "Daniel Tan",
        "Shelvia Hotama"
      ],
      "abstract": "Dictionary example sentences play an important role in illustrating word\ndefinitions and usage, but manually creating quality sentences is challenging.\nPrior works have demonstrated that language models can be trained to generate\nexample sentences. However, they relied on costly customized models and word\nsense datasets for generation and evaluation of their work. Rapid advancements\nin foundational models present the opportunity to create low-cost, zero-shot\nmethods for the generation and evaluation of dictionary example sentences. We\nintroduce a new automatic evaluation metric called OxfordEval that measures the\nwin-rate of generated sentences against existing Oxford Dictionary sentences.\nOxfordEval shows high alignment with human judgments, enabling large-scale\nautomated quality evaluation. We experiment with various LLMs and\nconfigurations to generate dictionary sentences across word classes. We\ncomplement this with a novel approach of using masked language models to\nidentify and select sentences that best exemplify word meaning. The eventual\nmodel, FM-MLM, achieves over 85.1% win rate against Oxford baseline sentences\naccording to OxfordEval, compared to 39.8% win rate for prior model-generated\nsentences.",
      "tldr_zh": "本研究针对字典例句生成和评估的挑战，提出了一种低成本的零样本方法，利用各种 LLMs 生成句子，并引入新评估指标 OxfordEval 来测量生成句子相对于牛津字典句子的胜率，该指标与人类判断高度一致。\n他们结合 masked language models 的新方法，识别和选择最佳例句，最终开发出 FM-MLM 模型。\n实验结果显示，FM-MLM 达到了 85.1% 的胜率，远超先前模型的 39.8%，显著提高了字典例句的质量和效率。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.06224v1",
      "published_date": "2024-04-09 11:26:59 UTC",
      "updated_date": "2024-04-09 11:26:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T22:59:34.873730"
    },
    {
      "arxiv_id": "2404.07239v1",
      "title": "Advancements in Radiomics and Artificial Intelligence for Thyroid Cancer Diagnosis",
      "title_zh": "放射组学和人工智能在甲状腺癌诊断中的进展",
      "authors": [
        "Milad Yousefi",
        "Shadi Farabi Maleki",
        "Ali Jafarizadeh",
        "Mahya Ahmadpour Youshanlui",
        "Aida Jafari",
        "Siamak Pedrammehr",
        "Roohallah Alizadehsani",
        "Ryszard Tadeusiewicz",
        "Pawel Plawiak"
      ],
      "abstract": "Thyroid cancer is an increasing global health concern that requires advanced\ndiagnostic methods. The application of AI and radiomics to thyroid cancer\ndiagnosis is examined in this review. A review of multiple databases was\nconducted in compliance with PRISMA guidelines until October 2023. A\ncombination of keywords led to the discovery of an English academic publication\non thyroid cancer and related subjects. 267 papers were returned from the\noriginal search after 109 duplicates were removed. Relevant studies were\nselected according to predetermined criteria after 124 articles were eliminated\nbased on an examination of their abstract and title. After the comprehensive\nanalysis, an additional six studies were excluded. Among the 28 included\nstudies, radiomics analysis, which incorporates ultrasound (US) images,\ndemonstrated its effectiveness in diagnosing thyroid cancer. Various results\nwere noted, some of the studies presenting new strategies that outperformed the\nstatus quo. The literature has emphasized various challenges faced by AI\nmodels, including interpretability issues, dataset constraints, and operator\ndependence. The synthesized findings of the 28 included studies mentioned the\nneed for standardization efforts and prospective multicenter studies to address\nthese concerns. Furthermore, approaches to overcome these obstacles were\nidentified, such as advances in explainable AI technology and personalized\nmedicine techniques. The review focuses on how AI and radiomics could transform\nthe diagnosis and treatment of thyroid cancer. Despite challenges, future\nresearch on multidisciplinary cooperation, clinical applicability validation,\nand algorithm improvement holds the potential to improve patient outcomes and\ndiagnostic precision in the treatment of thyroid cancer.",
      "tldr_zh": "这篇综述探讨了 AI 和 radiomics 在甲状腺癌诊断中的进展，通过遵循 PRISMA 指南对多数据库文献进行系统回顾，共纳入了 28 篇相关研究。研究发现，radiomics 分析结合超声 (US) 图像在诊断中表现出色，并提出了一些新策略优于现有方法，同时强调了 AI 模型面临的挑战，如可解释性问题、数据集限制和操作者依赖。作者建议通过 explainable AI 技术和标准化努力来克服这些障碍，并呼吁开展前瞻性多中心研究。总体而言，这为未来多学科合作、算法改进和临床验证提供了方向，有望提升甲状腺癌的诊断精度和患者预后。",
      "categories": [
        "q-bio.QM",
        "cs.AI",
        "eess.IV",
        "J.3.2; J.3.3"
      ],
      "primary_category": "q-bio.QM",
      "comment": "50 pages, 8 figures, 1 table, 119 references",
      "pdf_url": "http://arxiv.org/pdf/2404.07239v1",
      "published_date": "2024-04-09 11:05:20 UTC",
      "updated_date": "2024-04-09 11:05:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T22:59:48.051740"
    },
    {
      "arxiv_id": "2404.06212v1",
      "title": "OmniFusion Technical Report",
      "title_zh": "OmniFusion 技术报告",
      "authors": [
        "Elizaveta Goncharova",
        "Anton Razzhigaev",
        "Matvey Mikhalchuk",
        "Maxim Kurkin",
        "Irina Abdullaeva",
        "Matvey Skripkin",
        "Ivan Oseledets",
        "Denis Dimitrov",
        "Andrey Kuznetsov"
      ],
      "abstract": "Last year, multimodal architectures served up a revolution in AI-based\napproaches and solutions, extending the capabilities of large language models\n(LLM). We propose an \\textit{OmniFusion} model based on a pretrained LLM and\nadapters for visual modality. We evaluated and compared several architecture\ndesign principles for better text and visual data coupling: MLP and transformer\nadapters, various CLIP ViT-based encoders (SigLIP, InternVIT, etc.), and their\nfusing approach, image encoding method (whole image or tiles encoding) and two\n7B LLMs (the proprietary one and open-source Mistral). Experiments on 8\nvisual-language benchmarks show the top score for the best OmniFusion setup in\nterms of different VQA tasks in comparison with open-source LLaVA-like\nsolutions: VizWiz, Pope, MM-Vet, ScienceQA, MMBench, TextVQA, VQAv2, MMMU. We\nalso propose a variety of situations, where OmniFusion provides highly-detailed\nanswers in different domains: housekeeping, sightseeing, culture, medicine,\nhandwritten and scanned equations recognition, etc. Mistral-based OmniFusion\nmodel is an open-source solution with weights, training and inference scripts\navailable at https://github.com/AIRI-Institute/OmniFusion.",
      "tldr_zh": "该研究提出 OmniFusion，一种基于预训练 LLM 和视觉适配器的多模态模型，旨在提升文本和视觉数据的耦合。研究者评估了多种架构设计原则，包括 MLP 和 transformer adapters、各种 CLIP ViT-based encoders（如 SigLIP 和 InternVIT）、融合方法以及图像编码策略（如整张图像或切片编码），并比较了两个 7B LLM（专有和开源 Mistral）。在 8 个视觉语言基准测试（如 VizWiz、Pope、MM-Vet 等 VQA 任务）中，OmniFusion 模型超越了开源 LLaVA-like 解决方案，并展示了在多样领域（如家务、医学、手写方程识别）的详细回答能力；此外，Mistral-based 版本已开源，提供权重、训练和推理脚本。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "6804, 68T50 (Primary)",
        "I.2.7; I.2.10; I.4.9"
      ],
      "primary_category": "cs.CV",
      "comment": "17 pages, 4 figures, 9 tables, 2 appendices",
      "pdf_url": "http://arxiv.org/pdf/2404.06212v1",
      "published_date": "2024-04-09 11:00:19 UTC",
      "updated_date": "2024-04-09 11:00:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T22:59:59.474870"
    },
    {
      "arxiv_id": "2404.06209v3",
      "title": "Elephants Never Forget: Memorization and Learning of Tabular Data in Large Language Models",
      "title_zh": "大象永不忘记：大型语言模型中表格数据的记忆和学习",
      "authors": [
        "Sebastian Bordt",
        "Harsha Nori",
        "Vanessa Rodrigues",
        "Besmira Nushi",
        "Rich Caruana"
      ],
      "abstract": "While many have shown how Large Language Models (LLMs) can be applied to a\ndiverse set of tasks, the critical issues of data contamination and\nmemorization are often glossed over. In this work, we address this concern for\ntabular data. Specifically, we introduce a variety of different techniques to\nassess whether a language model has seen a tabular dataset during training.\nThis investigation reveals that LLMs have memorized many popular tabular\ndatasets verbatim. We then compare the few-shot learning performance of LLMs on\ndatasets that were seen during training to the performance on datasets released\nafter training. We find that LLMs perform better on datasets seen during\ntraining, indicating that memorization leads to overfitting. At the same time,\nLLMs show non-trivial performance on novel datasets and are surprisingly robust\nto data transformations. We then investigate the in-context statistical\nlearning abilities of LLMs. While LLMs are significantly better than random at\nsolving statistical classification problems, the sample efficiency of few-shot\nlearning lags behind traditional statistical learning algorithms, especially as\nthe dimension of the problem increases. This suggests that much of the observed\nfew-shot performance on novel real-world datasets is due to the LLM's world\nknowledge. Overall, our results highlight the importance of testing whether an\nLLM has seen an evaluation dataset during pre-training. We release the\nhttps://github.com/interpretml/LLM-Tabular-Memorization-Checker Python package\nto test LLMs for memorization of tabular datasets.",
      "tldr_zh": "这篇论文探讨了大型语言模型(LLMs)在处理表格数据时的记忆和学习问题，特别是数据污染和记忆化的影响。研究者开发了多种技术来检测LLMs是否在训练中见过特定数据集，结果显示LLMs已逐字记忆了许多流行表格数据集，导致在这些数据集上的少样本学习表现更好，但也引发了过拟合问题。与此同时，LLMs在新数据集上仍有非凡性能，并对数据变换表现出色。论文强调测试LLMs预训练数据的重要性，并发布了LLM-Tabular-Memorization-Checker Python包作为工具。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "COLM camera ready, fix typo",
      "pdf_url": "http://arxiv.org/pdf/2404.06209v3",
      "published_date": "2024-04-09 10:58:21 UTC",
      "updated_date": "2024-12-04 10:33:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:00:11.871760"
    },
    {
      "arxiv_id": "2404.15189v1",
      "title": "Text2Grasp: Grasp synthesis by text prompts of object grasping parts",
      "title_zh": "翻译失败",
      "authors": [
        "Xiaoyun Chang",
        "Yi Sun"
      ],
      "abstract": "The hand plays a pivotal role in human ability to grasp and manipulate\nobjects and controllable grasp synthesis is the key for successfully performing\ndownstream tasks. Existing methods that use human intention or task-level\nlanguage as control signals for grasping inherently face ambiguity. To address\nthis challenge, we propose a grasp synthesis method guided by text prompts of\nobject grasping parts, Text2Grasp, which provides more precise control.\nSpecifically, we present a two-stage method that includes a text-guided\ndiffusion model TextGraspDiff to first generate a coarse grasp pose, then apply\na hand-object contact optimization process to ensure both plausibility and\ndiversity. Furthermore, by leveraging Large Language Model, our method\nfacilitates grasp synthesis guided by task-level and personalized text\ndescriptions without additional manual annotations. Extensive experiments\ndemonstrate that our method achieves not only accurate part-level grasp control\nbut also comparable performance in grasp quality.",
      "tldr_zh": "该研究提出Text2Grasp方法，通过对象抓取部位的文本提示（如“抓取手柄”）来指导抓取合成，解决现有方法基于人类意图或任务级语言的模糊性问题。具体而言，该方法采用两阶段流程：首先使用文本引导的扩散模型TextGraspDiff生成粗略抓取姿势，然后通过手-对象接触优化过程确保抓取的可行性和多样性；此外，利用Large Language Model支持任务级和个性化的文本描述指导，而无需额外手动标注。实验结果显示，Text2Grasp实现了精确的部件级抓取控制，并在抓取质量上与现有方法相当。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.15189v1",
      "published_date": "2024-04-09 10:57:27 UTC",
      "updated_date": "2024-04-09 10:57:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:00:22.058703"
    },
    {
      "arxiv_id": "2404.06201v1",
      "title": "Open-Source AI-based SE Tools: Opportunities and Challenges of Collaborative Software Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Zhihao Lin",
        "Wei Ma",
        "Tao Lin",
        "Yaowen Zheng",
        "Jingquan Ge",
        "Jun Wang",
        "Jacques Klein",
        "Tegawende Bissyande",
        "Yang Liu",
        "Li Li"
      ],
      "abstract": "Large Language Models (LLMs) have become instrumental in advancing software\nengineering (SE) tasks, showcasing their efficacy in code understanding and\nbeyond. Like traditional SE tools, open-source collaboration is key in\nrealising the excellent products. However, with AI models, the essential need\nis in data. The collaboration of these AI-based SE models hinges on maximising\nthe sources of high-quality data. However, data especially of high quality,\noften holds commercial or sensitive value, making it less accessible for\nopen-source AI-based SE projects. This reality presents a significant barrier\nto the development and enhancement of AI-based SE tools within the software\nengineering community. Therefore, researchers need to find solutions for\nenabling open-source AI-based SE models to tap into resources by different\norganisations. Addressing this challenge, our position paper investigates one\nsolution to facilitate access to diverse organizational resources for\nopen-source AI models, ensuring privacy and commercial sensitivities are\nrespected. We introduce a governance framework centered on federated learning\n(FL), designed to foster the joint development and maintenance of open-source\nAI code models while safeguarding data privacy and security. Additionally, we\npresent guidelines for developers on AI-based SE tool collaboration, covering\ndata requirements, model architecture, updating strategies, and version\ncontrol. Given the significant influence of data characteristics on FL, our\nresearch examines the effect of code data heterogeneity on FL performance.",
      "tldr_zh": "这篇论文探讨了Large Language Models (LLMs) 在软件工程 (SE) 任务中的应用及其开源协作机遇与挑战，强调高质量数据获取的障碍，如商业敏感性和隐私问题。论文提出一个以Federated Learning (FL) 为核心的治理框架，旨在帮助开源AI-based SE 工具安全访问不同组织的资源，同时保护数据隐私和安全。作者还提供了开发者指南，包括数据要求、模型架构、更新策略和版本控制，并研究了代码数据异质性对FL 性能的影响，以促进协作式软件学习的发展。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.06201v1",
      "published_date": "2024-04-09 10:47:02 UTC",
      "updated_date": "2024-04-09 10:47:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:00:33.450218"
    },
    {
      "arxiv_id": "2404.06188v1",
      "title": "Diverse Randomized Value Functions: A Provably Pessimistic Approach for Offline Reinforcement Learning",
      "title_zh": "多样化的随机化价值函数：一种可证明的悲观方法用于离线强化学习",
      "authors": [
        "Xudong Yu",
        "Chenjia Bai",
        "Hongyi Guo",
        "Changhong Wang",
        "Zhen Wang"
      ],
      "abstract": "Offline Reinforcement Learning (RL) faces distributional shift and unreliable\nvalue estimation, especially for out-of-distribution (OOD) actions. To address\nthis, existing uncertainty-based methods penalize the value function with\nuncertainty quantification and demand numerous ensemble networks, posing\ncomputational challenges and suboptimal outcomes. In this paper, we introduce a\nnovel strategy employing diverse randomized value functions to estimate the\nposterior distribution of $Q$-values. It provides robust uncertainty\nquantification and estimates lower confidence bounds (LCB) of $Q$-values. By\napplying moderate value penalties for OOD actions, our method fosters a\nprovably pessimistic approach. We also emphasize on diversity within randomized\nvalue functions and enhance efficiency by introducing a diversity\nregularization method, reducing the requisite number of networks. These modules\nlead to reliable value estimation and efficient policy learning from offline\ndata. Theoretical analysis shows that our method recovers the provably\nefficient LCB-penalty under linear MDP assumptions. Extensive empirical results\nalso demonstrate that our proposed method significantly outperforms baseline\nmethods in terms of performance and parametric efficiency.",
      "tldr_zh": "这篇论文针对Offline Reinforcement Learning中的分布偏移和不可靠价值估计问题，提出了一种基于多样化随机化价值函数的新策略，用于估计Q-values的后验分布并计算下置信界(LCB)。该方法通过对OOD actions施加适度价值惩罚，实现可证明的悲观(pessimistic)方法，同时引入多样性正则化来减少所需网络数量，提升计算效率。实验结果显示，该方法在性能和参数效率上显著优于基线方法，并在线性MDP假设下理论上证明了其有效性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.06188v1",
      "published_date": "2024-04-09 10:15:18 UTC",
      "updated_date": "2024-04-09 10:15:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:00:46.954999"
    },
    {
      "arxiv_id": "2404.06186v1",
      "title": "Clue-Instruct: Text-Based Clue Generation for Educational Crossword Puzzles",
      "title_zh": "Clue-Instruct：基于文本的线索生成用于教育",
      "authors": [
        "Andrea Zugarini",
        "Kamyar Zeinalipour",
        "Surya Sai Kadali",
        "Marco Maggini",
        "Marco Gori",
        "Leonardo Rigutini"
      ],
      "abstract": "Crossword puzzles are popular linguistic games often used as tools to engage\nstudents in learning. Educational crosswords are characterized by less cryptic\nand more factual clues that distinguish them from traditional crossword\npuzzles. Despite there exist several publicly available clue-answer pair\ndatabases for traditional crosswords, educational clue-answer pairs datasets\nare missing. In this article, we propose a methodology to build educational\nclue generation datasets that can be used to instruct Large Language Models\n(LLMs). By gathering from Wikipedia pages informative content associated with\nrelevant keywords, we use Large Language Models to automatically generate\npedagogical clues related to the given input keyword and its context. With such\nan approach, we created clue-instruct, a dataset containing 44,075 unique\nexamples with text-keyword pairs associated with three distinct crossword\nclues. We used clue-instruct to instruct different LLMs to generate educational\nclues from a given input content and keyword. Both human and automatic\nevaluations confirmed the quality of the generated clues, thus validating the\neffectiveness of our approach.",
      "tldr_zh": "本文提出Clue-Instruct方法，用于生成教育性填字游戏线索，以填补传统线索数据库的空白。研究团队从Wikipedia页面提取与关键词相关的知识内容，并利用Large Language Models (LLMs)自动生成教学导向的线索，从而构建了一个包含44,075个独特例子的数据集，每个例子包括文本-关键词对和三种不同的线索。实验结果显示，通过Clue-Instruct指导的LLMs生成的线索质量高，经人工和自动评估验证了该方法的有效性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.06186v1",
      "published_date": "2024-04-09 10:12:34 UTC",
      "updated_date": "2024-04-09 10:12:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:00:59.611872"
    },
    {
      "arxiv_id": "2404.06181v1",
      "title": "EPL: Evidential Prototype Learning for Semi-supervised Medical Image Segmentation",
      "title_zh": "翻译失败",
      "authors": [
        "Yuanpeng He"
      ],
      "abstract": "Although current semi-supervised medical segmentation methods can achieve\ndecent performance, they are still affected by the uncertainty in unlabeled\ndata and model predictions, and there is currently a lack of effective\nstrategies that can explore the uncertain aspects of both simultaneously. To\naddress the aforementioned issues, we propose Evidential Prototype Learning\n(EPL), which utilizes an extended probabilistic framework to effectively fuse\nvoxel probability predictions from different sources and achieves prototype\nfusion utilization of labeled and unlabeled data under a generalized evidential\nframework, leveraging voxel-level dual uncertainty masking. The uncertainty not\nonly enables the model to self-correct predictions but also improves the guided\nlearning process with pseudo-labels and is able to feed back into the\nconstruction of hidden features. The method proposed in this paper has been\nexperimented on LA, Pancreas-CT and TBAD datasets, achieving the\nstate-of-the-art performance in three different labeled ratios, which strongly\ndemonstrates the effectiveness of our strategy.",
      "tldr_zh": "本文提出 Evidential Prototype Learning (EPL) 方法，用于半监督 medical image segmentation，以解决未标注数据和模型预测的不确定性问题。EPL 通过扩展的概率框架融合不同来源的体素概率预测，并采用体素级双重不确定性 masking，实现标注和未标注数据的原型融合，从而提升模型的自修正能力和伪标签引导学习。实验在 LA、Pancreas-CT 和 TBAD 数据集上验证了该方法的有效性，达到了 state-of-the-art 性能，在不同标注比例下均表现出色。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.06181v1",
      "published_date": "2024-04-09 10:04:06 UTC",
      "updated_date": "2024-04-09 10:04:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:01:12.451786"
    },
    {
      "arxiv_id": "2404.06177v2",
      "title": "Uncertainty-aware Evidential Fusion-based Learning for Semi-supervised Medical Image Segmentation",
      "title_zh": "翻译失败",
      "authors": [
        "Yuanpeng He",
        "Lijian Li"
      ],
      "abstract": "Although the existing uncertainty-based semi-supervised medical segmentation\nmethods have achieved excellent performance, they usually only consider a\nsingle uncertainty evaluation, which often fails to solve the problem related\nto credibility completely. Therefore, based on the framework of evidential deep\nlearning, this paper integrates the evidential predictive results in the\ncross-region of mixed and original samples to reallocate the confidence degree\nand uncertainty measure of each voxel, which is realized by emphasizing\nuncertain information of probability assignments fusion rule of traditional\nevidence theory. Furthermore, we design a voxel-level asymptotic learning\nstrategy by introducing information entropy to combine with the fused\nuncertainty measure to estimate voxel prediction more precisely. The model will\ngradually pay attention to the prediction results with high uncertainty in the\nlearning process, to learn the features that are difficult to master. The\nexperimental results on LA, Pancreas-CT, ACDC and TBAD datasets demonstrate the\nsuperior performance of our proposed method in comparison with the existing\nstate of the arts.",
      "tldr_zh": "本文提出了一种基于证据深度学习（evidential deep learning）的半监督医疗图像分割方法，通过整合混合和原始样本的交叉区域证据预测结果，重新分配每个体素的置信度和不确定性测量，并强调不确定信息的概率分配融合规则。方法还设计了体素级渐进学习策略，利用信息熵（information entropy）与融合的不确定性相结合，更精确地估计预测并逐步关注高不确定性区域的学习。实验在 LA、Pancreas-CT、ACDC 和 TBAD 数据集上表明，该方法优于现有最先进技术，提升了分割性能。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.06177v2",
      "published_date": "2024-04-09 09:58:10 UTC",
      "updated_date": "2024-04-11 15:57:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:01:24.135993"
    },
    {
      "arxiv_id": "2404.06170v1",
      "title": "CLIP-Embed-KD: Computationally Efficient Knowledge Distillation Using Embeddings as Teachers",
      "title_zh": "翻译失败",
      "authors": [
        "Lakshmi Nair"
      ],
      "abstract": "Contrastive Language-Image Pre-training (CLIP) has been shown to improve\nzero-shot generalization capabilities of language and vision models. In this\npaper, we extend CLIP for efficient knowledge distillation, by utilizing\nembeddings as teachers. Typical knowledge distillation frameworks require\nrunning forward passes through a teacher model, which is often prohibitive in\nthe case of billion or trillion parameter teachers. In these cases, using only\nthe embeddings of the teacher models to guide the distillation can yield\nsignificant computational savings. Our preliminary findings show that\nCLIP-based knowledge distillation with embeddings can outperform full scale\nknowledge distillation using $9\\times$ less memory and $8\\times$ less training\ntime. Code available at: https://github.com/lnairGT/CLIP-Distillation/",
      "tldr_zh": "这篇论文提出 CLIP-Embed-KD，一种计算高效的知识蒸馏方法，使用 embeddings 作为教师模型来扩展 CLIP（Contrastive Language-Image Pre-training）的零样本泛化能力。传统知识蒸馏需要运行大型教师模型的正向传递，而该方法仅利用教师模型的 embeddings 进行指导，从而显著减少计算开销。初步实验结果显示，CLIP-Embed-KD 比全规模知识蒸馏性能更优，同时节省 9 倍内存和 8 倍训练时间。代码已在 GitHub 上开源，供进一步研究使用。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Short paper - 5 pages; 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2404.06170v1",
      "published_date": "2024-04-09 09:49:57 UTC",
      "updated_date": "2024-04-09 09:49:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:01:36.893088"
    },
    {
      "arxiv_id": "2404.06167v1",
      "title": "scCDCG: Efficient Deep Structural Clustering for single-cell RNA-seq via Deep Cut-informed Graph Embedding",
      "title_zh": "翻译失败",
      "authors": [
        "Ping Xu",
        "Zhiyuan Ning",
        "Meng Xiao",
        "Guihai Feng",
        "Xin Li",
        "Yuanchun Zhou",
        "Pengfei Wang"
      ],
      "abstract": "Single-cell RNA sequencing (scRNA-seq) is essential for unraveling cellular\nheterogeneity and diversity, offering invaluable insights for bioinformatics\nadvancements. Despite its potential, traditional clustering methods in\nscRNA-seq data analysis often neglect the structural information embedded in\ngene expression profiles, crucial for understanding cellular correlations and\ndependencies. Existing strategies, including graph neural networks, face\nchallenges in handling the inefficiency due to scRNA-seq data's intrinsic\nhigh-dimension and high-sparsity. Addressing these limitations, we introduce\nscCDCG (single-cell RNA-seq Clustering via Deep Cut-informed Graph), a novel\nframework designed for efficient and accurate clustering of scRNA-seq data that\nsimultaneously utilizes intercellular high-order structural information. scCDCG\ncomprises three main components: (i) A graph embedding module utilizing deep\ncut-informed techniques, which effectively captures intercellular high-order\nstructural information, overcoming the over-smoothing and inefficiency issues\nprevalent in prior graph neural network methods. (ii) A self-supervised\nlearning module guided by optimal transport, tailored to accommodate the unique\ncomplexities of scRNA-seq data, specifically its high-dimension and\nhigh-sparsity. (iii) An autoencoder-based feature learning module that\nsimplifies model complexity through effective dimension reduction and feature\nextraction. Our extensive experiments on 6 datasets demonstrate scCDCG's\nsuperior performance and efficiency compared to 7 established models,\nunderscoring scCDCG's potential as a transformative tool in scRNA-seq data\nanalysis. Our code is available at: https://github.com/XPgogogo/scCDCG.",
      "tldr_zh": "本文提出 scCDCG 框架，用于单细胞 RNA 测序 (scRNA-seq) 数据的高效深度结构聚类，旨在解决传统方法忽略基因表达结构信息以及现有图神经网络 (graph neural networks) 在高维高稀疏数据上的效率问题。scCDCG 包括三个核心组件：Deep Cut-informed 图嵌入模块捕捉细胞间高阶结构信息、基于 optimal transport 的自监督学习模块处理数据复杂性，以及 autoencoder-based 特征学习模块实现降维和特征提取。在 6 个数据集的实验中，scCDCG 比 7 个现有模型表现出显著优越的性能和效率，并提供开源代码以促进进一步应用。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "q-bio.GN"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted as a long paper for the research track at DASFAA 2024",
      "pdf_url": "http://arxiv.org/pdf/2404.06167v1",
      "published_date": "2024-04-09 09:46:17 UTC",
      "updated_date": "2024-04-09 09:46:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:01:49.176917"
    },
    {
      "arxiv_id": "2404.06162v3",
      "title": "Characterizing Multimodal Long-form Summarization: A Case Study on Financial Reports",
      "title_zh": "多模态长形式摘要的表征：以财务报告为例研究",
      "authors": [
        "Tianyu Cao",
        "Natraj Raman",
        "Danial Dervovic",
        "Chenhao Tan"
      ],
      "abstract": "As large language models (LLMs) expand the power of natural language\nprocessing to handle long inputs, rigorous and systematic analyses are\nnecessary to understand their abilities and behavior. A salient application is\nsummarization, due to its ubiquity and controversy (e.g., researchers have\ndeclared the death of summarization). In this paper, we use financial report\nsummarization as a case study because financial reports are not only long but\nalso use numbers and tables extensively. We propose a computational framework\nfor characterizing multimodal long-form summarization and investigate the\nbehavior of Claude 2.0/2.1, GPT-4/3.5, and Cohere. We find that GPT-3.5 and\nCohere fail to perform this summarization task meaningfully. For Claude 2 and\nGPT-4, we analyze the extractiveness of the summary and identify a position\nbias in LLMs. This position bias disappears after shuffling the input for\nClaude, which suggests that Claude seems to recognize important information. We\nalso conduct a comprehensive investigation on the use of numeric data in\nLLM-generated summaries and offer a taxonomy of numeric hallucination. We\nemploy prompt engineering to improve GPT-4's use of numbers with limited\nsuccess. Overall, our analyses highlight the strong capability of Claude 2 in\nhandling long multimodal inputs compared to GPT-4. The generated summaries and\nevaluation code are available at\nhttps://github.com/ChicagoHAI/characterizing-multimodal-long-form-summarization.",
      "tldr_zh": "本研究以财务报告为案例，探讨大型语言模型（LLMs）处理多模态长形式摘要的能力，提出一个计算框架来表征这些模型的表现。研究评估了Claude 2.0/2.1、GPT-4/3.5和Cohere模型，发现GPT-3.5和Cohere无法有效生成摘要，而Claude 2和GPT-4存在摘要提取性和位置偏差等问题。进一步分析揭示Claude 2在处理数字数据和减少幻觉方面优于GPT-4，并通过提示工程尝试改善GPT-4的表现，但效果有限。该框架的分析结果突出了Claude 2在长多模态输入处理上的优势，并提供了相关代码以供进一步研究。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.06162v3",
      "published_date": "2024-04-09 09:34:25 UTC",
      "updated_date": "2024-08-15 13:59:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:02:00.589130"
    },
    {
      "arxiv_id": "2404.06152v1",
      "title": "HFNeRF: Learning Human Biomechanic Features with Neural Radiance Fields",
      "title_zh": "翻译失败",
      "authors": [
        "Arnab Dey",
        "Di Yang",
        "Antitza Dantcheva",
        "Jean Martinet"
      ],
      "abstract": "In recent advancements in novel view synthesis, generalizable Neural Radiance\nFields (NeRF) based methods applied to human subjects have shown remarkable\nresults in generating novel views from few images. However, this generalization\nability cannot capture the underlying structural features of the skeleton\nshared across all instances. Building upon this, we introduce HFNeRF: a novel\ngeneralizable human feature NeRF aimed at generating human biomechanic features\nusing a pre-trained image encoder. While previous human NeRF methods have shown\npromising results in the generation of photorealistic virtual avatars, such\nmethods lack underlying human structure or biomechanic features such as\nskeleton or joint information that are crucial for downstream applications\nincluding Augmented Reality (AR)/Virtual Reality (VR). HFNeRF leverages 2D\npre-trained foundation models toward learning human features in 3D using neural\nrendering, and then volume rendering towards generating 2D feature maps. We\nevaluate HFNeRF in the skeleton estimation task by predicting heatmaps as\nfeatures. The proposed method is fully differentiable, allowing to successfully\nlearn color, geometry, and human skeleton in a simultaneous manner. This paper\npresents preliminary results of HFNeRF, illustrating its potential in\ngenerating realistic virtual avatars with biomechanic features using NeRF.",
      "tldr_zh": "本研究提出 HFNeRF，一种基于 Neural Radiance Fields (NeRF) 的可泛化框架，旨在从少量图像中学习人体生物力学特征，如骨骼和关节信息，以生成更全面的虚拟头像。HFNeRF 利用预训练的 2D 图像编码器，通过神经渲染学习 3D 人体特征，并通过体积渲染生成 2D 特征图，使颜色、几何和骨骼信息能够同时被完全可微地学习。在骨骼估计任务中，该方法通过预测热图表现出色，初步结果展示了其在 Augmented Reality (AR)/Virtual Reality (VR) 等应用中的潜力。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.06152v1",
      "published_date": "2024-04-09 09:23:04 UTC",
      "updated_date": "2024-04-09 09:23:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:02:13.476139"
    },
    {
      "arxiv_id": "2404.06144v1",
      "title": "Differential Privacy for Anomaly Detection: Analyzing the Trade-off Between Privacy and Explainability",
      "title_zh": "异常检测中的差分隐私：分析隐私与可解释性之间的权衡",
      "authors": [
        "Fatima Ezzeddine",
        "Mirna Saad",
        "Omran Ayoub",
        "Davide Andreoletti",
        "Martin Gjoreski",
        "Ihab Sbeity",
        "Marc Langheinrich",
        "Silvia Giordano"
      ],
      "abstract": "Anomaly detection (AD), also referred to as outlier detection, is a\nstatistical process aimed at identifying observations within a dataset that\nsignificantly deviate from the expected pattern of the majority of the data.\nSuch a process finds wide application in various fields, such as finance and\nhealthcare. While the primary objective of AD is to yield high detection\naccuracy, the requirements of explainability and privacy are also paramount.\nThe first ensures the transparency of the AD process, while the second\nguarantees that no sensitive information is leaked to untrusted parties. In\nthis work, we exploit the trade-off of applying Explainable AI (XAI) through\nSHapley Additive exPlanations (SHAP) and differential privacy (DP). We perform\nAD with different models and on various datasets, and we thoroughly evaluate\nthe cost of privacy in terms of decreased accuracy and explainability. Our\nresults show that the enforcement of privacy through DP has a significant\nimpact on detection accuracy and explainability, which depends on both the\ndataset and the considered AD model. We further show that the visual\ninterpretation of explanations is also influenced by the choice of the AD\nalgorithm.",
      "tldr_zh": "本研究探讨了在异常检测(Anomaly Detection, AD)中应用差分隐私(Differential Privacy, DP)与可解释性(Explainability)之间的权衡。作者使用SHapley Additive exPlanations (SHAP)作为Explainable AI (XAI)工具，在不同AD模型和数据集上进行实验，评估DP对检测准确性和解释透明度的影响。结果显示，DP显著降低了检测准确性与可解释性水平，这种影响因数据集和AD模型而异；此外，AD算法的选择也会改变解释的可视化效果。该工作突出了在隐私保护下实现AD透明性的挑战，为未来算法设计提供了重要参考。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.06144v1",
      "published_date": "2024-04-09 09:09:36 UTC",
      "updated_date": "2024-04-09 09:09:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:02:23.596034"
    },
    {
      "arxiv_id": "2404.06137v1",
      "title": "SmurfCat at SemEval-2024 Task 6: Leveraging Synthetic Data for Hallucination Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Elisei Rykov",
        "Yana Shishkina",
        "Kseniia Petrushina",
        "Kseniia Titova",
        "Sergey Petrakov",
        "Alexander Panchenko"
      ],
      "abstract": "In this paper, we present our novel systems developed for the SemEval-2024\nhallucination detection task. Our investigation spans a range of strategies to\ncompare model predictions with reference standards, encompassing diverse\nbaselines, the refinement of pre-trained encoders through supervised learning,\nand an ensemble approaches utilizing several high-performing models. Through\nthese explorations, we introduce three distinct methods that exhibit strong\nperformance metrics. To amplify our training data, we generate additional\ntraining samples from unlabelled training subset. Furthermore, we provide a\ndetailed comparative analysis of our approaches. Notably, our premier method\nachieved a commendable 9th place in the competition's model-agnostic track and\n17th place in model-aware track, highlighting its effectiveness and potential.",
      "tldr_zh": "这篇论文介绍了SmurfCat系统，用于SemEval-2024 Task 6的hallucination detection任务，重点利用synthetic data扩充训练集以提升模型性能。研究者探索了多种策略，包括使用基线模型、通过监督学习微调pre-trained encoders，以及采用ensemble approaches整合多个高性能模型，从而引入三种表现出色的检测方法。最终，他们的首选方法在比赛中获得模型无关轨道第9名和模型相关轨道第17名的成绩，证明了该方法的有效性和潜力。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "12 pages, 10 tables, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2404.06137v1",
      "published_date": "2024-04-09 09:03:44 UTC",
      "updated_date": "2024-04-09 09:03:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:02:36.273594"
    },
    {
      "arxiv_id": "2404.06127v1",
      "title": "FLEX: FLEXible Federated Learning Framework",
      "title_zh": "FLEX：灵活的联邦学习框架",
      "authors": [
        "Francisco Herrera",
        "Daniel Jiménez-López",
        "Alberto Argente-Garrido",
        "Nuria Rodríguez-Barroso",
        "Cristina Zuheros",
        "Ignacio Aguilera-Martos",
        "Beatriz Bello",
        "Mario García-Márquez",
        "M. Victoria Luzón"
      ],
      "abstract": "In the realm of Artificial Intelligence (AI), the need for privacy and\nsecurity in data processing has become paramount. As AI applications continue\nto expand, the collection and handling of sensitive data raise concerns about\nindividual privacy protection. Federated Learning (FL) emerges as a promising\nsolution to address these challenges by enabling decentralized model training\non local devices, thus preserving data privacy. This paper introduces FLEX: a\nFLEXible Federated Learning Framework designed to provide maximum flexibility\nin FL research experiments. By offering customizable features for data\ndistribution, privacy parameters, and communication strategies, FLEX empowers\nresearchers to innovate and develop novel FL techniques. The framework also\nincludes libraries for specific FL implementations including: (1) anomalies,\n(2) blockchain, (3) adversarial attacks and defences, (4) natural language\nprocessing and (5) decision trees, enhancing its versatility and applicability\nin various domains. Overall, FLEX represents a significant advancement in FL\nresearch, facilitating the development of robust and efficient FL applications.",
      "tldr_zh": "该论文介绍了FLEX，一种灵活的Federated Learning (FL)框架，旨在解决AI领域的数据隐私和安全挑战，通过在本地设备上进行去中心化模型训练来保护敏感数据。FLEX提供可自定义的数据分布、隐私参数和通信策略，帮助研究人员创新开发新型FL技术，并包含针对特定实现的库，如anomalies、blockchain、adversarial attacks and defences、natural language processing和decision trees。整体而言，该框架提升了FL研究的适用性和效率，促进了鲁棒性强的FL应用的发展。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "Submitted to Information Fusion",
      "pdf_url": "http://arxiv.org/pdf/2404.06127v1",
      "published_date": "2024-04-09 08:51:05 UTC",
      "updated_date": "2024-04-09 08:51:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:02:46.782944"
    },
    {
      "arxiv_id": "2404.06124v3",
      "title": "Hierarchical Insights: Exploiting Structural Similarities for Reliable 3D Semantic Segmentation",
      "title_zh": "层级洞见：利用结构相似性实现可靠的3D语义分割",
      "authors": [
        "Mariella Dreissig",
        "Simon Ruehle",
        "Florian Piewak",
        "Joschka Boedecker"
      ],
      "abstract": "Safety-critical applications such as autonomous driving require robust 3D\nenvironment perception algorithms capable of handling diverse and ambiguous\nsurroundings. The predictive performance of classification models is heavily\ninfluenced by the dataset and the prior knowledge provided by the annotated\nlabels. While labels guide the learning process, they often fail to capture the\ninherent relationships between classes that are naturally understood by humans.\nWe propose a training strategy for a 3D LiDAR semantic segmentation model that\nlearns structural relationships between classes through abstraction. This is\nachieved by implicitly modeling these relationships using a learning rule for\nhierarchical multi-label classification (HMC). Our detailed analysis\ndemonstrates that this training strategy not only improves the model's\nconfidence calibration but also retains additional information useful for\ndownstream tasks such as fusion, prediction, and planning.",
      "tldr_zh": "该论文针对自动驾驶等安全关键应用，提出一种改进 3D LiDAR 语义分割模型的训练策略，通过利用类之间固有的结构相似性来提升模型的鲁棒性和可靠性。方法采用 Hierarchical Multi-Label Classification (HMC) 的学习规则，隐式建模类关系的抽象层次，从而更好地捕捉人类自然理解的类间关联。实验结果显示，该策略显著提高了模型的置信度校准，并保留了额外信息，支持下游任务如融合、预测和规划的优化。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.06124v3",
      "published_date": "2024-04-09 08:49:01 UTC",
      "updated_date": "2024-07-31 07:32:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:02:59.528691"
    },
    {
      "arxiv_id": "2404.06114v1",
      "title": "Communication-Efficient Large-Scale Distributed Deep Learning: A Comprehensive Survey",
      "title_zh": "通信高效的大规模分布式深度学习：全面综述",
      "authors": [
        "Feng Liang",
        "Zhen Zhang",
        "Haifeng Lu",
        "Victor C. M. Leung",
        "Yanyi Guo",
        "Xiping Hu"
      ],
      "abstract": "With the rapid growth in the volume of data sets, models, and devices in the\ndomain of deep learning, there is increasing attention on large-scale\ndistributed deep learning. In contrast to traditional distributed deep\nlearning, the large-scale scenario poses new challenges that include fault\ntolerance, scalability of algorithms and infrastructures, and heterogeneity in\ndata sets, models, and resources. Due to intensive synchronization of models\nand sharing of data across GPUs and computing nodes during distributed training\nand inference processes, communication efficiency becomes the bottleneck for\nachieving high performance at a large scale. This article surveys the\nliterature over the period of 2018-2023 on algorithms and technologies aimed at\nachieving efficient communication in large-scale distributed deep learning at\nvarious levels, including algorithms, frameworks, and infrastructures.\nSpecifically, we first introduce efficient algorithms for model synchronization\nand communication data compression in the context of large-scale distributed\ntraining. Next, we introduce efficient strategies related to resource\nallocation and task scheduling for use in distributed training and inference.\nAfter that, we present the latest technologies pertaining to modern\ncommunication infrastructures used in distributed deep learning with a focus on\nexamining the impact of the communication overhead in a large-scale and\nheterogeneous setting. Finally, we conduct a case study on the distributed\ntraining of large language models at a large scale to illustrate how to apply\nthese technologies in real cases. This article aims to offer researchers a\ncomprehensive understanding of the current landscape of large-scale distributed\ndeep learning and to reveal promising future research directions toward\ncommunication-efficient solutions in this scope.",
      "tldr_zh": "这篇综述论文系统调查了2018-2023年间大规模分布式深度学习中的通信效率问题，针对容错、可伸缩性和异构性挑战，重点探讨了算法、框架和基础设施层面的优化策略。论文详细介绍了高效算法（如模型同步和通信数据压缩）、资源分配与任务调度方法，以及现代通信基础设施如何减少大规模异构环境中的开销。通过一个大型语言模型分布式训练的案例研究，论文展示了这些技术的实际应用，并为未来通信高效解决方案指出了潜在研究方向。",
      "categories": [
        "cs.DC",
        "cs.AI"
      ],
      "primary_category": "cs.DC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.06114v1",
      "published_date": "2024-04-09 08:35:04 UTC",
      "updated_date": "2024-04-09 08:35:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:03:12.208953"
    },
    {
      "arxiv_id": "2404.08687v1",
      "title": "A Survey of Reasoning for Substitution Relationships: Definitions, Methods, and Directions",
      "title_zh": "替代关系的推理综述：定义、方法和方向",
      "authors": [
        "Anxin Yang",
        "Zhijuan Du",
        "Tao Sun"
      ],
      "abstract": "Substitute relationships are fundamental to people's daily lives across\nvarious domains. This study aims to comprehend and predict substitute\nrelationships among products in diverse fields, extensively analyzing the\napplication of machine learning algorithms, natural language processing, and\nother technologies. By comparing model methodologies across different domains,\nsuch as defining substitutes, representing and learning substitute\nrelationships, and substitute reasoning, this study offers a methodological\nfoundation for delving deeper into substitute relationships. Through ongoing\nresearch and innovation, we can further refine the personalization and accuracy\nof substitute recommendation systems, thus advancing the development and\napplication of this field.",
      "tldr_zh": "这篇调查论文探讨了替代关系（substitute relationships）的推理，包括定义、方法和未来方向，旨在理解和预测不同领域（如产品推荐）中的替代关系。论文分析了机器学习（machine learning）、自然语言处理（natural language processing）等技术在定义替代关系、表示与学习这些关系以及进行替代推理方面的应用，并比较了跨领域的模型方法。最终，该研究为深入探索替代关系提供方法论基础，有助于提升替代推荐系统的个性化（personalization）和准确性，推动该领域的创新发展。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.08687v1",
      "published_date": "2024-04-09 08:33:43 UTC",
      "updated_date": "2024-04-09 08:33:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:03:22.887262"
    },
    {
      "arxiv_id": "2404.06090v1",
      "title": "Fair Graph Neural Network with Supervised Contrastive Regularization",
      "title_zh": "翻译失败",
      "authors": [
        "Mahdi Tavassoli Kejani",
        "Fadi Dornaika",
        "Jean-Michel Loubes"
      ],
      "abstract": "In recent years, Graph Neural Networks (GNNs) have made significant\nadvancements, particularly in tasks such as node classification, link\nprediction, and graph representation. However, challenges arise from biases\nthat can be hidden not only in the node attributes but also in the connections\nbetween entities. Therefore, ensuring fairness in graph neural network learning\nhas become a critical problem. To address this issue, we propose a novel model\nfor training fairness-aware GNN, which enhances the Counterfactual Augmented\nFair Graph Neural Network Framework (CAF). Our approach integrates Supervised\nContrastive Loss and Environmental Loss to enhance both accuracy and fairness.\nExperimental validation on three real datasets demonstrates the superiority of\nour proposed model over CAF and several other existing graph-based learning\nmethods.",
      "tldr_zh": "该论文针对Graph Neural Networks (GNNs) 中存在的偏差问题（如节点属性和实体连接中的隐藏偏见），提出了一种新型公平感知训练模型，以改进Counterfactual Augmented Fair Graph Neural Network Framework (CAF)。该模型整合了Supervised Contrastive Loss 和 Environmental Loss，以同时提升GNNs的准确性和公平性。实验在三个真实数据集上验证了该方法的优越性，其性能超过了CAF和其他现有图学习方法。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.06090v1",
      "published_date": "2024-04-09 07:49:05 UTC",
      "updated_date": "2024-04-09 07:49:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:03:34.744087"
    },
    {
      "arxiv_id": "2404.06079v2",
      "title": "The X-LANCE Technical Report for Interspeech 2024 Speech Processing Using Discrete Speech Unit Challenge",
      "title_zh": "翻译失败",
      "authors": [
        "Yiwei Guo",
        "Chenrun Wang",
        "Yifan Yang",
        "Hankun Wang",
        "Ziyang Ma",
        "Chenpeng Du",
        "Shuai Wang",
        "Hanzheng Li",
        "Shuai Fan",
        "Hui Zhang",
        "Xie Chen",
        "Kai Yu"
      ],
      "abstract": "Discrete speech tokens have been more and more popular in multiple speech\nprocessing fields, including automatic speech recognition (ASR), text-to-speech\n(TTS) and singing voice synthesis (SVS). In this paper, we describe the systems\ndeveloped by the SJTU X-LANCE group for the TTS (acoustic + vocoder), SVS, and\nASR tracks in the Interspeech 2024 Speech Processing Using Discrete Speech Unit\nChallenge. Notably, we achieved 1st rank on the leaderboard in the TTS track\nboth with the whole training set and only 1h training data, with the highest\nUTMOS score and lowest bitrate among all submissions.",
      "tldr_zh": "该论文介绍了 SJTU X-LANCE 团队针对 Interspeech 2024 Speech Processing Using Discrete Speech Unit Challenge 开发的系统，这些系统利用 Discrete Speech Units 处理 ASR（自动语音识别）、TTS（文本到语音）和 SVS（歌声合成）任务。团队在 TTS 轨道上取得了显著成绩，使用完整训练集和仅 1 小时数据均排名第一，实现了最高的 UTMOS 得分和最低的比特率。这些结果突显了 Discrete Speech Units 在语音处理领域的潜力，提升了系统的效率和性能。",
      "categories": [
        "eess.AS",
        "cs.AI"
      ],
      "primary_category": "eess.AS",
      "comment": "5 pages, 3 figures. Report of a challenge",
      "pdf_url": "http://arxiv.org/pdf/2404.06079v2",
      "published_date": "2024-04-09 07:37:41 UTC",
      "updated_date": "2024-04-10 00:33:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:03:48.026078"
    },
    {
      "arxiv_id": "2404.06077v1",
      "title": "Is Your AI Truly Yours? Leveraging Blockchain for Copyrights, Provenance, and Lineage",
      "title_zh": "翻译失败",
      "authors": [
        "Yilin Sai",
        "Qin Wang",
        "Guangsheng Yu",
        "H. M. N. Dilum Bandara",
        "Shiping Chen"
      ],
      "abstract": "As Artificial Intelligence (AI) integrates into diverse areas, particularly\nin content generation, ensuring rightful ownership and ethical use becomes\nparamount. AI service providers are expected to prioritize responsibly sourcing\ntraining data and obtaining licenses from data owners. However, existing\nstudies primarily center on safeguarding static copyrights, which simply treats\nmetadata/datasets as non-fungible items with transferable/trading capabilities,\nneglecting the dynamic nature of training procedures that can shape an ongoing\ntrajectory.\n  In this paper, we present \\textsc{IBis}, a blockchain-based framework\ntailored for AI model training workflows. \\textsc{IBis} integrates on-chain\nregistries for datasets, licenses and models, alongside off-chain signing\nservices to facilitate collaboration among multiple participants. Our framework\naddresses concerns regarding data and model provenance and copyright\ncompliance. \\textsc{IBis} enables iterative model retraining and fine-tuning,\nand offers flexible license checks and renewals. Further, \\textsc{IBis}\nprovides APIs designed for seamless integration with existing contract\nmanagement software, minimizing disruptions to established model training\nprocesses. We implement \\textsc{IBis} using Daml on the Canton blockchain.\nEvaluation results showcase the feasibility and scalability of \\textsc{IBis}\nacross varying numbers of users, datasets, models, and licenses.",
      "tldr_zh": "随着人工智能（AI）在内容生成中的应用日益广泛，确保数据所有权、版权合规和道德使用变得至关重要，但现有方法仅关注静态版权，而忽略了训练过程的动态特性。本文提出\\textsc{IBis}，一个基于区块链的框架，用于管理AI模型训练工作流，包括on-chain注册（datasets、licenses和models）以及off-chain signing services，以支持多参与者协作、数据和模型provenance跟踪以及灵活的许可证检查和续期。\\textsc{IBis}通过提供与现有合同管理软件集成的APIs，实现迭代模型retraining和fine-tuning，并使用Daml on the Canton blockchain进行实现。评估结果证明了\\textsc{IBis}的可行性和可扩展性，在不同用户、数据集、模型和许可证场景下表现出色。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.06077v1",
      "published_date": "2024-04-09 07:32:30 UTC",
      "updated_date": "2024-04-09 07:32:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:04:00.709832"
    },
    {
      "arxiv_id": "2404.06063v2",
      "title": "Heuristic-enhanced Candidates Selection strategy for GPTs tackle Few-Shot Aspect-Based Sentiment Analysis",
      "title_zh": "翻译失败",
      "authors": [
        "Baoxing Jiang",
        "Yujie Wan",
        "Shenggen Ju"
      ],
      "abstract": "Few-Shot Aspect-Based Sentiment Analysis (FSABSA) is an indispensable and\nhighly challenging task in natural language processing. However, methods based\non Pre-trained Language Models (PLMs) struggle to accommodate multiple\nsub-tasks, and methods based on Generative Pre-trained Transformers (GPTs)\nperform poorly. To address the above issues, the paper designs a\nHeuristic-enhanced Candidates Selection (HCS) strategy and further proposes All\nin One (AiO) model based on it. The model works in a two-stage, which\nsimultaneously accommodates the accuracy of PLMs and the generalization\ncapability of GPTs. Specifically, in the first stage, a backbone model based on\nPLMs generates rough heuristic candidates for the input sentence. In the second\nstage, AiO leverages LLMs' contextual learning capabilities to generate precise\npredictions. The study conducted comprehensive comparative and ablation\nexperiments on five benchmark datasets. The experimental results demonstrate\nthat the proposed model can better adapt to multiple sub-tasks, and also\noutperforms the methods that directly utilize GPTs.",
      "tldr_zh": "该论文针对 Few-Shot Aspect-Based Sentiment Analysis (FSABSA) 的挑战，提出 Heuristic-enhanced Candidates Selection (HCS) 策略，并基于此构建 All in One (AiO) 模型，以结合 Pre-trained Language Models (PLMs) 的准确性和 Generative Pre-trained Transformers (GPTs) 的泛化能力。AiO 模型采用两阶段方法：第一阶段，使用 PLMs 骨干模型生成粗略的启发式候选项；第二阶段，利用大型语言模型 (LLMs) 的上下文学习能力进行精确预测。在五个基准数据集上的实验结果显示，该模型在适应多个子任务方面表现优异，并优于直接使用 GPTs 的方法。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "9 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2404.06063v2",
      "published_date": "2024-04-09 07:02:14 UTC",
      "updated_date": "2024-08-19 07:50:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:04:14.995879"
    },
    {
      "arxiv_id": "2404.06059v1",
      "title": "Efficient Quantum Circuits for Machine Learning Activation Functions including Constant T-depth ReLU",
      "title_zh": "翻译失败",
      "authors": [
        "Wei Zi",
        "Siyi Wang",
        "Hyunji Kim",
        "Xiaoming Sun",
        "Anupam Chattopadhyay",
        "Patrick Rebentrost"
      ],
      "abstract": "In recent years, Quantum Machine Learning (QML) has increasingly captured the\ninterest of researchers. Among the components in this domain, activation\nfunctions hold a fundamental and indispensable role. Our research focuses on\nthe development of activation functions quantum circuits for integration into\nfault-tolerant quantum computing architectures, with an emphasis on minimizing\n$T$-depth. Specifically, we present novel implementations of ReLU and leaky\nReLU activation functions, achieving constant $T$-depths of 4 and 8,\nrespectively. Leveraging quantum lookup tables, we extend our exploration to\nother activation functions such as the sigmoid. This approach enables us to\ncustomize precision and $T$-depth by adjusting the number of qubits, making our\nresults more adaptable to various application scenarios. This study represents\na significant advancement towards enhancing the practicality and application of\nquantum machine learning.",
      "tldr_zh": "本研究专注于开发高效量子电路，用于机器学习激活函数，以适应容错量子计算架构并最小化 T-depth。具体而言，提出新型 ReLU 和 leaky ReLU 激活函数的实现，分别实现常数 T-depth 为 4 和 8。通过利用量子查找表，扩展到其他函数如 sigmoid，并通过调整量子比特数自定义精度和 T-depth，提高了应用的灵活性。该工作显著提升了 Quantum Machine Learning (QML) 的实用性和可行性。",
      "categories": [
        "quant-ph",
        "cs.AI"
      ],
      "primary_category": "quant-ph",
      "comment": "13 pages",
      "pdf_url": "http://arxiv.org/pdf/2404.06059v1",
      "published_date": "2024-04-09 06:53:12 UTC",
      "updated_date": "2024-04-09 06:53:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:04:23.823535"
    },
    {
      "arxiv_id": "2404.06025v2",
      "title": "Greedy-DiM: Greedy Algorithms for Unreasonably Effective Face Morphs",
      "title_zh": "Greedy-Di",
      "authors": [
        "Zander W. Blasingame",
        "Chen Liu"
      ],
      "abstract": "Morphing attacks are an emerging threat to state-of-the-art Face Recognition\n(FR) systems, which aim to create a single image that contains the biometric\ninformation of multiple identities. Diffusion Morphs (DiM) are a recently\nproposed morphing attack that has achieved state-of-the-art performance for\nrepresentation-based morphing attacks. However, none of the existing research\non DiMs have leveraged the iterative nature of DiMs and left the DiM model as a\nblack box, treating it no differently than one would a Generative Adversarial\nNetwork (GAN) or Varational AutoEncoder (VAE). We propose a greedy strategy on\nthe iterative sampling process of DiM models which searches for an optimal step\nguided by an identity-based heuristic function. We compare our proposed\nalgorithm against ten other state-of-the-art morphing algorithms using the\nopen-source SYN-MAD 2022 competition dataset. We find that our proposed\nalgorithm is unreasonably effective, fooling all of the tested FR systems with\nan MMPMR of 100%, outperforming all other morphing algorithms compared.",
      "tldr_zh": "该研究针对人脸识别（Face Recognition, FR）系统的 Morphing attacks 威胁，提出了一种名为 Greedy-DiM 的贪婪算法（Greedy Algorithms），旨在优化 Diffusion Morphs (DiM) 模型的迭代采样过程。Greedy-DiM 通过基于身份的启发式函数（identity-based heuristic function）引导搜索最优步骤，从而生成更有效的伪造图像。实验结果显示，在 SYN-MAD 2022 数据集上，该算法欺骗了所有测试的 FR 系统，达到了 100% 的 MMPMR 指标，显著优于其他 10 种状态-of-the-art morphing 算法。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted as a conference paper at IJCB 2024",
      "pdf_url": "http://arxiv.org/pdf/2404.06025v2",
      "published_date": "2024-04-09 05:21:32 UTC",
      "updated_date": "2024-07-02 15:48:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:04:36.498941"
    },
    {
      "arxiv_id": "2404.06022v2",
      "title": "Band-Attention Modulated RetNet for Face Forgery Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Zhida Zhang",
        "Jie Cao",
        "Wenkui Yang",
        "Qihang Fan",
        "Kai Zhou",
        "Ran He"
      ],
      "abstract": "The transformer networks are extensively utilized in face forgery detection\ndue to their scalability across large datasets.Despite their success,\ntransformers face challenges in balancing the capture of global context, which\nis crucial for unveiling forgery clues, with computational complexity.To\nmitigate this issue, we introduce Band-Attention modulated RetNet (BAR-Net), a\nlightweight network designed to efficiently process extensive visual contexts\nwhile avoiding catastrophic forgetting.Our approach empowers the target token\nto perceive global information by assigning differential attention levels to\ntokens at varying distances. We implement self-attention along both spatial\naxes, thereby maintaining spatial priors and easing the computational\nburden.Moreover, we present the adaptive frequency Band-Attention Modulation\nmechanism, which treats the entire Discrete Cosine Transform spectrogram as a\nseries of frequency bands with learnable weights.Together, BAR-Net achieves\nfavorable performance on several face forgery datasets, outperforming current\nstate-of-the-art methods.",
      "tldr_zh": "该研究针对Transformer网络在面部伪造检测中捕获全局上下文与计算复杂度平衡的挑战，提出了一种轻量级模型Band-Attention modulated RetNet (BAR-Net)。BAR-Net通过为不同距离的标记分配差异化注意力水平，并在空间轴上实现自注意力，实现了高效处理视觉上下文并保持空间先验，同时避免灾难性遗忘。论文还引入自适应频率Band-Attention Modulation机制，将整个Discrete Cosine Transform (DCT)谱图视为可学习权重的频率带，最终在多个面部伪造数据集上表现出色，超越了当前最先进方法。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.MM"
      ],
      "primary_category": "cs.CV",
      "comment": "The essay is poorly expressed in writing and will be re-optimised",
      "pdf_url": "http://arxiv.org/pdf/2404.06022v2",
      "published_date": "2024-04-09 05:11:28 UTC",
      "updated_date": "2024-07-02 01:19:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:04:49.655808"
    },
    {
      "arxiv_id": "2404.06014v1",
      "title": "Using 3-Objective Evolutionary Algorithms for the Dynamic Chance Constrained Knapsack Problem",
      "title_zh": "使用三目标进化算法解决动态机会约束背包问题",
      "authors": [
        "Ishara Hewa Pathiranage",
        "Frank Neumann",
        "Denis Antipov",
        "Aneta Neumann"
      ],
      "abstract": "Real-world optimization problems often involve stochastic and dynamic\ncomponents. Evolutionary algorithms are particularly effective in these\nscenarios, as they can easily adapt to uncertain and changing environments but\noften uncertainty and dynamic changes are studied in isolation. In this paper,\nwe explore the use of 3-objective evolutionary algorithms for the chance\nconstrained knapsack problem with dynamic constraints. In our setting, the\nweights of the items are stochastic and the knapsack's capacity changes over\ntime. We introduce a 3-objective formulation that is able to deal with the\nstochastic and dynamic components at the same time and is independent of the\nconfidence level required for the constraint. This new approach is then\ncompared to the 2-objective formulation which is limited to a single confidence\nlevel. We evaluate the approach using two different multi-objective\nevolutionary algorithms (MOEAs), namely the global simple evolutionary\nmulti-objective optimizer (GSEMO) and the multi-objective evolutionary\nalgorithm based on decomposition (MOEA/D), across various benchmark scenarios.\nOur analysis highlights the advantages of the 3-objective formulation over the\n2-objective formulation in addressing the dynamic chance constrained knapsack\nproblem.",
      "tldr_zh": "该研究探讨了使用 3-Objective Evolutionary Algorithms 来解决动态机会约束背包问题（Dynamic Chance Constrained Knapsack Problem），其中物品权重为随机变量且背包容量随时间变化。论文引入了一个 3-目标公式，能够同时处理随机性和动态组件，并独立于置信水平，与传统的 2-目标公式相比具有更大灵活性。实验通过 GSEMO 和 MOEA/D 算法在各种基准场景中进行评估，结果显示 3-目标方法在处理该问题时显著优于 2-目标方法。",
      "categories": [
        "cs.NE",
        "cs.AI"
      ],
      "primary_category": "cs.NE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.06014v1",
      "published_date": "2024-04-09 04:47:01 UTC",
      "updated_date": "2024-04-09 04:47:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:05:03.241304"
    },
    {
      "arxiv_id": "2404.06007v1",
      "title": "Collaborative Edge AI Inference over Cloud-RAN",
      "title_zh": "基于 Cloud-RAN 的协作边缘 AI 推理",
      "authors": [
        "Pengfei Zhang",
        "Dingzhu Wen",
        "Guangxu Zhu",
        "Qimei Chen",
        "Kaifeng Han",
        "Yuanming Shi"
      ],
      "abstract": "In this paper, a cloud radio access network (Cloud-RAN) based collaborative\nedge AI inference architecture is proposed. Specifically, geographically\ndistributed devices capture real-time noise-corrupted sensory data samples and\nextract the noisy local feature vectors, which are then aggregated at each\nremote radio head (RRH) to suppress sensing noise. To realize efficient uplink\nfeature aggregation, we allow each RRH receives local feature vectors from all\ndevices over the same resource blocks simultaneously by leveraging an\nover-the-air computation (AirComp) technique. Thereafter, these aggregated\nfeature vectors are quantized and transmitted to a central processor (CP) for\nfurther aggregation and downstream inference tasks. Our aim in this work is to\nmaximize the inference accuracy via a surrogate accuracy metric called\ndiscriminant gain, which measures the discernibility of different classes in\nthe feature space. The key challenges lie on simultaneously suppressing the\ncoupled sensing noise, AirComp distortion caused by hostile wireless channels,\nand the quantization error resulting from the limited capacity of fronthaul\nlinks. To address these challenges, this work proposes a joint transmit\nprecoding, receive beamforming, and quantization error control scheme to\nenhance the inference accuracy. Extensive numerical experiments demonstrate the\neffectiveness and superiority of our proposed optimization algorithm compared\nto various baselines.",
      "tldr_zh": "本研究提出了一种基于 Cloud-RAN 的协作边缘 AI 推理架构，用于处理地理分布设备捕获的噪声污染传感器数据。系统通过在远程无线电头 (RRH) 处聚合本地特征向量，并利用过空计算 (AirComp) 技术同时接收数据，以抑制感知噪声和无线通道失真；随后，量化后的特征向量传输至中央处理器 (CP) 进行进一步处理。目标是最大化推理准确性，通过代理指标 discriminant gain 优化特征空间的可辨别性，并设计联合发射预编码、接收波束成形和量化错误控制方案来应对相关挑战。实验结果显示，该优化算法在推理性能上优于多种基线方案，证明了其有效性。",
      "categories": [
        "cs.IT",
        "cs.AI",
        "cs.LG",
        "eess.SP",
        "math.IT"
      ],
      "primary_category": "cs.IT",
      "comment": "This paper is accepted by IEEE Transactions on Communications on\n  08-Apr-2024",
      "pdf_url": "http://arxiv.org/pdf/2404.06007v1",
      "published_date": "2024-04-09 04:26:16 UTC",
      "updated_date": "2024-04-09 04:26:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:05:15.370893"
    },
    {
      "arxiv_id": "2404.06003v1",
      "title": "FreeEval: A Modular Framework for Trustworthy and Efficient Evaluation of Large Language Models",
      "title_zh": "FreeEval：一个模块化框架，用于可信且高效的大语言模型评估",
      "authors": [
        "Zhuohao Yu",
        "Chang Gao",
        "Wenjin Yao",
        "Yidong Wang",
        "Zhengran Zeng",
        "Wei Ye",
        "Jindong Wang",
        "Yue Zhang",
        "Shikun Zhang"
      ],
      "abstract": "The rapid development of large language model (LLM) evaluation methodologies\nand datasets has led to a profound challenge: integrating state-of-the-art\nevaluation techniques cost-effectively while ensuring reliability,\nreproducibility, and efficiency. Currently, there is a notable absence of a\nunified and adaptable framework that seamlessly integrates various evaluation\napproaches. Moreover, the reliability of evaluation findings is often\nquestionable due to potential data contamination, with the evaluation\nefficiency commonly overlooked when facing the substantial costs associated\nwith LLM inference. In response to these challenges, we introduce FreeEval, a\nmodular and scalable framework crafted to enable trustworthy and efficient\nautomatic evaluations of LLMs. Firstly, FreeEval's unified abstractions\nsimplify the integration and improve the transparency of diverse evaluation\nmethodologies, encompassing dynamic evaluation that demand sophisticated LLM\ninteractions. Secondly, the framework integrates meta-evaluation techniques\nlike human evaluation and data contamination detection, which, along with\ndynamic evaluation modules in the platform, enhance the fairness of the\nevaluation outcomes. Lastly, FreeEval is designed with a high-performance\ninfrastructure, including distributed computation and caching strategies,\nenabling extensive evaluations across multi-node, multi-GPU clusters for\nopen-source and proprietary LLMs.",
      "tldr_zh": "该研究提出 FreeEval，一种模块化和可扩展的框架，旨在解决大型语言模型 (LLMs) 评估中的可靠性、重复性和效率挑战，包括数据污染和高成本问题。FreeEval 通过统一的抽象简化多种评估方法的集成，支持动态评估和元评估技术（如人工评估和数据污染检测），从而提升评估结果的公平性。该框架还采用高性能基础设施，如分布式计算和缓存策略，支持多节点多 GPU 集群，适用于开源和专有 LLMs 的全面评估。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "We open-source all our code at:\n  https://github.com/WisdomShell/FreeEval",
      "pdf_url": "http://arxiv.org/pdf/2404.06003v1",
      "published_date": "2024-04-09 04:17:51 UTC",
      "updated_date": "2024-04-09 04:17:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:05:26.520197"
    },
    {
      "arxiv_id": "2404.05990v1",
      "title": "Automatic Authorities: Power and AI",
      "title_zh": "自动权威：权力与 AI",
      "authors": [
        "Seth Lazar"
      ],
      "abstract": "As rapid advances in Artificial Intelligence and the rise of some of\nhistory's most potent corporations meet the diminished neoliberal state, people\nare increasingly subject to power exercised by means of automated systems.\nMachine learning and related computational technologies now underpin vital\ngovernment services. They connect consumers and producers in new algorithmic\nmarkets. They determine how we find out about everything from how to vote to\nwhere to get vaccinated, and whose speech is amplified, reduced, or restricted.\nAnd a new wave of products based on Large Language Models (LLMs) will further\ntransform our economic and political lives. Automatic Authorities are automated\ncomputational systems used to exercise power over us by determining what we may\nknow, what we may have, and what our options will be. In response to their\nrise, scholars working on the societal impacts of AI and related technologies\nhave advocated shifting attention from how to make AI systems beneficial or\nfair towards a critical analysis of these new power relations. But power is\neverywhere, and is not necessarily bad. On what basis should we object to new\nor intensified power relations, and what can be done to justify them? This\npaper introduces the philosophical materials with which to formulate these\nquestions, and offers preliminary answers. It starts by pinning down the\nconcept of power, focusing on the ability that some agents have to shape\nothers' lives. It then explores how AI enables and intensifies the exercise of\npower so understood, and sketches three problems with power and three ways to\nsolve those problems. It emphasises, in particular, that justifying power\nrequires more than satisfying substantive justificatory criteria; standards of\nproper authority and procedural legitimacy must also be met. We need to know\nnot only what power may be used for, but how it may be used, and by whom.",
      "tldr_zh": "这篇论文探讨了人工智能（AI）如何通过 Automatic Authorities（自动化权威系统）强化权力，影响人们在政府服务、算法市场和信息传播中的生活，例如决定我们可知的信息、可拥有的资源和选项。作者分析了 AI 技术（如 machine learning 和 Large Language Models, LLMs）如何启用和加剧这些权力关系，并提出了权力的三个核心问题及其解决方案，包括满足实质性标准、适当权威和程序合法性。最终，论文强调，需要不仅审视权力的用途，还需考量其行使方式和主体，以为 AI 社会影响的批判性分析提供哲学基础。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.05990v1",
      "published_date": "2024-04-09 03:48:42 UTC",
      "updated_date": "2024-04-09 03:48:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:05:39.532072"
    },
    {
      "arxiv_id": "2404.06524v1",
      "title": "An Enhanced Grey Wolf Optimizer with Elite Inheritance and Balance Search Mechanisms",
      "title_zh": "翻译失败",
      "authors": [
        "Jianhua Jiang",
        "Ziying Zhao",
        "Weihua Li",
        "Keqin Li"
      ],
      "abstract": "The Grey Wolf Optimizer (GWO) is recognized as a novel meta-heuristic\nalgorithm inspired by the social leadership hierarchy and hunting mechanism of\ngrey wolves. It is well-known for its simple parameter setting, fast\nconvergence speed, and strong optimization capability. In the original GWO,\nthere are two significant design flaws in its fundamental optimization\nmechanisms. Problem (1): the algorithm fails to inherit from elite positions\nfrom the last iteration when generating the next positions of the wolf\npopulation, potentially leading to suboptimal solutions. Problem (2): the\npositions of the population are updated based on the central position of the\nthree leading wolves (alpha, beta, delta), without a balanced mechanism between\nlocal and global search. To tackle these problems, an enhanced Grey Wolf\nOptimizer with Elite Inheritance Mechanism and Balance Search Mechanism, named\nas EBGWO, is proposed to improve the effectiveness of the position updating and\nthe quality of the convergence solutions. The IEEE CEC 2014 benchmark functions\nsuite and a series of simulation tests are employed to evaluate the performance\nof the proposed algorithm. The simulation tests involve a comparative study\nbetween EBGWO, three GWO variants, GWO and two well-known meta-heuristic\nalgorithms. The experimental results demonstrate that the proposed EBGWO\nalgorithm outperforms other meta-heuristic algorithms in both accuracy and\nconvergence speed. Three engineering optimization problems are adopted to prove\nits capability in processing real-world problems. The results indicate that the\nproposed EBGWO outperforms several popular algorithms.",
      "tldr_zh": "本研究针对 Grey Wolf Optimizer (GWO) 算法的两个主要缺陷——未能从上一迭代的精英位置继承以及缺乏局部和全局搜索的平衡机制——提出了一种增强版算法 EBGWO。EBGWO 引入精英继承机制和平衡搜索机制，以优化狼群位置更新过程，提高收敛解决方案的质量和有效性。通过 IEEE CEC 2014 基准函数和模拟测试，EBGWO 与其他 GWO 变体以及知名元启发式算法相比，在准确性和收敛速度上表现出显著优势。该算法在三个工程优化问题上的应用进一步证明了其在处理实际问题的优越性能。",
      "categories": [
        "cs.NE",
        "cs.AI"
      ],
      "primary_category": "cs.NE",
      "comment": "51 pages, 21 tables, 16 figures, journal",
      "pdf_url": "http://arxiv.org/pdf/2404.06524v1",
      "published_date": "2024-04-09 03:28:00 UTC",
      "updated_date": "2024-04-09 03:28:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:05:51.248916"
    },
    {
      "arxiv_id": "2404.05980v5",
      "title": "Tackling Structural Hallucination in Image Translation with Local Diffusion",
      "title_zh": "翻译失败",
      "authors": [
        "Seunghoi Kim",
        "Chen Jin",
        "Tom Diethe",
        "Matteo Figini",
        "Henry F. J. Tregidgo",
        "Asher Mullokandov",
        "Philip Teare",
        "Daniel C. Alexander"
      ],
      "abstract": "Recent developments in diffusion models have advanced conditioned image\ngeneration, yet they struggle with reconstructing out-of-distribution (OOD)\nimages, such as unseen tumors in medical images, causing \"image hallucination\"\nand risking misdiagnosis. We hypothesize such hallucinations result from local\nOOD regions in the conditional images. We verify that partitioning the OOD\nregion and conducting separate image generations alleviates hallucinations in\nseveral applications. From this, we propose a training-free diffusion framework\nthat reduces hallucination with multiple Local Diffusion processes. Our\napproach involves OOD estimation followed by two modules: a \"branching\" module\ngenerates locally both within and outside OOD regions, and a \"fusion\" module\nintegrates these predictions into one. Our evaluation shows our method\nmitigates hallucination over baseline models quantitatively and qualitatively,\nreducing misdiagnosis by 40% and 25% in the real-world medical and natural\nimage datasets, respectively. It also demonstrates compatibility with various\npre-trained diffusion models.",
      "tldr_zh": "这项研究针对扩散模型在图像翻译中重建分布外（OOD）图像时产生的结构幻觉问题（如医疗图像中的未见肿瘤），提出了一种无训练的框架，利用 Local Diffusion 进程来缓解这一问题。该框架包括 OOD 估计、分支模块（在 OOD 区域内外进行本地生成）和融合模块（整合预测结果），从而减少幻觉并提升图像准确性。实验评估显示，该方法在医疗和自然图像数据集上分别降低了40%和25%的误诊率，并在定量和定性方面优于基线模型，同时兼容各种预训练扩散模型。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.05980v5",
      "published_date": "2024-04-09 03:24:10 UTC",
      "updated_date": "2024-07-17 06:07:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:06:04.785582"
    },
    {
      "arxiv_id": "2404.05971v1",
      "title": "Does Transformer Interpretability Transfer to RNNs?",
      "title_zh": "翻译失败",
      "authors": [
        "Gonçalo Paulo",
        "Thomas Marshall",
        "Nora Belrose"
      ],
      "abstract": "Recent advances in recurrent neural network architectures, such as Mamba and\nRWKV, have enabled RNNs to match or exceed the performance of equal-size\ntransformers in terms of language modeling perplexity and downstream\nevaluations, suggesting that future systems may be built on completely new\narchitectures. In this paper, we examine if selected interpretability methods\noriginally designed for transformer language models will transfer to these\nup-and-coming recurrent architectures. Specifically, we focus on steering model\noutputs via contrastive activation addition, on eliciting latent predictions\nvia the tuned lens, and eliciting latent knowledge from models fine-tuned to\nproduce false outputs under certain conditions. Our results show that most of\nthese techniques are effective when applied to RNNs, and we show that it is\npossible to improve some of them by taking advantage of RNNs' compressed state.",
      "tldr_zh": "本论文探讨了 Transformer 模型的可解释性方法是否能转移到新兴 RNN 架构（如 Mamba 和 RWKV），这些 RNN 在语言建模困惑度和下游评估中已能匹敌或超过同等大小的 Transformer。研究重点测试了 contrastive activation addition 用于引导模型输出、tuned lens 用于提取潜在预测，以及从特定条件下产生虚假输出的微调模型中提取潜在知识等技术。结果表明，这些方法在 RNN 上大多有效，且可以通过利用 RNN 的压缩状态来进一步改进，从而为 RNN 模型的可解释性提供了新见解。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.05971v1",
      "published_date": "2024-04-09 02:59:17 UTC",
      "updated_date": "2024-04-09 02:59:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:06:15.552680"
    },
    {
      "arxiv_id": "2404.05967v1",
      "title": "JSTR: Judgment Improves Scene Text Recognition",
      "title_zh": "翻译失败",
      "authors": [
        "Masato Fujitake"
      ],
      "abstract": "In this paper, we present a method for enhancing the accuracy of scene text\nrecognition tasks by judging whether the image and text match each other. While\nprevious studies focused on generating the recognition results from input\nimages, our approach also considers the model's misrecognition results to\nunderstand its error tendencies, thus improving the text recognition pipeline.\nThis method boosts text recognition accuracy by providing explicit feedback on\nthe data that the model is likely to misrecognize by predicting correct or\nincorrect between the image and text. The experimental results on publicly\navailable datasets demonstrate that our proposed method outperforms the\nbaseline and state-of-the-art methods in scene text recognition.",
      "tldr_zh": "这篇论文提出了JSTR方法，通过判断图像和文本是否匹配来提升场景文本识别的准确性。不同于以往仅关注生成识别结果的做法，JSTR还分析模型的误识别倾向，提供反馈预测图像与文本的正确性，从而优化文本识别流程。实验结果表明，该方法在公开数据集上优于基线和最先进方法，显著提高了识别性能。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "IntelliSys 2024",
      "pdf_url": "http://arxiv.org/pdf/2404.05967v1",
      "published_date": "2024-04-09 02:55:12 UTC",
      "updated_date": "2024-04-09 02:55:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:06:26.041990"
    },
    {
      "arxiv_id": "2404.05966v2",
      "title": "THOUGHTSCULPT: Reasoning with Intermediate Revision and Search",
      "title_zh": "THOUGHTSCULPT：通过中间修订和搜索进行推理",
      "authors": [
        "Yizhou Chi",
        "Kevin Yang",
        "Dan Klein"
      ],
      "abstract": "We present THOUGHTSCULPT, a general reasoning and search method for tasks\nwith outputs that can be decomposed into components. THOUGHTSCULPT explores a\nsearch tree of potential solutions using Monte Carlo Tree Search (MCTS),\nbuilding solutions one action at a time and evaluating according to any\ndomain-specific heuristic, which in practice is often simply an LLM evaluator.\nCritically, our action space includes revision actions: THOUGHTSCULPT may\nchoose to revise part of its previous output rather than continuing to build\nthe rest of its output. Empirically, THOUGHTSCULPT outperforms state-of-the-art\nreasoning methods across three challenging tasks: Story Outline Improvement (up\nto +30% interestingness), Mini-Crosswords Solving (up to +16% word success\nrate), and Constrained Generation (up to +10% concept coverage).",
      "tldr_zh": "本研究提出了一种通用推理和搜索方法THOUGHTSCULPT，针对输出可分解成组件的任务，通过Monte Carlo Tree Search (MCTS)探索潜在解决方案，一次构建一个动作，并允许中间修订动作来优化先前输出。方法的关键在于结合领域特定启发式评估（如LLM评估器），使系统能够灵活调整和改进生成过程。在实验中，THOUGHTSCULPT在三个挑战任务上超越了最先进方法，包括故事大纲改进（提高多达30%有趣度）、迷你填字游戏解决（提高多达16%单词成功率）和约束生成（提高多达10%概念覆盖率）。这为更高效的推理系统提供了新框架。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to NAACL 2025 Findings. Code and data available at\n  https://github.com/cyzus/thoughtsculpt",
      "pdf_url": "http://arxiv.org/pdf/2404.05966v2",
      "published_date": "2024-04-09 02:53:14 UTC",
      "updated_date": "2025-02-15 03:57:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:06:39.494190"
    },
    {
      "arxiv_id": "2404.05961v2",
      "title": "LLM2Vec: Large Language Models Are Secretly Powerful Text Encoders",
      "title_zh": "翻译失败",
      "authors": [
        "Parishad BehnamGhader",
        "Vaibhav Adlakha",
        "Marius Mosbach",
        "Dzmitry Bahdanau",
        "Nicolas Chapados",
        "Siva Reddy"
      ],
      "abstract": "Large decoder-only language models (LLMs) are the state-of-the-art models on\nmost of today's NLP tasks and benchmarks. Yet, the community is only slowly\nadopting these models for text embedding tasks, which require rich\ncontextualized representations. In this work, we introduce LLM2Vec, a simple\nunsupervised approach that can transform any decoder-only LLM into a strong\ntext encoder. LLM2Vec consists of three simple steps: 1) enabling bidirectional\nattention, 2) masked next token prediction, and 3) unsupervised contrastive\nlearning. We demonstrate the effectiveness of LLM2Vec by applying it to 4\npopular LLMs ranging from 1.3B to 8B parameters and evaluate the transformed\nmodels on English word- and sequence-level tasks. We outperform encoder-only\nmodels by a large margin on word-level tasks and reach a new unsupervised\nstate-of-the-art performance on the Massive Text Embeddings Benchmark (MTEB).\nMoreover, when combining LLM2Vec with supervised contrastive learning, we\nachieve state-of-the-art performance on MTEB among models that train only on\npublicly available data (as of May 24, 2024). Our strong empirical results and\nextensive analysis demonstrate that LLMs can be effectively transformed into\nuniversal text encoders in a parameter-efficient manner without the need for\nexpensive adaptation or synthetic GPT-4 generated data.",
      "tldr_zh": "该研究提出LLM2Vec，一种简单无监督方法，将大型解码器-only语言模型（LLMs）转化为强大的文本编码器。方法包括三个关键步骤：启用bidirectional attention、masked next token prediction以及unsupervised contrastive learning。通过在4个LLM上应用（参数从1.3B到8B），LLM2Vec在英文单词级任务上大幅超越编码器-only模型，并在Massive Text Embeddings Benchmark (MTEB)上达到新的无监督最先进性能；当结合监督对比学习时，仅使用公开数据即实现MTEB的最先进结果。该框架证明LLMs可以通过参数高效的方式转化为通用文本编码器，无需昂贵的适应或合成数据。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to COLM 2024",
      "pdf_url": "http://arxiv.org/pdf/2404.05961v2",
      "published_date": "2024-04-09 02:51:05 UTC",
      "updated_date": "2024-08-21 22:46:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:06:51.337961"
    },
    {
      "arxiv_id": "2404.05959v2",
      "title": "Map Optical Properties to Subwavelength Structures Directly via a Diffusion Model",
      "title_zh": "翻译失败",
      "authors": [
        "Shijie Rao",
        "Kaiyu Cui",
        "Yidong Huang",
        "Jiawei Yang",
        "Yali Li",
        "Shengjin Wang",
        "Xue Feng",
        "Fang Liu",
        "Wei Zhang"
      ],
      "abstract": "Subwavelength photonic structures and metamaterials provide revolutionary\napproaches for controlling light. The inverse design methods proposed for these\nsubwavelength structures are vital to the development of new photonic devices.\nHowever, most of the existing inverse design methods cannot realize direct\nmapping from optical properties to photonic structures but instead rely on\nforward simulation methods to perform iterative optimization. In this work, we\nexploit the powerful generative abilities of artificial intelligence (AI) and\npropose a practical inverse design method based on latent diffusion models. Our\nmethod maps directly the optical properties to structures without the\nrequirement of forward simulation and iterative optimization. Here, the given\noptical properties can work as \"prompts\" and guide the constructed model to\ncorrectly \"draw\" the required photonic structures. Experiments show that our\ndirect mapping-based inverse design method can generate subwavelength photonic\nstructures at high fidelity while following the given optical properties. This\nmay change the method used for optical design and greatly accelerate the\nresearch on new photonic devices.",
      "tldr_zh": "本文提出了一种基于latent diffusion models的直接反向设计方法，能够将光学属性直接映射到子波长 structures，而无需依赖正向模拟和迭代优化。  \n在该方法中，光学属性作为“prompts”引导模型生成高保真度的 photonic structures，确保生成的结构符合指定属性。  \n实验证明，这种方法显著提高了设计效率，并有望改变光学设计流程，加速新 photonic devices 的研究开发。",
      "categories": [
        "physics.optics",
        "cs.AI"
      ],
      "primary_category": "physics.optics",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.05959v2",
      "published_date": "2024-04-09 02:45:39 UTC",
      "updated_date": "2024-12-11 01:17:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:07:04.256989"
    },
    {
      "arxiv_id": "2404.05955v1",
      "title": "VisualWebBench: How Far Have Multimodal LLMs Evolved in Web Page Understanding and Grounding?",
      "title_zh": "翻译失败",
      "authors": [
        "Junpeng Liu",
        "Yifan Song",
        "Bill Yuchen Lin",
        "Wai Lam",
        "Graham Neubig",
        "Yuanzhi Li",
        "Xiang Yue"
      ],
      "abstract": "Multimodal Large Language models (MLLMs) have shown promise in web-related\ntasks, but evaluating their performance in the web domain remains a challenge\ndue to the lack of comprehensive benchmarks. Existing benchmarks are either\ndesigned for general multimodal tasks, failing to capture the unique\ncharacteristics of web pages, or focus on end-to-end web agent tasks, unable to\nmeasure fine-grained abilities such as OCR, understanding, and grounding. In\nthis paper, we introduce \\bench{}, a multimodal benchmark designed to assess\nthe capabilities of MLLMs across a variety of web tasks. \\bench{} consists of\nseven tasks, and comprises 1.5K human-curated instances from 139 real websites,\ncovering 87 sub-domains. We evaluate 14 open-source MLLMs, Gemini Pro, Claude-3\nseries, and GPT-4V(ision) on \\bench{}, revealing significant challenges and\nperformance gaps. Further analysis highlights the limitations of current MLLMs,\nincluding inadequate grounding in text-rich environments and subpar performance\nwith low-resolution image inputs. We believe \\bench{} will serve as a valuable\nresource for the research community and contribute to the creation of more\npowerful and versatile MLLMs for web-related applications.",
      "tldr_zh": "该研究引入了VisualWebBench，一个专门评估多模态大语言模型(MLLMs)在网页理解和grounding方面的基准，以解决现有基准无法捕捉网页独特特性和细粒度能力（如OCR和理解）的局限。VisualWebBench包含七个任务、1.5K个来自139个真实网站和87个子域的人类编制的实例。评估结果显示，14个开源MLLMs、Gemini Pro、Claude-3系列和GPT-4V在该基准上存在显著性能差距，特别是grounding在文本丰富环境中的不足以及低分辨率图像输入的表现不佳。该基准有望成为研究社区的宝贵资源，推动更强大、多功能的MLLMs在网页应用中的发展。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.05955v1",
      "published_date": "2024-04-09 02:29:39 UTC",
      "updated_date": "2024-04-09 02:29:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:07:18.634131"
    },
    {
      "arxiv_id": "2404.05950v1",
      "title": "Efficient Multi-Task Reinforcement Learning via Task-Specific Action Correction",
      "title_zh": "翻译失败",
      "authors": [
        "Jinyuan Feng",
        "Min Chen",
        "Zhiqiang Pu",
        "Tenghai Qiu",
        "Jianqiang Yi"
      ],
      "abstract": "Multi-task reinforcement learning (MTRL) demonstrate potential for enhancing\nthe generalization of a robot, enabling it to perform multiple tasks\nconcurrently. However, the performance of MTRL may still be susceptible to\nconflicts between tasks and negative interference. To facilitate efficient\nMTRL, we propose Task-Specific Action Correction (TSAC), a general and\ncomplementary approach designed for simultaneous learning of multiple tasks.\nTSAC decomposes policy learning into two separate policies: a shared policy\n(SP) and an action correction policy (ACP). To alleviate conflicts resulting\nfrom excessive focus on specific tasks' details in SP, ACP incorporates\ngoal-oriented sparse rewards, enabling an agent to adopt a long-term\nperspective and achieve generalization across tasks. Additional rewards\ntransform the original problem into a multi-objective MTRL problem.\nFurthermore, to convert the multi-objective MTRL into a single-objective\nformulation, TSAC assigns a virtual expected budget to the sparse rewards and\nemploys Lagrangian method to transform a constrained single-objective\noptimization into an unconstrained one. Experimental evaluations conducted on\nMeta-World's MT10 and MT50 benchmarks demonstrate that TSAC outperforms\nexisting state-of-the-art methods, achieving significant improvements in both\nsample efficiency and effective action execution.",
      "tldr_zh": "这篇论文针对多任务强化学习 (MTRL) 中的任务冲突和负面干扰问题，提出了一种高效方法Task-Specific Action Correction (TSAC)，将策略学习分解为共享策略 (SP) 和动作修正策略 (ACP)。ACP 通过引入目标导向的稀疏奖励和拉格朗日方法，将多目标优化转化为单目标形式，从而提升代理的长期泛化和样本效率。在 Meta-World 的 MT10 和 MT50 基准测试中，TSAC 比现有最先进方法在样本效率和有效动作执行方面实现了显著改进。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.05950v1",
      "published_date": "2024-04-09 02:11:35 UTC",
      "updated_date": "2024-04-09 02:11:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:07:29.513753"
    },
    {
      "arxiv_id": "2404.05943v1",
      "title": "Interplay of Machine Translation, Diacritics, and Diacritization",
      "title_zh": "机器翻译、变音符号与标音化的相互作用",
      "authors": [
        "Wei-Rui Chen",
        "Ife Adebara",
        "Muhammad Abdul-Mageed"
      ],
      "abstract": "We investigate two research questions: (1) how do machine translation (MT)\nand diacritization influence the performance of each other in a multi-task\nlearning setting (2) the effect of keeping (vs. removing) diacritics on MT\nperformance. We examine these two questions in both high-resource (HR) and\nlow-resource (LR) settings across 55 different languages (36 African languages\nand 19 European languages). For (1), results show that diacritization\nsignificantly benefits MT in the LR scenario, doubling or even tripling\nperformance for some languages, but harms MT in the HR scenario. We find that\nMT harms diacritization in LR but benefits significantly in HR for some\nlanguages. For (2), MT performance is similar regardless of diacritics being\nkept or removed. In addition, we propose two classes of metrics to measure the\ncomplexity of a diacritical system, finding these metrics to correlate\npositively with the performance of our diacritization models. Overall, our work\nprovides insights for developing MT and diacritization systems under different\ndata size conditions and may have implications that generalize beyond the 55\nlanguages we investigate.",
      "tldr_zh": "本研究探讨了机器翻译(MT)和加标点(diacritization)之间的相互影响，具体考察了在多任务学习设置下，二者如何在高资源(HR)和低资源(LR)场景中影响彼此的表现，以及保留或移除加标点对MT性能的影响。结果显示，在LR场景中，加标点可显著提升MT性能（如某些语言翻倍或三倍），但在HR场景中则会损害MT；反之，MT在LR中会削弱加标点，但在HR中对某些语言有益，且MT性能与加标点是否保留相似。该研究还提出两种度量加标点系统复杂性的指标，这些指标与加标点模型性能正相关，并为在不同数据规模下开发MT和加标点系统提供了宝贵见解，可能适用于超出55种语言的更广泛场景。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to NAACL 2024 Main Conference",
      "pdf_url": "http://arxiv.org/pdf/2404.05943v1",
      "published_date": "2024-04-09 01:55:05 UTC",
      "updated_date": "2024-04-09 01:55:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:07:42.681769"
    },
    {
      "arxiv_id": "2404.05920v1",
      "title": "Inclusive Practices for Child-Centered AI Design and Testing",
      "title_zh": "以儿童为中心的 AI 设计和测试的包容性实践",
      "authors": [
        "Emani Dotch",
        "Vitica Arnold"
      ],
      "abstract": "We explore ideas and inclusive practices for designing and testing\nchild-centered artificially intelligent technologies for neurodivergent\nchildren. AI is promising for supporting social communication, self-regulation,\nand sensory processing challenges common for neurodivergent children. The\nauthors, both neurodivergent individuals and related to neurodivergent people,\ndraw from their professional and personal experiences to offer insights on\ncreating AI technologies that are accessible and include input from\nneurodivergent children. We offer ideas for designing AI technologies for\nneurodivergent children and considerations for including them in the design\nprocess while accounting for their sensory sensitivities. We conclude by\nemphasizing the importance of adaptable and supportive AI technologies and\ndesign processes and call for further conversation to refine child-centered AI\ndesign and testing methods.",
      "tldr_zh": "本论文探讨了为神经多样性(neurodivergent)儿童设计和测试以孩子为中心的AI技术的包容性实践，旨在通过AI支持这些儿童在社会沟通、自律和感官处理方面的挑战。作者作为神经多样性个体或相关人士，基于自身专业和个人经验，提供设计建议，包括确保AI的可访问性、融入儿童输入以及处理感官敏感性。论文强调开发适应性和支持性的AI技术的重要性，并呼吁进一步对话以改进孩子为中心的AI设计和测试方法。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "CHI 2024 Workshop on Child-centred AI Design, May 11, 2024, Honolulu,\n  HI, USA",
      "pdf_url": "http://arxiv.org/pdf/2404.05920v1",
      "published_date": "2024-04-09 00:51:24 UTC",
      "updated_date": "2024-04-09 00:51:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:07:52.878782"
    },
    {
      "arxiv_id": "2404.05913v1",
      "title": "Deep Reinforcement Learning for Personalized Diagnostic Decision Pathways Using Electronic Health Records: A Comparative Study on Anemia and Systemic Lupus Erythematosus",
      "title_zh": "翻译失败",
      "authors": [
        "Lillian Muyama",
        "Antoine Neuraz",
        "Adrien Coulet"
      ],
      "abstract": "Background: Clinical diagnosis is typically reached by following a series of\nsteps recommended by guidelines authored by colleges of experts. Accordingly,\nguidelines play a crucial role in rationalizing clinical decisions but suffer\nfrom limitations as they are built to cover the majority of the population and\nfail at covering patients with uncommon conditions. Moreover, their updates are\nlong and expensive, making them unsuitable for emerging diseases and practices.\n  Methods: Inspired by guidelines, we formulate the task of diagnosis as a\nsequential decision-making problem and study the use of Deep Reinforcement\nLearning (DRL) algorithms to learn the optimal sequence of actions to perform\nin order to obtain a correct diagnosis from Electronic Health Records (EHRs).\nWe apply DRL on synthetic, but realistic EHRs and develop two clinical use\ncases: Anemia diagnosis, where the decision pathways follow the schema of a\ndecision tree; and Systemic Lupus Erythematosus (SLE) diagnosis, which follows\na weighted criteria score. We particularly evaluate the robustness of our\napproaches to noisy and missing data since these frequently occur in EHRs.\n  Results: In both use cases, and in the presence of imperfect data, our best\nDRL algorithms exhibit competitive performance when compared to the traditional\nclassifiers, with the added advantage that they enable the progressive\ngeneration of a pathway to the suggested diagnosis which can both guide and\nexplain the decision-making process.\n  Conclusion: DRL offers the opportunity to learn personalized decision\npathways to diagnosis. We illustrate with our two use cases their advantages:\nthey generate step-by-step pathways that are self-explanatory; and their\ncorrectness is competitive when compared to state-of-the-art approaches.",
      "tldr_zh": "这篇论文探讨了使用 Deep Reinforcement Learning (DRL) 从 Electronic Health Records (EHRs) 中学习个性化的诊断决策路径，以克服临床指南的局限性，如覆盖不全面和更新困难。研究将诊断任务建模为顺序决策问题，并通过合成数据在 Anemia 和 Systemic Lupus Erythematosus (SLE) 两个用例中评估 DRL 算法的性能，特别测试了其对噪声和缺失数据的鲁棒性。结果表明，DRL 方法与传统分类器竞争力相当，并能生成可解释的逐步决策路径，从而提升诊断过程的指导性和个性化水平。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "arXiv admin note: substantial text overlap with arXiv:2305.06295",
      "pdf_url": "http://arxiv.org/pdf/2404.05913v1",
      "published_date": "2024-04-09 00:07:16 UTC",
      "updated_date": "2024-04-09 00:07:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:08:05.367630"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 96,
  "processed_papers_count": 96,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-17T23:08:28.849021"
}