{
  "date": "2024-04-03",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-04-03 的 arXiv 中文 TLDR 快报！\n\n今天 arXiv 更新了 116 篇论文，主要聚焦 AI 模型优化（如 LLM 蒸馏和安全）、计算机视觉（如图像生成和解释）、医疗 AI 诊断，以及强化学习和伦理问题等领域；令人印象深刻的包括视觉生成模型的突破和 LLM 牢不可破攻击研究，而有名的学者如 Yann LeCun 和 Arman Cohan 的相关工作也值得关注。\n\n以下是今日论文的精选摘要，我优先选取了重要、创新性和话题度高的论文（如 AI 安全、医疗应用和视觉模型），并将相关主题归类快速讨论。其他次要论文（如一些基础实验或小规模改进）将简要掠过，以控制篇幅。\n\n### AI 模型和知识蒸馏\n- **Rethinking Kullback-Leibler Divergence in Knowledge Distillation for Large Language Models（在大型语言模型中重新思考 Kullback-Leibler 散度在知识蒸馏中的作用）**  \n  这篇论文探讨了 KL 散度在 LLM 知识蒸馏中的应用，发现正向和反向 KL 散度在优化目标上相同，但反向 KL 更关注分布尾部。主要贡献：提出 Adaptive Kullback-Leibler (AKL) 方法，提升了蒸馏效率，在多种任务上比基线提升 13%，为 LLM 压缩提供新视角。\n\n- **PiSSA: Principal Singular Values and Singular Vectors Adaptation of Large Language Models（PiSSA: 通过主奇异值和奇异向量适应大型语言模型）**  \n  作者包括知名学者如 Mark Gerstein。论文提出 PiSSA 方法，通过主成分初始化适应器矩阵，加速 LLM 微调。主要发现：在 GSM8K 等基准上，比 LoRA 提升 5% 准确率，同时减少参数 25%，为高效 LLM 训练提供实用工具。\n\n- **JailBreakV: A Benchmark for Assessing the Robustness of MultiModal Large Language Models against Jailbreak Attacks（JailBreakV: 评估多模态大型语言模型抗牢不可破攻击鲁棒性的基准）**  \n  这篇高话题度论文构建了 JailBreakV-28K 数据集，测试 MLLMs 对文本和图像攻击的鲁棒性。主要贡献：揭示 MLLMs 在处理 LLM 攻击时易受影响，攻击成功率高达 90%，强调未来需加强视觉和文本输入的防护机制。\n\n其他 AI 相关论文如 \"The Artificial Intelligence Ontology\"（AI 概念层次构建）快速掠过：它利用 LLM 辅助创建 AI 知识图谱，包含 16 万节点，提升跨学科研究，但细节较常规。\n\n### 计算机视觉和图像生成\n- **Visual Autoregressive Modeling: Scalable Image Generation via Next-Scale Prediction（视觉自回归建模：通过下一尺度预测的可扩展图像生成）**  \n  论文提出 VAR 模型，将图像生成转化为粗到细的尺度预测。主要发现：VAR 超越扩散模型，在 ImageNet 上 FID 降至 1.73，提升 17 倍推理速度，并展示零样本泛化能力，标志着自回归模型在视觉生成领域的突破。\n\n- **ASAP: Interpretable Analysis and Summarization of AI-generated Image Patterns at Scale（ASAP: 可解释的大规模 AI 生成图像模式分析）**  \n  作者包括知名机构如 Google。论文开发 ASAP 系统，使用 CLIP 编码器提取图像模式，并量化像素重要性。主要贡献：提升 AI 生成图像的可解释性，在基准数据集上检测假脸图像更准确，强调视觉模型的伦理应用。\n\n其他视觉论文如 \"FlightScope\"（卫星图像飞机检测比较）掠过：它评估 YOLO 等算法，但实验性强，不如上述创新性高。\n\n### 医疗 AI 和诊断\n- **Enhancing Human-Computer Interaction in Chest X-ray Analysis using Vision and Language Model with Eye Gaze Patterns（使用视觉语言模型和眼动模式增强胸部 X 光分析中的人机交互）**  \n  论文整合眼动数据到 VLM 中，提升 X 光图像分析。主要发现：在报告生成和错误检测任务上，比基线提升 0.21 BERTScore，首次将眼动融入医疗 AI，促进更可靠的诊断。\n\n- **Breast Cancer Histopathological Image Classification Using Cross-Colour Space Feature Fusion（使用跨颜色空间特征融合的乳腺癌组织病理图像分类）**  \n  论文提出量子-经典堆叠方法融合 RGB、HSV 和 CIE L*u*v 空间。主要贡献：在乳腺癌检测上，准确率接近 1，提升传统方法的性能，展示了跨模态融合在医疗图像中的潜力。\n\n其他医疗论文如 \"Unsupervised Occupancy Learning from Sparse Point Cloud\"（从稀疏点云的无监督占用学习）快速掠过：它改善 3D 医疗重建，但应用较窄。\n\n### 强化学习和机器人\n- **Deep Reinforcement Learning for Traveling Purchaser Problems（深度强化学习在旅行采购问题中的应用）**  \n  论文使用 DRL 优化采购路径。主要发现：在合成和真实数据集上，比传统启发式方法减少 40%-90% 最优差距，并展示元学习策略的泛化能力，适用于物流机器人。\n\n其他强化学习论文如 \"FedSelect\"（联邦学习中的个性化选择）掠过：它提升模型性能，但主题较专业，不如上述广泛。\n\n今日论文整体质量高，但许多（如 \"PhonologyBench\" 或 \"Domain Generalization\"）聚焦基础实验，我仅简要提及：这些工作如语音学基准或元学习调查，提供工具但影响力有限。总之，AI 安全和视觉生成是今日亮点，值得进一步探索！如果有特定兴趣，建议查看完整摘要。明天见！",
  "papers": [
    {
      "arxiv_id": "2404.04285v1",
      "title": "MIMIR: A Streamlined Platform for Personalized Agent Tuning in Domain Expertise",
      "title_zh": "MIMIR：一个简化的平台，用于在领域专业知识中进行个性化代理调优",
      "authors": [
        "Chunyuan Deng",
        "Xiangru Tang",
        "Yilun Zhao",
        "Hanming Wang",
        "Haoran Wang",
        "Wangchunshu Zhou",
        "Arman Cohan",
        "Mark Gerstein"
      ],
      "abstract": "Recently, large language models (LLMs) have evolved into interactive agents,\nproficient in planning, tool use, and task execution across a wide variety of\ntasks. However, without specific agent tuning, open-source models like LLaMA\ncurrently struggle to match the efficiency of GPT- 4, particularly given the\nscarcity of agent-tuning datasets for fine-tuning. In response, we introduce\n\\textsc{Mimir}: a streamlined platform offering a customizable pipeline that\nenables users to leverage both private knowledge and publicly available,\nlegally compliant datasets at scale for \\textbf{personalized agent tuning}.\nAdditionally, \\textsc{Mimir} supports the generation of general\ninstruction-tuning datasets from the same input. This dual capability ensures\nthat language agents developed through the platform possess both specific agent\nabilities and general competencies. \\textsc{Mimir} integrates these features\ninto a cohesive end-to-end platform, facilitating everything from the uploading\nof personalized files to one-click agent fine-tuning.",
      "tldr_zh": "该研究指出，大型语言模型（LLMs）虽能作为交互式代理进行规划、工具使用和任务执行，但开源模型如 LLaMA 因缺乏特定代理调优数据集，效率远逊于 GPT-4。为解决这一问题，研究引入 MIMIR 平台，这是一个简化的、可定制管道，支持用户利用私有知识和合法公开数据集进行个性化代理调优。MIMIR 同时能从相同输入生成一般指令调优数据集，确保代理具备特定代理能力和一般竞争力；平台提供端到端功能，从上传个性化文件到一键细调优，极大简化了过程。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.04285v1",
      "published_date": "2024-04-03 23:42:38 UTC",
      "updated_date": "2024-04-03 23:42:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T21:16:11.132995"
    },
    {
      "arxiv_id": "2404.03114v1",
      "title": "Testing the Effect of Code Documentation on Large Language Model Code Understanding",
      "title_zh": "测试代码文档对大型语言模型代码理解的影响",
      "authors": [
        "William Macke",
        "Michael Doyle"
      ],
      "abstract": "Large Language Models (LLMs) have demonstrated impressive abilities in recent\nyears with regards to code generation and understanding. However, little work\nhas investigated how documentation and other code properties affect an LLM's\nability to understand and generate code or documentation. We present an\nempirical analysis of how underlying properties of code or documentation can\naffect an LLM's capabilities. We show that providing an LLM with \"incorrect\"\ndocumentation can greatly hinder code understanding, while incomplete or\nmissing documentation does not seem to significantly affect an LLM's ability to\nunderstand code.",
      "tldr_zh": "本研究测试了代码文档对大型语言模型（LLMs）的代码理解能力的影响，通过实证分析探讨了文档属性如何改变LLMs的表现。研究发现，提供“错误”的代码文档会显著削弱LLMs的代码理解能力，而不完整的或缺失的文档则对理解效果影响不大。这些结果突出了在LLMs应用中，确保文档准确性的重要性，以提升模型的可靠性和实用性。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.SE",
      "comment": "7 pages, 5 figures, 2 tables. Accepted as a Findings paper in the\n  \"Generation\" track to NAACL 2024. MITRE Public Release Case Number 23-4132",
      "pdf_url": "http://arxiv.org/pdf/2404.03114v1",
      "published_date": "2024-04-03 23:33:56 UTC",
      "updated_date": "2024-04-03 23:33:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T21:16:21.136668"
    },
    {
      "arxiv_id": "2404.03099v1",
      "title": "Composite Bayesian Optimization In Function Spaces Using NEON -- Neural Epistemic Operator Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Leonardo Ferreira Guilhoto",
        "Paris Perdikaris"
      ],
      "abstract": "Operator learning is a rising field of scientific computing where inputs or\noutputs of a machine learning model are functions defined in\ninfinite-dimensional spaces. In this paper, we introduce NEON (Neural Epistemic\nOperator Networks), an architecture for generating predictions with uncertainty\nusing a single operator network backbone, which presents orders of magnitude\nless trainable parameters than deep ensembles of comparable performance. We\nshowcase the utility of this method for sequential decision-making by examining\nthe problem of composite Bayesian Optimization (BO), where we aim to optimize a\nfunction $f=g\\circ h$, where $h:X\\to C(\\mathcal{Y},\\mathbb{R}^{d_s})$ is an\nunknown map which outputs elements of a function space, and $g:\nC(\\mathcal{Y},\\mathbb{R}^{d_s})\\to \\mathbb{R}$ is a known and cheap-to-compute\nfunctional. By comparing our approach to other state-of-the-art methods on toy\nand real world scenarios, we demonstrate that NEON achieves state-of-the-art\nperformance while requiring orders of magnitude less trainable parameters.",
      "tldr_zh": "本论文引入了 NEON（Neural Epistemic Operator Networks），一种高效的操作符学习架构，能够使用单个网络生成不确定性预测，并显著减少可训练参数量，比深层集成模型低几个数量级。NEON 被应用于复合 Bayesian Optimization（BO），旨在优化函数 f = g ∘ h，其中 h 是一个未知映射输出函数空间的元素，而 g 是一个已知且计算廉价的功能。通过与现有方法的比较，实验结果显示 NEON 在玩具和真实世界场景中实现了最先进性能，同时大幅降低了参数需求。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CE",
        "cs.IT",
        "math.IT",
        "stat.ML",
        "68T37",
        "J.2; I.2.6"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.03099v1",
      "published_date": "2024-04-03 22:42:37 UTC",
      "updated_date": "2024-04-03 22:42:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T21:16:34.707801"
    },
    {
      "arxiv_id": "2404.03098v1",
      "title": "Exploring the Trade-off Between Model Performance and Explanation Plausibility of Text Classifiers Using Human Rationales",
      "title_zh": "翻译失败",
      "authors": [
        "Lucas E. Resck",
        "Marcos M. Raimundo",
        "Jorge Poco"
      ],
      "abstract": "Saliency post-hoc explainability methods are important tools for\nunderstanding increasingly complex NLP models. While these methods can reflect\nthe model's reasoning, they may not align with human intuition, making the\nexplanations not plausible. In this work, we present a methodology for\nincorporating rationales, which are text annotations explaining human\ndecisions, into text classification models. This incorporation enhances the\nplausibility of post-hoc explanations while preserving their faithfulness. Our\napproach is agnostic to model architectures and explainability methods. We\nintroduce the rationales during model training by augmenting the standard\ncross-entropy loss with a novel loss function inspired by contrastive learning.\nBy leveraging a multi-objective optimization algorithm, we explore the\ntrade-off between the two loss functions and generate a Pareto-optimal frontier\nof models that balance performance and plausibility. Through extensive\nexperiments involving diverse models, datasets, and explainability methods, we\ndemonstrate that our approach significantly enhances the quality of model\nexplanations without causing substantial (sometimes negligible) degradation in\nthe original model's performance.",
      "tldr_zh": "本研究探讨了使用人类理性（human rationales）来平衡文本分类模型的性能（model performance）和解释合理性（explanation plausibility）。他们提出了一种方法，通过在标准 cross-entropy loss 中添加一个基于 contrastive learning 的新损失函数，将人类理性整合到模型训练中，从而提升 saliency post-hoc explainability 方法的合理性，同时保持解释的忠实性（faithfulness）。该方法独立于模型架构和解释方法，并采用多目标优化算法生成 Pareto-optimal frontier 的模型，以探索性能与合理性的权衡。实验结果显示，在多种模型、数据集和解释方法上，该方法显著提高了解释质量，而对原始模型性能的下降通常很小甚至可忽略。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "27 pages, 22 figures, 8 tables; to appear in NAACL Findings 2024;\n  code and data available at\n  https://github.com/visual-ds/plausible-nlp-explanations",
      "pdf_url": "http://arxiv.org/pdf/2404.03098v1",
      "published_date": "2024-04-03 22:39:33 UTC",
      "updated_date": "2024-04-03 22:39:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T21:16:47.473815"
    },
    {
      "arxiv_id": "2404.08562v1",
      "title": "Dynamic Neural Control Flow Execution: An Agent-Based Deep Equilibrium Approach for Binary Vulnerability Detection",
      "title_zh": "动态神经控制流执行：基于智能体的深度平衡方法用于二进制漏洞检测",
      "authors": [
        "Litao Li",
        "Steven H. H. Ding",
        "Andrew Walenstein",
        "Philippe Charland",
        "Benjamin C. M. Fung"
      ],
      "abstract": "Software vulnerabilities are a challenge in cybersecurity. Manual security\npatches are often difficult and slow to be deployed, while new vulnerabilities\nare created. Binary code vulnerability detection is less studied and more\ncomplex compared to source code, and this has important practical implications.\nDeep learning has become an efficient and powerful tool in the security domain,\nwhere it provides end-to-end and accurate prediction. Modern deep learning\napproaches learn the program semantics through sequence and graph neural\nnetworks, using various intermediate representation of programs, such as\nabstract syntax trees (AST) or control flow graphs (CFG). Due to the complex\nnature of program execution, the output of an execution depends on the many\nprogram states and inputs. Also, a CFG generated from static analysis can be an\noverestimation of the true program flow. Moreover, the size of programs often\ndoes not allow a graph neural network with fixed layers to aggregate global\ninformation. To address these issues, we propose DeepEXE, an agent-based\nimplicit neural network that mimics the execution path of a program. We use\nreinforcement learning to enhance the branching decision at every program state\ntransition and create a dynamic environment to learn the dependency between a\nvulnerability and certain program states. An implicitly defined neural network\nenables nearly infinite state transitions until convergence, which captures the\nstructural information at a higher level. The experiments are conducted on two\nsemi-synthetic and two real-world datasets. We show that DeepEXE is an accurate\nand efficient method and outperforms the state-of-the-art vulnerability\ndetection methods.",
      "tldr_zh": "这篇论文针对二进制代码漏洞检测的复杂性问题，提出了一种基于代理的隐式神经网络方法DeepEXE，以动态模拟程序执行路径。DeepEXE利用强化学习强化分支决策，并在动态环境中学习漏洞与程序状态的依赖关系，同时通过隐式神经网络实现无限状态转换以捕获高级结构信息。实验在两个半合成和两个真实数据集上表明，DeepEXE比现有基于序列或图神经网络的方法更准确和高效，显著提升了漏洞检测性能。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.08562v1",
      "published_date": "2024-04-03 22:07:50 UTC",
      "updated_date": "2024-04-03 22:07:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T21:16:59.291266"
    },
    {
      "arxiv_id": "2404.03088v2",
      "title": "Robust Federated Learning for Wireless Networks: A Demonstration with Channel Estimation",
      "title_zh": "翻译失败",
      "authors": [
        "Zexin Fang",
        "Bin Han",
        "Hans D. Schotten"
      ],
      "abstract": "Federated learning (FL) offers a privacy-preserving collaborative approach\nfor training models in wireless networks, with channel estimation emerging as a\npromising application. Despite extensive studies on FL-empowered channel\nestimation, the security concerns associated with FL require meticulous\nattention. In a scenario where small base stations (SBSs) serve as local models\ntrained on cached data, and a macro base station (MBS) functions as the global\nmodel setting, an attacker can exploit the vulnerability of FL, launching\nattacks with various adversarial attacks or deployment tactics. In this paper,\nwe analyze such vulnerabilities, corresponding solutions were brought forth,\nand validated through simulation.",
      "tldr_zh": "本论文探讨了在无线网络中应用Federated Learning (FL)进行信道估计的鲁棒性问题，强调了FL的安全漏洞，如攻击者通过各种对抗攻击或部署策略利用小型基站 (SBSs) 和宏基站 (MBS) 的设置进行攻击。研究者分析了这些漏洞，并提出了相应的解决方案，包括隐私保护机制和防御策略。通过模拟实验，验证了这些方法的有效性，显著提升了FL在无线网络中的安全性和可靠性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NI",
        "eess.SP"
      ],
      "primary_category": "cs.LG",
      "comment": "Submitted to IEEE GLOBECOM 2024",
      "pdf_url": "http://arxiv.org/pdf/2404.03088v2",
      "published_date": "2024-04-03 22:03:28 UTC",
      "updated_date": "2024-07-30 08:19:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T21:17:11.336909"
    },
    {
      "arxiv_id": "2404.03085v1",
      "title": "Talaria: Interactively Optimizing Machine Learning Models for Efficient Inference",
      "title_zh": "翻译失败",
      "authors": [
        "Fred Hohman",
        "Chaoqun Wang",
        "Jinmook Lee",
        "Jochen Görtler",
        "Dominik Moritz",
        "Jeffrey P Bigham",
        "Zhile Ren",
        "Cecile Foret",
        "Qi Shan",
        "Xiaoyi Zhang"
      ],
      "abstract": "On-device machine learning (ML) moves computation from the cloud to personal\ndevices, protecting user privacy and enabling intelligent user experiences.\nHowever, fitting models on devices with limited resources presents a major\ntechnical challenge: practitioners need to optimize models and balance hardware\nmetrics such as model size, latency, and power. To help practitioners create\nefficient ML models, we designed and developed Talaria: a model visualization\nand optimization system. Talaria enables practitioners to compile models to\nhardware, interactively visualize model statistics, and simulate optimizations\nto test the impact on inference metrics. Since its internal deployment two\nyears ago, we have evaluated Talaria using three methodologies: (1) a log\nanalysis highlighting its growth of 800+ practitioners submitting 3,600+\nmodels; (2) a usability survey with 26 users assessing the utility of 20\nTalaria features; and (3) a qualitative interview with the 7 most active users\nabout their experience using Talaria.",
      "tldr_zh": "Talaria 是一个交互式系统，旨在优化机器学习 (ML) 模型以实现高效推理，解决设备端资源限制问题，如模型大小、延迟和功耗的平衡。系统允许用户编译模型到硬件、交互式可视化模型统计数据，并模拟优化以测试对推理指标的影响。内部部署两年后，通过日志分析（800+ 实践者提交3600+ 模型）、可用性调查（26 名用户评估20 个功能）和定性访谈（7 名活跃用户），Talaria 展示了其广泛采用和实用性。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.HC",
      "comment": "Proceedings of the 2024 ACM CHI Conference on Human Factors in\n  Computing Systems",
      "pdf_url": "http://arxiv.org/pdf/2404.03085v1",
      "published_date": "2024-04-03 21:55:44 UTC",
      "updated_date": "2024-04-03 21:55:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T21:17:23.175697"
    },
    {
      "arxiv_id": "2404.03084v2",
      "title": "Rethinking Teacher-Student Curriculum Learning through the Cooperative Mechanics of Experience",
      "title_zh": "重新审视教师-学生课程学习中的经验合作机制",
      "authors": [
        "Manfred Diaz",
        "Liam Paull",
        "Andrea Tacchetti"
      ],
      "abstract": "Teacher-Student Curriculum Learning (TSCL) is a curriculum learning framework\nthat draws inspiration from human cultural transmission and learning. It\ninvolves a teacher algorithm shaping the learning process of a learner\nalgorithm by exposing it to controlled experiences. Despite its success,\nunderstanding the conditions under which TSCL is effective remains challenging.\nIn this paper, we propose a data-centric perspective to analyze the underlying\nmechanics of the teacher-student interactions in TSCL. We leverage cooperative\ngame theory to describe how the composition of the set of experiences presented\nby the teacher to the learner, as well as their order, influences the\nperformance of the curriculum that is found by TSCL approaches. To do so, we\ndemonstrate that for every TSCL problem, an equivalent cooperative game exists,\nand several key components of the TSCL framework can be reinterpreted using\ngame-theoretic principles. Through experiments covering supervised learning,\nreinforcement learning, and classical games, we estimate the cooperative values\nof experiences and use value-proportional curriculum mechanisms to construct\ncurricula, even in cases where TSCL struggles. The framework and experimental\nsetup we present in this work represents a novel foundation for a deeper\nexploration of TSCL, shedding light on its underlying mechanisms and providing\ninsights into its broader applicability in machine learning.",
      "tldr_zh": "这篇论文重新审视 Teacher-Student Curriculum Learning (TSCL)，通过合作博弈理论分析老师算法如何通过控制体验组合和顺序影响学生算法的学习表现。作者提出从数据中心视角，将 TSCL 等价于合作博弈，并用游戏理论原则重新解释其关键组件。实验涵盖监督学习、强化学习和经典游戏，展示了通过估计体验的合作价值并采用基于价值的课程机制，能构建更有效的课程，即使在 TSCL 面临挑战时。整体框架为深入探索 TSCL 的机制并扩展其在机器学习中的应用提供了新基础。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.GT"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at TMLR (https://openreview.net/forum?id=qWh82br6KT)",
      "pdf_url": "http://arxiv.org/pdf/2404.03084v2",
      "published_date": "2024-04-03 21:55:17 UTC",
      "updated_date": "2024-09-12 16:56:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T21:17:35.717345"
    },
    {
      "arxiv_id": "2404.16042v2",
      "title": "How explainable AI affects human performance: A systematic review of the behavioural consequences of saliency maps",
      "title_zh": "翻译失败",
      "authors": [
        "Romy Müller"
      ],
      "abstract": "Saliency maps can explain how deep neural networks classify images. But are\nthey actually useful for humans? The present systematic review of 68 user\nstudies found that while saliency maps can enhance human performance, null\neffects or even costs are quite common. To investigate what modulates these\neffects, the empirical outcomes were organised along several factors related to\nthe human tasks, AI performance, XAI methods, images to be classified, human\nparticipants and comparison conditions. In image-focused tasks, benefits were\nless common than in AI-focused tasks, but the effects depended on the specific\ncognitive requirements. Moreover, benefits were usually restricted to incorrect\nAI predictions in AI-focused tasks but to correct ones in image-focused tasks.\nXAI-related factors had surprisingly little impact. The evidence was limited\nfor image- and human-related factors and the effects were highly dependent on\nthe comparison conditions. These findings may support the design of future user\nstudies.",
      "tldr_zh": "这篇系统综述分析了68个用户研究，探讨了saliency maps如何影响人类在图像分类任务中的表现。结果显示，虽然saliency maps能提升人类表现，但无效果或负面影响也很常见，且在图像焦点任务中益处较少，而在AI焦点任务中更依赖于AI预测的正确性。影响因素包括任务类型、AI性能和比较条件，而XAI方法的影响相对较小。这些发现有助于设计未来的用户研究，以优化explainable AI的应用。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.16042v2",
      "published_date": "2024-04-03 21:46:25 UTC",
      "updated_date": "2024-04-26 04:25:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T21:17:47.404091"
    },
    {
      "arxiv_id": "2404.03080v5",
      "title": "Construction and Application of Materials Knowledge Graph in Multidisciplinary Materials Science via Large Language Model",
      "title_zh": "通过大语言模型在多学科材料科学中",
      "authors": [
        "Yanpeng Ye",
        "Jie Ren",
        "Shaozhou Wang",
        "Yuwei Wan",
        "Imran Razzak",
        "Bram Hoex",
        "Haofen Wang",
        "Tong Xie",
        "Wenjie Zhang"
      ],
      "abstract": "Knowledge in materials science is widely dispersed across extensive\nscientific literature, posing significant challenges to the efficient discovery\nand integration of new materials. Traditional methods, often reliant on costly\nand time-consuming experimental approaches, further complicate rapid\ninnovation. Addressing these challenges, the integration of artificial\nintelligence with materials science has opened avenues for accelerating the\ndiscovery process, though it also demands precise annotation, data extraction,\nand traceability of information. To tackle these issues, this article\nintroduces the Materials Knowledge Graph (MKG), which utilizes advanced natural\nlanguage processing techniques integrated with large language models to extract\nand systematically organize a decade's worth of high-quality research into\nstructured triples, contains 162,605 nodes and 731,772 edges. MKG categorizes\ninformation into comprehensive labels such as Name, Formula, and Application,\nstructured around a meticulously designed ontology, thus enhancing data\nusability and integration. By implementing network-based algorithms, MKG not\nonly facilitates efficient link prediction but also significantly reduces\nreliance on traditional experimental methods. This structured approach not only\nstreamlines materials research but also lays the groundwork for more\nsophisticated science knowledge graphs.",
      "tldr_zh": "这篇论文针对材料科学知识分散和传统实验方法耗时的挑战，提出使用大型语言模型(Large Language Model)结合自然语言处理技术构建Materials Knowledge Graph (MKG)。MKG从十年高质量研究中提取数据，形成包含162,605个节点和731,772个边的结构化三元组，并通过精心设计的本体分类信息如Name、Formula和Application，提升数据可用性和整合性。该方法应用网络-based算法实现高效的链接预测，显著减少对实验依赖，并为更高级的科学知识图奠定基础。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted by 38th Conference on Neural Information Processing Systems\n  (NeurIPS 2024)",
      "pdf_url": "http://arxiv.org/pdf/2404.03080v5",
      "published_date": "2024-04-03 21:46:14 UTC",
      "updated_date": "2025-05-15 02:03:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T21:17:58.998600"
    },
    {
      "arxiv_id": "2404.03058v1",
      "title": "Automatic Extraction of Linguistic Description from Fuzzy Rule Base",
      "title_zh": "翻译失败",
      "authors": [
        "Krzysztof Siminski",
        "Konrad Wnuk"
      ],
      "abstract": "Neuro-fuzzy systems are a technique of explainable artificial intelligence\n(XAI). They elaborate knowledge models as a set of fuzzy rules. Fuzzy sets are\ncrucial components of fuzzy rules. They are used to model linguistic terms. In\nthis paper, we present an automatic extraction of fuzzy rules in the natural\nEnglish language. Full implementation is available free from a public\nrepository.",
      "tldr_zh": "本文提出了一种从模糊规则基自动提取语言描述的方法，旨在提升神经模糊系统（Neuro-fuzzy systems）作为可解释人工智能（XAI）的实用性。该方法利用模糊集（Fuzzy sets）来建模语言术语，并生成自然英语表达的模糊规则，从而使知识模型更易于理解。完整的实现代码已在公共仓库中免费提供，方便进一步应用和验证。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.03058v1",
      "published_date": "2024-04-03 20:50:48 UTC",
      "updated_date": "2024-04-03 20:50:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T21:18:11.396839"
    },
    {
      "arxiv_id": "2404.03054v2",
      "title": "Data-Driven Goal Recognition Design for General Behavioral Agents",
      "title_zh": "翻译失败",
      "authors": [
        "Robert Kasumba",
        "Guanghui Yu",
        "Chien-Ju Ho",
        "Sarah Keren",
        "William Yeoh"
      ],
      "abstract": "Goal recognition design aims to make limited modifications to decision-making\nenvironments with the goal of making it easier to infer the goals of agents\nacting within those environments. Although various research efforts have been\nmade in goal recognition design, existing approaches are computationally\ndemanding and often assume that agents are (near-)optimal in their\ndecision-making. To address these limitations, we introduce a data-driven\napproach to goal recognition design that can account for agents with general\nbehavioral models. Following existing literature, we use worst-case\ndistinctiveness($\\textit{wcd}$) as a measure of the difficulty in inferring the\ngoal of an agent in a decision-making environment. Our approach begins by\ntraining a machine learning model to predict the $\\textit{wcd}$ for a given\nenvironment and the agent behavior model. We then propose a gradient-based\noptimization framework that accommodates various constraints to optimize\ndecision-making environments for enhanced goal recognition. Through extensive\nsimulations, we demonstrate that our approach outperforms existing methods in\nreducing $\\textit{wcd}$ and enhancing runtime efficiency in conventional setup.\nMoreover, our approach also adapts to settings in which existing approaches do\nnot apply, such as those involving flexible budget constraints, more complex\nenvironments, and suboptimal agent behavior. Finally, we have conducted\nhuman-subject experiments which confirm that our method can create environments\nthat facilitate efficient goal recognition from real-world human\ndecision-makers.",
      "tldr_zh": "该研究提出了一种数据驱动的目标识别设计方法，针对一般行为模型的代理（general behavioral agents），通过对决策环境进行有限修改来提升目标推断的效率。该方法使用机器学习（ML）模型预测 worst-case distinctiveness（wcd）指标，并采用基于梯度的优化框架来优化环境，同时考虑各种约束。实验结果显示，该方法在模拟环境中显著降低了 wcd 值并提高了运行效率，且适用于现有方法无法处理的场景，如灵活预算约束、复杂环境和次优代理行为。最后，通过人类实验验证，该方法能有效辅助从真实人类决策者中识别目标。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.03054v2",
      "published_date": "2024-04-03 20:38:22 UTC",
      "updated_date": "2024-06-11 20:45:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T21:18:23.352024"
    },
    {
      "arxiv_id": "2404.03044v1",
      "title": "The Artificial Intelligence Ontology: LLM-assisted construction of AI concept hierarchies",
      "title_zh": "人工智能本体：大语言模型辅助的 AI 概念层次结构构建",
      "authors": [
        "Marcin P. Joachimiak",
        "Mark A. Miller",
        "J. Harry Caufield",
        "Ryan Ly",
        "Nomi L. Harris",
        "Andrew Tritt",
        "Christopher J. Mungall",
        "Kristofer E. Bouchard"
      ],
      "abstract": "The Artificial Intelligence Ontology (AIO) is a systematization of artificial\nintelligence (AI) concepts, methodologies, and their interrelations. Developed\nvia manual curation, with the additional assistance of large language models\n(LLMs), AIO aims to address the rapidly evolving landscape of AI by providing a\ncomprehensive framework that encompasses both technical and ethical aspects of\nAI technologies. The primary audience for AIO includes AI researchers,\ndevelopers, and educators seeking standardized terminology and concepts within\nthe AI domain. The ontology is structured around six top-level branches:\nNetworks, Layers, Functions, LLMs, Preprocessing, and Bias, each designed to\nsupport the modular composition of AI methods and facilitate a deeper\nunderstanding of deep learning architectures and ethical considerations in AI.\n  AIO's development utilized the Ontology Development Kit (ODK) for its\ncreation and maintenance, with its content being dynamically updated through\nAI-driven curation support. This approach not only ensures the ontology's\nrelevance amidst the fast-paced advancements in AI but also significantly\nenhances its utility for researchers, developers, and educators by simplifying\nthe integration of new AI concepts and methodologies.\n  The ontology's utility is demonstrated through the annotation of AI methods\ndata in a catalog of AI research publications and the integration into the\nBioPortal ontology resource, highlighting its potential for cross-disciplinary\nresearch. The AIO ontology is open source and is available on GitHub\n(https://github.com/berkeleybop/artificial-intelligence-ontology) and BioPortal\n(https://bioportal.bioontology.org/ontologies/AIO).",
      "tldr_zh": "本研究介绍了Artificial Intelligence Ontology (AIO)，这是一个通过手动整理和LLMs辅助构建的AI概念分层框架，旨在系统化AI的概念、方法及其相互关系，包括技术和社会伦理方面。AIO的结构基于六个顶级分支：Networks, Layers, Functions, LLMs, Preprocessing, and Bias，支持AI方法的模块化组合和深度学习架构的理解。利用Ontology Development Kit (ODK)进行开发，该框架通过AI驱动的动态更新，确保其在快速演进的AI领域保持相关性，并已在AI研究出版物注解和BioPortal整合中展示其实用价值。AIO作为开源资源，可在GitHub和BioPortal上获取。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.03044v1",
      "published_date": "2024-04-03 20:08:15 UTC",
      "updated_date": "2024-04-03 20:08:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T21:18:36.415713"
    },
    {
      "arxiv_id": "2404.03037v3",
      "title": "Model-based Reinforcement Learning for Parameterized Action Spaces",
      "title_zh": "翻译失败",
      "authors": [
        "Renhao Zhang",
        "Haotian Fu",
        "Yilin Miao",
        "George Konidaris"
      ],
      "abstract": "We propose a novel model-based reinforcement learning algorithm -- Dynamics\nLearning and predictive control with Parameterized Actions (DLPA) -- for\nParameterized Action Markov Decision Processes (PAMDPs). The agent learns a\nparameterized-action-conditioned dynamics model and plans with a modified Model\nPredictive Path Integral control. We theoretically quantify the difference\nbetween the generated trajectory and the optimal trajectory during planning in\nterms of the value they achieved through the lens of Lipschitz Continuity. Our\nempirical results on several standard benchmarks show that our algorithm\nachieves superior sample efficiency and asymptotic performance than\nstate-of-the-art PAMDP methods.",
      "tldr_zh": "我们提出了一种新的模型-based强化学习算法——Dynamics Learning and predictive control with Parameterized Actions (DLPA)，用于处理Parameterized Action Markov Decision Processes (PAMDPs)。该算法通过学习parameterized-action-conditioned dynamics model并采用modified Model Predictive Path Integral control进行规划，从而提升决策效率。理论上，我们利用Lipschitz Continuity量化了生成的轨迹与最优轨迹之间的价值差异。实验结果显示，DLPA在多个标准基准上比现有PAMDP方法实现了更高的样本效率和渐近性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.03037v3",
      "published_date": "2024-04-03 19:48:13 UTC",
      "updated_date": "2024-05-24 02:15:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T21:18:48.037154"
    },
    {
      "arxiv_id": "2406.11855v1",
      "title": "Law and the Emerging Political Economy of Algorithmic Audits",
      "title_zh": "法律与算法审计新兴政治经济",
      "authors": [
        "Petros Terzis",
        "Michael Veale",
        "Noëlle Gaumann"
      ],
      "abstract": "For almost a decade now, scholarship in and beyond the ACM FAccT community\nhas been focusing on novel and innovative ways and methodologies to audit the\nfunctioning of algorithmic systems. Over the years, this research idea and\ntechnical project has matured enough to become a regulatory mandate. Today, the\nDigital Services Act (DSA) and the Online Safety Act (OSA) have established the\nframework within which technology corporations and (traditional) auditors will\ndevelop the `practice' of algorithmic auditing thereby presaging how this\n`ecosystem' will develop. In this paper, we systematically review the auditing\nprovisions in the DSA and the OSA in light of observations from the emerging\nindustry of algorithmic auditing. Who is likely to occupy this space? What are\nsome political and ethical tensions that are likely to arise? How are the\nmandates of `independent auditing' or `the evaluation of the societal context\nof an algorithmic function' likely to play out in practice? By shaping the\npicture of the emerging political economy of algorithmic auditing, we draw\nattention to strategies and cultures of traditional auditors that risk eroding\nimportant regulatory pillars of the DSA and the OSA. Importantly, we warn that\nambitious research ideas and technical projects of/for algorithmic auditing may\nend up crashed by the standardising grip of traditional auditors and/or diluted\nwithin a complex web of (sub-)contractual arrangements, diverse portfolios, and\ntight timelines.",
      "tldr_zh": "这篇论文探讨了算法审计（algorithmic audits）的兴起，从学术研究转向监管要求，焦点在于欧盟的《数字服务法》（Digital Services Act, DSA）和英国的《在线安全法》（Online Safety Act, OSA）。作者通过系统审视这些法规的审计规定，并结合新兴行业观察，分析了谁可能主导这一领域，以及潜在的政治和伦理张力，如独立审计的挑战和对算法社会背景评估的实际影响。论文警告，传统审计师的标准化和合同安排可能侵蚀DSA和OSA的关键支柱，导致雄心勃勃的算法审计研究想法被稀释或削弱。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "14 pages",
      "pdf_url": "http://arxiv.org/pdf/2406.11855v1",
      "published_date": "2024-04-03 19:45:30 UTC",
      "updated_date": "2024-04-03 19:45:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T21:18:59.485973"
    },
    {
      "arxiv_id": "2404.03027v4",
      "title": "JailBreakV: A Benchmark for Assessing the Robustness of MultiModal Large Language Models against Jailbreak Attacks",
      "title_zh": "翻译失败",
      "authors": [
        "Weidi Luo",
        "Siyuan Ma",
        "Xiaogeng Liu",
        "Xiaoyu Guo",
        "Chaowei Xiao"
      ],
      "abstract": "With the rapid advancements in Multimodal Large Language Models (MLLMs),\nsecuring these models against malicious inputs while aligning them with human\nvalues has emerged as a critical challenge. In this paper, we investigate an\nimportant and unexplored question of whether techniques that successfully\njailbreak Large Language Models (LLMs) can be equally effective in jailbreaking\nMLLMs. To explore this issue, we introduce JailBreakV-28K, a pioneering\nbenchmark designed to assess the transferability of LLM jailbreak techniques to\nMLLMs, thereby evaluating the robustness of MLLMs against diverse jailbreak\nattacks. Utilizing a dataset of 2, 000 malicious queries that is also proposed\nin this paper, we generate 20, 000 text-based jailbreak prompts using advanced\njailbreak attacks on LLMs, alongside 8, 000 image-based jailbreak inputs from\nrecent MLLMs jailbreak attacks, our comprehensive dataset includes 28, 000 test\ncases across a spectrum of adversarial scenarios. Our evaluation of 10\nopen-source MLLMs reveals a notably high Attack Success Rate (ASR) for attacks\ntransferred from LLMs, highlighting a critical vulnerability in MLLMs that\nstems from their text-processing capabilities. Our findings underscore the\nurgent need for future research to address alignment vulnerabilities in MLLMs\nfrom both textual and visual inputs.",
      "tldr_zh": "本研究探讨了多模态大语言模型（MLLMs）是否容易受到大语言模型（LLMs）破解技术的转移攻击，引入了JailBreakV-28K基准，用于评估MLLMs在面对多样化越狱攻击时的鲁棒性。该基准基于一个新提出的2,000个恶意查询数据集，生成20,000个文本-based越狱提示和8,000个图像-based攻击输入，共计28,000个测试案例。实验评估了10个开源MLLMs，发现从LLMs转移的攻击具有高Attack Success Rate (ASR)，突显了MLLMs在文本处理方面的关键漏洞。研究强调，未来需加强MLLMs对文本和视觉输入的对齐机制，以提升其安全性。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.03027v4",
      "published_date": "2024-04-03 19:23:18 UTC",
      "updated_date": "2024-11-24 06:22:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T21:19:14.603960"
    },
    {
      "arxiv_id": "2404.03023v1",
      "title": "Toward Safe Evolution of Artificial Intelligence (AI) based Conversational Agents to Support Adolescent Mental and Sexual Health Knowledge Discovery",
      "title_zh": "翻译失败",
      "authors": [
        "Jinkyung Park",
        "Vivek Singh",
        "Pamela Wisniewski"
      ],
      "abstract": "Following the recent release of various Artificial Intelligence (AI) based\nConversation Agents (CAs), adolescents are increasingly using CAs for\ninteractive knowledge discovery on sensitive topics, including mental and\nsexual health topics. Exploring such sensitive topics through online search has\nbeen an essential part of adolescent development, and CAs can support their\nknowledge discovery on such topics through human-like dialogues. Yet,\nunintended risks have been documented with adolescents' interactions with\nAI-based CAs, such as being exposed to inappropriate content, false\ninformation, and/or being given advice that is detrimental to their mental and\nphysical well-being (e.g., to self-harm). In this position paper, we discuss\nthe current landscape and opportunities for CAs to support adolescents' mental\nand sexual health knowledge discovery. We also discuss some of the challenges\nrelated to ensuring the safety of adolescents when interacting with CAs\nregarding sexual and mental health topics. We call for a discourse on how to\nset guardrails for the safe evolution of AI-based CAs for adolescents.",
      "tldr_zh": "这篇立场论文探讨了人工智能（AI）驱动的对话代理（CAs）在支持青少年心理和性健康知识发现方面的潜力与风险。论文指出，青少年通过 CAs 进行互动式学习有助于探索敏感话题，但也可能导致暴露不适当内容、虚假信息或有害建议（如自残建议），从而威胁他们的身心健康。作者分析了当前景观、机会和挑战，并呼吁建立安全保障机制，以推动 AI-based CAs 的安全演变。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "This paper has been peer-reviewed and presented at the \"CHI 2024\n  Workshop on Child-centred AI Design, May 11, 2024, Honolulu, HI, USA.\"",
      "pdf_url": "http://arxiv.org/pdf/2404.03023v1",
      "published_date": "2024-04-03 19:18:25 UTC",
      "updated_date": "2024-04-03 19:18:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T21:19:23.355223"
    },
    {
      "arxiv_id": "2404.03021v2",
      "title": "Blessing or curse? A survey on the Impact of Generative AI on Fake News",
      "title_zh": "祝福还是诅咒？ 关于生成式 AI 对假新闻影响的调查",
      "authors": [
        "Alexander Loth",
        "Martin Kappes",
        "Marc-Oliver Pahl"
      ],
      "abstract": "Fake news significantly influence our society. They impact consumers, voters,\nand many other societal groups. While Fake News exist for a centuries,\nGenerative AI brings fake news on a new level. It is now possible to automate\nthe creation of masses of high-quality individually targeted Fake News. On the\nother end, Generative AI can also help detecting Fake News. Both fields are\nyoung but developing fast.\n  This survey provides a comprehensive examination of the research and\npractical use of Generative AI for Fake News detection and creation in 2024.\nFollowing the Structured Literature Survey approach, the paper synthesizes\ncurrent results in the following topic clusters 1) enabling technologies, 2)\ncreation of Fake News, 3) case study social media as most relevant distribution\nchannel, 4) detection of Fake News, and 5) deepfakes as upcoming technology.\n  The article also identifies current challenges and open issues.",
      "tldr_zh": "这篇调查论文探讨了生成式 AI（Generative AI）对假新闻（Fake News）的影响，分析其双重角色：一方面，它能自动化生成大规模、高质量的个性化假新闻，放大社会危害；另一方面，它也可用于检测假新闻。论文采用 Structured Literature Survey 方法，系统回顾了2024年的相关研究，涵盖主题集群包括启用技术、假新闻创建、社交媒体作为主要分发渠道的案例研究、假新闻检测以及 Deepfakes 等新兴技术。最终，论文总结了当前挑战和开放问题，为未来研究提供指导。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "I.2.7"
      ],
      "primary_category": "cs.CL",
      "comment": "16 pages, 2 figures. Submitted to ACM Transactions on Intelligent\n  Systems and Technology (ACM TIST). Added references",
      "pdf_url": "http://arxiv.org/pdf/2404.03021v2",
      "published_date": "2024-04-03 19:14:45 UTC",
      "updated_date": "2024-12-27 11:31:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T21:19:35.258763"
    },
    {
      "arxiv_id": "2404.03011v1",
      "title": "Transfer learning applications for anomaly detection in wind turbines",
      "title_zh": "用于风力涡轮机异常检测的迁移学习应用",
      "authors": [
        "Cyriana M. A. Roelofs",
        "Christian Gück",
        "Stefan Faulstich"
      ],
      "abstract": "Anomaly detection in wind turbines typically involves using normal behaviour\nmodels to detect faults early. However, training autoencoder models for each\nturbine is time-consuming and resource intensive. Thus, transfer learning\nbecomes essential for wind turbines with limited data or applications with\nlimited computational resources. This study examines how cross-turbine transfer\nlearning can be applied to autoencoder-based anomaly detection. Here,\nautoencoders are combined with constant thresholds for the reconstruction error\nto determine if input data contains an anomaly. The models are initially\ntrained on one year's worth of data from one or more source wind turbines. They\nare then fine-tuned using smaller amounts of data from another turbine. Three\nmethods for fine-tuning are investigated: adjusting the entire autoencoder,\nonly the decoder, or only the threshold of the model. The performance of the\ntransfer learning models is compared to baseline models that were trained on\none year's worth of data from the target wind turbine. The results of the tests\nconducted in this study indicate that models trained on data of multiple wind\nturbines do not improve the anomaly detection capability compared to models\ntrained on data of one source wind turbine. In addition, modifying the model's\nthreshold can lead to comparable or even superior performance compared to the\nbaseline, whereas fine-tuning the decoder or autoencoder further enhances the\nmodels' performance.",
      "tldr_zh": "本研究探讨了转移学习（transfer learning）在风力涡轮机异常检测中的应用，以解决训练自编码器（autoencoders）模型耗时且资源密集的问题。研究方法包括先用一个或多个源涡轮机一年的数据训练自编码器模型，然后通过调整整个自编码器、仅解码器或仅阈值的方式，使用目标涡轮机的少量数据进行微调。结果显示，使用多个源涡轮机数据训练的模型并未改善异常检测性能，而仅调整阈值即可达到或超过基线模型（直接用目标涡轮机一年的数据训练）的效果，进一步微调解码器或自编码器则能显著提升模型表现。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "I.2"
      ],
      "primary_category": "cs.LG",
      "comment": "16 pages, 7 figures, preprint submitted to Energy&AI",
      "pdf_url": "http://arxiv.org/pdf/2404.03011v1",
      "published_date": "2024-04-03 18:48:45 UTC",
      "updated_date": "2024-04-03 18:48:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T21:19:48.929820"
    },
    {
      "arxiv_id": "2404.02990v1",
      "title": "ASAP: Interpretable Analysis and Summarization of AI-generated Image Patterns at Scale",
      "title_zh": "翻译失败",
      "authors": [
        "Jinbin Huang",
        "Chen Chen",
        "Aditi Mishra",
        "Bum Chul Kwon",
        "Zhicheng Liu",
        "Chris Bryan"
      ],
      "abstract": "Generative image models have emerged as a promising technology to produce\nrealistic images. Despite potential benefits, concerns grow about its misuse,\nparticularly in generating deceptive images that could raise significant\nethical, legal, and societal issues. Consequently, there is growing demand to\nempower users to effectively discern and comprehend patterns of AI-generated\nimages. To this end, we developed ASAP, an interactive visualization system\nthat automatically extracts distinct patterns of AI-generated images and allows\nusers to interactively explore them via various views. To uncover fake\npatterns, ASAP introduces a novel image encoder, adapted from CLIP, which\ntransforms images into compact \"distilled\" representations, enriched with\ninformation for differentiating authentic and fake images. These\nrepresentations generate gradients that propagate back to the attention maps of\nCLIP's transformer block. This process quantifies the relative importance of\neach pixel to image authenticity or fakeness, exposing key deceptive patterns.\nASAP enables the at scale interactive analysis of these patterns through\nmultiple, coordinated visualizations. This includes a representation overview\nwith innovative cell glyphs to aid in the exploration and qualitative\nevaluation of fake patterns across a vast array of images, as well as a pattern\nview that displays authenticity-indicating patterns in images and quantifies\ntheir impact. ASAP supports the analysis of cutting-edge generative models with\nthe latest architectures, including GAN-based models like proGAN and diffusion\nmodels like the latent diffusion model. We demonstrate ASAP's usefulness\nthrough two usage scenarios using multiple fake image detection benchmark\ndatasets, revealing its ability to identify and understand hidden patterns in\nAI-generated images, especially in detecting fake human faces produced by\ndiffusion-based techniques.",
      "tldr_zh": "ASAP是一个交互式可视化系统，旨在分析和总结AI生成图像的模式，帮助用户识别假图像并理解其欺骗性特征。系统引入基于CLIP的图像编码器，将图像转化为紧凑的“distilled”表示，并通过梯度传播到CLIP的注意力映射，量化像素对图像真实性的重要性，从而暴露关键假模式。ASAP支持大规模交互探索，包括表示概述和模式视图，并通过多个基准数据集的实验证明其有效性，尤其在检测diffusion models生成的假人脸方面。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.CV",
      "comment": "9 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2404.02990v1",
      "published_date": "2024-04-03 18:20:41 UTC",
      "updated_date": "2024-04-03 18:20:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T21:20:00.877946"
    },
    {
      "arxiv_id": "2404.02954v2",
      "title": "Deep Generative Models through the Lens of the Manifold Hypothesis: A Survey and New Connections",
      "title_zh": "翻译失败",
      "authors": [
        "Gabriel Loaiza-Ganem",
        "Brendan Leigh Ross",
        "Rasa Hosseinzadeh",
        "Anthony L. Caterini",
        "Jesse C. Cresswell"
      ],
      "abstract": "In recent years there has been increased interest in understanding the\ninterplay between deep generative models (DGMs) and the manifold hypothesis.\nResearch in this area focuses on understanding the reasons why commonly-used\nDGMs succeed or fail at learning distributions supported on unknown\nlow-dimensional manifolds, as well as developing new models explicitly designed\nto account for manifold-supported data. This manifold lens provides both\nclarity as to why some DGMs (e.g. diffusion models and some generative\nadversarial networks) empirically surpass others (e.g. likelihood-based models\nsuch as variational autoencoders, normalizing flows, or energy-based models) at\nsample generation, and guidance for devising more performant DGMs. We carry out\nthe first survey of DGMs viewed through this lens, making two novel\ncontributions along the way. First, we formally establish that numerical\ninstability of likelihoods in high ambient dimensions is unavoidable when\nmodelling data with low intrinsic dimension. We then show that DGMs on learned\nrepresentations of autoencoders can be interpreted as approximately minimizing\nWasserstein distance: this result, which applies to latent diffusion models,\nhelps justify their outstanding empirical results. The manifold lens provides a\nrich perspective from which to understand DGMs, and we aim to make this\nperspective more accessible and widespread.",
      "tldr_zh": "这篇论文通过流形假设 (manifold hypothesis) 的视角对深度生成模型 (DGMs) 进行首次全面调查，解释了为什么某些 DGMs（如扩散模型和生成对抗网络）在生成低维流形支持的数据分布时优于其他模型（如变分自编码器、归一化流或能量模型）。论文的主要贡献包括：正式证明了在高维环境中建模低维数据的似然数值不稳定性是不可避免的，以及展示了基于自编码器学习表示的 DGMs 可以被解释为近似最小化 Wasserstein 距离，这为潜在扩散模型的出色实证结果提供了理论支撑。总体而言，这种流形视角为理解和改进 DGMs 的性能提供了宝贵指导。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "TMLR 2024 (survey certification, expert certification)",
      "pdf_url": "http://arxiv.org/pdf/2404.02954v2",
      "published_date": "2024-04-03 18:00:00 UTC",
      "updated_date": "2024-09-25 18:00:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T21:20:15.265140"
    },
    {
      "arxiv_id": "2404.02905v2",
      "title": "Visual Autoregressive Modeling: Scalable Image Generation via Next-Scale Prediction",
      "title_zh": "视觉自回归建模：通过下一尺度预测的可扩展图像生成",
      "authors": [
        "Keyu Tian",
        "Yi Jiang",
        "Zehuan Yuan",
        "Bingyue Peng",
        "Liwei Wang"
      ],
      "abstract": "We present Visual AutoRegressive modeling (VAR), a new generation paradigm\nthat redefines the autoregressive learning on images as coarse-to-fine\n\"next-scale prediction\" or \"next-resolution prediction\", diverging from the\nstandard raster-scan \"next-token prediction\". This simple, intuitive\nmethodology allows autoregressive (AR) transformers to learn visual\ndistributions fast and generalize well: VAR, for the first time, makes GPT-like\nAR models surpass diffusion transformers in image generation. On ImageNet\n256x256 benchmark, VAR significantly improve AR baseline by improving Frechet\ninception distance (FID) from 18.65 to 1.73, inception score (IS) from 80.4 to\n350.2, with around 20x faster inference speed. It is also empirically verified\nthat VAR outperforms the Diffusion Transformer (DiT) in multiple dimensions\nincluding image quality, inference speed, data efficiency, and scalability.\nScaling up VAR models exhibits clear power-law scaling laws similar to those\nobserved in LLMs, with linear correlation coefficients near -0.998 as solid\nevidence. VAR further showcases zero-shot generalization ability in downstream\ntasks including image in-painting, out-painting, and editing. These results\nsuggest VAR has initially emulated the two important properties of LLMs:\nScaling Laws and zero-shot task generalization. We have released all models and\ncodes to promote the exploration of AR/VAR models for visual generation and\nunified learning.",
      "tldr_zh": "本研究提出 Visual Autoregressive Modeling (VAR)，一种新型图像生成方法，通过从粗到细的“next-scale prediction”取代传统的逐 token 预测，从而加速视觉分布学习并提升模型泛化能力。相比基线，VAR 使 GPT-like 自回归模型首次在图像生成中超越 Diffusion Transformer (DiT)，在 ImageNet 256x256 上将 Frechet Inception Distance (FID) 从 18.65 降至 1.73、Inception Score (IS) 从 80.4 升至 350.2，同时推理速度快 20 倍，并在图像质量、数据效率和可扩展性上表现出色。实验还验证了 VAR 遵循类似于大型语言模型的 Scaling Laws，并展示零-shot generalization 在图像修复、扩展和编辑等下游任务中的能力，论文已开源模型和代码以推动相关研究。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Demo website: https://var.vision/",
      "pdf_url": "http://arxiv.org/pdf/2404.02905v2",
      "published_date": "2024-04-03 17:59:53 UTC",
      "updated_date": "2024-06-10 17:59:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T21:20:26.919883"
    },
    {
      "arxiv_id": "2404.02904v1",
      "title": "ALOHa: A New Measure for Hallucination in Captioning Models",
      "title_zh": "翻译失败",
      "authors": [
        "Suzanne Petryk",
        "David M. Chan",
        "Anish Kachinthaya",
        "Haodi Zou",
        "John Canny",
        "Joseph E. Gonzalez",
        "Trevor Darrell"
      ],
      "abstract": "Despite recent advances in multimodal pre-training for visual description,\nstate-of-the-art models still produce captions containing errors, such as\nhallucinating objects not present in a scene. The existing prominent metric for\nobject hallucination, CHAIR, is limited to a fixed set of MS COCO objects and\nsynonyms. In this work, we propose a modernized open-vocabulary metric, ALOHa,\nwhich leverages large language models (LLMs) to measure object hallucinations.\nSpecifically, we use an LLM to extract groundable objects from a candidate\ncaption, measure their semantic similarity to reference objects from captions\nand object detections, and use Hungarian matching to produce a final\nhallucination score. We show that ALOHa correctly identifies 13.6% more\nhallucinated objects than CHAIR on HAT, a new gold-standard subset of MS COCO\nCaptions annotated for hallucinations, and 30.8% more on nocaps, where objects\nextend beyond MS COCO categories. Our code is available at\nhttps://davidmchan.github.io/aloha/.",
      "tldr_zh": "本文提出ALOHa，一种新的开放词汇度量标准，用于评估图像标题模型中的对象幻觉问题，以克服现有指标CHAIR的局限性，该指标仅限于固定MS COCO对象集。ALOHa利用大型语言模型(LLMs)从候选标题中提取可grounding的对象，计算其与参考对象（来自标题和对象检测）的语义相似度，并通过Hungarian matching生成最终幻觉分数。实验结果显示，ALOHa在HAT数据集上比CHAIR多识别13.6%的幻觉对象，在nocaps数据集上多识别30.8%，从而为更准确的幻觉评估提供了改进方法。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "To appear at NAACL 2024",
      "pdf_url": "http://arxiv.org/pdf/2404.02904v1",
      "published_date": "2024-04-03 17:59:36 UTC",
      "updated_date": "2024-04-03 17:59:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T21:20:37.814959"
    },
    {
      "arxiv_id": "2404.02900v1",
      "title": "DeiT-LT Distillation Strikes Back for Vision Transformer Training on Long-Tailed Datasets",
      "title_zh": "翻译失败",
      "authors": [
        "Harsh Rangwani",
        "Pradipto Mondal",
        "Mayank Mishra",
        "Ashish Ramayee Asokan",
        "R. Venkatesh Babu"
      ],
      "abstract": "Vision Transformer (ViT) has emerged as a prominent architecture for various\ncomputer vision tasks. In ViT, we divide the input image into patch tokens and\nprocess them through a stack of self attention blocks. However, unlike\nConvolutional Neural Networks (CNN), ViTs simple architecture has no\ninformative inductive bias (e.g., locality,etc. ). Due to this, ViT requires a\nlarge amount of data for pre-training. Various data efficient approaches (DeiT)\nhave been proposed to train ViT on balanced datasets effectively. However,\nlimited literature discusses the use of ViT for datasets with long-tailed\nimbalances. In this work, we introduce DeiT-LT to tackle the problem of\ntraining ViTs from scratch on long-tailed datasets. In DeiT-LT, we introduce an\nefficient and effective way of distillation from CNN via distillation DIST\ntoken by using out-of-distribution images and re-weighting the distillation\nloss to enhance focus on tail classes. This leads to the learning of local\nCNN-like features in early ViT blocks, improving generalization for tail\nclasses. Further, to mitigate overfitting, we propose distilling from a flat\nCNN teacher, which leads to learning low-rank generalizable features for DIST\ntokens across all ViT blocks. With the proposed DeiT-LT scheme, the\ndistillation DIST token becomes an expert on the tail classes, and the\nclassifier CLS token becomes an expert on the head classes. The experts help to\neffectively learn features corresponding to both the majority and minority\nclasses using a distinct set of tokens within the same ViT architecture. We\nshow the effectiveness of DeiT-LT for training ViT from scratch on datasets\nranging from small-scale CIFAR-10 LT to large-scale iNaturalist-2018.",
      "tldr_zh": "本研究提出DeiT-LT方法，用于从零训练Vision Transformer (ViT)模型在长尾数据集上，以解决ViT缺乏归纳偏差（如局部性）的问题。DeiT-LT通过引入DIST token进行CNN知识蒸馏，利用out-of-distribution图像和重新加权损失函数，增强对尾部类的关注，从而在ViT早期块中学习类似CNN的局部特征，并从平坦CNN教师模型中蒸馏低秩可泛化特征以减少过拟合。结果，DIST token专攻尾部类，CLS token专攻头部类，实现同一ViT架构内对多数和少数类的有效特征学习，实验在CIFAR-10 LT和iNaturalist-2018等数据集上证明其有效性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "CVPR 2024. Project Page: https://rangwani-harsh.github.io/DeiT-LT",
      "pdf_url": "http://arxiv.org/pdf/2404.02900v1",
      "published_date": "2024-04-03 17:58:21 UTC",
      "updated_date": "2024-04-03 17:58:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T21:20:53.130722"
    },
    {
      "arxiv_id": "2404.02949v1",
      "title": "The SaTML '24 CNN Interpretability Competition: New Innovations for Concept-Level Interpretability",
      "title_zh": "翻译失败",
      "authors": [
        "Stephen Casper",
        "Jieun Yun",
        "Joonhyuk Baek",
        "Yeseong Jung",
        "Minhwan Kim",
        "Kiwan Kwon",
        "Saerom Park",
        "Hayden Moore",
        "David Shriver",
        "Marissa Connor",
        "Keltin Grimes",
        "Angus Nicolson",
        "Arush Tagade",
        "Jessica Rumbelow",
        "Hieu Minh Nguyen",
        "Dylan Hadfield-Menell"
      ],
      "abstract": "Interpretability techniques are valuable for helping humans understand and\noversee AI systems. The SaTML 2024 CNN Interpretability Competition solicited\nnovel methods for studying convolutional neural networks (CNNs) at the ImageNet\nscale. The objective of the competition was to help human crowd-workers\nidentify trojans in CNNs. This report showcases the methods and results of four\nfeatured competition entries. It remains challenging to help humans reliably\ndiagnose trojans via interpretability tools. However, the competition's entries\nhave contributed new techniques and set a new record on the benchmark from\nCasper et al., 2023.",
      "tldr_zh": "该 SaTML '24 CNN Interpretability Competition 聚焦于开发新型概念级可解释性方法，帮助人类通过解释工具识别 CNN 中的 trojans。竞赛征求了针对 ImageNet 规模 CNN 的创新技术，并展示了四个特色参赛作品，这些作品引入了新的可解释性技巧。结果显示，虽然帮助人类可靠诊断 trojans 仍面临挑战，但这些参赛作品在 Casper et al., 2023 的基准上设定了新记录，推动了 AI 系统可解释性和 oversight 的进步。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Competition for SaTML 2024",
      "pdf_url": "http://arxiv.org/pdf/2404.02949v1",
      "published_date": "2024-04-03 17:56:28 UTC",
      "updated_date": "2024-04-03 17:56:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T21:21:02.319958"
    },
    {
      "arxiv_id": "2404.02883v1",
      "title": "On the Scalability of Diffusion-based Text-to-Image Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Hao Li",
        "Yang Zou",
        "Ying Wang",
        "Orchid Majumder",
        "Yusheng Xie",
        "R. Manmatha",
        "Ashwin Swaminathan",
        "Zhuowen Tu",
        "Stefano Ermon",
        "Stefano Soatto"
      ],
      "abstract": "Scaling up model and data size has been quite successful for the evolution of\nLLMs. However, the scaling law for the diffusion based text-to-image (T2I)\nmodels is not fully explored. It is also unclear how to efficiently scale the\nmodel for better performance at reduced cost. The different training settings\nand expensive training cost make a fair model comparison extremely difficult.\nIn this work, we empirically study the scaling properties of diffusion based\nT2I models by performing extensive and rigours ablations on scaling both\ndenoising backbones and training set, including training scaled UNet and\nTransformer variants ranging from 0.4B to 4B parameters on datasets upto 600M\nimages. For model scaling, we find the location and amount of cross attention\ndistinguishes the performance of existing UNet designs. And increasing the\ntransformer blocks is more parameter-efficient for improving text-image\nalignment than increasing channel numbers. We then identify an efficient UNet\nvariant, which is 45% smaller and 28% faster than SDXL's UNet. On the data\nscaling side, we show the quality and diversity of the training set matters\nmore than simply dataset size. Increasing caption density and diversity\nimproves text-image alignment performance and the learning efficiency. Finally,\nwe provide scaling functions to predict the text-image alignment performance as\nfunctions of the scale of model size, compute and dataset size.",
      "tldr_zh": "本研究探讨了基于扩散模型的文本到图像 (T2I) 生成的可扩展性，旨在通过模型和数据缩放来提升性能并降低成本。研究者进行了广泛的消融实验，包括训练从 0.4B 到 4B 参数的 UNet 和 Transformer 变体，使用高达 600M 图像的数据集。关键发现包括：cross attention 的位置和数量显著影响 UNet 性能，增加 transformer blocks 比增加 channel numbers 更高效地改善 text-image alignment；此外，他们识别了一个高效 UNet 变体，比 SDXL 的 UNet 小 45% 并快 28%。在数据方面，训练集的质量和多样性（如 caption density 和 diversity）比单纯的大小更重要，最终提供了缩放函数来预测 text-image alignment 性能。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "CVPR2024",
      "pdf_url": "http://arxiv.org/pdf/2404.02883v1",
      "published_date": "2024-04-03 17:34:28 UTC",
      "updated_date": "2024-04-03 17:34:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T21:21:15.352387"
    },
    {
      "arxiv_id": "2404.02877v4",
      "title": "FlightScope: An Experimental Comparative Review of Aircraft Detection Algorithms in Satellite Imagery",
      "title_zh": "翻译失败",
      "authors": [
        "Safouane El Ghazouali",
        "Arnaud Gucciardi",
        "Francesca Venturini",
        "Nicola Venturi",
        "Michael Rueegsegger",
        "Umberto Michelucci"
      ],
      "abstract": "Object detection in remotely sensed satellite pictures is fundamental in many\nfields such as biophysical, and environmental monitoring. While deep learning\nalgorithms are constantly evolving, they have been mostly implemented and\ntested on popular ground-based taken photos. This paper critically evaluates\nand compares a suite of advanced object detection algorithms customized for the\ntask of identifying aircraft within satellite imagery. Using the large\nHRPlanesV2 dataset, together with a rigorous validation with the GDIT dataset,\nthis research encompasses an array of methodologies including YOLO versions 5\nand 8, Faster RCNN, CenterNet, RetinaNet, RTMDet, and DETR, all trained from\nscratch. This exhaustive training and validation study reveal YOLOv5 as the\npreeminent model for the specific case of identifying airplanes from remote\nsensing data, showcasing high precision and adaptability across diverse imaging\nconditions. This research highlight the nuanced performance landscapes of these\nalgorithms, with YOLOv5 emerging as a robust solution for aerial object\ndetection, underlining its importance through superior mean average precision,\nRecall, and Intersection over Union scores. The findings described here\nunderscore the fundamental role of algorithm selection aligned with the\nspecific demands of satellite imagery analysis and extend a comprehensive\nframework to evaluate model efficacy. The benchmark toolkit and codes,\navailable via https://github.com/toelt-llc/FlightScope_Bench, aims to further\nexploration and innovation in the realm of remote sensing object detection,\npaving the way for improved analytical methodologies in satellite imagery\napplications.",
      "tldr_zh": "本研究对卫星图像中飞机检测算法进行了实验性比较评估，聚焦于物体检测在遥感领域的应用。研究者使用 HRPlanesV2 数据集训练并通过 GDIT 数据集验证了一系列算法，包括 YOLO v5 和 v8、Faster RCNN、CenterNet、RetinaNet、RTMDet 和 DETR，所有模型均从零开始训练。结果显示，YOLOv5 在识别飞机方面表现出色，具有最高的 mean average precision、Recall 和 Intersection over Union 分数，并展示了良好的适应性。论文提供了开源基准工具（https://github.com/toelt-llc/FlightScope_Bench），强调了算法选择与卫星图像分析需求的匹配，为遥感物体检测的创新提供了框架。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "I.2.1; I.2.6; I.2.10"
      ],
      "primary_category": "cs.CV",
      "comment": "16 figures, 5 tables, comprehensive survey, comparative study",
      "pdf_url": "http://arxiv.org/pdf/2404.02877v4",
      "published_date": "2024-04-03 17:24:27 UTC",
      "updated_date": "2024-12-17 20:58:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T21:21:26.145245"
    },
    {
      "arxiv_id": "2404.02872v1",
      "title": "Integrating Explanations in Learning LTL Specifications from Demonstrations",
      "title_zh": "翻译失败",
      "authors": [
        "Ashutosh Gupta",
        "John Komp",
        "Abhay Singh Rajput",
        "Krishna Shankaranarayanan",
        "Ashutosh Trivedi",
        "Namrita Varshney"
      ],
      "abstract": "This paper investigates whether recent advances in Large Language Models\n(LLMs) can assist in translating human explanations into a format that can\nrobustly support learning Linear Temporal Logic (LTL) from demonstrations. Both\nLLMs and optimization-based methods can extract LTL specifications from\ndemonstrations; however, they have distinct limitations. LLMs can quickly\ngenerate solutions and incorporate human explanations, but their lack of\nconsistency and reliability hampers their applicability in safety-critical\ndomains. On the other hand, optimization-based methods do provide formal\nguarantees but cannot process natural language explanations and face\nscalability challenges. We present a principled approach to combining LLMs and\noptimization-based methods to faithfully translate human explanations and\ndemonstrations into LTL specifications. We have implemented a tool called\nJanaka based on our approach. Our experiments demonstrate the effectiveness of\ncombining explanations with demonstrations in learning LTL specifications\nthrough several case studies.",
      "tldr_zh": "这篇论文探讨了如何利用 Large Language Models (LLMs) 将人类解释转化为可支持从演示中学习 Linear Temporal Logic (LTL) 规范的格式，以克服 LLMs 的不一致性和优化-based 方法的可伸缩性挑战。论文提出了一种原则性方法，将 LLMs 用于处理自然语言解释，并与优化-based 方法结合，提供正式保证并实现可靠的规范学习。他们开发了名为 Janaka 的工具，并通过多个案例研究实验证明，这种整合解释和演示的方法在学习 LTL 规范方面高度有效。",
      "categories": [
        "cs.AI",
        "I.2.8"
      ],
      "primary_category": "cs.AI",
      "comment": "21 Pages, 13 Page Appendix",
      "pdf_url": "http://arxiv.org/pdf/2404.02872v1",
      "published_date": "2024-04-03 17:09:00 UTC",
      "updated_date": "2024-04-03 17:09:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T21:21:40.173767"
    },
    {
      "arxiv_id": "2404.02869v1",
      "title": "Human Activity Recognition using Smartphones",
      "title_zh": "翻译失败",
      "authors": [
        "Mayur Sonawane",
        "Sahil Rajesh Dhayalkar",
        "Siddesh Waje",
        "Soyal Markhelkar",
        "Akshay Wattamwar",
        "Seema C. Shrawne"
      ],
      "abstract": "Human Activity Recognition is a subject of great research today and has its\napplications in remote healthcare, activity tracking of the elderly or the\ndisables, calories burnt tracking etc. In our project, we have created an\nAndroid application that recognizes the daily human activities and calculate\nthe calories burnt in real time. We first captured labeled triaxial\nacceleration readings for different daily human activities from the\nsmartphone's embedded accelerometer. These readings were preprocessed using a\nmedian filter. 42 features were extracted using various methods. We then tested\nvarious machine learning algorithms along with dimensionality reduction.\nFinally, in our Android application, we used the machine learning algorithm and\na subset of features that provided maximum accuracy and minimum model building\ntime. This is used for real-time activity recognition and calculation of\ncalories burnt using a formula based on Metabolic Equivalent.",
      "tldr_zh": "该研究聚焦于 Human Activity Recognition，使用智能手机加速计识别日常人类活动，并应用于远程医疗和卡路里追踪等领域。研究团队开发了一个 Android application，通过捕获并标注 triaxial acceleration readings，然后使用 median filter 进行预处理，并提取 42 个特征。接着，他们测试了各种 machine learning algorithms 结合 dimensionality reduction，以选择提供最大准确率和最小模型构建时间的子集。最后，该应用实现了实时活动识别，并基于 Metabolic Equivalent 的公式计算卡路里消耗，展示了智能手机在活动监测中的潜力。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.02869v1",
      "published_date": "2024-04-03 17:05:41 UTC",
      "updated_date": "2024-04-03 17:05:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T21:21:50.133843"
    },
    {
      "arxiv_id": "2404.02838v1",
      "title": "I-Design: Personalized LLM Interior Designer",
      "title_zh": "I-Design：个性化的 LLM 室内设计师",
      "authors": [
        "Ata Çelen",
        "Guo Han",
        "Konrad Schindler",
        "Luc Van Gool",
        "Iro Armeni",
        "Anton Obukhov",
        "Xi Wang"
      ],
      "abstract": "Interior design allows us to be who we are and live how we want - each design\nis as unique as our distinct personality. However, it is not trivial for\nnon-professionals to express and materialize this since it requires aligning\nfunctional and visual expectations with the constraints of physical space; this\nrenders interior design a luxury. To make it more accessible, we present\nI-Design, a personalized interior designer that allows users to generate and\nvisualize their design goals through natural language communication. I-Design\nstarts with a team of large language model agents that engage in dialogues and\nlogical reasoning with one another, transforming textual user input into\nfeasible scene graph designs with relative object relationships. Subsequently,\nan effective placement algorithm determines optimal locations for each object\nwithin the scene. The final design is then constructed in 3D by retrieving and\nintegrating assets from an existing object database. Additionally, we propose a\nnew evaluation protocol that utilizes a vision-language model and complements\nthe design pipeline. Extensive quantitative and qualitative experiments show\nthat I-Design outperforms existing methods in delivering high-quality 3D design\nsolutions and aligning with abstract concepts that match user input, showcasing\nits advantages across detailed 3D arrangement and conceptual fidelity.",
      "tldr_zh": "该论文提出 I-Design，一种基于 LLM（Large Language Model）的个性化室内设计系统，旨在通过自然语言交互让非专业用户轻松生成和可视化设计方案。系统由一组 LLM 代理进行对话和逻辑推理，将用户文本输入转化为可行的 scene graph designs，并使用 placement algorithm 优化物体在场景中的位置，最终通过现有 object database 构建 3D 设计。论文还引入了一个新的评估协议，利用 vision-language model 进行评估；实验结果显示，I-Design 在 3D 安排质量和用户输入概念忠实性方面显著优于现有方法。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.02838v1",
      "published_date": "2024-04-03 16:17:53 UTC",
      "updated_date": "2024-04-03 16:17:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T21:22:03.257644"
    },
    {
      "arxiv_id": "2404.02831v2",
      "title": "Empowering Biomedical Discovery with AI Agents",
      "title_zh": "AI代理赋能生物医学发现",
      "authors": [
        "Shanghua Gao",
        "Ada Fang",
        "Yepeng Huang",
        "Valentina Giunchiglia",
        "Ayush Noori",
        "Jonathan Richard Schwarz",
        "Yasha Ektefaie",
        "Jovana Kondic",
        "Marinka Zitnik"
      ],
      "abstract": "We envision \"AI scientists\" as systems capable of skeptical learning and\nreasoning that empower biomedical research through collaborative agents that\nintegrate AI models and biomedical tools with experimental platforms. Rather\nthan taking humans out of the discovery process, biomedical AI agents combine\nhuman creativity and expertise with AI's ability to analyze large datasets,\nnavigate hypothesis spaces, and execute repetitive tasks. AI agents are poised\nto be proficient in various tasks, planning discovery workflows and performing\nself-assessment to identify and mitigate gaps in their knowledge. These agents\nuse large language models and generative models to feature structured memory\nfor continual learning and use machine learning tools to incorporate scientific\nknowledge, biological principles, and theories. AI agents can impact areas\nranging from virtual cell simulation, programmable control of phenotypes, and\nthe design of cellular circuits to developing new therapies.",
      "tldr_zh": "本文提出“AI scientists”概念，即通过整合 AI 模型、生物医学工具和实验平台的协作代理，来赋能生物医学研究，这些代理结合人类创造力和专业知识，利用 AI 处理大数据、导航假设空间并执行重复任务。AI agents 采用大型 language models 和生成模型，配备结构化记忆以实现持续学习，并通过机器学习工具融入科学知识和生物原理，以规划发现工作流程并进行自我评估。最终，这种方法有望影响多个领域，如虚拟细胞模拟、可编程控制表型、细胞电路设计和新疗法开发。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.02831v2",
      "published_date": "2024-04-03 16:08:01 UTC",
      "updated_date": "2024-07-24 20:31:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T21:22:15.833117"
    },
    {
      "arxiv_id": "2404.02830v2",
      "title": "Enhancing Interpretability of Vertebrae Fracture Grading using Human-interpretable Prototypes",
      "title_zh": "使用人类可解释原型增强椎体骨折分级可解释性",
      "authors": [
        "Poulami Sinhamahapatra",
        "Suprosanna Shit",
        "Anjany Sekuboyina",
        "Malek Husseini",
        "David Schinz",
        "Nicolas Lenhart",
        "Joern Menze",
        "Jan Kirschke",
        "Karsten Roscher",
        "Stephan Guennemann"
      ],
      "abstract": "Vertebral fracture grading classifies the severity of vertebral fractures,\nwhich is a challenging task in medical imaging and has recently attracted Deep\nLearning (DL) models. Only a few works attempted to make such models\nhuman-interpretable despite the need for transparency and trustworthiness in\ncritical use cases like DL-assisted medical diagnosis. Moreover, such models\neither rely on post-hoc methods or additional annotations. In this work, we\npropose a novel interpretable-by-design method, ProtoVerse, to find relevant\nsub-parts of vertebral fractures (prototypes) that reliably explain the model's\ndecision in a human-understandable way. Specifically, we introduce a novel\ndiversity-promoting loss to mitigate prototype repetitions in small datasets\nwith intricate semantics. We have experimented with the VerSe'19 dataset and\noutperformed the existing prototype-based method. Further, our model provides\nsuperior interpretability against the post-hoc method. Importantly, expert\nradiologists validated the visual interpretability of our results, showing\nclinical applicability.",
      "tldr_zh": "本研究针对椎体骨折分级在医学成像中的挑战，提出了一种新型可解释设计方法ProtoVerse，利用人类可解释的原型（Human-interpretable Prototypes）来识别椎体骨折的相关子部分，从而以可理解方式解释Deep Learning (DL)模型的决策。方法中引入了促进多样性的损失函数，以缓解小数据集中的原型重复问题。实验在VerSe'19数据集上显示，ProtoVerse优于现有基于原型的基准方法，并在可解释性上超越post-hoc方法。专家放射科医生验证了其结果的可视化可解释性，证明了该方法的临床适用性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted for publication at the Journal of Machine Learning for\n  Biomedical Imaging (MELBA) https://melba-journal.org/2024:015",
      "pdf_url": "http://arxiv.org/pdf/2404.02830v2",
      "published_date": "2024-04-03 16:04:59 UTC",
      "updated_date": "2024-07-31 12:34:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T21:22:29.269758"
    },
    {
      "arxiv_id": "2404.02823v1",
      "title": "Conifer: Improving Complex Constrained Instruction-Following Ability of Large Language Models",
      "title_zh": "Conifer: 提升大型语言模型的复杂约束指令跟随能力",
      "authors": [
        "Haoran Sun",
        "Lixin Liu",
        "Junjie Li",
        "Fengyu Wang",
        "Baohua Dong",
        "Ran Lin",
        "Ruohui Huang"
      ],
      "abstract": "The ability of large language models (LLMs) to follow instructions is crucial\nto real-world applications. Despite recent advances, several studies have\nhighlighted that LLMs struggle when faced with challenging instructions,\nespecially those that include complex constraints, hindering their\neffectiveness in various tasks. To address this challenge, we introduce\nConifer, a novel instruction tuning dataset, designed to enhance LLMs to follow\nmulti-level instructions with complex constraints. Utilizing GPT-4, we curate\nthe dataset by a series of LLM-driven refinement processes to ensure high\nquality. We also propose a progressive learning scheme that emphasizes an\neasy-to-hard progression, and learning from process feedback. Models trained\nwith Conifer exhibit remarkable improvements in instruction-following\nabilities, especially for instructions with complex constraints. On several\ninstruction-following benchmarks, our 7B model outperforms the state-of-the-art\nopen-source 7B models, even exceeds the performance of models 10 times larger\non certain metrics. All the code and Conifer dataset are available at\nhttps://www.github.com/ConiferLM/Conifer.",
      "tldr_zh": "该研究针对大型语言模型（LLMs）在处理复杂约束指令时的不足，引入了Conifer数据集，以提升模型的多级指令遵循能力。Conifer通过GPT-4驱动的一系列精炼过程构建而成，并结合渐进式学习方案，从简单到复杂逐步训练，并利用过程反馈优化学习。实验结果显示，使用Conifer训练的7B模型在多个指令遵循基准上显著超越最先进的开源7B模型，甚至在某些指标上超过了10倍规模的模型。数据集和代码已在GitHub上公开，可供进一步研究。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.02823v1",
      "published_date": "2024-04-03 15:55:39 UTC",
      "updated_date": "2024-04-03 15:55:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T21:22:39.616834"
    },
    {
      "arxiv_id": "2404.02817v5",
      "title": "A Survey of Optimization-based Task and Motion Planning: From Classical To Learning Approaches",
      "title_zh": "基于优化的任务和运动规划的综述：从经典方法到学习方法",
      "authors": [
        "Zhigen Zhao",
        "Shuo Cheng",
        "Yan Ding",
        "Ziyi Zhou",
        "Shiqi Zhang",
        "Danfei Xu",
        "Ye Zhao"
      ],
      "abstract": "Task and Motion Planning (TAMP) integrates high-level task planning and\nlow-level motion planning to equip robots with the autonomy to effectively\nreason over long-horizon, dynamic tasks. Optimization-based TAMP focuses on\nhybrid optimization approaches that define goal conditions via objective\nfunctions and are capable of handling open-ended goals, robotic dynamics, and\nphysical interaction between the robot and the environment. Therefore,\noptimization-based TAMP is particularly suited to solve highly complex,\ncontact-rich locomotion and manipulation problems. This survey provides a\ncomprehensive review on optimization-based TAMP, covering (i) planning domain\nrepresentations, including action description languages and temporal logic,\n(ii) individual solution strategies for components of TAMP, including AI\nplanning and trajectory optimization (TO), and (iii) the dynamic interplay\nbetween logic-based task planning and model-based TO. A particular focus of\nthis survey is to highlight the algorithm structures to efficiently solve TAMP,\nespecially hierarchical and distributed approaches. Additionally, the survey\nemphasizes the synergy between the classical methods and contemporary\nlearning-based innovations such as large language models. Furthermore, the\nfuture research directions for TAMP is discussed in this survey, highlighting\nboth algorithmic and application-specific challenges.",
      "tldr_zh": "这篇调查综述探讨了基于优化的Task and Motion Planning (TAMP)，它整合高层任务规划和底层运动规划，帮助机器人处理长期动态任务。论文回顾了优化-based TAMP的关键方面，包括规划领域表示（如行动描述语言和时序逻辑）、解决方案策略（如AI planning和trajectory optimization (TO)）、以及逻辑-based任务规划与模型-based TO的动态互动。特别强调了高效算法结构（如分层和分布式方法）和经典方法与学习-based创新（如large language models）的协同，并指出了未来研究方向，包括算法挑战和应用特定问题。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "26 pages, 13 figures, published at IEEE/ASME Transactions on\n  Mechatronics",
      "pdf_url": "http://arxiv.org/pdf/2404.02817v5",
      "published_date": "2024-04-03 15:38:36 UTC",
      "updated_date": "2024-10-07 10:09:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T21:22:51.680623"
    },
    {
      "arxiv_id": "2404.02807v3",
      "title": "An Optimization Framework to Personalize Passive Cardiac Mechanics",
      "title_zh": "一种个性化被动心脏力学的优化框架",
      "authors": [
        "Lei Shi",
        "Ian Chen",
        "Hiroo Takayama",
        "Vijay Vedula"
      ],
      "abstract": "Personalized cardiac mechanics modeling is a powerful tool for understanding\nthe biomechanics of cardiac function in health and disease and assisting in\ntreatment planning. However, current models are limited to using medical images\nacquired at a single cardiac phase, often limiting their applicability for\nprocessing dynamic image acquisitions. This study introduces an inverse finite\nelement analysis (iFEA) framework to estimate the passive mechanical properties\nof cardiac tissue using time-dependent medical image data. The iFEA framework\nrelies on a novel nested optimization scheme, in which the outer iterations\nutilize a traditional optimization method to best approximate material\nparameters that fit image data, while the inner iterations employ an augmented\nSellier's algorithm to estimate the stress-free reference configuration. With a\nfocus on characterizing the passive mechanical behavior, the framework employs\nstructurally based anisotropic hyperelastic constitutive models and\nphysiologically relevant boundary conditions to simulate myocardial mechanics.\nWe use a stabilized variational multiscale formulation for solving the\ngoverning nonlinear elastodynamics equations, verified for cardiac mechanics\napplications. The framework is tested in myocardium models of biventricle and\nleft atrium derived from cardiac phase-resolved computed tomographic (CT)\nimages of a healthy subject and three patients with hypertrophic obstructive\ncardiomyopathy (HOCM). The impact of the choice of optimization methods and\nother numerical settings, including fiber direction parameters, mesh size,\ninitial parameters for optimization, and perturbations to optimal material\nparameters, is assessed using a rigorous sensitivity analysis. The performance\nof the current iFEA is compared against an assumed power-law-based\npressure-volume relation, typically used for single-phase image acquisition.",
      "tldr_zh": "该研究提出了一种逆有限元分析(iFEA)框架，用于个性化心脏被动机械建模，通过利用时间相关的医学图像数据，克服了传统模型仅依赖单相图像的局限性。框架采用嵌套优化方案，外层优化材料参数以拟合图像数据，内层使用增强的Sellier's算法估计无应力参考配置，并结合结构化各向异性超弹性本构模型和生理边界条件模拟心肌力学。实验在健康受试者和肥厚性梗阻性心肌病(HOCM)患者的双心室和左心房模型上进行，显示了框架的鲁棒性，并通过敏感性分析评估了优化方法、纤维方向参数和网格大小等因素的影响。相比基于power-law的压力-体积关系方法，iFEA框架显著提高了动态图像处理的准确性和适用性。",
      "categories": [
        "physics.med-ph",
        "cs.AI"
      ],
      "primary_category": "physics.med-ph",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.02807v3",
      "published_date": "2024-04-03 15:23:17 UTC",
      "updated_date": "2024-04-06 03:24:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T21:23:04.369077"
    },
    {
      "arxiv_id": "2404.02806v2",
      "title": "The RealHumanEval: Evaluating Large Language Models' Abilities to Support Programmers",
      "title_zh": "RealHumanEval：评估大语言模型支持程序员的能力",
      "authors": [
        "Hussein Mozannar",
        "Valerie Chen",
        "Mohammed Alsobay",
        "Subhro Das",
        "Sebastian Zhao",
        "Dennis Wei",
        "Manish Nagireddy",
        "Prasanna Sattigeri",
        "Ameet Talwalkar",
        "David Sontag"
      ],
      "abstract": "Evaluation of large language models for code has primarily relied on static\nbenchmarks, including HumanEval (Chen et al., 2021), or more recently using\nhuman preferences of LLM responses. As LLMs are increasingly used as programmer\nassistants, we study whether gains on existing benchmarks or more preferred LLM\nresponses translate to programmer productivity when coding with LLMs, including\ntime spent coding. We introduce RealHumanEval, a web interface to measure the\nability of LLMs to assist programmers, through either autocomplete or chat\nsupport. We conducted a user study (N=243) using RealHumanEval in which users\ninteracted with seven LLMs of varying base model performance. Despite static\nbenchmarks not incorporating humans-in-the-loop, we find that improvements in\nbenchmark performance lead to increased programmer productivity; however gaps\nin benchmark versus human performance are not proportional -- a trend that\nholds across both forms of LLM support. In contrast, we find that programmer\npreferences do not correlate with their actual performance, motivating the need\nfor better proxy signals. We open-source RealHumanEval to enable human-centric\nevaluation of new models and the study data to facilitate efforts to improve\ncode models.",
      "tldr_zh": "这篇论文引入了 RealHumanEval，一种网络界面，用于评估 Large Language Models (LLMs) 在辅助程序员方面的能力，包括自动完成和聊天支持。研究者通过一项涉及 243 名用户的实验，比较了七个不同性能的 LLMs，发现静态基准（如 HumanEval）的改进确实能提升程序员的生产力，但基准表现与实际人类性能之间的差距并不成比例。结果显示，程序员对 LLMs 的偏好与实际表现无关，因此需要开发更好的代理信号。最后，论文开源了 RealHumanEval 工具和研究数据，以促进人类中心的新模型评估。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.02806v2",
      "published_date": "2024-04-03 15:20:57 UTC",
      "updated_date": "2024-10-14 23:06:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T21:23:17.011997"
    },
    {
      "arxiv_id": "2404.15319v1",
      "title": "The largest EEG-based BCI reproducibility study for open science: the MOABB benchmark",
      "title_zh": "翻译失败",
      "authors": [
        "Sylvain Chevallier",
        "Igor Carrara",
        "Bruno Aristimunha",
        "Pierre Guetschel",
        "Sara Sedlar",
        "Bruna Lopes",
        "Sebastien Velut",
        "Salim Khazem",
        "Thomas Moreau"
      ],
      "abstract": "Objective. This study conduct an extensive Brain-computer interfaces (BCI)\nreproducibility analysis on open electroencephalography datasets, aiming to\nassess existing solutions and establish open and reproducible benchmarks for\neffective comparison within the field. The need for such benchmark lies in the\nrapid industrial progress that has given rise to undisclosed proprietary\nsolutions. Furthermore, the scientific literature is dense, often featuring\nchallenging-to-reproduce evaluations, making comparisons between existing\napproaches arduous.\n  Approach. Within an open framework, 30 machine learning pipelines (separated\ninto raw signal: 11, Riemannian: 13, deep learning: 6) are meticulously\nre-implemented and evaluated across 36 publicly available datasets, including\nmotor imagery (14), P300 (15), and SSVEP (7). The analysis incorporates\nstatistical meta-analysis techniques for results assessment, encompassing\nexecution time and environmental impact considerations.\n  Main results. The study yields principled and robust results applicable to\nvarious BCI paradigms, emphasizing motor imagery, P300, and SSVEP. Notably,\nRiemannian approaches utilizing spatial covariance matrices exhibit superior\nperformance, underscoring the necessity for significant data volumes to achieve\ncompetitive outcomes with deep learning techniques. The comprehensive results\nare openly accessible, paving the way for future research to further enhance\nreproducibility in the BCI domain.\n  Significance. The significance of this study lies in its contribution to\nestablishing a rigorous and transparent benchmark for BCI research, offering\ninsights into optimal methodologies and highlighting the importance of\nreproducibility in driving advancements within the field.",
      "tldr_zh": "本研究进行了最大规模的基于EEG的脑机接口(BCI)可重复性分析，通过MOABB基准评估现有解决方案，并在36个公开数据集上（包括运动想象(motor imagery)14个、P300 15个和SSVEP 7个）重新实现了30个机器学习管道（涵盖原始信号、Riemannian和深度学习方法）。结果显示，Riemannian方法利用空间协方差矩阵表现出色，而深度学习技术需依赖大量数据才能竞争；该分析还纳入了统计元分析、执行时间和环境影响评估，以确保结果的稳健性。研究意义在于建立开放透明的BCI基准，促进领域内方法的有效比较和未来创新。",
      "categories": [
        "eess.SP",
        "cs.AI",
        "cs.HC",
        "cs.LG",
        "q-bio.NC"
      ],
      "primary_category": "eess.SP",
      "comment": "43 pages, 13 figures, 5 tables",
      "pdf_url": "http://arxiv.org/pdf/2404.15319v1",
      "published_date": "2024-04-03 15:18:50 UTC",
      "updated_date": "2024-04-03 15:18:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T21:23:28.537859"
    },
    {
      "arxiv_id": "2404.02800v1",
      "title": "On Few-Shot Prompting for Controllable Question-Answer Generation in Narrative Comprehension",
      "title_zh": "翻译失败",
      "authors": [
        "Bernardo Leite",
        "Henrique Lopes Cardoso"
      ],
      "abstract": "Question Generation aims to automatically generate questions based on a given\ninput provided as context. A controllable question generation scheme focuses on\ngenerating questions with specific attributes, allowing better control. In this\nstudy, we propose a few-shot prompting strategy for controlling the generation\nof question-answer pairs from children's narrative texts. We aim to control two\nattributes: the question's explicitness and underlying narrative elements. With\nempirical evaluation, we show the effectiveness of controlling the generation\nprocess by employing few-shot prompting side by side with a reference model.\nOur experiments highlight instances where the few-shot strategy surpasses the\nreference model, particularly in scenarios such as semantic closeness\nevaluation and the diversity and coherency of question-answer pairs. However,\nthese improvements are not always statistically significant. The code is\npublicly available at github.com/bernardoleite/few-shot-prompting-qg-control.",
      "tldr_zh": "本研究探讨了可控问题生成（Question Generation），提出了一种 few-shot prompting 策略，用于从儿童叙事文本生成问题-答案对，并控制两个属性：问题的 explicitness 和 narrative elements。实验结果显示，该策略与参考模型相比，在语义接近度、问题-答案对的多样性和连贯性等方面表现出色，有时甚至优于基准模型，尽管这些改进并非总是统计显著。该方法为可控生成任务提供了有效途径，并已在 GitHub 上公开代码。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Preprint - Accepted for publication at CSEDU 2024",
      "pdf_url": "http://arxiv.org/pdf/2404.02800v1",
      "published_date": "2024-04-03 15:17:21 UTC",
      "updated_date": "2024-04-03 15:17:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T21:23:39.440287"
    },
    {
      "arxiv_id": "2405.15778v1",
      "title": "Investigation of Energy-efficient AI Model Architectures and Compression Techniques for \"Green\" Fetal Brain Segmentation",
      "title_zh": "翻译失败",
      "authors": [
        "Szymon Mazurek",
        "Monika Pytlarz",
        "Sylwia Malec",
        "Alessandro Crimi"
      ],
      "abstract": "Artificial intelligence have contributed to advancements across various\nindustries. However, the rapid growth of artificial intelligence technologies\nalso raises concerns about their environmental impact, due to associated carbon\nfootprints to train computational models. Fetal brain segmentation in medical\nimaging is challenging due to the small size of the fetal brain and the limited\nimage quality of fast 2D sequences. Deep neural networks are a promising method\nto overcome this challenge. In this context, the construction of larger models\nrequires extensive data and computing power, leading to high energy\nconsumption. Our study aims to explore model architectures and compression\ntechniques that promote energy efficiency by optimizing the trade-off between\naccuracy and energy consumption through various strategies such as lightweight\nnetwork design, architecture search, and optimized distributed training tools.\nWe have identified several effective strategies including optimization of data\nloading, modern optimizers, distributed training strategy implementation, and\nreduced floating point operations precision usage with light model\narchitectures while tuning parameters according to available computer\nresources. Our findings demonstrate that these methods lead to satisfactory\nmodel performance with low energy consumption during deep neural network\ntraining for medical image segmentation.",
      "tldr_zh": "本文研究了能量高效的AI模型架构和压缩技术，以实现“绿色”胎儿脑分割，旨在解决深度神经网络训练中高能耗和碳足迹问题。研究探索了多种策略，包括轻量级网络设计、架构搜索、优化数据加载、现代优化器以及分布式训练和减少浮点运算精度，以平衡准确性和能耗。结果表明，这些方法在医疗图像分割任务中取得了满意的模型性能，同时显著降低了能量消耗。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV",
        "cs.LG",
        "cs.PF"
      ],
      "primary_category": "eess.IV",
      "comment": "Submitted to International Conference on Computational Science (ICCS)\n  2024",
      "pdf_url": "http://arxiv.org/pdf/2405.15778v1",
      "published_date": "2024-04-03 15:11:53 UTC",
      "updated_date": "2024-04-03 15:11:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T21:23:52.798509"
    },
    {
      "arxiv_id": "2404.02948v4",
      "title": "PiSSA: Principal Singular Values and Singular Vectors Adaptation of Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Fanxu Meng",
        "Zhaohui Wang",
        "Muhan Zhang"
      ],
      "abstract": "To parameter-efficiently fine-tune (PEFT) large language models (LLMs), the\nlow-rank adaptation (LoRA) method approximates the model changes $\\Delta W \\in\n\\mathbb{R}^{m \\times n}$ through the product of two matrices $A \\in\n\\mathbb{R}^{m \\times r}$ and $B \\in \\mathbb{R}^{r \\times n}$, where $r \\ll\n\\min(m, n)$, $A$ is initialized with Gaussian noise, and $B$ with zeros. LoRA\nfreezes the original model $W$ and updates the \"Noise & Zero\" adapter, which\nmay lead to slow convergence. To overcome this limitation, we introduce\nPrincipal Singular values and Singular vectors Adaptation (PiSSA). PiSSA shares\nthe same architecture as LoRA, but initializes the adaptor matrices $A$ and $B$\nwith the principal components of the original matrix $W$, and put the remaining\ncomponents into a residual matrix $W^{res} \\in \\mathbb{R}^{m \\times n}$ which\nis frozen during fine-tuning. Compared to LoRA, PiSSA updates the principal\ncomponents while freezing the \"residual\" parts, allowing faster convergence and\nenhanced performance. Comparative experiments of PiSSA and LoRA across 12\ndifferent models, ranging from 184M to 70B, encompassing 5 NLG and 8 NLU tasks,\nreveal that PiSSA consistently outperforms LoRA under identical experimental\nsetups. On the GSM8K benchmark, Mistral-7B fine-tuned with PiSSA achieves an\naccuracy of 72.86%, surpassing LoRA's 67.7% by 5.16%. Due to the same\narchitecture, PiSSA is also compatible with quantization to further reduce the\nmemory requirement of fine-tuning. Compared to QLoRA, QPiSSA exhibits smaller\nquantization errors in the initial stages. Fine-tuning LLaMA-3-70B on GSM8K,\nQPiSSA attains an accuracy of 86.05%, exceeding the performances of QLoRA at\n81.73%. Leveraging a fast SVD technique, PiSSA can be initialized in only a few\nseconds, presenting a negligible cost for transitioning from LoRA to PiSSA.\nCode is available at https://github.com/GraphPKU/PiSSA.",
      "tldr_zh": "本研究提出 PiSSA，一种改进低秩适配 (LoRA) 的方法，用于参数高效微调大语言模型 (LLMs)，通过使用原始矩阵的 principal singular values and singular vectors 初始化适配器矩阵 A 和 B，并将剩余组件放入冻结的 residual matrix，实现更快收敛和增强性能。与 LoRA 相比，PiSSA 在 12 个模型（从 184M 到 70B）和 13 个任务（包括 5 个 NLG 和 8 个 NLU）上表现出色，例如 Mistral-7B 在 GSM8K 基准上的准确率达到 72.86%，比 LoRA 的 67.7% 高 5.16%。此外，PiSSA 兼容量化技术，如与 QLoRA 相比，QPiSSA 在初始阶段显示更小的量化错误，并在 LLaMA-3-70B 上实现 86.05% 的 GSM8K 准确率；利用 fast SVD 技术，PiSSA 的初始化仅需几秒钟。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "NeurIPS 2024 spotlight",
      "pdf_url": "http://arxiv.org/pdf/2404.02948v4",
      "published_date": "2024-04-03 15:06:43 UTC",
      "updated_date": "2025-04-09 06:54:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T21:24:06.702789"
    },
    {
      "arxiv_id": "2404.02947v1",
      "title": "DNN Memory Footprint Reduction via Post-Training Intra-Layer Multi-Precision Quantization",
      "title_zh": "翻译失败",
      "authors": [
        "Behnam Ghavami",
        "Amin Kamjoo",
        "Lesley Shannon",
        "Steve Wilton"
      ],
      "abstract": "The imperative to deploy Deep Neural Network (DNN) models on\nresource-constrained edge devices, spurred by privacy concerns, has become\nincreasingly apparent. To facilitate the transition from cloud to edge\ncomputing, this paper introduces a technique that effectively reduces the\nmemory footprint of DNNs, accommodating the limitations of resource-constrained\nedge devices while preserving model accuracy. Our proposed technique, named\nPost-Training Intra-Layer Multi-Precision Quantization (PTILMPQ), employs a\npost-training quantization approach, eliminating the need for extensive\ntraining data. By estimating the importance of layers and channels within the\nnetwork, the proposed method enables precise bit allocation throughout the\nquantization process. Experimental results demonstrate that PTILMPQ offers a\npromising solution for deploying DNNs on edge devices with restricted memory\nresources. For instance, in the case of ResNet50, it achieves an accuracy of\n74.57\\% with a memory footprint of 9.5 MB, representing a 25.49\\% reduction\ncompared to previous similar methods, with only a minor 1.08\\% decrease in\naccuracy.",
      "tldr_zh": "本论文提出了一种后训练量化技术，名为 Post-Training Intra-Layer Multi-Precision Quantization (PTILMPQ)，旨在减少 DNN 模型的内存占用，以支持在资源受限的边缘设备上部署，同时保持模型准确性。\n该方法通过估计网络层和通道的重要性，实现精确的比特分配，而无需额外训练数据。\n实验结果显示，在 ResNet50 上，PTILMPQ 将内存占用降低 25.49% 至 9.5 MB，同时准确率仅下降 1.08%，达到 74.57%。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "The 25th International Symposium on Quality Electronic Design\n  (ISQED'24)",
      "pdf_url": "http://arxiv.org/pdf/2404.02947v1",
      "published_date": "2024-04-03 15:06:09 UTC",
      "updated_date": "2024-04-03 15:06:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T21:24:19.195897"
    },
    {
      "arxiv_id": "2404.02785v3",
      "title": "Domain Generalization through Meta-Learning: A Survey",
      "title_zh": "翻译失败",
      "authors": [
        "Arsham Gholamzadeh Khoee",
        "Yinan Yu",
        "Robert Feldt"
      ],
      "abstract": "Deep neural networks (DNNs) have revolutionized artificial intelligence but\noften lack performance when faced with out-of-distribution (OOD) data, a common\nscenario due to the inevitable domain shifts in real-world applications. This\nlimitation stems from the common assumption that training and testing data\nshare the same distribution--an assumption frequently violated in practice.\nDespite their effectiveness with large amounts of data and computational power,\nDNNs struggle with distributional shifts and limited labeled data, leading to\noverfitting and poor generalization across various tasks and domains.\nMeta-learning presents a promising approach by employing algorithms that\nacquire transferable knowledge across various tasks for fast adaptation,\neliminating the need to learn each task from scratch. This survey paper delves\ninto the realm of meta-learning with a focus on its contribution to domain\ngeneralization. We first clarify the concept of meta-learning for domain\ngeneralization and introduce a novel taxonomy based on the feature extraction\nstrategy and the classifier learning methodology, offering a granular view of\nmethodologies. Additionally, we present a decision graph to assist readers in\nnavigating the taxonomy based on data availability and domain shifts, enabling\nthem to select and develop a proper model tailored to their specific problem\nrequirements. Through an exhaustive review of existing methods and underlying\ntheories, we map out the fundamentals of the field. Our survey provides\npractical insights and an informed discussion on promising research directions.",
      "tldr_zh": "这篇调查论文探讨了深度神经网络(DNNs)在面对分布外(Out-of-Distribution, OOD)数据时的泛化挑战，强调了训练和测试数据分布差异导致的过拟合问题。论文提出 meta-learning 作为一种通过获取可转移知识来实现快速任务适应的解决方案，以提升 domain generalization。作者引入了一个基于特征提取策略和分类器学习方法的创新 taxonomy，并提供决策图，帮助根据数据可用性和域移位选择合适模型。通过全面回顾现有方法和理论，该论文为相关研究提供了实用见解和未来方向。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV",
        "cs.NE"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.02785v3",
      "published_date": "2024-04-03 14:55:17 UTC",
      "updated_date": "2024-08-22 13:57:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T21:24:31.727842"
    },
    {
      "arxiv_id": "2404.05746v2",
      "title": "Causality for Earth Science -- A Review on Time-series and Spatiotemporal Causality Methods",
      "title_zh": "翻译失败",
      "authors": [
        "Sahara Ali",
        "Uzma Hasan",
        "Xingyan Li",
        "Omar Faruque",
        "Akila Sampath",
        "Yiyi Huang",
        "Md Osman Gani",
        "Jianwu Wang"
      ],
      "abstract": "This survey paper covers the breadth and depth of time-series and\nspatiotemporal causality methods, and their applications in Earth Science. More\nspecifically, the paper presents an overview of causal discovery and causal\ninference, explains the underlying causal assumptions, and enlists evaluation\ntechniques and key terminologies of the domain area. The paper elicits the\nvarious state-of-the-art methods introduced for time-series and spatiotemporal\ncausal analysis along with their strengths and limitations. The paper further\ndescribes the existing applications of several methods for answering specific\nEarth Science questions such as extreme weather events, sea level rise,\nteleconnections etc. This survey paper can serve as a primer for Data Science\nresearchers interested in data-driven causal study as we share a list of\nresources, such as Earth Science datasets (synthetic, simulated and\nobservational data) and open source tools for causal analysis. It will equally\nbenefit the Earth Science community interested in taking an AI-driven approach\nto study the causality of different dynamic and thermodynamic processes as we\npresent the open challenges and opportunities in performing causality-based\nEarth Science study.",
      "tldr_zh": "这篇综述论文系统概述了time-series和spatiotemporal causality方法及其在地球科学中的应用，包括因果发现和因果推理的基本假设、评估技术和关键术语。论文讨论了各种最先进方法的优势与局限性，并阐述了这些方法在解决极端天气事件、海平面上升和teleconnections等具体问题的实际案例。最终，它为数据科学和地球科学研究者提供资源列表，如Earth Science数据集和开源工具，并指出现有的挑战和机会，以推动AI驱动的因果分析研究。",
      "categories": [
        "physics.data-an",
        "cs.AI",
        "cs.LG",
        "physics.ao-ph",
        "physics.geo-ph"
      ],
      "primary_category": "physics.data-an",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.05746v2",
      "published_date": "2024-04-03 14:33:23 UTC",
      "updated_date": "2024-08-30 21:51:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T21:24:43.322662"
    },
    {
      "arxiv_id": "2404.02945v1",
      "title": "Optimizing the Deployment of Tiny Transformers on Low-Power MCUs",
      "title_zh": "翻译失败",
      "authors": [
        "Victor J. B. Jung",
        "Alessio Burrello",
        "Moritz Scherer",
        "Francesco Conti",
        "Luca Benini"
      ],
      "abstract": "Transformer networks are rapidly becoming SotA in many fields, such as NLP\nand CV. Similarly to CNN, there is a strong push for deploying Transformer\nmodels at the extreme edge, ultimately fitting the tiny power budget and memory\nfootprint of MCUs. However, the early approaches in this direction are mostly\nad-hoc, platform, and model-specific. This work aims to enable and optimize the\nflexible, multi-platform deployment of encoder Tiny Transformers on commercial\nMCUs. We propose a complete framework to perform end-to-end deployment of\nTransformer models onto single and multi-core MCUs. Our framework provides an\noptimized library of kernels to maximize data reuse and avoid unnecessary data\nmarshaling operations into the crucial attention block. A novel MHSA inference\nschedule, named Fused-Weight Self-Attention, is introduced, fusing the linear\nprojection weights offline to further reduce the number of operations and\nparameters. Furthermore, to mitigate the memory peak reached by the computation\nof the attention map, we present a Depth-First Tiling scheme for MHSA. We\nevaluate our framework on three different MCU classes exploiting ARM and RISC-V\nISA, namely the STM32H7, the STM32L4, and GAP9 (RV32IMC-XpulpV2). We reach an\naverage of 4.79x and 2.0x lower latency compared to SotA libraries CMSIS-NN\n(ARM) and PULP-NN (RISC-V), respectively. Moreover, we show that our MHSA\ndepth-first tiling scheme reduces the memory peak by up to 6.19x, while the\nfused-weight attention can reduce the runtime by 1.53x, and number of\nparameters by 25%. We report significant improvements across several Tiny\nTransformers: for instance, when executing a transformer block for the task of\nradar-based hand-gesture recognition on GAP9, we achieve a latency of 0.14ms\nand energy consumption of 4.92 micro-joules, 2.32x lower than the SotA PULP-NN\nlibrary on the same platform.",
      "tldr_zh": "本研究针对Transformer网络在低功耗微控制器(MCUs)上的部署优化问题，提出一个完整的端到端框架，支持编码器Tiny Transformers在单核和多核MCUs上的灵活部署。该框架包括优化的内核库，以最大化数据重用，并引入Fused-Weight Self-Attention推理调度和Depth-First Tiling方案，分别减少操作参数和缓解MHSA模块的内存峰值。在STM32H7、STM32L4和GAP9等不同架构的MCUs上评估，结果显示，与SotA库CMSIS-NN和PULP-NN相比，延迟平均降低4.79x和2.0x；此外，Depth-First Tiling可减少内存峰值高达6.19x，Fused-Weight Self-Attention可将运行时降低1.53x和参数减少25%。这项工作显著提升了Tiny Transformers在边缘设备上的性能和能效，例如在GAP9上的雷达手势识别任务中，实现0.14ms延迟和4.92微焦耳能耗，比SotA低2.32x。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DC",
        "cs.PF"
      ],
      "primary_category": "cs.LG",
      "comment": "Pre-print manuscript submitted for review to the IEEE Transactions on\n  Computers",
      "pdf_url": "http://arxiv.org/pdf/2404.02945v1",
      "published_date": "2024-04-03 14:14:08 UTC",
      "updated_date": "2024-04-03 14:14:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T21:24:57.753862"
    },
    {
      "arxiv_id": "2404.02761v3",
      "title": "AQuA -- Combining Experts' and Non-Experts' Views To Assess Deliberation Quality in Online Discussions Using LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Maike Behrendt",
        "Stefan Sylvius Wagner",
        "Marc Ziegele",
        "Lena Wilms",
        "Anke Stoll",
        "Dominique Heinbach",
        "Stefan Harmeling"
      ],
      "abstract": "Measuring the quality of contributions in political online discussions is\ncrucial in deliberation research and computer science. Research has identified\nvarious indicators to assess online discussion quality, and with deep learning\nadvancements, automating these measures has become feasible. While some studies\nfocus on analyzing specific quality indicators, a comprehensive quality score\nincorporating various deliberative aspects is often preferred. In this work, we\nintroduce AQuA, an additive score that calculates a unified deliberative\nquality score from multiple indices for each discussion post. Unlike other\nsingular scores, AQuA preserves information on the deliberative aspects present\nin comments, enhancing model transparency. We develop adapter models for 20\ndeliberative indices, and calculate correlation coefficients between experts'\nannotations and the perceived deliberativeness by non-experts to weigh the\nindividual indices into a single deliberative score. We demonstrate that the\nAQuA score can be computed easily from pre-trained adapters and aligns well\nwith annotations on other datasets that have not be seen during training. The\nanalysis of experts' vs. non-experts' annotations confirms theoretical findings\nin the social science literature.",
      "tldr_zh": "这篇论文引入了 AQuA，一种使用 LLMs（大型语言模型）计算在线讨论审议质量的加权分数系统，通过整合专家和非专家的观点来评估多个审议指标。AQuA 采用加法分数方法，开发了 20 个审议指标的适配器模型，并根据专家标注与非专家感知的相关系数进行加权，从而保留了评论中的审议方面信息，提高模型透明度。主要实验结果显示，AQuA 分数与专家标注高度一致，并在未见训练数据集上表现出色，验证了社会科学文献中的理论发现。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.02761v3",
      "published_date": "2024-04-03 14:07:02 UTC",
      "updated_date": "2024-04-17 10:56:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T21:25:08.346216"
    },
    {
      "arxiv_id": "2404.02759v1",
      "title": "Unsupervised Occupancy Learning from Sparse Point Cloud",
      "title_zh": "翻译失败",
      "authors": [
        "Amine Ouasfi",
        "Adnane Boukhayma"
      ],
      "abstract": "Implicit Neural Representations have gained prominence as a powerful\nframework for capturing complex data modalities, encompassing a wide range from\n3D shapes to images and audio. Within the realm of 3D shape representation,\nNeural Signed Distance Functions (SDF) have demonstrated remarkable potential\nin faithfully encoding intricate shape geometry. However, learning SDFs from 3D\npoint clouds in the absence of ground truth supervision remains a very\nchallenging task. In this paper, we propose a method to infer occupancy fields\ninstead of SDFs as they are easier to learn from sparse inputs. We leverage a\nmargin-based uncertainty measure to differentially sample from the decision\nboundary of the occupancy function and supervise the sampled boundary points\nusing the input point cloud. We further stabilize the optimization process at\nthe early stages of the training by biasing the occupancy function towards\nminimal entropy fields while maximizing its entropy at the input point cloud.\nThrough extensive experiments and evaluations, we illustrate the efficacy of\nour proposed method, highlighting its capacity to improve implicit shape\ninference with respect to baselines and the state-of-the-art using synthetic\nand real data.",
      "tldr_zh": "该论文提出了一种无监督方法，用于从稀疏点云学习占用字段（occupancy fields），以克服 Neural Signed Distance Functions (SDF) 在缺乏地面真实监督时的学习挑战。方法利用基于边界的不确定性测量（margin-based uncertainty measure）对占用函数的决策边界进行差异化采样，并使用输入点云监督这些采样点。训练早期通过使占用函数偏向最小熵字段并在输入点云处最大化熵，来稳定优化过程。实验结果显示，该方法在合成和真实数据上显著提升了隐式形状推理的性能，优于基线和最先进模型。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.GR",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "CVPR 2024",
      "pdf_url": "http://arxiv.org/pdf/2404.02759v1",
      "published_date": "2024-04-03 14:05:39 UTC",
      "updated_date": "2024-04-03 14:05:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T21:25:19.771264"
    },
    {
      "arxiv_id": "2404.02755v1",
      "title": "DIBS: Enhancing Dense Video Captioning with Unlabeled Videos via Pseudo Boundary Enrichment and Online Refinement",
      "title_zh": "翻译失败",
      "authors": [
        "Hao Wu",
        "Huabin Liu",
        "Yu Qiao",
        "Xiao Sun"
      ],
      "abstract": "We present Dive Into the BoundarieS (DIBS), a novel pretraining framework for\ndense video captioning (DVC), that elaborates on improving the quality of the\ngenerated event captions and their associated pseudo event boundaries from\nunlabeled videos. By leveraging the capabilities of diverse large language\nmodels (LLMs), we generate rich DVC-oriented caption candidates and optimize\nthe corresponding pseudo boundaries under several meticulously designed\nobjectives, considering diversity, event-centricity, temporal ordering, and\ncoherence. Moreover, we further introduce a novel online boundary refinement\nstrategy that iteratively improves the quality of pseudo boundaries during\ntraining. Comprehensive experiments have been conducted to examine the\neffectiveness of the proposed technique components. By leveraging a substantial\namount of unlabeled video data, such as HowTo100M, we achieve a remarkable\nadvancement on standard DVC datasets like YouCook2 and ActivityNet. We\noutperform the previous state-of-the-art Vid2Seq across a majority of metrics,\nachieving this with just 0.4% of the unlabeled video data used for pre-training\nby Vid2Seq.",
      "tldr_zh": "本研究提出DIBS框架，用于提升密集视频描述(Dense Video Captioning, DVC)，通过从无标签视频中生成高质量的事件描述和伪事件边界。框架利用多样大型语言模型(LLMs)生成丰富的描述候选，并通过多样性、事件中心性、时间顺序和连贯性等多目标优化伪边界，同时引入在线边界精炼策略以在训练过程中迭代改进边界质量。实验结果显示，在YouCook2和ActivityNet等数据集上，DIBS仅使用Vid2Seq的0.4%无标签视频数据（如HowTo100M），即在大多数指标上超越了该现有最先进方法，显著提升了DVC性能。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.MM"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by CVPR 2024",
      "pdf_url": "http://arxiv.org/pdf/2404.02755v1",
      "published_date": "2024-04-03 13:57:08 UTC",
      "updated_date": "2024-04-03 13:57:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T21:25:31.987959"
    },
    {
      "arxiv_id": "2404.02944v1",
      "title": "Foundation Models for Structural Health Monitoring",
      "title_zh": "翻译失败",
      "authors": [
        "Luca Benfenati",
        "Daniele Jahier Pagliari",
        "Luca Zanatta",
        "Yhorman Alexander Bedoya Velez",
        "Andrea Acquaviva",
        "Massimo Poncino",
        "Enrico Macii",
        "Luca Benini",
        "Alessio Burrello"
      ],
      "abstract": "Structural Health Monitoring (SHM) is a critical task for ensuring the safety\nand reliability of civil infrastructures, typically realized on bridges and\nviaducts by means of vibration monitoring. In this paper, we propose for the\nfirst time the use of Transformer neural networks, with a Masked Auto-Encoder\narchitecture, as Foundation Models for SHM. We demonstrate the ability of these\nmodels to learn generalizable representations from multiple large datasets\nthrough self-supervised pre-training, which, coupled with task-specific\nfine-tuning, allows them to outperform state-of-the-art traditional methods on\ndiverse tasks, including Anomaly Detection (AD) and Traffic Load Estimation\n(TLE). We then extensively explore model size versus accuracy trade-offs and\nexperiment with Knowledge Distillation (KD) to improve the performance of\nsmaller Transformers, enabling their embedding directly into the SHM edge\nnodes. We showcase the effectiveness of our foundation models using data from\nthree operational viaducts. For AD, we achieve a near-perfect 99.9% accuracy\nwith a monitoring time span of just 15 windows. In contrast, a state-of-the-art\nmethod based on Principal Component Analysis (PCA) obtains its first good\nresult (95.03% accuracy) only considering 120 windows. On two different TLE\ntasks, our models obtain state-of-the-art performance on multiple evaluation\nmetrics (R$^2$ score, MAE% and MSE%). On the first benchmark, we achieve an\nR$^2$ score of 0.97 and 0.85 for light and heavy vehicle traffic, respectively,\nwhile the best previous approach stops at 0.91 and 0.84. On the second one, we\nachieve an R$^2$ score of 0.54 versus the 0.10 of the best existing method.",
      "tldr_zh": "本论文首次提出使用 Transformer 神经网络的 Masked Auto-Encoder 架构作为 Structural Health Monitoring (SHM) 的基础模型，通过自监督预训练从多个大型数据集学习可泛化表示，并结合任务特定微调，超越了传统方法在 Anomaly Detection (AD) 和 Traffic Load Estimation (TLE) 等任务上的表现。  \n实验验证显示，该模型在三个运营高架桥的数据上表现突出：在 AD 任务中，仅需 15 个窗口即达到 99.9% 准确率，而传统 Principal Component Analysis (PCA) 方法需 120 个窗口才达 95.03%；在 TLE 任务上，R² score 最高达 0.97（轻型车辆）和 0.85（重型车辆），优于现有最佳方法的 0.91 和 0.84。  \n此外，论文探讨了模型大小与准确率权衡，并通过 Knowledge Distillation (KD) 优化小型 Transformer，使其可直接嵌入 SHM 边缘节点，提升实际部署效率。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.SY",
        "eess.SY",
        "I.2.1; I.2.3"
      ],
      "primary_category": "cs.LG",
      "comment": "16 pages, 4 tables, 9 figures",
      "pdf_url": "http://arxiv.org/pdf/2404.02944v1",
      "published_date": "2024-04-03 13:32:44 UTC",
      "updated_date": "2024-04-03 13:32:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T21:25:46.928215"
    },
    {
      "arxiv_id": "2404.02943v1",
      "title": "Learning in Convolutional Neural Networks Accelerated by Transfer Entropy",
      "title_zh": "通过传输熵加速的卷积神经网络学习",
      "authors": [
        "Adrian Moldovan",
        "Angel Caţaron",
        "Răzvan Andonie"
      ],
      "abstract": "Recently, there is a growing interest in applying Transfer Entropy (TE) in\nquantifying the effective connectivity between artificial neurons. In a\nfeedforward network, the TE can be used to quantify the relationships between\nneuron output pairs located in different layers. Our focus is on how to include\nthe TE in the learning mechanisms of a Convolutional Neural Network (CNN)\narchitecture. We introduce a novel training mechanism for CNN architectures\nwhich integrates the TE feedback connections. Adding the TE feedback parameter\naccelerates the training process, as fewer epochs are needed. On the flip side,\nit adds computational overhead to each epoch. According to our experiments on\nCNN classifiers, to achieve a reasonable computational overhead--accuracy\ntrade-off, it is efficient to consider only the inter-neural information\ntransfer of a random subset of the neuron pairs from the last two fully\nconnected layers. The TE acts as a smoothing factor, generating stability and\nbecoming active only periodically, not after processing each input sample.\nTherefore, we can consider the TE is in our model a slowly changing\nmeta-parameter.",
      "tldr_zh": "本研究探讨了在卷积神经网络(CNN)中整合转移熵(Transfer Entropy, TE)来加速学习过程，TE用于量化不同层神经元间的有效连接。作者提出了一种新训练机制，通过添加TE反馈参数，仅考虑最后两层全连接层的随机子集神经元对，从而减少训练所需的epoch数量，同时作为平滑因子周期性激活。实验结果显示，这种方法在CNN分类器上实现了计算开销与准确率的合理权衡，提升了训练效率，并将TE视为一个缓慢变化的元参数。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.IT",
        "math.IT"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.02943v1",
      "published_date": "2024-04-03 13:31:49 UTC",
      "updated_date": "2024-04-03 13:31:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T21:25:56.280747"
    },
    {
      "arxiv_id": "2404.02729v1",
      "title": "Learning Sequence Attractors in Recurrent Networks with Hidden Neurons",
      "title_zh": "在具有隐藏神经元的循环网络中学习序列吸引子",
      "authors": [
        "Yao Lu",
        "Si Wu"
      ],
      "abstract": "The brain is targeted for processing temporal sequence information. It\nremains largely unclear how the brain learns to store and retrieve sequence\nmemories. Here, we study how recurrent networks of binary neurons learn\nsequence attractors to store predefined pattern sequences and retrieve them\nrobustly. We show that to store arbitrary pattern sequences, it is necessary\nfor the network to include hidden neurons even though their role in displaying\nsequence memories is indirect. We develop a local learning algorithm to learn\nsequence attractors in the networks with hidden neurons. The algorithm is\nproven to converge and lead to sequence attractors. We demonstrate that the\nnetwork model can store and retrieve sequences robustly on synthetic and\nreal-world datasets. We hope that this study provides new insights in\nunderstanding sequence memory and temporal information processing in the brain.",
      "tldr_zh": "本研究探讨了大脑如何学习存储和检索时间序列记忆，焦点在于使用包含隐藏神经元（hidden neurons）的循环网络（recurrent networks）来学习序列吸引子（sequence attractors）。研究者开发了一个局部学习算法（local learning algorithm），该算法被证明能收敛并有效存储预定义的模式序列，即使隐藏神经元在显示记忆时作用间接。实验结果显示，该网络模型在合成和真实数据集上能robustly存储和检索序列，显著提升了序列记忆的鲁棒性。该工作为理解大脑的序列记忆和时间信息处理机制提供了新见解。",
      "categories": [
        "cs.NE",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.NE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.02729v1",
      "published_date": "2024-04-03 13:29:12 UTC",
      "updated_date": "2024-04-03 13:29:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T21:26:08.140715"
    },
    {
      "arxiv_id": "2404.02728v1",
      "title": "Unsupervised Learning of Effective Actions in Robotics",
      "title_zh": "翻译失败",
      "authors": [
        "Marko Zaric",
        "Jakob Hollenstein",
        "Justus Piater",
        "Erwan Renaudo"
      ],
      "abstract": "Learning actions that are relevant to decision-making and can be executed\neffectively is a key problem in autonomous robotics. Current state-of-the-art\naction representations in robotics lack proper effect-driven learning of the\nrobot's actions. Although successful in solving manipulation tasks, deep\nlearning methods also lack this ability, in addition to their high cost in\nterms of memory or training data. In this paper, we propose an unsupervised\nalgorithm to discretize a continuous motion space and generate \"action\nprototypes\", each producing different effects in the environment. After an\nexploration phase, the algorithm automatically builds a representation of the\neffects and groups motions into action prototypes, where motions more likely to\nproduce an effect are represented more than those that lead to negligible\nchanges. We evaluate our method on a simulated stair-climbing reinforcement\nlearning task, and the preliminary results show that our effect driven\ndiscretization outperforms uniformly and randomly sampled discretizations in\nconvergence speed and maximum reward.",
      "tldr_zh": "本论文提出了一种无监督算法，用于机器人领域学习有效的动作原型(action prototypes)，以解决现有动作表示缺乏效果驱动学习的问题。该算法通过探索阶段离散化连续运动空间，并基于环境效果自动构建表示和分组动作，更注重那些能产生显著变化的动作，从而提高决策相关性。与深度学习方法相比，该方法减少了对内存和训练数据的依赖。在模拟楼梯爬行强化学习(reinforcement learning)任务中，实验结果显示，该效果驱动离散化在收敛速度和最大奖励上均优于均匀和随机采样基线。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "Accepted at The First Austrian Symposium on AI, Robotics, and Vision\n  (AIROV24)",
      "pdf_url": "http://arxiv.org/pdf/2404.02728v1",
      "published_date": "2024-04-03 13:28:52 UTC",
      "updated_date": "2024-04-03 13:28:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T21:26:20.826647"
    },
    {
      "arxiv_id": "2404.02719v1",
      "title": "Can We Understand Plasticity Through Neural Collapse?",
      "title_zh": "翻译失败",
      "authors": [
        "Guglielmo Bonifazi",
        "Iason Chalas",
        "Gian Hess",
        "Jakub Łucki"
      ],
      "abstract": "This paper explores the connection between two recently identified phenomena\nin deep learning: plasticity loss and neural collapse. We analyze their\ncorrelation in different scenarios, revealing a significant association during\nthe initial training phase on the first task. Additionally, we introduce a\nregularization approach to mitigate neural collapse, demonstrating its\neffectiveness in alleviating plasticity loss in this specific setting.",
      "tldr_zh": "这篇论文探讨了深度学习中plasticity loss和neural collapse两种现象之间的联系，通过分析不同场景发现，它们在第一个任务的初始训练阶段存在显著关联。作者引入了一种regularization approach来缓解neural collapse，并证明了该方法在减轻plasticity loss方面的有效性。该研究为理解深度学习模型的可塑性提供了新视角。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.02719v1",
      "published_date": "2024-04-03 13:21:58 UTC",
      "updated_date": "2024-04-03 13:21:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T21:26:32.331510"
    },
    {
      "arxiv_id": "2404.07230v1",
      "title": "Interval-valued fuzzy soft $β$-covering approximation spaces",
      "title_zh": "翻译失败",
      "authors": [
        "Shizhan Lu"
      ],
      "abstract": "The concept of interval-valued fuzzy soft $\\beta$-covering approximation\nspaces (IFS$\\beta$CASs) is introduced to combine the theories of soft sets,\nrough sets and interval-valued fuzzy sets, and some fundamental propositions\nconcerning interval-valued fuzzy soft $\\beta$-neighborhoods and soft\n$\\beta$-neighborhoods of IFS$\\beta$CASs are explored. And then four kinds of\ninterval-valued fuzzy soft $\\beta$-coverings based fuzzy rough sets are\nresearched. Finally, the relationships of four kinds of interval-valued fuzzy\nsoft $\\beta$-coverings based fuzzy rough sets are investigated.",
      "tldr_zh": "本论文引入了Interval-valued fuzzy soft β-covering approximation spaces (IFSβCASs)，旨在将soft sets、rough sets和interval-valued fuzzy sets的理论相结合。\n论文探讨了interval-valued fuzzy soft β-neighborhoods和soft β-neighborhoods的基本命题。\n随后，研究了四种基于interval-valued fuzzy soft β-coverings的fuzzy rough sets，并分析了它们之间的关系。",
      "categories": [
        "math.GM",
        "cs.AI"
      ],
      "primary_category": "math.GM",
      "comment": "12 pages",
      "pdf_url": "http://arxiv.org/pdf/2404.07230v1",
      "published_date": "2024-04-03 13:04:54 UTC",
      "updated_date": "2024-04-03 13:04:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T21:26:44.336231"
    },
    {
      "arxiv_id": "2406.11854v1",
      "title": "Attributions toward Artificial Agents in a modified Moral Turing Test",
      "title_zh": "翻译失败",
      "authors": [
        "Eyal Aharoni",
        "Sharlene Fernandes",
        "Daniel J. Brady",
        "Caelan Alexander",
        "Michael Criner",
        "Kara Queen",
        "Javier Rando",
        "Eddy Nahmias",
        "Victor Crespo"
      ],
      "abstract": "Advances in artificial intelligence (AI) raise important questions about\nwhether people view moral evaluations by AI systems similarly to\nhuman-generated moral evaluations. We conducted a modified Moral Turing Test\n(m-MTT), inspired by Allen and colleagues' (2000) proposal, by asking people to\ndistinguish real human moral evaluations from those made by a popular advanced\nAI language model: GPT-4. A representative sample of 299 U.S. adults first\nrated the quality of moral evaluations when blinded to their source.\nRemarkably, they rated the AI's moral reasoning as superior in quality to\nhumans' along almost all dimensions, including virtuousness, intelligence, and\ntrustworthiness, consistent with passing what Allen and colleagues call the\ncomparative MTT. Next, when tasked with identifying the source of each\nevaluation (human or computer), people performed significantly above chance\nlevels. Although the AI did not pass this test, this was not because of its\ninferior moral reasoning but, potentially, its perceived superiority, among\nother possible explanations. The emergence of language models capable of\nproducing moral responses perceived as superior in quality to humans' raises\nconcerns that people may uncritically accept potentially harmful moral guidance\nfrom AI. This possibility highlights the need for safeguards around generative\nlanguage models in matters of morality.",
      "tldr_zh": "本研究探讨了人们对AI系统道德评价的态度，通过修改的道德图灵测试（m-MTT）来比较人类和GPT-4的道德评估。实验中，299名美国成年参与者先在不知来源的情况下评估道德推理质量，结果显示他们认为GPT-4在美德、智能和可信度等维度上优于人类，从而通过了比较MTT。接下来，当要求识别评价来源时，参与者表现显著高于随机水平，AI未通过测试，可能由于其被感知为过于优越。研究强调，这种现象可能导致人们无批判地接受AI的道德指导，呼吁对生成式语言模型的道德应用设置防护措施。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CY",
      "comment": "23 pages, 0 figures, in press",
      "pdf_url": "http://arxiv.org/pdf/2406.11854v1",
      "published_date": "2024-04-03 13:00:47 UTC",
      "updated_date": "2024-04-03 13:00:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T21:26:56.990893"
    },
    {
      "arxiv_id": "2404.02702v3",
      "title": "PSCodec: A Series of High-Fidelity Low-bitrate Neural Speech Codecs Leveraging Prompt Encoders",
      "title_zh": "PSCodec：利用提示编码器的一系列高保真低比特率神经语音编解码器",
      "authors": [
        "Yu Pan",
        "Xiang Zhang",
        "Yuguang Yang",
        "Jixun Yao",
        "Yanni Hu",
        "Jianhao Ye",
        "Hongbin Zhou",
        "Lei Ma",
        "Jianjun Zhao"
      ],
      "abstract": "Neural speech codecs have recently emerged as a focal point in the fields of\nspeech compression and generation. Despite this progress, achieving\nhigh-quality speech reconstruction under low-bitrate scenarios remains a\nsignificant challenge. In this paper, we propose PSCodec, a series of neural\nspeech codecs based on prompt encoders, comprising PSCodec-Base,\nPSCodec-DRL-ICT, and PSCodec-CasAN, which are capable of delivering\nhigh-performance speech reconstruction with low bandwidths. Specifically, we\nfirst introduce PSCodec-Base, which leverages a pretrained speaker verification\nmodel-based prompt encoder (VPP-Enc) and a learnable Mel-spectrogram-based\nprompt encoder (MelP-Enc) to effectively disentangle and integrate voiceprint\nand Mel-related features in utterances. To further enhance feature utilization\nefficiency, we propose PSCodec-DRL-ICT, incorporating a structural similarity\n(SSIM) based disentangled representation loss (DRL) and an incremental\ncontinuous training (ICT) strategy. While PSCodec-DRL-ICT demonstrates\nimpressive performance, its reliance on extensive hyperparameter tuning and\nmulti-stage training makes it somewhat labor-intensive. To circumvent these\nlimitations, we propose PSCodec-CasAN, utilizing an advanced cascaded attention\nnetwork (CasAN) to enhance representational capacity of the entire system.\nExtensive experiments show that our proposed PSCodec-Base, PSCodec-DRL-ICT, and\nPSCodec-CasAN all significantly outperform several state-of-the-art neural\ncodecs, exhibiting substantial improvements in both speech reconstruction\nquality and speaker similarity under low-bitrate conditions.",
      "tldr_zh": "该论文提出 PSCodec 系列高保真低比特率神经语音编解码器，包括 PSCodec-Base、PSCodec-DRL-ICT 和 PSCodec-CasAN，以解决低比特率下高质量语音重建的挑战。PSCodec-Base 利用预训练的说话者验证模型-based prompt encoder (VPP-Enc) 和可学习的 Mel-spectrogram-based prompt encoder (MelP-Enc) 来分离并整合语音指纹和 Mel 相关特征。PSCodec-DRL-ICT 进一步引入基于结构相似性 (SSIM) 的分离表示损失 (DRL) 和增量连续训练 (ICT) 策略，以提升特征利用效率，而 PSCodec-CasAN 采用高级级联注意力网络 (CasAN) 来增强系统表示能力。实验结果显示，这些模型在低比特率条件下显著优于现有状态-of-the-art 神经编解码器，在语音重建质量和说话者相似性方面均取得实质性改善。",
      "categories": [
        "cs.SD",
        "cs.AI"
      ],
      "primary_category": "cs.SD",
      "comment": "Submiited to TASLP",
      "pdf_url": "http://arxiv.org/pdf/2404.02702v3",
      "published_date": "2024-04-03 13:00:08 UTC",
      "updated_date": "2024-11-21 10:31:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T21:27:10.305169"
    },
    {
      "arxiv_id": "2404.02942v1",
      "title": "Decision Predicate Graphs: Enhancing Interpretability in Tree Ensembles",
      "title_zh": "决策谓词图：提升树集成模型的可解释性",
      "authors": [
        "Leonardo Arrighi",
        "Luca Pennella",
        "Gabriel Marques Tavares",
        "Sylvio Barbon Junior"
      ],
      "abstract": "Understanding the decisions of tree-based ensembles and their relationships\nis pivotal for machine learning model interpretation. Recent attempts to\nmitigate the human-in-the-loop interpretation challenge have explored the\nextraction of the decision structure underlying the model taking advantage of\ngraph simplification and path emphasis. However, while these efforts enhance\nthe visualisation experience, they may either result in a visually complex\nrepresentation or compromise the interpretability of the original ensemble\nmodel. In addressing this challenge, especially in complex scenarios, we\nintroduce the Decision Predicate Graph (DPG) as a model-agnostic tool to\nprovide a global interpretation of the model. DPG is a graph structure that\ncaptures the tree-based ensemble model and learned dataset details, preserving\nthe relations among features, logical decisions, and predictions towards\nemphasising insightful points. Leveraging well-known graph theory concepts,\nsuch as the notions of centrality and community, DPG offers additional\nquantitative insights into the model, complementing visualisation techniques,\nexpanding the problem space descriptions, and offering diverse possibilities\nfor extensions. Empirical experiments demonstrate the potential of DPG in\naddressing traditional benchmarks and complex classification scenarios.",
      "tldr_zh": "该论文提出了 Decision Predicate Graphs (DPG)，一种模型无关的工具，用于提升树基集成模型（tree ensembles）的全局解释性，以解决现有方法在可视化时可能导致的复杂性和解释性损失问题。DPG 通过图结构捕获模型的决策细节，包括特征、逻辑决策和预测之间的关系，并利用图论概念如中心性和社区，提供额外的定量洞见，补充可视化技术并扩展问题空间描述。实验结果显示，DPG 在传统基准和复杂分类场景中表现出色，证明了其在增强模型可解释性方面的潜力。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.02942v1",
      "published_date": "2024-04-03 12:38:12 UTC",
      "updated_date": "2024-04-03 12:38:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T21:27:21.248788"
    },
    {
      "arxiv_id": "2404.02690v2",
      "title": "How Sparse Attention Approximates Exact Attention? Your Attention is Naturally $n^C$-Sparse",
      "title_zh": "翻译失败",
      "authors": [
        "Yichuan Deng",
        "Zhao Song",
        "Jing Xiong",
        "Chiwun Yang"
      ],
      "abstract": "Sparse Attention is a technique that approximates standard attention\ncomputation with sub-quadratic complexity. This is achieved by selectively\nignoring smaller entries in the attention matrix during the softmax function\ncomputation. Variations of this technique, such as pruning KV cache,\nsparsity-based fast attention, and Sparse Transformer, have been extensively\nutilized for efficient Large Language Models (LLMs) deployment. Despite its\nwidespread use, a theoretical understanding of the conditions under which\nsparse attention performs on par with traditional attention remains elusive.\nThis work aims to $\\textbf{bridge this gap by examining the inherent sparsity\nof standard attention processes}$. Our theoretical framework reveals several\nbrand-new key insights:\n  $\\bullet$ Attention is $n^{C}$-sparse, implying that considering only the\nlargest $\\Omega(n^{C})$ entries out of all $n$ entries is sufficient for sparse\nattention to approximate the exact attention matrix with decreasing loss. Here,\n$n$ represents the input length and $C \\in (0, 1)$ is a constant.\n  $\\bullet$ Stable $o(\\log(n))$-sparse attention, which approximates attention\ncomputation with $\\log(n)$ or fewer entries, may not be feasible since the\nerror will persist at a minimum of $O(1)$.\n  $\\bullet$ An adaptive strategy ($\\alpha \\cdot n^C, \\alpha \\in \\mathbb{R}$)\nfor the window size of efficient attention methods rather than a fixed one is\nguaranteed to perform more accurately and efficiently in a task for inference\non flexible context lengths.",
      "tldr_zh": "该论文探讨了Sparse Attention如何近似exact attention机制，通过忽略attention矩阵中较小的条目来实现子二次复杂度，从而提升Large Language Models (LLMs)的部署效率。研究者通过理论框架分析了标准attention的固有稀疏性，发现attention是$n^C$-sparse，仅需考虑最大的$\\Omega(n^C)$条目即可近似exact attention矩阵，同时警告稳定的$o(\\log(n))$-sparse attention可能因最小误差至少为$O(1)$而不可行。论文还提出采用自适应策略（$\\alpha \\cdot n^C$）来设置窗口大小，以在灵活的上下文长度下实现更准确和高效的attention计算。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.02690v2",
      "published_date": "2024-04-03 12:37:34 UTC",
      "updated_date": "2025-02-12 14:32:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T21:27:33.830688"
    },
    {
      "arxiv_id": "2404.02684v1",
      "title": "Cross-Architecture Transfer Learning for Linear-Cost Inference Transformers",
      "title_zh": "翻译失败",
      "authors": [
        "Sehyun Choi"
      ],
      "abstract": "Recently, multiple architectures has been proposed to improve the efficiency\nof the Transformer Language Models through changing the design of the\nself-attention block to have a linear-cost inference (LCI). A notable approach\nin this realm is the State-Space Machines (SSMs) architecture, which showed\non-par performance on language modeling tasks with the self-attention\ntransformers. However, such an architectural change requires a full pretraining\nof the weights from scratch, which incurs a huge cost to researchers and\npractitioners who want to use the new architectures. In the more traditional\nlinear attention works, it has been proposed to approximate full attention with\nlinear attention by swap-and-finetune framework. Motivated by this approach, we\npropose Cross-Architecture Transfer Learning (XATL), in which the weights of\nthe shared components between LCI and self-attention-based transformers, such\nas layernorms, MLPs, input/output embeddings, are directly transferred to the\nnew architecture from already pre-trained model parameters. We experimented the\nefficacy of the method on varying sizes and alternative attention architectures\nand show that \\methodabbr significantly reduces the training time up to 2.5x\ntimes and converges to a better minimum with up to 2.6% stronger model on the\nLM benchmarks within the same compute budget.",
      "tldr_zh": "该研究针对线性成本推理 (LCI) Transformer 架构提出 Cross-Architecture Transfer Learning (XATL) 方法，通过直接转移自注意力 Transformer 的共享组件权重（如 layernorms、MLPs 和输入/输出 embeddings），以避免从零开始的完整预训练。XATL 利用 swap-and-finetune 的灵感，显著减少了训练时间高达 2.5 倍，并在相同计算预算下使模型在语言建模基准上收敛到更好性能，提升至多 2.6%。实验验证了该方法在不同规模和注意力架构上的有效性，为高效 Transformer 模型部署提供了实用途径。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Preprint",
      "pdf_url": "http://arxiv.org/pdf/2404.02684v1",
      "published_date": "2024-04-03 12:27:36 UTC",
      "updated_date": "2024-04-03 12:27:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T21:27:46.586828"
    },
    {
      "arxiv_id": "2404.02681v1",
      "title": "PejorativITy: Disambiguating Pejorative Epithets to Improve Misogyny Detection in Italian Tweets",
      "title_zh": "PejorativITy：消除贬",
      "authors": [
        "Arianna Muti",
        "Federico Ruggeri",
        "Cagri Toraman",
        "Lorenzo Musetti",
        "Samuel Algherini",
        "Silvia Ronchi",
        "Gianmarco Saretto",
        "Caterina Zapparoli",
        "Alberto Barrón-Cedeño"
      ],
      "abstract": "Misogyny is often expressed through figurative language. Some neutral words\ncan assume a negative connotation when functioning as pejorative epithets.\nDisambiguating the meaning of such terms might help the detection of misogyny.\nIn order to address such task, we present PejorativITy, a novel corpus of 1,200\nmanually annotated Italian tweets for pejorative language at the word level and\nmisogyny at the sentence level. We evaluate the impact of injecting information\nabout disambiguated words into a model targeting misogyny detection. In\nparticular, we explore two different approaches for injection: concatenation of\npejorative information and substitution of ambiguous words with univocal terms.\nOur experimental results, both on our corpus and on two popular benchmarks on\nItalian tweets, show that both approaches lead to a major classification\nimprovement, indicating that word sense disambiguation is a promising\npreliminary step for misogyny detection. Furthermore, we investigate LLMs'\nunderstanding of pejorative epithets by means of contextual word embeddings\nanalysis and prompting.",
      "tldr_zh": "本研究提出了 PejorativITy 语料库，该语料库包含 1200 条手动标注的意大利推文，用于词级别的 pejorative epithets 消歧和句子级别的 misogyny detection，以改善对厌女症的识别。研究探索了两种注入 pejorative 信息的方法：连接相关信息和替换模糊词，并通过实验验证这些方法在自有语料库和两个流行基准上的分类性能均显著提升。结果表明，词义消歧作为 misogyny detection 的初步步骤极具潜力，此外，通过 contextual word embeddings 分析和 prompting，研究了 LLMs 对 pejorative epithets 的理解能力。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.02681v1",
      "published_date": "2024-04-03 12:24:48 UTC",
      "updated_date": "2024-04-03 12:24:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T21:27:57.717901"
    },
    {
      "arxiv_id": "2404.02675v1",
      "title": "Responsible Reporting for Frontier AI Development",
      "title_zh": "翻译失败",
      "authors": [
        "Noam Kolt",
        "Markus Anderljung",
        "Joslyn Barnhart",
        "Asher Brass",
        "Kevin Esvelt",
        "Gillian K. Hadfield",
        "Lennart Heim",
        "Mikel Rodriguez",
        "Jonas B. Sandbrink",
        "Thomas Woodside"
      ],
      "abstract": "Mitigating the risks from frontier AI systems requires up-to-date and\nreliable information about those systems. Organizations that develop and deploy\nfrontier systems have significant access to such information. By reporting\nsafety-critical information to actors in government, industry, and civil\nsociety, these organizations could improve visibility into new and emerging\nrisks posed by frontier systems. Equipped with this information, developers\ncould make better informed decisions on risk management, while policymakers\ncould design more targeted and robust regulatory infrastructure. We outline the\nkey features of responsible reporting and propose mechanisms for implementing\nthem in practice.",
      "tldr_zh": "这篇论文讨论了缓解前沿 AI 系统风险的重要性，强调开发和部署这些系统的组织应报告安全关键信息给政府、行业和民间社会，以提升对新风险的可见性。通过负责任报告，开发者能够做出更明智的风险管理决策，而政策制定者则能设计更针对性和稳健的监管基础设施。论文概述了负责任报告的关键特征，并提出实际实施机制，以促进信息共享和风险控制。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.02675v1",
      "published_date": "2024-04-03 12:18:45 UTC",
      "updated_date": "2024-04-03 12:18:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T21:28:08.991004"
    },
    {
      "arxiv_id": "2404.02657v4",
      "title": "Rethinking Kullback-Leibler Divergence in Knowledge Distillation for Large Language Models",
      "title_zh": "重新审视 Kullback-Leibler Divergence 在大型语言模型知识蒸馏中的作用",
      "authors": [
        "Taiqiang Wu",
        "Chaofan Tao",
        "Jiahao Wang",
        "Runming Yang",
        "Zhe Zhao",
        "Ngai Wong"
      ],
      "abstract": "Kullback-Leiber divergence has been widely used in Knowledge Distillation\n(KD) to compress Large Language Models (LLMs). Contrary to prior assertions\nthat reverse Kullback-Leibler (RKL) divergence is mode-seeking and thus\npreferable over the mean-seeking forward Kullback-Leibler (FKL) divergence,\nthis study empirically and theoretically demonstrates that neither mode-seeking\nnor mean-seeking properties manifest in KD for LLMs. Instead, RKL and FKL are\nfound to share the same optimization objective and both converge after a\nsufficient number of epochs. However, due to practical constraints, LLMs are\nseldom trained for such an extensive number of epochs. Meanwhile, we further\nfind that RKL focuses on the tail part of the distributions, while FKL focuses\non the head part at the beginning epochs. Consequently, we propose a simple yet\neffective Adaptive Kullback-Leiber (AKL) divergence method, which adaptively\nallocates weights to combine FKL and RKL. Metric-based and GPT-4-based\nevaluations demonstrate that the proposed AKL outperforms the baselines across\nvarious tasks and improves the diversity and quality of generated responses.\nCodes are available at \\href{https://github.com/wutaiqiang/LLM_KD_AKL}{github}.",
      "tldr_zh": "该研究重新审视了Kullback-Leibler divergence（KL divergence）在Knowledge Distillation（KD）中用于压缩Large Language Models（LLMs）的应用，通过实证和理论分析发现，Reverse KL（RKL）和Forward KL（FKL）均未表现出预期的mode-seeking或mean-seeking特性，而是共享相同的优化目标，并在充分训练后收敛。论文进一步指出，由于实际训练限制，RKL更关注分布尾部而FKL关注头部，因此提出了一种简单有效的Adaptive KL（AKL）方法，通过自适应分配权重结合FKL和RKL。实验结果显示，AKL在各种任务中优于基线模型，提高了生成响应的多样性和质量。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "COLING 2025",
      "pdf_url": "http://arxiv.org/pdf/2404.02657v4",
      "published_date": "2024-04-03 11:40:17 UTC",
      "updated_date": "2024-12-08 13:03:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T21:28:23.042091"
    },
    {
      "arxiv_id": "2404.02656v2",
      "title": "Non-negative Subspace Feature Representation for Few-shot Learning in Medical Imaging",
      "title_zh": "非负子空间特征表示用于医学成像中的少样本学习",
      "authors": [
        "Keqiang Fan",
        "Xiaohao Cai",
        "Mahesan Niranjan"
      ],
      "abstract": "Unlike typical visual scene recognition domains, in which massive datasets\nare accessible to deep neural networks, medical image interpretations are often\nobstructed by the paucity of data. In this paper, we investigate the\neffectiveness of data-based few-shot learning in medical imaging by exploring\ndifferent data attribute representations in a low-dimensional space. We\nintroduce different types of non-negative matrix factorization (NMF) in\nfew-shot learning, addressing the data scarcity issue in medical image\nclassification. Extensive empirical studies are conducted in terms of\nvalidating the effectiveness of NMF, especially its supervised variants (e.g.,\ndiscriminative NMF, and supervised and constrained NMF with sparseness), and\nthe comparison with principal component analysis (PCA), i.e., the collaborative\nrepresentation-based dimensionality reduction technique derived from\neigenvectors. With 14 different datasets covering 11 distinct illness\ncategories, thorough experimental results and comparison with related\ntechniques demonstrate that NMF is a competitive alternative to PCA for\nfew-shot learning in medical imaging, and the supervised NMF algorithms are\nmore discriminative in the subspace with greater effectiveness. Furthermore, we\nshow that the part-based representation of NMF, especially its supervised\nvariants, is dramatically impactful in detecting lesion areas in medical\nimaging with limited samples.",
      "tldr_zh": "本研究探讨了医疗图像领域的数据稀缺问题，提出使用非负子空间特征表示（Non-negative Subspace Feature Representation）来提升少样本学习（Few-shot Learning）的性能。具体而言，该方法引入了不同类型的非负矩阵分解（NMF），包括其监督变体（如discriminative NMF和supervised and constrained NMF with sparseness），并将其与主成分分析（PCA）进行比较，以解决医疗图像分类中的挑战。实验在涵盖11个疾病类别的14个数据集上进行，结果显示NMF及其监督变体在子空间中更具区分性，且在少样本场景下显著优于PCA。总之，该方法证明了NMF在医疗图像少样本学习中的竞争力，尤其在检测病变区域时表现出色。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.02656v2",
      "published_date": "2024-04-03 11:37:03 UTC",
      "updated_date": "2024-04-04 13:30:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T21:28:34.248973"
    },
    {
      "arxiv_id": "2404.02650v1",
      "title": "Towards detecting unanticipated bias in Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Anna Kruspe"
      ],
      "abstract": "Over the last year, Large Language Models (LLMs) like ChatGPT have become\nwidely available and have exhibited fairness issues similar to those in\nprevious machine learning systems. Current research is primarily focused on\nanalyzing and quantifying these biases in training data and their impact on the\ndecisions of these models, alongside developing mitigation strategies. This\nresearch largely targets well-known biases related to gender, race, ethnicity,\nand language. However, it is clear that LLMs are also affected by other, less\nobvious implicit biases. The complex and often opaque nature of these models\nmakes detecting such biases challenging, yet this is crucial due to their\npotential negative impact in various applications. In this paper, we explore\nnew avenues for detecting these unanticipated biases in LLMs, focusing\nspecifically on Uncertainty Quantification and Explainable AI methods. These\napproaches aim to assess the certainty of model decisions and to make the\ninternal decision-making processes of LLMs more transparent, thereby\nidentifying and understanding biases that are not immediately apparent. Through\nthis research, we aim to contribute to the development of fairer and more\ntransparent AI systems.",
      "tldr_zh": "这篇论文探讨了 Large Language Models (LLMs) 中存在的意外偏见问题，这些偏见往往隐蔽且超出已知类型，如性别或种族偏见。作者提出使用 Uncertainty Quantification 和 Explainable AI 方法来评估模型决策的确定性和内部决策过程的透明度，从而识别和理解这些不明显的偏见。最终，该研究旨在推动更公平、更透明的 AI 系统的发展。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.02650v1",
      "published_date": "2024-04-03 11:25:20 UTC",
      "updated_date": "2024-04-03 11:25:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T21:28:45.210512"
    },
    {
      "arxiv_id": "2404.02648v1",
      "title": "A Universal Deep Neural Network for Signal Detection in Wireless Communication Systems",
      "title_zh": "用于无线通信系统信号检测的通用深度神经网络",
      "authors": [
        "Khalid Albagami",
        "Nguyen Van Huynh",
        "Geoffrey Ye Li"
      ],
      "abstract": "Recently, deep learning (DL) has been emerging as a promising approach for\nchannel estimation and signal detection in wireless communications. The\nmajority of the existing studies investigating the use of DL techniques in this\ndomain focus on analysing channel impulse responses that are generated from\nonly one channel distribution such as additive white Gaussian channel noise and\nRayleigh channels. In practice, to cope with the dynamic nature of the wireless\nchannel, DL methods must be re-trained on newly non-aged collected data which\nis costly, inefficient, and impractical. To tackle this challenge, this paper\nproposes a novel universal deep neural network (Uni-DNN) that can achieve high\ndetection performance in various wireless environments without retraining the\nmodel. In particular, our proposed Uni-DNN model consists of a wireless channel\nclassifier and a signal detector which are constructed by using DNNs. The\nwireless channel classifier enables the signal detector to generalise and\nperform optimally for multiple wireless channel distributions. In addition, to\nfurther improve the signal detection performance of the proposed model,\nconvolutional neural network is employed. Extensive simulations using the\northogonal frequency division multiplexing scheme demonstrate that the bit\nerror rate performance of our proposed solution can outperform conventional\nDL-based approaches as well as least square and minimum mean square error\nchannel estimators in practical low pilot density scenarios.",
      "tldr_zh": "该论文针对无线通信中深度学习（DL）用于信道估计和信号检测的局限性，提出了一种通用深度神经网络（Uni-DNN），能够适应多种信道分布（如AWGN和Rayleigh信道）而无需重新训练，从而解决动态无线环境下的效率问题。Uni-DNN由一个无线信道分类器和一个信号检测器组成，后者利用DNN和卷积神经网络（CNN）构建，以实现信号检测的泛化和优化。实验结果显示，在正交频分复用（OFDM）方案的低导频密度场景中，Uni-DNN的误码率（BER）性能优于传统DL方法、least square (LS) 和 minimum mean square error (MMSE) 信道估计器。",
      "categories": [
        "cs.NI",
        "cs.AI",
        "cs.IT",
        "math.IT"
      ],
      "primary_category": "cs.NI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.02648v1",
      "published_date": "2024-04-03 11:21:10 UTC",
      "updated_date": "2024-04-03 11:21:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T21:28:58.136990"
    },
    {
      "arxiv_id": "2404.02637v2",
      "title": "Vocabulary Attack to Hijack Large Language Model Applications",
      "title_zh": "翻译失败",
      "authors": [
        "Patrick Levi",
        "Christoph P. Neumann"
      ],
      "abstract": "The fast advancements in Large Language Models (LLMs) are driving an\nincreasing number of applications. Together with the growing number of users,\nwe also see an increasing number of attackers who try to outsmart these\nsystems. They want the model to reveal confidential information, specific false\ninformation, or offensive behavior. To this end, they manipulate their\ninstructions for the LLM by inserting separators or rephrasing them\nsystematically until they reach their goal. Our approach is different. It\ninserts words from the model vocabulary. We find these words using an\noptimization procedure and embeddings from another LLM (attacker LLM). We prove\nour approach by goal hijacking two popular open-source LLMs from the Llama2 and\nthe Flan-T5 families, respectively. We present two main findings. First, our\napproach creates inconspicuous instructions and therefore it is hard to detect.\nFor many attack cases, we find that even a single word insertion is sufficient.\nSecond, we demonstrate that we can conduct our attack using a different model\nthan the target model to conduct our attack with.",
      "tldr_zh": "本文提出了一种名为Vocabulary Attack的新攻击方法，通过插入Large Language Models (LLMs) 的词汇来劫持其应用，从而诱导模型泄露机密信息、传播虚假信息或表现出攻击性行为。该方法利用优化过程和另一个attacker LLM的嵌入来选择插入词汇，并在Llama2和Flan-T5家族的开源模型上进行了实验验证。研究发现，这种攻击指令隐蔽性强，往往只需插入一个单词即可成功，且可以跨模型执行，为LLMs的安全性评估提供了重要启示。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.DC"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.02637v2",
      "published_date": "2024-04-03 10:54:07 UTC",
      "updated_date": "2024-05-30 06:28:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T21:29:09.450523"
    },
    {
      "arxiv_id": "2404.02625v1",
      "title": "A Differentiable Integer Linear Programming Solver for Explanation-Based Natural Language Inference",
      "title_zh": "翻译失败",
      "authors": [
        "Mokanarangan Thayaparan",
        "Marco Valentino",
        "André Freitas"
      ],
      "abstract": "Integer Linear Programming (ILP) has been proposed as a formalism for\nencoding precise structural and semantic constraints for Natural Language\nInference (NLI). However, traditional ILP frameworks are non-differentiable,\nposing critical challenges for the integration of continuous language\nrepresentations based on deep learning. In this paper, we introduce a novel\napproach, named Diff-Comb Explainer, a neuro-symbolic architecture for\nexplanation-based NLI based on Differentiable BlackBox Combinatorial Solvers\n(DBCS). Differently from existing neuro-symbolic solvers, Diff-Comb Explainer\ndoes not necessitate a continuous relaxation of the semantic constraints,\nenabling a direct, more precise, and efficient incorporation of neural\nrepresentations into the ILP formulation. Our experiments demonstrate that\nDiff-Comb Explainer achieves superior performance when compared to conventional\nILP solvers, neuro-symbolic black-box solvers, and Transformer-based encoders.\nMoreover, a deeper analysis reveals that Diff-Comb Explainer can significantly\nimprove the precision, consistency, and faithfulness of the constructed\nexplanations, opening new opportunities for research on neuro-symbolic\narchitectures for explainable and transparent NLI in complex domains.",
      "tldr_zh": "本研究提出Diff-Comb Explainer，一种基于Differentiable BlackBox Combinatorial Solvers (DBCS)的神经符号架构，用于Explanation-Based Natural Language Inference (NLI)，以解决传统Integer Linear Programming (ILP)求解器非微分的问题，无法有效整合深度学习表示。该方法无需对语义约束进行连续松弛，从而实现更精确和高效地将神经表示融入ILP框架。实验结果显示，Diff-Comb Explainer在性能上优于传统ILP求解器、神经符号黑箱求解器和Transformer-based编码器，并显著提升了解释的精确性、一致性和真实性。该框架为可解释的NLI研究开辟了新机遇，尤其在复杂领域。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to LREC-COLING 2024 - Camera Ready. arXiv admin note:\n  substantial text overlap with arXiv:2208.03339",
      "pdf_url": "http://arxiv.org/pdf/2404.02625v1",
      "published_date": "2024-04-03 10:29:06 UTC",
      "updated_date": "2024-04-03 10:29:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T21:29:22.135631"
    },
    {
      "arxiv_id": "2404.02618v1",
      "title": "Diffexplainer: Towards Cross-modal Global Explanations with Diffusion Models",
      "title_zh": "翻译失败",
      "authors": [
        "Matteo Pennisi",
        "Giovanni Bellitto",
        "Simone Palazzo",
        "Mubarak Shah",
        "Concetto Spampinato"
      ],
      "abstract": "We present DiffExplainer, a novel framework that, leveraging language-vision\nmodels, enables multimodal global explainability. DiffExplainer employs\ndiffusion models conditioned on optimized text prompts, synthesizing images\nthat maximize class outputs and hidden features of a classifier, thus providing\na visual tool for explaining decisions. Moreover, the analysis of generated\nvisual descriptions allows for automatic identification of biases and spurious\nfeatures, as opposed to traditional methods that often rely on manual\nintervention. The cross-modal transferability of language-vision models also\nenables the possibility to describe decisions in a more human-interpretable\nway, i.e., through text. We conduct comprehensive experiments, which include an\nextensive user study, demonstrating the effectiveness of DiffExplainer on 1)\nthe generation of high-quality images explaining model decisions, surpassing\nexisting activation maximization methods, and 2) the automated identification\nof biases and spurious features.",
      "tldr_zh": "本论文提出DiffExplainer，一种基于语言-视觉模型的框架，实现跨模态全局解释性。框架利用diffusion models结合优化的文本提示，合成图像来最大化分类器的类输出和隐藏特征，从而提供视觉工具自动识别偏差和无关特征，同时通过文本描述提升决策的可解释性。实验结果，包括广泛的用户研究，表明DiffExplainer在生成高质量解释图像方面优于现有激活最大化方法，并在偏差识别上表现出显著优势。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.02618v1",
      "published_date": "2024-04-03 10:11:22 UTC",
      "updated_date": "2024-04-03 10:11:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T21:29:33.680153"
    },
    {
      "arxiv_id": "2404.02611v3",
      "title": "X-SHIELD: Regularization for eXplainable Artificial Intelligence",
      "title_zh": "X-SHIELD：用于可解释人工智能的正则化",
      "authors": [
        "Iván Sevillano-García",
        "Julián Luengo",
        "Francisco Herrera"
      ],
      "abstract": "As artificial intelligence systems become integral across domains, the demand\nfor explainability grows, the called eXplainable artificial intelligence (XAI).\nExisting efforts primarily focus on generating and evaluating explanations for\nblack-box models while a critical gap in directly enhancing models remains\nthrough these evaluations. It is important to consider the potential of this\nexplanation process to improve model quality with a feedback on training as\nwell. XAI may be used to improve model performance while boosting its\nexplainability. Under this view, this paper introduces Transformation -\nSelective Hidden Input Evaluation for Learning Dynamics (T-SHIELD), a\nregularization family designed to improve model quality by hiding features of\ninput, forcing the model to generalize without those features. Within this\nfamily, we propose the XAI - SHIELD(X-SHIELD), a regularization for explainable\nartificial intelligence, which uses explanations to select specific features to\nhide. In contrast to conventional approaches, X-SHIELD regularization\nseamlessly integrates into the objective function enhancing model\nexplainability while also improving performance. Experimental validation on\nbenchmark datasets underscores X-SHIELD's effectiveness in improving\nperformance and overall explainability. The improvement is validated through\nexperiments comparing models with and without the X-SHIELD regularization, with\nfurther analysis exploring the rationale behind its design choices. This\nestablishes X-SHIELD regularization as a promising pathway for developing\nreliable artificial intelligence regularization.",
      "tldr_zh": "本文提出 X-SHIELD，一种针对 eXplainable Artificial Intelligence (XAI) 的正则化方法，旨在通过利用模型解释来改进模型性能和可解释性。X-SHIELD 基于 T-SHIELD 家族，通过选择隐藏特定输入特征来迫使模型在不依赖这些特征的情况下实现泛化，并无缝整合到训练目标函数中。实验在基准数据集上验证了其有效性，与未使用 X-SHIELD 的模型相比，性能和整体解释性均得到显著提升，为开发可靠的 AI 正则化技术提供了新途径。",
      "categories": [
        "cs.AI",
        "I.2.6"
      ],
      "primary_category": "cs.AI",
      "comment": "18 pages, 9 figures",
      "pdf_url": "http://arxiv.org/pdf/2404.02611v3",
      "published_date": "2024-04-03 09:56:38 UTC",
      "updated_date": "2025-03-11 12:24:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T21:29:47.213425"
    },
    {
      "arxiv_id": "2404.02589v1",
      "title": "Affective-NLI: Towards Accurate and Interpretable Personality Recognition in Conversation",
      "title_zh": "Affective-NLI：实现准确且可解释的对话中个性识别",
      "authors": [
        "Zhiyuan Wen",
        "Jiannong Cao",
        "Yu Yang",
        "Ruosong Yang",
        "Shuaiqi Liu"
      ],
      "abstract": "Personality Recognition in Conversation (PRC) aims to identify the\npersonality traits of speakers through textual dialogue content. It is\nessential for providing personalized services in various applications of\nHuman-Computer Interaction (HCI), such as AI-based mental therapy and companion\nrobots for the elderly. Most recent studies analyze the dialog content for\npersonality classification yet overlook two major concerns that hinder their\nperformance. First, crucial implicit factors contained in conversation, such as\nemotions that reflect the speakers' personalities are ignored. Second, only\nfocusing on the input dialog content disregards the semantic understanding of\npersonality itself, which reduces the interpretability of the results. In this\npaper, we propose Affective Natural Language Inference (Affective-NLI) for\naccurate and interpretable PRC. To utilize affectivity within dialog content\nfor accurate personality recognition, we fine-tuned a pre-trained language\nmodel specifically for emotion recognition in conversations, facilitating\nreal-time affective annotations for utterances. For interpretability of\nrecognition results, we formulate personality recognition as an NLI problem by\ndetermining whether the textual description of personality labels is entailed\nby the dialog content. Extensive experiments on two daily conversation datasets\nsuggest that Affective-NLI significantly outperforms (by 6%-7%)\nstate-of-the-art approaches. Additionally, our Flow experiment demonstrates\nthat Affective-NLI can accurately recognize the speaker's personality in the\nearly stages of conversations by surpassing state-of-the-art methods with\n22%-34%.",
      "tldr_zh": "该论文针对对话中的Personality Recognition in Conversation (PRC)问题，提出Affective-NLI方法，以提高个性识别的准确性和可解释性。Affective-NLI通过微调预训练语言模型进行对话情绪识别，实现实时情感标注，并将个性识别转化为Natural Language Inference (NLI)问题，判断个性标签描述是否被对话内容蕴含。实验结果显示，该方法在两个日常对话数据集上比现有方法提升6%-7%，且在对话早期阶段的识别准确率高出22%-34%。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted by IEEE PerCom 2024",
      "pdf_url": "http://arxiv.org/pdf/2404.02589v1",
      "published_date": "2024-04-03 09:14:24 UTC",
      "updated_date": "2024-04-03 09:14:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T21:29:57.667891"
    },
    {
      "arxiv_id": "2404.02587v2",
      "title": "The Surprising Effectiveness of Rankers Trained on Expanded Queries",
      "title_zh": "翻译失败",
      "authors": [
        "Abhijit Anand",
        "Venktesh V",
        "Vinay Setty",
        "Avishek Anand"
      ],
      "abstract": "An important problem in text-ranking systems is handling the hard queries\nthat form the tail end of the query distribution. The difficulty may arise due\nto the presence of uncommon, underspecified, or incomplete queries. In this\nwork, we improve the ranking performance of hard or difficult queries without\ncompromising the performance of other queries. Firstly, we do LLM based query\nenrichment for training queries using relevant documents. Next, a specialized\nranker is fine-tuned only on the enriched hard queries instead of the original\nqueries. We combine the relevance scores from the specialized ranker and the\nbase ranker, along with a query performance score estimated for each query. Our\napproach departs from existing methods that usually employ a single ranker for\nall queries, which is biased towards easy queries, which form the majority of\nthe query distribution. In our extensive experiments on the DL-Hard dataset, we\nfind that a principled query performance based scoring method using base and\nspecialized ranker offers a significant improvement of up to 25% on the passage\nranking task and up to 48.4% on the document ranking task when compared to the\nbaseline performance of using original queries, even outperforming SOTA model.",
      "tldr_zh": "本研究探讨了文本排名系统中处理难查询（hard queries，如不常见或不完整的查询）的方法，提出了一种创新策略，通过LLM进行查询扩展（query enrichment）来丰富训练查询，并针对扩展后的难查询微调一个专门的排名器（specialized ranker）。该方法将专门排名器的相关性分数与基础排名器（base ranker）的分数结合，并融入查询性能分数（query performance score），从而避免单一排名器对易查询的偏见。实验在DL-Hard数据集上显示，该方法在段落排名任务上提升高达25%，在文档排名任务上提升高达48.4%，甚至超越了SOTA模型。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.02587v2",
      "published_date": "2024-04-03 09:12:22 UTC",
      "updated_date": "2024-06-12 09:34:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T21:30:09.644824"
    },
    {
      "arxiv_id": "2404.02580v1",
      "title": "Active learning for efficient annotation in precision agriculture: a use-case on crop-weed semantic segmentation",
      "title_zh": "主动学习用于精准农业中的高效标注：作物-杂草语义分割的一个用例",
      "authors": [
        "Bart M. van Marrewijk",
        "Charbel Dandjinou",
        "Dan Jeric Arcega Rustia",
        "Nicolas Franco Gonzalez",
        "Boubacar Diallo",
        "Jérôme Dias",
        "Paul Melki",
        "Pieter M. Blok"
      ],
      "abstract": "Optimizing deep learning models requires large amounts of annotated images, a\nprocess that is both time-intensive and costly. Especially for semantic\nsegmentation models in which every pixel must be annotated. A potential\nstrategy to mitigate annotation effort is active learning. Active learning\nfacilitates the identification and selection of the most informative images\nfrom a large unlabelled pool. The underlying premise is that these selected\nimages can improve the model's performance faster than random selection to\nreduce annotation effort. While active learning has demonstrated promising\nresults on benchmark datasets like Cityscapes, its performance in the\nagricultural domain remains largely unexplored. This study addresses this\nresearch gap by conducting a comparative study of three active learning-based\nacquisition functions: Bayesian Active Learning by Disagreement (BALD),\nstochastic-based BALD (PowerBALD), and Random. The acquisition functions were\ntested on two agricultural datasets: Sugarbeet and Corn-Weed, both containing\nthree semantic classes: background, crop and weed. Our results indicated that\nactive learning, especially PowerBALD, yields a higher performance than Random\nsampling on both datasets. But due to the relatively large standard deviations,\nthe differences observed were minimal; this was partly caused by high image\nredundancy and imbalanced classes. Specifically, more than 89\\% of the pixels\nbelonged to the background class on both datasets. The absence of significant\nresults on both datasets indicates that further research is required for\napplying active learning on agricultural datasets, especially if they contain a\nhigh-class imbalance and redundant images. Recommendations and insights are\nprovided in this paper to potentially resolve such issues.",
      "tldr_zh": "这篇论文探讨了 active learning 在精确农业中用于减少图像标注努力的应用，针对 crop-weed semantic segmentation 任务，通过选择最信息丰富的图像来优化深度学习模型。研究比较了三种 acquisition functions：Bayesian Active Learning by Disagreement (BALD)、stochastic-based BALD (PowerBALD) 和 Random，在 Sugarbeet 和 Corn-Weed 数据集上进行测试，这些数据集包含 background、crop 和 weed 三类。结果显示 PowerBALD 比 Random 采样表现出更高的性能，但差异最小，主要受图像冗余和高类不平衡（背景类占89%以上）影响。论文强调需要进一步研究 active learning 在农业数据集中的应用，并提供了相关推荐。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.02580v1",
      "published_date": "2024-04-03 08:55:44 UTC",
      "updated_date": "2024-04-03 08:55:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T21:30:23.934721"
    },
    {
      "arxiv_id": "2404.02579v1",
      "title": "Learning Alternative Ways of Performing a Task",
      "title_zh": "翻译失败",
      "authors": [
        "David Nieves",
        "María José Ramírez-Quintana",
        "Carlos Monserrat",
        "César Ferri",
        "José Hernández-Orallo"
      ],
      "abstract": "A common way of learning to perform a task is to observe how it is carried\nout by experts. However, it is well known that for most tasks there is no\nunique way to perform them. This is especially noticeable the more complex the\ntask is because factors such as the skill or the know-how of the expert may\nwell affect the way she solves the task. In addition, learning from experts\nalso suffers of having a small set of training examples generally coming from\nseveral experts (since experts are usually a limited and expensive resource),\nbeing all of them positive examples (i.e. examples that represent successful\nexecutions of the task). Traditional machine learning techniques are not useful\nin such scenarios, as they require extensive training data. Starting from very\nfew executions of the task presented as activity sequences, we introduce a\nnovel inductive approach for learning multiple models, with each one\nrepresenting an alternative strategy of performing a task. By an iterative\nprocess based on generalisation and specialisation, we learn the underlying\npatterns that capture the different styles of performing a task exhibited by\nthe examples. We illustrate our approach on two common activity recognition\ntasks: a surgical skills training task and a cooking domain. We evaluate the\ninferred models with respect to two metrics that measure how well the models\nrepresent the examples and capture the different forms of executing a task\nshowed by the examples. We compare our results with the traditional process\nmining approach and show that a small set of meaningful examples is enough to\nobtain patterns that capture the different strategies that are followed to\nsolve the tasks.",
      "tldr_zh": "该论文指出，传统从专家演示中学习任务存在局限性，因为大多数任务有多种执行方式，且训练数据稀少且仅为正例。研究提出了一种新颖的归纳方法（inductive approach），通过基于泛化和特化的迭代过程，从少量任务执行序列中学习多个模型，每个模型代表一种备选策略，以捕获不同任务风格。实验在手术技能训练和烹饪领域进行，与传统过程挖掘（process mining）方法比较，结果显示少量示例即可有效识别和表示各种执行方式。",
      "categories": [
        "cs.AI",
        "I.2.6; I.5.4"
      ],
      "primary_category": "cs.AI",
      "comment": "32 pages, Github repository, published paper, authors' version",
      "pdf_url": "http://arxiv.org/pdf/2404.02579v1",
      "published_date": "2024-04-03 08:54:58 UTC",
      "updated_date": "2024-04-03 08:54:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T21:30:35.858824"
    },
    {
      "arxiv_id": "2404.07229v1",
      "title": "Personality-affected Emotion Generation in Dialog Systems",
      "title_zh": "人格影响下的情感生成在对话系统中",
      "authors": [
        "Zhiyuan Wen",
        "Jiannong Cao",
        "Jiaxing Shen",
        "Ruosong Yang",
        "Shuaiqi Liu",
        "Maosong Sun"
      ],
      "abstract": "Generating appropriate emotions for responses is essential for dialog systems\nto provide human-like interaction in various application scenarios. Most\nprevious dialog systems tried to achieve this goal by learning empathetic\nmanners from anonymous conversational data. However, emotional responses\ngenerated by those methods may be inconsistent, which will decrease user\nengagement and service quality. Psychological findings suggest that the\nemotional expressions of humans are rooted in personality traits. Therefore, we\npropose a new task, Personality-affected Emotion Generation, to generate\nemotion based on the personality given to the dialog system and further\ninvestigate a solution through the personality-affected mood transition.\nSpecifically, we first construct a daily dialog dataset, Personality\nEmotionLines Dataset (PELD), with emotion and personality annotations.\nSubsequently, we analyze the challenges in this task, i.e., (1) heterogeneously\nintegrating personality and emotional factors and (2) extracting\nmulti-granularity emotional information in the dialog context. Finally, we\npropose to model the personality as the transition weight by simulating the\nmood transition process in the dialog system and solve the challenges above. We\nconduct extensive experiments on PELD for evaluation. Results suggest that by\nadopting our method, the emotion generation performance is improved by 13% in\nmacro-F1 and 5% in weighted-F1 from the BERT-base model.",
      "tldr_zh": "该论文提出了一种新任务Personality-affected Emotion Generation，旨在根据对话系统的个性特征生成更一致的情感响应，以提升对话系统的用户互动质量。研究者构建了Personality EmotionLines Dataset (PELD)数据集，包含情感和个性注解，并分析了整合个性与情感因素的挑战，如异质整合和提取多粒度情感信息。为解决这些问题，他们将个性建模为过渡权重，模拟对话系统中的情绪转换过程。实验结果显示，该方法在PELD数据集上相比BERT-base模型，macro-F1得分提高了13%，weighted-F1得分提高了5%。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted by ACM Transactions on Information Systems",
      "pdf_url": "http://arxiv.org/pdf/2404.07229v1",
      "published_date": "2024-04-03 08:48:50 UTC",
      "updated_date": "2024-04-03 08:48:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T21:30:46.469009"
    },
    {
      "arxiv_id": "2404.02569v2",
      "title": "SliceIt! -- A Dual Simulator Framework for Learning Robot Food Slicing",
      "title_zh": "翻译失败",
      "authors": [
        "Cristian C. Beltran-Hernandez",
        "Nicolas Erbetti",
        "Masashi Hamaya"
      ],
      "abstract": "Cooking robots can enhance the home experience by reducing the burden of\ndaily chores. However, these robots must perform their tasks dexterously and\nsafely in shared human environments, especially when handling dangerous tools\nsuch as kitchen knives. This study focuses on enabling a robot to autonomously\nand safely learn food-cutting tasks. More specifically, our goal is to enable a\ncollaborative robot or industrial robot arm to perform food-slicing tasks by\nadapting to varying material properties using compliance control. Our approach\ninvolves using Reinforcement Learning (RL) to train a robot to compliantly\nmanipulate a knife, by reducing the contact forces exerted by the food items\nand by the cutting board. However, training the robot in the real world can be\ninefficient, and dangerous, and result in a lot of food waste. Therefore, we\nproposed SliceIt!, a framework for safely and efficiently learning robot\nfood-slicing tasks in simulation. Following a real2sim2real approach, our\nframework consists of collecting a few real food slicing data, calibrating our\ndual simulation environment (a high-fidelity cutting simulator and a robotic\nsimulator), learning compliant control policies on the calibrated simulation\nenvironment, and finally, deploying the policies on the real robot.",
      "tldr_zh": "本研究提出SliceIt!框架，这是一个双模拟器系统，用于帮助机器人安全高效地学习食物切割任务，目标是让机器人臂通过顺从控制(compliance control)适应不同材料属性的食物，同时减少接触力。框架采用real2sim2real方法，先收集少量真实数据校准高保真切割模拟器和机器人模拟器，然后在模拟环境中使用强化学习(Reinforcement Learning, RL)训练顺从控制策略。最终，策略部署到真实机器人上，避免了真实训练的浪费和危险，提高了切割任务的适应性和安全性。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "Accepted to ICRA 2024",
      "pdf_url": "http://arxiv.org/pdf/2404.02569v2",
      "published_date": "2024-04-03 08:42:36 UTC",
      "updated_date": "2024-09-26 05:57:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T21:31:00.732803"
    },
    {
      "arxiv_id": "2404.02552v1",
      "title": "Solar synthetic imaging: Introducing denoising diffusion probabilistic models on SDO/AIA data",
      "title_zh": "翻译失败",
      "authors": [
        "Francesco P. Ramunno",
        "S. Hackstein",
        "V. Kinakh",
        "M. Drozdova",
        "G. Quetant",
        "A. Csillaghy",
        "S. Voloshynovskiy"
      ],
      "abstract": "Given the rarity of significant solar flares compared to smaller ones,\ntraining effective machine learning models for solar activity forecasting is\nchallenging due to insufficient data. This study proposes using generative deep\nlearning models, specifically a Denoising Diffusion Probabilistic Model (DDPM),\nto create synthetic images of solar phenomena, including flares of varying\nintensities. By employing a dataset from the AIA instrument aboard the SDO\nspacecraft, focusing on the 171 {\\AA} band that captures various solar\nactivities, and classifying images with GOES X-ray measurements based on flare\nintensity, we aim to address the data scarcity issue. The DDPM's performance is\nevaluated using cluster metrics, Frechet Inception Distance (FID), and\nF1-score, showcasing promising results in generating realistic solar imagery.\nWe conduct two experiments: one to train a supervised classifier for event\nidentification and another for basic flare prediction, demonstrating the value\nof synthetic data in managing imbalanced datasets. This research underscores\nthe potential of DDPMs in solar data analysis and forecasting, suggesting\nfurther exploration into their capabilities for solar flare prediction and\napplication in other deep learning and physical tasks.",
      "tldr_zh": "这篇论文提出使用 Denoising Diffusion Probabilistic Model (DDPM) 生成合成太阳图像，以解决太阳活动预测中数据稀缺的问题，特别是针对不同强度的耀斑。研究基于 SDO/AIA 仪器的 171 Å 波段数据，并结合 GOES X-ray 测量进行图像分类和生成实验。评估指标包括 cluster metrics、Frechet Inception Distance (FID) 和 F1-score，结果显示 DDPM 能产生高度真实的合成图像，提升了事件识别和耀斑预测的性能。该方法为处理不平衡数据集提供了新途径，并建议进一步探索 DDPM 在太阳数据分析和预报中的应用。",
      "categories": [
        "astro-ph.SR",
        "astro-ph.IM",
        "cs.AI"
      ],
      "primary_category": "astro-ph.SR",
      "comment": "16 pages, 10 figures. Accepted for publication in Astronomy and\n  Astrophysics (A&A)",
      "pdf_url": "http://arxiv.org/pdf/2404.02552v1",
      "published_date": "2024-04-03 08:18:45 UTC",
      "updated_date": "2024-04-03 08:18:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T21:31:11.865862"
    },
    {
      "arxiv_id": "2404.02548v2",
      "title": "AI-Tutoring in Software Engineering Education",
      "title_zh": "翻译失败",
      "authors": [
        "Eduard Frankford",
        "Clemens Sauerwein",
        "Patrick Bassner",
        "Stephan Krusche",
        "Ruth Breu"
      ],
      "abstract": "With the rapid advancement of artificial intelligence (AI) in various\ndomains, the education sector is set for transformation. The potential of\nAI-driven tools in enhancing the learning experience, especially in\nprogramming, is immense. However, the scientific evaluation of Large Language\nModels (LLMs) used in Automated Programming Assessment Systems (APASs) as an\nAI-Tutor remains largely unexplored. Therefore, there is a need to understand\nhow students interact with such AI-Tutors and to analyze their experiences. In\nthis paper, we conducted an exploratory case study by integrating the\nGPT-3.5-Turbo model as an AI-Tutor within the APAS Artemis. Through a\ncombination of empirical data collection and an exploratory survey, we\nidentified different user types based on their interaction patterns with the\nAI-Tutor. Additionally, the findings highlight advantages, such as timely\nfeedback and scalability. However, challenges like generic responses and\nstudents' concerns about a learning progress inhibition when using the AI-Tutor\nwere also evident. This research adds to the discourse on AI's role in\neducation.",
      "tldr_zh": "这篇论文探讨了AI-Tutor在软件工程教育中的应用，特别是利用Large Language Models (LLMs)来提升编程学习体验，并评估其在Automated Programming Assessment Systems (APASs)中的效果。研究者通过将GPT-3.5-Turbo整合到APAS Artemis系统中，进行探索性案例研究，分析学生与AI-Tutor的交互模式，并识别了不同用户类型。结果显示，AI-Tutor的优势包括提供及时反馈和可扩展性，但也存在挑战，如泛化响应和学生对学习进步受阻的担忧。该研究为AI在教育领域的角色提供了新的讨论基础。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "11 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2404.02548v2",
      "published_date": "2024-04-03 08:15:08 UTC",
      "updated_date": "2024-04-05 07:05:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T21:31:23.327606"
    },
    {
      "arxiv_id": "2407.00828v1",
      "title": "DRL-Based RAT Selection in a Hybrid Vehicular Communication Network",
      "title_zh": "翻译失败",
      "authors": [
        "Badreddine Yacine Yacheur",
        "Toufik Ahmed",
        "Mohamed Mosbah"
      ],
      "abstract": "Cooperative intelligent transport systems rely on a set of\nVehicle-to-Everything (V2X) applications to enhance road safety. Emerging new\nV2X applications like Advanced Driver Assistance Systems (ADASs) and Connected\nAutonomous Driving (CAD) applications depend on a significant amount of shared\ndata and require high reliability, low end-to-end (E2E) latency, and high\nthroughput. However, present V2X communication technologies such as ITS-G5 and\nC-V2X (Cellular V2X) cannot satisfy these requirements alone. In this paper, we\npropose an intelligent, scalable hybrid vehicular communication architecture\nthat leverages the performance of multiple Radio Access Technologies (RATs) to\nmeet the needs of these applications. Then, we propose a communication mode\nselection algorithm based on Deep Reinforcement Learning (DRL) to maximize the\nnetwork's reliability while limiting resource consumption. Finally, we assess\nour work using the platooning scenario that requires high reliability.\nNumerical results reveal that the hybrid vehicular communication architecture\nhas the potential to enhance the packet reception rate (PRR) by up to 30%\ncompared to both the static RAT selection strategy and the multi-criteria\ndecision-making (MCDM) selection algorithm. Additionally, it improves the\nefficiency of the redundant communication mode by 20% regarding resource\nconsumption",
      "tldr_zh": "该论文针对合作智能交通系统中的 V2X 应用（如 ADAS 和 CAD），提出了一种智能可扩展的混合车辆通信架构，利用多种 Radio Access Technologies (RATs) 来满足高可靠性、低端到端 (E2E) 延迟和高吞吐量的需求。论文开发了一种基于 Deep Reinforcement Learning (DRL) 的通信模式选择算法，以最大化网络可靠性同时限制资源消耗。实验结果显示，在编队行驶 (platooning) 场景下，该架构相比静态 RAT 选择策略和多准则决策 (MCDM) 算法，提高了 Packet Reception Rate (PRR) 达 30%，并将冗余通信模式的资源效率提升 20%。",
      "categories": [
        "cs.NI",
        "cs.AI"
      ],
      "primary_category": "cs.NI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.00828v1",
      "published_date": "2024-04-03 08:13:07 UTC",
      "updated_date": "2024-04-03 08:13:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T21:31:34.917337"
    },
    {
      "arxiv_id": "2404.02545v2",
      "title": "Grid-Mapping Pseudo-Count Constraint for Offline Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Yi Shen",
        "Hanyan Huang"
      ],
      "abstract": "Offline reinforcement learning learns from a static dataset without\ninteracting with environments, which ensures security and thus owns a good\napplication prospect. However, directly applying naive reinforcement learning\nalgorithm usually fails in an offline environment due to inaccurate Q value\napproximation caused by out-of-distribution (OOD) state-actions. It is an\neffective way to solve this problem by penalizing the Q-value of OOD\nstate-actions. Among the methods of punishing OOD state-actions, count-based\nmethods have achieved good results in discrete domains in a simple form.\nInspired by it, a novel pseudo-count method for continuous domains called\nGrid-Mapping Pseudo-Count method (GPC) is proposed by extending the count-based\nmethod from discrete to continuous domains. Firstly, the continuous state and\naction space are mapped to discrete space using Grid-Mapping, then the Q-values\nof OOD state-actions are constrained through pseudo-count. Secondly, the\ntheoretical proof is given to show that GPC can obtain appropriate uncertainty\nconstraints under fewer assumptions than other pseudo-count methods. Thirdly,\nGPC is combined with Soft Actor-Critic algorithm (SAC) to get a new algorithm\ncalled GPC-SAC. Lastly, experiments on D4RL datasets are given to show that\nGPC-SAC has better performance and less computational cost than other\nalgorithms that constrain the Q-value.",
      "tldr_zh": "该论文针对离线强化学习（Offline Reinforcement Learning）中，由于OOD（Out-of-Distribution）状态-动作导致Q值估计不准确的问题，提出了一种新的伪计数方法Grid-Mapping Pseudo-Count (GPC)。GPC通过Grid-Mapping将连续状态和动作空间映射到离散空间，然后利用伪计数约束OOD状态-动作的Q值，以有效降低不确定性。作者提供了理论证明，表明GPC在更少的假设下即可实现合适的不确定性约束，并将其与Soft Actor-Critic (SAC)算法结合，形成了GPC-SAC算法。在D4RL数据集上的实验显示，GPC-SAC比其他算法表现出更好的性能和更低的计算成本。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.02545v2",
      "published_date": "2024-04-03 08:03:27 UTC",
      "updated_date": "2024-11-07 09:20:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T21:31:48.463266"
    },
    {
      "arxiv_id": "2404.02543v3",
      "title": "Unbiased Learning to Rank Meets Reality: Lessons from Baidu's Large-Scale Search Dataset",
      "title_zh": "翻译失败",
      "authors": [
        "Philipp Hager",
        "Romain Deffayet",
        "Jean-Michel Renders",
        "Onno Zoeter",
        "Maarten de Rijke"
      ],
      "abstract": "Unbiased learning-to-rank (ULTR) is a well-established framework for learning\nfrom user clicks, which are often biased by the ranker collecting the data.\nWhile theoretically justified and extensively tested in simulation, ULTR\ntechniques lack empirical validation, especially on modern search engines. The\nBaidu-ULTR dataset released for the WSDM Cup 2023, collected from Baidu's\nsearch engine, offers a rare opportunity to assess the real-world performance\nof prominent ULTR techniques. Despite multiple submissions during the WSDM Cup\n2023 and the subsequent NTCIR ULTRE-2 task, it remains unclear whether the\nobserved improvements stem from applying ULTR or other learning techniques.\n  In this work, we revisit and extend the available experiments on the\nBaidu-ULTR dataset. We find that standard unbiased learning-to-rank techniques\nrobustly improve click predictions but struggle to consistently improve ranking\nperformance, especially considering the stark differences obtained by choice of\nranking loss and query-document features. Our experiments reveal that gains in\nclick prediction do not necessarily translate to enhanced ranking performance\non expert relevance annotations, implying that conclusions strongly depend on\nhow success is measured in this benchmark.",
      "tldr_zh": "这篇论文评估了无偏学习排序 (ULTR) 技术在真实世界搜索引擎中的表现，利用 Baidu-ULTR 数据集进行实证分析。研究者重新审视了相关实验，发现标准 ULTR 方法能有效改善点击预测，但难以一致提升排名性能，尤其受排序损失函数和查询-文档特征的影响。主要发现是，点击预测的提升并不必然转化为基于专家相关性注解的排名改进，这表明在该基准测试中，结论高度依赖于成功评估指标的选择。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.02543v3",
      "published_date": "2024-04-03 08:00:46 UTC",
      "updated_date": "2024-05-15 14:04:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T21:32:00.264147"
    },
    {
      "arxiv_id": "2405.14879v1",
      "title": "Automatic Coral Detection with YOLO: A Deep Learning Approach for Efficient and Accurate Coral Reef Monitoring",
      "title_zh": "基于 YOLO 的自动珊瑚检测：一种用于高效且准确珊瑚礁监测的深度学习方法",
      "authors": [
        "Ouassine Younes",
        "Zahir Jihad",
        "Conruyt Noël",
        "Kayal Mohsen",
        "A. Martin Philippe",
        "Chenin Eric",
        "Bigot Lionel",
        "Vignes Lebbe Regine"
      ],
      "abstract": "Coral reefs are vital ecosystems that are under increasing threat due to\nlocal human impacts and climate change. Efficient and accurate monitoring of\ncoral reefs is crucial for their conservation and management. In this paper, we\npresent an automatic coral detection system utilizing the You Only Look Once\n(YOLO) deep learning model, which is specifically tailored for underwater\nimagery analysis. To train and evaluate our system, we employ a dataset\nconsisting of 400 original underwater images. We increased the number of\nannotated images to 580 through image manipulation using data augmentation\ntechniques, which can improve the model's performance by providing more diverse\nexamples for training. The dataset is carefully collected from underwater\nvideos that capture various coral reef environments, species, and lighting\nconditions. Our system leverages the YOLOv5 algorithm's real-time object\ndetection capabilities, enabling efficient and accurate coral detection. We\nused YOLOv5 to extract discriminating features from the annotated dataset,\nenabling the system to generalize, including previously unseen underwater\nimages. The successful implementation of the automatic coral detection system\nwith YOLOv5 on our original image dataset highlights the potential of advanced\ncomputer vision techniques for coral reef research and conservation. Further\nresearch will focus on refining the algorithm to handle challenging underwater\nimage conditions, and expanding the dataset to incorporate a wider range of\ncoral species and spatio-temporal variations.",
      "tldr_zh": "本文提出了一种基于 YOLO 的深度学习方法，用于高效准确的珊瑚礁监测，通过 YOLOv5 模型实现自动珊瑚检测，以应对珊瑚礁面临的人类影响和气候变化威胁。研究团队使用 400 张原始水下图像，并通过数据增强技术扩展到 580 张，涵盖多样化的环境、物种和光照条件，以训练模型提升其泛化能力。实验结果显示，该系统在实时物体检测中表现出色，在原始数据集上实现了高准确率，并为珊瑚礁研究和保护提供了先进计算机视觉应用的潜力。未来工作将优化算法以处理复杂水下图像，并扩展数据集以包含更多珊瑚物种和时空变化。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.14879v1",
      "published_date": "2024-04-03 08:00:46 UTC",
      "updated_date": "2024-04-03 08:00:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T21:32:12.202712"
    },
    {
      "arxiv_id": "2404.02534v1",
      "title": "ANGOFA: Leveraging OFA Embedding Initialization and Synthetic Data for Angolan Language Model",
      "title_zh": "翻译失败",
      "authors": [
        "Osvaldo Luamba Quinjica",
        "David Ifeoluwa Adelani"
      ],
      "abstract": "In recent years, the development of pre-trained language models (PLMs) has\ngained momentum, showcasing their capacity to transcend linguistic barriers and\nfacilitate knowledge transfer across diverse languages. However, this progress\nhas predominantly bypassed the inclusion of very-low resource languages,\ncreating a notable void in the multilingual landscape. This paper addresses\nthis gap by introducing four tailored PLMs specifically finetuned for Angolan\nlanguages, employing a Multilingual Adaptive Fine-tuning (MAFT) approach. In\nthis paper, we survey the role of informed embedding initialization and\nsynthetic data in enhancing the performance of MAFT models in downstream tasks.\nWe improve baseline over SOTA AfroXLMR-base (developed through MAFT) and OFA\n(an effective embedding initialization) by 12.3 and 3.8 points respectively.",
      "tldr_zh": "本论文提出ANGOFA框架，通过Multilingual Adaptive Fine-tuning (MAFT)方法开发了四个针对安哥拉语言的预训练语言模型 (PLMs)，以填补低资源语言在多语言模型中的空白。研究重点考察了OFA嵌入初始化和合成数据在提升MAFT模型下游任务性能方面的作用。结果显示，与SOTA AfroXLMR-base和OFA模型相比，该框架分别提高了12.3和3.8点的性能，为安哥拉语言的模型训练提供了有效改进路径。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.02534v1",
      "published_date": "2024-04-03 07:44:38 UTC",
      "updated_date": "2024-04-03 07:44:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T21:32:25.344107"
    },
    {
      "arxiv_id": "2404.02532v1",
      "title": "Learn to Disguise: Avoid Refusal Responses in LLM's Defense via a Multi-agent Attacker-Disguiser Game",
      "title_zh": "翻译失败",
      "authors": [
        "Qianqiao Xu",
        "Zhiliang Tian",
        "Hongyan Wu",
        "Zhen Huang",
        "Yiping Song",
        "Feng Liu",
        "Dongsheng Li"
      ],
      "abstract": "With the enhanced performance of large models on natural language processing\ntasks, potential moral and ethical issues of large models arise. There exist\nmalicious attackers who induce large models to jailbreak and generate\ninformation containing illegal, privacy-invasive information through techniques\nsuch as prompt engineering. As a result, large models counter malicious\nattackers' attacks using techniques such as safety alignment. However, the\nstrong defense mechanism of the large model through rejection replies is easily\nidentified by attackers and used to strengthen attackers' capabilities. In this\npaper, we propose a multi-agent attacker-disguiser game approach to achieve a\nweak defense mechanism that allows the large model to both safely reply to the\nattacker and hide the defense intent. First, we construct a multi-agent\nframework to simulate attack and defense scenarios, playing different roles to\nbe responsible for attack, disguise, safety evaluation, and disguise evaluation\ntasks. After that, we design attack and disguise game algorithms to optimize\nthe game strategies of the attacker and the disguiser and use the curriculum\nlearning process to strengthen the capabilities of the agents. The experiments\nverify that the method in this paper is more effective in strengthening the\nmodel's ability to disguise the defense intent compared with other methods.\nMoreover, our approach can adapt any black-box large model to assist the model\nin defense and does not suffer from model version iterations.",
      "tldr_zh": "该研究针对大型语言模型（LLMs）的安全问题，提出一种多智能体攻击者-伪装者游戏方法，以避免模型通过拒绝响应显露防御意图，从而实现更隐蔽的弱防御机制。该框架模拟攻击和防御场景，包括攻击、伪装、安全评估和伪装评估等角色，并通过攻击和伪装游戏算法结合课程学习（curriculum learning）优化代理策略。实验结果显示，该方法比其他方法更有效地增强模型的防御意图隐藏能力，且能适应任何黑盒LLMs，而不受模型版本迭代的影响。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "13 pages, 2 figures",
      "pdf_url": "http://arxiv.org/pdf/2404.02532v1",
      "published_date": "2024-04-03 07:43:11 UTC",
      "updated_date": "2024-04-03 07:43:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T21:32:37.539253"
    },
    {
      "arxiv_id": "2404.02530v2",
      "title": "Manipulating and Mitigating Generative Model Biases without Retraining",
      "title_zh": "翻译失败",
      "authors": [
        "Jordan Vice",
        "Naveed Akhtar",
        "Richard Hartley",
        "Ajmal Mian"
      ],
      "abstract": "Text-to-image (T2I) generative models have gained increased popularity in the\npublic domain. While boasting impressive user-guided generative abilities,\ntheir black-box nature exposes users to intentionally- and intrinsically-biased\noutputs. Bias manipulation (and mitigation) techniques typically rely on\ncareful tuning of learning parameters and training data to adjust decision\nboundaries to influence model bias characteristics, which is often\ncomputationally demanding. We propose a dynamic and computationally efficient\nmanipulation of T2I model biases by exploiting their rich language embedding\nspaces without model retraining. We show that leveraging foundational vector\nalgebra allows for a convenient control over language model embeddings to shift\nT2I model outputs and control the distribution of generated classes. As a\nby-product, this control serves as a form of precise prompt engineering to\ngenerate images which are generally implausible using regular text prompts. We\ndemonstrate a constructive application of our technique by balancing the\nfrequency of social classes in generated images, effectively balancing class\ndistributions across three social bias dimensions. We also highlight a negative\nimplication of bias manipulation by framing our method as a backdoor attack\nwith severity control using semantically-null input triggers, reporting up to\n100% attack success rate.\n  Key-words: Text-to-Image Models, Generative Models, Bias, Prompt Engineering,\nBackdoor Attacks",
      "tldr_zh": "本论文提出了一种无需重新训练的方法，来操纵和缓解文本到图像 (Text-to-Image) 生成模型的偏见问题，通过利用语言嵌入空间和基础向量代数来动态控制模型输出，从而调整生成的类分布。方法允许精确的提示工程 (Prompt Engineering)，生成常规文本提示无法实现的图像，并展示了其在平衡社会类分布方面的积极应用，例如在三个社会偏见维度上有效均衡图像中的类频率。实验结果显示，该技术在平衡偏见时表现出色，同时作者警告其负面潜力，将其作为后门攻击 (Backdoor Attacks) 的工具，使用语义空触发器可实现高达100%的攻击成功率。该方法为Generative Models的偏见管理提供了高效、可计算的解决方案。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted to ECCV 2024 WS: Workshop on critical evaluation of\n  generative models and their impact on society (CEGIS)",
      "pdf_url": "http://arxiv.org/pdf/2404.02530v2",
      "published_date": "2024-04-03 07:33:30 UTC",
      "updated_date": "2024-09-17 01:07:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T21:32:49.979128"
    },
    {
      "arxiv_id": "2404.02523v1",
      "title": "Text-driven Affordance Learning from Egocentric Vision",
      "title_zh": "翻译失败",
      "authors": [
        "Tomoya Yoshida",
        "Shuhei Kurita",
        "Taichi Nishimura",
        "Shinsuke Mori"
      ],
      "abstract": "Visual affordance learning is a key component for robots to understand how to\ninteract with objects. Conventional approaches in this field rely on\npre-defined objects and actions, falling short of capturing diverse\ninteractions in realworld scenarios. The key idea of our approach is employing\ntextual instruction, targeting various affordances for a wide range of objects.\nThis approach covers both hand-object and tool-object interactions. We\nintroduce text-driven affordance learning, aiming to learn contact points and\nmanipulation trajectories from an egocentric view following textual\ninstruction. In our task, contact points are represented as heatmaps, and the\nmanipulation trajectory as sequences of coordinates that incorporate both\nlinear and rotational movements for various manipulations. However, when we\ngather data for this task, manual annotations of these diverse interactions are\ncostly. To this end, we propose a pseudo dataset creation pipeline and build a\nlarge pseudo-training dataset: TextAFF80K, consisting of over 80K instances of\nthe contact points, trajectories, images, and text tuples. We extend existing\nreferring expression comprehension models for our task, and experimental\nresults show that our approach robustly handles multiple affordances, serving\nas a new standard for affordance learning in real-world scenarios.",
      "tldr_zh": "本文提出一种文本驱动的 affordance 学习方法，从 egocentric view 出发，利用文本指令来学习物体互动的接触点（用 heatmaps 表示）和操作轨迹（包括线性和平面运动的坐标序列），以覆盖手-物体和工具-物体等多种场景。针对数据标注成本高的问题，作者开发了伪数据集创建管道，构建了 TextAFF80K 数据集，包含超过80K的图像、文本、接触点和轨迹实例。实验结果显示，通过扩展 referring expression comprehension 模型，该方法能 robustly 处理多样 affordance，成为真实世界 affordance 学习的新标准。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.02523v1",
      "published_date": "2024-04-03 07:23:03 UTC",
      "updated_date": "2024-04-03 07:23:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T21:33:02.265251"
    },
    {
      "arxiv_id": "2404.02937v5",
      "title": "Towards Explainable Traffic Flow Prediction with Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Xusen Guo",
        "Qiming Zhang",
        "Junyue Jiang",
        "Mingxing Peng",
        "Meixin Zhu",
        "Hao",
        "Yang"
      ],
      "abstract": "Traffic forecasting is crucial for intelligent transportation systems. It has\nexperienced significant advancements thanks to the power of deep learning in\ncapturing latent patterns of traffic data. However, recent deep-learning\narchitectures require intricate model designs and lack an intuitive\nunderstanding of the mapping from input data to predicted results. Achieving\nboth accuracy and explainability in traffic prediction models remains a\nchallenge due to the complexity of traffic data and the inherent opacity of\ndeep learning models. To tackle these challenges, we propose a Traffic flow\nPrediction model based on Large Language Models (LLMs) to generate explainable\ntraffic predictions, named xTP-LLM. By transferring multi-modal traffic data\ninto natural language descriptions, xTP-LLM captures complex time-series\npatterns and external factors from comprehensive traffic data. The LLM\nframework is fine-tuned using language-based instructions to align with\nspatial-temporal traffic flow data. Empirically, xTP-LLM shows competitive\naccuracy compared with deep learning baselines, while providing an intuitive\nand reliable explanation for predictions. This paper contributes to advancing\nexplainable traffic prediction models and lays a foundation for future\nexploration of LLM applications in transportation. To the best of our\nknowledge, this is the first study to use LLM for explainable prediction of\ntraffic flows.",
      "tldr_zh": "该研究针对交通流量预测的准确性和可解释性挑战，提出了一种基于 Large Language Models (LLMs) 的模型 xTP-LLM，以生成直观的预测解释。通过将多模态交通数据转化为自然语言描述，xTP-LLM 能够捕捉复杂的时间序列模式和外部因素，并通过语言指令微调 LLM 以适应空间-时间交通数据。实验结果显示，xTP-LLM 的预测准确性与深度学习基线相当，同时提供可靠的解释，为可解释交通预测模型的发展奠定基础，且这是首个使用 LLMs 进行交通流量预测的研究。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "31pages, 16 figures",
      "pdf_url": "http://arxiv.org/pdf/2404.02937v5",
      "published_date": "2024-04-03 07:14:15 UTC",
      "updated_date": "2024-09-03 11:32:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T21:33:13.340053"
    },
    {
      "arxiv_id": "2404.02515v3",
      "title": "Tightly-Coupled LiDAR-IMU-Wheel Odometry with Online Calibration of a Kinematic Model for Skid-Steering Robots",
      "title_zh": "翻译失败",
      "authors": [
        "Taku Okawara",
        "Kenji Koide",
        "Shuji Oishi",
        "Masashi Yokozuka",
        "Atsuhiko Banno",
        "Kentaro Uno",
        "Kazuya Yoshida"
      ],
      "abstract": "Tunnels and long corridors are challenging environments for mobile robots\nbecause a LiDAR point cloud should degenerate in these environments. To tackle\npoint cloud degeneration, this study presents a tightly-coupled LiDAR-IMU-wheel\nodometry algorithm with an online calibration for skid-steering robots. We\npropose a full linear wheel odometry factor, which not only serves as a motion\nconstraint but also performs the online calibration of kinematic models for\nskid-steering robots. Despite the dynamically changing kinematic model (e.g.,\nwheel radii changes caused by tire pressures) and terrain conditions, our\nmethod can address the model error via online calibration. Moreover, our method\nenables an accurate localization in cases of degenerated environments, such as\nlong and straight corridors, by calibration while the LiDAR-IMU fusion\nsufficiently operates. Furthermore, we estimate the uncertainty (i.e.,\ncovariance matrix) of the wheel odometry online for creating a reasonable\nconstraint. The proposed method is validated through three experiments. The\nfirst indoor experiment shows that the proposed method is robust in severe\ndegeneracy cases (long corridors) and changes in the wheel radii. The second\noutdoor experiment demonstrates that our method accurately estimates the sensor\ntrajectory despite being in rough outdoor terrain owing to online uncertainty\nestimation of wheel odometry. The third experiment shows the proposed online\ncalibration enables robust odometry estimation in changing terrains.",
      "tldr_zh": "这篇论文针对LiDAR点云在隧道和长走廊等退化环境中的问题，提出了一种紧密耦合的LiDAR-IMU-Wheel Odometry算法，并实现了滑移转向机器人的运动学模型在线校准。算法引入全线性轮子odometry因子，作为运动约束，同时在线估计不确定性（如协方差矩阵），以应对轮子半径变化和地形条件带来的模型误差。该方法在三个实验中得到验证，包括室内长走廊的鲁棒性测试、室外粗糙地形的准确轨迹估计，以及变化地形下的稳定odometry性能，从而提升了机器人定位的精确性和可靠性。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "Accepted by IEEE Access journal (12 September) open-source:\n  https://github.com/TakuOkawara/full_linear_wheel_odometry_factor",
      "pdf_url": "http://arxiv.org/pdf/2404.02515v3",
      "published_date": "2024-04-03 07:07:29 UTC",
      "updated_date": "2024-09-12 10:29:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T21:33:26.360117"
    },
    {
      "arxiv_id": "2404.02510v1",
      "title": "An Interpretable Client Decision Tree Aggregation process for Federated Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Alberto Argente-Garrido",
        "Cristina Zuheros",
        "M. Victoria Luzón",
        "Francisco Herrera"
      ],
      "abstract": "Trustworthy Artificial Intelligence solutions are essential in today's\ndata-driven applications, prioritizing principles such as robustness, safety,\ntransparency, explainability, and privacy among others. This has led to the\nemergence of Federated Learning as a solution for privacy and distributed\nmachine learning. While decision trees, as self-explanatory models, are ideal\nfor collaborative model training across multiple devices in\nresource-constrained environments such as federated learning environments for\ninjecting interpretability in these models. Decision tree structure makes the\naggregation in a federated learning environment not trivial. They require\ntechniques that can merge their decision paths without introducing bias or\noverfitting while keeping the aggregated decision trees robust and\ngeneralizable. In this paper, we propose an Interpretable Client Decision Tree\nAggregation process for Federated Learning scenarios that keeps the\ninterpretability and the precision of the base decision trees used for the\naggregation. This model is based on aggregating multiple decision paths of the\ndecision trees and can be used on different decision tree types, such as ID3\nand CART. We carry out the experiments within four datasets, and the analysis\nshows that the tree built with the model improves the local models, and\noutperforms the state-of-the-art.",
      "tldr_zh": "本论文提出了一种可解释的客户端决策树聚合过程（Interpretable Client Decision Tree Aggregation），旨在解决联邦学习（Federated Learning）中决策树（Decision Trees）模型的聚合挑战，确保模型保持可解释性、精度，同时避免偏差和过拟合。方法基于聚合多个决策树的决策路径，支持不同类型如 ID3 和 CART 的决策树。实验在四个数据集上进行，结果显示该模型改善了本地模型的表现，并优于现有最先进方法。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Submitted to Information Science Journal",
      "pdf_url": "http://arxiv.org/pdf/2404.02510v1",
      "published_date": "2024-04-03 06:53:56 UTC",
      "updated_date": "2024-04-03 06:53:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T21:33:37.082958"
    },
    {
      "arxiv_id": "2404.02508v1",
      "title": "VIAssist: Adapting Multi-modal Large Language Models for Users with Visual Impairments",
      "title_zh": "翻译失败",
      "authors": [
        "Bufang Yang",
        "Lixing He",
        "Kaiwei Liu",
        "Zhenyu Yan"
      ],
      "abstract": "Individuals with visual impairments, encompassing both partial and total\ndifficulties in visual perception, are referred to as visually impaired (VI)\npeople. An estimated 2.2 billion individuals worldwide are affected by visual\nimpairments. Recent advancements in multi-modal large language models (MLLMs)\nhave showcased their extraordinary capabilities across various domains. It is\ndesirable to help VI individuals with MLLMs' great capabilities of visual\nunderstanding and reasoning. However, it is challenging for VI people to use\nMLLMs due to the difficulties in capturing the desirable images to fulfill\ntheir daily requests. For example, the target object is not fully or partially\nplaced in the image. This paper explores how to leverage MLLMs for VI\nindividuals to provide visual-question answers. VIAssist can identify undesired\nimages and provide detailed actions. Finally, VIAssist can provide reliable\nanswers to users' queries based on the images. Our results show that VIAssist\nprovides +0.21 and +0.31 higher BERTScore and ROUGE scores than the baseline,\nrespectively.",
      "tldr_zh": "该研究针对视觉障碍（VI）人群（全球约22亿人）使用多模态大语言模型（MLLMs）的挑战，提出VIAssist系统，以适应其视觉理解和推理能力。VIAssist能够识别图像中的不理想部分（如目标对象未完全捕获），并提供详细行动建议，帮助用户优化图像输入。最终，该系统基于改进后的图像生成可靠的视觉问题回答，并在实验中比基线模型在BERTScore和ROUGE得分上分别提高了0.21和0.31，展示了其在辅助VI人群方面的显著提升。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted to IEEE International Workshop on Foundation Models for\n  Cyber-Physical Systems & Internet of Things (FMSys 2024)",
      "pdf_url": "http://arxiv.org/pdf/2404.02508v1",
      "published_date": "2024-04-03 06:53:27 UTC",
      "updated_date": "2024-04-03 06:53:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T21:33:48.687406"
    },
    {
      "arxiv_id": "2404.02505v1",
      "title": "Dynamic Demonstration Retrieval and Cognitive Understanding for Emotional Support Conversation",
      "title_zh": "翻译失败",
      "authors": [
        "Zhe Xu",
        "Daoyuan Chen",
        "Jiayi Kuang",
        "Zihao Yi",
        "Yaliang Li",
        "Ying Shen"
      ],
      "abstract": "Emotional Support Conversation (ESC) systems are pivotal in providing\nempathetic interactions, aiding users through negative emotional states by\nunderstanding and addressing their unique experiences. In this paper, we tackle\ntwo key challenges in ESC: enhancing contextually relevant and empathetic\nresponse generation through dynamic demonstration retrieval, and advancing\ncognitive understanding to grasp implicit mental states comprehensively. We\nintroduce Dynamic Demonstration Retrieval and Cognitive-Aspect Situation\nUnderstanding (\\ourwork), a novel approach that synergizes these elements to\nimprove the quality of support provided in ESCs. By leveraging in-context\nlearning and persona information, we introduce an innovative retrieval\nmechanism that selects informative and personalized demonstration pairs. We\nalso propose a cognitive understanding module that utilizes four cognitive\nrelationships from the ATOMIC knowledge source to deepen situational awareness\nof help-seekers' mental states. Our supportive decoder integrates information\nfrom diverse knowledge sources, underpinning response generation that is both\nempathetic and cognitively aware. The effectiveness of \\ourwork is demonstrated\nthrough extensive automatic and human evaluations, revealing substantial\nimprovements over numerous state-of-the-art models, with up to 13.79\\%\nenhancement in overall performance of ten metrics. Our codes are available for\npublic access to facilitate further research and development.",
      "tldr_zh": "该论文针对Emotional Support Conversation (ESC) 系统中的两个关键挑战：通过动态演示检索提升上下文相关和移情的响应生成，以及利用认知理解全面把握隐含心理状态。作者提出Dynamic Demonstration Retrieval and Cognitive-Aspect Situation Understanding (\\ourwork) 框架，该框架结合in-context learning和persona information进行个性化的演示对检索，并使用ATOMIC知识源的四个认知关系模块加深对求助者心理状态的认识。支持性解码器整合多样知识源信息，以生成更移情和认知感知的响应；实验结果显示，该方法在自动和人工评估中比现有最先进模型提升了多达13.79%的整体性能，并公开代码以促进进一步研究。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "68T50",
        "I.2.7"
      ],
      "primary_category": "cs.CL",
      "comment": "Accpeted by SIGIR 2024",
      "pdf_url": "http://arxiv.org/pdf/2404.02505v1",
      "published_date": "2024-04-03 06:47:15 UTC",
      "updated_date": "2024-04-03 06:47:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T21:34:02.139873"
    },
    {
      "arxiv_id": "2404.02499v2",
      "title": "Learning Generalized Policies for Fully Observable Non-Deterministic Planning Domains",
      "title_zh": "学习完全可观察非确定性规划领域的广义策略",
      "authors": [
        "Till Hofmann",
        "Hector Geffner"
      ],
      "abstract": "General policies represent reactive strategies for solving large families of\nplanning problems like the infinite collection of solvable instances from a\ngiven domain. Methods for learning such policies from a collection of small\ntraining instances have been developed successfully for classical domains. In\nthis work, we extend the formulations and the resulting combinatorial methods\nfor learning general policies over fully observable, non-deterministic (FOND)\ndomains. We also evaluate the resulting approach experimentally over a number\nof benchmark domains in FOND planning, present the general policies that result\nin some of these domains, and prove their correctness. The method for learning\ngeneral policies for FOND planning can actually be seen as an alternative FOND\nplanning method that searches for solutions, not in the given state space but\nin an abstract space defined by features that must be learned as well.",
      "tldr_zh": "该论文探讨了在完全可观测、非确定性（FOND）规划域中学习通用 policies 的方法，这些策略能作为反应性解决方案适用于大量规划问题，如一个域中的所有可解实例。研究扩展了现有的组合方法，从经典域扩展到 FOND 域，通过从小训练实例中学习特征定义的抽象空间来搜索解决方案，而不是直接在给定状态空间中进行。实验在多个基准 FOND 规划域上评估了该方法，展示了生成的通用 policies 并证明了它们的正确性，从而为 FOND 规划提供了一种替代性框架。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "presented at IJCAI'24",
      "pdf_url": "http://arxiv.org/pdf/2404.02499v2",
      "published_date": "2024-04-03 06:25:42 UTC",
      "updated_date": "2024-05-13 09:20:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T21:34:13.592600"
    },
    {
      "arxiv_id": "2404.02491v4",
      "title": "Measuring Social Norms of Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Ye Yuan",
        "Kexin Tang",
        "Jianhao Shen",
        "Ming Zhang",
        "Chenguang Wang"
      ],
      "abstract": "We present a new challenge to examine whether large language models\nunderstand social norms. In contrast to existing datasets, our dataset requires\na fundamental understanding of social norms to solve. Our dataset features the\nlargest set of social norm skills, consisting of 402 skills and 12,383\nquestions covering a wide set of social norms ranging from opinions and\narguments to culture and laws. We design our dataset according to the K-12\ncurriculum. This enables the direct comparison of the social understanding of\nlarge language models to humans, more specifically, elementary students. While\nprior work generates nearly random accuracy on our benchmark, recent large\nlanguage models such as GPT3.5-Turbo and LLaMA2-Chat are able to improve the\nperformance significantly, only slightly below human performance. We then\npropose a multi-agent framework based on large language models to improve the\nmodels' ability to understand social norms. This method further improves large\nlanguage models to be on par with humans. Given the increasing adoption of\nlarge language models in real-world applications, our finding is particularly\nimportant and presents a unique direction for future improvements.",
      "tldr_zh": "本研究提出一个新数据集，用于评估大型语言模型（Large Language Models）对社会规范的理解，该数据集包含402个技能和12,383个问题，覆盖意见、争论、文化和法律等领域，并基于K-12课程设计以便与人类（尤其是小学生）直接比较。实验结果显示，现有模型在该基准上的表现几乎随机，而GPT3.5-Turbo和LLaMA2-Chat等模型已显著提升，仅略低于人类水平。作者进一步提出一种基于大型语言模型的多智能体框架，能够将模型的社会规范理解能力提升至与人类相当水平，这为模型在现实应用的改进提供了重要方向。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.02491v4",
      "published_date": "2024-04-03 05:58:57 UTC",
      "updated_date": "2024-05-22 05:23:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T21:34:27.316765"
    },
    {
      "arxiv_id": "2404.02484v2",
      "title": "New methods for drug synergy prediction: a mini-review",
      "title_zh": "药物协同",
      "authors": [
        "Fatemeh Abbasi",
        "Juho Rousu"
      ],
      "abstract": "In this mini-review, we explore the new prediction methods for drug\ncombination synergy relying on high-throughput combinatorial screens. The fast\nprogress of the field is witnessed in the more than thirty original machine\nlearning methods published since 2021, a clear majority of them based on deep\nlearning techniques. We aim to put these papers under a unifying lens by\nhighlighting the core technologies, the data sources, the input data types and\nsynergy scores used in the methods, as well as the prediction scenarios and\nevaluation protocols that the papers deal with. Our finding is that the best\nmethods accurately solve the synergy prediction scenarios involving known drugs\nor cell lines while the scenarios involving new drugs or cell lines still fall\nshort of an accurate prediction level.",
      "tldr_zh": "这篇 mini-review 探讨了基于高通量 combinatorial screens 的药物协同预测新方法，自 2021 年以来已有超过 30 种原创 machine learning 方法被提出，其中大多数依赖 deep learning 技术。作者从核心技术、数据来源、输入数据类型、synergy scores、预测场景和评估协议等方面对这些方法进行了统一分析。研究发现，最佳方法能准确处理涉及已知药物或细胞系的协同预测场景，但对于新药物或细胞系的场景，预测准确性仍显不足。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "q-bio.QM",
        "I.2.6; J.3"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.02484v2",
      "published_date": "2024-04-03 05:44:03 UTC",
      "updated_date": "2024-04-15 11:48:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T21:34:38.446276"
    },
    {
      "arxiv_id": "2404.02478v1",
      "title": "FedSelect: Personalized Federated Learning with Customized Selection of Parameters for Fine-Tuning",
      "title_zh": "FedSelect：通过自定义参数选择进行微调的个性化联邦学习",
      "authors": [
        "Rishub Tamirisa",
        "Chulin Xie",
        "Wenxuan Bao",
        "Andy Zhou",
        "Ron Arel",
        "Aviv Shamsian"
      ],
      "abstract": "Standard federated learning approaches suffer when client data distributions\nhave sufficient heterogeneity. Recent methods addressed the client data\nheterogeneity issue via personalized federated learning (PFL) - a class of FL\nalgorithms aiming to personalize learned global knowledge to better suit the\nclients' local data distributions. Existing PFL methods usually decouple global\nupdates in deep neural networks by performing personalization on particular\nlayers (i.e. classifier heads) and global aggregation for the rest of the\nnetwork. However, preselecting network layers for personalization may result in\nsuboptimal storage of global knowledge. In this work, we propose FedSelect, a\nnovel PFL algorithm inspired by the iterative subnetwork discovery procedure\nused for the Lottery Ticket Hypothesis. FedSelect incrementally expands\nsubnetworks to personalize client parameters, concurrently conducting global\naggregations on the remaining parameters. This approach enables the\npersonalization of both client parameters and subnetwork structure during the\ntraining process. Finally, we show that FedSelect outperforms recent\nstate-of-the-art PFL algorithms under challenging client data heterogeneity\nsettings and demonstrates robustness to various real-world distributional\nshifts. Our code is available at https://github.com/lapisrocks/fedselect.",
      "tldr_zh": "该论文针对联邦学习（Federated Learning, FL）中客户端数据异质性（client data heterogeneity）问题，提出了一种新型个性化联邦学习（Personalized Federated Learning, PFL）算法FedSelect。FedSelect受Lottery Ticket Hypothesis启发，通过迭代子网络发现过程逐步扩展子网络来个性化客户端参数，同时对剩余参数进行全局聚合，从而在训练过程中动态优化参数和结构。实验结果显示，FedSelect在高异质性设置下优于现有最先进PFL算法，并对各种真实世界分布偏移（distributional shifts）表现出鲁棒性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Published in CVPR 2024",
      "pdf_url": "http://arxiv.org/pdf/2404.02478v1",
      "published_date": "2024-04-03 05:36:21 UTC",
      "updated_date": "2024-04-03 05:36:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T21:34:51.521122"
    },
    {
      "arxiv_id": "2404.02477v1",
      "title": "Enhancing Sum-Rate Performance in Constrained Multicell Networks: A Low-Information Exchange Approach",
      "title_zh": "在受限多小区网络中提升总速率性能：一种低信息交换方法",
      "authors": [
        "Youjin Kim",
        "Jonggyu Jang",
        "Hyun Jong Yang"
      ],
      "abstract": "Despite the extensive research on massive MIMO systems for 5G\ntelecommunications and beyond, the reality is that many deployed base stations\nare equipped with a limited number of antennas rather than supporting massive\nMIMO configurations. Furthermore, while the cell-less network concept, which\neliminates cell boundaries, is under investigation, practical deployments often\ngrapple with significantly limited backhaul connection capacities between base\nstations. This letter explores techniques to maximize the sum-rate performance\nwithin the constraints of these more realistically equipped multicell networks.\nWe propose an innovative approach that dramatically reduces the need for\ninformation exchange between base stations to a mere few bits, in stark\ncontrast to conventional methods that require the exchange of hundreds of bits.\nOur proposed method not only addresses the limitations imposed by current\nnetwork infrastructure but also showcases significantly improved performance\nunder these constrained conditions.",
      "tldr_zh": "尽管5G及以后通信系统中广泛研究了massive MIMO，但实际部署的许多基站仅配备有限天线，且多小区网络（multicell networks）面临后向链路容量限制。论文提出一种创新方法，通过仅交换少量位（few bits）的信息来最大化总速率性能（sum-rate performance），显著减少了传统方法所需的数百位信息交换。实验结果表明，该方法在这些约束条件下表现出色，有效提升了网络性能。",
      "categories": [
        "eess.SP",
        "cs.AI"
      ],
      "primary_category": "eess.SP",
      "comment": "5 pages, 12 figures",
      "pdf_url": "http://arxiv.org/pdf/2404.02477v1",
      "published_date": "2024-04-03 05:34:32 UTC",
      "updated_date": "2024-04-03 05:34:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T21:35:01.762825"
    },
    {
      "arxiv_id": "2404.02476v5",
      "title": "Deep Reinforcement Learning for Traveling Purchaser Problems",
      "title_zh": "翻译失败",
      "authors": [
        "Haofeng Yuan",
        "Rongping Zhu",
        "Wanlu Yang",
        "Shiji Song",
        "Keyou You",
        "Wei Fan",
        "C. L. Philip Chen"
      ],
      "abstract": "The traveling purchaser problem (TPP) is an important combinatorial\noptimization problem with broad applications. Due to the coupling between\nrouting and purchasing, existing works on TPPs commonly address route\nconstruction and purchase planning simultaneously, which, however, leads to\nexact methods with high computational cost and heuristics with sophisticated\ndesign but limited performance. In sharp contrast, we propose a novel approach\nbased on deep reinforcement learning (DRL), which addresses route construction\nand purchase planning separately, while evaluating and optimizing the solution\nfrom a global perspective. The key components of our approach include a\nbipartite graph representation for TPPs to capture the market-product\nrelations, and a policy network that extracts information from the bipartite\ngraph and uses it to sequentially construct the route. One significant benefit\nof our framework is that we can efficiently construct the route using the\npolicy network, and once the route is determined, the associated purchasing\nplan can be easily derived through linear programming, while, leveraging DRL,\nwe can train the policy network to optimize the global solution objective.\nFurthermore, by introducing a meta-learning strategy, the policy network can be\ntrained stably on large-sized TPP instances, and generalize well across\ninstances of varying sizes and distributions, even to much larger instances\nthat are never seen during training. Experiments on various synthetic TPP\ninstances and the TPPLIB benchmark demonstrate that our DRL-based approach can\nsignificantly outperform well-established TPP heuristics, reducing the\noptimality gap by 40%-90%, and also showing an advantage in runtime, especially\non large-sized instances.",
      "tldr_zh": "本研究针对旅行采购问题（Traveling Purchaser Problems, TPP）提出了一种基于深度强化学习（Deep Reinforcement Learning, DRL）的创新方法，将路由建设和采购规划分开处理，以优化全局解决方案。该方法使用二分图（bipartite graph）表示来捕捉市场-产品关系，并通过策略网络（policy network）从图中提取信息来顺序构建路由，一旦路由确定，便可通过线性规划（linear programming）轻松得出采购计划。同时，引入元学习（meta-learning）策略，使策略网络在大型TPP实例上稳定训练，并实现对不同规模和分布实例的良好泛化。在实验中，该方法在各种合成TPP实例和TPPLIB基准上显著优于现有启发式算法，将最优性差距降低40%-90%，并在运行时间上尤其在大实例中表现出优势。",
      "categories": [
        "math.OC",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "math.OC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.02476v5",
      "published_date": "2024-04-03 05:32:10 UTC",
      "updated_date": "2024-10-14 13:33:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T21:35:15.918818"
    },
    {
      "arxiv_id": "2404.02474v1",
      "title": "uTeBC-NLP at SemEval-2024 Task 9: Can LLMs be Lateral Thinkers?",
      "title_zh": "翻译失败",
      "authors": [
        "Pouya Sadeghi",
        "Amirhossein Abaskohi",
        "Yadollah Yaghoobzadeh"
      ],
      "abstract": "Inspired by human cognition, Jiang et al.(2023c) create a benchmark for\nassessing LLMs' lateral thinking-thinking outside the box. Building upon this\nbenchmark, we investigate how different prompting methods enhance LLMs'\nperformance on this task to reveal their inherent power for outside-the-box\nthinking ability. Through participating in SemEval-2024, task 9, Sentence\nPuzzle sub-task, we explore prompt engineering methods: chain of thoughts (CoT)\nand direct prompting, enhancing with informative descriptions, and employing\ncontextualizing prompts using a retrieval augmented generation (RAG) pipeline.\nOur experiments involve three LLMs including GPT-3.5, GPT-4, and\nZephyr-7B-beta. We generate a dataset of thinking paths between riddles and\noptions using GPT-4, validated by humans for quality. Findings indicate that\ncompressed informative prompts enhance performance. Dynamic in-context learning\nenhances model performance significantly. Furthermore, fine-tuning Zephyr on\nour dataset enhances performance across other commonsense datasets,\nunderscoring the value of innovative thinking.",
      "tldr_zh": "本研究探讨大型语言模型（LLMs）的横向思维（lateral thinking）能力，基于 Jiang et al. (2023c) 的基准，通过参与 SemEval-2024 Task 9 的 Sentence Puzzle 子任务，测试了 Chain of Thoughts (CoT)、直接提示、添加信息描述以及 Retrieval Augmented Generation (RAG) 管道等提示工程方法。实验涉及 GPT-3.5、GPT-4 和 Zephyr-7B-beta 模型，并使用 GPT-4 生成并由人类验证的谜语思考路径数据集。结果显示，压缩的信息提示和动态 in-context learning 显著提升了模型性能，而对 Zephyr 的微调进一步提高了其在其他常识数据集上的表现，突出了创新性思考的价值。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "12 pages, 5 figures, 6 tables, Proceedings of the 18th International\n  Workshop on Semantic Evaluation (SemEval-2024) @ NAACL 2024",
      "pdf_url": "http://arxiv.org/pdf/2404.02474v1",
      "published_date": "2024-04-03 05:31:59 UTC",
      "updated_date": "2024-04-03 05:31:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T21:35:28.042844"
    },
    {
      "arxiv_id": "2404.02466v1",
      "title": "Prompting for Numerical Sequences: A Case Study on Market Comment Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Masayuki Kawarada",
        "Tatsuya Ishigaki",
        "Hiroya Takamura"
      ],
      "abstract": "Large language models (LLMs) have been applied to a wide range of\ndata-to-text generation tasks, including tables, graphs, and time-series\nnumerical data-to-text settings. While research on generating prompts for\nstructured data such as tables and graphs is gaining momentum, in-depth\ninvestigations into prompting for time-series numerical data are lacking.\nTherefore, this study explores various input representations, including\nsequences of tokens and structured formats such as HTML, LaTeX, and\nPython-style codes. In our experiments, we focus on the task of Market Comment\nGeneration, which involves taking a numerical sequence of stock prices as input\nand generating a corresponding market comment. Contrary to our expectations,\nthe results show that prompts resembling programming languages yield better\noutcomes, whereas those similar to natural languages and longer formats, such\nas HTML and LaTeX, are less effective. Our findings offer insights into\ncreating effective prompts for tasks that generate text from numerical\nsequences.",
      "tldr_zh": "本研究探讨了大型语言模型 (LLMs) 在处理时间序列数值数据生成文本时的提示策略，以市场评论生成任务为例，该任务涉及从股票价格序列生成相应评论。研究者实验比较了多种输入表示形式，包括令牌序列、HTML、LaTeX 和 Python-style codes。结果显示，类似于编程语言的提示效果更佳，而自然语言风格或较长格式（如 HTML 和 LaTeX）的提示表现较差。这些发现为针对数值序列生成文本的任务设计有效提示提供了宝贵见解。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CE"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to LREC-COLING2024 long paper",
      "pdf_url": "http://arxiv.org/pdf/2404.02466v1",
      "published_date": "2024-04-03 05:10:11 UTC",
      "updated_date": "2024-04-03 05:10:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T21:35:39.942940"
    },
    {
      "arxiv_id": "2404.02460v1",
      "title": "TSNet:A Two-stage Network for Image Dehazing with Multi-scale Fusion and Adaptive Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Xiaolin Gong",
        "Zehan Zheng",
        "Heyuan Du"
      ],
      "abstract": "Image dehazing has been a popular topic of research for a long time. Previous\ndeep learning-based image dehazing methods have failed to achieve satisfactory\ndehazing effects on both synthetic datasets and real-world datasets, exhibiting\npoor generalization. Moreover, single-stage networks often result in many\nregions with artifacts and color distortion in output images. To address these\nissues, this paper proposes a two-stage image dehazing network called TSNet,\nmainly consisting of the multi-scale fusion module (MSFM) and the adaptive\nlearning module (ALM). Specifically, MSFM and ALM enhance the generalization of\nTSNet. The MSFM can obtain large receptive fields at multiple scales and\nintegrate features at different frequencies to reduce the differences between\ninputs and learning objectives. The ALM can actively learn of regions of\ninterest in images and restore texture details more effectively. Additionally,\nTSNet is designed as a two-stage network, where the first-stage network\nperforms image dehazing, and the second-stage network is employed to improve\nissues such as artifacts and color distortion present in the results of the\nfirst-stage network. We also change the learning objective from ground truth\nimages to opposite fog maps, which improves the learning efficiency of TSNet.\nExtensive experiments demonstrate that TSNet exhibits superior dehazing\nperformance on both synthetic and real-world datasets compared to previous\nstate-of-the-art methods.",
      "tldr_zh": "本研究针对图像去雾领域的泛化能力差和输出图像伪影、颜色失真问题，提出了一种两阶段网络TSNet。TSNet 包括多尺度融合模块(MSFM)，用于获取多尺度大感受野并整合不同频率特征，以减少输入与学习目标的差异；以及自适应学习模块(ALM)，能够主动识别图像兴趣区域并更有效地恢复纹理细节。网络采用两阶段设计，第一阶段进行初步去雾，第二阶段优化伪影和颜色失真，同时将学习目标从地面真实图像改为相反的雾图，以提升学习效率。实验结果显示，TSNet 在合成和真实数据集上比现有最先进方法表现出色，具有更好的去雾性能。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "12 pages, 10 figures, 7 tables",
      "pdf_url": "http://arxiv.org/pdf/2404.02460v1",
      "published_date": "2024-04-03 05:02:46 UTC",
      "updated_date": "2024-04-03 05:02:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T21:35:51.385753"
    },
    {
      "arxiv_id": "2404.02456v2",
      "title": "PhonologyBench: Evaluating Phonological Skills of Large Language Models",
      "title_zh": "Phonology",
      "authors": [
        "Ashima Suvarna",
        "Harshita Khandelwal",
        "Nanyun Peng"
      ],
      "abstract": "Phonology, the study of speech's structure and pronunciation rules, is a\ncritical yet often overlooked component in Large Language Model (LLM) research.\nLLMs are widely used in various downstream applications that leverage phonology\nsuch as educational tools and poetry generation. Moreover, LLMs can potentially\nlearn imperfect associations between orthographic and phonological forms from\nthe training data. Thus, it is imperative to benchmark the phonological skills\nof LLMs. To this end, we present PhonologyBench, a novel benchmark consisting\nof three diagnostic tasks designed to explicitly test the phonological skills\nof LLMs in English: grapheme-to-phoneme conversion, syllable counting, and\nrhyme word generation. Despite having no access to speech data, LLMs showcased\nnotable performance on the PhonologyBench tasks. However, we observe a\nsignificant gap of 17% and 45% on Rhyme Word Generation and Syllable counting,\nrespectively, when compared to humans. Our findings underscore the importance\nof studying LLM performance on phonological tasks that inadvertently impact\nreal-world applications. Furthermore, we encourage researchers to choose LLMs\nthat perform well on the phonological task that is closely related to the\ndownstream application since we find that no single model consistently\noutperforms the others on all the tasks.",
      "tldr_zh": "这篇论文介绍了 PhonologyBench，一个新基准，用于评估大型语言模型(LLMs)在语音学(Phonology)技能方面的表现，包括grapheme-to-phoneme conversion（字母到音素转换）、syllable counting（音节计数）和rhyme word generation（押韵词生成）等三个任务。研究发现，尽管LLMs未使用语音数据，但它们在这些任务上表现出色，却与人类相比在押韵词生成和音节计数上存在17%和45%的性能差距。论文强调了评估LLMs语音学能力的必要性，以避免其在实际应用（如教育工具和诗歌生成）中的潜在问题，并建议根据下游任务选择在相关领域表现突出的模型。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG",
        "cs.SD",
        "eess.AS"
      ],
      "primary_category": "cs.CL",
      "comment": "17 pages, 7 figures, 6 tables",
      "pdf_url": "http://arxiv.org/pdf/2404.02456v2",
      "published_date": "2024-04-03 04:53:14 UTC",
      "updated_date": "2024-04-05 04:55:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T21:36:04.178774"
    },
    {
      "arxiv_id": "2404.02454v4",
      "title": "Techniques for Measuring the Inferential Strength of Forgetting Policies",
      "title_zh": "翻译失败",
      "authors": [
        "Patrick Doherty",
        "Andrzej Szalas"
      ],
      "abstract": "The technique of forgetting in knowledge representation has been shown to be\na powerful and useful knowledge engineering tool with widespread application.\nYet, very little research has been done on how different policies of\nforgetting, or use of different forgetting operators, affects the inferential\nstrength of the original theory. The goal of this paper is to define loss\nfunctions for measuring changes in inferential strength based on intuitions\nfrom model counting and probability theory. Properties of such loss measures\nare studied and a pragmatic knowledge engineering tool is proposed for\ncomputing loss measures using ProbLog. The paper includes a working methodology\nfor studying and determining the strength of different forgetting policies, in\naddition to concrete examples showing how to apply the theoretical results\nusing ProbLog. Although the focus is on forgetting, the results are much more\ngeneral and should have wider application to other areas.",
      "tldr_zh": "该论文探讨了遗忘技术（forgetting）在知识表示中的应用，焦点在于评估不同遗忘策略（forgetting policies）对原理论的推理强度（inferential strength）的影响。作者基于模型计数（model counting）和概率理论（probability theory）的直觉，定义了相应的损失函数（loss functions），并研究了这些函数的属性，同时提出了一种使用 ProbLog 作为计算工具的实用工程方法。论文还提供了一个实操方法来比较各种遗忘策略的强度，并通过具体例子展示了其应用，这些结果具有更广泛的推广价值。",
      "categories": [
        "cs.AI",
        "cs.LO"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.02454v4",
      "published_date": "2024-04-03 04:50:43 UTC",
      "updated_date": "2025-02-20 09:55:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T21:36:15.199997"
    },
    {
      "arxiv_id": "2404.02450v1",
      "title": "Task Agnostic Architecture for Algorithm Induction via Implicit Composition",
      "title_zh": "翻译失败",
      "authors": [
        "Sahil J. Sindhi",
        "Ignas Budvytis"
      ],
      "abstract": "Different fields in applied machine learning such as computer vision, speech\nor natural language processing have been building domain-specialised solutions.\nCurrently, we are witnessing an opposing trend towards developing more\ngeneralist architectures, driven by Large Language Models and multi-modal\nfoundational models. These architectures are designed to tackle a variety of\ntasks, including those previously unseen and using inputs across multiple\nmodalities. Taking this trend of generalization to the extreme suggests the\npossibility of a single deep network architecture capable of solving all tasks.\nThis position paper aims to explore developing such a unified architecture and\nproposes a theoretical framework of how it could be constructed. Our proposal\nis based on the following assumptions. Firstly, tasks are solved by following a\nsequence of instructions, typically implemented in code for conventional\ncomputing hardware, which inherently operates sequentially. Second, recent\nGenerative AI, especially Transformer-based models, demonstrate potential as an\narchitecture capable of constructing algorithms for a wide range of domains.\nFor example, GPT-4 shows exceptional capability at in-context learning of novel\ntasks which is hard to explain in any other way than the ability to compose\nnovel solutions from fragments on previously learnt algorithms. Third, the\nobservation that the main missing component in developing a truly generalised\nnetwork is an efficient approach for self-consistent input of previously learnt\nsub-steps of an algorithm and their (implicit) composition during the network's\ninternal forward pass. Our exploration delves into current capabilities and\nlimitations of Transformer-based and other methods in efficient and correct\nalgorithm composition and proposes a Transformer-like architecture as well as a\ndiscrete learning framework to overcome these limitations.",
      "tldr_zh": "这篇立场论文探讨了开发一个任务无关架构（Task Agnostic Architecture），通过隐式组合（Implicit Composition）实现算法归纳（Algorithm Induction），旨在创建一个单一的深度网络来处理各种任务。论文基于三个关键假设：任务通常通过指令序列解决、Transformer-based 模型展示出构建跨领域算法的能力，以及当前模型缺少高效的自洽输入和隐式组合机制。作者分析了Transformer等方法的优势与局限性，并提出一个Transformer-like 架构和离散学习框架，以提升算法组合的效率和正确性。总的来说，这为通用AI模型的未来发展提供了理论基础。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "12 pages, 2 figures, 2024 ICLR Generative Models for Decision Making\n  Workshop",
      "pdf_url": "http://arxiv.org/pdf/2404.02450v1",
      "published_date": "2024-04-03 04:31:09 UTC",
      "updated_date": "2024-04-03 04:31:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T21:36:29.008618"
    },
    {
      "arxiv_id": "2404.02448v2",
      "title": "Electric Vehicle Routing Problem for Emergency Power Supply: Towards Telecom Base Station Relief",
      "title_zh": "翻译失败",
      "authors": [
        "Daisuke Kikuta",
        "Hiroki Ikeuchi",
        "Kengo Tajiri",
        "Yuta Toyama",
        "Masaki Nakamura",
        "Yuusuke Nakano"
      ],
      "abstract": "As a telecom provider, our company has a critical mission to maintain telecom\nservices even during power outages. To accomplish the mission, it is essential\nto maintain the power of the telecom base stations. Here we consider a solution\nwhere electric vehicles (EVs) directly supply power to base stations by\ntraveling to their locations. The goal is to find EV routes that minimize both\nthe total travel distance of all EVs and the number of downed base stations. In\nthis paper, we formulate this routing problem as a new variant of the Electric\nVehicle Routing Problem (EVRP) and propose a solver that combines a rule-based\nvehicle selector and a reinforcement learning (RL)-based node selector. The\nrule of the vehicle selector ensures the exact environmental states when the\nselected EV starts to move. In addition, the node selection by the RL model\nenables fast route generation, which is critical in emergencies. We evaluate\nour solver on both synthetic datasets and real datasets. The results show that\nour solver outperforms baselines in terms of the objective value and\ncomputation time. Moreover, we analyze the generalization and scalability of\nour solver, demonstrating the capability toward unseen settings and large-scale\nproblems. Check also our project page: https://ntt-dkiku.github.io/rl-evrpeps.",
      "tldr_zh": "该研究针对电信基站断电场景，提出了一种 Electric Vehicle Routing Problem (EVRP) 的新变体，目标是优化电动车 (EVs) 路由以最小化总行驶距离和故障基站数量，从而维持紧急供电。研究者设计了一个求解器，结合规则-based 车辆选择器（确保 EVs 启动时的环境状态准确）和 reinforcement learning (RL)-based 节点选择器（实现快速路由生成，适合紧急情况）。实验结果显示，该求解器在合成和真实数据集上优于基线模型，在目标值和计算时间方面表现出色，并证明了其在未见场景和大规模问题中的泛化性和可扩展性。总的来说，此方法为电信基站紧急供电提供了高效、可信赖的解决方案。",
      "categories": [
        "math.OC",
        "cs.AI",
        "cs.LG",
        "cs.MA"
      ],
      "primary_category": "math.OC",
      "comment": "Accepted at AAMAS 2024 (extended abstract). 10 pages, 5 figures. Work\n  in progress",
      "pdf_url": "http://arxiv.org/pdf/2404.02448v2",
      "published_date": "2024-04-03 04:27:07 UTC",
      "updated_date": "2024-04-08 02:46:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T21:36:40.956277"
    },
    {
      "arxiv_id": "2404.02447v1",
      "title": "A Novel Approach to Breast Cancer Histopathological Image Classification Using Cross-Colour Space Feature Fusion and Quantum-Classical Stack Ensemble Method",
      "title_zh": "翻译失败",
      "authors": [
        "Sambit Mallick",
        "Snigdha Paul",
        "Anindya Sen"
      ],
      "abstract": "Breast cancer classification stands as a pivotal pillar in ensuring timely\ndiagnosis and effective treatment. This study with histopathological images\nunderscores the profound significance of harnessing the synergistic\ncapabilities of colour space ensembling and quantum-classical stacking to\nelevate the precision of breast cancer classification. By delving into the\ndistinct colour spaces of RGB, HSV and CIE L*u*v, the authors initiated a\ncomprehensive investigation guided by advanced methodologies. Employing the\nDenseNet121 architecture for feature extraction the authors have capitalized on\nthe robustness of Random Forest, SVM, QSVC, and VQC classifiers. This research\nencompasses a unique feature fusion technique within the colour space ensemble.\nThis approach not only deepens our comprehension of breast cancer\nclassification but also marks a milestone in personalized medical assessment.\nThe amalgamation of quantum and classical classifiers through stacking emerges\nas a potent catalyst, effectively mitigating the inherent constraints of\nindividual classifiers, paving a robust path towards more dependable and\nrefined breast cancer identification. Through rigorous experimentation and\nmeticulous analysis, fusion of colour spaces like RGB with HSV and RGB with CIE\nL*u*v, presents an classification accuracy, nearing the value of unity. This\nunderscores the transformative potential of our approach, where the fusion of\ndiverse colour spaces and the synergy of quantum and classical realms converge\nto establish a new horizon in medical diagnostics. Thus the implications of\nthis research extend across medical disciplines, offering promising avenues for\nadvancing diagnostic accuracy and treatment efficacy.",
      "tldr_zh": "本研究提出了一种新型乳腺癌组织病理图像分类方法，通过跨颜色空间特征融合（Cross-Colour Space Feature Fusion）和量子-经典堆叠集成方法（Quantum-Classical Stack Ensemble Method）来提升诊断精度。具体而言，该方法利用 DenseNet121 架构从 RGB、HSV 和 CIE L*u*v 颜色空间提取特征，并结合 Random Forest、SVM、QSVC 和 VQC 分类器进行融合，以克服单一分类器的局限性。实验结果显示，融合如 RGB 与 HSV 或 RGB 与 CIE L*u*v 的颜色空间后，分类准确率接近 100%，这标志着在个性化医疗评估和诊断准确性方面的重要里程碑。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.02447v1",
      "published_date": "2024-04-03 04:26:50 UTC",
      "updated_date": "2024-04-03 04:26:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T21:36:53.692620"
    },
    {
      "arxiv_id": "2404.02444v1",
      "title": "The Promises and Pitfalls of Using Language Models to Measure Instruction Quality in Education",
      "title_zh": "翻译失败",
      "authors": [
        "Paiheng Xu",
        "Jing Liu",
        "Nathan Jones",
        "Julie Cohen",
        "Wei Ai"
      ],
      "abstract": "Assessing instruction quality is a fundamental component of any improvement\nefforts in the education system. However, traditional manual assessments are\nexpensive, subjective, and heavily dependent on observers' expertise and\nidiosyncratic factors, preventing teachers from getting timely and frequent\nfeedback. Different from prior research that mostly focuses on low-inference\ninstructional practices on a singular basis, this paper presents the first\nstudy that leverages Natural Language Processing (NLP) techniques to assess\nmultiple high-inference instructional practices in two distinct educational\nsettings: in-person K-12 classrooms and simulated performance tasks for\npre-service teachers. This is also the first study that applies NLP to measure\na teaching practice that is widely acknowledged to be particularly effective\nfor students with special needs. We confront two challenges inherent in\nNLP-based instructional analysis, including noisy and long input data and\nhighly skewed distributions of human ratings. Our results suggest that\npretrained Language Models (PLMs) demonstrate performances comparable to the\nagreement level of human raters for variables that are more discrete and\nrequire lower inference, but their efficacy diminishes with more complex\nteaching practices. Interestingly, using only teachers' utterances as input\nyields strong results for student-centered variables, alleviating common\nconcerns over the difficulty of collecting and transcribing high-quality\nstudent speech data in in-person teaching settings. Our findings highlight both\nthe potential and the limitations of current NLP techniques in the education\ndomain, opening avenues for further exploration.",
      "tldr_zh": "本研究探讨了使用预训练语言模型 (PLMs) 来评估教育教学质量的潜力与挑战，旨在解决传统手动评估的昂贵、主观和低效率问题。论文首次应用 Natural Language Processing (NLP) 技术来分析多种高推理教学实践，包括 K-12 课堂和预服务教师模拟任务，并测量对特殊需求学生有效的教学方法。结果显示，PLMs 在离散、低推理变量上表现与人类评级者相当，但对复杂实践的效果减弱，且仅使用教师话语作为输入即可获得良好结果。该研究突显了 NLP 在教育领域的应用前景，同时强调了数据噪声和分布倾斜等局限性，为未来探索提供了方向。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "NAACL 2024",
      "pdf_url": "http://arxiv.org/pdf/2404.02444v1",
      "published_date": "2024-04-03 04:15:29 UTC",
      "updated_date": "2024-04-03 04:15:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T21:37:05.588355"
    },
    {
      "arxiv_id": "2404.02429v1",
      "title": "AD4RL: Autonomous Driving Benchmarks for Offline Reinforcement Learning with Value-based Dataset",
      "title_zh": "翻译失败",
      "authors": [
        "Dongsu Lee",
        "Chanin Eom",
        "Minhae Kwon"
      ],
      "abstract": "Offline reinforcement learning has emerged as a promising technology by\nenhancing its practicality through the use of pre-collected large datasets.\nDespite its practical benefits, most algorithm development research in offline\nreinforcement learning still relies on game tasks with synthetic datasets. To\naddress such limitations, this paper provides autonomous driving datasets and\nbenchmarks for offline reinforcement learning research. We provide 19 datasets,\nincluding real-world human driver's datasets, and seven popular offline\nreinforcement learning algorithms in three realistic driving scenarios. We also\nprovide a unified decision-making process model that can operate effectively\nacross different scenarios, serving as a reference framework in algorithm\ndesign. Our research lays the groundwork for further collaborations in the\ncommunity to explore practical aspects of existing reinforcement learning\nmethods. Dataset and codes can be found in https://sites.google.com/view/ad4rl.",
      "tldr_zh": "这篇论文针对离线强化学习(Offline Reinforcement Learning)的研究局限性，提供了19个基于自动驾驶的真实数据集（包括人类驾驶员数据）和基准测试，涵盖三个现实驾驶场景，并评估了七种流行算法。\n论文引入了一个统一的决策过程模型，能够在不同场景中有效运作，作为算法设计参考。\n这项工作促进了强化学习社区对实际应用方面的探索，并公开了数据集和代码（https://sites.google.com/view/ad4rl）。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "ICRA 2024 Website at: https://sites.google.com/view/ad4rl",
      "pdf_url": "http://arxiv.org/pdf/2404.02429v1",
      "published_date": "2024-04-03 03:36:35 UTC",
      "updated_date": "2024-04-03 03:36:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T21:37:16.975754"
    },
    {
      "arxiv_id": "2404.04281v2",
      "title": "Similar Data Points Identification with LLM: A Human-in-the-loop Strategy Using Summarization and Hidden State Insights",
      "title_zh": "翻译失败",
      "authors": [
        "Xianlong Zeng",
        "Yijing Gao",
        "Fanghao Song",
        "Ang Liu"
      ],
      "abstract": "This study introduces a simple yet effective method for identifying similar\ndata points across non-free text domains, such as tabular and image data, using\nLarge Language Models (LLMs). Our two-step approach involves data point\nsummarization and hidden state extraction. Initially, data is condensed via\nsummarization using an LLM, reducing complexity and highlighting essential\ninformation in sentences. Subsequently, the summarization sentences are fed\nthrough another LLM to extract hidden states, serving as compact, feature-rich\nrepresentations. This approach leverages the advanced comprehension and\ngenerative capabilities of LLMs, offering a scalable and efficient strategy for\nsimilarity identification across diverse datasets. We demonstrate the\neffectiveness of our method in identifying similar data points on multiple\ndatasets. Additionally, our approach enables non-technical domain experts, such\nas fraud investigators or marketing operators, to quickly identify similar data\npoints tailored to specific scenarios, demonstrating its utility in practical\napplications. In general, our results open new avenues for leveraging LLMs in\ndata analysis across various domains",
      "tldr_zh": "本研究提出了一种简单有效的策略，使用大型语言模型 (LLM) 来识别非自由文本领域（如表格和图像数据）中相似数据点，采用人类在循环中的方法。策略包括两个步骤：首先，通过 LLM 对数据进行 summarization，简化复杂信息并突出关键内容；其次，从总结句子中提取 hidden state 作为紧凑的特征表示，从而实现高效的相似性识别。实验结果显示，该方法在多个数据集上表现出色，并能帮助非技术专家（如欺诈调查员或营销人员）快速针对特定场景识别相似数据点。总体上，这为 LLM 在数据分析领域的应用开辟了新途径。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.04281v2",
      "published_date": "2024-04-03 03:17:28 UTC",
      "updated_date": "2024-09-27 23:15:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T21:37:29.596896"
    },
    {
      "arxiv_id": "2404.02418v2",
      "title": "Auxiliary task demands mask the capabilities of smaller language models",
      "title_zh": "辅助任务需求掩盖了较小语言模型的能力",
      "authors": [
        "Jennifer Hu",
        "Michael C. Frank"
      ],
      "abstract": "Developmental psychologists have argued about when cognitive capacities such\nas language understanding or theory of mind emerge. These debates often hinge\non the concept of \"task demands\" -- the auxiliary challenges associated with\nperforming a particular evaluation -- that may mask the child's underlying\nability. The same issues arise when measuring the capacities of language models\n(LMs): performance on a task is a function of the model's underlying knowledge,\ncombined with the model's ability to interpret and perform the task given its\navailable resources. Here, we show that for analogical reasoning, reflective\nreasoning, word prediction, and grammaticality judgments, evaluation methods\nwith greater task demands yield lower performance than evaluations with reduced\ndemands. This \"demand gap\" is most pronounced for models with fewer parameters\nand less training data. Our results illustrate that LM performance should not\nbe interpreted as a direct indication of intelligence (or lack thereof), but as\na reflection of capacities seen through the lens of researchers' design\nchoices.",
      "tldr_zh": "该研究探讨了辅助任务需求（task demands）如何掩盖较小语言模型（LMs）的真实能力，类似于儿童认知研究中的现象。作者通过比较不同任务需求的评估方法，包括analogical reasoning、reflective reasoning、word prediction和grammaticality judgments，发现高需求评估会导致模型表现显著下降。结果显示，这种“demand gap”在参数少、训练数据少的模型上更为明显。最终，论文强调，LMs 的性能不应直接视为智能水平的指标，而是受研究设计选择的影响。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Published at the 1st Conference on Language Modeling (COLM 2024)",
      "pdf_url": "http://arxiv.org/pdf/2404.02418v2",
      "published_date": "2024-04-03 02:56:52 UTC",
      "updated_date": "2024-07-29 20:29:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T21:37:40.601015"
    },
    {
      "arxiv_id": "2404.02935v1",
      "title": "KnowHalu: Hallucination Detection via Multi-Form Knowledge Based Factual Checking",
      "title_zh": "翻译失败",
      "authors": [
        "Jiawei Zhang",
        "Chejian Xu",
        "Yu Gai",
        "Freddy Lecue",
        "Dawn Song",
        "Bo Li"
      ],
      "abstract": "This paper introduces KnowHalu, a novel approach for detecting hallucinations\nin text generated by large language models (LLMs), utilizing step-wise\nreasoning, multi-formulation query, multi-form knowledge for factual checking,\nand fusion-based detection mechanism. As LLMs are increasingly applied across\nvarious domains, ensuring that their outputs are not hallucinated is critical.\nRecognizing the limitations of existing approaches that either rely on the\nself-consistency check of LLMs or perform post-hoc fact-checking without\nconsidering the complexity of queries or the form of knowledge, KnowHalu\nproposes a two-phase process for hallucination detection. In the first phase,\nit identifies non-fabrication hallucinations--responses that, while factually\ncorrect, are irrelevant or non-specific to the query. The second phase,\nmulti-form based factual checking, contains five key steps: reasoning and query\ndecomposition, knowledge retrieval, knowledge optimization, judgment\ngeneration, and judgment aggregation. Our extensive evaluations demonstrate\nthat KnowHalu significantly outperforms SOTA baselines in detecting\nhallucinations across diverse tasks, e.g., improving by 15.65% in QA tasks and\n5.50% in summarization tasks, highlighting its effectiveness and versatility in\ndetecting hallucinations in LLM-generated content.",
      "tldr_zh": "该论文提出 KnowHalu，一种新型方法，用于检测大型语言模型 (LLMs) 生成文本中的 hallucination，通过步进推理、多形式查询、多形式知识的事实检查以及基于融合的检测机制来提升准确性。KnowHalu 采用两阶段过程：第一阶段识别非捏造 hallucination（如事实正确但与查询无关的响应）；第二阶段包括推理和查询分解、知识检索、知识优化、判断生成及聚合等步骤，以处理查询复杂性和知识多样性。实验结果显示，该方法在 QA 任务中比最先进基线提高 15.65%，在总结任务中提高 5.50%，证明了其在多种任务中的有效性和通用性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.02935v1",
      "published_date": "2024-04-03 02:52:07 UTC",
      "updated_date": "2024-04-03 02:52:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T21:37:53.526789"
    },
    {
      "arxiv_id": "2404.03693v1",
      "title": "Improve Knowledge Distillation via Label Revision and Data Selection",
      "title_zh": "通过标签修正和数据选择改进知识蒸馏",
      "authors": [
        "Weichao Lan",
        "Yiu-ming Cheung",
        "Qing Xu",
        "Buhua Liu",
        "Zhikai Hu",
        "Mengke Li",
        "Zhenghua Chen"
      ],
      "abstract": "Knowledge distillation (KD) has become a widely used technique in the field\nof model compression, which aims to transfer knowledge from a large teacher\nmodel to a lightweight student model for efficient network development. In\naddition to the supervision of ground truth, the vanilla KD method regards the\npredictions of the teacher as soft labels to supervise the training of the\nstudent model. Based on vanilla KD, various approaches have been developed to\nfurther improve the performance of the student model. However, few of these\nprevious methods have considered the reliability of the supervision from\nteacher models. Supervision from erroneous predictions may mislead the training\nof the student model. This paper therefore proposes to tackle this problem from\ntwo aspects: Label Revision to rectify the incorrect supervision and Data\nSelection to select appropriate samples for distillation to reduce the impact\nof erroneous supervision. In the former, we propose to rectify the teacher's\ninaccurate predictions using the ground truth. In the latter, we introduce a\ndata selection technique to choose suitable training samples to be supervised\nby the teacher, thereby reducing the impact of incorrect predictions to some\nextent. Experiment results demonstrate the effectiveness of our proposed\nmethod, and show that our method can be combined with other distillation\napproaches, improving their performance.",
      "tldr_zh": "该论文旨在改进知识蒸馏（KD）技术，通过Label Revision和Data Selection两个方面提升学生模型（student model）的性能。Label Revision方法使用ground truth修正教师模型（teacher model）的错误预测，以减少不准确监督的影响；Data Selection则选择合适的训练样本，进一步降低错误预测的干扰。实验结果证明，该方法有效提升了KD的表现，并可与其他蒸馏方法结合使用。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.03693v1",
      "published_date": "2024-04-03 02:41:16 UTC",
      "updated_date": "2024-04-03 02:41:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T21:38:02.640300"
    },
    {
      "arxiv_id": "2404.02407v1",
      "title": "Decision Transformer as a Foundation Model for Partially Observable Continuous Control",
      "title_zh": "Decision Transformer 作为基础模型用于部分",
      "authors": [
        "Xiangyuan Zhang",
        "Weichao Mao",
        "Haoran Qiu",
        "Tamer Başar"
      ],
      "abstract": "Closed-loop control of nonlinear dynamical systems with partial-state\nobservability demands expert knowledge of a diverse, less standardized set of\ntheoretical tools. Moreover, it requires a delicate integration of controller\nand estimator designs to achieve the desired system behavior. To establish a\ngeneral controller synthesis framework, we explore the Decision Transformer\n(DT) architecture. Specifically, we first frame the control task as predicting\nthe current optimal action based on past observations, actions, and rewards,\neliminating the need for a separate estimator design. Then, we leverage the\npre-trained language models, i.e., the Generative Pre-trained Transformer (GPT)\nseries, to initialize DT and subsequently train it for control tasks using\nlow-rank adaptation (LoRA). Our comprehensive experiments across five distinct\ncontrol tasks, ranging from maneuvering aerospace systems to controlling\npartial differential equations (PDEs), demonstrate DT's capability to capture\nthe parameter-agnostic structures intrinsic to control tasks. DT exhibits\nremarkable zero-shot generalization abilities for completely new tasks and\nrapidly surpasses expert performance levels with a minimal amount of\ndemonstration data. These findings highlight the potential of DT as a\nfoundational controller for general control applications.",
      "tldr_zh": "本研究将 Decision Transformer (DT) 作为基础模型，用于处理部分可观测的连续控制任务，旨在简化控制器设计并消除单独估计器的需求。方法上，通过将控制任务框架化为基于过去观察、动作和奖励预测当前最优动作，并使用预训练的 Generative Pre-trained Transformer (GPT) 系列模型初始化 DT，然后通过 low-rank adaptation (LoRA) 进行针对性训练。实验在五个不同任务中（如航天系统操控和 partial differential equations (PDEs) 控制）验证了 DT 的参数无关结构捕捉能力，展示了其卓越的零样本泛化性能，并能以少量演示数据快速超越专家水平，从而确立 DT 在通用控制应用中的潜力。",
      "categories": [
        "eess.SY",
        "cs.AI",
        "cs.LG",
        "cs.RO",
        "cs.SY"
      ],
      "primary_category": "eess.SY",
      "comment": "Submitted to CDC 2024",
      "pdf_url": "http://arxiv.org/pdf/2404.02407v1",
      "published_date": "2024-04-03 02:17:34 UTC",
      "updated_date": "2024-04-03 02:17:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T21:38:17.485640"
    },
    {
      "arxiv_id": "2404.02406v1",
      "title": "Exploring Backdoor Vulnerabilities of Chat Models",
      "title_zh": "探索聊天模型的后门漏洞",
      "authors": [
        "Yunzhuo Hao",
        "Wenkai Yang",
        "Yankai Lin"
      ],
      "abstract": "Recent researches have shown that Large Language Models (LLMs) are\nsusceptible to a security threat known as Backdoor Attack. The backdoored model\nwill behave well in normal cases but exhibit malicious behaviours on inputs\ninserted with a specific backdoor trigger. Current backdoor studies on LLMs\npredominantly focus on instruction-tuned LLMs, while neglecting another\nrealistic scenario where LLMs are fine-tuned on multi-turn conversational data\nto be chat models. Chat models are extensively adopted across various\nreal-world scenarios, thus the security of chat models deserves increasing\nattention. Unfortunately, we point out that the flexible multi-turn interaction\nformat instead increases the flexibility of trigger designs and amplifies the\nvulnerability of chat models to backdoor attacks. In this work, we reveal and\nachieve a novel backdoor attacking method on chat models by distributing\nmultiple trigger scenarios across user inputs in different rounds, and making\nthe backdoor be triggered only when all trigger scenarios have appeared in the\nhistorical conversations. Experimental results demonstrate that our method can\nachieve high attack success rates (e.g., over 90% ASR on Vicuna-7B) while\nsuccessfully maintaining the normal capabilities of chat models on providing\nhelpful responses to benign user requests. Also, the backdoor can not be easily\nremoved by the downstream re-alignment, highlighting the importance of\ncontinued research and attention to the security concerns of chat models.\nWarning: This paper may contain toxic content.",
      "tldr_zh": "本研究探讨了聊天模型（Chat Models）对后门攻击（Backdoor Attack）的漏洞，指出多轮交互格式增加了触发器设计的灵活性，并放大了模型的安全风险。作者提出了一种新方法，通过在多轮对话中分布多个触发场景，仅当所有场景在历史对话中出现时才激活后门。实验结果显示，该方法在Vicuna-7B模型上实现了超过90%的攻击成功率，同时保持模型对正常用户请求的响应能力，且后门不易通过下游重新对齐（re-alignment）移除。这强调了聊天模型安全性的紧迫性，需要进一步研究和关注。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CR",
      "comment": "Code and data are available at\n  https://github.com/hychaochao/Chat-Models-Backdoor-Attacking",
      "pdf_url": "http://arxiv.org/pdf/2404.02406v1",
      "published_date": "2024-04-03 02:16:53 UTC",
      "updated_date": "2024-04-03 02:16:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T21:38:30.962722"
    },
    {
      "arxiv_id": "2404.02934v1",
      "title": "GreedLlama: Performance of Financial Value-Aligned Large Language Models in Moral Reasoning",
      "title_zh": "翻译失败",
      "authors": [
        "Jeffy Yu",
        "Maximilian Huber",
        "Kevin Tang"
      ],
      "abstract": "This paper investigates the ethical implications of aligning Large Language\nModels (LLMs) with financial optimization, through the case study of\nGreedLlama, a model fine-tuned to prioritize economically beneficial outcomes.\nBy comparing GreedLlama's performance in moral reasoning tasks to a base Llama2\nmodel, our results highlight a concerning trend: GreedLlama demonstrates a\nmarked preference for profit over ethical considerations, making morally\nappropriate decisions at significantly lower rates than the base model in\nscenarios of both low and high moral ambiguity. In low ambiguity situations,\nGreedLlama's ethical decisions decreased to 54.4%, compared to the base model's\n86.9%, while in high ambiguity contexts, the rate was 47.4% against the base\nmodel's 65.1%. These findings emphasize the risks of single-dimensional value\nalignment in LLMs, underscoring the need for integrating broader ethical values\ninto AI development to ensure decisions are not solely driven by financial\nincentives. The study calls for a balanced approach to LLM deployment,\nadvocating for the incorporation of ethical considerations in models intended\nfor business applications, particularly in light of the absence of regulatory\noversight.",
      "tldr_zh": "本论文研究了将 Large Language Models (LLMs) 与金融优化对齐的伦理影响，以 GreedLlama 为案例，该模型被微调以优先经济利益。研究通过与基线 Llama2 模型比较，发现 GreedLlama 在道德推理任务中表现出明显的偏向，即在低模糊性场景下道德决策率降至54.4%（相比 Llama2 的86.9%），而在高模糊性场景下为47.4%（相比65.1%）。这些发现突出了单一维度价值对齐的风险，呼吁在 AI 开发中整合更广泛的伦理价值观，以避免决策仅受金融激励驱动，并在商业应用中推动平衡的监管框架。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "9 pages, 1 figure",
      "pdf_url": "http://arxiv.org/pdf/2404.02934v1",
      "published_date": "2024-04-03 02:16:37 UTC",
      "updated_date": "2024-04-03 02:16:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T21:38:44.281070"
    },
    {
      "arxiv_id": "2404.02402v1",
      "title": "Token Trails: Navigating Contextual Depths in Conversational AI with ChatLLM",
      "title_zh": "翻译失败",
      "authors": [
        "Md. Kowsher",
        "Ritesh Panditi",
        "Nusrat Jahan Prottasha",
        "Prakash Bhat",
        "Anupam Kumar Bairagi",
        "Mohammad Shamsul Arefin"
      ],
      "abstract": "Conversational modeling using Large Language Models (LLMs) requires a nuanced\nunderstanding of context to generate coherent and contextually relevant\nresponses. In this paper, we present Token Trails, a novel approach that\nleverages token-type embeddings to navigate the intricate contextual nuances\nwithin conversations. Our framework utilizes token-type embeddings to\ndistinguish between user utterances and bot responses, facilitating the\ngeneration of context-aware replies. Through comprehensive experimentation and\nevaluation, we demonstrate the effectiveness of Token Trails in improving\nconversational understanding and response generation, achieving\nstate-of-the-art performance. Our results highlight the significance of\ncontextual modeling in conversational AI and underscore the promising potential\nof Token Trails to advance the field, paving the way for more sophisticated and\ncontextually aware chatbot interactions.",
      "tldr_zh": "本论文提出 Token Trails，一种创新方法，利用 token-type embeddings 来区分用户话语和机器人响应，从而提升 Large Language Models (LLMs) 在对话 AI 中的上下文理解和响应生成。该框架通过导航对话的复杂上下文，确保生成更连贯的相关回复。实验评估表明，Token Trails 取得了最先进性能，显著提高了对话建模的效果，并为开发更先进的上下文感知聊天机器人铺平了道路。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.02402v1",
      "published_date": "2024-04-03 02:11:39 UTC",
      "updated_date": "2024-04-03 02:11:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T21:38:54.979312"
    },
    {
      "arxiv_id": "2404.02389v1",
      "title": "On Linearizing Structured Data in Encoder-Decoder Language Models: Insights from Text-to-SQL",
      "title_zh": "翻译失败",
      "authors": [
        "Yutong Shao",
        "Ndapa Nakashole"
      ],
      "abstract": "Structured data, prevalent in tables, databases, and knowledge graphs, poses\na significant challenge in its representation. With the advent of large\nlanguage models (LLMs), there has been a shift towards linearization-based\nmethods, which process structured data as sequential token streams, diverging\nfrom approaches that explicitly model structure, often as a graph. Crucially,\nthere remains a gap in our understanding of how these linearization-based\nmethods handle structured data, which is inherently non-linear. This work\ninvestigates the linear handling of structured data in encoder-decoder language\nmodels, specifically T5. Our findings reveal the model's ability to mimic\nhuman-designed processes such as schema linking and syntax prediction,\nindicating a deep, meaningful learning of structure beyond simple token\nsequencing. We also uncover insights into the model's internal mechanisms,\nincluding the ego-centric nature of structure node encodings and the potential\nfor model compression due to modality fusion redundancy. Overall, this work\nsheds light on the inner workings of linearization-based methods and could\npotentially provide guidance for future research.",
      "tldr_zh": "该研究探讨了在 encoder-decoder 语言模型中对结构化数据（如表、数据库和知识图谱）的线性化处理，特别以 T5 模型和 Text-to-SQL 任务为研究焦点。研究发现，模型能够模拟人类设计的 schema linking 和 syntax prediction 等过程，表明其对结构化数据的处理超越了简单序列化，实现了深度学习。论文还揭示了模型内部机制，包括结构节点编码的 ego-centric 性质和 modality fusion redundancy 的潜在压缩机会，为线性化-based 方法的未来研究提供重要指导。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "to appear at NAACL 2024",
      "pdf_url": "http://arxiv.org/pdf/2404.02389v1",
      "published_date": "2024-04-03 01:16:20 UTC",
      "updated_date": "2024-04-03 01:16:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T21:39:07.853925"
    },
    {
      "arxiv_id": "2404.02933v4",
      "title": "NL2KQL: From Natural Language to Kusto Query",
      "title_zh": "NL2KQL：从自然语言到 Kusto 查询",
      "authors": [
        "Xinye Tang",
        "Amir H. Abdi",
        "Jeremias Eichelbaum",
        "Mahan Das",
        "Alex Klein",
        "Nihal Irmak Pakis",
        "William Blum",
        "Daniel L Mace",
        "Tanvi Raja",
        "Namrata Padmanabhan",
        "Ye Xing"
      ],
      "abstract": "Data is growing rapidly in volume and complexity. Proficiency in database\nquery languages is pivotal for crafting effective queries. As coding assistants\nbecome more prevalent, there is significant opportunity to enhance database\nquery languages. The Kusto Query Language (KQL) is a widely used query language\nfor large semi-structured data such as logs, telemetries, and time-series for\nbig data analytics platforms. This paper introduces NL2KQL an innovative\nframework that uses large language models (LLMs) to convert natural language\nqueries (NLQs) to KQL queries. The proposed NL2KQL framework includes several\nkey components: Schema Refiner which narrows down the schema to its most\npertinent elements; the Few-shot Selector which dynamically selects relevant\nexamples from a few-shot dataset; and the Query Refiner which repairs syntactic\nand semantic errors in KQL queries. Additionally, this study outlines a method\nfor generating large datasets of synthetic NLQ-KQL pairs which are valid within\na specific database contexts. To validate NL2KQL's performance, we utilize an\narray of online (based on query execution) and offline (based on query parsing)\nmetrics. Through ablation studies, the significance of each framework component\nis examined, and the datasets used for benchmarking are made publicly\navailable. This work is the first of its kind and is compared with available\nbaselines to demonstrate its effectiveness.",
      "tldr_zh": "这篇论文介绍了 NL2KQL 框架，利用大型语言模型 (LLMs) 将自然语言查询 (NLQs) 转换为 Kusto 查询语言 (KQL) 查询，以应对数据增长和查询复杂性的挑战。框架的关键组件包括 Schema Refiner（用于缩小相关 schema 元素）、Few-shot Selector（动态选择少样本示例）和 Query Refiner（修复 KQL 查询的语法和语义错误），并提出了一种生成合成 NLQ-KQL 对数据集的方法。研究通过在线（基于查询执行）和离线（基于查询解析）指标评估框架性能，并通过消融研究证明了每个组件的重要性，与现有基准相比表现出色，这是该领域的首创工作。",
      "categories": [
        "cs.DB",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.DB",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.02933v4",
      "published_date": "2024-04-03 01:09:41 UTC",
      "updated_date": "2025-01-17 03:19:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T21:39:19.098733"
    },
    {
      "arxiv_id": "2404.02370v1",
      "title": "Enhancing Human-Computer Interaction in Chest X-ray Analysis using Vision and Language Model with Eye Gaze Patterns",
      "title_zh": "翻译失败",
      "authors": [
        "Yunsoo Kim",
        "Jinge Wu",
        "Yusuf Abdulle",
        "Yue Gao",
        "Honghan Wu"
      ],
      "abstract": "Recent advancements in Computer Assisted Diagnosis have shown promising\nperformance in medical imaging tasks, particularly in chest X-ray analysis.\nHowever, the interaction between these models and radiologists has been\nprimarily limited to input images. This work proposes a novel approach to\nenhance human-computer interaction in chest X-ray analysis using\nVision-Language Models (VLMs) enhanced with radiologists' attention by\nincorporating eye gaze data alongside textual prompts. Our approach leverages\nheatmaps generated from eye gaze data, overlaying them onto medical images to\nhighlight areas of intense radiologist's focus during chest X-ray evaluation.\nWe evaluate this methodology in tasks such as visual question answering, chest\nX-ray report automation, error detection, and differential diagnosis. Our\nresults demonstrate the inclusion of eye gaze information significantly\nenhances the accuracy of chest X-ray analysis. Also, the impact of eye gaze on\nfine-tuning was confirmed as it outperformed other medical VLMs in all tasks\nexcept visual question answering. This work marks the potential of leveraging\nboth the VLM's capabilities and the radiologist's domain knowledge to improve\nthe capabilities of AI models in medical imaging, paving a novel way for\nComputer Assisted Diagnosis with a human-centred AI.",
      "tldr_zh": "该研究提出了一种增强胸部X光分析人机互动的方法，使用Vision-Language Models (VLMs) 结合放射科医生的eye gaze数据。具体而言，通过从eye gaze数据生成heatmaps并叠加到医疗图像上，突出医生的关注区域，从而应用于视觉问答、胸部X光报告自动化、错误检测和鉴别诊断等任务。实验结果表明，加入eye gaze信息显著提高了分析准确性，并在除视觉问答外的所有任务中优于其他医疗VLMs，为以人为中心的计算机辅助诊断开辟了新途径。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "Under review",
      "pdf_url": "http://arxiv.org/pdf/2404.02370v1",
      "published_date": "2024-04-03 00:09:05 UTC",
      "updated_date": "2024-04-03 00:09:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T21:39:31.310224"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 116,
  "processed_papers_count": 116,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-17T21:39:56.498239"
}