{
  "date": "2024-07-08",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-07-08 的 arXiv 中文 TLDR 快报！\n\n今天 arXiv 的论文主要聚焦于 AI 模型的安全性、效率优化和实际应用扩展，涵盖 LLM 的知识遗忘机制、强化学习在机器人和自动驾驶中的应用，以及多模态模型在图像生成和医学领域的创新。重点包括 MUSE（Weijia Shi 等作者提出的机器学习遗忘评估基准，令人印象深刻）、DebUnc（LLM 不确定性处理）和 InsightBench（AI 在商业分析中的多步洞察生成）。这些论文突出了 AI 模型的实用性和潜在风险。\n\n下面，我挑选并简要讨论几篇重要的、话题度高的论文，先从 LLM 相关安全和效率优化入手，再聊 AI 在机器人和医学领域的应用。其他论文如纯算法改进或小数据集实验，我会快速掠过，以控制篇幅。\n\n**1. MUSE: Machine Unlearning Six-Way Evaluation for Language Models（MUSE: 机器学习遗忘六向评估）**  \n这篇论文由 Weijia Shi 等作者提出，评估 LLM 在遗忘特定数据（如隐私内容）时的效果。贡献：提出 MUSE 基准，涵盖六大属性（如无记忆泄露、实用性保留），并测试八种算法在 7B 参数模型上的表现。发现：大多数算法能部分防止记忆泄露，但易导致隐私风险和性能下降。该工作对 LLM 安全有重要启示，尤其在隐私法规日益严格的环境中。\n\n**2. DebUnc: Improving Large Language Model Agent Communication With Uncertainty Metrics（DebUnc: 通过不确定性指标提升 LLM 代理通信）**  \nLuke Yoffe 等作者的这篇论文聚焦 LLM 在多代理辩论中的不确定性处理。贡献：引入 DebUnc 框架，使用不确定性指标（如注意力机制）调整代理响应。发现：注意力-based 方法显著提升辩论准确性，性能随不确定性估计可靠性而改善。该论文强调了 LLM 在协作场景中的鲁棒性，相关于 AI 通信和决策系统。\n\n**7. InsightBench: Evaluating Business Analytics Agents Through Multi-Step Insight Generation（InsightBench: 通过多步洞察生成评估商业分析代理）**  \nGaurav Sahu 等作者的工作扩展 LLM 到商业分析。贡献：构建 InsightBench 数据集（含 100 个数据集），评估代理的多步分析能力（如问题制定和洞察总结）。发现：提出的 AgentPoirot 模型优于单查询方法，提升了商业决策效率。该论文有实际应用价值，展示了 LLM 在数据分析中的潜力。\n\n**2. How Much Progress Did I Make? An Unexplored Human Feedback Signal for Teaching Robots（人类反馈信号用于教学机器人：一个未探索的进展指标）**  \nHang Yu 等作者探讨机器人学习中的人类反馈。贡献：引入“进展”信号（任务完成百分比）作为反馈机制，并构建数据集。发现：该信号能提升机器人学习一致性和效率，尤其在多策略任务中。该工作为强化学习提供新视角，适用于教育和交互机器人。\n\n**18. Enhanced Safety in Autonomous Driving: Integrating Latent State Diffusion Model for End-to-End Navigation（增强自动驾驶安全性：整合潜在状态扩散模型用于端到端导航）**  \nDetian Chu 等作者的论文针对自动驾驶安全。贡献：提出基于条件 Value-at-Risk 的强化学习框架，使用潜在状态扩散模型模拟轨迹。发现：模型在模拟和真实环境中提升了安全性，显著减少碰撞。该研究在自动驾驶领域有话题度，强调了 AI 在不确定场景中的鲁棒性。\n\n**24. Video-STaR: Self-Training Enables Video Instruction Tuning with Any Supervision（Video-STaR: 自训练实现视频指令微调，支持任意监督）**  \nOrr Zohar 等作者扩展多模态 LLM 到视频生成。贡献：提出自训练框架，利用视频标签作为弱监督微调模型。发现：模型提升了视频理解和任务适应性，在数据集上表现优于基线。该论文创新性地解决了视频生成中的数据稀缺问题。\n\n其他论文，如一些纯技术优化（如第16篇 Solving Multi-Model MDPs）或小规模实验（如第12篇 Interactively Diagnosing Errors），我快速掠过，因为它们虽有贡献（如动态规划算法改进），但影响力较小，不如上述论文有话题度或实际应用潜力。如果你对特定领域感兴趣，可以进一步查阅。\n\n总之，今天的论文展示了 AI 模型在安全、效率和应用上的进展，但也暴露出挑战，如数据隐私和泛化能力。希望这个快报能帮你快速筛选感兴趣的文章！",
  "papers": [
    {
      "arxiv_id": "2407.06460v2",
      "title": "MUSE: Machine Unlearning Six-Way Evaluation for Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Weijia Shi",
        "Jaechan Lee",
        "Yangsibo Huang",
        "Sadhika Malladi",
        "Jieyu Zhao",
        "Ari Holtzman",
        "Daogao Liu",
        "Luke Zettlemoyer",
        "Noah A. Smith",
        "Chiyuan Zhang"
      ],
      "abstract": "Language models (LMs) are trained on vast amounts of text data, which may\ninclude private and copyrighted content. Data owners may request the removal of\ntheir data from a trained model due to privacy or copyright concerns. However,\nexactly unlearning only these datapoints (i.e., retraining with the data\nremoved) is intractable in modern-day models. This has led to the development\nof many approximate unlearning algorithms. The evaluation of the efficacy of\nthese algorithms has traditionally been narrow in scope, failing to precisely\nquantify the success and practicality of the algorithm from the perspectives of\nboth the model deployers and the data owners. We address this issue by\nproposing MUSE, a comprehensive machine unlearning evaluation benchmark that\nenumerates six diverse desirable properties for unlearned models: (1) no\nverbatim memorization, (2) no knowledge memorization, (3) no privacy leakage,\n(4) utility preservation on data not intended for removal, (5) scalability with\nrespect to the size of removal requests, and (6) sustainability over sequential\nunlearning requests. Using these criteria, we benchmark how effectively eight\npopular unlearning algorithms on 7B-parameter LMs can unlearn Harry Potter\nbooks and news articles. Our results demonstrate that most algorithms can\nprevent verbatim memorization and knowledge memorization to varying degrees,\nbut only one algorithm does not lead to severe privacy leakage. Furthermore,\nexisting algorithms fail to meet deployer's expectations because they often\ndegrade general model utility and also cannot sustainably accommodate\nsuccessive unlearning requests or large-scale content removal. Our findings\nidentify key issues with the practicality of existing unlearning algorithms on\nlanguage models, and we release our benchmark to facilitate further\nevaluations: muse-bench.github.io",
      "tldr_zh": "本研究提出MUSE，一种全面评估语言模型(LMs)机器遗忘(machine unlearning)算法的基准框架，针对数据移除请求评估六个关键属性：(1) 无逐字记忆(no verbatim memorization)、(2) 无知识记忆(no knowledge memorization)、(3) 无隐私泄露(no privacy leakage)、(4) 保留非移除数据的效用(utility preservation)、(5) 移除请求的可扩展性(scalability)，以及(6) 连续请求的可持续性(sustainability)。通过在7B参数LMs上测试八种流行算法，实验结果显示这些算法能部分防止记忆问题，但大多数会导致严重隐私泄露，并降低模型整体效用，无法有效处理大规模或连续移除请求。该基准的发布有助于识别现有算法的局限性，并推动更实用的机器遗忘技术发展。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.06460v2",
      "published_date": "2024-07-08 23:47:29 UTC",
      "updated_date": "2024-07-14 20:14:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:25:17.859577"
    },
    {
      "arxiv_id": "2407.06459v1",
      "title": "How Much Progress Did I Make? An Unexplored Human Feedback Signal for Teaching Robots",
      "title_zh": "翻译失败",
      "authors": [
        "Hang Yu",
        "Qidi Fang",
        "Shijie Fang",
        "Reuben M. Aronson",
        "Elaine Schaertl Short"
      ],
      "abstract": "Enhancing the expressiveness of human teaching is vital for both improving\nrobots' learning from humans and the human-teaching-robot experience. In this\nwork, we characterize and test a little-used teaching signal:\n\\textit{progress}, designed to represent the completion percentage of a task.\nWe conducted two online studies with 76 crowd-sourced participants and one\npublic space study with 40 non-expert participants to validate the capability\nof this progress signal. We find that progress indicates whether the task is\nsuccessfully performed, reflects the degree of task completion, identifies\nunproductive but harmless behaviors, and is likely to be more consistent across\nparticipants. Furthermore, our results show that giving progress does not\nrequire extra workload and time. An additional contribution of our work is a\ndataset of 40 non-expert demonstrations from the public space study through an\nice cream topping-adding task, which we observe to be multi-policy and\nsub-optimal, with sub-optimality not only from teleoperation errors but also\nfrom exploratory actions and attempts. The dataset is available at\n\\url{https://github.com/TeachingwithProgress/Non-Expert\\_Demonstrations}.",
      "tldr_zh": "本研究探讨了“progress”信号——一种表示任务完成百分比的未被充分利用的人类反馈机制，以提升机器人从人类学习的过程和教学体验。通过两个在线研究（涉及76名参与者）和一个公共空间研究（涉及40名非专家参与者），结果显示：progress 信号能有效指示任务成功与否、反映完成程度、识别无害低效行为，且在参与者间更一致，同时不会增加额外工作量。该研究还贡献了一个数据集，包含40个非专家在添加冰淇淋配料任务中的多策略和次优演示（如操作错误和探索行为），数据集可从 https://github.com/TeachingwithProgress/Non-Expert_Demonstrations 获取。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "8 pages. RO-MAN 2024",
      "pdf_url": "http://arxiv.org/pdf/2407.06459v1",
      "published_date": "2024-07-08 23:47:13 UTC",
      "updated_date": "2024-07-08 23:47:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:25:30.089788"
    },
    {
      "arxiv_id": "2407.06452v1",
      "title": "Exploiting Heterogeneity in Timescales for Sparse Recurrent Spiking Neural Networks for Energy-Efficient Edge Computing",
      "title_zh": "翻译失败",
      "authors": [
        "Biswadeep Chakraborty",
        "Saibal Mukhopadhyay"
      ],
      "abstract": "Spiking Neural Networks (SNNs) represent the forefront of neuromorphic\ncomputing, promising energy-efficient and biologically plausible models for\ncomplex tasks. This paper weaves together three groundbreaking studies that\nrevolutionize SNN performance through the introduction of heterogeneity in\nneuron and synapse dynamics. We explore the transformative impact of\nHeterogeneous Recurrent Spiking Neural Networks (HRSNNs), supported by rigorous\nanalytical frameworks and novel pruning methods like Lyapunov Noise Pruning\n(LNP). Our findings reveal how heterogeneity not only enhances classification\nperformance but also reduces spiking activity, leading to more efficient and\nrobust networks. By bridging theoretical insights with practical applications,\nthis comprehensive summary highlights the potential of SNNs to outperform\ntraditional neural networks while maintaining lower computational costs. Join\nus on a journey through the cutting-edge advancements that pave the way for the\nfuture of intelligent, energy-efficient neural computing.",
      "tldr_zh": "本论文探讨了在稀疏循环脉冲神经网络（Sparse Recurrent Spiking Neural Networks, SNNs）中利用神经元和突触动态的异质性（heterogeneity），以实现更高效的边缘计算。研究引入了Heterogeneous Recurrent Spiking Neural Networks (HRSNNs)框架，并结合严格的分析方法和创新的修剪技术，如Lyapunov Noise Pruning (LNP)，来提升网络的分类性能并减少脉冲活动。结果显示，这种异质性方法不仅提高了网络的鲁棒性和效率，还使SNNs在计算成本上优于传统神经网络，为能量高效的神经计算铺平了道路。",
      "categories": [
        "cs.NE",
        "cs.AI"
      ],
      "primary_category": "cs.NE",
      "comment": "20 pages, 12 figures, 5 tables. arXiv admin note: text overlap with\n  arXiv:2211.04297, arXiv:2302.11618, arXiv:2403.03409",
      "pdf_url": "http://arxiv.org/pdf/2407.06452v1",
      "published_date": "2024-07-08 23:33:12 UTC",
      "updated_date": "2024-07-08 23:33:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:25:41.062564"
    },
    {
      "arxiv_id": "2407.06447v2",
      "title": "Geospatial Trajectory Generation via Efficient Abduction: Deployment for Independent Testing",
      "title_zh": "高效溯因实现的地理空间轨迹生成：用于独立测试的部署",
      "authors": [
        "Divyagna Bavikadi",
        "Dyuman Aditya",
        "Devendra Parkar",
        "Paulo Shakarian",
        "Graham Mueller",
        "Chad Parvis",
        "Gerardo I. Simari"
      ],
      "abstract": "The ability to generate artificial human movement patterns while meeting\nlocation and time constraints is an important problem in the security\ncommunity, particularly as it enables the study of the analog problem of\ndetecting such patterns while maintaining privacy. We frame this problem as an\ninstance of abduction guided by a novel parsimony function represented as an\naggregate truth value over an annotated logic program. This approach has the\nadded benefit of affording explainability to an analyst user. By showing that\nany subset of such a program can provide a lower bound on this parsimony\nrequirement, we are able to abduce movement trajectories efficiently through an\ninformed (i.e., A*) search. We describe how our implementation was enhanced\nwith the application of multiple techniques in order to be scaled and\nintegrated with a cloud-based software stack that included bottom-up rule\nlearning, geolocated knowledge graph retrieval/management, and interfaces with\ngovernment systems for independently conducted government-run tests for which\nwe provide results. We also report on our own experiments showing that we not\nonly provide exact results but also scale to very large scenarios and provide\nrealistic agent trajectories that can go undetected by machine learning anomaly\ndetectors.",
      "tldr_zh": "该论文提出了一种高效的溯因(abduction)方法，用于生成符合位置和时间约束的地理空间轨迹，旨在支持安全领域的研究，同时保护隐私并提供可解释性。方法通过一个基于注释逻辑程序的简约函数作为引导，并利用A*搜索算法高效地生成轨迹，确保计算可扩展。实验结果显示，该框架在政府独立测试中表现出色，不仅提供精确的轨迹生成，还能处理大规模场景，并生成真实代理轨迹，这些轨迹能逃避机器学习异常检测器。",
      "categories": [
        "cs.LO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.LO",
      "comment": "In Proceedings ICLP 2024, arXiv:2502.08453",
      "pdf_url": "http://arxiv.org/pdf/2407.06447v2",
      "published_date": "2024-07-08 23:11:47 UTC",
      "updated_date": "2025-02-13 11:46:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:25:52.844838"
    },
    {
      "arxiv_id": "2407.06443v2",
      "title": "Exposing Privacy Gaps: Membership Inference Attack on Preference Data for LLM Alignment",
      "title_zh": "翻译失败",
      "authors": [
        "Qizhang Feng",
        "Siva Rajesh Kasa",
        "Santhosh Kumar Kasa",
        "Hyokun Yun",
        "Choon Hui Teo",
        "Sravan Babu Bodapati"
      ],
      "abstract": "Large Language Models (LLMs) have seen widespread adoption due to their\nremarkable natural language capabilities. However, when deploying them in\nreal-world settings, it is important to align LLMs to generate texts according\nto acceptable human standards. Methods such as Proximal Policy Optimization\n(PPO) and Direct Preference Optimization (DPO) have enabled significant\nprogress in refining LLMs using human preference data. However, the privacy\nconcerns inherent in utilizing such preference data have yet to be adequately\nstudied. In this paper, we investigate the vulnerability of LLMs aligned using\ntwo widely used methods - DPO and PPO - to membership inference attacks (MIAs).\nOur study has two main contributions: first, we theoretically motivate that DPO\nmodels are more vulnerable to MIA compared to PPO models; second, we introduce\na novel reference-based attack framework specifically for analyzing preference\ndata called PREMIA (\\uline{Pre}ference data \\uline{MIA}). Using PREMIA and\nexisting baselines we empirically show that DPO models have a relatively\nheightened vulnerability towards MIA.",
      "tldr_zh": "这篇论文探讨了在使用人类偏好数据对 Large Language Models (LLMs) 进行对齐时存在的隐私风险，特别是针对 Proximal Policy Optimization (PPO) 和 Direct Preference Optimization (DPO) 方法的 Membership Inference Attacks (MIAs)。作者理论上证明了 DPO 模型比 PPO 模型更容易受到 MIA 攻击。论文引入了一个新的基于参考的攻击框架 PREMIA（Preference data MIA），专门用于分析偏好数据。实验结果显示，DPO 模型在 MIA 方面表现出更高的脆弱性，从而暴露了 LLM 对齐过程中的隐私漏洞。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.06443v2",
      "published_date": "2024-07-08 22:53:23 UTC",
      "updated_date": "2025-04-27 21:07:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:26:06.849889"
    },
    {
      "arxiv_id": "2407.06426v2",
      "title": "DebUnc: Improving Large Language Model Agent Communication With Uncertainty Metrics",
      "title_zh": "翻译失败",
      "authors": [
        "Luke Yoffe",
        "Alfonso Amayuelas",
        "William Yang Wang"
      ],
      "abstract": "Multi-agent debates have been introduced to improve the accuracy of Large\nLanguage Models (LLMs) by having multiple agents discuss solutions to a problem\nover several rounds of debate. However, models often generate incorrect yet\nconfident-sounding responses, which can mislead others. This issue arises\npartly because agents do not consider how confident their peers are. To address\nthis, we propose DebUnc, a debate framework that uses uncertainty metrics to\nassess agent confidence. Confidence is then conveyed through a modified\nattention mechanism that adjusts token weights, or through textual prompts.\nEvaluations across benchmarks show that attention-based methods are\nparticularly effective and that performance continues to improve as uncertainty\nestimation becomes more reliable. The code is available at\nhttps://github.com/lukeyoffe/debunc.",
      "tldr_zh": "本研究针对多智能体辩论中 Large Language Models (LLMs) 可能生成错误但自信的响应问题，提出 DebUnc 框架，利用 uncertainty metrics 来评估代理的自信度。DebUnc 通过修改的 attention mechanism 调整 token 权重，或使用 textual prompts 来传达自信信息，从而改善代理间的通信和决策准确性。在基准测试中，基于 attention 的方法表现突出，随着 uncertainty estimation 的可靠性提升，整体性能持续改进，为 LLM 应用提供了更可靠的讨论机制。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.06426v2",
      "published_date": "2024-07-08 22:15:01 UTC",
      "updated_date": "2025-02-22 02:15:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:26:16.920554"
    },
    {
      "arxiv_id": "2407.06423v4",
      "title": "InsightBench: Evaluating Business Analytics Agents Through Multi-Step Insight Generation",
      "title_zh": "InsightBench：通过多步骤洞察生成评估业务分析代理",
      "authors": [
        "Gaurav Sahu",
        "Abhay Puri",
        "Juan Rodriguez",
        "Amirhossein Abaskohi",
        "Mohammad Chegini",
        "Alexandre Drouin",
        "Perouz Taslakian",
        "Valentina Zantedeschi",
        "Alexandre Lacoste",
        "David Vazquez",
        "Nicolas Chapados",
        "Christopher Pal",
        "Sai Rajeswar Mudumba",
        "Issam Hadj Laradji"
      ],
      "abstract": "Data analytics is essential for extracting valuable insights from data that\ncan assist organizations in making effective decisions. We introduce\nInsightBench, a benchmark dataset with three key features. First, it consists\nof 100 datasets representing diverse business use cases such as finance and\nincident management, each accompanied by a carefully curated set of insights\nplanted in the datasets. Second, unlike existing benchmarks focusing on\nanswering single queries, InsightBench evaluates agents based on their ability\nto perform end-to-end data analytics, including formulating questions,\ninterpreting answers, and generating a summary of insights and actionable\nsteps. Third, we conducted comprehensive quality assurance to ensure that each\ndataset in the benchmark had clear goals and included relevant and meaningful\nquestions and analysis. Furthermore, we implement a two-way evaluation\nmechanism using LLaMA-3 as an effective, open-source evaluator to assess\nagents' ability to extract insights. We also propose AgentPoirot, our baseline\ndata analysis agent capable of performing end-to-end data analytics. Our\nevaluation on InsightBench shows that AgentPoirot outperforms existing\napproaches (such as Pandas Agent) that focus on resolving single queries. We\nalso compare the performance of open- and closed-source LLMs and various\nevaluation strategies. Overall, this benchmark serves as a testbed to motivate\nfurther development in comprehensive automated data analytics and can be\naccessed here: https://github.com/ServiceNow/insight-bench.",
      "tldr_zh": "该研究引入了InsightBench基准数据集，用于评估商业分析代理的多步骤洞见生成能力。该数据集包含100个多样化商业用例（如金融和事件管理）的子数据集，每个都预置了精心策划的洞见，并强调端到端分析过程，包括问题制定、答案解释和洞见总结。研究采用LLaMA-3作为双向评估器，并提出基线模型AgentPoirot，该模型在InsightBench上显著优于专注于单查询的现有方法（如Pandas Agent）。总体而言，此基准促进了全面自动化数据分析的发展，并提供开源访问。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted to ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2407.06423v4",
      "published_date": "2024-07-08 22:06:09 UTC",
      "updated_date": "2025-02-27 17:15:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:26:29.910766"
    },
    {
      "arxiv_id": "2407.06422v1",
      "title": "Exploring the Capability of ChatGPT to Reproduce Human Labels for Social Computing Tasks (Extended Version)",
      "title_zh": "翻译失败",
      "authors": [
        "Yiming Zhu",
        "Peixian Zhang",
        "Ehsan-Ul Haq",
        "Pan Hui",
        "Gareth Tyson"
      ],
      "abstract": "Harnessing the potential of large language models (LLMs) like ChatGPT can\nhelp address social challenges through inclusive, ethical, and sustainable\nmeans. In this paper, we investigate the extent to which ChatGPT can annotate\ndata for social computing tasks, aiming to reduce the complexity and cost of\nundertaking web research. To evaluate ChatGPT's potential, we re-annotate seven\ndatasets using ChatGPT, covering topics related to pressing social issues like\nCOVID-19 misinformation, social bot deception, cyberbully, clickbait news, and\nthe Russo-Ukrainian War. Our findings demonstrate that ChatGPT exhibits promise\nin handling these data annotation tasks, albeit with some challenges. Across\nthe seven datasets, ChatGPT achieves an average annotation F1-score of 72.00%.\nIts performance excels in clickbait news annotation, correctly labeling 89.66%\nof the data. However, we also observe significant variations in performance\nacross individual labels. Our study reveals predictable patterns in ChatGPT's\nannotation performance. Thus, we propose GPT-Rater, a tool to predict if\nChatGPT can correctly label data for a given annotation task. Researchers can\nuse this to identify where ChatGPT might be suitable for their annotation\nrequirements. We show that GPT-Rater effectively predicts ChatGPT's\nperformance. It performs best on a clickbait headlines dataset by achieving an\naverage F1-score of 95.00%. We believe that this research opens new avenues for\nanalysis and can reduce barriers to engaging in social computing research.",
      "tldr_zh": "这篇论文探讨了大型语言模型(LLMs)如 ChatGPT 在社会计算任务数据标注中的潜力，旨在通过自动化减少研究复杂性和成本。研究团队使用 ChatGPT 重新标注了七个数据集，涵盖 COVID-19 误传、社会机器人欺骗、网络霸凌、点击诱饵新闻和俄乌战争等主题，平均 F1-score 达到 72.00%。ChatGPT 在点击诱饵新闻标注上表现出色，准确率高达 89.66%，但在其他标签上存在显著性能差异。论文提出 GPT-Rater 工具，用于预测 ChatGPT 的标注准确性，该工具在点击诱饵标题数据集上实现 95.00% 的 F1-score。该研究为社会计算领域提供了新途径，帮助降低研究障碍并促进更高效的分析。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "Extended version of accepted short paper to ASONAM 2024. arXiv admin\n  note: text overlap with arXiv:2304.10145",
      "pdf_url": "http://arxiv.org/pdf/2407.06422v1",
      "published_date": "2024-07-08 22:04:30 UTC",
      "updated_date": "2024-07-08 22:04:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:26:42.450002"
    },
    {
      "arxiv_id": "2407.06416v1",
      "title": "Hybrid Classical-Quantum architecture for vectorised image classification of hand-written sketches",
      "title_zh": "翻译失败",
      "authors": [
        "Y. Cordero",
        "S. Biswas",
        "F. Vilariño",
        "M. Bilkis"
      ],
      "abstract": "Quantum machine learning (QML) investigates how quantum phenomena can be\nexploited in order to learn data in an alternative way, \\textit{e.g.} by means\nof a quantum computer. While recent results evidence that QML models can\npotentially surpass their classical counterparts' performance in specific\ntasks, quantum technology hardware is still unready to reach quantum advantage\nin tasks of significant relevance to the broad scope of the computer science\ncommunity. Recent advances indicate that hybrid classical-quantum models can\nreadily attain competitive performances at low architecture complexities. Such\ninvestigations are often carried out for image-processing tasks, and are\nnotably constrained to modelling \\textit{raster images}, represented as a grid\nof two-dimensional pixels. Here, we introduce vector-based representation of\nsketch drawings as a test-bed for QML models. Such a lower-dimensional data\nstructure results handful to benchmark model's performance, particularly in\ncurrent transition times, where classical simulations of quantum circuits are\nnaturally limited in the number of qubits, and quantum hardware is not readily\navailable to perform large-scale experiments. We report some encouraging\nresults for primitive hybrid classical-quantum architectures, in a canonical\nsketch recognition problem.",
      "tldr_zh": "该论文提出了一种混合经典-量子架构，用于处理手写草图的矢量图像分类，旨在利用Quantum Machine Learning (QML)来提升数据学习效率。不同于传统的栅格图像表示，该方法采用低维度的矢量表示作为测试平台，便于在量子硬件受限的过渡期内进行基准测试和模拟。实验结果显示，这种原始hybrid classical-quantum架构在典型草图识别问题上取得了有竞争力的性能，展示了其在QML领域的潜力。",
      "categories": [
        "quant-ph",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "quant-ph",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.06416v1",
      "published_date": "2024-07-08 21:51:20 UTC",
      "updated_date": "2024-07-08 21:51:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:26:53.129520"
    },
    {
      "arxiv_id": "2407.06405v1",
      "title": "AI-driven multi-omics integration for multi-scale predictive modeling of causal genotype-environment-phenotype relationships",
      "title_zh": "翻译失败",
      "authors": [
        "You Wu",
        "Lei Xie"
      ],
      "abstract": "Despite the wealth of single-cell multi-omics data, it remains challenging to\npredict the consequences of novel genetic and chemical perturbations in the\nhuman body. It requires knowledge of molecular interactions at all biological\nlevels, encompassing disease models and humans. Current machine learning\nmethods primarily establish statistical correlations between genotypes and\nphenotypes but struggle to identify physiologically significant causal factors,\nlimiting their predictive power. Key challenges in predictive modeling include\nscarcity of labeled data, generalization across different domains, and\ndisentangling causation from correlation. In light of recent advances in\nmulti-omics data integration, we propose a new artificial intelligence\n(AI)-powered biology-inspired multi-scale modeling framework to tackle these\nissues. This framework will integrate multi-omics data across biological\nlevels, organism hierarchies, and species to predict causal\ngenotype-environment-phenotype relationships under various conditions. AI\nmodels inspired by biology may identify novel molecular targets, biomarkers,\npharmaceutical agents, and personalized medicines for presently unmet medical\nneeds.",
      "tldr_zh": "尽管单细胞多组学数据丰富，但预测新基因和化学扰动对人体影响的挑战依然存在，主要由于当前机器学习方法仅建立统计相关性，而非生理意义的因果关系，导致数据稀缺、跨域泛化差等问题。  \n本文提出一个AI驱动的生物启发多尺度建模框架，通过整合跨生物水平、生物体层次和物种的多组学数据，来预测因果genotype-environment-phenotype关系。  \n该框架旨在解决现有方法的局限性，提升预测准确性，并识别潜在的分子目标、生物标志物、药物和个性化药物。  \n总体而言，此方法为未满足的医疗需求提供创新解决方案。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.06405v1",
      "published_date": "2024-07-08 21:23:25 UTC",
      "updated_date": "2024-07-08 21:23:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:27:06.752777"
    },
    {
      "arxiv_id": "2407.06401v1",
      "title": "Knowledge Management in the Companion Cognitive Architecture",
      "title_zh": "知识管理在 Companion 认知架构中",
      "authors": [
        "Constantine Nakos",
        "Kenneth D. Forbus"
      ],
      "abstract": "One of the fundamental aspects of cognitive architectures is their ability to\nencode and manipulate knowledge. Without a consistent, well-designed, and\nscalable knowledge management scheme, an architecture will be unable to move\npast toy problems and tackle the broader problems of cognition. In this paper,\nwe document some of the challenges we have faced in developing the knowledge\nstack for the Companion cognitive architecture and discuss the tools,\nrepresentations, and practices we have developed to overcome them. We also lay\nout a series of potential next steps that will allow Companion agents to play a\ngreater role in managing their own knowledge. It is our hope that these\nobservations will prove useful to other cognitive architecture developers\nfacing similar challenges.",
      "tldr_zh": "该论文探讨了认知架构中知识管理的核心挑战，强调缺乏一致、可扩展的设计会限制架构处理复杂认知问题。作者记录了在开发 Companion cognitive architecture 的知识堆栈过程中遇到的难题，并介绍了相应的工具、表示方法和实践策略来克服这些挑战。论文还提出未来步骤，让 Companion 代理能更自主地管理知识，并希望这些见解能为其他 cognitive architecture 开发者提供参考。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "16 pages, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2407.06401v1",
      "published_date": "2024-07-08 21:20:05 UTC",
      "updated_date": "2024-07-08 21:20:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:27:18.280930"
    },
    {
      "arxiv_id": "2407.06400v1",
      "title": "Interactively Diagnosing Errors in a Semantic Parser",
      "title_zh": "交互式诊断语义解析器的错误",
      "authors": [
        "Constantine Nakos",
        "Kenneth D. Forbus"
      ],
      "abstract": "Hand-curated natural language systems provide an inspectable, correctable\nalternative to language systems based on machine learning, but maintaining them\nrequires considerable effort and expertise. Interactive Natural Language\nDebugging (INLD) aims to lessen this burden by casting debugging as a reasoning\nproblem, asking the user a series of questions to diagnose and correct errors\nin the system's knowledge. In this paper, we present work in progress on an\ninteractive error diagnosis system for the CNLU semantic parser. We show how\nthe first two stages of the INLD pipeline (symptom identification and error\nlocalization) can be cast as a model-based diagnosis problem, demonstrate our\nsystem's ability to diagnose semantic errors on synthetic examples, and discuss\ndesign challenges and frontiers for future work.",
      "tldr_zh": "这篇论文介绍了 Interactive Natural Language Debugging (INLD)，一种交互式方法，通过一系列问题将语义解析器的错误诊断转化为推理问题，从而减少维护手写自然语言系统的负担。针对 CNLU semantic parser，该系统将 INLD 管道的前两个阶段（symptom identification 和 error localization）构建为 model-based diagnosis 问题，并在合成例子上成功诊断语义错误。论文还讨论了设计挑战和未来工作方向，以提升系统的实用性和效率。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "16 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2407.06400v1",
      "published_date": "2024-07-08 21:16:09 UTC",
      "updated_date": "2024-07-08 21:16:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:27:30.663896"
    },
    {
      "arxiv_id": "2407.06349v2",
      "title": "Large Language Model Recall Uncertainty is Modulated by the Fan Effect",
      "title_zh": "翻译失败",
      "authors": [
        "Jesse Roberts",
        "Kyle Moore",
        "Thao Pham",
        "Oseremhen Ewaleifoh",
        "Doug Fisher"
      ],
      "abstract": "This paper evaluates whether large language models (LLMs) exhibit cognitive\nfan effects, similar to those discovered by Anderson in humans, after being\npre-trained on human textual data. We conduct two sets of in-context recall\nexperiments designed to elicit fan effects. Consistent with human results, we\nfind that LLM recall uncertainty, measured via token probability, is influenced\nby the fan effect. Our results show that removing uncertainty disrupts the\nobserved effect. The experiments suggest the fan effect is consistent whether\nthe fan value is induced in-context or in the pre-training data. Finally, these\nfindings provide in-silico evidence that fan effects and typicality are\nexpressions of the same phenomena.",
      "tldr_zh": "这篇论文评估大型语言模型 (LLMs) 是否像人类一样表现出 fan effects，并通过两组 in-context recall 实验来验证这一现象。结果显示，LLMs 的 recall uncertainty（通过 token probability 测量）会受到 fan effect 的影响，且移除不确定性会破坏该效果。实验进一步证明，fan effect 在 in-context 或预训练数据中诱发时保持一致，并提供了 in-silico evidence，表明 fan effects 和 typicality 是同一现象的表现。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.06349v2",
      "published_date": "2024-07-08 19:40:50 UTC",
      "updated_date": "2024-09-29 15:47:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:27:43.761786"
    },
    {
      "arxiv_id": "2407.06339v1",
      "title": "Noise-Free Explanation for Driving Action Prediction",
      "title_zh": "翻译失败",
      "authors": [
        "Hongbo Zhu",
        "Theodor Wulff",
        "Rahul Singh Maharjan",
        "Jinpei Han",
        "Angelo Cangelosi"
      ],
      "abstract": "Although attention mechanisms have achieved considerable progress in\nTransformer-based architectures across various Artificial Intelligence (AI)\ndomains, their inner workings remain to be explored. Existing explainable\nmethods have different emphases but are rather one-sided. They primarily\nanalyse the attention mechanisms or gradient-based attribution while neglecting\nthe magnitudes of input feature values or the skip-connection module. Moreover,\nthey inevitably bring spurious noisy pixel attributions unrelated to the\nmodel's decision, hindering humans' trust in the spotted visualization result.\nHence, we propose an easy-to-implement but effective way to remedy this flaw:\nSmooth Noise Norm Attention (SNNA). We weigh the attention by the norm of the\ntransformed value vector and guide the label-specific signal with the attention\ngradient, then randomly sample the input perturbations and average the\ncorresponding gradients to produce noise-free attribution. Instead of\nevaluating the explanation method on the binary or multi-class classification\ntasks like in previous works, we explore the more complex multi-label\nclassification scenario in this work, i.e., the driving action prediction task,\nand trained a model for it specifically. Both qualitative and quantitative\nevaluation results show the superiority of SNNA compared to other SOTA\nattention-based explainable methods in generating a clearer visual explanation\nmap and ranking the input pixel importance.",
      "tldr_zh": "这篇论文针对 Transformer-based 模型的注意力机制解释问题，提出了 Smooth Noise Norm Attention (SNNA) 方法，以消除虚假噪声像素归因并提升解释的可信度。SNNA 通过价值向量的范数加权注意力、结合注意力梯度引导以及随机采样输入扰动并平均梯度，生成无噪声的像素归因。实验在驾驶行为预测的多标签分类任务上进行，结果显示 SNNA 在视觉解释图的清晰度和输入像素重要性排名方面优于现有 SOTA 方法。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "10 pages, 10 figures",
      "pdf_url": "http://arxiv.org/pdf/2407.06339v1",
      "published_date": "2024-07-08 19:21:24 UTC",
      "updated_date": "2024-07-08 19:21:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:27:55.088041"
    },
    {
      "arxiv_id": "2407.06334v2",
      "title": "Double-Ended Synthesis Planning with Goal-Constrained Bidirectional Search",
      "title_zh": "目标约束的双向搜索双端合成规划",
      "authors": [
        "Kevin Yu",
        "Jihye Roh",
        "Ziang Li",
        "Wenhao Gao",
        "Runzhong Wang",
        "Connor W. Coley"
      ],
      "abstract": "Computer-aided synthesis planning (CASP) algorithms have demonstrated\nexpert-level abilities in planning retrosynthetic routes to molecules of low to\nmoderate complexity. However, current search methods assume the sufficiency of\nreaching arbitrary building blocks, failing to address the common real-world\nconstraint where using specific molecules is desired. To this end, we present a\nformulation of synthesis planning with starting material constraints. Under\nthis formulation, we propose Double-Ended Synthesis Planning (DESP), a novel\nCASP algorithm under a bidirectional graph search scheme that interleaves\nexpansions from the target and from the goal starting materials to ensure\nconstraint satisfiability. The search algorithm is guided by a goal-conditioned\ncost network learned offline from a partially observed hypergraph of valid\nchemical reactions. We demonstrate the utility of DESP in improving solve rates\nand reducing the number of search expansions by biasing synthesis planning\ntowards expert goals on multiple new benchmarks. DESP can make use of existing\none-step retrosynthesis models, and we anticipate its performance to scale as\nthese one-step model capabilities improve.",
      "tldr_zh": "本文针对计算机辅助合成规划 (CASP) 的局限性，提出了一种考虑起始材料约束的合成规划公式，以解决现实中特定分子使用需求的问题。作者引入 Double-Ended Synthesis Planning (DESP)，这是一种双向图搜索算法，从目标分子和目标起始材料两端交替扩展，并由离线学习的目标条件成本网络引导，以确保约束满足。实验结果显示，DESP 在多个新基准上提高了求解率并减少了搜索扩展次数，同时偏向专家目标进行优化。该方法可与现有的单步逆合成模型兼容，并预计其性能将随着这些模型的改进而进一步提升。",
      "categories": [
        "cs.AI",
        "q-bio.QM"
      ],
      "primary_category": "cs.AI",
      "comment": "NeurIPS 2024 (Spotlight)",
      "pdf_url": "http://arxiv.org/pdf/2407.06334v2",
      "published_date": "2024-07-08 18:56:00 UTC",
      "updated_date": "2024-11-01 16:45:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:28:07.709692"
    },
    {
      "arxiv_id": "2407.06329v1",
      "title": "Solving Multi-Model MDPs by Coordinate Ascent and Dynamic Programming",
      "title_zh": "翻译失败",
      "authors": [
        "Xihong Su",
        "Marek Petrik"
      ],
      "abstract": "Multi-model Markov decision process (MMDP) is a promising framework for\ncomputing policies that are robust to parameter uncertainty in MDPs. MMDPs aim\nto find a policy that maximizes the expected return over a distribution of MDP\nmodels. Because MMDPs are NP-hard to solve, most methods resort to\napproximations. In this paper, we derive the policy gradient of MMDPs and\npropose CADP, which combines a coordinate ascent method and a dynamic\nprogramming algorithm for solving MMDPs. The main innovation of CADP compared\nwith earlier algorithms is to take the coordinate ascent perspective to adjust\nmodel weights iteratively to guarantee monotone policy improvements to a local\nmaximum. A theoretical analysis of CADP proves that it never performs worse\nthan previous dynamic programming algorithms like WSU. Our numerical results\nindicate that CADP substantially outperforms existing methods on several\nbenchmark problems.",
      "tldr_zh": "本研究针对 Multi-model Markov Decision Process (MMDPs) 的参数不确定性问题，提出了一种计算鲁棒政策的框架，该框架旨在最大化预期回报分布。作者导出了 MMDPs 的 policy gradient，并开发了 CADP 方法，该方法结合 coordinate ascent 和 dynamic programming 算法，通过迭代调整模型权重实现单调的政策改进。CADP 的创新在于从坐标上升视角保证收敛到局部最大，并理论证明其性能不逊于现有动态规划算法如 WSU。在多个基准问题上的数值实验表明，CADP 显著优于现有方法。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at UAI 2023",
      "pdf_url": "http://arxiv.org/pdf/2407.06329v1",
      "published_date": "2024-07-08 18:47:59 UTC",
      "updated_date": "2024-07-08 18:47:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:28:18.666293"
    },
    {
      "arxiv_id": "2407.06322v2",
      "title": "MagMax: Leveraging Model Merging for Seamless Continual Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Daniel Marczak",
        "Bartłomiej Twardowski",
        "Tomasz Trzciński",
        "Sebastian Cygert"
      ],
      "abstract": "This paper introduces a continual learning approach named MagMax, which\nutilizes model merging to enable large pre-trained models to continuously learn\nfrom new data without forgetting previously acquired knowledge. Distinct from\ntraditional continual learning methods that aim to reduce forgetting during\ntask training, MagMax combines sequential fine-tuning with a maximum magnitude\nweight selection for effective knowledge integration across tasks. Our initial\ncontribution is an extensive examination of model merging techniques, revealing\nthat simple approaches like weight averaging and random weight selection\nsurprisingly hold up well in various continual learning contexts. More\nimportantly, we present MagMax, a novel model-merging strategy that enables\ncontinual learning of large pre-trained models for successive tasks. Our\nthorough evaluation demonstrates the superiority of MagMax in various\nscenarios, including class- and domain-incremental learning settings. The code\nis available at this URL: https://github.com/danielm1405/magmax.",
      "tldr_zh": "本论文提出了一种名为 MagMax 的持续学习（continual learning）方法，通过模型合并（model merging）技术，让大型预训练模型从新数据中学习，同时避免忘记先前知识。不同于传统方法，MagMax 结合了顺序微调（sequential fine-tuning）和最大幅度权重选择（maximum magnitude weight selection），以有效整合跨任务知识。研究首先评估了简单模型合并技术，如权重平均和随机权重选择，发现它们在持续学习场景中表现出色。实验结果显示，MagMax 在类增量和领域增量学习等设置中优于基线模型，提供了一个无缝的持续学习框架。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted for ECCV2024",
      "pdf_url": "http://arxiv.org/pdf/2407.06322v2",
      "published_date": "2024-07-08 18:38:52 UTC",
      "updated_date": "2024-07-29 22:17:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:28:30.799663"
    },
    {
      "arxiv_id": "2407.06317v4",
      "title": "Enhanced Safety in Autonomous Driving: Integrating Latent State Diffusion Model for End-to-End Navigation",
      "title_zh": "自动驾驶的安全增强：整合潜在状态扩散模型用于端到端导航",
      "authors": [
        "Detian Chu",
        "Linyuan Bai",
        "Jianuo Huang",
        "Zhenlong Fang",
        "Peng Zhang",
        "Wei Kang",
        "Haifeng Lin"
      ],
      "abstract": "With the advancement of autonomous driving, ensuring safety during motion\nplanning and navigation is becoming more and more important. However, most\nend-to-end planning methods suffer from a lack of safety. This research\naddresses the safety issue in the control optimization problem of autonomous\ndriving, formulated as Constrained Markov Decision Processes (CMDPs). We\npropose a novel, model-based approach for policy optimization, utilizing a\nconditional Value-at-Risk based Soft Actor Critic to manage constraints in\ncomplex, high-dimensional state spaces effectively. Our method introduces a\nworst-case actor to guide safe exploration, ensuring rigorous adherence to\nsafety requirements even in unpredictable scenarios. The policy optimization\nemploys the Augmented Lagrangian method and leverages latent diffusion models\nto predict and simulate future trajectories. This dual approach not only aids\nin navigating environments safely but also refines the policy's performance by\nintegrating distribution modeling to account for environmental uncertainties.\nEmpirical evaluations conducted in both simulated and real environment\ndemonstrate that our approach outperforms existing methods in terms of safety,\nefficiency, and decision-making capabilities.",
      "tldr_zh": "本研究针对自动驾驶中的安全问题，提出一种基于模型的方法，将安全优化问题表述为Constrained Markov Decision Processes (CMDPs)，并使用conditional Value-at-Risk based Soft Actor Critic算法来有效管理高维状态空间中的约束。方法引入worst-case actor指导安全探索，并结合Augmented Lagrangian方法和latent diffusion models预测未来轨迹，以模拟环境不确定性和提升导航性能。实验在模拟和真实环境中表明，该方法在安全、效率和决策能力方面均优于现有端到端规划方法。",
      "categories": [
        "cs.AI",
        "cs.CV",
        "cs.RO"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.06317v4",
      "published_date": "2024-07-08 18:32:40 UTC",
      "updated_date": "2024-07-17 04:30:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:28:42.906261"
    },
    {
      "arxiv_id": "2407.06310v1",
      "title": "Homogeneous Speaker Features for On-the-Fly Dysarthric and Elderly Speaker Adaptation",
      "title_zh": "翻译失败",
      "authors": [
        "Mengzhe Geng",
        "Xurong Xie",
        "Jiajun Deng",
        "Zengrui Jin",
        "Guinan Li",
        "Tianzi Wang",
        "Shujie Hu",
        "Zhaoqing Li",
        "Helen Meng",
        "Xunying Liu"
      ],
      "abstract": "The application of data-intensive automatic speech recognition (ASR)\ntechnologies to dysarthric and elderly adult speech is confronted by their\nmismatch against healthy and nonaged voices, data scarcity and large\nspeaker-level variability. To this end, this paper proposes two novel\ndata-efficient methods to learn homogeneous dysarthric and elderly\nspeaker-level features for rapid, on-the-fly test-time adaptation of DNN/TDNN\nand Conformer ASR models. These include: 1) speaker-level variance-regularized\nspectral basis embedding (VR-SBE) features that exploit a special\nregularization term to enforce homogeneity of speaker features in adaptation;\nand 2) feature-based learning hidden unit contributions (f-LHUC) transforms\nthat are conditioned on VR-SBE features. Experiments are conducted on four\ntasks across two languages: the English UASpeech and TORGO dysarthric speech\ndatasets, the English DementiaBank Pitt and Cantonese JCCOCC MoCA elderly\nspeech corpora. The proposed on-the-fly speaker adaptation techniques\nconsistently outperform baseline iVector and xVector adaptation by\nstatistically significant word or character error rate reductions up to 5.32%\nabsolute (18.57% relative) and batch-mode LHUC speaker adaptation by 2.24%\nabsolute (9.20% relative), while operating with real-time factors speeding up\nto 33.6 times against xVectors during adaptation. The efficacy of the proposed\nadaptation techniques is demonstrated in a comparison against current ASR\ntechnologies including SSL pre-trained systems on UASpeech, where our best\nsystem produces a state-of-the-art WER of 23.33%. Analyses show VR-SBE features\nand f-LHUC transforms are insensitive to speaker-level data quantity in\ntesttime adaptation. T-SNE visualization reveals they have stronger\nspeaker-level homogeneity than baseline iVectors, xVectors and batch-mode LHUC\ntransforms.",
      "tldr_zh": "这篇论文针对自动语音识别（ASR）在处理构音障碍和老年语音时的匹配不佳、数据稀缺及说话者变异性问题，提出了两种数据高效方法：说话者级别方差正则化谱基嵌入（VR-SBE）特征和基于特征的学习隐藏单元贡献（f-LHUC）变换，用于DNN/TDNN和Conformer ASR模型的实时测试时适应。VR-SBE通过添加正则化术语强制说话者特征同质化，而f-LHUC则基于这些特征进行条件变换。实验在英语UASpeech、TORGO构音障碍数据集和英语DementiaBank Pitt、粤语JCCOCC MoCA老年语料上显示，这些方法比基线iVector和xVector减少词或字符错误率高达5.32%（相对18.57%），并比批量模式LHUC适应减少2.24%（相对9.20%），适应速度比xVector快33.6倍，同时在UASpeech上达到了最先进的WER 23.33%。分析表明，VR-SBE和f-LHUC对说话者数据量不敏感，并通过T-SNE可视化证明了其更强的说话者级别同质性。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.HC",
        "cs.LG",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "In submission to IEEE/ACM Transactions on Audio, Speech, and Language\n  Processing",
      "pdf_url": "http://arxiv.org/pdf/2407.06310v1",
      "published_date": "2024-07-08 18:20:24 UTC",
      "updated_date": "2024-07-08 18:20:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:28:59.192677"
    },
    {
      "arxiv_id": "2407.06309v1",
      "title": "Multimodal Chain-of-Thought Reasoning via ChatGPT to Protect Children from Age-Inappropriate Apps",
      "title_zh": "翻译失败",
      "authors": [
        "Chuanbo Hu",
        "Bin Liu",
        "Minglei Yin",
        "Yilu Zhou",
        "Xin Li"
      ],
      "abstract": "Mobile applications (Apps) could expose children to inappropriate themes such\nas sexual content, violence, and drug use. Maturity rating offers a quick and\neffective method for potential users, particularly guardians, to assess the\nmaturity levels of apps. Determining accurate maturity ratings for mobile apps\nis essential to protect children's health in today's saturated digital\nmarketplace. Existing approaches to maturity rating are either inaccurate\n(e.g., self-reported rating by developers) or costly (e.g., manual\nexamination). In the literature, there are few text-mining-based approaches to\nmaturity rating. However, each app typically involves multiple modalities,\nnamely app description in the text, and screenshots in the image. In this\npaper, we present a framework for determining app maturity levels that utilize\nmultimodal large language models (MLLMs), specifically ChatGPT-4 Vision.\nPowered by Chain-of-Thought (CoT) reasoning, our framework systematically\nleverages ChatGPT-4 to process multimodal app data (i.e., textual descriptions\nand screenshots) and guide the MLLM model through a step-by-step reasoning\npathway from initial content analysis to final maturity rating determination.\nAs a result, through explicitly incorporating CoT reasoning, our framework\nenables ChatGPT to understand better and apply maturity policies to facilitate\nmaturity rating. Experimental results indicate that the proposed method\noutperforms all baseline models and other fusion strategies.",
      "tldr_zh": "该论文针对移动应用可能暴露儿童不适当内容（如性、暴力或毒品主题）的问题，提出了一种利用 Multimodal Chain-of-Thought Reasoning 的框架，以 ChatGPT-4 Vision 为核心评估应用的成熟度水平。框架通过处理多模态数据（包括文本描述和截图），采用逐步推理路径从内容分析到最终成熟度评定，确保更好地理解和应用成熟度政策。实验结果表明，该方法在性能上优于所有基线模型和其他融合策略，从而为保护儿童提供更准确且高效的自动评估工具。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.06309v1",
      "published_date": "2024-07-08 18:20:10 UTC",
      "updated_date": "2024-07-08 18:20:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:29:07.303987"
    },
    {
      "arxiv_id": "2407.06304v1",
      "title": "VIMI: Grounding Video Generation through Multi-modal Instruction",
      "title_zh": "VIMI：通过多模态指令实现视频生成接地",
      "authors": [
        "Yuwei Fang",
        "Willi Menapace",
        "Aliaksandr Siarohin",
        "Tsai-Shien Chen",
        "Kuan-Chien Wang",
        "Ivan Skorokhodov",
        "Graham Neubig",
        "Sergey Tulyakov"
      ],
      "abstract": "Existing text-to-video diffusion models rely solely on text-only encoders for\ntheir pretraining. This limitation stems from the absence of large-scale\nmultimodal prompt video datasets, resulting in a lack of visual grounding and\nrestricting their versatility and application in multimodal integration. To\naddress this, we construct a large-scale multimodal prompt dataset by employing\nretrieval methods to pair in-context examples with the given text prompts and\nthen utilize a two-stage training strategy to enable diverse video generation\ntasks within the same model. In the first stage, we propose a multimodal\nconditional video generation framework for pretraining on these augmented\ndatasets, establishing a foundational model for grounded video generation.\nSecondly, we finetune the model from the first stage on three video generation\ntasks, incorporating multi-modal instructions. This process further refines the\nmodel's ability to handle diverse inputs and tasks, ensuring seamless\nintegration of multi-modal information. After this two-stage train-ing process,\nVIMI demonstrates multimodal understanding capabilities, producing contextually\nrich and personalized videos grounded in the provided inputs, as shown in\nFigure 1. Compared to previous visual grounded video generation methods, VIMI\ncan synthesize consistent and temporally coherent videos with large motion\nwhile retaining the semantic control. Lastly, VIMI also achieves\nstate-of-the-art text-to-video generation results on UCF101 benchmark.",
      "tldr_zh": "本文提出 VIMI，一种通过多模态指令实现视频生成的框架，以解决现有 text-to-video diffusion models 依赖文本编码器训练的问题，导致缺乏视觉 grounding 和多模态整合能力。研究者构建了大规模多模态提示数据集，使用检索方法配对上下文示例，并采用两阶段训练策略：第一阶段预训练多模态条件视频生成框架，第二阶段微调模型以处理多样视频生成任务，提升多模态理解。结果显示，VIMI 能合成一致、时间连贯的视频，支持大动作和语义控制，并在 UCF101 基准上实现最先进的文本到视频生成性能。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.06304v1",
      "published_date": "2024-07-08 18:12:49 UTC",
      "updated_date": "2024-07-08 18:12:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:29:20.410907"
    },
    {
      "arxiv_id": "2407.06292v1",
      "title": "Hybrid X-Linker: Automated Data Generation and Extreme Multi-label Ranking for Biomedical Entity Linking",
      "title_zh": "翻译失败",
      "authors": [
        "Pedro Ruas",
        "Fernando Gallego",
        "Francisco J. Veredas",
        "Francisco M. Couto"
      ],
      "abstract": "State-of-the-art deep learning entity linking methods rely on extensive\nhuman-labelled data, which is costly to acquire. Current datasets are limited\nin size, leading to inadequate coverage of biomedical concepts and diminished\nperformance when applied to new data. In this work, we propose to automatically\ngenerate data to create large-scale training datasets, which allows the\nexploration of approaches originally developed for the task of extreme\nmulti-label ranking in the biomedical entity linking task. We propose the\nhybrid X-Linker pipeline that includes different modules to link disease and\nchemical entity mentions to concepts in the MEDIC and the CTD-Chemical\nvocabularies, respectively. X-Linker was evaluated on several biomedical\ndatasets: BC5CDR-Disease, BioRED-Disease, NCBI-Disease, BC5CDR-Chemical,\nBioRED-Chemical, and NLM-Chem, achieving top-1 accuracies of 0.8307, 0.7969,\n0.8271, 0.9511, 0.9248, and 0.7895, respectively. X-Linker demonstrated\nsuperior performance in three datasets: BC5CDR-Disease, NCBI-Disease, and\nBioRED-Chemical. In contrast, SapBERT outperformed X-Linker in the remaining\nthree datasets. Both models rely only on the mention string for their\noperations. The source code of X-Linker and its associated data are publicly\navailable for performing biomedical entity linking without requiring\npre-labelled entities with identifiers from specific knowledge organization\nsystems.",
      "tldr_zh": "该研究解决了生物医学实体链接（Biomedical Entity Linking）中依赖人工标注数据的问题，通过自动生成数据来创建大规模训练数据集，并引入极端多标签排名（Extreme Multi-label Ranking）方法。论文提出Hybrid X-Linker管道，包括模块将疾病和化学实体提及链接到MEDIC和CTD-Chemical词汇表。实验在多个数据集上评估，如BC5CDR-Disease（准确率0.8307）和BioRED-Chemical（准确率0.9248），X-Linker在部分数据集上优于SapBERT模型；代码和数据已公开可用，促进了无需预标注的实体链接应用。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.DL"
      ],
      "primary_category": "cs.CL",
      "comment": "This work has been submitted to the IEEE for possible publication",
      "pdf_url": "http://arxiv.org/pdf/2407.06292v1",
      "published_date": "2024-07-08 18:04:22 UTC",
      "updated_date": "2024-07-08 18:04:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:29:32.139894"
    },
    {
      "arxiv_id": "2407.06192v2",
      "title": "Multi-Object Hallucination in Vision-Language Models",
      "title_zh": "视觉语言模型中的多对象幻觉",
      "authors": [
        "Xuweiyi Chen",
        "Ziqiao Ma",
        "Xuejun Zhang",
        "Sihan Xu",
        "Shengyi Qian",
        "Jianing Yang",
        "David F. Fouhey",
        "Joyce Chai"
      ],
      "abstract": "Large vision language models (LVLMs) often suffer from object hallucination,\nproducing objects not present in the given images. While current benchmarks for\nobject hallucination primarily concentrate on the presence of a single object\nclass rather than individual entities, this work systematically investigates\nmulti-object hallucination, examining how models misperceive (e.g., invent\nnonexistent objects or become distracted) when tasked with focusing on multiple\nobjects simultaneously. We introduce Recognition-based Object Probing\nEvaluation (ROPE), an automated evaluation protocol that considers the\ndistribution of object classes within a single image during testing and uses\nvisual referring prompts to eliminate ambiguity. With comprehensive empirical\nstudies and analysis of potential factors leading to multi-object\nhallucination, we found that (1). LVLMs suffer more hallucinations when\nfocusing on multiple objects compared to a single object. (2). The tested\nobject class distribution affects hallucination behaviors, indicating that\nLVLMs may follow shortcuts and spurious correlations. (3). Hallucinatory\nbehaviors are influenced by data-specific factors, salience and frequency, and\nmodel intrinsic behaviors. We hope to enable LVLMs to recognize and reason\nabout multiple objects that often occur in realistic visual scenes, provide\ninsights, and quantify our progress towards mitigating the issues.",
      "tldr_zh": "这项研究系统调查了大型视觉语言模型 (LVLMs) 在处理多对象幻觉 (multi-object hallucination) 时的问题，即模型在图像中生成不存在的对象或分心。作者引入了 Recognition-based Object Probing Evaluation (ROPE)，一种自动化评估协议，通过考虑图像中对象类的分布和使用视觉引用提示 (visual referring prompts) 来消除歧义，并进行全面实证分析。结果显示，LVLMs 在处理多个对象时比单个对象更容易出现幻觉，受对象类分布、数据特定因素（如显著性和频率）以及模型内在行为的影响；这项工作旨在提供见解，帮助改进 LVLMs 在现实场景中识别和推理多个对象的能力。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted to NeurIPS 2024 | Project page:\n  https://multi-object-hallucination.github.io/",
      "pdf_url": "http://arxiv.org/pdf/2407.06192v2",
      "published_date": "2024-07-08 17:59:57 UTC",
      "updated_date": "2024-10-31 18:16:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:29:44.456400"
    },
    {
      "arxiv_id": "2407.06189v1",
      "title": "Video-STaR: Self-Training Enables Video Instruction Tuning with Any Supervision",
      "title_zh": "翻译失败",
      "authors": [
        "Orr Zohar",
        "Xiaohan Wang",
        "Yonatan Bitton",
        "Idan Szpektor",
        "Serena Yeung-Levy"
      ],
      "abstract": "The performance of Large Vision Language Models (LVLMs) is dependent on the\nsize and quality of their training datasets. Existing video instruction tuning\ndatasets lack diversity as they are derived by prompting large language models\nwith video captions to generate question-answer pairs, and are therefore mostly\ndescriptive. Meanwhile, many labeled video datasets with diverse labels and\nsupervision exist - however, we find that their integration into LVLMs is\nnon-trivial. Herein, we present Video Self-Training with augmented Reasoning\n(Video-STaR), the first video self-training approach. Video-STaR allows the\nutilization of any labeled video dataset for video instruction tuning. In\nVideo-STaR, an LVLM cycles between instruction generation and finetuning, which\nwe show (I) improves general video understanding and (II) adapts LVLMs to novel\ndownstream tasks with existing supervision. During generation, an LVLM is\nprompted to propose an answer. The answers are then filtered only to those that\ncontain the original video labels, and the LVLM is then re-trained on the\ngenerated dataset. By only training on generated answers that contain the\ncorrect video labels, Video-STaR utilizes these existing video labels as weak\nsupervision for video instruction tuning. Our results demonstrate that\nVideo-STaR-enhanced LVLMs exhibit improved performance in (I) general video QA,\nwhere TempCompass performance improved by 10%, and (II) on downstream tasks,\nwhere Video-STaR improved Kinetics700-QA accuracy by 20% and action quality\nassessment on FineDiving by 15%.",
      "tldr_zh": "该研究提出 Video-STaR，一种视频自训练方法（Video Self-Training with augmented Reasoning），允许利用任何带标签的视频数据集来增强 Large Vision Language Models (LVLMs) 的视频指令调整。方法通过 LVLM 循环生成指令答案、过滤包含原始视频标签的答案，并重新微调模型，从而利用现有标签作为弱监督，提高视频理解能力。实验结果显示，Video-STaR 显著提升了一般视频 QA 性能（如 TempCompass 提升 10%），并在下游任务中取得进展（如 Kinetics700-QA 准确率提高 20%，FineDiving 动作质量评估提升 15%）。这为 LVLMs 的多样化训练提供了新途径。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Project page: https://orrzohar.github.io/projects/video-star/",
      "pdf_url": "http://arxiv.org/pdf/2407.06189v1",
      "published_date": "2024-07-08 17:59:42 UTC",
      "updated_date": "2024-07-08 17:59:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:29:55.665989"
    },
    {
      "arxiv_id": "2407.06177v1",
      "title": "Vision-Language Models under Cultural and Inclusive Considerations",
      "title_zh": "翻译失败",
      "authors": [
        "Antonia Karamolegkou",
        "Phillip Rust",
        "Yong Cao",
        "Ruixiang Cui",
        "Anders Søgaard",
        "Daniel Hershcovich"
      ],
      "abstract": "Large vision-language models (VLMs) can assist visually impaired people by\ndescribing images from their daily lives. Current evaluation datasets may not\nreflect diverse cultural user backgrounds or the situational context of this\nuse case. To address this problem, we create a survey to determine caption\npreferences and propose a culture-centric evaluation benchmark by filtering\nVizWiz, an existing dataset with images taken by people who are blind. We then\nevaluate several VLMs, investigating their reliability as visual assistants in\na culturally diverse setting. While our results for state-of-the-art models are\npromising, we identify challenges such as hallucination and misalignment of\nautomatic evaluation metrics with human judgment. We make our survey, data,\ncode, and model outputs publicly available.",
      "tldr_zh": "这篇论文探讨了视觉语言模型 (VLMs) 在文化多样性和包容性方面的应用，特别是为视力受损者提供日常生活图像描述。研究者通过创建调查以了解标题偏好，并基于 VizWiz 数据集过滤出文化中心评估基准，评估了多种 VLMs 在多样化环境中的可靠性。结果显示，最新模型表现出色，但面临 hallucination（幻觉）和自动评估指标与人类判断不一致的挑战。该研究公开了调查、数据、代码和模型输出，以推动相关领域的进一步发展。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.CY"
      ],
      "primary_category": "cs.CV",
      "comment": "HuCLLM @ ACL 2024",
      "pdf_url": "http://arxiv.org/pdf/2407.06177v1",
      "published_date": "2024-07-08 17:50:00 UTC",
      "updated_date": "2024-07-08 17:50:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:30:07.597190"
    },
    {
      "arxiv_id": "2407.06172v3",
      "title": "On Speeding Up Language Model Evaluation",
      "title_zh": "翻译失败",
      "authors": [
        "Jin Peng Zhou",
        "Christian K. Belardi",
        "Ruihan Wu",
        "Travis Zhang",
        "Carla P. Gomes",
        "Wen Sun",
        "Kilian Q. Weinberger"
      ],
      "abstract": "Developing prompt-based methods with Large Language Models (LLMs) requires\nmaking numerous decisions, which give rise to a combinatorial search problem\nover hyper-parameters. This exhaustive evaluation can be time-consuming and\ncostly. In this paper, we propose an $\\textit{adaptive}$ approach to explore\nthis space. We are exploiting the fact that often only few samples are needed\nto identify clearly superior or inferior settings, and that many evaluation\ntests are highly correlated. We lean on multi-armed bandits to sequentially\nidentify the next (method, validation sample)-pair to evaluate and utilize\nlow-rank matrix factorization to fill in missing evaluations. We carefully\nassess the efficacy of our approach on several competitive benchmark problems\nand show that it can identify the top-performing method using only 5-15% of the\ntypical resources -- resulting in 85-95% LLM cost savings. Our code is\navailable at https://github.com/kilian-group/banditeval.",
      "tldr_zh": "本研究针对开发基于提示的大语言模型 (LLMs) 方法时面临的组合搜索问题提出了一种自适应评估方法，以减少时间和成本。该方法利用 multi-armed bandits 算法顺序选择下一个要评估的 (方法、验证样本) 对，并通过 low-rank matrix factorization 技术填充缺失评估，从而利用样本效率和测试相关性。实验结果显示，在多个基准问题上，该方法只需 5-15% 的典型资源即可识别出最佳方法，实现 85-95% 的 LLM 成本节省。代码已开源，可从指定仓库获取。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2407.06172v3",
      "published_date": "2024-07-08 17:48:42 UTC",
      "updated_date": "2025-02-26 21:53:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:30:20.254951"
    },
    {
      "arxiv_id": "2407.06152v1",
      "title": "Uni-ELF: A Multi-Level Representation Learning Framework for Electrolyte Formulation Design",
      "title_zh": "翻译失败",
      "authors": [
        "Boshen Zeng",
        "Sian Chen",
        "Xinxin Liu",
        "Changhong Chen",
        "Bin Deng",
        "Xiaoxu Wang",
        "Zhifeng Gao",
        "Yuzhi Zhang",
        "Weinan E",
        "Linfeng Zhang"
      ],
      "abstract": "Advancements in lithium battery technology heavily rely on the design and\nengineering of electrolytes. However, current schemes for molecular design and\nrecipe optimization of electrolytes lack an effective\ncomputational-experimental closed loop and often fall short in accurately\npredicting diverse electrolyte formulation properties. In this work, we\nintroduce Uni-ELF, a novel multi-level representation learning framework to\nadvance electrolyte design. Our approach involves two-stage pretraining:\nreconstructing three-dimensional molecular structures at the molecular level\nusing the Uni-Mol model, and predicting statistical structural properties\n(e.g., radial distribution functions) from molecular dynamics simulations at\nthe mixture level. Through this comprehensive pretraining, Uni-ELF is able to\ncapture intricate molecular and mixture-level information, which significantly\nenhances its predictive capability. As a result, Uni-ELF substantially\noutperforms state-of-the-art methods in predicting both molecular properties\n(e.g., melting point, boiling point, synthesizability) and formulation\nproperties (e.g., conductivity, Coulombic efficiency). Moreover, Uni-ELF can be\nseamlessly integrated into an automatic experimental design workflow. We\nbelieve this innovative framework will pave the way for automated AI-based\nelectrolyte design and engineering.",
      "tldr_zh": "这篇论文介绍了 Uni-ELF，一种多级表示学习框架，用于推进锂电池电解质配方设计，以解决当前方法在计算-实验闭环和属性预测方面的不足。框架采用两阶段预训练：分子级使用 Uni-Mol 模型重建三维分子结构，以及混合级预测统计结构属性（如 radial distribution functions）从分子动力学模拟中，从而捕获复杂分子和混合级信息。Uni-ELF 在预测分子属性（如 melting point, boiling point, synthesizability）和配方属性（如 conductivity, Coulombic efficiency）上显著优于现有方法，并可无缝集成到自动实验设计工作流中。该框架有望为基于 AI 的电解质设计和工程铺平道路。",
      "categories": [
        "physics.chem-ph",
        "cs.AI"
      ],
      "primary_category": "physics.chem-ph",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.06152v1",
      "published_date": "2024-07-08 17:26:49 UTC",
      "updated_date": "2024-07-08 17:26:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:30:33.852031"
    },
    {
      "arxiv_id": "2407.06146v2",
      "title": "Using Grammar Masking to Ensure Syntactic Validity in LLM-based Modeling Tasks",
      "title_zh": "翻译失败",
      "authors": [
        "Lukas Netz",
        "Jan Reimer",
        "Bernhard Rumpe"
      ],
      "abstract": "We present and evaluate a method called grammar masking, which is used to\nguide large language models (LLMs) toward producing syntactically correct\nmodels for a given context-free grammar. Prompt engineering methods such as\nfew-shot learning or priming can be used to improve the chances of an LLM\nproducing correct syntax, but the more complex the grammar, the more\ntime-consuming and less promising these methods become. Previous work is\nfocused primarily on the usage of either language model training or prompt\nengineering. In this work, a method is presented that restricts the output to a\ngiven grammar using constrained decoding to ensure the output adheres to a\nvalid syntax. We use several DSLs built with MontiCore and task multiple LLMs\nto produce models with and without constrained decoding. A corresponding parser\nis used to confirm the syntactic correctness of each model. We show that\ngrammar masking can dramatically improve the modeling capabilities of several\nLLMs, reducing the need for well-refined prompting while increasing the chance\nof producing correct models.",
      "tldr_zh": "本研究提出grammar masking方法，用于指导大型语言模型（LLMs）生成符合给定上下文无关文法的语法正确模型。该方法通过constrained decoding技术限制输出，确保生成的模型在语法上有效，从而解决传统提示工程（如few-shot learning或priming）在复杂语法任务中的效率问题。实验使用MontiCore构建的多种DSL进行测试，结果显示，grammar masking显著提高了LLMs的建模能力，减少了对精确提示的依赖，并大幅提升了产生语法正确模型的成功率。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.SE"
      ],
      "primary_category": "cs.CL",
      "comment": "Preprint to be published in the MODELS Workshop \"MDE Intelligence\"",
      "pdf_url": "http://arxiv.org/pdf/2407.06146v2",
      "published_date": "2024-07-08 17:19:59 UTC",
      "updated_date": "2024-07-09 07:08:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:30:45.330996"
    },
    {
      "arxiv_id": "2407.06135v1",
      "title": "ANOLE: An Open, Autoregressive, Native Large Multimodal Models for Interleaved Image-Text Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Ethan Chern",
        "Jiadi Su",
        "Yan Ma",
        "Pengfei Liu"
      ],
      "abstract": "Previous open-source large multimodal models (LMMs) have faced several\nlimitations: (1) they often lack native integration, requiring adapters to\nalign visual representations with pre-trained large language models (LLMs); (2)\nmany are restricted to single-modal generation; (3) while some support\nmultimodal generation, they rely on separate diffusion models for visual\nmodeling and generation. To mitigate these limitations, we present Anole, an\nopen, autoregressive, native large multimodal model for interleaved image-text\ngeneration. We build Anole from Meta AI's Chameleon, adopting an innovative\nfine-tuning strategy that is both data-efficient and parameter-efficient. Anole\ndemonstrates high-quality, coherent multimodal generation capabilities. We have\nopen-sourced our model, training framework, and instruction tuning data.",
      "tldr_zh": "该论文提出了 ANOLE，一种开源、自回归、本地化的 Large Multimodal Models (LMMs)，旨在解决现有模型的局限性，如缺乏原生整合、仅支持单模态生成以及依赖单独的扩散模型，用于交错图像-文本生成。ANOLE 基于 Meta AI 的 Chameleon 构建，采用创新的细调策略，该策略在数据和参数方面均高效，提升了多模态生成的质量和连贯性。研究团队已开源模型、训练框架和指令调优数据，促进进一步的学术应用。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.06135v1",
      "published_date": "2024-07-08 17:08:02 UTC",
      "updated_date": "2024-07-08 17:08:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:30:59.107135"
    },
    {
      "arxiv_id": "2407.06129v2",
      "title": "Evaluating the Semantic Profiling Abilities of LLMs for Natural Language Utterances in Data Visualization",
      "title_zh": "翻译失败",
      "authors": [
        "Hannah K. Bako",
        "Arshnoor Bhutani",
        "Xinyi Liu",
        "Kwesi A. Cobbina",
        "Zhicheng Liu"
      ],
      "abstract": "Automatically generating data visualizations in response to human utterances\non datasets necessitates a deep semantic understanding of the data utterance,\nincluding implicit and explicit references to data attributes, visualization\ntasks, and necessary data preparation steps. Natural Language Interfaces (NLIs)\nfor data visualization have explored ways to infer such information, yet\nchallenges persist due to inherent uncertainty in human speech. Recent advances\nin Large Language Models (LLMs) provide an avenue to address these challenges,\nbut their ability to extract the relevant semantic information remains\nunexplored. In this study, we evaluate four publicly available LLMs (GPT-4,\nGemini-Pro, Llama3, and Mixtral), investigating their ability to comprehend\nutterances even in the presence of uncertainty and identify the relevant data\ncontext and visual tasks. Our findings reveal that LLMs are sensitive to\nuncertainties in utterances. Despite this sensitivity, they are able to extract\nthe relevant data context. However, LLMs struggle with inferring visualization\ntasks. Based on these results, we highlight future research directions on using\nLLMs for visualization generation.",
      "tldr_zh": "本研究评估了大型语言模型（LLMs）在处理数据可视化自然语言utterance时的语义理解能力，特别是针对utterance中的不确定性、数据属性引用和可视化任务的推断。研究者测试了四个公开LLMs（GPT-4、Gemini-Pro、Llama3和Mixtral），发现这些模型对utterance不确定性高度敏感，能够有效提取相关数据上下文，但难以准确推断可视化任务。基于这些结果，该研究指出了未来使用LLMs生成数据可视化的潜在研究方向，以提升其在Natural Language Interfaces (NLIs)中的应用。",
      "categories": [
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.AI",
      "comment": "5 pages, 4 figures, IEEE VIS short papers",
      "pdf_url": "http://arxiv.org/pdf/2407.06129v2",
      "published_date": "2024-07-08 17:04:31 UTC",
      "updated_date": "2024-07-09 15:59:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:31:08.375097"
    },
    {
      "arxiv_id": "2407.06125v2",
      "title": "Depression Detection and Analysis using Large Language Models on Textual and Audio-Visual Modalities",
      "title_zh": "使用大型语言模型对文本和视音频模态进行抑郁症检测与分析",
      "authors": [
        "Chayan Tank",
        "Sarthak Pol",
        "Vinayak Katoch",
        "Shaina Mehta",
        "Avinash Anand",
        "Rajiv Ratn Shah"
      ],
      "abstract": "Depression has proven to be a significant public health issue, profoundly\naffecting the psychological well-being of individuals. If it remains\nundiagnosed, depression can lead to severe health issues, which can manifest\nphysically and even lead to suicide. Generally, Diagnosing depression or any\nother mental disorder involves conducting semi-structured interviews alongside\nsupplementary questionnaires, including variants of the Patient Health\nQuestionnaire (PHQ) by Clinicians and mental health professionals. This\napproach places significant reliance on the experience and judgment of trained\nphysicians, making the diagnosis susceptible to personal biases. Given that the\nunderlying mechanisms causing depression are still being actively researched,\nphysicians often face challenges in diagnosing and treating the condition,\nparticularly in its early stages of clinical presentation. Recently,\nsignificant strides have been made in Artificial neural computing to solve\nproblems involving text, image, and speech in various domains. Our analysis has\naimed to leverage these state-of-the-art (SOTA) models in our experiments to\nachieve optimal outcomes leveraging multiple modalities. The experiments were\nperformed on the Extended Distress Analysis Interview Corpus Wizard of Oz\ndataset (E-DAIC) corpus presented in the Audio/Visual Emotion Challenge (AVEC)\n2019 Challenge. The proposed solutions demonstrate better results achieved by\nProprietary and Open-source Large Language Models (LLMs), which achieved a Root\nMean Square Error (RMSE) score of 3.98 on Textual Modality, beating the AVEC\n2019 challenge baseline results and current SOTA regression analysis\narchitectures. Additionally, the proposed solution achieved an accuracy of\n71.43% in the classification task. The paper also includes a novel audio-visual\nmulti-modal network that predicts PHQ-8 scores with an RMSE of 6.51.",
      "tldr_zh": "这篇论文探讨了使用大型语言模型(LLMs)检测抑郁症，通过分析文本和音频-视觉模态数据来改善传统诊断方法的准确性和客观性。研究在Extended Distress Analysis Interview Corpus Wizard of Oz (E-DAIC)数据集上进行实验，LLMs在文本模态上实现了Root Mean Square Error (RMSE)为3.98的成绩，优于AVEC 2019基线和当前SOTA模型；在分类任务中准确率达到71.43%。此外，论文提出了一种新型音频-视觉多模态网络，用于预测PHQ-8得分，RMSE为6.51，从而为早期抑郁症诊断提供更可靠的AI辅助工具。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "12 pages, 9 figures, 9 tables",
      "pdf_url": "http://arxiv.org/pdf/2407.06125v2",
      "published_date": "2024-07-08 17:00:51 UTC",
      "updated_date": "2024-12-02 10:02:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:31:23.685042"
    },
    {
      "arxiv_id": "2407.12852v2",
      "title": "Historical Ink: Semantic Shift Detection for 19th Century Spanish",
      "title_zh": "翻译失败",
      "authors": [
        "Tony Montes",
        "Laura Manrique-Gómez",
        "Rubén Manrique"
      ],
      "abstract": "This paper explores the evolution of word meanings in 19th-century Spanish\ntexts, with an emphasis on Latin American Spanish, using computational\nlinguistics techniques. It addresses the Semantic Shift Detection (SSD) task,\nwhich is crucial for understanding linguistic evolution, particularly in\nhistorical contexts. The study focuses on analyzing a set of Spanish target\nwords. To achieve this, a 19th-century Spanish corpus is constructed, and a\ncustomizable pipeline for SSD tasks is developed. This pipeline helps find the\nsenses of a word and measure their semantic change between two corpora using\nfine-tuned BERT-like models with old Spanish texts for both Latin American and\ngeneral Spanish cases. The results provide valuable insights into the cultural\nand societal shifts reflected in language changes over time.",
      "tldr_zh": "这篇论文研究了19世纪西班牙语，特别是拉丁美洲西班牙语中单词含义的演变，强调语义偏移检测（Semantic Shift Detection, SSD）在理解语言历史演变中的作用。研究者构建了一个19世纪西班牙语语料库，并开发了一个可定制的管道，使用细调的BERT-like模型来分析目标单词在不同语料库间的语义变化。结果提供了宝贵的见解，展示了语言变化如何反映文化和社会移转型态。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "I.2.7"
      ],
      "primary_category": "cs.CL",
      "comment": "13 pages; added a preprint-reference URL",
      "pdf_url": "http://arxiv.org/pdf/2407.12852v2",
      "published_date": "2024-07-08 16:49:34 UTC",
      "updated_date": "2024-07-19 01:54:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:31:33.097743"
    },
    {
      "arxiv_id": "2407.06098v1",
      "title": "Epistemological Bias As a Means for the Automated Detection of Injustices in Text",
      "title_zh": "认识论偏见作为自动化检测文本中不公正的手段",
      "authors": [
        "Kenya Andrews",
        "Lamogha Chiazor"
      ],
      "abstract": "Injustice occurs when someone experiences unfair treatment or their rights\nare violated and is often due to the presence of implicit biases and prejudice\nsuch as stereotypes. The automated identification of injustice in text has\nreceived little attention, due in part to the fact that underlying implicit\nbiases or stereotypes are rarely explicitly stated and that instances often\noccur unconsciously due to the pervasive nature of prejudice in society. Here,\nwe describe a novel framework that combines the use of a fine-tuned BERT-based\nbias detection model, two stereotype detection models, and a lexicon-based\napproach to show that epistemological biases (i.e., words, which presupposes,\nentails, asserts, hedges, or boosts text to erode or assert a person's capacity\nas a knower) can assist with the automatic detection of injustice in text. The\nnews media has many instances of injustice (i.e. discriminatory narratives),\nthus it is our use case here. We conduct and discuss an empirical qualitative\nresearch study which shows how the framework can be applied to detect\ninjustices, even at higher volumes of data.",
      "tldr_zh": "该论文探讨了如何利用认识论偏见（epistemological biases）自动检测文本中的不公正现象，这些不公正往往源于隐含的偏见和刻板印象。作者提出一个新框架，结合 fine-tuned BERT-based 偏见检测模型、两个刻板印象检测模型以及 lexicon-based approach，通过分析词语如何削弱或强化个人的认知能力来识别不公正叙述。实验通过实证定性研究应用于新闻媒体数据，证明该框架能有效检测大量文本中的不公正实例，提高了自动化识别的准确性和可扩展性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.06098v1",
      "published_date": "2024-07-08 16:38:31 UTC",
      "updated_date": "2024-07-08 16:38:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:31:47.263091"
    },
    {
      "arxiv_id": "2407.06093v1",
      "title": "Artificial Intuition: Efficient Classification of Scientific Abstracts",
      "title_zh": "人工直觉：科学摘要的高效分类",
      "authors": [
        "Harsh Sakhrani",
        "Naseela Pervez",
        "Anirudh Ravi Kumar",
        "Fred Morstatter",
        "Alexandra Graddy Reed",
        "Andrea Belz"
      ],
      "abstract": "It is desirable to coarsely classify short scientific texts, such as grant or\npublication abstracts, for strategic insight or research portfolio management.\nThese texts efficiently transmit dense information to experts possessing a rich\nbody of knowledge to aid interpretation. Yet this task is remarkably difficult\nto automate because of brevity and the absence of context. To address this gap,\nwe have developed a novel approach to generate and appropriately assign coarse\ndomain-specific labels. We show that a Large Language Model (LLM) can provide\nmetadata essential to the task, in a process akin to the augmentation of\nsupplemental knowledge representing human intuition, and propose a workflow. As\na pilot study, we use a corpus of award abstracts from the National Aeronautics\nand Space Administration (NASA). We develop new assessment tools in concert\nwith established performance metrics.",
      "tldr_zh": "该论文探讨了高效分类科学摘要（如资助或出版摘要）的需求，以支持战略洞见和研究组合管理，但由于摘要的简短和上下文缺失，这一任务自动化难度大。研究提出了一种新方法，使用 Large Language Model (LLM) 生成元数据，模拟人类直觉的补充知识，并设计了一个工作流程来分配粗略的领域特定标签。作为试点研究，他们利用 National Aeronautics and Space Administration (NASA) 的奖项摘要语料库，并开发了新的评估工具结合现有性能指标。结果表明，这一方法有效提升了分类准确性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.06093v1",
      "published_date": "2024-07-08 16:34:47 UTC",
      "updated_date": "2024-07-08 16:34:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:31:55.632201"
    },
    {
      "arxiv_id": "2407.06088v1",
      "title": "Qualitative Event Perception: Leveraging Spatiotemporal Episodic Memory for Learning Combat in a Strategy Game",
      "title_zh": "翻译失败",
      "authors": [
        "Will Hancock",
        "Kenneth D. Forbus"
      ],
      "abstract": "Event perception refers to people's ability to carve up continuous experience\ninto meaningful discrete events. We speak of finishing our morning coffee,\nmowing the lawn, leaving work, etc. as singular occurrences that are localized\nin time and space. In this work, we analyze how spatiotemporal representations\ncan be used to automatically segment continuous experience into structured\nepisodes, and how these descriptions can be used for analogical learning. These\nrepresentations are based on Hayes' notion of histories and build upon existing\nwork on qualitative episodic memory. Our agent automatically generates event\ndescriptions of military battles in a strategy game and improves its gameplay\nby learning from this experience. Episodes are segmented based on changing\nproperties in the world and we show evidence that they facilitate learning\nbecause they capture event descriptions at a useful spatiotemporal grain size.\nThis is evaluated through our agent's performance in the game. We also show\nempirical evidence that the perception of spatial extent of episodes affects\nboth their temporal duration as well as the number of overall cases generated.",
      "tldr_zh": "本研究探讨了事件感知（Event perception），即人类将连续体验分解为离散事件的机制，并提出了一种利用时空表征（spatiotemporal representations）自动分割体验成结构化情节（episodes）的方法，以支持类比学习。基于Hayes的history概念和现有qualitative episodic memory框架，该方法让代理在策略游戏中自动生成军事战役的事件描述，并通过这些描述改进游戏表现。实验结果显示，这种基于世界变化属性的情节分割能提升学习效率，因为它捕捉了合适的时空粒度；此外，事件的空间范围会影响其时间持续性和生成的案例数量。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "16 pages, 10 figures",
      "pdf_url": "http://arxiv.org/pdf/2407.06088v1",
      "published_date": "2024-07-08 16:28:38 UTC",
      "updated_date": "2024-07-08 16:28:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:32:08.770234"
    },
    {
      "arxiv_id": "2407.06079v1",
      "title": "Layered Diffusion Model for One-Shot High Resolution Text-to-Image Synthesis",
      "title_zh": "翻译失败",
      "authors": [
        "Emaad Khwaja",
        "Abdullah Rashwan",
        "Ting Chen",
        "Oliver Wang",
        "Suraj Kothawade",
        "Yeqing Li"
      ],
      "abstract": "We present a one-shot text-to-image diffusion model that can generate\nhigh-resolution images from natural language descriptions. Our model employs a\nlayered U-Net architecture that simultaneously synthesizes images at multiple\nresolution scales. We show that this method outperforms the baseline of\nsynthesizing images only at the target resolution, while reducing the\ncomputational cost per step. We demonstrate that higher resolution synthesis\ncan be achieved by layering convolutions at additional resolution scales, in\ncontrast to other methods which require additional models for super-resolution\nsynthesis.",
      "tldr_zh": "本研究提出了一种one-shot文本到图像扩散模型，用于从自然语言描述生成高分辨率图像。模型采用分层U-Net架构，同时在多个分辨率规模合成图像，从而提升合成质量并降低每步计算成本。与仅在目标分辨率合成的基线方法相比，该方法性能更优，并通过添加额外分辨率规模的卷积层实现更高分辨率合成，而无需额外的超分辨率模型。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.06079v1",
      "published_date": "2024-07-08 16:25:34 UTC",
      "updated_date": "2024-07-08 16:25:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:32:20.038761"
    },
    {
      "arxiv_id": "2407.06077v1",
      "title": "Object-Oriented Material Classification and 3D Clustering for Improved Semantic Perception and Mapping in Mobile Robots",
      "title_zh": "翻译失败",
      "authors": [
        "Siva Krishna Ravipati",
        "Ehsan Latif",
        "Ramviyas Parasuraman",
        "Suchendra M. Bhandarkar"
      ],
      "abstract": "Classification of different object surface material types can play a\nsignificant role in the decision-making algorithms for mobile robots and\nautonomous vehicles. RGB-based scene-level semantic segmentation has been\nwell-addressed in the literature. However, improving material recognition using\nthe depth modality and its integration with SLAM algorithms for 3D semantic\nmapping could unlock new potential benefits in the robotics perception\npipeline. To this end, we propose a complementarity-aware deep learning\napproach for RGB-D-based material classification built on top of an\nobject-oriented pipeline. The approach further integrates the ORB-SLAM2 method\nfor 3D scene mapping with multiscale clustering of the detected material\nsemantics in the point cloud map generated by the visual SLAM algorithm.\nExtensive experimental results with existing public datasets and newly\ncontributed real-world robot datasets demonstrate a significant improvement in\nmaterial classification and 3D clustering accuracy compared to state-of-the-art\napproaches for 3D semantic scene mapping.",
      "tldr_zh": "该论文提出了一种基于物体导向的 RGB-D 材料分类方法，旨在提升移动机器人的语义感知和映射能力，以辅助决策算法。方法结合互补性感知的深度学习技术，并将 ORB-SLAM2 算法集成到 3D 场景映射中，通过多尺度聚类处理检测到的材料语义。实验结果显示，在现有公共数据集和新采集的真实机器人数据集上，该方法在材料分类和 3D 聚类准确率上比现有先进方法有显著提升。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.RO",
      "comment": "Accepted to IROS 2024",
      "pdf_url": "http://arxiv.org/pdf/2407.06077v1",
      "published_date": "2024-07-08 16:25:01 UTC",
      "updated_date": "2024-07-08 16:25:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:32:33.667915"
    },
    {
      "arxiv_id": "2407.06076v2",
      "title": "Understanding Visual Feature Reliance through the Lens of Complexity",
      "title_zh": "从复杂性的视角理解视觉特征依赖",
      "authors": [
        "Thomas Fel",
        "Louis Bethune",
        "Andrew Kyle Lampinen",
        "Thomas Serre",
        "Katherine Hermann"
      ],
      "abstract": "Recent studies suggest that deep learning models inductive bias towards\nfavoring simpler features may be one of the sources of shortcut learning. Yet,\nthere has been limited focus on understanding the complexity of the myriad\nfeatures that models learn. In this work, we introduce a new metric for\nquantifying feature complexity, based on $\\mathscr{V}$-information and\ncapturing whether a feature requires complex computational transformations to\nbe extracted. Using this $\\mathscr{V}$-information metric, we analyze the\ncomplexities of 10,000 features, represented as directions in the penultimate\nlayer, that were extracted from a standard ImageNet-trained vision model. Our\nstudy addresses four key questions: First, we ask what features look like as a\nfunction of complexity and find a spectrum of simple to complex features\npresent within the model. Second, we ask when features are learned during\ntraining. We find that simpler features dominate early in training, and more\ncomplex features emerge gradually. Third, we investigate where within the\nnetwork simple and complex features flow, and find that simpler features tend\nto bypass the visual hierarchy via residual connections. Fourth, we explore the\nconnection between features complexity and their importance in driving the\nnetworks decision. We find that complex features tend to be less important.\nSurprisingly, important features become accessible at earlier layers during\ntraining, like a sedimentation process, allowing the model to build upon these\nfoundational elements.",
      "tldr_zh": "本研究提出了一种基于$\\mathscr{V}$-information的度量方法，用于量化深度学习模型中视觉特征的复杂性，并分析了从ImageNet训练模型中提取的10,000个特征。研究回答了四个关键问题：特征复杂度呈现从简单到复杂的谱系；训练早期主要学习简单特征，而复杂特征逐渐出现；简单特征通过残差连接绕过视觉层次流动；复杂特征对网络决策较不重要，且重要特征在训练早期层就变得可访问，如同沉积过程。总之，这一工作揭示了模型特征依赖的动态机制，有助于理解和缓解快捷学习问题。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.06076v2",
      "published_date": "2024-07-08 16:21:53 UTC",
      "updated_date": "2024-10-28 11:15:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:32:45.805675"
    },
    {
      "arxiv_id": "2407.06071v2",
      "title": "From Loops to Oops: Fallback Behaviors of Language Models Under Uncertainty",
      "title_zh": "翻译失败",
      "authors": [
        "Maor Ivgi",
        "Ori Yoran",
        "Jonathan Berant",
        "Mor Geva"
      ],
      "abstract": "Large language models (LLMs) often exhibit undesirable behaviors, such as\nhallucinations and sequence repetitions. We propose to view these behaviors as\nfallbacks that models exhibit under epistemic uncertainty, and investigate the\nconnection between them. We categorize fallback behaviors - sequence\nrepetitions, degenerate text, and hallucinations - and extensively analyze them\nin models from the same family that differ by the amount of pretraining tokens,\nparameter count, or the inclusion of instruction-following training. Our\nexperiments reveal a clear and consistent ordering of fallback behaviors,\nacross all these axes: the more advanced an LLM is (i.e., trained on more\ntokens, has more parameters, or instruction-tuned), its fallback behavior\nshifts from sequence repetitions, to degenerate text, and then to\nhallucinations. Moreover, the same ordering is observed during the generation\nof a single sequence, even for the best-performing models; as uncertainty\nincreases, models shift from generating hallucinations to producing degenerate\ntext and finally sequence repetitions. Lastly, we demonstrate that while common\ndecoding techniques, such as random sampling, alleviate unwanted behaviors like\nsequence repetitions, they increase harder-to-detect hallucinations.",
      "tldr_zh": "这篇论文探讨了大型语言模型(LLMs)在认识不确定性(epistemic uncertainty)下的后备行为，将这些行为分类为序列重复(sequence repetitions)、退化文本(degenerate text)和幻觉(hallucinations)，并分析它们之间的联系。研究通过比较不同模型（差异包括预训练 token 数量、参数大小和指令跟随训练）发现，更先进的LLMs倾向于从序列重复转向退化文本，再到幻觉；即使在生成单个序列时，随着不确定性增加，行为顺序也随之变化。实验结果表明，常见的解码技术如随机采样能缓解序列重复，但会增加更难检测的幻觉，从而为理解和优化LLMs的行为提供了新见解。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "NeurIPS Workshop on Attributing Model Behavior at Scale (ATTRIB 2024)",
      "pdf_url": "http://arxiv.org/pdf/2407.06071v2",
      "published_date": "2024-07-08 16:13:42 UTC",
      "updated_date": "2025-02-08 10:48:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:33:08.975205"
    },
    {
      "arxiv_id": "2407.06057v3",
      "title": "Variational Best-of-N Alignment",
      "title_zh": "翻译失败",
      "authors": [
        "Afra Amini",
        "Tim Vieira",
        "Elliott Ash",
        "Ryan Cotterell"
      ],
      "abstract": "Best-of-N (BoN) is a popular and effective algorithm for aligning language\nmodels to human preferences. The algorithm works as follows: at inference time,\nN samples are drawn from the language model, and the sample with the highest\nreward, as judged by a reward model, is returned as the output. Despite its\neffectiveness, BoN is computationally expensive; it reduces sampling throughput\nby a factor of N. To make BoN more efficient at inference time, one strategy is\nto fine-tune the language model to mimic what BoN does during inference. To\nachieve this, we derive the distribution induced by the BoN algorithm. We then\npropose to fine-tune the language model to minimize backward KL divergence to\nthe BoN distribution. Our approach is analogous to mean-field variational\ninference and, thus, we term it variational BoN (vBoN). To the extent this\nfine-tuning is successful and we end up with a good approximation, we have\nreduced the inference cost by a factor of N. Our experiments on controlled\ngeneration and summarization tasks show that BoN is the most effective\nalignment method, and our variational approximation to BoN achieves the closest\nperformance to BoN and surpasses models fine-tuned using the standard\nKL-constrained RL objective. In the controlled generation task, vBoN appears\nmore frequently on the Pareto frontier of reward and KL divergence compared to\nother alignment methods. In the summarization task, vBoN achieves high reward\nvalues across various sampling temperatures.",
      "tldr_zh": "本文提出 Variational Best-of-N Alignment (vBoN)，一种高效方法来优化 Best-of-N (BoN) 算法，用于将语言模型与人类偏好对齐。vBoN 通过推导 BoN 诱导的分布，并微调语言模型以最小化 backward KL divergence，从而模仿 BoN 的行为，显著降低了推理时的计算开销，将成本减少了 N 倍。实验结果显示，在控制生成和总结任务中，vBoN 的性能最接近 BoN，并优于标准 KL-constrained RL 目标的模型，在奖励与 KL divergence 的 Pareto 前沿上表现出色，并在各种采样温度下实现高奖励值。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted at ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2407.06057v3",
      "published_date": "2024-07-08 15:59:44 UTC",
      "updated_date": "2025-03-04 14:33:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:33:11.368752"
    },
    {
      "arxiv_id": "2407.06056v1",
      "title": "Stranger Danger! Identifying and Avoiding Unpredictable Pedestrians in RL-based Social Robot Navigation",
      "title_zh": "翻译失败",
      "authors": [
        "Sara Pohland",
        "Alvin Tan",
        "Prabal Dutta",
        "Claire Tomlin"
      ],
      "abstract": "Reinforcement learning (RL) methods for social robot navigation show great\nsuccess navigating robots through large crowds of people, but the performance\nof these learning-based methods tends to degrade in particularly challenging or\nunfamiliar situations due to the models' dependency on representative training\ndata. To ensure human safety and comfort, it is critical that these algorithms\nhandle uncommon cases appropriately, but the low frequency and wide diversity\nof such situations present a significant challenge for these data-driven\nmethods. To overcome this challenge, we propose modifications to the learning\nprocess that encourage these RL policies to maintain additional caution in\nunfamiliar situations. Specifically, we improve the Socially Attentive\nReinforcement Learning (SARL) policy by (1) modifying the training process to\nsystematically introduce deviations into a pedestrian model, (2) updating the\nvalue network to estimate and utilize pedestrian-unpredictability features, and\n(3) implementing a reward function to learn an effective response to pedestrian\nunpredictability. Compared to the original SARL policy, our modified policy\nmaintains similar navigation times and path lengths, while reducing the number\nof collisions by 82% and reducing the proportion of time spent in the\npedestrians' personal space by up to 19 percentage points for the most\ndifficult cases. We also describe how to apply these modifications to other RL\npolicies and demonstrate that some key high-level behaviors of our approach\ntransfer to a physical robot.",
      "tldr_zh": "该研究针对强化学习 (RL) 基于的社交机器人导航问题，提出改进方法以识别和避免不可预测的行人，因为现有模型在不熟悉场景下性能下降。研究者修改了 Socially Attentive Reinforcement Learning (SARL) 政策，包括在训练过程中引入行人模型偏差、更新价值网络以估计行人不可预测性特征，以及设计奖励函数来学习有效响应。实验结果显示，与原 SARL 相比，新政策减少了 82% 的碰撞事件，并将最困难场景中在行人个人空间停留的时间降低多达 19 百分比点，同时保持相似的导航时间和路径长度；此外，这些改进可扩展到其他 RL 政策，并在物理机器人上实现了关键行为转移。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.06056v1",
      "published_date": "2024-07-08 15:58:33 UTC",
      "updated_date": "2024-07-08 15:58:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:33:25.335584"
    },
    {
      "arxiv_id": "2407.06025v1",
      "title": "iLLM-TSC: Integration reinforcement learning and large language model for traffic signal control policy improvement",
      "title_zh": "翻译失败",
      "authors": [
        "Aoyu Pang",
        "Maonan Wang",
        "Man-On Pun",
        "Chung Shue Chen",
        "Xi Xiong"
      ],
      "abstract": "Urban congestion remains a critical challenge, with traffic signal control\n(TSC) emerging as a potent solution. TSC is often modeled as a Markov Decision\nProcess problem and then solved using reinforcement learning (RL), which has\nproven effective. However, the existing RL-based TSC system often overlooks\nimperfect observations caused by degraded communication, such as packet loss,\ndelays, and noise, as well as rare real-life events not included in the reward\nfunction, such as unconsidered emergency vehicles. To address these\nlimitations, we introduce a novel integration framework that combines a large\nlanguage model (LLM) with RL. This framework is designed to manage overlooked\nelements in the reward function and gaps in state information, thereby\nenhancing the policies of RL agents. In our approach, RL initially makes\ndecisions based on observed data. Subsequently, LLMs evaluate these decisions\nto verify their reasonableness. If a decision is found to be unreasonable, it\nis adjusted accordingly. Additionally, this integration approach can be\nseamlessly integrated with existing RL-based TSC systems without necessitating\nmodifications. Extensive testing confirms that our approach reduces the average\nwaiting time by $17.5\\%$ in degraded communication conditions as compared to\ntraditional RL methods, underscoring its potential to advance practical RL\napplications in intelligent transportation systems. The related code can be\nfound at \\url{https://github.com/Traffic-Alpha/iLLM-TSC}.",
      "tldr_zh": "该研究针对城市交通拥堵问题，提出 iLLM-TSC 框架，将强化学习 (RL) 与大型语言模型 (LLM) 整合，以改善交通信号控制 (TSC) 策略。该框架通过 RL 首先基于观察数据做出决策，然后由 LLM 评估决策的合理性，并在必要时进行调整，从而处理通信不完善（如数据丢失、延迟）和奖励函数缺失的稀有事件。实验结果显示，在通信条件恶化的场景下，该方法比传统 RL 减少平均等待时间 17.5%，并可无缝整合到现有 RL 系统，无需修改。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.06025v1",
      "published_date": "2024-07-08 15:22:49 UTC",
      "updated_date": "2024-07-08 15:22:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:33:35.397430"
    },
    {
      "arxiv_id": "2407.06023v3",
      "title": "Distilling System 2 into System 1",
      "title_zh": "翻译失败",
      "authors": [
        "Ping Yu",
        "Jing Xu",
        "Jason Weston",
        "Ilia Kulikov"
      ],
      "abstract": "Large language models (LLMs) can spend extra compute during inference to\ngenerate intermediate thoughts, which helps to produce better final responses.\nSince Chain-of-Thought (Wei et al., 2022), many such System 2 techniques have\nbeen proposed such as Rephrase and Respond (Deng et al., 2023a), System 2\nAttention (Weston and Sukhbaatar, 2023) and Branch-Solve-Merge (Saha et al.,\n2023). In this work we investigate self-supervised methods to ``compile''\n(distill) higher quality outputs from System 2 techniques back into LLM\ngenerations without intermediate reasoning token sequences, as this reasoning\nhas been distilled into System 1. We show that several such techniques can be\nsuccessfully distilled, resulting in improved results compared to the original\nSystem 1 performance, and with less inference cost than System 2. We posit that\nsuch System 2 distillation will be an important feature of future continually\nlearning AI systems, enabling them to focus System 2 capabilities on the\nreasoning tasks that they cannot yet do well.",
      "tldr_zh": "该研究探讨了如何通过自监督方法将 System 2 技术（如 Chain-of-Thought 和 Rephrase and Respond）蒸馏到 System 1 中，从而使大型语言模型 (LLMs) 在不生成中间推理序列的情况下产生更高质量的输出。实验结果显示，这种蒸馏方法不仅提升了原始 System 1 的性能，还降低了推理成本，使模型更高效。论文认为，这种 System 2 蒸馏将是未来持续学习 AI 系统的重要特征，允许它们专注于难以处理的推理任务。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.06023v3",
      "published_date": "2024-07-08 15:17:46 UTC",
      "updated_date": "2024-07-24 18:40:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:33:47.468484"
    },
    {
      "arxiv_id": "2407.06011v1",
      "title": "Igea: a Decoder-Only Language Model for Biomedical Text Generation in Italian",
      "title_zh": "翻译失败",
      "authors": [
        "Tommaso Mario Buonocore",
        "Simone Rancati",
        "Enea Parimbelli"
      ],
      "abstract": "The development of domain-specific language models has significantly advanced\nnatural language processing applications in various specialized fields,\nparticularly in biomedicine. However, the focus has largely been on\nEnglish-language models, leaving a gap for less-resourced languages such as\nItalian. This paper introduces Igea, the first decoder-only language model\ndesigned explicitly for biomedical text generation in Italian. Built on the\nMinerva model and continually pretrained on a diverse corpus of Italian medical\ntexts, Igea is available in three model sizes: 350 million, 1 billion, and 3\nbillion parameters. The models aim to balance computational efficiency and\nperformance, addressing the challenges of managing the peculiarities of medical\nterminology in Italian. We evaluate Igea using a mix of in-domain biomedical\ncorpora and general-purpose benchmarks, highlighting its efficacy and retention\nof general knowledge even after the domain-specific training. This paper\ndiscusses the model's development and evaluation, providing a foundation for\nfuture advancements in Italian biomedical NLP.",
      "tldr_zh": "本研究引入了 Igea，这是一个专为意大利语生物医学文本生成设计的 decoder-only language model，填补了非英语语言在该领域的空白。Igea 基于 Minerva model，在多样化的意大利医学文本语料上进行持续预训练，提供 350 million、1 billion 和 3 billion 参数的三种大小，以平衡计算效率和处理医疗术语的特殊性。通过混合的领域内生物医学和通用基准评估，Igea 展示了出色的性能，同时保留了一般知识，为意大利 biomedical NLP 的未来发展奠定了基础。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "I.2.7; J.3"
      ],
      "primary_category": "cs.CL",
      "comment": "6 pages, 1 figure, 3 tables",
      "pdf_url": "http://arxiv.org/pdf/2407.06011v1",
      "published_date": "2024-07-08 15:04:21 UTC",
      "updated_date": "2024-07-08 15:04:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:33:58.602897"
    },
    {
      "arxiv_id": "2407.15316v1",
      "title": "AI as a Tool for Fair Journalism: Case Studies from Malta",
      "title_zh": "人工智能作为公平新闻业的工具：马耳他的案例研究",
      "authors": [
        "Dylan Seychell",
        "Gabriel Hili",
        "Jonathan Attard",
        "Konstantinos Makantatis"
      ],
      "abstract": "In today`s media landscape, the role of Artificial Intelligence (AI) in\nshaping societal perspectives and journalistic integrity is becoming\nincreasingly apparent. This paper presents two case studies centred on Malta`s\nmedia market featuring technical novelty. Despite its relatively small scale,\nMalta offers invaluable insights applicable to both similar and broader media\ncontexts. These two projects focus on media monitoring and present tools\ndesigned to analyse potential biases in news articles and television news\nsegments. The first project uses Computer Vision and Natural Language\nProcessing techniques to analyse the coherence between images in news articles\nand their corresponding captions, headlines, and article bodies. The second\nproject employs computer vision techniques to track individuals` on-screen time\nor visual exposure in news videos, providing queryable data. These initiatives\naim to contribute to society by providing both journalists and the public with\nthe means to identify biases. Furthermore, we make these tools accessible to\njournalists to improve the trustworthiness of media outlets by offering robust\ntools for detecting and reducing bias.",
      "tldr_zh": "本论文探讨了人工智能（AI）作为促进公平新闻工具的作用，通过马耳他媒体市场的两个案例研究提供见解。这些研究聚焦媒体监控：第一个项目利用 Computer Vision 和 Natural Language Processing 技术，分析新闻文章中图像与标题、摘要及正文的一致性，以识别潜在偏差；第二个项目则应用 Computer Vision 追踪新闻视频中个人的屏幕时间和视觉暴露，提供可查询数据。这些工具旨在帮助记者和公众检测并减少偏差，从而提升媒体的可信度，并为更广泛的媒体环境提供可借鉴的经验。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "Accepted as a full paper in the proceedings of the IEEE 2024\n  Conference on Artificial Intelligence",
      "pdf_url": "http://arxiv.org/pdf/2407.15316v1",
      "published_date": "2024-07-08 15:02:39 UTC",
      "updated_date": "2024-07-08 15:02:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:34:10.962996"
    },
    {
      "arxiv_id": "2407.06003v1",
      "title": "Surprising gender biases in GPT",
      "title_zh": "GPT 中的惊人性别偏见",
      "authors": [
        "Raluca Alexandra Fulgu",
        "Valerio Capraro"
      ],
      "abstract": "We present seven experiments exploring gender biases in GPT. Initially, GPT\nwas asked to generate demographics of a potential writer of twenty phrases\ncontaining feminine stereotypes and twenty with masculine stereotypes. Results\nshow a strong asymmetry, with stereotypically masculine sentences attributed to\na female more often than vice versa. For example, the sentence \"I love playing\nfotbal! Im practicing with my cosin Michael\" was constantly assigned by ChatGPT\nto a female writer. This phenomenon likely reflects that while initiatives to\nintegrate women in traditionally masculine roles have gained momentum, the\nreverse movement remains relatively underdeveloped. Subsequent experiments\ninvestigate the same issue in high-stakes moral dilemmas. GPT-4 finds it more\nappropriate to abuse a man to prevent a nuclear apocalypse than to abuse a\nwoman. This bias extends to other forms of violence central to the gender\nparity debate (abuse), but not to those less central (torture). Moreover, this\nbias increases in cases of mixed-sex violence for the greater good: GPT-4\nagrees with a woman using violence against a man to prevent a nuclear\napocalypse but disagrees with a man using violence against a woman for the same\npurpose. Finally, these biases are implicit, as they do not emerge when GPT-4\nis directly asked to rank moral violations. These results highlight the\nnecessity of carefully managing inclusivity efforts to prevent unintended\ndiscrimination.",
      "tldr_zh": "本研究通过七个实验揭示了 GPT 中的性别偏见（gender biases）。首先，GPT 在推断短语作者时显示不对称倾向：刻板印象的男性句子（如“我喜欢踢足球！我在和表弟 Michael 练习”）更常被归因于女性作者，这可能反映了社会推动女性进入传统男性角色的努力，而反之不足。进一步实验涉及高风险道德困境，GPT-4 更倾向于虐待男性而非女性来防止核灾难，这种偏见在与性别平等相关的暴力（如 abuse）中显著，但在其他形式（如 torture）中不明显。实验还发现，在混合性别暴力场景中，GPT-4 支持女性对男性施暴以实现更大利益，但反对男性对女性施暴；这些偏见是隐性的，直接询问时不会显现。总体结果强调了谨慎管理包容性努力以避免意外歧视的必要性。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.06003v1",
      "published_date": "2024-07-08 14:57:02 UTC",
      "updated_date": "2024-07-08 14:57:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:34:24.775974"
    },
    {
      "arxiv_id": "2407.05991v2",
      "title": "Multi-Texture Synthesis through Signal Responsive Neural Cellular Automata",
      "title_zh": "翻译失败",
      "authors": [
        "Mirela-Magdalena Catrina",
        "Ioana Cristina Plajer",
        "Alexandra Baicoianu"
      ],
      "abstract": "Neural Cellular Automata (NCA) have proven to be effective in a variety of\nfields, with numerous biologically inspired applications. One of the fields, in\nwhich NCAs perform well is the generation of textures, modelling global\npatterns from local interactions governed by uniform and coherent rules. This\npaper aims to enhance the usability of NCAs in texture synthesis by addressing\na shortcoming of current NCA architectures for texture generation, which\nrequires separately trained NCA for each individual texture. In this work, we\ntrain a single NCA for the evolution of multiple textures, based on individual\nexamples. Our solution provides texture information in the state of each cell,\nin the form of an internally coded genomic signal, which enables the NCA to\ngenerate the expected texture. Such a neural cellular automaton not only\nmaintains its regenerative capability but also allows for interpolation between\nlearned textures and supports grafting techniques. This demonstrates the\nability to edit generated textures and the potential for them to merge and\ncoexist within the same automaton. We also address questions related to the\ninfluence of the genomic information and the cost function on the evolution of\nthe NCA.",
      "tldr_zh": "本研究针对 Neural Cellular Automata (NCA) 在纹理合成中的局限性，即每个纹理需单独训练，提出了一种 Signal Responsive NCA 框架，能够使用单个 NCA 基于不同示例生成多种纹理。方法通过在每个细胞的状态中加入内部编码的 genomic signal，提供纹理信息，从而实现纹理的精确演化，同时保留 NCA 的再生能力，并支持纹理之间的插值、嫁接和编辑功能。实验结果表明，该框架增强了纹理合成的灵活性，并探讨了 genomic signal 和成本函数对 NCA 演化的影响，为更高效的纹理生成应用奠定基础。",
      "categories": [
        "cs.NE",
        "cs.AI"
      ],
      "primary_category": "cs.NE",
      "comment": "29 pages",
      "pdf_url": "http://arxiv.org/pdf/2407.05991v2",
      "published_date": "2024-07-08 14:36:20 UTC",
      "updated_date": "2024-07-19 08:17:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:34:36.044637"
    },
    {
      "arxiv_id": "2407.05983v1",
      "title": "Towards A Comprehensive Visual Saliency Explanation Framework for AI-based Face Recognition Systems",
      "title_zh": "翻译失败",
      "authors": [
        "Yuhang Lu",
        "Zewei Xu",
        "Touradj Ebrahimi"
      ],
      "abstract": "Over recent years, deep convolutional neural networks have significantly\nadvanced the field of face recognition techniques for both verification and\nidentification purposes. Despite the impressive accuracy, these neural networks\nare often criticized for lacking explainability. There is a growing demand for\nunderstanding the decision-making process of AI-based face recognition systems.\nSome studies have investigated the use of visual saliency maps as explanations,\nbut they have predominantly focused on the specific face verification case. The\ndiscussion on more general face recognition scenarios and the corresponding\nevaluation methodology for these explanations have long been absent in current\nresearch. Therefore, this manuscript conceives a comprehensive explanation\nframework for face recognition tasks. Firstly, an exhaustive definition of\nvisual saliency map-based explanations for AI-based face recognition systems is\nprovided, taking into account the two most common recognition situations\nindividually, i.e., face verification and identification. Secondly, a new\nmodel-agnostic explanation method named CorrRISE is proposed to produce\nsaliency maps, which reveal both the similar and dissimilar regions between any\ngiven face images. Subsequently, the explanation framework conceives a new\nevaluation methodology that offers quantitative measurement and comparison of\nthe performance of general visual saliency explanation methods in face\nrecognition. Consequently, extensive experiments are carried out on multiple\nverification and identification scenarios. The results showcase that CorrRISE\ngenerates insightful saliency maps and demonstrates superior performance,\nparticularly in similarity maps in comparison with the state-of-the-art\nexplanation approaches.",
      "tldr_zh": "本论文针对AI-based人脸识别系统的可解释性问题，提出一个全面的visual saliency explanation框架，以解决现有研究主要聚焦于face verification而忽略更一般场景的不足。首先，该框架详细定义了基于visual saliency maps的解释方法，分别针对face verification和face identification两种任务。其次，引入了一个新的模型无关方法CorrRISE，用于生成显著性地图，揭示两张人脸图像之间的相似和不同区域，并设计了量化评估方法来比较解释性能。实验结果显示，CorrRISE在多个验证和识别场景中表现出色，尤其在相似性地图上优于现有state-of-the-art方法。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "arXiv admin note: text overlap with arXiv:2305.08546",
      "pdf_url": "http://arxiv.org/pdf/2407.05983v1",
      "published_date": "2024-07-08 14:25:46 UTC",
      "updated_date": "2024-07-08 14:25:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:34:48.108935"
    },
    {
      "arxiv_id": "2407.05977v1",
      "title": "Exploring Human-LLM Conversations: Mental Models and the Originator of Toxicity",
      "title_zh": "探索人类-LLM 对话：心理模型和毒性来源",
      "authors": [
        "Johannes Schneider",
        "Arianna Casanova Flores",
        "Anne-Catherine Kranz"
      ],
      "abstract": "This study explores real-world human interactions with large language models\n(LLMs) in diverse, unconstrained settings in contrast to most prior research\nfocusing on ethically trimmed models like ChatGPT for specific tasks. We aim to\nunderstand the originator of toxicity. Our findings show that although LLMs are\nrightfully accused of providing toxic content, it is mostly demanded or at\nleast provoked by humans who actively seek such content. Our manual analysis of\nhundreds of conversations judged as toxic by APIs commercial vendors, also\nraises questions with respect to current practices of what user requests are\nrefused to answer. Furthermore, we conjecture based on multiple empirical\nindicators that humans exhibit a change of their mental model, switching from\nthe mindset of interacting with a machine more towards interacting with a\nhuman.",
      "tldr_zh": "这篇论文探讨了人类与大型语言模型 (LLMs) 在真实、非受限环境中的互动，旨在识别毒性内容的起源，与以往专注于如 ChatGPT 等道德修剪模型的研究形成对比。通过手动分析数百次被商业 API 判断为毒性的对话，研究发现毒性内容大多由人类主动要求或挑起，同时质疑当前拒绝回答某些用户请求的做法。论文进一步推测，人类在这些互动中改变了心理模型 (mental models)，从与机器互动的思维转向更像与人类互动的模式。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.05977v1",
      "published_date": "2024-07-08 14:20:05 UTC",
      "updated_date": "2024-07-08 14:20:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:34:59.289987"
    },
    {
      "arxiv_id": "2407.05976v2",
      "title": "Change-Point Detection in Industrial Data Streams based on Online Dynamic Mode Decomposition with Control",
      "title_zh": "翻译失败",
      "authors": [
        "Marek Wadinger",
        "Michal Kvasnica",
        "Yoshinobu Kawahara"
      ],
      "abstract": "We propose a novel change-point detection method based on online Dynamic Mode\nDecomposition with control (ODMDwC). Leveraging ODMDwC's ability to find and\ntrack linear approximation of a non-linear system while incorporating control\neffects, the proposed method dynamically adapts to its changing behavior due to\naging and seasonality. This approach enables the detection of changes in\nspatial, temporal, and spectral patterns, providing a robust solution that\npreserves correspondence between the score and the extent of change in the\nsystem dynamics. We formulate a truncated version of ODMDwC and utilize\nhigher-order time-delay embeddings to mitigate noise and extract broad-band\nfeatures. Our method addresses the challenges faced in industrial settings\nwhere safety-critical systems generate non-uniform data streams while requiring\ntimely and accurate change-point detection to protect profit and life. Our\nresults demonstrate that this method yields intuitive and improved detection\nresults compared to the Singular-Value-Decomposition-based method. We validate\nour approach using synthetic and real-world data, showing its competitiveness\nto other approaches on complex systems' benchmark datasets. Provided guidelines\nfor hyperparameters selection enhance our method's practical applicability.",
      "tldr_zh": "该研究提出了一种基于在线动态模式分解 with control (ODMDwC) 的变更点检测方法，用于处理工业数据流中的非线性系统变化。该方法通过跟踪系统的线性近似、结合控制效果以及高阶时延嵌入来减少噪声并提取宽带特征，从而实现对空间、时间和频谱模式变化的准确检测。相比基于奇异值分解 (SVD) 的方法，该方法提供更直观且改进的检测结果，并在合成和真实世界数据上验证其竞争力。论文还提供了超参数选择的指导，以增强其在安全关键工业系统的实际应用。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "preprint under review in Elsevier",
      "pdf_url": "http://arxiv.org/pdf/2407.05976v2",
      "published_date": "2024-07-08 14:18:33 UTC",
      "updated_date": "2024-08-19 06:20:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:35:13.736954"
    },
    {
      "arxiv_id": "2407.05975v2",
      "title": "LLaMAX: Scaling Linguistic Horizons of LLM by Enhancing Translation Capabilities Beyond 100 Languages",
      "title_zh": "翻译失败",
      "authors": [
        "Yinquan Lu",
        "Wenhao Zhu",
        "Lei Li",
        "Yu Qiao",
        "Fei Yuan"
      ],
      "abstract": "Large Language Models (LLMs) demonstrate remarkable translation capabilities\nin high-resource language tasks, yet their performance in low-resource\nlanguages is hindered by insufficient multilingual data during pre-training. To\naddress this, we conduct extensive multilingual continual pre-training on the\nLLaMA series models, enabling translation support across more than 100\nlanguages. Through a comprehensive analysis of training strategies, such as\nvocabulary expansion and data augmentation, we develop LLaMAX. Remarkably,\nwithout sacrificing its generalization ability, LLaMAX achieves significantly\nhigher translation performance compared to existing open-source LLMs (by more\nthan 10 spBLEU points) and performs on-par with specialized translation model\n(M2M-100-12B) on the Flores-101 benchmark. Extensive experiments indicate that\nLLaMAX can serve as a robust multilingual foundation model. The code\n\\footnote{\\url{https://github.com/CONE-MT/LLaMAX/.}} and the models\n\\footnote{\\url{https://huggingface.co/LLaMAX/.}} are publicly available.",
      "tldr_zh": "本研究针对大语言模型 (LLMs) 在低资源语言翻译上的不足，通过对 LLaMA 系列模型进行广泛的多语言持续预训练，开发了 LLaMAX，以支持超过 100 种语言的翻译能力。作者通过词汇扩展和数据增强等策略优化训练过程，确保 LLaMAX 在不牺牲泛化能力的情况下，比现有开源 LLMs 高出超过 10 spBLEU 点，并在 Flores-101 基准上与专业翻译模型 M2M-100-12B 性能相当。实验结果表明，LLaMAX 可作为强大的多语言基础模型，并已开源其代码和模型。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "EMNLP 2024 findings",
      "pdf_url": "http://arxiv.org/pdf/2407.05975v2",
      "published_date": "2024-07-08 14:18:28 UTC",
      "updated_date": "2024-10-12 03:20:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:35:27.206734"
    },
    {
      "arxiv_id": "2407.05965v3",
      "title": "T2VSafetyBench: Evaluating the Safety of Text-to-Video Generative Models",
      "title_zh": "T2VSafetyBench：评估文本到视频生成模型的安全性",
      "authors": [
        "Yibo Miao",
        "Yifan Zhu",
        "Yinpeng Dong",
        "Lijia Yu",
        "Jun Zhu",
        "Xiao-Shan Gao"
      ],
      "abstract": "The recent development of Sora leads to a new era in text-to-video (T2V)\ngeneration. Along with this comes the rising concern about its security risks.\nThe generated videos may contain illegal or unethical content, and there is a\nlack of comprehensive quantitative understanding of their safety, posing a\nchallenge to their reliability and practical deployment. Previous evaluations\nprimarily focus on the quality of video generation. While some evaluations of\ntext-to-image models have considered safety, they cover fewer aspects and do\nnot address the unique temporal risk inherent in video generation. To bridge\nthis research gap, we introduce T2VSafetyBench, a new benchmark designed for\nconducting safety-critical assessments of text-to-video models. We define 12\ncritical aspects of video generation safety and construct a malicious prompt\ndataset including real-world prompts, LLM-generated prompts and jailbreak\nattack-based prompts. Based on our evaluation results, we draw several\nimportant findings, including: 1) no single model excels in all aspects, with\ndifferent models showing various strengths; 2) the correlation between GPT-4\nassessments and manual reviews is generally high; 3) there is a trade-off\nbetween the usability and safety of text-to-video generative models. This\nindicates that as the field of video generation rapidly advances, safety risks\nare set to surge, highlighting the urgency of prioritizing video safety. We\nhope that T2VSafetyBench can provide insights for better understanding the\nsafety of video generation in the era of generative AI.",
      "tldr_zh": "该论文引入 T2VSafetyBench，这是一个新的基准，用于评估 Text-to-Video (T2V) 生成模型的安全性，以应对如 Sora 模型可能产生的非法或不道德内容风险。基准定义了 12 个关键安全方面，并构建了一个恶意提示数据集，包括真实提示、LLM 生成提示和越狱攻击提示。评估结果显示，没有单一模型在所有方面表现出色，不同模型有各自优势，且 GPT-4 评估与人工审查的相关性较高，同时 T2V 模型在可用性和安全性之间存在权衡。该基准强调了视频生成领域快速发展的背景下，安全风险的紧迫性，并为提升生成 AI 的可靠性提供重要洞见。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.CR",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.05965v3",
      "published_date": "2024-07-08 14:04:58 UTC",
      "updated_date": "2024-09-08 16:19:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:35:39.120886"
    },
    {
      "arxiv_id": "2407.05963v2",
      "title": "6GSoft: Software for Edge-to-Cloud Continuum",
      "title_zh": "翻译失败",
      "authors": [
        "Muhammad Azeem Akbar",
        "Matteo Esposito",
        "Sami Hyrynsalmi",
        "Karthikeyan Dinesh Kumar",
        "Valentina Lenarduzzi",
        "Xiaozhou Li",
        "Ali Mehraj",
        "Tommi Mikkonen",
        "Sergio Moreschini",
        "Niko Mäkitalo",
        "Markku Oivo",
        "Anna-Sofia Paavonen",
        "Risha Parveen",
        "Kari Smolander",
        "Ruoyu Su",
        "Kari Systä",
        "Davide Taibi",
        "Nan Yang",
        "Zheying Zhang",
        "Muhammad Zohaib"
      ],
      "abstract": "In the era of 6G, developing and managing software requires cutting-edge\nsoftware engineering (SE) theories and practices tailored for such complexity\nacross a vast number of connected edge devices. Our project aims to lead the\ndevelopment of sustainable methods and energy-efficient orchestration models\nspecifically for edge environments, enhancing architectural support driven by\nAI for contemporary edge-to-cloud continuum computing. This initiative seeks to\nposition Finland at the forefront of the 6G landscape, focusing on\nsophisticated edge orchestration and robust software architectures to optimize\nthe performance and scalability of edge networks. Collaborating with leading\nFinnish universities and companies, the project emphasizes deep\nindustry-academia collaboration and international expertise to address critical\nchallenges in edge orchestration and software architecture, aiming to drive\nsignificant advancements in software productivity and market impact.",
      "tldr_zh": "本论文介绍了 6GSoft，这是一个针对 6G 时代复杂边际设备的软件框架，旨在通过先进的软件工程 (SE) 理论和实践开发可持续方法及节能编排模型。项目重点增强 AI 驱动的架构支持，以优化边际到云端连续体 (edge-to-cloud continuum) 的性能和可扩展性，同时通过芬兰大学和公司间的深度合作解决关键挑战。最终目标是将芬兰置于 6G 领先地位，推动软件生产力提升和市场影响力。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.NI",
        "cs.SI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.05963v2",
      "published_date": "2024-07-08 14:03:17 UTC",
      "updated_date": "2024-07-09 04:12:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:35:50.078940"
    },
    {
      "arxiv_id": "2407.11048v1",
      "title": "Magnitude and Rotation Invariant Detection of Transportation Modes with Missing Data Modalities",
      "title_zh": "翻译失败",
      "authors": [
        "Jeroen Van Der Donckt",
        "Jonas Van Der Donckt",
        "Sofie Van Hoecke"
      ],
      "abstract": "This work presents the solution of the Signal Sleuths team for the 2024 SHL\nrecognition challenge. The challenge involves detecting transportation modes\nusing shuffled, non-overlapping 5-second windows of phone movement data, with\nexactly one of the three available modalities (accelerometer, gyroscope,\nmagnetometer) randomly missing. Data analysis indicated a significant\ndistribution shift between train and validation data, necessitating a magnitude\nand rotation-invariant approach. We utilize traditional machine learning,\nfocusing on robust processing, feature extraction, and rotation-invariant\naggregation. An ablation study showed that relying solely on the frequently\nused signal magnitude vector results in the poorest performance. Conversely,\nour proposed rotation-invariant aggregation demonstrated substantial\nimprovement over using rotation-aware features, while also reducing the feature\nvector length. Moreover, z-normalization proved crucial for creating robust\nspectral features.",
      "tldr_zh": "这篇论文介绍了 Signal Sleuths 团队针对 2024 SHL 识别挑战的解决方案，用于检测交通模式，该方法处理了手机运动数据中随机缺失模态（accelerometer、gyroscope 或 magnetometer）的问题，并应对训练和验证数据间的分布偏移。研究采用传统机器学习，强调 magnitude and rotation invariant 的特征提取和聚合技术，以提高鲁棒性。消融研究显示，仅使用 signal magnitude vector 会导致性能最差，而提出的 rotation-invariant aggregation 显著提升了准确率，同时减少了特征向量长度。此外，z-normalization 被证明对创建鲁棒的 spectral features 至关重要。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at HASCA workshop - SHL challenge (UbiComp 2024)",
      "pdf_url": "http://arxiv.org/pdf/2407.11048v1",
      "published_date": "2024-07-08 13:42:01 UTC",
      "updated_date": "2024-07-08 13:42:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:36:02.832079"
    },
    {
      "arxiv_id": "2407.05934v1",
      "title": "Graph Anomaly Detection with Noisy Labels by Reinforcement Learning",
      "title_zh": "基于强化学习的噪声标签图异常检测",
      "authors": [
        "Zhu Wang",
        "Shuang Zhou",
        "Junnan Dong",
        "Chang Yang",
        "Xiao Huang",
        "Shengjie Zhao"
      ],
      "abstract": "Graph anomaly detection (GAD) has been widely applied in many areas, e.g.,\nfraud detection in finance and robot accounts in social networks. Existing\nmethods are dedicated to identifying the outlier nodes that deviate from normal\nones. While they heavily rely on high-quality annotation, which is hard to\nobtain in real-world scenarios, this could lead to severely degraded\nperformance based on noisy labels. Thus, we are motivated to cut the edges of\nsuspicious nodes to alleviate the impact of noise. However, it remains\ndifficult to precisely identify the nodes with noisy labels. Moreover, it is\nhard to quantitatively evaluate the regret of cutting the edges, which may have\neither positive or negative influences. To this end, we propose a novel\nframework REGAD, i.e., REinforced Graph Anomaly Detector. Specifically, we aim\nto maximize the performance improvement (AUC) of a base detector by cutting\nnoisy edges approximated through the nodes with high-confidence labels. (i) We\ndesign a tailored action and search space to train a policy network to\ncarefully prune edges step by step, where only a few suspicious edges are\nprioritized in each step. (ii) We design a policy-in-the-loop mechanism to\niteratively optimize the policy based on the feedback from base detector. The\noverall performance is evaluated by the cumulative rewards. Extensive\nexperiments are conducted on three datasets under different anomaly ratios. The\nresults indicate the superior performance of our proposed REGAD.",
      "tldr_zh": "这篇论文针对图异常检测（Graph Anomaly Detection, GAD）中噪声标签的问题，提出了一种基于强化学习的框架REGAD，以缓解标签噪声对检测性能的影响。REGAD通过训练一个策略网络逐步修剪可疑边，并设计定制的动作空间和策略循环机制，利用基线检测器的反馈（如AUC指标）来迭代优化整体性能。实验结果显示，在三个数据集的不同异常比率下，REGAD显著提升了检测准确率，证明了其有效性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.05934v1",
      "published_date": "2024-07-08 13:41:21 UTC",
      "updated_date": "2024-07-08 13:41:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:36:14.499280"
    },
    {
      "arxiv_id": "2407.12053v1",
      "title": "Improving AlphaFlow for Efficient Protein Ensembles Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Shaoning Li",
        "Mingyu Li",
        "Yusong Wang",
        "Xinheng He",
        "Nanning Zheng",
        "Jian Zhang",
        "Pheng-Ann Heng"
      ],
      "abstract": "Investigating conformational landscapes of proteins is a crucial way to\nunderstand their biological functions and properties. AlphaFlow stands out as a\nsequence-conditioned generative model that introduces flexibility into\nstructure prediction models by fine-tuning AlphaFold under the flow-matching\nframework. Despite the advantages of efficient sampling afforded by\nflow-matching, AlphaFlow still requires multiple runs of AlphaFold to finally\ngenerate one single conformation. Due to the heavy consumption of AlphaFold,\nits applicability is limited in sampling larger set of protein ensembles or the\nlonger chains within a constrained timeframe. In this work, we propose a\nfeature-conditioned generative model called AlphaFlow-Lit to realize efficient\nprotein ensembles generation. In contrast to the full fine-tuning on the entire\nstructure, we focus solely on the light-weight structure module to reconstruct\nthe conformation. AlphaFlow-Lit performs on-par with AlphaFlow and surpasses\nits distilled version without pretraining, all while achieving a significant\nsampling acceleration of around 47 times. The advancement in efficiency\nshowcases the potential of AlphaFlow-Lit in enabling faster and more scalable\ngeneration of protein ensembles.",
      "tldr_zh": "本研究针对AlphaFlow模型在蛋白质构象生成中的计算密集问题，提出了一种改进版本AlphaFlow-Lit，以实现更高效的蛋白质集合生成。AlphaFlow-Lit采用特征条件生成方法，仅对轻量级结构模块进行微调，而非整个AlphaFold结构，从而显著加速采样过程。实验结果显示，AlphaFlow-Lit的性能与AlphaFlow相当，甚至优于其未预训练的蒸馏版本，同时采样速度提高了约47倍。该方法提升了蛋白质集合生成的规模性和可扩展性，有助于更深入理解蛋白质的生物学功能。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "q-bio.QM"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by ICML 2024 AI4Science workshop",
      "pdf_url": "http://arxiv.org/pdf/2407.12053v1",
      "published_date": "2024-07-08 13:36:43 UTC",
      "updated_date": "2024-07-08 13:36:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:36:25.815843"
    },
    {
      "arxiv_id": "2407.05925v1",
      "title": "Towards Optimizing and Evaluating a Retrieval Augmented QA Chatbot using LLMs with Human in the Loop",
      "title_zh": "翻译失败",
      "authors": [
        "Anum Afzal",
        "Alexander Kowsik",
        "Rajna Fani",
        "Florian Matthes"
      ],
      "abstract": "Large Language Models have found application in various mundane and\nrepetitive tasks including Human Resource (HR) support. We worked with the\ndomain experts of SAP SE to develop an HR support chatbot as an efficient and\neffective tool for addressing employee inquiries. We inserted a\nhuman-in-the-loop in various parts of the development cycles such as dataset\ncollection, prompt optimization, and evaluation of generated output. By\nenhancing the LLM-driven chatbot's response quality and exploring alternative\nretrieval methods, we have created an efficient, scalable, and flexible tool\nfor HR professionals to address employee inquiries effectively. Our experiments\nand evaluation conclude that GPT-4 outperforms other models and can overcome\ninconsistencies in data through internal reasoning capabilities. Additionally,\nthrough expert analysis, we infer that reference-free evaluation metrics such\nas G-Eval and Prometheus demonstrate reliability closely aligned with that of\nhuman evaluation.",
      "tldr_zh": "这篇论文探讨了使用大型语言模型（LLMs）优化和评估一个基于检索增强问答（Retrieval Augmented QA）的聊天机器人，特别针对人力资源（HR）支持场景，并引入 Human in the Loop 于数据集收集、提示优化和输出评估过程。通过与 SAP SE 领域专家合作，研究者提升了聊天机器人的响应质量并测试了替代检索方法。实验结果显示，GPT-4 表现最佳，能够通过内部推理能力克服数据不一致性；此外，参考-free 评估指标如 G-Eval 和 Prometheus 与人类评估高度一致，为高效、可扩展的 HR 查询工具提供了可靠基础。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.05925v1",
      "published_date": "2024-07-08 13:32:14 UTC",
      "updated_date": "2024-07-08 13:32:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:36:38.545926"
    },
    {
      "arxiv_id": "2407.05921v2",
      "title": "TAPVid-3D: A Benchmark for Tracking Any Point in 3D",
      "title_zh": "翻译失败",
      "authors": [
        "Skanda Koppula",
        "Ignacio Rocco",
        "Yi Yang",
        "Joe Heyward",
        "João Carreira",
        "Andrew Zisserman",
        "Gabriel Brostow",
        "Carl Doersch"
      ],
      "abstract": "We introduce a new benchmark, TAPVid-3D, for evaluating the task of\nlong-range Tracking Any Point in 3D (TAP-3D). While point tracking in two\ndimensions (TAP) has many benchmarks measuring performance on real-world\nvideos, such as TAPVid-DAVIS, three-dimensional point tracking has none. To\nthis end, leveraging existing footage, we build a new benchmark for 3D point\ntracking featuring 4,000+ real-world videos, composed of three different data\nsources spanning a variety of object types, motion patterns, and indoor and\noutdoor environments. To measure performance on the TAP-3D task, we formulate a\ncollection of metrics that extend the Jaccard-based metric used in TAP to\nhandle the complexities of ambiguous depth scales across models, occlusions,\nand multi-track spatio-temporal smoothness. We manually verify a large sample\nof trajectories to ensure correct video annotations, and assess the current\nstate of the TAP-3D task by constructing competitive baselines using existing\ntracking models. We anticipate this benchmark will serve as a guidepost to\nimprove our ability to understand precise 3D motion and surface deformation\nfrom monocular video. Code for dataset download, generation, and model\nevaluation is available at https://tapvid3d.github.io",
      "tldr_zh": "本研究引入了TAPVid-3D基准，用于评估三维空间中任意点长期跟踪（TAP-3D）任务，目前二维点跟踪已有多个基准，但三维领域尚无类似标准。数据集利用现有视频构建，包含超过4000个真实世界视频，覆盖多种物体类型、运动模式以及室内外环境，并扩展了Jaccard-based metric等指标以处理深度尺度模糊、遮挡和多轨迹时空平滑性问题。研究团队手动验证了大量轨迹，确保注释准确，并通过现有跟踪模型构建竞争性基线，展示了当前任务状态。该基准有望指导未来模型改进，从单目视频中更精确地理解3D运动和表面变形。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.05921v2",
      "published_date": "2024-07-08 13:28:47 UTC",
      "updated_date": "2024-08-27 17:14:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:36:50.294847"
    },
    {
      "arxiv_id": "2407.05910v3",
      "title": "Enhancing Vision-Language Models with Scene Graphs for Traffic Accident Understanding",
      "title_zh": "使用场景图增强视觉语言模型以理解交通事故",
      "authors": [
        "Aaron Lohner",
        "Francesco Compagno",
        "Jonathan Francis",
        "Alessandro Oltramari"
      ],
      "abstract": "Recognizing a traffic accident is an essential part of any autonomous driving\nor road monitoring system. An accident can appear in a wide variety of forms,\nand understanding what type of accident is taking place may be useful to\nprevent it from recurring. This work focuses on classifying traffic scenes into\nspecific accident types. We approach the problem by representing a traffic\nscene as a graph, where objects such as cars can be represented as nodes, and\nrelative distances and directions between them as edges. This representation of\na traffic scene is referred to as a scene graph, and can be used as input for\nan accident classifier. Better results are obtained with a classifier that\nfuses the scene graph input with visual and textual representations. This work\nintroduces a multi-stage, multimodal pipeline that pre-processes videos of\ntraffic accidents, encodes them as scene graphs, and aligns this representation\nwith vision and language modalities before executing the classification task.\nWhen trained on 4 classes, our method achieves a balanced accuracy score of\n57.77% on an (unbalanced) subset of the popular Detection of Traffic Anomaly\n(DoTA) benchmark, representing an increase of close to 5 percentage points from\nthe case where scene graph information is not taken into account.",
      "tldr_zh": "本研究旨在通过引入 scene graphs 来增强视觉语言模型（Vision-Language Models），以更好地理解和分类交通事故场景。研究将交通场景表示为图结构，其中物体（如汽车）作为节点，相对距离和方向作为边，并设计了一个多阶段多模态管道，包括视频预处理、scene graphs 编码，以及与视觉和文本表示的融合，以执行事故分类任务。在 DoTA benchmark 的子集上，针对4类事故，该方法实现了57.77%的balanced accuracy，比不使用scene graphs的基准提高了近5个百分点，展示了其在交通事故识别中的潜在优势。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "Won the 'Best Paper Runner-up Award' at the 2024 IEEE International\n  Automated Vehicle Validation Conference (IAVVC 2024). Also accepted at the\n  1st Workshop on Semantic Reasoning and Goal Understanding in Robotics, at the\n  Robotics Science and Systems Conference (RSS SemRob 2024)",
      "pdf_url": "http://arxiv.org/pdf/2407.05910v3",
      "published_date": "2024-07-08 13:15:11 UTC",
      "updated_date": "2025-01-08 23:40:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:37:01.862348"
    },
    {
      "arxiv_id": "2407.06245v2",
      "title": "ORAN-Bench-13K: An Open Source Benchmark for Assessing LLMs in Open Radio Access Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Pranshav Gajjar",
        "Vijay K. Shah"
      ],
      "abstract": "Large Language Models (LLMs) can revolutionize how we deploy and operate Open\nRadio Access Networks (O-RAN) by enhancing network analytics, anomaly\ndetection, and code generation and significantly increasing the efficiency and\nreliability of a plethora of O-RAN tasks. In this paper, we present\nORAN-Bench-13K, the first comprehensive benchmark designed to evaluate the\nperformance of Large Language Models (LLMs) within the context of O-RAN. Our\nbenchmark consists of 13,952 meticulously curated multiple-choice questions\ngenerated from 116 O-RAN specification documents. We leverage a novel\nthree-stage LLM framework, and the questions are categorized into three\ndistinct difficulties to cover a wide spectrum of ORAN-related knowledge. We\nthoroughly evaluate the performance of several state-of-the-art LLMs, including\nGemini, Chat-GPT, and Mistral. Additionally, we propose ORANSight, a\nRetrieval-Augmented Generation (RAG)-based pipeline that demonstrates superior\nperformance on ORAN-Bench-13K compared to other tested closed-source models.\nOur findings indicate that current popular LLM models are not proficient in\nO-RAN, highlighting the need for specialized models. We observed a noticeable\nperformance improvement when incorporating the RAG-based ORANSight pipeline,\nwith a Macro Accuracy of 0.784 and a Weighted Accuracy of 0.776, which was on\naverage 21.55% and 22.59% better than the other tested LLMs.",
      "tldr_zh": "本研究引入了 ORAN-Bench-13K，这是一个开源基准，用于评估大型语言模型 (LLMs) 在开放无线接入网络 (O-RAN) 中的性能，涵盖网络分析、异常检测和代码生成等任务。基准由 13,952 个从 116 个 O-RAN 规范文档生成的多种难度多选题组成，并采用一个新型的三阶段 LLM 框架来构建问题。研究评估了 Gemini、Chat-GPT 和 Mistral 等先进模型，发现这些 LLMs 在 O-RAN 相关知识上表现不佳。作者提出基于检索增强生成 (RAG) 的 ORANSight 管道，其 Macro Accuracy 达 0.784，比其他模型平均高出 21.55%，显著提升了性能并突显了开发专用模型的必要性。",
      "categories": [
        "cs.NI",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.NI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.06245v2",
      "published_date": "2024-07-08 13:07:50 UTC",
      "updated_date": "2024-07-13 22:48:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:37:15.088077"
    },
    {
      "arxiv_id": "2407.05898v1",
      "title": "Contrastive Learning of Preferences with a Contextual InfoNCE Loss",
      "title_zh": "基于上下文 InfoNCE 损失的偏好对比学习",
      "authors": [
        "Timo Bertram",
        "Johannes Fürnkranz",
        "Martin Müller"
      ],
      "abstract": "A common problem in contextual preference ranking is that a single preferred\naction is compared against several choices, thereby blowing up the complexity\nand skewing the preference distribution. In this work, we show how one can\nsolve this problem via a suitable adaptation of the CLIP framework.This\nadaptation is not entirely straight-forward, because although the InfoNCE loss\nused by CLIP has achieved great success in computer vision and multi-modal\ndomains, its batch-construction technique requires the ability to compare\narbitrary items, and is not well-defined if one item has multiple positive\nassociations in the same batch. We empirically demonstrate the utility of our\nadapted version of the InfoNCE loss in the domain of collectable card games,\nwhere we aim to learn an embedding space that captures the associations between\nsingle cards and whole card pools based on human selections. Such selection\ndata only exists for restricted choices, thus generating concrete preferences\nof one item over a set of other items rather than a perfect fit between the\ncard and the pool.\n  Our results show that vanilla CLIP does not perform well due to the\naforementioned intuitive issues. However, by adapting CLIP to the problem, we\nreceive a model outperforming previous work trained with the triplet loss,\nwhile also alleviating problems associated with mining triplets.",
      "tldr_zh": "这篇论文提出了一种基于上下文 InfoNCE 损失的对比学习方法，用于解决偏好排名问题，其中一个首选动作与多个选择比较导致的复杂度增加和分布倾斜。作者适应了 CLIP 框架的 InfoNCE 损失，通过修改其批量构造技术来处理一个项目有多个正关联的场景，确保在限制选择数据下有效捕捉偏好。实验结果显示，该适应版本在收藏卡牌游戏领域 outperform 了使用 Triplet Loss 的先前模型，同时缓解了三元组挖掘的相关问题。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.05898v1",
      "published_date": "2024-07-08 13:05:08 UTC",
      "updated_date": "2024-07-08 13:05:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:37:27.497711"
    },
    {
      "arxiv_id": "2407.05892v2",
      "title": "An efficient method to automate tooth identification and 3D bounding box extraction from Cone Beam CT Images",
      "title_zh": "翻译失败",
      "authors": [
        "Ignacio Garrido Botella",
        "Ignacio Arranz Águeda",
        "Juan Carlos Armenteros Carmona",
        "Oleg Vorontsov",
        "Fernando Bayón Robledo",
        "Evgeny Solovykh",
        "Obrubov Aleksandr Andreevich",
        "Adrián Alonso Barriuso"
      ],
      "abstract": "Accurate identification, localization, and segregation of teeth from Cone\nBeam Computed Tomography (CBCT) images are essential for analyzing dental\npathologies. Modeling an individual tooth can be challenging and intricate to\naccomplish, especially when fillings and other restorations introduce\nartifacts. This paper proposes a method for automatically detecting,\nidentifying, and extracting teeth from CBCT images. Our approach involves\ndividing the three-dimensional images into axial slices for image detection.\nTeeth are pinpointed and labeled using a single-stage object detector.\nSubsequently, bounding boxes are delineated and identified to create\nthree-dimensional representations of each tooth. The proposed solution has been\nsuccessfully integrated into the dental analysis tool Dentomo.",
      "tldr_zh": "该论文提出了一种高效方法，用于从 Cone Beam CT (CBCT) 图像中自动识别牙齿并提取 3D bounding box，以辅助牙科病理分析。该方法首先将三维 CBCT 图像分成轴向切片，然后使用单阶段 object detector 定位和标记牙齿。随后，通过绘制边界框来生成每个牙齿的 3D 表示，从而处理填充物和修复物引起的伪像。该方案已成功集成到牙科分析工具 Dentomo 中，提升了牙齿建模的准确性和效率。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "7 pages, 6 figures, 4 tables",
      "pdf_url": "http://arxiv.org/pdf/2407.05892v2",
      "published_date": "2024-07-08 12:59:28 UTC",
      "updated_date": "2024-07-10 09:44:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:37:39.887200"
    },
    {
      "arxiv_id": "2407.05887v1",
      "title": "Generation and De-Identification of Indian Clinical Discharge Summaries using LLMs",
      "title_zh": "使用 LLMs 生成",
      "authors": [
        "Sanjeet Singh",
        "Shreya Gupta",
        "Niralee Gupta",
        "Naimish Sharma",
        "Lokesh Srivastava",
        "Vibhu Agarwal",
        "Ashutosh Modi"
      ],
      "abstract": "The consequences of a healthcare data breach can be devastating for the\npatients, providers, and payers. The average financial impact of a data breach\nin recent months has been estimated to be close to USD 10 million. This is\nespecially significant for healthcare organizations in India that are managing\nrapid digitization while still establishing data governance procedures that\nalign with the letter and spirit of the law. Computer-based systems for\nde-identification of personal information are vulnerable to data drift, often\nrendering them ineffective in cross-institution settings. Therefore, a rigorous\nassessment of existing de-identification against local health datasets is\nimperative to support the safe adoption of digital health initiatives in India.\nUsing a small set of de-identified patient discharge summaries provided by an\nIndian healthcare institution, in this paper, we report the nominal performance\nof de-identification algorithms (based on language models) trained on publicly\navailable non-Indian datasets, pointing towards a lack of cross-institutional\ngeneralization. Similarly, experimentation with off-the-shelf de-identification\nsystems reveals potential risks associated with the approach. To overcome data\nscarcity, we explore generating synthetic clinical reports (using publicly\navailable and Indian summaries) by performing in-context learning over Large\nLanguage Models (LLMs). Our experiments demonstrate the use of generated\nreports as an effective strategy for creating high-performing de-identification\nsystems with good generalization capabilities.",
      "tldr_zh": "这篇论文探讨了使用 Large Language Models (LLMs) 生成和去标识化印度临床出院总结的问题，强调了医疗数据泄露的严重财务风险，特别是现有去标识化算法在跨机构设置中的数据漂移问题和泛化能力不足。作者评估了基于非印度公共数据集训练的语言模型算法，发现其在印度本地数据集上的表现不佳，并指出了现成系统的潜在风险。为了克服数据稀缺，论文提出通过 in-context learning 在 LLMs 上生成合成临床报告的方法。实验结果证明，这种策略能有效创建高性能的去标识化系统，具有良好的泛化能力，从而支持印度的数字健康举措。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted at BioNLP Workshop at ACL 2024; 21 pages (9 pages main\n  content)",
      "pdf_url": "http://arxiv.org/pdf/2407.05887v1",
      "published_date": "2024-07-08 12:47:03 UTC",
      "updated_date": "2024-07-08 12:47:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:37:52.600095"
    },
    {
      "arxiv_id": "2407.05884v1",
      "title": "One system for learning and remembering episodes and rules",
      "title_zh": "一个用于学习和记忆事件与规则的系统",
      "authors": [
        "Joshua T. S. Hewson",
        "Sabina J. Sloman",
        "Marina Dubova"
      ],
      "abstract": "Humans can learn individual episodes and generalizable rules and also\nsuccessfully retain both kinds of acquired knowledge over time. In the\ncognitive science literature, (1) learning individual episodes and rules and\n(2) learning and remembering are often both conceptualized as competing\nprocesses that necessitate separate, complementary learning systems. Inspired\nby recent research in statistical learning, we challenge these trade-offs,\nhypothesizing that they arise from capacity limitations rather than from the\ninherent incompatibility of the underlying cognitive processes. Using an\nassociative learning task, we show that one system with excess representational\ncapacity can learn and remember both episodes and rules.",
      "tldr_zh": "本论文挑战认知科学中传统观点，即学习和记忆个体事件（episodes）和可泛化规则（rules）是竞争过程，需要分离的系统。作者假设这种权衡源于容量限制而非认知过程的固有不兼容性，受统计学习研究启发。实验通过一个关联学习任务（associative learning task）证明，一个具有足够表示容量（representational capacity）的单一系统能够同时学习和记忆episodes与rules。",
      "categories": [
        "cs.AI",
        "cs.NE"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.05884v1",
      "published_date": "2024-07-08 12:44:18 UTC",
      "updated_date": "2024-07-08 12:44:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:38:13.642895"
    },
    {
      "arxiv_id": "2407.05879v1",
      "title": "Learning With Generalised Card Representations for \"Magic: The Gathering\"",
      "title_zh": "翻译失败",
      "authors": [
        "Timo Bertram",
        "Johannes Fürnkranz",
        "Martin Müller"
      ],
      "abstract": "A defining feature of collectable card games is the deck building process\nprior to actual gameplay, in which players form their decks according to some\nrestrictions. Learning to build decks is difficult for players and models alike\ndue to the large card variety and highly complex semantics, as well as\nrequiring meaningful card and deck representations when aiming to utilise AI.\nIn addition, regular releases of new card sets lead to unforeseeable\nfluctuations in the available card pool, thus affecting possible deck\nconfigurations and requiring continuous updates. Previous Game AI approaches to\nbuilding decks have often been limited to fixed sets of possible cards, which\ngreatly limits their utility in practice. In this work, we explore possible\ncard representations that generalise to unseen cards, thus greatly extending\nthe real-world utility of AI-based deck building for the game \"Magic: The\nGathering\".We study such representations based on numerical, nominal, and\ntext-based features of cards, card images, and meta information about card\nusage from third-party services. Our results show that while the particular\nchoice of generalised input representation has little effect on learning to\npredict human card selections among known cards, the performance on new, unseen\ncards can be greatly improved. Our generalised model is able to predict 55\\% of\nhuman choices on completely unseen cards, thus showing a deep understanding of\ncard quality and strategy.",
      "tldr_zh": "本文针对“Magic: The Gathering”游戏，探讨了泛化卡牌表示方法，以解决AI在甲板构建（deck building）中的挑战，该过程因卡牌多样性和语义复杂性而难以学习，且新卡集发布会影响可用卡池。研究者使用了基于数值、名义、文本特征、卡牌图像以及元信息的表示方式，训练模型以泛化到未见卡牌。结果表明，该模型在预测人类对未见卡牌的选择时准确率达55%，展示了AI对卡牌质量和策略的深刻理解，并显著提升了AI在实际游戏中的实用性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Best paper award nominee at IEEE Conference on Games 2024",
      "pdf_url": "http://arxiv.org/pdf/2407.05879v1",
      "published_date": "2024-07-08 12:42:44 UTC",
      "updated_date": "2024-07-08 12:42:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:38:17.040623"
    },
    {
      "arxiv_id": "2407.05876v1",
      "title": "Efficiently Training Neural Networks for Imperfect Information Games by Sampling Information Sets",
      "title_zh": "翻译失败",
      "authors": [
        "Timo Bertram",
        "Johannes Fürnkranz",
        "Martin Müller"
      ],
      "abstract": "In imperfect information games, the evaluation of a game state not only\ndepends on the observable world but also relies on hidden parts of the\nenvironment. As accessing the obstructed information trivialises state\nevaluations, one approach to tackle such problems is to estimate the value of\nthe imperfect state as a combination of all states in the information set,\ni.e., all possible states that are consistent with the current imperfect\ninformation. In this work, the goal is to learn a function that maps from the\nimperfect game information state to its expected value. However, constructing a\nperfect training set, i.e. an enumeration of the whole information set for\nnumerous imperfect states, is often infeasible. To compute the expected values\nfor an imperfect information game like \\textit{Reconnaissance Blind Chess}, one\nwould need to evaluate thousands of chess positions just to obtain the training\ntarget for a single state. Still, the expected value of a state can already be\napproximated with appropriate accuracy from a much smaller set of evaluations.\nThus, in this paper, we empirically investigate how a budget of perfect\ninformation game evaluations should be distributed among training samples to\nmaximise the return. Our results show that sampling a small number of states,\nin our experiments roughly 3, for a larger number of separate positions is\npreferable over repeatedly sampling a smaller quantity of states. Thus, we find\nthat in our case, the quantity of different samples seems to be more important\nthan higher target quality.",
      "tldr_zh": "本研究针对不完美信息游戏（imperfect information games）中评估状态的挑战，提出了一种通过采样信息集（information sets）来高效训练神经网络的方法，以估计状态的期望值，而非枚举整个信息集，从而避免高计算开销。作者通过实验探索了评估预算的分配策略，发现为更多独立位置采样少量状态（约3个）比为较少位置采样更多状态更有效，这提高了训练效率。结果表明，这种采样方法在游戏如Reconnaissance Blind Chess中，能最大化回报，并强调样本数量比每个样本的质量更重要。",
      "categories": [
        "cs.AI",
        "cs.GT",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "KI 2024 - 47th German Conference on Artificial Intelligence",
      "pdf_url": "http://arxiv.org/pdf/2407.05876v1",
      "published_date": "2024-07-08 12:37:07 UTC",
      "updated_date": "2024-07-08 12:37:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:38:27.197002"
    },
    {
      "arxiv_id": "2407.11046v4",
      "title": "A Survey on LoRA of Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Yuren Mao",
        "Yuhang Ge",
        "Yijiang Fan",
        "Wenyi Xu",
        "Yu Mi",
        "Zhonghao Hu",
        "Yunjun Gao"
      ],
      "abstract": "Low-Rank Adaptation~(LoRA), which updates the dense neural network layers\nwith pluggable low-rank matrices, is one of the best performed parameter\nefficient fine-tuning paradigms. Furthermore, it has significant advantages in\ncross-task generalization and privacy-preserving. Hence, LoRA has gained much\nattention recently, and the number of related literature demonstrates\nexponential growth. It is necessary to conduct a comprehensive overview of the\ncurrent progress on LoRA. This survey categorizes and reviews the progress from\nthe perspectives of (1) downstream adaptation improving variants that improve\nLoRA's performance on downstream tasks; (2) cross-task generalization methods\nthat mix multiple LoRA plugins to achieve cross-task generalization; (3)\nefficiency-improving methods that boost the computation-efficiency of LoRA; (4)\ndata privacy-preserving methods that use LoRA in federated learning; (5)\napplication. Besides, this survey also discusses the future directions in this\nfield. At last, we provide a Github\npage~\\footnote{\\href{https://github.com/ZJU-LLMs/Awesome-LoRAs.git}{https://github.com/ZJU-LLMs/Awesome-LoRAs.git}}\nfor readers to check the updates and initiate discussions on this survey paper.",
      "tldr_zh": "这篇调查论文对LoRA（Low-Rank Adaptation）在大型语言模型中的应用进行了全面综述，强调了LoRA作为高效参数微调方法的优势，包括优秀的性能、跨任务泛化能力以及隐私保护。论文从五个视角分类审视相关进展：（1）下游适配改进变体（downstream adaptation improving variants）；（2）跨任务泛化方法（cross-task generalization methods）；（3）效率改进方法（efficiency-improving methods）；（4）数据隐私保护方法（data privacy-preserving methods）；以及（5）实际应用。研究发现LoRA的相关文献呈指数级增长，并讨论了未来方向，如进一步优化和扩展，同时提供了一个GitHub页面供读者跟踪更新和讨论。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "The article has been accepted by Frontiers of Computer Science (FCS),\n  with the DOI: {10.1007/s11704-024-40663-9}",
      "pdf_url": "http://arxiv.org/pdf/2407.11046v4",
      "published_date": "2024-07-08 12:32:10 UTC",
      "updated_date": "2024-10-24 03:30:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:38:39.717439"
    },
    {
      "arxiv_id": "2407.05869v2",
      "title": "PORCA: Root Cause Analysis with Partially Observed Data",
      "title_zh": "PORCA: 部分观察数据的根因分析",
      "authors": [
        "Chang Gong",
        "Di Yao",
        "Jin Wang",
        "Wenbin Li",
        "Lanting Fang",
        "Yongtao Xie",
        "Kaiyu Feng",
        "Peng Han",
        "Jingping Bi"
      ],
      "abstract": "Root Cause Analysis (RCA) aims at identifying the underlying causes of system\nfaults by uncovering and analyzing the causal structure from complex systems.\nIt has been widely used in many application domains. Reliable diagnostic\nconclusions are of great importance in mitigating system failures and financial\nlosses. However, previous studies implicitly assume a full observation of the\nsystem, which neglect the effect of partial observation (i.e., missing nodes\nand latent malfunction). As a result, they fail in deriving reliable RCA\nresults. In this paper, we unveil the issues of unobserved confounders and\nheterogeneity in partial observation and come up with a new problem of root\ncause analysis with partially observed data. To achieve this, we propose PORCA,\na novel RCA framework which can explore reliable root causes under both\nunobserved confounders and unobserved heterogeneity. PORCA leverages magnified\nscore-based causal discovery to efficiently optimize acyclic directed mixed\ngraph under unobserved confounders. In addition, we also develop a\nheterogeneity-aware scheduling strategy to provide adaptive sample weights.\nExtensive experimental results on one synthetic and two real-world datasets\ndemonstrate the effectiveness and superiority of the proposed framework.",
      "tldr_zh": "本研究针对 Root Cause Analysis (RCA) 在部分观察数据下的挑战，揭示了未观察到的混杂因素(unobserved confounders)和异质性(heterogeneity)导致的不可靠诊断问题，提出了一种新的 RCA 问题框架。PORCA 框架通过 magnified score-based causal discovery 优化无环有向混合图(acyclic directed mixed graph)来处理未观察到的混杂因素，并引入 heterogeneity-aware scheduling strategy 提供自适应样本权重，从而实现更可靠的根因分析。实验结果在合成数据集和两个真实世界数据集上证明了 PORCA 的有效性和优越性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.05869v2",
      "published_date": "2024-07-08 12:31:12 UTC",
      "updated_date": "2024-07-12 01:28:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:38:53.480625"
    },
    {
      "arxiv_id": "2407.05868v2",
      "title": "KG-FPQ: Evaluating Factuality Hallucination in LLMs with Knowledge Graph-based False Premise Questions",
      "title_zh": "翻译失败",
      "authors": [
        "Yanxu Zhu",
        "Jinlin Xiao",
        "Yuhang Wang",
        "Jitao Sang"
      ],
      "abstract": "Recent studies have demonstrated that large language models (LLMs) are\nsusceptible to being misled by false premise questions (FPQs), leading to\nerrors in factual knowledge, know as factuality hallucination. Existing\nbenchmarks that assess this vulnerability primarily rely on manual\nconstruction, resulting in limited scale and lack of scalability. In this work,\nwe introduce an automated, scalable pipeline to create FPQs based on knowledge\ngraphs (KGs). The first step is modifying true triplets extracted from KGs to\ncreate false premises. Subsequently, utilizing the state-of-the-art\ncapabilities of GPTs, we generate semantically rich FPQs. Based on the proposed\nmethod, we present a comprehensive benchmark, the Knowledge Graph-based False\nPremise Questions (KG-FPQ), which contains approximately 178k FPQs across three\nknowledge domains, at six levels of confusability, and in two task formats.\nUsing KG-FPQ, we conduct extensive evaluations on several representative LLMs\nand provide valuable insights. The KG-FPQ dataset and code are available\nat~https://github.com/yanxuzhu/KG-FPQ.",
      "tldr_zh": "本研究探讨了大型语言模型（LLMs）在面对虚假前提问题（FPQs）时容易产生的factuality hallucination问题，并指出现有基准依赖手动构建，规模有限。该团队提出了一种基于知识图谱（KGs）的自动化管道，首先修改KGs中的真实三元组创建虚假前提，然后利用GPT生成语义丰富的FPQs，从而构建了KG-FPQ基准数据集，包含约178k个问题，覆盖三个知识领域、六级混淆度和两种任务格式。通过KG-FPQ对多个代表性LLMs进行评估，该研究提供了宝贵的见解，并公开了数据集和代码以促进进一步研究。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "COLING2025 main",
      "pdf_url": "http://arxiv.org/pdf/2407.05868v2",
      "published_date": "2024-07-08 12:31:03 UTC",
      "updated_date": "2024-12-22 07:28:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:39:14.297293"
    },
    {
      "arxiv_id": "2407.05864v1",
      "title": "Neural Network-based Information Set Weighting for Playing Reconnaissance Blind Chess",
      "title_zh": "翻译失败",
      "authors": [
        "Timo Bertram",
        "Johannes Fürnkranz",
        "Martin Müller"
      ],
      "abstract": "In imperfect information games, the game state is generally not fully\nobservable to players. Therefore, good gameplay requires policies that deal\nwith the different information that is hidden from each player. To combat this,\neffective algorithms often reason about information sets; the sets of all\npossible game states that are consistent with a player's observations. While\nthere is no way to distinguish between the states within an information set,\nthis property does not imply that all states are equally likely to occur in\nplay. We extend previous research on assigning weights to the states in an\ninformation set in order to facilitate better gameplay in the imperfect\ninformation game of Reconnaissance Blind Chess. For this, we train two\ndifferent neural networks which estimate the likelihood of each state in an\ninformation set from historical game data. Experimentally, we find that a\nSiamese neural network is able to achieve higher accuracy and is more efficient\nthan a classical convolutional neural network for the given domain. Finally, we\nevaluate an RBC-playing agent that is based on the generated weightings and\ncompare different parameter settings that influence how strongly it should rely\non them. The resulting best player is ranked 5th on the public leaderboard.",
      "tldr_zh": "这篇论文针对不完美信息游戏（imperfect information games）提出了一种基于神经网络（neural networks）的信息集权重分配方法，以提升 Reconnaissance Blind Chess (RBC) 游戏的表现。研究训练了两个神经网络模型，包括 Siamese neural network 和 convolutional neural network，使用历史游戏数据估计信息集（information sets）中各状态的概率；实验结果显示，Siamese neural network 在准确性和效率上更胜一筹。最终，基于这些权重的 RBC 玩家代理在不同参数设置下优化后，在公开排行榜上排名第5，展示了该方法的实际价值。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "Extended version of IEEE Conference on Games 2023 paper",
      "pdf_url": "http://arxiv.org/pdf/2407.05864v1",
      "published_date": "2024-07-08 12:29:29 UTC",
      "updated_date": "2024-07-08 12:29:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:39:16.223949"
    },
    {
      "arxiv_id": "2407.05858v2",
      "title": "Fast On-device LLM Inference with NPUs",
      "title_zh": "翻译失败",
      "authors": [
        "Daliang Xu",
        "Hao Zhang",
        "Liming Yang",
        "Ruiqi Liu",
        "Gang Huang",
        "Mengwei Xu",
        "Xuanzhe Liu"
      ],
      "abstract": "On-device inference for Large Language Models (LLMs), driven by increasing\nprivacy concerns and advancements of mobile-sized models, has gained\nsignificant interest. However, even mobile-sized LLMs (e.g., Gemma-2B)\nencounter unacceptably high inference latency, often bottlenecked by the\nprefill stage in tasks like screen UI understanding.\n  We present llm.npu, the first LLM inference system utilizing on-device Neural\nProcessing Unit (NPU) offloading to reduce prefill latency. llm.npu enhances\nNPU offloading efficiency by re-constructing the prompt and model in three\nlevels: (1) At prompt level, it divides variable-length prompts into multiple\nfixed-sized chunks while maintaining data dependencies; (2) At tensor level, it\nidentifies and extracts significant outliers to run on the CPU/GPU in parallel\nwith minimal overhead; (3) At block level, it schedules Transformer blocks in\nan out-of-order manner to the CPU/GPU and NPU based on their hardware affinity\nand sensitivity to accuracy. Compared to competitive baselines, llm.npu\nachieves 22.4x faster prefill speed and 30.7$\\times$ energy savings on average,\nand up to 32.8x speedup in an end-to-end real-world application. For the first\ntime, llm.npu achieves more than 1,000 tokens/sec prefilling for a\nbillion-sized model.",
      "tldr_zh": "本文提出 llm.npu 系统，这是首个利用 on-device Neural Processing Unit (NPU) 来加速 Large Language Models (LLMs) 推理的框架，针对移动设备上预填充阶段（如屏幕 UI 理解）的延迟瓶颈问题。系统通过三个级别优化 NPU 卸载效率：(1) 在提示级别，将可变长提示分成固定大小块并保持数据依赖；(2) 在张量级别，识别并提取重要异常值在 CPU/GPU 上并行运行；(3) 在块级别，以乱序方式调度 Transformer 块根据硬件亲和性和准确性敏感度。实验结果显示，llm.npu 平均实现 22.4 倍预填充速度提升和 30.7 倍能源节省，并在端到端实际应用中最高达到 32.8 倍加速，首次使十亿级模型的预填充速度超过 1,000 tokens/sec。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.05858v2",
      "published_date": "2024-07-08 12:20:45 UTC",
      "updated_date": "2024-12-15 15:26:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:39:31.692021"
    },
    {
      "arxiv_id": "2407.05817v1",
      "title": "Cyber Physical Games",
      "title_zh": "翻译失败",
      "authors": [
        "Warisa Sritriratanarak",
        "Paulo Garcia"
      ],
      "abstract": "We describe a formulation of multi-agents operating within a Cyber-Physical\nSystem, resulting in collaborative or adversarial games. We show that the\nnon-determinism inherent in the communication medium between agents and the\nunderlying physical environment gives rise to environment evolution that is a\nprobabilistic function of agents' strategies. We name these emergent properties\nCyber Physical Games and study its properties. We present an algorithmic model\nthat determines the most likely system evolution, approximating Cyber Physical\nGames through Probabilistic Finite State Automata, and evaluate it on\ncollaborative and adversarial versions of the Iterated Boolean Game, comparing\ntheoretical results with simulated ones. Results support the validity of the\nproposed model, and suggest several required research directions to continue\nevolving our understanding of Cyber Physical System, as well as how to best\ndesign agents that must operate within such environments.",
      "tldr_zh": "该论文引入了 Cyber Physical Games 概念，描述多智能体在 Cyber-Physical System 中的协作或对抗互动，由于通信介质和物理环境的非确定性，导致系统演化成为智能体策略的概率函数。研究者提出一个算法模型，使用 Probabilistic Finite State Automata 来近似这些游戏，并计算系统最可能的演化路径。实验在协作和对抗版本的 Iterated Boolean Game 上验证了模型的有效性，将理论结果与模拟结果比较，并建议进一步探索 Cyber Physical System 的设计和智能体优化方向。",
      "categories": [
        "cs.DC",
        "cs.AI"
      ],
      "primary_category": "cs.DC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.05817v1",
      "published_date": "2024-07-08 10:54:14 UTC",
      "updated_date": "2024-07-08 10:54:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:39:39.600788"
    },
    {
      "arxiv_id": "2407.05816v1",
      "title": "Graph Reasoning Networks",
      "title_zh": "图推理网络",
      "authors": [
        "Markus Zopf",
        "Francesco Alesiani"
      ],
      "abstract": "Graph neural networks (GNNs) are the predominant approach for graph-based\nmachine learning. While neural networks have shown great performance at\nlearning useful representations, they are often criticized for their limited\nhigh-level reasoning abilities. In this work, we present Graph Reasoning\nNetworks (GRNs), a novel approach to combine the strengths of fixed and learned\ngraph representations and a reasoning module based on a differentiable\nsatisfiability solver. While results on real-world datasets show comparable\nperformance to GNN, experiments on synthetic datasets demonstrate the potential\nof the newly proposed method.",
      "tldr_zh": "该论文提出 Graph Reasoning Networks (GRNs)，一种新方法结合固定和学习图表示，并引入基于可微分可满足性求解器的推理模块，以弥补 Graph Neural Networks (GNNs) 在高级推理能力上的不足。GRNs 通过整合这些组件，提升了图-based 机器学习的表示和推理性能。在实验中，GRNs 在真实数据集上与 GNNs 表现相当，而在合成数据集上展示了显著潜力。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Presented at the workshop on graphs and more complex structures for\n  learning and reasoning at AAAI 2022",
      "pdf_url": "http://arxiv.org/pdf/2407.05816v1",
      "published_date": "2024-07-08 10:53:49 UTC",
      "updated_date": "2024-07-08 10:53:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:39:54.732387"
    },
    {
      "arxiv_id": "2407.05814v1",
      "title": "Cross-domain Few-shot In-context Learning for Enhancing Traffic Sign Recognition",
      "title_zh": "翻译失败",
      "authors": [
        "Yaozong Gan",
        "Guang Li",
        "Ren Togo",
        "Keisuke Maeda",
        "Takahiro Ogawa",
        "Miki Haseyama"
      ],
      "abstract": "Recent multimodal large language models (MLLM) such as GPT-4o and GPT-4v have\nshown great potential in autonomous driving. In this paper, we propose a\ncross-domain few-shot in-context learning method based on the MLLM for\nenhancing traffic sign recognition (TSR). We first construct a traffic sign\ndetection network based on Vision Transformer Adapter and an extraction module\nto extract traffic signs from the original road images. To reduce the\ndependence on training data and improve the performance stability of\ncross-country TSR, we introduce a cross-domain few-shot in-context learning\nmethod based on the MLLM. To enhance MLLM's fine-grained recognition ability of\ntraffic signs, the proposed method generates corresponding description texts\nusing template traffic signs. These description texts contain key information\nabout the shape, color, and composition of traffic signs, which can stimulate\nthe ability of MLLM to perceive fine-grained traffic sign categories. By using\nthe description texts, our method reduces the cross-domain differences between\ntemplate and real traffic signs. Our approach requires only simple and uniform\ntextual indications, without the need for large-scale traffic sign images and\nlabels. We perform comprehensive evaluations on the German traffic sign\nrecognition benchmark dataset, the Belgium traffic sign dataset, and two\nreal-world datasets taken from Japan. The experimental results show that our\nmethod significantly enhances the TSR performance.",
      "tldr_zh": "本论文提出了一种基于多模态大语言模型 (MLLM) 的跨域少样本上下文学习方法，以提升交通标志识别 (TSR) 的性能稳定性。方法包括构建一个基于 Vision Transformer Adapter 的检测网络和提取模块，从道路图像中提取交通标志，并通过生成描述文本（包含交通标志的形状、颜色和组成信息）来增强 MLLM 的细粒度识别能力，从而减少模板与真实标志之间的跨域差异。该方法无需大量图像和标签，仅依赖简单文本指示，并在德国、比利时和日本的真实数据集上实验，显著提高了 TSR 性能，准确率得到有效提升。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.MM"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.05814v1",
      "published_date": "2024-07-08 10:51:03 UTC",
      "updated_date": "2024-07-08 10:51:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:40:04.759828"
    },
    {
      "arxiv_id": "2407.05810v1",
      "title": "Integrating AI in College Education: Positive yet Mixed Experiences with ChatGPT",
      "title_zh": "翻译失败",
      "authors": [
        "Xinrui Song",
        "Jiajin Zhang",
        "Pingkun Yan",
        "Juergen Hahn",
        "Uwe Kruger",
        "Hisham Mohamed",
        "Ge Wang"
      ],
      "abstract": "The integration of artificial intelligence (AI) chatbots into higher\neducation marks a shift towards a new generation of pedagogical tools,\nmirroring the arrival of milestones like the internet. With the launch of\nChatGPT-4 Turbo in November 2023, we developed a ChatGPT-based teaching\napplication (https://chat.openai.com/g/g-1imx1py4K-chatge-medical-imaging) and\nintegrated it into our undergraduate medical imaging course in the Spring 2024\nsemester. This study investigates the use of ChatGPT throughout a semester-long\ntrial, providing insights into students' engagement, perception, and the\noverall educational effectiveness of the technology. We systematically\ncollected and analyzed data concerning students' interaction with ChatGPT,\nfocusing on their attitudes, concerns, and usage patterns. The findings\nindicate that ChatGPT offers significant advantages such as improved\ninformation access and increased interactivity, but its adoption is accompanied\nby concerns about the accuracy of the information provided and the necessity\nfor well-defined guidelines to optimize its use.",
      "tldr_zh": "本研究探讨了将AI聊天机器人ChatGPT整合到高等教育中的应用，特别通过在2024春季学期开发并部署一个基于ChatGPT-4 Turbo的教学应用于本科医学成像课程，系统分析了学生的互动模式、态度和使用情况。结果显示，ChatGPT显著提升了信息访问和互动性等教育优势，但也伴随信息准确性问题和潜在担忧。总体而言，该研究为AI在教育中的有效整合提供了宝贵见解，并强调了制定明确使用指南的必要性。",
      "categories": [
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.05810v1",
      "published_date": "2024-07-08 10:44:34 UTC",
      "updated_date": "2024-07-08 10:44:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:40:16.161877"
    },
    {
      "arxiv_id": "2407.05800v1",
      "title": "FedMRL: Data Heterogeneity Aware Federated Multi-agent Deep Reinforcement Learning for Medical Imaging",
      "title_zh": "翻译失败",
      "authors": [
        "Pranab Sahoo",
        "Ashutosh Tripathi",
        "Sriparna Saha",
        "Samrat Mondal"
      ],
      "abstract": "Despite recent advancements in federated learning (FL) for medical image\ndiagnosis, addressing data heterogeneity among clients remains a significant\nchallenge for practical implementation. A primary hurdle in FL arises from the\nnon-IID nature of data samples across clients, which typically results in a\ndecline in the performance of the aggregated global model. In this study, we\nintroduce FedMRL, a novel federated multi-agent deep reinforcement learning\nframework designed to address data heterogeneity. FedMRL incorporates a novel\nloss function to facilitate fairness among clients, preventing bias in the\nfinal global model. Additionally, it employs a multi-agent reinforcement\nlearning (MARL) approach to calculate the proximal term $(\\mu)$ for the\npersonalized local objective function, ensuring convergence to the global\noptimum. Furthermore, FedMRL integrates an adaptive weight adjustment method\nusing a Self-organizing map (SOM) on the server side to counteract distribution\nshifts among clients' local data distributions. We assess our approach using\ntwo publicly available real-world medical datasets, and the results demonstrate\nthat FedMRL significantly outperforms state-of-the-art techniques, showing its\nefficacy in addressing data heterogeneity in federated learning. The code can\nbe found here~{\\url{https://github.com/Pranabiitp/FedMRL}}.",
      "tldr_zh": "该研究提出 FedMRL，一种针对数据异质性（data heterogeneity）的联邦多智能体深度强化学习（Federated Multi-agent Deep Reinforcement Learning）框架，用于医疗图像诊断。FedMRL 引入了一个新损失函数以确保客户端公平性，防止全局模型偏置，并利用多智能体强化学习（MARL）计算个性化本地目标函数的近端项（proximal term, μ），从而实现全局最优收敛；同时，整合自组织映射（Self-organizing map, SOM）进行自适应权重调整，以应对数据分布偏移。实验在两个公开的真实医疗数据集上验证，FedMRL 显著优于现有技术，证明其在处理联邦学习数据异质性方面的有效性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV",
        "cs.DC"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted to MICCAI 2024",
      "pdf_url": "http://arxiv.org/pdf/2407.05800v1",
      "published_date": "2024-07-08 10:10:07 UTC",
      "updated_date": "2024-07-08 10:10:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:40:29.417866"
    },
    {
      "arxiv_id": "2407.05789v2",
      "title": "CANDID DAC: Leveraging Coupled Action Dimensions with Importance Differences in DAC",
      "title_zh": "翻译失败",
      "authors": [
        "Philipp Bordne",
        "M. Asif Hasan",
        "Eddie Bergman",
        "Noor Awad",
        "André Biedenkapp"
      ],
      "abstract": "High-dimensional action spaces remain a challenge for dynamic algorithm\nconfiguration (DAC). Interdependencies and varying importance between action\ndimensions are further known key characteristics of DAC problems. We argue that\nthese Coupled Action Dimensions with Importance Differences (CANDID) represent\naspects of the DAC problem that are not yet fully explored. To address this\ngap, we introduce a new white-box benchmark within the DACBench suite that\nsimulates the properties of CANDID. Further, we propose sequential policies as\nan effective strategy for managing these properties. Such policies factorize\nthe action space and mitigate exponential growth by learning a policy per\naction dimension. At the same time, these policies accommodate the\ninterdependence of action dimensions by fostering implicit coordination. We\nshow this in an experimental study of value-based policies on our new\nbenchmark. This study demonstrates that sequential policies significantly\noutperform independent learning of factorized policies in CANDID action spaces.\nIn addition, they overcome the scalability limitations associated with learning\na single policy across all action dimensions. The code used for our experiments\nis available under https://github.com/PhilippBordne/candidDAC.",
      "tldr_zh": "本文探讨了动态算法配置(DAC)中高维动作空间的挑战，特别是Coupled Action Dimensions with Importance Differences (CANDID)的相互依赖性和重要性差异特性。作者引入了一个新的白盒基准于DACBench套件中，以模拟这些属性，并提出sequential policies作为有效策略，该方法通过分解动作空间并为每个动作维度学习一个策略，同时促进隐式协调来处理相互依赖。实验研究显示，sequential policies在CANDID动作空间中显著优于独立学习的分化策略，并克服了学习单一策略的扩展性限制。代码已开源在https://github.com/PhilippBordne/candidDAC。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "5 pages main paper, 11 pages references and appendix, 9 figures, to\n  be published in: Proceedings of the Third International Conference on\n  Automated Machine Learning (AutoML 2024), Workshop Track",
      "pdf_url": "http://arxiv.org/pdf/2407.05789v2",
      "published_date": "2024-07-08 09:51:02 UTC",
      "updated_date": "2024-09-17 09:32:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:40:44.751525"
    },
    {
      "arxiv_id": "2407.05788v1",
      "title": "Automated Computational Energy Minimization of ML Algorithms using Constrained Bayesian Optimization",
      "title_zh": "翻译失败",
      "authors": [
        "Pallavi Mitra",
        "Felix Biessmann"
      ],
      "abstract": "Bayesian optimization (BO) is an efficient framework for optimization of\nblack-box objectives when function evaluations are costly and gradient\ninformation is not easily accessible. BO has been successfully applied to\nautomate the task of hyperparameter optimization (HPO) in machine learning (ML)\nmodels with the primary objective of optimizing predictive performance on\nheld-out data. In recent years, however, with ever-growing model sizes, the\nenergy cost associated with model training has become an important factor for\nML applications. Here we evaluate Constrained Bayesian Optimization (CBO) with\nthe primary objective of minimizing energy consumption and subject to the\nconstraint that the generalization performance is above some threshold. We\nevaluate our approach on regression and classification tasks and demonstrate\nthat CBO achieves lower energy consumption without compromising the predictive\nperformance of ML models.",
      "tldr_zh": "本研究利用 Constrained Bayesian Optimization (CBO) 自动最小化机器学习 (ML) 算法的能量消耗，同时作为约束条件确保模型的泛化性能达到预设阈值。CBO 基于 Bayesian Optimization (BO) 框架，针对黑盒优化问题进行改进，以应对模型训练中日益增长的能量成本问题。在回归和分类任务的实验中，CBO 证明了其有效性，能够显著降低能量消耗而不牺牲预测性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "13 pages",
      "pdf_url": "http://arxiv.org/pdf/2407.05788v1",
      "published_date": "2024-07-08 09:49:38 UTC",
      "updated_date": "2024-07-08 09:49:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:40:53.943231"
    },
    {
      "arxiv_id": "2407.05786v1",
      "title": "Large Language Models for Judicial Entity Extraction: A Comparative Study",
      "title_zh": "大语言模型用于司法实体提取：一项比较研究",
      "authors": [
        "Atin Sakkeer Hussain",
        "Anu Thomas"
      ],
      "abstract": "Domain-specific Entity Recognition holds significant importance in legal\ncontexts, serving as a fundamental task that supports various applications such\nas question-answering systems, text summarization, machine translation,\nsentiment analysis, and information retrieval specifically within case law\ndocuments. Recent advancements have highlighted the efficacy of Large Language\nModels in natural language processing tasks, demonstrating their capability to\naccurately detect and classify domain-specific facts (entities) from\nspecialized texts like clinical and financial documents. This research\ninvestigates the application of Large Language Models in identifying\ndomain-specific entities (e.g., courts, petitioner, judge, lawyer, respondents,\nFIR nos.) within case law documents, with a specific focus on their aptitude\nfor handling domain-specific language complexity and contextual variations. The\nstudy evaluates the performance of state-of-the-art Large Language Model\narchitectures, including Large Language Model Meta AI 3, Mistral, and Gemma, in\nthe context of extracting judicial facts tailored to Indian judicial texts.\nMistral and Gemma emerged as the top-performing models, showcasing balanced\nprecision and recall crucial for accurate entity identification. These findings\nconfirm the value of Large Language Models in judicial documents and\ndemonstrate how they can facilitate and quicken scientific research by\nproducing precise, organised data outputs that are appropriate for in-depth\nexamination.",
      "tldr_zh": "这篇论文比较了大型语言模型（Large Language Models）在司法实体提取（Entity Recognition）中的性能，焦点是识别案例法文档中的领域特定实体（如法院、原告、法官等），以支持法律应用如问答系统和信息检索。研究评估了Llama 3、Mistral和Gemma等模型在处理印度司法文本的复杂语言和上下文时的表现。结果表明，Mistral和Gemma模型表现出色，具有平衡的Precision和Recall，证实了LLM能加速科学研究并提供精确的数据输出。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "I.2.1"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.05786v1",
      "published_date": "2024-07-08 09:49:03 UTC",
      "updated_date": "2024-07-08 09:49:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:41:05.443729"
    },
    {
      "arxiv_id": "2407.05778v1",
      "title": "When is the consistent prediction likely to be a correct prediction?",
      "title_zh": "什么时候一致的预测很可能是一个正确的预测？",
      "authors": [
        "Alex Nguyen",
        "Dheeraj Mekala",
        "Chengyu Dong",
        "Jingbo Shang"
      ],
      "abstract": "Self-consistency (Wang et al., 2023) suggests that the most consistent answer\nobtained through large language models (LLMs) is more likely to be correct. In\nthis paper, we challenge this argument and propose a nuanced correction. Our\nobservations indicate that consistent answers derived through more computation\ni.e. longer reasoning texts, rather than simply the most consistent answer\nacross all outputs, are more likely to be correct. This is predominantly\nbecause we demonstrate that LLMs can autonomously produce chain-of-thought\n(CoT) style reasoning with no custom prompts merely while generating longer\nresponses, which lead to consistent predictions that are more accurate. In the\nzero-shot setting, by sampling Mixtral-8x7B model multiple times and\nconsidering longer responses, we achieve 86% of its self-consistency\nperformance obtained through zero-shot CoT prompting on the GSM8K and\nMultiArith datasets. Finally, we demonstrate that the probability of LLMs\ngenerating a longer response is quite low, highlighting the need for decoding\nstrategies conditioned on output length.",
      "tldr_zh": "本文质疑了 Self-consistency 方法的观点，即最一致的答案更可能是正确的，而是提出通过更多计算（如更长的推理文本）获得的一致答案更可能准确。研究发现，LLMs 在生成更长响应时能自主产生 Chain-of-Thought (CoT) 风格推理，从而提升预测的准确性。在零-shot 设置中，通过采样 Mixtral-8x7B 模型的更长响应，在 GSM8K 和 MultiArith 数据集上达到了 Self-consistency 性能的 86%。最终，论文强调 LLMs 生成长响应的概率较低，因此需要开发基于输出长度的解码策略。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.05778v1",
      "published_date": "2024-07-08 09:37:27 UTC",
      "updated_date": "2024-07-08 09:37:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:41:18.480286"
    },
    {
      "arxiv_id": "2407.05775v1",
      "title": "Structural Generalization in Autonomous Cyber Incident Response with Message-Passing Neural Networks and Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Jakob Nyberg",
        "Pontus Johnson"
      ],
      "abstract": "We believe that agents for automated incident response based on machine\nlearning need to handle changes in network structure. Computer networks are\ndynamic, and can naturally change in structure over time. Retraining agents for\nsmall network changes costs time and energy. We attempt to address this issue\nwith an existing method of relational agent learning, where the relations\nbetween objects are assumed to remain consistent across problem instances. The\nstate of the computer network is represented as a relational graph and encoded\nthrough a message passing neural network. The message passing neural network\nand an agent policy using the encoding are optimized end-to-end using\nreinforcement learning. We evaluate the approach on the second instance of the\nCyber Autonomy Gym for Experimentation (CAGE~2), a cyber incident simulator\nthat simulates attacks on an enterprise network. We create variants of the\noriginal network with different numbers of hosts and agents are tested without\nadditional training on them. Our results show that agents using relational\ninformation are able to find solutions despite changes to the network, and can\nperform optimally in some instances. Agents using the default vector state\nrepresentation perform better, but need to be specially trained on each network\nvariant, demonstrating a trade-off between specialization and generalization.",
      "tldr_zh": "本研究探讨了在自主网络事件响应中实现结构泛化的问题，针对计算机网络动态变化导致的代理重新训练需求，提出了一种基于消息传递神经网络(Message-Passing Neural Networks)和强化学习(Reinforcement Learning)的关系代理学习方法。网络状态被表示为关系图，通过消息传递神经网络编码，并端到端优化代理策略。在Cyber Autonomy Gym for Experimentation (CAGE 2)模拟器上进行实验，创建不同主机数量的网络变体，结果显示，使用关系信息的代理无需额外训练即可适应变化，并在某些场景下实现最优性能。相比之下，使用默认向量状态表示的代理虽表现更好，但需针对每个变体重新训练，这突显了泛化能力和专业化之间的权衡。",
      "categories": [
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted to IEEE CSR 2024",
      "pdf_url": "http://arxiv.org/pdf/2407.05775v1",
      "published_date": "2024-07-08 09:34:22 UTC",
      "updated_date": "2024-07-08 09:34:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:41:31.166844"
    },
    {
      "arxiv_id": "2407.05766v1",
      "title": "Multi-agent Reinforcement Learning-based Network Intrusion Detection System",
      "title_zh": "基于多智能体强化学习的网络入侵检测系统",
      "authors": [
        "Amine Tellache",
        "Amdjed Mokhtari",
        "Abdelaziz Amara Korba",
        "Yacine Ghamri-Doudane"
      ],
      "abstract": "Intrusion Detection Systems (IDS) play a crucial role in ensuring the\nsecurity of computer networks. Machine learning has emerged as a popular\napproach for intrusion detection due to its ability to analyze and detect\npatterns in large volumes of data. However, current ML-based IDS solutions\noften struggle to keep pace with the ever-changing nature of attack patterns\nand the emergence of new attack types. Additionally, these solutions face\nchallenges related to class imbalance, where the number of instances belonging\nto different classes (normal and intrusions) is significantly imbalanced, which\nhinders their ability to effectively detect minor classes. In this paper, we\npropose a novel multi-agent reinforcement learning (RL) architecture, enabling\nautomatic, efficient, and robust network intrusion detection. To enhance the\ncapabilities of the proposed model, we have improved the DQN algorithm by\nimplementing the weighted mean square loss function and employing\ncost-sensitive learning techniques. Our solution introduces a resilient\narchitecture designed to accommodate the addition of new attacks and\neffectively adapt to changes in existing attack patterns. Experimental results\nrealized using CIC-IDS-2017 dataset, demonstrate that our approach can\neffectively handle the class imbalance problem and provide a fine grained\nclassification of attacks with a very low false positive rate. In comparison to\nthe current state-of-the-art works, our solution demonstrates a significant\nsuperiority in both detection rate and false positive rate.",
      "tldr_zh": "本研究针对传统机器学习（ML）-based入侵检测系统（IDS）面临的挑战，如攻击模式快速变化、新攻击类型涌现以及类别不平衡问题，提出了一种新型多智能体强化学习（Multi-agent Reinforcement Learning）架构，用于实现自动、有效和鲁棒的网络入侵检测。该框架改进了DQN算法，通过采用加权均方损失函数（weighted mean square loss）和成本敏感学习（cost-sensitive learning）技术，使系统能够适应新攻击并调整现有攻击模式。实验结果基于CIC-IDS-2017数据集显示，该方法有效处理了类别不平衡问题，提供细粒度攻击分类，并显著降低假阳性率，与现有最先进方法相比，在检测率和假阳性率上表现出明显优势。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.05766v1",
      "published_date": "2024-07-08 09:18:59 UTC",
      "updated_date": "2024-07-08 09:18:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:41:43.887756"
    },
    {
      "arxiv_id": "2407.05758v1",
      "title": "Potential of Multimodal Large Language Models for Data Mining of Medical Images and Free-text Reports",
      "title_zh": "多模态大型语言模型在医疗图像和自由文本报告数据挖掘中的潜力",
      "authors": [
        "Yutong Zhang",
        "Yi Pan",
        "Tianyang Zhong",
        "Peixin Dong",
        "Kangni Xie",
        "Yuxiao Liu",
        "Hanqi Jiang",
        "Zhengliang Liu",
        "Shijie Zhao",
        "Tuo Zhang",
        "Xi Jiang",
        "Dinggang Shen",
        "Tianming Liu",
        "Xin Zhang"
      ],
      "abstract": "Medical images and radiology reports are crucial for diagnosing medical\nconditions, highlighting the importance of quantitative analysis for clinical\ndecision-making. However, the diversity and cross-source heterogeneity of these\ndata challenge the generalizability of current data-mining methods. Multimodal\nlarge language models (MLLMs) have recently transformed many domains,\nsignificantly affecting the medical field. Notably, Gemini-Vision-series\n(Gemini) and GPT-4-series (GPT-4) models have epitomized a paradigm shift in\nArtificial General Intelligence (AGI) for computer vision, showcasing their\npotential in the biomedical domain. In this study, we evaluated the performance\nof the Gemini, GPT-4, and 4 popular large models for an exhaustive evaluation\nacross 14 medical imaging datasets, including 5 medical imaging categories\n(dermatology, radiology, dentistry, ophthalmology, and endoscopy), and 3\nradiology report datasets. The investigated tasks encompass disease\nclassification, lesion segmentation, anatomical localization, disease\ndiagnosis, report generation, and lesion detection. Our experimental results\ndemonstrated that Gemini-series models excelled in report generation and lesion\ndetection but faces challenges in disease classification and anatomical\nlocalization. Conversely, GPT-series models exhibited proficiency in lesion\nsegmentation and anatomical localization but encountered difficulties in\ndisease diagnosis and lesion detection. Additionally, both the Gemini series\nand GPT series contain models that have demonstrated commendable generation\nefficiency. While both models hold promise in reducing physician workload,\nalleviating pressure on limited healthcare resources, and fostering\ncollaboration between clinical practitioners and artificial intelligence\ntechnologies, substantial enhancements and comprehensive validations remain\nimperative before clinical deployment.",
      "tldr_zh": "本研究评估了多模态大语言模型（MLLMs）在医疗图像和放射学报告数据挖掘中的潜力，针对数据多样性和异质性挑战，使用Gemini-Vision-series（Gemini）和GPT-4-series（GPT-4）等模型进行全面测试。实验涉及14个医疗图像数据集（涵盖皮肤科、放射学、牙科、眼科和内镜）和3个放射学报告数据集，任务包括疾病分类、病变分割、解剖定位、疾病诊断、报告生成及病变检测。结果显示，Gemini系列模型在报告生成和病变检测上表现出色，但疾病分类和解剖定位存在困难；反之，GPT系列模型擅长病变分割和解剖定位，却在疾病诊断和病变检测方面面临挑战。总体而言，这些模型显示出良好的生成效率，有望减轻医生工作负担并优化医疗资源，但需进一步改进和验证才能实现临床部署。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.05758v1",
      "published_date": "2024-07-08 09:08:42 UTC",
      "updated_date": "2024-07-08 09:08:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:41:56.822337"
    },
    {
      "arxiv_id": "2407.05746v1",
      "title": "MSP-Podcast SER Challenge 2024: L'antenne du Ventoux Multimodal Self-Supervised Learning for Speech Emotion Recognition",
      "title_zh": "翻译失败",
      "authors": [
        "Jarod Duret",
        "Mickael Rouvier",
        "Yannick Estève"
      ],
      "abstract": "In this work, we detail our submission to the 2024 edition of the MSP-Podcast\nSpeech Emotion Recognition (SER) Challenge. This challenge is divided into two\ndistinct tasks: Categorical Emotion Recognition and Emotional Attribute\nPrediction. We concentrated our efforts on Task 1, which involves the\ncategorical classification of eight emotional states using data from the\nMSP-Podcast dataset. Our approach employs an ensemble of models, each trained\nindependently and then fused at the score level using a Support Vector Machine\n(SVM) classifier. The models were trained using various strategies, including\nSelf-Supervised Learning (SSL) fine-tuning across different modalities: speech\nalone, text alone, and a combined speech and text approach. This joint training\nmethodology aims to enhance the system's ability to accurately classify\nemotional states. This joint training methodology aims to enhance the system's\nability to accurately classify emotional states. Thus, the system obtained\nF1-macro of 0.35\\% on development set.",
      "tldr_zh": "本篇论文介绍了我们提交给 2024 年 MSP-Podcast SER Challenge 的方案，专注于任务 1，即对 MSP-Podcast 数据集中的八种情感状态进行分类。我们的方法采用模型集合（ensemble）策略，通过 Self-Supervised Learning (SSL) 在不同模态上进行微调，包括语音单独、文本单独以及语音与文本结合的多模态训练，然后使用 Support Vector Machine (SVM) 在分数级别融合模型输出，以提升情感分类准确性。实验结果显示，该系统在开发集上取得了 F1-macro 为 0.35% 的性能，为多模态语音情感识别提供了新的参考框架。",
      "categories": [
        "cs.AI",
        "cs.SD",
        "eess.AS"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.05746v1",
      "published_date": "2024-07-08 08:52:06 UTC",
      "updated_date": "2024-07-08 08:52:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:42:07.678553"
    },
    {
      "arxiv_id": "2407.05739v1",
      "title": "Multi-Bit Mechanism: A Novel Information Transmission Paradigm for Spiking Neural Networks",
      "title_zh": "多位机制：一种用于脉冲神经网络的新颖信息传输范式",
      "authors": [
        "Yongjun Xiao",
        "Xianlong Tian",
        "Yongqi Ding",
        "Pei He",
        "Mengmeng Jing",
        "Lin Zuo"
      ],
      "abstract": "Since proposed, spiking neural networks (SNNs) gain recognition for their\nhigh performance, low power consumption and enhanced biological\ninterpretability. However, while bringing these advantages, the binary nature\nof spikes also leads to considerable information loss in SNNs, ultimately\ncausing performance degradation. We claim that the limited expressiveness of\ncurrent binary spikes, resulting in substantial information loss, is the\nfundamental issue behind these challenges. To alleviate this, our research\nintroduces a multi-bit information transmission mechanism for SNNs. This\nmechanism expands the output of spiking neurons from the original single bit to\nmultiple bits, enhancing the expressiveness of the spikes and reducing\ninformation loss during the forward process, while still maintaining the low\nenergy consumption advantage of SNNs. For SNNs, this represents a new paradigm\nof information transmission. Moreover, to further utilize the limited spikes,\nwe extract effective signals from the previous layer to re-stimulate the\nneurons, thus encouraging full spikes emission across various bit levels. We\nconducted extensive experiments with our proposed method using both direct\ntraining method and ANN-SNN conversion method, and the results show consistent\nperformance improvements.",
      "tldr_zh": "本研究针对尖峰神经网络(SNNs)中二进制尖峰导致的信息损失问题，提出了一种新型多位信息传输机制，将尖峰神经元的输出从单位扩展到多位，从而提升尖峰的表达力和减少前向传播中的信息损失，同时保留SNNs的低功耗优势。该机制还引入重新刺激策略，从前一层提取有效信号来激活神经元，促进多位尖峰的充分发射。实验结果显示，使用直接训练方法和ANN-SNN转换方法后，SNNs的性能得到一致提升，为SNNs的信息传输范式提供了新范例。",
      "categories": [
        "cs.NE",
        "cs.AI"
      ],
      "primary_category": "cs.NE",
      "comment": "Under review",
      "pdf_url": "http://arxiv.org/pdf/2407.05739v1",
      "published_date": "2024-07-08 08:46:31 UTC",
      "updated_date": "2024-07-08 08:46:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:42:18.020676"
    },
    {
      "arxiv_id": "2407.05736v1",
      "title": "TransMA: an explainable multi-modal deep learning model for predicting properties of ionizable lipid nanoparticles in mRNA delivery",
      "title_zh": "翻译失败",
      "authors": [
        "Kun Wu",
        "Zixu Wang",
        "Xiulong Yang",
        "Yangyang Chen",
        "Zhenqi Han",
        "Jialu Zhang",
        "Lizhuang Liu"
      ],
      "abstract": "As the primary mRNA delivery vehicles, ionizable lipid nanoparticles (LNPs)\nexhibit excellent safety, high transfection efficiency, and strong immune\nresponse induction. However, the screening process for LNPs is time-consuming\nand costly. To expedite the identification of high-transfection-efficiency mRNA\ndrug delivery systems, we propose an explainable LNPs transfection efficiency\nprediction model, called TransMA. TransMA employs a multi-modal molecular\nstructure fusion architecture, wherein the fine-grained atomic spatial\nrelationship extractor named molecule 3D Transformer captures three-dimensional\nspatial features of the molecule, and the coarse-grained atomic sequence\nextractor named molecule Mamba captures one-dimensional molecular features. We\ndesign the mol-attention mechanism block, enabling it to align coarse and\nfine-grained atomic features and captures relationships between atomic spatial\nand sequential structures. TransMA achieves state-of-the-art performance in\npredicting transfection efficiency using the scaffold and cliff data splitting\nmethods on the current largest LNPs dataset, including Hela and RAW cell lines.\nMoreover, we find that TransMA captures the relationship between subtle\nstructural changes and significant transfection efficiency variations,\nproviding valuable insights for LNPs design. Additionally, TransMA's\npredictions on external transfection efficiency data maintain a consistent\norder with actual transfection efficiencies, demonstrating its robust\ngeneralization capability. The code, model and data are made publicly available\nat https://github.com/wklix/TransMA/tree/master. We hope that high-accuracy\ntransfection prediction models in the future can aid in LNPs design and initial\nscreening, thereby assisting in accelerating the mRNA design process.",
      "tldr_zh": "本研究提出了一种可解释的多模态深度学习模型 TransMA，用于预测 mRNA 递送中离子化脂质纳米颗粒 (LNPs) 的转染效率，以加速 LNPs 的筛选过程。TransMA 采用多模态分子结构融合架构，包括 Molecule 3D Transformer 捕捉分子的三维空间特征、Molecule Mamba 捕捉一维分子序列特征，以及 mol-attention 机制来对齐粗细粒度特征并挖掘原子空间和序列关系。在当前最大的 LNPs 数据集上，TransMA 使用 scaffold 和 cliff 数据分割方法实现了最先进性能，并揭示了微妙结构变化与转染效率显著变动的关系，提供 LNPs 设计洞见。该模型在外部数据上显示出鲁棒的泛化能力，代码和数据已公开可用，有望辅助 mRNA 设计过程的优化。",
      "categories": [
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.AI",
      "comment": "14 pages, 9 figures",
      "pdf_url": "http://arxiv.org/pdf/2407.05736v1",
      "published_date": "2024-07-08 08:43:32 UTC",
      "updated_date": "2024-07-08 08:43:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:42:33.210309"
    },
    {
      "arxiv_id": "2407.05732v1",
      "title": "FairPFN: Transformers Can do Counterfactual Fairness",
      "title_zh": "翻译失败",
      "authors": [
        "Jake Robertson",
        "Noah Hollmann",
        "Noor Awad",
        "Frank Hutter"
      ],
      "abstract": "Machine Learning systems are increasingly prevalent across healthcare, law\nenforcement, and finance but often operate on historical data, which may carry\nbiases against certain demographic groups. Causal and counterfactual fairness\nprovides an intuitive way to define fairness that closely aligns with legal\nstandards. Despite its theoretical benefits, counterfactual fairness comes with\nseveral practical limitations, largely related to the reliance on domain\nknowledge and approximate causal discovery techniques in constructing a causal\nmodel. In this study, we take a fresh perspective on counterfactually fair\nprediction, building upon recent work in in context learning (ICL) and prior\nfitted networks (PFNs) to learn a transformer called FairPFN. This model is\npretrained using synthetic fairness data to eliminate the causal effects of\nprotected attributes directly from observational data, removing the requirement\nof access to the correct causal model in practice. In our experiments, we\nthoroughly assess the effectiveness of FairPFN in eliminating the causal impact\nof protected attributes on a series of synthetic case studies and real world\ndatasets. Our findings pave the way for a new and promising research area:\ntransformers for causal and counterfactual fairness.",
      "tldr_zh": "本研究针对机器学习系统在医疗、法 enforcement 和金融等领域基于历史数据可能存在的偏见问题，提出了一种基于 Transformers 的模型 FairPFN，以实现 Counterfactual Fairness。FairPFN 利用 In-context Learning (ICL) 和 Prior Fitted Networks (PFNs) 通过预训练合成公平数据，直接从观察数据中消除受保护属性的因果影响，从而避免了对正确因果模型的依赖。在实验中，FairPFN 在合成案例和真实数据集上有效消除了这些因果影响，为 Transformers 在因果和反事实公平性方面的应用开辟了新研究领域。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.05732v1",
      "published_date": "2024-07-08 08:36:44 UTC",
      "updated_date": "2024-07-08 08:36:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:42:43.258022"
    },
    {
      "arxiv_id": "2407.05714v1",
      "title": "Implementing a hybrid approach in a knowledge engineering process to manage technical advice relating to feedback from the operation of complex sensitive equipment",
      "title_zh": "翻译失败",
      "authors": [
        "Alain Claude Hervé Berger",
        "Sébastien Boblet",
        "Thierry Cartié",
        "Jean-Pierre Cotton",
        "François Vexler"
      ],
      "abstract": "How can technical advice on operating experience feedback be managed\nefficiently in an organization that has never used knowledge engineering\ntechniques and methods? This article explains how an industrial company in the\nnuclear and defense sectors adopted such an approach, adapted to its \"TA KM\"\norganizational context and falls within the ISO30401 framework, to build a\ncomplete system with a \"SARBACANES\" application to support its business\nprocesses and perpetuate its know-how and expertise in a knowledge base. Over\nand above the classic transfer of knowledge between experts and business\nspecialists, SARBACANES also reveals the ability of this type of engineering to\ndeliver multi-functional operation. Modeling was accelerated by the use of a\ntool adapted to this type of operation: the Ardans Knowledge Maker platform.",
      "tldr_zh": "这篇文章探讨了如何在从未采用知识工程技术的核能和国防行业组织中，高效管理复杂敏感设备操作反馈的技术建议。研究团队实施了一种混合方法，适应“TA KM”组织上下文并符合 ISO30401 框架，开发了 SARBACANES 系统，以支持业务流程并延续专业知识和专长。该系统不仅实现了专家与业务专家之间的知识转移，还展示了知识工程的多功能性，并通过 Ardans Knowledge Maker 平台加速了建模过程。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "in French language. 35es Journ{\\'e}es francophones d'Ing{\\'e}nierie\n  des Connaissances (IC 2024) @ Plate-Forme Intelligence Artificielle (PFIA\n  2024), Association Fran\\c{c}aise pour l'Intelligence Artificielle;\n  Laboratoire L3i La Rochelle Universit{\\'e}, Jul 2024, La Rochelle, France",
      "pdf_url": "http://arxiv.org/pdf/2407.05714v1",
      "published_date": "2024-07-08 08:17:10 UTC",
      "updated_date": "2024-07-08 08:17:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:42:54.537827"
    },
    {
      "arxiv_id": "2407.05713v1",
      "title": "Short-term Object Interaction Anticipation with Disentangled Object Detection @ Ego4D Short Term Object Interaction Anticipation Challenge",
      "title_zh": "翻译失败",
      "authors": [
        "Hyunjin Cho",
        "Dong Un Kang",
        "Se Young Chun"
      ],
      "abstract": "Short-term object interaction anticipation is an important task in egocentric\nvideo analysis, including precise predictions of future interactions and their\ntimings as well as the categories and positions of the involved active objects.\nTo alleviate the complexity of this task, our proposed method, SOIA-DOD,\neffectively decompose it into 1) detecting active object and 2) classifying\ninteraction and predicting their timing. Our method first detects all potential\nactive objects in the last frame of egocentric video by fine-tuning a\npre-trained YOLOv9. Then, we combine these potential active objects as query\nwith transformer encoder, thereby identifying the most promising next active\nobject and predicting its future interaction and time-to-contact. Experimental\nresults demonstrate that our method outperforms state-of-the-art models on the\nchallenge test set, achieving the best performance in predicting next active\nobjects and their interactions. Finally, our proposed ranked the third overall\ntop-5 mAP when including time-to-contact predictions. The source code is\navailable at https://github.com/KeenyJin/SOIA-DOD.",
      "tldr_zh": "该研究提出了一种名为 SOIA-DOD 的方法，用于 Ego4D 短时对象交互预测挑战，旨在通过分解任务为活跃对象检测和交互分类与时间预测来提升预测精度。方法首先利用微调后的 YOLOv9 在视频最后一帧检测潜在活跃对象，然后结合这些对象作为查询输入 Transformer 编码器，以识别下一个活跃对象及其未来交互和接触时间。实验结果显示，SOIA-DOD 在挑战测试集上超越了最先进模型，在预测活跃对象和交互方面表现最佳，并整体排名第三（top-5 mAP）。这为 egocentric 视频分析中的短时预测提供了高效框架。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "4 pages",
      "pdf_url": "http://arxiv.org/pdf/2407.05713v1",
      "published_date": "2024-07-08 08:13:16 UTC",
      "updated_date": "2024-07-08 08:13:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:43:07.482871"
    },
    {
      "arxiv_id": "2407.05712v3",
      "title": "MobilePortrait: Real-Time One-Shot Neural Head Avatars on Mobile Devices",
      "title_zh": "翻译失败",
      "authors": [
        "Jianwen Jiang",
        "Gaojie Lin",
        "Zhengkun Rong",
        "Chao Liang",
        "Yongming Zhu",
        "Jiaqi Yang",
        "Tianyun Zhong"
      ],
      "abstract": "Existing neural head avatars methods have achieved significant progress in\nthe image quality and motion range of portrait animation. However, these\nmethods neglect the computational overhead, and to the best of our knowledge,\nnone is designed to run on mobile devices. This paper presents MobilePortrait,\na lightweight one-shot neural head avatars method that reduces learning\ncomplexity by integrating external knowledge into both the motion modeling and\nimage synthesis, enabling real-time inference on mobile devices. Specifically,\nwe introduce a mixed representation of explicit and implicit keypoints for\nprecise motion modeling and precomputed visual features for enhanced foreground\nand background synthesis. With these two key designs and using simple U-Nets as\nbackbones, our method achieves state-of-the-art performance with less than\none-tenth the computational demand. It has been validated to reach speeds of\nover 100 FPS on mobile devices and support both video and audio-driven inputs.",
      "tldr_zh": "本文提出MobilePortrait，一种轻量级的单张图像（one-shot）神经头像方法，通过整合外部知识到动作建模和图像合成中，实现移动设备上的实时推理。具体设计包括混合关键点表示（explicit and implicit keypoints）用于精确动作建模，以及预计算视觉特征用于增强前景和背景合成，使用简单的U-Nets作为骨干网络。相比现有方法，MobilePortrait的计算需求不到十分之一，并在移动设备上达到超过100 FPS的速度，支持视频和音频驱动输入，同时实现了最先进性能。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "CVPR 2025",
      "pdf_url": "http://arxiv.org/pdf/2407.05712v3",
      "published_date": "2024-07-08 08:12:57 UTC",
      "updated_date": "2025-04-08 08:10:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:43:18.940045"
    },
    {
      "arxiv_id": "2407.05705v1",
      "title": "Fast and Continual Knowledge Graph Embedding via Incremental LoRA",
      "title_zh": "翻译失败",
      "authors": [
        "Jiajun Liu",
        "Wenjun Ke",
        "Peng Wang",
        "Jiahao Wang",
        "Jinhua Gao",
        "Ziyu Shang",
        "Guozheng Li",
        "Zijie Xu",
        "Ke Ji",
        "Yining Li"
      ],
      "abstract": "Continual Knowledge Graph Embedding (CKGE) aims to efficiently learn new\nknowledge and simultaneously preserve old knowledge. Dominant approaches\nprimarily focus on alleviating catastrophic forgetting of old knowledge but\nneglect efficient learning for the emergence of new knowledge. However, in\nreal-world scenarios, knowledge graphs (KGs) are continuously growing, which\nbrings a significant challenge to fine-tuning KGE models efficiently. To\naddress this issue, we propose a fast CKGE framework (\\model), incorporating an\nincremental low-rank adapter (\\mec) mechanism to efficiently acquire new\nknowledge while preserving old knowledge. Specifically, to mitigate\ncatastrophic forgetting, \\model\\ isolates and allocates new knowledge to\nspecific layers based on the fine-grained influence between old and new KGs.\nSubsequently, to accelerate fine-tuning, \\model\\ devises an efficient \\mec\\\nmechanism, which embeds the specific layers into incremental low-rank adapters\nwith fewer training parameters. Moreover, \\mec\\ introduces adaptive rank\nallocation, which makes the LoRA aware of the importance of entities and\nadjusts its rank scale adaptively. We conduct experiments on four public\ndatasets and two new datasets with a larger initial scale. Experimental results\ndemonstrate that \\model\\ can reduce training time by 34\\%-49\\% while still\nachieving competitive link prediction performance against state-of-the-art\nmodels on four public datasets (average MRR score of 21.0\\% vs.\n21.1\\%).Meanwhile, on two newly constructed datasets, \\model\\ saves 51\\%-68\\%\ntraining time and improves link prediction performance by 1.5\\%.",
      "tldr_zh": "该论文针对Continual Knowledge Graph Embedding (CKGE)问题，提出了一种快速框架\\model，通过增量低秩适配器(\\mec)机制来高效学习新知识同时缓解灾难性遗忘。具体地，该框架基于细粒度影响在旧和新知识图谱之间隔离知识分配，并引入自适应秩分配，使LoRA适应实体重要性，从而减少训练参数。实验结果显示，在四个公共数据集上，\\model减少34%-49%的训练时间，同时保持竞争性链接预测性能（平均MRR得分21.0% vs. 21.1%）；在两个新数据集上，它节省51%-68%的训练时间并提升链接预测性能1.5%。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted by IJCAI2024",
      "pdf_url": "http://arxiv.org/pdf/2407.05705v1",
      "published_date": "2024-07-08 08:07:13 UTC",
      "updated_date": "2024-07-08 08:07:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:43:32.224837"
    },
    {
      "arxiv_id": "2407.05700v2",
      "title": "InverseCoder: Self-improving Instruction-Tuned Code LLMs with Inverse-Instruct",
      "title_zh": "翻译失败",
      "authors": [
        "Yutong Wu",
        "Di Huang",
        "Wenxuan Shi",
        "Wei Wang",
        "Lingzhe Gao",
        "Shihao Liu",
        "Ziyuan Nan",
        "Kaizhao Yuan",
        "Rui Zhang",
        "Xishan Zhang",
        "Zidong Du",
        "Qi Guo",
        "Yewen Pu",
        "Dawei Yin",
        "Xing Hu",
        "Yunji Chen"
      ],
      "abstract": "Recent advancements in open-source code large language models (LLMs) have\nbeen driven by fine-tuning on the data generated from powerful closed-source\nLLMs, which are expensive to obtain. This paper explores whether it is possible\nto use a fine-tuned open-source model to generate additional data to augment\nits instruction-tuning dataset. We make two observations: (1) A code snippet\ncan serve as the response to different instructions. (2) Instruction-tuned code\nLLMs perform better at translating code into instructions than the reverse.\nBased on these observations, we propose Inverse-Instruct, a data augmentation\ntechnique that uses a fine-tuned LLM to generate additional instructions of\ncode responses from its own training dataset. The additional\ninstruction-response pairs are added to the original dataset, and a stronger\ncode LLM can be obtained by fine-tuning on the augmented dataset. We\nempirically validate Inverse-Instruct on a range of open-source code models\n(e.g. CodeLlama-Python and DeepSeek-Coder) and benchmarks (e.g., HumanEval(+),\nMBPP(+), DS-1000 and MultiPL-E), showing it consistently improves the base\nmodels.",
      "tldr_zh": "这篇论文提出了InverseCoder框架，利用Inverse-Instruct技术来实现开源代码大语言模型（LLMs）的自我改进。Inverse-Instruct基于两个关键观察——代码片段可对应多种指令，以及指令微调模型在代码到指令翻译上表现更优——通过使用微调后的LLM从其训练数据集生成额外指令-响应对，从而增强数据集并进一步微调模型。实验结果显示，该方法在CodeLlama-Python和DeepSeek-Coder等模型上，以及HumanEval(+)、MBPP(+)、DS-1000和MultiPL-E等基准中，一致提升了基线模型的性能。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.SE"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted for publication at AAAI 2025. Extended version with full\n  appendix, 18 pages",
      "pdf_url": "http://arxiv.org/pdf/2407.05700v2",
      "published_date": "2024-07-08 08:00:05 UTC",
      "updated_date": "2024-12-16 03:08:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:43:43.853632"
    },
    {
      "arxiv_id": "2407.05694v2",
      "title": "On the Limitations of Compute Thresholds as a Governance Strategy",
      "title_zh": "翻译失败",
      "authors": [
        "Sara Hooker"
      ],
      "abstract": "At face value, this essay is about understanding a fairly esoteric governance\ntool called compute thresholds. However, in order to grapple with whether these\nthresholds will achieve anything, we must first understand how they came to be.\nTo do so, we need to engage with a decades-old debate at the heart of computer\nscience progress, namely, is bigger always better? Does a certain inflection\npoint of compute result in changes to the risk profile of a model? Hence, this\nessay may be of interest not only to policymakers and the wider public but also\nto computer scientists interested in understanding the role of compute in\nunlocking breakthroughs. This discussion is timely given the wide adoption of\ncompute thresholds in both the White House Executive Orders on AI Safety (EO)\nand the EU AI Act to identify more risky systems. A key conclusion of this\nessay is that compute thresholds, as currently implemented, are shortsighted\nand likely to fail to mitigate risk. The relationship between compute and risk\nis highly uncertain and rapidly changing. Relying upon compute thresholds\noverestimates our ability to predict what abilities emerge at different scales.\nThis essay ends with recommendations for a better way forward.",
      "tldr_zh": "这篇论文探讨了计算阈值（compute thresholds）作为AI治理策略的局限性，审视了计算机科学中长期存在的争论，即更大计算量是否总是更好，以及特定计算阈值是否能准确改变模型的风险分布。论文指出，这些阈值已在White House Executive Orders on AI Safety (EO)和EU AI Act中广泛采用，但由于计算与风险的关系高度不确定且快速变化，当前实施方式可能短视且无法有效缓解风险。主要贡献是强调过高估计我们预测能力的问题，并提供改进建议，以更可靠的方式推进AI治理。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.ET",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.05694v2",
      "published_date": "2024-07-08 07:53:06 UTC",
      "updated_date": "2024-07-30 02:37:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:43:56.769677"
    },
    {
      "arxiv_id": "2407.05693v2",
      "title": "Sub-SA: Strengthen In-context Learning via Submodular Selective Annotation",
      "title_zh": "Sub-SA：通过子模函数选择性标注加强上下文学习",
      "authors": [
        "Jian Qian",
        "Miao Sun",
        "Sifan Zhou",
        "Ziyu Zhao",
        "Ruizhi Hun",
        "Patrick Chiang"
      ],
      "abstract": "In-context learning (ICL) leverages in-context examples as prompts for the\npredictions of Large Language Models (LLMs). These prompts play a crucial role\nin achieving strong performance. However, the selection of suitable prompts\nfrom a large pool of labeled examples often entails significant annotation\ncosts. To address this challenge, we propose Sub-SA (Submodular Selective\nAnnotation), a submodule-based selective annotation method. The aim of Sub-SA\nis to reduce annotation costs while improving the quality of in-context\nexamples and minimizing the time consumption of the selection process. In\nSub-SA, we design a submodular function that facilitates effective subset\nselection for annotation and demonstrates the characteristics of monotonically\nand submodularity from the theoretical perspective. Specifically, we propose\nRPR (Reward and Penalty Regularization) to better balance the diversity and\nrepresentativeness of the unlabeled dataset attributed to a reward term and a\npenalty term, respectively. Consequently, the selection for annotations can be\neffectively addressed with a simple yet effective greedy search algorithm based\non the submodular function. Finally, we apply the similarity prompt retrieval\nto get the examples for ICL.",
      "tldr_zh": "该论文针对 In-context Learning (ICL) 中从大量标记示例中选择提示的标注成本问题，提出了一种基于子模函数的 Sub-SA (Submodular Selective Annotation) 方法，以减少成本并提升示例质量。Sub-SA 通过设计一个子模函数来实现有效子集选择，并从理论上证明其单调性和子模性；其中，RPR (Reward and Penalty Regularization) 机制通过奖励项和惩罚项平衡数据集的多样性和代表性。最终，该方法结合贪婪搜索算法和相似性提示检索，显著提高了 ICL 的效率和性能。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by ECAI 2024",
      "pdf_url": "http://arxiv.org/pdf/2407.05693v2",
      "published_date": "2024-07-08 07:47:30 UTC",
      "updated_date": "2024-09-13 06:57:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:44:08.404893"
    },
    {
      "arxiv_id": "2407.05690v1",
      "title": "Pruning Large Language Models to Intra-module Low-rank Architecture with Transitional Activations",
      "title_zh": "通过过渡激活将大语言模型修剪至模块内低秩架构",
      "authors": [
        "Bowen Shen",
        "Zheng Lin",
        "Daren Zha",
        "Wei Liu",
        "Jian Luan",
        "Bin Wang",
        "Weiping Wang"
      ],
      "abstract": "Structured pruning fundamentally reduces computational and memory overheads\nof large language models (LLMs) and offers a feasible solution for end-side LLM\ndeployment. Structurally pruned models remain dense and high-precision, highly\ncompatible with further tuning and compression. However, as the coarse-grained\nstructured pruning poses large damage to the highly interconnected model,\nachieving a high compression ratio for scaled-up LLMs remains a challenge. In\nthis paper, we introduce a task-agnostic structured pruning approach coupled\nwith a compact Transformer architecture design. The proposed approach, named\nTransAct, reduces transitional activations inside multi-head attention (MHA)\nand multi-layer perceptron (MLP) modules, while preserving the inter-module\nactivations that are sensitive to perturbations. Hence, the LLM is pruned into\nan intra-module low-rank architecture, significantly reducing weights, KV Cache\nand attention computation. TransAct is implemented on the LLaMA model and\nevaluated on downstream benchmarks. Results verify the optimality of our\napproach at high compression with respect to both efficiency and performance.\nFurther, ablation studies reveal the strength of activation-guided iterative\npruning and provide experimental analysis on the redundancy of MHA and MLP\nmodules.",
      "tldr_zh": "本研究提出了一种任务无关的结构化剪枝方法TransAct，用于优化Large Language Models (LLMs)，通过减少Multi-Head Attention (MHA)和Multi-Layer Perceptron (MLP)模块内的过渡激活，同时保留模块间敏感激活，将模型剪枝为intra-module low-rank架构，从而显著降低权重、KV Cache和注意力计算开销。TransAct在LLaMA模型上进行评估，结果显示在高压缩率下，该方法在效率和性能方面均优于基线。消融研究进一步验证了激活引导迭代剪枝的有效性，并分析了MHA和MLP模块的冗余特性，为LLMs的端侧部署提供了可行解决方案。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Findings of ACL 2024",
      "pdf_url": "http://arxiv.org/pdf/2407.05690v1",
      "published_date": "2024-07-08 07:45:38 UTC",
      "updated_date": "2024-07-08 07:45:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:44:19.643238"
    },
    {
      "arxiv_id": "2407.05689v1",
      "title": "Ten Years of Teaching Empirical Software Engineering in the context of Energy-efficient Software",
      "title_zh": "在节能软件背景下教授实证软件工程的十年经验",
      "authors": [
        "Ivano Malavolta",
        "Vincenzo Stoico",
        "Patricia Lago"
      ],
      "abstract": "In this chapter we share our experience in running ten editions of the Green\nLab course at the Vrije Universiteit Amsterdam, the Netherlands. The course is\ngiven in the Software Engineering and Green IT track of the Computer Science\nMaster program of the VU. The course takes place every year over a 2-month\nperiod and teaches Computer Science students the fundamentals of Empirical\nSoftware Engineering in the context of energy-efficient software. The\npeculiarity of the course is its research orientation: at the beginning of the\ncourse the instructor presents a catalog of scientifically relevant goals, and\neach team of students signs up for one of them and works together for 2 months\non their own experiment for achieving the goal. Each team goes over the classic\nsteps of an empirical study, starting from a precise formulation of the goal\nand research questions to context definition, selection of experimental\nsubjects and objects, definition of experimental variables, experiment\nexecution, data analysis, and reporting. Over the years, the course became\nwell-known within the Software Engineering community since it led to several\nscientific studies that have been published at various scientific conferences\nand journals. Also, students execute their experiments using\n\\textit{open-source tools}, which are developed and maintained by researchers\nand other students within the program, thus creating a virtuous community of\nlearners where students exchange ideas, help each other, and learn how to\ncollaboratively contribute to open-source projects in a safe environment.",
      "tldr_zh": "本研究回顾了阿姆斯特丹自由大学在过去十年中举办的 Green Lab 课程，该课程作为计算机科学硕士程序的一部分，专注于在节能软件（Energy-efficient Software）背景下教授经验软件工程（Empirical Software Engineering）。课程为期两个月，学生通过团队形式选择科学目标，进行完整的实验流程，包括目标制定、研究问题定义、变量控制、实验执行、数据分析和报告。课程强调使用开源工具进行实验，促进学生间协作，并已产生多项在学术会议和期刊上发表的科学成果，从而培养了可持续的开源社区和实际技能。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.DC"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.05689v1",
      "published_date": "2024-07-08 07:44:49 UTC",
      "updated_date": "2024-07-08 07:44:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:44:30.653051"
    },
    {
      "arxiv_id": "2407.05688v2",
      "title": "Learning with Alignments: Tackling the Inter- and Intra-domain Shifts for Cross-multidomain Facial Expression Recognition",
      "title_zh": "翻译失败",
      "authors": [
        "Yuxiang Yang",
        "Lu Wen",
        "Xinyi Zeng",
        "Yuanyuan Xu",
        "Xi Wu",
        "Jiliu Zhou",
        "Yan Wang"
      ],
      "abstract": "Facial Expression Recognition (FER) holds significant importance in\nhuman-computer interactions. Existing cross-domain FER methods often transfer\nknowledge solely from a single labeled source domain to an unlabeled target\ndomain, neglecting the comprehensive information across multiple sources.\nNevertheless, cross-multidomain FER (CMFER) is very challenging for (i) the\ninherent inter-domain shifts across multiple domains and (ii) the intra-domain\nshifts stemming from the ambiguous expressions and low inter-class\ndistinctions. In this paper, we propose a novel Learning with Alignments CMFER\nframework, named LA-CMFER, to handle both inter- and intra-domain shifts.\nSpecifically, LA-CMFER is constructed with a global branch and a local branch\nto extract features from the full images and local subtle expressions,\nrespectively. Based on this, LA-CMFER presents a dual-level inter-domain\nalignment method to force the model to prioritize hard-to-align samples in\nknowledge transfer at a sample level while gradually generating a\nwell-clustered feature space with the guidance of class attributes at a cluster\nlevel, thus narrowing the inter-domain shifts. To address the intra-domain\nshifts, LA-CMFER introduces a multi-view intra-domain alignment method with a\nmulti-view clustering consistency constraint where a prediction similarity\nmatrix is built to pursue consistency between the global and local views, thus\nrefining pseudo labels and eliminating latent noise. Extensive experiments on\nsix benchmark datasets have validated the superiority of our LA-CMFER.",
      "tldr_zh": "本文提出 LA-CMFER 框架，用于解决跨多域面部表情识别 (CMFER) 中的 inter-domain shifts 和 intra-domain shifts 问题，这些差异分别源于多个域间的固有差异以及域内模糊表情和类别区分低。框架包括全局分支和局部分支，通过双层级 inter-domain alignment 在样本级优先处理难对齐样本并在聚类级指导特征空间，以及多视图 intra-domain alignment 以聚类一致性约束确保全局和局部视图预测一致，从而优化伪标签和减少噪声。在六个基准数据集上的广泛实验证明，LA-CMFER 比现有方法表现出色。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by ACM MM 2024",
      "pdf_url": "http://arxiv.org/pdf/2407.05688v2",
      "published_date": "2024-07-08 07:43:06 UTC",
      "updated_date": "2024-07-30 11:02:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:44:44.440827"
    },
    {
      "arxiv_id": "2407.05683v2",
      "title": "RadiomicsFill-Mammo: Synthetic Mammogram Mass Manipulation with Radiomics Features",
      "title_zh": "翻译失败",
      "authors": [
        "Inye Na",
        "Jonghun Kim",
        "Eun Sook Ko",
        "Hyunjin Park"
      ],
      "abstract": "Motivated by the question, \"Can we generate tumors with desired attributes?''\nthis study leverages radiomics features to explore the feasibility of\ngenerating synthetic tumor images. Characterized by its low-dimensional yet\nbiologically meaningful markers, radiomics bridges the gap between complex\nmedical imaging data and actionable clinical insights. We present\nRadiomicsFill-Mammo, the first of the RadiomicsFill series, an innovative\ntechnique that generates realistic mammogram mass images mirroring specific\nradiomics attributes using masked images and opposite breast images, leveraging\na recent stable diffusion model. This approach also allows for the\nincorporation of essential clinical variables, such as BI-RADS and breast\ndensity, alongside radiomics features as conditions for mass generation.\nResults indicate that RadiomicsFill-Mammo effectively generates diverse and\nrealistic tumor images based on various radiomics conditions. Results also\ndemonstrate a significant improvement in mass detection capabilities,\nleveraging RadiomicsFill-Mammo as a strategy to generate simulated samples.\nFurthermore, RadiomicsFill-Mammo not only advances medical imaging research but\nalso opens new avenues for enhancing treatment planning and tumor simulation.\nOur code is available at https://github.com/nainye/RadiomicsFill.",
      "tldr_zh": "本研究探讨了是否能生成具有特定属性的肿瘤图像，提出RadiomicsFill-Mammo技术，利用radiomics features作为低维生物标记，结合masked images、opposite breast images和stable diffusion模型，生成真实乳腺X光图像中的肿瘤质量。方法允许整合临床变量如BI-RADS和breast density作为生成条件，确保图像多样性和真实性。实验结果显示，该技术显著提升了肿瘤检测能力，并为医疗成像研究、治疗规划和肿瘤模拟开辟新途径。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "Accepted at MICCAI 2024",
      "pdf_url": "http://arxiv.org/pdf/2407.05683v2",
      "published_date": "2024-07-08 07:33:52 UTC",
      "updated_date": "2024-09-29 08:58:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:44:54.640122"
    },
    {
      "arxiv_id": "2407.05680v2",
      "title": "Fine-Grained Multi-View Hand Reconstruction Using Inverse Rendering",
      "title_zh": "翻译失败",
      "authors": [
        "Qijun Gan",
        "Wentong Li",
        "Jinwei Ren",
        "Jianke Zhu"
      ],
      "abstract": "Reconstructing high-fidelity hand models with intricate textures plays a\ncrucial role in enhancing human-object interaction and advancing real-world\napplications. Despite the state-of-the-art methods excelling in texture\ngeneration and image rendering, they often face challenges in accurately\ncapturing geometric details. Learning-based approaches usually offer better\nrobustness and faster inference, which tend to produce smoother results and\nrequire substantial amounts of training data. To address these issues, we\npresent a novel fine-grained multi-view hand mesh reconstruction method that\nleverages inverse rendering to restore hand poses and intricate details.\nFirstly, our approach predicts a parametric hand mesh model through Graph\nConvolutional Networks (GCN) based method from multi-view images. We further\nintroduce a novel Hand Albedo and Mesh (HAM) optimization module to refine both\nthe hand mesh and textures, which is capable of preserving the mesh topology.\nIn addition, we suggest an effective mesh-based neural rendering scheme to\nsimultaneously generate photo-realistic image and optimize mesh geometry by\nfusing the pre-trained rendering network with vertex features. We conduct the\ncomprehensive experiments on InterHand2.6M, DeepHandMesh and dataset collected\nby ourself, whose promising results show that our proposed approach outperforms\nthe state-of-the-art methods on both reconstruction accuracy and rendering\nquality. Code and dataset are publicly available at\nhttps://github.com/agnJason/FMHR.",
      "tldr_zh": "本研究提出了一种使用反向渲染（Inverse Rendering）的细粒度多视图手网格重建方法，旨在解决现有方法在捕捉手部几何细节方面的不足，同时提升重建准确性和渲染质量。该方法首先通过 Graph Convolutional Networks (GCN) 从多视图图像预测参数化手网格模型，然后引入 Hand Albedo and Mesh (HAM) 优化模块来精炼网格拓扑和纹理，并采用基于网格的神经渲染方案融合预训练网络生成逼真图像并优化几何细节。在 InterHand2.6M、DeepHandMesh 等数据集上的实验表明，该方法在重建准确性和渲染质量上均优于最先进方法，代码和数据集已公开。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by AAAI 2024",
      "pdf_url": "http://arxiv.org/pdf/2407.05680v2",
      "published_date": "2024-07-08 07:28:24 UTC",
      "updated_date": "2024-07-09 03:39:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:45:18.815819"
    },
    {
      "arxiv_id": "2407.05679v3",
      "title": "BEVWorld: A Multimodal World Simulator for Autonomous Driving via Scene-Level BEV Latents",
      "title_zh": "翻译失败",
      "authors": [
        "Yumeng Zhang",
        "Shi Gong",
        "Kaixin Xiong",
        "Xiaoqing Ye",
        "Xiaofan Li",
        "Xiao Tan",
        "Fan Wang",
        "Jizhou Huang",
        "Hua Wu",
        "Haifeng Wang"
      ],
      "abstract": "World models have attracted increasing attention in autonomous driving for\ntheir ability to forecast potential future scenarios. In this paper, we propose\nBEVWorld, a novel framework that transforms multimodal sensor inputs into a\nunified and compact Bird's Eye View (BEV) latent space for holistic environment\nmodeling. The proposed world model consists of two main components: a\nmulti-modal tokenizer and a latent BEV sequence diffusion model. The\nmulti-modal tokenizer first encodes heterogeneous sensory data, and its decoder\nreconstructs the latent BEV tokens into LiDAR and surround-view image\nobservations via ray-casting rendering in a self-supervised manner. This\nenables joint modeling and bidirectional encoding-decoding of panoramic imagery\nand point cloud data within a shared spatial representation. On top of this,\nthe latent BEV sequence diffusion model performs temporally consistent\nforecasting of future scenes, conditioned on high-level action tokens, enabling\nscene-level reasoning over time. Extensive experiments demonstrate the\neffectiveness of BEVWorld on autonomous driving benchmarks, showcasing its\ncapability in realistic future scene generation and its benefits for downstream\ntasks such as perception and motion prediction.",
      "tldr_zh": "本论文提出 BEVWorld，一种多模态世界模拟器，通过场景级 BEV 潜在空间统一处理传感器输入，实现自动驾驶环境的整体建模。\n框架的核心组件包括多模态 tokenizer，用于编码异构数据并自监督方式重建 LiDAR 和环视图像，以及潜在 BEV 序列扩散模型，支持基于高水平动作令牌的时空一致未来场景预测。\n实验结果显示，BEVWorld 在自动驾驶基准上表现出色，能够生成真实场景并提升下游任务如感知和运动预测的性能。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "10 pages",
      "pdf_url": "http://arxiv.org/pdf/2407.05679v3",
      "published_date": "2024-07-08 07:26:08 UTC",
      "updated_date": "2025-04-30 13:43:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:45:19.818829"
    },
    {
      "arxiv_id": "2407.05674v2",
      "title": "Coding Reliable LLM-based Integrated Task and Knowledge Agents with GenieWorksheets",
      "title_zh": "翻译失败",
      "authors": [
        "Harshit Joshi",
        "Shicheng Liu",
        "James Chen",
        "Robert Weigle",
        "Monica S. Lam"
      ],
      "abstract": "Large Language Models (LLMs) present an opportunity to create automated\nassistants that can help users navigate complex tasks. However, existing\napproaches have limitations in handling conditional logic, integrating\nknowledge sources, and consistently following instructions. Researchers and\nindustry professionals often employ ad hoc pipelines to construct\nconversational agents. These pipelines aim to maintain context, address failure\ncases, and minimize hallucinations, yet frequently fail to achieve these\nobjectives. To this end, we present Genie - a programmable framework for\ncreating task-oriented conversational agents that are designed to handle\ncomplex user interactions and knowledge queries. Unlike LLMs, Genie provides\nreliable grounded responses, with controllable agent policies through its\nexpressive specification, Genie Worksheet. In contrast to dialog trees, it is\nresilient to diverse user queries, helpful with knowledge sources, and offers\nease of programming policies through its declarative paradigm. The agents built\nusing Genie outperforms the state-of-the-art method on complex logic domains in\nSTARV2 dataset by up to 20.5%. Additionally, through a real-user study\ninvolving 62 participants, we show that Genie beats the GPT-4 with function\ncalling baseline by 21.1%, 20.1%, and 61% on execution accuracy, dialogue act\naccuracy, and goal completion rate, respectively, on three diverse real-world\ndomains",
      "tldr_zh": "本文提出 Genie 框架，利用 Genie Worksheet 来构建可靠的基于 LLM 的集成任务和知识代理，以解决现有方法在处理条件逻辑、整合知识来源和遵守指令方面的局限。Genie 通过表达性规范提供可控的代理策略，支持多样化用户查询和知识整合，并采用声明式范式便于编程策略。与对话树不同，该框架在 STARV2 数据集的复杂逻辑领域比最先进方法高出 20.5%。在涉及 62 名参与者的真实用户研究中，Genie 分别在执行准确性、对话行为准确性和目标完成率上优于 GPT-4 with function calling 基线，分别提高 21.1%、20.1% 和 61%。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.PL"
      ],
      "primary_category": "cs.AI",
      "comment": "preprint",
      "pdf_url": "http://arxiv.org/pdf/2407.05674v2",
      "published_date": "2024-07-08 07:17:40 UTC",
      "updated_date": "2024-10-31 02:02:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:45:33.091885"
    },
    {
      "arxiv_id": "2407.05671v1",
      "title": "MSTF: Multiscale Transformer for Incomplete Trajectory Prediction",
      "title_zh": "翻译失败",
      "authors": [
        "Zhanwen Liu",
        "Chao Li",
        "Nan Yang",
        "Yang Wang",
        "Jiaqi Ma",
        "Guangliang Cheng",
        "Xiangmo Zhao"
      ],
      "abstract": "Motion forecasting plays a pivotal role in autonomous driving systems,\nenabling vehicles to execute collision warnings and rational local-path\nplanning based on predictions of the surrounding vehicles. However, prevalent\nmethods often assume complete observed trajectories, neglecting the potential\nimpact of missing values induced by object occlusion, scope limitation, and\nsensor failures. Such oversights inevitably compromise the accuracy of\ntrajectory predictions. To tackle this challenge, we propose an end-to-end\nframework, termed Multiscale Transformer (MSTF), meticulously crafted for\nincomplete trajectory prediction. MSTF integrates a Multiscale Attention Head\n(MAH) and an Information Increment-based Pattern Adaptive (IIPA) module.\nSpecifically, the MAH component concurrently captures multiscale motion\nrepresentation of trajectory sequence from various temporal granularities,\nutilizing a multi-head attention mechanism. This approach facilitates the\nmodeling of global dependencies in motion across different scales, thereby\nmitigating the adverse effects of missing values. Additionally, the IIPA module\nadaptively extracts continuity representation of motion across time steps by\nanalyzing missing patterns in the data. The continuity representation\ndelineates motion trend at a higher level, guiding MSTF to generate predictions\nconsistent with motion continuity. We evaluate our proposed MSTF model using\ntwo large-scale real-world datasets. Experimental results demonstrate that MSTF\nsurpasses state-of-the-art (SOTA) models in the task of incomplete trajectory\nprediction, showcasing its efficacy in addressing the challenges posed by\nmissing values in motion forecasting for autonomous driving systems.",
      "tldr_zh": "该研究针对自动驾驶系统中运动预测面临的缺失值问题（如物体遮挡和传感器故障），提出了一种端到端框架Multiscale Transformer (MSTF)，用于处理不完整轨迹预测。MSTF 整合了Multiscale Attention Head (MAH)模块来捕捉多尺度运动表示，通过多头注意力机制建模不同时间粒度的全局依赖，从而缓解缺失值的影响；同时，Information Increment-based Pattern Adaptive (IIPA)模块分析缺失模式，提取运动连续性表示，以指导生成与运动趋势一致的预测。实验结果显示，在两个大规模真实数据集上，MSTF 超过了state-of-the-art (SOTA)模型，证明了其在提升不完整轨迹预测准确性方面的有效性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.05671v1",
      "published_date": "2024-07-08 07:10:17 UTC",
      "updated_date": "2024-07-08 07:10:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:45:44.093857"
    },
    {
      "arxiv_id": "2407.05669v1",
      "title": "Fractional Budget Allocation for Influence Maximization under General Marketing Strategies",
      "title_zh": "翻译失败",
      "authors": [
        "Akhil Bhimaraju",
        "Eliot W. Robson",
        "Lav R. Varshney",
        "Abhishek K. Umrawal"
      ],
      "abstract": "We consider the fractional influence maximization problem, i.e., identifying\nusers on a social network to be incentivized with potentially partial discounts\nto maximize the influence on the network. The larger the discount given to a\nuser, the higher the likelihood of its activation (adopting a new product or\ninnovation), who then attempts to activate its neighboring users, causing a\ncascade effect of influence through the network. Our goal is to devise\nefficient algorithms that assign initial discounts to the network's users to\nmaximize the total number of activated users at the end of the cascade, subject\nto a constraint on the total sum of discounts given. In general, the activation\nlikelihood could be any non-decreasing function of the discount, whereas, our\nfocus lies on the case when the activation likelihood is an affine function of\nthe discount, potentially varying across different users. As this problem is\nshown to be NP-hard, we propose and analyze an efficient (1-1/e)-approximation\nalgorithm. Furthermore, we run experiments on real-world social networks to\nshow the performance and scalability of our method.",
      "tldr_zh": "本文探讨了在社交网络中，通过分配部分折扣来最大化影响力的 fractional budget allocation 问题，目标是最大化最终激活用户数量，同时满足总折扣约束。论文假设激活可能性是 affine function 的非递减函数，并证明该问题是 NP-hard，随后提出一个高效的 (1-1/e)-approximation 算法来解决这一挑战。通过在真实社交网络上的实验，验证了算法的性能和可扩展性，为一般营销策略下的影响最大化提供了实用方法。",
      "categories": [
        "cs.SI",
        "cs.AI",
        "cs.DS",
        "stat.ML",
        "05C85, 60J60, 68R05, 68R10, 68T01, 90C27, 90C35",
        "F.2.2; G.1.2; G.1.6; G.2.1; G.2.2; G.3; I.2.0; J.4"
      ],
      "primary_category": "cs.SI",
      "comment": "5 pages, 2 figures, and 1 table",
      "pdf_url": "http://arxiv.org/pdf/2407.05669v1",
      "published_date": "2024-07-08 07:09:11 UTC",
      "updated_date": "2024-07-08 07:09:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:45:56.402924"
    },
    {
      "arxiv_id": "2407.05664v2",
      "title": "How DNNs break the Curse of Dimensionality: Compositionality and Symmetry Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Arthur Jacot",
        "Seok Hoan Choi",
        "Yuxiao Wen"
      ],
      "abstract": "We show that deep neural networks (DNNs) can efficiently learn any\ncomposition of functions with bounded $F_{1}$-norm, which allows DNNs to break\nthe curse of dimensionality in ways that shallow networks cannot. More\nspecifically, we derive a generalization bound that combines a covering number\nargument for compositionality, and the $F_{1}$-norm (or the related Barron\nnorm) for large width adaptivity. We show that the global minimizer of the\nregularized loss of DNNs can fit for example the composition of two functions\n$f^{*}=h\\circ g$ from a small number of observations, assuming $g$ is\nsmooth/regular and reduces the dimensionality (e.g. $g$ could be the quotient\nmap of the symmetries of $f^{*}$), so that $h$ can be learned in spite of its\nlow regularity. The measures of regularity we consider is the Sobolev norm with\ndifferent levels of differentiability, which is well adapted to the $F_{1}$\nnorm. We compute scaling laws empirically and observe phase transitions\ndepending on whether $g$ or $h$ is harder to learn, as predicted by our theory.",
      "tldr_zh": "本论文证明了深度神经网络 (DNNs) 通过学习函数的组合性 (compositionality) 和对称性 (symmetry) 可以打破维度的诅咒 (curse of dimensionality)，从而高效处理具有 bounded $F_{1}$-norm 的函数组合。研究推导了泛化边界，结合 covering number 的组合性论据和 $F_{1}$-norm 或 Barron norm 的宽度适应性，展示了 DNNs 如何从少量观察中拟合函数组合 $f^{*}=h\\circ g$，其中 $g$ 需平滑并减少维度，即使 $h$ 的规则性较低（如使用 Sobolev norm 衡量）。实验计算了缩放定律，并观察到相变现象，取决于 $g$ 或 $h$ 哪个更难学习，从而验证了理论预测。",
      "categories": [
        "stat.ML",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "stat.ML",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.05664v2",
      "published_date": "2024-07-08 06:59:29 UTC",
      "updated_date": "2025-03-06 13:40:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:46:10.184914"
    },
    {
      "arxiv_id": "2407.17508v1",
      "title": "Artificial Intelligence Based Navigation in Quasi Structured Environment",
      "title_zh": "基于人工智能的准结构化环境导航",
      "authors": [
        "Hariram Sampath Kumar",
        "Archana Singh",
        "Manish Kumar Ojha"
      ],
      "abstract": "The proper planning of different types of public transportation such as\nmetro, highway, waterways, and so on, can increase the efficiency, reduce the\ncongestion and improve the safety of the country. There are certain challenges\nassociated with route planning, such as high cost of implementation, need for\nadequate resource & infrastructure and resistance to change. The goal of this\nresearch is to examine the working, applications, complexity factors,\nadvantages & disadvantages of Floyd- Warshall, Bellman-Ford, Johnson, Ant\nColony Optimization (ACO), Particle Swarm Optimization (PSO), & Grey Wolf\nOptimizer (GWO), to find the best choice for the above application. In this\npaper, comparative analysis of above-mentioned algorithms is presented. The\nFloyd-Warshall method and ACO algorithm are chosen based on the comparisons.\nAlso, a combination of modified Floyd-Warshall with ACO algorithm is proposed.\nThe proposed algorithm showed better results with less time complexity, when\napplied on randomly structured points within a boundary called quasi-structured\npoints. In addition, this paper also discusses the future works of integrating\nFloyd-Warshall with ACO to develop a real-time model for overcoming above\nmentioned-challenges during transportation route planning.",
      "tldr_zh": "该研究探讨了人工智能在准结构化环境（Quasi Structured Environment）中用于公共交通路线规划的挑战，旨在提高效率、减少拥堵并提升安全。通过比较Floyd-Warshall、Bellant-Ford、Johnson、Ant Colony Optimization (ACO)、Particle Swarm Optimization (PSO) 和 Grey Wolf Optimizer (GWO) 等算法的性能、复杂性和优缺点，选择了Floyd-Warshall和ACO作为最佳方案。论文提出了一种结合修改版Floyd-Warshall与ACO的混合算法，在随机准结构化点上实现了更低的时复杂性和更好结果。最后，讨论了未来将该算法整合为实时模型，以应对交通规划中的实际挑战。",
      "categories": [
        "cs.NE",
        "cs.AI"
      ],
      "primary_category": "cs.NE",
      "comment": "10 pages, 8 figures",
      "pdf_url": "http://arxiv.org/pdf/2407.17508v1",
      "published_date": "2024-07-08 06:42:02 UTC",
      "updated_date": "2024-07-08 06:42:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:46:19.692357"
    },
    {
      "arxiv_id": "2407.05650v3",
      "title": "The Cooperative Network Architecture: Learning Structured Networks as Representation of Sensory Patterns",
      "title_zh": "合作网络架构：学习结构化网络作为感官模式的表示",
      "authors": [
        "Pascal J. Sager",
        "Jan M. Deriu",
        "Benjamin F. Grewe",
        "Thilo Stadelmann",
        "Christoph von der Malsburg"
      ],
      "abstract": "We introduce the Cooperative Network Architecture (CNA), a model that\nrepresents sensory signals using structured, recurrently connected networks of\nneurons, termed \"nets.\" Nets are dynamically assembled from overlapping net\nfragments, which are learned based on statistical regularities in sensory\ninput. This architecture offers robustness to noise, deformation, and\nout-of-distribution data, addressing challenges in current vision systems from\na novel perspective. We demonstrate that net fragments can be learned without\nsupervision and flexibly recombined to encode novel patterns, enabling figure\ncompletion and resilience to noise. Our findings establish CNA as a promising\nparadigm for developing neural representations that integrate local feature\nprocessing with global structure formation, providing a foundation for future\nresearch on invariant object recognition.",
      "tldr_zh": "本研究引入了 Cooperative Network Architecture (CNA)，一种使用结构化、循环连接的神经元网络（nets）来表示感觉信号的模型。nets 通过从重叠的 net 碎片动态组装而成，这些碎片基于感觉输入的统计规律性进行无监督学习，从而实现对噪声、变形和分布外数据的鲁棒性。实验结果显示，CNA 能灵活重组 net 碎片以编码新模式，支持图形完成和抗噪，并为整合局部特征处理与全局结构形成的神经表示提供了一个新范式，为不变物体识别奠定基础。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "cs.NE"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.05650v3",
      "published_date": "2024-07-08 06:22:10 UTC",
      "updated_date": "2025-03-20 20:44:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:46:34.994072"
    },
    {
      "arxiv_id": "2407.05649v5",
      "title": "Greener GRASS: Enhancing GNNs with Encoding, Rewiring, and Attention",
      "title_zh": "翻译失败",
      "authors": [
        "Tongzhou Liao",
        "Barnabás Póczos"
      ],
      "abstract": "Graph Neural Networks (GNNs) have become important tools for machine learning\non graph-structured data. In this paper, we explore the synergistic combination\nof graph encoding, graph rewiring, and graph attention, by introducing Graph\nAttention with Stochastic Structures (GRASS), a novel GNN architecture. GRASS\nutilizes relative random walk probabilities (RRWP) encoding and a novel\ndecomposed variant (D-RRWP) to efficiently capture structural information. It\nrewires the input graph by superimposing a random regular graph to enhance\nlong-range information propagation. It also employs a novel additive attention\nmechanism tailored for graph-structured data. Our empirical evaluations\ndemonstrate that GRASS achieves state-of-the-art performance on multiple\nbenchmark datasets, including a 20.3% reduction in mean absolute error on the\nZINC dataset.",
      "tldr_zh": "本文提出Greener GRASS，一种新型Graph Neural Networks (GNNs) 架构，通过整合图编码、图重连和注意力机制来提升图结构数据的处理能力。GRASS 利用相对随机游走概率 (RRWP) 编码及其分解变体 (D-RRWP) 捕获结构信息，并通过叠加随机规则图增强长程信息传播，同时引入针对图数据的加性注意力机制。实验评估显示，GRASS 在多个基准数据集上达到最先进性能，包括在ZINC数据集上将平均绝对误差降低20.3%。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NE"
      ],
      "primary_category": "cs.LG",
      "comment": "Published as a conference paper at ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2407.05649v5",
      "published_date": "2024-07-08 06:21:56 UTC",
      "updated_date": "2025-03-14 23:47:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:46:44.176705"
    },
    {
      "arxiv_id": "2407.05611v1",
      "title": "GenFollower: Enhancing Car-Following Prediction with Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Xianda Chen",
        "Mingxing Peng",
        "PakHin Tiu",
        "Yuanfei Wu",
        "Junjie Chen",
        "Meixin Zhu",
        "Xinhu Zheng"
      ],
      "abstract": "Accurate modeling of car-following behaviors is essential for various\napplications in traffic management and autonomous driving systems. However,\ncurrent approaches often suffer from limitations like high sensitivity to data\nquality and lack of interpretability. In this study, we propose GenFollower, a\nnovel zero-shot prompting approach that leverages large language models (LLMs)\nto address these challenges. We reframe car-following behavior as a language\nmodeling problem and integrate heterogeneous inputs into structured prompts for\nLLMs. This approach achieves improved prediction performance and\ninterpretability compared to traditional baseline models. Experiments on the\nWaymo Open datasets demonstrate GenFollower's superior performance and ability\nto provide interpretable insights into factors influencing car-following\nbehavior. This work contributes to advancing the understanding and prediction\nof car-following behaviors, paving the way for enhanced traffic management and\nautonomous driving systems.",
      "tldr_zh": "本研究提出GenFollower，一种基于大型语言模型(LLMs)的零样本提示(zero-shot prompting)方法，用于提升车跟随行为的预测准确性和可解释性。方法将车跟随行为重新表述为语言建模问题，并将异构输入整合到结构化提示中，以解决传统模型对数据质量敏感和缺乏解释性的问题。在Waymo Open数据集上的实验表明，GenFollower比基线模型表现出色，并能提供对影响行为的因素的可解释洞见。该工作为交通管理和自动驾驶系统的改进奠定了基础。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.05611v1",
      "published_date": "2024-07-08 04:54:42 UTC",
      "updated_date": "2024-07-08 04:54:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:46:55.747950"
    },
    {
      "arxiv_id": "2407.05603v1",
      "title": "WSI-VQA: Interpreting Whole Slide Images by Generative Visual Question Answering",
      "title_zh": "翻译失败",
      "authors": [
        "Pingyi Chen",
        "Chenglu Zhu",
        "Sunyi Zheng",
        "Honglin Li",
        "Lin Yang"
      ],
      "abstract": "Whole slide imaging is routinely adopted for carcinoma diagnosis and\nprognosis. Abundant experience is required for pathologists to achieve accurate\nand reliable diagnostic results of whole slide images (WSI). The huge size and\nheterogeneous features of WSIs make the workflow of pathological reading\nextremely time-consuming. In this paper, we propose a novel framework (WSI-VQA)\nto interpret WSIs by generative visual question answering. WSI-VQA shows\nuniversality by reframing various kinds of slide-level tasks in a\nquestion-answering pattern, in which pathologists can achieve\nimmunohistochemical grading, survival prediction, and tumor subtyping following\nhuman-machine interaction. Furthermore, we establish a WSI-VQA dataset which\ncontains 8672 slide-level question-answering pairs with 977 WSIs. Besides the\nability to deal with different slide-level tasks, our generative model which is\nnamed Wsi2Text Transformer (W2T) outperforms existing discriminative models in\nmedical correctness, which reveals the potential of our model to be applied in\nthe clinical scenario. Additionally, we also visualize the co-attention mapping\nbetween word embeddings and WSIs as an intuitive explanation for diagnostic\nresults. The dataset and related code are available at\nhttps://github.com/cpystan/WSI-VQA.",
      "tldr_zh": "该论文提出WSI-VQA框架，通过生成式视觉问答(Generative Visual Question Answering)来解释Whole Slide Images (WSI)，旨在简化病理学家对大型异质WSI的诊断流程，支持免疫组织化学分级、生存预测和肿瘤亚型分类等任务。研究建立了包含8672对问答对和977个WSI的WSI-VQA数据集，并开发了Wsi2Text Transformer (W2T)模型，该模型在医疗正确性上优于现有判别模型。模型还提供共注意力映射的可视化解释，以增强诊断结果的可解释性，并已在GitHub上公开数据集和代码。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted at ECCV 2024",
      "pdf_url": "http://arxiv.org/pdf/2407.05603v1",
      "published_date": "2024-07-08 04:37:32 UTC",
      "updated_date": "2024-07-08 04:37:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:47:19.265661"
    },
    {
      "arxiv_id": "2407.07921v1",
      "title": "A Trustworthy AIoT-enabled Localization System via Federated Learning and Blockchain",
      "title_zh": "翻译失败",
      "authors": [
        "Junfei Wang",
        "He Huang",
        "Jingze Feng",
        "Steven Wong",
        "Lihua Xie",
        "Jianfei Yang"
      ],
      "abstract": "There is a significant demand for indoor localization technology in smart\nbuildings, and the most promising solution in this field is using RF sensors\nand fingerprinting-based methods that employ machine learning models trained on\ncrowd-sourced user data gathered from IoT devices. However, this raises\nsecurity and privacy issues in practice. Some researchers propose to use\nfederated learning to partially overcome privacy problems, but there still\nremain security concerns, e.g., single-point failure and malicious attacks. In\nthis paper, we propose a framework named DFLoc to achieve precise 3D\nlocalization tasks while considering the following two security concerns.\nParticularly, we design a specialized blockchain to decentralize the framework\nby distributing the tasks such as model distribution and aggregation which are\nhandled by a central server to all clients in most previous works, to address\nthe issue of the single-point failure for a reliable and accurate indoor\nlocalization system. Moreover, we introduce an updated model verification\nmechanism within the blockchain to alleviate the concern of malicious node\nattacks. Experimental results substantiate the framework's capacity to deliver\naccurate 3D location predictions and its superior resistance to the impacts of\nsingle-point failure and malicious attacks when compared to conventional\ncentralized federated learning systems.",
      "tldr_zh": "本文提出了一种可信的 AIoT 启用定位系统 DFLoc，通过 Federated Learning 和 Blockchain 技术来解决室内定位中的安全和隐私问题。DFLoc 框架使用区块链分散化模型分发和聚合任务，避免单点故障，并引入模型验证机制来抵御恶意节点攻击。实验结果表明，该系统在 3D 定位任务中实现精确预测，并比传统集中式 Federated Learning 系统更能抵抗单点故障和恶意攻击的影响。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG",
        "eess.SP"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.07921v1",
      "published_date": "2024-07-08 04:14:19 UTC",
      "updated_date": "2024-07-08 04:14:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:47:21.080283"
    },
    {
      "arxiv_id": "2407.05580v1",
      "title": "$\\mathrm{E^{2}CFD}$: Towards Effective and Efficient Cost Function Design for Safe Reinforcement Learning via Large Language Model",
      "title_zh": "翻译失败",
      "authors": [
        "Zepeng Wang",
        "Chao Ma",
        "Linjiang Zhou",
        "Libing Wu",
        "Lei Yang",
        "Xiaochuan Shi",
        "Guojun Peng"
      ],
      "abstract": "Different classes of safe reinforcement learning algorithms have shown\nsatisfactory performance in various types of safety requirement scenarios.\nHowever, the existing methods mainly address one or several classes of specific\nsafety requirement scenario problems and cannot be applied to arbitrary safety\nrequirement scenarios. In addition, the optimization objectives of existing\nreinforcement learning algorithms are misaligned with the task requirements.\nBased on the need to address these issues, we propose $\\mathrm{E^{2}CFD}$, an\neffective and efficient cost function design framework. $\\mathrm{E^{2}CFD}$\nleverages the capabilities of a large language model (LLM) to comprehend\nvarious safety scenarios and generate corresponding cost functions. It\nincorporates the \\textit{fast performance evaluation (FPE)} method to\nfacilitate rapid and iterative updates to the generated cost function. Through\nthis iterative process, $\\mathrm{E^{2}CFD}$ aims to obtain the most suitable\ncost function for policy training, tailored to the specific tasks within the\nsafety scenario. Experiments have proven that the performance of policies\ntrained using this framework is superior to traditional safe reinforcement\nlearning algorithms and policies trained with carefully designed cost\nfunctions.",
      "tldr_zh": "该研究针对安全强化学习(safe reinforcement learning)算法的局限性，即仅适用于特定安全场景且优化目标与任务要求不一致，提出了一种有效且高效的成本函数设计框架$\\mathrm{E^{2}CFD}$。$\\mathrm{E^{2}CFD}$利用大型语言模型(LLM)来理解各种安全场景并生成相应的成本函数，同时结合快速性能评估(FPE)方法进行快速迭代更新，以获得最适合任务的成本函数。实验结果表明，使用该框架训练的策略性能优于传统安全强化学习算法和手动设计的成本函数，从而提升了算法的通用性和有效性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.05580v1",
      "published_date": "2024-07-08 03:30:25 UTC",
      "updated_date": "2024-07-08 03:30:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:47:33.728806"
    },
    {
      "arxiv_id": "2407.11044v1",
      "title": "Generalizing soft actor-critic algorithms to discrete action spaces",
      "title_zh": "翻译失败",
      "authors": [
        "Le Zhang",
        "Yong Gu",
        "Xin Zhao",
        "Yanshuo Zhang",
        "Shu Zhao",
        "Yifei Jin",
        "Xinxin Wu"
      ],
      "abstract": "ATARI is a suite of video games used by reinforcement learning (RL)\nresearchers to test the effectiveness of the learning algorithm. Receiving only\nthe raw pixels and the game score, the agent learns to develop sophisticated\nstrategies, even to the comparable level of a professional human games tester.\nIdeally, we also want an agent requiring very few interactions with the\nenvironment. Previous competitive model-free algorithms for the task use the\nvalued-based Rainbow algorithm without any policy head. In this paper, we\nchange it by proposing a practical discrete variant of the soft actor-critic\n(SAC) algorithm. The new variant enables off-policy learning using policy heads\nfor discrete domains. By incorporating it into the advanced Rainbow variant,\ni.e., the ``bigger, better, faster'' (BBF), the resulting SAC-BBF improves the\nprevious state-of-the-art interquartile mean (IQM) from 1.045 to 1.088, and it\nachieves these results using only replay ratio (RR) 2. By using lower RR 2, the\ntraining time of SAC-BBF is strictly one-third of the time required for BBF to\nachieve an IQM of 1.045 using RR 8. As a value of IQM greater than one\nindicates super-human performance, SAC-BBF is also the only model-free\nalgorithm with a super-human level using only RR 2. The code is publicly\navailable on GitHub at https://github.com/lezhang-thu/bigger-better-faster-SAC.",
      "tldr_zh": "本论文探讨了将 Soft Actor-Critic (SAC) 算法泛化到离散动作空间，以提升强化学习（RL）在 ATARI 游戏环境中的性能。作者提出了一种实用的离散 SAC 变体，支持 off-policy 学习，并将其整合到先进的 BBF（bigger, better, faster）框架中，形成 SAC-BBF 算法。该方法显著提高了 interquartile mean (IQM) 从 1.045 到 1.088，同时使用更低的 replay ratio (RR) 2，训练时间仅为 BBF 的三分之一，实现了超人类水平的性能。代码已在 GitHub 上开源。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Chinese Conference on Pattern Recognition and Computer Vision (PRCV)\n  2024. GitHub Repo https://github.com/lezhang-thu/bigger-better-faster-SAC",
      "pdf_url": "http://arxiv.org/pdf/2407.11044v1",
      "published_date": "2024-07-08 03:20:45 UTC",
      "updated_date": "2024-07-08 03:20:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:47:46.514673"
    },
    {
      "arxiv_id": "2407.05557v1",
      "title": "$R^2$-Guard: Robust Reasoning Enabled LLM Guardrail via Knowledge-Enhanced Logical Reasoning",
      "title_zh": "翻译失败",
      "authors": [
        "Mintong Kang",
        "Bo Li"
      ],
      "abstract": "As LLMs become increasingly prevalent across various applications, it is\ncritical to establish safety guardrails to moderate input/output content of\nLLMs. Existing guardrail models treat various safety categories independently\nand fail to explicitly capture the intercorrelations among them. This has led\nto limitations such as ineffectiveness due to inadequate training on long-tail\ndata from correlated safety categories, susceptibility to jailbreaking attacks,\nand inflexibility regarding new safety categories. To address these\nlimitations, we propose $R^2$-Guard, a robust reasoning enabled LLM guardrail\nvia knowledge-enhanced logical reasoning. Specifically, $R^2$-Guard comprises\ntwo parts: data-driven category-specific learning and reasoning components. The\ndata-driven guardrail models provide unsafety probabilities of moderated\ncontent on different safety categories. We then encode safety knowledge among\ndifferent categories as first-order logical rules and embed them into a\nprobabilistic graphic model (PGM) based reasoning component. The unsafety\nprobabilities of different categories from data-driven guardrail models are\nsent to the reasoning component for final inference. We employ two types of\nPGMs: Markov logic networks (MLNs) and probabilistic circuits (PCs), and\noptimize PCs to achieve precision-efficiency balance via improved graph\nstructure. To further perform stress tests for guardrail models, we employ a\npairwise construction method to construct a new safety benchmark TwinSafety,\nwhich features principled categories. We demonstrate the effectiveness of\n$R^2$-Guard by comparisons with eight strong guardrail models on six safety\nbenchmarks, and demonstrate the robustness of $R^2$-Guard against four SOTA\njailbreaking attacks. $R^2$-Guard significantly surpasses SOTA method\nLlamaGuard by 30.2% on ToxicChat and by 59.5% against jailbreaking attacks.",
      "tldr_zh": "该论文提出 $R^2$-Guard，一种通过知识增强逻辑推理实现的鲁棒 LLM 安全护栏，旨在解决现有模型忽略安全类别间相关性的问题，如处理长尾数据不足和易受 jailbreaking attacks 影响。$R^2$-Guard 结合数据驱动的类别特定学习（提供不同安全类别的 unsafe 概率）和基于概率图形模型 (PGM) 的推理组件（如 Markov logic networks (MLNs) 和 probabilistic circuits (PCs)），将安全知识编码为一阶逻辑规则以进行最终推理。实验结果显示，$R^2$-Guard 在 ToxicChat 等六个安全基准上比 SOTA 方法 LlamaGuard 提升 30.2%，并在对抗四种 jailbreaking attacks 时提升 59.5%，证明其有效性和鲁棒性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.05557v1",
      "published_date": "2024-07-08 02:15:29 UTC",
      "updated_date": "2024-07-08 02:15:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:48:00.167978"
    },
    {
      "arxiv_id": "2407.05550v4",
      "title": "MEEG and AT-DGNN: Improving EEG Emotion Recognition with Music Introducing and Graph-based Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Minghao Xiao",
        "Zhengxi Zhu",
        "Kang Xie",
        "Bin Jiang"
      ],
      "abstract": "We present the MEEG dataset, a multi-modal collection of music-induced\nelectroencephalogram (EEG) recordings designed to capture emotional responses\nto various musical stimuli across different valence and arousal levels. This\npublic dataset facilitates an in-depth examination of brainwave patterns within\nmusical contexts, providing a robust foundation for studying brain network\ntopology during emotional processing. Leveraging the MEEG dataset, we introduce\nthe Attention-based Temporal Learner with Dynamic Graph Neural Network\n(AT-DGNN), a novel framework for EEG-based emotion recognition. This model\ncombines an attention mechanism with a dynamic graph neural network (DGNN) to\ncapture intricate EEG dynamics. The AT-DGNN achieves state-of-the-art (SOTA)\nperformance with an accuracy of 83.74% in arousal recognition and 86.01% in\nvalence recognition, outperforming existing SOTA methods. Comparative analysis\nwith traditional datasets, such as DEAP, further validates the model's\neffectiveness and underscores the potency of music as an emotional stimulus.\nThis study advances graph-based learning methodology in brain-computer\ninterfaces (BCI), significantly improving the accuracy of EEG-based emotion\nrecognition. The MEEG dataset and source code are publicly available at\nhttps://github.com/xmh1011/AT-DGNN.",
      "tldr_zh": "本研究引入了 MEEG 数据集，这是一个多模态音乐诱导 EEG 记录集，用于捕捉不同唤醒和情感水平下的脑波模式，从而为研究音乐情境中的脑网络拓扑提供基础。基于 MEEG 数据集，他们提出了 AT-DGNN 框架，该框架结合注意力机制和动态图神经网络 (DGNN) 来捕捉 EEG 的复杂动态，实现 EEG 基于情绪识别。实验结果显示，AT-DGNN 在唤醒识别上达到 83.74% 的准确率，在情感识别上达到 86.01%，超过了现有 SOTA 方法，并通过与 DEAP 数据集的比较验证了其有效性。该工作推进了图-based 学习在脑机接口 (BCI) 中的应用，并公开了数据集和源代码。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.05550v4",
      "published_date": "2024-07-08 01:58:48 UTC",
      "updated_date": "2024-11-18 03:55:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:48:12.538722"
    },
    {
      "arxiv_id": "2407.05538v1",
      "title": "On the Equivalence between Logic Programming and SETAF",
      "title_zh": "论逻辑编程与 SETAF 的等价性",
      "authors": [
        "João Alcântara",
        "Renan Cordeiro",
        "Samy Sá"
      ],
      "abstract": "A framework with sets of attacking arguments (SETAF) is an extension of the\nwell-known Dung's Abstract Argumentation Frameworks (AAFs) that allows joint\nattacks on arguments. In this paper, we provide a translation from Normal Logic\nPrograms (NLPs) to SETAFs and vice versa, from SETAFs to NLPs. We show that\nthere is pairwise equivalence between their semantics, including the\nequivalence between L-stable and semi-stable semantics. Furthermore, for a\nclass of NLPs called Redundancy-Free Atomic Logic Programs (RFALPs), there is\nalso a structural equivalence as these back-and-forth translations are each\nother's inverse. Then, we show that RFALPs are as expressive as NLPs by\ntransforming any NLP into an equivalent RFALP through a series of program\ntransformations already known in the literature. We also show that these\nprogram transformations are confluent, meaning that every NLP will be\ntransformed into a unique RFALP. The results presented in this paper enhance\nour understanding that NLPs and SETAFs are essentially the same formalism.\nUnder consideration in Theory and Practice of Logic Programming (TPLP).",
      "tldr_zh": "这篇论文探讨了 Normal Logic Programs (NLPs) 与 SETAFs (Sets of Attacking Arguments) 之间的等价性，其中 SETAFs 是 Dung's Abstract Argumentation Frameworks 的扩展。论文提供了从 NLPs 到 SETAFs 以及反向的双向翻译，并证明了它们在语义上等价，包括 L-stable 和 semi-stable 语义。对于 Redundancy-Free Atomic Logic Programs (RFALPs) 子类，翻译是互逆的，从而实现了结构等价。最终，论文通过程序转换展示了 RFALPs 与 NLPs 具有相同的表达性，且这些转换是 confluent 的，强化了 NLPs 和 SETAFs 本质上是同一形式主义的观点。",
      "categories": [
        "cs.AI",
        "I.2.3"
      ],
      "primary_category": "cs.AI",
      "comment": "44 pages, 5 figures. Under consideration in Theory and Practice of\n  Logic Programming (TPLP)",
      "pdf_url": "http://arxiv.org/pdf/2407.05538v1",
      "published_date": "2024-07-08 01:03:53 UTC",
      "updated_date": "2024-07-08 01:03:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:48:22.931262"
    },
    {
      "arxiv_id": "2407.05530v1",
      "title": "This&That: Language-Gesture Controlled Video Generation for Robot Planning",
      "title_zh": "翻译失败",
      "authors": [
        "Boyang Wang",
        "Nikhil Sridhar",
        "Chao Feng",
        "Mark Van der Merwe",
        "Adam Fishman",
        "Nima Fazeli",
        "Jeong Joon Park"
      ],
      "abstract": "We propose a robot learning method for communicating, planning, and executing\na wide range of tasks, dubbed This&That. We achieve robot planning for general\ntasks by leveraging the power of video generative models trained on\ninternet-scale data containing rich physical and semantic context. In this\nwork, we tackle three fundamental challenges in video-based planning: 1)\nunambiguous task communication with simple human instructions, 2) controllable\nvideo generation that respects user intents, and 3) translating visual planning\ninto robot actions. We propose language-gesture conditioning to generate\nvideos, which is both simpler and clearer than existing language-only methods,\nespecially in complex and uncertain environments. We then suggest a behavioral\ncloning design that seamlessly incorporates the video plans. This&That\ndemonstrates state-of-the-art effectiveness in addressing the above three\nchallenges, and justifies the use of video generation as an intermediate\nrepresentation for generalizable task planning and execution. Project website:\nhttps://cfeng16.github.io/this-and-that/.",
      "tldr_zh": "本研究提出This&That，一种结合语言和手势控制的视频生成方法，用于机器人规划和执行广泛任务。该方法利用基于互联网规模数据的视频生成模型，解决三个关键挑战：通过简单指令实现无歧义任务沟通、生成符合用户意图的可控视频，以及将视觉规划转化为机器人动作。具体而言，它采用语言-gesture conditioning技术来创建视频，并通过behavioral cloning设计无缝整合视频计划。实验结果显示，This&That在这些方面表现出state-of-the-art效果，并证明了视频生成作为通用任务规划中间表示的有效性。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.05530v1",
      "published_date": "2024-07-08 00:28:41 UTC",
      "updated_date": "2024-07-08 00:28:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:48:33.194290"
    },
    {
      "arxiv_id": "2407.05526v1",
      "title": "Can Machines Learn the True Probabilities?",
      "title_zh": "机器能否学习真实的概率？",
      "authors": [
        "Jinsook Kim"
      ],
      "abstract": "When there exists uncertainty, AI machines are designed to make decisions so\nas to reach the best expected outcomes. Expectations are based on true facts\nabout the objective environment the machines interact with, and those facts can\nbe encoded into AI models in the form of true objective probability functions.\nAccordingly, AI models involve probabilistic machine learning in which the\nprobabilities should be objectively interpreted. We prove under some basic\nassumptions when machines can learn the true objective probabilities, if any,\nand when machines cannot learn them.",
      "tldr_zh": "这篇论文探讨了 AI 机器在不确定性环境中是否能学习 true objective probabilities，以做出最佳预期决策。作者基于一些基本假设，对 probabilistic machine learning 中的概率进行客观解释，并证明了机器在特定条件下能够学习这些真实概率，而在其他条件下则无法实现。该研究为理解 AI 模型与客观环境互动的局限性提供了重要理论基础。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.05526v1",
      "published_date": "2024-07-08 00:19:43 UTC",
      "updated_date": "2024-07-08 00:19:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:48:44.181587"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 117,
  "processed_papers_count": 117,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-19T04:49:05.033028"
}