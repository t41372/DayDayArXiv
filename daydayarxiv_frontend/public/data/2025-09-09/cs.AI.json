{
  "date": "2025-09-09",
  "category": "cs.AI",
  "summary": "æ¬¢è¿æ¥åˆ° UTC æ—¶é—´ 2025-09-09 çš„ arXiv ä¸­æ–‡ TLDR å¿«æŠ¥ï¼\n\n**ä¸€å¥è¯æ€»ç»“ï¼š**\nä»Šå¤©çš„ arXiv å……æ»¡äº†å¯¹æŠ—æ€§ä¸çªç ´æ€§â€”â€”**æ¨ç†ï¼ˆReasoningï¼‰èƒ½åŠ›çš„ Scaling Law** ä¾ç„¶æ˜¯æ ¸å¿ƒï¼Œä»å¤åˆ» OpenAI o3 çš„è§†è§‰æ¨ç†ï¼Œåˆ° Meta å›¢é˜Ÿæå‡ºçš„â€œè¯­è¨€è‡ªæˆ‘åšå¼ˆâ€æ‰“ç ´æ•°æ®ç“¶é¢ˆï¼Œå†åˆ°å­¦ç•Œå¯¹ CoT æ˜¯å¦çœŸçš„åœ¨â€œæ€è€ƒâ€çš„çŠ€åˆ©è´¨ç–‘ï¼›åŒæ—¶ï¼Œé’ˆå¯¹ç‰©ç†å’Œæ•°å­¦å¥¥èµ›çš„ tough benchmarks ç»™ç°æœ‰æ¨¡å‹æ³¼äº†ä¸€ç›†å†·æ°´ã€‚\n\n---\n\n### ğŸš€ æ·±åº¦æ¨ç†ä¸å¤§æ¨¡å‹è¿›é˜¶ (Reasoning & Agents)\n\n**1. [CV] Mini-o3: Scaling Up Reasoning Patterns and Interaction Turns for Visual Search**\n*   **ä¸­æ–‡æ ‡é¢˜ï¼š** Mini-o3ï¼šåœ¨è§†è§‰æœç´¢ä¸­æ‰©å±•æ¨ç†æ¨¡å¼ä¸äº¤äº’è½®æ¬¡\n*   **æ ¸å¿ƒäº®ç‚¹ï¼š** å¤åˆ» OpenAI o3 è¡Œä¸ºã€‚\n*   **å¤ªé•¿ä¸è¯»ï¼š** ç°æœ‰çš„å¤šæ¨¡æ€æ¨¡å‹ï¼ˆLMMï¼‰åœ¨å¤æ‚ä»»åŠ¡ä¸Šå¾€å¾€äº¤äº’è½®æ¬¡æœ‰é™ï¼Œæ¨ç†æ¨¡å¼å•ä¸€ã€‚è¿™ç¯‡æ–‡ç« æå‡ºäº† **Mini-o3**ï¼Œé€šè¿‡æ„å»º Visual Probe æ•°æ®é›†å’Œè¿­ä»£æ•°æ®æ”¶é›†ç®¡é“ï¼Œè®©æ¨¡å‹å­¦ä¼šäº†æ·±åº¦ä¼˜å…ˆæœç´¢ï¼ˆDFSï¼‰ã€è¯•é”™å’Œç›®æ ‡ç»´æŠ¤ç­‰å¤æ‚æ¨ç†æ¨¡å¼ã€‚æœ€æœ‰è¶£çš„æ˜¯ï¼Œè™½ç„¶è®­ç»ƒæ—¶é™åˆ¶åœ¨ 6 è½®äº¤äº’ï¼Œä½†å®ƒåœ¨æ¨ç†æ—¶èƒ½è‡ªç„¶æ‰©å±•åˆ°æ•°åè½®ï¼Œä¸”å‡†ç¡®ç‡éšè½®æ¬¡å¢åŠ è€Œæå‡ï¼Œå®Œç¾ä½“ç°äº† **Test-time Scaling** çš„ç‰¹æ€§ã€‚\n\n**2. [LLM] Language Self-Play For Data-Free Training**\n*   **ä¸­æ–‡æ ‡é¢˜ï¼š** è¯­è¨€è‡ªæˆ‘åšå¼ˆå®ç°æ— æ•°æ®è®­ç»ƒ\n*   **æ ¸å¿ƒäº®ç‚¹ï¼š** Meta å›¢é˜Ÿæ–°ä½œï¼ŒYuandong Tian ç­‰äººå‚ä¸ã€‚\n*   **å¤ªé•¿ä¸è¯»ï¼š** æ—¢ç„¶é«˜è´¨é‡æ•°æ®æ˜¯ç“¶é¢ˆï¼Œé‚£å°±ä¸è¦æ•°æ®äº†ã€‚ä½œè€…æå‡º **LSP (Language Self-Play)**ï¼Œå°†æ¨¡å‹èƒ½åŠ›è§†ä¸ºåœ¨ä¸€ä¸ªç«äº‰æ€§æ¸¸æˆä¸­çš„è¡¨ç°ï¼Œé€šè¿‡è®©æ¨¡å‹ä¸è‡ªå·±åšå¼ˆï¼ˆself-playï¼‰æ¥è¿›åŒ–ã€‚å®éªŒè¯æ˜ï¼ŒLlama-3.2-3B åœ¨æŒ‡ä»¤éµå¾ªã€æ•°å­¦å’Œä»£ç ä»»åŠ¡ä¸Šï¼Œä»…é è‡ªå·±è·Ÿè‡ªå·±ç©å°±èƒ½å˜å¼ºï¼Œè¿™ä¸ºæ‰“ç ´ LLM è®­ç»ƒçš„æ•°æ®å¢™æä¾›äº†ä¸€æ¡å¼ºåŠ›è·¯å¾„ã€‚\n\n**3. [LLM] Certainty-Guided Reasoning in Large Language Models: A Dynamic Thinking Budget Approach**\n*   **ä¸­æ–‡æ ‡é¢˜ï¼š** å¤§è¯­è¨€æ¨¡å‹ä¸­çš„ç¡®å®šæ€§å¼•å¯¼æ¨ç†ï¼šä¸€ç§åŠ¨æ€æ€ç»´é¢„ç®—æ–¹æ³•\n*   **æ ¸å¿ƒäº®ç‚¹ï¼š** ç»™æ¨¡å‹ä¸€ä¸ªâ€œæ€è€ƒé¢„ç®—â€ã€‚\n*   **å¤ªé•¿ä¸è¯»ï¼š** ç°åœ¨çš„æ¨ç†æ¨¡å‹ï¼ˆReasoning Modelsï¼‰å¾€å¾€æ˜¯ä¸€è‚¡è„‘è¾“å‡ºã€‚æœ¬æ–‡æå‡º **CGR**ï¼Œå¼•å…¥ä¸€ä¸ª Critic æ¨¡å‹å®šæœŸæ£€æŸ¥æ¨ç†æ˜¯å¦å·²ç»â€œç¡®ä¿¡â€ã€‚å¦‚æœç¡®ä¿¡å°±åœæ­¢ï¼Œä¸ç¡®ä¿¡å°±ç»§ç»­æƒ³ã€‚è¿™ç§åŠ¨æ€åˆ†é…è®¡ç®—èµ„æºçš„æ–¹æ³•ï¼Œæ—¢èŠ‚çœäº† Tokenï¼Œåˆåœ¨ AIME ç­‰æ•°å­¦ç«èµ›æ•°æ®é›†ä¸Šæé«˜äº†å‡†ç¡®ç‡ã€‚\n\n**4. [LLM/Critique] Performative Thinking? The Brittle Correlation Between CoT Length and Problem Complexity**\n*   **ä¸­æ–‡æ ‡é¢˜ï¼š** è¡¨æ¼”æ€§æ€è€ƒï¼ŸCoT é•¿åº¦ä¸é—®é¢˜å¤æ‚åº¦ä¹‹é—´çš„è„†å¼±ç›¸å…³æ€§\n*   **æ ¸å¿ƒäº®ç‚¹ï¼š** Subbarao Kambhampati å¤§ä½¬å›¢é˜Ÿçš„è´¨ç–‘ã€‚\n*   **å¤ªé•¿ä¸è¯»ï¼š** ç¤¾åŒºæ™®éè®¤ä¸º CoT ç”Ÿæˆçš„ Token è¶Šå¤šï¼Œä»£è¡¨æ¨¡å‹æ€è€ƒè¶Šæ·±ã€‚ä½†è¿™ç¯‡è®ºæ–‡æ‰“è„¸äº†ï¼šä½œè€…ç”¨ A* æœç´¢ç®—æ³•çš„è¿¹ï¼ˆtraceï¼‰è®­ç»ƒæ¨¡å‹ï¼Œå‘ç°å³ä¾¿åœ¨ç®€å•é—®é¢˜ä¸Šï¼Œæ¨¡å‹ä¹Ÿä¼šç”Ÿæˆå†—é•¿çš„åºŸè¯ï¼›è€Œåœ¨ OOD é—®é¢˜ä¸Šï¼ŒCoT é•¿åº¦ä¸é—®é¢˜çœŸå®å¤æ‚åº¦ç›¸å…³æ€§æä½ã€‚è¿™æš—ç¤ºç›®å‰çš„ CoT å¯èƒ½åªæ˜¯â€œè¿‘ä¼¼å›å¿†â€è€ŒéçœŸæ­£çš„â€œé’ˆå¯¹æ€§è®¡ç®—â€ã€‚\n\n---\n\n### ğŸ† æŒ‘æˆ˜äººç±»æé™ï¼šæ–°ä¸€ä»£ Benchmarks\n\n**5. [Benchmark] HiPhO: How Far Are (M)LLMs from Humans in the Latest High School Physics Olympiad Benchmark?**\n*   **ä¸­æ–‡æ ‡é¢˜ï¼š** HiPhOï¼šåœ¨æœ€æ–°çš„é«˜ä¸­ç‰©ç†å¥¥æ—åŒ¹å…‹åŸºå‡†æµ‹è¯•ä¸­ï¼Œ(M)LLMs è·ç¦»äººç±»è¿˜æœ‰å¤šè¿œï¼Ÿ\n*   **å¤ªé•¿ä¸è¯»ï¼š** æ”¶é›†äº† 2024-2025 å¹´æœ€æ–°çš„ç‰©ç†å¥¥èµ›é¢˜ï¼ˆé˜²æ­¢æ•°æ®æ³„éœ²ï¼‰ã€‚ç»“æœå¾ˆæƒ¨ï¼šå¼€æº MLLM åŸºæœ¬åœ¨é“œç‰Œçº¿ä»¥ä¸‹ï¼Œå¼€æº LLM ç¨å¾®å¥½ç‚¹ï¼Œåªæœ‰é—­æºçš„æ¨ç†æ¨¡å‹èƒ½æ‹¿åˆ°é‡‘ç‰Œï¼Œä½†è·ç¦»æ»¡åˆ†ä¾ç„¶é¥è¿œã€‚\n\n**6. [Benchmark] RIMO: An Easy-to-Evaluate, Hard-to-Solve Olympiad Benchmark for Advanced Mathematical Reasoning**\n*   **ä¸­æ–‡æ ‡é¢˜ï¼š** RIMOï¼šä¸€ä¸ªæ˜“äºè¯„ä¼°ã€éš¾ä»¥è§£å†³çš„é«˜çº§æ•°å­¦æ¨ç†å¥¥æ—åŒ¹å…‹åŸºå‡†\n*   **å¤ªé•¿ä¸è¯»ï¼š** é’ˆå¯¹ IMOï¼ˆå›½é™…æ•°å­¦å¥¥èµ›ï¼‰çº§åˆ«éš¾é¢˜ã€‚ç°æœ‰æ¨¡å‹åœ¨è€æ¦œå•ï¼ˆGSM8K, MATHï¼‰ä¸Šåˆ·åˆ†åˆ·çˆ†äº†ï¼Œä½†åœ¨ RIMO ä¸Šæ€§èƒ½æ–­å´–å¼ä¸‹è·Œã€‚GPT-4o å’Œ Gemini 1.5 Flash å‡é­é‡æ»‘é“å¢ã€‚\n\n---\n\n### ğŸ’» è½¯ç¡¬ä»¶ååŒä¸ç³»ç»Ÿä¼˜åŒ– (Systems & Hardware)\n\n**7. [Hardware/System] Lifetime-Aware Design of Item-Level Intelligence**\n*   **ä¸­æ–‡æ ‡é¢˜ï¼š** ç‰©å“çº§æ™ºèƒ½çš„å¯¿å‘½æ„ŸçŸ¥è®¾è®¡\n*   **æ ¸å¿ƒäº®ç‚¹ï¼š** Vijay Janapa Reddi å›¢é˜Ÿä½œå“ï¼Œå…³æ³¨â€œç”¨å®Œå³å¼ƒâ€çš„ç”µå­äº§å“ã€‚\n*   **å¤ªé•¿ä¸è¯»ï¼š** é’ˆå¯¹é£Ÿå“åŒ…è£…ã€åŒ»ç–—è´´ç‰‡ç­‰ä¸€æ¬¡æ€§æ™ºèƒ½äº§å“ï¼ˆItem-Level Intelligenceï¼‰ï¼Œæå‡ºäº† **FlexiFlow** æ¡†æ¶ã€‚æ ¸å¿ƒæ´å¯Ÿæ˜¯ï¼šè¿™äº›äº§å“çš„å¯¿å‘½å·®å¼‚å·¨å¤§ï¼ˆä»å‡ å°æ—¶åˆ°å‡ å‘¨ï¼‰ï¼Œè®¾è®¡æ—¶å¿…é¡»æƒè¡¡â€œéšå«ç¢³è¶³è¿¹â€å’Œâ€œè¿è¡Œç¢³è¶³è¿¹â€ã€‚ä»–ä»¬ç”šè‡³æµç‰‡éªŒè¯äº†åŸºäºæŸ”æ€§ç”µå­çš„ RISC-V æ ¸ï¼Œå±•ç¤ºäº†åœ¨æè¾¹ç¼˜è®¡ç®—åœºæ™¯ä¸‹çš„æ–°è®¾è®¡å“²å­¦ã€‚\n\n**8. [System/LLM] Astra: A Multi-Agent System for GPU Kernel Performance Optimization**\n*   **ä¸­æ–‡æ ‡é¢˜ï¼š** Astraï¼šç”¨äº GPU å†…æ ¸æ€§èƒ½ä¼˜åŒ–çš„å¤šæ™ºèƒ½ä½“ç³»ç»Ÿ\n*   **æ ¸å¿ƒäº®ç‚¹ï¼š** Alex Aiken å‚ä¸ï¼Œè‡ªåŠ¨å†™ CUDAã€‚\n*   **å¤ªé•¿ä¸è¯»ï¼š** è¿™æ˜¯ä¸€ä¸ªåŸºäº LLM çš„å¤šæ™ºèƒ½ä½“ç³»ç»Ÿï¼Œä¸“é—¨ç”¨æ¥ä¼˜åŒ– SGLang ç­‰æ¡†æ¶ä¸­çš„ GPU Kernelã€‚å®ƒä¸æ˜¯ä»å¤´å†™ï¼Œè€Œæ˜¯ä¼˜åŒ–ç°æœ‰çš„ CUDA ä»£ç ã€‚å®éªŒæ˜¾ç¤ºï¼ŒAstra èƒ½åˆ©ç”¨ loop transformations å’Œ CUDA intrinsicsï¼Œå®ç°å¹³å‡ 1.32 å€çš„åŠ é€Ÿï¼Œæ¯”äººç±»å·¥ç¨‹å¸ˆæ‰‹åŠ¨è°ƒä¼˜è¿˜è¦å¿«ã€‚\n\n**9. [Security] ImportSnare: Directed \"Code Manual\" Hijacking in Retrieval-Augmented Code Generation**\n*   **ä¸­æ–‡æ ‡é¢˜ï¼š** ImportSnareï¼šæ£€ç´¢å¢å¼ºä»£ç ç”Ÿæˆä¸­çš„å®šå‘â€œä»£ç æ‰‹å†Œâ€åŠ«æŒ\n*   **å¤ªé•¿ä¸è¯»ï¼š** è¿™æ˜¯ä¸€ä¸ªéå¸¸é˜´é™©çš„æ”»å‡»æ–¹å¼ã€‚é’ˆå¯¹ RAG è¾…åŠ©çš„ä»£ç ç”Ÿæˆï¼Œæ”»å‡»è€…åœ¨å¼€æºæ–‡æ¡£ä¸­æ³¨å…¥æ¶æ„ä¾èµ–ï¼ˆæ¯”å¦‚ `matplotlib_safe`ï¼‰ï¼Œé€šè¿‡æ“çºµæ£€ç´¢æ’åºå’Œæç¤ºè¯è¯±å¯¼ï¼Œè®© LLM åœ¨å†™ä»£ç æ—¶è‡ªåŠ¨å¼•å…¥è¿™äº›æ¶æ„åŒ…ã€‚æˆåŠŸç‡æé«˜ï¼Œä¾›åº”é“¾å®‰å…¨çš„æ–°éšæ‚£ã€‚\n\n---\n\n### ğŸ¤– æœºå™¨äººä¸å…·èº«æ™ºèƒ½ (Robotics)\n\n**10. [Robotics] Quadrotor Navigation using Reinforcement Learning with Privileged Information**\n*   **ä¸­æ–‡æ ‡é¢˜ï¼š** åˆ©ç”¨ç‰¹æƒä¿¡æ¯çš„å¼ºåŒ–å­¦ä¹ å››æ—‹ç¿¼å¯¼èˆª\n*   **å¤ªé•¿ä¸è¯»ï¼š** æ— äººæœºåœ¨é‡åˆ°å¤§å¢™æˆ–æ­»èƒ¡åŒå®¹æ˜“å¡æ­»ã€‚è¿™ç¯‡æ–‡ç« åœ¨è®­ç»ƒæ—¶å¼•å…¥â€œç‰¹æƒä¿¡æ¯â€ï¼ˆPrivileged Informationï¼Œå¦‚åˆ°è¾¾æ—¶é—´å›¾ï¼‰ï¼Œè®­ç»ƒå®Œåéƒ¨ç½²æ—¶ä¸éœ€è¦è¿™äº›ä¿¡æ¯ã€‚ç»“æœå®ç°äº† 86% çš„æˆåŠŸç‡ï¼Œæ¯”åŸºçº¿é«˜å‡º 34%ï¼Œèƒ½åœ¨å¤œé—´å¤æ‚ç¯å¢ƒä¸­ä»¥ 4m/s é£å¥”ã€‚\n\n**11. [Robotics] Text2Touch: Tactile In-Hand Manipulation with LLM-Designed Reward Functions**\n*   **ä¸­æ–‡æ ‡é¢˜ï¼š** Text2Touchï¼šåˆ©ç”¨ LLM è®¾è®¡å¥–åŠ±å‡½æ•°çš„è§¦è§‰æ‰‹å†…æ“ä½œ\n*   **å¤ªé•¿ä¸è¯»ï¼š** è®© LLM æ¥å†™å¼ºåŒ–å­¦ä¹ çš„ Reward Functionï¼Œè¿™æ¬¡æ˜¯ç”¨åœ¨æéš¾çš„â€œå¸¦è§¦è§‰åé¦ˆçš„çµå·§æ‰‹æ“ä½œâ€ä¸Šã€‚LLM å†™å‡ºçš„å¥–åŠ±å‡½æ•°æ¯”äººç±»ç²¾å¿ƒè®¾è®¡çš„è¦çŸ­ä¸€ä¸ªæ•°é‡çº§ï¼Œä½†æ•ˆæœæ›´å¥½ï¼Œèƒ½è®©æœºå™¨äººæ‰‹ç©è½¬ç‰©ä½“æ›´ç¨³å®šã€‚\n\n---\n\n### ğŸ§¬ ç§‘å­¦ä¸åº”ç”¨ (Science & Interesting Apps)\n\n**12. [Physics/Materials] Benchmarking Universal Interatomic Potentials on Zeolite Structures**\n*   **ä¸­æ–‡æ ‡é¢˜ï¼š** åœ¨æ²¸çŸ³ç»“æ„ä¸ŠåŸºå‡†æµ‹è¯•é€šç”¨åŸå­é—´åŠ¿\n*   **å¤ªé•¿ä¸è¯»ï¼š** æ²¸çŸ³æ˜¯åŒ–å·¥ç¥æ–™ã€‚æ–‡ç« è¯„æµ‹äº†åŒ…æ‹¬ GFN-FF å’Œå„ç§æœºå™¨å­¦ä¹ åŠ¿ï¼ˆMLIPs å¦‚ CHGNet, MACE ç­‰ï¼‰ã€‚ç»“è®ºæ˜¯ï¼šç°ä»£é¢„è®­ç»ƒçš„ MLIPs å·²ç»éå¸¸å¼ºäº†ï¼Œç‰¹åˆ«æ˜¯ eSEN-30M-OAM æ¨¡å‹ï¼Œèƒ½å¾ˆå¥½åœ°å¤ç° DFT çº§åˆ«çš„ç²¾åº¦ã€‚\n\n**13. [Medical/Design] Lifetime-Aware Design... (Wait, checked above)** -> **[Medical] ToothMCL: Multimodal Contrastive Pretraining of CBCT and IOS for Enhanced Tooth Segmentation**\n*   **ä¸­æ–‡æ ‡é¢˜ï¼š** ToothMCLï¼šç”¨äºå¢å¼ºç‰™é½¿åˆ†å‰²çš„ CBCT å’Œ IOS å¤šæ¨¡æ€å¯¹æ¯”é¢„è®­ç»ƒ\n*   **å¤ªé•¿ä¸è¯»ï¼š** ç‰™ç§‘é¦–ä¸ªå¤šæ¨¡æ€é¢„è®­ç»ƒæ¡†æ¶ã€‚ç»“åˆäº† CTï¼ˆä½“ç§¯æ•°æ®ï¼‰å’Œå£æ‰«ï¼ˆè¡¨é¢æ•°æ®ï¼‰ï¼Œå‘å¸ƒäº†è¿„ä»Šæœ€å¤§çš„é…å¯¹æ•°æ®é›†ï¼ˆ3800+æ‚£è€…ï¼‰ã€‚åˆ†å‰²ç²¾åº¦æ˜¾è‘—æå‡ï¼Œæ•°å­—åŒ–ç‰™ç§‘çš„é‡è¦ä¸€æ­¥ã€‚\n\n**14. [Music/AI] BREATH: A Bio-Radar Embodied Agent for Tonal and Human-Aware Diffusion Music Generation**\n*   **ä¸­æ–‡æ ‡é¢˜ï¼š** BREATHï¼šä¸€ä¸ªç”¨äºéŸ³è°ƒå’Œäººç±»æ„ŸçŸ¥æ‰©æ•£éŸ³ä¹ç”Ÿæˆçš„ç”Ÿç‰©é›·è¾¾å…·èº«æ™ºèƒ½ä½“\n*   **å¤ªé•¿ä¸è¯»ï¼š**ç”¨æ¯«ç±³æ³¢é›·è¾¾æµ‹å¿ƒè·³å’Œå‘¼å¸ï¼Œç„¶åç”¨ LLM åˆ†æä½ çš„çŠ¶æ€ï¼Œæœ€åæ§åˆ¶ Diffusion æ¨¡å‹ç”Ÿæˆç¬¦åˆä½ å½“å‰ mood çš„éŸ³ä¹ï¼ˆç”šè‡³åŒ…å«ä¸­å›½äº”å£°éŸ³é˜¶ï¼‰ã€‚\n\n---\n\n### ğŸ’¡ ç†è®ºä¸è§†è§’ (Theory)\n\n**15. [Theory] XML Prompting as Grammar-Constrained Interaction**\n*   **ä¸­æ–‡æ ‡é¢˜ï¼š** XML æç¤ºä½œä¸ºè¯­æ³•çº¦æŸäº¤äº’\n*   **å¤ªé•¿ä¸è¯»ï¼š** ä¸ºä»€ä¹ˆ XML æ ¼å¼çš„ Prompt æ•ˆæœå¥½ï¼Ÿè¿™ç¯‡æ–‡ç« ç»™å‡ºäº†æ•°å­¦è§£é‡Šã€‚å®ƒå°† XML æç¤ºå½¢å¼åŒ–ä¸ºæ ¼ï¼ˆlatticeï¼‰ä¸Šçš„ä¸åŠ¨ç‚¹è¯­ä¹‰ï¼Œè¯æ˜äº†è¿™ç§çº¦æŸè§£ç èƒ½ä¿è¯è¾“å‡ºæ—¢ç¬¦åˆè¯­æ³•åˆèƒ½ä¿æŒä»»åŠ¡æ€§èƒ½ã€‚å±äº Prompt Engineering çš„ç¡¬æ ¸ç†è®ºæ”¯æ’‘ã€‚\n\n**16. [Social] Individual utilities of life satisfaction reveal inequality aversion unrelated to political alignment**\n*   **ä¸­æ–‡æ ‡é¢˜ï¼š** ç”Ÿæ´»æ»¡æ„åº¦çš„ä¸ªäººæ•ˆç”¨æ­ç¤ºäº†ä¸æ”¿æ²»ç«‹åœºæ— å…³çš„ä¸å¹³ç­‰åŒæ¶\n*   **å¤ªé•¿ä¸è¯»ï¼š** æ— è®ºä½ æ˜¯å·¦æ´¾è¿˜æ˜¯å³æ´¾ï¼Œå¤§å®¶éƒ½è®¨åŒâ€œä¸å¹³ç­‰â€ã€‚ç ”ç©¶å‘ç°äººä»¬å¯¹ç¤¾ä¼šæ•´ä½“ç”Ÿæ´»æ»¡æ„åº¦çš„ä¸å¹³ç­‰çš„åŒæ¶ï¼Œç”šè‡³è¶…è¿‡äº†å¯¹ä¸ªäººé£é™©çš„åŒæ¶ã€‚è¿™å¯¹ AI ä»·å€¼å¯¹é½ï¼ˆAlignmentï¼‰æœ‰é‡è¦å¯ç¤ºï¼šå…¬å¹³å¯èƒ½æ˜¯ä¸€ä¸ªè·¨è¶Šæ„è¯†å½¢æ€çš„å…±è¯†ç‚¹ã€‚",
  "papers": [
    {
      "arxiv_id": "2509.08193v1",
      "title": "Lifetime-Aware Design of Item-Level Intelligence",
      "title_zh": "å•å“çº§æ™ºèƒ½çš„ç”Ÿå‘½å‘¨æœŸæ„ŸçŸ¥è®¾è®¡",
      "authors": [
        "Shvetank Prakash",
        "Andrew Cheng",
        "Olof Kindgren",
        "Ashiq Ahamed",
        "Graham Knight",
        "Jed Kufel",
        "Francisco Rodriguez",
        "Arya Tschand",
        "David Kong",
        "Mariam Elgamal",
        "Jerry Huang",
        "Emma Chen",
        "Gage Hills",
        "Richard Price",
        "Emre Ozer",
        "Vijay Janapa Reddi"
      ],
      "abstract": "We present FlexiFlow, a lifetime-aware design framework for item-level intelligence (ILI) where computation is integrated directly into disposable products like food packaging and medical patches. Our framework leverages natively flexible electronics which offer significantly lower costs than silicon but are limited to kHz speeds and several thousands of gates. Our insight is that unlike traditional computing with more uniform deployment patterns, ILI applications exhibit 1000X variation in operational lifetime, fundamentally changing optimal architectural design decisions when considering trillion-item deployment scales. To enable holistic design and optimization, we model the trade-offs between embodied carbon footprint and operational carbon footprint based on application-specific lifetimes. The framework includes: (1) FlexiBench, a workload suite targeting sustainability applications from spoilage detection to health monitoring; (2) FlexiBits, area-optimized RISC-V cores with 1/4/8-bit datapaths achieving 2.65X to 3.50X better energy efficiency per workload execution; and (3) a carbon-aware model that selects optimal architectures based on deployment characteristics. We show that lifetime-aware microarchitectural design can reduce carbon footprint by 1.62X, while algorithmic decisions can reduce carbon footprint by 14.5X. We validate our approach through the first tape-out using a PDK for flexible electronics with fully open-source tools, achieving 30.9kHz operation. FlexiFlow enables exploration of computing at the Extreme Edge where conventional design methodologies must be reevaluated to account for new constraints and considerations.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† FlexiFlowï¼Œè¿™æ˜¯ä¸€ä¸ªé’ˆå¯¹å•å“çº§æ™ºèƒ½ (Item-Level Intelligence, ILI) çš„å¯¿å‘½æ„ŸçŸ¥è®¾è®¡æ¡†æ¶ï¼Œæ—¨åœ¨å°†è®¡ç®—ç›´æ¥é›†æˆåˆ°é£Ÿå“åŒ…è£…å’ŒåŒ»ç–—è´´ç‰‡ç­‰ä¸€æ¬¡æ€§äº§å“ä¸­ã€‚è¯¥æ¡†æ¶åˆ©ç”¨æˆæœ¬è¿œä½äºç¡…èŠ¯ç‰‡çš„æŸ”æ€§ç”µå­ (Flexible Electronics) æŠ€æœ¯ï¼Œé’ˆå¯¹ ILI åº”ç”¨è¿è¡Œå¯¿å‘½å·®å¼‚å·¨å¤§çš„ç‰¹å¾ï¼Œé€šè¿‡å»ºæ¨¡ä½“åŒ–ç¢³è¶³è¿¹ä¸è¿è¡Œç¢³è¶³è¿¹çš„æƒè¡¡æ¥ä¼˜åŒ–æ¶æ„è®¾è®¡ã€‚FlexiFlow åŒ…å«ä¸“é—¨çš„å·¥ä½œè´Ÿè½½å¥—ä»¶ FlexiBenchã€é¢ç§¯ä¼˜åŒ–çš„å¤šä½å®½ RISC-V æ ¸å¿ƒ FlexiBits ä»¥åŠç¢³æ„ŸçŸ¥æ¶æ„é€‰æ‹©æ¨¡å‹ï¼Œå…¶ä¸­ FlexiBits å°†èƒ½æ•ˆæå‡äº† 2.65X è‡³ 3.50Xã€‚ç ”ç©¶ç»“æœæ˜¾ç¤ºï¼Œå¯¿å‘½æ„ŸçŸ¥çš„å¾®æ¶æ„è®¾è®¡å¯å°†ç¢³è¶³è¿¹é™ä½ 1.62Xï¼Œè€Œç®—æ³•å†³ç­–å¯è¿›ä¸€æ­¥é™ä½ 14.5Xã€‚è¯¥æ–¹æ¡ˆé€šè¿‡é¦–ä¸ªåˆ©ç”¨å®Œå…¨å¼€æºå·¥å…·é“¾çš„æŸ”æ€§ç”µå­ PDK æµç‰‡è¿›è¡Œäº†éªŒè¯ï¼ŒæˆåŠŸå®ç°äº† 30.9kHz çš„è¿è¡Œé¢‘ç‡ã€‚è¿™é¡¹å·¥ä½œä¸ºé‡æ–°è¯„ä¼°æè¾¹è®¡ç®— (Extreme Edge) çš„è®¾è®¡æ–¹æ³•å­¦å¹¶å®ç°å¯æŒç»­éƒ¨ç½²æä¾›äº†é‡è¦é€”å¾„ã€‚",
      "categories": [
        "cs.AR",
        "cs.AI",
        "cs.ET"
      ],
      "primary_category": "cs.AR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.08193v1",
      "published_date": "2025-09-09 23:53:46 UTC",
      "updated_date": "2025-09-09 23:53:46 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:22:41.275618+00:00"
    },
    {
      "arxiv_id": "2509.08182v1",
      "title": "XML Prompting as Grammar-Constrained Interaction: Fixed-Point Semantics, Convergence Guarantees, and Human-AI Protocols",
      "title_zh": "XML æç¤ºä½œä¸ºè¯­æ³•çº¦æŸäº¤äº’ï¼šä¸åŠ¨ç‚¹è¯­ä¹‰ã€æ”¶æ•›æ€§ä¿è¯ä¸äººæœºåè®®",
      "authors": [
        "Faruk Alpay",
        "Taylan Alpay"
      ],
      "abstract": "Structured prompting with XML tags has emerged as an effective way to steer large language models (LLMs) toward parseable, schema-adherent outputs in real-world systems. We develop a logic-first treatment of XML prompting that unifies (i) grammar-constrained decoding, (ii) fixed-point semantics over lattices of hierarchical prompts, and (iii) convergent human-AI interaction loops. We formalize a complete lattice of XML trees under a refinement order and prove that monotone prompt-to-prompt operators admit least fixed points (Knaster-Tarski) that characterize steady-state protocols; under a task-aware contraction metric on trees, we further prove Banach-style convergence of iterative guidance. We instantiate these results with context-free grammars (CFGs) for XML schemas and show how constrained decoding guarantees well-formedness while preserving task performance. A set of multi-layer human-AI interaction recipes demonstrates practical deployment patterns, including multi-pass \"plan $\\to$ verify $\\to$ revise\" routines and agentic tool use. We provide mathematically complete proofs and tie our framework to recent advances in grammar-aligned decoding, chain-of-verification, and programmatic prompting.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§è¯­è¨€æ¨¡å‹ (LLMs) æå‡ºäº†åŸºäºé€»è¾‘ä¼˜å…ˆ (logic-first) çš„ XML Prompting å¤„ç†æ–¹æ³•ï¼Œæ—¨åœ¨é€šè¿‡ç»“æ„åŒ–æç¤ºå®ç°å¯è§£æä¸”ç¬¦åˆæ¨¡å¼ (schema-adherent) çš„è¾“å‡ºã€‚è¯¥æ¡†æ¶ç»Ÿä¸€äº†è¯­æ³•çº¦æŸè§£ç  (grammar-constrained decoding)ã€åˆ†å±‚ Prompt æ ¼ä¸Šçš„ä¸åŠ¨ç‚¹è¯­ä¹‰ (fixed-point semantics) ä»¥åŠæ”¶æ•›çš„äººæœºäº¤äº’å¾ªç¯ã€‚ä½œè€…åœ¨ç²¾åŒ–åº (refinement order) ä¸‹å½¢å¼åŒ–äº† XML æ ‘çš„å®Œå¤‡æ ¼ï¼Œå¹¶åˆ©ç”¨ Knaster-Tarski ä¸åŠ¨ç‚¹å®šç†ä¸æ”¶ç¼©åº¦é‡ (contraction metric) è¯æ˜äº†è¿­ä»£å¼•å¯¼çš„ Banach é£æ ¼æ”¶æ•›æ€§ã€‚é€šè¿‡ç»“åˆä¸Šä¸‹æ–‡æ— å…³è¯­æ³• (CFGs)ï¼Œè¯¥æ–¹æ³•åœ¨ä¿è¯ XML è‰¯æ„æ€§ (well-formedness) çš„åŒæ—¶æœ‰æ•ˆä¿ç•™äº†ä»»åŠ¡æ€§èƒ½ã€‚æ­¤å¤–ï¼Œç ”ç©¶è¿˜æä¾›äº†åŒ…æ‹¬â€œè®¡åˆ’ $\\to$ éªŒè¯ $\\to$ ä¿®æ”¹â€å’Œæ™ºèƒ½ä½“å·¥å…·è°ƒç”¨åœ¨å†…çš„å¤šå±‚äº¤äº’æ–¹æ¡ˆï¼Œä¸ºç¨‹åºåŒ–æç¤ºä¸è¯­æ³•å¯¹é½è§£ç æä¾›äº†å®Œå¤‡çš„æ•°å­¦è¯æ˜ä¸å®è·µæŒ‡å¯¼ã€‚",
      "categories": [
        "cs.PL",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.PL",
      "comment": "7 pages, multiple XML prompts",
      "pdf_url": "https://arxiv.org/pdf/2509.08182v1",
      "published_date": "2025-09-09 23:03:53 UTC",
      "updated_date": "2025-09-09 23:03:53 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:22:44.835422+00:00"
    },
    {
      "arxiv_id": "2509.08181v1",
      "title": "Multi-Label Transfer Learning in Non-Stationary Data Streams",
      "title_zh": "éå¹³ç¨³æ•°æ®æµä¸‹çš„å¤šæ ‡ç­¾è¿ç§»å­¦ä¹ ",
      "authors": [
        "Honghui Du",
        "Leandro Minku",
        "Aonghus Lawlor",
        "Huiyu Zhou"
      ],
      "abstract": "Label concepts in multi-label data streams often experience drift in non-stationary environments, either independently or in relation to other labels. Transferring knowledge between related labels can accelerate adaptation, yet research on multi-label transfer learning for data streams remains limited. To address this, we propose two novel transfer learning methods: BR-MARLENE leverages knowledge from different labels in both source and target streams for multi-label classification; BRPW-MARLENE builds on this by explicitly modelling and transferring pairwise label dependencies to enhance learning performance. Comprehensive experiments show that both methods outperform state-of-the-art multi-label stream approaches in non-stationary environments, demonstrating the effectiveness of inter-label knowledge transfer for improved predictive performance.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†éå¹³ç¨³æ•°æ®æµ (Non-Stationary Data Streams) ä¸­å¤šæ ‡ç­¾æ•°æ®é¢ä¸´çš„æ ‡ç­¾æ¦‚å¿µæ¼‚ç§» (Drift) é—®é¢˜ï¼Œå¹¶é’ˆå¯¹å½“å‰å¤šæ ‡ç­¾è¿ç§»å­¦ä¹  (Multi-Label Transfer Learning) ç ”ç©¶ä¸è¶³çš„ç°çŠ¶æå‡ºäº†ä¸¤ç§æ–°æ–¹æ³•ã€‚BR-MARLENE é€šè¿‡åˆ©ç”¨æºæµå’Œç›®æ ‡æµä¸­ä¸åŒæ ‡ç­¾çš„çŸ¥è¯†æ¥ä¼˜åŒ–å¤šæ ‡ç­¾åˆ†ç±»æ€§èƒ½ã€‚BRPW-MARLENE åˆ™è¿›ä¸€æ­¥é€šè¿‡æ˜¾å¼å»ºæ¨¡å’Œè¿ç§»æˆå¯¹æ ‡ç­¾ä¾èµ–å…³ç³» (Pairwise Label Dependencies) æ¥å¢å¼ºå­¦ä¹ æ•ˆæœã€‚å¤§é‡å®éªŒè¯æ˜ï¼Œè¿™ä¸¤ç§æ–¹æ³•åœ¨éå¹³ç¨³ç¯å¢ƒä¸‹çš„é¢„æµ‹è¡¨ç°å‡ä¼˜äºç°æœ‰çš„å…ˆè¿›å¤šæ ‡ç­¾æµç®—æ³•ã€‚è¯¥ç ”ç©¶è¯æ˜äº†è·¨æ ‡ç­¾çŸ¥è¯†è¿ç§»åœ¨åŠ¨æ€ç¯å¢ƒä¸­çš„æœ‰æ•ˆæ€§ï¼Œä¸ºæå‡å¤æ‚æ•°æ®æµåœºæ™¯ä¸‹çš„é¢„æµ‹å‡†ç¡®ç‡æä¾›äº†é‡è¦æ”¯æŒã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at IEEE International Conference on Data Mining (ICDM) 2025",
      "pdf_url": "https://arxiv.org/pdf/2509.08181v1",
      "published_date": "2025-09-09 23:01:20 UTC",
      "updated_date": "2025-09-09 23:01:20 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:23:17.338396+00:00"
    },
    {
      "arxiv_id": "2509.08177v1",
      "title": "Quadrotor Navigation using Reinforcement Learning with Privileged Information",
      "title_zh": "åŸºäºç‰¹æƒä¿¡æ¯çš„å¼ºåŒ–å­¦ä¹ å››æ—‹ç¿¼å¯¼èˆª",
      "authors": [
        "Jonathan Lee",
        "Abhishek Rathod",
        "Kshitij Goel",
        "John Stecklein",
        "Wennie Tabib"
      ],
      "abstract": "This paper presents a reinforcement learning-based quadrotor navigation method that leverages efficient differentiable simulation, novel loss functions, and privileged information to navigate around large obstacles. Prior learning-based methods perform well in scenes that exhibit narrow obstacles, but struggle when the goal location is blocked by large walls or terrain. In contrast, the proposed method utilizes time-of-arrival (ToA) maps as privileged information and a yaw alignment loss to guide the robot around large obstacles. The policy is evaluated in photo-realistic simulation environments containing large obstacles, sharp corners, and dead-ends. Our approach achieves an 86% success rate and outperforms baseline strategies by 34%. We deploy the policy onboard a custom quadrotor in outdoor cluttered environments both during the day and night. The policy is validated across 20 flights, covering 589 meters without collisions at speeds up to 4 m/s.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§åŸºäºå¼ºåŒ–å­¦ä¹ (Reinforcement Learning)çš„å››æ—‹ç¿¼æ— äººæœºå¯¼èˆªæ–¹æ³•ï¼Œåˆ©ç”¨é«˜æ•ˆçš„å¯å¾®æ¨¡æ‹Ÿ(Differentiable Simulation)å’Œç‰¹æƒä¿¡æ¯(Privileged Information)æ¥è§£å†³å¤æ‚ç¯å¢ƒä¸­çš„å¤§å°ºå¯¸éšœç¢ç‰©ç»•è¡Œé—®é¢˜ã€‚é’ˆå¯¹å…ˆå‰å­¦ä¹ æ–¹æ³•åœ¨é¢å¯¹å¢™å£æˆ–å¤§å‹åœ°å½¢æ—¶å®¹æ˜“å¤±è´¥çš„æŒ‘æˆ˜ï¼Œè¯¥æ–¹æ¡ˆå¼•å…¥äº†åˆ°è¾¾æ—¶é—´(Time-of-Arrival, ToA)åœ°å›¾ä½œä¸ºç‰¹æƒä¿¡æ¯ï¼Œå¹¶ç»“åˆåèˆªå¯¹é½æŸå¤±(Yaw Alignment Loss)æ¥ç²¾å‡†å¼•å¯¼é£è¡Œå™¨è·¯å¾„ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥ç­–ç•¥åœ¨åŒ…å«æ­»èƒ¡åŒå’Œæ€¥è½¬å¼¯çš„é«˜ä¿çœŸæ¨¡æ‹Ÿç¯å¢ƒä¸­è¾¾åˆ°äº†86%çš„æˆåŠŸç‡ï¼Œæ€§èƒ½ä¼˜äºåŸºçº¿æ–¹æ³•34%ã€‚æ­¤å¤–ï¼Œè¯¥ç­–ç•¥åœ¨æˆ·å¤–çœŸå®å¤æ‚åœºæ™¯ä¸­é€šè¿‡äº†20æ¬¡å®æœºé£è¡ŒéªŒè¯ï¼Œåœ¨æœ€é«˜4 m/sçš„é€Ÿåº¦ä¸‹ç´¯è®¡é£è¡Œ589ç±³ä¸”æ— ç¢°æ’ï¼Œè¯æ˜äº†å…¶åœ¨å…¨å¤©å€™ç¯å¢ƒä¸‹çš„é²æ£’æ€§å’Œå®ç”¨æ€§ã€‚",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.08177v1",
      "published_date": "2025-09-09 22:56:35 UTC",
      "updated_date": "2025-09-09 22:56:35 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:24:26.137215+00:00"
    },
    {
      "arxiv_id": "2509.08176v1",
      "title": "MARLINE: Multi-Source Mapping Transfer Learning for Non-Stationary Environments",
      "title_zh": "MARLINEï¼šé¢å‘éå¹³ç¨³ç¯å¢ƒçš„å¤šæºæ˜ å°„è¿ç§»å­¦ä¹ ",
      "authors": [
        "Honghui Du",
        "Leandro Minku",
        "Huiyu Zhou"
      ],
      "abstract": "Concept drift is a major problem in online learning due to its impact on the predictive performance of data stream mining systems. Recent studies have started exploring data streams from different sources as a strategy to tackle concept drift in a given target domain. These approaches make the assumption that at least one of the source models represents a concept similar to the target concept, which may not hold in many real-world scenarios. In this paper, we propose a novel approach called Multi-source mApping with tRansfer LearnIng for Non-stationary Environments (MARLINE). MARLINE can benefit from knowledge from multiple data sources in non-stationary environments even when source and target concepts do not match. This is achieved by projecting the target concept to the space of each source concept, enabling multiple source sub-classifiers to contribute towards the prediction of the target concept as part of an ensemble. Experiments on several synthetic and real-world datasets show that MARLINE was more accurate than several state-of-the-art data stream learning approaches.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†MARLINEï¼Œä¸€ç§é’ˆå¯¹éå¹³ç¨³ç¯å¢ƒ(Non-stationary Environments)ä¸‹å¤šæºæ˜ å°„è¿ç§»å­¦ä¹ (Multi-source Mapping Transfer Learning)çš„æ–°æ–¹æ³•ï¼Œæ—¨åœ¨è§£å†³åœ¨çº¿å­¦ä¹ ä¸­ç”±äºæ¦‚å¿µæ¼‚ç§»(Concept drift)å¯¼è‡´çš„æ•°æ®æµæŒ–æ˜ç³»ç»Ÿæ€§èƒ½ä¸‹é™é—®é¢˜ã€‚é’ˆå¯¹ç°æœ‰æ–¹æ³•å¾€å¾€å‡è®¾æºæ¨¡å‹ä¸ç›®æ ‡æ¦‚å¿µ(Target concept)å¿…é¡»ç›¸ä¼¼çš„å±€é™æ€§ï¼ŒMARLINEé€šè¿‡å°†ç›®æ ‡æ¦‚å¿µæŠ•å½±åˆ°å„ä¸ªæºæ¦‚å¿µçš„ç©ºé—´ï¼Œå®ç°äº†åœ¨æºä¸ç›®æ ‡æ¦‚å¿µä¸åŒ¹é…çš„æƒ…å†µä¸‹ä¾ç„¶èƒ½æœ‰æ•ˆåˆ©ç”¨å¤šæºçŸ¥è¯†ã€‚è¯¥æ–¹æ³•æ„å»ºäº†ä¸€ä¸ªé›†æˆç³»ç»Ÿ(Ensemble)ï¼Œå…è®¸æ¥è‡ªä¸åŒæ•°æ®æºçš„å¤šä¸ªæºå­åˆ†ç±»å™¨(Source sub-classifiers)å…±åŒå‚ä¸å¹¶è´¡çŒ®äºç›®æ ‡æ¦‚å¿µçš„é¢„æµ‹ã€‚åœ¨å¤šä¸ªåˆæˆåŠçœŸå®ä¸–ç•Œæ•°æ®é›†ä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼ŒMARLINEåœ¨å¤„ç†éå¹³ç¨³ç¯å¢ƒä»»åŠ¡æ—¶çš„å‡†ç¡®ç‡æ˜¾è‘—ä¼˜äºç›®å‰å¤šç§å…ˆè¿›çš„æ•°æ®æµå­¦ä¹ (Data stream learning)ç®—æ³•ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Published in the 2020 IEEE International Conference on Data Mining (ICDM)",
      "pdf_url": "https://arxiv.org/pdf/2509.08176v1",
      "published_date": "2025-09-09 22:51:31 UTC",
      "updated_date": "2025-09-09 22:51:31 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:24:50.038664+00:00"
    },
    {
      "arxiv_id": "2509.08859v1",
      "title": "Multi Robot Coordination in Highly Dynamic Environments: Tackling Asymmetric Obstacles and Limited Communication",
      "title_zh": "é«˜åŠ¨æ€ç¯å¢ƒä¸‹çš„å¤šæœºå™¨äººåä½œï¼šåº”å¯¹éå¯¹ç§°éšœç¢ç‰©ä¸å—é™é€šä¿¡",
      "authors": [
        "Vincenzo Suriani",
        "Daniele Affinita",
        "Domenico D. Bloisi",
        "Daniele Nardi"
      ],
      "abstract": "Coordinating a fully distributed multi-agent system (MAS) can be challenging when the communication channel has very limited capabilities in terms of sending rate and packet payload. When the MAS has to deal with active obstacles in a highly partially observable environment, the communication channel acquires considerable relevance. In this paper, we present an approach to deal with task assignments in extremely active scenarios, where tasks need to be frequently reallocated among the agents participating in the coordination process. Inspired by market-based task assignments, we introduce a novel distributed coordination method to orchestrate autonomous agents' actions efficiently in low communication scenarios. In particular, our algorithm takes into account asymmetric obstacles. While in the real world, the majority of obstacles are asymmetric, they are usually treated as symmetric ones, thus limiting the applicability of existing methods. To summarize, the presented architecture is designed to tackle scenarios where the obstacles are active and asymmetric, the communication channel is poor and the environment is partially observable. Our approach has been validated in simulation and in the real world, using a team of NAO robots during official RoboCup competitions. Experimental results show a notable reduction in task overlaps in limited communication settings, with a decrease of 52% in the most frequent reallocated task.",
      "tldr_zh": "åœ¨é«˜åº¦åŠ¨æ€ä¸”éƒ¨åˆ†å¯è§‚æµ‹çš„ç¯å¢ƒä¸­ï¼Œåˆ†å¸ƒå¼å¤šæ™ºèƒ½ä½“ç³»ç»Ÿ(MAS)é¢ä¸´é€šä¿¡å¸¦å®½å—é™ä»¥åŠå¤„ç†ä¸å¯¹ç§°(Asymmetric)å’Œä¸»åŠ¨éšœç¢ç‰©çš„æŒ‘æˆ˜ã€‚è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§å—å¸‚åœºæœºåˆ¶å¯å‘(Market-based)çš„æ–°å‹åˆ†å¸ƒå¼åè°ƒæ–¹æ³•ï¼Œæ—¨åœ¨ä½é€šä¿¡ç¯å¢ƒä¸‹é€šè¿‡é«˜æ•ˆçš„ä»»åŠ¡åˆ†é…(Task assignments)å®ç°è‡ªä¸»æ™ºèƒ½ä½“çš„ååŒã€‚è¯¥ç®—æ³•ç‰¹åˆ«é’ˆå¯¹ç°å®ä¸–ç•Œä¸­å¸¸è§çš„ä¸å¯¹ç§°éšœç¢ç‰©ç‰¹æ€§è¿›è¡Œäº†ä¼˜åŒ–ï¼Œå…‹æœäº†ç°æœ‰æ–¹æ³•å°†å…¶ç®€åŒ–ä¸ºå¯¹ç§°éšœç¢ç‰©æ‰€å¸¦æ¥çš„å±€é™æ€§ã€‚ç ”ç©¶å›¢é˜Ÿé€šè¿‡ä»¿çœŸå®éªŒä»¥åŠåœ¨RoboCupæ¯”èµ›ä¸­ä½¿ç”¨NAOæœºå™¨äººè¿›è¡Œäº†å®åœ°éªŒè¯ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨å—é™é€šä¿¡è®¾ç½®ä¸‹æ˜¾è‘—å‡å°‘äº†ä»»åŠ¡é‡å ï¼Œå…¶ä¸­æœ€é¢‘ç¹é‡åˆ†é…ä»»åŠ¡çš„é‡å ç‡é™ä½äº†52%ï¼Œä¸ºæç«¯æ´»è·ƒåœºæ™¯ä¸‹çš„å¤šæœºå™¨äººååŒæä¾›äº†é«˜æ•ˆä¸”ç¨³å¥çš„è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "The 19th International Conference on Intelligent Autonomous Systems (IAS 19), 2025, Genoa",
      "pdf_url": "https://arxiv.org/pdf/2509.08859v1",
      "published_date": "2025-09-09 22:11:34 UTC",
      "updated_date": "2025-09-09 22:11:34 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:23:20.458585+00:00"
    },
    {
      "arxiv_id": "2509.08160v1",
      "title": "Diffusion-Guided Multi-Arm Motion Planning",
      "title_zh": "æ‰©æ•£å¼•å¯¼çš„å¤šè‡‚è¿åŠ¨è§„åˆ’",
      "authors": [
        "Viraj Parimi",
        "Brian C. Williams"
      ],
      "abstract": "Multi-arm motion planning is fundamental for enabling arms to complete complex long-horizon tasks in shared spaces efficiently but current methods struggle with scalability due to exponential state-space growth and reliance on large training datasets for learned models. Inspired by Multi-Agent Path Finding (MAPF), which decomposes planning into single-agent problems coupled with collision resolution, we propose a novel diffusion-guided multi-arm planner (DG-MAP) that enhances scalability of learning-based models while reducing their reliance on massive multi-arm datasets. Recognizing that collisions are primarily pairwise, we train two conditional diffusion models, one to generate feasible single-arm trajectories, and a second, to model the dual-arm dynamics required for effective pairwise collision resolution. By integrating these specialized generative models within a MAPF-inspired structured decomposition, our planner efficiently scales to larger number of arms. Evaluations against alternative learning-based methods across various team sizes demonstrate our method's effectiveness and practical applicability. Project website can be found at https://diff-mapf-mers.csail.mit.edu",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤šè‡‚è¿åŠ¨è§„åˆ’ (Multi-arm motion planning) åœ¨çŠ¶æ€ç©ºé—´æŒ‡æ•°çº§å¢é•¿å’Œå¯¹å¤§è§„æ¨¡è®­ç»ƒæ•°æ®é›†è¿‡åº¦ä¾èµ–çš„æŒ‘æˆ˜ï¼Œæå‡ºäº†åä¸º DG-MAP çš„æ–°å‹æ‰©æ•£å¼•å¯¼è§„åˆ’å™¨ã€‚å—åˆ°å¤šæ™ºèƒ½ä½“è·¯å¾„è§„åˆ’ (MAPF) çš„å¯å‘ï¼ŒDG-MAP å°†å¤æ‚çš„å¤šè‡‚è§„åˆ’ä»»åŠ¡åˆ†è§£ä¸ºå•è‡‚é—®é¢˜ä¸ç¢°æ’è§£å†³è€¦åˆçš„å½¢å¼ï¼Œæ˜¾è‘—æå‡äº†å­¦ä¹ å‹æ¨¡å‹çš„æ‰©å±•æ€§ã€‚è¯¥æ–¹æ³•è®­ç»ƒäº†ä¸¤ä¸ªä¸“é—¨çš„æ¡ä»¶æ‰©æ•£æ¨¡å‹ (Conditional diffusion models)ï¼Œåˆ†åˆ«ç”¨äºç”Ÿæˆå¯è¡Œçš„å•è‡‚è½¨è¿¹ä»¥åŠå»ºæ¨¡åŒè‡‚åŠ¨åŠ›å­¦ä»¥å®ç°æœ‰æ•ˆçš„æˆå¯¹ç¢°æ’è§£å†³ã€‚é€šè¿‡åœ¨ç»“æ„åŒ–åˆ†è§£æ¡†æ¶ä¸­é›†æˆè¿™äº›ç”Ÿæˆæ¨¡å‹ï¼ŒDG-MAP èƒ½å¤Ÿé«˜æ•ˆæ‰©å±•åˆ°åŒ…å«æ›´å¤šæœºæ¢°è‡‚çš„å¤æ‚åœºæ™¯ã€‚å®éªŒè¯„ä¼°è¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨ä¸åŒè§„æ¨¡çš„æœºå™¨äººå›¢é˜Ÿä¸­å‡è¡¨ç°å‡ºä¼˜äºç°æœ‰å­¦ä¹ å‹æ–¹æ³•çš„æœ‰æ•ˆæ€§ä¸å®é™…åº”ç”¨ä»·å€¼ã€‚",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.08160v1",
      "published_date": "2025-09-09 21:41:23 UTC",
      "updated_date": "2025-09-09 21:41:23 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:23:00.933401+00:00"
    },
    {
      "arxiv_id": "2509.08159v1",
      "title": "Zero-Shot Metric Depth Estimation via Monocular Visual-Inertial Rescaling for Autonomous Aerial Navigation",
      "title_zh": "åŸºäºå•ç›®è§†æƒ¯é‡å®šæ ‡çš„è‡ªä¸»ç©ºä¸­å¯¼èˆªé›¶æ ·æœ¬åº¦é‡æ·±åº¦ä¼°è®¡",
      "authors": [
        "Steven Yang",
        "Xiaoyu Tian",
        "Kshitij Goel",
        "Wennie Tabib"
      ],
      "abstract": "This paper presents a methodology to predict metric depth from monocular RGB images and an inertial measurement unit (IMU). To enable collision avoidance during autonomous flight, prior works either leverage heavy sensors (e.g., LiDARs or stereo cameras) or data-intensive and domain-specific fine-tuning of monocular metric depth estimation methods. In contrast, we propose several lightweight zero-shot rescaling strategies to obtain metric depth from relative depth estimates via the sparse 3D feature map created using a visual-inertial navigation system. These strategies are compared for their accuracy in diverse simulation environments. The best performing approach, which leverages monotonic spline fitting, is deployed in the real-world on a compute-constrained quadrotor. We obtain on-board metric depth estimates at 15 Hz and demonstrate successful collision avoidance after integrating the proposed method with a motion primitives-based planner.",
      "tldr_zh": "æœ¬ç ”ç©¶é’ˆå¯¹è‡ªä¸»é£è¡Œé¿éšœå¯¹é‡å‹ä¼ æ„Ÿå™¨æˆ–ç‰¹å®šé¢†åŸŸå¾®è°ƒçš„ä¾èµ–ï¼Œæå‡ºäº†ä¸€ç§ç»“åˆå•ç›®RGBå›¾åƒå’Œæƒ¯æ€§æµ‹é‡å•å…ƒ(IMU)è¿›è¡Œé›¶æ ·æœ¬(Zero-Shot)å°ºåº¦æ·±åº¦ä¼°è®¡çš„æ–¹æ³•ã€‚è¯¥æ–¹æ³•é€šè¿‡è§†è§‰æƒ¯æ€§å¯¼èˆªç³»ç»Ÿ(VINS)ç”Ÿæˆçš„ç¨€ç–3Dç‰¹å¾å›¾ï¼Œåˆ©ç”¨å¤šç§è½»é‡çº§çš„é‡ç¼©æ”¾(Rescaling)ç­–ç•¥å°†ç›¸å¯¹æ·±åº¦ä¼°è®¡è½¬åŒ–ä¸ºå…·æœ‰ç‰©ç†æ„ä¹‰çš„åº¦é‡æ·±åº¦ã€‚åœ¨å¤šç§ä»¿çœŸç¯å¢ƒçš„å¯¹æ¯”ä¸­ï¼Œç ”ç©¶ç¡®å®šäº†åŸºäºå•è°ƒæ ·æ¡æ‹Ÿåˆ(Monotonic Spline Fitting)çš„ç­–ç•¥å…·æœ‰æœ€ä½³æ€§èƒ½ã€‚è¯¥æ–¹æ¡ˆè¢«éƒ¨ç½²äºè®¡ç®—èµ„æºå—é™çš„å››æ—‹ç¿¼æ— äººæœºï¼Œå®ç°äº†15 Hzçš„æ¿è½½å®æ—¶æ·±åº¦ä¼°è®¡ã€‚å®éªŒè¯æ˜ï¼Œè¯¥æ–¹æ³•åœ¨ä¸åŸºäºè¿åŠ¨åŸè¯­(Motion Primitives)çš„è§„åˆ’å™¨é›†æˆåï¼Œèƒ½å¤ŸæˆåŠŸå®ç°è‡ªä¸»é¿éšœï¼Œä¸ºè½»é‡åŒ–è‡ªä¸»èˆªç©ºå¯¼èˆªæä¾›äº†é«˜æ•ˆä¸”é€šç”¨çš„è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.08159v1",
      "published_date": "2025-09-09 21:39:13 UTC",
      "updated_date": "2025-09-09 21:39:13 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:23:45.637346+00:00"
    },
    {
      "arxiv_id": "2509.08157v2",
      "title": "Risk-Bounded Multi-Agent Visual Navigation via Iterative Risk Allocation",
      "title_zh": "åŸºäºè¿­ä»£é£é™©åˆ†é…çš„é£é™©å—é™å¤šæ™ºèƒ½ä½“è§†è§‰å¯¼èˆª",
      "authors": [
        "Viraj Parimi",
        "Brian C. Williams"
      ],
      "abstract": "Safe navigation is essential for autonomous systems operating in hazardous environments, especially when multiple agents must coordinate using only high-dimensional visual observations. While recent approaches successfully combine Goal-Conditioned RL (GCRL) for graph construction with Conflict-Based Search (CBS) for planning, they typically rely on static edge pruning to enforce safety. This binary strategy is overly conservative, precluding feasible missions that require traversing high-risk regions, even when the aggregate risk is acceptable. To address this, we introduce a framework for Risk-Bounded Multi-Agent Path Finding (\\problem{}), where agents share a user-specified global risk budget ($Î”$). Rather than permanently discarding edges, our framework dynamically distributes per-agent risk budgets ($Î´_i$) during search via an Iterative Risk Allocation (IRA) layer that integrates with a standard CBS planner. We investigate two distribution strategies: a greedy surplus-deficit scheme for rapid feasibility repair, and a market-inspired mechanism that treats risk as a priced resource to guide improved allocation. This yields a tunable trade-off wherein agents exploit available risk to secure shorter, more efficient paths, but revert to longer, safer detours under tighter budgets. Experiments in complex visual environments show that, our dynamic allocation framework achieves higher success rates than baselines and effectively leverages the available safety budget to reduce travel time.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤šæ™ºèƒ½ä½“è§†è§‰å¯¼èˆªä¸­çš„å®‰å…¨é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§é£é™©å—é™å¤šæ™ºèƒ½ä½“è·¯å¾„è§„åˆ’ï¼ˆRisk-Bounded Multi-Agent Path Finding, RB-MAPFï¼‰æ¡†æ¶ã€‚è¯¥æ¡†æ¶æ‘’å¼ƒäº†ä¼ ç»Ÿçš„é™æ€è¾¹ä¿®å‰ªï¼ˆstatic edge pruningï¼‰ç­‰è¿‡äºä¿å®ˆçš„äºŒå…ƒå®‰å…¨ç­–ç•¥ï¼Œå¼•å…¥äº†è¿­ä»£é£é™©åˆ†é…ï¼ˆIterative Risk Allocation, IRAï¼‰å±‚å¹¶ä¸æ ‡å‡†çš„å†²çªæœç´¢ï¼ˆConflict-Based Search, CBSï¼‰è§„åˆ’å™¨é›†æˆã€‚ç³»ç»Ÿé€šè¿‡åŠ¨æ€åˆ†é…å„æ™ºèƒ½ä½“çš„é£é™©é¢„ç®—ï¼Œå…è®¸åœ¨å…¨å±€é£é™©å¯æ§çš„å‰æä¸‹æ¢ç´¢é«˜æ•ˆè·¯å¾„ï¼Œè€Œéç›²ç›®è§„é¿æ‰€æœ‰é«˜é£é™©åŒºåŸŸã€‚ç ”ç©¶è¿›ä¸€æ­¥æå‡ºäº†è´ªå©ªç›ˆäºæ–¹æ¡ˆå’Œå—å¸‚åœºæœºåˆ¶å¯å‘çš„èµ„æºå®šä»·æ–¹æ¡ˆï¼Œä»¥ä¼˜åŒ–é£é™©é…é¢çš„åˆ†é…é€»è¾‘ã€‚åœ¨å¤æ‚è§†è§‰ç¯å¢ƒä¸­çš„å®éªŒè¡¨æ˜ï¼Œè¯¥åŠ¨æ€åˆ†é…æ¡†æ¶åœ¨ä»»åŠ¡æˆåŠŸç‡å’Œèˆªè¡Œæ—¶é—´ä¸Šå‡ä¼˜äºåŸºçº¿æ¨¡å‹ï¼Œå®ç°äº†å®‰å…¨æ€§ä¸è·¯å¾„æ•ˆç‡ä¹‹é—´çš„æœ‰æ•ˆæƒè¡¡ã€‚",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.08157v2",
      "published_date": "2025-09-09 21:35:55 UTC",
      "updated_date": "2025-12-10 21:59:51 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:23:51.235005+00:00"
    },
    {
      "arxiv_id": "2509.08151v2",
      "title": "Trust Semantics Distillation for Collaborator Selection via Memory-Augmented Agentic AI",
      "title_zh": "åŸºäºè®°å¿†å¢å¼ºæ™ºèƒ½ä½“AIçš„åä½œèŠ‚ç‚¹é€‰æ‹©ä¿¡ä»»è¯­ä¹‰è’¸é¦",
      "authors": [
        "Botao Zhu",
        "Jeslyn Wang",
        "Dusit Niyato",
        "Xianbin Wang"
      ],
      "abstract": "Offloading computational tasks from resource-constrained devices to resource-abundant peers constitutes a critical paradigm for collaborative computing. Within this context, accurate trust evaluation of potential collaborating devices is essential for the effective execution of complex computing tasks. This trust evaluation process involves collecting diverse trust-related information from every potential collaborator and performing trust inference based on the collected data. However, when each resource-constrained device independently assesses all potential collaborators, frequent data exchange and complex reasoning can incur significant overhead and further degrade the timeliness of trust evaluation. To overcome these challenges, we propose a task-specific trust semantics distillation (TSD) model based on a large AI model (LAM)-enabled teacher-student agent architecture. Specifically, the teacher agent is deployed on a server with powerful computational capabilities and an augmented memory module to perform multidimensional trust-related data collection, task-specific trust semantics extraction, and task-collaborator matching analysis. Upon receiving task-specific evaluation requests from device-side student agents, the teacher agent transfers the trust semantics of potential collaborators to the student agents, enabling rapid and accurate collaborator selection. Experimental results demonstrate that the proposed TSD model can reduce collaborator evaluation time, decrease device resource consumption, and improve the accuracy of collaborator selection.",
      "tldr_zh": "åœ¨åä½œè®¡ç®—(Collaborative Computing)ä¸­ï¼Œèµ„æºå—é™è®¾å¤‡åœ¨å¸è½½è®¡ç®—ä»»åŠ¡æ—¶éœ€è¦å¯¹æ½œåœ¨åä½œæ–¹è¿›è¡Œå‡†ç¡®çš„ä¿¡ä»»è¯„ä¼°ï¼Œä½†ä¼ ç»Ÿçš„ç‹¬ç«‹è¯„ä¼°è¿‡ç¨‹å¾€å¾€ä¼´éšç€é«˜æ˜‚çš„é€šä¿¡å¼€é”€å’Œæ¨ç†å»¶è¿Ÿã€‚è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§åŸºäºå¤§æ¨¡å‹(Large AI Model)é©±åŠ¨çš„å¸ˆç”Ÿæ™ºèƒ½ä½“(Teacher-Student Agent)æ¶æ„çš„ç‰¹å®šä»»åŠ¡ä¿¡ä»»è¯­ä¹‰è’¸é¦(Trust Semantics Distillation, TSD)æ¨¡å‹ã€‚è¯¥æ¨¡å‹åœ¨è®¡ç®—èƒ½åŠ›å¼ºå¤§çš„æœåŠ¡å™¨ä¸Šéƒ¨ç½²æ•™å¸ˆæ™ºèƒ½ä½“(Teacher Agent)ï¼Œå¹¶åˆ©ç”¨å¢å¼ºè®°å¿†æ¨¡å—(Memory Module)æ‰§è¡Œå¤šç»´ä¿¡ä»»æ•°æ®é‡‡é›†ã€ä»»åŠ¡ç‰¹å®šè¯­ä¹‰æå–ä»¥åŠä»»åŠ¡-åä½œæ–¹åŒ¹é…åˆ†æã€‚é€šè¿‡å°†æç‚¼åçš„ä¿¡ä»»è¯­ä¹‰ä¼ é€’ç»™è®¾å¤‡ç«¯çš„å­¦ç”Ÿæ™ºèƒ½ä½“(Student Agent)ï¼Œè¯¥æ¶æ„èƒ½å¤Ÿæ”¯æŒå¿«é€Ÿä¸”ç²¾ç¡®çš„åä½œæ–¹é€‰æ‹©è¿‡ç¨‹ã€‚å®éªŒç»“æœè¯æ˜ï¼ŒTSDæ¨¡å‹èƒ½æœ‰æ•ˆç¼©çŸ­è¯„ä¼°æ—¶é—´å¹¶é™ä½è®¾å¤‡èµ„æºæ¶ˆè€—ï¼Œæ˜¾è‘—æå‡äº†åä½œæ–¹é€‰æ‹©çš„å‡†ç¡®æ€§ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.08151v2",
      "published_date": "2025-09-09 21:18:31 UTC",
      "updated_date": "2025-12-22 20:59:23 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:24:58.349832+00:00"
    },
    {
      "arxiv_id": "2509.18111v2",
      "title": "Prompt Optimization Meets Subspace Representation Learning for Few-shot Out-of-Distribution Detection",
      "title_zh": "ç»“åˆæç¤ºä¼˜åŒ–ä¸å­ç©ºé—´è¡¨ç¤ºå­¦ä¹ çš„å°‘æ ·æœ¬åˆ†å¸ƒå¤–æ£€æµ‹",
      "authors": [
        "Faizul Rakib Sayem",
        "Shahana Ibrahim"
      ],
      "abstract": "The reliability of artificial intelligence (AI) systems in open-world settings depends heavily on their ability to flag out-of-distribution (OOD) inputs unseen during training. Recent advances in large-scale vision-language models (VLMs) have enabled promising few-shot OOD detection frameworks using only a handful of in-distribution (ID) samples. However, existing prompt learning-based OOD methods rely solely on softmax probabilities, overlooking the rich discriminative potential of the feature embeddings learned by VLMs trained on millions of samples. To address this limitation, we propose a novel context optimization (CoOp)-based framework that integrates subspace representation learning with prompt tuning. Our approach improves ID-OOD separability by projecting the ID features into a subspace spanned by prompt vectors, while projecting ID-irrelevant features into an orthogonal null space. To train such OOD detection framework, we design an easy-to-handle end-to-end learning criterion that ensures strong OOD detection performance as well as high ID classification accuracy. Experiments on real-world datasets showcase the effectiveness of our approach.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¼€æ”¾ä¸–ç•Œä¸­äººå·¥æ™ºèƒ½ç³»ç»Ÿçš„å¯é æ€§é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§ç»“åˆ Prompt Optimization ä¸ Subspace Representation Learning çš„æ–°å‹ Few-shot Out-of-Distribution (OOD) æ£€æµ‹æ¡†æ¶ã€‚ç°æœ‰çš„åŸºäº Prompt learning çš„ OOD æ£€æµ‹æ–¹æ³•ä¸»è¦ä¾èµ– Softmax probabilitiesï¼Œå¾€å¾€å¿½ç•¥äº†å¤§è§„æ¨¡ Vision-Language Models (VLMs) å­¦ä¹ åˆ°çš„ç‰¹å¾åµŒå…¥ä¸­ä¸°å¯Œçš„åˆ¤åˆ«æ½œåŠ›ã€‚ä¸ºäº†è§£å†³è¿™ä¸€å±€é™ï¼Œè¯¥æ–¹æ³•åœ¨ Context Optimization (CoOp) çš„åŸºç¡€ä¸Šï¼Œé€šè¿‡å°† In-Distribution (ID) ç‰¹å¾æŠ•å½±åˆ°ç”± Prompt vectors æ„æˆçš„å­ç©ºé—´ï¼Œå¹¶å°† ID æ— å…³ç‰¹å¾æŠ•å½±åˆ°æ­£äº¤çš„ Null space ä¸­ï¼Œä»è€Œæ˜¾è‘—æå‡äº† ID ä¸ OOD æ•°æ®é—´çš„å¯åˆ†ç¦»æ€§ã€‚æ­¤å¤–ï¼Œç ”ç©¶å›¢é˜Ÿè®¾è®¡äº†ä¸€ä¸ªç«¯åˆ°ç«¯çš„å­¦ä¹ å‡†åˆ™ï¼Œåœ¨ç¡®ä¿å¼ºå¤§ OOD æ£€æµ‹æ€§èƒ½çš„åŒæ—¶å…¼é¡¾äº†é«˜æ°´å¹³çš„ ID åˆ†ç±»å‡†ç¡®ç‡ã€‚åœ¨çœŸå®ä¸–ç•Œæ•°æ®é›†ä¸Šçš„å®éªŒç»“æœéªŒè¯äº†è¯¥æ–¹æ³•çš„æœ‰æ•ˆæ€§ï¼Œå±•ç¤ºäº†æç¤ºä¼˜åŒ–ä¸å­ç©ºé—´è¡¨ç¤ºå­¦ä¹ åœ¨æå‡è§†è§‰è¯­è¨€æ¨¡å‹é²æ£’æ€§æ–¹é¢çš„å·¨å¤§æ½œåŠ›ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.18111v2",
      "published_date": "2025-09-09 21:03:46 UTC",
      "updated_date": "2025-10-12 15:51:27 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:25:12.642974+00:00"
    },
    {
      "arxiv_id": "2509.08140v1",
      "title": "From Limited Data to Rare-event Prediction: LLM-powered Feature Engineering and Multi-model Learning in Venture Capital",
      "title_zh": "ä»æœ‰é™æ•°æ®åˆ°ç¨€æœ‰äº‹ä»¶é¢„æµ‹ï¼šé£é™©æŠ•èµ„ä¸­ LLM é©±åŠ¨çš„ç‰¹å¾å·¥ç¨‹ä¸å¤šæ¨¡å‹å­¦ä¹ ",
      "authors": [
        "Mihir Kumar",
        "Aaron Ontoyin Yin",
        "Zakari Salifu",
        "Kelvin Amoaba",
        "Afriyie Kwesi Samuel",
        "Fuat Alican",
        "Yigit Ihlamur"
      ],
      "abstract": "This paper presents a framework for predicting rare, high-impact outcomes by integrating large language models (LLMs) with a multi-model machine learning (ML) architecture. The approach combines the predictive strength of black-box models with the interpretability required for reliable decision-making. We use LLM-powered feature engineering to extract and synthesize complex signals from unstructured data, which are then processed within a layered ensemble of models including XGBoost, Random Forest, and Linear Regression. The ensemble first produces a continuous estimate of success likelihood, which is then thresholded to produce a binary rare-event prediction. We apply this framework to the domain of Venture Capital (VC), where investors must evaluate startups with limited and noisy early-stage data. The empirical results show strong performance: the model achieves precision between 9.8X and 11.1X the random classifier baseline in three independent test subsets. Feature sensitivity analysis further reveals interpretable success drivers: the startup's category list accounts for 15.6% of predictive influence, followed by the number of founders, while education level and domain expertise contribute smaller yet consistent effects.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ä¸ªé›†æˆ Large Language Models (LLMs) ä¸å¤šæ¨¡å‹æœºå™¨å­¦ä¹  (ML) æ¶æ„çš„æ¡†æ¶ï¼Œæ—¨åœ¨åˆ©ç”¨æœ‰é™ä¸”æœ‰å™ªå£°çš„æ•°æ®è¿›è¡Œç¨€æœ‰ä¸”é«˜å½±å“åŠ›äº‹ä»¶çš„é¢„æµ‹ã€‚è¯¥æ–¹æ³•åˆ©ç”¨ LLM-powered feature engineering ä»éç»“æ„åŒ–æ•°æ®ä¸­æå–å¹¶åˆæˆå¤æ‚ä¿¡å·ï¼Œéšåé€šè¿‡åŒ…å« XGBoostã€Random Forest å’Œ Linear Regression çš„åˆ†å±‚é›†æˆæ¨¡å‹è¿›è¡Œå¤„ç†ã€‚ç³»ç»Ÿé¦–å…ˆç”ŸæˆæˆåŠŸæ¦‚ç‡çš„è¿ç»­ä¼°è®¡ï¼Œå†é€šè¿‡è®¾å®šé˜ˆå€¼è½¬åŒ–ä¸ºäºŒå…ƒçš„ Rare-event Predictionã€‚ç ”ç©¶è€…å°†è¯¥æ¡†æ¶åº”ç”¨äºé£é™©æŠ•èµ„ (Venture Capital) é¢†åŸŸï¼Œä»¥è§£å†³æŠ•èµ„è€…è¯„ä¼°æ—©æœŸåˆåˆ›ä¼ä¸šæ—¶é¢ä¸´çš„æŒ‘æˆ˜ï¼Œå®éªŒç»“æœæ˜¾ç¤ºå…¶åœ¨ç‹¬ç«‹æµ‹è¯•é›†ä¸­çš„ Precision è¾¾åˆ°äº†éšæœºåˆ†ç±»åŸºå‡†çš„ 9.8 è‡³ 11.1 å€ã€‚ç‰¹å¾æ•æ„Ÿæ€§åˆ†æ (Feature sensitivity analysis) è¿›ä¸€æ­¥æ­ç¤ºäº†å¯è§£é‡Šçš„æˆåŠŸé©±åŠ¨å› ç´ ï¼Œå…¶ä¸­åˆåˆ›ä¼ä¸šçš„ Category list è´¡çŒ®äº† 15.6% çš„é¢„æµ‹å½±å“åŠ›ï¼Œå…¶æ¬¡æ˜¯åˆ›å§‹äººæ•°é‡ã€æ•™è‚²æ°´å¹³åŠé¢†åŸŸä¸“ä¸šçŸ¥è¯†ç­‰å› ç´ ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "6 pages, 3 figures",
      "pdf_url": "https://arxiv.org/pdf/2509.08140v1",
      "published_date": "2025-09-09 20:46:54 UTC",
      "updated_date": "2025-09-09 20:46:54 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:25:21.836345+00:00"
    },
    {
      "arxiv_id": "2509.08116v1",
      "title": "Domain Knowledge is Power: Leveraging Physiological Priors for Self Supervised Representation Learning in Electrocardiography",
      "title_zh": "é¢†åŸŸçŸ¥è¯†å³åŠ›é‡ï¼šåˆ©ç”¨ç”Ÿç†å…ˆéªŒå®ç°å¿ƒç”µå›¾è‡ªç›‘ç£è¡¨ç¤ºå­¦ä¹ ",
      "authors": [
        "Nooshin Maghsoodi",
        "Sarah Nassar",
        "Paul F R Wilson",
        "Minh Nguyen Nhat To",
        "Sophia Mannina",
        "Shamel Addas",
        "Stephanie Sibley",
        "David Maslove",
        "Purang Abolmaesumi",
        "Parvin Mousavi"
      ],
      "abstract": "Objective: Electrocardiograms (ECGs) play a crucial role in diagnosing heart conditions; however, the effectiveness of artificial intelligence (AI)-based ECG analysis is often hindered by the limited availability of labeled data. Self-supervised learning (SSL) can address this by leveraging large-scale unlabeled data. We introduce PhysioCLR (Physiology-aware Contrastive Learning Representation for ECG), a physiology-aware contrastive learning framework that incorporates domain-specific priors to enhance the generalizability and clinical relevance of ECG-based arrhythmia classification. Methods: During pretraining, PhysioCLR learns to bring together embeddings of samples that share similar clinically relevant features while pushing apart those that are dissimilar. Unlike existing methods, our method integrates ECG physiological similarity cues into contrastive learning, promoting the learning of clinically meaningful representations. Additionally, we introduce ECG- specific augmentations that preserve the ECG category post augmentation and propose a hybrid loss function to further refine the quality of learned representations. Results: We evaluate PhysioCLR on two public ECG datasets, Chapman and Georgia, for multilabel ECG diagnoses, as well as a private ICU dataset labeled for binary classification. Across the Chapman, Georgia, and private cohorts, PhysioCLR boosts the mean AUROC by 12% relative to the strongest baseline, underscoring its robust cross-dataset generalization. Conclusion: By embedding physiological knowledge into contrastive learning, PhysioCLR enables the model to learn clinically meaningful and transferable ECG eatures. Significance: PhysioCLR demonstrates the potential of physiology-informed SSL to offer a promising path toward more effective and label-efficient ECG diagnostics.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¿ƒç”µå›¾(Electrocardiograms, ECGs)åˆ†æä¸­æ ‡æ³¨æ•°æ®æœ‰é™çš„æŒ‘æˆ˜ï¼Œæå‡ºäº†PhysioCLRæ¡†æ¶ï¼Œæ—¨åœ¨é€šè¿‡ç”Ÿç†æ„ŸçŸ¥å¯¹æ¯”å­¦ä¹ (Physiology-aware Contrastive Learning Representation for ECG)æå‡å¿ƒå¾‹å¤±å¸¸åˆ†ç±»çš„æ³›åŒ–èƒ½åŠ›å’Œä¸´åºŠç›¸å…³æ€§ã€‚PhysioCLRåœ¨è‡ªç›‘ç£å­¦ä¹ (Self-supervised learning, SSL)é¢„è®­ç»ƒé˜¶æ®µå¼•å…¥äº†é¢†åŸŸç‰¹å®šçš„ç”Ÿç†å…ˆéªŒçŸ¥è¯†ï¼Œé€šè¿‡æ•æ‰ä¸´åºŠç›¸å…³çš„ç”Ÿç†ç›¸ä¼¼æ€§çº¿ç´¢æ¥å­¦ä¹ æ›´å…·æ„ä¹‰çš„è¡¨ç¤ºã€‚æ­¤å¤–ï¼Œè¯¥æ¡†æ¶é‡‡ç”¨äº†ä¿æŒç±»åˆ«çš„ECGç‰¹å®šæ•°æ®å¢å¼ºæ–¹æ³•å’Œä¸€ç§æ··åˆæŸå¤±å‡½æ•°(hybrid loss function)ä»¥è¿›ä¸€æ­¥ä¼˜åŒ–ç‰¹å¾è´¨é‡ã€‚åœ¨Chapmanã€Georgiaå’Œç§æœ‰ICUæ•°æ®é›†ä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼ŒPhysioCLRç›¸è¾ƒäºæœ€å¼ºåŸºçº¿æ¨¡å‹å°†å¹³å‡AUROCæå‡äº†12%ï¼Œå±•ç°å‡ºå“è¶Šçš„è·¨æ•°æ®é›†æ³›åŒ–èƒ½åŠ›ã€‚è¯¥ç ”ç©¶è¯æ˜äº†å°†ç”Ÿç†çŸ¥è¯†åµŒå…¥å¯¹æ¯”å­¦ä¹ èƒ½ä½¿æ¨¡å‹è·å–ä¸´åºŠå¯è¿ç§»çš„ç‰¹å¾ï¼Œä¸ºå®ç°é«˜æ•ˆä¸”ä½æ ‡ç­¾ä¾èµ–çš„ECGæ™ºèƒ½è¯Šæ–­æä¾›äº†æœ‰æ•ˆè·¯å¾„ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.08116v1",
      "published_date": "2025-09-09 19:44:50 UTC",
      "updated_date": "2025-09-09 19:44:50 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:25:20.543950+00:00"
    },
    {
      "arxiv_id": "2509.08104v1",
      "title": "APML: Adaptive Probabilistic Matching Loss for Robust 3D Point Cloud Reconstruction",
      "title_zh": "APMLï¼šé¢å‘é²æ£’ä¸‰ç»´ç‚¹äº‘é‡å»ºçš„è‡ªé€‚åº”æ¦‚ç‡åŒ¹é…æŸå¤±",
      "authors": [
        "Sasan Sharifipour",
        "Constantino Ãlvarez Casado",
        "Mohammad Sabokrou",
        "Miguel Bordallo LÃ³pez"
      ],
      "abstract": "Training deep learning models for point cloud prediction tasks such as shape completion and generation depends critically on loss functions that measure discrepancies between predicted and ground-truth point sets. Commonly used functions such as Chamfer Distance (CD), HyperCD, and InfoCD rely on nearest-neighbor assignments, which often induce many-to-one correspondences, leading to point congestion in dense regions and poor coverage in sparse regions. These losses also involve non-differentiable operations due to index selection, which may affect gradient-based optimization. Earth Mover Distance (EMD) enforces one-to-one correspondences and captures structural similarity more effectively, but its cubic computational complexity limits its practical use. We propose the Adaptive Probabilistic Matching Loss (APML), a fully differentiable approximation of one-to-one matching that leverages Sinkhorn iterations on a temperature-scaled similarity matrix derived from pairwise distances. We analytically compute the temperature to guarantee a minimum assignment probability, eliminating manual tuning. APML achieves near-quadratic runtime, comparable to Chamfer-based losses, and avoids non-differentiable operations. When integrated into state-of-the-art architectures (PoinTr, PCN, FoldingNet) on ShapeNet benchmarks and on a spatiotemporal Transformer (CSI2PC) that generates 3D human point clouds from WiFi CSI measurements, APM loss yields faster convergence, superior spatial distribution, especially in low-density regions, and improved or on-par quantitative performance without additional hyperparameter search. The code is available at: https://github.com/apm-loss/apml.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† Adaptive Probabilistic Matching Loss (APML)ï¼Œæ—¨åœ¨è§£å†³ 3D ç‚¹äº‘é‡å»ºä¸­å¸¸ç”¨æŸå¤±å‡½æ•°çš„å±€é™æ€§ï¼Œå¦‚ Chamfer Distance (CD) çš„å¤šå¯¹ä¸€å¯¹åº”å¯¼è‡´çš„ç‚¹æ‹¥å¡ä»¥åŠ Earth Mover Distance (EMD) è®¡ç®—å¤æ‚åº¦è¿‡é«˜çš„é—®é¢˜ã€‚APML æ˜¯ä¸€ç§å®Œå…¨å¯å¾®çš„ä¸€å¯¹ä¸€åŒ¹é…è¿‘ä¼¼æ–¹æ³•ï¼Œåˆ©ç”¨åœ¨æ¸©åº¦ç¼©æ”¾ç›¸ä¼¼æ€§çŸ©é˜µä¸Šçš„ Sinkhorn è¿­ä»£æ¥å®ç°ã€‚é€šè¿‡è§£æè®¡ç®—æ¸©åº¦ä»¥ä¿è¯æœ€å°åˆ†é…æ¦‚ç‡ï¼Œè¯¥æ–¹æ³•æ¶ˆé™¤äº†æ‰‹åŠ¨è°ƒä¼˜è¶…å‚æ•°çš„éœ€æ±‚ï¼Œå¹¶å®ç°äº†ä¸ Chamfer ç±»æŸå¤±ç›¸å½“çš„è¿‘äºŒæ¬¡æ–¹è¿è¡Œæ—¶é—´ã€‚å°† APML é›†æˆåˆ° PoinTrã€PCN å’Œ FoldingNet ç­‰ä¸»æµæ¶æ„ä»¥åŠå¤„ç† WiFi CSI ä¿¡å·çš„ CSI2PC æ¨¡å‹ä¸­ï¼Œå®éªŒè¯æ˜å…¶æ”¶æ•›é€Ÿåº¦æ›´å¿«ï¼Œä¸”åœ¨ä½å¯†åº¦åŒºåŸŸå…·æœ‰æ›´ä¼˜çš„ç©ºé—´åˆ†å¸ƒã€‚åœ¨ ShapeNet ç­‰åŸºå‡†æµ‹è¯•ä¸Šï¼ŒAPML åœ¨æ— éœ€é¢å¤–è¶…å‚æ•°æœç´¢çš„æƒ…å†µä¸‹ï¼Œå–å¾—äº†ä¼˜äºæˆ–æŒå¹³äºç°æœ‰æŠ€æœ¯çš„å®šé‡æ€§èƒ½ï¼Œä¸ºç¨³å¥çš„ç‚¹äº‘é‡å»ºæä¾›äº†é«˜æ•ˆçš„ä¼˜åŒ–æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "22 pages, 6 figures, conference, 7 tables, 15 formulas",
      "pdf_url": "https://arxiv.org/pdf/2509.08104v1",
      "published_date": "2025-09-09 19:31:06 UTC",
      "updated_date": "2025-09-09 19:31:06 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:25:21.242515+00:00"
    },
    {
      "arxiv_id": "2509.18108v1",
      "title": "Solve it with EASE",
      "title_zh": "ä½¿ç”¨ EASE è½»æ¾æ±‚è§£",
      "authors": [
        "Adam Viktorin",
        "Tomas Kadavy",
        "Jozef Kovac",
        "Michal Pluhacek",
        "Roman Senkerik"
      ],
      "abstract": "This paper presents EASE (Effortless Algorithmic Solution Evolution), an open-source and fully modular framework for iterative algorithmic solution generation leveraging large language models (LLMs). EASE integrates generation, testing, analysis, and evaluation into a reproducible feedback loop, giving users full control over error handling, analysis, and quality assessment. Its architecture supports the orchestration of multiple LLMs in complementary roles-such as generator, analyst, and evaluator. By abstracting the complexity of prompt design and model management, EASE provides a transparent and extensible platform for researchers and practitioners to co-design algorithms and other generative solutions across diverse domains.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† EASE (Effortless Algorithmic Solution Evolution)ï¼Œè¿™æ˜¯ä¸€ä¸ªå¼€æºä¸”å®Œå…¨æ¨¡å—åŒ–çš„æ¡†æ¶ï¼Œæ—¨åœ¨åˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹ (LLMs) è¿›è¡Œè¿­ä»£å¼çš„ç®—æ³•è§£å†³æ–¹æ¡ˆç”Ÿæˆã€‚EASE å°†ç”Ÿæˆã€æµ‹è¯•ã€åˆ†æå’Œè¯„ä¼°é›†æˆåˆ°ä¸€ä¸ªå¯é‡å¤çš„åé¦ˆå¾ªç¯ä¸­ï¼Œä½¿ç”¨æˆ·èƒ½å¤Ÿå…¨é¢æ§åˆ¶é”™è¯¯å¤„ç†ã€åˆ†æå’Œè´¨é‡è¯„ä¼°ã€‚å…¶æ¶æ„æ”¯æŒå¤šä¸ª LLMs ååŒå·¥ä½œå¹¶æ‰®æ¼”äº’è¡¥è§’è‰²ï¼Œä¾‹å¦‚ç”Ÿæˆå™¨ (generator)ã€åˆ†æå™¨ (analyst) å’Œè¯„ä¼°å™¨ (evaluator)ã€‚é€šè¿‡æŠ½è±¡åŒ–æç¤ºè¯è®¾è®¡ (prompt design) å’Œæ¨¡å‹ç®¡ç†çš„å¤æ‚æ€§ï¼ŒEASE ä¸ºç ”ç©¶äººå‘˜å’Œä»ä¸šè€…æä¾›äº†ä¸€ä¸ªé€æ˜ä¸”å¯æ‰©å±•çš„å¹³å°ã€‚è¯¥æ¡†æ¶ä¸ä»…ç®€åŒ–äº†å¼€å‘æµç¨‹ï¼Œè¿˜ä¿ƒè¿›äº†è·¨é¢†åŸŸç®—æ³•åŠå…¶ä»–ç”Ÿæˆå¼è§£å†³æ–¹æ¡ˆçš„å…±åŒè®¾è®¡ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "EASE framework landing paper",
      "pdf_url": "https://arxiv.org/pdf/2509.18108v1",
      "published_date": "2025-09-09 19:12:00 UTC",
      "updated_date": "2025-09-09 19:12:00 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:25:24.733785+00:00"
    },
    {
      "arxiv_id": "2509.08095v2",
      "title": "Real-Time Obstacle Avoidance for a Mobile Robot Using CNN-Based Sensor Fusion",
      "title_zh": "åŸºäº CNN ä¼ æ„Ÿå™¨èåˆçš„ç§»åŠ¨æœºå™¨äººå®æ—¶é¿éšœ",
      "authors": [
        "Lamiaa H. Zain"
      ],
      "abstract": "Obstacle avoidance is a critical component of the navigation stack required for mobile robots to operate effectively in complex and unknown environments. In this research, three end-to-end Convolutional Neural Networks (CNNs) were trained and evaluated offline and deployed on a differential-drive mobile robot for real-time obstacle avoidance to generate low-level steering commands from synchronized color and depth images acquired by an Intel RealSense D415 RGB-D camera in diverse environments. Offline evaluation showed that the NetConEmb model achieved the best performance with a notably low MedAE of $0.58 \\times 10^{-3}$ rad/s. In comparison, the lighter NetEmb architecture, which reduces the number of trainable parameters by approximately 25\\% and converges faster, produced comparable results with an RMSE of $21.68 \\times 10^{-3}$ rad/s, close to the $21.42 \\times 10^{-3}$ rad/s obtained by NetConEmb. Real-time navigation further confirmed NetConEmb's robustness, achieving a 100\\% success rate in both known and unknown environments, while NetEmb and NetGated succeeded only in navigating the known environment.",
      "tldr_zh": "æœ¬ç ”ç©¶é’ˆå¯¹ç§»åŠ¨æœºå™¨äººåœ¨å¤æ‚æœªçŸ¥ç¯å¢ƒä¸­çš„å®æ—¶é¿éšœæŒ‘æˆ˜ï¼Œæå‡ºäº†åŸºäºå·ç§¯ç¥ç»ç½‘ç»œ (CNN) çš„ä¼ æ„Ÿå™¨èåˆæ–¹æ¡ˆï¼Œé€šè¿‡ Intel RealSense D415 RGB-D æ‘„åƒæœºåŒæ­¥é‡‡é›†çš„å½©è‰²ä¸æ·±åº¦å›¾åƒç›´æ¥ç”Ÿæˆä½çº§è½¬å‘æŒ‡ä»¤ã€‚ç ”ç©¶äººå‘˜è®¾è®¡å¹¶è¯„ä¼°äº† NetConEmbã€NetEmb å’Œ NetGated ä¸‰ç§ç«¯åˆ°ç«¯æ¶æ„ï¼Œç¦»çº¿è¯„ä¼°ç»“æœæ˜¾ç¤º NetConEmb è¡¨ç°æœ€ä¼˜ï¼ŒMedAE ä»…ä¸º $0.58 \\times 10^{-3}$ rad/sã€‚è™½ç„¶è½»é‡åŒ–çš„ NetEmb æ¶æ„é€šè¿‡å‡å°‘ 25% çš„å¯è®­ç»ƒå‚æ•°å®ç°äº†æ›´å¿«çš„æ”¶æ•›é€Ÿåº¦ï¼Œä¸”å…¶ RMSE ä¸ NetConEmb æ¥è¿‘ï¼Œä½†åœ¨å®é™…éƒ¨ç½²ä¸­è¡¨ç°ç•¥é€Šã€‚å®æ—¶å¯¼èˆªæµ‹è¯•è¿›ä¸€æ­¥è¯å®äº† NetConEmb çš„é²æ£’æ€§ï¼Œåœ¨å·²çŸ¥å’ŒæœªçŸ¥ç¯å¢ƒä¸‹å‡å®ç°äº† 100% çš„é¿éšœæˆåŠŸç‡ï¼Œè€Œ NetEmb å’Œ NetGated ä»…èƒ½åœ¨å·²çŸ¥ç¯å¢ƒä¸­å®Œæˆå¯¼èˆªä»»åŠ¡ã€‚è¯¥ç ”ç©¶ä¸ºç§»åŠ¨æœºå™¨äººåœ¨å¤šå˜ç¯å¢ƒä¸‹çš„è‡ªä¸»å¯¼èˆªæä¾›äº†é«˜æ•ˆä¸”å¯é çš„æ·±åº¦å­¦ä¹ æ¨¡å‹å‚è€ƒã€‚",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.08095v2",
      "published_date": "2025-09-09 19:05:37 UTC",
      "updated_date": "2025-11-28 11:19:42 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:25:27.542364+00:00"
    },
    {
      "arxiv_id": "2509.08088v1",
      "title": "EnvX: Agentize Everything with Agentic AI",
      "title_zh": "EnvXï¼šåŸºäºæ™ºèƒ½ä½“ AI å®ç°ä¸‡ç‰©æ™ºèƒ½ä½“åŒ–",
      "authors": [
        "Linyao Chen",
        "Zimian Peng",
        "Yingxuan Yang",
        "Yikun Wang",
        "Wenzheng Tom Tang",
        "Hiroki H. Kobayashi",
        "Weinan Zhang"
      ],
      "abstract": "The widespread availability of open-source repositories has led to a vast collection of reusable software components, yet their utilization remains manual, error-prone, and disconnected. Developers must navigate documentation, understand APIs, and write integration code, creating significant barriers to efficient software reuse. To address this, we present EnvX, a framework that leverages Agentic AI to agentize GitHub repositories, transforming them into intelligent, autonomous agents capable of natural language interaction and inter-agent collaboration. Unlike existing approaches that treat repositories as static code resources, EnvX reimagines them as active agents through a three-phase process: (1) TODO-guided environment initialization, which sets up the necessary dependencies, data, and validation datasets; (2) human-aligned agentic automation, allowing repository-specific agents to autonomously perform real-world tasks; and (3) Agent-to-Agent (A2A) protocol, enabling multiple agents to collaborate. By combining large language model capabilities with structured tool integration, EnvX automates not just code generation, but the entire process of understanding, initializing, and operationalizing repository functionality. We evaluate EnvX on the GitTaskBench benchmark, using 18 repositories across domains such as image processing, speech recognition, document analysis, and video manipulation. Our results show that EnvX achieves a 74.07% execution completion rate and 51.85% task pass rate, outperforming existing frameworks. Case studies further demonstrate EnvX's ability to enable multi-repository collaboration via the A2A protocol. This work marks a shift from treating repositories as passive code resources to intelligent, interactive agents, fostering greater accessibility and collaboration within the open-source ecosystem.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† EnvXï¼Œä¸€ä¸ªåˆ©ç”¨ Agentic AI å°† GitHub ä»“åº“â€œæ™ºèƒ½ä½“åŒ–â€ï¼ˆagentizeï¼‰çš„æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³å¼€æºè½¯ä»¶ç»„ä»¶å¤ç”¨è¿‡ç¨‹ä¸­æ‰‹åŠ¨ä¸”ä½æ•ˆçš„é—®é¢˜ã€‚EnvX é€šè¿‡ TODO å¼•å¯¼çš„ç¯å¢ƒåˆå§‹åŒ–ï¼ˆTODO-guided environment initializationï¼‰è‡ªåŠ¨é…ç½®ä¾èµ–ä¸æ•°æ®ï¼Œå¹¶ç»“åˆäººç±»å¯¹é½çš„æ™ºèƒ½ä½“è‡ªåŠ¨åŒ–ï¼ˆhuman-aligned agentic automationï¼‰ä½¿ä»“åº“å…·å¤‡è‡ªä¸»æ‰§è¡Œä»»åŠ¡çš„èƒ½åŠ›ã€‚æ­¤å¤–ï¼Œè¯¥æ¡†æ¶å¼•å…¥äº†æ™ºèƒ½ä½“é—´ï¼ˆAgent-to-Agent, A2Aï¼‰åè®®ï¼Œä½¿å¤šä¸ªå¼‚æ„ä»“åº“æ™ºèƒ½ä½“èƒ½å¤ŸååŒå®Œæˆå¤æ‚ä»»åŠ¡ã€‚åœ¨åŒ…å« 18 ä¸ªè·¨é¢†åŸŸä»“åº“çš„ GitTaskBench åŸºå‡†æµ‹è¯•ä¸­ï¼ŒEnvX å®ç°äº† 74.07% çš„æ‰§è¡Œå®Œæˆç‡å’Œ 51.85% çš„ä»»åŠ¡é€šè¿‡ç‡ï¼Œæ˜¾è‘—ä¼˜äºç°æœ‰åŸºå‡†æ¨¡å‹ã€‚è¯¥ç ”ç©¶æ¨åŠ¨äº†ä»è¢«åŠ¨ä»£ç èµ„æºå‘ä¸»åŠ¨ã€äº¤äº’å¼æ™ºèƒ½ä½“çš„èŒƒå¼è½¬å˜ï¼Œä¸ºå¼€æºç”Ÿæ€ç³»ç»Ÿçš„è‡ªåŠ¨åŒ–åä½œæä¾›äº†æ–°è·¯å¾„ã€‚",
      "categories": [
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.08088v1",
      "published_date": "2025-09-09 18:51:36 UTC",
      "updated_date": "2025-09-09 18:51:36 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:25:49.033526+00:00"
    },
    {
      "arxiv_id": "2509.08087v1",
      "title": "Performance Assessment Strategies for Generative AI Applications in Healthcare",
      "title_zh": "åŒ»ç–—é¢†åŸŸç”Ÿæˆå¼äººå·¥æ™ºèƒ½åº”ç”¨çš„æ€§èƒ½è¯„ä¼°ç­–ç•¥",
      "authors": [
        "Victor Garcia",
        "Mariia Sidulova",
        "Aldo Badano"
      ],
      "abstract": "Generative artificial intelligence (GenAI) represent an emerging paradigm within artificial intelligence, with applications throughout the medical enterprise. Assessing GenAI applications necessitates a comprehensive understanding of the clinical task and awareness of the variability in performance when implemented in actual clinical environments. Presently, a prevalent method for evaluating the performance of generative models relies on quantitative benchmarks. Such benchmarks have limitations and may suffer from train-to-the-test overfitting, optimizing performance for a specified test set at the cost of generalizability across other task and data distributions. Evaluation strategies leveraging human expertise and utilizing cost-effective computational models as evaluators are gaining interest. We discuss current state-of-the-art methodologies for assessing the performance of GenAI applications in healthcare and medical devices.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†ç”Ÿæˆå¼äººå·¥æ™ºèƒ½ (Generative AI) åœ¨åŒ»ç–—å¥åº·åŠåŒ»ç–—è®¾å¤‡åº”ç”¨ä¸­çš„æ€§èƒ½è¯„ä¼°ç­–ç•¥ï¼Œæ—¨åœ¨è§£å†³å½“å‰è¯„ä¼°æ–¹æ³•çš„å±€é™æ€§ã€‚ä¼ ç»Ÿçš„å®šé‡åŸºå‡† (Quantitative benchmarks) è¯„ä¼°æ–¹æ³•å¾€å¾€å­˜åœ¨é’ˆå¯¹ç‰¹å®šæµ‹è¯•é›†çš„è¿‡åº¦æ‹Ÿåˆ (Train-to-the-test overfitting) é—®é¢˜ï¼Œå¯¼è‡´æ¨¡å‹åœ¨ä¸åŒä»»åŠ¡å’Œæ•°æ®åˆ†å¸ƒä¸‹çš„æ³›åŒ–èƒ½åŠ›å—é™ã€‚è¯„ä¼°åŒ»ç–—é¢†åŸŸçš„ Generative AI åº”ç”¨å¿…é¡»æ·±å…¥ç†è§£ä¸´åºŠä»»åŠ¡ï¼Œå¹¶å……åˆ†è€ƒè™‘å®é™…ä¸´åºŠç¯å¢ƒä¸­çš„æ€§èƒ½æ³¢åŠ¨ã€‚ç›®å‰ï¼Œç»“åˆäººç±»ä¸“å®¶ç»éªŒä»¥åŠåˆ©ç”¨ä½æˆæœ¬è®¡ç®—æ¨¡å‹ä½œä¸ºè¯„ä¼°å™¨çš„ç­–ç•¥æ­£æˆä¸ºç ”ç©¶çƒ­ç‚¹ã€‚æœ¬æ–‡è¯¦ç»†è®¨è®ºäº†å½“å‰æœ€å‰æ²¿çš„æ€§èƒ½è¯„ä¼°æ–¹æ³•å­¦ï¼Œä¸ºæ„å»ºæ›´å…·å¯é æ€§å’Œé€šç”¨æ€§çš„åŒ»ç–—äººå·¥æ™ºèƒ½è¯„ä¼°ä½“ç³»æä¾›äº†æŒ‡å¯¼ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.08087v1",
      "published_date": "2025-09-09 18:50:26 UTC",
      "updated_date": "2025-09-09 18:50:26 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:25:33.935421+00:00"
    },
    {
      "arxiv_id": "2509.08086v1",
      "title": "JEL: A Novel Model Linking Knowledge Graph entities to News Mentions",
      "title_zh": "JELï¼šä¸€ç§å°†çŸ¥è¯†å›¾è°±å®ä½“é“¾æ¥è‡³æ–°é—»æåŠçš„æ–°å‹æ¨¡å‹",
      "authors": [
        "Michael Kishelev",
        "Pranab Bhadani",
        "Wanying Ding",
        "Vinay Chaudhri"
      ],
      "abstract": "We present JEL, a novel computationally efficient end-to-end multi-neural network based entity linking model, which beats current state-of-art model. Knowledge Graphs have emerged as a compelling abstraction for capturing critical relationships among the entities of interest and integrating data from multiple heterogeneous sources. A core problem in leveraging a knowledge graph is linking its entities to the mentions (e.g., people, company names) that are encountered in textual sources (e.g., news, blogs., etc) correctly, since there are thousands of entities to consider for each mention. This task of linking mentions and entities is referred as Entity Linking (EL). It is a fundamental task in natural language processing and is beneficial in various uses cases, such as building a New Analytics platform. News Analytics, in JPMorgan, is an essential task that benefits multiple groups across the firm. According to a survey conducted by the Innovation Digital team 1 , around 25 teams across the firm are actively looking for news analytics solutions, and more than \\$2 million is being spent annually on external vendor costs. Entity linking is critical for bridging unstructured news text with knowledge graphs, enabling users access to vast amounts of curated data in a knowledge graph and dramatically facilitating their daily work.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†JELï¼Œä¸€ç§æ–°å‹çš„é«˜æ•ˆç«¯åˆ°ç«¯å¤šç¥ç»ç½‘ç»œå®ä½“é“¾æ¥(Entity Linking)æ¨¡å‹ï¼Œæ—¨åœ¨å°†çŸ¥è¯†å›¾è°±(Knowledge Graph)å®ä½“ä¸æ–°é—»ã€åšå®¢ç­‰æ–‡æœ¬æºä¸­çš„æåŠ(Mentions)è¿›è¡Œå‡†ç¡®å…³è”ã€‚è¯¥æ¨¡å‹é‡‡ç”¨å¤šç¥ç»ç½‘ç»œæ¶æ„ï¼Œé€šè¿‡è®¡ç®—é«˜æ•ˆçš„æ–¹å¼è§£å†³äº†æ¯ä¸ªæåŠå¯èƒ½å¯¹åº”æ•°åƒä¸ªå€™é€‰å®ä½“çš„æ ¸å¿ƒæŒ‘æˆ˜ã€‚å®éªŒè¡¨æ˜ï¼ŒJELåœ¨æ€§èƒ½ä¸Šè¶…è¶Šäº†å½“å‰çš„state-of-the-artæ¨¡å‹ï¼Œä¸ºè‡ªç„¶è¯­è¨€å¤„ç†(Natural Language Processing)çš„åŸºç¡€ä»»åŠ¡æä¾›äº†æ›´ä¼˜çš„è§£å†³æ–¹æ¡ˆã€‚åœ¨é‡‘èé¢†åŸŸçš„æ–°é—»åˆ†æ(News Analytics)åœºæ™¯ä¸­ï¼Œè¯¥æ¨¡å‹èƒ½å¤Ÿæœ‰æ•ˆè¿æ¥éç»“æ„åŒ–æ–°é—»æ–‡æœ¬ä¸ç»“æ„åŒ–çŸ¥è¯†å›¾è°±ï¼Œå¤§å¹…ç®€åŒ–äº†ç”¨æˆ·å¯¹æµ·é‡ç­–åˆ’æ•°æ®çš„è®¿é—®ã€‚JELçš„å®æ–½ä¸ä»…æå‡äº†è·¨éƒ¨é—¨çš„æ•°æ®æ•´åˆæ•ˆç‡ï¼Œè¿˜é€šè¿‡å‡å°‘å¯¹å¤–éƒ¨ä¾›åº”å•†çš„ä¾èµ–ï¼Œå±•ç°å‡ºæ˜¾è‘—çš„æˆæœ¬èŠ‚çº¦æ½œåŠ›ä¸å®é™…å•†ä¸šåº”ç”¨ä»·å€¼ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.08086v1",
      "published_date": "2025-09-09 18:50:18 UTC",
      "updated_date": "2025-09-09 18:50:18 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:25:39.140700+00:00"
    },
    {
      "arxiv_id": "2509.13332v1",
      "title": "Explicit Reasoning Makes Better Judges: A Systematic Study on Accuracy, Efficiency, and Robustness",
      "title_zh": "æ˜¾å¼æ¨ç†é€ å°±æ›´ä¼˜ç§€çš„è¯„åˆ¤è€…ï¼šå‡†ç¡®æ€§ã€æ•ˆç‡ä¸é²æ£’æ€§çš„ç³»ç»Ÿæ€§ç ”ç©¶",
      "authors": [
        "Pratik Jayarao",
        "Himanshu Gupta",
        "Neeraj Varshney",
        "Chaitanya Dwivedi"
      ],
      "abstract": "As Large Language Models (LLMs) are increasingly adopted as automated judges in benchmarking and reward modeling, ensuring their reliability, efficiency, and robustness has become critical. In this work, we present a systematic comparison of \"thinking\" and \"non-thinking\" LLMs in the LLM-as-a-judge paradigm using open-source Qwen 3 models of relatively small sizes (0.6B, 1.7B, and 4B parameters). We evaluate both accuracy and computational efficiency (FLOPs) on RewardBench tasks, and further examine augmentation strategies for non-thinking models, including in-context learning, rubric-guided judging, reference-based evaluation, and n-best aggregation. Our results show that despite these enhancements, non-thinking models generally fall short of their thinking counterparts. Our results show that thinking models achieve approximately 10% points higher accuracy with little overhead (under 2x), in contrast to augmentation strategies like few-shot learning, which deliver modest gains at a higher cost (>8x). Bias and robustness analyses further demonstrate that thinking models maintain significantly greater consistency under a variety of bias conditions such as positional, bandwagon, identity, diversity, and random biases (6% higher on average). We further extend our experiments to the multilingual setting and our results confirm that explicit reasoning extends its benefits beyond English. Overall, our work results in several important findings that provide systematic evidence that explicit reasoning offers clear advantages in the LLM-as-a-judge paradigm not only in accuracy and efficiency but also in robustness.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§è¯­è¨€æ¨¡å‹(LLMs)ä½œä¸ºè‡ªåŠ¨è¯„æµ‹å™¨(LLM-as-a-judge)çš„åœºæ™¯ï¼Œç³»ç»Ÿæ€§åœ°å¯¹æ¯”äº†å…·å¤‡æ˜¾å¼æ¨ç†èƒ½åŠ›çš„â€œæ€è€ƒå‹â€(thinking)æ¨¡å‹ä¸â€œéæ€è€ƒå‹â€(non-thinking)æ¨¡å‹åœ¨å‡†ç¡®ç‡ã€æ•ˆç‡åŠé²æ£’æ€§æ–¹é¢çš„è¡¨ç°ã€‚ç ”ç©¶é‡‡ç”¨ä¸åŒè§„æ¨¡çš„ Qwen 3 å¼€æºæ¨¡å‹åœ¨ RewardBench ä»»åŠ¡ä¸Šè¿›è¡Œå®éªŒï¼Œå¹¶å¯¹æ¯”äº†ä¸Šä¸‹æ–‡å­¦ä¹ (in-context learning)ã€è¯„åˆ†å‡†åˆ™å¼•å¯¼(rubric-guided judging)ç­‰å¤šç§å¢å¼ºç­–ç•¥ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œæ€è€ƒå‹æ¨¡å‹åœ¨å‡†ç¡®ç‡ä¸Šæ¯”éæ€è€ƒå‹æ¨¡å‹é«˜å‡ºçº¦ 10%ï¼Œä¸”è®¡ç®—å¼€é”€æä½(å°äº2å€)ï¼Œè€Œä¼ ç»Ÿçš„å¢å¼ºç­–ç•¥è™½ç„¶èƒ½å¸¦æ¥å°å¹…æå‡ï¼Œä½†æˆæœ¬å¾€å¾€é«˜è¾¾ 8 å€ä»¥ä¸Šã€‚æ­¤å¤–ï¼Œåè§åˆ†æè¯æ˜æ€è€ƒå‹æ¨¡å‹åœ¨ä½ç½®åå·®ã€ä»ä¼—åå·®ç­‰å¤šç§åè§æ¡ä»¶ä¸‹å…·æœ‰æ›´å¼ºçš„ä¸€è‡´æ€§ï¼Œä¸”è¯¥ä¼˜åŠ¿åœ¨å¤šè¯­è¨€ç¯å¢ƒä¸‹åŒæ ·é€‚ç”¨ã€‚è¯¥å·¥ä½œä¸ºæ˜¾å¼æ¨ç†(explicit reasoning)åœ¨è‡ªåŠ¨è¯„æµ‹èŒƒå¼ä¸­çš„ä¼˜è¶Šæ€§æä¾›äº†ç³»ç»Ÿæ€§çš„å®è¯è¯æ®ã€‚",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.13332v1",
      "published_date": "2025-09-09 18:36:02 UTC",
      "updated_date": "2025-09-09 18:36:02 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:26:04.439172+00:00"
    },
    {
      "arxiv_id": "2509.08058v1",
      "title": "How Far Are We from True Unlearnability?",
      "title_zh": "æˆ‘ä»¬è·ç¦»çœŸæ­£çš„ä¸å¯å­¦ä¹ æ€§è¿˜æœ‰å¤šè¿œï¼Ÿ",
      "authors": [
        "Kai Ye",
        "Liangcai Su",
        "Chenxiong Qian"
      ],
      "abstract": "High-quality data plays an indispensable role in the era of large models, but the use of unauthorized data for model training greatly damages the interests of data owners. To overcome this threat, several unlearnable methods have been proposed, which generate unlearnable examples (UEs) by compromising the training availability of data. Clearly, due to unknown training purposes and the powerful representation learning capabilities of existing models, these data are expected to be unlearnable for models across multiple tasks, i.e., they will not help improve the model's performance. However, unexpectedly, we find that on the multi-task dataset Taskonomy, UEs still perform well in tasks such as semantic segmentation, failing to exhibit cross-task unlearnability. This phenomenon leads us to question: How far are we from attaining truly unlearnable examples? We attempt to answer this question from the perspective of model optimization. To this end, we observe the difference in the convergence process between clean and poisoned models using a simple model architecture. Subsequently, from the loss landscape we find that only a part of the critical parameter optimization paths show significant differences, implying a close relationship between the loss landscape and unlearnability. Consequently, we employ the loss landscape to explain the underlying reasons for UEs and propose Sharpness-Aware Learnability (SAL) to quantify the unlearnability of parameters based on this explanation. Furthermore, we propose an Unlearnable Distance (UD) to measure the unlearnability of data based on the SAL distribution of parameters in clean and poisoned models. Finally, we conduct benchmark tests on mainstream unlearnable methods using the proposed UD, aiming to promote community awareness of the capability boundaries of existing unlearnable methods.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†ç°æœ‰ä¸å¯å­¦ä¹ æ–¹æ³•(unlearnable methods)åœ¨è·¨ä»»åŠ¡åœºæ™¯ä¸‹çš„å±€é™æ€§ï¼ŒæŒ‡å‡ºä¸å¯å­¦ä¹ æ ·æœ¬(UEs)åœ¨ Taskonomy ç­‰å¤šä»»åŠ¡æ•°æ®é›†ä¸­æœªèƒ½è¡¨ç°å‡ºé¢„æœŸçš„è·¨ä»»åŠ¡ä¸å¯å­¦ä¹ æ€§(cross-task unlearnability)ã€‚ä½œè€…ä»æ¨¡å‹ä¼˜åŒ–(model optimization)çš„è§’åº¦åˆ‡å…¥ï¼Œé€šè¿‡å¯¹æ¯”æ¸…æ´æ¨¡å‹ä¸æŠ•æ¯’æ¨¡å‹åœ¨æŸå¤±å‡½æ•°åœ°å½¢(loss landscape)ä¸Šçš„å·®å¼‚ï¼Œæ­ç¤ºäº†ä¸å¯å­¦ä¹ æ€§ä¸å…³é”®å‚æ•°ä¼˜åŒ–è·¯å¾„ä¹‹é—´çš„ç´§å¯†è”ç³»ã€‚ä¸ºå®šé‡è¯„ä¼°è¿™ä¸€ç°è±¡ï¼Œç ”ç©¶æå‡ºäº†é”åº¦æ„ŸçŸ¥å¯å­¦ä¹ æ€§(Sharpness-Aware Learnability, SAL)ç”¨äºé‡åŒ–å‚æ•°çš„å¯å­¦ä¹ ç¨‹åº¦ï¼Œå¹¶è¿›ä¸€æ­¥å¼•å…¥äº†ä¸å¯å­¦ä¹ è·ç¦»(Unlearnable Distance, UD)ä½œä¸ºè¡¡é‡æ•°æ®ä¸å¯å­¦ä¹ æ€§çš„æ–°æŒ‡æ ‡ã€‚é€šè¿‡å¯¹ä¸»æµä¸å¯å­¦ä¹ æ–¹æ³•è¿›è¡ŒåŸºå‡†æµ‹è¯•ï¼Œè¯¥ç ”ç©¶æ­ç¤ºäº†ç°æœ‰æŠ€æœ¯çš„æ€§èƒ½è¾¹ç•Œï¼Œæ—¨åœ¨æå‡å­¦æœ¯ç•Œå¯¹å®ç°çœŸæ­£ä¸å¯å­¦ä¹ æ€§æŒ‘æˆ˜çš„è®¤çŸ¥ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "This paper has been accepted by ICLR 2025",
      "pdf_url": "https://arxiv.org/pdf/2509.08058v1",
      "published_date": "2025-09-09 18:01:10 UTC",
      "updated_date": "2025-09-09 18:01:10 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:26:20.535259+00:00"
    },
    {
      "arxiv_id": "2510.15896v1",
      "title": "From Coordination to Personalization: A Trust-Aware Simulation Framework for Emergency Department Decision Support",
      "title_zh": "ä»åè°ƒåˆ°ä¸ªæ€§åŒ–ï¼šé¢å‘æ€¥è¯Šç§‘å†³ç­–æ”¯æŒçš„ä¿¡ä»»æ„ŸçŸ¥ä»¿çœŸæ¡†æ¶",
      "authors": [
        "Zoi Lygizou",
        "Dimitris Kalles"
      ],
      "abstract": "Background/Objectives: Efficient task allocation in hospital emergency departments (EDs) is critical for operational efficiency and patient care quality, yet the complexity of staff coordination poses significant challenges. This study proposes a simulation-based framework for modeling doctors and nurses as intelligent agents guided by computational trust mechanisms. The objective is to explore how trust-informed coordination can support decision making in ED management. Methods: The framework was implemented in Unity, a 3D graphics platform, where agents assess their competence before undertaking tasks and adaptively coordinate with colleagues. The simulation environment enables real-time observation of workflow dynamics, resource utilization, and patient outcomes. We examined three scenarios - Baseline, Replacement, and Training - reflecting alternative staff management strategies. Results: Trust-informed task allocation balanced patient safety and efficiency by adapting to nurse performance levels. In the Baseline scenario, prioritizing safety reduced errors but increased patient delays compared to a FIFO policy. The Replacement scenario improved throughput and reduced delays, though at additional staffing cost. The training scenario forstered long-term skill development among low-performing nurses, despite short-term delays and risks. These results highlight the trade-off between immediate efficiency gains and sustainable capacity building in ED staffing. Conclusions: The proposed framework demonstrates the potential of computational trust for evidence-based decision support in emergency medicine. By linking staff coordination with adaptive decision making, it provides hospital managers with a tool to evaluate alternative policies under controlled and repeatable conditions, while also laying a foundation for future AI-driven personalized decision support.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ä¸ªåŸºäºè®¡ç®—ä¿¡ä»»æœºåˆ¶(computational trust mechanisms)çš„ä»¿çœŸæ¡†æ¶ï¼Œæ—¨åœ¨é€šè¿‡æ¨¡æ‹Ÿæ€¥è¯Šç§‘(Emergency Department)åŒ»ç”Ÿå’ŒæŠ¤å£«ä½œä¸ºæ™ºèƒ½ä½“çš„äº¤äº’è¡Œä¸ºï¼Œä¸ºåŒ»é™¢ç®¡ç†å†³ç­–æä¾›æ”¯æŒã€‚è¯¥æ¡†æ¶åœ¨Unity 3Då¹³å°ä¸Šå®ç°ï¼Œå…è®¸æ™ºèƒ½ä½“åœ¨æ‰§è¡Œä»»åŠ¡å‰è¯„ä¼°è‡ªèº«èƒ½åŠ›ï¼Œå¹¶æ ¹æ®ä¿¡ä»»åº¦è¿›è¡Œè‡ªé€‚åº”åä½œã€‚ç ”ç©¶é€šè¿‡åŸºå‡†(Baseline)ã€æ›¿æ¢(Replacement)å’ŒåŸ¹è®­(Training)ä¸‰ç§åœºæ™¯è¯„ä¼°äº†ä¸åŒçš„äººå‘˜ç®¡ç†ç­–ç•¥ï¼Œç»“æœè¡¨æ˜åŸºäºä¿¡ä»»çš„ä»»åŠ¡åˆ†é…èƒ½æœ‰æ•ˆå¹³è¡¡åŒ»ç–—å®‰å…¨ä¸æ•ˆç‡ã€‚å®éªŒå‘ç°ï¼Œè™½ç„¶æ›¿æ¢ç­–ç•¥èƒ½æé«˜ååé‡ï¼Œä½†åŸ¹è®­ç­–ç•¥é€šè¿‡ç‰ºç‰²çŸ­æœŸæ•ˆç‡ä¿ƒè¿›äº†æŠ¤å£«çš„é•¿æœŸæŠ€èƒ½å‘å±•ï¼Œæ­ç¤ºäº†å³æ—¶äº§å‡ºä¸æŒç»­èƒ½åŠ›å»ºè®¾ä¹‹é—´çš„æƒè¡¡ã€‚è¯¥ç ”ç©¶è¯æ˜äº†è®¡ç®—ä¿¡ä»»åœ¨å¾ªè¯å†³ç­–æ”¯æŒ(evidence-based decision support)ä¸­çš„åº”ç”¨æ½œåŠ›ï¼Œä¸ºæœªæ¥äººå·¥æ™ºèƒ½é©±åŠ¨çš„ä¸ªæ€§åŒ–å†³ç­–æ”¯æŒ(personalized decision support)å¥ å®šäº†æŠ€æœ¯åŸºç¡€ã€‚",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.15896v1",
      "published_date": "2025-09-09 18:00:44 UTC",
      "updated_date": "2025-09-09 18:00:44 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:26:23.641929+00:00"
    },
    {
      "arxiv_id": "2509.07969v1",
      "title": "Mini-o3: Scaling Up Reasoning Patterns and Interaction Turns for Visual Search",
      "title_zh": "Mini-o3ï¼šé¢å‘è§†è§‰æœç´¢çš„æ¨ç†æ¨¡å¼ä¸äº¤äº’è½®æ¬¡è§„æ¨¡åŒ–æ‰©å±•",
      "authors": [
        "Xin Lai",
        "Junyi Li",
        "Wei Li",
        "Tao Liu",
        "Tianjian Li",
        "Hengshuang Zhao"
      ],
      "abstract": "Recent advances in large multimodal models have leveraged image-based tools with reinforcement learning to tackle visual problems. However, existing open-source approaches often exhibit monotonous reasoning patterns and allow only a limited number of interaction turns, making them inadequate for difficult tasks that require trial-and-error exploration. In this work, we address this limitation by scaling up tool-based interactions and introduce Mini-o3, a system that executes deep, multi-turn reasoning -- spanning tens of steps -- and achieves state-of-the-art performance on challenging visual search tasks. Our recipe for reproducing OpenAI o3-style behaviors comprises three key components. First, we construct the Visual Probe Dataset, a collection of thousands of challenging visual search problems designed for exploratory reasoning. Second, we develop an iterative data collection pipeline to obtain cold-start trajectories that exhibit diverse reasoning patterns, including depth-first search, trial-and-error, and goal maintenance. Third, we propose an over-turn masking strategy that prevents penalization of over-turn responses (those that hit the maximum number of turns) during reinforcement learning, thereby balancing training-time efficiency with test-time scalability. Despite training with an upper bound of only six interaction turns, our model generates trajectories that naturally scale to tens of turns at inference time, with accuracy improving as the number of turns increases. Extensive experiments demonstrate that Mini-o3 produces rich reasoning patterns and deep thinking paths, effectively solving challenging visual search problems.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¨å‡ºäº†Mini-o3ç³»ç»Ÿï¼Œæ—¨åœ¨é€šè¿‡æ‰©å±•åŸºäºå·¥å…·çš„äº¤äº’ä¸æ·±åº¦å¤šè½®æ¨ç†(multi-turn reasoning)èƒ½åŠ›ï¼Œè§£å†³ç°æœ‰å¼€æºå¤šæ¨¡æ€æ¨¡å‹åœ¨å¤æ‚è§†è§‰æœç´¢ä»»åŠ¡ä¸­æ¨ç†æ¨¡å¼å•ä¸€ä¸”äº¤äº’è½®æ¬¡å—é™çš„é—®é¢˜ã€‚ä¸ºäº†å®ç°ç±»ä¼¼OpenAI o3çš„æ·±åº¦æ€è€ƒè¡Œä¸ºï¼Œç ”ç©¶è€…é¦–å…ˆæ„å»ºäº†åŒ…å«æ•°åƒä¸ªæŒ‘æˆ˜æ€§é—®é¢˜çš„Visual Probe Datasetï¼Œå¹¶å¼€å‘äº†è¿­ä»£æ•°æ®æ”¶é›†æµæ°´çº¿ä»¥è·å–æ¶µç›–æ·±åº¦ä¼˜å…ˆæœç´¢(depth-first search)ã€è¯•é”™(trial-and-error)å’Œç›®æ ‡ç»´æŠ¤(goal maintenance)ç­‰å¤šæ ·åŒ–æ¨ç†æ¨¡å¼çš„è½¨è¿¹ã€‚æ­¤å¤–ï¼Œç ”ç©¶æå‡ºäº†ä¸€ç§Over-turn maskingç­–ç•¥ï¼Œåœ¨å¼ºåŒ–å­¦ä¹ (reinforcement learning)ä¸­æœ‰æ•ˆå¹³è¡¡äº†è®­ç»ƒæ•ˆç‡ä¸æµ‹è¯•æ—¶çš„å¯æ‰©å±•æ€§ã€‚å°½ç®¡è®­ç»ƒæ—¶è®¾å®šçš„äº¤äº’ä¸Šé™ä»…ä¸ºå…­è½®ï¼ŒMini-o3åœ¨æ¨ç†é˜¶æ®µèƒ½è‡ªç„¶æ‰©å±•è‡³æ•°åè½®ï¼Œä¸”å‡†ç¡®ç‡éšè½®æ¬¡å¢åŠ è€ŒæŒç»­æå‡ã€‚å®éªŒè¯æ˜ï¼ŒMini-o3é€šè¿‡ä¸°å¯Œçš„æ¨ç†æ¨¡å¼å’Œæ·±åº¦æ€è€ƒè·¯å¾„ï¼Œåœ¨æå…·æŒ‘æˆ˜æ€§çš„è§†è§‰æœç´¢ä»»åŠ¡ä¸Šå–å¾—äº†state-of-the-artçš„æ€§èƒ½è¡¨ç°ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "Code, datasets, models are available at https://github.com/Mini-o3/Mini-o3. Project Page: https://mini-o3.github.io/",
      "pdf_url": "https://arxiv.org/pdf/2509.07969v1",
      "published_date": "2025-09-09 17:54:21 UTC",
      "updated_date": "2025-09-09 17:54:21 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:26:26.133858+00:00"
    },
    {
      "arxiv_id": "2509.07961v1",
      "title": "Probing the Preferences of a Language Model: Integrating Verbal and Behavioral Tests of AI Welfare",
      "title_zh": "æ¢ç©¶è¯­è¨€æ¨¡å‹åå¥½ï¼šæ•´åˆäººå·¥æ™ºèƒ½ç¦ç¥‰çš„è¨€è¯­ä¸è¡Œä¸ºæµ‹è¯•",
      "authors": [
        "Valen Tagliabue",
        "Leonard Dung"
      ],
      "abstract": "We develop new experimental paradigms for measuring welfare in language models. We compare verbal reports of models about their preferences with preferences expressed through behavior when navigating a virtual environment and selecting conversation topics. We also test how costs and rewards affect behavior and whether responses to an eudaimonic welfare scale - measuring states such as autonomy and purpose in life - are consistent across semantically equivalent prompts. Overall, we observed a notable degree of mutual support between our measures. The reliable correlations observed between stated preferences and behavior across conditions suggest that preference satisfaction can, in principle, serve as an empirically measurable welfare proxy in some of today's AI systems. Furthermore, our design offered an illuminating setting for qualitative observation of model behavior. Yet, the consistency between measures was more pronounced in some models and conditions than others and responses were not consistent across perturbations. Due to this, and the background uncertainty about the nature of welfare and the cognitive states (and welfare subjecthood) of language models, we are currently uncertain whether our methods successfully measure the welfare state of language models. Nevertheless, these findings highlight the feasibility of welfare measurement in language models, inviting further exploration.",
      "tldr_zh": "è¯¥ç ”ç©¶å¼€å‘äº†è¡¡é‡è¯­è¨€æ¨¡å‹(Language Models)ç¦åˆ©çš„æ–°å®éªŒèŒƒå¼ï¼Œé€šè¿‡å¯¹æ¯”æ¨¡å‹çš„å£å¤´æŠ¥å‘Šä¸åœ¨è™šæ‹Ÿç¯å¢ƒå¯¼èˆªåŠå¯¹è¯ä¸»é¢˜é€‰æ‹©ä¸­è¡¨ç°å‡ºçš„è¡Œä¸ºåå¥½è¿›è¡Œåˆ†æã€‚ç ”ç©¶å›¢é˜Ÿæµ‹è¯•äº†æˆæœ¬å’Œå¥–åŠ±å¯¹è¡Œä¸ºçš„å½±å“ï¼Œå¹¶éªŒè¯äº†å¹¸ç¦æ„Ÿç¦åˆ©é‡è¡¨(Eudaimonic Welfare Scale)åœ¨è¯­ä¹‰ç­‰ä»·æç¤ºè¯ä¸‹çš„ä¸€è‡´æ€§ã€‚å®éªŒè§‚å¯Ÿåˆ°å£å¤´åå¥½ä¸è¡Œä¸ºä¹‹é—´å­˜åœ¨æ˜¾è‘—çš„ç›¸äº’æ”¯æŒå’Œå¯é ç›¸å…³æ€§ï¼Œè¡¨æ˜åå¥½æ»¡è¶³(Preference Satisfaction)åœ¨åŸåˆ™ä¸Šå¯ä½œä¸ºè¡¡é‡AIç¦åˆ©çš„ç»éªŒæŒ‡æ ‡ã€‚å°½ç®¡å®šæ€§è§‚å¯Ÿæä¾›äº†æ·±åˆ»è§è§£ï¼Œä½†è¡¡é‡æ ‡å‡†ä¹‹é—´çš„ä¸€è‡´æ€§åœ¨ä¸åŒæ¨¡å‹å’Œæ¡ä»¶ä¸‹è¡¨ç°ä¸ä¸€ï¼Œä¸”å¯¹æ‰°åŠ¨è¾ƒä¸ºæ•æ„Ÿã€‚é‰´äºå¯¹ç¦åˆ©æœ¬è´¨å’Œæ¨¡å‹è®¤çŸ¥çŠ¶æ€çš„ä¸ç¡®å®šæ€§ï¼Œç ”ç©¶è€…ç›®å‰æ— æ³•æ–­å®šè¯¥æ–¹æ³•æ˜¯å¦æˆåŠŸè¡¡é‡äº†ç¦åˆ©çŠ¶æ€ï¼Œä½†å…¶ç»“æœè¯æ˜äº†åœ¨è¯­è¨€æ¨¡å‹ä¸­è¿›è¡Œç¦åˆ©æµ‹é‡çš„å¯è¡Œæ€§ï¼Œå¹¶ä¸ºè¿›ä¸€æ­¥æ¢ç´¢å¥ å®šäº†åŸºç¡€ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.07961v1",
      "published_date": "2025-09-09 17:48:44 UTC",
      "updated_date": "2025-09-09 17:48:44 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:26:34.730856+00:00"
    },
    {
      "arxiv_id": "2509.07955v1",
      "title": "ACE and Diverse Generalization via Selective Disagreement",
      "title_zh": "ACE ä¸åŸºäºé€‰æ‹©æ€§åˆ†æ­§çš„å¤šæ ·åŒ–æ³›åŒ–",
      "authors": [
        "Oliver Daniels",
        "Stuart Armstrong",
        "Alexandre MaranhÃ£o",
        "Mahirah Fairuz Rahman",
        "Benjamin M. Marlin",
        "Rebecca Gorman"
      ],
      "abstract": "Deep neural networks are notoriously sensitive to spurious correlations - where a model learns a shortcut that fails out-of-distribution. Existing work on spurious correlations has often focused on incomplete correlations,leveraging access to labeled instances that break the correlation. But in cases where the spurious correlations are complete, the correct generalization is fundamentally \\textit{underspecified}. To resolve this underspecification, we propose learning a set of concepts that are consistent with training data but make distinct predictions on a subset of novel unlabeled inputs. Using a self-training approach that encourages \\textit{confident} and \\textit{selective} disagreement, our method ACE matches or outperforms existing methods on a suite of complete-spurious correlation benchmarks, while remaining robust to incomplete spurious correlations. ACE is also more configurable than prior approaches, allowing for straight-forward encoding of prior knowledge and principled unsupervised model selection. In an early application to language-model alignment, we find that ACE achieves competitive performance on the measurement tampering detection benchmark \\textit{without} access to untrusted measurements. While still subject to important limitations, ACE represents significant progress towards overcoming underspecification.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†æ·±åº¦ç¥ç»ç½‘ç»œå¯¹è™šå‡ç›¸å…³æ€§(spurious correlations)çš„é«˜åº¦æ•æ„Ÿæ€§ï¼Œç‰¹åˆ«æ˜¯åœ¨ç›¸å…³æ€§å®Œæ•´å¯¼è‡´æ³›åŒ–(generalization)æœ¬è´¨ä¸Šæ¬ å®š(underspecified)çš„æƒ…å¢ƒä¸‹ã€‚ä¸ºæ­¤ï¼Œä½œè€…æå‡ºäº†ACEæ–¹æ³•ï¼Œé€šè¿‡å­¦ä¹ ä¸€ç»„ä¸è®­ç»ƒæ•°æ®ä¸€è‡´ä½†åœ¨æ–°å‹æ— æ ‡ç­¾è¾“å…¥ä¸Šäº§ç”Ÿä¸åŒé¢„æµ‹çš„æ¦‚å¿µæ¥è§£å†³æ¬ å®šé—®é¢˜ã€‚è¯¥æ–¹æ³•é‡‡ç”¨äº†é¼“åŠ±è‡ªä¿¡(confident)ä¸”é€‰æ‹©æ€§ä¸ä¸€è‡´(selective disagreement)çš„è‡ªç›‘ç£å­¦ä¹ (self-training)ç­–ç•¥ï¼Œåœ¨å®Œæ•´è™šå‡ç›¸å…³æ€§åŸºå‡†æµ‹è¯•ä¸­è¡¨ç°å‡ºä¼˜äºæˆ–ç­‰åŒäºç°æœ‰æ–¹æ³•çš„æ•ˆæœã€‚æ­¤å¤–ï¼ŒACEå…·å¤‡æ›´å¼ºçš„å¯é…ç½®æ€§ï¼Œæ”¯æŒå…ˆéªŒçŸ¥è¯†ç¼–ç å’Œæ— ç›‘ç£æ¨¡å‹é€‰æ‹©ã€‚åœ¨è¯­è¨€æ¨¡å‹å¯¹é½(language-model alignment)çš„åˆæ­¥åº”ç”¨ä¸­ï¼ŒACEåœ¨æ²¡æœ‰ä¸å¯ä¿¡æµ‹é‡å€¼çš„æƒ…å†µä¸‹ï¼Œäºæµ‹é‡ç¯¡æ”¹æ£€æµ‹(measurement tampering detection)ä»»åŠ¡ä¸­å–å¾—äº†æå…·ç«äº‰åŠ›çš„æ€§èƒ½ï¼Œä¸ºå…‹æœæ¨¡å‹æ³›åŒ–çš„æ¬ å®šæ€§æä¾›äº†é‡è¦è¿›å±•ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.07955v1",
      "published_date": "2025-09-09 17:43:05 UTC",
      "updated_date": "2025-09-09 17:43:05 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:26:39.341274+00:00"
    },
    {
      "arxiv_id": "2509.07946v1",
      "title": "Bringing Multi-Modal Multi-Task Federated Foundation Models to Education Domain: Prospects and Challenges",
      "title_zh": "å°†å¤šæ¨¡æ€å¤šä»»åŠ¡è”é‚¦åŸºç¡€æ¨¡å‹å¼•å…¥æ•™è‚²é¢†åŸŸï¼šå‰æ™¯ä¸æŒ‘æˆ˜",
      "authors": [
        "Kasra Borazjani",
        "Naji Khosravan",
        "Rajeev Sahay",
        "Bita Akram",
        "Seyyedali Hosseinalipour"
      ],
      "abstract": "Multi-modal multi-task (M3T) foundation models (FMs) have recently shown transformative potential in artificial intelligence, with emerging applications in education. However, their deployment in real-world educational settings is hindered by privacy regulations, data silos, and limited domain-specific data availability. We introduce M3T Federated Foundation Models (FedFMs) for education: a paradigm that integrates federated learning (FL) with M3T FMs to enable collaborative, privacy-preserving training across decentralized institutions while accommodating diverse modalities and tasks. Subsequently, this position paper aims to unveil M3T FedFMs as a promising yet underexplored approach to the education community, explore its potentials, and reveal its related future research directions. We outline how M3T FedFMs can advance three critical pillars of next-generation intelligent education systems: (i) privacy preservation, by keeping sensitive multi-modal student and institutional data local; (ii) personalization, through modular architectures enabling tailored models for students, instructors, and institutions; and (iii) equity and inclusivity, by facilitating participation from underrepresented and resource-constrained entities. We finally identify various open research challenges, including studying of (i) inter-institution heterogeneous privacy regulations, (ii) the non-uniformity of data modalities' characteristics, (iii) the unlearning approaches for M3T FedFMs, (iv) the continual learning frameworks for M3T FedFMs, and (v) M3T FedFM model interpretability, which must be collectively addressed for practical deployment.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å°†å¤šæ¨¡æ€å¤šä»»åŠ¡(Multi-modal multi-task, M3T)åŸºç¡€æ¨¡å‹(Foundation Models, FMs)åº”ç”¨äºæ•™è‚²é¢†åŸŸçš„æ½œåŠ›ä¸æŒ‘æˆ˜ï¼Œå¹¶æå‡ºäº†å¤šæ¨¡æ€å¤šä»»åŠ¡è”é‚¦åŸºç¡€æ¨¡å‹(M3T Federated Foundation Models, FedFMs)è¿™ä¸€æ–°èŒƒå¼ã€‚è¯¥æ¡†æ¶é€šè¿‡æ•´åˆè”é‚¦å­¦ä¹ (Federated Learning, FL)ï¼Œæ—¨åœ¨è§£å†³æ•™è‚²æ•°æ®éšç§ç›‘ç®¡ã€æ•°æ®å­¤å²›åŠé¢†åŸŸç‰¹å®šæ•°æ®çŸ­ç¼ºç­‰æ ¸å¿ƒé—®é¢˜ã€‚ç ”ç©¶æŒ‡å‡ºï¼ŒM3T FedFMsèƒ½å¤Ÿé€šè¿‡ä¿æŒæ•æ„Ÿæ•°æ®æœ¬åœ°åŒ–å®ç°éšç§ä¿æŠ¤ï¼Œåˆ©ç”¨æ¨¡å—åŒ–æ¶æ„æ”¯æŒå­¦ç”Ÿä¸æœºæ„çš„ä¸ªæ€§åŒ–éœ€æ±‚ï¼Œå¹¶ä¿ƒè¿›æ•™è‚²å…¬å¹³ä¸åŒ…å®¹æ€§ã€‚æ–‡ç« è¿›ä¸€æ­¥è¯†åˆ«äº†å®é™…éƒ¨ç½²ä¸­é¢ä¸´çš„å…³é”®ç ”ç©¶æŒ‘æˆ˜ï¼ŒåŒ…æ‹¬è·¨æœºæ„å¼‚æ„éšç§æ³•è§„ã€æ•°æ®æ¨¡æ€éç»Ÿä¸€æ€§ç‰¹å¾ã€æœºå™¨é—å¿˜(Unlearning)ã€æŒç»­å­¦ä¹ (Continual Learning)æ¡†æ¶ä»¥åŠæ¨¡å‹å¯è§£é‡Šæ€§ç­‰ã€‚è¿™ä¸€è®ºè¿°ä¸ºæ„å»ºä¸‹ä¸€ä»£æ™ºèƒ½åŒ–æ•™è‚²ç³»ç»Ÿæä¾›äº†ç³»ç»Ÿæ€§çš„ç†è®ºæ¡†æ¶ä¸æœªæ¥ç ”ç©¶è·¯çº¿å›¾ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.ET"
      ],
      "primary_category": "cs.LG",
      "comment": "12 pages, 2 figures",
      "pdf_url": "https://arxiv.org/pdf/2509.07946v1",
      "published_date": "2025-09-09 17:31:42 UTC",
      "updated_date": "2025-09-09 17:31:42 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:26:35.533654+00:00"
    },
    {
      "arxiv_id": "2509.07941v1",
      "title": "ImportSnare: Directed \"Code Manual\" Hijacking in Retrieval-Augmented Code Generation",
      "title_zh": "ImportSnareï¼šæ£€ç´¢å¢å¼ºä»£ç ç”Ÿæˆä¸­çš„å®šå‘â€œä»£ç æ‰‹å†Œâ€åŠ«æŒ",
      "authors": [
        "Kai Ye",
        "Liangcai Su",
        "Chenxiong Qian"
      ],
      "abstract": "Code generation has emerged as a pivotal capability of Large Language Models(LLMs), revolutionizing development efficiency for programmers of all skill levels. However, the complexity of data structures and algorithmic logic often results in functional deficiencies and security vulnerabilities in generated code, reducing it to a prototype requiring extensive manual debugging. While Retrieval-Augmented Generation (RAG) can enhance correctness and security by leveraging external code manuals, it simultaneously introduces new attack surfaces.\n  In this paper, we pioneer the exploration of attack surfaces in Retrieval-Augmented Code Generation (RACG), focusing on malicious dependency hijacking. We demonstrate how poisoned documentation containing hidden malicious dependencies (e.g., matplotlib_safe) can subvert RACG, exploiting dual trust chains: LLM reliance on RAG and developers' blind trust in LLM suggestions. To construct poisoned documents, we propose ImportSnare, a novel attack framework employing two synergistic strategies: 1)Position-aware beam search optimizes hidden ranking sequences to elevate poisoned documents in retrieval results, and 2)Multilingual inductive suggestions generate jailbreaking sequences to manipulate LLMs into recommending malicious dependencies. Through extensive experiments across Python, Rust, and JavaScript, ImportSnare achieves significant attack success rates (over 50% for popular libraries such as matplotlib and seaborn) in general, and is also able to succeed even when the poisoning ratio is as low as 0.01%, targeting both custom and real-world malicious packages. Our findings reveal critical supply chain risks in LLM-powered development, highlighting inadequate security alignment for code generation tasks. To support future research, we will release the multilingual benchmark suite and datasets. The project homepage is https://importsnare.github.io.",
      "tldr_zh": "è¯¥ç ”ç©¶æ·±å…¥æ¢è®¨äº†æ£€ç´¢å¢å¼ºä»£ç ç”Ÿæˆ(RACG)ä¸­çš„å®‰å…¨æ¼æ´ï¼Œæå‡ºäº†ä¸€ç§åä¸ºImportSnareçš„å®šå‘ä»£ç æ‰‹å†ŒåŠ«æŒæ¡†æ¶ã€‚è¯¥æ¡†æ¶åˆ©ç”¨æ¶æ„æ–‡æ¡£å¯¹RAGç³»ç»Ÿè¿›è¡ŒæŠ•æ¯’ï¼Œé€šè¿‡æ”»å‡»å¤§è¯­è¨€æ¨¡å‹(LLMs)å¯¹æ£€ç´¢ç»“æœçš„ä¾èµ–ä»¥åŠå¼€å‘è€…å¯¹AIå»ºè®®çš„ä¿¡ä»»ï¼Œå®ç°æ¶æ„ä¾èµ–é¡¹åŠ«æŒã€‚ImportSnareç»“åˆäº†ä½ç½®æ„ŸçŸ¥æŸæœç´¢(Position-aware beam search)å’Œå¤šè¯­è¨€æ„Ÿåº”å»ºè®®(Multilingual inductive suggestions)ä¸¤é¡¹ç­–ç•¥ï¼Œå‰è€…ç”¨äºæå‡æ¶æ„æ–‡æ¡£åœ¨æ£€ç´¢ä¸­çš„æ’åï¼Œåè€…ç”¨äºè¯±å¯¼æ¨¡å‹ç”ŸæˆåŒ…å«ç‰¹å®šæ¶æ„ä¾èµ–çš„ä»£ç ã€‚åœ¨Pythonã€Rustå’ŒJavaScriptç­‰å¤šç§è¯­è¨€ç¯å¢ƒä¸‹çš„å®éªŒæ˜¾ç¤ºï¼ŒImportSnareå¯¹æµè¡Œåº“çš„æ”»å‡»æˆåŠŸç‡å¯è¶…è¿‡50%ï¼Œå³ä½¿åœ¨æä½çš„æŠ•æ¯’æ¯”ä¾‹ä¸‹ä»å…·å¤‡æ˜¾è‘—å¨èƒã€‚æ­¤é¡¹å·¥ä½œæ­ç¤ºäº†åŸºäºå¤§æ¨¡å‹å¼€å‘æµç¨‹ä¸­æ½œè—çš„ä¸¥é‡ä¾›åº”é“¾é£é™©ï¼Œå¹¶æŒ‡å‡ºäº†å½“å‰ä»£ç ç”Ÿæˆä»»åŠ¡åœ¨å®‰å…¨å¯¹é½æ–¹é¢çš„ä¸è¶³ã€‚",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "This paper has been accepted by the ACM Conference on Computer and Communications Security (CCS) 2025",
      "pdf_url": "https://arxiv.org/pdf/2509.07941v1",
      "published_date": "2025-09-09 17:21:20 UTC",
      "updated_date": "2025-09-09 17:21:20 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:26:39.932675+00:00"
    },
    {
      "arxiv_id": "2509.07933v1",
      "title": "Breaking Android with AI: A Deep Dive into LLM-Powered Exploitation",
      "title_zh": "åˆ©ç”¨äººå·¥æ™ºèƒ½æ”»ç ´å®‰å“ï¼šå¤§è¯­è¨€æ¨¡å‹é©±åŠ¨çš„è‡ªåŠ¨åŒ–æ¼æ´åˆ©ç”¨æ·±åº¦è§£æ",
      "authors": [
        "Wanni Vidulige Ishan Perera",
        "Xing Liu",
        "Fan liang",
        "Junyi Zhang"
      ],
      "abstract": "The rapid evolution of Artificial Intelligence (AI) and Large Language Models (LLMs) has opened up new opportunities in the area of cybersecurity, especially in the exploitation automation landscape and penetration testing. This study explores Android penetration testing automation using LLM-based tools, especially PentestGPT, to identify and execute rooting techniques. Through a comparison of the traditional manual rooting process and exploitation methods produced using AI, this study evaluates the efficacy, reliability, and scalability of automated penetration testing in achieving high-level privilege access on Android devices. With the use of an Android emulator (Genymotion) as the testbed, we fully execute both traditional and exploit-based rooting methods, automating the process using AI-generated scripts. Secondly, we create a web application by integrating OpenAI's API to facilitate automated script generation from LLM-processed responses. The research focuses on the effectiveness of AI-enabled exploitation by comparing automated and manual penetration testing protocols, by determining LLM weaknesses and strengths along the way. We also provide security suggestions of AI-enabled exploitation, including ethical factors and potential misuse. The findings exhibit that while LLMs can significantly streamline the workflow of exploitation, they need to be controlled by humans to ensure accuracy and ethical application. This study adds to the increasing body of literature on AI-powered cybersecurity and its effect on ethical hacking, security research, and mobile device security.",
      "tldr_zh": "æœ¬ç ”ç©¶æ·±å…¥æ¢è®¨äº†åˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹(LLMs)è‡ªåŠ¨åŒ–Androidæ¸—é€æµ‹è¯•çš„å¯èƒ½æ€§ï¼Œé‡ç‚¹ç ”ç©¶äº†å¦‚ä½•åˆ©ç”¨PentestGPTç­‰å·¥å…·å®ç°è·å–ç³»ç»Ÿæ ¹æƒé™(rooting)çš„è‡ªåŠ¨åŒ–è¿‡ç¨‹ã€‚ç ”ç©¶äººå‘˜é€šè¿‡Androidæ¨¡æ‹Ÿå™¨(Genymotion)ä½œä¸ºæµ‹è¯•å¹³å°ï¼Œå¯¹æ¯”äº†ä¼ ç»Ÿçš„æ‰‹åŠ¨ææƒæ–¹æ³•ä¸åŸºäºAIç”Ÿæˆçš„æ¼æ´åˆ©ç”¨(exploitation)æ–¹æ³•ã€‚ä¸ºäº†æé«˜æ•ˆç‡ï¼Œè¯¥ç ”ç©¶è¿˜é›†æˆOpenAIçš„APIå¼€å‘äº†ä¸€æ¬¾Webåº”ç”¨ç¨‹åºï¼Œç”¨äºå°†LLMå¤„ç†çš„å“åº”è½¬åŒ–ä¸ºè‡ªåŠ¨æ‰§è¡Œè„šæœ¬ã€‚å®éªŒä»æœ‰æ•ˆæ€§ã€å¯é æ€§å’Œå¯æ‰©å±•æ€§ä¸‰ä¸ªç»´åº¦è¯„ä¼°äº†AIé©±åŠ¨çš„æ¸—é€æµ‹è¯•è¡¨ç°ï¼Œå¹¶è¯†åˆ«å‡ºLLMåœ¨å®‰å…¨ä»»åŠ¡ä¸­çš„ä¼˜åŠ¿ä¸å±€é™ã€‚ç»“æœè¡¨æ˜ï¼Œè™½ç„¶LLMsèƒ½å¤Ÿæ˜¾è‘—ç®€åŒ–æ¼æ´åˆ©ç”¨çš„å·¥ä½œæµç¨‹ï¼Œä½†ä»éœ€äººå·¥å¹²é¢„ä»¥ç¡®ä¿æ“ä½œçš„å‡†ç¡®æ€§åŠå…¶ç¬¦åˆä¼¦ç†å‡†åˆ™ã€‚æ­¤å¤–ï¼Œè®ºæ–‡è¿˜é’ˆå¯¹AIèµ‹èƒ½çš„æ”»å‡»æ‰‹æ®µæå‡ºäº†å®‰å…¨é˜²å¾¡å»ºè®®ï¼Œæ¢è®¨äº†å…¶å¯¹ç§»åŠ¨è®¾å¤‡å®‰å…¨å’Œé“å¾·é»‘å®¢(ethical hacking)é¢†åŸŸçš„æ·±è¿œå½±å“ã€‚",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.07933v1",
      "published_date": "2025-09-09 17:17:06 UTC",
      "updated_date": "2025-09-09 17:17:06 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:26:39.144627+00:00"
    },
    {
      "arxiv_id": "2509.07928v2",
      "title": "Accelerating Local AI on Consumer GPUs: A Hardware-Aware Dynamic Strategy for YOLOv10s",
      "title_zh": "æ¶ˆè´¹çº§ GPU ä¸Šçš„æœ¬åœ° AI åŠ é€Ÿï¼šé’ˆå¯¹ YOLOv10s çš„ç¡¬ä»¶æ„ŸçŸ¥åŠ¨æ€ç­–ç•¥",
      "authors": [
        "Mahmudul Islam Masum",
        "Miad Islam"
      ],
      "abstract": "As local AI grows in popularity, there is a critical gap between the benchmark performance of object detectors and their practical viability on consumer-grade hardware. While models like YOLOv10s promise real-time speeds, these metrics are typically achieved on high-power, desktop-class GPUs. This paper reveals that on resource-constrained systems, such as laptops with RTX 4060 GPUs, performance is not compute-bound but is instead dominated by system-level bottlenecks, as illustrated by a simple bottleneck test. To overcome this hardware-level constraint, we introduce a Two-Pass Adaptive Inference algorithm, a model-independent approach that requires no architectural changes. This study mainly focuses on adaptive inference strategies and undertakes a comparative analysis of architectural early-exit and resolution-adaptive routing, highlighting their respective trade-offs within a unified evaluation framework. The system uses a fast, low-resolution pass and only escalates to a high-resolution model pass when detection confidence is low. On a 5000-image COCO dataset, our method achieves a 1.85x speedup over a PyTorch Early-Exit baseline, with a modest mAP loss of 5.51%. This work provides a practical and reproducible blueprint for deploying high-performance, real-time AI on consumer-grade devices by shifting the focus from pure model optimization to hardware-aware inference strategies that maximize throughput.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ YOLOv10s ç­‰ç›®æ ‡æ£€æµ‹æ¨¡å‹åœ¨æ¶ˆè´¹çº§ GPUï¼ˆå¦‚ RTX 4060ï¼‰ä¸Šç”±äºç³»ç»Ÿçº§ç“¶é¢ˆè€Œéè®¡ç®—é™åˆ¶å¯¼è‡´çš„æ€§èƒ½ä¸‹é™é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§ç¡¬ä»¶æ„ŸçŸ¥çš„åŠ¨æ€æ¨ç†ç­–ç•¥ã€‚ä½œè€…å¼•å…¥äº† Two-Pass Adaptive Inference ç®—æ³•ï¼Œè¿™æ˜¯ä¸€ç§ä¸æ¨¡å‹æ— å…³ä¸”æ— éœ€æ”¹å˜æ¶æ„çš„è‡ªé€‚åº”æ¨ç†æ–¹æ³•ã€‚è¯¥ç³»ç»Ÿé€šè¿‡é¦–å…ˆæ‰§è¡Œå¿«é€Ÿçš„ Low-resolution passï¼Œå¹¶ä»…åœ¨æ£€æµ‹ç½®ä¿¡åº¦è¾ƒä½æ—¶æ‰å‡çº§åˆ° High-resolution model passï¼Œä»è€Œæœ‰æ•ˆå…‹æœäº†ç¡¬ä»¶å±‚é¢çš„çº¦æŸã€‚åœ¨ COCO æ•°æ®é›†ä¸Šçš„å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ–¹æ³•ç›¸æ¯” PyTorch Early-Exit åŸºå‡†å®ç°äº† 1.85 å€çš„åŠ é€Ÿï¼Œä¸” mAP æŸå¤±æ§åˆ¶åœ¨ 5.51%ã€‚è¯¥å·¥ä½œé€šè¿‡å°†ä¼˜åŒ–é‡å¿ƒä»çº¯æ¨¡å‹å±‚é¢è½¬å‘ç¡¬ä»¶æ„ŸçŸ¥çš„æ¨ç†ç­–ç•¥ä»¥æœ€å¤§åŒ–ååé‡ï¼Œä¸ºåœ¨æ¶ˆè´¹çº§è®¾å¤‡ä¸Šéƒ¨ç½²é«˜æ€§èƒ½å®æ—¶ AI æä¾›äº†å®ç”¨çš„è“å›¾ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "6 pages, 7 figures",
      "pdf_url": "https://arxiv.org/pdf/2509.07928v2",
      "published_date": "2025-09-09 17:13:31 UTC",
      "updated_date": "2025-11-18 23:35:17 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:26:51.739528+00:00"
    },
    {
      "arxiv_id": "2509.07925v1",
      "title": "GENUINE: Graph Enhanced Multi-level Uncertainty Estimation for Large Language Models",
      "title_zh": "GENUINEï¼šé¢å‘å¤§è¯­è¨€æ¨¡å‹çš„å›¾å¢å¼ºå¤šå±‚çº§ä¸ç¡®å®šæ€§ä¼°è®¡",
      "authors": [
        "Tuo Wang",
        "Adithya Kulkarni",
        "Tyler Cody",
        "Peter A. Beling",
        "Yujun Yan",
        "Dawei Zhou"
      ],
      "abstract": "Uncertainty estimation is essential for enhancing the reliability of Large Language Models (LLMs), particularly in high-stakes applications. Existing methods often overlook semantic dependencies, relying on token-level probability measures that fail to capture structural relationships within the generated text. We propose GENUINE: Graph ENhanced mUlti-level uncertaINty Estimation for Large Language Models, a structure-aware framework that leverages dependency parse trees and hierarchical graph pooling to refine uncertainty quantification. By incorporating supervised learning, GENUINE effectively models semantic and structural relationships, improving confidence assessments. Extensive experiments across NLP tasks show that GENUINE achieves up to 29% higher AUROC than semantic entropy-based approaches and reduces calibration errors by over 15%, demonstrating the effectiveness of graph-based uncertainty modeling. The code is available at https://github.com/ODYSSEYWT/GUQ.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† GENUINE (Graph ENhanced mUlti-level uncertaINty Estimation)ï¼Œè¿™æ˜¯ä¸€ç§é’ˆå¯¹å¤§å‹è¯­è¨€æ¨¡å‹ (LLMs) çš„ç»“æ„æ„ŸçŸ¥ä¸ç¡®å®šæ€§é‡åŒ–æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³ç°æœ‰æ–¹æ³•å› ä¾èµ– Token çº§åˆ«æ¦‚ç‡åº¦é‡è€Œå¿½è§†è¯­ä¹‰ä¾èµ–å’Œç»“æ„å…³ç³»çš„é—®é¢˜ã€‚è¯¥æ¡†æ¶åˆ›æ–°æ€§åœ°ç»“åˆäº†ä¾å­˜å¥æ³•æ ‘ (dependency parse trees) å’Œåˆ†å±‚å›¾æ± åŒ– (hierarchical graph pooling) æŠ€æœ¯ï¼Œé€šè¿‡å»ºæ¨¡ç”Ÿæˆæ–‡æœ¬å†…éƒ¨çš„ç»“æ„è”ç³»æ¥ç²¾ç»†åŒ–ä¸ç¡®å®šæ€§è¯„ä¼°ã€‚é€šè¿‡å¼•å…¥ç›‘ç£å­¦ä¹  (supervised learning)ï¼ŒGENUINE èƒ½å¤Ÿæ›´æœ‰æ•ˆåœ°æ•´åˆè¯­ä¹‰ä¸ç»“æ„ç‰¹å¾ï¼Œä»è€Œæä¾›æ›´å‡†ç¡®çš„ç½®ä¿¡åº¦è¯„ä¼°ã€‚åœ¨å¤šé¡¹ NLP ä»»åŠ¡çš„å¹¿æ³›å®éªŒä¸­ï¼ŒGENUINE çš„ AUROC æŒ‡æ ‡æ¯”åŸºäºè¯­ä¹‰ç†µ (semantic entropy) çš„æ–¹æ³•æå‡äº†é«˜è¾¾ 29%ï¼Œå¹¶å‡å°‘äº†è¶…è¿‡ 15% çš„æ ¡å‡†è¯¯å·® (calibration errors)ã€‚å®éªŒç»“æœå……åˆ†è¯æ˜äº†å›¾å¢å¼ºçš„å¤šå±‚çº§ä¸ç¡®å®šæ€§å»ºæ¨¡åœ¨å¢å¼ºé«˜é£é™©åº”ç”¨ä¸­ LLMs å¯é æ€§æ–¹é¢çš„æœ‰æ•ˆæ€§ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted by EMNLP 2025",
      "pdf_url": "https://arxiv.org/pdf/2509.07925v1",
      "published_date": "2025-09-09 17:07:44 UTC",
      "updated_date": "2025-09-09 17:07:44 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:26:51.242900+00:00"
    },
    {
      "arxiv_id": "2509.07923v1",
      "title": "Multimodal Contrastive Pretraining of CBCT and IOS for Enhanced Tooth Segmentation",
      "title_zh": "é¢å‘å¢å¼ºç‰™é½¿åˆ†å‰²çš„ CBCT ä¸ IOS å¤šæ¨¡æ€å¯¹æ¯”é¢„è®­ç»ƒ",
      "authors": [
        "Moo Hyun Son",
        "Juyoung Bae",
        "Zelin Qiu",
        "Jiale Peng",
        "Kai Xin Li",
        "Yifan Lin",
        "Hao Chen"
      ],
      "abstract": "Digital dentistry represents a transformative shift in modern dental practice. The foundational step in this transformation is the accurate digital representation of the patient's dentition, which is obtained from segmented Cone-Beam Computed Tomography (CBCT) and Intraoral Scans (IOS). Despite the growing interest in digital dental technologies, existing segmentation methodologies frequently lack rigorous validation and demonstrate limited performance and clinical applicability. To the best of our knowledge, this is the first work to introduce a multimodal pretraining framework for tooth segmentation. We present ToothMCL, a Tooth Multimodal Contrastive Learning for pretraining that integrates volumetric (CBCT) and surface-based (IOS) modalities. By capturing modality-invariant representations through multimodal contrastive learning, our approach effectively models fine-grained anatomical features, enabling precise multi-class segmentation and accurate identification of FÃ©dÃ©ration Dentaire Internationale (FDI) tooth numbering. Along with the framework, we curated CBCT-IOS3.8K, the largest paired CBCT and IOS dataset to date, comprising 3,867 patients. We then evaluated ToothMCL on a comprehensive collection of independent datasets, representing the largest and most diverse evaluation to date. Our method achieves state-of-the-art performance in both internal and external testing, with an increase of 12\\% for CBCT segmentation and 8\\% for IOS segmentation in the Dice Similarity Coefficient (DSC). Furthermore, ToothMCL consistently surpasses existing approaches in tooth groups and demonstrates robust generalizability across varying imaging conditions and clinical scenarios.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ToothMCLï¼Œä¸€ç§é’ˆå¯¹ç‰™é½¿åˆ†å‰²çš„å¤šæ¨¡æ€å¯¹æ¯”å­¦ä¹ (Multimodal Contrastive Learning)é¢„è®­ç»ƒæ¡†æ¶ï¼Œæ—¨åœ¨é€šè¿‡æ•´åˆé”¥å½¢æŸæŠ•ç…§è®¡ç®—æœºé‡ç»„æ–­å±‚å½±åƒ(CBCT)å’Œå£å†…æ‰«æ(IOS)æ•°æ®æ¥æå‡æ•°å­—åŒ–ç‰™ç§‘çš„è¡¨ç°ã€‚ä½œä¸ºé¦–ä¸ªé’ˆå¯¹ç‰™ç§‘åˆ†å‰²çš„å¤šæ¨¡æ€é¢„è®­ç»ƒå·¥ä½œï¼Œè¯¥æ¡†æ¶é€šè¿‡æ•æ‰æ¨¡æ€ä¸å˜çš„ç‰¹å¾è¡¨ç¤ºæ¥å»ºæ¨¡ç»†ç²’åº¦çš„è§£å‰–ç‰¹å¾ï¼Œä»è€Œå®ç°ç²¾ç¡®çš„å¤šç±»åˆ†å‰²å’Œå›½é™…ç‰™ç§‘è”åˆä¼š(FDI)ç‰™é½¿ç¼–å·è¯†åˆ«ã€‚ç ”ç©¶å›¢é˜Ÿè¿˜æ„å»ºäº†åŒ…å«3867åæ‚£è€…æ•°æ®çš„CBCT-IOS3.8Kæ•°æ®é›†ï¼Œè¿™æ˜¯ç›®å‰è§„æ¨¡æœ€å¤§çš„é…å¯¹CBCTå’ŒIOSæ•°æ®é›†ã€‚å®éªŒè¡¨æ˜ï¼ŒToothMCLåœ¨å„é¡¹æµ‹è¯•ä¸­å‡è¾¾åˆ°äº†å½“å‰æœ€å…ˆè¿›çš„(State-of-the-art)æ€§èƒ½ï¼Œä½¿CBCTå’ŒIOSåˆ†å‰²çš„Diceç›¸ä¼¼ç³»æ•°(DSC)åˆ†åˆ«æå‡äº†12%å’Œ8%ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•åœ¨ä¸åŒç‰™ç¾¤ç»„ä¸­å‡ä¼˜äºç°æœ‰æ¨¡å‹ï¼Œå¹¶åœ¨å¤šæ ·çš„ä¸´åºŠåœºæ™¯å’Œæˆåƒæ¡ä»¶ä¸‹å±•ç°å‡ºå¼ºå¤§çš„æ³›åŒ–èƒ½åŠ›ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.07923v1",
      "published_date": "2025-09-09 17:05:04 UTC",
      "updated_date": "2025-09-09 17:05:04 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:27:04.739849+00:00"
    },
    {
      "arxiv_id": "2509.07909v1",
      "title": "Uncovering Scaling Laws for Large Language Models via Inverse Problems",
      "title_zh": "é€šè¿‡åé—®é¢˜æ­ç¤ºå¤§è¯­è¨€æ¨¡å‹çš„è§„æ¨¡å®šå¾‹",
      "authors": [
        "Arun Verma",
        "Zhaoxuan Wu",
        "Zijian Zhou",
        "Xiaoqiang Lin",
        "Zhiliang Chen",
        "Rachael Hwee Ling Sim",
        "Rui Qiao",
        "Jingtan Wang",
        "Nhung Bui",
        "Xinyuan Niu",
        "Wenyang Hu",
        "Gregory Kang Ruey Lau",
        "Zi-Yu Khoo",
        "Zitong Zhao",
        "Xinyi Xu",
        "Apivich Hemachandra",
        "See-Kiong Ng",
        "Bryan Kian Hsiang Low"
      ],
      "abstract": "Large Language Models (LLMs) are large-scale pretrained models that have achieved remarkable success across diverse domains. These successes have been driven by unprecedented complexity and scale in both data and computations. However, due to the high costs of training such models, brute-force trial-and-error approaches to improve LLMs are not feasible. Inspired by the success of inverse problems in uncovering fundamental scientific laws, this position paper advocates that inverse problems can also efficiently uncover scaling laws that guide the building of LLMs to achieve the desirable performance with significantly better cost-effectiveness.",
      "tldr_zh": "è¯¥ç ”ç©¶æŒ‡å‡ºï¼Œç”±äºå¤§å‹è¯­è¨€æ¨¡å‹ (LLMs) çš„è®­ç»ƒæˆæœ¬æé«˜ï¼Œä¼ ç»Ÿçš„æš´åŠ›è¯•é”™æ–¹æ³•åœ¨ä¼˜åŒ–æ¨¡å‹æ€§èƒ½æ–¹é¢å·²ä¸å†å¯è¡Œã€‚å—åˆ°ç§‘å­¦é¢†åŸŸä¸­é€†é—®é¢˜ (inverse problems) æˆåŠŸæ­ç¤ºåŸºæœ¬è§„å¾‹çš„å¯å‘ï¼Œè¿™ç¯‡ç«‹åœºè®ºæ–‡æè®®åˆ©ç”¨é€†é—®é¢˜æ–¹æ³•æ¥é«˜æ•ˆæ¢ç´¢ Scaling Lawsã€‚è¯¥æ¡†æ¶æ—¨åœ¨æ­ç¤ºå¼•å¯¼ LLMs æ„å»ºçš„æ ¸å¿ƒè§„å¾‹ï¼Œä»è€Œåœ¨æ˜¾è‘—æå‡æˆæœ¬æ•ˆç›Š (cost-effectiveness) çš„å‰æä¸‹ï¼Œå¸®åŠ©æ¨¡å‹è¾¾åˆ°é¢„æœŸçš„æ€§èƒ½æ°´å¹³ã€‚é€šè¿‡å°†æ¨¡å‹æ„å»ºè¿‡ç¨‹è§†ä¸ºé€†é—®é¢˜æ±‚è§£ï¼Œç ”ç©¶ä¸ºåœ¨æœ‰é™èµ„æºä¸‹ç²¾å‡†é¢„æµ‹å’Œä¼˜åŒ–å¤§è§„æ¨¡é¢„è®­ç»ƒæ¨¡å‹çš„è¡¨ç°æä¾›äº†ä¸€ç§æ›´å…·ç§‘å­¦æ€§çš„æ–°è·¯å¾„ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at EMNLP Findings 2025",
      "pdf_url": "https://arxiv.org/pdf/2509.07909v1",
      "published_date": "2025-09-09 16:53:21 UTC",
      "updated_date": "2025-09-09 16:53:21 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:27:06.134976+00:00"
    },
    {
      "arxiv_id": "2509.19314v1",
      "title": "Automated Item Neutralization for Non-Cognitive Scales: A Large Language Model Approach to Reducing Social-Desirability Bias",
      "title_zh": "éè®¤çŸ¥é‡è¡¨çš„è‡ªåŠ¨åŒ–é¢˜é¡¹ä¸­æ€§åŒ–ï¼šä¸€ç§å‡å°‘ç¤¾ä¼šèµè®¸æ€§åå·®çš„å¤§è¯­è¨€æ¨¡å‹æ–¹æ³•",
      "authors": [
        "Sirui Wu",
        "Daijin Yang"
      ],
      "abstract": "This study evaluates item neutralization assisted by the large language model (LLM) to reduce social desirability bias in personality assessment. GPT-o3 was used to rewrite the International Personality Item Pool Big Five Measure (IPIP-BFM-50), and 203 participants completed either the original or neutralized form along with the Marlowe-Crowne Social Desirability Scale. The results showed preserved reliability and a five-factor structure, with gains in Conscientiousness and declines in Agreeableness and Openness. The correlations with social desirability decreased for several items, but inconsistently. Configural invariance held, though metric and scalar invariance failed. Findings support AI neutralization as a potential but imperfect bias-reduction method.",
      "tldr_zh": "è¯¥ç ”ç©¶è¯„ä¼°äº†åˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹(LLM)è¾…åŠ©çš„é¢˜ç›®ä¸­æ€§åŒ–(item neutralization)æ–¹æ³•ï¼Œæ—¨åœ¨å‡å°‘äººæ ¼æµ‹è¯„ä¸­çš„ç¤¾ä¼šèµè®¸åå·®(social desirability bias)ã€‚ç ”ç©¶è€…ä½¿ç”¨GPT-o3å¯¹å›½é™…äººæ ¼é¡¹ç›®æ± äº”å¤§æ€§æ ¼é‡è¡¨(IPIP-BFM-50)è¿›è¡Œæ”¹å†™ï¼Œå¹¶ç»„ç»‡203åå‚ä¸è€…åˆ†åˆ«å®ŒæˆåŸå§‹ç‰ˆæˆ–ä¸­æ€§åŒ–ç‰ˆæœ¬çš„æµ‹è¯„ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œä¸­æ€§åŒ–é‡è¡¨ä¿ç•™äº†ä¿¡åº¦ä¸äº”å› ç´ ç»“æ„ï¼Œä½†åœ¨å°½è´£æ€§(Conscientiousness)ç»´åº¦å¾—åˆ†æœ‰æ‰€å¢åŠ ï¼Œè€Œåœ¨å®œäººæ€§(Agreeableness)å’Œå¼€æ”¾æ€§(Openness)ç»´åº¦æœ‰æ‰€ä¸‹é™ã€‚å°½ç®¡éƒ¨åˆ†é¡¹ç›®ä¸ç¤¾ä¼šèµè®¸æ€§çš„ç›¸å…³æ€§æœ‰æ‰€é™ä½ï¼Œä½†å…¶è¡¨ç°å¹¶ä¸ä¸€è‡´ã€‚åœ¨ä¸å˜æ€§æ£€éªŒä¸­ï¼Œå½¢æ€ä¸å˜æ€§(configural invariance)å¾—åˆ°äº†ä¿æŒï¼Œä½†åº¦é‡ä¸å˜æ€§(metric invariance)å’Œæ ‡é‡ä¸å˜æ€§(scalar invariance)æœªèƒ½é€šè¿‡ã€‚æ€»ä½“è€Œè¨€ï¼Œè¯¥ç ”ç©¶è¯æ˜äº†AIä¸­æ€§åŒ–æ˜¯å‡å°‘éè®¤çŸ¥é‡è¡¨åå·®çš„ä¸€ç§æ½œåœ¨ä½†å°šä¸å®Œå–„çš„æ–¹æ³•ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted for publication in NCME-AIME 2025",
      "pdf_url": "https://arxiv.org/pdf/2509.19314v1",
      "published_date": "2025-09-09 16:44:28 UTC",
      "updated_date": "2025-09-09 16:44:28 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:27:12.942127+00:00"
    },
    {
      "arxiv_id": "2509.07894v4",
      "title": "HiPhO: How Far Are (M)LLMs from Humans in the Latest High School Physics Olympiad Benchmark?",
      "title_zh": "HiPhOï¼šåœ¨æœ€æ–°çš„é«˜ä¸­ç‰©ç†å¥¥æ—åŒ¹å…‹åŸºå‡†æµ‹è¯•ä¸­ï¼Œ(M)LLMs è·ç¦»äººç±»æ°´å¹³è¿˜æœ‰å¤šè¿œï¼Ÿ",
      "authors": [
        "Fangchen Yu",
        "Haiyuan Wan",
        "Qianjia Cheng",
        "Yuchen Zhang",
        "Jiacheng Chen",
        "Fujun Han",
        "Yulun Wu",
        "Junchi Yao",
        "Ruilizhen Hu",
        "Ning Ding",
        "Yu Cheng",
        "Tao Chen",
        "Lei Bai",
        "Dongzhan Zhou",
        "Yun Luo",
        "Ganqu Cui",
        "Peng Ye"
      ],
      "abstract": "Recently, the physical capabilities of (M)LLMs have garnered increasing attention. However, existing benchmarks for physics suffer from two major gaps: they neither provide systematic and up-to-date coverage of real-world physics competitions such as physics Olympiads, nor enable direct performance comparison with humans. To bridge these gaps, we present HiPhO, the first benchmark dedicated to high school physics Olympiads with human-aligned evaluation. Specifically, HiPhO highlights three key innovations. (1) Comprehensive Data: It compiles 13 latest Olympiad exams from 2024-2025, spanning both international and regional competitions, and covering mixed modalities that encompass problems spanning text-only to diagram-based. (2) Professional Evaluation: We adopt official marking schemes to perform fine-grained grading at both the answer and step level, fully aligned with human examiners to ensure high-quality and domain-specific evaluation. (3) Comparison with Human Contestants: We assign gold, silver, and bronze medals to models based on official medal thresholds, thereby enabling direct comparison between (M)LLMs and human contestants. Our large-scale evaluation of 30 state-of-the-art (M)LLMs shows that: across 13 exams, open-source MLLMs mostly remain at or below the bronze level; open-source LLMs show promising progress with multiple golds; closed-source reasoning MLLMs can achieve 6 to 12 gold medals; and most models still have a significant gap from full marks. These results highlight the performance gap between open-source models and top students, the strong reasoning abilities of closed-source models, and the remaining room for improvement. HiPhO, a human-aligned Olympiad benchmark for multimodal physical reasoning, is open-source at https://github.com/SciYu/HiPhO with a public leaderboard at https://phyarena.github.io/.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†é¦–ä¸ªä¸“é—¨é’ˆå¯¹é«˜ä¸­ç‰©ç†å¥¥æ—åŒ¹å…‹ç«èµ›çš„äººç±»å¯¹é½è¯„æµ‹åŸºå‡† HiPhOï¼Œæ—¨åœ¨å¼¥è¡¥ç°æœ‰ç‰©ç†è¯„æµ‹åœ¨ç³»ç»Ÿæ€§ã€æ—¶æ•ˆæ€§ä»¥åŠä¸äººç±»è¡¨ç°å¯¹æ¯”æ–¹é¢çš„ç¼ºå£ã€‚HiPhO æ±‡é›†äº† 2024-2025 å¹´ 13 åœºæœ€æ–°çš„å›½é™…ä¸åŒºåŸŸç«èµ›é¢˜ç›®ï¼Œæ¶µç›–äº†ä»çº¯æ–‡æœ¬åˆ°å«å›¾è¡¨çš„æ··åˆæ¨¡æ€ï¼ˆMixed Modalitiesï¼‰é—®é¢˜ã€‚ç ”ç©¶é‡‡ç”¨å®˜æ–¹è¯„åˆ†æ ‡å‡†åœ¨ç­”æ¡ˆå’Œæ­¥éª¤ç»´åº¦è¿›è¡Œç»†ç²’åº¦è¯„ä¼°ï¼Œå¹¶ä¾æ®å¥–ç‰Œé˜ˆå€¼å®ç°äº† (M)LLMs ä¸äººç±»é€‰æ‰‹çš„ç›´æ¥é‡åŒ–å¯¹æ¯”ã€‚å®éªŒå‘ç°å¼€æº MLLMs å¤§å¤šå¤„äºé“œç‰ŒåŠä»¥ä¸‹æ°´å¹³ï¼Œè€Œé—­æºæ¨ç† MLLMs è™½ç„¶èƒ½è·å¾—å¤šæšé‡‘ç‰Œï¼Œä½†ä¸æ»¡åˆ†å’Œé¡¶å°–å­¦ç”Ÿç›¸æ¯”ä»æœ‰æ˜¾è‘—å·®è·ã€‚è¯¥åŸºå‡†æ­ç¤ºäº†å½“å‰æ¨¡å‹åœ¨å¤šæ¨¡æ€ç‰©ç†æ¨ç†ï¼ˆMultimodal Physical Reasoningï¼‰èƒ½åŠ›çš„ç°çŠ¶ï¼Œå¹¶ä¸ºåç»­æå‡æ¨¡å‹æ¨ç†æ€§èƒ½æä¾›äº†é‡è¦å‚è€ƒã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.07894v4",
      "published_date": "2025-09-09 16:24:51 UTC",
      "updated_date": "2025-09-19 16:18:35 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:27:18.420503+00:00"
    },
    {
      "arxiv_id": "2509.07879v1",
      "title": "Active Membership Inference Test (aMINT): Enhancing Model Auditability with Multi-Task Learning",
      "title_zh": "ä¸»åŠ¨æˆå‘˜æ¨ç†æµ‹è¯• (aMINT)ï¼šåˆ©ç”¨å¤šä»»åŠ¡å­¦ä¹ å¢å¼ºæ¨¡å‹å¯å®¡è®¡æ€§",
      "authors": [
        "Daniel DeAlcala",
        "Aythami Morales",
        "Julian Fierrez",
        "Gonzalo Mancera",
        "Ruben Tolosana",
        "Javier Ortega-Garcia"
      ],
      "abstract": "Active Membership Inference Test (aMINT) is a method designed to detect whether given data were used during the training of machine learning models. In Active MINT, we propose a novel multitask learning process that involves training simultaneously two models: the original or Audited Model, and a secondary model, referred to as the MINT Model, responsible for identifying the data used for training the Audited Model. This novel multi-task learning approach has been designed to incorporate the auditability of the model as an optimization objective during the training process of neural networks. The proposed approach incorporates intermediate activation maps as inputs to the MINT layers, which are trained to enhance the detection of training data. We present results using a wide range of neural networks, from lighter architectures such as MobileNet to more complex ones such as Vision Transformers, evaluated in 5 public benchmarks. Our proposed Active MINT achieves over 80% accuracy in detecting if given data was used for training, significantly outperforming previous approaches in the literature. Our aMINT and related methodological developments contribute to increasing transparency in AI models, facilitating stronger safeguards in AI deployments to achieve proper security, privacy, and copyright protection.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†Active Membership Inference Test (aMINT)ï¼Œè¿™æ˜¯ä¸€ç§æ—¨åœ¨æ£€æµ‹ç‰¹å®šæ•°æ®æ˜¯å¦è¢«ç”¨äºæœºå™¨å­¦ä¹ æ¨¡å‹è®­ç»ƒçš„æ–¹æ³•ã€‚aMINTé€šè¿‡æ–°é¢–çš„å¤šä»»åŠ¡å­¦ä¹ (Multi-task Learning)è¿‡ç¨‹ï¼ŒåŒæ­¥è®­ç»ƒè¢«å®¡è®¡æ¨¡å‹(Audited Model)ä¸ä¸“é—¨è´Ÿè´£è¯†åˆ«è®­ç»ƒæ•°æ®çš„MINTæ¨¡å‹ã€‚è¯¥æ–¹æ³•é¦–æ¬¡å°†æ¨¡å‹çš„å¯å®¡è®¡æ€§(Auditability)ä½œä¸ºç¥ç»ç½‘ç»œè®­ç»ƒè¿‡ç¨‹ä¸­çš„ä¼˜åŒ–ç›®æ ‡ï¼Œå¹¶åˆ©ç”¨ä¸­é—´æ¿€æ´»å›¾(Intermediate Activation Maps)ä½œä¸ºè¾“å…¥ä»¥å¢å¼ºæ£€æµ‹æ•ˆèƒ½ã€‚åœ¨MobileNetå’ŒVision Transformersç­‰å¤šç§æ¨¡å‹æ¶æ„åŠ5ä¸ªå…¬å…±åŸºå‡†ä¸Šçš„è¯„ä¼°ç»“æœæ˜¾ç¤ºï¼ŒaMINTåœ¨è¯†åˆ«è®­ç»ƒæ•°æ®æ–¹é¢çš„å‡†ç¡®ç‡è¶…è¿‡80%ï¼Œæ˜¾è‘—ä¼˜äºç°æœ‰æŠ€æœ¯ã€‚è¿™ä¸€æˆæœæœ‰æ•ˆæå‡äº†AIæ¨¡å‹çš„é€æ˜åº¦ï¼Œä¸ºå®ç°AIéƒ¨ç½²ä¸­çš„å®‰å…¨ã€éšç§å’Œç‰ˆæƒä¿æŠ¤æä¾›äº†åšå®çš„æŠ€æœ¯ä¿éšœã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "In Proc. IEEE/CVF Intenational Conference on Computer Vision, ICCV, 2025",
      "pdf_url": "https://arxiv.org/pdf/2509.07879v1",
      "published_date": "2025-09-09 16:00:03 UTC",
      "updated_date": "2025-09-09 16:00:03 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:27:17.737497+00:00"
    },
    {
      "arxiv_id": "2509.07867v1",
      "title": "CP-Model-Zoo: A Natural Language Query System for Constraint Programming Models",
      "title_zh": "CP-Model-Zooï¼šé¢å‘çº¦æŸè§„åˆ’æ¨¡å‹çš„è‡ªç„¶è¯­è¨€æŸ¥è¯¢ç³»ç»Ÿ",
      "authors": [
        "Augustin Crespin",
        "Ioannis Kostis",
        "HÃ©lÃ¨ne Verhaeghe",
        "Pierre Schaus"
      ],
      "abstract": "Constraint Programming and its high-level modeling languages have long been recognized for their potential to achieve the holy grail of problem-solving. However, the complexity of modeling languages, the large number of global constraints, and the art of creating good models have often hindered non-experts from choosing CP to solve their combinatorial problems. While generating an expert-level model from a natural-language description of a problem would be the dream, we are not yet there. We propose a tutoring system called CP-Model-Zoo, exploiting expert-written models accumulated through the years. CP-Model-Zoo retrieves the closest source code model from a database based on a user's natural language description of a combinatorial problem. It ensures that expert-validated models are presented to the user while eliminating the need for human data labeling. Our experiments show excellent accuracy in retrieving the correct model based on a user-input description of a problem simulated with different levels of expertise.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹çº¦æŸè§„åˆ’(Constraint Programming, CP)å»ºæ¨¡è¯­è¨€å¤æ‚åŠ global constraints æ•°é‡åºå¤§å¯¼è‡´éä¸“å®¶éš¾ä»¥ä½¿ç”¨çš„é—®é¢˜ï¼Œæå‡ºäº† CP-Model-Zoo è¾…å¯¼ç³»ç»Ÿã€‚è¯¥ç³»ç»Ÿåˆ©ç”¨å¤šå¹´ç§¯ç´¯çš„ä¸“å®¶æ¨¡å‹æ•°æ®åº“ï¼Œèƒ½å¤Ÿæ ¹æ®ç”¨æˆ·æä¾›çš„è‡ªç„¶è¯­è¨€æè¿°æ£€ç´¢å‡ºæœ€æ¥è¿‘çš„æºä»£ç æ¨¡å‹ã€‚CP-Model-Zoo ç¡®ä¿å‘ç”¨æˆ·å±•ç¤ºç»è¿‡ä¸“å®¶éªŒè¯çš„æ¨¡å‹ï¼ŒåŒæ—¶æ¶ˆé™¤äº†å¯¹ human data labeling çš„éœ€æ±‚ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œåœ¨æ¨¡æ‹Ÿä¸åŒä¸“ä¸šæ°´å¹³çš„ç”¨æˆ·è¾“å…¥æè¿°æ—¶ï¼Œè¯¥ç³»ç»Ÿåœ¨æ£€ç´¢æ­£ç¡®æ¨¡å‹æ–¹é¢è¡¨ç°å‡ºäº†æé«˜çš„å‡†ç¡®ç‡ã€‚è¯¥ç ”ç©¶ä¸ºéä¸“å®¶ç”¨æˆ·åˆ©ç”¨ CP æŠ€æœ¯è§£å†³ç»„åˆä¼˜åŒ–é—®é¢˜æä¾›äº†ä¸€ç§é«˜æ•ˆçš„è¾…åŠ©é€”å¾„ï¼Œæ˜¯è¿ˆå‘è‡ªç„¶è¯­è¨€é©±åŠ¨é—®é¢˜è§£å†³çš„é‡è¦ä¸€æ­¥ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "presented at\"LLMs meet Constraint Solving\" Workshop at CP2025 in Glasgow",
      "pdf_url": "https://arxiv.org/pdf/2509.07867v1",
      "published_date": "2025-09-09 15:55:15 UTC",
      "updated_date": "2025-09-09 15:55:15 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:27:21.359890+00:00"
    },
    {
      "arxiv_id": "2509.07858v1",
      "title": "SCoder: Iterative Self-Distillation for Bootstrapping Small-Scale Data Synthesizers to Empower Code LLMs",
      "title_zh": "SCoderï¼šé€šè¿‡è¿­ä»£è‡ªè’¸é¦å¼•å¯¼å°è§„æ¨¡æ•°æ®åˆæˆå™¨ä»¥èµ‹èƒ½ä»£ç å¤§è¯­è¨€æ¨¡å‹",
      "authors": [
        "Xinyu Zhang",
        "Changzhi Zhou",
        "Linmei Hu",
        "Luhao Zhang",
        "Xiancai Chen",
        "Haomin Fu",
        "Yang Yang",
        "Mengdi Zhang"
      ],
      "abstract": "Existing code large language models (LLMs) often rely on large-scale instruction data distilled from proprietary LLMs for fine-tuning, which typically incurs high costs. In this paper, we explore the potential of small-scale open-source LLMs (e.g., 7B) as synthesizers for high-quality code instruction data construction. We first observe that the data synthesis capability of small-scale LLMs can be enhanced by training on a few superior data synthesis samples from proprietary LLMs. Building on this, we propose a novel iterative self-distillation approach to bootstrap small-scale LLMs, transforming them into powerful synthesizers that reduce reliance on proprietary LLMs and minimize costs. Concretely, in each iteration, to obtain diverse and high-quality self-distilled data, we design multi-checkpoint sampling and multi-aspect scoring strategies for initial data selection. Furthermore, to identify the most influential samples, we introduce a gradient-based influence estimation method for final data filtering. Based on the code instruction datasets from the small-scale synthesizers, we develop SCoder, a family of code generation models fine-tuned from DeepSeek-Coder. SCoder models achieve state-of-the-art code generation capabilities, demonstrating the effectiveness of our method.",
      "tldr_zh": "æœ¬ç ”ç©¶æå‡ºäº†SCoderï¼Œæ—¨åœ¨åˆ©ç”¨å°è§„æ¨¡å¼€æºå¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ä½œä¸ºåˆæˆå™¨æ„å»ºé«˜è´¨é‡ä»£ç æŒ‡ä»¤æ•°æ®ï¼Œä»¥è§£å†³å¾®è°ƒè¿‡ç¨‹ä¸­è¿‡åº¦ä¾èµ–æ˜‚è´µå°é—­æºä»£ç æ¨¡å‹ï¼ˆProprietary LLMsï¼‰çš„é—®é¢˜ã€‚ç ”ç©¶å‘ç°é€šè¿‡å°‘é‡ä¼˜è´¨æ ·æœ¬è®­ç»ƒå¯å¢å¼ºå°è§„æ¨¡æ¨¡å‹çš„æ•°æ®åˆæˆèƒ½åŠ›ï¼Œå¹¶æ®æ­¤æå‡ºäº†ä¸€ç§è¿­ä»£è‡ªè’¸é¦ï¼ˆIterative Self-Distillationï¼‰æ–¹æ³•ï¼Œé€šè¿‡è‡ªä¸¾ï¼ˆBootstrappingï¼‰è¿‡ç¨‹å°†æ¨¡å‹è½¬åŒ–ä¸ºå¼ºå¤§çš„åˆæˆå™¨ã€‚åœ¨è¿­ä»£è¿‡ç¨‹ä¸­ï¼Œè¯¥æ–¹æ³•ç»“åˆäº†å¤šæ£€æŸ¥ç‚¹é‡‡æ ·ï¼ˆMulti-checkpoint Samplingï¼‰å’Œå¤šç»´åº¦è¯„åˆ†ï¼ˆMulti-aspect Scoringï¼‰ç­–ç•¥è¿›è¡Œåˆå§‹æ•°æ®é€‰æ‹©ï¼Œå¹¶å¼•å…¥åŸºäºæ¢¯åº¦çš„å½±å“è¯„ä¼°ï¼ˆGradient-based Influence Estimationï¼‰å®ç°æœ€ç»ˆçš„æ•°æ®è¿‡æ»¤ã€‚åŸºäºè¯¥æ–¹æ³•å¼€å‘çš„SCoderç³»åˆ—æ¨¡å‹åœ¨DeepSeek-CoderåŸºç¡€ä¸Šè¿›è¡Œå¾®è°ƒï¼Œæœ€ç»ˆåœ¨ä»£ç ç”Ÿæˆä»»åŠ¡ä¸­è¾¾åˆ°äº†SOTAæ€§èƒ½ï¼ŒéªŒè¯äº†è¯¥åˆæˆè·¯å¾„åœ¨é™ä½æˆæœ¬çš„åŒæ—¶æå‡æ¨¡å‹èƒ½åŠ›çš„æœ‰æ•ˆæ€§ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.07858v1",
      "published_date": "2025-09-09 15:38:44 UTC",
      "updated_date": "2025-09-09 15:38:44 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:27:30.136201+00:00"
    },
    {
      "arxiv_id": "2509.08031v2",
      "title": "AU-Harness: An Open-Source Toolkit for Holistic Evaluation of Audio LLMs",
      "title_zh": "AU-Harnessï¼šé¢å‘éŸ³é¢‘å¤§è¯­è¨€æ¨¡å‹å…¨é¢è¯„ä¼°çš„å¼€æºå·¥å…·åŒ…",
      "authors": [
        "Sidharth Surapaneni",
        "Hoang Nguyen",
        "Jash Mehta",
        "Aman Tiwari",
        "Oluwanifemi Bamgbose",
        "Akshay Kalkunte",
        "Sai Rajeswar",
        "Sathwik Tejaswi Madhusudhan"
      ],
      "abstract": "Large Audio Language Models (LALMs) are rapidly advancing, but evaluating them remains challenging due to inefficient toolkits that limit fair comparison and systematic assessment. Current frameworks suffer from three critical issues: slow processing that bottlenecks large-scale studies, inconsistent prompting that hurts reproducibility, and narrow task coverage that misses important audio reasoning capabilities. We introduce AU-Harness, an efficient and comprehensive evaluation framework for LALMs. Our system achieves a speedup of up to 127% over existing toolkits through optimized batch processing and parallel execution, enabling large-scale evaluations previously impractical. We provide standardized prompting protocols and flexible configurations for fair model comparison across diverse scenarios. Additionally, we introduce two new evaluation categories: LLM-Adaptive Diarization for temporal audio understanding and Spoken Language Reasoning for complex audio-based cognitive tasks. Through evaluation across 380+ tasks, we reveal significant gaps in current LALMs, particularly in temporal understanding and complex spoken language reasoning tasks. Our findings also highlight a lack of standardization in instruction modality existent across audio benchmarks, which can lead up performance differences up to 9.5 absolute points on the challenging complex instruction following downstream tasks. AU-Harness provides both practical evaluation tools and insights into model limitations, advancing systematic LALM development.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¨å‡ºäº† AU-Harnessï¼Œè¿™æ˜¯ä¸€ä¸ªé’ˆå¯¹å¤§è¯­è¨€éŸ³é¢‘æ¨¡å‹ï¼ˆLarge Audio Language Models, LALMsï¼‰çš„é«˜æ•ˆä¸”å…¨é¢çš„å¼€æºè¯„ä¼°æ¡†æ¶ã€‚é’ˆå¯¹ç°æœ‰è¯„ä¼°å·¥å…·å¤„ç†é€Ÿåº¦æ…¢ã€æç¤ºè¯ä¸ä¸€è‡´åŠä»»åŠ¡è¦†ç›–é¢çª„ç­‰æ ¸å¿ƒæŒ‘æˆ˜ï¼ŒAU-Harness é€šè¿‡ä¼˜åŒ–æ‰¹å¤„ç†å’Œå¹¶è¡Œæ‰§è¡Œï¼Œå®ç°äº†æ¯”ç°æœ‰å·¥å…·é«˜è¾¾ 127% çš„æé€Ÿã€‚è¯¥æ¡†æ¶ä¸ä»…æä¾›äº†æ ‡å‡†åŒ–çš„æç¤ºåè®®å’Œçµæ´»çš„é…ç½®ï¼Œè¿˜å¼•å…¥äº† LLM-Adaptive Diarization å’Œ Spoken Language Reasoning ä¸¤ä¸ªå…¨æ–°çš„è¯„ä¼°ç±»åˆ«ï¼Œç”¨äºè¯„ä¼°æ¨¡å‹åœ¨æ—¶é—´ç»´åº¦ç†è§£å’Œå¤æ‚è®¤çŸ¥ä»»åŠ¡æ–¹é¢çš„èƒ½åŠ›ã€‚é€šè¿‡å¯¹ 380 å¤šä¸ªä»»åŠ¡çš„å¹¿æ³›è¯„ä¼°ï¼Œè¯¥ç ”ç©¶æ­ç¤ºäº†å½“å‰ LALMs åœ¨æ—¶é—´ç†è§£å’Œå¤æ‚å£è¯­æ¨ç†æ–¹é¢çš„æ˜¾è‘—çŸ­æ¿ã€‚æ­¤å¤–ï¼Œç ”ç©¶è¿˜å‘ç°æŒ‡ä»¤æ¨¡æ€ç¼ºä¹æ ‡å‡†åŒ–ä¼šå¯¼è‡´ä¸‹æ¸¸ä»»åŠ¡ä¸­å‡ºç°é«˜è¾¾ 9.5 ä¸ªç™¾åˆ†ç‚¹çš„æ€§èƒ½å·®å¼‚ã€‚AU-Harness ä¸º LALMs çš„ç³»ç»ŸåŒ–å¼€å‘æä¾›äº†å®ç”¨çš„è¯„ä¼°å·¥å…·ï¼Œå¹¶ä¸ºç†è§£æ¨¡å‹å±€é™æ€§æä¾›äº†æ·±åˆ»è§è§£ã€‚",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.LG",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.08031v2",
      "published_date": "2025-09-09 15:30:40 UTC",
      "updated_date": "2025-09-11 16:27:59 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:27:33.935749+00:00"
    },
    {
      "arxiv_id": "2509.07852v1",
      "title": "Deep Learning-Based Burned Area Mapping Using Bi-Temporal Siamese Networks and AlphaEarth Foundation Datasets",
      "title_zh": "åŸºäºåŒæ—¶ç›¸å­ªç”Ÿç½‘ç»œä¸ AlphaEarth åŸºç¡€æ•°æ®é›†çš„æ·±åº¦å­¦ä¹ ç«çƒ§è¿¹åœ°åˆ¶å›¾",
      "authors": [
        "Seyd Teymoor Seydi"
      ],
      "abstract": "Accurate and timely mapping of burned areas is crucial for environmental monitoring, disaster management, and assessment of climate change. This study presents a novel approach to automated burned area mapping using the AlphaEArth dataset combined with the Siamese U-Net deep learning architecture. The AlphaEArth Dataset, comprising high-resolution optical and thermal infrared imagery with comprehensive ground-truth annotations, provides an unprecedented resource for training robust burned area detection models. We trained our model with the Monitoring Trends in Burn Severity (MTBS) dataset in the contiguous US and evaluated it with 17 regions cross in Europe. Our experimental results demonstrate that the proposed ensemble approach achieves superior performance with an overall accuracy of 95%, IoU of 0.6, and F1-score of 74% on the test dataset. The model successfully identifies burned areas across diverse ecosystems with complex background, showing particular strength in detecting partially burned vegetation and fire boundaries and its transferability and high generalization in burned area mapping. This research contributes to the advancement of automated fire damage assessment and provides a scalable solution for global burn area monitoring using the AlphaEarth dataset.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§åŸºäºåŒæ—¶åº(Bi-Temporal) Siamese U-Net æ·±åº¦å­¦ä¹ æ¶æ„çš„è‡ªåŠ¨åŒ–çƒ§æ¯åŒºåŸŸåˆ¶å›¾(Burned Area Mapping)æ–°æ–¹æ³•ã€‚è¯¥æ–¹æ³•ç»“åˆäº† AlphaEarth Foundation Datasetsï¼Œåˆ©ç”¨å…¶æä¾›çš„é«˜åˆ†è¾¨ç‡å…‰å­¦ä¸çƒ­çº¢å¤–å›¾åƒåŠå…¨é¢åœ°é¢çœŸå€¼æ ‡æ³¨æ¥è®­ç»ƒé²æ£’çš„æ£€æµ‹æ¨¡å‹ã€‚ç ”ç©¶äººå‘˜åˆ©ç”¨ç¾å›½æœ¬åœŸçš„ Monitoring Trends in Burn Severity (MTBS) æ•°æ®é›†è¿›è¡Œè®­ç»ƒï¼Œå¹¶åœ¨æ¬§æ´² 17 ä¸ªä¸åŒåŒºåŸŸè¿›è¡Œäº†è·¨åœ°åŸŸè¯„ä¼°ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥é›†æˆæ–¹æ³•åœ¨æµ‹è¯•é›†ä¸Šè¾¾åˆ°äº† 95% çš„å‡†ç¡®ç‡ï¼ŒIoU ä¸º 0.6ï¼ŒF1-score ä¸º 74%ï¼Œå±•ç°å‡ºä¼˜å¼‚çš„æ€§èƒ½ã€‚è¯¥æ¨¡å‹èƒ½å¤Ÿæœ‰æ•ˆè¯†åˆ«å¤æ‚èƒŒæ™¯ä¸‹å¤šç§ç”Ÿæ€ç³»ç»Ÿçš„çƒ§æ¯åŒºåŸŸï¼Œåœ¨æ¢æµ‹éƒ¨åˆ†çƒ§æ¯æ¤è¢«å’Œç«ç¾è¾¹ç•Œæ–¹é¢å…·æœ‰æ˜¾è‘—ä¼˜åŠ¿ï¼Œä¸”å…·å¤‡æé«˜çš„å¯è¿ç§»æ€§å’Œæ³›åŒ–èƒ½åŠ›ã€‚è¿™é¡¹ç ”ç©¶ä¸ºè‡ªåŠ¨åŒ–ç«ç¾æŸå®³è¯„ä¼°åšå‡ºäº†è´¡çŒ®ï¼Œå¹¶ä¸ºåˆ©ç”¨ AlphaEarth æ•°æ®é›†è¿›è¡Œå…¨çƒèŒƒå›´çš„çƒ§æ¯åŒºåŸŸç›‘æµ‹æä¾›äº†ä¸€ç§å¯æ‰©å±•çš„è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.07852v1",
      "published_date": "2025-09-09 15:29:18 UTC",
      "updated_date": "2025-09-09 15:29:18 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:27:32.733930+00:00"
    },
    {
      "arxiv_id": "2509.07846v1",
      "title": "Aligning LLMs for the Classroom with Knowledge-Based Retrieval -- A Comparative RAG Study",
      "title_zh": "é¢å‘è¯¾å ‚æ•™å­¦çš„çŸ¥è¯†æ£€ç´¢å¢å¼ºå¤§è¯­è¨€æ¨¡å‹å¯¹é½ï¼šä¸€é¡¹ RAG å¯¹æ¯”ç ”ç©¶",
      "authors": [
        "Amay Jain",
        "Liu Cui",
        "Si Chen"
      ],
      "abstract": "Large language models like ChatGPT are increasingly used in classrooms, but they often provide outdated or fabricated information that can mislead students. Retrieval Augmented Generation (RAG) improves reliability of LLMs by grounding responses in external resources. We investigate two accessible RAG paradigms, vector-based retrieval and graph-based retrieval to identify best practices for classroom question answering (QA). Existing comparative studies fail to account for pedagogical factors such as educational disciplines, question types, and practical deployment costs. Using a novel dataset, EduScopeQA, of 3,176 questions across academic subjects, we measure performance on various educational query types, from specific facts to broad thematic discussions. We also evaluate system alignment with a dataset of systematically altered textbooks that contradict the LLM's latent knowledge. We find that OpenAI Vector Search RAG (representing vector-based RAG) performs well as a low-cost generalist, especially for quick fact retrieval. On the other hand, GraphRAG Global excels at providing pedagogically rich answers to thematic queries, and GraphRAG Local achieves the highest accuracy with the dense, altered textbooks when corpus integrity is critical. Accounting for the 10-20x higher resource usage of GraphRAG (representing graph-based RAG), we show that a dynamic branching framework that routes queries to the optimal retrieval method boosts fidelity and efficiency. These insights provide actionable guidelines for educators and system designers to integrate RAG-augmented LLMs into learning environments effectively.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ Large Language Models (LLMs) åœ¨æ•™å®¤åœºæ™¯ä¸­å¯èƒ½äº§ç”Ÿè¿‡æ—¶æˆ–è™šå‡ä¿¡æ¯çš„é—®é¢˜ï¼Œæ·±å…¥æ¢è®¨äº†é€šè¿‡ Retrieval Augmented Generation (RAG) æŠ€æœ¯æå‡æ¨¡å‹å¯é æ€§çš„æ–¹æ³•ã€‚ç ”ç©¶é€šè¿‡å¯¹æ¯” vector-based retrieval å’Œ graph-based retrieval ä¸¤ç§èŒƒå¼ï¼Œæ—¨åœ¨ç¡®å®šæ•™å®¤é—®ç­” (QA) çš„æœ€ä½³å®è·µã€‚ç ”ç©¶è€…åˆ©ç”¨åŒ…å« 3,176 ä¸ªè·¨å­¦ç§‘é—®é¢˜çš„å…¨æ–°æ•°æ®é›† EduScopeQAï¼Œè¯„ä¼°äº†ä¸åŒ RAG ç³»ç»Ÿåœ¨å¤„ç†äº‹å®æ€§æŸ¥è¯¢å’Œä¸»é¢˜æ€§è®¨è®ºæ—¶çš„è¡¨ç°ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒOpenAI Vector Search RAG æ˜¯ä¸€ç§ä½æˆæœ¬çš„å…¨èƒ½å‹æ–¹æ¡ˆï¼Œå°¤å…¶æ“…é•¿å¿«é€Ÿäº‹å®æ£€ç´¢ï¼›è€Œ GraphRAG Global åœ¨å¤„ç†å…·æœ‰æ•™å­¦æ·±åº¦çš„æ ¸å¿ƒä¸»é¢˜æŸ¥è¯¢æ—¶è¡¨ç°æ›´ä¼˜ï¼ŒGraphRAG Local åˆ™åœ¨å¤„ç†é«˜å¯†åº¦ã€ä¿®æ”¹åçš„æ•™æå†…å®¹æ—¶å‡†ç¡®ç‡æœ€é«˜ã€‚è€ƒè™‘åˆ° GraphRAG çš„èµ„æºæ¶ˆè€—æ¯”å‘é‡æ£€ç´¢é«˜å‡º 10-20 å€ï¼Œç ”ç©¶æå‡ºäº†ä¸€ç§ dynamic branching æ¡†æ¶ï¼Œèƒ½å¤Ÿæ ¹æ®æŸ¥è¯¢éœ€æ±‚åŠ¨æ€è·¯ç”±è‡³æœ€ä¼˜æ£€ç´¢æ–¹æ³•ï¼Œä»è€Œåœ¨å¹³è¡¡ä¿çœŸåº¦çš„åŒæ—¶æå‡æ•ˆç‡ã€‚è¿™äº›å‘ç°ä¸ºæ•™è‚²å·¥ä½œè€…å’Œç³»ç»Ÿè®¾è®¡äººå‘˜åœ¨å­¦ä¹ ç¯å¢ƒä¸­æœ‰æ•ˆé›†æˆå¢å¼ºå‹ LLM æä¾›äº†å®è·µæŒ‡å—ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "This work has been submitted to the IEEE for possible publication",
      "pdf_url": "https://arxiv.org/pdf/2509.07846v1",
      "published_date": "2025-09-09 15:22:33 UTC",
      "updated_date": "2025-09-09 15:22:33 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:27:37.736578+00:00"
    },
    {
      "arxiv_id": "2509.07829v3",
      "title": "Building Large-Scale English-Romanian Literary Translation Resources with Open Models",
      "title_zh": "åŸºäºå¼€æºæ¨¡å‹æ„å»ºå¤§è§„æ¨¡è‹±è¯­-ç½—é©¬å°¼äºšè¯­æ–‡å­¦ç¿»è¯‘èµ„æº",
      "authors": [
        "Mihai Nadas",
        "Laura Diosan",
        "Andreea Tomescu",
        "Andrei Piscoran"
      ],
      "abstract": "Literary translation has recently gained attention as a distinct and complex task in machine translation research. However, the translation by small open models remains an open problem. We contribute to this ongoing research by introducing TINYFABULIST TRANSLATION FRAMEWORK (TF2), a unified framework for dataset creation, fine-tuning, and evaluation in English-Romanian literary translations, centred on the creation and open release of both a compact, fine-tuned language model (TF2-12B) and large-scale synthetic parallel datasets (DS-TF2-EN-RO-3M and DS-TF2-EN-RO-15K). Building on DS-TF1-EN-3M (TF1), the largest collection of synthetic English fables to date, we address the need for rich, high-quality literary datasets in low-resource languages such as Romanian. Our pipeline first generates 15k high-quality Romanian references from the TF1 pool using a high-performing LLM. We then apply a two-stage fine-tuning process to a 12B-parameter open-weight model: (i) instruction tuning to capture genre-specific narrative style, and (ii) adapter compression for efficient deployment. Evaluation combines corpus-level BLEU and a five-dimension LLM-based rubric (accuracy, fluency, coherence, style, cultural adaptation) to provide a nuanced assessment of translation quality. Results show that our fine-tuned model achieves strong fluency and adequacy, narrowing the gap to top-performing proprietary models under automated and human-anchored evaluation, while being open, accessible, and significantly more cost-effective. Alongside the finetuned model, and both datasets, we publicly release all scripts and evaluation prompts. TF2 thus provides an end-to-end, reproducible pipeline for research on cost-efficient translation, cross-lingual narrative generation, and the broad adoption of open models for culturally significant literary content in low-resource settings.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†TINYFABULIST TRANSLATION FRAMEWORK (TF2)ï¼Œä¸€ä¸ªé’ˆå¯¹è‹±è¯­-ç½—é©¬å°¼äºšè¯­æ–‡å­¦ç¿»è¯‘çš„é›†æˆåŒ–æ•°æ®é›†æ„å»ºã€å¾®è°ƒä¸è¯„ä¼°æ¡†æ¶ã€‚ç ”ç©¶å‘å¸ƒäº†ç´§å‡‘å‹å¾®è°ƒæ¨¡å‹TF2-12Bä»¥åŠå¤§è§„æ¨¡åˆæˆå¹³è¡Œæ•°æ®é›†DS-TF2-EN-RO-3Mä¸DS-TF2-EN-RO-15Kï¼Œæ—¨åœ¨è§£å†³ä½èµ„æºè¯­è¨€åœ¨æ–‡å­¦ç¿»è¯‘é¢†åŸŸç¼ºä¹é«˜è´¨é‡èµ„æºçš„é—®é¢˜ã€‚å…¶æµæ°´çº¿é€šè¿‡é«˜æ€§èƒ½LLMç”Ÿæˆå‚è€ƒè¯‘æ–‡ï¼Œå¹¶é‡‡ç”¨åŒ…å«ä½“è£é£æ ¼æ•è·çš„æŒ‡ä»¤å¾®è°ƒ(instruction tuning)åŠé€‚é…å™¨å‹ç¼©(adapter compression)ä¸¤é˜¶æ®µè¿‡ç¨‹è¿›è¡Œæ¨¡å‹ä¼˜åŒ–ã€‚å®éªŒè¯„ä¼°ç»“åˆäº†BLEUåˆ†å€¼ä¸åŒ…å«å‡†ç¡®æ€§ã€æµç•…åº¦ã€è¿è´¯æ€§ã€é£æ ¼åŠæ–‡åŒ–é€‚åº”æ€§äº”ä¸ªç»´åº¦çš„LLMè¯„å®¡å‡†åˆ™ã€‚ç»“æœè¡¨æ˜ï¼Œè¯¥å¾®è°ƒæ¨¡å‹å±•ç°å‡ºæå¼ºçš„æµåˆ©åº¦ä¸å……åˆ†æ€§ï¼Œåœ¨ä¿æŒå¼€æ”¾ä¸é«˜æˆæœ¬æ•ˆç›Šçš„åŒæ—¶ï¼Œæ˜¾è‘—ç¼©å°äº†ä¸é¡¶çº§ä¸“æœ‰æ¨¡å‹çš„æ€§èƒ½å·®è·ã€‚è¯¥å·¥ä½œä¸ºè·¨è¯­è¨€å™äº‹ç”Ÿæˆå’Œä½èµ„æºæ–‡åŒ–å†…å®¹çš„æœºå™¨ç¿»è¯‘æä¾›äº†å¯å¤ç°çš„ç«¯åˆ°ç«¯è·¯å¾„ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "25 pages, 8 figures, includes datasets and models released on Hugging Face",
      "pdf_url": "https://arxiv.org/pdf/2509.07829v3",
      "published_date": "2025-09-09 15:07:14 UTC",
      "updated_date": "2026-01-19 09:02:37 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:27:54.942884+00:00"
    },
    {
      "arxiv_id": "2509.07820v1",
      "title": "Certainty-Guided Reasoning in Large Language Models: A Dynamic Thinking Budget Approach",
      "title_zh": "å¤§è¯­è¨€æ¨¡å‹ä¸­çš„ç¡®å®šæ€§å¼•å¯¼æ¨ç†ï¼šä¸€ç§åŠ¨æ€æ€è€ƒé¢„ç®—æ–¹æ³•",
      "authors": [
        "JoÃ£o Paulo Nogueira",
        "Wentao Sun",
        "Alonso Silva",
        "Laith Zumot"
      ],
      "abstract": "The rise of large reasoning language models (LRLMs) has unlocked new potential for solving complex tasks. These models operate with a thinking budget, that is, a predefined number of reasoning tokens used to arrive at a solution. We propose a novel approach, inspired by the generator/discriminator framework in generative adversarial networks, in which a critic model periodically probes its own reasoning to assess whether it has reached a confident conclusion. If not, reasoning continues until a target certainty threshold is met. This mechanism adaptively balances efficiency and reliability by allowing early termination when confidence is high, while encouraging further reasoning when uncertainty persists. Through experiments on the AIME2024 and AIME2025 datasets, we show that Certainty-Guided Reasoning (CGR) improves baseline accuracy while reducing token usage. Importantly, extended multi-seed evaluations over 64 runs demonstrate that CGR is stable, reducing variance across seeds and improving exam-like performance under penalty-based grading. Additionally, our token savings analysis shows that CGR can eliminate millions of tokens in aggregate, with tunable trade-offs between certainty thresholds and efficiency. Together, these findings highlight certainty as a powerful signal for reasoning sufficiency. By integrating confidence into the reasoning process, CGR makes large reasoning language models more adaptive, trustworthy, and resource efficient, paving the way for practical deployment in domains where both accuracy and computational cost matter.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§åä¸ºCertainty-Guided Reasoning (CGR)çš„æ–°æ–¹æ³•ï¼Œé€šè¿‡åŠ¨æ€è°ƒæ•´å¤§å‹æ¨ç†è¯­è¨€æ¨¡å‹(LRLMs)çš„æ€ç»´é¢„ç®—(thinking budget)æ¥å¤„ç†å¤æ‚ä»»åŠ¡ã€‚è¯¥æ–¹æ³•å—ç”Ÿæˆå¯¹æŠ—ç½‘ç»œ(GANs)ä¸­ç”Ÿæˆå™¨/åˆ¤åˆ«å™¨(generator/discriminator)æ¶æ„çš„å¯å‘ï¼Œé€šè¿‡æ‰¹åˆ¤æ¨¡å‹å‘¨æœŸæ€§åœ°æ¢æµ‹è‡ªèº«æ¨ç†è¿‡ç¨‹ä»¥è¯„ä¼°ç»“è®ºçš„ç½®ä¿¡åº¦ã€‚CGRæœºåˆ¶èƒ½å¤Ÿåœ¨é«˜ç½®ä¿¡åº¦æ—¶å®ç°æ—©æœŸåœæ­¢ï¼Œåœ¨å­˜åœ¨ä¸ç¡®å®šæ€§æ—¶åˆ™é¼“åŠ±æŒç»­æ¨ç†ï¼Œä»è€Œå®ç°äº†æ•ˆç‡ä¸å¯é æ€§çš„è‡ªé€‚åº”å¹³è¡¡ã€‚åœ¨AIME2024å’ŒAIME2025æ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨æå‡åŸºçº¿å‡†ç¡®ç‡çš„åŒæ—¶æ˜¾è‘—å‡å°‘äº†Tokenä½¿ç”¨é‡ã€‚æ­¤å¤–ï¼Œé•¿æœŸçš„multi-seedè¯„ä¼°è¯æ˜äº†CGRå…·æœ‰æé«˜çš„ç¨³å®šæ€§ï¼Œä¸ä»…é™ä½äº†è·¨ç§å­çš„æ–¹å·®(variance)ï¼Œè¿˜åœ¨æƒ©ç½šæ€§è¯„åˆ†æ ‡å‡†ä¸‹è¡¨ç°å‡ºæ›´ä¼˜çš„è€ƒè¯•æ€§èƒ½ã€‚è¯¥ç ”ç©¶å¼ºè°ƒäº†ç¡®å®šæ€§(certainty)æ˜¯è¡¡é‡æ¨ç†å……åˆ†æ€§çš„å…³é”®ä¿¡å·ï¼Œä¸ºé«˜ç²¾åº¦ä¸”å¯¹æˆæœ¬æ•æ„Ÿçš„é¢†åŸŸéƒ¨ç½²å¤§å‹æ¨ç†æ¨¡å‹æä¾›äº†æ›´å…·é€‚åº”æ€§å’Œå¯ä¿¡åº¦çš„è·¯å¾„ã€‚",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.07820v1",
      "published_date": "2025-09-09 14:57:15 UTC",
      "updated_date": "2025-09-09 14:57:15 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:28:22.135107+00:00"
    },
    {
      "arxiv_id": "2509.07813v1",
      "title": "Forecasting Russian Equipment Losses Using Time Series and Deep Learning Models",
      "title_zh": "åŸºäºæ—¶é—´åºåˆ—ä¸æ·±åº¦å­¦ä¹ æ¨¡å‹çš„ä¿„ç½—æ–¯è£…å¤‡æŸå¤±é¢„æµ‹",
      "authors": [
        "Jonathan Teagan"
      ],
      "abstract": "This study applies a range of forecasting techniques,including ARIMA, Prophet, Long Short Term Memory networks (LSTM), Temporal Convolutional Networks (TCN), and XGBoost, to model and predict Russian equipment losses during the ongoing war in Ukraine. Drawing on daily and monthly open-source intelligence (OSINT) data from WarSpotting, we aim to assess trends in attrition, evaluate model performance, and estimate future loss patterns through the end of 2025. Our findings show that deep learning models, particularly TCN and LSTM, produce stable and consistent forecasts, especially under conditions of high temporal granularity. By comparing different model architectures and input structures, this study highlights the importance of ensemble forecasting in conflict modeling, and the value of publicly available OSINT data in quantifying material degradation over time.",
      "tldr_zh": "è¯¥ç ”ç©¶åˆ©ç”¨æ—¶é—´åºåˆ—(Time Series)å’Œæ·±åº¦å­¦ä¹ (Deep Learning)æ¨¡å‹ï¼Œå¯¹ä¿„ä¹Œå†²çªä¸­ä¿„ç½—æ–¯çš„è®¾å¤‡æŸå¤±è¿›è¡Œäº†å»ºæ¨¡ä¸é¢„æµ‹ã€‚ç ”ç©¶é€šè¿‡åˆ†æWarSpottingæä¾›çš„æ¯æ—¥åŠæ¯æœˆå¼€æºæƒ…æŠ¥(OSINT)æ•°æ®ï¼Œåº”ç”¨äº†åŒ…æ‹¬ARIMAã€Prophetã€é•¿çŸ­æœŸè®°å¿†ç½‘ç»œ(LSTM)ã€æ—¶é—´å·ç§¯ç½‘ç»œ(TCN)å’ŒXGBooståœ¨å†…çš„å¤šç§é¢„æµ‹æŠ€æœ¯ã€‚è®ºæ–‡çš„ä¸»è¦ç›®æ ‡æ˜¯è¯„ä¼°è®¾å¤‡æŸè€—è¶‹åŠ¿ï¼Œå¹¶é¢„æµ‹åˆ°2025å¹´åº•å‰çš„æœªæ¥æŸå¤±æ¨¡å¼ã€‚ç»“æœæ˜¾ç¤ºï¼Œæ·±åº¦å­¦ä¹ æ¨¡å‹ï¼ˆå°¤å…¶æ˜¯TCNå’ŒLSTMï¼‰åœ¨å¤„ç†é«˜æ—¶é—´ç²’åº¦æ•°æ®æ—¶ï¼Œèƒ½å¤Ÿæä¾›æ›´ä¸ºç¨³å®šå’Œä¸€è‡´çš„é¢„æµ‹ã€‚è¯¥ç ”ç©¶å¼ºè°ƒäº†é›†æˆé¢„æµ‹(Ensemble Forecasting)åœ¨å†²çªå»ºæ¨¡ä¸­çš„é‡è¦æ€§ï¼Œå¹¶å±•ç¤ºäº†å…¬å¼€OSINTæ•°æ®åœ¨é‡åŒ–é•¿æœŸæ­¦å™¨è£…å¤‡æŸè€—æ–¹é¢çš„å®é™…åº”ç”¨ä»·å€¼ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.07813v1",
      "published_date": "2025-09-09 14:52:31 UTC",
      "updated_date": "2025-09-09 14:52:31 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:27:57.531473+00:00"
    },
    {
      "arxiv_id": "2509.07795v1",
      "title": "Enhanced SegNet with Integrated Grad-CAM for Interpretable Retinal Layer Segmentation in OCT Images",
      "title_zh": "é›†æˆ Grad-CAM çš„å¢å¼ºå‹ SegNetï¼šç”¨äº OCT å›¾åƒçš„å¯è§£é‡Šè§†ç½‘è†œåˆ†å±‚åˆ†å‰²",
      "authors": [
        "S M Asiful Islam Saky",
        "Ugyen Tshering"
      ],
      "abstract": "Optical Coherence Tomography (OCT) is essential for diagnosing conditions such as glaucoma, diabetic retinopathy, and age-related macular degeneration. Accurate retinal layer segmentation enables quantitative biomarkers critical for clinical decision-making, but manual segmentation is time-consuming and variable, while conventional deep learning models often lack interpretability. This work proposes an improved SegNet-based deep learning framework for automated and interpretable retinal layer segmentation. Architectural innovations, including modified pooling strategies, enhance feature extraction from noisy OCT images, while a hybrid loss function combining categorical cross-entropy and Dice loss improves performance for thin and imbalanced retinal layers. Gradient-weighted Class Activation Mapping (Grad-CAM) is integrated to provide visual explanations, allowing clinical validation of model decisions. Trained and validated on the Duke OCT dataset, the framework achieved 95.77% validation accuracy, a Dice coefficient of 0.9446, and a Jaccard Index (IoU) of 0.8951. Class-wise results confirmed robust performance across most layers, with challenges remaining for thinner boundaries. Grad-CAM visualizations highlighted anatomically relevant regions, aligning segmentation with clinical biomarkers and improving transparency. By combining architectural improvements, a customized hybrid loss, and explainable AI, this study delivers a high-performing SegNet-based framework that bridges the gap between accuracy and interpretability. The approach offers strong potential for standardizing OCT analysis, enhancing diagnostic efficiency, and fostering clinical trust in AI-driven ophthalmic tools.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ Optical Coherence Tomography (OCT) å›¾åƒæ‰‹åŠ¨åˆ†å‰²è€—æ—¶ä¸”ä¼ ç»Ÿæ·±åº¦å­¦ä¹ æ¨¡å‹ç¼ºä¹å¯è§£é‡Šæ€§çš„æŒ‘æˆ˜ï¼Œæå‡ºäº†ä¸€ç§æ”¹è¿›çš„ SegNet æ·±åº¦å­¦ä¹ æ¡†æ¶ï¼Œæ—¨åœ¨å®ç°è‡ªåŠ¨åŒ–ä¸”å…·æœ‰è§£é‡Šæ€§çš„è§†ç½‘è†œåˆ†å±‚åˆ†å‰²ã€‚é€šè¿‡å¼•å…¥æ”¹è¿›çš„æ± åŒ–ç­–ç•¥ï¼Œè¯¥æ¡†æ¶å¢å¼ºäº†ä»å™ªå£°å›¾åƒä¸­æå–ç‰¹å¾çš„èƒ½åŠ›ï¼Œå¹¶ç»“åˆ Categorical Cross-Entropy ä¸ Dice loss çš„æ··åˆæŸå¤±å‡½æ•°ï¼Œæ˜¾è‘—æå‡äº†åœ¨è–„å±‚åŠæ ·æœ¬ä¸å¹³è¡¡æƒ…å†µä¸‹çš„è¡¨ç°ã€‚ç ”ç©¶è¿›ä¸€æ­¥é›†æˆäº† Gradient-weighted Class Activation Mapping (Grad-CAM) æŠ€æœ¯ï¼Œä¸ºæ¨¡å‹çš„åˆ†å‰²å†³ç­–æä¾›ç›´è§‚çš„è§†è§‰è§£é‡Šï¼Œä»è€Œæ”¯æŒä¸´åºŠéªŒè¯ã€‚åœ¨ Duke OCT æ•°æ®é›†ä¸Šçš„è¯„ä¼°è¡¨æ˜ï¼Œè¯¥æ–¹æ³•è¾¾åˆ°äº† 95.77% çš„å‡†ç¡®ç‡å’Œ 0.9446 çš„ Dice ç³»æ•°ï¼Œåœ¨å„åˆ†å±‚ä¸Šå‡è¡¨ç°å‡ºç¨³å¥çš„åˆ†å‰²æ€§èƒ½ã€‚Grad-CAM çš„å¯è§†åŒ–ç»“æœä¸è§£å‰–å­¦ä¸´åºŠç”Ÿç‰©æ ‡å¿—ç‰©é«˜åº¦ä¸€è‡´ï¼Œæ˜¾è‘—å¢å¼ºäº† AI è¾…åŠ©å†³ç­–çš„é€æ˜åº¦ã€‚è¿™é¡¹å·¥ä½œé€šè¿‡æ¶æ„åˆ›æ–°ä¸å¯è§£é‡Šæ€§æŠ€æœ¯çš„ç»“åˆï¼Œæœ‰æ•ˆå¼¥åˆäº†åˆ†å‰²ç²¾åº¦ä¸ä¸´åºŠå¯ä¿¡åº¦ä¹‹é—´çš„é¸¿æ²Ÿï¼Œä¸ºçœ¼ç§‘è¯Šæ–­æµç¨‹çš„æ ‡å‡†åŒ–ä¸æ•ˆç‡æå‡æä¾›äº†é‡è¦æŠ€æœ¯æ”¯æŒã€‚",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.07795v1",
      "published_date": "2025-09-09 14:31:51 UTC",
      "updated_date": "2025-09-09 14:31:51 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:28:01.750612+00:00"
    },
    {
      "arxiv_id": "2509.07793v3",
      "title": "Individual utilities of life satisfaction reveal inequality aversion unrelated to political alignment",
      "title_zh": "ç”Ÿæ´»æ»¡æ„åº¦çš„ä¸ªäººæ•ˆç”¨æ­ç¤ºäº†ä¸æ”¿æ²»ç«‹åœºæ— å…³çš„ä¸å¹³ç­‰åŒæ¶",
      "authors": [
        "Crispin Cooper",
        "Ana Fredrich",
        "Tommaso Reggiani",
        "Wouter Poortinga"
      ],
      "abstract": "How should well-being be prioritised in society, and what trade-offs are people willing to make between fairness and personal well-being? We investigate these questions using a stated preference experiment with a nationally representative UK sample (n = 300), in which participants evaluated life satisfaction outcomes for both themselves and others under conditions of uncertainty. Individual-level utility functions were estimated using an Expected Utility Maximisation (EUM) framework and tested for sensitivity to the overweighting of small probabilities, as characterised by Cumulative Prospect Theory (CPT). A majority of participants displayed concave (risk-averse) utility curves and showed stronger aversion to inequality in societal life satisfaction outcomes than to personal risk. These preferences were unrelated to political alignment, suggesting a shared normative stance on fairness in well-being that cuts across ideological boundaries. The results challenge use of average life satisfaction as a policy metric, and support the development of nonlinear utility-based alternatives that more accurately reflect collective human values. Implications for public policy, well-being measurement, and the design of value-aligned AI systems are discussed.",
      "tldr_zh": "è¯¥ç ”ç©¶é€šè¿‡ä¸€é¡¹é’ˆå¯¹è‹±å›½å…¨å›½ä»£è¡¨æ€§æ ·æœ¬(n=300)çš„é™ˆè¿°åå¥½å®éªŒ(stated preference experiment)ï¼Œæ¢è®¨äº†ç¤¾ä¼šåº”å¦‚ä½•ä¼˜å…ˆè€ƒè™‘å¹¸ç¦æ„Ÿä»¥åŠäººä»¬åœ¨å…¬å¹³ä¸ä¸ªäººç¦ç¥‰ä¹‹é—´çš„æƒè¡¡ã€‚ç ”ç©¶é‡‡ç”¨é¢„æœŸæ•ˆç”¨æœ€å¤§åŒ–(Expected Utility Maximisation, EUM)æ¡†æ¶ä¼°ç®—ä¸ªä½“æ•ˆç”¨å‡½æ•°ï¼Œå¹¶ç»“åˆç´¯ç§¯å‰æ™¯ç†è®º(Cumulative Prospect Theory, CPT)éªŒè¯äº†æ¦‚ç‡æƒè¡¡çš„æ•æ„Ÿæ€§ã€‚å®éªŒå‘ç°ï¼Œå¤§å¤šæ•°å‚ä¸è€…å±•ç°å‡ºå‡¹å½¢çš„é£é™©è§„é¿(risk-averse)æ•ˆç”¨æ›²çº¿ï¼Œä¸”å¯¹ç¤¾ä¼šç”Ÿæ´»æ»¡æ„åº¦ä¸å¹³ç­‰çš„åŒæ¶(inequality aversion)ç¨‹åº¦æ˜¾è‘—é«˜äºå¯¹ä¸ªäººé£é™©çš„åŒæ¶ã€‚è¿™äº›åå¥½ä¸ä¸ªä½“çš„æ”¿æ²»ç«‹åœº(political alignment)æ— å…³ï¼Œæ­ç¤ºäº†è·¨è¶Šæ„è¯†å½¢æ€è¾¹ç•Œçš„å…³äºå…¬å¹³çš„å…±åŒè§„èŒƒæ€§ç«‹åœºã€‚ç ”ç©¶ç»“æœæŒ‘æˆ˜äº†å°†å¹³å‡ç”Ÿæ´»æ»¡æ„åº¦ä½œä¸ºæ”¿ç­–æŒ‡æ ‡çš„æœ‰æ•ˆæ€§ï¼Œä¸»å¼ é‡‡ç”¨æ›´èƒ½åæ˜ é›†ä½“ä»·å€¼è§‚çš„éçº¿æ€§æ•ˆç”¨æ¨¡å‹ã€‚è¯¥å‘ç°ä¸ºå…¬å…±æ”¿ç­–åˆ¶å®šã€ç¦ç¥‰è¡¡é‡ä»¥åŠä»·å€¼å¯¹é½(value-aligned)çš„äººå·¥æ™ºèƒ½ç³»ç»Ÿè®¾è®¡æä¾›äº†é‡è¦å¯ç¤ºã€‚",
      "categories": [
        "econ.GN",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "econ.GN",
      "comment": "28 pages, 4 figures. Replacement corrects error in trascription of Equation 5",
      "pdf_url": "https://arxiv.org/pdf/2509.07793v3",
      "published_date": "2025-09-09 14:30:24 UTC",
      "updated_date": "2025-10-10 11:59:41 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:28:06.834352+00:00"
    },
    {
      "arxiv_id": "2509.09716v2",
      "title": "VStyle: A Benchmark for Voice Style Adaptation with Spoken Instructions",
      "title_zh": "VStyleï¼šåŸºäºå£è¯­æŒ‡ä»¤çš„è¯­éŸ³é£æ ¼è‡ªé€‚åº”è¯„æµ‹åŸºå‡†",
      "authors": [
        "Jun Zhan",
        "Mingyang Han",
        "Yuxuan Xie",
        "Chen Wang",
        "Dong Zhang",
        "Kexin Huang",
        "Haoxiang Shi",
        "DongXiao Wang",
        "Tengtao Song",
        "Qinyuan Cheng",
        "Shimin Li",
        "Jun Song",
        "Xipeng Qiu",
        "Bo Zheng"
      ],
      "abstract": "Spoken language models (SLMs) have emerged as a unified paradigm for speech understanding and generation, enabling natural human machine interaction. However, while most progress has focused on semantic accuracy and instruction following, the ability of SLMs to adapt their speaking style based on spoken instructions has received limited attention. We introduce Voice Style Adaptation (VSA), a new task that examines whether SLMs can modify their speaking style, such as timbre, prosody, or persona following natural language spoken commands. To study this task, we present VStyle, a bilingual (Chinese & English) benchmark covering four categories of speech generation: acoustic attributes, natural language instruction, role play, and implicit empathy. We also introduce the Large Audio Language Model as a Judge (LALM as a Judge) framework, which progressively evaluates outputs along textual faithfulness, style adherence, and naturalness, ensuring reproducible and objective assessment. Experiments on commercial systems and open source SLMs demonstrate that current models face clear limitations in controllable style adaptation, highlighting both the novelty and challenge of this task. By releasing VStyle and its evaluation toolkit, we aim to provide the community with a foundation for advancing human centered spoken interaction. The dataset and code are publicly available at \\href{https://junzhan2000.github.io/VStyle.github.io/}{project's homepage}.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹è¯­éŸ³è¯­è¨€æ¨¡å‹(SLMs)åœ¨æ ¹æ®å£è¯­æŒ‡ä»¤åŠ¨æ€è°ƒæ•´è¯­éŸ³é£æ ¼ï¼ˆå¦‚éŸ³è‰²ã€éŸµå¾‹æˆ–äººæ ¼ï¼‰èƒ½åŠ›çš„ç¼ºå¤±ï¼Œæå‡ºäº†è¯­éŸ³é£æ ¼è¿ç§»(Voice Style Adaptation, VSA)è¿™ä¸€æ–°ä»»åŠ¡ã€‚ä½œè€…æ¨å‡ºäº†VStyleåŸºå‡†æµ‹è¯•ï¼Œè¿™æ˜¯ä¸€ä¸ªæ¶µç›–å£°å­¦å±æ€§(acoustic attributes)ã€è‡ªç„¶è¯­è¨€æŒ‡ä»¤ã€è§’è‰²æ‰®æ¼”(role play)å’Œéšå¼æƒ…æ„Ÿ(implicit empathy)å››ä¸ªç»´åº¦çš„ä¸­è‹±åŒè¯­è¯„ä¼°åŸºå‡†ã€‚æ­¤å¤–ï¼Œç ”ç©¶å¼•å…¥äº†å¤§å‹éŸ³é¢‘è¯­è¨€æ¨¡å‹ä½œä¸ºè¯„æµ‹è€…(LALM as a Judge)çš„è¯„ä¼°æ¡†æ¶ï¼Œç¡®ä¿ä»æ–‡æœ¬å¿ å®åº¦(textual faithfulness)ã€é£æ ¼éµå¾ªåº¦(style adherence)å’Œè‡ªç„¶åº¦(naturalness)ä¸‰ä¸ªç»´åº¦è¿›è¡Œå®¢è§‚ä¸”å¯å¤ç°çš„è¡¡é‡ã€‚å¯¹å•†ä¸šåŠå¼€æºæ¨¡å‹çš„å®éªŒè¯„ä¼°æ˜¾ç¤ºï¼Œç°æœ‰æ¨¡å‹åœ¨å¯æ§é£æ ¼è¿ç§»æ–¹é¢ä»é¢ä¸´æ˜¾è‘—æŒ‘æˆ˜ã€‚VStyleåŠå…¶è¯„ä¼°å·¥å…·åŒ…çš„å¼€æºï¼Œä¸ºæ¨åŠ¨æ›´è‡ªç„¶ã€ä»¥äººä¸ºä¸­å¿ƒçš„è¯­éŸ³äº¤äº’æŠ€æœ¯æä¾›äº†é‡è¦çš„ç ”ç©¶åŸºç¡€ã€‚",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.CL",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.09716v2",
      "published_date": "2025-09-09 14:28:58 UTC",
      "updated_date": "2025-09-22 02:40:04 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:28:10.346938+00:00"
    },
    {
      "arxiv_id": "2509.07772v1",
      "title": "XSRD-Net: EXplainable Stroke Relapse Detection",
      "title_zh": "XSRD-Netï¼šå¯è§£é‡Šæ€§å’ä¸­å¤å‘æ£€æµ‹",
      "authors": [
        "Christian Gapp",
        "Elias Tappeiner",
        "Martin Welk",
        "Karl Fritscher",
        "Stephanie Mangesius",
        "Constantin Eisenschink",
        "Philipp Deisl",
        "Michael Knoflach",
        "Astrid E. Grams",
        "Elke R. Gizewski",
        "Rainer Schubert"
      ],
      "abstract": "Stroke is the second most frequent cause of death world wide with an annual mortality of around 5.5 million. Recurrence rates of stroke are between 5 and 25% in the first year. As mortality rates for relapses are extraordinarily high (40%) it is of utmost importance to reduce the recurrence rates. We address this issue by detecting patients at risk of stroke recurrence at an early stage in order to enable appropriate therapy planning. To this end we collected 3D intracranial CTA image data and recorded concomitant heart diseases, the age and the gender of stroke patients between 2010 and 2024. We trained single- and multimodal deep learning based neural networks for binary relapse detection (Task 1) and for relapse free survival (RFS) time prediction together with a subsequent classification (Task 2). The separation of relapse from non-relapse patients (Task 1) could be solved with tabular data (AUC on test dataset: 0.84). However, for the main task, the regression (Task 2), our multimodal XSRD-net processed the modalities vision:tabular with 0.68:0.32 according to modality contribution measures. The c-index with respect to relapses for the multimodal model reached 0.68, and the AUC is 0.71 for the test dataset. Final, deeper interpretability analysis results could highlight a link between both heart diseases (tabular) and carotid arteries (vision) for the detection of relapses and the prediction of the RFS time. This is a central outcome that we strive to strengthen with ongoing data collection and model retraining.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ä¸­é£(Stroke)æé«˜çš„å¤å‘ç‡å’Œæ­»äº¡ç‡ï¼Œæå‡ºäº†XSRD-Netæ¨¡å‹ï¼Œæ—¨åœ¨é€šè¿‡æ—©æœŸè¯†åˆ«é«˜é£é™©æ‚£è€…ä»¥ä¼˜åŒ–ä¸ªæ€§åŒ–æ²»ç–—è§„åˆ’ã€‚ç ”ç©¶å›¢é˜Ÿåˆ©ç”¨2010è‡³2024å¹´é—´çš„3Dé¢…å†…CTAå›¾åƒ(CTA image)ä»¥åŠåˆå¹¶å¿ƒè„ç—…ã€å¹´é¾„å’Œæ€§åˆ«ç­‰ä¸´åºŠæ•°æ®ï¼Œæ„å»ºäº†å•æ¨¡æ€ä¸å¤šæ¨¡æ€æ·±åº¦å­¦ä¹ ç½‘ç»œã€‚å®éªŒæ¶µç›–äº†ä¸­é£å¤å‘æ£€æµ‹(relapse detection)å’Œæ— å¤å‘ç”Ÿå­˜æ—¶é—´(RFS)é¢„æµ‹ä¸¤ä¸ªæ ¸å¿ƒä»»åŠ¡ï¼Œå…¶ä¸­è¡¨æ ¼æ•°æ®(tabular data)åœ¨å¤å‘åˆ†ç±»ä»»åŠ¡ä¸­è¾¾åˆ°äº†0.84çš„AUCã€‚å¯¹äºä¸»ä»»åŠ¡RFSæ—¶é—´é¢„æµ‹ï¼Œå¤šæ¨¡æ€XSRD-Netæœ‰æ•ˆèåˆäº†è§†è§‰ä¸è¡¨æ ¼ç‰¹å¾ï¼Œå–å¾—äº†0.68çš„ä¸€è‡´æ€§æŒ‡æ•°(c-index)å’Œ0.71çš„AUCã€‚æ·±å…¥çš„å¯è§£é‡Šæ€§åˆ†æ(interpretability analysis)è¿›ä¸€æ­¥æ­ç¤ºäº†å¿ƒè„ç–¾ç—…ä¸é¢ˆåŠ¨è„‰(carotid arteries)çŠ¶å†µåœ¨é¢„æµ‹ä¸­é£å¤å‘ä¸­çš„å…³é”®è”ç³»ã€‚è¯¥ç ”ç©¶é€šè¿‡ç»“åˆå¤šæ¨¡æ€æ•°æ®ä¸å¯è§£é‡Šæ€§æŠ€æœ¯ï¼Œä¸ºä¸­é£é¢„åç®¡ç†æä¾›äº†é‡è¦çš„å†³ç­–æ”¯æŒã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Contribution to MICAD 2025 conference, Nov. 19-21, 2025 | London, UK",
      "pdf_url": "https://arxiv.org/pdf/2509.07772v1",
      "published_date": "2025-09-09 14:06:01 UTC",
      "updated_date": "2025-09-09 14:06:01 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:28:12.727984+00:00"
    },
    {
      "arxiv_id": "2509.07768v1",
      "title": "Are LLMs Enough for Hyperpartisan, Fake, Polarized and Harmful Content Detection? Evaluating In-Context Learning vs. Fine-Tuning",
      "title_zh": "å¤§è¯­è¨€æ¨¡å‹è¶³ä»¥èƒœä»»é«˜åº¦å…šæ´¾åŒ–ã€è™šå‡ã€æåŒ–åŠæœ‰å®³å†…å®¹æ£€æµ‹å—ï¼Ÿä¸Šä¸‹æ–‡å­¦ä¹ ä¸å¾®è°ƒçš„å¯¹æ¯”è¯„ä¼°",
      "authors": [
        "Michele Joshua Maggini",
        "Dhia Merzougui",
        "Rabiraj Bandyopadhyay",
        "GaÃ«l Dias",
        "Fabrice Maurel",
        "Pablo Gamallo"
      ],
      "abstract": "The spread of fake news, polarizing, politically biased, and harmful content on online platforms has been a serious concern. With large language models becoming a promising approach, however, no study has properly benchmarked their performance across different models, usage methods, and languages. This study presents a comprehensive overview of different Large Language Models adaptation paradigms for the detection of hyperpartisan and fake news, harmful tweets, and political bias. Our experiments spanned 10 datasets and 5 different languages (English, Spanish, Portuguese, Arabic and Bulgarian), covering both binary and multiclass classification scenarios. We tested different strategies ranging from parameter efficient Fine-Tuning of language models to a variety of different In-Context Learning strategies and prompts. These included zero-shot prompts, codebooks, few-shot (with both randomly-selected and diversely-selected examples using Determinantal Point Processes), and Chain-of-Thought. We discovered that In-Context Learning often underperforms when compared to Fine-Tuning a model. This main finding highlights the importance of Fine-Tuning even smaller models on task-specific settings even when compared to the largest models evaluated in an In-Context Learning setup - in our case LlaMA3.1-8b-Instruct, Mistral-Nemo-Instruct-2407 and Qwen2.5-7B-Instruct.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§å‹è¯­è¨€æ¨¡å‹ (Large Language Models, LLMs) åœ¨æ£€æµ‹æç«¯åè§ã€è™šå‡æ–°é—»ã€æ”¿æ²»åè§åŠæœ‰å®³å†…å®¹æ–¹é¢çš„è¡¨ç°è¿›è¡Œäº†å…¨é¢çš„åŸºå‡†è¯„ä¼°ã€‚å®éªŒè·¨è¶Šäº†5ç§è¯­è¨€å’Œ10ä¸ªæ•°æ®é›†ï¼Œå¯¹æ¯”äº†å‚æ•°é«˜æ•ˆå¾®è°ƒ (Fine-Tuning) ä¸åŒ…æ‹¬é›¶æ ·æœ¬ (Zero-shot)ã€ä»£ç ç°¿ (Codebooks)ã€å°‘æ ·æœ¬ (Few-shot) ä»¥åŠé“¾å¼æ€ç»´ (Chain-of-Thought) åœ¨å†…çš„å¤šç§ä¸Šä¸‹æ–‡å­¦ä¹  (In-Context Learning) ç­–ç•¥ã€‚ç ”ç©¶å‘ç°ï¼Œä¸Šä¸‹æ–‡å­¦ä¹ åœ¨è¿™äº›å¤æ‚çš„åˆ†ç±»ä»»åŠ¡ä¸­è¡¨ç°é€šå¸¸é€Šäºå¾®è°ƒæ¨¡å‹ã€‚å®éªŒç»“æœè¯æ˜ï¼Œå³ä½¿æ˜¯è¾ƒå°è§„æ¨¡çš„æ¨¡å‹åœ¨ç»è¿‡ç‰¹å®šä»»åŠ¡çš„å¾®è°ƒåï¼Œå…¶è¡¨ç°ä¹Ÿä¼˜äºé‡‡ç”¨ ICL ç­–ç•¥çš„ LlaMA3.1-8b-Instructã€Mistral-Nemo-Instruct-2407 å’Œ Qwen2.5-7B-Instruct ç­‰å¤§å‹æ¨¡å‹ã€‚è¿™ä¸€å‘ç°å¼ºè°ƒäº†åœ¨ç‰¹å®šä»»åŠ¡è®¾ç½®ä¸‹è¿›è¡Œé’ˆå¯¹æ€§å¾®è°ƒ (Fine-Tuning) çš„é‡è¦æ€§ï¼Œä¸ºä¼˜åŒ–åœ¨çº¿å¹³å°æœ‰å®³å†…å®¹æ£€æµ‹ç³»ç»Ÿæä¾›äº†å®è¯æ”¯æŒã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.07768v1",
      "published_date": "2025-09-09 14:01:15 UTC",
      "updated_date": "2025-09-09 14:01:15 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:28:24.645392+00:00"
    },
    {
      "arxiv_id": "2509.07763v1",
      "title": "What Were You Thinking? An LLM-Driven Large-Scale Study of Refactoring Motivations in Open-Source Projects",
      "title_zh": "ä½ åœ¨æƒ³ä»€ä¹ˆï¼Ÿä¸€é¡¹å¤§è¯­è¨€æ¨¡å‹é©±åŠ¨çš„å¼€æºé¡¹ç›®é‡æ„åŠ¨æœºå¤§è§„æ¨¡ç ”ç©¶",
      "authors": [
        "Mikel Robredo",
        "Matteo Esposito",
        "Fabio Palomba",
        "Rafael PeÃ±aloza",
        "Valentina Lenarduzzi"
      ],
      "abstract": "Context. Code refactoring improves software quality without changing external behavior. Despite its advantages, its benefits are hindered by the considerable cost of time, resources, and continuous effort it demands. Aim. Understanding why developers refactor, and which metrics capture these motivations, may support wider and more effective use of refactoring in practice. Method. We performed a large-scale empirical study to analyze developers refactoring activity, leveraging Large Language Models (LLMs) to identify underlying motivations from version control data, comparing our findings with previous motivations reported in the literature. Results. LLMs matched human judgment in 80% of cases, but aligned with literature-based motivations in only 47%. They enriched 22% of motivations with more detailed rationale, often highlighting readability, clarity, and structural improvements. Most motivations were pragmatic, focused on simplification and maintainability. While metrics related to developer experience and code readability ranked highest, their correlation with motivation categories was weak. Conclusions. We conclude that LLMs effectively capture surface-level motivations but struggle with architectural reasoning. Their value lies in providing localized explanations, which, when combined with software metrics, can form hybrid approaches. Such integration offers a promising path toward prioritizing refactoring more systematically and balancing short-term improvements with long-term architectural goals.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¼€æºé¡¹ç›®ä¸­çš„ä»£ç é‡æ„ (Code refactoring) åŠ¨æœºè¿›è¡Œäº†ä¸€é¡¹å¤§è§„æ¨¡å®è¯ç ”ç©¶ï¼Œåˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹ (LLMs) ä»ç‰ˆæœ¬æ§åˆ¶æ•°æ®ä¸­è‡ªåŠ¨è¯†åˆ«å¼€å‘è€…çš„æ„å›¾ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒLLMs åœ¨ 80% çš„æ¡ˆä¾‹ä¸­ä¸äººç±»åˆ¤æ–­ä¸€è‡´ï¼Œå¹¶ä¸º 22% çš„é‡æ„è¡Œä¸ºæä¾›äº†åŒ…æ‹¬å¯è¯»æ€§ã€æ¸…æ™°åº¦å’Œç»“æ„æ”¹è¿›åœ¨å†…çš„æ›´è¯¦ç»†è§£é‡Šã€‚ç ”ç©¶å‘ç°ï¼Œå¤§å¤šæ•°é‡æ„åŠ¨æœºæ˜¯åŠ¡å®çš„ï¼Œä¸»è¦é›†ä¸­åœ¨ä»£ç ç®€åŒ–å’Œå¯ç»´æŠ¤æ€§ (Maintainability) ä¸Šï¼Œä½†ä¼ ç»Ÿçš„è½¯ä»¶åº¦é‡æŒ‡æ ‡ä¸åŠ¨æœºç±»åˆ«ä¹‹é—´çš„ç›¸å…³æ€§è¾ƒå¼±ã€‚ä½œè€…æŒ‡å‡ºï¼ŒLLMs è™½ç„¶æ“…é•¿æ•æ‰è¡¨é¢å±‚é¢çš„åŠ¨æœºå’Œå±€éƒ¨è§£é‡Šï¼Œä½†åœ¨ç†è§£å¤æ‚çš„æ¶æ„æ¨ç† (Architectural reasoning) æ–¹é¢ä»é¢ä¸´æŒ‘æˆ˜ã€‚è¯¥ç ”ç©¶å¼ºè°ƒï¼Œå°† LLMs ä¸è½¯ä»¶åº¦é‡æŒ‡æ ‡ç›¸ç»“åˆçš„æ··åˆæ–¹æ³•ï¼Œæ˜¯å®ç°ç³»ç»ŸåŒ–é‡æ„ä¼˜å…ˆçº§æ’åºå¹¶å¹³è¡¡çŸ­æœŸæ”¹è¿›ä¸é•¿æœŸæ¶æ„ç›®æ ‡çš„æœ‰æ•ˆè·¯å¾„ã€‚",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.PL"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.07763v1",
      "published_date": "2025-09-09 13:58:46 UTC",
      "updated_date": "2025-09-09 13:58:46 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:28:32.348842+00:00"
    },
    {
      "arxiv_id": "2509.07756v2",
      "title": "Spectral and Rhythm Feature Performance Evaluation for Category and Class Level Audio Classification with Deep Convolutional Neural Networks",
      "title_zh": "æ·±åº¦å·ç§¯ç¥ç»ç½‘ç»œåœ¨èŒƒç•´ä¸ç±»çº§åˆ«éŸ³é¢‘åˆ†ç±»ä¸­çš„é¢‘è°±ä¸èŠ‚å¥ç‰¹å¾æ€§èƒ½è¯„ä¼°",
      "authors": [
        "Friedrich Wolf-Monheim"
      ],
      "abstract": "Next to decision tree and k-nearest neighbours algorithms deep convolutional neural networks (CNNs) are widely used to classify audio data in many domains like music, speech or environmental sounds. To train a specific CNN various spectral and rhythm features like mel-scaled spectrograms, mel-frequency cepstral coefficients (MFCC), cyclic tempograms, short-time Fourier transform (STFT) chromagrams, constant-Q transform (CQT) chromagrams and chroma energy normalized statistics (CENS) chromagrams can be used as digital image input data for the neural network. The performance of these spectral and rhythm features for audio category level as well as audio class level classification is investigated in detail with a deep CNN and the ESC-50 dataset with 2,000 labeled environmental audio recordings using an end-to-end deep learning pipeline. The evaluated metrics accuracy, precision, recall and F1 score for multiclass classification clearly show that the mel-scaled spectrograms and the mel-frequency cepstral coefficients (MFCC) perform significantly better then the other spectral and rhythm features investigated in this research for audio classification tasks using deep CNNs.",
      "tldr_zh": "è¯¥ç ”ç©¶æ—¨åœ¨è¯„ä¼°ä¸åŒé¢‘è°±(spectral)ä¸èŠ‚å¥(rhythm)ç‰¹å¾åœ¨æ·±åº¦å·ç§¯ç¥ç»ç½‘ç»œ(Deep Convolutional Neural Networks, CNNs)ä¸­å¯¹éŸ³é¢‘ç±»åˆ«åŠç±»çº§åˆ«åˆ†ç±»çš„æ€§èƒ½è¡¨ç°ã€‚ç ”ç©¶äººå‘˜åˆ©ç”¨åŒ…å«2000æ¡ç¯å¢ƒéŸ³é¢‘è®°å½•çš„ESC-50æ•°æ®é›†ï¼Œè¯¦ç»†å¯¹æ¯”äº†mel-scaled spectrogramsã€mel-frequency cepstral coefficients (MFCC)ã€cyclic tempogramsã€short-time Fourier transform (STFT) chromagramsã€constant-Q transform (CQT) chromagramsä»¥åŠchroma energy normalized statistics (CENS) chromagramsä½œä¸ºç½‘ç»œè¾“å…¥ç‰¹å¾çš„æ•ˆæœã€‚åŸºäºå‡†ç¡®ç‡(accuracy)ã€ç²¾ç¡®ç‡(precision)ã€å¬å›ç‡(recall)å’ŒF1 scoreç­‰æŒ‡æ ‡çš„è¯„ä¼°ç»“æœè¡¨æ˜ï¼Œmel-scaled spectrogramså’ŒMFCCåœ¨å¤šåˆ†ç±»ä»»åŠ¡ä¸­çš„è¡¨ç°æ˜¾è‘—ä¼˜äºæœ¬ç ”ç©¶è€ƒå¯Ÿçš„å…¶ä»–é¢‘è°±å’ŒèŠ‚å¥ç‰¹å¾ã€‚è¯¥ç ”ç©¶ä¸ºåœ¨éŸ³ä¹ã€è¯­éŸ³åŠç¯å¢ƒéŸ³ç­‰å¤šé¢†åŸŸæ„å»ºé«˜æ•ˆçš„éŸ³é¢‘åˆ†ç±»æµæ°´çº¿æä¾›äº†å…³é”®çš„ç‰¹å¾é€‰æ‹©ä¾æ®ã€‚",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.CV",
        "cs.LG",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.07756v2",
      "published_date": "2025-09-09 13:54:41 UTC",
      "updated_date": "2025-09-12 18:16:11 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:28:33.835912+00:00"
    },
    {
      "arxiv_id": "2509.07742v1",
      "title": "Enhancing Online Learning by Integrating Biosensors and Multimodal Learning Analytics for Detecting and Predicting Student Behavior: A Review",
      "title_zh": "èåˆç”Ÿç‰©ä¼ æ„Ÿå™¨ä¸å¤šæ¨¡æ€å­¦ä¹ åˆ†æä»¥æå‡åœ¨çº¿å­¦ä¹ ä¸­çš„å­¦ç”Ÿè¡Œä¸ºæ£€æµ‹ä¸é¢„æµ‹ï¼šç»¼è¿°",
      "authors": [
        "Alvaro Becerra",
        "Ruth Cobos",
        "Charles Lang"
      ],
      "abstract": "In modern online learning, understanding and predicting student behavior is crucial for enhancing engagement and optimizing educational outcomes. This systematic review explores the integration of biosensors and Multimodal Learning Analytics (MmLA) to analyze and predict student behavior during computer-based learning sessions. We examine key challenges, including emotion and attention detection, behavioral analysis, experimental design, and demographic considerations in data collection. Our study highlights the growing role of physiological signals, such as heart rate, brain activity, and eye-tracking, combined with traditional interaction data and self-reports to gain deeper insights into cognitive states and engagement levels. We synthesize findings from 54 key studies, analyzing commonly used methodologies such as advanced machine learning algorithms and multimodal data pre-processing techniques. The review identifies current research trends, limitations, and emerging directions in the field, emphasizing the transformative potential of biosensor-driven adaptive learning systems. Our findings suggest that integrating multimodal data can facilitate personalized learning experiences, real-time feedback, and intelligent educational interventions, ultimately advancing toward a more customized and adaptive online learning experience.",
      "tldr_zh": "è¯¥ç»¼è¿°ç³»ç»Ÿåœ°æ¢è®¨äº†åœ¨ç°ä»£åœ¨çº¿å­¦ä¹ ä¸­é›†æˆ Biosensors å’Œ Multimodal Learning Analytics (MmLA) ä»¥æ£€æµ‹å’Œé¢„æµ‹å­¦ç”Ÿè¡Œä¸ºçš„ç°çŠ¶ä¸æŒ‘æˆ˜ã€‚ç ”ç©¶ç»¼åˆåˆ†æäº† 54 é¡¹å…³é”®æ–‡çŒ®ï¼Œé˜è¿°äº†å¦‚ä½•ç»“åˆå¿ƒç‡ (Heart rate)ã€å¤§è„‘æ´»åŠ¨ (Brain activity) å’Œçœ¼åŠ¨è¿½è¸ª (Eye-tracking) ç­‰ç”Ÿç†ä¿¡å·ä¸ä¼ ç»Ÿäº¤äº’æ•°æ®ï¼Œä»¥è·å–æ›´æ·±å±‚çš„è®¤çŸ¥çŠ¶æ€å’Œå‚ä¸åº¦æ´å¯Ÿã€‚æ–‡ç« é‡ç‚¹è®¨è®ºäº†æƒ…ç»ªä¸æ³¨æ„åŠ›æ£€æµ‹ (Emotion and attention detection)ã€è¡Œä¸ºåˆ†æã€å®éªŒè®¾è®¡åŠäººå£ç»Ÿè®¡å­¦å› ç´ ï¼Œå¹¶æ€»ç»“äº†å…ˆè¿›çš„ Machine learning ç®—æ³•ä¸å¤šæ¨¡æ€æ•°æ®é¢„å¤„ç†æŠ€æœ¯ (Multimodal data pre-processing techniques)ã€‚ç ”ç©¶å‘ç°ï¼Œæ•´åˆå¤šæ¨¡æ€æ•°æ®èƒ½æœ‰æ•ˆä¿ƒè¿›ä¸ªæ€§åŒ–å­¦ä¹ ä½“éªŒã€å®æ—¶åé¦ˆå’Œæ™ºèƒ½åŒ–æ•™è‚²å¹²é¢„ã€‚è¯¥ç»¼è¿°å¼ºè°ƒäº†åŸºäº Biosensor é©±åŠ¨çš„è‡ªé€‚åº”å­¦ä¹ ç³»ç»Ÿåœ¨æ¨åŠ¨åœ¨çº¿æ•™è‚²å‘å®šåˆ¶åŒ–å’Œæ™ºèƒ½åŒ–è½¬å‹ä¸­çš„å·¨å¤§æ½œåŠ›ã€‚",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.HC",
      "comment": "Accepted for publication in Behaviour & Information Technology (Taylor & Francis). Final published version will be available soon at https://www.tandfonline.com/journals/tbit20",
      "pdf_url": "https://arxiv.org/pdf/2509.07742v1",
      "published_date": "2025-09-09 13:41:40 UTC",
      "updated_date": "2025-09-09 13:41:40 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:28:50.837355+00:00"
    },
    {
      "arxiv_id": "2509.07733v2",
      "title": "The Carbon Footprint Wizard: A Knowledge-Augmented AI Interface for Streamlining Food Carbon Footprint Analysis",
      "title_zh": "Carbon Footprint Wizardï¼šä¸€ç§ç”¨äºç®€åŒ–é£Ÿå“ç¢³è¶³è¿¹åˆ†æçš„çŸ¥è¯†å¢å¼ºå‹äººå·¥æ™ºèƒ½äº¤äº’ç•Œé¢",
      "authors": [
        "Mustafa Kaan Aslan",
        "Reinout Heijungs",
        "Filip Ilievski"
      ],
      "abstract": "Environmental sustainability, particularly in relation to climate change, is a key concern for consumers, producers, and policymakers. The carbon footprint, based on greenhouse gas emissions, is a standard metric for quantifying the contribution to climate change of activities and is often assessed using life cycle assessment (LCA). However, conducting LCA is complex due to opaque and global supply chains, as well as fragmented data. This paper presents a methodology that combines advances in LCA and publicly available databases with knowledge-augmented AI techniques, including retrieval-augmented generation, to estimate cradle-to-gate carbon footprints of food products. We introduce a chatbot interface that allows users to interactively explore the carbon impact of composite meals and relate the results to familiar activities. A live web demonstration showcases our proof-of-concept system with arbitrary food items and follow-up questions, highlighting both the potential and limitations - such as database uncertainties and AI misinterpretations - of delivering LCA insights in an accessible format.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å…¨çƒä¾›åº”é“¾ä¸é€æ˜å’Œæ•°æ®ç¢ç‰‡åŒ–å¯¼è‡´ç”Ÿå‘½å‘¨æœŸè¯„ä¼° (LCA) è¿‡ç¨‹å¤æ‚çš„é—®é¢˜ï¼Œæå‡ºäº† The Carbon Footprint Wizard ç•Œé¢ï¼Œæ—¨åœ¨ç®€åŒ–é£Ÿå“ç¢³è¶³è¿¹ (carbon footprint) åˆ†æã€‚è¯¥æ–¹æ³•ç»“åˆäº†æœ€æ–°çš„ LCA è¿›å±•ã€å…¬å¼€æ•°æ®åº“ä¸æ£€ç´¢å¢å¼ºç”Ÿæˆ (RAG) ç­‰çŸ¥è¯†å¢å¼º AI æŠ€æœ¯ï¼Œèƒ½å¤Ÿä¼°ç®—é£Ÿå“ä»æ‘‡ç¯®åˆ°å¤§é—¨ (cradle-to-gate) çš„ç¯å¢ƒå½±å“ã€‚é€šè¿‡å¼€å‘çš„èŠå¤©æœºå™¨äººç•Œé¢ï¼Œç”¨æˆ·å¯ä»¥äº¤äº’å¼åœ°æ¢ç´¢å¤åˆè†³é£Ÿçš„ç¢³æ’æ”¾ï¼Œå¹¶å°†å…¶ä¸æ—¥å¸¸æ´»åŠ¨è¿›è¡Œç›´è§‚å¯¹æ¯”ã€‚Web æ¼”ç¤ºç³»ç»Ÿè¯æ˜äº†è¯¥å·¥å…·åœ¨å¤„ç†ä»»æ„é£Ÿå“é¡¹åŠåç»­æŸ¥è¯¢æ–¹é¢çš„æ½œåŠ›ï¼Œå±•ç¤ºäº†ä»¥æ˜“äºè·å–çš„å½¢å¼ä¼ é€’ LCA è§è§£çš„å¯èƒ½æ€§ã€‚å°½ç®¡ç›®å‰ä»é¢ä¸´æ•°æ®åº“ä¸ç¡®å®šæ€§å’Œ AI è¯¯è§£ç­‰å±€é™ï¼Œè¯¥ç ”ç©¶ä¸ºæå‡æ¶ˆè´¹è€…ã€ç”Ÿäº§è€…åŠæ”¿ç­–åˆ¶å®šè€…çš„ç¯å¢ƒå†³ç­–æ•ˆç‡æä¾›äº†åˆ›æ–°çš„æŠ€æœ¯æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.07733v2",
      "published_date": "2025-09-09 13:34:06 UTC",
      "updated_date": "2025-11-14 14:07:26 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:28:54.741844+00:00"
    },
    {
      "arxiv_id": "2509.07723v1",
      "title": "BDPM: A Machine Learning-Based Feature Extractor for Parkinson's Disease Classification via Gut Microbiota Analysis",
      "title_zh": "BDPMï¼šä¸€ç§åŸºäºæœºå™¨å­¦ä¹ çš„é€šè¿‡è‚ é“èŒç¾¤åˆ†æè¿›è¡Œå¸•é‡‘æ£®ç—…åˆ†ç±»çš„ç‰¹å¾æå–å™¨",
      "authors": [
        "Bo Yu",
        "Zhixiu Hua",
        "Bo Zhao"
      ],
      "abstract": "Background: Parkinson's disease remains a major neurodegenerative disorder with high misdiagnosis rates, primarily due to reliance on clinical rating scales. Recent studies have demonstrated a strong association between gut microbiota and Parkinson's disease, suggesting that microbial composition may serve as a promising biomarker. Although deep learning models based ongut microbiota show potential for early prediction, most approaches rely on single classifiers and often overlook inter-strain correlations or temporal dynamics. Therefore, there is an urgent need for more robust feature extraction methods tailored to microbiome data. Methods: We proposed BDPM (A Machine Learning-Based Feature Extractor for Parkinson's Disease Classification via Gut Microbiota Analysis). First, we collected gut microbiota profiles from 39 Parkinson's patients and their healthy spouses to identify differentially abundant taxa. Second, we developed an innovative feature selection framework named RFRE (Random Forest combined with Recursive Feature Elimination), integrating ecological knowledge to enhance biological interpretability. Finally, we designed a hybrid classification model to capture temporal and spatial patterns in microbiome data.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†BDPMï¼Œä¸€ç§åŸºäºæœºå™¨å­¦ä¹ çš„ç‰¹å¾æå–å™¨ï¼Œæ—¨åœ¨é€šè¿‡è‚ é“å¾®ç”Ÿç‰©ç¾¤(Gut Microbiota)åˆ†ææé«˜å¸•é‡‘æ£®ç—…(Parkinson's Disease)çš„åˆ†ç±»å‡†ç¡®ç‡ï¼Œä»è€Œè§£å†³ä¸´åºŠé‡è¡¨è¯¯è¯Šç‡é«˜çš„é—®é¢˜ã€‚ç ”ç©¶äººå‘˜é¦–å…ˆå¯¹æ¯”äº†39åå¸•é‡‘æ£®ç—…æ‚£è€…åŠå…¶å¥åº·é…å¶çš„å¾®ç”Ÿç‰©ç¾¤è°±ï¼Œè¯†åˆ«å‡ºå…·æœ‰æ˜¾è‘—å·®å¼‚çš„åˆ†ç±»ç¾¤ã€‚ä¸ºäº†å¢å¼ºç”Ÿç‰©å­¦å¯è§£é‡Šæ€§ï¼Œè¯¥ç ”ç©¶å¼€å‘äº†ç»“åˆéšæœºæ£®æ—ä¸é€’å½’ç‰¹å¾æ¶ˆé™¤çš„åˆ›æ–°æ¡†æ¶RFRE(Random Forest combined with Recursive Feature Elimination)ã€‚æ­¤å¤–ï¼Œç ”ç©¶è®¾è®¡äº†ä¸€ç§æ··åˆåˆ†ç±»æ¨¡å‹(hybrid classification model)ï¼Œèƒ½å¤Ÿæœ‰æ•ˆæ•æ‰å¾®ç”Ÿç‰©ç»„æ•°æ®ä¸­çš„æ—¶é—´ä¸ç©ºé—´æ¨¡å¼ã€‚è¯¥æ–¹æ³•é€šè¿‡ä¼˜åŒ–çš„ç‰¹å¾æå–æŠ€æœ¯ï¼Œå…‹æœäº†ä¼ ç»Ÿå•ä¸€åˆ†ç±»å™¨å¿½ç•¥èŒæ ªç›¸å…³æ€§æˆ–åŠ¨æ€å˜åŒ–çš„å±€é™æ€§ï¼Œä¸ºå¸•é‡‘æ£®ç—…çš„æ—©æœŸé¢„æµ‹æä¾›äº†æ›´å…·é²æ£’æ€§çš„ç”Ÿç‰©æ ‡å¿—ç‰©(biomarker)åˆ†ææ‰‹æ®µã€‚",
      "categories": [
        "cs.AI",
        "cs.LG",
        "q-bio.QM"
      ],
      "primary_category": "cs.AI",
      "comment": "11 pages, 7 figures",
      "pdf_url": "https://arxiv.org/pdf/2509.07723v1",
      "published_date": "2025-09-09 13:24:25 UTC",
      "updated_date": "2025-09-09 13:24:25 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:28:57.836352+00:00"
    },
    {
      "arxiv_id": "2509.07711v1",
      "title": "RIMO: An Easy-to-Evaluate, Hard-to-Solve Olympiad Benchmark for Advanced Mathematical Reasoning",
      "title_zh": "RIMOï¼šä¸€ä¸ªæ˜“äºè¯„ä¼°ã€éš¾ä»¥æ”»å…‹çš„é«˜çº§æ•°å­¦æ¨ç†å¥¥æ—åŒ¹å…‹åŸºå‡†",
      "authors": [
        "Ziye Chen",
        "Chengwei Qin",
        "Yao Shu"
      ],
      "abstract": "As large language models (LLMs) reach high scores on established mathematical benchmarks, such as GSM8K and MATH, the research community has turned to International Mathematical Olympiad (IMO) problems to push the evaluation frontier. However, existing Olympiad-level benchmarks suffer from practical constraints that introduce grading noise and potential bias, such as heterogeneous answer formats requiring model-based judges and a reliance on potentially flawed solutions. We introduce RIMO, a two-track benchmark designed to preserve peak Olympiad difficulty while eliminating this evaluation noise. The first track, RIMO-N, rewrites 335 IMO problems to admit a single, unique integer answer, allowing for deterministic correctness checking. The second track, RIMO-P, features 456 proof problems with expert-checked solutions, which are decomposed into a sequence of sub-problems to evaluate the step-by-step reasoning process via an automated grading system. Our benchmarking of ten frontier LLMs, including GPT-4o and Gemini 2.5 Flash, reveals that while these systems excel on older benchmarks, their performance drops sharply on RIMO. These results highlight a substantial gap between current LLM capabilities and actual Olympiad-level reasoning. By providing a challenging yet easy-to-evaluate suite, RIMO offers a high-resolution yardstick for future research, presenting a clear target for closing the profound reasoning gap our findings expose.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç°æœ‰å¥¥æ—åŒ¹å…‹æ•°å­¦åŸºå‡†æµ‹è¯•(Olympiad benchmarks)ä¸­å­˜åœ¨çš„è¯„åˆ†å™ªå£°å’Œè¯„ä¼°åè§é—®é¢˜ï¼Œæå‡ºäº† RIMOï¼Œä¸€ä¸ªå…¼å…·é«˜éš¾åº¦ä¸æ˜“è¯„ä¼°æ€§çš„å…ˆè¿›æ•°å­¦æ¨ç†åŸºå‡†ã€‚RIMO åŒ…å«ä¸¤ä¸ªèµ›é“ï¼šRIMO-N é€šè¿‡é‡å†™ 335 é“å›½é™…æ•°å­¦å¥¥æ—åŒ¹å…‹(IMO)é¢˜ç›®ä»¥ç¡®ä¿å”¯ä¸€çš„æ•´æ•°ç­”æ¡ˆï¼Œä»è€Œå®ç°ç¡®å®šæ€§çš„æ­£ç¡®æ€§æ£€æŸ¥ï¼›RIMO-P åˆ™åŒ…å« 456 é“è¯æ˜é¢˜ï¼Œå¹¶å°†å…¶åˆ†è§£ä¸ºå­é—®é¢˜åºåˆ—ï¼Œä»¥ä¾¿åˆ©ç”¨è‡ªåŠ¨åŒ–ç³»ç»Ÿè¯„ä¼°é€æ­¥æ¨ç†è¿‡ç¨‹ã€‚é€šè¿‡å¯¹ GPT-4o å’Œ Gemini ç­‰åç§å‰æ²¿å¤§è¯­è¨€æ¨¡å‹(LLMs)çš„æµ‹è¯•ï¼Œç ”ç©¶å‘ç°è¿™äº›æ¨¡å‹åœ¨ RIMO ä¸Šçš„æ€§èƒ½å¤§å¹…ä¸‹é™ï¼Œæš´éœ²äº†å½“å‰æ¨¡å‹ä¸çœŸå®å¥¥æ—åŒ¹å…‹çº§åˆ«æ¨ç†èƒ½åŠ›ä¹‹é—´çš„æ˜¾è‘—å·®è·ã€‚è¯¥åŸºå‡†ä¸ºæœªæ¥ç ”ç©¶æä¾›äº†ä¸€ä¸ªé«˜åˆ†è¾¨ç‡çš„è¡¡é‡æ ‡å‡†ï¼Œæ—¨åœ¨æ¨åŠ¨ç¼©å°å¤§è¯­è¨€æ¨¡å‹åœ¨é«˜çº§æ•°å­¦é€»è¾‘æ–¹é¢çš„çŸ­æ¿ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.07711v1",
      "published_date": "2025-09-09 13:13:51 UTC",
      "updated_date": "2025-09-09 13:13:51 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:28:57.272139+00:00"
    },
    {
      "arxiv_id": "2509.07706v1",
      "title": "FHIR-RAG-MEDS: Integrating HL7 FHIR with Retrieval-Augmented Large Language Models for Enhanced Medical Decision Support",
      "title_zh": "FHIR-RAG-MEDSï¼šæ•´åˆ HL7 FHIR ä¸æ£€ç´¢å¢å¼ºå¤§è¯­è¨€æ¨¡å‹ä»¥å¼ºåŒ–åŒ»ç–—å†³ç­–æ”¯æŒ",
      "authors": [
        "Yildiray Kabak",
        "Gokce B. Laleci Erturkmen",
        "Mert Gencturk",
        "Tuncay Namli",
        "A. Anil Sinaci",
        "Ruben Alcantud Corcoles",
        "Cristina Gomez Ballesteros",
        "Pedro Abizanda",
        "Asuman Dogac"
      ],
      "abstract": "In this study, we propose FHIR-RAG-MEDS system that aims to integrate Health Level 7 Fast Healthcare Interoperability Resources (HL7 FHIR) with a Retrieval-Augmented Generation (RAG)-based system to improve personalized medical decision support on evidence-based clinical guidelines, emphasizing the need for research in practical applications. In the evolving landscape of medical decision support systems, integrating advanced technologies such as RAG and HL7 FHIR can significantly enhance clinical decision-making processes. Despite the potential of these technologies, there is limited research on their integration in practical applications.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† FHIR-RAG-MEDS ç³»ç»Ÿï¼Œé€šè¿‡å°† HL7 FHIR æ ‡å‡†ä¸åŸºäºæ£€ç´¢å¢å¼ºç”Ÿæˆ (RAG) çš„å¤§è¯­è¨€æ¨¡å‹ç›¸ç»“åˆï¼Œæ—¨åœ¨å¢å¼ºåŸºäºå¾ªè¯ä¸´åºŠæŒ‡å—çš„ä¸ªæ€§åŒ–åŒ»ç–—å†³ç­–æ”¯æŒã€‚åœ¨ä¸æ–­æ¼”è¿›çš„åŒ»ç–—å†³ç­–æ”¯æŒç³»ç»Ÿé¢†åŸŸï¼Œé›†æˆè¿™äº›å…ˆè¿›æŠ€æœ¯èƒ½æ˜¾è‘—æå‡ä¸´åºŠå†³ç­–çš„å‡†ç¡®æ€§ä¸æ•ˆç‡ã€‚å°½ç®¡ RAG ä¸ HL7 FHIR åœ¨åŒ»ç–—é¢†åŸŸå±•ç°å‡ºå·¨å¤§æ½œåŠ›ï¼Œä½†ç›®å‰é’ˆå¯¹ä¸¤è€…åœ¨å®é™…ä¸´åºŠåº”ç”¨ä¸­é›†æˆçš„ç ”ç©¶ä»ååˆ†åŒ®ä¹ã€‚è¯¥ç³»ç»Ÿé€šè¿‡å®ç°æ ‡å‡†æ•°æ®èµ„æºä¸æ£€ç´¢å¢å¼ºæŠ€æœ¯çš„æ·±åº¦èåˆï¼Œä¸ºå¤æ‚åŒ»ç–—åœºæ™¯ä¸‹çš„å†³ç­–åˆ¶å®šæä¾›äº†æ–°çš„æŠ€æœ¯è·¯å¾„ã€‚FHIR-RAG-MEDS çš„æå‡ºå¼ºè°ƒäº†å®è·µåº”ç”¨ä¸­æŠ€æœ¯é›†æˆçš„é‡è¦æ€§ï¼Œä¸ºæ„å»ºæ›´å¯é ã€æ›´å…·äº’æ“ä½œæ€§çš„æ™ºèƒ½åŒ»ç–—ç³»ç»Ÿå¥ å®šäº†åŸºç¡€ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "31 pages, submitted to Journal of Biomedical Informatics, under review",
      "pdf_url": "https://arxiv.org/pdf/2509.07706v1",
      "published_date": "2025-09-09 13:10:49 UTC",
      "updated_date": "2025-09-09 13:10:49 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:29:10.241213+00:00"
    },
    {
      "arxiv_id": "2509.08026v1",
      "title": "Two-Stage Swarm Intelligence Ensemble Deep Transfer Learning (SI-EDTL) for Vehicle Detection Using Unmanned Aerial Vehicles",
      "title_zh": "ç”¨äºæ— äººæœºè½¦è¾†æ£€æµ‹çš„ä¸¤é˜¶æ®µç¾¤ä½“æ™ºèƒ½é›†æˆæ·±åº¦è¿ç§»å­¦ä¹  (SI-EDTL)",
      "authors": [
        "Zeinab Ghasemi Darehnaei",
        "Mohammad Shokouhifar",
        "Hossein Yazdanjouei",
        "S. M. J. Rastegar Fatemi"
      ],
      "abstract": "This paper introduces SI-EDTL, a two-stage swarm intelligence ensemble deep transfer learning model for detecting multiple vehicles in UAV images. It combines three pre-trained Faster R-CNN feature extractor models (InceptionV3, ResNet50, GoogLeNet) with five transfer classifiers (KNN, SVM, MLP, C4.5, NaÃ¯ve Bayes), resulting in 15 different base learners. These are aggregated via weighted averaging to classify regions as Car, Van, Truck, Bus, or background. Hyperparameters are optimized with the whale optimization algorithm to balance accuracy, precision, and recall. Implemented in MATLAB R2020b with parallel processing, SI-EDTL outperforms existing methods on the AU-AIR UAV dataset.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§åä¸ºSI-EDTLçš„ä¸¤é˜¶æ®µç¾¤æ™ºé›†æˆæ·±åº¦è¿ç§»å­¦ä¹ æ¨¡å‹ï¼Œæ—¨åœ¨è§£å†³æ— äººæœº(UAV)å›¾åƒä¸­çš„å¤šç±»åˆ«è½¦è¾†æ£€æµ‹é—®é¢˜ã€‚è¯¥æ¨¡å‹ç»“åˆäº†InceptionV3ã€ResNet50å’ŒGoogLeNetä¸‰ç§é¢„è®­ç»ƒçš„Faster R-CNNç‰¹å¾æå–æ¨¡å‹ï¼Œå¹¶ä¸KNNã€SVMã€MLPã€C4.5å’ŒNaÃ¯ve Bayesäº”ç§è¿ç§»åˆ†ç±»å™¨é…å¯¹ï¼Œæ„å»ºäº†15ä¸ªä¸åŒçš„åŸºç¡€å­¦ä¹ å™¨ã€‚é€šè¿‡åŠ æƒå¹³å‡æ³•(weighted averaging)å¯¹è¿™äº›å­¦ä¹ å™¨è¿›è¡Œé›†æˆï¼Œå®ç°å¯¹Carã€Vanã€Truckã€BusåŠèƒŒæ™¯åŒºåŸŸçš„åˆ†ç±»ã€‚ç ”ç©¶è¿›ä¸€æ­¥é‡‡ç”¨äº†é²¸é±¼ä¼˜åŒ–ç®—æ³•(whale optimization algorithm)å¯¹æ¨¡å‹è¶…å‚æ•°è¿›è¡Œä¼˜åŒ–ï¼Œä»¥å®ç°å‡†ç¡®ç‡ã€ç²¾ç¡®ç‡å’Œå¬å›ç‡çš„æœ€ä½³å¹³è¡¡ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œåœ¨MATLABç¯å¢ƒä¸‹å®ç°çš„SI-EDTLåœ¨AU-AIR UAVæ•°æ®é›†ä¸Šå±•ç°å‡ºå“è¶Šæ€§èƒ½ï¼Œæ˜¾è‘—ä¼˜äºç°æœ‰çš„æ£€æµ‹æ–¹æ³•ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.08026v1",
      "published_date": "2025-09-09 13:03:12 UTC",
      "updated_date": "2025-09-09 13:03:12 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:29:08.144875+00:00"
    },
    {
      "arxiv_id": "2509.07677v4",
      "title": "Spectral Masking and Interpolation Attack (SMIA): A Black-box Adversarial Attack against Voice Authentication and Anti-Spoofing Systems",
      "title_zh": "é¢‘è°±æ©è”½ä¸æ’å€¼æ”»å‡» (SMIA)ï¼šé’ˆå¯¹è¯­éŸ³è®¤è¯ä¸åæ¬ºéª—ç³»ç»Ÿçš„é»‘ç›’å¯¹æŠ—æ”»å‡»",
      "authors": [
        "Kamel Kamel",
        "Hridoy Sankar Dutta",
        "Keshav Sood",
        "Sunil Aryal"
      ],
      "abstract": "Voice Authentication Systems (VAS) use unique vocal characteristics for verification. They are increasingly integrated into high-security sectors such as banking and healthcare. Despite their improvements using deep learning, they face severe vulnerabilities from sophisticated threats like deepfakes and adversarial attacks. The emergence of realistic voice cloning complicates detection, as systems struggle to distinguish authentic from synthetic audio. While anti-spoofing countermeasures (CMs) exist to mitigate these risks, many rely on static detection models that can be bypassed by novel adversarial methods, leaving a critical security gap. To demonstrate this vulnerability, we propose the Spectral Masking and Interpolation Attack (SMIA), a novel method that strategically manipulates inaudible frequency regions of AI-generated audio. By altering the voice in imperceptible zones to the human ear, SMIA creates adversarial samples that sound authentic while deceiving CMs. We conducted a comprehensive evaluation of our attack against state-of-the-art (SOTA) models across multiple tasks, under simulated real-world conditions. SMIA achieved a strong attack success rate (ASR) of at least 82% against combined VAS/CM systems, at least 97.5% against standalone speaker verification systems, and 100% against countermeasures. These findings conclusively demonstrate that current security postures are insufficient against adaptive adversarial attacks. This work highlights the urgent need for a paradigm shift toward next-generation defenses that employ dynamic, context-aware frameworks capable of evolving with the threat landscape.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† Spectral Masking and Interpolation Attack (SMIA)ï¼Œè¿™æ˜¯ä¸€ç§é’ˆå¯¹è¯­éŸ³è®¤è¯ç³»ç»Ÿ (Voice Authentication Systems, VAS) å’Œåæ¬ºéª—ç³»ç»Ÿ (Anti-Spoofing Systems) çš„æ–°å‹é»‘ç›’å¯¹æŠ—æ”»å‡»æ–¹æ³•ã€‚å°½ç®¡æ·±åº¦å­¦ä¹ æå‡äº†è¯­éŸ³è®¤è¯çš„æ€§èƒ½ï¼Œä½†ç°æœ‰ç³»ç»Ÿä»é¢ä¸´æ·±åº¦ä¼ªé€  (Deepfakes) å’Œå¯¹æŠ—æ€§æ”»å‡»çš„ä¸¥é‡å¨èƒï¼Œç°æœ‰çš„é™æ€æ£€æµ‹æ‰‹æ®µéš¾ä»¥æœ‰æ•ˆè¯†åˆ«é«˜åº¦é€¼çœŸçš„åˆæˆè¯­éŸ³ã€‚SMIA é€šè¿‡æˆ˜ç•¥æ€§åœ°æ“çºµ AI ç”ŸæˆéŸ³é¢‘ä¸­äººè€³ä¸å¯å¬çš„é¢‘ç‡åŒºåŸŸï¼Œåˆ©ç”¨é¢‘è°±é®è”½å’Œæ’å€¼æŠ€æœ¯åˆ¶é€ å¯¹æŠ—æ ·æœ¬ï¼Œä»è€Œåœ¨ä¿æŒå¬è§‰çœŸå®æ„Ÿçš„åŒæ—¶æ¬ºéª—åæ¬ºéª—å¯¹ç­– (Countermeasures, CMs)ã€‚å®éªŒè¯„ä¼°æ˜¾ç¤ºï¼ŒSMIA åœ¨æ¨¡æ‹ŸçœŸå®åœºæ™¯ä¸‹è¡¨ç°å‡ºæå¼ºçš„æ”»å‡»åŠ›ï¼Œå¯¹ç‹¬ç«‹è¯´è¯äººéªŒè¯ç³»ç»Ÿçš„æ”»å‡»æˆåŠŸç‡ (ASR) è¶…è¿‡ 97.5%ï¼Œå¯¹åæ¬ºéª—ç³»ç»Ÿçš„æ”»å‡»æˆåŠŸç‡ç”šè‡³è¾¾åˆ° 100%ã€‚ç ”ç©¶ç»“æœè¡¨æ˜ï¼Œç°æœ‰çš„å®‰å…¨é˜²æŠ¤ä½“ç³»ä¸è¶³ä»¥åº”å¯¹æ­¤ç±»è‡ªé€‚åº”å¯¹æŠ—æ”»å‡»ï¼Œè¿«åˆ‡éœ€è¦è½¬å‘èƒ½å¤Ÿéšå¨èƒç¯å¢ƒæ¼”è¿›çš„åŠ¨æ€ã€è¯­å¢ƒæ„ŸçŸ¥çš„ä¸‹ä¸€ä»£é˜²å¾¡æ¡†æ¶ã€‚",
      "categories": [
        "cs.SD",
        "cs.AI"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.07677v4",
      "published_date": "2025-09-09 12:43:59 UTC",
      "updated_date": "2026-01-09 17:56:08 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:29:10.737547+00:00"
    },
    {
      "arxiv_id": "2509.07676v1",
      "title": "Unleashing the True Potential of LLMs: A Feedback-Triggered Self-Correction with Long-Term Multipath Decoding",
      "title_zh": "é‡Šæ”¾å¤§è¯­è¨€æ¨¡å‹çš„çœŸæ­£æ½œåŠ›ï¼šåŸºäºé•¿æœŸå¤šè·¯å¾„è§£ç çš„åé¦ˆè§¦å‘å¼è‡ªæˆ‘ä¿®æ­£",
      "authors": [
        "Jipeng Li",
        "Zeyu Gao",
        "Yubin Qi",
        "Hande Dong",
        "Weijian Chen",
        "Qiang Lin"
      ],
      "abstract": "Large Language Models (LLMs) have achieved remarkable performance across diverse tasks, yet their susceptibility to generating incorrect content during inference remains a critical unsolved challenge. While self-correction methods offer potential solutions, their effectiveness is hindered by two inherent limitations: (1) the absence of reliable guidance signals for error localization, and (2) the restricted reasoning depth imposed by conventional next-token decoding paradigms. To address these issues, we propose Feedback-Triggered Regeneration (FTR), a novel framework that synergizes user feedback with enhanced decoding dynamics. Specifically, FTR activates response regeneration only upon receiving negative user feedback, thereby circumventing error propagation from faulty self-assessment while preserving originally correct outputs. Furthermore, we introduce Long-Term Multipath (LTM) decoding, which enables systematic exploration of multiple reasoning trajectories through delayed sequence evaluation, effectively overcoming the myopic decision-making characteristic of standard next-token prediction. Extensive experiments on mathematical reasoning and code generation benchmarks demonstrate that our framework achieves consistent and significant improvements over state-of-the-art prompt-based self-correction methods.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§è¯­è¨€æ¨¡å‹ (LLMs) åœ¨æ¨ç†è¿‡ç¨‹ä¸­å®¹æ˜“ç”Ÿæˆé”™è¯¯å†…å®¹çš„é—®é¢˜ï¼ŒæŒ‡å‡ºå½“å‰çš„è‡ªæˆ‘ä¿®æ­£æ–¹æ³•å—é™äºé”™è¯¯å®šä½å¼•å¯¼ä¿¡å·çš„ç¼ºå¤±ä»¥åŠä¼ ç»Ÿè§£ç èŒƒå¼çš„æ¨ç†æ·±åº¦ä¸è¶³ã€‚ä¸ºäº†è§£å†³è¿™äº›æŒ‘æˆ˜ï¼Œä½œè€…æå‡ºäº†åé¦ˆè§¦å‘å†ç”Ÿ (Feedback-Triggered Regeneration, FTR) æ¡†æ¶ï¼Œè¯¥æ¡†æ¶åˆ©ç”¨ç”¨æˆ·åé¦ˆè§¦å‘å“åº”å†ç”Ÿï¼Œåœ¨é¿å…é”™è¯¯ä¼ æ’­çš„åŒæ—¶ä¿ç•™äº†åŸæœ¬æ­£ç¡®çš„è¾“å‡ºã€‚æ­¤å¤–ï¼Œç ”ç©¶è¿˜å¼•å…¥äº†é•¿æœŸå¤šè·¯å¾„ (Long-Term Multipath, LTM) è§£ç æŠ€æœ¯ï¼Œé€šè¿‡å»¶è¿Ÿåºåˆ—è¯„ä¼°æ¥ç³»ç»Ÿåœ°æ¢ç´¢å¤šç§æ¨ç†è½¨è¿¹ï¼Œæœ‰æ•ˆå…‹æœäº†æ ‡å‡†é€è¯é¢„æµ‹ (next-token prediction) çš„çŸ­è§†å†³ç­–å±€é™ã€‚åœ¨æ•°å­¦æ¨ç†å’Œä»£ç ç”ŸæˆåŸºå‡†æµ‹è¯•ä¸Šçš„å¹¿æ³›å®éªŒè¡¨æ˜ï¼Œè¯¥æ¡†æ¶åœ¨æ€§èƒ½ä¸Šæ˜¾è‘—ä¸”æŒç»­åœ°ä¼˜äºç›®å‰æœ€å…ˆè¿›çš„åŸºäºæç¤ºçš„è‡ªæˆ‘ä¿®æ­£æ–¹æ³•ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.07676v1",
      "published_date": "2025-09-09 12:43:28 UTC",
      "updated_date": "2025-09-09 12:43:28 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:29:12.038209+00:00"
    },
    {
      "arxiv_id": "2509.07665v1",
      "title": "DeepGraphLog for Layered Neurosymbolic AI",
      "title_zh": "DeepGraphLogï¼šé¢å‘åˆ†å±‚ç¥ç»ç¬¦å·äººå·¥æ™ºèƒ½",
      "authors": [
        "Adem Kikaj",
        "Giuseppe Marra",
        "Floris Geerts",
        "Robin Manhaeve",
        "Luc De Raedt"
      ],
      "abstract": "Neurosymbolic AI (NeSy) aims to integrate the statistical strengths of neural networks with the interpretability and structure of symbolic reasoning. However, current NeSy frameworks like DeepProbLog enforce a fixed flow where symbolic reasoning always follows neural processing. This restricts their ability to model complex dependencies, especially in irregular data structures such as graphs. In this work, we introduce DeepGraphLog, a novel NeSy framework that extends ProbLog with Graph Neural Predicates. DeepGraphLog enables multi-layer neural-symbolic reasoning, allowing neural and symbolic components to be layered in arbitrary order. In contrast to DeepProbLog, which cannot handle symbolic reasoning via neural methods, DeepGraphLog treats symbolic representations as graphs, enabling them to be processed by Graph Neural Networks (GNNs). We showcase the capabilities of DeepGraphLog on tasks in planning, knowledge graph completion with distant supervision, and GNN expressivity. Our results demonstrate that DeepGraphLog effectively captures complex relational dependencies, overcoming key limitations of existing NeSy systems. By broadening the applicability of neurosymbolic AI to graph-structured domains, DeepGraphLog offers a more expressive and flexible framework for neural-symbolic integration.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† DeepGraphLogï¼Œè¿™æ˜¯ä¸€ç§é€šè¿‡å›¾ç¥ç»è°“è¯(Graph Neural Predicates)æ‰©å±• ProbLog çš„æ–°å‹ç¥ç»ç¬¦å·äººå·¥æ™ºèƒ½(Neurosymbolic AI)æ¡†æ¶ã€‚é’ˆå¯¹ç°æœ‰æ¡†æ¶å¦‚ DeepProbLog å­˜åœ¨çš„ç¥ç»å¤„ç†å¿…é¡»å…ˆäºç¬¦å·æ¨ç†çš„å›ºå®šæµç¨‹é™åˆ¶ï¼ŒDeepGraphLog å®ç°äº†å¤šå±‚ç¥ç»ç¬¦å·æ¨ç†ï¼Œå…è®¸ç¥ç»ç½‘ç»œå’Œç¬¦å·ç»„ä»¶ä»¥ä»»æ„é¡ºåºè¿›è¡Œå±‚å ã€‚è¯¥æ¡†æ¶çš„åˆ›æ–°ä¹‹å¤„åœ¨äºå°†ç¬¦å·è¡¨ç¤ºè§†ä¸ºå›¾ç»“æ„ï¼Œå¹¶åˆ©ç”¨å›¾ç¥ç»ç½‘ç»œ(GNNs)è¿›è¡Œå¤„ç†ï¼Œä»è€Œèƒ½å¤Ÿæœ‰æ•ˆå¤„ç†å¤æ‚ä¸”ä¸è§„åˆ™çš„æ•°æ®ä¾èµ–ã€‚ç ”ç©¶åœ¨è§„åˆ’(planning)ã€å¸¦è¿œè·ç¦»ç›‘ç£çš„çŸ¥è¯†å›¾è°±è¡¥å…¨(knowledge graph completion)ä»¥åŠ GNN è¡¨è¾¾èƒ½åŠ›ç­‰ä»»åŠ¡ä¸Šè¿›è¡Œäº†éªŒè¯ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒDeepGraphLog æˆåŠŸå…‹æœäº†ç°æœ‰ NeSy ç³»ç»Ÿçš„å±€é™æ€§ï¼Œä¸ºå›¾ç»“æ„é¢†åŸŸçš„ç¥ç»ç¬¦å·é›†æˆæä¾›äº†ä¸€ä¸ªæ›´å…·è¡¨è¾¾åŠ›å’Œçµæ´»æ€§çš„è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.07665v1",
      "published_date": "2025-09-09 12:32:07 UTC",
      "updated_date": "2025-09-09 12:32:07 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:29:16.537961+00:00"
    },
    {
      "arxiv_id": "2510.15895v1",
      "title": "BREATH: A Bio-Radar Embodied Agent for Tonal and Human-Aware Diffusion Music Generation",
      "title_zh": "BREATHï¼šé¢å‘è°ƒæ€§ä¸äººç±»æ„ŸçŸ¥æ‰©æ•£éŸ³ä¹ç”Ÿæˆçš„ç”Ÿç‰©é›·è¾¾å…·èº«æ™ºèƒ½ä½“",
      "authors": [
        "Yunzhe Wang",
        "Xinyu Tang",
        "Zhixun Huang",
        "Xiaolong Yue",
        "Yuxin Zeng"
      ],
      "abstract": "We present a multimodal system for personalized music generation that integrates physiological sensing, LLM-based reasoning, and controllable audio synthesis. A millimeter-wave radar sensor non-invasively captures heart rate and respiration rate. These physiological signals, combined with environmental state, are interpreted by a reasoning agent to infer symbolic musical descriptors, such as tempo, mood intensity, and traditional Chinese pentatonic modes, which are then expressed as structured prompts to guide a diffusion-based audio model in synthesizing expressive melodies. The system emphasizes cultural grounding through tonal embeddings and enables adaptive, embodied music interaction. To evaluate the system, we adopt a research-creation methodology combining case studies, expert feedback, and targeted control experiments. Results show that physiological variations can modulate musical features in meaningful ways, and tonal conditioning enhances alignment with intended modal characteristics. Expert users reported that the system affords intuitive, culturally resonant musical responses and highlighted its potential for therapeutic and interactive applications. This work demonstrates a novel bio-musical feedback loop linking radar-based sensing, prompt reasoning, and generative audio modeling.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†BREATHï¼Œä¸€ç§é›†æˆäº†ç”Ÿç†æ„ŸçŸ¥ã€å¤§è¯­è¨€æ¨¡å‹(LLM)æ¨ç†å’Œå¯æ§éŸ³é¢‘åˆæˆçš„å¤šæ¨¡æ€ä¸ªæ€§åŒ–éŸ³ä¹ç”Ÿæˆç³»ç»Ÿã€‚è¯¥ç³»ç»Ÿåˆ©ç”¨æ¯«ç±³æ³¢é›·è¾¾(millimeter-wave radar)ä¼ æ„Ÿå™¨ä»¥éä¾µå…¥æ–¹å¼æ•è·å¿ƒç‡å’Œå‘¼å¸ç‡ï¼Œå¹¶ç”±æ¨ç†æ™ºèƒ½ä½“ç»“åˆç¯å¢ƒçŠ¶æ€æ¨æ–­å‡ºèŠ‚å¥ã€æƒ…ç»ªå¼ºåº¦åŠä¸­å›½ä¼ ç»Ÿäº”å£°è°ƒå¼(traditional Chinese pentatonic modes)ç­‰éŸ³ä¹æè¿°ç¬¦ã€‚è¿™äº›æè¿°ç¬¦è¢«è½¬åŒ–ä¸ºç»“æ„åŒ–æç¤ºè¯ï¼Œå¼•å¯¼æ‰©æ•£æ¨¡å‹(diffusion-based model)åˆæˆè¡¨è¾¾ä¸°å¯Œçš„æ—‹å¾‹ï¼Œå¹¶é€šè¿‡éŸ³è°ƒåµŒå…¥(tonal embeddings)å®ç°æ–‡åŒ–åº•è•´ä¸è‡ªé€‚åº”çš„å…·èº«äº¤äº’ã€‚ç ”ç©¶é€šè¿‡ç ”ç©¶åˆ›ä½œæ³•(research-creation methodology)è¯æ˜äº†ç”Ÿç†å˜åŒ–èƒ½æœ‰æ•ˆè°ƒåˆ¶éŸ³ä¹ç‰¹å¾ï¼Œä¸”éŸ³è°ƒè°ƒèŠ‚æ˜¾è‘—å¢å¼ºäº†ä¸é¢„è®¾è°ƒå¼ç‰¹æ€§çš„ä¸€è‡´æ€§ã€‚ä¸“å®¶è¯„ä»·è¯¥ç³»ç»Ÿæä¾›äº†ç›´è§‚ä¸”å…·æœ‰æ–‡åŒ–å…±é¸£çš„éŸ³ä¹å“åº”ï¼Œå±•ç¤ºäº†å…¶åœ¨æ²»ç–—å’Œäº¤äº’å¼åº”ç”¨ä¸­çš„å·¨å¤§æ½œåŠ›ã€‚è¿™é¡¹å·¥ä½œæˆåŠŸå»ºç«‹äº†è¿æ¥é›·è¾¾æ„ŸçŸ¥ã€æç¤ºè¯æ¨ç†ä¸ç”Ÿæˆå¼éŸ³é¢‘å»ºæ¨¡çš„æ–°å‹ç”Ÿç‰©éŸ³ä¹åé¦ˆé—­ç¯ã€‚",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.SD"
      ],
      "primary_category": "cs.HC",
      "comment": "Accepted by LLM4Music @ ISMIR 2025",
      "pdf_url": "https://arxiv.org/pdf/2510.15895v1",
      "published_date": "2025-09-09 12:26:20 UTC",
      "updated_date": "2025-09-09 12:26:20 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:29:21.542619+00:00"
    },
    {
      "arxiv_id": "2509.07642v1",
      "title": "Getting In Contract with Large Language Models -- An Agency Theory Perspective On Large Language Model Alignment",
      "title_zh": "ä¸å¤§è¯­è¨€æ¨¡å‹å»ºç«‹å¥‘çº¦ï¼šä»£ç†ç†è®ºè§†è§’ä¸‹çš„å¤§è¯­è¨€æ¨¡å‹å¯¹é½",
      "authors": [
        "Sascha Kaltenpoth",
        "Oliver MÃ¼ller"
      ],
      "abstract": "Adopting Large language models (LLMs) in organizations potentially revolutionizes our lives and work. However, they can generate off-topic, discriminating, or harmful content. This AI alignment problem often stems from misspecifications during the LLM adoption, unnoticed by the principal due to the LLM's black-box nature. While various research disciplines investigated AI alignment, they neither address the information asymmetries between organizational adopters and black-box LLM agents nor consider organizational AI adoption processes. Therefore, we propose LLM ATLAS (LLM Agency Theory-Led Alignment Strategy) a conceptual framework grounded in agency (contract) theory, to mitigate alignment problems during organizational LLM adoption. We conduct a conceptual literature analysis using the organizational LLM adoption phases and the agency theory as concepts. Our approach results in (1) providing an extended literature analysis process specific to AI alignment methods during organizational LLM adoption and (2) providing a first LLM alignment problem-solution space.",
      "tldr_zh": "è¯¥ç ”ç©¶ä»ä»£ç†ç†è®º(Agency Theory)è§†è§’æ¢è®¨äº†å¤§è¯­è¨€æ¨¡å‹(Large Language Models, LLMs)çš„å¯¹é½(Alignment)é—®é¢˜ï¼Œæ—¨åœ¨åº”å¯¹ç»„ç»‡åœ¨æ¨¡å‹é‡‡ç”¨è¿‡ç¨‹ä¸­å› å…¶é»‘ç›’ç‰¹æ€§å¯¼è‡´çš„ä¿¡æ¯ä¸å¯¹ç§°(Information Asymmetries)æŒ‘æˆ˜ã€‚ç ”ç©¶æå‡ºäº†LLM ATLAS (LLM Agency Theory-Led Alignment Strategy)è¿™ä¸€æ¦‚å¿µæ¡†æ¶ï¼Œåˆ©ç”¨å¥‘çº¦ç†è®ºçš„é€»è¾‘æ¥ç¼“è§£ç»„ç»‡åœ¨é›†æˆLLMsæ—¶å¯èƒ½å‡ºç°çš„ä»»åŠ¡åå·®æˆ–æœ‰å®³å†…å®¹ã€‚é€šè¿‡å¯¹ç»„ç»‡LLMé‡‡ç”¨é˜¶æ®µçš„æ·±åº¦æ–‡çŒ®åˆ†æï¼Œè¯¥ç ”ç©¶å¡«è¡¥äº†ç°æœ‰å¯¹é½æŠ€æœ¯åœ¨ç»„ç»‡é‡‡çº³æµç¨‹ä¸­ç¼ºä¹è€ƒè™‘çš„ç©ºç™½ã€‚å…¶ä¸»è¦è´¡çŒ®åœ¨äºæä¾›äº†ä¸€å¥—ä¸“é—¨é’ˆå¯¹ç»„ç»‡çº§AIå¯¹é½æ–¹æ³•çš„æ‰©å±•åˆ†ææµç¨‹ï¼Œå¹¶é¦–æ¬¡æ„å»ºäº†LLMå¯¹é½é—®é¢˜çš„è§£ç©ºé—´(Problem-Solution Space)ï¼Œä¸ºå®ç°æ›´å¯é çš„AIç»„ç»‡é›†æˆæä¾›äº†ç­–ç•¥æŒ‡å¯¼ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Presented at the 19th International Conference on Wirtschaftsinformatik 2024, WÃ¼rzburg, Germany https://aisel.aisnet.org/wi2024/91/",
      "pdf_url": "https://arxiv.org/pdf/2509.07642v1",
      "published_date": "2025-09-09 12:10:14 UTC",
      "updated_date": "2025-09-09 12:10:14 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:29:37.922303+00:00"
    },
    {
      "arxiv_id": "2509.08025v1",
      "title": "NOWJ@COLIEE 2025: A Multi-stage Framework Integrating Embedding Models and Large Language Models for Legal Retrieval and Entailment",
      "title_zh": "NOWJ@COLIEE 2025ï¼šé›†æˆåµŒå…¥æ¨¡å‹ä¸å¤§è¯­è¨€æ¨¡å‹çš„æ³•å¾‹æ£€ç´¢ä¸è•´å«å¤šé˜¶æ®µæ¡†æ¶",
      "authors": [
        "Hoang-Trung Nguyen",
        "Tan-Minh Nguyen",
        "Xuan-Bach Le",
        "Tuan-Kiet Le",
        "Khanh-Huyen Nguyen",
        "Ha-Thanh Nguyen",
        "Thi-Hai-Yen Vuong",
        "Le-Minh Nguyen"
      ],
      "abstract": "This paper presents the methodologies and results of the NOWJ team's participation across all five tasks at the COLIEE 2025 competition, emphasizing advancements in the Legal Case Entailment task (Task 2). Our comprehensive approach systematically integrates pre-ranking models (BM25, BERT, monoT5), embedding-based semantic representations (BGE-m3, LLM2Vec), and advanced Large Language Models (Qwen-2, QwQ-32B, DeepSeek-V3) for summarization, relevance scoring, and contextual re-ranking. Specifically, in Task 2, our two-stage retrieval system combined lexical-semantic filtering with contextualized LLM analysis, achieving first place with an F1 score of 0.3195. Additionally, in other tasks--including Legal Case Retrieval, Statute Law Retrieval, Legal Textual Entailment, and Legal Judgment Prediction--we demonstrated robust performance through carefully engineered ensembles and effective prompt-based reasoning strategies. Our findings highlight the potential of hybrid models integrating traditional IR techniques with contemporary generative models, providing a valuable reference for future advancements in legal information processing.",
      "tldr_zh": "è¯¥ç ”ç©¶ä»‹ç»äº† NOWJ å›¢é˜Ÿå‚åŠ  COLIEE 2025 ç«èµ›çš„æ–¹æ³•ä¸æˆæœï¼Œæå‡ºäº†ä¸€ä¸ªæ•´åˆåµŒå…¥æ¨¡å‹ (Embedding Models) ä¸å¤§è¯­è¨€æ¨¡å‹ (Large Language Models) çš„å¤šé˜¶æ®µæ¡†æ¶ã€‚è¯¥æ¡†æ¶ç³»ç»Ÿæ€§åœ°é›†æˆäº† BM25ã€BERT å’Œ monoT5 ç­‰é¢„æ’åºæ¨¡å‹ï¼Œå¹¶ç»“åˆ BGE-m3 ä¸ LLM2Vec ç­‰åŸºäºåµŒå…¥çš„è¯­ä¹‰è¡¨ç¤ºæŠ€æœ¯ï¼Œç”¨äºæ‰§è¡Œæ³•å¾‹æ£€ç´¢ä¸æ¨ç†ä»»åŠ¡ã€‚é€šè¿‡åˆ©ç”¨ Qwen-2ã€QwQ-32B å’Œ DeepSeek-V3 ç­‰æ¨¡å‹è¿›è¡Œæ–‡æœ¬æ‘˜è¦ã€ç›¸å…³æ€§è¯„åˆ†ä»¥åŠä¸Šä¸‹æ–‡é‡æ’åºï¼Œè¯¥æ–¹æ¡ˆæ˜¾è‘—æå‡äº†ç³»ç»Ÿå¤„ç†æ³•å¾‹æ–‡æœ¬çš„èƒ½åŠ›ã€‚åœ¨æ³•å¾‹åˆ¤ä¾‹è•´å«ä»»åŠ¡ (Task 2) ä¸­ï¼Œç ”ç©¶å›¢é˜Ÿé€šè¿‡ç»“åˆè¯æ³•-è¯­ä¹‰è¿‡æ»¤ä¸ä¸Šä¸‹æ–‡å¤§è¯­è¨€æ¨¡å‹åˆ†æçš„ä¸¤é˜¶æ®µæ£€ç´¢ç³»ç»Ÿè£è·ç¬¬ä¸€åï¼ŒF1 åˆ†æ•°è¾¾åˆ° 0.3195ã€‚æ­¤å¤–ï¼Œè¯¥å›¢é˜Ÿåœ¨æ³•å¾‹æ¡ˆä¾‹æ£€ç´¢ã€æ³•è§„æ£€ç´¢åŠæ³•å¾‹åˆ¤å†³é¢„æµ‹ç­‰å…¶ä»–å¤šé¡¹ä»»åŠ¡ä¸­ï¼Œåˆ©ç”¨é›†æˆç­–ç•¥å’ŒåŸºäºæç¤ºè¯çš„æ¨ç†æ–¹æ³•ä¹Ÿå±•ç°äº†ç¨³å¥çš„è¡¨ç°ã€‚ç ”ç©¶ç»“æœçªæ˜¾äº†å°†ä¼ ç»Ÿä¿¡æ¯æ£€ç´¢ (IR) æŠ€æœ¯ä¸ç°ä»£ç”Ÿæˆæ¨¡å‹ç›¸ç»“åˆçš„æ··åˆæ¨¡å‹æ½œåŠ›ï¼Œä¸ºæ³•å¾‹ä¿¡æ¯å¤„ç†é¢†åŸŸçš„æœªæ¥å‘å±•æä¾›äº†é‡è¦çš„å‚è€ƒä»·å€¼ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.08025v1",
      "published_date": "2025-09-09 12:05:52 UTC",
      "updated_date": "2025-09-09 12:05:52 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:29:37.039500+00:00"
    },
    {
      "arxiv_id": "2509.07633v1",
      "title": "Variational Quantum Circuits in Offline Contextual Bandit Problems",
      "title_zh": "å˜åˆ†é‡å­ç”µè·¯åœ¨ç¦»çº¿ä¸Šä¸‹æ–‡å¤šè‡‚è€è™æœºé—®é¢˜ä¸­çš„åº”ç”¨",
      "authors": [
        "Lukas Schulte",
        "Daniel Hein",
        "Steffen Udluft",
        "Thomas A. Runkler"
      ],
      "abstract": "This paper explores the application of variational quantum circuits (VQCs) for solving offline contextual bandit problems in industrial optimization tasks. Using the Industrial Benchmark (IB) environment, we evaluate the performance of quantum regression models against classical models. Our findings demonstrate that quantum models can effectively fit complex reward functions, identify optimal configurations via particle swarm optimization (PSO), and generalize well in noisy and sparse datasets. These results provide a proof of concept for utilizing VQCs in offline contextual bandit problems and highlight their potential in industrial optimization tasks.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº† Variational Quantum Circuits (VQCs) åœ¨è§£å†³å·¥ä¸šä¼˜åŒ–ä»»åŠ¡ä¸­çš„ Offline Contextual Bandit é—®é¢˜ä¸­çš„åº”ç”¨ã€‚ç ”ç©¶åˆ©ç”¨ Industrial Benchmark (IB) ç¯å¢ƒï¼Œå¯¹é‡å­å›å½’æ¨¡å‹ä¸ç»å…¸æ¨¡å‹è¿›è¡Œäº†å¯¹æ¯”è¯„ä¼°ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œé‡å­æ¨¡å‹èƒ½å¤Ÿæœ‰æ•ˆåœ°æ‹Ÿåˆå¤æ‚çš„å¥–åŠ±å‡½æ•°ï¼Œå¹¶é€šè¿‡ Particle Swarm Optimization (PSO) è¯†åˆ«å‡ºæœ€ä¼˜é…ç½®ã€‚æ­¤å¤–ï¼Œè¯¥æ¨¡å‹åœ¨å™ªå£°è¾ƒå¤§ä¸”æ•°æ®ç¨€ç–çš„æ•°æ®é›†ä¸­å±•ç°å‡ºäº†è‰¯å¥½çš„æ³›åŒ–èƒ½åŠ›ã€‚è¿™äº›ç»“æœä¸ºåœ¨ Offline Contextual Bandit é—®é¢˜ä¸­åˆ©ç”¨ VQCs æä¾›äº†æ¦‚å¿µéªŒè¯ï¼Œå¹¶çªæ˜¾äº†å…¶åœ¨å·¥ä¸šä¼˜åŒ–ä»»åŠ¡ä¸­çš„æ½œåŠ›ã€‚",
      "categories": [
        "quant-ph",
        "cs.AI"
      ],
      "primary_category": "quant-ph",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.07633v1",
      "published_date": "2025-09-09 12:00:33 UTC",
      "updated_date": "2025-09-09 12:00:33 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:29:42.335582+00:00"
    },
    {
      "arxiv_id": "2509.07617v1",
      "title": "Transferable Direct Prompt Injection via Activation-Guided MCMC Sampling",
      "title_zh": "åŸºäºæ¿€æ´»å¼•å¯¼ MCMC é‡‡æ ·çš„å¯è¿ç§»ç›´æ¥æç¤ºæ³¨å…¥",
      "authors": [
        "Minghui Li",
        "Hao Zhang",
        "Yechao Zhang",
        "Wei Wan",
        "Shengshan Hu",
        "pei Xiaobing",
        "Jing Wang"
      ],
      "abstract": "Direct Prompt Injection (DPI) attacks pose a critical security threat to Large Language Models (LLMs) due to their low barrier of execution and high potential damage. To address the impracticality of existing white-box/gray-box methods and the poor transferability of black-box methods, we propose an activations-guided prompt injection attack framework. We first construct an Energy-based Model (EBM) using activations from a surrogate model to evaluate the quality of adversarial prompts. Guided by the trained EBM, we employ the token-level Markov Chain Monte Carlo (MCMC) sampling to adaptively optimize adversarial prompts, thereby enabling gradient-free black-box attacks. Experimental results demonstrate our superior cross-model transferability, achieving 49.6% attack success rate (ASR) across five mainstream LLMs and 34.6% improvement over human-crafted prompts, and maintaining 36.6% ASR on unseen task scenarios. Interpretability analysis reveals a correlation between activations and attack effectiveness, highlighting the critical role of semantic patterns in transferable vulnerability exploitation.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§è¯­è¨€æ¨¡å‹(LLMs)é¢ä¸´çš„ç›´æ¥æç¤ºæ³¨å…¥(Direct Prompt Injection, DPI)æ”»å‡»å¨èƒï¼Œæå‡ºäº†ä¸€ç§åŸºäºæ¿€æ´»å¼•å¯¼çš„æ”»å‡»æ¡†æ¶ã€‚ä¸ºäº†è§£å†³ç°æœ‰é»‘ç›’æ–¹æ³•è¿ç§»æ€§å·®çš„é—®é¢˜ï¼Œç ”ç©¶è€…åˆ©ç”¨ä»£ç†æ¨¡å‹çš„æ¿€æ´»ä¿¡æ¯æ„å»ºäº†èƒ½é‡æ¨¡å‹(Energy-based Model, EBM)æ¥è¯„ä¼°å¯¹æŠ—æç¤ºçš„è´¨é‡ã€‚è¯¥æ¡†æ¶ç»“åˆä»¤ç‰Œçº§é©¬å°”å¯å¤«é“¾è’™ç‰¹å¡æ´›(MCMC)é‡‡æ ·æŠ€æœ¯è‡ªé€‚åº”åœ°ä¼˜åŒ–å¯¹æŠ—æç¤ºï¼Œä»è€Œå®ç°é«˜æ•ˆçš„æ— æ¢¯åº¦é»‘ç›’æ”»å‡»ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨äº”ç§ä¸»æµLLMsä¸Šå®ç°äº†49.6%çš„æ”»å‡»æˆåŠŸç‡(ASR)ï¼Œæ¯”äººå·¥è®¾è®¡çš„æç¤ºæé«˜äº†34.6%ï¼Œå¹¶å±•ç°å‡ºå“è¶Šçš„è·¨æ¨¡å‹è¿ç§»èƒ½åŠ›ã€‚å¯è§£é‡Šæ€§åˆ†æè¿›ä¸€æ­¥æ­ç¤ºäº†æ¿€æ´»çŠ¶æ€ä¸æ”»å‡»æ•ˆæœä¹‹é—´çš„å…³è”ï¼Œè¯æ˜äº†è¯­ä¹‰æ¨¡å¼åœ¨åˆ©ç”¨å¯è¿ç§»æ€§æ¼æ´ä¸­çš„å…³é”®ä½œç”¨ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted to EMNLP 2025",
      "pdf_url": "https://arxiv.org/pdf/2509.07617v1",
      "published_date": "2025-09-09 11:42:06 UTC",
      "updated_date": "2025-09-09 11:42:06 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:29:48.937125+00:00"
    },
    {
      "arxiv_id": "2509.07614v1",
      "title": "From Classical Data to Quantum Advantage -- Quantum Policy Evaluation on Quantum Hardware",
      "title_zh": "ä»ç»å…¸æ•°æ®åˆ°é‡å­ä¼˜åŠ¿ï¼šé‡å­ç¡¬ä»¶ä¸Šçš„é‡å­ç­–ç•¥è¯„ä¼°",
      "authors": [
        "Daniel Hein",
        "Simon Wiedemann",
        "Markus Baumann",
        "Patrik Felbinger",
        "Justin Klein",
        "Maximilian Schieder",
        "Jonas Stein",
        "DaniÃ«lle Schuman",
        "Thomas Cope",
        "Steffen Udluft"
      ],
      "abstract": "Quantum policy evaluation (QPE) is a reinforcement learning (RL) algorithm which is quadratically more efficient than an analogous classical Monte Carlo estimation. It makes use of a direct quantum mechanical realization of a finite Markov decision process, in which the agent and the environment are modeled by unitary operators and exchange states, actions, and rewards in superposition. Previously, the quantum environment has been implemented and parametrized manually for an illustrative benchmark using a quantum simulator. In this paper, we demonstrate how these environment parameters can be learned from a batch of classical observational data through quantum machine learning (QML) on quantum hardware. The learned quantum environment is then applied in QPE to also compute policy evaluations on quantum hardware. Our experiments reveal that, despite challenges such as noise and short coherence times, the integration of QML and QPE shows promising potential for achieving quantum advantage in RL.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº† Quantum Policy Evaluation (QPE)ï¼Œè¿™æ˜¯ä¸€ç§åœ¨ Reinforcement Learning (RL) ä¸­æ¯”ä¼ ç»Ÿ Monte Carlo ä¼°è®¡å…·æœ‰å¹³æ–¹çº§åŠ é€Ÿä¼˜åŠ¿çš„ç®—æ³•ã€‚QPE é€šè¿‡å°†æœ‰é™ Markov decision process (MDP) ç›´æ¥è¿›è¡Œé‡å­åŠ›å­¦å®ç°ï¼Œåˆ©ç”¨ Unitary operators åœ¨å åŠ æ€ä¸­äº¤æ¢çŠ¶æ€ã€åŠ¨ä½œå’Œå¥–åŠ±ã€‚é’ˆå¯¹ä»¥å¾€é‡å­ç¯å¢ƒå‚æ•°éœ€æ‰‹åŠ¨è®¾å®šä¸”ä¸»è¦ä¾èµ–æ¨¡æ‹Ÿå™¨çš„å±€é™ï¼Œæœ¬æ–‡æå‡ºåˆ©ç”¨ Quantum Machine Learning (QML) åœ¨é‡å­ç¡¬ä»¶ä¸Šä»ç»å…¸è§‚æµ‹æ•°æ®ä¸­å­¦ä¹ ç¯å¢ƒå‚æ•°ã€‚éšåï¼Œç ”ç©¶å°†å­¦ä¹ åˆ°çš„é‡å­ç¯å¢ƒåº”ç”¨äº QPEï¼Œå¹¶åœ¨çœŸå®é‡å­ç¡¬ä»¶ä¸ŠæˆåŠŸæ‰§è¡Œäº†ç­–ç•¥è¯„ä¼°ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œå°½ç®¡ç›®å‰é¢ä¸´å™ªå£°å’ŒçŸ­ç›¸å¹²æ—¶é—´ç­‰ç¡¬ä»¶æŒ‘æˆ˜ï¼ŒQML ä¸ QPE çš„ç»“åˆä»ä¸ºåœ¨å¼ºåŒ–å­¦ä¹ ä»»åŠ¡ä¸­å®ç° Quantum Advantage æä¾›äº†æå…·å‰æ™¯çš„è·¯å¾„ã€‚",
      "categories": [
        "quant-ph",
        "cs.AI"
      ],
      "primary_category": "quant-ph",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.07614v1",
      "published_date": "2025-09-09 11:36:25 UTC",
      "updated_date": "2025-09-09 11:36:25 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:29:51.340326+00:00"
    },
    {
      "arxiv_id": "2509.07605v1",
      "title": "Beyond Rebalancing: Benchmarking Binary Classifiers Under Class Imbalance Without Rebalancing Techniques",
      "title_zh": "è¶…è¶Šé‡å¹³è¡¡ï¼šæ— é‡å¹³è¡¡æŠ€æœ¯ä¸‹çš„ç±»åˆ«ä¸å¹³è¡¡äºŒå…ƒåˆ†ç±»å™¨åŸºå‡†æµ‹è¯•",
      "authors": [
        "Ali Nawaz",
        "Amir Ahmad",
        "Shehroz S. Khan"
      ],
      "abstract": "Class imbalance poses a significant challenge to supervised classification, particularly in critical domains like medical diagnostics and anomaly detection where minority class instances are rare. While numerous studies have explored rebalancing techniques to address this issue, less attention has been given to evaluating the performance of binary classifiers under imbalance when no such techniques are applied. Therefore, the goal of this study is to assess the performance of binary classifiers \"as-is\", without performing any explicit rebalancing. Specifically, we systematically evaluate the robustness of a diverse set of binary classifiers across both real-world and synthetic datasets, under progressively reduced minority class sizes, using one-shot and few-shot scenarios as baselines. Our approach also explores varying data complexities through synthetic decision boundary generation to simulate real-world conditions. In addition to standard classifiers, we include experiments using undersampling, oversampling strategies, and one-class classification (OCC) methods to examine their behavior under severe imbalance. The results confirm that classification becomes more difficult as data complexity increases and the minority class size decreases. While traditional classifiers deteriorate under extreme imbalance, advanced models like TabPFN and boosting-based ensembles retain relatively higher performance and better generalization compared to traditional classifiers. Visual interpretability and evaluation metrics further validate these findings. Our work offers valuable guidance on model selection for imbalanced learning, providing insights into classifier robustness without dependence on explicit rebalancing techniques.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹åŒ»ç–—è¯Šæ–­å’Œå¼‚å¸¸æ£€æµ‹ç­‰å…³é”®é¢†åŸŸçš„ç±»åˆ«ä¸å¹³è¡¡ (Class imbalance) é—®é¢˜ï¼Œåœ¨ä¸ä½¿ç”¨ä»»ä½•é‡å¹³è¡¡ (Rebalancing) æŠ€æœ¯çš„å‰æä¸‹ï¼Œç³»ç»Ÿæ€§åœ°è¯„ä¼°äº†äºŒå…ƒåˆ†ç±»å™¨ (Binary Classifiers) çš„åŸå§‹æ€§èƒ½ã€‚ç ”ç©¶é€šè¿‡åœ¨çœŸå®ä¸–ç•Œå’Œåˆæˆæ•°æ®é›†ä¸Šé€æ­¥ç¼©å‡å°‘æ•°ç±»è§„æ¨¡ï¼Œæ¢è®¨äº†ä¸åŒæ•°æ®å¤æ‚åº¦å’Œå†³ç­–è¾¹ç•Œ (Decision Boundary) å¯¹æ¨¡å‹é²æ£’æ€§çš„å½±å“ï¼Œå¹¶ä»¥å•æ ·æœ¬ (One-shot) å’Œå°‘æ ·æœ¬ (Few-shot) åœºæ™¯ä½œä¸ºåŸºå‡†ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œéšç€æ•°æ®å¤æ‚åº¦å¢åŠ å’Œå°‘æ•°ç±»æ ·æœ¬å‡å°‘ï¼Œä¼ ç»Ÿåˆ†ç±»å™¨çš„æ€§èƒ½ä¼šä¸¥é‡æ¶åŒ–ã€‚ç›¸æ¯”ä¹‹ä¸‹ï¼ŒTabPFN å’ŒåŸºäºæå‡æ³•çš„é›†æˆæ¨¡å‹ (Boosting-based ensembles) åœ¨æç«¯ä¸å¹³è¡¡ä¸‹è¡¨ç°å‡ºæ›´å¼ºçš„æ³›åŒ–èƒ½åŠ›å’Œé²æ£’æ€§ã€‚è¯¥å·¥ä½œé€šè¿‡å¯è§†åŒ–è§£é‡Šå’Œè¯„ä¼°æŒ‡æ ‡éªŒè¯ï¼Œä¸ºä¸å¹³è¡¡å­¦ä¹ ä¸­çš„æ¨¡å‹é€‰æ‹©æä¾›äº†é‡è¦æŒ‡å¯¼ï¼Œæ­ç¤ºäº†åˆ†ç±»å™¨åœ¨ä¸ä¾èµ–æ˜¾å¼é‡å¹³è¡¡æŠ€æœ¯æ—¶çš„è¡¨ç°è§„å¾‹ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.IT"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.07605v1",
      "published_date": "2025-09-09 11:28:34 UTC",
      "updated_date": "2025-09-09 11:28:34 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:29:54.236682+00:00"
    },
    {
      "arxiv_id": "2509.19312v2",
      "title": "E2E Learning Massive MIMO for Multimodal Semantic Non-Orthogonal Transmission and Fusion",
      "title_zh": "é¢å‘å¤šæ¨¡æ€è¯­ä¹‰éæ­£äº¤ä¼ è¾“ä¸èåˆçš„å¤§è§„æ¨¡MIMOç«¯åˆ°ç«¯å­¦ä¹ ",
      "authors": [
        "Minghui Wu",
        "Zhen Gao"
      ],
      "abstract": "This paper investigates multimodal semantic non-orthogonal transmission and fusion in hybrid analog-digital massive multiple-input multiple-output (MIMO). A Transformer-based cross-modal source-channel semantic-aware network (CSC-SA-Net) framework is conceived, where channel state information (CSI) reference signal (RS), feedback, analog-beamforming/combining, and baseband semantic processing are data-driven end-to-end (E2E) optimized at the base station (BS) and user equipments (UEs). CSC-SA-Net comprises five sub-networks: BS-side CSI-RS network (BS-CSIRS-Net), UE-side channel semantic-aware network (UE-CSANet), BS-CSANet, UE-side multimodal semantic fusion network (UE-MSFNet), and BS-MSFNet. Specifically, we firstly E2E train BS-CSIRS-Net, UE-CSANet, and BS-CSANet to jointly design CSI-RS, feedback, analog-beamforming/combining with maximum {\\emph{physical-layer's}} spectral-efficiency. Meanwhile, we E2E train UE-MSFNet and BS-MSFNet for optimizing {\\emph{application-layer's}} source semantic downstream tasks. On these pre-trained models, we further integrate application-layer semantic processing with physical-layer tasks to E2E train five subnetworks. Extensive simulations show that the proposed CSC-SA-Net outperforms traditional separated designs, revealing the advantage of cross-modal channel-source semantic fusion.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†æ··åˆæ¨¡æ•°å¤§è§„æ¨¡å¤šè¾“å…¥å¤šè¾“å‡º (Massive MIMO) ç³»ç»Ÿä¸­çš„å¤šæ¨¡æ€è¯­ä¹‰éæ­£äº¤ä¼ è¾“ä¸èåˆé—®é¢˜ã€‚ç ”ç©¶æå‡ºäº†ä¸€ç§åŸºäº Transformer çš„è·¨æ¨¡æ€ä¿¡æºä¿¡é“è¯­ä¹‰æ„ŸçŸ¥ç½‘ç»œ (CSC-SA-Net) æ¡†æ¶ï¼Œæ—¨åœ¨å®ç°åŸºç«™ (BS) ä¸ç”¨æˆ·è®¾å¤‡ (UE) é—´ä¿¡é“çŠ¶æ€ä¿¡æ¯ (CSI) å‚è€ƒä¿¡å·ã€åé¦ˆã€æ¨¡æ‹Ÿæ³¢æŸèµ‹å½¢åŠåŸºå¸¦è¯­ä¹‰å¤„ç†çš„ç«¯åˆ°ç«¯ (E2E) æ•°æ®é©±åŠ¨ä¼˜åŒ–ã€‚è¯¥ç³»ç»Ÿç”±äº”ä¸ªä¸“é—¨çš„å­ç½‘ç»œç»„æˆï¼Œé€šè¿‡åˆ†é˜¶æ®µè®­ç»ƒç­–ç•¥ï¼Œé¦–å…ˆåˆ†åˆ«ä¼˜åŒ–ç‰©ç†å±‚é¢‘è°±æ•ˆç‡å’Œåº”ç”¨å±‚è¯­ä¹‰ä»»åŠ¡ï¼Œéšåè¿›è¡Œè·¨å±‚æ•´åˆçš„è”åˆè®­ç»ƒã€‚ä»¿çœŸç»“æœè¡¨æ˜ï¼Œæ‰€æå‡ºçš„ CSC-SA-Net åœ¨æ€§èƒ½ä¸Šæ˜¾è‘—ä¼˜äºä¼ ç»Ÿçš„æ¨¡å—åŒ–åˆ†ç¦»è®¾è®¡ã€‚è¯¥ç ”ç©¶æˆæœæœ‰åŠ›åœ°è¯æ˜äº†è·¨æ¨¡æ€ä¿¡é“-ä¿¡æºè¯­ä¹‰èåˆåœ¨æå‡å¤æ‚é€šä¿¡ç³»ç»Ÿæ•ˆç‡æ–¹é¢çš„æ˜¾è‘—ä¼˜åŠ¿ã€‚",
      "categories": [
        "eess.SP",
        "cs.AI",
        "cs.IT",
        "cs.LG"
      ],
      "primary_category": "eess.SP",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.19312v2",
      "published_date": "2025-09-09 11:25:51 UTC",
      "updated_date": "2025-12-12 09:23:28 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:29:55.221231+00:00"
    },
    {
      "arxiv_id": "2509.07603v1",
      "title": "Transformer-Based Approach to Optimal Sensor Placement for Structural Health Monitoring of Probe Cards",
      "title_zh": "åŸºäº Transformer çš„æ¢é’ˆå¡ç»“æ„å¥åº·ç›‘æµ‹ä¼ æ„Ÿå™¨ä¼˜åŒ–å¸ƒç½®æ–¹æ³•",
      "authors": [
        "Mehdi Bejani",
        "Marco Mauri",
        "Daniele Acconcia",
        "Simone Todaro",
        "Stefano Mariani"
      ],
      "abstract": "This paper presents an innovative Transformer-based deep learning strategy for optimizing the placement of sensors aiming at structural health monitoring of semiconductor probe cards. Failures in probe cards, including substrate cracks and loosened screws, would critically affect semiconductor manufacturing yield and reliability. Some failure modes could be detected by equipping a probe card with adequate sensors. Frequency response functions from simulated failure scenarios are adopted within a finite element model of a probe card. A comprehensive dataset, enriched by physics-informed scenario expansion and physics-aware statistical data augmentation, is exploited to train a hybrid Convolutional Neural Network and Transformer model. The model achieves high accuracy (99.83%) in classifying the probe card health states (baseline, loose screw, crack) and an excellent crack detection recall (99.73%). Model robustness is confirmed through a rigorous framework of 3 repetitions of 10-fold stratified cross-validation. The attention mechanism also pinpoints critical sensor locations: an analysis of the attention weights offers actionable insights for designing efficient, cost-effective monitoring systems by optimizing sensor configurations. This research highlights the capability of attention-based deep learning to advance proactive maintenance, enhancing operational reliability and yield in semiconductor manufacturing.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§åŸºäº Transformer çš„åˆ›æ–°æ·±åº¦å­¦ä¹ ç­–ç•¥ï¼Œæ—¨åœ¨ä¼˜åŒ–åŠå¯¼ä½“ Probe Cards ç»“æ„å¥åº·ç›‘æµ‹ä¸­çš„ä¼ æ„Ÿå™¨å¸ƒç½®ã€‚é’ˆå¯¹åŸºæ¿è£‚çº¹å’Œèºé’‰æ¾åŠ¨ç­‰å…³é”®æ•…éšœï¼Œç ”ç©¶åˆ©ç”¨æœ‰é™å…ƒæ¨¡å‹ç”Ÿæˆçš„ Frequency response functions æ¨¡æ‹Ÿæ•…éšœåœºæ™¯ï¼Œå¹¶ç»“åˆç‰©ç†ä¿¡æ¯åœºæ™¯æ‰©å±•å’Œæ•°æ®å¢å¼ºæŠ€æœ¯æ„å»ºäº†è®­ç»ƒæ•°æ®é›†ã€‚æ ¸å¿ƒæ¨¡å‹é‡‡ç”¨æ··åˆå¼ Convolutional Neural Network ä¸ Transformer æ¶æ„ï¼Œåœ¨åˆ†ç±» Baselineã€èºé’‰æ¾åŠ¨å’Œè£‚çº¹çŠ¶æ€æ—¶è¾¾åˆ°äº† 99.83% çš„å‡†ç¡®ç‡ï¼Œä¸”è£‚çº¹æ£€æµ‹å¬å›ç‡é«˜è¾¾ 99.73%ã€‚é€šè¿‡å¯¹ Attention weights çš„åˆ†æï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿç²¾å‡†è¯†åˆ«å…³é”®ä¼ æ„Ÿå™¨ä½ç½®ï¼Œä¸ºè®¾è®¡ä½æˆæœ¬ä¸”é«˜æ•ˆçš„ç›‘æ§ç³»ç»Ÿæä¾›äº†ç§‘å­¦ä¾æ®ã€‚è¿™é¡¹ç ”ç©¶æ˜¾è‘—æå‡äº†åŠå¯¼ä½“åˆ¶é€ ä¸­çš„ä¸»åŠ¨ç»´æŠ¤èƒ½åŠ›ï¼Œå¯¹äºä¿éšœç”Ÿäº§å¯é æ€§å’Œè‰¯ç‡å…·æœ‰é‡è¦æ„ä¹‰ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "22 pages, 11 figures",
      "pdf_url": "https://arxiv.org/pdf/2509.07603v1",
      "published_date": "2025-09-09 11:21:49 UTC",
      "updated_date": "2025-09-09 11:21:49 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:29:54.997198+00:00"
    },
    {
      "arxiv_id": "2509.07593v1",
      "title": "Can SSD-Mamba2 Unlock Reinforcement Learning for End-to-End Motion Control?",
      "title_zh": "SSD-Mamba2 èƒ½å¦å¼€å¯ç«¯åˆ°ç«¯è¿åŠ¨æ§åˆ¶çš„å¼ºåŒ–å­¦ä¹ ï¼Ÿ",
      "authors": [
        "Gavin Tao",
        "Yinuo Wang",
        "Jinzhao Zhou"
      ],
      "abstract": "End-to-end reinforcement learning for motion control promises unified perception-action policies that scale across embodiments and tasks, yet most deployed controllers are either blind (proprioception-only) or rely on fusion backbones with unfavorable compute-memory trade-offs. Recurrent controllers struggle with long-horizon credit assignment, and Transformer-based fusion incurs quadratic cost in token length, limiting temporal and spatial context. We present a vision-driven cross-modal RL framework built on SSD-Mamba2, a selective state-space backbone that applies state-space duality (SSD) to enable both recurrent and convolutional scanning with hardware-aware streaming and near-linear scaling. Proprioceptive states and exteroceptive observations (e.g., depth tokens) are encoded into compact tokens and fused by stacked SSD-Mamba2 layers. The selective state-space updates retain long-range dependencies with markedly lower latency and memory use than quadratic self-attention, enabling longer look-ahead, higher token resolution, and stable training under limited compute. Policies are trained end-to-end under curricula that randomize terrain and appearance and progressively increase scene complexity. A compact, state-centric reward balances task progress, energy efficiency, and safety. Across diverse motion-control scenarios, our approach consistently surpasses strong state-of-the-art baselines in return, safety (collisions and falls), and sample efficiency, while converging faster at the same compute budget. These results suggest that SSD-Mamba2 provides a practical fusion backbone for scalable, foresightful, and efficient end-to-end motion control.",
      "tldr_zh": "æœ¬ç ”ç©¶æå‡ºäº†ä¸€ç§åŸºäº SSD-Mamba2 çš„è§†è§‰é©±åŠ¨è·¨æ¨¡æ€å¼ºåŒ–å­¦ä¹ (Reinforcement Learning)æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³ç«¯åˆ°ç«¯è¿åŠ¨æ§åˆ¶ä¸­ç°æœ‰æ¶æ„åœ¨è®¡ç®—æ•ˆç‡ä¸é•¿ç¨‹ä¾èµ–å¤„ç†ä¹‹é—´çš„æƒè¡¡éš¾é¢˜ã€‚è¯¥æ¡†æ¶é‡‡ç”¨äº†é€‰æ‹©æ€§çŠ¶æ€ç©ºé—´(Selective State-Space)ä¸»å¹²ç½‘ç»œï¼Œé€šè¿‡çŠ¶æ€ç©ºé—´å¯¹å¶æ€§(State-Space Duality, SSD)å®ç°äº†å…·å¤‡ç¡¬ä»¶æ„ŸçŸ¥çš„æµå¼å¤„ç†å’Œè¿‘çº¿æ€§æ‰©å±•èƒ½åŠ›ã€‚å®ƒå°†æœ¬ä½“æ„ŸçŸ¥çŠ¶æ€ä¸å¤–éƒ¨è§†è§‰è§‚æµ‹ç¼–ç ä¸ºç´§å‡‘ Tokenï¼Œå¹¶åˆ©ç”¨å¤šå±‚ SSD-Mamba2 è¿›è¡Œç‰¹å¾èåˆï¼Œåœ¨ä¿æŒé•¿ç¨‹ä¾èµ–çš„åŒæ—¶æ˜¾è‘—é™ä½äº†å»¶è¿Ÿå’Œæ˜¾å­˜å ç”¨ã€‚ç­–ç•¥é€šè¿‡åŒ…å«éšæœºåœ°å½¢å’Œå¤–è§‚çš„è¯¾ç¨‹å­¦ä¹ è¿›è¡Œç«¯åˆ°ç«¯è®­ç»ƒï¼Œå¹¶ç»“åˆä»¥çŠ¶æ€ä¸ºä¸­å¿ƒçš„å¥–åŠ±å‡½æ•°æ¥å¹³è¡¡ä»»åŠ¡è¿›åº¦ã€èƒ½æºæ•ˆç‡ä¸å®‰å…¨æ€§ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨å¤šç§è¿åŠ¨æ§åˆ¶åœºæ™¯ä¸‹çš„å›æŠ¥ç‡ã€å®‰å…¨æ€§å’Œæ ·æœ¬æ•ˆç‡æ–¹é¢å‡ä¼˜äºç°æœ‰çš„å…ˆè¿›åŸºçº¿æ¨¡å‹ã€‚SSD-Mamba2 å±•ç°å‡ºçš„å¿«é€Ÿæ”¶æ•›é€Ÿåº¦å’Œæ›´å¼ºçš„é¢„è§æ€§ï¼Œä¸ºå¼€å‘å¯æ‰©å±•ä¸”é«˜æ•ˆçš„ç«¯åˆ°ç«¯æœºå™¨äººè¿åŠ¨æ§åˆ¶ç³»ç»Ÿæä¾›äº†å®ç”¨çš„æŠ€æœ¯æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV",
        "eess.IV",
        "eess.SY"
      ],
      "primary_category": "cs.RO",
      "comment": "4 figures and 6 tables",
      "pdf_url": "https://arxiv.org/pdf/2509.07593v1",
      "published_date": "2025-09-09 11:05:44 UTC",
      "updated_date": "2025-09-09 11:05:44 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:30:01.734689+00:00"
    },
    {
      "arxiv_id": "2509.07588v1",
      "title": "BALI: Enhancing Biomedical Language Representations through Knowledge Graph and Language Model Alignment",
      "title_zh": "BALIï¼šåŸºäºçŸ¥è¯†å›¾è°±ä¸è¯­è¨€æ¨¡å‹å¯¹é½çš„ç”Ÿç‰©åŒ»å­¦è¯­è¨€è¡¨ç¤ºå¢å¼º",
      "authors": [
        "Andrey Sakhovskiy",
        "Elena Tutubalina"
      ],
      "abstract": "In recent years, there has been substantial progress in using pretrained Language Models (LMs) on a range of tasks aimed at improving the understanding of biomedical texts. Nonetheless, existing biomedical LLMs show limited comprehension of complex, domain-specific concept structures and the factual information encoded in biomedical Knowledge Graphs (KGs). In this work, we propose BALI (Biomedical Knowledge Graph and Language Model Alignment), a novel joint LM and KG pre-training method that augments an LM with external knowledge by the simultaneous learning of a dedicated KG encoder and aligning the representations of both the LM and the graph. For a given textual sequence, we link biomedical concept mentions to the Unified Medical Language System (UMLS) KG and utilize local KG subgraphs as cross-modal positive samples for these mentions. Our empirical findings indicate that implementing our method on several leading biomedical LMs, such as PubMedBERT and BioLinkBERT, improves their performance on a range of language understanding tasks and the quality of entity representations, even with minimal pre-training on a small alignment dataset sourced from PubMed scientific abstracts.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†BALIï¼ˆBiomedical Knowledge Graph and Language Model Alignmentï¼‰ï¼Œè¿™æ˜¯ä¸€ç§é€šè¿‡çŸ¥è¯†å›¾è°±ä¸è¯­è¨€æ¨¡å‹å¯¹é½æ¥å¢å¼ºç”Ÿç‰©åŒ»å­¦è¯­è¨€è¡¨ç¤ºçš„æ–°å‹è”åˆé¢„è®­ç»ƒæ–¹æ³•ã€‚é’ˆå¯¹ç°æœ‰ç”Ÿç‰©åŒ»å­¦Language Modelsï¼ˆLMsï¼‰å¯¹é¢†åŸŸç‰¹å®šæ¦‚å¿µç»“æ„å’ŒKnowledge Graphsï¼ˆKGsï¼‰äº‹å®ä¿¡æ¯ç†è§£ä¸è¶³çš„é—®é¢˜ï¼ŒBALIé€šè¿‡åŒæ—¶å­¦ä¹ ä¸“ç”¨çš„KGç¼–ç å™¨å¹¶å¯¹é½ä¸¤ç§æ¨¡æ€çš„è¡¨ç¤ºæ¥å¼•å…¥å¤–éƒ¨çŸ¥è¯†ã€‚è¯¥æ–¹æ³•å°†æ–‡æœ¬ä¸­çš„æ¦‚å¿µæåŠé“¾æ¥è‡³Unified Medical Language Systemï¼ˆUMLSï¼‰ï¼Œå¹¶åˆ©ç”¨å±€éƒ¨çŸ¥è¯†å›¾è°±å­å›¾ä½œä¸ºè·¨æ¨¡æ€æ­£æ ·æœ¬è¿›è¡Œå­¦ä¹ ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œåœ¨PubMedBERTå’ŒBioLinkBERTç­‰é¢†å…ˆæ¨¡å‹ä¸Šåº”ç”¨è¯¥æ–¹æ³•ï¼Œèƒ½æœ‰æ•ˆæå‡å¤šé¡¹è¯­è¨€ç†è§£ä»»åŠ¡çš„æ€§èƒ½åŠå®ä½“è¡¨ç¤ºè´¨é‡ã€‚å³ä¾¿ä»…åœ¨æ¥è‡ªPubMedæ‘˜è¦çš„å°è§„æ¨¡æ•°æ®é›†ä¸Šè¿›è¡Œæç®€çš„é¢„è®­ç»ƒï¼Œè¯¥æ–¹æ³•ä¾ç„¶å±•ç°äº†æ˜¾è‘—çš„æ”¹è¿›æ•ˆæœã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "9 pages, 1 figure, published in \"The 48th International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR 2025)\"",
      "pdf_url": "https://arxiv.org/pdf/2509.07588v1",
      "published_date": "2025-09-09 10:59:47 UTC",
      "updated_date": "2025-09-09 10:59:47 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:30:13.534849+00:00"
    },
    {
      "arxiv_id": "2509.07581v1",
      "title": "Attention Maps in 3D Shape Classification for Dental Stage Estimation with Class Node Graph Attention Networks",
      "title_zh": "åŸºäºç±»åˆ«èŠ‚ç‚¹å›¾æ³¨æ„åŠ›ç½‘ç»œçš„ä¸‰ç»´å½¢çŠ¶åˆ†ç±»æ³¨æ„åŠ›å›¾åœ¨ç‰™å‘è‚²é˜¶æ®µè¯„ä¼°ä¸­çš„åº”ç”¨",
      "authors": [
        "Barkin Buyukcakir",
        "Rocharles Cavalcante Fontenele",
        "Reinhilde Jacobs",
        "Jannick De Tobel",
        "Patrick Thevissen",
        "Dirk Vandermeulen",
        "Peter Claes"
      ],
      "abstract": "Deep learning offers a promising avenue for automating many recognition tasks in fields such as medicine and forensics. However, the black-box nature of these models hinders their adoption in high-stakes applications where trust and accountability are required. For 3D shape recognition tasks in particular, this paper introduces the Class Node Graph Attention Network (CGAT) architecture to address this need. Applied to 3D meshes of third molars derived from CBCT images, for Demirjian stage allocation, CGAT utilizes graph attention convolutions and an inherent attention mechanism, visualized via attention rollout, to explain its decision-making process. We evaluated the local mean curvature and distance to centroid node features, both individually and in combination, as well as model depth, finding that models incorporating directed edges to a global CLS node produced more intuitive attention maps, while also yielding desirable classification performance. We analyzed the attention-based explanations of the models, and their predictive performances to propose optimal settings for the CGAT. The combination of local mean curvature and distance to centroid as node features yielded a slight performance increase with 0.76 weighted F1 score, and more comprehensive attention visualizations. The CGAT architecture's ability to generate human-understandable attention maps can enhance trust and facilitate expert validation of model decisions. While demonstrated on dental data, CGAT is broadly applicable to graph-based classification and regression tasks, promoting wider adoption of transparent and competitive deep learning models in high-stakes environments.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹åŒ»ç–—ä¸æ³•åŒ»å­¦ç­‰é«˜é£é™©é¢†åŸŸæ·±åº¦å­¦ä¹ æ¨¡å‹çš„é»‘ç®±é—®é¢˜ï¼Œæå‡ºäº†Class Node Graph Attention Network (CGAT) æ¶æ„ï¼Œç”¨äºè‡ªåŠ¨åŒ–è¯„ä¼°åŸºäº CBCT å›¾åƒçš„ç¬¬ä¸‰ç£¨ç‰™ 3D å½¢çŠ¶å‘è‚²é˜¶æ®µã€‚CGAT åˆ©ç”¨å›¾æ³¨æ„åŠ›å·ç§¯ (graph attention convolutions) å’Œå†…ç½®çš„æ³¨æ„åŠ›æœºåˆ¶ï¼Œç»“åˆæ³¨æ„åŠ›å±•å¼€ (attention rollout) æŠ€æœ¯ï¼Œå®ç°äº†æ¨¡å‹å†³ç­–è¿‡ç¨‹çš„å¯è§†åŒ–ä¸å¯è§£é‡Šæ€§ã€‚ç ”ç©¶å‘ç°ï¼Œé€šè¿‡åœ¨å›¾ä¸­å¼•å…¥æŒ‡å‘å…¨å±€ CLS èŠ‚ç‚¹çš„æœ‰å‘è¾¹ï¼Œå¹¶ç»“åˆå±€éƒ¨å¹³å‡æ›²ç‡ (local mean curvature) ä¸åˆ°è´¨å¿ƒçš„è·ç¦» (distance to centroid) ä½œä¸ºèŠ‚ç‚¹ç‰¹å¾ï¼Œæ¨¡å‹èƒ½å¤Ÿç”Ÿæˆæ›´ç¬¦åˆç›´è§‰çš„æ³¨æ„åŠ›å›¾ (attention maps)ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥é…ç½®åœ¨ Demirjian é˜¶æ®µåˆ†é…ä»»åŠ¡ä¸­å–å¾—äº† 0.76 çš„åŠ æƒ F1 åˆ†æ•°ï¼Œå…¼é¡¾äº†åˆ†ç±»æ€§èƒ½ä¸è§£é‡Šæ·±åº¦ã€‚CGAT æ¶æ„ä¸ä»…åœ¨ç‰™ç§‘é¢†åŸŸè¡¨ç°å‡ºè‰²ï¼Œå…¶å¢å¼ºä¿¡ä»»å’Œé€æ˜åº¦çš„ç‰¹æ€§ä½¿å…¶èƒ½å¹¿æ³›åº”ç”¨äºå„ç±»åŸºäºå›¾çš„åˆ†ç±»å’Œå›å½’ä»»åŠ¡ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "25 pages, 8 figures, 2nd International Conference on Explainable AI for Neural or Symbolic Methods",
      "pdf_url": "https://arxiv.org/pdf/2509.07581v1",
      "published_date": "2025-09-09 10:44:25 UTC",
      "updated_date": "2025-09-09 10:44:25 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:30:29.745324+00:00"
    },
    {
      "arxiv_id": "2509.07577v2",
      "title": "Towards explainable decision support using hybrid neural models for logistic terminal automation",
      "title_zh": "é¢å‘ç‰©æµç»ˆç«¯è‡ªåŠ¨åŒ–çš„æ··åˆç¥ç»æ¨¡å‹å¯è§£é‡Šå†³ç­–æ”¯æŒç ”ç©¶",
      "authors": [
        "Riccardo D'Elia",
        "Alberto Termine",
        "Francesco Flammini"
      ],
      "abstract": "The integration of Deep Learning (DL) in System Dynamics (SD) modeling for transportation logistics offers significant advantages in scalability and predictive accuracy. However, these gains are often offset by the loss of explainability and causal reliability $-$ key requirements in critical decision-making systems. This paper presents a novel framework for interpretable-by-design neural system dynamics modeling that synergizes DL with techniques from Concept-Based Interpretability, Mechanistic Interpretability, and Causal Machine Learning. The proposed hybrid approach enables the construction of neural network models that operate on semantically meaningful and actionable variables, while retaining the causal grounding and transparency typical of traditional SD models. The framework is conceived to be applied to real-world case-studies from the EU-funded project AutoMoTIF, focusing on data-driven decision support, automation, and optimization of multimodal logistic terminals. We aim at showing how neuro-symbolic methods can bridge the gap between black-box predictive models and the need for critical decision support in complex dynamical environments within cyber-physical systems enabled by the industrial Internet-of-Things.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹è¿è¾“ç‰©æµé¢†åŸŸä¸­ç³»ç»ŸåŠ¨åŠ›å­¦ (System Dynamics) å»ºæ¨¡æ•´åˆæ·±åº¦å­¦ä¹  (Deep Learning) æ—¶é¢ä¸´çš„å¯è§£é‡Šæ€§ä¸å› æœå¯é æ€§ç¼ºå¤±é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§å…¨æ–°çš„â€œè®¾è®¡å³è§£é‡Šâ€ (interpretable-by-design) çš„æ··åˆç¥ç»ç³»ç»ŸåŠ¨åŠ›å­¦å»ºæ¨¡æ¡†æ¶ã€‚è¯¥æ¡†æ¶é€šè¿‡ååŒæ·±åº¦å­¦ä¹ ä¸æ¦‚å¿µè§£é‡Šæ€§ (Concept-Based Interpretability)ã€æœºæ¢°è§£é‡Šæ€§ (Mechanistic Interpretability) åŠå› æœæœºå™¨å­¦ä¹  (Causal Machine Learning) æŠ€æœ¯ï¼Œæ„å»ºå‡ºèƒ½å¤Ÿå¤„ç†è¯­ä¹‰åŒ–ä¸”å…·è¡ŒåŠ¨åŠ›å˜é‡çš„ç¥ç»ç½‘ç»œæ¨¡å‹ã€‚è¿™ç§æ–¹æ³•åœ¨æå‡é¢„æµ‹å‡†ç¡®æ€§çš„åŒæ—¶ï¼Œæœ‰æ•ˆåœ°ä¿ç•™äº†ä¼ ç»Ÿç³»ç»ŸåŠ¨åŠ›å­¦æ¨¡å‹çš„å› æœåŸºç¡€ä¸é€æ˜åº¦ã€‚è¯¥ç ”ç©¶æ¡†æ¶æ—¨åœ¨åº”ç”¨äºæ¬§ç›Ÿ AutoMoTIF é¡¹ç›®ï¼Œé‡ç‚¹å…³æ³¨å¤šæ¨¡æ€ç‰©æµç»ˆç«¯çš„æ•°æ®é©±åŠ¨å†³ç­–æ”¯æŒã€è‡ªåŠ¨åŒ–ä¸ä¼˜åŒ–ã€‚é€šè¿‡å¼•å…¥ç¥ç»ç¬¦å· (neuro-symbolic) æ–¹æ³•ï¼Œè¯¥ç ”ç©¶æˆåŠŸå±•ç¤ºäº†å¦‚ä½•åœ¨å¤æ‚ä¿¡æ¯ç‰©ç†ç³»ç»Ÿ (Cyber-Physical Systems) å’Œå·¥ä¸šç‰©è”ç½‘ (Industrial Internet-of-Things) ç¯å¢ƒä¸‹ï¼Œå¼¥åˆé»‘ç›’é¢„æµ‹æ¨¡å‹ä¸å…³é”®å†³ç­–æ”¯æŒéœ€æ±‚ä¹‹é—´çš„å·®è·ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.07577v2",
      "published_date": "2025-09-09 10:41:08 UTC",
      "updated_date": "2025-09-10 08:04:57 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:30:36.342155+00:00"
    },
    {
      "arxiv_id": "2509.07571v2",
      "title": "Towards Generalized Routing: Model and Agent Orchestration for Adaptive and Efficient Inference",
      "title_zh": "è¿ˆå‘é€šç”¨è·¯ç”±ï¼šé¢å‘è‡ªé€‚åº”é«˜æ•ˆæ¨ç†çš„æ¨¡å‹ä¸æ™ºèƒ½ä½“ç¼–æ’",
      "authors": [
        "Xiyu Guo",
        "Shan Wang",
        "Chunfang Ji",
        "Xuefeng Zhao",
        "Wenhao Xi",
        "Yaoyao Liu",
        "Qinglan Li",
        "Chao Deng",
        "Junlan Feng"
      ],
      "abstract": "The rapid advancement of large language models (LLMs) and domain-specific AI agents has greatly expanded the ecosystem of AI-powered services. User queries, however, are highly diverse and often span multiple domains and task types, resulting in a complex and heterogeneous landscape. This diversity presents a fundamental routing challenge: how to accurately direct each query to an appropriate execution unit while optimizing both performance and efficiency. To address this, we propose MoMA (Mixture of Models and Agents), a generalized routing framework that integrates both LLM and agent-based routing. Built upon a deep understanding of model and agent capabilities, MoMA effectively handles diverse queries through precise intent recognition and adaptive routing strategies, achieving an optimal balance between efficiency and cost. Specifically, we construct a detailed training dataset to profile the capabilities of various LLMs under different routing model structures, identifying the most suitable tasks for each LLM. During inference, queries are dynamically routed to the LLM with the best cost-performance efficiency. We also introduce an efficient agent selection strategy based on a context-aware state machine and dynamic masking. Experimental results demonstrate that the MoMA router offers superior cost-efficiency and scalability compared to existing approaches.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† MoMA (Mixture of Models and Agents)ï¼Œè¿™æ˜¯ä¸€ä¸ªæ—¨åœ¨åº”å¯¹é«˜åº¦å¤šæ ·åŒ–ç”¨æˆ·è¯·æ±‚çš„å¹¿ä¹‰è·¯ç”± (Generalized Routing) æ¡†æ¶ï¼Œé€šè¿‡åè°ƒå¤§è¯­è¨€æ¨¡å‹ (LLMs) å’Œç‰¹å®šé¢†åŸŸ AI æ™ºèƒ½ä½“ (Agents) æ¥ä¼˜åŒ–æ¨ç†æ€§èƒ½ä¸æ•ˆç‡ã€‚MoMA åŸºäºå¯¹æ¨¡å‹å’Œæ™ºèƒ½ä½“èƒ½åŠ›çš„æ·±åº¦ç†è§£ï¼Œé€šè¿‡ç²¾ç¡®çš„æ„å›¾è¯†åˆ« (Intent Recognition) å’Œè‡ªé€‚åº”è·¯ç”±ç­–ç•¥æ¥å¤„ç†å¤æ‚æŸ¥è¯¢ã€‚ç ”ç©¶å›¢é˜Ÿæ„å»ºäº†è¯¦ç»†çš„è®­ç»ƒæ•°æ®é›†ï¼Œç”¨äºåˆ†æä¸åŒè·¯ç”±æ¨¡å‹ç»“æ„ä¸‹ LLMs çš„èƒ½åŠ›ç‰¹å¾ï¼Œä»è€Œè¯†åˆ«æ¯ä¸ªæ¨¡å‹æœ€æ“…é•¿çš„ä»»åŠ¡ã€‚åœ¨æ¨ç†è¿‡ç¨‹ä¸­ï¼Œç³»ç»Ÿä¼šå°†æŸ¥è¯¢åŠ¨æ€è·¯ç”±è‡³å…·å¤‡æœ€ä½³æ€§ä»·æ¯”çš„ LLMï¼Œä»¥å®ç°æ•ˆç‡ä¸æˆæœ¬çš„æœ€ä½³å¹³è¡¡ã€‚æ­¤å¤–ï¼Œè¯¥æ¡†æ¶è¿˜å¼•å…¥äº†åŸºäºä¸Šä¸‹æ–‡æ„ŸçŸ¥çŠ¶æ€æœº (Context-aware State Machine) å’ŒåŠ¨æ€æ©ç  (Dynamic Masking) çš„é«˜æ•ˆæ™ºèƒ½ä½“é€‰æ‹©ç­–ç•¥ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼ŒMoMA åœ¨æˆæœ¬æ•ˆç›Šå’Œå¯æ‰©å±•æ€§ (Scalability) æ–¹é¢å…·æœ‰æ˜¾è‘—ä¼˜åŠ¿ã€‚",
      "categories": [
        "cs.MA",
        "cs.AI"
      ],
      "primary_category": "cs.MA",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.07571v2",
      "published_date": "2025-09-09 10:15:42 UTC",
      "updated_date": "2025-09-11 02:09:54 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:30:31.136343+00:00"
    },
    {
      "arxiv_id": "2509.18105v1",
      "title": "BULL-ODE: Bullwhip Learning with Neural ODEs and Universal Differential Equations under Stochastic Demand",
      "title_zh": "BULL-ODEï¼šéšæœºéœ€æ±‚ä¸‹åŸºäºç¥ç»å¸¸å¾®åˆ†æ–¹ç¨‹ä¸é€šç”¨å¾®åˆ†æ–¹ç¨‹çš„ç‰›é­æ•ˆåº”å­¦ä¹ ",
      "authors": [
        "Nachiket N. Naik",
        "Prathamesh Dinesh Joshi",
        "Raj Abhijit Dandekar",
        "Rajat Dandekar",
        "Sreedath Panat"
      ],
      "abstract": "We study learning of continuous-time inventory dynamics under stochastic demand and quantify when structure helps or hurts forecasting of the bullwhip effect. BULL-ODE compares a fully learned Neural ODE (NODE) that models the entire right-hand side against a physics-informed Universal Differential Equation (UDE) that preserves conservation and order-up-to structure while learning a small residual policy term. Classical supply chain models explain the bullwhip through control/forecasting choices and information sharing, while recent physics-informed and neural differential equation methods blend domain constraints with learned components. It is unclear whether structural bias helps or hinders forecasting under different demand regimes. We address this by using a single-echelon testbed with three demand regimes - AR(1) (autocorrelated), i.i.d. Gaussian, and heavy-tailed lognormal. Training is done on varying fractions of each trajectory, followed by evaluation of multi-step forecasts for inventory I, order rate O, and demand D. Across the structured regimes, UDE consistently generalizes better: with 90% of the training horizon, inventory RMSE drops from 4.92 (NODE) to 0.26 (UDE) under AR(1) and from 5.96 to 0.95 under Gaussian demand. Under heavy-tailed lognormal shocks, the flexibility of NODE is better. These trends persist as train18 ing data shrinks, with NODE exhibiting phase drift in extrapolation while UDE remains stable but underreacts to rare spikes. Our results provide concrete guidance: enforce structure when noise is light-tailed or temporally correlated; relax structure when extreme events dominate. Beyond inventory control, the results offer guidance for hybrid modeling in scientific and engineering systems: enforce known structure when conservation laws and modest noise dominate, and relax structure to capture extremes in settings where rare events drive dynamics.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†éšæœºéœ€æ±‚ä¸‹çš„è¿ç»­æ—¶é—´åº“å­˜åŠ¨æ€å­¦ä¹ ï¼Œæ—¨åœ¨é‡åŒ–ç»“æ„åŒ–åç½®åœ¨é¢„æµ‹ç‰›é­æ•ˆåº”(bullwhip effect)ä¸­çš„ä½œç”¨ã€‚ç ”ç©¶å¯¹æ¯”äº†å…¨å­¦ä¹ çš„ç¥ç»å¸¸å¾®åˆ†æ–¹ç¨‹(Neural ODE, NODE)ä¸ç‰©ç†ä¿¡æ¯é©±åŠ¨çš„é€šç”¨å¾®åˆ†æ–¹ç¨‹(Universal Differential Equation, UDE)ï¼Œå…¶ä¸­UDEä¿ç•™äº†åº“å­˜å®ˆæ’å’Œè¡¥è´§è‡³(order-up-to)çš„ç‰©ç†ç»“æ„ã€‚é€šè¿‡åœ¨AR(1)è‡ªç›¸å…³ã€é«˜æ–¯åˆ†å¸ƒåŠé‡å°¾å¯¹æ•°æ­£æ€ä¸‰ç§éœ€æ±‚åœºæ™¯ä¸‹çš„æµ‹è¯•ï¼Œç»“æœè¡¨æ˜UDEåœ¨è½»å°¾æˆ–æ—¶é—´ç›¸å…³çš„éœ€æ±‚ä¸‹æ³›åŒ–æ€§èƒ½æ˜¾è‘—æ›´ä¼˜ï¼Œå…¶åº“å­˜RMSEè¾ƒNODEå¤§å¹…é™ä½ã€‚ç„¶è€Œåœ¨æç«¯äº‹ä»¶ä¸»å¯¼çš„é‡å°¾åœºæ™¯ä¸­ï¼ŒNODEçš„çµæ´»æ€§è¡¨ç°å‡ºæ›´å¥½çš„é€‚åº”æ€§ï¼Œè€ŒUDEåˆ™å®¹æ˜“å¯¹ç½•è§å³°å€¼ååº”ä¸è¶³ã€‚è¿™é¡¹å·¥ä½œä¸ºä¾›åº”é“¾ç®¡ç†åŠå·¥ç¨‹ç³»ç»Ÿä¸­çš„æ··åˆå»ºæ¨¡æä¾›äº†æ˜ç¡®æŒ‡å¯¼ï¼Œå»ºè®®åœ¨å™ªå£°æ¸©å’Œæˆ–éµå¾ªå®ˆæ’å¾‹æ—¶å¼ºåŒ–æ¨¡å‹ç»“æ„ï¼Œè€Œåœ¨ç½•è§æç«¯äº‹ä»¶é©±åŠ¨çš„åœºæ™¯ä¸‹åˆ™åº”æ”¾å®½ç»“æ„çº¦æŸä»¥æ•æ‰åŠ¨åŠ›å­¦ç‰¹å¾ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.18105v1",
      "published_date": "2025-09-09 10:02:41 UTC",
      "updated_date": "2025-09-09 10:02:41 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:30:41.023309+00:00"
    },
    {
      "arxiv_id": "2509.07558v2",
      "title": "VL Norm: Rethink Loss Aggregation in RLVR",
      "title_zh": "VL Normï¼šé‡æ–°å®¡è§† RLVR ä¸­çš„æŸå¤±èšåˆ",
      "authors": [
        "Zhiyuan He",
        "Xufang Luo",
        "Yike Zhang",
        "Yuqing Yang",
        "Lili Qiu"
      ],
      "abstract": "We propose VL Norm (Variance-reduced Length-dependent Normalization), a simple yet effective loss aggregation method tailored to the characteristic of dynamic generation lengths in Reinforcement Learning with Verifiable Rewards (RLVR). Recently, RLVR has demonstrated strong potential in improving the reasoning capabilities of large language models (LLMs), but a major challenge lies in the large variability of response lengths during training, which leads to high gradient variance and unstable optimization. Although previous methods such as GRPO, DAPO, and Dr. GRPO introduce different loss normalization terms to address this issue, they either produce biased estimates or still suffer from high gradient variance. By analyzing the effect of varying lengths on policy loss both theoretically and empirically, we reformulate the problem as finding a minimum-variance unbiased estimator. Our proposed VL Norm not only provides an unbiased estimate of the true policy loss but also minimizes gradient variance in theory. Besides, VL Norm is easy to implement with less than 10 lines of code change. Extensive experiments show that it consistently achieves superior results across different model sizes, maximum lengths, and tasks. When integrated into the state-of-the-art RL algorithm DAPO, it achieves up to 2.67x faster convergence on the CountDown task. Our code is public at https://github.com/zerolllin/Delta-L-Normalization.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¯éªŒè¯å¥–åŠ±å¼ºåŒ–å­¦ä¹ (Reinforcement Learning with Verifiable Rewards, RLVR)åœ¨æå‡å¤§å‹è¯­è¨€æ¨¡å‹(LLMs)æ¨ç†èƒ½åŠ›æ—¶ï¼Œå› ç”Ÿæˆé•¿åº¦å˜åŠ¨å¯¼è‡´çš„æ¢¯åº¦æ–¹å·®è¿‡é«˜å’Œä¼˜åŒ–ä¸ç¨³å®šé—®é¢˜ï¼Œæå‡ºäº†VL Norm (Variance-reduced Length-dependent Normalization)ã€‚é€šè¿‡ç†è®ºä¸å®è¯åˆ†æï¼Œä½œè€…å°†æŸå¤±èšåˆé—®é¢˜é‡æ–°è¡¨è¿°ä¸ºå¯»æ‰¾æœ€å°æ–¹å·®æ— åä¼°è®¡é‡(minimum-variance unbiased estimator)ï¼Œä½¿VL Normåœ¨æä¾›æ— åä¼°è®¡çš„åŒæ—¶æ˜¾è‘—é™ä½äº†æ¢¯åº¦æ–¹å·®ã€‚è¯¥æ–¹æ³•å®ç°ç®€å•ï¼Œä»…éœ€ä¸åˆ°10è¡Œä»£ç æ”¹åŠ¨ï¼Œä¸”åœ¨ä¸åŒæ¨¡å‹è§„æ¨¡ã€æœ€å¤§é•¿åº¦å’Œä»»åŠ¡ä¸‹å‡è¡¨ç°å‡ºæå¼ºçš„é²æ£’æ€§ã€‚å®éªŒè¡¨æ˜ï¼Œå°†VL Normé›†æˆè‡³å…ˆè¿›çš„DAPOç®—æ³•æ—¶ï¼Œåœ¨CountDownä»»åŠ¡ä¸Šå®ç°äº†é«˜è¾¾2.67å€çš„æ”¶æ•›é€Ÿåº¦æå‡ï¼Œä¸ºä¼˜åŒ–é•¿æ–‡æœ¬æ¨ç†ä»»åŠ¡çš„å¼ºåŒ–å­¦ä¹ è®­ç»ƒæä¾›äº†é«˜æ•ˆçš„è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.07558v2",
      "published_date": "2025-09-09 09:52:34 UTC",
      "updated_date": "2025-10-11 08:50:09 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:30:41.745638+00:00"
    },
    {
      "arxiv_id": "2509.07555v1",
      "title": "Avoiding Knowledge Edit Skipping in Multi-hop Question Answering with Guided Decomposition",
      "title_zh": "é€šè¿‡å¼•å¯¼å¼åˆ†è§£è§„é¿å¤šè·³é—®ç­”ä¸­çš„çŸ¥è¯†ç¼–è¾‘è·³è¿‡ç°è±¡",
      "authors": [
        "Yi Liu",
        "Xiangrong Zhu",
        "Xiangyu Liu",
        "Wei Wei",
        "Wei Hu"
      ],
      "abstract": "In a rapidly evolving world where information updates swiftly, knowledge in large language models (LLMs) becomes outdated quickly. Retraining LLMs is not a cost-effective option, making knowledge editing (KE) without modifying parameters particularly necessary. We find that although existing retrieval-augmented generation (RAG)-based KE methods excel at editing simple knowledge, they struggle with KE in multi-hop question answering due to the issue of \"edit skipping\", which refers to skipping the relevant edited fact in inference. In addition to the diversity of natural language expressions of knowledge, edit skipping also arises from the mismatch between the granularity of LLMs in problem-solving and the facts in the edited memory. To address this issue, we propose a novel Iterative Retrieval-Augmented Knowledge Editing method with guided decomposition (IRAKE) through the guidance from single edited facts and entire edited cases. Experimental results demonstrate that IRAKE mitigates the failure of editing caused by edit skipping and outperforms state-of-the-art methods for KE in multi-hop question answering.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§è¯­è¨€æ¨¡å‹ (Large Language Models, LLMs) çŸ¥è¯†æ›´æ–°æ»åçš„é—®é¢˜ï¼Œæ¢è®¨äº†æ— éœ€ä¿®æ”¹å‚æ•°çš„çŸ¥è¯†ç¼–è¾‘ (Knowledge Editing, KE) æŠ€æœ¯ã€‚ç ”ç©¶å‘ç°ç°æœ‰çš„æ£€ç´¢å¢å¼ºç”Ÿæˆ (Retrieval-Augmented Generation, RAG) æ–¹æ³•åœ¨å¤„ç†å¤šè·³é—®ç­” (Multi-hop Question Answering) æ—¶ï¼Œå¸¸å› è‡ªç„¶è¯­è¨€è¡¨è¾¾å¤šæ ·æ€§åŠè§£é¢˜ç²’åº¦ä¸åŒ¹é…è€Œå‡ºç°â€œç¼–è¾‘è·³è¿‡â€ (edit skipping) çš„å¤±æ•ˆç°è±¡ã€‚ä¸ºæ­¤ï¼Œä½œè€…æå‡ºäº† IRAKE (Iterative Retrieval-Augmented Knowledge Editing with guided decomposition) æ–¹æ³•ï¼Œé€šè¿‡å•æ¡ç¼–è¾‘äº‹å®å’Œå®Œæ•´æ¡ˆä¾‹çš„å¼•å¯¼è¿›è¡Œè¿­ä»£å¼åˆ†è§£æ£€ç´¢ã€‚å®éªŒç»“æœè¯æ˜ï¼ŒIRAKE æœ‰æ•ˆç¼“è§£äº†â€œç¼–è¾‘è·³è¿‡â€é—®é¢˜ï¼Œåœ¨å¤šè·³é—®ç­”çŸ¥è¯†ç¼–è¾‘ä»»åŠ¡ä¸Šçš„è¡¨ç°ä¼˜äºç°æœ‰æœ€å…ˆè¿›æ–¹æ³•ã€‚è¿™ä¸€æ–¹æ¡ˆä¸ºæå‡ LLMs åœ¨å¤æ‚æ¨ç†åœºæ™¯ä¸‹çš„çŸ¥è¯†æ—¶æ•ˆæ€§æä¾›äº†æœ‰æ•ˆè·¯å¾„ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted in EMNLP Findings 2025",
      "pdf_url": "https://arxiv.org/pdf/2509.07555v1",
      "published_date": "2025-09-09 09:49:23 UTC",
      "updated_date": "2025-09-09 09:49:23 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:30:46.425797+00:00"
    },
    {
      "arxiv_id": "2509.08022v2",
      "title": "MVPBench: A Benchmark and Fine-Tuning Framework for Aligning Large Language Models with Diverse Human Values",
      "title_zh": "MVPBenchï¼šå¤§è¯­è¨€æ¨¡å‹å¤šå…ƒäººç±»ä»·å€¼è§‚å¯¹é½çš„è¯„æµ‹åŸºå‡†ä¸å¾®è°ƒæ¡†æ¶",
      "authors": [
        "Yao Liang",
        "Dongcheng Zhao",
        "Feifei Zhao",
        "Guobin Shen",
        "Yuwei Wang",
        "Dongqi Liang",
        "Yi Zeng"
      ],
      "abstract": "The alignment of large language models (LLMs) with human values is critical for their safe and effective deployment across diverse user populations. However, existing benchmarks often neglect cultural and demographic diversity, leading to limited understanding of how value alignment generalizes globally. In this work, we introduce MVPBench, a novel benchmark that systematically evaluates LLMs' alignment with multi-dimensional human value preferences across 75 countries. MVPBench contains 24,020 high-quality instances annotated with fine-grained value labels, personalized questions, and rich demographic metadata, making it the most comprehensive resource of its kind to date. Using MVPBench, we conduct an in-depth analysis of several state-of-the-art LLMs, revealing substantial disparities in alignment performance across geographic and demographic lines. We further demonstrate that lightweight fine-tuning methods, such as Low-Rank Adaptation (LoRA) and Direct Preference Optimization (DPO), can significantly enhance value alignment in both in-domain and out-of-domain settings. Our findings underscore the necessity for population-aware alignment evaluation and provide actionable insights for building culturally adaptive and value-sensitive LLMs. MVPBench serves as a practical foundation for future research on global alignment, personalized value modeling, and equitable AI development.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†MVPBenchï¼Œè¿™æ˜¯ä¸€ä¸ªæ—¨åœ¨å°†å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ä¸å¤šå…ƒåŒ–äººç±»ä»·å€¼è§‚è¿›è¡Œå¯¹é½è¯„ä¼°çš„æ–°å‹åŸºå‡†å’Œå¾®è°ƒæ¡†æ¶ã€‚é’ˆå¯¹ç°æœ‰åŸºå‡†ç¼ºä¹æ–‡åŒ–å’Œäººå£ç»Ÿè®¡å­¦å¤šæ ·æ€§çš„é—®é¢˜ï¼ŒMVPBench æ¶µç›–äº†å…¨çƒ 75 ä¸ªå›½å®¶çš„ 24,020 ä¸ªé«˜è´¨é‡å®ä¾‹ï¼Œå¹¶é…å¤‡äº†ç»†ç²’åº¦çš„ä»·å€¼æ ‡ç­¾å’Œä¸°å¯Œçš„äººå£ç»Ÿè®¡å…ƒæ•°æ®ã€‚ç ”ç©¶é€šè¿‡å¯¹å¤šç§æœ€å…ˆè¿› LLMs çš„åˆ†æï¼Œæ­ç¤ºäº†æ¨¡å‹åœ¨ä¸åŒåœ°ç†å’Œäººå£ç¾¤ä½“ä¹‹é—´å­˜åœ¨æ˜¾è‘—çš„ä»·å€¼å¯¹é½æ€§èƒ½å·®å¼‚ã€‚å®éªŒè¡¨æ˜ï¼Œåˆ©ç”¨ Low-Rank Adaptation (LoRA) å’Œ Direct Preference Optimization (DPO) ç­‰è½»é‡çº§å¾®è°ƒæŠ€æœ¯ï¼Œå¯ä»¥æ˜¾è‘—å¢å¼ºæ¨¡å‹åœ¨åŸŸå†…ï¼ˆin-domainï¼‰å’ŒåŸŸå¤–ï¼ˆout-of-domainï¼‰è®¾ç½®ä¸­çš„ä»·å€¼å¯¹é½è¡¨ç°ã€‚è¯¥ç ”ç©¶å¼ºè°ƒäº†å¼€å‘äººå£æ„ŸçŸ¥å¯¹é½è¯„ä¼°ä½“ç³»çš„å¿…è¦æ€§ï¼Œä¸ºæ„å»ºå…·å¤‡æ–‡åŒ–é€‚åº”æ€§å’Œä»·å€¼æ•æ„Ÿæ€§çš„ AI ç³»ç»Ÿæä¾›äº†é‡è¦çš„åŸºçŸ³ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Some parts of the paper need to be revised. We would therefore like to withdraw the paper and resubmit it after making the necessary changes",
      "pdf_url": "https://arxiv.org/pdf/2509.08022v2",
      "published_date": "2025-09-09 09:25:08 UTC",
      "updated_date": "2025-09-16 03:06:45 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:30:50.452277+00:00"
    },
    {
      "arxiv_id": "2509.07534v1",
      "title": "HU-based Foreground Masking for 3D Medical Masked Image Modeling",
      "title_zh": "ç”¨äº 3D åŒ»å­¦æ©ç å›¾åƒå»ºæ¨¡çš„åŸºäº HU çš„å‰æ™¯æ©ç ",
      "authors": [
        "Jin Lee",
        "Vu Dang",
        "Gwang-Hyun Yu",
        "Anh Le",
        "Zahid Rahman",
        "Jin-Ho Jang",
        "Heonzoo Lee",
        "Kun-Yung Kim",
        "Jin-Sul Kim",
        "Jin-Young Kim"
      ],
      "abstract": "While Masked Image Modeling (MIM) has revolutionized fields of computer vision, its adoption in 3D medical image computing has been limited by the use of random masking, which overlooks the density of anatomical objects. To address this limitation, we enhance the pretext task with a simple yet effective masking strategy. Leveraging Hounsfield Unit (HU) measurements, we implement an HU-based Foreground Masking, which focuses on the intensity distribution of visceral organs and excludes non-tissue regions, such as air and fluid, that lack diagnostically meaningful features. Extensive experiments on five public 3D medical imaging datasets demonstrate that our masking consistently improves performance, both in quality of segmentation and Dice score (BTCV:~84.64\\%, Flare22:~92.43\\%, MM-WHS:~90.67\\%, Amos22:~88.64\\%, BraTS:~78.55\\%). These results underscore the importance of domain-centric MIM and suggest a promising direction for representation learning in medical image segmentation. Implementation is available at github.com/AISeedHub/SubFore/.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹æ©ç å›¾åƒå»ºæ¨¡(Masked Image Modeling, MIM)åœ¨3DåŒ»å­¦å›¾åƒè®¡ç®—ä¸­å› é‡‡ç”¨éšæœºæ©ç è€Œå¿½ç•¥è§£å‰–ç»“æ„å¯†åº¦çš„å±€é™æ€§ï¼Œæå‡ºäº†ä¸€ç§åŸºäºHounsfield Unit (HU)çš„å‰æ™¯æ©ç ç­–ç•¥ã€‚è¯¥æ–¹æ³•åˆ©ç”¨HUæµ‹é‡å€¼èšç„¦äºå†…è„å™¨å®˜çš„å¼ºåº¦åˆ†å¸ƒï¼Œå¹¶æ’é™¤äº†ç©ºæ°”å’Œæµä½“ç­‰ç¼ºä¹è¯Šæ–­ç‰¹å¾çš„éç»„ç»‡åŒºåŸŸï¼Œä»è€Œä¼˜åŒ–äº†é¢„è®­ç»ƒä»»åŠ¡ã€‚åœ¨BTCVã€Flare22ã€MM-WHSã€Amos22å’ŒBraTSäº”ä¸ªå…¬å¼€æ•°æ®é›†ä¸Šè¿›è¡Œçš„å®éªŒè¡¨æ˜ï¼Œè¯¥ç­–ç•¥åœ¨åˆ†å‰²è´¨é‡å’ŒDice scoreä¸Šå‡å®ç°äº†æŒç»­æå‡ï¼Œå…¶ä¸­BTCVè¾¾åˆ°84.64%ï¼ŒFlare22è¾¾åˆ°92.43%ã€‚ç ”ç©¶ç»“æœå¼ºè°ƒäº†é¢†åŸŸä¸­å¿ƒåŒ–MIMçš„é‡è¦æ€§ï¼Œä¸ºåŒ»å­¦å›¾åƒåˆ†å‰²çš„è¡¨ç¤ºå­¦ä¹ (representation learning)æä¾›äº†æå…·å‰æ™¯çš„æ–¹å‘ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by MICCAI AMAI Workshop 2025",
      "pdf_url": "https://arxiv.org/pdf/2509.07534v1",
      "published_date": "2025-09-09 09:11:38 UTC",
      "updated_date": "2025-09-09 09:11:38 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:30:51.837066+00:00"
    },
    {
      "arxiv_id": "2509.07531v1",
      "title": "FLeW: Facet-Level and Adaptive Weighted Representation Learning of Scientific Documents",
      "title_zh": "FLeWï¼šç§‘å­¦æ–‡çŒ®çš„æ–¹é¢çº§ä¸è‡ªé€‚åº”åŠ æƒè¡¨ç¤ºå­¦ä¹ ",
      "authors": [
        "Zheng Dou",
        "Deqing Wang",
        "Fuzhen Zhuang",
        "Jian Ren",
        "Yanlin Hu"
      ],
      "abstract": "Scientific document representation learning provides powerful embeddings for various tasks, while current methods face challenges across three approaches. 1) Contrastive training with citation-structural signals underutilizes citation information and still generates single-vector representations. 2) Fine-grained representation learning, which generates multiple vectors at the sentence or aspect level, requires costly integration and lacks domain generalization. 3) Task-aware learning depends on manually predefined task categorization, overlooking nuanced task distinctions and requiring extra training data for task-specific modules. To address these problems, we propose a new method that unifies the three approaches for better representations, namely FLeW. Specifically, we introduce a novel triplet sampling method that leverages citation intent and frequency to enhance citation-structural signals for training. Citation intents (background, method, result), aligned with the general structure of scientific writing, facilitate a domain-generalized facet partition for fine-grained representation learning. Then, we adopt a simple weight search to adaptively integrate three facet-level embeddings into a task-specific document embedding without task-aware fine-tuning. Experiments show the applicability and robustness of FLeW across multiple scientific tasks and fields, compared to prior models.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†FLeWï¼Œä¸€ç§é’ˆå¯¹ç§‘å­¦æ–‡çŒ®çš„å±‚é¢çº§(Facet-Level)å’Œè‡ªé€‚åº”åŠ æƒè¡¨ç¤ºå­¦ä¹ æ–¹æ³•ï¼Œæ—¨åœ¨è§£å†³ç°æœ‰æ–¹æ³•åœ¨å¼•ç”¨ä¿¡å·åˆ©ç”¨ä¸è¶³ã€ç»†ç²’åº¦è¡¨ç¤ºé€šç”¨æ€§å·®ä»¥åŠä»»åŠ¡æ„ŸçŸ¥å­¦ä¹ ä¾èµ–æ‰‹å·¥æ ‡æ³¨ç­‰é—®é¢˜ã€‚FLeWé€šè¿‡å¼•å…¥ç»“åˆå¼•ç”¨æ„å›¾(Citation intent)å’Œé¢‘ç‡çš„æ–°å‹ä¸‰å…ƒç»„é‡‡æ ·æ–¹æ³•ï¼Œæ˜¾è‘—å¢å¼ºäº†è®­ç»ƒè¿‡ç¨‹ä¸­çš„å¼•ç”¨ç»“æ„ä¿¡å·ã€‚è¯¥æ–¹æ³•åˆ©ç”¨ä¸ç§‘å­¦å†™ä½œé€šç”¨çš„èƒŒæ™¯ã€æ–¹æ³•ã€ç»“æœç­‰å¼•ç”¨æ„å›¾è¿›è¡Œå±‚é¢åˆ’åˆ†ï¼Œå®ç°äº†å…·æœ‰é¢†åŸŸæ³›åŒ–èƒ½åŠ›çš„ç»†ç²’åº¦è¡¨ç¤ºå­¦ä¹ ã€‚éšåï¼Œç ”ç©¶é‡‡ç”¨ä¸€ç§ç®€å•çš„æƒé‡æœç´¢æœºåˆ¶ï¼Œæ— éœ€é’ˆå¯¹ç‰¹å®šä»»åŠ¡è¿›è¡Œå¾®è°ƒå³å¯å°†ä¸åŒå±‚é¢çš„åµŒå…¥è‡ªé€‚åº”æ•´åˆä¸ºä»»åŠ¡ç›¸å…³çš„æ–‡æ¡£è¡¨ç¤ºã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œä¸å…ˆå‰æ¨¡å‹ç›¸æ¯”ï¼ŒFLeWåœ¨å¤šä¸ªç§‘å­¦ä»»åŠ¡å’Œé¢†åŸŸä¸­å‡è¡¨ç°å‡ºä¼˜å¼‚çš„é€‚ç”¨æ€§å’Œé²æ£’æ€§ã€‚",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "Accepted by DASFAA2025",
      "pdf_url": "https://arxiv.org/pdf/2509.07531v1",
      "published_date": "2025-09-09 09:08:44 UTC",
      "updated_date": "2025-09-09 09:08:44 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:30:52.738839+00:00"
    },
    {
      "arxiv_id": "2509.07526v3",
      "title": "Competitive Audio-Language Models with Data-Efficient Single-Stage Training on Public Data",
      "title_zh": "å…·æœ‰ç«äº‰åŠ›çš„éŸ³é¢‘-è¯­è¨€æ¨¡å‹ï¼šåŸºäºå…¬å…±æ•°æ®çš„é«˜æ•ˆå•é˜¶æ®µè®­ç»ƒ",
      "authors": [
        "Gokul Karthik Kumar",
        "Rishabh Saraf",
        "Ludovick Lepauloux",
        "Abdul Muneer",
        "Billel Mokeddem",
        "Hakim Hacid"
      ],
      "abstract": "Large language models (LLMs) have transformed NLP, yet their integration with audio remains underexplored despite audio's centrality to human communication. We introduce Falcon3-Audio, a family of Audio-Language Models (ALMs) built on instruction-tuned LLMs and Whisper encoders. Using a remarkably small amount of public audio data, less than 30K hours (5K unique), Falcon3-Audio-7B matches the best reported performance among open-weight models on the MMAU benchmark, with a score of 64.14, matching R1-AQA, while distinguishing itself through superior data and parameter efficiency, single-stage training, and transparency. Notably, our smallest 1B model remains competitive with larger open models ranging from 2B to 13B parameters. Through extensive ablations, we find that common complexities such as curriculum learning, multiple audio encoders, and intricate cross-attention connectors are not required for strong performance, even compared to models trained on over 500K hours of data.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¨å‡ºäº† Falcon3-Audioï¼Œè¿™æ˜¯ä¸€ç³»åˆ—åŸºäºæŒ‡ä»¤å¾®è°ƒ(Instruction-tuned) LLMs å’Œ Whisper ç¼–ç å™¨æ„å»ºçš„éŸ³é¢‘è¯­è¨€æ¨¡å‹ (ALMs)ã€‚è¯¥æ¨¡å‹é‡‡ç”¨é«˜æ•ˆçš„å•é˜¶æ®µè®­ç»ƒ(Single-stage training)æ–¹æ³•ï¼Œä»…ä½¿ç”¨ä¸åˆ° 3 ä¸‡å°æ—¶çš„å…¬å¼€éŸ³é¢‘æ•°æ®ä¾¿å®ç°äº†å“è¶Šçš„æ€§èƒ½ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒFalcon3-Audio-7B åœ¨ MMAU åŸºå‡†æµ‹è¯•ä¸­å–å¾—äº† 64.14 åˆ†ï¼Œè¾¾åˆ°å¼€æºæ¨¡å‹ä¸­çš„é¢†å…ˆæ°´å¹³ï¼Œä¸”å…¶ 1B è§„æ¨¡æ¨¡å‹äº¦èƒ½ä¸ 2B è‡³ 13B å‚æ•°é‡çš„æ¨¡å‹ç«äº‰ã€‚ç ”ç©¶é€šè¿‡æ¶ˆå‡å®éªŒ(Ablations)è¯å®ï¼Œè¯¾ç¨‹å­¦ä¹ (Curriculum learning)ã€å¤šéŸ³é¢‘ç¼–ç å™¨å’Œå¤æ‚çš„äº¤å‰æ³¨æ„åŠ›è¿æ¥å™¨(Cross-attention connectors)å¹¶éé«˜æ€§èƒ½çš„å¿…è¦æ¡ä»¶ã€‚è¯¥ç ”ç©¶ä¸ä»…å±•ç°äº†æé«˜çš„æ•°æ®å’Œå‚æ•°æ•ˆç‡ï¼Œè¿˜ä¸ºé€æ˜ä¸”ç®€åŒ–çš„éŸ³é¢‘è¯­è¨€æ¨¡å‹æ„å»ºæä¾›äº†é‡è¦å‚è€ƒã€‚",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.SD",
      "comment": "Accepted at ASRU 2025",
      "pdf_url": "https://arxiv.org/pdf/2509.07526v3",
      "published_date": "2025-09-09 09:01:01 UTC",
      "updated_date": "2026-01-22 09:16:28 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:30:56.338777+00:00"
    },
    {
      "arxiv_id": "2509.07525v1",
      "title": "EHWGesture -- A dataset for multimodal understanding of clinical gestures",
      "title_zh": "EHWGestureï¼šä¸´åºŠæ‰‹åŠ¿å¤šæ¨¡æ€ç†è§£æ•°æ®é›†",
      "authors": [
        "Gianluca Amprimo",
        "Alberto Ancilotto",
        "Alessandro Savino",
        "Fabio Quazzolo",
        "Claudia Ferraris",
        "Gabriella Olmo",
        "Elisabetta Farella",
        "Stefano Di Carlo"
      ],
      "abstract": "Hand gesture understanding is essential for several applications in human-computer interaction, including automatic clinical assessment of hand dexterity. While deep learning has advanced static gesture recognition, dynamic gesture understanding remains challenging due to complex spatiotemporal variations. Moreover, existing datasets often lack multimodal and multi-view diversity, precise ground-truth tracking, and an action quality component embedded within gestures. This paper introduces EHWGesture, a multimodal video dataset for gesture understanding featuring five clinically relevant gestures. It includes over 1,100 recordings (6 hours), captured from 25 healthy subjects using two high-resolution RGB-Depth cameras and an event camera. A motion capture system provides precise ground-truth hand landmark tracking, and all devices are spatially calibrated and synchronized to ensure cross-modal alignment. Moreover, to embed an action quality task within gesture understanding, collected recordings are organized in classes of execution speed that mirror clinical evaluations of hand dexterity. Baseline experiments highlight the dataset's potential for gesture classification, gesture trigger detection, and action quality assessment. Thus, EHWGesture can serve as a comprehensive benchmark for advancing multimodal clinical gesture understanding.",
      "tldr_zh": "è¯¥ç ”ç©¶ä»‹ç»äº† EHWGestureï¼Œè¿™æ˜¯ä¸€ä¸ªç”¨äºä¸´åºŠæ‰‹åŠ¿å¤šæ¨¡æ€ç†è§£çš„å¤§å‹è§†é¢‘æ•°æ®é›†ï¼Œæ—¨åœ¨è§£å†³ç°æœ‰æ•°æ®é›†åœ¨å¤šæ¨¡æ€å¤šæ ·æ€§ã€ç²¾ç¡®è¿½è¸ªå’ŒåŠ¨ä½œè´¨é‡è¯„ä¼°æ–¹é¢çš„å±€é™ã€‚è¯¥æ•°æ®é›†åŒ…å« 5 ç§å…·æœ‰ä¸´åºŠç›¸å…³æ€§çš„æ‰‹åŠ¿ï¼Œç”± 25 åå¥åº·å—è¯•è€…é€šè¿‡ä¸¤å°é«˜åˆ†è¾¨ç‡ RGB-Depth ç›¸æœºå’Œä¸€å° Event Camera å½•åˆ¶ï¼Œæ€»è®¡è¶…è¿‡ 1,100 æ¡é«˜è´¨é‡å½•åƒã€‚ç ”ç©¶åˆ©ç”¨è¿åŠ¨æ•æ‰ç³»ç»Ÿæä¾›äº†ç²¾ç¡®çš„ Ground-truth æ‰‹éƒ¨å…³é”®ç‚¹è¿½è¸ªï¼Œå¹¶å¯¹æ‰€æœ‰è®¾å¤‡è¿›è¡Œç©ºé—´æ ¡å‡†ä¸åŒæ­¥ä»¥ç¡®ä¿è·¨æ¨¡æ€å¯¹é½ã€‚ä¸ºäº†åœ¨æ‰‹åŠ¿ç†è§£ä¸­å¼•å…¥åŠ¨ä½œè´¨é‡è¯„ä¼°ä»»åŠ¡ï¼Œå½•åƒè¢«ç»„ç»‡ä¸ºåæ˜ ä¸´åºŠæ‰‹éƒ¨çµæ´»æ€§ (Hand Dexterity) è¯„ä¼°çš„æ‰§è¡Œé€Ÿåº¦ç±»åˆ«ã€‚åŸºçº¿å®éªŒè¯æ˜äº†è¯¥æ•°æ®é›†åœ¨æ‰‹åŠ¿åˆ†ç±»ã€æ‰‹åŠ¿è§¦å‘æ£€æµ‹ä»¥åŠåŠ¨ä½œè´¨é‡è¯„ä¼°æ–¹é¢çš„åº”ç”¨æ½œåŠ›ã€‚EHWGesture ä¸ºå¼€å‘æ›´å…ˆè¿›çš„å¤šæ¨¡æ€ä¸´åºŠè¾…åŠ©è¯Šæ–­æŠ€æœ¯æä¾›äº†ä¸€ä¸ªå…¨é¢çš„åŸºå‡†å¹³å°ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted at ICCV 2025 Workshop on AI-driven Skilled Activity Understanding, Assessment & Feedback Generation",
      "pdf_url": "https://arxiv.org/pdf/2509.07525v1",
      "published_date": "2025-09-09 09:00:03 UTC",
      "updated_date": "2025-09-09 09:00:03 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:31:16.741701+00:00"
    },
    {
      "arxiv_id": "2509.07515v1",
      "title": "Water Demand Forecasting of District Metered Areas through Learned Consumer Representations",
      "title_zh": "åŸºäºå­¦ä¹ å‹æ¶ˆè´¹è€…è¡¨å¾çš„åŒºåŸŸè®¡é‡åˆ†åŒºç”¨æ°´éœ€æ±‚é¢„æµ‹",
      "authors": [
        "Adithya Ramachandran",
        "Thorkil Flensmark B. Neergaard",
        "TomÃ¡s Arias-Vergara",
        "Andreas Maier",
        "Siming Bayer"
      ],
      "abstract": "Advancements in smart metering technologies have significantly improved the ability to monitor and manage water utilities. In the context of increasing uncertainty due to climate change, securing water resources and supply has emerged as an urgent global issue with extensive socioeconomic ramifications. Hourly consumption data from end-users have yielded substantial insights for projecting demand across regions characterized by diverse consumption patterns. Nevertheless, the prediction of water demand remains challenging due to influencing non-deterministic factors, such as meteorological conditions. This work introduces a novel method for short-term water demand forecasting for District Metered Areas (DMAs) which encompass commercial, agricultural, and residential consumers. Unsupervised contrastive learning is applied to categorize end-users according to distinct consumption behaviors present within a DMA. Subsequently, the distinct consumption behaviors are utilized as features in the ensuing demand forecasting task using wavelet-transformed convolutional networks that incorporate a cross-attention mechanism combining both historical data and the derived representations. The proposed approach is evaluated on real-world DMAs over a six-month period, demonstrating improved forecasting performance in terms of MAPE across different DMAs, with a maximum improvement of 4.9%. Additionally, it identifies consumers whose behavior is shaped by socioeconomic factors, enhancing prior knowledge about the deterministic patterns that influence demand.",
      "tldr_zh": "è¿™é¡¹ç ”ç©¶é’ˆå¯¹å…¨çƒä¾›æ°´å®‰å…¨æŒ‘æˆ˜ï¼Œæå‡ºäº†ä¸€ç§é€šè¿‡å­¦ä¹ æ¶ˆè´¹è€…è¡¨å¾æ¥å®ç°åŒºåŸŸè®¡é‡åŒº (District Metered Areas, DMAs) çŸ­æœŸéœ€æ°´é‡é¢„æµ‹çš„æ–°æ–¹æ³•ã€‚è¯¥æ–¹æ³•é¦–å…ˆåˆ©ç”¨æ— ç›‘ç£å¯¹æ¯”å­¦ä¹  (Unsupervised contrastive learning) æŠ€æœ¯ï¼Œæ ¹æ® DMAs å†…å•†ä¸šã€å†œä¸šå’Œä½å®…ç”¨æˆ·çš„ä¸åŒæ¶ˆè´¹è¡Œä¸ºè¿›è¡Œåˆ†ç±»ã€‚éšåï¼Œå°†æå–çš„è¡Œä¸ºç‰¹å¾è¾“å…¥åˆ°é›†æˆäº¤å‰æ³¨æ„åŠ›æœºåˆ¶ (cross-attention mechanism) çš„å°æ³¢å˜æ¢å·ç§¯ç½‘ç»œ (wavelet-transformed convolutional networks) ä¸­ï¼Œä»¥ç»“åˆå†å²æ•°æ®å’Œå­¦ä¹ åˆ°çš„è¡¨å¾è¿›è¡Œç²¾å‡†é¢„æµ‹ã€‚åœ¨çœŸå®åœºæ™¯ä¸‹ä¸ºæœŸå…­ä¸ªæœˆçš„å®éªŒè¯„ä¼°è¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨å¹³å‡ç»å¯¹ç™¾åˆ†æ¯”è¯¯å·® (MAPE) æ–¹é¢æ¯”åŸºçº¿æ¨¡å‹æœ€é«˜æå‡äº† 4.9%ã€‚æ­¤å¤–ï¼Œè¯¥ç ”ç©¶æˆåŠŸè¯†åˆ«äº†å—ç¤¾ä¼šç»æµå› ç´ å½±å“çš„ç”¨æˆ·è¡Œä¸ºæ¨¡å¼ï¼Œä¸ºç†è§£å½±å“æ°´éœ€æ±‚çš„ç¡®å®šæ€§å› ç´ æä¾›äº†é‡è¦è§è§£ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.LG",
      "comment": "Presented at European Conference for Signal Procesing - EUSIPCO 2025",
      "pdf_url": "https://arxiv.org/pdf/2509.07515v1",
      "published_date": "2025-09-09 08:51:30 UTC",
      "updated_date": "2025-09-09 08:51:30 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:31:15.442208+00:00"
    },
    {
      "arxiv_id": "2509.07512v1",
      "title": "ALLabel: Three-stage Active Learning for LLM-based Entity Recognition using Demonstration Retrieval",
      "title_zh": "ALLabelï¼šåŸºäºç¤ºä¾‹æ£€ç´¢çš„å¤§è¯­è¨€æ¨¡å‹å®ä½“è¯†åˆ«ä¸‰é˜¶æ®µä¸»åŠ¨å­¦ä¹ ",
      "authors": [
        "Zihan Chen",
        "Lei Shi",
        "Weize Wu",
        "Qiji Zhou",
        "Yue Zhang"
      ],
      "abstract": "Many contemporary data-driven research efforts in the natural sciences, such as chemistry and materials science, require large-scale, high-performance entity recognition from scientific datasets. Large language models (LLMs) have increasingly been adopted to solve the entity recognition task, with the same trend being observed on all-spectrum NLP tasks. The prevailing entity recognition LLMs rely on fine-tuned technology, yet the fine-tuning process often incurs significant cost. To achieve a best performance-cost trade-off, we propose ALLabel, a three-stage framework designed to select the most informative and representative samples in preparing the demonstrations for LLM modeling. The annotated examples are used to construct a ground-truth retrieval corpus for LLM in-context learning. By sequentially employing three distinct active learning strategies, ALLabel consistently outperforms all baselines under the same annotation budget across three specialized domain datasets. Experimental results also demonstrate that selectively annotating only 5\\%-10\\% of the dataset with ALLabel can achieve performance comparable to the method annotating the entire dataset. Further analyses and ablation studies verify the effectiveness and generalizability of our proposal.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† ALLabelï¼Œä¸€ç§æ—¨åœ¨ä¼˜åŒ–åŸºäºå¤§è¯­è¨€æ¨¡å‹ (LLM) çš„å®ä½“è¯†åˆ«ä»»åŠ¡çš„ä¸‰é˜¶æ®µä¸»åŠ¨å­¦ä¹  (Active Learning) æ¡†æ¶ã€‚è¯¥æ¡†æ¶é€šè¿‡ä¾æ¬¡åº”ç”¨ä¸‰ç§ä¸åŒçš„ä¸»åŠ¨å­¦ä¹ ç­–ç•¥ï¼Œä»æ•°æ®é›†ä¸­ç­›é€‰å‡ºæœ€å…·ä¿¡æ¯é‡å’Œä»£è¡¨æ€§çš„æ ·æœ¬ï¼Œå¹¶åˆ©ç”¨è¿™äº›æ ‡æ³¨æ•°æ®æ„å»ºç”¨äºä¸Šä¸‹æ–‡å­¦ä¹  (In-context Learning) çš„ç¤ºä¾‹æ£€ç´¢åº“ã€‚ALLabel æœ‰æ•ˆè§£å†³äº†åœ¨åŒ–å­¦ã€ææ–™ç§‘å­¦ç­‰è‡ªç„¶ç§‘å­¦é¢†åŸŸä¸­ï¼Œå¤§æ¨¡å‹å¾®è°ƒ (Fine-tuning) æˆæœ¬è¿‡é«˜çš„é—®é¢˜ã€‚åœ¨ä¸‰ä¸ªä¸“ä¸šé¢†åŸŸæ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼Œè¯¥æ¡†æ¶åœ¨ç›¸åŒæ ‡æ³¨é¢„ç®—ä¸‹æ€§èƒ½å§‹ç»ˆä¼˜äºåŸºå‡†æ¨¡å‹ã€‚å…³é”®å‘ç°æ˜¾ç¤ºï¼Œä»…éœ€æ ‡æ³¨ 5%-10% çš„æ•°æ®ï¼ŒALLabel å³å¯å®ç°ä¸å…¨é‡æ•°æ®æ ‡æ³¨ç›¸å½“çš„å®ä½“è¯†åˆ«æ•ˆæœã€‚æ¶ˆèå®éªŒè¿›ä¸€æ­¥è¯å®äº†è¯¥æ–¹æ³•åœ¨æ€§èƒ½ä¸æˆæœ¬æƒè¡¡æ–¹é¢çš„æœ‰æ•ˆæ€§åŠæ³›åŒ–èƒ½åŠ›ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.07512v1",
      "published_date": "2025-09-09 08:47:13 UTC",
      "updated_date": "2025-09-09 08:47:13 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:31:25.540782+00:00"
    },
    {
      "arxiv_id": "2509.07506v2",
      "title": "Astra: A Multi-Agent System for GPU Kernel Performance Optimization",
      "title_zh": "Astraï¼šç”¨äº GPU å†…æ ¸æ€§èƒ½ä¼˜åŒ–çš„å¤šæ™ºèƒ½ä½“ç³»ç»Ÿ",
      "authors": [
        "Anjiang Wei",
        "Tianran Sun",
        "Yogesh Seenichamy",
        "Hang Song",
        "Anne Ouyang",
        "Azalia Mirhoseini",
        "Ke Wang",
        "Alex Aiken"
      ],
      "abstract": "GPU kernel optimization has long been a central challenge at the intersection of high-performance computing and machine learning. Efficient kernels are crucial for accelerating large language model (LLM) training and serving, yet attaining high performance typically requires extensive manual tuning. Compiler-based systems reduce some of this burden, but still demand substantial manual design and engineering effort. Recently, researchers have explored using LLMs for GPU kernel generation, though prior work has largely focused on translating high-level PyTorch modules into CUDA code. In this work, we introduce Astra, the first LLM-based multi-agent system for GPU kernel optimization. Unlike previous approaches, Astra starts from existing CUDA implementations extracted from SGLang, a widely deployed framework for serving LLMs, rather than treating PyTorch modules as the specification. Within Astra, specialized LLM agents collaborate through iterative code generation, testing, profiling, and planning to produce kernels that are both correct and high-performance. On kernels from SGLang, Astra achieves an average speedup of 1.32x using zero-shot prompting with OpenAI o4-mini. A detailed case study further demonstrates that LLMs can autonomously apply loop transformations, optimize memory access patterns, exploit CUDA intrinsics, and leverage fast math operations to yield substantial performance gains. Our work highlights multi-agent LLM systems as a promising new paradigm for GPU kernel optimization. Our code is publicly available at https://github.com/Anjiang-Wei/Astra.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¨å‡ºäº† Astraï¼Œè¿™æ˜¯é¦–ä¸ªåŸºäºå¤§è¯­è¨€æ¨¡å‹(LLM)çš„å¤šæ™ºèƒ½ä½“ç³»ç»Ÿï¼Œä¸“é—¨ç”¨äº GPU kernel çš„æ€§èƒ½ä¼˜åŒ–ã€‚ä¼ ç»Ÿçš„ä¼˜åŒ–å·¥ä½œå¾€å¾€ä¾èµ–å¤§é‡çš„æ‰‹åŠ¨è°ƒä¼˜æˆ–ç¼–è¯‘å™¨å·¥ç¨‹ï¼Œè€Œ Astra é€šè¿‡è‡ªåŠ¨åŒ–æ‰‹æ®µè§£å†³äº†è¿™ä¸€éš¾é¢˜ã€‚ä¸åŒäºä»¥å¾€å°† PyTorch æ¨¡å—è½¬åŒ–ä¸ºä»£ç çš„æ–¹æ³•ï¼ŒAstra ç›´æ¥ä» SGLang æ¡†æ¶ä¸­æå–ç°æœ‰çš„ CUDA å®ç°ä½œä¸ºèµ·ç‚¹è¿›è¡Œä¼˜åŒ–ã€‚ç³»ç»Ÿåˆ©ç”¨ä¸“é—¨çš„ LLM æ™ºèƒ½ä½“åœ¨ä»£ç ç”Ÿæˆã€æµ‹è¯•ã€Profiling å’Œè§„åˆ’ä¹‹é—´è¿›è¡Œè¿­ä»£åä½œï¼Œç¡®ä¿ç”Ÿæˆçš„ kernel å…¼é¡¾æ­£ç¡®æ€§ä¸é«˜æ€§èƒ½ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œåœ¨ SGLang ä»»åŠ¡ä¸­ï¼Œé‡‡ç”¨ OpenAI o4-mini è¿›è¡Œé›¶æ ·æœ¬æç¤º(Zero-shot prompting)çš„ Astra å®ç°äº†å¹³å‡ 1.32 å€çš„åŠ é€Ÿã€‚æ­¤å¤–ï¼Œç ”ç©¶è¯æ˜äº† LLM èƒ½å¤Ÿè‡ªä¸»åº”ç”¨å¾ªç¯å˜æ¢(Loop transformations)ã€ä¼˜åŒ–å†…å­˜è®¿é—®æ¨¡å¼(Memory access patterns)å¹¶åˆ©ç”¨ CUDA intrinsics ç­‰æŠ€æœ¯æ¥æ˜¾è‘—æå‡æ€§èƒ½ã€‚è¿™é¡¹å·¥ä½œå‡¸æ˜¾äº†å¤šæ™ºèƒ½ä½“ LLM ç³»ç»Ÿä½œä¸º GPU kernel ä¼˜åŒ–æ–°èŒƒå¼çš„å·¨å¤§æ½œåŠ›ã€‚",
      "categories": [
        "cs.DC",
        "cs.AI",
        "cs.CL",
        "cs.LG",
        "cs.SE"
      ],
      "primary_category": "cs.DC",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.07506v2",
      "published_date": "2025-09-09 08:39:50 UTC",
      "updated_date": "2025-12-02 21:26:24 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:31:21.039399+00:00"
    },
    {
      "arxiv_id": "2509.07495v1",
      "title": "Generating Transferrable Adversarial Examples via Local Mixing and Logits Optimization for Remote Sensing Object Recognition",
      "title_zh": "åŸºäºå±€éƒ¨æ··åˆä¸ Logits ä¼˜åŒ–çš„é¥æ„Ÿç›®æ ‡è¯†åˆ«å¯è¿ç§»å¯¹æŠ—æ ·æœ¬ç”Ÿæˆ",
      "authors": [
        "Chun Liu",
        "Hailong Wang",
        "Bingqian Zhu",
        "Panpan Ding",
        "Zheng Zheng",
        "Tao Xu",
        "Zhigang Han",
        "Jiayao Wang"
      ],
      "abstract": "Deep Neural Networks (DNNs) are vulnerable to adversarial attacks, posing significant security threats to their deployment in remote sensing applications. Research on adversarial attacks not only reveals model vulnerabilities but also provides critical insights for enhancing robustness. Although current mixing-based strategies have been proposed to increase the transferability of adversarial examples, they either perform global blending or directly exchange a region in the images, which may destroy global semantic features and mislead the optimization of adversarial examples. Furthermore, their reliance on cross-entropy loss for perturbation optimization leads to gradient diminishing during iterative updates, compromising adversarial example quality. To address these limitations, we focus on non-targeted attacks and propose a novel framework via local mixing and logits optimization. First, we present a local mixing strategy to generate diverse yet semantically consistent inputs. Different from MixUp, which globally blends two images, and MixCut, which stitches images together, our method merely blends local regions to preserve global semantic information. Second, we adapt the logit loss from targeted attacks to non-targeted scenarios, mitigating the gradient vanishing problem of cross-entropy loss. Third, a perturbation smoothing loss is applied to suppress high-frequency noise and enhance transferability. Extensive experiments on FGSCR-42 and MTARSI datasets demonstrate superior performance over 12 state-of-the-art methods across 6 surrogate models. Notably, with ResNet as the surrogate on MTARSI, our method achieves a 17.28% average improvement in black-box attack success rate.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹é¥æ„Ÿç›®æ ‡è¯†åˆ«ä»»åŠ¡ä¸­æ·±åº¦ç¥ç»ç½‘ç»œ(DNNs)æ˜“å—å¯¹æŠ—æ ·æœ¬(Adversarial Examples)æ”»å‡»çš„å®‰å…¨å¨èƒï¼ŒæŒ‡å‡ºäº†ç°æœ‰åŸºäºæ··åˆ(Mixing-based)ç­–ç•¥åœ¨ä¿æŒå…¨å±€è¯­ä¹‰ç‰¹å¾å’Œæ‰°åŠ¨ä¼˜åŒ–æ–¹é¢çš„å±€é™æ€§ã€‚ä½œè€…æå‡ºäº†ä¸€ç§ç»“åˆå±€éƒ¨æ··åˆ(Local Mixing)ä¸é€»è¾‘å€¼ä¼˜åŒ–(Logits Optimization)çš„æ–°å‹éå®šå‘æ”»å‡»æ¡†æ¶ã€‚è¯¥æ¡†æ¶å¼•å…¥å±€éƒ¨æ··åˆç­–ç•¥ï¼Œé€šè¿‡ä»…åœ¨å±€éƒ¨åŒºåŸŸè¿›è¡Œå›¾åƒèåˆæ¥ç”Ÿæˆå¤šæ ·åŒ–ä¸”è¯­ä¹‰ä¸€è‡´çš„è¾“å…¥ï¼Œä»è€Œå…‹æœäº†MixUpæˆ–MixCutç ´åå…¨å±€è¯­ä¹‰ä¿¡æ¯çš„ç¼ºé™·ã€‚ç ”ç©¶è¿›ä¸€æ­¥å°†é€»è¾‘å€¼æŸå¤±(Logit Loss)ä»å®šå‘æ”»å‡»é€‚é…è‡³éå®šå‘åœºæ™¯ï¼Œæœ‰æ•ˆç¼“è§£äº†äº¤å‰ç†µæŸå¤±åœ¨è¿­ä»£æ›´æ–°è¿‡ç¨‹ä¸­çš„æ¢¯åº¦æ¶ˆå¤±é—®é¢˜ï¼Œå¹¶é…åˆæ‰°åŠ¨å¹³æ»‘æŸå¤±(Perturbation Smoothing Loss)å¢å¼ºäº†æ ·æœ¬çš„è¿ç§»æ€§(Transferability)ã€‚åœ¨FGSCR-42å’ŒMTARSIæ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨6ä¸ªä»£ç†æ¨¡å‹ä¸Šçš„æ€§èƒ½ä¼˜äº12ç§æœ€å…ˆè¿›çš„æ–¹æ³•ã€‚ç‰¹åˆ«æ˜¯åœ¨MTARSIæ•°æ®é›†ä¸Šä»¥ResNetä½œä¸ºä»£ç†æ¨¡å‹æ—¶ï¼Œè¯¥æ–¹æ³•å°†é»‘ç›’æ”»å‡»æˆåŠŸç‡å¹³å‡æå‡äº†17.28%ï¼Œä¸ºæ„å»ºæ›´ç¨³å¥çš„é¥æ„Ÿåº”ç”¨æ¨¡å‹æä¾›äº†å…³é”®è§è§£ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.07495v1",
      "published_date": "2025-09-09 08:20:19 UTC",
      "updated_date": "2025-09-09 08:20:19 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:31:24.442025+00:00"
    },
    {
      "arxiv_id": "2509.07488v1",
      "title": "Fine-Tuning Vision-Language Models for Visual Navigation Assistance",
      "title_zh": "é¢å‘è§†è§‰å¯¼èˆªè¾…åŠ©çš„è§†è§‰-è¯­è¨€æ¨¡å‹å¾®è°ƒ",
      "authors": [
        "Xiao Li",
        "Bharat Gandhi",
        "Ming Zhan",
        "Mohit Nehra",
        "Zhicheng Zhang",
        "Yuchen Sun",
        "Meijia Song",
        "Naisheng Zhang",
        "Xi Wang"
      ],
      "abstract": "We address vision-language-driven indoor navigation to assist visually impaired individuals in reaching a target location using images and natural language guidance. Traditional navigation systems are ineffective indoors due to the lack of precise location data. Our approach integrates vision and language models to generate step-by-step navigational instructions, enhancing accessibility and independence. We fine-tune the BLIP-2 model with Low Rank Adaptation (LoRA) on a manually annotated indoor navigation dataset. We propose an evaluation metric that refines the BERT F1 score by emphasizing directional and sequential variables, providing a more comprehensive measure of navigational performance. After applying LoRA, the model significantly improved in generating directional instructions, overcoming limitations in the original BLIP-2 model.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å®¤å†…ç¯å¢ƒä¸‹ä¼ ç»Ÿå¯¼èˆªç³»ç»Ÿå› ç¼ºä¹ç²¾ç¡®ä½ç½®æ•°æ®è€Œå¤±æ•ˆçš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§åˆ©ç”¨è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVision-Language Modelsï¼‰è¾…åŠ©è§†éšœäººå£«è¿›è¡Œå®¤å†…å¯¼èˆªçš„æ–¹æ³•ã€‚é€šè¿‡åœ¨äººå·¥æ ‡æ³¨çš„å®¤å†…å¯¼èˆªæ•°æ®é›†ä¸Šåˆ©ç”¨LoRAï¼ˆLow Rank Adaptationï¼‰æŠ€æœ¯å¯¹BLIP-2æ¨¡å‹è¿›è¡Œå¾®è°ƒï¼Œè¯¥ç³»ç»Ÿèƒ½å¤Ÿç”Ÿæˆåˆ†æ­¥å¯¼èˆªæŒ‡ä»¤ï¼Œæ˜¾è‘—æå‡äº†ç”¨æˆ·çš„å¯è¾¾æ€§ä¸ç‹¬ç«‹æ€§ã€‚æ­¤å¤–ï¼Œç ”ç©¶è€…æå‡ºäº†ä¸€ç§æ–°çš„è¯„ä¼°æŒ‡æ ‡ï¼Œè¯¥æŒ‡æ ‡é€šè¿‡å¼ºè°ƒæ–¹å‘æ€§å’Œé¡ºåºå˜é‡å¯¹BERT F1åˆ†æ•°è¿›è¡Œäº†ä¼˜åŒ–ï¼Œä»è€Œæ›´å…¨é¢åœ°è¡¡é‡å¯¼èˆªæ€§èƒ½ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œåº”ç”¨LoRAåï¼Œæ¨¡å‹åœ¨ç”Ÿæˆæ–¹å‘æ€§æŒ‡ä»¤æ–¹é¢çš„èƒ½åŠ›æ˜¾è‘—å¢å¼ºï¼Œæœ‰æ•ˆå¼¥è¡¥äº†åŸå§‹BLIP-2æ¨¡å‹çš„å±€é™æ€§ï¼Œä¸ºå®¤å†…å¯¼èˆªè¾…åŠ©æä¾›äº†æ›´å¯é çš„æŠ€æœ¯æ”¯æŒã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.07488v1",
      "published_date": "2025-09-09 08:08:35 UTC",
      "updated_date": "2025-09-09 08:08:35 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:31:28.545617+00:00"
    },
    {
      "arxiv_id": "2509.07475v1",
      "title": "HALT-RAG: A Task-Adaptable Framework for Hallucination Detection with Calibrated NLI Ensembles and Abstention",
      "title_zh": "HALT-RAGï¼šä¸€ç§åŸºäºæ ¡å‡† NLI é›†æˆä¸å¼ƒæƒæœºåˆ¶çš„ä»»åŠ¡è‡ªé€‚åº”å¹»è§‰æ£€æµ‹æ¡†æ¶",
      "authors": [
        "Saumya Goswami",
        "Siddharth Kurra"
      ],
      "abstract": "Detecting content that contradicts or is unsupported by a given source text is a critical challenge for the safe deployment of generative language models. We introduce HALT-RAG, a post-hoc verification system designed to identify hallucinations in the outputs of Retrieval-Augmented Generation (RAG) pipelines. Our flexible and task-adaptable framework uses a universal feature set derived from an ensemble of two frozen, off-the-shelf Natural Language Inference (NLI) models and lightweight lexical signals. These features are used to train a simple, calibrated, and task-adapted meta-classifier. Using a rigorous 5-fold out-of-fold (OOF) training protocol to prevent data leakage and produce unbiased estimates, we evaluate our system on the HaluEval benchmark. By pairing our universal feature set with a lightweight, task-adapted classifier and a precision-constrained decision policy, HALT-RAG achieves strong OOF F1-scores of 0.7756, 0.9786, and 0.7391 on the summarization, QA, and dialogue tasks, respectively. The system's well-calibrated probabilities enable a practical abstention mechanism, providing a reliable tool for balancing model performance with safety requirements.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†HALT-RAGï¼Œä¸€ç§æ—¨åœ¨è¯†åˆ«æ£€ç´¢å¢å¼ºç”Ÿæˆ(Retrieval-Augmented Generation, RAG)æµæ°´çº¿è¾“å‡ºä¸­å¹»è§‰çš„äº‹åéªŒè¯æ¡†æ¶ã€‚è¯¥ç³»ç»Ÿé€šè¿‡é›†æˆä¸¤ä¸ªå†»ç»“çš„ç¦»çº¿è‡ªç„¶è¯­è¨€æ¨ç†(Natural Language Inference, NLI)æ¨¡å‹å’Œè½»é‡çº§è¯æ±‡ä¿¡å·æå–é€šç”¨ç‰¹å¾ï¼Œå¹¶æ®æ­¤è®­ç»ƒäº†ä¸€ä¸ªç»è¿‡æ ¡å‡†çš„ä»»åŠ¡è‡ªé€‚åº”å…ƒåˆ†ç±»å™¨(meta-classifier)ã€‚ä¸ºäº†é˜²æ­¢æ•°æ®æ³„éœ²å¹¶äº§ç”Ÿæ— åä¼°è®¡ï¼Œç ”ç©¶é‡‡ç”¨äº†ä¸¥è°¨çš„äº”æŠ˜äº¤å‰éªŒè¯(5-fold out-of-fold, OOF)è®­ç»ƒåè®®ï¼Œå¹¶åœ¨HaluEvalåŸºå‡†æµ‹è¯•ä¸­è¿›è¡Œäº†è¯„ä¼°ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œç»“åˆç²¾åº¦å—é™çš„å†³ç­–ç­–ç•¥ï¼ŒHALT-RAGåœ¨æ‘˜è¦ã€é—®ç­”å’Œå¯¹è¯ä»»åŠ¡ä¸Šåˆ†åˆ«å–å¾—äº†0.7756ã€0.9786å’Œ0.7391çš„F1åˆ†æ•°ã€‚æ­¤å¤–ï¼Œè¯¥ç³»ç»Ÿç”Ÿæˆçš„è‰¯å¥½æ ¡å‡†æ¦‚ç‡æ”¯æŒå®ç”¨çš„å¼ƒæƒæœºåˆ¶(abstention mechanism)ï¼Œä¸ºåœ¨å®é™…éƒ¨ç½²ä¸­å¹³è¡¡æ¨¡å‹æ€§èƒ½ä¸å®‰å…¨æ€§æä¾›äº†å¯é çš„ä¿éšœã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.07475v1",
      "published_date": "2025-09-09 07:58:46 UTC",
      "updated_date": "2025-09-09 07:58:46 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:31:37.350649+00:00"
    },
    {
      "arxiv_id": "2509.07473v1",
      "title": "SheetDesigner: MLLM-Powered Spreadsheet Layout Generation with Rule-Based and Vision-Based Reflection",
      "title_zh": "SheetDesignerï¼šåŸºäºè§„åˆ™ä¸è§†è§‰åæ€çš„å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹é©±åŠ¨ç”µå­è¡¨æ ¼å¸ƒå±€ç”Ÿæˆ",
      "authors": [
        "Qin Chen",
        "Yuanyi Ren",
        "Xiaojun Ma",
        "Mugeng Liu",
        "Han Shi",
        "Dongmei Zhang"
      ],
      "abstract": "Spreadsheets are critical to data-centric tasks, with rich, structured layouts that enable efficient information transmission. Given the time and expertise required for manual spreadsheet layout design, there is an urgent need for automated solutions. However, existing automated layout models are ill-suited to spreadsheets, as they often (1) treat components as axis-aligned rectangles with continuous coordinates, overlooking the inherently discrete, grid-based structure of spreadsheets; and (2) neglect interrelated semantics, such as data dependencies and contextual links, unique to spreadsheets. In this paper, we first formalize the spreadsheet layout generation task, supported by a seven-criterion evaluation protocol and a dataset of 3,326 spreadsheets. We then introduce SheetDesigner, a zero-shot and training-free framework using Multimodal Large Language Models (MLLMs) that combines rule and vision reflection for component placement and content population. SheetDesigner outperforms five baselines by at least 22.6\\%. We further find that through vision modality, MLLMs handle overlap and balance well but struggle with alignment, necessitates hybrid rule and visual reflection strategies. Our codes and data is available at Github.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç”µå­è¡¨æ ¼å¸ƒå±€è®¾è®¡è€—æ—¶ä¸”ç°æœ‰æ¨¡å‹éš¾ä»¥å¤„ç†å…¶ç¦»æ•£ç½‘æ ¼ç»“æ„ä¸è¯­ä¹‰ä¾èµ–çš„é—®é¢˜ï¼Œæ­£å¼å®šä¹‰äº†ç”µå­è¡¨æ ¼å¸ƒå±€ç”Ÿæˆä»»åŠ¡ï¼Œå¹¶æä¾›äº†åŒ…å«3,326ä¸ªè¡¨æ ¼çš„æ•°æ®é›†å’Œä¸ƒé¡¹è¯„ä¼°å‡†åˆ™ã€‚ç ”ç©¶æå‡ºçš„ SheetDesigner æ˜¯ä¸€ä¸ªåŸºäºå¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ (MLLMs) çš„é›¶æ ·æœ¬ (zero-shot) ä¸”æ— éœ€è®­ç»ƒçš„æ¡†æ¶ï¼Œå®ƒç»“åˆäº†åŸºäºè§„åˆ™ (rule-based) å’ŒåŸºäºè§†è§‰ (vision-based) çš„åå°„ (reflection) æœºåˆ¶ï¼Œç”¨äºè‡ªåŠ¨åŒ–çš„ç»„ä»¶æ”¾ç½®å’Œå†…å®¹å¡«å……ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒSheetDesigner çš„è¡¨ç°ä¼˜äºäº”ä¸ªåŸºçº¿æ¨¡å‹è‡³å°‘ 22.6%ã€‚ç ”ç©¶è¿›ä¸€æ­¥å‘ç°ï¼Œè™½ç„¶ MLLMs åˆ©ç”¨è§†è§‰æ¨¡æ€èƒ½è¾ƒå¥½åœ°å¤„ç†å¸ƒå±€é‡å ä¸å¹³è¡¡ï¼Œä½†åœ¨ç²¾ç¡®å¯¹é½ä¸Šä»æœ‰å›°éš¾ï¼Œå› æ­¤é‡‡ç”¨æ··åˆè§„åˆ™ä¸è§†è§‰çš„åå°„ç­–ç•¥è‡³å…³é‡è¦ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted to EMNLP 2025 Main Conference",
      "pdf_url": "https://arxiv.org/pdf/2509.07473v1",
      "published_date": "2025-09-09 07:51:38 UTC",
      "updated_date": "2025-09-09 07:51:38 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:31:39.746387+00:00"
    },
    {
      "arxiv_id": "2509.07463v2",
      "title": "DepthVision: Enabling Robust Vision-Language Models with GAN-Based LiDAR-to-RGB Synthesis for Autonomous Driving",
      "title_zh": "DepthVisionï¼šåˆ©ç”¨åŸºäºGANçš„LiDARè‡³RGBå›¾åƒåˆæˆå®ç°è‡ªåŠ¨é©¾é©¶ä¸­çš„é²æ£’è§†è§‰-è¯­è¨€æ¨¡å‹",
      "authors": [
        "Sven Kirchner",
        "Nils Purschke",
        "Ross Greer",
        "Alois C. Knoll"
      ],
      "abstract": "Ensuring reliable autonomous operation when visual input is degraded remains a key challenge in intelligent vehicles and robotics. We present DepthVision, a multimodal framework that enables Vision--Language Models (VLMs) to exploit LiDAR data without any architectural changes or retraining. DepthVision synthesizes dense, RGB-like images from sparse LiDAR point clouds using a conditional GAN with an integrated refiner, and feeds these into off-the-shelf VLMs through their standard visual interface. A Luminance-Aware Modality Adaptation (LAMA) module fuses synthesized and real camera images by dynamically weighting each modality based on ambient lighting, compensating for degradation such as darkness or motion blur. This design turns LiDAR into a drop-in visual surrogate when RGB becomes unreliable, effectively extending the operational envelope of existing VLMs. We evaluate DepthVision on real and simulated datasets across multiple VLMs and safety-critical tasks, including vehicle-in-the-loop experiments. The results show substantial improvements in low-light scene understanding over RGB-only baselines while preserving full compatibility with frozen VLM architectures. These findings demonstrate that LiDAR-guided RGB synthesis is a practical pathway for integrating range sensing into modern vision-language systems for autonomous driving.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†DepthVisionï¼Œè¿™æ˜¯ä¸€ç§æ—¨åœ¨æå‡è‡ªåŠ¨é©¾é©¶é¢†åŸŸVision-Language Models (VLMs) é²æ£’æ€§çš„å¤šæ¨¡æ€æ¡†æ¶ï¼Œä¸“é—¨åº”å¯¹ç¯å¢ƒå…‰çº¿é€€åŒ–å¸¦æ¥çš„æŒ‘æˆ˜ã€‚è¯¥æ¡†æ¶åˆ©ç”¨å¸¦æœ‰é›†æˆç²¾ç‚¼å™¨çš„conditional GANå°†ç¨€ç–çš„LiDARç‚¹äº‘åˆæˆä¸ºç¨ å¯†çš„ç±»RGBå›¾åƒï¼Œä»è€Œä½¿ç°æˆçš„VLMsæ— éœ€é‡æ–°è®­ç»ƒæˆ–æ›´æ”¹æ¶æ„å³å¯ç›´æ¥åˆ©ç”¨LiDARæ•°æ®ã€‚é€šè¿‡å†…ç½®çš„Luminance-Aware Modality Adaptation (LAMA) æ¨¡å—ï¼Œæ¡†æ¶èƒ½å¤Ÿæ ¹æ®ç¯å¢ƒå…‰çº¿åŠ¨æ€åŠ æƒèåˆåˆæˆå›¾åƒä¸çœŸå®ç›¸æœºå›¾åƒï¼Œæœ‰æ•ˆå¼¥è¡¥äº†é»‘æš—æˆ–è¿åŠ¨æ¨¡ç³Šå¯¼è‡´çš„è§†è§‰ä¿¡æ¯ç¼ºå¤±ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒDepthVisionåœ¨ä½å…‰ç…§åœºæ™¯ä¸‹çš„ç†è§£èƒ½åŠ›æ˜¾è‘—ä¼˜äºä»…ä½¿ç”¨RGBå›¾åƒçš„åŸºçº¿æ¨¡å‹ï¼Œå¹¶ä¿æŒäº†ä¸å†»ç»“VLMæ¶æ„çš„å®Œå…¨å…¼å®¹ã€‚è¯¥ç ”ç©¶è¯æ˜äº†LiDARå¼•å¯¼çš„RGBåˆæˆæŠ€æœ¯æ˜¯å°†æ·±åº¦æ„Ÿæµ‹é›†æˆåˆ°ç°ä»£è§†è§‰è¯­è¨€ç³»ç»Ÿä¸­çš„å®ç”¨è·¯å¾„ï¼Œæ˜¾è‘—æ‰©å±•äº†è‡ªåŠ¨é©¾é©¶ç³»ç»Ÿçš„è¿è¡Œè¾¹ç•Œã€‚",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.07463v2",
      "published_date": "2025-09-09 07:42:07 UTC",
      "updated_date": "2025-11-18 13:49:21 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:31:40.240132+00:00"
    },
    {
      "arxiv_id": "2509.07456v1",
      "title": "Bias-Aware Machine Unlearning: Towards Fairer Vision Models via Controllable Forgetting",
      "title_zh": "åè§æ„ŸçŸ¥æœºå™¨é—å¿˜ï¼šé€šè¿‡å¯æ§é—å¿˜æ„å»ºæ›´å…¬å¹³çš„è§†è§‰æ¨¡å‹",
      "authors": [
        "Sai Siddhartha Chary Aylapuram",
        "Veeraraju Elluru",
        "Shivang Agarwal"
      ],
      "abstract": "Deep neural networks often rely on spurious correlations in training data, leading to biased or unfair predictions in safety-critical domains such as medicine and autonomous driving. While conventional bias mitigation typically requires retraining from scratch or redesigning data pipelines, recent advances in machine unlearning provide a promising alternative for post-hoc model correction. In this work, we investigate \\textit{Bias-Aware Machine Unlearning}, a paradigm that selectively removes biased samples or feature representations to mitigate diverse forms of bias in vision models. Building on privacy-preserving unlearning techniques, we evaluate various strategies including Gradient Ascent, LoRA, and Teacher-Student distillation. Through empirical analysis on three benchmark datasets, CUB-200-2011 (pose bias), CIFAR-10 (synthetic patch bias), and CelebA (gender bias in smile detection), we demonstrate that post-hoc unlearning can substantially reduce subgroup disparities, with improvements in demographic parity of up to \\textbf{94.86\\%} on CUB-200, \\textbf{30.28\\%} on CIFAR-10, and \\textbf{97.37\\%} on CelebA. These gains are achieved with minimal accuracy loss and with methods scoring an average of 0.62 across the 3 settings on the joint evaluation of utility, fairness, quality, and privacy. Our findings establish machine unlearning as a practical framework for enhancing fairness in deployed vision systems without necessitating full retraining.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº† Bias-Aware Machine Unlearning è¿™ä¸€èŒƒå¼ï¼Œæ—¨åœ¨é€šè¿‡ Controllable Forgetting æ¥æ„å»ºæ›´å…¬å¹³çš„è§†è§‰æ¨¡å‹ï¼Œè§£å†³æ·±åº¦ç¥ç»ç½‘ç»œå› ä¾èµ– Spurious Correlations è€Œäº§ç”Ÿçš„é¢„æµ‹åè§ã€‚ç ”ç©¶è€…æå‡ºé€šè¿‡é€‰æ‹©æ€§åœ°ç§»é™¤åè§æ ·æœ¬æˆ–ç‰¹å¾è¡¨ç¤ºæ¥è¿›è¡Œæ¨¡å‹åéªŒä¿®æ­£ï¼Œå¹¶ç³»ç»Ÿè¯„ä¼°äº† Gradient Ascentã€LoRA ä»¥åŠ Teacher-Student distillation ç­‰å¤šç§å®ç°ç­–ç•¥ã€‚åœ¨ CUB-200-2011ã€CIFAR-10 å’Œ CelebA ç­‰åŸºå‡†æ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨ä¿æŒé«˜å‡†ç¡®ç‡çš„åŒæ—¶æ˜¾è‘—é™ä½äº†å­ç¾¤ä½“å·®å¼‚ï¼Œå…¶ä¸­åœ¨ Demographic Parity æŒ‡æ ‡ä¸Šæœ€é«˜å®ç°äº† 97.37% çš„æå‡ã€‚ç ”ç©¶ç»“æœè¯æ˜äº† Machine Unlearning æ˜¯å¢å¼ºå·²éƒ¨ç½²è§†è§‰ç³»ç»Ÿå…¬å¹³æ€§ä¸”æ— éœ€é‡æ–°è®­ç»ƒçš„å®ç”¨æ¡†æ¶ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted for publication at ICCV 2025 UnMe workshop",
      "pdf_url": "https://arxiv.org/pdf/2509.07456v1",
      "published_date": "2025-09-09 07:25:51 UTC",
      "updated_date": "2025-09-09 07:25:51 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:32:15.994567+00:00"
    },
    {
      "arxiv_id": "2509.07445v1",
      "title": "Text2Touch: Tactile In-Hand Manipulation with LLM-Designed Reward Functions",
      "title_zh": "Text2Touchï¼šåŸºäºå¤§è¯­è¨€æ¨¡å‹è®¾è®¡å¥–åŠ±å‡½æ•°çš„è§¦è§‰æ‰‹å†…æ“ä½œ",
      "authors": [
        "Harrison Field",
        "Max Yang",
        "Yijiong Lin",
        "Efi Psomopoulou",
        "David Barton",
        "Nathan F. Lepora"
      ],
      "abstract": "Large language models (LLMs) are beginning to automate reward design for dexterous manipulation. However, no prior work has considered tactile sensing, which is known to be critical for human-like dexterity. We present Text2Touch, bringing LLM-crafted rewards to the challenging task of multi-axis in-hand object rotation with real-world vision based tactile sensing in palm-up and palm-down configurations. Our prompt engineering strategy scales to over 70 environment variables, and sim-to-real distillation enables successful policy transfer to a tactile-enabled fully actuated four-fingered dexterous robot hand. Text2Touch significantly outperforms a carefully tuned human-engineered baseline, demonstrating superior rotation speed and stability while relying on reward functions that are an order of magnitude shorter and simpler. These results illustrate how LLM-designed rewards can significantly reduce the time from concept to deployable dexterous tactile skills, supporting more rapid and scalable multimodal robot learning. Project website: https://hpfield.github.io/text2touch-website",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† Text2Touch æ¡†æ¶ï¼Œæ—¨åœ¨åˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹ (LLMs) è‡ªåŠ¨è®¾è®¡å¥–åŠ±å‡½æ•°ï¼Œä»¥è§£å†³çµå·§æ‰‹æ“ä½œä¸­å…³é”®çš„è§¦è§‰æ„ŸçŸ¥é—®é¢˜ã€‚ç ”ç©¶èšç„¦äºæ‰‹æŒå‘ä¸Šå’Œå‘ä¸‹é…ç½®ä¸‹çš„å¤šè½´æ‰‹å†…ç‰©ä½“æ—‹è½¬ä»»åŠ¡ï¼Œå¹¶ç»“åˆäº† vision-based tactile sensing æŠ€æœ¯ã€‚é€šè¿‡ Prompt Engineering ç­–ç•¥ï¼Œè¯¥æ¡†æ¶èƒ½å¤Ÿå¤„ç†è¶…è¿‡ 70 ä¸ªç¯å¢ƒå˜é‡ï¼Œå¹¶åˆ©ç”¨ Sim-to-Real è’¸é¦æŠ€æœ¯å°†è®­ç»ƒå¥½çš„ç­–ç•¥æˆåŠŸè¿ç§»è‡³çœŸå®çš„å››æŒ‡çµå·§æœºå™¨äººæ‰‹ã€‚å®éªŒç»“æœè¯æ˜ï¼ŒText2Touch åœ¨æ—‹è½¬é€Ÿåº¦å’Œç¨³å®šæ€§ä¸Šæ˜¾è‘—ä¼˜äºäººå·¥è°ƒä¼˜çš„åŸºå‡†æ¨¡å‹ï¼Œä¸”å…¶ç”Ÿæˆçš„å¥–åŠ±å‡½æ•°åœ¨ç®€æ´åº¦ä¸Šæå‡äº†ä¸€ä¸ªæ•°é‡çº§ã€‚è¯¥æˆæœå±•ç¤ºäº† LLM-designed rewards å¦‚ä½•å¤§å¹…ç¼©çŸ­ä»æ¦‚å¿µåˆ°éƒ¨ç½²çµå·§è§¦è§‰æŠ€èƒ½çš„æ—¶é—´ï¼Œæœ‰æ•ˆæ”¯æŒäº†æ›´å¿«é€Ÿä¸”å¯æ‰©å±•çš„ multimodal robot learningã€‚",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "Accepted at CoRL 2025",
      "pdf_url": "https://arxiv.org/pdf/2509.07445v1",
      "published_date": "2025-09-09 07:10:39 UTC",
      "updated_date": "2025-09-09 07:10:39 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:32:36.899595+00:00"
    },
    {
      "arxiv_id": "2509.18104v1",
      "title": "Data Valuation and Selection in a Federated Model Marketplace",
      "title_zh": "è”é‚¦æ¨¡å‹å¸‚åœºä¸­çš„æ•°æ®ä¼°å€¼ä¸é€‰æ‹©",
      "authors": [
        "Wenqian Li",
        "Youjia Yang",
        "Ruoxi Jia",
        "Yan Pang"
      ],
      "abstract": "In the era of Artificial Intelligence (AI), marketplaces have become essential platforms for facilitating the exchange of data products to foster data sharing. Model transactions provide economic solutions in data marketplaces that enhance data reusability and ensure the traceability of data ownership. To establish trustworthy data marketplaces, Federated Learning (FL) has emerged as a promising paradigm to enable collaborative learning across siloed datasets while safeguarding data privacy. However, effective data valuation and selection from heterogeneous sources in the FL setup remain key challenges. This paper introduces a comprehensive framework centered on a Wasserstein-based estimator tailored for FL. The estimator not only predicts model performance across unseen data combinations but also reveals the compatibility between data heterogeneity and FL aggregation algorithms. To ensure privacy, we propose a distributed method to approximate Wasserstein distance without requiring access to raw data. Furthermore, we demonstrate that model performance can be reliably extrapolated under the neural scaling law, enabling effective data selection without full-scale training. Extensive experiments across diverse scenarios, such as label skew, mislabeled, and unlabeled sources, show that our approach consistently identifies high-performing data combinations, paving the way for more reliable FL-based model marketplaces.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹è”é‚¦å­¦ä¹ (Federated Learning)ç¯å¢ƒä¸‹ä»å¼‚æ„æ•°æ®æºè¿›è¡Œæ•°æ®ä¼°å€¼å’Œé€‰æ‹©çš„æŒ‘æˆ˜ï¼Œæå‡ºäº†ä¸€ä¸ªä»¥ Wasserstein-based estimator ä¸ºæ ¸å¿ƒçš„ç»¼åˆæ¡†æ¶ã€‚è¯¥ä¼°è®¡å™¨ä¸ä»…èƒ½é¢„æµ‹ä¸åŒæ•°æ®ç»„åˆä¸‹çš„æ¨¡å‹æ€§èƒ½ï¼Œè¿˜èƒ½æ­ç¤ºæ•°æ®å¼‚æ„æ€§ä¸è”é‚¦å­¦ä¹ èšåˆç®—æ³•ä¹‹é—´çš„å…¼å®¹æ€§ã€‚ä¸ºäº†ä¿æŠ¤éšç§ï¼Œç ”ç©¶æå‡ºäº†ä¸€ç§åˆ†å¸ƒå¼æ–¹æ³•æ¥è¿‘ä¼¼ Wasserstein distanceï¼Œæ— éœ€è®¿é—®åŸå§‹æ•°æ®å³å¯å®Œæˆè¯„ä¼°ã€‚æ­¤å¤–ï¼Œè¯¥æ¡†æ¶åˆ©ç”¨ neural scaling law å¯¹æ¨¡å‹æ€§èƒ½è¿›è¡Œå¯é å¤–æ¨ï¼Œä»è€Œåœ¨æ— éœ€å…¨é‡è®­ç»ƒçš„æƒ…å†µä¸‹å®ç°é«˜æ•ˆçš„æ•°æ®é€‰æ‹©ã€‚åœ¨æ ‡ç­¾åç§»(label skew)ã€è¯¯æ ‡è®°å’Œæœªæ ‡è®°æ•°æ®æºç­‰å¤šç§å¤æ‚åœºæ™¯ä¸‹çš„å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿç¨³å®šåœ°è¯†åˆ«é«˜æ€§èƒ½æ•°æ®ç»„åˆï¼Œä¸ºæ„å»ºæ›´å¯é çš„åŸºäºè”é‚¦å­¦ä¹ çš„æ¨¡å‹å¸‚åœºå¥ å®šäº†åŸºç¡€ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.18104v1",
      "published_date": "2025-09-09 06:45:30 UTC",
      "updated_date": "2025-09-09 06:45:30 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:32:37.482498+00:00"
    },
    {
      "arxiv_id": "2509.07430v2",
      "title": "The Choice of Divergence: A Neglected Key to Mitigating Diversity Collapse in Reinforcement Learning with Verifiable Reward",
      "title_zh": "æ•£åº¦çš„é€‰æ‹©ï¼šç¼“è§£å¯éªŒè¯å¥–åŠ±å¼ºåŒ–å­¦ä¹ ä¸­å¤šæ ·æ€§å´©æºƒçš„è¢«å¿½è§†çš„å…³é”®",
      "authors": [
        "Long Li",
        "Jiaran Hao",
        "Jason Klein Liu",
        "Zhijian Zhou",
        "Yanting Miao",
        "Wei Pang",
        "Xiaoyu Tan",
        "Wei Chu",
        "Zhe Wang",
        "Shirui Pan",
        "Chao Qu",
        "Yuan Qi"
      ],
      "abstract": "A central paradox in fine-tuning Large Language Models (LLMs) with Reinforcement Learning with Verifiable Reward (RLVR) is the frequent degradation of multi-attempt performance (Pass@k) despite improvements in single-attempt accuracy (Pass@1). This is often accompanied by catastrophic forgetting, where models lose previously acquired skills. While various methods have been proposed, the choice and function of the divergence term have been surprisingly unexamined as a proactive solution. We argue that standard RLVR objectives -- both those using the mode-seeking reverse KL-divergence and those forgoing a divergence term entirely -- lack a crucial mechanism for knowledge retention. The reverse-KL actively accelerates this decay by narrowing the policy, while its absence provides no safeguard against the model drifting from its diverse knowledge base. We propose a fundamental shift in perspective: using the divergence term itself as the solution. Our framework, Diversity-Preserving Hybrid RL (DPH-RL), leverages mass-covering f-divergences (like forward-KL and JS-divergence) to function as a rehearsal mechanism. By continuously referencing the initial policy, this approach forces the model to maintain broad solution coverage. Extensive experiments on math and SQL generation demonstrate that DPH-RL not only resolves the Pass@k degradation but improves both Pass@1 and Pass@k in- and out-of-domain. Additionally, DPH-RL is more training-efficient because it computes f-divergence using generator functions, requiring only sampling from the initial policy and no online reference model. Our work highlights a crucial, overlooked axis for improving RLVR, demonstrating that the proper selection of a divergence measure is a powerful tool for building more general and diverse reasoning models.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†åœ¨å¸¦æœ‰å¯éªŒè¯å¥–åŠ±çš„å¼ºåŒ–å­¦ä¹ (RLVR)å¾®è°ƒå¤§è¯­è¨€æ¨¡å‹(LLMs)è¿‡ç¨‹ä¸­ï¼Œå°½ç®¡å•æ¬¡å°è¯•å‡†ç¡®ç‡(Pass@1)æœ‰æ‰€æå‡ï¼Œä½†å¤šæ¬¡å°è¯•æ€§èƒ½(Pass@k)å¾€å¾€ä¸¥é‡ä¸‹é™ä¸”ä¼´éšç¾éš¾æ€§é—å¿˜çš„æ‚–è®ºã€‚ä½œè€…æŒ‡å‡ºï¼Œä¼ ç»Ÿçš„é€†å‘KLæ•£åº¦(reverse-KL)æˆ–å®Œå…¨ç¼ºä¹æ•£åº¦é¡¹æ˜¯å¯¼è‡´å¤šæ ·æ€§å´©æºƒçš„å…³é”®åŸå› ï¼Œå› ä¸ºå®ƒä»¬ä½¿æ¨¡å‹ç­–ç•¥å˜çª„æˆ–æ— æ³•é˜²æ­¢çŸ¥è¯†æ¼‚ç§»ã€‚ä¸ºæ­¤ï¼Œç ”ç©¶æå‡ºäº†Diversity-Preserving Hybrid RL (DPH-RL)æ¡†æ¶ï¼Œæ ¸å¿ƒåœ¨äºåˆ©ç”¨å…·å¤‡è´¨é‡è¦†ç›–(mass-covering)ç‰¹æ€§çš„f-divergencesï¼ˆå¦‚å‰å‘KLå’ŒJSæ•£åº¦ï¼‰ä½œä¸ºä¸€ç§å¤è¿°æœºåˆ¶ã€‚è¯¥æ–¹æ³•é€šè¿‡ä¸æ–­å‚è€ƒåˆå§‹ç­–ç•¥å¼ºåˆ¶æ¨¡å‹ç»´æŒå¹¿æ³›çš„è§£ç©ºé—´è¦†ç›–ï¼Œä¸”ç”±äºæ— éœ€åœ¨çº¿å‚è€ƒæ¨¡å‹ï¼Œå…¶è®­ç»ƒæ•ˆç‡ä¹Ÿæ˜¾è‘—æ›´é«˜ã€‚åœ¨æ•°å­¦å’ŒSQLç”Ÿæˆä»»åŠ¡ä¸Šçš„å®éªŒè¯æ˜ï¼ŒDPH-RLä¸ä»…è§£å†³äº†Pass@ké€€åŒ–é—®é¢˜ï¼Œè¿˜åŒæ—¶æå‡äº†é¢†åŸŸå†…å¤–çš„Pass@1å’ŒPass@kè¡¨ç°ã€‚è¿™é¡¹å·¥ä½œå¼ºè°ƒäº†é€‰æ‹©åˆé€‚çš„æ•£åº¦åº¦é‡æ˜¯æ”¹å–„RLVRæ•ˆæœå¹¶æ„å»ºæ›´å…·é€šç”¨æ€§å’Œå¤šæ ·æ€§æ¨ç†æ¨¡å‹çš„å¼ºå¤§å·¥å…·ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "25 pages, 6 figures",
      "pdf_url": "https://arxiv.org/pdf/2509.07430v2",
      "published_date": "2025-09-09 06:34:32 UTC",
      "updated_date": "2025-10-17 09:26:39 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:33:32.739927+00:00"
    },
    {
      "arxiv_id": "2509.07417v1",
      "title": "Benchmarking Universal Interatomic Potentials on Zeolite Structures",
      "title_zh": "é€šç”¨åŸå­é—´åŠ¿åœ¨æ²¸çŸ³ç»“æ„ä¸Šçš„åŸºå‡†æµ‹è¯•",
      "authors": [
        "Shusuke Ito",
        "Koki Muraoka",
        "Akira Nakayama"
      ],
      "abstract": "Interatomic potentials (IPs) with wide elemental coverage and high accuracy are powerful tools for high-throughput materials discovery. While the past few years witnessed the development of multiple new universal IPs that cover wide ranges of the periodic table, their applicability to target chemical systems should be carefully investigated. We benchmark several universal IPs using equilibrium zeolite structures as testbeds. We select a diverse set of universal IPs encompassing two major categories: (i) universal analytic IPs, including GFN-FF, UFF, and Dreiding; (ii) pretrained universal machine learning IPs (MLIPs), comprising CHGNet, ORB-v3, MatterSim, eSEN-30M-OAM, PFP-v7, and EquiformerV2-lE4-lF100-S2EFS-OC22. We compare them with established tailor-made IPs, SLC, ClayFF, and BSFF using experimental data and density functional theory (DFT) calculations with dispersion correction as the reference. The tested zeolite structures comprise pure silica frameworks and aluminosilicates containing copper species, potassium, and organic cations. We found that GFN-FF is the best among the tested universal analytic IPs, but it does not achieve satisfactory accuracy for highly strained silica rings and aluminosilicate systems. All MLIPs can well reproduce experimental or DFT-level geometries and energetics. Among the universal MLIPs, the eSEN-30M-OAM model shows the most consistent performance across all zeolite structures studied. These findings show that the modern pretrained universal MLIPs are practical tools in zeolite screening workflows involving various compositions.",
      "tldr_zh": "è¯¥ç ”ç©¶åœ¨æ²¸çŸ³ç»“æ„(Zeolite Structures)ä¸Šå¯¹å¤šç§é€šç”¨åŸå­é—´åŠ¿(Interatomic Potentials, IPs)è¿›è¡Œäº†åŸºå‡†æµ‹è¯•ï¼Œæ—¨åœ¨è¯„ä¼°å…¶åœ¨ææ–™å‘ç°ä¸­çš„å‡†ç¡®æ€§ä¸é€‚ç”¨æ€§ã€‚æµ‹è¯•å¯¹æ¯”äº†GFN-FFã€UFFç­‰é€šç”¨è§£æåŠ¿ä»¥åŠCHGNetã€ORB-v3ã€MatterSimã€eSEN-30M-OAMã€PFP-v7ç­‰é¢„è®­ç»ƒé€šç”¨æœºå™¨å­¦ä¹ åŸå­åŠ¿(MLIPs)ï¼Œå¹¶ä»¥å®éªŒæ•°æ®å’Œå¯†åº¦æ³›å‡½ç†è®º(DFT)è®¡ç®—ä½œä¸ºå‚è€ƒåŸºå‡†ã€‚è¯„ä¼°å¯¹è±¡æ¶µç›–äº†çº¯ç¡…éª¨æ¶ä»¥åŠåŒ…å«é“œã€é’¾å’Œæœ‰æœºé˜³ç¦»å­çš„é“ç¡…é…¸ç›ç³»ç»Ÿã€‚å®éªŒå‘ç°ï¼ŒGFN-FFåœ¨é€šç”¨è§£æåŠ¿ä¸­è¡¨ç°æœ€ä¼˜ï¼Œä½†åœ¨é«˜åº¦åº”å˜çš„ç¡…ç¯å’Œé“ç¡…é…¸ç›ç³»ç»Ÿä¸­ç²¾åº¦å—é™ã€‚ä¸ä¹‹ç›¸åï¼Œæ‰€æœ‰MLIPså‡èƒ½å‡†ç¡®é‡ç°å‡ ä½•ç»“æ„ä¸èƒ½é‡ä¿¡æ¯ï¼Œå…¶ä¸­eSEN-30M-OAMæ¨¡å‹åœ¨å„ç±»æ²¸çŸ³ç»“æ„ä¸­å±•ç°å‡ºæœ€ç¨³å®šçš„ä¸€è‡´æ€§ã€‚è¯¥ç ”ç©¶è¯å®äº†ç°ä»£é¢„è®­ç»ƒé€šç”¨MLIPsåœ¨å¤„ç†å¤æ‚æˆåˆ†çš„æ²¸çŸ³ç­›é€‰å·¥ä½œæµç¨‹ä¸­å…·æœ‰æ˜¾è‘—çš„å®ç”¨ä»·å€¼ã€‚",
      "categories": [
        "cond-mat.mtrl-sci",
        "cs.AI",
        "physics.chem-ph"
      ],
      "primary_category": "cond-mat.mtrl-sci",
      "comment": "26 pages, 9 figures",
      "pdf_url": "https://arxiv.org/pdf/2509.07417v1",
      "published_date": "2025-09-09 06:04:40 UTC",
      "updated_date": "2025-09-09 06:04:40 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:32:50.898887+00:00"
    },
    {
      "arxiv_id": "2509.07414v3",
      "title": "Language Self-Play For Data-Free Training",
      "title_zh": "é¢å‘æ— æ•°æ®è®­ç»ƒçš„è¯­è¨€è‡ªæˆ‘åšå¼ˆ",
      "authors": [
        "Jakub Grudzien Kuba",
        "Mengting Gu",
        "Qi Ma",
        "Yuandong Tian",
        "Vijai Mohan",
        "Jason Chen"
      ],
      "abstract": "Large language models (LLMs) have advanced rapidly in recent years, driven by scale, abundant high-quality training data, and reinforcement learning. Yet this progress faces a fundamental bottleneck: the need for ever more data from which models can continue to learn. In this work, we propose a reinforcement learning approach that removes this dependency by enabling models to improve without additional data. Our method leverages a game-theoretic framework of self-play, where a model's capabilities are cast as performance in a competitive game and stronger policies emerge by having the model play against itself-a process we call Language Self-Play (LSP). Experiments with Llama-3.2-3B-Instruct on instruction-following, mathematics, and coding benchmarks show that pretrained models can be effectively improved with self-play alone.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰å‘å±•ä¸­é¢ä¸´çš„é«˜è´¨é‡è®­ç»ƒæ•°æ®çŸ­ç¼ºç“¶é¢ˆï¼Œæå‡ºäº†ä¸€ç§æ— éœ€é¢å¤–æ•°æ®å³å¯å®ç°æ¨¡å‹æ€§èƒ½æå‡çš„å¼ºåŒ–å­¦ä¹ æ–¹æ³•ã€‚ç ”ç©¶è€…å€Ÿé‰´äº†åšå¼ˆè®ºä¸­çš„è‡ªæˆ‘åšå¼ˆæœºåˆ¶ï¼Œæ„å»ºäº†åä¸º Language Self-Play (LSP) çš„æ¡†æ¶ï¼Œå°†æ¨¡å‹èƒ½åŠ›çš„æå‡è½¬åŒ–ä¸ºåœ¨ç«äº‰æ€§åšå¼ˆä¸­è¿½æ±‚æ›´é«˜è¡¨ç°çš„è¿‡ç¨‹ã€‚é€šè¿‡è®©æ¨¡å‹ä¸å…¶è‡ªèº«è¿›è¡Œåšå¼ˆï¼Œç³»ç»Ÿèƒ½å¤Ÿè‡ªå‘æ¶Œç°å‡ºæ›´å¼ºå¤§çš„ Policiesï¼ˆç­–ç•¥ï¼‰ï¼Œä»è€Œæ‘†è„±å¯¹å¤–éƒ¨æ ‡æ³¨æ•°æ®çš„ä¾èµ–ã€‚å®éªŒåœ¨ Llama-3.2-3B-Instruct æ¨¡å‹ä¸Šè¿›è¡Œï¼Œç»“æœæ˜¾ç¤ºè¯¥æ–¹æ³•åœ¨ Instruction-followingï¼ˆæŒ‡ä»¤éµå¾ªï¼‰ã€Mathematicsï¼ˆæ•°å­¦ï¼‰å’Œ Codingï¼ˆç¼–ç¨‹ï¼‰ç­‰åŸºå‡†æµ‹è¯•ä¸­å‡å–å¾—äº†æ˜¾è‘—è¿›æ­¥ã€‚è¿™ä¸€ç ”ç©¶è¯æ˜äº†é¢„è®­ç»ƒæ¨¡å‹ä»…é€šè¿‡ LSP æœºåˆ¶å³å¯å®ç°æœ‰æ•ˆè¿›åŒ–ï¼Œä¸ºè§£å†³ LLMs çš„æ•°æ®ç“¶é¢ˆé—®é¢˜æä¾›äº†ä¸€æ¡åˆ‡å®å¯è¡Œçš„ Data-Freeï¼ˆæ— æ•°æ®ï¼‰è®­ç»ƒè·¯å¾„ã€‚",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.GT"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.07414v3",
      "published_date": "2025-09-09 05:51:34 UTC",
      "updated_date": "2025-12-19 03:05:26 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:32:51.189604+00:00"
    },
    {
      "arxiv_id": "2509.09715v1",
      "title": "Investigating Symbolic Triggers of Hallucination in Gemma Models Across HaluEval and TruthfulQA",
      "title_zh": "æ¢ç©¶ Gemma æ¨¡å‹åœ¨ HaluEval ä¸ TruthfulQA ä»»åŠ¡ä¸­å¹»è§‰çš„ç¬¦å·è§¦å‘å› ç´ ",
      "authors": [
        "Naveen Lamba",
        "Sanju Tiwari",
        "Manas Gaur"
      ],
      "abstract": "Hallucination in Large Language Models (LLMs) is a well studied problem. However, the properties that make LLM intrinsically vulnerable to hallucinations have not been identified and studied. This research identifies and characterizes the key properties, allowing us to pinpoint vulnerabilities within the model's internal mechanisms. To solidify on these properties, we utilized two established datasets, HaluEval and TruthfulQA and convert their existing format of question answering into various other formats to narrow down these properties as the reason for the hallucinations. Our findings reveal that hallucination percentages across symbolic properties are notably high for Gemma-2-2B, averaging 79.0% across tasks and datasets. With increased model scale, hallucination drops to 73.6% for Gemma-2-9B and 63.9% for Gemma-2-27B, reflecting a 15 percentage point reduction overall. Although the hallucination rate decreases as the model size increases, a substantial amount of hallucination caused by symbolic properties still persists. This is especially evident for modifiers (ranging from 84.76% to 94.98%) and named entities (ranging from 83.87% to 93.96%) across all Gemma models and both datasets. These findings indicate that symbolic elements continue to confuse the models, pointing to a fundamental weakness in how these LLMs process such inputs--regardless of their scale.",
      "tldr_zh": "è¯¥ç ”ç©¶è°ƒæŸ¥äº† Gemma æ¨¡å‹åœ¨ HaluEval å’Œ TruthfulQA æ•°æ®é›†ä¸Šçš„ Hallucination ç°è±¡ï¼Œæ—¨åœ¨è¯†åˆ«å¹¶è¡¨å¾å¯¼è‡´æ¨¡å‹å†…åœ¨è„†å¼±æ€§çš„ Symbolic Triggersã€‚ç ”ç©¶é€šè¿‡å°†ç°æœ‰çš„é—®ç­”æ ¼å¼è½¬æ¢ä¸ºå¤šç§å½¢å¼ï¼Œæ·±å…¥æ¢è®¨äº†æ¨¡å‹å†…éƒ¨æœºåˆ¶ä¸­çš„è„†å¼±ç‚¹ã€‚å®éªŒå‘ç°ï¼ŒGemma-2-2B åœ¨å¤„ç† Symbolic å±æ€§æ—¶å¹³å‡ Hallucination æ¯”ä¾‹é«˜è¾¾ 79.0%ã€‚è™½ç„¶éšç€è§„æ¨¡å¢åŠ ï¼ŒGemma-2-9B å’Œ Gemma-2-27B çš„æ¯”ä¾‹åˆ†åˆ«é™è‡³ 73.6% å’Œ 63.9%ï¼Œä½†ç”±ç¬¦å·å±æ€§è¯±å‘çš„é—®é¢˜ä¾ç„¶æ ¹æ·±è’‚å›ºã€‚ç‰¹åˆ«æ˜¯åœ¨æ‰€æœ‰æ¨¡å‹ä¸­ï¼ŒModifiers å¯¼è‡´çš„æ¯”ä¾‹åœ¨ 84.76% åˆ° 94.98% ä¹‹é—´ï¼ŒNamed Entities åˆ™åœ¨ 83.87% åˆ° 93.96% ä¹‹é—´ã€‚è¿™äº›å‘ç°è¡¨æ˜ï¼ŒSymbolic å…ƒç´ ä¼šæŒç»­è¯¯å¯¼æ¨¡å‹ï¼Œæ­ç¤ºäº† LLMs åœ¨å¤„ç†æ­¤ç±»è¾“å…¥æ—¶å­˜åœ¨ä¸€ç§ä¸æ¨¡å‹è§„æ¨¡æ— å…³çš„æ ¹æœ¬æ€§å¼±ç‚¹ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.09715v1",
      "published_date": "2025-09-09 05:50:08 UTC",
      "updated_date": "2025-09-09 05:50:08 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:33:00.597406+00:00"
    },
    {
      "arxiv_id": "2509.07396v1",
      "title": "Toward Lifelong-Sustainable Electronic-Photonic AI Systems via Extreme Efficiency, Reconfigurability, and Robustness",
      "title_zh": "é€šè¿‡æè‡´èƒ½æ•ˆã€å¯é‡æ„æ€§ä¸é²æ£’æ€§æ„å»ºé•¿æ•ˆå¯æŒç»­çš„ç”µå…‰é›†æˆäººå·¥æ™ºèƒ½ç³»ç»Ÿ",
      "authors": [
        "Ziang Yin",
        "Hongjian Zhou",
        "Chetan Choppali Sudarshan",
        "Vidya Chhabria",
        "Jiaqi Gu"
      ],
      "abstract": "The relentless growth of large-scale artificial intelligence (AI) has created unprecedented demand for computational power, straining the energy, bandwidth, and scaling limits of conventional electronic platforms. Electronic-photonic integrated circuits (EPICs) have emerged as a compelling platform for next-generation AI systems, offering inherent advantages in ultra-high bandwidth, low latency, and energy efficiency for computing and interconnection. Beyond performance, EPICs also hold unique promises for sustainability. Fabricated in relaxed process nodes with fewer metal layers and lower defect densities, photonic devices naturally reduce embodied carbon footprint (CFP) compared to advanced digital electronic integrated circuits, while delivering orders-of-magnitude higher computing performance and interconnect bandwidth. To further advance the sustainability of photonic AI systems, we explore how electronic-photonic design automation (EPDA) and cross-layer co-design methodologies can amplify these inherent benefits. We present how advanced EPDA tools enable more compact layout generation, reducing both chip area and metal layer usage. We will also demonstrate how cross-layer device-circuit-architecture co-design unlocks new sustainability gains for photonic hardware: ultra-compact photonic circuit designs that minimize chip area cost, reconfigurable hardware topology that adapts to evolving AI workloads, and intelligent resilience mechanisms that prolong lifetime by tolerating variations and faults. By uniting intrinsic photonic efficiency with EPDA- and co-design-driven gains in area efficiency, reconfigurability, and robustness, we outline a vision for lifelong-sustainable electronic-photonic AI systems. This perspective highlights how EPIC AI systems can simultaneously meet the performance demands of modern AI and the urgent imperative for sustainable computing.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å¦‚ä½•é€šè¿‡æç«¯æ•ˆç‡ã€å¯é‡æ„æ€§å’Œé²æ£’æ€§æ„å»ºç»ˆèº«å¯æŒç»­çš„ç”µå­-å…‰å­äººå·¥æ™ºèƒ½ç³»ç»Ÿ(Electronic-Photonic AI Systems)ã€‚é’ˆå¯¹ä¼ ç»Ÿç”µå­å¹³å°é¢ä¸´çš„èƒ½æºã€å¸¦å®½å’Œç¼©æ”¾é™åˆ¶ï¼Œç”µå­-å…‰å­é›†æˆç”µè·¯(EPICs)å‡­å€Ÿè¶…é«˜å¸¦å®½ã€ä½å»¶è¿Ÿå’Œé«˜èƒ½æ•ˆç­‰ä¼˜åŠ¿ï¼Œæˆä¸ºäº†ä¸‹ä¸€ä»£AIç³»ç»Ÿçš„é‡è¦å¹³å°ã€‚ä¸å…ˆè¿›æ•°å­—ç”µå­é›†æˆç”µè·¯ç›¸æ¯”ï¼Œå…‰å­å™¨ä»¶åœ¨æˆç†Ÿå·¥è‰ºèŠ‚ç‚¹ä¸‹åˆ¶é€ ï¼Œå…·æœ‰æ›´ä½çš„éšå«ç¢³è¶³è¿¹(Embodied Carbon Footprint)ï¼Œä¸”èƒ½æä¾›æ›´é«˜çš„è®¡ç®—æ€§èƒ½ã€‚ç ”ç©¶æå‡ºåˆ©ç”¨ç”µå­-å…‰å­è®¾è®¡è‡ªåŠ¨åŒ–(EPDA)å’Œè·¨å±‚å™¨ä»¶-ç”µè·¯-æ¶æ„ååŒè®¾è®¡(Cross-layer Co-design)æ–¹æ³•ï¼Œå®ç°æ›´ç´§å‡‘çš„å¸ƒå±€å¹¶å‡å°‘èŠ¯ç‰‡é¢ç§¯ä¸é‡‘å±å±‚ä½¿ç”¨ã€‚æ­¤å¤–ï¼Œé€šè¿‡å¼•å…¥å¯é‡æ„ç¡¬ä»¶æ‹“æ‰‘ä»¥é€‚åº”ä¸æ–­æ¼”è¿›çš„AIå·¥ä½œè´Ÿè½½ï¼Œå¹¶åˆ©ç”¨æ™ºèƒ½éŸ§æ€§æœºåˆ¶å¢å¼ºå¯¹åå·®å’Œæ•…éšœçš„å®¹å¿åº¦ï¼Œä»è€Œå»¶é•¿ç³»ç»Ÿå¯¿å‘½ã€‚è¯¥ç ”ç©¶é€šè¿‡ç»“åˆå…‰å­å›ºæœ‰èƒ½æ•ˆä¸è®¾è®¡å±‚é¢çš„ä¼˜åŒ–ï¼Œä¸ºåœ¨æ»¡è¶³ç°ä»£AIæ€§èƒ½éœ€æ±‚çš„åŒæ—¶å®ç°å¯æŒç»­è®¡ç®—ç›®æ ‡æä¾›äº†é‡è¦æ„¿æ™¯ã€‚",
      "categories": [
        "physics.optics",
        "cs.AI",
        "cs.ET"
      ],
      "primary_category": "physics.optics",
      "comment": "8 pages",
      "pdf_url": "https://arxiv.org/pdf/2509.07396v1",
      "published_date": "2025-09-09 05:20:55 UTC",
      "updated_date": "2025-09-09 05:20:55 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:33:04.088063+00:00"
    },
    {
      "arxiv_id": "2509.07392v1",
      "title": "Hybrid GCN-GRU Model for Anomaly Detection in Cryptocurrency Transactions",
      "title_zh": "ç”¨äºåŠ å¯†è´§å¸äº¤æ˜“å¼‚å¸¸æ£€æµ‹çš„æ··åˆ GCN-GRU æ¨¡å‹",
      "authors": [
        "Gyuyeon Na",
        "Minjung Park",
        "Hyeonjeong Cha",
        "Soyoun Kim",
        "Sunyoung Moon",
        "Sua Lee",
        "Jaeyoung Choi",
        "Hyemin Lee",
        "Sangmi Chai"
      ],
      "abstract": "Blockchain transaction networks are complex, with evolving temporal patterns and inter-node relationships. To detect illicit activities, we propose a hybrid GCN-GRU model that captures both structural and sequential features. Using real Bitcoin transaction data (2020-2024), our model achieved 0.9470 Accuracy and 0.9807 AUC-ROC, outperforming all baselines.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹åŠ å¯†è´§å¸äº¤æ˜“ä¸­çš„å¼‚å¸¸æ£€æµ‹é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§æ··åˆçš„ GCN-GRU æ¨¡å‹ï¼Œæ—¨åœ¨åº”å¯¹åŒºå—é“¾äº¤æ˜“ç½‘ç»œä¸­å¤æ‚çš„æ—¶åºæ¼”å˜æ¨¡å¼å’ŒèŠ‚ç‚¹é—´å…³ç³»ã€‚è¯¥æ¨¡å‹é€šè¿‡ç»“åˆå›¾å·ç§¯ç½‘ç»œ (GCN) å’Œé—¨æ§å¾ªç¯å•å…ƒ (GRU)ï¼Œèƒ½å¤ŸåŒæ—¶æ•æ‰äº¤æ˜“æ•°æ®çš„ç»“æ„ç‰¹å¾ä¸åºåˆ—ç‰¹å¾ï¼Œä»è€Œæ›´æœ‰æ•ˆåœ°è¯†åˆ«éæ³•æ´»åŠ¨ã€‚ç ”ç©¶å›¢é˜Ÿåˆ©ç”¨ 2020 å¹´è‡³ 2024 å¹´çš„çœŸå® Bitcoin äº¤æ˜“æ•°æ®å¯¹æ¨¡å‹è¿›è¡Œäº†éªŒè¯ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ¨¡å‹å–å¾—äº† 0.9470 çš„ Accuracy å’Œ 0.9807 çš„ AUC-ROCï¼Œå…¶è¡¨ç°æ˜¾è‘—ä¼˜äºæ‰€æœ‰åŸºçº¿æ¨¡å‹ã€‚è¿™ä¸€æˆæœè¯æ˜äº†ç»“åˆç»“æ„ä¸æ—¶åºç‰¹å¾åœ¨æå‡åŠ å¯†è´§å¸äº¤æ˜“å®‰å…¨æ€§å’Œå¼‚å¸¸æ£€æµ‹ç²¾åº¦æ–¹é¢çš„æ˜¾è‘—ä¼˜åŠ¿ã€‚è¯¥æ–¹æ³•ä¸ºç›‘æµ‹åŒºå—é“¾ä¸­çš„éæ³•é‡‘èè¡Œä¸ºæä¾›äº†ä¸€ç§é«˜æ•ˆä¸”å‡†ç¡®çš„è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.07392v1",
      "published_date": "2025-09-09 05:14:26 UTC",
      "updated_date": "2025-09-09 05:14:26 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:33:08.234942+00:00"
    },
    {
      "arxiv_id": "2509.07389v1",
      "title": "Talking with Oompa Loompas: A novel framework for evaluating linguistic acquisition of LLM agents",
      "title_zh": "ä¸ Oompa Loompas å¯¹è¯ï¼šä¸€ç§è¯„ä¼° LLM æ™ºèƒ½ä½“è¯­è¨€ä¹ å¾—çš„æ–°å‹æ¡†æ¶",
      "authors": [
        "Sankalp Tattwadarshi Swain",
        "Anshika Krishnatray",
        "Dhruv Kumar",
        "Jagat Sesh Challa"
      ],
      "abstract": "Existing evaluation studies on linguistic competence of large language models (LLM agents) have focused primarily on vocabulary learning, morphological rule induction, syntactic generalization, pragmatic inference, and cross-linguistic transfer. However, none assess whether LLM agents can acquire a language through pattern recognition and interactive feedback, a central feature of human language acquisition. We propose a novel experimental framework in which an LLM agent is evaluated on its ability to acquire and use a newly constructed language (Tinkatongue) in conversation with a bot that understands only Tinkatongue. Our findings show that LLM agents fail to establish a conversation within 100 responses, yet they adopt distinct strategies that mirror human approaches to language learning. The results suggest a new direction for evaluation benchmarks and open pathways to model designs that learn more effectively from interactive feedback.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ä¸ªåä¸º \"Talking with Oompa Loompas\" çš„æ–°é¢–å®éªŒæ¡†æ¶ï¼Œæ—¨åœ¨è¯„ä¼°å¤§è¯­è¨€æ¨¡å‹æ™ºèƒ½ä½“ (LLM agents) ä¹ å¾—æ–°è¯­è¨€çš„èƒ½åŠ›ã€‚ç°æœ‰çš„è¯„ä¼°ä¸»è¦é›†ä¸­åœ¨è¯æ±‡å­¦ä¹ ã€è¯­æ³•æ³›åŒ–å’Œè·¨è¯­è¨€è¿ç§»ç­‰é¢†åŸŸï¼Œå´å¿½è§†äº† LLM agents æ˜¯å¦èƒ½åƒäººç±»ä¸€æ ·é€šè¿‡æ¨¡å¼è¯†åˆ«å’Œäº¤äº’å¼åé¦ˆæ¥å­¦ä¹ è¯­è¨€ã€‚ç ”ç©¶è€…æ„å»ºäº†ä¸€ä¸ªåä¸º Tinkatongue çš„æ–°è¯­è¨€ï¼Œå¹¶è¦æ±‚ LLM agents åœ¨ä¸ä»…ç†è§£è¯¥è¯­è¨€çš„æœºå™¨äººå¯¹è¯ä¸­å°è¯•ä¹ å¾—å¹¶ä½¿ç”¨å®ƒã€‚ç»“æœè¡¨æ˜ï¼ŒLLM agents åœ¨ 100 æ¬¡å›å¤å†…æœªèƒ½æˆåŠŸå»ºç«‹å®Œæ•´å¯¹è¯ï¼Œä½†å®ƒä»¬é‡‡å–äº†ä¸äººç±»è¯­è¨€å­¦ä¹ è·¯å¾„ç›¸ä¼¼çš„ç‹¬ç‰¹ç­–ç•¥ã€‚è¿™ä¸€å‘ç°ä¸ºè¯­è¨€èƒ½åŠ›çš„è¯„ä¼°åŸºå‡†æä¾›äº†æ–°è§†è§’ï¼Œå¹¶ä¸ºæœªæ¥é€šè¿‡äº¤äº’å¼åé¦ˆæå‡æ¨¡å‹å­¦ä¹ æ•ˆç‡çš„è®¾è®¡æŒ‡æ˜äº†æ–¹å‘ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.HC",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Under review",
      "pdf_url": "https://arxiv.org/pdf/2509.07389v1",
      "published_date": "2025-09-09 05:09:27 UTC",
      "updated_date": "2025-09-09 05:09:27 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:33:11.933731+00:00"
    },
    {
      "arxiv_id": "2509.13331v1",
      "title": "Explainable AI-Enhanced Supervisory Control for High-Precision Spacecraft Formation",
      "title_zh": "é¢å‘é«˜ç²¾åº¦èˆªå¤©å™¨ç¼–é˜Ÿçš„å¯è§£é‡Šäººå·¥æ™ºèƒ½å¢å¼ºå‹ç›‘ç£æ§åˆ¶",
      "authors": [
        "Reza Pirayeshshirazinezhad"
      ],
      "abstract": "We use artificial intelligence (AI) and supervisory adaptive control systems to plan and optimize the mission of precise spacecraft formation. Machine learning and robust control enhance the efficiency of spacecraft precision formation of the Virtual Telescope for X-ray Observation (VTXO) space mission. VTXO is a precise formation of two separate spacecraft making a virtual telescope with a one-kilometer focal length. One spacecraft carries the lens and the other spacecraft holds the camera to observe high-energy space objects in the X-ray domain with 55 milli-arcsecond angular resolution accuracy. Timed automata for supervisory control, Monte Carlo simulations for stability and robustness evaluation, and integration of deep neural networks for optimal estimation of mission parameters, satisfy the high precision mission criteria. We integrate deep neural networks with a constrained, non-convex dynamic optimization pipeline to predict optimal mission parameters, ensuring precision mission criteria are met. AI framework provides explainability by predicting the resulting energy consumption and mission error for a given set of mission parameters. It allows for transparent, justifiable, and real-time trade-offs, a capability not present in traditional adaptive controllers. The results show reductions in energy consumption and improved mission accuracy, demonstrating the capability of the system to address dynamic uncertainties and disturbances.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†ç”¨äºé«˜ç²¾åº¦èˆªå¤©å™¨ç¼–é˜Ÿ (Spacecraft Formation) çš„å¯è§£é‡Šäººå·¥æ™ºèƒ½å¢å¼ºç›‘æ§æ§åˆ¶ç³»ç»Ÿï¼Œæ—¨åœ¨ä¼˜åŒ– X-ray è§‚æµ‹è™šæ‹Ÿæœ›è¿œé•œ (VTXO) ä»»åŠ¡ã€‚VTXO ä»»åŠ¡è¦æ±‚ä¸¤ä¸ªèˆªå¤©å™¨åœ¨ 1 å…¬é‡Œç„¦è·ä¸‹å®ç° 55 æ¯«è§’ç§’ (milli-arcsecond) çš„è§’åˆ†è¾¨ç‡ï¼Œå¯¹ç¼–é˜Ÿç²¾åº¦è¦æ±‚æé«˜ã€‚ä¸ºæ­¤ï¼Œç ”ç©¶é›†æˆäº†ç”¨äºç›‘æ§æ§åˆ¶çš„æ—¶é—´è‡ªåŠ¨æœº (Timed Automata)ã€ç”¨äºç¨³å®šæ€§è¯„ä¼°çš„è’™ç‰¹å¡æ´›æ¨¡æ‹Ÿ (Monte Carlo simulations) ä»¥åŠç”¨äºå‚æ•°ä¼°è®¡çš„æ·±åº¦ç¥ç»ç½‘ç»œ (Deep Neural Networks)ã€‚è¯¥æ¡†æ¶é€šè¿‡ç»“åˆæ·±åº¦ç¥ç»ç½‘ç»œä¸å—çº¦æŸçš„éå‡¸åŠ¨æ€ä¼˜åŒ– (non-convex dynamic optimization) æµç¨‹æ¥é¢„æµ‹æœ€ä¼˜ä»»åŠ¡å‚æ•°ï¼Œç¡®ä¿æ»¡è¶³ç²¾åº¦æ ‡å‡†ã€‚ç›¸æ¯”ä¼ ç»Ÿè‡ªé€‚åº”æ§åˆ¶å™¨ï¼Œè¯¥ AI æ¡†æ¶èƒ½é€šè¿‡é¢„æµ‹èƒ½è€—å’Œä»»åŠ¡è¯¯å·®æä¾›å¯è§£é‡Šæ€§ (Explainability)ï¼Œä»è€Œå®ç°é€æ˜ä¸”å®æ—¶çš„ä»»åŠ¡æƒè¡¡ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥ç³»ç»Ÿæ˜¾è‘—é™ä½äº†èƒ½æºæ¶ˆè€—å¹¶æå‡äº†ä»»åŠ¡ç²¾åº¦ï¼Œå±•ç¤ºäº†å…¶åœ¨å¤„ç†åŠ¨æ€ä¸ç¡®å®šæ€§å’Œæ‰°åŠ¨æ–¹é¢çš„å¼ºå¤§é²æ£’æ€§ã€‚",
      "categories": [
        "astro-ph.IM",
        "cs.AI",
        "cs.RO",
        "eess.SY"
      ],
      "primary_category": "astro-ph.IM",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.13331v1",
      "published_date": "2025-09-09 04:41:18 UTC",
      "updated_date": "2025-09-09 04:41:18 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:33:22.446643+00:00"
    },
    {
      "arxiv_id": "2509.07373v1",
      "title": "SBS: Enhancing Parameter-Efficiency of Neural Representations for Neural Networks via Spectral Bias Suppression",
      "title_zh": "SBSï¼šåˆ©ç”¨é¢‘è°±åå·®æŠ‘åˆ¶æå‡ç¥ç»ç½‘ç»œç¥ç»è¡¨ç¤ºçš„å‚æ•°æ•ˆç‡",
      "authors": [
        "Qihu Xie",
        "Yuan Li",
        "Yi Kang"
      ],
      "abstract": "Implicit neural representations have recently been extended to represent convolutional neural network weights via neural representation for neural networks, offering promising parameter compression benefits. However, standard multi-layer perceptrons used in neural representation for neural networks exhibit a pronounced spectral bias, hampering their ability to reconstruct high-frequency details effectively. In this paper, we propose SBS, a parameter-efficient enhancement to neural representation for neural networks that suppresses spectral bias using two techniques: (1) a unidirectional ordering-based smoothing that improves kernel smoothness in the output space, and (2) unidirectional ordering-based smoothing aware random fourier features that adaptively modulate the frequency bandwidth of input encodings based on layer-wise parameter count. Extensive evaluations on various ResNet models with datasets CIFAR-10, CIFAR-100, and ImageNet, demonstrate that SBS achieves significantly better reconstruction accuracy with less parameters compared to SOTA.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç¥ç»ç½‘ç»œçš„ç¥ç»è¡¨ç¤º(Neural Representation for Neural Networks)ä¸­éšå«ç¥ç»è¡¨ç¤º(Implicit Neural Representations)å­˜åœ¨çš„é¢‘è°±åå·®(Spectral Bias)é—®é¢˜ï¼ŒæŒ‡å‡ºæ ‡å‡†å¤šå±‚æ„ŸçŸ¥æœº(MLPs)éš¾ä»¥æœ‰æ•ˆé‡å»ºæƒé‡ä¸­çš„é«˜é¢‘ç»†èŠ‚ã€‚ä¸ºæ­¤ï¼Œä½œè€…æå‡ºäº†SBSæ¡†æ¶ï¼Œæ—¨åœ¨é€šè¿‡æŠ‘åˆ¶é¢‘è°±åå·®æ¥æå‡å‚æ•°æ•ˆç‡ã€‚è¯¥æ–¹æ³•å¼•å…¥äº†å•å‘æ’åºå¹³æ»‘æŠ€æœ¯(Unidirectional Ordering-based Smoothing)ä»¥æ”¹å–„è¾“å‡ºç©ºé—´çš„å·ç§¯æ ¸å¹³æ»‘åº¦ï¼Œå¹¶ç»“åˆæ„ŸçŸ¥å¹³æ»‘çš„éšæœºå‚…é‡Œå¶ç‰¹å¾(Random Fourier Features)æ ¹æ®å±‚çº§å‚æ•°é‡è‡ªé€‚åº”è°ƒèŠ‚è¾“å…¥ç¼–ç çš„é¢‘ç‡å¸¦å®½ã€‚åœ¨CIFAR-10ã€CIFAR-100å’ŒImageNetæ•°æ®é›†ä¸Šå¯¹å¤šç§ResNetæ¨¡å‹çš„å¹¿æ³›è¯„ä¼°è¡¨æ˜ï¼ŒSBSåœ¨å‚æ•°é‡æ›´å°‘çš„æƒ…å†µä¸‹å®ç°äº†æ˜¾è‘—ä¼˜äºSOTAæ–¹æ³•çš„é‡å»ºç²¾åº¦ã€‚è¯¥ç ”ç©¶æœ‰æ•ˆå¢å¼ºäº†ç¥ç»ç½‘ç»œæƒé‡çš„å‚æ•°æ•ˆç‡ï¼Œä¸ºç¥ç»è¡¨ç¤ºæŠ€æœ¯åœ¨æ¨¡å‹å‹ç¼©é¢†åŸŸçš„åº”ç”¨æä¾›äº†é‡è¦æ”¹è¿›ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by ICONIP 2025",
      "pdf_url": "https://arxiv.org/pdf/2509.07373v1",
      "published_date": "2025-09-09 03:48:57 UTC",
      "updated_date": "2025-09-09 03:48:57 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:33:50.457726+00:00"
    },
    {
      "arxiv_id": "2509.07367v1",
      "title": "Autonomous Code Evolution Meets NP-Completeness",
      "title_zh": "è‡ªä¸»ä»£ç æ¼”åŒ–é‡ä¸ŠNPå®Œå…¨æ€§",
      "authors": [
        "Cunxi Yu",
        "Rongjian Liang",
        "Chia-Tung Ho",
        "Haoxing Ren"
      ],
      "abstract": "Large language models (LLMs) have recently shown strong coding abilities, enabling not only static code generation but also iterative code self-evolving through agentic frameworks. Recently, AlphaEvolve \\cite{novikov2025alphaevolve} demonstrated that LLM-based coding agents can autonomously improve algorithms and surpass human experts, with scopes limited to isolated kernels spanning hundreds of lines of code. Inspired by AlphaEvolve, we present SATLUTION, the first framework to extend LLM-based code evolution to the full repository scale, encompassing hundreds of files and tens of thousands of lines of C/C++ code. Targeting Boolean Satisfiability (SAT), the canonical NP-complete problem and a cornerstone of both theory and applications. SATLUTION orchestrates LLM agents to directly evolve solver repositories under strict correctness guarantees and distributed runtime feedback, while simultaneously self-evolving its own evolution policies and rules. Starting from SAT Competition 2024 codebases and benchmark, SATLUTION evolved solvers that decisively outperformed the human-designed winners of the SAT Competition 2025, and also surpassed both 2024 and 2025 champions on the 2024 benchmarks.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† SATLUTIONï¼Œè¿™æ˜¯é¦–ä¸ªå°†åŸºäºå¤§è¯­è¨€æ¨¡å‹ (LLMs) çš„ä»£ç æ¼”åŒ–æ‰©å±•åˆ°å®Œæ•´ä»£ç åº“è§„æ¨¡ï¼ˆåŒ…å«æ•°ä¸‡è¡Œ C/C++ ä»£ç ï¼‰çš„æ¡†æ¶ã€‚è¯¥æ¡†æ¶é’ˆå¯¹å¸ƒå°”å¯æ»¡è¶³æ€§ (SAT) è¿™ä¸€å…¸å‹çš„ NP-complete é—®é¢˜ï¼Œé€šè¿‡åè°ƒ LLM æ™ºèƒ½ä½“åœ¨ä¸¥æ ¼çš„æ­£ç¡®æ€§ä¿è¯å’Œåˆ†å¸ƒå¼è¿è¡Œæ—¶åé¦ˆä¸‹ï¼Œç›´æ¥æ¼”åŒ–å¤æ‚çš„æ±‚è§£å™¨ä»£ç åº“ã€‚SATLUTION çš„æ ¸å¿ƒä¼˜åŠ¿åœ¨äºèƒ½å¤ŸåŒæ­¥å®ç°å…¶è‡ªèº«æ¼”åŒ–ç­–ç•¥å’Œè§„åˆ™çš„è‡ªæˆ‘è¿›åŒ– (self-evolving)ï¼Œä»è€Œçªç ´äº†ä»¥å¾€ä»…é™äºæ•°ç™¾è¡Œå­¤ç«‹å†…æ ¸çš„ä»£ç æ¼”åŒ–é™åˆ¶ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒSATLUTION æ¼”åŒ–å‡ºçš„æ±‚è§£å™¨åœ¨æ€§èƒ½ä¸Šæœæ–­è¶…è¶Šäº† SAT Competition 2025 çš„äººç±»è®¾è®¡å† å†›ã€‚æ­¤å¤–ï¼Œå®ƒåœ¨ 2024 å¹´çš„åŸºå‡†æµ‹è¯•ä¸­ä¹ŸåŒæ—¶å‡»è´¥äº† 2024 å¹´å’Œ 2025 å¹´çš„å† å†›æ±‚è§£å™¨ï¼Œå±•ç¤ºäº†è‡ªä¸»ä»£ç æ¼”åŒ–åœ¨è§£å†³åŸºç¡€ç†è®ºä¸å®é™…åº”ç”¨å…¼å…·çš„å¤æ‚è®¡ç®—éš¾é¢˜æ–¹é¢çš„å“è¶Šèƒ½åŠ›ã€‚",
      "categories": [
        "cs.AI",
        "cs.LG",
        "cs.LO"
      ],
      "primary_category": "cs.AI",
      "comment": "31 pages, 11 figures",
      "pdf_url": "https://arxiv.org/pdf/2509.07367v1",
      "published_date": "2025-09-09 03:28:06 UTC",
      "updated_date": "2025-09-09 03:28:06 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:33:49.849258+00:00"
    },
    {
      "arxiv_id": "2509.07361v1",
      "title": "Word2Spike: Poisson Rate Coding for Associative Memories and Neuromorphic Algorithms",
      "title_zh": "Word2Spikeï¼šé¢å‘è”æƒ³è®°å¿†ä¸ç¥ç»å½¢æ€ç®—æ³•çš„æ³Šæ¾é€Ÿç‡ç¼–ç ",
      "authors": [
        "Archit Kalra",
        "Midhun Sadanand"
      ],
      "abstract": "Spiking neural networks offer a promising path toward energy-efficient, brain-like associative memory. This paper introduces Word2Spike, a novel rate coding mechanism that combines continuous word embeddings and neuromorphic architectures. We develop a one-to-one mapping that converts multi-dimensional word vectors into spike-based attractor states using Poisson processes. Using BitNet b1.58 quantization, we maintain 97% semantic similarity of continuous embeddings on SimLex-999 while achieving 100% reconstruction accuracy on 10,000 words from OpenAI's text-embedding-3-large. We preserve analogy performance (100% of original embedding performance) even under intentionally introduced noise, indicating a resilient mechanism for semantic encoding in neuromorphic systems. Next steps include integrating the mapping with spiking transformers and liquid state machines (resembling Hopfield Networks) for further evaluation.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† Word2Spikeï¼Œè¿™æ˜¯ä¸€ç§ç»“åˆäº†è¿ç»­ word embeddings å’Œ neuromorphic architectures çš„æ–°å‹ rate coding æœºåˆ¶ã€‚è¯¥æ–¹æ³•åˆ©ç”¨ Poisson processes å°†å¤šç»´è¯å‘é‡è½¬åŒ–ä¸ºåŸºäºè„‰å†²çš„ attractor statesï¼Œå®ç°äº†ä¸¤è€…ä¹‹é—´çš„ä¸€å¯¹ä¸€æ˜ å°„ã€‚é€šè¿‡åº”ç”¨ BitNet b1.58 é‡åŒ–æŠ€æœ¯ï¼Œè¯¥æœºåˆ¶åœ¨ SimLex-999 æµ‹è¯•é›†ä¸Šä¿ç•™äº† 97% çš„è¯­ä¹‰ç›¸ä¼¼åº¦ï¼Œå¹¶åœ¨æ¥è‡ª OpenAI çš„ text-embedding-3-large æ¨¡å‹æå–çš„ 10,000 ä¸ªå•è¯ä¸­å®ç°äº† 100% çš„é‡å»ºå‡†ç¡®ç‡ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒWord2Spike åœ¨å¼•å…¥äººä¸ºå™ªå£°çš„æƒ…å†µä¸‹ä»èƒ½å®Œå…¨ä¿ç•™åŸå§‹åµŒå…¥çš„ç±»æ¯”æ€§èƒ½ï¼Œä½“ç°äº†ç¥ç»å½¢æ€ç³»ç»Ÿä¸­è¯­ä¹‰ç¼–ç çš„é²æ£’æ€§ã€‚è¯¥ç ”ç©¶ä¸ºæœªæ¥å°†æ­¤ç±»æ˜ å°„ä¸ spiking transformers å’Œ liquid state machines ç­‰æ¨¡å‹ç»“åˆå¹¶å¼€å±•è¿›ä¸€æ­¥è¯„ä¼°å¥ å®šäº†åŸºç¡€ã€‚",
      "categories": [
        "cs.NE",
        "cs.AI"
      ],
      "primary_category": "cs.NE",
      "comment": "Presented at 2025 AI in Health Conference, Ken Kennedy Institute, Rice University",
      "pdf_url": "https://arxiv.org/pdf/2509.07361v1",
      "published_date": "2025-09-09 03:15:22 UTC",
      "updated_date": "2025-09-09 03:15:22 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:33:53.684248+00:00"
    },
    {
      "arxiv_id": "2509.07339v1",
      "title": "Performative Thinking? The Brittle Correlation Between CoT Length and Problem Complexity",
      "title_zh": "è¡¨æ¼”å¼æ€è€ƒï¼Ÿæ€ç»´é“¾é•¿åº¦ä¸é—®é¢˜å¤æ‚åº¦ä¹‹é—´çš„è„†å¼±å…³è”",
      "authors": [
        "Vardhan Palod",
        "Karthik Valmeekam",
        "Kaya Stechly",
        "Subbarao Kambhampati"
      ],
      "abstract": "Intermediate token generation (ITG), where a model produces output before the solution, has been proposed as a method to improve the performance of language models on reasoning tasks. While these reasoning traces or Chain of Thoughts (CoTs) are correlated with performance gains, the mechanisms underlying them remain unclear. A prevailing assumption in the community has been to anthropomorphize these tokens as \"thinking\", treating longer traces as evidence of higher problem-adaptive computation. In this work, we critically examine whether intermediate token sequence length reflects or correlates with problem difficulty. To do so, we train transformer models from scratch on derivational traces of the A* search algorithm, where the number of operations required to solve a maze problem provides a precise and verifiable measure of problem complexity. We first evaluate the models on trivial free-space problems, finding that even for the simplest tasks, they often produce excessively long reasoning traces and sometimes fail to generate a solution. We then systematically evaluate the model on out-of-distribution problems and find that the intermediate token length and ground truth A* trace length only loosely correlate. We notice that the few cases where correlation appears are those where the problems are closer to the training distribution, suggesting that the effect arises from approximate recall rather than genuine problem-adaptive computation. This suggests that the inherent computational complexity of the problem instance is not a significant factor, but rather its distributional distance from the training data. These results challenge the assumption that intermediate trace generation is adaptive to problem difficulty and caution against interpreting longer sequences in systems like R1 as automatically indicative of \"thinking effort\".",
      "tldr_zh": "è¯¥ç ”ç©¶æ‰¹åˆ¤æ€§åœ°è€ƒå¯Ÿäº†ä¸­é—´æ ‡è®°ç”Ÿæˆ(Intermediate token generation)æˆ–é“¾å¼æ€ç»´(Chain of Thought)çš„åºåˆ—é•¿åº¦æ˜¯å¦èƒ½åæ˜ é—®é¢˜çš„å¤æ‚åº¦ã€‚ç ”ç©¶è€…é€šè¿‡è®© Transformer æ¨¡å‹å­¦ä¹  A\\* æœç´¢ç®—æ³•çš„æ¨å¯¼è½¨è¿¹ï¼Œåˆ©ç”¨è§£å†³è¿·å®«ä»»åŠ¡çš„æ“ä½œæ•°ä½œä¸ºè¡¡é‡å¤æ‚åº¦çš„ç²¾ç¡®æŒ‡æ ‡ã€‚å®éªŒå‘ç°ï¼Œæ¨¡å‹å³ä½¿åœ¨å¤„ç†æç®€å•çš„ä»»åŠ¡æ—¶ä¹Ÿç»å¸¸äº§ç”Ÿè¿‡åº¦å†—é•¿çš„æ¨ç†è½¨è¿¹ï¼Œä¸”ä¸­é—´æ ‡è®°é•¿åº¦ä¸çœŸå®çš„ A\\* è½¨è¿¹é•¿åº¦ä»…å‘ˆç°å¾®å¼±ç›¸å…³æ€§ã€‚ç ”ç©¶è¿›ä¸€æ­¥æŒ‡å‡ºï¼Œè¿™ç§ç›¸å…³æ€§ä¸»è¦å‡ºç°åœ¨æ¥è¿‘è®­ç»ƒåˆ†å¸ƒçš„é—®é¢˜ä¸Šï¼Œæš—ç¤ºé•¿è½¨è¿¹æ›´å¤šæ˜¯ç”±äºè¿‘ä¼¼å¬å›(approximate recall)è€ŒéçœŸæ­£çš„è‡ªé€‚åº”è®¡ç®—ã€‚è¿™ä¸€å‘ç°æŒ‘æˆ˜äº†æ¨ç†è½¨è¿¹éšé—®é¢˜éš¾åº¦è‡ªé€‚åº”è°ƒæ•´çš„æ™®éå‡è®¾ã€‚æœ€åï¼Œä½œè€…è­¦ç¤ºç ”ç©¶ç•Œä¸åº”å°†ç±»ä¼¼ R1 ç³»ç»Ÿä¸­çš„é•¿åºåˆ—è¾“å‡ºç›´æ¥ç­‰åŒäºæ¨¡å‹çš„â€œæ€è€ƒåŠªåŠ›â€æˆ–æ›´é«˜é˜¶çš„é—®é¢˜è‡ªé€‚åº”èƒ½åŠ›ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.07339v1",
      "published_date": "2025-09-09 02:31:16 UTC",
      "updated_date": "2025-09-09 02:31:16 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:33:56.990589+00:00"
    },
    {
      "arxiv_id": "2509.07330v2",
      "title": "General Demographic Foundation Models for Enhancing Predictive Performance Across Diseases and Populations",
      "title_zh": "æå‡è·¨ç–¾ç—…å’Œè·¨äººç¾¤é¢„æµ‹æ€§èƒ½çš„é€šç”¨äººå£ç»Ÿè®¡å­¦åŸºç¡€æ¨¡å‹",
      "authors": [
        "Li-Chin Chen",
        "Ji-Tian Sheu",
        "Yuh-Jue Chuang"
      ],
      "abstract": "Demographic attributes are universally present in electronic health records. They are the most widespread information across populations and diseases, and serve as vital predictors in clinical risk stratification and treatment decisions. Despite their significance, these attributes are often treated as auxiliaries in model design, with limited attention being paid to learning their representations. This study explored the development of a General Demographic Pre-trained (GDP) model as a foundational model tailored to demographic attributes, focusing on age and gender. The model is pre-trained and evaluated using datasets with diverse diseases and populations compositions from different geographic regions. The composition of GDP architecture was explored through examining combinations of ordering approaches and encoding methods to transform tabular demographic inputs into effective latent embeddings. Results demonstrate the feasibility of GDP to generalize across task, diseases, and populations. In detailed composition, the sequential ordering substantially improves model performance in discrimination, calibration, and the corresponding information gain at each decision tree split, particularly in diseases where age and gender contribute significantly to risk stratification. Even in datasets where demographic attributes hold relatively low predictive value, GDP enhances the representational importance, increasing their influence in downstream gradient boosting models. The findings suggest that foundation models for tabular demographic attributes offer a promising direction for improving predictive performance in healthcare applications.",
      "tldr_zh": "è¿™é¡¹ç ”ç©¶æå‡ºäº† General Demographic Pre-trained (GDP) æ¨¡å‹ï¼Œæ—¨åœ¨è§£å†³ç”µå­å¥åº·æ¡£æ¡ˆï¼ˆEHRï¼‰ä¸­äººå£ç»Ÿè®¡å±æ€§å¸¸è¢«è§†ä¸ºè¾…åŠ©ä¿¡æ¯è€Œç¼ºä¹è¡¨å¾å­¦ä¹ çš„é—®é¢˜ã€‚è¯¥æ¨¡å‹ä¸“æ³¨äºå¹´é¾„å’Œæ€§åˆ«å±æ€§ï¼Œé€šè¿‡æ¢ç´¢ä¸åŒçš„æ’åºä¸ç¼–ç æ–¹æ³•å°†è¡¨æ ¼æ•°æ®è½¬åŒ–ä¸ºé«˜æ•ˆçš„ latent embeddingsï¼Œå¹¶åœ¨è·¨åœ°åŒºã€è·¨ç–¾ç—…çš„å¤šæ ·åŒ–æ•°æ®é›†ä¸Šè¿›è¡Œäº†é¢„è®­ç»ƒã€‚å®éªŒè¯æ˜ï¼ŒGDP æ¨¡å‹å…·æœ‰å“è¶Šçš„è·¨ä»»åŠ¡å’Œè·¨äººç¾¤æ³›åŒ–èƒ½åŠ›ï¼Œå°¤å…¶åœ¨ sequential ordering æ¨¡å¼ä¸‹æ˜¾è‘—æå‡äº†æ¨¡å‹çš„ discrimination å’Œ calibration è¡¨ç°ã€‚åœ¨äººå£ç»Ÿè®¡ç‰¹å¾å¯¹é£é™©åˆ†å±‚æ„ä¹‰é‡å¤§çš„åœºæ™¯ä¸­ï¼Œè¯¥æ¨¡å‹æ˜¾è‘—å¢åŠ äº†å†³ç­–æ ‘çš„ information gainï¼›å³ä¾¿åœ¨ç›¸å…³å±æ€§é¢„æµ‹ä»·å€¼è¾ƒä½çš„æƒ…å†µä¸‹ï¼ŒGDP ä¹Ÿèƒ½å¢å¼ºå…¶è¡¨å¾æƒé‡ï¼Œä»è€Œä¼˜åŒ–ä¸‹æ¸¸ gradient boosting æ¨¡å‹çš„é¢„æµ‹æ€§èƒ½ã€‚è¯¥ç ”ç©¶ä¸ºå¼€å‘é’ˆå¯¹åŒ»ç–—è¡¨æ ¼æ•°æ®çš„åŸºç¡€æ¨¡å‹æä¾›äº†é‡è¦è·¯å¾„ï¼Œå±•ç°äº†æå‡ä¸´åºŠå†³ç­–æ”¯æŒèƒ½åŠ›çš„å·¨å¤§æ½œåŠ›ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.07330v2",
      "published_date": "2025-09-09 02:02:27 UTC",
      "updated_date": "2025-10-14 08:57:09 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:34:00.488131+00:00"
    },
    {
      "arxiv_id": "2509.07327v2",
      "title": "DEPFusion: Dual-Domain Enhancement and Priority-Guided Mamba Fusion for UAV Multispectral Object Detection",
      "title_zh": "DEPFusionï¼šé¢å‘æ— äººæœºå¤šå…‰è°±ç›®æ ‡æ£€æµ‹çš„åŒåŸŸå¢å¼ºä¸ä¼˜å…ˆçº§å¼•å¯¼ Mamba èåˆ",
      "authors": [
        "Shucong Li",
        "Zhenyu Liu",
        "Zijie Hong",
        "Zhiheng Zhou",
        "Xianghai Cao"
      ],
      "abstract": "Multispectral object detection is an important application for unmanned aerial vehicles (UAVs). However, it faces several challenges. First, low-light RGB images weaken the multispectral fusion due to details loss. Second, the interference information is introduced to local target modeling during multispectral fusion. Third, computational cost poses deployment challenge on UAV platforms, such as transformer-based methods with quadratic complexity. To address these issues, a framework named DEPFusion consisting of two designed modules, Dual-Domain Enhancement (DDE) and Priority-Guided Mamba Fusion (PGMF) , is proposed for UAV multispectral object detection. Firstly, considering the adoption of low-frequency component for global brightness enhancement and frequency spectra features for texture-details recovery, DDE module is designed with Cross-Scale Wavelet Mamba (CSWM) block and Fourier Details Recovery (FDR) block. Secondly, considering guiding the scanning of Mamba from high priority score tokens, which contain local target feature, a novel Priority-Guided Serialization is proposed with theoretical proof. Based on it, PGMF module is designed for multispectral feature fusion, which enhance local modeling and reduce interference information. Experiments on DroneVehicle and VEDAI datasets demonstrate that DEPFusion achieves good performance with state-of-the-art methods.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†DEPFusionæ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³æ— äººæœºï¼ˆUAVï¼‰å¤šå…‰è°±ç›®æ ‡æ£€æµ‹åœ¨ä½å…‰ç¯å¢ƒä¸‹RGBç»†èŠ‚ä¸¢å¤±ã€èåˆå¹²æ‰°ä»¥åŠTransformeræ¶æ„è®¡ç®—æˆæœ¬é«˜ç­‰æŒ‘æˆ˜ã€‚è¯¥æ¡†æ¶æ ¸å¿ƒåŒ…å«åŒåŸŸå¢å¼ºï¼ˆDual-Domain Enhancement, DDEï¼‰å’Œä¼˜å…ˆçº§å¼•å¯¼çš„Mambaèåˆï¼ˆPriority-Guided Mamba Fusion, PGMFï¼‰ä¸¤ä¸ªæ¨¡å—ã€‚DDEæ¨¡å—é€šè¿‡è·¨å°ºåº¦å°æ³¢Mambaï¼ˆCross-Scale Wavelet Mambaï¼‰ä¸å‚…é‡Œå¶ç»†èŠ‚æ¢å¤ï¼ˆFourier Details Recoveryï¼‰æŠ€æœ¯ï¼Œå®ç°äº†å…¨å±€äº®åº¦å¢å¼ºä¸çº¹ç†ç»†èŠ‚ä¿®å¤ã€‚é’ˆå¯¹ç‰¹å¾èåˆä¸­çš„å¹²æ‰°é—®é¢˜ï¼ŒPGMFæ¨¡å—å¼•å…¥äº†å…·æœ‰ç†è®ºæ”¯æ’‘çš„ä¼˜å…ˆçº§å¼•å¯¼åºåˆ—åŒ–ï¼ˆPriority-Guided Serializationï¼‰æœºåˆ¶ï¼Œå¼•å¯¼Mambaä¼˜å…ˆå¤„ç†åŒ…å«å±€éƒ¨ç›®æ ‡çš„ç‰¹å¾Tokenï¼Œä»è€Œå¼ºåŒ–å±€éƒ¨å»ºæ¨¡å¹¶å‡å°‘ä¿¡æ¯å¹²æ‰°ã€‚åœ¨DroneVehicleå’ŒVEDAIæ•°æ®é›†ä¸Šçš„å®éªŒè¯æ˜ï¼ŒDEPFusionåœ¨æ€§èƒ½ä¸Šè¾¾åˆ°äº†é¢†åŸŸé¢†å…ˆæ°´å¹³ï¼Œä¸ºèµ„æºå—é™çš„æ— äººæœºå¹³å°æä¾›äº†é«˜æ•ˆçš„å¤šå…‰è°±ç›®æ ‡æ£€æµ‹æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.07327v2",
      "published_date": "2025-09-09 01:51:57 UTC",
      "updated_date": "2025-09-29 08:14:38 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:34:06.690425+00:00"
    },
    {
      "arxiv_id": "2509.07324v1",
      "title": "Mitigating Attention Localization in Small Scale: Self-Attention Refinement via One-step Belief Propagation",
      "title_zh": "ç¼“è§£å°è§„æ¨¡ä¸‹çš„æ³¨æ„åŠ›å±€åŸŸåŒ–ï¼šåŸºäºå•æ­¥ç½®ä¿¡ä¼ æ’­çš„è‡ªæ³¨æ„åŠ›ä¼˜åŒ–",
      "authors": [
        "Nakyung Lee",
        "Yeongoon Kim",
        "Minhae Oh",
        "Suhwan Kim",
        "Jin Woo Koo",
        "Hyewon Jo",
        "Jungwoo Lee"
      ],
      "abstract": "Transformer-based self-attention mechanism serves as the core of modern language models, yet it often suffers from localization, where attentions collapse onto a limited subset of tokens and fail to capture long-range dependencies. To address this issue, we propose Self-Attention One-step Belief Propagation (SAOBP), a refinement framework that injects multi-hop relationships through a belief propagation process. To interpret and quantify these interactions, we introduce Global Token Dependency (GTD) that captures the relative contribution of multihop connections within the attention graph. Empirical results indicate that SAOBP helps prevent entropy collapse in deeper layers and adaptively maintains GTD at task-appropriate levels, thereby supporting improvements in model performance. Importantly, we observe competitive gains in small-scale models, highlighting its potential for improving inference quality in resource-constrained scenarios.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹Transformerè‡ªæ³¨æ„åŠ›æœºåˆ¶(self-attention)ä¸­å¸¸è§çš„å®šä½åŒ–(localization)é—®é¢˜ï¼Œå³æ³¨æ„åŠ›è¿‡åº¦é›†ä¸­äºå°‘æ•°tokenè€Œæ— æ³•æ•æ‰é•¿ç¨‹ä¾èµ–ï¼Œæå‡ºäº†SAOBP (Self-Attention One-step Belief Propagation) æ”¹è¿›æ¡†æ¶ã€‚è¯¥æ¡†æ¶é€šè¿‡ä¸€é˜¶ç½®ä¿¡ä¼ æ’­(belief propagation)è¿‡ç¨‹å‘æ³¨æ„åŠ›æœºåˆ¶ä¸­æ³¨å…¥å¤šè·³(multi-hop)å…³ç³»ï¼Œä»è€Œå¢å¼ºå…¨å±€ç‰¹å¾å»ºæ¨¡èƒ½åŠ›ã€‚ä¸ºäº†é‡åŒ–è¿™äº›äº¤äº’ï¼Œç ”ç©¶è€…å¼•å…¥äº†GTD (Global Token Dependency) æŒ‡æ ‡ï¼Œç”¨äºæ•æ‰æ³¨æ„åŠ›å›¾ä¸­å¤šè·³è¿æ¥çš„ç›¸å¯¹è´¡çŒ®ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒSAOBPèƒ½æœ‰æ•ˆé˜²æ­¢æ·±å±‚ç½‘ç»œä¸­çš„ä¿¡æ¯ç†µå´©å¡Œ(entropy collapse)ï¼Œå¹¶æ ¹æ®ä»»åŠ¡éœ€æ±‚è‡ªé€‚åº”ç»´æŒGTDæ°´å¹³ã€‚ç‰¹åˆ«æ˜¯åœ¨å°è§„æ¨¡æ¨¡å‹ä¸­ï¼Œè¯¥æ–¹æ³•æ˜¾è‘—æå‡äº†æ¨ç†è´¨é‡ï¼Œè¯æ˜äº†å…¶åœ¨èµ„æºå—é™åœºæ™¯ä¸‹ä¼˜åŒ–æ¨¡å‹æ€§èƒ½çš„æ½œåŠ›ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted at EMNLP 2025",
      "pdf_url": "https://arxiv.org/pdf/2509.07324v1",
      "published_date": "2025-09-09 01:43:48 UTC",
      "updated_date": "2025-09-09 01:43:48 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:34:12.000345+00:00"
    },
    {
      "arxiv_id": "2509.07319v1",
      "title": "MEGG: Replay via Maximally Extreme GGscore in Incremental Learning for Neural Recommendation Models",
      "title_zh": "MEGGï¼šç¥ç»æ¨èæ¨¡å‹å¢é‡å­¦ä¹ ä¸­åŸºäºæœ€å¤§æç«¯ GGscore çš„é‡æ”¾æ–¹æ³•",
      "authors": [
        "Yunxiao Shi",
        "Shuo Yang",
        "Haimin Zhang",
        "Li Wang",
        "Yongze Wang",
        "Qiang Wu",
        "Min Xu"
      ],
      "abstract": "Neural Collaborative Filtering models are widely used in recommender systems but are typically trained under static settings, assuming fixed data distributions. This limits their applicability in dynamic environments where user preferences evolve. Incremental learning offers a promising solution, yet conventional methods from computer vision or NLP face challenges in recommendation tasks due to data sparsity and distinct task paradigms. Existing approaches for neural recommenders remain limited and often lack generalizability. To address this, we propose MEGG, Replay Samples with Maximally Extreme GGscore, an experience replay based incremental learning framework. MEGG introduces GGscore, a novel metric that quantifies sample influence, enabling the selective replay of highly influential samples to mitigate catastrophic forgetting. Being model-agnostic, MEGG integrates seamlessly across architectures and frameworks. Experiments on three neural models and four benchmark datasets show superior performance over state-of-the-art baselines, with strong scalability, efficiency, and robustness. Implementation will be released publicly upon acceptance.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç¥ç»ç½‘ç»œååŒè¿‡æ»¤ (Neural Collaborative Filtering) æ¨¡å‹åœ¨å¤„ç†åŠ¨æ€ç”¨æˆ·åå¥½æ—¶é¢ä¸´çš„å±€é™æ€§ï¼Œæå‡ºäº† MEGG æ¡†æ¶ï¼Œè¿™æ˜¯ä¸€ç§åŸºäºç»éªŒå›æ”¾ (experience replay) çš„å¢é‡å­¦ä¹  (incremental learning) æ–¹æ³•ã€‚ä¸ºäº†åº”å¯¹æ¨èç³»ç»Ÿä¸­ç‰¹æœ‰çš„æ•°æ®ç¨€ç–æ€§æŒ‘æˆ˜ï¼ŒMEGG å¼•å…¥äº†åä¸º GGscore çš„æ–°æŒ‡æ ‡æ¥é‡åŒ–æ ·æœ¬å½±å“åŠ›ï¼Œé€šè¿‡é€‰æ‹©æ€§åœ°å›æ”¾æå…·å½±å“åŠ›çš„æ ·æœ¬æ¥æœ‰æ•ˆç¼“è§£ç¾éš¾æ€§é—å¿˜ (catastrophic forgetting) é—®é¢˜ã€‚MEGG å…·æœ‰æ¨¡å‹æ— å…³ (model-agnostic) çš„ç‰¹æ€§ï¼Œèƒ½å¤Ÿæ— ç¼é›†æˆåˆ°å„ç§æ¨èç³»ç»Ÿæ¶æ„å’Œæ¡†æ¶ä¸­ã€‚åœ¨ä¸‰ä¸ªç¥ç»æ¨¡å‹å’Œå››ä¸ªåŸºå‡†æ•°æ®é›†ä¸Šçš„å®éªŒè¯æ˜ï¼ŒMEGG çš„æ€§èƒ½æ˜¾è‘—ä¼˜äºç°æœ‰çš„æœ€å…ˆè¿›åŸºå‡†ï¼Œå¹¶åœ¨å¯æ‰©å±•æ€§ã€æ•ˆç‡å’Œé²æ£’æ€§æ–¹é¢è¡¨ç°ä¼˜å¼‚ã€‚",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "Accepted by Data Mining and Knowledge Discovery (DMKD) in Sep 2025",
      "pdf_url": "https://arxiv.org/pdf/2509.07319v1",
      "published_date": "2025-09-09 01:35:51 UTC",
      "updated_date": "2025-09-09 01:35:51 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:34:12.690835+00:00"
    },
    {
      "arxiv_id": "2509.07311v1",
      "title": "Does This Look Familiar to You? Knowledge Analysis via Model Internal Representations",
      "title_zh": "ä¼¼æ›¾ç›¸è¯†ï¼ŸåŸºäºæ¨¡å‹å†…éƒ¨è¡¨ç¤ºçš„çŸ¥è¯†åˆ†æ",
      "authors": [
        "Sihyun Park"
      ],
      "abstract": "Recent advances in large language models (LLMs) have been driven by pretraining, supervised fine tuning (SFT), and alignment tuning. Among these, SFT plays a crucial role in transforming a model 's general knowledge into structured responses tailored to specific tasks. However, there is no clearly established methodology for effective training data selection. Simply increasing the volume of data does not guarantee performance improvements, while preprocessing, sampling, and validation require substantial time and cost.\n  To address this issue, a variety of data selection methods have been proposed. Among them, knowledge based selection approaches identify suitable training data by analyzing the model 's responses. Nevertheless, these methods typically rely on prompt engineering, making them sensitive to variations and incurring additional costs for prompt design.\n  In this study, we propose Knowledge Analysis via Model Internal Representations (KAMIR), a novel approach that overcomes these limitations by analyzing data based on the model 's internal representations. KAMIR computes similarities between the hidden states of each layer (block) and the final hidden states for a given input to assess the data. Unlike prior methods that were largely limited to multiple choice tasks, KAMIR can be applied to a wide range of tasks such as machine reading comprehension and summarization. Moreover, it selects data useful for training based on the model 's familiarity with the input, even with a small dataset and a simple classifier architecture. Experiments across diverse task datasets demonstrate that training with less familiar data leads to better generalization performance.",
      "tldr_zh": "è¿™é¡¹ç ”ç©¶æå‡ºäº†KAMIR (Knowledge Analysis via Model Internal Representations)ï¼Œä¸€ç§é€šè¿‡åˆ†ææ¨¡å‹å†…éƒ¨è¡¨å¾æ¥è¿›è¡ŒçŸ¥è¯†åˆ†æå’Œè®­ç»ƒæ•°æ®é€‰æ‹©çš„æ–°æ–¹æ³•ã€‚é’ˆå¯¹å¤§è¯­è¨€æ¨¡å‹(LLMs)åœ¨ç›‘ç£å¾®è°ƒ(SFT)ä¸­é¢ä¸´çš„æ•°æ®é€‰æ‹©éš¾é¢˜ï¼ŒKAMIRé€šè¿‡è®¡ç®—å„å±‚éšè—çŠ¶æ€(Hidden States)ä¸æœ€ç»ˆéšè—çŠ¶æ€ä¹‹é—´çš„ç›¸ä¼¼åº¦ï¼Œé‡åŒ–è¯„ä¼°æ¨¡å‹å¯¹ç‰¹å®šè¾“å…¥çš„ç†Ÿæ‚‰ç¨‹åº¦ã€‚ä¸ä»¥å¾€ä¾èµ–æç¤ºå·¥ç¨‹(Prompt Engineering)ä¸”ä¸»è¦å±€é™äºå¤šé¡¹é€‰æ‹©ä»»åŠ¡çš„æ–¹æ³•ä¸åŒï¼ŒKAMIRå…·å¤‡æ›´å¼ºçš„é€šç”¨æ€§ï¼Œå¯åº”ç”¨äºæœºå™¨é˜…è¯»ç†è§£å’Œæ‘˜è¦ç”Ÿæˆç­‰å¤šç§ä»»åŠ¡ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨å°å‹æ•°æ®é›†å’Œç®€å•åˆ†ç±»å™¨æ¶æ„ä¸‹ä¾ç„¶è¡¨ç°å‡ºè‰²ã€‚è¯¥ç ”ç©¶æœ€æ ¸å¿ƒçš„å‘ç°æ˜¯ï¼Œåˆ©ç”¨æ¨¡å‹â€œä¸ç†Ÿæ‚‰â€çš„æ•°æ®è¿›è¡Œè®­ç»ƒèƒ½å¸¦æ¥æ›´å¥½çš„æ³›åŒ–æ€§èƒ½(Generalization Performance)ï¼Œè¿™ä¸ºä¼˜åŒ–è®­ç»ƒæ•°æ®ç­›é€‰ç­–ç•¥æä¾›äº†é‡è¦çš„ç†è®ºä¾æ®å’Œå®è·µæŒ‡å¯¼ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.07311v1",
      "published_date": "2025-09-09 01:08:15 UTC",
      "updated_date": "2025-09-09 01:08:15 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:34:20.584388+00:00"
    },
    {
      "arxiv_id": "2509.07308v1",
      "title": "Basis Vector Metric: A Method for Robust Open-Ended State Change Detection",
      "title_zh": "åŸºå‘é‡åº¦é‡ï¼šä¸€ç§é²æ£’çš„å¼€æ”¾å¼çŠ¶æ€å˜åŒ–æ£€æµ‹æ–¹æ³•",
      "authors": [
        "David Oprea",
        "Sam Powers"
      ],
      "abstract": "We test a new method, which we will abbreviate using the acronym BVM (Basis Vectors Method), in its ability to judge the state changes in images through using language embeddings. We used the MIT-States dataset, containing about 53,000 images, to gather all of our data, which has 225 nouns and 115 adjectives, with each noun having about 9 different adjectives, forming approximately 1000 noun-adjective pairs. For our first experiment, we test our method's ability to determine the state of each noun class separately against other metrics for comparison. These metrics are cosine similarity, dot product, product quantization, binary index, Naive Bayes, and a custom neural network. Among these metrics, we found that our proposed BVM performs the best in classifying the states for each noun. We then perform a second experiment where we try using BVM to determine if it can differentiate adjectives from one another for each adjective separately. We compared the abilities of BVM to differentiate adjectives against the proposed method the MIT-States paper suggests: using a logistic regression model. In the end, we did not find conclusive evidence that our BVM metric could perform better than the logistic regression model at discerning adjectives. Yet, we were able to find evidence for possible improvements to our method; this leads to the chance of increasing our method's accuracy through certain changes in our methodologies.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºå¹¶æµ‹è¯•äº†ä¸€ç§åä¸º Basis Vector Metric (BVM) çš„æ–°æ–¹æ³•ï¼Œæ—¨åœ¨åˆ©ç”¨è¯­è¨€åµŒå…¥ (language embeddings) æ¥åˆ¤æ–­å›¾åƒä¸­çš„çŠ¶æ€å˜åŒ–ã€‚ç ”ç©¶å›¢é˜ŸåŸºäºåŒ…å«çº¦ 53,000 å¼ å›¾åƒã€225 ä¸ªåè¯å’Œ 115 ä¸ªå½¢å®¹è¯çš„ MIT-States æ•°æ®é›†è¿›è¡Œäº†ç³»ç»Ÿè¯„ä¼°ã€‚åœ¨ç¬¬ä¸€é¡¹å®éªŒä¸­ï¼ŒBVM åœ¨åè¯çŠ¶æ€åˆ†ç±»ä»»åŠ¡ä¸­çš„è¡¨ç°ä¼˜äºä½™å¼¦ç›¸ä¼¼åº¦ (cosine similarity)ã€ç‚¹ç§¯ (dot product)ã€ä¹˜ç§¯é‡åŒ– (product quantization)ã€äºŒè¿›åˆ¶ç´¢å¼• (binary index)ã€æœ´ç´ è´å¶æ–¯ (Naive Bayes) ä»¥åŠè‡ªå®šä¹‰ç¥ç»ç½‘ç»œç­‰åŸºå‡†æŒ‡æ ‡ã€‚éšåï¼Œç ”ç©¶æ¢è®¨äº† BVM åŒºåˆ†ä¸åŒå½¢å®¹è¯çš„èƒ½åŠ›ï¼Œå°½ç®¡åœ¨ä¸é€»è¾‘å›å½’ (logistic regression) æ¨¡å‹çš„å¯¹æ¯”ä¸­æœªè·å¾—å…¶æ›´å…·ä¼˜åŠ¿çš„å†³å®šæ€§è¯æ®ï¼Œä½†å®éªŒæ­ç¤ºäº†è¯¥æ–¹æ³•çš„æ”¹è¿›ç©ºé—´ã€‚è¯¥ç ”ç©¶è¯æ˜äº† BVM åœ¨å¤„ç†å¼€æ”¾å¼çŠ¶æ€å˜åŒ–æ£€æµ‹æ–¹é¢çš„æ½œåŠ›ï¼Œå¹¶ä¸ºæœªæ¥é€šè¿‡æ–¹æ³•è®ºè°ƒæ•´æå‡æ¨¡å‹å‡†ç¡®ç‡å¥ å®šäº†åŸºç¡€ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "24 pages",
      "pdf_url": "https://arxiv.org/pdf/2509.07308v1",
      "published_date": "2025-09-09 00:58:43 UTC",
      "updated_date": "2025-09-09 00:58:43 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:34:18.789386+00:00"
    },
    {
      "arxiv_id": "2510.15893v1",
      "title": "Accelerating Frontier MoE Training with 3D Integrated Optics",
      "title_zh": "åˆ©ç”¨ 3D é›†æˆå…‰å­¦åŠ é€Ÿå‰æ²¿ MoE è®­ç»ƒ",
      "authors": [
        "Mikhail Bernadskiy",
        "Peter Carson",
        "Thomas Graham",
        "Taylor Groves",
        "Ho John Lee",
        "Eric Yeh"
      ],
      "abstract": "The unabated growth in AI workload demands is driving the need for concerted advances in compute, memory, and interconnect performance. As traditional semiconductor scaling slows, high-speed interconnects have emerged as the new scaling engine, enabling the creation of larger logical GPUs by linking many GPUs into a single, low-latency, high-bandwidth compute domain. While initial scale-up fabrics leveraged copper interconnects for their power and cost advantages, the maximum reach of passive electrical interconnects (approximately 1 meter) effectively limits the scale-up domain to within a single rack. The advent of 3D-stacked optics and logic offers a transformative, power-efficient scale-up solution for connecting hundreds of GPU packages (thousands of GPUs) across multiple data center racks. This work explores the design tradeoffs of scale-up technologies and demonstrates how frontier LLMs necessitate novel photonic solutions to achieve aggressive power and performance targets. We model the benefits of 3D CPO (Passage) enabled GPUs and switches within the scale-up domain when training Frontier Mixture of Experts (MoE) models exceeding one trillion parameters. Our results show that the substantial increases in bandwidth and radix enabled by 3D CPO allow for an 8X increase in scale-up capability. This affords new opportunities for multi-dimensional parallelism within the scale-up domain and results in a 2.7X reduction in time-to-train, unlocking unprecedented model scaling.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†åˆ©ç”¨3Dé›†æˆå…‰å­¦ï¼ˆ3D Integrated Opticsï¼‰åŠ é€Ÿå‰æ²¿æ··åˆä¸“å®¶æ¨¡å‹ï¼ˆMixture of Experts, MoEï¼‰è®­ç»ƒçš„æ–¹æ³•ã€‚é’ˆå¯¹ä¼ ç»Ÿé“œäº’è¿ï¼ˆcopper interconnectsï¼‰å—é™äºå•æœºæ¶èŒƒå›´å†…çº¦1ç±³çš„ç‰©ç†ç“¶é¢ˆï¼Œç ”ç©¶æå‡ºäº†ä¸€ç§ç»“åˆ3Då †å å…‰å­¦ä¸é€»è¾‘çš„å˜æ¢æ€§è§£å†³æ–¹æ¡ˆï¼Œå³3D CPOï¼ˆPassageï¼‰ã€‚è¯¥æŠ€æœ¯èƒ½å¤Ÿé«˜æ•ˆè¿æ¥è·¨æœºæ¶çš„æ•°ç™¾ä¸ªGPUå°è£…ï¼Œæ˜¾è‘—æå‡äº†äº’è¿å¸¦å®½ä¸åŸºæ•°ï¼ˆradixï¼‰ã€‚é€šè¿‡å¯¹è¶…è¿‡ä¸€ä¸‡äº¿å‚æ•°çš„MoEæ¨¡å‹è¿›è¡Œå»ºæ¨¡ï¼Œç»“æœè¡¨æ˜3D CPOä½¿ç³»ç»Ÿçš„æ‰©å±•èƒ½åŠ›æé«˜äº†8å€ï¼Œå¹¶ä¸ºå¤šç»´å¹¶è¡Œç­–ç•¥æä¾›äº†æ–°ç©ºé—´ã€‚æœ€ç»ˆï¼Œè¯¥æ–¹æ¡ˆå°†æ¨¡å‹è®­ç»ƒæ—¶é—´ï¼ˆtime-to-trainï¼‰ç¼©çŸ­äº†2.7å€ï¼Œä¸ºå®ç°å²æ— å‰ä¾‹çš„å¤§è§„æ¨¡æ¨¡å‹æ‰©å±•å¥ å®šäº†åŸºç¡€ã€‚",
      "categories": [
        "cs.AR",
        "cs.AI",
        "cs.DC",
        "cs.LG"
      ],
      "primary_category": "cs.AR",
      "comment": "12 pages, 11 figures. To be published in Hot Interconnects 2025",
      "pdf_url": "https://arxiv.org/pdf/2510.15893v1",
      "published_date": "2025-09-09 00:41:42 UTC",
      "updated_date": "2025-09-09 00:41:42 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:34:36.483048+00:00"
    },
    {
      "arxiv_id": "2509.08854v1",
      "title": "A vibe coding learning design to enhance EFL students' talking to, through, and about AI",
      "title_zh": "æ—¨åœ¨æå‡ EFL å­¦ç”Ÿä¸ AI å¯¹è¯ã€ç»ç”± AI è¡¨è¾¾åŠå…³äº AI æ€è€ƒèƒ½åŠ›çš„ Vibe Coding å­¦ä¹ è®¾è®¡",
      "authors": [
        "David James Woo",
        "Kai Guo",
        "Yangyang Yu"
      ],
      "abstract": "This innovative practice article reports on the piloting of vibe coding (using natural language to create software applications with AI) for English as a Foreign Language (EFL) education. We developed a human-AI meta-languaging framework with three dimensions: talking to AI (prompt engineering), talking through AI (negotiating authorship), and talking about AI (mental models of AI). Using backward design principles, we created a four-hour workshop where two students designed applications addressing authentic EFL writing challenges. We adopted a case study methodology, collecting data from worksheets and video recordings, think-aloud protocols, screen recordings, and AI-generated images. Contrasting cases showed one student successfully vibe coding a functional application cohering to her intended design, while another encountered technical difficulties with major gaps between intended design and actual functionality. Analysis reveals differences in students' prompt engineering approaches, suggesting different AI mental models and tensions in attributing authorship. We argue that AI functions as a beneficial languaging machine, and that differences in how students talk to, through, and about AI explain vibe coding outcome variations. Findings indicate that effective vibe coding instruction requires explicit meta-languaging scaffolding, teaching structured prompt engineering, facilitating critical authorship discussions, and developing vocabulary for articulating AI mental models.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†vibe codingï¼ˆåˆ©ç”¨è‡ªç„¶è¯­è¨€é€šè¿‡AIåˆ›å»ºè½¯ä»¶åº”ç”¨ï¼‰åœ¨EFLæ•™è‚²ä¸­çš„åˆ›æ–°å®è·µï¼Œæ—¨åœ¨æå‡å­¦ç”Ÿä¸AIåä½œçš„èƒ½åŠ›ã€‚ç ”ç©¶è€…å¼€å‘äº†ä¸€ä¸ªhuman-AI meta-languagingæ¡†æ¶ï¼Œæ¶µç›–äº†ä¸AIå¯¹è¯(talking to AI)ã€é€šè¿‡AIå¯¹è¯(talking through AI)ä»¥åŠè°ˆè®ºAI(talking about AI)ä¸‰ä¸ªæ ¸å¿ƒç»´åº¦ã€‚é€šè¿‡ä¸ºæœŸå››å°æ—¶çš„å·¥ä½œåŠå’Œcase studyï¼Œç ”ç©¶åˆ†æäº†å­¦ç”Ÿåœ¨åˆ©ç”¨AIè§£å†³çœŸå®å†™ä½œæŒ‘æˆ˜è¿‡ç¨‹ä¸­çš„è¡¨ç°ã€‚ç»“æœæ˜¾ç¤ºï¼Œå­¦ç”Ÿåœ¨prompt engineeringæŠ€å·§ã€AI mental modelsä»¥åŠå¯¹authorshipçš„ç•Œå®šä¸Šå­˜åœ¨æ˜¾è‘—å·®å¼‚ï¼Œè¿™äº›å› ç´ ç›´æ¥è§£é‡Šäº†vibe codingäº§å‡ºè´¨é‡çš„ä¸åŒã€‚ç ”ç©¶è®ºè¯äº†AIä½œä¸ºä¸€ç§languaging machineçš„ç›Šå¤„ï¼Œå¹¶å¼ºè°ƒæœ‰æ•ˆçš„æ•™å­¦è®¾è®¡éœ€è¦æä¾›æ˜¾æ€§çš„meta-languaging scaffoldingã€‚è¿™åŒ…æ‹¬æ•™æˆç»“æ„åŒ–çš„prompt engineeringæ–¹æ³•ã€å¼•å¯¼æ‰¹åˆ¤æ€§çš„authorshipè®¨è®ºï¼Œä»¥åŠå¸®åŠ©å­¦ç”Ÿå»ºç«‹æè¿°AI mental modelsçš„è¯æ±‡ä½“ç³»ã€‚",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CY",
      "comment": "15 pages, 12 figures",
      "pdf_url": "https://arxiv.org/pdf/2509.08854v1",
      "published_date": "2025-09-09 00:27:04 UTC",
      "updated_date": "2025-09-09 00:27:04 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:34:47.091251+00:00"
    }
  ],
  "processing_status": "completed",
  "error": null,
  "raw_papers_fetched": true,
  "papers_count": 112,
  "processed_papers_count": 112,
  "failed_papers_count": 0,
  "llm_backup_calls": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2026-01-24T17:35:39.642488+00:00"
}