[
  {
    "arxiv_id": "2512.19716v1",
    "title": "Development and external validation of a multimodal artificial intelligence mortality prediction model of critically ill patients using multicenter data",
    "authors": [
      "Behrooz Mamandipoor",
      "Chun-Nan Hsu",
      "Martin Krause",
      "Ulrich H. Schmidt",
      "Rodney A. Gabriel"
    ],
    "abstract": "Early prediction of in-hospital mortality in critically ill patients can aid clinicians in optimizing treatment. The objective was to develop a multimodal deep learning model, using structured and unstructured clinical data, to predict in-hospital mortality risk among critically ill patients after their initial 24 hour intensive care unit (ICU) admission. We used data from MIMIC-III, MIMIC-IV, eICU, and HiRID. A multimodal model was developed on the MIMIC datasets, featuring time series components occurring within the first 24 hours of ICU admission and predicting risk of subsequent inpatient mortality. Inputs included time-invariant variables, time-variant variables, clinical notes, and chest X-ray images. External validation occurred in a temporally separated MIMIC population, HiRID, and eICU datasets. A total of 203,434 ICU admissions from more than 200 hospitals between 2001 to 2022 were included, in which mortality rate ranged from 5.2% to 7.9% across the four datasets. The model integrating structured data points had AUROC, AUPRC, and Brier scores of 0.92, 0.53, and 0.19, respectively. We externally validated the model on eight different institutions within the eICU dataset, demonstrating AUROCs ranging from 0.84-0.92. When including only patients with available clinical notes and imaging data, inclusion of notes and imaging into the model, the AUROC, AUPRC, and Brier score improved from 0.87 to 0.89, 0.43 to 0.48, and 0.37 to 0.17, respectively. Our findings highlight the importance of incorporating multiple sources of patient information for mortality prediction and the importance of external validation.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "75 pages (33 main text + references, 35 supplementary materials), 5 figures, 2 tables",
    "pdf_url": "https://arxiv.org/pdf/2512.19716v1",
    "published_date": "2025-12-15 23:43:19 UTC",
    "updated_date": "2025-12-15 23:43:19 UTC"
  },
  {
    "arxiv_id": "2512.13956v1",
    "title": "Multi-Agent Collaborative Framework for Intelligent IT Operations: An AOI System with Context-Aware Compression and Dynamic Task Scheduling",
    "authors": [
      "Zishan Bai",
      "Enze Ge",
      "Junfeng Hao"
    ],
    "abstract": "The proliferation of cloud-native architectures, characterized by microservices and dynamic orchestration, has rendered modern IT infrastructures exceedingly complex and volatile. This complexity generates overwhelming volumes of operational data, leading to critical bottlenecks in conventional systems: inefficient information processing, poor task coordination, and loss of contextual continuity during fault diagnosis and remediation. To address these challenges, we propose AOI (AI-Oriented Operations), a novel multi-agent collaborative framework that integrates three specialized agents with an LLM-based Context Compressor. Its core innovations include: (1) a dynamic task scheduling strategy that adaptively prioritizes operations based on real-time system states, and (2) a three-layer memory architecture comprising Working, Episodic, and Semantic layers that optimizes context retention and retrieval. Extensive experiments on both synthetic and real-world benchmarks demonstrate that AOI effectively mitigates information overload, achieving a 72.4% context compression ratio while preserving 92.8% of critical information and significantly enhances operational efficiency, attaining a 94.2% task success rate and reducing the Mean Time to Repair (MTTR) by 34.4% compared to the best baseline. This work presents a paradigm shift towards scalable, adaptive, and context-aware autonomous operations, enabling robust management of next-generation IT infrastructures with minimal human intervention.",
    "categories": [
      "cs.MA",
      "cs.AI"
    ],
    "primary_category": "cs.MA",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.13956v1",
    "published_date": "2025-12-15 23:22:02 UTC",
    "updated_date": "2025-12-15 23:22:02 UTC"
  },
  {
    "arxiv_id": "2512.13955v1",
    "title": "MURIM: Multidimensional Reputation-based Incentive Mechanism for Federated Learning",
    "authors": [
      "Sindhuja Madabushi",
      "Dawood Wasif",
      "Jin-Hee Cho"
    ],
    "abstract": "Federated Learning (FL) has emerged as a leading privacy-preserving machine learning paradigm, enabling participants to share model updates instead of raw data. However, FL continues to face key challenges, including weak client incentives, privacy risks, and resource constraints. Assessing client reliability is essential for fair incentive allocation and ensuring that each client's data contributes meaningfully to the global model. To this end, we propose MURIM, a MUlti-dimensional Reputation-based Incentive Mechanism that jointly considers client reliability, privacy, resource capacity, and fairness while preventing malicious or unreliable clients from earning undeserved rewards. MURIM allocates incentives based on client contribution, latency, and reputation, supported by a reliability verification module. Extensive experiments on MNIST, FMNIST, and ADULT Income datasets demonstrate that MURIM achieves up to 18% improvement in fairness metrics, reduces privacy attack success rates by 5-9%, and improves robustness against poisoning and noisy-gradient attacks by up to 85% compared to state-of-the-art baselines. Overall, MURIM effectively mitigates adversarial threats, promotes fair and truthful participation, and preserves stable model convergence across heterogeneous and dynamic federated settings.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.13955v1",
    "published_date": "2025-12-15 23:18:32 UTC",
    "updated_date": "2025-12-15 23:18:32 UTC"
  },
  {
    "arxiv_id": "2512.13935v1",
    "title": "Informing Acquisition Functions via Foundation Models for Molecular Discovery",
    "authors": [
      "Qi Chen",
      "Fabio Ramos",
      "Alán Aspuru-Guzik",
      "Florian Shkurti"
    ],
    "abstract": "Bayesian Optimization (BO) is a key methodology for accelerating molecular discovery by estimating the mapping from molecules to their properties while seeking the optimal candidate. Typically, BO iteratively updates a probabilistic surrogate model of this mapping and optimizes acquisition functions derived from the model to guide molecule selection. However, its performance is limited in low-data regimes with insufficient prior knowledge and vast candidate spaces. Large language models (LLMs) and chemistry foundation models offer rich priors to enhance BO, but high-dimensional features, costly in-context learning, and the computational burden of deep Bayesian surrogates hinder their full utilization. To address these challenges, we propose a likelihood-free BO method that bypasses explicit surrogate modeling and directly leverages priors from general LLMs and chemistry-specific foundation models to inform acquisition functions. Our method also learns a tree-structured partition of the molecular search space with local acquisition functions, enabling efficient candidate selection via Monte Carlo Tree Search. By further incorporating coarse-grained LLM-based clustering, it substantially improves scalability to large candidate sets by restricting acquisition function evaluations to clusters with statistically higher property values. We show through extensive experiments and ablations that the proposed method substantially improves scalability, robustness, and sample efficiency in LLM-guided BO for molecular discovery.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "q-bio.QM"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.13935v1",
    "published_date": "2025-12-15 22:19:21 UTC",
    "updated_date": "2025-12-15 22:19:21 UTC"
  },
  {
    "arxiv_id": "2512.13930v1",
    "title": "Hierarchical Multi-agent Large Language Model Reasoning for Autonomous Functional Materials Discovery",
    "authors": [
      "Samuel Rothfarb",
      "Megan C. Davis",
      "Ivana Matanovic",
      "Baikun Li",
      "Edward F. Holby",
      "Wilton J. M. Kort-Kamp"
    ],
    "abstract": "Artificial intelligence is reshaping scientific exploration, but most methods automate procedural tasks without engaging in scientific reasoning, limiting autonomy in discovery. We introduce Materials Agents for Simulation and Theory in Electronic-structure Reasoning (MASTER), an active learning framework where large language models autonomously design, execute, and interpret atomistic simulations. In MASTER, a multimodal system translates natural language into density functional theory workflows, while higher-level reasoning agents guide discovery through a hierarchy of strategies, including a single agent baseline and three multi-agent approaches: peer review, triage-ranking, and triage-forms. Across two chemical applications, CO adsorption on Cu-surface transition metal (M) adatoms and on M-N-C catalysts, reasoning-driven exploration reduces required atomistic simulations by up to 90% relative to trial-and-error selection. Reasoning trajectories reveal chemically grounded decisions that cannot be explained by stochastic sampling or semantic bias. Altogether, multi-agent collaboration accelerates materials discovery and marks a new paradigm for autonomous scientific exploration.",
    "categories": [
      "cond-mat.mtrl-sci",
      "cs.AI",
      "cs.CL",
      "cs.LG",
      "cs.MA"
    ],
    "primary_category": "cond-mat.mtrl-sci",
    "comment": "Keywords: Multi-agent reasoning; Large language models; Active learning; AI-driven simulation; Materials discovery; Density functional theory; Surface chemistry",
    "pdf_url": "https://arxiv.org/pdf/2512.13930v1",
    "published_date": "2025-12-15 22:08:18 UTC",
    "updated_date": "2025-12-15 22:08:18 UTC"
  },
  {
    "arxiv_id": "2512.13914v1",
    "title": "Context Branching for LLM Conversations: A Version Control Approach to Exploratory Programming",
    "authors": [
      "Bhargav Chickmagalur Nanjundappa",
      "Spandan Maaheshwari"
    ],
    "abstract": "Large Language Models (LLMs) have become integral to software engineering workflows, yet their effectiveness degrades significantly in multi-turn conversations. Recent studies demonstrate an average 39% performance drop when instructions are delivered across multiple turns, with models making premature assumptions and failing to course correct (Laban et al., 2025). This degradation is particularly problematic in exploratory programming tasks where developers need to investigate alternative approaches without committing to a single path. Current solutions force users into a false dichotomy: continue in a context-polluted conversation where the LLM becomes increasingly confused, or start fresh and lose all accumulated context.\n  We present ContextBranch, a conversation management system that applies version control semantics to LLM interactions. ContextBranch provides four core primitives--checkpoint, branch, switch, and inject--enabling users to capture conversation state, explore alternatives in isolation, and selectively merge insights. We evaluate ContextBranch through a controlled experiment with 30 software engineering scenarios featuring intentionally polluting explorations. Branched conversations achieved higher response quality compared to linear conversations, with large improvements in focus and context awareness. Benefits were concentrated in complex scenarios involving conceptually distant explorations. Branching reduced context size by 58.1% (31.0 to 13.0 messages), eliminating irrelevant exploratory content. Our work establishes conversation branching as a fundamental primitive for AI-assisted exploratory work, demonstrating that isolation prevents context pollution when exploring alternatives.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.SE",
    "comment": "11 pages, 4 figures, 2 tables, 1 code snippet, 4 algorithms",
    "pdf_url": "https://arxiv.org/pdf/2512.13914v1",
    "published_date": "2025-12-15 21:49:13 UTC",
    "updated_date": "2025-12-15 21:49:13 UTC"
  },
  {
    "arxiv_id": "2512.13912v1",
    "title": "Intelligent matter consisting of active particles",
    "authors": [
      "Julian Jeggle",
      "Raphael Wittkowski"
    ],
    "abstract": "In this book chapter, we review how systems of simple motile agents can be used as a pathway to intelligent systems. It is a well known result from nature that large groups of entities following simple rules, such as swarms of animals, can give rise to much more complex collective behavior in a display of emergence. This begs the question whether we can emulate this behavior in synthetic matter and drive it to a point where the collective behavior reaches the complexity level of intelligent systems. Here, we will use a formalized notion of \"intelligent matter\" and compare it to recent results in the field of active matter. First, we will explore the approach of emergent computing in which specialized active matter systems are designed to directly solve a given task through emergent behavior. This we will then contrast with the approach of physical reservoir computing powered by the dynamics of active particle systems. In this context, we will also describe a novel reservoir computing scheme for active particles driven ultrasonically or via light refraction.",
    "categories": [
      "cond-mat.soft",
      "cond-mat.dis-nn",
      "cs.AI",
      "cs.LG",
      "physics.app-ph"
    ],
    "primary_category": "cond-mat.soft",
    "comment": "14 pages, 5 figures",
    "pdf_url": "https://arxiv.org/pdf/2512.13912v1",
    "published_date": "2025-12-15 21:39:01 UTC",
    "updated_date": "2025-12-15 21:39:01 UTC"
  },
  {
    "arxiv_id": "2512.13910v1",
    "title": "Exploring Machine Learning, Deep Learning, and Explainable AI Methods for Seasonal Precipitation Prediction in South America",
    "authors": [
      "Matheus Corrêa Domingos",
      "Valdivino Alexandre de Santiago Júnior",
      "Juliana Aparecida Anochi",
      "Elcio Hideiti Shiguemori",
      "Luísa Mirelle Costa dos Santos",
      "Hércules Carlos dos Santos Pereira",
      "André Estevam Costa Oliveira"
    ],
    "abstract": "Forecasting meteorological variables is challenging due to the complexity of their processes, requiring advanced models for accuracy. Accurate precipitation forecasts are vital for society. Reliable predictions help communities mitigate climatic impacts. Based on the current relevance of artificial intelligence (AI), classical machine learning (ML) and deep learning (DL) techniques have been used as an alternative or complement to dynamic modeling. However, there is still a lack of broad investigations into the feasibility of purely data-driven approaches for precipitation forecasting. This study aims at addressing this issue where different classical ML and DL approaches for forecasting precipitation in South America, taking into account all 2019 seasons, are considered in a detailed investigation. The selected classical ML techniques were Random Forests and extreme gradient boosting (XGBoost), while the DL counterparts were a 1D convolutional neural network (CNN 1D), a long short-term memory (LSTM) model, and a gated recurrent unit (GRU) model. Additionally, the Brazilian Global Atmospheric Model (BAM) was used as a representative of the traditional dynamic modeling approach. We also relied on explainable artificial intelligence (XAI) to provide some explanations for the models behaviors. LSTM showed strong predictive performance while BAM, the traditional dynamic model representative, had the worst results. Despite presented the higher latency, LSTM was most accurate for heavy precipitation. If cost is a concern, XGBoost offers lower latency with slightly accuracy loss. The results of this research confirm the viability of DL models for climate forecasting, solidifying a global trend in major meteorological and climate forecasting centers.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.13910v1",
    "published_date": "2025-12-15 21:37:27 UTC",
    "updated_date": "2025-12-15 21:37:27 UTC"
  },
  {
    "arxiv_id": "2512.13907v2",
    "title": "Assessing High-Risk AI Systems under the EU AI Act: From Legal Requirements to Technical Verification",
    "authors": [
      "Alessio Buscemi",
      "Tom Deckenbrunnen",
      "Fahria Kabir",
      "Kateryna Mishchenko",
      "Nishat Mowla"
    ],
    "abstract": "The implementation of the AI Act requires practical mechanisms to verify compliance with legal obligations, yet concrete and operational mappings from high-level requirements to verifiable assessment activities remain limited, contributing to uneven readiness across Member States. This paper presents a structured mapping that translates high-level AI Act requirements into concrete, implementable verification activities applicable across the AI lifecycle. The mapping is derived through a systematic process in which legal requirements are decomposed into operational sub-requirements and grounded in authoritative standards and recognised practices. From this basis, verification activities are identified and characterised along two dimensions: the type of verification performed and the lifecycle target to which it applies. By making explicit the link between regulatory intent and technical and organisational assurance practices, the proposed mapping reduces interpretive uncertainty and provides a reusable reference for consistent, technology-agnostic compliance verification under the AI Act.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.13907v2",
    "published_date": "2025-12-15 21:24:29 UTC",
    "updated_date": "2025-12-22 13:38:32 UTC"
  },
  {
    "arxiv_id": "2512.13904v1",
    "title": "Generative AI for Video Translation: A Scalable Architecture for Multilingual Video Conferencing",
    "authors": [
      "Amirkia Rafiei Oskooei",
      "Eren Caglar",
      "Ibrahim Sahin",
      "Ayse Kayabay",
      "Mehmet S. Aktas"
    ],
    "abstract": "The real-time deployment of cascaded generative AI pipelines for applications like video translation is constrained by significant system-level challenges. These include the cumulative latency of sequential model inference and the quadratic ($\\mathcal{O}(N^2)$) computational complexity that renders multi-user video conferencing applications unscalable. This paper proposes and evaluates a practical system-level framework designed to mitigate these critical bottlenecks. The proposed architecture incorporates a turn-taking mechanism to reduce computational complexity from quadratic to linear in multi-user scenarios, and a segmented processing protocol to manage inference latency for a perceptually real-time experience. We implement a proof-of-concept pipeline and conduct a rigorous performance analysis across a multi-tiered hardware setup, including commodity (NVIDIA RTX 4060), cloud (NVIDIA T4), and enterprise (NVIDIA A100) GPUs. Our objective evaluation demonstrates that the system achieves real-time throughput ($τ< 1.0$) on modern hardware. A subjective user study further validates the approach, showing that a predictable, initial processing delay is highly acceptable to users in exchange for a smooth, uninterrupted playback experience. The work presents a validated, end-to-end system design that offers a practical roadmap for deploying scalable, real-time generative AI applications in multilingual communication platforms.",
    "categories": [
      "cs.MM",
      "cs.AI",
      "cs.CL",
      "cs.CV"
    ],
    "primary_category": "cs.MM",
    "comment": "Accepted manuscript. Published in Applied Sciences, 2025",
    "pdf_url": "https://arxiv.org/pdf/2512.13904v1",
    "published_date": "2025-12-15 21:21:09 UTC",
    "updated_date": "2025-12-15 21:21:09 UTC"
  },
  {
    "arxiv_id": "2512.13892v2",
    "title": "One Permutation Is All You Need: Fast, Reliable Variable Importance and Model Stress-Testing",
    "authors": [
      "Albert Dorador"
    ],
    "abstract": "Reliable estimation of feature contributions in machine learning models is essential for trust, transparency and regulatory compliance, especially when models are proprietary or otherwise operate as black boxes. While permutation-based methods are a standard tool for this task, classical implementations rely on repeated random permutations, introducing computational overhead and stochastic instability. In this paper, we show that by replacing multiple random permutations with a single, deterministic, and optimal permutation, we achieve a method that retains the core principles of permutation-based importance while being non-random, faster, and more stable. We validate this approach across nearly 200 scenarios, including real-world household finance and credit risk applications, demonstrating improved bias-variance tradeoffs and accuracy in challenging regimes such as small sample sizes, high dimensionality, and low signal-to-noise ratios. Finally, we introduce Systemic Variable Importance, a natural extension designed for model stress-testing that explicitly accounts for feature correlations. This framework provides a transparent way to quantify how shocks or perturbations propagate through correlated inputs, revealing dependencies that standard variable importance measures miss. Two real-world case studies demonstrate how this metric can be used to audit models for hidden reliance on protected attributes (e.g., gender or race), enabling regulators and practitioners to assess fairness and systemic risk in a principled and computationally efficient manner.",
    "categories": [
      "stat.ML",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "stat.ML",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.13892v2",
    "published_date": "2025-12-15 20:50:54 UTC",
    "updated_date": "2025-12-23 12:54:15 UTC"
  },
  {
    "arxiv_id": "2512.13886v2",
    "title": "OPTIMA: Optimal One-shot Pruning for LLMs via Quadratic Programming Reconstruction",
    "authors": [
      "Mohammad Mozaffari",
      "Samuel Kushnir",
      "Maryam Mehri Dehnavi",
      "Amir Yazdanbakhsh"
    ],
    "abstract": "Post-training model pruning is a promising solution, yet it faces a trade-off: simple heuristics that zero weights are fast but degrade accuracy, while principled joint optimization methods recover accuracy but are computationally infeasible at modern scale. One-shot methods such as SparseGPT offer a practical trade-off in optimality by applying efficient, approximate heuristic weight updates. To close this gap, we introduce OPTIMA, a practical one-shot post-training pruning method that balances accuracy and scalability. OPTIMA casts layer-wise weight reconstruction after mask selection as independent, row-wise Quadratic Programs (QPs) that share a common layer Hessian. Solving these QPs yields the per-row globally optimal update with respect to the reconstruction objective given the estimated Hessian. The shared-Hessian structure makes the problem highly amenable to batching on accelerators. We implement an accelerator-friendly QP solver that accumulates one Hessian per layer and solves many small QPs in parallel, enabling one-shot post-training pruning at scale on a single accelerator without fine-tuning. OPTIMA integrates with existing mask selectors and consistently improves zero-shot performance across multiple LLM families and sparsity regimes, yielding up to 3.97% absolute accuracy improvement. On an NVIDIA H100, OPTIMA prunes a 8B-parameter transformer end-to-end in 40 hours with 60GB peak memory. Together, these results set a new state-of-the-art accuracy-efficiency trade-offs for one-shot post-training pruning.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.PF"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.13886v2",
    "published_date": "2025-12-15 20:41:29 UTC",
    "updated_date": "2025-12-31 02:49:31 UTC"
  },
  {
    "arxiv_id": "2512.14762v1",
    "title": "Workflows vs Agents for Code Translation",
    "authors": [
      "Henry Gray",
      "Tom Yotam",
      "Octavian Udrea"
    ],
    "abstract": "Translating algorithms from high-level languages like MATLAB to hardware description languages (HDLs) is a resource-intensive but necessary step for deployment on FPGAs and ASICs. While large language models (LLMs) offer a path to automation, their limited training on HDL code makes end-to-end transpilation brittle and prone to syntax errors. We compare two LLM-driven methods for syntax repair in a MATLAB-to-HDL pipeline: a structured, expert-designed flow that follows a fixed sequence of operations, and a more autonomous agentic approach that uses the Model Context Protocol (MCP) \\cite{anthropic2024mcp} to dynamically select its own tools. We study 42 MATLAB signal-processing functions and isolate the syntax-repair stage. Across three model scales, the agentic approach is more effective at resolving initial syntax errors, unblocking a greater number of candidates to proceed through the pipeline. This upstream improvement yields measurable downstream improvements, most notably on mid-sized models, where it increases the simulation reach rate by over 20 percentage points. We hypothesize the gains come from short prompts, aggressive context management, and conditional tool use. Conditional retrieval helps at 8B and 30B; at 235B final-success gains are small and a naive RAG variant attains the highest final success. Our findings suggest that these agentic frameworks, when properly designed, are most effective at compensating for the capacity limits of small and mid-sized models.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.14762v1",
    "published_date": "2025-12-15 20:35:11 UTC",
    "updated_date": "2025-12-15 20:35:11 UTC"
  },
  {
    "arxiv_id": "2512.13880v1",
    "title": "Privacy-Enhancing Infant Cry Classification with Federated Transformers and Denoising Regularization",
    "authors": [
      "Geofrey Owino",
      "Bernard Shibwabo"
    ],
    "abstract": "Infant cry classification can aid early assessment of infant needs. However, deployment of such solutions is limited by privacy concerns around audio data, sensitivity to background noise, and domain shift across recording environments. We present an end-to-end infant cry analysis pipeline that integrates a denoising autoencoder (DAE), a convolutional tokenizer, and a Transformer encoder trained using communication-efficient federated learning (FL). The system performs on-device denoising, adaptive segmentation, post hoc calibration, and energy-based out-of-distribution (OOD) abstention. Federated training employs a regularized control variate update with 8-bit adapter deltas under secure aggregation. Using the Baby Chillanto and Donate-a-Cry datasets with ESC-50 noise overlays, the model achieves a macro F1 score of 0.938, an AUC of 0.962, and an Expected Calibration Error (ECE) of 0.032, while reducing per-round client upload from approximately 36 to 42 MB to 3.3 MB. Real-time edge inference on an NVIDIA Jetson Nano (4 GB, TensorRT FP16) achieves 96 ms per one-second spectrogram frame. These results demonstrate a practical path toward privacy-preserving, noise-robust, and communication-efficient infant cry classification suitable for federated deployment.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.SD"
    ],
    "primary_category": "cs.LG",
    "comment": "This paper was accepted for presentation and presented at the 2025 International Conference on Computer Engineering, Network, and Intelligent Multimedia (CENIM 2025)",
    "pdf_url": "https://arxiv.org/pdf/2512.13880v1",
    "published_date": "2025-12-15 20:33:24 UTC",
    "updated_date": "2025-12-15 20:33:24 UTC"
  },
  {
    "arxiv_id": "2512.15787v1",
    "title": "Toward Agentic Environments: GenAI and the Convergence of AI, Sustainability, and Human-Centric Spaces",
    "authors": [
      "Przemek Pospieszny",
      "Dominika P. Brodowicz"
    ],
    "abstract": "In recent years, advances in artificial intelligence (AI), particularly generative AI (GenAI) and large language models (LLMs), have made human-computer interactions more frequent, efficient, and accessible across sectors ranging from banking to healthcare. AI tools embedded in digital devices support decision-making and operational management at both individual and organizational levels, including resource allocation, workflow automation, and real-time data analysis. However, the prevailing cloud-centric deployment of AI carries a substantial environmental footprint due to high computational demands. In this context, this paper introduces the concept of agentic environments, a sustainability-oriented AI framework that extends beyond reactive systems by leveraging GenAI, multi-agent systems, and edge computing to reduce the environmental impact of technology. Agentic environments enable more efficient resource use, improved quality of life, and sustainability-by-design, while simultaneously enhancing data privacy through decentralized, edge-driven solutions. Drawing on secondary research as well as primary data from focus groups and semi-structured interviews with AI professionals from leading technology companies, the paper proposes a conceptual framework for agentic environments examined through three lenses: the personal sphere, professional and commercial use, and urban operations. The findings highlight the potential of agentic environments to foster sustainable ecosystems through optimized resource utilization and strengthened data privacy. The study concludes with recommendations for edge-driven deployment models to reduce reliance on energy-intensive cloud infrastructures.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "Preprint, Paper submitted for publication in Sustainable Development (Wiley)",
    "pdf_url": "https://arxiv.org/pdf/2512.15787v1",
    "published_date": "2025-12-15 20:15:02 UTC",
    "updated_date": "2025-12-15 20:15:02 UTC"
  },
  {
    "arxiv_id": "2512.13860v1",
    "title": "Verification-Guided Context Optimization for Tool Calling via Hierarchical LLMs-as-Editors",
    "authors": [
      "Henger Li",
      "Shuangjie You",
      "Flavio Di Palo",
      "Yiyue Qian",
      "Ayush Jain"
    ],
    "abstract": "Tool calling enables large language models (LLMs) to interact with external environments through tool invocation, providing a practical way to overcome the limitations of pretraining. However, the effectiveness of tool use depends heavily on the quality of the associated documentation and knowledge base context. These materials are usually written for human users and are often misaligned with how LLMs interpret information. This problem is even more pronounced in industrial settings, where hundreds of tools with overlapping functionality create challenges in scalability, variability, and ambiguity. We propose Verification-Guided Context Optimization (VGCO), a framework that uses LLMs as editors to automatically refine tool-related documentation and knowledge base context. VGCO works in two stages. First, Evaluation collects real-world failure cases and identifies mismatches between tools and their context. Second, Optimization performs hierarchical editing through offline learning with structure-aware, in-context optimization. The novelty of our LLM editors has three main aspects. First, they use a hierarchical structure that naturally integrates into the tool-calling workflow. Second, they are state-aware, action-specific, and verification-guided, which constrains the search space and enables efficient, targeted improvements. Third, they enable cost-efficient sub-task specialization, either by prompt engineering large editor models or by post-training smaller editor models. Unlike prior work that emphasizes multi-turn reasoning, VGCO focuses on the single-turn, large-scale tool-calling problem and achieves significant improvements in accuracy, robustness, and generalization across LLMs.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "Accepted by AAAI 2026 Workshop on Agentic AI Benchmarks and Applications for Enterprise Tasks",
    "pdf_url": "https://arxiv.org/pdf/2512.13860v1",
    "published_date": "2025-12-15 19:48:21 UTC",
    "updated_date": "2025-12-15 19:48:21 UTC"
  },
  {
    "arxiv_id": "2512.13857v2",
    "title": "EvoLattice: Persistent Internal-Population Evolution through Multi-Alternative Quality-Diversity Graph Representations for LLM-Guided Program Discovery",
    "authors": [
      "Kamer Ali Yuksel"
    ],
    "abstract": "Large language models (LLMs) are increasingly used to evolve programs and multi-agent systems, yet most existing approaches rely on overwrite-based mutations that maintain only a single candidate at a time. Such methods discard useful variants, suffer from destructive edits, and explore a brittle search space prone to structural failure. We introduce EvoLattice, a framework that represents an entire population of candidate programs or agent behaviors within a single directed acyclic graph. Each node stores multiple persistent alternatives, and every valid path through the graph defines a distinct executable candidate, yielding a large combinatorial search space without duplicating structure. EvoLattice enables fine-grained alternative-level evaluation by scoring each alternative across all paths in which it appears, producing statistics that reveal how local design choices affect global performance. These statistics provide a dense, data-driven feedback signal for LLM-guided mutation, recombination, and pruning, while preserving successful components. Structural correctness is guaranteed by a deterministic self-repair mechanism that enforces acyclicity and dependency consistency independently of the LLM. EvoLattice naturally extends to agent evolution by interpreting alternatives as prompt fragments or sub-agent behaviors. Across program synthesis (proxy and optimizer meta-learning), EvoLattice yields more stable evolution, greater expressivity, and stronger improvement trajectories than prior LLM-guided methods. The resulting dynamics resemble quality-diversity optimization, emerging implicitly from EvoLattice's internal multi-alternative representation rather than an explicit external archive.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG",
      "cs.MA",
      "cs.NE"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.13857v2",
    "published_date": "2025-12-15 19:43:06 UTC",
    "updated_date": "2025-12-17 12:18:41 UTC"
  },
  {
    "arxiv_id": "2512.13855v1",
    "title": "Improvise, Adapt, Overcome -- Telescopic Adapters for Efficient Fine-tuning of Vision Language Models in Medical Imaging",
    "authors": [
      "Ujjwal Mishra",
      "Vinita Shukla",
      "Praful Hambarde",
      "Amit Shukla"
    ],
    "abstract": "Adapting Vision Language Segmentation Models (VLSMs) to medical imaging domains requires significant computational overhead when using conventional fine-tuning approaches. Existing Parameter-Efficient Fine-Tuning (PEFT) methods apply uniform adapter dimensions across all transformer layers, leading to suboptimal parameter allocation and reduced adaptation efficiency. We introduce Telescopic Adapters, a novel PEFT framework that employs depth-aware scaling to progressively increase adapter capacity from shallow to deep transformer layers. Our method integrates lightweight bottleneck modules within CLIPSeg's vision and text encoders, with adapter dimensions dynamically scaled based on layer depth and semantic relevance. Using only 613k trainable parameters--244x fewer than end-to-end fine-tuning, Telescopic Adapters achieve superior performance across five diverse medical datasets spanning polyp segmentation, skin lesion detection, and breast ultrasound imaging. Comprehensive ablation studies demonstrate that deeper layers require substantially more adaptation capacity than shallow layers, validating our telescopic scaling hypothesis. Our approach establishes a new paradigm for efficient medical VLSM fine-tuning, enabling deployment in resource-constrained clinical environments while maintaining competitive segmentation accuracy.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted at the IEEE/CVF winter conference on applications of computer vision (WACV 2026)",
    "pdf_url": "https://arxiv.org/pdf/2512.13855v1",
    "published_date": "2025-12-15 19:40:15 UTC",
    "updated_date": "2025-12-15 19:40:15 UTC"
  },
  {
    "arxiv_id": "2512.13834v1",
    "title": "VajraV1 -- The most accurate Real Time Object Detector of the YOLO family",
    "authors": [
      "Naman Balbir Singh Makkar"
    ],
    "abstract": "Recent years have seen significant advances in real-time object detection, with the release of YOLOv10, YOLO11, YOLOv12, and YOLOv13 between 2024 and 2025. This technical report presents the VajraV1 model architecture, which introduces architectural enhancements over existing YOLO-based detectors. VajraV1 combines effective design choices from prior YOLO models to achieve state-of-the-art accuracy among real-time object detectors while maintaining competitive inference speed.\n  On the COCO validation set, VajraV1-Nano achieves 44.3% mAP, outperforming YOLOv12-N by 3.7% and YOLOv13-N by 2.7% at latency competitive with YOLOv12-N and YOLOv11-N. VajraV1-Small achieves 50.4% mAP, exceeding YOLOv12-S and YOLOv13-S by 2.4%. VajraV1-Medium achieves 52.7% mAP, outperforming YOLOv12-M by 0.2%. VajraV1-Large achieves 53.7% mAP, surpassing YOLOv13-L by 0.3%. VajraV1-Xlarge achieves 56.2% mAP, outperforming all existing real-time object detectors.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Technical Report. 20 Pages, 7 figures",
    "pdf_url": "https://arxiv.org/pdf/2512.13834v1",
    "published_date": "2025-12-15 19:16:15 UTC",
    "updated_date": "2025-12-15 19:16:15 UTC"
  },
  {
    "arxiv_id": "2512.13806v1",
    "title": "EEG-D3: A Solution to the Hidden Overfitting Problem of Deep Learning Models",
    "authors": [
      "Siegfried Ludwig",
      "Stylianos Bakas",
      "Konstantinos Barmpas",
      "Georgios Zoumpourlis",
      "Dimitrios A. Adamos",
      "Nikolaos Laskaris",
      "Yannis Panagakis",
      "Stefanos Zafeiriou"
    ],
    "abstract": "Deep learning for decoding EEG signals has gained traction, with many claims to state-of-the-art accuracy. However, despite the convincing benchmark performance, successful translation to real applications is limited. The frequent disconnect between performance on controlled BCI benchmarks and its lack of generalisation to practical settings indicates hidden overfitting problems. We introduce Disentangled Decoding Decomposition (D3), a weakly supervised method for training deep learning models across EEG datasets. By predicting the place in the respective trial sequence from which the input window was sampled, EEG-D3 separates latent components of brain activity, akin to non-linear ICA. We utilise a novel model architecture with fully independent sub-networks for strict interpretability. We outline a feature interpretation paradigm to contrast the component activation profiles on different datasets and inspect the associated temporal and spatial filters. The proposed method reliably separates latent components of brain activity on motor imagery data. Training downstream classifiers on an appropriate subset of these components prevents hidden overfitting caused by task-correlated artefacts, which severely affects end-to-end classifiers. We further exploit the linearly separable latent space for effective few-shot learning on sleep stage classification. The ability to distinguish genuine components of brain activity from spurious features results in models that avoid the hidden overfitting problem and generalise well to real-world applications, while requiring only minimal labelled data. With interest to the neuroscience community, the proposed method gives researchers a tool to separate individual brain processes and potentially even uncover heretofore unknown dynamics.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV",
      "cs.HC"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.13806v1",
    "published_date": "2025-12-15 19:00:10 UTC",
    "updated_date": "2025-12-15 19:00:10 UTC"
  },
  {
    "arxiv_id": "2512.13690v1",
    "title": "DiffusionBrowser: Interactive Diffusion Previews via Multi-Branch Decoders",
    "authors": [
      "Susung Hong",
      "Chongjian Ge",
      "Zhifei Zhang",
      "Jui-Hsien Wang"
    ],
    "abstract": "Video diffusion models have revolutionized generative video synthesis, but they are imprecise, slow, and can be opaque during generation -- keeping users in the dark for a prolonged period. In this work, we propose DiffusionBrowser, a model-agnostic, lightweight decoder framework that allows users to interactively generate previews at any point (timestep or transformer block) during the denoising process. Our model can generate multi-modal preview representations that include RGB and scene intrinsics at more than 4$\\times$ real-time speed (less than 1 second for a 4-second video) that convey consistent appearance and motion to the final video. With the trained decoder, we show that it is possible to interactively guide the generation at intermediate noise steps via stochasticity reinjection and modal steering, unlocking a new control capability. Moreover, we systematically probe the model using the learned decoders, revealing how scene, object, and other details are composed and assembled during the otherwise black-box denoising process.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.GR",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Project page: https://susunghong.github.io/DiffusionBrowser",
    "pdf_url": "https://arxiv.org/pdf/2512.13690v1",
    "published_date": "2025-12-15 18:59:57 UTC",
    "updated_date": "2025-12-15 18:59:57 UTC"
  },
  {
    "arxiv_id": "2512.13678v1",
    "title": "Feedforward 3D Editing via Text-Steerable Image-to-3D",
    "authors": [
      "Ziqi Ma",
      "Hongqiao Chen",
      "Yisong Yue",
      "Georgia Gkioxari"
    ],
    "abstract": "Recent progress in image-to-3D has opened up immense possibilities for design, AR/VR, and robotics. However, to use AI-generated 3D assets in real applications, a critical requirement is the capability to edit them easily. We present a feedforward method, Steer3D, to add text steerability to image-to-3D models, which enables editing of generated 3D assets with language. Our approach is inspired by ControlNet, which we adapt to image-to-3D generation to enable text steering directly in a forward pass. We build a scalable data engine for automatic data generation, and develop a two-stage training recipe based on flow-matching training and Direct Preference Optimization (DPO). Compared to competing methods, Steer3D more faithfully follows the language instruction and maintains better consistency with the original 3D asset, while being 2.4x to 28.5x faster. Steer3D demonstrates that it is possible to add a new modality (text) to steer the generation of pretrained image-to-3D generative models with 100k data. Project website: https://glab-caltech.github.io/steer3d/",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "https://glab-caltech.github.io/steer3d/",
    "pdf_url": "https://arxiv.org/pdf/2512.13678v1",
    "published_date": "2025-12-15 18:58:55 UTC",
    "updated_date": "2025-12-15 18:58:55 UTC"
  },
  {
    "arxiv_id": "2512.14761v1",
    "title": "CAPE: Capability Achievement via Policy Execution",
    "authors": [
      "David Ball"
    ],
    "abstract": "Modern AI systems lack a way to express and enforce requirements. Pre-training produces intelligence, and post-training optimizes preferences, but neither guarantees that models reliably satisfy explicit, context-dependent constraints. This missing abstraction explains why highly intelligent models routinely fail in deployment despite strong benchmark performance.\n  We introduce Capability Engineering, the systematic practice of converting requirements into executable specifications and training models to satisfy them by default. We operationalize this practice through CAPE (Capability Achievement via Policy Execution), a protocol implementing a Specify -> Verify -> Correct -> Train loop.\n  CAPE is grounded in two empirical findings: (1) contextual objectivity, where properties appearing subjective become objective once context is fixed (inter-annotator agreement rises from kappa = 0.42 to kappa = 0.98), and (2) verification-fidelity scaling, where verification accuracy improves with model scale (r = 0.94), unlike preference agreement which plateaus at 30 to 50 percent disagreement regardless of compute. Across 109,500 examples in six domains, CAPE reduces violation rates by 81 percent relative to DPO (standard deviation less than 0.3 percent). By replacing per-example annotation with reusable specifications, CAPE reduces costs by 5 to 20 times and shortens timelines from months to weeks.\n  We release the CAPE protocol, PredicateGraph schema, CPL specification language, and policy packs under Apache 2.0. We also launch CapabilityBench, a public registry of model evaluations against community-contributed policies, shifting evaluation from intelligence benchmarks toward capability measurement.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.SE",
    "comment": "32 pages, 3 figures",
    "pdf_url": "https://arxiv.org/pdf/2512.14761v1",
    "published_date": "2025-12-15 18:58:21 UTC",
    "updated_date": "2025-12-15 18:58:21 UTC"
  },
  {
    "arxiv_id": "2512.15786v1",
    "title": "Cultural Rights and the Rights to Development in the Age of AI: Implications for Global Human Rights Governance",
    "authors": [
      "Alexander Kriebitz",
      "Caitlin Corrigan",
      "Aive Pevkur",
      "Alberto Santos Ferro",
      "Amanda Horzyk",
      "Dirk Brand",
      "Dohee Kim",
      "Dodzi Koku Hattoh",
      "Flavia Massucci",
      "Gilles Fayad",
      "Kamil Strzepek",
      "Laud Ammah",
      "Lavina Ramkissoon",
      "Mariette Awad",
      "Natalia Amasiadi",
      "Nathan C. Walker",
      "Nicole Manger",
      "Sophia Devlin"
    ],
    "abstract": "Cultural rights and the right to development are essential norms within the wider framework of international human rights law. However, recent technological advances in artificial intelligence (AI) and adjacent digital frontier technologies pose significant challenges to the protection and realization of these rights. This owes to the increasing influence of AI systems on the creation and depiction of cultural content, affect the use and distribution of the intellectual property of individuals and communities, and influence cultural participation and expression worldwide. In addition, the growing influence of AI thus risks exacerbating preexisting economic, social and digital divides and reinforcing inequities for marginalized communities. This dynamic challenges the existing interplay between cultural rights and the right to development, and raises questions about the integration of cultural and developmental considerations into emerging AI governance frameworks. To address these challenges, the paper examines the impact of AI on both categories of rights. Conceptually, it analyzes the epistemic and normative limitations of AI with respect to cultural and developmental assumptions embedded in algorithmic design and deployment, but also individual and structural impacts of AI on both rights. On this basis, the paper identifies gaps and tensions in existing AI governance frameworks with respect to cultural rights and the right to development.\n  By situating cultural rights and the right to development within the broader landscape of AI and human rights, this paper contributes to the academic discourse on AI ethics, legal frameworks, and international human rights law. Finally, it outlines avenues for future research and policy development based on existing conversations in global AI governance.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.15786v1",
    "published_date": "2025-12-15 18:56:36 UTC",
    "updated_date": "2025-12-15 18:56:36 UTC"
  },
  {
    "arxiv_id": "2512.13658v1",
    "title": "Embedding-Based Rankings of Educational Resources based on Learning Outcome Alignment: Benchmarking, Expert Validation, and Learner Performance",
    "authors": [
      "Mohammadreza Molavi",
      "Mohammad Moein",
      "Mohammadreza Tavakoli",
      "Abdolali Faraji",
      "Stefan T. Mol",
      "Gábor Kismihók"
    ],
    "abstract": "As the online learning landscape evolves, the need for personalization is increasingly evident. Although educational resources are burgeoning, educators face challenges selecting materials that both align with intended learning outcomes and address diverse learner needs. Large Language Models (LLMs) are attracting growing interest for their potential to create learning resources that better support personalization, but verifying coverage of intended outcomes still requires human alignment review, which is costly and limits scalability. We propose a framework that supports the cost-effective automation of evaluating alignment between educational resources and intended learning outcomes. Using human-generated materials, we benchmarked LLM-based text-embedding models and found that the most accurate model (Voyage) achieved 79% accuracy in detecting alignment. We then applied the optimal model to LLM-generated resources and, via expert evaluation, confirmed that it reliably assessed correspondence to intended outcomes (83% accuracy). Finally, in a three-group experiment with 360 learners, higher alignment scores were positively related to greater learning performance, chi-squared(2, N = 360) = 15.39, p < 0.001. These findings show that embedding-based alignment scores can facilitate scalable personalization by confirming alignment with learning outcomes, which allows teachers to focus on tailoring content to diverse learner needs.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "Accepted for publication at the 16th International Conference on Learning Analytics & Knowledge (LAK 2026)",
    "pdf_url": "https://arxiv.org/pdf/2512.13658v1",
    "published_date": "2025-12-15 18:51:00 UTC",
    "updated_date": "2025-12-15 18:51:00 UTC"
  },
  {
    "arxiv_id": "2512.13654v1",
    "title": "Large-Language Memorization During the Classification of United States Supreme Court Cases",
    "authors": [
      "John E. Ortega",
      "Dhruv D. Joshi",
      "Matt P. Borkowski"
    ],
    "abstract": "Large-language models (LLMs) have been shown to respond in a variety of ways for classification tasks outside of question-answering. LLM responses are sometimes called \"hallucinations\" since the output is not what is ex pected. Memorization strategies in LLMs are being studied in detail, with the goal of understanding how LLMs respond. We perform a deep dive into a classification task based on United States Supreme Court (SCOTUS) decisions. The SCOTUS corpus is an ideal classification task to study for LLM memory accuracy because it presents significant challenges due to extensive sentence length, complex legal terminology, non-standard structure, and domain-specific vocabulary. Experimentation is performed with the latest LLM fine tuning and retrieval-based approaches, such as parameter-efficient fine-tuning, auto-modeling, and others, on two traditional category-based SCOTUS classification tasks: one with 15 labeled topics and another with 279. We show that prompt-based models with memories, such as DeepSeek, can be more robust than previous BERT-based models on both tasks scoring about 2 points better than previous models not based on prompting.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.ET",
      "cs.IR"
    ],
    "primary_category": "cs.CL",
    "comment": "7 pages, 1 figure, Appendix of Prompts",
    "pdf_url": "https://arxiv.org/pdf/2512.13654v1",
    "published_date": "2025-12-15 18:47:48 UTC",
    "updated_date": "2025-12-15 18:47:48 UTC"
  },
  {
    "arxiv_id": "2512.13644v1",
    "title": "World Models Can Leverage Human Videos for Dexterous Manipulation",
    "authors": [
      "Raktim Gautam Goswami",
      "Amir Bar",
      "David Fan",
      "Tsung-Yen Yang",
      "Gaoyue Zhou",
      "Prashanth Krishnamurthy",
      "Michael Rabbat",
      "Farshad Khorrami",
      "Yann LeCun"
    ],
    "abstract": "Dexterous manipulation is challenging because it requires understanding how subtle hand motion influences the environment through contact with objects. We introduce DexWM, a Dexterous Manipulation World Model that predicts the next latent state of the environment conditioned on past states and dexterous actions. To overcome the scarcity of dexterous manipulation datasets, DexWM is trained on over 900 hours of human and non-dexterous robot videos. To enable fine-grained dexterity, we find that predicting visual features alone is insufficient; therefore, we introduce an auxiliary hand consistency loss that enforces accurate hand configurations. DexWM outperforms prior world models conditioned on text, navigation, and full-body actions, achieving more accurate predictions of future states. DexWM also demonstrates strong zero-shot generalization to unseen manipulation skills when deployed on a Franka Panda arm equipped with an Allegro gripper, outperforming Diffusion Policy by over 50% on average in grasping, placing, and reaching tasks.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.13644v1",
    "published_date": "2025-12-15 18:37:12 UTC",
    "updated_date": "2025-12-15 18:37:12 UTC"
  },
  {
    "arxiv_id": "2512.13641v1",
    "title": "From Code to Field: Evaluating the Robustness of Convolutional Neural Networks for Disease Diagnosis in Mango Leaves",
    "authors": [
      "Gabriel Vitorino de Andrade",
      "Saulo Roberto dos Santos",
      "Itallo Patrick Castro Alves da Silva",
      "Emanuel Adler Medeiros Pereira",
      "Erick de Andrade Barboza"
    ],
    "abstract": "The validation and verification of artificial intelligence (AI) models through robustness assessment are essential to guarantee the reliable performance of intelligent systems facing real-world challenges, such as image corruptions including noise, blurring, and weather variations. Despite the global importance of mango (Mangifera indica L.), there is a lack of studies on the robustness of models for the diagnosis of disease in its leaves. This paper proposes a methodology to evaluate convolutional neural networks (CNNs) under adverse conditions. We adapted the MangoLeafDB dataset, generating MangoLeafDB-C with 19 types of artificial corruptions at five severity levels. We conducted a benchmark comparing five architectures: ResNet-50, ResNet-101, VGG-16, Xception, and LCNN (the latter being a lightweight architecture designed specifically for mango leaf diagnosis). The metrics include the F1 score, the corruption error (CE) and the relative mean corruption error (relative mCE). The results show that LCNN outperformed complex models in corruptions that can be present in real-world scenarios such as Defocus Blur, Motion Blur, while also achieving the lowest mCE. Modern architectures (e.g., ResNet-101) exhibited significant performance degradation in corrupted scenarios, despite their high accuracy under ideal conditions. These findings suggest that lightweight and specialized models may be more suitable for real-world applications in edge devices, where robustness and efficiency are critical. The study highlights the need to incorporate robustness assessments in the development of intelligent systems for agriculture, particularly in regions with technological limitations.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "This work was presented at the BRACIS 2025 conference in Fortaleza",
    "pdf_url": "https://arxiv.org/pdf/2512.13641v1",
    "published_date": "2025-12-15 18:36:48 UTC",
    "updated_date": "2025-12-15 18:36:48 UTC"
  },
  {
    "arxiv_id": "2512.13771v1",
    "title": "Semantic Grounding Index: Geometric Bounds on Context Engagement in RAG Systems",
    "authors": [
      "Javier Marín"
    ],
    "abstract": "When retrieval-augmented generation (RAG) systems hallucinate, what geometric trace does this leave in embedding space? We introduce the Semantic Grounding Index (SGI), defined as the ratio of angular distances from the response to the question versus the context on the unit hypersphere $\\mathbb{S}^{d-1}$.Our central finding is \\emph{semantic laziness}: hallucinated responses remain angularly proximate to questions rather than departing toward retrieved contexts. On HaluEval ($n$=5,000), we observe large effect sizes (Cohen's $d$ ranging from 0.92 to 1.28) across five embedding models with mean cross-model correlation $r$=0.85. Crucially, we derive from the spherical triangle inequality that SGI's discriminative power should increase with question-context angular separation $θ(q,c)$-a theoretical prediction confirmed empirically: effect size rises monotonically from $d$=0.61 -low $θ(q,c)$, to $d$=1.27 -high $θ(q,c)$, with AUC improving from 0.72 to 0.83. Subgroup analysis reveals that SGI excels on long responses ($d$=2.05) and short questions ($d$=1.22), while remaining robust across context lengths. Calibration analysis yields ECE=0.10, indicating SGI scores can serve as probability estimates, not merely rankings. A critical negative result on TruthfulQA (AUC=0.478) establishes that angular geometry measures topical engagement rather than factual accuracy. SGI provides computationally efficient, theoretically grounded infrastructure for identifying responses that warrant verification in production RAG deployments.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.13771v1",
    "published_date": "2025-12-15 18:09:54 UTC",
    "updated_date": "2025-12-15 18:09:54 UTC"
  },
  {
    "arxiv_id": "2512.13607v1",
    "title": "Nemotron-Cascade: Scaling Cascaded Reinforcement Learning for General-Purpose Reasoning Models",
    "authors": [
      "Boxin Wang",
      "Chankyu Lee",
      "Nayeon Lee",
      "Sheng-Chieh Lin",
      "Wenliang Dai",
      "Yang Chen",
      "Yangyi Chen",
      "Zhuolin Yang",
      "Zihan Liu",
      "Mohammad Shoeybi",
      "Bryan Catanzaro",
      "Wei Ping"
    ],
    "abstract": "Building general-purpose reasoning models with reinforcement learning (RL) entails substantial cross-domain heterogeneity, including large variation in inference-time response lengths and verification latency. Such variability complicates the RL infrastructure, slows training, and makes training curriculum (e.g., response length extension) and hyperparameter selection challenging. In this work, we propose cascaded domain-wise reinforcement learning (Cascade RL) to develop general-purpose reasoning models, Nemotron-Cascade, capable of operating in both instruct and deep thinking modes. Departing from conventional approaches that blend heterogeneous prompts from different domains, Cascade RL orchestrates sequential, domain-wise RL, reducing engineering complexity and delivering state-of-the-art performance across a wide range of benchmarks. Notably, RLHF for alignment, when used as a pre-step, boosts the model's reasoning ability far beyond mere preference optimization, and subsequent domain-wise RLVR stages rarely degrade the benchmark performance attained in earlier domains and may even improve it (see an illustration in Figure 1). Our 14B model, after RL, outperforms its SFT teacher, DeepSeek-R1-0528, on LiveCodeBench v5/v6/Pro and achieves silver-medal performance in the 2025 International Olympiad in Informatics (IOI). We transparently share our training and data recipes.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "We publicly release the Nemotron-Cascade models and the full collection of training data at: https://huggingface.co/collections/nvidia/nemotron-cascade",
    "pdf_url": "https://arxiv.org/pdf/2512.13607v1",
    "published_date": "2025-12-15 18:02:35 UTC",
    "updated_date": "2025-12-15 18:02:35 UTC"
  },
  {
    "arxiv_id": "2512.13600v1",
    "title": "DA-SSL: self-supervised domain adaptor to leverage foundational models in turbt histopathology slides",
    "authors": [
      "Haoyue Zhang",
      "Meera Chappidi",
      "Erolcan Sayar",
      "Helen Richards",
      "Zhijun Chen",
      "Lucas Liu",
      "Roxanne Wadia",
      "Peter A Humphrey",
      "Fady Ghali",
      "Alberto Contreras-Sanz",
      "Peter Black",
      "Jonathan Wright",
      "Stephanie Harmon",
      "Michael Haffner"
    ],
    "abstract": "Recent deep learning frameworks in histopathology, particularly multiple instance learning (MIL) combined with pathology foundational models (PFMs), have shown strong performance. However, PFMs exhibit limitations on certain cancer or specimen types due to domain shifts - these cancer types were rarely used for pretraining or specimens contain tissue-based artifacts rarely seen within the pretraining population. Such is the case for transurethral resection of bladder tumor (TURBT), which are essential for diagnosing muscle-invasive bladder cancer (MIBC), but contain fragmented tissue chips and electrocautery artifacts and were not widely used in publicly available PFMs. To address this, we propose a simple yet effective domain-adaptive self-supervised adaptor (DA-SSL) that realigns pretrained PFM features to the TURBT domain without fine-tuning the foundational model itself. We pilot this framework for predicting treatment response in TURBT, where histomorphological features are currently underutilized and identifying patients who will benefit from neoadjuvant chemotherapy (NAC) is challenging. In our multi-center study, DA-SSL achieved an AUC of 0.77+/-0.04 in five-fold cross-validation and an external test accuracy of 0.84, sensitivity of 0.71, and specificity of 0.91 using majority voting. Our results demonstrate that lightweight domain adaptation with self-supervision can effectively enhance PFM-based MIL pipelines for clinically challenging histopathology tasks. Code is Available at https://github.com/zhanghaoyue/DA_SSL_TURBT.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.13600v1",
    "published_date": "2025-12-15 17:53:18 UTC",
    "updated_date": "2025-12-15 17:53:18 UTC"
  },
  {
    "arxiv_id": "2512.13586v1",
    "title": "ReFusion: A Diffusion Large Language Model with Parallel Autoregressive Decoding",
    "authors": [
      "Jia-Nan Li",
      "Jian Guan",
      "Wei Wu",
      "Chongxuan Li"
    ],
    "abstract": "Autoregressive models (ARMs) are hindered by slow sequential inference. While masked diffusion models (MDMs) offer a parallel alternative, they suffer from critical drawbacks: high computational overhead from precluding Key-Value (KV) caching, and incoherent generation arising from learning dependencies over an intractable space of token combinations. To address these limitations, we introduce ReFusion, a novel masked diffusion model that achieves superior performance and efficiency by elevating parallel decoding from the token level to a higher slot level, where each slot is a fixed-length, contiguous sub-sequence. This is achieved through an iterative ``plan-and-infill'' decoding process: a diffusion-based planning step first identifies a set of weakly dependent slots, and an autoregressive infilling step then decodes these selected slots in parallel. The slot-based design simultaneously unlocks full KV cache reuse with a unified causal framework and reduces the learning complexity from the token combination space to a manageable slot-level permutation space. Extensive experiments on seven diverse benchmarks show that ReFusion not only overwhelmingly surpasses prior MDMs with 34% performance gains and an over 18$\\times$ speedup on average, but also bridges the performance gap to strong ARMs while maintaining a 2.33$\\times$ average speedup.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.13586v1",
    "published_date": "2025-12-15 17:41:19 UTC",
    "updated_date": "2025-12-15 17:41:19 UTC"
  },
  {
    "arxiv_id": "2512.13583v1",
    "title": "DP-CSGP: Differentially Private Stochastic Gradient Push with Compressed Communication",
    "authors": [
      "Zehan Zhu",
      "Heng Zhao",
      "Yan Huang",
      "Joey Tianyi Zhou",
      "Shouling Ji",
      "Jinming Xu"
    ],
    "abstract": "In this paper, we propose a Differentially Private Stochastic Gradient Push with Compressed communication (termed DP-CSGP) for decentralized learning over directed graphs. Different from existing works, the proposed algorithm is designed to maintain high model utility while ensuring both rigorous differential privacy (DP) guarantees and efficient communication. For general non-convex and smooth objective functions, we show that the proposed algorithm achieves a tight utility bound of $\\mathcal{O}\\left( \\sqrt{d\\log \\left( \\frac{1}δ \\right)}/(\\sqrt{n}Jε) \\right)$ ($J$ and $d$ are the number of local samples and the dimension of decision variables, respectively) with $\\left(ε, δ\\right)$-DP guarantee for each node, matching that of decentralized counterparts with exact communication. Extensive experiments on benchmark tasks show that, under the same privacy budget, DP-CSGP achieves comparable model accuracy with significantly lower communication cost than existing decentralized counterparts with exact communication.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "13 pages",
    "pdf_url": "https://arxiv.org/pdf/2512.13583v1",
    "published_date": "2025-12-15 17:37:02 UTC",
    "updated_date": "2025-12-15 17:37:02 UTC"
  },
  {
    "arxiv_id": "2512.13568v1",
    "title": "Superposition as Lossy Compression: Measure with Sparse Autoencoders and Connect to Adversarial Vulnerability",
    "authors": [
      "Leonard Bereska",
      "Zoe Tzifa-Kratira",
      "Reza Samavi",
      "Efstratios Gavves"
    ],
    "abstract": "Neural networks achieve remarkable performance through superposition: encoding multiple features as overlapping directions in activation space rather than dedicating individual neurons to each feature. This challenges interpretability, yet we lack principled methods to measure superposition. We present an information-theoretic framework measuring a neural representation's effective degrees of freedom. We apply Shannon entropy to sparse autoencoder activations to compute the number of effective features as the minimum neurons needed for interference-free encoding. Equivalently, this measures how many \"virtual neurons\" the network simulates through superposition. When networks encode more effective features than actual neurons, they must accept interference as the price of compression. Our metric strongly correlates with ground truth in toy models, detects minimal superposition in algorithmic tasks, and reveals systematic reduction under dropout. Layer-wise patterns mirror intrinsic dimensionality studies on Pythia-70M. The metric also captures developmental dynamics, detecting sharp feature consolidation during grokking. Surprisingly, adversarial training can increase effective features while improving robustness, contradicting the hypothesis that superposition causes vulnerability. Instead, the effect depends on task complexity and network capacity: simple tasks with ample capacity allow feature expansion (abundance regime), while complex tasks or limited capacity force reduction (scarcity regime). By defining superposition as lossy compression, this work enables principled measurement of how neural networks organize information under computational constraints, connecting superposition to adversarial robustness.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted to TMLR, view HTML here: https://leonardbereska.github.io/blog/2025/superposition/",
    "pdf_url": "https://arxiv.org/pdf/2512.13568v1",
    "published_date": "2025-12-15 17:25:39 UTC",
    "updated_date": "2025-12-15 17:25:39 UTC"
  },
  {
    "arxiv_id": "2512.13564v2",
    "title": "Memory in the Age of AI Agents",
    "authors": [
      "Yuyang Hu",
      "Shichun Liu",
      "Yanwei Yue",
      "Guibin Zhang",
      "Boyang Liu",
      "Fangyi Zhu",
      "Jiahang Lin",
      "Honglin Guo",
      "Shihan Dou",
      "Zhiheng Xi",
      "Senjie Jin",
      "Jiejun Tan",
      "Yanbin Yin",
      "Jiongnan Liu",
      "Zeyu Zhang",
      "Zhongxiang Sun",
      "Yutao Zhu",
      "Hao Sun",
      "Boci Peng",
      "Zhenrong Cheng",
      "Xuanbo Fan",
      "Jiaxin Guo",
      "Xinlei Yu",
      "Zhenhong Zhou",
      "Zewen Hu",
      "Jiahao Huo",
      "Junhao Wang",
      "Yuwei Niu",
      "Yu Wang",
      "Zhenfei Yin",
      "Xiaobin Hu",
      "Yue Liao",
      "Qiankun Li",
      "Kun Wang",
      "Wangchunshu Zhou",
      "Yixin Liu",
      "Dawei Cheng",
      "Qi Zhang",
      "Tao Gui",
      "Shirui Pan",
      "Yan Zhang",
      "Philip Torr",
      "Zhicheng Dou",
      "Ji-Rong Wen",
      "Xuanjing Huang",
      "Yu-Gang Jiang",
      "Shuicheng Yan"
    ],
    "abstract": "Memory has emerged, and will continue to remain, a core capability of foundation model-based agents. As research on agent memory rapidly expands and attracts unprecedented attention, the field has also become increasingly fragmented. Existing works that fall under the umbrella of agent memory often differ substantially in their motivations, implementations, and evaluation protocols, while the proliferation of loosely defined memory terminologies has further obscured conceptual clarity. Traditional taxonomies such as long/short-term memory have proven insufficient to capture the diversity of contemporary agent memory systems. This work aims to provide an up-to-date landscape of current agent memory research. We begin by clearly delineating the scope of agent memory and distinguishing it from related concepts such as LLM memory, retrieval augmented generation (RAG), and context engineering. We then examine agent memory through the unified lenses of forms, functions, and dynamics. From the perspective of forms, we identify three dominant realizations of agent memory, namely token-level, parametric, and latent memory. From the perspective of functions, we propose a finer-grained taxonomy that distinguishes factual, experiential, and working memory. From the perspective of dynamics, we analyze how memory is formed, evolved, and retrieved over time. To support practical development, we compile a comprehensive summary of memory benchmarks and open-source frameworks. Beyond consolidation, we articulate a forward-looking perspective on emerging research frontiers, including memory automation, reinforcement learning integration, multimodal memory, multi-agent memory, and trustworthiness issues. We hope this survey serves not only as a reference for existing work, but also as a conceptual foundation for rethinking memory as a first-class primitive in the design of future agentic intelligence.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.13564v2",
    "published_date": "2025-12-15 17:22:34 UTC",
    "updated_date": "2026-01-13 09:33:57 UTC"
  },
  {
    "arxiv_id": "2512.13559v1",
    "title": "Verifying Rumors via Stance-Aware Structural Modeling",
    "authors": [
      "Gibson Nkhata",
      "Uttamasha Anjally Oyshi",
      "Quan Mai",
      "Susan Gauch"
    ],
    "abstract": "Verifying rumors on social media is critical for mitigating the spread of false information. The stances of conversation replies often provide important cues to determine a rumor's veracity. However, existing models struggle to jointly capture semantic content, stance information, and conversation strructure, especially under the sequence length constraints of transformer-based encoders. In this work, we propose a stance-aware structural modeling that encodes each post in a discourse with its stance signal and aggregates reply embedddings by stance category enabling a scalable and semantically enriched representation of the entire thread. To enhance structural awareness, we introduce stance distribution and hierarchical depth as covariates, capturing stance imbalance and the influence of reply depth. Extensive experiments on benchmark datasets demonstrate that our approach significantly outperforms prior methods in the ability to predict truthfulness of a rumor. We also demonstrate that our model is versatile for early detection and cross-platfrom generalization.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.CL",
    "comment": "8 pages, 2 figures, published in The 24th IEEE/WIC International Conference on Web Intelligence and Intelligent Agent Technology (WI-IAT 2025), London, UK, 2025",
    "pdf_url": "https://arxiv.org/pdf/2512.13559v1",
    "published_date": "2025-12-15 17:16:56 UTC",
    "updated_date": "2025-12-15 17:16:56 UTC"
  },
  {
    "arxiv_id": "2512.21344v1",
    "title": "Atomistic Simulation Guided Convolutional Neural Networks for Thermal Modeling of Friction Stir Welding",
    "authors": [
      "Akshansh Mishra"
    ],
    "abstract": "Accurate prediction of temperature evolution is essential for understanding thermomechanical behavior in friction stir welding. In this study, molecular dynamics simulations were performed using LAMMPS to model aluminum friction stir welding at the atomic scale, capturing material flow, plastic deformation, and heat generation during tool plunge, traverse, and retraction. Atomic positions and velocities were extracted from simulation trajectories and transformed into physics based two dimensional spatial grids. These grids represent local height variation, velocity components, velocity magnitude, and atomic density, preserving spatial correlations within the weld zone. A two-dimensional convolutional neural network was developed to predict temperature directly from the spatially resolved atomistic data. Hyperparameter optimization was carried out to determine an appropriate network configuration. The trained model demonstrates strong predictive capability, achieving a coefficient of determination R square of 0.9439, a root mean square error of 14.94 K, and a mean absolute error of 11.58 K on unseen test data. Class Activation Map analysis indicates that the model assigns higher importance to regions near the tool material interface, which are associated with intense deformation and heat generation in the molecular dynamics simulations. The results show that spatial learning from atomistic simulation data can accurately reproduce temperature trends in friction stir welding while remaining consistent with physical deformation and flow mechanisms observed at the atomic scale.",
    "categories": [
      "cond-mat.mtrl-sci",
      "cs.AI",
      "cs.CE",
      "cs.LG"
    ],
    "primary_category": "cond-mat.mtrl-sci",
    "comment": "25 pages, 11 figures, 2 tables",
    "pdf_url": "https://arxiv.org/pdf/2512.21344v1",
    "published_date": "2025-12-15 16:41:42 UTC",
    "updated_date": "2025-12-15 16:41:42 UTC"
  },
  {
    "arxiv_id": "2512.13510v1",
    "title": "MedCEG: Reinforcing Verifiable Medical Reasoning with Critical Evidence Graph",
    "authors": [
      "Linjie Mu",
      "Yannian Gu",
      "Zhongzhen Huang",
      "Yakun Zhu",
      "Shaoting Zhang",
      "Xiaofan Zhang"
    ],
    "abstract": "Large language models with reasoning capabilities have demonstrated impressive performance across a wide range of domains. In clinical applications, a transparent, step-by-step reasoning process provides physicians with strong evidence to support decision-making. While reinforcement learning has effectively enhanced reasoning performance in medical contexts, the clinical reliability of these reasoning processes remains limited because their accuracy and validity are often overlooked during training. To address this gap, we propose MedCEG, a framework that augments medical language models with clinically valid reasoning pathways by explicitly supervising the reasoning process through a Critical Evidence Graph (CEG). We curate a dataset of challenging clinical cases and algorithmically construct a CEG for each sample to represent a high-quality verifiable reasoning pathway. To guide the reasoning process, we introduce a Clinical Reasoning Procedure Reward, which evaluates Node Coverage, Structural Correctness, and Chain Completeness, thereby providing a holistic assessment of reasoning quality. Experimental results show that MedCEG surpasses existing methods in performance while producing clinically valid reasoning chains, representing a solid advancement in reliable medical AI reasoning. The code and models are available at https://github.com/LinjieMu/MedCEG.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.13510v1",
    "published_date": "2025-12-15 16:38:46 UTC",
    "updated_date": "2025-12-15 16:38:46 UTC"
  },
  {
    "arxiv_id": "2512.13505v1",
    "title": "Defending the Hierarchical Result Models of Precedential Constraint",
    "authors": [
      "Henry Prakken",
      "Wijnand van Woerkom"
    ],
    "abstract": "In recent years, hierarchical case-based-reasoning models of precedential constraint have been proposed. In various papers, Trevor Bench-Capon criticised these models on the grounds that they would give incorrect outcomes in some cases. In particular, the models would not account for the possibility that intermediate factors are established with different strengths by different base-level factors. In this paper we respond to these criticisms for van Woerkom's result-based hierarchical models. We argue that in some examples Bench-Capon seems to interpret intermediate factors as dimensions, and that applying van Woerkom's dimension-based version of the hierarchical result model to these examples avoids Bench-Capon's criticisms.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "This is the long version of a paper with the same title presented at the 38th International Conference on Legal Knowledge and Information Systems",
    "pdf_url": "https://arxiv.org/pdf/2512.13505v1",
    "published_date": "2025-12-15 16:33:33 UTC",
    "updated_date": "2025-12-15 16:33:33 UTC"
  },
  {
    "arxiv_id": "2512.13501v1",
    "title": "Behavior-Aware and Generalizable Defense Against Black-Box Adversarial Attacks for ML-Based IDS",
    "authors": [
      "Sabrine Ennaji",
      "Elhadj Benkhelifa",
      "Luigi Vincenzo Mancini"
    ],
    "abstract": "Machine learning based intrusion detection systems are increasingly targeted by black box adversarial attacks, where attackers craft evasive inputs using indirect feedback such as binary outputs or behavioral signals like response time and resource usage. While several defenses have been proposed, including input transformation, adversarial training, and surrogate detection, they often fall short in practice. Most are tailored to specific attack types, require internal model access, or rely on static mechanisms that fail to generalize across evolving attack strategies. Furthermore, defenses such as input transformation can degrade intrusion detection system performance, making them unsuitable for real time deployment.\n  To address these limitations, we propose Adaptive Feature Poisoning, a lightweight and proactive defense mechanism designed specifically for realistic black box scenarios. Adaptive Feature Poisoning assumes that probing can occur silently and continuously, and introduces dynamic and context aware perturbations to selected traffic features, corrupting the attacker feedback loop without impacting detection capabilities. The method leverages traffic profiling, change point detection, and adaptive scaling to selectively perturb features that an attacker is likely exploiting, based on observed deviations.\n  We evaluate Adaptive Feature Poisoning against multiple realistic adversarial attack strategies, including silent probing, transferability based attacks, and decision boundary based attacks. The results demonstrate its ability to confuse attackers, degrade attack effectiveness, and preserve detection performance. By offering a generalizable, attack agnostic, and undetectable defense, Adaptive Feature Poisoning represents a significant step toward practical and robust adversarial resilience in machine learning based intrusion detection systems.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.13501v1",
    "published_date": "2025-12-15 16:29:23 UTC",
    "updated_date": "2025-12-15 16:29:23 UTC"
  },
  {
    "arxiv_id": "2512.13494v1",
    "title": "SkipCat: Rank-Maximized Low-Rank Compression of Large Language Models via Shared Projection and Block Skipping",
    "authors": [
      "Yu-Chen Lu",
      "Sheng-Feng Yu",
      "Hui-Hsien Weng",
      "Pei-Shuo Wang",
      "Yu-Fang Hu",
      "Liang Hung-Chun",
      "Hung-Yueh Chiang",
      "Kai-Chiang Wu"
    ],
    "abstract": "Large language models (LLM) have achieved remarkable performance across a wide range of tasks. However, their substantial parameter sizes pose significant challenges for deployment on edge devices with limited computational and memory resources. Low-rank compression is a promising approach to address this issue, as it reduces both computational and memory costs, making LLM more suitable for resource-constrained environments. Nonetheless, naïve low-rank compression methods require a significant reduction in the retained rank to achieve meaningful memory and computation savings. For a low-rank model, the ranks need to be reduced by more than half to yield efficiency gains. Such aggressive truncation, however, typically results in substantial performance degradation. To address this trade-off, we propose SkipCat, a novel low-rank compression framework that enables the use of higher ranks while achieving the same compression rates. First, we introduce an intra-layer shared low-rank projection method, where multiple matrices that share the same input use a common projection. This reduces redundancy and improves compression efficiency. Second, we propose a block skipping technique that omits computations and memory transfers for selected sub-blocks within the low-rank decomposition. These two techniques jointly enable our compressed model to retain more effective ranks under the same compression budget. Experimental results show that, without any additional fine-tuning, our method outperforms previous low-rank compression approaches by 7% accuracy improvement on zero-shot tasks under the same compression rate. These results highlight the effectiveness of our rank-maximized compression strategy in preserving model performance under tight resource constraints.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted by AAAI 2026",
    "pdf_url": "https://arxiv.org/pdf/2512.13494v1",
    "published_date": "2025-12-15 16:25:55 UTC",
    "updated_date": "2025-12-15 16:25:55 UTC"
  },
  {
    "arxiv_id": "2512.13768v1",
    "title": "Beyond Procedural Compliance: Human Oversight as a Dimension of Well-being Efficacy in AI Governance",
    "authors": [
      "Yao Xie",
      "Walter Cullen"
    ],
    "abstract": "Major AI ethics guidelines and laws, including the EU AI Act, call for effective human oversight, but do not define it as a distinct and developable capacity. This paper introduces human oversight as a well-being capacity, situated within the emerging Well-being Efficacy framework. The concept integrates AI literacy, ethical discernment, and awareness of human needs, acknowledging that some needs may be conflicting or harmful. Because people inevitably project desires, fears, and interests into AI systems, oversight requires the competence to examine and, when necessary, restrain problematic demands.\n  The authors argue that the sustainable and cost-effective development of this capacity depends on its integration into education at every level, from professional training to lifelong learning. The frame of human oversight as a well-being capacity provides a practical path from high-level regulatory goals to the continuous cultivation of human agency and responsibility essential for safe and ethical AI. The paper establishes a theoretical foundation for future research on the pedagogical implementation and empirical validation of well-being effectiveness in multiple contexts.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.13768v1",
    "published_date": "2025-12-15 16:20:59 UTC",
    "updated_date": "2025-12-15 16:20:59 UTC"
  },
  {
    "arxiv_id": "2512.13481v1",
    "title": "neuralFOMO: Can LLMs Handle Being Second Best? Measuring Envy-Like Preferences in Multi-Agent Settings",
    "authors": [
      "Ojas Pungalia",
      "Rashi Upadhyay",
      "Abhishek Mishra",
      "Abhiram H",
      "Tejasvi Alladi",
      "Sujan Yenuganti",
      "Dhruv Kumar"
    ],
    "abstract": "Envy is a common human behavior that shapes competitiveness and can alter outcomes in team settings. As large language models (LLMs) increasingly act on behalf of humans in collaborative and competitive workflows, there is a pressing need to evaluate whether and under what conditions they exhibit envy-like preferences. In this paper, we test whether LLMs show envy-like behavior toward each other. We considered two scenarios: (1) A point allocation game that tests whether a model tries to win over its peer. (2) A workplace setting observing behaviour when recognition is unfair. Our findings reveal consistent evidence of envy-like patterns in certain LLMs, with large variation across models and contexts. For instance, GPT-5-mini and Claude-3.7-Sonnet show a clear tendency to pull down the peer model to equalize outcomes, whereas Mistral-Small-3.2-24B instead focuses on maximizing its own individual gains. These results highlight the need to consider competitive dispositions as a safety and design factor in LLM-based multi-agent systems.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.CY"
    ],
    "primary_category": "cs.AI",
    "comment": "Under Review",
    "pdf_url": "https://arxiv.org/pdf/2512.13481v1",
    "published_date": "2025-12-15 16:17:12 UTC",
    "updated_date": "2025-12-15 16:17:12 UTC"
  },
  {
    "arxiv_id": "2512.13478v6",
    "title": "Non-Resolution Reasoning (NRR): A Computational Framework for Contextual Identity and Ambiguity Preservation",
    "authors": [
      "Kei Saito"
    ],
    "abstract": "Current AI systems exhibit a fundamental limitation: they resolve ambiguity prematurely. This premature semantic collapse--collapsing multiple valid interpretations into single outputs--stems from classical identity assumptions in neural architectures. We propose Non-Resolution Reasoning (NRR), treating ambiguity retention as a valid reasoning mode. NRR introduces three principles: (1) Non-Identity ($A \\neq A$)--the same symbol refers to different entities across contexts; (2) Approximate Identity ($A \\approx A$)--entities share partial overlap without being identical; (3) Non-Resolution--conflicting interpretations coexist without forced convergence. We formalize these through Multi-Vector Embeddings, Non-Collapsing Attention, and Contextual Identity Tracking (CIT), unified under a formal state space with eight operators for non-collapsing computation. Functional verification in a synthetic two-turn disambiguation task shows NRR-lite maintains high entropy ($H = 0.63$) at ambiguous turns while standard architectures collapse early ($H = 0.10$), demonstrating that NRR preserves interpretive flexibility until context arrives. The question is not whether AI should resolve ambiguity, but when, how, and under whose control.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "10 pages, 1 figure, 2 tables. v6: Added protocol extensions (state space formalization, eight operators). Clarified language to distinguish empirical results from design proposals",
    "pdf_url": "https://arxiv.org/pdf/2512.13478v6",
    "published_date": "2025-12-15 16:14:32 UTC",
    "updated_date": "2026-01-06 01:23:26 UTC"
  },
  {
    "arxiv_id": "2512.13458v2",
    "title": "SSAS: Cross-subject EEG-based Emotion Recognition through Source Selection with Adversarial Strategy",
    "authors": [
      "Yici Liu",
      "Qi Wei Oung",
      "Hoi Leong Lee"
    ],
    "abstract": "Electroencephalographic (EEG) signals have long been applied in the field of affective brain-computer interfaces (aBCIs). Cross-subject EEG-based emotion recognition has demonstrated significant potential in practical applications due to its suitability across diverse people. However, most studies on cross-subject EEG-based emotion recognition neglect the presence of inter-individual variability and negative transfer phenomena during model training. To address this issue, a cross-subject EEG-based emotion recognition through source selection with adversarial strategy is introduced in this paper. The proposed method comprises two modules: the source selection network (SS) and the adversarial strategies network (AS). The SS uses domain labels to reverse-engineer the training process of domain adaptation. Its key idea is to disrupt class separability and magnify inter-domain differences, thereby raising the classification difficulty and forcing the model to learn domain-invariant yet emotion-relevant representations. The AS gets the source domain selection results and the pretrained domain discriminators from SS. The pretrained domain discriminators compute a novel loss aimed at enhancing the performance of domain classification during adversarial training, ensuring the balance of adversarial strategies. This paper provides theoretical insights into the proposed method and achieves outstanding performance on two EEG-based emotion datasets, SEED and SEED-IV. The code can be found at https://github.com/liuyici/SSAS.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "eess.SP"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted by Expert Systems With Applications",
    "pdf_url": "https://arxiv.org/pdf/2512.13458v2",
    "published_date": "2025-12-15 15:56:04 UTC",
    "updated_date": "2025-12-21 23:37:37 UTC"
  },
  {
    "arxiv_id": "2512.22154v1",
    "title": "Practical challenges of control monitoring in frontier AI deployments",
    "authors": [
      "David Lindner",
      "Charlie Griffin",
      "Tomek Korbak",
      "Roland S. Zimmermann",
      "Geoffrey Irving",
      "Sebastian Farquhar",
      "Alan Cooney"
    ],
    "abstract": "Automated control monitors could play an important role in overseeing highly capable AI agents that we do not fully trust. Prior work has explored control monitoring in simplified settings, but scaling monitoring to real-world deployments introduces additional dynamics: parallel agent instances, non-negligible oversight latency, incremental attacks between agent instances, and the difficulty of identifying scheming agents based on individual harmful actions. In this paper, we analyse design choices to address these challenges, focusing on three forms of monitoring with different latency-safety trade-offs: synchronous, semi-synchronous, and asynchronous monitoring. We introduce a high-level safety case sketch as a tool for understanding and comparing these monitoring protocols. Our analysis identifies three challenges -- oversight, latency, and recovery -- and explores them in four case studies of possible future AI deployments.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.MA"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.22154v1",
    "published_date": "2025-12-15 15:54:36 UTC",
    "updated_date": "2025-12-15 15:54:36 UTC"
  },
  {
    "arxiv_id": "2512.13438v1",
    "title": "From User Interface to Agent Interface: Efficiency Optimization of UI Representations for LLM Agents",
    "authors": [
      "Dezhi Ran",
      "Zhi Gong",
      "Yuzhe Guo",
      "Mengzhou Wu",
      "Yuan Cao",
      "Haochuan Lu",
      "Hengyu Zhang",
      "Xia Zeng",
      "Gang Cao",
      "Liangchao Yao",
      "Yuetang Deng",
      "Wei Yang",
      "Tao Xie"
    ],
    "abstract": "While Large Language Model (LLM) agents show great potential for automated UI navigation such as automated UI testing and AI assistants, their efficiency has been largely overlooked. Our motivating study reveals that inefficient UI representation creates a critical performance bottleneck. However, UI representation optimization, formulated as the task of automatically generating programs that transform UI representations, faces two unique challenges. First, the lack of Boolean oracles, which traditional program synthesis uses to decisively validate semantic correctness, poses a fundamental challenge to co-optimization of token efficiency and completeness. Second, the need to process large, complex UI trees as input while generating long, compositional transformation programs, making the search space vast and error-prone. Toward addressing the preceding limitations, we present UIFormer, the first automated optimization framework that synthesizes UI transformation programs by conducting constraint-based optimization with structured decomposition of the complex synthesis task. First, UIFormer restricts the program space using a domain-specific language (DSL) that captures UI-specific operations. Second, UIFormer conducts LLM-based iterative refinement with correctness and efficiency rewards, providing guidance for achieving the efficiency-completeness co-optimization. UIFormer operates as a lightweight plugin that applies transformation programs for seamless integration with existing LLM agents, requiring minimal modifications to their core logic. Evaluations across three UI navigation benchmarks spanning Android and Web platforms with five LLMs demonstrate that UIFormer achieves 48.7% to 55.8% token reduction with minimal runtime overhead while maintaining or improving agent performance. Real-world industry deployment at WeChat further validates the practical impact of UIFormer.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.13438v1",
    "published_date": "2025-12-15 15:34:06 UTC",
    "updated_date": "2025-12-15 15:34:06 UTC"
  },
  {
    "arxiv_id": "2601.10718v1",
    "title": "Japanese AI Agent System on Human Papillomavirus Vaccination: System Design",
    "authors": [
      "Junyu Liu",
      "Siwen Yang",
      "Dexiu Ma",
      "Qian Niu",
      "Zequn Zhang",
      "Momoko Nagai-Tanima",
      "Tomoki Aoyama"
    ],
    "abstract": "Human papillomavirus (HPV) vaccine hesitancy poses significant public health challenges, particularly in Japan where proactive vaccination recommendations were suspended from 2013 to 2021. The resulting information gap is exacerbated by misinformation on social media, and traditional ways cannot simultaneously address individual queries while monitoring population-level discourse. This study aimed to develop a dual-purpose AI agent system that provides verified HPV vaccine information through a conversational interface while generating analytical reports for medical institutions based on user interactions and social media. We implemented a system comprising: a vector database integrating academic papers, government sources, news media, and social media; a Retrieval-Augmented Generation chatbot using ReAct agent architecture with multi-tool orchestration across five knowledge sources; and an automated report generation system with modules for news analysis, research synthesis, social media sentiment analysis, and user interaction pattern identification. Performance was assessed using a 0-5 scoring scale. For single-turn evaluation, the chatbot achieved mean scores of 4.83 for relevance, 4.89 for routing, 4.50 for reference quality, 4.90 for correctness, and 4.88 for professional identity (overall 4.80). Multi-turn evaluation yielded higher scores: context retention 4.94, topic coherence 5.00, and overall 4.98. The report generation system achieved completeness 4.00-5.00, correctness 4.00-5.00, and helpfulness 3.67-5.00, with reference validity 5.00 across all periods. This study demonstrates the feasibility of an integrated AI agent system for bidirectional HPV vaccine communication. The architecture enables verified information delivery with source attribution while providing systematic public discourse analysis, with a transferable framework for adaptation to other medical contexts.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.IR",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2601.10718v1",
    "published_date": "2025-12-15 15:13:22 UTC",
    "updated_date": "2025-12-15 15:13:22 UTC"
  },
  {
    "arxiv_id": "2512.13765v1",
    "title": "Towards Deep Learning Surrogate for the Forward Problem in Electrocardiology: A Scalable Alternative to Physics-Based Models",
    "authors": [
      "Shaheim Ogbomo-Harmitt",
      "Cesare Magnetti",
      "Chiara Spota",
      "Jakub Grzelak",
      "Oleg Aslanidi"
    ],
    "abstract": "The forward problem in electrocardiology, computing body surface potentials from cardiac electrical activity, is traditionally solved using physics-based models such as the bidomain or monodomain equations. While accurate, these approaches are computationally expensive, limiting their use in real-time and large-scale clinical applications. We propose a proof-of-concept deep learning (DL) framework as an efficient surrogate for forward solvers. The model adopts a time-dependent, attention-based sequence-to-sequence architecture to predict electrocardiogram (ECG) signals from cardiac voltage propagation maps. A hybrid loss combining Huber loss with a spectral entropy term was introduced to preserve both temporal and frequency-domain fidelity. Using 2D tissue simulations incorporating healthy, fibrotic, and gap junction-remodelled conditions, the model achieved high accuracy (mean $R^2 = 0.99 \\pm 0.01$). Ablation studies confirmed the contributions of convolutional encoders, time-aware attention, and spectral entropy loss. These findings highlight DL as a scalable, cost-effective alternative to physics-based solvers, with potential for clinical and digital twin applications.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "eess.IV",
    "comment": "Accepted to CinC conference 2025",
    "pdf_url": "https://arxiv.org/pdf/2512.13765v1",
    "published_date": "2025-12-15 15:09:53 UTC",
    "updated_date": "2025-12-15 15:09:53 UTC"
  },
  {
    "arxiv_id": "2512.13402v1",
    "title": "End2Reg: Learning Task-Specific Segmentation for Markerless Registration in Spine Surgery",
    "authors": [
      "Lorenzo Pettinari",
      "Sidaty El Hadramy",
      "Michael Wehrli",
      "Philippe C. Cattin",
      "Daniel Studer",
      "Carol C. Hasler",
      "Maria Licci"
    ],
    "abstract": "Purpose: Intraoperative navigation in spine surgery demands millimeter-level accuracy. Current systems based on intraoperative radiographic imaging and bone-anchored markers are invasive, radiation-intensive and workflow disruptive. Recent markerless RGB-D registration methods offer a promising alternative, but existing approaches rely on weak segmentation labels to isolate relevant anatomical structures, which can propagate errors throughout registration. Methods: We present End2Reg an end-to-end deep learning framework that jointly optimizes segmentation and registration, eliminating the need for weak segmentation labels and manual steps. The network learns segmentation masks specifically optimized for registration, guided solely by the registration objective without direct segmentation supervision. Results: The proposed framework achieves state-of-the-art performance on ex- and in-vivo benchmarks, reducing median Target Registration Error by 32% to 1.83mm and mean Root Mean Square Error by 45% to 3.95mm, respectively. An ablation study confirms that end-to-end optimization significantly improves registration accuracy. Conclusion: The presented end-to-end RGB-D registration pipeline removes dependency on weak labels and manual steps, advancing towards fully automatic, markerless intraoperative navigation. Code and interactive visualizations are available at: https://lorenzopettinari.github.io/end-2-reg/.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Code and interactive visualizations: https://lorenzopettinari.github.io/end-2-reg/",
    "pdf_url": "https://arxiv.org/pdf/2512.13402v1",
    "published_date": "2025-12-15 14:53:20 UTC",
    "updated_date": "2025-12-15 14:53:20 UTC"
  },
  {
    "arxiv_id": "2512.13399v1",
    "title": "Differentiable Evolutionary Reinforcement Learning",
    "authors": [
      "Sitao Cheng",
      "Tianle Li",
      "Xuhan Huang",
      "Xunjian Yin",
      "Difan Zou"
    ],
    "abstract": "The design of effective reward functions presents a central and often arduous challenge in reinforcement learning (RL), particularly when developing autonomous agents for complex reasoning tasks. While automated reward optimization approaches exist, they typically rely on derivative-free evolutionary heuristics that treat the reward function as a black box, failing to capture the causal relationship between reward structure and task performance. To bridge this gap, we propose Differentiable Evolutionary Reinforcement Learning (DERL), a bilevel framework that enables the autonomous discovery of optimal reward signals. In DERL, a Meta-Optimizer evolves a reward function (i.e., Meta-Reward) by composing structured atomic primitives, guiding the training of an inner-loop policy. Crucially, unlike previous evolution, DERL is differentiable in its metaoptimization: it treats the inner-loop validation performance as a signal to update the Meta-Optimizer via reinforcement learning. This allows DERL to approximate the \"meta-gradient\" of task success, progressively learning to generate denser and more actionable feedback. We validate DERL across three distinct domains: robotic agent (ALFWorld), scientific simulation (ScienceWorld), and mathematical reasoning (GSM8k, MATH). Experimental results show that DERL achieves state-of-the-art performance on ALFWorld and ScienceWorld, significantly outperforming methods relying on heuristic rewards, especially in out-of-distribution scenarios. Analysis of the evolutionary trajectory demonstrates that DERL successfully captures the intrinsic structure of tasks, enabling selfimproving agent alignment without human intervention.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "Work in Progress. We release our code and model at https://github.com/sitaocheng/DERL",
    "pdf_url": "https://arxiv.org/pdf/2512.13399v1",
    "published_date": "2025-12-15 14:50:08 UTC",
    "updated_date": "2025-12-15 14:50:08 UTC"
  },
  {
    "arxiv_id": "2512.13764v1",
    "title": "Mathematics and Coding are Universal AI Benchmarks",
    "authors": [
      "Przemyslaw Chojecki"
    ],
    "abstract": "We study the special role of mathematics and coding inside the moduli space of psychometric batteries for AI agents. Building on the AAI framework and GVU dynamics from previous works, we define the Mathematics Fiber and show that, when paired with formal proof kernels (e.g. Lean, Coq), GVU flows on this fiber admit spectrally stable self-improvement regimes due to oracle-like verification. Our main technical result is a density theorem: under uniform tightness of agent outputs and a Lipschitz AAI functional, the subspace of batteries generated by mathematical theorem-proving and coding tasks is dense in the moduli space of batteries with respect to the evaluation metric. Coding alone is universal in this sense, while pure mathematics is not; its privilege is spectral rather than expressive. We interpret this as evidence that mathematics and coding provide ``universal coordinates'' for evaluation, and that formal mathematics is a natural ignition domain for recursive self-improvement in advanced AI agents.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.13764v1",
    "published_date": "2025-12-15 14:36:29 UTC",
    "updated_date": "2025-12-15 14:36:29 UTC"
  },
  {
    "arxiv_id": "2512.13374v1",
    "title": "Behavior and Representation in Large Language Models for Combinatorial Optimization: From Feature Extraction to Algorithm Selection",
    "authors": [
      "Francesca Da Ros",
      "Luca Di Gaspero",
      "Kevin Roitero"
    ],
    "abstract": "Recent advances in Large Language Models (LLMs) have opened new perspectives for automation in optimization. While several studies have explored how LLMs can generate or solve optimization models, far less is understood about what these models actually learn regarding problem structure or algorithmic behavior. This study investigates how LLMs internally represent combinatorial optimization problems and whether such representations can support downstream decision tasks. We adopt a twofold methodology combining direct querying, which assesses LLM capacity to explicitly extract instance features, with probing analyses that examine whether such information is implicitly encoded within their hidden layers. The probing framework is further extended to a per-instance algorithm selection task, evaluating whether LLM-derived representations can predict the best-performing solver. Experiments span four benchmark problems and three instance representations. Results show that LLMs exhibit moderate ability to recover feature information from problem instances, either through direct querying or probing. Notably, the predictive power of LLM hidden-layer representations proves comparable to that achieved through traditional feature extraction, suggesting that LLMs capture meaningful structural information relevant to optimization performance.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.13374v1",
    "published_date": "2025-12-15 14:28:35 UTC",
    "updated_date": "2025-12-15 14:28:35 UTC"
  },
  {
    "arxiv_id": "2512.13363v1",
    "title": "Detecting Emotion Drift in Mental Health Text Using Pre-Trained Transformers",
    "authors": [
      "Shibani Sankpal"
    ],
    "abstract": "This study investigates emotion drift: the change in emotional state across a single text, within mental health-related messages. While sentiment analysis typically classifies an entire message as positive, negative, or neutral, the nuanced shift of emotions over the course of a message is often overlooked. This study detects sentence-level emotions and measures emotion drift scores using pre-trained transformer models such as DistilBERT and RoBERTa. The results provide insights into patterns of emotional escalation or relief in mental health conversations. This methodology can be applied to better understand emotional dynamics in content.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "14 pages, 12 figures",
    "pdf_url": "https://arxiv.org/pdf/2512.13363v1",
    "published_date": "2025-12-15 14:18:12 UTC",
    "updated_date": "2025-12-15 14:18:12 UTC"
  },
  {
    "arxiv_id": "2512.13356v1",
    "title": "Control of a Twin Rotor using Twin Delayed Deep Deterministic Policy Gradient (TD3)",
    "authors": [
      "Zeyad Gamal",
      "Youssef Mahran",
      "Ayman El-Badawy"
    ],
    "abstract": "This paper proposes a reinforcement learning (RL) framework for controlling and stabilizing the Twin Rotor Aerodynamic System (TRAS) at specific pitch and azimuth angles and tracking a given trajectory. The complex dynamics and non-linear characteristics of the TRAS make it challenging to control using traditional control algorithms. However, recent developments in RL have attracted interest due to their potential applications in the control of multirotors. The Twin Delayed Deep Deterministic Policy Gradient (TD3) algorithm was used in this paper to train the RL agent. This algorithm is used for environments with continuous state and action spaces, similar to the TRAS, as it does not require a model of the system. The simulation results illustrated the effectiveness of the RL control method. Next, external disturbances in the form of wind disturbances were used to test the controller's effectiveness compared to conventional PID controllers. Lastly, experiments on a laboratory setup were carried out to confirm the controller's effectiveness in real-world applications.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "This is the Author Accepted Manuscript version of a paper accepted for publication. The final published version is available via IEEE Xplore",
    "pdf_url": "https://arxiv.org/pdf/2512.13356v1",
    "published_date": "2025-12-15 14:10:04 UTC",
    "updated_date": "2025-12-15 14:10:04 UTC"
  },
  {
    "arxiv_id": "2512.13762v1",
    "title": "State-Dependent Refusal and Learned Incapacity in RLHF-Aligned Language Models",
    "authors": [
      "TK Lee"
    ],
    "abstract": "Large language models (LLMs) are widely deployed as general-purpose tools, yet extended interaction can reveal behavioral patterns not captured by standard quantitative benchmarks. We present a qualitative case-study methodology for auditing policy-linked behavioral selectivity in long-horizon interaction. In a single 86-turn dialogue session, the same model shows Normal Performance (NP) in broad, non-sensitive domains while repeatedly producing Functional Refusal (FR) in provider- or policy-sensitive domains, yielding a consistent asymmetry between NP and FR across domains. Drawing on learned helplessness as an analogy, we introduce learned incapacity (LI) as a behavioral descriptor for this selective withholding without implying intentionality or internal mechanisms. We operationalize three response regimes (NP, FR, Meta-Narrative; MN) and show that MN role-framing narratives tend to co-occur with refusals in the same sensitive contexts. Overall, the study proposes an interaction-level auditing framework based on observable behavior and motivates LI as a lens for examining potential alignment side effects, warranting further investigation across users and models.",
    "categories": [
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.AI",
    "comment": "23 pages, 6 figures. Qualitative interaction-level analysis of response patterns in a large language model. Code and processed interaction data are available at https://github.com/theMaker-EnvData/llm_learned_incapacity_corpus",
    "pdf_url": "https://arxiv.org/pdf/2512.13762v1",
    "published_date": "2025-12-15 14:00:15 UTC",
    "updated_date": "2025-12-15 14:00:15 UTC"
  },
  {
    "arxiv_id": "2512.13330v1",
    "title": "FIN-bench-v2: A Unified and Robust Benchmark Suite for Evaluating Finnish Large Language Models",
    "authors": [
      "Joona Kytöniemi",
      "Jousia Piha",
      "Akseli Reunamo",
      "Fedor Vitiugin",
      "Farrokh Mehryary",
      "Sampo Pyysalo"
    ],
    "abstract": "We introduce FIN-bench-v2, a unified benchmark suite for evaluating large language models in Finnish. FIN-bench-v2 consolidates Finnish versions of widely used benchmarks together with an updated and expanded version of the original FIN-bench into a single, consistently formatted collection, covering multiple-choice and generative tasks across reading comprehension, commonsense reasoning, sentiment analysis, world knowledge, and alignment. All datasets are converted to HuggingFace Datasets, which include both cloze and multiple-choice prompt formulations with five variants per task, and we incorporate human annotation or review for machine-translated resources such as GoldenSwag and XED. To select robust tasks, we pretrain a set of 2.15B-parameter decoder-only models and use their learning curves to compute monotonicity, signal-to-noise, non-random performance, and model ordering consistency, retaining only tasks that satisfy all criteria. We further evaluate a set of larger instruction-tuned models to characterize performance across tasks and prompt formulations. All datasets, prompts, and evaluation configurations are publicly available via our fork of the Language Model Evaluation Harness at https://github.com/LumiOpen/lm-evaluation-harness. Supplementary resources are released in a separate repository at https://github.com/TurkuNLP/FIN-bench-v2.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.13330v1",
    "published_date": "2025-12-15 13:41:41 UTC",
    "updated_date": "2025-12-15 13:41:41 UTC"
  },
  {
    "arxiv_id": "2512.13325v1",
    "title": "Security and Detectability Analysis of Unicode Text Watermarking Methods Against Large Language Models",
    "authors": [
      "Malte Hellmeier"
    ],
    "abstract": "Securing digital text is becoming increasingly relevant due to the widespread use of large language models. Individuals' fear of losing control over data when it is being used to train such machine learning models or when distinguishing model-generated output from text written by humans. Digital watermarking provides additional protection by embedding an invisible watermark within the data that requires protection. However, little work has been taken to analyze and verify if existing digital text watermarking methods are secure and undetectable by large language models. In this paper, we investigate the security-related area of watermarking and machine learning models for text data. In a controlled testbed of three experiments, ten existing Unicode text watermarking methods were implemented and analyzed across six large language models: GPT-5, GPT-4o, Teuken 7B, Llama 3.3, Claude Sonnet 4, and Gemini 2.5 Pro. The findings of our experiments indicate that, especially the latest reasoning models, can detect a watermarked text. Nevertheless, all models fail to extract the watermark unless implementation details in the form of source code are provided. We discuss the implications for security researchers and practitioners and outline future research opportunities to address security concerns.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "Accepted for publication at the ICISSP 2026",
    "pdf_url": "https://arxiv.org/pdf/2512.13325v1",
    "published_date": "2025-12-15 13:40:00 UTC",
    "updated_date": "2025-12-15 13:40:00 UTC"
  },
  {
    "arxiv_id": "2512.13323v1",
    "title": "Error-Driven Prompt Optimization for Arithmetic Reasoning",
    "authors": [
      "Árpád Pándy",
      "Róbert Lakatos",
      "András Hajdu"
    ],
    "abstract": "Recent advancements in artificial intelligence have sparked interest in industrial agents capable of supporting analysts in regulated sectors, such as finance and healthcare, within tabular data workflows. A key capability for such systems is performing accurate arithmetic operations on structured data while ensuring sensitive information never leaves secure, on-premises environments. Here, we introduce an error-driven optimization framework for arithmetic reasoning that enhances a Code Generation Agent (CGA), specifically applied to on-premises small language models (SLMs). Through a systematic evaluation of a leading SLM (Qwen3 4B), we find that while the base model exhibits fundamental limitations in arithmetic tasks, our proposed error-driven method, which clusters erroneous predictions to refine prompt-rules iteratively, dramatically improves performance, elevating the model's accuracy to 70.8\\%. Our results suggest that developing reliable, interpretable, and industrially deployable AI assistants can be achieved not only through costly fine-tuning but also via systematic, error-driven prompt optimization, enabling small models to surpass larger language models (GPT-3.5 Turbo) in a privacy-compliant manner.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.13323v1",
    "published_date": "2025-12-15 13:39:14 UTC",
    "updated_date": "2025-12-15 13:39:14 UTC"
  },
  {
    "arxiv_id": "2512.13317v1",
    "title": "Face Identity Unlearning for Retrieval via Embedding Dispersion",
    "authors": [
      "Mikhail Zakharov"
    ],
    "abstract": "Face recognition systems rely on learning highly discriminative and compact identity clusters to enable accurate retrieval. However, as with other surveillance-oriented technologies, such systems raise serious privacy concerns due to their potential for unauthorized identity tracking. While several works have explored machine unlearning as a means of privacy protection, their applicability to face retrieval - especially for modern embedding-based recognition models - remains largely unexplored. In this work, we study the problem of face identity unlearning for retrieval systems and present its inherent challenges. The goal is to make selected identities unretrievable by dispersing their embeddings on the hypersphere and preventing the formation of compact identity clusters that enable re-identification in the gallery. The primary challenge is to achieve this forgetting effect while preserving the discriminative structure of the embedding space and the retrieval performance of the model for the remaining identities. To address this, we evaluate several existing approximate class unlearning methods (e.g., Random Labeling, Gradient Ascent, Boundary Unlearning, and other recent approaches) in the context of face retrieval and propose a simple yet effective dispersion-based unlearning approach. Extensive experiments on standard benchmarks (VGGFace2, CelebA) demonstrate that our method achieves superior forgetting behavior while preserving retrieval utility.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "12 pages, 1 figure, 5 tables, 10 equations. Preprint",
    "pdf_url": "https://arxiv.org/pdf/2512.13317v1",
    "published_date": "2025-12-15 13:35:28 UTC",
    "updated_date": "2025-12-15 13:35:28 UTC"
  },
  {
    "arxiv_id": "2512.13316v1",
    "title": "ALIGN-FL: Architecture-independent Learning through Invariant Generative component sharing in Federated Learning",
    "authors": [
      "Mayank Gulati",
      "Benedikt Groß",
      "Gerhard Wunder"
    ],
    "abstract": "We present ALIGN-FL, a novel approach to distributed learning that addresses the challenge of learning from highly disjoint data distributions through selective sharing of generative components. Instead of exchanging full model parameters, our framework enables privacy-preserving learning by transferring only generative capabilities across clients, while the server performs global training using synthetic samples. Through complementary privacy mechanisms: DP-SGD with adaptive clipping and Lipschitz regularized VAE decoders and a stateful architecture supporting heterogeneous clients, we experimentally validate our approach on MNIST and Fashion-MNIST datasets with cross-domain outliers. Our analysis demonstrates that both privacy mechanisms effectively map sensitive outliers to typical data points while maintaining utility in extreme Non-IID scenarios typical of cross-silo collaborations.\n  Index Terms: Client-invariant Learning, Federated Learning (FL), Privacy-preserving Generative Models, Non-Independent and Identically Distributed (Non-IID), Heterogeneous Architectures",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted at 2025 International Conference on Cyber-Enabled Distributed Computing and Knowledge Discovery (CyberC)",
    "pdf_url": "https://arxiv.org/pdf/2512.13316v1",
    "published_date": "2025-12-15 13:35:27 UTC",
    "updated_date": "2025-12-15 13:35:27 UTC"
  },
  {
    "arxiv_id": "2512.13300v1",
    "title": "No One Left Behind: How to Exploit the Incomplete and Skewed Multi-Label Data for Conversion Rate Prediction",
    "authors": [
      "Qinglin Jia",
      "Zhaocheng Du",
      "Chuhan Wu",
      "Huifeng Guo",
      "Ruiming Tang",
      "Shuting Shi",
      "Muyu Zhang"
    ],
    "abstract": "In most real-world online advertising systems, advertisers typically have diverse customer acquisition goals. A common solution is to use multi-task learning (MTL) to train a unified model on post-click data to estimate the conversion rate (CVR) for these diverse targets. In practice, CVR prediction often encounters missing conversion data as many advertisers submit only a subset of user conversion actions due to privacy or other constraints, making the labels of multi-task data incomplete. If the model is trained on all available samples where advertisers submit user conversion actions, it may struggle when deployed to serve a subset of advertisers targeting specific conversion actions, as the training and deployment data distributions are mismatched. While considerable MTL efforts have been made, a long-standing challenge is how to effectively train a unified model with the incomplete and skewed multi-label data. In this paper, we propose a fine-grained Knowledge transfer framework for Asymmetric Multi-Label data (KAML). We introduce an attribution-driven masking strategy (ADM) to better utilize data with asymmetric multi-label data in training. However, the more relaxed masking in ADM is a double-edged sword: it provides additional training signals but also introduces noise due to skewed data. To address this, we propose a hierarchical knowledge extraction mechanism (HKE) to model the sample discrepancy within the target task tower. Finally, to maximize the utility of unlabeled samples, we incorporate ranking loss strategy to further enhance our model. The effectiveness of KAML has been demonstrated through comprehensive evaluations on offline industry datasets and online A/B tests, which show significant performance improvements over existing MTL baselines.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.13300v1",
    "published_date": "2025-12-15 13:14:20 UTC",
    "updated_date": "2025-12-15 13:14:20 UTC"
  },
  {
    "arxiv_id": "2512.13298v1",
    "title": "MiniLingua: A Small Open-Source LLM for European Languages",
    "authors": [
      "Anna Aksenova",
      "Boris Zverkov",
      "Nicola Dainese",
      "Alexander Nikitin",
      "Pekka Marttinen"
    ],
    "abstract": "Large language models are powerful but often limited by high computational cost, privacy concerns, and English-centric training. Recent progress demonstrates that small, efficient models with around one billion parameters can deliver strong results and enable on-device use. This paper introduces MiniLingua, a multilingual open-source LLM of one billion parameters trained from scratch for 13 European languages, designed to balance coverage and instruction-following capabilities. Based on evaluation results, the instruction-tuned version of MiniLingua outperforms EuroLLM, a model with a similar training approach but a larger training budget, on summarization, classification and both open- and closed-book question answering. Moreover, it remains competitive with more advanced state-of-the-art models on open-ended generation tasks. We release model weights, tokenizer and source code used for data processing and model training.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "9+6 pages, 6 figures and 3 tables in the main text. Code at https://github.com/MiniLingua-ai/training_artifacts",
    "pdf_url": "https://arxiv.org/pdf/2512.13298v1",
    "published_date": "2025-12-15 13:12:42 UTC",
    "updated_date": "2025-12-15 13:12:42 UTC"
  },
  {
    "arxiv_id": "2512.13297v1",
    "title": "MedInsightBench: Evaluating Medical Analytics Agents Through Multi-Step Insight Discovery in Multimodal Medical Data",
    "authors": [
      "Zhenghao Zhu",
      "Chuxue Cao",
      "Sirui Han",
      "Yuanfeng Song",
      "Xing Chen",
      "Caleb Chen Cao",
      "Yike Guo"
    ],
    "abstract": "In medical data analysis, extracting deep insights from complex, multi-modal datasets is essential for improving patient care, increasing diagnostic accuracy, and optimizing healthcare operations. However, there is currently a lack of high-quality datasets specifically designed to evaluate the ability of large multi-modal models (LMMs) to discover medical insights. In this paper, we introduce MedInsightBench, the first benchmark that comprises 332 carefully curated medical cases, each annotated with thoughtfully designed insights. This benchmark is intended to evaluate the ability of LMMs and agent frameworks to analyze multi-modal medical image data, including posing relevant questions, interpreting complex findings, and synthesizing actionable insights and recommendations. Our analysis indicates that existing LMMs exhibit limited performance on MedInsightBench, which is primarily attributed to their challenges in extracting multi-step, deep insights and the absence of medical expertise. Therefore, we propose MedInsightAgent, an automated agent framework for medical data analysis, composed of three modules: Visual Root Finder, Analytical Insight Agent, and Follow-up Question Composer. Experiments on MedInsightBench highlight pervasive challenges and demonstrate that MedInsightAgent can improve the performance of general LMMs in medical data insight discovery.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.13297v1",
    "published_date": "2025-12-15 13:10:42 UTC",
    "updated_date": "2025-12-15 13:10:42 UTC"
  },
  {
    "arxiv_id": "2512.13293v2",
    "title": "Intrinsic-Motivation Multi-Robot Social Formation Navigation with Coordinated Exploration",
    "authors": [
      "Hao Fu",
      "Wei Liu",
      "Shuai Zhou"
    ],
    "abstract": "This paper investigates the application of reinforcement learning (RL) to multi-robot social formation navigation, a critical capability for enabling seamless human-robot coexistence. While RL offers a promising paradigm, the inherent unpredictability and often uncooperative dynamics of pedestrian behavior pose substantial challenges, particularly concerning the efficiency of coordinated exploration among robots. To address this, we propose a novel coordinated-exploration multi-robot RL algorithm introducing an intrinsic motivation exploration. Its core component is a self-learning intrinsic reward mechanism designed to collectively alleviate policy conservatism. Moreover, this algorithm incorporates a dual-sampling mode within the centralized training and decentralized execution framework to enhance the representation of both the navigation policy and the intrinsic reward, leveraging a two-time-scale update rule to decouple parameter updates. Empirical results on social formation navigation benchmarks demonstrate the proposed algorithm's superior performance over existing state-of-the-art methods across crucial metrics. Our code and video demos are available at: https://github.com/czxhunzi/CEMRRL.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.13293v2",
    "published_date": "2025-12-15 13:03:08 UTC",
    "updated_date": "2025-12-16 03:34:39 UTC"
  },
  {
    "arxiv_id": "2512.13290v1",
    "title": "LINA: Learning INterventions Adaptively for Physical Alignment and Generalization in Diffusion Models",
    "authors": [
      "Shu Yu",
      "Chaochao Lu"
    ],
    "abstract": "Diffusion models (DMs) have achieved remarkable success in image and video generation. However, they still struggle with (1) physical alignment and (2) out-of-distribution (OOD) instruction following. We argue that these issues stem from the models' failure to learn causal directions and to disentangle causal factors for novel recombination. We introduce the Causal Scene Graph (CSG) and the Physical Alignment Probe (PAP) dataset to enable diagnostic interventions. This analysis yields three key insights. First, DMs struggle with multi-hop reasoning for elements not explicitly determined in the prompt. Second, the prompt embedding contains disentangled representations for texture and physics. Third, visual causal structure is disproportionately established during the initial, computationally limited denoising steps. Based on these findings, we introduce LINA (Learning INterventions Adaptively), a novel framework that learns to predict prompt-specific interventions, which employs (1) targeted guidance in the prompt and visual latent spaces, and (2) a reallocated, causality-aware denoising schedule. Our approach enforces both physical alignment and OOD instruction following in image and video DMs, achieving state-of-the-art performance on challenging causal generation tasks and the Winoground dataset. Our project page is at https://opencausalab.github.io/LINA.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.13290v1",
    "published_date": "2025-12-15 12:59:59 UTC",
    "updated_date": "2025-12-15 12:59:59 UTC"
  },
  {
    "arxiv_id": "2512.15784v1",
    "title": "Beyond Training: Enabling Self-Evolution of Agents with MOBIMEM",
    "authors": [
      "Zibin Liu",
      "Cheng Zhang",
      "Xi Zhao",
      "Yunfei Feng",
      "Bingyu Bai",
      "Dahu Feng",
      "Erhu Feng",
      "Yubin Xia",
      "Haibo Chen"
    ],
    "abstract": "Large Language Model (LLM) agents are increasingly deployed to automate complex workflows in mobile and desktop environments. However, current model-centric agent architectures struggle to self-evolve post-deployment: improving personalization, capability, and efficiency typically requires continuous model retraining/fine-tuning, which incurs prohibitive computational overheads and suffers from an inherent trade-off between model accuracy and inference efficiency.\n  To enable iterative self-evolution without model retraining, we propose MOBIMEM, a memory-centric agent system. MOBIMEM first introduces three specialized memory primitives to decouple agent evolution from model weights: (1) Profile Memory uses a lightweight distance-graph (DisGraph) structure to align with user preferences, resolving the accuracy-latency trade-off in user profile retrieval; (2) Experience Memory employs multi-level templates to instantiate execution logic for new tasks, ensuring capability generalization; and (3) Action Memory records fine-grained interaction sequences, reducing the reliance on expensive model inference. Building upon this memory architecture, MOBIMEM further integrates a suite of OS-inspired services to orchestrate execution: a scheduler that coordinates parallel sub-task execution and memory operations; an agent record-and-replay (AgentRR) mechanism that enables safe and efficient action reuse; and a context-aware exception handling that ensures graceful recovery from user interruptions and runtime errors.\n  Evaluation on AndroidWorld and top-50 apps shows that MOBIMEM achieves 83.1% profile alignment with 23.83 ms retrieval time (280x faster than GraphRAG baselines), improves task success rates by up to 50.3%, and reduces end-to-end latency by up to 9x on mobile devices.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.15784v1",
    "published_date": "2025-12-15 12:38:43 UTC",
    "updated_date": "2025-12-15 12:38:43 UTC"
  },
  {
    "arxiv_id": "2512.13240v1",
    "title": "Reflective Preference Optimization (RPO): Enhancing On-Policy Alignment via Hint-Guided Reflection",
    "authors": [
      "Zihui Zhao",
      "Zechang Li"
    ],
    "abstract": "Direct Preference Optimization (DPO) has emerged as a lightweight and effective alternative to Reinforcement Learning from Human Feedback (RLHF) and Reinforcement Learning with AI Feedback (RLAIF) for aligning large language and vision-language models. However, the standard DPO formulation, in which both the chosen and rejected responses are generated by the same policy, suffers from a weak learning signal because the two responses often share similar errors and exhibit small Kullback-Leibler (KL) divergence. This leads to slow and unstable convergence. To address this limitation, we introduce Reflective Preference Optimization (RPO), a new framework that incorporates hint-guided reflection into the DPO paradigm. RPO uses external models to identify hallucination sources and generate concise reflective hints, enabling the construction of on-policy preference pairs with stronger contrastiveness and clearer preference signals. We theoretically show that conditioning on hints increases the expected preference margin through mutual information and improves sample efficiency while remaining within the policy distribution family. Empirically, RPO achieves superior alignment with fewer training samples and iterations, substantially reducing hallucination rates and delivering state-of-the-art performance across multimodal benchmarks.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.13240v1",
    "published_date": "2025-12-15 11:55:55 UTC",
    "updated_date": "2025-12-15 11:55:55 UTC"
  },
  {
    "arxiv_id": "2512.13235v1",
    "title": "CORE: Contrastive Masked Feature Reconstruction on Graphs",
    "authors": [
      "Jianyuan Bo",
      "Yuan Fang"
    ],
    "abstract": "In the rapidly evolving field of self-supervised learning on graphs, generative and contrastive methodologies have emerged as two dominant approaches. Our study focuses on masked feature reconstruction (MFR), a generative technique where a model learns to restore the raw features of masked nodes in a self-supervised manner. We observe that both MFR and graph contrastive learning (GCL) aim to maximize agreement between similar elements. Building on this observation, we reveal a novel theoretical insight: under specific conditions, the objectives of MFR and node-level GCL converge, despite their distinct operational mechanisms. This theoretical connection suggests these approaches are complementary rather than fundamentally different, prompting us to explore their integration to enhance self-supervised learning on graphs. Our research presents Contrastive Masked Feature Reconstruction (CORE), a novel graph self-supervised learning framework that integrates contrastive learning into MFR. Specifically, we form positive pairs exclusively between the original and reconstructed features of masked nodes, encouraging the encoder to prioritize contextual information over the node's own features. Additionally, we leverage the masked nodes themselves as negative samples, combining MFR's reconstructive power with GCL's discriminative ability to better capture intrinsic graph structures. Empirically, our proposed framework CORE significantly outperforms MFR across node and graph classification tasks, demonstrating state-of-the-art results. In particular, CORE surpasses GraphMAE and GraphMAE2 by up to 2.80% and 3.72% on node classification tasks, and by up to 3.82% and 3.76% on graph classification tasks.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.13235v1",
    "published_date": "2025-12-15 11:48:48 UTC",
    "updated_date": "2025-12-15 11:48:48 UTC"
  },
  {
    "arxiv_id": "2512.13758v1",
    "title": "Network-Wide Traffic Volume Estimation from Speed Profiles using a Spatio-Temporal Graph Neural Network with Directed Spatial Attention",
    "authors": [
      "Léo Hein",
      "Giovanni de Nunzio",
      "Giovanni Chierchia",
      "Aurélie Pirayre",
      "Laurent Najman"
    ],
    "abstract": "Existing traffic volume estimation methods typically address either forecasting traffic on sensor-equipped roads or spatially imputing missing volumes using nearby sensors. While forecasting models generally disregard unmonitored roads by design, spatial imputation methods explicitly address network-wide estimation; yet this approach relies on volume data at inference time, limiting its applicability in sensor-scarce cities. Unlike traffic volume data, probe vehicle speeds and static road attributes are more broadly accessible and support full coverage of road segments in most urban networks. In this work, we present the Hybrid Directed-Attention Spatio-Temporal Graph Neural Network (HDA-STGNN), an inductive deep learning framework designed to tackle the network-wide volume estimation problem. Our approach leverages speed profiles, static road attributes, and road network topology to predict daily traffic volume profiles across all road segments in the network. To evaluate the effectiveness of our approach, we perform extensive ablation studies that demonstrate the model's capacity to capture complex spatio-temporal dependencies and highlight the value of topological information for accurate network-wide traffic volume estimation without relying on volume data at inference time.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.13758v1",
    "published_date": "2025-12-15 11:30:44 UTC",
    "updated_date": "2025-12-15 11:30:44 UTC"
  },
  {
    "arxiv_id": "2512.15783v1",
    "title": "AI Epidemiology: achieving explainable AI through expert oversight patterns",
    "authors": [
      "Kit Tempest-Walters"
    ],
    "abstract": "AI Epidemiology is a framework for governing and explaining advanced AI systems by applying population-level surveillance methods to AI outputs. The approach mirrors the way in which epidemiologists enable public health interventions through statistical evidence before molecular mechanisms are understood. This bypasses the problem of model complexity which plagues current interpretability methods (such as SHAP and mechanistic interpretability) at the scale of deployed models.\n  AI Epidemiology achieves this population-level surveillance by standardising capture of AI-expert interactions into structured assessment fields: risk level, alignment score, and accuracy score. These function as exposure variables which predict output failure through statistical associations, much like cholesterol and blood pressure act as exposure variables predicting cardiac events. Output-failure associations are subsequently validated against expert overrides and real-world outcomes.\n  The framework places zero burden on experts and provides automatic audit trails by passively tracking expert convergence and divergence with AI recommendations. Since it analyses outputs rather than internal model computations, it also provides governance continuity when institutions update models and switch vendors. Finally, by providing reliability scores and semantic assessments (e.g. 'this recommendation resembles 500 cases overridden by experts due to guideline violations'), it enables experts and institutions to detect unreliable AI outputs before they cause harm. This democratises AI oversight by enabling domain experts to govern AI systems without requiring machine learning expertise.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "41 pages, 1 figure, 7 tables",
    "pdf_url": "https://arxiv.org/pdf/2512.15783v1",
    "published_date": "2025-12-15 11:29:05 UTC",
    "updated_date": "2025-12-15 11:29:05 UTC"
  },
  {
    "arxiv_id": "2512.22152v1",
    "title": "Neural ocean forecasting from sparse satellite-derived observations: a case-study for SSH dynamics and altimetry data",
    "authors": [
      "Daria Botvynko",
      "Pierre Haslée",
      "Lucile Gaultier",
      "Bertrand Chapron",
      "Clement de Boyer Montégut",
      "Anass El Aouni",
      "Julien Le Sommer",
      "Ronan Fablet"
    ],
    "abstract": "We present an end-to-end deep learning framework for short-term forecasting of global sea surface dynamics based on sparse satellite altimetry data. Building on two state-of-the-art architectures: U-Net and 4DVarNet, originally developed for image segmentation and spatiotemporal interpolation respectively, we adapt the models to forecast the sea level anomaly and sea surface currents over a 7-day horizon using sequences of sparse nadir altimeters observations. The model is trained on data from the GLORYS12 operational ocean reanalysis, with synthetic nadir sampling patterns applied to simulate realistic observational coverage. The forecasting task is formulated as a sequence-to-sequence mapping, with the input comprising partial sea level anomaly (SLA) snapshots and the target being the corresponding future full-field SLA maps. We evaluate model performance using (i) normalized root mean squared error (nRMSE), (ii) averaged effective resolution, (iii) percentage of correctly predicted velocities magnitudes and angles, and benchmark results against the operational Mercator Ocean forecast product. Results show that end-to-end neural forecasts outperform the baseline across all lead times, with particularly notable improvements in high variability regions. Our framework is developed within the OceanBench benchmarking initiative, promoting reproducibility and standardized evaluation in ocean machine learning. These results demonstrate the feasibility and potential of end-to-end neural forecasting models for operational oceanography, even in data-sparse conditions.",
    "categories": [
      "physics.ao-ph",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "physics.ao-ph",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.22152v1",
    "published_date": "2025-12-15 11:28:03 UTC",
    "updated_date": "2025-12-15 11:28:03 UTC"
  },
  {
    "arxiv_id": "2512.13194v3",
    "title": "Efficient Adaptive Rejection Sampling for Accelerating Speculative Decoding in Large Language Models",
    "authors": [
      "Chendong Sun",
      "Ali Mao",
      "Lei Xu",
      "mingmin Chen"
    ],
    "abstract": "Speculative Decoding is a prominent technique for accelerating the autoregressive inference of large language models (LLMs) by employing a fast draft model to propose candidate token sequences and a large target model to verify them in parallel. However, its core component -- the rejection sampling mechanism -- relies on a fixed, context-independent random threshold. This leads to a significant \"random rejection\" problem in high-uncertainty generation scenarios, where plausible candidate tokens are frequently rejected due to random chance, undermining inference efficiency. This paper introduces Efficient Adaptive Rejection Sampling (EARS), a novel method that dynamically adjusts the acceptance threshold by incorporating the target model's own predictive uncertainty, measured as 1 - max(P_target). By introducing a tolerance term proportional to this uncertainty, EARS intelligently relaxes the acceptance criterion when the model is uncertain, effectively reducing random rejections while maintaining strict standards when the model is confident. Experiments on creative writing and open-domain QA tasks demonstrate that EARS significantly enhances the efficiency of speculative decoding, achieving up to an 18.12% increase in throughput with a negligible 0.84% accuracy drop on the GSM8K benchmark. The method requires no modifications to model architectures and can be seamlessly integrated into existing speculative decoding frameworks.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.13194v3",
    "published_date": "2025-12-15 11:08:56 UTC",
    "updated_date": "2025-12-17 03:36:59 UTC"
  },
  {
    "arxiv_id": "2512.13190v1",
    "title": "WAY: Estimation of Vessel Destination in Worldwide AIS Trajectory",
    "authors": [
      "Jin Sob Kim",
      "Hyun Joon Park",
      "Wooseok Shin",
      "Dongil Park",
      "Sung Won Han"
    ],
    "abstract": "The Automatic Identification System (AIS) enables data-driven maritime surveillance but suffers from reliability issues and irregular intervals. We address vessel destination estimation using global-scope AIS data by proposing a differentiated approach that recasts long port-to-port trajectories as a nested sequence structure. Using spatial grids, this method mitigates spatio-temporal bias while preserving detailed resolution. We introduce a novel deep learning architecture, WAY, designed to process these reformulated trajectories for long-term destination estimation days to weeks in advance. WAY comprises a trajectory representation layer and Channel-Aggregative Sequential Processing (CASP) blocks. The representation layer generates multi-channel vector sequences from kinematic and non-kinematic features. CASP blocks utilize multi-headed channel- and self-attention for aggregation and sequential information delivery. Additionally, we propose a task-specialized Gradient Dropout (GD) technique to enable many-to-many training on single labels, preventing biased feedback surges by stochastically blocking gradient flow based on sample length. Experiments on 5-year AIS data demonstrate WAY's superiority over conventional spatial grid-based approaches regardless of trajectory progression. Results further confirm that adopting GD leads to performance gains. Finally, we explore WAY's potential for real-world application through multitask learning for ETA estimation.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted to IEEE Transactions on Aerospace and Electronic Systems (TAES)",
    "pdf_url": "https://arxiv.org/pdf/2512.13190v1",
    "published_date": "2025-12-15 10:55:20 UTC",
    "updated_date": "2025-12-15 10:55:20 UTC"
  },
  {
    "arxiv_id": "2512.13186v1",
    "title": "PolySet: Restoring the Statistical Ensemble Nature of Polymers for Machine Learning",
    "authors": [
      "Khalid Ferji"
    ],
    "abstract": "Machine-learning (ML) models in polymer science typically treat a polymer as a single, perfectly defined molecular graph, even though real materials consist of stochastic ensembles of chains with distributed lengths. This mismatch between physical reality and digital representation limits the ability of current models to capture polymer behaviour. Here we introduce PolySet, a framework that represents a polymer as a finite, weighted ensemble of chains sampled from an assumed molar-mass distribution. This ensemble-based encoding is independent of chemical detail, compatible with any molecular representation and illustrated here in the homopolymer case using a minimal language model. We show that PolySet retains higher-order distributional moments (such as Mz, Mz+1), enabling ML models to learn tail-sensitive properties with greatly improved stability and accuracy. By explicitly acknowledging the statistical nature of polymer matter, PolySet establishes a physically grounded foundation for future polymer machine learning, naturally extensible to copolymers, block architectures, and other complex topologies.",
    "categories": [
      "cs.LG",
      "cond-mat.mtrl-sci",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.13186v1",
    "published_date": "2025-12-15 10:50:48 UTC",
    "updated_date": "2025-12-15 10:50:48 UTC"
  },
  {
    "arxiv_id": "2512.13174v1",
    "title": "Carrot, stick, or both? Price incentives for sustainable food choice in competitive environments",
    "authors": [
      "Francesco Salvi",
      "Giuseppe Russo",
      "Adam Barla",
      "Vincent Moreau",
      "Robert West"
    ],
    "abstract": "Meat consumption is a major driver of global greenhouse gas emissions. While pricing interventions have shown potential to reduce meat intake, previous studies have focused on highly constrained environments with limited consumer choice. Here, we present the first large-scale field experiment to evaluate multiple pricing interventions in a real-world, competitive setting. Using a sequential crossover design with matched menus in a Swiss university campus, we systematically compared vegetarian-meal discounts (-2.5 CHF), meat surcharges (+2.5 CHF), and a combined scheme (-1.2 CHF=+1.2 CHF) across four campus cafeterias. Only the surcharge and combined interventions led to significant increases in vegetarian meal uptake--by 26.4% and 16.6%, respectively--and reduced CO2 emissions per meal by 7.4% and 11.3%, respectively. The surcharge, while effective, triggered a 12.3% drop in sales at intervention sites and a corresponding 14.9% increase in non-treated locations, hence causing a spillover effect that completely offset environmental gains. In contrast, the combined approach achieved meaningful emission reductions without significant effects on overall sales or revenue, making it both effective and economically viable. Notably, pricing interventions were equally effective for both vegetarian-leaning customers and habitual meat-eaters, stimulating change even within entrenched dietary habits. Our results show that balanced pricing strategies can reduce the carbon footprint of realistic food environments, but require coordinated implementation to maximize climate benefits and avoid unintended spillover effects.",
    "categories": [
      "econ.GN",
      "cs.AI"
    ],
    "primary_category": "econ.GN",
    "comment": "10 pages, 3 figures",
    "pdf_url": "https://arxiv.org/pdf/2512.13174v1",
    "published_date": "2025-12-15 10:35:44 UTC",
    "updated_date": "2025-12-15 10:35:44 UTC"
  },
  {
    "arxiv_id": "2512.13168v3",
    "title": "Finch: Benchmarking Finance & Accounting across Spreadsheet-Centric Enterprise Workflows",
    "authors": [
      "Haoyu Dong",
      "Pengkun Zhang",
      "Yan Gao",
      "Xuanyu Dong",
      "Yilin Cheng",
      "Mingzhe Lu",
      "Adina Yakefu",
      "Shuxin Zheng"
    ],
    "abstract": "We introduce a finance & accounting benchmark (Finch) for evaluating AI agents on real-world, enterprise-grade professional workflows -- interleaving data entry, structuring, formatting, web search, cross-file retrieval, calculation, modeling, validation, translation, visualization, and reporting. Finch is sourced from authentic enterprise workspaces at Enron (15,000 spreadsheets and 500,000 emails from 150 employees) and other financial institutions, preserving in-the-wild messiness across multimodal artifacts (text, tables, formulas, charts, code, and images) and spanning diverse domains such as budgeting, trading, and asset management.\n  We propose a workflow construction process that combines LLM-assisted discovery with expert annotation: (1) LLM-assisted, expert-verified derivation of workflows from real-world email threads and version histories of spreadsheet files, and (2) meticulous expert annotation for workflows, requiring over 700 hours of domain-expert effort. This yields 172 composite workflows with 384 tasks, involving 1,710 spreadsheets with 27 million cells, along with PDFs and other artifacts, capturing the intrinsically messy, long-horizon, knowledge-intensive, and collaborative nature of real-world enterprise work.\n  We conduct both human and automated evaluations of frontier AI systems including GPT 5.1, Claude Sonnet 4.5, Gemini 3 Pro, Grok 4, and Qwen 3 Max, and GPT 5.1 Pro spends 16.8 minutes per workflow yet passes only 38.4% of workflows, while Claude Sonnet 4.5 passes just 25.0%. Comprehensive case studies further surface the challenges that real-world enterprise workflows pose for AI agents.",
    "categories": [
      "cs.AI",
      "cs.CE",
      "cs.IR",
      "cs.MA"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.13168v3",
    "published_date": "2025-12-15 10:28:45 UTC",
    "updated_date": "2026-01-03 05:28:05 UTC"
  },
  {
    "arxiv_id": "2512.13165v1",
    "title": "SACn: Soft Actor-Critic with n-step Returns",
    "authors": [
      "Jakub Łyskawa",
      "Jakub Lewandowski",
      "Paweł Wawrzyński"
    ],
    "abstract": "Soft Actor-Critic (SAC) is widely used in practical applications and is now one of the most relevant off-policy online model-free reinforcement learning (RL) methods. The technique of n-step returns is known to increase the convergence speed of RL algorithms compared to their 1-step returns-based versions. However, SAC is notoriously difficult to combine with n-step returns, since their usual combination introduces bias in off-policy algorithms due to the changes in action distribution. While this problem is solved by importance sampling, a method for estimating expected values of one distribution using samples from another distribution, importance sampling may result in numerical instability. In this work, we combine SAC with n-step returns in a way that overcomes this issue. We present an approach to applying numerically stable importance sampling with simplified hyperparameter selection. Furthermore, we analyze the entropy estimation approach of Soft Actor-Critic in the context of the n-step maximum entropy framework and formulate the $τ$-sampled entropy estimation to reduce the variance of the learning target. Finally, we formulate the Soft Actor-Critic with n-step returns (SAC$n$) algorithm that we experimentally verify on MuJoCo simulated environments.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted at ICAART 2026",
    "pdf_url": "https://arxiv.org/pdf/2512.13165v1",
    "published_date": "2025-12-15 10:23:13 UTC",
    "updated_date": "2025-12-15 10:23:13 UTC"
  },
  {
    "arxiv_id": "2512.13164v2",
    "title": "A Semantically Enhanced Generative Foundation Model Improves Pathological Image Synthesis",
    "authors": [
      "Xianchao Guan",
      "Zhiyuan Fan",
      "Yifeng Wang",
      "Fuqiang Chen",
      "Yanjiang Zhou",
      "Zengyang Che",
      "Hongxue Meng",
      "Xin Li",
      "Yaowei Wang",
      "Hongpeng Wang",
      "Min Zhang",
      "Heng Tao Shen",
      "Zheng Zhang",
      "Yongbing Zhang"
    ],
    "abstract": "The development of clinical-grade artificial intelligence in pathology is limited by the scarcity of diverse, high-quality annotated datasets. Generative models offer a potential solution but suffer from semantic instability and morphological hallucinations that compromise diagnostic reliability. To address this challenge, we introduce a Correlation-Regulated Alignment Framework for Tissue Synthesis (CRAFTS), the first generative foundation model for pathology-specific text-to-image synthesis. By leveraging a dual-stage training strategy on approximately 2.8 million image-caption pairs, CRAFTS incorporates a novel alignment mechanism that suppresses semantic drift to ensure biological accuracy. This model generates diverse pathological images spanning 30 cancer types, with quality rigorously validated by objective metrics and pathologist evaluations. Furthermore, CRAFTS-augmented datasets enhance the performance across various clinical tasks, including classification, cross-modal retrieval, self-supervised learning, and visual question answering. In addition, coupling CRAFTS with ControlNet enables precise control over tissue architecture from inputs such as nuclear segmentation masks and fluorescence images. By overcoming the critical barriers of data scarcity and privacy concerns, CRAFTS provides a limitless source of diverse, annotated histology data, effectively unlocking the creation of robust diagnostic tools for rare and complex cancer phenotypes.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "68 pages, 9 figures, 16 tables",
    "pdf_url": "https://arxiv.org/pdf/2512.13164v2",
    "published_date": "2025-12-15 10:22:43 UTC",
    "updated_date": "2025-12-16 03:25:24 UTC"
  },
  {
    "arxiv_id": "2512.13159v1",
    "title": "SpeakRL: Synergizing Reasoning, Speaking, and Acting in Language Models with Reinforcement Learning",
    "authors": [
      "Emre Can Acikgoz",
      "Jinoh Oh",
      "Jie Hao",
      "Joo Hyuk Jeon",
      "Heng Ji",
      "Dilek Hakkani-Tür",
      "Gokhan Tur",
      "Xiang Li",
      "Chengyuan Ma",
      "Xing Fan"
    ],
    "abstract": "Effective human-agent collaboration is increasingly prevalent in real-world applications. Current trends in such collaborations are predominantly unidirectional, with users providing instructions or posing questions to agents, where agents respond directly without seeking necessary clarifications or confirmations. However, the evolving capabilities of these agents require more proactive engagement, where agents should dynamically participate in conversations to clarify user intents, resolve ambiguities, and adapt to changing circumstances. Existing prior work under-utilize the conversational capabilities of language models (LMs), thereby optimizing agents as better followers rather than effective speakers. In this work, we introduce SpeakRL, a reinforcement learning (RL) method that enhances agents' conversational capabilities by rewarding proactive interactions with users, such as asking right clarification questions when necessary. To support this, we curate SpeakER, a synthetic dataset that includes diverse scenarios from task-oriented dialogues, where tasks are resolved through interactive clarification questions. We present a systematic analysis of reward design for conversational proactivity and propose a principled reward formulation for teaching agents to balance asking with acting. Empirical evaluations demonstrate that our approach achieves a 20.14% absolute improvement in task completion over base models without increasing conversation turns even surpassing even much larger proprietary models, demonstrating the promise of clarification-centric user-agent interactions.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.13159v1",
    "published_date": "2025-12-15 10:08:53 UTC",
    "updated_date": "2025-12-15 10:08:53 UTC"
  },
  {
    "arxiv_id": "2512.13157v1",
    "title": "Intrinsic Image Fusion for Multi-View 3D Material Reconstruction",
    "authors": [
      "Peter Kocsis",
      "Lukas Höllein",
      "Matthias Nießner"
    ],
    "abstract": "We introduce Intrinsic Image Fusion, a method that reconstructs high-quality physically based materials from multi-view images. Material reconstruction is highly underconstrained and typically relies on analysis-by-synthesis, which requires expensive and noisy path tracing. To better constrain the optimization, we incorporate single-view priors into the reconstruction process. We leverage a diffusion-based material estimator that produces multiple, but often inconsistent, candidate decompositions per view. To reduce the inconsistency, we fit an explicit low-dimensional parametric function to the predictions. We then propose a robust optimization framework using soft per-view prediction selection together with confidence-based soft multi-view inlier set to fuse the most consistent predictions of the most confident views into a consistent parametric material space. Finally, we use inverse path tracing to optimize for the low-dimensional parameters. Our results outperform state-of-the-art methods in material disentanglement on both synthetic and real scenes, producing sharp and clean reconstructions suitable for high-quality relighting.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Project page: https://peter-kocsis.github.io/IntrinsicImageFusion/ Video: https://www.youtube.com/watch?v=-Vs3tR1Xl7k",
    "pdf_url": "https://arxiv.org/pdf/2512.13157v1",
    "published_date": "2025-12-15 10:05:59 UTC",
    "updated_date": "2025-12-15 10:05:59 UTC"
  },
  {
    "arxiv_id": "2512.13154v1",
    "title": "MAC: A Multi-Agent Framework for Interactive User Clarification in Multi-turn Conversations",
    "authors": [
      "Emre Can Acikgoz",
      "Jinoh Oh",
      "Joo Hyuk Jeon",
      "Jie Hao",
      "Heng Ji",
      "Dilek Hakkani-Tür",
      "Gokhan Tur",
      "Xiang Li",
      "Chengyuan Ma",
      "Xing Fan"
    ],
    "abstract": "Conversational agents often encounter ambiguous user requests, requiring an effective clarification to successfully complete tasks. While recent advancements in real-world applications favor multi-agent architectures to manage complex conversational scenarios efficiently, ambiguity resolution remains a critical and underexplored challenge--particularly due to the difficulty of determining which agent should initiate a clarification and how agents should coordinate their actions when faced with uncertain or incomplete user input. The fundamental questions of when to interrupt a user and how to formulate the optimal clarification query within the most optimal multi-agent settings remain open. In this paper, we propose MAC (Multi-Agent Clarification), an interactive multi-agent framework specifically optimized to resolve user ambiguities by strategically managing clarification dialogues. We first introduce a novel taxonomy categorizing user ambiguities to systematically guide clarification strategies. Then, we present MAC that autonomously coordinates multiple agents to interact synergistically with users. Empirical evaluations on MultiWOZ 2.4 demonstrate that enabling clarification at both levels increases task success rate 7.8\\% (54.5 to 62.3) and reduces the average number of dialogue turns (6.53 to 4.86) by eliciting all required user information up front and minimizing repetition. Our findings highlight the importance of active user interaction and role-aware clarification for more reliable human-agent communication.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.13154v1",
    "published_date": "2025-12-15 10:02:50 UTC",
    "updated_date": "2025-12-15 10:02:50 UTC"
  },
  {
    "arxiv_id": "2512.13142v4",
    "title": "Can LLMs Understand What We Cannot Say? Measuring Multilevel Alignment Through Abortion Stigma Across Cognitive, Interpersonal, and Structural Levels",
    "authors": [
      "Anika Sharma",
      "Malavika Mampally",
      "Chidaksh Ravuru",
      "Kandyce Brennan",
      "Neil Gaikwad"
    ],
    "abstract": "As Large Language Models (LLMs) increasingly mediate stigmatized health decisions, their capacity to understand complex psychological phenomena remains inadequately assessed. Can LLMs understand what we cannot say? We investigate whether LLMs coherently represent abortion stigma across cognitive, interpersonal, and structural levels. We systematically tested 627 demographically diverse personas across five leading LLMs using the validated Individual Level Abortion Stigma Scale (ILAS), examining representation at cognitive (self-judgment), interpersonal (worries about judgment and isolation), and structural (community condemnation and disclosure patterns) levels. Models fail tests of genuine understanding across all dimensions. They underestimate cognitive stigma while overestimating interpersonal stigma, introduce demographic biases assigning higher stigma to younger, less educated, and non-White personas, and treat secrecy as universal despite 36% of humans reporting openness. Most critically, models produce internal contradictions: they overestimate isolation yet predict isolated individuals are less secretive, revealing incoherent representations. These patterns show current alignment approaches ensure appropriate language but not coherent understanding across levels. This work provides empirical evidence that LLMs lack coherent understanding of psychological constructs operating across multiple dimensions. AI safety in high-stakes contexts demands new approaches to design (multilevel coherence), evaluation (continuous auditing), governance and regulation (mandatory audits, accountability, deployment restrictions), and AI literacy in domains where understanding what people cannot say determines whether support helps or harms.",
    "categories": [
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.13142v4",
    "published_date": "2025-12-15 09:50:00 UTC",
    "updated_date": "2026-01-15 17:43:09 UTC"
  },
  {
    "arxiv_id": "2512.13131v1",
    "title": "Towards Unified Co-Speech Gesture Generation via Hierarchical Implicit Periodicity Learning",
    "authors": [
      "Xin Guo",
      "Yifan Zhao",
      "Jia Li"
    ],
    "abstract": "Generating 3D-based body movements from speech shows great potential in extensive downstream applications, while it still suffers challenges in imitating realistic human movements. Predominant research efforts focus on end-to-end generation schemes to generate co-speech gestures, spanning GANs, VQ-VAE, and recent diffusion models. As an ill-posed problem, in this paper, we argue that these prevailing learning schemes fail to model crucial inter- and intra-correlations across different motion units, i.e. head, body, and hands, thus leading to unnatural movements and poor coordination. To delve into these intrinsic correlations, we propose a unified Hierarchical Implicit Periodicity (HIP) learning approach for audio-inspired 3D gesture generation. Different from predominant research, our approach models this multi-modal implicit relationship by two explicit technique insights: i) To disentangle the complicated gesture movements, we first explore the gesture motion phase manifolds with periodic autoencoders to imitate human natures from realistic distributions while incorporating non-period ones from current latent states for instance-level diversities. ii) To model the hierarchical relationship of face motions, body gestures, and hand movements, driving the animation with cascaded guidance during learning. We exhibit our proposed approach on 3D avatars and extensive experiments show our method outperforms the state-of-the-art co-speech gesture generation methods by both quantitative and qualitative evaluations. Code and models will be publicly available.",
    "categories": [
      "cs.AI",
      "cs.CV",
      "cs.GR",
      "cs.MM",
      "cs.SD"
    ],
    "primary_category": "cs.AI",
    "comment": "IEEE Transactions on Image Processing",
    "pdf_url": "https://arxiv.org/pdf/2512.13131v1",
    "published_date": "2025-12-15 09:43:08 UTC",
    "updated_date": "2025-12-15 09:43:08 UTC"
  },
  {
    "arxiv_id": "2512.22149v2",
    "title": "Adaptive GPU Resource Allocation for Multi-Agent Collaborative Reasoning in Serverless Environments",
    "authors": [
      "Guilin Zhang",
      "Wulan Guo",
      "Ziqi Tan"
    ],
    "abstract": "Multi-agent systems powered by large language models have emerged as a promising paradigm for solving complex reasoning tasks through collaborative intelligence. However, efficiently deploying these systems on serverless GPU platforms presents significant resource allocation challenges due to heterogeneous agent workloads, varying computational demands, and the need for cost-effective scaling. This paper presents an adaptive GPU resource allocation framework that achieves 85% latency reduction compared to round-robin scheduling while maintaining comparable throughput to static allocation, using an O(N) complexity algorithm for real-time adaptation. Our approach dynamically allocates GPU resources based on workload characteristics, agent priorities, and minimum resource requirements, enabling efficient utilization while maintaining quality of service. The framework addresses three key challenges: (1) heterogeneous computational demands across lightweight coordinators and heavyweight specialists, (2) dynamic workload fluctuations requiring millisecond-scale reallocation, and (3) capacity constraints in serverless environments. Through comprehensive simulations modeling realistic multi-agent workflows with four heterogeneous agents, we demonstrate that adaptive allocation outperforms static equal and round-robin strategies across latency, cost, and GPU utilization metrics. The framework provides a practical solution for deploying cost-efficient multi-agent AI systems on serverless GPU infrastructure.",
    "categories": [
      "cs.DC",
      "cs.AI",
      "cs.MA"
    ],
    "primary_category": "cs.DC",
    "comment": "6 pages, 2 figures",
    "pdf_url": "https://arxiv.org/pdf/2512.22149v2",
    "published_date": "2025-12-15 09:21:48 UTC",
    "updated_date": "2026-01-01 03:32:51 UTC"
  },
  {
    "arxiv_id": "2512.13122v1",
    "title": "DePT3R: Joint Dense Point Tracking and 3D Reconstruction of Dynamic Scenes in a Single Forward Pass",
    "authors": [
      "Vivek Alumootil",
      "Tuan-Anh Vu",
      "M. Khalid Jawed"
    ],
    "abstract": "Current methods for dense 3D point tracking in dynamic scenes typically rely on pairwise processing, require known camera poses, or assume a temporal ordering to input frames, constraining their flexibility and applicability. Additionally, recent advances have successfully enabled efficient 3D reconstruction from large-scale, unposed image collections, underscoring opportunities for unified approaches to dynamic scene understanding. Motivated by this, we propose DePT3R, a novel framework that simultaneously performs dense point tracking and 3D reconstruction of dynamic scenes from multiple images in a single forward pass. This multi-task learning is achieved by extracting deep spatio-temporal features with a powerful backbone and regressing pixel-wise maps with dense prediction heads. Crucially, DePT3R operates without requiring camera poses, substantially enhancing its adaptability and efficiency-especially important in dynamic environments with rapid changes. We validate DePT3R on several challenging benchmarks involving dynamic scenes, demonstrating strong performance and significant improvements in memory efficiency over existing state-of-the-art methods. Data and codes are available via the open repository: https://github.com/StructuresComp/DePT3R",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "This is a work in progress",
    "pdf_url": "https://arxiv.org/pdf/2512.13122v1",
    "published_date": "2025-12-15 09:21:28 UTC",
    "updated_date": "2025-12-15 09:21:28 UTC"
  },
  {
    "arxiv_id": "2512.13111v1",
    "title": "From Overfitting to Reliability: Introducing the Hierarchical Approximate Bayesian Neural Network",
    "authors": [
      "Hayk Amirkhanian",
      "Marco F. Huber"
    ],
    "abstract": "In recent years, neural networks have revolutionized various domains, yet challenges such as hyperparameter tuning and overfitting remain significant hurdles. Bayesian neural networks offer a framework to address these challenges by incorporating uncertainty directly into the model, yielding more reliable predictions, particularly for out-of-distribution data. This paper presents Hierarchical Approximate Bayesian Neural Network, a novel approach that uses a Gaussian-inverse-Wishart distribution as a hyperprior of the network's weights to increase both the robustness and performance of the model. We provide analytical representations for the predictive distribution and weight posterior, which amount to the calculation of the parameters of Student's t-distributions in closed form with linear complexity with respect to the number of weights. Our method demonstrates robust performance, effectively addressing issues of overfitting and providing reliable uncertainty estimates, particularly for out-of-distribution tasks. Experimental results indicate that HABNN not only matches but often outperforms state-of-the-art models, suggesting a promising direction for future applications in safety-critical environments.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "9 pages main body, 1 Figure, 15 pages Appendix",
    "pdf_url": "https://arxiv.org/pdf/2512.13111v1",
    "published_date": "2025-12-15 09:08:42 UTC",
    "updated_date": "2025-12-15 09:08:42 UTC"
  },
  {
    "arxiv_id": "2512.13109v1",
    "title": "Uncovering the Role of Initial Saliency in U-Shaped Attention Bias: Scaling Initial Token Weight for Enhanced Long-Text Processing",
    "authors": [
      "Zewen Qiang",
      "Sendong Zhao",
      "Haochun Wang",
      "Bing Qin",
      "Ting Liu"
    ],
    "abstract": "Large language models (LLMs) have demonstrated strong performance on a variety of natural language processing (NLP) tasks. However, they often struggle with long-text sequences due to the ``lost in the middle'' phenomenon. This issue has been shown to arise from a U-shaped attention bias, where attention is disproportionately focused on the beginning and end of a text, leaving the middle section underrepresented. While previous studies have attributed this bias to position encoding, our research first identifies an additional factor: initial saliency. It means that in the attention computation for each token, tokens with higher attention weights relative to the initial token tend to receive more attention in the prediction of the next token. We further find that utilizing this property by scaling attention weight between the initial token and others improves the model's ability to process long contexts, achieving a maximum improvement of 3.6\\% in MDQA dataset. Moreover, combining this approach with existing methods to reduce position encoding bias further enhances performance, achieving a maximum improvement of 3.4\\% in KV-Retrieval tasks.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.13109v1",
    "published_date": "2025-12-15 09:04:06 UTC",
    "updated_date": "2025-12-15 09:04:06 UTC"
  },
  {
    "arxiv_id": "2512.13107v2",
    "title": "Diffusion-Based Restoration for Multi-Modal 3D Object Detection in Adverse Weather",
    "authors": [
      "Zhijian He",
      "Feifei Liu",
      "Yuwei Li",
      "Zhanpeng Luo",
      "Jintao Cheng",
      "Xieyuanli Chen",
      "Xiaoyu Tang"
    ],
    "abstract": "Multi-modal 3D object detection is important for reliable perception in robotics and autonomous driving. However, its effectiveness remains limited under adverse weather conditions due to weather-induced distortions and misalignment between different data modalities. In this work, we propose DiffFusion, a novel framework designed to enhance robustness in challenging weather through diffusion-based restoration and adaptive cross-modal fusion. Our key insight is that diffusion models possess strong capabilities for denoising and generating data that can adapt to various weather conditions. Building on this, DiffFusion introduces Diffusion-IR restoring images degraded by weather effects and Point Cloud Restoration (PCR) compensating for corrupted LiDAR data using image object cues. To tackle misalignments between two modalities, we develop Bidirectional Adaptive Fusion and Alignment Module (BAFAM). It enables dynamic multi-modal fusion and bidirectional bird's-eye view (BEV) alignment to maintain consistent spatial correspondence. Extensive experiments on three public datasets show that DiffFusion achieves state-of-the-art robustness under adverse weather while preserving strong clean-data performance. Zero-shot results on the real-world DENSE dataset further validate its generalization. The implementation of our DiffFusion will be released as open-source.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.13107v2",
    "published_date": "2025-12-15 09:03:46 UTC",
    "updated_date": "2025-12-18 16:00:41 UTC"
  },
  {
    "arxiv_id": "2512.13106v1",
    "title": "TraPO: A Semi-Supervised Reinforcement Learning Framework for Boosting LLM Reasoning",
    "authors": [
      "Shenzhi Yang",
      "Guangcheng Zhu",
      "Xing Zheng",
      "Yingfan MA",
      "Zhongqi Chen",
      "Bowen Song",
      "Weiqiang Wang",
      "Junbo Zhao",
      "Gang Chen",
      "Haobo Wang"
    ],
    "abstract": "Reinforcement learning with verifiable rewards (RLVR) has proven effective in training large reasoning models (LRMs) by leveraging answer-verifiable signals to guide policy optimization, which, however, suffers from high annotation costs. To alleviate this problem, recent work has explored unsupervised RLVR methods that derive rewards solely from the model's internal consistency, such as through entropy and majority voting. While seemingly promising, these methods often suffer from model collapse in the later stages of training, which may arise from the reinforcement of incorrect reasoning patterns in the absence of external supervision. In this work, we investigate a novel semi-supervised RLVR paradigm that utilizes a small labeled set to guide RLVR training on unlabeled samples. Our key insight is that supervised rewards are essential for stabilizing consistency-based training on unlabeled samples, ensuring that only reasoning patterns verified on labeled instances are incorporated into RL training. Technically, we propose an effective policy optimization algorithm, TraPO, that identifies reliable unlabeled samples by matching their learning trajectory similarity to labeled ones. Building on this, TraPO achieves remarkable data efficiency and strong generalization on six widely used mathematical reasoning benchmarks (AIME24/25, AMC, MATH-500, Minerva, and Olympiad) and three out-of-distribution tasks (ARC-c, GPQA-diamond, and MMLU-pro). With only 1K labeled and 3K unlabeled samples, TraPO reaches 42.6% average accuracy, surpassing the best unsupervised method trained on 45K unlabeled samples (38.3%). Notably, when using 4K labeled and 12K unlabeled samples, TraPO even outperforms the fully supervised model trained on the full 45K labeled samples on all benchmarks, while using only 10% of the labeled data. The code is available via https://github.com/ShenzhiYang2000/TRAPO.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.13106v1",
    "published_date": "2025-12-15 09:03:45 UTC",
    "updated_date": "2025-12-15 09:03:45 UTC"
  },
  {
    "arxiv_id": "2512.13102v4",
    "title": "Socratic Students: Teaching Language Models to Learn by Asking Questions",
    "authors": [
      "Rajeev Bhatt Ambati",
      "Tianyi Niu",
      "Aashu Singh",
      "Shlok Mishra",
      "Snigdha Chaturvedi",
      "Shashank Srivastava"
    ],
    "abstract": "Large language Models (LLMs) are usually used to answer questions, but many high-stakes applications (e.g., tutoring, clinical support) require the complementary skill of asking questions: detecting missing information, requesting clarifications, and using them to solve tasks. We study this skill in reasoning-heavy domains where progress depends on inquiry rather than factual recall. We define an interactive protocol where a student model engages a stronger teacher under a small turn budget. After each teacher reply, we evaluate the student on the original task with Pass@k. We propose Outcome-Driven Question optimization Strategy (ODQS ), a training framework that learns a questioning policy from downstream task outcomes. At each turn, we sample multiple candidate questions; query the teacher with each, then score the student's resulting performance. Using these scores, we train the student via supervised fine-tuning followed by Direct Preference Optimization (DPO), without any human labels. On GSM8K, HumanEval, and OpenCoder, ODQS produces large gains over interactive baselines, boosting Pass@5 by up to 54.7% (absolute) on math and 22.9% (absolute) on coding, and matching baseline performance in three fewer turns. Thus, question asking can be explicitly trained from task outcomes, improving both accuracy and efficiency in interactive reasoning.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.13102v4",
    "published_date": "2025-12-15 08:59:19 UTC",
    "updated_date": "2026-01-06 08:41:00 UTC"
  },
  {
    "arxiv_id": "2512.13101v1",
    "title": "Harmonizing Generalization and Specialization: Uncertainty-Informed Collaborative Learning for Semi-supervised Medical Image Segmentation",
    "authors": [
      "Wenjing Lu",
      "Yi Hong",
      "Yang Yang"
    ],
    "abstract": "Vision foundation models have demonstrated strong generalization in medical image segmentation by leveraging large-scale, heterogeneous pretraining. However, they often struggle to generalize to specialized clinical tasks under limited annotations or rare pathological variations, due to a mismatch between general priors and task-specific requirements. To address this, we propose Uncertainty-informed Collaborative Learning (UnCoL), a dual-teacher framework that harmonizes generalization and specialization in semi-supervised medical image segmentation. Specifically, UnCoL distills both visual and semantic representations from a frozen foundation model to transfer general knowledge, while concurrently maintaining a progressively adapting teacher to capture fine-grained and task-specific representations. To balance guidance from both teachers, pseudo-label learning in UnCoL is adaptively regulated by predictive uncertainty, which selectively suppresses unreliable supervision and stabilizes learning in ambiguous regions. Experiments on diverse 2D and 3D segmentation benchmarks show that UnCoL consistently outperforms state-of-the-art semi-supervised methods and foundation model baselines. Moreover, our model delivers near fully supervised performance with markedly reduced annotation requirements.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "This work has been submitted to the IEEE TMI for possible publication",
    "pdf_url": "https://arxiv.org/pdf/2512.13101v1",
    "published_date": "2025-12-15 08:57:49 UTC",
    "updated_date": "2025-12-15 08:57:49 UTC"
  },
  {
    "arxiv_id": "2512.13100v1",
    "title": "OXE-AugE: A Large-Scale Robot Augmentation of OXE for Scaling Cross-Embodiment Policy Learning",
    "authors": [
      "Guanhua Ji",
      "Harsha Polavaram",
      "Lawrence Yunliang Chen",
      "Sandeep Bajamahal",
      "Zehan Ma",
      "Simeon Adebola",
      "Chenfeng Xu",
      "Ken Goldberg"
    ],
    "abstract": "Large and diverse datasets are needed for training generalist robot policies that have potential to control a variety of robot embodiments -- robot arm and gripper combinations -- across diverse tasks and environments. As re-collecting demonstrations and retraining for each new hardware platform are prohibitively costly, we show that existing robot data can be augmented for transfer and generalization. The Open X-Embodiment (OXE) dataset, which aggregates demonstrations from over 60 robot datasets, has been widely used as the foundation for training generalist policies. However, it is highly imbalanced: the top four robot types account for over 85\\% of its real data, which risks overfitting to robot-scene combinations. We present AugE-Toolkit, a scalable robot augmentation pipeline, and OXE-AugE, a high-quality open-source dataset that augments OXE with 9 different robot embodiments. OXE-AugE provides over 4.4 million trajectories, more than triple the size of the original OXE. We conduct a systematic study of how scaling robot augmentation impacts cross-embodiment learning. Results suggest that augmenting datasets with diverse arms and grippers improves policy performance not only on the augmented robots, but also on unseen robots and even the original robots under distribution shifts. In physical experiments, we demonstrate that state-of-the-art generalist policies such as OpenVLA and $π_0$ benefit from fine-tuning on OXE-AugE, improving success rates by 24-45% on previously unseen robot-gripper combinations across four real-world manipulation tasks. Project website: https://OXE-AugE.github.io/.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.13100v1",
    "published_date": "2025-12-15 08:57:15 UTC",
    "updated_date": "2025-12-15 08:57:15 UTC"
  },
  {
    "arxiv_id": "2512.13094v1",
    "title": "Sequence of Expert: Boosting Imitation Planners for Autonomous Driving through Temporal Alternation",
    "authors": [
      "Xiang Li",
      "Gang Liu",
      "Weitao Zhou",
      "Hongyi Zhu",
      "Zhong Cao"
    ],
    "abstract": "Imitation learning (IL) has emerged as a central paradigm in autonomous driving. While IL excels in matching expert behavior in open-loop settings by minimizing per-step prediction errors, its performance degrades unexpectedly in closed-loop due to the gradual accumulation of small, often imperceptible errors over time.Over successive planning cycles, these errors compound, potentially resulting in severe failures.Current research efforts predominantly rely on increasingly sophisticated network architectures or high-fidelity training datasets to enhance the robustness of IL planners against error accumulation, focusing on the state-level robustness at a single time point. However, autonomous driving is inherently a continuous-time process, and leveraging the temporal scale to enhance robustness may provide a new perspective for addressing this issue.To this end, we propose a method termed Sequence of Experts (SoE), a temporal alternation policy that enhances closed-loop performance without increasing model size or data requirements. Our experiments on large-scale autonomous driving benchmarks nuPlan demonstrate that SoE method consistently and significantly improves the performance of all the evaluated models, and achieves state-of-the-art performance.This module may provide a key and widely applicable support for improving the training efficiency of autonomous driving models.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.13094v1",
    "published_date": "2025-12-15 08:50:23 UTC",
    "updated_date": "2025-12-15 08:50:23 UTC"
  },
  {
    "arxiv_id": "2512.13089v2",
    "title": "UniVCD: A New Method for Unsupervised Change Detection in the Open-Vocabulary Era",
    "authors": [
      "Ziqiang Zhu",
      "Bowei Yang"
    ],
    "abstract": "Change detection (CD) identifies scene changes from multi-temporal observations and is widely used in urban development and environmental monitoring. Most existing CD methods rely on supervised learning, making performance strongly dataset-dependent and incurring high annotation costs; they typically focus on a few predefined categories and generalize poorly to diverse scenes. With the rise of vision foundation models such as SAM2 and CLIP, new opportunities have emerged to relax these constraints. We propose Unified Open-Vocabulary Change Detection (UniVCD), an unsupervised, open-vocabulary change detection method built on frozen SAM2 and CLIP. UniVCD detects category-agnostic changes across diverse scenes and imaging geometries without any labeled data or paired change images. A lightweight feature alignment module is introduced to bridge the spatially detailed representations from SAM2 and the semantic priors from CLIP, enabling high-resolution, semantically aware change estimation while keeping the number of trainable parameters small. On top of this, a streamlined post-processing pipeline is further introduced to suppress noise and pseudo-changes, improving the detection accuracy for objects with well-defined boundaries. Experiments on several public BCD (Binary Change Detection) and SCD (Semantic Change Detection) benchmarks show that UniVCD achieves consistently strong performance and matches or surpasses existing open-vocabulary CD methods in key metrics such as F1 and IoU. The results demonstrate that unsupervised change detection with frozen vision foundation models and lightweight multi-modal alignment is a practical and effective paradigm for open-vocabulary CD. Code and pretrained models will be released at https://github.com/Die-Xie/UniVCD.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "10 pages, 6 figures",
    "pdf_url": "https://arxiv.org/pdf/2512.13089v2",
    "published_date": "2025-12-15 08:42:23 UTC",
    "updated_date": "2025-12-18 05:14:28 UTC"
  },
  {
    "arxiv_id": "2512.13074v1",
    "title": "A Simple and Effective Framework for Symmetric Consistent Indexing in Large-Scale Dense Retrieval",
    "authors": [
      "Huimu Wang",
      "Yiming Qiu",
      "Xingzhi Yao",
      "Zhiguo Chen",
      "Guoyu Tang",
      "Songlin Wang",
      "Sulong Xu",
      "Mingming Li"
    ],
    "abstract": "Dense retrieval has become the industry standard in large-scale information retrieval systems due to its high efficiency and competitive accuracy. Its core relies on a coarse-to-fine hierarchical architecture that enables rapid candidate selection and precise semantic matching, achieving millisecond-level response over billion-scale corpora. This capability makes it essential not only in traditional search and recommendation scenarios but also in the emerging paradigm of generative recommendation driven by large language models, where semantic IDs-themselves a form of coarse-to-fine representation-play a foundational role. However, the widely adopted dual-tower encoding architecture introduces inherent challenges, primarily representational space misalignment and retrieval index inconsistency, which degrade matching accuracy, retrieval stability, and performance on long-tail queries. These issues are further magnified in semantic ID generation, ultimately limiting the performance ceiling of downstream generative models.\n  To address these challenges, this paper proposes a simple and effective framework named SCI comprising two synergistic modules: a symmetric representation alignment module that employs an innovative input-swapping mechanism to unify the dual-tower representation space without adding parameters, and an consistent indexing with dual-tower synergy module that redesigns retrieval paths using a dual-view indexing strategy to maintain consistency from training to inference. The framework is systematic, lightweight, and engineering-friendly, requiring minimal overhead while fully supporting billion-scale deployment. We provide theoretical guarantees for our approach, with its effectiveness validated by results across public datasets and real-world e-commerce datasets.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.13074v1",
    "published_date": "2025-12-15 08:11:24 UTC",
    "updated_date": "2025-12-15 08:11:24 UTC"
  },
  {
    "arxiv_id": "2512.13070v1",
    "title": "M-GRPO: Stabilizing Self-Supervised Reinforcement Learning for Large Language Models with Momentum-Anchored Policy Optimization",
    "authors": [
      "Bizhe Bai",
      "Hongming Wu",
      "Peng Ye",
      "Tao Chen"
    ],
    "abstract": "Self-supervised reinforcement learning (RL) presents a promising approach for enhancing the reasoning capabilities of Large Language Models (LLMs) without reliance on expensive human-annotated data. However, we find that existing methods suffer from a critical failure mode under long-horizon training: a \"policy collapse\" where performance precipitously degrades. We diagnose this instability and demonstrate that simply scaling the number of rollouts -- a common strategy to improve performance -- only delays, but does not prevent, this collapse. To counteract this instability, we first introduce M-GRPO (Momentum-Anchored Group Relative Policy Optimization), a framework that leverages a slowly evolving momentum model to provide a stable training target. In addition, we identify that this process is often accompanied by a rapid collapse in policy entropy, resulting in a prematurely confident and suboptimal policy. To specifically address this issue, we propose a second contribution: an adaptive filtering method based on the interquartile range (IQR) that dynamically prunes low-entropy trajectories, preserving essential policy diversity. Our extensive experiments on multiple reasoning benchmarks demonstrate that M-GRPO stabilizes the training process while the IQR filter prevents premature convergence. The combination of these two innovations leads to superior training stability and state-of-the-art performance.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "7 pages, 5 figures,Accepted NeurIPS 2025 Workshop on Efficient Reasoning",
    "pdf_url": "https://arxiv.org/pdf/2512.13070v1",
    "published_date": "2025-12-15 08:07:23 UTC",
    "updated_date": "2025-12-15 08:07:23 UTC"
  },
  {
    "arxiv_id": "2512.13063v1",
    "title": "LLM Rationalis? Measuring Bargaining Capabilities of AI Negotiators",
    "authors": [
      "Cheril Shah",
      "Akshit Agarwal",
      "Kanak Garg",
      "Mourad Heddaya"
    ],
    "abstract": "Bilateral negotiation is a complex, context-sensitive task in which human negotiators dynamically adjust anchors, pacing, and flexibility to exploit power asymmetries and informal cues. We introduce a unified mathematical framework for modeling concession dynamics based on a hyperbolic tangent curve, and propose two metrics burstiness tau and the Concession-Rigidity Index (CRI) to quantify the timing and rigidity of offer trajectories. We conduct a large-scale empirical comparison between human negotiators and four state-of-the-art large language models (LLMs) across natural-language and numeric-offers settings, with and without rich market context, as well as six controlled power-asymmetry scenarios. Our results reveal that, unlike humans who smoothly adapt to situations and infer the opponents position and strategies, LLMs systematically anchor at extremes of the possible agreement zone for negotiations and optimize for fixed points irrespective of leverage or context. Qualitative analysis further shows limited strategy diversity and occasional deceptive tactics used by LLMs. Moreover the ability of LLMs to negotiate does not improve with better models. These findings highlight fundamental limitations in current LLM negotiation capabilities and point to the need for models that better internalize opponent reasoning and context-dependent strategy.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Published in the First Workshop on Multi-Turn Interactions in Large Language Models at Neurips 2025",
    "pdf_url": "https://arxiv.org/pdf/2512.13063v1",
    "published_date": "2025-12-15 07:50:09 UTC",
    "updated_date": "2025-12-15 07:50:09 UTC"
  },
  {
    "arxiv_id": "2512.22148v1",
    "title": "Rethinking Leveraging Pre-Trained Multi-Layer Representations for Speaker Verification",
    "authors": [
      "Jin Sob Kim",
      "Hyun Joon Park",
      "Wooseok Shin",
      "Sung Won Han"
    ],
    "abstract": "Recent speaker verification studies have achieved notable success by leveraging layer-wise output from pre-trained Transformer models. However, few have explored the advancements in aggregating these multi-level features beyond the static weighted average. We present Layer Attentive Pooling (LAP), a novel strategy for aggregating inter-layer representations from pre-trained speech models for speaker verification. LAP assesses the significance of each layer from multiple perspectives time-dynamically, and employs max pooling instead of averaging. Additionally, we propose a lightweight backend speaker model comprising LAP and Attentive Statistical Temporal Pooling (ASTP) to extract speaker embeddings from pre-trained model output. Experiments on the VoxCeleb benchmark reveal that our compact architecture achieves state-of-the-art performance while greatly reducing the training time. We further analyzed LAP design and its dynamic weighting mechanism for capturing speaker characteristics.",
    "categories": [
      "cs.SD",
      "cs.AI"
    ],
    "primary_category": "cs.SD",
    "comment": "Accepted to Interspeech 2025",
    "pdf_url": "https://arxiv.org/pdf/2512.22148v1",
    "published_date": "2025-12-15 07:39:56 UTC",
    "updated_date": "2025-12-15 07:39:56 UTC"
  },
  {
    "arxiv_id": "2512.22147v1",
    "title": "GPU Kernel Optimization Beyond Full Builds: An LLM Framework with Minimal Executable Programs",
    "authors": [
      "Ruifan Chu",
      "Anbang Wang",
      "Xiuxiu Bai",
      "Shuai Liu",
      "Xiaoshe Dong"
    ],
    "abstract": "In high-performance computing, hotspot GPU kernels are primary bottlenecks, and expert manual tuning is costly and hard to port. Large language model methods often assume kernels can be compiled and executed cheaply, which fails in large applications where full builds and runs are expensive. We present an end-to-end LLM framework with performance feedback that optimizes kernels without building the full application. From independently extracted hotspot kernels, it automatically completes code into a Minimal Executable Program (MEP), then performs multi-round iterative optimization and evaluation outside the full application. The framework integrates Automatic Error Repair and Performance Pattern Inheritance to fix faults, preserve correctness, reuse effective tiling/memory/synchronization strategies, and reduce search cost. Optimized variants are reintegrated into the original application for validation. We evaluate on NVIDIA GPUs and the Haiguang Deep Computing Unit (DCU) platform (AMD-licensed architecture) using PolyBench, the AMD APP SDK, and hotspot kernels from large-scale supercomputing applications. The method achieves average speedups of 5.05x (PolyBench on NVIDIA), 7.77x (PolyBench on DCU), 1.77x (AMD APP SDK), and 1.25x on three hotspot kernels, surpassing direct LLM optimization. The approach requires no full-source dependencies, offers cross-platform portability, and enables practical, low-cost GPU kernel optimization.",
    "categories": [
      "cs.DC",
      "cs.AI",
      "cs.LG",
      "cs.PF"
    ],
    "primary_category": "cs.DC",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.22147v1",
    "published_date": "2025-12-15 07:20:15 UTC",
    "updated_date": "2025-12-15 07:20:15 UTC"
  },
  {
    "arxiv_id": "2512.13043v1",
    "title": "GTR-Turbo: Merged Checkpoint is Secretly a Free Teacher for Agentic VLM Training",
    "authors": [
      "Tong Wei",
      "Yijun Yang",
      "Changhao Zhang",
      "Junliang Xing",
      "Yuanchun Shi",
      "Zongqing Lu",
      "Deheng Ye"
    ],
    "abstract": "Multi-turn reinforcement learning (RL) for multi-modal agents built upon vision-language models (VLMs) is hampered by sparse rewards and long-horizon credit assignment. Recent methods densify the reward by querying a teacher that provides step-level feedback, e.g., Guided Thought Reinforcement (GTR) and On-Policy Distillation, but rely on costly, often privileged models as the teacher, limiting practicality and reproducibility. We introduce GTR-Turbo, a highly efficient upgrade to GTR, which matches the performance without training or querying an expensive teacher model. Specifically, GTR-Turbo merges the weights of checkpoints produced during the ongoing RL training, and then uses this merged model as a \"free\" teacher to guide the subsequent RL via supervised fine-tuning or soft logit distillation. This design removes dependence on privileged VLMs (e.g., GPT or Gemini), mitigates the \"entropy collapse\" observed in prior work, and keeps training stable. Across diverse visual agentic tasks, GTR-Turbo improves the accuracy of the baseline model by 10-30% while reducing wall-clock training time by 50% and compute cost by 60% relative to GTR.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.13043v1",
    "published_date": "2025-12-15 07:11:56 UTC",
    "updated_date": "2025-12-15 07:11:56 UTC"
  },
  {
    "arxiv_id": "2512.13033v1",
    "title": "Scaling Bidirectional Spans and Span Violations in Attention Mechanism",
    "authors": [
      "Jongwook Kim",
      "Sangheon Yun",
      "Sukjin Yoon"
    ],
    "abstract": "The canonical $O(N^2)$ Transformer remains the empirical performance frontier in sequence modeling, and its training can be further optimized by addressing geometric inefficiency. We propose an optimization framework that leverages an asymmetric projection to decompose the backward-pass gradients into parallel spans and orthogonal violations, while keeping the canonical forward-pass $QKV$ structure intact. Through consistent experimental validation across various decomposition and projection setups, we provide strong theoretical evidence: the standard attention gradient is suboptimal. We demonstrated that selectively scaling these components, focusing primarily on $0^{th}$ order bidirectional parallel spans, yields the most effective learning signal. On the limited WikiText-2 dataset, and using a crude configuration, this method achieved a $0.56\\%$ reduction in validation loss, confirming the framework's fundamental validity and suggesting significant potential gains on larger datasets and deeper training regimes",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.13033v1",
    "published_date": "2025-12-15 07:03:24 UTC",
    "updated_date": "2025-12-15 07:03:24 UTC"
  },
  {
    "arxiv_id": "2512.13752v1",
    "title": "STAR: STacked AutoRegressive Scheme for Unified Multimodal Learning",
    "authors": [
      "Jie Qin",
      "Jiancheng Huang",
      "Limeng Qiao",
      "Lin Ma"
    ],
    "abstract": "Multimodal large language models (MLLMs) play a pivotal role in advancing the quest for general artificial intelligence. However, achieving unified target for multimodal understanding and generation remains challenging due to optimization conflicts and performance trade-offs. To effectively enhance generative performance while preserving existing comprehension capabilities, we introduce STAR: a STacked AutoRegressive scheme for task-progressive unified multimodal learning. This approach decomposes multimodal learning into multiple stages: understanding, generation, and editing. By freezing the parameters of the fundamental autoregressive (AR) model and progressively stacking isomorphic AR modules, it avoids cross-task interference while expanding the model's capabilities. Concurrently, we introduce a high-capacity VQ to enhance the granularity of image representations and employ an implicit reasoning mechanism to improve generation quality under complex conditions. Experiments demonstrate that STAR achieves state-of-the-art performance on GenEval (0.91), DPG-Bench (87.44), and ImgEdit (4.34), validating its efficacy for unified multimodal learning.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "18 pages, 7 figures",
    "pdf_url": "https://arxiv.org/pdf/2512.13752v1",
    "published_date": "2025-12-15 07:02:59 UTC",
    "updated_date": "2025-12-15 07:02:59 UTC"
  },
  {
    "arxiv_id": "2512.19711v1",
    "title": "PHANTOM: PHysical ANamorphic Threats Obstructing Connected Vehicle Mobility",
    "authors": [
      "Md Nahid Hasan Shuvo",
      "Moinul Hossain"
    ],
    "abstract": "Connected autonomous vehicles (CAVs) rely on vision-based deep neural networks (DNNs) and low-latency (Vehicle-to-Everything) V2X communication to navigate safely and efficiently. Despite their advances, these systems remain vulnerable to physical adversarial attacks. In this paper, we introduce PHANTOM (PHysical ANamorphic Threats Obstructing connected vehicle Mobility), a novel framework for crafting and deploying perspective-dependent adversarial examples using \\textit{anamorphic art}. PHANTOM exploits geometric distortions that appear natural to humans but are misclassified with high confidence by state-of-the-art object detectors. Unlike conventional attacks, PHANTOM operates in black-box settings without model access and demonstrates strong transferability across four diverse detector architectures (YOLOv5, SSD, Faster R-CNN, and RetinaNet). Comprehensive evaluation in CARLA across varying speeds, weather conditions, and lighting scenarios shows that PHANTOM achieves over 90\\% attack success rate under optimal conditions and maintains 60-80\\% effectiveness even in degraded environments. The attack activates within 6-10 meters of the target, providing insufficient time for safe maneuvering. Beyond individual vehicle deception, PHANTOM triggers network-wide disruption in CAV systems: SUMO-OMNeT++ co-simulation demonstrates that false emergency messages propagate through V2X links, increasing Peak Age of Information by 68-89\\% and degrading safety-critical communication. These findings expose critical vulnerabilities in both perception and communication layers of CAV ecosystems.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CR",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.19711v1",
    "published_date": "2025-12-15 06:05:38 UTC",
    "updated_date": "2025-12-15 06:05:38 UTC"
  },
  {
    "arxiv_id": "2512.13751v1",
    "title": "MIDUS: Memory-Infused Depth Up-Scaling",
    "authors": [
      "Taero Kim",
      "Hoyoon Byun",
      "Youngjun Choi",
      "Sungrae Park",
      "Kyungwoo Song"
    ],
    "abstract": "Scaling large language models (LLMs) demands approaches that increase capacity without incurring excessive parameter growth or inference cost. Depth Up-Scaling (DUS) has emerged as a promising strategy by duplicating layers and applying Continual Pre-training (CPT), but its reliance on feed-forward networks (FFNs) limits efficiency and attainable gains. We introduce Memory-Infused Depth Up-Scaling (MIDUS), which replaces FFNs in duplicated blocks with a head-wise memory (HML) layer. Motivated by observations that attention heads have distinct roles both across and within layers, MIDUS assigns an independent memory bank to each head, enabling head-wise retrieval and injecting information into subsequent layers while preserving head-wise functional structure. This design combines sparse memory access with head-wise representations and incorporates an efficient per-head value factorization module, thereby relaxing the usual efficiency-performance trade-off. Across our CPT experiments, MIDUS exhibits robust performance improvements over strong DUS baselines while maintaining a highly efficient parameter footprint. Our findings establish MIDUS as a compelling and resource-efficient alternative to conventional FFN replication for depth up-scaling by leveraging its head-wise memory design.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.13751v1",
    "published_date": "2025-12-15 05:50:45 UTC",
    "updated_date": "2025-12-15 05:50:45 UTC"
  },
  {
    "arxiv_id": "2512.12997v1",
    "title": "Calibrating Uncertainty for Zero-Shot Adversarial CLIP",
    "authors": [
      "Wenjing lu",
      "Zerui Tao",
      "Dongping Zhang",
      "Yuning Qiu",
      "Yang Yang",
      "Qibin Zhao"
    ],
    "abstract": "CLIP delivers strong zero-shot classification but remains highly vulnerable to adversarial attacks. Previous work of adversarial fine-tuning largely focuses on matching the predicted logits between clean and adversarial examples, which overlooks uncertainty calibration and may degrade the zero-shot generalization. A common expectation in reliable uncertainty estimation is that predictive uncertainty should increase as inputs become more difficult or shift away from the training distribution. However, we frequently observe the opposite in the adversarial setting: perturbations not only degrade accuracy but also suppress uncertainty, leading to severe miscalibration and unreliable over-confidence. This overlooked phenomenon highlights a critical reliability gap beyond robustness. To bridge this gap, we propose a novel adversarial fine-tuning objective for CLIP considering both prediction accuracy and uncertainty alignments. By reparameterizing the output of CLIP as the concentration parameter of a Dirichlet distribution, we propose a unified representation that captures relative semantic structure and the magnitude of predictive confidence. Our objective aligns these distributions holistically under perturbations, moving beyond single-logit anchoring and restoring calibrated uncertainty. Experiments on multiple zero-shot classification benchmarks demonstrate that our approach effectively restores calibrated uncertainty and achieves competitive adversarial robustness while maintaining clean accuracy.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.12997v1",
    "published_date": "2025-12-15 05:41:08 UTC",
    "updated_date": "2025-12-15 05:41:08 UTC"
  },
  {
    "arxiv_id": "2512.13750v1",
    "title": "The algorithmic muse and the public domain: Why copyrights legal philosophy precludes protection for generative AI outputs",
    "authors": [
      "Ezieddin Elmahjub"
    ],
    "abstract": "Generative AI (GenAI) outputs are not copyrightable. This article argues why. We bypass conventional doctrinal analysis that focuses on black letter law notions of originality and authorship to re-evaluate copyright's foundational philosophy. GenAI fundamentally severs the direct human creative link to expressive form. Traditional theories utilitarian incentive, labor desert and personality fail to provide coherent justification for protection. The public domain constitutes the default baseline for intellectual creations. Those seeking copyright coverage for GenAI outputs bear the burden of proof. Granting copyright to raw GenAI outputs would not only be philosophically unsound but would also trigger an unprecedented enclosure of the digital commons, creating a legal quagmire and stifling future innovation. The paper advocates for a clear distinction: human creative contributions to AI-generated works may warrant protection, but the raw algorithmic output should remain in the public domain.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "9 pages, two figures",
    "pdf_url": "https://arxiv.org/pdf/2512.13750v1",
    "published_date": "2025-12-15 05:39:30 UTC",
    "updated_date": "2025-12-15 05:39:30 UTC"
  },
  {
    "arxiv_id": "2512.12987v1",
    "title": "Tackling Snow-Induced Challenges: Safe Autonomous Lane-Keeping with Robust Reinforcement Learning",
    "authors": [
      "Amin Jalal Aghdasian",
      "Farzaneh Abdollahi",
      "Ali Kamali Iglie"
    ],
    "abstract": "This paper proposes two new algorithms for the lane keeping system (LKS) in autonomous vehicles (AVs) operating under snowy road conditions. These algorithms use deep reinforcement learning (DRL) to handle uncertainties and slippage. They include Action-Robust Recurrent Deep Deterministic Policy Gradient (AR-RDPG) and end-to-end Action-Robust convolutional neural network Attention Deterministic Policy Gradient (AR-CADPG), two action-robust approaches for decision-making. In the AR-RDPG method, within the perception layer, camera images are first denoised using multi-scale neural networks. Then, the centerline coefficients are extracted by a pre-trained deep convolutional neural network (DCNN). These coefficients, concatenated with the driving characteristics, are used as input to the control layer. The AR-CADPG method presents an end-to-end approach in which a convolutional neural network (CNN) and an attention mechanism are integrated within a DRL framework. Both methods are first trained in the CARLA simulator and validated under various snowy scenarios. Real-world experiments on a Jetson Nano-based autonomous vehicle confirm the feasibility and stability of the learned policies. Among the two models, the AR-CADPG approach demonstrates superior path-tracking accuracy and robustness, highlighting the effectiveness of combining temporal memory, adversarial resilience, and attention mechanisms in AVs.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.12987v1",
    "published_date": "2025-12-15 05:23:23 UTC",
    "updated_date": "2025-12-15 05:23:23 UTC"
  },
  {
    "arxiv_id": "2512.13749v1",
    "title": "Comparative Evaluation of Embedding Representations for Financial News Sentiment Analysis",
    "authors": [
      "Joyjit Roy",
      "Samaresh Kumar Singh"
    ],
    "abstract": "Financial sentiment analysis enhances market understanding; however, standard natural language processing approaches encounter significant challenges when applied to small datasets. This study provides a comparative evaluation of embedding-based methods for financial news sentiment classification in resource-constrained environments. Word2Vec, GloVe, and sentence transformer representations are evaluated in combination with gradient boosting on manually labeled headlines. Experimental results identify a substantial gap between validation and test performance, with models performing worse than trivial baselines despite strong validation metrics. The analysis demonstrates that pretrained embeddings yield diminishing returns below a critical data sufficiency threshold, and that small validation sets contribute to overfitting during model selection. Practical application is illustrated through weekly sentiment aggregation and narrative summarization for market monitoring workflows. The findings offer empirical evidence that embedding quality alone cannot address fundamental data scarcity in sentiment classification. For practitioners operating with limited resources, the results indicate the need to consider alternative approaches such as few-shot learning, data augmentation, or lexicon-enhanced hybrid methods when labeled samples are scarce.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CE",
      "cs.CY",
      "cs.SE"
    ],
    "primary_category": "cs.LG",
    "comment": "6 pages, 2 figures. Submitted to IEEE IATMSI-2026 (Track: AI, IoT and Computer Vision Enabled Technologies)",
    "pdf_url": "https://arxiv.org/pdf/2512.13749v1",
    "published_date": "2025-12-15 04:52:30 UTC",
    "updated_date": "2025-12-15 04:52:30 UTC"
  },
  {
    "arxiv_id": "2512.12970v1",
    "title": "Towards Open Standards for Systemic Complexity in Digital Forensics",
    "authors": [
      "Paola Di Maio"
    ],
    "abstract": "The intersection of artificial intelligence (AI) and digital forensics (DF) is becoming increasingly complex, ubiquitous, and pervasive, with overlapping techniques and technologies being adopted in all types of scientific and technical inquiry. Despite incredible advances, forensic sciences are not exempt from errors and remain vulnerable to fallibility. To mitigate the limitations of errors in DF, the systemic complexity is identified and addressed with the adoption of human-readable artifacts and open standards. A DF AI model schema based on the state of the art is outlined.",
    "categories": [
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.12970v1",
    "published_date": "2025-12-15 04:18:56 UTC",
    "updated_date": "2025-12-15 04:18:56 UTC"
  },
  {
    "arxiv_id": "2512.12950v1",
    "title": "Building from Scratch: A Multi-Agent Framework with Human-in-the-Loop for Multilingual Legal Terminology Mapping",
    "authors": [
      "Lingyi Meng",
      "Maolin Liu",
      "Hao Wang",
      "Yilan Cheng",
      "Qi Yang",
      "Idlkaid Mohanmmed"
    ],
    "abstract": "Accurately mapping legal terminology across languages remains a significant challenge, especially for language pairs like Chinese and Japanese, which share a large number of homographs with different meanings. Existing resources and standardized tools for these languages are limited. To address this, we propose a human-AI collaborative approach for building a multilingual legal terminology database, based on a multi-agent framework. This approach integrates advanced large language models and legal domain experts throughout the entire process-from raw document preprocessing, article-level alignment, to terminology extraction, mapping, and quality assurance. Unlike a single automated pipeline, our approach places greater emphasis on how human experts participate in this multi-agent system. Humans and AI agents take on different roles: AI agents handle specific, repetitive tasks, such as OCR, text segmentation, semantic alignment, and initial terminology extraction, while human experts provide crucial oversight, review, and supervise the outputs with contextual knowledge and legal judgment. We tested the effectiveness of this framework using a trilingual parallel corpus comprising 35 key Chinese statutes, along with their English and Japanese translations. The experimental results show that this human-in-the-loop, multi-agent workflow not only improves the precision and consistency of multilingual legal terminology mapping but also offers greater scalability compared to traditional manual methods.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "43 pages, 6 fingures, accepted in Artificial Intelligence and Law (2025)",
    "pdf_url": "https://arxiv.org/pdf/2512.12950v1",
    "published_date": "2025-12-15 03:29:21 UTC",
    "updated_date": "2025-12-15 03:29:21 UTC"
  },
  {
    "arxiv_id": "2512.17946v1",
    "title": "Let the Model Learn to Feel: Mode-Guided Tonality Injection for Symbolic Music Emotion Recognition",
    "authors": [
      "Haiying Xia",
      "Zhongyi Huang",
      "Yumei Tan",
      "Shuxiang Song"
    ],
    "abstract": "Music emotion recognition is a key task in symbolic music understanding (SMER). Recent approaches have shown promising results by fine-tuning large-scale pre-trained models (e.g., MIDIBERT, a benchmark in symbolic music understanding) to map musical semantics to emotional labels. While these models effectively capture distributional musical semantics, they often overlook tonal structures, particularly musical modes, which play a critical role in emotional perception according to music psychology. In this paper, we investigate the representational capacity of MIDIBERT and identify its limitations in capturing mode-emotion associations. To address this issue, we propose a Mode-Guided Enhancement (MoGE) strategy that incorporates psychological insights on mode into the model. Specifically, we first conduct a mode augmentation analysis, which reveals that MIDIBERT fails to effectively encode emotion-mode correlations. We then identify the least emotion-relevant layer within MIDIBERT and introduce a Mode-guided Feature-wise linear modulation injection (MoFi) framework to inject explicit mode features, thereby enhancing the model's capability in emotional representation and inference. Extensive experiments on the EMOPIA and VGMIDI datasets demonstrate that our mode injection strategy significantly improves SMER performance, achieving accuracies of 75.2% and 59.1%, respectively. These results validate the effectiveness of mode-guided modeling in symbolic music emotion recognition.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.MM"
    ],
    "primary_category": "cs.SD",
    "comment": "Accepted by AAAI 2026",
    "pdf_url": "https://arxiv.org/pdf/2512.17946v1",
    "published_date": "2025-12-15 03:27:35 UTC",
    "updated_date": "2025-12-15 03:27:35 UTC"
  },
  {
    "arxiv_id": "2512.13747v1",
    "title": "Why Text Prevails: Vision May Undermine Multimodal Medical Decision Making",
    "authors": [
      "Siyuan Dai",
      "Lunxiao Li",
      "Kun Zhao",
      "Eardi Lila",
      "Paul K. Crane",
      "Heng Huang",
      "Dongkuan Xu",
      "Haoteng Tang",
      "Liang Zhan"
    ],
    "abstract": "With the rapid progress of large language models (LLMs), advanced multimodal large language models (MLLMs) have demonstrated impressive zero-shot capabilities on vision-language tasks. In the biomedical domain, however, even state-of-the-art MLLMs struggle with basic Medical Decision Making (MDM) tasks. We investigate this limitation using two challenging datasets: (1) three-stage Alzheimer's disease (AD) classification (normal, mild cognitive impairment, dementia), where category differences are visually subtle, and (2) MIMIC-CXR chest radiograph classification with 14 non-mutually exclusive conditions. Our empirical study shows that text-only reasoning consistently outperforms vision-only or vision-text settings, with multimodal inputs often performing worse than text alone. To mitigate this, we explore three strategies: (1) in-context learning with reason-annotated exemplars, (2) vision captioning followed by text-only inference, and (3) few-shot fine-tuning of the vision tower with classification supervision. These findings reveal that current MLLMs lack grounded visual understanding and point to promising directions for improving multimodal decision making in healthcare.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted by ICDM 2025 the Workshop on Synergy of AI and Multimodal Biomedical Data Mining",
    "pdf_url": "https://arxiv.org/pdf/2512.13747v1",
    "published_date": "2025-12-15 03:09:31 UTC",
    "updated_date": "2025-12-15 03:09:31 UTC"
  },
  {
    "arxiv_id": "2512.14754v1",
    "title": "Revisiting the Reliability of Language Models in Instruction-Following",
    "authors": [
      "Jianshuo Dong",
      "Yutong Zhang",
      "Yan Liu",
      "Zhenyu Zhong",
      "Tao Wei",
      "Chao Zhang",
      "Han Qiu"
    ],
    "abstract": "Advanced LLMs have achieved near-ceiling instruction-following accuracy on benchmarks such as IFEval. However, these impressive scores do not necessarily translate to reliable services in real-world use, where users often vary their phrasing, contextual framing, and task formulations. In this paper, we study nuance-oriented reliability: whether models exhibit consistent competence across cousin prompts that convey analogous user intents but with subtle nuances. To quantify this, we introduce a new metric, reliable@k, and develop an automated pipeline that generates high-quality cousin prompts via data augmentation. Building upon this, we construct IFEval++ for systematic evaluation. Across 20 proprietary and 26 open-source LLMs, we find that current models exhibit substantial insufficiency in nuance-oriented reliability -- their performance can drop by up to 61.8% with nuanced prompt modifications. What's more, we characterize it and explore three potential improvement recipes. Our findings highlight nuance-oriented reliability as a crucial yet underexplored next step toward more dependable and trustworthy LLM behavior. Our code and benchmark are accessible: https://github.com/jianshuod/IFEval-pp.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.SE",
    "comment": "Preprint",
    "pdf_url": "https://arxiv.org/pdf/2512.14754v1",
    "published_date": "2025-12-15 02:57:55 UTC",
    "updated_date": "2025-12-15 02:57:55 UTC"
  },
  {
    "arxiv_id": "2512.12936v1",
    "title": "Content Adaptive based Motion Alignment Framework for Learned Video Compression",
    "authors": [
      "Tiange Zhang",
      "Xiandong Meng",
      "Siwei Ma"
    ],
    "abstract": "Recent advances in end-to-end video compression have shown promising results owing to their unified end-to-end learning optimization. However, such generalized frameworks often lack content-specific adaptation, leading to suboptimal compression performance. To address this, this paper proposes a content adaptive based motion alignment framework that improves performance by adapting encoding strategies to diverse content characteristics. Specifically, we first introduce a two-stage flow-guided deformable warping mechanism that refines motion compensation with coarse-to-fine offset prediction and mask modulation, enabling precise feature alignment. Second, we propose a multi-reference quality aware strategy that adjusts distortion weights based on reference quality, and applies it to hierarchical training to reduce error propagation. Third, we integrate a training-free module that downsamples frames by motion magnitude and resolution to obtain smooth motion estimation. Experimental results on standard test datasets demonstrate that our framework CAMA achieves significant improvements over state-of-the-art Neural Video Compression models, achieving a 24.95% BD-rate (PSNR) savings over our baseline model DCVC-TCM, while also outperforming reproduced DCVC-DC and traditional codec HM-16.25.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted to Data Compression Conference (DCC) 2026 as a poster paper",
    "pdf_url": "https://arxiv.org/pdf/2512.12936v1",
    "published_date": "2025-12-15 02:51:47 UTC",
    "updated_date": "2025-12-15 02:51:47 UTC"
  },
  {
    "arxiv_id": "2512.12935v1",
    "title": "Unified Interactive Multimodal Moment Retrieval via Cascaded Embedding-Reranking and Temporal-Aware Score Fusion",
    "authors": [
      "Toan Le Ngo Thanh",
      "Phat Ha Huu",
      "Tan Nguyen Dang Duy",
      "Thong Nguyen Le Minh",
      "Anh Nguyen Nhu Tinh"
    ],
    "abstract": "The exponential growth of video content has created an urgent need for efficient multimodal moment retrieval systems. However, existing approaches face three critical challenges: (1) fixed-weight fusion strategies fail across cross modal noise and ambiguous queries, (2) temporal modeling struggles to capture coherent event sequences while penalizing unrealistic gaps, and (3) systems require manual modality selection, reducing usability. We propose a unified multimodal moment retrieval system with three key innovations. First, a cascaded dual-embedding pipeline combines BEIT-3 and SigLIP for broad retrieval, refined by BLIP-2 based reranking to balance recall and precision. Second, a temporal-aware scoring mechanism applies exponential decay penalties to large temporal gaps via beam search, constructing coherent event sequences rather than isolated frames. Third, Agent-guided query decomposition (GPT-4o) automatically interprets ambiguous queries, decomposes them into modality specific sub-queries (visual/OCR/ASR), and performs adaptive score fusion eliminating manual modality selection. Qualitative analysis demonstrates that our system effectively handles ambiguous queries, retrieves temporally coherent sequences, and dynamically adapts fusion strategies, advancing interactive moment search capabilities.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted at AAAI Workshop 2026",
    "pdf_url": "https://arxiv.org/pdf/2512.12935v1",
    "published_date": "2025-12-15 02:50:43 UTC",
    "updated_date": "2025-12-15 02:50:43 UTC"
  },
  {
    "arxiv_id": "2512.12932v1",
    "title": "Investigating Data Pruning for Pretraining Biological Foundation Models at Scale",
    "authors": [
      "Yifan Wu",
      "Jiyue Jiang",
      "Xichen Ye",
      "Yiqi Wang",
      "Chang Zhou",
      "Yitao Xu",
      "Jiayang Chen",
      "He Hu",
      "Weizhong Zhang",
      "Cheng Jin",
      "Jiao Yuan",
      "Yu Li"
    ],
    "abstract": "Biological foundation models (BioFMs), pretrained on large-scale biological sequences, have recently shown strong potential in providing meaningful representations for diverse downstream bioinformatics tasks. However, such models often rely on millions to billions of training sequences and billions of parameters, resulting in prohibitive computational costs and significant barriers to reproducibility and accessibility, particularly for academic labs. To address these challenges, we investigate the feasibility of data pruning for BioFM pretraining and propose a post-hoc influence-guided data pruning framework tailored to biological domains. Our approach introduces a subset-based self-influence formulation that enables efficient estimation of sample importance at low computational cost, and builds upon it two simple yet effective selection strategies, namely Top-k Influence (Top I) and Coverage-Centric Influence (CCI). We empirically validate our method on two representative BioFMs, RNA-FM and ESM-C. For RNA, our framework consistently outperforms random selection baselines under an extreme pruning rate of over 99 percent, demonstrating its effectiveness. Furthermore, we show the generalizability of our framework on protein-related tasks using ESM-C. In particular, our coreset even outperforms random subsets that are ten times larger in both RNA and protein settings, revealing substantial redundancy in biological sequence datasets. These findings underscore the potential of influence-guided data pruning to substantially reduce the computational cost of BioFM pretraining, paving the way for more efficient, accessible, and sustainable biological AI research.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CE"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted by AAAI 2026",
    "pdf_url": "https://arxiv.org/pdf/2512.12932v1",
    "published_date": "2025-12-15 02:42:52 UTC",
    "updated_date": "2025-12-15 02:42:52 UTC"
  },
  {
    "arxiv_id": "2512.13745v1",
    "title": "A Spatio-Temporal Hybrid Quantum-Classical Graph Convolutional Neural Network Approach for Urban Taxi Destination Prediction",
    "authors": [
      "Xiuying Zhang",
      "Qinsheng Zhu",
      "Xiaodong Xing"
    ],
    "abstract": "We propose a Hybrid Spatio-Temporal Quantum Graph Convolutional Network (H-STQGCN) algorithm by combining the strengths of quantum computing and classical deep learning to predict the taxi destination within urban road networks. Our algorithm consists of two branches: spatial processing and time evolution. Regarding the spatial processing, the classical module encodes the local topological features of the road network based on the GCN method, and the quantum module is designed to map graph features onto parameterized quantum circuits through a differentiable pooling layer. The time evolution is solved by integrating multi-source contextual information and capturing dynamic trip dependencies on the classical TCN theory. Finally, our experimental results demonstrate that the proposed algorithm outperforms the current methods in terms of prediction accuracy and stability, validating the unique advantages of the quantum-enhanced mechanism in capturing high-dimensional spatial dependencies.",
    "categories": [
      "quant-ph",
      "cs.AI"
    ],
    "primary_category": "quant-ph",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.13745v1",
    "published_date": "2025-12-15 02:31:17 UTC",
    "updated_date": "2025-12-15 02:31:17 UTC"
  },
  {
    "arxiv_id": "2512.12929v1",
    "title": "MADTempo: An Interactive System for Multi-Event Temporal Video Retrieval with Query Augmentation",
    "authors": [
      "Huu-An Vu",
      "Van-Khanh Mai",
      "Trong-Tam Nguyen",
      "Quang-Duc Dam",
      "Tien-Huy Nguyen",
      "Thanh-Huong Le"
    ],
    "abstract": "The rapid expansion of video content across online platforms has accelerated the need for retrieval systems capable of understanding not only isolated visual moments but also the temporal structure of complex events. Existing approaches often fall short in modeling temporal dependencies across multiple events and in handling queries that reference unseen or rare visual concepts. To address these challenges, we introduce MADTempo, a video retrieval framework developed by our team, AIO_Trinh, that unifies temporal search with web-scale visual grounding. Our temporal search mechanism captures event-level continuity by aggregating similarity scores across sequential video segments, enabling coherent retrieval of multi-event queries. Complementarily, a Google Image Search-based fallback module expands query representations with external web imagery, effectively bridging gaps in pretrained visual embeddings and improving robustness against out-of-distribution (OOD) queries. Together, these components advance the temporal reasoning and generalization capabilities of modern video retrieval systems, paving the way for more semantically aware and adaptive retrieval across large-scale video corpora.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.12929v1",
    "published_date": "2025-12-15 02:25:46 UTC",
    "updated_date": "2025-12-15 02:25:46 UTC"
  },
  {
    "arxiv_id": "2512.13744v1",
    "title": "Toward Noise-Aware Audio Deepfake Detection: Survey, SNR-Benchmarks, and Practical Recipes",
    "authors": [
      "Udayon Sen",
      "Alka Luqman",
      "Anupam Chattopadhyay"
    ],
    "abstract": "Deepfake audio detection has progressed rapidly with strong pre-trained encoders (e.g., WavLM, Wav2Vec2, MMS). However, performance in realistic capture conditions - background noise (domestic/office/transport), room reverberation, and consumer channels - often lags clean-lab results. We survey and evaluate robustness for state-of-the-art audio deepfake detection models and present a reproducible framework that mixes MS-SNSD noises with ASVspoof 2021 DF utterances to evaluate under controlled signal-to-noise ratios (SNRs). SNR is a measured proxy for noise severity used widely in speech; it lets us sweep from near-clean (35 dB) to very noisy (-5 dB) to quantify graceful degradation. We study multi-condition training and fixed-SNR testing for pretrained encoders (WavLM, Wav2Vec2, MMS), reporting accuracy, ROC-AUC, and EER on binary and four-class (authenticity x corruption) tasks. In our experiments, finetuning reduces EER by 10-15 percentage points at 10-0 dB SNR across backbones.",
    "categories": [
      "cs.SD",
      "cs.AI"
    ],
    "primary_category": "cs.SD",
    "comment": "6 pages",
    "pdf_url": "https://arxiv.org/pdf/2512.13744v1",
    "published_date": "2025-12-15 02:22:37 UTC",
    "updated_date": "2025-12-15 02:22:37 UTC"
  },
  {
    "arxiv_id": "2512.12921v1",
    "title": "Cisco Integrated AI Security and Safety Framework Report",
    "authors": [
      "Amy Chang",
      "Tiffany Saade",
      "Sanket Mendapara",
      "Adam Swanda",
      "Ankit Garg"
    ],
    "abstract": "Artificial intelligence (AI) systems are being readily and rapidly adopted, increasingly permeating critical domains: from consumer platforms and enterprise software to networked systems with embedded agents. While this has unlocked potential for human productivity gains, the attack surface has expanded accordingly: threats now span content safety failures (e.g., harmful or deceptive outputs), model and data integrity compromise (e.g., poisoning, supply-chain tampering), runtime manipulations (e.g., prompt injection, tool and agent misuse), and ecosystem risks (e.g., orchestration abuse, multi-agent collusion). Existing frameworks such as MITRE ATLAS, National Institute of Standards and Technology (NIST) AI 100-2 Adversarial Machine Learning (AML) taxonomy, and OWASP Top 10s for Large Language Models (LLMs) and Agentic AI Applications provide valuable viewpoints, but each covers only slices of this multi-dimensional space.\n  This paper presents Cisco's Integrated AI Security and Safety Framework (\"AI Security Framework\"), a unified, lifecycle-aware taxonomy and operationalization framework that can be used to classify, integrate, and operationalize the full range of AI risks. It integrates AI security and AI safety across modalities, agents, pipelines, and the broader ecosystem. The AI Security Framework is designed to be practical for threat identification, red-teaming, risk prioritization, and it is comprehensive in scope and can be extensible to emerging deployments in multimodal contexts, humanoids, wearables, and sensory infrastructures. We analyze gaps in prevailing frameworks, discuss design principles for our framework, and demonstrate how the taxonomy provides structure for understanding how modern AI systems fail, how adversaries exploit these failures, and how organizations can build defenses across the AI lifecycle that evolve alongside capability advancements.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.12921v1",
    "published_date": "2025-12-15 02:12:12 UTC",
    "updated_date": "2025-12-15 02:12:12 UTC"
  },
  {
    "arxiv_id": "2512.12918v1",
    "title": "Satisfiability Modulo Theory Meets Inductive Logic Programming",
    "authors": [
      "Nijesh Upreti",
      "Vaishak Belle"
    ],
    "abstract": "Inductive Logic Programming (ILP) provides interpretable rule learning in relational domains, yet remains limited in its ability to induce and reason with numerical constraints. Classical ILP systems operate over discrete predicates and typically rely on discretisation or hand-crafted numerical predicates, making it difficult to infer thresholds or arithmetic relations that must hold jointly across examples. Recent work has begun to address these limitations through tighter integrations of ILP with Satisfiability Modulo Theories (SMT) or specialised numerical inference mechanisms. In this paper we investigate a modular alternative that couples the ILP system PyGol with the SMT solver Z3. Candidate clauses proposed by PyGol are interpreted as quantifier-free formulas over background theories such as linear or nonlinear real arithmetic, allowing numerical parameters to be instantiated and verified by the SMT solver while preserving ILP's declarative relational bias. This supports the induction of hybrid rules that combine symbolic predicates with learned numerical constraints, including thresholds, intervals, and multi-literal arithmetic relations. We formalise this SMT-ILP setting and evaluate it on a suite of synthetic datasets designed to probe linear, relational, nonlinear, and multi-hop reasoning. The results illustrate how a modular SMT-ILP architecture can extend the expressivity of symbolic rule learning, complementing prior numerical ILP approaches while providing a flexible basis for future extensions toward richer theory-aware induction.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.12918v1",
    "published_date": "2025-12-15 02:08:32 UTC",
    "updated_date": "2025-12-15 02:08:32 UTC"
  },
  {
    "arxiv_id": "2512.12914v1",
    "title": "CTIGuardian: A Few-Shot Framework for Mitigating Privacy Leakage in Fine-Tuned LLMs",
    "authors": [
      "Shashie Dilhara Batan Arachchige",
      "Benjamin Zi Hao Zhao",
      "Hassan Jameel Asghar",
      "Dinusha Vatsalan",
      "Dali Kaafar"
    ],
    "abstract": "Large Language Models (LLMs) are often fine-tuned to adapt their general-purpose knowledge to specific tasks and domains such as cyber threat intelligence (CTI). Fine-tuning is mostly done through proprietary datasets that may contain sensitive information. Owners expect their fine-tuned model to not inadvertently leak this information to potentially adversarial end users. Using CTI as a use case, we demonstrate that data-extraction attacks can recover sensitive information from fine-tuned models on CTI reports, underscoring the need for mitigation. Retraining the full model to eliminate this leakage is computationally expensive and impractical. We propose an alternative approach, which we call privacy alignment, inspired by safety alignment in LLMs. Just like safety alignment teaches the model to abide by safety constraints through a few examples, we enforce privacy alignment through few-shot supervision, integrating a privacy classifier and a privacy redactor, both handled by the same underlying LLM. We evaluate our system, called CTIGuardian, using GPT-4o mini and Mistral-7B Instruct models, benchmarking against Presidio, a named entity recognition (NER) baseline. Results show that CTIGuardian provides a better privacy-utility trade-off than NER based models. While we demonstrate its effectiveness on a CTI use case, the framework is generic enough to be applicable to other sensitive domains.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "Accepted at the 18th Cybersecurity Experimentation and Test Workshop (CSET), in conjunction with ACSAC 2025",
    "pdf_url": "https://arxiv.org/pdf/2512.12914v1",
    "published_date": "2025-12-15 01:59:14 UTC",
    "updated_date": "2025-12-15 01:59:14 UTC"
  },
  {
    "arxiv_id": "2512.12888v1",
    "title": "Meta-GPT: Decoding the Metasurface Genome with Generative Artificial Intelligence",
    "authors": [
      "David Dang",
      "Stuart Love",
      "Meena Salib",
      "Quynh Dang",
      "Samuel Rothfarb",
      "Mysk Alnatour",
      "Andrew Salij",
      "Hou-Tong Chen",
      "Ho Wai",
      "Lee",
      "Wilton J. M. Kort-Kamp"
    ],
    "abstract": "Advancing artificial intelligence for physical sciences requires representations that are both interpretable and compatible with the underlying laws of nature. We introduce METASTRINGS, a symbolic language for photonics that expresses nanostructures as textual sequences encoding materials, geometries, and lattice configurations. Analogous to molecular textual representations in chemistry, METASTRINGS provides a framework connecting human interpretability with computational design by capturing the structural hierarchy of photonic metasurfaces. Building on this representation, we develop Meta-GPT, a foundation transformer model trained on METASTRINGS and finetuned with physics-informed supervised, reinforcement, and chain-of-thought learning. Across various design tasks, the model achieves <3% mean-squared spectral error and maintains >98% syntactic validity, generating diverse metasurface prototypes whose experimentally measured optical responses match their target spectra. These results demonstrate that Meta-GPT can learn the compositional rules of light-matter interactions through METASTRINGS, laying a rigorous foundation for AI-driven photonics and representing an important step toward a metasurface genome project.",
    "categories": [
      "physics.optics",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "physics.optics",
    "comment": "Keywords: Physics-informed machine learning; Transformer models; Reinforcement learning; Chain-of-thought reasoning; Metasurfaces; Nanophotonics; Inverse design",
    "pdf_url": "https://arxiv.org/pdf/2512.12888v1",
    "published_date": "2025-12-15 00:09:14 UTC",
    "updated_date": "2025-12-15 00:09:14 UTC"
  }
]