{
  "date": "2024-01-30",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-01-30 的 arXiv 中文 TLDR 快报！\n\n今天的 arXiv 论文主要聚焦于 AI 和大型语言模型 (LLMs) 的创新应用、安全挑战以及跨领域扩展，如视频生成、强化学习和解释性 AI，同时涉及一些物理模拟和多模态模型的进展，其中令人印象深刻的是 LLMs 在天气预报和视频生成中的潜力，以及多位知名学者如 Vijay Ganesh 和 Shinji Watanabe 的相关工作。\n\n下面，我将挑选并简要讨论今天的重点论文，先聊那些创新性强、可能引发话题的文章（如 LLMs 的安全和应用），并将相关主题归类。其他较常规或次要论文（如一些算法优化或特定领域小改进）将快速掠过，只列出标题和核心点，以控制篇幅。\n\n### LLMs 的安全与解释性\n- **检测 LLM 辅助写作：Identifying False Content and Hate Speech in Sinhala YouTube Videos by Analyzing the Audio (英文)**  \n  这篇论文探讨了在 YouTube 视频中检测假信息和仇恨言论的方法，使用音频分析和 Whisper 模型进行转录，结合 BERT 变体实现高精度分类。主要贡献：提出一个多模态框架，F1 分数达 0.856，显著提升了针对非英语（如 Sinhala）内容的检测能力，强调了 LLM 在社交媒体内容审核中的实际应用潜力。\n\n- **鲁棒提示优化以防御语言模型攻击：Robust Prompt Optimization for Defending Language Models Against Jailbreaking Attacks (英文)**  \n  作者包括 Yang Liu 和 Yaowen Zheng，这篇工作针对 LLMs 的越狱攻击提出 RPO 框架，通过优化提示减少攻击成功率。主要发现：RPO 在 JailbreakBench 上将 GPT-4 的攻击成功率降低至 6%，提供了一种高效的防御机制，突出了 LLM 安全性的热门话题。\n\n- **LLMs 在软件渗透测试中的初步研究：A Preliminary Study on Using Large Language Models in Software Pentesting (英文)**  \n  由 Vijay Ganesh 等知名学者发布，探讨 LLMs 在检测软件漏洞中的潜力。主要贡献：通过提示工程和 OWASP 数据集，LLMs 模型如 Gemini-pro 和 GPT-4 在测试集上超越传统工具 SonarQube，提升了 AI 在安全领域的实用性。\n\n相关论文如 \"Proactive Detection of Voice Cloning\" 等也涉及 AI 生成内容的安全，但它们更侧重特定应用（如语音克隆检测），核心是使用水印技术降低篡改风险，我这里快速掠过：这篇提出 AudioSeal 框架，提升了语音生成的安全性，F1 分数和鲁棒性均有提升。\n\n### LLMs 的应用与扩展\n- **LLMs 在经济决策预测中的潜力：Can LLMs Replace Economic Choice Prediction Labs? The Case of Language-based Persuasion Games (英文)**  \n  这篇论文测试 LLMs 是否能替代实验经济学中的人类决策预测，使用 GPT 模型训练数据。主要发现：在说服游戏中，LLMs 生成的数据能预测人类行为，甚至超越真实数据，F1 分数更高，展示了 LLMs 在社会科学中的扩展潜力。\n\n- **多专家视觉语言模型：MouSi: Poly-Visual-Expert Vision-Language Models (英文)**  \n  作者包括 Yu-Gang Jiang 和 Xuanjing Huang，提出一个集成多专家（如图像匹配和 OCR）的视觉语言模型。主要贡献：通过融合网络和位置编码优化，提升了多模态任务的性能，如图像生成和工具使用，适用于复杂视觉任务。\n\n- **用于创意写作的 Foundation 模型：Weaver: Foundation Models for Creative Writing (英文)**  \n  这篇工作由一组作者如 Yuchen Eleanor Jiang 开发，介绍 Weaver 系列模型（从 1.8B 到 34B 参数）。主要发现：Weaver 在写作任务中超越 GPT-4，支持检索增强生成和个性化写作，强调了 LLM 在内容创作中的高效性。\n\n其他如 \"When Large Language Models Meet Vector Databases\" 探讨 LLMs 与向量数据库的整合，解决幻觉和内存问题；\"Arrows of Time for Large Language Models\" 分析 LLMs 的时间不对称性，这些是 LLMs 基础研究的延续，我快速总结：前者提出整合框架提升 LLM 功能，后者理论解释了信息不对称，均有潜在影响但不需深挖。\n\n### 其他创新领域\n- **视频生成和评估：STREAM: Spatio-TempoRal Evaluation and Analysis Metric for Video Generative Models (英文)**  \n  这篇论文提出 STREAM 指标，用于评估视频生成模型的空间和时间质量。主要贡献：STREAM 独立评估多模态视频，提升了生成模型如 Stable Diffusion 的分析精度，F1 分数和鲁棒性优于传统指标。\n\n- **AI 在天气预报中的应用：Improving Global Weather and Ocean Wave Forecast with Large Artificial Intelligence Models (英文)**  \n  作者包括 Jing-Jia Luo，构建大型 AI 模型预测全球天气和海浪。主要发现：结合传统数值模型，AI 框架提升了预测准确性和效率，适用于海洋和大气科学，展示了 AI 在物理模拟中的话题潜力。\n\n其他论文如 \"BlockFusion: Expandable 3D Scene Generation using Latent Tri-plane Extrapolation\" 创新 3D 场景生成；\"Diffusion model for relational inference\" 应用于复杂系统关系推断；这些是图像和强化学习领域的进展，我快速掠过：前者提出可扩展生成框架，提升 3D 场景质量；后者使用扩散模型优化关系学习，均有技术创新但较为专业。\n\n剩余论文（如算法优化、特定任务的细微改进）数量较多，我仅列出标题并简要概述核心点，以节省篇幅。例如：\n- **嵌套极化码构建：Nested Construction of Polar Codes via Transformers (英文)** – 使用 Transformer 优化编码，提升通信效率。\n- **LLMs 在纳米生物学中的实体识别：NanoNER: Named Entity Recognition for nanobiology using experts' knowledge and distant supervision (英文)** – 提出远程监督框架，F1 分数达 0.98，用于生物实体提取。\n- **其他如 \"EvoMerge: Neuroevolution for Large Language Models\" 和 \"ShaRP: A Novel Feature Importance Framework for Ranking\" 等** – 分别探讨 LLM 进化优化和排名特征重要性，但这些更偏向技术细节，我不深入。\n\n总之，今天的论文突显了 AI 和 LLMs 的多样性与挑战，LLMs 在安全和应用领域的进展最值得关注。希望这份快报能帮您快速筛选感兴趣的文章！如果有具体领域需求，欢迎反馈。",
  "papers": [
    {
      "arxiv_id": "2401.17505v4",
      "title": "Arrows of Time for Large Language Models",
      "title_zh": "大型语言模型的时间之箭",
      "authors": [
        "Vassilis Papadopoulos",
        "Jérémie Wenger",
        "Clément Hongler"
      ],
      "abstract": "We study the probabilistic modeling performed by Autoregressive Large\nLanguage Models (LLMs) through the angle of time directionality, addressing a\nquestion first raised in (Shannon, 1951). For large enough models, we\nempirically find a time asymmetry in their ability to learn natural language: a\ndifference in the average log-perplexity when trying to predict the next token\nversus when trying to predict the previous one. This difference is at the same\ntime subtle and very consistent across various modalities (language, model\nsize, training time, ...). Theoretically, this is surprising: from an\ninformation-theoretic point of view, there should be no such difference. We\nprovide a theoretical framework to explain how such an asymmetry can appear\nfrom sparsity and computational complexity considerations, and outline a number\nof perspectives opened by our results.",
      "tldr_zh": "本研究探讨了自回归大型语言模型 (LLMs) 在时间方向性方面的概率建模，针对 Shannon 提出的问题，通过实证实验发现大型模型在预测下一个词元和上一个词元的平均 log-perplexity 之间存在微妙但一致的不对称现象，这种不对称在不同语言、模型大小和训练时间等模式下均显现。理论上，这与信息理论预期相悖，论文从稀疏性和计算复杂性角度提供了解释框架，揭示了这种不对称的潜在原因。最终，该工作为理解 LLMs 的时间不对称性打开了新视角，并为未来模型设计提供了启发。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "Corrected typos in Table 2. Added links. 12 figures, 20 pages",
      "pdf_url": "http://arxiv.org/pdf/2401.17505v4",
      "published_date": "2024-01-30 23:46:35 UTC",
      "updated_date": "2024-07-24 12:57:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:22:15.901592"
    },
    {
      "arxiv_id": "2402.01763v3",
      "title": "When Large Language Models Meet Vector Databases: A Survey",
      "title_zh": "翻译失败",
      "authors": [
        "Zhi Jing",
        "Yongye Su",
        "Yikun Han"
      ],
      "abstract": "This survey explores the synergistic potential of Large Language Models\n(LLMs) and Vector Databases (VecDBs), a burgeoning but rapidly evolving\nresearch area. With the proliferation of LLMs comes a host of challenges,\nincluding hallucinations, outdated knowledge, prohibitive commercial\napplication costs, and memory issues. VecDBs emerge as a compelling solution to\nthese issues by offering an efficient means to store, retrieve, and manage the\nhigh-dimensional vector representations intrinsic to LLM operations. Through\nthis nuanced review, we delineate the foundational principles of LLMs and\nVecDBs and critically analyze their integration's impact on enhancing LLM\nfunctionalities. This discourse extends into a discussion on the speculative\nfuture developments in this domain, aiming to catalyze further research into\noptimizing the confluence of LLMs and VecDBs for advanced data handling and\nknowledge extraction capabilities.",
      "tldr_zh": "这篇调查论文探讨了大型语言模型（LLMs）和向量数据库（VecDBs）的协同潜力，以解决LLMs面临的挑战，如hallucinations、过时知识、高商业成本和内存问题。VecDBs通过高效存储、检索和管理高维向量表示，为LLMs提供了一个关键解决方案，从而提升其数据处理和知识提取能力。论文审视了LLMs和VecDBs的基础原则，分析了它们的整合对功能优化的影响，并展望了未来发展方向，以推动该领域的进一步研究。",
      "categories": [
        "cs.DB",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.DB",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.01763v3",
      "published_date": "2024-01-30 23:35:28 UTC",
      "updated_date": "2024-11-01 03:49:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:22:28.370096"
    },
    {
      "arxiv_id": "2401.17500v3",
      "title": "LeTO: Learning Constrained Visuomotor Policy with Differentiable Trajectory Optimization",
      "title_zh": "LeTO：利用",
      "authors": [
        "Zhengtong Xu",
        "Yu She"
      ],
      "abstract": "This paper introduces LeTO, a method for learning constrained visuomotor\npolicy with differentiable trajectory optimization. Our approach integrates a\ndifferentiable optimization layer into the neural network. By formulating the\noptimization layer as a trajectory optimization problem, we enable the model to\nend-to-end generate actions in a safe and constraint-controlled fashion without\nextra modules. Our method allows for the introduction of constraint information\nduring the training process, thereby balancing the training objectives of\nsatisfying constraints, smoothing the trajectories, and minimizing errors with\ndemonstrations. This ``gray box\" method marries optimization-based safety and\ninterpretability with powerful representational abilities of neural networks.\nWe quantitatively evaluate LeTO in simulation and in the real robot. The\nresults demonstrate that LeTO performs well in both simulated and real-world\ntasks. In addition, it is capable of generating trajectories that are less\nuncertain, higher quality, and smoother compared to existing imitation learning\nmethods. Therefore, it is shown that LeTO provides a practical example of how\nto achieve the integration of neural networks with trajectory optimization. We\nrelease our code at https://github.com/ZhengtongXu/LeTO.",
      "tldr_zh": "本文提出LeTO方法，通过将可微分轨迹优化(differentiable trajectory optimization)层整合到神经网络中，实现端到端的受约束视觉运动策略(visuomotor policy)学习。该方法在训练过程中引入约束信息，平衡约束满足、轨迹光滑度和演示错误最小化，采用“灰盒”方式结合优化-based的安全性和神经网络的表示能力。在模拟和真实机器人环境中评估，LeTO表现出色，生成的轨迹不确定性更低、质量更高，并为神经网络与轨迹优化集成提供了实用示例。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.17500v3",
      "published_date": "2024-01-30 23:18:35 UTC",
      "updated_date": "2024-10-23 18:04:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:22:40.802225"
    },
    {
      "arxiv_id": "2401.17477v2",
      "title": "Detecting mental disorder on social media: a ChatGPT-augmented explainable approach",
      "title_zh": "在社交媒体上检测心理障碍：一种ChatGPT增强的可解释方法",
      "authors": [
        "Loris Belcastro",
        "Riccardo Cantini",
        "Fabrizio Marozzo",
        "Domenico Talia",
        "Paolo Trunfio"
      ],
      "abstract": "In the digital era, the prevalence of depressive symptoms expressed on social\nmedia has raised serious concerns, necessitating advanced methodologies for\ntimely detection. This paper addresses the challenge of interpretable\ndepression detection by proposing a novel methodology that effectively combines\nLarge Language Models (LLMs) with eXplainable Artificial Intelligence (XAI) and\nconversational agents like ChatGPT. In our methodology, explanations are\nachieved by integrating BERTweet, a Twitter-specific variant of BERT, into a\nnovel self-explanatory model, namely BERT-XDD, capable of providing both\nclassification and explanations via masked attention. The interpretability is\nfurther enhanced using ChatGPT to transform technical explanations into\nhuman-readable commentaries. By introducing an effective and modular approach\nfor interpretable depression detection, our methodology can contribute to the\ndevelopment of socially responsible digital platforms, fostering early\nintervention and support for mental health challenges under the guidance of\nqualified healthcare professionals.",
      "tldr_zh": "这篇论文提出了一种结合 Large Language Models (LLMs) 和 eXplainable Artificial Intelligence (XAI) 的新方法，用于在社交媒体上检测心理障碍，特别是抑郁症状。核心技术包括开发 BERT-XDD 模型，该模型基于 Twitter 专用变体 BERTweet，通过 masked attention 提供分类结果和自解释功能。进一步利用 ChatGPT 将技术解释转化为易读的评论，提升了方法的解释性和可访问性。该方法促进了负责任的数字平台发展，支持心理健康的早期干预，在专业医疗指导下提升社会支持。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG",
        "cs.SI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.17477v2",
      "published_date": "2024-01-30 22:22:55 UTC",
      "updated_date": "2025-03-10 09:32:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:22:53.715965"
    },
    {
      "arxiv_id": "2402.00076v1",
      "title": "Exploitation Strategies in Conditional Markov Chain Search: A case study on the three-index assignment problem",
      "title_zh": "翻译失败",
      "authors": [
        "Sahil Patel",
        "Daniel Karapetyan"
      ],
      "abstract": "The Conditional Markov Chain Search (CMCS) is a framework for automated\ndesign of metaheuristics for discrete combinatorial optimisation problems.\nGiven a set of algorithmic components such as hill climbers and mutations, CMCS\ndecides in which order to apply those components. The decisions are dictated by\nthe CMCS configuration that can be learnt offline. CMCS does not have an\nacceptance criterion; any moves are accepted by the framework. As a result, it\nis particularly good in exploration but is not as good at exploitation. In this\nstudy, we explore several extensions of the framework to improve its\nexploitation abilities. To perform a computational study, we applied the\nframework to the three-index assignment problem. The results of our experiments\nshowed that a two-stage CMCS is indeed superior to a single-stage CMCS.",
      "tldr_zh": "该论文探讨了 Conditional Markov Chain Search (CMCS) 框架在离散组合优化问题中的扩展策略，旨在提升其开发能力，因为原框架虽擅长探索但缺乏接受标准。研究者通过引入多种改进方法，如两阶段设计，并以三索引分配问题作为案例研究。实验结果表明，两阶段 CMCS 比单阶段 CMCS 性能更优越，为元启发式算法的自动设计提供了新见解。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "14 pages",
      "pdf_url": "http://arxiv.org/pdf/2402.00076v1",
      "published_date": "2024-01-30 22:13:46 UTC",
      "updated_date": "2024-01-30 22:13:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:23:04.368787"
    },
    {
      "arxiv_id": "2401.17461v1",
      "title": "Synthetic Dialogue Dataset Generation using LLM Agents",
      "title_zh": "翻译失败",
      "authors": [
        "Yelaman Abdullin",
        "Diego Molla-Aliod",
        "Bahadorreza Ofoghi",
        "John Yearwood",
        "Qingyang Li"
      ],
      "abstract": "Linear programming (LP) problems are pervasive in real-life applications.\nHowever, despite their apparent simplicity, an untrained user may find it\ndifficult to determine the linear model of their specific problem. We envisage\nthe creation of a goal-oriented conversational agent that will engage in\nconversation with the user to elicit all information required so that a\nsubsequent agent can generate the linear model. In this paper, we present an\napproach for the generation of sample dialogues that can be used to develop and\ntrain such a conversational agent. Using prompt engineering, we develop two\nagents that \"talk\" to each other, one acting as the conversational agent, and\nthe other acting as the user. Using a set of text descriptions of linear\nproblems from NL4Opt available to the user only, the agent and the user engage\nin conversation until the agent has retrieved all key information from the\noriginal problem description. We also propose an extrinsic evaluation of the\ndialogues by assessing how well the summaries generated by the dialogues match\nthe original problem descriptions. We conduct human and automatic evaluations,\nincluding an evaluation approach that uses GPT-4 to mimic the human evaluation\nmetrics. The evaluation results show an overall good quality of the dialogues,\nthough research is still needed to improve the quality of the GPT-4 evaluation\nmetrics. The resulting dialogues, including the human annotations of a subset,\nare available to the research community. The conversational agent used for the\ngeneration of the dialogues can be used as a baseline.",
      "tldr_zh": "本研究提出了一种使用LLM Agents生成合成对话数据集的方法，旨在帮助用户定义线性规划(LP)问题。该方法通过提示工程(prompt engineering)创建两个代理：一个扮演对话代理，另一个模拟用户，他们基于NL4Opt的线性问题描述进行互动，直至提取所有关键信息。论文还引入了外部评估机制，包括人类评估和使用GPT-4的自动评估，结果显示对话质量整体良好，但GPT-4评估指标需进一步优化。该数据集及其人类标注子集已公开，可作为训练对话代理的基线。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "GEM Workshop @ EMNLP 2023",
      "pdf_url": "http://arxiv.org/pdf/2401.17461v1",
      "published_date": "2024-01-30 21:49:30 UTC",
      "updated_date": "2024-01-30 21:49:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:23:15.300124"
    },
    {
      "arxiv_id": "2401.17459v1",
      "title": "A Preliminary Study on Using Large Language Models in Software Pentesting",
      "title_zh": "使用大语言模型进行软件渗透测试的初步研究",
      "authors": [
        "Kumar Shashwat",
        "Francis Hahn",
        "Xinming Ou",
        "Dmitry Goldgof",
        "Lawrence Hall",
        "Jay Ligatti",
        "S. Raj Rajgopalan",
        "Armin Ziaie Tabari"
      ],
      "abstract": "Large language models (LLM) are perceived to offer promising potentials for\nautomating security tasks, such as those found in security operation centers\n(SOCs). As a first step towards evaluating this perceived potential, we\ninvestigate the use of LLMs in software pentesting, where the main task is to\nautomatically identify software security vulnerabilities in source code. We\nhypothesize that an LLM-based AI agent can be improved over time for a specific\nsecurity task as human operators interact with it. Such improvement can be\nmade, as a first step, by engineering prompts fed to the LLM based on the\nresponses produced, to include relevant contexts and structures so that the\nmodel provides more accurate results. Such engineering efforts become\nsustainable if the prompts that are engineered to produce better results on\ncurrent tasks, also produce better results on future unknown tasks. To examine\nthis hypothesis, we utilize the OWASP Benchmark Project 1.2 which contains\n2,740 hand-crafted source code test cases containing various types of\nvulnerabilities. We divide the test cases into training and testing data, where\nwe engineer the prompts based on the training data (only), and evaluate the\nfinal system on the testing data. We compare the AI agent's performance on the\ntesting data against the performance of the agent without the prompt\nengineering. We also compare the AI agent's results against those from\nSonarQube, a widely used static code analyzer for security testing. We built\nand tested multiple versions of the AI agent using different off-the-shelf LLMs\n-- Google's Gemini-pro, as well as OpenAI's GPT-3.5-Turbo and GPT-4-Turbo (with\nboth chat completion and assistant APIs). The results show that using LLMs is a\nviable approach to build an AI agent for software pentesting that can improve\nthrough repeated use and prompt engineering.",
      "tldr_zh": "这篇论文初步探讨了使用 Large Language Models (LLM) 在软件渗透测试中自动识别源代码安全漏洞的可行性。研究假设通过提示工程 (prompt engineering) 和人类交互，可以逐步改进 LLM-based AI 代理的性能，并使用 OWASP Benchmark Project 1.2 的 2,740 个测试案例进行验证，将数据分为训练集和测试集。实验比较了未工程提示的 AI 代理与工程后的版本（基于 Google's Gemini-pro 和 OpenAI's GPT-3.5-Turbo/GPT-4-Turbo），结果显示改进后的代理在测试数据上表现更优，并与 SonarQube 静态代码分析器相当，证明 LLM 通过重复使用和提示工程可有效提升软件 pentesting 的准确性。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.17459v1",
      "published_date": "2024-01-30 21:42:59 UTC",
      "updated_date": "2024-01-30 21:42:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:23:29.699250"
    },
    {
      "arxiv_id": "2401.17455v1",
      "title": "Multiscale Parallel Tempering for Fast Sampling on Redistricting Plans",
      "title_zh": "多尺度平行退火用于选区划分计划的快速采样",
      "authors": [
        "Gabriel Chuang",
        "Gregory Herschlag",
        "Jonathan C. Mattingly"
      ],
      "abstract": "When auditing a redistricting plan, a persuasive method is to compare the\nplan with an ensemble of neutrally drawn redistricting plans. Ensembles are\ngenerated via algorithms that sample distributions on balanced graph\npartitions. To audit the partisan difference between the ensemble and a given\nplan, one must ensure that the non-partisan criteria are matched so that we may\nconclude that partisan differences come from bias rather than, for example,\nlevels of compactness or differences in community preservation. Certain\nsampling algorithms allow one to explicitly state the policy-based probability\ndistribution on plans, however, these algorithms have shown poor mixing times\nfor large graphs (i.e. redistricting spaces) for all but a few specialized\nmeasures. In this work, we generate a multiscale parallel tempering approach\nthat makes local moves at each scale. The local moves allow us to adopt a wide\nvariety of policy-based measures. We examine our method in the state of\nConnecticut and succeed at achieving fast mixing on a policy-based distribution\nthat has never before been sampled at this scale. Our algorithm shows promise\nto expand to a significantly wider class of measures that will (i) allow for\nmore principled and situation-based comparisons and (ii) probe for the typical\npartisan impact that policy can have on redistricting.",
      "tldr_zh": "本研究针对重划区计划（redistricting plans）的审计问题，提出了一种多尺度并行温度调节（multiscale parallel tempering）算法，以加速对平衡图分区分布的采样。该方法通过在每个尺度上进行局部移动，支持多种政策导向措施（policy-based measures），确保非党派标准（如紧凑性和社区保留）匹配，从而准确评估计划间的党派差异。在康涅狄格州的应用中，该算法实现了快速混合（fast mixing），为更原则化和情境化的比较提供可能，并有助于评估政策对重划区党派影响的典型作用。",
      "categories": [
        "physics.soc-ph",
        "cs.AI",
        "cs.SI",
        "math.PR",
        "60J10, 91G60",
        "G.3.8; E.1.3"
      ],
      "primary_category": "physics.soc-ph",
      "comment": "26 pages with appendix; 11 figures",
      "pdf_url": "http://arxiv.org/pdf/2401.17455v1",
      "published_date": "2024-01-30 21:33:05 UTC",
      "updated_date": "2024-01-30 21:33:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:23:39.600229"
    },
    {
      "arxiv_id": "2401.17443v1",
      "title": "Liquid Democracy for Low-Cost Ensemble Pruning",
      "title_zh": "翻译失败",
      "authors": [
        "Ben Armstrong",
        "Kate Larson"
      ],
      "abstract": "We argue that there is a strong connection between ensemble learning and a\ndelegative voting paradigm -- liquid democracy -- that can be leveraged to\nreduce ensemble training costs. We present an incremental training procedure\nthat identifies and removes redundant classifiers from an ensemble via\ndelegation mechanisms inspired by liquid democracy. Through both analysis and\nextensive experiments we show that this process greatly reduces the\ncomputational cost of training compared to training a full ensemble. By\ncarefully selecting the underlying delegation mechanism, weight centralization\nin the classifier population is avoided, leading to higher accuracy than some\nboosting methods. Furthermore, this work serves as an exemplar of how\nframeworks from computational social choice literature can be applied to\nproblems in nontraditional domains.",
      "tldr_zh": "该论文探讨了 ensemble learning 与 liquid democracy 之间的联系，提出了一种基于 liquid democracy 启发的增量训练过程，用于低成本的 ensemble pruning。通过委托机制识别并移除冗余分类器，该方法显著降低了训练计算成本，同时避免了权重集中问题，从而实现比某些 boosting methods 更高的准确率。此外，这项工作展示了 computational social choice 框架在非传统领域（如机器学习）的应用潜力。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.LG",
      "comment": "30 pages, 20 figures. Extended abstract to appear at AAMAS 2024",
      "pdf_url": "http://arxiv.org/pdf/2401.17443v1",
      "published_date": "2024-01-30 21:11:35 UTC",
      "updated_date": "2024-01-30 21:11:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:23:52.724513"
    },
    {
      "arxiv_id": "2401.17441v1",
      "title": "Explaining Predictive Uncertainty by Exposing Second-Order Effects",
      "title_zh": "通过揭示二阶效应解释预测不确定性",
      "authors": [
        "Florian Bley",
        "Sebastian Lapuschkin",
        "Wojciech Samek",
        "Grégoire Montavon"
      ],
      "abstract": "Explainable AI has brought transparency into complex ML blackboxes, enabling,\nin particular, to identify which features these models use for their\npredictions. So far, the question of explaining predictive uncertainty, i.e.\nwhy a model 'doubts', has been scarcely studied. Our investigation reveals that\npredictive uncertainty is dominated by second-order effects, involving single\nfeatures or product interactions between them. We contribute a new method for\nexplaining predictive uncertainty based on these second-order effects.\nComputationally, our method reduces to a simple covariance computation over a\ncollection of first-order explanations. Our method is generally applicable,\nallowing for turning common attribution techniques (LRP, Gradient x Input,\netc.) into powerful second-order uncertainty explainers, which we call CovLRP,\nCovGI, etc. The accuracy of the explanations our method produces is\ndemonstrated through systematic quantitative evaluations, and the overall\nusefulness of our method is demonstrated via two practical showcases.",
      "tldr_zh": "本研究探讨了预测不确定性的解释问题，发现这种不确定性主要受二阶效应（second-order effects）主导，这些效应涉及单个特征或特征间的乘积交互。作者提出了一种新方法，通过对一组一阶解释进行协方差计算（covariance computation），来解释预测不确定性，该方法可将常见归因技术如LRP和Gradient x Input转化为增强版本（如CovLRP和CovGI）。实验结果显示，该方法在系统定量评估中表现出高准确性，并在两个实际案例中证明了其实用价值。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "12 pages + supplement",
      "pdf_url": "http://arxiv.org/pdf/2401.17441v1",
      "published_date": "2024-01-30 21:02:21 UTC",
      "updated_date": "2024-01-30 21:02:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:24:03.110860"
    },
    {
      "arxiv_id": "2401.17436v1",
      "title": "Difficulty Modelling in Mobile Puzzle Games: An Empirical Study on Different Methods to Combine Player Analytics and Simulated Data",
      "title_zh": "移动益智游戏中的难度建模：结合玩家分析和模拟数据的不同方法的实证研究",
      "authors": [
        "Jeppe Theiss Kristensen",
        "Paolo Burelli"
      ],
      "abstract": "Difficulty is one of the key drivers of player engagement and it is often one\nof the aspects that designers tweak most to optimise the player experience;\noperationalising it is, therefore, a crucial task for game development studios.\nA common practice consists of creating metrics out of data collected by player\ninteractions with the content; however, this allows for estimation only after\nthe content is released and does not consider the characteristics of potential\nfuture players.\n  In this article, we present a number of potential solutions for the\nestimation of difficulty under such conditions, and we showcase the results of\na comparative study intended to understand which method and which types of data\nperform better in different scenarios.\n  The results reveal that models trained on a combination of cohort statistics\nand simulated data produce the most accurate estimations of difficulty in all\nscenarios. Furthermore, among these models, artificial neural networks show the\nmost consistent results.",
      "tldr_zh": "本文通过实证研究探讨了移动益智游戏中难度建模的方法，旨在结合 player analytics 和 simulated data 来估算难度，以解决传统方法仅在内容发布后才能应用的局限性。研究比较了多种潜在解决方案，包括使用 cohort statistics 和 simulated data 训练的模型在不同场景下的性能。结果表明，这些结合数据的模型在所有场景中提供了最准确的难度估算，其中 artificial neural networks 显示出最一致的表现，为游戏设计师优化玩家体验提供了实用指导。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.17436v1",
      "published_date": "2024-01-30 20:51:42 UTC",
      "updated_date": "2024-01-30 20:51:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:24:16.472846"
    },
    {
      "arxiv_id": "2401.17435v4",
      "title": "Can LLMs Replace Economic Choice Prediction Labs? The Case of Language-based Persuasion Games",
      "title_zh": "翻译失败",
      "authors": [
        "Eilam Shapira",
        "Omer Madmon",
        "Roi Reichart",
        "Moshe Tennenholtz"
      ],
      "abstract": "Human choice prediction in economic contexts is crucial for applications in\nmarketing, finance, public policy, and more. This task, however, is often\nconstrained by the difficulties in acquiring human choice data. With most\nexperimental economics studies focusing on simple choice settings, the AI\ncommunity has explored whether LLMs can substitute for humans in these\npredictions and examined more complex experimental economics settings. However,\na key question remains: can LLMs generate training data for human choice\nprediction? We explore this in language-based persuasion games, a complex\neconomic setting involving natural language in strategic interactions. Our\nexperiments show that models trained on LLM-generated data can effectively\npredict human behavior in these games and even outperform models trained on\nactual human data.",
      "tldr_zh": "本研究探讨了大型语言模型（LLMs）是否能替代经济选择预测实验室，特别是针对language-based persuasion games（一种涉及自然语言的复杂战略互动游戏）。作者通过实验验证了LLMs生成训练数据的能力，结果显示，使用LLMs生成的数据训练的模型能有效预测人类行为，甚至在某些情况下优于基于真实人类数据的模型。这种方法为简化经济实验数据采集提供新途径，有望应用于营销、金融和公共政策等领域。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.GT",
        "cs.HC"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.17435v4",
      "published_date": "2024-01-30 20:49:47 UTC",
      "updated_date": "2024-08-14 19:23:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:24:27.332960"
    },
    {
      "arxiv_id": "2401.17434v3",
      "title": "Integrating Generative AI in Hackathons: Opportunities, Challenges, and Educational Implications",
      "title_zh": "翻译失败",
      "authors": [
        "Ramteja Sajja",
        "Carlos Erazo Ramirez",
        "Zhouyayan Li",
        "Bekir Z. Demiray",
        "Yusuf Sermet",
        "Ibrahim Demir"
      ],
      "abstract": "Hackathons have emerged as pivotal platforms in the software industry,\ndriving both innovation and skill development for organizations and students\nalike. These events enable companies to quickly prototype new ideas while\noffering students practical, hands-on learning experiences. Over time,\nhackathons have transitioned from purely competitive events to valuable\neducational tools, integrating theory with real-world problem-solving through\ncollaboration between academia and industry. The infusion of artificial\nintelligence (AI) and machine learning is now reshaping hackathons, providing\nenhanced learning opportunities while also introducing ethical challenges. This\nstudy explores the influence of generative AI on students' technological\nchoices, focusing on a case study from the 2023 University of Iowa Hackathon.\nThe findings offer insights into AI's role in these events, its educational\nimpact, and propose strategies for integrating such technologies in future\nhackathons, ensuring a balance between innovation, ethics, and educational\nvalue.",
      "tldr_zh": "该研究探讨了在 hackathons 中整合 generative AI 的机会、挑战和教育影响，强调 hackathons 作为创新和技能发展的平台如何通过 AI 增强实际学习体验。基于 2023 年 University of Iowa Hackathon 的案例研究，论文分析了 generative AI 对学生技术选择的影响，发现它提供了更丰富的学习机会，但也带来了道德挑战。最终，研究提出策略建议，以平衡创新、伦理和教育价值，确保未来 hackathons 的可持续性。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.CY",
      "comment": "9792 words, 26 pages, 12 figures",
      "pdf_url": "http://arxiv.org/pdf/2401.17434v3",
      "published_date": "2024-01-30 20:45:49 UTC",
      "updated_date": "2024-09-18 17:07:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:24:39.539162"
    },
    {
      "arxiv_id": "2401.17426v1",
      "title": "Superiority of Multi-Head Attention in In-Context Linear Regression",
      "title_zh": "多头注意力在上下文线性回归中的优越性",
      "authors": [
        "Yingqian Cui",
        "Jie Ren",
        "Pengfei He",
        "Jiliang Tang",
        "Yue Xing"
      ],
      "abstract": "We present a theoretical analysis of the performance of transformer with\nsoftmax attention in in-context learning with linear regression tasks. While\nthe existing literature predominantly focuses on the convergence of\ntransformers with single-/multi-head attention, our research centers on\ncomparing their performance. We conduct an exact theoretical analysis to\ndemonstrate that multi-head attention with a substantial embedding dimension\nperforms better than single-head attention. When the number of in-context\nexamples D increases, the prediction loss using single-/multi-head attention is\nin O(1/D), and the one for multi-head attention has a smaller multiplicative\nconstant. In addition to the simplest data distribution setting, we consider\nmore scenarios, e.g., noisy labels, local examples, correlated features, and\nprior knowledge. We observe that, in general, multi-head attention is preferred\nover single-head attention. Our results verify the effectiveness of the design\nof multi-head attention in the transformer architecture.",
      "tldr_zh": "本文通过精确理论分析，比较了 Transformer 中 single-head attention 和 multi-head attention 在 in-context linear regression 任务中的性能。结果显示，当 in-context 例子数量 D 增加时，两者预测损失均为 O(1/D)，但 multi-head attention 的乘法常数更小，尤其在较大嵌入维度下表现优越。该研究还扩展到噪声标签、局部例子、相关特征和先验知识等场景，证明 multi-head attention 总体上优于 single-head attention，从而验证了其在 Transformer 架构中的有效性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.17426v1",
      "published_date": "2024-01-30 20:29:06 UTC",
      "updated_date": "2024-01-30 20:29:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:24:52.490180"
    },
    {
      "arxiv_id": "2401.17424v1",
      "title": "Application of Neural Networks for the Reconstruction of Supernova Neutrino Energy Spectra Following Fast Neutrino Flavor Conversions",
      "title_zh": "神经网络在快速中微子味转换后重建超新星中微子能量谱的应用",
      "authors": [
        "Sajad Abbar",
        "Meng-Ru Wu",
        "Zewei Xiong"
      ],
      "abstract": "Neutrinos can undergo fast flavor conversions (FFCs) within extremely dense\nastrophysical environments such as core-collapse supernovae (CCSNe) and neutron\nstar mergers (NSMs). In this study, we explore FFCs in a \\emph{multi-energy}\nneutrino gas, revealing that when the FFC growth rate significantly exceeds\nthat of the vacuum Hamiltonian, all neutrinos (regardless of energy) share a\ncommon survival probability dictated by the energy-integrated neutrino\nspectrum. We then employ physics-informed neural networks (PINNs) to predict\nthe asymptotic outcomes of FFCs within such a multi-energy neutrino gas. These\npredictions are based on the first two moments of neutrino angular\ndistributions for each energy bin, typically available in state-of-the-art CCSN\nand NSM simulations. Our PINNs achieve errors as low as $\\lesssim6\\%$ and\n$\\lesssim 18\\%$ for predicting the number of neutrinos in the electron channel\nand the relative absolute error in the neutrino moments, respectively.",
      "tldr_zh": "本文研究了中微子在核心坍缩超新星(CCSNe)和中子星合并(NSMs)中的快速风味转换(FFCs)，发现当FFC增长率远大于真空哈密顿量时，所有能量水平的中微子共享一个由能量积分谱决定的共同存活概率。作者使用physics-informed neural networks (PINNs)来基于每个能量 bin 的中微子角分布前两个矩预测FFCs的渐进结果，这些数据通常来自先进模拟。结果显示，PINNs在预测电子通道中微子数量的错误率低至6%，而在中微子矩的相对绝对错误率低至18%。",
      "categories": [
        "astro-ph.HE",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "astro-ph.HE",
      "comment": "13 pages, 6 figures, submitted to PRD. arXiv admin note: text overlap\n  with arXiv:2311.15656",
      "pdf_url": "http://arxiv.org/pdf/2401.17424v1",
      "published_date": "2024-01-30 20:27:28 UTC",
      "updated_date": "2024-01-30 20:27:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:25:06.072154"
    },
    {
      "arxiv_id": "2401.17417v2",
      "title": "Through-Wall Imaging based on WiFi Channel State Information",
      "title_zh": "基于 WiFi 信道状态信息的穿墙成像",
      "authors": [
        "Julian Strohmayer",
        "Rafael Sterzinger",
        "Christian Stippel",
        "Martin Kampel"
      ],
      "abstract": "This work presents a seminal approach for synthesizing images from WiFi\nChannel State Information (CSI) in through-wall scenarios. Leveraging the\nstrengths of WiFi, such as cost-effectiveness, illumination invariance, and\nwall-penetrating capabilities, our approach enables visual monitoring of indoor\nenvironments beyond room boundaries and without the need for cameras. More\ngenerally, it improves the interpretability of WiFi CSI by unlocking the option\nto perform image-based downstream tasks, e.g., visual activity recognition. In\norder to achieve this crossmodal translation from WiFi CSI to images, we rely\non a multimodal Variational Autoencoder (VAE) adapted to our problem specifics.\nWe extensively evaluate our proposed methodology through an ablation study on\narchitecture configuration and a quantitative/qualitative assessment of\nreconstructed images. Our results demonstrate the viability of our method and\nhighlight its potential for practical applications.",
      "tldr_zh": "本研究提出了一种基于WiFi Channel State Information (CSI) 的穿墙成像方法，利用WiFi的成本效益、不受光照影响和穿墙能力，实现无需摄像头的室内环境视觉监控，并提升CSI的可解释性以支持图像-based下游任务，如视觉活动识别。方法采用多模态Variational Autoencoder (VAE)，针对穿墙场景进行适应性优化。实验通过消融研究和定量/定性评估证明，该方法能有效重建图像，并展示其实用潜力，例如在穿墙监控中的应用。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Added link to source code repository",
      "pdf_url": "http://arxiv.org/pdf/2401.17417v2",
      "published_date": "2024-01-30 20:17:51 UTC",
      "updated_date": "2025-02-07 20:09:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:25:15.138845"
    },
    {
      "arxiv_id": "2402.00070v1",
      "title": "EvoMerge: Neuroevolution for Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Yushu Jiang"
      ],
      "abstract": "Extensive fine-tuning on Large Language Models does not always yield better\nresults. Oftentimes, models tend to get better at imitating one form of data\nwithout gaining greater reasoning ability and may even end up losing some\nintelligence. Here I introduce EvoMerge, a systematic approach to large\nlanguage model training and merging. Leveraging model merging for weight\ncrossover and fine-tuning for weight mutation, EvoMerge establishes an\nevolutionary process aimed at pushing models beyond the limits of conventional\nfine-tuning.",
      "tldr_zh": "本研究指出，大规模微调 Large Language Models 并不总是带来更好结果，往往使模型更擅长模仿特定数据而非提升推理能力，甚至导致某些智能退化。为解决这一问题，作者引入 EvoMerge，一种系统方法，通过模型合并（model merging）实现权重交叉（weight crossover）和微调（fine-tuning）实现权重变异（weight mutation），构建一个进化过程。EvoMerge 旨在超越传统微调的局限，推动 Large Language Models 在智能和性能方面取得更大进展。",
      "categories": [
        "cs.NE",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.NE",
      "comment": "The current submission is the first draft, published for the sole\n  purpose of sharing an idea and encouraging community effort. A more\n  consolidated version may come later",
      "pdf_url": "http://arxiv.org/pdf/2402.00070v1",
      "published_date": "2024-01-30 19:37:21 UTC",
      "updated_date": "2024-01-30 19:37:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:25:27.267830"
    },
    {
      "arxiv_id": "2401.17401v1",
      "title": "Step-size Optimization for Continual Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Thomas Degris",
        "Khurram Javed",
        "Arsalan Sharifnassab",
        "Yuxin Liu",
        "Richard Sutton"
      ],
      "abstract": "In continual learning, a learner has to keep learning from the data over its\nwhole life time. A key issue is to decide what knowledge to keep and what\nknowledge to let go. In a neural network, this can be implemented by using a\nstep-size vector to scale how much gradient samples change network weights.\nCommon algorithms, like RMSProp and Adam, use heuristics, specifically\nnormalization, to adapt this step-size vector. In this paper, we show that\nthose heuristics ignore the effect of their adaptation on the overall objective\nfunction, for example by moving the step-size vector away from better step-size\nvectors. On the other hand, stochastic meta-gradient descent algorithms, like\nIDBD (Sutton, 1992), explicitly optimize the step-size vector with respect to\nthe overall objective function. On simple problems, we show that IDBD is able\nto consistently improve step-size vectors, where RMSProp and Adam do not. We\nexplain the differences between the two approaches and their respective\nlimitations. We conclude by suggesting that combining both approaches could be\na promising future direction to improve the performance of neural networks in\ncontinual learning.",
      "tldr_zh": "本论文探讨了在持续学习(Continual Learning)中优化步长向量(step-size vector)的方法，以决定保留或放弃知识。传统算法如 RMSProp 和 Adam 通过启发式归一化调整步长，但忽略了对整体目标函数的影响，导致优化不佳。相比之下，随机元梯度下降算法如 IDBD (Sutton, 1992) 显式针对整体目标优化步长向量，并在简单问题上表现出色，能持续改进步长，而 RMSProp 和 Adam 则无法实现。论文分析了两种方法的差异和局限性，并建议未来结合两者以提升神经网络在持续学习中的性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.17401v1",
      "published_date": "2024-01-30 19:35:43 UTC",
      "updated_date": "2024-01-30 19:35:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:25:40.224585"
    },
    {
      "arxiv_id": "2402.00069v1",
      "title": "Using the Abstract Computer Architecture Description Language to Model AI Hardware Accelerators",
      "title_zh": "翻译失败",
      "authors": [
        "Mika Markus Müller",
        "Alexander Richard Manfred Borst",
        "Konstantin Lübeck",
        "Alexander Louis-Ferdinand Jung",
        "Oliver Bringmann"
      ],
      "abstract": "Artificial Intelligence (AI) has witnessed remarkable growth, particularly\nthrough the proliferation of Deep Neural Networks (DNNs). These powerful models\ndrive technological advancements across various domains. However, to harness\ntheir potential in real-world applications, specialized hardware accelerators\nare essential. This demand has sparked a market for parameterizable AI hardware\naccelerators offered by different vendors.\n  Manufacturers of AI-integrated products face a critical challenge: selecting\nan accelerator that aligns with their product's performance requirements. The\ndecision involves choosing the right hardware and configuring a suitable set of\nparameters. However, comparing different accelerator design alternatives\nremains a complex task. Often, engineers rely on data sheets, spreadsheet\ncalculations, or slow black-box simulators, which only offer a coarse\nunderstanding of the performance characteristics.\n  The Abstract Computer Architecture Description Language (ACADL) is a concise\nformalization of computer architecture block diagrams, which helps to\ncommunicate computer architecture on different abstraction levels and allows\nfor inferring performance characteristics. In this paper, we demonstrate how to\nuse the ACADL to model AI hardware accelerators, use their ACADL description to\nmap DNNs onto them, and explain the timing simulation semantics to gather\nperformance results.",
      "tldr_zh": "该论文探讨了在AI硬件加速器建模中应用Abstract Computer Architecture Description Language (ACADL)，以解决制造商在选择和配置加速器时面临的性能比较难题。ACADL是一种简洁的形式化语言，用于描述计算机架构的块图，并支持不同抽象层次的性能推断。研究展示了如何使用ACADL来建模AI硬件加速器，将Deep Neural Networks (DNNs)映射到这些模型上，并通过timing simulation semantics进行性能模拟，从而提供比传统数据表或模拟器更精确的评估方法。总的来说，这为AI加速器设计决策提供了更高效的工具。",
      "categories": [
        "cs.AR",
        "cs.AI"
      ],
      "primary_category": "cs.AR",
      "comment": "Accepted Version for: MBMV'24",
      "pdf_url": "http://arxiv.org/pdf/2402.00069v1",
      "published_date": "2024-01-30 19:27:16 UTC",
      "updated_date": "2024-01-30 19:27:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:25:51.757575"
    },
    {
      "arxiv_id": "2401.17396v1",
      "title": "Fine-tuning Transformer-based Encoder for Turkish Language Understanding Tasks",
      "title_zh": "翻译失败",
      "authors": [
        "Savas Yildirim"
      ],
      "abstract": "Deep learning-based and lately Transformer-based language models have been\ndominating the studies of natural language processing in the last years. Thanks\nto their accurate and fast fine-tuning characteristics, they have outperformed\ntraditional machine learning-based approaches and achieved state-of-the-art\nresults for many challenging natural language understanding (NLU) problems.\nRecent studies showed that the Transformer-based models such as BERT, which is\nBidirectional Encoder Representations from Transformers, have reached\nimpressive achievements on many tasks. Moreover, thanks to their transfer\nlearning capacity, these architectures allow us to transfer pre-built models\nand fine-tune them to specific NLU tasks such as question answering. In this\nstudy, we provide a Transformer-based model and a baseline benchmark for the\nTurkish Language. We successfully fine-tuned a Turkish BERT model, namely\nBERTurk that is trained with base settings, to many downstream tasks and\nevaluated with a the Turkish Benchmark dataset. We showed that our studies\nsignificantly outperformed other existing baseline approaches for Named-Entity\nRecognition, Sentiment Analysis, Question Answering and Text Classification in\nTurkish Language. We publicly released these four fine-tuned models and\nresources in reproducibility and with the view of supporting other Turkish\nresearchers and applications.",
      "tldr_zh": "该研究专注于微调 Transformer-based 模型以提升土耳其语的自然语言理解（NLU）任务性能。作者开发并微调了 BERTurk 模型，该模型基于 BERT 架构，并在 Turkish Benchmark 数据集上进行了评估。实验结果显示，BERTurk 在命名实体识别（Named-Entity Recognition）、情感分析（Sentiment Analysis）、问答（Question Answering）和文本分类（Text Classification）等任务上，显著超过了现有基准方法。该模型及其资源已公开发布，以支持土耳其语相关的研究和应用。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.17396v1",
      "published_date": "2024-01-30 19:27:04 UTC",
      "updated_date": "2024-01-30 19:27:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:26:05.425018"
    },
    {
      "arxiv_id": "2401.17390v2",
      "title": "Customizing Language Model Responses with Contrastive In-Context Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Xiang Gao",
        "Kamalika Das"
      ],
      "abstract": "Large language models (LLMs) are becoming increasingly important for machine\nlearning applications. However, it can be challenging to align LLMs with our\nintent, particularly when we want to generate content that is preferable over\nothers or when we want the LLM to respond in a certain style or tone that is\nhard to describe. To address this challenge, we propose an approach that uses\ncontrastive examples to better describe our intent. This involves providing\npositive examples that illustrate the true intent, along with negative examples\nthat show what characteristics we want LLMs to avoid. The negative examples can\nbe retrieved from labeled data, written by a human, or generated by the LLM\nitself. Before generating an answer, we ask the model to analyze the examples\nto teach itself what to avoid. This reasoning step provides the model with the\nappropriate articulation of the user's need and guides it towards generting a\nbetter answer. We tested our approach on both synthesized and real-world\ndatasets, including StackExchange and Reddit, and found that it significantly\nimproves performance compared to standard few-shot prompting",
      "tldr_zh": "这篇论文提出了一种名为Contrastive In-Context Learning的方法，用于定制大语言模型(LLMs)的响应，以更好地对齐用户意图，尤其是在生成偏好内容或特定风格时。方法通过提供正例(positive examples)来展示期望特征，以及负例(negative examples)来避免不想要的特性，这些负例可从标记数据、人类输入或LLMs自身生成；在此基础上，让模型先进行分析和推理步骤，以指导生成更精确的答案。实验在合成和真实数据集（如StackExchange和Reddit）上验证，该方法比标准few-shot prompting显著提高了性能。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to appear at AAAI 2024",
      "pdf_url": "http://arxiv.org/pdf/2401.17390v2",
      "published_date": "2024-01-30 19:13:12 UTC",
      "updated_date": "2024-04-08 05:22:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:26:17.877817"
    },
    {
      "arxiv_id": "2401.17377v4",
      "title": "Infini-gram: Scaling Unbounded n-gram Language Models to a Trillion Tokens",
      "title_zh": "翻译失败",
      "authors": [
        "Jiacheng Liu",
        "Sewon Min",
        "Luke Zettlemoyer",
        "Yejin Choi",
        "Hannaneh Hajishirzi"
      ],
      "abstract": "Are $n$-gram language models still relevant in this era of neural large\nlanguage models (LLMs)? Our answer is yes, and we showcase their values in both\ntext analysis and improving neural LLMs. This was done by modernizing $n$-gram\nLMs in two aspects. First, we train them at the same data scale as neural LLMs\n-- 5 trillion tokens. This is the largest $n$-gram LM ever built. Second,\nexisting $n$-gram LMs use small $n$ which hinders their performance; we instead\nallow $n$ to be arbitrarily large, by introducing a new $\\infty$-gram LM with\nbackoff. Instead of pre-computing $n$-gram count tables (which would be very\nexpensive), we develop an engine named infini-gram -- powered by suffix arrays\n-- that can compute $\\infty$-gram (as well as $n$-gram with arbitrary $n$)\nprobabilities with millisecond-level latency. The $\\infty$-gram framework and\ninfini-gram engine enable us to conduct many novel and interesting analyses of\nhuman-written and machine-generated text: we find that the $\\infty$-gram LM has\nfairly high accuracy for next-token prediction (47%), and can complement neural\nLLMs to greatly reduce their perplexity. When analyzing machine-generated text,\nwe also observe irregularities in the machine--$\\infty$-gram agreement level\nwith respect to the suffix length, which indicates deficiencies in neural LLM\npretraining and the positional embeddings of Transformers.",
      "tldr_zh": "该论文证明了n-gram语言模型在神经大型语言模型(LLMs)时代仍具价值，用于文本分析和提升LLMs性能。通过在5万亿tokens规模上训练n-gram模型（迄今最大规模），并引入∞-gram LM with backoff，论文解决了传统n-gram模型的局限。infini-gram引擎利用suffix arrays实现了毫秒级延迟的任意n-gram概率计算，避免了昂贵的预计算。实验结果显示，∞-gram LM在下一个token预测中准确率达47%，能显著降低神经LLMs的perplexity，并揭示了机器生成文本中与∞-gram一致性的不规则问题，暴露了LLMs在预训练和位置嵌入方面的缺陷。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.CL",
      "comment": "Published at COLM 2024, spotlight paper",
      "pdf_url": "http://arxiv.org/pdf/2401.17377v4",
      "published_date": "2024-01-30 19:03:49 UTC",
      "updated_date": "2025-04-07 17:59:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:26:31.178997"
    },
    {
      "arxiv_id": "2401.17373v1",
      "title": "Arabic Tweet Act: A Weighted Ensemble Pre-Trained Transformer Model for Classifying Arabic Speech Acts on Twitter",
      "title_zh": "Arabic Tweet Act：一种用于分类 Twitter 上阿拉伯语言语行为的加权集成预训练 Transformer 模型",
      "authors": [
        "Khadejaa Alshehri",
        "Areej Alhothali",
        "Nahed Alowidi"
      ],
      "abstract": "Speech acts are a speakers actions when performing an utterance within a\nconversation, such as asking, recommending, greeting, or thanking someone,\nexpressing a thought, or making a suggestion. Understanding speech acts helps\ninterpret the intended meaning and actions behind a speakers or writers words.\nThis paper proposes a Twitter dialectal Arabic speech act classification\napproach based on a transformer deep learning neural network. Twitter and\nsocial media, are becoming more and more integrated into daily life. As a\nresult, they have evolved into a vital source of information that represents\nthe views and attitudes of their users. We proposed a BERT based weighted\nensemble learning approach to integrate the advantages of various BERT models\nin dialectal Arabic speech acts classification. We compared the proposed model\nagainst several variants of Arabic BERT models and sequence-based models. We\ndeveloped a dialectal Arabic tweet act dataset by annotating a subset of a\nlarge existing Arabic sentiment analysis dataset (ASAD) based on six speech act\ncategories. We also evaluated the models on a previously developed Arabic Tweet\nAct dataset (ArSAS). To overcome the class imbalance issue commonly observed in\nspeech act problems, a transformer-based data augmentation model was\nimplemented to generate an equal proportion of speech act categories. The\nresults show that the best BERT model is araBERTv2-Twitter models with a\nmacro-averaged F1 score and an accuracy of 0.73 and 0.84, respectively. The\nperformance improved using a BERT-based ensemble method with a 0.74 and 0.85\naveraged F1 score and accuracy on our dataset, respectively.",
      "tldr_zh": "这篇论文提出了一种名为 Arabic Tweet Act 的加权集成预训练 Transformer 模型，用于分类 Twitter 上的方言阿拉伯语语音行为（Speech Acts），以更好地理解用户意图如问候或建议。方法基于多种 BERT 模型的集成学习，并采用 Transformer 基于的数据增强技术来解决类别不平衡问题，同时开发了一个新的方言阿拉伯语推文数据集（基于 ASAD 子集的六类类别）。实验结果显示，araBERTv2-Twitter 模型的宏平均 F1 分数和准确率分别为 0.73 和 0.84，而集成方法进一步提升至 0.74 和 0.85，在现有 ArSAS 数据集上也表现出色。该研究为阿拉伯语社交媒体分析提供了更有效的工具。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "16 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2401.17373v1",
      "published_date": "2024-01-30 19:01:24 UTC",
      "updated_date": "2024-01-30 19:01:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:26:43.102474"
    },
    {
      "arxiv_id": "2401.17268v1",
      "title": "Weaver: Foundation Models for Creative Writing",
      "title_zh": "Weaver: 用于创意写作的基础模型",
      "authors": [
        "Tiannan Wang",
        "Jiamin Chen",
        "Qingrui Jia",
        "Shuai Wang",
        "Ruoyu Fang",
        "Huilin Wang",
        "Zhaowei Gao",
        "Chunzhao Xie",
        "Chuou Xu",
        "Jihong Dai",
        "Yibin Liu",
        "Jialong Wu",
        "Shengwei Ding",
        "Long Li",
        "Zhiwei Huang",
        "Xinle Deng",
        "Teng Yu",
        "Gangan Ma",
        "Han Xiao",
        "Zixin Chen",
        "Danjun Xiang",
        "Yunxia Wang",
        "Yuanyuan Zhu",
        "Yi Xiao",
        "Jing Wang",
        "Yiru Wang",
        "Siran Ding",
        "Jiayang Huang",
        "Jiayi Xu",
        "Yilihamu Tayier",
        "Zhenyu Hu",
        "Yuan Gao",
        "Chengfeng Zheng",
        "Yueshu Ye",
        "Yihang Li",
        "Lei Wan",
        "Xinyue Jiang",
        "Yujie Wang",
        "Siyu Cheng",
        "Zhule Song",
        "Xiangru Tang",
        "Xiaohua Xu",
        "Ningyu Zhang",
        "Huajun Chen",
        "Yuchen Eleanor Jiang",
        "Wangchunshu Zhou"
      ],
      "abstract": "This work introduces Weaver, our first family of large language models (LLMs)\ndedicated to content creation. Weaver is pre-trained on a carefully selected\ncorpus that focuses on improving the writing capabilities of large language\nmodels. We then fine-tune Weaver for creative and professional writing purposes\nand align it to the preference of professional writers using a suit of novel\nmethods for instruction data synthesis and LLM alignment, making it able to\nproduce more human-like texts and follow more diverse instructions for content\ncreation. The Weaver family consists of models of Weaver Mini (1.8B), Weaver\nBase (6B), Weaver Pro (14B), and Weaver Ultra (34B) sizes, suitable for\ndifferent applications and can be dynamically dispatched by a routing agent\naccording to query complexity to balance response quality and computation cost.\nEvaluation on a carefully curated benchmark for assessing the writing\ncapabilities of LLMs shows Weaver models of all sizes outperform generalist\nLLMs several times larger than them. Notably, our most-capable Weaver Ultra\nmodel surpasses GPT-4, a state-of-the-art generalist LLM, on various writing\nscenarios, demonstrating the advantage of training specialized LLMs for writing\npurposes. Moreover, Weaver natively supports retrieval-augmented generation\n(RAG) and function calling (tool usage). We present various use cases of these\nabilities for improving AI-assisted writing systems, including integration of\nexternal knowledge bases, tools, or APIs, and providing personalized writing\nassistance. Furthermore, we discuss and summarize a guideline and best\npractices for pre-training and fine-tuning domain-specific LLMs.",
      "tldr_zh": "这篇论文介绍了 Weaver，一系列专为创意写作设计的 Foundation Models（大型语言模型，LLMs），通过在精心选择的语料库上预训练，并使用新颖的指令数据合成和对齐方法进行细调，使其能生成更人性化的文本并处理多样化指令。Weaver 家族包括不同规模的模型，如 Weaver Mini (1.8B) 到 Weaver Ultra (34B)，并通过路由代理根据查询复杂度动态分发，以平衡响应质量和计算成本。在基准测试中，Weaver 模型在所有规模上均超越了比它们大数倍的通用 LLMs，且 Weaver Ultra 优于 GPT-4；在写作场景中，Weaver 支持检索增强生成 (RAG) 和函数调用，提供个性化写作辅助，并总结了预训练和细调领域特定 LLMs 的最佳实践。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.17268v1",
      "published_date": "2024-01-30 18:58:43 UTC",
      "updated_date": "2024-01-30 18:58:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:26:55.889717"
    },
    {
      "arxiv_id": "2401.17264v2",
      "title": "Proactive Detection of Voice Cloning with Localized Watermarking",
      "title_zh": "主动检测语音克隆的本地化水印技术",
      "authors": [
        "Robin San Roman",
        "Pierre Fernandez",
        "Alexandre Défossez",
        "Teddy Furon",
        "Tuan Tran",
        "Hady Elsahar"
      ],
      "abstract": "In the rapidly evolving field of speech generative models, there is a\npressing need to ensure audio authenticity against the risks of voice cloning.\nWe present AudioSeal, the first audio watermarking technique designed\nspecifically for localized detection of AI-generated speech. AudioSeal employs\na generator/detector architecture trained jointly with a localization loss to\nenable localized watermark detection up to the sample level, and a novel\nperceptual loss inspired by auditory masking, that enables AudioSeal to achieve\nbetter imperceptibility. AudioSeal achieves state-of-the-art performance in\nterms of robustness to real life audio manipulations and imperceptibility based\non automatic and human evaluation metrics. Additionally, AudioSeal is designed\nwith a fast, single-pass detector, that significantly surpasses existing models\nin speed - achieving detection up to two orders of magnitude faster, making it\nideal for large-scale and real-time applications.",
      "tldr_zh": "这篇论文提出了 AudioSeal，一种针对语音克隆风险的音频水印技术，首次实现局部检测 AI 生成语音的能力。AudioSeal 采用生成器/检测器架构，同时结合 localization loss 和受听觉掩蔽启发的 perceptual loss，确保水印检测精确到样本级别并提升隐蔽性。实验结果显示，AudioSeal 在鲁棒性和隐蔽性方面达到最先进水平，并通过快速单通道检测器，比现有模型快两个数量级，适用于大规模和实时应用。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.SD",
      "comment": "Published at ICML 2024. Code at\n  https://github.com/facebookresearch/audioseal - webpage at\n  https://pierrefdz.github.io/publications/audioseal/",
      "pdf_url": "http://arxiv.org/pdf/2401.17264v2",
      "published_date": "2024-01-30 18:56:22 UTC",
      "updated_date": "2024-06-06 17:48:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:27:06.195971"
    },
    {
      "arxiv_id": "2401.17263v5",
      "title": "Robust Prompt Optimization for Defending Language Models Against Jailbreaking Attacks",
      "title_zh": "翻译失败",
      "authors": [
        "Andy Zhou",
        "Bo Li",
        "Haohan Wang"
      ],
      "abstract": "Despite advances in AI alignment, large language models (LLMs) remain\nvulnerable to adversarial attacks or jailbreaking, in which adversaries can\nmodify prompts to induce unwanted behavior. While some defenses have been\nproposed, they have not been adapted to newly proposed attacks and more\nchallenging threat models. To address this, we propose an optimization-based\nobjective for defending LLMs against jailbreaking attacks and an algorithm,\nRobust Prompt Optimization (RPO) to create robust system-level defenses. Our\napproach directly incorporates the adversary into the defensive objective and\noptimizes a lightweight and transferable suffix, enabling RPO to adapt to\nworst-case adaptive attacks. Our theoretical and experimental results show\nimproved robustness to both jailbreaks seen during optimization and unknown\njailbreaks, reducing the attack success rate (ASR) on GPT-4 to 6% and Llama-2\nto 0% on JailbreakBench, setting the state-of-the-art. Code can be found at\nhttps://github.com/lapisrocks/rpo",
      "tldr_zh": "本研究针对大型语言模型 (LLMs) 面临的越狱攻击 (jailbreaking attacks) 问题，提出了一种优化-based 防御方法 Robust Prompt Optimization (RPO)，通过直接整合攻击者到防御目标中并优化轻量级、可转移的后缀，以适应最坏情况的自适应攻击。RPO 算法能有效提升模型的鲁棒性，对已知和未知攻击均有显著效果。实验结果显示，在 JailbreakBench 基准上，该方法将 GPT-4 的攻击成功率 (ASR) 降低到 6%，Llama-2 降低到 0%，从而设定了 state-of-the-art 水平。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "NeurIPS 2024 Spotlight; code available at\n  https://github.com/lapisrocks/rpo",
      "pdf_url": "http://arxiv.org/pdf/2401.17263v5",
      "published_date": "2024-01-30 18:56:08 UTC",
      "updated_date": "2024-11-08 06:57:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:27:19.805764"
    },
    {
      "arxiv_id": "2401.17244v3",
      "title": "LLaMP: Large Language Model Made Powerful for High-fidelity Materials Knowledge Retrieval and Distillation",
      "title_zh": "翻译失败",
      "authors": [
        "Yuan Chiang",
        "Elvis Hsieh",
        "Chia-Hong Chou",
        "Janosh Riebesell"
      ],
      "abstract": "Reducing hallucination of Large Language Models (LLMs) is imperative for use\nin the sciences, where reliability and reproducibility are crucial. However,\nLLMs inherently lack long-term memory, making it a nontrivial, ad hoc, and\ninevitably biased task to fine-tune them on domain-specific literature and\ndata. Here we introduce LLaMP, a multimodal retrieval-augmented generation\n(RAG) framework of hierarchical reasoning-and-acting (ReAct) agents that can\ndynamically and recursively interact with computational and experimental data\non Materials Project (MP) and run atomistic simulations via high-throughput\nworkflow interface. Without fine-tuning, LLaMP demonstrates strong tool usage\nability to comprehend and integrate various modalities of materials science\nconcepts, fetch relevant data stores on the fly, process higher-order data\n(such as crystal structure and elastic tensor), and streamline complex tasks in\ncomputational materials and chemistry. We propose a simple metric combining\nuncertainty and confidence estimates to evaluate the self-consistency of\nresponses by LLaMP and vanilla LLMs. Our benchmark shows that LLaMP effectively\nmitigates the intrinsic bias in LLMs, counteracting the errors on bulk moduli,\nelectronic bandgaps, and formation energies that seem to derive from mixed data\nsources. We also demonstrate LLaMP's capability to edit crystal structures and\nrun annealing molecular dynamics simulations using pre-trained machine-learning\nforce fields. The framework offers an intuitive and nearly hallucination-free\napproach to exploring and scaling materials informatics, and establishes a\npathway for knowledge distillation and fine-tuning other language models. Code\nand live demo are available at https://github.com/chiang-yuan/llamp",
      "tldr_zh": "本研究引入了 LLaMP，一种多模态检索增强生成 (RAG) 框架，结合层次化推理和行动 (ReAct) 代理，用于高保真材料知识检索和提炼，而无需对 Large Language Models (LLMs) 进行微调。LLaMP 能动态与 Materials Project (MP) 等数据源交互，处理材料科学的多模态概念（如晶体结构和弹性张量），并运行高通量原子模拟，从而减少 LLMs 的幻觉问题。研究提出了一种结合不确定性和置信度的指标来评估响应一致性，结果显示 LLaMP 在计算材料属性（如体模量、电子带隙和形成能）上显著降低了偏差，并在晶体结构编辑和分子动力学模拟中表现出色，为材料信息学的探索和知识提炼提供了可靠路径。",
      "categories": [
        "cs.CL",
        "cond-mat.mtrl-sci",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "32 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2401.17244v3",
      "published_date": "2024-01-30 18:37:45 UTC",
      "updated_date": "2024-10-09 20:13:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:27:31.094848"
    },
    {
      "arxiv_id": "2401.17230v2",
      "title": "ESPnet-SPK: full pipeline speaker embedding toolkit with reproducible recipes, self-supervised front-ends, and off-the-shelf models",
      "title_zh": "翻译失败",
      "authors": [
        "Jee-weon Jung",
        "Wangyou Zhang",
        "Jiatong Shi",
        "Zakaria Aldeneh",
        "Takuya Higuchi",
        "Barry-John Theobald",
        "Ahmed Hussen Abdelaziz",
        "Shinji Watanabe"
      ],
      "abstract": "This paper introduces ESPnet-SPK, a toolkit designed with several objectives\nfor training speaker embedding extractors. First, we provide an open-source\nplatform for researchers in the speaker recognition community to effortlessly\nbuild models. We provide several models, ranging from x-vector to recent\nSKA-TDNN. Through the modularized architecture design, variants can be\ndeveloped easily. We also aspire to bridge developed models with other domains,\nfacilitating the broad research community to effortlessly incorporate\nstate-of-the-art embedding extractors. Pre-trained embedding extractors can be\naccessed in an off-the-shelf manner and we demonstrate the toolkit's\nversatility by showcasing its integration with two tasks. Another goal is to\nintegrate with diverse self-supervised learning features. We release a\nreproducible recipe that achieves an equal error rate of 0.39% on the Vox1-O\nevaluation protocol using WavLM-Large with ECAPA-TDNN.",
      "tldr_zh": "本论文介绍了 ESPnet-SPK 工具包，这是一个用于训练 speaker embedding extractors 的开源平台，支持从 x-vector 到 SKA-TDNN 等多种模型，并通过模块化架构便于开发变体和与其他领域的整合。工具包允许用户以现成方式访问预训练模型，并展示了其与多样化自监督学习特征（如 WavLM-Large）的兼容性，便于扩展到其他任务。实验结果显示，使用可重现的配方，ESPnet-SPK 在 Vox1-O 评估协议上实现了 0.39% 的等错误率，显著提升了 speaker recognition 研究的效率和可访问性。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "5 pages, 3 figures, 7 tables, Interspeech 2024",
      "pdf_url": "http://arxiv.org/pdf/2401.17230v2",
      "published_date": "2024-01-30 18:18:27 UTC",
      "updated_date": "2024-06-13 05:19:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:27:42.903783"
    },
    {
      "arxiv_id": "2401.17228v1",
      "title": "Morality is Non-Binary: Building a Pluralist Moral Sentence Embedding Space using Contrastive Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Jeongwoo Park",
        "Enrico Liscio",
        "Pradeep K. Murukannaiah"
      ],
      "abstract": "Recent advances in NLP show that language models retain a discernible level\nof knowledge in deontological ethics and moral norms. However, existing works\noften treat morality as binary, ranging from right to wrong. This simplistic\nview does not capture the nuances of moral judgment. Pluralist moral\nphilosophers argue that human morality can be deconstructed into a finite\nnumber of elements, respecting individual differences in moral judgment. In\nline with this view, we build a pluralist moral sentence embedding space via a\nstate-of-the-art contrastive learning approach. We systematically investigate\nthe embedding space by studying the emergence of relationships among moral\nelements, both quantitatively and qualitatively. Our results show that a\npluralist approach to morality can be captured in an embedding space. However,\nmoral pluralism is challenging to deduce via self-supervision alone and\nrequires a supervised approach with human labels.",
      "tldr_zh": "本文批评现有NLP模型将道德判断视为二元（right to wrong），忽略了道德的细微差异，并提出使用Contrastive Learning构建一个Pluralist Moral Sentence Embedding Space，以捕捉多元道德元素。研究通过定量和定性方法系统调查了嵌入空间中道德元素之间的关系，结果表明这种多元方法能有效表示道德，但难以仅靠自监督实现，需要人类标签的监督学习。整体贡献为推动NLP中更细致、包容的道德表示。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "To appear in Findings of EACL 2024",
      "pdf_url": "http://arxiv.org/pdf/2401.17228v1",
      "published_date": "2024-01-30 18:15:25 UTC",
      "updated_date": "2024-01-30 18:15:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:27:54.886972"
    },
    {
      "arxiv_id": "2402.01762v1",
      "title": "Commercial AI, Conflict, and Moral Responsibility: A theoretical analysis and practical approach to the moral responsibilities associated with dual-use AI technology",
      "title_zh": "翻译失败",
      "authors": [
        "Daniel Trusilo",
        "David Danks"
      ],
      "abstract": "This paper presents a theoretical analysis and practical approach to the\nmoral responsibilities when developing AI systems for non-military applications\nthat may nonetheless be used for conflict applications. We argue that AI\nrepresents a form of crossover technology that is different from previous\nhistorical examples of dual- or multi-use technology as it has a multiplicative\neffect across other technologies. As a result, existing analyses of ethical\nresponsibilities around dual-use technologies do not necessarily work for AI\nsystems. We instead argue that stakeholders involved in the AI system lifecycle\nare morally responsible for uses of their systems that are reasonably\nforeseeable. The core idea is that an agent's moral responsibility for some\naction is not necessarily determined by their intentions alone; we must also\nconsider what the agent could reasonably have foreseen to be potential outcomes\nof their action, such as the potential use of a system in conflict even when it\nis not designed for that. In particular, we contend that it is reasonably\nforeseeable that: (1) civilian AI systems will be applied to active conflict,\nincluding conflict support activities, (2) the use of civilian AI systems in\nconflict will impact applications of the law of armed conflict, and (3)\ncrossover AI technology will be applied to conflicts that fall short of armed\nconflict. Given these reasonably foreseeably outcomes, we present three\ntechnically feasible actions that developers of civilian AIs can take to\npotentially mitigate their moral responsibility: (a) establishing systematic\napproaches to multi-perspective capability testing, (b) integrating digital\nwatermarking in model weight matrices, and (c) utilizing monitoring and\nreporting mechanisms for conflict-related AI applications.",
      "tldr_zh": "本论文对商业 AI 在非军事应用中可能被用于冲突情境的道德责任进行理论分析和实用方法探讨。作者认为，AI 作为一种具有乘数效应的交叉技术（crossover technology），不同于传统双重用途（dual-use）技术，因此现有道德责任框架不适用。论文强调，AI 生命周期中的利益相关者应对合理可预见的系统用途负有道德责任，包括 AI 被用于武装冲突、影响武装冲突法（law of armed conflict）的应用，以及非武装冲突情境。针对这些风险，作者提出三项可行措施：建立多视角能力测试（multi-perspective capability testing）、集成数字水印（digital watermarking）于模型权重，以及实施监控和报告机制，以缓解潜在道德责任。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "K.4.1; K.5.2"
      ],
      "primary_category": "cs.CY",
      "comment": "9 pages",
      "pdf_url": "http://arxiv.org/pdf/2402.01762v1",
      "published_date": "2024-01-30 18:09:45 UTC",
      "updated_date": "2024-01-30 18:09:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:28:06.316690"
    },
    {
      "arxiv_id": "2401.17221v1",
      "title": "MouSi: Poly-Visual-Expert Vision-Language Models",
      "title_zh": "MouSi：多视觉专家视觉语言模型",
      "authors": [
        "Xiaoran Fan",
        "Tao Ji",
        "Changhao Jiang",
        "Shuo Li",
        "Senjie Jin",
        "Sirui Song",
        "Junke Wang",
        "Boyang Hong",
        "Lu Chen",
        "Guodong Zheng",
        "Ming Zhang",
        "Caishuang Huang",
        "Rui Zheng",
        "Zhiheng Xi",
        "Yuhao Zhou",
        "Shihan Dou",
        "Junjie Ye",
        "Hang Yan",
        "Tao Gui",
        "Qi Zhang",
        "Xipeng Qiu",
        "Xuanjing Huang",
        "Zuxuan Wu",
        "Yu-Gang Jiang"
      ],
      "abstract": "Current large vision-language models (VLMs) often encounter challenges such\nas insufficient capabilities of a single visual component and excessively long\nvisual tokens. These issues can limit the model's effectiveness in accurately\ninterpreting complex visual information and over-lengthy contextual\ninformation. Addressing these challenges is crucial for enhancing the\nperformance and applicability of VLMs. This paper proposes the use of ensemble\nexperts technique to synergizes the capabilities of individual visual encoders,\nincluding those skilled in image-text matching, OCR, image segmentation, etc.\nThis technique introduces a fusion network to unify the processing of outputs\nfrom different visual experts, while bridging the gap between image encoders\nand pre-trained LLMs. In addition, we explore different positional encoding\nschemes to alleviate the waste of positional encoding caused by lengthy image\nfeature sequences, effectively addressing the issue of position overflow and\nlength limitations. For instance, in our implementation, this technique\nsignificantly reduces the positional occupancy in models like SAM, from a\nsubstantial 4096 to a more efficient and manageable 64 or even down to 1.\nExperimental results demonstrate that VLMs with multiple experts exhibit\nconsistently superior performance over isolated visual encoders and mark a\nsignificant performance boost as more experts are integrated. We have\nopen-sourced the training code used in this report. All of these resources can\nbe found on our project website.",
      "tldr_zh": "本文提出MouSi框架，以解决当前视觉语言模型(VLMs)面临的单一视觉组件能力不足和视觉标记过长的问题。该框架采用ensemble experts技术整合多种视觉专家（如图像文本匹配、OCR和图像分割），并引入融合网络统一处理输出，同时探索位置编码方案，将如SAM模型的占用从4096减少到64或1。实验结果表明，多专家模型在性能上显著优于单一编码器，且随着专家数量增加表现进一步提升；相关训练代码已开源。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.17221v1",
      "published_date": "2024-01-30 18:09:11 UTC",
      "updated_date": "2024-01-30 18:09:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:28:18.440815"
    },
    {
      "arxiv_id": "2401.17350v2",
      "title": "Time Series Supplier Allocation via Deep Black-Litterman Model",
      "title_zh": "翻译失败",
      "authors": [
        "Jiayuan Luo",
        "Wentao Zhang",
        "Yuchen Fang",
        "Xiaowei Gao",
        "Dingyi Zhuang",
        "Hao Chen",
        "Xinke Jiang"
      ],
      "abstract": "Time Series Supplier Allocation (TSSA) poses a complex NP-hard challenge,\naimed at refining future order dispatching strategies to satisfy order demands\nwith maximum supply efficiency fully. Traditionally derived from financial\nportfolio management, the Black-Litterman (BL) model offers a new perspective\nfor the TSSA scenario by balancing expected returns against insufficient supply\nrisks. However, its application within TSSA is constrained by the reliance on\nmanually constructed perspective matrices and spatio-temporal market dynamics,\ncoupled with the absence of supervisory signals and data unreliability inherent\nto supplier information. To solve these limitations, we introduce the\npioneering Deep Black-Litterman Model (DBLM), which innovatively adapts the BL\nmodel from financial roots to supply chain context. Leveraging the\nSpatio-Temporal Graph Neural Networks (STGNNS), DBLM automatically generates\nfuture perspective matrices for TSSA, by integrating spatio-temporal\ndependency. Moreover, a novel Spearman rank correlation distinctively\nsupervises our approach to address the lack of supervisory signals,\nspecifically designed to navigate through the complexities of supplier risks\nand interactions. This is further enhanced by a masking mechanism aimed at\ncounteracting the biases from unreliable data, thereby improving the model's\nprecision and reliability. Extensive experimentation on two datasets\nunequivocally demonstrates DBLM's enhanced performance in TSSA, setting new\nstandards for the field. Our findings and methodology are made available for\ncommunity access and further development.",
      "tldr_zh": "本研究针对Time Series Supplier Allocation (TSSA)这一复杂NP-hard问题，提出Deep Black-Litterman Model (DBLM)，将传统的Black-Litterman (BL)模型从金融投资组合管理领域移植到供应链场景，以优化订单分配策略并平衡预期回报与供应风险。\nDBLM创新性地利用Spatio-Temporal Graph Neural Networks (STGNNs)自动生成未来视角矩阵，整合时空依赖；同时引入Spearman秩相关系数作为监督信号处理供应商风险，并采用掩码机制缓解数据不可靠带来的偏差。\n实验结果显示，DBLM在两个真实数据集上显著提升了TSSA性能，并为该领域设定了新标准，所有方法和发现已公开以供社区进一步开发。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "In submission to SIGKDD 2024",
      "pdf_url": "http://arxiv.org/pdf/2401.17350v2",
      "published_date": "2024-01-30 17:57:07 UTC",
      "updated_date": "2024-02-09 05:44:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:28:32.251113"
    },
    {
      "arxiv_id": "2402.01761v1",
      "title": "Rethinking Interpretability in the Era of Large Language Models",
      "title_zh": "在大型语言模型时代重新",
      "authors": [
        "Chandan Singh",
        "Jeevana Priya Inala",
        "Michel Galley",
        "Rich Caruana",
        "Jianfeng Gao"
      ],
      "abstract": "Interpretable machine learning has exploded as an area of interest over the\nlast decade, sparked by the rise of increasingly large datasets and deep neural\nnetworks. Simultaneously, large language models (LLMs) have demonstrated\nremarkable capabilities across a wide array of tasks, offering a chance to\nrethink opportunities in interpretable machine learning. Notably, the\ncapability to explain in natural language allows LLMs to expand the scale and\ncomplexity of patterns that can be given to a human. However, these new\ncapabilities raise new challenges, such as hallucinated explanations and\nimmense computational costs.\n  In this position paper, we start by reviewing existing methods to evaluate\nthe emerging field of LLM interpretation (both interpreting LLMs and using LLMs\nfor explanation). We contend that, despite their limitations, LLMs hold the\nopportunity to redefine interpretability with a more ambitious scope across\nmany applications, including in auditing LLMs themselves. We highlight two\nemerging research priorities for LLM interpretation: using LLMs to directly\nanalyze new datasets and to generate interactive explanations.",
      "tldr_zh": "这篇论文重新审视了在 Large Language Models (LLMs) 时代下的可解释机器学习，强调 LLMs 通过自然语言解释能力，能够扩展人类理解复杂模式的能力，但也面临幻觉解释 (hallucinated explanations) 和高计算成本等挑战。作者回顾了现有方法来评估 LLM 解释领域，包括解释 LLMs 本身和使用 LLMs 进行解释，并认为尽管存在局限性，LLMs 仍有潜力重新定义可解释性的范围和应用。论文特别突出了两个新兴研究优先事项：利用 LLMs 直接分析新数据集和生成交互式解释，从而在审计 LLMs 及其他领域中发挥作用。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "7 pages",
      "pdf_url": "http://arxiv.org/pdf/2402.01761v1",
      "published_date": "2024-01-30 17:38:54 UTC",
      "updated_date": "2024-01-30 17:38:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:28:43.001719"
    },
    {
      "arxiv_id": "2401.17200v1",
      "title": "NormEnsembleXAI: Unveiling the Strengths and Weaknesses of XAI Ensemble Techniques",
      "title_zh": "翻译失败",
      "authors": [
        "Weronika Hryniewska-Guzik",
        "Bartosz Sawicki",
        "Przemysław Biecek"
      ],
      "abstract": "This paper presents a comprehensive comparative analysis of explainable\nartificial intelligence (XAI) ensembling methods. Our research brings three\nsignificant contributions. Firstly, we introduce a novel ensembling method,\nNormEnsembleXAI, that leverages minimum, maximum, and average functions in\nconjunction with normalization techniques to enhance interpretability.\nSecondly, we offer insights into the strengths and weaknesses of XAI ensemble\nmethods. Lastly, we provide a library, facilitating the practical\nimplementation of XAI ensembling, thus promoting the adoption of transparent\nand interpretable deep learning models.",
      "tldr_zh": "这篇论文对可解释人工智能(XAI)集成技术进行了全面比较分析，揭示其优势和劣势。研究的主要贡献包括引入新方法NormEnsembleXAI，该方法结合最小值、最大值和平均函数以及标准化技术，以提升模型的可解释性。此外，论文提供了一个实用库，支持XAI集成技术的实现，从而促进透明和可解释深度学习模型的广泛应用。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.17200v1",
      "published_date": "2024-01-30 17:33:35 UTC",
      "updated_date": "2024-01-30 17:33:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:28:53.890526"
    },
    {
      "arxiv_id": "2402.09443v1",
      "title": "Review of algorithms for predicting fatigue using EEG",
      "title_zh": "使用 EEG 预测疲",
      "authors": [
        "Ildar Rakhmatulin"
      ],
      "abstract": "Fatigue detection is of paramount importance in enhancing safety,\nproductivity, and well-being across diverse domains, including transportation,\nhealthcare, and industry. This scientific paper presents a comprehensive\ninvestigation into the application of machine learning algorithms for the\ndetection of physiological fatigue using Electroencephalogram (EEG) signals.\nThe primary objective of this study was to assess the efficacy of various\nalgorithms in predicting an individual's level of fatigue based on EEG data.",
      "tldr_zh": "这篇论文审阅了使用 EEG（Electroencephalogram）信号预测疲劳的机器学习算法，强调了疲劳检测在交通、健康和工业领域提升安全、生产力和福祉的重要性。研究的主要目标是评估各种算法在基于 EEG 数据预测个体疲劳水平方面的有效性。通过全面调查，这些算法展示了在生理疲劳检测中的潜在应用前景。",
      "categories": [
        "eess.SP",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "eess.SP",
      "comment": "arXiv admin note: text overlap with arXiv:2401.15766",
      "pdf_url": "http://arxiv.org/pdf/2402.09443v1",
      "published_date": "2024-01-30 17:32:02 UTC",
      "updated_date": "2024-01-30 17:32:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:29:06.589917"
    },
    {
      "arxiv_id": "2401.17188v1",
      "title": "Nested Construction of Polar Codes via Transformers",
      "title_zh": "翻译失败",
      "authors": [
        "Sravan Kumar Ankireddy",
        "S Ashwin Hebbar",
        "Heping Wan",
        "Joonyoung Cho",
        "Charlie Zhang"
      ],
      "abstract": "Tailoring polar code construction for decoding algorithms beyond successive\ncancellation has remained a topic of significant interest in the field.\nHowever, despite the inherent nested structure of polar codes, the use of\nsequence models in polar code construction is understudied. In this work, we\npropose using a sequence modeling framework to iteratively construct a polar\ncode for any given length and rate under various channel conditions.\nSimulations show that polar codes designed via sequential modeling using\ntransformers outperform both 5G-NR sequence and Density Evolution based\napproaches for both AWGN and Rayleigh fading channels.",
      "tldr_zh": "本研究探讨了使用序列建模框架来构建 Polar Codes 的方法，针对超越 Successive Cancellation 解码算法的优化需求。论文提出一种基于 Transformers 的迭代构建方法，利用 Polar Codes 的嵌套结构，以适应不同信道条件下的长度和速率。模拟结果显示，该方法在 AWGN 和 Rayleigh fading channels 上优于 5G-NR sequence 和 Density Evolution 基于方法，提高了编码性能。",
      "categories": [
        "cs.IT",
        "cs.AI",
        "math.IT"
      ],
      "primary_category": "cs.IT",
      "comment": "7 pages; 8 figures",
      "pdf_url": "http://arxiv.org/pdf/2401.17188v1",
      "published_date": "2024-01-30 17:17:43 UTC",
      "updated_date": "2024-01-30 17:17:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:29:17.756745"
    },
    {
      "arxiv_id": "2401.17186v1",
      "title": "Embracing Language Inclusivity and Diversity in CLIP through Continual Language Learning",
      "title_zh": "通过持续语言学习拥抱 CLIP 中的语言",
      "authors": [
        "Bang Yang",
        "Yong Dai",
        "Xuxin Cheng",
        "Yaowei Li",
        "Asif Raza",
        "Yuexian Zou"
      ],
      "abstract": "While vision-language pre-trained models (VL-PTMs) have advanced multimodal\nresearch in recent years, their mastery in a few languages like English\nrestricts their applicability in broader communities. To this end, there is an\nincreasing interest in developing multilingual VL models via a joint-learning\nsetup, which, however, could be unrealistic due to expensive costs and data\navailability. In this work, we propose to extend VL-PTMs' language capacity by\ncontinual language learning (CLL), where a model needs to update its linguistic\nknowledge incrementally without suffering from catastrophic forgetting (CF). We\nbegin our study by introducing a model dubbed CLL-CLIP, which builds upon CLIP,\na prevailing VL-PTM that has acquired image-English text alignment.\nSpecifically, CLL-CLIP contains an expandable token embedding layer to handle\nlinguistic differences. It solely trains token embeddings to improve memory\nstability and is optimized under cross-modal and cross-lingual objectives to\nlearn the alignment between images and multilingual texts. To alleviate CF\nraised by covariate shift and lexical overlap, we further propose a novel\napproach that ensures the identical distribution of all token embeddings during\ninitialization and regularizes token embedding learning during training. We\nconstruct a CLL benchmark covering 36 languages based on MSCOCO and XM3600\ndatasets and then evaluate multilingual image-text retrieval performance.\nExtensive experiments verify the effectiveness of CLL-CLIP and show that our\napproach can boost CLL-CLIP, e.g., by 6.7% in text-to-image average Recall@1 on\nXM3600, and improve various state-of-the-art methods consistently. Our code and\ndata are available at \\url{https://github.com/yangbang18/CLFM}.",
      "tldr_zh": "该论文旨在通过持续语言学习（Continual Language Learning, CLL）扩展视觉语言预训练模型（VL-PTMs）如 CLIP 的多语言能力，以解决其主要依赖英语的问题，从而提升语言包容性和多样性。研究提出 CLL-CLIP 模型，该模型基于 CLIP 构建，采用可扩展的 token embedding 层，仅训练 token embeddings 并结合跨模态和跨语言优化目标，以避免灾难性遗忘（Catastrophic Forgetting, CF）。此外，作者引入一种新方法，通过确保 token embeddings 初始化时的相同分布和训练过程中的正则化，来缓解因协变量偏移和词汇重叠导致的 CF。实验在基于 MSCOCO 和 XM3600 的 CLL 基准上（覆盖 36 种语言）验证了 CLL-CLIP 的有效性，例如在 XM3600 的 text-to-image 检索中平均 Recall@1 提升 6.7%，并一致改善了多种最先进方法。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by AAAI'2024, 15 pages (with appendix), 7 figures, 10 tables",
      "pdf_url": "http://arxiv.org/pdf/2401.17186v1",
      "published_date": "2024-01-30 17:14:05 UTC",
      "updated_date": "2024-01-30 17:14:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:29:34.170771"
    },
    {
      "arxiv_id": "2401.17178v1",
      "title": "GraphViz2Vec: A Structure-aware Feature Generation Model to Improve Classification in GNNs",
      "title_zh": "GraphViz2Vec：一种结构感知特征生成模型，用于",
      "authors": [
        "Shraban Kumar Chatterjee",
        "Suman Kundu"
      ],
      "abstract": "GNNs are widely used to solve various tasks including node classification and\nlink prediction. Most of the GNN architectures assume the initial embedding to\nbe random or generated from popular distributions. These initial embeddings\nrequire multiple layers of transformation to converge into a meaningful latent\nrepresentation. While number of layers allow accumulation of larger\nneighbourhood of a node it also introduce the problem of over-smoothing. In\naddition, GNNs are inept at representing structural information. For example,\nthe output embedding of a node does not capture its triangles participation. In\nthis paper, we presented a novel feature extraction methodology GraphViz2Vec\nthat can capture the structural information of a node's local neighbourhood to\ncreate meaningful initial embeddings for a GNN model. These initial embeddings\nhelps existing models achieve state-of-the-art results in various\nclassification tasks. Further, these initial embeddings help the model to\nproduce desired results with only two layers which in turn reduce the problem\nof over-smoothing. The initial encoding of a node is obtained from an image\nclassification model trained on multiple energy diagrams of its local\nneighbourhood. These energy diagrams are generated with the induced sub-graph\nof the nodes traversed by multiple random walks. The generated encodings\nincrease the performance of existing models on classification tasks (with a\nmean increase of $4.65\\%$ and $2.58\\%$ for the node and link classification\ntasks, respectively), with some models achieving state-of-the-art results.",
      "tldr_zh": "本研究针对图神经网络(GNNs)中初始嵌入随机性导致的过平滑问题以及结构信息表示不足的问题，提出了一种新型特征生成模型GraphViz2Vec。该模型通过捕捉节点的局部邻域结构信息（如三角形参与），利用随机游走生成的诱导子图创建能量图(energy diagrams)，并借助图像分类模型产生有意义的初始嵌入，从而减少所需层数并提升模型效率。实验结果显示，GraphViz2Vec显著提高了现有GNNs在节点分类和链接预测任务上的性能，平均提升4.65%和2.58%，并使某些模型达到最先进(state-of-the-art)水平。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.SI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.17178v1",
      "published_date": "2024-01-30 17:11:04 UTC",
      "updated_date": "2024-01-30 17:11:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:29:43.731849"
    },
    {
      "arxiv_id": "2401.17173v3",
      "title": "Zero-Shot Reinforcement Learning via Function Encoders",
      "title_zh": "翻译失败",
      "authors": [
        "Tyler Ingebrand",
        "Amy Zhang",
        "Ufuk Topcu"
      ],
      "abstract": "Although reinforcement learning (RL) can solve many challenging sequential\ndecision making problems, achieving zero-shot transfer across related tasks\nremains a challenge. The difficulty lies in finding a good representation for\nthe current task so that the agent understands how it relates to previously\nseen tasks. To achieve zero-shot transfer, we introduce the function encoder, a\nrepresentation learning algorithm which represents a function as a weighted\ncombination of learned, non-linear basis functions. By using a function encoder\nto represent the reward function or the transition function, the agent has\ninformation on how the current task relates to previously seen tasks via a\ncoherent vector representation. Thus, the agent is able to achieve transfer\nbetween related tasks at run time with no additional training. We demonstrate\nstate-of-the-art data efficiency, asymptotic performance, and training\nstability in three RL fields by augmenting basic RL algorithms with a function\nencoder task representation.",
      "tldr_zh": "这篇论文提出了一种名为function encoder的表示学习算法，用于实现强化学习（RL）中的zero-shot transfer，旨在解决代理在相关任务间转移的挑战。方法通过将奖励函数（reward function）或转移函数（transition function）表示为学得的非线性基函数的加权组合，从而提供一个连贯的向量表示，让代理无需额外训练即可在运行时理解和转移任务。实验结果显示，该方法在三个RL领域中，显著提升了数据效率（data efficiency）、渐近性能（asymptotic performance）和训练稳定性（training stability），达到了最先进的水平。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "A critical issue was found in the multi-agent experiments published\n  in version 2. We rerun the multi-agent experiments on a more challenging,\n  partially observable Markov game",
      "pdf_url": "http://arxiv.org/pdf/2401.17173v3",
      "published_date": "2024-01-30 17:04:47 UTC",
      "updated_date": "2025-03-21 14:37:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:29:55.274870"
    },
    {
      "arxiv_id": "2401.17169v4",
      "title": "Conditional and Modal Reasoning in Large Language Models",
      "title_zh": "大语言模型中的条件与模态推理",
      "authors": [
        "Wesley H. Holliday",
        "Matthew Mandelkern",
        "Cedegao E. Zhang"
      ],
      "abstract": "The reasoning abilities of large language models (LLMs) are the topic of a\ngrowing body of research in AI and cognitive science. In this paper, we probe\nthe extent to which twenty-nine LLMs are able to distinguish logically correct\ninferences from logically fallacious ones. We focus on inference patterns\ninvolving conditionals (e.g., 'If Ann has a queen, then Bob has a jack') and\nepistemic modals (e.g., 'Ann might have an ace', 'Bob must have a king'). These\ninferences have been of special interest to logicians, philosophers, and\nlinguists, since they play a central role in the fundamental human ability to\nreason about distal possibilities. Assessing LLMs on these inferences is thus\nhighly relevant to the question of how much the reasoning abilities of LLMs\nmatch those of humans. All the LLMs we tested make some basic mistakes with\nconditionals or modals, though zero-shot chain-of-thought prompting helps them\nmake fewer mistakes. Even the best performing LLMs make basic errors in modal\nreasoning, display logically inconsistent judgments across inference patterns\ninvolving epistemic modals and conditionals, and give answers about complex\nconditional inferences that do not match reported human judgments. These\nresults highlight gaps in basic logical reasoning in today's LLMs.",
      "tldr_zh": "这篇论文评估了29个Large Language Models (LLMs) 在条件句 (如 'If Ann has a queen, then Bob has a jack') 和认识论模态 (如 'Ann might have an ace') 推理方面的能力。研究通过测试逻辑正确与错误的推理模式，发现所有LLMs都存在基本错误，尽管zero-shot chain-of-thought prompting能帮助减少这些错误。结果显示，即使表现最好的LLMs也表现出逻辑不一致和与人类判断不符的问题，突显了当前LLMs在基本逻辑推理中的局限性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LO",
        "68T50, 03B65",
        "I.2.7"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted for The 2024 Conference on Empirical Methods in Natural\n  Language Processing (EMNLP 2024). Final version includes additional models\n  and additional inference patterns",
      "pdf_url": "http://arxiv.org/pdf/2401.17169v4",
      "published_date": "2024-01-30 16:56:54 UTC",
      "updated_date": "2024-10-13 11:08:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:30:07.255622"
    },
    {
      "arxiv_id": "2402.00891v1",
      "title": "Large Language Models in Cybersecurity: State-of-the-Art",
      "title_zh": "翻译失败",
      "authors": [
        "Farzad Nourmohammadzadeh Motlagh",
        "Mehrdad Hajizadeh",
        "Mehryar Majd",
        "Pejman Najafi",
        "Feng Cheng",
        "Christoph Meinel"
      ],
      "abstract": "The rise of Large Language Models (LLMs) has revolutionized our comprehension\nof intelligence bringing us closer to Artificial Intelligence. Since their\nintroduction, researchers have actively explored the applications of LLMs\nacross diverse fields, significantly elevating capabilities. Cybersecurity,\ntraditionally resistant to data-driven solutions and slow to embrace machine\nlearning, stands out as a domain. This study examines the existing literature,\nproviding a thorough characterization of both defensive and adversarial\napplications of LLMs within the realm of cybersecurity. Our review not only\nsurveys and categorizes the current landscape but also identifies critical\nresearch gaps. By evaluating both offensive and defensive applications, we aim\nto provide a holistic understanding of the potential risks and opportunities\nassociated with LLM-driven cybersecurity.",
      "tldr_zh": "这篇论文综述了Large Language Models (LLMs)在Cybersecurity领域的现状，审查了现有文献并分类了LLMs的防御和攻击应用。研究者评估了这些应用带来的潜在风险和机会，同时识别了关键的研究空白，以推动该领域的进一步发展。该工作为理解LLMs在网络安全中的作用提供了全面视角。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.00891v1",
      "published_date": "2024-01-30 16:55:25 UTC",
      "updated_date": "2024-01-30 16:55:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:30:18.961215"
    },
    {
      "arxiv_id": "2401.17159v2",
      "title": "Layered and Staged Monte Carlo Tree Search for SMT Strategy Synthesis",
      "title_zh": "翻译失败",
      "authors": [
        "Zhengyang Lu",
        "Stefan Siemer",
        "Piyush Jha",
        "Joel Day",
        "Florin Manea",
        "Vijay Ganesh"
      ],
      "abstract": "Modern SMT solvers, such as Z3, offer user-controllable strategies, enabling\nusers to tailor solving strategies for their unique set of instances, thus\ndramatically enhancing solver performance for their use case. However, this\napproach of strategy customization presents a significant challenge:\nhandcrafting an optimized strategy for a class of SMT instances remains a\ncomplex and demanding task for both solver developers and users alike.\n  In this paper, we address this problem of automatic SMT strategy synthesis\nvia a novel Monte Carlo Tree Search (MCTS) based method. Our method treats\nstrategy synthesis as a sequential decision-making process, whose search tree\ncorresponds to the strategy space, and employs MCTS to navigate this vast\nsearch space. The key innovations that enable our method to identify effective\nstrategies, while keeping costs low, are the ideas of layered and staged MCTS\nsearch. These novel heuristics allow for a deeper and more efficient\nexploration of the strategy space, enabling us to synthesize more effective\nstrategies than the default ones in state-of-the-art (SOTA) SMT solvers. We\nimplement our method, dubbed Z3alpha, as part of the Z3 SMT solver. Through\nextensive evaluations across six important SMT logics, Z3alpha demonstrates\nsuperior performance compared to the SOTA synthesis tool FastSMT, the default\nZ3 solver, and the CVC5 solver on most benchmarks. Remarkably, on a challenging\nQF_BV benchmark set, Z3alpha solves 42.7% more instances than the default\nstrategy in the Z3 SMT solver.",
      "tldr_zh": "该论文针对SMT求解器（如Z3）策略自定义的复杂性问题，提出了一种基于Monte Carlo Tree Search (MCTS)的自动策略合成方法，将策略合成视为顺序决策过程。关键创新在于引入Layered and Staged MCTS搜索，这些启发式机制提升了策略空间的深入和高效探索，从而生成比默认策略更有效的SMT策略。该方法实现为Z3alpha工具，并在六个重要SMT逻辑上进行评估，结果显示Z3alpha在大多数基准上优于FastSMT、默认Z3和CVC5求解器，尤其在QF_BV基准上比默认Z3策略多解决42.7%的实例。",
      "categories": [
        "cs.AI",
        "cs.LO",
        "cs.SE"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted at IJCAI 2024",
      "pdf_url": "http://arxiv.org/pdf/2401.17159v2",
      "published_date": "2024-01-30 16:47:30 UTC",
      "updated_date": "2024-04-30 16:34:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:30:31.645359"
    },
    {
      "arxiv_id": "2402.01760v2",
      "title": "Trust and ethical considerations in a multi-modal, explainable AI-driven chatbot tutoring system: The case of collaboratively solving Rubik's Cube",
      "title_zh": "翻译失败",
      "authors": [
        "Kausik Lakkaraju",
        "Vedant Khandelwal",
        "Biplav Srivastava",
        "Forest Agostinelli",
        "Hengtao Tang",
        "Prathamjeet Singh",
        "Dezhi Wu",
        "Matt Irvin",
        "Ashish Kundu"
      ],
      "abstract": "Artificial intelligence (AI) has the potential to transform education with\nits power of uncovering insights from massive data about student learning\npatterns. However, ethical and trustworthy concerns of AI have been raised but\nare unsolved. Prominent ethical issues in high school AI education include data\nprivacy, information leakage, abusive language, and fairness. This paper\ndescribes technological components that were built to address ethical and\ntrustworthy concerns in a multi-modal collaborative platform (called ALLURE\nchatbot) for high school students to collaborate with AI to solve the Rubik's\ncube. In data privacy, we want to ensure that the informed consent of children,\nparents, and teachers, is at the center of any data that is managed. Since\nchildren are involved, language, whether textual, audio, or visual, is\nacceptable both from users and AI and the system can steer interaction away\nfrom dangerous situations. In information management, we also want to ensure\nthat the system, while learning to improve over time, does not leak information\nabout users from one group to another.",
      "tldr_zh": "这篇论文探讨了多模态、explainable AI驱动的聊天机器人系统（ALLURE chatbot）在教育中的信任和伦理问题，以高中生合作解决Rubik's Cube为例。论文重点解决AI伦理挑战，包括数据隐私、信息泄露、滥用语言和公平性，通过技术组件确保儿童、父母和教师的知情同意，并过滤文本、音频或视觉语言以避免危险互动。同时，该系统在学习改进时采用信息隔离机制，防止用户群之间数据泄露，为可信赖的AI教育协作提供了实用框架。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "Accepted at 'Neural Conversational AI Workshop - What's left to TEACH\n  (Trustworthy, Enhanced, Adaptable, Capable, and Human-centric) chatbots?' at\n  ICML 2023",
      "pdf_url": "http://arxiv.org/pdf/2402.01760v2",
      "published_date": "2024-01-30 16:33:21 UTC",
      "updated_date": "2024-08-27 15:09:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:30:44.245988"
    },
    {
      "arxiv_id": "2402.01759v1",
      "title": "Systematic Literature Review: Computational Approaches for Humour Style Classification",
      "title_zh": "系统文献综述：用于幽默风格分类的计算方法",
      "authors": [
        "Mary Ogbuka Kenneth",
        "Foaad Khosmood",
        "Abbas Edalat"
      ],
      "abstract": "Understanding various humour styles is essential for comprehending the\nmultifaceted nature of humour and its impact on fields such as psychology and\nartificial intelligence. This understanding has revealed that humour, depending\non the style employed, can either have therapeutic or detrimental effects on an\nindividual's health and relationships. Although studies dedicated exclusively\nto computational-based humour style analysis remain somewhat rare, an expansive\nbody of research thrives within related task, particularly binary humour and\nsarcasm recognition. In this systematic literature review (SLR), we survey the\nlandscape of computational techniques applied to these related tasks and also\nuncover their fundamental relevance to humour style analysis. Through this\nstudy, we unveil common approaches, illuminate various datasets and evaluation\nmetrics, and effectively navigate the complex terrain of humour research. Our\nefforts determine potential research gaps and outlined promising directions.\nFurthermore, the SLR identifies a range of features and computational models\nthat can seamlessly transition from related tasks like binary humour and\nsarcasm detection to invigorate humour style classification. These features\nencompass incongruity, sentiment and polarity analysis, ambiguity detection,\nacoustic nuances, visual cues, contextual insights, and more. The computational\nmodels that emerge contain traditional machine learning paradigms, neural\nnetwork architectures, transformer-based models, and specialised models attuned\nto the nuances of humour. Finally, the SLR provides access to existing datasets\nrelated to humour and sarcasm, facilitating the work of future researchers.",
      "tldr_zh": "这篇系统文献综述（Systematic Literature Review）探讨了计算方法在幽默风格分类（humour style classification）中的应用，强调了理解不同幽默风格对心理健康和人际关系的影响。论文回顾了相关任务如二元幽默（binary humour）和讽刺识别（sarcasm recognition）的计算技术，包括特征（如incongruity、sentiment and polarity analysis）和模型（如传统机器学习、神经网络和Transformer-based models），并揭示了这些方法的可转移性。最终，它指出了研究空白、未来方向，并提供了相关数据集资源，以支持后续幽默研究。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.01759v1",
      "published_date": "2024-01-30 16:21:47 UTC",
      "updated_date": "2024-01-30 16:21:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:30:56.436609"
    },
    {
      "arxiv_id": "2401.17139v2",
      "title": "Diff-eRank: A Novel Rank-Based Metric for Evaluating Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Lai Wei",
        "Zhiquan Tan",
        "Chenghai Li",
        "Jindong Wang",
        "Weiran Huang"
      ],
      "abstract": "Large Language Models (LLMs) have transformed natural language processing and\nextended their powerful capabilities to multi-modal domains. As LLMs continue\nto advance, it is crucial to develop diverse and appropriate metrics for their\nevaluation. In this paper, we introduce a novel rank-based metric, Diff-eRank,\ngrounded in information theory and geometry principles. Diff-eRank assesses\nLLMs by analyzing their hidden representations, providing a quantitative\nmeasure of how efficiently they eliminate redundant information during\ntraining. We demonstrate the applicability of Diff-eRank in both single-modal\n(e.g., language) and multi-modal settings. For language models, our results\nshow that Diff-eRank increases with model size and correlates well with\nconventional metrics such as loss and accuracy. In the multi-modal context, we\npropose an alignment evaluation method based on the eRank, and verify that\ncontemporary multi-modal LLMs exhibit strong alignment performance based on our\nmethod. Our code is publicly available at\nhttps://github.com/waltonfuture/Diff-eRank.",
      "tldr_zh": "这篇论文引入了Diff-eRank，一种基于信息理论和几何原则的新型排名指标，用于评估大型语言模型(LLMs)的隐藏表示效率，量化模型在训练过程中消除冗余信息的能力。Diff-eRank适用于单模态（如语言）和多模态场景，实验结果显示它随模型大小增加而提升，并与传统指标如损失和准确率高度相关。在多模态上下文中，该指标还提出了一种基于eRank的对齐评估方法，并验证了当代多模态LLMs的强对齐性能，代码已在GitHub上公开。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.IT",
        "math.IT"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2401.17139v2",
      "published_date": "2024-01-30 16:19:55 UTC",
      "updated_date": "2024-10-14 04:36:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:31:09.065771"
    },
    {
      "arxiv_id": "2401.17133v2",
      "title": "SongBsAb: A Dual Prevention Approach against Singing Voice Conversion based Illegal Song Covers",
      "title_zh": "翻译失败",
      "authors": [
        "Guangke Chen",
        "Yedi Zhang",
        "Fu Song",
        "Ting Wang",
        "Xiaoning Du",
        "Yang Liu"
      ],
      "abstract": "Singing voice conversion (SVC) automates song covers by converting a source\nsinging voice from a source singer into a new singing voice with the same\nlyrics and melody as the source, but sounds like being covered by the target\nsinger of some given target singing voices. However, it raises serious concerns\nabout copyright and civil right infringements. We propose SongBsAb, the first\nproactive approach to tackle SVC-based illegal song covers. SongBsAb adds\nperturbations to singing voices before releasing them, so that when they are\nused, the process of SVC will be interfered, leading to unexpected singing\nvoices. Perturbations are carefully crafted to (1) provide a dual prevention,\ni.e., preventing the singing voice from being used as the source and target\nsinging voice in SVC, by proposing a gender-transformation loss and a high/low\nhierarchy multi-target loss, respectively; and (2) be harmless, i.e., no\nside-effect on the enjoyment of protected songs, by refining a psychoacoustic\nmodel-based loss with the backing track as an additional masker, a unique\naccompanying element for singing voices compared to ordinary speech voices. We\nalso adopt a frame-level interaction reduction-based loss and encoder ensemble\nto enhance the transferability of SongBsAb to unknown SVC models. We\ndemonstrate the prevention effectiveness, harmlessness, and robustness of\nSongBsAb on five diverse and promising SVC models, using both English and\nChinese datasets, and both objective and human study-based subjective metrics.\nOur work fosters an emerging research direction for mitigating illegal\nautomated song covers.",
      "tldr_zh": "该研究提出 SongBsAb，一种双重预防方法，用于对抗基于 Singing Voice Conversion (SVC) 的非法歌曲翻唱问题，通过在发布前向演唱声添加精心设计的扰动来干扰 SVC 过程。SongBsAb 包括 gender-transformation loss 和 high/low hierarchy multi-target loss，分别防止歌曲被用作源声音或目标声音，同时采用 psychoacoustic model-based loss 和 backing track 作为 masker，确保扰动不会影响歌曲的正常欣赏。实验在多种 SVC 模型上验证了 SongBsAb 的有效性、无害性和鲁棒性，包括客观指标和主观人类评估，推动了缓解自动化非法歌曲翻唱的新研究方向。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.CR",
        "cs.LG",
        "cs.MM",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "In Proceedings of the 32nd Network and Distributed System Security\n  (NDSS) Symposium 2025",
      "pdf_url": "http://arxiv.org/pdf/2401.17133v2",
      "published_date": "2024-01-30 16:07:44 UTC",
      "updated_date": "2024-12-01 04:06:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:31:20.178056"
    },
    {
      "arxiv_id": "2401.17095v1",
      "title": "Traffic estimation in unobserved network locations using data-driven macroscopic models",
      "title_zh": "翻译失败",
      "authors": [
        "Pablo Guarda",
        "Sean Qian"
      ],
      "abstract": "This paper leverages macroscopic models and multi-source spatiotemporal data\ncollected from automatic traffic counters and probe vehicles to accurately\nestimate traffic flow and travel time in links where these measurements are\nunavailable. This problem is critical in transportation planning applications\nwhere the sensor coverage is low and the planned interventions have\nnetwork-wide impacts. The proposed model, named the Macroscopic Traffic\nEstimator (MaTE), can perform network-wide estimations of traffic flow and\ntravel time only using the set of observed measurements of these quantities.\nBecause MaTE is grounded in macroscopic flow theory, all parameters and\nvariables are interpretable. The estimated traffic flow satisfies fundamental\nflow conservation constraints and exhibits an increasing monotonic relationship\nwith the estimated travel time. Using logit-based stochastic traffic assignment\nas the principle for routing flow behavior makes the model fully differentiable\nwith respect to the model parameters. This property facilitates the application\nof computational graphs to learn parameters from vast amounts of spatiotemporal\ndata. We also integrate neural networks and polynomial kernel functions to\ncapture link flow interactions and enrich the mapping of traffic flows into\ntravel times. MaTE also adds a destination choice model and a trip generation\nmodel that uses historical data on the number of trips generated by location.\nExperiments on synthetic data show that the model can accurately estimate\ntravel time and traffic flow in out-of-sample links. Results obtained using\nreal-world multi-source data from a large-scale transportation network suggest\nthat MaTE outperforms data-driven benchmarks, especially in travel time\nestimation. The estimated parameters of MaTE are also informative about the\nhourly change in travel demand and supply characteristics of the transportation\nnetwork.",
      "tldr_zh": "本文提出 Macroscopic Traffic Estimator (MaTE) 模型，利用宏观流量理论和多源时空数据（如自动交通计数器和探测车辆数据），准确估计交通网络中未观察位置的流量和旅行时间，以解决传感器覆盖不足的交通规划问题。MaTE 基于 logit-based stochastic traffic assignment 原理，使模型参数完全可微，并整合神经网络和多项式核函数来捕捉链路互动，同时添加目的地选择和出行生成模型以提升估计精度。实验结果显示，MaTE 在合成和真实世界数据上显著优于数据驱动基准模型，尤其在旅行时间估计方面，并提供可解释的参数来揭示交通网络的出行需求和供给动态变化。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "34 pages, 28 figures, 6 tables",
      "pdf_url": "http://arxiv.org/pdf/2401.17095v1",
      "published_date": "2024-01-30 15:21:50 UTC",
      "updated_date": "2024-01-30 15:21:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:31:33.201905"
    },
    {
      "arxiv_id": "2402.00068v3",
      "title": "Adapting Amidst Degradation: Cross Domain Li-ion Battery Health Estimation via Physics-Guided Test-Time Training",
      "title_zh": "翻译失败",
      "authors": [
        "Yuyuan Feng",
        "Guosheng Hu",
        "Xiaodong Li",
        "Zhihong Zhang"
      ],
      "abstract": "Health modeling of lithium-ion batteries (LIBs) is crucial for safe and\nefficient energy management and carries significant socio-economic\nimplications. Although Machine Learning (ML)-based State of Health (SOH)\nestimation methods have made significant progress in accuracy, the scarcity of\nhigh-quality LIB data remains a major obstacle. Existing transfer learning\nmethods for cross-domain LIB SOH estimation have significantly alleviated the\nlabeling burden of target LIB data, however, they still require sufficient\nunlabeled target data (UTD) for effective adaptation to the target domain.\nCollecting this UTD is challenging due to the time-consuming nature of\ndegradation experiments. To address this issue, we introduce a practical\nTest-Time Training framework, BatteryTTT, which adapts the model continually\nusing each UTD collected amidst degradation, thereby significantly reducing\ndata collection time. To fully utilize each UTD, BatteryTTT integrates the\ninherent physical laws of modern LIBs into self-supervised learning, termed\nPhyscics-Guided Test-Time Training. Additionally, we explore the potential of\nlarge language models (LLMs) in battery sequence modeling by evaluating their\nperformance in SOH estimation through model reprogramming and prefix prompt\nadaptation. The combination of BatteryTTT and LLM modeling, termed GPT4Battery,\nachieves state-of-the-art generalization results across current LIB benchmarks.\nFurthermore, we demonstrate the practical value and scalability of our approach\nby deploying it in our real-world battery management system (BMS) for 300Ah\nlarge-scale energy storage LIBs.",
      "tldr_zh": "该论文针对锂离子电池 (Li-ion batteries) 的健康建模问题，提出了一种实用框架 BatteryTTT，通过 Physics-Guided Test-Time Training 整合电池的物理定律和自监督学习，实现在退化过程中持续适应模型，从而显著减少无标签目标数据 (UTD) 的收集时间。研究还探索了大型语言模型 (LLMs) 在 SOH 估计中的潜力，使用模型重编程和前缀提示适应，形成 GPT4Battery 方法，并在跨域 LIB 基准上实现了最先进的泛化性能。最后，该方法已在真实电池管理系统 (BMS) 中部署于 300Ah 大规模能量存储电池，展示了其实际价值和可扩展性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.00068v3",
      "published_date": "2024-01-30 14:47:15 UTC",
      "updated_date": "2024-11-19 05:08:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:31:45.610774"
    },
    {
      "arxiv_id": "2404.16038v1",
      "title": "A Survey on Generative AI and LLM for Video Generation, Understanding, and Streaming",
      "title_zh": "翻译失败",
      "authors": [
        "Pengyuan Zhou",
        "Lin Wang",
        "Zhi Liu",
        "Yanbin Hao",
        "Pan Hui",
        "Sasu Tarkoma",
        "Jussi Kangasharju"
      ],
      "abstract": "This paper offers an insightful examination of how currently top-trending AI\ntechnologies, i.e., generative artificial intelligence (Generative AI) and\nlarge language models (LLMs), are reshaping the field of video technology,\nincluding video generation, understanding, and streaming. It highlights the\ninnovative use of these technologies in producing highly realistic videos, a\nsignificant leap in bridging the gap between real-world dynamics and digital\ncreation. The study also delves into the advanced capabilities of LLMs in video\nunderstanding, demonstrating their effectiveness in extracting meaningful\ninformation from visual content, thereby enhancing our interaction with videos.\nIn the realm of video streaming, the paper discusses how LLMs contribute to\nmore efficient and user-centric streaming experiences, adapting content\ndelivery to individual viewer preferences. This comprehensive review navigates\nthrough the current achievements, ongoing challenges, and future possibilities\nof applying Generative AI and LLMs to video-related tasks, underscoring the\nimmense potential these technologies hold for advancing the field of video\ntechnology related to multimedia, networking, and AI communities.",
      "tldr_zh": "这篇论文对生成式人工智能(Generative AI)和大型语言模型(LLMs)在视频生成、理解和流媒体领域的应用进行了全面调查，强调了这些技术在创建高度逼真视频方面的创新进展，从而缩小了现实动态与数字创作的差距。研究探讨了LLMs在视频理解中的先进能力，能够从视觉内容中提取有意义的信息，并提升用户互动；同时，在视频流媒体方面，LLMs有助于实现更高效、个性化的内容交付，以适应观众偏好。总体上，该调查回顾了当前成就、面临的挑战以及未来潜力，为多媒体、网络和AI社区提供了宝贵见解。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.MM"
      ],
      "primary_category": "cs.CV",
      "comment": "16 pages, 10 figures, 4 tables",
      "pdf_url": "http://arxiv.org/pdf/2404.16038v1",
      "published_date": "2024-01-30 14:37:10 UTC",
      "updated_date": "2024-01-30 14:37:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:31:55.398136"
    },
    {
      "arxiv_id": "2401.17053v4",
      "title": "BlockFusion: Expandable 3D Scene Generation using Latent Tri-plane Extrapolation",
      "title_zh": "翻译失败",
      "authors": [
        "Zhennan Wu",
        "Yang Li",
        "Han Yan",
        "Taizhang Shang",
        "Weixuan Sun",
        "Senbo Wang",
        "Ruikai Cui",
        "Weizhe Liu",
        "Hiroyuki Sato",
        "Hongdong Li",
        "Pan Ji"
      ],
      "abstract": "We present BlockFusion, a diffusion-based model that generates 3D scenes as\nunit blocks and seamlessly incorporates new blocks to extend the scene.\nBlockFusion is trained using datasets of 3D blocks that are randomly cropped\nfrom complete 3D scene meshes. Through per-block fitting, all training blocks\nare converted into the hybrid neural fields: with a tri-plane containing the\ngeometry features, followed by a Multi-layer Perceptron (MLP) for decoding the\nsigned distance values. A variational auto-encoder is employed to compress the\ntri-planes into the latent tri-plane space, on which the denoising diffusion\nprocess is performed. Diffusion applied to the latent representations allows\nfor high-quality and diverse 3D scene generation. To expand a scene during\ngeneration, one needs only to append empty blocks to overlap with the current\nscene and extrapolate existing latent tri-planes to populate new blocks. The\nextrapolation is done by conditioning the generation process with the feature\nsamples from the overlapping tri-planes during the denoising iterations. Latent\ntri-plane extrapolation produces semantically and geometrically meaningful\ntransitions that harmoniously blend with the existing scene. A 2D layout\nconditioning mechanism is used to control the placement and arrangement of\nscene elements. Experimental results indicate that BlockFusion is capable of\ngenerating diverse, geometrically consistent and unbounded large 3D scenes with\nunprecedented high-quality shapes in both indoor and outdoor scenarios.",
      "tldr_zh": "我们提出了 BlockFusion，一种基于扩散模型的框架，用于生成可扩展的 3D 场景，将场景分解为单位块，并通过 latent tri-plane 外推实现无缝扩展。模型训练使用从完整 3D 场景网格中随机裁剪的块，将每个块转换为混合神经场，包括 tri-plane 几何特征和 MLP 解码 signed distance values，同时利用 VAE 压缩 tri-planes 到 latent 空间进行去噪扩散，以生成高质量、多样化的场景。扩展机制通过添加空块与现有场景重叠，并使用重叠 tri-planes 的特征样本条件生成，确保语义和几何一致性；此外，2D 布局条件机制允许控制场景元素的放置。实验结果显示，BlockFusion 能生成多样、几何一致的无界大型 3D 场景，在室内和室外环境中表现出色。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.GR"
      ],
      "primary_category": "cs.CV",
      "comment": "ACM Transactions on Graphics (SIGGRAPH'24). Code:\n  https://yang-l1.github.io/blockfusion",
      "pdf_url": "http://arxiv.org/pdf/2401.17053v4",
      "published_date": "2024-01-30 14:34:19 UTC",
      "updated_date": "2024-05-24 03:56:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:32:08.721960"
    },
    {
      "arxiv_id": "2401.17050v1",
      "title": "ViTree: Single-path Neural Tree for Step-wise Interpretable Fine-grained Visual Categorization",
      "title_zh": "翻译失败",
      "authors": [
        "Danning Lao",
        "Qi Liu",
        "Jiazi Bu",
        "Junchi Yan",
        "Wei Shen"
      ],
      "abstract": "As computer vision continues to advance and finds widespread applications\nacross various domains, the need for interpretability in deep learning models\nbecomes paramount. Existing methods often resort to post-hoc techniques or\nprototypes to explain the decision-making process, which can be indirect and\nlack intrinsic illustration. In this research, we introduce ViTree, a novel\napproach for fine-grained visual categorization that combines the popular\nvision transformer as a feature extraction backbone with neural decision trees.\nBy traversing the tree paths, ViTree effectively selects patches from\ntransformer-processed features to highlight informative local regions, thereby\nrefining representations in a step-wise manner. Unlike previous tree-based\nmodels that rely on soft distributions or ensembles of paths, ViTree selects a\nsingle tree path, offering a clearer and simpler decision-making process. This\npatch and path selectivity enhances model interpretability of ViTree, enabling\nbetter insights into the model's inner workings. Remarkably, extensive\nexperimentation validates that this streamlined approach surpasses various\nstrong competitors and achieves state-of-the-art performance while maintaining\nexceptional interpretability which is proved by multi-perspective methods. Code\ncan be found at https://github.com/SJTU-DeepVisionLab/ViTree.",
      "tldr_zh": "本文提出 ViTree，一种新型框架，用于细粒度视觉分类（fine-grained visual categorization），它结合 Vision Transformer 作为特征提取骨干和 neural decision trees，通过遍历树路径选择关键补丁（patches），实现逐步精炼表示和更清晰的决策过程。不同于以往依赖软分布或多路径的树基模型，ViTree 采用单一树路径，提升了模型的内在可解释性。实验结果显示，该方法在多个基准上超越了竞争对手，达到了 state-of-the-art 性能，并通过多视角验证证明了其优秀的解释能力。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.17050v1",
      "published_date": "2024-01-30 14:32:25 UTC",
      "updated_date": "2024-01-30 14:32:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:32:21.284752"
    },
    {
      "arxiv_id": "2401.17045v5",
      "title": "Explaining Explanations in Probabilistic Logic Programming",
      "title_zh": "翻译失败",
      "authors": [
        "Germán Vidal"
      ],
      "abstract": "The emergence of tools based on artificial intelligence has also led to the\nneed of producing explanations which are understandable by a human being. In\nmost approaches, the system is considered a black box, making it difficult to\ngenerate appropriate explanations. In this work, though, we consider a setting\nwhere models are transparent: probabilistic logic programming (PLP), a paradigm\nthat combines logic programming for knowledge representation and probability to\nmodel uncertainty. However, given a query, the usual notion of explanation is\nassociated with a set of choices, one for each random variable of the model.\nUnfortunately, such a set does not explain why the query is true and, in fact,\nit may contain choices that are actually irrelevant for the considered query.\nTo improve this situation, we present in this paper an approach to explaining\nexplanations which is based on defining a new query-driven inference mechanism\nfor PLP where proofs are labeled with \"choice expressions\", a compact and easy\nto manipulate representation for sets of choices. The combination of proof\ntrees and choice expressions allows us to produce comprehensible query\njustifications with a causal structure.",
      "tldr_zh": "该论文探讨了在Probabilistic Logic Programming (PLP)中解释解释的挑战，针对AI系统生成可理解解释的需求。传统PLP解释依赖于每个随机变量的选择集，但这往往包含无关选择，无法清晰说明查询为何成立。为解决此问题，作者提出了一种基于查询驱动的推理机制，使用“choice expressions”作为紧凑的表示形式来标记证明树。这种方法结合证明树和choice expressions，能生成具有因果结构的、可理解查询证明，从而提升PLP解释的准确性和实用性。",
      "categories": [
        "cs.AI",
        "cs.PL"
      ],
      "primary_category": "cs.AI",
      "comment": "This preprint has not undergone peer review or any post-submission\n  improvements or corrections. The Version of Record of this contribution is\n  published in Programming Languages and Systems (Proceedings of APLAS 2024),\n  Springer LNCS, 2024, and is available online at\n  https://doi.org/10.1007/978-981-97-8943-6_7",
      "pdf_url": "http://arxiv.org/pdf/2401.17045v5",
      "published_date": "2024-01-30 14:27:37 UTC",
      "updated_date": "2024-10-22 03:06:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:32:32.856491"
    },
    {
      "arxiv_id": "2401.17044v2",
      "title": "Scalable Mechanism Design for Multi-Agent Path Finding",
      "title_zh": "翻译失败",
      "authors": [
        "Paul Friedrich",
        "Yulun Zhang",
        "Michael Curry",
        "Ludwig Dierks",
        "Stephen McAleer",
        "Jiaoyang Li",
        "Tuomas Sandholm",
        "Sven Seuken"
      ],
      "abstract": "Multi-Agent Path Finding (MAPF) involves determining paths for multiple\nagents to travel simultaneously and collision-free through a shared area toward\ngiven goal locations. This problem is computationally complex, especially when\ndealing with large numbers of agents, as is common in realistic applications\nlike autonomous vehicle coordination. Finding an optimal solution is often\ncomputationally infeasible, making the use of approximate, suboptimal\nalgorithms essential. Adding to the complexity, agents might act in a\nself-interested and strategic way, possibly misrepresenting their goals to the\nMAPF algorithm if it benefits them. Although the field of mechanism design\noffers tools to align incentives, using these tools without careful\nconsideration can fail when only having access to approximately optimal\noutcomes. In this work, we introduce the problem of scalable mechanism design\nfor MAPF and propose three strategyproof mechanisms, two of which even use\napproximate MAPF algorithms. We test our mechanisms on realistic MAPF domains\nwith problem sizes ranging from dozens to hundreds of agents. We find that they\nimprove welfare beyond a simple baseline.",
      "tldr_zh": "本研究探讨了 Multi-Agent Path Finding (MAPF) 的可扩展机制设计问题，该问题涉及多个代理在共享区域中无碰撞地移动到目标位置，但面临计算复杂性和代理的自私行为（如误报目标）。为了对齐代理激励，研究者提出三种策略证明机制（strategyproof mechanisms），其中两种结合了近似 MAPF 算法，以适应大规模场景。实验在涉及数十到数百代理的真实 MAPF 领域中进行，结果显示这些机制显著提高了整体福利（welfare），优于简单基线。",
      "categories": [
        "cs.AI",
        "cs.GT",
        "cs.MA"
      ],
      "primary_category": "cs.AI",
      "comment": "12 pages, 5 figures. IJCAI'24 camera-ready version",
      "pdf_url": "http://arxiv.org/pdf/2401.17044v2",
      "published_date": "2024-01-30 14:26:04 UTC",
      "updated_date": "2024-05-08 14:03:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:32:44.911586"
    },
    {
      "arxiv_id": "2401.17343v1",
      "title": "YTCommentQA: Video Question Answerability in Instructional Videos",
      "title_zh": "翻译失败",
      "authors": [
        "Saelyne Yang",
        "Sunghyun Park",
        "Yunseok Jang",
        "Moontae Lee"
      ],
      "abstract": "Instructional videos provide detailed how-to guides for various tasks, with\nviewers often posing questions regarding the content. Addressing these\nquestions is vital for comprehending the content, yet receiving immediate\nanswers is difficult. While numerous computational models have been developed\nfor Video Question Answering (Video QA) tasks, they are primarily trained on\nquestions generated based on video content, aiming to produce answers from\nwithin the content. However, in real-world situations, users may pose questions\nthat go beyond the video's informational boundaries, highlighting the necessity\nto determine if a video can provide the answer. Discerning whether a question\ncan be answered by video content is challenging due to the multi-modal nature\nof videos, where visual and verbal information are intertwined. To bridge this\ngap, we present the YTCommentQA dataset, which contains naturally-generated\nquestions from YouTube, categorized by their answerability and required\nmodality to answer -- visual, script, or both. Experiments with answerability\nclassification tasks demonstrate the complexity of YTCommentQA and emphasize\nthe need to comprehend the combined role of visual and script information in\nvideo reasoning. The dataset is available at\nhttps://github.com/lgresearch/YTCommentQA.",
      "tldr_zh": "这篇论文探讨了教学视频中用户问题回答性的挑战，指出现有 Video QA 模型主要针对视频内内容生成答案，而现实中问题可能超出视频范围。论文引入 YTCommentQA 数据集，该数据集基于 YouTube 评论收集的自然问题，并按 answerability 和所需模态（visual、script 或两者）进行分类，以帮助评估问题是否可由视频内容回答。实验结果展示了数据集的复杂性，并强调了视觉和脚本信息在视频推理中的联合作用，为改进 Video QA 任务提供了新资源。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "AAAI 2024",
      "pdf_url": "http://arxiv.org/pdf/2401.17343v1",
      "published_date": "2024-01-30 14:18:37 UTC",
      "updated_date": "2024-01-30 14:18:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:32:57.387982"
    },
    {
      "arxiv_id": "2401.17010v5",
      "title": "Finetuning Large Language Models for Vulnerability Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Alexey Shestov",
        "Rodion Levichev",
        "Ravil Mussabayev",
        "Evgeny Maslov",
        "Anton Cheshkov",
        "Pavel Zadorozhny"
      ],
      "abstract": "This paper presents the results of finetuning large language models (LLMs)\nfor the task of detecting vulnerabilities in source code. We leverage\nWizardCoder, a recent improvement of the state-of-the-art LLM StarCoder, and\nadapt it for vulnerability detection through further finetuning. To accelerate\ntraining, we modify WizardCoder's training procedure, also we investigate\noptimal training regimes. For the imbalanced dataset with many more negative\nexamples than positive, we also explore different techniques to improve\nclassification performance. The finetuned WizardCoder model achieves\nimprovement in ROC AUC and F1 measures on balanced and imbalanced vulnerability\ndatasets over CodeBERT-like model, demonstrating the effectiveness of adapting\npretrained LLMs for vulnerability detection in source code. The key\ncontributions are finetuning the state-of-the-art code LLM, WizardCoder,\nincreasing its training speed without the performance harm, optimizing the\ntraining procedure and regimes, handling class imbalance, and improving\nperformance on difficult vulnerability detection datasets. This demonstrates\nthe potential for transfer learning by finetuning large pretrained language\nmodels for specialized source code analysis tasks.",
      "tldr_zh": "本研究探讨了通过微调大型语言模型（LLMs）来检测源代码中漏洞的可行性，具体使用WizardCoder（基于StarCoder的改进版本）进行进一步训练。研究者修改了WizardCoder的训练过程以加速训练，并优化训练方案，同时采用多种技术处理数据集的不平衡问题，如正负样本比例失调。实验结果显示，微调后的模型在平衡和不平衡数据集上，ROC AUC和F1指标均超过了CodeBERT-like模型，证明了预训练LLMs通过迁移学习应用于源代码分析任务的潜力。关键贡献包括提升WizardCoder的训练速度、优化训练过程和处理类别不平衡，从而提高了漏洞检测的性能。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.17010v5",
      "published_date": "2024-01-30 13:46:49 UTC",
      "updated_date": "2024-07-27 11:22:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:33:09.487724"
    },
    {
      "arxiv_id": "2401.17342v2",
      "title": "A Latent Space Metric for Enhancing Prediction Confidence in Earth Observation Data",
      "title_zh": "翻译失败",
      "authors": [
        "Ioannis Pitsiorlas",
        "Argyro Tsantalidou",
        "George Arvanitakis",
        "Marios Kountouris",
        "Charalambos Kontoes"
      ],
      "abstract": "This study presents a new approach for estimating confidence in machine\nlearning model predictions, specifically in regression tasks utilizing Earth\nObservation (EO) data, with a particular focus on mosquito abundance (MA)\nestimation. We take advantage of a Variational AutoEncoder architecture, to\nderive a confidence metric by the latent space representations of EO datasets.\nThis methodology is pivotal in establishing a correlation between the Euclidean\ndistance in latent representations and the Absolute Error (AE) in individual MA\npredictions. Our research focuses on EO datasets from the Veneto region in\nItaly and the Upper Rhine Valley in Germany, targeting areas significantly\naffected by mosquito populations. A key finding is a notable correlation of\n0.46 between the AE of MA predictions and the proposed confidence metric. This\ncorrelation signifies a robust, new metric for quantifying the reliability and\nenhancing the trustworthiness of the AI model's predictions in the context of\nboth EO data analysis and mosquito abundance studies.",
      "tldr_zh": "本研究提出了一种基于潜在空间的指标，用于提升机器学习模型在回归任务中的预测置信度，特别针对Earth Observation (EO) 数据中的蚊虫丰度 (MA) 估计。方法利用Variational AutoEncoder (VAE) 架构，从EO数据集的潜在空间表示中计算欧氏距离，并将其与预测的Absolute Error (AE) 建立相关性。实验基于意大利Veneto地区和德国Upper Rhine Valley的EO数据集，结果显示AE与置信度指标的相关性达0.46，这为提高EO数据分析和MA研究的AI模型可靠性和可信度提供了新工具。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.17342v2",
      "published_date": "2024-01-30 13:41:12 UTC",
      "updated_date": "2024-06-11 08:00:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:33:21.303733"
    },
    {
      "arxiv_id": "2402.07913v2",
      "title": "QACP: An Annotated Question Answering Dataset for Assisting Chinese Python Programming Learners",
      "title_zh": "翻译失败",
      "authors": [
        "Rui Xiao",
        "Lu Han",
        "Xiaoying Zhou",
        "Jiong Wang",
        "Na Zong",
        "Pengyu Zhang"
      ],
      "abstract": "In online learning platforms, particularly in rapidly growing computer\nprogramming courses, addressing the thousands of students' learning queries\nrequires considerable human cost. The creation of intelligent assistant large\nlanguage models (LLMs) tailored for programming education necessitates distinct\ndata support. However, in real application scenarios, the data resources for\ntraining such LLMs are relatively scarce. Therefore, to address the data\nscarcity in intelligent educational systems for programming, this paper\nproposes a new Chinese question-and-answer dataset for Python learners. To\nensure the authenticity and reliability of the sources of the questions, we\ncollected questions from actual student questions and categorized them\naccording to various dimensions such as the type of questions and the type of\nlearners. This annotation principle is designed to enhance the effectiveness\nand quality of online programming education, providing a solid data foundation\nfor developing the programming teaching assists (TA). Furthermore, we conducted\ncomprehensive evaluations of various LLMs proficient in processing and\ngenerating Chinese content, highlighting the potential limitations of general\nLLMs as intelligent teaching assistants in computer programming courses.",
      "tldr_zh": "本论文引入了QACP数据集，这是一个针对中国Python编程学习者的注释式问答数据集，旨在解决在线编程教育中学生查询的资源不足问题。数据集从真实学生问题中收集，并根据问题类型（如技术疑问）和学习者类型进行分类，以确保数据的真实性和可靠性，从而为开发编程教学助手（TA）提供坚实的数据基础。该研究还评估了多种处理中文内容的LLMs，发现通用LLMs在编程教育场景中存在潜在局限性，如处理特定查询的准确性不足。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.07913v2",
      "published_date": "2024-01-30 13:11:23 UTC",
      "updated_date": "2024-02-23 02:35:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:33:32.065247"
    },
    {
      "arxiv_id": "2401.16982v1",
      "title": "ActDroid: An active learning framework for Android malware detection",
      "title_zh": "ActDroid：一种用于Android恶意软件检测的主动学习框架",
      "authors": [
        "Ali Muzaffar",
        "Hani Ragab Hassen",
        "Hind Zantout",
        "Michael A Lones"
      ],
      "abstract": "The growing popularity of Android requires malware detection systems that can\nkeep up with the pace of new software being released. According to a recent\nstudy, a new piece of malware appears online every 12 seconds. To address this,\nwe treat Android malware detection as a streaming data problem and explore the\nuse of active online learning as a means of mitigating the problem of labelling\napplications in a timely and cost-effective manner. Our resulting framework\nachieves accuracies of up to 96\\%, requires as little of 24\\% of the training\ndata to be labelled, and compensates for concept drift that occurs between the\nrelease and labelling of an application. We also consider the broader\npracticalities of online learning within Android malware detection, and\nsystematically explore the trade-offs between using different static, dynamic\nand hybrid feature sets to classify malware.",
      "tldr_zh": "本研究提出ActDroid框架，这是一种主动学习(active learning)方法，用于应对Android恶意软件检测的挑战，尤其是在新恶意软件每12秒出现一次的流数据环境中。该框架采用主动在线学习(active online learning)策略，仅需标记24%的训练数据，即可实现高达96%的检测准确率，并有效补偿概念漂移(concept drift)。此外，研究系统地探讨了使用不同静态(static)、动态(dynamic)和混合(hybrid)特征集的权衡，提供更高效且实用的恶意软件检测解决方案。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.16982v1",
      "published_date": "2024-01-30 13:10:33 UTC",
      "updated_date": "2024-01-30 13:10:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:33:44.835748"
    },
    {
      "arxiv_id": "2401.16974v1",
      "title": "CORE: Towards Scalable and Efficient Causal Discovery with Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Andreas W. M. Sauter",
        "Nicolò Botteghi",
        "Erman Acar",
        "Aske Plaat"
      ],
      "abstract": "Causal discovery is the challenging task of inferring causal structure from\ndata. Motivated by Pearl's Causal Hierarchy (PCH), which tells us that passive\nobservations alone are not enough to distinguish correlation from causation,\nthere has been a recent push to incorporate interventions into machine learning\nresearch. Reinforcement learning provides a convenient framework for such an\nactive approach to learning. This paper presents CORE, a deep reinforcement\nlearning-based approach for causal discovery and intervention planning. CORE\nlearns to sequentially reconstruct causal graphs from data while learning to\nperform informative interventions. Our results demonstrate that CORE\ngeneralizes to unseen graphs and efficiently uncovers causal structures.\nFurthermore, CORE scales to larger graphs with up to 10 variables and\noutperforms existing approaches in structure estimation accuracy and sample\nefficiency. All relevant code and supplementary material can be found at\nhttps://github.com/sa-and/CORE",
      "tldr_zh": "该论文针对因果发现（causal discovery）的挑战，提出了一种基于深度强化学习（deep reinforcement learning）的框架 CORE，以解决被动观察无法区分相关性和因果性的问题。CORE 通过学习顺序重建因果图并执行信息丰富的干预（interventions），实现了高效的因果结构发现和干预规划。实验结果显示，CORE 能泛化到未见图表，在规模达 10 个变量的更大图表上，准确性和样本效率均优于现有方法。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "I.2.6; I.2.8"
      ],
      "primary_category": "cs.LG",
      "comment": "To be published In Proc. of the 23rd International Conference on\n  Autonomous Agents and Multiagent Systems (AAMAS 2024), Auckland, New Zealand,\n  May 6 - 10, 2024, IFAAMAS",
      "pdf_url": "http://arxiv.org/pdf/2401.16974v1",
      "published_date": "2024-01-30 12:57:52 UTC",
      "updated_date": "2024-01-30 12:57:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:33:56.697711"
    },
    {
      "arxiv_id": "2401.16960v1",
      "title": "Two Heads Are Better Than One: Integrating Knowledge from Knowledge Graphs and Large Language Models for Entity Alignment",
      "title_zh": "翻译失败",
      "authors": [
        "Linyao Yang",
        "Hongyang Chen",
        "Xiao Wang",
        "Jing Yang",
        "Fei-Yue Wang",
        "Han Liu"
      ],
      "abstract": "Entity alignment, which is a prerequisite for creating a more comprehensive\nKnowledge Graph (KG), involves pinpointing equivalent entities across disparate\nKGs. Contemporary methods for entity alignment have predominantly utilized\nknowledge embedding models to procure entity embeddings that encapsulate\nvarious similarities-structural, relational, and attributive. These embeddings\nare then integrated through attention-based information fusion mechanisms.\nDespite this progress, effectively harnessing multifaceted information remains\nchallenging due to inherent heterogeneity. Moreover, while Large Language\nModels (LLMs) have exhibited exceptional performance across diverse downstream\ntasks by implicitly capturing entity semantics, this implicit knowledge has yet\nto be exploited for entity alignment. In this study, we propose a Large\nLanguage Model-enhanced Entity Alignment framework (LLMEA), integrating\nstructural knowledge from KGs with semantic knowledge from LLMs to enhance\nentity alignment. Specifically, LLMEA identifies candidate alignments for a\ngiven entity by considering both embedding similarities between entities across\nKGs and edit distances to a virtual equivalent entity. It then engages an LLM\niteratively, posing multiple multi-choice questions to draw upon the LLM's\ninference capability. The final prediction of the equivalent entity is derived\nfrom the LLM's output. Experiments conducted on three public datasets reveal\nthat LLMEA surpasses leading baseline models. Additional ablation studies\nunderscore the efficacy of our proposed framework.",
      "tldr_zh": "该研究提出了一种名为LLMEA的实体对齐框架，将知识图谱（KG）的结构知识与大语言模型（LLMs）的语义知识相结合，以解决传统方法在处理实体异质性时的挑战。具体来说，LLMEA通过计算实体嵌入相似性和编辑距离来识别候选对齐，然后利用LLMs进行迭代的多选问题推理，最终输出等价实体预测。实验结果显示，该框架在三个公共数据集上超越了领先基线模型，消融研究进一步验证了其有效性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.16960v1",
      "published_date": "2024-01-30 12:41:04 UTC",
      "updated_date": "2024-01-30 12:41:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:34:09.040187"
    },
    {
      "arxiv_id": "2402.01758v1",
      "title": "Aalap: AI Assistant for Legal & Paralegal Functions in India",
      "title_zh": "翻译失败",
      "authors": [
        "Aman Tiwari",
        "Prathamesh Kalamkar",
        "Atreyo Banerjee",
        "Saurabh Karn",
        "Varun Hemachandran",
        "Smita Gupta"
      ],
      "abstract": "Using proprietary Large Language Models on legal tasks poses challenges due\nto data privacy issues, domain data heterogeneity, domain knowledge\nsophistication, and domain objectives uniqueness. We created Aalalp, a\nfine-tuned Mistral 7B model on instructions data related to specific Indian\nlegal tasks. The performance of Aalap is better than gpt-3.5-turbo in 31\\% of\nour test data and obtains an equivalent score in 34\\% of the test data as\nevaluated by GPT4. Training Aalap mainly focuses on teaching legal reasoning\nrather than legal recall. Aalap is definitely helpful for the day-to-day\nactivities of lawyers, judges, or anyone working in legal systems.",
      "tldr_zh": "该研究针对使用专有 Large Language Models 在印度法律任务中的挑战（如数据隐私、领域数据异质性等），开发了 Aalap，这是一个基于 Mistral 7B 模型的微调版本，专注于特定印度法律指令数据。\nAalap 的训练强调法律推理而非简单回忆，使其在测试数据中表现突出：在 31% 的情况下优于 gpt-3.5-turbo，在 34% 的情况下与 gpt-3.5-turbo 相当，由 GPT4 评估。\nAalap 可以有效辅助律师、法官和其他法律从业者的日常活动，提供更可靠的法律支持。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.01758v1",
      "published_date": "2024-01-30 12:39:58 UTC",
      "updated_date": "2024-01-30 12:39:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:34:23.551639"
    },
    {
      "arxiv_id": "2402.07912v1",
      "title": "Spatial Computing: Concept, Applications, Challenges and Future Directions",
      "title_zh": "空间计算：概念、应用、挑战和未来方向",
      "authors": [
        "Gokul Yenduri",
        "Ramalingam M",
        "Praveen Kumar Reddy Maddikunta",
        "Thippa Reddy Gadekallu",
        "Rutvij H Jhaveri",
        "Ajay Bandi",
        "Junxin Chen",
        "Wei Wang",
        "Adarsh Arunkumar Shirawalmath",
        "Raghav Ravishankar",
        "Weizheng Wang"
      ],
      "abstract": "Spatial computing is a technological advancement that facilitates the\nseamless integration of devices into the physical environment, resulting in a\nmore natural and intuitive digital world user experience. Spatial computing has\nthe potential to become a significant advancement in the field of computing.\nFrom GPS and location-based services to healthcare, spatial computing\ntechnologies have influenced and improved our interactions with the digital\nworld. The use of spatial computing in creating interactive digital\nenvironments has become increasingly popular and effective. This is explained\nby its increasing significance among researchers and industrial organisations,\nwhich motivated us to conduct this review. This review provides a detailed\noverview of spatial computing, including its enabling technologies and its\nimpact on various applications. Projects related to spatial computing are also\ndiscussed. In this review, we also explored the potential challenges and\nlimitations of spatial computing. Furthermore, we discuss potential solutions\nand future directions. Overall, this paper aims to provide a comprehensive\nunderstanding of spatial computing, its enabling technologies, their impact on\nvarious applications, emerging challenges, and potential solutions.",
      "tldr_zh": "这篇论文综述了Spatial Computing的概念及其重要性，该技术通过将设备无缝整合到物理环境中，提供更自然直观的数字用户体验，并在GPS、位置服务和医疗等领域广泛应用。论文详细探讨了Spatial Computing的启用技术（如交互式数字环境）、对各种应用的影响，以及相关项目案例。作者还分析了潜在挑战和限制，并提出解决方案和未来方向，以期为全面理解Spatial Computing提供指导。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "Submitted to peer reviewe",
      "pdf_url": "http://arxiv.org/pdf/2402.07912v1",
      "published_date": "2024-01-30 11:47:12 UTC",
      "updated_date": "2024-01-30 11:47:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:34:32.527829"
    },
    {
      "arxiv_id": "2401.16889v2",
      "title": "Reinforcement Learning for Versatile, Dynamic, and Robust Bipedal Locomotion Control",
      "title_zh": "强化学习用于多功能、动态和鲁棒的双足机器人运动控制",
      "authors": [
        "Zhongyu Li",
        "Xue Bin Peng",
        "Pieter Abbeel",
        "Sergey Levine",
        "Glen Berseth",
        "Koushil Sreenath"
      ],
      "abstract": "This paper presents a comprehensive study on using deep reinforcement\nlearning (RL) to create dynamic locomotion controllers for bipedal robots.\nGoing beyond focusing on a single locomotion skill, we develop a general\ncontrol solution that can be used for a range of dynamic bipedal skills, from\nperiodic walking and running to aperiodic jumping and standing. Our RL-based\ncontroller incorporates a novel dual-history architecture, utilizing both a\nlong-term and short-term input/output (I/O) history of the robot. This control\narchitecture, when trained through the proposed end-to-end RL approach,\nconsistently outperforms other methods across a diverse range of skills in both\nsimulation and the real world. The study also delves into the adaptivity and\nrobustness introduced by the proposed RL system in developing locomotion\ncontrollers. We demonstrate that the proposed architecture can adapt to both\ntime-invariant dynamics shifts and time-variant changes, such as contact\nevents, by effectively using the robot's I/O history. Additionally, we identify\ntask randomization as another key source of robustness, fostering better task\ngeneralization and compliance to disturbances. The resulting control policies\ncan be successfully deployed on Cassie, a torque-controlled human-sized bipedal\nrobot. This work pushes the limits of agility for bipedal robots through\nextensive real-world experiments. We demonstrate a diverse range of locomotion\nskills, including: robust standing, versatile walking, fast running with a\ndemonstration of a 400-meter dash, and a diverse set of jumping skills, such as\nstanding long jumps and high jumps.",
      "tldr_zh": "这篇论文使用深度强化学习 (RL) 开发了一个通用动态步行控制器，适用于双足机器人从周期性步行、奔跑到非周期性跳跃和站立的多种技能。提出的双历史架构 (dual-history architecture) 结合了机器人的长期和短期输入/输出 (I/O) 历史，通过端到端 RL 训练方法，在模拟和现实环境中显著超越其他控制器。研究强调了 RL 系统的适应性和鲁棒性，能够有效应对时间不变动态变化、接触事件以及干扰，任务随机化 (task randomization) 进一步提升了任务泛化和稳定性。最后，该控制器在 Cassie 机器人上成功部署，展示了包括稳固站立、灵活步行、400米冲刺和多种跳跃技能在内的多样化性能。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.RO",
      "comment": "Accepted in International Journal of Robotics Research (IJRR) 2024.\n  This is the author's version and will no longer be updated as the copyright\n  may get transferred at anytime",
      "pdf_url": "http://arxiv.org/pdf/2401.16889v2",
      "published_date": "2024-01-30 10:48:43 UTC",
      "updated_date": "2024-08-26 06:51:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:34:46.981784"
    },
    {
      "arxiv_id": "2403.08790v1",
      "title": "Using Sequential Runtime Distributions for the Parallel Speedup Prediction of SAT Local Search",
      "title_zh": "翻译失败",
      "authors": [
        "Alejandro Arbelaez",
        "Charlotte Truchet",
        "Philippe Codognet"
      ],
      "abstract": "This paper presents a detailed analysis of the scalability and\nparallelization of local search algorithms for the Satisfiability problem. We\npropose a framework to estimate the parallel performance of a given algorithm\nby analyzing the runtime behavior of its sequential version. Indeed, by\napproximating the runtime distribution of the sequential process with\nstatistical methods, the runtime behavior of the parallel process can be\npredicted by a model based on order statistics. We apply this approach to study\nthe parallel performance of two SAT local search solvers, namely Sparrow and\nCCASAT, and compare the predicted performances to the results of an actual\nexperimentation on parallel hardware up to 384 cores. We show that the model is\naccurate and predicts performance close to the empirical data. Moreover, as we\nstudy different types of instances (random and crafted), we observe that the\nlocal search solvers exhibit different behaviors and that their runtime\ndistributions can be approximated by two types of distributions: exponential\n(shifted and non-shifted) and lognormal.",
      "tldr_zh": "本文提出一个框架，通过分析顺序运行时分布（runtime distributions）来预测 SAT 本地搜索（SAT local search）算法的并行加速性能。具体方法使用统计方法近似顺序过程的运行时分布，并基于顺序统计学（order statistics）模型进行预测。实验应用于 Sparrow 和 CCASAT 求解器，在多达 384 核的并行硬件上进行验证，结果显示模型预测准确，与实证数据高度一致。此外，研究发现不同实例类型（如随机和手工制作）的运行时分布可近似为指数分布（exponential, shifted 和 non-shifted）和对数正态分布（lognormal）。",
      "categories": [
        "cs.DC",
        "cs.AI"
      ],
      "primary_category": "cs.DC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.08790v1",
      "published_date": "2024-01-30 10:29:01 UTC",
      "updated_date": "2024-01-30 10:29:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:34:58.800615"
    },
    {
      "arxiv_id": "2401.16867v1",
      "title": "A Tournament of Transformation Models: B-Spline-based vs. Mesh-based Multi-Objective Deformable Image Registration",
      "title_zh": "翻译失败",
      "authors": [
        "Georgios Andreadis",
        "Joas I. Mulder",
        "Anton Bouter",
        "Peter A. N. Bosman",
        "Tanja Alderliesten"
      ],
      "abstract": "The transformation model is an essential component of any deformable image\nregistration approach. It provides a representation of physical deformations\nbetween images, thereby defining the range and realism of registrations that\ncan be found. Two types of transformation models have emerged as popular\nchoices: B-spline models and mesh models. Although both models have been\ninvestigated in detail, a direct comparison has not yet been made, since the\nmodels are optimized using very different optimization methods in practice.\nB-spline models are predominantly optimized using gradient-descent methods,\nwhile mesh models are typically optimized using finite-element method solvers\nor evolutionary algorithms. Multi-objective optimization methods, which aim to\nfind a diverse set of high-quality trade-off registrations, are increasingly\nacknowledged to be important in deformable image registration. Since these\nmethods search for a diverse set of registrations, they can provide a more\ncomplete picture of the capabilities of different transformation models, making\nthem suitable for a comparison of models. In this work, we conduct the first\ndirect comparison between B-spline and mesh transformation models, by\noptimizing both models with the same state-of-the-art multi-objective\noptimization method, the Multi-Objective Real-Valued Gene-pool Optimal Mixing\nEvolutionary Algorithm (MO-RV-GOMEA). The combination with B-spline\ntransformation models, moreover, is novel. We experimentally compare both\nmodels on two different registration problems that are both based on pelvic CT\nscans of cervical cancer patients, featuring large deformations. Our results,\non three cervical cancer patients, indicate that the choice of transformation\nmodel can have a profound impact on the diversity and quality of achieved\nregistration outcomes.",
      "tldr_zh": "本研究比较了两种变形图像配准的变换模型：B-spline-based模型和mesh-based模型，旨在评估它们在多目标优化下的性能差异。研究首次使用相同的先进算法Multi-Objective Real-Valued Gene-pool Optimal Mixing Evolutionary Algorithm (MO-RV-GOMEA)来优化两种模型，其中B-spline模型与该算法的结合是新颖的。实验基于颈癌患者盆腔CT扫描的两个注册问题，结果显示变换模型的选择对注册结果的多样性和质量有显著影响，突显了模型在处理大变形时的关键作用。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.NE"
      ],
      "primary_category": "cs.CV",
      "comment": "Pre-print for the SPIE Medical Imaging: Image Processing Conference",
      "pdf_url": "http://arxiv.org/pdf/2401.16867v1",
      "published_date": "2024-01-30 10:17:46 UTC",
      "updated_date": "2024-01-30 10:17:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:35:09.191529"
    },
    {
      "arxiv_id": "2403.08789v1",
      "title": "Bridging Human Concepts and Computer Vision for Explainable Face Verification",
      "title_zh": "翻译失败",
      "authors": [
        "Miriam Doh",
        "Caroline Mazini Rodrigues",
        "Nicolas Boutry",
        "Laurent Najman",
        "Matei Mancas",
        "Hugues Bersini"
      ],
      "abstract": "With Artificial Intelligence (AI) influencing the decision-making process of\nsensitive applications such as Face Verification, it is fundamental to ensure\nthe transparency, fairness, and accountability of decisions. Although\nExplainable Artificial Intelligence (XAI) techniques exist to clarify AI\ndecisions, it is equally important to provide interpretability of these\ndecisions to humans. In this paper, we present an approach to combine computer\nand human vision to increase the explanation's interpretability of a face\nverification algorithm. In particular, we are inspired by the human perceptual\nprocess to understand how machines perceive face's human-semantic areas during\nface comparison tasks. We use Mediapipe, which provides a segmentation\ntechnique that identifies distinct human-semantic facial regions, enabling the\nmachine's perception analysis. Additionally, we adapted two model-agnostic\nalgorithms to provide human-interpretable insights into the decision-making\nprocesses.",
      "tldr_zh": "该论文旨在通过融合人类概念和计算机视觉，提升人脸验证算法的解释性（Explainable Artificial Intelligence, XAI），以确保AI决策的透明性、公平性和可问责性。研究受人类感知过程启发，使用Mediapipe进行人脸语义区域分割，从而分析机器在人脸比较任务中对这些区域的感知。作者还适应了两个模型无关的算法，提供人类可解读的决策洞见。这种方法有助于桥接AI与人类理解的差距，在敏感应用中提升解释的可靠性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.HC",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.08789v1",
      "published_date": "2024-01-30 09:13:49 UTC",
      "updated_date": "2024-01-30 09:13:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:35:21.633460"
    },
    {
      "arxiv_id": "2402.03362v1",
      "title": "NanoNER: Named Entity Recognition for nanobiology using experts' knowledge and distant supervision",
      "title_zh": "翻译失败",
      "authors": [
        "Martin Lentschat",
        "Cyril Labbé",
        "Ran Cheng"
      ],
      "abstract": "Here we present the training and evaluation of NanoNER, a Named Entity\nRecognition (NER) model for Nanobiology. NER consists in the identification of\nspecific entities in spans of unstructured texts and is often a primary task in\nNatural Language Processing (NLP) and Information Extraction. The aim of our\nmodel is to recognise entities previously identified by domain experts as\nconstituting the essential knowledge of the domain. Relying on ontologies,\nwhich provide us with a domain vocabulary and taxonomy, we implemented an\niterative process enabling experts to determine the entities relevant to the\ndomain at hand. We then delve into the potential of distant supervision\nlearning in NER, supporting how this method can increase the quantity of\nannotated data with minimal additional manpower. On our full corpus of 728\nfull-text nanobiology articles, containing more than 120k entity occurrences,\nNanoNER obtained a F1-score of 0.98 on the recognition of previously known\nentities. Our model also demonstrated its ability to discover new entities in\nthe text, with precision scores ranging from 0.77 to 0.81. Ablation experiments\nfurther confirmed this and allowed us to assess the dependency of our approach\non the external resources. It highlighted the dependency of the approach to the\nresource, while also confirming its ability to rediscover up to 30% of the\nablated terms. This paper details the methodology employed, experimental\ndesign, and key findings, providing valuable insights and directions for future\nrelated researches on NER in specialized domain. Furthermore, since our\napproach require minimal manpower , we believe that it can be generalized to\nother specialized fields.",
      "tldr_zh": "这篇论文介绍了 NanoNER，一种基于专家知识和 distant supervision 的 Named Entity Recognition (NER) 模型，专门用于纳米生物学领域。模型利用 ontologies 提供的词汇和分类，通过迭代过程由专家确定相关实体，并采用 distant supervision 来高效增加标注数据，从而减少人力需求。在包含 728 篇全文文章和超过 12 万实体实例的语料库上，NanoNER 实现了 0.98 的 F1-score，并在发现新实体时达到 0.77-0.81 的精确度。消融实验 (ablation experiments) 验证了方法的依赖性和鲁棒性，证明其能重新发现高达 30% 的实体，并为其他专业领域的 NER 研究提供可推广的见解。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.03362v1",
      "published_date": "2024-01-30 09:10:53 UTC",
      "updated_date": "2024-01-30 09:10:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:35:34.620524"
    },
    {
      "arxiv_id": "2403.08788v1",
      "title": "Verification for Object Detection -- IBP IoU",
      "title_zh": "对象检测验证 -- IBP IoU",
      "authors": [
        "Noémie Cohen",
        "Mélanie Ducoffe",
        "Ryma Boumazouza",
        "Christophe Gabreau",
        "Claire Pagetti",
        "Xavier Pucel",
        "Audrey Galametz"
      ],
      "abstract": "We introduce a novel Interval Bound Propagation (IBP) approach for the formal\nverification of object detection models, specifically targeting the\nIntersection over Union (IoU) metric. The approach has been implemented in an\nopen source code, named IBP IoU, compatible with popular abstract\ninterpretation based verification tools. The resulting verifier is evaluated on\nlanding approach runway detection and handwritten digit recognition case\nstudies. Comparisons against a baseline (Vanilla IBP IoU) highlight the\nsuperior performance of IBP IoU in ensuring accuracy and stability,\ncontributing to more secure and robust machine learning applications.",
      "tldr_zh": "本研究引入了一种新的 Interval Bound Propagation (IBP) 方法，名为 IBP IoU，用于正式验证对象检测模型的准确性，特别针对 Intersection over Union (IoU) 指标。该方法以开源代码形式实现，并兼容流行的抽象解释验证工具，在着陆进场跑道检测和手写数字识别案例中进行了评估。与基线模型 Vanilla IBP IoU 相比，IBP IoU 显示出更高的准确性和稳定性，从而提升了机器学习应用的可靠性和安全性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.NE"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.08788v1",
      "published_date": "2024-01-30 09:05:38 UTC",
      "updated_date": "2024-01-30 09:05:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:35:44.990056"
    },
    {
      "arxiv_id": "2402.07911v1",
      "title": "Does mapping elites illuminate search spaces? A large-scale user study of MAP--Elites applied to human--AI collaborative design",
      "title_zh": "翻译失败",
      "authors": [
        "Sean P. Walton",
        "Ben J. Evans",
        "Alma A. M. Rahat",
        "James Stovold",
        "Jakub Vincalek"
      ],
      "abstract": "Two studies of a human-AI collaborative design tool were carried out in order\nto understand the influence design recommendations have on the design process.\nThe tool investigated is based on an evolutionary algorithm attempting to\ndesign a virtual car to travel as far as possible in a fixed time. Participants\nwere able to design their own cars, make recommendations to the algorithm and\nview sets of recommendations from the algorithm. The algorithm-recommended sets\nwere designs which had been previously tested; some sets were simply randomly\npicked and other sets were picked using MAP-Elites. In the first study 808\ndesign sessions were recorded as part of a science outreach program, each with\nanalytical data of how each participant used the tool. To provide context to\nthis quantitative data, a smaller double-blind lab study was also carried out\nwith 12 participants. In the lab study the same quantitative data from the\nlarge scale study was collected alongside responses to interview questions.\nAlthough there is some evidence that the MAP-Elites provide higher-quality\nindividual recommendations, neither study provides convincing evidence that\nthese recommendations have a more positive influence on the design process than\nsimply a random selection of designs. In fact, it seems that providing a\ncombination of MAP-Elites and randomly selected recommendations is beneficial\nto the process. Furthermore, simply viewing recommendations from the MAP-Elites\nhad a positive influence on engagement in the design task and the quality of\nthe final design produced. Our findings are significant both for researchers\ndesigning new mixed-initiative tools, and those who wish to evaluate existing\ntools. Most significantly, we found that metrics researchers currently use to\nevaluate the success of human-AI collaborative algorithms do not measure the\nfull influence these algorithms have on the design process.",
      "tldr_zh": "这篇论文通过大规模用户研究（包括808个设计会话）和小型实验室实验，评估了MAP-Elites算法在人类-AI协作设计工具中的作用，该工具基于进化算法用于设计虚拟汽车。研究发现，虽然MAP-Elites提供更高质量的单个推荐，但它对设计过程的整体影响并不优于随机选择的推荐；相反，结合MAP-Elites和随机推荐能更有效地提升参与度和最终设计质量。主要贡献在于揭示了现有评估人类-AI协作算法的指标（如推荐质量）未能全面捕捉其对设计过程的真实影响，为改进混合主动工具提供新见解。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CE",
        "cs.NE",
        "I.2.0; J.6; G.1.6"
      ],
      "primary_category": "cs.HC",
      "comment": "17 pages",
      "pdf_url": "http://arxiv.org/pdf/2402.07911v1",
      "published_date": "2024-01-30 08:54:46 UTC",
      "updated_date": "2024-01-30 08:54:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:35:58.598911"
    },
    {
      "arxiv_id": "2402.09442v3",
      "title": "Progress in artificial intelligence applications based on the combination of self-driven sensors and deep learning",
      "title_zh": "基于自驱动传感器与深度学习的结合的人工智能应用进展",
      "authors": [
        "Weixiang Wan",
        "Wenjian Sun",
        "Qiang Zeng",
        "Linying Pan",
        "Jingyu Xu",
        "Bo Liu"
      ],
      "abstract": "In the era of Internet of Things, how to develop a smart sensor system with\nsustainable power supply, easy deployment and flexible use has become a\ndifficult problem to be solved. The traditional power supply has problems such\nas frequent replacement or charging when in use, which limits the development\nof wearable devices. The contact-to-separate friction nanogenerator (TENG) was\nprepared by using polychotomy thy lene (PTFE) and aluminum (AI) foils. Human\nmotion energy was collected by human body arrangement, and human motion posture\nwas monitored according to the changes of output electrical signals. In 2012,\nAcademician Wang Zhong lin and his team invented the triboelectric\nnanogenerator (TENG), which uses Maxwell displacement current as a driving\nforce to directly convert mechanical stimuli into electrical signals, so it can\nbe used as a self-driven sensor. Teng-based sensors have the advantages of\nsimple structure and high instantaneous power density, which provides an\nimportant means for building intelligent sensor systems. At the same time,\nmachine learning, as a technology with low cost, short development cycle,\nstrong data processing ability and prediction ability, has a significant effect\non the processing of a large number of electrical signals generated by TENG,\nand the combination with TENG sensors will promote the rapid development of\nintelligent sensor networks in the future. Therefore, this paper is based on\nthe intelligent sound monitoring and recognition system of TENG, which has good\nsound recognition capability, and aims to evaluate the feasibility of the sound\nperception module architecture in ubiquitous sensor networks.",
      "tldr_zh": "本论文探讨了物联网（Internet of Things）时代中，自驱动传感器与深度学习的结合在人工智能应用中的进展，旨在解决传统供电问题（如频繁更换或充电）对智能传感器系统部署的限制。论文介绍了摩擦纳米发电机（TENG），其利用聚四氟乙烯（PTFE）和铝箔收集人体运动能量，并通过输出电信号监控姿势，具备简单结构和高瞬时功率密度的优势。TENG 与机器学习相结合，可高效处理大量电信号，推动智能传感器网络的发展；具体而言，论文基于 TENG 构建了一个智能声音监测和识别系统，以评估其在泛在传感器网络中的可行性。实验结果表明，这种集成方法为可持续、可穿戴设备的开发提供了重要途径。",
      "categories": [
        "eess.SP",
        "cs.AI"
      ],
      "primary_category": "eess.SP",
      "comment": "This aticle was accepted by ieee conference",
      "pdf_url": "http://arxiv.org/pdf/2402.09442v3",
      "published_date": "2024-01-30 08:53:54 UTC",
      "updated_date": "2024-03-12 11:14:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:36:09.796677"
    },
    {
      "arxiv_id": "2403.09669v3",
      "title": "STREAM: Spatio-TempoRal Evaluation and Analysis Metric for Video Generative Models",
      "title_zh": "翻译失败",
      "authors": [
        "Pum Jun Kim",
        "Seojun Kim",
        "Jaejun Yoo"
      ],
      "abstract": "Image generative models have made significant progress in generating\nrealistic and diverse images, supported by comprehensive guidance from various\nevaluation metrics. However, current video generative models struggle to\ngenerate even short video clips, with limited tools that provide insights for\nimprovements. Current video evaluation metrics are simple adaptations of image\nmetrics by switching the embeddings with video embedding networks, which may\nunderestimate the unique characteristics of video. Our analysis reveals that\nthe widely used Frechet Video Distance (FVD) has a stronger emphasis on the\nspatial aspect than the temporal naturalness of video and is inherently\nconstrained by the input size of the embedding networks used, limiting it to 16\nframes. Additionally, it demonstrates considerable instability and diverges\nfrom human evaluations. To address the limitations, we propose STREAM, a new\nvideo evaluation metric uniquely designed to independently evaluate spatial and\ntemporal aspects. This feature allows comprehensive analysis and evaluation of\nvideo generative models from various perspectives, unconstrained by video\nlength. We provide analytical and experimental evidence demonstrating that\nSTREAM provides an effective evaluation tool for both visual and temporal\nquality of videos, offering insights into area of improvement for video\ngenerative models. To the best of our knowledge, STREAM is the first evaluation\nmetric that can separately assess the temporal and spatial aspects of videos.\nOur code is available at https://github.com/pro2nit/STREAM.",
      "tldr_zh": "该研究指出现有视频生成模型的评估指标（如 Frechet Video Distance, FVD）过度强调空间特性而忽略时间自然性，且受限于嵌入网络输入（仅16帧），导致稳定性差和与人类评估不一致。作者提出 STREAM，一种新型视频评估指标，能够独立评估视频的空间和时间方面，提供不受视频长度限制的全面分析。实验证据表明，STREAM 有效评估视觉和时间质量，并为视频生成模型的改进提供宝贵洞见；据知，这是首个能单独评估视频时空特性的指标。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Our work is accepted to ICLR 2024",
      "pdf_url": "http://arxiv.org/pdf/2403.09669v3",
      "published_date": "2024-01-30 08:18:20 UTC",
      "updated_date": "2024-03-28 04:45:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:36:22.413857"
    },
    {
      "arxiv_id": "2401.16808v3",
      "title": "Encoding Temporal Statistical-space Priors via Augmented Representation",
      "title_zh": "翻译失败",
      "authors": [
        "Insu Choi",
        "Woosung Koh",
        "Gimin Kang",
        "Yuntae Jang",
        "Woo Chang Kim"
      ],
      "abstract": "Modeling time series data remains a pervasive issue as the temporal dimension\nis inherent to numerous domains. Despite significant strides in time series\nforecasting, high noise-to-signal ratio, non-normality, non-stationarity, and\nlack of data continue challenging practitioners. In response, we leverage a\nsimple representation augmentation technique to overcome these challenges. Our\naugmented representation acts as a statistical-space prior encoded at each time\nstep. In response, we name our method Statistical-space Augmented\nRepresentation (SSAR). The underlying high-dimensional data-generating process\ninspires our representation augmentation. We rigorously examine the empirical\ngeneralization performance on two data sets with two downstream temporal\nlearning algorithms. Our approach significantly beats all five up-to-date\nbaselines. Moreover, the highly modular nature of our approach can easily be\napplied to various settings. Lastly, fully-fledged theoretical perspectives are\navailable throughout the writing for a clear and rigorous understanding.",
      "tldr_zh": "本论文针对时间序列数据建模面临的挑战，如高噪声比、非正态性、非平稳性和数据不足，提出了一种简单的表示增强技术，名为Statistical-space Augmented Representation (SSAR)。SSAR通过在每个时间步编码统计空间先验，模拟高维数据生成过程，从而提升模型的鲁棒性和泛化能力。在两个数据集上与两种下游时间学习算法的实验中，SSAR显著优于五个最新基线模型，并展示了高度模块化的特性，便于应用于各种场景，同时提供了全面的理论分析以支持其有效性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "IJCAI 2024 STRL Workshop (Oral)",
      "pdf_url": "http://arxiv.org/pdf/2401.16808v3",
      "published_date": "2024-01-30 08:11:36 UTC",
      "updated_date": "2024-08-12 06:36:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:36:33.904217"
    },
    {
      "arxiv_id": "2402.01752v1",
      "title": "Identifying False Content and Hate Speech in Sinhala YouTube Videos by Analyzing the Audio",
      "title_zh": "通过分析音频识别 Sinhala YouTube 视频中的虚假内容和仇恨言论",
      "authors": [
        "W. A. K. M. Wickramaarachchi",
        "Sameeri Sathsara Subasinghe",
        "K. K. Rashani Tharushika Wijerathna",
        "A. Sahashra Udani Athukorala",
        "Lakmini Abeywardhana",
        "A. Karunasena"
      ],
      "abstract": "YouTube faces a global crisis with the dissemination of false information and\nhate speech. To counter these issues, YouTube has implemented strict rules\nagainst uploading content that includes false information or promotes hate\nspeech. While numerous studies have been conducted to reduce offensive\nEnglish-language content, there's a significant lack of research on Sinhala\ncontent. This study aims to address the aforementioned gap by proposing a\nsolution to minimize the spread of violence and misinformation in Sinhala\nYouTube videos. The approach involves developing a rating system that assesses\nwhether a video contains false information by comparing the title and\ndescription with the audio content and evaluating whether the video includes\nhate speech. The methodology encompasses several steps, including audio\nextraction using the Pytube library, audio transcription via the fine-tuned\nWhisper model, hate speech detection employing the distilroberta-base model and\na text classification LSTM model, and text summarization through the fine-tuned\nBART-Large- XSUM model. Notably, the Whisper model achieved a 48.99\\% word\nerror rate, while the distilroberta-base model demonstrated an F1 score of\n0.856 and a recall value of 0.861 in comparison to the LSTM model, which\nexhibited signs of overfitting.",
      "tldr_zh": "本研究针对 YouTube 上 Sinhala 语言视频的虚假信息和仇恨言论问题，提出了一种基于音频分析的评分系统，通过比较视频标题、描述与音频内容来检测虚假信息，并使用 distilroberta-base 模型和 LSTM 模型评估仇恨言论，同时结合 fine-tuned Whisper 模型进行音频转录和 fine-tuned BART-Large-XSUM 模型进行文本总结。方法涉及使用 Pytube 库提取音频，并细化相关模型以优化性能。实验结果显示，Whisper 模型的词错误率为 48.99%，distilroberta-base 模型的 F1 分数为 0.856 和召回率为 0.861，而 LSTM 模型表现出过拟合迹象，这为减少 Sinhala 内容中的 misinformation 和 hate speech 提供了有效工具。",
      "categories": [
        "eess.AS",
        "cs.AI",
        "cs.CL",
        "cs.LG",
        "cs.SD"
      ],
      "primary_category": "eess.AS",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.01752v1",
      "published_date": "2024-01-30 08:08:34 UTC",
      "updated_date": "2024-01-30 08:08:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:36:48.172012"
    },
    {
      "arxiv_id": "2401.16807v2",
      "title": "Detecting LLM-Assisted Writing in Scientific Communication: Are We There Yet?",
      "title_zh": "检测科学交流中的LLM辅助写作：我们已经做到了吗？",
      "authors": [
        "Teddy Lazebnik",
        "Ariel Rosenfeld"
      ],
      "abstract": "Large Language Models (LLMs), exemplified by ChatGPT, have significantly\nreshaped text generation, particularly in the realm of writing assistance.\nWhile ethical considerations underscore the importance of transparently\nacknowledging LLM use, especially in scientific communication, genuine\nacknowledgment remains infrequent. A potential avenue to encourage accurate\nacknowledging of LLM-assisted writing involves employing automated detectors.\nOur evaluation of four cutting-edge LLM-generated text detectors reveals their\nsuboptimal performance compared to a simple ad-hoc detector designed to\nidentify abrupt writing style changes around the time of LLM proliferation. We\ncontend that the development of specialized detectors exclusively dedicated to\nLLM-assisted writing detection is necessary. Such detectors could play a\ncrucial role in fostering more authentic recognition of LLM involvement in\nscientific communication, addressing the current challenges in acknowledgment\npractices.",
      "tldr_zh": "大语言模型（LLMs）如 ChatGPT 显著改变了写作辅助，但科学交流中对其使用缺乏透明承认。研究评估了四种先进的 LLM 生成文本检测器，发现它们不如一个简单的 ad-hoc 检测器（识别 LLM 普及前后写作风格的突然变化）表现更优。作者主张开发专用检测器，以鼓励更真实的 LLM 辅助写作承认，从而提升科学通信的诚信性。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.16807v2",
      "published_date": "2024-01-30 08:07:28 UTC",
      "updated_date": "2024-07-05 14:19:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:36:57.907732"
    },
    {
      "arxiv_id": "2402.01751v1",
      "title": "Performance Assessment of ChatGPT vs Bard in Detecting Alzheimer's Dementia",
      "title_zh": "翻译失败",
      "authors": [
        "Balamurali B T",
        "Jer-Ming Chen"
      ],
      "abstract": "Large language models (LLMs) find increasing applications in many fields.\nHere, three LLM chatbots (ChatGPT-3.5, ChatGPT-4 and Bard) are assessed - in\ntheir current form, as publicly available - for their ability to recognize\nAlzheimer's Dementia (AD) and Cognitively Normal (CN) individuals using textual\ninput derived from spontaneous speech recordings. Zero-shot learning approach\nis used at two levels of independent queries, with the second query\n(chain-of-thought prompting) eliciting more detailed than the first. Each LLM\nchatbot's performance is evaluated on the prediction generated in terms of\naccuracy, sensitivity, specificity, precision and F1 score. LLM chatbots\ngenerated three-class outcome (\"AD\", \"CN\", or \"Unsure\"). When positively\nidentifying AD, Bard produced highest true-positives (89% recall) and highest\nF1 score (71%), but tended to misidentify CN as AD, with high confidence (low\n\"Unsure\" rates); for positively identifying CN, GPT-4 resulted in the highest\ntrue-negatives at 56% and highest F1 score (62%), adopting a diplomatic stance\n(moderate \"Unsure\" rates). Overall, three LLM chatbots identify AD vs CN\nsurpassing chance-levels but do not currently satisfy clinical application.",
      "tldr_zh": "本文评估了 ChatGPT-3.5、ChatGPT-4 和 Bard 等大型语言模型（LLMs）在检测 Alzheimer's Dementia (AD) 和 Cognitively Normal (CN) 个体方面的性能，使用零-shot learning 和 chain-of-thought prompting 从文本输入中进行识别。结果显示，Bard 在 AD 检测中表现出色，具有最高的真正例回召率（89%）和 F1 score（71%），但容易将 CN 误判为 AD；反之，ChatGPT-4 在 CN 检测中表现最佳，F1 score 达62%。总体而言，三者均超过了随机水平，但准确性不足以满足临床应用需求。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "22 pages",
      "pdf_url": "http://arxiv.org/pdf/2402.01751v1",
      "published_date": "2024-01-30 07:55:43 UTC",
      "updated_date": "2024-01-30 07:55:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:37:12.188252"
    },
    {
      "arxiv_id": "2402.10224v1",
      "title": "Human-Centric Goal Reasoning with Ripple-Down Rules",
      "title_zh": "翻译失败",
      "authors": [
        "Kenji Brameld",
        "Germán Castro",
        "Claude Sammut",
        "Mark Roberts",
        "David W. Aha"
      ],
      "abstract": "ActorSim is a goal reasoning framework developed at the Naval Research\nLaboratory. Originally, all goal reasoning rules were hand-crafted. This work\nextends ActorSim with the capability of learning by demonstration, that is,\nwhen a human trainer disagrees with a decision made by the system, the trainer\ncan take over and show the system the correct decision. The learning component\nuses Ripple-Down Rules (RDR) to build new decision rules to correctly handle\nsimilar cases in the future. The system is demonstrated using the RoboCup\nRescue Agent Simulation, which simulates a city-wide disaster, requiring\nemergency services, including fire, ambulance and police, to be dispatched to\ndifferent sites to evacuate civilians from dangerous situations. The RDRs are\nimplemented in a scripting language, FrameScript, which is used to mediate\nbetween ActorSim and the agent simulator. Using Ripple-Down Rules, ActorSim can\nscale to an order of magnitude more goals than the previous version.",
      "tldr_zh": "本研究扩展了 ActorSim 框架，引入人类中心的目标推理（Human-Centric Goal Reasoning），允许系统通过学习由演示（learning by demonstration）来改进决策，当人类训练者不同意系统决定时，可接管并教导正确行为。方法采用 Ripple-Down Rules (RDR) 来构建新规则，从而处理类似场景，确保未来决策更准确。该框架在 RoboCup Rescue Agent Simulation 中进行演示，模拟城市灾害和紧急服务调度，结果显示 ActorSim 能够处理比之前多一个数量级的目标，提升了系统的可扩展性和实用性。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.RO",
      "comment": "Proceedings of the Ninth Goal Reasoning Workshop (Advances in\n  Cognitive Systems, 2021)",
      "pdf_url": "http://arxiv.org/pdf/2402.10224v1",
      "published_date": "2024-01-30 07:52:38 UTC",
      "updated_date": "2024-01-30 07:52:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:37:21.585555"
    },
    {
      "arxiv_id": "2401.16795v1",
      "title": "Performance Insights-based AI-driven Football Transfer Fee Prediction",
      "title_zh": "翻译失败",
      "authors": [
        "Daniil Sulimov"
      ],
      "abstract": "We developed an artificial intelligence approach to predict the transfer fee\nof a football player. This model can help clubs make better decisions about\nwhich players to buy and sell, which can lead to improved performance and\nincreased club budgets. Having collected data on player performance, transfer\nfees, and other factors that might affect a player's value, we then used this\ndata to train a machine learning model that can accurately predict a player's\nimpact on the game. We further passed the obtained results as one of the\nfeatures to the predictor of transfer fees. The model can help clubs identify\nplayers who are undervalued and who could be sold for a profit. It can also\nhelp clubs avoid overpaying for players. We believe that our model can be a\nvaluable tool for football clubs. It can help them make better decisions about\nplayer recruitment and transfers.",
      "tldr_zh": "本研究开发了一种基于AI的模型，用于预测足球球员的转会费，旨在帮助俱乐部优化球员买卖决策。该模型通过收集球员表现数据、转会费和其他影响因素，训练机器学习模型来评估球员对比赛的影响，并将这些评估结果作为特征输入转会费预测器。实验结果表明，该模型能有效识别undervalued球员并避免overpaying，从而提升俱乐部预算和整体表现。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "68T99"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.16795v1",
      "published_date": "2024-01-30 07:16:09 UTC",
      "updated_date": "2024-01-30 07:16:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:37:33.754897"
    },
    {
      "arxiv_id": "2401.16788v1",
      "title": "Can Large Language Models be Trusted for Evaluation? Scalable Meta-Evaluation of LLMs as Evaluators via Agent Debate",
      "title_zh": "翻译失败",
      "authors": [
        "Steffi Chern",
        "Ethan Chern",
        "Graham Neubig",
        "Pengfei Liu"
      ],
      "abstract": "Despite the utility of Large Language Models (LLMs) across a wide range of\ntasks and scenarios, developing a method for reliably evaluating LLMs across\nvaried contexts continues to be challenging. Modern evaluation approaches often\nuse LLMs to assess responses generated by LLMs. However, the meta-evaluation\nconducted to assess the effectiveness of these LLMs as evaluators is typically\nconstrained by the coverage of existing benchmarks or requires extensive human\nannotation. This underscores the urgency of methods for scalable\nmeta-evaluation that can effectively, reliably, and efficiently evaluate the\nperformance of LLMs as evaluators across diverse tasks and scenarios,\nparticularly in potentially new, user-defined scenarios. To fill this gap, we\npropose ScaleEval, an agent-debate-assisted meta-evaluation framework that\nleverages the capabilities of multiple communicative LLM agents. This framework\nsupports multi-round discussions to assist human annotators in discerning the\nmost capable LLMs as evaluators, which significantly eases their workload in\ncases that used to require large-scale annotations during meta-evaluation. We\nrelease the code for our framework, which is publicly available at:\n\\url{https://github.com/GAIR-NLP/scaleeval}.",
      "tldr_zh": "这篇论文探讨了 Large Language Models (LLMs) 作为评估者的可信度问题，提出 ScaleEval 框架作为一种可扩展的 meta-evaluation 方法，以解决现有评估受限于基准覆盖和人工标注的挑战。ScaleEval 通过多个沟通型 LLM 代理进行多轮辩论，帮助人类标注者快速识别最有效的 LLM 评估者，从而显著减轻工作量。该框架在多样化任务和新场景中表现出高效性和可靠性，并已开源代码以供进一步应用。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.16788v1",
      "published_date": "2024-01-30 07:03:32 UTC",
      "updated_date": "2024-01-30 07:03:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:37:47.280855"
    },
    {
      "arxiv_id": "2402.01750v1",
      "title": "PACE: A Pragmatic Agent for Enhancing Communication Efficiency Using Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Jiaxuan Li",
        "Minxi Yang",
        "Dahua Gao",
        "Wenlong Xu",
        "Guangming Shi"
      ],
      "abstract": "Current communication technologies face limitations in terms of theoretical\ncapacity, spectrum availability, and power resources. Pragmatic communication,\nleveraging terminal intelligence for selective data transmission, offers\nresource conservation. Existing research lacks universal intention resolution\ntools, limiting applicability to specific tasks. This paper proposes an image\npragmatic communication framework based on a Pragmatic Agent for Communication\nEfficiency (PACE) using Large Language Models (LLM). In this framework, PACE\nsequentially performs semantic perception, intention resolution, and\nintention-oriented coding. To ensure the effective utilization of LLM in\ncommunication, a knowledge base is designed to supplement the necessary\nknowledge, dedicated prompts are introduced to facilitate understanding of\npragmatic communication scenarios and task requirements, and a chain of thought\nis designed to assist in making reasonable trade-offs between transmission\nefficiency and cost. For experimental validation, this paper constructs an\nimage pragmatic communication dataset along with corresponding evaluation\nstandards. Simulation results indicate that the proposed method outperforms\ntraditional and non-LLM-based pragmatic communication in terms of transmission\nefficiency.",
      "tldr_zh": "本文提出 PACE，一种基于 Large Language Models (LLM) 的实用通信代理，用于提升通信效率，解决现有技术的容量、频谱和功率资源限制问题。PACE 通过语义感知、意图解析和意图导向编码的顺序过程，实现选择性数据传输，并引入知识基、专用提示和 chain of thought 来平衡传输效率与成本。研究构建了图像实用通信数据集和相应的评估标准，实验结果表明，该方法在传输效率上优于传统和非LLM-based 实用通信框架。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "11 pages,11 figures, submitted to IJCAI 2024",
      "pdf_url": "http://arxiv.org/pdf/2402.01750v1",
      "published_date": "2024-01-30 06:55:17 UTC",
      "updated_date": "2024-01-30 06:55:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:37:59.252720"
    },
    {
      "arxiv_id": "2401.16784v1",
      "title": "Graph Fairness Learning under Distribution Shifts",
      "title_zh": "在分布偏移下的图公平性学习",
      "authors": [
        "Yibo Li",
        "Xiao Wang",
        "Yujie Xing",
        "Shaohua Fan",
        "Ruijia Wang",
        "Yaoqi Liu",
        "Chuan Shi"
      ],
      "abstract": "Graph neural networks (GNNs) have achieved remarkable performance on\ngraph-structured data. However, GNNs may inherit prejudice from the training\ndata and make discriminatory predictions based on sensitive attributes, such as\ngender and race. Recently, there has been an increasing interest in ensuring\nfairness on GNNs, but all of them are under the assumption that the training\nand testing data are under the same distribution, i.e., training data and\ntesting data are from the same graph. Will graph fairness performance decrease\nunder distribution shifts? How does distribution shifts affect graph fairness\nlearning? All these open questions are largely unexplored from a theoretical\nperspective. To answer these questions, we first theoretically identify the\nfactors that determine bias on a graph. Subsequently, we explore the factors\ninfluencing fairness on testing graphs, with a noteworthy factor being the\nrepresentation distances of certain groups between the training and testing\ngraph. Motivated by our theoretical analysis, we propose our framework\nFatraGNN. Specifically, to guarantee fairness performance on unknown testing\ngraphs, we propose a graph generator to produce numerous graphs with\nsignificant bias and under different distributions. Then we minimize the\nrepresentation distances for each certain group between the training graph and\ngenerated graphs. This empowers our model to achieve high classification and\nfairness performance even on generated graphs with significant bias, thereby\neffectively handling unknown testing graphs. Experiments on real-world and\nsemi-synthetic datasets demonstrate the effectiveness of our model in terms of\nboth accuracy and fairness.",
      "tldr_zh": "该研究探讨了图神经网络 (GNNs) 在分布偏移下如何保持公平性，指出现有方法假设训练和测试数据来自同一分布，而忽略了偏移可能导致的偏见放大。论文首先理论分析了影响图上偏见的因素，并强调了训练图和测试图之间特定群体的表示距离对公平性的关键影响。为解决此问题，提出 FatraGNN 框架，该框架使用图生成器创建大量有显著偏见和不同分布的图，并最小化各群体间的表示距离，从而提升模型在未知测试图上的分类准确性和公平性能。实验在真实和半合成数据集上验证了 FatraGNN 的有效性，在准确性和公平性指标上均优于基线模型。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.SI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by WWW 2024",
      "pdf_url": "http://arxiv.org/pdf/2401.16784v1",
      "published_date": "2024-01-30 06:51:24 UTC",
      "updated_date": "2024-01-30 06:51:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:38:12.020129"
    },
    {
      "arxiv_id": "2401.16772v1",
      "title": "Extrinsicaly Rewarded Soft Q Imitation Learning with Discriminator",
      "title_zh": "翻译失败",
      "authors": [
        "Ryoma Furuyama",
        "Daiki Kuyoshi",
        "Satoshi Yamane"
      ],
      "abstract": "Imitation learning is often used in addition to reinforcement learning in\nenvironments where reward design is difficult or where the reward is sparse,\nbut it is difficult to be able to imitate well in unknown states from a small\namount of expert data and sampling data. Supervised learning methods such as\nBehavioral Cloning do not require sampling data, but usually suffer from\ndistribution shift. The methods based on reinforcement learning, such as\ninverse reinforcement learning and Generative Adversarial imitation learning\n(GAIL), can learn from only a few expert data. However, they often need to\ninteract with the environment. Soft Q imitation learning (SQIL) addressed the\nproblems, and it was shown that it could learn efficiently by combining\nBehavioral Cloning and soft Q-learning with constant rewards. In order to make\nthis algorithm more robust to distribution shift, we propose more efficient and\nrobust algorithm by adding to this method a reward function based on\nadversarial inverse reinforcement learning that rewards the agent for\nperforming actions in status similar to the demo. We call this algorithm\nDiscriminator Soft Q Imitation Learning (DSQIL). We evaluated it on MuJoCo\nenvironments.",
      "tldr_zh": "这篇论文针对模仿学习(Imitation Learning)中从少量专家数据学习未知状态的挑战，提出了一种改进算法，以解决Behavioral Cloning的分布偏移问题和传统强化学习方法的局限。作者在Soft Q Imitation Learning (SQIL)基础上，添加了基于adversarial inverse reinforcement learning的鉴别器奖励函数，奖励代理在与演示状态相似的环境中执行动作，从而提升算法的鲁棒性和效率。新算法名为Discriminator Soft Q Imitation Learning (DSQIL)，并在MuJoCo环境中进行了评估，展示了显著的改进。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "I.2.6"
      ],
      "primary_category": "cs.LG",
      "comment": "9 pages, 4 figures. arXiv admin note: text overlap with\n  arXiv:2001.06808",
      "pdf_url": "http://arxiv.org/pdf/2401.16772v1",
      "published_date": "2024-01-30 06:22:19 UTC",
      "updated_date": "2024-01-30 06:22:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:38:25.186716"
    },
    {
      "arxiv_id": "2401.16766v1",
      "title": "Detection and Recovery Against Deep Neural Network Fault Injection Attacks Based on Contrastive Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Chenan Wang",
        "Pu Zhao",
        "Siyue Wang",
        "Xue Lin"
      ],
      "abstract": "Deep Neural Network (DNN) models when implemented on executing devices as the\ninference engines are susceptible to Fault Injection Attacks (FIAs) that\nmanipulate model parameters to disrupt inference execution with disastrous\nperformance. This work introduces Contrastive Learning (CL) of visual\nrepresentations i.e., a self-supervised learning approach into the deep\nlearning training and inference pipeline to implement DNN inference engines\nwith self-resilience under FIAs. Our proposed CL based FIA Detection and\nRecovery (CFDR) framework features (i) real-time detection with only a single\nbatch of testing data and (ii) fast recovery effective even with only a small\namount of unlabeled testing data. Evaluated with the CIFAR-10 dataset on\nmultiple types of FIAs, our CFDR shows promising detection and recovery\neffectiveness.",
      "tldr_zh": "本研究针对Deep Neural Network (DNN)模型在执行设备上易受Fault Injection Attacks (FIAs)影响的问题，提出了一种基于Contrastive Learning (CL)的检测和恢复框架CFDR，以提升模型的自恢复能力。CFDR框架利用自监督学习方法，实现仅需一组测试数据即可进行实时检测，并通过少量无标签测试数据快速恢复模型性能。在CIFAR-10数据集上测试多种FIAs类型时，CFDR展示了出色的检测和恢复效果，为DNN的安全性提供了新途径。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "Published in AdvML 2021",
      "pdf_url": "http://arxiv.org/pdf/2401.16766v1",
      "published_date": "2024-01-30 06:06:57 UTC",
      "updated_date": "2024-01-30 06:06:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:38:35.793889"
    },
    {
      "arxiv_id": "2401.16765v1",
      "title": "A Cross-Language Investigation into Jailbreak Attacks in Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Jie Li",
        "Yi Liu",
        "Chongyang Liu",
        "Ling Shi",
        "Xiaoning Ren",
        "Yaowen Zheng",
        "Yang Liu",
        "Yinxing Xue"
      ],
      "abstract": "Large Language Models (LLMs) have become increasingly popular for their\nadvanced text generation capabilities across various domains. However, like any\nsoftware, they face security challenges, including the risk of 'jailbreak'\nattacks that manipulate LLMs to produce prohibited content. A particularly\nunderexplored area is the Multilingual Jailbreak attack, where malicious\nquestions are translated into various languages to evade safety filters.\nCurrently, there is a lack of comprehensive empirical studies addressing this\nspecific threat.\n  To address this research gap, we conducted an extensive empirical study on\nMultilingual Jailbreak attacks. We developed a novel semantic-preserving\nalgorithm to create a multilingual jailbreak dataset and conducted an\nexhaustive evaluation on both widely-used open-source and commercial LLMs,\nincluding GPT-4 and LLaMa. Additionally, we performed interpretability analysis\nto uncover patterns in Multilingual Jailbreak attacks and implemented a\nfine-tuning mitigation method. Our findings reveal that our mitigation strategy\nsignificantly enhances model defense, reducing the attack success rate by\n96.2%. This study provides valuable insights into understanding and mitigating\nMultilingual Jailbreak attacks.",
      "tldr_zh": "本研究调查了大型语言模型 (LLMs) 中的 Multilingual Jailbreak 攻击，这种攻击通过将恶意问题翻译成不同语言来规避安全过滤器，并填补了这一领域的实证研究空白。研究团队开发了一个语义保存算法来创建多语言越狱数据集，并对包括 GPT-4 和 LLaMa 在内的开源和商业 LLMs 进行了全面评估和可解释性分析，以揭示攻击模式。最终，他们实施了微调缓解方法，将攻击成功率降低了 96.2%，为有效理解和 mitigation Multilingual Jailbreak 攻击提供了重要见解。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.16765v1",
      "published_date": "2024-01-30 06:04:04 UTC",
      "updated_date": "2024-01-30 06:04:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:38:50.738268"
    },
    {
      "arxiv_id": "2401.16757v1",
      "title": "SwapNet: Efficient Swapping for DNN Inference on Edge AI Devices Beyond the Memory Budget",
      "title_zh": "翻译失败",
      "authors": [
        "Kun Wang",
        "Jiani Cao",
        "Zimu Zhou",
        "Zhenjiang Li"
      ],
      "abstract": "Executing deep neural networks (DNNs) on edge artificial intelligence (AI)\ndevices enables various autonomous mobile computing applications. However, the\nmemory budget of edge AI devices restricts the number and complexity of DNNs\nallowed in such applications. Existing solutions, such as model compression or\ncloud offloading, reduce the memory footprint of DNN inference at the cost of\ndecreased model accuracy or autonomy. To avoid these drawbacks, we divide DNN\ninto blocks and swap them in and out in order, such that large DNNs can execute\nwithin a small memory budget. Nevertheless, naive swapping on edge AI devices\ninduces significant delays due to the redundant memory operations in the DNN\ndevelopment ecosystem for edge AI devices. To this end, we develop SwapNet, an\nefficient DNN block swapping middleware for edge AI devices. We systematically\neliminate the unnecessary memory operations during block swapping while\nretaining compatible with the deep learning frameworks, GPU backends, and\nhardware architectures of edge AI devices. We further showcase the utility of\nSwapNet via a multi-DNN scheduling scheme. Evaluations on eleven DNN inference\ntasks in three applications demonstrate that SwapNet achieves almost the same\nlatency as the case with sufficient memory even when DNNs demand 2.32x to 5.81x\nmemory beyond the available budget. The design of SwapNet also provides novel\nand feasible insights for deploying large language models (LLMs) on edge AI\ndevices in the future.",
      "tldr_zh": "该研究针对边缘 AI 设备内存限制的问题，提出SwapNet，一种高效的DNN块交换中间件，能够在内存预算不足的情况下运行大型DNN模型，而无需牺牲准确性或自治性。SwapNet通过将DNN分成块并优化交换过程，消除不必要的内存操作，并确保与深度学习框架、GPU后端和硬件架构的兼容性；此外，它还集成多DNN调度方案。在实际评估中，SwapNet在十一项DNN推理任务上实现了与充足内存情况几乎相同的延迟，即使模型内存需求超出可用预算2.32x至5.81x，并为未来在边缘设备上部署大型语言模型(LLMs)提供了新颖见解。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DC"
      ],
      "primary_category": "cs.LG",
      "comment": "14 pages, 19 figures, accepted by IEEE Transactions on Mobile\n  Computing",
      "pdf_url": "http://arxiv.org/pdf/2401.16757v1",
      "published_date": "2024-01-30 05:29:49 UTC",
      "updated_date": "2024-01-30 05:29:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:39:00.804825"
    },
    {
      "arxiv_id": "2401.16755v2",
      "title": "Diffusion model for relational inference",
      "title_zh": "翻译失败",
      "authors": [
        "Shuhan Zheng",
        "Ziqiang Li",
        "Kantaro Fujiwara",
        "Gouhei Tanaka"
      ],
      "abstract": "Dynamical behaviors of complex interacting systems, including brain\nactivities, financial price movements, and physical collective phenomena, are\nassociated with underlying interactions between the system's components. The\nissue of uncovering interaction relations in such systems using observable\ndynamics is called relational inference. In this study, we propose a Diffusion\nmodel for Relational Inference (DiffRI), inspired by a self-supervised method\nfor probabilistic time series imputation. DiffRI learns to infer the\nprobability of the presence of connections between components through\nconditional diffusion modeling.",
      "tldr_zh": "该论文针对复杂互动系统（如大脑活动、金融价格变动和物理集体现象）的动态行为，提出了一种名为DiffRI的Diffusion model for Relational Inference方法，用于揭示系统组件之间的交互关系。DiffRI基于自监督的概率时间序列插值技术，通过条件扩散建模学习推断组件连接存在的概率。该方法为关系推断提供了新颖的框架，有望提升对真实世界复杂系统的建模和预测准确性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.16755v2",
      "published_date": "2024-01-30 05:25:02 UTC",
      "updated_date": "2024-06-20 13:19:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:39:11.575974"
    },
    {
      "arxiv_id": "2401.16744v4",
      "title": "ShaRP: A Novel Feature Importance Framework for Ranking",
      "title_zh": "ShaRP：一种新颖的特征重要性框架用于排名",
      "authors": [
        "Venetia Pliatsika",
        "Joao Fonseca",
        "Kateryna Akhynko",
        "Ivan Shevchenko",
        "Julia Stoyanovich"
      ],
      "abstract": "Algorithmic decisions in critical domains such as hiring, college admissions,\nand lending are often based on rankings. Given the impact of these decisions on\nindividuals, organizations, and population groups, it is essential to\nunderstand them-to help individuals improve their ranking position, design\nbetter ranking procedures, and ensure legal compliance. In this paper, we argue\nthat explainability methods for classification and regression, such as SHAP,\nare insufficient for ranking tasks, and present ShaRP-Shapley Values for\nRankings and Preferences-a framework that explains the contributions of\nfeatures to various aspects of a ranked outcome.\n  ShaRP computes feature contributions for various ranking-specific profit\nfunctions, such as rank and top-k, and also includes a novel Shapley\nvalue-based method for explaining pairwise preference outcomes. We provide a\nflexible implementation of ShaRP, capable of efficiently and comprehensively\nexplaining ranked and pairwise outcomes over tabular data, in score-based\nranking and learning-to-rank tasks. Finally, to evaluate ShaRP and compare it\nwith other explainability methods, we define ranking-specific explanation\nmetrics and conduct an extensive experimental analysis, demonstrating the\nframework's flexibility and efficiency.",
      "tldr_zh": "本论文提出ShaRP框架，一种新型特征重要性方法，针对排名任务（如招聘、大学录取和贷款决策）的解释需求，解决现有SHAP等方法的不适用性。ShaRP利用Shapley Values计算特征对排名特定收益函数（如具体排名和top-k）的贡献，并引入新方法解释成对偏好结果，提供灵活的实现支持表格数据上的分数-based排名和学习-to-rank任务。通过定义排名专用解释指标进行实验评估，结果显示ShaRP在灵活性和效率上优于基线方法。",
      "categories": [
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.AI",
      "comment": "20 pages",
      "pdf_url": "http://arxiv.org/pdf/2401.16744v4",
      "published_date": "2024-01-30 04:48:43 UTC",
      "updated_date": "2025-02-15 21:18:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:39:24.203371"
    },
    {
      "arxiv_id": "2402.01749v2",
      "title": "Towards Urban General Intelligence: A Review and Outlook of Urban Foundation Models",
      "title_zh": "迈向城市通用智能：城市基础模型的回顾与展望",
      "authors": [
        "Weijia Zhang",
        "Jindong Han",
        "Zhao Xu",
        "Hang Ni",
        "Tengfei Lyu",
        "Hao Liu",
        "Hui Xiong"
      ],
      "abstract": "The integration of machine learning techniques has become a cornerstone in\nthe development of intelligent urban services, significantly contributing to\nthe enhancement of urban efficiency, sustainability, and overall livability.\nRecent advancements in foundational models, such as ChatGPT, have introduced a\nparadigm shift within the fields of machine learning and artificial\nintelligence. These models, with their exceptional capacity for contextual\ncomprehension, problem-solving, and task adaptability, present a transformative\nopportunity to reshape the future of smart cities and drive progress toward\nUrban General Intelligence (UGI). Despite increasing attention to Urban\nFoundation Models (UFMs), this rapidly evolving field faces critical\nchallenges, including the lack of clear definitions, systematic reviews, and\nuniversalizable solutions. To address these issues, this paper first introduces\nthe definition and concept of UFMs and highlights the distinctive challenges\ninvolved in their development. Furthermore, we present a data-centric taxonomy\nthat classifies existing research on UFMs according to the various urban data\nmodalities and types. In addition, we propose a prospective framework designed\nto facilitate the realization of versatile UFMs, aimed at overcoming the\nidentified challenges and driving further progress in this field. Finally, this\npaper explores the wide-ranging applications of UFMs within urban contexts,\nillustrating their potential to significantly impact and transform urban\nsystems. A comprehensive collection of relevant research papers and open-source\nresources have been collated and are continuously updated at:\nhttps://github.com/usail-hkust/Awesome-Urban-Foundation-Models.",
      "tldr_zh": "本论文审视了Urban Foundation Models (UFMs)在智能城市发展中的作用，强调这些模型如ChatGPT如何提升城市效率、可持续性和宜居性，并推动Urban General Intelligence (UGI)。作者首先定义了UFMs的概念，并指出了其面临的挑战，如缺乏清晰定义和系统回顾，然后提出一个数据-centric的分类taxonomy，根据城市数据模态和类型整理现有研究。论文还设计了一个前瞻性框架来克服这些挑战，并探讨UFMs在城市系统的广泛应用，同时提供资源链接以支持进一步研究。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.01749v2",
      "published_date": "2024-01-30 04:48:16 UTC",
      "updated_date": "2025-01-05 03:45:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:39:36.861869"
    },
    {
      "arxiv_id": "2401.16742v1",
      "title": "Generative AI-based closed-loop fMRI system",
      "title_zh": "基于生成式 AI 的闭环 fMRI 系统",
      "authors": [
        "Mikihiro Kasahara",
        "Taiki Oka",
        "Vincent Taschereau-Dumouchel",
        "Mitsuo Kawato",
        "Hiroki Takakura",
        "Aurelio Cortese"
      ],
      "abstract": "While generative AI is now widespread and useful in society, there are\npotential risks of misuse, e.g., unconsciously influencing cognitive processes\nor decision-making. Although this causes a security problem in the cognitive\ndomain, there has been no research about neural and computational mechanisms\ncounteracting the impact of malicious generative AI in humans. We propose\nDecNefGAN, a novel framework that combines a generative adversarial system and\na neural reinforcement model. More specifically, DecNefGAN bridges human and\ngenerative AI in a closed-loop system, with the AI creating stimuli that induce\nspecific mental states, thus exerting external control over neural activity.\nThe objective of the human is the opposite, to compete and reach an orthogonal\nmental state. This framework can contribute to elucidating how the human brain\nresponds to and counteracts the potential influence of generative AI.",
      "tldr_zh": "该论文提出DecNefGAN框架，这是一种结合生成对抗系统(Generative Adversarial System)和神经强化模型(Neural Reinforcement Model)的创新方法，用于研究人类大脑如何对抗恶意生成AI的影响。框架构建了一个闭环fMRI系统，其中AI生成刺激诱导特定心理状态以控制神经活动，而人类则通过竞争达到正交的心理状态。该方法有助于阐明大脑的响应机制，并为防范生成AI潜在风险提供新的计算和神经基础。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CR",
        "cs.LG"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.16742v1",
      "published_date": "2024-01-30 04:40:49 UTC",
      "updated_date": "2024-01-30 04:40:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:39:47.937712"
    },
    {
      "arxiv_id": "2401.16731v1",
      "title": "Towards Generating Informative Textual Description for Neurons in Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Shrayani Mondal",
        "Rishabh Garodia",
        "Arbaaz Qureshi",
        "Taesung Lee",
        "Youngja Park"
      ],
      "abstract": "Recent developments in transformer-based language models have allowed them to\ncapture a wide variety of world knowledge that can be adapted to downstream\ntasks with limited resources. However, what pieces of information are\nunderstood in these models is unclear, and neuron-level contributions in\nidentifying them are largely unknown. Conventional approaches in neuron\nexplainability either depend on a finite set of pre-defined descriptors or\nrequire manual annotations for training a secondary model that can then explain\nthe neurons of the primary model. In this paper, we take BERT as an example and\nwe try to remove these constraints and propose a novel and scalable framework\nthat ties textual descriptions to neurons. We leverage the potential of\ngenerative language models to discover human-interpretable descriptors present\nin a dataset and use an unsupervised approach to explain neurons with these\ndescriptors. Through various qualitative and quantitative analyses, we\ndemonstrate the effectiveness of this framework in generating useful\ndata-specific descriptors with little human involvement in identifying the\nneurons that encode these descriptors. In particular, our experiment shows that\nthe proposed approach achieves 75% precision@2, and 50% recall@2",
      "tldr_zh": "本文针对 transformer-based 语言模型中神经元（neurons）的解释问题，提出一个新型可扩展框架，以 BERT 为例，通过生成式语言模型发现数据集中的人类可解释描述符，并采用无监督方法将这些描述符与神经元关联。相比传统依赖预定义描述符或手动标注的方法，该框架减少了人为干预，实现了高效的神经元解释。实验结果显示，该方法在定性和定量分析中表现出色，达到了 75% 的 precision@2 和 50% 的 recall@2。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "AAAI 2024",
      "pdf_url": "http://arxiv.org/pdf/2401.16731v1",
      "published_date": "2024-01-30 04:06:25 UTC",
      "updated_date": "2024-01-30 04:06:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:40:00.014725"
    },
    {
      "arxiv_id": "2402.00888v2",
      "title": "Security and Privacy Challenges of Large Language Models: A Survey",
      "title_zh": "翻译失败",
      "authors": [
        "Badhan Chandra Das",
        "M. Hadi Amini",
        "Yanzhao Wu"
      ],
      "abstract": "Large Language Models (LLMs) have demonstrated extraordinary capabilities and\ncontributed to multiple fields, such as generating and summarizing text,\nlanguage translation, and question-answering. Nowadays, LLM is becoming a very\npopular tool in computerized language processing tasks, with the capability to\nanalyze complicated linguistic patterns and provide relevant and appropriate\nresponses depending on the context. While offering significant advantages,\nthese models are also vulnerable to security and privacy attacks, such as\njailbreaking attacks, data poisoning attacks, and Personally Identifiable\nInformation (PII) leakage attacks. This survey provides a thorough review of\nthe security and privacy challenges of LLMs for both training data and users,\nalong with the application-based risks in various domains, such as\ntransportation, education, and healthcare. We assess the extent of LLM\nvulnerabilities, investigate emerging security and privacy attacks for LLMs,\nand review the potential defense mechanisms. Additionally, the survey outlines\nexisting research gaps in this domain and highlights future research\ndirections.",
      "tldr_zh": "这篇调查论文探讨了Large Language Models (LLMs) 的安全和隐私挑战，包括jailbreaking attacks、data poisoning attacks 以及 Personally Identifiable Information (PII) leakage attacks 等风险，这些攻击可能影响模型的训练数据和用户隐私。论文评估了LLMs 在交通、教育和医疗等领域的应用风险，并审查了潜在的防御机制，以缓解这些漏洞。最终，它指出了当前研究中的空白，并提出了未来研究方向，以增强LLMs 的安全性和隐私保护。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.00888v2",
      "published_date": "2024-01-30 04:00:54 UTC",
      "updated_date": "2024-11-14 22:20:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:40:12.223811"
    },
    {
      "arxiv_id": "2401.16708v2",
      "title": "Multivariate Beta Mixture Model: Probabilistic Clustering With Flexible Cluster Shapes",
      "title_zh": "翻译失败",
      "authors": [
        "Yung-Peng Hsu",
        "Hung-Hsuan Chen"
      ],
      "abstract": "This paper introduces the multivariate beta mixture model (MBMM), a new\nprobabilistic model for soft clustering. MBMM adapts to diverse cluster shapes\nbecause of the flexible probability density function of the multivariate beta\ndistribution. We introduce the properties of MBMM, describe the parameter\nlearning procedure, and present the experimental results, showing that MBMM\nfits diverse cluster shapes on synthetic and real datasets. The code is\nreleased anonymously at https://github.com/hhchen1105/mbmm/.",
      "tldr_zh": "本论文引入了 multivariate beta mixture model (MBMM)，一个新的概率模型，用于软聚类，能够适应各种灵活的聚类形状。MBMM 利用多变量 Beta 分布的灵活概率密度函数，介绍了其属性和参数学习过程，以实现更精确的聚类建模。实验结果显示，该模型在合成和真实数据集上有效拟合多样化的聚类形状，并提供了匿名开源代码（https://github.com/hhchen1105/mbmm/）。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.16708v2",
      "published_date": "2024-01-30 03:12:19 UTC",
      "updated_date": "2024-02-21 00:26:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:40:24.919812"
    },
    {
      "arxiv_id": "2403.08786v1",
      "title": "One-Spike SNN: Single-Spike Phase Coding with Base Manipulation for ANN-to-SNN Conversion Loss Minimization",
      "title_zh": "翻译失败",
      "authors": [
        "Sangwoo Hwang",
        "Jaeha Kung"
      ],
      "abstract": "As spiking neural networks (SNNs) are event-driven, energy efficiency is\nhigher than conventional artificial neural networks (ANNs). Since SNN delivers\ndata through discrete spikes, it is difficult to use gradient methods for\ntraining, limiting its accuracy. To keep the accuracy of SNNs similar to ANN\ncounterparts, pre-trained ANNs are converted to SNNs (ANN-to-SNN conversion).\nDuring the conversion, encoding activations of ANNs to a set of spikes in SNNs\nis crucial for minimizing the conversion loss. In this work, we propose a\nsingle-spike phase coding as an encoding scheme that minimizes the number of\nspikes to transfer data between SNN layers. To minimize the encoding error due\nto single-spike approximation in phase coding, threshold shift and base\nmanipulation are proposed. Without any additional retraining or architectural\nconstraints on ANNs, the proposed conversion method does not lose inference\naccuracy (0.58% on average) verified on three convolutional neural networks\n(CNNs) with CIFAR and ImageNet datasets.In addition, graph convolutional\nnetworks (GCNs) are converted to SNNs successfully with an average accuracy\nloss of 0.90%.Most importantly, the energy efficiency of our SNN improves by\n4.6~17.3 X compared to the ANN baseline.",
      "tldr_zh": "本研究提出了一种名为 One-Spike SNN 的方法，通过单 spike 相位编码结合基数操作 (base manipulation) 和阈值偏移 (threshold shift)，来最小化 ANN-to-SNN 转换过程中的损失，从而将预训练的 artificial neural networks (ANNs) 高效转换为 spiking neural networks (SNNs)。该方法无需额外重新训练或架构约束，仅使用单 spike 方案即可在 SNNs 之间传输数据，显著降低了编码错误。实验结果显示，在三个 convolutional neural networks (CNNs) 上使用 CIFAR 和 ImageNet 数据集时，准确性损失平均仅 0.58%；而在 graph convolutional networks (GCNs) 上，损失平均为 0.90%。此外，该方法使 SNNs 的能量效率比 ANN 基线提高了 4.6~17.3 倍，提供了一种高效的 SNN 实现途径。",
      "categories": [
        "cs.NE",
        "cs.AI",
        "68T07"
      ],
      "primary_category": "cs.NE",
      "comment": "11 pages, 10 figures",
      "pdf_url": "http://arxiv.org/pdf/2403.08786v1",
      "published_date": "2024-01-30 02:00:28 UTC",
      "updated_date": "2024-01-30 02:00:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:40:38.256399"
    },
    {
      "arxiv_id": "2401.16672v1",
      "title": "AutoIE: An Automated Framework for Information Extraction from Scientific Literature",
      "title_zh": "AutoIE：一种用于从科学文献中抽取信息的自动化框架",
      "authors": [
        "Yangyang Liu",
        "Shoubin Li"
      ],
      "abstract": "In the rapidly evolving field of scientific research, efficiently extracting\nkey information from the burgeoning volume of scientific papers remains a\nformidable challenge. This paper introduces an innovative framework designed to\nautomate the extraction of vital data from scientific PDF documents, enabling\nresearchers to discern future research trajectories more readily. AutoIE\nuniquely integrates four novel components: (1) A multi-semantic feature\nfusion-based approach for PDF document layout analysis; (2) Advanced functional\nblock recognition in scientific texts; (3) A synergistic technique for\nextracting and correlating information on molecular sieve synthesis; (4) An\nonline learning paradigm tailored for molecular sieve literature. Our SBERT\nmodel achieves high Marco F1 scores of 87.19 and 89.65 on CoNLL04 and ADE\ndatasets. In addition, a practical application of AutoIE in the petrochemical\nmolecular sieve synthesis domain demonstrates its efficacy, evidenced by an\nimpressive 78\\% accuracy rate. This research paves the way for enhanced data\nmanagement and interpretation in molecular sieve synthesis. It is a valuable\nasset for seasoned experts and newcomers in this specialized field.",
      "tldr_zh": "该研究引入了AutoIE，一种自动化框架，用于从科学文献PDF文档中提取关键信息，从而帮助研究人员更高效地识别未来研究方向。AutoIE整合了四个创新组件：(1) 基于多语义特征融合的PDF文档布局分析；(2) 高级功能块识别在科学文本中；(3) 提取和关联分子筛合成信息的协同技术；(4) 针对分子筛文献的在线学习范式。实验结果显示，SBERT模型在CoNLL04和ADE数据集上分别获得87.19和89.65的宏F1分数，并在石化分子筛合成领域的实际应用中达到78%的准确率。该框架为分子筛合成领域的數據管理和解释提供了宝贵工具，适用于专家和新手。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CE"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.16672v1",
      "published_date": "2024-01-30 01:45:03 UTC",
      "updated_date": "2024-01-30 01:45:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:40:49.595532"
    },
    {
      "arxiv_id": "2401.16669v2",
      "title": "Improving Global Weather and Ocean Wave Forecast with Large Artificial Intelligence Models",
      "title_zh": "翻译失败",
      "authors": [
        "Fenghua Ling",
        "Lin Ouyang",
        "Boufeniza Redouane Larbi",
        "Jing-Jia Luo",
        "Tao Han",
        "Xiaohui Zhong",
        "Lei Bai"
      ],
      "abstract": "The rapid advancement of artificial intelligence technologies, particularly\nin recent years, has led to the emergence of several large parameter artificial\nintelligence weather forecast models. These models represent a significant\nbreakthrough, overcoming the limitations of traditional numerical weather\nprediction models and indicating the emergence of profound potential tools for\natmosphere-ocean forecasts. This study explores the evolution of these advanced\nartificial intelligence forecast models, and based on the identified\ncommonalities, proposes the \"Three Large Rules\" to measure their development.\nWe discuss the potential of artificial intelligence in revolutionizing\nnumerical weather prediction, and briefly outlining the underlying reasons for\nits great potential. While acknowledging the high accuracy, computational\nefficiency, and ease of deployment of large artificial intelligence forecast\nmodels, we also emphasize the irreplaceable values of traditional numerical\nforecasts and explore the challenges in the future development of large-scale\nartificial intelligence atmosphere-ocean forecast models. We believe that the\noptimal future of atmosphere-ocean weather forecast lies in achieving a\nseamless integration of artificial intelligence and traditional numerical\nmodels. Such a synthesis is anticipated to offer a more advanced and reliable\napproach for improved atmosphere-ocean forecasts. Additionally, we illustrate\nhow forecasters can adapt and leverage the advanced artificial intelligence\nmodel through an example by building a large artificial intelligence model for\nglobal ocean wave forecast.",
      "tldr_zh": "这篇论文探讨了大型人工智能模型在全球天气和海洋波浪预报中的应用，强调这些模型克服了传统数值天气预报的局限性，并基于模型共同点提出了“Three Large Rules”作为发展衡量标准。研究分析了人工智能的高准确性、计算效率和易部署优势，同时指出传统数值预报的不可替代性，并强调未来应实现人工智能与传统模型的无缝整合，以提升预报可靠性。作为示例，论文展示了如何构建一个用于全球海洋波浪预报的大型人工智能模型。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "physics.ao-ph",
        "physics.geo-ph"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.16669v2",
      "published_date": "2024-01-30 01:34:43 UTC",
      "updated_date": "2024-04-19 02:01:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:41:01.317814"
    },
    {
      "arxiv_id": "2401.16657v1",
      "title": "Recovering Mental Representations from Large Language Models with Markov Chain Monte Carlo",
      "title_zh": "通过 Markov Chain Monte Carlo 从大型语言模型中恢复心理表征",
      "authors": [
        "Jian-Qiao Zhu",
        "Haijiang Yan",
        "Thomas L. Griffiths"
      ],
      "abstract": "Simulating sampling algorithms with people has proven a useful method for\nefficiently probing and understanding their mental representations. We propose\nthat the same methods can be used to study the representations of Large\nLanguage Models (LLMs). While one can always directly prompt either humans or\nLLMs to disclose their mental representations introspectively, we show that\nincreased efficiency can be achieved by using LLMs as elements of a sampling\nalgorithm. We explore the extent to which we recover human-like representations\nwhen LLMs are interrogated with Direct Sampling and Markov chain Monte Carlo\n(MCMC). We found a significant increase in efficiency and performance using\nadaptive sampling algorithms based on MCMC. We also highlight the potential of\nour method to yield a more general method of conducting Bayesian inference\n\\textit{with} LLMs.",
      "tldr_zh": "该论文提出了一种方法，通过将大型语言模型 (LLMs) 整合到采样算法中，来高效恢复其内部心理表征，类似于模拟人类的采样过程。研究比较了直接采样和 Markov Chain Monte Carlo (MCMC) 算法，发现基于 MCMC 的自适应采样显著提高了效率和性能。最终，这方法不仅揭示了 LLMs 的表征与人类相似性，还为更广泛的 Bayesian inference 应用提供了新途径。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.16657v1",
      "published_date": "2024-01-30 01:22:18 UTC",
      "updated_date": "2024-01-30 01:22:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:41:11.920975"
    },
    {
      "arxiv_id": "2401.16650v3",
      "title": "Augmenting Replay in World Models for Continual Reinforcement Learning",
      "title_zh": "在世界模型中增强重放机制用于持续强化学习",
      "authors": [
        "Luke Yang",
        "Levin Kuhlmann",
        "Gideon Kowadlo"
      ],
      "abstract": "Continual RL requires an agent to learn new tasks without forgetting previous\nones, while improving on both past and future tasks. The most common approaches\nuse model-free algorithms and replay buffers can help to mitigate catastrophic\nforgetting, but often struggle with scalability due to large memory\nrequirements. Biologically inspired replay suggests replay to a world model,\naligning with model-based RL; as opposed to the common setting of replay in\nmodel-free algorithms. Model-based RL offers benefits for continual RL by\nleveraging knowledge of the environment, independent of policy. We introduce\nWMAR (World Models with Augmented Replay), a model-based RL algorithm with a\nmemory-efficient distribution-matching replay buffer. WMAR extends the well\nknown DreamerV3 algorithm, which employs a simple FIFO buffer and was not\ntested in continual RL. We evaluated WMAR and DreamerV3, with the same-size\nreplay buffers. They were tested on two scenarios: tasks with shared structure\nusing OpenAI Procgen and tasks without shared structure using the Atari\nbenchmark. WMAR demonstrated favourable properties for continual RL considering\nmetrics for forgetting as well as skill transfer on past and future tasks.\nCompared to DreamerV3, WMAR showed slight benefits in tasks with shared\nstructure and substantially better forgetting characteristics on tasks without\nshared structure. Our results suggest that model-based RL with a\nmemory-efficient replay buffer can be an effective approach to continual RL,\njustifying further research.",
      "tldr_zh": "这篇论文提出了 WMAR（World Models with Augmented Replay），一种基于模型的强化学习算法，用于持续强化学习（Continual RL），旨在通过内存高效的分布匹配重放缓冲区缓解灾难性遗忘问题，同时提升对过去和未来任务的性能。WMAR 扩展了 DreamerV3 算法，将重放应用于世界模型（world model），并在 OpenAI Procgen（任务有共享结构）和 Atari 基准（任务无共享结构）的场景中进行了评估。实验结果显示，WMAR 相对于 DreamerV3 表现出更好的遗忘控制和技能转移优势，证明了基于模型的 RL 在 Continual RL 中的有效性，并建议进一步研究。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "I.2.6; I.5.0; I.5.1"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.16650v3",
      "published_date": "2024-01-30 00:48:26 UTC",
      "updated_date": "2024-07-16 07:33:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:41:26.926221"
    },
    {
      "arxiv_id": "2401.16646v2",
      "title": "Incoherent Probability Judgments in Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Jian-Qiao Zhu",
        "Thomas L. Griffiths"
      ],
      "abstract": "Autoregressive Large Language Models (LLMs) trained for next-word prediction\nhave demonstrated remarkable proficiency at producing coherent text. But are\nthey equally adept at forming coherent probability judgments? We use\nprobabilistic identities and repeated judgments to assess the coherence of\nprobability judgments made by LLMs. Our results show that the judgments\nproduced by these models are often incoherent, displaying human-like systematic\ndeviations from the rules of probability theory. Moreover, when prompted to\njudge the same event, the mean-variance relationship of probability judgments\nproduced by LLMs shows an inverted-U-shaped like that seen in humans. We\npropose that these deviations from rationality can be explained by linking\nautoregressive LLMs to implicit Bayesian inference and drawing parallels with\nthe Bayesian Sampler model of human probability judgments.",
      "tldr_zh": "本研究评估了 autoregressive Large Language Models (LLMs) 在形成概率判断时的连贯性，尽管这些模型在生成连贯文本方面表现出色，但结果显示其概率判断往往不连贯，并表现出类似于人类的系统偏差。研究者通过概率恒等式和重复判断的方法，对 LLMs 的判断进行了测试，发现概率判断的均值-方差关系呈现出倒 U 形曲线。作者提出，这些偏差可通过将 autoregressive LLMs 与隐式 Bayesian inference 联系起来，并类比 Bayesian Sampler 模型来解释，从而为理解 LLMs 的理性局限性提供了新视角。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.16646v2",
      "published_date": "2024-01-30 00:40:49 UTC",
      "updated_date": "2025-05-06 01:43:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:41:37.354433"
    },
    {
      "arxiv_id": "2401.16638v1",
      "title": "Breaking Free Transformer Models: Task-specific Context Attribution Promises Improved Generalizability Without Fine-tuning Pre-trained LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Stepan Tytarenko",
        "Mohammad Ruhul Amin"
      ],
      "abstract": "Fine-tuning large pre-trained language models (LLMs) on particular datasets\nis a commonly employed strategy in Natural Language Processing (NLP)\nclassification tasks. However, this approach usually results in a loss of\nmodels generalizability. In this paper, we present a framework that allows for\nmaintaining generalizability, and enhances the performance on the downstream\ntask by utilizing task-specific context attribution. We show that a linear\ntransformation of the text representation from any transformer model using the\ntask-specific concept operator results in a projection onto the latent concept\nspace, referred to as context attribution in this paper. The specific concept\noperator is optimized during the supervised learning stage via novel loss\nfunctions. The proposed framework demonstrates that context attribution of the\ntext representation for each task objective can improve the capacity of the\ndiscriminator function and thus achieve better performance for the\nclassification task. Experimental results on three datasets, namely HateXplain,\nIMDB reviews, and Social Media Attributions, illustrate that the proposed model\nattains superior accuracy and generalizability. Specifically, for the\nnon-fine-tuned BERT on the HateXplain dataset, we observe 8% improvement in\naccuracy and 10% improvement in F1-score. Whereas for the IMDB dataset,\nfine-tuned state-of-the-art XLNet is outperformed by 1% for both accuracy and\nF1-score. Furthermore, in an out-of-domain cross-dataset test, DistilBERT\nfine-tuned on the IMDB dataset in conjunction with the proposed model improves\nthe F1-score on the HateXplain dataset by 7%. For the Social Media Attributions\ndataset of YouTube comments, we observe 5.2% increase in F1-metric. The\nproposed framework is implemented with PyTorch and provided open-source on\nGitHub.",
      "tldr_zh": "该研究提出了一种框架，通过任务特定的上下文归因（context attribution）来提升Transformer模型在下游分类任务中的性能，而无需微调预训练的LLMs，从而保持模型的泛化能力。该框架利用线性变换文本表示，并通过优化概念操作符投影到潜在概念空间，以改善判别函数的表现。在HateXplain、IMDB reviews和Social Media Attributions数据集上的实验显示，该方法显著提升了准确率和F1-score，例如非微调BERT在HateXplain上准确率提高8%、F1-score提高10%，并在跨数据集测试中表现出色。该框架以PyTorch实现，并开源在GitHub上。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "I.2.7; I.2.4"
      ],
      "primary_category": "cs.CL",
      "comment": "8 pages, 3 figures, 5 tables, To be published in 2024 AAAI workshop\n  on Responsible Language Models (ReLM)",
      "pdf_url": "http://arxiv.org/pdf/2401.16638v1",
      "published_date": "2024-01-30 00:23:29 UTC",
      "updated_date": "2024-01-30 00:23:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:41:49.172886"
    },
    {
      "arxiv_id": "2402.01748v2",
      "title": "Large Multi-Modal Models (LMMs) as Universal Foundation Models for AI-Native Wireless Systems",
      "title_zh": "大型多模态模型 (LMMs) 作为通用基础模型，用于 AI 原生无线系统",
      "authors": [
        "Shengzhe Xu",
        "Christo Kurisummoottil Thomas",
        "Omar Hashash",
        "Nikhil Muralidhar",
        "Walid Saad",
        "Naren Ramakrishnan"
      ],
      "abstract": "Large language models (LLMs) and foundation models have been recently touted\nas a game-changer for 6G systems. However, recent efforts on LLMs for wireless\nnetworks are limited to a direct application of existing language models that\nwere designed for natural language processing (NLP) applications. To address\nthis challenge and create wireless-centric foundation models, this paper\npresents a comprehensive vision on how to design universal foundation models\nthat are tailored towards the deployment of artificial intelligence (AI)-native\nnetworks. Diverging from NLP-based foundation models, the proposed framework\npromotes the design of large multi-modal models (LMMs) fostered by three key\ncapabilities: 1) processing of multi-modal sensing data, 2) grounding of\nphysical symbol representations in real-world wireless systems using causal\nreasoning and retrieval-augmented generation (RAG), and 3) enabling\ninstructibility from the wireless environment feedback to facilitate dynamic\nnetwork adaptation thanks to logical and mathematical reasoning facilitated by\nneuro-symbolic AI. In essence, these properties enable the proposed LMM\nframework to build universal capabilities that cater to various cross-layer\nnetworking tasks and alignment of intents across different domains. Preliminary\nresults from experimental evaluation demonstrate the efficacy of grounding\nusing RAG in LMMs, and showcase the alignment of LMMs with wireless system\ndesigns. Furthermore, the enhanced rationale exhibited in the responses to\nmathematical questions by LMMs, compared to vanilla LLMs, demonstrates the\nlogical and mathematical reasoning capabilities inherent in LMMs. Building on\nthose results, we present a sequel of open questions and challenges for LMMs.\nWe then conclude with a set of recommendations that ignite the path towards\nLMM-empowered AI-native systems.",
      "tldr_zh": "该论文批评现有LLMs直接应用于无线网络的局限性，并提出LMMs作为AI原生无线系统的通用基础模型，以设计无线专属的模型框架。LMMs具备三个关键能力：处理多模态感知数据、使用因果推理和RAG实现物理符号grounding，以及通过神经符号AI进行逻辑和数学推理，以支持动态网络适应和跨层任务。实验结果证明LMMs在系统对齐和推理能力上优于传统LLMs，并讨论了未来的开放挑战及推荐路径。",
      "categories": [
        "cs.NI",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.NI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.01748v2",
      "published_date": "2024-01-30 00:21:41 UTC",
      "updated_date": "2024-02-07 17:55:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:42:01.571823"
    },
    {
      "arxiv_id": "2401.16635v3",
      "title": "Improving Reinforcement Learning from Human Feedback with Efficient Reward Model Ensemble",
      "title_zh": "翻译失败",
      "authors": [
        "Shun Zhang",
        "Zhenfang Chen",
        "Sunli Chen",
        "Yikang Shen",
        "Zhiqing Sun",
        "Chuang Gan"
      ],
      "abstract": "Reinforcement Learning from Human Feedback (RLHF) is a widely adopted\napproach for aligning large language models with human values. However, RLHF\nrelies on a reward model that is trained with a limited amount of human\npreference data, which could lead to inaccurate predictions. As a result, RLHF\nmay produce outputs that are misaligned with human values. To mitigate this\nissue, we contribute a reward ensemble method that allows the reward model to\nmake more accurate predictions. As using an ensemble of large language\nmodel-based reward models can be computationally and resource-expensive, we\nexplore efficient ensemble methods including linear-layer ensemble and\nLoRA-based ensemble. Empirically, we run Best-of-$n$ and Proximal Policy\nOptimization with our ensembled reward models, and verify that our ensemble\nmethods help improve the alignment performance of RLHF outputs.",
      "tldr_zh": "这篇论文针对 Reinforcement Learning from Human Feedback (RLHF) 中奖励模型基于有限人类偏好数据导致预测不准确的问题，提出了一种奖励模型集成方法，以提升模型对人类价值观的输出对齐。作者探索了高效集成策略，包括 linear-layer ensemble 和 LoRA-based ensemble，以减少计算资源消耗。实验通过 Best-of-n 和 Proximal Policy Optimization 验证了这些方法，能显著改善 RLHF 的整体性能。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.16635v3",
      "published_date": "2024-01-30 00:17:37 UTC",
      "updated_date": "2024-10-22 06:19:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:42:13.671768"
    },
    {
      "arxiv_id": "2401.16633v1",
      "title": "I came, I saw, I certified: some perspectives on the safety assurance of cyber-physical systems",
      "title_zh": "翻译失败",
      "authors": [
        "Mithila Sivakumar",
        "Alvine B. Belle",
        "Kimya Khakzad Shahandashti",
        "Oluwafemi Odu",
        "Hadi Hemmati",
        "Segla Kpodjedo",
        "Song Wang",
        "Opeyemi O. Adesina"
      ],
      "abstract": "The execution failure of cyber-physical systems (e.g., autonomous driving\nsystems, unmanned aerial systems, and robotic systems) could result in the loss\nof life, severe injuries, large-scale environmental damage, property\ndestruction, and major economic loss. Hence, such systems usually require a\nstrong justification that they will effectively support critical requirements\n(e.g., safety, security, and reliability) for which they were designed. Thus,\nit is often mandatory to develop compelling assurance cases to support that\njustification and allow regulatory bodies to certify such systems. In such\ncontexts, detecting assurance deficits, relying on patterns to improve the\nstructure of assurance cases, improving existing assurance case notations, and\n(semi-)automating the generation of assurance cases are key to develop\ncompelling assurance cases and foster consumer acceptance. We therefore explore\nchallenges related to such assurance enablers and outline some potential\ndirections that could be explored to tackle them.",
      "tldr_zh": "这篇论文探讨了 cyber-physical systems（如自动驾驶系统、无人机和机器人系统）的安全保障问题，强调通过开发 assurance cases 来证明这些系统满足关键要求（如安全、security 和 reliability），从而获得监管机构的认证。论文识别了主要挑战，包括检测 assurance deficits、使用 patterns 改进 assurance cases 的结构、提升 assurance case notations，以及实现（半）自动化生成这些 cases。作者概述了潜在方向，以应对这些挑战并促进消费者对 cyber-physical systems 的接受。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.16633v1",
      "published_date": "2024-01-30 00:06:16 UTC",
      "updated_date": "2024-01-30 00:06:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:42:25.311126"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 101,
  "processed_papers_count": 101,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-17T01:42:52.159907"
}