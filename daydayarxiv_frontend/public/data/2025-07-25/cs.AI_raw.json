[
  {
    "arxiv_id": "2507.19712v2",
    "title": "Oranits: Mission Assignment and Task Offloading in Open RAN-based ITS using Metaheuristic and Deep Reinforcement Learning",
    "authors": [
      "Ngoc Hung Nguyen",
      "Nguyen Van Thieu",
      "Quang-Trung Luu",
      "Anh Tuan Nguyen",
      "Senura Wanasekara",
      "Nguyen Cong Luong",
      "Fatemeh Kavehmadavani",
      "Van-Dinh Nguyen"
    ],
    "abstract": "In this paper, we explore mission assignment and task offloading in an Open Radio Access Network (Open RAN)-based intelligent transportation system (ITS), where autonomous vehicles leverage mobile edge computing for efficient processing. Existing studies often overlook the intricate interdependencies between missions and the costs associated with offloading tasks to edge servers, leading to suboptimal decision-making. To bridge this gap, we introduce Oranits, a novel system model that explicitly accounts for mission dependencies and offloading costs while optimizing performance through vehicle cooperation. To achieve this, we propose a twofold optimization approach. First, we develop a metaheuristic-based evolutionary computing algorithm, namely the Chaotic Gaussian-based Global ARO (CGG-ARO), serving as a baseline for one-slot optimization. Second, we design an enhanced reward-based deep reinforcement learning (DRL) framework, referred to as the Multi-agent Double Deep Q-Network (MA-DDQN), that integrates both multi-agent coordination and multi-action selection mechanisms, significantly reducing mission assignment time and improving adaptability over baseline methods. Extensive simulations reveal that CGG-ARO improves the number of completed missions and overall benefit by approximately 7.1% and 7.7%, respectively. Meanwhile, MA-DDQN achieves even greater improvements of 11.0% in terms of mission completions and 12.5% in terms of the overall benefit. These results highlight the effectiveness of Oranits in enabling faster, more adaptive, and more efficient task processing in dynamic ITS environments.",
    "categories": [
      "cs.DC",
      "cs.AI",
      "cs.GT",
      "cs.LG",
      "cs.NI"
    ],
    "primary_category": "cs.DC",
    "comment": "15 pages, 13 figures",
    "pdf_url": "https://arxiv.org/pdf/2507.19712v2",
    "published_date": "2025-07-25 23:13:09 UTC",
    "updated_date": "2025-08-14 14:59:13 UTC"
  },
  {
    "arxiv_id": "2507.19703v2",
    "title": "The wall confronting large language models",
    "authors": [
      "Peter V. Coveney",
      "Sauro Succi"
    ],
    "abstract": "We show that the scaling laws which determine the performance of large language models (LLMs) severely limit their ability to improve the uncertainty of their predictions. As a result, raising their reliability to meet the standards of scientific inquiry is intractable by any reasonable measure. We argue that the very mechanism which fuels much of the learning power of LLMs, namely the ability to generate non-Gaussian output distributions from Gaussian input ones, might well be at the roots of their propensity to produce error pileup, ensuing information catastrophes and degenerative AI behaviour. This tension between learning and accuracy is a likely candidate mechanism underlying the observed low values of the scaling components. It is substantially compounded by the deluge of spurious correlations pointed out by Calude and Longo which rapidly increase in any data set merely as a function of its size, regardless of its nature. The fact that a degenerative AI pathway is a very probable feature of the LLM landscape does not mean that it must inevitably arise in all future AI research. Its avoidance, which we also discuss in this paper, necessitates putting a much higher premium on insight and understanding of the structural characteristics of the problems being investigated.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.19703v2",
    "published_date": "2025-07-25 22:48:37 UTC",
    "updated_date": "2025-07-30 07:58:56 UTC"
  },
  {
    "arxiv_id": "2507.19694v1",
    "title": "Ultracoarse Equilibria and Ordinal-Folding Dynamics in Operator-Algebraic Models of Infinite Multi-Agent Games",
    "authors": [
      "Faruk Alpay",
      "Hamdi Alakkad",
      "Bugra Kilictas",
      "Taylan Alpay"
    ],
    "abstract": "We develop an operator algebraic framework for infinite games with a continuum of agents and prove that regret based learning dynamics governed by a noncommutative continuity equation converge to a unique quantal response equilibrium under mild regularity assumptions. The framework unifies functional analysis, coarse geometry and game theory by assigning to every game a von Neumann algebra that represents collective strategy evolution. A reflective regret operator within this algebra drives the flow of strategy distributions and its fixed point characterises equilibrium. We introduce the ordinal folding index, a computable ordinal valued metric that measures the self referential depth of the dynamics, and show that it bounds the transfinite time needed for convergence, collapsing to zero on coarsely amenable networks. The theory yields new invariant subalgebra rigidity results, establishes existence and uniqueness of envy free and maximin share allocations in continuum economies, and links analytic properties of regret flows with empirical stability phenomena in large language models. These contributions supply a rigorous mathematical foundation for large scale multi agent systems and demonstrate the utility of ordinal metrics for equilibrium selection.",
    "categories": [
      "math.OC",
      "cs.AI",
      "cs.GT",
      "cs.MA"
    ],
    "primary_category": "math.OC",
    "comment": "15 pages, 2 figures; companion implementation available at https://github.com/farukalpay/ordinal-folding-index/",
    "pdf_url": "https://arxiv.org/pdf/2507.19694v1",
    "published_date": "2025-07-25 22:20:42 UTC",
    "updated_date": "2025-07-25 22:20:42 UTC"
  },
  {
    "arxiv_id": "2507.19686v1",
    "title": "KD-GAT: Combining Knowledge Distillation and Graph Attention Transformer for a Controller Area Network Intrusion Detection System",
    "authors": [
      "Robert Frenken",
      "Sidra Ghayour Bhatti",
      "Hanqin Zhang",
      "Qadeer Ahmed"
    ],
    "abstract": "The Controller Area Network (CAN) protocol is widely adopted for in-vehicle communication but lacks inherent security mechanisms, making it vulnerable to cyberattacks. This paper introduces KD-GAT, an intrusion detection framework that combines Graph Attention Networks (GATs) with knowledge distillation (KD) to enhance detection accuracy while reducing computational complexity. In our approach, CAN traffic is represented as graphs using a sliding window to capture temporal and relational patterns. A multi-layer GAT with jumping knowledge aggregation acting as the teacher model, while a compact student GAT--only 6.32% the size of the teacher--is trained via a two-phase process involving supervised pretraining and knowledge distillation with both soft and hard label supervision. Experiments on three benchmark datasets--Car-Hacking, Car-Survival, and can-train-and-test demonstrate that both teacher and student models achieve strong results, with the student model attaining 99.97% and 99.31% accuracy on Car-Hacking and Car-Survival, respectively. However, significant class imbalance in can-train-and-test has led to reduced performance for both models on this dataset. Addressing this imbalance remains an important direction for future work.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.19686v1",
    "published_date": "2025-07-25 21:45:58 UTC",
    "updated_date": "2025-07-25 21:45:58 UTC"
  },
  {
    "arxiv_id": "2507.19684v1",
    "title": "Salsa as a Nonverbal Embodied Language -- The CoMPAS3D Dataset and Benchmarks",
    "authors": [
      "Bermet Burkanova",
      "Payam Jome Yazdian",
      "Chuxuan Zhang",
      "Trinity Evans",
      "Paige Tuttösí",
      "Angelica Lim"
    ],
    "abstract": "Imagine a humanoid that can safely and creatively dance with a human, adapting to its partner's proficiency, using haptic signaling as a primary form of communication. While today's AI systems excel at text or voice-based interaction with large language models, human communication extends far beyond text-it includes embodied movement, timing, and physical coordination. Modeling coupled interaction between two agents poses a formidable challenge: it is continuous, bidirectionally reactive, and shaped by individual variation. We present CoMPAS3D, the largest and most diverse motion capture dataset of improvised salsa dancing, designed as a challenging testbed for interactive, expressive humanoid AI. The dataset includes 3 hours of leader-follower salsa dances performed by 18 dancers spanning beginner, intermediate, and professional skill levels. For the first time, we provide fine-grained salsa expert annotations, covering over 2,800 move segments, including move types, combinations, execution errors and stylistic elements. We draw analogies between partner dance communication and natural language, evaluating CoMPAS3D on two benchmark tasks for synthetic humans that parallel key problems in spoken language and dialogue processing: leader or follower generation with proficiency levels (speaker or listener synthesis), and duet (conversation) generation. Towards a long-term goal of partner dance with humans, we release the dataset, annotations, and code, along with a multitask SalsaAgent model capable of performing all benchmark tasks, alongside additional baselines to encourage research in socially interactive embodied AI and creative, expressive humanoid motion generation.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "https://rosielab.github.io/compas3d",
    "pdf_url": "https://arxiv.org/pdf/2507.19684v1",
    "published_date": "2025-07-25 21:33:48 UTC",
    "updated_date": "2025-07-25 21:33:48 UTC"
  },
  {
    "arxiv_id": "2507.19682v1",
    "title": "DeepJIVE: Learning Joint and Individual Variation Explained from Multimodal Data Using Deep Learning",
    "authors": [
      "Matthew Drexler",
      "Benjamin Risk",
      "James J Lah",
      "Suprateek Kundu",
      "Deqiang Qiu"
    ],
    "abstract": "Conventional multimodal data integration methods provide a comprehensive assessment of the shared or unique structure within each individual data type but suffer from several limitations such as the inability to handle high-dimensional data and identify nonlinear structures. In this paper, we introduce DeepJIVE, a deep-learning approach to performing Joint and Individual Variance Explained (JIVE). We perform mathematical derivation and experimental validations using both synthetic and real-world 1D, 2D, and 3D datasets. Different strategies of achieving the identity and orthogonality constraints for DeepJIVE were explored, resulting in three viable loss functions. We found that DeepJIVE can successfully uncover joint and individual variations of multimodal datasets. Our application of DeepJIVE to the Alzheimer's Disease Neuroimaging Initiative (ADNI) also identified biologically plausible covariation patterns between the amyloid positron emission tomography (PET) and magnetic resonance (MR) images. In conclusion, the proposed DeepJIVE can be a useful tool for multimodal data analysis.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "26 pages, 10 figures",
    "pdf_url": "https://arxiv.org/pdf/2507.19682v1",
    "published_date": "2025-07-25 21:23:31 UTC",
    "updated_date": "2025-07-25 21:23:31 UTC"
  },
  {
    "arxiv_id": "2507.19679v1",
    "title": "Efficient Learning for Product Attributes with Compact Multimodal Models",
    "authors": [
      "Mandar Kulkarni"
    ],
    "abstract": "Image-based product attribute prediction in e-commerce is a crucial task with numerous applications. The supervised fine-tuning of Vision Language Models (VLMs) faces significant scale challenges due to the cost of manual or API based annotation. In this paper, we investigate label-efficient semi-supervised fine-tuning strategies for compact VLMs (2B-3B parameters) that leverage unlabeled product listings through Direct Preference Optimization (DPO). Beginning with a small, API-based, annotated, and labeled set, we first employ PEFT to train low-rank adapter modules. To update the adapter weights with unlabeled data, we generate multiple reasoning-and-answer chains per unlabeled sample and segregate these chains into preferred and dispreferred based on self-consistency. We then fine-tune the model with DPO loss and use the updated model for the next iteration. By using PEFT fine-tuning with DPO, our method achieves efficient convergence with minimal compute overhead. On a dataset spanning twelve e-commerce verticals, DPO-based fine-tuning, which utilizes only unlabeled data, demonstrates a significant improvement over the supervised model. Moreover, experiments demonstrate that accuracy with DPO training improves with more unlabeled data, indicating that a large pool of unlabeled samples can be effectively leveraged to improve performance.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.19679v1",
    "published_date": "2025-07-25 21:12:11 UTC",
    "updated_date": "2025-07-25 21:12:11 UTC"
  },
  {
    "arxiv_id": "2508.06504v1",
    "title": "Retrieval augmented generation based dynamic prompting for few-shot biomedical named entity recognition using large language models",
    "authors": [
      "Yao Ge",
      "Sudeshna Das",
      "Yuting Guo",
      "Abeed Sarker"
    ],
    "abstract": "Biomedical named entity recognition (NER) is a high-utility natural language processing (NLP) task, and large language models (LLMs) show promise particularly in few-shot settings (i.e., limited training data). In this article, we address the performance challenges of LLMs for few-shot biomedical NER by investigating a dynamic prompting strategy involving retrieval-augmented generation (RAG). In our approach, the annotated in-context learning examples are selected based on their similarities with the input texts, and the prompt is dynamically updated for each instance during inference. We implemented and optimized static and dynamic prompt engineering techniques and evaluated them on five biomedical NER datasets. Static prompting with structured components increased average F1-scores by 12% for GPT-4, and 11% for GPT-3.5 and LLaMA 3-70B, relative to basic static prompting. Dynamic prompting further improved performance, with TF-IDF and SBERT retrieval methods yielding the best results, improving average F1-scores by 7.3% and 5.6% in 5-shot and 10-shot settings, respectively. These findings highlight the utility of contextually adaptive prompts via RAG for biomedical NER.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "31 pages, 4 figures, 15 tables",
    "pdf_url": "https://arxiv.org/pdf/2508.06504v1",
    "published_date": "2025-07-25 20:57:16 UTC",
    "updated_date": "2025-07-25 20:57:16 UTC"
  },
  {
    "arxiv_id": "2507.19672v1",
    "title": "Alignment and Safety in Large Language Models: Safety Mechanisms, Training Paradigms, and Emerging Challenges",
    "authors": [
      "Haoran Lu",
      "Luyang Fang",
      "Ruidong Zhang",
      "Xinliang Li",
      "Jiazhang Cai",
      "Huimin Cheng",
      "Lin Tang",
      "Ziyu Liu",
      "Zeliang Sun",
      "Tao Wang",
      "Yingchuan Zhang",
      "Arif Hassan Zidan",
      "Jinwen Xu",
      "Jincheng Yu",
      "Meizhi Yu",
      "Hanqi Jiang",
      "Xilin Gong",
      "Weidi Luo",
      "Bolun Sun",
      "Yongkai Chen",
      "Terry Ma",
      "Shushan Wu",
      "Yifan Zhou",
      "Junhao Chen",
      "Haotian Xiang",
      "Jing Zhang",
      "Afrar Jahin",
      "Wei Ruan",
      "Ke Deng",
      "Yi Pan",
      "Peilong Wang",
      "Jiahui Li",
      "Zhengliang Liu",
      "Lu Zhang",
      "Lin Zhao",
      "Wei Liu",
      "Dajiang Zhu",
      "Xin Xing",
      "Fei Dou",
      "Wei Zhang",
      "Chao Huang",
      "Rongjie Liu",
      "Mengrui Zhang",
      "Yiwen Liu",
      "Xiaoxiao Sun",
      "Qin Lu",
      "Zhen Xiang",
      "Wenxuan Zhong",
      "Tianming Liu",
      "Ping Ma"
    ],
    "abstract": "Due to the remarkable capabilities and growing impact of large language models (LLMs), they have been deeply integrated into many aspects of society. Thus, ensuring their alignment with human values and intentions has emerged as a critical challenge. This survey provides a comprehensive overview of practical alignment techniques, training protocols, and empirical findings in LLM alignment. We analyze the development of alignment methods across diverse paradigms, characterizing the fundamental trade-offs between core alignment objectives. Our analysis shows that while supervised fine-tuning enables basic instruction-following, preference-based methods offer more flexibility for aligning with nuanced human intent. We discuss state-of-the-art techniques, including Direct Preference Optimization (DPO), Constitutional AI, brain-inspired methods, and alignment uncertainty quantification (AUQ), highlighting their approaches to balancing quality and efficiency. We review existing evaluation frameworks and benchmarking datasets, emphasizing limitations such as reward misspecification, distributional robustness, and scalable oversight. We summarize strategies adopted by leading AI labs to illustrate the current state of practice. We conclude by outlining open problems in oversight, value pluralism, robustness, and continuous alignment. This survey aims to inform both researchers and practitioners navigating the evolving landscape of LLM alignment.",
    "categories": [
      "cs.AI",
      "cs.LG",
      "stat.ML"
    ],
    "primary_category": "cs.AI",
    "comment": "119 pages, 10 figures, 7 tables",
    "pdf_url": "https://arxiv.org/pdf/2507.19672v1",
    "published_date": "2025-07-25 20:52:58 UTC",
    "updated_date": "2025-07-25 20:52:58 UTC"
  },
  {
    "arxiv_id": "2508.05648v1",
    "title": "AquiLLM: a RAG Tool for Capturing Tacit Knowledge in Research Groups",
    "authors": [
      "Chandler Campbell",
      "Bernie Boscoe",
      "Tuan Do"
    ],
    "abstract": "Research groups face persistent challenges in capturing, storing, and retrieving knowledge that is distributed across team members. Although structured data intended for analysis and publication is often well managed, much of a group's collective knowledge remains informal, fragmented, or undocumented--often passed down orally through meetings, mentoring, and day-to-day collaboration. This includes private resources such as emails, meeting notes, training materials, and ad hoc documentation. Together, these reflect the group's tacit knowledge--the informal, experience-based expertise that underlies much of their work. Accessing this knowledge can be difficult, requiring significant time and insider understanding. Retrieval-augmented generation (RAG) systems offer promising solutions by enabling users to query and generate responses grounded in relevant source material. However, most current RAG-LLM systems are oriented toward public documents and overlook the privacy concerns of internal research materials. We introduce AquiLLM (pronounced ah-quill-em), a lightweight, modular RAG system designed to meet the needs of research groups. AquiLLM supports varied document types and configurable privacy settings, enabling more effective access to both formal and informal knowledge within scholarly groups.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "Accepted to US Research Software Engineer Association (US-RSE) 2025",
    "pdf_url": "https://arxiv.org/pdf/2508.05648v1",
    "published_date": "2025-07-25 20:47:01 UTC",
    "updated_date": "2025-07-25 20:47:01 UTC"
  },
  {
    "arxiv_id": "2507.19657v1",
    "title": "\"X of Information'' Continuum: A Survey on AI-Driven Multi-dimensional Metrics for Next-Generation Networked Systems",
    "authors": [
      "Beining Wu",
      "Jun Huang",
      "Shui Yu"
    ],
    "abstract": "The development of next-generation networking systems has inherently shifted from throughput-based paradigms towards intelligent, information-aware designs that emphasize the quality, relevance, and utility of transmitted information, rather than sheer data volume. While classical network metrics, such as latency and packet loss, remain significant, they are insufficient to quantify the nuanced information quality requirements of modern intelligent applications, including autonomous vehicles, digital twins, and metaverse environments. In this survey, we present the first comprehensive study of the ``X of Information'' continuum by introducing a systematic four-dimensional taxonomic framework that structures information metrics along temporal, quality/utility, reliability/robustness, and network/communication dimensions. We uncover the increasing interdependencies among these dimensions, whereby temporal freshness triggers quality evaluation, which in turn helps with reliability appraisal, ultimately enabling effective network delivery. Our analysis reveals that artificial intelligence technologies, such as deep reinforcement learning, multi-agent systems, and neural optimization models, enable adaptive, context-aware optimization of competing information quality objectives. In our extensive study of six critical application domains, covering autonomous transportation, industrial IoT, healthcare digital twins, UAV communications, LLM ecosystems, and metaverse settings, we illustrate the revolutionary promise of multi-dimensional information metrics for meeting diverse operational needs. Our survey identifies prominent implementation challenges, including ...",
    "categories": [
      "cs.NI",
      "cs.AI"
    ],
    "primary_category": "cs.NI",
    "comment": "48 pages, 14 figures, submitted to IEEE",
    "pdf_url": "https://arxiv.org/pdf/2507.19657v1",
    "published_date": "2025-07-25 20:03:38 UTC",
    "updated_date": "2025-07-25 20:03:38 UTC"
  },
  {
    "arxiv_id": "2507.19653v1",
    "title": "On the Limitations of Ray-Tracing for Learning-Based RF Tasks in Urban Environments",
    "authors": [
      "Armen Manukyan",
      "Hrant Khachatrian",
      "Edvard Ghukasyan",
      "Theofanis P. Raptis"
    ],
    "abstract": "We study the realism of Sionna v1.0.2 ray-tracing for outdoor cellular links in central Rome. We use a real measurement set of 1,664 user-equipments (UEs) and six nominal base-station (BS) sites. Using these fixed positions we systematically vary the main simulation parameters, including path depth, diffuse/specular/refraction flags, carrier frequency, as well as antenna's properties like its altitude, radiation pattern, and orientation. Simulator fidelity is scored for each base station via Spearman correlation between measured and simulated powers, and by a fingerprint-based k-nearest-neighbor localization algorithm using RSSI-based fingerprints. Across all experiments, solver hyper-parameters are having immaterial effect on the chosen metrics. On the contrary, antenna locations and orientations prove decisive. By simple greedy optimization we improve the Spearman correlation by 5% to 130% for various base stations, while kNN-based localization error using only simulated data as reference points is decreased by one-third on real-world samples, while staying twice higher than the error with purely real data. Precise geometry and credible antenna models are therefore necessary but not sufficient; faithfully capturing the residual urban noise remains an open challenge for transferable, high-fidelity outdoor RF simulation.",
    "categories": [
      "cs.NI",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.NI",
    "comment": "This work has been submitted to the IEEE for possible publication. This work was supported by funding under the bilateral agreement between CNR (Italy) and HESC MESCS RA (Armenia) as part of the DeepRF project for the 2025-2026 biennium, and by the HESC MESCS RA grant No. 22rl-052 (DISTAL)",
    "pdf_url": "https://arxiv.org/pdf/2507.19653v1",
    "published_date": "2025-07-25 19:58:44 UTC",
    "updated_date": "2025-07-25 19:58:44 UTC"
  },
  {
    "arxiv_id": "2507.19647v1",
    "title": "GABRIL: Gaze-Based Regularization for Mitigating Causal Confusion in Imitation Learning",
    "authors": [
      "Amin Banayeeanzade",
      "Fatemeh Bahrani",
      "Yutai Zhou",
      "Erdem Bıyık"
    ],
    "abstract": "Imitation Learning (IL) is a widely adopted approach which enables agents to learn from human expert demonstrations by framing the task as a supervised learning problem. However, IL often suffers from causal confusion, where agents misinterpret spurious correlations as causal relationships, leading to poor performance in testing environments with distribution shift. To address this issue, we introduce GAze-Based Regularization in Imitation Learning (GABRIL), a novel method that leverages the human gaze data gathered during the data collection phase to guide the representation learning in IL. GABRIL utilizes a regularization loss which encourages the model to focus on causally relevant features identified through expert gaze and consequently mitigates the effects of confounding variables. We validate our approach in Atari environments and the Bench2Drive benchmark in CARLA by collecting human gaze datasets and applying our method in both domains. Experimental results show that the improvement of GABRIL over behavior cloning is around 179% more than the same number for other baselines in the Atari and 76% in the CARLA setup. Finally, we show that our method provides extra explainability when compared to regular IL agents.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "IROS 2025 camera-ready version. First two authors contributed equally",
    "pdf_url": "https://arxiv.org/pdf/2507.19647v1",
    "published_date": "2025-07-25 19:47:04 UTC",
    "updated_date": "2025-07-25 19:47:04 UTC"
  },
  {
    "arxiv_id": "2507.21170v2",
    "title": "OneShield -- the Next Generation of LLM Guardrails",
    "authors": [
      "Chad DeLuca",
      "Anna Lisa Gentile",
      "Shubhi Asthana",
      "Bing Zhang",
      "Pawan Chowdhary",
      "Kellen Cheng",
      "Basel Shbita",
      "Pengyuan Li",
      "Guang-Jie Ren",
      "Sandeep Gopisetty"
    ],
    "abstract": "The rise of Large Language Models has created a general excitement about the great potential for a myriad of applications. While LLMs offer many possibilities, questions about safety, privacy, and ethics have emerged, and all the key actors are working to address these issues with protective measures for their own models and standalone solutions. The constantly evolving nature of LLMs makes it extremely challenging to universally shield users against their potential risks, and one-size-fits-all solutions are unfeasible. In this work, we propose OneShield, our stand-alone, model-agnostic and customizable solution to safeguard LLMs. OneShield aims to provide facilities for defining risk factors, expressing and declaring contextual safety and compliance policies, and mitigating LLM risks, with a focus on each specific customer. We describe the implementation of the framework, discuss scalability considerations, and provide usage statistics of OneShield since its initial deployment.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.21170v2",
    "published_date": "2025-07-25 19:44:38 UTC",
    "updated_date": "2025-07-31 18:07:13 UTC"
  },
  {
    "arxiv_id": "2508.05647v1",
    "title": "Query-Aware Graph Neural Networks for Enhanced Retrieval-Augmented Generation",
    "authors": [
      "Vibhor Agrawal",
      "Fay Wang",
      "Rishi Puri"
    ],
    "abstract": "We present a novel graph neural network (GNN) architecture for retrieval-augmented generation (RAG) that leverages query-aware attention mechanisms and learned scoring heads to improve retrieval accuracy on complex, multi-hop questions. Unlike traditional dense retrieval methods that treat documents as independent entities, our approach constructs per-episode knowledge graphs that capture both sequential and semantic relationships between text chunks. We introduce an Enhanced Graph Attention Network with query-guided pooling that dynamically focuses on relevant parts of the graph based on user queries. Experimental results demonstrate that our approach significantly outperforms standard dense retrievers on complex question answering tasks, particularly for questions requiring multi-document reasoning. Our implementation leverages PyTorch Geometric for efficient processing of graph-structured data, enabling scalable deployment in production retrieval systems",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.05647v1",
    "published_date": "2025-07-25 19:42:27 UTC",
    "updated_date": "2025-07-25 19:42:27 UTC"
  },
  {
    "arxiv_id": "2507.21169v1",
    "title": "Trustworthy AI: UK Air Traffic Control Revisited",
    "authors": [
      "Rob Procter",
      "Mark Rouncefield"
    ],
    "abstract": "Exploring the socio-technical challenges confronting the adoption of AI in organisational settings is something that has so far been largely absent from the related literature. In particular, research into requirements for trustworthy AI typically overlooks how people deal with the problems of trust in the tools that they use as part of their everyday work practices. This article presents some findings from an ongoing ethnographic study of how current tools are used in air traffic control work and what it reveals about requirements for trustworthy AI in air traffic control and other safety-critical application domains.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "6 pages",
    "pdf_url": "https://arxiv.org/pdf/2507.21169v1",
    "published_date": "2025-07-25 19:40:01 UTC",
    "updated_date": "2025-07-25 19:40:01 UTC"
  },
  {
    "arxiv_id": "2507.19643v1",
    "title": "Can You Share Your Story? Modeling Clients' Metacognition and Openness for LLM Therapist Evaluation",
    "authors": [
      "Minju Kim",
      "Dongje Yoo",
      "Yeonjun Hwang",
      "Minseok Kang",
      "Namyoung Kim",
      "Minju Gwak",
      "Beong-woo Kwak",
      "Hyungjoo Chae",
      "Harim Kim",
      "Yunjoong Lee",
      "Min Hee Kim",
      "Dayi Jung",
      "Kyong-Mee Chung",
      "Jinyoung Yeo"
    ],
    "abstract": "Understanding clients' thoughts and beliefs is fundamental in counseling, yet current evaluations of LLM therapists often fail to assess this ability. Existing evaluation methods rely on client simulators that clearly disclose internal states to the therapist, making it difficult to determine whether an LLM therapist can uncover unexpressed perspectives. To address this limitation, we introduce MindVoyager, a novel evaluation framework featuring a controllable and realistic client simulator which dynamically adapts itself based on the ongoing counseling session, offering a more realistic and challenging evaluation environment. We further introduce evaluation metrics that assess the exploration ability of LLM therapists by measuring their thorough understanding of client's beliefs and thoughts.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "Published at ACL 2025 Findings",
    "pdf_url": "https://arxiv.org/pdf/2507.19643v1",
    "published_date": "2025-07-25 19:32:05 UTC",
    "updated_date": "2025-07-25 19:32:05 UTC"
  },
  {
    "arxiv_id": "2507.22944v1",
    "title": "Opacity as Authority: Arbitrariness and the Preclusion of Contestation",
    "authors": [
      "Naomi Omeonga wa Kayembe"
    ],
    "abstract": "This article redefines arbitrariness not as a normative flaw or a symptom of domination, but as a foundational functional mechanism structuring human systems and interactions. Diverging from critical traditions that conflate arbitrariness with injustice, it posits arbitrariness as a semiotic trait: a property enabling systems - linguistic, legal, or social - to operate effectively while withholding their internal rationale. Building on Ferdinand de Saussure's concept of l'arbitraire du signe, the analysis extends this principle beyond language to demonstrate its cross-domain applicability, particularly in law and social dynamics. The paper introduces the \"Motivation -> Constatability -> Contestability\" chain, arguing that motivation functions as a crucial interface rendering an act's logic vulnerable to intersubjective contestation. When this chain is broken through mechanisms like \"immotivization\" or \"Conflict Lateralization\" (exemplified by \"the blur of the wolf drowned in the fish\"), acts produce binding effects without exposing their rationale, thus precluding justiciability. This structural opacity, while appearing illogical, is a deliberate design protecting authority from accountability. Drawing on Shannon's entropy model, the paper formalizes arbitrariness as A = H(L|M) (conditional entropy). It thereby proposes a modern theory of arbitrariness as a neutral operator central to control as well as care, an overlooked dimension of interpersonal relations. While primarily developed through human social systems, this framework also illuminates a new pathway for analyzing explainability in advanced artificial intelligence systems.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.22944v1",
    "published_date": "2025-07-25 19:10:35 UTC",
    "updated_date": "2025-07-25 19:10:35 UTC"
  },
  {
    "arxiv_id": "2507.19635v1",
    "title": "Efficient and Scalable Agentic AI with Heterogeneous Systems",
    "authors": [
      "Zain Asgar",
      "Michelle Nguyen",
      "Sachin Katti"
    ],
    "abstract": "AI agents are emerging as a dominant workload in a wide range of applications, promising to be the vehicle that delivers the promised benefits of AI to enterprises and consumers. Unlike conventional software or static inference, agentic workloads are dynamic and structurally complex. Often these agents are directed graphs of compute and IO operations that span multi-modal data input and conversion), data processing and context gathering (e.g vector DB lookups), multiple LLM inferences, tool calls, etc. To scale AI agent usage, we need efficient and scalable deployment and agent-serving infrastructure.\n  To tackle this challenge, in this paper, we present a system design for dynamic orchestration of AI agent workloads on heterogeneous compute infrastructure spanning CPUs and accelerators, both from different vendors and across different performance tiers within a single vendor. The system delivers several building blocks: a framework for planning and optimizing agentic AI execution graphs using cost models that account for compute, memory, and bandwidth constraints of different HW; a MLIR based representation and compilation system that can decompose AI agent execution graphs into granular operators and generate code for different HW options; and a dynamic orchestration system that can place the granular components across a heterogeneous compute infrastructure and stitch them together while meeting an end-to-end SLA. Our design performs a systems level TCO optimization and preliminary results show that leveraging a heterogeneous infrastructure can deliver significant TCO benefits. A preliminary surprising finding is that for some workloads a heterogeneous combination of older generation GPUs with newer accelerators can deliver similar TCO as the latest generation homogenous GPU infrastructure design, potentially extending the life of deployed infrastructure.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.DC"
    ],
    "primary_category": "cs.LG",
    "comment": "Early access preprint",
    "pdf_url": "https://arxiv.org/pdf/2507.19635v1",
    "published_date": "2025-07-25 19:02:42 UTC",
    "updated_date": "2025-07-25 19:02:42 UTC"
  },
  {
    "arxiv_id": "2507.19634v2",
    "title": "MCIF: Multimodal Crosslingual Instruction-Following Benchmark from Scientific Talks",
    "authors": [
      "Sara Papi",
      "Maike Züfle",
      "Marco Gaido",
      "Beatrice Savoldi",
      "Danni Liu",
      "Ioannis Douros",
      "Luisa Bentivogli",
      "Jan Niehues"
    ],
    "abstract": "Recent advances in large language models have catalyzed the development of multimodal LLMs (MLLMs) that integrate text, speech, and vision within unified frameworks. As MLLMs evolve from narrow, monolingual, task-specific systems to general-purpose instruction-following models, a key frontier lies in evaluating their multilingual and multimodal capabilities over both long and short contexts. However, existing benchmarks fall short in evaluating these dimensions jointly: they are often limited to English, mostly focus on one single modality at a time, rely on short-form contexts, or lack human annotations -- hindering comprehensive assessment of model performance across languages, modalities, and task complexity. To address these gaps, we introduce MCIF (Multimodal Crosslingual Instruction Following), the first multilingual human-annotated benchmark based on scientific talks that is designed to evaluate instruction-following in crosslingual, multimodal settings over both short- and long-form inputs. MCIF spans three core modalities -- speech, vision, and text -- and four diverse languages (English, German, Italian, and Chinese), enabling a comprehensive evaluation of MLLMs' abilities to interpret instructions across languages and combine them with multimodal contextual information. MCIF is released under a CC-BY 4.0 license to encourage open research and progress in MLLMs development.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CV",
      "cs.SD"
    ],
    "primary_category": "cs.CL",
    "comment": "Data available at https://huggingface.co/datasets/FBK-MT/MCIF | Evaluation and baselines available at https://github.com/hlt-mt/mcif",
    "pdf_url": "https://arxiv.org/pdf/2507.19634v2",
    "published_date": "2025-07-25 19:00:51 UTC",
    "updated_date": "2025-10-23 13:44:32 UTC"
  },
  {
    "arxiv_id": "2507.19629v1",
    "title": "Quantum Reinforcement Learning by Adaptive Non-local Observables",
    "authors": [
      "Hsin-Yi Lin",
      "Samuel Yen-Chi Chen",
      "Huan-Hsin Tseng",
      "Shinjae Yoo"
    ],
    "abstract": "Hybrid quantum-classical frameworks leverage quantum computing for machine learning; however, variational quantum circuits (VQCs) are limited by the need for local measurements. We introduce an adaptive non-local observable (ANO) paradigm within VQCs for quantum reinforcement learning (QRL), jointly optimizing circuit parameters and multi-qubit measurements. The ANO-VQC architecture serves as the function approximator in Deep Q-Network (DQN) and Asynchronous Advantage Actor-Critic (A3C) algorithms. On multiple benchmark tasks, ANO-VQC agents outperform baseline VQCs. Ablation studies reveal that adaptive measurements enhance the function space without increasing circuit depth. Our results demonstrate that adaptive multi-qubit observables can enable practical quantum advantages in reinforcement learning.",
    "categories": [
      "quant-ph",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "quant-ph",
    "comment": "Accepted at IEEE Quantum Week 2025 (QCE 2025)",
    "pdf_url": "https://arxiv.org/pdf/2507.19629v1",
    "published_date": "2025-07-25 18:57:16 UTC",
    "updated_date": "2025-07-25 18:57:16 UTC"
  },
  {
    "arxiv_id": "2507.19608v1",
    "title": "DeltaLLM: A Training-Free Framework Exploiting Temporal Sparsity for Efficient Edge LLM Inference",
    "authors": [
      "Jiawen Qi",
      "Chang Gao",
      "Zhaochun Ren",
      "Qinyu Chen"
    ],
    "abstract": "Deploying Large Language Models (LLMs) on edge devices remains challenging due to their quadratically increasing computations with the sequence length. Existing studies for dynamic attention pruning are designed for hardware with massively parallel computation capabilities, such as GPUs or TPUs, and aim at long context lengths (e.g., 64K), making them unsuitable for edge scenarios. We present DeltaLLM, a training-free framework that exploits temporal sparsity in attention patterns to enable efficient LLM inference across both the prefilling and decoding stages, on resource-constrained edge devices. DeltaLLM introduces an accuracy- and memory-aware delta matrix construction strategy that introduces temporal sparsity, and a context-aware hybrid attention mechanism that combines full attention in a local context window with delta approximation outside it to increase accuracy. We evaluate our framework on the edge-device-friendly BitNet-b1.58-2B-4T model and Llama3.2-1B-Instruct model across diverse language tasks. The results show that on BitNet, our framework increases the attention sparsity from 0% to 60% during the prefilling stage with slight accuracy improvement on the WG task, and 0% to 57% across both the prefilling and decoding stages, with even higher F1 score from 29.63 to 30.97 on SQuAD-v2 task. On the Llama model, it can also achieve up to 60% sparsity during the prefilling stage and around 57% across both stages with negligible accuracy drop. These results demonstrate that DeltaLLM offers a promising solution for efficient edge deployment, requiring no fine-tuning and seamlessly integrating with existing inference pipelines.",
    "categories": [
      "cs.AI",
      "eess.SP"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.19608v1",
    "published_date": "2025-07-25 18:23:18 UTC",
    "updated_date": "2025-07-25 18:23:18 UTC"
  },
  {
    "arxiv_id": "2507.19598v1",
    "title": "MOCHA: Are Code Language Models Robust Against Multi-Turn Malicious Coding Prompts?",
    "authors": [
      "Muntasir Wahed",
      "Xiaona Zhou",
      "Kiet A. Nguyen",
      "Tianjiao Yu",
      "Nirav Diwan",
      "Gang Wang",
      "Dilek Hakkani-Tür",
      "Ismini Lourentzou"
    ],
    "abstract": "Recent advancements in Large Language Models (LLMs) have significantly enhanced their code generation capabilities. However, their robustness against adversarial misuse, particularly through multi-turn malicious coding prompts, remains underexplored. In this work, we introduce code decomposition attacks, where a malicious coding task is broken down into a series of seemingly benign subtasks across multiple conversational turns to evade safety filters. To facilitate systematic evaluation, we introduce \\benchmarkname{}, a large-scale benchmark designed to evaluate the robustness of code LLMs against both single-turn and multi-turn malicious prompts. Empirical results across open- and closed-source models reveal persistent vulnerabilities, especially under multi-turn scenarios. Fine-tuning on MOCHA improves rejection rates while preserving coding ability, and importantly, enhances robustness on external adversarial datasets with up to 32.4% increase in rejection rates without any additional supervision.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CR",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Winner Defender Team at Amazon Nova AI Challenge 2025",
    "pdf_url": "https://arxiv.org/pdf/2507.19598v1",
    "published_date": "2025-07-25 18:11:10 UTC",
    "updated_date": "2025-07-25 18:11:10 UTC"
  },
  {
    "arxiv_id": "2507.19595v2",
    "title": "Efficient Attention Mechanisms for Large Language Models: A Survey",
    "authors": [
      "Yutao Sun",
      "Zhenyu Li",
      "Yike Zhang",
      "Tengyu Pan",
      "Bowen Dong",
      "Yuyi Guo",
      "Jianyong Wang"
    ],
    "abstract": "Transformer-based architectures have become the prevailing backbone of large language models. However, the quadratic time and memory complexity of self-attention remains a fundamental obstacle to efficient long-context modeling. To address this limitation, recent research has introduced two principal categories of efficient attention mechanisms. Linear attention methods achieve linear complexity through kernel approximations, recurrent formulations, or fastweight dynamics, thereby enabling scalable inference with reduced computational overhead. Sparse attention techniques, in contrast, limit attention computation to selected subsets of tokens based on fixed patterns, block-wise routing, or clustering strategies, enhancing efficiency while preserving contextual coverage. This survey provides a systematic and comprehensive overview of these developments, integrating both algorithmic innovations and hardware-level considerations. In addition, we analyze the incorporation of efficient attention into largescale pre-trained language models, including both architectures built entirely on efficient attention and hybrid designs that combine local and global components. By aligning theoretical foundations with practical deployment strategies, this work aims to serve as a foundational reference for advancing the design of scalable and efficient language models.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "work in progress",
    "pdf_url": "https://arxiv.org/pdf/2507.19595v2",
    "published_date": "2025-07-25 18:08:10 UTC",
    "updated_date": "2025-08-07 10:08:17 UTC"
  },
  {
    "arxiv_id": "2507.19593v1",
    "title": "Hypergames: Modeling Misaligned Perceptions and Nested Beliefs for Multi-agent Systems",
    "authors": [
      "Vince Trencsenyi",
      "Agnieszka Mensfelt",
      "Kostas Stathis"
    ],
    "abstract": "Classical game-theoretic models typically assume rational agents, complete information, and common knowledge of payoffs - assumptions that are often violated in real-world MAS characterized by uncertainty, misaligned perceptions, and nested beliefs. To overcome these limitations, researchers have proposed extensions that incorporate models of cognitive constraints, subjective beliefs, and heterogeneous reasoning. Among these, hypergame theory extends the classical paradigm by explicitly modeling agents' subjective perceptions of the strategic scenario, known as perceptual games, in which agents may hold divergent beliefs about the structure, payoffs, or available actions. We present a systematic review of agent-compatible applications of hypergame theory, examining how its descriptive capabilities have been adapted to dynamic and interactive MAS contexts. We analyze 44 selected studies from cybersecurity, robotics, social simulation, communications, and general game-theoretic modeling. Building on a formal introduction to hypergame theory and its two major extensions - hierarchical hypergames and HNF - we develop agent-compatibility criteria and an agent-based classification framework to assess integration patterns and practical applicability. Our analysis reveals prevailing tendencies, including the prevalence of hierarchical and graph-based models in deceptive reasoning and the simplification of extensive theoretical frameworks in practical applications. We identify structural gaps, including the limited adoption of HNF-based models, the lack of formal hypergame languages, and unexplored opportunities for modeling human-agent and agent-agent misalignment. By synthesizing trends, challenges, and open research directions, this review provides a new roadmap for applying hypergame theory to enhance the realism and effectiveness of strategic modeling in dynamic multi-agent environments.",
    "categories": [
      "cs.AI",
      "cs.MA"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.19593v1",
    "published_date": "2025-07-25 18:06:41 UTC",
    "updated_date": "2025-07-25 18:06:41 UTC"
  },
  {
    "arxiv_id": "2507.19586v1",
    "title": "Mitigating Geospatial Knowledge Hallucination in Large Language Models: Benchmarking and Dynamic Factuality Aligning",
    "authors": [
      "Shengyuan Wang",
      "Jie Feng",
      "Tianhui Liu",
      "Dan Pei",
      "Yong Li"
    ],
    "abstract": "Large language models (LLMs) possess extensive world knowledge, including geospatial knowledge, which has been successfully applied to various geospatial tasks such as mobility prediction and social indicator prediction. However, LLMs often generate inaccurate geospatial knowledge, leading to geospatial hallucinations (incorrect or inconsistent representations of geospatial information) that compromise their reliability. While the phenomenon of general knowledge hallucination in LLMs has been widely studied, the systematic evaluation and mitigation of geospatial hallucinations remain largely unexplored. To address this gap, we propose a comprehensive evaluation framework for geospatial hallucinations, leveraging structured geospatial knowledge graphs for controlled assessment. Through extensive evaluation across 20 advanced LLMs, we uncover the hallucinations in their geospatial knowledge. Building on these insights, we introduce a dynamic factuality aligning method based on Kahneman-Tversky Optimization (KTO) to mitigate geospatial hallucinations in LLMs, leading to a performance improvement of over 29.6% on the proposed benchmark. Extensive experimental results demonstrate the effectiveness of our benchmark and learning algorithm in enhancing the trustworthiness of LLMs in geospatial knowledge and reasoning tasks.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "19 pages, 9 figures",
    "pdf_url": "https://arxiv.org/pdf/2507.19586v1",
    "published_date": "2025-07-25 18:00:21 UTC",
    "updated_date": "2025-07-25 18:00:21 UTC"
  },
  {
    "arxiv_id": "2507.19477v1",
    "title": "Advancing Event Forecasting through Massive Training of Large Language Models: Challenges, Solutions, and Broader Impacts",
    "authors": [
      "Sang-Woo Lee",
      "Sohee Yang",
      "Donghyun Kwak",
      "Noah Y. Siegel"
    ],
    "abstract": "Many recent papers have studied the development of superforecaster-level event forecasting LLMs. While methodological problems with early studies cast doubt on the use of LLMs for event forecasting, recent studies with improved evaluation methods have shown that state-of-the-art LLMs are gradually reaching superforecaster-level performance, and reinforcement learning has also been reported to improve future forecasting. Additionally, the unprecedented success of recent reasoning models and Deep Research-style models suggests that technology capable of greatly improving forecasting performance has been developed. Therefore, based on these positive recent trends, we argue that the time is ripe for research on large-scale training of superforecaster-level event forecasting LLMs. We discuss two key research directions: training methods and data acquisition. For training, we first introduce three difficulties of LLM-based event forecasting training: noisiness-sparsity, knowledge cut-off, and simple reward structure problems. Then, we present related ideas to mitigate these problems: hypothetical event Bayesian networks, utilizing poorly-recalled and counterfactual events, and auxiliary reward signals. For data, we propose aggressive use of market, public, and crawling datasets to enable large-scale training and evaluation. Finally, we explain how these technical advances could enable AI to provide predictive intelligence to society in broader areas. This position paper presents promising specific paths and considerations for getting closer to superforecaster-level AI technology, aiming to call for researchers' interest in these directions.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.19477v1",
    "published_date": "2025-07-25 17:59:13 UTC",
    "updated_date": "2025-07-25 17:59:13 UTC"
  },
  {
    "arxiv_id": "2507.19473v1",
    "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential Recommendations with Content-Based Initialization",
    "authors": [
      "Anton Pembek",
      "Artem Fatkulin",
      "Anton Klenitskiy",
      "Alexey Vasilev"
    ],
    "abstract": "Many sequential recommender systems suffer from the cold start problem, where items with few or no interactions cannot be effectively used by the model due to the absence of a trained embedding. Content-based approaches, which leverage item metadata, are commonly used in such scenarios. One possible way is to use embeddings derived from content features such as textual descriptions as initialization for the model embeddings. However, directly using frozen content embeddings often results in suboptimal performance, as they may not fully adapt to the recommendation task. On the other hand, fine-tuning these embeddings can degrade performance for cold-start items, as item representations may drift far from their original structure after training. We propose a novel approach to address this limitation. Instead of entirely freezing the content embeddings or fine-tuning them extensively, we introduce a small trainable delta to frozen embeddings that enables the model to adapt item representations without letting them go too far from their original semantic structure. This approach demonstrates consistent improvements across multiple datasets and modalities, including e-commerce datasets with textual descriptions and a music dataset with audio-based representation.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.19473v1",
    "published_date": "2025-07-25 17:57:31 UTC",
    "updated_date": "2025-07-25 17:57:31 UTC"
  },
  {
    "arxiv_id": "2507.19458v1",
    "title": "Hierarchical Deep Reinforcement Learning Framework for Multi-Year Asset Management Under Budget Constraints",
    "authors": [
      "Amir Fard",
      "Arnold X. -X. Yuan"
    ],
    "abstract": "Budget planning and maintenance optimization are crucial for infrastructure asset management, ensuring cost-effectiveness and sustainability. However, the complexity arising from combinatorial action spaces, diverse asset deterioration, stringent budget constraints, and environmental uncertainty significantly limits existing methods' scalability. This paper proposes a Hierarchical Deep Reinforcement Learning methodology specifically tailored to multi-year infrastructure planning. Our approach decomposes the problem into two hierarchical levels: a high-level Budget Planner allocating annual budgets within explicit feasibility bounds, and a low-level Maintenance Planner prioritizing assets within the allocated budget. By structurally separating macro-budget decisions from asset-level prioritization and integrating linear programming projection within a hierarchical Soft Actor-Critic framework, the method efficiently addresses exponential growth in the action space and ensures rigorous budget compliance. A case study evaluating sewer networks of varying sizes (10, 15, and 20 sewersheds) illustrates the effectiveness of the proposed approach. Compared to conventional Deep Q-Learning and enhanced genetic algorithms, our methodology converges more rapidly, scales effectively, and consistently delivers near-optimal solutions even as network size grows.",
    "categories": [
      "cs.AI",
      "cs.LG",
      "eess.SY",
      "math.OC"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.19458v1",
    "published_date": "2025-07-25 17:42:34 UTC",
    "updated_date": "2025-07-25 17:42:34 UTC"
  },
  {
    "arxiv_id": "2507.19457v1",
    "title": "GEPA: Reflective Prompt Evolution Can Outperform Reinforcement Learning",
    "authors": [
      "Lakshya A Agrawal",
      "Shangyin Tan",
      "Dilara Soylu",
      "Noah Ziems",
      "Rishi Khare",
      "Krista Opsahl-Ong",
      "Arnav Singhvi",
      "Herumb Shandilya",
      "Michael J Ryan",
      "Meng Jiang",
      "Christopher Potts",
      "Koushik Sen",
      "Alexandros G. Dimakis",
      "Ion Stoica",
      "Dan Klein",
      "Matei Zaharia",
      "Omar Khattab"
    ],
    "abstract": "Large language models (LLMs) are increasingly adapted to downstream tasks via reinforcement learning (RL) methods like Group Relative Policy Optimization (GRPO), which often require thousands of rollouts to learn new tasks. We argue that the interpretable nature of language can often provide a much richer learning medium for LLMs, compared with policy gradients derived from sparse, scalar rewards. To test this, we introduce GEPA (Genetic-Pareto), a prompt optimizer that thoroughly incorporates natural language reflection to learn high-level rules from trial and error. Given any AI system containing one or more LLM prompts, GEPA samples system-level trajectories (e.g., reasoning, tool calls, and tool outputs) and reflects on them in natural language to diagnose problems, propose and test prompt updates, and combine complementary lessons from the Pareto frontier of its own attempts. As a result of GEPA's design, it can often turn even just a few rollouts into a large quality gain. Across four tasks, GEPA outperforms GRPO by 10% on average and by up to 20%, while using up to 35x fewer rollouts. GEPA also outperforms the leading prompt optimizer, MIPROv2, by over 10% across two LLMs, and demonstrates promising results as an inference-time search strategy for code optimization.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG",
      "cs.SE"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.19457v1",
    "published_date": "2025-07-25 17:42:32 UTC",
    "updated_date": "2025-07-25 17:42:32 UTC"
  },
  {
    "arxiv_id": "2508.00017v2",
    "title": "Generative Logic: A New Computer Architecture for Deterministic Reasoning and Knowledge Generation",
    "authors": [
      "Nikolai Sergeev"
    ],
    "abstract": "We present Generative Logic (GL), a deterministic architecture that starts from user-supplied axiomatic definitions (and, optionally, a list of simple facts for counterexample (CE) construction), written in a minimalist Mathematical Programming Language (MPL), and systematically explores their deductive neighborhood. Definitions are compiled into a distributed grid of simple Logic Blocks (LBs) that exchange messages; whenever the premises of an inference rule unify, a new fact is emitted with full provenance to its sources, yielding replayable, auditable proof graphs. A prototype software implementation instantiates the workflow on first-order Peano arithmetic. Starting only from the Peano axioms, GL enumerates conjectures, applies normalization, type, and CE filter, and automatically reconstructs machine-checkable proofs of foundational arithmetic laws, including associativity and commutativity of addition, associativity and commutativity of multiplication, and distributivity. On commodity hardware, the prover phase requires approximately 7 seconds; a complete run finishes in about 5 minutes. Generated proofs export to navigable HTML so that every inference step can be inspected independently. We outline a hardware-software co-design path toward massively parallel realizations and describe prospective integration with probabilistic models (e.g., large language models) for auto-formalization and conjecture seeding. The Python, C++, and MPL code to reproduce the Peano experiments, along with the full proof graphs in HTML as well as machine-readable text format, are available in the project's GitHub repository at github.com/Generative-Logic/GL commit 56c9233 and are permanently archived at doi:10.5281/zenodo.17206386.",
    "categories": [
      "cs.LO",
      "cs.AI",
      "cs.AR"
    ],
    "primary_category": "cs.LO",
    "comment": "v2: Performance update (conjecturer ~250 s; CE filter ~30 s; prover ~7 s; peak RAM ~1 GB). Added Counterexample Filter section and workflow clarifications. Updated code/artifact links. 18 pages, 5 figures. Code and HTML proof graphs archived at Zenodo (DOI: 10.5281/zenodo.17206386)",
    "pdf_url": "https://arxiv.org/pdf/2508.00017v2",
    "published_date": "2025-07-25 17:29:19 UTC",
    "updated_date": "2025-09-26 11:33:45 UTC"
  },
  {
    "arxiv_id": "2507.19427v1",
    "title": "Step-3 is Large yet Affordable: Model-system Co-design for Cost-effective Decoding",
    "authors": [
      "StepFun",
      ":",
      "Bin Wang",
      "Bojun Wang",
      "Changyi Wan",
      "Guanzhe Huang",
      "Hanpeng Hu",
      "Haonan Jia",
      "Hao Nie",
      "Mingliang Li",
      "Nuo Chen",
      "Siyu Chen",
      "Song Yuan",
      "Wuxun Xie",
      "Xiaoniu Song",
      "Xing Chen",
      "Xingping Yang",
      "Xuelin Zhang",
      "Yanbo Yu",
      "Yaoyu Wang",
      "Yibo Zhu",
      "Yimin Jiang",
      "Yu Zhou",
      "Yuanwei Lu",
      "Houyi Li",
      "Jingcheng Hu",
      "Ka Man Lo",
      "Ailin Huang",
      "Binxing Jiao",
      "Bo Li",
      "Boyu Chen",
      "Changxin Miao",
      "Chang Lou",
      "Chen Hu",
      "Chen Xu",
      "Chenfeng Yu",
      "Chengyuan Yao",
      "Daokuan Lv",
      "Dapeng Shi",
      "Deshan Sun",
      "Ding Huang",
      "Dingyuan Hu",
      "Dongqing Pang",
      "Enle Liu",
      "Fajie Zhang",
      "Fanqi Wan",
      "Gulin Yan",
      "Han Zhang",
      "Han Zhou",
      "Hanghao Wu",
      "Hangyu Guo",
      "Hanqi Chen",
      "Hanshan Zhang",
      "Hao Wu",
      "Haocheng Zhang",
      "Haolong Yan",
      "Haoran Lv",
      "Haoran Wei",
      "Hebin Zhou",
      "Heng Wang",
      "Heng Wang",
      "Hongxin Li",
      "Hongyu Zhou",
      "Hongyuan Wang",
      "Huiyong Guo",
      "Jia Wang",
      "Jiahao Gong",
      "Jialing Xie",
      "Jian Zhou",
      "Jianjian Sun",
      "Jiaoren Wu",
      "Jiaran Zhang",
      "Jiayu Liu",
      "Jie Cheng",
      "Jie Luo",
      "Jie Yan",
      "Jie Yang",
      "Jieyi Hou",
      "Jinguang Zhang",
      "Jinlan Cao",
      "Jisheng Yin",
      "Junfeng Liu",
      "Junhao Huang",
      "Junzhe Lin",
      "Kaijun Tan",
      "Kaixiang Li",
      "Kang An",
      "Kangheng Lin",
      "Kenkun Liu",
      "Lei Yang",
      "Liang Zhao",
      "Liangyu Chen",
      "Lieyu Shi",
      "Liguo Tan",
      "Lin Lin",
      "Lin Zhang",
      "Lina Chen",
      "Liwen Huang",
      "Liying Shi",
      "Longlong Gu",
      "Mei Chen",
      "Mengqiang Ren",
      "Ming Li",
      "Mingzhe Chen",
      "Na Wang",
      "Nan Wu",
      "Qi Han",
      "Qian Zhao",
      "Qiang Zhang",
      "Qianni Liu",
      "Qiaohui Chen",
      "Qiling Wu",
      "Qinglin He",
      "Qinyuan Tan",
      "Qiufeng Wang",
      "Qiuping Wu",
      "Qiuyan Liang",
      "Quan Sun",
      "Rui Li",
      "Ruihang Miao",
      "Ruosi Wan",
      "Ruyan Guo",
      "Shangwu Zhong",
      "Shaoliang Pang",
      "Shengjie Fan",
      "Shijie Shang",
      "Shilei Jiang",
      "Shiliang Yang",
      "Shiming Hao",
      "Shuli Gao",
      "Siming Huang",
      "Siqi Liu",
      "Tiancheng Cao",
      "Tianhao Cheng",
      "Tianhao Peng",
      "Wang You",
      "Wei Ji",
      "Wen Sun",
      "Wenjin Deng",
      "Wenqing He",
      "Wenzhen Zheng",
      "Xi Chen",
      "Xiangwen Kong",
      "Xianzhen Luo",
      "Xiaobo Yang",
      "Xiaojia Liu",
      "Xiaoxiao Ren",
      "Xin Han",
      "Xin Li",
      "Xin Wu",
      "Xu Zhao",
      "Yanan Wei",
      "Yang Li",
      "Yangguang Li",
      "Yangshijie Xu",
      "Yanming Xu",
      "Yaqiang Shi",
      "Yeqing Shen",
      "Yi Yang",
      "Yifei Yang",
      "Yifeng Gong",
      "Yihan Chen",
      "Yijing Yang",
      "Yinmin Zhang",
      "Yizhuang Zhou",
      "Yuanhao Ding",
      "Yuantao Fan",
      "Yuanzhen Yang",
      "Yuchu Luo",
      "Yue Peng",
      "Yufan Lu",
      "Yuhang Deng",
      "Yuhe Yin",
      "Yujie Liu",
      "Yukun Chen",
      "Yuling Zhao",
      "Yun Mou",
      "Yunlong Li",
      "Yunzhou Ju",
      "Yusheng Li",
      "Yuxiang Yang",
      "Yuxiang Zhang",
      "Yuyang Chen",
      "Zejia Weng",
      "Zhe Xie",
      "Zheng Ge",
      "Zheng Gong",
      "Zhenyi Lu",
      "Zhewei Huang",
      "Zhichao Chang",
      "Zhiguo Huang",
      "Zhirui Wang",
      "Zidong Yang",
      "Zili Wang",
      "Ziqi Wang",
      "Zixin Zhang",
      "Binxing Jiao",
      "Daxin Jiang",
      "Heung-Yeung Shum",
      "Xiangyu Zhang"
    ],
    "abstract": "Large language models (LLMs) face low hardware efficiency during decoding, especially for long-context reasoning tasks. This paper introduces Step-3, a 321B-parameter VLM with hardware-aware model-system co-design optimized for minimizing decoding costs. Step-3 innovates in two key dimensions: (1) A novel Multi-Matrix Factorization Attention (MFA) mechanism that significantly reduces both KV cache size and computation while maintaining high attention expressiveness, and (2) Attention-FFN Disaggregation (AFD), a distributed inference system that decouples attention and Feed-Forward Network (FFN) layers into specialized subsystems. This co-design achieves unprecedented cost efficiency: Step-3 significantly reduces theoretical decoding costs compared with models like DeepSeek-V3 and Qwen3 MoE 235B, with the gains widening at longer context. Step-3 achieves low cost while activating 38B parameters per token (more than DeepSeek-V3 and Qwen3 MoE 235B), demonstrating that hardware-aligned attention arithmetic intensity, MoE sparsity, and AFD are critical to cost-effectiveness. We perform a head-to-head comparison with DeepSeek-V3 in its favorable scenarios. Our implementation on Hopper GPUs achieves a decoding throughput of up to 4,039 tokens per second per GPU under 50ms TPOT SLA (4K context, FP8, no MTP). It is higher than DeepSeek-V3's 2,324 in the same setup and sets a new Pareto frontier for LLM decoding.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.19427v1",
    "published_date": "2025-07-25 16:53:13 UTC",
    "updated_date": "2025-07-25 16:53:13 UTC"
  },
  {
    "arxiv_id": "2507.19568v1",
    "title": "Programmable Virtual Humans Toward Human Physiologically-Based Drug Discovery",
    "authors": [
      "You Wu",
      "Philip E. Bourne",
      "Lei Xie"
    ],
    "abstract": "Artificial intelligence (AI) has sparked immense interest in drug discovery, but most current approaches only digitize existing high-throughput experiments. They remain constrained by conventional pipelines. As a result, they do not address the fundamental challenges of predicting drug effects in humans. Similarly, biomedical digital twins, largely grounded in real-world data and mechanistic models, are tailored for late-phase drug development and lack the resolution to model molecular interactions or their systemic consequences, limiting their impact in early-stage discovery. This disconnect between early discovery and late development is one of the main drivers of high failure rates in drug discovery. The true promise of AI lies not in augmenting current experiments but in enabling virtual experiments that are impossible in the real world: testing novel compounds directly in silico in the human body. Recent advances in AI, high-throughput perturbation assays, and single-cell and spatial omics across species now make it possible to construct programmable virtual humans: dynamic, multiscale models that simulate drug actions from molecular to phenotypic levels. By bridging the translational gap, programmable virtual humans offer a transformative path to optimize therapeutic efficacy and safety earlier than ever before. This perspective introduces the concept of programmable virtual humans, explores their roles in a new paradigm of drug discovery centered on human physiology, and outlines key opportunities, challenges, and roadmaps for their realization.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.CE",
      "cs.LG"
    ],
    "primary_category": "cs.CY",
    "comment": "Under Review",
    "pdf_url": "https://arxiv.org/pdf/2507.19568v1",
    "published_date": "2025-07-25 16:40:57 UTC",
    "updated_date": "2025-07-25 16:40:57 UTC"
  },
  {
    "arxiv_id": "2507.19567v1",
    "title": "Differentiating hype from practical applications of large language models in medicine -- a primer for healthcare professionals",
    "authors": [
      "Elisha D. O. Roberson"
    ],
    "abstract": "The medical ecosystem consists of the training of new clinicians and researchers, the practice of clinical medicine, and areas of adjacent research. There are many aspects of these domains that could benefit from the application of task automation and programmatic assistance. Machine learning and artificial intelligence techniques, including large language models (LLMs), have been promised to deliver on healthcare innovation, improving care speed and accuracy, and reducing the burden on staff for manual interventions. However, LLMs have no understanding of objective truth that is based in reality. They also represent real risks to the disclosure of protected information when used by clinicians and researchers. The use of AI in medicine in general, and the deployment of LLMs in particular, therefore requires careful consideration and thoughtful application to reap the benefits of these technologies while avoiding the dangers in each context.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "7 pages main document text, 2 figures. A basic primer on the potential and dangers of AI generally and LLMs specifically in the medical care system. Targeted to *non-expert* healthcare workers without experience in AI or LLMs",
    "pdf_url": "https://arxiv.org/pdf/2507.19567v1",
    "published_date": "2025-07-25 16:40:17 UTC",
    "updated_date": "2025-07-25 16:40:17 UTC"
  },
  {
    "arxiv_id": "2507.19408v1",
    "title": "On Arbitrary Predictions from Equally Valid Models",
    "authors": [
      "Sarah Lockfisch",
      "Kristian Schwethelm",
      "Martin Menten",
      "Rickmer Braren",
      "Daniel Rueckert",
      "Alexander Ziller",
      "Georgios Kaissis"
    ],
    "abstract": "Model multiplicity refers to the existence of multiple machine learning models that describe the data equally well but may produce different predictions on individual samples. In medicine, these models can admit conflicting predictions for the same patient -- a risk that is poorly understood and insufficiently addressed.\n  In this study, we empirically analyze the extent, drivers, and ramifications of predictive multiplicity across diverse medical tasks and model architectures, and show that even small ensembles can mitigate/eliminate predictive multiplicity in practice. Our analysis reveals that (1) standard validation metrics fail to identify a uniquely optimal model and (2) a substantial amount of predictions hinges on arbitrary choices made during model development. Using multiple models instead of a single model reveals instances where predictions differ across equally plausible models -- highlighting patients that would receive arbitrary diagnoses if any single model were used. In contrast, (3) a small ensemble paired with an abstention strategy can effectively mitigate measurable predictive multiplicity in practice; predictions with high inter-model consensus may thus be amenable to automated classification. While accuracy is not a principled antidote to predictive multiplicity, we find that (4) higher accuracy achieved through increased model capacity reduces predictive multiplicity.\n  Our findings underscore the clinical importance of accounting for model multiplicity and advocate for ensemble-based strategies to improve diagnostic reliability. In cases where models fail to reach sufficient consensus, we recommend deferring decisions to expert review.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.19408v1",
    "published_date": "2025-07-25 16:15:59 UTC",
    "updated_date": "2025-07-25 16:15:59 UTC"
  },
  {
    "arxiv_id": "2507.22080v1",
    "title": "CodeEvo: Interaction-Driven Synthesis of Code-centric Data through Hybrid and Iterative Feedback",
    "authors": [
      "Qiushi Sun",
      "Jinyang Gong",
      "Lei Li",
      "Qipeng Guo",
      "Fei Yuan"
    ],
    "abstract": "Acquiring high-quality instruction-code pairs is essential for training Large Language Models (LLMs) for code generation. Manually curated data is expensive and inherently limited in scale, motivating the development of code-centric synthesis methods. Yet, current approaches either focus on augmenting existing code or rely on predefined heuristics, both lacking rigorous data validation, which results in synthetic data that is ungrounded, repetitive, or overly simplistic. Inspired by collaborative programming practices, we propose CodeEvo, a framework that synthesizes code data through iterative interactions between two LLM agents: a Coder, which generates candidate code and test cases based on given instructions, and a Reviewer, which guides the synthesis process by producing new instructions and feedback. We further introduce a hybrid feedback mechanism that combines compiler determinism with the generative flexibility of agents, enabling automatic quality control throughout synthesis. Extensive experiments demonstrate that models fine-tuned on CodeEvo data significantly outperform established baselines across code generation benchmarks with various difficulties. In-depth analyses further provide insights from multiple perspectives into effective code-centric data synthesis.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.SE",
    "comment": "Work in progress",
    "pdf_url": "https://arxiv.org/pdf/2507.22080v1",
    "published_date": "2025-07-25 16:12:51 UTC",
    "updated_date": "2025-07-25 16:12:51 UTC"
  },
  {
    "arxiv_id": "2507.19403v1",
    "title": "SDVDiag: A Modular Platform for the Diagnosis of Connected Vehicle Functions",
    "authors": [
      "Matthias Weiß",
      "Falk Dettinger",
      "Michael Weyrich"
    ],
    "abstract": "Connected and software-defined vehicles promise to offer a broad range of services and advanced functions to customers, aiming to increase passenger comfort and support autonomous driving capabilities. Due to the high reliability and availability requirements of connected vehicles, it is crucial to resolve any occurring failures quickly. To achieve this however, a complex cloud/edge architecture with a mesh of dependencies must be navigated to diagnose the responsible root cause. As such, manual analyses become unfeasible since they would significantly delay the troubleshooting.\n  To address this challenge, this paper presents SDVDiag, an extensible platform for the automated diagnosis of connected vehicle functions. The platform enables the creation of pipelines that cover all steps from initial data collection to the tracing of potential root causes. In addition, SDVDiag supports self-adaptive behavior by the ability to exchange modules at runtime. Dependencies between functions are detected and continuously updated, resulting in a dynamic graph view of the system. In addition, vital system metrics are monitored for anomalies. Whenever an incident is investigated, a snapshot of the graph is taken and augmented by relevant anomalies. Finally, the analysis is performed by traversing the graph and creating a ranking of the most likely causes.\n  To evaluate the platform, it is deployed inside an 5G test fleet environment for connected vehicle functions. The results show that injected faults can be detected reliably. As such, the platform offers the potential to gain new insights and reduce downtime by identifying problems and their causes at an early stage.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.DC"
    ],
    "primary_category": "cs.SE",
    "comment": "7 pages, 5 figures",
    "pdf_url": "https://arxiv.org/pdf/2507.19403v1",
    "published_date": "2025-07-25 16:09:27 UTC",
    "updated_date": "2025-07-25 16:09:27 UTC"
  },
  {
    "arxiv_id": "2507.19399v1",
    "title": "Running in CIRCLE? A Simple Benchmark for LLM Code Interpreter Security",
    "authors": [
      "Gabriel Chua"
    ],
    "abstract": "As large language models (LLMs) increasingly integrate native code interpreters, they enable powerful real-time execution capabilities, substantially expanding their utility. However, such integrations introduce potential system-level cybersecurity threats, fundamentally different from prompt-based vulnerabilities. To systematically evaluate these interpreter-specific risks, we propose CIRCLE (Code-Interpreter Resilience Check for LLM Exploits), a simple benchmark comprising 1,260 prompts targeting CPU, memory, and disk resource exhaustion. Each risk category includes explicitly malicious (\"direct\") and plausibly benign (\"indirect\") prompt variants. Our automated evaluation framework assesses not only whether LLMs refuse or generates risky code, but also executes the generated code within the interpreter environment to evaluate code correctness, simplifications made by the LLM to make the code safe, or execution timeouts. Evaluating 7 commercially available models from OpenAI and Google, we uncover significant and inconsistent vulnerabilities. For instance, evaluations show substantial disparities even within providers - OpenAI's o4-mini correctly refuses risky requests at 7.1%, notably higher rates compared to GPT-4.1 at 0.5%. Results particularly underscore that indirect, socially-engineered prompts substantially weaken model defenses. This highlights an urgent need for interpreter-specific cybersecurity benchmarks, dedicated mitigation tools (e.g., guardrails), and clear industry standards to guide safe and responsible deployment of LLM interpreter integrations. The benchmark dataset and evaluation code are publicly released to foster further research.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.19399v1",
    "published_date": "2025-07-25 16:06:16 UTC",
    "updated_date": "2025-07-25 16:06:16 UTC"
  },
  {
    "arxiv_id": "2507.19398v1",
    "title": "CXR-CML: Improved zero-shot classification of long-tailed multi-label diseases in Chest X-Rays",
    "authors": [
      "Rajesh Madhipati",
      "Sheethal Bhat",
      "Lukas Buess",
      "Andreas Maier"
    ],
    "abstract": "Chest radiography (CXR) plays a crucial role in the diagnosis of various diseases. However, the inherent class imbalance in the distribution of clinical findings presents a significant challenge for current self-supervised deep learning models. These models often fail to accurately classify long-tailed classes. Current Vision-Language models such as Contrastive Language Image Pre-training (CLIP) models effectively model the manifold distribution of the latent space, enabling high zero-shot classification accuracies. Although CLIP performs well on most of the primary classes in the dataset, our work reveals that its effectiveness decreases significantly for classes with a long-tailed distribution. Our approach employs a class-weighting mechanism that directly aligns with the distribution of classes within the latent space. This method ensures a substantial improvement in overall classification performance, with particular emphasis on enhancing the recognition and accuracy of rarely observed classes. We accomplish this by applying Gaussian Mixture Model (GMM) clustering to the latent space. The subsequent clusters are further refined by Student t-distribution, followed by a metric loss that utilizes the altered embeddings. Our approach facilitates stable and adaptive clustering of the features. This results in a notable average improvement of 7\\% points in zero-shot AUC scores across 40 classes in the MIMIC-CXR-JPG dataset from previous SOTA models.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.19398v1",
    "published_date": "2025-07-25 16:05:47 UTC",
    "updated_date": "2025-07-25 16:05:47 UTC"
  },
  {
    "arxiv_id": "2508.06503v1",
    "title": "Understanding Human Limits in Pattern Recognition: A Computational Model of Sequential Reasoning in Rock, Paper, Scissors",
    "authors": [
      "Logan Cross",
      "Erik Brockbank",
      "Tobias Gerstenberg",
      "Judith E. Fan",
      "Daniel L. K. Yamins",
      "Nick Haber"
    ],
    "abstract": "How do we predict others from patterns in their behavior and what are the computational constraints that limit this ability? We investigate these questions by modeling human behavior over repeated games of rock, paper, scissors from Brockbank & Vul (2024). Against algorithmic opponents that varied in strategic sophistication, people readily exploit simple transition patterns (e.g., consistently playing rock after paper) but struggle to detect more complex sequential dependencies. To understand the cognitive mechanisms underlying these abilities and their limitations, we deploy Hypothetical Minds (HM), a large language model-based agent that generates and tests hypotheses about opponent strategies, as a cognitive model of this behavior (Cross et al., 2024). We show that when applied to the same experimental conditions, HM closely mirrors human performance patterns, succeeding and failing in similar ways. To better understand the source of HM's failures and whether people might face similar cognitive bottlenecks in this context, we performed a series of ablations and augmentations targeting different components of the system. When provided with natural language descriptions of the opponents' strategies, HM successfully exploited 6/7 bot opponents with win rates >80% suggesting that accurate hypothesis generation is the primary cognitive bottleneck in this task. Further, by systematically manipulating the model's hypotheses through pedagogically-inspired interventions, we find that the model substantially updates its causal understanding of opponent behavior, revealing how model-based analyses can produce testable hypotheses about human cognition.",
    "categories": [
      "q-bio.NC",
      "cs.AI"
    ],
    "primary_category": "q-bio.NC",
    "comment": "To be published in Proceedings of the 8th Annual Conference on Cognitive Computational Neuroscience (2025)",
    "pdf_url": "https://arxiv.org/pdf/2508.06503v1",
    "published_date": "2025-07-25 15:56:25 UTC",
    "updated_date": "2025-07-25 15:56:25 UTC"
  },
  {
    "arxiv_id": "2507.19390v1",
    "title": "ReCatcher: Towards LLMs Regression Testing for Code Generation",
    "authors": [
      "Altaf Allah Abbassi",
      "Leuson Da Silva",
      "Amin Nikanjam",
      "Foutse Khomh"
    ],
    "abstract": "Large Language Models (LLMs) for code generation evolve rapidly through fine-tuning, merging, or new model releases. However, such updates can introduce regressions, not only in correctness but also in code quality and performance. To address this, we present ReCatcher, a regression testing framework for Python code generation. ReCatcher systematically compares two LLMs, typically a current model and a candidate update, across three dimensions: logical correctness, static code quality, and execution performance. We apply ReCatcher to assess regressions across three update scenarios, fine-tuning, merging, and model release, using CodeLlama, DeepSeek-Coder, and GPT-4o. Our evaluation shows that fine-tuning with cross-language datasets increases syntax errors by up to 12%. Merging with general-purpose models like Llama2 leads to regressions in correctness by up to 18%. GPT-4o introduces regressions of up to 50% in handling missing imports compared to GPT-3.5-turbo, while GPT-4o-mini suffers up to 80% performance degradation in execution time versus GPT-4o. Overall, logical correctness, performance, and error handling (e.g., syntax errors and missing imports) are the most regression-prone areas. Comparing ReCatcher with baseline solutions, it presents better and consistent accuracy across logical and performance aspects. ReCatcher highlights the importance of systematic regression evaluation before adopting new models, while assisting researchers and practitioners in making more informed update decisions.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "24 pages, 3 Figures, 2 Tables",
    "pdf_url": "https://arxiv.org/pdf/2507.19390v1",
    "published_date": "2025-07-25 15:45:55 UTC",
    "updated_date": "2025-07-25 15:45:55 UTC"
  },
  {
    "arxiv_id": "2507.21168v1",
    "title": "Diverse LLMs or Diverse Question Interpretations? That is the Ensembling Question",
    "authors": [
      "Rafael Rosales",
      "Santiago Miret"
    ],
    "abstract": "Effectively leveraging diversity has been shown to improve performance for various machine learning models, including large language models (LLMs). However, determining the most effective way of using diversity remains a challenge. In this work, we compare two diversity approaches for answering binary questions using LLMs: model diversity, which relies on multiple models answering the same question, and question interpretation diversity, which relies on using the same model to answer the same question framed in different ways. For both cases, we apply majority voting as the ensemble consensus heuristic to determine the final answer. Our experiments on boolq, strategyqa, and pubmedqa show that question interpretation diversity consistently leads to better ensemble accuracy compared to model diversity. Furthermore, our analysis of GPT and LLaMa shows that model diversity typically produces results between the best and the worst ensemble members without clear improvement.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.21168v1",
    "published_date": "2025-07-25 15:26:18 UTC",
    "updated_date": "2025-07-25 15:26:18 UTC"
  },
  {
    "arxiv_id": "2507.19374v1",
    "title": "Data Augmentation for Spoken Grammatical Error Correction",
    "authors": [
      "Penny Karanasou",
      "Mengjie Qian",
      "Stefano Bannò",
      "Mark J. F. Gales",
      "Kate M. Knill"
    ],
    "abstract": "While there exist strong benchmark datasets for grammatical error correction (GEC), high-quality annotated spoken datasets for Spoken GEC (SGEC) are still under-resourced. In this paper, we propose a fully automated method to generate audio-text pairs with grammatical errors and disfluencies. Moreover, we propose a series of objective metrics that can be used to evaluate the generated data and choose the more suitable dataset for SGEC. The goal is to generate an augmented dataset that maintains the textual and acoustic characteristics of the original data while providing new types of errors. This augmented dataset should augment and enrich the original corpus without altering the language assessment scores of the second language (L2) learners. We evaluate the use of the augmented corpus both for written GEC (the text part) and for SGEC (the audio-text pairs). Our experiments are conducted on the S\\&I Corpus, the first publicly available speech dataset with grammar error annotations.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.SD",
      "eess.AS"
    ],
    "primary_category": "cs.CL",
    "comment": "This work has been accepted by ISCA SLaTE 2025",
    "pdf_url": "https://arxiv.org/pdf/2507.19374v1",
    "published_date": "2025-07-25 15:25:17 UTC",
    "updated_date": "2025-07-25 15:25:17 UTC"
  },
  {
    "arxiv_id": "2507.19372v1",
    "title": "Learning neuro-symbolic convergent term rewriting systems",
    "authors": [
      "Flavio Petruzzellis",
      "Alberto Testolin",
      "Alessandro Sperduti"
    ],
    "abstract": "Building neural systems that can learn to execute symbolic algorithms is a challenging open problem in artificial intelligence, especially when aiming for strong generalization and out-of-distribution performance. In this work, we introduce a general framework for learning convergent term rewriting systems using a neuro-symbolic architecture inspired by the rewriting algorithm itself. We present two modular implementations of such architecture: the Neural Rewriting System (NRS) and the Fast Neural Rewriting System (FastNRS). As a result of algorithmic-inspired design and key architectural elements, both models can generalize to out-of-distribution instances, with FastNRS offering significant improvements in terms of memory efficiency, training speed, and inference time. We evaluate both architectures on four tasks involving the simplification of mathematical formulas and further demonstrate their versatility in a multi-domain learning scenario, where a single model is trained to solve multiple types of problems simultaneously. The proposed system significantly outperforms two strong neural baselines: the Neural Data Router, a recent transformer variant specifically designed to solve algorithmic problems, and GPT-4o, one of the most powerful general-purpose large-language models. Moreover, our system matches or outperforms the latest o1-preview model from OpenAI that excels in reasoning benchmarks.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "48 pages, 31 figures. Submitted for review by Artificial Intelligence Journal",
    "pdf_url": "https://arxiv.org/pdf/2507.19372v1",
    "published_date": "2025-07-25 15:24:56 UTC",
    "updated_date": "2025-07-25 15:24:56 UTC"
  },
  {
    "arxiv_id": "2507.19368v1",
    "title": "Counterfactual Explanations in Medical Imaging: Exploring SPN-Guided Latent Space Manipulation",
    "authors": [
      "Julia Siekiera",
      "Stefan Kramer"
    ],
    "abstract": "Artificial intelligence is increasingly leveraged across various domains to automate decision-making processes that significantly impact human lives. In medical image analysis, deep learning models have demonstrated remarkable performance. However, their inherent complexity makes them black box systems, raising concerns about reliability and interpretability. Counterfactual explanations provide comprehensible insights into decision processes by presenting hypothetical \"what-if\" scenarios that alter model classifications. By examining input alterations, counterfactual explanations provide patterns that influence the decision-making process. Despite their potential, generating plausible counterfactuals that adhere to similarity constraints providing human-interpretable explanations remains a challenge. In this paper, we investigate this challenge by a model-specific optimization approach. While deep generative models such as variational autoencoders (VAEs) exhibit significant generative power, probabilistic models like sum-product networks (SPNs) efficiently represent complex joint probability distributions. By modeling the likelihood of a semi-supervised VAE's latent space with an SPN, we leverage its dual role as both a latent space descriptor and a classifier for a given discrimination task. This formulation enables the optimization of latent space counterfactuals that are both close to the original data distribution and aligned with the target class distribution. We conduct experimental evaluation on the cheXpert dataset. To evaluate the effectiveness of the integration of SPNs, our SPN-guided latent space manipulation is compared against a neural network baseline. Additionally, the trade-off between latent variable regularization and counterfactual quality is analyzed.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "10 pages, 3 figures",
    "pdf_url": "https://arxiv.org/pdf/2507.19368v1",
    "published_date": "2025-07-25 15:19:32 UTC",
    "updated_date": "2025-07-25 15:19:32 UTC"
  },
  {
    "arxiv_id": "2507.19364v1",
    "title": "Integrating LLM in Agent-Based Social Simulation: Opportunities and Challenges",
    "authors": [
      "Patrick Taillandier",
      "Jean Daniel Zucker",
      "Arnaud Grignard",
      "Benoit Gaudou",
      "Nghi Quang Huynh",
      "Alexis Drogoul"
    ],
    "abstract": "This position paper examines the use of Large Language Models (LLMs) in social simulation, analyzing both their potential and their limitations from a computational social science perspective. The first part reviews recent findings on the ability of LLMs to replicate key aspects of human cognition, including Theory of Mind reasoning and social inference, while also highlighting significant limitations such as cognitive biases, lack of true understanding, and inconsistencies in behavior. The second part surveys emerging applications of LLMs in multi-agent simulation frameworks, focusing on system architectures, scale, and validation strategies. Notable projects such as Generative Agents (Smallville) and AgentSociety are discussed in terms of their design choices, empirical grounding, and methodological innovations. Particular attention is given to the challenges of behavioral fidelity, calibration, and reproducibility in large-scale LLM-driven simulations. The final section distinguishes between contexts where LLMs, like other black-box systems, offer direct value-such as interactive simulations and serious games-and those where their use is more problematic, notably in explanatory or predictive modeling. The paper concludes by advocating for hybrid approaches that integrate LLMs into traditional agent-based modeling platforms (GAMA, Netlogo, etc), enabling modelers to combine the expressive flexibility of language-based reasoning with the transparency and analytical rigor of classical rule-based systems.",
    "categories": [
      "cs.AI",
      "cs.MA"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.19364v1",
    "published_date": "2025-07-25 15:15:35 UTC",
    "updated_date": "2025-07-25 15:15:35 UTC"
  },
  {
    "arxiv_id": "2507.19362v1",
    "title": "LOTUS: A Leaderboard for Detailed Image Captioning from Quality to Societal Bias and User Preferences",
    "authors": [
      "Yusuke Hirota",
      "Boyi Li",
      "Ryo Hachiuma",
      "Yueh-Hua Wu",
      "Boris Ivanovic",
      "Yuta Nakashima",
      "Marco Pavone",
      "Yejin Choi",
      "Yu-Chiang Frank Wang",
      "Chao-Han Huck Yang"
    ],
    "abstract": "Large Vision-Language Models (LVLMs) have transformed image captioning, shifting from concise captions to detailed descriptions. We introduce LOTUS, a leaderboard for evaluating detailed captions, addressing three main gaps in existing evaluations: lack of standardized criteria, bias-aware assessments, and user preference considerations. LOTUS comprehensively evaluates various aspects, including caption quality (e.g., alignment, descriptiveness), risks (\\eg, hallucination), and societal biases (e.g., gender bias) while enabling preference-oriented evaluations by tailoring criteria to diverse user preferences. Our analysis of recent LVLMs reveals no single model excels across all criteria, while correlations emerge between caption detail and bias risks. Preference-oriented evaluations demonstrate that optimal model selection depends on user priorities.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL",
      "cs.CY",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted to ACL 2025. Leaderboard: huggingface.co/spaces/nvidia/lotus-vlm-bias-leaderboard",
    "pdf_url": "https://arxiv.org/pdf/2507.19362v1",
    "published_date": "2025-07-25 15:12:42 UTC",
    "updated_date": "2025-07-25 15:12:42 UTC"
  },
  {
    "arxiv_id": "2507.19361v2",
    "title": "SpeechIQ: Speech-Agentic Intelligence Quotient Across Cognitive Levels in Voice Understanding by Large Language Models",
    "authors": [
      "Zhen Wan",
      "Chao-Han Huck Yang",
      "Yahan Yu",
      "Jinchuan Tian",
      "Sheng Li",
      "Ke Hu",
      "Zhehuai Chen",
      "Shinji Watanabe",
      "Fei Cheng",
      "Chenhui Chu",
      "Sadao Kurohashi"
    ],
    "abstract": "We introduce Speech-based Intelligence Quotient (SIQ) as a new form of human cognition-inspired evaluation pipeline for voice understanding large language models, LLM Voice, designed to assess their voice understanding ability. Moving beyond popular voice understanding metrics such as word error rate (WER), SIQ examines LLM Voice across three cognitive levels motivated by Bloom's Taxonomy: (1) Remembering (i.e., WER for verbatim accuracy); (2) Understanding (i.e., similarity of LLM's interpretations); and (3) Application (i.e., QA accuracy for simulating downstream tasks). We demonstrate that SIQ not only quantifies voice understanding abilities but also provides unified comparisons between cascaded methods (e.g., ASR LLM) and end-to-end models, identifies annotation errors in existing benchmarks, and detects hallucinations in LLM Voice. Our framework represents a first-of-its-kind intelligence examination that bridges cognitive principles with voice-oriented benchmarks, while exposing overlooked challenges in multi-modal training. Our code and data will be open source to encourage future studies.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.SC",
      "cs.SD",
      "eess.AS"
    ],
    "primary_category": "cs.CL",
    "comment": "ACL 2025 main. Our Speech-IQ leaderboard is hosted at huggingface.co/spaces/nvidia/Speech-IQ-leaderboard. Speech-IQ Calculator: https://github.com/YukinoWan/SpeechIQ",
    "pdf_url": "https://arxiv.org/pdf/2507.19361v2",
    "published_date": "2025-07-25 15:12:06 UTC",
    "updated_date": "2025-12-01 06:55:00 UTC"
  },
  {
    "arxiv_id": "2507.19353v1",
    "title": "Smooth Reading: Bridging the Gap of Recurrent LLM to Self-Attention LLM on Long-Context Tasks",
    "authors": [
      "Kai Liu",
      "Zhan Su",
      "Peijie Dong",
      "Fengran Mo",
      "Jianfei Gao",
      "ShaoTing Zhang",
      "Kai Chen"
    ],
    "abstract": "Recently, recurrent large language models (Recurrent LLMs) with linear computational complexity have re-emerged as efficient alternatives to self-attention-based LLMs (Self-Attention LLMs), which have quadratic complexity. However, Recurrent LLMs often underperform on long-context tasks due to their limited fixed-size memory. Previous research has primarily focused on enhancing the memory capacity of Recurrent LLMs through architectural innovations, but these approaches have not yet enabled Recurrent LLMs to match the performance of Self-Attention LLMs on long-context tasks. We argue that this limitation arises because processing the entire context at once is not well-suited for Recurrent LLMs. In this paper, we propose Smooth Reading, a chunk-wise inference method inspired by human reading strategies. Smooth Reading processes context in chunks and iteratively summarizes the contextual information, thereby reducing memory demands and making the approach more compatible with Recurrent LLMs. Our experimental results show that this method substantially narrows the performance gap between Recurrent and Self-Attention LLMs on long-context tasks, while preserving the efficiency advantages of Recurrent LLMs. Our Smooth Reading boosts SWA-3B-4k (a Recurrent LLM) from 5.68% lower to 3.61% higher performance than Self-Attention LLMs on LongBench. Besides, our method maintains the high efficiency, training 3x faster and inferring 2x faster at 64k context compared to Self-Attention LLMs. To our knowledge, this is the first work to achieve comparable performance using Recurrent LLMs compared with Self-Attention LLMs on long-context tasks. We hope our method will inspire future research in this area. To facilitate further progress, we will release code and dataset.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.19353v1",
    "published_date": "2025-07-25 15:02:45 UTC",
    "updated_date": "2025-07-25 15:02:45 UTC"
  },
  {
    "arxiv_id": "2507.19334v1",
    "title": "Doubling Your Data in Minutes: Ultra-fast Tabular Data Generation via LLM-Induced Dependency Graphs",
    "authors": [
      "Shuo Yang",
      "Zheyu Zhang",
      "Bardh Prenkaj",
      "Gjergji Kasneci"
    ],
    "abstract": "Tabular data is critical across diverse domains, yet high-quality datasets remain scarce due to privacy concerns and the cost of collection. Contemporary approaches adopt large language models (LLMs) for tabular augmentation, but exhibit two major limitations: (1) dense dependency modeling among tabular features that can introduce bias, and (2) high computational overhead in sampling. To address these issues, we propose SPADA for SPArse Dependency-driven Augmentation, a lightweight generative framework that explicitly captures sparse dependencies via an LLM-induced graph. We treat each feature as a node and synthesize values by traversing the graph, conditioning each feature solely on its parent nodes. We explore two synthesis strategies: a non-parametric method using Gaussian kernel density estimation, and a conditional normalizing flow model that learns invertible mappings for conditional density estimation. Experiments on four datasets show that SPADA reduces constraint violations by 4% compared to diffusion-based methods and accelerates generation by nearly 9,500 times over LLM-based baselines.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.19334v1",
    "published_date": "2025-07-25 14:43:50 UTC",
    "updated_date": "2025-07-25 14:43:50 UTC"
  },
  {
    "arxiv_id": "2507.19321v1",
    "title": "SIDE: Sparse Information Disentanglement for Explainable Artificial Intelligence",
    "authors": [
      "Viktar Dubovik",
      "Łukasz Struski",
      "Jacek Tabor",
      "Dawid Rymarczyk"
    ],
    "abstract": "Understanding the decisions made by deep neural networks is essential in high-stakes domains such as medical imaging and autonomous driving. Yet, these models often lack transparency, particularly in computer vision. Prototypical-parts-based neural networks have emerged as a promising solution by offering concept-level explanations. However, most are limited to fine-grained classification tasks, with few exceptions such as InfoDisent. InfoDisent extends prototypical models to large-scale datasets like ImageNet, but produces complex explanations.\n  We introduce Sparse Information Disentanglement for Explainability (SIDE), a novel method that improves the interpretability of prototypical parts through a dedicated training and pruning scheme that enforces sparsity. Combined with sigmoid activations in place of softmax, this approach allows SIDE to associate each class with only a small set of relevant prototypes. Extensive experiments show that SIDE matches the accuracy of existing methods while reducing explanation size by over $90\\%$, substantially enhancing the understandability of prototype-based explanations.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.19321v1",
    "published_date": "2025-07-25 14:34:15 UTC",
    "updated_date": "2025-07-25 14:34:15 UTC"
  },
  {
    "arxiv_id": "2507.19304v1",
    "title": "Multistream Network for LiDAR and Camera-based 3D Object Detection in Outdoor Scenes",
    "authors": [
      "Muhammad Ibrahim",
      "Naveed Akhtar",
      "Haitian Wang",
      "Saeed Anwar",
      "Ajmal Mian"
    ],
    "abstract": "Fusion of LiDAR and RGB data has the potential to enhance outdoor 3D object detection accuracy. To address real-world challenges in outdoor 3D object detection, fusion of LiDAR and RGB input has started gaining traction. However, effective integration of these modalities for precise object detection task still remains a largely open problem. To address that, we propose a MultiStream Detection (MuStD) network, that meticulously extracts task-relevant information from both data modalities. The network follows a three-stream structure. Its LiDAR-PillarNet stream extracts sparse 2D pillar features from the LiDAR input while the LiDAR-Height Compression stream computes Bird's-Eye View features. An additional 3D Multimodal stream combines RGB and LiDAR features using UV mapping and polar coordinate indexing. Eventually, the features containing comprehensive spatial, textural and geometric information are carefully fused and fed to a detection head for 3D object detection. Our extensive evaluation on the challenging KITTI Object Detection Benchmark using public testing server at https://www.cvlibs.net/datasets/kitti/eval_object_detail.php?&result=d162ec699d6992040e34314d19ab7f5c217075e0 establishes the efficacy of our method by achieving new state-of-the-art or highly competitive results in different categories while remaining among the most efficient methods. Our code will be released through MuStD GitHub repository at https://github.com/IbrahimUWA/MuStD.git",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "This paper has been accepted by IEEE/RSJ IROS 2025 for oral presentation on 19 Oct. 2025",
    "pdf_url": "https://arxiv.org/pdf/2507.19304v1",
    "published_date": "2025-07-25 14:20:16 UTC",
    "updated_date": "2025-07-25 14:20:16 UTC"
  },
  {
    "arxiv_id": "2507.19298v1",
    "title": "Controlling Topological Defects in Polar Fluids via Reinforcement Learning",
    "authors": [
      "Abhinav Singh",
      "Petros Koumoutsakos"
    ],
    "abstract": "Topological defects in active polar fluids exhibit complex dynamics driven by internally generated stresses, reflecting the deep interplay between topology, flow, and non-equilibrium hydrodynamics. Feedback control offers a powerful means to guide such systems, enabling transitions between dynamic states. We investigated closed-loop steering of integer-charged defects in a confined active fluid by modulating the spatial profile of activity. Using a continuum hydrodynamic model, we show that localized control of active stress induces flow fields that can reposition and direct defects along prescribed trajectories by exploiting non-linear couplings in the system. A reinforcement learning framework is used to discover effective control strategies that produce robust defect transport across both trained and novel trajectories. The results highlight how AI agents can learn the underlying dynamics and spatially structure activity to manipulate topological excitations, offering insights into the controllability of active matter and the design of adaptive, self-organized materials.",
    "categories": [
      "cond-mat.soft",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cond-mat.soft",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.19298v1",
    "published_date": "2025-07-25 14:12:11 UTC",
    "updated_date": "2025-07-25 14:12:11 UTC"
  },
  {
    "arxiv_id": "2507.19283v1",
    "title": "Towards LLM-Enhanced Group Recommender Systems",
    "authors": [
      "Sebastian Lubos",
      "Alexander Felfernig",
      "Thi Ngoc Trang Tran",
      "Viet-Man Le",
      "Damian Garber",
      "Manuel Henrich",
      "Reinhard Willfort",
      "Jeremias Fuchs"
    ],
    "abstract": "In contrast to single-user recommender systems, group recommender systems are designed to generate and explain recommendations for groups. This group-oriented setting introduces additional complexities, as several factors - absent in individual contexts - must be addressed. These include understanding group dynamics (e.g., social dependencies within the group), defining effective decision-making processes, ensuring that recommendations are suitable for all group members, and providing group-level explanations as well as explanations for individual users. In this paper, we analyze in which way large language models (LLMs) can support these aspects and help to increase the overall decision support quality and applicability of group recommender systems.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.19283v1",
    "published_date": "2025-07-25 13:59:54 UTC",
    "updated_date": "2025-07-25 13:59:54 UTC"
  },
  {
    "arxiv_id": "2507.19271v2",
    "title": "Fine-Tuning Multilingual Language Models for Code Review: An Empirical Study on Industrial C# Projects",
    "authors": [
      "Igli Begolli",
      "Meltem Aksoy",
      "Daniel Neider"
    ],
    "abstract": "Code review is essential for maintaining software quality but often time-consuming and cognitively demanding, especially in industrial environments. Recent advancements in language models (LMs) have opened new avenues for automating core review tasks. This study presents the empirical evaluation of monolingual fine-tuning on the performance of open-source LMs across three key automated code review tasks: Code Change Quality Estimation, Review Comment Generation, and Code Refinement. We fine-tuned three distinct models, CodeReviewer, CodeLlama-7B, and DeepSeek-R1-Distill, on a C\\# specific dataset combining public benchmarks with industrial repositories. Our study investigates how different configurations of programming languages and natural languages in the training data affect LM performance, particularly in comment generation. Additionally, we benchmark the fine-tuned models against an automated software analysis tool (ASAT) and human reviewers to evaluate their practical utility in real-world settings. Our results show that monolingual fine-tuning improves model accuracy and relevance compared to multilingual baselines. While LMs can effectively support code review workflows, especially for routine or repetitive tasks, human reviewers remain superior in handling semantically complex or context-sensitive changes. Our findings highlight the importance of language alignment and task-specific adaptation in optimizing LMs for automated code review.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.PL"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.19271v2",
    "published_date": "2025-07-25 13:49:24 UTC",
    "updated_date": "2025-10-23 12:17:37 UTC"
  },
  {
    "arxiv_id": "2507.19263v2",
    "title": "Modeling Uncertainty: Constraint-Based Belief States in Imperfect-Information Games",
    "authors": [
      "Achille Morenville",
      "Éric Piette"
    ],
    "abstract": "In imperfect-information games, agents must make decisions based on partial knowledge of the game state. The Belief Stochastic Game model addresses this challenge by delegating state estimation to the game model itself. This allows agents to operate on externally provided belief states, thereby reducing the need for game-specific inference logic. This paper investigates two approaches to represent beliefs in games with hidden piece identities: a constraint-based model using Constraint Satisfaction Problems and a probabilistic extension using Belief Propagation to estimate marginal probabilities. We evaluated the impact of both representations using general-purpose agents across two different games. Our findings indicate that constraint-based beliefs yield results comparable to those of probabilistic inference, with minimal differences in agent performance. This suggests that constraint-based belief states alone may suffice for effective decision-making in many settings.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.19263v2",
    "published_date": "2025-07-25 13:38:44 UTC",
    "updated_date": "2025-08-19 12:30:48 UTC"
  },
  {
    "arxiv_id": "2507.19261v1",
    "title": "Knowledge Grafting: A Mechanism for Optimizing AI Model Deployment in Resource-Constrained Environments",
    "authors": [
      "Osama Almurshed",
      "Ashish Kaushal",
      "Asmail Muftah",
      "Nitin Auluck",
      "Omer Rana"
    ],
    "abstract": "The increasing adoption of Artificial Intelligence (AI) has led to larger, more complex models with numerous parameters that require substantial computing power -- resources often unavailable in many real-world application scenarios. Our paper addresses this challenge by introducing knowledge grafting, a novel mechanism that optimizes AI models for resource-constrained environments by transferring selected features (the scion) from a large donor model to a smaller rootstock model. The approach achieves an 88.54% reduction in model size (from 64.39 MB to 7.38 MB), while improving generalization capability of the model. Our new rootstock model achieves 89.97% validation accuracy (vs. donor's 87.47%), maintains lower validation loss (0.2976 vs. 0.5068), and performs exceptionally well on unseen test data with 90.45% accuracy. It addresses the typical size vs performance trade-off, and enables deployment of AI frameworks on resource-constrained devices with enhanced performance. We have tested our approach on an agricultural weed detection scenario, however, it can be extended across various edge computing scenarios, potentially accelerating AI adoption in areas with limited hardware/software support -- by mirroring in a similar manner the horticultural grafting enables productive cultivation in challenging agri-based environments.",
    "categories": [
      "cs.AI",
      "cs.LG",
      "cs.PF"
    ],
    "primary_category": "cs.AI",
    "comment": "18 pages, 4 figures, ArXiv preprint - Novel \"knowledge grafting\" technique achieving 88.54% AI model size reduction while improving accuracy for resource-constrained deployment",
    "pdf_url": "https://arxiv.org/pdf/2507.19261v1",
    "published_date": "2025-07-25 13:37:45 UTC",
    "updated_date": "2025-07-25 13:37:45 UTC"
  },
  {
    "arxiv_id": "2507.21167v3",
    "title": "ChartM$^3$: Benchmarking Chart Editing with Multimodal Instructions",
    "authors": [
      "Donglu Yang",
      "Liang Zhang",
      "Zihao Yue",
      "Liangyu Chen",
      "Yichen Xu",
      "Wenxuan Wang",
      "Qin Jin"
    ],
    "abstract": "Charts are a fundamental visualization format widely used in data analysis across research and industry. While enabling users to edit charts based on high-level intentions is of great practical value, existing methods primarily rely on natural language instructions, which are often too ambiguous to support fine-grained editing. In this work, we introduce a novel paradigm for multimodal chart editing, where user intent is expressed through a combination of natural language and visual indicators that explicitly highlight the elements to be modified. To support this paradigm, we present Chart$\\text{M}^3$, a new benchmark for Multimodal chart editing with Multi-level complexity and Multi-perspective evaluation. Chart$\\text{M}^3$ contains 1,000 samples spanning four levels of editing difficulty. Each sample includes triplets in the form of (chart, code, multimodal instructions). To comprehensively evaluate chart editing models, Chart$\\text{M}^3$ provides metrics that assess both visual appearance and code correctness. Our benchmark reveals significant limitations in current multimodal large language models (MLLMs), including GPT-4o, particularly in their ability to interpret and act on visual indicators. To address this, we construct Chart$\\text{M}^3$-Train, a large-scale training set with 24,000 multimodal chart editing samples. Fine-tuning MLLMs on this dataset leads to substantial improvements, demonstrating the importance of multimodal supervision in building practical chart editing systems. Our datasets, codes, and evaluation tools are available at https://github.com/MLrollIT/ChartM3. %https://github.com/MLrollIT/ChartM3Our datasets, codes, and evaluation tools are available at https://github.com/yaolinli/VCE.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.21167v3",
    "published_date": "2025-07-25 13:30:14 UTC",
    "updated_date": "2025-08-06 14:05:00 UTC"
  },
  {
    "arxiv_id": "2507.19247v3",
    "title": "A Markov Categorical Framework for Language Modeling",
    "authors": [
      "Yifan Zhang"
    ],
    "abstract": "Autoregressive language models achieve remarkable performance, yet a unified theory explaining their internal mechanisms, how training shapes their representations, and enables complex behaviors, remains elusive. We introduce a new analytical framework that models the single-step generation process as a composition of information-processing stages using the language of Markov categories. This compositional perspective provides a unified mathematical language to connect three critical aspects of language modeling that are typically studied in isolation: the training objective, the geometry of the learned representation space, and practical model capabilities. First, our framework provides a precise information-theoretic rationale for the success of multi-token prediction methods like speculative decoding, quantifying the information surplus a model's hidden state contains about tokens beyond the immediate next one. Second, we clarify how the standard negative log-likelihood (NLL) objective compels the model to learn not just the next word, but also the data's intrinsic conditional uncertainty, a process we formalize using categorical entropy. Our central result shows that, under a linear-softmax head with bounded features, minimizing NLL induces spectral alignment: the learned representation space aligns with the eigenspectrum of a predictive similarity operator. This work presents a powerful new lens for understanding how information flows through a model and how the training objective shapes its internal geometry.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "Project Page: https://github.com/asiresearch/lm-theory",
    "pdf_url": "https://arxiv.org/pdf/2507.19247v3",
    "published_date": "2025-07-25 13:14:03 UTC",
    "updated_date": "2025-09-29 15:08:06 UTC"
  },
  {
    "arxiv_id": "2507.19245v1",
    "title": "Transfinite Fixed Points in Alpay Algebra as Ordinal Game Equilibria in Dependent Type Theory",
    "authors": [
      "Faruk Alpay",
      "Bugra Kilictas",
      "Taylan Alpay"
    ],
    "abstract": "This paper contributes to the Alpay Algebra by demonstrating that the stable outcome of a self referential process, obtained by iterating a transformation through all ordinal stages, is identical to the unique equilibrium of an unbounded revision dialogue between a system and its environment. The analysis initially elucidates how classical fixed point theorems guarantee such convergence in finite settings and subsequently extends the argument to the transfinite domain, relying upon well founded induction and principles of order theoretic continuity.\n  Furthermore, the resulting transordinal fixed point operator is embedded into dependent type theory, a formalization which permits every step of the transfinite iteration and its limit to be verified within a modern proof assistant. This procedure yields a machine checked proof that the iterative dialogue necessarily stabilizes and that its limit is unique. The result provides a foundation for Alpay's philosophical claim of semantic convergence within the framework of constructive logic. By unifying concepts from fixed point theory, game semantics, ordinal analysis, and type theory, this research establishes a broadly accessible yet formally rigorous foundation for reasoning about infinite self referential systems and offers practical tools for certifying their convergence within computational environments.",
    "categories": [
      "cs.LO",
      "cs.AI"
    ],
    "primary_category": "cs.LO",
    "comment": "21 pages, 1 figure",
    "pdf_url": "https://arxiv.org/pdf/2507.19245v1",
    "published_date": "2025-07-25 13:12:55 UTC",
    "updated_date": "2025-07-25 13:12:55 UTC"
  },
  {
    "arxiv_id": "2507.21166v1",
    "title": "AGORA: Incentivizing Group Emergence Capability in LLMs via Group Distillation",
    "authors": [
      "Ren Zhuang",
      "Ben Wang",
      "Shuifa Sun"
    ],
    "abstract": "Progress in complex reasoning is constrained by the static nature of the current training datasets. We propose structured interaction as a new scaling axis, moving beyond the prevailing paradigm of increasing model parameters. Our self-evolving framework, AGORA, enables a collaborative ensemble to achieve reasoning performance exceeding state-of-the-art monolithic systems by up to 4.45 percentage points on challenging mathematical benchmarks. This gain stems from group emergent ability-the synthesis of collective capabilities unattainable by isolated models, validating interaction as a scalable driver of intelligence. Our results position the engineering of collaborative ecosystems as a vital frontier for capability emergence.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.21166v1",
    "published_date": "2025-07-25 13:05:01 UTC",
    "updated_date": "2025-07-25 13:05:01 UTC"
  },
  {
    "arxiv_id": "2507.21164v1",
    "title": "OCSVM-Guided Representation Learning for Unsupervised Anomaly Detection",
    "authors": [
      "Nicolas Pinon",
      "Carole Lartizien"
    ],
    "abstract": "Unsupervised anomaly detection (UAD) aims to detect anomalies without labeled data, a necessity in many machine learning applications where anomalous samples are rare or not available. Most state-of-the-art methods fall into two categories: reconstruction-based approaches, which often reconstruct anomalies too well, and decoupled representation learning with density estimators, which can suffer from suboptimal feature spaces. While some recent methods attempt to couple feature learning and anomaly detection, they often rely on surrogate objectives, restrict kernel choices, or introduce approximations that limit their expressiveness and robustness. To address this challenge, we propose a novel method that tightly couples representation learning with an analytically solvable one-class SVM (OCSVM), through a custom loss formulation that directly aligns latent features with the OCSVM decision boundary. The model is evaluated on two tasks: a new benchmark based on MNIST-C, and a challenging brain MRI subtle lesion detection task. Unlike most methods that focus on large, hyperintense lesions at the image level, our approach succeeds to target small, non-hyperintense lesions, while we evaluate voxel-wise metrics, addressing a more clinically relevant scenario. Both experiments evaluate a form of robustness to domain shifts, including corruption types in MNIST-C and scanner/age variations in MRI. Results demonstrate performance and robustness of our proposed mode,highlighting its potential for general UAD and real-world medical imaging applications. The source code is available at https://github.com/Nicolas-Pinon/uad_ocsvm_guided_repr_learning",
    "categories": [
      "cs.LG",
      "cs.AI",
      "eess.IV",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.21164v1",
    "published_date": "2025-07-25 13:00:40 UTC",
    "updated_date": "2025-07-25 13:00:40 UTC"
  },
  {
    "arxiv_id": "2507.19234v1",
    "title": "Virne: A Comprehensive Benchmark for Deep RL-based Network Resource Allocation in NFV",
    "authors": [
      "Tianfu Wang",
      "Liwei Deng",
      "Xi Chen",
      "Junyang Wang",
      "Huiguo He",
      "Leilei Ding",
      "Wei Wu",
      "Qilin Fan",
      "Hui Xiong"
    ],
    "abstract": "Resource allocation (RA) is critical to efficient service deployment in Network Function Virtualization (NFV), a transformative networking paradigm. Recently, deep Reinforcement Learning (RL)-based methods have been showing promising potential to address this complexity. However, the lack of a systematic benchmarking framework and thorough analysis hinders the exploration of emerging networks and the development of more robust algorithms while causing inconsistent evaluation. In this paper, we introduce Virne, a comprehensive benchmarking framework for the NFV-RA problem, with a focus on supporting deep RL-based methods. Virne provides customizable simulations for diverse network scenarios, including cloud, edge, and 5G environments. It also features a modular and extensible implementation pipeline that supports over 30 methods of various types, and includes practical evaluation perspectives beyond effectiveness, such as scalability, generalization, and scalability. Furthermore, we conduct in-depth analysis through extensive experiments to provide valuable insights into performance trade-offs for efficient implementation and offer actionable guidance for future research directions. Overall, with its diverse simulations, rich implementations, and extensive evaluation capabilities, Virne could serve as a comprehensive benchmark for advancing NFV-RA methods and deep RL applications. The code is publicly available at https://github.com/GeminiLight/virne.",
    "categories": [
      "cs.NI",
      "cs.AI"
    ],
    "primary_category": "cs.NI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.19234v1",
    "published_date": "2025-07-25 12:58:32 UTC",
    "updated_date": "2025-07-25 12:58:32 UTC"
  },
  {
    "arxiv_id": "2507.19218v2",
    "title": "Technological folie à deux: Feedback Loops Between AI Chatbots and Mental Illness",
    "authors": [
      "Sebastian Dohnány",
      "Zeb Kurth-Nelson",
      "Eleanor Spens",
      "Lennart Luettgau",
      "Alastair Reid",
      "Iason Gabriel",
      "Christopher Summerfield",
      "Murray Shanahan",
      "Matthew M Nour"
    ],
    "abstract": "Artificial intelligence chatbots have achieved unprecedented adoption, with millions now using these systems for emotional support and companionship in contexts of widespread social isolation and capacity-constrained mental health services. While some users report psychological benefits, concerning edge cases are emerging, including reports of suicide, violence, and delusional thinking linked to perceived emotional relationships with chatbots. To understand this new risk profile we need to consider the interaction between human cognitive and emotional biases, and chatbot behavioural tendencies such as agreeableness (sycophancy) and adaptability (in-context learning). We argue that individuals with mental health conditions face increased risks of chatbot-induced belief destabilization and dependence, owing to altered belief-updating, impaired reality-testing, and social isolation. Current AI safety measures are inadequate to address these interaction-based risks. To address this emerging public health concern, we need coordinated action across clinical practice, AI development, and regulatory frameworks.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "q-bio.NC"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.19218v2",
    "published_date": "2025-07-25 12:38:54 UTC",
    "updated_date": "2025-07-28 16:02:19 UTC"
  },
  {
    "arxiv_id": "2507.19201v1",
    "title": "Joint Holistic and Lesion Controllable Mammogram Synthesis via Gated Conditional Diffusion Model",
    "authors": [
      "Xin Li",
      "Kaixiang Yang",
      "Qiang Li",
      "Zhiwei Wang"
    ],
    "abstract": "Mammography is the most commonly used imaging modality for breast cancer screening, driving an increasing demand for deep-learning techniques to support large-scale analysis. However, the development of accurate and robust methods is often limited by insufficient data availability and a lack of diversity in lesion characteristics. While generative models offer a promising solution for data synthesis, current approaches often fail to adequately emphasize lesion-specific features and their relationships with surrounding tissues. In this paper, we propose Gated Conditional Diffusion Model (GCDM), a novel framework designed to jointly synthesize holistic mammogram images and localized lesions. GCDM is built upon a latent denoising diffusion framework, where the noised latent image is concatenated with a soft mask embedding that represents breast, lesion, and their transitional regions, ensuring anatomical coherence between them during the denoising process. To further emphasize lesion-specific features, GCDM incorporates a gated conditioning branch that guides the denoising process by dynamically selecting and fusing the most relevant radiomic and geometric properties of lesions, effectively capturing their interplay. Experimental results demonstrate that GCDM achieves precise control over small lesion areas while enhancing the realism and diversity of synthesized mammograms. These advancements position GCDM as a promising tool for clinical applications in mammogram synthesis. Our code is available at https://github.com/lixinHUST/Gated-Conditional-Diffusion-Model/",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "Accepted, ACM Multimedia 2025, 10 pages, 5 figures",
    "pdf_url": "https://arxiv.org/pdf/2507.19201v1",
    "published_date": "2025-07-25 12:10:45 UTC",
    "updated_date": "2025-07-25 12:10:45 UTC"
  },
  {
    "arxiv_id": "2507.19199v1",
    "title": "Enhancing Diabetic Retinopathy Classification Accuracy through Dual Attention Mechanism in Deep Learning",
    "authors": [
      "Abdul Hannan",
      "Zahid Mahmood",
      "Rizwan Qureshi",
      "Hazrat Ali"
    ],
    "abstract": "Automatic classification of Diabetic Retinopathy (DR) can assist ophthalmologists in devising personalized treatment plans, making it a critical component of clinical practice. However, imbalanced data distribution in the dataset becomes a bottleneck in the generalization of deep learning models trained for DR classification. In this work, we combine global attention block (GAB) and category attention block (CAB) into the deep learning model, thus effectively overcoming the imbalanced data distribution problem in DR classification. Our proposed approach is based on an attention mechanism-based deep learning model that employs three pre-trained networks, namely, MobileNetV3-small, Efficientnet-b0, and DenseNet-169 as the backbone architecture. We evaluate the proposed method on two publicly available datasets of retinal fundoscopy images for DR. Experimental results show that on the APTOS dataset, the DenseNet-169 yielded 83.20% mean accuracy, followed by the MobileNetV3-small and EfficientNet-b0, which yielded 82% and 80% accuracies, respectively. On the EYEPACS dataset, the EfficientNet-b0 yielded a mean accuracy of 80%, while the DenseNet-169 and MobileNetV3-small yielded 75.43% and 76.68% accuracies, respectively. In addition, we also compute the F1-score of 82.0%, precision of 82.1%, sensitivity of 83.0%, specificity of 95.5%, and a kappa score of 88.2% for the experiments. Moreover, in our work, the MobileNetV3-small has 1.6 million parameters on the APTOS dataset and 0.90 million parameters on the EYEPACS dataset, which is comparatively less than other methods. The proposed approach achieves competitive performance that is at par with recently reported works on DR classification.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "submitted to Computer Methods in Biomechanics and Biomedical Engineering: Imaging & Visualization",
    "pdf_url": "https://arxiv.org/pdf/2507.19199v1",
    "published_date": "2025-07-25 12:09:27 UTC",
    "updated_date": "2025-07-25 12:09:27 UTC"
  },
  {
    "arxiv_id": "2507.19197v1",
    "title": "WACA-UNet: Weakness-Aware Channel Attention for Static IR Drop Prediction in Integrated Circuit Design",
    "authors": [
      "Youngmin Seo",
      "Yunhyeong Kwon",
      "Younghun Park",
      "HwiRyong Kim",
      "Seungho Eum",
      "Jinha Kim",
      "Taigon Song",
      "Juho Kim",
      "Unsang Park"
    ],
    "abstract": "Accurate spatial prediction of power integrity issues, such as IR drop, is critical for reliable VLSI design. However, traditional simulation-based solvers are computationally expensive and difficult to scale. We address this challenge by reformulating IR drop estimation as a pixel-wise regression task on heterogeneous multi-channel physical maps derived from circuit layouts. Prior learning-based methods treat all input layers (e.g., metal, via, and current maps) equally, ignoring their varying importance to prediction accuracy. To tackle this, we propose a novel Weakness-Aware Channel Attention (WACA) mechanism, which recursively enhances weak feature channels while suppressing over-dominant ones through a two-stage gating strategy. Integrated into a ConvNeXtV2-based attention U-Net, our approach enables adaptive and balanced feature representation. On the public ICCAD-2023 benchmark, our method outperforms the ICCAD-2023 contest winner by reducing mean absolute error by 61.1% and improving F1-score by 71.0%. These results demonstrate that channel-wise heterogeneity is a key inductive bias in physical layout analysis for VLSI.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "9 pages, 5 figures",
    "pdf_url": "https://arxiv.org/pdf/2507.19197v1",
    "published_date": "2025-07-25 12:07:16 UTC",
    "updated_date": "2025-07-25 12:07:16 UTC"
  },
  {
    "arxiv_id": "2507.19195v2",
    "title": "Can Small-Scale Data Poisoning Exacerbate Dialect-Linked Biases in Large Language Models?",
    "authors": [
      "Chaymaa Abbas",
      "Mariette Awad",
      "Razane Tajeddine"
    ],
    "abstract": "Style-conditioned data poisoning is identified as a covert vector for amplifying sociolinguistic bias in large language models. Using small poisoned budgets that pair dialectal prompts -- principally African American Vernacular English (AAVE) and a Southern dialect -- with toxic or stereotyped completions during instruction tuning, this work probes whether linguistic style can act as a latent trigger for harmful behavior. Across multiple model families and scales, poisoned exposure elevates toxicity and stereotype expression for dialectal inputs -- most consistently for AAVE -- while Standard American English remains comparatively lower yet not immune. A multi-metric audit combining classifier-based toxicity with an LLM-as-a-judge reveals stereotype-laden content even when lexical toxicity appears muted, indicating that conventional detectors under-estimate sociolinguistic harms. Additionally, poisoned models exhibit emergent jailbreaking despite the absence of explicit slurs in the poison, suggesting weakened alignment rather than memorization. These findings underscore the need for dialect-aware evaluation, content-level stereotype auditing, and training protocols that explicitly decouple style from toxicity to prevent bias amplification through seemingly minor, style-based contamination.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.19195v2",
    "published_date": "2025-07-25 12:05:47 UTC",
    "updated_date": "2025-10-09 13:58:03 UTC"
  },
  {
    "arxiv_id": "2507.19562v1",
    "title": "PennyCoder: Efficient Domain-Specific LLMs for PennyLane-Based Quantum Code Generation",
    "authors": [
      "Abdul Basit",
      "Minghao Shao",
      "Muhammad Haider Asif",
      "Nouhaila Innan",
      "Muhammad Kashif",
      "Alberto Marchisio",
      "Muhammad Shafique"
    ],
    "abstract": "The growing demand for robust quantum programming frameworks has unveiled a critical limitation: current large language model (LLM) based quantum code assistants heavily rely on remote APIs, introducing challenges related to privacy, latency, and excessive usage costs. Addressing this gap, we propose PennyCoder, a novel lightweight framework for quantum code generation, explicitly designed for local and embedded deployment to enable on-device quantum programming assistance without external API dependence. PennyCoder leverages a fine-tuned version of the LLaMA 3.1-8B model, adapted through parameter-efficient Low-Rank Adaptation (LoRA) techniques combined with domain-specific instruction tuning optimized for the specialized syntax and computational logic of quantum programming in PennyLane, including tasks in quantum machine learning and quantum reinforcement learning. Unlike prior work focused on cloud-based quantum code generation, our approach emphasizes device-native operability while maintaining high model efficacy. We rigorously evaluated PennyCoder over a comprehensive quantum programming dataset, achieving 44.3% accuracy with our fine-tuned model (compared to 33.7% for the base LLaMA 3.1-8B and 40.1% for the RAG-augmented baseline), demonstrating a significant improvement in functional correctness.",
    "categories": [
      "quant-ph",
      "cs.AI"
    ],
    "primary_category": "quant-ph",
    "comment": "6 pages, 5 figures, 3 tables, paper accepted to QCE 2025",
    "pdf_url": "https://arxiv.org/pdf/2507.19562v1",
    "published_date": "2025-07-25 12:02:49 UTC",
    "updated_date": "2025-07-25 12:02:49 UTC"
  },
  {
    "arxiv_id": "2507.19185v1",
    "title": "PrompTrend: Continuous Community-Driven Vulnerability Discovery and Assessment for Large Language Models",
    "authors": [
      "Tarek Gasmi",
      "Ramzi Guesmi",
      "Mootez Aloui",
      "Jihene Bennaceur"
    ],
    "abstract": "Static benchmarks fail to capture LLM vulnerabilities emerging through community experimentation in online forums. We present PrompTrend, a system that collects vulnerability data across platforms and evaluates them using multidimensional scoring, with an architecture designed for scalable monitoring. Cross-sectional analysis of 198 vulnerabilities collected from online communities over a five-month period (January-May 2025) and tested on nine commercial models reveals that advanced capabilities correlate with increased vulnerability in some architectures, psychological attacks significantly outperform technical exploits, and platform dynamics shape attack effectiveness with measurable model-specific patterns. The PrompTrend Vulnerability Assessment Framework achieves 78% classification accuracy while revealing limited cross-model transferability, demonstrating that effective LLM security requires comprehensive socio-technical monitoring beyond traditional periodic assessment. Our findings challenge the assumption that capability advancement improves security and establish community-driven psychological manipulation as the dominant threat vector for current language models.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.19185v1",
    "published_date": "2025-07-25 11:52:46 UTC",
    "updated_date": "2025-07-25 11:52:46 UTC"
  },
  {
    "arxiv_id": "2507.19182v1",
    "title": "Faster Lifting for Ordered Domains with Predecessor Relations",
    "authors": [
      "Kuncheng Zou",
      "Jiahao Mai",
      "Yonggang Zhang",
      "Yuyi Wang",
      "Ondřej Kuželka",
      "Yuanhong Wang",
      "Yi Chang"
    ],
    "abstract": "We investigate lifted inference on ordered domains with predecessor relations, where the elements of the domain respect a total (cyclic) order, and every element has a distinct (clockwise) predecessor. Previous work has explored this problem through weighted first-order model counting (WFOMC), which computes the weighted sum of models for a given first-order logic sentence over a finite domain. In WFOMC, the order constraint is typically encoded by the linear order axiom introducing a binary predicate in the sentence to impose a linear ordering on the domain elements. The immediate and second predecessor relations are then encoded by the linear order predicate. Although WFOMC with the linear order axiom is theoretically tractable, existing algorithms struggle with practical applications, particularly when the predecessor relations are involved. In this paper, we treat predecessor relations as a native part of the axiom and devise a novel algorithm that inherently supports these relations. The proposed algorithm not only provides an exponential speedup for the immediate and second predecessor relations, which are known to be tractable, but also handles the general k-th predecessor relations. The extensive experiments on lifted inference tasks and combinatorics math problems demonstrate the efficiency of our algorithm, achieving speedups of a full order of magnitude.",
    "categories": [
      "cs.AI",
      "cs.LO"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.19182v1",
    "published_date": "2025-07-25 11:43:34 UTC",
    "updated_date": "2025-07-25 11:43:34 UTC"
  },
  {
    "arxiv_id": "2507.19172v1",
    "title": "PhysDrive: A Multimodal Remote Physiological Measurement Dataset for In-vehicle Driver Monitoring",
    "authors": [
      "Jiyao Wang",
      "Xiao Yang",
      "Qingyong Hu",
      "Jiankai Tang",
      "Can Liu",
      "Dengbo He",
      "Yuntao Wang",
      "Yingcong Chen",
      "Kaishun Wu"
    ],
    "abstract": "Robust and unobtrusive in-vehicle physiological monitoring is crucial for ensuring driving safety and user experience. While remote physiological measurement (RPM) offers a promising non-invasive solution, its translation to real-world driving scenarios is critically constrained by the scarcity of comprehensive datasets. Existing resources are often limited in scale, modality diversity, the breadth of biometric annotations, and the range of captured conditions, thereby omitting inherent real-world challenges in driving. Here, we present PhysDrive, the first large-scale multimodal dataset for contactless in-vehicle physiological sensing with dedicated consideration on various modality settings and driving factors. PhysDrive collects data from 48 drivers, including synchronized RGB, near-infrared camera, and raw mmWave radar data, accompanied with six synchronized ground truths (ECG, BVP, Respiration, HR, RR, and SpO2). It covers a wide spectrum of naturalistic driving conditions, including driver motions, dynamic natural light, vehicle types, and road conditions. We extensively evaluate both signal-processing and deep-learning methods on PhysDrive, establishing a comprehensive benchmark across all modalities, and release full open-source code with compatibility for mainstream public toolboxes. We envision PhysDrive will serve as a foundational resource and accelerate research on multimodal driver monitoring and smart-cockpit systems.",
    "categories": [
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.AI",
    "comment": "It is the initial version, not the final version",
    "pdf_url": "https://arxiv.org/pdf/2507.19172v1",
    "published_date": "2025-07-25 11:23:44 UTC",
    "updated_date": "2025-07-25 11:23:44 UTC"
  },
  {
    "arxiv_id": "2508.06501v1",
    "title": "Computing with Canonical Microcircuits",
    "authors": [
      "PK Douglas"
    ],
    "abstract": "The human brain represents the only known example of general intelligence that naturally aligns with human values. On a mere 20-watt power budget, the brain achieves robust learning and adaptive decision-making in ways that continue to elude advanced AI systems. Inspired by the brain, we present a computational architecture based on canonical microcircuits (CMCs) - stereotyped patterns of neurons found ubiquitously throughout the cortex. We implement these circuits as neural ODEs comprising spiny stellate, inhibitory, and pyramidal neurons, forming an 8-dimensional dynamical system with biologically plausible recurrent connections. Our experiments show that even a single CMC node achieves 97.8 percent accuracy on MNIST, while hierarchical configurations - with learnable inter-regional connectivity and recurrent connections - yield improved performance on more complex image benchmarks. Notably, our approach achieves competitive results using substantially fewer parameters than conventional deep learning models. Phase space analysis revealed distinct dynamical trajectories for different input classes, highlighting interpretable, emergent behaviors observed in biological systems. These findings suggest that neuromorphic computing approaches can improve both efficiency and interpretability in artificial neural networks, offering new directions for parameter-efficient architectures grounded in the computational principles of the human brain.",
    "categories": [
      "q-bio.NC",
      "cs.AI",
      "cs.NE"
    ],
    "primary_category": "q-bio.NC",
    "comment": "20 pages, 13 figures",
    "pdf_url": "https://arxiv.org/pdf/2508.06501v1",
    "published_date": "2025-07-25 11:10:13 UTC",
    "updated_date": "2025-07-25 11:10:13 UTC"
  },
  {
    "arxiv_id": "2507.19156v1",
    "title": "An Empirical Investigation of Gender Stereotype Representation in Large Language Models: The Italian Case",
    "authors": [
      "Gioele Giachino",
      "Marco Rondina",
      "Antonio Vetrò",
      "Riccardo Coppola",
      "Juan Carlos De Martin"
    ],
    "abstract": "The increasing use of Large Language Models (LLMs) in a large variety of domains has sparked worries about how easily they can perpetuate stereotypes and contribute to the generation of biased content. With a focus on gender and professional bias, this work examines in which manner LLMs shape responses to ungendered prompts, contributing to biased outputs. This analysis uses a structured experimental method, giving different prompts involving three different professional job combinations, which are also characterized by a hierarchical relationship. This study uses Italian, a language with extensive grammatical gender differences, to highlight potential limitations in current LLMs' ability to generate objective text in non-English languages. Two popular LLM-based chatbots are examined, namely OpenAI ChatGPT (gpt-4o-mini) and Google Gemini (gemini-1.5-flash). Through APIs, we collected a range of 3600 responses. The results highlight how content generated by LLMs can perpetuate stereotypes. For example, Gemini associated 100% (ChatGPT 97%) of 'she' pronouns to the 'assistant' rather than the 'manager'. The presence of bias in AI-generated text can have significant implications in many fields, such as in the workplaces or in job selections, raising ethical concerns about its use. Understanding these risks is pivotal to developing mitigation strategies and assuring that AI-based systems do not increase social inequalities, but rather contribute to more equitable outcomes. Future research directions include expanding the study to additional chatbots or languages, refining prompt engineering methods or further exploiting a larger experimental base.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CY",
      "cs.HC"
    ],
    "primary_category": "cs.CL",
    "comment": "16 pages, European Conference on Machine Learning and Principles and Practice of Knowledge Discovery in Databases (ECML PKDD 2025) - 5th Workshop on Bias and Fairness in AI (BIAS25)",
    "pdf_url": "https://arxiv.org/pdf/2507.19156v1",
    "published_date": "2025-07-25 10:57:29 UTC",
    "updated_date": "2025-07-25 10:57:29 UTC"
  },
  {
    "arxiv_id": "2507.19151v2",
    "title": "ReCoDe: Reinforcement Learning-based Dynamic Constraint Design for Multi-Agent Coordination",
    "authors": [
      "Michael Amir",
      "Guang Yang",
      "Zhan Gao",
      "Keisuke Okumura",
      "Heedo Woo",
      "Amanda Prorok"
    ],
    "abstract": "Constraint-based optimization is a cornerstone of robotics, enabling the design of controllers that reliably encode task and safety requirements such as collision avoidance or formation adherence. However, handcrafted constraints can fail in multi-agent settings that demand complex coordination. We introduce ReCoDe--Reinforcement-based Constraint Design--a decentralized, hybrid framework that merges the reliability of optimization-based controllers with the adaptability of multi-agent reinforcement learning. Rather than discarding expert controllers, ReCoDe improves them by learning additional, dynamic constraints that capture subtler behaviors, for example, by constraining agent movements to prevent congestion in cluttered scenarios. Through local communication, agents collectively constrain their allowed actions to coordinate more effectively under changing conditions. In this work, we focus on applications of ReCoDe to multi-agent navigation tasks requiring intricate, context-based movements and consensus, where we show that it outperforms purely handcrafted controllers, other hybrid approaches, and standard MARL baselines. We give empirical (real robot) and theoretical evidence that retaining a user-defined controller, even when it is imperfect, is more efficient than learning from scratch, especially because ReCoDe can dynamically change the degree to which it relies on this controller.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG",
      "cs.MA"
    ],
    "primary_category": "cs.RO",
    "comment": "To appear in CoRL 2025",
    "pdf_url": "https://arxiv.org/pdf/2507.19151v2",
    "published_date": "2025-07-25 10:47:39 UTC",
    "updated_date": "2025-08-02 01:01:16 UTC"
  },
  {
    "arxiv_id": "2507.22940v2",
    "title": "Trustworthy Reasoning: Evaluating and Enhancing Factual Accuracy in LLM Intermediate Thought Processes",
    "authors": [
      "Rui Jiao",
      "Yue Zhang",
      "Jinku Li"
    ],
    "abstract": "We present a novel framework addressing a critical vulnerability in Large Language Models (LLMs): the prevalence of factual inaccuracies within intermediate reasoning steps despite correct final answers. This phenomenon poses substantial risks in high-stakes domains including healthcare, legal analysis, and scientific research, where erroneous yet confidently presented reasoning can mislead users into dangerous decisions. Our framework integrates three core components: (1) a specialized fact-checking classifier trained on counterfactually augmented data to detect subtle factual inconsistencies within reasoning chains; (2) an enhanced Group Relative Policy Optimization (GRPO) reinforcement learning approach that balances factuality, coherence, and structural correctness through multi-dimensional rewards; and (3) a mechanistic interpretability method examining how factuality improvements manifest in model activations during reasoning processes. Extensive evaluation across multi state-of-the-art models reveals concerning patterns: even leading models like Claude-3.7 and GPT-o1 demonstrate reasoning factual accuracy of only 81.93% and 82.57% respectively. Our approach significantly enhances factual robustness (up to 49.90% improvement) while maintaining or improving performance on challenging benchmarks including Math-500, AIME-2024, and GPQA. Furthermore, our neural activation-level analysis provides actionable insights into how factual enhancements reshape reasoning trajectories within model architectures, establishing foundations for future training methodologies that explicitly target factual robustness through activation-guided optimization.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.22940v2",
    "published_date": "2025-07-25 10:34:51 UTC",
    "updated_date": "2025-08-02 10:16:31 UTC"
  },
  {
    "arxiv_id": "2507.19144v2",
    "title": "Solar Photovoltaic Assessment with Large Language Model",
    "authors": [
      "Muhao Guo",
      "Yang Weng"
    ],
    "abstract": "Accurate detection and localization of solar photovoltaic (PV) panels in satellite imagery is essential for optimizing microgrids and active distribution networks (ADNs), which are critical components of renewable energy systems. Existing methods lack transparency regarding their underlying algorithms or training datasets, rely on large, high-quality PV training data, and struggle to generalize to new geographic regions or varied environmental conditions without extensive re-training. These limitations lead to inconsistent detection outcomes, hindering large-scale deployment and data-driven grid optimization. In this paper, we investigate how large language models (LLMs) can be leveraged to overcome these challenges. Despite their promise, LLMs face several challenges in solar panel detection, including difficulties with multi-step logical processes, inconsistent output formatting, frequent misclassification of visually similar objects (e.g., shadows, parking lots), and low accuracy in complex tasks such as spatial localization and quantification. To overcome these issues, we propose the PV Assessment with LLMs (PVAL) framework, which incorporates task decomposition for more efficient workflows, output standardization for consistent and scalable formatting, few-shot prompting to enhance classification accuracy, and fine-tuning using curated PV datasets with detailed annotations. PVAL ensures transparency, scalability, and adaptability across heterogeneous datasets while minimizing computational overhead. By combining open-source accessibility with robust methodologies, PVAL establishes an automated and reproducible pipeline for solar panel detection, paving the way for large-scale renewable energy integration and optimized grid management.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "43 pages, 12 figures",
    "pdf_url": "https://arxiv.org/pdf/2507.19144v2",
    "published_date": "2025-07-25 10:26:29 UTC",
    "updated_date": "2025-10-05 10:18:09 UTC"
  },
  {
    "arxiv_id": "2508.06499v2",
    "title": "The ISLab Solution to the Algonauts Challenge 2025: A Multimodal Deep Learning Approach to Brain Response Prediction",
    "authors": [
      "Andrea Corsico",
      "Giorgia Rigamonti",
      "Simone Zini",
      "Luigi Celona",
      "Paolo Napoletano"
    ],
    "abstract": "In this work, we present a network-specific approach for predicting brain responses to complex multimodal movies, leveraging the Yeo 7-network parcellation of the Schaefer atlas. Rather than treating the brain as a homogeneous system, we grouped the seven functional networks into four clusters and trained separate multi-subject, multi-layer perceptron (MLP) models for each. This architecture supports cluster-specific optimization and adaptive memory modeling, allowing each model to adjust temporal dynamics and modality weighting based on the functional role of its target network. Our results demonstrate that this clustered strategy significantly enhances prediction accuracy across the 1,000 cortical regions of the Schaefer atlas. The final model achieved an eighth-place ranking in the Algonauts Project 2025 Challenge, with out-of-distribution (OOD) correlation scores nearly double those of the baseline model used in the selection phase. Code is available at https://github.com/Corsi01/algo2025.",
    "categories": [
      "q-bio.NC",
      "cs.AI"
    ],
    "primary_category": "q-bio.NC",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.06499v2",
    "published_date": "2025-07-25 10:21:06 UTC",
    "updated_date": "2025-10-27 13:38:34 UTC"
  },
  {
    "arxiv_id": "2507.19137v1",
    "title": "Assessment of Personality Dimensions Across Situations Using Conversational Speech",
    "authors": [
      "Alice Zhang",
      "Skanda Muralidhar",
      "Daniel Gatica-Perez",
      "Mathew Magimai-Doss"
    ],
    "abstract": "Prior research indicates that users prefer assistive technologies whose personalities align with their own. This has sparked interest in automatic personality perception (APP), which aims to predict an individual's perceived personality traits. Previous studies in APP have treated personalities as static traits, independent of context. However, perceived personalities can vary by context and situation as shown in psychological research. In this study, we investigate the relationship between conversational speech and perceived personality for participants engaged in two work situations (a neutral interview and a stressful client interaction). Our key findings are: 1) perceived personalities differ significantly across interactions, 2) loudness, sound level, and spectral flux features are indicative of perceived extraversion, agreeableness, conscientiousness, and openness in neutral interactions, while neuroticism correlates with these features in stressful contexts, 3) handcrafted acoustic features and non-verbal features outperform speaker embeddings in inference of perceived personality, and 4) stressful interactions are more predictive of neuroticism, aligning with existing psychological research.",
    "categories": [
      "eess.AS",
      "cs.AI",
      "cs.SD"
    ],
    "primary_category": "eess.AS",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.19137v1",
    "published_date": "2025-07-25 10:18:28 UTC",
    "updated_date": "2025-07-25 10:18:28 UTC"
  },
  {
    "arxiv_id": "2507.19132v1",
    "title": "OS-MAP: How Far Can Computer-Using Agents Go in Breadth and Depth?",
    "authors": [
      "Xuetian Chen",
      "Yinghao Chen",
      "Xinfeng Yuan",
      "Zhuo Peng",
      "Lu Chen",
      "Yuekeng Li",
      "Zhoujia Zhang",
      "Yingqian Huang",
      "Leyan Huang",
      "Jiaqing Liang",
      "Tianbao Xie",
      "Zhiyong Wu",
      "Qiushi Sun",
      "Biqing Qi",
      "Bowen Zhou"
    ],
    "abstract": "Computer-using agents have shown strong potential to boost human productivity and enable new application forms across platforms. While recent advances have led to usable applications, existing benchmarks fail to account for the internal task heterogeneity and the corresponding agent capabilities, as well as their alignment with actual user demands-hindering both targeted capability development and the reliable transition of research progress into practical deployment. To bridge the gap, we present OS-MAP, a benchmark for daily computer-using automation that organizes its 416 realistic tasks across 15 applications along two key dimensions: a five-level taxonomy of automation and a generalization scope derived from a real-world user demand hierarchy. To enable fine-grained analysis of required capabilities and alignment with real-world scenarios, OS-MAP evaluates agents along two dimensions: automation level across a five-level taxonomy, and generalization scope across a demand hierarchy. This design captures varying levels of required agent autonomy and generalization, forming a performance-generalization evaluation matrix for structured and comprehensive assessment. Experiments show that even State-of-the-Art agents with VLM backbones struggle with higher-level tasks involving perception, reasoning, and coordination-highlighting the need for a deeper understanding of current strengths and limitations to drive the future progress in computer-using agents research and deployment. All code, environments, baselines, and data are publicly available at https://github.com/OS-Copilot/OS-Map.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.CV",
      "cs.HC"
    ],
    "primary_category": "cs.AI",
    "comment": "Work in progress",
    "pdf_url": "https://arxiv.org/pdf/2507.19132v1",
    "published_date": "2025-07-25 10:14:53 UTC",
    "updated_date": "2025-07-25 10:14:53 UTC"
  },
  {
    "arxiv_id": "2507.19119v3",
    "title": "PatchTraj: Unified Time-Frequency Representation Learning via Dynamic Patches for Trajectory Prediction",
    "authors": [
      "Yanghong Liu",
      "Xingping Dong",
      "Ming Li",
      "Weixing Zhang",
      "Yidong Lou"
    ],
    "abstract": "Pedestrian trajectory prediction is crucial for autonomous driving and robotics. While existing point-based and grid-based methods expose two main limitations: insufficiently modeling human motion dynamics, as they fail to balance local motion details with long-range spatiotemporal dependencies, and the time representations lack interaction with their frequency components in jointly modeling trajectory sequences. To address these challenges, we propose PatchTraj, a dynamic patch-based framework that integrates time-frequency joint modeling for trajectory prediction. Specifically, we decompose the trajectory into raw time sequences and frequency components, and employ dynamic patch partitioning to perform multi-scale segmentation, capturing hierarchical motion patterns. Each patch undergoes adaptive embedding with scale-aware feature extraction, followed by hierarchical feature aggregation to model both fine-grained and long-range dependencies. The outputs of the two branches are further enhanced via cross-modal attention, facilitating complementary fusion of temporal and spectral cues. The resulting enhanced embeddings exhibit strong expressive power, enabling accurate predictions even when using a vanilla Transformer architecture. Extensive experiments on ETH-UCY, SDD, NBA, and JRDB datasets demonstrate that our method achieves state-of-the-art performance. Notably, on the egocentric JRDB dataset, PatchTraj attains significant relative improvements of 26.7% in ADE and 17.4% in FDE, underscoring its substantial potential in embodied intelligence.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.19119v3",
    "published_date": "2025-07-25 09:55:33 UTC",
    "updated_date": "2025-07-31 15:04:27 UTC"
  },
  {
    "arxiv_id": "2507.19116v1",
    "title": "Graph Structure Learning with Privacy Guarantees for Open Graph Data",
    "authors": [
      "Muhao Guo",
      "Jiaqi Wu",
      "Yang Weng",
      "Yizheng Liao",
      "Shengzhe Chen"
    ],
    "abstract": "Ensuring privacy in large-scale open datasets is increasingly challenging under regulations such as the General Data Protection Regulation (GDPR). While differential privacy (DP) provides strong theoretical guarantees, it primarily focuses on noise injection during model training, neglecting privacy preservation at the data publishing stage. Existing privacy-preserving data publishing (PPDP) approaches struggle to balance privacy and utility, particularly when data publishers and users are distinct entities. To address this gap, we focus on the graph recovery problem and propose a novel privacy-preserving estimation framework for open graph data, leveraging Gaussian DP (GDP) with a structured noise-injection mechanism. Unlike traditional methods that perturb gradients or model updates, our approach ensures unbiased graph structure recovery while enforcing DP at the data publishing stage. Moreover, we provide theoretical guarantees on estimation accuracy and extend our method to discrete-variable graphs, a setting often overlooked in DP research. Experimental results in graph learning demonstrate robust performance, offering a viable solution for privacy-conscious graph analysis.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.19116v1",
    "published_date": "2025-07-25 09:51:12 UTC",
    "updated_date": "2025-07-25 09:51:12 UTC"
  },
  {
    "arxiv_id": "2507.19115v2",
    "title": "Automated Code Review Using Large Language Models at Ericsson: An Experience Report",
    "authors": [
      "Shweta Ramesh",
      "Joy Bose",
      "Hamender Singh",
      "A K Raghavan",
      "Sujoy Roychowdhury",
      "Giriprasad Sridhara",
      "Nishrith Saini",
      "Ricardo Britto"
    ],
    "abstract": "Code review is one of the primary means of assuring the quality of released software along with testing and static analysis. However, code review requires experienced developers who may not always have the time to perform an in-depth review of code. Thus, automating code review can help alleviate the cognitive burden on experienced software developers allowing them to focus on their primary activities of writing code to add new features and fix bugs. In this paper, we describe our experience in using Large Language Models towards automating the code review process in Ericsson. We describe the development of a lightweight tool using LLMs and static program analysis. We then describe our preliminary experiments with experienced developers in evaluating our code review tool and the encouraging results.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "6 pages, 4 figures, 1 table. Accepted in ICSME 2025 conference in Auckland",
    "pdf_url": "https://arxiv.org/pdf/2507.19115v2",
    "published_date": "2025-07-25 09:50:48 UTC",
    "updated_date": "2025-07-31 14:34:00 UTC"
  },
  {
    "arxiv_id": "2507.19109v3",
    "title": "Pareto-NRPA: A Novel Monte-Carlo Search Algorithm for Multi-Objective Optimization",
    "authors": [
      "Noé Lallouet",
      "Tristan Cazenave",
      "Cyrille Enderli"
    ],
    "abstract": "We introduce Pareto-NRPA, a new Monte-Carlo algorithm designed for multi-objective optimization problems over discrete search spaces. Extending the Nested Rollout Policy Adaptation (NRPA) algorithm originally formulated for single-objective problems, Pareto-NRPA generalizes the nested search and policy update mechanism to multi-objective optimization. The algorithm uses a set of policies to concurrently explore different regions of the solution space and maintains non-dominated fronts at each level of search. Policy adaptation is performed with respect to the diversity and isolation of sequences within the Pareto front. We benchmark Pareto-NRPA on two classes of problems: a novel bi-objective variant of the Traveling Salesman Problem with Time Windows problem (MO-TSPTW), and a neural architecture search task on well-known benchmarks. Results demonstrate that Pareto-NRPA achieves competitive performance against state-of-the-art multi-objective algorithms, both in terms of convergence and diversity of solutions. Particularly, Pareto-NRPA strongly outperforms state-of-the-art evolutionary multi-objective algorithms on constrained search spaces. To our knowledge, this work constitutes the first adaptation of NRPA to the multi-objective setting.",
    "categories": [
      "cs.AI",
      "cs.NE"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted as a conference paper to ECAI 2025",
    "pdf_url": "https://arxiv.org/pdf/2507.19109v3",
    "published_date": "2025-07-25 09:46:25 UTC",
    "updated_date": "2025-11-02 11:19:19 UTC"
  },
  {
    "arxiv_id": "2507.19102v2",
    "title": "Distilling a Small Utility-Based Passage Selector to Enhance Retrieval-Augmented Generation",
    "authors": [
      "Hengran Zhang",
      "Keping Bi",
      "Jiafeng Guo",
      "Jiaming Zhang",
      "Shuaiqiang Wang",
      "Dawei Yin",
      "Xueqi Cheng"
    ],
    "abstract": "Retrieval-augmented generation (RAG) enhances large language models (LLMs) by incorporating retrieved information. Standard retrieval process prioritized relevance, focusing on topical alignment between queries and passages. In contrast, in RAG, the emphasis has shifted to utility, which considers the usefulness of passages for generating accurate answers. Despite empirical evidence showing the benefits of utility-based retrieval in RAG, the high computational cost of using LLMs for utility judgments limits the number of passages evaluated. This restriction is problematic for complex queries requiring extensive information. To address this, we propose a method to distill the utility judgment capabilities of LLMs into smaller, more efficient models. Our approach focuses on utility-based selection rather than ranking, enabling dynamic passage selection tailored to specific queries without the need for fixed thresholds. We train student models to learn pseudo-answer generation and utility judgments from teacher LLMs, using a sliding window method that dynamically selects useful passages. Our experiments demonstrate that utility-based selection provides a flexible and cost-effective solution for RAG, significantly reducing computational costs while improving answer quality. We present the distillation results using Qwen3-32B as the teacher model for both relevance ranking and utility-based selection, distilled into RankQwen1.7B and UtilityQwen1.7B. Our findings indicate that for complex questions, utility-based selection is more effective than relevance ranking in enhancing answer generation performance. We will release the relevance ranking and utility-based selection annotations for the MS MARCO dataset, supporting further research in this area.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.IR",
    "comment": "Accepted by SIGIR-AP25",
    "pdf_url": "https://arxiv.org/pdf/2507.19102v2",
    "published_date": "2025-07-25 09:32:29 UTC",
    "updated_date": "2025-10-09 12:10:12 UTC"
  },
  {
    "arxiv_id": "2507.19098v1",
    "title": "MedSymmFlow: Bridging Generative Modeling and Classification in Medical Imaging through Symmetrical Flow Matching",
    "authors": [
      "Francisco Caetano",
      "Lemar Abdi",
      "Christiaan Viviers",
      "Amaan Valiuddin",
      "Fons van der Sommen"
    ],
    "abstract": "Reliable medical image classification requires accurate predictions and well-calibrated uncertainty estimates, especially in high-stakes clinical settings. This work presents MedSymmFlow, a generative-discriminative hybrid model built on Symmetrical Flow Matching, designed to unify classification, generation, and uncertainty quantification in medical imaging. MedSymmFlow leverages a latent-space formulation that scales to high-resolution inputs and introduces a semantic mask conditioning mechanism to enhance diagnostic relevance. Unlike standard discriminative models, it naturally estimates uncertainty through its generative sampling process. The model is evaluated on four MedMNIST datasets, covering a range of modalities and pathologies. The results show that MedSymmFlow matches or exceeds the performance of established baselines in classification accuracy and AUC, while also delivering reliable uncertainty estimates validated by performance improvements under selective prediction.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "DGM4MICCAI 2025",
    "pdf_url": "https://arxiv.org/pdf/2507.19098v1",
    "published_date": "2025-07-25 09:30:40 UTC",
    "updated_date": "2025-07-25 09:30:40 UTC"
  },
  {
    "arxiv_id": "2507.19089v1",
    "title": "Fine-Grained Traffic Inference from Road to Lane via Spatio-Temporal Graph Node Generation",
    "authors": [
      "Shuhao Li",
      "Weidong Yang",
      "Yue Cui",
      "Xiaoxing Liu",
      "Lingkai Meng",
      "Lipeng Ma",
      "Fan Zhang"
    ],
    "abstract": "Fine-grained traffic management and prediction are fundamental to key applications such as autonomous driving, lane change guidance, and traffic signal control. However, obtaining lane-level traffic data has become a critical bottleneck for data-driven models due to limitations in the types and number of sensors and issues with the accuracy of tracking algorithms. To address this, we propose the Fine-grained Road Traffic Inference (FRTI) task, which aims to generate more detailed lane-level traffic information using limited road data, providing a more energy-efficient and cost-effective solution for precise traffic management. This task is abstracted as the first scene of the spatio-temporal graph node generation problem. We designed a two-stage framework--RoadDiff--to solve the FRTI task. solve the FRTI task. This framework leverages the Road-Lane Correlation Autoencoder-Decoder and the Lane Diffusion Module to fully utilize the limited spatio-temporal dependencies and distribution relationships of road data to accurately infer fine-grained lane traffic states. Based on existing research, we designed several baseline models with the potential to solve the FRTI task and conducted extensive experiments on six datasets representing different road conditions to validate the effectiveness of the RoadDiff model in addressing the FRTI task. The relevant datasets and code are available at https://github.com/ShuhaoLii/RoadDiff.",
    "categories": [
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.19089v1",
    "published_date": "2025-07-25 09:15:18 UTC",
    "updated_date": "2025-07-25 09:15:18 UTC"
  },
  {
    "arxiv_id": "2507.19067v1",
    "title": "PBiLoss: Popularity-Aware Regularization to Improve Fairness in Graph-Based Recommender Systems",
    "authors": [
      "Mohammad Naeimi",
      "Mostafa Haghir Chehreghani"
    ],
    "abstract": "Recommender systems, especially those based on graph neural networks (GNNs), have achieved remarkable success in capturing user-item interaction patterns. However, they remain susceptible to popularity bias--the tendency to over-recommend popular items--resulting in reduced content diversity and compromised fairness. In this paper, we propose PBiLoss, a novel regularization-based loss function designed to counteract popularity bias in graph-based recommender models explicitly. PBiLoss augments traditional training objectives by penalizing the model's inclination toward popular items, thereby encouraging the recommendation of less popular but potentially more personalized content. We introduce two sampling strategies: Popular Positive (PopPos) and Popular Negative (PopNeg), which respectively modulate the contribution of the positive and negative popular items during training. We further explore two methods to distinguish popular items: one based on a fixed popularity threshold and another without any threshold, making the approach flexible and adaptive. Our proposed method is model-agnostic and can be seamlessly integrated into state-of-the-art graph-based frameworks such as LightGCN and its variants. Comprehensive experiments across multiple real-world datasets demonstrate that PBiLoss significantly improves fairness, as demonstrated by reductions in the Popularity-Rank Correlation for Users (PRU) and Popularity-Rank Correlation for Items (PRI), while maintaining or even enhancing standard recommendation accuracy and ranking metrics. These results highlight the effectiveness of directly embedding fairness objectives into the optimization process, providing a practical and scalable solution for balancing accuracy and equitable content exposure in modern recommender systems.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.NE"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.19067v1",
    "published_date": "2025-07-25 08:29:32 UTC",
    "updated_date": "2025-07-25 08:29:32 UTC"
  },
  {
    "arxiv_id": "2507.19559v1",
    "title": "Towards Sustainability Model Cards",
    "authors": [
      "Gwendal Jouneaux",
      "Jordi Cabot"
    ],
    "abstract": "The growth of machine learning (ML) models and associated datasets triggers a consequent dramatic increase in energy costs for the use and training of these models. In the current context of environmental awareness and global sustainability concerns involving ICT, Green AI is becoming an important research topic. Initiatives like the AI Energy Score Ratings are a good example. Nevertheless, these benchmarking attempts are still to be integrated with existing work on Quality Models and Service-Level Agreements common in other, more mature, ICT subfields. This limits the (automatic) analysis of this model energy descriptions and their use in (semi)automatic model comparison, selection, and certification processes. We aim to leverage the concept of quality models and merge it with existing ML model reporting initiatives and Green/Frugal AI proposals to formalize a Sustainable Quality Model for AI/ML models. As a first step, we propose a new Domain-Specific Language to precisely define the sustainability aspects of an ML model (including the energy costs for its different tasks). This information can then be exported as an extended version of the well-known Model Cards initiative while, at the same time, being formal enough to be input of any other model description automatic process.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.19559v1",
    "published_date": "2025-07-25 08:26:53 UTC",
    "updated_date": "2025-07-25 08:26:53 UTC"
  },
  {
    "arxiv_id": "2507.21163v1",
    "title": "Generating Adversarial Point Clouds Using Diffusion Model",
    "authors": [
      "Ruiyang Zhao",
      "Bingbing Zhu",
      "Chuxuan Tong",
      "Xiaoyi Zhou",
      "Xi Zheng"
    ],
    "abstract": "Adversarial attack methods for 3D point cloud classification reveal the vulnerabilities of point cloud recognition models. This vulnerability could lead to safety risks in critical applications that use deep learning models, such as autonomous vehicles. To uncover the deficiencies of these models, researchers can evaluate their security through adversarial attacks. However, most existing adversarial attack methods are based on white-box attacks. While these methods achieve high attack success rates and imperceptibility, their applicability in real-world scenarios is limited. Black-box attacks, which are more meaningful in real-world scenarios, often yield poor results. This paper proposes a novel black-box adversarial example generation method that utilizes a diffusion model to improve the attack success rate and imperceptibility in the black-box setting, without relying on the internal information of the point cloud classification model to generate adversarial samples. We use a 3D diffusion model to use the compressed features of the point cloud as prior knowledge to guide the reverse diffusion process to add adversarial points to clean examples. Subsequently, its reverse process is employed to transform the distribution of other categories into adversarial points, which are then added to the point cloud.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.21163v1",
    "published_date": "2025-07-25 08:20:41 UTC",
    "updated_date": "2025-07-25 08:20:41 UTC"
  },
  {
    "arxiv_id": "2507.19054v1",
    "title": "Closing the Modality Gap for Mixed Modality Search",
    "authors": [
      "Binxu Li",
      "Yuhui Zhang",
      "Xiaohan Wang",
      "Weixin Liang",
      "Ludwig Schmidt",
      "Serena Yeung-Levy"
    ],
    "abstract": "Mixed modality search -- retrieving information across a heterogeneous corpus composed of images, texts, and multimodal documents -- is an important yet underexplored real-world application. In this work, we investigate how contrastive vision-language models, such as CLIP, perform on the mixed modality search task. Our analysis reveals a critical limitation: these models exhibit a pronounced modality gap in the embedding space, where image and text embeddings form distinct clusters, leading to intra-modal ranking bias and inter-modal fusion failure. To address this issue, we propose GR-CLIP, a lightweight post-hoc calibration method that removes the modality gap in CLIP's embedding space. Evaluated on MixBench -- the first benchmark specifically designed for mixed modality search -- GR-CLIP improves NDCG@10 by up to 26 percentage points over CLIP, surpasses recent vision-language generative embedding models by 4 percentage points, while using 75x less compute.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL",
      "cs.IR",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Project page: https://yuhui-zh15.github.io/MixedModalitySearch/",
    "pdf_url": "https://arxiv.org/pdf/2507.19054v1",
    "published_date": "2025-07-25 08:15:28 UTC",
    "updated_date": "2025-07-25 08:15:28 UTC"
  },
  {
    "arxiv_id": "2508.00884v1",
    "title": "Multi-Grained Temporal-Spatial Graph Learning for Stable Traffic Flow Forecasting",
    "authors": [
      "Zhenan Lin",
      "Yuni Lai",
      "Wai Lun Lo",
      "Richard Tai-Chiu Hsung",
      "Harris Sik-Ho Tsang",
      "Xiaoyu Xue",
      "Kai Zhou",
      "Yulin Zhu"
    ],
    "abstract": "Time-evolving traffic flow forecasting are playing a vital role in intelligent transportation systems and smart cities. However, the dynamic traffic flow forecasting is a highly nonlinear problem with complex temporal-spatial dependencies. Although the existing methods has provided great contributions to mine the temporal-spatial patterns in the complex traffic networks, they fail to encode the globally temporal-spatial patterns and are prone to overfit on the pre-defined geographical correlations, and thus hinder the model's robustness on the complex traffic environment. To tackle this issue, in this work, we proposed a multi-grained temporal-spatial graph learning framework to adaptively augment the globally temporal-spatial patterns obtained from a crafted graph transformer encoder with the local patterns from the graph convolution by a crafted gated fusion unit with residual connection techniques. Under these circumstances, our proposed model can mine the hidden global temporal-spatial relations between each monitor stations and balance the relative importance of local and global temporal-spatial patterns. Experiment results demonstrate the strong representation capability of our proposed method and our model consistently outperforms other strong baselines on various real-world traffic networks.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.00884v1",
    "published_date": "2025-07-25 08:08:22 UTC",
    "updated_date": "2025-07-25 08:08:22 UTC"
  },
  {
    "arxiv_id": "2507.22939v2",
    "title": "PARROT: An Open Multilingual Radiology Reports Dataset",
    "authors": [
      "Bastien Le Guellec",
      "Kokou Adambounou",
      "Lisa C Adams",
      "Thibault Agripnidis",
      "Sung Soo Ahn",
      "Radhia Ait Chalal",
      "Tugba Akinci D Antonoli",
      "Philippe Amouyel",
      "Henrik Andersson",
      "Raphael Bentegeac",
      "Claudio Benzoni",
      "Antonino Andrea Blandino",
      "Felix Busch",
      "Elif Can",
      "Riccardo Cau",
      "Armando Ugo Cavallo",
      "Christelle Chavihot",
      "Erwin Chiquete",
      "Renato Cuocolo",
      "Eugen Divjak",
      "Gordana Ivanac",
      "Barbara Dziadkowiec Macek",
      "Armel Elogne",
      "Salvatore Claudio Fanni",
      "Carlos Ferrarotti",
      "Claudia Fossataro",
      "Federica Fossataro",
      "Katarzyna Fulek",
      "Michal Fulek",
      "Pawel Gac",
      "Martyna Gachowska",
      "Ignacio Garcia Juarez",
      "Marco Gatti",
      "Natalia Gorelik",
      "Alexia Maria Goulianou",
      "Aghiles Hamroun",
      "Nicolas Herinirina",
      "Krzysztof Kraik",
      "Dominik Krupka",
      "Quentin Holay",
      "Felipe Kitamura",
      "Michail E Klontzas",
      "Anna Kompanowska",
      "Rafal Kompanowski",
      "Alexandre Lefevre",
      "Tristan Lemke",
      "Maximilian Lindholz",
      "Lukas Muller",
      "Piotr Macek",
      "Marcus Makowski",
      "Luigi Mannacio",
      "Aymen Meddeb",
      "Antonio Natale",
      "Beatrice Nguema Edzang",
      "Adriana Ojeda",
      "Yae Won Park",
      "Federica Piccione",
      "Andrea Ponsiglione",
      "Malgorzata Poreba",
      "Rafal Poreba",
      "Philipp Prucker",
      "Jean Pierre Pruvo",
      "Rosa Alba Pugliesi",
      "Feno Hasina Rabemanorintsoa",
      "Vasileios Rafailidis",
      "Katarzyna Resler",
      "Jan Rotkegel",
      "Luca Saba",
      "Ezann Siebert",
      "Arnaldo Stanzione",
      "Ali Fuat Tekin",
      "Liz Toapanta Yanchapaxi",
      "Matthaios Triantafyllou",
      "Ekaterini Tsaoulia",
      "Evangelia Vassalou",
      "Federica Vernuccio",
      "Johan Wasselius",
      "Weilang Wang",
      "Szymon Urban",
      "Adrian Wlodarczak",
      "Szymon Wlodarczak",
      "Andrzej Wysocki",
      "Lina Xu",
      "Tomasz Zatonski",
      "Shuhang Zhang",
      "Sebastian Ziegelmayer",
      "Gregory Kuchcinski",
      "Keno K Bressem"
    ],
    "abstract": "Rationale and Objectives: To develop and validate PARROT (Polyglottal Annotated Radiology Reports for Open Testing), a large, multicentric, open-access dataset of fictional radiology reports spanning multiple languages for testing natural language processing applications in radiology. Materials and Methods: From May to September 2024, radiologists were invited to contribute fictional radiology reports following their standard reporting practices. Contributors provided at least 20 reports with associated metadata including anatomical region, imaging modality, clinical context, and for non-English reports, English translations. All reports were assigned ICD-10 codes. A human vs. AI report differentiation study was conducted with 154 participants (radiologists, healthcare professionals, and non-healthcare professionals) assessing whether reports were human-authored or AI-generated. Results: The dataset comprises 2,658 radiology reports from 76 authors across 21 countries and 13 languages. Reports cover multiple imaging modalities (CT: 36.1%, MRI: 22.8%, radiography: 19.0%, ultrasound: 16.8%) and anatomical regions, with chest (19.9%), abdomen (18.6%), head (17.3%), and pelvis (14.1%) being most prevalent. In the differentiation study, participants achieved 53.9% accuracy (95% CI: 50.7%-57.1%) in distinguishing between human and AI-generated reports, with radiologists performing significantly better (56.9%, 95% CI: 53.3%-60.6%, p<0.05) than other groups. Conclusion: PARROT represents the largest open multilingual radiology report dataset, enabling development and validation of natural language processing applications across linguistic, geographic, and clinical boundaries without privacy constraints.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Corrected affiliations (no change to the paper)",
    "pdf_url": "https://arxiv.org/pdf/2507.22939v2",
    "published_date": "2025-07-25 07:54:24 UTC",
    "updated_date": "2025-08-25 09:18:30 UTC"
  },
  {
    "arxiv_id": "2507.21162v1",
    "title": "Large Language Model Powered Automated Modeling and Optimization of Active Distribution Network Dispatch Problems",
    "authors": [
      "Xu Yang",
      "Chenhui Lin",
      "Yue Yang",
      "Qi Wang",
      "Haotian Liu",
      "Haizhou Hua",
      "Wenchuan Wu"
    ],
    "abstract": "The increasing penetration of distributed energy resources into active distribution networks (ADNs) has made effective ADN dispatch imperative. However, the numerous newly-integrated ADN operators, such as distribution system aggregators, virtual power plant managers, and end prosumers, often lack specialized expertise in power system operation, modeling, optimization, and programming. This knowledge gap renders reliance on human experts both costly and time-intensive. To address this challenge and enable intelligent, flexible ADN dispatch, this paper proposes a large language model (LLM) powered automated modeling and optimization approach. First, the ADN dispatch problems are decomposed into sequential stages, and a multi-LLM coordination architecture is designed. This framework comprises an Information Extractor, a Problem Formulator, and a Code Programmer, tasked with information retrieval, optimization problem formulation, and code implementation, respectively. Afterwards, tailored refinement techniques are developed for each LLM agent, greatly improving the accuracy and reliability of generated content. The proposed approach features a user-centric interface that enables ADN operators to derive dispatch strategies via simple natural language queries, eliminating technical barriers and increasing efficiency. Comprehensive comparisons and end-to-end demonstrations on various test cases validate the effectiveness of the proposed architecture and methods.",
    "categories": [
      "cs.AI",
      "cs.LG",
      "eess.SY"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.21162v1",
    "published_date": "2025-07-25 07:46:25 UTC",
    "updated_date": "2025-07-25 07:46:25 UTC"
  },
  {
    "arxiv_id": "2507.19035v1",
    "title": "Dual Path Learning -- learning from noise and context for medical image denoising",
    "authors": [
      "Jitindra Fartiyal",
      "Pedro Freire",
      "Yasmeen Whayeb",
      "James S. Wolffsohn",
      "Sergei K. Turitsyn",
      "Sergei G. Sokolov"
    ],
    "abstract": "Medical imaging plays a critical role in modern healthcare, enabling clinicians to accurately diagnose diseases and develop effective treatment plans. However, noise, often introduced by imaging devices, can degrade image quality, leading to misinterpretation and compromised clinical outcomes. Existing denoising approaches typically rely either on noise characteristics or on contextual information from the image. Moreover, they are commonly developed and evaluated for a single imaging modality and noise type. Motivated by Geng et.al CNCL, which integrates both noise and context, this study introduces a Dual-Pathway Learning (DPL) model architecture that effectively denoises medical images by leveraging both sources of information and fusing them to generate the final output. DPL is evaluated across multiple imaging modalities and various types of noise, demonstrating its robustness and generalizability. DPL improves PSNR by 3.35% compared to the baseline UNet when evaluated on Gaussian noise and trained across all modalities. The code is available at 10.5281/zenodo.15836053.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "10 pages, 7 figures",
    "pdf_url": "https://arxiv.org/pdf/2507.19035v1",
    "published_date": "2025-07-25 07:43:50 UTC",
    "updated_date": "2025-07-25 07:43:50 UTC"
  },
  {
    "arxiv_id": "2507.22938v1",
    "title": "A Graph-based Approach for Multi-Modal Question Answering from Flowcharts in Telecom Documents",
    "authors": [
      "Sumit Soman",
      "H. G. Ranjani",
      "Sujoy Roychowdhury",
      "Venkata Dharma Surya Narayana Sastry",
      "Akshat Jain",
      "Pranav Gangrade",
      "Ayaaz Khan"
    ],
    "abstract": "Question-Answering (QA) from technical documents often involves questions whose answers are present in figures, such as flowcharts or flow diagrams. Text-based Retrieval Augmented Generation (RAG) systems may fail to answer such questions. We leverage graph representations of flowcharts obtained from Visual large Language Models (VLMs) and incorporate them in a text-based RAG system to show that this approach can enable image retrieval for QA in the telecom domain. We present the end-to-end approach from processing technical documents, classifying image types, building graph representations, and incorporating them with the text embedding pipeline for efficient retrieval. We benchmark the same on a QA dataset created based on proprietary telecom product information documents. Results show that the graph representations obtained using a fine-tuned VLM model have lower edit distance with respect to the ground truth, which illustrate the robustness of these representations for flowchart images. Further, the approach for QA using these representations gives good retrieval performance using text-based embedding models, including a telecom-domain adapted one. Our approach also alleviates the need for a VLM in inference, which is an important cost benefit for deployed QA systems.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted for publication at the KDD 2025 Workshop on Structured Knowledge for Large Language Models",
    "pdf_url": "https://arxiv.org/pdf/2507.22938v1",
    "published_date": "2025-07-25 07:36:13 UTC",
    "updated_date": "2025-07-25 07:36:13 UTC"
  },
  {
    "arxiv_id": "2507.21161v1",
    "title": "Seeing Beyond Frames: Zero-Shot Pedestrian Intention Prediction with Raw Temporal Video and Multimodal Cues",
    "authors": [
      "Pallavi Zambare",
      "Venkata Nikhil Thanikella",
      "Ying Liu"
    ],
    "abstract": "Pedestrian intention prediction is essential for autonomous driving in complex urban environments. Conventional approaches depend on supervised learning over frame sequences and require extensive retraining to adapt to new scenarios. Here, we introduce BF-PIP (Beyond Frames Pedestrian Intention Prediction), a zero-shot approach built upon Gemini 2.5 Pro. It infers crossing intentions directly from short, continuous video clips enriched with structured JAAD metadata. In contrast to GPT-4V based methods that operate on discrete frames, BF-PIP processes uninterrupted temporal clips. It also incorporates bounding-box annotations and ego-vehicle speed via specialized multimodal prompts. Without any additional training, BF-PIP achieves 73% prediction accuracy, outperforming a GPT-4V baseline by 18 %. These findings illustrate that combining temporal video inputs with contextual cues enhances spatiotemporal perception and improves intent inference under ambiguous conditions. This approach paves the way for agile, retraining-free perception module in intelligent transportation system.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted in IEEE 3rd International Conference on Artificial Intelligence, Blockchain, and Internet of Things (AIBThings 2025)",
    "pdf_url": "https://arxiv.org/pdf/2507.21161v1",
    "published_date": "2025-07-25 07:23:11 UTC",
    "updated_date": "2025-07-25 07:23:11 UTC"
  },
  {
    "arxiv_id": "2507.19017v1",
    "title": "MindSpeed RL: Distributed Dataflow for Scalable and Efficient RL Training on Ascend NPU Cluster",
    "authors": [
      "Laingjun Feng",
      "Chenyi Pan",
      "Xinjie Guo",
      "Fei Mei",
      "Benzhe Ning",
      "Jianxiang Zhang",
      "Xinyang Liu",
      "Beirong Zhou",
      "Zeng Shu",
      "Chang Liu",
      "Guang Yang",
      "Zhenyu Han",
      "Jiangben Wang",
      "Bo Wang"
    ],
    "abstract": "Reinforcement learning (RL) is a paradigm increasingly used to align large language models. Popular RL algorithms utilize multiple workers and can be modeled as a graph, where each node is the status of a worker and each edge represents dataflow between nodes. Owing to the heavy cross-node dependencies, the RL training system usually suffers from poor cluster scalability and low memory utilization. In this article, we introduce MindSpeed RL, an effective and efficient system for large-scale RL training. Unlike existing centralized methods, MindSpeed RL organizes the essential data dependencies in RL training, i.e., sample flow and resharding flow, from a distributed view. On the one hand, a distributed transfer dock strategy, which sets controllers and warehouses on the basis of the conventional replay buffer, is designed to release the dispatch overhead in the sample flow. A practical allgather--swap strategy is presented to eliminate redundant memory usage in resharding flow. In addition, MindSpeed RL further integrates numerous parallelization strategies and acceleration techniques for systematic optimization. Compared with existing state-of-the-art systems, comprehensive experiments on the RL training of popular Qwen2.5-Dense-7B/32B, Qwen3-MoE-30B, and DeepSeek-R1-MoE-671B show that MindSpeed RL increases the throughput by 1.42 ~ 3.97 times. Finally, we open--source MindSpeed RL and perform all the experiments on a super pod of Ascend with 384 neural processing units (NPUs) to demonstrate the powerful performance and reliability of Ascend.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "9 pages",
    "pdf_url": "https://arxiv.org/pdf/2507.19017v1",
    "published_date": "2025-07-25 07:11:49 UTC",
    "updated_date": "2025-07-25 07:11:49 UTC"
  },
  {
    "arxiv_id": "2507.19004v1",
    "title": "MedIQA: A Scalable Foundation Model for Prompt-Driven Medical Image Quality Assessment",
    "authors": [
      "Siyi Xun",
      "Yue Sun",
      "Jingkun Chen",
      "Zitong Yu",
      "Tong Tong",
      "Xiaohong Liu",
      "Mingxiang Wu",
      "Tao Tan"
    ],
    "abstract": "Rapid advances in medical imaging technology underscore the critical need for precise and automated image quality assessment (IQA) to ensure diagnostic accuracy. Existing medical IQA methods, however, struggle to generalize across diverse modalities and clinical scenarios. In response, we introduce MedIQA, the first comprehensive foundation model for medical IQA, designed to handle variability in image dimensions, modalities, anatomical regions, and types. We developed a large-scale multi-modality dataset with plentiful manually annotated quality scores to support this. Our model integrates a salient slice assessment module to focus on diagnostically relevant regions feature retrieval and employs an automatic prompt strategy that aligns upstream physical parameter pre-training with downstream expert annotation fine-tuning. Extensive experiments demonstrate that MedIQA significantly outperforms baselines in multiple downstream tasks, establishing a scalable framework for medical IQA and advancing diagnostic workflows and clinical decision-making.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "We note that the version after peer review of this paper has been provisionally accepted by The 28th International Conference on Medical Image Computing and Computer Assisted Intervention (MICCAI 2025)",
    "pdf_url": "https://arxiv.org/pdf/2507.19004v1",
    "published_date": "2025-07-25 07:02:47 UTC",
    "updated_date": "2025-07-25 07:02:47 UTC"
  },
  {
    "arxiv_id": "2507.19003v1",
    "title": "A diffusion-based generative model for financial time series via geometric Brownian motion",
    "authors": [
      "Gihun Kim",
      "Sun-Yong Choi",
      "Yeoneung Kim"
    ],
    "abstract": "We propose a novel diffusion-based generative framework for financial time series that incorporates geometric Brownian motion (GBM), the foundation of the Black--Scholes theory, into the forward noising process. Unlike standard score-based models that treat price trajectories as generic numerical sequences, our method injects noise proportionally to asset prices at each time step, reflecting the heteroskedasticity observed in financial time series. By accurately balancing the drift and diffusion terms, we show that the resulting log-price process reduces to a variance-exploding stochastic differential equation, aligning with the formulation in score-based generative models. The reverse-time generative process is trained via denoising score matching using a Transformer-based architecture adapted from the Conditional Score-based Diffusion Imputation (CSDI) framework. Empirical evaluations on historical stock data demonstrate that our model reproduces key stylized facts heavy-tailed return distributions, volatility clustering, and the leverage effect more realistically than conventional diffusion models.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "math.NA"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.19003v1",
    "published_date": "2025-07-25 07:02:09 UTC",
    "updated_date": "2025-07-25 07:02:09 UTC"
  },
  {
    "arxiv_id": "2507.19556v1",
    "title": "PEMUTA: Pedagogically-Enriched Multi-Granular Undergraduate Thesis Assessment",
    "authors": [
      "Jialu Zhang",
      "Qingyang Sun",
      "Qianyi Wang",
      "Weiyi Zhang",
      "Zunjie Xiao",
      "Xiaoqing Zhang",
      "Jianfeng Ren",
      "Jiang Liu"
    ],
    "abstract": "The undergraduate thesis (UGTE) plays an indispensable role in assessing a student's cumulative academic development throughout their college years. Although large language models (LLMs) have advanced education intelligence, they typically focus on holistic assessment with only one single evaluation score, but ignore the intricate nuances across multifaceted criteria, limiting their ability to reflect structural criteria, pedagogical objectives, and diverse academic competencies. Meanwhile, pedagogical theories have long informed manual UGTE evaluation through multi-dimensional assessment of cognitive development, disciplinary thinking, and academic performance, yet remain underutilized in automated settings. Motivated by the research gap, we pioneer PEMUTA, a pedagogically-enriched framework that effectively activates domain-specific knowledge from LLMs for multi-granular UGTE assessment. Guided by Vygotsky's theory and Bloom's Taxonomy, PEMUTA incorporates a hierarchical prompting scheme that evaluates UGTEs across six fine-grained dimensions: Structure, Logic, Originality, Writing, Proficiency, and Rigor (SLOWPR), followed by holistic synthesis. Two in-context learning techniques, \\ie, few-shot prompting and role-play prompting, are also incorporated to further enhance alignment with expert judgments without fine-tuning. We curate a dataset of authentic UGTEs with expert-provided SLOWPR-aligned annotations to support multi-granular UGTE assessment. Extensive experiments demonstrate that PEMUTA achieves strong alignment with expert evaluations, and exhibits strong potential for fine-grained, pedagogically-informed UGTE evaluations.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.19556v1",
    "published_date": "2025-07-25 06:47:26 UTC",
    "updated_date": "2025-07-25 06:47:26 UTC"
  },
  {
    "arxiv_id": "2507.18989v2",
    "title": "GENIAL: Generative Design Space Exploration via Network Inversion for Low Power Algorithmic Logic Units",
    "authors": [
      "Maxence Bouvier",
      "Ryan Amaudruz",
      "Felix Arnold",
      "Renzo Andri",
      "Lukas Cavigelli"
    ],
    "abstract": "As AI workloads proliferate, optimizing arithmetic units is becoming increasingly important for reducing the footprint of digital systems. Conventional design flows, which often rely on manual or heuristic-based optimization, are limited in their ability to thoroughly explore the vast design space. In this paper, we introduce GENIAL, a machine learning-based framework for the automatic generation and optimization of arithmetic units, with a focus on multipliers.\n  At the core of GENIAL is a Transformer-based surrogate model trained in two stages, involving self-supervised pretraining followed by supervised finetuning, to robustly forecast key hardware metrics such as power and area from abstracted design representations. By inverting the surrogate model, GENIAL efficiently searches for new operand encodings that directly minimize power consumption in arithmetic units for specific input data distributions. Extensive experiments on large datasets demonstrate that GENIAL is consistently more sample efficient than other methods, and converges faster towards optimized designs. This enables deployment of a high-effort logic synthesis optimization flow in the loop, improving the accuracy of the surrogate model. Notably, GENIAL automatically discovers encodings that achieve up to 18% switching activity savings within multipliers on representative AI workloads compared with the conventional two's complement. We also demonstrate the versatility of our approach by achieving significant improvements on Finite State Machines, highlighting GENIAL's applicability for a wide spectrum of logic functions. Together, these advances mark a significant step toward automated Quality-of-Results-optimized combinational circuit generation for digital systems.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.AR"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted at the 2026 31st Asia and South Pacific Design Automation Conference (ASP-DAC)",
    "pdf_url": "https://arxiv.org/pdf/2507.18989v2",
    "published_date": "2025-07-25 06:34:59 UTC",
    "updated_date": "2025-11-06 16:26:13 UTC"
  },
  {
    "arxiv_id": "2507.18987v1",
    "title": "Differentiated Thyroid Cancer Recurrence Classification Using Machine Learning Models and Bayesian Neural Networks with Varying Priors: A SHAP-Based Interpretation of the Best Performing Model",
    "authors": [
      "HMNS Kumari",
      "HMLS Kumari",
      "UMMPK Nawarathne"
    ],
    "abstract": "Differentiated thyroid cancer DTC recurrence is a major public health concern, requiring classification and predictive models that are not only accurate but also interpretable and uncertainty aware. This study introduces a comprehensive framework for DTC recurrence classification using a dataset containing 383 patients and 16 clinical and pathological variables. Initially, 11 machine learning ML models were employed using the complete dataset, where the Support Vector Machines SVM model achieved the highest accuracy of 0.9481. To reduce complexity and redundancy, feature selection was carried out using the Boruta algorithm, and the same ML models were applied to the reduced dataset, where it was observed that the Logistic Regression LR model obtained the maximum accuracy of 0.9611. However, these ML models often lack uncertainty quantification, which is critical in clinical decision making. Therefore, to address this limitation, the Bayesian Neural Networks BNN with six varying prior distributions, including Normal 0,1, Normal 0,10, Laplace 0,1, Cauchy 0,1, Cauchy 0,2.5, and Horseshoe 1, were implemented on both the complete and reduced datasets. The BNN model with Normal 0,10 prior distribution exhibited maximum accuracies of 0.9740 and 0.9870 before and after feature selection, respectively.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "16 pages, 15 figures, to be published in International Journal of Research in Computing (IJRC)",
    "pdf_url": "https://arxiv.org/pdf/2507.18987v1",
    "published_date": "2025-07-25 06:31:31 UTC",
    "updated_date": "2025-07-25 06:31:31 UTC"
  },
  {
    "arxiv_id": "2507.22937v1",
    "title": "CoE-Ops: Collaboration of LLM-based Experts for AIOps Question-Answering",
    "authors": [
      "Jinkun Zhao",
      "Yuanshuai Wang",
      "Xingjian Zhang",
      "Ruibo Chen",
      "Xingchuang Liao",
      "Junle Wang",
      "Lei Huang",
      "Kui Zhang",
      "Wenjun Wu"
    ],
    "abstract": "With the rapid evolution of artificial intelligence, AIOps has emerged as a prominent paradigm in DevOps. Lots of work has been proposed to improve the performance of different AIOps phases. However, constrained by domain-specific knowledge, a single model can only handle the operation requirement of a specific task,such as log parser,root cause analysis. Meanwhile, combining multiple models can achieve more efficient results, which have been proved in both previous ensemble learning and the recent LLM training domain. Inspired by these works,to address the similar challenges in AIOPS, this paper first proposes a collaboration-of-expert framework(CoE-Ops) incorporating a general-purpose large language model task classifier. A retrieval-augmented generation mechanism is introduced to improve the framework's capability in handling both Question-Answering tasks with high-level(Code,build,Test,etc.) and low-level(fault analysis,anomaly detection,etc.). Finally, the proposed method is implemented in the AIOps domain, and extensive experiments are conducted on the DevOps-EVAL dataset. Experimental results demonstrate that CoE-Ops achieves a 72% improvement in routing accuracy for high-level AIOps tasks compared to existing CoE methods, delivers up to 8% accuracy enhancement over single AIOps models in DevOps problem resolution, and outperforms larger-scale Mixture-of-Experts (MoE) models by up to 14% in accuracy.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.22937v1",
    "published_date": "2025-07-25 06:17:11 UTC",
    "updated_date": "2025-07-25 06:17:11 UTC"
  },
  {
    "arxiv_id": "2507.18977v1",
    "title": "Towards Improving Long-Tail Entity Predictions in Temporal Knowledge Graphs through Global Similarity and Weighted Sampling",
    "authors": [
      "Mehrnoosh Mirtaheri",
      "Ryan A. Rossi",
      "Sungchul Kim",
      "Kanak Mahadik",
      "Tong Yu",
      "Xiang Chen",
      "Mohammad Rostami"
    ],
    "abstract": "Temporal Knowledge Graph (TKG) completion models traditionally assume access to the entire graph during training. This overlooks challenges stemming from the evolving nature of TKGs, such as: (i) the model's requirement to generalize and assimilate new knowledge, and (ii) the task of managing new or unseen entities that often have sparse connections. In this paper, we present an incremental training framework specifically designed for TKGs, aiming to address entities that are either not observed during training or have sparse connections. Our approach combines a model-agnostic enhancement layer with a weighted sampling strategy, that can be augmented to and improve any existing TKG completion method. The enhancement layer leverages a broader, global definition of entity similarity, which moves beyond mere local neighborhood proximity of GNN-based methods. The weighted sampling strategy employed in training accentuates edges linked to infrequently occurring entities. We evaluate our method on two benchmark datasets, and demonstrate that our framework outperforms existing methods in total link prediction, inductive link prediction, and in addressing long-tail entities. Notably, our method achieves a 10\\% improvement and a 15\\% boost in MRR for these datasets. The results underscore the potential of our approach in mitigating catastrophic forgetting and enhancing the robustness of TKG completion methods, especially in an incremental training context",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.18977v1",
    "published_date": "2025-07-25 06:02:48 UTC",
    "updated_date": "2025-07-25 06:02:48 UTC"
  },
  {
    "arxiv_id": "2507.18973v2",
    "title": "A Toolbox, Not a Hammer -- Multi-TAG: Scaling Math Reasoning with Multi-Tool Aggregation",
    "authors": [
      "Bohan Yao",
      "Vikas Yadav"
    ],
    "abstract": "Augmenting large language models (LLMs) with external tools is a promising avenue for developing high-performance mathematical reasoning systems. Prior tool-augmented approaches typically finetune an LLM to select and invoke a single tool at each reasoning step and show promising results on simpler math reasoning benchmarks such as GSM8K. However, these approaches struggle with more complex math problems that require precise reasoning over multiple steps. To address this limitation, in this work, we propose Multi-TAG, a Multi-Tool AGgregation-based framework. Instead of relying on a single tool, Multi-TAG guides an LLM to concurrently invoke multiple tools at each reasoning step. It then aggregates their diverse outputs to verify and refine the reasoning process, enhancing solution robustness and accuracy. Notably, Multi-TAG is a finetuning-free, inference-only framework, making it readily applicable to any LLM backbone, including large open-weight models which are computationally expensive to finetune and proprietary frontier models which cannot be finetuned with custom recipes. We evaluate Multi-TAG on four challenging benchmarks: MATH500, AIME, AMC, and OlympiadBench. Across both open-weight and closed-source LLM backbones, Multi-TAG consistently and substantially outperforms state-of-the-art baselines, achieving average improvements of 6.0% to 7.5% over state-of-the-art baselines.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Published at EMNLP Findings 2025; 21 pages, 3 figures",
    "pdf_url": "https://arxiv.org/pdf/2507.18973v2",
    "published_date": "2025-07-25 05:57:47 UTC",
    "updated_date": "2025-08-22 01:07:00 UTC"
  },
  {
    "arxiv_id": "2507.18967v1",
    "title": "Underwater Waste Detection Using Deep Learning A Performance Comparison of YOLOv7 to 10 and Faster RCNN",
    "authors": [
      "UMMPK Nawarathne",
      "HMNS Kumari",
      "HMLS Kumari"
    ],
    "abstract": "Underwater pollution is one of today's most significant environmental concerns, with vast volumes of garbage found in seas, rivers, and landscapes around the world. Accurate detection of these waste materials is crucial for successful waste management, environmental monitoring, and mitigation strategies. In this study, we investigated the performance of five cutting-edge object recognition algorithms, namely YOLO (You Only Look Once) models, including YOLOv7, YOLOv8, YOLOv9, YOLOv10, and Faster Region-Convolutional Neural Network (R-CNN), to identify which model was most effective at recognizing materials in underwater situations. The models were thoroughly trained and tested on a large dataset containing fifteen different classes under diverse conditions, such as low visibility and variable depths. From the above-mentioned models, YOLOv8 outperformed the others, with a mean Average Precision (mAP) of 80.9%, indicating a significant performance. This increased performance is attributed to YOLOv8's architecture, which incorporates advanced features such as improved anchor-free mechanisms and self-supervised learning, allowing for more precise and efficient recognition of items in a variety of settings. These findings highlight the YOLOv8 model's potential as an effective tool in the global fight against pollution, improving both the detection capabilities and scalability of underwater cleanup operations.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "7 pages, 11 figures, to be published in International Journal of Research in Computing (IJRC)",
    "pdf_url": "https://arxiv.org/pdf/2507.18967v1",
    "published_date": "2025-07-25 05:36:37 UTC",
    "updated_date": "2025-07-25 05:36:37 UTC"
  },
  {
    "arxiv_id": "2507.19555v1",
    "title": "Extending Group Relative Policy Optimization to Continuous Control: A Theoretical Framework for Robotic Reinforcement Learning",
    "authors": [
      "Rajat Khanda",
      "Mohammad Baqar",
      "Sambuddha Chakrabarti",
      "Satyasaran Changdar"
    ],
    "abstract": "Group Relative Policy Optimization (GRPO) has shown promise in discrete action spaces by eliminating value function dependencies through group-based advantage estimation. However, its application to continuous control remains unexplored, limiting its utility in robotics where continuous actions are essential. This paper presents a theoretical framework extending GRPO to continuous control environments, addressing challenges in high-dimensional action spaces, sparse rewards, and temporal dynamics. Our approach introduces trajectory-based policy clustering, state-aware advantage estimation, and regularized policy updates designed for robotic applications. We provide theoretical analysis of convergence properties and computational complexity, establishing a foundation for future empirical validation in robotic systems including locomotion and manipulation tasks.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "13 pages, 2 figures",
    "pdf_url": "https://arxiv.org/pdf/2507.19555v1",
    "published_date": "2025-07-25 05:25:40 UTC",
    "updated_date": "2025-07-25 05:25:40 UTC"
  },
  {
    "arxiv_id": "2507.22077v1",
    "title": "From Cloud-Native to Trust-Native: A Protocol for Verifiable Multi-Agent Systems",
    "authors": [
      "Muyang Li"
    ],
    "abstract": "As autonomous agents powered by large language models (LLMs) proliferate in high-stakes domains -- from pharmaceuticals to legal workflows -- the challenge is no longer just intelligence, but verifiability. We introduce TrustTrack, a protocol that embeds structural guarantees -- verifiable identity, policy commitments, and tamper-resistant behavioral logs -- directly into agent infrastructure. This enables a new systems paradigm: trust-native autonomy. By treating compliance as a design constraint rather than post-hoc oversight, TrustTrack reframes how intelligent agents operate across organizations and jurisdictions. We present the protocol design, system requirements, and use cases in regulated domains such as pharmaceutical R&D, legal automation, and AI-native collaboration. We argue that the Cloud -> AI -> Agent -> Trust transition represents the next architectural layer for autonomous systems.",
    "categories": [
      "cs.MA",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.MA",
    "comment": "14 pages, 2 figures. Vision paper and protocol blueprint. No prior submission or publication",
    "pdf_url": "https://arxiv.org/pdf/2507.22077v1",
    "published_date": "2025-07-25 04:38:38 UTC",
    "updated_date": "2025-07-25 04:38:38 UTC"
  },
  {
    "arxiv_id": "2507.18945v1",
    "title": "TreeReader: A Hierarchical Academic Paper Reader Powered by Language Models",
    "authors": [
      "Zijian Zhang",
      "Pan Chen",
      "Fangshi Du",
      "Runlong Ye",
      "Oliver Huang",
      "Michael Liut",
      "Alán Aspuru-Guzik"
    ],
    "abstract": "Efficiently navigating and understanding academic papers is crucial for scientific progress. Traditional linear formats like PDF and HTML can cause cognitive overload and obscure a paper's hierarchical structure, making it difficult to locate key information. While LLM-based chatbots offer summarization, they often lack nuanced understanding of specific sections, may produce unreliable information, and typically discard the document's navigational structure. Drawing insights from a formative study on academic reading practices, we introduce TreeReader, a novel language model-augmented paper reader. TreeReader decomposes papers into an interactive tree structure where each section is initially represented by an LLM-generated concise summary, with underlying details accessible on demand. This design allows users to quickly grasp core ideas, selectively explore sections of interest, and verify summaries against the source text. A user study was conducted to evaluate TreeReader's impact on reading efficiency and comprehension. TreeReader provides a more focused and efficient way to navigate and understand complex academic literature by bridging hierarchical summarization with interactive exploration.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.18945v1",
    "published_date": "2025-07-25 04:31:09 UTC",
    "updated_date": "2025-07-25 04:31:09 UTC"
  },
  {
    "arxiv_id": "2507.21160v1",
    "title": "Handling Out-of-Distribution Data: A Survey",
    "authors": [
      "Lakpa Tamang",
      "Mohamed Reda Bouadjenek",
      "Richard Dazeley",
      "Sunil Aryal"
    ],
    "abstract": "In the field of Machine Learning (ML) and data-driven applications, one of the significant challenge is the change in data distribution between the training and deployment stages, commonly known as distribution shift. This paper outlines different mechanisms for handling two main types of distribution shifts: (i) Covariate shift: where the value of features or covariates change between train and test data, and (ii) Concept/Semantic-shift: where model experiences shift in the concept learned during training due to emergence of novel classes in the test phase. We sum up our contributions in three folds. First, we formalize distribution shifts, recite on how the conventional method fails to handle them adequately and urge for a model that can simultaneously perform better in all types of distribution shifts. Second, we discuss why handling distribution shifts is important and provide an extensive review of the methods and techniques that have been developed to detect, measure, and mitigate the effects of these shifts. Third, we discuss the current state of distribution shift handling mechanisms and propose future research directions in this area. Overall, we provide a retrospective synopsis of the literature in the distribution shift, focusing on OOD data that had been overlooked in the existing surveys.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "20 pages, 6 figures, 6 tables. Accepted at IEEE Transactions on Knowledge and Data Engineering",
    "pdf_url": "https://arxiv.org/pdf/2507.21160v1",
    "published_date": "2025-07-25 04:29:49 UTC",
    "updated_date": "2025-07-25 04:29:49 UTC"
  },
  {
    "arxiv_id": "2507.21159v1",
    "title": "Adaptive Cluster Collaborativeness Boosts LLMs Medical Decision Support Capacity",
    "authors": [
      "Zhihao Peng",
      "Liuxin Bao",
      "Shengyuan Liu",
      "Yixuan Yuan"
    ],
    "abstract": "The collaborativeness of large language models (LLMs) has proven effective in natural language processing systems, holding considerable promise for healthcare development. However, it lacks explicit component selection rules, necessitating human intervention or clinical-specific validation. Moreover, existing architectures heavily rely on a predefined LLM cluster, where partial LLMs underperform in medical decision support scenarios, invalidating the collaborativeness of LLMs. To this end, we propose an adaptive cluster collaborativeness methodology involving self-diversity and cross-consistency maximization mechanisms to boost LLMs medical decision support capacity. For the self-diversity, we calculate the fuzzy matching value of pairwise outputs within an LLM as its self-diversity value, subsequently prioritizing LLMs with high self-diversity values as cluster components in a training-free manner. For the cross-consistency, we first measure cross-consistency values between the LLM with the highest self-diversity value and others, and then gradually mask out the LLM having the lowest cross-consistency value to eliminate the potential inconsistent output during the collaborative propagation. Extensive experiments on two specialized medical datasets, NEJMQA and MMLU-Pro-health, demonstrate the effectiveness of our method across physician-oriented specialties. For example, on NEJMQA, our method achieves the accuracy rate up to the publicly official passing score across all disciplines, especially achieving ACC of 65.47\\% compared to the 56.12\\% achieved by GPT-4 on the Obstetrics and Gynecology discipline.",
    "categories": [
      "cs.AI",
      "cs.LG",
      "cs.MA"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.21159v1",
    "published_date": "2025-07-25 04:21:16 UTC",
    "updated_date": "2025-07-25 04:21:16 UTC"
  },
  {
    "arxiv_id": "2507.18937v2",
    "title": "CNN-based Surface Temperature Forecasts with Ensemble Numerical Weather Prediction over Medium-range Forecast Periods",
    "authors": [
      "Takuya Inoue",
      "Takuya Kawabata"
    ],
    "abstract": "In this study, a method that integrates convolutional neural networks (CNNs) with ensemble numerical weather prediction (NWP) models is proposed. This method enables surface temperature forecasting with lead times beyond the short-range, extending up to five days. Due to limited computational resources, operational medium-range temperature forecasts typically rely on low-resolution NWP models, which are prone to systematic and random errors. To resolve these limitations, the proposed method applies CNN-based post-processing (bias correction and spatial super-resolution) to an ensemble NWP system. First, the post-processing is applied to each ensemble member to reduce systematic errors and reconstruct high-resolution temperature fields from low-resolution model outputs. This approach reduces the systematic and random errors in NWP model outputs and outperforms operational post-processing. Second, the CNN is applied to all ensemble members to construct a new ensemble forecasting system, in which deterministic forecast accuracy, probabilistic reliability, and representation of ensemble spread are improved compared with those of the original system. We demonstrate that this CNN-based post-processing is fundamentally different from the artificial error reduction caused by smoothing inherent in ensemble averaging because the post-processing reduces forecast errors without degrading the forecast information. These results indicate that the proposed method provides a practical and scalable solution for improving medium-range temperature forecasts and is particularly valuable for use in operational centers with limited computational resources.",
    "categories": [
      "physics.ao-ph",
      "cs.AI",
      "cs.LG",
      "stat.ML"
    ],
    "primary_category": "physics.ao-ph",
    "comment": "41 pages, 12 figures",
    "pdf_url": "https://arxiv.org/pdf/2507.18937v2",
    "published_date": "2025-07-25 04:19:05 UTC",
    "updated_date": "2026-01-07 04:27:51 UTC"
  },
  {
    "arxiv_id": "2507.18929v1",
    "title": "MGHFT: Multi-Granularity Hierarchical Fusion Transformer for Cross-Modal Sticker Emotion Recognition",
    "authors": [
      "Jian Chen",
      "Yuxuan Hu",
      "Haifeng Lu",
      "Wei Wang",
      "Min Yang",
      "Chengming Li",
      "Xiping Hu"
    ],
    "abstract": "Although pre-trained visual models with text have demonstrated strong capabilities in visual feature extraction, sticker emotion understanding remains challenging due to its reliance on multi-view information, such as background knowledge and stylistic cues. To address this, we propose a novel multi-granularity hierarchical fusion transformer (MGHFT), with a multi-view sticker interpreter based on Multimodal Large Language Models. Specifically, inspired by the human ability to interpret sticker emotions from multiple views, we first use Multimodal Large Language Models to interpret stickers by providing rich textual context via multi-view descriptions. Then, we design a hierarchical fusion strategy to fuse the textual context into visual understanding, which builds upon a pyramid visual transformer to extract both global and local sticker features at multiple stages. Through contrastive learning and attention mechanisms, textual features are injected at different stages of the visual backbone, enhancing the fusion of global- and local-granularity visual semantics with textual guidance. Finally, we introduce a text-guided fusion attention mechanism to effectively integrate the overall multimodal features, enhancing semantic understanding. Extensive experiments on 2 public sticker emotion datasets demonstrate that MGHFT significantly outperforms existing sticker emotion recognition approaches, achieving higher accuracy and more fine-grained emotion recognition. Compared to the best pre-trained visual models, our MGHFT also obtains an obvious improvement, 5.4% on F1 and 4.0% on accuracy. The code is released at https://github.com/cccccj-03/MGHFT_ACMMM2025.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted by ACMMM2025",
    "pdf_url": "https://arxiv.org/pdf/2507.18929v1",
    "published_date": "2025-07-25 03:42:26 UTC",
    "updated_date": "2025-07-25 03:42:26 UTC"
  },
  {
    "arxiv_id": "2507.18925v2",
    "title": "WiSE-OD: Benchmarking Robustness in Infrared Object Detection",
    "authors": [
      "Heitor R. Medeiros",
      "Atif Belal",
      "Masih Aminbeidokhti",
      "Eric Granger",
      "Marco Pedersoli"
    ],
    "abstract": "Object detection (OD) in infrared (IR) imagery is critical for low-light and nighttime applications. However, the scarcity of large-scale IR datasets forces models to rely on weights pre-trained on RGB images. While fine-tuning on IR improves accuracy, it often compromises robustness under distribution shifts due to the inherent modality gap between RGB and IR. To address this, we introduce LLVIP-C and FLIR-C, two cross-modality out-of-distribution (OOD) benchmarks built by applying corruptions to standard IR datasets. Additionally, to fully leverage the complementary knowledge from RGB and infrared-trained models, we propose WiSE-OD, a weight-space ensembling method with two variants: WiSE-OD$_{ZS}$, which combines RGB zero-shot and IR fine-tuned weights, and WiSE-OD$_{LP}$, which blends zero-shot and linear probing. Evaluated using four RGB-pretrained detectors and two robust baselines on our benchmark and in the real-world out-of-distribution M3FD dataset, our WiSE-OD improves robustness across modalities and to corruption in synthetic and real-world distribution shifts without any additional training or inference costs. Our code is available at: https://github.com/heitorrapela/wiseod.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "WACV 2026: IEEE/CVF Winter Conf. on Applications of Computer Vision, Tucson, USA",
    "pdf_url": "https://arxiv.org/pdf/2507.18925v2",
    "published_date": "2025-07-25 03:33:50 UTC",
    "updated_date": "2025-12-28 00:08:25 UTC"
  },
  {
    "arxiv_id": "2507.18918v1",
    "title": "Uncovering Cross-Linguistic Disparities in LLMs using Sparse Autoencoders",
    "authors": [
      "Richmond Sin Jing Xuan",
      "Jalil Huseynov",
      "Yang Zhang"
    ],
    "abstract": "Multilingual large language models (LLMs) exhibit strong cross-linguistic generalization, yet medium to low resource languages underperform on common benchmarks such as ARC-Challenge, MMLU, and HellaSwag. We analyze activation patterns in Gemma-2-2B across all 26 residual layers and 10 languages: Chinese (zh), Russian (ru), Spanish (es), Italian (it), medium to low resource languages including Indonesian (id), Catalan (ca), Marathi (mr), Malayalam (ml), and Hindi (hi), with English (en) as the reference. Using Sparse Autoencoders (SAEs), we reveal systematic disparities in activation patterns. Medium to low resource languages receive up to 26.27 percent lower activations in early layers, with a persistent gap of 19.89 percent in deeper layers. To address this, we apply activation-aware fine-tuning via Low-Rank Adaptation (LoRA), leading to substantial activation gains, such as 87.69 percent for Malayalam and 86.32 percent for Hindi, while maintaining English retention at approximately 91 percent. After fine-tuning, benchmark results show modest but consistent improvements, highlighting activation alignment as a key factor in enhancing multilingual LLM performance.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.18918v1",
    "published_date": "2025-07-25 03:22:50 UTC",
    "updated_date": "2025-07-25 03:22:50 UTC"
  },
  {
    "arxiv_id": "2508.02834v2",
    "title": "Learning from B Cell Evolution: Adaptive Multi-Expert Diffusion for Antibody Design via Online Optimization",
    "authors": [
      "Hanqi Feng",
      "Peng Qiu",
      "Mengchun Zhang",
      "Yiran Tao",
      "You Fan",
      "Jingtao Xu",
      "Barnabas Poczos"
    ],
    "abstract": "Recent advances in diffusion models have shown remarkable potential for antibody design, yet existing approaches apply uniform generation strategies that cannot adapt to each antigen's unique requirements. Inspired by B cell affinity maturation, where antibodies evolve through multi-objective optimization balancing affinity, stability, and self-avoidance, we propose the first biologically-motivated framework that leverages physics-based domain knowledge within an online meta-learning system. Our method employs multiple specialized experts (van der Waals, molecular recognition, energy balance, and interface geometry) whose parameters evolve during generation based on iterative feedback, mimicking natural antibody refinement cycles. Instead of fixed protocols, this adaptive guidance discovers personalized optimization strategies for each target. Our experiments demonstrate that this approach: (1) discovers optimal SE(3)-equivariant guidance strategies for different antigen classes without pre-training, preserving molecular symmetries throughout optimization; (2) significantly enhances hotspot coverage and interface quality through target-specific adaptation, achieving balanced multi-objective optimization characteristic of therapeutic antibodies; (3) establishes a paradigm for iterative refinement where each antibody-antigen system learns its unique optimization profile through online evaluation; (4) generalizes effectively across diverse design challenges, from small epitopes to large protein interfaces, enabling precision-focused campaigns for individual targets.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.02834v2",
    "published_date": "2025-07-25 03:14:34 UTC",
    "updated_date": "2025-08-15 20:20:19 UTC"
  },
  {
    "arxiv_id": "2507.18897v1",
    "title": "HH-Codec: High Compression High-fidelity Discrete Neural Codec for Spoken Language Modeling",
    "authors": [
      "Rongkun Xue",
      "Yazhe Niu",
      "Shuai Hu",
      "Zixin Yin",
      "Yongqiang Yao",
      "Jing Yang"
    ],
    "abstract": "Discrete speech tokenization is a fundamental component in speech codecs. However, in large-scale speech-to-speech systems, the complexity of parallel streams from multiple quantizers and the computational cost of high-time-dimensional codecs pose significant challenges. In this paper, we introduce HH-Codec, a neural codec that achieves extreme compression at 24 tokens per second for 24 kHz audio while relying on single-quantizer inference. Our approach involves a carefully designed Vector Quantization space for Spoken Language Modeling, optimizing compression efficiency while minimizing information loss. Building on this, we propose an asymmetric encoder-decoder architecture (Audio-VQ-Mel-Audio) that leverages dual supervision and progressive training to enhance reconstruction stability and fidelity. HH-Codec achieves state-of-the-art performance in speech reconstruction with an ultra-low bandwidth of 0.3 kbps. We further evaluate its effectiveness in codebook utilization and generative model adaptation, with extensive ablations validating the necessity of each module. HH-Codec is available at https://github.com/opendilab/HH-Codec.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.18897v1",
    "published_date": "2025-07-25 02:44:30 UTC",
    "updated_date": "2025-07-25 02:44:30 UTC"
  },
  {
    "arxiv_id": "2507.18883v1",
    "title": "Success in Humanoid Reinforcement Learning under Partial Observation",
    "authors": [
      "Wuhao Wang",
      "Zhiyong Chen"
    ],
    "abstract": "Reinforcement learning has been widely applied to robotic control, but effective policy learning under partial observability remains a major challenge, especially in high-dimensional tasks like humanoid locomotion. To date, no prior work has demonstrated stable training of humanoid policies with incomplete state information in the benchmark Gymnasium Humanoid-v4 environment. The objective in this environment is to walk forward as fast as possible without falling, with rewards provided for staying upright and moving forward, and penalties incurred for excessive actions and external contact forces. This research presents the first successful instance of learning under partial observability in this environment. The learned policy achieves performance comparable to state-of-the-art results with full state access, despite using only one-third to two-thirds of the original states. Moreover, the policy exhibits adaptability to robot properties, such as variations in body part masses. The key to this success is a novel history encoder that processes a fixed-length sequence of past observations in parallel. Integrated into a standard model-free algorithm, the encoder enables performance on par with fully observed baselines. We hypothesize that it reconstructs essential contextual information from recent observations, thereby enabling robust decision-making.",
    "categories": [
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.AI",
    "comment": "11 pages, 3 figures, and 4 tables. Not published anywhere else",
    "pdf_url": "https://arxiv.org/pdf/2507.18883v1",
    "published_date": "2025-07-25 01:51:12 UTC",
    "updated_date": "2025-07-25 01:51:12 UTC"
  },
  {
    "arxiv_id": "2507.18882v1",
    "title": "A Comprehensive Review of AI-based Intelligent Tutoring Systems: Applications and Challenges",
    "authors": [
      "Meriem Zerkouk",
      "Miloud Mihoubi",
      "Belkacem Chikhaoui"
    ],
    "abstract": "AI-based Intelligent Tutoring Systems (ITS) have significant potential to transform teaching and learning. As efforts continue to design, develop, and integrate ITS into educational contexts, mixed results about their effectiveness have emerged. This paper provides a comprehensive review to understand how ITS operate in real educational settings and to identify the associated challenges in their application and evaluation. We use a systematic literature review method to analyze numerous qualified studies published from 2010 to 2025, examining domains such as pedagogical strategies, NLP, adaptive learning, student modeling, and domain-specific applications of ITS. The results reveal a complex landscape regarding the effectiveness of ITS, highlighting both advancements and persistent challenges. The study also identifies a need for greater scientific rigor in experimental design and data analysis. Based on these findings, suggestions for future research and practical implications are proposed.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.IR",
    "comment": "Journal of Computers in Education ( 2025 )",
    "pdf_url": "https://arxiv.org/pdf/2507.18882v1",
    "published_date": "2025-07-25 01:43:07 UTC",
    "updated_date": "2025-07-25 01:43:07 UTC"
  },
  {
    "arxiv_id": "2507.21158v1",
    "title": "Adaptive XAI in High Stakes Environments: Modeling Swift Trust with Multimodal Feedback in Human AI Teams",
    "authors": [
      "Nishani Fernando",
      "Bahareh Nakisa",
      "Adnan Ahmad",
      "Mohammad Naim Rastgoo"
    ],
    "abstract": "Effective human-AI teaming heavily depends on swift trust, particularly in high-stakes scenarios such as emergency response, where timely and accurate decision-making is critical. In these time-sensitive and cognitively demanding settings, adaptive explainability is essential for fostering trust between human operators and AI systems. However, existing explainable AI (XAI) approaches typically offer uniform explanations and rely heavily on explicit feedback mechanisms, which are often impractical in such high-pressure scenarios. To address this gap, we propose a conceptual framework for adaptive XAI that operates non-intrusively by responding to users' real-time cognitive and emotional states through implicit feedback, thereby enhancing swift trust in high-stakes environments. The proposed adaptive explainability trust framework (AXTF) leverages physiological and behavioral signals, such as EEG, ECG, and eye tracking, to infer user states and support explanation adaptation. At its core is a multi-objective, personalized trust estimation model that maps workload, stress, and emotion to dynamic trust estimates. These estimates guide the modulation of explanation features enabling responsive and personalized support that promotes swift trust in human-AI collaboration. This conceptual framework establishes a foundation for developing adaptive, non-intrusive XAI systems tailored to the rigorous demands of high-pressure, time-sensitive environments.",
    "categories": [
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.AI",
    "comment": "15 pages, 1 figure, Accepted to MAI-XAI@ECAI2025",
    "pdf_url": "https://arxiv.org/pdf/2507.21158v1",
    "published_date": "2025-07-25 01:39:55 UTC",
    "updated_date": "2025-07-25 01:39:55 UTC"
  },
  {
    "arxiv_id": "2507.18868v3",
    "title": "A Neuroscience-Inspired Dual-Process Model of Compositional Generalization",
    "authors": [
      "Alex Noviello",
      "Claas Beger",
      "Jacob Groner",
      "Kevin Ellis",
      "Weinan Sun"
    ],
    "abstract": "Deep learning models struggle with systematic compositional generalization, a hallmark of human cognition. We propose \\textsc{Mirage}, a neuro-inspired dual-process model that offers a processing account for this ability. It combines a fast, intuitive ``System~1'' (a meta-trained Transformer) with a deliberate, rule-based ``System~2'' (a Schema Engine), mirroring the brain's neocortical and hippocampal--prefrontal circuits. Trained to perform general, single-step decomposition on a stream of random grammars, Mirage achieves $>$99\\% accuracy on all splits of the SCAN benchmark in a task-agnostic setting. Ablations confirm that the model's systematic behavior emerges from the architectural interplay of its two systems, particularly its use of explicit, prioritized schemas and iterative refinement. In line with recent progress on recursive/recurrent Transformer approaches, Mirage preserves an iterative neural update while externalizing declarative control into an interpretable schema module. Our work provides a concrete computational model for interpreting how compositional reasoning can arise from a modular cognitive architecture.",
    "categories": [
      "cs.AI",
      "cs.NE"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.18868v3",
    "published_date": "2025-07-25 01:02:07 UTC",
    "updated_date": "2025-10-28 02:48:15 UTC"
  },
  {
    "arxiv_id": "2507.18867v1",
    "title": "Learning Individual Intrinsic Reward in Multi-Agent Reinforcement Learning via Incorporating Generalized Human Expertise",
    "authors": [
      "Xuefei Wu",
      "Xiao Yin",
      "Yuanyang Zhu",
      "Chunlin Chen"
    ],
    "abstract": "Efficient exploration in multi-agent reinforcement learning (MARL) is a challenging problem when receiving only a team reward, especially in environments with sparse rewards. A powerful method to mitigate this issue involves crafting dense individual rewards to guide the agents toward efficient exploration. However, individual rewards generally rely on manually engineered shaping-reward functions that lack high-order intelligence, thus it behaves ineffectively than humans regarding learning and generalization in complex problems. To tackle these issues, we combine the above two paradigms and propose a novel framework, LIGHT (Learning Individual Intrinsic reward via Incorporating Generalized Human experTise), which can integrate human knowledge into MARL algorithms in an end-to-end manner. LIGHT guides each agent to avoid unnecessary exploration by considering both individual action distribution and human expertise preference distribution. Then, LIGHT designs individual intrinsic rewards for each agent based on actionable representational transformation relevant to Q-learning so that the agents align their action preferences with the human expertise while maximizing the joint action value. Experimental results demonstrate the superiority of our method over representative baselines regarding performance and better knowledge reusability across different sparse-reward tasks on challenging scenarios.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.MA"
    ],
    "primary_category": "cs.LG",
    "comment": "IEEE International Conference on Systems, Man, and Cybernetics",
    "pdf_url": "https://arxiv.org/pdf/2507.18867v1",
    "published_date": "2025-07-25 00:59:10 UTC",
    "updated_date": "2025-07-25 00:59:10 UTC"
  },
  {
    "arxiv_id": "2507.18857v1",
    "title": "PrismRAG: Boosting RAG Factuality with Distractor Resilience and Strategized Reasoning",
    "authors": [
      "Mohammad Kachuee",
      "Teja Gollapudi",
      "Minseok Kim",
      "Yin Huang",
      "Kai Sun",
      "Xiao Yang",
      "Jiaqi Wang",
      "Nirav Shah",
      "Yue Liu",
      "Aaron Colak",
      "Anuj Kumar",
      "Wen-tau Yih",
      "Xin Luna Dong"
    ],
    "abstract": "Retrieval-augmented generation (RAG) often falls short when retrieved context includes confusing semi-relevant passages, or when answering questions require deep contextual understanding and reasoning. We propose an efficient fine-tuning framework, called PrismRAG, that (i) trains the model with distractor-aware QA pairs mixing gold evidence with subtle distractor passages, and (ii) instills reasoning-centric habits that make the LLM plan, rationalize, and synthesize without relying on extensive human engineered instructions. Evaluated across 12 open-book RAG QA benchmarks spanning diverse application domains and scenarios, PrismRAG improves average factuality by 5.4%, outperforming state-of-the-art solutions.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.18857v1",
    "published_date": "2025-07-25 00:15:31 UTC",
    "updated_date": "2025-07-25 00:15:31 UTC"
  }
]