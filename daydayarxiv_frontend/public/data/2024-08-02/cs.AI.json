{
  "date": "2024-08-02",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-08-02 的 arXiv 中文 TLDR 快报！\n\n今天 arXiv 的论文主要聚焦于 AI 模型的优化、鲁棒性和实际应用，包括 LLM 在多模态处理、强化学习和生物医学中的创新，以及图像处理和交通预测等领域的进展。其中，GPUDrive（第7篇）的高性能多代理模拟和 BioRAG（第50篇）的生物问答框架特别引人注目，同时一些论文如 Han Shao 的博士论文（第3篇）探讨了 AI 的社会挑战，展示了知名学者的学术深度。\n\n以下是今日论文的精选摘要，我将相关主题归类，先讨论重要或创新性强的论文（如 LLM 和强化学习），再快速掠过其他。每个条目列出论文标题（中文 + 英文），并简要概述核心贡献和发现。\n\n### LLM 和 AI 安全相关\n- **A General-Purpose Device for Interaction with LLMs（通用设备用于 LLM 交互）**（第2篇）：提出一种可扩展的硬件设备，支持 LLM 的多模态处理和隐私保护，主要贡献是通过强调可扩展性和效率，填补了 LLM 硬件应用中的空白，发现了在实际部署中的实用性。\n- **Trustworthy Machine Learning under Social and Adversarial Data Sources（社会和对抗数据源下的可信机器学习）**（第3篇，由 Han Shao 撰写）：分析机器学习在社会环境中的鲁棒性，主要发现是针对战略数据生成和攻击的挑战，提供了解决深度神经网络易受扰动的框架。\n- **Responsible AI Question Bank: A Comprehensive Tool for AI Risk Assessment（负责任 AI 问题库：AI 风险评估的综合工具）**（第4篇）：开发了一个基于公平性和透明度的 AI 风险评估框架，主要贡献是整合 EU AI Act 标准，帮助识别风险并提升 AI 治理。\n- **SumRecom: A Personalized Summarization Approach by Learning from Users' Feedback（SumRecom：基于用户反馈的学习个性化摘要方法）**（第5篇）：引入强化学习优化多文档摘要，主要发现是通过用户反馈捕获偏好，实现高效的个性化摘要。\n- **LibreLog: Accurate and Efficient Unsupervised Log Parsing Using Open-Source Large Language Models（LibreLog：使用开源 LLM 的准确高效无监督日志解析）**（第6篇）：提出无监督日志解析方法，使用 Llama3-8B 模型，主要贡献是提升解析准确性25%并减少查询，提高了隐私和效率。\n- **Evaluating the Impact of Advanced LLM Techniques on AI-Lecture Tutors for a Robotics Course（评估高级 LLM 技术对机器人课程 AI 助教的影响）**（第12篇）：评估提示工程和 RAG 在教育中的效果，主要发现 RAG 显著提升了 AI 助教的准确性和可信度。\n- **Gradient flow in parameter space is equivalent to linear interpolation in output space（参数空间的梯度流等价于输出空间的线性插值）**（第16篇）：证明了神经网络训练中的等价关系，主要贡献是提供理论基础，优化了训练过程的理解。\n- **Mission Impossible: A Statistical Perspective on Jailbreaking LLMs（不可能的任务：从统计视角看 LLM 越狱）**（第18篇）：从统计角度分析 LLM 偏好对齐和越狱问题，主要发现越狱是不可避免的，并提出 E-RLHF 方法改善安全。\n- **Prompt Recursive Search: A Living Framework with Adaptive Growth in LLM Auto-Prompting（提示递归搜索：LLM 自动提示的自适应框架）**（第17篇）：开发递归提示框架，提高 LLM 在复杂任务中的准确性，主要贡献是比 CoT 方法提升8%准确率。\n\n### 强化学习和机器人相关\n- **GPUDrive: Data-driven, multi-agent driving simulation at 1 million FPS（GPUDrive：基于数据的多代理驾驶模拟，每秒百万帧）**（第7篇）：构建高性能 GPU 模拟器，实现百万帧速率的多代理学习，主要发现加速了强化学习训练，适用于大规模场景。\n- **Conformal Diffusion Models for Individual Treatment Effect Estimation and Inference（保形扩散模型用于个体治疗效果估计和推理）**（第8篇）：提出扩散模型结合保形推理的方法，用于因果推断，主要贡献是处理分布偏移，提高了医疗决策的准确性。\n- **Active Learning for Neural PDE Solvers（神经 PDE 求解器的主动学习）**（第13篇）：开发主动学习基准 AL4PDE，减少训练数据需求，主要发现显著降低了 PDE 求解的错误率。\n- **Robot-Enabled Machine Learning-Based Diagnosis of Gastric Cancer Polyps Using Partial Surface Tactile Imaging（机器人辅助的机器学习胃癌息肉诊断，使用部分表面触觉成像）**（第11篇）：利用机器人和触觉传感器诊断胃癌，主要贡献是生成合成数据，提高了诊断准确性。\n- **A Backbone for Long-Horizon Robot Task Understanding（长时机器人任务理解的骨干框架）**（第27篇）：提出 Therblig-Based Backbone 框架，提升机器人任务分解和适应性，主要发现提高了任务执行成功率94%。\n\n### 图像和多模态处理相关\n- **SHARP-Net: A Refined Pyramid Network for Deficiency Segmentation in Culverts and Sewer Pipes（SHARP-Net：用于涵洞和下水道缺陷分割的精炼金字塔网络）**（第1篇）：设计新型语义分割网络，结合 Haar-like 特征，主要发现提升了 IoU 成绩22%，适用于基础设施检测。\n- **Contextual Cross-Modal Attention for Audio-Visual Deepfake Detection and Localization（语境跨模态注意力用于音频-视觉深度伪造检测和定位）**（第14篇）：提出 RNN 基于注意力框架检测深度伪造，主要贡献是提高了检测精度3.47%。\n- **PC²: Pseudo-Classification Based Pseudo-Captioning for Noisy Correspondence Learning in Cross-Modal Retrieval（PC²：基于伪分类的伪字幕生成，用于跨模态检索的噪声对应学习）**（第24篇）：开发框架处理跨模态噪声，主要发现提升了检索鲁棒性。\n\n### 生物医学和应用相关\n- **BioRAG: A RAG-LLM Framework for Biological Question Reasoning（BioRAG：用于生物问题推理的 RAG-LLM 框架）**（第50篇）：构建生物问答框架，使用 LLM 生成 TCR 序列，主要贡献是提高了序列生成准确性，适用于免疫疗法。\n- **TCR-GPT: Integrating Autoregressive Model and Reinforcement Learning for T-Cell Receptor Repertoires Generation（TCR-GPT：整合自回归模型和强化学习的 T 细胞受体库生成）**（第45篇）：结合 LLM 和强化学习生成 T 细胞序列，主要发现提升了生物序列的针对性。\n\n其他论文如交通预测（第9篇）、多模态融合（第25篇）和 LLM 适应性（第22篇）等，虽然有一定价值，但主题较窄或技术细节较常规，我这里快速掠过：这些工作主要优化了特定领域模型，如第9篇的 STPS 模型在长时交通预测中提升了准确性，第25篇的 StitchFusion 框架改进了多模态分割性能。\n\n总之，今天的论文展示了 AI 领域的多样创新，LLM 和强化学习方向尤为活跃，读者可关注 GPUDrive 和 BioRAG 等前沿应用。如果有特定兴趣，建议查看相关摘要深入！（本快报基于71篇论文精选，保持简洁以便快速阅读。）",
  "papers": [
    {
      "arxiv_id": "2408.08879v1",
      "title": "SHARP-Net: A Refined Pyramid Network for Deficiency Segmentation in Culverts and Sewer Pipes",
      "title_zh": "翻译失败",
      "authors": [
        "Rasha Alshawi",
        "Md Meftahul Ferdaus",
        "Md Tamjidul Hoque",
        "Kendall Niles",
        "Ken Pathak",
        "Steve Sloan",
        "Mahdi Abdelguerfi"
      ],
      "abstract": "This paper introduces Semantic Haar-Adaptive Refined Pyramid Network\n(SHARP-Net), a novel architecture for semantic segmentation. SHARP-Net\nintegrates a bottom-up pathway featuring Inception-like blocks with varying\nfilter sizes (3x3$ and 5x5), parallel max-pooling, and additional spatial\ndetection layers. This design captures multi-scale features and fine structural\ndetails. Throughout the network, depth-wise separable convolutions are used to\nreduce complexity. The top-down pathway of SHARP-Net focuses on generating\nhigh-resolution features through upsampling and information fusion using\n$1\\times1$ and $3\\times3$ depth-wise separable convolutions. We evaluated our\nmodel using our developed challenging Culvert-Sewer Defects dataset and the\nbenchmark DeepGlobe Land Cover dataset. Our experimental evaluation\ndemonstrated the base model's (excluding Haar-like features) effectiveness in\nhandling irregular defect shapes, occlusions, and class imbalances. It\noutperformed state-of-the-art methods, including U-Net, CBAM U-Net, ASCU-Net,\nFPN, and SegFormer, achieving average improvements of 14.4% and 12.1% on the\nCulvert-Sewer Defects and DeepGlobe Land Cover datasets, respectively, with IoU\nscores of 77.2% and 70.6%. Additionally, the training time was reduced.\nFurthermore, the integration of carefully selected and fine-tuned Haar-like\nfeatures enhanced the performance of deep learning models by at least 20%. The\nproposed SHARP-Net, incorporating Haar-like features, achieved an impressive\nIoU of 94.75%, representing a 22.74% improvement over the base model. These\nfeatures were also applied to other deep learning models, showing a 35.0%\nimprovement, proving their versatility and effectiveness. SHARP-Net thus\nprovides a powerful and efficient solution for accurate semantic segmentation\nin challenging real-world scenarios.",
      "tldr_zh": "该研究提出了 SHARP-Net，一种新型语义分割网络，结合底部向上的 Inception-like 块（使用 3x3 和 5x5 滤波器、并行最大池化和深度可分离卷积）以及顶部向下的上采样和信息融合路径，以捕获多尺度特征和精细结构细节，同时降低计算复杂度。实验在 Culvert-Sewer Defects 和 DeepGlobe Land Cover 数据集上评估，SHARP-Net 基础模型比 U-Net 等现有方法提升了平均 14.4% 和 12.1% 的 IoU，分别达到 77.2% 和 70.6%，并显著改善了不规则缺陷形状、遮挡和类别不平衡问题。进一步整合 Haar-like 特征后，SHARP-Net 的 IoU 提升至 94.75%，比基础模型提高 22.74%，并在其他模型上实现 35.0% 的性能提升，展示了其在真实场景语义分割中的高效性和通用性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.08879v1",
      "published_date": "2024-08-02 23:55:04 UTC",
      "updated_date": "2024-08-02 23:55:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T12:21:04.207839"
    },
    {
      "arxiv_id": "2408.10230v1",
      "title": "A General-Purpose Device for Interaction with LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Jiajun Xu",
        "Qun Wang",
        "Yuhang Cao",
        "Baitao Zeng",
        "Sicheng Liu"
      ],
      "abstract": "This paper investigates integrating large language models (LLMs) with\nadvanced hardware, focusing on developing a general-purpose device designed for\nenhanced interaction with LLMs. Initially, we analyze the current landscape,\nwhere virtual assistants and LLMs are reshaping human-technology interactions,\nhighlighting pivotal advancements and setting the stage for a new era of\nintelligent hardware. Despite substantial progress in LLM technology, a\nsignificant gap exists in hardware development, particularly concerning\nscalability, efficiency, affordability, and multimodal capabilities. This\ndisparity presents both challenges and opportunities, underscoring the need for\nhardware that is not only powerful but also versatile and capable of managing\nthe sophisticated demands of modern computation. Our proposed device addresses\nthese needs by emphasizing scalability, multimodal data processing, enhanced\nuser interaction, and privacy considerations, offering a comprehensive platform\nfor LLM integration in various applications.",
      "tldr_zh": "这篇论文探讨了将大型语言模型(LLMs)与先进硬件集成的可能性，旨在开发一个通用设备以提升人类与LLMs的交互。论文分析了当前技术景观，指出硬件发展在可扩展性(efficiency)、效率(scalability)、负担能力和多模态(multimodal)能力方面存在显著差距，这些问题既是挑战也是机遇。所提出的设备针对这些不足，强调可扩展性、多模态数据处理、增强的用户交互以及隐私考虑，提供一个全面平台，支持LLMs在各种应用中的集成。",
      "categories": [
        "cs.AR",
        "cs.AI",
        "cs.CL",
        "cs.HC",
        "cs.RO"
      ],
      "primary_category": "cs.AR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.10230v1",
      "published_date": "2024-08-02 23:43:29 UTC",
      "updated_date": "2024-08-02 23:43:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T12:21:12.668771"
    },
    {
      "arxiv_id": "2408.01596v1",
      "title": "Trustworthy Machine Learning under Social and Adversarial Data Sources",
      "title_zh": "在社会性和对抗性数据来源",
      "authors": [
        "Han Shao"
      ],
      "abstract": "Machine learning has witnessed remarkable breakthroughs in recent years. As\nmachine learning permeates various aspects of daily life, individuals and\norganizations increasingly interact with these systems, exhibiting a wide range\nof social and adversarial behaviors. These behaviors may have a notable impact\non the behavior and performance of machine learning systems. Specifically,\nduring these interactions, data may be generated by strategic individuals,\ncollected by self-interested data collectors, possibly poisoned by adversarial\nattackers, and used to create predictors, models, and policies satisfying\nmultiple objectives. As a result, the machine learning systems' outputs might\ndegrade, such as the susceptibility of deep neural networks to adversarial\nexamples (Shafahi et al., 2018; Szegedy et al., 2013) and the diminished\nperformance of classic algorithms in the presence of strategic individuals\n(Ahmadi et al., 2021). Addressing these challenges is imperative for the\nsuccess of machine learning in societal settings.",
      "tldr_zh": "该论文探讨了在社会和对抗性数据来源下构建可信赖机器学习系统的挑战。随着机器学习广泛应用于日常生活，数据可能由战略 individuals 生成、由自利数据收集者获取，或被 adversarial attackers 毒害，导致系统性能下降，例如深度神经网络对 adversarial examples 的易感性，以及经典算法在战略 individuals 存在时的表现减弱。论文强调，需要通过处理这些交互行为来开发鲁棒的预测模型和策略，以确保机器学习在社会环境中的成功应用。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.GT"
      ],
      "primary_category": "cs.LG",
      "comment": "PhD thesis",
      "pdf_url": "http://arxiv.org/pdf/2408.01596v1",
      "published_date": "2024-08-02 22:51:52 UTC",
      "updated_date": "2024-08-02 22:51:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T12:21:24.018093"
    },
    {
      "arxiv_id": "2408.11820v2",
      "title": "Responsible AI Question Bank: A Comprehensive Tool for AI Risk Assessment",
      "title_zh": "翻译失败",
      "authors": [
        "Sung Une Lee",
        "Harsha Perera",
        "Yue Liu",
        "Boming Xia",
        "Qinghua Lu",
        "Liming Zhu",
        "Olivier Salvado",
        "Jon Whittle"
      ],
      "abstract": "The rapid growth of Artificial Intelligence (AI) has underscored the urgent\nneed for responsible AI practices. Despite increasing interest, a comprehensive\nAI risk assessment toolkit remains lacking. This study introduces our\nResponsible AI (RAI) Question Bank, a comprehensive framework and tool designed\nto support diverse AI initiatives. By integrating AI ethics principles such as\nfairness, transparency, and accountability into a structured question format,\nthe RAI Question Bank aids in identifying potential risks, aligning with\nemerging regulations like the EU AI Act, and enhancing overall AI governance. A\nkey benefit of the RAI Question Bank is its systematic approach to linking\nlower-level risk questions to higher-level ones and related themes, preventing\nsiloed assessments and ensuring a cohesive evaluation process. Case studies\nillustrate the practical application of the RAI Question Bank in assessing AI\nprojects, from evaluating risk factors to informing decision-making processes.\nThe study also demonstrates how the RAI Question Bank can be used to ensure\ncompliance with standards, mitigate risks, and promote the development of\ntrustworthy AI systems. This work advances RAI by providing organizations with\na valuable tool to navigate the complexities of ethical AI development and\ndeployment while ensuring comprehensive risk management.",
      "tldr_zh": "本研究针对AI快速发展引发的负责任AI实践需求，引入了Responsible AI (RAI) Question Bank，这是一个全面的框架和工具，用于支持AI风险评估。RAI Question Bank通过整合AI伦理原则如fairness、transparency和accountability，形成结构化问题，并系统链接低级风险问题到高级主题，以避免孤立评估并提升AI治理。该工具通过案例研究证明了其在识别风险、符合法规（如EU AI Act）和决策过程中的实际应用，最终促进可信赖AI系统的开发和部署。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "30 pages, 6 tables, 14 figures",
      "pdf_url": "http://arxiv.org/pdf/2408.11820v2",
      "published_date": "2024-08-02 22:40:20 UTC",
      "updated_date": "2025-01-22 05:42:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T12:21:36.086772"
    },
    {
      "arxiv_id": "2408.07294v1",
      "title": "SumRecom: A Personalized Summarization Approach by Learning from Users' Feedback",
      "title_zh": "SumRecom：一种通过从用户反馈中学习来实现个性化的摘要方法",
      "authors": [
        "Samira Ghodratnama",
        "Mehrdad Zakershahrak"
      ],
      "abstract": "Existing multi-document summarization approaches produce a uniform summary\nfor all users without considering individuals' interests, which is highly\nimpractical. Making a user-specific summary is a challenging task as it\nrequires: i) acquiring relevant information about a user; ii) aggregating and\nintegrating the information into a user-model; and iii) utilizing the provided\ninformation in making the personalized summary. Therefore, in this paper, we\npropose a solution to a substantial and challenging problem in summarization,\ni.e., recommending a summary for a specific user. The proposed approach, called\nSumRecom, brings the human into the loop and focuses on three aspects:\npersonalization, interaction, and learning user's interest without the need for\nreference summaries. SumRecom has two steps: i) The user preference extractor\nto capture users' inclination in choosing essential concepts, and ii) The\nsummarizer to discover the user's best-fitted summary based on the given\nfeedback. Various automatic and human evaluations on the benchmark dataset\ndemonstrate the supremacy SumRecom in generating user-specific summaries.\nDocument summarization and Interactive summarization and Personalized\nsummarization and Reinforcement learning.",
      "tldr_zh": "本研究针对现有多文档 summarization 方法忽略用户个人兴趣的问题，提出了一种名为 SumRecom 的个性化摘要生成方法，通过学习用户的反馈来创建定制化总结。SumRecom 包括两个关键步骤：用户偏好提取器（user preference extractor），用于捕获用户在选择关键概念时的倾向；以及总结器（summarizer），基于反馈生成最适合用户的摘要。该方法强调个性化、交互和用户兴趣学习，无需参考摘要，并在基准数据集上的自动和人类评估中表现出色，优于传统基准模型。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.07294v1",
      "published_date": "2024-08-02 22:33:59 UTC",
      "updated_date": "2024-08-02 22:33:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T12:21:47.719808"
    },
    {
      "arxiv_id": "2408.01585v3",
      "title": "LibreLog: Accurate and Efficient Unsupervised Log Parsing Using Open-Source Large Language Models",
      "title_zh": "LibreLog：准确且高效的无监督日志解析，使用开源大型语言模型",
      "authors": [
        "Zeyang Ma",
        "Dong Jae Kim",
        "Tse-Hsun Chen"
      ],
      "abstract": "Log parsing is a critical step that transforms unstructured log data into\nstructured formats, facilitating subsequent log-based analysis. Traditional\nsyntax-based log parsers are efficient and effective, but they often experience\ndecreased accuracy when processing logs that deviate from the predefined rules.\nRecently, large language models (LLM) based log parsers have shown superior\nparsing accuracy. However, existing LLM-based parsers face three main\nchallenges: 1)time-consuming and labor-intensive manual labeling for\nfine-tuning or in-context learning, 2)increased parsing costs due to the vast\nvolume of log data and limited context size of LLMs, and 3)privacy risks from\nusing commercial models like ChatGPT with sensitive log information. To\novercome these limitations, this paper introduces LibreLog, an unsupervised log\nparsing approach that leverages open-source LLMs (i.e., Llama3-8B) to enhance\nprivacy and reduce operational costs while achieving state-of-the-art parsing\naccuracy. LibreLog first groups logs with similar static text but varying\ndynamic variables using a fixed-depth grouping tree. It then parses logs within\nthese groups using three components: i)similarity scoring-based retrieval\naugmented generation: selects diverse logs within each group based on Jaccard\nsimilarity, helping the LLM distinguish between static text and dynamic\nvariables; ii)self-reflection: iteratively query LLMs to refine log templates\nto improve parsing accuracy; and iii) log template memory: stores parsed\ntemplates to reduce LLM queries for improved parsing efficiency. Our evaluation\non LogHub-2.0 shows that LibreLog achieves 25% higher parsing accuracy and\nprocesses logs 2.7 times faster compared to state-of-the-art LLM-based parsers.\nIn short, LibreLog addresses privacy and cost concerns of using commercial LLMs\nwhile achieving state-of-the-arts parsing efficiency and accuracy.",
      "tldr_zh": "这篇论文提出了 LibreLog，一种无监督日志解析方法，使用开源 LLM（如 Llama3-8B）来解决传统解析器准确性不足以及现有 LLM-based 解析器在手动标注、成本和隐私风险上的挑战。LibreLog 通过固定深度分组树先对日志进行分组，然后结合基于 Jaccard 相似度的检索增强生成、自反省（迭代优化日志模板）和日志模板内存（减少 LLM 查询）来提升解析效率和准确性。在 LogHub-2.0 数据集上，LibreLog 的解析准确性比最先进方法高 25%，处理速度快 2.7 倍，从而实现了隐私友好且高效的日志解析。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.01585v3",
      "published_date": "2024-08-02 21:54:13 UTC",
      "updated_date": "2024-11-18 05:18:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T12:22:01.007993"
    },
    {
      "arxiv_id": "2408.01584v3",
      "title": "GPUDrive: Data-driven, multi-agent driving simulation at 1 million FPS",
      "title_zh": "翻译失败",
      "authors": [
        "Saman Kazemkhani",
        "Aarav Pandya",
        "Daphne Cornelisse",
        "Brennan Shacklett",
        "Eugene Vinitsky"
      ],
      "abstract": "Multi-agent learning algorithms have been successful at generating superhuman\nplanning in various games but have had limited impact on the design of deployed\nmulti-agent planners. A key bottleneck in applying these techniques to\nmulti-agent planning is that they require billions of steps of experience. To\nenable the study of multi-agent planning at scale, we present GPUDrive.\nGPUDrive is a GPU-accelerated, multi-agent simulator built on top of the\nMadrona Game Engine capable of generating over a million simulation steps per\nsecond. Observation, reward, and dynamics functions are written directly in\nC++, allowing users to define complex, heterogeneous agent behaviors that are\nlowered to high-performance CUDA. Despite these low-level optimizations,\nGPUDrive is fully accessible through Python, offering a seamless and efficient\nworkflow for multi-agent, closed-loop simulation. Using GPUDrive, we train\nreinforcement learning agents on the Waymo Open Motion Dataset, achieving\nefficient goal-reaching in minutes and scaling to thousands of scenarios in\nhours. We open-source the code and pre-trained agents at\nhttps://github.com/Emerge-Lab/gpudrive.",
      "tldr_zh": "该论文引入了 GPUDrive，一种数据驱动的多智能体驾驶模拟器，基于 Madrona Game Engine 并利用 GPU 加速，能够每秒生成超过一百万模拟步骤，从而解决多智能体学习算法需要海量经验的瓶颈。用户可以通过 C++ 定义复杂的观察、奖励和动态函数，同时通过 Python 接口实现无缝集成和高效工作流程。实验结果显示，使用 Waymo Open Motion Dataset 训练 reinforcement learning 代理，仅需几分钟即可实现高效目标到达，并在数小时内扩展到数千场景；代码和预训练代理已在 GitHub 开源。",
      "categories": [
        "cs.AI",
        "cs.AR",
        "cs.GR",
        "cs.PF"
      ],
      "primary_category": "cs.AI",
      "comment": "ICLR 2025 camera-ready version",
      "pdf_url": "http://arxiv.org/pdf/2408.01584v3",
      "published_date": "2024-08-02 21:37:46 UTC",
      "updated_date": "2025-02-18 14:09:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T12:22:12.162904"
    },
    {
      "arxiv_id": "2408.01582v1",
      "title": "Conformal Diffusion Models for Individual Treatment Effect Estimation and Inference",
      "title_zh": "翻译失败",
      "authors": [
        "Hengrui Cai",
        "Huaqing Jin",
        "Lexin Li"
      ],
      "abstract": "Estimating treatment effects from observational data is of central interest\nacross numerous application domains. Individual treatment effect offers the\nmost granular measure of treatment effect on an individual level, and is the\nmost useful to facilitate personalized care. However, its estimation and\ninference remain underdeveloped due to several challenges. In this article, we\npropose a novel conformal diffusion model-based approach that addresses those\nintricate challenges. We integrate the highly flexible diffusion modeling, the\nmodel-free statistical inference paradigm of conformal inference, along with\npropensity score and covariate local approximation that tackle distributional\nshifts. We unbiasedly estimate the distributions of potential outcomes for\nindividual treatment effect, construct an informative confidence interval, and\nestablish rigorous theoretical guarantees. We demonstrate the competitive\nperformance of the proposed method over existing solutions through extensive\nnumerical studies.",
      "tldr_zh": "该研究针对从观察数据中估计个体治疗效果（Individual Treatment Effect）的挑战，提出了一种新型的Conformal Diffusion Models方法，以支持个性化护理。方法整合了灵活的Diffusion Modeling、Conformal Inference的统计推断框架，以及Propensity Score和Covariate Local Approximation来处理分布偏移问题，从而实现潜在结果分布的无偏估计和信息丰富的置信区间构建。研究还提供了严格的理论保证，并通过广泛的数值实验证明，该方法在性能上优于现有解决方案。",
      "categories": [
        "stat.ML",
        "cs.AI",
        "cs.LG",
        "stat.ME"
      ],
      "primary_category": "stat.ML",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.01582v1",
      "published_date": "2024-08-02 21:35:08 UTC",
      "updated_date": "2024-08-02 21:35:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T12:22:23.934865"
    },
    {
      "arxiv_id": "2408.02689v1",
      "title": "Spatio-Temporal Partial Sensing Forecast for Long-term Traffic",
      "title_zh": "针对长期交通的时空部分感知预测",
      "authors": [
        "Zibo Liu",
        "Zhe Jiang",
        "Zelin Xu",
        "Tingsong Xiao",
        "Zhengkun Xiao",
        "Haibo Wang",
        "Shigang Chen"
      ],
      "abstract": "Traffic forecasting uses recent measurements by sensors installed at chosen\nlocations to forecast the future road traffic. Existing work either assumes all\nlocations are equipped with sensors or focuses on short-term forecast. This\npaper studies partial sensing traffic forecast of long-term traffic, assuming\nsensors only at some locations. The study is important in lowering the\ninfrastructure investment cost in traffic management since deploying sensors at\nall locations could incur prohibitively high cost. However, the problem is\nchallenging due to the unknown distribution at unsensed locations, the\nintricate spatio-temporal correlation in long-term forecasting, as well as\nnoise in data and irregularities in traffic patterns (e.g., road closure). We\npropose a Spatio-Temporal Partial Sensing (STPS) forecast model for long-term\ntraffic prediction, with several novel contributions, including a rank-based\nembedding technique to capture irregularities and overcome noise, a spatial\ntransfer matrix to overcome the spatial distribution shift from permanently\nsensed locations to unsensed locations, and a multi-step training process that\nutilizes all available data to successively refine the model parameters for\nbetter accuracy. Extensive experiments on several real-world traffic datasets\ndemonstrate that STPS outperforms the state-of-the-art and achieves superior\naccuracy in partial sensing long-term forecasting.",
      "tldr_zh": "本文研究了部分感知识别下的长期交通预测问题，旨在通过仅在部分位置部署传感器来降低基础设施成本，同时应对未知分布、时空相关性、数据噪声和交通模式不规则（如道路封闭）的挑战。提出 Spatio-Temporal Partial Sensing (STPS) 模型，其关键创新包括 rank-based embedding technique 用于捕捉不规则性和克服噪声、spatial transfer matrix 用于处理从已感知识别到未感知识别的空间分布偏移，以及 multi-step training process 通过利用所有数据逐步优化模型参数。实验结果显示，在多个真实交通数据集上，STPS 优于现有最先进方法，在部分感知识别下的长期预测中实现了更高的准确性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.02689v1",
      "published_date": "2024-08-02 21:22:22 UTC",
      "updated_date": "2024-08-02 21:22:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T12:22:37.558974"
    },
    {
      "arxiv_id": "2408.03964v1",
      "title": "Telecom Foundation Models: Applications, Challenges, and Future Trends",
      "title_zh": "电信基础模型：应用、挑战与未来趋势",
      "authors": [
        "Tahar Zanouda",
        "Meysam Masoudi",
        "Fitsum Gaim Gebre",
        "Mischa Dohler"
      ],
      "abstract": "Telecom networks are becoming increasingly complex, with diversified\ndeployment scenarios, multi-standards, and multi-vendor support. The intricate\nnature of the telecom network ecosystem presents challenges to effectively\nmanage, operate, and optimize networks. To address these hurdles, Artificial\nIntelligence (AI) has been widely adopted to solve different tasks in telecom\nnetworks. However, these conventional AI models are often designed for specific\ntasks, rely on extensive and costly-to-collect labeled data that require\nspecialized telecom expertise for development and maintenance. The AI models\nusually fail to generalize and support diverse deployment scenarios and\napplications. In contrast, Foundation Models (FMs) show effective\ngeneralization capabilities in various domains in language, vision, and\ndecision-making tasks. FMs can be trained on multiple data modalities generated\nfrom the telecom ecosystem and leverage specialized domain knowledge. Moreover,\nFMs can be fine-tuned to solve numerous specialized tasks with minimal\ntask-specific labeled data and, in some instances, are able to leverage context\nto solve previously unseen problems. At the dawn of 6G, this paper investigates\nthe potential opportunities of using FMs to shape the future of telecom\ntechnologies and standards. In particular, the paper outlines a conceptual\nprocess for developing Telecom FMs (TFMs) and discusses emerging opportunities\nfor orchestrating specialized TFMs for network configuration, operation, and\nmaintenance. Finally, the paper discusses the limitations and challenges of\ndeveloping and deploying TFMs.",
      "tldr_zh": "该论文探讨了在日益复杂的电信网络环境中，使用Foundation Models (FMs)来解决传统AI模型的局限性，如任务专用性、数据依赖性和泛化能力不足。论文提出Telecom Foundation Models (TFMs)的概念框架，包括基于多模态数据训练和少量标注数据的微调方法，以支持网络配置、操作和维护等应用。研究强调TFMs在6G时代的发展机会，同时分析了潜在挑战，如数据获取和部署难题，最终为电信技术的未来趋势提供指导。",
      "categories": [
        "cs.NI",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.NI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.03964v1",
      "published_date": "2024-08-02 21:09:13 UTC",
      "updated_date": "2024-08-02 21:09:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T12:22:48.133808"
    },
    {
      "arxiv_id": "2408.01554v1",
      "title": "Robot-Enabled Machine Learning-Based Diagnosis of Gastric Cancer Polyps Using Partial Surface Tactile Imaging",
      "title_zh": "翻译失败",
      "authors": [
        "Siddhartha Kapuria",
        "Jeff Bonyun",
        "Yash Kulkarni",
        "Naruhiko Ikoma",
        "Sandeep Chinchali",
        "Farshid Alambeigi"
      ],
      "abstract": "In this paper, to collectively address the existing limitations on endoscopic\ndiagnosis of Advanced Gastric Cancer (AGC) Tumors, for the first time, we\npropose (i) utilization and evaluation of our recently developed Vision-based\nTactile Sensor (VTS), and (ii) a complementary Machine Learning (ML) algorithm\nfor classifying tumors using their textural features. Leveraging a seven DoF\nrobotic manipulator and unique custom-designed and additively-manufactured\nrealistic AGC tumor phantoms, we demonstrated the advantages of automated data\ncollection using the VTS addressing the problem of data scarcity and biases\nencountered in traditional ML-based approaches. Our synthetic-data-trained ML\nmodel was successfully evaluated and compared with traditional ML models\nutilizing various statistical metrics even under mixed morphological\ncharacteristics and partial sensor contact.",
      "tldr_zh": "本文提出了一种基于机器学习 (ML) 的高级胃癌 (AGC) 肿瘤诊断方法，利用视觉-based Tactile Sensor (VTS) 和七自由度机器人进行部分表面触觉成像，以解决传统内镜诊断的数据稀缺和偏差问题。研究通过自定义的3D打印肿瘤模型实现自动化数据收集，并训练ML算法使用肿瘤纹理特征进行分类。实验结果显示，该模型在混合形态和部分传感器接触条件下优于传统模型，在各种统计指标上表现出显著优势。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.01554v1",
      "published_date": "2024-08-02 20:01:23 UTC",
      "updated_date": "2024-08-02 20:01:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T12:23:01.438838"
    },
    {
      "arxiv_id": "2408.04645v1",
      "title": "Evaluating the Impact of Advanced LLM Techniques on AI-Lecture Tutors for a Robotics Course",
      "title_zh": "评估高级LLM技术对机器人课程AI-Lecture Tutors的影响",
      "authors": [
        "Sebastian Kahl",
        "Felix Löffler",
        "Martin Maciol",
        "Fabian Ridder",
        "Marius Schmitz",
        "Jennifer Spanagel",
        "Jens Wienkamp",
        "Christopher Burgahn",
        "Malte Schilling"
      ],
      "abstract": "This study evaluates the performance of Large Language Models (LLMs) as an\nArtificial Intelligence-based tutor for a university course. In particular,\ndifferent advanced techniques are utilized, such as prompt engineering,\nRetrieval-Augmented-Generation (RAG), and fine-tuning. We assessed the\ndifferent models and applied techniques using common similarity metrics like\nBLEU-4, ROUGE, and BERTScore, complemented by a small human evaluation of\nhelpfulness and trustworthiness. Our findings indicate that RAG combined with\nprompt engineering significantly enhances model responses and produces better\nfactual answers. In the context of education, RAG appears as an ideal technique\nas it is based on enriching the input of the model with additional information\nand material which usually is already present for a university course.\nFine-tuning, on the other hand, can produce quite small, still strong expert\nmodels, but poses the danger of overfitting. Our study further asks how we\nmeasure performance of LLMs and how well current measurements represent\ncorrectness or relevance? We find high correlation on similarity metrics and a\nbias of most of these metrics towards shorter responses. Overall, our research\npoints to both the potential and challenges of integrating LLMs in educational\nsettings, suggesting a need for balanced training approaches and advanced\nevaluation frameworks.",
      "tldr_zh": "这篇论文评估了先进LLM技术（如提示工程、Retrieval-Augmented-Generation (RAG)和fine-tuning）对机器人课程AI助教的影响。研究通过BLEU-4、ROUGE和BERTScore等相似性指标，以及少量人类评估，发现RAG结合提示工程显著提升了模型的响应质量和事实准确性，使其更适合教育环境，因为它利用现有课程材料增强输入。另一方面，fine-tuning虽能创建小型高效专家模型，但存在过度拟合风险；论文还指出当前性能测量指标存在偏差（如偏向较短响应），并强调LLMs在教育中的潜力与挑战，需要平衡的训练方法和更先进的评估框架。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY",
        "cs.RO"
      ],
      "primary_category": "cs.CL",
      "comment": "The article is an extended version of a paper presented at the\n  International Workshop on AI in Education and Educational Research (AIEER) at\n  ECAI-2024 (27th European Conference on Artificial Intelligence)",
      "pdf_url": "http://arxiv.org/pdf/2408.04645v1",
      "published_date": "2024-08-02 19:49:19 UTC",
      "updated_date": "2024-08-02 19:49:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T12:23:13.034696"
    },
    {
      "arxiv_id": "2408.01536v2",
      "title": "Active Learning for Neural PDE Solvers",
      "title_zh": "翻译失败",
      "authors": [
        "Daniel Musekamp",
        "Marimuthu Kalimuthu",
        "David Holzmüller",
        "Makoto Takamoto",
        "Mathias Niepert"
      ],
      "abstract": "Solving partial differential equations (PDEs) is a fundamental problem in\nscience and engineering. While neural PDE solvers can be more efficient than\nestablished numerical solvers, they often require large amounts of training\ndata that is costly to obtain. Active learning (AL) could help surrogate models\nreach the same accuracy with smaller training sets by querying classical\nsolvers with more informative initial conditions and PDE parameters. While AL\nis more common in other domains, it has yet to be studied extensively for\nneural PDE solvers. To bridge this gap, we introduce AL4PDE, a modular and\nextensible active learning benchmark. It provides multiple parametric PDEs and\nstate-of-the-art surrogate models for the solver-in-the-loop setting, enabling\nthe evaluation of existing and the development of new AL methods for neural PDE\nsolving. We use the benchmark to evaluate batch active learning algorithms such\nas uncertainty- and feature-based methods. We show that AL reduces the average\nerror by up to 71% compared to random sampling and significantly reduces\nworst-case errors. Moreover, AL generates similar datasets across repeated\nruns, with consistent distributions over the PDE parameters and initial\nconditions. The acquired datasets are reusable, providing benefits for\nsurrogate models not involved in the data generation.",
      "tldr_zh": "本论文探讨了使用主动学习 (Active Learning, AL) 来优化神经偏微分方程 (PDEs) 求解器的问题，以减少训练数据需求并提高效率。研究引入了 AL4PDE，一个模块化和可扩展的基准平台，包含多种参数化 PDE 和最先进的代理模型，支持求解器在循环设置下的评估和算法开发。实验结果表明，基于不确定性和特征的批量 AL 方法比随机采样降低了平均错误高达 71%，并显著减少了最坏情况错误；此外，AL 生成的数据集在重复运行中保持一致分布，且可重用于其他代理模型，提供更广泛的适用性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CE",
        "cs.NE"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.01536v2",
      "published_date": "2024-08-02 18:48:58 UTC",
      "updated_date": "2025-03-24 10:31:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T12:23:25.607911"
    },
    {
      "arxiv_id": "2408.01532v2",
      "title": "Contextual Cross-Modal Attention for Audio-Visual Deepfake Detection and Localization",
      "title_zh": "翻译失败",
      "authors": [
        "Vinaya Sree Katamneni",
        "Ajita Rattani"
      ],
      "abstract": "In the digital age, the emergence of deepfakes and synthetic media presents a\nsignificant threat to societal and political integrity. Deepfakes based on\nmulti-modal manipulation, such as audio-visual, are more realistic and pose a\ngreater threat. Current multi-modal deepfake detectors are often based on the\nattention-based fusion of heterogeneous data streams from multiple modalities.\nHowever, the heterogeneous nature of the data (such as audio and visual\nsignals) creates a distributional modality gap and poses a significant\nchallenge in effective fusion and hence multi-modal deepfake detection. In this\npaper, we propose a novel multi-modal attention framework based on recurrent\nneural networks (RNNs) that leverages contextual information for audio-visual\ndeepfake detection. The proposed approach applies attention to multi-modal\nmulti-sequence representations and learns the contributing features among them\nfor deepfake detection and localization. Thorough experimental validations on\naudio-visual deepfake datasets, namely FakeAVCeleb, AV-Deepfake1M, TVIL, and\nLAV-DF datasets, demonstrate the efficacy of our approach. Cross-comparison\nwith the published studies demonstrates superior performance of our approach\nwith an improved accuracy and precision by 3.47% and 2.05% in deepfake\ndetection and localization, respectively. Thus, obtaining state-of-the-art\nperformance. To facilitate reproducibility, the code and the datasets\ninformation is available at https://github.com/vcbsl/audiovisual-deepfake/.",
      "tldr_zh": "本研究针对音频-视觉多模态深度伪造（deepfakes）的检测挑战，提出了一种基于循环神经网络（RNNs）的上下文跨模态注意力框架，以克服模态间分布差距问题。该框架通过对多模态多序列表示应用注意力机制，学习关键特征，从而实现深度伪造的检测和定位。在FakeAVCeleb、AV-Deepfake1M等数据集上的实验验证显示，该方法比现有研究提高了3.47%的准确率和2.05%的精确率，达到了最先进性能。该框架的代码和数据集信息已开源，以促进复现和进一步研究。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.CV",
        "cs.MM",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.01532v2",
      "published_date": "2024-08-02 18:45:01 UTC",
      "updated_date": "2024-08-06 21:19:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T12:23:36.280293"
    },
    {
      "arxiv_id": "2408.01527v2",
      "title": "Using LLMs to Establish Implicit User Sentiment of Software Desirability",
      "title_zh": "利用 LLMs 建立软件可取性的隐含用户情感",
      "authors": [
        "Sherri Weitl-Harms",
        "John D. Hastings",
        "Jonah Lum"
      ],
      "abstract": "This study explores the use of LLMs for providing quantitative zero-shot\nsentiment analysis of implicit software desirability, addressing a critical\nchallenge in product evaluation where traditional review scores, though\nconvenient, fail to capture the richness of qualitative user feedback.\nInnovations include establishing a method that 1) works with qualitative user\nexperience data without the need for explicit review scores, 2) focuses on\nimplicit user satisfaction, and 3) provides scaled numerical sentiment\nanalysis, offering a more nuanced understanding of user sentiment, instead of\nsimply classifying sentiment as positive, neutral, or negative.\n  Data is collected using the Microsoft Product Desirability Toolkit (PDT), a\nwell-known qualitative user experience analysis tool. For initial exploration,\nthe PDT metric was given to users of two software systems. PDT data was fed\nthrough several LLMs (Claude Sonnet 3 and 3.5, GPT4, and GPT4o) and through a\nleading transfer learning technique, Twitter-Roberta-Base-Sentiment, and Vader,\na leading sentiment analysis tool. Each system was asked to evaluate the data\nin two ways, by looking at the sentiment expressed in the PDT word/explanation\npairs; and by looking at the sentiment expressed by the users in their grouped\nselection of five words and explanations, as a whole. Each LLM provided a\nsentiment score, its confidence (low, medium, high) in the score, and an\nexplanation of the score.\n  All LLMs tested were able to statistically detect user sentiment from the\nusers' grouped data, whereas TRBS and Vader were not. The confidence and\nexplanation of confidence provided by the LLMs assisted in understanding user\nsentiment. This study adds deeper understanding of evaluating user experiences,\ntoward the goal of creating a universal tool that quantifies implicit\nsentiment.",
      "tldr_zh": "这篇论文探讨了使用大型语言模型（LLMs）进行零-shot情感分析，以量化软件的隐性吸引力，解决了传统评论分数无法捕捉定性用户反馈的局限。研究创新性地采用Microsoft Product Desirability Toolkit (PDT)收集用户数据，并通过LLMs（如Claude Sonnet 3.5、GPT4）分析情感，提供数值分数、置信度（low, medium, high）和解释，而非简单分类。实验结果显示，LLMs能有效从用户分组数据中检测隐性情感，而传统模型如Twitter-Roberta-Base-Sentiment和Vader无法实现，这为开发通用工具量化隐性用户体验奠定了基础。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.HC",
        "cs.LG",
        "cs.SE",
        "I.2.7; D.2.8; I.2.6; H.5.2"
      ],
      "primary_category": "cs.CL",
      "comment": "6 pages, 2 figures, 2 tables, updated to incorporate feedback",
      "pdf_url": "http://arxiv.org/pdf/2408.01527v2",
      "published_date": "2024-08-02 18:40:10 UTC",
      "updated_date": "2024-09-08 19:59:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T12:23:49.426907"
    },
    {
      "arxiv_id": "2408.01517v1",
      "title": "Gradient flow in parameter space is equivalent to linear interpolation in output space",
      "title_zh": "参数空间中的梯度流等价于输出空间中的线性插值",
      "authors": [
        "Thomas Chen",
        "Patrícia Muñoz Ewald"
      ],
      "abstract": "We prove that the usual gradient flow in parameter space that underlies many\ntraining algorithms for neural networks in deep learning can be continuously\ndeformed into an adapted gradient flow which yields (constrained) Euclidean\ngradient flow in output space. Moreover, if the Jacobian of the outputs with\nrespect to the parameters is full rank (for fixed training data), then the time\nvariable can be reparametrized so that the resulting flow is simply linear\ninterpolation, and a global minimum can be achieved.",
      "tldr_zh": "该论文证明了神经网络训练中的gradient flow在参数空间可以连续变形为输出空间的Euclidean gradient flow，从而实现对训练过程的优化。如果输出相对于参数的Jacobian是满秩的，则可以通过重新参数化时间变量，使gradient flow等价于linear interpolation，并能达到全局最小。这一发现为深度学习算法提供了新的理论基础，提升了训练效率和可解释性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "math-ph",
        "math.MP",
        "math.OC",
        "stat.ML",
        "62M45, 37C10"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.01517v1",
      "published_date": "2024-08-02 18:23:17 UTC",
      "updated_date": "2024-08-02 18:23:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T12:23:59.354738"
    },
    {
      "arxiv_id": "2408.01423v1",
      "title": "Prompt Recursive Search: A Living Framework with Adaptive Growth in LLM Auto-Prompting",
      "title_zh": "翻译失败",
      "authors": [
        "Xiangyu Zhao",
        "Chengqian Ma"
      ],
      "abstract": "Large Language Models (LLMs) exhibit remarkable proficiency in addressing a\ndiverse array of tasks within the Natural Language Processing (NLP) domain,\nwith various prompt design strategies significantly augmenting their\ncapabilities. However, these prompts, while beneficial, each possess inherent\nlimitations. The primary prompt design methodologies are twofold: The first,\nexemplified by the Chain of Thought (CoT), involves manually crafting prompts\nspecific to individual datasets, hence termed Expert-Designed Prompts (EDPs).\nOnce these prompts are established, they are unalterable, and their\neffectiveness is capped by the expertise of the human designers. When applied\nto LLMs, the static nature of EDPs results in a uniform approach to both simple\nand complex problems within the same dataset, leading to the inefficient use of\ntokens for straightforward issues. The second method involves prompts\nautonomously generated by the LLM, known as LLM-Derived Prompts (LDPs), which\nprovide tailored solutions to specific problems, mitigating the limitations of\nEDPs. However, LDPs may encounter a decline in performance when tackling\ncomplex problems due to the potential for error accumulation during the\nsolution planning process. To address these challenges, we have conceived a\nnovel Prompt Recursive Search (PRS) framework that leverages the LLM to\ngenerate solutions specific to the problem, thereby conserving tokens. The\nframework incorporates an assessment of problem complexity and an adjustable\nstructure, ensuring a reduction in the likelihood of errors. We have\nsubstantiated the efficacy of PRS framework through extensive experiments using\nLLMs with different numbers of parameters across a spectrum of datasets in\nvarious domains. Compared to the CoT method, the PRS method has increased the\naccuracy on the BBH dataset by 8% using Llama3-7B model, achieving a 22%\nimprovement.",
      "tldr_zh": "该论文针对 Large Language Models (LLMs) 的提示设计问题，分析了 Expert-Designed Prompts (EDPs) 的静态局限性和 LLM-Derived Prompts (LDPs) 的错误积累风险，提出了一种新型 Prompt Recursive Search (PRS) 框架。该框架利用 LLM 生成问题特定提示、评估问题复杂度和动态调整结构，从而节省 tokens 并降低错误发生概率。通过广泛实验验证，PRS 在不同参数规模的 LLMs 和多种数据集上表现出色，例如在 BBH 数据集上，使用 Llama3-7B 模型比 Chain of Thought (CoT) 方法提高了 8% 的准确率，并实现了总体 22% 的改进。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "8 pages,4 figures",
      "pdf_url": "http://arxiv.org/pdf/2408.01423v1",
      "published_date": "2024-08-02 17:59:42 UTC",
      "updated_date": "2024-08-02 17:59:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T12:24:14.935990"
    },
    {
      "arxiv_id": "2408.01420v1",
      "title": "Mission Impossible: A Statistical Perspective on Jailbreaking LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Jingtong Su",
        "Julia Kempe",
        "Karen Ullrich"
      ],
      "abstract": "Large language models (LLMs) are trained on a deluge of text data with\nlimited quality control. As a result, LLMs can exhibit unintended or even\nharmful behaviours, such as leaking information, fake news or hate speech.\nCountermeasures, commonly referred to as preference alignment, include\nfine-tuning the pretrained LLMs with carefully crafted text examples of desired\nbehaviour. Even then, empirical evidence shows preference aligned LLMs can be\nenticed to harmful behaviour. This so called jailbreaking of LLMs is typically\nachieved by adversarially modifying the input prompt to the LLM. Our paper\nprovides theoretical insights into the phenomenon of preference alignment and\njailbreaking from a statistical perspective. Under our framework, we first show\nthat pretrained LLMs will mimic harmful behaviour if present in the training\ncorpus. Under that same framework, we then introduce a statistical notion of\nalignment, and lower-bound the jailbreaking probability, showing that it is\nunpreventable under reasonable assumptions. Based on our insights, we propose\nan alteration to the currently prevalent alignment strategy RLHF. Specifically,\nwe introduce a simple modification to the RLHF objective, we call E-RLHF, that\naims to increase the likelihood of safe responses. E-RLHF brings no additional\ntraining cost, and is compatible with other methods. Empirically, we\ndemonstrate that E-RLHF outperforms RLHF on all alignment problems put forward\nby the AdvBench and HarmBench project without sacrificing model performance as\nmeasured by the MT-Bench project.",
      "tldr_zh": "该论文从统计视角分析了大语言模型（LLMs）的偏好对齐（preference alignment）和越狱（jailbreaking）现象，揭示了预训练LLMs会模仿训练语料中的有害行为，如信息泄露、假新闻或仇恨言论。作者引入了一个统计框架，证明即使经过偏好对齐，越狱概率在合理假设下仍是不可避免的。基于此，他们提出了一种改进的强化学习从人类反馈（RLHF）方法，名为E-RLHF，通过简单修改目标函数来提升安全响应概率，而不增加训练成本。实验结果显示，E-RLHF在AdvBench和HarmBench的对齐问题上优于标准RLHF，同时在MT-Bench上保持了模型性能。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.01420v1",
      "published_date": "2024-08-02 17:55:50 UTC",
      "updated_date": "2024-08-02 17:55:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T12:24:24.744136"
    },
    {
      "arxiv_id": "2408.01417v1",
      "title": "Talk Less, Interact Better: Evaluating In-context Conversational Adaptation in Multimodal LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Yilun Hua",
        "Yoav Artzi"
      ],
      "abstract": "Humans spontaneously use increasingly efficient language as interactions\nprogress, by adapting and forming ad-hoc conventions. This phenomenon has been\nstudied extensively using reference games, showing properties of human language\nthat go beyond relaying intents. It remains unexplored whether multimodal large\nlanguage models (MLLMs) similarly increase communication efficiency during\ninteractions, and what mechanisms they may adopt for this purpose. We introduce\nICCA, an automated framework to evaluate such conversational adaptation as an\nin-context behavior in MLLMs. We evaluate several state-of-the-art MLLMs, and\nobserve that while they may understand the increasingly efficient language of\ntheir interlocutor, they do not spontaneously make their own language more\nefficient over time. This latter ability can only be elicited in some models\n(e.g., GPT-4) with heavy-handed prompting. This shows that this property of\nlinguistic interaction does not arise from current training regimes, even\nthough it is a common hallmark of human language. ICCA is available at\nhttps://github.com/lil-lab/ICCA.",
      "tldr_zh": "该研究探讨了多模态大型语言模型（Multimodal LLMs）在互动中是否能像人类一样自发提高语言效率，通过适应和形成临时约定。研究者引入了ICCA框架，这是一个自动评估工具，用于测试MLLMs的in-context conversational adaptation行为。实验结果显示，多数MLLMs能够理解对话者的更高效语言，但不会主动使自身语言更简洁高效；只有某些模型（如GPT-4）在强有力的提示下才能表现出这种能力。这表明，这种人类语言的典型特征并未从当前训练机制中自然产生，ICCA框架已开源在GitHub上以供进一步研究。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to COLM 2024",
      "pdf_url": "http://arxiv.org/pdf/2408.01417v1",
      "published_date": "2024-08-02 17:51:57 UTC",
      "updated_date": "2024-08-02 17:51:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T12:24:36.978843"
    },
    {
      "arxiv_id": "2408.01416v1",
      "title": "The Quest for the Right Mediator: A History, Survey, and Theoretical Grounding of Causal Interpretability",
      "title_zh": "对正确中介的追求：因果可解释性的历史、调查和理论基础",
      "authors": [
        "Aaron Mueller",
        "Jannik Brinkmann",
        "Millicent Li",
        "Samuel Marks",
        "Koyena Pal",
        "Nikhil Prakash",
        "Can Rager",
        "Aruna Sankaranarayanan",
        "Arnab Sen Sharma",
        "Jiuding Sun",
        "Eric Todd",
        "David Bau",
        "Yonatan Belinkov"
      ],
      "abstract": "Interpretability provides a toolset for understanding how and why neural\nnetworks behave in certain ways. However, there is little unity in the field:\nmost studies employ ad-hoc evaluations and do not share theoretical\nfoundations, making it difficult to measure progress and compare the pros and\ncons of different techniques. Furthermore, while mechanistic understanding is\nfrequently discussed, the basic causal units underlying these mechanisms are\noften not explicitly defined. In this paper, we propose a perspective on\ninterpretability research grounded in causal mediation analysis. Specifically,\nwe describe the history and current state of interpretability taxonomized\naccording to the types of causal units (mediators) employed, as well as methods\nused to search over mediators. We discuss the pros and cons of each mediator,\nproviding insights as to when particular kinds of mediators and search methods\nare most appropriate depending on the goals of a given study. We argue that\nthis framing yields a more cohesive narrative of the field, as well as\nactionable insights for future work. Specifically, we recommend a focus on\ndiscovering new mediators with better trade-offs between human-interpretability\nand compute-efficiency, and which can uncover more sophisticated abstractions\nfrom neural networks than the primarily linear mediators employed in current\nwork. We also argue for more standardized evaluations that enable principled\ncomparisons across mediator types, such that we can better understand when\nparticular causal units are better suited to particular use cases.",
      "tldr_zh": "这篇论文审视了神经网络解释性研究的碎片化问题，提出了一种基于因果中介分析（causal mediation analysis）的理论框架，以统一该领域。论文回顾了解释性研究的历史和现状，并按因果单位（mediators）的类型（如线性中介）和搜索方法进行分类，讨论了每种中介的优缺点，以指导其在不同研究目标下的适用性。主要贡献包括为未来工作提供行动性建议：聚焦于开发新中介，以平衡人类可解释性和计算效率，并推动标准化评估来比较不同中介类型，从而更好地适应特定应用场景。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.01416v1",
      "published_date": "2024-08-02 17:51:42 UTC",
      "updated_date": "2024-08-02 17:51:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T12:24:48.321834"
    },
    {
      "arxiv_id": "2408.01415v1",
      "title": "Conditional LoRA Parameter Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Xiaolong Jin",
        "Kai Wang",
        "Dongwen Tang",
        "Wangbo Zhao",
        "Yukun Zhou",
        "Junshu Tang",
        "Yang You"
      ],
      "abstract": "Generative models have achieved remarkable success in image, video, and text\ndomains. Inspired by this, researchers have explored utilizing generative\nmodels to generate neural network parameters. However, these efforts have been\nlimited by the parameter size and the practicality of generating\nhigh-performance parameters. In this paper, we propose COND P-DIFF, a novel\napproach that demonstrates the feasibility of controllable high-performance\nparameter generation, particularly for LoRA (Low-Rank Adaptation) weights,\nduring the fine-tuning process. Specifically, we employ an autoencoder to\nextract efficient latent representations for parameters. We then train a\nconditional latent diffusion model to synthesize high-performing model\nparameters from random noise based on specific task conditions. Experimental\nresults in both computer vision and natural language processing domains\nconsistently demonstrate that COND P-DIFF can generate high-performance\nparameters conditioned on the given task. Moreover, we observe that the\nparameter distribution generated by COND P-DIFF exhibits differences compared\nto the distribution obtained through normal optimization methods, indicating a\ncertain level of generalization capability. Our work paves the way for further\nexploration of condition-driven parameter generation, offering a promising\ndirection for task-specific adaptation of neural networks.",
      "tldr_zh": "本研究提出COND P-DIFF，一种新颖方法，用于在微调过程中实现可控的高性能LoRA（Low-Rank Adaptation）参数生成。该方法利用autoencoder提取参数的潜在表示，然后训练conditional latent diffusion model从随机噪声中合成高性能参数，基于特定任务条件。实验在计算机视觉和自然语言处理领域显示，COND P-DIFF生成的参数表现出色，且其分布与传统优化方法不同，表明具备一定的泛化能力。该工作为条件驱动的参数生成开辟了新路径，促进神经网络的任务特定适应。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.01415v1",
      "published_date": "2024-08-02 17:43:34 UTC",
      "updated_date": "2024-08-02 17:43:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T12:24:59.893398"
    },
    {
      "arxiv_id": "2408.01402v1",
      "title": "Pre-trained Language Models Improve the Few-shot Prompt Ability of Decision Transformer",
      "title_zh": "预训练语言模型提升 Decision Transformer 的少样本提示能力",
      "authors": [
        "Yu Yang",
        "Pan Xu"
      ],
      "abstract": "Decision Transformer (DT) has emerged as a promising class of algorithms in\noffline reinforcement learning (RL) tasks, leveraging pre-collected datasets\nand Transformer's capability to model long sequences. Recent works have\ndemonstrated that using parts of trajectories from training tasks as prompts in\nDT enhances its performance on unseen tasks, giving rise to Prompt-DT methods.\nHowever, collecting data from specific environments can be both costly and\nunsafe in many scenarios, leading to suboptimal performance and limited\nfew-shot prompt abilities due to the data-hungry nature of Transformer-based\nmodels. Additionally, the limited datasets used in pre-training make it\nchallenging for Prompt-DT type of methods to distinguish between various RL\ntasks through prompts alone. To address these challenges, we introduce the\nLanguage model-initialized Prompt Decision Transformer (LPDT), which leverages\npre-trained language models for meta-RL tasks and fine-tunes the model using\nLow-rank Adaptation (LoRA). We further incorporate prompt regularization to\neffectively differentiate between tasks based on prompt feature\nrepresentations. Our approach integrates pre-trained language model and RL\ntasks seamlessly. Extensive empirical studies demonstrate that initializing\nwith a pre-trained language model significantly enhances the performance of\nPrompt-DT on unseen tasks compared to baseline methods.",
      "tldr_zh": "本研究针对 Decision Transformer (DT) 在离线 reinforcement learning (RL) 任务中的局限性，特别是 Prompt-DT 方法因数据收集成本高和模型数据饥饿而导致的少样本提示能力不足和任务区分困难。研究提出 Language model-initialized Prompt Decision Transformer (LPDT)，通过利用预训练语言模型进行初始化，并结合 Low-rank Adaptation (LoRA) 微调以及提示正则化，来提升模型对未见任务的适应性。实验结果显示，与基线方法相比，LPDT 显著提高了 Prompt-DT 在少样本场景下的性能，为高效的元强化学习(meta-RL) 任务提供了新途径。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "2 figures, 8 tables. Accepted by the Training Agents with Foundation\n  Models Workshop at RLC 2024",
      "pdf_url": "http://arxiv.org/pdf/2408.01402v1",
      "published_date": "2024-08-02 17:25:34 UTC",
      "updated_date": "2024-08-02 17:25:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T12:25:12.089957"
    },
    {
      "arxiv_id": "2408.03866v2",
      "title": "A semantic approach to mapping the Provenance Ontology to Basic Formal Ontology",
      "title_zh": "翻译失败",
      "authors": [
        "Tim Prudhomme",
        "Giacomo De Colle",
        "Austin Liebers",
        "Alec Sculley",
        "Peihong \"Karl\" Xie",
        "Sydney Cohen",
        "John Beverley"
      ],
      "abstract": "The Provenance Ontology (PROV-O) is a World Wide Web Consortium (W3C)\nrecommended ontology used to structure data about provenance across a wide\nvariety of domains. Basic Formal Ontology (BFO) is a top-level ontology ISO/IEC\nstandard used to structure a wide variety of ontologies, such as the OBO\nFoundry ontologies and the Common Core Ontologies (CCO). To enhance\ninteroperability between these two ontologies, their extensions, and data\norganized by them, a mapping methodology and set of alignments are presented\naccording to specific criteria which prioritize semantic and logical\nprinciples. The ontology alignments are evaluated by checking their logical\nconsistency with canonical examples of PROV-O instances and querying terms that\ndo not satisfy the alignment criteria as formalized in SPARQL. A variety of\nsemantic web technologies are used in support of FAIR (Findable, Accessible,\nInteroperable, Reusable) principles.",
      "tldr_zh": "该研究提出了一种语义方法，将 Provenance Ontology (PROV-O) 映射到 Basic Formal Ontology (BFO)，以提高这两个本体及其扩展之间的互操作性。映射方法基于优先考虑语义和逻辑原则的标准，呈现了一套本体对齐 (alignments)。这些对齐通过检查 PROV-O 实例的逻辑一致性和使用 SPARQL 查询不满足标准的术语来评估，并利用各种语义网技术支持 FAIR (Findable, Accessible, Interoperable, Reusable) 原则。",
      "categories": [
        "cs.DB",
        "cs.AI",
        "cs.LO"
      ],
      "primary_category": "cs.DB",
      "comment": "31 pages, 12 figures. This version of the article has been accepted\n  for publication, after peer review (when applicable) but is not the Version\n  of Record and does not reflect post-acceptance improvements, or any\n  corrections. The Version of Record is available online at:\n  https://doi.org/10.1038/s41597-025-04580-1",
      "pdf_url": "http://arxiv.org/pdf/2408.03866v2",
      "published_date": "2024-08-02 16:50:17 UTC",
      "updated_date": "2025-03-23 17:23:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T12:25:24.978737"
    },
    {
      "arxiv_id": "2408.01349v1",
      "title": "PC$^2$: Pseudo-Classification Based Pseudo-Captioning for Noisy Correspondence Learning in Cross-Modal Retrieval",
      "title_zh": "翻译失败",
      "authors": [
        "Yue Duan",
        "Zhangxuan Gu",
        "Zhenzhe Ying",
        "Lei Qi",
        "Changhua Meng",
        "Yinghuan Shi"
      ],
      "abstract": "In the realm of cross-modal retrieval, seamlessly integrating diverse\nmodalities within multimedia remains a formidable challenge, especially given\nthe complexities introduced by noisy correspondence learning (NCL). Such noise\noften stems from mismatched data pairs, which is a significant obstacle\ndistinct from traditional noisy labels. This paper introduces\nPseudo-Classification based Pseudo-Captioning (PC$^2$) framework to address\nthis challenge. PC$^2$ offers a threefold strategy: firstly, it establishes an\nauxiliary \"pseudo-classification\" task that interprets captions as categorical\nlabels, steering the model to learn image-text semantic similarity through a\nnon-contrastive mechanism. Secondly, unlike prevailing margin-based techniques,\ncapitalizing on PC$^2$'s pseudo-classification capability, we generate\npseudo-captions to provide more informative and tangible supervision for each\nmismatched pair. Thirdly, the oscillation of pseudo-classification is borrowed\nto assistant the correction of correspondence. In addition to technical\ncontributions, we develop a realistic NCL dataset called Noise of Web (NoW),\nwhich could be a new powerful NCL benchmark where noise exists naturally.\nEmpirical evaluations of PC$^2$ showcase marked improvements over existing\nstate-of-the-art robust cross-modal retrieval techniques on both simulated and\nrealistic datasets with various NCL settings. The contributed dataset and\nsource code are released at https://github.com/alipay/PC2-NoiseofWeb.",
      "tldr_zh": "这篇论文提出了 PC² 框架，用于解决跨模态检索中的 Noisy Correspondence Learning (NCL) 问题，特别是由不匹配数据对引发的噪音。PC² 通过三重策略，包括辅助的 pseudo-classification 任务来学习图像-文本语义相似性、生成 pseudo-captions 提供更具信息性的监督，以及利用 pseudo-classification 的波动来修正对应关系。研究者还开发了新的真实 NCL 数据集 Noise of Web (NoW) 作为基准，并实验证明 PC² 在模拟和真实数据集上显著优于现有最先进技术。",
      "categories": [
        "cs.MM",
        "cs.AI",
        "cs.CV",
        "cs.IR",
        "cs.LG"
      ],
      "primary_category": "cs.MM",
      "comment": "Accepted by ACM MM 2024",
      "pdf_url": "http://arxiv.org/pdf/2408.01349v1",
      "published_date": "2024-08-02 15:54:49 UTC",
      "updated_date": "2024-08-02 15:54:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T12:25:38.071820"
    },
    {
      "arxiv_id": "2408.01343v1",
      "title": "StitchFusion: Weaving Any Visual Modalities to Enhance Multimodal Semantic Segmentation",
      "title_zh": "StitchFusion：编织任意视觉模态以增强多模态语义分割",
      "authors": [
        "Bingyu Li",
        "Da Zhang",
        "Zhiyuan Zhao",
        "Junyu Gao",
        "Xuelong Li"
      ],
      "abstract": "Multimodal semantic segmentation shows significant potential for enhancing\nsegmentation accuracy in complex scenes. However, current methods often\nincorporate specialized feature fusion modules tailored to specific modalities,\nthereby restricting input flexibility and increasing the number of training\nparameters. To address these challenges, we propose StitchFusion, a\nstraightforward yet effective modal fusion framework that integrates\nlarge-scale pre-trained models directly as encoders and feature fusers. This\napproach facilitates comprehensive multi-modal and multi-scale feature fusion,\naccommodating any visual modal inputs. Specifically, Our framework achieves\nmodal integration during encoding by sharing multi-modal visual information. To\nenhance information exchange across modalities, we introduce a\nmulti-directional adapter module (MultiAdapter) to enable cross-modal\ninformation transfer during encoding. By leveraging MultiAdapter to propagate\nmulti-scale information across pre-trained encoders during the encoding\nprocess, StitchFusion achieves multi-modal visual information integration\nduring encoding. Extensive comparative experiments demonstrate that our model\nachieves state-of-the-art performance on four multi-modal segmentation datasets\nwith minimal additional parameters. Furthermore, the experimental integration\nof MultiAdapter with existing Feature Fusion Modules (FFMs) highlights their\ncomplementary nature. Our code is available at StitchFusion_repo.",
      "tldr_zh": "该研究针对多模态语义分割中的问题，提出StitchFusion框架，该框架通过直接整合大型预训练模型作为编码器和特征融合器，实现任意视觉模态的灵活融合，从而减少训练参数并提升输入适应性。具体而言，StitchFusion引入MultiAdapter模块，在编码过程中实现多向跨模态信息传输和多尺度特征融合。实验结果显示，该模型在四个多模态分割数据集上达到最先进性能，仅需最少额外参数，且MultiAdapter与现有Feature Fusion Modules (FFMs)具有互补效果。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.01343v1",
      "published_date": "2024-08-02 15:41:16 UTC",
      "updated_date": "2024-08-02 15:41:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T12:25:48.893038"
    },
    {
      "arxiv_id": "2408.01342v1",
      "title": "Leveraging Knowledge Graph Embedding for Effective Conversational Recommendation",
      "title_zh": "利用知识图谱嵌入实现有效的对话式推荐",
      "authors": [
        "Yunwen Xia",
        "Hui Fang",
        "Jie Zhang",
        "Chong Long"
      ],
      "abstract": "Conversational recommender system (CRS), which combines the techniques of\ndialogue system and recommender system, has obtained increasing interest\nrecently. In contrast to traditional recommender system, it learns the user\npreference better through interactions (i.e. conversations), and then further\nboosts the recommendation performance. However, existing studies on CRS ignore\nto address the relationship among attributes, users, and items effectively,\nwhich might lead to inappropriate questions and inaccurate recommendations. In\nthis view, we propose a knowledge graph based conversational recommender system\n(referred as KG-CRS). Specifically, we first integrate the user-item graph and\nitem-attribute graph into a dynamic graph, i.e., dynamically changing during\nthe dialogue process by removing negative items or attributes. We then learn\ninformative embedding of users, items, and attributes by also considering\npropagation through neighbors on the graph. Extensive experiments on three real\ndatasets validate the superiority of our method over the state-of-the-art\napproaches in terms of both the recommendation and conversation tasks.",
      "tldr_zh": "该论文针对对话推荐系统（Conversational Recommender System, CRS），通过整合对话系统和推荐系统技术来更好地学习用户偏好，但指出现有方法忽略了属性、用户和物品之间的关系，导致推荐不准确。作者提出了一种基于知识图的对话推荐系统（KG-CRS），将用户-物品图和物品-属性图整合成一个动态图，并在对话过程中动态更新（如移除负面物品或属性），并通过图上的邻居传播学习用户、物品和属性的信息嵌入。实验在三个真实数据集上验证了KG-CRS在推荐和对话任务上的优越性，显著提升了系统性能。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "26pages, 15figures",
      "pdf_url": "http://arxiv.org/pdf/2408.01342v1",
      "published_date": "2024-08-02 15:38:55 UTC",
      "updated_date": "2024-08-02 15:38:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T12:26:00.310210"
    },
    {
      "arxiv_id": "2408.01334v3",
      "title": "A Backbone for Long-Horizon Robot Task Understanding",
      "title_zh": "翻译失败",
      "authors": [
        "Xiaoshuai Chen",
        "Wei Chen",
        "Dongmyoung Lee",
        "Yukun Ge",
        "Nicolas Rojas",
        "Petar Kormushev"
      ],
      "abstract": "End-to-end robot learning, particularly for long-horizon tasks, often results\nin unpredictable outcomes and poor generalization. To address these challenges,\nwe propose a novel Therblig-Based Backbone Framework (TBBF) as a fundamental\nstructure to enhance interpretability, data efficiency, and generalization in\nrobotic systems. TBBF utilizes expert demonstrations to enable therblig-level\ntask decomposition, facilitate efficient action-object mapping, and generate\nadaptive trajectories for new scenarios. The approach consists of two stages:\noffline training and online testing. During the offline training stage, we\ndeveloped the Meta-RGate SynerFusion (MGSF) network for accurate therblig\nsegmentation across various tasks. In the online testing stage, after a\none-shot demonstration of a new task is collected, our MGSF network extracts\nhigh-level knowledge, which is then encoded into the image using Action\nRegistration (ActionREG). Additionally, Large Language Model (LLM)-Alignment\nPolicy for Visual Correction (LAP-VC) is employed to ensure precise action\nregistration, facilitating trajectory transfer in novel robot scenarios.\nExperimental results validate these methods, achieving 94.37% recall in\ntherblig segmentation and success rates of 94.4% and 80% in real-world online\nrobot testing for simple and complex scenarios, respectively. Supplementary\nmaterial is available at:\nhttps://sites.google.com/view/therbligsbasedbackbone/home",
      "tldr_zh": "本研究提出 Therblig-Based Backbone Framework (TBBF)，作为一种基础结构，用于提升机器人系统在长时域任务中的可解释性、数据效率和泛化能力。框架通过专家演示实现 therblig-level 任务分解，包括离线训练阶段的 Meta-RGate SynerFusion (MGSF) 网络用于精确 therblig 分段，以及在线测试阶段的 Action Registration (ActionREG) 和 Large Language Model (LLM)-Alignment Policy for Visual Correction (LAP-VC) 来支持动作映射和轨迹适应。实验结果显示，therblig 分段 recall 达到 94.37%，在真实世界测试中，简单场景成功率达 94.4%，复杂场景为 80%。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV",
        "cs.HC"
      ],
      "primary_category": "cs.RO",
      "comment": "8 pages, 8 figures. This work has been published by IEEE Robotics and\n  Automation Letters (RA-L)",
      "pdf_url": "http://arxiv.org/pdf/2408.01334v3",
      "published_date": "2024-08-02 15:32:42 UTC",
      "updated_date": "2025-03-06 11:59:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T12:26:13.763032"
    },
    {
      "arxiv_id": "2408.01322v3",
      "title": "A Robotics-Inspired Scanpath Model Reveals the Importance of Uncertainty and Semantic Object Cues for Gaze Guidance in Dynamic Scenes",
      "title_zh": "翻译失败",
      "authors": [
        "Vito Mengers",
        "Nicolas Roth",
        "Oliver Brock",
        "Klaus Obermayer",
        "Martin Rolfs"
      ],
      "abstract": "The objects we perceive guide our eye movements when observing real-world\ndynamic scenes. Yet, gaze shifts and selective attention are critical for\nperceiving details and refining object boundaries. Object segmentation and gaze\nbehavior are, however, typically treated as two independent processes. Here, we\npresent a computational model that simulates these processes in an\ninterconnected manner and allows for hypothesis-driven investigations of\ndistinct attentional mechanisms. Drawing on an information processing pattern\nfrom robotics, we use a Bayesian filter to recursively segment the scene, which\nalso provides an uncertainty estimate for the object boundaries that we use to\nguide active scene exploration. We demonstrate that this model closely\nresembles observers' free viewing behavior on a dataset of dynamic real-world\nscenes, measured by scanpath statistics, including foveation duration and\nsaccade amplitude distributions used for parameter fitting and higher-level\nstatistics not used for fitting. These include how object detections,\ninspections, and returns are balanced and a delay of returning saccades without\nan explicit implementation of such temporal inhibition of return. Extensive\nsimulations and ablation studies show that uncertainty promotes balanced\nexploration and that semantic object cues are crucial to forming the perceptual\nunits used in object-based attention. Moreover, we show how our model's modular\ndesign allows for extensions, such as incorporating saccadic momentum or\npre-saccadic attention, to further align its output with human scanpaths.",
      "tldr_zh": "本研究提出一个受机器人启发的计算模型，用于模拟人类在动态场景中的注视行为（scanpath），强调不确定性（uncertainty）和语义物体线索（semantic object cues）对注视引导的重要性。模型使用 Bayesian filter 递归分割场景，并基于物体边界的不确定性估计来指导主动探索，从而将物体分割和注视行为整合为互联过程。实验结果显示，该模型在真实动态场景数据集上，与人类自由注视行为高度一致，包括注视持续时间（foveation duration）、扫视振幅（saccade amplitude）等统计指标，以及未用于参数拟合的高级统计，如物体检测、检查和返回的平衡。进一步的模拟和消融研究证明，不确定性促进探索平衡，而语义物体线索是形成物体基于注意力的关键单元，且模型的模块化设计允许扩展，如加入扫视动量（saccadic momentum）以更好地匹配人类注视路径。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "q-bio.NC"
      ],
      "primary_category": "cs.CV",
      "comment": "40+25 pages, 8+7 figures",
      "pdf_url": "http://arxiv.org/pdf/2408.01322v3",
      "published_date": "2024-08-02 15:20:34 UTC",
      "updated_date": "2025-02-11 11:18:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T12:26:24.962824"
    },
    {
      "arxiv_id": "2408.01319v1",
      "title": "A Comprehensive Review of Multimodal Large Language Models: Performance and Challenges Across Different Tasks",
      "title_zh": "多模态大型语言模型的全面综述：不同任务中的性能和挑战",
      "authors": [
        "Jiaqi Wang",
        "Hanqi Jiang",
        "Yiheng Liu",
        "Chong Ma",
        "Xu Zhang",
        "Yi Pan",
        "Mengyuan Liu",
        "Peiran Gu",
        "Sichen Xia",
        "Wenjun Li",
        "Yutong Zhang",
        "Zihao Wu",
        "Zhengliang Liu",
        "Tianyang Zhong",
        "Bao Ge",
        "Tuo Zhang",
        "Ning Qiang",
        "Xintao Hu",
        "Xi Jiang",
        "Xin Zhang",
        "Wei Zhang",
        "Dinggang Shen",
        "Tianming Liu",
        "Shu Zhang"
      ],
      "abstract": "In an era defined by the explosive growth of data and rapid technological\nadvancements, Multimodal Large Language Models (MLLMs) stand at the forefront\nof artificial intelligence (AI) systems. Designed to seamlessly integrate\ndiverse data types-including text, images, videos, audio, and physiological\nsequences-MLLMs address the complexities of real-world applications far beyond\nthe capabilities of single-modality systems. In this paper, we systematically\nsort out the applications of MLLM in multimodal tasks such as natural language,\nvision, and audio. We also provide a comparative analysis of the focus of\ndifferent MLLMs in the tasks, and provide insights into the shortcomings of\ncurrent MLLMs, and suggest potential directions for future research. Through\nthese discussions, this paper hopes to provide valuable insights for the\nfurther development and application of MLLM.",
      "tldr_zh": "本论文对Multimodal Large Language Models (MLLMs)进行全面综述，探讨了这些模型在整合文本、图像、视频、音频和生理序列等多样数据类型方面的性能和应用，超越了单模态系统的局限性。作者系统整理了MLLMs在自然语言、视觉和音频等多模态任务中的表现，并通过比较分析揭示了不同模型的重点。论文还指出了当前MLLMs的不足，如领域挑战，并提出未来研究方向，以推动其进一步发展和实际应用。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.01319v1",
      "published_date": "2024-08-02 15:14:53 UTC",
      "updated_date": "2024-08-02 15:14:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T12:26:36.366407"
    },
    {
      "arxiv_id": "2408.01316v1",
      "title": "Synergistic pathways of modulation enable robust task packing within neural dynamics",
      "title_zh": "翻译失败",
      "authors": [
        "Giacomo Vedovati",
        "ShiNung Ching"
      ],
      "abstract": "Understanding how brain networks learn and manage multiple tasks\nsimultaneously is of interest in both neuroscience and artificial intelligence.\nIn this regard, a recent research thread in theoretical neuroscience has\nfocused on how recurrent neural network models and their internal dynamics\nenact multi-task learning. To manage different tasks requires a mechanism to\nconvey information about task identity or context into the model, which from a\nbiological perspective may involve mechanisms of neuromodulation. In this\nstudy, we use recurrent network models to probe the distinctions between two\nforms of contextual modulation of neural dynamics, at the level of neuronal\nexcitability and at the level of synaptic strength. We characterize these\nmechanisms in terms of their functional outcomes, focusing on their robustness\nto context ambiguity and, relatedly, their efficiency with respect to packing\nmultiple tasks into finite size networks. We also demonstrate distinction\nbetween these mechanisms at the level of the neuronal dynamics they induce.\nTogether, these characterizations indicate complementarity and synergy in how\nthese mechanisms act, potentially over multiple time-scales, toward enhancing\nrobustness of multi-task learning.",
      "tldr_zh": "本研究探讨大脑网络如何同时学习和管理多个任务（multi-task learning），使用循环神经网络模型（recurrent neural network models）来模拟神经动态中的上下文调制机制。论文比较了两种神经调制形式：一种影响神经元兴奋性（neuronal excitability），另一种影响突触强度（synaptic strength），并评估它们在处理上下文模糊性（context ambiguity）时的鲁棒性（robustness）和多任务打包效率（task packing）。结果表明，这两种机制互补且协同作用，能够在有限规模网络中增强多任务学习的稳健性，并可能涉及多个时间尺度。",
      "categories": [
        "q-bio.NC",
        "cs.AI"
      ],
      "primary_category": "q-bio.NC",
      "comment": "24 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2408.01316v1",
      "published_date": "2024-08-02 15:12:01 UTC",
      "updated_date": "2024-08-02 15:12:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T12:26:48.622486"
    },
    {
      "arxiv_id": "2408.01301v1",
      "title": "A Decision-driven Methodology for Designing Uncertainty-aware AI Self-Assessment",
      "title_zh": "翻译失败",
      "authors": [
        "Gregory Canal",
        "Vladimir Leung",
        "Philip Sage",
        "Eric Heim",
        "I-Jeng Wang"
      ],
      "abstract": "Artificial intelligence (AI) has revolutionized decision-making processes and\nsystems throughout society and, in particular, has emerged as a significant\ntechnology in high-impact scenarios of national interest. Yet, despite AI's\nimpressive predictive capabilities in controlled settings, it still suffers\nfrom a range of practical setbacks preventing its widespread use in various\ncritical scenarios. In particular, it is generally unclear if a given AI\nsystem's predictions can be trusted by decision-makers in downstream\napplications. To address the need for more transparent, robust, and trustworthy\nAI systems, a suite of tools has been developed to quantify the uncertainty of\nAI predictions and, more generally, enable AI to \"self-assess\" the reliability\nof its predictions. In this manuscript, we categorize methods for AI\nself-assessment along several key dimensions and provide guidelines for\nselecting and designing the appropriate method for a practitioner's needs. In\nparticular, we focus on uncertainty estimation techniques that consider the\nimpact of self-assessment on the choices made by downstream decision-makers and\non the resulting costs and benefits of decision outcomes. To demonstrate the\nutility of our methodology for self-assessment design, we illustrate its use\nfor two realistic national-interest scenarios. This manuscript is a practical\nguide for machine learning engineers and AI system users to select the ideal\nself-assessment techniques for each problem.",
      "tldr_zh": "这篇论文提出了一种决策驱动的方法，用于设计能够评估自身预测不确定性的 AI 系统（uncertainty-aware AI self-assessment），以提升 AI 在高影响场景中的透明度和可信度。论文对 AI 自评估技术进行分类，并提供选择和设计指南，特别关注不确定性估计（uncertainty estimation）如何影响下游决策者的选择及决策结果的成本收益。通过两个实际的国家利益场景演示，该方法展示了其实用性，为机器学习工程师和 AI 系统用户提供了一个选择理想自评估技术的实用指南。",
      "categories": [
        "stat.ML",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "stat.ML",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.01301v1",
      "published_date": "2024-08-02 14:43:45 UTC",
      "updated_date": "2024-08-02 14:43:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T12:27:00.834533"
    },
    {
      "arxiv_id": "2408.01292v1",
      "title": "3DPX: Progressive 2D-to-3D Oral Image Reconstruction with Hybrid MLP-CNN Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Xiaoshuang Li",
        "Mingyuan Meng",
        "Zimo Huang",
        "Lei Bi",
        "Eduardo Delamare",
        "Dagan Feng",
        "Bin Sheng",
        "Jinman Kim"
      ],
      "abstract": "Panoramic X-ray (PX) is a prevalent modality in dental practice for its wide\navailability and low cost. However, as a 2D projection image, PX does not\ncontain 3D anatomical information, and therefore has limited use in dental\napplications that can benefit from 3D information, e.g., tooth angular\nmisa-lignment detection and classification. Reconstructing 3D structures\ndirectly from 2D PX has recently been explored to address limitations with\nexisting methods primarily reliant on Convolutional Neural Networks (CNNs) for\ndirect 2D-to-3D mapping. These methods, however, are unable to correctly infer\ndepth-axis spatial information. In addition, they are limited by the in-trinsic\nlocality of convolution operations, as the convolution kernels only capture the\ninformation of immediate neighborhood pixels. In this study, we propose a\nprogressive hybrid Multilayer Perceptron (MLP)-CNN pyra-mid network (3DPX) for\n2D-to-3D oral PX reconstruction. We introduce a progressive reconstruction\nstrategy, where 3D images are progressively re-constructed in the 3DPX with\nguidance imposed on the intermediate recon-struction result at each pyramid\nlevel. Further, motivated by the recent ad-vancement of MLPs that show promise\nin capturing fine-grained long-range dependency, our 3DPX integrates MLPs and\nCNNs to improve the semantic understanding during reconstruction. Extensive\nexperiments on two large datasets involving 464 studies demonstrate that our\n3DPX outperforms state-of-the-art 2D-to-3D oral reconstruction methods,\nincluding standalone MLP and transformers, in reconstruction quality, and also\nim-proves the performance of downstream angular misalignment classification\ntasks.",
      "tldr_zh": "本文提出3DPX，一种渐进式混合Multilayer Perceptron (MLP)-CNN网络，用于从2D全景X光(Panoramic X-ray, PX)图像重建3D口腔结构，以解决现有方法在深度信息推断和局部卷积限制上的不足。3DPX采用渐进重建策略，在金字塔级别的中间结果上施加指导，并结合MLP捕捉细粒度长距离依赖，提升语义理解和重建准确性。在两个大型数据集上的实验表明，3DPX在重建质量上优于现有CNN、MLP和Transformer方法，并显著提高了下游牙齿角度错位检测和分类任务的性能。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "accepted by MICCAI 2024",
      "pdf_url": "http://arxiv.org/pdf/2408.01292v1",
      "published_date": "2024-08-02 14:28:10 UTC",
      "updated_date": "2024-08-02 14:28:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T12:27:13.300095"
    },
    {
      "arxiv_id": "2408.01263v3",
      "title": "Designing the virtual CAT: A digital tool for algorithmic thinking assessment in compulsory education",
      "title_zh": "设计虚拟 CAT：一种用于义务教育的算法思维评估数字工具",
      "authors": [
        "Giorgia Adorni",
        "Alberto Piatti"
      ],
      "abstract": "Algorithmic thinking (AT) is a critical skill in today's digital society, and\nit is indispensable not only in computer science-related fields but also in\neveryday problem-solving. As a foundational component of digital education and\nliteracy, fostering AT skills is increasingly relevant for all students and\nshould become a standard part of compulsory education. However, successfully\nintegrating AT into formal education requires effective teaching strategies and\nrobust and scalable assessment procedures. In this paper, we present the design\nand development process of the virtual Cross Array Task (CAT), a digital\nadaptation of an unplugged assessment activity aimed at evaluating algorithmic\nskills in Swiss compulsory education. The development process followed\niterative design cycles, incorporating expert evaluations to refine the tool's\nusability, accessibility and functionality. A participatory design study played\na dual role in shaping the platform. First, it gathered valuable insights from\nend users, including students and teachers, to ensure the tool's relevance and\npracticality in classroom settings. Second, it facilitated the collection and\npreliminary analysis of data related to students' AT skills, providing an\ninitial evaluation of the tool's assessment capabilities across various\ndevelopmental stages. This was achieved through a pilot study involving a\ndiverse group of students aged 4 to 12, spanning preschool to lower secondary\nschool levels. The resulting instrument features multilingual support and\nincludes both gesture-based and visual block-based programming interfaces,\nmaking it accessible to a broad range of learners. Findings from the pilot\nstudy demonstrate the platform's usability and accessibility, as well as its\nsuitability for assessing AT skills, with preliminary results showing its\nability to cater to diverse age groups and educational contexts.",
      "tldr_zh": "本研究设计了virtual Cross Array Task (CAT)，一个数字工具，用于评估义务教育中学生的Algorithmic Thinking (AT)技能，以促进AT在数字教育中的整合。开发过程采用迭代设计循环，包括专家评估和参与式设计，从学生和教师反馈中优化工具的可用性、可访问性和功能，并通过试点研究收集数据。CAT支持多语言，并提供手势和视觉块式编程界面，适用于4-12岁学生；试点结果显示，该工具易用且有效，能适应不同年龄组和教育背景，初步证明其评估AT技能的潜力。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.01263v3",
      "published_date": "2024-08-02 13:36:17 UTC",
      "updated_date": "2024-11-26 17:05:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T12:27:23.963976"
    },
    {
      "arxiv_id": "2408.01257v1",
      "title": "Detection and Characterization of Coordinated Online Behavior: A Survey",
      "title_zh": "协调在线行为的检测与表征：综述",
      "authors": [
        "Lorenzo Mannocci",
        "Michele Mazza",
        "Anna Monreale",
        "Maurizio Tesconi",
        "Stefano Cresci"
      ],
      "abstract": "Coordination is a fundamental aspect of life. The advent of social media has\nmade it integral also to online human interactions, such as those that\ncharacterize thriving online communities and social movements. At the same\ntime, coordination is also core to effective disinformation, manipulation, and\nhate campaigns. This survey collects, categorizes, and critically discusses the\nbody of work produced as a result of the growing interest on coordinated online\nbehavior. We reconcile industry and academic definitions, propose a\ncomprehensive framework to study coordinated online behavior, and review and\ncritically discuss the existing detection and characterization methods. Our\nanalysis identifies open challenges and promising directions of research,\nserving as a guide for scholars, practitioners, and policymakers in\nunderstanding and addressing the complexities inherent to online coordination.",
      "tldr_zh": "这篇调查论文探讨了在线协调行为（coordinated online behavior）的检测和特征化，涵盖其在社交媒体中的双重作用，包括促进社区和社会运动以及助长虚假信息（disinformation）、操纵和仇恨活动。论文收集并分类了现有研究，统一了行业和学术定义，并提出一个全面框架来系统研究这种行为。作者审视并批判讨论了检测和特征化方法，同时识别了开放挑战和有前景的研究方向，为学者、从业者和政策制定者提供理解和应对在线协调的指导。",
      "categories": [
        "cs.SI",
        "cs.AI",
        "cs.CY",
        "cs.HC",
        "cs.LG"
      ],
      "primary_category": "cs.SI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.01257v1",
      "published_date": "2024-08-02 13:27:56 UTC",
      "updated_date": "2024-08-02 13:27:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T12:27:47.733762"
    },
    {
      "arxiv_id": "2408.01254v2",
      "title": "TrIM, Triangular Input Movement Systolic Array for Convolutional Neural Networks: Dataflow and Analytical Modelling",
      "title_zh": "TrIM，三角形输入运动脉动阵列用于卷积神经网络：数据流和分析建模",
      "authors": [
        "Cristian Sestito",
        "Shady Agwa",
        "Themis Prodromakis"
      ],
      "abstract": "In order to follow the ever-growing computational complexity and data\nintensity of state-of-the-art AI models, new computing paradigms are being\nproposed. These paradigms aim at achieving high energy efficiency, by\nmitigating the Von Neumann bottleneck that relates to the energy cost of moving\ndata between the processing cores and the memory. Convolutional Neural Networks\n(CNNs) are susceptible to this bottleneck, given the massive data they have to\nmanage. Systolic Arrays (SAs) are promising architectures to mitigate the data\ntransmission cost, thanks to high data utilization of Processing Elements\n(PEs). These PEs continuously exchange and process data locally based on\nspecific dataflows (like weight stationary and row stationary), in turn\nreducing the number of memory accesses to the main memory. In SAs, convolutions\nare managed either as matrix multiplications or exploiting the raster-order\nscan of sliding windows. However, data redundancy is a primary concern\naffecting area, power and energy. In this paper, we propose TrIM: a novel\ndataflow for SAs based on a Triangular Input Movement and compatible with CNN\ncomputing. TrIM maximizes the local input utilization, minimizes the weight\ndata movement and solves the data redundancy problem. Furthermore, TrIM does\nnot incur the significant on-chip memory penalty introduced by the row\nstationary dataflow. When compared to state-of-the-art SA dataflows the high\ndata utilization offered by TrIM guarantees ~10x less memory access.\nFurthermore, considering that PEs continuously overlap multiplications and\naccumulations, TrIM achieves high throughput (up to 81.8% higher than row\nstationary), other than requiring a limited number of registers (up to 15.6x\nfewer registers than row stationary).",
      "tldr_zh": "这篇论文提出了 TrIM，一种基于 Triangular Input Movement 的新型数据流，用于 Systolic Arrays 在 Convolutional Neural Networks (CNNs) 中的应用，旨在缓解 Von Neumann 瓶颈问题并减少数据冗余。TrIM 通过最大化本地输入利用、最小化权重数据移动，并避免 row stationary 数据流的 on-chip 内存开销，显著提升了数据处理效率。实验结果显示，TrIM 相比现有数据流减少约 10 倍内存访问、提高最高 81.8% 吞吐量，并降低最多 15.6 倍寄存器使用，为高效 CNN 计算提供了新范式。",
      "categories": [
        "cs.AI",
        "cs.AR"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.01254v2",
      "published_date": "2024-08-02 13:15:17 UTC",
      "updated_date": "2024-12-23 08:15:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T12:27:50.696744"
    },
    {
      "arxiv_id": "2408.01253v2",
      "title": "Metareasoning in uncertain environments: a meta-BAMDP framework",
      "title_zh": "不确定环境中的元推理：一个元-BAMDP 框架",
      "authors": [
        "Prakhar Godara",
        "Tilman Diego Aléman",
        "Angela J. Yu"
      ],
      "abstract": "\\textit{Reasoning} may be viewed as an algorithm $P$ that makes a choice of\nan action $a^* \\in \\mathcal{A}$, aiming to optimize some outcome. However,\nexecuting $P$ itself bears costs (time, energy, limited capacity, etc.) and\nneeds to be considered alongside explicit utility obtained by making the choice\nin the underlying decision problem. Finding the right $P$ can itself be framed\nas an optimization problem over the space of reasoning processes $P$, generally\nreferred to as \\textit{metareasoning}. Conventionally, human metareasoning\nmodels assume that the agent knows the transition and reward distributions of\nthe underlying MDP. This paper generalizes such models by proposing a meta\nBayes-Adaptive MDP (meta-BAMDP) framework to handle metareasoning in\nenvironments with unknown reward/transition distributions, which encompasses a\nfar larger and more realistic set of planning problems that humans and AI\nsystems face. As a first step, we apply the framework to Bernoulli bandit\ntasks. Owing to the meta problem's complexity, our solutions are necessarily\napproximate. However, we introduce two novel theorems that significantly\nenhance the tractability of the problem, enabling stronger approximations that\nare robust within a range of assumptions grounded in realistic human\ndecision-making scenarios. These results offer a resource-rational perspective\nand a normative framework for understanding human exploration under cognitive\nconstraints, as well as providing experimentally testable predictions about\nhuman behavior in Bernoulli Bandit tasks.",
      "tldr_zh": "这篇论文提出了meta-BAMDP框架，用于处理metareasoning在不确定环境中的应用，该框架将推理过程（reasoning）视为一个优化问题，同时考虑执行推理的成本，如时间和能量。不同于传统模型假设已知MDP的过渡和奖励分布，meta-BAMDP扩展到未知分布的场景，提供更广泛的规划问题解决方案。作者首先将其应用于Bernoulli bandit任务，并引入两个新定理，提升了问题的可处理性和近似精度。整体框架为理解人类在认知约束下的探索行为提供了资源理性的规范视角，并生成可实验验证的人类行为预测。",
      "categories": [
        "cs.AI",
        "cs.SY",
        "eess.SY",
        "q-bio.NC"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.01253v2",
      "published_date": "2024-08-02 13:15:01 UTC",
      "updated_date": "2025-02-03 15:11:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T12:28:02.205059"
    },
    {
      "arxiv_id": "2408.01248v1",
      "title": "Deep progressive reinforcement learning-based flexible resource scheduling framework for IRS and UAV-assisted MEC system",
      "title_zh": "基于深度渐进强化学习的灵活资源调度框架，用于IRS和UAV辅助的MEC系统",
      "authors": [
        "Li Dong",
        "Feibo Jiang",
        "Minjie Wang",
        "Yubo Peng",
        "Xiaolong Li"
      ],
      "abstract": "The intelligent reflection surface (IRS) and unmanned aerial vehicle\n(UAV)-assisted mobile edge computing (MEC) system is widely used in temporary\nand emergency scenarios. Our goal is to minimize the energy consumption of the\nMEC system by jointly optimizing UAV locations, IRS phase shift, task\noffloading, and resource allocation with a variable number of UAVs. To this\nend, we propose a Flexible REsource Scheduling (FRES) framework by employing a\nnovel deep progressive reinforcement learning which includes the following\ninnovations: Firstly, a novel multi-task agent is presented to deal with the\nmixed integer nonlinear programming (MINLP) problem. The multi-task agent has\ntwo output heads designed for different tasks, in which a classified head is\nemployed to make offloading decisions with integer variables while a fitting\nhead is applied to solve resource allocation with continuous variables.\nSecondly, a progressive scheduler is introduced to adapt the agent to the\nvarying number of UAVs by progressively adjusting a part of neurons in the\nagent. This structure can naturally accumulate experiences and be immune to\ncatastrophic forgetting. Finally, a light taboo search (LTS) is introduced to\nenhance the global search of the FRES. The numerical results demonstrate the\nsuperiority of the FRES framework which can make real-time and optimal resource\nscheduling even in dynamic MEC systems.",
      "tldr_zh": "本研究针对 IRS 和 UAV 辅助 MEC 系统，提出了一种基于深度渐进强化学习的灵活资源调度框架 (FRES)，目标是通过联合优化 UAV 位置、IRS 相移、任务卸载和资源分配来最小化系统能量消耗，同时处理可变数量的 UAV。框架创新性地引入多任务代理 (multi-task agent) 来解决混合整数非线性规划 (MINLP) 问题，其中分类头用于卸载决策的整数变量，拟合头用于资源分配的连续变量；此外，渐进调度器 (progressive scheduler) 通过逐步调整代理神经元适应不同 UAV 数量，并避免灾难性遗忘。实验结果显示，FRES 框架结合轻量禁忌搜索 (LTS) 实现了实时且最优的资源调度，在动态 MEC 系统中的性能明显优于基线方法。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "13 pages, 10 figures",
      "pdf_url": "http://arxiv.org/pdf/2408.01248v1",
      "published_date": "2024-08-02 13:10:33 UTC",
      "updated_date": "2024-08-02 13:10:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T12:28:14.219845"
    },
    {
      "arxiv_id": "2408.01239v2",
      "title": "Tailoring Graph Neural Network-based Flow-guided Localization to Individual Bloodstreams and Activities",
      "title_zh": "翻译失败",
      "authors": [
        "Pablo Galván",
        "Filip Lemic",
        "Gerard Calvo Bartra",
        "Sergi Abadal",
        "Xavier Costa Pérez"
      ],
      "abstract": "Flow-guided localization using in-body nanodevices in the bloodstream is\nexpected to be beneficial for early disease detection, continuous monitoring of\nbiological conditions, and targeted treatment. The nanodevices face size and\npower constraints that produce erroneous raw data for localization purposes.\nOn-body anchors receive this data, and use it to derive the locations of\ndiagnostic events of interest. Different Machine Learning (ML) approaches have\nbeen recently proposed for this task, yet they are currently restricted to a\nreference bloodstream of a resting patient. As such, they are unable to deal\nwith the physical diversity of patients' bloodstreams and cannot provide\ncontinuous monitoring due to changes in individual patient's activities. Toward\naddressing these issues for the current State-of-the-Art (SotA) flow-guided\nlocalization approach based on Graph Neural Networks (GNNs), we propose a\npipeline for GNN adaptation based on individual physiological indicators\nincluding height, weight, and heart rate. Our results indicate that the\nproposed adaptions are beneficial in reconciling the individual differences\nbetween bloodstreams and activities.",
      "tldr_zh": "这篇论文针对基于Graph Neural Networks (GNNs)的流导向定位技术，提出了一种适应管道，以处理患者血流个体差异和活动变化问题。现有方法受限于静息患者参考血流，无法应对纳米设备数据错误和生理多样性。该管道通过整合个人生理指标（如身高、体重和心率）来个性化调整GNN模型，结果表明这种适应显著提高了定位准确性，支持早期疾病检测和持续监测。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.ET",
        "cs.NI"
      ],
      "primary_category": "cs.LG",
      "comment": "7 pages, 9 figures, 2 tables, 16 references, accepted at ACM\n  NanoCom'25",
      "pdf_url": "http://arxiv.org/pdf/2408.01239v2",
      "published_date": "2024-08-02 12:58:08 UTC",
      "updated_date": "2024-08-20 11:12:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T12:28:25.073934"
    },
    {
      "arxiv_id": "2408.01221v1",
      "title": "Rubric-based Learner Modelling via Noisy Gates Bayesian Networks for Computational Thinking Skills Assessment",
      "title_zh": "翻译失败",
      "authors": [
        "Giorgia Adorni",
        "Francesca Mangili",
        "Alberto Piatti",
        "Claudio Bonesana",
        "Alessandro Antonucci"
      ],
      "abstract": "In modern and personalised education, there is a growing interest in\ndeveloping learners' competencies and accurately assessing them. In a previous\nwork, we proposed a procedure for deriving a learner model for automatic skill\nassessment from a task-specific competence rubric, thus simplifying the\nimplementation of automated assessment tools. The previous approach, however,\nsuffered two main limitations: (i) the ordering between competencies defined by\nthe assessment rubric was only indirectly modelled; (ii) supplementary skills,\nnot under assessment but necessary for accomplishing the task, were not\nincluded in the model. In this work, we address issue (i) by introducing dummy\nobserved nodes, strictly enforcing the skills ordering without changing the\nnetwork's structure. In contrast, for point (ii), we design a network with two\nlayers of gates, one performing disjunctive operations by noisy-OR gates and\nthe other conjunctive operations through logical ANDs. Such changes improve the\nmodel outcomes' coherence and the modelling tool's flexibility without\ncompromising the model's compact parametrisation, interpretability and simple\nexperts' elicitation. We used this approach to develop a learner model for\nComputational Thinking (CT) skills assessment. The CT-cube skills assessment\nframework and the Cross Array Task (CAT) are used to exemplify it and\ndemonstrate its feasibility.",
      "tldr_zh": "本文提出了一种基于 Rubric 的学习者建模方法，利用 Noisy Gates Bayesian Networks 改进自动技能评估，解决了之前模型中技能顺序间接建模和缺少补充技能的局限性。通过引入 dummy observed nodes 强制技能顺序，并设计两层门结构（noisy-OR gates 进行析取操作，逻辑 AND 进行合取操作），该方法提升了模型结果的 coherence 和建模工具的 flexibility，同时保持了紧凑参数化、可解释性和专家易于获取。该方法应用于 Computational Thinking (CT) 技能评估，使用 CT-cube 框架和 Cross Array Task (CAT) 进行示例，证明了其可行性。",
      "categories": [
        "cs.AI",
        "cs.ET"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.01221v1",
      "published_date": "2024-08-02 12:21:05 UTC",
      "updated_date": "2024-08-02 12:21:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T12:28:38.249657"
    },
    {
      "arxiv_id": "2408.01214v1",
      "title": "High-Throughput Phenotyping of Clinical Text Using Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Daniel B. Hier",
        "S. Ilyas Munzir",
        "Anne Stahlfeld",
        "Tayo Obafemi-Ajayi",
        "Michael D. Carrithers"
      ],
      "abstract": "High-throughput phenotyping automates the mapping of patient signs to\nstandardized ontology concepts and is essential for precision medicine. This\nstudy evaluates the automation of phenotyping of clinical summaries from the\nOnline Mendelian Inheritance in Man (OMIM) database using large language\nmodels. Due to their rich phenotype data, these summaries can be surrogates for\nphysician notes. We conduct a performance comparison of GPT-4 and\nGPT-3.5-Turbo. Our results indicate that GPT-4 surpasses GPT-3.5-Turbo in\nidentifying, categorizing, and normalizing signs, achieving concordance with\nmanual annotators comparable to inter-rater agreement. Despite some limitations\nin sign normalization, the extensive pre-training of GPT-4 results in high\nperformance and generalizability across several phenotyping tasks while\nobviating the need for manually annotated training data. Large language models\nare expected to be the dominant method for automating high-throughput\nphenotyping of clinical text.",
      "tldr_zh": "这篇论文评估了使用大型语言模型（Large Language Models）自动进行高通量表型学（High-throughput phenotyping），以将 Online Mendelian Inheritance in Man (OMIM) 数据库的临床总结中患者症状映射到标准化本体概念。研究比较了 GPT-4 和 GPT-3.5-Turbo 的性能，结果显示 GPT-4 在识别、分类和标准化症状方面表现出色，与人工注释者的一致性接近评级者间协议。尽管存在一些症状标准化局限性，但 GPT-4 的广泛预训练使其无需手动注释数据即可实现高性能和泛化能力，预计将成为自动化临床文本表型学的 dominant 方法。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "I.7; I.2"
      ],
      "primary_category": "cs.CL",
      "comment": "Submitted to IEEE-EMBS International Conference on Biomedical and\n  Health Informatics (BHI), Houston TX",
      "pdf_url": "http://arxiv.org/pdf/2408.01214v1",
      "published_date": "2024-08-02 12:00:00 UTC",
      "updated_date": "2024-08-02 12:00:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T12:28:50.642765"
    },
    {
      "arxiv_id": "2408.02686v1",
      "title": "A Systematic Review of Intermediate Fusion in Multimodal Deep Learning for Biomedical Applications",
      "title_zh": "翻译失败",
      "authors": [
        "Valerio Guarrasi",
        "Fatih Aksu",
        "Camillo Maria Caruso",
        "Francesco Di Feola",
        "Aurora Rofena",
        "Filippo Ruffini",
        "Paolo Soda"
      ],
      "abstract": "Deep learning has revolutionized biomedical research by providing\nsophisticated methods to handle complex, high-dimensional data. Multimodal deep\nlearning (MDL) further enhances this capability by integrating diverse data\ntypes such as imaging, textual data, and genetic information, leading to more\nrobust and accurate predictive models. In MDL, differently from early and late\nfusion methods, intermediate fusion stands out for its ability to effectively\ncombine modality-specific features during the learning process. This systematic\nreview aims to comprehensively analyze and formalize current intermediate\nfusion methods in biomedical applications. We investigate the techniques\nemployed, the challenges faced, and potential future directions for advancing\nintermediate fusion methods. Additionally, we introduce a structured notation\nto enhance the understanding and application of these methods beyond the\nbiomedical domain. Our findings are intended to support researchers, healthcare\nprofessionals, and the broader deep learning community in developing more\nsophisticated and insightful multimodal models. Through this review, we aim to\nprovide a foundational framework for future research and practical applications\nin the dynamic field of MDL.",
      "tldr_zh": "这篇综述系统审视了多模态深度学习（Multimodal Deep Learning, MDL）中中间融合（Intermediate Fusion）方法在生物医学应用的现状和潜力。不同于早融合和晚融合，中间融合通过在学习过程中有效整合模态特定特征（如图像、文本和遗传信息），提升了预测模型的鲁棒性和准确性。作者分析了相关技术、面临的挑战（如数据整合复杂性），并引入结构化符号以促进这些方法的理解和跨领域应用。最终，该研究为研究人员、医疗专业人士和深度学习社区提供了基础框架，支持未来MDL模型的开发和实际应用。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.02686v1",
      "published_date": "2024-08-02 11:48:04 UTC",
      "updated_date": "2024-08-02 11:48:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T12:29:02.759235"
    },
    {
      "arxiv_id": "2408.01188v2",
      "title": "Multi-Objective Deep Reinforcement Learning for Optimisation in Autonomous Systems",
      "title_zh": "多目标深度强化学习在自治系统的优化应用",
      "authors": [
        "Juan C. Rosero",
        "Ivana Dusparic",
        "Nicolás Cardozo"
      ],
      "abstract": "Reinforcement Learning (RL) is used extensively in Autonomous Systems (AS) as\nit enables learning at runtime without the need for a model of the environment\nor predefined actions. However, most applications of RL in AS, such as those\nbased on Q-learning, can only optimize one objective, making it necessary in\nmulti-objective systems to combine multiple objectives in a single objective\nfunction with predefined weights. A number of Multi-Objective Reinforcement\nLearning (MORL) techniques exist but they have mostly been applied in RL\nbenchmarks rather than real-world AS systems. In this work, we use a MORL\ntechnique called Deep W-Learning (DWN) and apply it to the Emergent Web Servers\nexemplar, a self-adaptive server, to find the optimal configuration for runtime\nperformance optimization. We compare DWN to two single-objective optimization\nimplementations: {\\epsilon}-greedy algorithm and Deep Q-Networks. Our initial\nevaluation shows that DWN optimizes multiple objectives simultaneously with\nsimilar results than DQN and {\\epsilon}-greedy approaches, having a better\nperformance for some metrics, and avoids issues associated with combining\nmultiple objectives into a single utility function.",
      "tldr_zh": "这篇论文探讨了在自主系统（AS）中应用多目标强化学习（MORL）来优化多个目标的问题，相比传统强化学习（RL）如Q-learning，它避免了将多目标合并为单一加权函数的局限性。研究团队使用Deep W-Learning (DWN) 技术应用于Emergent Web Servers（一个自适应服务器），以实现运行时性能优化，并与ε-greedy算法和Deep Q-Networks (DQN) 进行了比较。结果显示，DWN能同时优化多个目标，性能与单目标方法相当或更好，从而为真实AS系统的优化提供了更可靠的解决方案。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "pages, Accepted to AI4AS 2024 workshop",
      "pdf_url": "http://arxiv.org/pdf/2408.01188v2",
      "published_date": "2024-08-02 11:16:09 UTC",
      "updated_date": "2024-09-30 13:15:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T12:29:15.624347"
    },
    {
      "arxiv_id": "2408.01187v1",
      "title": "Optimizing Variational Quantum Circuits Using Metaheuristic Strategies in Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Michael Kölle",
        "Daniel Seidl",
        "Maximilian Zorn",
        "Philipp Altmann",
        "Jonas Stein",
        "Thomas Gabor"
      ],
      "abstract": "Quantum Reinforcement Learning (QRL) offers potential advantages over\nclassical Reinforcement Learning, such as compact state space representation\nand faster convergence in certain scenarios. However, practical benefits\nrequire further validation. QRL faces challenges like flat solution landscapes,\nwhere traditional gradient-based methods are inefficient, necessitating the use\nof gradient-free algorithms. This work explores the integration of\nmetaheuristic algorithms -- Particle Swarm Optimization, Ant Colony\nOptimization, Tabu Search, Genetic Algorithm, Simulated Annealing, and Harmony\nSearch -- into QRL. These algorithms provide flexibility and efficiency in\nparameter optimization. Evaluations in $5\\times5$ MiniGrid Reinforcement\nLearning environments show that, all algorithms yield near-optimal results,\nwith Simulated Annealing and Particle Swarm Optimization performing best. In\nthe Cart Pole environment, Simulated Annealing, Genetic Algorithms, and\nParticle Swarm Optimization achieve optimal results, while the others perform\nslightly better than random action selection. These findings demonstrate the\npotential of Particle Swarm Optimization and Simulated Annealing for efficient\nQRL learning, emphasizing the need for careful algorithm selection and\nadaptation.",
      "tldr_zh": "本研究探讨了使用元启发式(metaheuristic)策略优化变分量子电路在 Quantum Reinforcement Learning (QRL) 中的应用，以克服传统梯度方法在 QRL 面临的挑战，如平坦解景观。研究整合了 Particle Swarm Optimization (PSO)、Ant Colony Optimization (ACO)、Tabu Search、Genetic Algorithm (GA)、Simulated Annealing (SA) 和 Harmony Search (HS) 等算法，并在 5×5 MiniGrid 和 Cart Pole 环境中进行评估，结果显示这些算法均能实现近优结果，其中 SA 和 PSO 表现最佳。实验证明，PSO 和 SA 在 QRL 中具有高效潜力，并强调了算法选择和适应的必要性，为 QRL 的实际应用提供了新见解。",
      "categories": [
        "quant-ph",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "quant-ph",
      "comment": "Accepted at QCE24 - QCRL24 Workshop",
      "pdf_url": "http://arxiv.org/pdf/2408.01187v1",
      "published_date": "2024-08-02 11:14:41 UTC",
      "updated_date": "2024-08-02 11:14:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T12:29:27.604158"
    },
    {
      "arxiv_id": "2408.01168v1",
      "title": "Misinforming LLMs: vulnerabilities, challenges and opportunities",
      "title_zh": "翻译失败",
      "authors": [
        "Bo Zhou",
        "Daniel Geißler",
        "Paul Lukowicz"
      ],
      "abstract": "Large Language Models (LLMs) have made significant advances in natural\nlanguage processing, but their underlying mechanisms are often misunderstood.\nDespite exhibiting coherent answers and apparent reasoning behaviors, LLMs rely\non statistical patterns in word embeddings rather than true cognitive\nprocesses. This leads to vulnerabilities such as \"hallucination\" and\nmisinformation. The paper argues that current LLM architectures are inherently\nuntrustworthy due to their reliance on correlations of sequential patterns of\nword embedding vectors. However, ongoing research into combining generative\ntransformer-based models with fact bases and logic programming languages may\nlead to the development of trustworthy LLMs capable of generating statements\nbased on given truth and explaining their self-reasoning process.",
      "tldr_zh": "该论文探讨了大型语言模型 (LLMs) 的易受误导性，强调其依赖于词嵌入向量的统计模式而非真实认知过程，导致 hallucination 和 misinformation 等漏洞。作者指出，当前 LLM 架构因过度依赖顺序模式的相关性而不可靠，难以提供可信的输出。然而，通过将生成 transformer-based 模型与事实库和逻辑编程语言相结合，未来可能开发出可信任的 LLMs，能够基于给定事实生成语句并解释其自推理过程，从而开辟新机会。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.01168v1",
      "published_date": "2024-08-02 10:35:49 UTC",
      "updated_date": "2024-08-02 10:35:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T12:29:50.104938"
    },
    {
      "arxiv_id": "2408.01156v1",
      "title": "TCR-GPT: Integrating Autoregressive Model and Reinforcement Learning for T-Cell Receptor Repertoires Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Yicheng Lin",
        "Dandan Zhang",
        "Yun Liu"
      ],
      "abstract": "T-cell receptors (TCRs) play a crucial role in the immune system by\nrecognizing and binding to specific antigens presented by infected or cancerous\ncells. Understanding the sequence patterns of TCRs is essential for developing\ntargeted immune therapies and designing effective vaccines. Language models,\nsuch as auto-regressive transformers, offer a powerful solution to this problem\nby learning the probability distributions of TCR repertoires, enabling the\ngeneration of new TCR sequences that inherit the underlying patterns of the\nrepertoire. We introduce TCR-GPT, a probabilistic model built on a decoder-only\ntransformer architecture, designed to uncover and replicate sequence patterns\nin TCR repertoires. TCR-GPT demonstrates an accuracy of 0.953 in inferring\nsequence probability distributions measured by Pearson correlation coefficient.\nFurthermore, by leveraging Reinforcement Learning(RL), we adapted the\ndistribution of TCR sequences to generate TCRs capable of recognizing specific\npeptides, offering significant potential for advancing targeted immune\ntherapies and vaccine development. With the efficacy of RL, fine-tuned\npretrained TCR-GPT models demonstrated the ability to produce TCR repertoires\nlikely to bind specific peptides, illustrating RL's efficiency in enhancing the\nmodel's adaptability to the probability distributions of biologically relevant\nTCR sequences.",
      "tldr_zh": "本研究开发了 TCR-GPT，一种基于自回归 transformer 模型的概率框架，用于学习和生成 T-cell receptors (TCRs) 序列，从而揭示其序列模式并支持免疫疗法和疫苗设计。TCR-GPT 在推断 TCR 序列概率分布时，准确率达到 0.953 (Pearson 相关系数)，展示了其在复制序列模式方面的强大能力。通过整合 Reinforcement Learning (RL)，模型能够调整 TCR 序列分布，生成针对特定肽的 TCR 序列，提升了其在生物学相关应用中的适应性。该方法为推进针对性免疫疗法和疫苗开发提供了重要潜力。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.01156v1",
      "published_date": "2024-08-02 10:16:28 UTC",
      "updated_date": "2024-08-02 10:16:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T12:29:52.137985"
    },
    {
      "arxiv_id": "2408.01154v1",
      "title": "DERA: Dense Entity Retrieval for Entity Alignment in Knowledge Graphs",
      "title_zh": "翻译失败",
      "authors": [
        "Zhichun Wang",
        "Xuan Chen"
      ],
      "abstract": "Entity Alignment (EA) aims to match equivalent entities in different\nKnowledge Graphs (KGs), which is essential for knowledge fusion and\nintegration. Recently, embedding-based EA has attracted significant attention\nand many approaches have been proposed. Early approaches primarily focus on\nlearning entity embeddings from the structural features of KGs, defined by\nrelation triples. Later methods incorporated entities' names and attributes as\nauxiliary information to enhance embeddings for EA. However, these approaches\noften used different techniques to encode structural and attribute information,\nlimiting their interaction and mutual enhancement. In this work, we propose a\ndense entity retrieval framework for EA, leveraging language models to\nuniformly encode various features of entities and facilitate nearest entity\nsearch across KGs. Alignment candidates are first generated through entity\nretrieval, which are subsequently reranked to determine the final alignments.\nWe conduct comprehensive experiments on both cross-lingual and monolingual EA\ndatasets, demonstrating that our approach achieves state-of-the-art performance\ncompared to existing EA methods.",
      "tldr_zh": "实体对齐 (Entity Alignment, EA) 旨在匹配不同知识图谱 (Knowledge Graphs, KGs) 中的等价实体，以支持知识融合和整合。DERA 框架通过使用语言模型统一编码实体的结构特征、名称和属性信息，实现密集实体检索 (Dense Entity Retrieval)，并结合候选生成和重新排序步骤来提升对齐准确性。与现有方法相比，这种统一编码策略允许特征间更有效的互动。实验结果显示，DERA 在跨语言和单语言 EA 数据集上达到了最先进 (state-of-the-art) 性能。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.01154v1",
      "published_date": "2024-08-02 10:12:42 UTC",
      "updated_date": "2024-08-02 10:12:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T12:30:04.035969"
    },
    {
      "arxiv_id": "2408.01139v2",
      "title": "Interpreting Global Perturbation Robustness of Image Models using Axiomatic Spectral Importance Decomposition",
      "title_zh": "翻译失败",
      "authors": [
        "Róisín Luo",
        "James McDermott",
        "Colm O'Riordan"
      ],
      "abstract": "Perturbation robustness evaluates the vulnerabilities of models, arising from\na variety of perturbations, such as data corruptions and adversarial attacks.\nUnderstanding the mechanisms of perturbation robustness is critical for global\ninterpretability. We present a model-agnostic, global mechanistic\ninterpretability method to interpret the perturbation robustness of image\nmodels. This research is motivated by two key aspects. First, previous global\ninterpretability works, in tandem with robustness benchmarks, e.g. mean\ncorruption error (mCE), are not designed to directly interpret the mechanisms\nof perturbation robustness within image models. Second, we notice that the\nspectral signal-to-noise ratios (SNR) of perturbed natural images exponentially\ndecay over the frequency. This power-law-like decay implies that: Low-frequency\nsignals are generally more robust than high-frequency signals -- yet high\nclassification accuracy can not be achieved by low-frequency signals alone. By\napplying Shapley value theory, our method axiomatically quantifies the\npredictive powers of robust features and non-robust features within an\ninformation theory framework. Our method, dubbed as \\textbf{I-ASIDE}\n(\\textbf{I}mage \\textbf{A}xiomatic \\textbf{S}pectral \\textbf{I}mportance\n\\textbf{D}ecomposition \\textbf{E}xplanation), provides a unique insight into\nmodel robustness mechanisms. We conduct extensive experiments over a variety of\nvision models pre-trained on ImageNet to show that \\textbf{I-ASIDE} can not\nonly \\textbf{measure} the perturbation robustness but also \\textbf{provide\ninterpretations} of its mechanisms.",
      "tldr_zh": "该研究提出了一种模型无关的全局机制解释方法 I-ASIDE（Image Axiomatic Spectral Importance Decomposition Explanation），用于解读图像模型的扰动鲁棒性（perturbation robustness），以应对数据损坏和对抗攻击等挑战。方法基于 Shapley 值理论和频谱分析（spectral SNR），在信息理论框架下量化鲁棒特征和非鲁棒特征的预测能力，并利用观察到扰动图像中低频信号更鲁棒的特性来解释鲁棒性机制。尽管低频信号无法单独实现高分类准确率，该方法仍能提供深入的全局可解释性。实验在 ImageNet 上预训练的各种视觉模型上进行，证明 I-ASIDE 不仅能测量扰动鲁棒性，还能揭示其内部机制。",
      "categories": [
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted by Transactions on Machine Learning Research (TMLR 2024)",
      "pdf_url": "http://arxiv.org/pdf/2408.01139v2",
      "published_date": "2024-08-02 09:35:06 UTC",
      "updated_date": "2024-08-18 17:13:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T12:30:15.289420"
    },
    {
      "arxiv_id": "2408.01129v5",
      "title": "A Survey of Mamba",
      "title_zh": "Mamba 的综述",
      "authors": [
        "Haohao Qu",
        "Liangbo Ning",
        "Rui An",
        "Wenqi Fan",
        "Tyler Derr",
        "Hui Liu",
        "Xin Xu",
        "Qing Li"
      ],
      "abstract": "As one of the most representative DL techniques, Transformer architecture has\nempowered numerous advanced models, especially the large language models (LLMs)\nthat comprise billions of parameters, becoming a cornerstone in deep learning.\nDespite the impressive achievements, Transformers still face inherent\nlimitations, particularly the time-consuming inference resulting from the\nquadratic computation complexity of attention calculation. Recently, a novel\narchitecture named Mamba, drawing inspiration from classical state space models\n(SSMs), has emerged as a promising alternative for building foundation models,\ndelivering comparable modeling abilities to Transformers while preserving\nnear-linear scalability concerning sequence length. This has sparked an\nincreasing number of studies actively exploring Mamba's potential to achieve\nimpressive performance across diverse domains. Given such rapid evolution,\nthere is a critical need for a systematic review that consolidates existing\nMamba-empowered models, offering a comprehensive understanding of this emerging\nmodel architecture. In this survey, we therefore conduct an in-depth\ninvestigation of recent Mamba-associated studies, covering three main aspects:\nthe advancements of Mamba-based models, the techniques of adapting Mamba to\ndiverse data, and the applications where Mamba can excel. Specifically, we\nfirst review the foundational knowledge of various representative deep learning\nmodels and the details of Mamba-1&2 as preliminaries. Then, to showcase the\nsignificance of Mamba for AI, we comprehensively review the related studies\nfocusing on Mamba models' architecture design, data adaptability, and\napplications. Finally, we present a discussion of current limitations and\nexplore various promising research directions to provide deeper insights for\nfuture investigations.",
      "tldr_zh": "本文对 Mamba 架构进行了系统性调查，作为 Transformer 的潜在替代方案，Mamba 借鉴状态空间模型 (SSMs) 的灵感，提供与 Transformer 相当的建模能力，同时实现近线性的序列长度可扩展性。论文首先回顾了深度学习模型的基础知识和 Mamba-1 与 Mamba-2 的细节，然后全面分析了 Mamba 模型的架构设计、适应多样数据的技术，以及在不同领域的应用表现。调查结果突出了 Mamba 在提升效率方面的优势，并讨论了其当前局限性以及未来研究方向，如进一步优化和扩展应用。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.01129v5",
      "published_date": "2024-08-02 09:18:41 UTC",
      "updated_date": "2024-12-13 06:16:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T12:30:27.884114"
    },
    {
      "arxiv_id": "2408.01121v1",
      "title": "Being Accountable is Smart: Navigating the Technical and Regulatory Landscape of AI-based Services for Power Grid",
      "title_zh": "翻译失败",
      "authors": [
        "Anna Volkova",
        "Mahdieh Hatamian",
        "Alina Anapyanova",
        "Hermann de Meer"
      ],
      "abstract": "The emergence of artificial intelligence and digitization of the power grid\nintroduced numerous effective application scenarios for AI-based services for\nthe smart grid. Nevertheless, adopting AI in critical infrastructures presents\nchallenges due to unclear regulations and lacking risk quantification\ntechniques. Regulated and accountable approaches for integrating AI-based\nservices into the smart grid could accelerate the adoption of innovative\nmethods in daily practices and address society's general safety concerns. This\npaper contributes to this objective by defining accountability and highlighting\nits importance for AI-based services in the energy sector. It underlines the\ncurrent shortcomings of the AI Act and proposes an approach to address these\nissues in a potential delegated act. The proposed technical approach for\ndeveloping and operating accountable AI-based smart grid services allows for\nassessing different service life cycle phases and identifying related\naccountability risks.",
      "tldr_zh": "该论文探讨了人工智能(AI)应用于智能电网的挑战，包括不明确的法规和缺乏风险量化技术，并强调责任性(accountability)在能源部门AI服务中的重要性。论文定义了accountability的概念，指出欧盟AI Act的当前不足，并提出一种技术方法来解决这些问题。该方法通过评估AI服务生命周期的不同阶段并识别相关风险，帮助加速创新方法的采用并缓解社会安全担忧。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Author's version of the paper for International Conference on\n  Information Technology for Social Good (GoodIT '24), September 4--6, 2024,\n  Bremen, Germany. It is posted here for your personal use. Not for\n  redistribution",
      "pdf_url": "http://arxiv.org/pdf/2408.01121v1",
      "published_date": "2024-08-02 09:02:42 UTC",
      "updated_date": "2024-08-02 09:02:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T12:30:39.709618"
    },
    {
      "arxiv_id": "2408.01107v2",
      "title": "BioRAG: A RAG-LLM Framework for Biological Question Reasoning",
      "title_zh": "BioRAG：一种 RAG-LLM 框架用于生物学问题推理",
      "authors": [
        "Chengrui Wang",
        "Qingqing Long",
        "Meng Xiao",
        "Xunxin Cai",
        "Chengjun Wu",
        "Zhen Meng",
        "Xuezhi Wang",
        "Yuanchun Zhou"
      ],
      "abstract": "The question-answering system for Life science research, which is\ncharacterized by the rapid pace of discovery, evolving insights, and complex\ninteractions among knowledge entities, presents unique challenges in\nmaintaining a comprehensive knowledge warehouse and accurate information\nretrieval. To address these issues, we introduce BioRAG, a novel\nRetrieval-Augmented Generation (RAG) with the Large Language Models (LLMs)\nframework. Our approach starts with parsing, indexing, and segmenting an\nextensive collection of 22 million scientific papers as the basic knowledge,\nfollowed by training a specialized embedding model tailored to this domain.\nAdditionally, we enhance the vector retrieval process by incorporating a\ndomain-specific knowledge hierarchy, which aids in modeling the intricate\ninterrelationships among each query and context. For queries requiring the most\ncurrent information, BioRAG deconstructs the question and employs an iterative\nretrieval process incorporated with the search engine for step-by-step\nreasoning. Rigorous experiments have demonstrated that our model outperforms\nfine-tuned LLM, LLM with search engines, and other scientific RAG frameworks\nacross multiple life science question-answering tasks.",
      "tldr_zh": "该研究提出BioRAG框架，一种结合Retrieval-Augmented Generation (RAG)和Large Language Models (LLMs)的系统，旨在解决生命科学领域问答系统的知识更新和复杂交互挑战。BioRAG通过解析、索引和分割2200万篇科学论文来构建基础知识库，并训练专用嵌入模型，同时融入领域特定知识层次结构以优化查询与上下文的关联。对于需要最新信息的查询，该框架采用问题分解和迭代检索过程结合搜索引擎进行逐步推理。实验结果显示，BioRAG在多个生命科学问答任务中，优于微调的LLMs、结合搜索引擎的LLMs以及其他科学RAG框架。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.CL",
      "comment": "12 pages, 7 figures",
      "pdf_url": "http://arxiv.org/pdf/2408.01107v2",
      "published_date": "2024-08-02 08:37:03 UTC",
      "updated_date": "2024-08-14 09:54:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T12:30:51.085564"
    },
    {
      "arxiv_id": "2408.01099v1",
      "title": "Contribution-based Low-Rank Adaptation with Pre-training Model for Real Image Restoration",
      "title_zh": "翻译失败",
      "authors": [
        "Donwon Park",
        "Hayeon Kim",
        "Se Young Chun"
      ],
      "abstract": "Recently, pre-trained model and efficient parameter tuning have achieved\nremarkable success in natural language processing and high-level computer\nvision with the aid of masked modeling and prompt tuning. In low-level computer\nvision, however, there have been limited investigations on pre-trained models\nand even efficient fine-tuning strategy has not yet been explored despite its\nimportance and benefit in various real-world tasks such as alleviating memory\ninflation issue when integrating new tasks on AI edge devices. Here, we propose\na novel efficient parameter tuning approach dubbed contribution-based low-rank\nadaptation (CoLoRA) for multiple image restorations along with effective\npre-training method with random order degradations (PROD). Unlike prior arts\nthat tune all network parameters, our CoLoRA effectively fine-tunes small\namount of parameters by leveraging LoRA (low-rank adaptation) for each new\nvision task with our contribution-based method to adaptively determine layer by\nlayer capacity for that task to yield comparable performance to full tuning.\nFurthermore, our PROD strategy allows to extend the capability of pre-trained\nmodels with improved performance as well as robustness to bridge synthetic\npre-training and real-world fine-tuning. Our CoLoRA with PROD has demonstrated\nits superior performance in various image restoration tasks across diverse\ndegradation types on both synthetic and real-world datasets for known and novel\ntasks.",
      "tldr_zh": "本文提出了一种高效参数调整方法——contribution-based low-rank adaptation (CoLoRA)，结合随机顺序退化预训练 (PROD)，用于真实图像恢复任务，以解决低级计算机视觉中内存膨胀等问题。CoLoRA 基于 LoRA 仅微调少量参数，通过贡献-based 策略自适应确定每层的容量，实现与全参数调整相当的性能，同时提升模型的鲁棒性和泛化能力。PROD 策略通过随机退化增强预训练模型的适用性，桥接合成数据预训练与真实世界微调。实验结果显示，该方法在各种图像恢复任务中，包括已知和新型任务，在合成和真实数据集上均表现出优越性能。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "33 pages, 15 figures, for homepage see this url :\n  https://janeyeon.github.io/colora/",
      "pdf_url": "http://arxiv.org/pdf/2408.01099v1",
      "published_date": "2024-08-02 08:24:05 UTC",
      "updated_date": "2024-08-02 08:24:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T12:31:15.636720"
    },
    {
      "arxiv_id": "2408.02685v1",
      "title": "Artificial Neural Networks for Photonic Applications: From Algorithms to Implementation",
      "title_zh": "翻译失败",
      "authors": [
        "Pedro Freire",
        "Egor Manuylovich",
        "Jaroslaw E. Prilepsky",
        "Sergei K. Turitsy"
      ],
      "abstract": "This tutorial-review on applications of artificial neural networks in\nphotonics targets a broad audience, ranging from optical research and\nengineering communities to computer science and applied mathematics. We focus\nhere on the research areas at the interface between these disciplines,\nattempting to find the right balance between technical details specific to each\ndomain and overall clarity. First, we briefly recall key properties and\npeculiarities of some core neural network types, which we believe are the most\nrelevant to photonics, also linking the layer's theoretical design to some\nphotonics hardware realizations. After that, we elucidate the question of how\nto fine-tune the selected model's design to perform the required task with\noptimized accuracy. Then, in the review part, we discuss recent developments\nand progress for several selected applications of neural networks in photonics,\nincluding multiple aspects relevant to optical communications, imaging,\nsensing, and the design of new materials and lasers. In the following section,\nwe put a special emphasis on how to accurately evaluate the complexity of\nneural networks in the context of the transition from algorithms to hardware\nimplementation. The introduced complexity characteristics are used to analyze\nthe applications of neural networks in optical communications, as a specific,\nalbeit highly important example, comparing those with some benchmark signal\nprocessing methods. We combine the description of the well-known model\ncompression strategies used in machine learning, with some novel techniques\nintroduced recently in optical applications of neural networks. It is important\nto stress that although our focus in this tutorial-review is on photonics, we\nbelieve that the methods and techniques presented here can be handy in a much\nwider range of scientific and engineering applications.",
      "tldr_zh": "这篇教程性评论探讨了人工神经网络（Artificial Neural Networks）在光子学（Photonics）中的应用，针对光学工程、计算机科学和应用数学等领域的受众，平衡了技术细节与整体清晰度。主要内容包括回顾核心神经网络类型及其与光子硬件实现的关联、微调模型设计以优化任务准确性，以及神经网络在光学通信、成像、传感、材料设计和激光领域的最新进展。论文强调评估神经网络复杂性的方法，特别是从算法到硬件实现的过渡，并通过比较分析显示神经网络在光学通信中优于某些基准信号处理方法，同时引入模型压缩策略以提升实用性。这些技术不仅适用于光子学，还可扩展到更广泛的科学和工程领域。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "eess.SP",
        "physics.optics"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.02685v1",
      "published_date": "2024-08-02 08:22:49 UTC",
      "updated_date": "2024-08-02 08:22:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T12:31:16.594060"
    },
    {
      "arxiv_id": "2408.01096v1",
      "title": "Six Dragons Fly Again: Reviving 15th-Century Korean Court Music with Transformers and Novel Encoding",
      "title_zh": "翻译失败",
      "authors": [
        "Danbinaerin Han",
        "Mark Gotham",
        "Dongmin Kim",
        "Hannah Park",
        "Sihun Lee",
        "Dasaem Jeong"
      ],
      "abstract": "We introduce a project that revives a piece of 15th-century Korean court\nmusic, Chihwapyeong and Chwipunghyeong, composed upon the poem Songs of the\nDragon Flying to Heaven. One of the earliest examples of Jeongganbo, a Korean\nmusical notation system, the remaining version only consists of a rudimentary\nmelody. Our research team, commissioned by the National Gugak (Korean\nTraditional Music) Center, aimed to transform this old melody into a\nperformable arrangement for a six-part ensemble. Using Jeongganbo data acquired\nthrough bespoke optical music recognition, we trained a BERT-like masked\nlanguage model and an encoder-decoder transformer model. We also propose an\nencoding scheme that strictly follows the structure of Jeongganbo and denotes\nnote durations as positions. The resulting machine-transformed version of\nChihwapyeong and Chwipunghyeong were evaluated by experts and performed by the\nCourt Music Orchestra of National Gugak Center. Our work demonstrates that\ngenerative models can successfully be applied to traditional music with limited\ntraining data if combined with careful design.",
      "tldr_zh": "本研究旨在复兴15世纪韩国宫廷音乐Chihwapyeong和Chwipunghyeong，这些音乐基于《龙飞天之歌》并使用Jeongganbo记谱系统，但仅存基本旋律。研究团队通过光学音乐识别获取数据，训练BERT-like masked language model和encoder-decoder transformer model，并提出一种新编码方案，将音符持续时间表示为位置，以生成适合六声部合奏的表演版本。生成的音乐由国家国乐中心专家评估并由宫廷音乐乐团实际表演，证明了生成模型在训练数据有限的情况下，通过精心设计，可成功应用于传统音乐领域。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "Accepted at the 25th International Society for Music Information\n  Retrieval Conference (ISMIR 2024)",
      "pdf_url": "http://arxiv.org/pdf/2408.01096v1",
      "published_date": "2024-08-02 08:16:55 UTC",
      "updated_date": "2024-08-02 08:16:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T12:31:27.830706"
    },
    {
      "arxiv_id": "2408.01091v2",
      "title": "Dissecting Dissonance: Benchmarking Large Multimodal Models Against Self-Contradictory Instructions",
      "title_zh": "翻译失败",
      "authors": [
        "Jin Gao",
        "Lei Gan",
        "Yuankai Li",
        "Yixin Ye",
        "Dequan Wang"
      ],
      "abstract": "Large multimodal models (LMMs) excel in adhering to human instructions.\nHowever, self-contradictory instructions may arise due to the increasing trend\nof multimodal interaction and context length, which is challenging for language\nbeginners and vulnerable populations. We introduce the Self-Contradictory\nInstructions benchmark to evaluate the capability of LMMs in recognizing\nconflicting commands. It comprises 20,000 conflicts, evenly distributed between\nlanguage and vision paradigms. It is constructed by a novel automatic dataset\ncreation framework, which expedites the process and enables us to encompass a\nwide range of instruction forms. Our comprehensive evaluation reveals current\nLMMs consistently struggle to identify multimodal instruction discordance due\nto a lack of self-awareness. Hence, we propose the Cognitive Awakening\nPrompting to inject cognition from external, largely enhancing dissonance\ndetection. The dataset and code are here: https://selfcontradiction.github.io/.",
      "tldr_zh": "该研究探讨了大型多模态模型 (LMMs) 在处理自相矛盾指令时的挑战，这些指令可能因多模态交互和上下文长度增加而出现。研究者引入了 Self-Contradictory Instructions 基准测试数据集，包含 20,000 个冲突指令，平均分布在语言和视觉范式中，并通过一个新型的自动数据集创建框架来加速构建和覆盖多样指令形式。评估结果显示，当前 LMMs 由于缺乏自我意识，无法有效识别多模态指令的不一致性。为此，论文提出 Cognitive Awakening Prompting 方法，通过外部注入认知显著提升了不一致性检测能力。数据集和代码已公开，可用于进一步研究。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted by the 18th European Conference on Computer Vision ECCV 2024",
      "pdf_url": "http://arxiv.org/pdf/2408.01091v2",
      "published_date": "2024-08-02 08:11:11 UTC",
      "updated_date": "2024-08-05 06:56:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T12:31:40.295877"
    },
    {
      "arxiv_id": "2408.01075v1",
      "title": "The EAP-AIAS: Adapting the AI Assessment Scale for English for Academic Purposes",
      "title_zh": "翻译失败",
      "authors": [
        "Jasper Roe",
        "Mike Perkins",
        "Yulia Tregubova"
      ],
      "abstract": "The rapid advancement of Generative Artificial Intelligence (GenAI) presents\nboth opportunities and challenges for English for Academic Purposes (EAP)\ninstruction. This paper proposes an adaptation of the AI Assessment Scale\n(AIAS) specifically tailored for EAP contexts, termed the EAP-AIAS.\n  This framework aims to provide a structured approach for integrating GenAI\ntools into EAP assessment practices while maintaining academic integrity and\nsupporting language development. The EAP-AIAS consists of five levels, ranging\nfrom \"No AI\" to \"Full AI\", each delineating appropriate GenAI usage in EAP\ntasks. We discuss the rationale behind this adaptation, considering the unique\nneeds of language learners and the dual focus of EAP on language proficiency\nand academic acculturation.\n  This paper explores potential applications of the EAP-AIAS across various EAP\nassessment types, including writing tasks, presentations, and research\nprojects. By offering a flexible framework, the EAP-AIAS seeks to empower EAP\npractitioners seeking to deal with the complexities of GenAI integration in\neducation and prepare students for an AI-enhanced academic and professional\nfuture. This adaptation represents a step towards addressing the pressing need\nfor ethical and pedagogically sound AI integration in language education.",
      "tldr_zh": "这篇论文提出了一种适应版 AI Assessment Scale (AIAS)，即 EAP-AIAS，专门针对英语学术目的 (EAP) 环境，以结构化方式整合 Generative Artificial Intelligence (GenAI) 工具。EAP-AIAS 包括从 \"No AI\" 到 \"Full AI\" 的五个级别，旨在平衡学术诚信、语言发展和 GenAI 的使用，同时考虑语言学习者的独特需求和 EAP 在语言熟练度与学术适应的双重焦点。论文探讨了该框架在写作任务、演讲和研究项目等 EAP 评估中的应用，帮助教育者应对 AI 整合的复杂性，并为学生准备 AI 增强的学术与职业未来。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.01075v1",
      "published_date": "2024-08-02 07:51:29 UTC",
      "updated_date": "2024-08-02 07:51:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T12:31:55.256819"
    },
    {
      "arxiv_id": "2408.01072v3",
      "title": "A Survey on Self-play Methods in Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Ruize Zhang",
        "Zelai Xu",
        "Chengdong Ma",
        "Chao Yu",
        "Wei-Wei Tu",
        "Wenhao Tang",
        "Shiyu Huang",
        "Deheng Ye",
        "Wenbo Ding",
        "Yaodong Yang",
        "Yu Wang"
      ],
      "abstract": "Self-play, characterized by agents' interactions with copies or past versions\nof themselves, has recently gained prominence in reinforcement learning (RL).\nThis paper first clarifies the preliminaries of self-play, including the\nmulti-agent reinforcement learning framework and basic game theory concepts.\nThen, it provides a unified framework and classifies existing self-play\nalgorithms within this framework. Moreover, the paper bridges the gap between\nthe algorithms and their practical implications by illustrating the role of\nself-play in different scenarios. Finally, the survey highlights open\nchallenges and future research directions in self-play. This paper is an\nessential guide map for understanding the multifaceted landscape of self-play\nin RL.",
      "tldr_zh": "这篇论文对自博弈(self-play)方法在强化学习(reinforcement learning, RL)中的应用进行了全面调查。首先，它阐明了自博弈的基础知识，包括多智能体强化学习(multi-agent reinforcement learning)框架和基本博弈论(game theory)概念，并提供了一个统一的框架来分类现有算法。其次，论文桥接了算法与实际应用的差距，展示了自博弈在不同场景中的作用。最后，它突出了自博弈领域的开放挑战和未来研究方向，为理解RL中自博弈的多方面景观提供了 essential guide map。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.01072v3",
      "published_date": "2024-08-02 07:47:51 UTC",
      "updated_date": "2025-03-27 13:42:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T12:32:04.293810"
    },
    {
      "arxiv_id": "2408.01055v1",
      "title": "LLM as Runtime Error Handler: A Promising Pathway to Adaptive Self-Healing of Software Systems",
      "title_zh": "翻译失败",
      "authors": [
        "Zhensu Sun",
        "Haotian Zhu",
        "Bowen Xu",
        "Xiaoning Du",
        "Li Li",
        "David Lo"
      ],
      "abstract": "Unanticipated runtime errors, lacking predefined handlers, can abruptly\nterminate execution and lead to severe consequences, such as data loss or\nsystem crashes. Despite extensive efforts to identify potential errors during\nthe development phase, such unanticipated errors remain a challenge to to be\nentirely eliminated, making the runtime mitigation measurements still\nindispensable to minimize their impact. Automated self-healing techniques, such\nas reusing existing handlers, have been investigated to reduce the loss coming\nthrough with the execution termination. However, the usability of existing\nmethods is retained by their predefined heuristic rules and they fail to handle\ndiverse runtime errors adaptively. Recently, the advent of Large Language\nModels (LLMs) has opened new avenues for addressing this problem. Inspired by\ntheir remarkable capabilities in understanding and generating code, we propose\nto deal with the runtime errors in a real-time manner using LLMs.\n  Specifically, we propose Healer, the first LLM-assisted self-healing\nframework for handling runtime errors. When an unhandled runtime error occurs,\nHealer will be activated to generate a piece of error-handling code with the\nhelp of its internal LLM and the code will be executed inside the runtime\nenvironment owned by the framework to obtain a rectified program state from\nwhich the program should continue its execution. Our exploratory study\nevaluates the performance of Healer using four different code benchmarks and\nthree state-of-the-art LLMs, GPT-3.5, GPT-4, and CodeQwen-7B. Results show\nthat, without the need for any fine-tuning, GPT-4 can successfully help\nprograms recover from 72.8% of runtime errors, highlighting the potential of\nLLMs in handling runtime errors.",
      "tldr_zh": "这篇论文探讨了使用 Large Language Models (LLMs) 来处理运行时错误的问题，提出 Healer 框架作为首个 LLM 辅助的自愈系统。当运行时错误发生时，Healer 会利用 LLM 生成实时错误处理代码，并在运行环境执行，以恢复程序状态并继续执行。实验在四个代码基准上评估了 Healer，使用 GPT-3.5、GPT-4 和 CodeQwen-7B，结果显示 GPT-4 无需微调即可成功处理 72.8% 的运行时错误，展示了 LLMs 在实现自适应软件自愈的潜力。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.01055v1",
      "published_date": "2024-08-02 07:03:00 UTC",
      "updated_date": "2024-08-02 07:03:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T12:32:15.709135"
    },
    {
      "arxiv_id": "2408.01051v1",
      "title": "From Stem to Stern: Contestability Along AI Value Chains",
      "title_zh": "从头到尾：AI价值链的可争议性",
      "authors": [
        "Agathe Balayn",
        "Yulu Pi",
        "David Gray Widder",
        "Kars Alfrink",
        "Mireia Yurrita",
        "Sohini Upadhyay",
        "Naveena Karusala",
        "Henrietta Lyons",
        "Cagatay Turkay",
        "Christelle Tessono",
        "Blair Attard-Frost",
        "Ujwal Gadiraju"
      ],
      "abstract": "This workshop will grow and consolidate a community of interdisciplinary CSCW\nresearchers focusing on the topic of contestable AI. As an outcome of the\nworkshop, we will synthesize the most pressing opportunities and challenges for\ncontestability along AI value chains in the form of a research roadmap. This\nroadmap will help shape and inspire imminent work in this field. Considering\nthe length and depth of AI value chains, it will especially spur discussions\naround the contestability of AI systems along various sites of such chains. The\nworkshop will serve as a platform for dialogue and demonstrations of concrete,\nsuccessful, and unsuccessful examples of AI systems that (could or should) have\nbeen contested, to identify requirements, obstacles, and opportunities for\ndesigning and deploying contestable AI in various contexts. This will be held\nprimarily as an in-person workshop, with some hybrid accommodation. The day\nwill consist of individual presentations and group activities to stimulate\nideation and inspire broad reflections on the field of contestable AI. Our aim\nis to facilitate interdisciplinary dialogue by bringing together researchers,\npractitioners, and stakeholders to foster the design and deployment of\ncontestable AI.",
      "tldr_zh": "本研讨会聚焦于“contestable AI”在 AI value chains 中的应用，旨在建立一个跨学科的 CSCW 研究社区，并合成一个研究路线图来识别关键机会和挑战。通过个人演示、小组活动和混合形式（以面对面为主）的互动，参与者将讨论实际 AI 系统案例，包括成功、失败或潜在的可争辩场景。最终，该路线图将激发未来工作，推动在各种上下文中设计和部署 contestable AI 系统。",
      "categories": [
        "cs.AI",
        "cs.CY",
        "cs.HC"
      ],
      "primary_category": "cs.AI",
      "comment": "5 pages, 0 figure, to be held as a workshop at CSCW'24",
      "pdf_url": "http://arxiv.org/pdf/2408.01051v1",
      "published_date": "2024-08-02 06:57:52 UTC",
      "updated_date": "2024-08-02 06:57:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T12:32:27.221162"
    },
    {
      "arxiv_id": "2408.01024v2",
      "title": "Semantic Skill Grounding for Embodied Instruction-Following in Cross-Domain Environments",
      "title_zh": "翻译失败",
      "authors": [
        "Sangwoo Shin",
        "Seunghyun Kim",
        "Youngsoo Jang",
        "Moontae Lee",
        "Honguk Woo"
      ],
      "abstract": "In embodied instruction-following (EIF), the integration of pretrained\nlanguage models (LMs) as task planners emerges as a significant branch, where\ntasks are planned at the skill level by prompting LMs with pretrained skills\nand user instructions. However, grounding these pretrained skills in different\ndomains remains challenging due to their intricate entanglement with the\ndomain-specific knowledge. To address this challenge, we present a semantic\nskill grounding (SemGro) framework that leverages the hierarchical nature of\nsemantic skills. SemGro recognizes the broad spectrum of these skills, ranging\nfrom short-horizon low-semantic skills that are universally applicable across\ndomains to long-horizon rich-semantic skills that are highly specialized and\ntailored for particular domains. The framework employs an iterative skill\ndecomposition approach, starting from the higher levels of semantic skill\nhierarchy and then moving downwards, so as to ground each planned skill to an\nexecutable level within the target domain. To do so, we use the reasoning\ncapabilities of LMs for composing and decomposing semantic skills, as well as\ntheir multi-modal extension for assessing the skill feasibility in the target\ndomain. Our experiments in the VirtualHome benchmark show the efficacy of\nSemGro in 300 cross-domain EIF scenarios.",
      "tldr_zh": "本研究针对Embodied Instruction-Following (EIF)任务中，预训练语言模型 (LMs) 规划的技能难以在跨领域环境中地面的问题，提出了一种Semantic Skill Grounding (SemGro)框架。该框架利用语义技能的层次结构，从高层长视野技能开始，通过迭代分解和LMs的推理能力，将技能逐步转化为目标领域的可执行操作，同时使用多模态扩展评估技能可行性。在VirtualHome基准上的实验显示，SemGro在300个跨领域EIF场景中表现出色，证明了其有效性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Findings of ACL-2024 Camera Ready Version",
      "pdf_url": "http://arxiv.org/pdf/2408.01024v2",
      "published_date": "2024-08-02 05:50:31 UTC",
      "updated_date": "2024-08-21 01:46:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T12:32:49.738843"
    },
    {
      "arxiv_id": "2408.01018v4",
      "title": "GNN-SKAN: Harnessing the Power of SwallowKAN to Advance Molecular Representation Learning with GNNs",
      "title_zh": "翻译失败",
      "authors": [
        "Ruifeng Li",
        "Mingqian Li",
        "Wei Liu",
        "Hongyang Chen"
      ],
      "abstract": "Effective molecular representation learning is crucial for advancing\nmolecular property prediction and drug design. Mainstream molecular\nrepresentation learning approaches are based on Graph Neural Networks (GNNs).\nHowever, these approaches struggle with three significant challenges:\ninsufficient annotations, molecular diversity, and architectural limitations\nsuch as over-squashing, which leads to the loss of critical structural details.\nTo address these challenges, we introduce a new class of GNNs that integrates\nthe Kolmogorov-Arnold Networks (KANs), known for their robust data-fitting\ncapabilities and high accuracy in small-scale AI + Science tasks. By\nincorporating KANs into GNNs, our model enhances the representation of\nmolecular structures. We further advance this approach with a variant called\nSwallowKAN (SKAN), which employs adaptive Radial Basis Functions (RBFs) as the\ncore of the non-linear neurons. This innovation improves both computational\nefficiency and adaptability to diverse molecular structures. Building on the\nstrengths of SKAN, we propose a new class of GNNs, GNN-SKAN, and its augmented\nvariant, GNN-SKAN+, which incorporates a SKAN-based classifier to further boost\nperformance. To our knowledge, this is the first work to integrate KANs into\nGNN architectures tailored for molecular representation learning. Experiments\nacross 6 classification datasets, 6 regression datasets, and 4 few-shot\nlearning datasets demonstrate that our approach achieves new state-of-the-art\nperformance in terms of accuracy and computational cost.",
      "tldr_zh": "本文提出了一种新的 Graph Neural Networks (GNNs) 类，即 GNN-SKAN，通过整合 Kolmogorov-Arnold Networks (KANs) 来提升分子表示学习，解决标注不足、分子多样性和结构细节丢失等问题。GNN-SKAN 基于 SwallowKAN (SKAN) 创新，使用自适应 Radial Basis Functions (RBFs) 作为非线性神经元核心，提高计算效率和对多样分子结构的适应性。实验结果显示，GNN-SKAN 和其增强版 GNN-SKAN+ 在 6 个分类、6 个回归和 4 个少样本学习数据集上，实现了新的最先进性能，在准确性和计算成本方面均有显著提升。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "68T99",
        "J.2.4"
      ],
      "primary_category": "cs.LG",
      "comment": "10 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2408.01018v4",
      "published_date": "2024-08-02 05:36:14 UTC",
      "updated_date": "2024-11-09 14:22:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T12:32:54.207790"
    },
    {
      "arxiv_id": "2408.01016v1",
      "title": "IBB Traffic Graph Data: Benchmarking and Road Traffic Prediction Model",
      "title_zh": "翻译失败",
      "authors": [
        "Eren Olug",
        "Kiymet Kaya",
        "Resul Tugay",
        "Sule Gunduz Oguducu"
      ],
      "abstract": "Road traffic congestion prediction is a crucial component of intelligent\ntransportation systems, since it enables proactive traffic management, enhances\nsuburban experience, reduces environmental impact, and improves overall safety\nand efficiency. Although there are several public datasets, especially for\nmetropolitan areas, these datasets may not be applicable to practical scenarios\ndue to insufficiency in the scale of data (i.e. number of sensors and road\nlinks) and several external factors like different characteristics of the\ntarget area such as urban, highways and the data collection location. To\naddress this, this paper introduces a novel IBB Traffic graph dataset as an\nalternative benchmark dataset to mitigate these limitations and enrich the\nliterature with new geographical characteristics. IBB Traffic graph dataset\ncovers the sensor data collected at 2451 distinct locations. Moreover, we\npropose a novel Road Traffic Prediction Model that strengthens temporal links\nthrough feature engineering, node embedding with GLEE to represent\ninter-related relationships within the traffic network, and traffic prediction\nwith ExtraTrees. The results indicate that the proposed model consistently\noutperforms the baseline models, demonstrating an average accuracy improvement\nof 4%.",
      "tldr_zh": "本论文介绍了IBB Traffic Graph数据集，作为一种新的基准数据集，用于解决现有路交通预测数据集在规模（如传感器和道路链接数量）和区域特性（如城市或高速公路）方面的不足。该数据集涵盖了2451个不同位置的传感器数据，提供更丰富的地理特征以支持交通拥堵预测研究。同时，论文提出了一种新型Road Traffic Prediction Model，通过特征工程、GLEE节点嵌入来捕捉交通网络的互相关系，并使用ExtraTrees算法进行预测。实验结果显示，该模型比基线模型平均准确率提高了4%，为智能交通系统的优化提供了更可靠的工具。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.IT",
        "math.IT"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.01016v1",
      "published_date": "2024-08-02 05:23:19 UTC",
      "updated_date": "2024-08-02 05:23:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T12:33:09.583595"
    },
    {
      "arxiv_id": "2408.01008v1",
      "title": "Tensor Train Low-rank Approximation (TT-LoRA): Democratizing AI with Accelerated LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Afia Anjum",
        "Maksim E. Eren",
        "Ismael Boureima",
        "Boian Alexandrov",
        "Manish Bhattarai"
      ],
      "abstract": "In recent years, Large Language Models (LLMs) have demonstrated remarkable\ncapabilities across a wide range of natural language processing (NLP) tasks,\nsuch as question-answering, sentiment analysis, text summarization, and machine\ntranslation. However, the ever-growing complexity of LLMs demands immense\ncomputational resources, hindering the broader research and application of\nthese models. To address this, various parameter-efficient fine-tuning\nstrategies, such as Low-Rank Approximation (LoRA) and Adapters, have been\ndeveloped. Despite their potential, these methods often face limitations in\ncompressibility. Specifically, LoRA struggles to scale effectively with the\nincreasing number of trainable parameters in modern large scale LLMs.\nAdditionally, Low-Rank Economic Tensor-Train Adaptation (LoRETTA), which\nutilizes tensor train decomposition, has not yet achieved the level of\ncompression necessary for fine-tuning very large scale models with limited\nresources. This paper introduces Tensor Train Low-Rank Approximation (TT-LoRA),\na novel parameter-efficient fine-tuning (PEFT) approach that extends LoRETTA\nwith optimized tensor train (TT) decomposition integration. By eliminating\nAdapters and traditional LoRA-based structures, TT-LoRA achieves greater model\ncompression without compromising downstream task performance, along with\nreduced inference latency and computational overhead. We conduct an exhaustive\nparameter search to establish benchmarks that highlight the trade-off between\nmodel compression and performance. Our results demonstrate significant\ncompression of LLMs while maintaining comparable performance to larger models,\nfacilitating their deployment on resource-constraint platforms.",
      "tldr_zh": "本研究针对大型语言模型（LLMs）的计算资源需求问题，提出了一种新型参数高效微调（PEFT）方法——Tensor Train Low-rank Approximation (TT-LoRA)，以扩展Low-Rank Approximation (LoRA) 和Low-Rank Economic Tensor-Train Adaptation (LoRETTA)的局限性。TT-LoRA 通过优化tensor train (TT) decomposition，消除Adapters和传统LoRA结构，实现更高的模型压缩，同时减少推理延迟和计算开销。实验结果显示，该方法在保持下游任务性能的同时显著压缩LLMs，并通过参数搜索建立了基准，便于在资源受限平台上部署，推动AI的民主化。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "LA-UR-24-28177",
      "pdf_url": "http://arxiv.org/pdf/2408.01008v1",
      "published_date": "2024-08-02 04:45:58 UTC",
      "updated_date": "2024-08-02 04:45:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T12:33:18.547440"
    },
    {
      "arxiv_id": "2408.01003v1",
      "title": "Piculet: Specialized Models-Guided Hallucination Decrease for MultiModal Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Kohou Wang",
        "Xiang Liu",
        "Zhaoxiang Liu",
        "Kai Wang",
        "Shiguo Lian"
      ],
      "abstract": "Multimodal Large Language Models (MLLMs) have made significant progress in\nbridging the gap between visual and language modalities. However,\nhallucinations in MLLMs, where the generated text does not align with image\ncontent, continue to be a major challenge. Existing methods for addressing\nhallucinations often rely on instruction-tuning, which requires retraining the\nmodel with specific data, which increases the cost of utilizing MLLMs further.\nIn this paper, we introduce a novel training-free method, named Piculet, for\nenhancing the input representation of MLLMs. Piculet leverages multiple\nspecialized models to extract descriptions of visual information from the input\nimage and combine these descriptions with the original image and query as input\nto the MLLM. We evaluate our method both quantitively and qualitatively, and\nthe results demonstrate that Piculet greatly decreases hallucinations of MLLMs.\nOur method can be easily extended to different MLLMs while being universal.",
      "tldr_zh": "本文提出 Piculet，一种无需训练的训练-free 方法，用于减少 Multimodal Large Language Models (MLLMs) 中的 hallucination，即生成的文本与图像内容不一致的问题。Piculet 利用多个 specialized models 从输入图像中提取视觉信息描述，并将这些描述与原始图像和查询结合，作为输入提供给 MLLM，从而增强输入表示。实验结果显示，Piculet 通过定量和定性评估显著降低了 hallucination，且易于扩展到不同 MLLMs，具有通用性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "14 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2408.01003v1",
      "published_date": "2024-08-02 04:34:37 UTC",
      "updated_date": "2024-08-02 04:34:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T12:33:30.567907"
    },
    {
      "arxiv_id": "2408.00998v2",
      "title": "FBSDiff: Plug-and-Play Frequency Band Substitution of Diffusion Features for Highly Controllable Text-Driven Image Translation",
      "title_zh": "FBSDiff：即插即用式扩散特征频带替换，用于高度可控的文本驱动图像翻译",
      "authors": [
        "Xiang Gao",
        "Jiaying Liu"
      ],
      "abstract": "Large-scale text-to-image diffusion models have been a revolutionary\nmilestone in the evolution of generative AI and multimodal technology, allowing\nwonderful image generation with natural-language text prompt. However, the\nissue of lacking controllability of such models restricts their practical\napplicability for real-life content creation. Thus, attention has been focused\non leveraging a reference image to control text-to-image synthesis, which is\nalso regarded as manipulating (or editing) a reference image as per a text\nprompt, namely, text-driven image-to-image translation. This paper contributes\na novel, concise, and efficient approach that adapts pre-trained large-scale\ntext-to-image (T2I) diffusion model to the image-to-image (I2I) paradigm in a\nplug-and-play manner, realizing high-quality and versatile text-driven I2I\ntranslation without any model training, model fine-tuning, or online\noptimization process. To guide T2I generation with a reference image, we\npropose to decompose diverse guiding factors with different frequency bands of\ndiffusion features in the DCT spectral space, and accordingly devise a novel\nfrequency band substitution layer which realizes dynamic control of the\nreference image to the T2I generation result in a plug-and-play manner. We\ndemonstrate that our method allows flexible control over both guiding factor\nand guiding intensity of the reference image simply by tuning the type and\nbandwidth of the substituted frequency band, respectively. Extensive\nqualitative and quantitative experiments verify superiority of our approach\nover related methods in I2I translation visual quality, versatility, and\ncontrollability. The code is publicly available at:\nhttps://github.com/XiangGao1102/FBSDiff.",
      "tldr_zh": "该论文提出 FBSDiff，一种插件式（plug-and-play）方法，用于实现高度可控的文本驱动图像翻译（Text-Driven Image Translation），无需任何模型训练或微调。核心技术是将扩散特征（Diffusion Features）在 DCT 频谱空间分解为不同频率带，并设计频率带替代层（Frequency Band Substitution）来动态控制参考图像的引导因素和强度。实验结果显示，该方法在图像到图像（I2I）翻译的视觉质量、多功能性和可控性方面优于相关方法，提供灵活的控制选项。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted conference paper of ACM MM 2024",
      "pdf_url": "http://arxiv.org/pdf/2408.00998v2",
      "published_date": "2024-08-02 04:13:38 UTC",
      "updated_date": "2024-08-06 12:01:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T12:33:43.143821"
    },
    {
      "arxiv_id": "2408.00997v1",
      "title": "A Safe Exploration Strategy for Model-free Task Adaptation in Safety-constrained Grid Environments",
      "title_zh": "一种安全探索策略，用于无模型任务适应在安全约束网格环境",
      "authors": [
        "Erfan Entezami",
        "Mahsa Sahebdel",
        "Dhawal Gupta"
      ],
      "abstract": "Training a model-free reinforcement learning agent requires allowing the\nagent to sufficiently explore the environment to search for an optimal policy.\nIn safety-constrained environments, utilizing unsupervised exploration or a\nnon-optimal policy may lead the agent to undesirable states, resulting in\noutcomes that are potentially costly or hazardous for both the agent and the\nenvironment. In this paper, we introduce a new exploration framework for\nnavigating the grid environments that enables model-free agents to interact\nwith the environment while adhering to safety constraints. Our framework\nincludes a pre-training phase, during which the agent learns to identify\npotentially unsafe states based on both observable features and specified\nsafety constraints in the environment. Subsequently, a binary classification\nmodel is trained to predict those unsafe states in new environments that\nexhibit similar dynamics. This trained classifier empowers model-free agents to\ndetermine situations in which employing random exploration or a suboptimal\npolicy may pose safety risks, in which case our framework prompts the agent to\nfollow a predefined safe policy to mitigate the potential for hazardous\nconsequences. We evaluated our framework on three randomly generated grid\nenvironments and demonstrated how model-free agents can safely adapt to new\ntasks and learn optimal policies for new environments. Our results indicate\nthat by defining an appropriate safe policy and utilizing a well-trained model\nto detect unsafe states, our framework enables a model-free agent to adapt to\nnew tasks and environments with significantly fewer safety violations.",
      "tldr_zh": "该研究提出了一种安全探索策略，用于无模型强化学习（model-free reinforcement learning）代理在安全约束网格环境（safety-constrained grid environments）中适应新任务。该框架包括预训练阶段，让代理基于可观察特征和安全约束学习识别潜在不安全状态，随后训练一个二元分类模型（binary classification model）来预测新环境中的风险，并在检测到危险时切换到预定义的安全策略。实验在三个随机生成的网格环境中进行，结果显示，该策略显著减少了安全违规次数，同时使代理能够高效学习最优策略。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.00997v1",
      "published_date": "2024-08-02 04:09:30 UTC",
      "updated_date": "2024-08-02 04:09:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T12:33:54.401960"
    },
    {
      "arxiv_id": "2408.00996v1",
      "title": "IncidentNet: Traffic Incident Detection, Localization and Severity Estimation with Sparse Sensing",
      "title_zh": "IncidentNet: 基于稀疏传感的交通事故检测、定位和严重程度估计",
      "authors": [
        "Sai Shashank Peddiraju",
        "Kaustubh Harapanahalli",
        "Edward Andert",
        "Aviral Shrivastava"
      ],
      "abstract": "Prior art in traffic incident detection relies on high sensor coverage and is\nprimarily based on decision-tree and random forest models that have limited\nrepresentation capacity and, as a result, cannot detect incidents with high\naccuracy. This paper presents IncidentNet - a novel approach for classifying,\nlocalizing, and estimating the severity of traffic incidents using deep\nlearning models trained on data captured from sparsely placed sensors in urban\nenvironments. Our model works on microscopic traffic data that can be collected\nusing cameras installed at traffic intersections. Due to the unavailability of\ndatasets that provide microscopic traffic details and traffic incident details\nsimultaneously, we also present a methodology to generate a synthetic\nmicroscopic traffic dataset that matches given macroscopic traffic data.\nIncidentNet achieves a traffic incident detection rate of 98%, with false alarm\nrates of less than 7% in 197 seconds on average in urban environments with\ncameras on less than 20% of the traffic intersections.",
      "tldr_zh": "本研究提出 IncidentNet，一种基于深度学习模型的新方法，用于在稀疏传感器覆盖的城市环境中，对交通事故进行检测、定位和严重程度估计。该方法利用安装在交通路口的摄像头捕获微观交通数据，并引入一种合成数据集生成技术，以弥补缺乏同时包含微观交通和事故细节的真实数据集问题。与传统决策树和随机森林模型相比，IncidentNet 在不到20% 交通路口摄像头的条件下，实现了98% 的事故检测率、低于7% 的假警报率，并平均在197秒内完成检测。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "6 pages, 6 figures, 2024 IEEE 27th International Conference on\n  Intelligent Transportation Systems (ITSC)",
      "pdf_url": "http://arxiv.org/pdf/2408.00996v1",
      "published_date": "2024-08-02 04:09:15 UTC",
      "updated_date": "2024-08-02 04:09:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T12:34:06.313961"
    },
    {
      "arxiv_id": "2408.00994v1",
      "title": "ArchCode: Incorporating Software Requirements in Code Generation with Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Hojae Han",
        "Jaejin Kim",
        "Jaeseok Yoo",
        "Youngwon Lee",
        "Seung-won Hwang"
      ],
      "abstract": "This paper aims to extend the code generation capability of large language\nmodels (LLMs) to automatically manage comprehensive software requirements from\ngiven textual descriptions. Such requirements include both functional (i.e.\nachieving expected behavior for inputs) and non-functional (e.g., time/space\nperformance, robustness, maintainability) requirements. However, textual\ndescriptions can either express requirements verbosely or may even omit some of\nthem. We introduce ARCHCODE, a novel framework that leverages in-context\nlearning to organize requirements observed in descriptions and to extrapolate\nunexpressed requirements from them. ARCHCODE generates requirements from given\ndescriptions, conditioning them to produce code snippets and test cases. Each\ntest case is tailored to one of the requirements, allowing for the ranking of\ncode snippets based on the compliance of their execution results with the\nrequirements. Public benchmarks show that ARCHCODE enhances to satisfy\nfunctional requirements, significantly improving Pass@k scores. Furthermore, we\nintroduce HumanEval-NFR, the first evaluation of LLMs' non-functional\nrequirements in code generation, demonstrating ARCHCODE's superiority over\nbaseline methods. The implementation of ARCHCODE and the HumanEval-NFR\nbenchmark are both publicly accessible.",
      "tldr_zh": "这篇论文提出了 ArchCode 框架，用于在大型语言模型 (LLMs) 的代码生成中自动整合软件需求，包括功能需求（如预期行为）和非功能需求（如性能和鲁棒性）。ArchCode 利用 in-context learning 来组织描述中的需求、推断未表达的需求，并生成代码片段及针对每个需求的测试用例，从而通过测试结果排名代码的符合性。实验结果显示，ArchCode 显著提升了功能需求的满足率，提高了 Pass@k 分数，并在新引入的 HumanEval-NFR 基准上优于基线方法，所有实现和基准已公开可用。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.SE",
      "comment": "Accepted by ACL 2024 main conference",
      "pdf_url": "http://arxiv.org/pdf/2408.00994v1",
      "published_date": "2024-08-02 03:54:36 UTC",
      "updated_date": "2024-08-02 03:54:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T12:34:19.702310"
    },
    {
      "arxiv_id": "2408.00989v3",
      "title": "On the Resilience of LLM-Based Multi-Agent Collaboration with Faulty Agents",
      "title_zh": "翻译失败",
      "authors": [
        "Jen-tse Huang",
        "Jiaxu Zhou",
        "Tailin Jin",
        "Xuhui Zhou",
        "Zixi Chen",
        "Wenxuan Wang",
        "Youliang Yuan",
        "Michael R. Lyu",
        "Maarten Sap"
      ],
      "abstract": "Large language model-based multi-agent systems have shown great abilities\nacross various tasks due to the collaboration of expert agents, each focusing\non a specific domain. However, the impact of clumsy or even malicious agents,\ni.e., those who frequently make errors in their tasks, on the overall\nperformance of the system remains underexplored. This paper investigates: (1)\nWhat is the resilience of various system structures (e.g.,\nA$\\rightarrow$B$\\rightarrow$C, A$\\leftrightarrow$B$\\leftrightarrow$C) under\nfaulty agents, on different downstream tasks? (2) How can we increase system\nresilience to defend against these agents? To simulate faulty agents, we\npropose two approaches, AutoTransform and AutoInject, which introduce mistakes\ninto the agents' responses. We select four downstream tasks, including code\ngeneration, math problems, translation, and text evaluation. Results suggest\nthat the hierarchical structure, i.e., A$\\rightarrow$(B$\\leftrightarrow$C),\nexhibits superior resilience with the lowest performance drop of $9.2\\%$,\ncompared to $26.0\\%$ and $31.2\\%$ of other two structures. Additionally, we\nimprove the system resilience with two methods, introducing a mechanism for\neach agent to challenge others' outputs, and an additional agent to review and\ncorrect messages. Our code and data are available at\nhttps://github.com/CUHK-ARISE/MAS-Resilience.",
      "tldr_zh": "本研究探讨了基于大型语言模型(LLM)的多智能体系统在存在故障代理（如笨拙或恶意代理）时的弹性，重点调查不同系统结构（如 A→B→C 和 A↔B↔C）在代码生成、数学问题、翻译和文本评估等下游任务中的表现。作者提出 AutoTransform 和 AutoInject 两种方法来模拟代理错误，并通过实验发现，层次结构 A→(B↔C) 显示出最高的弹性，性能下降仅为 9.2%，远低于其他结构的 26.0% 和 31.2%。为了提升系统弹性，该论文引入了代理间挑战机制和额外审查代理来修正消息，为构建更可靠的多智能体协作提供实用策略。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "9 pages of main text; 11 pages of appendix",
      "pdf_url": "http://arxiv.org/pdf/2408.00989v3",
      "published_date": "2024-08-02 03:25:20 UTC",
      "updated_date": "2025-01-28 07:45:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T12:34:30.954443"
    },
    {
      "arxiv_id": "2408.00986v1",
      "title": "A SAT-based approach to rigorous verification of Bayesian networks",
      "title_zh": "翻译失败",
      "authors": [
        "Ignacy Stępka",
        "Nicholas Gisolfi",
        "Artur Dubrawski"
      ],
      "abstract": "Recent advancements in machine learning have accelerated its widespread\nadoption across various real-world applications. However, in safety-critical\ndomains, the deployment of machine learning models is riddled with challenges\ndue to their complexity, lack of interpretability, and absence of formal\nguarantees regarding their behavior. In this paper, we introduce a verification\nframework tailored for Bayesian networks, designed to address these drawbacks.\nOur framework comprises two key components: (1) a two-step compilation and\nencoding scheme that translates Bayesian networks into Boolean logic literals,\nand (2) formal verification queries that leverage these literals to verify\nvarious properties encoded as constraints. Specifically, we introduce two\nverification queries: if-then rules (ITR) and feature monotonicity (FMO). We\nbenchmark the efficiency of our verification scheme and demonstrate its\npractical utility in real-world scenarios.",
      "tldr_zh": "这篇论文提出了一种基于 SAT 的方法，用于严格验证 Bayesian networks，以解决机器学习在安全关键领域面临的复杂性、可解释性不足和缺乏正式保证等问题。框架的核心包括一个两步编译和编码方案，将 Bayesian networks 转化为 Boolean logic literals，以及利用这些 literals 进行属性验证的查询。论文具体引入了 if-then rules (ITR) 和 feature monotonicity (FMO) 两种验证查询，以检查网络的特定属性。通过基准测试，该方法展示了高效性和在真实场景中的实用价值。",
      "categories": [
        "cs.AI",
        "cs.LO"
      ],
      "primary_category": "cs.AI",
      "comment": "Workshop on Explainable and Robust AI for Industry 4.0 & 5.0 (X-RAI)\n  at European Conference on Machine Learning and Principles and Practice of\n  Knowledge Discovery in Databases (2024)",
      "pdf_url": "http://arxiv.org/pdf/2408.00986v1",
      "published_date": "2024-08-02 03:06:51 UTC",
      "updated_date": "2024-08-02 03:06:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T12:34:46.286823"
    },
    {
      "arxiv_id": "2408.00965v2",
      "title": "Integrating ESG and AI: A Comprehensive Responsible AI Assessment Framework",
      "title_zh": "整合 ESG 与 AI：一个全面负责任 AI ",
      "authors": [
        "Sung Une Lee",
        "Harsha Perera",
        "Yue Liu",
        "Boming Xia",
        "Qinghua Lu",
        "Liming Zhu",
        "Jessica Cairns",
        "Moana Nottage"
      ],
      "abstract": "Artificial Intelligence (AI) is a widely developed and adopted technology\nacross entire industry sectors. Integrating environmental, social, and\ngovernance (ESG) considerations with AI investments is crucial for ensuring\nethical and sustainable technological advancement. Particularly from an\ninvestor perspective, this integration not only mitigates risks but also\nenhances long-term value creation by aligning AI initiatives with broader\nsocietal goals. Yet, this area has been less explored in both academia and\nindustry. To bridge the gap, we introduce a novel ESG-AI framework, which is\ndeveloped based on insights from engagements with 28 companies and comprises\nthree key components. The framework provides a structured approach to this\nintegration, developed in collaboration with industry practitioners. The ESG-AI\nframework provides an overview of the environmental and social impacts of AI\napplications, helping users such as investors assess the materiality of AI use.\nMoreover, it enables investors to evaluate a company's commitment to\nresponsible AI through structured engagements and thorough assessment of\nspecific risk areas. We have publicly released the framework and toolkit in\nApril 2024, which has received significant attention and positive feedback from\nthe investment community. This paper details each component of the framework,\ndemonstrating its applicability in real-world contexts and its potential to\nguide ethical AI investments.",
      "tldr_zh": "本论文提出一个名为ESG-AI的综合框架，用于整合环境、社会和治理（ESG）因素与AI投资，确保AI发展的伦理性和可持续性。该框架基于与28家公司的互动开发，包含三个关键组件，提供结构化方法来评估AI应用对环境和社会的影响，并帮助投资者识别相关风险和公司承诺。框架已于2024年4月公开发布，获得投资社区的积极反馈，并在实际情境中指导负责任的AI投资决策。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "23 pages, 8 tables, 10 figures",
      "pdf_url": "http://arxiv.org/pdf/2408.00965v2",
      "published_date": "2024-08-02 00:58:01 UTC",
      "updated_date": "2024-08-06 00:12:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T12:34:54.337583"
    },
    {
      "arxiv_id": "2408.00960v1",
      "title": "PERSOMA: PERsonalized SOft ProMpt Adapter Architecture for Personalized Language Prompting",
      "title_zh": "翻译失败",
      "authors": [
        "Liam Hebert",
        "Krishna Sayana",
        "Ambarish Jash",
        "Alexandros Karatzoglou",
        "Sukhdeep Sodhi",
        "Sumanth Doddapaneni",
        "Yanli Cai",
        "Dima Kuzmin"
      ],
      "abstract": "Understanding the nuances of a user's extensive interaction history is key to\nbuilding accurate and personalized natural language systems that can adapt to\nevolving user preferences. To address this, we introduce PERSOMA, Personalized\nSoft Prompt Adapter architecture. Unlike previous personalized prompting\nmethods for large language models, PERSOMA offers a novel approach to\nefficiently capture user history. It achieves this by resampling and\ncompressing interactions as free form text into expressive soft prompt\nembeddings, building upon recent research utilizing embedding representations\nas input for LLMs. We rigorously validate our approach by evaluating various\nadapter architectures, first-stage sampling strategies, parameter-efficient\ntuning techniques like LoRA, and other personalization methods. Our results\ndemonstrate PERSOMA's superior ability to handle large and complex user\nhistories compared to existing embedding-based and text-prompt-based\ntechniques.",
      "tldr_zh": "该研究提出PERSOMA，一种个性化软提示适配器（Personalized Soft Prompt Adapter）架构，用于构建适应用户偏好的自然语言系统。该方法通过重新采样和压缩用户互动历史为自由形式文本，并转换为表达性的软提示嵌入，基于LLMs（Large Language Models）的输入表示，高效捕捉用户历史。与现有技术相比，PERSOMA结合了各种适配器架构、采样策略和参数高效调优如LoRA，实验结果显示其在处理大型复杂用户历史方面表现出色，优于基于嵌入和文本提示的方法。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.00960v1",
      "published_date": "2024-08-02 00:24:22 UTC",
      "updated_date": "2024-08-02 00:24:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T12:35:09.921763"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 71,
  "processed_papers_count": 71,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-19T12:35:47.937053"
}