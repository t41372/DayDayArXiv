{
  "date": "2024-11-02",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-11-02 的 arXiv 中文 TLDR 快报！今天 arXiv 更新了 54 篇论文，主要聚焦于 AI 和机器学习的创新应用，包括强化学习、生成模型、联邦学习和医疗图像处理等领域，亮点是 NeurIPS 接受的多篇论文（如强化学习和扩散模型优化）以及知名机构（如 OpenAI）的安全研究，强调了模型鲁棒性、隐私保护和高效计算的趋势。\n\n### 重点论文讨论\n我将优先讨论令人印象深刻、可能有话题度的论文，如 NeurIPS 相关工作和知名学者贡献，并将相关主题归类讨论。其他次要论文将简要掠过，以控制篇幅。\n\n#### AI 安全与解释性（NeurIPS 亮点）\n- **利用人类行为建模操纵 AI 解释（Utilizing Human Behavior Modeling to Manipulate Explanations in AI-Assisted Decision Making: The Good, the Bad, and the Scary）**  \n  作者包括 Ming Yin，这篇论文揭示了 AI 解释如何被操纵以影响决策，主要贡献是通过实验证明人类行为模型可用于定向操控解释，导致决策偏差；发现即使意图良性，也可能被滥用，强调了 AI 解释的潜在风险。\n  \n- **What Features in Prompts Jailbreak LLMs? Investigating the Mechanisms Behind Attacks**  \n  作者 Stephen Casper 等研究了 LLM 越狱攻击机制，主要贡献是使用非线性探针分析提示特征，证明不同攻击策略依赖非通用特征；发现这可用于增强模型鲁棒性，但攻击难以通过简单线性方法检测。\n\n- **Privacy Leakage Overshadowed by Views of AI: A Study on Human Oversight of Privacy in Language Model Agent**  \n  这篇论文探讨 LLM 代理的隐私泄露，主要贡献是通过用户调查发现人们倾向于接受泄露更多隐私的响应，导致有害披露率从 15.7% 上升至 55.0%；提出六种隐私配置文件，帮助设计隐私保护的 LLM 系统。\n\n这些论文突出了 AI 安全和解释性的挑战，NeurIPS 接受的作品（如 #8）可能推动未来研究。\n\n#### 生成模型与强化学习（NeurIPS 和高效计算焦点）\n- **Adaptive World Models: Learning Behaviors by Latent Imagination Under Non-Stationarity**  \n  作者 Gerhard Neumann 等提出 Hidden Parameter-POMDP 框架，主要贡献是让强化学习模型在非平稳环境中学习鲁棒行为；发现该方法能无监督学习任务抽象，提升泛化能力，已被 NeurIPS 2024 接受。\n\n- **Visual Fourier Prompt Tuning**  \n  作者 Ying Nian Wu 等创新了视觉提示调优方法，主要贡献是结合快速傅立叶变换处理空间和频率域信息，提升预训练模型在数据差异大的任务中的性能；实验显示在 VTAB-1k 上精度达 73.20%，参数使用率仅 0.57%。\n\n- **Fast and Memory-Efficient Video Diffusion Using Streamlined Inference**  \n  这篇论文优化了视频扩散模型，主要贡献是通过特征切分和操作分组减少 GPU 内存使用，实现 7.5 倍吞吐量提升；发现新方法在 T4 和 H100 GPU 上保持高质量生成，显著降低了计算开销。\n\n这些作品展示了生成模型的效率提升，NeurIPS 相关（如 #6 和 #10）强调了实际部署潜力。\n\n#### 医疗与生物应用（实际影响强）\n- **Guided Synthesis of Labeled Brain MRI Data Using Latent Diffusion Models for Segmentation of Enlarged Ventricles**  \n  作者如 Ulrich Lindberg 使用潜在扩散模型合成脑 MRI 数据，主要贡献是改进脑室分割，合成数据训练的模型 MAE 降至 6.23 mL，Dice 分数达 0.892；发现此方法超越现有状态如 SynthSeg，提升了诊断准确性。\n\n- **Medical X-Ray Image Enhancement Using Global Contrast-Limited Adaptive Histogram Equalization**  \n  提出 G-CLAHE 方法，主要贡献是平衡局部和全局图像特征，提升 X 射线图像对比度；实验证明它改善了诊断精度，解决了传统方法（如 CLAHE）的局限。\n\n这些论文在医疗 AI 领域有直接应用，#4 的扩散模型创新特别值得关注。\n\n#### 联邦学习与隐私保护（高效和隐私焦点）\n- **FEED: Fairness-Enhanced Meta-Learning for Domain Generalization**  \n  作者如 Feng Chen 设计了公平增强元学习框架，主要贡献是解耦数据表示为内容、风格和敏感向量，提升模型在分布偏移下的泛化公平性；实验显示在基准数据集上准确性和公平性均优于现有方法。\n\n- **Boosting Federated Learning with FedEntOpt: Mitigating Label Skew by Entropy-Based Client Selection**  \n  这篇论文提出 FedEntOpt 方法，主要贡献是通过熵最大化选择客户端，缓解标签分布偏差；发现它在低参与率场景下准确率提升 30%，适用于分布式学习。\n\n联邦学习论文如 #11 和 #22 强调隐私和效率，适合实际部署场景。\n\n### 其他论文快速掠过\n剩余论文涉及多样主题，如强化学习代理（#20，由 Vikram Krishnamurthy 等），量子计算（#54），和生物信息学（#53）。例如，**GarmentLab: A Unified Simulation and Benchmark for Garment Manipulation** 构建了服装操纵基准，主要贡献是整合多模拟方法缩小模拟到真实差距；**Rule Based Rewards for Language Model Safety** （OpenAI 相关）使用规则奖励提升 LLM 安全，F1 分数达 97.1%。这些论文虽有价值，但非核心焦点，仅提及其创新点以控制篇幅。\n\n总之，今天的 arXiv 快报展示了 AI 领域的快速进展，NeurIPS 论文和医疗应用尤为突出，读者可关注安全与高效主题以寻找感兴趣方向。保持关注，未来更新将带来更多洞见！",
  "papers": [
    {
      "arxiv_id": "2411.01375v3",
      "title": "Learning with Hidden Factorial Structure",
      "title_zh": "翻译失败",
      "authors": [
        "Charles Arnal",
        "Clement Berenfeld",
        "Simon Rosenberg",
        "Vivien Cabannes"
      ],
      "abstract": "Statistical learning in high-dimensional spaces is challenging without a\nstrong underlying data structure. Recent advances with foundational models\nsuggest that text and image data contain such hidden structures, which help\nmitigate the curse of dimensionality. Inspired by results from nonparametric\nstatistics, we hypothesize that this phenomenon can be partially explained in\nterms of decomposition of complex tasks into simpler subtasks. In this paper,\nwe present a controlled experimental framework to test whether neural networks\ncan indeed exploit such \"hidden factorial structures\". We find that they do\nleverage these latent patterns to learn discrete distributions more\nefficiently. We also study the interplay between our structural assumptions and\nthe models' capacity for generalization.",
      "tldr_zh": "本研究探讨了高维空间中统计学习的挑战，假设复杂任务可分解为更简单的子任务，从而利用隐藏因子结构（hidden factorial structures）缓解维数灾难（curse of dimensionality）。作者提出一个受控实验框架，测试神经网络是否能有效利用这些潜在模式，发现神经网络确实能更高效地学习离散分布。研究还分析了这些结构假设与模型泛化能力之间的相互作用，为理解基础模型在文本和图像数据中的性能提供了新见解。",
      "categories": [
        "stat.ML",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "stat.ML",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.01375v3",
      "published_date": "2024-11-02 22:32:53 UTC",
      "updated_date": "2025-02-02 22:25:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T20:22:33.848914"
    },
    {
      "arxiv_id": "2411.01373v1",
      "title": "Medical X-Ray Image Enhancement Using Global Contrast-Limited Adaptive Histogram Equalization",
      "title_zh": "翻译失败",
      "authors": [
        "Sohrab Namazi Nia",
        "Frank Y. Shih"
      ],
      "abstract": "In medical imaging, accurate diagnosis heavily relies on effective image\nenhancement techniques, particularly for X-ray images. Existing methods often\nsuffer from various challenges such as sacrificing global image characteristics\nover local image characteristics or vice versa. In this paper, we present a\nnovel approach, called G-CLAHE (Global-Contrast Limited Adaptive Histogram\nEqualization), which perfectly suits medical imaging with a focus on X-rays.\nThis method adapts from Global Histogram Equalization (GHE) and Contrast\nLimited Adaptive Histogram Equalization (CLAHE) to take both advantages and\navoid weakness to preserve local and global characteristics. Experimental\nresults show that it can significantly improve current state-of-the-art\nalgorithms to effectively address their limitations and enhance the contrast\nand quality of X-ray images for diagnostic accuracy.",
      "tldr_zh": "本研究针对医疗X-ray图像增强的挑战，提出了一种新方法G-CLAHE（Global-Contrast Limited Adaptive Histogram Equalization），它结合了Global Histogram Equalization (GHE)和Contrast Limited Adaptive Histogram Equalization (CLAHE)的优势，同时避免了它们各自的缺点，以平衡局部和全局图像特征。G-CLAHE能够有效提升X-ray图像的对比度和质量，而不会牺牲整体特性。实验结果显示，该方法显著优于现有算法，提高了诊断准确性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.01373v1",
      "published_date": "2024-11-02 22:20:56 UTC",
      "updated_date": "2024-11-02 22:20:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T20:20:52.431699"
    },
    {
      "arxiv_id": "2411.01354v1",
      "title": "Online and Offline Evaluations of Collaborative Filtering and Content Based Recommender Systems",
      "title_zh": "在线与离线评估协同过滤和基于内容的推荐系统",
      "authors": [
        "Ali Elahi",
        "Armin Zirak"
      ],
      "abstract": "Recommender systems are widely used AI applications designed to help users\nefficiently discover relevant items. The effectiveness of such systems is tied\nto the satisfaction of both users and providers. However, user satisfaction is\ncomplex and cannot be easily framed mathematically using information retrieval\nand accuracy metrics. While many studies evaluate accuracy through offline\ntests, a growing number of researchers argue that online evaluation methods\nsuch as A/B testing are better suited for this purpose. We have employed a\nvariety of algorithms on different types of datasets divergent in size and\nsubject, producing recommendations in various platforms, including media\nstreaming services, digital publishing websites, e-commerce systems, and news\nbroadcasting networks. Notably, our target websites and datasets are in Persian\n(Farsi) language.\n  This study provides a comparative analysis of a large-scale recommender\nsystem that has been operating for the past year across about 70 websites in\nIran, processing roughly 300 requests per second collectively. The system\nemploys user-based and item-based recommendations using content-based,\ncollaborative filtering, trend-based methods, and hybrid approaches. Through\nboth offline and online evaluations, we aim to identify where these algorithms\nperform most efficiently and determine the best method for our specific needs,\nconsidering the dataset and system scale. Our methods of evaluation include\nmanual evaluation, offline tests including accuracy and ranking metrics like\nhit-rate@k and nDCG, and online tests consisting of click-through rate (CTR).\nAdditionally we analyzed and proposed methods to address cold-start and\npopularity bias.",
      "tldr_zh": "这篇论文比较了协同过滤(collaborative filtering)和基于内容的推荐系统的离线和在线评估方法，强调在线评估如A/B testing更能反映用户满意度。作者在波斯语(Farsi)数据集和各种平台（如媒体流媒体、电商和新闻网站）上测试了多种算法，包括content-based、collaborative filtering、trend-based和混合方法，并通过手动评估、离线指标如hit-rate@k和nDCG、在线指标如CTR进行全面分析。研究还探讨了cold-start和popularity bias问题，并提出解决方案，最终识别出这些算法在处理大规模系统（如伊朗70个网站、300请求/秒）时的最佳应用场景。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.IR",
      "comment": "9 pages, 9 figures",
      "pdf_url": "http://arxiv.org/pdf/2411.01354v1",
      "published_date": "2024-11-02 20:05:31 UTC",
      "updated_date": "2024-11-02 20:05:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T20:21:05.979894"
    },
    {
      "arxiv_id": "2411.01351v1",
      "title": "Guided Synthesis of Labeled Brain MRI Data Using Latent Diffusion Models for Segmentation of Enlarged Ventricles",
      "title_zh": "利用潜在扩散模型引导合成标记脑部 MRI 数据以分割",
      "authors": [
        "Tim Ruschke",
        "Jonathan Frederik Carlsen",
        "Adam Espe Hansen",
        "Ulrich Lindberg",
        "Amalie Monberg Hindsholm",
        "Martin Norgaard",
        "Claes Nøhr Ladefoged"
      ],
      "abstract": "Deep learning models in medical contexts face challenges like data scarcity,\ninhomogeneity, and privacy concerns. This study focuses on improving\nventricular segmentation in brain MRI images using synthetic data. We employed\ntwo latent diffusion models (LDMs): a mask generator trained using 10,000\nmasks, and a corresponding SPADE image generator optimized using 6,881 scans to\ncreate an MRI conditioned on a 3D brain mask. Conditioning the mask generator\non ventricular volume in combination with classifier-free guidance enabled the\ncontrol of the ventricular volume distribution of the generated synthetic\nimages. Next, the performance of the synthetic data was tested using three\nnnU-Net segmentation models trained on a real, augmented and entirely synthetic\ndata, respectively. The resulting models were tested on a completely\nindependent hold-out dataset of patients with enlarged ventricles, with manual\ndelineation of the ventricles used as ground truth. The model trained on real\ndata showed a mean absolute error (MAE) of 9.09 \\pm 12.18 mL in predicted\nventricular volume, while the models trained on synthetic and augmented data\nshowed MAEs of 7.52 \\pm 4.81 mL and 6.23 \\pm 4.33 mL, respectively. Both the\nsynthetic and augmented model also outperformed the state-of-the-art model\nSynthSeg, which due to limited performance in cases of large ventricular\nvolumes, showed an MAE of 7.73 \\pm 12.12 mL with a factor of 3 higher standard\ndeviation. The model trained on augmented data showed the highest Dice score of\n0.892 \\pm 0.05, slightly outperforming SynthSeg and on par with the model\ntrained on real data. The synthetic model performed similar to SynthSeg. In\nsummary, we provide evidence that guided synthesis of labeled brain MRI data\nusing LDMs improves the segmentation of enlarged ventricles and outperforms\nexisting state-of-the-art segmentation models.",
      "tldr_zh": "这篇论文提出了一种使用 Latent Diffusion Models (LDMs) 引导合成标记脑 MRI 数据的方法，以解决医疗深度学习模型面临的数据稀缺、不均匀性和隐私问题，从而改善扩大脑室的分割性能。具体而言，该方法包括训练一个基于 10,000 个掩码的掩码生成器和一个使用 6,881 个扫描优化的 SPADE 图像生成器，并通过脑室体积条件化和无分类器引导控制合成图像的分布。实验使用 nnU-Net 模型分别在真实、增强和全合成数据上训练，结果显示增强数据模型的 MAE 为 6.23 ± 4.33 mL 和 Dice score 为 0.892 ± 0.05，均优于真实数据模型（MAE 9.09 ± 12.18 mL）和现有最先进模型 SynthSeg（MAE 7.73 ± 12.12 mL）。总之，该方法证明了合成数据能显著提升脑室分割的准确性和鲁棒性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.01351v1",
      "published_date": "2024-11-02 19:44:10 UTC",
      "updated_date": "2024-11-02 19:44:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T20:21:19.902744"
    },
    {
      "arxiv_id": "2411.01344v2",
      "title": "Privacy Leakage Overshadowed by Views of AI: A Study on Human Oversight of Privacy in Language Model Agent",
      "title_zh": "翻译失败",
      "authors": [
        "Zhiping Zhang",
        "Bingcan Guo",
        "Tianshi Li"
      ],
      "abstract": "Language model (LM) agents that act on users' behalf for personal tasks\n(e.g., replying emails) can boost productivity, but are also susceptible to\nunintended privacy leakage risks. We present the first study on people's\ncapacity to oversee the privacy implications of the LM agents. By conducting a\ntask-based survey (N=300), we investigate how people react to and assess the\nresponse generated by LM agents for asynchronous interpersonal communication\ntasks, compared with a response they wrote. We found that people may favor the\nagent response with more privacy leakage over the response they drafted or\nconsider both good, leading to an increased harmful disclosure from 15.7% to\n55.0%. We further identified six privacy profiles to characterize distinct\npatterns of concerns, trust, and privacy preferences in LM agents. Our findings\nshed light on designing agentic systems that enable privacy-preserving\ninteractions and achieve bidirectional alignment on privacy preferences to help\nusers calibrate trust.",
      "tldr_zh": "该研究探讨了语言模型 (LM) 代理在处理个人任务（如回复电子邮件）时可能导致的隐私泄露风险，以及人们监督这些风险的能力。研究通过一项任务-based survey (N=300) 比较了人们对 LM 代理生成的响应和他们自己撰写的响应的评估，发现人们更倾向于选择隐私泄露更多的代理响应，导致有害披露率从15.7% 上升到55.0%。此外，研究识别了六种隐私配置文件，以描述人们在 LM 代理中的关注、信任和偏好模式。这些发现为设计支持隐私保护的代理系统提供了指导，帮助实现隐私偏好的双向对齐并校准用户信任。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.01344v2",
      "published_date": "2024-11-02 19:15:42 UTC",
      "updated_date": "2025-01-30 20:31:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T20:23:22.758600"
    },
    {
      "arxiv_id": "2411.01342v1",
      "title": "Adaptive World Models: Learning Behaviors by Latent Imagination Under Non-Stationarity",
      "title_zh": "翻译失败",
      "authors": [
        "Emiliyan Gospodinov",
        "Vaisakh Shaj",
        "Philipp Becker",
        "Stefan Geyer",
        "Gerhard Neumann"
      ],
      "abstract": "Developing foundational world models is a key research direction for embodied\nintelligence, with the ability to adapt to non-stationary environments being a\ncrucial criterion. In this work, we introduce a new formalism, Hidden\nParameter-POMDP, designed for control with adaptive world models. We\ndemonstrate that this approach enables learning robust behaviors across a\nvariety of non-stationary RL benchmarks. Additionally, this formalism\neffectively learns task abstractions in an unsupervised manner, resulting in\nstructured, task-aware latent spaces.",
      "tldr_zh": "该研究针对非平稳环境下的体现智能，提出Adaptive World Models框架，通过Hidden Parameter-POMDP形式主义实现行为学习。该方法利用潜在想象（Latent Imagination）来适应动态变化，允许在各种非平稳强化学习基准上训练鲁棒行为。此外，该形式主义以无监督方式学习任务抽象，生成结构化的任务感知潜在空间。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at NeurIPS 2024 Workshop Adaptive Foundation Models",
      "pdf_url": "http://arxiv.org/pdf/2411.01342v1",
      "published_date": "2024-11-02 19:09:56 UTC",
      "updated_date": "2024-11-02 19:09:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T20:21:40.521677"
    },
    {
      "arxiv_id": "2411.11862v1",
      "title": "Machine Learning Assisted Postural Movement Recognition using Photoplethysmography(PPG)",
      "title_zh": "利用光电容积描记术(PPG)的机器学习辅助姿势运动识别",
      "authors": [
        "Robbie Maccay",
        "Roshan Weerasekera"
      ],
      "abstract": "With the growing percentage of elderly people and care home admissions, there\nis an urgent need for the development of fall detection and fall prevention\ntechnologies. This work presents, for the first time, the use of machine\nlearning techniques to recognize postural movements exclusively from\nPhotoplethysmography (PPG) data. To achieve this goal, a device was developed\nfor reading the PPG signal, segmenting the PPG signals into individual pulses,\nextracting pulse morphology and homeostatic characteristic features, and\nevaluating different ML algorithms. Investigations into different postural\nmovements (stationary, sitting to standing, and lying to standing) were\nperformed by 11 participants. The results of these investigations provided\ninsight into the differences in homeostasis after the movements in the PPG\nsignal. Various machine learning approaches were used for classification, and\nthe Artificial Neural Network (ANN) was found to be the best classifier, with a\ntesting accuracy of 85.2\\% and an F1 score of 78\\% from experimental results.",
      "tldr_zh": "该研究首次利用机器学习技术，通过 Photoplethysmography (PPG) 数据识别姿势运动，以应对老年人跌倒检测和预防的需求。研究团队开发了一种设备，用于读取 PPG 信号、分割脉冲、提取脉冲形态和稳态特征，并评估多种 Machine Learning 算法。实验涉及 11 名参与者进行不同姿势（如静止、坐到站和躺到站），结果显示 Artificial Neural Network (ANN) 是最佳分类器，测试准确率达 85.2%，F1 分数为 78%。这项工作为基于 PPG 的跌倒预防技术提供了新颖的见解和基础。",
      "categories": [
        "eess.SP",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "eess.SP",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.11862v1",
      "published_date": "2024-11-02 18:56:41 UTC",
      "updated_date": "2024-11-02 18:56:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T20:21:53.447680"
    },
    {
      "arxiv_id": "2411.10461v1",
      "title": "Utilizing Human Behavior Modeling to Manipulate Explanations in AI-Assisted Decision Making: The Good, the Bad, and the Scary",
      "title_zh": "翻译失败",
      "authors": [
        "Zhuoyan Li",
        "Ming Yin"
      ],
      "abstract": "Recent advances in AI models have increased the integration of AI-based\ndecision aids into the human decision making process. To fully unlock the\npotential of AI-assisted decision making, researchers have computationally\nmodeled how humans incorporate AI recommendations into their final decisions,\nand utilized these models to improve human-AI team performance. Meanwhile, due\nto the ``black-box'' nature of AI models, providing AI explanations to human\ndecision makers to help them rely on AI recommendations more appropriately has\nbecome a common practice. In this paper, we explore whether we can\nquantitatively model how humans integrate both AI recommendations and\nexplanations into their decision process, and whether this quantitative\nunderstanding of human behavior from the learned model can be utilized to\nmanipulate AI explanations, thereby nudging individuals towards making targeted\ndecisions. Our extensive human experiments across various tasks demonstrate\nthat human behavior can be easily influenced by these manipulated explanations\ntowards targeted outcomes, regardless of the intent being adversarial or\nbenign. Furthermore, individuals often fail to detect any anomalies in these\nexplanations, despite their decisions being affected by them.",
      "tldr_zh": "这篇论文探讨了利用Human Behavior Modeling来操纵AI explanations在AI-Assisted Decision Making中的应用，旨在量化建模人类如何整合AI推荐和解释以影响决策过程。研究通过广泛的人类实验证明，这种模型可以轻松引导个体做出预设决策，无论意图是良性（如提升团队表现）还是恶意（如欺骗），且参与者通常无法察觉解释中的异常。最终，该工作揭示了AI解释的潜在益处、风险和伦理挑战，为更可靠的人-AI交互提供了重要启示。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2411.10461v1",
      "published_date": "2024-11-02 18:33:28 UTC",
      "updated_date": "2024-11-02 18:33:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T20:22:05.459209"
    },
    {
      "arxiv_id": "2411.01332v4",
      "title": "A Mechanistic Explanatory Strategy for XAI",
      "title_zh": "翻译失败",
      "authors": [
        "Marcin Rabiza"
      ],
      "abstract": "Despite significant advancements in XAI, scholars continue to note a\npersistent lack of robust conceptual foundations and integration with broader\ndiscourse on scientific explanation. In response, emerging XAI research\nincreasingly draws on explanatory strategies from various scientific\ndisciplines and the philosophy of science to address these gaps. This paper\noutlines a mechanistic strategy for explaining the functional organization of\ndeep learning systems, situating recent developments in AI explainability\nwithin a broader philosophical context. According to the mechanistic approach,\nexplaining opaque AI systems involves identifying the mechanisms underlying\ndecision-making processes. For deep neural networks, this means discerning\nfunctionally relevant components - such as neurons, layers, circuits, or\nactivation patterns - and understanding their roles through decomposition,\nlocalization, and recomposition. Proof-of-principle case studies from image\nrecognition and language modeling align this theoretical framework with recent\nresearch from OpenAI and Anthropic. The findings suggest that pursuing\nmechanistic explanations can uncover elements that traditional explainability\ntechniques may overlook, ultimately contributing to more thoroughly explainable\nAI.",
      "tldr_zh": "本文针对 XAI 的概念基础不足和科学解释整合问题，提出了一种机制论(mechanistic)解释策略，用于阐释深度学习系统的功能组织。该策略强调通过识别决策过程的底层机制，包括分解、定位和重组神经元、层、电路或激活模式，来揭示 AI 系统的关键组件。论文以图像识别和语言建模的案例研究为例，参考 OpenAI 和 Anthropic 的相关工作，证明此方法能发现传统可解释性技术忽略的元素。最终，该框架有助于构建更彻底和可靠的 XAI 系统。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Forthcoming in M\\\"uller, V. C., Dung, L., L\\\"ohr, G., & Rumana, A.\n  (Eds.). Philosophy of Artificial Intelligence: The State of the Art, Synthese\n  Library, Springer Nature. Please cite the published version",
      "pdf_url": "http://arxiv.org/pdf/2411.01332v4",
      "published_date": "2024-11-02 18:30:32 UTC",
      "updated_date": "2025-03-25 01:41:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T20:22:17.350063"
    },
    {
      "arxiv_id": "2411.01327v2",
      "title": "Visual Fourier Prompt Tuning",
      "title_zh": "视觉傅立叶提示调优",
      "authors": [
        "Runjia Zeng",
        "Cheng Han",
        "Qifan Wang",
        "Chunshu Wu",
        "Tong Geng",
        "Lifu Huang",
        "Ying Nian Wu",
        "Dongfang Liu"
      ],
      "abstract": "With the scale of vision Transformer-based models continuing to grow,\nfinetuning these large-scale pretrained models for new tasks has become\nincreasingly parameter-intensive. Visual prompt tuning is introduced as a\nparameter-efficient finetuning (PEFT) method to this trend. Despite its\nsuccesses, a notable research challenge persists within almost all PEFT\napproaches: significant performance degradation is observed when there is a\nsubstantial disparity between the datasets applied in pretraining and\nfinetuning phases. To address this challenge, we draw inspiration from human\nvisual cognition, and propose the Visual Fourier Prompt Tuning (VFPT) method as\na general and effective solution for adapting large-scale transformer-based\nmodels. Our approach innovatively incorporates the Fast Fourier Transform into\nprompt embeddings and harmoniously considers both spatial and frequency domain\ninformation. Apart from its inherent simplicity and intuitiveness, VFPT\nexhibits superior performance across all datasets, offering a general solution\nto dataset challenges, irrespective of data disparities. Empirical results\ndemonstrate that our approach outperforms current state-of-the-art baselines on\ntwo benchmarks, with low parameter usage (e.g., 0.57% of model parameters on\nVTAB-1k) and notable performance enhancements (e.g., 73.20% of mean accuracy on\nVTAB-1k). Our code is avaliable at https://github.com/runtsang/VFPT.",
      "tldr_zh": "本文提出 Visual Fourier Prompt Tuning (VFPT) 方法，以解决大型视觉 Transformer 模型在预训练和微调数据集差异较大时导致的参数高效微调 (PEFT) 性能下降问题。VFPT 创新地将 Fast Fourier Transform 融入提示嵌入中，结合空间和频率域信息，灵感来源于人类视觉认知，提供一个简单而通用的适应方案。实验结果显示，该方法在 VTAB-1k 等基准上仅使用模型参数的 0.57%，就实现了显著性能提升（如 73.20% 的平均准确率），并优于现有最先进基线。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "[NeurIPS 2024] Homepage: https://runjia.tech/vfpt_page/",
      "pdf_url": "http://arxiv.org/pdf/2411.01327v2",
      "published_date": "2024-11-02 18:18:35 UTC",
      "updated_date": "2024-11-15 22:18:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T20:22:30.095900"
    },
    {
      "arxiv_id": "2411.01316v1",
      "title": "FEED: Fairness-Enhanced Meta-Learning for Domain Generalization",
      "title_zh": "翻译失败",
      "authors": [
        "Kai Jiang",
        "Chen Zhao",
        "Haoliang Wang",
        "Feng Chen"
      ],
      "abstract": "Generalizing to out-of-distribution data while being aware of model fairness\nis a significant and challenging problem in meta-learning. The goal of this\nproblem is to find a set of fairness-aware invariant parameters of classifier\nthat is trained using data drawn from a family of related training domains with\ndistribution shift on non-sensitive features as well as different levels of\ndependence between model predictions and sensitive features so that the\nclassifier can achieve good generalization performance on unknown but distinct\ntest domains. To tackle this challenge, existing state-of-the-art methods\neither address the domain generalization problem but completely ignore learning\nwith fairness or solely specify shifted domains with various fairness levels.\nThis paper introduces an approach to fairness-aware meta-learning that\nsignificantly enhances domain generalization capabilities. Our framework,\nFairness-Enhanced Meta-Learning for Domain Generalization (FEED), disentangles\nlatent data representations into content, style, and sensitive vectors. This\ndisentanglement facilitates the robust generalization of machine learning\nmodels across diverse domains while adhering to fairness constraints. Unlike\ntraditional methods that focus primarily on domain invariance or sensitivity to\nshifts, our model integrates a fairness-aware invariance criterion directly\ninto the meta-learning process. This integration ensures that the learned\nparameters uphold fairness consistently, even when domain characteristics vary\nwidely. We validate our approach through extensive experiments across multiple\nbenchmarks, demonstrating not only superior performance in maintaining high\naccuracy and fairness but also significant improvements over existing\nstate-of-the-art methods in domain generalization tasks.",
      "tldr_zh": "这篇论文提出 FEED 框架，即 Fairness-Enhanced Meta-Learning for Domain Generalization，用于解决元学习（meta-learning）中模型在分布外数据上的泛化问题，同时确保公平性。FEED 通过将数据表示解耦成内容、风格和敏感向量，并将公平感知不变性标准直接集成到元学习过程中，实现模型在不同域上的鲁棒性和公平约束。实验在多个基准上验证了 FEED 的优越性，不仅提升了准确性，还在公平性方面显著超过了现有方法。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "IEEE International Conference on Big Data 2024",
      "pdf_url": "http://arxiv.org/pdf/2411.01316v1",
      "published_date": "2024-11-02 17:34:33 UTC",
      "updated_date": "2024-11-02 17:34:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T20:23:34.353692"
    },
    {
      "arxiv_id": "2411.03343v2",
      "title": "What Features in Prompts Jailbreak LLMs? Investigating the Mechanisms Behind Attacks",
      "title_zh": "提示中的哪些特征会导致 LLMs 被越狱？调查攻击背后的机制",
      "authors": [
        "Nathalie Kirch",
        "Constantin Weisser",
        "Severin Field",
        "Helen Yannakoudakis",
        "Stephen Casper"
      ],
      "abstract": "Jailbreaks have been a central focus of research regarding the safety and\nreliability of large language models (LLMs), yet the mechanisms underlying\nthese attacks remain poorly understood. While previous studies have\npredominantly relied on linear methods to detect jailbreak attempts and model\nrefusals, we take a different approach by examining both linear and non-linear\nfeatures in prompts that lead to successful jailbreaks. First, we introduce a\nnovel dataset comprising 10,800 jailbreak attempts spanning 35 diverse attack\nmethods. Leveraging this dataset, we train probes to classify successful from\nunsuccessful jailbreaks using the latent representations corresponding to\nprompt tokens. Notably, we find that even when probes achieve high accuracy in\npredicting the success of jailbreaks, their performance often fails to\ngeneralize to unseen attack methods. This reveals that different jailbreaking\nstrategies exploit different non-linear, non-universal features. Next, we\ndemonstrate that non-linear probes provide a powerful tool for steering model\nbehavior. Specifically, we use these probes to guide targeted latent space\nperturbations, enabling us to effectively modulate the model's robustness\nagainst jailbreaks. Overall, our findings challenge the assumption that\njailbreaks can be fully understood through linear or simple universal prompt\nfeatures alone, highlighting the importance of a nuanced understanding of the\nmechanisms behind LLM vulnerabilities.",
      "tldr_zh": "本研究调查了提示（prompts）中的特征如何导致大型语言模型（LLMs）遭受jailbreak攻击，强调了这些攻击机制的复杂性。作者构建了一个包含10,800个jailbreak尝试的新数据集，涵盖35种攻击方法，并使用线性与非线性probes分析提示标记的潜在表示（latent representations），发现probes虽能准确预测攻击成功，但无法泛化到新攻击策略，因为不同jailbreak方法依赖独特的非线性特征。最终，他们展示了非线性probes可用于指导潜在空间扰动，提升模型对jailbreak的鲁棒性，挑战了仅靠线性或通用特征理解LLM漏洞的假设，并呼吁更细致的机制分析。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.03343v2",
      "published_date": "2024-11-02 17:29:47 UTC",
      "updated_date": "2025-05-14 12:32:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T20:23:47.253730"
    },
    {
      "arxiv_id": "2411.01313v2",
      "title": "False Data Injection Attack Detection in Edge-based Smart Metering Networks with Federated Learning",
      "title_zh": "基于边缘的智能计量网络中利用联邦学习的假数据注入攻击检测",
      "authors": [
        "Md Raihan Uddin",
        "Ratun Rahman",
        "Dinh C. Nguyen"
      ],
      "abstract": "Smart metering networks are increasingly susceptible to cyber threats, where\nfalse data injection (FDI) appears as a critical attack. Data-driven-based\nmachine learning (ML) methods have shown immense benefits in detecting FDI\nattacks via data learning and prediction abilities. Literature works have\nmostly focused on centralized learning and deploying FDI attack detection\nmodels at the control center, which requires data collection from local\nutilities like meters and transformers. However, this data sharing may raise\nprivacy concerns due to the potential disclosure of household information like\nenergy usage patterns. This paper proposes a new privacy-preserved FDI attack\ndetection by developing an efficient federated learning (FL) framework in the\nsmart meter network with edge computing. Distributed edge servers located at\nthe network edge run an ML-based FDI attack detection model and share the\ntrained model with the grid operator, aiming to build a strong FDI attack\ndetection model without data sharing. Simulation results demonstrate the\nefficiency of our proposed FL method over the conventional method without\ncollaboration.",
      "tldr_zh": "这篇论文针对智能计量网络中虚假数据注入（FDI）攻击的问题，提出了一种基于联邦学习（FL）的隐私保护检测框架，利用边缘计算来避免数据共享。方法涉及分布式边缘服务器运行机器学习（ML）模型，仅共享训练模型，从而保护用户隐私如能源使用模式。模拟结果显示，该框架比传统无协作方法更高效，提升了FDI攻击检测的性能。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.LG",
      "comment": "This work has been accepted by IEEE Consumer Communications &\n  Networking Conference (CCNC)",
      "pdf_url": "http://arxiv.org/pdf/2411.01313v2",
      "published_date": "2024-11-02 17:23:08 UTC",
      "updated_date": "2024-11-06 18:30:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T20:23:57.541842"
    },
    {
      "arxiv_id": "2411.01312v2",
      "title": "From Federated Learning to Quantum Federated Learning for Space-Air-Ground Integrated Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Vu Khanh Quy",
        "Nguyen Minh Quy",
        "Tran Thi Hoai",
        "Shaba Shaon",
        "Md Raihan Uddin",
        "Tien Nguyen",
        "Dinh C. Nguyen",
        "Aryan Kaushik",
        "Periklis Chatzimisios"
      ],
      "abstract": "6G wireless networks are expected to provide seamless and data-based\nconnections that cover space-air-ground and underwater networks. As a core\npartition of future 6G networks, Space-Air-Ground Integrated Networks (SAGIN)\nhave been envisioned to provide countless real-time intelligent applications.\nTo realize this, promoting AI techniques into SAGIN is an inevitable trend. Due\nto the distributed and heterogeneous architecture of SAGIN, federated learning\n(FL) and then quantum FL are emerging AI model training techniques for enabling\nfuture privacy-enhanced and computation-efficient SAGINs. In this work, we\nexplore the vision of using FL/QFL in SAGINs. We present a few representative\napplications enabled by the integration of FL and QFL in SAGINs. A case study\nof QFL over UAV networks is also given, showing the merit of quantum-enabled\ntraining approach over the conventional FL benchmark. Research challenges along\nwith standardization for QFL adoption in future SAGINs are also highlighted.",
      "tldr_zh": "本论文探讨了从 Federated Learning (FL) 到 Quantum Federated Learning (QFL) 在 Space-Air-Ground Integrated Networks (SAGIN) 中的应用，旨在为 6G 无线网络提供隐私增强和计算高效的 AI 训练技术。论文呈现了 FL 和 QFL 在 SAGIN 下的几个代表性应用，如实时智能应用支持，并通过一个 QFL 在 UAV 网络的案例研究，展示了量子方法比传统 FL 基准的性能优势。最终，论文突出了 QFL 采用在 SAGIN 中的研究挑战和标准化需求，为未来网络发展奠定基础。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.LG",
      "comment": "This work has been accepted by IEEE Conference on Standards for\n  Communications and Networking",
      "pdf_url": "http://arxiv.org/pdf/2411.01312v2",
      "published_date": "2024-11-02 17:13:00 UTC",
      "updated_date": "2024-11-06 18:35:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T20:24:10.944101"
    },
    {
      "arxiv_id": "2411.01297v2",
      "title": "Receding Hamiltonian-Informed Optimal Neural Control and State Estimation for Closed-Loop Dynamical Systems",
      "title_zh": "翻译失败",
      "authors": [
        "Josue N. Rivera",
        "Dengfeng Sun"
      ],
      "abstract": "This paper formalizes Hamiltonian-Informed Optimal Neural (Hion) controllers,\na novel class of neural network-based controllers for dynamical systems and\nexplicit non-linear model predictive control. Hion controllers estimate future\nstates and compute optimal control inputs using Pontryagin's Maximum Principle.\nThe proposed framework allows for customization of transient behavior,\naddressing limitations of existing methods. The Taylored Multi-Faceted Approach\nfor Neural ODE and Optimal Control (T-mano) architecture facilitates training\nand ensures accurate state estimation. Optimal control strategies are\ndemonstrated for both linear and non-linear dynamical systems.",
      "tldr_zh": "这篇论文提出了Hamiltonian-Informed Optimal Neural (Hion)控制器，一种新型基于神经网络的控制器，用于动态系统和显式非线性模型预测控制。Hion控制器通过Pontryagin's Maximum Principle估计未来状态并计算最优控制输入，同时允许自定义瞬态行为，以克服现有方法的局限性。Taylored Multi-Faceted Approach for Neural ODE and Optimal Control (T-mano)架构支持训练和精确状态估计，并在线性与非线性动态系统上展示了有效的控制策略。",
      "categories": [
        "eess.SY",
        "cs.AI",
        "cs.ET",
        "cs.LG",
        "cs.RO",
        "cs.SY"
      ],
      "primary_category": "eess.SY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.01297v2",
      "published_date": "2024-11-02 16:06:29 UTC",
      "updated_date": "2024-11-09 18:19:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T20:24:22.351212"
    },
    {
      "arxiv_id": "2411.01295v2",
      "title": "Marginal Causal Flows for Validation and Inference",
      "title_zh": "边际因果流用于验证和推断",
      "authors": [
        "Daniel de Vassimon Manela",
        "Laura Battaglia",
        "Robin J. Evans"
      ],
      "abstract": "Investigating the marginal causal effect of an intervention on an outcome\nfrom complex data remains challenging due to the inflexibility of employed\nmodels and the lack of complexity in causal benchmark datasets, which often\nfail to reproduce intricate real-world data patterns. In this paper we\nintroduce Frugal Flows, a novel likelihood-based machine learning model that\nuses normalising flows to flexibly learn the data-generating process, while\nalso directly inferring the marginal causal quantities from observational data.\nWe propose that these models are exceptionally well suited for generating\nsynthetic data to validate causal methods. They can create synthetic datasets\nthat closely resemble the empirical dataset, while automatically and exactly\nsatisfying a user-defined average treatment effect. To our knowledge, Frugal\nFlows are the first generative model to both learn flexible data\nrepresentations and also exactly parameterise quantities such as the average\ntreatment effect and the degree of unobserved confounding. We demonstrate the\nabove with experiments on both simulated and real-world datasets.",
      "tldr_zh": "这篇论文提出了 Frugal Flows，一种基于 normalising flows 的似然机器学习模型，用于灵活学习数据生成过程并直接从观察数据中推断边际因果效应，从而解决复杂数据中干预对结果影响的挑战。该模型能够生成与真实数据集相似的合成数据，同时精确满足用户定义的 average treatment effect，并自动处理未观察混杂度，是首个兼顾灵活数据表示和精确因果参数化的生成模型。通过模拟和真实数据集的实验，Frugal Flows 证明了其在因果方法验证和推断中的有效性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ME",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "23 pages, 10 figures, Accepted as a Poster at NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2411.01295v2",
      "published_date": "2024-11-02 16:04:57 UTC",
      "updated_date": "2024-12-05 02:49:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T20:24:34.495301"
    },
    {
      "arxiv_id": "2411.01292v2",
      "title": "Causal reasoning in difference graphs",
      "title_zh": "翻译失败",
      "authors": [
        "Charles K. Assaad"
      ],
      "abstract": "Understanding causal mechanisms across different populations is essential for\ndesigning effective public health interventions. Recently, difference graphs\nhave been introduced as a tool to visually represent causal variations between\ntwo distinct populations. While there has been progress in inferring these\ngraphs from data through causal discovery methods, there remains a gap in\nsystematically leveraging their potential to enhance causal reasoning. This\npaper addresses that gap by establishing conditions for identifying causal\nchanges and effects using difference graphs. It specifically focuses on\nidentifying total causal changes and total effects in a nonparametric setting,\nas well as direct causal changes and direct effects in a linear setting. In\ndoing so, it provides a novel approach to causal reasoning that holds potential\nfor various public health applications.",
      "tldr_zh": "本文探讨了利用差分图（difference graphs）增强跨人群因果推理，以支持公共卫生干预设计。论文填补了现有方法的空白，通过建立特定条件来识别因果变化和效果，包括在非参数设置（nonparametric setting）中识别总因果变化（total causal changes）和总效果（total effects），以及在线性设置（linear setting）中识别直接因果变化（direct causal changes）和直接效果（direct effects）。这种新方法为系统利用差分图提供了一个框架，能够可视化并分析不同人群间的因果差异。最终，该方法具有广泛的公共卫生应用潜力。",
      "categories": [
        "cs.AI",
        "stat.ME"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted at CLeaR2025",
      "pdf_url": "http://arxiv.org/pdf/2411.01292v2",
      "published_date": "2024-11-02 16:01:42 UTC",
      "updated_date": "2025-02-16 12:17:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T20:24:46.320016"
    },
    {
      "arxiv_id": "2411.01281v3",
      "title": "Varco Arena: A Tournament Approach to Reference-Free Benchmarking Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Seonil Son",
        "Ju-Min Oh",
        "Heegon Jin",
        "Cheolhun Jang",
        "Jeongbeom Jeong",
        "Kuntae Kim"
      ],
      "abstract": "Most existing benchmarking approaches for evaluating the output quality of\nlarge language models (LLMs) rely on comparing LLM responses to predefined\nreferences. Such methods, based on static datasets, quickly become outdated as\nLLM capabilities and use cases evolve. In this work, we introduce VARCO\nArena--a novel, cost-effective, and robust benchmarking approach that leverages\na single-elimination tournament structure to minimize the number of required\ncomparisons while eliminating the need for static references or costly human\nannotations. We validate our approach through two experiments: (i) a simulation\nstudy that examines its robustness under various conditions, and (ii) an\nempirical evaluation using publicly available benchmark prompts. In both\nexperiments, VARCO Arena consistently outperforms current LLM benchmarking\npractices, achieving stronger correlations with human-established Elo ratings.\nOur results demonstrate that VARCO Arena not only produces reliable LLM\nrankings but also provides a scalable, adaptable solution for qualitative\nevaluation across diverse, customized use cases.",
      "tldr_zh": "本文提出 VARCO Arena，一种基于单淘汰锦标赛结构的参考无关基准方法，用于评估 Large Language Models (LLMs) 的输出质量，避免依赖静态数据集和昂贵的人工标注，从而提高评估的成本效益和适应性。相比传统方法，该方法通过最小化比较次数并提升鲁棒性，在模拟研究和实证实验中表现出色，与人类建立的 Elo ratings 相关性更强。最终，VARCO Arena 提供了一个可扩展的解决方案，支持多样化、自定义的定性评估，帮助LLMs 排名更可靠。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "8 pages for main body, 17 pages in total",
      "pdf_url": "http://arxiv.org/pdf/2411.01281v3",
      "published_date": "2024-11-02 15:23:28 UTC",
      "updated_date": "2025-02-19 01:34:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T20:24:58.142818"
    },
    {
      "arxiv_id": "2411.01272v1",
      "title": "Improving Energy Efficiency in Manufacturing: A Novel Expert System Shell",
      "title_zh": "提升制造业",
      "authors": [
        "Borys Ioshchikhes",
        "Michael Frank",
        "Tresa Maria Joseph",
        "Matthias Weigold"
      ],
      "abstract": "Expert systems are effective tools for automatically identifying energy\nefficiency potentials in manufacturing, thereby contributing significantly to\nglobal climate targets. These systems analyze energy data, pinpoint\ninefficiencies, and recommend optimizations to reduce energy consumption.\nBeyond systematic approaches for developing expert systems, there is a pressing\nneed for simple and rapid software implementation solutions. Expert system\nshells, which facilitate the swift development and deployment of expert\nsystems, are crucial tools in this process. They provide a template that\nsimplifies the creation and integration of expert systems into existing\nmanufacturing processes. This paper provides a comprehensive comparison of\nexisting expert system shells regarding their suitability for improving energy\nefficiency, highlighting significant gaps and limitations. To address these\ndeficiencies, we introduce a novel expert system shell, implemented in Jupyter\nNotebook, that provides a flexible and easily integrable solution for expert\nsystem development.",
      "tldr_zh": "本文讨论了专家系统在制造业中识别能源效率潜力的重要性，这些系统通过分析能源数据、识别低效问题并推荐优化措施，支持全球气候目标。现有expert system shells在开发和集成方面存在显著缺陷，为此，论文对这些工具进行了全面比较，突出了其局限性。作者引入了一个新型expert system shell，使用Jupyter Notebook实现，提供灵活且易集成的解决方案，以加速专家系统的快速部署和应用。",
      "categories": [
        "cs.AI",
        "cs.HC",
        "cs.SE"
      ],
      "primary_category": "cs.AI",
      "comment": "6 pages, 3 figures, preprint for conference contribution",
      "pdf_url": "http://arxiv.org/pdf/2411.01272v1",
      "published_date": "2024-11-02 14:50:37 UTC",
      "updated_date": "2024-11-02 14:50:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T20:25:09.634805"
    },
    {
      "arxiv_id": "2411.01271v1",
      "title": "Interacting Large Language Model Agents. Interpretable Models and Social Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Adit Jain",
        "Vikram Krishnamurthy"
      ],
      "abstract": "This paper develops theory and algorithms for interacting large language\nmodel agents (LLMAs) using methods from statistical signal processing and\nmicroeconomics. While both fields are mature, their application to\ndecision-making by interacting LLMAs remains unexplored. Motivated by Bayesian\nsentiment analysis on online platforms, we construct interpretable models and\nstochastic control algorithms that enable LLMAs to interact and perform\nBayesian inference. Because interacting LLMAs learn from prior decisions and\nexternal inputs, they exhibit bias and herding behavior. Thus, developing\ninterpretable models and stochastic control algorithms is essential to\nunderstand and mitigate these behaviors. This paper has three main results.\nFirst, we show using Bayesian revealed preferences from microeconomics that an\nindividual LLMA satisfies the sufficient conditions for rationally inattentive\n(bounded rationality) utility maximization and, given an observation, the LLMA\nchooses an action that maximizes a regularized utility. Second, we utilize\nBayesian social learning to construct interpretable models for LLMAs that\ninteract sequentially with each other and the environment while performing\nBayesian inference. Our models capture the herding behavior exhibited by\ninteracting LLMAs. Third, we propose a stochastic control framework to delay\nherding and improve state estimation accuracy under two settings: (a) centrally\ncontrolled LLMAs and (b) autonomous LLMAs with incentives. Throughout the\npaper, we demonstrate the efficacy of our methods on real datasets for hate\nspeech classification and product quality assessment, using open-source models\nlike Mistral and closed-source models like ChatGPT. The main takeaway of this\npaper, based on substantial empirical analysis and mathematical formalism, is\nthat LLMAs act as rationally bounded Bayesian agents that exhibit social\nlearning when interacting.",
      "tldr_zh": "这篇论文使用统计信号处理和微观经济学的理论，开发了互动大型语言模型代理（LLMAs）的算法和可解释模型，以理解其决策过程和行为。论文的关键贡献包括：证明单个 LLMA 通过 Bayesian revealed preferences 满足理性不注意（bounded rationality）效用最大化的条件，并利用 Bayesian social learning 构建模型来捕捉 LLMAs 顺序互动时的 herding behavior；以及提出随机控制框架，在中心控制和自主设置下延迟 herding 并改善状态估计准确性。实验在仇恨言论分类和产品质量评估的真实数据集上验证了这些方法，使用了 Mistral 和 ChatGPT 等模型，最终揭示 LLMAs 如同理性有限的 Bayesian 代理，在互动中表现出社会学习行为。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.ET",
        "cs.MA",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.01271v1",
      "published_date": "2024-11-02 14:49:34 UTC",
      "updated_date": "2024-11-02 14:49:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T20:25:23.650083"
    },
    {
      "arxiv_id": "2411.02442v2",
      "title": "TODO: Enhancing LLM Alignment with Ternary Preferences",
      "title_zh": "TODO：通过三",
      "authors": [
        "Yuxiang Guo",
        "Lu Yin",
        "Bo Jiang",
        "Jiaqi Zhang"
      ],
      "abstract": "Aligning large language models (LLMs) with human intent is critical for\nenhancing their performance across a variety of tasks. Standard alignment\ntechniques, such as Direct Preference Optimization (DPO), often rely on the\nbinary Bradley-Terry (BT) model, which can struggle to capture the complexities\nof human preferences -- particularly in the presence of noisy or inconsistent\nlabels and frequent ties. To address these limitations, we introduce the\nTie-rank Oriented Bradley-Terry model (TOBT), an extension of the BT model that\nexplicitly incorporates ties, enabling more nuanced preference representation.\nBuilding on this, we propose Tie-rank Oriented Direct Preference Optimization\n(TODO), a novel alignment algorithm that leverages TOBT's ternary ranking\nsystem to improve preference alignment. In evaluations on Mistral-7B and Llama\n3-8B models, TODO consistently outperforms DPO in modeling preferences across\nboth in-distribution and out-of-distribution datasets. Additional assessments\nusing MT Bench and benchmarks such as Piqa, ARC-c, and MMLU further demonstrate\nTODO's superior alignment performance. Notably, TODO also shows strong results\nin binary preference alignment, highlighting its versatility and potential for\nbroader integration into LLM alignment. The implementation details can be found\nin https://github.com/XXares/TODO.",
      "tldr_zh": "该论文针对大型语言模型（LLMs）的对齐问题，提出了一种新的算法 TODO（Tie-rank Oriented Direct Preference Optimization），通过扩展 Bradley-Terry (BT) 模型的变体 TOBT（Tie-rank Oriented Bradley-Terry model），来处理二元偏好模型的局限性，如噪声标签、一致性问题和 ties。TODO 利用三元排名系统，提供更细致的偏好表示，从而提升模型在各种任务中的性能。在 Mistral-7B 和 Llama 3-8B 模型上的实验显示，TODO 优于标准 DPO 方法，在 in-distribution 和 out-of-distribution 数据集上表现更好，并通过 MT Bench 以及 Piqa、ARC-c 和 MMLU 等基准验证了其在偏好对齐方面的卓越性和通用性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2411.02442v2",
      "published_date": "2024-11-02 14:36:03 UTC",
      "updated_date": "2025-03-29 02:56:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T20:25:35.875111"
    },
    {
      "arxiv_id": "2411.01240v2",
      "title": "Boosting Federated Learning with FedEntOpt: Mitigating Label Skew by Entropy-Based Client Selection",
      "title_zh": "翻译失败",
      "authors": [
        "Andreas Lutz",
        "Gabriele Steidl",
        "Karsten Müller",
        "Wojciech Samek"
      ],
      "abstract": "Deep learning is an emerging field revolutionizing various industries,\nincluding natural language processing, computer vision, and many more. These\ndomains typically require an extensive amount of data for optimal performance,\npotentially utilizing huge centralized data repositories. However, such\ncentralization could raise privacy issues concerning the storage of sensitive\ndata. To address this issue, federated learning was developed. It is a newly\ndistributed learning technique that enables to collaboratively train a deep\nlearning model on decentralized devices, referred to as clients, without\ncompromising their data privacy. Traditional federated learning methods often\nsuffer from severe performance degradation when the data distribution among\nclients differs significantly. This becomes especially problematic in the case\nof label distribution skew, where the distribution of labels varies across\nclients. To address this, a novel method called FedEntOpt is proposed.\nFedEntOpt is designed to mitigate performance issues caused by label\ndistribution skew by maximizing the entropy of the global label distribution of\nthe selected client subset in each federated learning round. This ensures that\nthe aggregated model parameters from the clients were exhibited to data from\nall available labels, which improves the accuracy of the global model.\nExtensive experiments on multiple benchmark datasets show that the proposed\nmethod outperforms several state-of-the-art algorithms by up to 6\\% in\nclassification accuracy under standard settings regardless of the model size.\nMoreover, it exhibits robust and superior performance in scenarios with low\nparticipation rates and client dropout, achieving increases in classification\naccuracy of over 30\\%. In addition, FedEntOpt offers the flexibility to be\ncombined with existing algorithms, enhancing their performance by over 40\\%.",
      "tldr_zh": "本研究针对联邦学习（Federated Learning）中标签分布偏差（label distribution skew）导致的性能下降问题，提出了一种新方法FedEntOpt，通过基于熵的客户端选择（Entropy-Based Client Selection）来最大化选定客户端子集的全局标签分布熵，从而确保模型接触到所有标签并提升全局模型准确性。FedEntOpt的设计允许在每个联邦学习轮次优化数据分布，确保在不泄露隐私的情况下改善模型训练。实验结果显示，该方法在多个基准数据集上比现有算法提高高达6%的分类准确率，并在低参与率和客户端掉线场景下实现超过30%的准确率提升，同时与其他算法结合可提升性能超过40%。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DC"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.01240v2",
      "published_date": "2024-11-02 13:31:36 UTC",
      "updated_date": "2025-01-29 14:17:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T20:25:47.213745"
    },
    {
      "arxiv_id": "2411.01236v1",
      "title": "AutoPT: How Far Are We from the End2End Automated Web Penetration Testing?",
      "title_zh": "AutoPT: 我们距离端到端自动 Web 渗透测试还有多远？",
      "authors": [
        "Benlong Wu",
        "Guoqiang Chen",
        "Kejiang Chen",
        "Xiuwei Shang",
        "Jiapeng Han",
        "Yanru He",
        "Weiming Zhang",
        "Nenghai Yu"
      ],
      "abstract": "Penetration testing is essential to ensure Web security, which can detect and\nfix vulnerabilities in advance, and prevent data leakage and serious\nconsequences. The powerful inference capabilities of large language models\n(LLMs) have made significant progress in various fields, and the development\npotential of LLM-based agents can revolutionize the cybersecurity penetration\ntesting industry. In this work, we establish a comprehensive end-to-end\npenetration testing benchmark using a real-world penetration testing\nenvironment to explore the capabilities of LLM-based agents in this domain. Our\nresults reveal that the agents are familiar with the framework of penetration\ntesting tasks, but they still face limitations in generating accurate commands\nand executing complete processes. Accordingly, we summarize the current\nchallenges, including the difficulty of maintaining the entire message history\nand the tendency for the agent to become stuck.\n  Based on the above insights, we propose a Penetration testing State Machine\n(PSM) that utilizes the Finite State Machine (FSM) methodology to address these\nlimitations. Then, we introduce AutoPT, an automated penetration testing agent\nbased on the principle of PSM driven by LLMs, which utilizes the inherent\ninference ability of LLM and the constraint framework of state machines. Our\nevaluation results show that AutoPT outperforms the baseline framework ReAct on\nthe GPT-4o mini model and improves the task completion rate from 22% to 41% on\nthe benchmark target. Compared with the baseline framework and manual work,\nAutoPT also reduces time and economic costs further. Hence, our AutoPT has\nfacilitated the development of automated penetration testing and significantly\nimpacted both academia and industry.",
      "tldr_zh": "本文探讨了大型语言模型 (LLMs) 在端到端自动化网络渗透测试中的潜力，通过建立一个真实环境的全面基准，评估了 LLM 代理的能力，发现它们虽熟悉任务框架，但受限于生成准确命令和执行完整过程。针对这些挑战，论文提出了 Penetration testing State Machine (PSM)，基于 Finite State Machine (FSM) 原理，并开发了 AutoPT 框架，该框架结合 LLMs 的推理能力和状态机约束，提升了测试效率。实验结果显示，AutoPT 在 GPT-4o mini 上比基线框架 ReAct 将任务完成率从 22% 提高到 41%，并显著降低了时间和经济成本，为自动化渗透测试在学术和工业领域的应用提供了重要推动。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "22 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2411.01236v1",
      "published_date": "2024-11-02 13:24:30 UTC",
      "updated_date": "2024-11-02 13:24:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T20:25:59.965224"
    },
    {
      "arxiv_id": "2411.01228v2",
      "title": "The Interaction Layer: An Exploration for Co-Designing User-LLM Interactions in Parental Wellbeing Support Systems",
      "title_zh": "翻译失败",
      "authors": [
        "Sruthi Viswanathan",
        "Seray Ibrahim",
        "Ravi Shankar",
        "Reuben Binns",
        "Max Van Kleek",
        "Petr Slovak"
      ],
      "abstract": "Parenting brings emotional and physical challenges, from balancing work,\nchildcare, and finances to coping with exhaustion and limited personal time.\nYet, one in three parents never seek support. AI systems potentially offer\nstigma-free, accessible, and affordable solutions. Yet, user adoption often\nfails due to issues with explainability and reliability. To see if these issues\ncould be solved using a co-design approach, we developed and tested NurtureBot,\na wellbeing support assistant for new parents. 32 parents co-designed the\nsystem through Asynchronous Remote Communities method, identifying the key\nchallenge as achieving a \"successful chat.\" As part of co-design, parents\nrole-played as NurtureBot, rewriting its dialogues to improve user\nunderstanding, control, and outcomes. The refined prototype, featuring an\nInteraction Layer, was evaluated by 32 initial and 46 new parents, showing\nimproved user experience and usability, with final CUQ score of 91.3/100,\ndemonstrating successful interaction patterns. Our process revealed useful\ninteraction design lessons for effective AI parenting support.",
      "tldr_zh": "这篇论文探讨了通过共同设计（Co-Designing）方法优化用户与大型语言模型（LLM）交互的问题，旨在解决AI父母福祉支持系统在解释性和可靠性方面的挑战。研究团队开发了NurtureBot，一款针对新父母的福祉助手，并通过异步远程社区方法让32名父母参与角色扮演和对话重写，识别“成功聊天”作为关键挑战，并创建了Interaction Layer来提升用户理解、控制和体验。最终评估显示，该原型在32名初始父母和46名新父母中获得显著改善，用户体验分数（CUQ）达91.3/100，并提供了有效的AI育儿支持交互设计教训。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.01228v2",
      "published_date": "2024-11-02 12:32:36 UTC",
      "updated_date": "2025-03-12 16:29:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T20:26:11.609847"
    },
    {
      "arxiv_id": "2411.01212v1",
      "title": "Infinite-Resolution Integral Noise Warping for Diffusion Models",
      "title_zh": "无限分辨率积分噪声变形用于扩散模型",
      "authors": [
        "Yitong Deng",
        "Winnie Lin",
        "Lingxiao Li",
        "Dmitriy Smirnov",
        "Ryan Burgert",
        "Ning Yu",
        "Vincent Dedun",
        "Mohammad H. Taghavi"
      ],
      "abstract": "Adapting pretrained image-based diffusion models to generate temporally\nconsistent videos has become an impactful generative modeling research\ndirection. Training-free noise-space manipulation has proven to be an effective\ntechnique, where the challenge is to preserve the Gaussian white noise\ndistribution while adding in temporal consistency. Recently, Chang et al.\n(2024) formulated this problem using an integral noise representation with\ndistribution-preserving guarantees, and proposed an upsampling-based algorithm\nto compute it. However, while their mathematical formulation is advantageous,\nthe algorithm incurs a high computational cost. Through analyzing the\nlimiting-case behavior of their algorithm as the upsampling resolution goes to\ninfinity, we develop an alternative algorithm that, by gathering increments of\nmultiple Brownian bridges, achieves their infinite-resolution accuracy while\nsimultaneously reducing the computational cost by orders of magnitude. We prove\nand experimentally validate our theoretical claims, and demonstrate our\nmethod's effectiveness in real-world applications. We further show that our\nmethod readily extends to the 3-dimensional space.",
      "tldr_zh": "这篇论文提出了一种无限分辨率的积分噪声变形方法，用于扩散模型，以生成时间一致的视频，同时保持高斯白噪声分布。作者通过分析Chang et al. (2024)的上采样算法在无限分辨率下的行为，开发了新算法，利用多个Brownian bridges的增量计算，实现了相同准确性但计算成本降低数量级。实验验证了理论声明，并在真实应用中证明了方法的有效性，该方法还可扩展到3D空间。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.GR",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.01212v1",
      "published_date": "2024-11-02 11:05:00 UTC",
      "updated_date": "2024-11-02 11:05:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T20:26:23.160945"
    },
    {
      "arxiv_id": "2411.01211v2",
      "title": "Spatial Transformers for Radio Map Estimation",
      "title_zh": "空间变换器用于无线电地图估计",
      "authors": [
        "Pham Q. Viet",
        "Daniel Romero"
      ],
      "abstract": "Radio map estimation (RME) involves spatial interpolation of radio\nmeasurements to predict metrics such as the received signal strength at\nlocations where no measurements were collected. The most popular estimators\nnowadays project the measurement locations to a regular grid and complete the\nresulting measurement tensor with a convolutional deep neural network.\nUnfortunately, these approaches suffer from poor spatial resolution and require\na great number of parameters. The first contribution of this paper addresses\nthese limitations by means of an attention-based estimator named Spatial\nTransfOrmer for Radio Map estimation (STORM). This scheme not only outperforms\nthe existing estimators, but also exhibits lower computational complexity,\ntranslation equivariance, rotation equivariance, and full spatial resolution.\nThe second contribution is an extended transformer architecture that allows\nSTORM to perform active sensing, by which the next measurement location is\nselected based on the previous measurements. This is particularly useful for\nminimization of drive tests (MDT) in cellular networks, where operators request\nuser equipment to collect measurements. Finally, STORM is extensively validated\nby experiments with one ray-tracing and two real-measurement datasets.",
      "tldr_zh": "本论文针对 Radio Map Estimation (RME) 的问题，提出了一种基于注意力的估计器 Spatial TransfOrmer for Radio Map estimation (STORM)，用于空间插值无线电测量以预测未测量位置的接收信号强度，相比传统使用 convolutional deep neural network 的方法，它提高了空间分辨率、降低了计算复杂度，并具备平移等变性和旋转等变性。STORM 的第二个贡献是扩展 transformer 架构，支持 active sensing 功能，能根据先前测量动态选择下一个测量位置，这对 Minimization of Drive Tests (MDT) 在蜂窝网络中的应用特别有益。通过一个射线追踪数据集和两个真实测量数据集的实验验证，STORM 展示了优越的性能和实际可行性。",
      "categories": [
        "math.OC",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "math.OC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.01211v2",
      "published_date": "2024-11-02 11:04:45 UTC",
      "updated_date": "2024-11-07 14:51:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T20:26:36.176065"
    },
    {
      "arxiv_id": "2411.01205v1",
      "title": "PRIMO: Progressive Induction for Multi-hop Open Rule Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Jianyu Liu",
        "Sheng Bi",
        "Guilin Qi"
      ],
      "abstract": "Open rule refer to the implication from premise atoms to hypothesis atoms,\nwhich captures various relations between instances in the real world. Injecting\nopen rule knowledge into the machine helps to improve the performance of\ndownstream tasks such as dialogue and relation extraction. Existing approaches\nfocus on single-hop open rule generation, ignoring multi-hop scenarios, leading\nto logical inconsistencies between premise and hypothesis atoms, as well as\nsemantic duplication of generated rule atoms. To address these issues, we\npropose a progressive multi-stage open rule generation method called PRIMO. We\nintroduce ontology information during the rule generation stage to reduce\nambiguity and improve rule accuracy. PRIMO constructs a multi-stage structure\nconsisting of generation, extraction, and ranking modules to fully leverage the\nlatent knowledge within the language model across multiple dimensions.\nFurthermore, we employ reinforcement learning from human feedback to further\noptimize model, enhancing the model's understanding of commonsense knowledge.\nExperiments show that compared to baseline models, PRIMO significantly improves\nrule quality and diversity while reducing the repetition rate of rule atoms.",
      "tldr_zh": "本文提出 PRIMO 方法，这是一种渐进的多阶段框架，用于生成多跳 open rule，以解决现有方法的逻辑不一致和语义重复问题。PRIMO 通过引入 ontology information 并构建生成、提取和排名模块，利用语言模型的潜在知识，并采用 reinforcement learning from human feedback 来优化模型对常识知识的理解。实验结果表明，与基线模型相比，PRIMO 显著提升了规则的质量、多样性和准确性，同时降低了规则原子的重复率。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "COLING 2024",
      "pdf_url": "http://arxiv.org/pdf/2411.01205v1",
      "published_date": "2024-11-02 10:33:50 UTC",
      "updated_date": "2024-11-02 10:33:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T20:26:47.295435"
    },
    {
      "arxiv_id": "2411.01204v1",
      "title": "Class-specific feature selection for classification explainability",
      "title_zh": "类特定的特征选择用于分类可解释性",
      "authors": [
        "Jesus S. Aguilar-Ruiz"
      ],
      "abstract": "Feature Selection techniques aim at finding a relevant subset of features\nthat perform equally or better than the original set of features at explaining\nthe behavior of data. Typically, features are extracted from feature ranking or\nsubset selection techniques, and the performance is measured by classification\nor regression tasks. However, while selected features may not have equal\nimportance for the task, they do have equal importance for each class. This\nwork first introduces a comprehensive review of the concept of class-specific,\nwith a focus on feature selection and classification. The fundamental idea of\nthe class-specific concept resides in the understanding that the significance\nof each feature can vary from one class to another. This contrasts with the\ntraditional class-independent approach, which evaluates the importance of\nattributes collectively for all classes. For example, in tumor prediction\nscenarios, each type of tumor may be associated with a distinct subset of\nrelevant features. These features possess significant discriminatory power,\nenabling the differentiation of one tumor type from others. This class-specific\nperspective offers a more effective approach to classification tasks by\nrecognizing and leveraging the unique characteristics of each class. Secondly,\nclassification schemes from one-versus-all and one-versus-each strategies are\ndescribed, and a novel deep one-versus-each strategy is introduced, which\noffers advantages from the point of view of explainability (feature selection)\nand decomposability (classification). Thirdly, a novel class-specific relevance\nmatrix is presented, from which some more sophisticated classification schemes\ncan be derived, such as the three-layer class-specific scheme. The potential\nfor further advancements is wide and will open new horizons for exploring novel\nresearch directions in multiclass hyperdimensional contexts.",
      "tldr_zh": "该论文探讨了类特定（class-specific）特征选择技术，以提升分类任务的可解释性（classification explainability）。传统特征选择方法假设特征对所有类的重要性相同，但作者强调，每个特征的重要性可能因类而异，例如在肿瘤预测中，不同肿瘤类型对应不同的相关特征子集。论文首先回顾了类特定概念，并引入了一种新型深度 one-versus-each 策略，结合 one-versus-all 方法，提高了特征选择的可解释性和分类的可分解性（decomposability）。此外，作者提出一个类特定相关矩阵（class-specific relevance matrix），用于衍生更先进的分类方案，如三层类特定方案，并指出这为多类超维度（multiclass hyperdimensional）环境下的新研究方向提供了广阔潜力。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.01204v1",
      "published_date": "2024-11-02 10:31:55 UTC",
      "updated_date": "2024-11-02 10:31:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T20:26:59.792515"
    },
    {
      "arxiv_id": "2411.01203v1",
      "title": "XNB: Explainable Class-Specific NaIve-Bayes Classifier",
      "title_zh": "翻译失败",
      "authors": [
        "Jesus S. Aguilar-Ruiz",
        "Cayetano Romero",
        "Andrea Cicconardi"
      ],
      "abstract": "In today's data-intensive landscape, where high-dimensional datasets are\nincreasingly common, reducing the number of input features is essential to\nprevent overfitting and improve model accuracy. Despite numerous efforts to\ntackle dimensionality reduction, most approaches apply a universal set of\nfeatures across all classes, potentially missing the unique characteristics of\nindividual classes. This paper presents the Explainable Class-Specific Naive\nBayes (XNB) classifier, which introduces two critical innovations: 1) the use\nof Kernel Density Estimation to calculate posterior probabilities, allowing for\na more accurate and flexible estimation process, and 2) the selection of\nclass-specific feature subsets, ensuring that only the most relevant variables\nfor each class are utilized. Extensive empirical analysis on high-dimensional\ngenomic datasets shows that XNB matches the classification performance of\ntraditional Naive Bayes while drastically improving model interpretability. By\nisolating the most relevant features for each class, XNB not only reduces the\nfeature set to a minimal, distinct subset for each class but also provides\ndeeper insights into how the model makes predictions. This approach offers\nsignificant advantages in fields where both precision and explainability are\ncritical.",
      "tldr_zh": "这篇论文提出了 Explainable Class-Specific Naive Bayes (XNB) 分类器，用于解决高维数据集中的特征选择问题，通过针对每个类别的独特特性避免统一特征集的局限。XNB 的关键创新包括使用 Kernel Density Estimation 计算后验概率以实现更准确灵活的估计，以及选择类特定特征子集以仅保留每个类别的相关变量。在高维基因组数据集上的实验显示，XNB 的分类性能与传统 Naive Bayes 相当，但显著提升了模型的可解释性。该方法为需要精确性和可解释性的领域提供了更深入的预测洞察和特征优化。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.01203v1",
      "published_date": "2024-11-02 10:28:22 UTC",
      "updated_date": "2024-11-02 10:28:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T20:27:11.678566"
    },
    {
      "arxiv_id": "2411.01200v3",
      "title": "GarmentLab: A Unified Simulation and Benchmark for Garment Manipulation",
      "title_zh": "翻译失败",
      "authors": [
        "Haoran Lu",
        "Ruihai Wu",
        "Yitong Li",
        "Sijie Li",
        "Ziyu Zhu",
        "Chuanruo Ning",
        "Yan Shen",
        "Longzan Luo",
        "Yuanpei Chen",
        "Hao Dong"
      ],
      "abstract": "Manipulating garments and fabrics has long been a critical endeavor in the\ndevelopment of home-assistant robots. However, due to complex dynamics and\ntopological structures, garment manipulations pose significant challenges.\nRecent successes in reinforcement learning and vision-based methods offer\npromising avenues for learning garment manipulation. Nevertheless, these\napproaches are severely constrained by current benchmarks, which offer limited\ndiversity of tasks and unrealistic simulation behavior. Therefore, we present\nGarmentLab, a content-rich benchmark and realistic simulation designed for\ndeformable object and garment manipulation. Our benchmark encompasses a diverse\nrange of garment types, robotic systems and manipulators. The abundant tasks in\nthe benchmark further explores of the interactions between garments, deformable\nobjects, rigid bodies, fluids, and human body. Moreover, by incorporating\nmultiple simulation methods such as FEM and PBD, along with our proposed\nsim-to-real algorithms and real-world benchmark, we aim to significantly narrow\nthe sim-to-real gap. We evaluate state-of-the-art vision methods, reinforcement\nlearning, and imitation learning approaches on these tasks, highlighting the\nchallenges faced by current algorithms, notably their limited generalization\ncapabilities. Our proposed open-source environments and comprehensive analysis\nshow promising boost to future research in garment manipulation by unlocking\nthe full potential of these methods. We guarantee that we will open-source our\ncode as soon as possible. You can watch the videos in supplementary files to\nlearn more about the details of our work. Our project page is available at:\nhttps://garmentlab.github.io/",
      "tldr_zh": "这篇论文提出了 GarmentLab，这是一个统一的模拟和基准框架，旨在解决服装操控在机器人领域面临的复杂动态和拓扑挑战。GarmentLab 涵盖多样化的服装类型、机器人系统和任务，包括服装与其他物体（如可变形物体、刚体、流体和人体）的交互，并采用 FEM 和 PBD 等模拟方法结合 sim-to-real 算法来缩小模拟与现实差距。实验评估显示，当前视觉方法、强化学习和模仿学习算法在这些任务上存在显著的泛化能力不足问题，而 GarmentLab 的开源环境有望推动未来服装操控研究的进展。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV",
        "cs.HC"
      ],
      "primary_category": "cs.RO",
      "comment": "NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2411.01200v3",
      "published_date": "2024-11-02 10:09:08 UTC",
      "updated_date": "2024-12-23 14:33:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T20:27:23.537888"
    },
    {
      "arxiv_id": "2411.01188v1",
      "title": "Learning Rules Explaining Interactive Theorem Proving Tactic Prediction",
      "title_zh": "学习规则解释交互式定理证明策略预测",
      "authors": [
        "Liao Zhang",
        "David M. Cerna",
        "Cezary Kaliszyk"
      ],
      "abstract": "Formally verifying the correctness of mathematical proofs is more accessible\nthan ever, however, the learning curve remains steep for many of the\nstate-of-the-art interactive theorem provers (ITP). Deriving the most\nappropriate subsequent proof step, and reasoning about it, given the multitude\nof possibilities, remains a daunting task for novice users. To improve the\nsituation, several investigations have developed machine learning based\nguidance for tactic selection. Such approaches struggle to learn non-trivial\nrelationships between the chosen tactic and the structure of the proof state\nand represent them as symbolic expressions. To address these issues we (i) We\nrepresent the problem as an Inductive Logic Programming (ILP) task, (ii) Using\nthe ILP representation we enriched the feature space by encoding additional,\ncomputationally expensive properties as background knowledge predicates, (iii)\nWe use this enriched feature space to learn rules explaining when a tactic is\napplicable to a given proof state, (iv) we use the learned rules to filter the\noutput of an existing tactic selection approach and empirically show\nimprovement over the non-filtering approaches.",
      "tldr_zh": "本研究针对交互式定理证明 (ITP) 的陡峭学习曲线问题，提出一种方法来学习规则，以解释策略预测的适用性，从而帮助新手用户更好地选择和推理证明步骤。作者将问题表述为 Inductive Logic Programming (ILP) 任务，并通过编码额外的计算密集型属性作为背景知识谓词来丰富特征空间，从而学习出符号表达式形式的规则。利用这些规则过滤现有策略选择方法的输出，实验结果显示该方法在性能上优于未过滤的基线方法，为提升 ITP 的用户友好性提供了新途径。",
      "categories": [
        "cs.LO",
        "cs.AI",
        "cs.LG",
        "F.4.1, I.2.4"
      ],
      "primary_category": "cs.LO",
      "comment": "15 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2411.01188v1",
      "published_date": "2024-11-02 09:18:33 UTC",
      "updated_date": "2024-11-02 09:18:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T20:27:35.227986"
    },
    {
      "arxiv_id": "2411.01184v1",
      "title": "Guiding Multi-agent Multi-task Reinforcement Learning by a Hierarchical Framework with Logical Reward Shaping",
      "title_zh": "通过分层",
      "authors": [
        "Chanjuan Liu",
        "Jinmiao Cong",
        "Bingcai Chen",
        "Yaochu Jin",
        "Enqiang Zhu"
      ],
      "abstract": "Multi-agent hierarchical reinforcement learning (MAHRL) has been studied as\nan effective means to solve intelligent decision problems in complex and\nlarge-scale environments. However, most current MAHRL algorithms follow the\ntraditional way of using reward functions in reinforcement learning, which\nlimits their use to a single task. This study aims to design a multi-agent\ncooperative algorithm with logic reward shaping (LRS), which uses a more\nflexible way of setting the rewards, allowing for the effective completion of\nmulti-tasks. LRS uses Linear Temporal Logic (LTL) to express the internal logic\nrelation of subtasks within a complex task. Then, it evaluates whether the\nsubformulae of the LTL expressions are satisfied based on a designed reward\nstructure. This helps agents to learn to effectively complete tasks by adhering\nto the LTL expressions, thus enhancing the interpretability and credibility of\ntheir decisions. To enhance coordination and cooperation among multiple agents,\na value iteration technique is designed to evaluate the actions taken by each\nagent. Based on this evaluation, a reward function is shaped for coordination,\nwhich enables each agent to evaluate its status and complete the remaining\nsubtasks through experiential learning. Experiments have been conducted on\nvarious types of tasks in the Minecraft-like environment. The results\ndemonstrate that the proposed algorithm can improve the performance of\nmulti-agents when learning to complete multi-tasks.",
      "tldr_zh": "该研究针对多智能体分层强化学习（MAHRL）算法的传统奖励函数限制于单任务的问题，提出了一种基于逻辑奖励塑造（LRS）的多智能体合作框架，利用线性时序逻辑（LTL）来表达复杂任务中子任务的内部逻辑关系，并通过评估 LTL 子公式来设计奖励结构，以提升代理的可解释性和可信度。框架还引入价值迭代技术来评估代理动作并塑造协调奖励函数，帮助代理通过经验学习完成剩余子任务，从而增强多智能体间的合作。实验在 Minecraft-like 环境中的多任务场景中进行，结果显示，该算法显著提高了多智能体的性能，证明了其在多任务学习中的有效性。",
      "categories": [
        "cs.AI",
        "cs.LO"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.01184v1",
      "published_date": "2024-11-02 09:03:23 UTC",
      "updated_date": "2024-11-02 09:03:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T20:27:47.689061"
    },
    {
      "arxiv_id": "2411.01179v1",
      "title": "Hollowed Net for On-Device Personalization of Text-to-Image Diffusion Models",
      "title_zh": "翻译失败",
      "authors": [
        "Wonguk Cho",
        "Seokeon Choi",
        "Debasmit Das",
        "Matthias Reisser",
        "Taesup Kim",
        "Sungrack Yun",
        "Fatih Porikli"
      ],
      "abstract": "Recent advancements in text-to-image diffusion models have enabled the\npersonalization of these models to generate custom images from textual prompts.\nThis paper presents an efficient LoRA-based personalization approach for\non-device subject-driven generation, where pre-trained diffusion models are\nfine-tuned with user-specific data on resource-constrained devices. Our method,\ntermed Hollowed Net, enhances memory efficiency during fine-tuning by modifying\nthe architecture of a diffusion U-Net to temporarily remove a fraction of its\ndeep layers, creating a hollowed structure. This approach directly addresses\non-device memory constraints and substantially reduces GPU memory requirements\nfor training, in contrast to previous methods that primarily focus on\nminimizing training steps and reducing the number of parameters to update.\nAdditionally, the personalized Hollowed Net can be transferred back into the\noriginal U-Net, enabling inference without additional memory overhead.\nQuantitative and qualitative analyses demonstrate that our approach not only\nreduces training memory to levels as low as those required for inference but\nalso maintains or improves personalization performance compared to existing\nmethods.",
      "tldr_zh": "这篇论文提出了Hollowed Net，一种基于LoRA的个性化方法，用于在资源受限设备上微调文本到图像扩散模型，从而实现用户驱动的图像生成。方法通过修改扩散U-Net的架构，临时移除部分深层以创建空心结构，大大降低了训练时的GPU内存需求，同时避免了以往方法仅聚焦于减少训练步骤和参数更新的局限。实验结果显示，Hollowed Net将训练内存需求降低到与推理相当的水平，并保持或提升了个性化性能，为on-device个性化提供了高效解决方案。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.GR",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2411.01179v1",
      "published_date": "2024-11-02 08:42:48 UTC",
      "updated_date": "2024-11-02 08:42:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T20:27:58.303752"
    },
    {
      "arxiv_id": "2411.02438v1",
      "title": "Entropic Hetero-Associative Memory",
      "title_zh": "翻译失败",
      "authors": [
        "Rafael Morales",
        "Luis A. Pineda"
      ],
      "abstract": "The Entropic Associative Memory holds objects in a 2D relation or ``memory\nplane'' using a finite table as the medium. Memory objects are stored by\nreinforcing simultaneously the cells used by the cue, implementing a form of\nHebb's learning rule. Stored objects are ``overlapped'' on the medium, hence\nthe memory is indeterminate and has an entropy value at each state. The\nretrieval operation constructs an object from the cue and such indeterminate\ncontent. In this paper we present the extension to the hetero-associative case\nin which these properties are preserved. Pairs of hetero-associated objects,\npossibly of different domain and/or modalities, are held in a 4D relation. The\nmemory retrieval operation selects a largely indeterminate 2D memory plane that\nis specific to the input cue; however, there is no cue left to retrieve an\nobject from such latter plane. We propose three incremental methods to address\nsuch missing cue problem, which we call random, sample and test, and search and\ntest. The model is assessed with composite recollections consisting of\nmanuscripts digits and letters selected from the MNIST and the EMNIST corpora,\nrespectively, such that cue digits retrieve their associated letters and vice\nversa. We show the memory performance and illustrate the memory retrieval\noperation using all three methods. The system shows promise for storing,\nrecognizing and retrieving very large sets of object with very limited\ncomputing resources.",
      "tldr_zh": "本论文扩展了Entropic Associative Memory模型，提出Entropic Hetero-Associative Memory，用于在4D关系中存储异质关联对象对（如不同领域或模态），这些对象通过Hebb's learning rule在有限表中重叠存储，导致记忆不确定性和熵值。针对检索操作中缺少后续提示的问题，作者引入三种方法：random、sample and test以及search and test，以从输入提示中选择并处理不确定的2D记忆平面。实验使用MNIST和EMNIST数据集评估了系统在存储和检索手写数字与字母的复合回忆方面的性能，结果显示该系统在有限计算资源下，能够高效识别和检索大量对象，具有广阔的应用潜力。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "17 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2411.02438v1",
      "published_date": "2024-11-02 08:30:57 UTC",
      "updated_date": "2024-11-02 08:30:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T20:28:10.854954"
    },
    {
      "arxiv_id": "2411.01173v1",
      "title": "Reasoning Limitations of Multimodal Large Language Models. A case study of Bongard Problems",
      "title_zh": "多模态大型语言模型的推理限制：Bongard Problems 的案例研究",
      "authors": [
        "Mikołaj Małkiński",
        "Szymon Pawlonka",
        "Jacek Mańdziuk"
      ],
      "abstract": "Abstract visual reasoning (AVR) encompasses a suite of tasks whose solving\nrequires the ability to discover common concepts underlying the set of pictures\nthrough an analogy-making process, similarly to human IQ tests. Bongard\nProblems (BPs), proposed in 1968, constitute a fundamental challenge in this\ndomain mainly due to their requirement to combine visual reasoning and verbal\ndescription. This work poses a question whether multimodal large language\nmodels (MLLMs) inherently designed to combine vision and language are capable\nof tackling BPs. To this end, we propose a set of diverse MLLM-suited\nstrategies to tackle BPs and examine four popular proprietary MLLMs: GPT-4o,\nGPT-4 Turbo, Gemini 1.5 Pro, and Claude 3.5 Sonnet, and four open models:\nInternVL2-8B, LLaVa-1.6 Mistral-7B, Phi-3.5-Vision, and Pixtral 12B. The above\nMLLMs are compared on three BP datasets: a set of original BP instances relying\non synthetic, geometry-based images and two recent datasets based on real-world\nimages, i.e., Bongard-HOI and Bongard-OpenWorld. The experiments reveal\nsignificant limitations of MLLMs in solving BPs. In particular, the models\nstruggle to solve the classical set of synthetic BPs, despite their visual\nsimplicity. Though their performance ameliorates on real-world concepts\nexpressed in Bongard-HOI and Bongard-OpenWorld, the models still have\ndifficulty in utilizing new information to improve their predictions, as well\nas utilizing a dialog context window effectively. To capture the reasons of\nperformance discrepancy between synthetic and real-world AVR domains, we\npropose Bongard-RWR, a new BP dataset consisting of real-world images that\ntranslates concepts from hand-crafted synthetic BPs to real-world concepts. The\nMLLMs' results on Bongard-RWR suggest that their poor performance on classical\nBPs is not due to domain specificity but rather reflects their general AVR\nlimitations.",
      "tldr_zh": "这篇论文通过对Bongard Problems (BPs) 的案例研究，评估了Multimodal Large Language Models (MLLMs) 在抽象视觉推理 (AVR) 任务中的推理局限性，特别是结合视觉和语言的能力。作者测试了八种MLLMs，包括GPT-4o、Gemini 1.5 Pro等专有模型和开源模型InternVL2-8B等，在三个数据集（经典合成图像BPs、Bongard-HOI 和Bongard-OpenWorld）上进行实验。结果显示，MLLMs在简单合成BPs上表现不佳，尽管在真实世界图像任务上有所改善，但仍难以有效利用新信息和对话上下文。论文进一步提出新数据集Bongard-RWR，将合成BPs概念转化为真实世界图像，证明MLLMs的缺陷源于其一般AVR局限性而非特定领域问题。",
      "categories": [
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.01173v1",
      "published_date": "2024-11-02 08:06:30 UTC",
      "updated_date": "2024-11-02 08:06:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T20:28:24.843905"
    },
    {
      "arxiv_id": "2411.01172v1",
      "title": "Covariance-based Space Regularization for Few-shot Class Incremental Learning",
      "title_zh": "基于协方差的空间正则化用于少样本类增量学习",
      "authors": [
        "Yijie Hu",
        "Guanyu Yang",
        "Zhaorui Tan",
        "Xiaowei Huang",
        "Kaizhu Huang",
        "Qiu-Feng Wang"
      ],
      "abstract": "Few-shot Class Incremental Learning (FSCIL) presents a challenging yet\nrealistic scenario, which requires the model to continually learn new classes\nwith limited labeled data (i.e., incremental sessions) while retaining\nknowledge of previously learned base classes (i.e., base sessions). Due to the\nlimited data in incremental sessions, models are prone to overfitting new\nclasses and suffering catastrophic forgetting of base classes. To tackle these\nissues, recent advancements resort to prototype-based approaches to constrain\nthe base class distribution and learn discriminative representations of new\nclasses. Despite the progress, the limited data issue still induces ill-divided\nfeature space, leading the model to confuse the new class with old classes or\nfail to facilitate good separation among new classes. In this paper, we aim to\nmitigate these issues by directly constraining the span of each class\ndistribution from a covariance perspective. In detail, we propose a simple yet\neffective covariance constraint loss to force the model to learn each class\ndistribution with the same covariance matrix. In addition, we propose a\nperturbation approach to perturb the few-shot training samples in the feature\nspace, which encourages the samples to be away from the weighted distribution\nof other classes. Regarding perturbed samples as new class data, the classifier\nis forced to establish explicit boundaries between each new class and the\nexisting ones. Our approach is easy to integrate into existing FSCIL approaches\nto boost performance. Experiments on three benchmarks validate the\neffectiveness of our approach, achieving a new state-of-the-art performance of\nFSCIL.",
      "tldr_zh": "该论文针对Few-shot Class Incremental Learning (FSCIL)的问题，提出了一种基于协方差的空间正则化方法，以缓解模型在有限数据下过拟合新类和遗忘旧类的问题。具体而言，该方法包括covariance constraint loss，用于强制每个类分布采用相同的协方差矩阵，以及perturbation approach，通过在特征空间扰动训练样本来增强新类与现有类之间的明确边界。实验结果显示，该方法易于整合到现有FSCIL框架中，并在三个基准数据集上实现了新的state-of-the-art性能。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "WACV2025,10 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2411.01172v1",
      "published_date": "2024-11-02 08:03:04 UTC",
      "updated_date": "2024-11-02 08:03:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T20:28:35.693585"
    },
    {
      "arxiv_id": "2411.02437v1",
      "title": "TypeScore: A Text Fidelity Metric for Text-to-Image Generative Models",
      "title_zh": "TypeScore：一种用于文本到图像生成模型的文本保真度指标",
      "authors": [
        "Georgia Gabriela Sampaio",
        "Ruixiang Zhang",
        "Shuangfei Zhai",
        "Jiatao Gu",
        "Josh Susskind",
        "Navdeep Jaitly",
        "Yizhe Zhang"
      ],
      "abstract": "Evaluating text-to-image generative models remains a challenge, despite the\nremarkable progress being made in their overall performances. While existing\nmetrics like CLIPScore work for coarse evaluations, they lack the sensitivity\nto distinguish finer differences as model performance rapidly improves. In this\nwork, we focus on the text rendering aspect of these models, which provides a\nlens for evaluating a generative model's fine-grained instruction-following\ncapabilities. To this end, we introduce a new evaluation framework called\nTypeScore to sensitively assess a model's ability to generate images with\nhigh-fidelity embedded text by following precise instructions. We argue that\nthis text generation capability serves as a proxy for general\ninstruction-following ability in image synthesis. TypeScore uses an additional\nimage description model and leverages an ensemble dissimilarity measure between\nthe original and extracted text to evaluate the fidelity of the rendered text.\nOur proposed metric demonstrates greater resolution than CLIPScore to\ndifferentiate popular image generation models across a range of instructions\nwith diverse text styles. Our study also evaluates how well these\nvision-language models (VLMs) adhere to stylistic instructions, disentangling\nstyle evaluation from embedded-text fidelity. Through human evaluation studies,\nwe quantitatively meta-evaluate the effectiveness of the metric. Comprehensive\nanalysis is conducted to explore factors such as text length, captioning\nmodels, and current progress towards human parity on this task. The framework\nprovides insights into remaining gaps in instruction-following for image\ngeneration with embedded text.",
      "tldr_zh": "这篇论文针对文本到图像生成模型的评估挑战，提出TypeScore指标，以更敏感地评估模型在渲染嵌入文本时的保真度，从而反映其细粒度指令遵循能力。TypeScore框架利用图像描述模型和集成差异度量，比较原始文本与提取文本的差异，并通过实验证明其比CLIPScore更能区分流行模型的表现，尤其在多样文本样式和风格指令上。研究还通过人类评估验证了指标的有效性，并分析了文本长度、标题模型等因素，揭示了当前模型在指令遵循方面的不足和与人类水平的差距。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.02437v1",
      "published_date": "2024-11-02 07:56:54 UTC",
      "updated_date": "2024-11-02 07:56:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T20:28:47.215074"
    },
    {
      "arxiv_id": "2411.01171v1",
      "title": "Fast and Memory-Efficient Video Diffusion Using Streamlined Inference",
      "title_zh": "翻译失败",
      "authors": [
        "Zheng Zhan",
        "Yushu Wu",
        "Yifan Gong",
        "Zichong Meng",
        "Zhenglun Kong",
        "Changdi Yang",
        "Geng Yuan",
        "Pu Zhao",
        "Wei Niu",
        "Yanzhi Wang"
      ],
      "abstract": "The rapid progress in artificial intelligence-generated content (AIGC),\nespecially with diffusion models, has significantly advanced development of\nhigh-quality video generation. However, current video diffusion models exhibit\ndemanding computational requirements and high peak memory usage, especially for\ngenerating longer and higher-resolution videos. These limitations greatly\nhinder the practical application of video diffusion models on standard hardware\nplatforms. To tackle this issue, we present a novel, training-free framework\nnamed Streamlined Inference, which leverages the temporal and spatial\nproperties of video diffusion models. Our approach integrates three core\ncomponents: Feature Slicer, Operator Grouping, and Step Rehash. Specifically,\nFeature Slicer effectively partitions input features into sub-features and\nOperator Grouping processes each sub-feature with a group of consecutive\noperators, resulting in significant memory reduction without sacrificing the\nquality or speed. Step Rehash further exploits the similarity between adjacent\nsteps in diffusion, and accelerates inference through skipping unnecessary\nsteps. Extensive experiments demonstrate that our approach significantly\nreduces peak memory and computational overhead, making it feasible to generate\nhigh-quality videos on a single consumer GPU (e.g., reducing peak memory of\nAnimateDiff from 42GB to 11GB, featuring faster inference on 2080Ti).",
      "tldr_zh": "该研究针对视频扩散模型在生成长视频和高分辨率视频时的高计算需求和内存占用问题，提出了一种无需额外训练的 Streamlined Inference 框架。该框架利用视频的时空特性，通过 Feature Slicer 分割输入特征、Operator Grouping 处理子特征以减少内存，以及 Step Rehash 利用相邻步骤的相似性跳过不必要步骤，从而实现高效推理。实验结果显示，该方法显著降低峰值内存（如将 AnimateDiff 从 42GB 减至 11GB）和计算开销，使高品质视频生成可在单消费级 GPU（如 2080Ti）上轻松实现。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted to NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2411.01171v1",
      "published_date": "2024-11-02 07:52:18 UTC",
      "updated_date": "2024-11-02 07:52:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T20:29:00.129486"
    },
    {
      "arxiv_id": "2411.01169v1",
      "title": "Bi-Level Graph Structure Learning for Next POI Recommendation",
      "title_zh": "双层图结构学习用于下一个兴趣点推荐",
      "authors": [
        "Liang Wang",
        "Shu Wu",
        "Qiang Liu",
        "Yanqiao Zhu",
        "Xiang Tao",
        "Mengdi Zhang",
        "Liang Wang"
      ],
      "abstract": "Next point-of-interest (POI) recommendation aims to predict a user's next\ndestination based on sequential check-in history and a set of POI candidates.\nGraph neural networks (GNNs) have demonstrated a remarkable capability in this\nendeavor by exploiting the extensive global collaborative signals present among\nPOIs. However, most of the existing graph-based approaches construct graph\nstructures based on pre-defined heuristics, failing to consider inherent\nhierarchical structures of POI features such as geographical locations and\nvisiting peaks, or suffering from noisy and incomplete structures in graphs. To\naddress the aforementioned issues, this paper presents a novel Bi-level Graph\nStructure Learning (BiGSL) for next POI recommendation. BiGSL first learns a\nhierarchical graph structure to capture the fine-to-coarse connectivity between\nPOIs and prototypes, and then uses a pairwise learning module to dynamically\ninfer relationships between POI pairs and prototype pairs. Based on the learned\nbi-level graphs, our model then employs a multi-relational graph network that\nconsiders both POI- and prototype-level neighbors, resulting in improved POI\nrepresentations. Our bi-level structure learning scheme is more robust to data\nnoise and incompleteness, and improves the exploration ability for\nrecommendation by alleviating sparsity issues. Experimental results on three\nreal-world datasets demonstrate the superiority of our model over existing\nstate-of-the-art methods, with a significant improvement in recommendation\naccuracy and exploration performance.",
      "tldr_zh": "该论文针对Next POI Recommendation问题，提出了一种Bi-Level Graph Structure Learning (BiGSL)方法，利用Graph Neural Networks (GNNs)来更好地捕捉POI间的全局协作信号。BiGSL首先学习一个层次化图结构，以捕捉POI和原型之间的细到粗的连接，然后通过配对学习模块动态推断POI对和原型对的关系，从而构建更鲁棒的多关系图网络。实验在三个真实数据集上证明，该方法显著提高了推荐准确性和探索性能，相比现有最先进方法更能处理数据噪声、不完整性和稀疏问题。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.SI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by IEEE Transactions on Knowledge and Data Engineering",
      "pdf_url": "http://arxiv.org/pdf/2411.01169v1",
      "published_date": "2024-11-02 07:40:16 UTC",
      "updated_date": "2024-11-02 07:40:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T20:30:51.792474"
    },
    {
      "arxiv_id": "2411.01168v1",
      "title": "Prompt Tuning with Diffusion for Few-Shot Pre-trained Policy Generalization",
      "title_zh": "翻译失败",
      "authors": [
        "Shengchao Hu",
        "Wanru Zhao",
        "Weixiong Lin",
        "Li Shen",
        "Ya Zhang",
        "Dacheng Tao"
      ],
      "abstract": "Offline reinforcement learning (RL) methods harness previous experiences to\nderive an optimal policy, forming the foundation for pre-trained large-scale\nmodels (PLMs). When encountering tasks not seen before, PLMs often utilize\nseveral expert trajectories as prompts to expedite their adaptation to new\nrequirements. Though a range of prompt-tuning methods have been proposed to\nenhance the quality of prompts, these methods often face optimization\nrestrictions due to prompt initialization, which can significantly constrain\nthe exploration domain and potentially lead to suboptimal solutions. To\neliminate the reliance on the initial prompt, we shift our perspective towards\nthe generative model, framing the prompt-tuning process as a form of\nconditional generative modeling, where prompts are generated from random noise.\nOur innovation, the Prompt Diffuser, leverages a conditional diffusion model to\nproduce prompts of exceptional quality. Central to our framework is the\napproach to trajectory reconstruction and the meticulous integration of\ndownstream task guidance during the training phase. Further experimental\nresults underscore the potency of the Prompt Diffuser as a robust and effective\ntool for the prompt-tuning process, demonstrating strong performance in the\nmeta-RL tasks.",
      "tldr_zh": "这篇论文针对少样本预训练策略泛化问题，提出Prompt Diffuser方法，使用条件扩散模型（Diffusion Model）从随机噪声生成高质量提示，从而消除传统提示调整对初始化的依赖。核心创新包括轨迹重建和下游任务指导的整合，确保提示优化过程更高效。实验结果显示，Prompt Diffuser在元强化学习（meta-RL）任务中表现出色，提供了一个鲁棒的提示调整框架。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "19 pages",
      "pdf_url": "http://arxiv.org/pdf/2411.01168v1",
      "published_date": "2024-11-02 07:38:02 UTC",
      "updated_date": "2024-11-02 07:38:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T20:29:22.700558"
    },
    {
      "arxiv_id": "2411.01166v1",
      "title": "Role Play: Learning Adaptive Role-Specific Strategies in Multi-Agent Interactions",
      "title_zh": "翻译失败",
      "authors": [
        "Weifan Long",
        "Wen Wen",
        "Peng Zhai",
        "Lihua Zhang"
      ],
      "abstract": "Zero-shot coordination problem in multi-agent reinforcement learning (MARL),\nwhich requires agents to adapt to unseen agents, has attracted increasing\nattention. Traditional approaches often rely on the Self-Play (SP) framework to\ngenerate a diverse set of policies in a policy pool, which serves to improve\nthe generalization capability of the final agent. However, these frameworks may\nstruggle to capture the full spectrum of potential strategies, especially in\nreal-world scenarios that demand agents balance cooperation with competition.\nIn such settings, agents need strategies that can adapt to varying and often\nconflicting goals. Drawing inspiration from Social Value Orientation\n(SVO)-where individuals maintain stable value orientations during interactions\nwith others-we propose a novel framework called \\emph{Role Play} (RP). RP\nemploys role embeddings to transform the challenge of policy diversity into a\nmore manageable diversity of roles. It trains a common policy with role\nembedding observations and employs a role predictor to estimate the joint role\nembeddings of other agents, helping the learning agent adapt to its assigned\nrole. We theoretically prove that an approximate optimal policy can be achieved\nby optimizing the expected cumulative reward relative to an approximate\nrole-based policy. Experimental results in both cooperative (Overcooked) and\nmixed-motive games (Harvest, CleanUp) reveal that RP consistently outperforms\nstrong baselines when interacting with unseen agents, highlighting its\nrobustness and adaptability in complex environments.",
      "tldr_zh": "本研究针对多智能体强化学习（MARL）中的零样本协调（zero-shot coordination）问题，提出了一种名为 Role Play (RP) 的新框架，以帮助智能体适应未见过的其他智能体。RP 通过角色嵌入（role embeddings）将策略多样性转化为角色多样性，训练一个通用策略并使用角色预测器估计其他智能体的联合角色嵌入，从而使智能体根据分配角色实现自适应策略。论文理论证明了优化基于角色的预期累积奖励可实现近似最优策略；在合作游戏（如 Overcooked）和混合动机游戏（如 Harvest 和 CleanUp）中的实验显示，RP 比 Self-Play (SP) 等基线方法表现出更强的鲁棒性和适应性。",
      "categories": [
        "cs.MA",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.MA",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.01166v1",
      "published_date": "2024-11-02 07:25:48 UTC",
      "updated_date": "2024-11-02 07:25:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T20:31:04.408831"
    },
    {
      "arxiv_id": "2411.14433v1",
      "title": "Transforming Engineering Education Using Generative AI and Digital Twin Technologies",
      "title_zh": "翻译失败",
      "authors": [
        "Yu-Zheng Lin",
        "Ahmed Hussain J Alhamadah",
        "Matthew William Redondo",
        "Karan Himanshu Patel",
        "Sujan Ghimire",
        "Banafsheh Saber Latibari",
        "Soheil Salehi",
        "Pratik Satam"
      ],
      "abstract": "Digital twin technology, traditionally used in industry, is increasingly\nrecognized for its potential to enhance educational experiences. This study\ninvestigates the application of industrial digital twins (DTs) in education,\nfocusing on how DT models of varying fidelity can support different stages of\nBloom's taxonomy in the cognitive domain. We align Bloom's six cognitive stages\nwith educational levels: undergraduate studies for \"Remember\" and \"Understand,\"\nmaster's level for \"Apply\" and \"Analyze,\" and doctoral level for \"Evaluate\" and\n\"Create.\" Low-fidelity DTs aid essential knowledge acquisition and skill\ntraining, providing a low-risk environment for grasping fundamental concepts.\nMedium-fidelity DTs offer more detailed and dynamic simulations, enhancing\napplication skills and problem-solving. High-fidelity DTs support advanced\nlearners by replicating physical phenomena, allowing for innovative design and\ncomplex experiments. Within this framework, large language models (LLMs) serve\nas mentors, assessing progress, filling knowledge gaps, and assisting with DT\ninteractions, parameter setting, and debugging. We evaluate the educational\nimpact using the Kirkpatrick Model, examining how each DT model's fidelity\ninfluences learning outcomes. This framework helps educators make informed\ndecisions on integrating DTs and LLMs to meet specific learning objectives.",
      "tldr_zh": "这篇论文探讨了使用数字孪生 (DTs) 和生成式 AI 技术改造工程教育的方法，特别将工业 DTs 与 Bloom's 分类法整合，以支持不同认知阶段的学习。研究将低保真度 DTs 用于本科生的“Remember”和“Understand”阶段，帮助基础知识获取和技能训练；中保真度 DTs 增强硕士生的“Apply”和“Analyze”能力，提供动态模拟；高保真度 DTs 则支持博士生的“Evaluate”和“Create”，实现复杂实验和创新设计。同时，大型语言模型 (LLMs) 作为导师评估学习进度、填补知识缺口，并辅助 DT 互动。最终，通过 Kirkpatrick 模型评估，该框架帮助教育者根据具体学习目标选择合适的 DT 模型，提升整体教育效果。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.CR",
        "cs.HC"
      ],
      "primary_category": "cs.CY",
      "comment": "8 pages, 7 figures",
      "pdf_url": "http://arxiv.org/pdf/2411.14433v1",
      "published_date": "2024-11-02 07:16:47 UTC",
      "updated_date": "2024-11-02 07:16:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T20:31:16.464997"
    },
    {
      "arxiv_id": "2411.01159v2",
      "title": "Supervised Score-Based Modeling by Gradient Boosting",
      "title_zh": "翻译失败",
      "authors": [
        "Changyuan Zhao",
        "Hongyang Du",
        "Guangyuan Liu",
        "Dusit Niyato"
      ],
      "abstract": "Score-based generative models can effectively learn the distribution of data\nby estimating the gradient of the distribution. Due to the multi-step denoising\ncharacteristic, researchers have recently considered combining score-based\ngenerative models with the gradient boosting algorithm, a multi-step supervised\nlearning algorithm, to solve supervised learning tasks. However, existing\ngenerative model algorithms are often limited by the stochastic nature of the\nmodels and the long inference time, impacting prediction performances.\nTherefore, we propose a Supervised Score-based Model (SSM), which can be viewed\nas a gradient boosting algorithm combining score matching. We provide a\ntheoretical analysis of learning and sampling for SSM to balance inference time\nand prediction accuracy. Via the ablation experiment in selected examples, we\ndemonstrate the outstanding performances of the proposed techniques.\nAdditionally, we compare our model with other probabilistic models, including\nNatural Gradient Boosting (NGboost), Classification and Regression Diffusion\nModels (CARD), Diffusion Boosted Trees (DBT), and non-probabilistic GBM models.\nThe experimental results show that our model outperforms existing models in\nboth accuracy and inference time.",
      "tldr_zh": "本文提出了一种Supervised Score-Based Model (SSM)，将分数匹配与梯度提升算法相结合，用于解决监督学习任务中的分布估计问题。该模型通过理论分析平衡了推理时间和预测准确性，避免了传统生成模型的随机性和低效性。在实验中，SSM 与NGboost、CARD、Diffusion Boosted Trees (DBT)以及非概率GBM模型相比，表现出更高的准确性和更短的推理时间，验证了其优越性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.01159v2",
      "published_date": "2024-11-02 07:06:53 UTC",
      "updated_date": "2024-12-15 12:02:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T20:31:27.186001"
    },
    {
      "arxiv_id": "2411.01158v1",
      "title": "Pin-Tuning: Parameter-Efficient In-Context Tuning for Few-Shot Molecular Property Prediction",
      "title_zh": "Pin-Tuning：参数高效的上下文内调优，用于少样本分子属性预测",
      "authors": [
        "Liang Wang",
        "Qiang Liu",
        "Shaozhen Liu",
        "Xin Sun",
        "Shu Wu",
        "Liang Wang"
      ],
      "abstract": "Molecular property prediction (MPP) is integral to drug discovery and\nmaterial science, but often faces the challenge of data scarcity in real-world\nscenarios. Addressing this, few-shot molecular property prediction (FSMPP) has\nbeen developed. Unlike other few-shot tasks, FSMPP typically employs a\npre-trained molecular encoder and a context-aware classifier, benefiting from\nmolecular pre-training and molecular context information. Despite these\nadvancements, existing methods struggle with the ineffective fine-tuning of\npre-trained encoders. We attribute this issue to the imbalance between the\nabundance of tunable parameters and the scarcity of labeled molecules, and the\nlack of contextual perceptiveness in the encoders. To overcome this hurdle, we\npropose a parameter-efficient in-context tuning method, named Pin-Tuning.\nSpecifically, we propose a lightweight adapter for pre-trained message passing\nlayers (MP-Adapter) and Bayesian weight consolidation for pre-trained atom/bond\nembedding layers (Emb-BWC), to achieve parameter-efficient tuning while\npreventing over-fitting and catastrophic forgetting. Additionally, we enhance\nthe MP-Adapters with contextual perceptiveness. This innovation allows for\nin-context tuning of the pre-trained encoder, thereby improving its\nadaptability for specific FSMPP tasks. When evaluated on public datasets, our\nmethod demonstrates superior tuning with fewer trainable parameters, improving\nfew-shot predictive performance.",
      "tldr_zh": "分子属性预测（MPP）在药物发现和材料科学中至关重要，但受限于数据稀缺，现有Few-Shot Molecular Property Prediction (FSMPP) 方法在微调预训练编码器时效率低下，主要因可调参数过多和缺乏上下文感知。我们提出Pin-Tuning方法，包括轻量级适配器MP-Adapter用于消息传递层，以及Bayesian weight consolidation (Emb-BWC)用于原子/键嵌入层，以实现参数高效调优、防止过拟合和灾难性遗忘，同时增强编码器的上下文感知能力。在公共数据集上的评估显示，Pin-Tuning显著提高了FSMPP的预测性能，同时减少了可训练参数。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "q-bio.MN"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2411.01158v1",
      "published_date": "2024-11-02 07:06:30 UTC",
      "updated_date": "2024-11-02 07:06:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T20:31:40.140800"
    },
    {
      "arxiv_id": "2411.01153v1",
      "title": "Designing a Robust Radiology Report Generation System",
      "title_zh": "设计一个鲁棒的放射学报告生成系统",
      "authors": [
        "Sonit Singh"
      ],
      "abstract": "Recent advances in deep learning have enabled researchers to explore tasks at\nthe intersection of computer vision and natural language processing, such as\nimage captioning, visual question answering, visual dialogue, and visual\nlanguage navigation. Taking inspiration from image captioning, the task of\nradiology report generation aims at automatically generating radiology reports\nby having a comprehensive understanding of medical images. However,\nautomatically generating radiology reports from medical images is a challenging\ntask due to the complexity, diversity, and nature of medical images. In this\npaper, we outline the design of a robust radiology report generation system by\nintegrating different modules and highlighting best practices drawing upon\nlessons from our past work and also from relevant studies in the literature. We\nalso discuss the impact of integrating different components to form a single\nintegrated system. We believe that these best practices, when implemented,\ncould improve automatic radiology report generation, augment radiologists in\ndecision making, and expedite diagnostic workflow, in turn improve healthcare\nand save human lives.",
      "tldr_zh": "这篇论文探讨了设计一个稳健的放射学报告生成系统，利用深度学习在计算机视觉和自然语言处理交叉领域的进展，例如图像描述和视觉问答。系统通过整合不同模块和最佳实践，应对医学图像的复杂性、多样性和特性，从而实现对图像的全面理解并自动生成报告。研究强调，这种整合方法能提升报告生成质量、辅助放射科医生决策、加速诊断流程，并最终改善医疗保健和挽救生命。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "21 pages, 2 figures",
      "pdf_url": "http://arxiv.org/pdf/2411.01153v1",
      "published_date": "2024-11-02 06:38:04 UTC",
      "updated_date": "2024-11-02 06:38:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T20:31:50.988198"
    },
    {
      "arxiv_id": "2411.01146v1",
      "title": "Task-Aware Harmony Multi-Task Decision Transformer for Offline Reinforcement Learning",
      "title_zh": "任务感知和谐多任务决策 Transformer 用于离线强化学习",
      "authors": [
        "Ziqing Fan",
        "Shengchao Hu",
        "Yuhang Zhou",
        "Li Shen",
        "Ya Zhang",
        "Yanfeng Wang",
        "Dacheng Tao"
      ],
      "abstract": "The purpose of offline multi-task reinforcement learning (MTRL) is to develop\na unified policy applicable to diverse tasks without the need for online\nenvironmental interaction. Recent advancements approach this through sequence\nmodeling, leveraging the Transformer architecture's scalability and the\nbenefits of parameter sharing to exploit task similarities. However, variations\nin task content and complexity pose significant challenges in policy\nformulation, necessitating judicious parameter sharing and management of\nconflicting gradients for optimal policy performance. Furthermore, identifying\nthe optimal parameter subspace for each task often necessitates prior knowledge\nof the task identifier during inference, limiting applicability in real-world\nscenarios with variable task content and unknown current tasks. In this work,\nwe introduce the Harmony Multi-Task Decision Transformer (HarmoDT), a novel\nsolution designed to identify an optimal harmony subspace of parameters for\neach task. We formulate this as a bi-level optimization problem within a\nmeta-learning framework, where the upper level learns masks to define the\nharmony subspace, while the inner level focuses on updating parameters to\nimprove the overall performance of the unified policy. To eliminate the need\nfor task identifiers, we further design a group-wise variant (G-HarmoDT) that\nclusters tasks into coherent groups based on gradient information, and utilizes\na gating network to determine task identifiers during inference. Empirical\nevaluations across various benchmarks highlight the superiority of our\napproach, demonstrating its effectiveness in the multi-task context with\nspecific improvements of 8% gain in task-provided settings, 5% in task-agnostic\nsettings, and 10% in unseen settings.",
      "tldr_zh": "本论文针对离线强化学习（Offline Reinforcement Learning）中的多任务场景，提出了一种任务感知的Harmony Multi-Task Decision Transformer（HarmoDT），旨在通过参数共享和梯度冲突管理来开发统一的策略，而无需在线环境交互。HarmoDT 将问题建模为双层优化框架，其中上层学习掩码定义每个任务的和谐参数子空间，下层更新参数以提升整体策略性能；此外，作者设计了分组变体 G-HarmoDT，通过梯度信息聚类任务并使用门控网络在推理时自动确定任务标识，从而避免依赖先验知识。实验结果显示，该方法在多个基准上表现出色，分别在任务提供设置提升8%、任务无关设置提升5%、以及未见过设置提升10%。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Extension of corresponding ICML edition arXiv:2405.18080. arXiv admin\n  note: substantial text overlap with arXiv:2405.18080",
      "pdf_url": "http://arxiv.org/pdf/2411.01146v1",
      "published_date": "2024-11-02 05:49:14 UTC",
      "updated_date": "2024-11-02 05:49:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T20:32:03.580927"
    },
    {
      "arxiv_id": "2411.01144v1",
      "title": "LEARNER: Learning Granular Labels from Coarse Labels using Contrastive Learning",
      "title_zh": "LEARNER：使用对比学习从粗粒度标签学习细粒度标签",
      "authors": [
        "Gautam Gare",
        "Jana Armouti",
        "Nikhil Madaan",
        "Rohan Panda",
        "Tom Fox",
        "Laura Hutchins",
        "Amita Krishnan",
        "Ricardo Rodriguez",
        "Bennett DeBoisblanc",
        "Deva Ramanan",
        "John Galeotti"
      ],
      "abstract": "A crucial question in active patient care is determining if a treatment is\nhaving the desired effect, especially when changes are subtle over short\nperiods. We propose using inter-patient data to train models that can learn to\ndetect these fine-grained changes within a single patient. Specifically, can a\nmodel trained on multi-patient scans predict subtle changes in an individual\npatient's scans? Recent years have seen increasing use of deep learning (DL) in\npredicting diseases using biomedical imaging, such as predicting COVID-19\nseverity using lung ultrasound (LUS) data. While extensive literature exists on\nsuccessful applications of DL systems when well-annotated large-scale datasets\nare available, it is quite difficult to collect a large corpus of personalized\ndatasets for an individual. In this work, we investigate the ability of recent\ncomputer vision models to learn fine-grained differences while being trained on\ndata showing larger differences. We evaluate on an in-house LUS dataset and a\npublic ADNI brain MRI dataset. We find that models pre-trained on clips from\nmultiple patients can better predict fine-grained differences in scans from a\nsingle patient by employing contrastive learning.",
      "tldr_zh": "该论文提出LEARNER框架，使用Contrastive Learning从粗粒度标签学习细粒度标签，旨在帮助模型检测患者扫描中的细微变化，例如治疗效果的微妙差异。研究通过在多患者数据上训练计算机视觉模型，并应用于单个患者的LUS和ADNI脑MRI数据集，评估模型学习细粒度差异的能力。结果表明，这种方法显著提高了模型对细微变化的预测准确性，为医疗成像中缺乏个性化数据集的场景提供了实用解决方案。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "eess.IV",
      "comment": "Under review at ISBI 2025 conference",
      "pdf_url": "http://arxiv.org/pdf/2411.01144v1",
      "published_date": "2024-11-02 05:27:52 UTC",
      "updated_date": "2024-11-02 05:27:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T20:32:15.514905"
    },
    {
      "arxiv_id": "2411.01142v1",
      "title": "NEO: Saving GPU Memory Crisis with CPU Offloading for Online LLM Inference",
      "title_zh": "翻译失败",
      "authors": [
        "Xuanlin Jiang",
        "Yang Zhou",
        "Shiyi Cao",
        "Ion Stoica",
        "Minlan Yu"
      ],
      "abstract": "Online LLM inference powers many exciting applications such as intelligent\nchatbots and autonomous agents. Modern LLM inference engines widely rely on\nrequest batching to improve inference throughput, aiming to make it\ncost-efficient when running on expensive GPU accelerators. However, the limited\nGPU memory has largely limited the batch size achieved in practice, leaving\nsignificant GPU compute resources wasted.\n  We present NEO, an online LLM inference system that offloads part of\nattention compute and KV cache states from the GPU to the local host CPU,\neffectively increasing the GPU batch size and thus inference throughput. To\nthis end, NEO proposes asymmetric GPU-CPU pipelining and load-aware scheduling\nto balance GPU and CPU loads and fully utilize their compute and memory\nresources. We evaluate NEO on a wide range of workloads (i.e., code generation,\ntext summarization), GPUs (i.e., T4, A10G, H100), and LLM models (i.e., 7B, 8B,\n70B). NEO achieves up to 7.5$\\times$, 26%, and 14% higher throughput compared\nto GPU-only approach on T4, A10G, and H100 GPUs, respectively, while\nmaintaining the same latency; with more powerful CPUs, NEO achieves up to 79.3%\nthroughput gain on A10G GPU.",
      "tldr_zh": "该研究提出NEO系统，通过将部分注意力计算和KV cache从GPU转移到CPU，实现在线LLM推理的内存优化，从而增加批处理大小并提升吞吐量。NEO采用不对称GPU-CPU流水线(asymmetric GPU-CPU pipelining)和负载感知调度(load-aware scheduling)，以平衡设备负载并充分利用计算资源。在各种工作负载（如代码生成和文本摘要）、GPU（如T4、A10G、H100）和LLM模型（如7B、8B、70B）上，NEO相比GPU-only方法实现了最高7.5倍的吞吐量提升，同时保持相同延迟，使用更强大CPU时可达79.3%的额外增益。",
      "categories": [
        "cs.DC",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.DC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.01142v1",
      "published_date": "2024-11-02 05:15:44 UTC",
      "updated_date": "2024-11-02 05:15:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T20:32:26.911278"
    },
    {
      "arxiv_id": "2411.01140v3",
      "title": "Privacy-Preserving Federated Learning with Differentially Private Hyperdimensional Computing",
      "title_zh": "基于差异隐私高维计算的隐私保护联邦学习",
      "authors": [
        "Fardin Jalil Piran",
        "Zhiling Chen",
        "Mohsen Imani",
        "Farhad Imani"
      ],
      "abstract": "Federated Learning (FL) has become a key method for preserving data privacy\nin Internet of Things (IoT) environments, as it trains Machine Learning (ML)\nmodels locally while transmitting only model updates. Despite this design, FL\nremains susceptible to threats such as model inversion and membership inference\nattacks, which can reveal private training data. Differential Privacy (DP)\ntechniques are often introduced to mitigate these risks, but simply injecting\nDP noise into black-box ML models can compromise accuracy, particularly in\ndynamic IoT contexts, where continuous, lifelong learning leads to excessive\nnoise accumulation. To address this challenge, we propose Federated\nHyperDimensional computing with Privacy-preserving (FedHDPrivacy), an\neXplainable Artificial Intelligence (XAI) framework that integrates\nneuro-symbolic computing and DP. Unlike conventional approaches, FedHDPrivacy\nactively monitors the cumulative noise across learning rounds and adds only the\nadditional noise required to satisfy privacy constraints. In a real-world\napplication for monitoring manufacturing machining processes, FedHDPrivacy\nmaintains high performance while surpassing standard FL frameworks - Federated\nAveraging (FedAvg), Federated Proximal (FedProx), Federated Normalized\nAveraging (FedNova), and Federated Optimization (FedOpt) - by up to 37%.\nLooking ahead, FedHDPrivacy offers a promising avenue for further enhancements,\nsuch as incorporating multimodal data fusion.",
      "tldr_zh": "该研究针对联邦学习（Federated Learning, FL）在物联网（IoT）环境中面临的隐私风险，如模型反转和成员推理攻击，提出了一种结合差分隐私（Differential Privacy, DP）和超维计算（Hyperdimensional Computing）的框架FedHDPrivacy。不同于传统方法，该框架通过监控累计噪声并仅添加必要噪声来维持隐私约束，同时整合神经符号计算（neuro-symbolic computing）和可解释人工智能（XAI），从而减少准确性损失。在制造业加工监控的实际应用中，FedHDPrivacy比FedAvg、FedProx等基准框架性能提升高达37%。未来，该框架有望通过整合多模态数据融合进一步优化。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "31 Pages, 14 Figures",
      "pdf_url": "http://arxiv.org/pdf/2411.01140v3",
      "published_date": "2024-11-02 05:00:44 UTC",
      "updated_date": "2025-03-22 04:10:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T20:32:39.503625"
    },
    {
      "arxiv_id": "2411.01137v2",
      "title": "Data movement limits to frontier model training",
      "title_zh": "翻译失败",
      "authors": [
        "Ege Erdil",
        "David Schneider-Joseph"
      ],
      "abstract": "We present a theoretical model of distributed training, and use it to analyze\nhow far dense and sparse training runs can be scaled. Under our baseline\nassumptions, given a three month training duration, data movement bottlenecks\nbegin to significantly lower hardware utilization for training runs exceeding\nabout $10^{28}$ FLOP, two orders of magnitude above the largest training run to\ndate, suggesting the arrival of fundamental barriers to scaling in three years\ngiven recent rates of growth. A training run exceeding about $10^{31}$ FLOP is\ninfeasible even at low utilization. However, more aggressive batch size scaling\nand/or shorter and fatter model shapes, if achievable, have the potential to\npermit much larger training runs.",
      "tldr_zh": "本研究提出一个理论模型，用于分析分布式训练的规模限制，特别是针对密集(dense)和稀疏(sparse)训练。模型显示，在三个月的训练期限下，当训练规模超过约10^28 FLOP时，数据移动瓶颈会显著降低硬件 utilization，导致硬件利用率下降两个数量级以上，并预示未来三年内可能出现根本性障碍。超过约10^31 FLOP的训练即使在低utilization下也难以实现，但通过更激进的batch size scaling和/或更短更宽的model shapes优化，可能实现更大规模的训练运行。",
      "categories": [
        "cs.DC",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.DC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.01137v2",
      "published_date": "2024-11-02 04:48:41 UTC",
      "updated_date": "2024-11-13 08:24:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T20:32:51.336926"
    },
    {
      "arxiv_id": "2411.01114v1",
      "title": "Infant Agent: A Tool-Integrated, Logic-Driven Agent with Cost-Effective API Usage",
      "title_zh": "Infant Agent：一种工具集成的、逻辑驱动的代理，具有成本有效的 API 使用",
      "authors": [
        "Bin Lei",
        "Yuchen Li",
        "Yiming Zeng",
        "Tao Ren",
        "Yi Luo",
        "Tianyu Shi",
        "Zitian Gao",
        "Zeyu Hu",
        "Weitai Kang",
        "Qiuwu Chen"
      ],
      "abstract": "Despite the impressive capabilities of large language models (LLMs), they\ncurrently exhibit two primary limitations,\n\\textbf{\\uppercase\\expandafter{\\romannumeral 1}}: They struggle to\n\\textbf{autonomously solve the real world engineering problem}.\n\\textbf{\\uppercase\\expandafter{\\romannumeral 2}}: They remain\n\\textbf{challenged in reasoning through complex logic problems}. To address\nthese challenges, we developed the \\textsc{Infant Agent}, integrating\ntask-aware functions, operators, a hierarchical management system, and a memory\nretrieval mechanism. Together, these components enable large language models to\nsustain extended reasoning processes and handle complex, multi-step tasks\nefficiently, all while significantly reducing API costs. Using the\n\\textsc{Infant Agent}, GPT-4o's accuracy on the SWE-bench-lite dataset rises\nfrom $\\mathbf{0.33\\%}$ to $\\mathbf{30\\%}$, and in the AIME-2024 mathematics\ncompetition, it increases GPT-4o's accuracy from $\\mathbf{13.3\\%}$ to\n$\\mathbf{37\\%}$.",
      "tldr_zh": "该研究针对大型语言模型(LLMs)的两大局限性——无法自主解决真实工程问题和处理复杂逻辑挑战——开发了 Infant Agent，这是一种集成了任务感知函数、操作符、层次化管理系统和记忆检索机制的工具驱动代理系统。Infant Agent 能够支持 LLMs 进行高效的持续推理和多步任务处理，同时显著降低 API 使用成本。实验结果显示，在 SWE-bench-lite 数据集上，GPT-4o 的准确率从 0.33% 提高到 30%，而在 AIME-2024 数学竞赛中，从 13.3% 提升至 37%。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.01114v1",
      "published_date": "2024-11-02 02:48:37 UTC",
      "updated_date": "2024-11-02 02:48:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T20:33:04.874132"
    },
    {
      "arxiv_id": "2411.01111v1",
      "title": "Rule Based Rewards for Language Model Safety",
      "title_zh": "翻译失败",
      "authors": [
        "Tong Mu",
        "Alec Helyar",
        "Johannes Heidecke",
        "Joshua Achiam",
        "Andrea Vallone",
        "Ian Kivlichan",
        "Molly Lin",
        "Alex Beutel",
        "John Schulman",
        "Lilian Weng"
      ],
      "abstract": "Reinforcement learning based fine-tuning of large language models (LLMs) on\nhuman preferences has been shown to enhance both their capabilities and safety\nbehavior. However, in cases related to safety, without precise instructions to\nhuman annotators, the data collected may cause the model to become overly\ncautious, or to respond in an undesirable style, such as being judgmental.\nAdditionally, as model capabilities and usage patterns evolve, there may be a\ncostly need to add or relabel data to modify safety behavior. We propose a\nnovel preference modeling approach that utilizes AI feedback and only requires\na small amount of human data. Our method, Rule Based Rewards (RBR), uses a\ncollection of rules for desired or undesired behaviors (e.g. refusals should\nnot be judgmental) along with a LLM grader. In contrast to prior methods using\nAI feedback, our method uses fine-grained, composable, LLM-graded few-shot\nprompts as reward directly in RL training, resulting in greater control,\naccuracy and ease of updating. We show that RBRs are an effective training\nmethod, achieving an F1 score of 97.1, compared to a human-feedback baseline of\n91.7, resulting in much higher safety-behavior accuracy through better\nbalancing usefulness and safety.",
      "tldr_zh": "该研究针对强化学习（Reinforcement Learning）在大型语言模型（LLMs）上的微调问题，指出人类反馈数据可能导致模型过度谨慎或回应风格不当（如判断性）。作者提出了一种新方法Rule Based Rewards (RBR)，利用少量人类数据结合AI反馈和规则集（如拒绝回应不应带有判断性），通过细粒度的LLM评分作为直接奖励进行RL训练，从而实现更精确、可更新和可组合的安全行为控制。实验结果显示，RBR的F1分数达到97.1，比人类反馈基线91.7高出显著幅度，提升了模型的安全性与有用性的平衡。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted at Neurips 2024",
      "pdf_url": "http://arxiv.org/pdf/2411.01111v1",
      "published_date": "2024-11-02 02:22:21 UTC",
      "updated_date": "2024-11-02 02:22:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T20:33:16.706941"
    },
    {
      "arxiv_id": "2411.01098v1",
      "title": "Artificial Intelligence for Microbiology and Microbiome Research",
      "title_zh": "人工智能用于微生物学和微生物组研究",
      "authors": [
        "Xu-Wen Wang",
        "Tong Wang",
        "Yang-Yu Liu"
      ],
      "abstract": "Advancements in artificial intelligence (AI) have transformed many scientific\nfields, with microbiology and microbiome research now experiencing significant\nbreakthroughs through machine learning and deep learning applications. This\nreview provides a comprehensive overview of AI-driven approaches tailored for\nmicrobiology and microbiome studies, emphasizing both technical advancements\nand biological insights. We begin with an introduction to foundational AI\ntechniques, including primary machine learning paradigms and various deep\nlearning architectures, and offer guidance on choosing between machine learning\nand deep learning methods based on specific research goals. The primary section\non application scenarios spans diverse research areas, from taxonomic\nprofiling, functional annotation & prediction, microbe-X interactions,\nmicrobial ecology, metabolic modeling, precision nutrition, clinical\nmicrobiology, to prevention & therapeutics. Finally, we discuss challenges\nunique to this field, including the balance between interpretability and\ncomplexity, the \"small n, large p\" problem, and the critical need for\nstandardized benchmarking datasets to validate and compare models. Together,\nthis review underscores AI's transformative role in microbiology and microbiome\nresearch, paving the way for innovative methodologies and applications that\nenhance our understanding of microbial life and its impact on our planet and\nour health.",
      "tldr_zh": "这篇综述探讨了 Artificial Intelligence (AI) 在微生物学和微生物组研究中的应用，强调机器学习和深度学习技术如何推动领域突破。论文介绍了基础 AI 方法，包括各种机器学习范式和深度学习架构，并提供指导以根据研究目标选择合适方法，同时涵盖从 taxonomic profiling 到 clinical microbiology 等多样应用场景。最终，它讨论了独特挑战，如“small n, large p”问题和标准化 benchmarking datasets 的需求，突显 AI 在增强微生物理解和健康影响方面的变革潜力。",
      "categories": [
        "q-bio.QM",
        "cs.AI",
        "cs.LG",
        "stat.ML"
      ],
      "primary_category": "q-bio.QM",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.01098v1",
      "published_date": "2024-11-02 01:03:43 UTC",
      "updated_date": "2024-11-02 01:03:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T20:33:27.674338"
    },
    {
      "arxiv_id": "2411.01086v3",
      "title": "Practical hybrid PQC-QKD protocols with enhanced security and performance",
      "title_zh": "实用的混合 PQC-QKD 协议，具有增强的安全性和性能",
      "authors": [
        "Pei Zeng",
        "Debayan Bandyopadhyay",
        "José A. Méndez Méndez",
        "Nolan Bitner",
        "Alexander Kolar",
        "Michael T. Solomon",
        "Ziyu Ye",
        "Filip Rozpędek",
        "Tian Zhong",
        "F. Joseph Heremans",
        "David D. Awschalom",
        "Liang Jiang",
        "Junyu Liu"
      ],
      "abstract": "Quantum resistance is vital for emerging cryptographic systems as quantum\ntechnologies continue to advance towards large-scale, fault-tolerant quantum\ncomputers. Resistance may be offered by quantum key distribution (QKD), which\nprovides information-theoretic security using quantum states of photons, but\nmay be limited by transmission loss at long distances. An alternative approach\nuses classical means and is conjectured to be resistant to quantum attacks,\nso-called post-quantum cryptography (PQC), but it is yet to be rigorously\nproven, and its current implementations are computationally expensive. To\novercome the security and performance challenges present in each, here we\ndevelop hybrid protocols by which QKD and PQC inter-operate within a joint\nquantum-classical network. In particular, we consider different hybrid designs\nthat may offer enhanced speed and/or security over the individual performance\nof either approach. Furthermore, we present a method for analyzing the security\nof hybrid protocols in key distribution networks. Our hybrid approach paves the\nway for joint quantum-classical communication networks, which leverage the\nadvantages of both QKD and PQC and can be tailored to the requirements of\nvarious practical networks.",
      "tldr_zh": "该研究探讨了量子密钥分发(QKD)和后量子密码学(PQC)的混合协议，以应对量子计算机对加密系统的潜在威胁。论文提出多种实用混合设计，使QKD和PQC在联合量子-经典网络中互操作，从而提升密钥分发的速度和安全性，并提供了一种分析混合协议安全性的方法。实验结果表明，这种混合方法比单一QKD或PQC更具优势，可根据实际网络需求进行定制，为未来通信网络铺平道路。",
      "categories": [
        "quant-ph",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "quant-ph",
      "comment": "6 pages, 3 figures, including extra supplementary materials",
      "pdf_url": "http://arxiv.org/pdf/2411.01086v3",
      "published_date": "2024-11-02 00:02:01 UTC",
      "updated_date": "2024-11-07 22:01:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T20:33:38.747932"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 54,
  "processed_papers_count": 54,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-20T20:33:59.137441"
}