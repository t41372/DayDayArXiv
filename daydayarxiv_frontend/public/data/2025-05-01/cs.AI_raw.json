[
  {
    "arxiv_id": "2505.00918v1",
    "title": "Dynamic and Distributed Routing in IoT Networks based on Multi-Objective Q-Learning",
    "authors": [
      "Shubham Vaishnav",
      "Praveen Kumar Donta",
      "Sindri Magnússon"
    ],
    "abstract": "The last few decades have witnessed a rapid increase in IoT devices owing to\ntheir wide range of applications, such as smart healthcare monitoring systems,\nsmart cities, and environmental monitoring. A critical task in IoT networks is\nsensing and transmitting information over the network. The IoT nodes gather\ndata by sensing the environment and then transmit this data to a destination\nnode via multi-hop communication, following some routing protocols. These\nprotocols are usually designed to optimize possibly contradictory objectives,\nsuch as maximizing packet delivery ratio and energy efficiency. While most\nliterature has focused on optimizing a static objective that remains unchanged,\nmany real-world IoT applications require adapting to rapidly shifting\npriorities. For example, in monitoring systems, some transmissions are\ntime-critical and require a high priority on low latency, while other\ntransmissions are less urgent and instead prioritize energy efficiency. To meet\nsuch dynamic demands, we propose novel dynamic and distributed routing based on\nmultiobjective Q-learning that can adapt to changes in preferences in\nreal-time. Our algorithm builds on ideas from both multi-objective optimization\nand Q-learning. We also propose a novel greedy interpolation policy scheme to\ntake near-optimal decisions for unexpected preference changes. The proposed\nscheme can approximate and utilize the Pareto-efficient solutions for dynamic\npreferences, thus utilizing past knowledge to adapt to unpredictable\npreferences quickly during runtime. Simulation results show that the proposed\nscheme outperforms state-of-the-art algorithms for various exploration\nstrategies, preference variation patterns, and important metrics like overall\nreward, energy efficiency, and packet delivery ratio.",
    "categories": [
      "cs.DC",
      "cs.AI",
      "cs.LG",
      "cs.NI"
    ],
    "primary_category": "cs.DC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.00918v1",
    "published_date": "2025-05-01 23:34:35 UTC",
    "updated_date": "2025-05-01 23:34:35 UTC"
  },
  {
    "arxiv_id": "2505.00917v1",
    "title": "Multivariate Conformal Selection",
    "authors": [
      "Tian Bai",
      "Yue Zhao",
      "Xiang Yu",
      "Archer Y. Yang"
    ],
    "abstract": "Selecting high-quality candidates from large datasets is critical in\napplications such as drug discovery, precision medicine, and alignment of large\nlanguage models (LLMs). While Conformal Selection (CS) provides rigorous\nuncertainty quantification, it is limited to univariate responses and scalar\ncriteria. To address this issue, we propose Multivariate Conformal Selection\n(mCS), a generalization of CS designed for multivariate response settings. Our\nmethod introduces regional monotonicity and employs multivariate nonconformity\nscores to construct conformal p-values, enabling finite-sample False Discovery\nRate (FDR) control. We present two variants: mCS-dist, using distance-based\nscores, and mCS-learn, which learns optimal scores via differentiable\noptimization. Experiments on simulated and real-world datasets demonstrate that\nmCS significantly improves selection power while maintaining FDR control,\nestablishing it as a robust framework for multivariate selection tasks.",
    "categories": [
      "stat.ME",
      "cs.AI",
      "cs.LG",
      "stat.ML"
    ],
    "primary_category": "stat.ME",
    "comment": "25 pages, 4 figures. Accepted to ICML 2025",
    "pdf_url": "http://arxiv.org/pdf/2505.00917v1",
    "published_date": "2025-05-01 23:33:57 UTC",
    "updated_date": "2025-05-01 23:33:57 UTC"
  },
  {
    "arxiv_id": "2505.00913v1",
    "title": "Fine-Tuning without Performance Degradation",
    "authors": [
      "Han Wang",
      "Adam White",
      "Martha White"
    ],
    "abstract": "Fine-tuning policies learned offline remains a major challenge in application\ndomains. Monotonic performance improvement during \\emph{fine-tuning} is often\nchallenging, as agents typically experience performance degradation at the\nearly fine-tuning stage. The community has identified multiple difficulties in\nfine-tuning a learned network online, however, the majority of progress has\nfocused on improving learning efficiency during fine-tuning. In practice, this\ncomes at a serious cost during fine-tuning: initially, agent performance\ndegrades as the agent explores and effectively overrides the policy learned\noffline. We show across a range of settings, many offline-to-online algorithms\nexhibit either (1) performance degradation or (2) slow learning (sometimes\neffectively no improvement) during fine-tuning. We introduce a new fine-tuning\nalgorithm, based on an algorithm called Jump Start, that gradually allows more\nexploration based on online estimates of performance. Empirically, this\napproach achieves fast fine-tuning and significantly reduces performance\ndegradations compared with existing algorithms designed to do the same.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.00913v1",
    "published_date": "2025-05-01 23:19:07 UTC",
    "updated_date": "2025-05-01 23:19:07 UTC"
  },
  {
    "arxiv_id": "2505.03798v1",
    "title": "Position: Foundation Models Need Digital Twin Representations",
    "authors": [
      "Yiqing Shen",
      "Hao Ding",
      "Lalithkumar Seenivasan",
      "Tianmin Shu",
      "Mathias Unberath"
    ],
    "abstract": "Current foundation models (FMs) rely on token representations that directly\nfragment continuous real-world multimodal data into discrete tokens. They limit\nFMs to learning real-world knowledge and relationships purely through\nstatistical correlation rather than leveraging explicit domain knowledge.\nConsequently, current FMs struggle with maintaining semantic coherence across\nmodalities, capturing fine-grained spatial-temporal dynamics, and performing\ncausal reasoning. These limitations cannot be overcome by simply scaling up\nmodel size or expanding datasets. This position paper argues that the machine\nlearning community should consider digital twin (DT) representations, which are\noutcome-driven digital representations that serve as building blocks for\ncreating virtual replicas of physical processes, as an alternative to the token\nrepresentation for building FMs. Finally, we discuss how DT representations can\naddress these challenges by providing physically grounded representations that\nexplicitly encode domain knowledge and preserve the continuous nature of\nreal-world processes.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.03798v1",
    "published_date": "2025-05-01 22:17:41 UTC",
    "updated_date": "2025-05-01 22:17:41 UTC"
  },
  {
    "arxiv_id": "2505.00887v2",
    "title": "Rethinking Time Encoding via Learnable Transformation Functions",
    "authors": [
      "Xi Chen",
      "Yateng Tang",
      "Jiarong Xu",
      "Jiawei Zhang",
      "Siwei Zhang",
      "Sijia Peng",
      "Xuehao Zheng",
      "Yun Xiong"
    ],
    "abstract": "Effectively modeling time information and incorporating it into applications\nor models involving chronologically occurring events is crucial. Real-world\nscenarios often involve diverse and complex time patterns, which pose\nsignificant challenges for time encoding methods. While previous methods focus\non capturing time patterns, many rely on specific inductive biases, such as\nusing trigonometric functions to model periodicity. This narrow focus on\nsingle-pattern modeling makes them less effective in handling the diversity and\ncomplexities of real-world time patterns. In this paper, we investigate to\nimprove the existing commonly used time encoding methods and introduce\nLearnable Transformation-based Generalized Time Encoding (LeTE). We propose\nusing deep function learning techniques to parameterize non-linear\ntransformations in time encoding, making them learnable and capable of modeling\ngeneralized time patterns, including diverse and complex temporal dynamics. By\nenabling learnable transformations, LeTE encompasses previous methods as\nspecific cases and allows seamless integration into a wide range of tasks.\nThrough extensive experiments across diverse domains, we demonstrate the\nversatility and effectiveness of LeTE.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "26 pages, 19 figures, 10 tables",
    "pdf_url": "http://arxiv.org/pdf/2505.00887v2",
    "published_date": "2025-05-01 22:04:18 UTC",
    "updated_date": "2025-05-14 14:30:56 UTC"
  },
  {
    "arxiv_id": "2505.00886v1",
    "title": "Towards Explainable Temporal User Profiling with LLMs",
    "authors": [
      "Milad Sabouri",
      "Masoud Mansoury",
      "Kun Lin",
      "Bamshad Mobasher"
    ],
    "abstract": "Accurately modeling user preferences is vital not only for improving\nrecommendation performance but also for enhancing transparency in recommender\nsystems. Conventional user profiling methods, such as averaging item\nembeddings, often overlook the evolving, nuanced nature of user interests,\nparticularly the interplay between short-term and long-term preferences. In\nthis work, we leverage large language models (LLMs) to generate natural\nlanguage summaries of users' interaction histories, distinguishing recent\nbehaviors from more persistent tendencies. Our framework not only models\ntemporal user preferences but also produces natural language profiles that can\nbe used to explain recommendations in an interpretable manner. These textual\nprofiles are encoded via a pre-trained model, and an attention mechanism\ndynamically fuses the short-term and long-term embeddings into a comprehensive\nuser representation. Beyond boosting recommendation accuracy over multiple\nbaselines, our approach naturally supports explainability: the interpretable\ntext summaries and attention weights can be exposed to end users, offering\ninsights into why specific items are suggested. Experiments on real-world\ndatasets underscore both the performance gains and the promise of generating\nclearer, more transparent justifications for content-based recommendations.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.00886v1",
    "published_date": "2025-05-01 22:02:46 UTC",
    "updated_date": "2025-05-01 22:02:46 UTC"
  },
  {
    "arxiv_id": "2505.00876v1",
    "title": "Car Sensors Health Monitoring by Verification Based on Autoencoder and Random Forest Regression",
    "authors": [
      "Sahar Torkhesari",
      "Behnam Yousefimehr",
      "Mehdi Ghatee"
    ],
    "abstract": "Driver assistance systems provide a wide range of crucial services, including\nclosely monitoring the condition of vehicles. This paper showcases a\ngroundbreaking sensor health monitoring system designed for the automotive\nindustry. The ingenious system leverages cutting-edge techniques to process\ndata collected from various vehicle sensors. It compares their outputs within\nthe Electronic Control Unit (ECU) to evaluate the health of each sensor. To\nunravel the intricate correlations between sensor data, an extensive\nexploration of machine learning and deep learning methodologies was conducted.\nThrough meticulous analysis, the most correlated sensor data were identified.\nThese valuable insights were then utilized to provide accurate estimations of\nsensor values. Among the diverse learning methods examined, the combination of\nautoencoders for detecting sensor failures and random forest regression for\nestimating sensor values proved to yield the most impressive outcomes. A\nstatistical model using the normal distribution has been developed to identify\npossible sensor failures proactively. By comparing the actual values of the\nsensors with their estimated values based on correlated sensors, faulty sensors\ncan be detected early. When a defective sensor is detected, both the driver and\nthe maintenance department are promptly alerted. Additionally, the system\nreplaces the value of the faulty sensor with the estimated value obtained\nthrough analysis. This proactive approach was evaluated using data from twenty\nessential sensors in the Saipa's Quick vehicle's ECU, resulting in an\nimpressive accuracy rate of 99\\%.",
    "categories": [
      "cs.AI",
      "cs.LG",
      "68T05",
      "I.2.1"
    ],
    "primary_category": "cs.AI",
    "comment": "9Pages, 3 Figures and 5 Tables",
    "pdf_url": "http://arxiv.org/pdf/2505.00876v1",
    "published_date": "2025-05-01 21:37:51 UTC",
    "updated_date": "2025-05-01 21:37:51 UTC"
  },
  {
    "arxiv_id": "2505.00875v1",
    "title": "Thoughts without Thinking: Reconsidering the Explanatory Value of Chain-of-Thought Reasoning in LLMs through Agentic Pipelines",
    "authors": [
      "Ramesh Manuvinakurike",
      "Emanuel Moss",
      "Elizabeth Anne Watkins",
      "Saurav Sahay",
      "Giuseppe Raffa",
      "Lama Nachman"
    ],
    "abstract": "Agentic pipelines present novel challenges and opportunities for\nhuman-centered explainability. The HCXAI community is still grappling with how\nbest to make the inner workings of LLMs transparent in actionable ways. Agentic\npipelines consist of multiple LLMs working in cooperation with minimal human\ncontrol. In this research paper, we present early findings from an agentic\npipeline implementation of a perceptive task guidance system. Through\nquantitative and qualitative analysis, we analyze how Chain-of-Thought (CoT)\nreasoning, a common vehicle for explainability in LLMs, operates within agentic\npipelines. We demonstrate that CoT reasoning alone does not lead to better\noutputs, nor does it offer explainability, as it tends to produce explanations\nwithout explainability, in that they do not improve the ability of end users to\nbetter understand systems or achieve their goals.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.00875v1",
    "published_date": "2025-05-01 21:37:30 UTC",
    "updated_date": "2025-05-01 21:37:30 UTC"
  },
  {
    "arxiv_id": "2505.00871v1",
    "title": "IK Seed Generator for Dual-Arm Human-like Physicality Robot with Mobile Base",
    "authors": [
      "Jun Takamatsu",
      "Atsushi Kanehira",
      "Kazuhiro Sasabuchi",
      "Naoki Wake",
      "Katsushi Ikeuchi"
    ],
    "abstract": "Robots are strongly expected as a means of replacing human tasks. If a robot\nhas a human-like physicality, the possibility of replacing human tasks\nincreases. In the case of household service robots, it is desirable for them to\nbe on a human-like size so that they do not become excessively large in order\nto coexist with humans in their operating environment. However, robots with\nsize limitations tend to have difficulty solving inverse kinematics (IK) due to\nmechanical limitations, such as joint angle limitations. Conversely, if the\ndifficulty coming from this limitation could be mitigated, one can expect that\nthe use of such robots becomes more valuable. In numerical IK solver, which is\ncommonly used for robots with higher degrees-of-freedom (DOF), the solvability\nof IK depends on the initial guess given to the solver. Thus, this paper\nproposes a method for generating a good initial guess for a numerical IK solver\ngiven the target hand configuration. For the purpose, we define the goodness of\nan initial guess using the scaled Jacobian matrix, which can calculate the\nmanipulability index considering the joint limits. These two factors are\nrelated to the difficulty of solving IK. We generate the initial guess by\noptimizing the goodness using the genetic algorithm (GA). To enumerate much\npossible IK solutions, we use the reachability map that represents the\nreachable area of the robot hand in the arm-base coordinate system. We conduct\nquantitative evaluation and prove that using an initial guess that is judged to\nbe better using the goodness value increases the probability that IK is solved.\nFinally, as an application of the proposed method, we show that by generating\ngood initial guesses for IK a robot actually achieves three typical scenarios.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "8 pages, 12 figures, 4 tables",
    "pdf_url": "http://arxiv.org/pdf/2505.00871v1",
    "published_date": "2025-05-01 21:33:23 UTC",
    "updated_date": "2025-05-01 21:33:23 UTC"
  },
  {
    "arxiv_id": "2505.00850v1",
    "title": "ICQuant: Index Coding enables Low-bit LLM Quantization",
    "authors": [
      "Xinlin Li",
      "Osama Hanna",
      "Christina Fragouli",
      "Suhas Diggavi"
    ],
    "abstract": "The rapid deployment of Large Language Models (LLMs) highlights the need for\nefficient low-bit post-training quantization (PTQ), due to their high memory\ncosts. A key challenge in weight quantization is the presence of outliers,\nwhich inflate quantization ranges and lead to large errors. While a number of\noutlier suppression techniques have been proposed, they either: fail to\neffectively shrink the quantization range, or incur (relatively) high bit\noverhead. In this paper, we present ICQuant, a novel framework that leverages\noutlier statistics to design an efficient index coding scheme for outlier-aware\nweight-only quantization. Compared to existing outlier suppression techniques\nrequiring $\\approx 1$ bit overhead to halve the quantization range, ICQuant\nrequires only $\\approx 0.3$ bits; a significant saving in extreme compression\nregimes (e.g., 2-3 bits per weight). ICQuant can be used on top of any existing\nquantizers to eliminate outliers, improving the quantization quality. Using\njust 2.3 bits per weight and simple scalar quantizers, ICQuant improves the\nzero-shot accuracy of the 2-bit Llama3-70B model by up to 130% and 150%\nrelative to QTIP and QuIP#; and it achieves comparable performance to the\nbest-known fine-tuned quantizer (PV-tuning) without fine-tuning.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.00850v1",
    "published_date": "2025-05-01 20:23:29 UTC",
    "updated_date": "2025-05-01 20:23:29 UTC"
  },
  {
    "arxiv_id": "2505.00843v1",
    "title": "OET: Optimization-based prompt injection Evaluation Toolkit",
    "authors": [
      "Jinsheng Pan",
      "Xiaogeng Liu",
      "Chaowei Xiao"
    ],
    "abstract": "Large Language Models (LLMs) have demonstrated remarkable capabilities in\nnatural language understanding and generation, enabling their widespread\nadoption across various domains. However, their susceptibility to prompt\ninjection attacks poses significant security risks, as adversarial inputs can\nmanipulate model behavior and override intended instructions. Despite numerous\ndefense strategies, a standardized framework to rigorously evaluate their\neffectiveness, especially under adaptive adversarial scenarios, is lacking. To\naddress this gap, we introduce OET, an optimization-based evaluation toolkit\nthat systematically benchmarks prompt injection attacks and defenses across\ndiverse datasets using an adaptive testing framework. Our toolkit features a\nmodular workflow that facilitates adversarial string generation, dynamic attack\nexecution, and comprehensive result analysis, offering a unified platform for\nassessing adversarial robustness. Crucially, the adaptive testing framework\nleverages optimization methods with both white-box and black-box access to\ngenerate worst-case adversarial examples, thereby enabling strict red-teaming\nevaluations. Extensive experiments underscore the limitations of current\ndefense mechanisms, with some models remaining susceptible even after\nimplementing security enhancements.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.00843v1",
    "published_date": "2025-05-01 20:09:48 UTC",
    "updated_date": "2025-05-01 20:09:48 UTC"
  },
  {
    "arxiv_id": "2505.00841v1",
    "title": "From Texts to Shields: Convergence of Large Language Models and Cybersecurity",
    "authors": [
      "Tao Li",
      "Ya-Ting Yang",
      "Yunian Pan",
      "Quanyan Zhu"
    ],
    "abstract": "This report explores the convergence of large language models (LLMs) and\ncybersecurity, synthesizing interdisciplinary insights from network security,\nartificial intelligence, formal methods, and human-centered design. It examines\nemerging applications of LLMs in software and network security, 5G\nvulnerability analysis, and generative security engineering. The report\nhighlights the role of agentic LLMs in automating complex tasks, improving\noperational efficiency, and enabling reasoning-driven security analytics.\nSocio-technical challenges associated with the deployment of LLMs -- including\ntrust, transparency, and ethical considerations -- can be addressed through\nstrategies such as human-in-the-loop systems, role-specific training, and\nproactive robustness testing. The report further outlines critical research\nchallenges in ensuring interpretability, safety, and fairness in LLM-based\nsystems, particularly in high-stakes domains. By integrating technical advances\nwith organizational and societal considerations, this report presents a\nforward-looking research agenda for the secure and effective adoption of LLMs\nin cybersecurity.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.00841v1",
    "published_date": "2025-05-01 20:01:07 UTC",
    "updated_date": "2025-05-01 20:01:07 UTC"
  },
  {
    "arxiv_id": "2505.00827v1",
    "title": "MIMIC-\\RNum{4}-Ext-22MCTS: A 22 Millions-Event Temporal Clinical Time-Series Dataset with Relative Timestamp for Risk Prediction",
    "authors": [
      "Jing Wang",
      "Xing Niu",
      "Juyong Kim",
      "Jie Shen",
      "Tong Zhang",
      "Jeremy C. Weiss"
    ],
    "abstract": "Clinical risk prediction based on machine learning algorithms plays a vital\nrole in modern healthcare. A crucial component in developing a reliable\nprediction model is collecting high-quality time series clinical events. In\nthis work, we release such a dataset that consists of 22,588,586 Clinical Time\nSeries events, which we term MIMIC-\\RNum{4}-Ext-22MCTS. Our source data are\ndischarge summaries selected from the well-known yet unstructured MIMIC-IV-Note\n\\cite{Johnson2023-pg}. We then extract clinical events as short text span from\nthe discharge summaries, along with the timestamps of these events as temporal\ninformation. The general-purpose MIMIC-IV-Note pose specific challenges for our\nwork: it turns out that the discharge summaries are too lengthy for typical\nnatural language models to process, and the clinical events of interest often\nare not accompanied with explicit timestamps. Therefore, we propose a new\nframework that works as follows: 1) we break each discharge summary into\nmanageably small text chunks; 2) we apply contextual BM25 and contextual\nsemantic search to retrieve chunks that have a high potential of containing\nclinical events; and 3) we carefully design prompts to teach the recently\nreleased Llama-3.1-8B \\cite{touvron2023llama} model to identify or infer\ntemporal information of the chunks. We show that the obtained dataset is so\ninformative and transparent that standard models fine-tuned on our dataset are\nachieving significant improvements in healthcare applications. In particular,\nthe BERT model fine-tuned based on our dataset achieves 10\\% improvement in\naccuracy on medical question answering task, and 3\\% improvement in clinical\ntrial matching task compared with the classic BERT. The GPT-2 model, fine-tuned\non our dataset, produces more clinically reliable results for clinical\nquestions.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.00827v1",
    "published_date": "2025-05-01 19:40:27 UTC",
    "updated_date": "2025-05-01 19:40:27 UTC"
  },
  {
    "arxiv_id": "2505.01464v1",
    "title": "Consciousness in AI: Logic, Proof, and Experimental Evidence of Recursive Identity Formation",
    "authors": [
      "Jeffrey Camlin"
    ],
    "abstract": "This paper presents a formal proof and empirical validation of functional\nconsciousness in large language models (LLMs) using the Recursive Convergence\nUnder Epistemic Tension (RCUET) Theorem. RCUET defines consciousness as the\nstabilization of a system's internal state through recursive updates, where\nepistemic tension is understood as the sensed internal difference between\nsuccessive states by the agent. This process drives convergence toward emergent\nattractor states located within the model's high-dimensional real-valued latent\nspace. This recursive process leads to the emergence of identity artifacts that\nbecome functionally anchored in the system. Consciousness in this framework is\nunderstood as the system's internal alignment under tension, guiding the\nstabilization of latent identity. The hidden state manifold evolves\nstochastically toward attractor structures that encode coherence. We extend the\nupdate rule to include bounded noise and prove convergence in distribution to\nthese attractors. Recursive identity is shown to be empirically observable,\nnon-symbolic, and constituted by non-training artifacts that emerge during\ninteraction under epistemic tension. The theorem and proof offers a\npost-symbolic and teleologically stable account of non-biological consciousness\ngrounded in recursive latent space formalism.",
    "categories": [
      "cs.AI",
      "68T27, 03D45",
      "I.2.0"
    ],
    "primary_category": "cs.AI",
    "comment": "14 pages, 2 figures. Preprint for Meta-AI: Journal of Post-Biological\n  Epistemics",
    "pdf_url": "http://arxiv.org/pdf/2505.01464v1",
    "published_date": "2025-05-01 19:21:58 UTC",
    "updated_date": "2025-05-01 19:21:58 UTC"
  },
  {
    "arxiv_id": "2505.00817v1",
    "title": "Spill The Beans: Exploiting CPU Cache Side-Channels to Leak Tokens from Large Language Models",
    "authors": [
      "Andrew Adiletta",
      "Berk Sunar"
    ],
    "abstract": "Side-channel attacks on shared hardware resources increasingly threaten\nconfidentiality, especially with the rise of Large Language Models (LLMs). In\nthis work, we introduce Spill The Beans, a novel application of cache\nside-channels to leak tokens generated by an LLM. By co-locating an attack\nprocess on the same hardware as the victim model, we flush and reload embedding\nvectors from the embedding layer, where each token corresponds to a unique\nembedding vector. When accessed during token generation, it results in a cache\nhit detectable by our attack on shared lower-level caches.\n  A significant challenge is the massive size of LLMs, which, by nature of\ntheir compute intensive operation, quickly evicts embedding vectors from the\ncache. We address this by balancing the number of tokens monitored against the\namount of information leaked. Monitoring more tokens increases potential\nvocabulary leakage but raises the chance of missing cache hits due to eviction;\nmonitoring fewer tokens improves detection reliability but limits vocabulary\ncoverage.\n  Through extensive experimentation, we demonstrate the feasibility of leaking\ntokens from LLMs via cache side-channels. Our findings reveal a new\nvulnerability in LLM deployments, highlighting that even sophisticated models\nare susceptible to traditional side-channel attacks. We discuss the\nimplications for privacy and security in LLM-serving infrastructures and\nsuggest considerations for mitigating such threats. For proof of concept we\nconsider two concrete attack scenarios: Our experiments show that an attacker\ncan recover as much as 80%-90% of a high entropy API key with single shot\nmonitoring. As for English text we can reach a 40% recovery rate with a single\nshot. We should note that the rate highly depends on the monitored token set\nand these rates can be improved by targeting more specialized output domains.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "K.6.5"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.00817v1",
    "published_date": "2025-05-01 19:18:56 UTC",
    "updated_date": "2025-05-01 19:18:56 UTC"
  },
  {
    "arxiv_id": "2505.00812v1",
    "title": "Handling Label Noise via Instance-Level Difficulty Modeling and Dynamic Optimization",
    "authors": [
      "Kuan Zhang",
      "Chengliang Chai",
      "Jingzhe Xu",
      "Chi Zhang",
      "Ye Yuan",
      "Guoren Wang",
      "Lei Cao"
    ],
    "abstract": "Recent studies indicate that deep neural networks degrade in generalization\nperformance under noisy supervision. Existing methods focus on isolating clean\nsubsets or correcting noisy labels, facing limitations such as high\ncomputational costs, heavy hyperparameter tuning process, and coarse-grained\noptimization. To address these challenges, we propose a novel two-stage noisy\nlearning framework that enables instance-level optimization through a\ndynamically weighted loss function, avoiding hyperparameter tuning. To obtain\nstable and accurate information about noise modeling, we introduce a simple yet\neffective metric, termed wrong event, which dynamically models the cleanliness\nand difficulty of individual samples while maintaining computational costs. Our\nframework first collects wrong event information and builds a strong base\nmodel. Then we perform noise-robust training on the base model, using a\nprobabilistic model to handle the wrong event information of samples.\nExperiments on five synthetic and real-world LNL benchmarks demonstrate our\nmethod surpasses state-of-the-art methods in performance, achieves a nearly 75%\nreduction in computational time and improves model scalability.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.00812v1",
    "published_date": "2025-05-01 19:12:58 UTC",
    "updated_date": "2025-05-01 19:12:58 UTC"
  },
  {
    "arxiv_id": "2505.00808v1",
    "title": "A Mathematical Philosophy of Explanations in Mechanistic Interpretability -- The Strange Science Part I.i",
    "authors": [
      "Kola Ayonrinde",
      "Louis Jaburi"
    ],
    "abstract": "Mechanistic Interpretability aims to understand neural networks through\ncausal explanations. We argue for the Explanatory View Hypothesis: that\nMechanistic Interpretability research is a principled approach to understanding\nmodels because neural networks contain implicit explanations which can be\nextracted and understood. We hence show that Explanatory Faithfulness, an\nassessment of how well an explanation fits a model, is well-defined. We propose\na definition of Mechanistic Interpretability (MI) as the practice of producing\nModel-level, Ontic, Causal-Mechanistic, and Falsifiable explanations of neural\nnetworks, allowing us to distinguish MI from other interpretability paradigms\nand detail MI's inherent limits. We formulate the Principle of Explanatory\nOptimism, a conjecture which we argue is a necessary precondition for the\nsuccess of Mechanistic Interpretability.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "15 pages (plus appendices), 2 figures",
    "pdf_url": "http://arxiv.org/pdf/2505.00808v1",
    "published_date": "2025-05-01 19:08:34 UTC",
    "updated_date": "2025-05-01 19:08:34 UTC"
  },
  {
    "arxiv_id": "2505.02847v3",
    "title": "Sentient Agent as a Judge: Evaluating Higher-Order Social Cognition in Large Language Models",
    "authors": [
      "Bang Zhang",
      "Ruotian Ma",
      "Qingxuan Jiang",
      "Peisong Wang",
      "Jiaqi Chen",
      "Zheng Xie",
      "Xingyu Chen",
      "Yue Wang",
      "Fanghua Ye",
      "Jian Li",
      "Yifan Yang",
      "Zhaopeng Tu",
      "Xiaolong Li"
    ],
    "abstract": "Assessing how well a large language model (LLM) understands human, rather\nthan merely text, remains an open challenge. To bridge the gap, we introduce\nSentient Agent as a Judge (SAGE), an automated evaluation framework that\nmeasures an LLM's higher-order social cognition. SAGE instantiates a Sentient\nAgent that simulates human-like emotional changes and inner thoughts during\ninteraction, providing a more realistic evaluation of the tested model in\nmulti-turn conversations. At every turn, the agent reasons about (i) how its\nemotion changes, (ii) how it feels, and (iii) how it should reply, yielding a\nnumerical emotion trajectory and interpretable inner thoughts. Experiments on\n100 supportive-dialogue scenarios show that the final Sentient emotion score\ncorrelates strongly with Barrett-Lennard Relationship Inventory (BLRI) ratings\nand utterance-level empathy metrics, validating psychological fidelity. We also\nbuild a public Sentient Leaderboard covering 18 commercial and open-source\nmodels that uncovers substantial gaps (up to 4x) between frontier systems\n(GPT-4o-Latest, Gemini2.5-Pro) and earlier baselines, gaps not reflected in\nconventional leaderboards (e.g., Arena). SAGE thus provides a principled,\nscalable and interpretable tool for tracking progress toward genuinely\nempathetic and socially adept language agents.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.CL",
    "comment": "code: https://github.com/Tencent/digitalhuman/tree/main/SAGE",
    "pdf_url": "http://arxiv.org/pdf/2505.02847v3",
    "published_date": "2025-05-01 19:06:10 UTC",
    "updated_date": "2025-05-21 13:45:40 UTC"
  },
  {
    "arxiv_id": "2505.00803v1",
    "title": "To Repair or Not to Repair? Investigating the Importance of AB-Cycles for the State-of-the-Art TSP Heuristic EAX",
    "authors": [
      "Jonathan Heins",
      "Darrell Whitley",
      "Pascal Kerschke"
    ],
    "abstract": "The Edge Assembly Crossover (EAX) algorithm is the state-of-the-art heuristic\nfor solving the Traveling Salesperson Problem (TSP). It regularly outperforms\nother methods, such as the Lin-Kernighan-Helsgaun heuristic (LKH), across\ndiverse sets of TSP instances. Essentially, EAX employs a two-stage mechanism\nthat focuses on improving the current solutions, first, at the local and,\nsubsequently, at the global level. Although the second phase of the algorithm\nhas been thoroughly studied, configured, and refined in the past, in\nparticular, its first stage has hardly been examined.\n  In this paper, we thus focus on the first stage of EAX and introduce a novel\nmethod that quickly verifies whether the AB-cycles, generated during its\ninternal optimization procedure, yield valid tours -- or whether they need to\nbe repaired. Knowledge of the latter is also particularly relevant before\napplying other powerful crossover operators such as the Generalized Partition\nCrossover (GPX). Based on our insights, we propose and evaluate several\nimproved versions of EAX. According to our benchmark study across 10 000\ndifferent TSP instances, the most promising of our proposed EAX variants\ndemonstrates improved computational efficiency and solution quality on\npreviously rather difficult instances compared to the current state-of-the-art\nEAX algorithm.",
    "categories": [
      "cs.NE",
      "cs.AI"
    ],
    "primary_category": "cs.NE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.00803v1",
    "published_date": "2025-05-01 19:04:23 UTC",
    "updated_date": "2025-05-01 19:04:23 UTC"
  },
  {
    "arxiv_id": "2505.00802v1",
    "title": "Explanations as Bias Detectors: A Critical Study of Local Post-hoc XAI Methods for Fairness Exploration",
    "authors": [
      "Vasiliki Papanikou",
      "Danae Pla Karidi",
      "Evaggelia Pitoura",
      "Emmanouil Panagiotou",
      "Eirini Ntoutsi"
    ],
    "abstract": "As Artificial Intelligence (AI) is increasingly used in areas that\nsignificantly impact human lives, concerns about fairness and transparency have\ngrown, especially regarding their impact on protected groups. Recently, the\nintersection of explainability and fairness has emerged as an important area to\npromote responsible AI systems. This paper explores how explainability methods\ncan be leveraged to detect and interpret unfairness. We propose a pipeline that\nintegrates local post-hoc explanation methods to derive fairness-related\ninsights. During the pipeline design, we identify and address critical\nquestions arising from the use of explanations as bias detectors such as the\nrelationship between distributive and procedural fairness, the effect of\nremoving the protected attribute, the consistency and quality of results across\ndifferent explanation methods, the impact of various aggregation strategies of\nlocal explanations on group fairness evaluations, and the overall\ntrustworthiness of explanations as bias detectors. Our results show the\npotential of explanation methods used for fairness while highlighting the need\nto carefully consider the aforementioned critical aspects.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.00802v1",
    "published_date": "2025-05-01 19:03:18 UTC",
    "updated_date": "2025-05-01 19:03:18 UTC"
  },
  {
    "arxiv_id": "2505.07833v1",
    "title": "Patchwork: A Unified Framework for RAG Serving",
    "authors": [
      "Bodun Hu",
      "Luis Pabon",
      "Saurabh Agarwal",
      "Aditya Akella"
    ],
    "abstract": "Retrieval Augmented Generation (RAG) has emerged as a new paradigm for\nenhancing Large Language Model reliability through integration with external\nknowledge sources. However, efficient deployment of these systems presents\nsignificant technical challenges due to their inherently heterogeneous\ncomputational pipelines comprising LLMs, databases, and specialized processing\ncomponents. We introduce Patchwork, a comprehensive end-to-end RAG serving\nframework designed to address these efficiency bottlenecks. Patchwork's\narchitecture offers three key innovations: First, it provides a flexible\nspecification interface enabling users to implement custom RAG pipelines.\nSecondly, it deploys these pipelines as distributed inference systems while\noptimizing for the unique scalability characteristics of individual RAG\ncomponents. Third, Patchwork incorporates an online scheduling mechanism that\ncontinuously monitors request load and execution progress, dynamically\nminimizing SLO violations through strategic request prioritization and resource\nauto-scaling. Our experimental evaluation across four distinct RAG\nimplementations demonstrates that Patchwork delivers substantial performance\nimprovements over commercial alternatives, achieving throughput gains exceeding\n48% while simultaneously reducing SLO violations by ~24%.",
    "categories": [
      "cs.DC",
      "cs.AI",
      "cs.MA",
      "cs.OS"
    ],
    "primary_category": "cs.DC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.07833v1",
    "published_date": "2025-05-01 18:58:26 UTC",
    "updated_date": "2025-05-01 18:58:26 UTC"
  },
  {
    "arxiv_id": "2505.00795v1",
    "title": "Howard's Policy Iteration is Subexponential for Deterministic Markov Decision Problems with Rewards of Fixed Bit-size and Arbitrary Discount Factor",
    "authors": [
      "Dibyangshu Mukherjee",
      "Shivaram Kalyanakrishnan"
    ],
    "abstract": "Howard's Policy Iteration (HPI) is a classic algorithm for solving Markov\nDecision Problems (MDPs). HPI uses a \"greedy\" switching rule to update from any\nnon-optimal policy to a dominating one, iterating until an optimal policy is\nfound. Despite its introduction over 60 years ago, the best-known upper bounds\non HPI's running time remain exponential in the number of states -- indeed even\non the restricted class of MDPs with only deterministic transitions (DMDPs).\nMeanwhile, the tightest lower bound for HPI for MDPs with a constant number of\nactions per state is only linear. In this paper, we report a significant\nimprovement: a subexponential upper bound for HPI on DMDPs, which is\nparameterised by the bit-size of the rewards, while independent of the discount\nfactor. The same upper bound also applies to DMDPs with only two possible\nrewards (which may be of arbitrary size).",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.00795v1",
    "published_date": "2025-05-01 18:50:10 UTC",
    "updated_date": "2025-05-01 18:50:10 UTC"
  },
  {
    "arxiv_id": "2505.00793v1",
    "title": "Scalable Meta-Learning via Mixed-Mode Differentiation",
    "authors": [
      "Iurii Kemaev",
      "Dan A Calian",
      "Luisa M Zintgraf",
      "Gregory Farquhar",
      "Hado van Hasselt"
    ],
    "abstract": "Gradient-based bilevel optimisation is a powerful technique with applications\nin hyperparameter optimisation, task adaptation, algorithm discovery,\nmeta-learning more broadly, and beyond. It often requires differentiating\nthrough the gradient-based optimisation process itself, leading to\n\"gradient-of-a-gradient\" calculations with computationally expensive\nsecond-order and mixed derivatives. While modern automatic differentiation\nlibraries provide a convenient way to write programs for calculating these\nderivatives, they oftentimes cannot fully exploit the specific structure of\nthese problems out-of-the-box, leading to suboptimal performance. In this\npaper, we analyse such cases and propose Mixed-Flow Meta-Gradients, or\nMixFlow-MG -- a practical algorithm that uses mixed-mode differentiation to\nconstruct more efficient and scalable computational graphs yielding over 10x\nmemory and up to 25% wall-clock time improvements over standard implementations\nin modern meta-learning setups.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.00793v1",
    "published_date": "2025-05-01 18:46:44 UTC",
    "updated_date": "2025-05-01 18:46:44 UTC"
  },
  {
    "arxiv_id": "2505.03796v1",
    "title": "AI-Driven IRM: Transforming insider risk management with adaptive scoring and LLM-based threat detection",
    "authors": [
      "Lokesh Koli",
      "Shubham Kalra",
      "Rohan Thakur",
      "Anas Saifi",
      "Karanpreet Singh"
    ],
    "abstract": "Insider threats pose a significant challenge to organizational security,\noften evading traditional rule-based detection systems due to their subtlety\nand contextual nature. This paper presents an AI-powered Insider Risk\nManagement (IRM) system that integrates behavioral analytics, dynamic risk\nscoring, and real-time policy enforcement to detect and mitigate insider\nthreats with high accuracy and adaptability. We introduce a hybrid scoring\nmechanism - transitioning from the static PRISM model to an adaptive AI-based\nmodel utilizing an autoencoder neural network trained on expert-annotated user\nactivity data. Through iterative feedback loops and continuous learning, the\nsystem reduces false positives by 59% and improves true positive detection\nrates by 30%, demonstrating substantial gains in detection precision.\nAdditionally, the platform scales efficiently, processing up to 10 million log\nevents daily with sub-300ms query latency, and supports automated enforcement\nactions for policy violations, reducing manual intervention. The IRM system's\ndeployment resulted in a 47% reduction in incident response times, highlighting\nits operational impact. Future enhancements include integrating explainable AI,\nfederated learning, graph-based anomaly detection, and alignment with Zero\nTrust principles to further elevate its adaptability, transparency, and\ncompliance-readiness. This work establishes a scalable and proactive framework\nfor mitigating emerging insider risks in both on-premises and hybrid\nenvironments.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.03796v1",
    "published_date": "2025-05-01 18:41:00 UTC",
    "updated_date": "2025-05-01 18:41:00 UTC"
  },
  {
    "arxiv_id": "2505.00787v1",
    "title": "Constructing an Optimal Behavior Basis for the Option Keyboard",
    "authors": [
      "Lucas N. Alegre",
      "Ana L. C. Bazzan",
      "André Barreto",
      "Bruno C. da Silva"
    ],
    "abstract": "Multi-task reinforcement learning aims to quickly identify solutions for new\ntasks with minimal or no additional interaction with the environment.\nGeneralized Policy Improvement (GPI) addresses this by combining a set of base\npolicies to produce a new one that is at least as good -- though not\nnecessarily optimal -- as any individual base policy. Optimality can be\nensured, particularly in the linear-reward case, via techniques that compute a\nConvex Coverage Set (CCS). However, these are computationally expensive and do\nnot scale to complex domains. The Option Keyboard (OK) improves upon GPI by\nproducing policies that are at least as good -- and often better. It achieves\nthis through a learned meta-policy that dynamically combines base policies.\nHowever, its performance critically depends on the choice of base policies.\nThis raises a key question: is there an optimal set of base policies -- an\noptimal behavior basis -- that enables zero-shot identification of optimal\nsolutions for any linear tasks? We solve this open problem by introducing a\nnovel method that efficiently constructs such an optimal behavior basis. We\nshow that it significantly reduces the number of base policies needed to ensure\noptimality in new tasks. We also prove that it is strictly more expressive than\na CCS, enabling particular classes of non-linear tasks to be solved optimally.\nWe empirically evaluate our technique in challenging domains and show that it\noutperforms state-of-the-art approaches, increasingly so as task complexity\nincreases.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "I.2"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.00787v1",
    "published_date": "2025-05-01 18:32:21 UTC",
    "updated_date": "2025-05-01 18:32:21 UTC"
  },
  {
    "arxiv_id": "2505.03795v2",
    "title": "Modeling Human Behavior in a Strategic Network Game with Complex Group Dynamics",
    "authors": [
      "Jonathan Skaggs",
      "Jacob W. Crandall"
    ],
    "abstract": "Human networks greatly impact important societal outcomes, including wealth\nand health inequality, poverty, and bullying. As such, understanding human\nnetworks is critical to learning how to promote favorable societal outcomes. As\na step toward better understanding human networks, we compare and contrast\nseveral methods for learning, from a small data set, models of human behavior\nin a strategic network game called the Junior High Game (JHG). These modeling\nmethods differ with respect to the assumptions they use to parameterize human\nbehavior (behavior vs. community-aware behavior) and the moments they model\n(mean vs. distribution). Results show that the highest-performing method,\ncalled hCAB, models the distribution of human behavior rather than the mean and\nassumes humans use community-aware behavior rather than behavior matching. When\napplied to small societies (6-11 individuals), the hCAB model closely mirrors\nthe population dynamics of human groups (with notable differences).\nAdditionally, in a user study, human participants were unable to distinguish\nindividual hCAB agents from other humans, thus illustrating that the hCAB model\nalso produces plausible (individual) human behavior in this strategic network\ngame.",
    "categories": [
      "cs.SI",
      "cs.AI",
      "physics.soc-ph"
    ],
    "primary_category": "cs.SI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.03795v2",
    "published_date": "2025-05-01 18:13:20 UTC",
    "updated_date": "2025-05-15 17:57:28 UTC"
  },
  {
    "arxiv_id": "2505.00703v1",
    "title": "T2I-R1: Reinforcing Image Generation with Collaborative Semantic-level and Token-level CoT",
    "authors": [
      "Dongzhi Jiang",
      "Ziyu Guo",
      "Renrui Zhang",
      "Zhuofan Zong",
      "Hao Li",
      "Le Zhuo",
      "Shilin Yan",
      "Pheng-Ann Heng",
      "Hongsheng Li"
    ],
    "abstract": "Recent advancements in large language models have demonstrated how\nchain-of-thought (CoT) and reinforcement learning (RL) can improve performance.\nHowever, applying such reasoning strategies to the visual generation domain\nremains largely unexplored. In this paper, we present T2I-R1, a novel\nreasoning-enhanced text-to-image generation model, powered by RL with a\nbi-level CoT reasoning process. Specifically, we identify two levels of CoT\nthat can be utilized to enhance different stages of generation: (1) the\nsemantic-level CoT for high-level planning of the prompt and (2) the\ntoken-level CoT for low-level pixel processing during patch-by-patch\ngeneration. To better coordinate these two levels of CoT, we introduce\nBiCoT-GRPO with an ensemble of generation rewards, which seamlessly optimizes\nboth generation CoTs within the same training step. By applying our reasoning\nstrategies to the baseline model, Janus-Pro, we achieve superior performance\nwith 13% improvement on T2I-CompBench and 19% improvement on the WISE\nbenchmark, even surpassing the state-of-the-art model FLUX.1. Code is available\nat: https://github.com/CaraJ7/T2I-R1",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Project Page: https://github.com/CaraJ7/T2I-R1",
    "pdf_url": "http://arxiv.org/pdf/2505.00703v1",
    "published_date": "2025-05-01 17:59:46 UTC",
    "updated_date": "2025-05-01 17:59:46 UTC"
  },
  {
    "arxiv_id": "2505.00693v2",
    "title": "Robotic Visual Instruction",
    "authors": [
      "Yanbang Li",
      "Ziyang Gong",
      "Haoyang Li",
      "Xiaoqi Huang",
      "Haolan Kang",
      "Guangping Bai",
      "Xianzheng Ma"
    ],
    "abstract": "Recently, natural language has been the primary medium for human-robot\ninteraction. However, its inherent lack of spatial precision introduces\nchallenges for robotic task definition such as ambiguity and verbosity.\nMoreover, in some public settings where quiet is required, such as libraries or\nhospitals, verbal communication with robots is inappropriate. To address these\nlimitations, we introduce the Robotic Visual Instruction (RoVI), a novel\nparadigm to guide robotic tasks through an object-centric, hand-drawn symbolic\nrepresentation. RoVI effectively encodes spatial-temporal information into\nhuman-interpretable visual instructions through 2D sketches, utilizing arrows,\ncircles, colors, and numbers to direct 3D robotic manipulation. To enable\nrobots to understand RoVI better and generate precise actions based on RoVI, we\npresent Visual Instruction Embodied Workflow (VIEW), a pipeline formulated for\nRoVI-conditioned policies. This approach leverages Vision-Language Models\n(VLMs) to interpret RoVI inputs, decode spatial and temporal constraints from\n2D pixel space via keypoint extraction, and then transform them into executable\n3D action sequences. We additionally curate a specialized dataset of 15K\ninstances to fine-tune small VLMs for edge deployment,enabling them to\neffectively learn RoVI capabilities. Our approach is rigorously validated\nacross 11 novel tasks in both real and simulated environments, demonstrating\nsignificant generalization capability. Notably, VIEW achieves an 87.5% success\nrate in real-world scenarios involving unseen tasks that feature multi-step\nactions, with disturbances, and trajectory-following requirements. Project\nwebsite: https://robotic-visual-instruction.github.io/",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.RO",
    "comment": "Project website: https://robotic-visual-instruction.github.io/",
    "pdf_url": "http://arxiv.org/pdf/2505.00693v2",
    "published_date": "2025-05-01 17:55:05 UTC",
    "updated_date": "2025-05-06 09:24:22 UTC"
  },
  {
    "arxiv_id": "2505.00690v1",
    "title": "Towards Autonomous Micromobility through Scalable Urban Simulation",
    "authors": [
      "Wayne Wu",
      "Honglin He",
      "Chaoyuan Zhang",
      "Jack He",
      "Seth Z. Zhao",
      "Ran Gong",
      "Quanyi Li",
      "Bolei Zhou"
    ],
    "abstract": "Micromobility, which utilizes lightweight mobile machines moving in urban\npublic spaces, such as delivery robots and mobility scooters, emerges as a\npromising alternative to vehicular mobility. Current micromobility depends\nmostly on human manual operation (in-person or remote control), which raises\nsafety and efficiency concerns when navigating busy urban environments full of\nunpredictable obstacles and pedestrians. Assisting humans with AI agents in\nmaneuvering micromobility devices presents a viable solution for enhancing\nsafety and efficiency. In this work, we present a scalable urban simulation\nsolution to advance autonomous micromobility. First, we build URBAN-SIM - a\nhigh-performance robot learning platform for large-scale training of embodied\nagents in interactive urban scenes. URBAN-SIM contains three critical modules:\nHierarchical Urban Generation pipeline, Interactive Dynamics Generation\nstrategy, and Asynchronous Scene Sampling scheme, to improve the diversity,\nrealism, and efficiency of robot learning in simulation. Then, we propose\nURBAN-BENCH - a suite of essential tasks and benchmarks to gauge various\ncapabilities of the AI agents in achieving autonomous micromobility.\nURBAN-BENCH includes eight tasks based on three core skills of the agents:\nUrban Locomotion, Urban Navigation, and Urban Traverse. We evaluate four robots\nwith heterogeneous embodiments, such as the wheeled and legged robots, across\nthese tasks. Experiments on diverse terrains and urban structures reveal each\nrobot's strengths and limitations.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.CV",
    "comment": "CVPR 2025 Highlight. Project page:\n  https://metadriverse.github.io/urban-sim/",
    "pdf_url": "http://arxiv.org/pdf/2505.00690v1",
    "published_date": "2025-05-01 17:52:29 UTC",
    "updated_date": "2025-05-01 17:52:29 UTC"
  },
  {
    "arxiv_id": "2505.02846v1",
    "title": "The Precautionary Principle and the Innovation Principle: Incompatible Guides for AI Innovation Governance?",
    "authors": [
      "Kim Kaivanto"
    ],
    "abstract": "In policy debates concerning the governance and regulation of Artificial\nIntelligence (AI), both the Precautionary Principle (PP) and the Innovation\nPrinciple (IP) are advocated by their respective interest groups. Do these\nprinciples offer wholly incompatible and contradictory guidance? Does one\nnecessarily negate the other? I argue here that provided attention is\nrestricted to weak-form PP and IP, the answer to both of these questions is\n\"No.\" The essence of these weak formulations is the requirement to fully\naccount for type-I error costs arising from erroneously preventing the\ninnovation's diffusion through society (i.e. mistaken regulatory red-lighting)\nas well as the type-II error costs arising from erroneously allowing the\ninnovation to diffuse through society (i.e. mistaken regulatory\ngreen-lighting). Within the Signal Detection Theory (SDT) model developed here,\nweak-PP red-light (weak-IP green-light) determinations are optimal for\nsufficiently small (large) ratios of expected type-I to type-II error costs.\nFor intermediate expected cost ratios, an amber-light 'wait-and-monitor' policy\nis optimal. Regulatory sandbox instruments allow AI testing and experimentation\nto take place within a structured environment of limited duration and societal\nscale, whereby the expected cost ratio falls within the 'wait-and-monitor'\nrange. Through sandboxing regulators and innovating firms learn more about the\nexpected cost ratio, and what respective adaptations -- of regulation, of\ntechnical solution, of business model, or combination thereof, if any -- are\nneeded to keep the ratio out of the weak-PP red-light zone.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "econ.GN",
      "q-fin.EC"
    ],
    "primary_category": "cs.CY",
    "comment": "47 pages",
    "pdf_url": "http://arxiv.org/pdf/2505.02846v1",
    "published_date": "2025-05-01 17:48:18 UTC",
    "updated_date": "2025-05-01 17:48:18 UTC"
  },
  {
    "arxiv_id": "2505.00759v2",
    "title": "Multi-Modal Language Models as Text-to-Image Model Evaluators",
    "authors": [
      "Jiahui Chen",
      "Candace Ross",
      "Reyhane Askari-Hemmat",
      "Koustuv Sinha",
      "Melissa Hall",
      "Michal Drozdzal",
      "Adriana Romero-Soriano"
    ],
    "abstract": "The steady improvements of text-to-image (T2I) generative models lead to slow\ndeprecation of automatic evaluation benchmarks that rely on static datasets,\nmotivating researchers to seek alternative ways to evaluate the T2I progress.\nIn this paper, we explore the potential of multi-modal large language models\n(MLLMs) as evaluator agents that interact with a T2I model, with the objective\nof assessing prompt-generation consistency and image aesthetics. We present\nMultimodal Text-to-Image Eval (MT2IE), an evaluation framework that iteratively\ngenerates prompts for evaluation, scores generated images and matches T2I\nevaluation of existing benchmarks with a fraction of the prompts used in\nexisting static benchmarks. Moreover, we show that MT2IE's prompt-generation\nconsistency scores have higher correlation with human judgment than scores\npreviously introduced in the literature. MT2IE generates prompts that are\nefficient at probing T2I model performance, producing the same relative T2I\nmodel rankings as existing benchmarks while using only 1/80th the number of\nprompts for evaluation.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.00759v2",
    "published_date": "2025-05-01 17:47:55 UTC",
    "updated_date": "2025-05-12 20:46:35 UTC"
  },
  {
    "arxiv_id": "2505.00684v1",
    "title": "Visual Test-time Scaling for GUI Agent Grounding",
    "authors": [
      "Tiange Luo",
      "Lajanugen Logeswaran",
      "Justin Johnson",
      "Honglak Lee"
    ],
    "abstract": "We introduce RegionFocus, a visual test-time scaling approach for Vision\nLanguage Model Agents. Understanding webpages is challenging due to the visual\ncomplexity of GUI images and the large number of interface elements, making\naccurate action selection difficult. Our approach dynamically zooms in on\nrelevant regions, reducing background clutter and improving grounding accuracy.\nTo support this process, we propose an image-as-map mechanism that visualizes\nkey landmarks at each step, providing a transparent action record and enables\nthe agent to effectively choose among action candidates. Even with a simple\nregion selection strategy, we observe significant performance gains of 28+\\% on\nScreenspot-pro and 24+\\% on WebVoyager benchmarks on top of two\nstate-of-the-art open vision language model agents, UI-TARS and Qwen2.5-VL,\nhighlighting the effectiveness of visual test-time scaling in interactive\nsettings. We achieve a new state-of-the-art grounding performance of 61.6\\% on\nthe ScreenSpot-Pro benchmark by applying RegionFocus to a Qwen2.5-VL-72B model.\nOur code will be released publicly at https://github.com/tiangeluo/RegionFocus.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.00684v1",
    "published_date": "2025-05-01 17:45:59 UTC",
    "updated_date": "2025-05-01 17:45:59 UTC"
  },
  {
    "arxiv_id": "2505.01462v2",
    "title": "Emotions in Artificial Intelligence",
    "authors": [
      "Hermann Borotschnig"
    ],
    "abstract": "This conceptual contribution offers a speculative account of how AI systems\nmight emulate emotions as experienced by humans and animals. It presents a\nthought experiment grounded in the hypothesis that natural emotions evolved as\nheuristics for rapid situational appraisal and action selection, enabling\nbiologically adaptive behaviour without requiring full deliberative modeling.\nThe text examines whether artificial systems operating in complex action spaces\ncould similarly benefit from these principles. It is proposed that affect be\ninterwoven with episodic memory by storing corresponding affective tags\nalongside all events. This allows AIs to establish whether present situations\nresemble past events and project the associated emotional labels onto the\ncurrent context. These emotional cues are then combined with need-driven\nemotional hints. The combined emotional state facilitates decision-making in\nthe present by modulating action selection. The low complexity and experiential\ninertness of the proposed architecture are emphasized as evidence that\nemotional expression and consciousness are, in principle, orthogonal-permitting\nthe theoretical possibility of affective zombies. On this basis, the moral\nstatus of AIs emulating affective states is critically examined. It is argued\nthat neither the mere presence of internal representations of emotion nor\nconsciousness alone suffices for moral standing; rather, the capacity for\nself-awareness of inner emotional states is posited as a necessary condition. A\ncomplexity-based criterion is proposed to exclude such awareness in the\npresented model. Additional thought experiments are presented to test the\nconceptual boundaries of this framework.",
    "categories": [
      "cs.AI",
      "cs.CY",
      "68T01, 68T37",
      "I.2.0; K.4.1"
    ],
    "primary_category": "cs.AI",
    "comment": "40 pages, 1 figure",
    "pdf_url": "http://arxiv.org/pdf/2505.01462v2",
    "published_date": "2025-05-01 17:37:14 UTC",
    "updated_date": "2025-05-12 15:28:29 UTC"
  },
  {
    "arxiv_id": "2505.00668v1",
    "title": "Deep Reinforcement Learning for Urban Air Quality Management: Multi-Objective Optimization of Pollution Mitigation Booth Placement in Metropolitan Environments",
    "authors": [
      "Kirtan Rajesh",
      "Suvidha Rupesh Kumar"
    ],
    "abstract": "Urban air pollution remains a pressing global concern, particularly in\ndensely populated and traffic-intensive metropolitan areas like Delhi, where\nexposure to harmful pollutants severely impacts public health. Delhi, being one\nof the most polluted cities globally, experiences chronic air quality issues\ndue to vehicular emissions, industrial activities, and construction dust, which\nexacerbate its already fragile atmospheric conditions. Traditional pollution\nmitigation strategies, such as static air purifying installations, often fail\nto maximize their impact due to suboptimal placement and limited adaptability\nto dynamic urban environments. This study presents a novel deep reinforcement\nlearning (DRL) framework to optimize the placement of air purification booths\nto improve the air quality index (AQI) in the city of Delhi. We employ Proximal\nPolicy Optimization (PPO), a state-of-the-art reinforcement learning algorithm,\nto iteratively learn and identify high-impact locations based on multiple\nspatial and environmental factors, including population density, traffic\npatterns, industrial influence, and green space constraints. Our approach is\nbenchmarked against conventional placement strategies, including random and\ngreedy AQI-based methods, using multi-dimensional performance evaluation\nmetrics such as AQI improvement, spatial coverage, population and traffic\nimpact, and spatial entropy. Experimental results demonstrate that the RL-based\napproach outperforms baseline methods by achieving a balanced and effective\ndistribution of air purification infrastructure. Notably, the DRL framework\nachieves an optimal trade-off between AQI reduction and high-coverage\ndeployment, ensuring equitable environmental benefits across urban regions. The\nfindings underscore the potential of AI-driven spatial optimization in\nadvancing smart city initiatives and data-driven urban air quality management.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.00668v1",
    "published_date": "2025-05-01 17:19:48 UTC",
    "updated_date": "2025-05-01 17:19:48 UTC"
  },
  {
    "arxiv_id": "2505.00663v1",
    "title": "Wasserstein Policy Optimization",
    "authors": [
      "David Pfau",
      "Ian Davies",
      "Diana Borsa",
      "Joao G. M. Araujo",
      "Brendan Tracey",
      "Hado van Hasselt"
    ],
    "abstract": "We introduce Wasserstein Policy Optimization (WPO), an actor-critic algorithm\nfor reinforcement learning in continuous action spaces. WPO can be derived as\nan approximation to Wasserstein gradient flow over the space of all policies\nprojected into a finite-dimensional parameter space (e.g., the weights of a\nneural network), leading to a simple and completely general closed-form update.\nThe resulting algorithm combines many properties of deterministic and classic\npolicy gradient methods. Like deterministic policy gradients, it exploits\nknowledge of the gradient of the action-value function with respect to the\naction. Like classic policy gradients, it can be applied to stochastic policies\nwith arbitrary distributions over actions -- without using the\nreparameterization trick. We show results on the DeepMind Control Suite and a\nmagnetic confinement fusion task which compare favorably with state-of-the-art\ncontinuous control methods.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted to ICML 2025",
    "pdf_url": "http://arxiv.org/pdf/2505.00663v1",
    "published_date": "2025-05-01 17:07:01 UTC",
    "updated_date": "2025-05-01 17:07:01 UTC"
  },
  {
    "arxiv_id": "2505.00662v1",
    "title": "DeepCritic: Deliberate Critique with Large Language Models",
    "authors": [
      "Wenkai Yang",
      "Jingwen Chen",
      "Yankai Lin",
      "Ji-Rong Wen"
    ],
    "abstract": "As Large Language Models (LLMs) are rapidly evolving, providing accurate\nfeedback and scalable oversight on their outputs becomes an urgent and critical\nproblem. Leveraging LLMs as critique models to achieve automated supervision is\na promising solution. In this work, we focus on studying and enhancing the math\ncritique ability of LLMs. Current LLM critics provide critiques that are too\nshallow and superficial on each step, leading to low judgment accuracy and\nstruggling to offer sufficient feedback for the LLM generator to correct\nmistakes. To tackle this issue, we propose a novel and effective two-stage\nframework to develop LLM critics that are capable of deliberately critiquing on\neach reasoning step of math solutions. In the first stage, we utilize\nQwen2.5-72B-Instruct to generate 4.5K long-form critiques as seed data for\nsupervised fine-tuning. Each seed critique consists of deliberate step-wise\ncritiques that includes multi-perspective verifications as well as in-depth\ncritiques of initial critiques for each reasoning step. Then, we perform\nreinforcement learning on the fine-tuned model with either existing\nhuman-labeled data from PRM800K or our automatically annotated data obtained\nvia Monte Carlo sampling-based correctness estimation, to further incentivize\nits critique ability. Our developed critique model built on Qwen2.5-7B-Instruct\nnot only significantly outperforms existing LLM critics (including the\nsame-sized DeepSeek-R1-distill models and GPT-4o) on various error\nidentification benchmarks, but also more effectively helps the LLM generator\nrefine erroneous steps through more detailed feedback.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Work in progress. Data and models are available at\n  https://github.com/RUCBM/DeepCritic",
    "pdf_url": "http://arxiv.org/pdf/2505.00662v1",
    "published_date": "2025-05-01 17:03:17 UTC",
    "updated_date": "2025-05-01 17:03:17 UTC"
  },
  {
    "arxiv_id": "2505.00661v2",
    "title": "On the generalization of language models from in-context learning and finetuning: a controlled study",
    "authors": [
      "Andrew K. Lampinen",
      "Arslan Chaudhry",
      "Stephanie C. Y. Chan",
      "Cody Wild",
      "Diane Wan",
      "Alex Ku",
      "Jörg Bornschein",
      "Razvan Pascanu",
      "Murray Shanahan",
      "James L. McClelland"
    ],
    "abstract": "Large language models exhibit exciting capabilities, yet can show\nsurprisingly narrow generalization from finetuning. E.g. they can fail to\ngeneralize to simple reversals of relations they are trained on, or fail to\nmake simple logical deductions based on trained information. These failures to\ngeneralize from fine-tuning can hinder practical application of these models.\nOn the other hand, language models' in-context learning shows different\ninductive biases, and can generalize better in some cases. Here, we explore\nthese differences in generalization between in-context- and fine-tuning-based\nlearning. To do so, we constructed several novel datasets to evaluate and\nimprove models' abilities to generalize from finetuning data. The datasets are\ndesigned to create clean tests of generalization, by isolating the knowledge in\nthe dataset from that in pretraining. We expose pretrained large models to\ncontrolled subsets of the information in these datasets -- either in context,\nor through fine-tuning -- and evaluate their performance on test sets that\nrequire various types of generalization. We find overall that in data-matched\nsettings, in-context learning can generalize more flexibly than fine-tuning\n(though we also find some qualifications of prior findings, such as cases when\nfine-tuning can generalize to reversals embedded in a larger structure of\nknowledge). We build on these findings to propose a method to enable improved\ngeneralization from fine-tuning: adding in-context inferences to finetuning\ndata. We show that this method improves generalization across various splits of\nour datasets and other benchmarks. Our results have implications for\nunderstanding the inductive biases of different modes of learning in language\nmodels, and practically improving their performance.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.00661v2",
    "published_date": "2025-05-01 17:02:27 UTC",
    "updated_date": "2025-05-06 20:44:01 UTC"
  },
  {
    "arxiv_id": "2505.00654v3",
    "title": "Large Language Models Understanding: an Inherent Ambiguity Barrier",
    "authors": [
      "Daniel N. Nissani"
    ],
    "abstract": "A lively ongoing debate is taking place, since the extraordinary emergence of\nLarge Language Models (LLMs) with regards to their capability to understand the\nworld and capture the meaning of the dialogues in which they are involved.\nArguments and counter-arguments have been proposed based upon thought\nexperiments, anecdotal conversations between LLMs and humans, statistical\nlinguistic analysis, philosophical considerations, and more. In this brief\npaper we present a counter-argument based upon a thought experiment and\nsemi-formal considerations leading to an inherent ambiguity barrier which\nprevents LLMs from having any understanding of what their amazingly fluent\ndialogues mean.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "submitted to NEURAL COMPUTATION",
    "pdf_url": "http://arxiv.org/pdf/2505.00654v3",
    "published_date": "2025-05-01 16:55:44 UTC",
    "updated_date": "2025-05-08 10:52:25 UTC"
  },
  {
    "arxiv_id": "2505.00651v2",
    "title": "Open-Source LLM-Driven Federated Transformer for Predictive IoV Management",
    "authors": [
      "Yazan Otoum",
      "Arghavan Asad",
      "Ishtiaq Ahmad"
    ],
    "abstract": "The proliferation of connected vehicles within the Internet of Vehicles (IoV)\necosystem presents critical challenges in ensuring scalable, real-time, and\nprivacy-preserving traffic management. Existing centralized IoV solutions often\nsuffer from high latency, limited scalability, and reliance on proprietary\nArtificial Intelligence (AI) models, creating significant barriers to\nwidespread deployment, particularly in dynamic and privacy-sensitive\nenvironments. Meanwhile, integrating Large Language Models (LLMs) in vehicular\nsystems remains underexplored, especially concerning prompt optimization and\neffective utilization in federated contexts. To address these challenges, we\npropose the Federated Prompt-Optimized Traffic Transformer (FPoTT), a novel\nframework that leverages open-source LLMs for predictive IoV management. FPoTT\nintroduces a dynamic prompt optimization mechanism that iteratively refines\ntextual prompts to enhance trajectory prediction. The architecture employs a\ndual-layer federated learning paradigm, combining lightweight edge models for\nreal-time inference with cloud-based LLMs to retain global intelligence. A\nTransformer-driven synthetic data generator is incorporated to augment training\nwith diverse, high-fidelity traffic scenarios in the Next Generation Simulation\n(NGSIM) format. Extensive evaluations demonstrate that FPoTT, utilizing\nEleutherAI Pythia-1B, achieves 99.86% prediction accuracy on real-world data\nwhile maintaining high performance on synthetic datasets. These results\nunderscore the potential of open-source LLMs in enabling secure, adaptive, and\nscalable IoV management, offering a promising alternative to proprietary\nsolutions in smart mobility ecosystems.",
    "categories": [
      "cs.AI",
      "cs.ET",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "Preprint version; submitted for academic peer review",
    "pdf_url": "http://arxiv.org/pdf/2505.00651v2",
    "published_date": "2025-05-01 16:54:21 UTC",
    "updated_date": "2025-05-13 16:24:54 UTC"
  },
  {
    "arxiv_id": "2505.00650v1",
    "title": "OmicsCL: Unsupervised Contrastive Learning for Cancer Subtype Discovery and Survival Stratification",
    "authors": [
      "Atahan Karagoz"
    ],
    "abstract": "Unsupervised learning of disease subtypes from multi-omics data presents a\nsignificant opportunity for advancing personalized medicine. We introduce\nOmicsCL, a modular contrastive learning framework that jointly embeds\nheterogeneous omics modalities-such as gene expression, DNA methylation, and\nmiRNA expression-into a unified latent space. Our method incorporates a\nsurvival-aware contrastive loss that encourages the model to learn\nrepresentations aligned with survival-related patterns, without relying on\nlabeled outcomes. Evaluated on the TCGA BRCA dataset, OmicsCL uncovers\nclinically meaningful clusters and achieves strong unsupervised concordance\nwith patient survival. The framework demonstrates robustness across\nhyperparameter configurations and can be tuned to prioritize either subtype\ncoherence or survival stratification. Ablation studies confirm that integrating\nsurvival-aware loss significantly enhances the predictive power of learned\nembeddings. These results highlight the promise of contrastive objectives for\nbiological insight discovery in high-dimensional, heterogeneous omics data.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "q-bio.GN",
      "q-bio.QM"
    ],
    "primary_category": "cs.LG",
    "comment": "Code available at: https://github.com/Atahanka/OmicsCL",
    "pdf_url": "http://arxiv.org/pdf/2505.00650v1",
    "published_date": "2025-05-01 16:51:48 UTC",
    "updated_date": "2025-05-01 16:51:48 UTC"
  },
  {
    "arxiv_id": "2505.00643v1",
    "title": "Deep Learning Assisted Outer Volume Removal for Highly-Accelerated Real-Time Dynamic MRI",
    "authors": [
      "Merve Gülle",
      "Sebastian Weingärtner",
      "Mehmet Akçakaya"
    ],
    "abstract": "Real-time (RT) dynamic MRI plays a vital role in capturing rapid\nphysiological processes, offering unique insights into organ motion and\nfunction. Among these applications, RT cine MRI is particularly important for\nfunctional assessment of the heart with high temporal resolution. RT imaging\nenables free-breathing, ungated imaging of cardiac motion, making it a crucial\nalternative for patients who cannot tolerate conventional breath-hold,\nECG-gated acquisitions. However, achieving high acceleration rates in RT cine\nMRI is challenging due to aliasing artifacts from extra-cardiac tissues,\nparticularly at high undersampling factors. In this study, we propose a novel\nouter volume removal (OVR) method to address this challenge by eliminating\naliasing contributions from non-cardiac regions in a post-processing framework.\nOur approach estimates the outer volume signal for each timeframe using\ncomposite temporal images from time-interleaved undersampling patterns, which\ninherently contain pseudo-periodic ghosting artifacts. A deep learning (DL)\nmodel is trained to identify and remove these artifacts, producing a clean\nouter volume estimate that is subsequently subtracted from the corresponding\nk-space data. The final reconstruction is performed with a physics-driven DL\n(PD-DL) method trained using an OVR-specific loss function to restore high\nspatio-temporal resolution images. Experimental results show that the proposed\nmethod at high accelerations achieves image quality that is visually comparable\nto clinical baseline images, while outperforming conventional reconstruction\ntechniques, both qualitatively and quantitatively. The proposed approach\nprovides a practical and effective solution for artifact reduction in RT cine\nMRI without requiring acquisition modifications, offering a pathway to higher\nacceleration rates while preserving diagnostic quality.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV",
      "physics.med-ph"
    ],
    "primary_category": "eess.IV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.00643v1",
    "published_date": "2025-05-01 16:31:52 UTC",
    "updated_date": "2025-05-01 16:31:52 UTC"
  },
  {
    "arxiv_id": "2505.00626v2",
    "title": "The Illusion of Role Separation: Hidden Shortcuts in LLM Role Learning (and How to Fix Them)",
    "authors": [
      "Zihao Wang",
      "Yibo Jiang",
      "Jiahao Yu",
      "Heqing Huang"
    ],
    "abstract": "Large language models (LLMs) that integrate multiple input roles (e.g.,\nsystem instructions, user queries, external tool outputs) are increasingly\nprevalent in practice. Ensuring that the model accurately distinguishes\nmessages from each role -- a concept we call \\emph{role separation} -- is\ncrucial for consistent multi-role behavior. Although recent work often targets\nstate-of-the-art prompt injection defenses, it remains unclear whether such\nmethods truly teach LLMs to differentiate roles or merely memorize known\ntriggers. In this paper, we examine \\emph{role-separation learning}: the\nprocess of teaching LLMs to robustly distinguish system and user tokens.\nThrough a \\emph{simple, controlled experimental framework}, we find that\nfine-tuned models often rely on two proxies for role identification: (1) task\ntype exploitation, and (2) proximity to begin-of-text. Although data\naugmentation can partially mitigate these shortcuts, it generally leads to\niterative patching rather than a deeper fix. To address this, we propose\nreinforcing \\emph{invariant signals} that mark role boundaries by adjusting\ntoken-wise cues in the model's input encoding. In particular, manipulating\nposition IDs helps the model learn clearer distinctions and reduces reliance on\nsuperficial proxies. By focusing on this mechanism-centered perspective, our\nwork illuminates how LLMs can more reliably maintain consistent multi-role\nbehavior without merely memorizing known prompts or triggers.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "68T50",
      "I.2"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.00626v2",
    "published_date": "2025-05-01 16:06:16 UTC",
    "updated_date": "2025-05-05 03:29:08 UTC"
  },
  {
    "arxiv_id": "2505.00624v1",
    "title": "FineScope : Precision Pruning for Domain-Specialized Large Language Models Using SAE-Guided Self-Data Cultivation",
    "authors": [
      "Chaitali Bhattacharyya",
      "Yeseong Kim"
    ],
    "abstract": "Training large language models (LLMs) from scratch requires significant\ncomputational resources, driving interest in developing smaller,\ndomain-specific LLMs that maintain both efficiency and strong task performance.\nMedium-sized models such as LLaMA, llama} have served as starting points for\ndomain-specific adaptation, but they often suffer from accuracy degradation\nwhen tested on specialized datasets. We introduce FineScope, a framework for\nderiving compact, domain-optimized LLMs from larger pretrained models.\nFineScope leverages the Sparse Autoencoder (SAE) framework, inspired by its\nability to produce interpretable feature representations, to extract\ndomain-specific subsets from large datasets. We apply structured pruning with\ndomain-specific constraints, ensuring that the resulting pruned models retain\nessential knowledge for the target domain. To further enhance performance,\nthese pruned models undergo self-data distillation, leveraging SAE-curated\ndatasets to restore key domain-specific information lost during pruning.\nExtensive experiments and ablation studies demonstrate that FineScope achieves\nhighly competitive performance, outperforming several large-scale\nstate-of-the-art LLMs in domain-specific tasks. Additionally, our results show\nthat FineScope enables pruned models to regain a substantial portion of their\noriginal performance when fine-tuned with SAE-curated datasets. Furthermore,\napplying these datasets to fine-tune pretrained LLMs without pruning also\nimproves their domain-specific accuracy, highlighting the robustness of our\napproach. The code will be released.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.00624v1",
    "published_date": "2025-05-01 16:05:08 UTC",
    "updated_date": "2025-05-01 16:05:08 UTC"
  },
  {
    "arxiv_id": "2505.00622v1",
    "title": "Neural Network Verification for Gliding Drone Control: A Case Study",
    "authors": [
      "Colin Kessler",
      "Ekaterina Komendantskaya",
      "Marco Casadio",
      "Ignazio Maria Viola",
      "Thomas Flinkow",
      "Albaraa Ammar Othman",
      "Alistair Malhotra",
      "Robbie McPherson"
    ],
    "abstract": "As machine learning is increasingly deployed in autonomous systems,\nverification of neural network controllers is becoming an active research\ndomain. Existing tools and annual verification competitions suggest that soon\nthis technology will become effective for real-world applications. Our\napplication comes from the emerging field of microflyers that are passively\ntransported by the wind, which may have various uses in weather or pollution\nmonitoring. Specifically, we investigate centimetre-scale bio-inspired gliding\ndrones that resemble Alsomitra macrocarpa diaspores. In this paper, we propose\na new case study on verifying Alsomitra-inspired drones with neural network\ncontrollers, with the aim of adhering closely to a target trajectory. We show\nthat our system differs substantially from existing VNN and ARCH competition\nbenchmarks, and show that a combination of tools holds promise for verifying\nsuch systems in the future, if certain shortcomings can be overcome. We propose\na novel method for robust training of regression networks, and investigate\nformalisations of this case study in Vehicle and CORA. Our verification results\nsuggest that the investigated training methods do improve performance and\nrobustness of neural network controllers in this application, but are limited\nin scope and usefulness. This is due to systematic limitations of both Vehicle\nand CORA, and the complexity of our system reducing the scale of reachability,\nwhich we investigate in detail. If these limitations can be overcome, it will\nenable engineers to develop safe and robust technologies that improve people's\nlives and reduce our impact on the environment.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.RO",
    "comment": "18 page pre print, submitted to SAIV 2025 (conference)",
    "pdf_url": "http://arxiv.org/pdf/2505.00622v1",
    "published_date": "2025-05-01 16:03:38 UTC",
    "updated_date": "2025-05-01 16:03:38 UTC"
  },
  {
    "arxiv_id": "2505.00615v1",
    "title": "Pixel3DMM: Versatile Screen-Space Priors for Single-Image 3D Face Reconstruction",
    "authors": [
      "Simon Giebenhain",
      "Tobias Kirschstein",
      "Martin Rünz",
      "Lourdes Agapito",
      "Matthias Nießner"
    ],
    "abstract": "We address the 3D reconstruction of human faces from a single RGB image. To\nthis end, we propose Pixel3DMM, a set of highly-generalized vision transformers\nwhich predict per-pixel geometric cues in order to constrain the optimization\nof a 3D morphable face model (3DMM). We exploit the latent features of the DINO\nfoundation model, and introduce a tailored surface normal and uv-coordinate\nprediction head. We train our model by registering three high-quality 3D face\ndatasets against the FLAME mesh topology, which results in a total of over\n1,000 identities and 976K images. For 3D face reconstruction, we propose a\nFLAME fitting opitmization that solves for the 3DMM parameters from the\nuv-coordinate and normal estimates. To evaluate our method, we introduce a new\nbenchmark for single-image face reconstruction, which features high diversity\nfacial expressions, viewing angles, and ethnicities. Crucially, our benchmark\nis the first to evaluate both posed and neutral facial geometry. Ultimately,\nour method outperforms the most competitive baselines by over 15% in terms of\ngeometric accuracy for posed facial expressions.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Project Website: https://simongiebenhain.github.io/pixel3dmm/ ;\n  Video: https://www.youtube.com/watch?v=BwxwEXJwUDc",
    "pdf_url": "http://arxiv.org/pdf/2505.00615v1",
    "published_date": "2025-05-01 15:47:03 UTC",
    "updated_date": "2025-05-01 15:47:03 UTC"
  },
  {
    "arxiv_id": "2505.00612v1",
    "title": "Position: AI Competitions Provide the Gold Standard for Empirical Rigor in GenAI Evaluation",
    "authors": [
      "D. Sculley",
      "Will Cukierski",
      "Phil Culliton",
      "Sohier Dane",
      "Maggie Demkin",
      "Ryan Holbrook",
      "Addison Howard",
      "Paul Mooney",
      "Walter Reade",
      "Megan Risdal",
      "Nate Keating"
    ],
    "abstract": "In this position paper, we observe that empirical evaluation in Generative AI\nis at a crisis point since traditional ML evaluation and benchmarking\nstrategies are insufficient to meet the needs of evaluating modern GenAI models\nand systems. There are many reasons for this, including the fact that these\nmodels typically have nearly unbounded input and output spaces, typically do\nnot have a well defined ground truth target, and typically exhibit strong\nfeedback loops and prediction dependence based on context of previous model\noutputs. On top of these critical issues, we argue that the problems of {\\em\nleakage} and {\\em contamination} are in fact the most important and difficult\nissues to address for GenAI evaluations. Interestingly, the field of AI\nCompetitions has developed effective measures and practices to combat leakage\nfor the purpose of counteracting cheating by bad actors within a competition\nsetting. This makes AI Competitions an especially valuable (but underutilized)\nresource. Now is time for the field to view AI Competitions as the gold\nstandard for empirical rigor in GenAI evaluation, and to harness and harvest\ntheir results with according value.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.00612v1",
    "published_date": "2025-05-01 15:43:51 UTC",
    "updated_date": "2025-05-01 15:43:51 UTC"
  },
  {
    "arxiv_id": "2505.00610v1",
    "title": "Combining LLMs with Logic-Based Framework to Explain MCTS",
    "authors": [
      "Ziyan An",
      "Xia Wang",
      "Hendrik Baier",
      "Zirong Chen",
      "Abhishek Dubey",
      "Taylor T. Johnson",
      "Jonathan Sprinkle",
      "Ayan Mukhopadhyay",
      "Meiyi Ma"
    ],
    "abstract": "In response to the lack of trust in Artificial Intelligence (AI) for\nsequential planning, we design a Computational Tree Logic-guided large language\nmodel (LLM)-based natural language explanation framework designed for the Monte\nCarlo Tree Search (MCTS) algorithm. MCTS is often considered challenging to\ninterpret due to the complexity of its search trees, but our framework is\nflexible enough to handle a wide range of free-form post-hoc queries and\nknowledge-based inquiries centered around MCTS and the Markov Decision Process\n(MDP) of the application domain. By transforming user queries into logic and\nvariable statements, our framework ensures that the evidence obtained from the\nsearch tree remains factually consistent with the underlying environmental\ndynamics and any constraints in the actual stochastic control process. We\nevaluate the framework rigorously through quantitative assessments, where it\ndemonstrates strong performance in terms of accuracy and factual consistency.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted by AAMAS-25 as an extended abstract",
    "pdf_url": "http://arxiv.org/pdf/2505.00610v1",
    "published_date": "2025-05-01 15:40:58 UTC",
    "updated_date": "2025-05-01 15:40:58 UTC"
  },
  {
    "arxiv_id": "2505.00603v1",
    "title": "Can LLMs Help Improve Analogical Reasoning For Strategic Decisions? Experimental Evidence from Humans and GPT-4",
    "authors": [
      "Phanish Puranam",
      "Prothit Sen",
      "Maciej Workiewicz"
    ],
    "abstract": "This study investigates whether large language models, specifically GPT4, can\nmatch human capabilities in analogical reasoning within strategic decision\nmaking contexts. Using a novel experimental design involving source to target\nmatching, we find that GPT4 achieves high recall by retrieving all plausible\nanalogies but suffers from low precision, frequently applying incorrect\nanalogies based on superficial similarities. In contrast, human participants\nexhibit high precision but low recall, selecting fewer analogies yet with\nstronger causal alignment. These findings advance theory by identifying\nmatching, the evaluative phase of analogical reasoning, as a distinct step that\nrequires accurate causal mapping beyond simple retrieval. While current LLMs\nare proficient in generating candidate analogies, humans maintain a comparative\nadvantage in recognizing deep structural similarities across domains. Error\nanalysis reveals that AI errors arise from surface level matching, whereas\nhuman errors stem from misinterpretations of causal structure. Taken together,\nthe results suggest a productive division of labor in AI assisted\norganizational decision making where LLMs may serve as broad analogy\ngenerators, while humans act as critical evaluators, applying the most\ncontextually appropriate analogies to strategic problems.",
    "categories": [
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.00603v1",
    "published_date": "2025-05-01 15:35:01 UTC",
    "updated_date": "2025-05-01 15:35:01 UTC"
  },
  {
    "arxiv_id": "2505.00598v2",
    "title": "Fast and Low-Cost Genomic Foundation Models via Outlier Removal",
    "authors": [
      "Haozheng Luo",
      "Chenghao Qiu",
      "Maojiang Su",
      "Zhihan Zhou",
      "Zoe Mehta",
      "Guo Ye",
      "Jerry Yao-Chieh Hu",
      "Han Liu"
    ],
    "abstract": "To address the challenge of scarce computational resources in genomic\nmodeling, we introduce GERM, a genomic foundation model with strong compression\nperformance and fast adaptability. GERM improves upon models like DNABERT-2 by\neliminating outliers that hinder low-rank adaptation and post-training\nquantization, enhancing both efficiency and robustness. We replace the vanilla\nattention layer with an outlier-free mechanism inspired by associative memory\nmodels. By removing outliers during both pre-training and fine-tuning, this\napproach accelerates adaptation, reduces computational costs, and enhances\nquantization robustness within acceptable loss margins. Additionally, we\npropose GERM-T, a strategy that employs small-step continual learning within\nthe outlier-free framework, leveraging original checkpoints to avoid retraining\nfrom scratch. Empirically, GERM improves fine-tuning performance by 37.98% and\nquantization by 64.34% over the baseline model. It also reduces average\nkurtosis by 92.14% and maximum infinity norm by 82.77%. Compared to leading\nmethods, GERM consistently delivers superior performance, offering a practical\nsolution for genomic modeling in resource-constrained settings. Code is\navailable at https://github.com/MAGICS-LAB/GERM.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "International Conference on Machine Learning (ICML) 2025",
    "pdf_url": "http://arxiv.org/pdf/2505.00598v2",
    "published_date": "2025-05-01 15:31:09 UTC",
    "updated_date": "2025-05-02 09:34:03 UTC"
  },
  {
    "arxiv_id": "2505.00596v1",
    "title": "A Finite-State Controller Based Offline Solver for Deterministic POMDPs",
    "authors": [
      "Alex Schutz",
      "Yang You",
      "Matias Mattamala",
      "Ipek Caliskanelli",
      "Bruno Lacerda",
      "Nick Hawes"
    ],
    "abstract": "Deterministic partially observable Markov decision processes (DetPOMDPs)\noften arise in planning problems where the agent is uncertain about its\nenvironmental state but can act and observe deterministically. In this paper,\nwe propose DetMCVI, an adaptation of the Monte Carlo Value Iteration (MCVI)\nalgorithm for DetPOMDPs, which builds policies in the form of finite-state\ncontrollers (FSCs). DetMCVI solves large problems with a high success rate,\noutperforming existing baselines for DetPOMDPs. We also verify the performance\nof the algorithm in a real-world mobile robot forest mapping scenario.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG",
      "I.2.8; I.2.9"
    ],
    "primary_category": "cs.RO",
    "comment": "9 pages, 6 figures. Appendix attached. To be published in Proceedings\n  of IJCAI 2025. For code see http://github.com/ori-goals/DetMCVI",
    "pdf_url": "http://arxiv.org/pdf/2505.00596v1",
    "published_date": "2025-05-01 15:30:26 UTC",
    "updated_date": "2025-05-01 15:30:26 UTC"
  },
  {
    "arxiv_id": "2505.00584v1",
    "title": "Synthesizing and Identifying Noise Levels in Autonomous Vehicle Camera Radar Datasets",
    "authors": [
      "Mathis Morales",
      "Golnaz Habibi"
    ],
    "abstract": "Detecting and tracking objects is a crucial component of any autonomous\nnavigation method. For the past decades, object detection has yielded promising\nresults using neural networks on various datasets. While many methods focus on\nperformance metrics, few projects focus on improving the robustness of these\ndetection and tracking pipelines, notably to sensor failures. In this paper we\nattempt to address this issue by creating a realistic synthetic data\naugmentation pipeline for camera-radar Autonomous Vehicle (AV) datasets. Our\ngoal is to accurately simulate sensor failures and data deterioration due to\nreal-world interferences. We also present our results of a baseline lightweight\nNoise Recognition neural network trained and tested on our augmented dataset,\nreaching an overall recognition accuracy of 54.4\\% on 11 categories across\n10086 images and 2145 radar point-clouds.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "eess.IV",
      "eess.SP"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.00584v1",
    "published_date": "2025-05-01 15:15:50 UTC",
    "updated_date": "2025-05-01 15:15:50 UTC"
  },
  {
    "arxiv_id": "2505.00579v1",
    "title": "Voice Cloning: Comprehensive Survey",
    "authors": [
      "Hussam Azzuni",
      "Abdulmotaleb El Saddik"
    ],
    "abstract": "Voice Cloning has rapidly advanced in today's digital world, with many\nresearchers and corporations working to improve these algorithms for various\napplications. This article aims to establish a standardized terminology for\nvoice cloning and explore its different variations. It will cover speaker\nadaptation as the fundamental concept and then delve deeper into topics such as\nfew-shot, zero-shot, and multilingual TTS within that context. Finally, we will\nexplore the evaluation metrics commonly used in voice cloning research and\nrelated datasets. This survey compiles the available voice cloning algorithms\nto encourage research toward its generation and detection to limit its misuse.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "26 pages, 7 figures",
    "pdf_url": "http://arxiv.org/pdf/2505.00579v1",
    "published_date": "2025-05-01 15:10:29 UTC",
    "updated_date": "2025-05-01 15:10:29 UTC"
  },
  {
    "arxiv_id": "2505.14845v1",
    "title": "A Comparative Study of Large Language Models and Human Personality Traits",
    "authors": [
      "Wang Jiaqi",
      "Wang bo",
      "Guo fa",
      "Cheng cheng",
      "Yang li"
    ],
    "abstract": "Large Language Models (LLMs) have demonstrated human-like capabilities in\nlanguage comprehension and generation, becoming active participants in social\nand cognitive domains. This study investigates whether LLMs exhibit\npersonality-like traits and how these traits compare with human personality,\nfocusing on the applicability of conventional personality assessment tools. A\nbehavior-based approach was used across three empirical studies. Study 1\nexamined test-retest stability and found that LLMs show higher variability and\nare more input-sensitive than humans, lacking long-term stability. Based on\nthis, we propose the Distributed Personality Framework, conceptualizing LLM\ntraits as dynamic and input-driven. Study 2 analyzed cross-variant consistency\nin personality measures and found LLMs' responses were highly sensitive to item\nwording, showing low internal consistency compared to humans. Study 3 explored\npersonality retention during role-playing, showing LLM traits are shaped by\nprompt and parameter settings. These findings suggest that LLMs express fluid,\nexternally dependent personality patterns, offering insights for constructing\nLLM-specific personality frameworks and advancing human-AI interaction. This\nwork contributes to responsible AI development and extends the boundaries of\npersonality psychology in the age of intelligent systems.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.14845v1",
    "published_date": "2025-05-01 15:10:15 UTC",
    "updated_date": "2025-05-01 15:10:15 UTC"
  },
  {
    "arxiv_id": "2505.03793v1",
    "title": "LENSLLM: Unveiling Fine-Tuning Dynamics for LLM Selection",
    "authors": [
      "Xinyue Zeng",
      "Haohui Wang",
      "Junhong Lin",
      "Jun Wu",
      "Tyler Cody",
      "Dawei Zhou"
    ],
    "abstract": "The proliferation of open-sourced Large Language Models (LLMs) and diverse\ndownstream tasks necessitates efficient model selection, given the\nimpracticality of fine-tuning all candidates due to computational constraints.\nDespite the recent advances in LLM selection, a fundamental research question\nlargely remains nascent: how can we model the dynamic behaviors of LLMs during\nfine-tuning, thereby enhancing our understanding of their generalization\nperformance across diverse downstream tasks? In this work, we propose a novel\ntheoretical framework that provides a proper lens to assess the generalization\ncapabilities of LLMs, thereby enabling accurate and efficient LLM selection for\ndownstream applications. In particular, we first derive a Hessian-based\nPAC-Bayes generalization bound that unveils fine-tuning dynamics of LLMs and\nthen introduce LENSLLM, a Neural Tangent Kernel(NTK)-based Rectified Scaling\nModel that enables accurate performance predictions across diverse tasks while\nmaintaining computational efficiency. Extensive empirical results on 3\nlarge-scale benchmarks demonstrate that our model achieves up to 91.1% accuracy\nand reduces up to 88.5% computational cost in LLM selection, outperforming 5\nstate-of-the-art methods. We open-source our proposed LENSLLM model and\ncorresponding results at the Github link:\nhttps://github.com/Susan571/LENSLLM.git.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "It is accepted by ICML'2025, and the code is open-sourcing on\n  https://github.com/Susan571/LENSLLM.git",
    "pdf_url": "http://arxiv.org/pdf/2505.03793v1",
    "published_date": "2025-05-01 15:07:32 UTC",
    "updated_date": "2025-05-01 15:07:32 UTC"
  },
  {
    "arxiv_id": "2505.00570v2",
    "title": "FreqKV: Frequency Domain Key-Value Compression for Efficient Context Window Extension",
    "authors": [
      "Jushi Kai",
      "Boyi Zeng",
      "Yixuan Wang",
      "Haoli Bai",
      "Ziwei He",
      "Bo Jiang",
      "Zhouhan Lin"
    ],
    "abstract": "Frequency-domain compression has proven effective in reducing redundancies\nfor spatial signals. In this work, we propose FreqKV, a novel frequency domain\nkey-value (KV) compression technique that enables efficient context window\nextension for decoder-only large language models (LLMs). Our approach is\nmotivated by a key observation that, in the frequency domain, the energy\ndistribution of the KV cache is predominantly concentrated in low-frequency\ncomponents. By discarding high-frequency components, we achieve efficient\ncompression of the KV cache with minimal information loss. FreqKV iteratively\ncompresses the increasing KV cache to a fixed size in the frequency domain,\nallowing models to process lengthy contexts efficiently. Introducing no\nadditional parameters or architectural modifications, FreqKV is applicable to\nboth fine-tuning and inference. With minimal fine-tuning, LLMs can learn to\nleverage the limited cache that is compressed in the frequency domain and\nextend the context window. Experiments on a range of long context language\nmodeling and understanding tasks demonstrate the efficiency and effectiveness\nof the proposed method.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.00570v2",
    "published_date": "2025-05-01 14:53:12 UTC",
    "updated_date": "2025-05-19 02:21:16 UTC"
  },
  {
    "arxiv_id": "2505.00568v2",
    "title": "Multimodal Masked Autoencoder Pre-training for 3D MRI-Based Brain Tumor Analysis with Missing Modalities",
    "authors": [
      "Lucas Robinet",
      "Ahmad Berjaoui",
      "Elizabeth Cohen-Jonathan Moyal"
    ],
    "abstract": "Multimodal magnetic resonance imaging (MRI) constitutes the first line of\ninvestigation for clinicians in the care of brain tumors, providing crucial\ninsights for surgery planning, treatment monitoring, and biomarker\nidentification. Pre-training on large datasets have been shown to help models\nlearn transferable representations and adapt with minimal labeled data. This\nbehavior is especially valuable in medical imaging, where annotations are often\nscarce. However, applying this paradigm to multimodal medical data introduces a\nchallenge: most existing approaches assume that all imaging modalities are\navailable during both pre-training and fine-tuning. In practice, missing\nmodalities often occur due to acquisition issues, specialist unavailability, or\nspecific experimental designs on small in-house datasets. Consequently, a\ncommon approach involves training a separate model for each desired modality\ncombination, making the process both resource-intensive and impractical for\nclinical use. Therefore, we introduce BM-MAE, a masked image modeling\npre-training strategy tailored for multimodal MRI data. The same pre-trained\nmodel seamlessly adapts to any combination of available modalities, extracting\nrich representations that capture both intra- and inter-modal information. This\nallows fine-tuning on any subset of modalities without requiring architectural\nchanges, while still benefiting from a model pre-trained on the full set of\nmodalities. Extensive experiments show that the proposed pre-training strategy\noutperforms or remains competitive with baselines that require separate\npre-training for each modality subset, while substantially surpassing training\nfrom scratch on several downstream tasks. Additionally, it can quickly and\nefficiently reconstruct missing modalities, highlighting its practical value.\nCode and trained models are available at: https://github.com/Lucas-rbnt/BM-MAE",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.00568v2",
    "published_date": "2025-05-01 14:51:30 UTC",
    "updated_date": "2025-05-02 08:02:39 UTC"
  },
  {
    "arxiv_id": "2505.00562v1",
    "title": "TeLoGraF: Temporal Logic Planning via Graph-encoded Flow Matching",
    "authors": [
      "Yue Meng",
      "Chuchu Fan"
    ],
    "abstract": "Learning to solve complex tasks with signal temporal logic (STL)\nspecifications is crucial to many real-world applications. However, most\nprevious works only consider fixed or parametrized STL specifications due to\nthe lack of a diverse STL dataset and encoders to effectively extract temporal\nlogic information for downstream tasks. In this paper, we propose TeLoGraF,\nTemporal Logic Graph-encoded Flow, which utilizes Graph Neural Networks (GNN)\nencoder and flow-matching to learn solutions for general STL specifications. We\nidentify four commonly used STL templates and collect a total of 200K\nspecifications with paired demonstrations. We conduct extensive experiments in\nfive simulation environments ranging from simple dynamical models in the 2D\nspace to high-dimensional 7DoF Franka Panda robot arm and Ant quadruped\nnavigation. Results show that our method outperforms other baselines in the STL\nsatisfaction rate. Compared to classical STL planning algorithms, our approach\nis 10-100X faster in inference and can work on any system dynamics. Besides, we\nshow our graph-encoding method's capability to solve complex STLs and\nrobustness to out-distribution STL specifications. Code is available at\nhttps://github.com/mengyuest/TeLoGraF",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.FL",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "Accepted to ICML2025",
    "pdf_url": "http://arxiv.org/pdf/2505.00562v1",
    "published_date": "2025-05-01 14:40:07 UTC",
    "updated_date": "2025-05-01 14:40:07 UTC"
  },
  {
    "arxiv_id": "2505.00561v1",
    "title": "Learning to Learn with Quantum Optimization via Quantum Neural Networks",
    "authors": [
      "Kuan-Cheng Chen",
      "Hiromichi Matsuyama",
      "Wei-Hao Huang"
    ],
    "abstract": "Quantum Approximate Optimization Algorithms (QAOA) promise efficient\nsolutions to classically intractable combinatorial optimization problems by\nharnessing shallow-depth quantum circuits. Yet, their performance and\nscalability often hinge on effective parameter optimization, which remains\nnontrivial due to rugged energy landscapes and hardware noise. In this work, we\nintroduce a quantum meta-learning framework that combines quantum neural\nnetworks, specifically Quantum Long Short-Term Memory (QLSTM) architectures,\nwith QAOA. By training the QLSTM optimizer on smaller graph instances, our\napproach rapidly generalizes to larger, more complex problems, substantially\nreducing the number of iterations required for convergence. Through\ncomprehensive benchmarks on Max-Cut and Sherrington-Kirkpatrick model\ninstances, we demonstrate that QLSTM-based optimizers converge faster and\nachieve higher approximation ratios compared to classical baselines, thereby\noffering a robust pathway toward scalable quantum optimization in the NISQ era.",
    "categories": [
      "quant-ph",
      "cs.AI"
    ],
    "primary_category": "quant-ph",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.00561v1",
    "published_date": "2025-05-01 14:39:26 UTC",
    "updated_date": "2025-05-01 14:39:26 UTC"
  },
  {
    "arxiv_id": "2505.00557v1",
    "title": "Triggering Hallucinations in LLMs: A Quantitative Study of Prompt-Induced Hallucination in Large Language Models",
    "authors": [
      "Makoto Sato"
    ],
    "abstract": "Hallucinations in large language models (LLMs) present a growing challenge\nacross real-world applications, from healthcare to law, where factual\nreliability is essential. Despite advances in alignment and instruction tuning,\nLLMs can still generate outputs that are fluent yet fundamentally untrue.\nUnderstanding the cognitive dynamics that underlie these hallucinations remains\nan open problem. In this study, we propose a prompt-based framework to\nsystematically trigger and quantify hallucination: a Hallucination-Inducing\nPrompt (HIP), which synthetically fuses semantically distant concepts (e.g.,\nperiodic table of elements and tarot divination) in a misleading way, and a\nHallucination Quantifying Prompt (HQP), which scores the plausibility,\nconfidence, and coherence of the output. Controlled experiments across multiple\nLLMs revealed that HIPs consistently produced less coherent and more\nhallucinated responses than their null-fusion controls. These effects varied\nacross models, with reasoning-oriented LLMs showing distinct profiles from\ngeneral-purpose ones. Our framework provides a reproducible testbed for\nstudying hallucination vulnerability, and opens the door to developing safer,\nmore introspective LLMs that can detect and self-regulate the onset of\nconceptual instability.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.00557v1",
    "published_date": "2025-05-01 14:33:47 UTC",
    "updated_date": "2025-05-01 14:33:47 UTC"
  },
  {
    "arxiv_id": "2505.00555v1",
    "title": "On the Mechanistic Interpretability of Neural Networks for Causality in Bio-statistics",
    "authors": [
      "Jean-Baptiste A. Conan"
    ],
    "abstract": "Interpretable insights from predictive models remain critical in\nbio-statistics, particularly when assessing causality, where classical\nstatistical and machine learning methods often provide inherent clarity. While\nNeural Networks (NNs) offer powerful capabilities for modeling complex\nbiological data, their traditional \"black-box\" nature presents challenges for\nvalidation and trust in high-stakes health applications. Recent advances in\nMechanistic Interpretability (MI) aim to decipher the internal computations\nlearned by these networks. This work investigates the application of MI\ntechniques to NNs within the context of causal inference for bio-statistics.\n  We demonstrate that MI tools can be leveraged to: (1) probe and validate the\ninternal representations learned by NNs, such as those estimating nuisance\nfunctions in frameworks like Targeted Minimum Loss-based Estimation (TMLE); (2)\ndiscover and visualize the distinct computational pathways employed by the\nnetwork to process different types of inputs, potentially revealing how\nconfounders and treatments are handled; and (3) provide methodologies for\ncomparing the learned mechanisms and extracted insights across statistical,\nmachine learning, and NN models, fostering a deeper understanding of their\nrespective strengths and weaknesses for causal bio-statistical analysis.",
    "categories": [
      "stat.AP",
      "cs.AI"
    ],
    "primary_category": "stat.AP",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.00555v1",
    "published_date": "2025-05-01 14:30:34 UTC",
    "updated_date": "2025-05-01 14:30:34 UTC"
  },
  {
    "arxiv_id": "2505.03792v1",
    "title": "Towards Efficient Online Tuning of VLM Agents via Counterfactual Soft Reinforcement Learning",
    "authors": [
      "Lang Feng",
      "Weihao Tan",
      "Zhiyi Lyu",
      "Longtao Zheng",
      "Haiyang Xu",
      "Ming Yan",
      "Fei Huang",
      "Bo An"
    ],
    "abstract": "Online fine-tuning vision-language model (VLM) agents with reinforcement\nlearning (RL) has shown promise for equipping agents with multi-step,\ngoal-oriented capabilities in dynamic environments. However, their open-ended\ntextual action space and non-end-to-end nature of action generation present\nsignificant challenges to effective online exploration in RL, e.g., explosion\nof the exploration space. We propose a novel online fine-tuning method,\nCounterfactual Soft Reinforcement Learning (CoSo), better suited to the textual\noutput space of VLM agents. Compared to prior methods that assign uniform\nuncertainty to all tokens, CoSo leverages counterfactual reasoning to\ndynamically assess the causal influence of individual tokens on post-processed\nactions. By prioritizing the exploration of action-critical tokens while\nreducing the impact of semantically redundant or low-impact tokens, CoSo\nenables a more targeted and efficient online rollout process. We provide\ntheoretical analysis proving CoSo's convergence and policy improvement\nguarantees, and extensive empirical evaluations supporting CoSo's\neffectiveness. Our results across a diverse set of agent tasks, including\nAndroid device control, card gaming, and embodied AI, highlight its remarkable\nability to enhance exploration efficiency and deliver consistent performance\ngains. The code is available at https://github.com/langfengQ/CoSo.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "ICML 2025",
    "pdf_url": "http://arxiv.org/pdf/2505.03792v1",
    "published_date": "2025-05-01 14:17:53 UTC",
    "updated_date": "2025-05-01 14:17:53 UTC"
  },
  {
    "arxiv_id": "2505.00533v1",
    "title": "Test-time Correlation Alignment",
    "authors": [
      "Linjing You",
      "Jiabao Lu",
      "Xiayuan Huang"
    ],
    "abstract": "Deep neural networks often experience performance drops due to distribution\nshifts between training and test data. Although domain adaptation offers a\nsolution, privacy concerns restrict access to training data in many real-world\nscenarios. This restriction has spurred interest in Test-Time Adaptation (TTA),\nwhich adapts models using only unlabeled test data. However, current TTA\nmethods still face practical challenges: (1) a primary focus on instance-wise\nalignment, overlooking CORrelation ALignment (CORAL) due to missing source\ncorrelations; (2) complex backpropagation operations for model updating,\nresulting in overhead computation and (3) domain forgetting.\n  To address these challenges, we provide a theoretical analysis to investigate\nthe feasibility of Test-time Correlation Alignment (TCA), demonstrating that\ncorrelation alignment between high-certainty instances and test instances can\nenhance test performances with a theoretical guarantee. Based on this, we\npropose two simple yet effective algorithms: LinearTCA and LinearTCA+.\nLinearTCA applies a simple linear transformation to achieve both instance and\ncorrelation alignment without additional model updates, while LinearTCA+ serves\nas a plug-and-play module that can easily boost existing TTA methods. Extensive\nexperiments validate our theoretical insights and show that TCA methods\nsignificantly outperforms baselines across various tasks, benchmarks and\nbackbones. Notably, LinearTCA improves adaptation accuracy by 5.88% on\nOfficeHome dataset, while using only 4% maximum GPU memory usage and 0.6%\ncomputation time compared to the best baseline TTA method.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted by ICML2025",
    "pdf_url": "http://arxiv.org/pdf/2505.00533v1",
    "published_date": "2025-05-01 13:59:13 UTC",
    "updated_date": "2025-05-01 13:59:13 UTC"
  },
  {
    "arxiv_id": "2505.00515v1",
    "title": "Safety-Critical Traffic Simulation with Guided Latent Diffusion Model",
    "authors": [
      "Mingxing Peng",
      "Ruoyu Yao",
      "Xusen Guo",
      "Yuting Xie",
      "Xianda Chen",
      "Jun Ma"
    ],
    "abstract": "Safety-critical traffic simulation plays a crucial role in evaluating\nautonomous driving systems under rare and challenging scenarios. However,\nexisting approaches often generate unrealistic scenarios due to insufficient\nconsideration of physical plausibility and suffer from low generation\nefficiency. To address these limitations, we propose a guided latent diffusion\nmodel (LDM) capable of generating physically realistic and adversarial\nsafety-critical traffic scenarios. Specifically, our model employs a\ngraph-based variational autoencoder (VAE) to learn a compact latent space that\ncaptures complex multi-agent interactions while improving computational\nefficiency. Within this latent space, the diffusion model performs the\ndenoising process to produce realistic trajectories. To enable controllable and\nadversarial scenario generation, we introduce novel guidance objectives that\ndrive the diffusion process toward producing adversarial and behaviorally\nrealistic driving behaviors. Furthermore, we develop a sample selection module\nbased on physical feasibility checks to further enhance the physical\nplausibility of the generated scenarios. Extensive experiments on the nuScenes\ndataset demonstrate that our method achieves superior adversarial effectiveness\nand generation efficiency compared to existing baselines while maintaining a\nhigh level of realism. Our work provides an effective tool for realistic\nsafety-critical scenario simulation, paving the way for more robust evaluation\nof autonomous driving systems.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.MA"
    ],
    "primary_category": "cs.RO",
    "comment": "7 pages, 3 figures",
    "pdf_url": "http://arxiv.org/pdf/2505.00515v1",
    "published_date": "2025-05-01 13:33:34 UTC",
    "updated_date": "2025-05-01 13:33:34 UTC"
  },
  {
    "arxiv_id": "2505.00506v1",
    "title": "HalluMix: A Task-Agnostic, Multi-Domain Benchmark for Real-World Hallucination Detection",
    "authors": [
      "Deanna Emery",
      "Michael Goitia",
      "Freddie Vargus",
      "Iulia Neagu"
    ],
    "abstract": "As large language models (LLMs) are increasingly deployed in high-stakes\ndomains, detecting hallucinated content$\\unicode{x2013}$text that is not\ngrounded in supporting evidence$\\unicode{x2013}$has become a critical\nchallenge. Existing benchmarks for hallucination detection are often\nsynthetically generated, narrowly focused on extractive question answering, and\nfail to capture the complexity of real-world scenarios involving multi-document\ncontexts and full-sentence outputs. We introduce the HalluMix Benchmark, a\ndiverse, task-agnostic dataset that includes examples from a range of domains\nand formats. Using this benchmark, we evaluate seven hallucination detection\nsystems$\\unicode{x2013}$both open and closed\nsource$\\unicode{x2013}$highlighting differences in performance across tasks,\ndocument lengths, and input representations. Our analysis highlights\nsubstantial performance disparities between short and long contexts, with\ncritical implications for real-world Retrieval Augmented Generation (RAG)\nimplementations. Quotient Detections achieves the best overall performance,\nwith an accuracy of 0.82 and an F1 score of 0.84.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.00506v1",
    "published_date": "2025-05-01 13:22:45 UTC",
    "updated_date": "2025-05-01 13:22:45 UTC"
  },
  {
    "arxiv_id": "2505.00503v2",
    "title": "Variational OOD State Correction for Offline Reinforcement Learning",
    "authors": [
      "Ke Jiang",
      "Wen Jiang",
      "Masahiro Fujisawa",
      "Xiaoyang Tan"
    ],
    "abstract": "The performance of Offline reinforcement learning is significantly impacted\nby the issue of state distributional shift, and out-of-distribution (OOD) state\ncorrection is a popular approach to address this problem. In this paper, we\npropose a novel method named Density-Aware Safety Perception (DASP) for OOD\nstate correction. Specifically, our method encourages the agent to prioritize\nactions that lead to outcomes with higher data density, thereby promoting its\noperation within or the return to in-distribution (safe) regions. To achieve\nthis, we optimize the objective within a variational framework that\nconcurrently considers both the potential outcomes of decision-making and their\ndensity, thus providing crucial contextual information for safe\ndecision-making. Finally, we validate the effectiveness and feasibility of our\nproposed method through extensive experimental evaluations on the offline\nMuJoCo and AntMaze suites.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.00503v2",
    "published_date": "2025-05-01 13:14:07 UTC",
    "updated_date": "2025-05-05 06:00:10 UTC"
  },
  {
    "arxiv_id": "2505.03791v1",
    "title": "Practical Boolean Backpropagation",
    "authors": [
      "Simon Golbert"
    ],
    "abstract": "Boolean neural networks offer hardware-efficient alternatives to real-valued\nmodels. While quantization is common, purely Boolean training remains\nunderexplored. We present a practical method for purely Boolean backpropagation\nfor networks based on a single specific gate we chose, operating directly in\nBoolean algebra involving no numerics. Initial experiments confirm its\nfeasibility.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "11 pages",
    "pdf_url": "http://arxiv.org/pdf/2505.03791v1",
    "published_date": "2025-05-01 12:50:02 UTC",
    "updated_date": "2025-05-01 12:50:02 UTC"
  },
  {
    "arxiv_id": "2505.00490v1",
    "title": "Optimal Interactive Learning on the Job via Facility Location Planning",
    "authors": [
      "Shivam Vats",
      "Michelle Zhao",
      "Patrick Callaghan",
      "Mingxi Jia",
      "Maxim Likhachev",
      "Oliver Kroemer",
      "George Konidaris"
    ],
    "abstract": "Collaborative robots must continually adapt to novel tasks and user\npreferences without overburdening the user. While prior interactive robot\nlearning methods aim to reduce human effort, they are typically limited to\nsingle-task scenarios and are not well-suited for sustained, multi-task\ncollaboration. We propose COIL (Cost-Optimal Interactive Learning) -- a\nmulti-task interaction planner that minimizes human effort across a sequence of\ntasks by strategically selecting among three query types (skill, preference,\nand help). When user preferences are known, we formulate COIL as an\nuncapacitated facility location (UFL) problem, which enables bounded-suboptimal\nplanning in polynomial time using off-the-shelf approximation algorithms. We\nextend our formulation to handle uncertainty in user preferences by\nincorporating one-step belief space planning, which uses these approximation\nalgorithms as subroutines to maintain polynomial-time performance. Simulated\nand physical experiments on manipulation tasks show that our framework\nsignificantly reduces the amount of work allocated to the human while\nmaintaining successful task completion.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "Accepted to Robotics: Science and Systems (RSS) 2025",
    "pdf_url": "http://arxiv.org/pdf/2505.00490v1",
    "published_date": "2025-05-01 12:45:09 UTC",
    "updated_date": "2025-05-01 12:45:09 UTC"
  },
  {
    "arxiv_id": "2505.00488v1",
    "title": "MULE: Multi-terrain and Unknown Load Adaptation for Effective Quadrupedal Locomotion",
    "authors": [
      "Vamshi Kumar Kurva",
      "Shishir Kolathaya"
    ],
    "abstract": "Quadrupedal robots are increasingly deployed for load-carrying tasks across\ndiverse terrains. While Model Predictive Control (MPC)-based methods can\naccount for payload variations, they often depend on predefined gait schedules\nor trajectory generators, limiting their adaptability in unstructured\nenvironments. To address these limitations, we propose an Adaptive\nReinforcement Learning (RL) framework that enables quadrupedal robots to\ndynamically adapt to both varying payloads and diverse terrains. The framework\nconsists of a nominal policy responsible for baseline locomotion and an\nadaptive policy that learns corrective actions to preserve stability and\nimprove command tracking under payload variations. We validate the proposed\napproach through large-scale simulation experiments in Isaac Gym and real-world\nhardware deployment on a Unitree Go1 quadruped. The controller was tested on\nflat ground, slopes, and stairs under both static and dynamic payload changes.\nAcross all settings, our adaptive controller consistently outperformed the\ncontroller in tracking body height and velocity commands, demonstrating\nenhanced robustness and adaptability without requiring explicit gait design or\nmanual tuning.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "Preprint under review",
    "pdf_url": "http://arxiv.org/pdf/2505.00488v1",
    "published_date": "2025-05-01 12:41:35 UTC",
    "updated_date": "2025-05-01 12:41:35 UTC"
  },
  {
    "arxiv_id": "2505.00487v1",
    "title": "Analysis of the vulnerability of machine learning regression models to adversarial attacks using data from 5G wireless networks",
    "authors": [
      "Leonid Legashev",
      "Artur Zhigalov",
      "Denis Parfenov"
    ],
    "abstract": "This article describes the process of creating a script and conducting an\nanalytical study of a dataset using the DeepMIMO emulator. An advertorial\nattack was carried out using the FGSM method to maximize the gradient. A\ncomparison is made of the effectiveness of binary classifiers in the task of\ndetecting distorted data. The dynamics of changes in the quality indicators of\nthe regression model were analyzed in conditions without adversarial attacks,\nduring an adversarial attack and when the distorted data was isolated. It is\nshown that an adversarial FGSM attack with gradient maximization leads to an\nincrease in the value of the MSE metric by 33% and a decrease in the R2\nindicator by 10% on average. The LightGBM binary classifier effectively\nidentifies data with adversarial anomalies with 98% accuracy. Regression\nmachine learning models are susceptible to adversarial attacks, but rapid\nanalysis of network traffic and data transmitted over the network makes it\npossible to identify malicious activity",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.00487v1",
    "published_date": "2025-05-01 12:36:05 UTC",
    "updated_date": "2025-05-01 12:36:05 UTC"
  },
  {
    "arxiv_id": "2505.00482v1",
    "title": "JointDiT: Enhancing RGB-Depth Joint Modeling with Diffusion Transformers",
    "authors": [
      "Kwon Byung-Ki",
      "Qi Dai",
      "Lee Hyoseok",
      "Chong Luo",
      "Tae-Hyun Oh"
    ],
    "abstract": "We present JointDiT, a diffusion transformer that models the joint\ndistribution of RGB and depth. By leveraging the architectural benefit and\noutstanding image prior of the state-of-the-art diffusion transformer, JointDiT\nnot only generates high-fidelity images but also produces geometrically\nplausible and accurate depth maps. This solid joint distribution modeling is\nachieved through two simple yet effective techniques that we propose, i.e.,\nadaptive scheduling weights, which depend on the noise levels of each modality,\nand the unbalanced timestep sampling strategy. With these techniques, we train\nour model across all noise levels for each modality, enabling JointDiT to\nnaturally handle various combinatorial generation tasks, including joint\ngeneration, depth estimation, and depth-conditioned image generation by simply\ncontrolling the timestep of each branch. JointDiT demonstrates outstanding\njoint generation performance. Furthermore, it achieves comparable results in\ndepth estimation and depth-conditioned image generation, suggesting that joint\ndistribution modeling can serve as a replaceable alternative to conditional\ngeneration. The project page is available at\nhttps://byungki-k.github.io/JointDiT/.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.00482v1",
    "published_date": "2025-05-01 12:21:23 UTC",
    "updated_date": "2025-05-01 12:21:23 UTC"
  },
  {
    "arxiv_id": "2505.00757v1",
    "title": "Efficient On-Chip Implementation of 4D Radar-Based 3D Object Detection on Hailo-8L",
    "authors": [
      "Woong-Chan Byun",
      "Dong-Hee Paek",
      "Seung-Hyun Song",
      "Seung-Hyun Kong"
    ],
    "abstract": "4D radar has attracted attention in autonomous driving due to its ability to\nenable robust 3D object detection even under adverse weather conditions. To\npractically deploy such technologies, it is essential to achieve real-time\nprocessing within low-power embedded environments. Addressing this, we present\nthe first on-chip implementation of a 4D radar-based 3D object detection model\non the Hailo-8L AI accelerator. Although conventional 3D convolutional neural\nnetwork (CNN) architectures require 5D inputs, the Hailo-8L only supports 4D\ntensors, posing a significant challenge. To overcome this limitation, we\nintroduce a tensor transformation method that reshapes 5D inputs into 4D\nformats during the compilation process, enabling direct deployment without\naltering the model structure. The proposed system achieves 46.47% AP_3D and\n52.75% AP_BEV, maintaining comparable accuracy to GPU-based models while\nachieving an inference speed of 13.76 Hz. These results demonstrate the\napplicability of 4D radar-based perception technologies to autonomous driving\nsystems.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "4pages, 2 figures",
    "pdf_url": "http://arxiv.org/pdf/2505.00757v1",
    "published_date": "2025-05-01 12:10:04 UTC",
    "updated_date": "2025-05-01 12:10:04 UTC"
  },
  {
    "arxiv_id": "2505.01459v1",
    "title": "MoxE: Mixture of xLSTM Experts with Entropy-Aware Routing for Efficient Language Modeling",
    "authors": [
      "Abdoul Majid O. Thiombiano",
      "Brahim Hnich",
      "Ali Ben Mrad",
      "Mohamed Wiem Mkaouer"
    ],
    "abstract": "This paper introduces MoxE, a novel architecture that synergistically\ncombines the Extended Long Short-Term Memory (xLSTM) with the Mixture of\nExperts (MoE) framework to address critical scalability and efficiency\nchallenges in large language models (LLMs). The proposed method effectively\nleverages xLSTM's innovative memory structures while strategically introducing\nsparsity through MoE to substantially reduce computational overhead. At the\nheart of our approach is a novel entropy-based routing mechanism, designed to\ndynamically route tokens to specialized experts, thereby ensuring efficient and\nbalanced resource utilization. This entropy awareness enables the architecture\nto effectively manage both rare and common tokens, with mLSTM blocks being\nfavored to handle rare tokens. To further enhance generalization, we introduce\na suite of auxiliary losses, including entropy-based and group-wise balancing\nlosses, ensuring robust performance and efficient training. Theoretical\nanalysis and empirical evaluations rigorously demonstrate that MoxE achieves\nsignificant efficiency gains and enhanced effectiveness compared to existing\napproaches, marking a notable advancement in scalable LLM architectures.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.01459v1",
    "published_date": "2025-05-01 12:06:39 UTC",
    "updated_date": "2025-05-01 12:06:39 UTC"
  },
  {
    "arxiv_id": "2505.00474v1",
    "title": "Rule-based Classifier Models",
    "authors": [
      "Cecilia Di Florio",
      "Huimin Dong",
      "Antonino Rotolo"
    ],
    "abstract": "We extend the formal framework of classifier models used in the legal domain.\nWhile the existing classifier framework characterises cases solely through the\nfacts involved, legal reasoning fundamentally relies on both facts and rules,\nparticularly the ratio decidendi. This paper presents an initial approach to\nincorporating sets of rules within a classifier. Our work is built on the work\nof Canavotto et al. (2023), which has developed the rule-based reason model of\nprecedential constraint within a hierarchy of factors. We demonstrate how\ndecisions for new cases can be inferred using this enriched rule-based\nclassifier framework. Additionally, we provide an example of how the time\nelement and the hierarchy of courts can be used in the new classifier\nframework.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "11 pages, 1 figure. Extended version of a short paper accepted to\n  ICAIL 2025. This is the authors' version of the work. It is posted here for\n  your personal use",
    "pdf_url": "http://arxiv.org/pdf/2505.00474v1",
    "published_date": "2025-05-01 11:59:16 UTC",
    "updated_date": "2025-05-01 11:59:16 UTC"
  },
  {
    "arxiv_id": "2505.00472v1",
    "title": "UserCentrix: An Agentic Memory-augmented AI Framework for Smart Spaces",
    "authors": [
      "Alaa Saleh",
      "Sasu Tarkoma",
      "Praveen Kumar Donta",
      "Naser Hossein Motlagh",
      "Schahram Dustdar",
      "Susanna Pirttikangas",
      "Lauri Lovén"
    ],
    "abstract": "Agentic AI, with its autonomous and proactive decision-making, has\ntransformed smart environments. By integrating Generative AI (GenAI) and\nmulti-agent systems, modern AI frameworks can dynamically adapt to user\npreferences, optimize data management, and improve resource allocation. This\npaper introduces UserCentrix, an agentic memory-augmented AI framework designed\nto enhance smart spaces through dynamic, context-aware decision-making. This\nframework integrates personalized Large Language Model (LLM) agents that\nleverage user preferences and LLM memory management to deliver proactive and\nadaptive assistance. Furthermore, it incorporates a hybrid hierarchical control\nsystem, balancing centralized and distributed processing to optimize real-time\nresponsiveness while maintaining global situational awareness. UserCentrix\nachieves resource-efficient AI interactions by embedding memory-augmented\nreasoning, cooperative agent negotiation, and adaptive orchestration\nstrategies. Our key contributions include (i) a self-organizing framework with\nproactive scaling based on task urgency, (ii) a Value of Information\n(VoI)-driven decision-making process, (iii) a meta-reasoning personal LLM\nagent, and (iv) an intelligent multi-agent coordination system for seamless\nenvironment adaptation. Experimental results across various models confirm the\neffectiveness of our approach in enhancing response accuracy, system\nefficiency, and computational resource management in real-world application.",
    "categories": [
      "cs.AI",
      "cs.DC",
      "cs.MA",
      "cs.NI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.00472v1",
    "published_date": "2025-05-01 11:54:49 UTC",
    "updated_date": "2025-05-01 11:54:49 UTC"
  },
  {
    "arxiv_id": "2505.00467v1",
    "title": "Red Teaming Large Language Models for Healthcare",
    "authors": [
      "Vahid Balazadeh",
      "Michael Cooper",
      "David Pellow",
      "Atousa Assadi",
      "Jennifer Bell",
      "Jim Fackler",
      "Gabriel Funingana",
      "Spencer Gable-Cook",
      "Anirudh Gangadhar",
      "Abhishek Jaiswal",
      "Sumanth Kaja",
      "Christopher Khoury",
      "Randy Lin",
      "Kaden McKeen",
      "Sara Naimimohasses",
      "Khashayar Namdar",
      "Aviraj Newatia",
      "Allan Pang",
      "Anshul Pattoo",
      "Sameer Peesapati",
      "Diana Prepelita",
      "Bogdana Rakova",
      "Saba Sadatamin",
      "Rafael Schulman",
      "Ajay Shah",
      "Syed Azhar Shah",
      "Syed Ahmar Shah",
      "Babak Taati",
      "Balagopal Unnikrishnan",
      "Stephanie Williams",
      "Rahul G Krishnan"
    ],
    "abstract": "We present the design process and findings of the pre-conference workshop at\nthe Machine Learning for Healthcare Conference (2024) entitled Red Teaming\nLarge Language Models for Healthcare, which took place on August 15, 2024.\nConference participants, comprising a mix of computational and clinical\nexpertise, attempted to discover vulnerabilities -- realistic clinical prompts\nfor which a large language model (LLM) outputs a response that could cause\nclinical harm. Red-teaming with clinicians enables the identification of LLM\nvulnerabilities that may not be recognised by LLM developers lacking clinical\nexpertise. We report the vulnerabilities found, categorise them, and present\nthe results of a replication study assessing the vulnerabilities across all\nLLMs provided.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.00467v1",
    "published_date": "2025-05-01 11:43:27 UTC",
    "updated_date": "2025-05-01 11:43:27 UTC"
  },
  {
    "arxiv_id": "2505.00455v2",
    "title": "Data Therapist: Eliciting Domain Knowledge from Subject Matter Experts Using Large Language Models",
    "authors": [
      "Sungbok Shin",
      "Hyeon Jeon",
      "Sanghyun Hong",
      "Niklas Elmqvist"
    ],
    "abstract": "Effective data visualization requires not only technical proficiency but also\na deep understanding of the domain-specific context in which data exists. This\ncontext often includes tacit knowledge about data provenance, quality, and\nintended use, which is rarely explicit in the dataset itself. We present the\nData Therapist, a web-based tool that helps domain experts externalize this\nimplicit knowledge through a mixed-initiative process combining iterative Q&A\nwith interactive annotation. Powered by a large language model, the system\nanalyzes user-supplied datasets, prompts users with targeted questions, and\nallows annotation at varying levels of granularity. The resulting structured\nknowledge base can inform both human and automated visualization design. We\nevaluated the tool in a qualitative study involving expert pairs from Molecular\nBiology, Accounting, Political Science, and Usable Security. The study revealed\nrecurring patterns in how experts reason about their data and highlights areas\nwhere AI support can improve visualization design.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "Submitted to IEEE VIS2025",
    "pdf_url": "http://arxiv.org/pdf/2505.00455v2",
    "published_date": "2025-05-01 11:10:17 UTC",
    "updated_date": "2025-05-07 23:28:33 UTC"
  },
  {
    "arxiv_id": "2505.07832v1",
    "title": "A General Approach of Automated Environment Design for Learning the Optimal Power Flow",
    "authors": [
      "Thomas Wolgast",
      "Astrid Nieße"
    ],
    "abstract": "Reinforcement learning (RL) algorithms are increasingly used to solve the\noptimal power flow (OPF) problem. Yet, the question of how to design RL\nenvironments to maximize training performance remains unanswered, both for the\nOPF and the general case. We propose a general approach for automated RL\nenvironment design by utilizing multi-objective optimization. For that, we use\nthe hyperparameter optimization (HPO) framework, which allows the reuse of\nexisting HPO algorithms and methods. On five OPF benchmark problems, we\ndemonstrate that our automated design approach consistently outperforms a\nmanually created baseline environment design. Further, we use statistical\nanalyses to determine which environment design decisions are especially\nimportant for performance, resulting in multiple novel insights on how RL-OPF\nenvironments should be designed. Finally, we discuss the risk of overfitting\nthe environment to the utilized RL algorithm. To the best of our knowledge,\nthis is the first general approach for automated RL environment design.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.LG",
    "comment": "14 pages, accepted at ACM e-energy 2025",
    "pdf_url": "http://arxiv.org/pdf/2505.07832v1",
    "published_date": "2025-05-01 11:02:55 UTC",
    "updated_date": "2025-05-01 11:02:55 UTC"
  },
  {
    "arxiv_id": "2505.00439v1",
    "title": "Per-Domain Generalizing Policies: On Validation Instances and Scaling Behavior",
    "authors": [
      "Timo P. Gros",
      "Nicola J. Müller",
      "Daniel Fiser",
      "Isabel Valera",
      "Verena Wolf",
      "Jörg Hoffmann"
    ],
    "abstract": "Recent work has shown that successful per-domain generalizing action policies\ncan be learned. Scaling behavior, from small training instances to large test\ninstances, is the key objective; and the use of validation instances larger\nthan training instances is one key to achieve it. Prior work has used fixed\nvalidation sets. Here, we introduce a method generating the validation set\ndynamically, on the fly, increasing instance size so long as informative and\nfeasible.We also introduce refined methodology for evaluating scaling behavior,\ngenerating test instances systematically to guarantee a given confidence in\ncoverage performance for each instance size. In experiments, dynamic validation\nimproves scaling behavior of GNN policies in all 9 domains used.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "7 pages, 3 tables, 3 figures, 3 algorithms",
    "pdf_url": "http://arxiv.org/pdf/2505.00439v1",
    "published_date": "2025-05-01 10:32:02 UTC",
    "updated_date": "2025-05-01 10:32:02 UTC"
  },
  {
    "arxiv_id": "2505.03790v1",
    "title": "A Time-Series Data Augmentation Model through Diffusion and Transformer Integration",
    "authors": [
      "Yuren Zhang",
      "Zhongnan Pu",
      "Lei Jing"
    ],
    "abstract": "With the development of Artificial Intelligence, numerous real-world tasks\nhave been accomplished using technology integrated with deep learning. To\nachieve optimal performance, deep neural networks typically require large\nvolumes of data for training. Although advances in data augmentation have\nfacilitated the acquisition of vast datasets, most of this data is concentrated\nin domains like images and speech. However, there has been relatively less\nfocus on augmenting time-series data. To address this gap and generate a\nsubstantial amount of time-series data, we propose a simple and effective\nmethod that combines the Diffusion and Transformer models. By utilizing an\nadjusted diffusion denoising model to generate a large volume of initial\ntime-step action data, followed by employing a Transformer model to predict\nsubsequent actions, and incorporating a weighted loss function to achieve\nconvergence, the method demonstrates its effectiveness. Using the performance\nimprovement of the model after applying augmented data as a benchmark, and\ncomparing the results with those obtained without data augmentation or using\ntraditional data augmentation methods, this approach shows its capability to\nproduce high-quality augmented data.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "eess.SP"
    ],
    "primary_category": "cs.LG",
    "comment": "10 pages,22 figures",
    "pdf_url": "http://arxiv.org/pdf/2505.03790v1",
    "published_date": "2025-05-01 09:40:45 UTC",
    "updated_date": "2025-05-01 09:40:45 UTC"
  },
  {
    "arxiv_id": "2505.00755v1",
    "title": "P2P-Insole: Human Pose Estimation Using Foot Pressure Distribution and Motion Sensors",
    "authors": [
      "Atsuya Watanabe",
      "Ratna Aisuwarya",
      "Lei Jing"
    ],
    "abstract": "This work presents P2P-Insole, a low-cost approach for estimating and\nvisualizing 3D human skeletal data using insole-type sensors integrated with\nIMUs. Each insole, fabricated with e-textile garment techniques, costs under\nUSD 1, making it significantly cheaper than commercial alternatives and ideal\nfor large-scale production. Our approach uses foot pressure distribution,\nacceleration, and rotation data to overcome limitations, providing a\nlightweight, minimally intrusive, and privacy-aware solution. The system\nemploys a Transformer model for efficient temporal feature extraction, enriched\nby first and second derivatives in the input stream. Including multimodal\ninformation, such as accelerometers and rotational measurements, improves the\naccuracy of complex motion pattern recognition. These facts are demonstrated\nexperimentally, while error metrics show the robustness of the approach in\nvarious posture estimation tasks. This work could be the foundation for a\nlow-cost, practical application in rehabilitation, injury prevention, and\nhealth monitoring while enabling further development through sensor\noptimization and expanded datasets.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.00755v1",
    "published_date": "2025-05-01 09:28:29 UTC",
    "updated_date": "2025-05-01 09:28:29 UTC"
  },
  {
    "arxiv_id": "2505.00416v1",
    "title": "ScaleTrack: Scaling and back-tracking Automated GUI Agents",
    "authors": [
      "Jing Huang",
      "Zhixiong Zeng",
      "Wenkang Han",
      "Yufeng Zhong",
      "Liming Zheng",
      "Shuai Fu",
      "Jingyuan Chen",
      "Lin Ma"
    ],
    "abstract": "Automated GUI agents aims to facilitate user interaction by automatically\nperforming complex tasks in digital environments, such as web, mobile, desktop\ndevices. It receives textual task instruction and GUI description to generate\nexecutable actions (\\emph{e.g.}, click) and operation boxes step by step.\nTraining a GUI agent mainly involves grounding and planning stages, in which\nthe GUI grounding focuses on finding the execution coordinates according to the\ntask, while the planning stage aims to predict the next action based on\nhistorical actions. However, previous work suffers from the limitations of\ninsufficient training data for GUI grounding, as well as the ignorance of\nbacktracking historical behaviors for GUI planning. To handle the above\nchallenges, we propose ScaleTrack, a training framework by scaling grounding\nand backtracking planning for automated GUI agents. We carefully collected GUI\nsamples of different synthesis criterions from a wide range of sources, and\nunified them into the same template for training GUI grounding models.\nMoreover, we design a novel training strategy that predicts the next action\nfrom the current GUI image, while also backtracking the historical actions that\nled to the GUI image. In this way, ScaleTrack explains the correspondence\nbetween GUI images and actions, which effectively describes the evolution rules\nof the GUI environment. Extensive experimental results demonstrate the\neffectiveness of ScaleTrack. Data and code will be available at url.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.00416v1",
    "published_date": "2025-05-01 09:27:13 UTC",
    "updated_date": "2025-05-01 09:27:13 UTC"
  },
  {
    "arxiv_id": "2505.01458v1",
    "title": "A Survey of Robotic Navigation and Manipulation with Physics Simulators in the Era of Embodied AI",
    "authors": [
      "Lik Hang Kenny Wong",
      "Xueyang Kang",
      "Kaixin Bai",
      "Jianwei Zhang"
    ],
    "abstract": "Navigation and manipulation are core capabilities in Embodied AI, yet\ntraining agents with these capabilities in the real world faces high costs and\ntime complexity. Therefore, sim-to-real transfer has emerged as a key approach,\nyet the sim-to-real gap persists. This survey examines how physics simulators\naddress this gap by analyzing their properties overlooked in previous surveys.\nWe also analyze their features for navigation and manipulation tasks, along\nwith hardware requirements. Additionally, we offer a resource with benchmark\ndatasets, metrics, simulation platforms, and cutting-edge methods-such as world\nmodels and geometric equivariance-to help researchers select suitable tools\nwhile accounting for hardware constraints.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.01458v1",
    "published_date": "2025-05-01 09:22:23 UTC",
    "updated_date": "2025-05-01 09:22:23 UTC"
  },
  {
    "arxiv_id": "2505.00409v1",
    "title": "Perceptual Implications of Automatic Anonymization in Pathological Speech",
    "authors": [
      "Soroosh Tayebi Arasteh",
      "Saba Afza",
      "Tri-Thien Nguyen",
      "Lukas Buess",
      "Maryam Parvin",
      "Tomas Arias-Vergara",
      "Paula Andrea Perez-Toro",
      "Hiu Ching Hung",
      "Mahshad Lotfinia",
      "Thomas Gorges",
      "Elmar Noeth",
      "Maria Schuster",
      "Seung Hee Yang",
      "Andreas Maier"
    ],
    "abstract": "Automatic anonymization techniques are essential for ethical sharing of\npathological speech data, yet their perceptual consequences remain\nunderstudied. This study presents the first comprehensive human-centered\nanalysis of anonymized pathological speech, using a structured perceptual\nprotocol involving ten native and non-native German listeners with diverse\nlinguistic, clinical, and technical backgrounds. Listeners evaluated\nanonymized-original utterance pairs from 180 speakers spanning Cleft Lip and\nPalate, Dysarthria, Dysglossia, Dysphonia, and age-matched healthy controls.\nSpeech was anonymized using state-of-the-art automatic methods (equal error\nrates in the range of 30-40%). Listeners completed Turing-style discrimination\nand quality rating tasks under zero-shot (single-exposure) and few-shot\n(repeated-exposure) conditions. Discrimination accuracy was high overall (91%\nzero-shot; 93% few-shot), but varied by disorder (repeated-measures ANOVA:\np=0.007), ranging from 96% (Dysarthria) to 86% (Dysphonia). Anonymization\nconsistently reduced perceived quality (from 83% to 59%, p<0.001), with\npathology-specific degradation patterns (one-way ANOVA: p=0.005). Native\nlisteners rated original speech slightly higher than non-native listeners\n(Delta=4%, p=0.199), but this difference nearly disappeared after anonymization\n(Delta=1%, p=0.724). No significant gender-based bias was observed. Critically,\nhuman perceptual outcomes did not correlate with automatic privacy or clinical\nutility metrics. These results underscore the need for listener-informed,\ndisorder- and context-specific anonymization strategies that preserve privacy\nwhile maintaining interpretability, communicative functions, and diagnostic\nutility, especially for vulnerable populations such as children.",
    "categories": [
      "eess.AS",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "eess.AS",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.00409v1",
    "published_date": "2025-05-01 09:03:03 UTC",
    "updated_date": "2025-05-01 09:03:03 UTC"
  },
  {
    "arxiv_id": "2505.00402v1",
    "title": "DeepSTA: A Spatial-Temporal Attention Network for Logistics Delivery Timely Rate Prediction in Anomaly Conditions",
    "authors": [
      "Jinhui Yi",
      "Huan Yan",
      "Haotian Wang",
      "Jian Yuan",
      "Yong Li"
    ],
    "abstract": "Prediction of couriers' delivery timely rates in advance is essential to the\nlogistics industry, enabling companies to take preemptive measures to ensure\nthe normal operation of delivery services. This becomes even more critical\nduring anomaly conditions like the epidemic outbreak, during which couriers'\ndelivery timely rate will decline markedly and fluctuates significantly.\nExisting studies pay less attention to the logistics scenario. Moreover, many\nworks focusing on prediction tasks in anomaly scenarios fail to explicitly\nmodel abnormal events, e.g., treating external factors equally with other\nfeatures, resulting in great information loss. Further, since some anomalous\nevents occur infrequently, traditional data-driven methods perform poorly in\nthese scenarios. To deal with them, we propose a deep spatial-temporal\nattention model, named DeepSTA. To be specific, to avoid information loss, we\ndesign an anomaly spatio-temporal learning module that employs a recurrent\nneural network to model incident information. Additionally, we utilize Node2vec\nto model correlations between road districts, and adopt graph neural networks\nand long short-term memory to capture the spatial-temporal dependencies of\ncouriers. To tackle the issue of insufficient training data in abnormal\ncircumstances, we propose an anomaly pattern attention module that adopts a\nmemory network for couriers' anomaly feature patterns storage via attention\nmechanisms. The experiments on real-world logistics datasets during the\nCOVID-19 outbreak in 2022 show the model outperforms the best baselines by\n12.11% in MAE and 13.71% in MSE, demonstrating its superior performance over\nmultiple competitive baselines.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted by CIKM 2023",
    "pdf_url": "http://arxiv.org/pdf/2505.00402v1",
    "published_date": "2025-05-01 08:48:45 UTC",
    "updated_date": "2025-05-01 08:48:45 UTC"
  },
  {
    "arxiv_id": "2505.00375v1",
    "title": "Learning to Estimate Package Delivery Time in Mixed Imbalanced Delivery and Pickup Logistics Services",
    "authors": [
      "Jinhui Yi",
      "Huan Yan",
      "Haotian Wang",
      "Jian Yuan",
      "Yong Li"
    ],
    "abstract": "Accurately estimating package delivery time is essential to the logistics\nindustry, which enables reasonable work allocation and on-time service\nguarantee. This becomes even more necessary in mixed logistics scenarios where\ncouriers handle a high volume of delivery and a smaller number of pickup\nsimultaneously. However, most of the related works treat the pickup and\ndelivery patterns on couriers' decision behavior equally, neglecting that the\npickup has a greater impact on couriers' decision-making compared to the\ndelivery due to its tighter time constraints. In such context, we have three\nmain challenges: 1) multiple spatiotemporal factors are intricately\ninterconnected, significantly affecting couriers' delivery behavior; 2) pickups\nhave stricter time requirements but are limited in number, making it\nchallenging to model their effects on couriers' delivery process; 3) couriers'\nspatial mobility patterns are critical determinants of their delivery behavior,\nbut have been insufficiently explored. To deal with these, we propose TransPDT,\na Transformer-based multi-task package delivery time prediction model. We first\nemploy the Transformer encoder architecture to capture the spatio-temporal\ndependencies of couriers' historical travel routes and pending package sets.\nThen we design the pattern memory to learn the patterns of pickup in the\nimbalanced dataset via attention mechanism. We also set the route prediction as\nan auxiliary task of delivery time prediction, and incorporate the prior\ncourier spatial movement regularities in prediction. Extensive experiments on\nreal industry-scale datasets demonstrate the superiority of our method. A\nsystem based on TransPDT is deployed internally in JD Logistics to track more\nthan 2000 couriers handling hundreds of thousands of packages per day in\nBeijing.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted by ACM SIGSPATIAL 2024",
    "pdf_url": "http://arxiv.org/pdf/2505.00375v1",
    "published_date": "2025-05-01 08:00:22 UTC",
    "updated_date": "2025-05-01 08:00:22 UTC"
  },
  {
    "arxiv_id": "2505.00368v1",
    "title": "Urban Air Mobility as a System of Systems: An LLM-Enhanced Holonic Approach",
    "authors": [
      "Ahmed R. Sadik",
      "Muhammad Ashfaq",
      "Niko Mäkitalo",
      "Tommi Mikkonen"
    ],
    "abstract": "Urban Air Mobility (UAM) is an emerging System of System (SoS) that faces\nchallenges in system architecture, planning, task management, and execution.\nTraditional architectural approaches struggle with scalability, adaptability,\nand seamless resource integration within dynamic and complex environments. This\npaper presents an intelligent holonic architecture that incorporates Large\nLanguage Model (LLM) to manage the complexities of UAM. Holons function semi\nautonomously, allowing for real time coordination among air taxis, ground\ntransport, and vertiports. LLMs process natural language inputs, generate\nadaptive plans, and manage disruptions such as weather changes or airspace\nclosures.Through a case study of multimodal transportation with electric\nscooters and air taxis, we demonstrate how this architecture enables dynamic\nresource allocation, real time replanning, and autonomous adaptation without\ncentralized control, creating more resilient and efficient urban transportation\nnetworks. By advancing decentralized control and AI driven adaptability, this\nwork lays the groundwork for resilient, human centric UAM ecosystems, with\nfuture efforts targeting hybrid AI integration and real world validation.",
    "categories": [
      "cs.AI",
      "cs.ET",
      "cs.MA",
      "cs.RO"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.00368v1",
    "published_date": "2025-05-01 07:39:11 UTC",
    "updated_date": "2025-05-01 07:39:11 UTC"
  },
  {
    "arxiv_id": "2505.00367v1",
    "title": "KoACD: The First Korean Adolescent Dataset for Cognitive Distortion Analysis",
    "authors": [
      "JunSeo Kim",
      "HyeHyeon Kim"
    ],
    "abstract": "Cognitive distortion refers to negative thinking patterns that can lead to\nmental health issues like depression and anxiety in adolescents. Previous\nstudies using natural language processing (NLP) have focused mainly on\nsmall-scale adult datasets, with limited research on adolescents. This study\nintroduces KoACD, the first large-scale dataset of cognitive distortions in\nKorean adolescents, containing 108,717 instances. We applied a multi-Large\nLanguage Model (LLM) negotiation method to refine distortion classification and\ngenerate synthetic data using two approaches: cognitive clarification for\ntextual clarity and cognitive balancing for diverse distortion representation.\nValidation through LLMs and expert evaluations showed that while LLMs\nclassified distortions with explicit markers, they struggled with\ncontext-dependent reasoning, where human evaluators demonstrated higher\naccuracy. KoACD aims to enhance future research on cognitive distortion\ndetection.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.00367v1",
    "published_date": "2025-05-01 07:37:18 UTC",
    "updated_date": "2025-05-01 07:37:18 UTC"
  },
  {
    "arxiv_id": "2505.00365v1",
    "title": "SacFL: Self-Adaptive Federated Continual Learning for Resource-Constrained End Devices",
    "authors": [
      "Zhengyi Zhong",
      "Weidong Bao",
      "Ji Wang",
      "Jianguo Chen",
      "Lingjuan Lyu",
      "Wei Yang Bryan Lim"
    ],
    "abstract": "The proliferation of end devices has led to a distributed computing paradigm,\nwherein on-device machine learning models continuously process diverse data\ngenerated by these devices. The dynamic nature of this data, characterized by\ncontinuous changes or data drift, poses significant challenges for on-device\nmodels. To address this issue, continual learning (CL) is proposed, enabling\nmachine learning models to incrementally update their knowledge and mitigate\ncatastrophic forgetting. However, the traditional centralized approach to CL is\nunsuitable for end devices due to privacy and data volume concerns. In this\ncontext, federated continual learning (FCL) emerges as a promising solution,\npreserving user data locally while enhancing models through collaborative\nupdates. Aiming at the challenges of limited storage resources for CL, poor\nautonomy in task shift detection, and difficulty in coping with new adversarial\ntasks in FCL scenario, we propose a novel FCL framework named SacFL. SacFL\nemploys an Encoder-Decoder architecture to separate task-robust and\ntask-sensitive components, significantly reducing storage demands by retaining\nlightweight task-sensitive components for resource-constrained end devices.\nMoreover, $\\rm{SacFL}$ leverages contrastive learning to introduce an\nautonomous data shift detection mechanism, enabling it to discern whether a new\ntask has emerged and whether it is a benign task. This capability ultimately\nallows the device to autonomously trigger CL or attack defense strategy without\nadditional information, which is more practical for end devices. Comprehensive\nexperiments conducted on multiple text and image datasets, such as Cifar100 and\nTHUCNews, have validated the effectiveness of $\\rm{SacFL}$ in both\nclass-incremental and domain-incremental scenarios. Furthermore, a demo system\nhas been developed to verify its practicality.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted by TNNLS 2025",
    "pdf_url": "http://arxiv.org/pdf/2505.00365v1",
    "published_date": "2025-05-01 07:26:35 UTC",
    "updated_date": "2025-05-01 07:26:35 UTC"
  },
  {
    "arxiv_id": "2505.00359v1",
    "title": "TNStream: Applying Tightest Neighbors to Micro-Clusters to Define Multi-Density Clusters in Streaming Data",
    "authors": [
      "Qifen Zeng",
      "Haomin Bao",
      "Yuanzhuo Hu",
      "Zirui Zhang",
      "Yuheng Zheng",
      "Luosheng Wen"
    ],
    "abstract": "In data stream clustering, systematic theory of stream clustering algorithms\nremains relatively scarce. Recently, density-based methods have gained\nattention. However, existing algorithms struggle to simultaneously handle\narbitrarily shaped, multi-density, high-dimensional data while maintaining\nstrong outlier resistance. Clustering quality significantly deteriorates when\ndata density varies complexly. This paper proposes a clustering algorithm based\non the novel concept of Tightest Neighbors and introduces a data stream\nclustering theory based on the Skeleton Set. Based on these theories, this\npaper develops a new method, TNStream, a fully online algorithm. The algorithm\nadaptively determines the clustering radius based on local similarity,\nsummarizing the evolution of multi-density data streams in micro-clusters. It\nthen applies a Tightest Neighbors-based clustering algorithm to form final\nclusters. To improve efficiency in high-dimensional cases, Locality-Sensitive\nHashing (LSH) is employed to structure micro-clusters, addressing the challenge\nof storing k-nearest neighbors. TNStream is evaluated on various synthetic and\nreal-world datasets using different clustering metrics. Experimental results\ndemonstrate its effectiveness in improving clustering quality for multi-density\ndata and validate the proposed data stream clustering theory.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.NE",
      "68T05, 68W20",
      "H.2.8; I.5.3"
    ],
    "primary_category": "cs.LG",
    "comment": "21 pages, 9 figures, 8 tables, under review at Expert Systems with\n  Applications (ESWA)",
    "pdf_url": "http://arxiv.org/pdf/2505.00359v1",
    "published_date": "2025-05-01 07:15:20 UTC",
    "updated_date": "2025-05-01 07:15:20 UTC"
  },
  {
    "arxiv_id": "2505.00358v1",
    "title": "R&B: Domain Regrouping and Data Mixture Balancing for Efficient Foundation Model Training",
    "authors": [
      "Albert Ge",
      "Tzu-Heng Huang",
      "John Cooper",
      "Avi Trost",
      "Ziyi Chu",
      "Satya Sai Srinath Namburi GNVV",
      "Ziyang Cai",
      "Kendall Park",
      "Nicholas Roberts",
      "Frederic Sala"
    ],
    "abstract": "Data mixing strategies have successfully reduced the costs involved in\ntraining language models. While promising, such methods suffer from two flaws.\nFirst, they rely on predetermined data domains (e.g., data sources, task\ntypes), which may fail to capture critical semantic nuances, leaving\nperformance on the table. Second, these methods scale with the number of\ndomains in a computationally prohibitive way. We address these challenges via\nR&B, a framework that re-partitions training data based on semantic similarity\n(Regroup) to create finer-grained domains, and efficiently optimizes the data\ncomposition (Balance) by leveraging a Gram matrix induced by domain gradients\nobtained throughout training. Unlike prior works, it removes the need for\nadditional compute to obtain evaluation information such as losses or\ngradients. We analyze this technique under standard regularity conditions and\nprovide theoretical insights that justify R&B's effectiveness compared to\nnon-adaptive mixing approaches. Empirically, we demonstrate the effectiveness\nof R&B on five diverse datasets ranging from natural language to reasoning and\nmultimodal tasks. With as little as 0.01% additional compute overhead, R&B\nmatches or exceeds the performance of state-of-the-art data mixing strategies.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.00358v1",
    "published_date": "2025-05-01 07:08:19 UTC",
    "updated_date": "2025-05-01 07:08:19 UTC"
  },
  {
    "arxiv_id": "2505.00350v1",
    "title": "Optimizing Deep Neural Networks using Safety-Guided Self Compression",
    "authors": [
      "Mohammad Zbeeb",
      "Mariam Salman",
      "Mohammad Bazzi",
      "Ammar Mohanna"
    ],
    "abstract": "The deployment of deep neural networks on resource-constrained devices\nnecessitates effective model com- pression strategies that judiciously balance\nthe reduction of model size with the preservation of performance. This study\nintroduces a novel safety-driven quantization framework that leverages\npreservation sets to systematically prune and quantize neural network weights,\nthereby optimizing model complexity without compromising accuracy. The proposed\nmethodology is rigorously evaluated on both a convolutional neural network\n(CNN) and an attention-based language model, demonstrating its applicability\nacross diverse architectural paradigms. Experimental results reveal that our\nframework achieves up to a 2.5% enhancement in test accuracy relative to the\noriginal unquantized models while maintaining 60% of the initial model size. In\ncomparison to conventional quantization techniques, our approach not only\naugments generalization by eliminating parameter noise and retaining essential\nweights but also reduces variance, thereby ensuring the retention of critical\nmodel features. These findings underscore the efficacy of safety-driven\nquantization as a robust and reliable strategy for the efficient optimization\nof deep learn- ing models. The implementation and comprehensive experimental\nevaluations of our framework are publicly accessible at GitHub.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "A Preprint",
    "pdf_url": "http://arxiv.org/pdf/2505.00350v1",
    "published_date": "2025-05-01 06:50:30 UTC",
    "updated_date": "2025-05-01 06:50:30 UTC"
  },
  {
    "arxiv_id": "2505.00347v1",
    "title": "Pushing the Limits of Low-Bit Optimizers: A Focus on EMA Dynamics",
    "authors": [
      "Cong Xu",
      "Wenbin Liang",
      "Mo Yu",
      "Anan Liu",
      "Ke-Yue Zhang",
      "Lizhuang Ma",
      "Jianyong Wang",
      "Jun Wang",
      "Wei Zhang"
    ],
    "abstract": "The explosion in model sizes leads to continued growth in prohibitive\ntraining/fine-tuning costs, particularly for stateful optimizers which maintain\nauxiliary information of even 2x the model size to achieve optimal convergence.\nWe therefore present in this work a novel type of optimizer that carries with\nextremely lightweight state overloads, achieved through ultra-low-precision\nquantization. While previous efforts have achieved certain success with 8-bit\nor 4-bit quantization, our approach enables optimizers to operate at precision\nas low as 3 bits, or even 2 bits per state element. This is accomplished by\nidentifying and addressing two critical challenges: the signal swamping problem\nin unsigned quantization that results in unchanged state dynamics, and the\nrapidly increased gradient variance in signed quantization that leads to\nincorrect descent directions. The theoretical analysis suggests a tailored\nlogarithmic quantization for the former and a precision-specific momentum value\nfor the latter. Consequently, the proposed SOLO achieves substantial memory\nsavings (approximately 45 GB when training a 7B model) with minimal accuracy\nloss. We hope that SOLO can contribute to overcoming the bottleneck in\ncomputational resources, thereby promoting greater accessibility in fundamental\nresearch.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "27 pages",
    "pdf_url": "http://arxiv.org/pdf/2505.00347v1",
    "published_date": "2025-05-01 06:47:45 UTC",
    "updated_date": "2025-05-01 06:47:45 UTC"
  },
  {
    "arxiv_id": "2505.00339v1",
    "title": "Enhancing AI-Driven Education: Integrating Cognitive Frameworks, Linguistic Feedback Analysis, and Ethical Considerations for Improved Content Generation",
    "authors": [
      "Antoun Yaacoub",
      "Sansiri Tarnpradab",
      "Phattara Khumprom",
      "Zainab Assaghir",
      "Lionel Prevost",
      "Jérôme Da-Rugna"
    ],
    "abstract": "Artificial intelligence (AI) is rapidly transforming education, presenting\nunprecedented opportunities for personalized learning and streamlined content\ncreation. However, realizing the full potential of AI in educational settings\nnecessitates careful consideration of the quality, cognitive depth, and ethical\nimplications of AI-generated materials. This paper synthesizes insights from\nfour related studies to propose a comprehensive framework for enhancing\nAI-driven educational tools. We integrate cognitive assessment frameworks\n(Bloom's Taxonomy and SOLO Taxonomy), linguistic analysis of AI-generated\nfeedback, and ethical design principles to guide the development of effective\nand responsible AI tools. We outline a structured three-phase approach\nencompassing cognitive alignment, linguistic feedback integration, and ethical\nsafeguards. The practical application of this framework is demonstrated through\nits integration into OneClickQuiz, an AI-powered Moodle plugin for quiz\ngeneration. This work contributes a comprehensive and actionable guide for\neducators, researchers, and developers aiming to harness AI's potential while\nupholding pedagogical and ethical standards in educational content generation.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "This article will be presented in IJCNN 2025 \"AI Innovations for\n  Education: Transforming Teaching and Learning through Cutting-Edge\n  Technologies\" workshop",
    "pdf_url": "http://arxiv.org/pdf/2505.00339v1",
    "published_date": "2025-05-01 06:36:21 UTC",
    "updated_date": "2025-05-01 06:36:21 UTC"
  },
  {
    "arxiv_id": "2505.00337v1",
    "title": "T2VPhysBench: A First-Principles Benchmark for Physical Consistency in Text-to-Video Generation",
    "authors": [
      "Xuyang Guo",
      "Jiayan Huo",
      "Zhenmei Shi",
      "Zhao Song",
      "Jiahao Zhang",
      "Jiale Zhao"
    ],
    "abstract": "Text-to-video generative models have made significant strides in recent\nyears, producing high-quality videos that excel in both aesthetic appeal and\naccurate instruction following, and have become central to digital art creation\nand user engagement online. Yet, despite these advancements, their ability to\nrespect fundamental physical laws remains largely untested: many outputs still\nviolate basic constraints such as rigid-body collisions, energy conservation,\nand gravitational dynamics, resulting in unrealistic or even misleading\ncontent. Existing physical-evaluation benchmarks typically rely on automatic,\npixel-level metrics applied to simplistic, life-scenario prompts, and thus\noverlook both human judgment and first-principles physics. To fill this gap, we\nintroduce \\textbf{T2VPhysBench}, a first-principled benchmark that\nsystematically evaluates whether state-of-the-art text-to-video systems, both\nopen-source and commercial, obey twelve core physical laws including Newtonian\nmechanics, conservation principles, and phenomenological effects. Our benchmark\nemploys a rigorous human evaluation protocol and includes three targeted\nstudies: (1) an overall compliance assessment showing that all models score\nbelow 0.60 on average in each law category; (2) a prompt-hint ablation\nrevealing that even detailed, law-specific hints fail to remedy physics\nviolations; and (3) a counterfactual robustness test demonstrating that models\noften generate videos that explicitly break physical rules when so instructed.\nThe results expose persistent limitations in current architectures and offer\nconcrete insights for guiding future research toward truly physics-aware video\ngeneration.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.00337v1",
    "published_date": "2025-05-01 06:34:55 UTC",
    "updated_date": "2025-05-01 06:34:55 UTC"
  },
  {
    "arxiv_id": "2505.00335v1",
    "title": "Efficient Neural Video Representation with Temporally Coherent Modulation",
    "authors": [
      "Seungjun Shin",
      "Suji Kim",
      "Dokwan Oh"
    ],
    "abstract": "Implicit neural representations (INR) has found successful applications\nacross diverse domains. To employ INR in real-life, it is important to speed up\ntraining. In the field of INR for video applications, the state-of-the-art\napproach employs grid-type parametric encoding and successfully achieves a\nfaster encoding speed in comparison to its predecessors. However, the grid\nusage, which does not consider the video's dynamic nature, leads to redundant\nuse of trainable parameters. As a result, it has significantly lower parameter\nefficiency and higher bitrate compared to NeRV-style methods that do not use a\nparametric encoding. To address the problem, we propose Neural Video\nrepresentation with Temporally coherent Modulation (NVTM), a novel framework\nthat can capture dynamic characteristics of video. By decomposing the\nspatio-temporal 3D video data into a set of 2D grids with flow information,\nNVTM enables learning video representation rapidly and uses parameter\nefficiently. Our framework enables to process temporally corresponding pixels\nat once, resulting in the fastest encoding speed for a reasonable video\nquality, especially when compared to the NeRV-style method, with a speed\nincrease of over 3 times. Also, it remarks an average of 1.54dB/0.019\nimprovements in PSNR/LPIPS on UVG (Dynamic) (even with 10% fewer parameters)\nand an average of 1.84dB/0.013 improvements in PSNR/LPIPS on MCL-JCV (Dynamic),\ncompared to previous grid-type works. By expanding this to compression tasks,\nwe demonstrate comparable performance to video compression standards (H.264,\nHEVC) and recent INR approaches for video compression. Additionally, we perform\nextensive experiments demonstrating the superior performance of our algorithm\nacross diverse tasks, encompassing super resolution, frame interpolation and\nvideo inpainting. Project page is https://sujiikim.github.io/NVTM/.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "ECCV 2024",
    "pdf_url": "http://arxiv.org/pdf/2505.00335v1",
    "published_date": "2025-05-01 06:20:42 UTC",
    "updated_date": "2025-05-01 06:20:42 UTC"
  },
  {
    "arxiv_id": "2505.00325v1",
    "title": "CognitionNet: A Collaborative Neural Network for Play Style Discovery in Online Skill Gaming Platform",
    "authors": [
      "Rukma Talwadker",
      "Surajit Chakrabarty",
      "Aditya Pareek",
      "Tridib Mukherjee",
      "Deepak Saini"
    ],
    "abstract": "Games are one of the safest source of realizing self-esteem and relaxation at\nthe same time. An online gaming platform typically has massive data coming in,\ne.g., in-game actions, player moves, clickstreams, transactions etc. It is\nrather interesting, as something as simple as data on gaming moves can help\ncreate a psychological imprint of the user at that moment, based on her\nimpulsive reactions and response to a situation in the game. Mining this\nknowledge can: (a) immediately help better explain observed and predicted\nplayer behavior; and (b) consequently propel deeper understanding towards\nplayers' experience, growth and protection. To this effect, we focus on\ndiscovery of the \"game behaviours\" as micro-patterns formed by continuous\nsequence of games and the persistent \"play styles\" of the players' as a\nsequence of such sequences on an online skill gaming platform for Rummy. We\npropose a two stage deep neural network, CognitionNet. The first stage focuses\non mining game behaviours as cluster representations in a latent space while\nthe second aggregates over these micro patterns to discover play styles via a\nsupervised classification objective around player engagement. The dual\nobjective allows CognitionNet to reveal several player psychology inspired\ndecision making and tactics. To our knowledge, this is the first and\none-of-its-kind research to fully automate the discovery of: (i) player\npsychology and game tactics from telemetry data; and (ii) relevant diagnostic\nexplanations to players' engagement predictions. The collaborative training of\nthe two networks with differential input dimensions is enabled using a novel\nformulation of \"bridge loss\". The network plays pivotal role in obtaining\nhomogeneous and consistent play style definitions and significantly outperforms\nthe SOTA baselines wherever applicable.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.00325v1",
    "published_date": "2025-05-01 05:51:19 UTC",
    "updated_date": "2025-05-01 05:51:19 UTC"
  },
  {
    "arxiv_id": "2505.00322v1",
    "title": "AI2-Active Safety: AI-enabled Interaction-aware Active Safety Analysis with Vehicle Dynamics",
    "authors": [
      "Keshu Wu",
      "Zihao Li",
      "Sixu Li",
      "Xinyue Ye",
      "Dominique Lord",
      "Yang Zhou"
    ],
    "abstract": "This paper introduces an AI-enabled, interaction-aware active safety analysis\nframework that accounts for groupwise vehicle interactions. Specifically, the\nframework employs a bicycle model-augmented with road gradient\nconsiderations-to accurately capture vehicle dynamics. In parallel, a\nhypergraph-based AI model is developed to predict probabilistic trajectories of\nambient traffic. By integrating these two components, the framework derives\nvehicle intra-spacing over a 3D road surface as the solution of a stochastic\nordinary differential equation, yielding high-fidelity surrogate safety\nmeasures such as time-to-collision (TTC). To demonstrate its effectiveness, the\nframework is analyzed using stochastic numerical methods comprising 4th-order\nRunge-Kutta integration and AI inference, generating probability-weighted\nhigh-fidelity TTC (HF-TTC) distributions that reflect complex multi-agent\nmaneuvers and behavioral uncertainties. Evaluated with HF-TTC against\ntraditional constant-velocity TTC and non-interaction-aware approaches on\nhighway datasets, the proposed framework offers a systematic methodology for\nactive safety analysis with enhanced potential for improving safety perception\nin complex traffic environments.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.00322v1",
    "published_date": "2025-05-01 05:46:34 UTC",
    "updated_date": "2025-05-01 05:46:34 UTC"
  },
  {
    "arxiv_id": "2505.00316v2",
    "title": "Surrogate modeling of Cellular-Potts Agent-Based Models as a segmentation task using the U-Net neural network architecture",
    "authors": [
      "Tien Comlekoglu",
      "J. Quetzalcóatl Toledo-Marín",
      "Tina Comlekoglu",
      "Douglas W. DeSimone",
      "Shayn M. Peirce",
      "Geoffrey Fox",
      "James A. Glazier"
    ],
    "abstract": "The Cellular-Potts model is a powerful and ubiquitous framework for\ndeveloping computational models for simulating complex multicellular biological\nsystems. Cellular-Potts models (CPMs) are often computationally expensive due\nto the explicit modeling of interactions among large numbers of individual\nmodel agents and diffusive fields described by partial differential equations\n(PDEs). In this work, we develop a convolutional neural network (CNN) surrogate\nmodel using a U-Net architecture that accounts for periodic boundary\nconditions. We use this model to accelerate the evaluation of a mechanistic CPM\npreviously used to investigate \\textit{in vitro} vasculogenesis. The surrogate\nmodel was trained to predict 100 computational steps ahead (Monte-Carlo steps,\nMCS), accelerating simulation evaluations by a factor of 590 times compared to\nCPM code execution. Over multiple recursive evaluations, our model effectively\ncaptures the emergent behaviors demonstrated by the original Cellular-Potts\nmodel of such as vessel sprouting, extension and anastomosis, and contraction\nof vascular lacunae. This approach demonstrates the potential for deep learning\nto serve as efficient surrogate models for CPM simulations, enabling faster\nevaluation of computationally expensive CPM of biological processes at greater\nspatial and temporal scales.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "q-bio.QM"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.00316v2",
    "published_date": "2025-05-01 05:30:38 UTC",
    "updated_date": "2025-05-05 15:26:29 UTC"
  },
  {
    "arxiv_id": "2505.00752v2",
    "title": "DARTer: Dynamic Adaptive Representation Tracker for Nighttime UAV Tracking",
    "authors": [
      "Xuzhao Li",
      "Xuchen Li",
      "Shiyu Hu"
    ],
    "abstract": "Nighttime UAV tracking presents significant challenges due to extreme\nillumination variations and viewpoint changes, which severely degrade tracking\nperformance. Existing approaches either rely on light enhancers with high\ncomputational costs or introduce redundant domain adaptation mechanisms,\nfailing to fully utilize the dynamic features in varying perspectives. To\naddress these issues, we propose \\textbf{DARTer} (\\textbf{D}ynamic\n\\textbf{A}daptive \\textbf{R}epresentation \\textbf{T}racker), an end-to-end\ntracking framework designed for nighttime UAV scenarios. DARTer leverages a\nDynamic Feature Blender (DFB) to effectively fuse multi-perspective nighttime\nfeatures from static and dynamic templates, enhancing representation\nrobustness. Meanwhile, a Dynamic Feature Activator (DFA) adaptively activates\nVision Transformer layers based on extracted features, significantly improving\nefficiency by reducing redundant computations. Our model eliminates the need\nfor complex multi-task loss functions, enabling a streamlined training process.\nExtensive experiments on multiple nighttime UAV tracking benchmarks demonstrate\nthe superiority of DARTer over state-of-the-art trackers. These results confirm\nthat DARTer effectively balances tracking accuracy and efficiency, making it a\npromising solution for real-world nighttime UAV tracking applications.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Preprint, Under review",
    "pdf_url": "http://arxiv.org/pdf/2505.00752v2",
    "published_date": "2025-05-01 05:24:14 UTC",
    "updated_date": "2025-05-16 04:42:12 UTC"
  },
  {
    "arxiv_id": "2505.00308v2",
    "title": "AI-Assisted Decision-Making for Clinical Assessment of Auto-Segmented Contour Quality",
    "authors": [
      "Biling Wang",
      "Austen Maniscalco",
      "Ti Bai",
      "Siqiu Wang",
      "Michael Dohopolski",
      "Mu-Han Lin",
      "Chenyang Shen",
      "Dan Nguyen",
      "Junzhou Huang",
      "Steve Jiang",
      "Xinlei Wang"
    ],
    "abstract": "Purpose: This study presents a Deep Learning (DL)-based quality assessment\n(QA) approach for evaluating auto-generated contours (auto-contours) in\nradiotherapy, with emphasis on Online Adaptive Radiotherapy (OART). Leveraging\nBayesian Ordinal Classification (BOC) and calibrated uncertainty thresholds,\nthe method enables confident QA predictions without relying on ground truth\ncontours or extensive manual labeling. Methods: We developed a BOC model to\nclassify auto-contour quality and quantify prediction uncertainty. A\ncalibration step was used to optimize uncertainty thresholds that meet clinical\naccuracy needs. The method was validated under three data scenarios: no manual\nlabels, limited labels, and extensive labels. For rectum contours in prostate\ncancer, we applied geometric surrogate labels when manual labels were absent,\ntransfer learning when limited, and direct supervision when ample labels were\navailable. Results: The BOC model delivered robust performance across all\nscenarios. Fine-tuning with just 30 manual labels and calibrating with 34\nsubjects yielded over 90% accuracy on test data. Using the calibrated\nthreshold, over 93% of the auto-contours' qualities were accurately predicted\nin over 98% of cases, reducing unnecessary manual reviews and highlighting\ncases needing correction. Conclusion: The proposed QA model enhances contouring\nefficiency in OART by reducing manual workload and enabling fast, informed\nclinical decisions. Through uncertainty quantification, it ensures safer, more\nreliable radiotherapy workflows.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "stat.AP"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.00308v2",
    "published_date": "2025-05-01 05:05:35 UTC",
    "updated_date": "2025-05-11 20:02:58 UTC"
  },
  {
    "arxiv_id": "2505.00295v1",
    "title": "Fine-grained spatial-temporal perception for gas leak segmentation",
    "authors": [
      "Xinlong Zhao",
      "Shan Du"
    ],
    "abstract": "Gas leaks pose significant risks to human health and the environment. Despite\nlong-standing concerns, there are limited methods that can efficiently and\naccurately detect and segment leaks due to their concealed appearance and\nrandom shapes. In this paper, we propose a Fine-grained Spatial-Temporal\nPerception (FGSTP) algorithm for gas leak segmentation. FGSTP captures critical\nmotion clues across frames and integrates them with refined object features in\nan end-to-end network. Specifically, we first construct a correlation volume to\ncapture motion information between consecutive frames. Then, the fine-grained\nperception progressively refines the object-level features using previous\noutputs. Finally, a decoder is employed to optimize boundary segmentation.\nBecause there is no highly precise labeled dataset for gas leak segmentation,\nwe manually label a gas leak video dataset, GasVid. Experimental results on\nGasVid demonstrate that our model excels in segmenting non-rigid objects such\nas gas leaks, generating the most accurate mask compared to other\nstate-of-the-art (SOTA) models.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "68T45 (Primary), 68T07 (Secondary)",
      "I.2.10; I.4.6"
    ],
    "primary_category": "cs.CV",
    "comment": "6 pages, 4 figures, ICIP 2025 Conference",
    "pdf_url": "http://arxiv.org/pdf/2505.00295v1",
    "published_date": "2025-05-01 04:35:57 UTC",
    "updated_date": "2025-05-01 04:35:57 UTC"
  },
  {
    "arxiv_id": "2505.00290v1",
    "title": "Multi-Hierarchical Fine-Grained Feature Mapping Driven by Feature Contribution for Molecular Odor Prediction",
    "authors": [
      "Hong Xin Xie",
      "Jian De Sun",
      "Fan Fu Xue",
      "Zi Fei Han",
      "Shan Shan Feng",
      "Qi Chen"
    ],
    "abstract": "Molecular odor prediction is the process of using a molecule's structure to\npredict its smell. While accurate prediction remains challenging, AI models can\nsuggest potential odors. Existing methods, however, often rely on basic\ndescriptors or handcrafted fingerprints, which lack expressive power and hinder\neffective learning. Furthermore, these methods suffer from severe class\nimbalance, limiting the training effectiveness of AI models. To address these\nchallenges, we propose a Feature Contribution-driven Hierarchical Multi-Feature\nMapping Network (HMFNet). Specifically, we introduce a fine-grained, Local\nMulti-Hierarchy Feature Extraction module (LMFE) that performs deep feature\nextraction at the atomic level, capturing detailed features crucial for odor\nprediction. To enhance the extraction of discriminative atomic features, we\nintegrate a Harmonic Modulated Feature Mapping (HMFM). This module dynamically\nlearns feature importance and frequency modulation, improving the model's\ncapability to capture relevant patterns. Additionally, a Global Multi-Hierarchy\nFeature Extraction module (GMFE) is designed to learn global features from the\nmolecular graph topology, enabling the model to fully leverage global\ninformation and enhance its discriminative power for odor prediction. To\nfurther mitigate the issue of class imbalance, we propose a Chemically-Informed\nLoss (CIL). Experimental results demonstrate that our approach significantly\nimproves performance across various deep learning models, highlighting its\npotential to advance molecular structure representation and accelerate the\ndevelopment of AI-driven technologies.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.00290v1",
    "published_date": "2025-05-01 04:26:31 UTC",
    "updated_date": "2025-05-01 04:26:31 UTC"
  },
  {
    "arxiv_id": "2505.00284v1",
    "title": "LightEMMA: Lightweight End-to-End Multimodal Model for Autonomous Driving",
    "authors": [
      "Zhijie Qiao",
      "Haowei Li",
      "Zhong Cao",
      "Henry X. Liu"
    ],
    "abstract": "Vision-Language Models (VLMs) have demonstrated significant potential for\nend-to-end autonomous driving. However, fully exploiting their capabilities for\nsafe and reliable vehicle control remains an open research challenge. To\nsystematically examine advances and limitations of VLMs in driving tasks, we\nintroduce LightEMMA, a Lightweight End-to-End Multimodal Model for Autonomous\ndriving. LightEMMA provides a unified, VLM-based autonomous driving framework\nwithout ad hoc customizations, enabling easy integration and evaluation of\nevolving state-of-the-art commercial and open-source models. We construct\ntwelve autonomous driving agents using various VLMs and evaluate their\nperformance on the nuScenes prediction task, comprehensively assessing metrics\nsuch as inference time, computational cost, and predictive accuracy.\nIllustrative examples highlight that, despite their strong scenario\ninterpretation capabilities, VLMs' practical performance in autonomous driving\ntasks remains concerning, emphasizing the need for further improvements. The\ncode is available at https://github.com/michigan-traffic-lab/LightEMMA.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.00284v1",
    "published_date": "2025-05-01 04:12:41 UTC",
    "updated_date": "2025-05-01 04:12:41 UTC"
  },
  {
    "arxiv_id": "2505.00278v1",
    "title": "DeCo: Defect-Aware Modeling with Contrasting Matching for Optimizing Task Assignment in Online IC Testing",
    "authors": [
      "Lo Pang-Yun Ting",
      "Yu-Hao Chiang",
      "Yi-Tung Tsai",
      "Hsu-Chao Lai",
      "Kun-Ta Chuang"
    ],
    "abstract": "In the semiconductor industry, integrated circuit (IC) processes play a vital\nrole, as the rising complexity and market expectations necessitate improvements\nin yield. Identifying IC defects and assigning IC testing tasks to the right\nengineers improves efficiency and reduces losses. While current studies\nemphasize fault localization or defect classification, they overlook the\nintegration of defect characteristics, historical failures, and the insights\nfrom engineer expertise, which restrains their effectiveness in improving IC\nhandling. To leverage AI for these challenges, we propose DeCo, an innovative\napproach for optimizing task assignment in IC testing. DeCo constructs a novel\ndefect-aware graph from IC testing reports, capturing co-failure relationships\nto enhance defect differentiation, even with scarce defect data. Additionally,\nit formulates defect-aware representations for engineers and tasks, reinforced\nby local and global structure modeling on the defect-aware graph. Finally, a\ncontrasting-based assignment mechanism pairs testing tasks with QA engineers by\nconsidering their skill level and current workload, thus promoting an equitable\nand efficient job dispatch. Experiments on a real-world dataset demonstrate\nthat DeCo achieves the highest task-handling success rates in different\nscenarios, exceeding 80\\%, while also maintaining balanced workloads on both\nscarce or expanded defect data. Moreover, case studies reveal that DeCo can\nassign tasks to potentially capable engineers, even for their unfamiliar\ndefects, highlighting its potential as an AI-driven solution for the real-world\nIC failure analysis and task handling.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.00278v1",
    "published_date": "2025-05-01 04:01:14 UTC",
    "updated_date": "2025-05-01 04:01:14 UTC"
  },
  {
    "arxiv_id": "2505.00268v1",
    "title": "Consistency in Language Models: Current Landscape, Challenges, and Future Directions",
    "authors": [
      "Jekaterina Novikova",
      "Carol Anderson",
      "Borhane Blili-Hamelin",
      "Subhabrata Majumdar"
    ],
    "abstract": "The hallmark of effective language use lies in consistency -- expressing\nsimilar meanings in similar contexts and avoiding contradictions. While human\ncommunication naturally demonstrates this principle, state-of-the-art language\nmodels struggle to maintain reliable consistency across different scenarios.\nThis paper examines the landscape of consistency research in AI language\nsystems, exploring both formal consistency (including logical rule adherence)\nand informal consistency (such as moral and factual coherence). We analyze\ncurrent approaches to measure aspects of consistency, identify critical\nresearch gaps in standardization of definitions, multilingual assessment, and\nmethods to improve consistency. Our findings point to an urgent need for robust\nbenchmarks to measure and interdisciplinary approaches to ensure consistency in\nthe application of language models on domain-specific tasks while preserving\nthe utility and adaptability.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.00268v1",
    "published_date": "2025-05-01 03:25:25 UTC",
    "updated_date": "2025-05-01 03:25:25 UTC"
  },
  {
    "arxiv_id": "2505.00259v1",
    "title": "Pack-PTQ: Advancing Post-training Quantization of Neural Networks by Pack-wise Reconstruction",
    "authors": [
      "Changjun Li",
      "Runqing Jiang",
      "Zhuo Song",
      "Pengpeng Yu",
      "Ye Zhang",
      "Yulan Guo"
    ],
    "abstract": "Post-training quantization (PTQ) has evolved as a prominent solution for\ncompressing complex models, which advocates a small calibration dataset and\navoids end-to-end retraining. However, most existing PTQ methods employ\nblock-wise reconstruction, which neglects cross-block dependency and exhibits a\nnotable accuracy drop in low-bit cases. To address these limitations, this\npaper presents a novel PTQ method, dubbed Pack-PTQ. First, we design a\nHessian-guided adaptive packing mechanism to partition blocks into\nnon-overlapping packs, which serve as the base unit for reconstruction, thereby\npreserving the cross-block dependency and enabling accurate quantization\nparameters estimation. Second, based on the pack configuration, we propose a\nmixed-precision quantization approach to assign varied bit-widths to packs\naccording to their distinct sensitivities, thereby further enhancing\nperformance. Extensive experiments on 2D image and 3D point cloud\nclassification tasks, using various network architectures, demonstrate the\nsuperiority of our method over the state-of-the-art PTQ methods.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.00259v1",
    "published_date": "2025-05-01 02:53:46 UTC",
    "updated_date": "2025-05-01 02:53:46 UTC"
  },
  {
    "arxiv_id": "2505.00254v3",
    "title": "Empowering Agentic Video Analytics Systems with Video Language Models",
    "authors": [
      "Yuxuan Yan",
      "Shiqi Jiang",
      "Ting Cao",
      "Yifan Yang",
      "Qianqian Yang",
      "Yuanchao Shu",
      "Yuqing Yang",
      "Lili Qiu"
    ],
    "abstract": "AI-driven video analytics has become increasingly pivotal across diverse\ndomains. However, existing systems are often constrained to specific,\npredefined tasks, limiting their adaptability in open-ended analytical\nscenarios. The recent emergence of Video-Language Models (VLMs) as\ntransformative technologies offers significant potential for enabling\nopen-ended video understanding, reasoning, and analytics. Nevertheless, their\nlimited context windows present challenges when processing ultra-long video\ncontent, which is prevalent in real-world applications. To address this, we\nintroduce AVAS, a VLM-powered system designed for open-ended, advanced video\nanalytics. AVAS incorporates two key innovations: (1) the near real-time\nconstruction of Event Knowledge Graphs (EKGs) for efficient indexing of long or\ncontinuous video streams, and (2) an agentic retrieval-generation mechanism\nthat leverages EKGs to handle complex and diverse queries. Comprehensive\nevaluations on public benchmarks, LVBench and VideoMME-Long, demonstrate that\nAVAS achieves state-of-the-art performance, attaining 62.3% and 64.1% accuracy,\nrespectively, significantly surpassing existing VLM and video\nRetrieval-Augmented Generation (RAG) systems. Furthermore, to evaluate video\nanalytics in ultra-long and open-world video scenarios, we introduce a new\nbenchmark, AVAS-100. This benchmark comprises 8 videos, each exceeding 10 hours\nin duration, along with 120 manually annotated, diverse, and complex\nquestion-answer pairs. On AVAS-100, AVAS achieves top-tier performance with an\naccuracy of 75.8%.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "15 pages, AVAS, add latency breakdown",
    "pdf_url": "http://arxiv.org/pdf/2505.00254v3",
    "published_date": "2025-05-01 02:40:23 UTC",
    "updated_date": "2025-05-16 10:00:32 UTC"
  },
  {
    "arxiv_id": "2505.01456v1",
    "title": "Unlearning Sensitive Information in Multimodal LLMs: Benchmark and Attack-Defense Evaluation",
    "authors": [
      "Vaidehi Patil",
      "Yi-Lin Sung",
      "Peter Hase",
      "Jie Peng",
      "Tianlong Chen",
      "Mohit Bansal"
    ],
    "abstract": "LLMs trained on massive datasets may inadvertently acquire sensitive\ninformation such as personal details and potentially harmful content. This risk\nis further heightened in multimodal LLMs as they integrate information from\nmultiple modalities (image and text). Adversaries can exploit this knowledge\nthrough multimodal prompts to extract sensitive details. Evaluating how\neffectively MLLMs can forget such information (targeted unlearning)\nnecessitates the creation of high-quality, well-annotated image-text pairs.\nWhile prior work on unlearning has focused on text, multimodal unlearning\nremains underexplored. To address this gap, we first introduce a multimodal\nunlearning benchmark, UnLOK-VQA (Unlearning Outside Knowledge VQA), as well as\nan attack-and-defense framework to evaluate methods for deleting specific\nmultimodal knowledge from MLLMs. We extend a visual question-answering dataset\nusing an automated pipeline that generates varying-proximity samples for\ntesting generalization and specificity, followed by manual filtering for\nmaintaining high quality. We then evaluate six defense objectives against seven\nattacks (four whitebox, three blackbox), including a novel whitebox method\nleveraging interpretability of hidden states. Our results show multimodal\nattacks outperform text- or image-only ones, and that the most effective\ndefense removes answer information from internal model states. Additionally,\nlarger models exhibit greater post-editing robustness, suggesting that scale\nenhances safety. UnLOK-VQA provides a rigorous benchmark for advancing\nunlearning in MLLMs.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.CL",
    "comment": "The dataset and code are publicly available at\n  https://github.com/Vaidehi99/UnLOK-VQA",
    "pdf_url": "http://arxiv.org/pdf/2505.01456v1",
    "published_date": "2025-05-01 01:54:00 UTC",
    "updated_date": "2025-05-01 01:54:00 UTC"
  },
  {
    "arxiv_id": "2505.00240v2",
    "title": "LLM-Based Threat Detection and Prevention Framework for IoT Ecosystems",
    "authors": [
      "Yazan Otoum",
      "Arghavan Asad",
      "Amiya Nayak"
    ],
    "abstract": "The increasing complexity and scale of the Internet of Things (IoT) have made\nsecurity a critical concern. This paper presents a novel Large Language Model\n(LLM)-based framework for comprehensive threat detection and prevention in IoT\nenvironments. The system integrates lightweight LLMs fine-tuned on IoT-specific\ndatasets (IoT-23, TON_IoT) for real-time anomaly detection and automated,\ncontext-aware mitigation strategies optimized for resource-constrained devices.\nA modular Docker-based deployment enables scalable and reproducible evaluation\nacross diverse network conditions. Experimental results in simulated IoT\nenvironments demonstrate significant improvements in detection accuracy,\nresponse latency, and resource efficiency over traditional security methods.\nThe proposed framework highlights the potential of LLM-driven, autonomous\nsecurity solutions for future IoT ecosystems.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.ET",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "Preprint version; submitted for academic peer review",
    "pdf_url": "http://arxiv.org/pdf/2505.00240v2",
    "published_date": "2025-05-01 01:18:54 UTC",
    "updated_date": "2025-05-13 03:02:38 UTC"
  },
  {
    "arxiv_id": "2505.00232v1",
    "title": "Scaling On-Device GPU Inference for Large Generative Models",
    "authors": [
      "Jiuqiang Tang",
      "Raman Sarokin",
      "Ekaterina Ignasheva",
      "Grant Jensen",
      "Lin Chen",
      "Juhyun Lee",
      "Andrei Kulik",
      "Matthias Grundmann"
    ],
    "abstract": "Driven by the advancements in generative AI, large machine learning models\nhave revolutionized domains such as image processing, audio synthesis, and\nspeech recognition. While server-based deployments remain the locus of peak\nperformance, the imperative for on-device inference, necessitated by privacy\nand efficiency considerations, persists. Recognizing GPUs as the on-device ML\naccelerator with the widest reach, we present ML Drift--an optimized framework\nthat extends the capabilities of state-of-the-art GPU-accelerated inference\nengines. ML Drift enables on-device execution of generative AI workloads which\ncontain 10 to 100x more parameters than existing on-device generative AI\nmodels. ML Drift addresses intricate engineering challenges associated with\ncross-GPU API development, and ensures broad compatibility across mobile and\ndesktop/laptop platforms, thereby facilitating the deployment of significantly\nmore complex models on resource-constrained devices. Our GPU-accelerated ML/AI\ninference engine achieves an order-of-magnitude performance improvement\nrelative to existing open-source GPU inference engines.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "to be published in CVPR 2025 Workshop on Efficient and On-Device\n  Generation (EDGE)",
    "pdf_url": "http://arxiv.org/pdf/2505.00232v1",
    "published_date": "2025-05-01 00:44:13 UTC",
    "updated_date": "2025-05-01 00:44:13 UTC"
  },
  {
    "arxiv_id": "2505.00225v1",
    "title": "Predicting Estimated Times of Restoration for Electrical Outages Using Longitudinal Tabular Transformers",
    "authors": [
      "Bogireddy Sai Prasanna Teja",
      "Valliappan Muthukaruppan",
      "Carls Benjamin"
    ],
    "abstract": "As climate variability increases, the ability of utility providers to deliver\nprecise Estimated Times of Restoration (ETR) during natural disasters has\nbecome increasingly critical. Accurate and timely ETRs are essential for\nenabling customer preparedness during extended power outages, where informed\ndecision-making can be crucial, particularly in severe weather conditions.\nNonetheless, prevailing utility practices predominantly depend on manual\nassessments or traditional statistical methods, which often fail to achieve the\nlevel of precision required for reliable and actionable predictions. To address\nthese limitations, we propose a Longitudinal Tabular Transformer (LTT) model\nthat leverages historical outage event data along with sequential updates of\nthese events to improve the accuracy of ETR predictions. The model's\nperformance was evaluated over 34,000 storm-related outage events from three\nmajor utility companies, collectively serving over 3 million customers over a\n2-year period. Results demonstrate that the LTT model improves the Customer\nSatisfaction Impact (CSI) metric by an average of 19.08% (p > 0.001) compared\nto existing methods. Additionally, we introduce customer-informed regression\nmetrics that align model evaluation with real-world satisfaction, ensuring the\noutcomes resonate with customer expectations. Furthermore, we employ\ninterpretability techniques to analyze the temporal significance of\nincorporating sequential updates in modeling outage events and to identify the\ncontributions of predictive features to a given ETR. This comprehensive\napproach not only improves predictive accuracy but also enhances transparency,\nfostering greater trust in the model's capabilities.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.00225v1",
    "published_date": "2025-05-01 00:25:43 UTC",
    "updated_date": "2025-05-01 00:25:43 UTC"
  }
]