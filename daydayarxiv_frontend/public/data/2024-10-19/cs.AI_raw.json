[
  {
    "arxiv_id": "2410.15234v2",
    "title": "Bias Amplification: Large Language Models as Increasingly Biased Media",
    "authors": [
      "Ze Wang",
      "Zekun Wu",
      "Jeremy Zhang",
      "Xin Guan",
      "Navya Jain",
      "Skylar Lu",
      "Saloni Gupta",
      "Adriano Koshiyama"
    ],
    "abstract": "Model collapse, a phenomenon where models degrade in performance due to\nindiscriminate use of synthetic data is well studied. However, its role in bias\namplification, the progressive reinforcement of preexisting social biases in\nLarge Language Models (LLMs) remains underexplored. In this paper, we formally\ndefine the conditions for bias amplification and demonstrate through\nstatistical simulations that bias can intensify even in the absence of sampling\nerrors, the primary driver of model collapse. Empirically, we investigate\npolitical bias amplification in GPT2 using a custom built benchmark for\nsentence continuation tasks. Our findings reveal a progressively increasing\nright-leaning bias. Furthermore, we evaluate three mitigation strategies,\nOverfitting, Preservation, and Accumulation, and show that bias amplification\npersists even when model collapse is mitigated. Finally, a mechanistic\ninterpretation identifies distinct sets of neurons responsible for model\ncollapse and bias amplification, suggesting they arise from different\nunderlying mechanisms.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.15234v2",
    "published_date": "2024-10-19 22:53:27 UTC",
    "updated_date": "2025-02-17 07:49:14 UTC"
  },
  {
    "arxiv_id": "2410.15225v1",
    "title": "Chasing Random: Instruction Selection Strategies Fail to Generalize",
    "authors": [
      "Harshita Diddee",
      "Daphne Ippolito"
    ],
    "abstract": "Prior work has shown that language models can be tuned to follow user\ninstructions using only a small set of high-quality instructions. This has\naccelerated the development of methods that filter a large, noisy\ninstruction-tuning datasets down to high-quality subset which works just as\nwell. However, typically, the performance of these methods is not demonstrated\nacross a uniform experimental setup and thus their generalization capabilities\nare not well established. In this work, we analyze popular selection strategies\nacross different source datasets, selection budgets and evaluation benchmarks:\nOur results indicate that selection strategies generalize poorly, often failing\nto consistently outperform even random baselines. We also analyze the\ncost-performance trade-offs of using data selection. Our findings reveal that\ndata selection can often exceed the cost of fine-tuning on the full dataset,\nyielding only marginal and sometimes no gains compared to tuning on the full\ndataset or a random subset.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.15225v1",
    "published_date": "2024-10-19 22:10:49 UTC",
    "updated_date": "2024-10-19 22:10:49 UTC"
  },
  {
    "arxiv_id": "2410.15222v1",
    "title": "AutoFLUKA: A Large Language Model Based Framework for Automating Monte Carlo Simulations in FLUKA",
    "authors": [
      "Zavier Ndum Ndum",
      "Jian Tao",
      "John Ford",
      "Yang Liu"
    ],
    "abstract": "Monte Carlo (MC) simulations, particularly using FLUKA, are essential for\nreplicating real-world scenarios across scientific and engineering fields.\nDespite the robustness and versatility, FLUKA faces significant limitations in\nautomation and integration with external post-processing tools, leading to\nworkflows with a steep learning curve, which are time-consuming and prone to\nhuman errors. Traditional methods involving the use of shell and Python\nscripts, MATLAB, and Microsoft Excel require extensive manual intervention and\nlack flexibility, adding complexity to evolving scenarios. This study explores\nthe potential of Large Language Models (LLMs) and AI agents to address these\nlimitations. AI agents, integrate natural language processing with autonomous\nreasoning for decision-making and adaptive planning, making them ideal for\nautomation. We introduce AutoFLUKA, an AI agent application developed using the\nLangChain Python Framework to automate typical MC simulation workflows in\nFLUKA. AutoFLUKA can modify FLUKA input files, execute simulations, and\nefficiently process results for visualization, significantly reducing human\nlabor and error. Our case studies demonstrate that AutoFLUKA can handle both\ngeneralized and domain-specific cases, such as Microdosimetry, with an\nstreamlined automated workflow, showcasing its scalability and flexibility. The\nstudy also highlights the potential of Retrieval Augmentation Generation (RAG)\ntools to act as virtual assistants for FLUKA, further improving user\nexperience, time and efficiency. In conclusion, AutoFLUKA represents a\nsignificant advancement in automating MC simulation workflows, offering a\nrobust solution to the inherent limitations. This innovation not only saves\ntime and resources but also opens new paradigms for research and development in\nhigh energy physics, medical physics, nuclear engineering space and\nenvironmental science.",
    "categories": [
      "cs.AI",
      "hep-ex",
      "nucl-ex",
      "physics.comp-ph",
      "physics.med-ph"
    ],
    "primary_category": "cs.AI",
    "comment": "58 pages including text, figures, references and appendices",
    "pdf_url": "http://arxiv.org/pdf/2410.15222v1",
    "published_date": "2024-10-19 21:50:11 UTC",
    "updated_date": "2024-10-19 21:50:11 UTC"
  },
  {
    "arxiv_id": "2410.15221v1",
    "title": "IntersectionZoo: Eco-driving for Benchmarking Multi-Agent Contextual Reinforcement Learning",
    "authors": [
      "Vindula Jayawardana",
      "Baptiste Freydt",
      "Ao Qu",
      "Cameron Hickert",
      "Zhongxia Yan",
      "Cathy Wu"
    ],
    "abstract": "Despite the popularity of multi-agent reinforcement learning (RL) in\nsimulated and two-player applications, its success in messy real-world\napplications has been limited. A key challenge lies in its generalizability\nacross problem variations, a common necessity for many real-world problems.\nContextual reinforcement learning (CRL) formalizes learning policies that\ngeneralize across problem variations. However, the lack of standardized\nbenchmarks for multi-agent CRL has hindered progress in the field. Such\nbenchmarks are desired to be based on real-world applications to naturally\ncapture the many open challenges of real-world problems that affect\ngeneralization. To bridge this gap, we propose IntersectionZoo, a comprehensive\nbenchmark suite for multi-agent CRL through the real-world application of\ncooperative eco-driving in urban road networks. The task of cooperative\neco-driving is to control a fleet of vehicles to reduce fleet-level vehicular\nemissions. By grounding IntersectionZoo in a real-world application, we\nnaturally capture real-world problem characteristics, such as partial\nobservability and multiple competing objectives. IntersectionZoo is built on\ndata-informed simulations of 16,334 signalized intersections derived from 10\nmajor US cities, modeled in an open-source industry-grade microscopic traffic\nsimulator. By modeling factors affecting vehicular exhaust emissions (e.g.,\ntemperature, road conditions, travel demand), IntersectionZoo provides one\nmillion data-driven traffic scenarios. Using these traffic scenarios, we\nbenchmark popular multi-agent RL and human-like driving algorithms and\ndemonstrate that the popular multi-agent RL algorithms struggle to generalize\nin CRL settings.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.MA",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.LG",
    "comment": "In review",
    "pdf_url": "http://arxiv.org/pdf/2410.15221v1",
    "published_date": "2024-10-19 21:34:24 UTC",
    "updated_date": "2024-10-19 21:34:24 UTC"
  },
  {
    "arxiv_id": "2410.15208v1",
    "title": "Low-cost Robust Night-time Aerial Material Segmentation through Hyperspectral Data and Sparse Spatio-Temporal Learning",
    "authors": [
      "Chandrajit Bajaj",
      "Minh Nguyen",
      "Shubham Bhardwaj"
    ],
    "abstract": "Material segmentation is a complex task, particularly when dealing with\naerial data in poor lighting and atmospheric conditions. To address this,\nhyperspectral data from specialized cameras can be very useful in addition to\nRGB images. However, due to hardware constraints, high spectral data often come\nwith lower spatial resolution. Additionally, incorporating such data into a\nlearning-based segmentation framework is challenging due to the numerous data\nchannels involved. To overcome these difficulties, we propose an innovative\nSiamese framework that uses time series-based compression to effectively and\nscalably integrate the additional spectral data into the segmentation task. We\ndemonstrate our model's effectiveness through competitive benchmarks on aerial\ndatasets in various environmental conditions.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted to the International Conference on Neural Information\n  Processing (ICONIP) 2024. To be published in Springer-Nature Communications\n  in Computer and Information Science (CCIS) Series",
    "pdf_url": "http://arxiv.org/pdf/2410.15208v1",
    "published_date": "2024-10-19 20:48:41 UTC",
    "updated_date": "2024-10-19 20:48:41 UTC"
  },
  {
    "arxiv_id": "2410.19835v1",
    "title": "Multidimensional Knowledge Graph Embeddings for International Trade Flow Analysis",
    "authors": [
      "Durgesh Nandini",
      "Simon Bloethner",
      "Mirco Schoenfeld",
      "Mario Larch"
    ],
    "abstract": "Understanding the complex dynamics of high-dimensional, contingent, and\nstrongly nonlinear economic data, often shaped by multiplicative processes,\nposes significant challenges for traditional regression methods as such methods\noffer limited capacity to capture the structural changes they feature. To\naddress this, we propose leveraging the potential of knowledge graph embeddings\nfor economic trade data, in particular, to predict international trade\nrelationships. We implement KonecoKG, a knowledge graph representation of\neconomic trade data with multidimensional relationships using SDM-RDFizer, and\ntransform the relationships into a knowledge graph embedding using AmpliGraph.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.IR",
      "econ.GN",
      "q-fin.EC"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.19835v1",
    "published_date": "2024-10-19 20:28:20 UTC",
    "updated_date": "2024-10-19 20:28:20 UTC"
  },
  {
    "arxiv_id": "2410.15198v4",
    "title": "Medical-GAT: Cancer Document Classification Leveraging Graph-Based Residual Network for Scenarios with Limited Data",
    "authors": [
      "Elias Hossain",
      "Tasfia Nuzhat",
      "Shamsul Masum",
      "Shahram Rahimi",
      "Noorbakhsh Amiri Golilarz"
    ],
    "abstract": "Accurate classification of cancer-related medical abstracts is crucial for\nhealthcare management and research. However, obtaining large, labeled datasets\nin the medical domain is challenging due to privacy concerns and the complexity\nof clinical data. This scarcity of annotated data impedes the development of\neffective machine learning models for cancer document classification. To\naddress this challenge, we present a curated dataset of 1,874 biomedical\nabstracts, categorized into thyroid cancer, colon cancer, lung cancer, and\ngeneric topics. Our research focuses on leveraging this dataset to improve\nclassification performance, particularly in data-scarce scenarios. We introduce\na Residual Graph Attention Network (R-GAT) with multiple graph attention layers\nthat capture the semantic information and structural relationships within\ncancer-related documents. Our R-GAT model is compared with various techniques,\nincluding transformer-based models such as Bidirectional Encoder\nRepresentations from Transformers (BERT), RoBERTa, and domain-specific models\nlike BioBERT and Bio+ClinicalBERT. We also evaluated deep learning models\n(CNNs, LSTMs) and traditional machine learning models (Logistic Regression,\nSVM). Additionally, we explore ensemble approaches that combine deep learning\nmodels to enhance classification. Various feature extraction methods are\nassessed, including Term Frequency-Inverse Document Frequency (TF-IDF) with\nunigrams and bigrams, Word2Vec, and tokenizers from BERT and RoBERTa. The R-GAT\nmodel outperforms other techniques, achieving precision, recall, and F1 scores\nof 0.99, 0.97, and 0.98 for thyroid cancer; 0.96, 0.94, and 0.95 for colon\ncancer; 0.96, 0.99, and 0.97 for lung cancer; and 0.95, 0.96, and 0.95 for\ngeneric topics.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.15198v4",
    "published_date": "2024-10-19 20:07:40 UTC",
    "updated_date": "2025-04-08 22:53:41 UTC"
  },
  {
    "arxiv_id": "2410.15188v1",
    "title": "Augmented Lagrangian-Based Safe Reinforcement Learning Approach for Distribution System Volt/VAR Control",
    "authors": [
      "Guibin Chen"
    ],
    "abstract": "This paper proposes a data-driven solution for Volt-VAR control problem in\nactive distribution system. As distribution system models are always inaccurate\nand incomplete, it is quite difficult to solve the problem. To handle with this\ndilemma, this paper formulates the Volt-VAR control problem as a constrained\nMarkov decision process (CMDP). By synergistically combining the augmented\nLagrangian method and soft actor critic algorithm, a novel safe off-policy\nreinforcement learning (RL) approach is proposed in this paper to solve the\nCMDP. The actor network is updated in a policy gradient manner with the\nLagrangian value function. A double-critics network is adopted to synchronously\nestimate the action-value function to avoid overestimation bias. The proposed\nalgorithm does not require strong convexity guarantee of examined problems and\nis sample efficient. A two-stage strategy is adopted for offline training and\nonline execution, so the accurate distribution system model is no longer\nneeded. To achieve scalability, a centralized training distributed execution\nstrategy is adopted for a multi-agent framework, which enables a decentralized\nVolt-VAR control for large-scale distribution system. Comprehensive numerical\nexperiments with real-world electricity data demonstrate that our proposed\nalgorithm can achieve high solution optimality and constraints compliance.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "arXiv admin note: substantial text overlap with arXiv:2209.09772",
    "pdf_url": "http://arxiv.org/pdf/2410.15188v1",
    "published_date": "2024-10-19 19:45:09 UTC",
    "updated_date": "2024-10-19 19:45:09 UTC"
  },
  {
    "arxiv_id": "2410.15186v1",
    "title": "Fine-tuning foundational models to code diagnoses from veterinary health records",
    "authors": [
      "Mayla R. Boguslav",
      "Adam Kiehl",
      "David Kott",
      "G. Joseph Strecker",
      "Tracy Webb",
      "Nadia Saklou",
      "Terri Ward",
      "Michael Kirby"
    ],
    "abstract": "Veterinary medical records represent a large data resource for application to\nveterinary and One Health clinical research efforts. Use of the data is limited\nby interoperability challenges including inconsistent data formats and data\nsiloing. Clinical coding using standardized medical terminologies enhances the\nquality of medical records and facilitates their interoperability with\nveterinary and human health records from other sites. Previous studies, such as\nDeepTag and VetTag, evaluated the application of Natural Language Processing\n(NLP) to automate veterinary diagnosis coding, employing long short-term memory\n(LSTM) and transformer models to infer a subset of Systemized Nomenclature of\nMedicine - Clinical Terms (SNOMED-CT) diagnosis codes from free-text clinical\nnotes. This study expands on these efforts by incorporating all 7,739 distinct\nSNOMED-CT diagnosis codes recognized by the Colorado State University (CSU)\nVeterinary Teaching Hospital (VTH) and by leveraging the increasing\navailability of pre-trained large language models (LLMs). Ten freely-available\npre-trained LLMs were fine-tuned on the free-text notes from 246,473\nmanually-coded veterinary patient visits included in the CSU VTH's electronic\nhealth records (EHRs), which resulted in superior performance relative to\nprevious efforts. The most accurate results were obtained when expansive\nlabeled data were used to fine-tune relatively large clinical LLMs, but the\nstudy also showed that comparable results can be obtained using more limited\nresources and non-clinical LLMs. The results of this study contribute to the\nimprovement of the quality of veterinary EHRs by investigating accessible\nmethods for automated coding and support both animal and human health research\nby paving the way for more integrated and comprehensive health databases that\nspan species and institutions.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "I.2.7"
    ],
    "primary_category": "cs.CL",
    "comment": "26 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2410.15186v1",
    "published_date": "2024-10-19 19:30:29 UTC",
    "updated_date": "2024-10-19 19:30:29 UTC"
  },
  {
    "arxiv_id": "2410.15184v1",
    "title": "Action abstractions for amortized sampling",
    "authors": [
      "Oussama Boussif",
      "Léna Néhale Ezzine",
      "Joseph D Viviano",
      "Michał Koziarski",
      "Moksh Jain",
      "Nikolay Malkin",
      "Emmanuel Bengio",
      "Rim Assouel",
      "Yoshua Bengio"
    ],
    "abstract": "As trajectories sampled by policies used by reinforcement learning (RL) and\ngenerative flow networks (GFlowNets) grow longer, credit assignment and\nexploration become more challenging, and the long planning horizon hinders mode\ndiscovery and generalization. The challenge is particularly pronounced in\nentropy-seeking RL methods, such as generative flow networks, where the agent\nmust learn to sample from a structured distribution and discover multiple\nhigh-reward states, each of which take many steps to reach. To tackle this\nchallenge, we propose an approach to incorporate the discovery of action\nabstractions, or high-level actions, into the policy optimization process. Our\napproach involves iteratively extracting action subsequences commonly used\nacross many high-reward trajectories and `chunking' them into a single action\nthat is added to the action space. In empirical evaluation on synthetic and\nreal-world environments, our approach demonstrates improved sample efficiency\nperformance in discovering diverse high-reward objects, especially on harder\nexploration problems. We also observe that the abstracted high-order actions\nare interpretable, capturing the latent structure of the reward landscape of\nthe action space. This work provides a cognitively motivated approach to action\nabstraction in RL and is the first demonstration of hierarchical planning in\namortized sequential sampling.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.15184v1",
    "published_date": "2024-10-19 19:22:50 UTC",
    "updated_date": "2024-10-19 19:22:50 UTC"
  },
  {
    "arxiv_id": "2410.15178v3",
    "title": "GUIDEd Agents: Enhancing Navigation Policies through Task-Specific Uncertainty Abstraction in Localization-Limited Environments",
    "authors": [
      "Gokul Puthumanaillam",
      "Paulo Padrao",
      "Jose Fuentes",
      "Leonardo Bobadilla",
      "Melkior Ornik"
    ],
    "abstract": "Autonomous vehicles performing navigation tasks in complex environments face\nsignificant challenges due to uncertainty in state estimation. In many\nscenarios, such as stealth operations or resource-constrained settings,\naccessing high-precision localization comes at a significant cost, forcing\nrobots to rely primarily on less precise state estimates. Our key observation\nis that different tasks require varying levels of precision in different\nregions: a robot navigating a crowded space might need precise localization\nnear obstacles but can operate effectively with less precision elsewhere. In\nthis paper, we present a planning method for integrating task-specific\nuncertainty requirements directly into navigation policies. We introduce\nTask-Specific Uncertainty Maps (TSUMs), which abstract the acceptable levels of\nstate estimation uncertainty across different regions. TSUMs align task\nrequirements and environmental features using a shared representation space,\ngenerated via a domain-adapted encoder. Using TSUMs, we propose Generalized\nUncertainty Integration for Decision-Making and Execution (GUIDE), a policy\nconditioning framework that incorporates these uncertainty requirements into\nrobot decision-making. We find that TSUMs provide an effective way to abstract\ntask-specific uncertainty requirements, and conditioning policies on TSUMs\nenables the robot to reason about the context-dependent value of certainty and\nadapt its behavior accordingly. We show how integrating GUIDE into\nreinforcement learning frameworks allows the agent to learn navigation policies\nthat effectively balance task completion and uncertainty management without\nexplicit reward engineering. We evaluate GUIDE on various real-world robotic\nnavigation tasks and find that it demonstrates significant improvement in task\ncompletion rates compared to baseline methods that do not explicitly consider\ntask-specific uncertainty.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.15178v3",
    "published_date": "2024-10-19 18:46:17 UTC",
    "updated_date": "2025-02-03 04:57:52 UTC"
  },
  {
    "arxiv_id": "2410.15175v1",
    "title": "Implicit neural representation for free-breathing MR fingerprinting (INR-MRF): co-registered 3D whole-liver water T1, water T2, proton density fat fraction, and R2* mapping",
    "authors": [
      "Chao Li",
      "Jiahao Li",
      "Jinwei Zhang",
      "Eddy Solomon",
      "Alexey V. Dimov",
      "Pascal Spincemaille",
      "Thanh D. Nguyen",
      "Martin R. Prince",
      "Yi Wang"
    ],
    "abstract": "Purpose: To develop an MRI technique for free-breathing 3D whole-liver\nquantification of water T1, water T2, proton density fat fraction (PDFF), R2*.\nMethods: An Eight-echo spoiled gradient echo pulse sequence with spiral readout\nwas developed by interleaving inversion recovery and T2 magnetization\npreparation. We propose a neural network based on a 4D and a 3D implicit neural\nrepresentation (INR) which simultaneously learns the motion deformation fields\nand the static reference frame MRI subspace images respectively. Water and fat\nsingular images were separated during network training, with no need of\nperforming retrospective water-fat separation. T1, T2, R2* and proton density\nfat fraction (PDFF) produced by the proposed method were validated in vivo on\n10 healthy subjects, using quantitative maps generated from conventional scans\nas reference. Results: Our results showed minimal bias and narrow 95% limits of\nagreement on T1, T2, R2* and PDFF values in the liver compared to conventional\nbreath-holding scans. Conclusions: INR-MRF enabled co-registered 3D whole liver\nT1, T2, R2* and PDFF mapping in a single free-breathing scan.",
    "categories": [
      "physics.med-ph",
      "cs.AI",
      "eess.SP"
    ],
    "primary_category": "physics.med-ph",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.15175v1",
    "published_date": "2024-10-19 18:35:36 UTC",
    "updated_date": "2024-10-19 18:35:36 UTC"
  },
  {
    "arxiv_id": "2410.15173v1",
    "title": "Uncovering Autoregressive LLM Knowledge of Thematic Fit in Event Representation",
    "authors": [
      "Safeyah Khaled Alshemali",
      "Daniel Bauer",
      "Yuval Marton"
    ],
    "abstract": "The thematic fit estimation task measures the compatibility between a\npredicate (typically a verb), an argument (typically a noun phrase), and a\nspecific semantic role assigned to the argument. Previous state-of-the-art work\nhas focused on modeling thematic fit through distributional or neural models of\nevent representation, trained in a supervised fashion with indirect labels. In\nthis work, we assess whether pre-trained autoregressive LLMs possess\nconsistent, expressible knowledge about thematic fit. We evaluate both closed\nand open state-of-the-art LLMs on several psycholinguistic datasets, along\nthree axes: (1) Reasoning Form: multi-step logical reasoning (chain-of-thought\nprompting) vs. simple prompting. (2) Input Form: providing context (generated\nsentences) vs. raw tuples <predicate, argument, role>. (3) Output Form:\ncategorical vs. numeric. Our results show that chain-of-thought reasoning is\nmore effective on datasets with self-explanatory semantic role labels,\nespecially Location. Generated sentences helped only in few settings, and\nlowered results in many others. Predefined categorical (compared to numeric)\noutput raised GPT's results across the board with few exceptions, but lowered\nLlama's. We saw that semantically incoherent generated sentences, which the\nmodels lack the ability to consistently filter out, hurt reasoning and overall\nperformance too. Our GPT-powered methods set new state-of-the-art on all tested\ndatasets.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "15 pages, 3 figures",
    "pdf_url": "http://arxiv.org/pdf/2410.15173v1",
    "published_date": "2024-10-19 18:25:30 UTC",
    "updated_date": "2024-10-19 18:25:30 UTC"
  },
  {
    "arxiv_id": "2410.15171v1",
    "title": "Linguistic Fuzzy Information Evolution with Random Leader Election Mechanism for Decision-Making Systems",
    "authors": [
      "Qianlei Jia",
      "Witold Pedrycz"
    ],
    "abstract": "Linguistic fuzzy information evolution is crucial in understanding\ninformation exchange among agents. However, different agent weights may lead to\ndifferent convergence results in the classic DeGroot model. Similarly, in the\nHegselmann-Krause bounded confidence model (HK model), changing the confidence\nthreshold values of agents can lead to differences in the final results. To\naddress these limitations, this paper proposes three new models of linguistic\nfuzzy information dynamics: the per-round random leader election\nmechanism-based DeGroot model (PRRLEM-DeGroot), the PRRLEM-based homogeneous HK\nmodel (PRRLEM-HOHK), and the PRRLEM-based heterogeneous HK model (PRRLEM-HEHK).\nIn these models, after each round of fuzzy information updates, an agent is\nrandomly selected to act as a temporary leader with more significant influence,\nwith the leadership structure being reset after each update. This strategy\nincreases the information sharing and enhances decision-making by integrating\nmultiple agents' evaluation information, which is also in line with real life\n(\\emph{Leader is not unchanged}). The Monte Carlo method is then employed to\nsimulate the behavior of complex systems through repeated random tests,\nobtaining confidence intervals for different fuzzy information. Subsequently,\nan improved golden rule representative value (GRRV) in fuzzy theory is proposed\nto rank these confidence intervals. Simulation examples and a real-world\nscenario about space situational awareness validate the effectiveness of the\nproposed models. Comparative analysis with the other models demonstrate our\nability to address the echo chamber and improve the robustness.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.15171v1",
    "published_date": "2024-10-19 18:15:24 UTC",
    "updated_date": "2024-10-19 18:15:24 UTC"
  },
  {
    "arxiv_id": "2410.15164v3",
    "title": "SPA-Bench: A Comprehensive Benchmark for SmartPhone Agent Evaluation",
    "authors": [
      "Jingxuan Chen",
      "Derek Yuen",
      "Bin Xie",
      "Yuhao Yang",
      "Gongwei Chen",
      "Zhihao Wu",
      "Li Yixing",
      "Xurui Zhou",
      "Weiwen Liu",
      "Shuai Wang",
      "Kaiwen Zhou",
      "Rui Shao",
      "Liqiang Nie",
      "Yasheng Wang",
      "Jianye Hao",
      "Jun Wang",
      "Kun Shao"
    ],
    "abstract": "Smartphone agents are increasingly important for helping users control\ndevices efficiently, with (Multimodal) Large Language Model (MLLM)-based\napproaches emerging as key contenders. Fairly comparing these agents is\nessential but challenging, requiring a varied task scope, the integration of\nagents with different implementations, and a generalisable evaluation pipeline\nto assess their strengths and weaknesses. In this paper, we present SPA-Bench,\na comprehensive SmartPhone Agent Benchmark designed to evaluate (M)LLM-based\nagents in an interactive environment that simulates real-world conditions.\nSPA-Bench offers three key contributions: (1) A diverse set of tasks covering\nsystem and third-party apps in both English and Chinese, focusing on features\ncommonly used in daily routines; (2) A plug-and-play framework enabling\nreal-time agent interaction with Android devices, integrating over ten agents\nwith the flexibility to add more; (3) A novel evaluation pipeline that\nautomatically assesses agent performance across multiple dimensions,\nencompassing seven metrics related to task completion and resource consumption.\nOur extensive experiments across tasks and agents reveal challenges like\ninterpreting mobile user interfaces, action grounding, memory retention, and\nexecution costs. We propose future research directions to ease these\ndifficulties, moving closer to real-world smartphone agent applications.\nSPA-Bench is available at https://ai-agents-2030.github.io/SPA-Bench/.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "ICLR 2025 Spotlight",
    "pdf_url": "http://arxiv.org/pdf/2410.15164v3",
    "published_date": "2024-10-19 17:28:48 UTC",
    "updated_date": "2025-03-31 20:39:17 UTC"
  },
  {
    "arxiv_id": "2410.15163v2",
    "title": "Optimizing Large Language Models for Dynamic Constraints through Human-in-the-Loop Discriminators",
    "authors": [
      "Timothy Wei",
      "Annabelle Miin",
      "Anastasia Miin"
    ],
    "abstract": "Large Language Models (LLMs) have recently demonstrated impressive\ncapabilities across various real-world applications. However, due to the\ncurrent text-in-text-out paradigm, it remains challenging for LLMs to handle\ndynamic and complex application constraints, let alone devise general solutions\nthat meet predefined system goals. Current common practices like model\nfinetuning and reflection-based reasoning often address these issues\ncase-by-case, limiting their generalizability. To address this issue, we\npropose a flexible framework that enables LLMs to interact with system\ninterfaces, summarize constraint concepts, and continually optimize performance\nmetrics by collaborating with human experts. As a case in point, we initialized\na travel planner agent by establishing constraints from evaluation interfaces.\nThen, we employed both LLM-based and human discriminators to identify critical\ncases and continuously improve agent performance until the desired outcomes\nwere achieved. After just one iteration, our framework achieved a $7.78\\%$ pass\nrate with the human discriminator (a $40.2\\%$ improvement over baseline) and a\n$6.11\\%$ pass rate with the LLM-based discriminator. Given the adaptability of\nour proposal, we believe this framework can be applied to a wide range of\nconstraint-based applications and lay a solid foundation for model finetuning\nwith performance-sensitive data samples.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.15163v2",
    "published_date": "2024-10-19 17:27:38 UTC",
    "updated_date": "2024-10-24 04:46:32 UTC"
  },
  {
    "arxiv_id": "2410.15156v1",
    "title": "Simulation-Based Optimistic Policy Iteration For Multi-Agent MDPs with Kullback-Leibler Control Cost",
    "authors": [
      "Khaled Nakhleh",
      "Ceyhun Eksin",
      "Sabit Ekin"
    ],
    "abstract": "This paper proposes an agent-based optimistic policy iteration (OPI) scheme\nfor learning stationary optimal stochastic policies in multi-agent Markov\nDecision Processes (MDPs), in which agents incur a Kullback-Leibler (KL)\ndivergence cost for their control efforts and an additional cost for the joint\nstate. The proposed scheme consists of a greedy policy improvement step\nfollowed by an m-step temporal difference (TD) policy evaluation step. We use\nthe separable structure of the instantaneous cost to show that the policy\nimprovement step follows a Boltzmann distribution that depends on the current\nvalue function estimate and the uncontrolled transition probabilities. This\nallows agents to compute the improved joint policy independently. We show that\nboth the synchronous (entire state space evaluation) and asynchronous (a\nuniformly sampled set of substates) versions of the OPI scheme with finite\npolicy evaluation rollout converge to the optimal value function and an optimal\njoint policy asymptotically. Simulation results on a multi-agent MDP with KL\ncontrol cost variant of the Stag-Hare game validates our scheme's performance\nin terms of minimizing the cost return.",
    "categories": [
      "cs.AI",
      "cs.MA",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.15156v1",
    "published_date": "2024-10-19 17:00:23 UTC",
    "updated_date": "2024-10-19 17:00:23 UTC"
  },
  {
    "arxiv_id": "2410.15154v2",
    "title": "MCCoder: Streamlining Motion Control with LLM-Assisted Code Generation and Rigorous Verification",
    "authors": [
      "Yin Li",
      "Liangwei Wang",
      "Shiyuan Piao",
      "Boo-Ho Yang",
      "Ziyue Li",
      "Wei Zeng",
      "Fugee Tsung"
    ],
    "abstract": "Large Language Models (LLMs) have demonstrated significant potential in code\ngeneration. However, in the factory automation sector, particularly motion\ncontrol, manual programming, alongside inefficient and unsafe debugging\npractices, remains prevalent. This stems from the complex interplay of\nmechanical and electrical systems and stringent safety requirements. Moreover,\nmost current AI-assisted motion control programming efforts focus on PLCs, with\nlittle attention given to high-level languages and function libraries. To\naddress these challenges, we introduce MCCoder, an LLM-powered system tailored\nfor generating motion control code, integrated with a soft-motion controller.\nMCCoder improves code generation through a structured workflow that combines\nmultitask decomposition, hybrid retrieval-augmented generation (RAG), and\niterative self-correction, utilizing a well-established motion library.\nAdditionally, it integrates a 3D simulator for intuitive motion validation and\nlogs of full motion trajectories for data verification, significantly enhancing\naccuracy and safety. In the absence of benchmark datasets and metrics tailored\nfor evaluating motion control code generation, we propose MCEVAL, a dataset\nspanning motion tasks of varying complexity. Experiments show that MCCoder\noutperforms baseline models using Advanced RAG, achieving an overall\nperformance gain of 33.09% and a 131.77% improvement on complex tasks in the\nMCEVAL dataset.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.15154v2",
    "published_date": "2024-10-19 16:46:21 UTC",
    "updated_date": "2025-03-16 06:03:20 UTC"
  },
  {
    "arxiv_id": "2410.15143v2",
    "title": "Budgeted Online Continual Learning by Adaptive Layer Freezing and Frequency-based Sampling",
    "authors": [
      "Minhyuk Seo",
      "Hyunseo Koh",
      "Jonghyun Choi"
    ],
    "abstract": "The majority of online continual learning (CL) advocates single-epoch\ntraining and imposes restrictions on the size of replay memory. However,\nsingle-epoch training would incur a different amount of computations per CL\nalgorithm, and the additional storage cost to store logit or model in addition\nto replay memory is largely ignored in calculating the storage budget. Arguing\ndifferent computational and storage budgets hinder fair comparison among CL\nalgorithms in practice, we propose to use floating point operations (FLOPs) and\ntotal memory size in Byte as a metric for computational and memory budgets,\nrespectively, to compare and develop CL algorithms in the same 'total resource\nbudget.' To improve a CL method in a limited total budget, we propose adaptive\nlayer freezing that does not update the layers for less informative batches to\nreduce computational costs with a negligible loss of accuracy. In addition, we\npropose a memory retrieval method that allows the model to learn the same\namount of knowledge as using random retrieval in fewer iterations. Empirical\nvalidations on the CIFAR-10/100, CLEAR-10/100, and ImageNet-1K datasets\ndemonstrate that the proposed approach outperforms the state-of-the-art methods\nwithin the same total budget",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "ICLR 2025 Spotlight",
    "pdf_url": "http://arxiv.org/pdf/2410.15143v2",
    "published_date": "2024-10-19 16:00:00 UTC",
    "updated_date": "2025-03-16 20:18:42 UTC"
  },
  {
    "arxiv_id": "2410.15128v1",
    "title": "Generalized Flow Matching for Transition Dynamics Modeling",
    "authors": [
      "Haibo Wang",
      "Yuxuan Qiu",
      "Yanze Wang",
      "Rob Brekelmans",
      "Yuanqi Du"
    ],
    "abstract": "Simulating transition dynamics between metastable states is a fundamental\nchallenge in dynamical systems and stochastic processes with wide real-world\napplications in understanding protein folding, chemical reactions and neural\nactivities. However, the computational challenge often lies on sampling\nexponentially many paths in which only a small fraction ends in the target\nmetastable state due to existence of high energy barriers. To amortize the\ncost, we propose a data-driven approach to warm-up the simulation by learning\nnonlinear interpolations from local dynamics. Specifically, we infer a\npotential energy function from local dynamics data. To find plausible paths\nbetween two metastable states, we formulate a generalized flow matching\nframework that learns a vector field to sample propable paths between the two\nmarginal densities under the learned energy function. Furthermore, we\niteratively refine the model by assigning importance weights to the sampled\npaths and buffering more likely paths for training. We validate the\neffectiveness of the proposed method to sample probable paths on both synthetic\nand real-world molecular systems.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "physics.bio-ph",
      "physics.chem-ph"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.15128v1",
    "published_date": "2024-10-19 15:03:39 UTC",
    "updated_date": "2024-10-19 15:03:39 UTC"
  },
  {
    "arxiv_id": "2410.15127v2",
    "title": "Reinfier and Reintrainer: Verification and Interpretation-Driven Safe Deep Reinforcement Learning Frameworks",
    "authors": [
      "Zixuan Yang",
      "Jiaqi Zheng",
      "Guihai Chen"
    ],
    "abstract": "Ensuring verifiable and interpretable safety of deep reinforcement learning\n(DRL) is crucial for its deployment in real-world applications. Existing\napproaches like verification-in-the-loop training, however, face challenges\nsuch as difficulty in deployment, inefficient training, lack of\ninterpretability, and suboptimal performance in property satisfaction and\nreward performance. In this work, we propose a novel verification-driven\ninterpretation-in-the-loop framework Reintrainer to develop trustworthy DRL\nmodels, which are guaranteed to meet the expected constraint properties.\nSpecifically, in each iteration, this framework measures the gap between the\non-training model and predefined properties using formal verification,\ninterprets the contribution of each input feature to the model's output, and\nthen generates the training strategy derived from the on-the-fly measure\nresults, until all predefined properties are proven. Additionally, the low\nreusability of existing verifiers and interpreters motivates us to develop\nReinfier, a general and fundamental tool within Reintrainer for DRL\nverification and interpretation. Reinfier features breakpoints searching and\nverification-driven interpretation, associated with a concise\nconstraint-encoding language DRLP. Evaluations demonstrate that Reintrainer\noutperforms the state-of-the-art on six public benchmarks in both performance\nand property guarantees. Our framework can be accessed at\nhttps://github.com/Kurayuri/Reinfier.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.15127v2",
    "published_date": "2024-10-19 15:03:26 UTC",
    "updated_date": "2025-02-04 14:01:02 UTC"
  },
  {
    "arxiv_id": "2410.15126v1",
    "title": "MELT: Materials-aware Continued Pre-training for Language Model Adaptation to Materials Science",
    "authors": [
      "Junho Kim",
      "Yeachan Kim",
      "Jun-Hyung Park",
      "Yerim Oh",
      "Suho Kim",
      "SangKeun Lee"
    ],
    "abstract": "We introduce a novel continued pre-training method, MELT (MatEriaLs-aware\ncontinued pre-Training), specifically designed to efficiently adapt the\npre-trained language models (PLMs) for materials science. Unlike previous\nadaptation strategies that solely focus on constructing domain-specific corpus,\nMELT comprehensively considers both the corpus and the training strategy, given\nthat materials science corpus has distinct characteristics from other domains.\nTo this end, we first construct a comprehensive materials knowledge base from\nthe scientific corpus by building semantic graphs. Leveraging this extracted\nknowledge, we integrate a curriculum into the adaptation process that begins\nwith familiar and generalized concepts and progressively moves toward more\nspecialized terms. We conduct extensive experiments across diverse benchmarks\nto verify the effectiveness and generality of MELT. A comprehensive evaluation\nconvincingly supports the strength of MELT, demonstrating superior performance\ncompared to existing continued pre-training methods. The in-depth analysis also\nshows that MELT enables PLMs to effectively represent materials entities\ncompared to the existing adaptation methods, thereby highlighting its broad\napplicability across a wide spectrum of materials science.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted at EMNLP 2024 (Findings)",
    "pdf_url": "http://arxiv.org/pdf/2410.15126v1",
    "published_date": "2024-10-19 14:49:03 UTC",
    "updated_date": "2024-10-19 14:49:03 UTC"
  },
  {
    "arxiv_id": "2410.15116v1",
    "title": "Coarse-to-Fine Highlighting: Reducing Knowledge Hallucination in Large Language Models",
    "authors": [
      "Qitan Lv",
      "Jie Wang",
      "Hanzhu Chen",
      "Bin Li",
      "Yongdong Zhang",
      "Feng Wu"
    ],
    "abstract": "Generation of plausible but incorrect factual information, often termed\nhallucination, has attracted significant research interest. Retrieval-augmented\nlanguage model (RALM) -- which enhances models with up-to-date knowledge --\nemerges as a promising method to reduce hallucination. However, existing RALMs\nmay instead exacerbate hallucination when retrieving lengthy contexts. To\naddress this challenge, we propose COFT, a novel\n\\textbf{CO}arse-to-\\textbf{F}ine highligh\\textbf{T}ing method to focus on\ndifferent granularity-level key texts, thereby avoiding getting lost in lengthy\ncontexts. Specifically, COFT consists of three components: \\textit{recaller},\n\\textit{scorer}, and \\textit{selector}. First, \\textit{recaller} applies a\nknowledge graph to extract potential key entities in a given context. Second,\n\\textit{scorer} measures the importance of each entity by calculating its\ncontextual weight. Finally, \\textit{selector} selects high contextual weight\nentities with a dynamic threshold algorithm and highlights the corresponding\nparagraphs, sentences, or words in a coarse-to-fine manner. Extensive\nexperiments on the knowledge hallucination benchmark demonstrate the\neffectiveness of COFT, leading to a superior performance over $30\\%$ in the F1\nscore metric. Moreover, COFT also exhibits remarkable versatility across\nvarious long-form tasks, such as reading comprehension and question answering.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.15116v1",
    "published_date": "2024-10-19 13:59:48 UTC",
    "updated_date": "2024-10-19 13:59:48 UTC"
  },
  {
    "arxiv_id": "2410.15115v3",
    "title": "On Designing Effective RL Reward at Training Time for LLM Reasoning",
    "authors": [
      "Jiaxuan Gao",
      "Shusheng Xu",
      "Wenjie Ye",
      "Weilin Liu",
      "Chuyi He",
      "Wei Fu",
      "Zhiyu Mei",
      "Guangju Wang",
      "Yi Wu"
    ],
    "abstract": "Reward models have been increasingly critical for improving the reasoning\ncapability of LLMs. Existing research has shown that a well-trained reward\nmodel can substantially improve model performances at inference time via\nsearch. However, the potential of reward models during RL training time still\nremains largely under-explored. It is currently unclear whether these reward\nmodels can provide additional training signals to enhance the reasoning\ncapabilities of LLMs in RL training that uses sparse success rewards, which\nverify the correctness of solutions. In this work, we evaluate popular reward\nmodels for RL training, including the Outcome-supervised Reward Model (ORM) and\nthe Process-supervised Reward Model (PRM), and train a collection of LLMs for\nmath problems using RL by combining these learned rewards with success rewards.\nSurprisingly, even though these learned reward models have strong\ninference-time performances, they may NOT help or even hurt RL training,\nproducing worse performances than LLMs trained with the success reward only.\nOur analysis reveals that an LLM can receive high rewards from some of these\nreward models by repeating correct but unnecessary reasoning steps, leading to\na severe reward hacking issue. Therefore, we introduce two novel reward\nrefinement techniques, including Clipping and Delta. The key idea is to ensure\nthe accumulative reward of any reasoning trajectory is upper-bounded to keep a\nlearned reward model effective without being exploited. We evaluate our\ntechniques with multiple reward models over a set of 1.5B and 7B LLMs on MATH\nand GSM8K benchmarks and demonstrate that with a carefully designed reward\nfunction, RL training without any additional supervised tuning can improve all\nthe evaluated LLMs, including the state-of-the-art 7B LLM\nQwen2.5-Math-7B-Instruct on MATH and GSM8K benchmarks.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.15115v3",
    "published_date": "2024-10-19 13:53:50 UTC",
    "updated_date": "2024-11-27 11:58:50 UTC"
  },
  {
    "arxiv_id": "2410.15111v1",
    "title": "A Prompt Refinement-based Large Language Model for Metro Passenger Flow Forecasting under Delay Conditions",
    "authors": [
      "Ping Huang",
      "Yuxin He",
      "Hao Wang",
      "Jingjing Chen",
      "Qin Luo"
    ],
    "abstract": "Accurate short-term forecasts of passenger flow in metro systems under delay\nconditions are crucial for emergency response and service recovery, which pose\nsignificant challenges and are currently under-researched. Due to the rare\noccurrence of delay events, the limited sample size under delay condictions\nmake it difficult for conventional models to effectively capture the complex\nimpacts of delays on passenger flow, resulting in low forecasting accuracy.\nRecognizing the strengths of large language models (LLMs) in few-shot learning\ndue to their powerful pre-training, contextual understanding, ability to\nperform zero-shot and few-shot reasoning, to address the issues that\neffectively generalize and adapt with minimal data, we propose a passenger flow\nforecasting framework under delay conditions that synthesizes an LLM with\ncarefully designed prompt engineering. By Refining prompt design, we enable the\nLLM to understand delay event information and the pattern from historical\npassenger flow data, thus overcoming the challenges of passenger flow\nforecasting under delay conditions. The propmpt engineering in the framework\nconsists of two main stages: systematic prompt generation and prompt\nrefinement. In the prompt generation stage, multi-source data is transformed\ninto descriptive texts understandable by the LLM and stored. In the prompt\nrefinement stage, we employ the multidimensional Chain of Thought (CoT) method\nto refine the prompts. We verify the proposed framework by conducting\nexperiments using real-world datasets specifically targeting passenger flow\nforecasting under delay conditions of Shenzhen metro in China. The experimental\nresults demonstrate that the proposed model performs particularly well in\nforecasting passenger flow under delay conditions.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "14 pages, 2 figures",
    "pdf_url": "http://arxiv.org/pdf/2410.15111v1",
    "published_date": "2024-10-19 13:46:46 UTC",
    "updated_date": "2024-10-19 13:46:46 UTC"
  },
  {
    "arxiv_id": "2410.19834v1",
    "title": "GNNRL-Smoothing: A Prior-Free Reinforcement Learning Model for Mesh Smoothing",
    "authors": [
      "Zhichao Wang",
      "Xinhai Chen",
      "Chunye Gong",
      "Bo Yang",
      "Liang Deng",
      "Yufei Sun",
      "Yufei Pang",
      "Jie Liu"
    ],
    "abstract": "Mesh smoothing methods can enhance mesh quality by eliminating distorted\nelements, leading to improved convergence in simulations. To balance the\nefficiency and robustness of traditional mesh smoothing process, previous\napproaches have employed supervised learning and reinforcement learning to\ntrain intelligent smoothing models. However, these methods heavily rely on\nlabeled dataset or prior knowledge to guide the models' learning. Furthermore,\ntheir limited capacity to enhance mesh connectivity often restricts the\neffectiveness of smoothing. In this paper, we first systematically analyze the\nlearning mechanisms of recent intelligent smoothing methods and propose a\nprior-free reinforcement learning model for intelligent mesh smoothing. Our\nproposed model integrates graph neural networks with reinforcement learning to\nimplement an intelligent node smoothing agent and introduces, for the first\ntime, a mesh connectivity improvement agent. We formalize mesh optimization as\na Markov Decision Process and successfully train both agents using Twin Delayed\nDeep Deterministic Policy Gradient and Double Dueling Deep Q-Network in the\nabsence of any prior data or knowledge. We verified the proposed model on both\n2D and 3D meshes. Experimental results demonstrate that our model achieves\nfeature-preserving smoothing on complex 3D surface meshes. It also achieves\nstate-of-the-art results among intelligent smoothing methods on 2D meshes and\nis 7.16 times faster than traditional optimization-based smoothing methods.\nMoreover, the connectivity improvement agent can effectively enhance the\nquality distribution of the mesh.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.19834v1",
    "published_date": "2024-10-19 13:26:52 UTC",
    "updated_date": "2024-10-19 13:26:52 UTC"
  },
  {
    "arxiv_id": "2410.15098v1",
    "title": "Incorporating Group Prior into Variational Inference for Tail-User Behavior Modeling in CTR Prediction",
    "authors": [
      "Han Xu",
      "Taoxing Pan",
      "Zhiqiang Liu",
      "Xiaoxiao Xu",
      "Lantao Hu"
    ],
    "abstract": "User behavior modeling -- which aims to extract user interests from\nbehavioral data -- has shown great power in Click-through rate (CTR)\nprediction, a key component in recommendation systems. Recently,\nattention-based algorithms have become a promising direction, as attention\nmechanisms emphasize the relevant interactions from rich behaviors. However,\nthe methods struggle to capture the preferences of tail users with sparse\ninteraction histories. To address the problem, we propose a novel variational\ninference approach, namely Group Prior Sampler Variational Inference (GPSVI),\nwhich introduces group preferences as priors to refine latent user interests\nfor tail users. In GPSVI, the extent of adjustments depends on the estimated\nuncertainty of individual preference modeling. In addition, We further enhance\nthe expressive power of variational inference by a volume-preserving flow. An\nappealing property of the GPSVI method is its ability to revert to traditional\nattention for head users with rich behavioral data while consistently enhancing\nperformance for long-tail users with sparse behaviors. Rigorous analysis and\nextensive experiments demonstrate that GPSVI consistently improves the\nperformance of tail users. Moreover, online A/B testing on a large-scale\nreal-world recommender system further confirms the effectiveness of our\nproposed approach.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.15098v1",
    "published_date": "2024-10-19 13:15:36 UTC",
    "updated_date": "2024-10-19 13:15:36 UTC"
  },
  {
    "arxiv_id": "2410.15096v1",
    "title": "GDPO: Learning to Directly Align Language Models with Diversity Using GFlowNets",
    "authors": [
      "Oh Joon Kwon",
      "Daiki E. Matsunaga",
      "Kee-Eung Kim"
    ],
    "abstract": "A critical component of the current generation of language models is\npreference alignment, which aims to precisely control the model's behavior to\nmeet human needs and values. The most notable among such methods is\nReinforcement Learning with Human Feedback (RLHF) and its offline variant\nDirect Preference Optimization (DPO), both of which seek to maximize a reward\nmodel based on human preferences. In particular, DPO derives reward signals\ndirectly from the offline preference data, but in doing so overfits the reward\nsignals and generates suboptimal responses that may contain human biases in the\ndataset. In this work, we propose a practical application of a\ndiversity-seeking RL algorithm called GFlowNet-DPO (GDPO) in an offline\npreference alignment setting to curtail such challenges. Empirical results show\nGDPO can generate far more diverse responses than the baseline methods that are\nstill relatively aligned with human values in dialog generation and\nsummarization tasks.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.15096v1",
    "published_date": "2024-10-19 13:07:52 UTC",
    "updated_date": "2024-10-19 13:07:52 UTC"
  },
  {
    "arxiv_id": "2410.15093v1",
    "title": "DPVS-Shapley:Faster and Universal Contribution Evaluation Component in Federated Learning",
    "authors": [
      "Ketin Yin",
      "Zonghao Guo",
      "ZhengHan Qin"
    ],
    "abstract": "In the current era of artificial intelligence, federated learning has emerged\nas a novel approach to addressing data privacy concerns inherent in centralized\nlearning paradigms. This decentralized learning model not only mitigates the\nrisk of data breaches but also enhances the system's scalability and\nrobustness. However, this approach introduces a new challenge: how to fairly\nand accurately assess the contribution of each participant. Developing an\neffective contribution evaluation mechanism is crucial for federated learning.\nSuch a mechanism incentivizes participants to actively contribute their data\nand computational resources, thereby improving the overall performance of the\nfederated learning system. By allocating resources and rewards based on the\nsize of the contributions, it ensures that each participant receives fair\ntreatment, fostering sustained engagement.Currently, Shapley value-based\nmethods are widely used to evaluate participants' contributions, with many\nresearchers proposing modifications to adapt these methods to real-world\nscenarios. In this paper, we introduce a component called Dynamic Pruning\nValidation Set Shapley (DPVS-Shapley). This method accelerates the contribution\nassessment process by dynamically pruning the original dataset without\ncompromising the evaluation's accuracy. Furthermore, this component can assign\ndifferent weights to various samples, thereby allowing clients capable of\ndistinguishing difficult examples to receive higher contribution scores.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR",
      "cs.GT"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.15093v1",
    "published_date": "2024-10-19 13:01:44 UTC",
    "updated_date": "2024-10-19 13:01:44 UTC"
  },
  {
    "arxiv_id": "2410.15086v1",
    "title": "Towards Safer Heuristics With XPlain",
    "authors": [
      "Pantea Karimi",
      "Solal Pirelli",
      "Siva Kesava Reddy Kakarla",
      "Ryan Beckett",
      "Santiago Segarra",
      "Beibin Li",
      "Pooria Namyar",
      "Behnaz Arzani"
    ],
    "abstract": "Many problems that cloud operators solve are computationally expensive, and\noperators often use heuristic algorithms (that are faster and scale better than\noptimal) to solve them more efficiently. Heuristic analyzers enable operators\nto find when and by how much their heuristics underperform. However, these\ntools do not provide enough detail for operators to mitigate the heuristic's\nimpact in practice: they only discover a single input instance that causes the\nheuristic to underperform (and not the full set), and they do not explain why.\n  We propose XPlain, a tool that extends these analyzers and helps operators\nunderstand when and why their heuristics underperform. We present promising\ninitial results that show such an extension is viable.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.DC",
      "cs.NI",
      "cs.PF"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.15086v1",
    "published_date": "2024-10-19 12:21:42 UTC",
    "updated_date": "2024-10-19 12:21:42 UTC"
  },
  {
    "arxiv_id": "2410.15081v4",
    "title": "A Distribution Semantics for Probabilistic Term Rewriting",
    "authors": [
      "Germán Vidal"
    ],
    "abstract": "Probabilistic programming is becoming increasingly popular thanks to its\nability to specify problems with a certain degree of uncertainty. In this work,\nwe focus on term rewriting, a well-known computational formalism. In\nparticular, we consider systems that combine traditional rewriting rules with\nprobabilities. Then, we define a novel \"distribution semantics\" for such\nsystems that can be used to model the probability of reducing a term to some\nvalue. We also show how to compute a set of \"explanations\" for a given\nreduction, which can be used to compute its probability in a more efficient\nway. Finally, we illustrate our approach with several examples and outline a\ncouple of extensions that may prove useful to improve the expressive power of\nprobabilistic rewrite systems.",
    "categories": [
      "cs.PL",
      "cs.AI"
    ],
    "primary_category": "cs.PL",
    "comment": "Submitted for publication",
    "pdf_url": "http://arxiv.org/pdf/2410.15081v4",
    "published_date": "2024-10-19 12:00:13 UTC",
    "updated_date": "2025-03-19 11:03:59 UTC"
  },
  {
    "arxiv_id": "2410.15076v2",
    "title": "EPT-1.5 Technical Report",
    "authors": [
      "Roberto Molinaro",
      "Jordan Dane Daubinet",
      "Alexander Jakob Dautel",
      "Andreas Schlueter",
      "Alex Grigoryev",
      "Nikoo Ekhtiari",
      "Bas Steunebrink",
      "Kevin Thiart",
      "Roan John Song",
      "Henry Martin",
      "Leonie Wagner",
      "Andrea Giussani",
      "Marvin Vincent Gabler"
    ],
    "abstract": "We announce the release of EPT-1.5, the latest iteration in our Earth Physics\nTransformer (EPT) family of foundation AI earth system models. EPT-1.5\ndemonstrates substantial improvements over its predecessor, EPT-1. Built\nspecifically for the European energy industry, EPT-1.5 shows remarkable\nperformance in predicting energy-relevant variables, particularly 10m & 100m\nwind speed and solar radiation. Especially in wind prediction, it outperforms\nexisting AI weather models like GraphCast, FuXi, and Pangu-Weather, as well as\nthe leading numerical weather model, IFS HRES by the European Centre for\nMedium-Range Weather Forecasts (ECMWF), setting a new state of the art.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.15076v2",
    "published_date": "2024-10-19 11:44:04 UTC",
    "updated_date": "2024-11-03 18:11:28 UTC"
  },
  {
    "arxiv_id": "2410.15075v1",
    "title": "SLIC: Secure Learned Image Codec through Compressed Domain Watermarking to Defend Image Manipulation",
    "authors": [
      "Chen-Hsiu Huang",
      "Ja-Ling Wu"
    ],
    "abstract": "The digital image manipulation and advancements in Generative AI, such as\nDeepfake, has raised significant concerns regarding the authenticity of images\nshared on social media. Traditional image forensic techniques, while helpful,\nare often passive and insufficient against sophisticated tampering methods.\nThis paper introduces the Secure Learned Image Codec (SLIC), a novel active\napproach to ensuring image authenticity through watermark embedding in the\ncompressed domain. SLIC leverages neural network-based compression to embed\nwatermarks as adversarial perturbations in the latent space, creating images\nthat degrade in quality upon re-compression if tampered with. This degradation\nacts as a defense mechanism against unauthorized modifications. Our method\ninvolves fine-tuning a neural encoder/decoder to balance watermark invisibility\nwith robustness, ensuring minimal quality loss for non-watermarked images.\nExperimental results demonstrate SLIC's effectiveness in generating visible\nartifacts in tampered images, thereby preventing their redistribution. This\nwork represents a significant step toward developing secure image codecs that\ncan be widely adopted to safeguard digital image integrity.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "accepted by ACM Multimedia Asia 2024",
    "pdf_url": "http://arxiv.org/pdf/2410.15075v1",
    "published_date": "2024-10-19 11:42:36 UTC",
    "updated_date": "2024-10-19 11:42:36 UTC"
  },
  {
    "arxiv_id": "2410.15074v1",
    "title": "LLaVA-Ultra: Large Chinese Language and Vision Assistant for Ultrasound",
    "authors": [
      "Xuechen Guo",
      "Wenhao Chai",
      "Shi-Yan Li",
      "Gaoang Wang"
    ],
    "abstract": "Multimodal Large Language Model (MLLM) has recently garnered attention as a\nprominent research focus. By harnessing powerful LLM, it facilitates a\ntransition of conversational generative AI from unimodal text to performing\nmultimodal tasks. This boom begins to significantly impact medical field.\nHowever, general visual language model (VLM) lacks sophisticated comprehension\nfor medical visual question answering (Med-VQA). Even models specifically\ntailored for medical domain tend to produce vague answers with weak visual\nrelevance. In this paper, we propose a fine-grained adaptive VLM architecture\nfor Chinese medical visual conversations through parameter-efficient tuning.\nSpecifically, we devise a fusion module with fine-grained vision encoders to\nachieve enhancement for subtle medical visual semantics. Then we note data\nredundancy common to medical scenes is ignored in most prior works. In cases of\na single text paired with multiple figures, we utilize weighted scoring with\nknowledge distillation to adaptively screen valid images mirroring text\ndescriptions. For execution, we leverage a large-scale multimodal Chinese\nultrasound dataset obtained from the hospital. We create instruction-following\ndata based on text from professional doctors, which ensures effective tuning.\nWith enhanced model and quality data, our Large Chinese Language and Vision\nAssistant for Ultrasound (LLaVA-Ultra) shows strong capability and robustness\nto medical scenarios. On three Med-VQA datasets, LLaVA-Ultra surpasses previous\nstate-of-the-art models on various metrics.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.15074v1",
    "published_date": "2024-10-19 11:38:31 UTC",
    "updated_date": "2024-10-19 11:38:31 UTC"
  },
  {
    "arxiv_id": "2410.15073v1",
    "title": "Personalized Federated Learning with Adaptive Feature Aggregation and Knowledge Transfer",
    "authors": [
      "Keting Yin",
      "Jiayi Mao"
    ],
    "abstract": "Federated Learning(FL) is popular as a privacy-preserving machine learning\nparadigm for generating a single model on decentralized data. However,\nstatistical heterogeneity poses a significant challenge for FL. As a subfield\nof FL, personalized FL (pFL) has attracted attention for its ability to achieve\npersonalized models that perform well on non-independent and identically\ndistributed (Non-IID) data. However, existing pFL methods are limited in terms\nof leveraging the global model's knowledge to enhance generalization while\nachieving personalization on local data. To address this, we proposed a new\nmethod personalized Federated learning with Adaptive Feature Aggregation and\nKnowledge Transfer (FedAFK), to train better feature extractors while balancing\ngeneralization and personalization for participating clients, which improves\nthe performance of personalized models on Non-IID data. We conduct extensive\nexperiments on three datasets in two widely-used heterogeneous settings and\nshow the superior performance of our proposed method over thirteen\nstate-of-the-art baselines.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.15073v1",
    "published_date": "2024-10-19 11:32:39 UTC",
    "updated_date": "2024-10-19 11:32:39 UTC"
  },
  {
    "arxiv_id": "2410.15068v2",
    "title": "LLM-HDR: Bridging LLM-based Perception and Self-Supervision for Unpaired LDR-to-HDR Image Reconstruction",
    "authors": [
      "Hrishav Bakul Barua",
      "Kalin Stefanov",
      "Lemuel Lai En Che",
      "Abhinav Dhall",
      "KokSheik Wong",
      "Ganesh Krishnasamy"
    ],
    "abstract": "The translation of Low Dynamic Range (LDR) to High Dynamic Range (HDR) images\nis an important computer vision task. There is a significant amount of research\nutilizing both conventional non-learning methods and modern data-driven\napproaches, focusing on using both single-exposed and multi-exposed LDR for HDR\nimage reconstruction. However, most current state-of-the-art methods require\nhigh-quality paired {LDR,HDR} datasets for model training. In addition, there\nis limited literature on using unpaired datasets for this task, that is, the\nmodel learns a mapping between domains, i.e., {LDR,HDR}. This paper proposes\nLLM-HDR, a method that integrates the perception of Large Language Models (LLM)\ninto a modified semantic- and cycle-consistent adversarial architecture that\nutilizes unpaired {LDR,HDR} datasets for training. The method introduces novel\nartifact- and exposure-aware generators to address visual artifact removal and\nan encoder and loss to address semantic consistency, another under-explored\ntopic. LLM-HDR is the first to use an LLM for the {LDR,HDR} translation task in\na self-supervised setup. The method achieves state-of-the-art performance\nacross several benchmark datasets and reconstructs high-quality HDR images. The\nofficial website of this work is available at:\nhttps://github.com/HrishavBakulBarua/LLM-HDR",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.GR",
      "cs.LG",
      "cs.RO",
      "Artificial intelligence, Computer vision, Machine learning, Deep\n  learning",
      "I.3.3; I.4.5"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.15068v2",
    "published_date": "2024-10-19 11:11:58 UTC",
    "updated_date": "2025-03-11 06:46:42 UTC"
  },
  {
    "arxiv_id": "2410.15064v1",
    "title": "A Prompt Engineering Approach and a Knowledge Graph based Framework for Tackling Legal Implications of Large Language Model Answers",
    "authors": [
      "George Hannah",
      "Rita T. Sousa",
      "Ioannis Dasoulas",
      "Claudia d'Amato"
    ],
    "abstract": "With the recent surge in popularity of Large Language Models (LLMs), there is\nthe rising risk of users blindly trusting the information in the response, even\nin cases where the LLM recommends actions that have potential legal\nimplications and this may put the user in danger. We provide an empirical\nanalysis on multiple existing LLMs showing the urgency of the problem. Hence,\nwe propose a short-term solution consisting in an approach for isolating these\nlegal issues through prompt re-engineering. We further analyse the outcomes but\nalso the limitations of the prompt engineering based approach and we highlight\nthe need of additional resources for fully solving the problem We also propose\na framework powered by a legal knowledge graph (KG) to generate legal citations\nfor these legal issues, enriching the response of the LLM.",
    "categories": [
      "cs.AI",
      "I.2.1"
    ],
    "primary_category": "cs.AI",
    "comment": "27 pages, 2 figures",
    "pdf_url": "http://arxiv.org/pdf/2410.15064v1",
    "published_date": "2024-10-19 10:59:50 UTC",
    "updated_date": "2024-10-19 10:59:50 UTC"
  },
  {
    "arxiv_id": "2410.15054v1",
    "title": "A Dual-Fusion Cognitive Diagnosis Framework for Open Student Learning Environments",
    "authors": [
      "Yuanhao Liu",
      "Shuo Liu",
      "Yimeng Liu",
      "Jingwen Yang",
      "Hong Qian"
    ],
    "abstract": "Cognitive diagnosis model (CDM) is a fundamental and upstream component in\nintelligent education. It aims to infer students' mastery levels based on\nhistorical response logs. However, existing CDMs usually follow the ID-based\nembedding paradigm, which could often diminish the effectiveness of CDMs in\nopen student learning environments. This is mainly because they can hardly\ndirectly infer new students' mastery levels or utilize new exercises or\nknowledge without retraining. Textual semantic information, due to its unified\nfeature space and easy accessibility, can help alleviate this issue.\nUnfortunately, directly incorporating semantic information may not benefit\nCDMs, since it does not capture response-relevant features and thus discards\nthe individual characteristics of each student. To this end, this paper\nproposes a dual-fusion cognitive diagnosis framework (DFCD) to address the\nchallenge of aligning two different modalities, i.e., textual semantic features\nand response-relevant features. Specifically, in DFCD, we first propose the\nexercise-refiner and concept-refiner to make the exercises and knowledge\nconcepts more coherent and reasonable via large language models. Then, DFCD\nencodes the refined features using text embedding models to obtain the semantic\ninformation. For response-related features, we propose a novel response matrix\nto fully incorporate the information within the response logs. Finally, DFCD\ndesigns a dual-fusion module to merge the two modal features. The ultimate\nrepresentations possess the capability of inference in open student learning\nenvironments and can be also plugged in existing CDMs. Extensive experiments\nacross real-world datasets show that DFCD achieves superior performance by\nintegrating different modalities and strong adaptability in open student\nlearning environments.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.15054v1",
    "published_date": "2024-10-19 10:12:02 UTC",
    "updated_date": "2024-10-19 10:12:02 UTC"
  },
  {
    "arxiv_id": "2410.15052v4",
    "title": "GlitchMiner: Mining Glitch Tokens in Large Language Models via Gradient-based Discrete Optimization",
    "authors": [
      "Zihui Wu",
      "Haichang Gao",
      "Ping Wang",
      "Shudong Zhang",
      "Zhaoxiang Liu",
      "Shiguo Lian"
    ],
    "abstract": "Glitch tokens in Large Language Models (LLMs) can trigger unpredictable\nbehaviors, threatening model reliability and safety. Existing detection methods\nrely on predefined patterns, limiting their adaptability across diverse LLM\narchitectures. We propose GlitchMiner, a gradient-based discrete optimization\nframework that efficiently identifies glitch tokens by introducing entropy as a\nmeasure of prediction uncertainty and employing a local search strategy to\nexplore the token space. Experiments across multiple LLM architectures\ndemonstrate that GlitchMiner outperforms existing methods in detection accuracy\nand adaptability, achieving over 10% average efficiency improvement. This\nmethod enhances vulnerability assessment in LLMs, contributing to the\ndevelopment of more robust and reliable applications. Code is available at\nhttps://github.com/wooozihui/GlitchMiner.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.15052v4",
    "published_date": "2024-10-19 09:49:12 UTC",
    "updated_date": "2024-11-09 06:25:27 UTC"
  },
  {
    "arxiv_id": "2410.15048v1",
    "title": "MorphAgent: Empowering Agents through Self-Evolving Profiles and Decentralized Collaboration",
    "authors": [
      "Siyuan Lu",
      "Jiaqi Shao",
      "Bing Luo",
      "Tao Lin"
    ],
    "abstract": "Large Language Model (LLM) based multi-agent systems (MAS) have shown promise\nin tackling complex tasks, but often rely on predefined roles and centralized\ncoordination, limiting their adaptability to evolving challenges. This paper\nintroduces MorphAgent, a novel framework for decentralized multi-agent\ncollaboration that enables agents to dynamically evolve their roles and\ncapabilities. Our approach employs self-evolving agent profiles, optimized\nthrough three key metrics, guiding agents in refining their individual\nexpertise while maintaining complementary team dynamics. MorphAgent implements\na two-phase process: a warm-up phase for initial profile optimization, followed\nby a task execution phase where agents continuously adapt their roles based on\ntask feedback. Our experimental results show that MorphAgent outperforms\ntraditional static-role MAS in terms of task performance and adaptability to\nchanging requirements, paving the way for more robust and versatile multi-agent\ncollaborative systems. Our code will be publicly available at\n\\url{https://github.com/LINs-lab/learn2collaborate}.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.15048v1",
    "published_date": "2024-10-19 09:10:49 UTC",
    "updated_date": "2024-10-19 09:10:49 UTC"
  },
  {
    "arxiv_id": "2410.15045v2",
    "title": "Distribution-Aware Compensation Design for Sustainable Data Rights in Machine Learning",
    "authors": [
      "Jiaqi Shao",
      "Tao Lin",
      "Bing Luo"
    ],
    "abstract": "Modern distributed learning systems face a critical challenge when clients\nrequest the removal of their data influence from trained models, as this\nprocess can significantly destabilize system performance and affect remaining\nparticipants. We propose an innovative mechanism that views this challenge\nthrough the lens of game theory, establishing a leader-follower framework where\na central coordinator provides strategic incentives to maintain system\nstability during data removal operations. Our approach quantifies the ripple\neffects of data removal through a comprehensive analytical model that captures\nboth system-wide and participant-specific impacts. We establish mathematical\nfoundations for measuring participant utility and system outcomes, revealing\ncritical insights into how data diversity influences both individual decisions\nand overall system stability. The framework incorporates a computationally\nefficient solution method that addresses the inherent complexity of optimizing\nparticipant interactions and resource allocation.",
    "categories": [
      "cs.GT",
      "cs.AI"
    ],
    "primary_category": "cs.GT",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.15045v2",
    "published_date": "2024-10-19 09:04:13 UTC",
    "updated_date": "2024-10-24 01:25:51 UTC"
  },
  {
    "arxiv_id": "2410.15042v1",
    "title": "Adversarial Training: A Survey",
    "authors": [
      "Mengnan Zhao",
      "Lihe Zhang",
      "Jingwen Ye",
      "Huchuan Lu",
      "Baocai Yin",
      "Xinchao Wang"
    ],
    "abstract": "Adversarial training (AT) refers to integrating adversarial examples --\ninputs altered with imperceptible perturbations that can significantly impact\nmodel predictions -- into the training process. Recent studies have\ndemonstrated the effectiveness of AT in improving the robustness of deep neural\nnetworks against diverse adversarial attacks. However, a comprehensive overview\nof these developments is still missing. This survey addresses this gap by\nreviewing a broad range of recent and representative studies. Specifically, we\nfirst describe the implementation procedures and practical applications of AT,\nfollowed by a comprehensive review of AT techniques from three perspectives:\ndata enhancement, network design, and training configurations. Lastly, we\ndiscuss common challenges in AT and propose several promising directions for\nfuture research.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.15042v1",
    "published_date": "2024-10-19 08:57:35 UTC",
    "updated_date": "2024-10-19 08:57:35 UTC"
  },
  {
    "arxiv_id": "2410.15040v1",
    "title": "Retrieval Augmented Diffusion Model for Structure-informed Antibody Design and Optimization",
    "authors": [
      "Zichen Wang",
      "Yaokun Ji",
      "Jianing Tian",
      "Shuangjia Zheng"
    ],
    "abstract": "Antibodies are essential proteins responsible for immune responses in\norganisms, capable of specifically recognizing antigen molecules of pathogens.\nRecent advances in generative models have significantly enhanced rational\nantibody design. However, existing methods mainly create antibodies from\nscratch without template constraints, leading to model optimization challenges\nand unnatural sequences. To address these issues, we propose a\nretrieval-augmented diffusion framework, termed RADAb, for efficient antibody\ndesign. Our method leverages a set of structural homologous motifs that align\nwith query structural constraints to guide the generative model in inversely\noptimizing antibodies according to desired design criteria. Specifically, we\nintroduce a structure-informed retrieval mechanism that integrates these\nexemplar motifs with the input backbone through a novel dual-branch denoising\nmodule, utilizing both structural and evolutionary information. Additionally,\nwe develop a conditional diffusion model that iteratively refines the\noptimization process by incorporating both global context and local\nevolutionary conditions. Our approach is agnostic to the choice of generative\nmodels. Empirical experiments demonstrate that our method achieves\nstate-of-the-art performance in multiple antibody inverse folding and\noptimization tasks, offering a new perspective on biomolecular generative\nmodels.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.15040v1",
    "published_date": "2024-10-19 08:53:01 UTC",
    "updated_date": "2024-10-19 08:53:01 UTC"
  },
  {
    "arxiv_id": "2410.15038v3",
    "title": "A Multimodal Vision Foundation Model for Clinical Dermatology",
    "authors": [
      "Siyuan Yan",
      "Zhen Yu",
      "Clare Primiero",
      "Cristina Vico-Alonso",
      "Zhonghua Wang",
      "Litao Yang",
      "Philipp Tschandl",
      "Ming Hu",
      "Lie Ju",
      "Gin Tan",
      "Vincent Tang",
      "Aik Beng Ng",
      "David Powell",
      "Paul Bonnington",
      "Simon See",
      "Elisabetta Magnaterra",
      "Peter Ferguson",
      "Jennifer Nguyen",
      "Pascale Guitera",
      "Jose Banuls",
      "Monika Janda",
      "Victoria Mar",
      "Harald Kittler",
      "H. Peter Soyer",
      "Zongyuan Ge"
    ],
    "abstract": "Diagnosing and treating skin diseases require advanced visual skills across\ndomains and the ability to synthesize information from multiple imaging\nmodalities. While current deep learning models excel at specific tasks like\nskin cancer diagnosis from dermoscopic images, they struggle to meet the\ncomplex, multimodal requirements of clinical practice. Here, we introduce\nPanDerm, a multimodal dermatology foundation model pretrained through\nself-supervised learning on over 2 million real-world skin disease images from\n11 clinical institutions across 4 imaging modalities. We evaluated PanDerm on\n28 diverse benchmarks, including skin cancer screening, risk stratification,\ndifferential diagnosis of common and rare skin conditions, lesion segmentation,\nlongitudinal monitoring, and metastasis prediction and prognosis. PanDerm\nachieved state-of-the-art performance across all evaluated tasks, often\noutperforming existing models when using only 10% of labeled data. We conducted\nthree reader studies to assess PanDerm's potential clinical utility. PanDerm\noutperformed clinicians by 10.2% in early-stage melanoma detection through\nlongitudinal analysis, improved clinicians' skin cancer diagnostic accuracy by\n11% on dermoscopy images, and enhanced non-dermatologist healthcare providers'\ndifferential diagnosis by 16.5% across 128 skin conditions on clinical\nphotographs. These results demonstrate PanDerm's potential to improve patient\ncare across diverse clinical scenarios and serve as a model for developing\nmultimodal foundation models in other medical specialties, potentially\naccelerating the integration of AI support in healthcare. The code can be found\nat https://github.com/SiyuanYan1/PanDerm.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "74 pages; Preprint; The code can be found at\n  https://github.com/SiyuanYan1/PanDerm",
    "pdf_url": "http://arxiv.org/pdf/2410.15038v3",
    "published_date": "2024-10-19 08:48:01 UTC",
    "updated_date": "2025-04-13 05:58:18 UTC"
  },
  {
    "arxiv_id": "2410.15029v2",
    "title": "Enhancing Multimodal Sentiment Analysis for Missing Modality through Self-Distillation and Unified Modality Cross-Attention",
    "authors": [
      "Yuzhe Weng",
      "Haotian Wang",
      "Tian Gao",
      "Kewei Li",
      "Shutong Niu",
      "Jun Du"
    ],
    "abstract": "In multimodal sentiment analysis, collecting text data is often more\nchallenging than video or audio due to higher annotation costs and inconsistent\nautomatic speech recognition (ASR) quality. To address this challenge, our\nstudy has developed a robust model that effectively integrates multimodal\nsentiment information, even in the absence of text modality. Specifically, we\nhave developed a Double-Flow Self-Distillation Framework, including Unified\nModality Cross-Attention (UMCA) and Modality Imagination Autoencoder (MIA),\nwhich excels at processing both scenarios with complete modalities and those\nwith missing text modality. In detail, when the text modality is missing, our\nframework uses the LLM-based model to simulate the text representation from the\naudio modality, while the MIA module supplements information from the other two\nmodalities to make the simulated text representation similar to the real text\nrepresentation. To further align the simulated and real representations, and to\nenable the model to capture the continuous nature of sample orders in sentiment\nvalence regression tasks, we have also introduced the Rank-N Contrast (RNC)\nloss function. When testing on the CMU-MOSEI, our model achieved outstanding\nperformance on MAE and significantly outperformed other models when text\nmodality is missing. The code is available at:\nhttps://github.com/WarmCongee/SDUMC",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.15029v2",
    "published_date": "2024-10-19 07:59:41 UTC",
    "updated_date": "2025-03-24 08:50:39 UTC"
  },
  {
    "arxiv_id": "2410.15028v3",
    "title": "A Novel Reinforcement Learning Model for Post-Incident Malware Investigations",
    "authors": [
      "Dipo Dunsin",
      "Mohamed Chahine Ghanem",
      "Karim Ouazzane",
      "Vassil Vassilev"
    ],
    "abstract": "This Research proposes a Novel Reinforcement Learning (RL) model to optimise\nmalware forensics investigation during cyber incident response. It aims to\nimprove forensic investigation efficiency by reducing false negatives and\nadapting current practices to evolving malware signatures. The proposed RL\nframework leverages techniques such as Q-learning and the Markov Decision\nProcess (MDP) to train the system to identify malware patterns in live memory\ndumps, thereby automating forensic tasks. The RL model is based on a detailed\nmalware workflow diagram that guides the analysis of malware artefacts using\nstatic and behavioural techniques as well as machine learning algorithms.\nFurthermore, it seeks to address challenges in the UK justice system by\nensuring the accuracy of forensic evidence. We conduct testing and evaluation\nin controlled environments, using datasets created with Windows operating\nsystems to simulate malware infections. The experimental results demonstrate\nthat RL improves malware detection rates compared to conventional methods, with\nthe RL model's performance varying depending on the complexity and learning\nrate of the environment. The study concludes that while RL offers promising\npotential for automating malware forensics, its efficacy across diverse malware\ntypes requires ongoing refinement of reward systems and feature extraction\nmethods.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "v3, 8 pages. arXiv admin note: substantial text overlap with\n  arXiv:2408.01999",
    "pdf_url": "http://arxiv.org/pdf/2410.15028v3",
    "published_date": "2024-10-19 07:59:10 UTC",
    "updated_date": "2025-01-12 12:24:23 UTC"
  },
  {
    "arxiv_id": "2410.15026v1",
    "title": "A Recommendation Model Utilizing Separation Embedding and Self-Attention for Feature Mining",
    "authors": [
      "Wenyi Liu",
      "Rui Wang",
      "Yuanshuai Luo",
      "Jianjun Wei",
      "Zihao Zhao",
      "Junming Huang"
    ],
    "abstract": "With the explosive growth of Internet data, users are facing the problem of\ninformation overload, which makes it a challenge to efficiently obtain the\nrequired resources. Recommendation systems have emerged in this context. By\nfiltering massive amounts of information, they provide users with content that\nmeets their needs, playing a key role in scenarios such as advertising\nrecommendation and product recommendation. However, traditional click-through\nrate prediction and TOP-K recommendation mechanisms are gradually unable to\nmeet the recommendations needs in modern life scenarios due to high\ncomputational complexity, large memory consumption, long feature selection\ntime, and insufficient feature interaction. This paper proposes a\nrecommendations system model based on a separation embedding cross-network. The\nmodel uses an embedding neural network layer to transform sparse feature\nvectors into dense embedding vectors, and can independently perform feature\ncross operations on different dimensions, thereby improving the accuracy and\ndepth of feature mining. Experimental results show that the model shows\nstronger adaptability and higher prediction accuracy in processing complex data\nsets, effectively solving the problems existing in existing models.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.15026v1",
    "published_date": "2024-10-19 07:49:21 UTC",
    "updated_date": "2024-10-19 07:49:21 UTC"
  },
  {
    "arxiv_id": "2410.15025v1",
    "title": "LLM-Driven Learning Analytics Dashboard for Teachers in EFL Writing Education",
    "authors": [
      "Minsun Kim",
      "SeonGyeom Kim",
      "Suyoun Lee",
      "Yoosang Yoon",
      "Junho Myung",
      "Haneul Yoo",
      "Hyunseung Lim",
      "Jieun Han",
      "Yoonsu Kim",
      "So-Yeon Ahn",
      "Juho Kim",
      "Alice Oh",
      "Hwajung Hong",
      "Tak Yeon Lee"
    ],
    "abstract": "This paper presents the development of a dashboard designed specifically for\nteachers in English as a Foreign Language (EFL) writing education. Leveraging\nLLMs, the dashboard facilitates the analysis of student interactions with an\nessay writing system, which integrates ChatGPT for real-time feedback. The\ndashboard aids teachers in monitoring student behavior, identifying\nnoneducational interaction with ChatGPT, and aligning instructional strategies\nwith learning objectives. By combining insights from NLP and Human-Computer\nInteraction (HCI), this study demonstrates how a human-centered approach can\nenhance the effectiveness of teacher dashboards, particularly in\nChatGPT-integrated learning.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "EMNLP 2024 Workshop CustomNLP4U. arXiv admin note: text overlap with\n  arXiv:2405.19691",
    "pdf_url": "http://arxiv.org/pdf/2410.15025v1",
    "published_date": "2024-10-19 07:46:11 UTC",
    "updated_date": "2024-10-19 07:46:11 UTC"
  },
  {
    "arxiv_id": "2410.15017v1",
    "title": "DM-Codec: Distilling Multimodal Representations for Speech Tokenization",
    "authors": [
      "Md Mubtasim Ahasan",
      "Md Fahim",
      "Tasnim Mohiuddin",
      "A K M Mahbubur Rahman",
      "Aman Chadha",
      "Tariq Iqbal",
      "M Ashraful Amin",
      "Md Mofijul Islam",
      "Amin Ahsan Ali"
    ],
    "abstract": "Recent advancements in speech-language models have yielded significant\nimprovements in speech tokenization and synthesis. However, effectively mapping\nthe complex, multidimensional attributes of speech into discrete tokens remains\nchallenging. This process demands acoustic, semantic, and contextual\ninformation for precise speech representations. Existing speech representations\ngenerally fall into two categories: acoustic tokens from audio codecs and\nsemantic tokens from speech self-supervised learning models. Although recent\nefforts have unified acoustic and semantic tokens for improved performance,\nthey overlook the crucial role of contextual representation in comprehensive\nspeech modeling. Our empirical investigations reveal that the absence of\ncontextual representations results in elevated Word Error Rate (WER) and Word\nInformation Lost (WIL) scores in speech transcriptions. To address these\nlimitations, we propose two novel distillation approaches: (1) a language model\n(LM)-guided distillation method that incorporates contextual information, and\n(2) a combined LM and self-supervised speech model (SM)-guided distillation\ntechnique that effectively distills multimodal representations (acoustic,\nsemantic, and contextual) into a comprehensive speech tokenizer, termed\nDM-Codec. The DM-Codec architecture adopts a streamlined encoder-decoder\nframework with a Residual Vector Quantizer (RVQ) and incorporates the LM and SM\nduring the training process. Experiments show DM-Codec significantly\noutperforms state-of-the-art speech tokenization models, reducing WER by up to\n13.46%, WIL by 9.82%, and improving speech quality by 5.84% and intelligibility\nby 1.85% on the LibriSpeech benchmark dataset. The code, samples, and model\ncheckpoints are available at https://github.com/mubtasimahasan/DM-Codec.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.SD",
      "eess.AS"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.15017v1",
    "published_date": "2024-10-19 07:14:14 UTC",
    "updated_date": "2024-10-19 07:14:14 UTC"
  },
  {
    "arxiv_id": "2410.15016v1",
    "title": "Transit Pulse: Utilizing Social Media as a Source for Customer Feedback and Information Extraction with Large Language Model",
    "authors": [
      "Jiahao Wang",
      "Amer Shalaby"
    ],
    "abstract": "Users of the transit system flood social networks daily with messages that\ncontain valuable insights crucial for improving service quality. These posts\nhelp transit agencies quickly identify emerging issues. Parsing topics and\nsentiments is key to gaining comprehensive insights to foster service\nexcellence. However, the volume of messages makes manual analysis impractical,\nand standard NLP techniques like Term Frequency-Inverse Document Frequency\n(TF-IDF) fall short in nuanced interpretation. Traditional sentiment analysis\nseparates topics and sentiments before integrating them, often missing the\ninteraction between them. This incremental approach complicates classification\nand reduces analytical productivity. To address these challenges, we propose a\nnovel approach to extracting and analyzing transit-related information,\nincluding sentiment and sarcasm detection, identification of unusual system\nproblems, and location data from social media. Our method employs Large\nLanguage Models (LLM), specifically Llama 3, for a streamlined analysis free\nfrom pre-established topic labels. To enhance the model's domain-specific\nknowledge, we utilize Retrieval-Augmented Generation (RAG), integrating\nexternal knowledge sources into the information extraction pipeline. We\nvalidated our method through extensive experiments comparing its performance\nwith traditional NLP approaches on user tweet data from the real world transit\nsystem. Our results demonstrate the potential of LLMs to transform social media\ndata analysis in the public transit domain, providing actionable insights and\nenhancing transit agencies' responsiveness by extracting a broader range of\ninformation.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CY",
      "cs.IR",
      "cs.LG",
      "cs.SI"
    ],
    "primary_category": "cs.CL",
    "comment": "17 pages, 21 figures",
    "pdf_url": "http://arxiv.org/pdf/2410.15016v1",
    "published_date": "2024-10-19 07:08:40 UTC",
    "updated_date": "2024-10-19 07:08:40 UTC"
  },
  {
    "arxiv_id": "2410.15013v1",
    "title": "DST-TransitNet: A Dynamic Spatio-Temporal Deep Learning Model for Scalable and Efficient Network-Wide Prediction of Station-Level Transit Ridership",
    "authors": [
      "Jiahao Wang",
      "Amer Shalaby"
    ],
    "abstract": "Accurate prediction of public transit ridership is vital for efficient\nplanning and management of transit in rapidly growing urban areas in Canada.\nUnexpected increases in passengers can cause overcrowded vehicles, longer\nboarding times, and service disruptions. Traditional time series models like\nARIMA and SARIMA face limitations, particularly in short-term predictions and\nintegration of spatial and temporal features. These models struggle with the\ndynamic nature of ridership patterns and often ignore spatial correlations\nbetween nearby stops. Deep Learning (DL) models present a promising\nalternative, demonstrating superior performance in short-term prediction tasks\nby effectively capturing both spatial and temporal features. However,\nchallenges such as dynamic spatial feature extraction, balancing accuracy with\ncomputational efficiency, and ensuring scalability remain.\n  This paper introduces DST-TransitNet, a hybrid DL model for system-wide\nstation-level ridership prediction. This proposed model uses graph neural\nnetworks (GNN) and recurrent neural networks (RNN) to dynamically integrate the\nchanging temporal and spatial correlations within the stations. The model also\nemploys a precise time series decomposition framework to enhance accuracy and\ninterpretability. Tested on Bogota's BRT system data, with three distinct\nsocial scenarios, DST-TransitNet outperformed state-of-the-art models in\nprecision, efficiency and robustness. Meanwhile, it maintains stability over\nlong prediction intervals, demonstrating practical applicability.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CY",
      "cs.SI"
    ],
    "primary_category": "cs.LG",
    "comment": "16 pages, 22 figures. Accepted by TRB 2025",
    "pdf_url": "http://arxiv.org/pdf/2410.15013v1",
    "published_date": "2024-10-19 06:59:39 UTC",
    "updated_date": "2024-10-19 06:59:39 UTC"
  },
  {
    "arxiv_id": "2410.15012v1",
    "title": "Pathologist-like explainable AI for interpretable Gleason grading in prostate cancer",
    "authors": [
      "Gesa Mittmann",
      "Sara Laiouar-Pedari",
      "Hendrik A. Mehrtens",
      "Sarah Haggenmüller",
      "Tabea-Clara Bucher",
      "Tirtha Chanda",
      "Nadine T. Gaisa",
      "Mathias Wagner",
      "Gilbert Georg Klamminger",
      "Tilman T. Rau",
      "Christina Neppl",
      "Eva Maria Compérat",
      "Andreas Gocht",
      "Monika Hämmerle",
      "Niels J. Rupp",
      "Jula Westhoff",
      "Irene Krücken",
      "Maximillian Seidl",
      "Christian M. Schürch",
      "Marcus Bauer",
      "Wiebke Solass",
      "Yu Chun Tam",
      "Florian Weber",
      "Rainer Grobholz",
      "Jaroslaw Augustyniak",
      "Thomas Kalinski",
      "Christian Hörner",
      "Kirsten D. Mertz",
      "Constanze Döring",
      "Andreas Erbersdobler",
      "Gabriele Deubler",
      "Felix Bremmer",
      "Ulrich Sommer",
      "Michael Brodhun",
      "Jon Griffin",
      "Maria Sarah L. Lenon",
      "Kiril Trpkov",
      "Liang Cheng",
      "Fei Chen",
      "Angelique Levi",
      "Guoping Cai",
      "Tri Q. Nguyen",
      "Ali Amin",
      "Alessia Cimadamore",
      "Ahmed Shabaik",
      "Varsha Manucha",
      "Nazeel Ahmad",
      "Nidia Messias",
      "Francesca Sanguedolce",
      "Diana Taheri",
      "Ezra Baraban",
      "Liwei Jia",
      "Rajal B. Shah",
      "Farshid Siadat",
      "Nicole Swarbrick",
      "Kyung Park",
      "Oudai Hassan",
      "Siamak Sakhaie",
      "Michelle R. Downes",
      "Hiroshi Miyamoto",
      "Sean R. Williamson",
      "Tim Holland-Letz",
      "Carolin V. Schneider",
      "Jakob Nikolas Kather",
      "Yuri Tolkach",
      "Titus J. Brinker"
    ],
    "abstract": "The aggressiveness of prostate cancer, the most common cancer in men\nworldwide, is primarily assessed based on histopathological data using the\nGleason scoring system. While artificial intelligence (AI) has shown promise in\naccurately predicting Gleason scores, these predictions often lack inherent\nexplainability, potentially leading to distrust in human-machine interactions.\nTo address this issue, we introduce a novel dataset of 1,015 tissue microarray\ncore images, annotated by an international group of 54 pathologists. The\nannotations provide detailed localized pattern descriptions for Gleason grading\nin line with international guidelines. Utilizing this dataset, we develop an\ninherently explainable AI system based on a U-Net architecture that provides\npredictions leveraging pathologists' terminology. This approach circumvents\npost-hoc explainability methods while maintaining or exceeding the performance\nof methods trained directly for Gleason pattern segmentation (Dice score: 0.713\n$\\pm$ 0.003 trained on explanations vs. 0.691 $\\pm$ 0.010 trained on Gleason\npatterns). By employing soft labels during training, we capture the intrinsic\nuncertainty in the data, yielding strong results in Gleason pattern\nsegmentation even in the context of high interobserver variability. With the\nrelease of this dataset, we aim to encourage further research into segmentation\nin medical tasks with high levels of subjectivity and to advance the\nunderstanding of pathologists' reasoning processes.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "58 pages, 15 figures (incl. supplementary)",
    "pdf_url": "http://arxiv.org/pdf/2410.15012v1",
    "published_date": "2024-10-19 06:58:26 UTC",
    "updated_date": "2024-10-19 06:58:26 UTC"
  },
  {
    "arxiv_id": "2410.15010v1",
    "title": "FlexMol: A Flexible Toolkit for Benchmarking Molecular Relational Learning",
    "authors": [
      "Sizhe Liu",
      "Jun Xia",
      "Lecheng Zhang",
      "Yuchen Liu",
      "Yue Liu",
      "Wenjie Du",
      "Zhangyang Gao",
      "Bozhen Hu",
      "Cheng Tan",
      "Hongxin Xiang",
      "Stan Z. Li"
    ],
    "abstract": "Molecular relational learning (MRL) is crucial for understanding the\ninteraction behaviors between molecular pairs, a critical aspect of drug\ndiscovery and development. However, the large feasible model space of MRL poses\nsignificant challenges to benchmarking, and existing MRL frameworks face\nlimitations in flexibility and scope. To address these challenges, avoid\nrepetitive coding efforts, and ensure fair comparison of models, we introduce\nFlexMol, a comprehensive toolkit designed to facilitate the construction and\nevaluation of diverse model architectures across various datasets and\nperformance metrics. FlexMol offers a robust suite of preset model components,\nincluding 16 drug encoders, 13 protein sequence encoders, 9 protein structure\nencoders, and 7 interaction layers. With its easy-to-use API and flexibility,\nFlexMol supports the dynamic construction of over 70, 000 distinct combinations\nof model architectures. Additionally, we provide detailed benchmark results and\ncode examples to demonstrate FlexMol's effectiveness in simplifying and\nstandardizing MRL model development and comparison.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.15010v1",
    "published_date": "2024-10-19 06:53:11 UTC",
    "updated_date": "2024-10-19 06:53:11 UTC"
  },
  {
    "arxiv_id": "2410.14998v1",
    "title": "A comparative study of NeuralODE and Universal ODE approaches to solving Chandrasekhar White Dwarf equation",
    "authors": [
      "Raymundo Vazquez Martinez",
      "Raj Abhijit Dandekar",
      "Rajat Dandekar",
      "Sreedath Panat"
    ],
    "abstract": "In this study, we apply two pillars of Scientific Machine Learning: Neural\nOrdinary Differential Equations (Neural ODEs) and Universal Differential\nEquations (UDEs) to the Chandrasekhar White Dwarf Equation (CWDE). The CWDE is\nfundamental for understanding the life cycle of a star, and describes the\nrelationship between the density of the white dwarf and its distance from the\ncenter. Despite the rise in Scientific Machine Learning frameworks, very less\nattention has been paid to the systematic applications of the above SciML\npillars on astronomy based ODEs. Through robust modeling in the Julia\nprogramming language, we show that both Neural ODEs and UDEs can be used\neffectively for both prediction as well as forecasting of the CWDE. More\nimportantly, we introduce the forecasting breakdown point - the time at which\nforecasting fails for both Neural ODEs and UDEs. Through a robust\nhyperparameter optimization testing, we provide insights on the neural network\narchitecture, activation functions and optimizers which provide the best\nresults. This study provides opens a door to investigate the applicability of\nScientific Machine Learning frameworks in forecasting tasks for a wide range of\nscientific domains.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.14998v1",
    "published_date": "2024-10-19 06:13:32 UTC",
    "updated_date": "2024-10-19 06:13:32 UTC"
  },
  {
    "arxiv_id": "2410.14997v2",
    "title": "Improving Pronunciation and Accent Conversion through Knowledge Distillation And Synthetic Ground-Truth from Native TTS",
    "authors": [
      "Tuan Nam Nguyen",
      "Seymanur Akti",
      "Ngoc Quan Pham",
      "Alexander Waibel"
    ],
    "abstract": "Previous approaches on accent conversion (AC) mainly aimed at making\nnon-native speech sound more native while maintaining the original content and\nspeaker identity. However, non-native speakers sometimes have pronunciation\nissues, which can make it difficult for listeners to understand them. Hence, we\ndeveloped a new AC approach that not only focuses on accent conversion but also\nimproves pronunciation of non-native accented speaker. By providing the\nnon-native audio and the corresponding transcript, we generate the ideal\nground-truth audio with native-like pronunciation with original duration and\nprosody. This ground-truth data aids the model in learning a direct mapping\nbetween accented and native speech. We utilize the end-to-end VITS framework to\nachieve high-quality waveform reconstruction for the AC task. As a result, our\nsystem not only produces audio that closely resembles native accents and while\nretaining the original speaker's identity but also improve pronunciation, as\ndemonstrated by evaluation results.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "accepted at ICASSP 2025",
    "pdf_url": "http://arxiv.org/pdf/2410.14997v2",
    "published_date": "2024-10-19 06:12:31 UTC",
    "updated_date": "2025-03-04 13:17:59 UTC"
  },
  {
    "arxiv_id": "2410.14989v1",
    "title": "AutoFPDesigner: Automated Flight Procedure Design Based on Multi-Agent Large Language Model",
    "authors": [
      "Longtao Zhu",
      "Hongyu Yang",
      "Ge Song",
      "Xin Ma",
      "Yanxin Zhang",
      "Yulong Ji"
    ],
    "abstract": "Current flight procedure design methods heavily rely on human-led design\nprocess, which is not only low auto-mation but also suffer from complex\nalgorithm modelling and poor generalization. To address these challenges, this\npaper proposes an agent-driven flight procedure design method based on large\nlanguage model, named Au-toFPDesigner, which utilizes multi-agent collaboration\nto complete procedure design. The method enables end-to-end automated design of\nperformance-based navigation (PBN) procedures. In this process, the user input\nthe design requirements in natural language, AutoFPDesigner models the flight\nprocedure design by loading the design speci-fications and utilizing tool\nlibraries complete the design. AutoFPDesigner allows users to oversee and\nseamlessly participate in the design process. Experimental results show that\nAutoFPDesigner ensures nearly 100% safety in the designed flight procedures and\nachieves 75% task completion rate, with good adaptability across different\ndesign tasks. AutoFPDesigner introduces a new paradigm for flight procedure\ndesign and represents a key step towards the automation of this process.\nKeywords: Flight Procedure Design; Large Language Model; Performance-Based\nNavigation (PBN); Multi Agent;",
    "categories": [
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.AI",
    "comment": "21 pages, 18 figures, 5 tables",
    "pdf_url": "http://arxiv.org/pdf/2410.14989v1",
    "published_date": "2024-10-19 05:41:11 UTC",
    "updated_date": "2024-10-19 05:41:11 UTC"
  },
  {
    "arxiv_id": "2410.14986v1",
    "title": "NeuralMAG: Fast and Generalizable Micromagnetic Simulation with Deep Neural Nets",
    "authors": [
      "Yunqi Cai",
      "Jiangnan Li",
      "Dong Wang"
    ],
    "abstract": "Micromagnetics has made significant strides, particularly due to its\nwide-ranging applications in magnetic storage design. Numerical simulation is a\ncornerstone of micromagnetics research, relying on first-principle rules to\ncompute the dynamic evolution of micromagnetic systems based on the renowned\nLLG equation, named after Landau, Lifshitz, and Gilbert. However, simulations\nare often hindered by their slow speed. Although Fast-Fourier transformation\n(FFT) calculations reduce the computational complexity to O(NlogN), it remains\nimpractical for large-scale simulations. In this paper, we introduce NeuralMAG,\na deep learning approach to micromagnetic simulation. Our approach follows the\nLLG iterative framework but accelerates demagnetizing field computation through\nthe employment of a U-shaped neural network (Unet). The Unet architecture\ncomprises an encoder that extracts aggregated spins at various scales and\nlearns the local interaction at each scale, followed by a decoder that\naccumulates the local interactions at different scales to approximate the\nglobal convolution. This divide-and-accumulate scheme achieves a time\ncomplexity of O(N), significantly enhancing the speed and feasibility of\nlarge-scale simulations. Unlike existing neural methods, NeuralMAG concentrates\non the core computation rather than an end-to-end approximation for a specific\ntask, making it inherently generalizable. To validate the new approach, we\ntrained a single model and evaluated it on two micromagnetics tasks with\nvarious sample sizes, shapes, and material settings.",
    "categories": [
      "cs.LG",
      "cond-mat.mes-hall",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.14986v1",
    "published_date": "2024-10-19 05:25:08 UTC",
    "updated_date": "2024-10-19 05:25:08 UTC"
  },
  {
    "arxiv_id": "2410.14979v5",
    "title": "Do Large Language Models Truly Grasp Mathematics? An Empirical Exploration From Cognitive Psychology",
    "authors": [
      "Wei Xie",
      "Shuoyoucheng Ma",
      "Zhenhua Wang",
      "Enze Wang",
      "Kai Chen",
      "Xiaobing Sun",
      "Baosheng Wang"
    ],
    "abstract": "The cognitive mechanism by which Large Language Models (LLMs) solve\nmathematical problems remains a widely debated and unresolved issue. Currently,\nthere is little interpretable experimental evidence that connects LLMs'\nproblem-solving with human cognitive psychology.To determine if LLMs possess\nhuman-like mathematical reasoning, we modified the problems used in the human\nCognitive Reflection Test (CRT). Our results show that, even with the use of\nChains of Thought (CoT) prompts, mainstream LLMs, including the latest o1 model\n(noted for its reasoning capabilities), have a high error rate when solving\nthese modified CRT problems. Specifically, the average accuracy rate dropped by\nup to 50% compared to the original questions.Further analysis of LLMs'\nincorrect answers suggests that they primarily rely on pattern matching from\ntheir training data, which aligns more with human intuition (System 1 thinking)\nrather than with human-like reasoning (System 2 thinking). This finding\nchallenges the belief that LLMs have genuine mathematical reasoning abilities\ncomparable to humans. As a result, this work may adjust overly optimistic views\non LLMs' progress towards artificial general intelligence.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.14979v5",
    "published_date": "2024-10-19 05:01:56 UTC",
    "updated_date": "2024-11-15 12:46:30 UTC"
  },
  {
    "arxiv_id": "2410.14975v2",
    "title": "Reflexive Guidance: Improving OoDD in Vision-Language Models via Self-Guided Image-Adaptive Concept Generation",
    "authors": [
      "Jihyo Kim",
      "Seulbi Lee",
      "Sangheum Hwang"
    ],
    "abstract": "With the recent emergence of foundation models trained on internet-scale data\nand demonstrating remarkable generalization capabilities, such foundation\nmodels have become more widely adopted, leading to an expanding range of\napplication domains. Despite this rapid proliferation, the trustworthiness of\nfoundation models remains underexplored. Specifically, the out-of-distribution\ndetection (OoDD) capabilities of large vision-language models (LVLMs), such as\nGPT-4o, which are trained on massive multi-modal data, have not been\nsufficiently addressed. The disparity between their demonstrated potential and\npractical reliability raises concerns regarding the safe and trustworthy\ndeployment of foundation models. To address this gap, we evaluate and analyze\nthe OoDD capabilities of various proprietary and open-source LVLMs. Our\ninvestigation contributes to a better understanding of how these foundation\nmodels represent confidence scores through their generated natural language\nresponses. Furthermore, we propose a self-guided prompting approach, termed\nReflexive Guidance (ReGuide), aimed at enhancing the OoDD capability of LVLMs\nby leveraging self-generated image-adaptive concept suggestions. Experimental\nresults demonstrate that our ReGuide enhances the performance of current LVLMs\nin both image classification and OoDD tasks. The lists of sampled images, along\nwith the prompts and responses for each sample are available at\nhttps://github.com/daintlab/ReGuide.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted at ICLR 2025. The first two authors contributed equally",
    "pdf_url": "http://arxiv.org/pdf/2410.14975v2",
    "published_date": "2024-10-19 04:46:51 UTC",
    "updated_date": "2025-02-08 20:38:33 UTC"
  },
  {
    "arxiv_id": "2410.14971v2",
    "title": "BrainECHO: Semantic Brain Signal Decoding through Vector-Quantized Spectrogram Reconstruction for Whisper-Enhanced Text Generation",
    "authors": [
      "Jilong Li",
      "Zhenxi Song",
      "Jiaqi Wang",
      "Meishan Zhang",
      "Honghai Liu",
      "Min Zhang",
      "Zhiguo Zhang"
    ],
    "abstract": "Current EEG/MEG-to-text decoding systems suffer from three key limitations:\n(1) reliance on teacher-forcing methods, which compromises robustness during\ninference, (2) sensitivity to session-specific noise, hindering generalization\nacross subjects, and (3) misalignment between brain signals and linguistic\nrepresentations due to pre-trained language model over-dominance. To overcome\nthese challenges, we propose BrainECHO (Brain signal decoding via\nvEctor-quantized speCtrogram reconstruction for WHisper-enhanced text\ngeneratiOn), a multi-stage framework that employs decoupled representation\nlearning to achieve state-of-the-art performance on both EEG and MEG datasets.\nSpecifically, BrainECHO consists of three stages: (1) Discrete autoencoding,\nwhich transforms continuous Mel spectrograms into a finite set of high-quality\ndiscrete representations for subsequent stages. (2) Frozen alignment, where\nbrain signal embeddings are mapped to corresponding Mel spectrogram embeddings\nin a frozen latent space, effectively filtering session-specific noise through\nvector-quantized reconstruction, yielding a 3.65% improvement in BLEU-4 score.\n(3) Constrained decoding fine-tuning, which leverages the pre-trained Whisper\nmodel for audio-to-text translation, balancing signal adaptation with knowledge\npreservation, and achieving 74%-89% decoding BLEU scores without excessive\nreliance on teacher forcing. BrainECHO demonstrates robustness across sentence,\nsession, and subject-independent conditions, passing Gaussian noise tests and\nshowcasing its potential for enhancing language-based brain-computer\ninterfaces.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.SD",
      "eess.AS"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.14971v2",
    "published_date": "2024-10-19 04:29:03 UTC",
    "updated_date": "2025-05-19 08:17:48 UTC"
  },
  {
    "arxiv_id": "2410.14970v4",
    "title": "Taming the Long Tail in Human Mobility Prediction",
    "authors": [
      "Xiaohang Xu",
      "Renhe Jiang",
      "Chuang Yang",
      "Zipei Fan",
      "Kaoru Sezaki"
    ],
    "abstract": "With the popularity of location-based services, human mobility prediction\nplays a key role in enhancing personalized navigation, optimizing\nrecommendation systems, and facilitating urban mobility and planning. This\ninvolves predicting a user's next POI (point-of-interest) visit using their\npast visit history. However, the uneven distribution of visitations over time\nand space, namely the long-tail problem in spatial distribution, makes it\ndifficult for AI models to predict those POIs that are less visited by humans.\nIn light of this issue, we propose the Long-Tail Adjusted Next POI Prediction\n(LoTNext) framework for mobility prediction, combining a Long-Tailed Graph\nAdjustment module to reduce the impact of the long-tailed nodes in the user-POI\ninteraction graph and a novel Long-Tailed Loss Adjustment module to adjust loss\nby logit score and sample weight adjustment strategy. Also, we employ the\nauxiliary prediction task to enhance generalization and accuracy. Our\nexperiments with two real-world trajectory datasets demonstrate that LoTNext\nsignificantly surpasses existing state-of-the-art works.",
    "categories": [
      "cs.SI",
      "cs.AI",
      "cs.CY",
      "cs.LG"
    ],
    "primary_category": "cs.SI",
    "comment": "Accepted by NeurIPS 2024",
    "pdf_url": "http://arxiv.org/pdf/2410.14970v4",
    "published_date": "2024-10-19 04:28:44 UTC",
    "updated_date": "2025-01-15 15:35:22 UTC"
  },
  {
    "arxiv_id": "2410.17094v1",
    "title": "Team Ryu's Submission to SIGMORPHON 2024 Shared Task on Subword Tokenization",
    "authors": [
      "Zilong Li"
    ],
    "abstract": "This papers presents the submission of team Ryu to the canceled SIGMORPHON\n2024 shared task on subword tokenization. My submission explores whether\nmorphological segmentation methods can be used as a part of subword tokenizers.\nI adopt two approaches: the statistical segmentation method Morfessor and a\ntransformer based sequence-to-sequence (seq2seq) segmentation model in\ntokenizers. The prediction results show that morphological segmentation could\nbe as effective as commonly used subword tokenizers. Additionally, I\ninvestigate how a tokenizer's vocabulary influences the performance of language\nmodels. A tokenizer with a balanced token frequency distribution tends to work\nbetter. A balanced token vocabulary can be achieved by keeping frequent words\nas unique tokens.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.17094v1",
    "published_date": "2024-10-19 04:06:09 UTC",
    "updated_date": "2024-10-19 04:06:09 UTC"
  },
  {
    "arxiv_id": "2410.14961v1",
    "title": "LangGFM: A Large Language Model Alone Can be a Powerful Graph Foundation Model",
    "authors": [
      "Tianqianjin Lin",
      "Pengwei Yan",
      "Kaisong Song",
      "Zhuoren Jiang",
      "Yangyang Kang",
      "Jun Lin",
      "Weikang Yuan",
      "Junjie Cao",
      "Changlong Sun",
      "Xiaozhong Liu"
    ],
    "abstract": "Graph foundation models (GFMs) have recently gained significant attention.\nHowever, the unique data processing and evaluation setups employed by different\nstudies hinder a deeper understanding of their progress. Additionally, current\nresearch tends to focus on specific subsets of graph learning tasks, such as\nstructural tasks, node-level tasks, or classification tasks. As a result, they\noften incorporate specialized modules tailored to particular task types, losing\ntheir applicability to other graph learning tasks and contradicting the\noriginal intent of foundation models to be universal. Therefore, to enhance\nconsistency, coverage, and diversity across domains, tasks, and research\ninterests within the graph learning community in the evaluation of GFMs, we\npropose GFMBench-a systematic and comprehensive benchmark comprising 26\ndatasets. Moreover, we introduce LangGFM, a novel GFM that relies entirely on\nlarge language models. By revisiting and exploring the effective graph\ntextualization principles, as well as repurposing successful techniques from\ngraph augmentation and graph self-supervised learning within the language\nspace, LangGFM achieves performance on par with or exceeding the state of the\nart across GFMBench, which can offer us new perspectives, experiences, and\nbaselines to drive forward the evolution of GFMs.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.SI"
    ],
    "primary_category": "cs.LG",
    "comment": "under review",
    "pdf_url": "http://arxiv.org/pdf/2410.14961v1",
    "published_date": "2024-10-19 03:27:19 UTC",
    "updated_date": "2024-10-19 03:27:19 UTC"
  },
  {
    "arxiv_id": "2410.14957v2",
    "title": "Offline-to-online Reinforcement Learning for Image-based Grasping with Scarce Demonstrations",
    "authors": [
      "Bryan Chan",
      "Anson Leung",
      "James Bergstra"
    ],
    "abstract": "Offline-to-online reinforcement learning (O2O RL) aims to obtain a\ncontinually improving policy as it interacts with the environment, while\nensuring the initial policy behaviour is satisficing. This satisficing\nbehaviour is necessary for robotic manipulation where random exploration can be\ncostly due to catastrophic failures and time. O2O RL is especially compelling\nwhen we can only obtain a scarce amount of (potentially suboptimal)\ndemonstrations$\\unicode{x2014}$a scenario where behavioural cloning (BC) is\nknown to suffer from distribution shift. Previous works have outlined the\nchallenges in applying O2O RL algorithms under the image-based environments. In\nthis work, we propose a novel O2O RL algorithm that can learn in a real-life\nimage-based robotic vacuum grasping task with a small number of demonstrations\nwhere BC fails majority of the time. The proposed algorithm replaces the target\nnetwork in off-policy actor-critic algorithms with a regularization technique\ninspired by neural tangent kernel. We demonstrate that the proposed algorithm\ncan reach above 90\\% success rate in under two hours of interaction time, with\nonly 50 human demonstrations, while BC and existing commonly-used RL algorithms\nfail to achieve similar performance.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "In CoRL Workshop on Mastering Robot Manipulation in a World of\n  Abundant Data 2024",
    "pdf_url": "http://arxiv.org/pdf/2410.14957v2",
    "published_date": "2024-10-19 03:08:10 UTC",
    "updated_date": "2025-01-22 22:15:13 UTC"
  },
  {
    "arxiv_id": "2410.14951v1",
    "title": "LSS-SKAN: Efficient Kolmogorov-Arnold Networks based on Single-Parameterized Function",
    "authors": [
      "Zhijie Chen",
      "Xinglin Zhang"
    ],
    "abstract": "The recently proposed Kolmogorov-Arnold Networks (KAN) networks have\nattracted increasing attention due to their advantage of high visualizability\ncompared to MLP. In this paper, based on a series of small-scale experiments,\nwe proposed the Efficient KAN Expansion Principle (EKE Principle): allocating\nparameters to expand network scale, rather than employing more complex basis\nfunctions, leads to more efficient performance improvements in KANs. Based on\nthis principle, we proposed a superior KAN termed SKAN, where the basis\nfunction utilizes only a single learnable parameter. We then evaluated various\nsingle-parameterized functions for constructing SKANs, with LShifted\nSoftplus-based SKANs (LSS-SKANs) demonstrating superior accuracy. Subsequently,\nextensive experiments were performed, comparing LSS-SKAN with other KAN\nvariants on the MNIST dataset. In the final accuracy tests, LSS-SKAN exhibited\nsuperior performance on the MNIST dataset compared to all tested pure KAN\nvariants. Regarding execution speed, LSS-SKAN outperformed all compared popular\nKAN variants. Our experimental codes are available at\nhttps://github.com/chikkkit/LSS-SKAN and SKAN's Python library (for quick\nconstruction of SKAN in python) codes are available at\nhttps://github.com/chikkkit/SKAN .",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "25 pages, 14 figures, experiment codes are available at\n  https://github.com/chikkkit/LSS-SKAN , and SKAN's Python library code are\n  available at https://github.com/chikkkit/SKAN",
    "pdf_url": "http://arxiv.org/pdf/2410.14951v1",
    "published_date": "2024-10-19 02:44:35 UTC",
    "updated_date": "2024-10-19 02:44:35 UTC"
  },
  {
    "arxiv_id": "2410.14947v1",
    "title": "Optimally Solving Colored Generalized Sliding-Tile Puzzles: Complexity and Bounds",
    "authors": [
      "Marcus Gozon",
      "Jingjin Yu"
    ],
    "abstract": "The Generalized Sliding-Tile Puzzle (GSTP), allowing many square tiles on a\nboard to move in parallel while enforcing natural geometric collision\nconstraints on the movement of neighboring tiles, provide a high-fidelity\nmathematical model for many high-utility existing and future multi-robot\napplications, e.g., at mobile robot-based warehouses or autonomous garages.\nMotivated by practical relevance, this work examines a further generalization\nof GSTP called the Colored Generalized Sliding-Tile Puzzle (CGSP), where tiles\ncan now assume varying degrees of distinguishability, a common occurrence in\nthe aforementioned applications. Our study establishes the computational\ncomplexity of CGSP and its key sub-problems under a broad spectrum of possible\nconditions and characterizes solution makespan lower and upper bounds that\ndiffer by at most a logarithmic factor. These results are further extended to\nhigher-dimensional versions of the puzzle game.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.MA"
    ],
    "primary_category": "cs.RO",
    "comment": "WAFR 2024 Conference Version",
    "pdf_url": "http://arxiv.org/pdf/2410.14947v1",
    "published_date": "2024-10-19 02:34:13 UTC",
    "updated_date": "2024-10-19 02:34:13 UTC"
  },
  {
    "arxiv_id": "2410.14946v2",
    "title": "DEL-Ranking: Ranking-Correction Denoising Framework for Elucidating Molecular Affinities in DNA-Encoded Libraries",
    "authors": [
      "Hanqun Cao",
      "Mutian He",
      "Ning Ma",
      "Chang-yu Hsieh",
      "Chunbin Gu",
      "Pheng-Ann Heng"
    ],
    "abstract": "DNA-encoded library (DEL) screening has revolutionized the detection of\nprotein-ligand interactions through read counts, enabling rapid exploration of\nvast chemical spaces. However, noise in read counts, stemming from nonspecific\ninteractions, can mislead this exploration process. We present DEL-Ranking, a\nnovel distribution-correction denoising framework that addresses these\nchallenges. Our approach introduces two key innovations: (1) a novel ranking\nloss that rectifies relative magnitude relationships between read counts,\nenabling the learning of causal features determining activity levels, and (2)\nan iterative algorithm employing self-training and consistency loss to\nestablish model coherence between activity label and read count predictions.\nFurthermore, we contribute three new DEL screening datasets, the first to\ncomprehensively include multi-dimensional molecular representations,\nprotein-ligand enrichment values, and their activity labels. These datasets\nmitigate data scarcity issues in AI-driven DEL screening research. Rigorous\nevaluation on diverse DEL datasets demonstrates DEL-Ranking's superior\nperformance across multiple correlation metrics, with significant improvements\nin binding affinity prediction accuracy. Our model exhibits zero-shot\ngeneralization ability across different protein targets and successfully\nidentifies potential motifs determining compound binding affinity. This work\nadvances DEL screening analysis and provides valuable resources for future\nresearch in this area.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "q-bio.BM"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.14946v2",
    "published_date": "2024-10-19 02:32:09 UTC",
    "updated_date": "2024-12-04 07:58:40 UTC"
  },
  {
    "arxiv_id": "2410.14929v1",
    "title": "Water quality polluted by total suspended solids classified within an Artificial Neural Network approach",
    "authors": [
      "I. Luviano Soto",
      "Y. Concha Sánchez",
      "A. Raya"
    ],
    "abstract": "This study investigates the application of an artificial neural network\nframework for analysing water pollution caused by solids. Water pollution by\nsuspended solids poses significant environmental and health risks. Traditional\nmethods for assessing and predicting pollution levels are often time-consuming\nand resource-intensive. To address these challenges, we developed a model that\nleverages a comprehensive dataset of water quality from total suspended solids.\nA convolutional neural network was trained under a transfer learning approach\nusing data corresponding to different total suspended solids concentrations,\nwith the goal of accurately predicting low, medium and high pollution levels\nbased on various input variables. Our model demonstrated high predictive\naccuracy, outperforming conventional statistical methods in terms of both speed\nand reliability. The results suggest that the artificial neural network\nframework can serve as an effective tool for real-time monitoring and\nmanagement of water pollution, facilitating proactive decision-making and\npolicy formulation. This approach not only enhances our understanding of\npollution dynamics but also underscores the potential of machine learning\ntechniques in environmental science.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV",
      "Machine Learning"
    ],
    "primary_category": "cs.LG",
    "comment": "42 pages, 8 figures and 2 tables",
    "pdf_url": "http://arxiv.org/pdf/2410.14929v1",
    "published_date": "2024-10-19 01:33:08 UTC",
    "updated_date": "2024-10-19 01:33:08 UTC"
  },
  {
    "arxiv_id": "2410.14916v1",
    "title": "Cooperation and Fairness in Multi-Agent Reinforcement Learning",
    "authors": [
      "Jasmine Jerry Aloor",
      "Siddharth Nayak",
      "Sydney Dolan",
      "Hamsa Balakrishnan"
    ],
    "abstract": "Multi-agent systems are trained to maximize shared cost objectives, which\ntypically reflect system-level efficiency. However, in the resource-constrained\nenvironments of mobility and transportation systems, efficiency may be achieved\nat the expense of fairness -- certain agents may incur significantly greater\ncosts or lower rewards compared to others. Tasks could be distributed\ninequitably, leading to some agents receiving an unfair advantage while others\nincur disproportionately high costs. It is important to consider the tradeoffs\nbetween efficiency and fairness. We consider the problem of fair multi-agent\nnavigation for a group of decentralized agents using multi-agent reinforcement\nlearning (MARL). We consider the reciprocal of the coefficient of variation of\nthe distances traveled by different agents as a measure of fairness and\ninvestigate whether agents can learn to be fair without significantly\nsacrificing efficiency (i.e., increasing the total distance traveled). We find\nthat by training agents using min-max fair distance goal assignments along with\na reward term that incentivizes fairness as they move towards their goals, the\nagents (1) learn a fair assignment of goals and (2) achieve almost perfect goal\ncoverage in navigation scenarios using only local observations. For goal\ncoverage scenarios, we find that, on average, our model yields a 14%\nimprovement in efficiency and a 5% improvement in fairness over a baseline\ntrained using random assignments. Furthermore, an average of 21% improvement in\nfairness can be achieved compared to a model trained on optimally efficient\nassignments; this increase in fairness comes at the expense of only a 7%\ndecrease in efficiency. Finally, we extend our method to environments in which\nagents must complete coverage tasks in prescribed formations and show that it\nis possible to do so without tailoring the models to specific formation shapes.",
    "categories": [
      "cs.MA",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.MA",
    "comment": "Manuscript accepted in ACM Journal on Autonomous Transportation\n  Systems",
    "pdf_url": "http://arxiv.org/pdf/2410.14916v1",
    "published_date": "2024-10-19 00:10:52 UTC",
    "updated_date": "2024-10-19 00:10:52 UTC"
  }
]