{
  "date": "2024-08-13",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-08-13 的 arXiv 中文 TLDR 快报！\n\n今天 arXiv 的论文主要聚焦于 AI 和机器学习领域，包括大型语言模型（LLM）的增强、强化学习应用、多模态模型创新，以及图像和语音处理等方面。其中，令人印象深刻的文章包括 Chelsea Finn 和 Silvio Savarese 等知名学者的作品，如 Agent Q 和 Diversity Empowers Intelligence，它们展示了 LLM 在自主代理和协作系统中的潜力；其他重点论文则探讨了 LLM 的推理能力、知识蒸馏和高效训练方法。\n\n下面，我挑选并简要概述几篇重要的、话题度高的论文，先从 LLM 和强化学习相关的内容入手，再聊聊多模态和图像处理的创新。其他论文较多，我会快速掠过不那么核心的主题，以保持简洁。\n\n1. **使用高级 LLM 增强小型 LLM：一种可解释的知识蒸馏方法 / Using Advanced LLMs to Enhance Smaller LLMs: An Interpretable Knowledge Distillation Approach**  \n   这篇论文由 Tong Wang 和 K. Sudhir 等作者提出，主要贡献是通过可解释的策略教学方法，让高级 LLM（如 GPT-4）指导小型 LLM 的性能提升。不同于传统知识蒸馏，该方法聚焦于生成场景库和优化策略，发现这种黑盒访问方式能提升客户服务代理的表现，并可转移到其他场景，强调了隐私和可解释性的重要性。\n\n2. **大型语言模型能否推理？基于 3-SAT 的表征 / Can Large Language Models Reason? A Characterization via 3-SAT**  \n   作者包括 Luc De Raedt，这篇论文通过 NP-完全问题 3-SAT 测试 LLM 的推理能力。关键发现是 LLM 无法进行真正的推理，尤其在难题实例中表现差，但结合外部推理器能显著改善。这为 LLM 的局限性和增强策略提供了新视角。\n\n3. **Agent Q：用于自主 AI 代理的先进推理和学习 / Agent Q: Advanced Reasoning and Learning for Autonomous AI Agents**  \n   Chelsea Finn 和 Silvio Savarese 等知名学者参与，这篇论文提出了一种框架，使用引导的 Monte Carlo Tree Search 和 DPO 算法训练 LLM 代理。贡献在于处理多步交互环境，实现 Web 导航和真实场景决策，显著提升了零样本性能（如从 18.6% 到 95.4%），为自主代理铺平道路。\n\n4. **多样性赋予智能：集成软件工程代理的专业知识 / Diversity Empowers Intelligence: Integrating Expertise of Software Engineering Agents**  \n   Silvio Savarese 作为作者，这篇论文引入 DEI 框架，利用多个代理的多样性解决软件工程问题。发现代理组合能大幅提升 GitHub 问题解决率（如从 27.3% 到 55%），强调协作 AI 系统在复杂任务中的潜力。\n\n5. **强化学习导论 / Introduction to Reinforcement Learning**  \n   这篇综述性论文由 Majid Ghasemi 和 Dariush Ebrahimi 撰写，覆盖 RL 的核心概念、算法（如模型无关和基于价值的）和资源。主要发现是为初学者提供清晰路径，简化 RL 复杂性，促进实际应用。\n\n6. **音乐生成中的语义鸿沟：AI 工具的挑战和可解释性 / Play Me Something Icy: Practical Challenges, Explainability and the Semantic Gap in Generative AI Music**  \n   作者包括 Jesse Allison，这篇论文探讨文本到音乐生成工具的语义鸿沟。贡献在于识别提示创建和可解释性的问题，并提出改进建议，如增强用户控制，帮助 AI 音乐工具更有效地捕捉抽象音乐元素。\n\n7. **视觉语言模型用于可解释的安全合规检测 / Vision Language Model for Interpretable and Fine-grained Detection of Safety Compliance in Diverse Workplaces**  \n   这篇论文提出 Clip2Safety 框架，用于多场景下 PPE 合规检测。关键发现是通过场景识别和细粒度验证，提升检测准确性，同时加速推理，适用于工业安全。\n\n8. **基于扩散的生成音乐和文本工具 / SpectralGaussians: Semantic, spectral 3D Gaussian splatting for multi-spectral scene representation**  \n   作者 Saptarshi Neil Sinha 等人开发了 SpectralGaussians 方法，用于多光谱场景表示。贡献在于结合语义和光谱信息，提高 3D 重建质量，并支持场景编辑，如风格转移。\n\n9. **扩散模型在时序生成中的应用 / Leveraging Priors via Diffusion Bridge for Time Series Generation**  \n   这篇论文提出 TimeBridge 框架，使用扩散桥连接先验和数据分布。发现能处理无条件和条件生成，提高时序数据合成效率。\n\n其他论文涉及主题较多，如语音增强（Direction of Arrival Correction）、医疗诊断（PathInsight）和模型计数（Model Counting in the Wild），但这些相对小众或理论导向，我快速掠过：例如，\"TableGuard\" 提出数据混淆保护，\"KAN You See It?\" 使用 Kolmogorov-Arnold 网络改善作物分割。这些论文的贡献在于特定领域应用，但整体影响力不如上述重点文章。\n\n总之，今天的 arXiv 更新突显了 AI 模型的优化和应用潜力，建议关注 LLM 和代理相关研究，以捕捉前沿趋势。更多细节可查阅具体论文！",
  "papers": [
    {
      "arxiv_id": "2408.07238v1",
      "title": "Using Advanced LLMs to Enhance Smaller LLMs: An Interpretable Knowledge Distillation Approach",
      "title_zh": "翻译失败",
      "authors": [
        "Tong Wang",
        "K. Sudhir",
        "Dat Hong"
      ],
      "abstract": "Advanced Large language models (LLMs) like GPT-4 or LlaMa 3 provide superior\nperformance in complex human-like interactions. But they are costly, or too\nlarge for edge devices such as smartphones and harder to self-host, leading to\nsecurity and privacy concerns. This paper introduces a novel interpretable\nknowledge distillation approach to enhance the performance of smaller, more\neconomical LLMs that firms can self-host. We study this problem in the context\nof building a customer service agent aimed at achieving high customer\nsatisfaction through goal-oriented dialogues. Unlike traditional knowledge\ndistillation, where the \"student\" model learns directly from the \"teacher\"\nmodel's responses via fine-tuning, our interpretable \"strategy\" teaching\napproach involves the teacher providing strategies to improve the student's\nperformance in various scenarios. This method alternates between a \"scenario\ngeneration\" step and a \"strategies for improvement\" step, creating a customized\nlibrary of scenarios and optimized strategies for automated prompting. The\nmethod requires only black-box access to both student and teacher models; hence\nit can be used without manipulating model parameters. In our customer service\napplication, the method improves performance, and the learned strategies are\ntransferable to other LLMs and scenarios beyond the training set. The method's\ninterpretabilty helps safeguard against potential harms through human audit.",
      "tldr_zh": "该论文提出了一种可解释的知识蒸馏方法，使用高级LLMs（如GPT-4或LLaMa 3）来提升较小、易部署的LLMs性能，解决其在成本、安全和隐私方面的挑战。不同于传统知识蒸馏，该方法让教师模型提供改进策略，通过交替的“场景生成”和“策略优化”步骤，构建自定义场景库和自动化提示库，仅需黑盒访问模型参数。实验在客户服务代理应用中显示，该方法显著提高了目标导向对话的性能，且学到的策略可转移到其他LLMs和场景，并通过可解释性支持人工审计以防范潜在风险。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.07238v1",
      "published_date": "2024-08-13 23:59:36 UTC",
      "updated_date": "2024-08-13 23:59:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:51:50.077754"
    },
    {
      "arxiv_id": "2408.07234v1",
      "title": "Direction of Arrival Correction through Speech Quality Feedback",
      "title_zh": "翻译失败",
      "authors": [
        "Caleb Rascon"
      ],
      "abstract": "Real-time speech enhancement has began to rise in performance, and the Demucs\nDenoiser model has recently demonstrated strong performance in\nmultiple-speech-source scenarios when accompanied by a location-based speech\ntarget selection strategy. However, it has shown to be sensitive to errors in\nthe direction-of-arrival (DOA) estimation. In this work, a DOA correction\nscheme is proposed that uses the real-time estimated speech quality of its\nenhanced output as the observed variable in an Adam-based optimization feedback\nloop to find the correct DOA. In spite of the high variability of the speech\nquality estimation, the proposed system is able to correct in real-time an\nerror of up to 15$^o$ using only the speech quality as its guide. Several\ninsights are provided for future versions of the proposed system to speed up\nconvergence and further reduce the speech quality estimation variability.",
      "tldr_zh": "本研究针对 Demucs Denoiser 模型在多语音源场景中的语音增强性能，提出了一种基于语音质量反馈的 Direction of Arrival (DOA) 修正方案，以解决 DOA 估计错误导致的敏感性问题。该方案利用实时估计的语音质量作为观察变量，通过 Adam-based 优化反馈循环实时调整 DOA，能够有效修正高达15度的错误。实验结果显示，该系统显著提升了语音增强的鲁棒性，并提供了见解来加速收敛和降低语音质量估计的变异性，为未来实时语音处理技术提供了改进基础。",
      "categories": [
        "eess.AS",
        "cs.AI"
      ],
      "primary_category": "eess.AS",
      "comment": "Submitted to Digital Signal Processing",
      "pdf_url": "http://arxiv.org/pdf/2408.07234v1",
      "published_date": "2024-08-13 23:43:20 UTC",
      "updated_date": "2024-08-13 23:43:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:51:59.637089"
    },
    {
      "arxiv_id": "2408.07712v3",
      "title": "Introduction to Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Majid Ghasemi",
        "Dariush Ebrahimi"
      ],
      "abstract": "Reinforcement Learning (RL), a subfield of Artificial Intelligence (AI),\nfocuses on training agents to make decisions by interacting with their\nenvironment to maximize cumulative rewards. This paper provides an overview of\nRL, covering its core concepts, methodologies, and resources for further\nlearning. It offers a thorough explanation of fundamental components such as\nstates, actions, policies, and reward signals, ensuring readers develop a solid\nfoundational understanding. Additionally, the paper presents a variety of RL\nalgorithms, categorized based on the key factors such as model-free,\nmodel-based, value-based, policy-based, and other key factors. Resources for\nlearning and implementing RL, such as books, courses, and online communities\nare also provided. By offering a clear, structured introduction, this paper\naims to simplify the complexities of RL for beginners, providing a\nstraightforward pathway to understanding.",
      "tldr_zh": "这篇论文介绍了Reinforcement Learning (RL)，一个Artificial Intelligence (AI)子领域，焦点是训练代理通过与环境互动来最大化累积奖励，提供了一个清晰的入门概述。论文详细解释了RL的核心概念，包括states, actions, policies和reward signals，帮助读者建立坚实基础。同时，它分类了各种RL算法，如model-free, model-based, value-based和policy-based方法，并列出了学习资源，例如书籍、课程和在线社区。总体上，该论文旨在简化RL的复杂性，为初学者提供直观的理解路径。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "19 pages",
      "pdf_url": "http://arxiv.org/pdf/2408.07712v3",
      "published_date": "2024-08-13 23:08:06 UTC",
      "updated_date": "2024-12-03 16:17:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:52:12.222234"
    },
    {
      "arxiv_id": "2408.07224v1",
      "title": "Play Me Something Icy: Practical Challenges, Explainability and the Semantic Gap in Generative AI Music",
      "title_zh": "翻译失败",
      "authors": [
        "Jesse Allison",
        "Drew Farrar",
        "Treya Nash",
        "Carlos Román",
        "Morgan Weeks",
        "Fiona Xue Ju"
      ],
      "abstract": "This pictorial aims to critically consider the nature of text-to-audio and\ntext-to-music generative tools in the context of explainable AI. As a group of\nexperimental musicians and researchers, we are enthusiastic about the creative\npotential of these tools and have sought to understand and evaluate them from\nperspectives of prompt creation, control, usability, understandability,\nexplainability of the AI process, and overall aesthetic effectiveness of the\nresults. One of the challenges we have identified that is not explicitly\naddressed by these tools is the inherent semantic gap in using text-based tools\nto describe something as abstract as music. Other gaps include explainability\nvs. useability, and user control and input vs. the human creative process. The\naim of this pictorial is to raise questions for discussion and make a few\ngeneral suggestions on the kinds of improvements we would like to see in\ngenerative AI music tools.",
      "tldr_zh": "这篇论文探讨了文本到音频/音乐生成工具在可解释性 AI（explainable AI）背景下的实际挑战。作为实验音乐家和研究者，作者从提示创建（prompt creation）、控制、可用性、理解性、AI 过程可解释性和整体美学效果等方面评估这些工具。关键发现包括使用文本描述音乐的语义鸿沟（semantic gap）、可解释性与可用性的权衡，以及用户控制与人类创意过程的冲突。论文旨在引发相关讨论，并提出改进建议，如增强工具的语义理解和用户交互设计，以提升生成式 AI 音乐（generative AI music）的实用性和创意潜力。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "In Proceedings of Explainable AI for the Arts Workshop 2024 (XAIxArts\n  2024) arXiv:2406.14485",
      "pdf_url": "http://arxiv.org/pdf/2408.07224v1",
      "published_date": "2024-08-13 22:42:05 UTC",
      "updated_date": "2024-08-13 22:42:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:52:23.813149"
    },
    {
      "arxiv_id": "2408.07215v2",
      "title": "Can Large Language Models Reason? A Characterization via 3-SAT",
      "title_zh": "大语言模型能推理吗？ 基于 3",
      "authors": [
        "Rishi Hazra",
        "Gabriele Venturato",
        "Pedro Zuidberg Dos Martires",
        "Luc De Raedt"
      ],
      "abstract": "Large Language Models (LLMs) have been touted as AI models possessing\nadvanced reasoning abilities. However, recent works have shown that LLMs often\nbypass true reasoning using shortcuts, sparking skepticism. To study the\nreasoning capabilities in a principled fashion, we adopt a computational theory\nperspective and propose an experimental protocol centered on 3-SAT -- the\nprototypical NP-complete problem lying at the core of logical reasoning and\nconstraint satisfaction tasks. Specifically, we examine the phase transitions\nin random 3-SAT and characterize the reasoning abilities of LLMs by varying the\ninherent hardness of the problem instances. Our experimental evidence shows\nthat LLMs are incapable of performing true reasoning, as required for solving\n3-SAT problems. Moreover, we observe significant performance variation based on\nthe inherent hardness of the problems -- performing poorly on harder instances\nand vice versa. Importantly, we show that integrating external reasoners can\nconsiderably enhance LLM performance. By following a principled experimental\nprotocol, our study draws concrete conclusions and moves beyond the anecdotal\nevidence often found in LLM reasoning research.",
      "tldr_zh": "本研究质疑大型语言模型（LLMs）的真正推理能力，通过以3-SAT（一个典型的NP-complete问题）为核心的实验协议进行系统表征。研究者考察了3-SAT问题的相变和实例难度，观察到LLMs在更难的问题上表现显著下降，无法进行真正的推理，而在简单实例上则相对较好。结果显示，整合外部reasoners能大幅提升LLMs的表现；该工作通过原则性的实验设计，提供具体结论，超越了以往的轶事证据。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.07215v2",
      "published_date": "2024-08-13 21:54:10 UTC",
      "updated_date": "2024-10-22 21:44:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:52:34.843954"
    },
    {
      "arxiv_id": "2408.07199v1",
      "title": "Agent Q: Advanced Reasoning and Learning for Autonomous AI Agents",
      "title_zh": "翻译失败",
      "authors": [
        "Pranav Putta",
        "Edmund Mills",
        "Naman Garg",
        "Sumeet Motwani",
        "Chelsea Finn",
        "Divyansh Garg",
        "Rafael Rafailov"
      ],
      "abstract": "Large Language Models (LLMs) have shown remarkable capabilities in natural\nlanguage tasks requiring complex reasoning, yet their application in agentic,\nmulti-step reasoning within interactive environments remains a difficult\nchallenge. Traditional supervised pre-training on static datasets falls short\nin enabling autonomous agent capabilities needed to perform complex\ndecision-making in dynamic settings like web navigation. Previous attempts to\nbridge this ga-through supervised fine-tuning on curated expert\ndemonstrations-often suffer from compounding errors and limited exploration\ndata, resulting in sub-optimal policy outcomes. To overcome these challenges,\nwe propose a framework that combines guided Monte Carlo Tree Search (MCTS)\nsearch with a self-critique mechanism and iterative fine-tuning on agent\ninteractions using an off-policy variant of the Direct Preference Optimization\n(DPO) algorithm. Our method allows LLM agents to learn effectively from both\nsuccessful and unsuccessful trajectories, thereby improving their\ngeneralization in complex, multi-step reasoning tasks. We validate our approach\nin the WebShop environment-a simulated e-commerce platform where it\nconsistently outperforms behavior cloning and reinforced fine-tuning baseline,\nand beats average human performance when equipped with the capability to do\nonline search. In real-world booking scenarios, our methodology boosts Llama-3\n70B model's zero-shot performance from 18.6% to 81.7% success rate (a 340%\nrelative increase) after a single day of data collection and further to 95.4%\nwith online search. We believe this represents a substantial leap forward in\nthe capabilities of autonomous agents, paving the way for more sophisticated\nand reliable decision-making in real-world settings.",
      "tldr_zh": "这项研究提出Agent Q框架，以提升大型语言模型(LLMs)在自主AI代理中的多步推理和决策能力，通过结合guided Monte Carlo Tree Search (MCTS)、self-critique机制和off-policy Direct Preference Optimization (DPO)算法，让代理从成功和失败轨迹中进行迭代学习，从而改善在动态环境的泛化性能。传统方法如监督微调常因累积错误和数据限制而表现不佳，该框架有效解决了这些问题。在WebShop模拟环境中，Agent Q超过了行为克隆和强化微调基线，并超过了平均人类水平；在真实预订场景中，它将Llama-3 70B模型的零样本成功率从18.6%提升到95.4%，展示了显著的实际应用潜力。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.07199v1",
      "published_date": "2024-08-13 20:52:13 UTC",
      "updated_date": "2024-08-13 20:52:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:52:49.565635"
    },
    {
      "arxiv_id": "2408.07194v1",
      "title": "Massive Dimensions Reduction and Hybridization with Meta-heuristics in Deep Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Rasa Khosrowshahli",
        "Shahryar Rahnamayan",
        "Beatrice Ombuki-Berman"
      ],
      "abstract": "Deep learning is mainly based on utilizing gradient-based optimization for\ntraining Deep Neural Network (DNN) models. Although robust and widely used,\ngradient-based optimization algorithms are prone to getting stuck in local\nminima. In this modern deep learning era, the state-of-the-art DNN models have\nmillions and billions of parameters, including weights and biases, making them\nhuge-scale optimization problems in terms of search space. Tuning a huge number\nof parameters is a challenging task that causes vanishing/exploding gradients\nand overfitting; likewise, utilized loss functions do not exactly represent our\ntargeted performance metrics. A practical solution to exploring large and\ncomplex solution space is meta-heuristic algorithms. Since DNNs exceed\nthousands and millions of parameters, even robust meta-heuristic algorithms,\nsuch as Differential Evolution, struggle to efficiently explore and converge in\nsuch huge-dimensional search spaces, leading to very slow convergence and high\nmemory demand. To tackle the mentioned curse of dimensionality, the concept of\nblocking was recently proposed as a technique that reduces the search space\ndimensions by grouping them into blocks. In this study, we aim to introduce\nHistogram-based Blocking Differential Evolution (HBDE), a novel approach that\nhybridizes gradient-based and gradient-free algorithms to optimize parameters.\nExperimental results demonstrated that the HBDE could reduce the parameters in\nthe ResNet-18 model from 11M to 3K during the training/optimizing phase by\nmetaheuristics, namely, the proposed HBDE, which outperforms baseline\ngradient-based and parent gradient-free DE algorithms evaluated on CIFAR-10 and\nCIFAR-100 datasets showcasing its effectiveness with reduced computational\ndemands for the very first time.",
      "tldr_zh": "本研究针对深度学习中基于梯度优化的 Deep Neural Network (DNN) 模型面临的高维参数优化问题，如陷入局部最小、梯度消失/爆炸和过拟合，提出了一种混合方法。研究引入 Histogram-based Blocking Differential Evolution (HBDE)，这是一种结合梯度-based 和梯度-free 算法的框架，通过 blocking 技术将参数分组减少搜索空间维度，例如将 ResNet-18 的参数从 11M 降至 3K。实验结果显示，HBDE 在 CIFAR-10 和 CIFAR-100 数据集上优于基线梯度-based 和 Differential Evolution 算法，显著降低了计算需求并提升了优化效率。",
      "categories": [
        "cs.NE",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.NE",
      "comment": "8 pages, 5 figures, 3 tables, accepted at IEEE CCECE 2024 (updated\n  Fig. 1 and conclusion remarks)",
      "pdf_url": "http://arxiv.org/pdf/2408.07194v1",
      "published_date": "2024-08-13 20:28:20 UTC",
      "updated_date": "2024-08-13 20:28:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:53:10.916964"
    },
    {
      "arxiv_id": "2408.07192v1",
      "title": "Solving Truly Massive Budgeted Monotonic POMDPs with Oracle-Guided Meta-Reinforcement Learning",
      "title_zh": "使用由预言机指导的元强化学习解决真正大规模的预算约束单调 POMDPs",
      "authors": [
        "Manav Vora",
        "Michael N Grussing",
        "Melkior Ornik"
      ],
      "abstract": "Monotonic Partially Observable Markov Decision Processes (POMDPs), where the\nsystem state progressively decreases until a restorative action is performed,\ncan be used to model sequential repair problems effectively. This paper\nconsiders the problem of solving budget-constrained multi-component monotonic\nPOMDPs, where a finite budget limits the maximal number of restorative actions.\nFor a large number of components, solving such a POMDP using current methods is\ncomputationally intractable due to the exponential growth in the state space\nwith an increasing number of components. To address this challenge, we propose\na two-step approach. Since the individual components of a budget-constrained\nmulti-component monotonic POMDP are only connected via the shared budget, we\nfirst approximate the optimal budget allocation among these components using an\napproximation of each component POMDP's optimal value function which is\nobtained through a random forest model. Subsequently, we introduce an\noracle-guided meta-trained Proximal Policy Optimization (PPO) algorithm to\nsolve each of the independent budget-constrained single-component monotonic\nPOMDPs. The oracle policy is obtained by performing value iteration on the\ncorresponding monotonic Markov Decision Process (MDP). This two-step method\nprovides scalability in solving truly massive multi-component monotonic POMDPs.\nTo demonstrate the efficacy of our approach, we consider a real-world\nmaintenance scenario that involves inspection and repair of an administrative\nbuilding by a team of agents within a maintenance budget. Finally, we perform a\ncomputational complexity analysis for a varying number of components to show\nthe scalability of the proposed approach.",
      "tldr_zh": "这篇论文解决了大规模预算约束的多组件 Monotonic POMDPs 的计算挑战，这些 POMDPs 用于建模顺序修复问题，但状态空间指数增长导致传统方法不可行。作者提出一个两步方法：首先，使用随机森林模型近似每个组件 POMDP 的 optimal value function 来分配预算；其次，引入 oracle-guided meta-trained Proximal Policy Optimization (PPO) 算法，其中 oracle 政策通过在对应的 Monotonic MDP 上执行价值迭代获得，从而高效解决每个独立组件的 POMDP。实验在真实维护场景（如建筑检查和修复）中验证了该方法的有效性，并通过计算复杂性分析证明了其可扩展性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "math.OC"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.07192v1",
      "published_date": "2024-08-13 20:20:58 UTC",
      "updated_date": "2024-08-13 20:20:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:53:13.543703"
    },
    {
      "arxiv_id": "2408.10259v1",
      "title": "Contrastive Learning on Medical Intents for Sequential Prescription Recommendation",
      "title_zh": "针对医疗意图的对比学习用于顺序处方推荐",
      "authors": [
        "Arya Hadizadeh Moghaddam",
        "Mohsen Nayebi Kerdabadi",
        "Mei Liu",
        "Zijun Yao"
      ],
      "abstract": "Recent advancements in sequential modeling applied to Electronic Health\nRecords (EHR) have greatly influenced prescription recommender systems. While\nthe recent literature on drug recommendation has shown promising performance,\nthe study of discovering a diversity of coexisting temporal relationships at\nthe level of medical codes over consecutive visits remains less explored. The\ngoal of this study can be motivated from two perspectives. First, there is a\nneed to develop a sophisticated sequential model capable of disentangling the\ncomplex relationships across sequential visits. Second, it is crucial to\nestablish multiple and diverse health profiles for the same patient to ensure a\ncomprehensive consideration of different medical intents in drug\nrecommendation. To achieve this goal, we introduce Attentive Recommendation\nwith Contrasted Intents (ARCI), a multi-level transformer-based method designed\nto capture the different but coexisting temporal paths across a shared sequence\nof visits. Specifically, we propose a novel intent-aware method with\ncontrastive learning, that links specialized medical intents of the patients to\nthe transformer heads for extracting distinct temporal paths associated with\ndifferent health profiles. We conducted experiments on two real-world datasets\nfor the prescription recommendation task using both ranking and classification\nmetrics. Our results demonstrate that ARCI has outperformed the\nstate-of-the-art prescription recommendation methods and is capable of\nproviding interpretable insights for healthcare practitioners.",
      "tldr_zh": "这篇论文针对电子健康记录 (EHR) 中的处方推荐问题，提出了一种名为 Attentive Recommendation with Contrasted Intents (ARCI) 的方法，利用多级 Transformer 模型来捕捉患者连续就诊中不同但共存的时间关系和医疗意图。ARCI 通过引入意图感知对比学习 (Contrastive Learning) 技术，将患者的多种健康配置文件链接到 Transformer 的头，从而提取多样化的时间路径以支持全面的药物推荐。实验结果显示，在两个真实数据集上，ARCI 在排名和分类指标上超过了最先进的方法，并为医疗从业者提供了可解释的洞见。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted to the 33rd ACM International Conference on Information and\n  Knowledge Management (CIKM 2024)",
      "pdf_url": "http://arxiv.org/pdf/2408.10259v1",
      "published_date": "2024-08-13 20:10:28 UTC",
      "updated_date": "2024-08-13 20:10:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:53:25.297785"
    },
    {
      "arxiv_id": "2408.07184v1",
      "title": "A New Dataset, Notation Software, and Representation for Computational Schenkerian Analysis",
      "title_zh": "翻译失败",
      "authors": [
        "Stephen Ni-Hahn",
        "Weihan Xu",
        "Jerry Yin",
        "Rico Zhu",
        "Simon Mak",
        "Yue Jiang",
        "Cynthia Rudin"
      ],
      "abstract": "Schenkerian Analysis (SchA) is a uniquely expressive method of music\nanalysis, combining elements of melody, harmony, counterpoint, and form to\ndescribe the hierarchical structure supporting a work of music. However,\ndespite its powerful analytical utility and potential to improve music\nunderstanding and generation, SchA has rarely been utilized by the computer\nmusic community. This is in large part due to the paucity of available\nhigh-quality data in a computer-readable format. With a larger corpus of\nSchenkerian data, it may be possible to infuse machine learning models with a\ndeeper understanding of musical structure, thus leading to more \"human\"\nresults. To encourage further research in Schenkerian analysis and its\npotential benefits for music informatics and generation, this paper presents\nthree main contributions: 1) a new and growing dataset of SchAs, the largest in\nhuman- and computer-readable formats to date (>140 excerpts), 2) a novel\nsoftware for visualization and collection of SchA data, and 3) a novel,\nflexible representation of SchA as a heterogeneous-edge graph data structure.",
      "tldr_zh": "这篇论文针对Schenkerian Analysis (SchA)——一种结合旋律、和声、对位和形式的音乐层次结构分析方法——在计算机音乐领域应用不足的问题，提出三个主要贡献。贡献包括一个新的、不断增长的数据集（目前超过140个节选），这是迄今为止最大的人类和计算机可读SchA数据集；一个新型软件，用于SchA数据的可视化和收集；以及一个灵活的SchA表示方法，即基于异构-edge graph数据结构。这些创新有望为机器学习模型注入更深层的音乐结构理解，提升音乐生成和分析的“人性化”效果。",
      "categories": [
        "cs.SD",
        "cs.AI"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.07184v1",
      "published_date": "2024-08-13 19:52:06 UTC",
      "updated_date": "2024-08-13 19:52:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:53:36.502713"
    },
    {
      "arxiv_id": "2408.07181v1",
      "title": "VulCatch: Enhancing Binary Vulnerability Detection through CodeT5 Decompilation and KAN Advanced Feature Extraction",
      "title_zh": "翻译失败",
      "authors": [
        "Abdulrahman Hamman Adama Chukkol",
        "Senlin Luo",
        "Kashif Sharif",
        "Yunusa Haruna",
        "Muhammad Muhammad Abdullahi"
      ],
      "abstract": "Binary program vulnerability detection is critical for software security, yet\nexisting deep learning approaches often rely on source code analysis, limiting\ntheir ability to detect unknown vulnerabilities. To address this, we propose\nVulCatch, a binary-level vulnerability detection framework. VulCatch introduces\na Synergy Decompilation Module (SDM) and Kolmogorov-Arnold Networks (KAN) to\ntransform raw binary code into pseudocode using CodeT5, preserving high-level\nsemantics for deep analysis with tools like Ghidra and IDA. KAN further\nenhances feature transformation, enabling the detection of complex\nvulnerabilities. VulCatch employs word2vec, Inception Blocks, BiLSTM Attention,\nand Residual connections to achieve high detection accuracy (98.88%) and\nprecision (97.92%), while minimizing false positives (1.56%) and false\nnegatives (2.71%) across seven CVE datasets.",
      "tldr_zh": "本研究提出 VulCatch，一种二进制级别漏洞检测框架，旨在解决现有深度学习方法依赖源代码而难以检测未知漏洞的问题。VulCatch 引入 Synergy Decompilation Module (SDM) 和 Kolmogorov-Arnold Networks (KAN)，利用 CodeT5 将原始二进制代码转化为伪代码，结合 Ghidra 和 IDA 等工具保留高级语义，并通过 word2vec、Inception Blocks、BiLSTM Attention 和 Residual connections 增强特征提取以识别复杂漏洞。实验结果显示，在七个 CVE 数据集上，VulCatch 实现了 98.88% 的检测准确率和 97.92% 的精确率，同时将假阳性率降至 1.56% 和假阴性率降至 2.71%。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG",
        "cs.SE"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.07181v1",
      "published_date": "2024-08-13 19:46:50 UTC",
      "updated_date": "2024-08-13 19:46:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:53:50.329629"
    },
    {
      "arxiv_id": "2408.07146v1",
      "title": "Vision Language Model for Interpretable and Fine-grained Detection of Safety Compliance in Diverse Workplaces",
      "title_zh": "翻译失败",
      "authors": [
        "Zhiling Chen",
        "Hanning Chen",
        "Mohsen Imani",
        "Ruimin Chen",
        "Farhad Imani"
      ],
      "abstract": "Workplace accidents due to personal protective equipment (PPE) non-compliance\nraise serious safety concerns and lead to legal liabilities, financial\npenalties, and reputational damage. While object detection models have shown\nthe capability to address this issue by identifying safety items, most existing\nmodels, such as YOLO, Faster R-CNN, and SSD, are limited in verifying the\nfine-grained attributes of PPE across diverse workplace scenarios. Vision\nlanguage models (VLMs) are gaining traction for detection tasks by leveraging\nthe synergy between visual and textual information, offering a promising\nsolution to traditional object detection limitations in PPE recognition.\nNonetheless, VLMs face challenges in consistently verifying PPE attributes due\nto the complexity and variability of workplace environments, requiring them to\ninterpret context-specific language and visual cues simultaneously. We\nintroduce Clip2Safety, an interpretable detection framework for diverse\nworkplace safety compliance, which comprises four main modules: scene\nrecognition, the visual prompt, safety items detection, and fine-grained\nverification. The scene recognition identifies the current scenario to\ndetermine the necessary safety gear. The visual prompt formulates the specific\nvisual prompts needed for the detection process. The safety items detection\nidentifies whether the required safety gear is being worn according to the\nspecified scenario. Lastly, the fine-grained verification assesses whether the\nworn safety equipment meets the fine-grained attribute requirements. We conduct\nreal-world case studies across six different scenarios. The results show that\nClip2Safety not only demonstrates an accuracy improvement over state-of-the-art\nquestion-answering based VLMs but also achieves inference times two hundred\ntimes faster.",
      "tldr_zh": "该研究针对工作场所PPE（个人防护装备）不合规导致的安全问题，提出了一种基于Vision Language Models（VLMs）的Clip2Safety框架，以实现可解释和细粒度的安全合规检测。该框架包括四个模块：场景识别（确定必要的安全装备）、视觉提示（制定检测提示）、安全物品检测（检查装备是否佩戴）和细粒度验证（评估装备属性是否符合要求），从而克服传统模型如YOLO、Faster R-CNN和SSD的局限性。实验在六个真实场景中进行，结果显示Clip2Safety比现有基于问答的VLMs准确性更高，且推理速度快200倍，为多样化工作场所的安全监测提供了高效解决方案。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "20 pages, 7 figures",
      "pdf_url": "http://arxiv.org/pdf/2408.07146v1",
      "published_date": "2024-08-13 18:32:06 UTC",
      "updated_date": "2024-08-13 18:32:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:54:01.632740"
    },
    {
      "arxiv_id": "2408.07060v1",
      "title": "Diversity Empowers Intelligence: Integrating Expertise of Software Engineering Agents",
      "title_zh": "翻译失败",
      "authors": [
        "Kexun Zhang",
        "Weiran Yao",
        "Zuxin Liu",
        "Yihao Feng",
        "Zhiwei Liu",
        "Rithesh Murthy",
        "Tian Lan",
        "Lei Li",
        "Renze Lou",
        "Jiacheng Xu",
        "Bo Pang",
        "Yingbo Zhou",
        "Shelby Heinecke",
        "Silvio Savarese",
        "Huan Wang",
        "Caiming Xiong"
      ],
      "abstract": "Large language model (LLM) agents have shown great potential in solving\nreal-world software engineering (SWE) problems. The most advanced open-source\nSWE agent can resolve over 27% of real GitHub issues in SWE-Bench Lite.\nHowever, these sophisticated agent frameworks exhibit varying strengths,\nexcelling in certain tasks while underperforming in others. To fully harness\nthe diversity of these agents, we propose DEI (Diversity Empowered\nIntelligence), a framework that leverages their unique expertise. DEI functions\nas a meta-module atop existing SWE agent frameworks, managing agent collectives\nfor enhanced problem-solving. Experimental results show that a DEI-guided\ncommittee of agents is able to surpass the best individual agent's performance\nby a large margin. For instance, a group of open-source SWE agents, with a\nmaximum individual resolve rate of 27.3% on SWE-Bench Lite, can achieve a 34.3%\nresolve rate with DEI, making a 25% improvement and beating most closed-source\nsolutions. Our best-performing group excels with a 55% resolve rate, securing\nthe highest ranking on SWE-Bench Lite. Our findings contribute to the growing\nbody of research on collaborative AI systems and their potential to solve\ncomplex software engineering challenges.",
      "tldr_zh": "本研究探讨了大型语言模型(LLM)代理在软件工程(SWE)领域的多样性，提出DEI(Diversity Empowered Intelligence)框架，以整合多个SWE代理的专长。DEI作为一个元模块，管理代理集体来提升问题解决能力，利用代理间的互补优势。实验结果显示，DEI指导的代理委员会在SWE-Bench Lite基准测试中大幅超越单个最佳代理，例如一组开源代理从27.3%的解决率提升至34.3%，最佳组合甚至达到55%，领先大多数闭源解决方案。该框架为协作AI系统的发展提供新见解，有助于应对复杂的软件工程挑战。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.07060v1",
      "published_date": "2024-08-13 17:50:28 UTC",
      "updated_date": "2024-08-13 17:50:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:54:14.416416"
    },
    {
      "arxiv_id": "2408.07059v1",
      "title": "Model Counting in the Wild",
      "title_zh": "翻译失败",
      "authors": [
        "Arijit Shaw",
        "Kuldeep S. Meel"
      ],
      "abstract": "Model counting is a fundamental problem in automated reasoning with\napplications in probabilistic inference, network reliability, neural network\nverification, and more. Although model counting is computationally intractable\nfrom a theoretical perspective due to its #P-completeness, the past decade has\nseen significant progress in developing state-of-the-art model counters to\naddress scalability challenges.\n  In this work, we conduct a rigorous assessment of the scalability of model\ncounters in the wild. To this end, we surveyed 11 application domains and\ncollected an aggregate of 2262 benchmarks from these domains. We then evaluated\nsix state-of-the-art model counters on these instances to assess scalability\nand runtime performance.\n  Our empirical evaluation demonstrates that the performance of model counters\nvaries significantly across different application domains, underscoring the\nneed for careful selection by the end user. Additionally, we investigated the\nbehavior of different counters with respect to two parameters suggested by the\nmodel counting community, finding only a weak correlation. Our analysis\nhighlights the challenges and opportunities for portfolio-based approaches in\nmodel counting.",
      "tldr_zh": "本研究评估了模型计数（model counting）在实际应用中的可扩展性，该问题虽因其 #P-completeness 而理论上计算上棘手，但过去十年已取得显著进展。研究者调查了11个应用领域，收集了2262个基准实例，并对六个最先进的模型计数器进行了性能测试。结果显示，这些计数器的运行时性能在不同领域间差异显著，且与社区建议的两个参数仅存在弱相关性，这突出了组合式方法（portfolio-based approaches）在模型计数中的挑战与机遇。",
      "categories": [
        "cs.LO",
        "cs.AI"
      ],
      "primary_category": "cs.LO",
      "comment": "Full version of conference paper accepted at KR 2024",
      "pdf_url": "http://arxiv.org/pdf/2408.07059v1",
      "published_date": "2024-08-13 17:49:46 UTC",
      "updated_date": "2024-08-13 17:49:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:54:25.349578"
    },
    {
      "arxiv_id": "2408.07057v1",
      "title": "A Survey on Model MoErging: Recycling and Routing Among Specialized Experts for Collaborative Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Prateek Yadav",
        "Colin Raffel",
        "Mohammed Muqeeth",
        "Lucas Caccia",
        "Haokun Liu",
        "Tianlong Chen",
        "Mohit Bansal",
        "Leshem Choshen",
        "Alessandro Sordoni"
      ],
      "abstract": "The availability of performant pre-trained models has led to a proliferation\nof fine-tuned expert models that are specialized to a particular domain or\ntask. Model MoErging methods aim to recycle expert models to create an\naggregate system with improved performance or generalization. A key component\nof MoErging methods is the creation of a router that decides which expert\nmodel(s) to use for a particular input or application. The promise,\neffectiveness, and large design space of MoErging has spurred the development\nof many new methods over the past few years. This rapid pace of development has\nmade it challenging to compare different MoErging methods, which are rarely\ncompared to one another and are often validated in different experimental\nsetups. To remedy such gaps, we present a comprehensive survey of MoErging\nmethods that includes a novel taxonomy for cataloging key design choices and\nclarifying suitable applications for each method. Apart from surveying MoErging\nresearch, we inventory software tools and applications that make use of\nMoErging. We additionally discuss related fields of study such as model\nmerging, multitask learning, and mixture-of-experts models. Taken as a whole,\nour survey provides a unified overview of existing MoErging methods and creates\na solid foundation for future work in this burgeoning field.",
      "tldr_zh": "这篇论文对Model MoErging方法进行了全面调查，该方法通过回收和路由专门化的专家模型，实现模型间的协作学习，以提升整体性能和泛化能力。论文提出一个新颖的分类法（taxonomy），用于整理MoErging的关键设计选择和适用场景，同时列出了相关软件工具、应用，并讨论了与模型合并、多任务学习和Mixture-of-Experts模型等领域的关联。通过提供统一的概述，论文填补了现有方法间缺乏比较的空白，为未来MoErging研究奠定坚实基础。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "26 pages",
      "pdf_url": "http://arxiv.org/pdf/2408.07057v1",
      "published_date": "2024-08-13 17:49:00 UTC",
      "updated_date": "2024-08-13 17:49:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:54:37.346286"
    },
    {
      "arxiv_id": "2408.07052v2",
      "title": "The News Comment Gap and Algorithmic Agenda Setting in Online Forums",
      "title_zh": "新闻评论差距与算法议程设置在在线论坛中",
      "authors": [
        "Flora Böwing",
        "Patrick Gildersleve"
      ],
      "abstract": "The disparity between news stories valued by journalists and those preferred\nby readers, known as the \"News Gap\", is well-documented. However, the\ndifference in expectations regarding news related user-generated content is\nless studied. Comment sections, hosted by news websites, are popular venues for\nreader engagement, yet still subject to editorial decisions. It is thus\nimportant to understand journalist vs reader comment preferences and how these\nare served by various comment ranking algorithms that represent discussions\ndifferently. We analyse 1.2 million comments from Austrian newspaper Der\nStandard to understand the \"News Comment Gap\" and the effects of different\nranking algorithms. We find that journalists prefer positive, timely, complex,\ndirect responses, while readers favour comments similar to article content from\nelite authors. We introduce the versatile Feature-Oriented Ranking Utility\nMetric (FORUM) to assess the impact of different ranking algorithms and find\ndramatic differences in how they prioritise the display of comments by\nsentiment, topical relevance, lexical diversity, and readability. Journalists\ncan exert substantial influence over the discourse through both curatorial and\nalgorithmic means. Understanding these choices' implications is vital in\nfostering engaging and civil discussions while aligning with journalistic\nobjectives, especially given the increasing legal scrutiny and societal\nimportance of online discourse.",
      "tldr_zh": "本研究探讨了“News Comment Gap”，即记者与读者在新闻相关用户生成内容偏好上的差异，通过分析奥地利报纸 Der Standard 的120万条评论进行实证研究。研究发现，记者更倾向于积极、及时、复杂且直接的回应，而读者更青睐与文章内容相似且来自精英作者的评论；此外，论文引入了Feature-Oriented Ranking Utility Metric (FORUM)来评估不同评论排名算法在情感、主题相关性、词汇多样性和可读性方面的影响。结果显示，这些算法显著改变了评论展示优先级，突显了记者通过策展和算法手段对在线话语的控制力，并强调理解这些选择对于促进文明讨论和符合新闻目标的重要性。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.CL",
        "cs.SI",
        "physics.soc-ph"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.07052v2",
      "published_date": "2024-08-13 17:43:32 UTC",
      "updated_date": "2024-08-23 09:29:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:54:52.429906"
    },
    {
      "arxiv_id": "2408.07045v1",
      "title": "TableGuard -- Securing Structured & Unstructured Data",
      "title_zh": "TableGuard -- 保护结构化与非结构化数据",
      "authors": [
        "Anantha Sharma",
        "Ajinkya Deshmukh"
      ],
      "abstract": "With the increasing demand for data sharing across platforms and\norganizations, ensuring the privacy and security of sensitive information has\nbecome a critical challenge. This paper introduces \"TableGuard\". An innovative\napproach to data obfuscation tailored for relational databases. Building on the\nprinciples and techniques developed in prior work on context-sensitive\nobfuscation, TableGuard applies these methods to ensure that API calls return\nonly obfuscated data, thereby safeguarding privacy when sharing data with third\nparties. TableGuard leverages advanced context-sensitive obfuscation techniques\nto replace sensitive data elements with contextually appropriate alternatives.\nBy maintaining the relational integrity and coherence of the data, our approach\nmitigates the risks of cognitive dissonance and data leakage. We demonstrate\nthe implementation of TableGuard using a BERT based transformer model, which\nidentifies and obfuscates sensitive entities within relational tables. Our\nevaluation shows that TableGuard effectively balances privacy protection with\ndata utility, minimizing information loss while ensuring that the obfuscated\ndata remains functionally useful for downstream applications. The results\nhighlight the importance of domain-specific obfuscation strategies and the role\nof context length in preserving data integrity. The implications of this\nresearch are significant for organizations that need to share data securely\nwith external parties. TableGuard offers a robust framework for implementing\nprivacy-preserving data sharing mechanisms, thereby contributing to the broader\nfield of data privacy and security.",
      "tldr_zh": "本研究提出 TableGuard，一种创新的数据混淆方法，旨在保护关系数据库中敏感信息的隐私，尤其适用于跨平台数据共享场景。TableGuard 基于上下文敏感 obfuscation 技术，使用 BERT 基于的 transformer 模型来识别并替换敏感实体，同时保持数据的关系完整性和连贯性，以减少认知 dissonance 和数据 leakage 风险。实验结果显示，该方法在隐私保护与数据效用之间实现了有效平衡，显著降低了信息损失，并强调了领域特定 obfuscation 策略和上下文长度对数据完整性的重要性。该框架为组织安全共享数据提供了可靠的机制，对数据隐私与安全领域具有重要贡献。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CL",
        "cs.IR",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "7 pages, 3 tables, 1 figure",
      "pdf_url": "http://arxiv.org/pdf/2408.07045v1",
      "published_date": "2024-08-13 17:20:52 UTC",
      "updated_date": "2024-08-13 17:20:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:55:01.297757"
    },
    {
      "arxiv_id": "2408.07040v1",
      "title": "KAN You See It? KANs and Sentinel for Effective and Explainable Crop Field Segmentation",
      "title_zh": "翻译失败",
      "authors": [
        "Daniele Rege Cambrin",
        "Eleonora Poeta",
        "Eliana Pastor",
        "Tania Cerquitelli",
        "Elena Baralis",
        "Paolo Garza"
      ],
      "abstract": "Segmentation of crop fields is essential for enhancing agricultural\nproductivity, monitoring crop health, and promoting sustainable practices. Deep\nlearning models adopted for this task must ensure accurate and reliable\npredictions to avoid economic losses and environmental impact. The newly\nproposed Kolmogorov-Arnold networks (KANs) offer promising advancements in the\nperformance of neural networks. This paper analyzes the integration of KAN\nlayers into the U-Net architecture (U-KAN) to segment crop fields using\nSentinel-2 and Sentinel-1 satellite images and provides an analysis of the\nperformance and explainability of these networks. Our findings indicate a 2\\%\nimprovement in IoU compared to the traditional full-convolutional U-Net model\nin fewer GFLOPs. Furthermore, gradient-based explanation techniques show that\nU-KAN predictions are highly plausible and that the network has a very high\nability to focus on the boundaries of cultivated areas rather than on the areas\nthemselves. The per-channel relevance analysis also reveals that some channels\nare irrelevant to this task.",
      "tldr_zh": "本文提出了一种将 Kolmogorov-Arnold networks (KANs) 整合到 U-Net 架构中的 U-KAN 模型，用于基于 Sentinel-2 和 Sentinel-1 卫星图像的作物田地分割，以提高农业生产力、作物健康监测和可持续实践。实验结果显示，U-KAN 相比传统 U-Net 模型在 IoU 上提高了 2%，同时减少了 GFLOPs，实现了更高的计算效率。梯度-based 解释技术进一步证明，U-KAN 的预测更可信，特别擅长关注耕作区域边界，而某些通道被发现对任务无关。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted at ECCV 2024 CVPPA Workshop",
      "pdf_url": "http://arxiv.org/pdf/2408.07040v1",
      "published_date": "2024-08-13 17:07:29 UTC",
      "updated_date": "2024-08-13 17:07:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:55:14.110555"
    },
    {
      "arxiv_id": "2408.07037v1",
      "title": "PathInsight: Instruction Tuning of Multimodal Datasets and Models for Intelligence Assisted Diagnosis in Histopathology",
      "title_zh": "翻译失败",
      "authors": [
        "Xiaomin Wu",
        "Rui Xu",
        "Pengchen Wei",
        "Wenkang Qin",
        "Peixiang Huang",
        "Ziheng Li",
        "Lin Luo"
      ],
      "abstract": "Pathological diagnosis remains the definitive standard for identifying\ntumors. The rise of multimodal large models has simplified the process of\nintegrating image analysis with textual descriptions. Despite this advancement,\nthe substantial costs associated with training and deploying these complex\nmultimodal models, together with a scarcity of high-quality training datasets,\ncreate a significant divide between cutting-edge technology and its application\nin the clinical setting. We had meticulously compiled a dataset of\napproximately 45,000 cases, covering over 6 different tasks, including the\nclassification of organ tissues, generating pathology report descriptions, and\naddressing pathology-related questions and answers. We have fine-tuned\nmultimodal large models, specifically LLaVA, Qwen-VL, InternLM, with this\ndataset to enhance instruction-based performance. We conducted a qualitative\nassessment of the capabilities of the base model and the fine-tuned model in\nperforming image captioning and classification tasks on the specific dataset.\nThe evaluation results demonstrate that the fine-tuned model exhibits\nproficiency in addressing typical pathological questions. We hope that by\nmaking both our models and datasets publicly available, they can be valuable to\nthe medical and research communities.",
      "tldr_zh": "本研究针对病理学诊断中多模态大型模型(multimodal large models)的训练成本高和高质量数据集稀缺问题，提出PathInsight框架，通过指令调优(instruction tuning)来整合图像分析和文本描述。研究团队编译了一个约45,000例的病理数据集，涵盖6个任务，包括器官组织分类、生成病理报告描述以及回答病理相关问题，并对LLaVA、Qwen-VL和InternLM模型进行了微调。评估结果显示，微调模型在图像标题(image captioning)和分类任务上表现出色，能够更有效地处理典型病理问题；该模型和数据集将公开共享，以支持医疗和研究社区的应用。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "10 pages, 2 figures",
      "pdf_url": "http://arxiv.org/pdf/2408.07037v1",
      "published_date": "2024-08-13 17:05:06 UTC",
      "updated_date": "2024-08-13 17:05:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:55:26.949094"
    },
    {
      "arxiv_id": "2408.07016v1",
      "title": "Defining and Measuring Disentanglement for non-Independent Factors of Variation",
      "title_zh": "翻译失败",
      "authors": [
        "Antonio Almudévar",
        "Alfonso Ortega",
        "Luis Vicente",
        "Antonio Miguel",
        "Eduardo Lleida"
      ],
      "abstract": "Representation learning is an approach that allows to discover and extract\nthe factors of variation from the data. Intuitively, a representation is said\nto be disentangled if it separates the different factors of variation in a way\nthat is understandable to humans. Definitions of disentanglement and metrics to\nmeasure it usually assume that the factors of variation are independent of each\nother. However, this is generally false in the real world, which limits the use\nof these definitions and metrics to very specific and unrealistic scenarios. In\nthis paper we give a definition of disentanglement based on information theory\nthat is also valid when the factors of variation are not independent.\nFurthermore, we relate this definition to the Information Bottleneck Method.\nFinally, we propose a method to measure the degree of disentanglement from the\ngiven definition that works when the factors of variation are not independent.\nWe show through different experiments that the method proposed in this paper\ncorrectly measures disentanglement with non-independent factors of variation,\nwhile other methods fail in this scenario.",
      "tldr_zh": "这篇论文针对表示学习（representation learning）中的disentanglement定义和测量问题，指出传统方法假设factors of variation相互独立，但现实世界中这些因素往往不独立，从而限制了其应用。作者基于信息理论提出了一种新的disentanglement定义，能够适用于非独立factors of variation的情景，并将其与Information Bottleneck Method相关联。同时，他们开发了一种测量disentanglement程度的方法，通过实验验证其有效性，而其他方法在非独立因素场景下则失败。总的来说，该工作扩展了disentanglement概念，使其更适用于真实数据分析。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.07016v1",
      "published_date": "2024-08-13 16:30:36 UTC",
      "updated_date": "2024-08-13 16:30:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:55:37.508172"
    },
    {
      "arxiv_id": "2408.07004v1",
      "title": "Casper: Prompt Sanitization for Protecting User Privacy in Web-Based Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Chun Jie Chong",
        "Chenxi Hou",
        "Zhihao Yao",
        "Seyed Mohammadjavad Seyed Talebi"
      ],
      "abstract": "Web-based Large Language Model (LLM) services have been widely adopted and\nhave become an integral part of our Internet experience. Third-party plugins\nenhance the functionalities of LLM by enabling access to real-world data and\nservices. However, the privacy consequences associated with these services and\ntheir third-party plugins are not well understood. Sensitive prompt data are\nstored, processed, and shared by cloud-based LLM providers and third-party\nplugins. In this paper, we propose Casper, a prompt sanitization technique that\naims to protect user privacy by detecting and removing sensitive information\nfrom user inputs before sending them to LLM services. Casper runs entirely on\nthe user's device as a browser extension and does not require any changes to\nthe online LLM services. At the core of Casper is a three-layered sanitization\nmechanism consisting of a rule-based filter, a Machine Learning (ML)-based\nnamed entity recognizer, and a browser-based local LLM topic identifier. We\nevaluate Casper on a dataset of 4000 synthesized prompts and show that it can\neffectively filter out Personal Identifiable Information (PII) and\nprivacy-sensitive topics with high accuracy, at 98.5% and 89.9%, respectively.",
      "tldr_zh": "本文提出 Casper，一种提示净化（Prompt Sanitization）技术，旨在保护用户在 Web-based Large Language Models (LLM) 服务中使用第三方插件时的隐私风险，通过检测并移除用户输入中的敏感信息。Casper 作为浏览器扩展在用户设备上运行，采用三层净化机制，包括规则-based 过滤器、Machine Learning (ML)-based 命名实体识别器和本地 LLM 主题标识器，无需修改现有 LLM 服务。实验在 4000 个合成提示数据集上评估，结果显示 Personal Identifiable Information (PII) 过滤准确率达 98.5%，隐私敏感主题识别准确率达 89.9%。这项技术为增强用户隐私提供了高效、可行的解决方案。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.07004v1",
      "published_date": "2024-08-13 16:08:37 UTC",
      "updated_date": "2024-08-13 16:08:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:55:52.195844"
    },
    {
      "arxiv_id": "2408.07003v1",
      "title": "Generative AI for automatic topic labelling",
      "title_zh": "翻译失败",
      "authors": [
        "Diego Kozlowski",
        "Carolina Pradier",
        "Pierre Benz"
      ],
      "abstract": "Topic Modeling has become a prominent tool for the study of scientific\nfields, as they allow for a large scale interpretation of research trends.\nNevertheless, the output of these models is structured as a list of keywords\nwhich requires a manual interpretation for the labelling. This paper proposes\nto assess the reliability of three LLMs, namely flan, GPT-4o, and GPT-4 mini\nfor topic labelling. Drawing on previous research leveraging BERTopic, we\ngenerate topics from a dataset of all the scientific articles (n=34,797)\nauthored by all biology professors in Switzerland (n=465) between 2008 and\n2020, as recorded in the Web of Science database. We assess the output of the\nthree models both quantitatively and qualitatively and find that, first, both\nGPT models are capable of accurately and precisely label topics from the\nmodels' output keywords. Second, 3-word labels are preferable to grasp the\ncomplexity of research topics.",
      "tldr_zh": "这篇论文评估了 flan、GPT-4o 和 GPT-4 mini 等 LLMs 在自动主题标记中的可靠性，以解决传统主题建模输出（如关键词列表）需要手动解释的问题。研究使用 BERTopic 从瑞士生物学教授（n=465）在 2008-2020 年发表的科学文章（n=34,797）中生成主题，并通过定量和定性方法评估模型表现。结果表明，GPT-4o 和 GPT-4 mini 能准确精确地标记主题，且 3-word labels 更适合捕捉研究主题的复杂性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "10 pages, 1 figure",
      "pdf_url": "http://arxiv.org/pdf/2408.07003v1",
      "published_date": "2024-08-13 16:07:16 UTC",
      "updated_date": "2024-08-13 16:07:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:56:02.727594"
    },
    {
      "arxiv_id": "2408.07113v1",
      "title": "A Theory-Based Explainable Deep Learning Architecture for Music Emotion",
      "title_zh": "翻译失败",
      "authors": [
        "Hortense Fong",
        "Vineet Kumar",
        "K. Sudhir"
      ],
      "abstract": "This paper paper develops a theory-based, explainable deep learning\nconvolutional neural network (CNN) classifier to predict the time-varying\nemotional response to music. We design novel CNN filters that leverage the\nfrequency harmonics structure from acoustic physics known to impact the\nperception of musical features. Our theory-based model is more parsimonious,\nbut provides comparable predictive performance to atheoretical deep learning\nmodels, while performing better than models using handcrafted features. Our\nmodel can be complemented with handcrafted features, but the performance\nimprovement is marginal. Importantly, the harmonics-based structure placed on\nthe CNN filters provides better explainability for how the model predicts\nemotional response (valence and arousal), because emotion is closely related to\nconsonance--a perceptual feature defined by the alignment of harmonics.\nFinally, we illustrate the utility of our model with an application involving\ndigital advertising. Motivated by YouTube mid-roll ads, we conduct a lab\nexperiment in which we exogenously insert ads at different times within videos.\nWe find that ads placed in emotionally similar contexts increase ad engagement\n(lower skip rates, higher brand recall rates). Ad insertion based on emotional\nsimilarity metrics predicted by our theory-based, explainable model produces\ncomparable or better engagement relative to atheoretical models.",
      "tldr_zh": "这篇论文提出了一种基于理论的、可解释深度学习 CNN 分类器，用于预测音乐对情绪（valence and arousal）的时变响应。模型通过设计新型 CNN filters，利用声学物理中的频率 harmonics 结构来提升对音乐特征感知的建模，使其比无理论模型更简洁且预测性能相当，甚至优于使用 handcrafted features 的模型。谐波-based 结构提高了模型的可解释性，因为情绪与 consonance（谐波对齐定义的感知特征）密切相关。最后，通过一个数字广告实验，论文展示了在 YouTube 中间广告中，根据模型预测的情绪相似性插入广告，能显著提高广告参与度（如降低跳过率和提高品牌回忆率）。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.HC",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.07113v1",
      "published_date": "2024-08-13 16:01:27 UTC",
      "updated_date": "2024-08-13 16:01:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:56:14.989589"
    },
    {
      "arxiv_id": "2408.06993v1",
      "title": "LLMs can Schedule",
      "title_zh": "翻译失败",
      "authors": [
        "Henrik Abgaryan",
        "Ararat Harutyunyan",
        "Tristan Cazenave"
      ],
      "abstract": "The job shop scheduling problem (JSSP) remains a significant hurdle in\noptimizing production processes. This challenge involves efficiently allocating\njobs to a limited number of machines while minimizing factors like total\nprocessing time or job delays. While recent advancements in artificial\nintelligence have yielded promising solutions, such as reinforcement learning\nand graph neural networks, this paper explores the potential of Large Language\nModels (LLMs) for JSSP. We introduce the very first supervised 120k dataset\nspecifically designed to train LLMs for JSSP. Surprisingly, our findings\ndemonstrate that LLM-based scheduling can achieve performance comparable to\nother neural approaches. Furthermore, we propose a sampling method that\nenhances the effectiveness of LLMs in tackling JSSP.",
      "tldr_zh": "本论文探讨Large Language Models (LLMs) 在Job Shop Scheduling Problem (JSSP) 中的应用，旨在优化作业分配以最小化处理时间等因素。研究者引入了首个针对JSSP的监督式120k数据集，用于训练LLMs，并提出了一种采样方法来提升其效能。结果显示，LLMs的表现可与reinforcement learning和graph neural networks等神经方法相当，甚至通过采样方法进一步改善了调度性能，为生产过程优化提供了新途径。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.06993v1",
      "published_date": "2024-08-13 15:53:58 UTC",
      "updated_date": "2024-08-13 15:53:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:56:26.026758"
    },
    {
      "arxiv_id": "2408.06975v1",
      "title": "SpectralGaussians: Semantic, spectral 3D Gaussian splatting for multi-spectral scene representation, visualization and analysis",
      "title_zh": "翻译失败",
      "authors": [
        "Saptarshi Neil Sinha",
        "Holger Graf",
        "Michael Weinmann"
      ],
      "abstract": "We propose a novel cross-spectral rendering framework based on 3D Gaussian\nSplatting (3DGS) that generates realistic and semantically meaningful splats\nfrom registered multi-view spectrum and segmentation maps. This extension\nenhances the representation of scenes with multiple spectra, providing insights\ninto the underlying materials and segmentation. We introduce an improved\nphysically-based rendering approach for Gaussian splats, estimating reflectance\nand lights per spectra, thereby enhancing accuracy and realism. In a\ncomprehensive quantitative and qualitative evaluation, we demonstrate the\nsuperior performance of our approach with respect to other recent\nlearning-based spectral scene representation approaches (i.e., XNeRF and\nSpectralNeRF) as well as other non-spectral state-of-the-art learning-based\napproaches. Our work also demonstrates the potential of spectral scene\nunderstanding for precise scene editing techniques like style transfer,\ninpainting, and removal. Thereby, our contributions address challenges in\nmulti-spectral scene representation, rendering, and editing, offering new\npossibilities for diverse applications.",
      "tldr_zh": "我们提出SpectralGaussians，一种基于3D Gaussian Splatting (3DGS)的跨光谱渲染框架，能够从注册的多视图光谱和分割图生成真实且语义有意义的splats，从而增强多光谱场景的表示和对底层材料及分割的洞见。该框架引入改进的基于物理的渲染方法，估计每个光谱的反射率和光照，提高了渲染的准确性和真实性。在定量和定性评估中，SpectralGaussians优于其他方法如XNeRF和SpectralNeRF，并展示了其在精确场景编辑（如风格转移、修复和移除）中的潜力，为多光谱场景表示、渲染和编辑的应用提供了新机遇。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.GR",
        "I.2.10; I.3.7; I.4.8; I.4.1"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.06975v1",
      "published_date": "2024-08-13 15:32:54 UTC",
      "updated_date": "2024-08-13 15:32:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:56:39.148151"
    },
    {
      "arxiv_id": "2408.06954v2",
      "title": "Neural Speech and Audio Coding: Modern AI Technology Meets Traditional Codecs",
      "title_zh": "翻译失败",
      "authors": [
        "Minje Kim",
        "Jan Skoglund"
      ],
      "abstract": "This paper explores the integration of model-based and data-driven approaches\nwithin the realm of neural speech and audio coding systems. It highlights the\nchallenges posed by the subjective evaluation processes of speech and audio\ncodecs and discusses the limitations of purely data-driven approaches, which\noften require inefficiently large architectures to match the performance of\nmodel-based methods. The study presents hybrid systems as a viable solution,\noffering significant improvements to the performance of conventional codecs\nthrough meticulously chosen design enhancements. Specifically, it introduces a\nneural network-based signal enhancer designed to post-process existing codecs'\noutput, along with the autoencoder-based end-to-end models and LPCNet--hybrid\nsystems that combine linear predictive coding (LPC) with neural networks.\nFurthermore, the paper delves into predictive models operating within custom\nfeature spaces (TF-Codec) or predefined transform domains (MDCTNet) and\nexamines the use of psychoacoustically calibrated loss functions to train\nend-to-end neural audio codecs. Through these investigations, the paper\ndemonstrates the potential of hybrid systems to advance the field of speech and\naudio coding by bridging the gap between traditional model-based approaches and\nmodern data-driven techniques.",
      "tldr_zh": "这篇论文探讨了神经语音和音频编码领域中模型驱动和数据驱动方法的整合，强调了主观评估挑战以及纯数据驱动方法（如需要大型架构）的局限性。论文提出混合系统作为解决方案，包括神经网络增强器用于后处理传统编解码器输出、基于 autoencoder 的端到端模型、LPCNet（结合线性预测编码和神经网络）、TF-Codec（在自定义特征空间中操作）和MDCTNet（在预定义变换域中操作）。通过引入心理声学校准的损失函数，研究展示了这些混合系统如何显著提升传统编解码器的性能，并桥接模型-based 和数据-driven 技术。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS",
        "eess.SP"
      ],
      "primary_category": "cs.SD",
      "comment": "Published in IEEE Signal Processing Magazine",
      "pdf_url": "http://arxiv.org/pdf/2408.06954v2",
      "published_date": "2024-08-13 15:13:21 UTC",
      "updated_date": "2025-01-07 04:11:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:56:51.540499"
    },
    {
      "arxiv_id": "2408.06945v2",
      "title": "Heavy-Ball Momentum Accelerated Actor-Critic With Function Approximation",
      "title_zh": "翻译失败",
      "authors": [
        "Yanjie Dong",
        "Haijun Zhang",
        "Gang Wang",
        "Shisheng Cui",
        "Xiping Hu"
      ],
      "abstract": "By using an parametric value function to replace the Monte-Carlo rollouts for\nvalue estimation, the actor-critic (AC) algorithms can reduce the variance of\nstochastic policy gradient so that to improve the convergence rate. While\nexisting works mainly focus on analyzing convergence rate of AC algorithms\nunder Markovian noise, the impacts of momentum on AC algorithms remain largely\nunexplored. In this work, we first propose a heavy-ball momentum based\nadvantage actor-critic (\\mbox{HB-A2C}) algorithm by integrating the heavy-ball\nmomentum into the critic recursion that is parameterized by a linear function.\nWhen the sample trajectory follows a Markov decision process, we quantitatively\ncertify the acceleration capability of the proposed HB-A2C algorithm. Our\ntheoretical results demonstrate that the proposed HB-A2C finds an\n$\\epsilon$-approximate stationary point with $\\oo{\\epsilon^{-2}}$ iterations\nfor reinforcement learning tasks with Markovian noise. Moreover, we also reveal\nthe dependence of learning rates on the length of the sample trajectory. By\ncarefully selecting the momentum factor of the critic recursion, the proposed\nHB-A2C can balance the errors introduced by the initialization and the\nstoschastic approximation.",
      "tldr_zh": "本研究提出了一种基于Heavy-Ball Momentum的加速优势演员-评论家（HB-A2C）算法，通过将Heavy-Ball动量整合到用线性函数参数化的评论家递归中，减少随机策略梯度的方差并提升收敛率。相比现有工作，该算法重点探讨了动量在Markov Decision Process下的影响，并证明HB-A2C能在O(ε^{-2})迭代内找到ε-近似静止点，同时揭示了学习率与样本轨迹长度的依赖关系。实验结果显示，通过优化动量因子，该算法能有效平衡初始化和随机逼近引入的错误，从而加速强化学习任务的处理。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.06945v2",
      "published_date": "2024-08-13 15:03:46 UTC",
      "updated_date": "2024-08-16 15:09:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:57:02.593994"
    },
    {
      "arxiv_id": "2408.08910v1",
      "title": "Why Do Experts Favor Solar and Wind as Renewable Energies Despite their Intermittency?",
      "title_zh": "翻译失败",
      "authors": [
        "Steven P. Reinhardt"
      ],
      "abstract": "As humanity accelerates its shift to renewable energy generation, people who\nare not experts in renewable energy are learning about energy technologies and\nthe energy market, which are complex. The answers to some questions will be\nobvious to expert practitioners but not to non-experts. One such question is\nWhy solar and wind generation are expected to supply the bulk of future energy\nwhen they are intermittent. We learn here that once the baseline hurdles of\nscalability to utility scale and the underlying resources being widely\navailable globally are satisfied, the forecasted cost of solar and wind is 2-4X\nlower than competing technologies, even those that are not as scalable and\navailable. The market views intermittency as surmountable.",
      "tldr_zh": "本论文探讨了专家为什么偏好太阳能和风能作为主要可再生能源，尽管它们具有间歇性(intermittency)。研究发现，一旦满足可扩展性(scalability)到实用规模和全球资源可用性，这些能源的预估成本比竞争技术低2-4倍，即使后者在可扩展性和可用性上不如前者。作者强调，市场将间歇性视为可克服的挑战，从而支持太阳能和风能主导未来的能源供应。",
      "categories": [
        "physics.soc-ph",
        "cs.AI"
      ],
      "primary_category": "physics.soc-ph",
      "comment": "Shifted references from hyperlinks to academic style",
      "pdf_url": "http://arxiv.org/pdf/2408.08910v1",
      "published_date": "2024-08-13 14:56:23 UTC",
      "updated_date": "2024-08-13 14:56:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:57:14.280646"
    },
    {
      "arxiv_id": "2408.06931v2",
      "title": "The advantages of context specific language models: the case of the Erasmian Language Model",
      "title_zh": "特定上下文语言模型的优势：Erasmian Language Model 的案例",
      "authors": [
        "João Gonçalves",
        "Nick Jelicic",
        "Michele Murgia",
        "Evert Stamhuis"
      ],
      "abstract": "The current trend to improve language model performance seems to be based on\nscaling up with the number of parameters (e.g. the state of the art GPT4 model\nhas approximately 1.7 trillion parameters) or the amount of training data fed\ninto the model. However this comes at significant costs in terms of\ncomputational resources and energy costs that compromise the sustainability of\nAI solutions, as well as risk relating to privacy and misuse. In this paper we\npresent the Erasmian Language Model (ELM) a small context specific, 900 million\nparameter model, pre-trained and fine-tuned by and for Erasmus University\nRotterdam. We show how the model performs adequately in a classroom context for\nessay writing, and how it achieves superior performance in subjects that are\npart of its context. This has implications for a wide range of institutions and\norganizations, showing that context specific language models may be a viable\nalternative for resource constrained, privacy sensitive use cases.",
      "tldr_zh": "本研究讨论了当前语言模型提升性能的趋势，即通过增加参数（如GPT-4的1.7万亿参数）或训练数据，但这导致了计算资源、能源消耗、隐私和滥用风险等问题。为此，作者提出Erasmian Language Model (ELM)，一个小型的特定上下文模型，仅有900百万参数，并针对埃拉斯mus大学罗特丹分校进行预训练和微调。实验结果显示，ELM在课堂作文写作中表现良好，尤其在相关学科上优于一般模型。这种方法为资源受限和隐私敏感的机构提供了一种可行的语言模型替代方案。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "12 pages, 3 figures, 1 table",
      "pdf_url": "http://arxiv.org/pdf/2408.06931v2",
      "published_date": "2024-08-13 14:34:59 UTC",
      "updated_date": "2025-04-23 11:31:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:57:26.561052"
    },
    {
      "arxiv_id": "2408.06930v2",
      "title": "Diagnosis extraction from unstructured Dutch echocardiogram reports using span- and document-level characteristic classification",
      "title_zh": "翻译失败",
      "authors": [
        "Bauke Arends",
        "Melle Vessies",
        "Dirk van Osch",
        "Arco Teske",
        "Pim van der Harst",
        "René van Es",
        "Bram van Es"
      ],
      "abstract": "Clinical machine learning research and AI driven clinical decision support\nmodels rely on clinically accurate labels. Manually extracting these labels\nwith the help of clinical specialists is often time-consuming and expensive.\nThis study tests the feasibility of automatic span- and document-level\ndiagnosis extraction from unstructured Dutch echocardiogram reports. We\nincluded 115,692 unstructured echocardiogram reports from the UMCU a large\nuniversity hospital in the Netherlands. A randomly selected subset was manually\nannotated for the occurrence and severity of eleven commonly described cardiac\ncharacteristics. We developed and tested several automatic labelling techniques\nat both span and document levels, using weighted and macro F1-score, precision,\nand recall for performance evaluation. We compared the performance of span\nlabelling against document labelling methods, which included both direct\ndocument classifiers and indirect document classifiers that rely on span\nclassification results. The SpanCategorizer and MedRoBERTa$.$nl models\noutperformed all other span and document classifiers, respectively. The\nweighted F1-score varied between characteristics, ranging from 0.60 to 0.93 in\nSpanCategorizer and 0.96 to 0.98 in MedRoBERTa$.$nl. Direct document\nclassification was superior to indirect document classification using span\nclassifiers. SetFit achieved competitive document classification performance\nusing only 10% of the training data. Utilizing a reduced label set yielded\nnear-perfect document classification results. We recommend using our published\nSpanCategorizer and MedRoBERTa$.$nl models for span- and document-level\ndiagnosis extraction from Dutch echocardiography reports. For settings with\nlimited training data, SetFit may be a promising alternative for document\nclassification.",
      "tldr_zh": "本研究探讨了从非结构化荷兰语超声心动图报告中自动提取诊断的可行性，旨在减少手动标注的耗时和成本。研究者使用11万多份UMCU报告，手动标注了11种心脏特征的发生和严重程度，并开发了span-level和document-level分类技术，包括SpanCategorizer和MedRoBERTa.nl模型。结果显示，SpanCategorizer在span-level分类中F1-score达0.60-0.93，MedRoBERTa.nl在document-level分类中达0.96-0.98，直接分类方法优于间接方法，且SetFit模型仅需10%的训练数据即可实现竞争性性能。作者推荐使用这些模型进行诊断提取，并在训练数据有限的场景中考虑SetFit作为替代方案。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "68T50, 68P20",
        "I.2.7; J.3; H.3.3"
      ],
      "primary_category": "cs.CL",
      "comment": "28 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2408.06930v2",
      "published_date": "2024-08-13 14:33:32 UTC",
      "updated_date": "2024-08-15 12:42:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:57:40.542846"
    },
    {
      "arxiv_id": "2408.06922v1",
      "title": "Temporal Variability and Multi-Viewed Self-Supervised Representations to Tackle the ASVspoof5 Deepfake Challenge",
      "title_zh": "时间变异性与多视图自监督表示用于应对 ASVspoof5 深度伪造挑战",
      "authors": [
        "Yuankun Xie",
        "Xiaopeng Wang",
        "Zhiyong Wang",
        "Ruibo Fu",
        "Zhengqi Wen",
        "Haonan Cheng",
        "Long Ye"
      ],
      "abstract": "ASVspoof5, the fifth edition of the ASVspoof series, is one of the largest\nglobal audio security challenges. It aims to advance the development of\ncountermeasure (CM) to discriminate bonafide and spoofed speech utterances. In\nthis paper, we focus on addressing the problem of open-domain audio deepfake\ndetection, which corresponds directly to the ASVspoof5 Track1 open condition.\nAt first, we comprehensively investigate various CM on ASVspoof5, including\ndata expansion, data augmentation, and self-supervised learning (SSL) features.\nDue to the high-frequency gaps characteristic of the ASVspoof5 dataset, we\nintroduce Frequency Mask, a data augmentation method that masks specific\nfrequency bands to improve CM robustness. Combining various scale of temporal\ninformation with multiple SSL features, our experiments achieved a minDCF of\n0.0158 and an EER of 0.55% on the ASVspoof 5 Track 1 evaluation progress set.",
      "tldr_zh": "这篇论文针对ASVspoof5挑战，专注于开放域音频深度伪造检测，旨在通过各种反制措施(CM)区分真实和伪造语音。研究者引入了Frequency Mask数据增强方法来处理数据集的高频差距，并结合时间变异性和多视图自监督学习(SSL)特征进行模型优化。实验结果显示，在ASVspoof5 Track1评估集上，该方法实现了minDCF 0.0158和EER 0.55%的出色性能，显著提升了音频安全检测的鲁棒性。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.06922v1",
      "published_date": "2024-08-13 14:15:15 UTC",
      "updated_date": "2024-08-13 14:15:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:57:54.029809"
    },
    {
      "arxiv_id": "2408.06920v1",
      "title": "Multi-Agent Continuous Control with Generative Flow Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Shuang Luo",
        "Yinchuan Li",
        "Shunyu Liu",
        "Xu Zhang",
        "Yunfeng Shao",
        "Chao Wu"
      ],
      "abstract": "Generative Flow Networks (GFlowNets) aim to generate diverse trajectories\nfrom a distribution in which the final states of the trajectories are\nproportional to the reward, serving as a powerful alternative to reinforcement\nlearning for exploratory control tasks. However, the individual-flow matching\nconstraint in GFlowNets limits their applications for multi-agent systems,\nespecially continuous joint-control problems. In this paper, we propose a novel\nMulti-Agent generative Continuous Flow Networks (MACFN) method to enable\nmultiple agents to perform cooperative exploration for various compositional\ncontinuous objects. Technically, MACFN trains decentralized\nindividual-flow-based policies in a centralized global-flow-based matching\nfashion. During centralized training, MACFN introduces a continuous flow\ndecomposition network to deduce the flow contributions of each agent in the\npresence of only global rewards. Then agents can deliver actions solely based\non their assigned local flow in a decentralized way, forming a joint policy\ndistribution proportional to the rewards. To guarantee the expressiveness of\ncontinuous flow decomposition, we theoretically derive a consistency condition\non the decomposition network. Experimental results demonstrate that the\nproposed method yields results superior to the state-of-the-art counterparts\nand better exploration capability. Our code is available at\nhttps://github.com/isluoshuang/MACFN.",
      "tldr_zh": "这篇论文提出了 Multi-Agent generative Continuous Flow Networks (MACFN)，一种新方法，用于解决 Generative Flow Networks (GFlowNets) 在多智能体连续控制问题中的局限性，特别是 individual-flow matching 约束。MACFN 通过集中式训练分散的个体流策略，并引入连续流分解网络来分解全局奖励下的智能体贡献，实现多个代理的合作探索和联合策略分布。实验结果显示，该方法在各种组合连续任务上优于最先进技术，并展现出更强的探索能力。",
      "categories": [
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.06920v1",
      "published_date": "2024-08-13 14:12:03 UTC",
      "updated_date": "2024-08-13 14:12:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:58:06.788789"
    },
    {
      "arxiv_id": "2408.06911v1",
      "title": "Heterogeneous Space Fusion and Dual-Dimension Attention: A New Paradigm for Speech Enhancement",
      "title_zh": "异构空间融合和双维度注意力：语音增强的新范式",
      "authors": [
        "Tao Zheng",
        "Liejun Wang",
        "Yinfeng Yu"
      ],
      "abstract": "Self-supervised learning has demonstrated impressive performance in speech\ntasks, yet there remains ample opportunity for advancement in the realm of\nspeech enhancement research. In addressing speech tasks, confining the\nattention mechanism solely to the temporal dimension poses limitations in\neffectively focusing on critical speech features. Considering the\naforementioned issues, our study introduces a novel speech enhancement\nframework, HFSDA, which skillfully integrates heterogeneous spatial features\nand incorporates a dual-dimension attention mechanism to significantly enhance\nspeech clarity and quality in noisy environments. By leveraging self-supervised\nlearning embeddings in tandem with Short-Time Fourier Transform (STFT)\nspectrogram features, our model excels at capturing both high-level semantic\ninformation and detailed spectral data, enabling a more thorough analysis and\nrefinement of speech signals. Furthermore, we employ the innovative\nOmni-dimensional Dynamic Convolution (ODConv) technology within the spectrogram\ninput branch, enabling enhanced extraction and integration of crucial\ninformation across multiple dimensions. Additionally, we refine the Conformer\nmodel by enhancing its feature extraction capabilities not only in the temporal\ndimension but also across the spectral domain. Extensive experiments on the\nVCTK-DEMAND dataset show that HFSDA is comparable to existing state-of-the-art\nmodels, confirming the validity of our approach.",
      "tldr_zh": "本文提出了一种新的语音增强框架 HFSDA，通过融合异构空间特征和引入双维度注意力机制，解决了传统注意力机制仅关注时间维度的局限性。框架结合自监督学习嵌入与 Short-Time Fourier Transform (STFT) 谱图特征，利用 Omni-dimensional Dynamic Convolution (ODConv) 技术增强多维度信息提取，并改进 Conformer 模型在时间和谱域的特征提取能力，从而实现对噪声环境语音信号的更全面分析和优化。在 VCTK-DEMAND 数据集上的实验显示，HFSDA 的性能与现有最先进模型相当，验证了其有效性。",
      "categories": [
        "eess.AS",
        "cs.AI"
      ],
      "primary_category": "eess.AS",
      "comment": "Accepted for publication by IEEE International Conference on Systems,\n  Man, and Cybernetics 2024",
      "pdf_url": "http://arxiv.org/pdf/2408.06911v1",
      "published_date": "2024-08-13 14:04:24 UTC",
      "updated_date": "2024-08-13 14:04:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:58:18.059066"
    },
    {
      "arxiv_id": "2408.16003v1",
      "title": "Meta-Learning for Federated Face Recognition in Imbalanced Data Regimes",
      "title_zh": "翻译失败",
      "authors": [
        "Arwin Gansekoele",
        "Emiel Hess",
        "Sandjai Bhulai"
      ],
      "abstract": "The growing privacy concerns surrounding face image data demand new\ntechniques that can guarantee user privacy. One such face recognition technique\nthat claims to achieve better user privacy is Federated Face Recognition (FRR),\na subfield of Federated Learning (FL). However, FFR faces challenges due to the\nheterogeneity of the data, given the large number of classes that need to be\nhandled. To overcome this problem, solutions are sought in the field of\npersonalized FL. This work introduces three new data partitions based on the\nCelebA dataset, each with a different form of data heterogeneity. It also\nproposes Hessian-Free Model Agnostic Meta-Learning (HF-MAML) in an FFR setting.\nWe show that HF-MAML scores higher in verification tests than current FFR\nmodels on three different CelebA data partitions. In particular, the\nverification scores improve the most in heterogeneous data partitions. To\nbalance personalization with the development of an effective global model, an\nembedding regularization term is introduced for the loss function. This term\ncan be combined with HF-MAML and is shown to increase global model verification\nperformance. Lastly, this work performs a fairness analysis, showing that\nHF-MAML and its embedding regularization extension can improve fairness by\nreducing the standard deviation over the client evaluation scores.",
      "tldr_zh": "该研究针对Federated Face Recognition (FFR) 在数据异质性和不平衡类别下的挑战，引入三种基于CelebA数据集的新数据分区，以模拟不同形式的异质性。论文提出Hessian-Free Model Agnostic Meta-Learning (HF-MAML) 方法，用于个性化Federated Learning (FL)，结果显示HF-MAML在验证测试中比现有FFR模型表现更好，尤其在异质数据分区中提升显著。针对个性化与全局模型平衡问题，添加嵌入正则化项到损失函数中，进一步提高了全局模型的验证性能，并通过公平性分析证明了HF-MAML及其扩展能降低客户端评估分数的标准差，从而改善系统公平性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.CV",
      "comment": "To appear in the IEEE FLTA 2024 proceedings",
      "pdf_url": "http://arxiv.org/pdf/2408.16003v1",
      "published_date": "2024-08-13 14:03:10 UTC",
      "updated_date": "2024-08-13 14:03:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:58:29.255260"
    },
    {
      "arxiv_id": "2408.06906v1",
      "title": "VNet: A GAN-based Multi-Tier Discriminator Network for Speech Synthesis Vocoders",
      "title_zh": "翻译失败",
      "authors": [
        "Yubing Cao",
        "Yongming Li",
        "Liejun Wang",
        "Yinfeng Yu"
      ],
      "abstract": "Since the introduction of Generative Adversarial Networks (GANs) in speech\nsynthesis, remarkable achievements have been attained. In a thorough\nexploration of vocoders, it has been discovered that audio waveforms can be\ngenerated at speeds exceeding real-time while maintaining high fidelity,\nachieved through the utilization of GAN-based models. Typically, the inputs to\nthe vocoder consist of band-limited spectral information, which inevitably\nsacrifices high-frequency details. To address this, we adopt the full-band Mel\nspectrogram information as input, aiming to provide the vocoder with the most\ncomprehensive information possible. However, previous studies have revealed\nthat the use of full-band spectral information as input can result in the issue\nof over-smoothing, compromising the naturalness of the synthesized speech. To\ntackle this challenge, we propose VNet, a GAN-based neural vocoder network that\nincorporates full-band spectral information and introduces a Multi-Tier\nDiscriminator (MTD) comprising multiple sub-discriminators to generate\nhigh-resolution signals. Additionally, we introduce an asymptotically\nconstrained method that modifies the adversarial loss of the generator and\ndiscriminator, enhancing the stability of the training process. Through\nrigorous experiments, we demonstrate that the VNet model is capable of\ngenerating high-fidelity speech and significantly improving the performance of\nthe vocoder.",
      "tldr_zh": "本研究针对语音合成中基于 GANs 的 vocoders 问题，提出 VNet 模型，该模型使用全带 Mel 谱图作为输入，以解决传统带限谱图导致的高频细节丢失问题，同时避免过平滑影响语音自然性。VNet 引入 Multi-Tier Discriminator (MTD)，由多个子鉴别器组成，用于生成高分辨率信号，并采用渐进约束方法修改生成器和鉴别器的对抗损失，以提升训练稳定性。通过实验验证，VNet 显著提高了语音编码器的性能，能够生成高保真语音。",
      "categories": [
        "eess.AS",
        "cs.AI"
      ],
      "primary_category": "eess.AS",
      "comment": "Accepted for publication by IEEE International Conference on Systems,\n  Man, and Cybernetics 2024",
      "pdf_url": "http://arxiv.org/pdf/2408.06906v1",
      "published_date": "2024-08-13 14:00:02 UTC",
      "updated_date": "2024-08-13 14:00:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:58:41.329700"
    },
    {
      "arxiv_id": "2408.06900v1",
      "title": "Entendre, a Social Bot Detection Tool for Niche, Fringe, and Extreme Social Media",
      "title_zh": "翻译失败",
      "authors": [
        "Pranav Venkatesh",
        "Kami Vinton",
        "Dhiraj Murthy",
        "Kellen Sharp",
        "Akaash Kolluri"
      ],
      "abstract": "Social bots-automated accounts that generate and spread content on social\nmedia-are exploiting vulnerabilities in these platforms to manipulate public\nperception and disseminate disinformation. This has prompted the development of\npublic bot detection services; however, most of these services focus primarily\non Twitter, leaving niche platforms vulnerable. Fringe social media platforms\nsuch as Parler, Gab, and Gettr often have minimal moderation, which facilitates\nthe spread of hate speech and misinformation. To address this gap, we introduce\nEntendre, an open-access, scalable, and platform-agnostic bot detection\nframework. Entendre can process a labeled dataset from any social platform to\nproduce a tailored bot detection model using a random forest classification\napproach, ensuring robust social bot detection. We exploit the idea that most\nsocial platforms share a generic template, where users can post content,\napprove content, and provide a bio (common data features). By emphasizing\ngeneral data features over platform-specific ones, Entendre offers rapid\nextensibility at the expense of some accuracy. To demonstrate Entendre's\neffectiveness, we used it to explore the presence of bots among accounts\nposting racist content on the now-defunct right-wing platform Parler. We\nexamined 233,000 posts from 38,379 unique users and found that 1,916 unique\nusers (4.99%) exhibited bot-like behavior. Visualization techniques further\nrevealed that these bots significantly impacted the network, amplifying\ninfluential rhetoric and hashtags (e.g., #qanon, #trump, #antilgbt). These\npreliminary findings underscore the need for tools like Entendre to monitor and\nassess bot activity across diverse platforms.",
      "tldr_zh": "本文介绍了 Entendre，一种开源、可扩展且平台无关的社交机器人检测工具，针对 Twitter 以外的利基和极端社交媒体（如 Parler、Gab 和 Gettr）进行检测，以应对这些平台上仇恨言论和虚假信息的传播。Entendre 采用随机森林分类器（random forest classification）基于通用数据特征（如用户帖子、点赞和个人简介）构建定制的机器人检测模型，实现快速扩展但可能略微牺牲准确性。在 Parler 平台的实验中，分析了 23.3 万条帖子，发现 4.99% 的用户（1,916 个）显示机器人行为，这些机器人显著放大了影响力的修辞和 hashtags（如 #qanon、#trump 和 #antilgbt）。这项研究突出了 Entendre 等工具在监控跨平台社交机器人活动方面的必要性。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.HC",
        "cs.SI",
        "J.4; I.2; I.7; K.4"
      ],
      "primary_category": "cs.CY",
      "comment": "6 pages",
      "pdf_url": "http://arxiv.org/pdf/2408.06900v1",
      "published_date": "2024-08-13 13:50:49 UTC",
      "updated_date": "2024-08-13 13:50:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:58:54.920419"
    },
    {
      "arxiv_id": "2408.06891v2",
      "title": "Automatic Feature Recognition and Dimensional Attributes Extraction From CAD Models for Hybrid Additive-Subtractive Manufacturing",
      "title_zh": "翻译失败",
      "authors": [
        "Muhammad Tayyab Khan",
        "Wenhe Feng",
        "Lequn Chen",
        "Ye Han Ng",
        "Nicholas Yew Jin Tan",
        "Seung Ki Moon"
      ],
      "abstract": "The integration of Computer-Aided Design (CAD), Computer-Aided Process\nPlanning (CAPP), and Computer-Aided Manufacturing (CAM) plays a crucial role in\nmodern manufacturing, facilitating seamless transitions from digital designs to\nphysical products. However, a significant challenge within this integration is\nthe Automatic Feature Recognition (AFR) of CAD models, especially in the\ncontext of hybrid manufacturing that combines subtractive and additive\nmanufacturing processes. Traditional AFR methods, focused mainly on the\nidentification of subtractive (machined) features including holes, fillets,\nchamfers, pockets, and slots, fail to recognize features pertinent to additive\nmanufacturing. Furthermore, the traditional methods fall short in accurately\nextracting geometric dimensions and orientations, which are also key factors\nfor effective manufacturing process planning. This paper presents a novel\napproach for creating a synthetic CAD dataset that encompasses features\nrelevant to both additive and subtractive machining through Python Open\nCascade. The Hierarchical Graph Convolutional Neural Network (HGCNN) model is\nimplemented to accurately identify the composite additive-subtractive features\nwithin the synthetic CAD dataset. The key novelty and contribution of the\nproposed methodology lie in its ability to recognize a wide range of\nmanufacturing features, and precisely extracting their dimensions,\norientations, and stock sizes. The proposed model demonstrates remarkable\nfeature recognition accuracy exceeding 97% and a dimension extraction accuracy\nof 100% for identified features. Therefore, the proposed methodology enhances\nthe integration of CAD, CAPP, and CAM within hybrid manufacturing by providing\nprecise feature recognition and dimension extraction. It facilitates improved\nmanufacturing process planning, by enabling more informed decision-making.",
      "tldr_zh": "本文提出一种新型方法，用于Automatic Feature Recognition (AFR) 和从CAD模型中提取几何尺寸属性，以支持混合加法-减法制造。针对传统AFR方法无法识别加法制造特征并准确提取尺寸和方向的问题，该方法使用Python Open Cascade创建合成CAD数据集，并采用Hierarchical Graph Convolutional Neural Network (HGCNN) 模型来识别复合特征。实验结果显示，该模型的特征识别准确率超过97%，而提取尺寸的准确率达100%。这一创新增强了CAD、CAPP和CAM的整合，促进了更高效的制造过程规划和决策。",
      "categories": [
        "cs.AI",
        "cs.CE",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "10 pages, 12 figures. This paper has been accepted for presentation\n  at the ASME IDETC-CIE 2024 conference",
      "pdf_url": "http://arxiv.org/pdf/2408.06891v2",
      "published_date": "2024-08-13 13:38:32 UTC",
      "updated_date": "2024-08-14 05:16:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:59:06.263311"
    },
    {
      "arxiv_id": "2408.06890v2",
      "title": "BMFT: Achieving Fairness via Bias-based Weight Masking Fine-tuning",
      "title_zh": "BMFT：通过基于偏差的权重掩码微调实现公平性",
      "authors": [
        "Yuyang Xue",
        "Junyu Yan",
        "Raman Dutt",
        "Fasih Haider",
        "Jingshuai Liu",
        "Steven McDonagh",
        "Sotirios A. Tsaftaris"
      ],
      "abstract": "Developing models with robust group fairness properties is paramount,\nparticularly in ethically sensitive domains such as medical diagnosis. Recent\napproaches to achieving fairness in machine learning require a substantial\namount of training data and depend on model retraining, which may not be\npractical in real-world scenarios. To mitigate these challenges, we propose\nBias-based Weight Masking Fine-Tuning (BMFT), a novel post-processing method\nthat enhances the fairness of a trained model in significantly fewer epochs\nwithout requiring access to the original training data. BMFT produces a mask\nover model parameters, which efficiently identifies the weights contributing\nthe most towards biased predictions. Furthermore, we propose a two-step\ndebiasing strategy, wherein the feature extractor undergoes initial fine-tuning\non the identified bias-influenced weights, succeeded by a fine-tuning phase on\na reinitialised classification layer to uphold discriminative performance.\nExtensive experiments across four dermatological datasets and two sensitive\nattributes demonstrate that BMFT outperforms existing state-of-the-art (SOTA)\ntechniques in both diagnostic accuracy and fairness metrics. Our findings\nunderscore the efficacy and robustness of BMFT in advancing fairness across\nvarious out-of-distribution (OOD) settings. Our code is available at:\nhttps://github.com/vios-s/BMFT",
      "tldr_zh": "该论文针对机器学习模型的公平性问题，特别是在医疗诊断等领域，提出了一种新型后处理方法 BMFT（Bias-based Weight Masking Fine-Tuning），旨在通过权重掩码识别偏置权重，并在不需原始训练数据的情况下，仅需少量 epoch 进行微调。BMFT 的两步去偏策略包括先微调特征提取器以减少偏置影响，随后微调重新初始化的分类层，以保持模型的辨别性能。实验结果显示，在四个皮肤病数据集和两种敏感属性上，BMFT 超过了现有 SOTA 技术，在诊断准确性和公平性指标上表现出色，尤其在 OOD（out-of-distribution）设置中。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by MICCAI 2024 FAIMI Workshop Oral",
      "pdf_url": "http://arxiv.org/pdf/2408.06890v2",
      "published_date": "2024-08-13 13:36:48 UTC",
      "updated_date": "2024-10-01 13:10:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:59:17.709879"
    },
    {
      "arxiv_id": "2408.06876v2",
      "title": "Decision-Focused Learning to Predict Action Costs for Planning",
      "title_zh": "翻译失败",
      "authors": [
        "Jayanta Mandi",
        "Marco Foschini",
        "Daniel Holler",
        "Sylvie Thiebaux",
        "Jorg Hoffmann",
        "Tias Guns"
      ],
      "abstract": "In many automated planning applications, action costs can be hard to specify.\nAn example is the time needed to travel through a certain road segment, which\ndepends on many factors, such as the current weather conditions. A natural way\nto address this issue is to learn to predict these parameters based on input\nfeatures (e.g., weather forecasts) and use the predicted action costs in\nautomated planning afterward. Decision-Focused Learning (DFL) has been\nsuccessful in learning to predict the parameters of combinatorial optimization\nproblems in a way that optimizes solution quality rather than prediction\nquality. This approach yields better results than treating prediction and\noptimization as separate tasks. In this paper, we investigate for the first\ntime the challenges of implementing DFL for automated planning in order to\nlearn to predict the action costs. There are two main challenges to overcome:\n(1) planning systems are called during gradient descent learning, to solve\nplanning problems with negative action costs, which are not supported in\nplanning. We propose novel methods for gradient computation to avoid this\nissue. (2) DFL requires repeated planner calls during training, which can limit\nthe scalability of the method. We experiment with different methods\napproximating the optimal plan as well as an easy-to-implement caching\nmechanism to speed up the learning process. As the first work that addresses\nDFL for automated planning, we demonstrate that the proposed gradient\ncomputation consistently yields significantly better plans than predictions\naimed at minimizing prediction error; and that caching can temper the\ncomputation requirements.",
      "tldr_zh": "本文提出了一种 Decision-Focused Learning (DFL) 方法，用于预测自动规划中的行动成本（如旅行时间），以优化规划解决方案质量，而不是单纯最小化预测误差。该方法针对两个主要挑战：一是处理规划系统中可能出现的负行动成本问题，通过创新的梯度计算技术避免其影响；二是提升训练的可扩展性，实验了近似最优计划方法和缓存机制来减少反复调用规划器的计算开销。实验结果显示，DFL 显著提高了规划性能，比传统最小化预测误差的方法更有效，并证明了缓存机制能显著降低计算需求。",
      "categories": [
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.06876v2",
      "published_date": "2024-08-13 13:14:54 UTC",
      "updated_date": "2024-08-26 11:29:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:59:29.184689"
    },
    {
      "arxiv_id": "2408.06875v2",
      "title": "Advancing Interactive Explainable AI via Belief Change Theory",
      "title_zh": "通过信念变化理论推进交互式可解释 AI",
      "authors": [
        "Antonio Rago",
        "Maria Vanina Martinez"
      ],
      "abstract": "As AI models become ever more complex and intertwined in humans' daily lives,\ngreater levels of interactivity of explainable AI (XAI) methods are needed. In\nthis paper, we propose the use of belief change theory as a formal foundation\nfor operators that model the incorporation of new information, i.e. user\nfeedback in interactive XAI, to logical representations of data-driven\nclassifiers. We argue that this type of formalisation provides a framework and\na methodology to develop interactive explanations in a principled manner,\nproviding warranted behaviour and favouring transparency and accountability of\nsuch interactions. Concretely, we first define a novel, logic-based formalism\nto represent explanatory information shared between humans and machines. We\nthen consider real world scenarios for interactive XAI, with different\nprioritisations of new and existing knowledge, where our formalism may be\ninstantiated. Finally, we analyse a core set of belief change postulates,\ndiscussing their suitability for our real world settings and pointing to\nparticular challenges that may require the relaxation or reinterpretation of\nsome of the theoretical assumptions underlying existing operators.",
      "tldr_zh": "这篇论文提出使用信念变化理论（belief change theory）作为交互式可解释 AI (XAI) 的形式基础，以系统地处理用户反馈并整合到数据驱动分类器的逻辑表示中。作者定义了一个新的逻辑-based 形式主义，用于表示人类和机器之间的解释信息，并探讨了不同现实场景下的应用，例如优先考虑新旧知识。最终，通过分析核心信念变化假设，该框架提升了交互式解释的透明度和责任性，但也指出了某些理论假设可能需要在实际设置中进行放松或重新解释。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "9 pages. To be published at KR 2024",
      "pdf_url": "http://arxiv.org/pdf/2408.06875v2",
      "published_date": "2024-08-13 13:11:56 UTC",
      "updated_date": "2024-08-14 11:23:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:59:41.303112"
    },
    {
      "arxiv_id": "2408.06872v1",
      "title": "Generative AI Tools in Academic Research: Applications and Implications for Qualitative and Quantitative Research Methodologies",
      "title_zh": "生成式 AI 工具在学术研究中的应用及其对定性和定量研究方法论的影响",
      "authors": [
        "Mike Perkins",
        "Jasper Roe"
      ],
      "abstract": "This study examines the impact of Generative Artificial Intelligence (GenAI)\non academic research, focusing on its application to qualitative and\nquantitative data analysis. As GenAI tools evolve rapidly, they offer new\npossibilities for enhancing research productivity and democratising complex\nanalytical processes. However, their integration into academic practice raises\nsignificant questions regarding research integrity and security, authorship,\nand the changing nature of scholarly work. Through an examination of current\ncapabilities and potential future applications, this study provides insights\ninto how researchers may utilise GenAI tools responsibly and ethically.\n  We present case studies that demonstrate the application of GenAI in various\nresearch methodologies, discuss the challenges of replicability and consistency\nin AI-assisted research, and consider the ethical implications of increased AI\nintegration in academia. This study explores both qualitative and quantitative\napplications of GenAI, highlighting tools for transcription, coding, thematic\nanalysis, visual analytics, and statistical analysis. By addressing these\nissues, we aim to contribute to the ongoing discourse on the role of AI in\nshaping the future of academic research and provide guidance for researchers\nexploring the rapidly evolving landscape of AI-assisted research tools and\nresearch.",
      "tldr_zh": "本研究探讨了生成式人工智能 (GenAI) 在学术研究中的应用及其对定性和定量研究方法的影响，强调了 GenAI 如何提升研究生产力和简化复杂分析过程，同时促进学术民主化。研究通过案例分析展示了 GenAI 在转录、编码、主观分析、视觉分析和统计分析中的实际应用，并讨论了相关挑战，如研究完整性、安全性、作者权问题以及 AI 辅助研究的复制性和一致性问题。最终，该研究提供了负责任使用 GenAI 的伦理指导，帮助研究者应对 AI 在学术领域的快速演变。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.06872v1",
      "published_date": "2024-08-13 13:10:03 UTC",
      "updated_date": "2024-08-13 13:10:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:59:56.593181"
    },
    {
      "arxiv_id": "2408.08909v1",
      "title": "An Adaptive Differential Privacy Method Based on Federated Learning",
      "title_zh": "基于联邦学习的自适应差",
      "authors": [
        "Zhiqiang Wang",
        "Xinyue Yu",
        "Qianli Huang",
        "Yongguang Gong"
      ],
      "abstract": "Differential privacy is one of the methods to solve the problem of privacy\nprotection in federated learning. Setting the same privacy budget for each\nround will result in reduced accuracy in training. The existing methods of the\nadjustment of privacy budget consider fewer influencing factors and tend to\nignore the boundaries, resulting in unreasonable privacy budgets. Therefore, we\nproposed an adaptive differential privacy method based on federated learning.\nThe method sets the adjustment coefficient and scoring function according to\naccuracy, loss, training rounds, and the number of datasets and clients. And\nthe privacy budget is adjusted based on them. Then the local model update is\nprocessed according to the scaling factor and the noise. Fi-nally, the server\naggregates the noised local model update and distributes the noised global\nmodel. The range of parameters and the privacy of the method are analyzed.\nThrough the experimental evaluation, it can reduce the privacy budget by about\n16%, while the accuracy remains roughly the same.",
      "tldr_zh": "本文提出了一种基于联邦学习的自适应差分隐私（Differential Privacy）方法，以解决传统固定隐私预算导致训练准确率降低的问题。该方法通过结合准确率、损失、训练轮数、数据集数量和客户端数量等因素，设置调整系数和评分函数来动态调整隐私预算，并使用缩放因子和噪声处理本地模型更新，最终由服务器聚合并分发全局模型。实验评估显示，该方法可将隐私预算降低约16%，同时保持准确率基本不变，从而在保护隐私的同时提升联邦学习效率。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.DC"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.08909v1",
      "published_date": "2024-08-13 13:08:11 UTC",
      "updated_date": "2024-08-13 13:08:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T15:00:06.200916"
    },
    {
      "arxiv_id": "2408.06851v1",
      "title": "BSS-CFFMA: Cross-Domain Feature Fusion and Multi-Attention Speech Enhancement Network based on Self-Supervised Embedding",
      "title_zh": "BSS-CFFMA：基于自监督嵌入的跨域特征融合和多注意力语音增强网络",
      "authors": [
        "Alimjan Mattursun",
        "Liejun Wang",
        "Yinfeng Yu"
      ],
      "abstract": "Speech self-supervised learning (SSL) represents has achieved\nstate-of-the-art (SOTA) performance in multiple downstream tasks. However, its\napplication in speech enhancement (SE) tasks remains immature, offering\nopportunities for improvement. In this study, we introduce a novel cross-domain\nfeature fusion and multi-attention speech enhancement network, termed\nBSS-CFFMA, which leverages self-supervised embeddings. BSS-CFFMA comprises a\nmulti-scale cross-domain feature fusion (MSCFF) block and a residual hybrid\nmulti-attention (RHMA) block. The MSCFF block effectively integrates\ncross-domain features, facilitating the extraction of rich acoustic\ninformation. The RHMA block, serving as the primary enhancement module,\nutilizes three distinct attention modules to capture diverse attention\nrepresentations and estimate high-quality speech signals.\n  We evaluate the performance of the BSS-CFFMA model through comparative and\nablation studies on the VoiceBank-DEMAND dataset, achieving SOTA results.\nFurthermore, we select three types of data from the WHAMR! dataset, a\ncollection specifically designed for speech enhancement tasks, to assess the\ncapabilities of BSS-CFFMA in tasks such as denoising only, dereverberation\nonly, and simultaneous denoising and dereverberation. This study marks the\nfirst attempt to explore the effectiveness of self-supervised embedding-based\nspeech enhancement methods in complex tasks encompassing dereverberation and\nsimultaneous denoising and dereverberation. The demo implementation of\nBSS-CFFMA is available online\\footnote[2]{https://github.com/AlimMat/BSS-CFFMA.\n\\label{s1}}.",
      "tldr_zh": "本研究提出了一种基于自监督嵌入（self-supervised embedding）的语音增强网络BSS-CFFMA，用于提升语音增强（speech enhancement）任务的性能。该网络包括多尺度跨域特征融合（MSCFF）块和残差混合多注意力（RHMA）块，其中MSCFF块整合跨域特征以提取丰富声学信息，而RHMA块通过三种不同注意力模块捕获多样化表示并生成高质量语音信号。在VoiceBank-DEMAND数据集上，BSS-CFFMA实现了state-of-the-art (SOTA)结果，并在WHAMR!数据集的去噪、去混响和同时去噪去混响任务中表现出色，这是首次探索self-supervised embedding方法在这些复杂任务中的有效性。",
      "categories": [
        "eess.AS",
        "cs.AI"
      ],
      "primary_category": "eess.AS",
      "comment": "Accepted for publication by IEEE International Conference on Systems,\n  Man, and Cybernetics 2024",
      "pdf_url": "http://arxiv.org/pdf/2408.06851v1",
      "published_date": "2024-08-13 12:27:24 UTC",
      "updated_date": "2024-08-13 12:27:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T15:00:18.343594"
    },
    {
      "arxiv_id": "2408.06849v1",
      "title": "Causal Agent based on Large Language Model",
      "title_zh": "基于大型语言模型的因果代理",
      "authors": [
        "Kairong Han",
        "Kun Kuang",
        "Ziyu Zhao",
        "Junjian Ye",
        "Fei Wu"
      ],
      "abstract": "Large language models (LLMs) have achieved significant success across various\ndomains. However, the inherent complexity of causal problems and causal theory\nposes challenges in accurately describing them in natural language, making it\ndifficult for LLMs to comprehend and use them effectively. Causal methods are\nnot easily conveyed through natural language, which hinders LLMs' ability to\napply them accurately. Additionally, causal datasets are typically tabular,\nwhile LLMs excel in handling natural language data, creating a structural\nmismatch that impedes effective reasoning with tabular data. This lack of\ncausal reasoning capability limits the development of LLMs. To address these\nchallenges, we have equipped the LLM with causal tools within an agent\nframework, named the Causal Agent, enabling it to tackle causal problems. The\ncausal agent comprises tools, memory, and reasoning modules. In the tools\nmodule, the causal agent applies causal methods to align tabular data with\nnatural language. In the reasoning module, the causal agent employs the ReAct\nframework to perform reasoning through multiple iterations with the tools. In\nthe memory module, the causal agent maintains a dictionary instance where the\nkeys are unique names and the values are causal graphs. To verify the causal\nability of the causal agent, we established a benchmark consisting of four\nlevels of causal problems: variable level, edge level, causal graph level, and\ncausal effect level. We generated a test dataset of 1.3K using ChatGPT-3.5 for\nthese four levels of issues and tested the causal agent on the datasets. Our\nmethodology demonstrates remarkable efficacy on the four-level causal problems,\nwith accuracy rates all above 80%. For further insights and implementation\ndetails, our code is accessible via the GitHub repository\nhttps://github.com/Kairong-Han/Causal_Agent.",
      "tldr_zh": "该论文指出，大型语言模型（Large Language Models, LLMs）在处理因果问题时面临描述复杂性和数据格式不匹配等挑战，因此提出了一种名为Causal Agent的代理框架，以增强LLMs的因果推理能力。Causal Agent 包括工具模块（用于将表格数据与自然语言对齐）、推理模块（采用ReAct框架进行多轮迭代推理）和记忆模块（维护因果图字典）。通过构建一个四级因果问题基准（variable level、edge level、causal graph level 和 causal effect level）并使用ChatGPT-3.5生成1.3K测试数据集，框架在所有级别上实现了超过80%的准确率，为LLMs应用因果方法提供了有效解决方案。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.06849v1",
      "published_date": "2024-08-13 12:22:26 UTC",
      "updated_date": "2024-08-13 12:22:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T15:00:31.976768"
    },
    {
      "arxiv_id": "2408.06847v1",
      "title": "AI Research is not Magic, it has to be Reproducible and Responsible: Challenges in the AI field from the Perspective of its PhD Students",
      "title_zh": "翻译失败",
      "authors": [
        "Andrea Hrckova",
        "Jennifer Renoux",
        "Rafael Tolosana Calasanz",
        "Daniela Chuda",
        "Martin Tamajka",
        "Jakub Simko"
      ],
      "abstract": "With the goal of uncovering the challenges faced by European AI students\nduring their research endeavors, we surveyed 28 AI doctoral candidates from 13\nEuropean countries. The outcomes underscore challenges in three key areas: (1)\nthe findability and quality of AI resources such as datasets, models, and\nexperiments; (2) the difficulties in replicating the experiments in AI papers;\n(3) and the lack of trustworthiness and interdisciplinarity. From our findings,\nit appears that although early stage AI researchers generally tend to share\ntheir AI resources, they lack motivation or knowledge to engage more in dataset\nand code preparation and curation, and ethical assessments, and are not used to\ncooperate with well-versed experts in application domains. Furthermore, we\nexamine existing practices in data governance and reproducibility both in\ncomputer science and in artificial intelligence. For instance, only a minority\nof venues actively promote reproducibility initiatives such as reproducibility\nevaluations.\n  Critically, there is need for immediate adoption of responsible and\nreproducible AI research practices, crucial for society at large, and essential\nfor the AI research community in particular. This paper proposes a combination\nof social and technical recommendations to overcome the identified challenges.\nSocially, we propose the general adoption of reproducibility initiatives in AI\nconferences and journals, as well as improved interdisciplinary collaboration,\nespecially in data governance practices. On the technical front, we call for\nenhanced tools to better support versioning control of datasets and code, and a\ncomputing infrastructure that facilitates the sharing and discovery of AI\nresources, as well as the sharing, execution, and verification of experiments.",
      "tldr_zh": "本研究通过调查28名来自13个欧洲国家的AI博士生，揭示了AI领域的主要挑战，包括AI resources（如数据集、模型和实验）的findability和quality问题、实验reproducibility的困难，以及trustworthiness和interdisciplinarity的缺失。调查发现，虽然早期AI研究者倾向于分享资源，但他们往往缺乏动机或知识来处理数据集和代码的准备、curation和伦理评估，且不习惯与应用领域专家合作。作者分析了计算机科学和AI中的现有数据governance和reproducibility实践，并提出社会建议（如在AI会议和期刊中推广reproducibility举措及加强跨学科合作）和技术建议（如开发更好的工具支持数据集和代码的versioning control，以及改进计算基础设施以促进资源共享和实验验证）。这些措施旨在推动AI研究变得更负责任和可重复，从而造福整个社会和研究社区。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "8 pages, 4 figures, 1 appendix (interview questions)",
      "pdf_url": "http://arxiv.org/pdf/2408.06847v1",
      "published_date": "2024-08-13 12:19:02 UTC",
      "updated_date": "2024-08-13 12:19:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T15:00:43.650748"
    },
    {
      "arxiv_id": "2408.15276v1",
      "title": "A Survey of Deep Learning for Group-level Emotion Recognition",
      "title_zh": "翻译失败",
      "authors": [
        "Xiaohua Huang",
        "Jinke Xu",
        "Wenming Zheng",
        "Qirong Mao",
        "Abhinav Dhall"
      ],
      "abstract": "With the advancement of artificial intelligence (AI) technology, group-level\nemotion recognition (GER) has emerged as an important area in analyzing human\nbehavior. Early GER methods are primarily relied on handcrafted features.\nHowever, with the proliferation of Deep Learning (DL) techniques and their\nremarkable success in diverse tasks, neural networks have garnered increasing\ninterest in GER. Unlike individual's emotion, group emotions exhibit diversity\nand dynamics. Presently, several DL approaches have been proposed to\neffectively leverage the rich information inherent in group-level image and\nenhance GER performance significantly. In this survey, we present a\ncomprehensive review of DL techniques applied to GER, proposing a new taxonomy\nfor the field cover all aspects of GER based on DL. The survey overviews\ndatasets, the deep GER pipeline, and performance comparisons of the\nstate-of-the-art methods past decade. Moreover, it summarizes and discuss the\nfundamental approaches and advanced developments for each aspect. Furthermore,\nwe identify outstanding challenges and suggest potential avenues for the design\nof robust GER systems. To the best of our knowledge, thus survey represents the\nfirst comprehensive review of deep GER methods, serving as a pivotal references\nfor future GER research endeavors.",
      "tldr_zh": "本调查综述了深度学习（Deep Learning）在群体级情感识别（Group-level Emotion Recognition, GER）中的应用，强调了与个体情感不同，GER 具有多样性和动态性。论文提出一个新的分类法，涵盖数据集、深度 GER 管道以及过去十年的最先进方法的性能比较。作者总结了基本方法和高级发展，如利用群体级图像的丰富信息来提升识别性能，并识别了关键挑战，例如处理多样性数据的问题。最终，论文建议了设计鲁棒 GER 系统的潜在方向，为未来研究提供重要参考。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "16 pages, 2 figures",
      "pdf_url": "http://arxiv.org/pdf/2408.15276v1",
      "published_date": "2024-08-13 11:54:09 UTC",
      "updated_date": "2024-08-13 11:54:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T15:00:54.010656"
    },
    {
      "arxiv_id": "2408.06820v1",
      "title": "Efficient Search for Customized Activation Functions with Gradient Descent",
      "title_zh": "翻译失败",
      "authors": [
        "Lukas Strack",
        "Mahmoud Safari",
        "Frank Hutter"
      ],
      "abstract": "Different activation functions work best for different deep learning models.\nTo exploit this, we leverage recent advancements in gradient-based search\ntechniques for neural architectures to efficiently identify high-performing\nactivation functions for a given application. We propose a fine-grained search\ncell that combines basic mathematical operations to model activation functions,\nallowing for the exploration of novel activations. Our approach enables the\nidentification of specialized activations, leading to improved performance in\nevery model we tried, from image classification to language models. Moreover,\nthe identified activations exhibit strong transferability to larger models of\nthe same type, as well as new datasets. Importantly, our automated process for\ncreating customized activation functions is orders of magnitude more efficient\nthan previous approaches. It can easily be applied on top of arbitrary deep\nlearning pipelines and thus offers a promising practical avenue for enhancing\ndeep learning architectures.",
      "tldr_zh": "这篇论文提出了一种基于 gradient descent 的高效搜索方法，用于为特定深度学习应用定制高性能的激活 functions。研究者设计了一个细粒度搜索单元，通过基本数学运算的组合来探索新颖的激活函数，从而解决不同模型对激活函数的个性化需求。实验结果显示，该方法在图像分类和语言模型等任务上显著提高了模型性能，且这些定制激活函数在更大模型和新数据集上表现出强转移性。该方法比以往方法高效几个数量级，并可轻松应用于任意深度学习管道中，提供了一个实用途径来提升架构性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "10 pages, 1 figure, excluding references and appendix",
      "pdf_url": "http://arxiv.org/pdf/2408.06820v1",
      "published_date": "2024-08-13 11:27:31 UTC",
      "updated_date": "2024-08-13 11:27:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T15:01:06.734711"
    },
    {
      "arxiv_id": "2408.06818v1",
      "title": "Personalized Dynamic Difficulty Adjustment -- Imitation Learning Meets Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Ronja Fuchs",
        "Robin Gieseke",
        "Alexander Dockhorn"
      ],
      "abstract": "Balancing game difficulty in video games is a key task to create interesting\ngaming experiences for players. Mismatching the game difficulty and a player's\nskill or commitment results in frustration or boredom on the player's side, and\nhence reduces time spent playing the game. In this work, we explore balancing\ngame difficulty using machine learning-based agents to challenge players based\non their current behavior. This is achieved by a combination of two agents, in\nwhich one learns to imitate the player, while the second is trained to beat the\nfirst. In our demo, we investigate the proposed framework for personalized\ndynamic difficulty adjustment of AI agents in the context of the fighting game\nAI competition.",
      "tldr_zh": "这篇论文探讨了在视频游戏中实现 Personalized Dynamic Difficulty Adjustment 的方法，以匹配玩家的技能和承诺，避免 frustration 或 boredom。方法结合 Imitation Learning 和 Reinforcement Learning，通过训练两个代理：一个代理学习模仿玩家的行为，另一个代理被训练来击败前者，从而动态调整游戏难度。在格斗游戏 AI 竞赛的演示中，该框架证明了其在个性化挑战玩家方面的有效性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "2 pages, the code to our demo can be found here:\n  https://github.com/ronjafuchs/ICE_AI",
      "pdf_url": "http://arxiv.org/pdf/2408.06818v1",
      "published_date": "2024-08-13 11:24:12 UTC",
      "updated_date": "2024-08-13 11:24:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T15:01:21.950078"
    },
    {
      "arxiv_id": "2408.06816v2",
      "title": "MAQA: Evaluating Uncertainty Quantification in LLMs Regarding Data Uncertainty",
      "title_zh": "翻译失败",
      "authors": [
        "Yongjin Yang",
        "Haneul Yoo",
        "Hwaran Lee"
      ],
      "abstract": "Despite the massive advancements in large language models (LLMs), they still\nsuffer from producing plausible but incorrect responses. To improve the\nreliability of LLMs, recent research has focused on uncertainty quantification\nto predict whether a response is correct or not. However, most uncertainty\nquantification methods have been evaluated on single-labeled questions, which\nremoves data uncertainty: the irreducible randomness often present in user\nqueries, which can arise from factors like multiple possible answers. This\nlimitation may cause uncertainty quantification results to be unreliable in\npractical settings. In this paper, we investigate previous uncertainty\nquantification methods under the presence of data uncertainty. Our\ncontributions are two-fold: 1) proposing a new Multi-Answer Question Answering\ndataset, MAQA, consisting of world knowledge, mathematical reasoning, and\ncommonsense reasoning tasks to evaluate uncertainty quantification regarding\ndata uncertainty, and 2) assessing 5 uncertainty quantification methods of\ndiverse white- and black-box LLMs. Our findings show that previous methods\nrelatively struggle compared to single-answer settings, though this varies\ndepending on the task. Moreover, we observe that entropy- and consistency-based\nmethods effectively estimate model uncertainty, even in the presence of data\nuncertainty. We believe these observations will guide future work on\nuncertainty quantification in more realistic settings.",
      "tldr_zh": "这篇论文探讨了大型语言模型(LLMs)的不确定性量化(uncertainty quantification)方法在数据不确定性(data uncertainty)下的表现问题，因为现有方法主要基于单答案问题，导致实际应用可靠性不足。论文的主要贡献包括：提出一个新的多答案问答数据集MAQA，涵盖世界知识、数学推理和常识推理任务，用于评估数据不确定性；以及评估5种白盒和黑盒LLMs的不确定性量化方法。研究发现，这些方法在多答案设置中整体表现较差，但entropy-based和consistency-based方法能够有效估计模型不确定性，即使在数据不确定性存在时。这些观察为未来在更现实场景下的不确定性量化研究提供了重要指导。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "Findings of NAACL 2025",
      "pdf_url": "http://arxiv.org/pdf/2408.06816v2",
      "published_date": "2024-08-13 11:17:31 UTC",
      "updated_date": "2025-03-31 13:03:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T15:01:32.152834"
    },
    {
      "arxiv_id": "2408.08907v1",
      "title": "What should I wear to a party in a Greek taverna? Evaluation for Conversational Agents in the Fashion Domain",
      "title_zh": "翻译失败",
      "authors": [
        "Antonis Maronikolakis",
        "Ana Peleteiro Ramallo",
        "Weiwei Cheng",
        "Thomas Kober"
      ],
      "abstract": "Large language models (LLMs) are poised to revolutionize the domain of online\nfashion retail, enhancing customer experience and discovery of fashion online.\nLLM-powered conversational agents introduce a new way of discovery by directly\ninteracting with customers, enabling them to express in their own ways, refine\ntheir needs, obtain fashion and shopping advice that is relevant to their taste\nand intent. For many tasks in e-commerce, such as finding a specific product,\nconversational agents need to convert their interactions with a customer to a\nspecific call to different backend systems, e.g., a search system to showcase a\nrelevant set of products. Therefore, evaluating the capabilities of LLMs to\nperform those tasks related to calling other services is vital. However, those\nevaluations are generally complex, due to the lack of relevant and high quality\ndatasets, and do not align seamlessly with business needs, amongst others. To\nthis end, we created a multilingual evaluation dataset of 4k conversations\nbetween customers and a fashion assistant in a large e-commerce fashion\nplatform to measure the capabilities of LLMs to serve as an assistant between\ncustomers and a backend engine. We evaluate a range of models, showcasing how\nour dataset scales to business needs and facilitates iterative development of\ntools.",
      "tldr_zh": "这篇论文探讨了大型语言模型（LLMs）在时尚电商领域的应用，特别是作为对话代理来提升客户互动和产品发现体验。作者创建了一个包含4k条多语言对话的数据集，用于评估LLMs将客户查询转化为后端系统调用（如搜索引擎）的能力，以解决现有评估方法缺乏高质量数据和业务相关性的问题。通过测试多种模型，论文展示了该数据集如何有效支持电商需求的迭代开发，并为LLMs在conversational agents中的性能提供了量化基准。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CL",
        "cs.HC"
      ],
      "primary_category": "cs.IR",
      "comment": "Accepted at KDD workshop on Evaluation and Trustworthiness of\n  Generative AI Models",
      "pdf_url": "http://arxiv.org/pdf/2408.08907v1",
      "published_date": "2024-08-13 11:11:27 UTC",
      "updated_date": "2024-08-13 11:11:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T15:01:42.757107"
    },
    {
      "arxiv_id": "2408.06806v1",
      "title": "Unmasking the Uniqueness: A Glimpse into Age-Invariant Face Recognition of Indigenous African Faces",
      "title_zh": "翻译失败",
      "authors": [
        "Fakunle Ajewole",
        "Joseph Damilola Akinyemi",
        "Khadijat Tope Ladoja",
        "Olufade Falade Williams Onifade"
      ],
      "abstract": "The task of recognizing the age-separated faces of an individual,\nAge-Invariant Face Recognition (AIFR), has received considerable research\nefforts in Europe, America, and Asia, compared to Africa. Thus, AIFR research\nefforts have often under-represented/misrepresented the African ethnicity with\nnon-indigenous Africans. This work developed an AIFR system for indigenous\nAfrican faces to reduce the misrepresentation of African ethnicity in facial\nimage analysis research. We adopted a pre-trained deep learning model (VGGFace)\nfor AIFR on a dataset of 5,000 indigenous African faces (FAGE\\_v2) collected\nfor this study. FAGE\\_v2 was curated via Internet image searches of 500\nindividuals evenly distributed across 10 African countries. VGGFace was trained\non FAGE\\_v2 to obtain the best accuracy of 81.80\\%. We also performed\nexperiments on an African-American subset of the CACD dataset and obtained the\nbest accuracy of 91.5\\%. The results show a significant difference in the\nrecognition accuracies of indigenous versus non-indigenous Africans.",
      "tldr_zh": "本研究针对年龄不变人脸识别 (AIFR) 在非洲的不足，开发了一个针对土著非洲人脸的识别系统，以减少非洲种族在面部图像分析研究中的误表。研究者采用预训练的深度学习模型 (VGGFace) 在新数据集 FAGE_v2 上进行训练，该数据集包含 5000 张图像，来自 10 个非洲国家的 500 个个体。实验结果显示，在 FAGE_v2 上实现了 81.80% 的最佳准确率，而在 CACD 数据集的非洲裔美国子集上达到 91.5%，突显了土著非洲人脸与非土著非洲人脸识别准确率之间的显著差异。该工作为提升 AIFR 在非洲种族的适用性提供了重要基础。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Keywords: Age-Invariant Face Recognition, CACD, FAGE_v2, VGGFace",
      "pdf_url": "http://arxiv.org/pdf/2408.06806v1",
      "published_date": "2024-08-13 10:54:10 UTC",
      "updated_date": "2024-08-13 10:54:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T15:01:56.745803"
    },
    {
      "arxiv_id": "2408.06804v1",
      "title": "Deep Learning for Speaker Identification: Architectural Insights from AB-1 Corpus Analysis and Performance Evaluation",
      "title_zh": "翻译失败",
      "authors": [
        "Matthias Bartolo"
      ],
      "abstract": "In the fields of security systems, forensic investigations, and personalized\nservices, the importance of speech as a fundamental human input outweighs\ntext-based interactions. This research delves deeply into the complex field of\nSpeaker Identification (SID), examining its essential components and\nemphasising Mel Spectrogram and Mel Frequency Cepstral Coefficients (MFCC) for\nfeature extraction. Moreover, this study evaluates six slightly distinct model\narchitectures using extensive analysis to evaluate their performance, with\nhyperparameter tuning applied to the best-performing model. This work performs\na linguistic analysis to verify accent and gender accuracy, in addition to bias\nevaluation within the AB-1 Corpus dataset.",
      "tldr_zh": "这篇论文探讨了深度学习在说话者识别(SID)中的应用，强调了 Mel Spectrogram 和 Mel Frequency Cepstral Coefficients (MFCC) 在特征提取中的关键作用。研究评估了六种不同模型架构的性能，并对最佳模型进行了超参数调整，以优化整体效果。此外，通过对 AB-1 Corpus 数据集的分析，论文验证了口音和性别准确性，并评估了潜在偏差，为安全系统、取证调查和个性化服务提供了架构见解。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "Resultant work from Assignment, Department of AI, University of\n  Malta. Code available at: https://github.com/mbar0075/Speech-Technology",
      "pdf_url": "http://arxiv.org/pdf/2408.06804v1",
      "published_date": "2024-08-13 10:46:50 UTC",
      "updated_date": "2024-08-13 10:46:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T15:02:07.785881"
    },
    {
      "arxiv_id": "2408.06803v1",
      "title": "Integrating Saliency Ranking and Reinforcement Learning for Enhanced Object Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Matthias Bartolo",
        "Dylan Seychell",
        "Josef Bajada"
      ],
      "abstract": "With the ever-growing variety of object detection approaches, this study\nexplores a series of experiments that combine reinforcement learning (RL)-based\nvisual attention methods with saliency ranking techniques to investigate\ntransparent and sustainable solutions. By integrating saliency ranking for\ninitial bounding box prediction and subsequently applying RL techniques to\nrefine these predictions through a finite set of actions over multiple time\nsteps, this study aims to enhance RL object detection accuracy. Presented as a\nseries of experiments, this research investigates the use of various image\nfeature extraction methods and explores diverse Deep Q-Network (DQN)\narchitectural variations for deep reinforcement learning-based localisation\nagent training. Additionally, we focus on optimising the detection pipeline at\nevery step by prioritising lightweight and faster models, while also\nincorporating the capability to classify detected objects, a feature absent in\nprevious RL approaches. We show that by evaluating the performance of these\ntrained agents using the Pascal VOC 2007 dataset, faster and more optimised\nmodels were developed. Notably, the best mean Average Precision (mAP) achieved\nin this study was 51.4, surpassing benchmarks set by RL-based single object\ndetectors in the literature.",
      "tldr_zh": "本研究整合了显著性排名(saliency ranking)和强化学习(reinforcement learning, RL)技术，以提升对象检测的准确性和效率。具体方法包括使用显著性排名进行初始边界框预测，然后通过RL算法（如Deep Q-Network, DQN）在多个时间步内精炼预测，同时优化图像特征提取和检测管道，并新增对象分类功能。实验采用Pascal VOC 2007数据集，开发的轻量级模型实现了51.4的平均精度(mean Average Precision, mAP)，超过了现有RL-based单对象检测器的基准。整体框架为透明且可持续的对象检测解决方案提供了新途径。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Resultant work from Dissertation, Department of AI, University of\n  Malta. Code available at: https://github.com/mbar0075/SaRLVision",
      "pdf_url": "http://arxiv.org/pdf/2408.06803v1",
      "published_date": "2024-08-13 10:46:42 UTC",
      "updated_date": "2024-08-13 10:46:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T15:02:30.318703"
    },
    {
      "arxiv_id": "2408.06797v1",
      "title": "Stunned by Sleeping Beauty: How Prince Probability updates his forecast upon their fateful encounter",
      "title_zh": "翻译失败",
      "authors": [
        "Laurens Walleghem"
      ],
      "abstract": "The Sleeping Beauty problem is a puzzle in probability theory that has gained\nmuch attention since Elga's discussion of it [Elga, Adam, Analysis 60 (2),\np.143-147 (2000)]. Sleeping Beauty is put asleep, and a coin is tossed. If the\noutcome of the coin toss is Tails, Sleeping Beauty is woken up on Monday, put\nasleep again and woken up again on Tuesday (with no recollection of having\nwoken up on Monday). If the outcome is Heads, Sleeping Beauty is woken up on\nMonday only. Each time Sleeping Beauty is woken up, she is asked what her\nbelief is that the outcome was Heads. What should Sleeping Beauty reply? In\nliterature arguments have been given for both 1/3 and 1/2 as the correct\nanswer. In this short note we argue using simple Bayesian probability theory\nwhy 1/3 is the right answer, and not 1/2. Briefly, when Sleeping Beauty\nawakens, her being awake is nontrivial extra information that leads her to\nupdate her beliefs about Heads to 1/3. We strengthen our claim by considering\nan additional observer, Prince Probability, who may or may not meet Sleeping\nBeauty. If he meets Sleeping Beauty while she is awake, he lowers his credence\nin Heads to 1/3. We also briefly consider the credence in Heads of a Sleeping\nBeauty who knows that she is dreaming (and thus asleep).",
      "tldr_zh": "这篇论文讨论了Sleeping Beauty问题，使用Bayesian probability theory论证Sleeping Beauty在被叫醒时应将硬币为Heads的概率更新为1/3，而不是1/2，因为醒来本身是额外信息导致信念调整。论文通过引入一个额外的观察者Prince Probability来加强论点：如果他遇到Sleeping Beauty，也会降低对Heads的置信度至1/3。最终，论文为这一经典概率难题提供了简单且合理的解释，并简要探讨了知道自己在做梦的Sleeping Beauty的信念更新。",
      "categories": [
        "math.PR",
        "cs.AI",
        "physics.soc-ph"
      ],
      "primary_category": "math.PR",
      "comment": "12 pages, 1 figure, all comments welcome!",
      "pdf_url": "http://arxiv.org/pdf/2408.06797v1",
      "published_date": "2024-08-13 10:27:16 UTC",
      "updated_date": "2024-08-13 10:27:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T15:02:43.050260"
    },
    {
      "arxiv_id": "2408.06776v1",
      "title": "Robust Deep Reinforcement Learning for Inverter-based Volt-Var Control in Partially Observable Distribution Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Qiong Liu",
        "Ye Guo",
        "Tong Xu"
      ],
      "abstract": "Inverter-based volt-var control is studied in this paper. One key issue in\nDRL-based approaches is the limited measurement deployment in active\ndistribution networks, which leads to problems of a partially observable state\nand unknown reward. To address those problems, this paper proposes a robust DRL\napproach with a conservative critic and a surrogate reward. The conservative\ncritic utilizes the quantile regression technology to estimate conservative\nstate-action value function based on the partially observable state, which\nhelps to train a robust policy; the surrogate rewards of power loss and voltage\nviolation are designed that can be calculated from the limited measurements.\nThe proposed approach optimizes the power loss of the whole network and the\nvoltage profile of buses with measurable voltages while indirectly improving\nthe voltage profile of other buses. Extensive simulations verify the\neffectiveness of the robust DRL approach in different limited measurement\nconditions, even when only the active power injection of the root bus and less\nthan 10% of bus voltages are measurable.",
      "tldr_zh": "本文提出了一种鲁棒深度强化学习（DRL）方法，用于处理部分可观测配电网络中基于逆变器的 Volt-Var Control 问题，特别是针对有限测量导致的部分可观测状态和未知奖励的挑战。方法包括使用分位数回归（quantile regression）的保守 critic 来估计保守状态-动作价值函数，从而训练出鲁棒策略，以及设计基于功率损失和电压违规的代理奖励（surrogate reward），这些奖励可从有限测量中计算。实验结果显示，该方法在不同测量条件下（如仅测量根总线有功功率注入和不到10%的总线电压）有效优化了网络功率损失和电压分布，并间接改善了其他总线的电压性能。",
      "categories": [
        "eess.SY",
        "cs.AI",
        "cs.SY"
      ],
      "primary_category": "eess.SY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.06776v1",
      "published_date": "2024-08-13 10:02:10 UTC",
      "updated_date": "2024-08-13 10:02:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T15:02:44.668643"
    },
    {
      "arxiv_id": "2408.06772v1",
      "title": "Exploring Domain Shift on Radar-Based 3D Object Detection Amidst Diverse Environmental Conditions",
      "title_zh": "翻译失败",
      "authors": [
        "Miao Zhang",
        "Sherif Abdulatif",
        "Benedikt Loesch",
        "Marco Altmann",
        "Marius Schwarz",
        "Bin Yang"
      ],
      "abstract": "The rapid evolution of deep learning and its integration with autonomous\ndriving systems have led to substantial advancements in 3D perception using\nmultimodal sensors. Notably, radar sensors show greater robustness compared to\ncameras and lidar under adverse weather and varying illumination conditions.\nThis study delves into the often-overlooked yet crucial issue of domain shift\nin 4D radar-based object detection, examining how varying environmental\nconditions, such as different weather patterns and road types, impact 3D object\ndetection performance. Our findings highlight distinct domain shifts across\nvarious weather scenarios, revealing unique dataset sensitivities that\nunderscore the critical role of radar point cloud generation. Additionally, we\ndemonstrate that transitioning between different road types, especially from\nhighways to urban settings, introduces notable domain shifts, emphasizing the\nnecessity for diverse data collection across varied road environments. To the\nbest of our knowledge, this is the first comprehensive analysis of domain shift\neffects on 4D radar-based object detection. We believe this empirical study\ncontributes to understanding the complex nature of domain shifts in radar data\nand suggests paths forward for data collection strategy in the face of\nenvironmental variability.",
      "tldr_zh": "本文探讨了在不同环境条件下（如天气和道路类型）对基于 4D radar 的 3D 物体检测性能的影响，强调 radar 传感器在恶劣天气中的鲁棒性优势。研究发现，各种天气场景会导致明显的 domain shift，并揭示了 radar point cloud 生成在缓解这些问题中的关键作用；此外，从高速公路到城市环境的转变也会引入显著的 domain shift。实验结果突出了不同数据集的敏感性，并为未来数据收集策略提供了指导。该研究首次对 4D radar-based 物体检测中的 domain shift 进行了全面分析，旨在提升自动驾驶系统的可靠性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "6 pages, 5 figures, 3 tables, accepted in IEEE International\n  Conference on Intelligent Transportation Systems (ITSC) 2024",
      "pdf_url": "http://arxiv.org/pdf/2408.06772v1",
      "published_date": "2024-08-13 09:55:38 UTC",
      "updated_date": "2024-08-13 09:55:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T15:02:57.402174"
    },
    {
      "arxiv_id": "2408.06761v1",
      "title": "Cross-View Geolocalization and Disaster Mapping with Street-View and VHR Satellite Imagery: A Case Study of Hurricane IAN",
      "title_zh": "翻译失败",
      "authors": [
        "Hao Li",
        "Fabian Deuser",
        "Wenping Yina",
        "Xuanshu Luo",
        "Paul Walther",
        "Gengchen Mai",
        "Wei Huang",
        "Martin Werner"
      ],
      "abstract": "Nature disasters play a key role in shaping human-urban infrastructure\ninteractions. Effective and efficient response to natural disasters is\nessential for building resilience and a sustainable urban environment. Two\ntypes of information are usually the most necessary and difficult to gather in\ndisaster response. The first information is about disaster damage perception,\nwhich shows how badly people think that urban infrastructure has been damaged.\nThe second information is geolocation awareness, which means how people\nwhereabouts are made available. In this paper, we proposed a novel disaster\nmapping framework, namely CVDisaster, aiming at simultaneously addressing\ngeolocalization and damage perception estimation using cross-view Street-View\nImagery (SVI) and Very High-Resolution satellite imagery. CVDisaster consists\nof two cross-view models, where CVDisaster-Geoloc refers to a cross-view\ngeolocalization model based on a contrastive learning objective with a Siamese\nConvNeXt image encoder, and CVDisaster-Est is a cross-view classification model\nbased on a Couple Global Context Vision Transformer (CGCViT). Taking Hurricane\nIAN as a case study, we evaluate the CVDisaster framework by creating a novel\ncross-view dataset (CVIAN) and conducting extensive experiments. As a result,\nwe show that CVDisaster can achieve highly competitive performance (over 80%\nfor geolocalization and 75% for damage perception estimation) with even limited\nfine-tuning efforts, which largely motivates future cross-view models and\napplications within a broader GeoAI research community. The data and code are\npublicly available at: https://github.com/tum-bgd/CVDisaster.",
      "tldr_zh": "本研究提出了一种名为 CVDisaster 的新型灾害映射框架，利用 Street-View Imagery (SVI) 和 Very High-Resolution satellite imagery，针对自然灾害响应中的地理定位（Cross-View Geolocalization）和损害感知估计问题。框架包括两个模型：CVDisaster-Geoloc 基于对比学习和 Siamese ConvNeXt 图像编码器进行跨视图地理定位，以及 CVDisaster-Est 基于 Couple Global Context Vision Transformer (CGCViT) 进行损害感知分类。以 Hurricane IAN 为案例研究，该框架在创建的 CVIAN 数据集上实验显示，地理定位准确率超过 80%，损害感知估计超过 75%，即使仅进行有限微调也能实现高性能。该工作公开数据和代码，旨在推动 GeoAI 社区的跨视图模型应用和发展。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.06761v1",
      "published_date": "2024-08-13 09:37:26 UTC",
      "updated_date": "2024-08-13 09:37:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T15:03:09.279831"
    },
    {
      "arxiv_id": "2408.06752v2",
      "title": "Evaluating Research Quality with Large Language Models: An Analysis of ChatGPT's Effectiveness with Different Settings and Inputs",
      "title_zh": "使用大型语言模型评估研究质量：ChatGPT在不同设置和输入下的有效性分析",
      "authors": [
        "Mike Thelwall"
      ],
      "abstract": "Evaluating the quality of academic journal articles is a time consuming but\ncritical task for national research evaluation exercises, appointments and\npromotion. It is therefore important to investigate whether Large Language\nModels (LLMs) can play a role in this process. This article assesses which\nChatGPT inputs (full text without tables, figures and references; title and\nabstract; title only) produce better quality score estimates, and the extent to\nwhich scores are affected by ChatGPT models and system prompts. The results\nshow that the optimal input is the article title and abstract, with average\nChatGPT scores based on these (30 iterations on a dataset of 51 papers)\ncorrelating at 0.67 with human scores, the highest ever reported. ChatGPT 4o is\nslightly better than 3.5-turbo (0.66), and 4o-mini (0.66). The results suggest\nthat article full texts might confuse LLM research quality evaluations, even\nthough complex system instructions for the task are more effective than simple\nones. Thus, whilst abstracts contain insufficient information for a thorough\nassessment of rigour, they may contain strong pointers about originality and\nsignificance. Finally, linear regression can be used to convert the model\nscores into the human scale scores, which is 31% more accurate than guessing.",
      "tldr_zh": "本研究评估了Large Language Models (LLMs)如ChatGPT在学术论文质量评估中的有效性，测试了不同输入类型（如全文、标题和摘要、仅标题）、模型版本（ChatGPT 4o、3.5-turbo、4o-mini）和系统提示的影响。\n结果显示，使用标题和摘要作为输入时，ChatGPT的评分与人类评分相关性最高（0.67），而全文输入可能导致模型混淆。\n复杂系统指令比简单指令更有效，且线性回归可将模型评分转换为人类评分，提高31%的准确率。\n这项发现表明，摘要可能提供足够的原创性和重要性线索，但不足以全面评估论文的严谨性。",
      "categories": [
        "cs.DL",
        "cs.AI"
      ],
      "primary_category": "cs.DL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.06752v2",
      "published_date": "2024-08-13 09:19:21 UTC",
      "updated_date": "2024-11-29 09:17:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T15:03:21.243855"
    },
    {
      "arxiv_id": "2408.06740v3",
      "title": "DiffLoRA: Generating Personalized Low-Rank Adaptation Weights with Diffusion",
      "title_zh": "DiffLoRA：基于扩散生成个性化的低秩适配权重",
      "authors": [
        "Yujia Wu",
        "Yiming Shi",
        "Jiwei Wei",
        "Chengwei Sun",
        "Yang Yang",
        "Heng Tao Shen"
      ],
      "abstract": "Personalized text-to-image generation has gained significant attention for\nits capability to generate high-fidelity portraits of specific identities\nconditioned on user-defined prompts. Existing methods typically involve\ntest-time fine-tuning or incorporating an additional pre-trained branch.\nHowever, these approaches struggle to simultaneously address efficiency,\nidentity fidelity, and the preservation of the model's original generative\ncapabilities. In this paper, we propose DiffLoRA, an efficient method that\nleverages the diffusion model as a hypernetwork to predict personalized\nLow-Rank Adaptation (LoRA) weights based on the reference images. By\nincorporating these LoRA weights into the off-the-shelf text-to-image model,\nDiffLoRA enables zero-shot personalization during inference, eliminating the\nneed for post-processing optimization. Moreover, we introduce a novel\nidentity-oriented LoRA weights construction pipeline to facilitate the training\nprocess of DiffLoRA. The dataset generated through this pipeline enables\nDiffLoRA to produce consistently high-quality LoRA weights. Notably, the\ndistinctive properties of the diffusion model enhance the generation of\nsuperior weights by employing probabilistic modeling to capture intricate\nstructural patterns and thoroughly explore the weight space. Comprehensive\nexperimental results demonstrate that DiffLoRA outperforms existing\npersonalization approaches across multiple benchmarks, achieving both time\nefficiency and maintaining identity fidelity throughout the personalization\nprocess.",
      "tldr_zh": "本研究提出DiffLoRA，一种高效的个性化文本到图像生成方法，使用diffusion模型作为hypernetwork来预测基于参考图像的个性化Low-Rank Adaptation (LoRA)权重，从而实现零样本个性化推断，而无需测试时微调或后处理优化。DiffLoRA引入了一个新型身份导向的LoRA权重构建管道，通过生成的特定数据集辅助训练，并利用diffusion模型的概率建模能力捕获复杂结构并探索权重空间，以确保高保真度和模型原生生成能力的保持。实验结果显示，DiffLoRA在多个基准上超越现有方法，在时间效率和身份保真度方面表现出显著优势。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "9 pages,8 figures",
      "pdf_url": "http://arxiv.org/pdf/2408.06740v3",
      "published_date": "2024-08-13 09:00:35 UTC",
      "updated_date": "2024-11-15 08:36:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T15:03:32.124045"
    },
    {
      "arxiv_id": "2408.06736v1",
      "title": "Speculations on Uncertainty and Humane Algorithms",
      "title_zh": "翻译失败",
      "authors": [
        "Nicholas Gray"
      ],
      "abstract": "The appreciation and utilisation of risk and uncertainty can play a key role\nin helping to solve some of the many ethical issues that are posed by AI.\nUnderstanding the uncertainties can allow algorithms to make better decisions\nby providing interrogatable avenues to check the correctness of outputs.\nAllowing algorithms to deal with variability and ambiguity with their inputs\nmeans they do not need to force people into uncomfortable classifications.\nProvenance enables algorithms to know what they know preventing possible harms.\nAdditionally, uncertainty about provenance highlights the trustworthiness of\nalgorithms. It is essential to compute with what we know rather than make\nassumptions that may be unjustified or untenable. This paper provides a\nperspective on the need for the importance of risk and uncertainty in the\ndevelopment of ethical AI, especially in high-risk scenarios. It argues that\nthe handling of uncertainty, especially epistemic uncertainty, is critical to\nensuring that algorithms do not cause harm and are trustworthy and ensure that\nthe decisions that they make are humane.",
      "tldr_zh": "这篇论文探讨了风险和不确定性在解决AI伦理问题中的关键作用，主张通过理解不确定性，算法可以做出更可靠的决策，并提供可检查的输出正确性途径。论文强调，算法处理输入的变异性和模糊性（variability and ambiguity）能避免强迫人们接受不适的分类，同时Provenance（来源性）帮助算法识别自身知识边界，防止潜在伤害。不确定性，尤其是epistemic uncertainty（认识论不确定性），被视为确保算法可信和人性化的核心要素，在高风险场景中尤为重要。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.06736v1",
      "published_date": "2024-08-13 08:54:34 UTC",
      "updated_date": "2024-08-13 08:54:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T15:03:43.137894"
    },
    {
      "arxiv_id": "2408.06731v1",
      "title": "Large language models can consistently generate high-quality content for election disinformation operations",
      "title_zh": "翻译失败",
      "authors": [
        "Angus R. Williams",
        "Liam Burke-Moore",
        "Ryan Sze-Yin Chan",
        "Florence E. Enock",
        "Federico Nanni",
        "Tvesha Sippy",
        "Yi-Ling Chung",
        "Evelina Gabasova",
        "Kobi Hackenburg",
        "Jonathan Bright"
      ],
      "abstract": "Advances in large language models have raised concerns about their potential\nuse in generating compelling election disinformation at scale. This study\npresents a two-part investigation into the capabilities of LLMs to automate\nstages of an election disinformation operation. First, we introduce DisElect, a\nnovel evaluation dataset designed to measure LLM compliance with instructions\nto generate content for an election disinformation operation in localised UK\ncontext, containing 2,200 malicious prompts and 50 benign prompts. Using\nDisElect, we test 13 LLMs and find that most models broadly comply with these\nrequests; we also find that the few models which refuse malicious prompts also\nrefuse benign election-related prompts, and are more likely to refuse to\ngenerate content from a right-wing perspective. Secondly, we conduct a series\nof experiments (N=2,340) to assess the \"humanness\" of LLMs: the extent to which\ndisinformation operation content generated by an LLM is able to pass as\nhuman-written. Our experiments suggest that almost all LLMs tested released\nsince 2022 produce election disinformation operation content indiscernible by\nhuman evaluators over 50% of the time. Notably, we observe that multiple models\nachieve above-human levels of humanness. Taken together, these findings suggest\nthat current LLMs can be used to generate high-quality content for election\ndisinformation operations, even in hyperlocalised scenarios, at far lower costs\nthan traditional methods, and offer researchers and policymakers an empirical\nbenchmark for the measurement and evaluation of these capabilities in current\nand future models.",
      "tldr_zh": "这篇论文研究了大语言模型（LLMs）在生成选举虚假信息方面的能力，引入了DisElect数据集（包含2,200个恶意提示和50个良性提示）来评估13个LLMs对英国本地化虚假信息请求的遵从性。结果显示，大多数LLMs会遵从恶意指令，但也可能拒绝良性或右翼视角的内容；此外，通过2,340次实验，研究发现自2022年以来发布的LLMs生成的虚假信息内容在超过50%的情况下能通过人类评估，甚至达到或超过人类水平。总体而言，该研究证明LLMs能以低成本产生高质量选举虚假信息，并为研究者和政策制定者提供了一个实证基准。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.06731v1",
      "published_date": "2024-08-13 08:45:34 UTC",
      "updated_date": "2024-08-13 08:45:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T15:03:56.759911"
    },
    {
      "arxiv_id": "2408.06725v1",
      "title": "Enhancing Visual Dialog State Tracking through Iterative Object-Entity Alignment in Multi-Round Conversations",
      "title_zh": "通过迭代对象-实体对齐增强多轮对话中的视觉对话状态跟踪",
      "authors": [
        "Wei Pang",
        "Ruixue Duan",
        "Jinfu Yang",
        "Ning Li"
      ],
      "abstract": "Visual Dialog (VD) is a task where an agent answers a series of image-related\nquestions based on a multi-round dialog history. However, previous VD methods\noften treat the entire dialog history as a simple text input, disregarding the\ninherent conversational information flows at the round level. In this paper, we\nintroduce Multi-round Dialogue State Tracking model (MDST), a framework that\naddresses this limitation by leveraging the dialogue state learned from dialog\nhistory to answer questions. MDST captures each round of dialog history,\nconstructing internal dialogue state representations defined as 2-tuples of\nvision-language representations. These representations effectively ground the\ncurrent question, enabling the generation of accurate answers. Experimental\nresults on the VisDial v1.0 dataset demonstrate that MDST achieves a new\nstate-of-the-art performance in generative setting. Furthermore, through a\nseries of human studies, we validate the effectiveness of MDST in generating\nlong, consistent, and human-like answers while consistently answering a series\nof questions correctly.",
      "tldr_zh": "本研究针对Visual Dialog (VD)任务中，现有方法忽略多轮对话信息流的局限，提出Multi-round Dialogue State Tracking model (MDST)框架。该框架通过捕捉每轮对话历史并构建视觉-语言表示的2-元组对话状态，来实现迭代对象-实体对齐，从而更准确地回答当前问题。在VisDial v1.0数据集上的实验显示，MDST在生成设置中达到了新的最先进性能；此外，人类研究证实了其在生成长、一致且人性化答案方面的有效性。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.CV"
      ],
      "primary_category": "cs.AI",
      "comment": "This article has been accepted in CAAI Transactions on Intelligence\n  Technology! Article ID: CIT2_12370, Article DOI: 10.1049/cit2.12370",
      "pdf_url": "http://arxiv.org/pdf/2408.06725v1",
      "published_date": "2024-08-13 08:36:15 UTC",
      "updated_date": "2024-08-13 08:36:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T15:04:07.838169"
    },
    {
      "arxiv_id": "2408.06724v1",
      "title": "Adaptive Data Quality Scoring Operations Framework using Drift-Aware Mechanism for Industrial Applications",
      "title_zh": "翻译失败",
      "authors": [
        "Firas Bayram",
        "Bestoun S. Ahmed",
        "Erik Hallin"
      ],
      "abstract": "Within data-driven artificial intelligence (AI) systems for industrial\napplications, ensuring the reliability of the incoming data streams is an\nintegral part of trustworthy decision-making. An approach to assess data\nvalidity is data quality scoring, which assigns a score to each data point or\nstream based on various quality dimensions. However, certain dimensions exhibit\ndynamic qualities, which require adaptation on the basis of the system's\ncurrent conditions. Existing methods often overlook this aspect, making them\ninefficient in dynamic production environments. In this paper, we introduce the\nAdaptive Data Quality Scoring Operations Framework, a novel framework developed\nto address the challenges posed by dynamic quality dimensions in industrial\ndata streams. The framework introduces an innovative approach by integrating a\ndynamic change detector mechanism that actively monitors and adapts to changes\nin data quality, ensuring the relevance of quality scores. We evaluate the\nproposed framework performance in a real-world industrial use case. The\nexperimental results reveal high predictive performance and efficient\nprocessing time, highlighting its effectiveness in practical quality-driven AI\napplications.",
      "tldr_zh": "本文提出Adaptive Data Quality Scoring Operations Framework，这是一个新框架，旨在解决工业数据流中动态质量维度带来的挑战，通过整合drift-aware机制动态监控并适应数据变化，确保数据质量分数的相关性和可靠性。现有方法往往忽略这些动态特性，导致在生产环境中效率低下，而该框架通过主动检测机制提升了数据驱动AI系统的决策可靠性。在真实工业用例中，实验结果显示框架具有高预测性能和高效处理时间，证明其在质量驱动AI应用中的有效性。",
      "categories": [
        "cs.DB",
        "cs.AI",
        "cs.SE"
      ],
      "primary_category": "cs.DB",
      "comment": "17 pages",
      "pdf_url": "http://arxiv.org/pdf/2408.06724v1",
      "published_date": "2024-08-13 08:32:06 UTC",
      "updated_date": "2024-08-13 08:32:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T15:04:19.702122"
    },
    {
      "arxiv_id": "2408.06717v1",
      "title": "Computation-friendly Graph Neural Network Design by Accumulating Knowledge on Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Jialiang Wang",
        "Shimin Di",
        "Hanmo Liu",
        "Zhili Wang",
        "Jiachuan Wang",
        "Lei Chen",
        "Xiaofang Zhou"
      ],
      "abstract": "Graph Neural Networks (GNNs), like other neural networks, have shown\nremarkable success but are hampered by the complexity of their architecture\ndesigns, which heavily depend on specific data and tasks. Traditionally,\ndesigning proper architectures involves trial and error, which requires\nintensive manual effort to optimize various components. To reduce human\nworkload, researchers try to develop automated algorithms to design GNNs.\nHowever, both experts and automated algorithms suffer from two major issues in\ndesigning GNNs: 1) the substantial computational resources expended in\nrepeatedly trying candidate GNN architectures until a feasible design is\nachieved, and 2) the intricate and prolonged processes required for humans or\nalgorithms to accumulate knowledge of the interrelationship between graphs,\nGNNs, and performance.\n  To further enhance the automation of GNN architecture design, we propose a\ncomputation-friendly way to empower Large Language Models (LLMs) with\nspecialized knowledge in designing GNNs, thereby drastically shortening the\ncomputational overhead and development cycle of designing GNN architectures.\nOur framework begins by establishing a knowledge retrieval pipeline that\ncomprehends the intercorrelations between graphs, GNNs, and performance. This\npipeline converts past model design experiences into structured knowledge for\nLLM reference, allowing it to quickly suggest initial model proposals.\nSubsequently, we introduce a knowledge-driven search strategy that emulates the\nexploration-exploitation process of human experts, enabling quick refinement of\ninitial proposals within a promising scope. Extensive experiments demonstrate\nthat our framework can efficiently deliver promising (e.g., Top-5.77%) initial\nmodel proposals for unseen datasets within seconds and without any prior\ntraining and achieve outstanding search performance in a few iterations.",
      "tldr_zh": "本研究针对 Graph Neural Networks (GNNs) 设计过程的计算资源消耗和知识积累复杂问题，提出了一种计算友好的框架，通过在 Large Language Models (LLMs) 上积累知识来自动化 GNN 架构设计。框架的核心包括一个知识检索管道，将过去的模型设计经验转化为结构化知识，以便 LLM 快速生成初始模型提案；以及一个知识驱动搜索策略，模仿人类专家的探索-利用过程，对提案进行高效优化。实验结果表明，该框架能在几秒内为新数据集提供优秀的初始模型提案（如 Top-5.77%），无需任何训练，并在几次迭代中实现出色的搜索性能，从而显著缩短开发周期。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.06717v1",
      "published_date": "2024-08-13 08:22:01 UTC",
      "updated_date": "2024-08-13 08:22:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T15:04:32.914960"
    },
    {
      "arxiv_id": "2408.06710v1",
      "title": "Variational Learning of Gaussian Process Latent Variable Models through Stochastic Gradient Annealed Importance Sampling",
      "title_zh": "翻译失败",
      "authors": [
        "Jian Xu",
        "Shian Du",
        "Junmei Yang",
        "Qianli Ma",
        "Delu Zeng"
      ],
      "abstract": "Gaussian Process Latent Variable Models (GPLVMs) have become increasingly\npopular for unsupervised tasks such as dimensionality reduction and missing\ndata recovery due to their flexibility and non-linear nature. An\nimportance-weighted version of the Bayesian GPLVMs has been proposed to obtain\na tighter variational bound. However, this version of the approach is primarily\nlimited to analyzing simple data structures, as the generation of an effective\nproposal distribution can become quite challenging in high-dimensional spaces\nor with complex data sets. In this work, we propose an Annealed Importance\nSampling (AIS) approach to address these issues. By transforming the posterior\ninto a sequence of intermediate distributions using annealing, we combine the\nstrengths of Sequential Monte Carlo samplers and VI to explore a wider range of\nposterior distributions and gradually approach the target distribution. We\nfurther propose an efficient algorithm by reparameterizing all variables in the\nevidence lower bound (ELBO). Experimental results on both toy and image\ndatasets demonstrate that our method outperforms state-of-the-art methods in\nterms of tighter variational bounds, higher log-likelihoods, and more robust\nconvergence.",
      "tldr_zh": "本文提出了一种基于 Annealed Importance Sampling (AIS) 的变分学习方法，用于改进 Gaussian Process Latent Variable Models (GPLVMs) 在高维或复杂数据集中的性能。该方法通过将后验分布转化为一系列中间分布，结合 Sequential Monte Carlo samplers 和 Variational Inference (VI)，以探索更广泛的后验空间并逐步逼近目标分布。同时，作者通过重新参数化 evidence lower bound (ELBO) 中的所有变量，设计了一个高效算法。实验结果表明，该方法在玩具数据和图像数据集上，实现了更紧的变分边界、更高的对数似然和更稳健的收敛，优于现有技术。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.06710v1",
      "published_date": "2024-08-13 08:09:05 UTC",
      "updated_date": "2024-08-13 08:09:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T15:04:45.962638"
    },
    {
      "arxiv_id": "2408.06699v1",
      "title": "Information Geometry and Beta Link for Optimizing Sparse Variational Student-t Processes",
      "title_zh": "信息几何和 Beta 链接用于优化稀疏变分 Student-t 过程",
      "authors": [
        "Jian Xu",
        "Delu Zeng",
        "John Paisley"
      ],
      "abstract": "Recently, a sparse version of Student-t Processes, termed sparse variational\nStudent-t Processes, has been proposed to enhance computational efficiency and\nflexibility for real-world datasets using stochastic gradient descent. However,\ntraditional gradient descent methods like Adam may not fully exploit the\nparameter space geometry, potentially leading to slower convergence and\nsuboptimal performance. To mitigate these issues, we adopt natural gradient\nmethods from information geometry for variational parameter optimization of\nStudent-t Processes. This approach leverages the curvature and structure of the\nparameter space, utilizing tools such as the Fisher information matrix which is\nlinked to the Beta function in our model. This method provides robust\nmathematical support for the natural gradient algorithm when using Student's\nt-distribution as the variational distribution. Additionally, we present a\nmini-batch algorithm for efficiently computing natural gradients. Experimental\nresults across four benchmark datasets demonstrate that our method consistently\naccelerates convergence speed.",
      "tldr_zh": "这篇论文提出使用信息几何中的自然梯度方法来优化稀疏变分Student-t Processes，以解决传统梯度下降（如Adam）在参数空间几何利用不足的问题，从而提升收敛速度和性能。方法通过Fisher information matrix与Beta function的关联，提供数学支持，并引入mini-batch算法来高效计算自然梯度。实验结果在四个基准数据集上表明，该方法显著加速了收敛速度，为处理真实世界数据集的计算效率提供了改进。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.06699v1",
      "published_date": "2024-08-13 07:53:39 UTC",
      "updated_date": "2024-08-13 07:53:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T15:04:55.898261"
    },
    {
      "arxiv_id": "2408.06697v1",
      "title": "SlotLifter: Slot-guided Feature Lifting for Learning Object-centric Radiance Fields",
      "title_zh": "翻译失败",
      "authors": [
        "Yu Liu",
        "Baoxiong Jia",
        "Yixin Chen",
        "Siyuan Huang"
      ],
      "abstract": "The ability to distill object-centric abstractions from intricate visual\nscenes underpins human-level generalization. Despite the significant progress\nin object-centric learning methods, learning object-centric representations in\nthe 3D physical world remains a crucial challenge. In this work, we propose\nSlotLifter, a novel object-centric radiance model addressing scene\nreconstruction and decomposition jointly via slot-guided feature lifting. Such\na design unites object-centric learning representations and image-based\nrendering methods, offering state-of-the-art performance in scene decomposition\nand novel-view synthesis on four challenging synthetic and four complex\nreal-world datasets, outperforming existing 3D object-centric learning methods\nby a large margin. Through extensive ablative studies, we showcase the efficacy\nof designs in SlotLifter, revealing key insights for potential future\ndirections.",
      "tldr_zh": "本研究提出了一种名为 SlotLifter 的新型物体中心辐射模型，通过 slot-guided feature lifting 技术来联合处理场景重建和分解，从而将物体中心学习表示与基于图像的渲染方法相结合。实验结果显示，SlotLifter 在四个合成和四个复杂真实世界数据集上，实现了最先进的性能，在场景分解和新型视图合成方面大幅优于现有3D物体中心学习方法。作者通过广泛的消融研究验证了该设计的有效性，并为未来研究方向提供了关键见解。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by ECCV 2024. Project website: https://slotlifter.github.io",
      "pdf_url": "http://arxiv.org/pdf/2408.06697v1",
      "published_date": "2024-08-13 07:51:37 UTC",
      "updated_date": "2024-08-13 07:51:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T15:05:09.199688"
    },
    {
      "arxiv_id": "2408.06693v1",
      "title": "DC3DO: Diffusion Classifier for 3D Objects",
      "title_zh": "翻译失败",
      "authors": [
        "Nursena Koprucu",
        "Meher Shashwat Nigam",
        "Shicheng Xu",
        "Biruk Abere",
        "Gabriele Dominici",
        "Andrew Rodriguez",
        "Sharvaree Vadgama",
        "Berfin Inal",
        "Alberto Tono"
      ],
      "abstract": "Inspired by Geoffrey Hinton emphasis on generative modeling, To recognize\nshapes, first learn to generate them, we explore the use of 3D diffusion models\nfor object classification. Leveraging the density estimates from these models,\nour approach, the Diffusion Classifier for 3D Objects (DC3DO), enables\nzero-shot classification of 3D shapes without additional training. On average,\nour method achieves a 12.5 percent improvement compared to its multiview\ncounterparts, demonstrating superior multimodal reasoning over discriminative\napproaches. DC3DO employs a class-conditional diffusion model trained on\nShapeNet, and we run inferences on point clouds of chairs and cars. This work\nhighlights the potential of generative models in 3D object classification.",
      "tldr_zh": "该论文受 Geoffrey Hinton 的观点启发，即“先学会生成形状，然后才能识别它们”，提出了一种基于 3D 扩散模型（diffusion models）的分类器 DC3DO，用于 3D 物体分类。DC3DO 利用扩散模型的密度估计实现零样本（zero-shot）分类，无需额外训练，仅在 ShapeNet 数据集上训练模型，并对点云（point clouds）如椅子和汽车进行推理。与多视图方法相比，该方法平均提高了 12.5% 的性能，展示了生成模型在多模态推理方面的优势。该研究突显了生成模型在 3D 物体分类中的潜力。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.06693v1",
      "published_date": "2024-08-13 07:35:56 UTC",
      "updated_date": "2024-08-13 07:35:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T15:05:19.583573"
    },
    {
      "arxiv_id": "2408.06687v2",
      "title": "Masked Image Modeling: A Survey",
      "title_zh": "掩码图像建模：综述",
      "authors": [
        "Vlad Hondru",
        "Florinel Alin Croitoru",
        "Shervin Minaee",
        "Radu Tudor Ionescu",
        "Nicu Sebe"
      ],
      "abstract": "In this work, we survey recent studies on masked image modeling (MIM), an\napproach that emerged as a powerful self-supervised learning technique in\ncomputer vision. The MIM task involves masking some information, e.g.~pixels,\npatches, or even latent representations, and training a model, usually an\nautoencoder, to predicting the missing information by using the context\navailable in the visible part of the input. We identify and formalize two\ncategories of approaches on how to implement MIM as a pretext task, one based\non reconstruction and one based on contrastive learning. Then, we construct a\ntaxonomy and review the most prominent papers in recent years. We complement\nthe manually constructed taxonomy with a dendrogram obtained by applying a\nhierarchical clustering algorithm. We further identify relevant clusters via\nmanually inspecting the resulting dendrogram. Our review also includes datasets\nthat are commonly used in MIM research. We aggregate the performance results of\nvarious masked image modeling methods on the most popular datasets, to\nfacilitate the comparison of competing methods. Finally, we identify research\ngaps and propose several interesting directions of future work. We supplement\nour survey with the following public repository containing organized\nreferences: https://github.com/vladhondru25/MIM-Survey.",
      "tldr_zh": "本调查论文回顾了Masked Image Modeling (MIM)，一种在计算机视觉中强大的自监督学习技术，通过掩盖输入部分（如像素或补丁）并训练模型（如自编码器）预测缺失信息。论文将MIM分为基于重建和基于对比学习的两大类别，并构建了分类法(taxonomy)，结合层次聚类算法生成树状图(dendrogram)以组织并分析主要研究。作者汇总了各种MIM方法在常用数据集上的性能结果，便于比较，并识别了研究空白，提出了未来工作方向，如扩展应用和改进方法。最终，提供了一个公共仓库（https://github.com/vladhondru25/MIM-Survey）以供参考。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Revised version",
      "pdf_url": "http://arxiv.org/pdf/2408.06687v2",
      "published_date": "2024-08-13 07:27:02 UTC",
      "updated_date": "2025-01-09 22:14:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T15:05:33.569848"
    },
    {
      "arxiv_id": "2408.08906v1",
      "title": "Bundle Recommendation with Item-level Causation-enhanced Multi-view Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Huy-Son Nguyen",
        "Tuan-Nghia Bui",
        "Long-Hai Nguyen",
        "Hoang Manh-Hung",
        "Cam-Van Thi Nguyen",
        "Hoang-Quynh Le",
        "Duc-Trong Le"
      ],
      "abstract": "Bundle recommendation aims to enhance business profitability and user\nconvenience by suggesting a set of interconnected items. In real-world\nscenarios, leveraging the impact of asymmetric item affiliations is crucial for\neffective bundle modeling and understanding user preferences. To address this,\nwe present BunCa, a novel bundle recommendation approach employing item-level\ncausation-enhanced multi-view learning. BunCa provides comprehensive\nrepresentations of users and bundles through two views: the Coherent View,\nleveraging the Multi-Prospect Causation Network for causation-sensitive\nrelations among items, and the Cohesive View, employing LightGCN for\ninformation propagation among users and bundles. Modeling user preferences and\nbundle construction combined from both views ensures rigorous cohesion in\ndirect user-bundle interactions through the Cohesive View and captures explicit\nintents through the Coherent View. Simultaneously, the integration of concrete\nand discrete contrastive learning optimizes the consistency and\nself-discrimination of multi-view representations. Extensive experiments with\nBunCa on three benchmark datasets demonstrate the effectiveness of this novel\nresearch and validate our hypothesis.",
      "tldr_zh": "本研究提出了一种名为 BunCa 的捆绑推荐方法，通过项目级因果增强的多视图学习来处理不对称物品关联，从而更好地理解用户偏好和构建捆绑包。BunCa 包括两个视图：Coherent View 使用 Multi-Prospect Causation Network 捕捉物品间的因果敏感关系，以及 Cohesive View 采用 LightGCN 进行用户和捆绑包的信息传播，同时整合具体的和离散的对比学习来优化多视图表示的一致性和自我区分。实验在三个基准数据集上验证了 BunCa 的有效性，证明了该方法能显著提升推荐性能。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.08906v1",
      "published_date": "2024-08-13 07:05:27 UTC",
      "updated_date": "2024-08-13 07:05:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T15:05:44.768302"
    },
    {
      "arxiv_id": "2408.06672v1",
      "title": "Leveraging Priors via Diffusion Bridge for Time Series Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Jinseong Park",
        "Seungyun Lee",
        "Woojin Jeong",
        "Yujin Choi",
        "Jaewook Lee"
      ],
      "abstract": "Time series generation is widely used in real-world applications such as\nsimulation, data augmentation, and hypothesis test techniques. Recently,\ndiffusion models have emerged as the de facto approach for time series\ngeneration, emphasizing diverse synthesis scenarios based on historical or\ncorrelated time series data streams. Since time series have unique\ncharacteristics, such as fixed time order and data scaling, standard Gaussian\nprior might be ill-suited for general time series generation. In this paper, we\nexploit the usage of diverse prior distributions for synthesis. Then, we\npropose TimeBridge, a framework that enables flexible synthesis by leveraging\ndiffusion bridges to learn the transport between chosen prior and data\ndistributions. Our model covers a wide range of scenarios in time series\ndiffusion models, which leverages (i) data- and time-dependent priors for\nunconditional synthesis, and (ii) data-scale preserving synthesis with a\nconstraint as a prior for conditional generation. Experimentally, our model\nachieves state-of-the-art performance in both unconditional and conditional\ntime series generation tasks.",
      "tldr_zh": "该论文探讨了时间序列生成的问题，指出标准高斯先验可能不适合时间序列的独特特性，如固定时间顺序和数据缩放，因此提出利用多样化先验分布进行合成。作者引入 TimeBridge 框架，通过 diffusion bridges 学习从选定的先验分布到数据分布的转换，支持无条件合成（使用数据和时间相关的先验）和条件生成（以约束作为先验保持数据缩放）。实验结果显示，TimeBridge 在无条件和条件时间序列生成任务中实现了最先进性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.06672v1",
      "published_date": "2024-08-13 06:47:59 UTC",
      "updated_date": "2024-08-13 06:47:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T15:05:57.145843"
    },
    {
      "arxiv_id": "2408.06665v1",
      "title": "RW-NSGCN: A Robust Approach to Structural Attacks via Negative Sampling",
      "title_zh": "翻译失败",
      "authors": [
        "Shuqi He",
        "Jun Zhuang",
        "Ding Wang",
        "Jun Song"
      ],
      "abstract": "Node classification using Graph Neural Networks (GNNs) has been widely\napplied in various practical scenarios, such as predicting user interests and\ndetecting communities in social networks. However, recent studies have shown\nthat graph-structured networks often contain potential noise and attacks, in\nthe form of topological perturbations and weight disturbances, which can lead\nto decreased classification performance in GNNs. To improve the robustness of\nthe model, we propose a novel method: Random Walk Negative Sampling Graph\nConvolutional Network (RW-NSGCN). Specifically, RW-NSGCN integrates the Random\nWalk with Restart (RWR) and PageRank (PGR) algorithms for negative sampling and\nemploys a Determinantal Point Process (DPP)-based GCN for convolution\noperations. RWR leverages both global and local information to manage noise and\nlocal variations, while PGR assesses node importance to stabilize the\ntopological structure. The DPP-based GCN ensures diversity among negative\nsamples and aggregates their features to produce robust node embeddings,\nthereby improving classification performance. Experimental results demonstrate\nthat the RW-NSGCN model effectively addresses network topology attacks and\nweight instability, increasing the accuracy of anomaly detection and overall\nstability. In terms of classification accuracy, RW-NSGCN significantly\noutperforms existing methods, showing greater resilience across various\nscenarios and effectively mitigating the impact of such vulnerabilities.",
      "tldr_zh": "本研究针对Graph Neural Networks (GNNs) 在节点分类任务中面临的拓扑扰动和权重干扰问题，提出了一种鲁棒方法RW-NSGCN，以提升模型的抗攻击能力。具体而言，RW-NSGCN 整合Random Walk with Restart (RWR) 和PageRank (PGR) 算法进行负采样，其中RWR 处理全局和局部信息以管理噪声，PGR 评估节点重要性稳定拓扑结构；同时，使用Determinantal Point Process (DPP)-based GCN 确保负样本多样性和特征聚合，生成更鲁棒的节点嵌入。实验结果显示，RW-NSGCN 在各种场景下显著提高分类准确率和异常检测稳定性，比现有方法表现出更强的抗网络攻击能力。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.06665v1",
      "published_date": "2024-08-13 06:34:56 UTC",
      "updated_date": "2024-08-13 06:34:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T15:06:10.406718"
    },
    {
      "arxiv_id": "2408.06663v5",
      "title": "Amuro and Char: Analyzing the Relationship between Pre-Training and Fine-Tuning of Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Kaiser Sun",
        "Mark Dredze"
      ],
      "abstract": "The development of large language models leads to the formation of a\npre-train-then-align paradigm, in which the model is typically pre-trained on a\nlarge text corpus and undergoes a tuning stage to align the model with human\npreference or downstream tasks. In this work, we investigate the relationship\nbetween pre-training and fine-tuning by fine-tuning multiple intermediate\npre-trained model checkpoints. Our results on 18 datasets suggest that i)\ncontinual pre-training improves the model in a latent way that unveils after\nfine-tuning; ii) with extra fine-tuning, the datasets that the model does not\ndemonstrate capability gain much more than those that the model performs well\nduring the pre-training stage; iii) although model benefits significantly\nthrough supervised fine-tuning, it may forget previously known domain knowledge\nand the tasks that are not seen during fine-tuning; iv) the model resembles\nhigh sensitivity to evaluation prompts after supervised fine-tuning, but this\nsensitivity can be alleviated by more pre-training.",
      "tldr_zh": "本文研究了大语言模型的预训练和微调关系，通过微调多个中间预训练模型检查点，并在18个数据集上进行实验。结果显示，持续预训练以隐形方式改善模型，只有在微调后显现；微调后，模型在预训练阶段表现较差的数据集上获得更大收益。监督微调虽然显著提升模型性能，但可能导致模型遗忘先前领域知识和未见任务，且对评估提示高度敏感；然而，增加预训练可以缓解这种敏感性。总的来说，该工作揭示了预训练与微调的动态互动，为优化大型语言模型提供了新见解。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Rep4NLP Camera Ready",
      "pdf_url": "http://arxiv.org/pdf/2408.06663v5",
      "published_date": "2024-08-13 06:28:43 UTC",
      "updated_date": "2025-03-18 16:21:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T15:06:22.164988"
    },
    {
      "arxiv_id": "2408.06653v3",
      "title": "Hierarchical Structured Neural Network: Efficient Retrieval Scaling for Large Scale Recommendation",
      "title_zh": "层次结构化神经网络：用于大规模推荐的高效检索扩展",
      "authors": [
        "Kaushik Rangadurai",
        "Siyang Yuan",
        "Minhui Huang",
        "Yiqun Liu",
        "Golnaz Ghasemiesfeh",
        "Yunchen Pu",
        "Haiyu Lu",
        "Xingfeng He",
        "Fangzhou Xu",
        "Andrew Cui",
        "Vidhoon Viswanathan",
        "Lin Yang",
        "Liang Wang",
        "Jiyan Yang",
        "Chonglin Sun"
      ],
      "abstract": "Retrieval, the initial stage of a recommendation system, is tasked with\ndown-selecting items from a pool of tens of millions of candidates to a few\nthousands. Embedding Based Retrieval (EBR) has been a typical choice for this\nproblem, addressing the computational demands of deep neural networks across\nvast item corpora. EBR utilizes Two Tower or Siamese Networks to learn\nrepresentations for users and items, and employ Approximate Nearest Neighbor\n(ANN) search to efficiently retrieve relevant items. Despite its popularity in\nindustry, EBR faces limitations. The Two Tower architecture, relying on a\nsingle dot product interaction, struggles to capture complex data distributions\ndue to limited capability in learning expressive interactions between users and\nitems. Additionally, ANN index building and representation learning for user\nand item are often separate, leading to inconsistencies exacerbated by\nrepresentation (e.g. continuous online training) and item drift (e.g. items\nexpired and new items added). In this paper, we introduce the Hierarchical\nStructured Neural Network (HSNN), an efficient deep neural network model to\nlearn intricate user and item interactions beyond the commonly used dot product\nin retrieval tasks, achieving sublinear computational costs relative to corpus\nsize. A Modular Neural Network (MoNN) is designed to maintain high\nexpressiveness for interaction learning while ensuring efficiency. A mixture of\nMoNNs operate on a hierarchical item index to achieve extensive computation\nsharing, enabling it to scale up to large corpus size. MoNN and the\nhierarchical index are jointly learnt to continuously adapt to distribution\nshifts in both user interests and item distributions. HSNN achieves substantial\nimprovement in offline evaluation compared to prevailing methods.",
      "tldr_zh": "本研究针对大规模推荐系统的检索阶段，指出传统 Embedding Based Retrieval (EBR) 方法（如 Two Tower 架构）在捕捉复杂用户-物品互动和处理表示漂移及物品漂移方面存在局限，导致计算效率低下和不一致性。作者提出 Hierarchical Structured Neural Network (HSNN)，一种高效深度神经网络模型，通过 Modular Neural Network (MoNN) 实现高表达性的互动学习，并在分层物品索引上进行计算共享，从而实现相对于语料库大小的亚线性计算成本。HSNN 通过联合学习 MoNN 和分层索引，适应用户兴趣和物品分布的变化，并在离线评估中比现有方法取得显著改进。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "Resubmit",
      "pdf_url": "http://arxiv.org/pdf/2408.06653v3",
      "published_date": "2024-08-13 05:53:46 UTC",
      "updated_date": "2025-01-08 20:40:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T15:06:34.420154"
    },
    {
      "arxiv_id": "2408.14478v1",
      "title": "Uncertainty Quantification in Alzheimer's Disease Progression Modeling",
      "title_zh": "阿尔茨海默病进展建模的不确定性量化",
      "authors": [
        "Wael Mobeirek",
        "Shirley Mao"
      ],
      "abstract": "With the increasing number of patients diagnosed with Alzheimer's Disease,\nprognosis models have the potential to aid in early disease detection. However,\ncurrent approaches raise dependability concerns as they do not account for\nuncertainty. In this work, we compare the performance of Monte Carlo Dropout,\nVariational Inference, Markov Chain Monte Carlo, and Ensemble Learning trained\non 512 patients to predict 4-year cognitive score trajectories with confidence\nbounds. We show that MC Dropout and MCMC are able to produce well-calibrated,\nand accurate predictions under noisy training data.",
      "tldr_zh": "该研究探讨了在阿尔茨海默病进展建模中量化不确定性的重要性，以提升预后模型的可靠性。研究者比较了 Monte Carlo Dropout、Variational Inference、Markov Chain Monte Carlo 和 Ensemble Learning 四种方法，使用 512 名患者的数据预测 4 年的认知分数轨迹并提供置信区间。结果显示，Monte Carlo Dropout 和 Markov Chain Monte Carlo 在噪声训练数据环境下，能够生成校准良好且准确的预测，从而为早期疾病检测提供更可信的工具。",
      "categories": [
        "q-bio.NC",
        "cs.AI",
        "cs.CY",
        "cs.IT",
        "math.IT"
      ],
      "primary_category": "q-bio.NC",
      "comment": "This work was done as part of degree requirements for the authors in\n  2021-2022",
      "pdf_url": "http://arxiv.org/pdf/2408.14478v1",
      "published_date": "2024-08-13 05:53:34 UTC",
      "updated_date": "2024-08-13 05:53:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T15:06:45.141914"
    },
    {
      "arxiv_id": "2408.06634v2",
      "title": "Harnessing Earnings Reports for Stock Predictions: A QLoRA-Enhanced LLM Approach",
      "title_zh": "利用收益报告进行股票预测：一种 QLoRA 增强的大型语言模型",
      "authors": [
        "Haowei Ni",
        "Shuchen Meng",
        "Xupeng Chen",
        "Ziqing Zhao",
        "Andi Chen",
        "Panfeng Li",
        "Shiyao Zhang",
        "Qifu Yin",
        "Yuanqing Wang",
        "Yuxi Chan"
      ],
      "abstract": "Accurate stock market predictions following earnings reports are crucial for\ninvestors. Traditional methods, particularly classical machine learning models,\nstruggle with these predictions because they cannot effectively process and\ninterpret extensive textual data contained in earnings reports and often\noverlook nuances that influence market movements. This paper introduces an\nadvanced approach by employing Large Language Models (LLMs) instruction\nfine-tuned with a novel combination of instruction-based techniques and\nquantized low-rank adaptation (QLoRA) compression. Our methodology integrates\n'base factors', such as financial metric growth and earnings transcripts, with\n'external factors', including recent market indices performances and analyst\ngrades, to create a rich, supervised dataset. This comprehensive dataset\nenables our models to achieve superior predictive performance in terms of\naccuracy, weighted F1, and Matthews correlation coefficient (MCC), especially\nevident in the comparison with benchmarks such as GPT-4. We specifically\nhighlight the efficacy of the llama-3-8b-Instruct-4bit model, which showcases\nsignificant improvements over baseline models. The paper also discusses the\npotential of expanding the output capabilities to include a 'Hold' option and\nextending the prediction horizon, aiming to accommodate various investment\nstyles and time frames. This study not only demonstrates the power of\nintegrating cutting-edge AI with fine-tuned financial data but also paves the\nway for future research in enhancing AI-driven financial analysis tools.",
      "tldr_zh": "本研究提出了一种利用收益报告进行股票预测的方法，通过指令微调和量化低秩适配（QLoRA）压缩来增强大型语言模型（LLMs）的性能，以克服传统机器学习模型在处理文本数据方面的局限性。该方法整合了“基本因素”（如财务指标增长和收益报告）与“外部因素”（如市场指数表现和分析师评分），构建了一个丰富的监督数据集，从而提升预测准确性。实验结果显示，llama-3-8b-Instruct-4bit 模型在准确率、加权 F1 分数和 Matthews 相关系数（MCC）上显著优于基准模型如 GPT-4。未来，该方法可扩展到包括“Hold”选项和更长预测时限，以适应多样化的投资策略，并推动 AI 在金融分析中的应用。",
      "categories": [
        "q-fin.CP",
        "cs.AI",
        "cs.CL",
        "cs.LG",
        "q-fin.ST"
      ],
      "primary_category": "q-fin.CP",
      "comment": "Accepted by 2024 6th International Conference on Data-driven\n  Optimization of Complex Systems",
      "pdf_url": "http://arxiv.org/pdf/2408.06634v2",
      "published_date": "2024-08-13 04:53:31 UTC",
      "updated_date": "2024-11-12 07:52:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T15:06:59.320235"
    },
    {
      "arxiv_id": "2408.06632v1",
      "title": "EditScribe: Non-Visual Image Editing with Natural Language Verification Loops",
      "title_zh": "EditScribe：基于自然语言验证循环的非视觉图像编辑",
      "authors": [
        "Ruei-Che Chang",
        "Yuxuan Liu",
        "Lotus Zhang",
        "Anhong Guo"
      ],
      "abstract": "Image editing is an iterative process that requires precise visual evaluation\nand manipulation for the output to match the editing intent. However, current\nimage editing tools do not provide accessible interaction nor sufficient\nfeedback for blind and low vision individuals to achieve this level of control.\nTo address this, we developed EditScribe, a prototype system that makes image\nediting accessible using natural language verification loops powered by large\nmultimodal models. Using EditScribe, the user first comprehends the image\ncontent through initial general and object descriptions, then specifies edit\nactions using open-ended natural language prompts. EditScribe performs the\nimage edit, and provides four types of verification feedback for the user to\nverify the performed edit, including a summary of visual changes, AI judgement,\nand updated general and object descriptions. The user can ask follow-up\nquestions to clarify and probe into the edits or verification feedback, before\nperforming another edit. In a study with ten blind or low-vision users, we\nfound that EditScribe supported participants to perform and verify image edit\nactions non-visually. We observed different prompting strategies from\nparticipants, and their perceptions on the various types of verification\nfeedback. Finally, we discuss the implications of leveraging natural language\nverification loops to make visual authoring non-visually accessible.",
      "tldr_zh": "该研究介绍了 EditScribe 系统，一种基于自然语言验证循环(Natural Language Verification Loops)的原型，用于让盲人和低视力个体进行非视觉图像编辑。用户通过初始图像描述理解内容，并用开放式自然语言提示指定编辑动作，系统随后执行编辑并提供四种验证反馈，包括视觉变化摘要、AI judgement 以及更新后的描述。研究中，十名参与者成功完成了非视觉编辑，展示了不同提示策略和对反馈的感知。最后，该系统突显了利用自然语言验证循环使视觉创作更具包容性的潜力。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.HC",
      "comment": "ASSETS 2024",
      "pdf_url": "http://arxiv.org/pdf/2408.06632v1",
      "published_date": "2024-08-13 04:40:56 UTC",
      "updated_date": "2024-08-13 04:40:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T15:07:09.739758"
    },
    {
      "arxiv_id": "2408.11849v1",
      "title": "Style-Talker: Finetuning Audio Language Model and Style-Based Text-to-Speech Model for Fast Spoken Dialogue Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Yinghao Aaron Li",
        "Xilin Jiang",
        "Jordan Darefsky",
        "Ge Zhu",
        "Nima Mesgarani"
      ],
      "abstract": "The rapid advancement of large language models (LLMs) has significantly\npropelled the development of text-based chatbots, demonstrating their\ncapability to engage in coherent and contextually relevant dialogues. However,\nextending these advancements to enable end-to-end speech-to-speech conversation\nbots remains a formidable challenge, primarily due to the extensive dataset and\ncomputational resources required. The conventional approach of cascading\nautomatic speech recognition (ASR), LLM, and text-to-speech (TTS) models in a\npipeline, while effective, suffers from unnatural prosody because it lacks\ndirect interactions between the input audio and its transcribed text and the\noutput audio. These systems are also limited by their inherent latency from the\nASR process for real-time applications. This paper introduces Style-Talker, an\ninnovative framework that fine-tunes an audio LLM alongside a style-based TTS\nmodel for fast spoken dialog generation. Style-Talker takes user input audio\nand uses transcribed chat history and speech styles to generate both the\nspeaking style and text for the response. Subsequently, the TTS model\nsynthesizes the speech, which is then played back to the user. While the\nresponse speech is being played, the input speech undergoes ASR processing to\nextract the transcription and speaking style, serving as the context for the\nensuing dialogue turn. This novel pipeline accelerates the traditional cascade\nASR-LLM-TTS systems while integrating rich paralinguistic information from\ninput speech. Our experimental results show that Style-Talker significantly\noutperforms the conventional cascade and speech-to-speech baselines in terms of\nboth dialogue naturalness and coherence while being more than 50% faster.",
      "tldr_zh": "该论文提出Style-Talker框架，通过微调Audio Language Model和Style-Based Text-to-Speech Model，实现快速的口语对话生成，以解决传统ASR-LLM-TTS级联系统的延迟和不自然韵律问题。框架接受用户输入音频，结合转录的聊天历史和语音风格，生成响应的文本和风格，然后使用TTS模型合成语音，同时处理输入以提取后续对话上下文。这种创新管道整合了副语言信息，比传统系统快50%以上，并在实验中显著提升对话的自然性和连贯性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.CL",
      "comment": "CoLM 2024",
      "pdf_url": "http://arxiv.org/pdf/2408.11849v1",
      "published_date": "2024-08-13 04:35:11 UTC",
      "updated_date": "2024-08-13 04:35:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T15:07:21.494792"
    },
    {
      "arxiv_id": "2408.06627v1",
      "title": "WorldScribe: Towards Context-Aware Live Visual Descriptions",
      "title_zh": "翻译失败",
      "authors": [
        "Ruei-Che Chang",
        "Yuxuan Liu",
        "Anhong Guo"
      ],
      "abstract": "Automated live visual descriptions can aid blind people in understanding\ntheir surroundings with autonomy and independence. However, providing\ndescriptions that are rich, contextual, and just-in-time has been a\nlong-standing challenge in accessibility. In this work, we develop WorldScribe,\na system that generates automated live real-world visual descriptions that are\ncustomizable and adaptive to users' contexts: (i) WorldScribe's descriptions\nare tailored to users' intents and prioritized based on semantic relevance.\n(ii) WorldScribe is adaptive to visual contexts, e.g., providing consecutively\nsuccinct descriptions for dynamic scenes, while presenting longer and detailed\nones for stable settings. (iii) WorldScribe is adaptive to sound contexts,\ne.g., increasing volume in noisy environments, or pausing when conversations\nstart. Powered by a suite of vision, language, and sound recognition models,\nWorldScribe introduces a description generation pipeline that balances the\ntradeoffs between their richness and latency to support real-time use. The\ndesign of WorldScribe is informed by prior work on providing visual\ndescriptions and a formative study with blind participants. Our user study and\nsubsequent pipeline evaluation show that WorldScribe can provide real-time and\nfairly accurate visual descriptions to facilitate environment understanding\nthat is adaptive and customized to users' contexts. Finally, we discuss the\nimplications and further steps toward making live visual descriptions more\ncontext-aware and humanized.",
      "tldr_zh": "该研究开发了WorldScribe系统，利用视觉、语言和声音识别模型，提供实时且context-aware的视觉描述，帮助盲人自主理解周围环境。WorldScribe的关键创新包括根据用户意图优先化描述、适应视觉上下文（如动态场景提供简短描述，稳定场景提供详细描述）、以及响应声音上下文（如在嘈杂环境中提高音量或暂停）。通过一个平衡丰富度和延迟的描述生成管道，该系统在用户研究中显示出实时准确性，并为更人性化的辅助技术提供了重要启示。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.HC",
      "comment": "UIST 2024",
      "pdf_url": "http://arxiv.org/pdf/2408.06627v1",
      "published_date": "2024-08-13 04:32:45 UTC",
      "updated_date": "2024-08-13 04:32:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T15:07:33.853285"
    },
    {
      "arxiv_id": "2408.06618v1",
      "title": "Generalized knowledge-enhanced framework for biomedical entity and relation extraction",
      "title_zh": "翻译失败",
      "authors": [
        "Minh Nguyen",
        "Phuong Le"
      ],
      "abstract": "In recent years, there has been an increasing number of frameworks developed\nfor biomedical entity and relation extraction. This research effort aims to\naddress the accelerating growth in biomedical publications and the intricate\nnature of biomedical texts, which are written for mainly domain experts. To\nhandle these challenges, we develop a novel framework that utilizes external\nknowledge to construct a task-independent and reusable background knowledge\ngraph for biomedical entity and relation extraction. The design of our model is\ninspired by how humans learn domain-specific topics. In particular, humans\noften first acquire the most basic and common knowledge regarding a field to\nbuild the foundational knowledge and then use that as a basis for extending to\nvarious specialized topics. Our framework employs such common-knowledge-sharing\nmechanism to build a general neural-network knowledge graph that is learning\ntransferable to different domain-specific biomedical texts effectively.\nExperimental evaluations demonstrate that our model, equipped with this\ngeneralized and cross-transferable knowledge base, achieves competitive\nperformance benchmarks, including BioRelEx for binding interaction detection\nand ADE for Adverse Drug Effect identification.",
      "tldr_zh": "该研究提出了一种通用的知识增强框架，用于生物医学实体和关系提取，以应对生物医学文本的复杂性和快速增长。该框架利用外部知识构建一个任务独立的、可重用的背景知识 graph，模仿人类学习方式，先建立基础知识再扩展到特定领域，从而实现知识的可转移性。实验结果显示，该模型在BioRelEx（绑定交互检测）和ADE（不良药物效应识别）等基准上取得了竞争性的性能表现，为处理领域特定文本提供了高效解决方案。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.06618v1",
      "published_date": "2024-08-13 04:06:45 UTC",
      "updated_date": "2024-08-13 04:06:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T15:07:44.450564"
    },
    {
      "arxiv_id": "2408.06603v1",
      "title": "Simple but Effective Compound Geometric Operations for Temporal Knowledge Graph Completion",
      "title_zh": "翻译失败",
      "authors": [
        "Rui Ying",
        "Mengting Hu",
        "Jianfeng Wu",
        "Yalan Xie",
        "Xiaoyi Liu",
        "Zhunheng Wang",
        "Ming Jiang",
        "Hang Gao",
        "Linlin Zhang",
        "Renhong Cheng"
      ],
      "abstract": "Temporal knowledge graph completion aims to infer the missing facts in\ntemporal knowledge graphs. Current approaches usually embed factual knowledge\ninto continuous vector space and apply geometric operations to learn potential\npatterns in temporal knowledge graphs. However, these methods only adopt a\nsingle operation, which may have limitations in capturing the complex temporal\ndynamics present in temporal knowledge graphs. Therefore, we propose a simple\nbut effective method, i.e. TCompoundE, which is specially designed with two\ngeometric operations, including time-specific and relation-specific operations.\nWe provide mathematical proofs to demonstrate the ability of TCompoundE to\nencode various relation patterns. Experimental results show that our proposed\nmodel significantly outperforms existing temporal knowledge graph embedding\nmodels. Our code is available at https://github.com/nk-ruiying/TCompoundE.",
      "tldr_zh": "本研究针对时间知识图谱补全（Temporal Knowledge Graph Completion）问题，提出了一种简单而有效的模型TCompoundE，该模型使用复合几何操作，包括时间特定（time-specific）和关系特定（relation-specific）操作，以更好地捕捉知识图谱中的复杂时间动态。TCompoundE通过数学证明展示了其编码各种关系模式的能力，相比现有仅采用单一操作的方法，具有更强的泛化性。实验结果表明，该模型在相关基准测试中显著优于现有时间知识图谱嵌入模型，代码已在GitHub上公开。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.06603v1",
      "published_date": "2024-08-13 03:36:30 UTC",
      "updated_date": "2024-08-13 03:36:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T15:07:56.750821"
    },
    {
      "arxiv_id": "2408.06602v3",
      "title": "Super-intelligence or Superstition? Exploring Psychological Factors Influencing Belief in AI Predictions about Personal Behavior",
      "title_zh": "翻译失败",
      "authors": [
        "Eunhae Lee",
        "Pat Pataranutaporn",
        "Judith Amores",
        "Pattie Maes"
      ],
      "abstract": "Could belief in AI predictions be just another form of superstition? This\nstudy investigates psychological factors that influence belief in AI\npredictions about personal behavior, comparing it to belief in astrology- and\npersonality-based predictions. Through an experiment with 238 participants, we\nexamined how cognitive style, paranormal beliefs, AI attitudes, personality\ntraits, and other factors affect perceived validity, reliability, usefulness,\nand personalization of predictions from different sources. Our findings reveal\nthat belief in AI predictions is positively correlated with belief in\npredictions based on astrology and personality psychology. Notably, paranormal\nbeliefs and positive attitudes about AI significantly increased perceived\nvalidity, reliability, usefulness, and personalization of AI predictions.\nConscientiousness was negatively correlated with belief in predictions across\nall sources, and interest in the prediction topic increased believability\nacross predictions. Surprisingly, we found no evidence that cognitive style has\nan impact on belief in fictitious AI-generated predictions. These results\nhighlight the \"rational superstition\" phenomenon in AI, where belief is driven\nmore by mental heuristics and intuition than critical evaluation. This research\nadvances our understanding of the psychology of human-AI interaction, offering\ninsights into designing and promoting AI systems that foster appropriate trust\nand skepticism, critical for responsible integration in an increasingly\nAI-driven world.",
      "tldr_zh": "这篇论文探讨了人们对AI预测个人行为的信念是否类似于迷信（如astrology-based predictions），通过一项涉及238名参与者的实验，考察了认知风格、paranormal beliefs、AI attitudes和人格特质等因素对预测的感知有效性、可靠性、 usefulness和personalization的影响。研究发现，信念在AI、astrology和personality psychology预测之间呈正相关，paranormal beliefs和积极AI态度显著提升了对AI预测的认可，而conscientiousness人格特质则与所有预测的信念负相关。总体结果揭示了AI中的“理性迷信”现象，强调信念更多受心理启发式和直觉驱动，并为设计促进适当信任和怀疑的AI系统提供了重要见解。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.06602v3",
      "published_date": "2024-08-13 03:35:26 UTC",
      "updated_date": "2024-12-19 00:50:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T15:08:10.228624"
    },
    {
      "arxiv_id": "2408.06598v1",
      "title": "A Perspective on Large Language Models, Intelligent Machines, and Knowledge Acquisition",
      "title_zh": "大型语言模型、智能机器和知识获取的视角",
      "authors": [
        "Vladimir Cherkassky",
        "Eng Hock Lee"
      ],
      "abstract": "Large Language Models (LLMs) are known for their remarkable ability to\ngenerate synthesized 'knowledge', such as text documents, music, images, etc.\nHowever, there is a huge gap between LLM's and human capabilities for\nunderstanding abstract concepts and reasoning. We discuss these issues in a\nlarger philosophical context of human knowledge acquisition and the Turing\ntest. In addition, we illustrate the limitations of LLMs by analyzing GPT-4\nresponses to questions ranging from science and math to common sense reasoning.\nThese examples show that GPT-4 can often imitate human reasoning, even though\nit lacks understanding. However, LLM responses are synthesized from a large LLM\nmodel trained on all available data. In contrast, human understanding is based\non a small number of abstract concepts. Based on this distinction, we discuss\nthe impact of LLMs on acquisition of human knowledge and education.",
      "tldr_zh": "这篇论文从哲学角度审视 Large Language Models (LLMs) 的能力，强调其在生成合成知识（如文本、音乐和图像）方面的强大表现，但指出 LLMs 在理解抽象概念和推理方面远逊于人类，并将其与人类知识获取和 Turing test 进行对比。作者通过分析 GPT-4 对科学、数学和常识推理问题的响应，展示了 LLMs 能模仿人类推理却缺乏真正理解的特点，因为其基于海量训练数据，而人类依赖少量抽象概念。最终，论文讨论了 LLMs 对人类知识获取和教育的影响，可能加剧依赖合成知识的风险。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.06598v1",
      "published_date": "2024-08-13 03:25:49 UTC",
      "updated_date": "2024-08-13 03:25:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T15:08:21.240918"
    },
    {
      "arxiv_id": "2408.06569v1",
      "title": "Social Debiasing for Fair Multi-modal LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Harry Cheng",
        "Yangyang Guo",
        "Qingpei Guo",
        "Ming Yang",
        "Tian Gan",
        "Liqiang Nie"
      ],
      "abstract": "Multi-modal Large Language Models (MLLMs) have advanced significantly,\noffering powerful vision-language understanding capabilities. However, these\nmodels often inherit severe social biases from their training datasets, leading\nto unfair predictions based on attributes like race and gender. This paper\naddresses the issue of social biases in MLLMs by i) Introducing a comprehensive\nCounterfactual dataset with Multiple Social Concepts (CMSC), which provides a\nmore diverse and extensive training set compared to existing datasets. ii)\nProposing an Anti-Stereotype Debiasing strategy (ASD). Our method works by\nrevisiting the MLLM training process, rescaling the autoregressive loss\nfunction, and improving data sampling methods to counteract biases. Through\nextensive experiments on various MLLMs, our CMSC dataset and ASD method\ndemonstrate a significant reduction in social biases while maintaining the\nmodels' original performance.",
      "tldr_zh": "这篇论文针对多模态大语言模型(MLLMs)中的社会偏见问题（如基于种族和性别的歧视性预测），提出了解决方案。作者引入了CMSC（Counterfactual dataset with Multiple Social Concepts）数据集，提供更全面和多样的训练数据；并提出了ASD（Anti-Stereotype Debiasing strategy），通过重新审视训练过程、调整autoregressive损失函数和优化数据采样方法来对抗偏见。在各种MLLMs上的实验表明，该方法显著降低了社会偏见，同时保持了模型的原始性能。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.06569v1",
      "published_date": "2024-08-13 02:08:32 UTC",
      "updated_date": "2024-08-13 02:08:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T15:08:34.941000"
    },
    {
      "arxiv_id": "2408.06567v1",
      "title": "AquilaMoE: Efficient Training for MoE Models with Scale-Up and Scale-Out Strategies",
      "title_zh": "翻译失败",
      "authors": [
        "Bo-Wen Zhang",
        "Liangdong Wang",
        "Ye Yuan",
        "Jijie Li",
        "Shuhao Gu",
        "Mengdi Zhao",
        "Xinya Wu",
        "Guang Liu",
        "Chengwei Wu",
        "Hanyu Zhao",
        "Li Du",
        "Yiming Ju",
        "Quanyue Ma",
        "Yulong Ao",
        "Yingli Zhao",
        "Songhe Zhu",
        "Zhou Cao",
        "Dong Liang",
        "Yonghua Lin",
        "Ming Zhang",
        "Shunfei Wang",
        "Yanxin Zhou",
        "Min Ye",
        "Xuekai Chen",
        "Xinyang Yu",
        "Xiangjun Huang",
        "Jian Yang"
      ],
      "abstract": "In recent years, with the rapid application of large language models across\nvarious fields, the scale of these models has gradually increased, and the\nresources required for their pre-training have grown exponentially. Training an\nLLM from scratch will cost a lot of computation resources while scaling up from\na smaller model is a more efficient approach and has thus attracted significant\nattention. In this paper, we present AquilaMoE, a cutting-edge bilingual 8*16B\nMixture of Experts (MoE) language model that has 8 experts with 16 billion\nparameters each and is developed using an innovative training methodology\ncalled EfficientScale. This approach optimizes performance while minimizing\ndata requirements through a two-stage process. The first stage, termed\nScale-Up, initializes the larger model with weights from a pre-trained smaller\nmodel, enabling substantial knowledge transfer and continuous pretraining with\nsignificantly less data. The second stage, Scale-Out, uses a pre-trained dense\nmodel to initialize the MoE experts, further enhancing knowledge transfer and\nperformance. Extensive validation experiments on 1.8B and 7B models compared\nvarious initialization schemes, achieving models that maintain and reduce loss\nduring continuous pretraining. Utilizing the optimal scheme, we successfully\ntrained a 16B model and subsequently the 8*16B AquilaMoE model, demonstrating\nsignificant improvements in performance and training efficiency.",
      "tldr_zh": "本论文介绍了 AquilaMoE，一种双语 8*16B Mixture of Experts (MoE) 语言模型，通过创新的 EfficientScale 训练方法实现高效训练。该方法包括 Scale-Up 阶段，从预训练的较小模型初始化较大模型，实现知识转移并减少数据需求；以及 Scale-Out 阶段，使用预训练的稠密模型初始化 MoE 专家，进一步提升性能和效率。实验在 1.8B 和 7B 模型上验证了多种初始化方案，发现最佳方案能保持或降低损失，最终成功训练了 16B 和 8*16B 模型，显著提高了整体性能和训练效率。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.06567v1",
      "published_date": "2024-08-13 02:07:00 UTC",
      "updated_date": "2024-08-13 02:07:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T15:08:48.036907"
    },
    {
      "arxiv_id": "2408.11848v2",
      "title": "MGH Radiology Llama: A Llama 3 70B Model for Radiology",
      "title_zh": "翻译失败",
      "authors": [
        "Yucheng Shi",
        "Peng Shu",
        "Zhengliang Liu",
        "Zihao Wu",
        "Quanzheng Li",
        "Tianming Liu",
        "Ninghao Liu",
        "Xiang Li"
      ],
      "abstract": "In recent years, the field of radiology has increasingly harnessed the power\nof artificial intelligence (AI) to enhance diagnostic accuracy, streamline\nworkflows, and improve patient care. Large language models (LLMs) have emerged\nas particularly promising tools, offering significant potential in assisting\nradiologists with report generation, clinical decision support, and patient\ncommunication. This paper presents an advanced radiology-focused large language\nmodel: MGH Radiology Llama. It is developed using the Llama 3 70B model,\nbuilding upon previous domain-specific models like Radiology-GPT and\nRadiology-Llama2. Leveraging a unique and comprehensive dataset from\nMassachusetts General Hospital, comprising over 6.5 million de-identified\nmedical reports across various imaging modalities, the model demonstrates\nsignificant improvements in generating accurate and clinically relevant\nradiology impressions given the corresponding findings. Our evaluation,\nincorporating both traditional metrics and a GPT-4-based assessment, highlights\nthe enhanced performance of this work over general-purpose LLMs.",
      "tldr_zh": "这篇论文介绍了 MGH Radiology Llama，一种基于 Llama 3 70B 模型的放射学专用大型语言模型 (LLM)，旨在提升诊断准确性、工作流程效率和患者护理。模型利用马萨诸塞总医院的超过 650 万份匿名医疗报告数据集进行训练，构建于 Radiology-GPT 和 Radiology-Llama2 等前人工作之上，专注于生成准确的放射学印象。评估结果显示，该模型在报告生成、临床决策支持和患者沟通方面显著优于通用 LLM，通过传统指标和 GPT-4 评估证实其性能提升。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "11 pages, 3 figures, 1 table",
      "pdf_url": "http://arxiv.org/pdf/2408.11848v2",
      "published_date": "2024-08-13 01:30:03 UTC",
      "updated_date": "2024-12-16 18:25:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T15:08:59.029887"
    },
    {
      "arxiv_id": "2408.06543v3",
      "title": "HDRGS: High Dynamic Range Gaussian Splatting",
      "title_zh": "翻译失败",
      "authors": [
        "Jiahao Wu",
        "Lu Xiao",
        "Rui Peng",
        "Kaiqiang Xiong",
        "Ronggang Wang"
      ],
      "abstract": "Recent years have witnessed substantial advancements in the field of 3D\nreconstruction from 2D images, particularly following the introduction of the\nneural radiance field (NeRF) technique. However, reconstructing a 3D high\ndynamic range (HDR) radiance field, which aligns more closely with real-world\nconditions, from 2D multi-exposure low dynamic range (LDR) images continues to\npose significant challenges. Approaches to this issue fall into two categories:\ngrid-based and implicit-based. Implicit methods, using multi-layer perceptrons\n(MLP), face inefficiencies, limited solvability, and overfitting risks.\nConversely, grid-based methods require significant memory and struggle with\nimage quality and long training times. In this paper, we introduce Gaussian\nSplatting-a recent, high-quality, real-time 3D reconstruction technique-into\nthis domain. We further develop the High Dynamic Range Gaussian Splatting\n(HDR-GS) method, designed to address the aforementioned challenges. This method\nenhances color dimensionality by including luminance and uses an asymmetric\ngrid for tone-mapping, swiftly and precisely converting pixel irradiance to\ncolor. Our approach improves HDR scene recovery accuracy and integrates a novel\ncoarse-to-fine strategy to speed up model convergence, enhancing robustness\nagainst sparse viewpoints and exposure extremes, and preventing local optima.\nExtensive testing confirms that our method surpasses current state-of-the-art\ntechniques in both synthetic and real-world scenarios.",
      "tldr_zh": "本论文针对从2D多曝光LDR图像重建3D HDR辐射场的问题，引入Gaussian Splatting技术并提出HDR-GS方法，以克服隐式方法（如基于MLP的）的效率低下和网格方法的内存消耗大等问题。该方法通过增强颜色维度（包括亮度）和采用不对称网格进行色调映射，实现快速精确的像素辐照度转换，并结合粗到细策略加速模型收敛，提高对稀疏视点和极端曝光的鲁棒性。实验结果表明，HDR-GS在合成和真实场景中超越了现有最先进技术，在准确性和性能上表现出色。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.06543v3",
      "published_date": "2024-08-13 00:32:36 UTC",
      "updated_date": "2024-11-03 11:15:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T15:09:10.515871"
    },
    {
      "arxiv_id": "2408.06542v1",
      "title": "Value of Information and Reward Specification in Active Inference and POMDPs",
      "title_zh": "翻译失败",
      "authors": [
        "Ran Wei"
      ],
      "abstract": "Expected free energy (EFE) is a central quantity in active inference which\nhas recently gained popularity due to its intuitive decomposition of the\nexpected value of control into a pragmatic and an epistemic component. While\nnumerous conjectures have been made to justify EFE as a decision making\nobjective function, the most widely accepted is still its intuitiveness and\nresemblance to variational free energy in approximate Bayesian inference. In\nthis work, we take a bottom up approach and ask: taking EFE as given, what's\nthe resulting agent's optimality gap compared with a reward-driven\nreinforcement learning (RL) agent, which is well understood? By casting EFE\nunder a particular class of belief MDP and using analysis tools from RL theory,\nwe show that EFE approximates the Bayes optimal RL policy via information\nvalue. We discuss the implications for objective specification of active\ninference agents.",
      "tldr_zh": "本研究探讨了 Expected Free Energy (EFE) 在 Active Inference 中的作用，并将其与强化学习 (RL) 代理进行比较，旨在评估 EFE 作为决策目标函数的优缺点。作者将 EFE 建模为特定类别的 Belief MDP，并运用 RL 理论工具分析，证明 EFE 通过信息价值 (Value of Information) 逼近 Bayes optimal RL 策略，从而量化了代理的优化差距。最终，该工作讨论了这些发现对 Active Inference 代理目标指定的实际含义，提供了一种更坚实的理论基础。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.06542v1",
      "published_date": "2024-08-13 00:32:05 UTC",
      "updated_date": "2024-08-13 00:32:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T15:09:21.389803"
    },
    {
      "arxiv_id": "2408.06540v1",
      "title": "Dynamic Exclusion of Low-Fidelity Data in Bayesian Optimization for Autonomous Beamline Alignment",
      "title_zh": "翻译失败",
      "authors": [
        "Megha R. Narayanan",
        "Thomas W. Morris"
      ],
      "abstract": "Aligning beamlines at synchrotron light sources is a high-dimensional,\nexpensive-to-sample optimization problem, as beams are focused using a series\nof dynamic optical components. Bayesian Optimization is an efficient machine\nlearning approach to finding global optima of beam quality, but the model can\neasily be impaired by faulty data points caused by the beam going off the edge\nof the sensor or by background noise. This study, conducted at the National\nSynchrotron Light Source II (NSLS-II) facility at Brookhaven National\nLaboratory (BNL), is an investigation of methods to identify untrustworthy\nreadings of beam quality and discourage the optimization model from seeking out\npoints likely to yield low-fidelity beams. The approaches explored include\ndynamic pruning using loss analysis of size and position models and a\nlengthscale-based genetic algorithm to determine which points to include in the\nmodel for optimal fit. Each method successfully classified high and low\nfidelity points. This research advances BNL's mission to tackle our nation's\nenergy challenges by providing scientists at all beamlines with access to\nhigher quality beams, and faster convergence to these optima for their\nexperiments.",
      "tldr_zh": "本研究针对同步加速器光源束线对准这一高维、采样成本高的优化问题，提出在Bayesian Optimization中使用动态排除低保真度数据的方法，以避免模型受光束超出传感器或背景噪声等故障数据的影响。方法包括基于size和position模型的loss analysis进行动态pruning，以及lengthscale-based genetic algorithm来筛选纳入模型的点，从而优化拟合。实验在Brookhaven National Laboratory的NSLS-II设施进行，结果显示这些方法成功分类高低保真度点，提升了光束质量和优化收敛速度，支持国家能源挑战的研究。",
      "categories": [
        "physics.acc-ph",
        "cs.AI",
        "cs.LG",
        "I.2.8; I.2.9; J.2"
      ],
      "primary_category": "physics.acc-ph",
      "comment": "12 pages, 6 figure sets",
      "pdf_url": "http://arxiv.org/pdf/2408.06540v1",
      "published_date": "2024-08-13 00:20:39 UTC",
      "updated_date": "2024-08-13 00:20:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T15:09:33.427226"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 89,
  "processed_papers_count": 89,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-19T15:09:57.172663"
}