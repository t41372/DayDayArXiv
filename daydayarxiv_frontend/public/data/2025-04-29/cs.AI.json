{
  "date": "2025-04-29",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2025-04-29 的 arXiv 中文 TLDR 快报！今天 arXiv 的论文主要聚焦 AI 安全、LLM 优化、医疗应用和强化学习等领域，强调了 LLM 在推理和知识蒸馏中的潜力（如 ReasonIR 和 Token-Efficient RL），同时探讨了后门攻击和多模态生成的风险，由知名学者如 Sebastian Dumbrava 和 Neil F. Johnson 等参与的文章令人印象深刻。\n\n### LLM 优化与安全\n今天有众多论文探讨 LLM 的性能提升和安全风险，以高效提示工程和知识转移为主。以下挑选了关键文章：\n\n- **Token-Efficient RL for LLM Reasoning (Token-Efficient RL for LLM Reasoning)**: 这篇论文提出了一种基于强化学习的 token 高效方法，显著提升 LLM 在数学推理任务中的准确性，仅需一个训练示例即可在 GSM8k 和 MATH 数据集上提高 20% 以上性能，贡献在于减少计算开销的同时提升推理效率。\n  \n- **ReasonIR: Training Retrievers for Reasoning Tasks (ReasonIR: Training Retrievers for Reasoning Tasks)**: Meta 团队的作品，通过合成数据训练检索器，提升 LLM 的推理能力，在 BRIGHT 等基准上实现 29.9 nDCG@10 的新 SOTA，关键发现是检索器能有效辅助跨任务泛化。\n\n- **UniversalRAG: Retrieval-Augmented Generation over Corpora of Diverse Modalities and Granularities (UniversalRAG: Retrieval-Augmented Generation over Corpora of Diverse Modalities and Granularities)**: 该研究引入模态感知路由机制，支持多模态（如文本、图像）检索，在多基准测试中超越基线，贡献在于提升 RAG 在异构数据上的鲁棒性。\n\n- **Chain-of-Defensive-Thought: Structured Reasoning Elicits Robustness in Large Language Models against Reference Corruption (Chain-of-Defensive-Thought: Structured Reasoning Elicits Robustness in Large Language Models against Reference Corruption)**: 论文探索了防御性推理提示，显著提升 LLM 对参考数据破坏的鲁棒性，在 SVAMP 等任务上提高 6.4% 准确率，主要发现是结构化提示能缓解幻觉问题。\n\n- **Hallucination by Code Generation LLMs: Taxonomy, Benchmarks, Mitigation, and Challenges (Hallucination by Code Generation LLMs: Taxonomy, Benchmarks, Mitigation, and Challenges)**: 这篇综述分类了代码生成 LLM 的幻觉问题，提供新基准和缓解策略，强调了检测和移除幻觉的挑战，为代码安全提供指导。\n\n- **Jekyll-and-Hyde Tipping Point in an AI's Behavior (Jekyll-and-Hyde Tipping Point in an AI's Behavior)**: Neil F. Johnson 的作品，从算法信息论角度分析 LLM 输出突变点，提出精确公式预测 AI 行为切换，贡献在于为 AI 信任提供理论基础。\n\n其他 LLM 相关论文，如 **Trace-of-Thought Prompting (Trace-of-Thought Prompting)** 和 **Grokking in the Wild (Grokking in the Wild)**，则通过提示优化和数据增强提升推理泛化，但细节较常规，快速掠过。\n\n### 图神经网络和强化学习\n这些论文强调了图结构和动态学习的优化，相关工作有：\n\n- **FedHERO: A Federated Learning Approach for Node Classification Task on Heterophilic Graphs (FedHERO: A Federated Learning Approach for Node Classification Task on Heterophilic Graphs)**: 提出联邦学习框架处理异质图分类，在基准数据集上超越现有方法，主要发现是双通道 GNN 能有效共享结构洞见。\n\n- **Graph-Based Fault Diagnosis for Rotating Machinery (Graph-Based Fault Diagnosis for Rotating Machinery)**: 使用图神经网络结合 Laban 运动分析诊断机械故障，准确率达 99.18%，贡献在于融入时序上下文提升诊断精度。\n\n强化学习论文如 **Reinforcement Learning for Reasoning in Large Language Models with One Training Example (Reinforcement Learning for Reasoning in Large Language Models with One Training Example)**，展示了 RL 在 LLM 推理中的数据效率，但与其他 RL 工作（如 **Toward Efficient Exploration by Large Language Model Agents**) 相比，创新性一般，仅提及其在数学任务上的 30% 改进。\n\n### 医疗 AI 和其他应用\n医疗领域论文众多，以 AI 诊断和生成模型为主：\n\n- **Theoretical Foundations for Semantic Cognition in Artificial Intelligence (Theoretical Foundations for Semantic Cognition in Artificial Intelligence)**: Sebastian Dumbrava 的专著，构建认知架构模拟信念状态，贡献在于提供可实现的框架，提升 AI 在医疗中的语义推理。\n\n- **ChestX-Reasoner: Advancing Radiology Foundation Models with Reasoning through Step-by-Step Verification (ChestX-Reasoner: Advancing Radiology Foundation Models with Reasoning through Step-by-Step Verification)**: 提出多模态模型提升放射诊断准确性，在基准上提高 16% 推理能力和 3.3% 结果准确率，主要发现是逐步验证机制增强临床解释性。\n\n- **Light Weight CNN for classification of Brain Tumors from MRI Images (Light Weight CNN for classification of Brain Tumors from MRI Images)**: 设计轻量 CNN 模型，MRI 图像分类准确率达 98.78%，适合资源有限的临床应用。\n\n其他医疗论文如 **Pretraining Large Brain Language Model for Active BCI (Pretraining Large Brain Language Model for Active BCI)** 和 **A Domain-Agnostic Scalable AI Safety Ensuring Framework (A Domain-Agnostic Scalable AI Safety Ensuring Framework)**，聚焦脑机接口和安全框架，但较技术性强，快速总结为提升诊断效率和 AI 安全。\n\n剩余论文涉及领域广泛，如 **MemeBLIP2 (MemeBLIP2)** 在有害模因检测上创新，但整体影响力有限；**SecRepoBench (SecRepoBench)** 等安全基准论文则提供新工具但未有突破性发现，仅提及其在代码生成中的应用。\n\n总之，今天的 arXiv 论文突显了 AI 在推理和医疗中的进展，但也暴露了安全隐患，建议关注 LLM 优化相关工作以推动实际应用。",
  "papers": [
    {
      "arxiv_id": "2504.21231v1",
      "title": "T2ID-CAS: Diffusion Model and Class Aware Sampling to Mitigate Class Imbalance in Neck Ultrasound Anatomical Landmark Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Manikanta Varaganti",
        "Amulya Vankayalapati",
        "Nour Awad",
        "Gregory R. Dion",
        "Laura J. Brattain"
      ],
      "abstract": "Neck ultrasound (US) plays a vital role in airway management by providing\nnon-invasive, real-time imaging that enables rapid and precise interventions.\nDeep learning-based anatomical landmark detection in neck US can further\nfacilitate procedural efficiency. However, class imbalance within datasets,\nwhere key structures like tracheal rings and vocal folds are underrepresented,\npresents significant challenges for object detection models. To address this,\nwe propose T2ID-CAS, a hybrid approach that combines a text-to-image latent\ndiffusion model with class-aware sampling to generate high-quality synthetic\nsamples for underrepresented classes. This approach, rarely explored in the\nultrasound domain, improves the representation of minority classes.\nExperimental results using YOLOv9 for anatomical landmark detection in neck US\ndemonstrated that T2ID-CAS achieved a mean Average Precision of 88.2,\nsignificantly surpassing the baseline of 66. This highlights its potential as a\ncomputationally efficient and scalable solution for mitigating class imbalance\nin AI-assisted ultrasound-guided interventions.",
      "tldr_zh": "本文提出 T2ID-CAS 方法，结合文本到图像潜在扩散模型（text-to-image latent diffusion model）和类别感知采样（class-aware sampling），以生成高质量合成样本，缓解颈部超声（Neck Ultrasound）解剖标志检测中的类别不平衡问题。针对 underrepresented 类如气管环和声带，该方法在超声领域鲜有探索，能显著提升模型对少数类别的表示。实验使用 YOLOv9 进行检测，结果显示 T2ID-CAS 达到了 88.2 的 mean Average Precision，比基线模型的 66 提高了 22%，证明其作为高效、可扩展的 AI 辅助超声引导干预解决方案的潜力。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "submitted to IEEE EMBC 2025",
      "pdf_url": "http://arxiv.org/pdf/2504.21231v1",
      "published_date": "2025-04-29 23:46:21 UTC",
      "updated_date": "2025-04-29 23:46:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:39:29.817524"
    },
    {
      "arxiv_id": "2504.21228v1",
      "title": "CachePrune: Neural-Based Attribution Defense Against Indirect Prompt Injection Attacks",
      "title_zh": "翻译失败",
      "authors": [
        "Rui Wang",
        "Junda Wu",
        "Yu Xia",
        "Tong Yu",
        "Ruiyi Zhang",
        "Ryan Rossi",
        "Lina Yao",
        "Julian McAuley"
      ],
      "abstract": "Large Language Models (LLMs) are identified as being susceptible to indirect\nprompt injection attack, where the model undesirably deviates from\nuser-provided instructions by executing tasks injected in the prompt context.\nThis vulnerability stems from LLMs' inability to distinguish between data and\ninstructions within a prompt. In this paper, we propose CachePrune that defends\nagainst this attack by identifying and pruning task-triggering neurons from the\nKV cache of the input prompt context. By pruning such neurons, we encourage the\nLLM to treat the text spans of input prompt context as only pure data, instead\nof any indicator of instruction following. These neurons are identified via\nfeature attribution with a loss function induced from an upperbound of the\nDirect Preference Optimization (DPO) objective. We show that such a loss\nfunction enables effective feature attribution with only a few samples. We\nfurther improve on the quality of feature attribution, by exploiting an\nobserved triggering effect in instruction following. Our approach does not\nimpose any formatting on the original prompt or introduce extra test-time LLM\ncalls. Experiments show that CachePrune significantly reduces attack success\nrates without compromising the response quality. Note: This paper aims to\ndefend against indirect prompt injection attacks, with the goal of developing\nmore secure and robust AI systems.",
      "tldr_zh": "该研究针对大语言模型 (LLMs) 易受间接提示注入攻击的问题，提出 CachePrune 方法，通过从 KV cache 中识别并修剪任务触发神经元来防御攻击。这些神经元利用基于 Direct Preference Optimization (DPO) 的损失函数进行特征归因，并通过指令遵循的触发效应优化归因过程，以确保模型将提示上下文视为纯数据，而非指令。实验显示，CachePrune 显著降低了攻击成功率，同时保持了响应质量，为构建更安全、鲁棒的 AI 系统提供了有效策略。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.21228v1",
      "published_date": "2025-04-29 23:42:21 UTC",
      "updated_date": "2025-04-29 23:42:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:39:42.440978"
    },
    {
      "arxiv_id": "2504.21226v2",
      "title": "MemeBLIP2: A novel lightweight multimodal system to detect harmful memes",
      "title_zh": "MemeBLIP2：一种新颖的轻量级多模态系统，用于检测有害模因",
      "authors": [
        "Jiaqi Liu",
        "Ran Tong",
        "Aowei Shen",
        "Shuzheng Li",
        "Changlin Yang",
        "Lisha Xu"
      ],
      "abstract": "Memes often merge visuals with brief text to share humor or opinions, yet\nsome memes contain harmful messages such as hate speech. In this paper, we\nintroduces MemeBLIP2, a light weight multimodal system that detects harmful\nmemes by combining image and text features effectively. We build on previous\nstudies by adding modules that align image and text representations into a\nshared space and fuse them for better classification. Using BLIP-2 as the core\nvision-language model, our system is evaluated on the PrideMM datasets. The\nresults show that MemeBLIP2 can capture subtle cues in both modalities, even in\ncases with ironic or culturally specific content, thereby improving the\ndetection of harmful material.",
      "tldr_zh": "本文提出 MemeBLIP2，一种新型轻量级多模态系统，用于检测有害 memes，通过有效结合图像和文本特征来识别仇恨言论等内容。系统基于 BLIP-2 模型，添加模块将图像和文本表示对齐到共享空间并进行融合，以提升分类准确性。在 PrideMM 数据集上评估结果表明，MemeBLIP2 能够捕捉微妙线索，即使在讽刺或文化特定内容中，也显著提高了有害材料的检测性能。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "11pages, 3 figures, manucripts in preparation",
      "pdf_url": "http://arxiv.org/pdf/2504.21226v2",
      "published_date": "2025-04-29 23:41:06 UTC",
      "updated_date": "2025-05-06 22:01:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:39:52.350345"
    },
    {
      "arxiv_id": "2504.21218v2",
      "title": "Theoretical Foundations for Semantic Cognition in Artificial Intelligence",
      "title_zh": "人工智能中语义认知的理论基础",
      "authors": [
        "Sebastian Dumbrava"
      ],
      "abstract": "This monograph presents a modular cognitive architecture for artificial\nintelligence grounded in the formal modeling of belief as structured semantic\nstate. Belief states are defined as dynamic ensembles of linguistic expressions\nembedded within a navigable manifold, where operators enable assimilation,\nabstraction, nullification, memory, and introspection. Drawing from philosophy,\ncognitive science, and neuroscience, we develop a layered framework that\nenables self-regulating epistemic agents capable of reflective, goal-directed\nthought. At the core of this framework is the epistemic vacuum: a class of\nsemantically inert cognitive states that serves as the conceptual origin of\nbelief space. From this foundation, the Null Tower arises as a generative\nstructure recursively built through internal representational capacities. The\ntheoretical constructs are designed to be implementable in both symbolic and\nneural systems, including large language models, hybrid agents, and adaptive\nmemory architectures. This work offers a foundational substrate for\nconstructing agents that reason, remember, and regulate their beliefs in\nstructured, interpretable ways.",
      "tldr_zh": "本论文提出一个模块化的认知架构，用于人工智能中的语义认知，基于正式建模信念作为结构化的语义状态。信念状态被定义为动态集合的语言表达式，嵌入可导航的流形中，并通过操作符支持同化、抽象、nullification、记忆和内省。核心概念包括epistemic vacuum（作为信念空间的起源）和Null Tower（通过递归内部表征构建），这些理论框架借鉴哲学、认知科学和神经科学，支持自我调节的认识代理进行反思性和目标导向思考。该架构可应用于符号和神经系统，如large language models和混合代理，提供基础以构建结构化、可解释的AI代理，实现有效的推理、记忆和信念调节。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "248 pages, 77 figures",
      "pdf_url": "http://arxiv.org/pdf/2504.21218v2",
      "published_date": "2025-04-29 23:10:07 UTC",
      "updated_date": "2025-05-08 05:47:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:40:05.091114"
    },
    {
      "arxiv_id": "2504.21214v2",
      "title": "Pretraining Large Brain Language Model for Active BCI: Silent Speech",
      "title_zh": "翻译失败",
      "authors": [
        "Jinzhao Zhou",
        "Zehong Cao",
        "Yiqun Duan",
        "Connor Barkley",
        "Daniel Leong",
        "Xiaowei Jiang",
        "Quoc-Toan Nguyen",
        "Ziyi Zhao",
        "Thomas Do",
        "Yu-Cheng Chang",
        "Sheng-Fu Liang",
        "Chin-teng Lin"
      ],
      "abstract": "This paper explores silent speech decoding in active brain-computer interface\n(BCI) systems, which offer more natural and flexible communication than\ntraditional BCI applications. We collected a new silent speech dataset of over\n120 hours of electroencephalogram (EEG) recordings from 12 subjects, capturing\n24 commonly used English words for language model pretraining and decoding.\nFollowing the recent success of pretraining large models with self-supervised\nparadigms to enhance EEG classification performance, we propose Large Brain\nLanguage Model (LBLM) pretrained to decode silent speech for active BCI. To\npretrain LBLM, we propose Future Spectro-Temporal Prediction (FSTP) pretraining\nparadigm to learn effective representations from unlabeled EEG data. Unlike\nexisting EEG pretraining methods that mainly follow a masked-reconstruction\nparadigm, our proposed FSTP method employs autoregressive modeling in temporal\nand frequency domains to capture both temporal and spectral dependencies from\nEEG signals. After pretraining, we finetune our LBLM on downstream tasks,\nincluding word-level and semantic-level classification. Extensive experiments\ndemonstrate significant performance gains of the LBLM over fully-supervised and\npretrained baseline models. For instance, in the difficult cross-session\nsetting, our model achieves 47.0\\% accuracy on semantic-level classification\nand 39.6\\% in word-level classification, outperforming baseline methods by\n5.4\\% and 7.3\\%, respectively. Our research advances silent speech decoding in\nactive BCI systems, offering an innovative solution for EEG language model\npretraining and a new dataset for fundamental research.",
      "tldr_zh": "本研究探讨主动脑机接口（BCI）中的无声语音解码，旨在提供更自然灵活的通信方式，并收集了超过120小时的EEG数据，涵盖12个受试者的24个常用英语单词，用于Large Brain Language Model (LBLM)的预训练。研究提出Future Spectro-Temporal Prediction (FSTP)预训练范式，该方法采用自回归建模捕获EEG信号的时域和频域依赖性，区别于传统的masked-reconstruction方法。实验结果显示，LBLM在下游任务如单词级和语义级分类上显著优于基线模型，例如在跨会话设置中，语义级分类准确率达47.0%、单词级达39.6%，分别比基线高5.4%和7.3%。这项工作为无声语音解码提供了创新解决方案，并贡献了新的EEG数据集和预训练方法。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.21214v2",
      "published_date": "2025-04-29 22:48:27 UTC",
      "updated_date": "2025-05-03 07:53:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:40:17.392871"
    },
    {
      "arxiv_id": "2504.21211v1",
      "title": "A Cost-Effective LLM-based Approach to Identify Wildlife Trafficking in Online Marketplaces",
      "title_zh": "一种基于LLM的成本有效方法，用于识别在线市场中的野生动物贩运",
      "authors": [
        "Juliana Barbosa",
        "Ulhas Gondhali",
        "Gohar Petrossian",
        "Kinshuk Sharma",
        "Sunandan Chakraborty",
        "Jennifer Jacquet",
        "Juliana Freire"
      ],
      "abstract": "Wildlife trafficking remains a critical global issue, significantly impacting\nbiodiversity, ecological stability, and public health. Despite efforts to\ncombat this illicit trade, the rise of e-commerce platforms has made it easier\nto sell wildlife products, putting new pressure on wild populations of\nendangered and threatened species. The use of these platforms also opens a new\nopportunity: as criminals sell wildlife products online, they leave digital\ntraces of their activity that can provide insights into trafficking activities\nas well as how they can be disrupted. The challenge lies in finding these\ntraces. Online marketplaces publish ads for a plethora of products, and\nidentifying ads for wildlife-related products is like finding a needle in a\nhaystack. Learning classifiers can automate ad identification, but creating\nthem requires costly, time-consuming data labeling that hinders support for\ndiverse ads and research questions. This paper addresses a critical challenge\nin the data science pipeline for wildlife trafficking analytics: generating\nquality labeled data for classifiers that select relevant data. While large\nlanguage models (LLMs) can directly label advertisements, doing so at scale is\nprohibitively expensive. We propose a cost-effective strategy that leverages\nLLMs to generate pseudo labels for a small sample of the data and uses these\nlabels to create specialized classification models. Our novel method\nautomatically gathers diverse and representative samples to be labeled while\nminimizing the labeling costs. Our experimental evaluation shows that our\nclassifiers achieve up to 95% F1 score, outperforming LLMs at a lower cost. We\npresent real use cases that demonstrate the effectiveness of our approach in\nenabling analyses of different aspects of wildlife trafficking.",
      "tldr_zh": "本论文针对野生动物贩卖在电商平台的识别问题，提出了一种基于大型语言模型(LLM)的成本有效方法，通过利用LLM生成伪标签(pseudo labels)来训练专用分类模型，并自动收集多样化和代表性的样本以最小化标注成本。实验结果显示，该方法使分类器达到95% F1 score，比直接使用LLM更经济高效。论文还展示了实际用例，证明该方法能有效支持对野生动物贩卖不同方面的分析。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.21211v1",
      "published_date": "2025-04-29 22:34:42 UTC",
      "updated_date": "2025-04-29 22:34:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:40:28.217143"
    },
    {
      "arxiv_id": "2504.21206v1",
      "title": "FedHERO: A Federated Learning Approach for Node Classification Task on Heterophilic Graphs",
      "title_zh": "翻译失败",
      "authors": [
        "Zihan Chen",
        "Xingbo Fu",
        "Yushun Dong",
        "Jundong Li",
        "Cong Shen"
      ],
      "abstract": "Federated Graph Learning (FGL) empowers clients to collaboratively train\nGraph neural networks (GNNs) in a distributed manner while preserving data\nprivacy. However, FGL methods usually require that the graph data owned by all\nclients is homophilic to ensure similar neighbor distribution patterns of\nnodes. Such an assumption ensures that the learned knowledge is consistent\nacross the local models from all clients. Therefore, these local models can be\nproperly aggregated as a global model without undermining the overall\nperformance. Nevertheless, when the neighbor distribution patterns of nodes\nvary across different clients (e.g., when clients hold graphs with different\nlevels of heterophily), their local models may gain different and even conflict\nknowledge from their node-level predictive tasks. Consequently, aggregating\nthese local models usually leads to catastrophic performance deterioration on\nthe global model. To address this challenge, we propose FedHERO, an FGL\nframework designed to harness and share insights from heterophilic graphs\neffectively. At the heart of FedHERO is a dual-channel GNN equipped with a\nstructure learner, engineered to discern the structural knowledge encoded in\nthe local graphs. With this specialized component, FedHERO enables the local\nmodel for each client to identify and learn patterns that are universally\napplicable across graphs with different patterns of node neighbor\ndistributions. FedHERO not only enhances the performance of individual client\nmodels by leveraging both local and shared structural insights but also sets a\nnew precedent in this field to effectively handle graph data with various node\nneighbor distribution patterns. We conduct extensive experiments to validate\nthe superior performance of FedHERO against existing alternatives.",
      "tldr_zh": "传统的 Federated Graph Learning (FGL) 方法假设图数据是同质的（homophilic），但在处理异质图（heterophilic graphs）时，客户端本地模型可能学到冲突的知识，导致全局模型性能急剧下降。为解决此问题，提出 FedHERO 框架，该框架的核心是双通道 GNN 结合结构学习器，帮助每个客户端识别和学习不同节点邻居分布模式下的通用结构知识。FedHERO 通过整合本地和共享洞见，提升了客户端模型的整体性能，并在广泛实验中证明了其比现有方法更优的表现。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DC"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.21206v1",
      "published_date": "2025-04-29 22:23:35 UTC",
      "updated_date": "2025-04-29 22:23:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:40:40.997049"
    },
    {
      "arxiv_id": "2504.21205v1",
      "title": "SecRepoBench: Benchmarking LLMs for Secure Code Generation in Real-World Repositories",
      "title_zh": "翻译失败",
      "authors": [
        "Connor Dilgren",
        "Purva Chiniya",
        "Luke Griffith",
        "Yu Ding",
        "Yizheng Chen"
      ],
      "abstract": "This paper introduces SecRepoBench, a benchmark to evaluate LLMs on secure\ncode generation in real-world repositories. SecRepoBench has 318 code\ngeneration tasks in 27 C/C++ repositories, covering 15 CWEs. We evaluate 19\nstate-of-the-art LLMs using our benchmark and find that the models struggle\nwith generating correct and secure code. In addition, the performance of LLMs\nto generate self-contained programs as measured by prior benchmarks do not\ntranslate to comparative performance at generating secure and correct code at\nthe repository level in SecRepoBench. We show that the state-of-the-art prompt\nengineering techniques become less effective when applied to the repository\nlevel secure code generation problem. We conduct extensive experiments,\nincluding an agentic technique to generate secure code, to demonstrate that our\nbenchmark is currently the most difficult secure coding benchmark, compared to\nprevious state-of-the-art benchmarks. Finally, our comprehensive analysis\nprovides insights into potential directions for enhancing the ability of LLMs\nto generate correct and secure code in real-world repositories.",
      "tldr_zh": "本论文引入了 SecRepoBench 基准，用于评估大型语言模型（LLMs）在真实仓库中生成安全代码的能力，该基准包含 318 个代码生成任务，涉及 27 个 C/C++ 仓库和 15 个 CWEs。\n评估 19 个最先进 LLMs 后，发现这些模型在生成正确和安全的代码方面存在显著困难，且先前基准中 LLMs 的自包含程序生成性能无法转化为仓库级别的表现。\n此外，实验证明先进的提示工程技术在仓库级别安全代码生成问题上效果有限，而 SecRepoBench 被证实是目前最难的安全编码基准；论文通过全面分析提供了提升 LLMs 生成正确和安全代码的潜在改进方向。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.21205v1",
      "published_date": "2025-04-29 22:22:44 UTC",
      "updated_date": "2025-04-29 22:22:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:40:54.422153"
    },
    {
      "arxiv_id": "2504.21202v1",
      "title": "Automatic Legal Writing Evaluation of LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Ramon Pires",
        "Roseval Malaquias Junior",
        "Rodrigo Nogueira"
      ],
      "abstract": "Despite the recent advances in Large Language Models, benchmarks for\nevaluating legal writing remain scarce due to the inherent complexity of\nassessing open-ended responses in this domain. One of the key challenges in\nevaluating language models on domain-specific tasks is finding test datasets\nthat are public, frequently updated, and contain comprehensive evaluation\nguidelines. The Brazilian Bar Examination meets these requirements. We\nintroduce oab-bench, a benchmark comprising 105 questions across seven areas of\nlaw from recent editions of the exam. The benchmark includes comprehensive\nevaluation guidelines and reference materials used by human examiners to ensure\nconsistent grading. We evaluate the performance of four LLMs on oab-bench,\nfinding that Claude-3.5 Sonnet achieves the best results with an average score\nof 7.93 out of 10, passing all 21 exams. We also investigated whether LLMs can\nserve as reliable automated judges for evaluating legal writing. Our\nexperiments show that frontier models like OpenAI's o1 achieve a strong\ncorrelation with human scores when evaluating approved exams, suggesting their\npotential as reliable automated evaluators despite the inherently subjective\nnature of legal writing assessment. The source code and the benchmark --\ncontaining questions, evaluation guidelines, model-generated responses, and\ntheir respective automated evaluations -- are publicly available.",
      "tldr_zh": "这篇论文引入了oab-bench基准，利用巴西律师考试的105个问题和全面评估指南，来评估LLMs在法律写作领域的表现，旨在解决现有基准稀缺的问题。实验结果显示，Claude-3.5 Sonnet表现最佳，平均得分7.93/10，并通过所有21个考试。研究进一步探索了LLMs作为自动评估者，如OpenAI's o1模型，与人类评分显示出强相关性，证明其在主观性强的法律评估中具有潜力。该基准及其源代码已公开可用。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.21202v1",
      "published_date": "2025-04-29 22:16:39 UTC",
      "updated_date": "2025-04-29 22:16:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:41:05.841014"
    },
    {
      "arxiv_id": "2504.21195v1",
      "title": "Turning Up the Heat: Assessing 2-m Temperature Forecast Errors in AI Weather Prediction Models During Heat Waves",
      "title_zh": "翻译失败",
      "authors": [
        "Kelsey E. Ennis",
        "Elizabeth A. Barnes",
        "Marybeth C. Arcodia",
        "Martin A. Fernandez",
        "Eric D. Maloney"
      ],
      "abstract": "Extreme heat is the deadliest weather-related hazard in the United States.\nFurthermore, it is increasing in intensity, frequency, and duration, making\nskillful forecasts vital to protecting life and property. Traditional numerical\nweather prediction (NWP) models struggle with extreme heat for medium-range and\nsubseasonal-to-seasonal (S2S) timescales. Meanwhile, artificial\nintelligence-based weather prediction (AIWP) models are progressing rapidly.\nHowever, it is largely unknown how well AIWP models forecast extremes,\nespecially for medium-range and S2S timescales. This study investigates 2-m\ntemperature forecasts for 60 heat waves across the four boreal seasons and over\nfour CONUS regions at lead times up to 20 days, using two AIWP models (Google\nGraphCast and Pangu-Weather) and one traditional NWP model (NOAA United\nForecast System Global Ensemble Forecast System (UFS GEFS)). First, case study\nanalyses show that both AIWP models and the UFS GEFS exhibit consistent cold\nbiases on regional scales in the 5-10 days of lead time before heat wave onset.\nGraphCast is the more skillful AIWP model, outperforming UFS GEFS and\nPangu-Weather in most locations. Next, the two AIWP models are isolated and\nanalyzed across all heat waves and seasons, with events split among the model's\ntesting (2018-2023) and training (1979-2017) periods. There are cold biases\nbefore and during the heat waves in both models and all seasons, except\nPangu-Weather in winter, which exhibits a mean warm bias before heat wave\nonset. Overall, results offer encouragement that AIWP models may be useful for\nmedium-range and S2S predictability of extreme heat.",
      "tldr_zh": "这篇论文评估了AI天气预测（AIWP）模型在热浪期间的2-m温度预测错误，比较了Google GraphCast、Pangu-Weather和传统数值天气预测（NWP）模型NOAA UFS GEFS，共分析了60个热浪事件，覆盖四个北半球季节和四个CONUS地区，提前时间长达20天。研究发现，所有模型在热浪开始前5-10天显示一致的冷偏差，而GraphCast作为AIWP模型在大多数位置的表现优于UFS GEFS和Pangu-Weather。总体结果表明，AIWP模型在中等范围和S2S时间尺度上对极端热浪的预测具有潜力，尽管存在季节性偏差。",
      "categories": [
        "physics.ao-ph",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "physics.ao-ph",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.21195v1",
      "published_date": "2025-04-29 22:02:32 UTC",
      "updated_date": "2025-04-29 22:02:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:41:17.679227"
    },
    {
      "arxiv_id": "2504.21194v1",
      "title": "Geolocating Earth Imagery from ISS: Integrating Machine Learning with Astronaut Photography for Enhanced Geographic Mapping",
      "title_zh": "翻译失败",
      "authors": [
        "Vedika Srivastava",
        "Hemant Kumar Singh",
        "Jaisal Singh"
      ],
      "abstract": "This paper presents a novel approach to geolocating images captured from the\nInternational Space Station (ISS) using advanced machine learning algorithms.\nDespite having precise ISS coordinates, the specific Earth locations depicted\nin astronaut-taken photographs often remain unidentified. Our research\naddresses this gap by employing three distinct image processing pipelines: a\nNeural Network based approach, a SIFT based method, and GPT-4 model. Each\npipeline is tailored to process high-resolution ISS imagery, identifying both\nnatural and man-made geographical features. Through extensive evaluation on a\ndiverse dataset of over 140 ISS images, our methods demonstrate significant\npromise in automated geolocation with varied levels of success. The NN approach\nshowed a high success rate in accurately matching geographical features, while\nthe SIFT pipeline excelled in processing zoomed-in images. GPT-4 model provided\nenriched geographical descriptions alongside location predictions. This\nresearch contributes to the fields of remote sensing and Earth observation by\nenhancing the accuracy and efficiency of geolocating space-based imagery,\nthereby aiding environmental monitoring and global mapping efforts.",
      "tldr_zh": "本文提出了一种新方法，用于地理定位国际空间站（ISS）拍摄的地球图像，通过整合机器学习算法解决照片中具体位置的识别问题。方法包括三个图像处理管道：基于 Neural Network 的特征匹配、SIFT 算法的图像处理，以及 GPT-4 模型的地理描述生成，这些管道针对高分辨率 ISS 图像识别自然和人工特征。在超过 140 张图像的数据集上评估显示，Neural Network 方法在地理特征匹配方面成功率最高，SIFT 管道在处理缩放图像时表现出色，而 GPT-4 提供了丰富的辅助描述。该研究提升了远程感知和地球观测的准确性与效率，支持环境监测和全球映射应用。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.21194v1",
      "published_date": "2025-04-29 22:00:02 UTC",
      "updated_date": "2025-04-29 22:00:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:41:30.499255"
    },
    {
      "arxiv_id": "2504.21191v1",
      "title": "Small or Large? Zero-Shot or Finetuned? Guiding Language Model Choice for Specialized Applications in Healthcare",
      "title_zh": "翻译失败",
      "authors": [
        "Lovedeep Gondara",
        "Jonathan Simkin",
        "Graham Sayle",
        "Shebnum Devji",
        "Gregory Arbour",
        "Raymond Ng"
      ],
      "abstract": "This study aims to guide language model selection by investigating: 1) the\nnecessity of finetuning versus zero-shot usage, 2) the benefits of\ndomain-adjacent versus generic pretrained models, 3) the value of further\ndomain-specific pretraining, and 4) the continued relevance of Small Language\nModels (SLMs) compared to Large Language Models (LLMs) for specific tasks.\nUsing electronic pathology reports from the British Columbia Cancer Registry\n(BCCR), three classification scenarios with varying difficulty and data size\nare evaluated. Models include various SLMs and an LLM. SLMs are evaluated both\nzero-shot and finetuned; the LLM is evaluated zero-shot only. Finetuning\nsignificantly improved SLM performance across all scenarios compared to their\nzero-shot results. The zero-shot LLM outperformed zero-shot SLMs but was\nconsistently outperformed by finetuned SLMs. Domain-adjacent SLMs generally\nperformed better than the generic SLM after finetuning, especially on harder\ntasks. Further domain-specific pretraining yielded modest gains on easier tasks\nbut significant improvements on the complex, data-scarce task. The results\nhighlight the critical role of finetuning for SLMs in specialized domains,\nenabling them to surpass zero-shot LLM performance on targeted classification\ntasks. Pretraining on domain-adjacent or domain-specific data provides further\nadvantages, particularly for complex problems or limited finetuning data. While\nLLMs offer strong zero-shot capabilities, their performance on these specific\ntasks did not match that of appropriately finetuned SLMs. In the era of LLMs,\nSLMs remain relevant and effective, offering a potentially superior\nperformance-resource trade-off compared to LLMs.",
      "tldr_zh": "本研究探讨了在医疗领域的特定应用中，选择语言模型的策略，包括zero-shot vs. finetuned使用、domain-adjacent vs. generic pretrained模型的比较，以及Small Language Models (SLMs) 与Large Language Models (LLMs)的相关性。\n使用不列颠哥伦比亚癌症登记处的电子病理报告数据，进行三种不同难度和数据规模的分类任务实验，结果显示微调显著提升了SLMs的性能，使其超越zero-shot LLMs的表现。\n此外，domain-adjacent SLMs在微调后尤其在困难任务上优于generic模型，而进一步的domain-specific pretraining在复杂或数据稀缺任务上带来显著改善。\n总体而言，该研究强调了在专业领域微调SLMs的重要性，证明SLMs在性能-资源权衡上可能优于LLMs。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.21191v1",
      "published_date": "2025-04-29 21:50:06 UTC",
      "updated_date": "2025-04-29 21:50:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:41:43.585939"
    },
    {
      "arxiv_id": "2504.21190v1",
      "title": "TT-LoRA MoE: Unifying Parameter-Efficient Fine-Tuning and Sparse Mixture-of-Experts",
      "title_zh": "TT-LoRA MoE：统一参数高效微调和稀疏混合专家模型",
      "authors": [
        "Pradip Kunwar",
        "Minh N. Vu",
        "Maanak Gupta",
        "Mahmoud Abdelsalam",
        "Manish Bhattarai"
      ],
      "abstract": "We propose Tensor-Trained Low-Rank Adaptation Mixture of Experts (TT-LoRA\nMoE), a novel computational framework integrating Parameter-Efficient\nFine-Tuning (PEFT) with sparse MoE routing to address scalability challenges in\nlarge model deployments. Unlike traditional MoE approaches, which face\nsubstantial computational overhead as expert counts grow, TT-LoRA MoE\ndecomposes training into two distinct, optimized stages. First, we\nindependently train lightweight, tensorized low-rank adapters (TT-LoRA\nexperts), each specialized for specific tasks. Subsequently, these expert\nadapters remain frozen, eliminating inter-task interference and catastrophic\nforgetting in multi-task setting. A sparse MoE router, trained separately,\ndynamically leverages base model representations to select exactly one\nspecialized adapter per input at inference time, automating expert selection\nwithout explicit task specification. Comprehensive experiments confirm our\narchitecture retains the memory efficiency of low-rank adapters, seamlessly\nscales to large expert pools, and achieves robust task-level optimization. This\nstructured decoupling significantly enhances computational efficiency and\nflexibility: uses only 2% of LoRA, 0.3% of Adapters and 0.03% of AdapterFusion\nparameters and outperforms AdapterFusion by 4 value in multi-tasking, enabling\npractical and scalable multi-task inference deployments.",
      "tldr_zh": "该研究提出了一种名为 TT-LoRA MoE 的新框架，将 Parameter-Efficient Fine-Tuning (PEFT) 与 sparse Mixture-of-Experts (MoE) 相结合，以解决大规模模型部署中的可扩展性挑战。框架将训练分为两个阶段：首先独立训练轻量化的 tensorized low-rank adapters (TT-LoRA experts)，每个针对特定任务，并随后冻结这些 experts 以避免多任务设置中的干扰和灾难性遗忘；接着训练一个 sparse MoE router，在推理时动态根据输入选择恰好一个专家。实验结果显示，TT-LoRA MoE 仅使用 LoRA 的 2%、Adapters 的 0.3% 和 AdapterFusion 的 0.03% 参数，就在多任务场景中比 AdapterFusion 提升 4% 的性能，同时保持内存效率并无缝扩展到大型专家池。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.21190v1",
      "published_date": "2025-04-29 21:46:43 UTC",
      "updated_date": "2025-04-29 21:46:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:41:53.320694"
    },
    {
      "arxiv_id": "2504.21189v1",
      "title": "Artificial Intelligence for Personalized Prediction of Alzheimer's Disease Progression: A Survey of Methods, Data Challenges, and Future Directions",
      "title_zh": "翻译失败",
      "authors": [
        "Gulsah Hancerliogullari Koksalmis",
        "Bulent Soykan",
        "Laura J. Brattain",
        "Hsin-Hsiung Huang"
      ],
      "abstract": "Alzheimer's Disease (AD) is marked by significant inter-individual\nvariability in its progression, complicating accurate prognosis and\npersonalized care planning. This heterogeneity underscores the critical need\nfor predictive models capable of forecasting patient-specific disease\ntrajectories. Artificial Intelligence (AI) offers powerful tools to address\nthis challenge by analyzing complex, multi-modal, and longitudinal patient\ndata. This paper provides a comprehensive survey of AI methodologies applied to\npersonalized AD progression prediction. We review key approaches including\nstate-space models for capturing temporal dynamics, deep learning techniques\nlike Recurrent Neural Networks for sequence modeling, Graph Neural Networks\n(GNNs) for leveraging network structures, and the emerging concept of AI-driven\ndigital twins for individualized simulation. Recognizing that data limitations\noften impede progress, we examine common challenges such as high\ndimensionality, missing data, and dataset imbalance. We further discuss\nAI-driven mitigation strategies, with a specific focus on synthetic data\ngeneration using Variational Autoencoders (VAEs) and Generative Adversarial\nNetworks (GANs) to augment and balance datasets. The survey synthesizes the\nstrengths and limitations of current approaches, emphasizing the trend towards\nmultimodal integration and the persistent need for model interpretability and\ngeneralizability. Finally, we identify critical open challenges, including\nrobust external validation, clinical integration, and ethical considerations,\nand outline promising future research directions such as hybrid models, causal\ninference, and federated learning. This review aims to consolidate current\nknowledge and guide future efforts in developing clinically relevant AI tools\nfor personalized AD prognostication.",
      "tldr_zh": "这篇论文对使用人工智能（AI）进行阿尔茨海默病（AD）进展个性化预测的方法进行了全面调查，强调了AI在分析多模态和纵向患者数据方面的潜力。论文回顾了关键技术，包括状态空间模型（state-space models）捕捉时间动态、循环神经网络（RNNs）处理序列数据、图神经网络（GNNs）利用网络结构，以及AI驱动的数字孪生（digital twins）实现个性化模拟，同时讨论了数据挑战如高维度、缺失数据和数据集不平衡。作者提出缓解策略，如使用变分自动编码器（VAEs）和生成对抗网络（GANs）生成合成数据，以增强数据集，并总结了现有方法的优势和局限性，如多模态整合的趋势与模型可解释性和泛化性的需求。最终，论文指出了开放挑战包括外部验证、临床整合和伦理问题，并建议未来方向如混合模型、因果推理和联邦学习，以推动临床相关AI工具的发展。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.ET"
      ],
      "primary_category": "cs.LG",
      "comment": "25 pages, 11 figures",
      "pdf_url": "http://arxiv.org/pdf/2504.21189v1",
      "published_date": "2025-04-29 21:45:28 UTC",
      "updated_date": "2025-04-29 21:45:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:42:06.487488"
    },
    {
      "arxiv_id": "2504.21188v2",
      "title": "Light Weight CNN for classification of Brain Tumors from MRI Images",
      "title_zh": "轻量级 CNN 用于 MRI 图像脑肿瘤分类",
      "authors": [
        "Natnael Alemayehu"
      ],
      "abstract": "This study presents a convolutional neural network (CNN)-based approach for\nthe multi-class classification of brain tumors using magnetic resonance imaging\n(MRI) scans. We utilize a publicly available dataset containing MRI images\ncategorized into four classes: glioma, meningioma, pituitary tumor, and no\ntumor. Our primary objective is to build a light weight deep learning model\nthat can automatically classify brain tumor types with high accuracy. To\nachieve this goal, we incorporate image preprocessing steps, including\nnormalization, data augmentation, and a cropping technique designed to reduce\nbackground noise and emphasize relevant regions. The CNN architecture is\noptimized through hyperparameter tuning using Keras Tuner, enabling systematic\nexploration of network parameters. To ensure reliable evaluation, we apply\n5-fold cross-validation, where each hyperparameter configuration is evaluated\nacross multiple data splits to mitigate overfitting. Experimental results\ndemonstrate that the proposed model achieves a classification accuracy of\n98.78%, indicating its potential as a diagnostic aid in clinical settings. The\nproposed method offers a low-complexity yet effective solution for assisting in\nearly brain tumor diagnosis.",
      "tldr_zh": "本研究提出了一种轻量级 CNN 模型，用于从 MRI 图像中对脑肿瘤进行多类分类，包括胶质瘤、脑膜瘤、垂体瘤和无肿瘤。模型通过图像预处理（如归一化、数据增强和裁剪技术）、超参数调优（使用 Keras Tuner）和5折交叉验证来优化性能，并有效减少背景噪声和过拟合。实验结果显示，该模型在公开数据集上实现了98.78%的分类准确率，为临床诊断提供了一个低复杂度、高效的早诊辅助工具。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "eess.IV",
      "comment": "6 pages",
      "pdf_url": "http://arxiv.org/pdf/2504.21188v2",
      "published_date": "2025-04-29 21:45:11 UTC",
      "updated_date": "2025-05-05 20:00:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:42:16.929148"
    },
    {
      "arxiv_id": "2504.21184v1",
      "title": "AffectEval: A Modular and Customizable Framework for Affective Computing",
      "title_zh": "翻译失败",
      "authors": [
        "Emily Zhou",
        "Khushboo Khatri",
        "Yixue Zhao",
        "Bhaskar Krishnamachari"
      ],
      "abstract": "The field of affective computing focuses on recognizing, interpreting, and\nresponding to human emotions, and has broad applications across education,\nchild development, and human health and wellness. However, developing affective\ncomputing pipelines remains labor-intensive due to the lack of software\nframeworks that support multimodal, multi-domain emotion recognition\napplications. This often results in redundant effort when building pipelines\nfor different applications. While recent frameworks attempt to address these\nchallenges, they remain limited in reducing manual effort and ensuring\ncross-domain generalizability. We introduce AffectEval, a modular and\ncustomizable framework to facilitate the development of affective computing\npipelines while reducing the manual effort and duplicate work involved in\ndeveloping such pipelines. We validate AffectEval by replicating prior\naffective computing experiments, and we demonstrate that our framework reduces\nprogramming effort by up to 90%, as measured by the reduction in raw lines of\ncode.",
      "tldr_zh": "这篇论文介绍了 AffectEval，一个模块化和可定制的框架，旨在简化情感计算(affective computing)管道的开发，支持多模态和多领域情绪识别应用。AffectEval 通过减少手动努力和重复工作，解决了现有框架在跨领域泛化方面的局限性。实验验证显示，该框架在复制先前实验时，能将编程努力减少高达 90%，如通过减少原始代码行数。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "The short version is published in ACM/IEEE CHASE 2025",
      "pdf_url": "http://arxiv.org/pdf/2504.21184v1",
      "published_date": "2025-04-29 21:40:49 UTC",
      "updated_date": "2025-04-29 21:40:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:42:29.263394"
    },
    {
      "arxiv_id": "2504.21166v1",
      "title": "Dance Style Recognition Using Laban Movement Analysis",
      "title_zh": "基于 Laban 运动分析的舞蹈风格识别",
      "authors": [
        "Muhammad Turab",
        "Philippe Colantoni",
        "Damien Muselet",
        "Alain Tremeau"
      ],
      "abstract": "The growing interest in automated movement analysis has presented new\nchallenges in recognition of complex human activities including dance. This\nstudy focuses on dance style recognition using features extracted using Laban\nMovement Analysis. Previous studies for dance style recognition often focus on\ncross-frame movement analysis, which limits the ability to capture temporal\ncontext and dynamic transitions between movements. This gap highlights the need\nfor a method that can add temporal context to LMA features. For this, we\nintroduce a novel pipeline which combines 3D pose estimation, 3D human mesh\nreconstruction, and floor aware body modeling to effectively extract LMA\nfeatures. To address the temporal limitation, we propose a sliding window\napproach that captures movement evolution across time in features. These\nfeatures are then used to train various machine learning methods for\nclassification, and their explainability explainable AI methods to evaluate the\ncontribution of each feature to classification performance. Our proposed method\nachieves a highest classification accuracy of 99.18\\% which shows that the\naddition of temporal context significantly improves dance style recognition\nperformance.",
      "tldr_zh": "该研究聚焦于使用 Laban Movement Analysis (LMA) 进行舞蹈风格识别，解决了传统方法忽略时间上下文和动态过渡的局限性。研究提出一个新管道，包括 3D pose estimation、3D human mesh reconstruction 和 floor aware body modeling 来提取 LMA 特征，并采用 sliding window  approach 来捕捉特征的时间演变。接着，使用这些增强特征训练各种 machine learning 方法，并通过 explainable AI 方法评估特征贡献，最终实现最高分类准确率99.18%，证明添加时间上下文显著提升了识别性能。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.21166v1",
      "published_date": "2025-04-29 20:35:01 UTC",
      "updated_date": "2025-04-29 20:35:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:42:40.912493"
    },
    {
      "arxiv_id": "2504.21155v2",
      "title": "Evaluation and Verification of Physics-Informed Neural Models of the Grad-Shafranov Equation",
      "title_zh": "翻译失败",
      "authors": [
        "Fauzan Nazranda Rizqan",
        "Matthew Hole",
        "Charles Gretton"
      ],
      "abstract": "Our contributions are motivated by fusion reactors that rely on maintaining\nmagnetohydrodynamic (MHD) equilibrium, where the balance between plasma\npressure and confining magnetic fields is required for stable operation. In\naxisymmetric tokamak reactors in particular, and under the assumption of\ntoroidal symmetry, this equilibrium can be mathematically modelled using the\nGrad-Shafranov Equation (GSE). Recent works have demonstrated the potential of\nusing Physics-Informed Neural Networks (PINNs) to model the GSE. Existing\nstudies did not examine realistic scenarios in which a single network\ngeneralizes to a variety of boundary conditions. Addressing that limitation, we\nevaluate a PINN architecture that incorporates boundary points as network\ninputs. Additionally, we compare PINN model accuracy and inference speeds with\na Fourier Neural Operator (FNO) model. Finding the PINN model to be the most\nperformant, and accurate in our setting, we use the network verification tool\nMarabou to perform a range of verification tasks. Although we find some\ndiscrepancies between evaluations of the networks natively in PyTorch, compared\nto via Marabou, we are able to demonstrate useful and practical verification\nworkflows. Our study is the first investigation of verification of such\nnetworks.",
      "tldr_zh": "本研究评估了 Physics-Informed Neural Networks (PINNs) 在模拟 Grad-Shafranov Equation (GSE) 的应用，GSE 用于建模核聚变反应器中磁流体动力学 (MHD) 平衡。研究提出了一种 PINN 架构，将边界点作为网络输入，以实现对多种边界条件的泛化，并与 Fourier Neural Operator (FNO) 模型进行比较，结果显示 PINN 在准确性和推理速度上更具优势。利用 Marabou 工具进行网络验证，首次探索了此类模型的验证工作流程，尽管 PyTorch 和 Marabou 评估间存在差异，但证明了其实用性。",
      "categories": [
        "physics.plasm-ph",
        "cs.AI",
        "cs.NE"
      ],
      "primary_category": "physics.plasm-ph",
      "comment": "9 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2504.21155v2",
      "published_date": "2025-04-29 20:17:43 UTC",
      "updated_date": "2025-05-01 04:26:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:42:53.258210"
    },
    {
      "arxiv_id": "2504.21154v1",
      "title": "Emotion Recognition in Contemporary Dance Performances Using Laban Movement Analysis",
      "title_zh": "使用 Laban Movement Analysis 进行当代舞表演的情感识别",
      "authors": [
        "Muhammad Turab",
        "Philippe Colantoni",
        "Damien Muselet",
        "Alain Tremeau"
      ],
      "abstract": "This paper presents a novel framework for emotion recognition in contemporary\ndance by improving existing Laban Movement Analysis (LMA) feature descriptors\nand introducing robust, novel descriptors that capture both quantitative and\nqualitative aspects of the movement. Our approach extracts expressive\ncharacteristics from 3D keypoints data of professional dancers performing\ncontemporary dance under various emotional states, and trains multiple\nclassifiers, including Random Forests and Support Vector Machines.\nAdditionally, we provide in-depth explanation of features and their impact on\nmodel predictions using explainable machine learning methods. Overall, our\nstudy improves emotion recognition in contemporary dance and offers promising\napplications in performance analysis, dance training, and human--computer\ninteraction, with a highest accuracy of 96.85\\%.",
      "tldr_zh": "这篇论文提出了一种新框架，通过改进 Laban Movement Analysis (LMA) 特征描述符并引入新型描述符，来识别当代舞表演中的情感特征。框架从专业舞者的 3D 关键点数据中提取定量和定性表现特性，并训练 Random Forests 和 Support Vector Machines 等分类器，同时运用 explainable machine learning 方法解释特征对模型预测的影响。研究结果显示，情感识别准确率最高达 96.85%，为表演分析、舞蹈训练和人机交互等领域提供了有前景的应用。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.21154v1",
      "published_date": "2025-04-29 20:17:27 UTC",
      "updated_date": "2025-04-29 20:17:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:43:05.466050"
    },
    {
      "arxiv_id": "2504.21152v1",
      "title": "SMOGAN: Synthetic Minority Oversampling with GAN Refinement for Imbalanced Regression",
      "title_zh": "翻译失败",
      "authors": [
        "Shayan Alahyari",
        "Mike Domaratzki"
      ],
      "abstract": "Imbalanced regression refers to prediction tasks where the target variable is\nskewed. This skewness hinders machine learning models, especially neural\nnetworks, which concentrate on dense regions and therefore perform poorly on\nunderrepresented (minority) samples. Despite the importance of this problem,\nonly a few methods have been proposed for imbalanced regression. Many of the\navailable solutions for imbalanced regression adapt techniques from the class\nimbalance domain, such as linear interpolation and the addition of Gaussian\nnoise, to create synthetic data in sparse regions. However, in many cases, the\nunderlying distribution of the data is complex and non-linear. Consequently,\nthese approaches generate synthetic samples that do not accurately represent\nthe true feature-target relationship. To overcome these limitations, we propose\nSMOGAN, a two-step oversampling framework for imbalanced regression. In Stage\n1, an existing oversampler generates initial synthetic samples in sparse target\nregions. In Stage 2, we introduce DistGAN, a distribution-aware GAN that serves\nas SMOGAN's filtering layer and refines these samples via adversarial loss\naugmented with a Maximum Mean Discrepancy objective, aligning them with the\ntrue joint feature-target distribution. Extensive experiments on 23 imbalanced\ndatasets show that SMOGAN consistently outperforms the default oversampling\nmethod without the DistGAN filtering layer.",
      "tldr_zh": "这篇论文针对不平衡回归问题，提出SMOGAN框架，以解决现有过采样方法在处理复杂非线性分布时的不足。SMOGAN采用两阶段方法：第一阶段使用现有过采样器生成初始合成样本于稀疏目标区域；第二阶段引入DistGAN，一个分布感知的GAN，通过对抗损失结合Maximum Mean Discrepancy (MMD)目标来精炼这些样本，使其更准确地对齐真实联合特征-目标分布。在23个不平衡数据集上的广泛实验中，SMOGAN显著优于未使用DistGAN过滤层的默认方法。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.21152v1",
      "published_date": "2025-04-29 20:15:25 UTC",
      "updated_date": "2025-04-29 20:15:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:43:17.640019"
    },
    {
      "arxiv_id": "2505.00040v1",
      "title": "Convolutional Autoencoders for Data Compression and Anomaly Detection in Small Satellite Technologies",
      "title_zh": "翻译失败",
      "authors": [
        "Dishanand Jayeprokash",
        "Julia Gonski"
      ],
      "abstract": "Small satellite technologies have enhanced the potential and feasibility of\ngeodesic missions, through simplification of design and decreased costs\nallowing for more frequent launches. On-satellite data acquisition systems can\nbenefit from the implementation of machine learning (ML), for better\nperformance and greater efficiency on tasks such as image processing or feature\nextraction. This work presents convolutional autoencoders for implementation on\nthe payload of small satellites, designed to achieve dual functionality of data\ncompression for more efficient off-satellite transmission, and at-source\nanomaly detection to inform satellite data-taking. This capability is\ndemonstrated for a use case of disaster monitoring using aerial image datasets\nof the African continent, offering avenues for both novel ML-based approaches\nin small satellite applications along with the expansion of space technology\nand artificial intelligence in Africa.",
      "tldr_zh": "该研究提出使用卷积自动编码器（convolutional autoencoders）在小卫星有效载荷上，实现数据压缩和异常检测的双重功能，以提升图像处理和特征提取的效率。方法结合机器学习（ML），通过压缩数据减少离线传输负担，并在源头识别异常以指导卫星数据采集。实验以非洲大陆航空图像数据集为例，应用于灾害监测场景，展示了这一创新方法如何为小卫星技术开辟新途径，并促进非洲的空间技术和人工智能的扩展。",
      "categories": [
        "astro-ph.IM",
        "cs.AI"
      ],
      "primary_category": "astro-ph.IM",
      "comment": "10 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.00040v1",
      "published_date": "2025-04-29 19:51:08 UTC",
      "updated_date": "2025-04-29 19:51:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:43:30.323554"
    },
    {
      "arxiv_id": "2504.21131v1",
      "title": "A Formalism for Optimal Search with Dynamic Heuristics",
      "title_zh": "翻译失败",
      "authors": [
        "Remo Christen",
        "Florian Pommerening",
        "Clemens Büchner",
        "Malte Helmert"
      ],
      "abstract": "While most heuristics studied in heuristic search depend only on the state,\nsome accumulate information during search and thus also depend on the search\nhistory. Various existing approaches use such dynamic heuristics in\n$\\mathrm{A}^*$-like algorithms and appeal to classic results for $\\mathrm{A}^*$\nto show optimality. However, doing so ignores the complexities of searching\nwith a mutable heuristic. In this paper we formalize the idea of dynamic\nheuristics and use them in a generic algorithm framework. We study a particular\ninstantiation that models $\\mathrm{A}^*$ with dynamic heuristics and show\ngeneral optimality results. Finally we show how existing approaches from\nclassical planning can be viewed as special cases of this instantiation, making\nit possible to directly apply our optimality results.",
      "tldr_zh": "这篇论文形式化了动态启发式(dynamic heuristics)，这些启发式不仅依赖于状态，还积累搜索历史信息，以解决传统 A* 算法中的复杂性问题。研究者提出一个通用算法框架，并研究其特定实例化，以模拟带有动态启发式的 A* 算法，并证明了其一般最优性(optimality results)。最后，论文展示了现有经典规划方法如何作为该框架的特例，从而使这些最优性结果直接适用于相关领域。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.21131v1",
      "published_date": "2025-04-29 19:25:31 UTC",
      "updated_date": "2025-04-29 19:25:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:43:41.225025"
    },
    {
      "arxiv_id": "2504.21099v1",
      "title": "A Survey on Parameter-Efficient Fine-Tuning for Foundation Models in Federated Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Jieming Bian",
        "Yuanzhe Peng",
        "Lei Wang",
        "Yin Huang",
        "Jie Xu"
      ],
      "abstract": "Foundation models have revolutionized artificial intelligence by providing\nrobust, versatile architectures pre-trained on large-scale datasets. However,\nadapting these massive models to specific downstream tasks requires\nfine-tuning, which can be prohibitively expensive in computational resources.\nParameter-Efficient Fine-Tuning (PEFT) methods address this challenge by\nselectively updating only a small subset of parameters. Meanwhile, Federated\nLearning (FL) enables collaborative model training across distributed clients\nwithout sharing raw data, making it ideal for privacy-sensitive applications.\nThis survey provides a comprehensive review of the integration of PEFT\ntechniques within federated learning environments. We systematically categorize\nexisting approaches into three main groups: Additive PEFT (which introduces new\ntrainable parameters), Selective PEFT (which fine-tunes only subsets of\nexisting parameters), and Reparameterized PEFT (which transforms model\narchitectures to enable efficient updates). For each category, we analyze how\nthese methods address the unique challenges of federated settings, including\ndata heterogeneity, communication efficiency, computational constraints, and\nprivacy concerns. We further organize the literature based on application\ndomains, covering both natural language processing and computer vision tasks.\nFinally, we discuss promising research directions, including scaling to larger\nfoundation models, theoretical analysis of federated PEFT methods, and\nsustainable approaches for resource-constrained environments.",
      "tldr_zh": "这篇调查论文探讨了在联邦学习(Federated Learning)中对基础模型(Foundation Models)进行参数高效微调(Parameter-Efficient Fine-Tuning, PEFT)的技术，以解决计算资源消耗高的问题。论文将 PEFT 方法分为三类：Additive PEFT（引入新参数）、Selective PEFT（微调现有参数子集）和 Reparameterized PEFT（转换模型架构以高效更新），并分析这些方法如何应对联邦学习中的挑战，如数据异质性、通信效率、计算约束和隐私问题。调查还按应用领域（如自然语言处理和计算机视觉）组织文献，并提出未来研究方向，包括扩展到更大模型的理论分析和可持续方法。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "survey paper, under updating",
      "pdf_url": "http://arxiv.org/pdf/2504.21099v1",
      "published_date": "2025-04-29 18:18:39 UTC",
      "updated_date": "2025-04-29 18:18:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:43:53.912005"
    },
    {
      "arxiv_id": "2505.07830v1",
      "title": "An Optimized Evacuation Plan for an Active-Shooter Situation Constrained by Network Capacity",
      "title_zh": "针对活跃射手事件的网络容量约束下的优化疏散计划",
      "authors": [
        "Joseph Lavalle-Rivera",
        "Aniirudh Ramesh",
        "Subhadeep Chakraborty"
      ],
      "abstract": "A total of more than 3400 public shootings have occurred in the United States\nbetween 2016 and 2022. Among these, 25.1% of them took place in an educational\ninstitution, 29.4% at the workplace including office buildings, 19.6% in retail\nstore locations, and 13.4% in restaurants and bars. During these critical\nscenarios, making the right decisions while evacuating can make the difference\nbetween life and death. However, emergency evacuation is intensely stressful,\nwhich along with the lack of verifiable real-time information may lead to fatal\nincorrect decisions. To tackle this problem, we developed a multi-route routing\noptimization algorithm that determines multiple optimal safe routes for each\nevacuee while accounting for available capacity along the route, thus reducing\nthe threat of crowding and bottlenecking. Overall, our algorithm reduces the\ntotal casualties by 34.16% and 53.3%, compared to our previous routing\nalgorithm without capacity constraints and an expert-advised routing strategy\nrespectively. Further, our approach to reduce crowding resulted in an\napproximate 50% reduction in occupancy in key bottlenecking nodes compared to\nboth of the other evacuation algorithms.",
      "tldr_zh": "该论文针对活跃射手事件下的紧急疏散问题，开发了一个考虑网络容量(multi-route routing optimization algorithm)的多路由优化算法，以为每个疏散者提供多个最优安全路线，从而减少拥挤和瓶颈风险。算法通过整合实时信息和容量约束，帮助避免因压力和信息缺失导致的错误决策。实验结果显示，与无容量约束的先前算法相比，该方法降低了总伤亡34.16%，与专家建议策略相比降低了53.3%；此外，它还使关键瓶颈节点的占用率减少约50%。这为高效的疏散规划提供了可行框架。",
      "categories": [
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.AI",
      "comment": "21 pages, 18 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.07830v1",
      "published_date": "2025-04-29 18:06:00 UTC",
      "updated_date": "2025-04-29 18:06:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:44:04.858059"
    },
    {
      "arxiv_id": "2504.20998v1",
      "title": "YoChameleon: Personalized Vision and Language Generation",
      "title_zh": "YoChameleon：个性化视觉和语言生成",
      "authors": [
        "Thao Nguyen",
        "Krishna Kumar Singh",
        "Jing Shi",
        "Trung Bui",
        "Yong Jae Lee",
        "Yuheng Li"
      ],
      "abstract": "Large Multimodal Models (e.g., GPT-4, Gemini, Chameleon) have evolved into\npowerful tools with millions of users. However, they remain generic models and\nlack personalized knowledge of specific user concepts. Previous work has\nexplored personalization for text generation, yet it remains unclear how these\nmethods can be adapted to new modalities, such as image generation. In this\npaper, we introduce Yo'Chameleon, the first attempt to study personalization\nfor large multimodal models. Given 3-5 images of a particular concept,\nYo'Chameleon leverages soft-prompt tuning to embed subject-specific information\nto (i) answer questions about the subject and (ii) recreate pixel-level details\nto produce images of the subject in new contexts. Yo'Chameleon is trained with\n(i) a self-prompting optimization mechanism to balance performance across\nmultiple modalities, and (ii) a ``soft-positive\" image generation approach to\nenhance image quality in a few-shot setting.",
      "tldr_zh": "本研究针对大型多模态模型（如 GPT-4 和 Gemini）的局限性，提出 Yo'Chameleon，这是首个针对视觉和语言生成进行个性化的框架。通过提供 3-5 张特定概念的图像，Yo'Chameleon 利用 soft-prompt tuning 嵌入主题信息，实现（i）回答相关问题和（ii）在新上下文中生成精确图像。训练过程结合自提示优化机制和“soft-positive”图像生成方法，以平衡多模态性能并提升 few-shot 设置下的图像质量，从而为个性化多模态模型提供新途径。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "CVPR 2025; Project page: https://thaoshibe.github.io/YoChameleon",
      "pdf_url": "http://arxiv.org/pdf/2504.20998v1",
      "published_date": "2025-04-29 17:59:57 UTC",
      "updated_date": "2025-04-29 17:59:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:44:16.752283"
    },
    {
      "arxiv_id": "2504.20997v1",
      "title": "Toward Efficient Exploration by Large Language Model Agents",
      "title_zh": "翻译失败",
      "authors": [
        "Dilip Arumugam",
        "Thomas L. Griffiths"
      ],
      "abstract": "A burgeoning area within reinforcement learning (RL) is the design of\nsequential decision-making agents centered around large language models (LLMs).\nWhile autonomous decision-making agents powered by modern LLMs could facilitate\nnumerous real-world applications, such successes demand agents that are capable\nof data-efficient RL. One key obstacle to achieving data efficiency in RL is\nexploration, a challenge that we demonstrate many recent proposals for LLM\nagent designs struggle to contend with. Meanwhile, classic algorithms from the\nRL literature known to gracefully address exploration require technical\nmachinery that can be challenging to operationalize in purely natural language\nsettings. In this work, rather than relying on finetuning or in-context\nlearning to coax LLMs into implicitly imitating a RL algorithm, we illustrate\nhow LLMs can be used to explicitly implement an existing RL algorithm\n(Posterior Sampling for Reinforcement Learning) whose capacity for\nstatistically-efficient exploration is already well-studied. We offer empirical\nresults demonstrating how our LLM-based implementation of a known,\ndata-efficient RL algorithm can be considerably more effective in natural\nlanguage tasks that demand prudent exploration.",
      "tldr_zh": "该研究探讨了如何让大型语言模型（LLMs）驱动的智能体在强化学习（RL）中实现高效探索，以解决现有设计在数据效率上的挑战。作者提出一种方法，使用LLMs显式实现后验采样强化学习（Posterior Sampling for Reinforcement Learning）算法，该算法已知在探索方面具有统计效率优势，而无需依赖微调或上下文学习。实验结果显示，这种方法在需要谨慎探索的自然语言任务中显著提高了智能体的表现，为LLMs在RL应用中的数据高效决策提供了新途径。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.20997v1",
      "published_date": "2025-04-29 17:59:48 UTC",
      "updated_date": "2025-04-29 17:59:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:44:28.816491"
    },
    {
      "arxiv_id": "2504.20988v1",
      "title": "Hubs and Spokes Learning: Efficient and Scalable Collaborative Machine Learning",
      "title_zh": "Hubs and Spokes Learning：高效且可扩展的协作机器学习",
      "authors": [
        "Atul Sharma",
        "Kavindu Herath",
        "Saurabh Bagchi",
        "Chaoyue Liu",
        "Somali Chaterji"
      ],
      "abstract": "We introduce the Hubs and Spokes Learning (HSL) framework, a novel paradigm\nfor collaborative machine learning that combines the strengths of Federated\nLearning (FL) and Decentralized Learning (P2PL). HSL employs a two-tier\ncommunication structure that avoids the single point of failure inherent in FL\nand outperforms the state-of-the-art P2PL framework, Epidemic Learning Local\n(ELL). At equal communication budgets (total edges), HSL achieves higher\nperformance than ELL, while at significantly lower communication budgets, it\ncan match ELL's performance. For instance, with only 400 edges, HSL reaches the\nsame test accuracy that ELL achieves with 1000 edges for 100 peers (spokes) on\nCIFAR-10, demonstrating its suitability for resource-constrained systems. HSL\nalso achieves stronger consensus among nodes after mixing, resulting in\nimproved performance with fewer training rounds. We substantiate these claims\nthrough rigorous theoretical analyses and extensive experimental results,\nshowcasing HSL's practicality for large-scale collaborative learning.",
      "tldr_zh": "本研究引入了 Hubs and Spokes Learning (HSL) 框架，这是一种高效且可扩展的协作机器学习范式，结合了 Federated Learning (FL) 和 Decentralized Learning (P2PL) 的优势，并采用两层通信结构来避免 FL 的单点故障，同时优于 P2PL 框架如 Epidemic Learning Local (ELL)。HSL 在相同通信预算下实现更高的性能，并在更低预算时匹配 ELL 的表现，例如在 CIFAR-10 数据集上，HSL 仅需 400 条边就达到 ELL 用 1000 条边的测试准确率，并通过更强的节点共识减少训练轮次。通过理论分析和广泛实验，HSL 证明了其在资源受限的大型协作学习场景中的实用性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DC"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.20988v1",
      "published_date": "2025-04-29 17:56:55 UTC",
      "updated_date": "2025-04-29 17:56:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:44:42.739955"
    },
    {
      "arxiv_id": "2504.20983v1",
      "title": "LTLf Adaptive Synthesis for Multi-Tier Goals in Nondeterministic Domains",
      "title_zh": "翻译失败",
      "authors": [
        "Giuseppe De Giacomo",
        "Gianmarco Parretti",
        "Shufang Zhu"
      ],
      "abstract": "We study a variant of LTLf synthesis that synthesizes adaptive strategies for\nachieving a multi-tier goal, consisting of multiple increasingly challenging\nLTLf objectives in nondeterministic planning domains. Adaptive strategies are\nstrategies that at any point of their execution (i) enforce the satisfaction of\nas many objectives as possible in the multi-tier goal, and (ii) exploit\npossible cooperation from the environment to satisfy as many as possible of the\nremaining ones. This happens dynamically: if the environment cooperates (ii)\nand an objective becomes enforceable (i), then our strategies will enforce it.\nWe provide a game-theoretic technique to compute adaptive strategies that is\nsound and complete. Notably, our technique is polynomial, in fact quadratic, in\nthe number of objectives. In other words, it handles multi-tier goals with only\na minor overhead compared to standard LTLf synthesis.",
      "tldr_zh": "该论文研究了 LTLf 合成的变体，旨在为非确定性规划域中的多层目标（multiple increasingly challenging LTLf objectives）合成适应性策略（adaptive strategies）。这些策略在执行过程中动态强制满足尽可能多的目标，并利用环境的合作来实现剩余目标，如果条件允许则实时调整。论文提出了一种基于游戏理论的技术来计算这些策略，该技术是健全且完整的，且在目标数量上计算复杂度为二次多项式，仅比标准 LTLf 合成有微小开销。总的来说，这为处理复杂多层目标的规划问题提供了高效解决方案。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.20983v1",
      "published_date": "2025-04-29 17:53:16 UTC",
      "updated_date": "2025-04-29 17:53:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:44:53.640820"
    },
    {
      "arxiv_id": "2504.21074v1",
      "title": "On the Potential of Large Language Models to Solve Semantics-Aware Process Mining Tasks",
      "title_zh": "关于大语言模型解决",
      "authors": [
        "Adrian Rebmann",
        "Fabian David Schmidt",
        "Goran Glavaš",
        "Han van der Aa"
      ],
      "abstract": "Large language models (LLMs) have shown to be valuable tools for tackling\nprocess mining tasks. Existing studies report on their capability to support\nvarious data-driven process analyses and even, to some extent, that they are\nable to reason about how processes work. This reasoning ability suggests that\nthere is potential for LLMs to tackle semantics-aware process mining tasks,\nwhich are tasks that rely on an understanding of the meaning of activities and\ntheir relationships. Examples of these include process discovery, where the\nmeaning of activities can indicate their dependency, whereas in anomaly\ndetection the meaning can be used to recognize process behavior that is\nabnormal. In this paper, we systematically explore the capabilities of LLMs for\nsuch tasks. Unlike prior work, which largely evaluates LLMs in their default\nstate, we investigate their utility through both in-context learning and\nsupervised fine-tuning. Concretely, we define five process mining tasks\nrequiring semantic understanding and provide extensive benchmarking datasets\nfor evaluation. Our experiments reveal that while LLMs struggle with\nchallenging process mining tasks when used out of the box or with minimal\nin-context examples, they achieve strong performance when fine-tuned for these\ntasks across a broad range of process types and industries.",
      "tldr_zh": "这篇论文探讨了 Large Language Models (LLMs) 在处理语义感知过程挖掘任务（如过程发现和异常检测）方面的潜力，这些任务需要理解活动含义及其关系。作者通过 in-context learning 和 supervised fine-tuning 方法进行评估，并定义了五个需要语义理解的过程挖掘任务，同时提供了广泛的基准数据集。实验结果表明，LLMs 在默认状态或仅使用少量 in-context 示例时表现较差，但经过 fine-tuning 后，在多种过程类型和行业中实现了强劲的性能。",
      "categories": [
        "cs.DB",
        "cs.AI"
      ],
      "primary_category": "cs.DB",
      "comment": "31 pages, submitted to PS",
      "pdf_url": "http://arxiv.org/pdf/2504.21074v1",
      "published_date": "2025-04-29 17:52:28 UTC",
      "updated_date": "2025-04-29 17:52:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:45:06.322172"
    },
    {
      "arxiv_id": "2504.20980v1",
      "title": "Jekyll-and-Hyde Tipping Point in an AI's Behavior",
      "title_zh": "翻译失败",
      "authors": [
        "Neil F. Johnson",
        "Frank Yingjie Huo"
      ],
      "abstract": "Trust in AI is undermined by the fact that there is no science that predicts\n-- or that can explain to the public -- when an LLM's output (e.g. ChatGPT) is\nlikely to tip mid-response to become wrong, misleading, irrelevant or\ndangerous. With deaths and trauma already being blamed on LLMs, this\nuncertainty is even pushing people to treat their 'pet' LLM more politely to\n'dissuade' it (or its future Artificial General Intelligence offspring) from\nsuddenly turning on them. Here we address this acute need by deriving from\nfirst principles an exact formula for when a Jekyll-and-Hyde tipping point\noccurs at LLMs' most basic level. Requiring only secondary school mathematics,\nit shows the cause to be the AI's attention spreading so thin it suddenly\nsnaps. This exact formula provides quantitative predictions for how the\ntipping-point can be delayed or prevented by changing the prompt and the AI's\ntraining. Tailored generalizations will provide policymakers and the public\nwith a firm platform for discussing any of AI's broader uses and risks, e.g. as\na personal counselor, medical advisor, decision-maker for when to use force in\na conflict situation. It also meets the need for clear and transparent answers\nto questions like ''should I be polite to my LLM?''",
      "tldr_zh": "该论文探讨了大型语言模型（LLM）输出中可能突然从正确转向错误、误导或危险的Jekyll-and-Hyde tipping point问题，这影响了公众对AI的信任。研究从第一原理推导出一个精确公式，解释该转折点源于AI注意力过度扩散导致的突然断裂，仅需中学数学即可理解。公式提供量化预测，帮助通过修改提示和训练来延迟或防止转折点，并为政策制定者及公众讨论AI风险（如是否对LLM礼貌）提供透明平台。",
      "categories": [
        "cs.AI",
        "cs.CY",
        "nlin.AO",
        "physics.comp-ph",
        "physics.soc-ph"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.20980v1",
      "published_date": "2025-04-29 17:50:29 UTC",
      "updated_date": "2025-04-29 17:50:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:45:18.164849"
    },
    {
      "arxiv_id": "2504.20970v1",
      "title": "SVD Based Least Squares for X-Ray Pneumonia Classification Using Deep Features",
      "title_zh": "翻译失败",
      "authors": [
        "Mete Erdogan",
        "Sebnem Demirtas"
      ],
      "abstract": "Accurate and early diagnosis of pneumonia through X-ray imaging is essential\nfor effective treatment and improved patient outcomes. Recent advancements in\nmachine learning have enabled automated diagnostic tools that assist\nradiologists in making more reliable and efficient decisions. In this work, we\npropose a Singular Value Decomposition-based Least Squares (SVD-LS) framework\nfor multi-class pneumonia classification, leveraging powerful feature\nrepresentations from state-of-the-art self-supervised and transfer learning\nmodels. Rather than relying on computationally expensive gradient based\nfine-tuning, we employ a closed-form, non-iterative classification approach\nthat ensures efficiency without compromising accuracy. Experimental results\ndemonstrate that SVD-LS achieves competitive performance while offering\nsignificantly reduced computational costs, making it a viable alternative for\nreal-time medical imaging applications.",
      "tldr_zh": "本研究提出了一种基于Singular Value Decomposition (SVD) 的Least Squares (SVD-LS) 框架，用于多类X-Ray 肺炎分类，旨在利用自监督和迁移学习模型的深度特征进行高效诊断。不同于计算密集的梯度-based 微调方法，该框架采用闭式形式、非迭代的分类策略，确保了准确性同时显著降低了计算成本。实验结果显示，SVD-LS 在性能上与现有方法竞争，并适用于实时医疗成像应用，从而提升了肺炎早期诊断的可靠性和效率。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Preprint submitted to IEEE International Workshop on Machine Learning\n  for Signal Processing (MLSP), 2025",
      "pdf_url": "http://arxiv.org/pdf/2504.20970v1",
      "published_date": "2025-04-29 17:39:16 UTC",
      "updated_date": "2025-04-29 17:39:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:45:29.544959"
    },
    {
      "arxiv_id": "2504.20964v1",
      "title": "OSVBench: Benchmarking LLMs on Specification Generation Tasks for Operating System Verification",
      "title_zh": "翻译失败",
      "authors": [
        "Shangyu Li",
        "Juyong Jiang",
        "Tiancheng Zhao",
        "Jiasi Shen"
      ],
      "abstract": "We introduce OSVBench, a new benchmark for evaluating Large Language Models\n(LLMs) in generating complete specification code pertaining to operating system\nkernel verification tasks. The benchmark first defines the specification\ngeneration problem into a program synthesis problem within a confined scope of\nsyntax and semantics by providing LLMs with the programming model. The LLMs are\nrequired to understand the provided verification assumption and the potential\nsyntax and semantics space to search for, then generate the complete\nspecification for the potentially buggy operating system code implementation\nunder the guidance of the high-level functional description of the operating\nsystem. This benchmark is built upon a real-world operating system kernel,\nHyperkernel, and consists of 245 complex specification generation tasks in\ntotal, each is a long context task of about 20k-30k tokens. Our comprehensive\nevaluation of 12 LLMs exhibits the limited performance of the current LLMs on\nthe specification generation tasks for operating system verification.\nSignificant disparities in their performance on the benchmark highlight\ndifferences in their ability to handle long-context code generation tasks. The\nevaluation toolkit and benchmark are available at\nhttps://github.com/lishangyu-hkust/OSVBench.",
      "tldr_zh": "本研究引入了OSVBench基准，用于评估LLMs在操作系统内核验证规范生成任务中的性能。该基准将规范生成问题转化为程序合成问题，提供编程模型和验证假设，引导LLMs理解语法语义空间并生成完整的规范代码。基于真实操作系统Hyperkernel，OSVBench包含245个复杂任务，每个任务涉及20k-30k tokens的长期上下文。对12个LLMs的全面评估显示，其性能有限，并暴露了在处理长上下文代码生成方面的显著能力差异。基准工具可在https://github.com/lishangyu-hkust/OSVBench获取。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.OS",
        "cs.PL",
        "cs.SE"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.20964v1",
      "published_date": "2025-04-29 17:34:49 UTC",
      "updated_date": "2025-04-29 17:34:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:45:41.786592"
    },
    {
      "arxiv_id": "2504.20946v2",
      "title": "Trace-of-Thought Prompting: Investigating Prompt-Based Knowledge Distillation Through Question Decomposition",
      "title_zh": "Trace-of-Thought Prompting：通过问题分解调查基于提示的知识蒸馏",
      "authors": [
        "Tyler McDonald",
        "Ali Emami"
      ],
      "abstract": "Knowledge distillation allows smaller neural networks to emulate the\nperformance of larger, teacher models with reduced computational demands.\nTraditional methods for Large Language Models (LLMs) often necessitate\nextensive fine-tuning, which limits their accessibility. To address this, we\nintroduce Trace-of-Thought Prompting, a novel framework designed to distill\ncritical reasoning capabilities from high-resource teacher models (over 8\nbillion parameters) to low-resource student models (up to 8 billion\nparameters). This approach leverages problem decomposition to enhance\ninterpretability and facilitate human-in-the-loop interventions. Empirical\nevaluations on the GSM8K and MATH datasets show that student models achieve\naccuracy gains of up to 113% on GSM8K and 21% on MATH, with significant\nimprovements particularly notable in smaller models like Llama 2 and Zephyr.\nOur results suggest a promising pathway for open-source, low-resource models to\neventually serve both as both students and teachers, potentially reducing our\nreliance on high-resource, proprietary models.",
      "tldr_zh": "本研究提出Trace-of-Thought Prompting框架，通过Question Decomposition实现基于提示的Knowledge Distillation，将关键推理能力从高资源教师模型（超过8亿参数）转移到低资源学生模型（最多8亿参数），从而避免传统方法的广泛fine-tuning需求。 该框架利用问题分解提升模型的可解释性和支持人类干预，在GSM8K和MATH数据集上的实证评估显示，学生模型准确率在GSM8K上提高高达113%，在MATH上提高21%，尤其在较小模型如Llama 2和Zephyr上表现显著。 总体结果为开源、低资源模型提供了一个可持续路径，使其能兼任学生和教师角色，减少对高资源专有模型的依赖。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.20946v2",
      "published_date": "2025-04-29 17:14:54 UTC",
      "updated_date": "2025-04-30 20:44:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:45:54.538391"
    },
    {
      "arxiv_id": "2505.01445v1",
      "title": "Explainable AI for Correct Root Cause Analysis of Product Quality in Injection Moulding",
      "title_zh": "翻译失败",
      "authors": [
        "Muhammad Muaz",
        "Sameed Sajid",
        "Tobias Schulze",
        "Chang Liu",
        "Nils Klasen",
        "Benny Drescher"
      ],
      "abstract": "If a product deviates from its desired properties in the injection moulding\nprocess, its root cause analysis can be aided by models that relate the input\nmachine settings with the output quality characteristics. The machine learning\nmodels tested in the quality prediction are mostly black boxes; therefore, no\ndirect explanation of their prognosis is given, which restricts their\napplicability in the quality control. The previously attempted explainability\nmethods are either restricted to tree-based algorithms only or do not emphasize\non the fact that some explainability methods can lead to wrong root cause\nidentification of a product's deviation from its desired properties. This study\nfirst shows that the interactions among the multiple input machine settings do\nexist in real experimental data collected as per a central composite design.\nThen, the model-agnostic explainable AI methods are compared for the first time\nto show that different explainability methods indeed lead to different feature\nimpact analysis in injection moulding. Moreover, it is shown that the better\nfeature attribution translates to the correct cause identification and\nactionable insights for the injection moulding process. Being model agnostic,\nexplanations on both random forest and multilayer perceptron are performed for\nthe cause analysis, as both models have the mean absolute percentage error of\nless than 0.05% on the experimental dataset.",
      "tldr_zh": "本研究针对注塑成型（Injection Moulding）过程中产品质量偏差的根因分析（Root Cause Analysis），探讨了Explainable AI的应用，以解决传统黑箱机器学习模型的解释性不足问题。研究首先通过中心复合设计（Central Composite Design）收集的实验数据，证明了多个输入机器设置之间存在交互作用。然后，比较了模型无关的可解释AI方法（Model-Agnostic Explainable AI Methods），发现不同方法会导致不同的特征影响分析，并证明更好的特征归因（Feature Attribution）能准确识别根因并提供可操作的见解。在随机森林（Random Forest）和多层感知器（Multilayer Perceptron）模型上进行解释，这些模型在实验数据集上的均方百分比误差（Mean Absolute Percentage Error）均小于0.05%，从而提升了注塑成型质量控制的可解释性和实用性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.01445v1",
      "published_date": "2025-04-29 16:58:01 UTC",
      "updated_date": "2025-04-29 16:58:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:46:06.932026"
    },
    {
      "arxiv_id": "2504.20930v2",
      "title": "ChestX-Reasoner: Advancing Radiology Foundation Models with Reasoning through Step-by-Step Verification",
      "title_zh": "翻译失败",
      "authors": [
        "Ziqing Fan",
        "Cheng Liang",
        "Chaoyi Wu",
        "Ya Zhang",
        "Yanfeng Wang",
        "Weidi Xie"
      ],
      "abstract": "Recent advances in reasoning-enhanced large language models (LLMs) and\nmultimodal LLMs (MLLMs) have significantly improved performance in complex\ntasks, yet medical AI models often overlook the structured reasoning processes\ninherent in clinical practice. In this work, we present ChestX-Reasoner, a\nradiology diagnosis MLLM designed to leverage process supervision mined\ndirectly from clinical reports, reflecting the step-by-step reasoning followed\nby radiologists. We construct a large dataset by extracting and refining\nreasoning chains from routine radiology reports. Our two-stage training\nframework combines supervised fine-tuning and reinforcement learning guided by\nprocess rewards to better align model reasoning with clinical standards. We\nintroduce RadRBench-CXR, a comprehensive benchmark featuring 59K visual\nquestion answering samples with 301K clinically validated reasoning steps, and\npropose RadRScore, a metric evaluating reasoning factuality, completeness, and\neffectiveness. ChestX-Reasoner outperforms existing medical and general-domain\nMLLMs in both diagnostic accuracy and reasoning ability, achieving 16%, 5.9%,\nand 18% improvements in reasoning ability compared to the best medical MLLM,\nthe best general MLLM, and its base model, respectively, as well as 3.3%, 24%,\nand 27% improvements in outcome accuracy. All resources are open-sourced to\nfacilitate further research in medical reasoning MLLMs.",
      "tldr_zh": "该研究提出ChestX-Reasoner，一种放射学诊断的多模态LLM (MLLM)，通过从临床报告中提取的逐步推理过程监督来提升医疗AI的结构化推理能力。研究构建了一个大型数据集，并采用两阶段训练框架，包括supervised fine-tuning和基于过程奖励的reinforcement learning，以更好地符合临床标准。同时，引入RadRBench-CXR基准（包含59K视觉问答样本和301K推理步骤）及RadRScore指标来评估推理的真实性、完整性和有效性。实验结果显示，ChestX-Reasoner在诊断准确性和推理能力上显著超越现有模型，实现与最佳医疗MLLM相比推理能力提高16%、与最佳通用MLLM相比提高5.9%，并开源所有资源以推动医疗推理MLLM的研究。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.CV"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.20930v2",
      "published_date": "2025-04-29 16:48:23 UTC",
      "updated_date": "2025-05-21 08:50:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:46:19.980155"
    },
    {
      "arxiv_id": "2504.20924v3",
      "title": "A Domain-Agnostic Scalable AI Safety Ensuring Framework",
      "title_zh": "一个领域无关的可扩展 AI 安全确保框架",
      "authors": [
        "Beomjun Kim",
        "Kangyeon Kim",
        "Sunwoo Kim",
        "Heejin Ahn"
      ],
      "abstract": "Ensuring the safety of AI systems has emerged as a critical priority as these\nsystems are increasingly deployed in real-world applications. We propose a\nnovel domain-agnostic framework that guarantees AI systems satisfy user-defined\nsafety constraints with specified probabilities. Our approach combines any AI\nmodel with an optimization problem that ensures outputs meet safety\nrequirements while maintaining performance. The key challenge is handling\nuncertain constraints -- those whose satisfaction cannot be deterministically\nevaluated~(e.g., whether a chatbot response is ``harmful''). We address this\nthrough three innovations: (1) a safety classification model that assesses\nconstraint satisfaction probability, (2) internal test data to evaluate this\nclassifier's reliability, and (3) conservative testing to prevent overfitting\nwhen this data is used in training. We prove our method guarantees\nprobabilistic safety under mild conditions and establish the first scaling law\nin AI safety -- showing that the safety-performance trade-off improves\npredictably with more internal test data. Experiments across production\nplanning, reinforcement learning, and language generation demonstrate our\nframework achieves up to 140 times better safety than existing methods at the\nsame performance levels. This work enables AI systems to achieve both rigorous\nsafety guarantees and high performance across diverse domains.",
      "tldr_zh": "本研究提出一个领域无关的（domain-agnostic）可扩展 AI 安全确保框架，用于保证 AI 系统以指定概率满足用户定义的安全约束，同时保持系统性能。该框架将任意 AI 模型与优化问题相结合，通过三个创新点处理不确定约束：安全分类模型评估约束满足概率、内部测试数据评估分类器可靠性，以及保守测试防止过拟合。研究证明了该方法在温和条件下实现概率安全，并首次建立了 AI 安全领域的缩放定律（scaling law），显示安全-性能权衡随内部测试数据增加而改善。在生产规划、强化学习（reinforcement learning）和语言生成等领域的实验中，该框架在相同性能水平下比现有方法提高高达 140 倍的安全性，从而使 AI 系统在多样领域实现严格安全保证和高性能。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Theoretical supplementary material (Part 1) is available in submitted\n  files. Experimental supplementary material (Part 2) will be available before\n  May 22 23:59PM AOE This paper is still in progress. Some experiments are\n  still ongoing and acknowledgements will be added soon",
      "pdf_url": "http://arxiv.org/pdf/2504.20924v3",
      "published_date": "2025-04-29 16:38:35 UTC",
      "updated_date": "2025-05-17 04:28:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:46:31.351448"
    },
    {
      "arxiv_id": "2504.20922v1",
      "title": "DYNAMAX: Dynamic computing for Transformers and Mamba based architectures",
      "title_zh": "翻译失败",
      "authors": [
        "Miguel Nogales",
        "Matteo Gambella",
        "Manuel Roveri"
      ],
      "abstract": "Early exits (EEs) offer a promising approach to reducing computational costs\nand latency by dynamically terminating inference once a satisfactory prediction\nconfidence on a data sample is achieved. Although many works integrate EEs into\nencoder-only Transformers, their application to decoder-only architectures and,\nmore importantly, Mamba models, a novel family of state-space architectures in\nthe LLM realm, remains insufficiently explored. This work introduces DYNAMAX,\nthe first framework to exploit the unique properties of Mamba architectures for\nearly exit mechanisms. We not only integrate EEs into Mamba but also repurpose\nMamba as an efficient EE classifier for both Mamba-based and transformer-based\nLLMs, showcasing its versatility. Our experiments employ the Mistral 7B\ntransformer compared to the Codestral 7B Mamba model, using data sets such as\nTruthfulQA, CoQA, and TriviaQA to evaluate computational savings, accuracy, and\nconsistency. The results highlight the adaptability of Mamba as a powerful EE\nclassifier and its efficiency in balancing computational cost and performance\nquality across NLP tasks. By leveraging Mamba's inherent design for dynamic\nprocessing, we open pathways for scalable and efficient inference in embedded\napplications and resource-constrained environments. This study underscores the\ntransformative potential of Mamba in redefining dynamic computing paradigms for\nLLMs.",
      "tldr_zh": "该研究引入了DYNAMAX框架，利用早退出(Early Exits, EEs)机制来优化Transformer和Mamba-based架构的动态计算，通过在达到满意预测置信度时终止推理，从而降低计算成本和延迟。DYNAMAX首次将EEs整合到Mamba模型中，并将Mamba重新设计为高效的EE分类器，适用于Mamba-based和Transformer-based大型语言模型(LLMs)。实验使用Mistral 7B和Codestral 7B模型，在TruthfulQA、CoQA和TriviaQA数据集上评估，结果显示Mamba作为EE分类器表现出色，能平衡计算效率与性能质量，为资源受限环境中的可扩展推理提供新路径。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG",
        "68T50 (Primary), 68T07 (Secondary)"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to IJCNN 2025",
      "pdf_url": "http://arxiv.org/pdf/2504.20922v1",
      "published_date": "2025-04-29 16:38:15 UTC",
      "updated_date": "2025-04-29 16:38:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:46:43.813357"
    },
    {
      "arxiv_id": "2504.20921v1",
      "title": "Leveraging Generative AI Through Prompt Engineering and Rigorous Validation to Create Comprehensive Synthetic Datasets for AI Training in Healthcare",
      "title_zh": "翻译失败",
      "authors": [
        "Polycarp Nalela"
      ],
      "abstract": "Access to high-quality medical data is often restricted due to privacy\nconcerns, posing significant challenges for training artificial intelligence\n(AI) algorithms within Electronic Health Record (EHR) applications. In this\nstudy, prompt engineering with the GPT-4 API was employed to generate\nhigh-quality synthetic datasets aimed at overcoming this limitation. The\ngenerated data encompassed a comprehensive array of patient admission\ninformation, including healthcare provider details, hospital departments,\nwards, bed assignments, patient demographics, emergency contacts, vital signs,\nimmunizations, allergies, medical histories, appointments, hospital visits,\nlaboratory tests, diagnoses, treatment plans, medications, clinical notes,\nvisit logs, discharge summaries, and referrals. To ensure data quality and\nintegrity, advanced validation techniques were implemented utilizing models\nsuch as BERT's Next Sentence Prediction for sentence coherence, GPT-2 for\noverall plausibility, RoBERTa for logical consistency, autoencoders for anomaly\ndetection, and conducted diversity analysis. Synthetic data that met all\nvalidation criteria were integrated into a comprehensive PostgreSQL database,\nserving as the data management system for the EHR application. This approach\ndemonstrates that leveraging generative AI models with rigorous validation can\neffectively produce high-quality synthetic medical data, facilitating the\ntraining of AI algorithms while addressing privacy concerns associated with\nreal patient data.",
      "tldr_zh": "本文研究了如何通过提示工程（Prompt Engineering）和严格验证，利用生成式AI（Generative AI）生成高质量合成医疗数据集，以解决医疗数据隐私问题限制AI训练的挑战。研究使用GPT-4 API创建涵盖患者入院信息、医疗历史、诊断和治疗计划等全面数据的合成数据集，并通过BERT的Next Sentence Prediction、GPT-2、RoBERTa和autoencoders等模型进行句子连贯性、逻辑一致性和异常检测验证。最终，合格数据整合到PostgreSQL数据库中，用于EHR应用，支持AI算法训练，同时有效保护患者隐私。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.20921v1",
      "published_date": "2025-04-29 16:37:34 UTC",
      "updated_date": "2025-04-29 16:37:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:46:54.545208"
    },
    {
      "arxiv_id": "2504.20910v1",
      "title": "When Testing AI Tests Us: Safeguarding Mental Health on the Digital Frontlines",
      "title_zh": "当测试 AI 测试我们：保护数字前线的心理健康",
      "authors": [
        "Sachin R. Pendse",
        "Darren Gergle",
        "Rachel Kornfield",
        "Jonah Meyerhoff",
        "David Mohr",
        "Jina Suh",
        "Annie Wescott",
        "Casey Williams",
        "Jessica Schleider"
      ],
      "abstract": "Red-teaming is a core part of the infrastructure that ensures that AI models\ndo not produce harmful content. Unlike past technologies, the black box nature\nof generative AI systems necessitates a uniquely interactional mode of testing,\none in which individuals on red teams actively interact with the system,\nleveraging natural language to simulate malicious actors and solicit harmful\noutputs. This interactional labor done by red teams can result in mental health\nharms that are uniquely tied to the adversarial engagement strategies necessary\nto effectively red team. The importance of ensuring that generative AI models\ndo not propagate societal or individual harm is widely recognized -- one less\nvisible foundation of end-to-end AI safety is also the protection of the mental\nhealth and wellbeing of those who work to keep model outputs safe. In this\npaper, we argue that the unmet mental health needs of AI red-teamers is a\ncritical workplace safety concern. Through analyzing the unique mental health\nimpacts associated with the labor done by red teams, we propose potential\nindividual and organizational strategies that could be used to meet these\nneeds, and safeguard the mental health of red-teamers. We develop our proposed\nstrategies through drawing parallels between common red-teaming practices and\ninteractional labor common to other professions (including actors, mental\nhealth professionals, conflict photographers, and content moderators),\ndescribing how individuals and organizations within these professional spaces\nsafeguard their mental health given similar psychological demands. Drawing on\nthese protective practices, we describe how safeguards could be adapted for the\ndistinct mental health challenges experienced by red teaming organizations as\nthey mitigate emerging technological risks on the new digital frontlines.",
      "tldr_zh": "这篇论文探讨了AI红-teaming（红队测试）在确保AI模型不产生有害内容方面的重要性，但强调了这种互动式测试对测试人员心理健康的潜在危害。作者分析了红队成员通过模拟恶意行为进行自然语言互动所带来的独特精神健康风险，并将其与演员、心理健康专业人士、冲突摄影师和内容审核员等职业的类似挑战进行比较。论文提出了一系列个人和组织策略，如心理支持机制和风险管理措施，以保护红队成员的心理健康，并帮助相关组织适应这些策略，从而在数字前沿有效缓解AI安全测试中的新兴风险。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.CY",
      "comment": "Accepted to ACM Conference on Fairness, Accountability, and\n  Transparency (FAccT 2025)",
      "pdf_url": "http://arxiv.org/pdf/2504.20910v1",
      "published_date": "2025-04-29 16:27:20 UTC",
      "updated_date": "2025-04-29 16:27:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:47:06.087197"
    },
    {
      "arxiv_id": "2504.20903v2",
      "title": "Modeling AI-Human Collaboration as a Multi-Agent Adaptation",
      "title_zh": "将 AI-人类协作建模为多智能体适应",
      "authors": [
        "Prothit Sen",
        "Sai Mihir Jakkaraju"
      ],
      "abstract": "We develop an agent-based simulation to formalize AI-human collaboration as a\nfunction of task structure, advancing a generalizable framework for strategic\ndecision-making in organizations. Distinguishing between heuristic-based human\nadaptation and rule-based AI search, we model interactions across modular\n(parallel) and sequenced (interdependent) tasks using an NK model. Our results\nreveal that in modular tasks, AI often substitutes for humans - delivering\nhigher payoffs unless human expertise is very high, and the AI search space is\neither narrowly focused or extremely broad. In sequenced tasks, interesting\ncomplementarities emerge. When an expert human initiates the search and AI\nsubsequently refines it, aggregate performance is maximized. Conversely, when\nAI leads, excessive heuristic refinement by the human can reduce payoffs. We\nalso show that even \"hallucinatory\" AI - lacking memory or structure - can\nimprove outcomes when augmenting low-capability humans by helping escape local\noptima. These results yield a robust implication: the effectiveness of AI-human\ncollaboration depends less on context or industry, and more on the underlying\ntask structure. By elevating task decomposition as the central unit of\nanalysis, our model provides a transferable lens for strategic decision-making\ninvolving humans and an agentic AI across diverse organizational settings.",
      "tldr_zh": "这篇论文使用代理-based simulation 和 NK model 形式化 AI-人类协作，基于任务结构分析战略决策。研究区分了基于启发式的人类适应和基于规则的 AI 搜索，在模块化（平行）任务中发现 AI 通常替代人类以获得更高收益，除非人类专业知识极高或 AI 搜索空间狭窄/极广。在序列化（相互依赖）任务中，专家人类先启动搜索再由 AI 精炼可最大化性能，而 AI 领导时人类过度 heuristic refinement 可能降低收益。该研究还表明，即使是“hallucinatory” AI（缺乏记忆或结构），也能帮助低能力人类逃离局部最优，从而改善整体结果。最终，论文强调 AI-人类协作的有效性主要取决于任务结构，而非具体上下文或行业，提供了一个可转移的战略决策框架。",
      "categories": [
        "cs.MA",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.MA",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.20903v2",
      "published_date": "2025-04-29 16:19:53 UTC",
      "updated_date": "2025-05-05 04:26:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:47:20.293529"
    },
    {
      "arxiv_id": "2504.20902v1",
      "title": "Classifier-to-Bias: Toward Unsupervised Automatic Bias Detection for Visual Classifiers",
      "title_zh": "翻译失败",
      "authors": [
        "Quentin Guimard",
        "Moreno D'Incà",
        "Massimiliano Mancini",
        "Elisa Ricci"
      ],
      "abstract": "A person downloading a pre-trained model from the web should be aware of its\nbiases. Existing approaches for bias identification rely on datasets containing\nlabels for the task of interest, something that a non-expert may not have\naccess to, or may not have the necessary resources to collect: this greatly\nlimits the number of tasks where model biases can be identified. In this work,\nwe present Classifier-to-Bias (C2B), the first bias discovery framework that\nworks without access to any labeled data: it only relies on a textual\ndescription of the classification task to identify biases in the target\nclassification model. This description is fed to a large language model to\ngenerate bias proposals and corresponding captions depicting biases together\nwith task-specific target labels. A retrieval model collects images for those\ncaptions, which are then used to assess the accuracy of the model w.r.t. the\ngiven biases. C2B is training-free, does not require any annotations, has no\nconstraints on the list of biases, and can be applied to any pre-trained model\non any classification task. Experiments on two publicly available datasets show\nthat C2B discovers biases beyond those of the original datasets and outperforms\na recent state-of-the-art bias detection baseline that relies on task-specific\nannotations, being a promising first step toward addressing task-agnostic\nunsupervised bias detection.",
      "tldr_zh": "本文提出 Classifier-to-Bias (C2B)，一个无需标签数据的无监督框架，用于自动检测视觉分类器的偏见，仅依赖于任务的文本描述。C2B 通过大型语言模型 (LLM) 生成偏见提案和相关标题，再利用检索模型收集图像来评估模型对这些偏见的准确性，该方法训练-free、不需注解，且适用于任何预训练模型和分类任务。实验在两个公开数据集上显示，C2B 发现了超出原始数据集的偏见，并优于基于任务特定注解的最新基准方法，为任务无关的无监督偏见检测提供了重要进展。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "CVPR 2025. Code: https://github.com/mardgui/C2B",
      "pdf_url": "http://arxiv.org/pdf/2504.20902v1",
      "published_date": "2025-04-29 16:19:38 UTC",
      "updated_date": "2025-04-29 16:19:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:47:32.230284"
    },
    {
      "arxiv_id": "2504.20898v2",
      "title": "CBM-RAG: Demonstrating Enhanced Interpretability in Radiology Report Generation with Multi-Agent RAG and Concept Bottleneck Models",
      "title_zh": "翻译失败",
      "authors": [
        "Hasan Md Tusfiqur Alam",
        "Devansh Srivastav",
        "Abdulrahman Mohamed Selim",
        "Md Abdul Kadir",
        "Md Moktadirul Hoque Shuvo",
        "Daniel Sonntag"
      ],
      "abstract": "Advancements in generative Artificial Intelligence (AI) hold great promise\nfor automating radiology workflows, yet challenges in interpretability and\nreliability hinder clinical adoption. This paper presents an automated\nradiology report generation framework that combines Concept Bottleneck Models\n(CBMs) with a Multi-Agent Retrieval-Augmented Generation (RAG) system to bridge\nAI performance with clinical explainability. CBMs map chest X-ray features to\nhuman-understandable clinical concepts, enabling transparent disease\nclassification. Meanwhile, the RAG system integrates multi-agent collaboration\nand external knowledge to produce contextually rich, evidence-based reports.\nOur demonstration showcases the system's ability to deliver interpretable\npredictions, mitigate hallucinations, and generate high-quality, tailored\nreports with an interactive interface addressing accuracy, trust, and usability\nchallenges. This framework provides a pathway to improving diagnostic\nconsistency and empowering radiologists with actionable insights.",
      "tldr_zh": "该研究提出CBM-RAG框架，将Concept Bottleneck Models (CBMs)与Multi-Agent Retrieval-Augmented Generation (RAG)系统结合，用于自动化放射学报告生成，以提升AI的可解释性和可靠性。CBMs通过将胸部X光特征映射到人类可理解的临床概念，实现透明的疾病分类，而Multi-Agent RAG则利用多智能体协作和外部知识生成上下文丰富的报告。实验演示显示，该框架能减少幻觉，提供可解释预测，并通过交互界面提高报告的准确性、信任度和可用性，最终改善诊断一致性和为放射科医生提供可操作洞见。",
      "categories": [
        "cs.AI",
        "cs.CV",
        "cs.IR"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted in the 17th ACM SIGCHI Symposium on Engineering Interactive\n  Computing Systems (EICS 2025)",
      "pdf_url": "http://arxiv.org/pdf/2504.20898v2",
      "published_date": "2025-04-29 16:14:55 UTC",
      "updated_date": "2025-05-04 22:38:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:47:43.913982"
    },
    {
      "arxiv_id": "2504.21072v1",
      "title": "Erased but Not Forgotten: How Backdoors Compromise Concept Erasure",
      "title_zh": "被擦除但未被遗忘：后门如何破坏概念擦",
      "authors": [
        "Jonas Henry Grebe",
        "Tobias Braun",
        "Marcus Rohrbach",
        "Anna Rohrbach"
      ],
      "abstract": "The expansion of large-scale text-to-image diffusion models has raised\ngrowing concerns about their potential to generate undesirable or harmful\ncontent, ranging from fabricated depictions of public figures to sexually\nexplicit images. To mitigate these risks, prior work has devised machine\nunlearning techniques that attempt to erase unwanted concepts through\nfine-tuning. However, in this paper, we introduce a new threat model, Toxic\nErasure (ToxE), and demonstrate how recent unlearning algorithms, including\nthose explicitly designed for robustness, can be circumvented through targeted\nbackdoor attacks. The threat is realized by establishing a link between a\ntrigger and the undesired content. Subsequent unlearning attempts fail to erase\nthis link, allowing adversaries to produce harmful content. We instantiate ToxE\nvia two established backdoor attacks: one targeting the text encoder and\nanother manipulating the cross-attention layers. Further, we introduce Deep\nIntervention Score-based Attack (DISA), a novel, deeper backdoor attack that\noptimizes the entire U-Net using a score-based objective, improving the\nattack's persistence across different erasure methods. We evaluate five recent\nconcept erasure methods against our threat model. For celebrity identity\nerasure, our deep attack circumvents erasure with up to 82% success, averaging\n57% across all erasure methods. For explicit content erasure, ToxE attacks can\nelicit up to 9 times more exposed body parts, with DISA yielding an average\nincrease by a factor of 2.9. These results highlight a critical security gap in\ncurrent unlearning strategies.",
      "tldr_zh": "这篇论文引入了新的威胁模型Toxic Erasure (ToxE)，展示了后门攻击（backdoor attacks）如何破坏文本到图像扩散模型中的概念擦除（concept erasure）技术，导致有害内容无法完全消除。研究者通过两种后门攻击——针对文本编码器和跨注意力层——以及一个新方法Deep Intervention Score-based Attack (DISA)，优化整个U-Net以提高攻击的持久性。实验结果表明，DISA在对抗五种擦除方法时，对名人身份擦除的成功率平均达57%、最高82%，并能使显式内容暴露身体部位增加多达9倍，从而突显了当前机器无学习策略的安全漏洞。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.21072v1",
      "published_date": "2025-04-29 16:13:06 UTC",
      "updated_date": "2025-04-29 16:13:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:47:58.434039"
    },
    {
      "arxiv_id": "2504.20887v1",
      "title": "Return Capping: Sample-Efficient CVaR Policy Gradient Optimisation",
      "title_zh": "回报上限：样本高效的 CVaR 策略梯度优化",
      "authors": [
        "Harry Mead",
        "Clarissa Costen",
        "Bruno Lacerda",
        "Nick Hawes"
      ],
      "abstract": "When optimising for conditional value at risk (CVaR) using policy gradients\n(PG), current methods rely on discarding a large proportion of trajectories,\nresulting in poor sample efficiency. We propose a reformulation of the CVaR\noptimisation problem by capping the total return of trajectories used in\ntraining, rather than simply discarding them, and show that this is equivalent\nto the original problem if the cap is set appropriately. We show, with\nempirical results in an number of environments, that this reformulation of the\nproblem results in consistently improved performance compared to baselines.",
      "tldr_zh": "论文提出了一种名为 Return Capping 的方法，以提升条件价值在风险 (CVaR) 的策略梯度 (PG) 优化效率，该方法通过对轨迹的总回报设置上限，而不是简单丢弃轨迹，从而改善样本效率。研究证明，如果上限设置合适，这种改革等价于原优化问题。实验结果显示，在多个环境中，Return Capping 方法比基线模型表现出一致的性能提升。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.20887v1",
      "published_date": "2025-04-29 16:04:16 UTC",
      "updated_date": "2025-04-29 16:04:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:48:08.460936"
    },
    {
      "arxiv_id": "2505.07829v1",
      "title": "Blockbuster, Part 1: Block-level AI Operator Fusion",
      "title_zh": "翻译失败",
      "authors": [
        "Ofer Dekel"
      ],
      "abstract": "Blockbuster is a framework for AI operator fusion in inference programs. The\nBlockbuster framework is compatible with any multiprocessor architecture that\nhas a tiered memory hierarchy, including GPUs, multi-core CPUs, and some AI\naccelerator chips. It includes a graph-based representation for AI workloads,\ncalled a block program, which explicitly models how blocks of data move between\nthe memory tiers. It also includes an operator fusion procedure, which is made\nup of a candidate selection algorithm and a fusion algorithm that fuses each\nindividual candidate - this two-algorithm structure makes Blockbuster\nespecially suitable for large AI programs. The current paper focuses on the\nfusion algorithm, which is a rule-based technique. While the literature is full\nof previous rule-based fusion algorithms, what sets our algorithm apart is its\ndirect modeling of data movement between memory tiers, resulting in uniquely\npowerful fusion results. As a first sanity check, we demonstrate how our\nalgorithm automatically rediscovers the well-known Flash Attention kernel.\nThen, we demonstrate the real power of our approach by fusing LayerNorm with\nmatrix multiplication and RMSNorm with FNN-SwiGLU - the latter involves fusing\nthree matrix multiplications, a Hadamard product, a reduction, and a few\nelementwise operations into a single mega-kernel.",
      "tldr_zh": "该论文介绍了 Blockbuster 框架的第1部分，专注于 AI operator fusion，用于优化推理程序中的运算符融合，支持多处理器架构如 GPU、多核 CPU 和 AI 加速器。框架采用基于图的 block program 表示来显式建模数据块在内存层级间的移动，并通过候选选择算法和规则-based 融合算法进行运算符融合，这种方法直接处理数据移动，实现更高效的融合结果。实验展示了该算法能自动重现 Flash Attention kernel，并成功融合 LayerNorm 与 matrix multiplication，以及 RMSNorm 与 FNN-SwiGLU，形成单一 mega-kernel，从而提升 AI 工作负载的性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.07829v1",
      "published_date": "2025-04-29 15:49:33 UTC",
      "updated_date": "2025-04-29 15:49:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:48:20.144168"
    },
    {
      "arxiv_id": "2504.20879v2",
      "title": "The Leaderboard Illusion",
      "title_zh": "排行榜的幻觉",
      "authors": [
        "Shivalika Singh",
        "Yiyang Nan",
        "Alex Wang",
        "Daniel D'Souza",
        "Sayash Kapoor",
        "Ahmet Üstün",
        "Sanmi Koyejo",
        "Yuntian Deng",
        "Shayne Longpre",
        "Noah A. Smith",
        "Beyza Ermis",
        "Marzieh Fadaee",
        "Sara Hooker"
      ],
      "abstract": "Measuring progress is fundamental to the advancement of any scientific field.\nAs benchmarks play an increasingly central role, they also grow more\nsusceptible to distortion. Chatbot Arena has emerged as the go-to leaderboard\nfor ranking the most capable AI systems. Yet, in this work we identify\nsystematic issues that have resulted in a distorted playing field. We find that\nundisclosed private testing practices benefit a handful of providers who are\nable to test multiple variants before public release and retract scores if\ndesired. We establish that the ability of these providers to choose the best\nscore leads to biased Arena scores due to selective disclosure of performance\nresults. At an extreme, we identify 27 private LLM variants tested by Meta in\nthe lead-up to the Llama-4 release. We also establish that proprietary closed\nmodels are sampled at higher rates (number of battles) and have fewer models\nremoved from the arena than open-weight and open-source alternatives. Both\nthese policies lead to large data access asymmetries over time. Providers like\nGoogle and OpenAI have received an estimated 19.2% and 20.4% of all data on the\narena, respectively. In contrast, a combined 83 open-weight models have only\nreceived an estimated 29.7% of the total data. We show that access to Chatbot\nArena data yields substantial benefits; even limited additional data can result\nin relative performance gains of up to 112% on the arena distribution, based on\nour conservative estimates. Together, these dynamics result in overfitting to\nArena-specific dynamics rather than general model quality. The Arena builds on\nthe substantial efforts of both the organizers and an open community that\nmaintains this valuable evaluation platform. We offer actionable\nrecommendations to reform the Chatbot Arena's evaluation framework and promote\nfairer, more transparent benchmarking for the field",
      "tldr_zh": "该研究揭示了Chatbot Arena作为AI系统排名的基准存在系统性问题，导致排行榜失真，包括私有测试的 selective disclosure和数据访问不对称。作者发现，某些提供者如Meta能测试多个LLM变体并选择最佳分数，而Google和OpenAI等私有模型获得远多于开源模型的测试数据（分别约19.2%和20.4%的总数据，对开源模型仅29.7%）。这些动态导致模型过度拟合Arena特定分布而非整体性能，并证明额外数据可带来高达112%的相对性能提升；论文提供了可操作推荐，以改革评估框架，促进更公平透明的基准测试。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG",
        "stat.ME"
      ],
      "primary_category": "cs.AI",
      "comment": "68 pages, 18 figures, 9 tables",
      "pdf_url": "http://arxiv.org/pdf/2504.20879v2",
      "published_date": "2025-04-29 15:48:49 UTC",
      "updated_date": "2025-05-12 16:33:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:48:31.689407"
    },
    {
      "arxiv_id": "2504.20869v2",
      "title": "Quantifying the Noise of Structural Perturbations on Graph Adversarial Attacks",
      "title_zh": "量化结构扰动在图对抗攻击中的噪声",
      "authors": [
        "Junyuan Fang",
        "Han Yang",
        "Haixian Wen",
        "Jiajing Wu",
        "Zibin Zheng",
        "Chi K. Tse"
      ],
      "abstract": "Graph neural networks have been widely utilized to solve graph-related tasks\nbecause of their strong learning power in utilizing the local information of\nneighbors. However, recent studies on graph adversarial attacks have proven\nthat current graph neural networks are not robust against malicious attacks.\nYet much of the existing work has focused on the optimization objective based\non attack performance to obtain (near) optimal perturbations, but paid less\nattention to the strength quantification of each perturbation such as the\ninjection of a particular node/link, which makes the choice of perturbations a\nblack-box model that lacks interpretability. In this work, we propose the\nconcept of noise to quantify the attack strength of each adversarial link.\nFurthermore, we propose three attack strategies based on the defined noise and\nclassification margins in terms of single and multiple steps optimization.\nExtensive experiments conducted on benchmark datasets against three\nrepresentative graph neural networks demonstrate the effectiveness of the\nproposed attack strategies. Particularly, we also investigate the preferred\npatterns of effective adversarial perturbations by analyzing the corresponding\nproperties of the selected perturbation nodes.",
      "tldr_zh": "本文提出“noise”概念，用于量化图神经网络(Graph Neural Networks)中结构扰动对对抗攻击(Adversarial Attacks)的强度，从而提升攻击策略的解释性。研究基于noise和分类边际(Classification Margins)设计了三种攻击策略，包括单步和多步优化方法。实验在基准数据集上针对三种代表性Graph Neural Networks进行评估，结果显示这些策略显著提高了攻击效果，并通过分析所选扰动节点的属性揭示了有效对抗扰动的首选模式。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.LG",
      "comment": "Under Review",
      "pdf_url": "http://arxiv.org/pdf/2504.20869v2",
      "published_date": "2025-04-29 15:42:56 UTC",
      "updated_date": "2025-04-30 01:46:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:48:43.957663"
    },
    {
      "arxiv_id": "2504.20862v1",
      "title": "Tabular Data Adapters: Improving Outlier Detection for Unlabeled Private Data",
      "title_zh": "翻译失败",
      "authors": [
        "Dayananda Herurkar",
        "Jörn Hees",
        "Vesselin Tzvetkov",
        "Andreas Dengel"
      ],
      "abstract": "The remarkable success of Deep Learning approaches is often based and\ndemonstrated on large public datasets. However, when applying such approaches\nto internal, private datasets, one frequently faces challenges arising from\nstructural differences in the datasets, domain shift, and the lack of labels.\nIn this work, we introduce Tabular Data Adapters (TDA), a novel method for\ngenerating soft labels for unlabeled tabular data in outlier detection tasks.\nBy identifying statistically similar public datasets and transforming private\ndata (based on a shared autoencoder) into a format compatible with\nstate-of-the-art public models, our approach enables the generation of weak\nlabels. It thereby can help to mitigate the cold start problem of labeling by\nbasing on existing outlier detection models for public datasets. In experiments\non 50 tabular datasets across different domains, we demonstrate that our method\nis able to provide more accurate annotations than baseline approaches while\nreducing computational time. Our approach offers a scalable, efficient, and\ncost-effective solution, to bridge the gap between public research models and\nreal-world industrial applications.",
      "tldr_zh": "这篇论文提出了 Tabular Data Adapters (TDA)，一种新方法，用于提升无标签私有表格数据的异常检测（outlier detection）性能，通过生成软标签（soft labels）来解决数据集结构差异、领域偏移和标签缺失的挑战。TDA 的核心机制是识别统计上相似的公共数据集，并利用共享 autoencoder 将私有数据转换为与先进公共模型兼容的格式，从而生成弱标签（weak labels）并缓解标签的冷启动问题。在50个跨领域表格数据集上的实验中，TDA 比基线方法提供了更准确的注释，同时减少了计算时间，提供了一个可扩展、高效且成本有效的解决方案，以桥接公共研究模型和实际工业应用间的差距。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "outlier detection, tabular data, neural networks, weak annotations,\n  soft labeling, unsupervised approach",
      "pdf_url": "http://arxiv.org/pdf/2504.20862v1",
      "published_date": "2025-04-29 15:38:43 UTC",
      "updated_date": "2025-04-29 15:38:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:48:56.601805"
    },
    {
      "arxiv_id": "2504.20859v1",
      "title": "X-Cross: Dynamic Integration of Language Models for Cross-Domain Sequential Recommendation",
      "title_zh": "翻译失败",
      "authors": [
        "Guy Hadad",
        "Haggai Roitman",
        "Yotam Eshel",
        "Bracha Shapira",
        "Lior Rokach"
      ],
      "abstract": "As new products are emerging daily, recommendation systems are required to\nquickly adapt to possible new domains without needing extensive retraining.\nThis work presents ``X-Cross'' -- a novel cross-domain\nsequential-recommendation model that recommends products in new domains by\nintegrating several domain-specific language models; each model is fine-tuned\nwith low-rank adapters (LoRA). Given a recommendation prompt, operating layer\nby layer, X-Cross dynamically refines the representation of each source\nlanguage model by integrating knowledge from all other models. These refined\nrepresentations are propagated from one layer to the next, leveraging the\nactivations from each domain adapter to ensure domain-specific nuances are\npreserved while enabling adaptability across domains. Using Amazon datasets for\nsequential recommendation, X-Cross achieves performance comparable to a model\nthat is fine-tuned with LoRA, while using only 25% of the additional\nparameters. In cross-domain tasks, such as adapting from Toys domain to Tools,\nElectronics or Sports, X-Cross demonstrates robust performance, while requiring\nabout 50%-75% less fine-tuning data than LoRA to make fine-tuning effective.\nFurthermore, X-Cross achieves significant improvement in accuracy over\nalternative cross-domain baselines. Overall, X-Cross enables scalable and\nadaptive cross-domain recommendations, reducing computational overhead and\nproviding an efficient solution for data-constrained environments.",
      "tldr_zh": "该研究提出了一种名为 X-Cross 的新型跨域顺序推荐模型（Sequential Recommendation），旨在帮助推荐系统快速适应新领域，而无需大量重新训练。X-Cross 通过动态整合多个领域特定语言模型（Language Models），每个模型使用低秩适配器（LoRA）进行微调，并在层级操作中精炼表示，以整合跨模型知识并保留领域特定细微差别。实验结果显示，在 Amazon 数据集上，X-Cross 仅使用 25% 的额外参数就达到了与 LoRA 完全微调相当的性能；在跨域任务中，如从 Toys 领域适应到 Tools、Electronics 或 Sports，它需要 50%-75% 更少的微调数据，并显著提高了准确率，从而提供高效、可扩展的推荐解决方案，特别适合数据受限环境。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.IR",
      "comment": "Accepted for publication in SIGIR '25",
      "pdf_url": "http://arxiv.org/pdf/2504.20859v1",
      "published_date": "2025-04-29 15:33:20 UTC",
      "updated_date": "2025-04-29 15:33:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:49:09.217538"
    },
    {
      "arxiv_id": "2504.20854v1",
      "title": "Towards Easy and Realistic Network Infrastructure Testing for Large-scale Machine Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Jinsun Yoo",
        "ChonLam Lao",
        "Lianjie Cao",
        "Bob Lantz",
        "Minlan Yu",
        "Tushar Krishna",
        "Puneet Sharma"
      ],
      "abstract": "This paper lays the foundation for Genie, a testing framework that captures\nthe impact of real hardware network behavior on ML workload performance,\nwithout requiring expensive GPUs. Genie uses CPU-initiated traffic over a\nhardware testbed to emulate GPU to GPU communication, and adapts the ASTRA-sim\nsimulator to model interaction between the network and the ML workload.",
      "tldr_zh": "这篇论文介绍了Genie框架，它为大规模机器学习网络基础设施测试奠定基础，能够捕捉真实硬件网络行为对ML工作负载性能的影响，而无需昂贵的GPU。Genie通过在硬件测试床上使用CPU发起的流量来模拟GPU到GPU的通信，并改编ASTRA-sim模拟器以建模网络和ML工作负载之间的交互。该框架使网络测试变得更易实现和更贴近实际场景，从而提升了测试效率和准确性。",
      "categories": [
        "cs.NI",
        "cs.AI",
        "cs.DC",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.NI",
      "comment": "Presented as a poster in NSDI 25",
      "pdf_url": "http://arxiv.org/pdf/2504.20854v1",
      "published_date": "2025-04-29 15:23:55 UTC",
      "updated_date": "2025-04-29 15:23:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:49:20.161482"
    },
    {
      "arxiv_id": "2504.20851v1",
      "title": "Fostering Self-Directed Growth with Generative AI: Toward a New Learning Analytics Framework",
      "title_zh": "使用生成式 AI 促进自我导向成长：朝向一个新的学习分析框架",
      "authors": [
        "Qianrun Mao"
      ],
      "abstract": "In an era increasingly shaped by decentralized knowledge ecosystems and\npervasive AI technologies, fostering sustainable learner agency has become a\ncritical educational imperative. This study introduces a novel conceptual\nframework integrating Generative Artificial Intelligence and Learning Analytics\nto cultivate Self-Directed Growth, a dynamic competency that enables learners\nto iteratively drive their own developmental pathways across diverse\ncontexts.Building upon critical gaps in current research on Self Directed\nLearning and AI-mediated education, the proposed Aspire to Potentials for\nLearners (A2PL) model reconceptualizes the interplay of learner aspirations,\ncomplex thinking, and summative self-assessment within GAI supported\nenvironments.Methodological implications for future intervention design and\nlearning analytics applications are discussed, positioning Self-Directed Growth\nas a pivotal axis for developing equitable, adaptive, and sustainable learning\nsystems in the digital era.",
      "tldr_zh": "本研究在分散知识生态和AI技术主导的时代，提出一个新框架，将Generative AI与Learning Analytics整合，以培养Self-Directed Growth——一种动态能力，让学习者自主驱动自身发展路径。框架名为Aspire to Potentials for Learners (A2PL)，重新概念化了学习者愿望、复杂思考和总结性自我评估在GAI支持环境中的互动，填补了Self-Directed Learning和AI-mediated教育的研究空白。该框架为未来干预设计和学习分析应用提供了方法论指导，有助于构建公平、适应性和可持续的学习系统。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.20851v1",
      "published_date": "2025-04-29 15:19:48 UTC",
      "updated_date": "2025-04-29 15:19:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:49:32.379081"
    },
    {
      "arxiv_id": "2504.20848v1",
      "title": "Mitigating the Structural Bias in Graph Adversarial Defenses",
      "title_zh": "缓解图对抗防御中的结构偏差",
      "authors": [
        "Junyuan Fang",
        "Huimin Liu",
        "Han Yang",
        "Jiajing Wu",
        "Zibin Zheng",
        "Chi K. Tse"
      ],
      "abstract": "In recent years, graph neural networks (GNNs) have shown great potential in\naddressing various graph structure-related downstream tasks. However, recent\nstudies have found that current GNNs are susceptible to malicious adversarial\nattacks. Given the inevitable presence of adversarial attacks in the real\nworld, a variety of defense methods have been proposed to counter these attacks\nand enhance the robustness of GNNs. Despite the commendable performance of\nthese defense methods, we have observed that they tend to exhibit a structural\nbias in terms of their defense capability on nodes with low degree (i.e., tail\nnodes), which is similar to the structural bias of traditional GNNs on nodes\nwith low degree in the clean graph. Therefore, in this work, we propose a\ndefense strategy by including hetero-homo augmented graph construction, $k$NN\naugmented graph construction, and multi-view node-wise attention modules to\nmitigate the structural bias of GNNs against adversarial attacks. Notably, the\nhetero-homo augmented graph consists of removing heterophilic links (i.e.,\nlinks connecting nodes with dissimilar features) globally and adding homophilic\nlinks (i.e., links connecting nodes with similar features) for nodes with low\ndegree. To further enhance the defense capability, an attention mechanism is\nadopted to adaptively combine the representations from the above two kinds of\ngraph views. We conduct extensive experiments to demonstrate the defense and\ndebiasing effect of the proposed strategy on benchmark datasets.",
      "tldr_zh": "该论文探讨了图神经网络 (GNNs) 在面对对抗攻击时的结构偏差问题，特别是对低度节点 (tail nodes) 的防御能力不足。作者提出了一种新防御策略，包括 hetero-homo augmented graph construction（移除异质链接并为低度节点添加同质链接）、kNN augmented graph construction，以及 multi-view node-wise attention modules，以缓解这种偏差并增强 GNNs 的鲁棒性。这些方法通过注意力机制自适应地结合不同图视图的表示，提高了整体防御效果。实验在基准数据集上验证了该策略的有效性，在防御和去偏方面表现出色。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.LG",
      "comment": "Under Review",
      "pdf_url": "http://arxiv.org/pdf/2504.20848v1",
      "published_date": "2025-04-29 15:19:05 UTC",
      "updated_date": "2025-04-29 15:19:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:49:44.213849"
    },
    {
      "arxiv_id": "2504.20846v1",
      "title": "Disjunctive and Conjunctive Normal Form Explanations of Clusters Using Auxiliary Information",
      "title_zh": "翻译失败",
      "authors": [
        "Robert F. Downey",
        "S. S. Ravi"
      ],
      "abstract": "We consider generating post-hoc explanations of clusters generated from\nvarious datasets using auxiliary information which was not used by clustering\nalgorithms. Following terminology used in previous work, we refer to the\nauxiliary information as tags. Our focus is on two forms of explanations,\nnamely disjunctive form (where the explanation for a cluster consists of a set\nof tags) and a two-clause conjunctive normal form (CNF) explanation (where the\nexplanation consists of two sets of tags, combined through the AND operator).\nWe use integer linear programming (ILP) as well as heuristic methods to\ngenerate these explanations. We experiment with a variety of datasets and\ndiscuss the insights obtained from our explanations. We also present\nexperimental results regarding the scalability of our explanation methods.",
      "tldr_zh": "这篇论文探讨了使用辅助信息（auxiliary information）生成聚类后验解释的方法，焦点在于 disjunctive form（由一组标签组成）和 two-clause conjunctive normal form (CNF)（两个标签集通过 AND 运算符结合）的解释形式。作者采用 integer linear programming (ILP) 和启发式方法来生成这些解释，并通过多种数据集进行实验，揭示了聚类的洞见。实验结果还评估了方法的扩展性，证明其在实际应用中的可行性。",
      "categories": [
        "cs.AI",
        "I.2"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.20846v1",
      "published_date": "2025-04-29 15:18:18 UTC",
      "updated_date": "2025-04-29 15:18:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:49:55.689095"
    },
    {
      "arxiv_id": "2505.00035v1",
      "title": "Linguistic Complexity and Socio-cultural Patterns in Hip-Hop Lyrics",
      "title_zh": "嘻哈歌词中的语言复杂性与社会文化模式",
      "authors": [
        "Aayam Bansal",
        "Raghav Agarwal",
        "Kaashvi Jain"
      ],
      "abstract": "This paper presents a comprehensive computational framework for analyzing\nlinguistic complexity and socio-cultural trends in hip-hop lyrics. Using a\ndataset of 3,814 songs from 146 influential artists spanning four decades\n(1980-2020), we employ natural language processing techniques to quantify\nmultiple dimensions of lyrical complexity. Our analysis reveals a 23.7%\nincrease in vocabulary diversity over the study period, with East Coast artists\ndemonstrating 17.3% higher lexical variation than other regions. Rhyme density\nincreased by 34.2% across all regions, with Midwest artists exhibiting the\nhighest technical complexity (3.04 rhymes per line). Topic modeling identified\nsignificant shifts in thematic content, with social justice themes decreasing\nfrom 28.5% to 13.8% of content while introspective themes increased from 7.6%\nto 26.3%. Sentiment analysis demon- strated that lyrics became significantly\nmore negative during sociopolitical crises, with polarity decreasing by 0.31\nfollowing major social unrest. Multi-dimensional analysis revealed four dis-\ntinct stylistic approaches that correlate strongly with geographic origin\n(r=0.68, p!0.001) and time period (r=0.59, p<0.001). These findings establish\nquantitative evidence for the evolution of hip- hop as both an art form and a\nreflection of societal dynamics, providing insights into the interplay between\nlinguistic innovation and cultural context in popular music.",
      "tldr_zh": "这篇论文提出一个全面的计算框架，使用自然语言处理 (NLP) 技术分析嘻哈歌词的语言复杂性和社会文化趋势，基于 1980-2020 年 3814 首歌曲的数据集。研究发现，词汇多样性增加了 23.7%，东海岸艺术家显示 17.3% 更高的词汇变化，而押韵密度 (rhyme density) 整体上升 34.2%，以中西部艺术家最高 (3.04 rhymes per line)。主题建模和情感分析 (sentiment analysis) 揭示了社会正义主题从 28.5% 降至 13.8%、内省主题从 7.6% 升至 26.3%，并在社会政治危机中歌词极性下降 0.31，这些多维度结果证明了嘻哈音乐作为艺术形式和社会动态反映的量化演变。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "12 pages",
      "pdf_url": "http://arxiv.org/pdf/2505.00035v1",
      "published_date": "2025-04-29 15:01:23 UTC",
      "updated_date": "2025-04-29 15:01:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:50:10.073551"
    },
    {
      "arxiv_id": "2504.20837v1",
      "title": "RadSAM: Segmenting 3D radiological images with a 2D promptable model",
      "title_zh": "翻译失败",
      "authors": [
        "Julien Khlaut",
        "Elodie Ferreres",
        "Daniel Tordjman",
        "Hélène Philippe",
        "Tom Boeken",
        "Pierre Manceron",
        "Corentin Dancette"
      ],
      "abstract": "Medical image segmentation is a crucial and time-consuming task in clinical\ncare, where mask precision is extremely important. The Segment Anything Model\n(SAM) offers a promising approach, as it provides an interactive interface\nbased on visual prompting and edition to refine an initial segmentation. This\nmodel has strong generalization capabilities, does not rely on predefined\nclasses, and adapts to diverse objects; however, it is pre-trained on natural\nimages and lacks the ability to process medical data effectively. In addition,\nthis model is built for 2D images, whereas a whole medical domain is based on\n3D images, such as CT and MRI. Recent adaptations of SAM for medical imaging\nare based on 2D models, thus requiring one prompt per slice to segment 3D\nobjects, making the segmentation process tedious. They also lack important\nfeatures such as editing. To bridge this gap, we propose RadSAM, a novel method\nfor segmenting 3D objects with a 2D model from a single prompt. In practice, we\ntrain a 2D model using noisy masks as initial prompts, in addition to bounding\nboxes and points. We then use this novel prompt type with an iterative\ninference pipeline to reconstruct the 3D mask slice-by-slice. We introduce a\nbenchmark to evaluate the model's ability to segment 3D objects in CT images\nfrom a single prompt and evaluate the models' out-of-domain transfer and\nedition capabilities. We demonstrate the effectiveness of our approach against\nstate-of-the-art models on this benchmark using the AMOS abdominal organ\nsegmentation dataset.",
      "tldr_zh": "医疗图像分割是临床护理中的关键任务，但 Segment Anything Model (SAM) 虽具备交互式提示和泛化能力，却因针对自然图像训练而难以处理 3D 放射学图像，如 CT 和 MRI，且现有适应方法需逐切片提示，过程繁琐。为解决此问题，我们提出 RadSAM，一种使用 2D 模型从单个提示分割 3D 对象的创新方法，通过训练模型处理 noisy masks、bounding boxes 和 points，并采用迭代推理管道逐切片重建 3D 掩码。在 AMOS 腹部器官分割数据集的基准测试中，RadSAM 展示了出色的分割准确性、出域转移和编辑能力，优于现有最先进模型。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.20837v1",
      "published_date": "2025-04-29 15:00:25 UTC",
      "updated_date": "2025-04-29 15:00:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:50:21.596426"
    },
    {
      "arxiv_id": "2504.20834v3",
      "title": "Token-Efficient RL for LLM Reasoning",
      "title_zh": "翻译失败",
      "authors": [
        "Alan Lee",
        "Harry Tong"
      ],
      "abstract": "We propose reinforcement learning (RL) strategies tailored for reasoning in\nlarge language models (LLMs) under strict memory and compute limits, with a\nparticular focus on compatibility with LoRA fine-tuning. Building on early\npolicy gradient methods with baseline subtraction, we design critic-free\nmethods that operate on a small, informative subset of output tokens to reduce\nmemory usage and stabilize training. We introduce S-GRPO, a stochastic variant\nof Group Relative Policy Optimization, and T-SPMO, a token-level prefix\nmatching approach for fine-grained credit assignment. Applied to Qwen2-1.5B,\nour methods raise accuracy on the SVAMP benchmark from 46% to over 70% and show\nstrong performance on multi-digit multiplication. Surprisingly, full-token GRPO\nunder LoRA fails to improve over the base model, suggesting that selective\ntoken-level optimization may act as an implicit regularizer in low-parameter\ntraining regimes.",
      "tldr_zh": "本研究提出了一种高效的强化学习 (RL) 策略，用于大型语言模型 (LLMs) 的推理任务，特别关注内存和计算限制下的兼容性，并与 LoRA 微调相结合。该策略设计了不依赖批评家的方法，只处理一小部分输出标记，以减少内存使用并稳定训练，并引入了 S-GRPO（Group Relative Policy Optimization 的随机变体）和 T-SPMO（标记级前缀匹配方法）来实现细粒度信用分配。在 Qwen2-1.5B 模型上应用后，SVAMP 基准准确率从 46% 提升至超过 70%，并在多位乘法任务中表现出色；同时发现，全标记 GRPO 在 LoRA 下未能改善基线模型，表明选择性标记级优化可能充当隐式正则化器。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Title updated to \"Token-Efficient RL for LLM Reasoning\" to better\n  reflect algorithmic focus. Revised abstract, intro, and conclusion. Paper\n  shortened and typos fixed",
      "pdf_url": "http://arxiv.org/pdf/2504.20834v3",
      "published_date": "2025-04-29 14:58:43 UTC",
      "updated_date": "2025-05-09 23:50:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:50:34.775815"
    },
    {
      "arxiv_id": "2504.20829v1",
      "title": "GaussTrap: Stealthy Poisoning Attacks on 3D Gaussian Splatting for Targeted Scene Confusion",
      "title_zh": "翻译失败",
      "authors": [
        "Jiaxin Hong",
        "Sixu Chen",
        "Shuoyang Sun",
        "Hongyao Yu",
        "Hao Fang",
        "Yuqi Tan",
        "Bin Chen",
        "Shuhan Qi",
        "Jiawei Li"
      ],
      "abstract": "As 3D Gaussian Splatting (3DGS) emerges as a breakthrough in scene\nrepresentation and novel view synthesis, its rapid adoption in safety-critical\ndomains (e.g., autonomous systems, AR/VR) urgently demands scrutiny of\npotential security vulnerabilities. This paper presents the first systematic\nstudy of backdoor threats in 3DGS pipelines. We identify that adversaries may\nimplant backdoor views to induce malicious scene confusion during inference,\npotentially leading to environmental misperception in autonomous navigation or\nspatial distortion in immersive environments. To uncover this risk, we propose\nGuassTrap, a novel poisoning attack method targeting 3DGS models. GuassTrap\ninjects malicious views at specific attack viewpoints while preserving\nhigh-quality rendering in non-target views, ensuring minimal detectability and\nmaximizing potential harm. Specifically, the proposed method consists of a\nthree-stage pipeline (attack, stabilization, and normal training) to implant\nstealthy, viewpoint-consistent poisoned renderings in 3DGS, jointly optimizing\nattack efficacy and perceptual realism to expose security risks in 3D\nrendering. Extensive experiments on both synthetic and real-world datasets\ndemonstrate that GuassTrap can effectively embed imperceptible yet harmful\nbackdoor views while maintaining high-quality rendering in normal views,\nvalidating its robustness, adaptability, and practical applicability.",
      "tldr_zh": "本研究首次系统探讨了 3D Gaussian Splatting (3DGS) 在安全关键领域（如自主系统和 AR/VR）中的后门威胁，揭示攻击者可通过植入后门视图引发恶意场景混淆，导致环境误判或空间扭曲。论文提出 GaussTrap，一种隐蔽的 poisoning attack 方法，针对 3DGS 模型在特定攻击视点注入恶意视图，同时保持非目标视图的高质量渲染。GaussTrap 采用三阶段管道（attack、stabilization 和 normal training），优化攻击效果和感知真实性。在合成和真实数据集上的广泛实验证明，该方法能有效嵌入不易察觉的有害后门视图，同时确保攻击的鲁棒性和实用性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.20829v1",
      "published_date": "2025-04-29 14:52:14 UTC",
      "updated_date": "2025-04-29 14:52:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:50:44.606375"
    },
    {
      "arxiv_id": "2504.20828v2",
      "title": "Ascendra: Dynamic Request Prioritization for Efficient LLM Serving",
      "title_zh": "Ascendra: 用于高效LLM服务的动态请求优先级排序",
      "authors": [
        "Azam Ikram",
        "Xiang Li",
        "Sameh Elnikety",
        "Saurabh Bagchi"
      ],
      "abstract": "The rapid advancement of Large Language Models (LLMs) has driven the need for\nmore efficient serving strategies. In this context, efficiency refers to the\nproportion of requests that meet their Service Level Objectives (SLOs),\nparticularly for Time To First Token (TTFT) and Time Between Tokens (TBT).\nHowever, existing systems often prioritize one metric at the cost of the other.\nWe present Ascendra, an LLM serving system designed to meet both TTFT and TBT\nSLOs simultaneously. The core insight behind Ascendra is that a request's\nurgency evolves as it approaches its deadline. To leverage this, Ascendra\npartitions GPU resources into two types of instances: low-priority and\nhigh-priority. Low-priority instances maximize throughput by processing\nrequests out of arrival order, but at the risk of request starvation. To\naddress this, Ascendra employs a performance model to predict requests at risk\nof missing their SLOs and proactively offloads them to high-priority instances.\nHigh-priority instances are optimized for low-latency execution and handle\nurgent requests nearing their deadlines. This partitioned architecture enables\nAscendra to effectively balance high throughput and low latency. Extensive\nevaluation shows that Ascendra improves system throughput by up to 1.7x\ncompared to vLLM and Sarathi-Serve while meeting both TTFT and TBT SLOs.",
      "tldr_zh": "本论文提出Ascendra，一种动态请求优先级系统，用于提升Large Language Models (LLMs) 的服务效率。该系统通过将GPU资源分为低优先级和高优先级实例，动态处理请求的紧急性：低优先级实例优化吞吐量，而高优先级实例则使用性能模型预测并转移风险请求，以同时满足Time To First Token (TTFT) 和Time Between Tokens (TBT) 的Service Level Objectives (SLOs)。实验结果显示，Ascendra相较于vLLM和Sarathi-Serve，提高系统吞吐量高达1.7倍，同时有效平衡高吞吐和低延迟。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.20828v2",
      "published_date": "2025-04-29 14:51:26 UTC",
      "updated_date": "2025-04-30 14:08:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:50:55.502859"
    },
    {
      "arxiv_id": "2505.13455v1",
      "title": "Exploring Emotional Synchrony in Dyadic Interactions: The Role of Speech Conditions in Facial and Vocal Affective Alignment",
      "title_zh": "探索二元互动中的情感同步：语音条件在面部和语音情感对齐中的作用",
      "authors": [
        "Von Ralph Dane Marquez Herbuela",
        "Yukie Nagai"
      ],
      "abstract": "Understanding how humans express and synchronize emotions across multiple\ncommunication channels particularly facial expressions and speech has\nsignificant implications for emotion recognition systems and human computer\ninteraction. Motivated by the notion that non-overlapping speech promotes\nclearer emotional coordination, while overlapping speech disrupts synchrony,\nthis study examines how these conversational dynamics shape the spatial and\ntemporal alignment of arousal and valence across facial and vocal modalities.\nUsing dyadic interactions from the IEMOCAP dataset, we extracted continuous\nemotion estimates via EmoNet (facial video) and a Wav2Vec2-based model (speech\naudio). Segments were categorized based on speech overlap, and emotional\nalignment was assessed using Pearson correlation, lag adjusted analysis, and\nDynamic Time Warping (DTW). Across analyses, non overlapping speech was\nassociated with more stable and predictable emotional synchrony than\noverlapping speech. While zero-lag correlations were low and not statistically\ndifferent, non overlapping speech showed reduced variability, especially for\narousal. Lag adjusted correlations and best-lag distributions revealed clearer,\nmore consistent temporal alignment in these segments. In contrast, overlapping\nspeech exhibited higher variability and flatter lag profiles, though DTW\nindicated unexpectedly tighter alignment suggesting distinct coordination\nstrategies. Notably, directionality patterns showed that facial expressions\nmore often preceded speech during turn-taking, while speech led during\nsimultaneous vocalizations. These findings underscore the importance of\nconversational structure in regulating emotional communication and provide new\ninsight into the spatial and temporal dynamics of multimodal affective\nalignment in real world interaction.",
      "tldr_zh": "本研究探讨了在二人互动中，语音条件（非重叠 vs. 重叠）如何影响面部表情和语音在唤醒度和情感价值上的空间及时间同步，使用 IEMOCAP 数据集通过 EmoNet（面部视频）和 Wav2Vec2（语音音频）模型提取连续情绪估计。研究采用 Pearson correlation、滞后调整分析和 Dynamic Time Warping (DTW) 等方法分析情绪对齐，结果显示非重叠语音导致更稳定的同步和更低的变异性，而重叠语音虽显示更紧凑的对齐但伴随更高变异性。总体而言，面部表情通常先于语音出现，这些发现为情绪识别系统和人机交互提供了对多模态情感动态的新见解。",
      "categories": [
        "eess.AS",
        "cs.AI"
      ],
      "primary_category": "eess.AS",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.13455v1",
      "published_date": "2025-04-29 14:41:55 UTC",
      "updated_date": "2025-04-29 14:41:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:51:09.460831"
    },
    {
      "arxiv_id": "2504.20808v1",
      "title": "SoccerDiffusion: Toward Learning End-to-End Humanoid Robot Soccer from Gameplay Recordings",
      "title_zh": "翻译失败",
      "authors": [
        "Florian Vahl",
        "Jörn Griepenburg",
        "Jan Gutsche",
        "Jasper Güldenstein",
        "Jianwei Zhang"
      ],
      "abstract": "This paper introduces SoccerDiffusion, a transformer-based diffusion model\ndesigned to learn end-to-end control policies for humanoid robot soccer\ndirectly from real-world gameplay recordings. Using data collected from RoboCup\ncompetitions, the model predicts joint command trajectories from multi-modal\nsensor inputs, including vision, proprioception, and game state. We employ a\ndistillation technique to enable real-time inference on embedded platforms that\nreduces the multi-step diffusion process to a single step. Our results\ndemonstrate the model's ability to replicate complex motion behaviors such as\nwalking, kicking, and fall recovery both in simulation and on physical robots.\nAlthough high-level tactical behavior remains limited, this work provides a\nrobust foundation for subsequent reinforcement learning or preference\noptimization methods. We release the dataset, pretrained models, and code\nunder: https://bit-bots.github.io/SoccerDiffusion",
      "tldr_zh": "本论文提出SoccerDiffusion，一种基于Transformer的扩散模型，用于从真实RoboCup比赛录像中直接学习人形机器人足球的端到端控制策略。该模型利用多模态传感器输入（如视觉、专有感知和游戏状态）预测关节命令轨迹，并通过蒸馏技术将多步扩散过程简化为单步，实现嵌入式平台的实时推理。实验结果显示，模型能在模拟和物理机器人上成功复制复杂动作，包括行走、踢球和跌倒恢复，尽管高层次战术行为仍需改进。该工作为后续强化学习或偏好优化方法提供了坚实基础，并开源了数据集、预训练模型和代码。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.20808v1",
      "published_date": "2025-04-29 14:21:08 UTC",
      "updated_date": "2025-04-29 14:21:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:51:19.384315"
    },
    {
      "arxiv_id": "2504.20799v2",
      "title": "Hallucination by Code Generation LLMs: Taxonomy, Benchmarks, Mitigation, and Challenges",
      "title_zh": "翻译失败",
      "authors": [
        "Yunseo Lee",
        "John Youngeun Song",
        "Dongsun Kim",
        "Jindae Kim",
        "Mijung Kim",
        "Jaechang Nam"
      ],
      "abstract": "Recent technical breakthroughs in large language models (LLMs) have enabled\nthem to fluently generate source code. Software developers often leverage both\ngeneral-purpose and code-specialized LLMs to revise existing code or even\ngenerate a whole function from scratch. These capabilities are also beneficial\nin no-code or low-code contexts, in which one can write programs without a\ntechnical background. However, due to their internal design, LLMs are prone to\ngenerating hallucinations, which are incorrect, nonsensical, and not\njustifiable information but difficult to identify its presence. This problem\nalso occurs when generating source code. Once hallucinated code is produced, it\nis often challenging for users to identify and fix it, especially when such\nhallucinations can be identified under specific execution paths. As a result,\nthe hallucinated code may remain unnoticed within the codebase. This survey\ninvestigates recent studies and techniques relevant to hallucinations generated\nby CodeLLMs. We categorize the types of hallucinations in the code generated by\nCodeLLMs, review existing benchmarks and mitigation strategies, and identify\nopen challenges. Based on these findings, this survey outlines further research\ndirections in the detection and removal of hallucinations produced by CodeLLMs.",
      "tldr_zh": "该研究调查了代码生成大型语言模型（CodeLLMs）产生的幻觉问题，包括不正确或不合理的代码输出。论文对代码幻觉进行了分类（Taxonomy），回顾了现有的基准（benchmarks）和缓解策略（mitigation），并识别了相关挑战。最终，研究概述了检测和移除CodeLLMs幻觉的未来研究方向，以提升代码生成的可信度。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "15 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2504.20799v2",
      "published_date": "2025-04-29 14:13:57 UTC",
      "updated_date": "2025-05-13 11:51:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:51:30.692099"
    },
    {
      "arxiv_id": "2504.20797v1",
      "title": "Partitioned Memory Storage Inspired Few-Shot Class-Incremental learning",
      "title_zh": "翻译失败",
      "authors": [
        "Renye Zhang",
        "Yimin Yin",
        "Jinghua Zhang"
      ],
      "abstract": "Current mainstream deep learning techniques exhibit an over-reliance on\nextensive training data and a lack of adaptability to the dynamic world,\nmarking a considerable disparity from human intelligence. To bridge this gap,\nFew-Shot Class-Incremental Learning (FSCIL) has emerged, focusing on continuous\nlearning of new categories with limited samples without forgetting old\nknowledge. Existing FSCIL studies typically use a single model to learn\nknowledge across all sessions, inevitably leading to the stability-plasticity\ndilemma. Unlike machines, humans store varied knowledge in different cerebral\ncortices. Inspired by this characteristic, our paper aims to develop a method\nthat learns independent models for each session. It can inherently prevent\ncatastrophic forgetting. During the testing stage, our method integrates\nUncertainty Quantification (UQ) for model deployment. Our method provides a\nfresh viewpoint for FSCIL and demonstrates the state-of-the-art performance on\nCIFAR-100 and mini-ImageNet datasets.",
      "tldr_zh": "本研究针对深度学习过度依赖大量数据且缺乏适应性的问题，提出了一种受分区记忆存储启发的Few-Shot Class-Incremental Learning (FSCIL)方法。该方法为每个学习会话训练独立模型，从而避免了传统单一模型带来的stability-plasticity dilemma和灾难性遗忘。测试阶段通过Uncertainty Quantification (UQ)进行模型部署，提供更可靠的预测。该方法在CIFAR-100和mini-ImageNet数据集上实现了最先进性能，为FSCIL提供了新视角。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.20797v1",
      "published_date": "2025-04-29 14:11:06 UTC",
      "updated_date": "2025-04-29 14:11:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:51:43.656115"
    },
    {
      "arxiv_id": "2505.00034v2",
      "title": "Improving Phishing Email Detection Performance of Small Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Zijie Lin",
        "Zikang Liu",
        "Hanbo Fan"
      ],
      "abstract": "Large language models(LLMs) have demonstrated remarkable performance on many\nnatural language processing(NLP) tasks and have been employed in phishing email\ndetection research. However, in current studies, well-performing LLMs typically\ncontain billions or even tens of billions of parameters, requiring enormous\ncomputational resources. To reduce computational costs, we investigated the\neffectiveness of small-parameter LLMs for phishing email detection. These LLMs\nhave around 3 billion parameters and can run on consumer-grade GPUs. However,\nsmall LLMs often perform poorly in phishing email detection task. To address\nthese issues, we designed a set of methods including Prompt Engineering,\nExplanation Augmented Fine-tuning, and Model Ensemble to improve phishing email\ndetection capabilities of small LLMs. We validated the effectiveness of our\napproach through experiments, significantly improving both accuracy and F1\nscore on the SpamAssassin and CEAS\\_08 datasets. Furthermore, the fine-tuned\nmodels demonstrated strong transferability, achieving robust performance across\nmultiple unseen phishing datasets, outperforming traditional baselines and\napproaching standard-sized LLMs.",
      "tldr_zh": "本研究针对小型大型语言模型（small LLMs，约3亿参数）在网络钓鱼邮件检测中的性能不足问题，提出了一系列优化方法，包括Prompt Engineering、Explanation Augmented Fine-tuning和Model Ensemble，以降低计算资源需求并提升检测能力。这些方法通过实验在SpamAssassin和CEAS_08数据集上显著提高了模型的准确性和F1 score。结果表明，微调后的小型LLMs不仅在未见数据集上表现出强转移性，还优于传统基线并接近标准大小LLMs的表现。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.00034v2",
      "published_date": "2025-04-29 14:07:06 UTC",
      "updated_date": "2025-05-03 13:08:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:51:56.623675"
    },
    {
      "arxiv_id": "2504.20784v2",
      "title": "Approximate Lifted Model Construction",
      "title_zh": "翻译失败",
      "authors": [
        "Malte Luttermann",
        "Jan Speller",
        "Marcel Gehrke",
        "Tanya Braun",
        "Ralf Möller",
        "Mattis Hartwig"
      ],
      "abstract": "Probabilistic relational models such as parametric factor graphs enable\nefficient (lifted) inference by exploiting the indistinguishability of objects.\nIn lifted inference, a representative of indistinguishable objects is used for\ncomputations. To obtain a relational (i.e., lifted) representation, the\nAdvanced Colour Passing (ACP) algorithm is the state of the art. The ACP\nalgorithm, however, requires underlying distributions, encoded as\npotential-based factorisations, to exactly match to identify and exploit\nindistinguishabilities. Hence, ACP is unsuitable for practical applications\nwhere potentials learned from data inevitably deviate even if associated\nobjects are indistinguishable. To mitigate this problem, we introduce the\n$\\varepsilon$-Advanced Colour Passing ($\\varepsilon$-ACP) algorithm, which\nallows for a deviation of potentials depending on a hyperparameter\n$\\varepsilon$. $\\varepsilon$-ACP efficiently uncovers and exploits\nindistinguishabilities that are not exact. We prove that the approximation\nerror induced by $\\varepsilon$-ACP is strictly bounded and our experiments show\nthat the approximation error is close to zero in practice.",
      "tldr_zh": "本论文针对概率关系模型（如parametric factor graphs）中的提升推理问题，指出现有Advanced Colour Passing (ACP)算法要求潜在函数精确匹配才能利用对象的不可区分性，但实际数据学得的函数往往存在偏差。作者提出ε-Advanced Colour Passing (ε-ACP)算法，通过引入超参数ε允许一定偏差，从而高效识别和利用不完全精确的不可区分性。该方法证明了近似误差严格bounded，且实验结果显示实际误差接近零，为实用应用中的提升推理提供了更鲁棒的解决方案。",
      "categories": [
        "cs.AI",
        "cs.DS",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "Extended version of paper accepted to the Proceedings of the 34th\n  International Joint Conference on Artificial Intelligence (IJCAI-2025)",
      "pdf_url": "http://arxiv.org/pdf/2504.20784v2",
      "published_date": "2025-04-29 14:01:10 UTC",
      "updated_date": "2025-05-08 13:18:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:52:07.406325"
    },
    {
      "arxiv_id": "2504.20781v1",
      "title": "Using LLMs in Generating Design Rationale for Software Architecture Decisions",
      "title_zh": "使用 LLMs 生成软件架构决策的设计理由",
      "authors": [
        "Xiyu Zhou",
        "Ruiyin Li",
        "Peng Liang",
        "Beiqi Zhang",
        "Mojtaba Shahin",
        "Zengyang Li",
        "Chen Yang"
      ],
      "abstract": "Design Rationale (DR) for software architecture decisions refers to the\nreasoning underlying architectural choices, which provides valuable insights\ninto the different phases of the architecting process throughout software\ndevelopment. However, in practice, DR is often inadequately documented due to a\nlack of motivation and effort from developers. With the recent advancements in\nLarge Language Models (LLMs), their capabilities in text comprehension,\nreasoning, and generation may enable the generation and recovery of DR for\narchitecture decisions. In this study, we evaluated the performance of LLMs in\ngenerating DR for architecture decisions. First, we collected 50 Stack Overflow\n(SO) posts, 25 GitHub issues, and 25 GitHub discussions related to architecture\ndecisions to construct a dataset of 100 architecture-related problems. Then, we\nselected five LLMs to generate DR for the architecture decisions with three\nprompting strategies, including zero-shot, chain of thought (CoT), and\nLLM-based agents. With the DR provided by human experts as ground truth, the\nPrecision of LLM-generated DR with the three prompting strategies ranges from\n0.267 to 0.278, Recall from 0.627 to 0.715, and F1-score from 0.351 to 0.389.\nAdditionally, 64.45% to 69.42% of the arguments of DR not mentioned by human\nexperts are also helpful, 4.12% to 4.87% of the arguments have uncertain\ncorrectness, and 1.59% to 3.24% of the arguments are potentially misleading.\nBased on the results, we further discussed the pros and cons of the three\nprompting strategies and the strengths and limitations of the DR generated by\nLLMs.",
      "tldr_zh": "本文研究了使用 Large Language Models (LLMs) 生成软件架构决策的 Design Rationale (DR)，旨在解决 DR 记录不足的问题，从而提供对架构过程的洞见。研究人员构建了一个数据集，包括 50 个 Stack Overflow 帖子、25 个 GitHub issues 和 25 个 GitHub discussions，并采用 zero-shot、chain of thought (CoT) 和 LLM-based agents 三种提示策略，让五个 LLMs 生成 DR。结果显示，与人类专家提供的 DR 相比，LLMs 的 Precision 为 0.267-0.278、Recall 为 0.627-0.715、F1-score 为 0.351-0.389，且 64.45% 到 69.42% 的额外生成论点有帮助，但部分论点存在不确定性或误导风险。论文进一步讨论了三种策略的优缺点，以及 LLMs 在 DR 生成中的优势和局限性。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "28 pages, 5 images, 7 tables, Manuscript submitted to a journal\n  (2025)",
      "pdf_url": "http://arxiv.org/pdf/2504.20781v1",
      "published_date": "2025-04-29 14:00:18 UTC",
      "updated_date": "2025-04-29 14:00:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:52:22.306357"
    },
    {
      "arxiv_id": "2504.20776v1",
      "title": "ECOSoundSet: a finely annotated dataset for the automated acoustic identification of Orthoptera and Cicadidae in North, Central and temperate Western Europe",
      "title_zh": "翻译失败",
      "authors": [
        "David Funosas",
        "Elodie Massol",
        "Yves Bas",
        "Svenja Schmidt",
        "Dominik Arend",
        "Alexander Gebhard",
        "Luc Barbaro",
        "Sebastian König",
        "Rafael Carbonell Font",
        "David Sannier",
        "Fernand Deroussen",
        "Jérôme Sueur",
        "Christian Roesti",
        "Tomi Trilar",
        "Wolfgang Forstmeier",
        "Lucas Roger",
        "Eloïsa Matheu",
        "Piotr Guzik",
        "Julien Barataud",
        "Laurent Pelozuelo",
        "Stéphane Puissant",
        "Sandra Mueller",
        "Björn Schuller",
        "Jose M. Montoya",
        "Andreas Triantafyllopoulos",
        "Maxime Cauchoix"
      ],
      "abstract": "Currently available tools for the automated acoustic recognition of European\ninsects in natural soundscapes are limited in scope. Large and ecologically\nheterogeneous acoustic datasets are currently needed for these algorithms to\ncross-contextually recognize the subtle and complex acoustic signatures\nproduced by each species, thus making the availability of such datasets a key\nrequisite for their development. Here we present ECOSoundSet (European\nCicadidae and Orthoptera Sound dataSet), a dataset containing 10,653 recordings\nof 200 orthopteran and 24 cicada species (217 and 26 respective taxa when\nincluding subspecies) present in North, Central, and temperate Western Europe\n(Andorra, Belgium, Denmark, mainland France and Corsica, Germany, Ireland,\nLuxembourg, Monaco, Netherlands, United Kingdom, Switzerland), collected partly\nthrough targeted fieldwork in South France and Catalonia and partly through\ncontributions from various European entomologists. The dataset is composed of a\ncombination of coarsely labeled recordings, for which we can only infer the\npresence, at some point, of their target species (weak labeling), and finely\nannotated recordings, for which we know the specific time and frequency range\nof each insect sound present in the recording (strong labeling). We also\nprovide a train/validation/test split of the strongly labeled recordings, with\nrespective approximate proportions of 0.8, 0.1 and 0.1, in order to facilitate\ntheir incorporation in the training and evaluation of deep learning algorithms.\nThis dataset could serve as a meaningful complement to recordings already\navailable online for the training of deep learning algorithms for the acoustic\nclassification of orthopterans and cicadas in North, Central, and temperate\nWestern Europe.",
      "tldr_zh": "本研究介绍了ECOSoundSet数据集，这是一个针对North, Central and temperate Western Europe地区的Orthoptera和Cicadidae昆虫的精细标注声学数据集，旨在支持自动化声学识别算法的开发。数据集包含10,653个录音，覆盖200种Orthoptera和24种Cicadidae物种（包括子种），结合了weak labeling（仅标注物种存在）和strong labeling（标注具体时间和频率范围）的标注方式，并提供了约0.8/0.1/0.1的训练/验证/测试集划分。ECOSoundSet可作为现有在线录音的补充，帮助训练deep learning algorithms，实现跨上下文的精确昆虫声学分类。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "3 Figures + 2 Supplementary Figures, 2 Tables + 3 Supplementary\n  Tables",
      "pdf_url": "http://arxiv.org/pdf/2504.20776v1",
      "published_date": "2025-04-29 13:53:33 UTC",
      "updated_date": "2025-04-29 13:53:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:52:32.842049"
    },
    {
      "arxiv_id": "2504.20770v1",
      "title": "JTreeformer: Graph-Transformer via Latent-Diffusion Model for Molecular Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Ji Shi",
        "Chengxun Xie",
        "Zhonghao Li",
        "Xinming Zhang",
        "Miao Zhang"
      ],
      "abstract": "The discovery of new molecules based on the original chemical molecule\ndistributions is of great importance in medicine. The graph transformer, with\nits advantages of high performance and scalability compared to traditional\ngraph networks, has been widely explored in recent research for applications of\ngraph structures. However, current transformer-based graph decoders struggle to\neffectively utilize graph information, which limits their capacity to leverage\nonly sequences of nodes rather than the complex topological structures of\nmolecule graphs. This paper focuses on building a graph transformer-based\nframework for molecular generation, which we call \\textbf{JTreeformer} as it\ntransforms graph generation into junction tree generation. It combines GCN\nparallel with multi-head attention as the encoder. It integrates a directed\nacyclic GCN into a graph-based Transformer to serve as a decoder, which can\niteratively synthesize the entire molecule by leveraging information from the\npartially constructed molecular structure at each step. In addition, a\ndiffusion model is inserted in the latent space generated by the encoder, to\nenhance the efficiency and effectiveness of sampling further. The empirical\nresults demonstrate that our novel framework outperforms existing molecule\ngeneration methods, thus offering a promising tool to advance drug discovery\n(https://anonymous.4open.science/r/JTreeformer-C74C).",
      "tldr_zh": "该论文提出 JTreeformer，一种基于 Graph-Transformer 的框架，用于分子生成，通过将图生成转化为连接树生成来更好地利用分子图的拓扑结构。框架采用 GCN 与多头注意力作为编码器，并整合有向无环 GCN 到基于图的 Transformer 解码器，实现逐步合成分子，同时在编码器生成的潜在空间中插入 Latent-Diffusion Model 以提升采样效率。实验结果表明，JTreeformer 优于现有分子生成方法，为药物发现提供了一个有前景的工具。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "9 pages, 6figures",
      "pdf_url": "http://arxiv.org/pdf/2504.20770v1",
      "published_date": "2025-04-29 13:51:07 UTC",
      "updated_date": "2025-04-29 13:51:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:52:44.417048"
    },
    {
      "arxiv_id": "2504.20769v1",
      "title": "Chain-of-Defensive-Thought: Structured Reasoning Elicits Robustness in Large Language Models against Reference Corruption",
      "title_zh": "翻译失败",
      "authors": [
        "Wenxiao Wang",
        "Parsa Hosseini",
        "Soheil Feizi"
      ],
      "abstract": "Chain-of-thought prompting has demonstrated great success in facilitating the\nreasoning abilities of large language models. In this work, we explore how\nthese enhanced reasoning abilities can be exploited to improve the robustness\nof large language models in tasks that are not necessarily reasoning-focused.\nIn particular, we show how a wide range of large language models exhibit\nsignificantly improved robustness against reference corruption using a simple\nmethod called chain-of-defensive-thought, where only a few exemplars with\nstructured and defensive reasoning are provided as demonstrations. Empirically,\nthe improvements can be astounding, especially given the simplicity and\napplicability of the method. For example, in the Natural Questions task, the\naccuracy of GPT-4o degrades from 60% to as low as 3% with standard prompting\nwhen 1 out of 10 references provided is corrupted with prompt injection\nattacks. In contrast, GPT-4o using chain-of-defensive-thought prompting\nmaintains an accuracy of 50%.",
      "tldr_zh": "这篇论文探索了Chain-of-thought prompting如何提升大型语言模型（Large Language Models, LLMs）的鲁棒性，提出了一种简单方法Chain-of-Defensive-Thought，通过提供几个带有结构化和防御性推理的示例作为演示，来帮助模型抵抗参考信息腐败。研究发现，这种方法在非推理任务中表现出色，例如在Natural Questions任务中，GPT-4o的标准提示准确率因1/10的参考被注入攻击而降至3%，而使用Chain-of-Defensive-Thought后，准确率保持在50%。总体而言，该方法以其简易性和广泛适用性，为增强LLMs的可靠性提供了新途径。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.20769v1",
      "published_date": "2025-04-29 13:50:05 UTC",
      "updated_date": "2025-04-29 13:50:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:52:56.473686"
    },
    {
      "arxiv_id": "2505.07828v1",
      "title": "AI-Based Crypto Tokens: The Illusion of Decentralized AI?",
      "title_zh": "翻译失败",
      "authors": [
        "Rischan Mafrur"
      ],
      "abstract": "The convergence of blockchain and artificial intelligence (AI) has led to the\nemergence of AI-based tokens, which are cryptographic assets designed to power\ndecentralized AI platforms and services. This paper provides a comprehensive\nreview of leading AI-token projects, examining their technical architectures,\ntoken utilities, consensus mechanisms, and underlying business models. We\nexplore how these tokens operate across various blockchain ecosystems and\nassess the extent to which they offer value beyond traditional centralized AI\nservices. Based on this assessment, our analysis identifies several core\nlimitations. From a technical perspective, many platforms depend extensively on\noff-chain computation, exhibit limited capabilities for on-chain intelligence,\nand encounter significant scalability challenges. From a business perspective,\nmany models appear to replicate centralized AI service structures, simply\nadding token-based payment and governance layers without delivering truly novel\nvalue. In light of these challenges, we also examine emerging developments that\nmay shape the next phase of decentralized AI systems. These include approaches\nfor on-chain verification of AI outputs, blockchain-enabled federated learning,\nand more robust incentive frameworks. Collectively, while emerging innovations\noffer pathways to strengthen decentralized AI ecosystems, significant gaps\nremain between the promises and the realities of current AI-token\nimplementations. Our findings contribute to a growing body of research at the\nintersection of AI and blockchain, highlighting the need for critical\nevaluation and more grounded approaches as the field continues to evolve.",
      "tldr_zh": "这篇论文对AI-based crypto tokens进行了全面审查，评估了这些加密资产在区块链生态中的技术架构、token utilities、共识机制和商业模型，并探讨它们是否超越传统集中式AI服务。研究发现，这些平台存在核心限制，包括技术层面上的off-chain computation依赖、on-chain intelligence能力不足以及可伸缩性挑战，以及商业层面上对集中式结构的简单复制，仅添加token-based支付和治理层。论文还讨论了潜在的发展方向，如on-chain verification of AI outputs、blockchain-enabled federated learning和更强的激励框架，并呼吁对AI和区块链交叉领域的创新进行批判性评估，以缩小当前AI-token实现的承诺与现实差距。",
      "categories": [
        "cs.DC",
        "cs.AI",
        "cs.CR",
        "cs.DB"
      ],
      "primary_category": "cs.DC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.07828v1",
      "published_date": "2025-04-29 13:44:33 UTC",
      "updated_date": "2025-04-29 13:44:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:53:08.363168"
    },
    {
      "arxiv_id": "2504.21066v1",
      "title": "A Brief Review for Compression and Transfer Learning Techniques in DeepFake Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Andreas Karathanasis",
        "John Violos",
        "Ioannis Kompatsiaris",
        "Symeon Papadopoulos"
      ],
      "abstract": "Training and deploying deepfake detection models on edge devices offers the\nadvantage of maintaining data privacy and confidentiality by processing it\nclose to its source. However, this approach is constrained by the limited\ncomputational and memory resources available at the edge. To address this\nchallenge, we explore compression techniques to reduce computational demands\nand inference time, alongside transfer learning methods to minimize training\noverhead. Using the Synthbuster, RAISE, and ForenSynths datasets, we evaluate\nthe effectiveness of pruning, knowledge distillation (KD), quantization,\nfine-tuning, and adapter-based techniques. Our experimental results demonstrate\nthat both compression and transfer learning can be effectively achieved, even\nwith a high compression level of 90%, remaining at the same performance level\nwhen the training and validation data originate from the same DeepFake model.\nHowever, when the testing dataset is generated by DeepFake models not present\nin the training set, a domain generalization issue becomes evident.",
      "tldr_zh": "这篇论文审视了压缩和迁移学习技术在DeepFake检测中的应用，旨在解决边缘设备资源有限的挑战，从而实现数据隐私保护的同时降低计算需求和训练开销。作者使用Synthbuster、RAISE和ForenSynths数据集，评估了pruning、knowledge distillation (KD)、quantization、fine-tuning和adapter-based等技术。实验结果显示，即使压缩率高达90%，当训练和验证数据来自同一DeepFake模型时，性能保持不变；然而，如果测试数据涉及未见过的DeepFake模型，则会显现domain generalization问题，这突显了模型泛化能力的局限性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.21066v1",
      "published_date": "2025-04-29 13:37:21 UTC",
      "updated_date": "2025-04-29 13:37:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:53:20.378411"
    },
    {
      "arxiv_id": "2504.20756v1",
      "title": "Graph-Based Fault Diagnosis for Rotating Machinery: Adaptive Segmentation and Structural Feature Integration",
      "title_zh": "基于图的旋转机械故障诊断：自适应",
      "authors": [
        "Moirangthem Tiken Singh"
      ],
      "abstract": "This paper proposes a novel graph-based framework for robust and\ninterpretable multiclass fault diagnosis in rotating machinery. The method\nintegrates entropy-optimized signal segmentation, time-frequency feature\nextraction, and graph-theoretic modeling to transform vibration signals into\nstructured representations suitable for classification. Graph metrics, such as\naverage shortest path length, modularity, and spectral gap, are computed and\ncombined with local features to capture global and segment-level fault\ncharacteristics. The proposed method achieves high diagnostic accuracy when\nevaluated on two benchmark datasets, the CWRU bearing dataset (under 0-3 HP\nloads) and the SU gearbox and bearing datasets (under different speed-load\nconfigurations). Classification scores reach up to 99.8% accuracy on Case\nWestern Reserve University (CWRU) and 100% accuracy on the Southeast University\ndatasets using a logistic regression classifier. Furthermore, the model\nexhibits strong noise resilience, maintaining over 95.4% accuracy at high noise\nlevels (standard deviation = 0.5), and demonstrates excellent cross-domain\ntransferability with up to 99.7% F1-score in load-transfer scenarios. Compared\nto traditional techniques, this approach requires no deep learning\narchitecture, enabling lower complexity while ensuring interpretability. The\nresults confirm the method's scalability, reliability, and potential for\nreal-time deployment in industrial diagnostics.",
      "tldr_zh": "本论文提出了一种基于图的框架，用于旋转机械的多类故障诊断，该框架整合熵优化信号分割、时频特征提取和图论建模，将振动信号转化为结构化表示，并结合图指标（如平均最短路径长度、模块度和谱间隙）与局部特征，捕获全局和分段级别的故障特性。实验在CWRU轴承数据集和SU齿轮箱及轴承数据集上评估，实现了高达99.8%和100%的分类准确率，同时在高噪声水平（标准差=0.5）下保持95.4%以上准确率，并展现出优秀的跨域转移能力（F1分数达99.7%）。与传统方法相比，该方法无需深度学习架构，复杂度低，确保可解释性和实时工业诊断的潜力。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.20756v1",
      "published_date": "2025-04-29 13:34:52 UTC",
      "updated_date": "2025-04-29 13:34:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:53:32.542861"
    },
    {
      "arxiv_id": "2504.20752v2",
      "title": "Grokking in the Wild: Data Augmentation for Real-World Multi-Hop Reasoning with Transformers",
      "title_zh": "翻译失败",
      "authors": [
        "Roman Abramov",
        "Felix Steinbauer",
        "Gjergji Kasneci"
      ],
      "abstract": "Transformers have achieved great success in numerous NLP tasks but continue\nto exhibit notable gaps in multi-step factual reasoning, especially when\nreal-world knowledge is sparse. Recent advances in grokking have demonstrated\nthat neural networks can transition from memorizing to perfectly generalizing\nonce they detect underlying logical patterns - yet these studies have primarily\nused small, synthetic tasks. In this paper, for the first time, we extend\ngrokking to real-world factual data and address the challenge of dataset\nsparsity by augmenting existing knowledge graphs with carefully designed\nsynthetic data to raise the ratio $\\phi_r$ of inferred facts to atomic facts\nabove the threshold required for grokking. Surprisingly, we find that even\nfactually incorrect synthetic data can strengthen emergent reasoning circuits\nrather than degrade accuracy, as it forces the model to rely on relational\nstructure rather than memorization. When evaluated on multi-hop reasoning\nbenchmarks, our approach achieves up to 95-100% accuracy on 2WikiMultiHopQA -\nsubstantially improving over strong baselines and matching or exceeding current\nstate-of-the-art results. We further provide an in-depth analysis of how\nincreasing $\\phi_r$ drives the formation of generalizing circuits inside\nTransformers. Our findings suggest that grokking-based data augmentation can\nunlock implicit multi-hop reasoning capabilities, opening the door to more\nrobust and interpretable factual reasoning in large-scale language models.",
      "tldr_zh": "这篇论文首次将 Grokking 概念扩展到真实世界事实数据中，针对 Transformers 在多跳推理中的知识稀缺问题，通过在知识图上添加精心设计的合成数据来提高 inferred facts 与 atomic facts 的比率 φ_r，从而促进模型从记忆向泛化过渡。研究发现，即使是事实错误的合成数据也能增强推理电路，因为它迫使模型依赖关系结构而非简单记忆。在多跳推理基准 2WikiMultiHopQA 上，该方法实现了 95-100% 的准确率，显著优于现有基线，并通过深入分析揭示了增加 φ_r 如何驱动 Transformers 内部泛化电路的形成。总体而言，这为大型语言模型提供了更鲁棒和可解释的多跳推理能力。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG",
        "I.2.7; I.2.6; I.2.3; I.7"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to the International Conference on Machine Learning (ICML)\n  2025",
      "pdf_url": "http://arxiv.org/pdf/2504.20752v2",
      "published_date": "2025-04-29 13:33:29 UTC",
      "updated_date": "2025-05-07 09:47:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:53:46.001048"
    },
    {
      "arxiv_id": "2504.20741v1",
      "title": "In defence of post-hoc explanations in medical AI",
      "title_zh": "翻译失败",
      "authors": [
        "Joshua Hatherley",
        "Lauritz Munch",
        "Jens Christian Bjerring"
      ],
      "abstract": "Since the early days of the Explainable AI movement, post-hoc explanations\nhave been praised for their potential to improve user understanding, promote\ntrust, and reduce patient safety risks in black box medical AI systems.\nRecently, however, critics have argued that the benefits of post-hoc\nexplanations are greatly exaggerated since they merely approximate, rather than\nreplicate, the actual reasoning processes that black box systems take to arrive\nat their outputs. In this article, we aim to defend the value of post-hoc\nexplanations against this recent critique. We argue that even if post-hoc\nexplanations do not replicate the exact reasoning processes of black box\nsystems, they can still improve users' functional understanding of black box\nsystems, increase the accuracy of clinician-AI teams, and assist clinicians in\njustifying their AI-informed decisions. While post-hoc explanations are not a\n\"silver bullet\" solution to the black box problem in medical AI, we conclude\nthat they remain a useful strategy for addressing the black box problem in\nmedical AI.",
      "tldr_zh": "本论文为post-hoc explanations（事后解释）在医疗AI中的应用进行辩护，反驳了批评者声称这些解释无法精确复制黑 box systems（黑箱系统）的实际推理过程，从而夸大其益处的观点。作者论证，即使post-hoc explanations仅是近似推理，它们仍能提升用户对系统的功能理解、提高临床医生-AI团队的决策准确性，并帮助临床医生证明AI-informed决策的合理性。尽管post-hoc explanations不是解决黑箱问题的“银弹”方案，但论文认为它们仍是医疗AI中一个宝贵的策略。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CY",
        "cs.LG"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.20741v1",
      "published_date": "2025-04-29 13:24:21 UTC",
      "updated_date": "2025-04-29 13:24:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:53:55.019490"
    },
    {
      "arxiv_id": "2504.20734v2",
      "title": "UniversalRAG: Retrieval-Augmented Generation over Corpora of Diverse Modalities and Granularities",
      "title_zh": "翻译失败",
      "authors": [
        "Woongyeong Yeo",
        "Kangsan Kim",
        "Soyeong Jeong",
        "Jinheon Baek",
        "Sung Ju Hwang"
      ],
      "abstract": "Retrieval-Augmented Generation (RAG) has shown substantial promise in\nimproving factual accuracy by grounding model responses with external knowledge\nrelevant to queries. However, most existing RAG approaches are limited to a\ntext-only corpus, and while recent efforts have extended RAG to other\nmodalities such as images and videos, they typically operate over a single\nmodality-specific corpus. In contrast, real-world queries vary widely in the\ntype of knowledge they require, which a single type of knowledge source cannot\naddress. To address this, we introduce UniversalRAG, a novel RAG framework\ndesigned to retrieve and integrate knowledge from heterogeneous sources with\ndiverse modalities and granularities. Specifically, motivated by the\nobservation that forcing all modalities into a unified representation space\nderived from a single aggregated corpus causes a modality gap, where the\nretrieval tends to favor items from the same modality as the query, we propose\na modality-aware routing mechanism that dynamically identifies the most\nappropriate modality-specific corpus and performs targeted retrieval within it.\nAlso, beyond modality, we organize each modality into multiple granularity\nlevels, enabling fine-tuned retrieval tailored to the complexity and scope of\nthe query. We validate UniversalRAG on 8 benchmarks spanning multiple\nmodalities, showing its superiority over various modality-specific and unified\nbaselines.",
      "tldr_zh": "该研究提出 UniversalRAG，一种新型 Retrieval-Augmented Generation (RAG) 框架，旨在从多样模态（如文本、图像和视频）和不同粒度的异构语料库中检索并整合知识，以更好地处理真实世界查询的需求。UniversalRAG 通过模态感知路由机制（modality-aware routing）动态识别最合适的模态特定语料库，并针对查询的复杂性进行细化检索，从而避免了模态间差距问题。实验在 8 个跨模态基准上验证了其优越性，超越了模态特定和统一基线模型。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CV",
        "cs.IR",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Project page : https://universalrag.github.io",
      "pdf_url": "http://arxiv.org/pdf/2504.20734v2",
      "published_date": "2025-04-29 13:18:58 UTC",
      "updated_date": "2025-05-19 11:09:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:54:08.443207"
    },
    {
      "arxiv_id": "2504.20733v1",
      "title": "Unsupervised Surrogate Anomaly Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Simon Klüttermann",
        "Tim Katzke",
        "Emmanuel Müller"
      ],
      "abstract": "In this paper, we study unsupervised anomaly detection algorithms that learn\na neural network representation, i.e. regular patterns of normal data, which\nanomalies are deviating from. Inspired by a similar concept in engineering, we\nrefer to our methodology as surrogate anomaly detection. We formalize the\nconcept of surrogate anomaly detection into a set of axioms required for\noptimal surrogate models and propose a new algorithm, named DEAN (Deep Ensemble\nANomaly detection), designed to fulfill these criteria. We evaluate DEAN on 121\nbenchmark datasets, demonstrating its competitive performance against 19\nexisting methods, as well as the scalability and reliability of our method.",
      "tldr_zh": "本论文研究无监督的 surrogate anomaly detection 方法，通过学习神经网络表示正常数据的常规模式来识别异常。作者将 surrogate anomaly detection 概念形式化为一组优化 surrogate 模型的公理，并提出新算法 DEAN (Deep Ensemble ANomaly detection)，旨在满足这些公理。在 121 个基准数据集上的实验表明，DEAN 与 19 种现有方法相比表现出竞争性性能，并证明了其可扩展性和可靠性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "13 pages + references and appendix = 35 pages",
      "pdf_url": "http://arxiv.org/pdf/2504.20733v1",
      "published_date": "2025-04-29 13:15:55 UTC",
      "updated_date": "2025-04-29 13:15:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:54:20.583655"
    },
    {
      "arxiv_id": "2504.20726v1",
      "title": "Enhancing Vulnerability Reports with Automated and Augmented Description Summarization",
      "title_zh": "翻译失败",
      "authors": [
        "Hattan Althebeiti",
        "Mohammed Alkinoon",
        "Manar Mohaisen",
        "Saeed Salem",
        "DaeHun Nyang",
        "David Mohaisen"
      ],
      "abstract": "Public vulnerability databases, such as the National Vulnerability Database\n(NVD), document vulnerabilities and facilitate threat information sharing.\nHowever, they often suffer from short descriptions and outdated or insufficient\ninformation. In this paper, we introduce Zad, a system designed to enrich NVD\nvulnerability descriptions by leveraging external resources. Zad consists of\ntwo pipelines: one collects and filters supplementary data using two encoders\nto build a detailed dataset, while the other fine-tunes a pre-trained model on\nthis dataset to generate enriched descriptions. By addressing brevity and\nimproving content quality, Zad produces more comprehensive and cohesive\nvulnerability descriptions. We evaluate Zad using standard summarization\nmetrics and human assessments, demonstrating its effectiveness in enhancing\nvulnerability information.",
      "tldr_zh": "该研究针对公共漏洞数据库如NVD的描述简短和信息不足问题，提出Zad系统，通过利用外部资源来丰富漏洞描述。Zad包括两个管道：一个使用两个编码器收集并过滤补充数据以构建详细数据集，另一个则在该数据集上微调预训练模型生成更全面和连贯的描述。实验结果通过标准摘要指标和人工评估证明，Zad显著提升了漏洞信息的质量和完整性。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "12 pages, 3 tables, 12 figures. Accepted for publication in IEEE\n  Transactions on Big Data. Extended version of arXiv:2210.01260",
      "pdf_url": "http://arxiv.org/pdf/2504.20726v1",
      "published_date": "2025-04-29 13:08:27 UTC",
      "updated_date": "2025-04-29 13:08:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:54:31.037836"
    },
    {
      "arxiv_id": "2505.00733v1",
      "title": "ROSA: A Knowledge-based Solution for Robot Self-Adaptation",
      "title_zh": "ROSA：基于知识的机器人自适应解决方案",
      "authors": [
        "Gustavo Rezende Silva",
        "Juliane Päßler",
        "S. Lizeth Tapia Tarifa",
        "Einar Broch Johnsen",
        "Carlos Hernández Corbato"
      ],
      "abstract": "Autonomous robots must operate in diverse environments and handle multiple\ntasks despite uncertainties. This creates challenges in designing software\narchitectures and task decision-making algorithms, as different contexts may\nrequire distinct task logic and architectural configurations. To address this,\nrobotic systems can be designed as self-adaptive systems capable of adapting\ntheir task execution and software architecture at runtime based on their\ncontext.This paper introduces ROSA, a novel knowledge-based framework for RObot\nSelf-Adaptation, which enables task-and-architecture co-adaptation (TACA) in\nrobotic systems. ROSA achieves this by providing a knowledge model that\ncaptures all application-specific knowledge required for adaptation and by\nreasoning over this knowledge at runtime to determine when and how adaptation\nshould occur. In addition to a conceptual framework, this work provides an\nopen-source ROS 2-based reference implementation of ROSA and evaluates its\nfeasibility and performance in an underwater robotics application. Experimental\nresults highlight ROSA's advantages in reusability and development effort for\ndesigning self-adaptive robotic systems.",
      "tldr_zh": "该论文提出ROSA，一种基于知识的框架，用于解决自主机器人面对多样环境和不确定性时，在软件架构和任务决策方面的适应挑战。ROSA通过一个知识模型捕获应用程序特定知识，并在运行时进行推理，实现任务和架构的共同适应(TACA)。该框架提供概念设计、开源ROS 2参考实现，并在水下机器人应用中进行评估，结果显示ROSA显著提高了系统的可重用性和开发效率。",
      "categories": [
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.00733v1",
      "published_date": "2025-04-29 12:49:45 UTC",
      "updated_date": "2025-04-29 12:49:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:54:43.317994"
    },
    {
      "arxiv_id": "2504.20708v1",
      "title": "Beyond the Last Answer: Your Reasoning Trace Uncovers More than You Think",
      "title_zh": "超越最后的答案：你的推理轨迹揭示了比你想象中更多的内容",
      "authors": [
        "Hasan Abed Al Kader Hammoud",
        "Hani Itani",
        "Bernard Ghanem"
      ],
      "abstract": "Large Language Models (LLMs) leverage step-by-step reasoning to solve complex\nproblems. Standard evaluation practice involves generating a complete reasoning\ntrace and assessing the correctness of the final answer presented at its\nconclusion. In this paper, we challenge the reliance on the final answer by\nposing the following two questions: Does the final answer reliably represent\nthe model's optimal conclusion? Can alternative reasoning paths yield different\nresults? To answer these questions, we analyze intermediate reasoning steps,\ntermed subthoughts, and propose a method based on our findings. Our approach\ninvolves segmenting a reasoning trace into sequential subthoughts based on\nlinguistic cues. We start by prompting the model to generate continuations from\nthe end-point of each intermediate subthought. We extract a potential answer\nfrom every completed continuation originating from different subthoughts. We\nfind that aggregating these answers by selecting the most frequent one (the\nmode) often yields significantly higher accuracy compared to relying solely on\nthe answer derived from the original complete trace. Analyzing the consistency\namong the answers derived from different subthoughts reveals characteristics\nthat correlate with the model's confidence and correctness, suggesting\npotential for identifying less reliable answers. Our experiments across various\nLLMs and challenging mathematical reasoning datasets (AIME2024 and AIME2025)\nshow consistent accuracy improvements, with gains reaching up to 13\\% and 10\\%\nrespectively. Implementation is available at:\nhttps://github.com/hammoudhasan/SubthoughtReasoner.",
      "tldr_zh": "本文质疑了大语言模型(LLMs)推理评估中仅依赖最终答案的可靠性，提出通过分析中间推理步骤(subthoughts)来挖掘更准确的结论。研究方法包括将推理痕迹分割成顺序子思考，并从每个子思考的终点生成延续、提取潜在答案，然后通过取众数聚合这些答案，结果显示准确率显著提升。实验在不同 LLMs 和数学推理数据集(AIME2024 和 AIME2025)上验证了这一方法，准确率分别提高了高达 13% 和 10%，并揭示了答案一致性与模型信心和正确性的相关性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Preprint",
      "pdf_url": "http://arxiv.org/pdf/2504.20708v1",
      "published_date": "2025-04-29 12:39:07 UTC",
      "updated_date": "2025-04-29 12:39:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:54:56.484223"
    },
    {
      "arxiv_id": "2504.20699v1",
      "title": "Can LLMs Detect Intrinsic Hallucinations in Paraphrasing and Machine Translation?",
      "title_zh": "大型语言模型能否检测改写和机器翻译中的内在幻觉？",
      "authors": [
        "Evangelia Gogoulou",
        "Shorouq Zahra",
        "Liane Guillou",
        "Luise Dürlich",
        "Joakim Nivre"
      ],
      "abstract": "A frequently observed problem with LLMs is their tendency to generate output\nthat is nonsensical, illogical, or factually incorrect, often referred to\nbroadly as hallucination. Building on the recently proposed HalluciGen task for\nhallucination detection and generation, we evaluate a suite of open-access LLMs\non their ability to detect intrinsic hallucinations in two conditional\ngeneration tasks: translation and paraphrasing. We study how model performance\nvaries across tasks and language and we investigate the impact of model size,\ninstruction tuning, and prompt choice. We find that performance varies across\nmodels but is consistent across prompts. Finally, we find that NLI models\nperform comparably well, suggesting that LLM-based detectors are not the only\nviable option for this specific task.",
      "tldr_zh": "这篇论文评估了大型语言模型 (LLMs) 在检测翻译和改写任务中的内在幻觉能力，包括 nonsensical、illogical 或事实错误的输出。研究基于 HalluciGen 任务，对开源 LLMs 进行了实验，考察了性能在不同任务、语言、模型大小、指令微调和提示选择下的变化。结果显示，模型性能因模型而异，但提示选择的影响相对一致，且 NLI 模型的表现与 LLMs 相当，表明幻觉检测并非仅依赖 LLMs。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.20699v1",
      "published_date": "2025-04-29 12:30:05 UTC",
      "updated_date": "2025-04-29 12:30:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:55:07.976514"
    },
    {
      "arxiv_id": "2504.20676v1",
      "title": "The Limits of AI Explainability: An Algorithmic Information Theory Approach",
      "title_zh": "AI可解释性的极限：一种算法信息理论方法",
      "authors": [
        "Shrisha Rao"
      ],
      "abstract": "This paper establishes a theoretical foundation for understanding the\nfundamental limits of AI explainability through algorithmic information theory.\nWe formalize explainability as the approximation of complex models by simpler\nones, quantifying both approximation error and explanation complexity using\nKolmogorov complexity. Our key theoretical contributions include: (1) a\ncomplexity gap theorem proving that any explanation significantly simpler than\nthe original model must differ from it on some inputs; (2) precise bounds\nshowing that explanation complexity grows exponentially with input dimension\nbut polynomially with error tolerance for Lipschitz functions; and (3) a\ncharacterization of the gap between local and global explainability,\ndemonstrating that local explanations can be significantly simpler while\nmaintaining accuracy in relevant regions. We further establish a regulatory\nimpossibility theorem proving that no governance framework can simultaneously\npursue unrestricted AI capabilities, human-interpretable explanations, and\nnegligible error. These results highlight considerations likely to be relevant\nto the design, evaluation, and oversight of explainable AI systems.",
      "tldr_zh": "本论文使用算法信息理论探讨 AI 可解释性的根本限制，将可解释性形式化为用简单模型近似复杂模型，并通过 Kolmogorov complexity 量化近似误差和解释复杂性。主要贡献包括：(1) 复杂度差距定理，证明任何显著更简单的解释必须在某些输入上与原模型不同；(2) 精确边界，显示解释复杂性随输入维度指数增长，但对 Lipschitz functions 的误差容忍度呈多项式增长；(3) 局部与全局可解释性的差距分析，表明局部解释可在相关区域保持准确性同时更简单。此外，该论文提出监管不可能定理，证明无法同时实现不受限的 AI 能力、人可解释的解释和可忽略的误差，这些发现将影响可解释 AI 系统的设计、评估和监管。",
      "categories": [
        "cs.AI",
        "cs.CY",
        "cs.IT",
        "math.IT",
        "68Q30, 68T01",
        "I.2.0; H.1.1; K.4.1"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.20676v1",
      "published_date": "2025-04-29 11:58:37 UTC",
      "updated_date": "2025-04-29 11:58:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:55:21.024040"
    },
    {
      "arxiv_id": "2504.20673v1",
      "title": "CoCo-Bench: A Comprehensive Code Benchmark For Multi-task Large Language Model Evaluation",
      "title_zh": "翻译失败",
      "authors": [
        "Wenjing Yin",
        "Tianze Sun",
        "Yijiong Yu",
        "Jiawei Fang",
        "Guangyao Su",
        "Jiancheng Wang",
        "Zekun Wang",
        "Wei Wang",
        "Ran Chen",
        "Ziyun Dai",
        "Shuai Yuan",
        "Menghang Dong",
        "Peng Luo",
        "Dong Cao",
        "Da Lei",
        "Yajun Zhang",
        "Hao Chen",
        "Xiang Ma",
        "Yong Liu",
        "Weifeng Liu",
        "Yuanjian Xu",
        "Ji Pei"
      ],
      "abstract": "Large language models (LLMs) play a crucial role in software engineering,\nexcelling in tasks like code generation and maintenance. However, existing\nbenchmarks are often narrow in scope, focusing on a specific task and lack a\ncomprehensive evaluation framework that reflects real-world applications. To\naddress these gaps, we introduce CoCo-Bench (Comprehensive Code Benchmark),\ndesigned to evaluate LLMs across four critical dimensions: code understanding,\ncode generation, code modification, and code review. These dimensions capture\nessential developer needs, ensuring a more systematic and representative\nevaluation. CoCo-Bench includes multiple programming languages and varying task\ndifficulties, with rigorous manual review to ensure data quality and accuracy.\nEmpirical results show that CoCo-Bench aligns with existing benchmarks while\nuncovering significant variations in model performance, effectively\nhighlighting strengths and weaknesses. By offering a holistic and objective\nevaluation, CoCo-Bench provides valuable insights to guide future research and\ntechnological advancements in code-oriented LLMs, establishing a reliable\nbenchmark for the field.",
      "tldr_zh": "本论文提出了 CoCo-Bench，一个全面的代码基准，用于评估多任务 Large Language Models (LLMs) 在软件工程中的性能，旨在解决现有基准范围狭窄和缺乏系统框架的问题。CoCo-Bench 涵盖四个关键维度：code understanding、code generation、code modification 和 code review，同时支持多种编程语言、不同难度任务，并通过严格的手动审查确保数据质量。实验结果显示，该基准与现有评估一致，但突出了模型性能的显著差异，提供宝贵的见解来指导代码导向 LLMs 的未来研究和发展。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "Submitted to ACL 2025. Under review",
      "pdf_url": "http://arxiv.org/pdf/2504.20673v1",
      "published_date": "2025-04-29 11:57:23 UTC",
      "updated_date": "2025-04-29 11:57:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:55:32.172519"
    },
    {
      "arxiv_id": "2504.21065v1",
      "title": "A 3D pocket-aware and affinity-guided diffusion model for lead optimization",
      "title_zh": "一种 3D 结合口袋感知和亲和力引导的扩散模型，用于先导优化",
      "authors": [
        "Anjie Qiao",
        "Junjie Xie",
        "Weifeng Huang",
        "Hao Zhang",
        "Jiahua Rao",
        "Shuangjia Zheng",
        "Yuedong Yang",
        "Zhen Wang",
        "Guo-Bo Li",
        "Jinping Lei"
      ],
      "abstract": "Molecular optimization, aimed at improving binding affinity or other\nmolecular properties, is a crucial task in drug discovery that often relies on\nthe expertise of medicinal chemists. Recently, deep learning-based 3D\ngenerative models showed promise in enhancing the efficiency of molecular\noptimization. However, these models often struggle to adequately consider\nbinding affinities with protein targets during lead optimization. Herein, we\npropose a 3D pocket-aware and affinity-guided diffusion model, named Diffleop,\nto optimize molecules with enhanced binding affinity. The model explicitly\nincorporates the knowledge of protein-ligand binding affinity to guide the\ndenoising sampling for molecule generation with high affinity. The\ncomprehensive evaluations indicated that Diffleop outperforms baseline models\nacross multiple metrics, especially in terms of binding affinity.",
      "tldr_zh": "该研究针对药物发现中的分子优化问题，提出了一种名为Diffleop的3D pocket-aware and affinity-guided diffusion model，以提升分子与蛋白靶点的结合亲和力。该模型通过整合蛋白-配体结合亲和力知识来指导分子的去噪采样过程，从而生成具有高亲和力的优化分子。在多项指标的全面评估中，Diffleop显著优于基线模型，尤其在结合亲和力方面表现出色。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.21065v1",
      "published_date": "2025-04-29 11:52:42 UTC",
      "updated_date": "2025-04-29 11:52:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:55:44.901919"
    },
    {
      "arxiv_id": "2504.20669v1",
      "title": "Advance Fake Video Detection via Vision Transformers",
      "title_zh": "翻译失败",
      "authors": [
        "Joy Battocchio",
        "Stefano Dell'Anna",
        "Andrea Montibeller",
        "Giulia Boato"
      ],
      "abstract": "Recent advancements in AI-based multimedia generation have enabled the\ncreation of hyper-realistic images and videos, raising concerns about their\npotential use in spreading misinformation. The widespread accessibility of\ngenerative techniques, which allow for the production of fake multimedia from\nprompts or existing media, along with their continuous refinement, underscores\nthe urgent need for highly accurate and generalizable AI-generated media\ndetection methods, underlined also by new regulations like the European Digital\nAI Act. In this paper, we draw inspiration from Vision Transformer (ViT)-based\nfake image detection and extend this idea to video. We propose an {original}\n%innovative framework that effectively integrates ViT embeddings over time to\nenhance detection performance. Our method shows promising accuracy,\ngeneralization, and few-shot learning capabilities across a new, large and\ndiverse dataset of videos generated using five open source generative\ntechniques from the state-of-the-art, as well as a separate dataset containing\nvideos produced by proprietary generative methods.",
      "tldr_zh": "该论文针对AI生成假视频可能传播误信息的风险，提出了一种基于Vision Transformers (ViT)的创新检测框架，以扩展假图像检测到视频领域。该框架通过在时间维度上整合ViT嵌入，提升了检测的准确性和泛化能力，并在少样本学习场景下表现出色。在一个大型、多样数据集上，该方法对使用五种开源生成技术和专有方法的视频进行了测试，实现了显著的性能提升。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.MM"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.20669v1",
      "published_date": "2025-04-29 11:51:07 UTC",
      "updated_date": "2025-04-29 11:51:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:55:56.249236"
    },
    {
      "arxiv_id": "2504.20658v1",
      "title": "TrueFake: A Real World Case Dataset of Last Generation Fake Images also Shared on Social Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Stefano Dell'Anna",
        "Andrea Montibeller",
        "Giulia Boato"
      ],
      "abstract": "AI-generated synthetic media are increasingly used in real-world scenarios,\noften with the purpose of spreading misinformation and propaganda through\nsocial media platforms, where compression and other processing can degrade fake\ndetection cues. Currently, many forensic tools fail to account for these\nin-the-wild challenges. In this work, we introduce TrueFake, a large-scale\nbenchmarking dataset of 600,000 images including top notch generative\ntechniques and sharing via three different social networks. This dataset allows\nfor rigorous evaluation of state-of-the-art fake image detectors under very\nrealistic and challenging conditions. Through extensive experimentation, we\nanalyze how social media sharing impacts detection performance, and identify\ncurrent most effective detection and training strategies. Our findings\nhighlight the need for evaluating forensic models in conditions that mirror\nreal-world use.",
      "tldr_zh": "本文引入了 TrueFake 数据集，这是一个包含 60 万张图像的大型基准，用于评估 AI-generated synthetic media 在真实世界社交网络环境下的检测性能。数据集涵盖了顶尖生成技术和通过三个社交平台的分享过程，模拟了图像压缩和其他处理对假图像检测线索的降级影响。通过广泛实验，研究分析了社交媒体分享对检测器性能的影响，并识别了当前最有效的检测和训练策略。结果强调了在模拟真实条件中评估取证模型的必要性，以更好地应对传播误信息的问题。",
      "categories": [
        "cs.MM",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.MM",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.20658v1",
      "published_date": "2025-04-29 11:33:52 UTC",
      "updated_date": "2025-04-29 11:33:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:56:08.584685"
    },
    {
      "arxiv_id": "2504.20656v1",
      "title": "Federated learning, ethics, and the double black box problem in medical AI",
      "title_zh": "翻译失败",
      "authors": [
        "Joshua Hatherley",
        "Anders Søgaard",
        "Angela Ballantyne",
        "Ruben Pauwels"
      ],
      "abstract": "Federated learning (FL) is a machine learning approach that allows multiple\ndevices or institutions to collaboratively train a model without sharing their\nlocal data with a third-party. FL is considered a promising way to address\npatient privacy concerns in medical artificial intelligence. The ethical risks\nof medical FL systems themselves, however, have thus far been underexamined.\nThis paper aims to address this gap. We argue that medical FL presents a new\nvariety of opacity -- federation opacity -- that, in turn, generates a\ndistinctive double black box problem in healthcare AI. We highlight several\ninstances in which the anticipated benefits of medical FL may be exaggerated,\nand conclude by highlighting key challenges that must be overcome to make FL\nethically feasible in medicine.",
      "tldr_zh": "这篇论文探讨了Federated learning (FL) 在医疗AI中的伦理风险，强调FL虽然能通过协作训练模型而无需共享本地数据来保护患者隐私，但引入了一种新的不透明性，即federation opacity，导致了医疗AI的独特双重 black box problem。作者论证了FL的预期益处可能被夸大，并指出了若干关键挑战，如模型解释性和伦理可行性，必须加以克服才能在医学领域推广FL。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CY",
        "cs.HC"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.20656v1",
      "published_date": "2025-04-29 11:31:48 UTC",
      "updated_date": "2025-04-29 11:31:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:56:20.862151"
    },
    {
      "arxiv_id": "2504.20648v1",
      "title": "SpaRE: Enhancing Spatial Reasoning in Vision-Language Models with Synthetic Data",
      "title_zh": "翻译失败",
      "authors": [
        "Michael Ogezi",
        "Freda Shi"
      ],
      "abstract": "Vision-language models (VLMs) work well in tasks ranging from image\ncaptioning to visual question answering (VQA), yet they struggle with spatial\nreasoning, a key skill for understanding our physical world that humans excel\nat. We find that spatial relations are generally rare in widely used VL\ndatasets, with only a few being well represented, while most form a long tail\nof underrepresented relations. This gap leaves VLMs ill-equipped to handle\ndiverse spatial relationships. To bridge it, we construct a synthetic VQA\ndataset focused on spatial reasoning generated from hyper-detailed image\ndescriptions in Localized Narratives, DOCCI, and PixMo-Cap. Our dataset\nconsists of 455k samples containing 3.4 million QA pairs. Trained on this\ndataset, our Spatial-Reasoning Enhanced (SpaRE) VLMs show strong improvements\non spatial reasoning benchmarks, achieving up to a 49% performance gain on the\nWhat's Up benchmark, while maintaining strong results on general tasks. Our\nwork narrows the gap between human and VLM spatial reasoning and makes VLMs\nmore capable in real-world tasks such as robotics and navigation.",
      "tldr_zh": "这项研究发现，Vision-Language Models (VLMs) 在图像描述和视觉问答 (VQA) 等任务上表现出色，但存在空间推理能力的不足，因为常用数据集中的空间关系分布不均。研究者构建了一个合成 VQA 数据集，使用 Localized Narratives、DOCCI 和 PixMo-Cap 中的详细图像描述生成，共包含 455k 样本和 340 万 QA 对。训练后的 SpaRE 模型在空间推理基准上实现了显著提升，例如在 What's Up 基准上性能提升 49%，同时保持了在一般任务上的强劲表现。该工作有助于缩小人类与 VLM 在空间推理上的差距，并提升模型在机器人和导航等现实应用中的能力。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.20648v1",
      "published_date": "2025-04-29 11:18:38 UTC",
      "updated_date": "2025-04-29 11:18:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:56:33.462289"
    },
    {
      "arxiv_id": "2504.20643v1",
      "title": "Cooking Up Creativity: A Cognitively-Inspired Approach for Enhancing LLM Creativity through Structured Representations",
      "title_zh": "翻译失败",
      "authors": [
        "Moran Mizrahi",
        "Chen Shani",
        "Gabriel Stanovsky",
        "Dan Jurafsky",
        "Dafna Shahaf"
      ],
      "abstract": "Large Language Models (LLMs) excel at countless tasks, yet struggle with\ncreativity. In this paper, we introduce a novel approach that couples LLMs with\nstructured representations and cognitively inspired manipulations to generate\nmore creative and diverse ideas. Our notion of creativity goes beyond\nsuperficial token-level variations; rather, we explicitly recombine structured\nrepresentations of existing ideas, allowing our algorithm to effectively\nexplore the more abstract landscape of ideas. We demonstrate our approach in\nthe culinary domain with DishCOVER, a model that generates creative recipes.\nExperiments comparing our model's results to those of GPT-4o show greater\ndiversity. Domain expert evaluations reveal that our outputs, which are mostly\ncoherent and feasible culinary creations, significantly surpass GPT-4o in terms\nof novelty, thus outperforming it in creative generation. We hope our work\ninspires further research into structured creativity in AI.",
      "tldr_zh": "这篇论文提出了一种认知启发的创新方法，通过结构化表示和操作来提升LLMs（Large Language Models）的创造力，超越了表面的token-level变化，转而探索抽象想法空间的重组。研究在烹饪领域开发了DishCOVER模型，用于生成更具多样性和新颖性的创意食谱。实验结果显示，与GPT-4o相比，DishCOVER的输出在多样性上更出色，且领域专家评估确认其在新颖性方面显著优于GPT-4o，同时保持了大多数输出的连贯性和可行性。该工作旨在激发AI中结构化创造力的进一步研究。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "10 pages, 8 figures",
      "pdf_url": "http://arxiv.org/pdf/2504.20643v1",
      "published_date": "2025-04-29 11:13:06 UTC",
      "updated_date": "2025-04-29 11:13:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:56:45.433612"
    },
    {
      "arxiv_id": "2504.21064v1",
      "title": "Frequency Feature Fusion Graph Network For Depression Diagnosis Via fNIRS",
      "title_zh": "fNIRS 频率特征融合图",
      "authors": [
        "Chengkai Yang",
        "Xingping Dong",
        "Xiaofen Zong"
      ],
      "abstract": "Data-driven approaches for depression diagnosis have emerged as a significant\nresearch focus in neuromedicine, driven by the development of relevant\ndatasets. Recently, graph neural network (GNN)-based models have gained\nwidespread adoption due to their ability to capture brain channel functional\nconnectivity from both spatial and temporal perspectives. However, their\neffectiveness is hindered by the absence of a robust temporal biomarker. In\nthis paper, we introduce a novel and effective biomarker for depression\ndiagnosis by leveraging the discrete Fourier transform (DFT) and propose a\ncustomized graph network architecture based on Temporal Graph Convolutional\nNetwork (TGCN). Our model was trained on a dataset comprising 1,086 subjects,\nwhich is over 10 times larger than previous datasets in the field of depression\ndiagnosis. Furthermore, to align with medical requirements, we performed\npropensity score matching (PSM) to create a refined subset, referred to as the\nPSM dataset. Experimental results demonstrate that incorporating our newly\ndesigned biomarker enhances the representation of temporal characteristics in\nbrain channels, leading to improved F1 scores in both the real-world dataset\nand the PSM dataset. This advancement has the potential to contribute to the\ndevelopment of more effective depression diagnostic tools. In addition, we used\nSHapley Additive exPlaination (SHAP) to validate the interpretability of our\nmodel, ensuring its practical applicability in medical settings.",
      "tldr_zh": "本研究针对使用fNIRS进行抑郁症诊断的问题，提出了一种Frequency Feature Fusion Graph Network，通过引入基于离散傅里叶变换(DFT)的新时间生物标记物，增强了图神经网络(GNN)对脑通道空间和时间特征的捕捉。模型基于Temporal Graph Convolutional Network (TGCN)架构，在一个包含1086个受试者的数据集上训练，并通过倾向评分匹配(PSM)处理数据以满足医疗需求。实验结果显示，该方法显著提高了F1分数，在真实数据集和PSM子集上均表现出色，并利用SHapley Additive exPlaination (SHAP)验证了模型的可解释性，为更有效的抑郁诊断工具开发提供了新途径。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.21064v1",
      "published_date": "2025-04-29 11:10:05 UTC",
      "updated_date": "2025-04-29 11:10:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:56:56.327968"
    },
    {
      "arxiv_id": "2504.21063v1",
      "title": "Token-Level Prompt Mixture with Parameter-Free Routing for Federated Domain Generalization",
      "title_zh": "翻译失败",
      "authors": [
        "Shuai Gong",
        "Chaoran Cui",
        "Xiaolin Dong",
        "Xiushan Nie",
        "Lei Zhu",
        "Xiaojun Chang"
      ],
      "abstract": "Federated domain generalization (FedDG) aims to learn a globally\ngeneralizable model from decentralized clients with heterogeneous data while\npreserving privacy. Recent studies have introduced prompt learning to adapt\nvision-language models (VLMs) in FedDG by learning a single global prompt.\nHowever, such a one-prompt-fits-all learning paradigm typically leads to\nperformance degradation on personalized samples. Although the mixture of\nexperts (MoE) offers a promising solution for specialization, existing\nMoE-based methods suffer from coarse image-level expert assignment and high\ncommunication costs from parameterized routers. To address these limitations,\nwe propose TRIP, a Token-level prompt mixture with parameter-free routing\nframework for FedDG, which treats multiple prompts as distinct experts. Unlike\nexisting image-level routing designs, TRIP assigns different tokens within an\nimage to specific experts. To ensure communication efficiency, TRIP\nincorporates a parameter-free routing mechanism based on token clustering and\noptimal transport. The instance-specific prompt is then synthesized by\naggregating experts, weighted by the number of tokens assigned to each.\nAdditionally, TRIP develops an unbiased learning strategy for prompt experts,\nleveraging the VLM's zero-shot generalization capability. Extensive experiments\nacross four benchmarks demonstrate that TRIP achieves optimal generalization\nresults, with communication of only 1K parameters per round. Our code is\navailable at https://github.com/GongShuai8210/TRIP.",
      "tldr_zh": "这篇论文针对 Federated Domain Generalization (FedDG) 提出 TRIP 框架，通过 Token-level prompt mixture 和 parameter-free routing 来处理分散客户端的异构数据，同时保护隐私。TRIP 将图像中的不同 token 分配给多个提示专家，利用基于 token 聚类和最优传输的无参数路由机制，实现高效通信和实例特定提示的合成，并结合 VLM 的零样本泛化能力进行无偏学习。实验在四个基准上证明，TRIP 实现了最佳的泛化性能，每轮仅需通信 1K 参数。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "The manuscript has been submitted to IEEE Transactions on Knowledge\n  and Data Engineering",
      "pdf_url": "http://arxiv.org/pdf/2504.21063v1",
      "published_date": "2025-04-29 11:06:03 UTC",
      "updated_date": "2025-04-29 11:06:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:57:09.146259"
    },
    {
      "arxiv_id": "2504.20634v1",
      "title": "On Stochastic Rounding with Few Random Bits",
      "title_zh": "翻译失败",
      "authors": [
        "Andrew Fitzgibbon",
        "Stephen Felix"
      ],
      "abstract": "Large-scale numerical computations make increasing use of low-precision (LP)\nfloating point formats and mixed precision arithmetic, which can be enhanced by\nthe technique of stochastic rounding (SR), that is, rounding an intermediate\nhigh-precision value up or down randomly as a function of the value's distance\nto the two rounding candidates. Stochastic rounding requires, in addition to\nthe high-precision input value, a source of random bits. As the provision of\nhigh-quality random bits is an additional computational cost, it is of interest\nto require as few bits as possible while maintaining the desirable properties\nof SR in a given computation, or computational domain. This paper examines a\nnumber of possible implementations of few-bit stochastic rounding (FBSR), and\nshows how several natural implementations can introduce sometimes significant\nbias into the rounding process, which are not present in the case of\ninfinite-bit, infinite-precision examinations of these implementations. The\npaper explores the impact of these biases in machine learning examples, and\nhence opens another class of configuration parameters of which practitioners\nshould be aware when developing or adopting low-precision floating point. Code\nis available at\nhttp://github.com/graphcore-research/arith25-stochastic-rounding.",
      "tldr_zh": "这篇论文探讨了在低精度浮点计算中，使用少量随机位的随机舍入(Stochastic Rounding, SR)技术，以减少随机位生成带来的额外成本。研究分析了多种 Few-Bit Stochastic Rounding (FBSR) 实现的潜在问题，发现某些实现会引入显著偏差，这些偏差在无限位无限精度条件下不明显。实验通过机器学习示例验证了这些偏差的影响，并为开发或采用低精度浮点格式的从业者提供了配置参数的注意事项和指导。",
      "categories": [
        "math.NA",
        "cs.AI",
        "cs.LG",
        "cs.MS",
        "cs.NA"
      ],
      "primary_category": "math.NA",
      "comment": "Published at ARITH 2025",
      "pdf_url": "http://arxiv.org/pdf/2504.20634v1",
      "published_date": "2025-04-29 11:04:25 UTC",
      "updated_date": "2025-04-29 11:04:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:57:21.496816"
    },
    {
      "arxiv_id": "2504.20629v1",
      "title": "AlignDiT: Multimodal Aligned Diffusion Transformer for Synchronized Speech Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Jeongsoo Choi",
        "Ji-Hoon Kim",
        "Kim Sung-Bin",
        "Tae-Hyun Oh",
        "Joon Son Chung"
      ],
      "abstract": "In this paper, we address the task of multimodal-to-speech generation, which\naims to synthesize high-quality speech from multiple input modalities: text,\nvideo, and reference audio. This task has gained increasing attention due to\nits wide range of applications, such as film production, dubbing, and virtual\navatars. Despite recent progress, existing methods still suffer from\nlimitations in speech intelligibility, audio-video synchronization, speech\nnaturalness, and voice similarity to the reference speaker. To address these\nchallenges, we propose AlignDiT, a multimodal Aligned Diffusion Transformer\nthat generates accurate, synchronized, and natural-sounding speech from aligned\nmultimodal inputs. Built upon the in-context learning capability of the DiT\narchitecture, AlignDiT explores three effective strategies to align multimodal\nrepresentations. Furthermore, we introduce a novel multimodal classifier-free\nguidance mechanism that allows the model to adaptively balance information from\neach modality during speech synthesis. Extensive experiments demonstrate that\nAlignDiT significantly outperforms existing methods across multiple benchmarks\nin terms of quality, synchronization, and speaker similarity. Moreover,\nAlignDiT exhibits strong generalization capability across various multimodal\ntasks, such as video-to-speech synthesis and visual forced alignment,\nconsistently achieving state-of-the-art performance. The demo page is available\nat https://mm.kaist.ac.kr/projects/AlignDiT .",
      "tldr_zh": "本研究针对多模态到语音生成任务，提出AlignDiT，一种多模态对齐Diffusion Transformer，用于从文本、视频和参考音频合成高质量、同步且自然的语音，以解决现有方法的语音清晰度、音视频同步和说话者相似度不足等问题。AlignDiT基于DiT架构，利用in-context learning探索三种多模态表示对齐策略，并引入新型多模态无分类器引导机制，适应性平衡各模态信息。实验结果显示，AlignDiT在多个基准上显著优于现有方法，在语音质量、同步性和说话者相似度方面表现突出，并展示出强大的泛化能力，在视频到语音合成和视觉强制对齐等任务中达到最先进水平。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.MM"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.20629v1",
      "published_date": "2025-04-29 10:56:24 UTC",
      "updated_date": "2025-04-29 10:56:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:57:33.150094"
    },
    {
      "arxiv_id": "2504.20628v1",
      "title": "Cognitive maps are generative programs",
      "title_zh": "认知地图是生成性程序",
      "authors": [
        "Marta Kryven",
        "Cole Wyeth",
        "Aidan Curtis",
        "Kevin Ellis"
      ],
      "abstract": "Making sense of the world and acting in it relies on building simplified\nmental representations that abstract away aspects of reality. This principle of\ncognitive mapping is universal to agents with limited resources. Living\norganisms, people, and algorithms all face the problem of forming functional\nrepresentations of their world under various computing constraints. In this\nwork, we explore the hypothesis that human resource-efficient planning may\narise from representing the world as predictably structured. Building on the\nmetaphor of concepts as programs, we propose that cognitive maps can take the\nform of generative programs that exploit predictability and redundancy, in\ncontrast to directly encoding spatial layouts. We use a behavioral experiment\nto show that people who navigate in structured spaces rely on modular planning\nstrategies that align with programmatic map representations. We describe a\ncomputational model that predicts human behavior in a variety of structured\nscenarios. This model infers a small distribution over possible programmatic\ncognitive maps conditioned on human prior knowledge of the world, and uses this\ndistribution to generate resource-efficient plans. Our models leverages a Large\nLanguage Model as an embedding of human priors, implicitly learned through\ntraining on a vast corpus of human data. Our model demonstrates improved\ncomputational efficiency, requires drastically less memory, and outperforms\nunstructured planning algorithms with cognitive constraints at predicting human\nbehavior, suggesting that human planning strategies rely on programmatic\ncognitive maps.",
      "tldr_zh": "本研究假设认知地图是一种生成程序，能够利用世界的可预测性和冗余来构建资源高效的简化表示，从而支持人类的规划和决策。作者通过行为实验证明，人们在结构化空间中采用模块化规划策略，与程序化认知地图相一致，并开发了一个计算模型，该模型基于人类先验知识推断可能的程序地图分布，并生成高效计划。模型利用 Large Language Model 作为人类先验的嵌入，实现了更高的计算效率、更低的内存需求，并在预测人类行为方面优于无结构规划算法，表明人类的规划策略依赖于程序化认知地图。",
      "categories": [
        "cs.AI",
        "cs.ET"
      ],
      "primary_category": "cs.AI",
      "comment": "9 pages, 4 figures, to be published in Cognitive Sciences Society\n  proceedings",
      "pdf_url": "http://arxiv.org/pdf/2504.20628v1",
      "published_date": "2025-04-29 10:55:40 UTC",
      "updated_date": "2025-04-29 10:55:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:57:44.398490"
    },
    {
      "arxiv_id": "2504.20625v1",
      "title": "DiffusionRIR: Room Impulse Response Interpolation using Diffusion Models",
      "title_zh": "翻译失败",
      "authors": [
        "Sagi Della Torre",
        "Mirco Pezzoli",
        "Fabio Antonacci",
        "Sharon Gannot"
      ],
      "abstract": "Room Impulse Responses (RIRs) characterize acoustic environments and are\ncrucial in multiple audio signal processing tasks. High-quality RIR estimates\ndrive applications such as virtual microphones, sound source localization,\naugmented reality, and data augmentation. However, obtaining RIR measurements\nwith high spatial resolution is resource-intensive, making it impractical for\nlarge spaces or when dense sampling is required. This research addresses the\nchallenge of estimating RIRs at unmeasured locations within a room using\nDenoising Diffusion Probabilistic Models (DDPM). Our method leverages the\nanalogy between RIR matrices and image inpainting, transforming RIR data into a\nformat suitable for diffusion-based reconstruction.\n  Using simulated RIR data based on the image method, we demonstrate our\napproach's effectiveness on microphone arrays of different curvatures, from\nlinear to semi-circular. Our method successfully reconstructs missing RIRs,\neven in large gaps between microphones. Under these conditions, it achieves\naccurate reconstruction, significantly outperforming baseline Spline Cubic\nInterpolation in terms of Normalized Mean Square Error and Cosine Distance\nbetween actual and interpolated RIRs.\n  This research highlights the potential of using generative models for\neffective RIR interpolation, paving the way for generating additional data from\nlimited real-world measurements.",
      "tldr_zh": "本文提出 DiffusionRIR 方法，使用 Denoising Diffusion Probabilistic Models (DDPM) 来插值 Room Impulse Responses (RIRs)，以解决获取高空间分辨率 RIR 测量资源密集的挑战。方法将 RIR 矩阵类比为图像修复，并在模拟的麦克风阵列（如线性或半圆形）上进行测试，结果显示它能准确重建缺失 RIR，甚至在麦克风间隙较大时，在 Normalized Mean Square Error 和 Cosine Distance 上显著优于 Spline Cubic Interpolation 基线。该研究展示了生成模型在 RIR 插值中的潜力，为从有限实测数据生成更多音频处理资源铺平了道路。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.20625v1",
      "published_date": "2025-04-29 10:52:07 UTC",
      "updated_date": "2025-04-29 10:52:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:57:57.471596"
    },
    {
      "arxiv_id": "2504.20624v1",
      "title": "PaRT: Enhancing Proactive Social Chatbots with Personalized Real-Time Retrieval",
      "title_zh": "PaRT：通过个性化的实时检索增强主动社交聊天机器人",
      "authors": [
        "Zihan Niu",
        "Zheyong Xie",
        "Shaosheng Cao",
        "Chonggang Lu",
        "Zheyu Ye",
        "Tong Xu",
        "Zuozhu Liu",
        "Yan Gao",
        "Jia Chen",
        "Zhe Xu",
        "Yi Wu",
        "Yao Hu"
      ],
      "abstract": "Social chatbots have become essential intelligent companions in daily\nscenarios ranging from emotional support to personal interaction. However,\nconventional chatbots with passive response mechanisms usually rely on users to\ninitiate or sustain dialogues by bringing up new topics, resulting in\ndiminished engagement and shortened dialogue duration. In this paper, we\npresent PaRT, a novel framework enabling context-aware proactive dialogues for\nsocial chatbots through personalized real-time retrieval and generation.\nSpecifically, PaRT first integrates user profiles and dialogue context into a\nlarge language model (LLM), which is initially prompted to refine user queries\nand recognize their underlying intents for the upcoming conversation. Guided by\nrefined intents, the LLM generates personalized dialogue topics, which then\nserve as targeted queries to retrieve relevant passages from RedNote. Finally,\nwe prompt LLMs with summarized passages to generate knowledge-grounded and\nengagement-optimized responses. Our approach has been running stably in a\nreal-world production environment for more than 30 days, achieving a 21.77\\%\nimprovement in the average duration of dialogues.",
      "tldr_zh": "本文提出 PaRT 框架，通过个性化的实时检索增强社交聊天机器人的主动对话能力，以解决传统被动响应机制导致的对话参与度低和持续时间短的问题。具体而言，PaRT 整合用户配置文件和对话上下文，使用大型语言模型 (LLM) 来提炼用户查询意图、生成个性化对话主题，并从 RedNote 中检索相关内容，最终生成基于知识的优化响应。在真实生产环境中，该框架已稳定运行超过 30 天，平均对话持续时间提高了 21.77%。这为提升社交聊天机器人互动效果提供了重要贡献。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.20624v1",
      "published_date": "2025-04-29 10:51:58 UTC",
      "updated_date": "2025-04-29 10:51:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:58:09.140068"
    },
    {
      "arxiv_id": "2504.20612v1",
      "title": "The Hidden Risks of LLM-Generated Web Application Code: A Security-Centric Evaluation of Code Generation Capabilities in Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Swaroop Dora",
        "Deven Lunkad",
        "Naziya Aslam",
        "S. Venkatesan",
        "Sandeep Kumar Shukla"
      ],
      "abstract": "The rapid advancement of Large Language Models (LLMs) has enhanced software\ndevelopment processes, minimizing the time and effort required for coding and\nenhancing developer productivity. However, despite their potential benefits,\ncode generated by LLMs has been shown to generate insecure code in controlled\nenvironments, raising critical concerns about their reliability and security in\nreal-world applications. This paper uses predefined security parameters to\nevaluate the security compliance of LLM-generated code across multiple models,\nsuch as ChatGPT, DeepSeek, Claude, Gemini and Grok. The analysis reveals\ncritical vulnerabilities in authentication mechanisms, session management,\ninput validation and HTTP security headers. Although some models implement\nsecurity measures to a limited extent, none fully align with industry best\npractices, highlighting the associated risks in automated software development.\nOur findings underscore that human expertise is crucial to ensure secure\nsoftware deployment or review of LLM-generated code. Also, there is a need for\nrobust security assessment frameworks to enhance the reliability of\nLLM-generated code in real-world applications.",
      "tldr_zh": "这篇论文评估了 Large Language Models (LLMs) 生成的 web 应用代码的安全风险，通过预定义的安全参数测试了 ChatGPT、DeepSeek、Claude、Gemini 和 Grok 等模型。研究发现，这些代码在认证机制、会话管理、输入验证和 HTTP 安全头等方面存在关键漏洞，尽管部分模型有限地实现了安全措施，但均未完全符合行业最佳实践。论文强调，LLMs 虽然提高了开发效率，但其生成代码的可靠性不足，需要人类专家进行审查，并开发更 robust 的安全评估框架以确保实际应用的安全性。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.ET"
      ],
      "primary_category": "cs.CR",
      "comment": "9 pages",
      "pdf_url": "http://arxiv.org/pdf/2504.20612v1",
      "published_date": "2025-04-29 10:23:11 UTC",
      "updated_date": "2025-04-29 10:23:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:58:21.666360"
    },
    {
      "arxiv_id": "2504.20610v1",
      "title": "Information Retrieval in the Age of Generative AI: The RGB Model",
      "title_zh": "翻译失败",
      "authors": [
        "Michele Garetto",
        "Alessandro Cornacchia",
        "Franco Galante",
        "Emilio Leonardi",
        "Alessandro Nordio",
        "Alberto Tarable"
      ],
      "abstract": "The advent of Large Language Models (LLMs) and generative AI is fundamentally\ntransforming information retrieval and processing on the Internet, bringing\nboth great potential and significant concerns regarding content authenticity\nand reliability. This paper presents a novel quantitative approach to shed\nlight on the complex information dynamics arising from the growing use of\ngenerative AI tools. Despite their significant impact on the digital ecosystem,\nthese dynamics remain largely uncharted and poorly understood. We propose a\nstochastic model to characterize the generation, indexing, and dissemination of\ninformation in response to new topics. This scenario particularly challenges\ncurrent LLMs, which often rely on real-time Retrieval-Augmented Generation\n(RAG) techniques to overcome their static knowledge limitations. Our findings\nsuggest that the rapid pace of generative AI adoption, combined with increasing\nuser reliance, can outpace human verification, escalating the risk of\ninaccurate information proliferation across digital resources. An in-depth\nanalysis of Stack Exchange data confirms that high-quality answers inevitably\nrequire substantial time and human effort to emerge. This underscores the\nconsiderable risks associated with generating persuasive text in response to\nnew questions and highlights the critical need for responsible development and\ndeployment of future generative AI tools.",
      "tldr_zh": "这篇论文探讨了生成式 AI（如 Large Language Models, LLMs）对信息检索的影响，提出 RGB Model 作为一种新颖的定量方法，以分析信息生成、索引和传播的动态过程。该模型通过随机模型（stochastic model）量化新主题下的信息流动，揭示生成式 AI 的快速采用可能超出人为验证能力，导致不准确信息泛滥。基于 Stack Exchange 数据分析，研究发现高质量答案需要大量时间和人力努力，强调未来 Retrieval-Augmented Generation (RAG) 工具的开发需注重责任性和可靠性。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.PF"
      ],
      "primary_category": "cs.IR",
      "comment": "To be presented at ACM SIGIR 25",
      "pdf_url": "http://arxiv.org/pdf/2504.20610v1",
      "published_date": "2025-04-29 10:21:40 UTC",
      "updated_date": "2025-04-29 10:21:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:58:34.766422"
    },
    {
      "arxiv_id": "2504.20605v1",
      "title": "TF1-EN-3M: Three Million Synthetic Moral Fables for Training Small, Open Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Mihai Nadas",
        "Laura Diosan",
        "Andrei Piscoran",
        "Andreea Tomescu"
      ],
      "abstract": "Moral stories are a time-tested vehicle for transmitting values, yet modern\nNLP lacks a large, structured corpus that couples coherent narratives with\nexplicit ethical lessons. We close this gap with TF1-EN-3M, the first open\ndataset of three million English-language fables generated exclusively by\ninstruction-tuned models no larger than 8B parameters. Each story follows a\nsix-slot scaffold (character -> trait -> setting -> conflict -> resolution ->\nmoral), produced through a combinatorial prompt engine that guarantees genre\nfidelity while covering a broad thematic space.\n  A hybrid evaluation pipeline blends (i) a GPT-based critic that scores\ngrammar, creativity, moral clarity, and template adherence with (ii)\nreference-free diversity and readability metrics. Among ten open-weight\ncandidates, an 8B-parameter Llama-3 variant delivers the best quality-speed\ntrade-off, producing high-scoring fables on a single consumer GPU (<24 GB VRAM)\nat approximately 13.5 cents per 1,000 fables.\n  We release the dataset, generation code, evaluation scripts, and full\nmetadata under a permissive license, enabling exact reproducibility and cost\nbenchmarking. TF1-EN-3M opens avenues for research in instruction following,\nnarrative intelligence, value alignment, and child-friendly educational AI,\ndemonstrating that large-scale moral storytelling no longer requires\nproprietary giant models.",
      "tldr_zh": "本研究介绍了 TF1-EN-3M 数据集，这是首个包含 300 万个英文合成道德寓言故事的开放数据集，用于训练小型开放语言模型（不超过 8B 参数）。每个故事遵循六槽结构（character -> trait -> setting -> conflict -> resolution -> moral），通过组合提示引擎生成，确保类型一致性和主题多样性。采用混合评估管道，包括 GPT-based 批评者（评估语法、创意、道德清晰度和模板遵守）以及无参考多样性和可读性指标，结果显示 8B 参数的 Llama-3 变体在单消费级 GPU 上提供最佳质量-速度权衡，每 1000 个故事成本约 13.5 美分。该数据集及其代码、脚本和元数据以宽松许可发布，促进了指令遵循、叙事智能、价值对齐和儿童教育 AI 的研究，并证明大规模道德故事生成无需依赖专有巨型模型。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.DL",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.20605v1",
      "published_date": "2025-04-29 10:15:28 UTC",
      "updated_date": "2025-04-29 10:15:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:58:47.700219"
    },
    {
      "arxiv_id": "2505.06250v1",
      "title": "DeltaDPD: Exploiting Dynamic Temporal Sparsity in Recurrent Neural Networks for Energy-Efficient Wideband Digital Predistortion",
      "title_zh": "翻译失败",
      "authors": [
        "Yizhuo Wu",
        "Yi Zhu",
        "Kun Qian",
        "Qinyu Chen",
        "Anding Zhu",
        "John Gajadharsing",
        "Leo C. N. de Vreede",
        "Chang Gao"
      ],
      "abstract": "Digital Predistortion (DPD) is a popular technique to enhance signal quality\nin wideband RF power amplifiers (PAs). With increasing bandwidth and data\nrates, DPD faces significant energy consumption challenges during deployment,\ncontrasting with its efficiency goals. State-of-the-art DPD models rely on\nrecurrent neural networks (RNN), whose computational complexity hinders system\nefficiency. This paper introduces DeltaDPD, exploring the dynamic temporal\nsparsity of input signals and neuronal hidden states in RNNs for\nenergy-efficient DPD, reducing arithmetic operations and memory accesses while\npreserving satisfactory linearization performance. Applying a TM3.1a 200MHz-BW\n256-QAM OFDM signal to a 3.5 GHz GaN Doherty RF PA, DeltaDPD achieves -50.03\ndBc in Adjacent Channel Power Ratio (ACPR), -37.22 dB in Normalized Mean Square\nError (NMSE) and -38.52 dBc in Error Vector Magnitude (EVM) with 52% temporal\nsparsity, leading to a 1.8X reduction in estimated inference power. The\nDeltaDPD code will be released after formal publication at\nhttps://www.opendpd.com.",
      "tldr_zh": "本论文提出 DeltaDPD，一种利用 Recurrent Neural Networks (RNN) 中输入信号和神经元隐藏状态的动态时间稀疏性，来提升宽带 Digital Predistortion (DPD) 的能效，从而减少算术运算和内存访问，同时保持信号线性化性能。DeltaDPD 针对宽带 RF 功率放大器 (PA) 的能耗挑战，通过优化 RNN 模型实现了高效部署。实验结果显示，在 3.5 GHz GaN Doherty RF PA 上处理 200MHz-BW 256-QAM OFDM 信号时，DeltaDPD 达到了 -50.03 dBc Adjacent Channel Power Ratio (ACPR)、-37.22 dB Normalized Mean Square Error (NMSE) 和 -38.52 dBc Error Vector Magnitude (EVM)，并以 52% 时间稀疏性降低了 1.8 倍的推理功率。",
      "categories": [
        "eess.SP",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "eess.SP",
      "comment": "Accepted to IEEE Microwave and Wireless Technology Letters (MWTL)",
      "pdf_url": "http://arxiv.org/pdf/2505.06250v1",
      "published_date": "2025-04-29 10:07:52 UTC",
      "updated_date": "2025-04-29 10:07:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:59:01.133111"
    },
    {
      "arxiv_id": "2504.20595v1",
      "title": "ReasonIR: Training Retrievers for Reasoning Tasks",
      "title_zh": "ReasonIR：训练用于推理任务的检索器",
      "authors": [
        "Rulin Shao",
        "Rui Qiao",
        "Varsha Kishore",
        "Niklas Muennighoff",
        "Xi Victoria Lin",
        "Daniela Rus",
        "Bryan Kian Hsiang Low",
        "Sewon Min",
        "Wen-tau Yih",
        "Pang Wei Koh",
        "Luke Zettlemoyer"
      ],
      "abstract": "We present ReasonIR-8B, the first retriever specifically trained for general\nreasoning tasks. Existing retrievers have shown limited gains on reasoning\ntasks, in part because existing training datasets focus on short factual\nqueries tied to documents that straightforwardly answer them. We develop a\nsynthetic data generation pipeline that, for each document, our pipeline\ncreates a challenging and relevant query, along with a plausibly related but\nultimately unhelpful hard negative. By training on a mixture of our synthetic\ndata and existing public data, ReasonIR-8B achieves a new state-of-the-art of\n29.9 nDCG@10 without reranker and 36.9 nDCG@10 with reranker on BRIGHT, a\nwidely-used reasoning-intensive information retrieval (IR) benchmark. When\napplied to RAG tasks, ReasonIR-8B improves MMLU and GPQA performance by 6.4%\nand 22.6% respectively, relative to the closed-book baseline, outperforming\nother retrievers and search engines. In addition, ReasonIR-8B uses test-time\ncompute more effectively: on BRIGHT, its performance consistently increases\nwith longer and more information-rich rewritten queries; it continues to\noutperform other retrievers when combined with an LLM reranker. Our training\nrecipe is general and can be easily extended to future LLMs; to this end, we\nopen-source our code, data, and model.",
      "tldr_zh": "该研究引入了 ReasonIR-8B，这是首个专门针对一般推理任务训练的检索器，旨在克服现有检索器在处理复杂查询时的局限性。研究团队开发了一个合成数据生成管道，为每个文档创建挑战性查询和相关但无帮助的硬负样本，并通过混合合成数据和公共数据进行训练。在 BRIGHT 基准上，ReasonIR-8B 实现了 29.9 nDCG@10 的新 state-of-the-art 性能，并在 RAG 任务中相对闭合书基线提升了 MMLU 和 GPQA 的表现，分别提高 6.4% 和 22.6%。此外，该模型开源了代码、数据和训练配方，便于扩展到未来的 LLM 系统。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.IR",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "Our code is released at\n  \\url{https://github.com/facebookresearch/ReasonIR}",
      "pdf_url": "http://arxiv.org/pdf/2504.20595v1",
      "published_date": "2025-04-29 09:49:28 UTC",
      "updated_date": "2025-04-29 09:49:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:59:11.626951"
    },
    {
      "arxiv_id": "2504.20571v1",
      "title": "Reinforcement Learning for Reasoning in Large Language Models with One Training Example",
      "title_zh": "翻译失败",
      "authors": [
        "Yiping Wang",
        "Qing Yang",
        "Zhiyuan Zeng",
        "Liliang Ren",
        "Lucas Liu",
        "Baolin Peng",
        "Hao Cheng",
        "Xuehai He",
        "Kuan Wang",
        "Jianfeng Gao",
        "Weizhu Chen",
        "Shuohang Wang",
        "Simon Shaolei Du",
        "Yelong Shen"
      ],
      "abstract": "We show that reinforcement learning with verifiable reward using one training\nexample (1-shot RLVR) is effective in incentivizing the math reasoning\ncapabilities of large language models (LLMs). Applying RLVR to the base model\nQwen2.5-Math-1.5B, we identify a single example that elevates model performance\non MATH500 from 36.0% to 73.6%, and improves the average performance across six\ncommon mathematical reasoning benchmarks from 17.6% to 35.7%. This result\nmatches the performance obtained using the 1.2k DeepScaleR subset (MATH500:\n73.6%, average: 35.9%), which includes the aforementioned example. Similar\nsubstantial improvements are observed across various models (Qwen2.5-Math-7B,\nLlama3.2-3B-Instruct, DeepSeek-R1-Distill-Qwen-1.5B), RL algorithms (GRPO and\nPPO), and different math examples (many of which yield approximately 30% or\ngreater improvement on MATH500 when employed as a single training example). In\naddition, we identify some interesting phenomena during 1-shot RLVR, including\ncross-domain generalization, increased frequency of self-reflection, and\nsustained test performance improvement even after the training accuracy has\nsaturated, a phenomenon we term post-saturation generalization. Moreover, we\nverify that the effectiveness of 1-shot RLVR primarily arises from the policy\ngradient loss, distinguishing it from the \"grokking\" phenomenon. We also show\nthe critical role of promoting exploration (e.g., by adding entropy loss with\nan appropriate coefficient) in 1-shot RLVR training. As a bonus, we observe\nthat applying entropy loss alone, without any outcome reward, significantly\nenhances Qwen2.5-Math-1.5B's performance on MATH500 by 27.4%. These findings\ncan inspire future work on RLVR data efficiency and encourage a re-examination\nof both recent progress and the underlying mechanisms in RLVR. Our code, model,\nand data are open source at https://github.com/ypwang61/One-Shot-RLVR",
      "tldr_zh": "该研究提出了一种使用一个训练示例的强化学习方法（1-shot RLVR），旨在提升大型语言模型（LLMs）的数学推理能力。通过应用 RLVR 于 Qwen2.5-Math-1.5B 模型，该方法将 MATH500 基准的性能从 36.0% 提升至 73.6%，并在六个数学推理基准上的平均性能从 17.6% 提高到 35.7%。实验结果显示，这种方法在多种模型（如 Qwen2.5-Math-7B 和 Llama3.2-3B-Instruct）和 RL 算法（如 GRPO 和 PPO）上均表现出显著改善，包括跨领域泛化、增加的自省频率以及训练饱和后持续改进（post-saturation generalization）。此外，研究验证了策略梯度损失和探索机制（如熵损失）的关键作用，并开源了代码、模型和数据，以促进 RLVR 的数据效率研究。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "28 pages, 12 figures, link: https://github.com/ypwang61/One-Shot-RLVR",
      "pdf_url": "http://arxiv.org/pdf/2504.20571v1",
      "published_date": "2025-04-29 09:24:30 UTC",
      "updated_date": "2025-04-29 09:24:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:59:24.929398"
    },
    {
      "arxiv_id": "2504.20566v1",
      "title": "Inclusive Training Separation and Implicit Knowledge Interaction for Balanced Online Class-Incremental Learning",
      "title_zh": "包容",
      "authors": [
        "Shunjie Wen",
        "Thomas Heinis",
        "Dong-Wan Choi"
      ],
      "abstract": "Online class-incremental learning (OCIL) focuses on gradually learning new\nclasses (called plasticity) from a stream of data in a single-pass, while\nconcurrently preserving knowledge of previously learned classes (called\nstability). The primary challenge in OCIL lies in maintaining a good balance\nbetween the knowledge of old and new classes within the continually updated\nmodel. Most existing methods rely on explicit knowledge interaction through\nexperience replay, and often employ exclusive training separation to address\nbias problems. Nevertheless, it still remains a big challenge to achieve a\nwell-balanced learner, as these methods often exhibit either reduced plasticity\nor limited stability due to difficulties in continually integrating knowledge\nin the OCIL setting. In this paper, we propose a novel replay-based method,\ncalled Balanced Online Incremental Learning (BOIL), which can achieve both high\nplasticity and stability, thus ensuring more balanced performance in OCIL. Our\nBOIL method proposes an inclusive training separation strategy using dual\nclassifiers so that knowledge from both old and new classes can effectively be\nintegrated into the model, while introducing implicit approaches for\ntransferring knowledge across the two classifiers. Extensive experimental\nevaluations over three widely-used OCIL benchmark datasets demonstrate the\nsuperiority of BOIL, showing more balanced yet better performance compared to\nstate-of-the-art replay-based OCIL methods.",
      "tldr_zh": "在线类增量学习 (OCIL) 旨在从数据流中逐步学习新类 (plasticity) 同时保留旧类知识 (stability)，但现有方法在平衡两者方面面临挑战，往往依赖显式知识交互和独占训练分离。本文提出了一种新型回放-based 方法 Balanced Online Incremental Learning (BOIL)，采用双分类器的包容性训练分离策略和隐式知识交互机制，实现旧类和新类知识的有效整合，从而提升模型的整体平衡性。在三个常用 OCIL 基准数据集上的广泛实验验证了 BOIL 的优越性，其性能比现有 state-of-the-art 方法更平衡且显著更好。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Under review",
      "pdf_url": "http://arxiv.org/pdf/2504.20566v1",
      "published_date": "2025-04-29 09:13:00 UTC",
      "updated_date": "2025-04-29 09:13:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:59:38.028513"
    },
    {
      "arxiv_id": "2504.20560v1",
      "title": "Generate more than one child in your co-evolutionary semi-supervised learning GAN",
      "title_zh": "翻译失败",
      "authors": [
        "Francisco Sedeño",
        "Jamal Toutouh",
        "Francisco Chicano"
      ],
      "abstract": "Generative Adversarial Networks (GANs) are very useful methods to address\nsemi-supervised learning (SSL) datasets, thanks to their ability to generate\nsamples similar to real data. This approach, called SSL-GAN has attracted many\nresearchers in the last decade. Evolutionary algorithms have been used to guide\nthe evolution and training of SSL-GANs with great success. In particular,\nseveral co-evolutionary approaches have been applied where the two networks of\na GAN (the generator and the discriminator) are evolved in separate\npopulations. The co-evolutionary approaches published to date assume some\nspatial structure of the populations, based on the ideas of cellular\nevolutionary algorithms. They also create one single individual per generation\nand follow a generational replacement strategy in the evolution. In this paper,\nwe re-consider those algorithmic design decisions and propose a new\nco-evolutionary approach, called Co-evolutionary Elitist SSL-GAN (CE-SSLGAN),\nwith panmictic population, elitist replacement, and more than one individual in\nthe offspring. We evaluate the performance of our proposed method using three\nstandard benchmark datasets. The results show that creating more than one\noffspring per population and using elitism improves the results in comparison\nwith a classical SSL-GAN.",
      "tldr_zh": "该论文探讨了生成对抗网络(GAN)在半监督学习(SSL)中的应用，特别关注使用进化算法的共进化方法来训练SSL-GAN。作者提出了一种新方法Co-evolutionary Elitist SSL-GAN (CE-SSLGAN)，它采用panmictic种群结构、elitist替换策略，并生成多个后代个体，以改进现有算法的设计决策。实验结果显示，在三个标准基准数据集上，CE-SSLGAN相较于经典SSL-GAN取得了更好的性能，提升了模型的训练效果。",
      "categories": [
        "cs.NE",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.NE",
      "comment": "Submitted to The Leading European Event on Bio-Inspired AI (EvoStar\n  2025)",
      "pdf_url": "http://arxiv.org/pdf/2504.20560v1",
      "published_date": "2025-04-29 09:04:22 UTC",
      "updated_date": "2025-04-29 09:04:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:59:49.550283"
    },
    {
      "arxiv_id": "2504.20520v1",
      "title": "PRISM: Projection-based Reward Integration for Scene-Aware Real-to-Sim-to-Real Transfer with Few Demonstrations",
      "title_zh": "翻译失败",
      "authors": [
        "Haowen Sun",
        "Han Wang",
        "Chengzhong Ma",
        "Shaolong Zhang",
        "Jiawei Ye",
        "Xingyu Chen",
        "Xuguang Lan"
      ],
      "abstract": "Learning from few demonstrations to develop policies robust to variations in\nrobot initial positions and object poses is a problem of significant practical\ninterest in robotics. Compared to imitation learning, which often struggles to\ngeneralize from limited samples, reinforcement learning (RL) can autonomously\nexplore to obtain robust behaviors. Training RL agents through direct\ninteraction with the real world is often impractical and unsafe, while building\nsimulation environments requires extensive manual effort, such as designing\nscenes and crafting task-specific reward functions. To address these\nchallenges, we propose an integrated real-to-sim-to-real pipeline that\nconstructs simulation environments based on expert demonstrations by\nidentifying scene objects from images and retrieving their corresponding 3D\nmodels from existing libraries. We introduce a projection-based reward model\nfor RL policy training that is supervised by a vision-language model (VLM)\nusing human-guided object projection relationships as prompts, with the policy\nfurther fine-tuned using expert demonstrations. In general, our work focuses on\nthe construction of simulation environments and RL-based policy training,\nultimately enabling the deployment of reliable robotic control policies in\nreal-world scenarios.",
      "tldr_zh": "该论文提出PRISM框架，旨在通过少量演示实现场景感知的real-to-sim-to-real转移，解决机器人政策对初始位置和物体姿态变化的鲁棒性问题。框架首先基于专家演示自动构建模拟环境，通过从图像识别场景物体并检索现有库中的3D模型，减少手动设计努力。接着，引入projection-based reward model与vision-language model (VLM)结合，使用人类指导的对象投影关系作为提示来监督reinforcement learning (RL)政策训练，并通过专家演示进一步fine-tune。该方法相比imitation learning更能从有限样本中泛化，最终支持在真实世界部署可靠的机器人控制政策。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.20520v1",
      "published_date": "2025-04-29 08:01:27 UTC",
      "updated_date": "2025-04-29 08:01:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:00:01.269981"
    },
    {
      "arxiv_id": "2504.20505v1",
      "title": "MuRAL: A Multi-Resident Ambient Sensor Dataset Annotated with Natural Language for Activities of Daily Living",
      "title_zh": "MuRAL：用自然语言标注的多居民环境传感器数据集，用于日常生活活动",
      "authors": [
        "Xi Chen",
        "Julien Cumin",
        "Fano Ramparany",
        "Dominique Vaufreydaz"
      ],
      "abstract": "Recent advances in Large Language Models (LLMs) have shown promising\npotential for human activity recognition (HAR) using ambient sensors,\nespecially through natural language reasoning and zero-shot learning. However,\nexisting datasets such as CASAS, ARAS, and MARBLE were not originally designed\nwith LLMs in mind and therefore lack the contextual richness, complexity, and\nannotation granularity required to fully exploit LLM capabilities. In this\npaper, we introduce MuRAL, the first Multi-Resident Ambient sensor dataset with\nnatural Language, comprising over 21 hours of multi-user sensor data collected\nfrom 21 sessions in a smart-home environment. MuRAL is annotated with\nfine-grained natural language descriptions, resident identities, and high-level\nactivity labels, all situated in dynamic, realistic multi-resident settings. We\nbenchmark MuRAL using state-of-the-art LLMs for three core tasks: subject\nassignment, action description, and activity classification. Our results\ndemonstrate that while LLMs can provide rich semantic interpretations of\nambient data, current models still face challenges in handling multi-user\nambiguity and under-specified sensor contexts. We release MuRAL to support\nfuture research on LLM-powered, explainable, and socially aware activity\nunderstanding in smart environments. For access to the dataset, please reach\nout to us via the provided contact information. A direct link for dataset\nretrieval will be made available at this location in due course.",
      "tldr_zh": "本研究引入了MuRAL数据集，这是首个针对日常生活活动(Activities of Daily Living)的多居民环境传感器数据集，包含超过21小时的多用户数据，旨在提升大型语言模型(LLMs)在人类活动识别(HAR)中的性能。MuRAL通过细粒度的自然语言描述、居民身份和高层活动标签进行标注，解决了现有数据集如CASAS、ARAS和MARBLE在上下文丰富性和复杂性方面的不足。研究利用最先进的LLMs对MuRAL进行基准测试，包括主体分配、动作描述和活动分类任务，结果显示LLMs能提供丰富的语义解释，但仍面临多用户模糊性和传感器上下文不足的挑战。该数据集的发布将支持未来LLM驱动的、可解释和社交感知的智能环境活动理解研究。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.20505v1",
      "published_date": "2025-04-29 07:46:14 UTC",
      "updated_date": "2025-04-29 07:46:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:00:14.983191"
    },
    {
      "arxiv_id": "2504.20493v1",
      "title": "Token-Efficient Prompt Injection Attack: Provoking Cessation in LLM Reasoning via Adaptive Token Compression",
      "title_zh": "令牌高效的提示注入攻击：通过自适应令牌",
      "authors": [
        "Yu Cui",
        "Yujun Cai",
        "Yiwei Wang"
      ],
      "abstract": "While reasoning large language models (LLMs) demonstrate remarkable\nperformance across various tasks, they also contain notable security\nvulnerabilities. Recent research has uncovered a \"thinking-stopped\"\nvulnerability in DeepSeek-R1, where model-generated reasoning tokens can\nforcibly interrupt the inference process, resulting in empty responses that\ncompromise LLM-integrated applications. However, existing methods triggering\nthis vulnerability require complex mathematical word problems with long\nprompts--even exceeding 5,000 tokens. To reduce the token cost and formally\ndefine this vulnerability, we propose a novel prompt injection attack named\n\"Reasoning Interruption Attack\", based on adaptive token compression. We\ndemonstrate that simple standalone arithmetic tasks can effectively trigger\nthis vulnerability, and the prompts based on such tasks exhibit simpler logical\nstructures than mathematical word problems. We develop a systematic approach to\nefficiently collect attack prompts and an adaptive token compression framework\nthat utilizes LLMs to automatically compress these prompts. Experiments show\nour compression framework significantly reduces prompt length while maintaining\neffective attack capabilities. We further investigate the attack's performance\nvia output prefix and analyze the underlying causes of the vulnerability,\nproviding valuable insights for improving security in reasoning LLMs.",
      "tldr_zh": "本文提出了一种高效的prompt injection攻击，名为\"Reasoning Interruption Attack\"，通过adaptive token compression技术来触发大型语言模型(LLMs)的\"thinking-stopped\"漏洞，从而以更少的令牌（如从5000+减少到更短的提示）中断模型推理过程。攻击方法利用简单的独立算术任务生成逻辑结构更简单的提示，并开发了一个系统框架，使用LLMs自动压缩这些提示。实验结果显示，该框架显著降低了提示长度，同时保持了高攻击成功率，并通过输出前缀分析揭示了漏洞根因，为改进LLMs的安全性提供了宝贵见解。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.20493v1",
      "published_date": "2025-04-29 07:34:22 UTC",
      "updated_date": "2025-04-29 07:34:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:00:25.675262"
    },
    {
      "arxiv_id": "2504.20482v1",
      "title": "Group Relative Knowledge Distillation: Learning from Teacher's Relational Inductive Bias",
      "title_zh": "分组相对知识蒸馏：从教师的关联归纳偏差中学习",
      "authors": [
        "Chao Li",
        "Changhua Zhou",
        "Jia Chen"
      ],
      "abstract": "Knowledge distillation typically transfers knowledge from a teacher model to\na student model by minimizing differences between their output distributions.\nHowever, existing distillation approaches largely focus on mimicking absolute\nprobabilities and neglect the valuable relational inductive biases embedded in\nthe teacher's relative predictions, leading to exposure bias. In this paper, we\npropose Group Relative Knowledge Distillation (GRKD), a novel framework that\ndistills teacher knowledge by learning the relative ranking among classes,\nrather than directly fitting the absolute distribution. Specifically, we\nintroduce a group relative loss that encourages the student model to preserve\nthe pairwise preference orderings provided by the teacher's outputs. Extensive\nexperiments on classification benchmarks demonstrate that GRKD achieves\nsuperior generalization compared to existing methods, especially in tasks\nrequiring fine-grained class differentiation. Our method provides a new\nperspective on exploiting teacher knowledge, focusing on relational structure\nrather than absolute likelihood.",
      "tldr_zh": "本文提出 Group Relative Knowledge Distillation (GRKD)，一种新型知识蒸馏框架，旨在从教师模型的相对关系归纳偏差中学习，而不是简单模仿绝对概率输出，从而缓解暴露偏差问题。具体而言，GRKD 通过引入 group relative loss 来保持教师输出中的成对偏好顺序，确保学生模型更好地捕捉类别间的相对排名。在分类基准实验中，GRKD 比现有方法表现出更强的泛化能力，尤其在需要细粒度类区分的任务上，提供了一个新的视角来利用教师知识的结构关系。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.20482v1",
      "published_date": "2025-04-29 07:23:22 UTC",
      "updated_date": "2025-04-29 07:23:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:00:37.241551"
    },
    {
      "arxiv_id": "2504.20471v1",
      "title": "The Estimation of Continual Causal Effect for Dataset Shifting Streams",
      "title_zh": "针对数据集偏移数据流的持续因果效应估计",
      "authors": [
        "Baining Chen",
        "Yiming Zhang",
        "Yuqiao Han",
        "Ruyue Zhang",
        "Ruihuan Du",
        "Zhishuo Zhou",
        "Zhengdan Zhu",
        "Xun Liu",
        "Jiecheng Guo"
      ],
      "abstract": "Causal effect estimation has been widely used in marketing optimization. The\nframework of an uplift model followed by a constrained optimization algorithm\nis popular in practice. To enhance performance in the online environment, the\nframework needs to be improved to address the complexities caused by temporal\ndataset shift. This paper focuses on capturing the dataset shift from user\nbehavior and domain distribution changing over time. We propose an Incremental\nCausal Effect with Proxy Knowledge Distillation (ICE-PKD) framework to tackle\nthis challenge. The ICE-PKD framework includes two components: (i) a\nmulti-treatment uplift network that eliminates confounding bias using\ncounterfactual regression; (ii) an incremental training strategy that adapts to\nthe temporal dataset shift by updating with the latest data and protects\ngeneralization via replay-based knowledge distillation. We also revisit the\nuplift modeling metrics and introduce a novel metric for more precise online\nevaluation in multiple treatment scenarios. Extensive experiments on both\nsimulated and online datasets show that the proposed framework achieves better\nperformance. The ICE-PKD framework has been deployed in the marketing system of\nHuaxiaozhu, a ride-hailing platform in China.",
      "tldr_zh": "该论文针对在线环境中的数据集移位问题，提出Incremental Causal Effect with Proxy Knowledge Distillation (ICE-PKD)框架，用于提升因果效应估计在营销优化中的性能。该框架包括多处理提升网络(multi-treatment uplift network)，通过反事实回归(counterfactual regression)消除混杂偏差，以及增量训练策略，利用最新数据更新模型并采用基于重放的知识蒸馏(replay-based knowledge distillation)保护泛化能力。论文还重新审视了提升建模指标，并引入新型指标以更精确评估多处理场景下的在线效果。在模拟和真实数据集上的广泛实验显示，ICE-PKD框架表现出色，并已在中国的网约车平台Huaxiaozhu的营销系统中部署。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ME"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.20471v1",
      "published_date": "2025-04-29 07:13:28 UTC",
      "updated_date": "2025-04-29 07:13:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:00:48.617100"
    },
    {
      "arxiv_id": "2504.20464v2",
      "title": "A Survey on GUI Agents with Foundation Models Enhanced by Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Jiahao Li",
        "Kaer Huang"
      ],
      "abstract": "Graphical User Interface (GUI) agents, driven by Multi-modal Large Language\nModels (MLLMs), have emerged as a promising paradigm for enabling intelligent\ninteraction with digital systems. This paper provides a structured survey of\nrecent advances in GUI agents, focusing on architectures enhanced by\nReinforcement Learning (RL). We first formalize GUI agent tasks as Markov\nDecision Processes and discuss typical execution environments and evaluation\nmetrics. We then review the modular architecture of (M)LLM-based GUI agents,\ncovering Perception, Planning, and Acting modules, and trace their evolution\nthrough representative works. Furthermore, we categorize GUI agent training\nmethodologies into Prompt-based, Supervised Fine-Tuning (SFT)-based, and\nRL-based approaches, highlighting the progression from simple prompt\nengineering to dynamic policy learning via RL. Our summary illustrates how\nrecent innovations in multimodal perception, decision reasoning, and adaptive\naction generation have significantly improved the generalization and robustness\nof GUI agents in complex real-world environments. We conclude by identifying\nkey challenges and future directions for building more capable and reliable GUI\nagents.",
      "tldr_zh": "本篇论文对基于基础模型的图形用户界面(GUI)代理进行了结构化调查，重点关注强化学习(Reinforcement Learning, RL)的增强作用。论文将GUI代理任务形式化为Markov Decision Processes (MDP)，并讨论了执行环境、评估指标以及模块化架构，包括Perception、Planning和Acting模块，通过回顾代表性作品展示了其演变过程。训练方法被分类为Prompt-based、Supervised Fine-Tuning (SFT)-based和RL-based方法，强调从提示工程到动态策略学习的进展，这些创新显著提升了GUI代理在复杂环境的泛化和鲁棒性。最后，论文指出了构建更可靠GUI代理的关键挑战和未来方向。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.20464v2",
      "published_date": "2025-04-29 06:55:15 UTC",
      "updated_date": "2025-05-13 01:59:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:01:00.826210"
    },
    {
      "arxiv_id": "2504.20462v2",
      "title": "TAMO:Fine-Grained Root Cause Analysis via Tool-Assisted LLM Agent with Multi-Modality Observation Data",
      "title_zh": "翻译失败",
      "authors": [
        "Qi Wang",
        "Xiao Zhang",
        "Mingyi Li",
        "Yuan Yuan",
        "Mengbai Xiao",
        "Fuzhen Zhuang",
        "Dongxiao Yu"
      ],
      "abstract": "With the development of distributed systems, microservices and cloud native\ntechnologies have become central to modern enterprise software development.\nDespite bringing significant advantages, these technologies also increase\nsystem complexity and operational challenges. Traditional root cause analysis\n(RCA) struggles to achieve automated fault response, heavily relying on manual\nintervention. In recent years, large language models (LLMs) have made\nbreakthroughs in contextual inference and domain knowledge integration,\nproviding new solutions for Artificial Intelligence for Operations (AIOps).\nHowever, Existing LLM-based approaches face three key challenges: text input\nconstraints, dynamic service dependency hallucinations, and context window\nlimitations. To address these issues, we propose a tool-assisted LLM agent with\nmulti-modality observation data, namely TAMO, for fine-grained RCA. It unifies\nmulti-modal observational data into time-aligned representations to extract\nconsistent features and employs specialized root cause localization and fault\nclassification tools for perceiving the contextual environment. This approach\novercomes the limitations of LLM in handling real-time changing service\ndependencies and raw observational data and guides LLM to generate repair\nstrategies aligned with system contexts by structuring key information into a\nprompt. Experimental results show that TAMO performs well in root cause\nanalysis when dealing with public datasets characterized by heterogeneity and\ncommon fault types, demonstrating its effectiveness.",
      "tldr_zh": "本文提出TAMO，一种工具辅助的LLM代理，用于细粒度根因分析(RCA)，旨在解决分布式系统中微服务和云原生技术的复杂性问题，包括LLM的文本输入约束、动态服务依赖幻觉和上下文窗口限制。TAMO通过统一多模态观察数据为时间对齐表示，并结合专用工具进行根因定位和故障分类，帮助LLM生成与系统上下文一致的修复策略。实验结果显示，TAMO在异构公共数据集上表现出色，证明了其在AIOps领域的有效性和可靠性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.20462v2",
      "published_date": "2025-04-29 06:50:48 UTC",
      "updated_date": "2025-04-30 10:20:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:01:13.966948"
    },
    {
      "arxiv_id": "2504.21055v1",
      "title": "Modeling and Performance Analysis for Semantic Communications Based on Empirical Results",
      "title_zh": "翻译失败",
      "authors": [
        "Shuai Ma",
        "Bin Shen",
        "Chuanhui Zhang",
        "Youlong Wu",
        "Hang Li",
        "Shiyin Li",
        "Guangming Shi",
        "Naofal Al-Dhahir"
      ],
      "abstract": "Due to the black-box characteristics of deep learning based semantic encoders\nand decoders, finding a tractable method for the performance analysis of\nsemantic communications is a challenging problem. In this paper, we propose an\nAlpha-Beta-Gamma (ABG) formula to model the relationship between the end-to-end\nmeasurement and SNR, which can be applied for both image reconstruction tasks\nand inference tasks. Specifically, for image reconstruction tasks, the proposed\nABG formula can well fit the commonly used DL networks, such as SCUNet, and\nVision Transformer, for semantic encoding with the multi scale-structural\nsimilarity index measure (MS-SSIM) measurement. Furthermore, we find that the\nupper bound of the MS-SSIM depends on the number of quantized output bits of\nsemantic encoders, and we also propose a closed-form expression to fit the\nrelationship between the MS-SSIM and quantized output bits. To the best of our\nknowledge, this is the first theoretical expression between end-to-end\nperformance metrics and SNR for semantic communications. Based on the proposed\nABG formula, we investigate an adaptive power control scheme for semantic\ncommunications over random fading channels, which can effectively guarantee\nquality of service (QoS) for semantic communications, and then design the\noptimal power allocation scheme to maximize the energy efficiency of the\nsemantic communication system. Furthermore, by exploiting the bisection\nalgorithm, we develop the power allocation scheme to maximize the minimum QoS\nof multiple users for OFDMA downlink semantic communication Extensive\nsimulations verify the effectiveness and superiority of the proposed ABG\nformula and power allocation schemes.",
      "tldr_zh": "该论文提出了一种 Alpha-Beta-Gamma (ABG) 公式，用于基于经验结果建模语义通信中端到端性能指标与信噪比 (SNR) 的关系，适用于图像重建任务（如使用 SCUNet 和 Vision Transformer 网络的 MS-SSIM 度量）和推理任务，这是首个将这些指标理论化的表达式。研究发现，MS-SSIM 的上界取决于语义编码器的量化输出位数，并给出了相应的闭合形式拟合。基于 ABG 公式，作者设计了自适应功率控制方案和最优功率分配策略，以保证语义通信的质量服务 (QoS)，并通过二分法算法最大化多用户 OFDMA 下行通信的最小 QoS；模拟结果验证了该公式的有效性和方案的优越性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.21055v1",
      "published_date": "2025-04-29 06:07:50 UTC",
      "updated_date": "2025-04-29 06:07:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:01:26.435809"
    },
    {
      "arxiv_id": "2504.20452v1",
      "title": "Enhancing News Recommendation with Hierarchical LLM Prompting",
      "title_zh": "翻译失败",
      "authors": [
        "Hai-Dang Kieu",
        "Delvin Ce Zhang",
        "Minh Duc Nguyen",
        "Min Xu",
        "Qiang Wu",
        "Dung D. Le"
      ],
      "abstract": "Personalized news recommendation systems often struggle to effectively\ncapture the complexity of user preferences, as they rely heavily on shallow\nrepresentations, such as article titles and abstracts. To address this problem,\nwe introduce a novel method, namely PNR-LLM, for Large Language Models for\nPersonalized News Recommendation. Specifically, PNR-LLM harnesses the\ngeneration capabilities of LLMs to enrich news titles and abstracts, and\nconsequently improves recommendation quality. PNR-LLM contains a novel module,\nNews Enrichment via LLMs, which generates deeper semantic information and\nrelevant entities from articles, transforming shallow contents into richer\nrepresentations. We further propose an attention mechanism to aggregate\nenriched semantic- and entity-level data, forming unified user and news\nembeddings that reveal a more accurate user-news match. Extensive experiments\non MIND datasets show that PNR-LLM outperforms state-of-the-art baselines.\nMoreover, the proposed data enrichment module is model-agnostic, and we\nempirically show that applying our proposed module to multiple existing models\ncan further improve their performance, verifying the advantage of our design.",
      "tldr_zh": "该研究针对个性化新闻推荐系统在捕捉用户偏好复杂性方面的不足，提出了一种新型方法PNR-LLM，利用大型语言模型(LLMs)来丰富新闻标题和摘要。PNR-LLM包括一个名为News Enrichment via LLMs的模块，该模块生成更深层的语义信息和相关实体，并通过注意力机制聚合这些数据，形成统一的用户和新闻嵌入，从而提升用户-新闻匹配准确性。在MIND数据集上的实验表明，PNR-LLM优于现有基线模型，且该数据丰富模块具有模型无关性，能进一步提升其他推荐系统的性能。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.20452v1",
      "published_date": "2025-04-29 06:02:16 UTC",
      "updated_date": "2025-04-29 06:02:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:01:38.156829"
    },
    {
      "arxiv_id": "2504.21054v1",
      "title": "FFCBA: Feature-based Full-target Clean-label Backdoor Attacks",
      "title_zh": "FFCBA：基于特征的全目标干净标签后门攻击",
      "authors": [
        "Yangxu Yin",
        "Honglong Chen",
        "Yudong Gao",
        "Peng Sun",
        "Liantao Wu",
        "Zhe Li",
        "Weifeng Liu"
      ],
      "abstract": "Backdoor attacks pose a significant threat to deep neural networks, as\nbackdoored models would misclassify poisoned samples with specific triggers\ninto target classes while maintaining normal performance on clean samples.\nAmong these, multi-target backdoor attacks can simultaneously target multiple\nclasses. However, existing multi-target backdoor attacks all follow the\ndirty-label paradigm, where poisoned samples are mislabeled, and most of them\nrequire an extremely high poisoning rate. This makes them easily detectable by\nmanual inspection. In contrast, clean-label attacks are more stealthy, as they\navoid modifying the labels of poisoned samples. However, they generally\nstruggle to achieve stable and satisfactory attack performance and often fail\nto scale effectively to multi-target attacks. To address this issue, we propose\nthe Feature-based Full-target Clean-label Backdoor Attacks (FFCBA) which\nconsists of two paradigms: Feature-Spanning Backdoor Attacks (FSBA) and\nFeature-Migrating Backdoor Attacks (FMBA). FSBA leverages class-conditional\nautoencoders to generate noise triggers that align perturbed in-class samples\nwith the original category's features, ensuring the effectiveness, intra-class\nconsistency, inter-class specificity and natural-feature correlation of\ntriggers. While FSBA supports swift and efficient attacks, its cross-model\nattack capability is relatively weak. FMBA employs a two-stage\nclass-conditional autoencoder training process that alternates between using\nout-of-class samples and in-class samples. This allows FMBA to generate\ntriggers with strong target-class features, making it highly effective for\ncross-model attacks. We conduct experiments on multiple datasets and models,\nthe results show that FFCBA achieves outstanding attack performance and\nmaintains desirable robustness against the state-of-the-art backdoor defenses.",
      "tldr_zh": "该论文提出FFCBA（Feature-based Full-target Clean-label Backdoor Attacks），一种基于特征的全目标清洁标签后门攻击框架，旨在解决现有多目标Backdoor Attacks的易检测问题，同时提升攻击的隐秘性和稳定性。FFCBA包括两个范式：FSBA（Feature-Spanning Backdoor Attacks）利用类条件自编码器生成噪声触发器，确保触发器的有效性、类内一致性和类间特异性；FMBA（Feature-Migrating Backdoor Attacks）采用两阶段训练过程，生成更强的目标类特征，以支持高效的跨模型攻击。实验在多个数据集和模型上验证，FFCBA实现了出色的攻击性能，并对最先进的后门防御表现出色鲁棒性。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.21054v1",
      "published_date": "2025-04-29 05:49:42 UTC",
      "updated_date": "2025-04-29 05:49:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:01:51.247273"
    },
    {
      "arxiv_id": "2504.21053v1",
      "title": "NeuRel-Attack: Neuron Relearning for Safety Disalignment in Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Yi Zhou",
        "Wenpeng Xing",
        "Dezhang Kong",
        "Changting Lin",
        "Meng Han"
      ],
      "abstract": "Safety alignment in large language models (LLMs) is achieved through\nfine-tuning mechanisms that regulate neuron activations to suppress harmful\ncontent. In this work, we propose a novel approach to induce disalignment by\nidentifying and modifying the neurons responsible for safety constraints. Our\nmethod consists of three key steps: Neuron Activation Analysis, where we\nexamine activation patterns in response to harmful and harmless prompts to\ndetect neurons that are critical for distinguishing between harmful and\nharmless inputs; Similarity-Based Neuron Identification, which systematically\nlocates the neurons responsible for safe alignment; and Neuron Relearning for\nSafety Removal, where we fine-tune these selected neurons to restore the\nmodel's ability to generate previously restricted responses. Experimental\nresults demonstrate that our method effectively removes safety constraints with\nminimal fine-tuning, highlighting a critical vulnerability in current alignment\ntechniques. Our findings underscore the need for robust defenses against\nadversarial fine-tuning attacks on LLMs.",
      "tldr_zh": "本研究提出 NeuRel-Attack 方法，用于破坏大型语言模型（LLMs）的安全对齐，通过识别和微调关键神经元来移除安全约束。该方法包括三个关键步骤：Neuron Activation Analysis 分析有害和无害提示下的神经元激活模式、Similarity-Based Neuron Identification 系统定位负责安全对齐的神经元，以及 Neuron Relearning for Safety Removal 微调这些神经元以恢复生成受限响应。实验结果表明，该方法能以最小微调有效去除安全约束，暴露了当前对齐技术的关键漏洞，并呼吁开发更稳健的防御机制。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.21053v1",
      "published_date": "2025-04-29 05:49:35 UTC",
      "updated_date": "2025-04-29 05:49:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:02:02.756136"
    },
    {
      "arxiv_id": "2504.20447v1",
      "title": "APG-MOS: Auditory Perception Guided-MOS Predictor for Synthetic Speech",
      "title_zh": "APG-MOS：听觉感知引导的 MOS 预测器，用于合成语音",
      "authors": [
        "Zhicheng Lian",
        "Lizhi Wang",
        "Hua Huang"
      ],
      "abstract": "Automatic speech quality assessment aims to quantify subjective human\nperception of speech through computational models to reduce the need for\nlabor-consuming manual evaluations. While models based on deep learning have\nachieved progress in predicting mean opinion scores (MOS) to assess synthetic\nspeech, the neglect of fundamental auditory perception mechanisms limits\nconsistency with human judgments. To address this issue, we propose an auditory\nperception guided-MOS prediction model (APG-MOS) that synergistically\nintegrates auditory modeling with semantic analysis to enhance consistency with\nhuman judgments. Specifically, we first design a perceptual module, grounded in\nbiological auditory mechanisms, to simulate cochlear functions, which encodes\nacoustic signals into biologically aligned electrochemical representations.\nSecondly, we propose a residual vector quantization (RVQ)-based semantic\ndistortion modeling method to quantify the degradation of speech quality at the\nsemantic level. Finally, we design a residual cross-attention architecture,\ncoupled with a progressive learning strategy, to enable multimodal fusion of\nencoded electrochemical signals and semantic representations. Experiments\ndemonstrate that APG-MOS achieves superior performance on two primary\nbenchmarks. Our code and checkpoint will be available on a public repository\nupon publication.",
      "tldr_zh": "本研究提出 APG-MOS 模型，用于合成语音的自动质量评估，通过整合听觉感知机制和语义分析，提升预测均等意见分数 (MOS) 与人类判断的一致性。具体而言，该模型包括一个基于生物耳蜗功能的感知模块将声学信号编码为电化学表示、一个基于残差向量量化 (RVQ) 的语义失真建模方法，以及残差交叉注意力 (residual cross-attention) 架构结合渐进学习策略进行多模态融合。实验结果显示，APG-MOS 在两个主要基准测试中表现出色，显著优于现有深度学习模型。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.20447v1",
      "published_date": "2025-04-29 05:45:09 UTC",
      "updated_date": "2025-04-29 05:45:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:02:15.346075"
    },
    {
      "arxiv_id": "2504.20445v2",
      "title": "Head-Tail-Aware KL Divergence in Knowledge Distillation for Spiking Neural Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Tianqing Zhang",
        "Zixin Zhu",
        "Kairong Yu",
        "Hongwei Wang"
      ],
      "abstract": "Spiking Neural Networks (SNNs) have emerged as a promising approach for\nenergy-efficient and biologically plausible computation. However, due to\nlimitations in existing training methods and inherent model constraints, SNNs\noften exhibit a performance gap when compared to Artificial Neural Networks\n(ANNs). Knowledge distillation (KD) has been explored as a technique to\ntransfer knowledge from ANN teacher models to SNN student models to mitigate\nthis gap. Traditional KD methods typically use Kullback-Leibler (KL) divergence\nto align output distributions. However, conventional KL-based approaches fail\nto fully exploit the unique characteristics of SNNs, as they tend to\noveremphasize high-probability predictions while neglecting low-probability\nones, leading to suboptimal generalization. To address this, we propose\nHead-Tail Aware Kullback-Leibler (HTA-KL) divergence, a novel KD method for\nSNNs. HTA-KL introduces a cumulative probability-based mask to dynamically\ndistinguish between high- and low-probability regions. It assigns adaptive\nweights to ensure balanced knowledge transfer, enhancing the overall\nperformance. By integrating forward KL (FKL) and reverse KL (RKL) divergence,\nour method effectively align both head and tail regions of the distribution. We\nevaluate our methods on CIFAR-10, CIFAR-100 and Tiny ImageNet datasets. Our\nmethod outperforms existing methods on most datasets with fewer timesteps.",
      "tldr_zh": "本研究针对Spiking Neural Networks (SNNs)的性能差距，提出了一种改进的Knowledge Distillation (KD)方法，即Head-Tail Aware Kullback-Leibler (HTA-KL) divergence，以解决传统KL Divergence过度强调高概率预测而忽略低概率问题的局限性。HTA-KL通过基于累积概率的掩码动态区分高概率和低概率区域，并整合Forward KL (FKL)和Reverse KL (RKL)来实现平衡的知识转移，从而提升SNNs的泛化性能。在CIFAR-10、CIFAR-100和Tiny ImageNet数据集上的实验表明，该方法在使用更少时步的情况下，优于现有方法，显著提高了SNNs的整体表现。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted by IJCNN2025",
      "pdf_url": "http://arxiv.org/pdf/2504.20445v2",
      "published_date": "2025-04-29 05:36:32 UTC",
      "updated_date": "2025-05-16 15:19:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:02:28.919918"
    },
    {
      "arxiv_id": "2504.20444v1",
      "title": "On Psychology of AI -- Does Primacy Effect Affect ChatGPT and Other LLMs?",
      "title_zh": "翻译失败",
      "authors": [
        "Mika Hämäläinen"
      ],
      "abstract": "We study the primacy effect in three commercial LLMs: ChatGPT, Gemini and\nClaude. We do this by repurposing the famous experiment Asch (1946) conducted\nusing human subjects. The experiment is simple, given two candidates with equal\ndescriptions which one is preferred if one description has positive adjectives\nfirst before negative ones and another description has negative adjectives\nfollowed by positive ones. We test this in two experiments. In one experiment,\nLLMs are given both candidates simultaneously in the same prompt, and in\nanother experiment, LLMs are given both candidates separately. We test all the\nmodels with 200 candidate pairs. We found that, in the first experiment,\nChatGPT preferred the candidate with positive adjectives listed first, while\nGemini preferred both equally often. Claude refused to make a choice. In the\nsecond experiment, ChatGPT and Claude were most likely to rank both candidates\nequally. In the case where they did not give an equal rating, both showed a\nclear preference to a candidate that had negative adjectives listed first.\nGemini was most likely to prefer a candidate with negative adjectives listed\nfirst.",
      "tldr_zh": "本研究探讨了 primacy effect（ primacy effect ）是否影响 ChatGPT、Gemini 和 Claude 等 LLMs，通过改编 Asch (1946) 实验测试两个候选人描述的顺序偏好。实验一中，同时呈现候选人时，ChatGPT 更倾向于正形容词先的描述，Gemini 无显著偏好，而 Claude 拒绝选择。实验二中，分开呈现候选人时，ChatGPT 和 Claude 大多给出平等评分，但若不等则偏好负形容词先的候选人；Gemini 最可能偏好负形容词先。该研究揭示了 LLMs 在信息处理中的心理偏差，为理解 AI 决策偏见提供了重要洞见。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.20444v1",
      "published_date": "2025-04-29 05:35:23 UTC",
      "updated_date": "2025-04-29 05:35:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:02:42.244009"
    },
    {
      "arxiv_id": "2504.21052v1",
      "title": "SFIBA: Spatial-based Full-target Invisible Backdoor Attacks",
      "title_zh": "翻译失败",
      "authors": [
        "Yangxu Yin",
        "Honglong Chen",
        "Yudong Gao",
        "Peng Sun",
        "Zhishuai Li",
        "Weifeng Liu"
      ],
      "abstract": "Multi-target backdoor attacks pose significant security threats to deep\nneural networks, as they can preset multiple target classes through a single\nbackdoor injection. This allows attackers to control the model to misclassify\npoisoned samples with triggers into any desired target class during inference,\nexhibiting superior attack performance compared with conventional backdoor\nattacks. However, existing multi-target backdoor attacks fail to guarantee\ntrigger specificity and stealthiness in black-box settings, resulting in two\nmain issues. First, they are unable to simultaneously target all classes when\nonly training data can be manipulated, limiting their effectiveness in\nrealistic attack scenarios. Second, the triggers often lack visual\nimperceptibility, making poisoned samples easy to detect. To address these\nproblems, we propose a Spatial-based Full-target Invisible Backdoor Attack,\ncalled SFIBA. It restricts triggers for different classes to specific local\nspatial regions and morphologies in the pixel space to ensure specificity,\nwhile employing a frequency-domain-based trigger injection method to guarantee\nstealthiness. Specifically, for injection of each trigger, we first apply fast\nfourier transform to obtain the amplitude spectrum of clean samples in local\nspatial regions. Then, we employ discrete wavelet transform to extract the\nfeatures from the amplitude spectrum and use singular value decomposition to\nintegrate the trigger. Subsequently, we selectively filter parts of the trigger\nin pixel space to implement trigger morphology constraints and adjust injection\ncoefficients based on visual effects. We conduct experiments on multiple\ndatasets and models. The results demonstrate that SFIBA can achieve excellent\nattack performance and stealthiness, while preserving the model's performance\non benign samples, and can also bypass existing backdoor defenses.",
      "tldr_zh": "本研究提出了一种基于空间的完全目标隐形后门攻击（SFIBA），旨在解决现有多目标 backdoor attacks 在黑盒设置中触发器特异性和隐秘性不足的问题，特别是无法同时针对所有类别的样本和易被检测的触发器。\nSFIBA 方法将不同类别的触发器限制在特定局部空间区域和形态上，并通过快速傅里叶变换（fast Fourier transform）获取样本幅度谱，结合离散小波变换（discrete wavelet transform）和奇异值分解（singular value decomposition）在频率域注入触发器，随后在像素空间过滤和调整以确保视觉隐秘性。\n实验在多个数据集和模型上验证，SFIBA 实现了出色的攻击性能和隐秘性，同时保持模型在正常样本上的性能，并能绕过现有 backdoor defenses。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.21052v1",
      "published_date": "2025-04-29 05:28:12 UTC",
      "updated_date": "2025-04-29 05:28:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:02:52.414038"
    },
    {
      "arxiv_id": "2504.20437v1",
      "title": "GaLore 2: Large-Scale LLM Pre-Training by Gradient Low-Rank Projection",
      "title_zh": "GaLore 2：通过梯度低秩投影进行大规模LLM预训练",
      "authors": [
        "DiJia Su",
        "Andrew Gu",
        "Jane Xu",
        "Yuandong Tian",
        "Jiawei Zhao"
      ],
      "abstract": "Large language models (LLMs) have revolutionized natural language\nunderstanding and generation but face significant memory bottlenecks during\ntraining. GaLore, Gradient Low-Rank Projection, addresses this issue by\nleveraging the inherent low-rank structure of weight gradients, enabling\nsubstantial memory savings without sacrificing performance. Recent works\nfurther extend GaLore from various aspects, including low-bit quantization and\nhigher-order tensor structures. However, there are several remaining challenges\nfor GaLore, such as the computational overhead of SVD for subspace updates and\nthe integration with state-of-the-art training parallelization strategies\n(e.g., FSDP). In this paper, we present GaLore 2, an efficient and scalable\nGaLore framework that addresses these challenges and incorporates recent\nadvancements. In addition, we demonstrate the scalability of GaLore 2 by\npre-training Llama 7B from scratch using up to 500 billion training tokens,\nhighlighting its potential impact on real LLM pre-training scenarios.",
      "tldr_zh": "该论文介绍了 GaLore 2，一种基于 Gradient Low-Rank Projection 的框架，用于解决大型语言模型 (LLMs) 预训练中的内存瓶颈问题，通过利用权重梯度的低秩结构实现显著内存节省而不影响性能。GaLore 2 解决了原有 GaLore 的挑战，包括减少 SVD 的计算开销并与先进训练并行策略（如 FSDP）整合，同时吸收了低位量化 (low-bit quantization) 和更高阶张量结构的最新进展。实验证明，GaLore 2 展示了出色的可扩展性，通过从零开始预训练 Llama 7B，使用高达 500 亿训练标记，展示了其在实际 LLM 预训练场景中的潜力。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.20437v1",
      "published_date": "2025-04-29 05:27:02 UTC",
      "updated_date": "2025-04-29 05:27:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:03:02.608010"
    },
    {
      "arxiv_id": "2504.20434v1",
      "title": "ARCS: Agentic Retrieval-Augmented Code Synthesis with Iterative Refinement",
      "title_zh": "ARCS：代理式检索增强代码合成与迭代",
      "authors": [
        "Manish Bhattarai",
        "Miguel Cordova",
        "Javier Santos",
        "Dan O'Malley"
      ],
      "abstract": "In supercomputing, efficient and optimized code generation is essential to\nleverage high-performance systems effectively. We propose Agentic\nRetrieval-Augmented Code Synthesis (ARCS), an advanced framework for accurate,\nrobust, and efficient code generation, completion, and translation. ARCS\nintegrates Retrieval-Augmented Generation (RAG) with Chain-of-Thought (CoT)\nreasoning to systematically break down and iteratively refine complex\nprogramming tasks. An agent-based RAG mechanism retrieves relevant code\nsnippets, while real-time execution feedback drives the synthesis of candidate\nsolutions. This process is formalized as a state-action search tree\noptimization, balancing code correctness with editing efficiency. Evaluations\non the Geeks4Geeks and HumanEval benchmarks demonstrate that ARCS significantly\noutperforms traditional prompting methods in translation and generation\nquality. By enabling scalable and precise code synthesis, ARCS offers\ntransformative potential for automating and optimizing code development in\nsupercomputing applications, enhancing computational resource utilization.",
      "tldr_zh": "我们提出了ARCS框架，一种基于代理的检索增强代码合成系统（Agentic Retrieval-Augmented Code Synthesis），它整合了RAG（Retrieval-Augmented Generation）和CoT（Chain-of-Thought）推理来分解复杂编程任务，并通过实时执行反馈进行迭代精炼，以优化代码正确性和编辑效率。ARCS将过程形式化为状态-行动搜索树，确保高效的代码生成、完成和翻译。实验结果显示，在Geeks4Geeks和HumanEval基准测试中，ARCS显著优于传统提示方法，提升了代码质量，并为超级计算应用的自动化代码开发提供了潜力。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.20434v1",
      "published_date": "2025-04-29 05:15:52 UTC",
      "updated_date": "2025-04-29 05:15:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:03:14.658160"
    },
    {
      "arxiv_id": "2504.20426v1",
      "title": "RV-Syn: Rational and Verifiable Mathematical Reasoning Data Synthesis based on Structured Function Library",
      "title_zh": "RV-Syn：基于结构化函数库的",
      "authors": [
        "Jiapeng Wang",
        "Jinhao Jiang",
        "Zhiqiang Zhang",
        "Jun Zhou",
        "Wayne Xin Zhao"
      ],
      "abstract": "The advancement of reasoning capabilities in Large Language Models (LLMs)\nrequires substantial amounts of high-quality reasoning data, particularly in\nmathematics. Existing data synthesis methods, such as data augmentation from\nannotated training sets or direct question generation based on relevant\nknowledge points and documents, have expanded datasets but face challenges in\nmastering the inner logic of the problem during generation and ensuring the\nverifiability of the solutions. To address these issues, we propose RV-Syn, a\nnovel Rational and Verifiable mathematical Synthesis approach. RV-Syn\nconstructs a structured mathematical operation function library based on\ninitial seed problems and generates computational graphs as solutions by\ncombining Python-formatted functions from this library. These graphs are then\nback-translated into complex problems. Based on the constructed computation\ngraph, we achieve solution-guided logic-aware problem generation. Furthermore,\nthe executability of the computational graph ensures the verifiability of the\nsolving process. Experimental results show that RV-Syn surpasses existing\nsynthesis methods, including those involving human-generated problems,\nachieving greater efficient data scaling. This approach provides a scalable\nframework for generating high-quality reasoning datasets.",
      "tldr_zh": "该研究针对 Large Language Models (LLMs) 的数学推理能力，提出了一种名为 RV-Syn 的新颖数据合成方法，以解决现有方法在问题内在逻辑掌握和解决方案可验证性方面的挑战。RV-Syn 通过基于初始种子问题构建结构化的数学操作函数库，并生成计算图作为解决方案，然后将这些图反向翻译成复杂问题，从而实现逻辑感知的问题生成和可执行计算图的验证。实验结果显示，RV-Syn 优于现有合成方法，包括人类生成的问题，实现了更高效的数据扩展，并为生成高质量推理数据集提供了可扩展框架。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.20426v1",
      "published_date": "2025-04-29 04:42:02 UTC",
      "updated_date": "2025-04-29 04:42:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:03:26.821983"
    },
    {
      "arxiv_id": "2504.20412v2",
      "title": "CrashFixer: A crash resolution agent for the Linux kernel",
      "title_zh": "CrashFixer：针对 Linux 内核的崩溃解决代理",
      "authors": [
        "Alex Mathai",
        "Chenxi Huang",
        "Suwei Ma",
        "Jihwan Kim",
        "Hailie Mitchell",
        "Aleksandr Nogikh",
        "Petros Maniatis",
        "Franjo Ivančić",
        "Junfeng Yang",
        "Baishakhi Ray"
      ],
      "abstract": "Code large language models (LLMs) have shown impressive capabilities on a\nmultitude of software engineering tasks. In particular, they have demonstrated\nremarkable utility in the task of code repair. However, common benchmarks used\nto evaluate the performance of code LLMs are often limited to small-scale\nsettings. In this work, we build upon kGym, which shares a benchmark for\nsystem-level Linux kernel bugs and a platform to run experiments on the Linux\nkernel.\n  This paper introduces CrashFixer, the first LLM-based software repair agent\nthat is applicable to Linux kernel bugs. Inspired by the typical workflow of a\nkernel developer, we identify the key capabilities an expert developer\nleverages to resolve a kernel crash. Using this as our guide, we revisit the\nkGym platform and identify key system improvements needed to practically run\nLLM-based agents at the scale of the Linux kernel (50K files and 20M lines of\ncode). We implement these changes by extending kGym to create an improved\nplatform - called kGymSuite, which will be open-sourced. Finally, the paper\npresents an evaluation of various repair strategies for such complex kernel\nbugs and showcases the value of explicitly generating a hypothesis before\nattempting to fix bugs in complex systems such as the Linux kernel. We also\nevaluated CrashFixer's capabilities on still open bugs, and found at least two\npatch suggestions considered plausible to resolve the reported bug.",
      "tldr_zh": "本文提出 CrashFixer，一种基于代码大型语言模型 (LLMs) 的修复代理，专门针对 Linux 内核崩溃问题，填补了现有基准在小规模设置下的局限性。该代理借鉴内核开发人员的工作流程，通过扩展 kGym 平台为 kGymSuite（支持50K文件和20M行代码），实现了关键能力如生成假设后再进行修复。实验评估显示，不同修复策略中显式生成假设显著提升了效果，并在开放错误上产生了至少两个被认为可行的补丁建议。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.OS"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.20412v2",
      "published_date": "2025-04-29 04:18:51 UTC",
      "updated_date": "2025-05-13 18:59:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:03:39.083234"
    },
    {
      "arxiv_id": "2504.20408v1",
      "title": "FourierSpecNet: Neural Collision Operator Approximation Inspired by the Fourier Spectral Method for Solving the Boltzmann Equation",
      "title_zh": "翻译失败",
      "authors": [
        "Jae Yong Lee",
        "Gwang Jae Jung",
        "Byung Chan Lim",
        "Hyung Ju Hwang"
      ],
      "abstract": "The Boltzmann equation, a fundamental model in kinetic theory, describes the\nevolution of particle distribution functions through a nonlinear,\nhigh-dimensional collision operator. However, its numerical solution remains\ncomputationally demanding, particularly for inelastic collisions and\nhigh-dimensional velocity domains. In this work, we propose the Fourier Neural\nSpectral Network (FourierSpecNet), a hybrid framework that integrates the\nFourier spectral method with deep learning to approximate the collision\noperator in Fourier space efficiently. FourierSpecNet achieves\nresolution-invariant learning and supports zero-shot super-resolution, enabling\naccurate predictions at unseen resolutions without retraining. Beyond empirical\nvalidation, we establish a consistency result showing that the trained operator\nconverges to the spectral solution as the discretization is refined. We\nevaluate our method on several benchmark cases, including Maxwellian and\nhard-sphere molecular models, as well as inelastic collision scenarios. The\nresults demonstrate that FourierSpecNet offers competitive accuracy while\nsignificantly reducing computational cost compared to traditional spectral\nsolvers. Our approach provides a robust and scalable alternative for solving\nthe Boltzmann equation across both elastic and inelastic regimes.",
      "tldr_zh": "这篇论文提出了一种名为 FourierSpecNet 的混合框架，将 Fourier 谱方法与深度学习相结合，用于高效逼近 Boltzmann 方程中非线性、高维的碰撞算子，从而解决其数值求解的计算密集问题。该框架实现了分辨率不变的学习和 zero-shot super-resolution，支持在未见分辨率下准确预测，而无需重新训练，并证明了训练后的算子在离散化细化时收敛到谱解。在多个基准案例中，包括 Maxwellian 和 hard-sphere 分子模型以及非弹性碰撞场景，FourierSpecNet 展示了与传统谱求解器相当的准确性，但显著降低了计算成本，为弹性及非弹性 Boltzmann 方程的鲁棒、可扩展求解提供了新途径。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NA",
        "math.NA",
        "physics.comp-ph",
        "68T20, 35Q20, 35B40, 82C40"
      ],
      "primary_category": "cs.LG",
      "comment": "27 pages, 11 figures",
      "pdf_url": "http://arxiv.org/pdf/2504.20408v1",
      "published_date": "2025-04-29 04:07:03 UTC",
      "updated_date": "2025-04-29 04:07:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:03:52.583069"
    },
    {
      "arxiv_id": "2504.20406v1",
      "title": "Skill Discovery for Software Scripting Automation via Offline Simulations with LLMs",
      "title_zh": "软件脚本自动化的技能发现：通过 LLMs 的离线模拟",
      "authors": [
        "Paiheng Xu",
        "Gang Wu",
        "Xiang Chen",
        "Tong Yu",
        "Chang Xiao",
        "Franck Dernoncourt",
        "Tianyi Zhou",
        "Wei Ai",
        "Viswanathan Swaminathan"
      ],
      "abstract": "Scripting interfaces enable users to automate tasks and customize software\nworkflows, but creating scripts traditionally requires programming expertise\nand familiarity with specific APIs, posing barriers for many users. While Large\nLanguage Models (LLMs) can generate code from natural language queries, runtime\ncode generation is severely limited due to unverified code, security risks,\nlonger response times, and higher computational costs. To bridge the gap, we\npropose an offline simulation framework to curate a software-specific skillset,\na collection of verified scripts, by exploiting LLMs and publicly available\nscripting guides. Our framework comprises two components: (1) task creation,\nusing top-down functionality guidance and bottom-up API synergy exploration to\ngenerate helpful tasks; and (2) skill generation with trials, refining and\nvalidating scripts based on execution feedback. To efficiently navigate the\nextensive API landscape, we introduce a Graph Neural Network (GNN)-based link\nprediction model to capture API synergy, enabling the generation of skills\ninvolving underutilized APIs and expanding the skillset's diversity.\nExperiments with Adobe Illustrator demonstrate that our framework significantly\nimproves automation success rates, reduces response time, and saves runtime\ntoken costs compared to traditional runtime code generation. This is the first\nattempt to use software scripting interfaces as a testbed for LLM-based\nsystems, highlighting the advantages of leveraging execution feedback in a\ncontrolled environment and offering valuable insights into aligning AI\ncapabilities with user needs in specialized software domains.",
      "tldr_zh": "该研究针对软件脚本自动化的挑战，提出了一种利用大型语言模型(LLMs)的离线模拟框架，以生成验证过的脚本技能集。该框架包括任务创建模块（通过自上而下的功能指导和自下而上的API协同探索生成任务）和技能生成模块（基于执行反馈精炼脚本），并引入Graph Neural Network (GNN)-based链接预测模型来捕捉API协同，提升技能多样性和覆盖未充分利用的API。在Adobe Illustrator的实验中，该框架显著提高了自动化成功率、缩短了响应时间并降低了运行时token成本，这是首次将软件脚本接口作为LLMs系统的测试平台，提供宝贵见解以更好地满足用户需求。",
      "categories": [
        "cs.AI",
        "cs.SE"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.20406v1",
      "published_date": "2025-04-29 04:03:37 UTC",
      "updated_date": "2025-04-29 04:03:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:04:03.120417"
    },
    {
      "arxiv_id": "2504.20405v1",
      "title": "SCOPE-MRI: Bankart Lesion Detection as a Case Study in Data Curation and Deep Learning for Challenging Diagnoses",
      "title_zh": "SCOPE-MRI：",
      "authors": [
        "Sahil Sethi",
        "Sai Reddy",
        "Mansi Sakarvadia",
        "Jordan Serotte",
        "Darlington Nwaudo",
        "Nicholas Maassen",
        "Lewis Shi"
      ],
      "abstract": "While deep learning has shown strong performance in musculoskeletal imaging,\nexisting work has largely focused on pathologies where diagnosis is not a\nclinical challenge, leaving more difficult problems underexplored, such as\ndetecting Bankart lesions (anterior-inferior glenoid labral tears) on standard\nMRIs. Diagnosing these lesions is challenging due to their subtle imaging\nfeatures, often leading to reliance on invasive MRI arthrograms (MRAs). This\nstudy introduces ScopeMRI, the first publicly available, expert-annotated\ndataset for shoulder pathologies, and presents a deep learning (DL) framework\nfor detecting Bankart lesions on both standard MRIs and MRAs. ScopeMRI includes\n586 shoulder MRIs (335 standard, 251 MRAs) from 558 patients who underwent\narthroscopy. Ground truth labels were derived from intraoperative findings, the\ngold standard for diagnosis. Separate DL models for MRAs and standard MRIs were\ntrained using a combination of CNNs and transformers. Predictions from\nsagittal, axial, and coronal views were ensembled to optimize performance. The\nmodels were evaluated on a 20% hold-out test set (117 MRIs: 46 MRAs, 71\nstandard MRIs). The models achieved an AUC of 0.91 and 0.93, sensitivity of 83%\nand 94%, and specificity of 91% and 86% for standard MRIs and MRAs,\nrespectively. Notably, model performance on non-invasive standard MRIs matched\nor surpassed radiologists interpreting MRAs. External validation demonstrated\ninitial generalizability across imaging protocols. This study demonstrates that\nDL models can achieve radiologist-level diagnostic performance on standard\nMRIs, reducing the need for invasive MRAs. By releasing ScopeMRI and a modular\ncodebase for training and evaluating deep learning models on 3D medical imaging\ndata, we aim to accelerate research in musculoskeletal imaging and support the\ndevelopment of new datasets for clinically challenging diagnostic tasks.",
      "tldr_zh": "本研究针对Bankart病变（anterior-inferior glenoid labral tears）在标准MRI上的检测难题，引入了首个公开的专家标注数据集ScopeMRI，该数据集包含586个肩部MRI（335个标准MRI和251个MRAs）来自558个患者，并以手术为金标准提供标签。研究开发了一个基于CNN和Transformer的深层学习（DL）框架，通过集成矢状面、轴向和冠状面预测，对标准MRI和MRAs进行检测，模型在测试集上分别达到AUC 0.91和0.93、敏感性83%和94%、特异性91%和86%。结果显示，DL模型在标准MRI上的表现已达到或超过放射科医生水平，减少了对侵入性MRAs的依赖，并通过发布数据集和模块化代码，促进肌肉骨骼成像领域的进一步研究。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.20405v1",
      "published_date": "2025-04-29 04:02:44 UTC",
      "updated_date": "2025-04-29 04:02:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:04:17.108002"
    },
    {
      "arxiv_id": "2504.20368v1",
      "title": "AKIBoards: A Structure-Following Multiagent System for Predicting Acute Kidney Injury",
      "title_zh": "翻译失败",
      "authors": [
        "David Gordon",
        "Panayiotis Petousis",
        "Susanne B. Nicholas",
        "Alex A. T. Bui"
      ],
      "abstract": "Diagnostic reasoning entails a physician's local (mental) model based on an\nassumed or known shared perspective (global model) to explain patient\nobservations with evidence assigned towards a clinical assessment. But in\nseveral (complex) medical situations, multiple experts work together as a team\nto optimize health evaluation and decision-making by leveraging different\nperspectives. Such consensus-driven reasoning reflects individual knowledge\ncontributing toward a broader perspective on the patient. In this light, we\nintroduce STRUCture-following for Multiagent Systems (STRUC-MAS), a framework\nautomating the learning of these global models and their incorporation as prior\nbeliefs for agents in multiagent systems (MAS) to follow. We demonstrate proof\nof concept with a prosocial MAS application for predicting acute kidney\ninjuries (AKIs). In this case, we found that incorporating a global structure\nenabled multiple agents to achieve better performance (average precision, AP)\nin predicting AKI 48 hours before onset (structure-following-fine-tuned, SF-FT,\nAP=0.195; SF-FT-retrieval-augmented generation, SF-FT-RAG, AP=0.194) vs.\nbaseline (non-structure-following-FT, NSF-FT, AP=0.141; NSF-FT-RAG, AP=0.180)\nfor balanced precision-weighted-recall-weighted voting. Markedly, SF-FT agents\nwith higher recall scores reported lower confidence levels in the initial round\non true positive and false negative cases. But after explicit interactions,\ntheir confidence in their decisions increased (suggesting reinforced belief).\nIn contrast, the SF-FT agent with the lowest recall decreased its confidence in\ntrue positive and false negative cases (suggesting a new belief). This approach\nsuggests that learning and leveraging global structures in MAS is necessary\nprior to achieving competitive classification and diagnostic reasoning\nperformance.",
      "tldr_zh": "该论文引入了STRUC-MAS框架，这是一种遵循结构的多智能体系统（Multiagent System, MAS），旨在自动学习全局模型并将其作为先验信念，用于模拟专家团队在诊断推理中的合作。框架应用于预测急性肾损伤（Acute Kidney Injury, AKI），通过结构跟随机制结合细调（fine-tuned, FT）和检索增强生成（Retrieval-Augmented Generation, RAG）技术，使代理在预测AKI 48小时前时平均精度（AP）提升至0.195（SF-FT）和0.194（SF-FT-RAG），显著高于基线模型（NSF-FT AP=0.141）。实验结果显示，代理间的互动增强了置信度，尤其在真阳性和假阴性案例中，这证明了在MAS中学习和利用全局结构对于提升分类和诊断性能的必要性。",
      "categories": [
        "cs.MA",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.MA",
      "comment": "Accepted at International Conference on Autonomous Agents and\n  Multiagent Systems (AAMAS) Workshop, 2025",
      "pdf_url": "http://arxiv.org/pdf/2504.20368v1",
      "published_date": "2025-04-29 02:12:48 UTC",
      "updated_date": "2025-04-29 02:12:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:04:27.461859"
    },
    {
      "arxiv_id": "2504.20357v1",
      "title": "Automated Unit Test Case Generation: A Systematic Literature Review",
      "title_zh": "自动化单元测试用例生成：系统文献综述",
      "authors": [
        "Jason Wang",
        "Basem Suleiman",
        "Muhammad Johan Alibasa"
      ],
      "abstract": "Software is omnipresent within all factors of society. It is thus important\nto ensure that software are well tested to mitigate bad user experiences as\nwell as the potential for severe financial and human losses. Software testing\nis however expensive and absorbs valuable time and resources. As a result, the\nfield of automated software testing has grown of interest to researchers in\npast decades. In our review of present and past research papers, we have\nidentified an information gap in the areas of improvement for the Genetic\nAlgorithm and Particle Swarm Optimisation. A gap in knowledge in the current\nchallenges that face automated testing has also been identified. We therefore\npresent this systematic literature review in an effort to consolidate existing\nknowledge in regards to the evolutionary approaches as well as their\nimprovements and resulting limitations. These improvements include hybrid\nalgorithm combinations as well as interoperability with mutation testing and\nneural networks. We will also explore the main test criterion that are used in\nthese algorithms alongside the challenges currently faced in the field related\nto readability, mocking and more.",
      "tldr_zh": "这篇论文通过 Systematic Literature Review 回顾了 Automated Unit Test Case Generation 的研究现状，强调了软件测试的重要性及其面临的资源消耗问题。研究识别了 Genetic Algorithm 和 Particle Swarm Optimisation 在改进方面的信息空白，并探讨了进化方法的整合，如混合算法与 Mutation Testing 和 Neural Networks 的互操作性。综述还总结了主要测试标准和当前挑战，包括可读性、Mocking 等，为未来优化自动化测试提供了宝贵见解。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.20357v1",
      "published_date": "2025-04-29 01:50:06 UTC",
      "updated_date": "2025-04-29 01:50:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:04:39.159560"
    },
    {
      "arxiv_id": "2504.20355v1",
      "title": "Local Prompt Optimization",
      "title_zh": "局部提示优化",
      "authors": [
        "Yash Jain",
        "Vishal Chowdhary"
      ],
      "abstract": "In recent years, the use of prompts to guide the output of Large Language\nModels have increased dramatically. However, even the best of experts struggle\nto choose the correct words to stitch up a prompt for the desired task. To\nsolve this, LLM driven prompt optimization emerged as an important problem.\nExisting prompt optimization methods optimize a prompt globally, where in all\nthe prompt tokens have to be optimized over a large vocabulary while solving a\ncomplex task. The large optimization space (tokens) leads to insufficient\nguidance for a better prompt. In this work, we introduce Local Prompt\nOptimization (LPO) that integrates with any general automatic prompt\nengineering method. We identify the optimization tokens in a prompt and nudge\nthe LLM to focus only on those tokens in its optimization step. We observe\nremarkable performance improvements on Math Reasoning (GSM8k and MultiArith)\nand BIG-bench Hard benchmarks across various automatic prompt engineering\nmethods. Further, we show that LPO converges to the optimal prompt faster than\nglobal methods.",
      "tldr_zh": "本文提出Local Prompt Optimization (LPO)，一种新方法，通过识别并专注于提示中的特定token进行优化，与现有自动提示工程方法集成，从而解决大语言模型(LLMs)提示优化的挑战。LPO显著提升了Math Reasoning基准（如GSM8k和MultiArith）以及BIG-bench Hard的性能，观察到比全局优化方法更快的收敛速度。实验结果证明了LPO在提高提示效率和模型输出质量方面的有效性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted as Oral at NAACL 2025 (Main Conference)",
      "pdf_url": "http://arxiv.org/pdf/2504.20355v1",
      "published_date": "2025-04-29 01:45:47 UTC",
      "updated_date": "2025-04-29 01:45:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:04:49.921136"
    },
    {
      "arxiv_id": "2504.20348v2",
      "title": "CarbonCall: Sustainability-Aware Function Calling for Large Language Models on Edge Devices",
      "title_zh": "翻译失败",
      "authors": [
        "Varatheepan Paramanayakam",
        "Andreas Karatzas",
        "Iraklis Anagnostopoulos",
        "Dimitrios Stamoulis"
      ],
      "abstract": "Large Language Models (LLMs) enable real-time function calling in edge AI\nsystems but introduce significant computational overhead, leading to high power\nconsumption and carbon emissions. Existing methods optimize for performance\nwhile neglecting sustainability, making them inefficient for energy-constrained\nenvironments. We introduce CarbonCall, a sustainability-aware function-calling\nframework that integrates dynamic tool selection, carbon-aware execution, and\nquantized LLM adaptation. CarbonCall adjusts power thresholds based on\nreal-time carbon intensity forecasts and switches between model variants to\nsustain high tokens-per-second throughput under power constraints. Experiments\non an NVIDIA Jetson AGX Orin show that CarbonCall reduces carbon emissions by\nup to 52%, power consumption by 30%, and execution time by 30%, while\nmaintaining high efficiency.",
      "tldr_zh": "该研究针对大型语言模型(LLMs)在边缘设备上进行函数调用的高能耗和碳排放问题，提出CarbonCall框架，这是一种可持续性感知的函数调用方法。CarbonCall整合动态工具选择、碳感知执行和量化LLM适应，通过实时碳强度预测调整功率阈值，并在功率约束下切换模型变体，以维持高吞吐量。实验在NVIDIA Jetson AGX Orin上显示，CarbonCall可将碳排放减少高达52%，功率消耗和执行时间各降低30%，同时保持高效性能。",
      "categories": [
        "cs.PF",
        "cs.AI",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.PF",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.20348v2",
      "published_date": "2025-04-29 01:37:08 UTC",
      "updated_date": "2025-05-02 19:16:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:05:01.770016"
    },
    {
      "arxiv_id": "2504.20342v1",
      "title": "Narrative-Centered Emotional Reflection: Scaffolding Autonomous Emotional Literacy with AI",
      "title_zh": "翻译失败",
      "authors": [
        "Shou-Tzu Han"
      ],
      "abstract": "Reflexion is an AI-powered platform designed to enable structured emotional\nself-reflection at scale. By integrating real-time emotion detection, layered\nreflective prompting, and metaphorical storytelling generation, Reflexion\nempowers users to engage in autonomous emotional exploration beyond basic\nsentiment categorization. Grounded in theories of expressive writing, cognitive\nrestructuring, self-determination, and critical consciousness development, the\nsystem scaffolds a progressive journey from surface-level emotional recognition\ntoward value-aligned action planning. Initial pilot studies with diverse\nparticipants demonstrate positive outcomes in emotional articulation, cognitive\nreframing, and perceived psychological resilience. Reflexion represents a\npromising direction for scalable, theory-informed affective computing\ninterventions aimed at fostering emotional literacy and psychological growth\nacross educational, therapeutic, and public health contexts.",
      "tldr_zh": "Reflexion 是一个 AI 驱动的平台，旨在通过实时情感检测、分层反思提示和比喻故事生成，支持用户进行自主情感探索，超越基本情感分类。系统基于表达性写作(expressive writing)、认知重组(cognitive restructuring)、自我决定(self-determination)和批判意识发展的理论，引导用户从表面情感识别逐步到与价值观一致的行动规划。初步试点研究显示，该平台在情感表达、认知重构和感知心理韧性方面取得了积极成果，为可扩展的情感计算(affective computing)干预在教育、治疗和公共卫生领域推广情感素养和心理成长提供了新方向。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CY",
        "H.5.2; H.1.2"
      ],
      "primary_category": "cs.HC",
      "comment": "10 pages, 5 figures, preliminary results, early-stage work intended\n  for future conference submission",
      "pdf_url": "http://arxiv.org/pdf/2504.20342v1",
      "published_date": "2025-04-29 01:24:46 UTC",
      "updated_date": "2025-04-29 01:24:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:05:15.790638"
    },
    {
      "arxiv_id": "2504.20340v1",
      "title": "A Picture is Worth a Thousand Prompts? Efficacy of Iterative Human-Driven Prompt Refinement in Image Regeneration Tasks",
      "title_zh": "翻译失败",
      "authors": [
        "Khoi Trinh",
        "Scott Seidenberger",
        "Raveen Wijewickrama",
        "Murtuza Jadliwala",
        "Anindya Maiti"
      ],
      "abstract": "With AI-generated content becoming ubiquitous across the web, social media,\nand other digital platforms, it is vital to examine how such content are\ninspired and generated. The creation of AI-generated images often involves\nrefining the input prompt iteratively to achieve desired visual outcomes. This\nstudy focuses on the relatively underexplored concept of image regeneration\nusing AI, in which a human operator attempts to closely recreate a specific\ntarget image by iteratively refining their prompt. Image regeneration is\ndistinct from normal image generation, which lacks any predefined visual\nreference. A separate challenge lies in determining whether existing image\nsimilarity metrics (ISMs) can provide reliable, objective feedback in iterative\nworkflows, given that we do not fully understand if subjective human judgments\nof similarity align with these metrics. Consequently, we must first validate\ntheir alignment with human perception before assessing their potential as a\nfeedback mechanism in the iterative prompt refinement process. To address these\nresearch gaps, we present a structured user study evaluating how iterative\nprompt refinement affects the similarity of regenerated images relative to\ntheir targets, while also examining whether ISMs capture the same improvements\nperceived by human observers. Our findings suggest that incremental prompt\nadjustments substantially improve alignment, verified through both subjective\nevaluations and quantitative measures, underscoring the broader potential of\niterative workflows to enhance generative AI content creation across various\napplication domains.",
      "tldr_zh": "本文研究了在图像再生任务中，迭代人类驱动的提示优化（Iterative Human-Driven Prompt Refinement）的有效性，与普通图像生成不同，图像再生需要精确参考目标图像。研究通过结构化的用户研究，评估了提示调整如何提升再生图像与目标图像的相似度，并检验了图像相似性指标（ISMs）是否与人类主观判断一致。结果表明，增量提示优化显著改善了图像对齐度，这在主观评估和定量测量中均得到验证，从而突显了迭代工作流在生成AI内容创建中的广阔潜力。",
      "categories": [
        "cs.AI",
        "cs.CV",
        "cs.HC"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.20340v1",
      "published_date": "2025-04-29 01:21:16 UTC",
      "updated_date": "2025-04-29 01:21:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:05:26.978296"
    },
    {
      "arxiv_id": "2504.21049v1",
      "title": "Phishing URL Detection using Bi-LSTM",
      "title_zh": "使用 Bi-LSTM 的 Phishing URL 检测",
      "authors": [
        "Sneha Baskota"
      ],
      "abstract": "Phishing attacks threaten online users, often leading to data breaches,\nfinancial losses, and identity theft. Traditional phishing detection systems\nstruggle with high false positive rates and are usually limited by the types of\nattacks they can identify. This paper proposes a deep learning-based approach\nusing a Bidirectional Long Short-Term Memory (Bi-LSTM) network to classify URLs\ninto four categories: benign, phishing, defacement, and malware. The model\nleverages sequential URL data and captures contextual information, improving\nthe accuracy of phishing detection. Experimental results on a dataset\ncomprising over 650,000 URLs demonstrate the model's effectiveness, achieving\n97% accuracy and significant improvements over traditional techniques.",
      "tldr_zh": "本研究针对网络钓鱼攻击导致的数据泄露、金融损失和身份盗窃等问题，提出了一种基于 Bidirectional Long Short-Term Memory (Bi-LSTM) 网络的深度学习方法，用于检测和分类 URL。模型通过处理顺序 URL 数据并捕捉上下文信息，将 URL 分类为 benign、phishing、defacement 和 malware 四类，显著降低了传统系统的假阳性率。实验在超过 650,000 个 URL 的数据集上实现了 97% 的准确率，并比传统技术取得了显著改进。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.21049v1",
      "published_date": "2025-04-29 00:55:01 UTC",
      "updated_date": "2025-04-29 00:55:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:05:37.634079"
    },
    {
      "arxiv_id": "2504.20323v1",
      "title": "Labeling Case Similarity based on Co-Citation of Legal Articles in Judgment Documents with Empirical Dispute-Based Evaluation",
      "title_zh": "翻译失败",
      "authors": [
        "Chao-Lin Liu",
        "Po-Hsien Wu",
        "Yi-Ting Yu"
      ],
      "abstract": "This report addresses the challenge of limited labeled datasets for\ndeveloping legal recommender systems, particularly in specialized domains like\nlabor disputes. We propose a new approach leveraging the co-citation of legal\narticles within cases to establish similarity and enable algorithmic\nannotation. This method draws a parallel to the concept of case co-citation,\nutilizing cited precedents as indicators of shared legal issues. To evaluate\nthe labeled results, we employ a system that recommends similar cases based on\nplaintiffs' accusations, defendants' rebuttals, and points of disputes. The\nevaluation demonstrates that the recommender, with finetuned text embedding\nmodels and a reasonable BiLSTM module can recommend labor cases whose\nsimilarity was measured by the co-citation of the legal articles. This research\ncontributes to the development of automated annotation techniques for legal\ndocuments, particularly in areas with limited access to comprehensive legal\ndatabases.",
      "tldr_zh": "该研究针对法律推荐系统在专业领域（如劳动纠纷）中标签数据集有限的挑战，提出了一种基于法律文章共同引用（co-citation）的方法来标注案例相似性，该方法利用引用的先例作为共享法律问题的指标。研究设计了一个推荐系统，通过原告指控、被告反驳和争议点进行评估，并结合微调的文本嵌入模型（text embedding models）和 BiLSTM 模块来推荐相似案例。实验结果显示，该系统能够有效识别通过共同引用测量的相似劳动案例，从而为法律文档的自动化标注提供新途径，尤其适用于数据库资源有限的场景。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.DL",
        "cs.IR",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "16 pages, 9 figures, 2 tables, the Nineteenth International Workshop\n  on Juris-Informatics (JURISIN 2025), associated with the Seventeenth JSAI\n  International Symposium on AI (JSAI-isAI 2025)",
      "pdf_url": "http://arxiv.org/pdf/2504.20323v1",
      "published_date": "2025-04-29 00:26:37 UTC",
      "updated_date": "2025-04-29 00:26:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:05:49.868085"
    },
    {
      "arxiv_id": "2504.21048v1",
      "title": "Multi-Agent Reinforcement Learning for Resources Allocation Optimization: A Survey",
      "title_zh": "翻译失败",
      "authors": [
        "Mohamad A. Hady",
        "Siyi Hu",
        "Mahardhika Pratama",
        "Jimmy Cao",
        "Ryszard Kowalczyk"
      ],
      "abstract": "Multi-Agent Reinforcement Learning (MARL) has become a powerful framework for\nnumerous real-world applications, modeling distributed decision-making and\nlearning from interactions with complex environments. Resource Allocation\nOptimization (RAO) benefits significantly from MARL's ability to tackle dynamic\nand decentralized contexts. MARL-based approaches are increasingly applied to\nRAO challenges across sectors playing pivotal roles to Industry 4.0\ndevelopments. This survey provides a comprehensive review of recent MARL\nalgorithms for RAO, encompassing core concepts, classifications, and a\nstructured taxonomy. By outlining the current research landscape and\nidentifying primary challenges and future directions, this survey aims to\nsupport researchers and practitioners in leveraging MARL's potential to advance\nresource allocation solutions.",
      "tldr_zh": "这篇调查综述了Multi-Agent Reinforcement Learning (MARL) 在Resource Allocation Optimization (RAO) 中的应用，强调MARL在处理动态和去中心化环境中的优势。论文回顾了MARL算法的核心概念、分类以及结构化分类，涵盖其在Industry 4.0 等领域的实际应用。作者识别了当前研究中的主要挑战和未来方向，以帮助研究者和从业者利用MARL提升资源分配解决方案的效率。",
      "categories": [
        "cs.MA",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.MA",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.21048v1",
      "published_date": "2025-04-29 00:18:31 UTC",
      "updated_date": "2025-04-29 00:18:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:06:01.797776"
    },
    {
      "arxiv_id": "2504.21047v1",
      "title": "Model Connectomes: A Generational Approach to Data-Efficient Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Klemen Kotar",
        "Greta Tuckute"
      ],
      "abstract": "Biological neural networks are shaped both by evolution across generations\nand by individual learning within an organism's lifetime, whereas standard\nartificial neural networks undergo a single, large training procedure without\ninherited constraints. In this preliminary work, we propose a framework that\nincorporates this crucial generational dimension - an \"outer loop\" of evolution\nthat shapes the \"inner loop\" of learning - so that artificial networks better\nmirror the effects of evolution and individual learning in biological\norganisms. Focusing on language, we train a model that inherits a \"model\nconnectome\" from the outer evolution loop before exposing it to a\ndevelopmental-scale corpus of 100M tokens. Compared with two closely matched\ncontrol models, we show that the connectome model performs better or on par on\nnatural language processing tasks as well as alignment to human behavior and\nbrain data. These findings suggest that a model connectome serves as an\nefficient prior for learning in low-data regimes - narrowing the gap between\nsingle-generation artificial models and biologically evolved neural networks.",
      "tldr_zh": "本研究提出“Model Connectomes”框架，将生物神经网络的跨代进化（evolution）和个体学习（individual learning）融入人工语言模型训练中，通过一个“外循环”进化来塑造“内循环”学习，从而提升数据效率。方法包括训练模型继承“model connectome”作为先验知识，并在100M tokens的语料上进行学习。与对照模型相比，该模型在自然语言处理任务（NLP tasks）上表现更好或相当，并更接近人类行为和脑数据对齐。结果表明，“model connectome”作为高效的prior，在低数据环境下缩小了单代人工模型与生物神经网络的差距。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.21047v1",
      "published_date": "2025-04-29 00:17:53 UTC",
      "updated_date": "2025-04-29 00:17:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:06:15.032776"
    },
    {
      "arxiv_id": "2504.20318v1",
      "title": "Leveraging Action Relational Structures for Integrated Learning and Planning",
      "title_zh": "利用行动关系结构实现集成",
      "authors": [
        "Ryan Xiao Wang",
        "Felipe Trevizan"
      ],
      "abstract": "Recent advances in planning have explored using learning methods to help\nplanning. However, little attention has been given to adapting search\nalgorithms to work better with learning systems. In this paper, we introduce\npartial-space search, a new search space for classical planning that leverages\nthe relational structure of actions given by PDDL action schemas -- a structure\noverlooked by traditional planning approaches. Partial-space search provides a\nmore granular view of the search space and allows earlier pruning of poor\nactions compared to state-space search. To guide partial-space search, we\nintroduce action set heuristics that evaluate sets of actions in a state. We\ndescribe how to automatically convert existing heuristics into action set\nheuristics. We also train action set heuristics from scratch using large\ntraining datasets from partial-space search. Our new planner, LazyLifted,\nexploits our better integrated search and learning heuristics and outperforms\nthe state-of-the-art ML-based heuristic on IPC 2023 learning track (LT)\nbenchmarks. We also show the efficiency of LazyLifted on high-branching factor\ntasks and show that it surpasses LAMA in the combined IPC 2023 LT and\nhigh-branching factor benchmarks.",
      "tldr_zh": "本研究提出 partial-space search，一种新的搜索空间，利用 PDDL action schemas 的动作关系结构，相比传统 state-space search 提供更细粒度的视图并实现更早的动作修剪，从而更好地整合学习和规划。论文引入 action set heuristics 用于评估状态中的动作集，并描述了从现有启发式转换或从零训练新启发式的方法。实验结果显示，新规划器 LazyLifted 在 IPC 2023 学习轨道基准上优于最先进的 ML-based 启发式，并在高分支因子任务中超越 LAMA，展示了其高效性和整体性能提升。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Extended version of ICAPS 2025 paper",
      "pdf_url": "http://arxiv.org/pdf/2504.20318v1",
      "published_date": "2025-04-29 00:10:14 UTC",
      "updated_date": "2025-04-29 00:10:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:06:26.468147"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 135,
  "processed_papers_count": 135,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-24T18:06:48.924892"
}