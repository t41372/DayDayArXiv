{
  "date": "2025-04-29",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2025-04-29 的 arXiv 中文 TLDR 快报！\n\n今天 arXiv 的论文再次被 **大型语言模型 (LLM)** 全面占领，讨论范围极广，从**基础理论、效率优化、安全性、可解释性**，到**推理能力提升、代码生成、多模态应用、信息检索增强 (RAG)、评测基准**等无所不包。特别值得关注的是对现有评测体系 **Chatbot Arena 的深刻反思 (论文 18)**，以及 **仅用一个样本进行强化学习就能显著提升 LLM 推理能力 (论文 61)** 的惊人发现。此外，**个性化多模态生成 (论文 1)**、**高效 LLM 预训练框架 GaLore 2 (论文 75)** 以及 **LLM 驱动的 Linux 内核崩溃修复 (论文 78)** 也展示了 AI 能力的持续拓展。\n\n**重点论文聚焦：**\n\n*   **排行榜的幻觉 (The Leaderboard Illusion) (论文 18)**\n    *   这篇论文对流行的 LLM 评测平台 Chatbot Arena 提出了系统性批评。研究发现，不透明的私下测试使得少数供应商受益，他们可以测试多个版本并选择性公布最佳分数，导致评分存在偏差。此外，闭源模型获得更高的采样率和更少被移除，造成数据访问的不对称性 (Google 和 OpenAI 分别获得约 20% 数据，而 83 个开源模型合计仅 30%)。研究表明，访问 Arena 数据能带来显著性能提升，这可能导致模型过度拟合 Arena 而非通用能力。论文呼吁改革评测框架，促进更公平透明的基准测试。\n\n*   **单样本强化学习提升 LLM 推理能力 (Reinforcement Learning for Reasoning in Large Language Models with One Training Example) (论文 61)**\n    *   这项研究展示了一个惊人的发现：使用带有可验证奖励的强化学习 (RLVR)，仅需一个训练样本，就能显著提升 LLM 的数学推理能力。例如，在 Qwen2.5-Math-1.5B 模型上，仅用一个特定样本训练，MATH500 准确率从 36.0% 提升到 73.6%，多个基准平均性能从 17.6% 提升到 35.7%，效果媲美使用 1.2k 样本训练。这种现象在不同模型、RL 算法和样本上均有体现，并观察到跨领域泛化、自反思增加和“饱和后泛化”等现象。研究指出策略梯度损失是主要原因，并强调了探索的重要性。\n\n*   **GaLore 2: 通过梯度低秩投影进行大规模 LLM 预训练 (GaLore 2: Large-Scale LLM Pre-Training by Gradient Low-Rank Projection) (论文 75)**\n    *   GaLore 是一种利用梯度低秩结构来节省 LLM 训练内存的技术。这篇论文提出了 GaLore 2，一个更高效、可扩展的框架，解决了原方法中 SVD 计算开销大、与 FSDP 等并行策略集成困难等问题，并整合了近期进展。研究者使用 GaLore 2 成功从头预训练了 Llama 7B 模型（使用高达 5000 亿 token），展示了其在真实 LLM 预训练场景中的潜力。\n\n*   **YoChameleon: 个性化视觉与语言生成 (YoChameleon: Personalized Vision and Language Generation) (论文 1)**\n    *   大型多模态模型 (MLLM) 通常缺乏对用户特定概念的个性化知识。这篇论文首次尝试研究 MLLM 的个性化问题，提出了 Yo'Chameleon。给定一个概念的 3-5 张图片，Yo'Chameleon 利用软提示调优 (soft-prompt tuning) 嵌入特定主体信息，使其能够 (i) 回答关于该主体的问题，以及 (ii) 在新情境下生成包含该主体像素级细节的图像。训练中使用了自提示优化机制和“软正例”图像生成方法。\n\n*   **CrashFixer: 面向 Linux 内核的崩溃解决智能体 (CrashFixer: A crash resolution agent for the Linux kernel) (论文 78)**\n    *   将 LLM 应用于修复复杂的系统级 Bug (如 Linux 内核) 极具挑战。该研究提出了 CrashFixer，首个基于 LLM 的、适用于 Linux 内核 Bug 的软件修复智能体。受内核开发者工作流启发，研究者识别了专家解决内核崩溃的关键能力，并改进了 kGym 平台，创建了 kGymSuite 以支持 LLM 智能体在内核规模代码上的运行。评估表明，显式生成修复假设对于处理复杂系统 Bug 非常有价值，并且 CrashFixer 对一些未解决的 Bug 提出了看似合理的补丁建议。\n\n**LLM 推理、学习与优化:**\n\n*   **面向 LLM 智能体的高效探索 (Toward Efficient Exploration by Large Language Model Agents) (论文 2)**：指出当前 LLM Agent 在数据高效 RL 的探索方面存在挑战，提出让 LLM 显式实现已知的、数据高效的 RL 算法 (如后验采样)，而非隐式模仿，实验证明效果更好。\n*   **思维轨迹：从大模型到小模型的推理蒸馏以增强算术问题解决 (Trace-of-Thought: Enhanced Arithmetic Problem Solving via Reasoning Distillation From Large to Small Language Models) (论文 8)**：提出 Trace-of-Thought Prompting，一种零样本提示方法，指导 LLM 创建可观察子问题，显著提升了小型开源模型 (≤7B) 的算术推理能力。\n*   **防御链思维：结构化推理引发 LLM 对抗引用污染的鲁棒性 (Chain-of-Defensive-Thought: Structured Reasoning Elicits Robustness in Large Language Models against Reference Corruption) (论文 37)**：提出 Chain-of-Defensive-Thought，通过提供带有结构化防御性推理的 few-shot 示例，显著提高了 LLM 在面对被污染（如提示注入）的参考信息时的鲁棒性。\n*   **超越最终答案：你的推理轨迹揭示了更多 (Beyond the Last Answer: Your Reasoning Trace Uncovers More than You Think) (论文 44)**：挑战仅依赖 LLM 推理最终答案进行评估的做法，提出分析中间“子思维”(subthoughts)，通过聚合不同子思维路径产生的答案（取众数），显著提高了数学推理任务的准确率。\n*   **面向记忆约束下 LLM 推理的强化学习 (Reinforcement Learning for LLM Reasoning Under Memory Constraints) (论文 27)**：探索在单 GPU (40GB) 限制下，使用无 Critic 的 RL 方法 (S-GRPO, T-SPMO) 结合 LoRA 微调，显著提升了 Qwen2-1.5B 在 SVAMP 等基准上的推理准确率。\n*   **RV-Syn: 基于结构化函数库的理性可验证数学推理数据合成 (RV-Syn: Rational and Verifiable Mathematical Reasoning Data Synthesis based on Structured Function Library) (论文 77)**：提出 RV-Syn 方法，通过构建结构化数学运算函数库生成计算图作为解，再反向生成问题，确保了生成过程的逻辑性和解的可验证性，有效扩展了高质量推理数据集。\n*   **局部提示优化 (Local Prompt Optimization) (论文 84)**：提出 LPO 方法，改进自动提示工程，通过识别提示中的关键优化 token 并引导 LLM 聚焦优化这些 token，显著提升了在数学推理和 BIG-bench Hard 任务上的性能，且收敛更快。\n*   **群体相对知识蒸馏：学习教师的关系归纳偏置 (Group Relative Knowledge Distillation: Learning from Teacher's Relational Inductive Bias) (论文 67)**：提出 GRKD，一种新的知识蒸馏框架，通过学习类别间的相对排序而非拟合绝对概率分布来传递教师知识，关注关系结构，提升了学生模型的泛化能力。\n\n**LLM 评测、安全与伦理:**\n\n*   **OSVBench: 面向操作系统验证规范生成任务的 LLM 基准 (OSVBench: Benchmarking LLMs on Specification Generation Tasks for Operating System Verification) (论文 7)**：提出 OSVBench，首个评估 LLM 为操作系统内核验证任务生成完整规范代码能力的基准。任务涉及长上下文 (20-30k token)，评估了 12 个 LLM，发现当前模型在该任务上性能有限。\n*   **代码生成 LLM 的幻觉：分类、基准、缓解与挑战 (Hallucination by Code Generation LLMs: Taxonomy, Benchmarks, Mitigation, and Challenges) (论文 31)**：综述了 CodeLLM 生成幻觉代码的问题，对其类型进行分类，回顾了现有基准和缓解策略，并指出了开放挑战和未来研究方向。\n*   **LLM 能检测释义和机器翻译中的内在幻觉吗？ (Can LLMs Detect Intrinsic Hallucinations in Paraphrasing and Machine Translation?) (论文 45)**：基于 HalluciGen 任务，评估了一系列开源 LLM 检测翻译和释义中内在幻觉的能力，发现模型性能各异，但提示选择影响不大，NLI 模型表现相当。\n*   **面向视觉分类器的无监督自动偏见检测 (Classifier-to-Bias: Toward Unsupervised Automatic Bias Detection for Visual Classifiers) (论文 15)**：提出 C2B，首个无需任何标注数据即可发现分类模型偏见的框架，仅依赖任务描述，利用 LLM 生成偏见提议和图像标题，通过检索图像评估模型准确性。\n*   **AI 的“化身博士”临界点行为 (Jekyll-and-Hyde Tipping Point in an AI's Behavior) (论文 5)**：从第一性原理推导出一个精确公式，解释了 LLM 输出（如 ChatGPT）何时可能突然从中途变得错误、误导或危险，认为是注意力分散到极限导致“断裂”，并提出了预防方法。\n*   **当测试 AI 时考验我们：在数字前线保护心理健康 (When Testing AI Tests Us: Safeguarding Mental Health on the Digital Frontlines) (论文 13)**：探讨了 AI 红队测试人员（通过交互诱导 AI 产生有害内容）面临的心理健康风险，认为这是一个关键的职场安全问题，并借鉴其他职业（演员、心理医生等）的经验提出了保护策略。\n*   **LLM 生成的 Web 应用代码隐藏风险：以安全为中心的 LLM 代码生成能力评估 (The Hidden Risks of LLM-Generated Web Application Code: A Security-Centric Evaluation of Code Generation Capabilities in Large Language Models) (论文 58)**：评估了多个 LLM (ChatGPT, DeepSeek, Claude 等) 生成的 Web 应用代码的安全性，发现普遍存在认证、会话管理、输入验证等方面的严重漏洞，强调了人工审查的必要性。\n*   **令牌高效的提示注入攻击：通过自适应令牌压缩引发 LLM 推理终止 (Token-Efficient Prompt Injection Attack: Provoking Cessation in LLM Reasoning via Adaptive Token Compression) (论文 66)**：针对 DeepSeek-R1 的“思维停止”漏洞，提出“推理中断攻击”，通过自适应令牌压缩显著降低触发该漏洞所需的提示长度，并分析了漏洞成因。\n*   **为医学 AI 中的后验解释辩护 (In defence of post-hoc explanations in medical AI) (论文 40)**：回应了对医学 AI 后验解释（仅近似而非复制黑箱推理过程）的批评，认为即使如此，它们仍能提高用户的功能理解、 clinician-AI 团队的准确性，并辅助决策辩护。\n*   **联邦学习、伦理与医学 AI 中的双重黑箱问题 (Federated learning, ethics, and the double black box problem in medical AI) (论文 50)**：探讨了医学联邦学习 (FL) 的伦理风险，认为其引入了新的“联邦不透明性”，导致了独特的“双重黑箱问题”，并指出了实现伦理可行性需克服的挑战。\n*   **AI 可解释性的极限：一种算法信息论方法 (The Limits of AI Explainability: An Algorithmic Information Theory Approach) (论文 46)**：使用算法信息论为 AI 可解释性的基本限制奠定理论基础，证明了简单解释必然存在误差，界定了复杂度与误差/维度的关系，并提出了监管不可能性定理。\n\n**信息检索与 RAG:**\n\n*   **ReasonIR: 为推理任务训练检索器 (ReasonIR: Training Retrievers for Reasoning Tasks) (论文 60)**：提出了首个专门为通用推理任务训练的检索器 ReasonIR-8B。通过合成具有挑战性的查询和难负例的数据进行训练，在推理密集型 IR 基准 BRIGHT 上达到 SOTA，并显著提升了 MMLU 等 RAG 任务性能。\n*   **UniversalRAG: 跨越多模态和粒度语料库的检索增强生成 (UniversalRAG: Retrieval-Augmented Generation over Multiple Corpora with Diverse Modalities and Granularities) (论文 41)**：提出 UniversalRAG 框架，能从具有不同模态（文本、图像、视频等）和不同粒度的异构知识源中检索和整合知识，通过模态感知路由机制解决模态偏差问题。\n*   **CBM-RAG: 通过多智能体 RAG 和概念瓶颈模型展示放射学报告生成的增强可解释性 (CBM-RAG: Demonstrating Enhanced Interpretability in Radiology Report Generation with Multi-Agent RAG and Concept Bottleneck Models) (论文 16)**：结合概念瓶颈模型 (CBM) 提取可理解的临床概念和多智能体 RAG 系统生成报告，提高了放射学报告生成的自动化水平和可解释性。\n*   **PaRT: 通过个性化实时检索增强主动社交聊天机器人 (PaRT: Enhancing Proactive Social Chatbots with Personalized Real-Time Retrieval) (论文 57)**：提出 PaRT 框架，使社交机器人能基于用户画像和对话上下文，通过 LLM 识别意图、生成个性化话题，并从外部知识源 (RedNote) 检索信息，生成更主动、更有吸引力的回复，显著延长了对话时长。\n*   **通过分层 LLM 提示增强新闻推荐 (Enhancing News Recommendation with Hierarchical LLM Prompting) (论文 71)**：提出 PNR-LLM 方法，利用 LLM 从新闻标题和摘要中生成更深层次的语义信息和相关实体，丰富内容表示，并通过注意力机制聚合信息，提升个性化新闻推荐效果。\n*   **ARCS: 具有迭代优化的智能体检索增强代码合成 (ARCS: Agentic Retrieval-Augmented Code Synthesis with Iterative Refinement) (论文 76)**：提出 ARCS 框架，用于超算领域的代码生成、补全和翻译。结合 RAG、CoT 推理和实时执行反馈，通过状态-动作搜索树优化生成代码，在基准测试中优于传统方法。\n*   **生成式 AI 时代的信息检索：RGB 模型 (Information Retrieval in the Age of Generative AI: The RGB Model) (论文 59)**：提出了一个随机模型来量化 GenAI（特别是 RAG）对互联网信息动态的影响，分析表明 GenAI 的快速采用可能导致错误信息加速传播，强调高质量答案需要时间和人力。\n\n**多模态与计算机视觉:**\n\n*   **SpaRE: 用合成数据增强视觉语言模型的空间推理能力 (SpaRE: Enhancing Spatial Reasoning in Vision-Language Models with Synthetic Data) (论文 51)**：发现 VLM 在空间推理方面较弱，现有数据集中空间关系稀疏。通过从详细图像描述生成大规模合成 VQA 数据集进行训练，显著提升了 VLM 的空间推理性能。\n*   **AlignDiT: 用于同步语音生成的多模态对齐 Diffusion Transformer (AlignDiT: Multimodal Aligned Diffusion Transformer for Synchronized Speech Generation) (论文 54)**：提出 AlignDiT 模型，用于从文本、视频和参考音频生成高质量、同步且自然的语音。采用 DiT 架构，探索了多模态对齐策略和新的多模态无分类器引导机制。\n*   **通过视觉 Transformer 提升伪造视频检测 (Advance Fake Video Detection via Vision Transformers) (论文 48)**：将基于 ViT 的伪造图像检测思想扩展到视频领域，提出一个框架有效整合 ViT 嵌入随时间变化的信息，在新的大型数据集上展现了良好的准确性和泛化能力。\n*   **TrueFake: 包含最新伪造图像且在社交网络共享的真实世界案例数据集 (TrueFake: A Real World Case Dataset of Last Generation Fake Images also Shared on Social Networks) (论文 49)**：发布了一个包含 60 万张图像的大型基准数据集 TrueFake，特点是包含了最新的生成技术伪造的图像，并且模拟了通过社交网络（带压缩和处理）传播的场景，用于评估检测器在真实挑战下的性能。\n*   **RadSAM: 用 2D 可提示模型分割 3D 放射学图像 (RadSAM: Segmenting 3D radiological images with a 2D promptable model) (论文 26)**：提出 RadSAM，一种用 2D 的 SAM 模型通过单次提示分割 3D 目标（如 CT/MRI 图像）的方法。通过训练模型使用噪声掩模作为初始提示，并采用迭代推理流程逐片重建 3D 掩模。\n*   **GuassTrap: 针对 3D 高斯溅射的隐蔽中毒攻击以实现目标场景混淆 (GaussTrap: Stealthy Poisoning Attacks on 3D Gaussian Splatting for Targeted Scene Confusion) (论文 28)**：首次系统研究了 3D 高斯溅射 (3DGS) 中的后门威胁，提出 GuassTrap 攻击方法，可在特定视点注入恶意视图导致场景混淆，同时保持其他视图的高质量渲染，具有隐蔽性。\n\n**AI for Science & Specific Domains:**\n\n*   **JTreeformer: 通过潜在扩散模型进行分子生成的图 Transformer (JTreeformer: Graph-Transformer via Latent-Diffusion Model for Molecular Generation) (论文 36)**：提出 JTreeformer 框架，将图生成转化为连接树生成，结合 GCN 和 Transformer 进行编码解码，并在潜在空间中加入扩散模型，用于高效分子生成。\n*   **FourierSpecNet: 受傅里叶谱方法启发的用于求解玻尔兹曼方程的神经碰撞算子近似 (FourierSpecNet: Neural Collision Operator Approximation Inspired by the Fourier Spectral Method for Solving the Boltzmann Equation) (论文 79)**：提出 FourierSpecNet，一个混合框架，结合傅里叶谱方法和深度学习，在傅里叶空间中高效近似玻尔兹曼方程的碰撞算子，支持分辨率不变学习和零样本超分辨率。\n*   **认知地图是生成式程序 (Cognitive maps are generative programs) (论文 55)**：提出假设，认为认知地图（心理表征）可能是利用可预测性和冗余性的生成式程序。通过行为实验和计算模型（利用 LLM 作为人类先验知识嵌入）验证，发现人类在结构化空间中的导航规划策略与程序化地图表征一致。\n*   **烹饪创意：一种认知启发的方法，通过结构化表示增强 LLM 创造力 (Cooking Up Creativity: A Cognitively-Inspired Approach for Enhancing LLM Creativity through Structured Representations) (论文 52)**：提出将 LLM 与结构化表示和认知启发的操作相结合以产生更有创意的想法。以烹饪为例，DishCOVER 模型通过重组食谱的结构化表示生成创意食谱，比 GPT-4o 更新颖、更多样。\n*   **ECOSoundSet: 用于北欧、中欧和温带西欧直翅目和蝉科昆虫自动声学识别的精细标注数据集 (ECOSoundSet: a finely annotated dataset for the automated acoustic identification of Orthoptera and Cicadidae in North, Central and temperate Western Europe) (论文 35)**：发布了一个包含 200 种直翅目和 24 种蝉科昆虫（共 10653 条录音）的大型声学数据集，包含粗略标签和精细标签（时间和频率范围），并提供了训练/验证/测试划分，用于训练深度学习模型。\n*   **MuRAL: 一个带有自然语言标注的用于日常生活活动的多住户环境传感器数据集 (MuRAL: A Multi-Resident Ambient Sensor Dataset Annotated with Natural Language for Activities of Daily Living) (论文 65)**：发布了 MuRAL 数据集，包含 21 小时以上的多用户智能家居环境传感器数据，带有细粒度的自然语言描述、住户身份和活动标签，旨在支持基于 LLM 的活动理解研究。\n*   **SCOPE-MRI: Bankart 损伤检测作为挑战性诊断中数据整理和深度学习的案例研究 (SCOPE-MRI: Bankart Lesion Detection as a Case Study in Data Curation and Deep Learning for Challenging Diagnoses) (论文 81)**：发布了首个公开的肩部病理学专家标注数据集 ScopeMRI，并提出了一个 DL 框架用于在标准 MRI 和 MRA 上检测 Bankart 损伤（一种诊断困难的肩关节唇撕裂），模型在标准 MRI 上的表现达到了放射科医生解读 MRA 的水平。\n\n**其他值得关注的研究:**\n\n*   **中心辐射式学习：高效可扩展的协作机器学习 (Hubs and Spokes Learning: Efficient and Scalable Collaborative Machine Learning) (论文 3)**：提出 HSL 框架，结合了联邦学习和去中心化学习的优点，避免了单点故障，并在相同/更低通信预算下优于 P2PL 方法 ELL。\n*   **狂野中的 Grokking：用 Transformer 进行真实世界多跳推理的数据增强 (Grokking in the Wild: Data Augmentation for Real-World Multi-Hop Reasoning with Transformers) (论文 39)**：首次将 Grokking（从记忆到泛化的转变）扩展到真实世界事实数据，通过精心设计的合成数据增强稀疏知识图谱，显著提高了 Transformer 在多跳推理任务上的性能。\n*   **用于旋转机械的基于图的故障诊断：自适应分割与结构特征集成 (Graph-Based Fault Diagnosis for Rotating Machinery: Adaptive Segmentation and Structural Feature Integration) (论文 38)**：提出一种基于图的旋转机械故障诊断框架，将振动信号转化为图结构，利用图度量和局部特征进行分类，在基准数据集上表现出高精度和鲁棒性。\n*   **利用动作关系结构进行集成学习和规划 (Leveraging Action Relational Structures for Integrated Learning and Planning) (论文 89)**：提出部分空间搜索 (partial-space search) 和动作集启发式 (action set heuristics) 来更好地结合学习和规划，利用 PDDL 动作模式的关系结构，提高了规划效率。\n*   **关于少量随机比特的随机舍入 (On Stochastic Rounding with Few Random Bits) (论文 53)**：研究了在低精度浮点运算中使用少量随机比特进行随机舍入 (SR) 的不同实现方式，发现一些看似自然的实现会引入显著偏差，并探讨了其在机器学习中的影响。\n*   **TAMO: 通过工具辅助 LLM 智能体和多模态观测数据进行细粒度根因分析 (TAMO:Fine-Grained Root Cause Analysis via Tool-Assisted LLM Agent with Multi-Modality Observation Data) (论文 70)**：提出 TAMO，一个用于微服务根因分析 (RCA) 的工具辅助 LLM 智能体，统一多模态观测数据，利用专门工具感知环境，克服 LLM 处理实时依赖和原始数据的限制。\n*   **CarbonCall: 边缘设备上大型语言模型的可持续性感知函数调用 (CarbonCall: Sustainability-Aware Function Calling for Large Language Models on Edge Devices) (论文 85)**：提出 CarbonCall 框架，在 LLM 函数调用中集成动态工具选择、碳感知执行和量化模型适应，根据实时碳强度预测调整功耗，显著降低碳排放和功耗。\n\n今天的论文内容非常丰富，涵盖了从理论到应用的众多方向。希望这份 TLDR 能帮助你快速把握今日 arXiv 的精华！",
  "papers": [
    {
      "arxiv_id": "2504.20998v1",
      "title": "YoChameleon: Personalized Vision and Language Generation",
      "title_zh": "YoChameleon：个性化的视觉和语言生成\n",
      "authors": [
        "Thao Nguyen",
        "Krishna Kumar Singh",
        "Jing Shi",
        "Trung Bui",
        "Yong Jae Lee",
        "Yuheng Li"
      ],
      "abstract": "Large Multimodal Models (e.g., GPT-4, Gemini, Chameleon) have evolved into\npowerful tools with millions of users. However, they remain generic models and\nlack personalized knowledge of specific user concepts. Previous work has\nexplored personalization for text generation, yet it remains unclear how these\nmethods can be adapted to new modalities, such as image generation. In this\npaper, we introduce Yo'Chameleon, the first attempt to study personalization\nfor large multimodal models. Given 3-5 images of a particular concept,\nYo'Chameleon leverages soft-prompt tuning to embed subject-specific information\nto (i) answer questions about the subject and (ii) recreate pixel-level details\nto produce images of the subject in new contexts. Yo'Chameleon is trained with\n(i) a self-prompting optimization mechanism to balance performance across\nmultiple modalities, and (ii) a ``soft-positive\" image generation approach to\nenhance image quality in a few-shot setting.",
      "tldr_zh": "Yo'Chameleon是首个针对大型多模态模型进行个性化定制的研究。它通过仅使用3-5张特定概念的图像，利用软提示调整(soft-prompt tuning)将特定主题的信息嵌入模型，从而实现：(1) 回答关于该主题的问题；(2) 在新的上下文中生成该主题的图像，并重现像素级的细节。Yo'Chameleon采用自提示优化机制(self-prompting optimization mechanism)平衡跨模态性能，并使用“软正向”(soft-positive)图像生成方法提高少样本情况下的图像质量。\n",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "CVPR 2025; Project page: https://thaoshibe.github.io/YoChameleon",
      "pdf_url": "http://arxiv.org/pdf/2504.20998v1",
      "published_date": "2025-04-29 17:59:57 UTC",
      "updated_date": "2025-04-29 17:59:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-01T02:22:55.477922"
    },
    {
      "arxiv_id": "2504.20997v1",
      "title": "Toward Efficient Exploration by Large Language Model Agents",
      "title_zh": "面向基于大型语言模型智能体的高效探索\n",
      "authors": [
        "Dilip Arumugam",
        "Thomas L. Griffiths"
      ],
      "abstract": "A burgeoning area within reinforcement learning (RL) is the design of\nsequential decision-making agents centered around large language models (LLMs).\nWhile autonomous decision-making agents powered by modern LLMs could facilitate\nnumerous real-world applications, such successes demand agents that are capable\nof data-efficient RL. One key obstacle to achieving data efficiency in RL is\nexploration, a challenge that we demonstrate many recent proposals for LLM\nagent designs struggle to contend with. Meanwhile, classic algorithms from the\nRL literature known to gracefully address exploration require technical\nmachinery that can be challenging to operationalize in purely natural language\nsettings. In this work, rather than relying on finetuning or in-context\nlearning to coax LLMs into implicitly imitating a RL algorithm, we illustrate\nhow LLMs can be used to explicitly implement an existing RL algorithm\n(Posterior Sampling for Reinforcement Learning) whose capacity for\nstatistically-efficient exploration is already well-studied. We offer empirical\nresults demonstrating how our LLM-based implementation of a known,\ndata-efficient RL algorithm can be considerably more effective in natural\nlanguage tasks that demand prudent exploration.",
      "tldr_zh": "这篇论文探讨了如何提高基于大型语言模型(LLM)的智能体在强化学习(RL)中的探索效率。研究指出，现有的LLM智能体设计在探索方面表现不佳。论文提出了一种方法，即利用LLM显式地实现一种已知的、数据高效的RL算法——后验采样强化学习(Posterior Sampling for Reinforcement Learning)。实验结果表明，这种基于LLM的后验采样方法在需要谨慎探索的自然语言任务中，比其他方法更有效。该研究强调了将经典RL算法与LLM结合，以实现数据高效探索的潜力。\n",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.20997v1",
      "published_date": "2025-04-29 17:59:48 UTC",
      "updated_date": "2025-04-29 17:59:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-01T02:23:07.424802"
    },
    {
      "arxiv_id": "2504.20988v1",
      "title": "Hubs and Spokes Learning: Efficient and Scalable Collaborative Machine Learning",
      "title_zh": "枢纽辐射式学习：高效且可扩展的协作式机器学习\n",
      "authors": [
        "Atul Sharma",
        "Kavindu Herath",
        "Saurabh Bagchi",
        "Chaoyue Liu",
        "Somali Chaterji"
      ],
      "abstract": "We introduce the Hubs and Spokes Learning (HSL) framework, a novel paradigm\nfor collaborative machine learning that combines the strengths of Federated\nLearning (FL) and Decentralized Learning (P2PL). HSL employs a two-tier\ncommunication structure that avoids the single point of failure inherent in FL\nand outperforms the state-of-the-art P2PL framework, Epidemic Learning Local\n(ELL). At equal communication budgets (total edges), HSL achieves higher\nperformance than ELL, while at significantly lower communication budgets, it\ncan match ELL's performance. For instance, with only 400 edges, HSL reaches the\nsame test accuracy that ELL achieves with 1000 edges for 100 peers (spokes) on\nCIFAR-10, demonstrating its suitability for resource-constrained systems. HSL\nalso achieves stronger consensus among nodes after mixing, resulting in\nimproved performance with fewer training rounds. We substantiate these claims\nthrough rigorous theoretical analyses and extensive experimental results,\nshowcasing HSL's practicality for large-scale collaborative learning.",
      "tldr_zh": "本文提出了一种新的协作机器学习框架——Hubs and Spokes Learning (HSL)。HSL结合了联邦学习(FL)和去中心化学习(P2PL)的优点，采用双层通信结构，避免了FL中固有的单点故障问题，并且性能优于最先进的P2PL框架Epidemic Learning Local (ELL)。在相同的通信预算下，HSL比ELL实现了更高的性能；在显著降低通信预算的情况下，HSL可以达到与ELL相当的性能。例如，在CIFAR-10数据集上，对于100个peers (spokes)，HSL仅用400条边就达到了ELL用1000条边才能达到的测试精度，证明了其适用于资源受限的系统。HSL还在混合后实现了节点间更强的共识，从而以更少的训练轮数提高了性能。通过严格的理论分析和大量的实验结果，证实了HSL在大规模协作学习中的实用性。\n",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DC"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.20988v1",
      "published_date": "2025-04-29 17:56:55 UTC",
      "updated_date": "2025-04-29 17:56:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-01T02:23:19.907475"
    },
    {
      "arxiv_id": "2504.20983v1",
      "title": "LTLf Adaptive Synthesis for Multi-Tier Goals in Nondeterministic Domains",
      "title_zh": "非确定性领域中面向多层目标的 LTLf 自适应合成\n",
      "authors": [
        "Giuseppe De Giacomo",
        "Gianmarco Parretti",
        "Shufang Zhu"
      ],
      "abstract": "We study a variant of LTLf synthesis that synthesizes adaptive strategies for\nachieving a multi-tier goal, consisting of multiple increasingly challenging\nLTLf objectives in nondeterministic planning domains. Adaptive strategies are\nstrategies that at any point of their execution (i) enforce the satisfaction of\nas many objectives as possible in the multi-tier goal, and (ii) exploit\npossible cooperation from the environment to satisfy as many as possible of the\nremaining ones. This happens dynamically: if the environment cooperates (ii)\nand an objective becomes enforceable (i), then our strategies will enforce it.\nWe provide a game-theoretic technique to compute adaptive strategies that is\nsound and complete. Notably, our technique is polynomial, in fact quadratic, in\nthe number of objectives. In other words, it handles multi-tier goals with only\na minor overhead compared to standard LTLf synthesis.",
      "tldr_zh": "本文研究了一种LTLf综合的变体，用于在非确定性规划领域中，为实现多层目标（包含多个难度递增的LTLf目标）合成自适应策略。自适应策略在执行的任何时刻，都能尽可能地满足多层目标中的目标，并利用环境的潜在合作来满足剩余目标。这种动态调整允许策略在环境合作的情况下，将原本可利用的目标转化为可强制执行的目标。研究提出了一种博弈论技术来计算自适应策略，该技术是可靠且完备的。值得注意的是，该技术在目标数量上是多项式的，实际上是二次的，这意味着与标准的LTLf综合相比，处理多层目标只会带来很小的开销。\n",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.20983v1",
      "published_date": "2025-04-29 17:53:16 UTC",
      "updated_date": "2025-04-29 17:53:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-01T02:23:31.631579"
    },
    {
      "arxiv_id": "2504.20980v1",
      "title": "Jekyll-and-Hyde Tipping Point in an AI's Behavior",
      "title_zh": "人工智能行为中的杰基尔与海德式转折点\n",
      "authors": [
        "Neil F. Johnson",
        "Frank Yingjie Huo"
      ],
      "abstract": "Trust in AI is undermined by the fact that there is no science that predicts\n-- or that can explain to the public -- when an LLM's output (e.g. ChatGPT) is\nlikely to tip mid-response to become wrong, misleading, irrelevant or\ndangerous. With deaths and trauma already being blamed on LLMs, this\nuncertainty is even pushing people to treat their 'pet' LLM more politely to\n'dissuade' it (or its future Artificial General Intelligence offspring) from\nsuddenly turning on them. Here we address this acute need by deriving from\nfirst principles an exact formula for when a Jekyll-and-Hyde tipping point\noccurs at LLMs' most basic level. Requiring only secondary school mathematics,\nit shows the cause to be the AI's attention spreading so thin it suddenly\nsnaps. This exact formula provides quantitative predictions for how the\ntipping-point can be delayed or prevented by changing the prompt and the AI's\ntraining. Tailored generalizations will provide policymakers and the public\nwith a firm platform for discussing any of AI's broader uses and risks, e.g. as\na personal counselor, medical advisor, decision-maker for when to use force in\na conflict situation. It also meets the need for clear and transparent answers\nto questions like ''should I be polite to my LLM?''",
      "tldr_zh": "该论文探讨了大型语言模型(LLMs)行为中“Jekyll-and-Hyde”式的突变现象，即LLM在生成过程中突然变得错误、误导、无关或危险。研究从第一性原理推导出一个精确的公式，解释了这种突变发生的根本原因：AI的注意力分散到临界点，导致突然崩溃。该公式能够量化预测如何通过改变提示和AI训练来延迟或阻止这种突变。该研究为决策者和公众提供了一个讨论AI风险的平台，并解答了诸如“我应该对我的LLM礼貌吗？”等问题。\n",
      "categories": [
        "cs.AI",
        "cs.CY",
        "nlin.AO",
        "physics.comp-ph",
        "physics.soc-ph"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.20980v1",
      "published_date": "2025-04-29 17:50:29 UTC",
      "updated_date": "2025-04-29 17:50:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-01T02:23:43.470475"
    },
    {
      "arxiv_id": "2504.20970v1",
      "title": "SVD Based Least Squares for X-Ray Pneumonia Classification Using Deep Features",
      "title_zh": "基于SVD最小二乘法的深度特征X射线肺炎分类",
      "authors": [
        "Mete Erdogan",
        "Sebnem Demirtas"
      ],
      "abstract": "Accurate and early diagnosis of pneumonia through X-ray imaging is essential\nfor effective treatment and improved patient outcomes. Recent advancements in\nmachine learning have enabled automated diagnostic tools that assist\nradiologists in making more reliable and efficient decisions. In this work, we\npropose a Singular Value Decomposition-based Least Squares (SVD-LS) framework\nfor multi-class pneumonia classification, leveraging powerful feature\nrepresentations from state-of-the-art self-supervised and transfer learning\nmodels. Rather than relying on computationally expensive gradient based\nfine-tuning, we employ a closed-form, non-iterative classification approach\nthat ensures efficiency without compromising accuracy. Experimental results\ndemonstrate that SVD-LS achieves competitive performance while offering\nsignificantly reduced computational costs, making it a viable alternative for\nreal-time medical imaging applications.",
      "tldr_zh": "该论文提出了一种基于奇异值分解的最小二乘(SVD-LS)框架，用于利用深度特征进行多类别X射线肺炎分类。该方法利用自监督学习和迁移学习模型提取的强大特征表示，并采用闭式、非迭代的分类方法，避免了计算量大的基于梯度的微调。实验结果表明，SVD-LS在保证竞争力的同时，显著降低了计算成本，使其成为实时医学影像应用的可行选择。\n",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Preprint submitted to IEEE International Workshop on Machine Learning\n  for Signal Processing (MLSP), 2025",
      "pdf_url": "http://arxiv.org/pdf/2504.20970v1",
      "published_date": "2025-04-29 17:39:16 UTC",
      "updated_date": "2025-04-29 17:39:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-01T02:23:55.763090"
    },
    {
      "arxiv_id": "2504.20964v1",
      "title": "OSVBench: Benchmarking LLMs on Specification Generation Tasks for Operating System Verification",
      "title_zh": "OSVBench：用于操作系统验证的 LLM 在规范生成任务上的基准测试\n",
      "authors": [
        "Shangyu Li",
        "Juyong Jiang",
        "Tiancheng Zhao",
        "Jiasi Shen"
      ],
      "abstract": "We introduce OSVBench, a new benchmark for evaluating Large Language Models\n(LLMs) in generating complete specification code pertaining to operating system\nkernel verification tasks. The benchmark first defines the specification\ngeneration problem into a program synthesis problem within a confined scope of\nsyntax and semantics by providing LLMs with the programming model. The LLMs are\nrequired to understand the provided verification assumption and the potential\nsyntax and semantics space to search for, then generate the complete\nspecification for the potentially buggy operating system code implementation\nunder the guidance of the high-level functional description of the operating\nsystem. This benchmark is built upon a real-world operating system kernel,\nHyperkernel, and consists of 245 complex specification generation tasks in\ntotal, each is a long context task of about 20k-30k tokens. Our comprehensive\nevaluation of 12 LLMs exhibits the limited performance of the current LLMs on\nthe specification generation tasks for operating system verification.\nSignificant disparities in their performance on the benchmark highlight\ndifferences in their ability to handle long-context code generation tasks. The\nevaluation toolkit and benchmark are available at\nhttps://github.com/lishangyu-hkust/OSVBench.",
      "tldr_zh": "本文提出了OSVBench，一个用于评估大型语言模型(LLMs)在操作系统内核验证任务中生成完整规范代码能力的新基准。该基准将规范生成问题定义为程序合成问题，通过提供编程模型来限定LLMs的语法和语义范围。LLMs需要理解给定的验证假设和潜在的语法/语义空间，并根据操作系统的高级功能描述，为潜在的错误操作系统代码实现生成完整的规范。OSVBench基于真实的操作系统内核Hyperkernel构建，包含245个复杂的规范生成任务，每个任务都是一个约20k-30k tokens的长上下文任务。对12个LLMs的综合评估表明，当前LLMs在操作系统验证的规范生成任务上的性能有限。不同LLMs在该基准上的显著性能差异突显了它们处理长上下文代码生成任务能力的不同。该评估工具包和基准可在https://github.com/lishangyu-hkust/OSVBench 获取。\n",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.OS",
        "cs.PL",
        "cs.SE"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.20964v1",
      "published_date": "2025-04-29 17:34:49 UTC",
      "updated_date": "2025-04-29 17:34:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-01T02:24:07.848516"
    },
    {
      "arxiv_id": "2504.20946v1",
      "title": "Trace-of-Thought: Enhanced Arithmetic Problem Solving via Reasoning Distillation From Large to Small Language Models",
      "title_zh": "思维轨迹：通过从大型到小型语言模型的推理提炼来增强算术问题求解能力\n",
      "authors": [
        "Tyler McDonald",
        "Ali Emami"
      ],
      "abstract": "As Large Language Models (LLMs) continue to be leveraged for daily tasks,\nprompt engineering remains an active field of contribution within computational\nlinguistics, particularly in domains requiring specialized knowledge such as\narithmetic reasoning. While these LLMs are optimized for a variety of tasks,\ntheir exhaustive employment may become computationally or financially\ncumbersome for small teams. Additionally, complete reliance on proprietary,\nclosed-source models often limits customization and adaptability, posing\nsignificant challenges in research and application scalability. Instead, by\nleveraging open-source models at or below 7 billion parameters, we can optimize\nour resource usage while still observing remarkable gains over standard\nprompting approaches. To cultivate this notion, we introduce Trace-of-Thought\nPrompting, a simple, zero-shot prompt engineering method that instructs LLMs to\ncreate observable subproblems using critical problem-solving, specifically\ndesigned to enhance arithmetic reasoning capabilities. When applied to\nopen-source models in tandem with GPT-4, we observe that Trace-of-Thought not\nonly allows novel insight into the problem-solving process but also introduces\nperformance gains as large as 125% on language models at or below 7 billion\nparameters. This approach underscores the potential of open-source initiatives\nin democratizing AI research and improving the accessibility of high-quality\ncomputational linguistics applications.",
      "tldr_zh": "该论文提出了一种名为Trace-of-Thought Prompting的零样本提示工程方法，旨在提升小型语言模型（参数小于等于70亿）的算术问题解决能力。该方法通过引导LLM创建可观察的子问题，利用批判性问题解决能力来增强算术推理。实验结果表明，结合GPT-4，Trace-of-Thought Prompting能够显著提升小型开源模型的性能，最高可达125%。该研究强调了开源模型在AI研究中的潜力，并提高了高质量计算语言学应用的可访问性。\n",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.20946v1",
      "published_date": "2025-04-29 17:14:54 UTC",
      "updated_date": "2025-04-29 17:14:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-01T02:24:19.627712"
    },
    {
      "arxiv_id": "2504.20930v1",
      "title": "ChestX-Reasoner: Advancing Radiology Foundation Models with Reasoning through Step-by-Step Verification",
      "title_zh": "ChestX-Reasoner：通过逐步验证推理来推进放射学基础模型",
      "authors": [
        "Ziqing Fan",
        "Cheng Liang",
        "Chaoyi Wu",
        "Ya Zhang",
        "Yanfeng Wang",
        "Weidi Xie"
      ],
      "abstract": "Recent advances in reasoning-enhanced large language models (LLMs) and\nmultimodal LLMs (MLLMs) have significantly improved performance in complex\ntasks, yet medical AI models often overlook the structured reasoning processes\ninherent in clinical practice. In this work, we present ChestX-Reasoner, a\nradiology diagnosis MLLM designed to leverage process supervision mined\ndirectly from clinical reports, reflecting the step-by-step reasoning followed\nby radiologists. We construct a large dataset by extracting and refining\nreasoning chains from routine radiology reports. Our two-stage training\nframework combines supervised fine-tuning and reinforcement learning guided by\nprocess rewards to better align model reasoning with clinical standards. We\nintroduce RadRBench-CXR, a comprehensive benchmark featuring 59K visual\nquestion answering samples with 301K clinically validated reasoning steps, and\npropose RadRScore, a metric evaluating reasoning factuality, completeness, and\neffectiveness. ChestX-Reasoner outperforms existing medical and general-domain\nMLLMs in both diagnostic accuracy and reasoning ability, achieving 16%, 5.9%,\nand 18% improvements in reasoning ability compared to the best medical MLLM,\nthe best general MLLM, and its base model, respectively, as well as 3.3%, 24%,\nand 27% improvements in outcome accuracy. All resources are open-sourced to\nfacilitate further research in medical reasoning MLLMs.",
      "tldr_zh": "该论文提出了ChestX-Reasoner，一种用于放射诊断的多模态大型语言模型(MLLM)，它通过逐步验证进行推理，模拟放射科医生的临床实践。研究人员构建了一个大型数据集，从放射报告中提取并提炼推理链，并采用两阶段训练框架，结合监督微调和强化学习，使模型推理与临床标准对齐。他们还引入了RadRBench-CXR基准测试和RadRScore指标，用于评估推理的真实性、完整性和有效性。实验结果表明，ChestX-Reasoner在诊断准确性和推理能力方面均优于现有的医学和通用MLLM，并在推理能力和结果准确性方面取得了显著提升。所有资源均已开源。\n",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.CV"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.20930v1",
      "published_date": "2025-04-29 16:48:23 UTC",
      "updated_date": "2025-04-29 16:48:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-01T02:24:31.753041"
    },
    {
      "arxiv_id": "2504.20924v1",
      "title": "A Domain-Agnostic Scalable AI Safety Ensuring Framework",
      "title_zh": "一种领域无关的可扩展人工智能安全保障框架\n",
      "authors": [
        "Beomjun Kim",
        "Kangyeon Kim",
        "Sunwoo Kim",
        "Heejin Ahn"
      ],
      "abstract": "Ensuring the safety of AI systems has recently emerged as a critical priority\nfor real-world deployment, particularly in physical AI applications. Current\napproaches to AI safety typically address predefined domain-specific safety\nconditions, limiting their ability to generalize across contexts.\n  We propose a novel AI safety framework that ensures AI systems comply with\n\\textbf{any user-defined constraint}, with \\textbf{any desired probability},\nand across \\textbf{various domains}.\n  In this framework, we combine an AI component (e.g., neural network) with an\noptimization problem to produce responses that minimize objectives while\nsatisfying user-defined constraints with probabilities exceeding user-defined\nthresholds. For credibility assessment of the AI component, we propose\n\\textit{internal test data}, a supplementary set of safety-labeled data, and a\n\\textit{conservative testing} methodology that provides statistical validity of\nusing internal test data. We also present an approximation method of a loss\nfunction and how to compute its gradient for training.\n  We mathematically prove that probabilistic constraint satisfaction is\nguaranteed under specific, mild conditions and prove a scaling law between\nsafety and the number of internal test data. We demonstrate our framework's\neffectiveness through experiments in diverse domains: demand prediction for\nproduction decision, safe reinforcement learning within the SafetyGym\nsimulator, and guarding AI chatbot outputs. Through these experiments, we\ndemonstrate that our method guarantees safety for user-specified constraints,\noutperforms {for \\textbf{up to several order of magnitudes}} existing methods\nin low safety threshold regions, and scales effectively with respect to the\nsize of internal test data.",
      "tldr_zh": "该论文提出了一种领域无关且可扩展的AI安全框架，旨在确保AI系统在各种领域中以用户指定的概率满足用户定义的任何约束。该框架结合了AI组件（如神经网络）和优化问题，以生成在满足约束条件的同时最小化目标的回应。为了评估AI组件的可信度，论文提出了内部测试数据和保守测试方法，并证明了使用内部测试数据的统计有效性。通过在生产决策的需求预测、SafetyGym中的安全强化学习和AI聊天机器人输出的安全防护等多个领域的实验，证明了该框架的有效性，尤其是在低安全阈值区域，其性能优于现有方法几个数量级，并能有效地随内部测试数据的规模进行扩展。\n",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Experimental supplementary material will be available before May 22\n  23:59PM AOE",
      "pdf_url": "http://arxiv.org/pdf/2504.20924v1",
      "published_date": "2025-04-29 16:38:35 UTC",
      "updated_date": "2025-04-29 16:38:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-01T02:24:43.577581"
    },
    {
      "arxiv_id": "2504.20922v1",
      "title": "DYNAMAX: Dynamic computing for Transformers and Mamba based architectures",
      "title_zh": "DYNAMAX：基于 Transformer 和 Mamba 架构的动态计算\n",
      "authors": [
        "Miguel Nogales",
        "Matteo Gambella",
        "Manuel Roveri"
      ],
      "abstract": "Early exits (EEs) offer a promising approach to reducing computational costs\nand latency by dynamically terminating inference once a satisfactory prediction\nconfidence on a data sample is achieved. Although many works integrate EEs into\nencoder-only Transformers, their application to decoder-only architectures and,\nmore importantly, Mamba models, a novel family of state-space architectures in\nthe LLM realm, remains insufficiently explored. This work introduces DYNAMAX,\nthe first framework to exploit the unique properties of Mamba architectures for\nearly exit mechanisms. We not only integrate EEs into Mamba but also repurpose\nMamba as an efficient EE classifier for both Mamba-based and transformer-based\nLLMs, showcasing its versatility. Our experiments employ the Mistral 7B\ntransformer compared to the Codestral 7B Mamba model, using data sets such as\nTruthfulQA, CoQA, and TriviaQA to evaluate computational savings, accuracy, and\nconsistency. The results highlight the adaptability of Mamba as a powerful EE\nclassifier and its efficiency in balancing computational cost and performance\nquality across NLP tasks. By leveraging Mamba's inherent design for dynamic\nprocessing, we open pathways for scalable and efficient inference in embedded\napplications and resource-constrained environments. This study underscores the\ntransformative potential of Mamba in redefining dynamic computing paradigms for\nLLMs.",
      "tldr_zh": "该论文提出了DYNAMAX，一个用于Transformer和Mamba架构的动态计算框架，旨在通过Early Exits (EEs) 降低计算成本和延迟。DYNAMAX首次将EEs集成到Mamba模型中，并创新性地将Mamba用作高效的EE分类器，适用于Mamba和Transformer架构的LLM。实验结果表明，Mamba作为EE分类器具有强大的适应性，能够在NLP任务中平衡计算成本和性能质量。该研究强调了Mamba在重新定义LLM动态计算范式方面的变革潜力，为嵌入式应用和资源受限环境中的可扩展和高效推理开辟了道路。\n",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG",
        "68T50 (Primary), 68T07 (Secondary)"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to IJCNN 2025",
      "pdf_url": "http://arxiv.org/pdf/2504.20922v1",
      "published_date": "2025-04-29 16:38:15 UTC",
      "updated_date": "2025-04-29 16:38:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-01T02:24:55.917118"
    },
    {
      "arxiv_id": "2504.20921v1",
      "title": "Leveraging Generative AI Through Prompt Engineering and Rigorous Validation to Create Comprehensive Synthetic Datasets for AI Training in Healthcare",
      "title_zh": "利用生成式人工智能，通过提示工程和严格验证，创建全面的合成数据集，用于医疗保健领域的人工智能训练\n",
      "authors": [
        "Polycarp Nalela"
      ],
      "abstract": "Access to high-quality medical data is often restricted due to privacy\nconcerns, posing significant challenges for training artificial intelligence\n(AI) algorithms within Electronic Health Record (EHR) applications. In this\nstudy, prompt engineering with the GPT-4 API was employed to generate\nhigh-quality synthetic datasets aimed at overcoming this limitation. The\ngenerated data encompassed a comprehensive array of patient admission\ninformation, including healthcare provider details, hospital departments,\nwards, bed assignments, patient demographics, emergency contacts, vital signs,\nimmunizations, allergies, medical histories, appointments, hospital visits,\nlaboratory tests, diagnoses, treatment plans, medications, clinical notes,\nvisit logs, discharge summaries, and referrals. To ensure data quality and\nintegrity, advanced validation techniques were implemented utilizing models\nsuch as BERT's Next Sentence Prediction for sentence coherence, GPT-2 for\noverall plausibility, RoBERTa for logical consistency, autoencoders for anomaly\ndetection, and conducted diversity analysis. Synthetic data that met all\nvalidation criteria were integrated into a comprehensive PostgreSQL database,\nserving as the data management system for the EHR application. This approach\ndemonstrates that leveraging generative AI models with rigorous validation can\neffectively produce high-quality synthetic medical data, facilitating the\ntraining of AI algorithms while addressing privacy concerns associated with\nreal patient data.",
      "tldr_zh": "该研究利用GPT-4 API通过提示工程生成高质量的合成医疗数据集，以解决电子健康记录(EHR)应用中因隐私限制导致AI算法训练数据不足的问题。生成的数据集包含全面的患者入院信息，包括医疗提供者信息、医院部门、病房、床位分配、患者人口统计、紧急联系人、生命体征、免疫接种、过敏史、病史、预约、医院就诊、实验室检查、诊断、治疗计划、药物、临床笔记、就诊记录、出院总结和转诊等。为确保数据质量，采用了BERT的Next Sentence Prediction、GPT-2、RoBERTa和自编码器等模型进行验证，并通过PostgreSQL数据库进行管理。实验结果表明，通过严格验证的生成式AI模型能够有效生成高质量的合成医疗数据，促进AI算法的训练，同时解决与真实患者数据相关的隐私问题。\n",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.20921v1",
      "published_date": "2025-04-29 16:37:34 UTC",
      "updated_date": "2025-04-29 16:37:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-01T02:25:07.918474"
    },
    {
      "arxiv_id": "2504.20910v1",
      "title": "When Testing AI Tests Us: Safeguarding Mental Health on the Digital Frontlines",
      "title_zh": "当 AI 测试反过来测试我们时：守护数字前线的心理健康\n",
      "authors": [
        "Sachin R. Pendse",
        "Darren Gergle",
        "Rachel Kornfield",
        "Jonah Meyerhoff",
        "David Mohr",
        "Jina Suh",
        "Annie Wescott",
        "Casey Williams",
        "Jessica Schleider"
      ],
      "abstract": "Red-teaming is a core part of the infrastructure that ensures that AI models\ndo not produce harmful content. Unlike past technologies, the black box nature\nof generative AI systems necessitates a uniquely interactional mode of testing,\none in which individuals on red teams actively interact with the system,\nleveraging natural language to simulate malicious actors and solicit harmful\noutputs. This interactional labor done by red teams can result in mental health\nharms that are uniquely tied to the adversarial engagement strategies necessary\nto effectively red team. The importance of ensuring that generative AI models\ndo not propagate societal or individual harm is widely recognized -- one less\nvisible foundation of end-to-end AI safety is also the protection of the mental\nhealth and wellbeing of those who work to keep model outputs safe. In this\npaper, we argue that the unmet mental health needs of AI red-teamers is a\ncritical workplace safety concern. Through analyzing the unique mental health\nimpacts associated with the labor done by red teams, we propose potential\nindividual and organizational strategies that could be used to meet these\nneeds, and safeguard the mental health of red-teamers. We develop our proposed\nstrategies through drawing parallels between common red-teaming practices and\ninteractional labor common to other professions (including actors, mental\nhealth professionals, conflict photographers, and content moderators),\ndescribing how individuals and organizations within these professional spaces\nsafeguard their mental health given similar psychological demands. Drawing on\nthese protective practices, we describe how safeguards could be adapted for the\ndistinct mental health challenges experienced by red teaming organizations as\nthey mitigate emerging technological risks on the new digital frontlines.",
      "tldr_zh": "本文探讨了AI红队测试人员在对抗性测试生成式AI系统时面临的独特心理健康风险。由于需要模拟恶意行为并诱导有害输出，红队测试人员的工作可能导致精神健康损害。文章强调了保护红队测试人员心理健康的重要性，这对于确保AI安全至关重要。通过类比演员、心理健康专家等职业中常见的互动式劳动，文章提出了个人和组织层面的策略，以应对红队测试人员面临的心理健康挑战，从而保障他们在数字前线的心理健康。\n",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.CY",
      "comment": "Accepted to ACM Conference on Fairness, Accountability, and\n  Transparency (FAccT 2025)",
      "pdf_url": "http://arxiv.org/pdf/2504.20910v1",
      "published_date": "2025-04-29 16:27:20 UTC",
      "updated_date": "2025-04-29 16:27:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-01T02:25:19.538787"
    },
    {
      "arxiv_id": "2504.20903v1",
      "title": "Modeling AI-Human Collaboration as a Multi-Agent Adaptation",
      "title_zh": "将 AI-人类协作建模为多智能体适应\n",
      "authors": [
        "Prothit Sen",
        "Sai Mihir Jakkaraju"
      ],
      "abstract": "We develop an agent-based simulation to formalize AI-human collaboration as a\nfunction of task structure, advancing a generalizable framework for strategic\ndecision-making in organizations. Distinguishing between heuristic-based human\nadaptation and rule-based AI search, we model interactions across modular\n(parallel) and sequenced (interdependent) tasks using an NK model. Our results\nreveal that in modular tasks, AI often substitutes for humans - delivering\nhigher payoffs unless human expertise is very high, and the AI search space is\neither narrowly focused or extremely broad. In sequenced tasks, interesting\ncomplementarities emerge. When an expert human initiates the search and AI\nsubsequently refines it, aggregate performance is maximized. Conversely, when\nAI leads, excessive heuristic refinement by the human can reduce payoffs. We\nalso show that even \"hallucinatory\" AI - lacking memory or structure - can\nimprove outcomes when augmenting low-capability humans by helping escape local\noptima. These results yield a robust implication: the effectiveness of AI-human\ncollaboration depends less on context or industry, and more on the underlying\ntask structure. By elevating task decomposition as the central unit of\nanalysis, our model provides a transferable lens for strategic decision-making\ninvolving humans and an agentic AI across diverse organizational settings.",
      "tldr_zh": "该研究将AI-人类协作建模为一个多智能体适应过程，通过基于智能体的仿真，形式化了任务结构对协作的影响。研究区分了基于启发式的人类适应和基于规则的AI搜索，并使用NK模型模拟了模块化（并行）和序列化（相互依赖）任务中的交互。结果表明，在模块化任务中，AI通常可以替代人类，除非人类专业知识非常高，或者AI搜索空间非常窄或非常宽。在序列化任务中，当专家人类发起搜索，AI随后进行优化时，总体性能最佳。即使是缺乏记忆或结构的“幻觉”AI，也可以通过帮助人类摆脱局部最优来提高能力较弱的人类的表现。研究强调，AI-人类协作的有效性更多地取决于底层任务结构，而非背景或行业。该模型提供了一个可转移的视角，用于在涉及人类和智能AI的各种组织环境中进行战略决策。\n",
      "categories": [
        "cs.MA",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.MA",
      "comment": "Manuscript under review for the Special Issue: 'Can AI Do Strategy?'\n  at Strategy Science (May 1, 2025)",
      "pdf_url": "http://arxiv.org/pdf/2504.20903v1",
      "published_date": "2025-04-29 16:19:53 UTC",
      "updated_date": "2025-04-29 16:19:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-01T02:25:32.299450"
    },
    {
      "arxiv_id": "2504.20902v1",
      "title": "Classifier-to-Bias: Toward Unsupervised Automatic Bias Detection for Visual Classifiers",
      "title_zh": "从分类器到偏差：面向视觉分类器的无监督自动偏差检测\n",
      "authors": [
        "Quentin Guimard",
        "Moreno D'Incà",
        "Massimiliano Mancini",
        "Elisa Ricci"
      ],
      "abstract": "A person downloading a pre-trained model from the web should be aware of its\nbiases. Existing approaches for bias identification rely on datasets containing\nlabels for the task of interest, something that a non-expert may not have\naccess to, or may not have the necessary resources to collect: this greatly\nlimits the number of tasks where model biases can be identified. In this work,\nwe present Classifier-to-Bias (C2B), the first bias discovery framework that\nworks without access to any labeled data: it only relies on a textual\ndescription of the classification task to identify biases in the target\nclassification model. This description is fed to a large language model to\ngenerate bias proposals and corresponding captions depicting biases together\nwith task-specific target labels. A retrieval model collects images for those\ncaptions, which are then used to assess the accuracy of the model w.r.t. the\ngiven biases. C2B is training-free, does not require any annotations, has no\nconstraints on the list of biases, and can be applied to any pre-trained model\non any classification task. Experiments on two publicly available datasets show\nthat C2B discovers biases beyond those of the original datasets and outperforms\na recent state-of-the-art bias detection baseline that relies on task-specific\nannotations, being a promising first step toward addressing task-agnostic\nunsupervised bias detection.",
      "tldr_zh": "本文提出了Classifier-to-Bias (C2B)，一种无需标注数据的无监督自动偏见检测框架，用于识别视觉分类器中的偏见。C2B仅依赖于分类任务的文本描述，利用大型语言模型生成偏见提议和相应的图像描述，结合任务特定的目标标签。通过检索模型收集与这些描述相关的图像，并评估模型在这些偏见方面的准确性。实验表明，C2B能够发现超出原始数据集范围的偏见，并在两个公开数据集上优于依赖任务特定标注的现有偏见检测方法，为实现任务无关的无监督偏见检测迈出了重要一步。C2B无需训练，不需要任何标注，对偏见列表没有限制，可以应用于任何分类任务的预训练模型。\n",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "CVPR 2025. Code: https://github.com/mardgui/C2B",
      "pdf_url": "http://arxiv.org/pdf/2504.20902v1",
      "published_date": "2025-04-29 16:19:38 UTC",
      "updated_date": "2025-04-29 16:19:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-01T02:25:43.681552"
    },
    {
      "arxiv_id": "2504.20898v1",
      "title": "CBM-RAG: Demonstrating Enhanced Interpretability in Radiology Report Generation with Multi-Agent RAG and Concept Bottleneck Models",
      "title_zh": "CBM-RAG：利用多智能体 RAG 和概念瓶颈模型展示放射学报告生成中增强的可解释性\n",
      "authors": [
        "Hasan Md Tusfiqur Alam",
        "Devansh Srivastav",
        "Abdulrahman Mohamed Selim",
        "Md Abdul Kadir",
        "Md Moktadiurl Hoque Shuvo",
        "Daniel Sonntag"
      ],
      "abstract": "Advancements in generative Artificial Intelligence (AI) hold great promise\nfor automating radiology workflows, yet challenges in interpretability and\nreliability hinder clinical adoption. This paper presents an automated\nradiology report generation framework that combines Concept Bottleneck Models\n(CBMs) with a Multi-Agent Retrieval-Augmented Generation (RAG) system to bridge\nAI performance with clinical explainability. CBMs map chest X-ray features to\nhuman-understandable clinical concepts, enabling transparent disease\nclassification. Meanwhile, the RAG system integrates multi-agent collaboration\nand external knowledge to produce contextually rich, evidence-based reports.\nOur demonstration showcases the system's ability to deliver interpretable\npredictions, mitigate hallucinations, and generate high-quality, tailored\nreports with an interactive interface addressing accuracy, trust, and usability\nchallenges. This framework provides a pathway to improving diagnostic\nconsistency and empowering radiologists with actionable insights.",
      "tldr_zh": "该论文提出了一种结合概念瓶颈模型(CBMs)和多智能体检索增强生成(RAG)系统的自动化放射学报告生成框架，旨在提高AI在放射学工作流程中的可解释性和可靠性。CBMs将胸部X光特征映射到人类可理解的临床概念，实现透明的疾病分类。RAG系统则整合多智能体协作和外部知识，生成上下文丰富、基于证据的报告。该系统能够提供可解释的预测，减少幻觉，并生成高质量的定制报告，从而提高诊断一致性并为放射科医生提供可操作的见解。该框架通过交互式界面解决了准确性、信任和可用性方面的挑战。\n",
      "categories": [
        "cs.AI",
        "cs.CV",
        "cs.IR"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted in the 17th ACM SIGCHI Symposium on Engineering Interactive\n  Computing Systems (EICS 2025)",
      "pdf_url": "http://arxiv.org/pdf/2504.20898v1",
      "published_date": "2025-04-29 16:14:55 UTC",
      "updated_date": "2025-04-29 16:14:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-01T02:25:55.943689"
    },
    {
      "arxiv_id": "2504.20887v1",
      "title": "Return Capping: Sample-Efficient CVaR Policy Gradient Optimisation",
      "title_zh": "回报封顶：样本高效的 CVaR 策略梯度优化\n",
      "authors": [
        "Harry Mead",
        "Clarissa Costen",
        "Bruno Lacerda",
        "Nick Hawes"
      ],
      "abstract": "When optimising for conditional value at risk (CVaR) using policy gradients\n(PG), current methods rely on discarding a large proportion of trajectories,\nresulting in poor sample efficiency. We propose a reformulation of the CVaR\noptimisation problem by capping the total return of trajectories used in\ntraining, rather than simply discarding them, and show that this is equivalent\nto the original problem if the cap is set appropriately. We show, with\nempirical results in an number of environments, that this reformulation of the\nproblem results in consistently improved performance compared to baselines.",
      "tldr_zh": "该论文提出了一种新的CVaR（条件风险价值）策略梯度优化方法，旨在提高样本效率。传统方法通过丢弃大量轨迹来优化CVaR，导致效率低下。本文通过限制训练中使用轨迹的总回报（Return Capping）来重新构建CVaR优化问题，而非直接丢弃轨迹。理论证明，如果上限设置得当，这种方法与原始问题等价。实验结果表明，与基线方法相比，Return Capping在多个环境中表现出持续改进的性能。\n",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.20887v1",
      "published_date": "2025-04-29 16:04:16 UTC",
      "updated_date": "2025-04-29 16:04:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-01T02:26:07.550556"
    },
    {
      "arxiv_id": "2504.20879v1",
      "title": "The Leaderboard Illusion",
      "title_zh": "排行榜的幻觉\n",
      "authors": [
        "Shivalika Singh",
        "Yiyang Nan",
        "Alex Wang",
        "Daniel D'Souza",
        "Sayash Kapoor",
        "Ahmet Üstün",
        "Sanmi Koyejo",
        "Yuntian Deng",
        "Shayne Longpre",
        "Noah Smith",
        "Beyza Ermis",
        "Marzieh Fadaee",
        "Sara Hooker"
      ],
      "abstract": "Measuring progress is fundamental to the advancement of any scientific field.\nAs benchmarks play an increasingly central role, they also grow more\nsusceptible to distortion. Chatbot Arena has emerged as the go-to leaderboard\nfor ranking the most capable AI systems. Yet, in this work we identify\nsystematic issues that have resulted in a distorted playing field. We find that\nundisclosed private testing practices benefit a handful of providers who are\nable to test multiple variants before public release and retract scores if\ndesired. We establish that the ability of these providers to choose the best\nscore leads to biased Arena scores due to selective disclosure of performance\nresults. At an extreme, we identify 27 private LLM variants tested by Meta in\nthe lead-up to the Llama-4 release. We also establish that proprietary closed\nmodels are sampled at higher rates (number of battles) and have fewer models\nremoved from the arena than open-weight and open-source alternatives. Both\nthese policies lead to large data access asymmetries over time. Providers like\nGoogle and OpenAI have received an estimated 19.2% and 20.4% of all data on the\narena, respectively. In contrast, a combined 83 open-weight models have only\nreceived an estimated 29.7% of the total data. We show that access to Chatbot\nArena data yields substantial benefits; even limited additional data can result\nin relative performance gains of up to 112% on the arena distribution, based on\nour conservative estimates. Together, these dynamics result in overfitting to\nArena-specific dynamics rather than general model quality. The Arena builds on\nthe substantial efforts of both the organizers and an open community that\nmaintains this valuable evaluation platform. We offer actionable\nrecommendations to reform the Chatbot Arena's evaluation framework and promote\nfairer, more transparent benchmarking for the field",
      "tldr_zh": "该论文揭示了Chatbot Arena排行榜中存在的系统性问题，这些问题导致了评估结果的偏差。研究发现，部分供应商通过私下测试多个模型变体并在发布前选择最佳结果，从而获得不公平的优势，造成选择性披露偏差。此外，闭源模型相比开源模型拥有更高的采样率和更少的模型移除，导致数据访问的不对称性。研究表明，访问Chatbot Arena数据能显著提升模型性能，即使是有限的额外数据也能带来高达112%的相对性能提升。这些因素共同导致模型过度拟合Arena特定的动态，而非提升通用模型质量。论文最后提出了改进Chatbot Arena评估框架的建议，以促进更公平、更透明的基准测试。\n",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG",
        "stat.ME"
      ],
      "primary_category": "cs.AI",
      "comment": "68 pages, 18 figures, 9 tables",
      "pdf_url": "http://arxiv.org/pdf/2504.20879v1",
      "published_date": "2025-04-29 15:48:49 UTC",
      "updated_date": "2025-04-29 15:48:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-01T02:26:19.719592"
    },
    {
      "arxiv_id": "2504.20869v2",
      "title": "Quantifying the Noise of Structural Perturbations on Graph Adversarial Attacks",
      "title_zh": "量化结构扰动对图对抗攻击的噪声影响\n",
      "authors": [
        "Junyuan Fang",
        "Han Yang",
        "Haixian Wen",
        "Jiajing Wu",
        "Zibin Zheng",
        "Chi K. Tse"
      ],
      "abstract": "Graph neural networks have been widely utilized to solve graph-related tasks\nbecause of their strong learning power in utilizing the local information of\nneighbors. However, recent studies on graph adversarial attacks have proven\nthat current graph neural networks are not robust against malicious attacks.\nYet much of the existing work has focused on the optimization objective based\non attack performance to obtain (near) optimal perturbations, but paid less\nattention to the strength quantification of each perturbation such as the\ninjection of a particular node/link, which makes the choice of perturbations a\nblack-box model that lacks interpretability. In this work, we propose the\nconcept of noise to quantify the attack strength of each adversarial link.\nFurthermore, we propose three attack strategies based on the defined noise and\nclassification margins in terms of single and multiple steps optimization.\nExtensive experiments conducted on benchmark datasets against three\nrepresentative graph neural networks demonstrate the effectiveness of the\nproposed attack strategies. Particularly, we also investigate the preferred\npatterns of effective adversarial perturbations by analyzing the corresponding\nproperties of the selected perturbation nodes.",
      "tldr_zh": "本文研究了图对抗攻击中结构扰动的噪声量化问题，旨在解决现有方法对扰动强度缺乏解释性的问题。作者提出了“噪声”的概念来量化每个对抗链接的攻击强度，并基于此定义和分类边界，提出了单步和多步优化的三种攻击策略。通过在基准数据集上针对三种代表性图神经网络的实验，验证了所提出攻击策略的有效性。此外，还分析了所选扰动节点的属性，研究了有效对抗扰动的偏好模式。\n",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.LG",
      "comment": "Under Review",
      "pdf_url": "http://arxiv.org/pdf/2504.20869v2",
      "published_date": "2025-04-29 15:42:56 UTC",
      "updated_date": "2025-04-30 01:46:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-01T02:26:31.716535"
    },
    {
      "arxiv_id": "2504.20862v1",
      "title": "Tabular Data Adapters: Improving Outlier Detection for Unlabeled Private Data",
      "title_zh": "表格数据适配器：改进未标记私有数据的异常值检测\n",
      "authors": [
        "Dayananda Herurkar",
        "Jörn Hees",
        "Vesselin Tzvetkov",
        "Andreas Dengel"
      ],
      "abstract": "The remarkable success of Deep Learning approaches is often based and\ndemonstrated on large public datasets. However, when applying such approaches\nto internal, private datasets, one frequently faces challenges arising from\nstructural differences in the datasets, domain shift, and the lack of labels.\nIn this work, we introduce Tabular Data Adapters (TDA), a novel method for\ngenerating soft labels for unlabeled tabular data in outlier detection tasks.\nBy identifying statistically similar public datasets and transforming private\ndata (based on a shared autoencoder) into a format compatible with\nstate-of-the-art public models, our approach enables the generation of weak\nlabels. It thereby can help to mitigate the cold start problem of labeling by\nbasing on existing outlier detection models for public datasets. In experiments\non 50 tabular datasets across different domains, we demonstrate that our method\nis able to provide more accurate annotations than baseline approaches while\nreducing computational time. Our approach offers a scalable, efficient, and\ncost-effective solution, to bridge the gap between public research models and\nreal-world industrial applications.",
      "tldr_zh": "本文提出了表格数据适配器(Tabular Data Adapters, TDA)，一种为无标签表格数据生成软标签的新方法，用于异常检测任务。TDA通过识别统计上相似的公共数据集，并利用共享的自编码器将私有数据转换为与先进公共模型兼容的格式，从而生成弱标签。这有助于缓解标注的冷启动问题，并基于现有的公共数据集异常检测模型。在跨不同领域的50个表格数据集上的实验表明，TDA能够提供比基线方法更准确的标注，同时减少计算时间，为公共研究模型和实际工业应用之间架起桥梁，提供了一种可扩展、高效且经济高效的解决方案。\n",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "outlier detection, tabular data, neural networks, weak annotations,\n  soft labeling, unsupervised approach",
      "pdf_url": "http://arxiv.org/pdf/2504.20862v1",
      "published_date": "2025-04-29 15:38:43 UTC",
      "updated_date": "2025-04-29 15:38:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-01T02:26:43.758396"
    },
    {
      "arxiv_id": "2504.20859v1",
      "title": "X-Cross: Dynamic Integration of Language Models for Cross-Domain Sequential Recommendation",
      "title_zh": "X-Cross：用于跨领域序列推荐的语言模型动态集成\n",
      "authors": [
        "Guy Hadad",
        "Haggai Roitman",
        "Yotam Eshel",
        "Bracha Shapira",
        "Lior Rokach"
      ],
      "abstract": "As new products are emerging daily, recommendation systems are required to\nquickly adapt to possible new domains without needing extensive retraining.\nThis work presents ``X-Cross'' -- a novel cross-domain\nsequential-recommendation model that recommends products in new domains by\nintegrating several domain-specific language models; each model is fine-tuned\nwith low-rank adapters (LoRA). Given a recommendation prompt, operating layer\nby layer, X-Cross dynamically refines the representation of each source\nlanguage model by integrating knowledge from all other models. These refined\nrepresentations are propagated from one layer to the next, leveraging the\nactivations from each domain adapter to ensure domain-specific nuances are\npreserved while enabling adaptability across domains. Using Amazon datasets for\nsequential recommendation, X-Cross achieves performance comparable to a model\nthat is fine-tuned with LoRA, while using only 25% of the additional\nparameters. In cross-domain tasks, such as adapting from Toys domain to Tools,\nElectronics or Sports, X-Cross demonstrates robust performance, while requiring\nabout 50%-75% less fine-tuning data than LoRA to make fine-tuning effective.\nFurthermore, X-Cross achieves significant improvement in accuracy over\nalternative cross-domain baselines. Overall, X-Cross enables scalable and\nadaptive cross-domain recommendations, reducing computational overhead and\nproviding an efficient solution for data-constrained environments.",
      "tldr_zh": "该论文提出了名为\"X-Cross\"的跨域序列推荐模型，旨在解决推荐系统快速适应新领域而无需大量重新训练的问题。X-Cross通过动态整合多个领域特定的语言模型，并使用低秩适配器(LoRA)进行微调，从而实现跨域推荐。该模型逐层运行，通过整合来自所有其他模型的知识来动态细化每个源语言模型的表示。实验结果表明，X-Cross在Amazon数据集上达到了与LoRA微调模型相当的性能，同时仅使用了25%的额外参数。在跨域任务中，X-Cross在数据受限的环境下表现出强大的性能，并且比其他跨域基线模型在准确性方面有显著提高。总之，X-Cross实现了可扩展和自适应的跨域推荐，降低了计算开销，并为数据受限的环境提供了一个有效的解决方案。\n",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.IR",
      "comment": "Accepted for publication in SIGIR '25",
      "pdf_url": "http://arxiv.org/pdf/2504.20859v1",
      "published_date": "2025-04-29 15:33:20 UTC",
      "updated_date": "2025-04-29 15:33:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-01T02:26:56.234089"
    },
    {
      "arxiv_id": "2504.20854v1",
      "title": "Towards Easy and Realistic Network Infrastructure Testing for Large-scale Machine Learning",
      "title_zh": "面向大规模机器学习的简易、真实网络基础设施测试\n",
      "authors": [
        "Jinsun Yoo",
        "ChonLam Lao",
        "Lianjie Cao",
        "Bob Lantz",
        "Minlan Yu",
        "Tushar Krishna",
        "Puneet Sharma"
      ],
      "abstract": "This paper lays the foundation for Genie, a testing framework that captures\nthe impact of real hardware network behavior on ML workload performance,\nwithout requiring expensive GPUs. Genie uses CPU-initiated traffic over a\nhardware testbed to emulate GPU to GPU communication, and adapts the ASTRA-sim\nsimulator to model interaction between the network and the ML workload.",
      "tldr_zh": "本文提出Genie，一个用于大规模机器学习网络基础设施测试的框架，旨在以低成本的方式模拟真实硬件网络行为对ML workload性能的影响。Genie通过在硬件测试平台上使用CPU发起的流量来模拟GPU间的通信，并改进了ASTRA-sim模拟器来建模网络和ML workload之间的交互。该框架能够在不依赖昂贵GPU的情况下，实现简易且真实的测试。\n",
      "categories": [
        "cs.NI",
        "cs.AI",
        "cs.DC",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.NI",
      "comment": "Presented as a poster in NSDI 25",
      "pdf_url": "http://arxiv.org/pdf/2504.20854v1",
      "published_date": "2025-04-29 15:23:55 UTC",
      "updated_date": "2025-04-29 15:23:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-01T02:27:07.397531"
    },
    {
      "arxiv_id": "2504.20851v1",
      "title": "Fostering Self-Directed Growth with Generative AI: Toward a New Learning Analytics Framework",
      "title_zh": "利用生成式人工智能促进自主导向成长：构建一种新的学习分析框架\n",
      "authors": [
        "Qianrun Mao"
      ],
      "abstract": "In an era increasingly shaped by decentralized knowledge ecosystems and\npervasive AI technologies, fostering sustainable learner agency has become a\ncritical educational imperative. This study introduces a novel conceptual\nframework integrating Generative Artificial Intelligence and Learning Analytics\nto cultivate Self-Directed Growth, a dynamic competency that enables learners\nto iteratively drive their own developmental pathways across diverse\ncontexts.Building upon critical gaps in current research on Self Directed\nLearning and AI-mediated education, the proposed Aspire to Potentials for\nLearners (A2PL) model reconceptualizes the interplay of learner aspirations,\ncomplex thinking, and summative self-assessment within GAI supported\nenvironments.Methodological implications for future intervention design and\nlearning analytics applications are discussed, positioning Self-Directed Growth\nas a pivotal axis for developing equitable, adaptive, and sustainable learning\nsystems in the digital era.",
      "tldr_zh": "该研究提出了一个新颖的框架A2PL，整合了生成式人工智能(Generative AI)和学习分析(Learning Analytics)，旨在培养“自我导向成长(Self-Directed Growth)”这一动态能力，使学习者能够在不同情境下迭代地驱动自身发展。该框架基于当前自我导向学习和AI辅助教育研究中的关键差距，重新概念化了学习者的期望、复杂思维和总结性自我评估在GAI支持环境中的相互作用。研究讨论了未来干预设计和学习分析应用的方法论意义，将自我导向成长定位为在数字时代开发公平、适应性和可持续学习系统的关键轴。\n",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.20851v1",
      "published_date": "2025-04-29 15:19:48 UTC",
      "updated_date": "2025-04-29 15:19:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-01T02:27:19.590908"
    },
    {
      "arxiv_id": "2504.20848v1",
      "title": "Mitigating the Structural Bias in Graph Adversarial Defenses",
      "title_zh": "缓解图对抗防御中的结构偏差\n",
      "authors": [
        "Junyuan Fang",
        "Huimin Liu",
        "Han Yang",
        "Jiajing Wu",
        "Zibin Zheng",
        "Chi K. Tse"
      ],
      "abstract": "In recent years, graph neural networks (GNNs) have shown great potential in\naddressing various graph structure-related downstream tasks. However, recent\nstudies have found that current GNNs are susceptible to malicious adversarial\nattacks. Given the inevitable presence of adversarial attacks in the real\nworld, a variety of defense methods have been proposed to counter these attacks\nand enhance the robustness of GNNs. Despite the commendable performance of\nthese defense methods, we have observed that they tend to exhibit a structural\nbias in terms of their defense capability on nodes with low degree (i.e., tail\nnodes), which is similar to the structural bias of traditional GNNs on nodes\nwith low degree in the clean graph. Therefore, in this work, we propose a\ndefense strategy by including hetero-homo augmented graph construction, $k$NN\naugmented graph construction, and multi-view node-wise attention modules to\nmitigate the structural bias of GNNs against adversarial attacks. Notably, the\nhetero-homo augmented graph consists of removing heterophilic links (i.e.,\nlinks connecting nodes with dissimilar features) globally and adding homophilic\nlinks (i.e., links connecting nodes with similar features) for nodes with low\ndegree. To further enhance the defense capability, an attention mechanism is\nadopted to adaptively combine the representations from the above two kinds of\ngraph views. We conduct extensive experiments to demonstrate the defense and\ndebiasing effect of the proposed strategy on benchmark datasets.",
      "tldr_zh": "该研究关注图神经网络(GNNs)防御对抗攻击时存在的结构性偏差问题，即对低度节点（尾部节点）的防御能力较弱。为了缓解这一偏差，作者提出了一种防御策略，包括异质-同质增强图构建、$k$NN增强图构建和多视角节点注意力模块。具体而言，该策略全局移除异质链接，并为低度节点添加同质链接。此外，利用注意力机制自适应地融合来自不同图视角的表示，以增强防御能力。实验结果表明，该策略在基准数据集上有效提升了GNNs的防御能力并减轻了结构性偏差。\n",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.LG",
      "comment": "Under Review",
      "pdf_url": "http://arxiv.org/pdf/2504.20848v1",
      "published_date": "2025-04-29 15:19:05 UTC",
      "updated_date": "2025-04-29 15:19:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-01T02:27:33.068725"
    },
    {
      "arxiv_id": "2504.20846v1",
      "title": "Disjunctive and Conjunctive Normal Form Explanations of Clusters Using Auxiliary Information",
      "title_zh": "利用辅助信息对聚类进行析取范式和合取范式解释\n",
      "authors": [
        "Robert F. Downey",
        "S. S. Ravi"
      ],
      "abstract": "We consider generating post-hoc explanations of clusters generated from\nvarious datasets using auxiliary information which was not used by clustering\nalgorithms. Following terminology used in previous work, we refer to the\nauxiliary information as tags. Our focus is on two forms of explanations,\nnamely disjunctive form (where the explanation for a cluster consists of a set\nof tags) and a two-clause conjunctive normal form (CNF) explanation (where the\nexplanation consists of two sets of tags, combined through the AND operator).\nWe use integer linear programming (ILP) as well as heuristic methods to\ngenerate these explanations. We experiment with a variety of datasets and\ndiscuss the insights obtained from our explanations. We also present\nexperimental results regarding the scalability of our explanation methods.",
      "tldr_zh": "该论文研究了如何利用聚类算法未使用的辅助信息（称为tags）为聚类结果生成事后解释。论文重点关注两种解释形式：析取范式（Disjunctive Normal Form）和双子句合取范式（Conjunctive Normal Form）。研究使用整数线性规划（Integer Linear Programming，ILP）以及启发式方法来生成这些解释。通过在多种数据集上的实验，论文探讨了从解释中获得的见解，并展示了解释方法的可扩展性实验结果。\n",
      "categories": [
        "cs.AI",
        "I.2"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.20846v1",
      "published_date": "2025-04-29 15:18:18 UTC",
      "updated_date": "2025-04-29 15:18:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-01T02:27:43.551706"
    },
    {
      "arxiv_id": "2504.20837v1",
      "title": "RadSAM: Segmenting 3D radiological images with a 2D promptable model",
      "title_zh": "RadSAM：使用 2D 可提示模型分割 3D 放射影像\n",
      "authors": [
        "Julien Khlaut",
        "Elodie Ferreres",
        "Daniel Tordjman",
        "Hélène Philippe",
        "Tom Boeken",
        "Pierre Manceron",
        "Corentin Dancette"
      ],
      "abstract": "Medical image segmentation is a crucial and time-consuming task in clinical\ncare, where mask precision is extremely important. The Segment Anything Model\n(SAM) offers a promising approach, as it provides an interactive interface\nbased on visual prompting and edition to refine an initial segmentation. This\nmodel has strong generalization capabilities, does not rely on predefined\nclasses, and adapts to diverse objects; however, it is pre-trained on natural\nimages and lacks the ability to process medical data effectively. In addition,\nthis model is built for 2D images, whereas a whole medical domain is based on\n3D images, such as CT and MRI. Recent adaptations of SAM for medical imaging\nare based on 2D models, thus requiring one prompt per slice to segment 3D\nobjects, making the segmentation process tedious. They also lack important\nfeatures such as editing. To bridge this gap, we propose RadSAM, a novel method\nfor segmenting 3D objects with a 2D model from a single prompt. In practice, we\ntrain a 2D model using noisy masks as initial prompts, in addition to bounding\nboxes and points. We then use this novel prompt type with an iterative\ninference pipeline to reconstruct the 3D mask slice-by-slice. We introduce a\nbenchmark to evaluate the model's ability to segment 3D objects in CT images\nfrom a single prompt and evaluate the models' out-of-domain transfer and\nedition capabilities. We demonstrate the effectiveness of our approach against\nstate-of-the-art models on this benchmark using the AMOS abdominal organ\nsegmentation dataset.",
      "tldr_zh": "RadSAM提出了一种新颖的方法，利用2D可Prompt模型分割3D放射影像，旨在解决医学图像分割中mask精度和效率问题。该方法基于Segment Anything Model (SAM)，通过训练一个2D模型，使用noisy masks、bounding boxes和points作为初始prompt。RadSAM采用迭代推理流程，逐层重建3D mask，仅需单个prompt即可分割3D物体。该研究还引入了一个benchmark，用于评估模型在CT图像中分割3D物体的能力，并在AMOS数据集上验证了RadSAM相对于现有模型的有效性，尤其在out-of-domain迁移和编辑能力方面。\n",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.20837v1",
      "published_date": "2025-04-29 15:00:25 UTC",
      "updated_date": "2025-04-29 15:00:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-01T02:27:56.171690"
    },
    {
      "arxiv_id": "2504.20834v1",
      "title": "Reinforcement Learning for LLM Reasoning Under Memory Constraints",
      "title_zh": "基于内存约束下的大语言模型推理的强化学习\n",
      "authors": [
        "Alan Lee",
        "Harry Tong"
      ],
      "abstract": "We explore reinforcement learning (RL) techniques to enhance reasoning within\ntargeted problem spaces in large language models (LLMs) under memory and\ncompute constraints. Our focus is on critic-free methods compatible with LoRA\nfine-tuning on a single 40GB GPU, a common limitation in academic settings. We\nintroduce S-GRPO, a memory-efficient variant of Group Relative Policy\nOptimization, and T-SPMO, a token-level prefix matching strategy for\nfine-grained credit assignment. Despite limited resources, when used to\nfine-tune Qwen2-1.5B both methods significantly improve SVAMP benchmark\naccuracy from 46% to above 70% using LoRA training. T-SPMO also excels in\nmulti-digit multiplication tasks, underscoring the potential of RL fine-tuning\nunder hardware constraints. Additionally, we find that our full-token GRPO\nbaseline under LoRA fine-tuning did not improve model performance (compared to\nbase model) on either task, suggesting that our memory-efficient methods may\nact as a form of regularization that stabilizes training when only a small\nsubset of parameters are updated.",
      "tldr_zh": "该研究探索了在内存和计算资源受限的情况下，利用强化学习(RL)提升大型语言模型(LLM)推理能力的方法。重点是无评论家(critic-free)方法，并与LoRA微调兼容，可在单个40GB GPU上运行。研究提出了S-GRPO，一种内存高效的Group Relative Policy Optimization变体，以及T-SPMO，一种用于细粒度信用分配的token级别前缀匹配策略。实验结果表明，在Qwen2-1.5B上使用LoRA微调，两种方法均显著提高了SVAMP基准测试的准确率，从46%提升至70%以上。T-SPMO在多位数乘法任务中也表现出色，突显了在硬件约束下RL微调的潜力。此外，研究发现，LoRA微调下的全token GRPO基线模型在这两项任务中均未提高模型性能，表明内存高效方法可能起到正则化的作用，从而在仅更新一小部分参数时稳定训练。\n",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.20834v1",
      "published_date": "2025-04-29 14:58:43 UTC",
      "updated_date": "2025-04-29 14:58:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-01T02:28:08.236945"
    },
    {
      "arxiv_id": "2504.20829v1",
      "title": "GaussTrap: Stealthy Poisoning Attacks on 3D Gaussian Splatting for Targeted Scene Confusion",
      "title_zh": "GaussTrap：针对 3D 高斯溅射的隐蔽式投毒攻击，用于实现定向场景混淆\n",
      "authors": [
        "Jiaxin Hong",
        "Sixu Chen",
        "Shuoyang Sun",
        "Hongyao Yu",
        "Hao Fang",
        "Yuqi Tan",
        "Bin Chen",
        "Shuhan Qi",
        "Jiawei Li"
      ],
      "abstract": "As 3D Gaussian Splatting (3DGS) emerges as a breakthrough in scene\nrepresentation and novel view synthesis, its rapid adoption in safety-critical\ndomains (e.g., autonomous systems, AR/VR) urgently demands scrutiny of\npotential security vulnerabilities. This paper presents the first systematic\nstudy of backdoor threats in 3DGS pipelines. We identify that adversaries may\nimplant backdoor views to induce malicious scene confusion during inference,\npotentially leading to environmental misperception in autonomous navigation or\nspatial distortion in immersive environments. To uncover this risk, we propose\nGuassTrap, a novel poisoning attack method targeting 3DGS models. GuassTrap\ninjects malicious views at specific attack viewpoints while preserving\nhigh-quality rendering in non-target views, ensuring minimal detectability and\nmaximizing potential harm. Specifically, the proposed method consists of a\nthree-stage pipeline (attack, stabilization, and normal training) to implant\nstealthy, viewpoint-consistent poisoned renderings in 3DGS, jointly optimizing\nattack efficacy and perceptual realism to expose security risks in 3D\nrendering. Extensive experiments on both synthetic and real-world datasets\ndemonstrate that GuassTrap can effectively embed imperceptible yet harmful\nbackdoor views while maintaining high-quality rendering in normal views,\nvalidating its robustness, adaptability, and practical applicability.",
      "tldr_zh": "该论文首次系统研究了3D高斯溅射(3DGS)管道中的后门威胁，提出了一种名为GuassTrap的隐蔽中毒攻击方法。GuassTrap通过在特定攻击视点注入恶意视图，诱导推理过程中产生恶意场景混淆，从而可能导致自动驾驶中的环境误判或沉浸式环境中的空间扭曲。该方法包含攻击、稳定和正常训练三个阶段，旨在3DGS中植入隐蔽且视点一致的中毒渲染，联合优化攻击效果和感知真实感。在合成和真实世界数据集上的大量实验表明，GuassTrap能够有效地嵌入难以察觉但有害的后门视图，同时保持正常视图中的高质量渲染，验证了其鲁棒性、适应性和实际应用性。\n",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.20829v1",
      "published_date": "2025-04-29 14:52:14 UTC",
      "updated_date": "2025-04-29 14:52:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-01T02:28:19.879308"
    },
    {
      "arxiv_id": "2504.20828v2",
      "title": "Ascendra: Dynamic Request Prioritization for Efficient LLM Serving",
      "title_zh": "Ascendra：用于高效 LLM 服务的动态请求优先级排序\n",
      "authors": [
        "Azam Ikram",
        "Xiang Li",
        "Sameh Elnikety",
        "Saurabh Bagchi"
      ],
      "abstract": "The rapid advancement of Large Language Models (LLMs) has driven the need for\nmore efficient serving strategies. In this context, efficiency refers to the\nproportion of requests that meet their Service Level Objectives (SLOs),\nparticularly for Time To First Token (TTFT) and Time Between Tokens (TBT).\nHowever, existing systems often prioritize one metric at the cost of the other.\nWe present Ascendra, an LLM serving system designed to meet both TTFT and TBT\nSLOs simultaneously. The core insight behind Ascendra is that a request's\nurgency evolves as it approaches its deadline. To leverage this, Ascendra\npartitions GPU resources into two types of instances: low-priority and\nhigh-priority. Low-priority instances maximize throughput by processing\nrequests out of arrival order, but at the risk of request starvation. To\naddress this, Ascendra employs a performance model to predict requests at risk\nof missing their SLOs and proactively offloads them to high-priority instances.\nHigh-priority instances are optimized for low-latency execution and handle\nurgent requests nearing their deadlines. This partitioned architecture enables\nAscendra to effectively balance high throughput and low latency. Extensive\nevaluation shows that Ascendra improves system throughput by up to 1.7x\ncompared to vLLM and Sarathi-Serve while meeting both TTFT and TBT SLOs.",
      "tldr_zh": "Ascendra是一个LLM服务系统，旨在同时满足TTFT（首个token生成时间）和TBT（token间时间）的服务水平目标(SLO)。其核心思想是根据请求接近截止期限的程度动态调整优先级。Ascendra将GPU资源划分为低优先级和高优先级实例，低优先级实例通过乱序处理请求来最大化吞吐量，而高优先级实例则专注于低延迟执行，处理临近截止期限的紧急请求。Ascendra使用性能模型预测可能错过SLO的请求，并主动将其转移到高优先级实例。实验表明，Ascendra在满足TTFT和TBT SLO的同时，相比vLLM和Sarathi-Serve，系统吞吐量提高了1.7倍。\n",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.20828v2",
      "published_date": "2025-04-29 14:51:26 UTC",
      "updated_date": "2025-04-30 14:08:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-01T02:28:31.714370"
    },
    {
      "arxiv_id": "2504.20808v1",
      "title": "SoccerDiffusion: Toward Learning End-to-End Humanoid Robot Soccer from Gameplay Recordings",
      "title_zh": "SoccerDiffusion：从游戏记录中学习端到端人形机器人足球\n",
      "authors": [
        "Florian Vahl",
        "Jörn Griepenburg",
        "Jan Gutsche",
        "Jasper Güldenstein",
        "Jianwei Zhang"
      ],
      "abstract": "This paper introduces SoccerDiffusion, a transformer-based diffusion model\ndesigned to learn end-to-end control policies for humanoid robot soccer\ndirectly from real-world gameplay recordings. Using data collected from RoboCup\ncompetitions, the model predicts joint command trajectories from multi-modal\nsensor inputs, including vision, proprioception, and game state. We employ a\ndistillation technique to enable real-time inference on embedded platforms that\nreduces the multi-step diffusion process to a single step. Our results\ndemonstrate the model's ability to replicate complex motion behaviors such as\nwalking, kicking, and fall recovery both in simulation and on physical robots.\nAlthough high-level tactical behavior remains limited, this work provides a\nrobust foundation for subsequent reinforcement learning or preference\noptimization methods. We release the dataset, pretrained models, and code\nunder: https://bit-bots.github.io/SoccerDiffusion",
      "tldr_zh": "SoccerDiffusion 是一种基于Transformer的扩散模型，旨在直接从真实足球比赛记录中学习人形机器人足球的端到端控制策略。该模型利用RoboCup比赛数据，从视觉、本体感觉和游戏状态等多模态传感器输入预测关节指令轨迹。通过蒸馏技术，将多步扩散过程简化为单步，实现了在嵌入式平台上进行实时推理。实验结果表明，该模型能够在模拟和物理机器人上复制复杂的运动行为，如行走、踢球和跌倒恢复。虽然高级战术行为仍有限制，但该研究为后续的强化学习或偏好优化方法奠定了坚实的基础。项目的数据集、预训练模型和代码已开源。\n",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.20808v1",
      "published_date": "2025-04-29 14:21:08 UTC",
      "updated_date": "2025-04-29 14:21:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-01T02:28:43.776563"
    },
    {
      "arxiv_id": "2504.20799v1",
      "title": "Hallucination by Code Generation LLMs: Taxonomy, Benchmarks, Mitigation, and Challenges",
      "title_zh": "代码生成LLM的幻觉：分类、基准、缓解和挑战\n",
      "authors": [
        "Yunseo Lee",
        "John Youngeun Song",
        "Dongsun Kim",
        "Jindae Kim",
        "Mijung Kim",
        "Jaechang Nam"
      ],
      "abstract": "Recent technical breakthroughs in large language models (LLMs) have enabled\nthem to fluently generate source code. Software developers often leverage both\ngeneral-purpose and code-specialized LLMs to revise existing code or even\ngenerate a whole function from scratch. These capabilities are also beneficial\nin no-code or low-code contexts, in which one can write programs without a\ntechnical background. However, due to their internal design, LLMs are prone to\ngenerating hallucinations, which are incorrect, nonsensical, and not\njustifiable information but difficult to identify its presence. This problem\nalso occurs when generating source code. Once hallucinated code is produced, it\nis often challenging for users to identify and fix it, especially when such\nhallucinations can be identified under specific execution paths. As a result,\nthe hallucinated code may remain unnoticed within the codebase. This survey\ninvestigates recent studies and techniques relevant to hallucinations generated\nby CodeLLMs. We categorize the types of hallucinations in the code generated by\nCodeLLMs, review existing benchmarks and mitigation strategies, and identify\nopen challenges. Based on these findings, this survey outlines further research\ndirections in the detection and removal of hallucinations produced by CodeLLMs.",
      "tldr_zh": "这篇综述论文深入研究了代码生成大型语言模型(CodeLLMs)产生的幻觉问题。论文首先对CodeLLMs生成的代码中出现的幻觉类型进行了分类，然后回顾了现有的基准测试和缓解策略。研究指出，由于LLM的内在设计，生成的代码容易出现不正确、无意义且难以识别的幻觉信息，这给用户识别和修复带来了挑战，尤其是在特定执行路径下。最后，论文总结了该领域目前面临的挑战，并为未来检测和消除CodeLLMs产生的幻觉的研究方向提出了建议。\n",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "15 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2504.20799v1",
      "published_date": "2025-04-29 14:13:57 UTC",
      "updated_date": "2025-04-29 14:13:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-01T02:28:55.766325"
    },
    {
      "arxiv_id": "2504.20797v1",
      "title": "Partitioned Memory Storage Inspired Few-Shot Class-Incremental learning",
      "title_zh": "受分区内存存储启发的少样本类增量学习\n",
      "authors": [
        "Renye Zhang",
        "Yimin Yin",
        "Jinghua Zhang"
      ],
      "abstract": "Current mainstream deep learning techniques exhibit an over-reliance on\nextensive training data and a lack of adaptability to the dynamic world,\nmarking a considerable disparity from human intelligence. To bridge this gap,\nFew-Shot Class-Incremental Learning (FSCIL) has emerged, focusing on continuous\nlearning of new categories with limited samples without forgetting old\nknowledge. Existing FSCIL studies typically use a single model to learn\nknowledge across all sessions, inevitably leading to the stability-plasticity\ndilemma. Unlike machines, humans store varied knowledge in different cerebral\ncortices. Inspired by this characteristic, our paper aims to develop a method\nthat learns independent models for each session. It can inherently prevent\ncatastrophic forgetting. During the testing stage, our method integrates\nUncertainty Quantification (UQ) for model deployment. Our method provides a\nfresh viewpoint for FSCIL and demonstrates the state-of-the-art performance on\nCIFAR-100 and mini-ImageNet datasets.",
      "tldr_zh": "这篇论文受到人类大脑不同区域存储不同知识的启发，提出了一种新的FSCIL（Few-Shot Class-Incremental Learning）方法，该方法为每个session学习独立的模型，从而避免灾难性遗忘。该方法在测试阶段结合了不确定性量化（Uncertainty Quantification, UQ）用于模型部署。实验结果表明，该方法在CIFAR-100和mini-ImageNet数据集上取得了state-of-the-art的性能，为FSCIL提供了一个新的视角。\n",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.20797v1",
      "published_date": "2025-04-29 14:11:06 UTC",
      "updated_date": "2025-04-29 14:11:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-01T02:29:07.584034"
    },
    {
      "arxiv_id": "2504.20784v1",
      "title": "Approximate Lifted Model Construction",
      "title_zh": "近似的提升模型构建\n",
      "authors": [
        "Malte Luttermann",
        "Jan Speller",
        "Marcel Gehrke",
        "Tanya Braun",
        "Ralf Möller",
        "Mattis Hartwig"
      ],
      "abstract": "Probabilistic relational models such as parametric factor graphs enable\nefficient (lifted) inference by exploiting the indistinguishability of objects.\nIn lifted inference, a representative of indistinguishable objects is used for\ncomputations. To obtain a relational (i.e., lifted) representation, the\nAdvanced Colour Passing (ACP) algorithm is the state of the art. The ACP\nalgorithm, however, requires underlying distributions, encoded as\npotential-based factorisations, to exactly match to identify and exploit\nindistinguishabilities. Hence, ACP is unsuitable for practical applications\nwhere potentials learned from data inevitably deviate even if associated\nobjects are indistinguishable. To mitigate this problem, we introduce the\n$\\varepsilon$-Advanced Colour Passing ($\\varepsilon$-ACP) algorithm, which\nallows for a deviation of potentials depending on a hyperparameter\n$\\varepsilon$. $\\varepsilon$-ACP efficiently uncovers and exploits\nindistinguishabilities that are not exact. We prove that the approximation\nerror induced by $\\varepsilon$-ACP is strictly bounded and our experiments show\nthat the approximation error is close to zero in practice.",
      "tldr_zh": "本文提出了一种近似的提升模型构建方法，旨在解决传统Advanced Colour Passing (ACP)算法在处理实际应用中由于数据学习导致的潜在偏差时，无法有效识别和利用对象不可区分性的问题。为此，作者引入了$\\varepsilon$-Advanced Colour Passing ($\\varepsilon$-ACP)算法，该算法允许潜在函数存在一定的偏差（由超参数$\\varepsilon$控制），从而能够发现和利用非完全相同的不可区分性。论文证明了$\\varepsilon$-ACP引入的近似误差存在严格的界限，并且实验结果表明在实践中该近似误差接近于零。该方法为参数化因子图等概率关系模型的高效（提升）推理提供了新的途径。\n",
      "categories": [
        "cs.AI",
        "cs.DS",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "Extended version of paper accepted to the Proceedings of the 34th\n  International Joint Conference on Artificial Intelligence (IJCAI-2025)",
      "pdf_url": "http://arxiv.org/pdf/2504.20784v1",
      "published_date": "2025-04-29 14:01:10 UTC",
      "updated_date": "2025-04-29 14:01:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-01T02:29:19.823762"
    },
    {
      "arxiv_id": "2504.20781v1",
      "title": "Using LLMs in Generating Design Rationale for Software Architecture Decisions",
      "title_zh": "利用LLM生成软件架构决策的设计原理\n",
      "authors": [
        "Xiyu Zhou",
        "Ruiyin Li",
        "Peng Liang",
        "Beiqi Zhang",
        "Mojtaba Shahin",
        "Zengyang Li",
        "Chen Yang"
      ],
      "abstract": "Design Rationale (DR) for software architecture decisions refers to the\nreasoning underlying architectural choices, which provides valuable insights\ninto the different phases of the architecting process throughout software\ndevelopment. However, in practice, DR is often inadequately documented due to a\nlack of motivation and effort from developers. With the recent advancements in\nLarge Language Models (LLMs), their capabilities in text comprehension,\nreasoning, and generation may enable the generation and recovery of DR for\narchitecture decisions. In this study, we evaluated the performance of LLMs in\ngenerating DR for architecture decisions. First, we collected 50 Stack Overflow\n(SO) posts, 25 GitHub issues, and 25 GitHub discussions related to architecture\ndecisions to construct a dataset of 100 architecture-related problems. Then, we\nselected five LLMs to generate DR for the architecture decisions with three\nprompting strategies, including zero-shot, chain of thought (CoT), and\nLLM-based agents. With the DR provided by human experts as ground truth, the\nPrecision of LLM-generated DR with the three prompting strategies ranges from\n0.267 to 0.278, Recall from 0.627 to 0.715, and F1-score from 0.351 to 0.389.\nAdditionally, 64.45% to 69.42% of the arguments of DR not mentioned by human\nexperts are also helpful, 4.12% to 4.87% of the arguments have uncertain\ncorrectness, and 1.59% to 3.24% of the arguments are potentially misleading.\nBased on the results, we further discussed the pros and cons of the three\nprompting strategies and the strengths and limitations of the DR generated by\nLLMs.",
      "tldr_zh": "该研究评估了大型语言模型(LLMs)在为软件架构决策生成设计原理(DR)方面的性能。研究人员构建了一个包含100个与架构相关问题的的数据集，这些问题来自Stack Overflow、GitHub issues和GitHub discussions。他们使用零样本(zero-shot)、链式思考(CoT)和基于LLM的代理三种提示策略，利用五个LLM生成DR。结果表明，LLM生成的DR的精确度(Precision)在0.267到0.278之间，召回率(Recall)在0.627到0.715之间，F1分数在0.351到0.389之间。此外，大部分LLM生成的、但专家未提及的论点是有帮助的。研究进一步讨论了三种提示策略的优缺点以及LLM生成DR的优势和局限性。\n",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "28 pages, 5 images, 7 tables, Manuscript submitted to a journal\n  (2025)",
      "pdf_url": "http://arxiv.org/pdf/2504.20781v1",
      "published_date": "2025-04-29 14:00:18 UTC",
      "updated_date": "2025-04-29 14:00:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-01T02:29:32.057557"
    },
    {
      "arxiv_id": "2504.20776v1",
      "title": "ECOSoundSet: a finely annotated dataset for the automated acoustic identification of Orthoptera and Cicadidae in North, Central and temperate Western Europe",
      "title_zh": "ECOSoundSet：一个精细标注的数据集，用于在北欧、中欧和西欧温带地区自动进行直翅目和蝉科昆虫的声学识别\n",
      "authors": [
        "David Funosas",
        "Elodie Massol",
        "Yves Bas",
        "Svenja Schmidt",
        "Dominik Arend",
        "Alexander Gebhard",
        "Luc Barbaro",
        "Sebastian König",
        "Rafael Carbonell Font",
        "David Sannier",
        "Fernand Deroussen",
        "Jérôme Sueur",
        "Christian Roesti",
        "Tomi Trilar",
        "Wolfgang Forstmeier",
        "Lucas Roger",
        "Eloïsa Matheu",
        "Piotr Guzik",
        "Julien Barataud",
        "Laurent Pelozuelo",
        "Stéphane Puissant",
        "Sandra Mueller",
        "Björn Schuller",
        "Jose M. Montoya",
        "Andreas Triantafyllopoulos",
        "Maxime Cauchoix"
      ],
      "abstract": "Currently available tools for the automated acoustic recognition of European\ninsects in natural soundscapes are limited in scope. Large and ecologically\nheterogeneous acoustic datasets are currently needed for these algorithms to\ncross-contextually recognize the subtle and complex acoustic signatures\nproduced by each species, thus making the availability of such datasets a key\nrequisite for their development. Here we present ECOSoundSet (European\nCicadidae and Orthoptera Sound dataSet), a dataset containing 10,653 recordings\nof 200 orthopteran and 24 cicada species (217 and 26 respective taxa when\nincluding subspecies) present in North, Central, and temperate Western Europe\n(Andorra, Belgium, Denmark, mainland France and Corsica, Germany, Ireland,\nLuxembourg, Monaco, Netherlands, United Kingdom, Switzerland), collected partly\nthrough targeted fieldwork in South France and Catalonia and partly through\ncontributions from various European entomologists. The dataset is composed of a\ncombination of coarsely labeled recordings, for which we can only infer the\npresence, at some point, of their target species (weak labeling), and finely\nannotated recordings, for which we know the specific time and frequency range\nof each insect sound present in the recording (strong labeling). We also\nprovide a train/validation/test split of the strongly labeled recordings, with\nrespective approximate proportions of 0.8, 0.1 and 0.1, in order to facilitate\ntheir incorporation in the training and evaluation of deep learning algorithms.\nThis dataset could serve as a meaningful complement to recordings already\navailable online for the training of deep learning algorithms for the acoustic\nclassification of orthopterans and cicadas in North, Central, and temperate\nWestern Europe.",
      "tldr_zh": "该研究发布了ECOSoundSet，一个精细标注的数据集，用于自动识别欧洲北部、中部和温带西部的直翅目和蝉科昆虫的声音。该数据集包含10653个录音，涵盖200种直翅目和24种蝉科物种（包括亚种则分别为217和26个分类单元）。数据来源于实地考察和欧洲昆虫学家的贡献，包括粗略标注（弱标注）和精细标注（强标注）的录音，后者提供了昆虫声音的具体时间和频率范围。研究者还提供了训练/验证/测试集的划分，比例约为0.8/0.1/0.1，以方便深度学习算法的训练和评估。ECOSoundSet可以作为现有在线录音的重要补充，用于训练深度学习算法，从而实现对欧洲直翅目和蝉科昆虫声音的声学分类。\n",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "3 Figures + 2 Supplementary Figures, 2 Tables + 3 Supplementary\n  Tables",
      "pdf_url": "http://arxiv.org/pdf/2504.20776v1",
      "published_date": "2025-04-29 13:53:33 UTC",
      "updated_date": "2025-04-29 13:53:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-01T02:29:44.148407"
    },
    {
      "arxiv_id": "2504.20770v1",
      "title": "JTreeformer: Graph-Transformer via Latent-Diffusion Model for Molecular Generation",
      "title_zh": "JTreeformer：基于潜在扩散模型的图 Transformer 用于分子生成\n",
      "authors": [
        "Ji Shi",
        "Chengxun Xie",
        "Zhonghao Li",
        "Xinming Zhang",
        "Miao Zhang"
      ],
      "abstract": "The discovery of new molecules based on the original chemical molecule\ndistributions is of great importance in medicine. The graph transformer, with\nits advantages of high performance and scalability compared to traditional\ngraph networks, has been widely explored in recent research for applications of\ngraph structures. However, current transformer-based graph decoders struggle to\neffectively utilize graph information, which limits their capacity to leverage\nonly sequences of nodes rather than the complex topological structures of\nmolecule graphs. This paper focuses on building a graph transformer-based\nframework for molecular generation, which we call \\textbf{JTreeformer} as it\ntransforms graph generation into junction tree generation. It combines GCN\nparallel with multi-head attention as the encoder. It integrates a directed\nacyclic GCN into a graph-based Transformer to serve as a decoder, which can\niteratively synthesize the entire molecule by leveraging information from the\npartially constructed molecular structure at each step. In addition, a\ndiffusion model is inserted in the latent space generated by the encoder, to\nenhance the efficiency and effectiveness of sampling further. The empirical\nresults demonstrate that our novel framework outperforms existing molecule\ngeneration methods, thus offering a promising tool to advance drug discovery\n(https://anonymous.4open.science/r/JTreeformer-C74C).",
      "tldr_zh": "该论文提出了一种名为JTreeformer的图Transformer框架，用于分子生成，旨在解决现有基于Transformer的图解码器无法有效利用图信息的问题。JTreeformer将图生成转化为junction tree生成，并结合GCN并行结构和多头注意力作为编码器。解码器则集成了有向无环GCN到基于图的Transformer中，通过利用部分构建的分子结构信息迭代合成整个分子。此外，该框架还在编码器生成的潜在空间中插入了一个扩散模型，以提高采样的效率和有效性。实验结果表明，JTreeformer优于现有的分子生成方法，为药物发现提供了一个有前景的工具。\n",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "9 pages, 6figures",
      "pdf_url": "http://arxiv.org/pdf/2504.20770v1",
      "published_date": "2025-04-29 13:51:07 UTC",
      "updated_date": "2025-04-29 13:51:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-01T02:29:56.298445"
    },
    {
      "arxiv_id": "2504.20769v1",
      "title": "Chain-of-Defensive-Thought: Structured Reasoning Elicits Robustness in Large Language Models against Reference Corruption",
      "title_zh": "链式防御思维：结构化推理激发大型语言模型抵抗参考腐败的鲁棒性\n",
      "authors": [
        "Wenxiao Wang",
        "Parsa Hosseini",
        "Soheil Feizi"
      ],
      "abstract": "Chain-of-thought prompting has demonstrated great success in facilitating the\nreasoning abilities of large language models. In this work, we explore how\nthese enhanced reasoning abilities can be exploited to improve the robustness\nof large language models in tasks that are not necessarily reasoning-focused.\nIn particular, we show how a wide range of large language models exhibit\nsignificantly improved robustness against reference corruption using a simple\nmethod called chain-of-defensive-thought, where only a few exemplars with\nstructured and defensive reasoning are provided as demonstrations. Empirically,\nthe improvements can be astounding, especially given the simplicity and\napplicability of the method. For example, in the Natural Questions task, the\naccuracy of GPT-4o degrades from 60% to as low as 3% with standard prompting\nwhen 1 out of 10 references provided is corrupted with prompt injection\nattacks. In contrast, GPT-4o using chain-of-defensive-thought prompting\nmaintains an accuracy of 50%.",
      "tldr_zh": "该研究提出了一种名为“防御性思维链(Chain-of-Defensive-Thought)”的简单方法，旨在提升大型语言模型(LLMs)在面对参考信息污染时的鲁棒性。通过提供少量包含结构化和防御性推理的示例，该方法能够显著提高LLMs在非推理任务中的性能。实验结果表明，即使在十分之一的参考信息被注入提示攻击的情况下，使用防御性思维链的GPT-4o模型在Natural Questions任务中仍能保持50%的准确率，而标准提示下的准确率则会降至3%。该方法简单易用，具有广泛的应用前景。\n",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.20769v1",
      "published_date": "2025-04-29 13:50:05 UTC",
      "updated_date": "2025-04-29 13:50:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-01T02:30:07.850926"
    },
    {
      "arxiv_id": "2504.20756v1",
      "title": "Graph-Based Fault Diagnosis for Rotating Machinery: Adaptive Segmentation and Structural Feature Integration",
      "title_zh": "基于图的旋转机械故障诊断：自适应分割与结构特征融合\n",
      "authors": [
        "Moirangthem Tiken Singh"
      ],
      "abstract": "This paper proposes a novel graph-based framework for robust and\ninterpretable multiclass fault diagnosis in rotating machinery. The method\nintegrates entropy-optimized signal segmentation, time-frequency feature\nextraction, and graph-theoretic modeling to transform vibration signals into\nstructured representations suitable for classification. Graph metrics, such as\naverage shortest path length, modularity, and spectral gap, are computed and\ncombined with local features to capture global and segment-level fault\ncharacteristics. The proposed method achieves high diagnostic accuracy when\nevaluated on two benchmark datasets, the CWRU bearing dataset (under 0-3 HP\nloads) and the SU gearbox and bearing datasets (under different speed-load\nconfigurations). Classification scores reach up to 99.8% accuracy on Case\nWestern Reserve University (CWRU) and 100% accuracy on the Southeast University\ndatasets using a logistic regression classifier. Furthermore, the model\nexhibits strong noise resilience, maintaining over 95.4% accuracy at high noise\nlevels (standard deviation = 0.5), and demonstrates excellent cross-domain\ntransferability with up to 99.7% F1-score in load-transfer scenarios. Compared\nto traditional techniques, this approach requires no deep learning\narchitecture, enabling lower complexity while ensuring interpretability. The\nresults confirm the method's scalability, reliability, and potential for\nreal-time deployment in industrial diagnostics.",
      "tldr_zh": "该论文提出了一种基于图的旋转机械故障诊断框架，用于实现稳健且可解释的多类别故障诊断。该方法集成了熵优化的信号分割、时频特征提取和图论建模，将振动信号转换为结构化的表示形式，用于分类。通过计算图的指标（如平均最短路径长度、模块度和谱隙）并与局部特征相结合，来捕获全局和分割层面的故障特征。在CWRU轴承数据集和SU齿轮箱与轴承数据集上的评估结果表明，该方法具有很高的诊断准确率，在CWRU数据集上使用逻辑回归分类器达到了高达99.8%的准确率，在东南大学数据集上达到了100%的准确率。此外，该模型还表现出很强的抗噪声能力和出色的跨域迁移能力。与传统技术相比，该方法不需要深度学习架构，从而降低了复杂性，同时保证了可解释性。\n",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.20756v1",
      "published_date": "2025-04-29 13:34:52 UTC",
      "updated_date": "2025-04-29 13:34:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-01T02:30:20.171413"
    },
    {
      "arxiv_id": "2504.20752v1",
      "title": "Grokking in the Wild: Data Augmentation for Real-World Multi-Hop Reasoning with Transformers",
      "title_zh": "野外 Grokking：使用 Transformer 进行真实世界多跳推理的数据增强\n",
      "authors": [
        "Roman Abramov",
        "Felix Steinbauer",
        "Gjergji Kasneci"
      ],
      "abstract": "Transformers have achieved great success in numerous NLP tasks but continue\nto exhibit notable gaps in multi-step factual reasoning, especially when\nreal-world knowledge is sparse. Recent advances in grokking have demonstrated\nthat neural networks can transition from memorizing to perfectly generalizing\nonce they detect underlying logical patterns - yet these studies have primarily\nused small, synthetic tasks. In this paper, for the first time, we extend\ngrokking to real-world factual data and address the challenge of dataset\nsparsity by augmenting existing knowledge graphs with carefully designed\nsynthetic data to raise the ratio $\\phi_r$ of inferred facts to atomic facts\nabove the threshold required for grokking. Surprisingly, we find that even\nfactually incorrect synthetic data can strengthen emergent reasoning circuits\nrather than degrade accuracy, as it forces the model to rely on relational\nstructure rather than memorization. When evaluated on multi-hop reasoning\nbenchmarks, our approach achieves up to 95-100% accuracy on 2WikiMultiHopQA -\nsubstantially improving over strong baselines and matching or exceeding current\nstate-of-the-art results. We further provide an in-depth analysis of how\nincreasing $\\phi_r$ drives the formation of generalizing circuits inside\nTransformers. Our findings suggest that grokking-based data augmentation can\nunlock implicit multi-hop reasoning capabilities, opening the door to more\nrobust and interpretable factual reasoning in large-scale language models.",
      "tldr_zh": "该研究探索了在真实世界多跳推理任务中利用数据增强技术，使Transformer模型实现\"grokking\"现象的可能性。通过向现有知识图谱中添加精心设计的合成数据，提高推断事实与原子事实的比率$\\phi_r$，克服了数据集稀疏性的挑战。研究发现，即使是包含错误事实的合成数据也能增强模型的推理能力，迫使其依赖关系结构而非记忆。在多跳推理基准测试中，该方法在2WikiMultiHopQA上取得了高达95-100%的准确率，显著优于现有基线模型。进一步分析表明，提高$\\phi_r$能够促进Transformer内部泛化电路的形成。该研究表明，基于grokking的数据增强可以激发Transformer的隐式多跳推理能力，为大规模语言模型中更鲁棒和可解释的事实推理开辟了道路。\n",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG",
        "I.2.7; I.2.6; I.2.3; I.7"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.20752v1",
      "published_date": "2025-04-29 13:33:29 UTC",
      "updated_date": "2025-04-29 13:33:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-01T02:30:32.305344"
    },
    {
      "arxiv_id": "2504.20741v1",
      "title": "In defence of post-hoc explanations in medical AI",
      "title_zh": "为医学人工智能中的事后解释辩护\n",
      "authors": [
        "Joshua Hatherley",
        "Lauritz Munch",
        "Jens Christian Bjerring"
      ],
      "abstract": "Since the early days of the Explainable AI movement, post-hoc explanations\nhave been praised for their potential to improve user understanding, promote\ntrust, and reduce patient safety risks in black box medical AI systems.\nRecently, however, critics have argued that the benefits of post-hoc\nexplanations are greatly exaggerated since they merely approximate, rather than\nreplicate, the actual reasoning processes that black box systems take to arrive\nat their outputs. In this article, we aim to defend the value of post-hoc\nexplanations against this recent critique. We argue that even if post-hoc\nexplanations do not replicate the exact reasoning processes of black box\nsystems, they can still improve users' functional understanding of black box\nsystems, increase the accuracy of clinician-AI teams, and assist clinicians in\njustifying their AI-informed decisions. While post-hoc explanations are not a\n\"silver bullet\" solution to the black box problem in medical AI, we conclude\nthat they remain a useful strategy for addressing the black box problem in\nmedical AI.",
      "tldr_zh": "本文旨在为医学人工智能(Medical AI)中事后解释(post-hoc explanations)的价值辩护，反驳近期对其作用的质疑。尽管事后解释无法完全复制黑盒系统的推理过程，但作者认为它们仍然可以增进用户对黑盒系统的功能性理解，提高临床医生与AI团队的协作准确性，并辅助医生论证其基于AI的决策。文章强调，事后解释并非解决医学AI黑盒问题的“万能药”，但仍然是应对该问题的一种有效策略。\n",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CY",
        "cs.LG"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.20741v1",
      "published_date": "2025-04-29 13:24:21 UTC",
      "updated_date": "2025-04-29 13:24:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-01T02:30:43.916813"
    },
    {
      "arxiv_id": "2504.20734v1",
      "title": "UniversalRAG: Retrieval-Augmented Generation over Multiple Corpora with Diverse Modalities and Granularities",
      "title_zh": "UniversalRAG：基于多种模态和粒度的多语料库检索增强生成",
      "authors": [
        "Woongyeong Yeo",
        "Kangsan Kim",
        "Soyeong Jeong",
        "Jinheon Baek",
        "Sung Ju Hwang"
      ],
      "abstract": "Retrieval-Augmented Generation (RAG) has shown substantial promise in\nimproving factual accuracy by grounding model responses with external knowledge\nrelevant to queries. However, most existing RAG approaches are limited to a\ntext-only corpus, and while recent efforts have extended RAG to other\nmodalities such as images and videos, they typically operate over a single\nmodality-specific corpus. In contrast, real-world queries vary widely in the\ntype of knowledge they require, which a single type of knowledge source cannot\naddress. To address this, we introduce UniversalRAG, a novel RAG framework\ndesigned to retrieve and integrate knowledge from heterogeneous sources with\ndiverse modalities and granularities. Specifically, motivated by the\nobservation that forcing all modalities into a unified representation space\nderived from a single combined corpus causes a modality gap, where the\nretrieval tends to favor items from the same modality as the query, we propose\na modality-aware routing mechanism that dynamically identifies the most\nappropriate modality-specific corpus and performs targeted retrieval within it.\nAlso, beyond modality, we organize each modality into multiple granularity\nlevels, enabling fine-tuned retrieval tailored to the complexity and scope of\nthe query. We validate UniversalRAG on 8 benchmarks spanning multiple\nmodalities, showing its superiority over modality-specific and unified\nbaselines.",
      "tldr_zh": "本文提出了UniversalRAG，一种新型的检索增强生成(RAG)框架，旨在从具有不同模态和粒度的异构数据源中检索和整合知识。该框架通过模态感知路由机制，动态识别最合适的模态特定语料库，并在其中执行有针对性的检索，从而解决现有RAG方法仅限于文本语料库的问题。此外，UniversalRAG将每种模态组织成多个粒度级别，从而实现根据查询的复杂性和范围进行微调的检索。在涵盖多种模态的8个基准测试中，UniversalRAG 优于模态特定和统一的基线模型，验证了其有效性。\n",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CV",
        "cs.IR",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Project page : https://universalrag.github.io",
      "pdf_url": "http://arxiv.org/pdf/2504.20734v1",
      "published_date": "2025-04-29 13:18:58 UTC",
      "updated_date": "2025-04-29 13:18:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-01T02:30:56.336622"
    },
    {
      "arxiv_id": "2504.20733v1",
      "title": "Unsupervised Surrogate Anomaly Detection",
      "title_zh": "无监督代理异常检测\n",
      "authors": [
        "Simon Klüttermann",
        "Tim Katzke",
        "Emmanuel Müller"
      ],
      "abstract": "In this paper, we study unsupervised anomaly detection algorithms that learn\na neural network representation, i.e. regular patterns of normal data, which\nanomalies are deviating from. Inspired by a similar concept in engineering, we\nrefer to our methodology as surrogate anomaly detection. We formalize the\nconcept of surrogate anomaly detection into a set of axioms required for\noptimal surrogate models and propose a new algorithm, named DEAN (Deep Ensemble\nANomaly detection), designed to fulfill these criteria. We evaluate DEAN on 121\nbenchmark datasets, demonstrating its competitive performance against 19\nexisting methods, as well as the scalability and reliability of our method.",
      "tldr_zh": "本文研究了无监督异常检测算法，该算法学习神经网络表示，即正常数据的常规模式，异常数据偏离这些模式。受工程学中类似概念的启发，作者将该方法称为代理异常检测（surrogate anomaly detection）。作者将代理异常检测的概念形式化为最优代理模型所需的一组公理，并提出了一种名为DEAN（Deep Ensemble Anomaly detection）的新算法，旨在满足这些标准。在121个基准数据集上评估DEAN，证明了其相对于19种现有方法的竞争性能，以及该方法的可扩展性和可靠性。\n",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "13 pages + references and appendix = 35 pages",
      "pdf_url": "http://arxiv.org/pdf/2504.20733v1",
      "published_date": "2025-04-29 13:15:55 UTC",
      "updated_date": "2025-04-29 13:15:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-01T02:31:07.921447"
    },
    {
      "arxiv_id": "2504.20726v1",
      "title": "Enhancing Vulnerability Reports with Automated and Augmented Description Summarization",
      "title_zh": "利用自动化和增强型描述总结来增强漏洞报告\n",
      "authors": [
        "Hattan Althebeiti",
        "Mohammed Alkinoon",
        "Manar Mohaisen",
        "Saeed Salem",
        "DaeHun Nyang",
        "David Mohaisen"
      ],
      "abstract": "Public vulnerability databases, such as the National Vulnerability Database\n(NVD), document vulnerabilities and facilitate threat information sharing.\nHowever, they often suffer from short descriptions and outdated or insufficient\ninformation. In this paper, we introduce Zad, a system designed to enrich NVD\nvulnerability descriptions by leveraging external resources. Zad consists of\ntwo pipelines: one collects and filters supplementary data using two encoders\nto build a detailed dataset, while the other fine-tunes a pre-trained model on\nthis dataset to generate enriched descriptions. By addressing brevity and\nimproving content quality, Zad produces more comprehensive and cohesive\nvulnerability descriptions. We evaluate Zad using standard summarization\nmetrics and human assessments, demonstrating its effectiveness in enhancing\nvulnerability information.",
      "tldr_zh": "该论文提出了Zad，一个用于增强国家漏洞数据库(NVD)漏洞描述的系统。Zad通过两个pipeline实现：第一个pipeline利用两个encoder收集和过滤补充数据，构建详细的数据集；第二个pipeline在此数据集上微调预训练模型，生成增强的描述。Zad旨在解决NVD漏洞描述简短、信息不足的问题，通过更全面和连贯的描述来提升漏洞信息质量。实验结果表明，Zad在标准摘要指标和人工评估中均表现出有效性，能够有效增强漏洞信息。\n",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "12 pages, 3 tables, 12 figures. Accepted for publication in IEEE\n  Transactions on Big Data. Extended version of arXiv:2210.01260",
      "pdf_url": "http://arxiv.org/pdf/2504.20726v1",
      "published_date": "2025-04-29 13:08:27 UTC",
      "updated_date": "2025-04-29 13:08:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-01T02:31:19.794004"
    },
    {
      "arxiv_id": "2504.20708v1",
      "title": "Beyond the Last Answer: Your Reasoning Trace Uncovers More than You Think",
      "title_zh": "超越最终答案：你的推理轨迹揭示的比你想象的更多",
      "authors": [
        "Hasan Abed Al Kader Hammoud",
        "Hani Itani",
        "Bernard Ghanem"
      ],
      "abstract": "Large Language Models (LLMs) leverage step-by-step reasoning to solve complex\nproblems. Standard evaluation practice involves generating a complete reasoning\ntrace and assessing the correctness of the final answer presented at its\nconclusion. In this paper, we challenge the reliance on the final answer by\nposing the following two questions: Does the final answer reliably represent\nthe model's optimal conclusion? Can alternative reasoning paths yield different\nresults? To answer these questions, we analyze intermediate reasoning steps,\ntermed subthoughts, and propose a method based on our findings. Our approach\ninvolves segmenting a reasoning trace into sequential subthoughts based on\nlinguistic cues. We start by prompting the model to generate continuations from\nthe end-point of each intermediate subthought. We extract a potential answer\nfrom every completed continuation originating from different subthoughts. We\nfind that aggregating these answers by selecting the most frequent one (the\nmode) often yields significantly higher accuracy compared to relying solely on\nthe answer derived from the original complete trace. Analyzing the consistency\namong the answers derived from different subthoughts reveals characteristics\nthat correlate with the model's confidence and correctness, suggesting\npotential for identifying less reliable answers. Our experiments across various\nLLMs and challenging mathematical reasoning datasets (AIME2024 and AIME2025)\nshow consistent accuracy improvements, with gains reaching up to 13\\% and 10\\%\nrespectively. Implementation is available at:\nhttps://github.com/hammoudhasan/SubthoughtReasoner.",
      "tldr_zh": "该论文挑战了传统LLM评估中仅依赖最终答案的做法，认为推理过程中的中间步骤（subthoughts）蕴含更多信息。研究者提出一种方法，将推理链分割成多个subthoughts，并从每个subthought的终点生成多个延续，提取每个延续的潜在答案。通过聚合这些答案（选择最频繁的答案，即mode），能够显著提高准确率，优于仅依赖原始完整推理链的最终答案。实验表明，在AIME2024和AIME2025等数学推理数据集上，该方法能够稳定提升准确率，最高可达13%和10%。该研究揭示了推理过程的重要性，并为提高LLM的可靠性提供了新思路。\n",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Preprint",
      "pdf_url": "http://arxiv.org/pdf/2504.20708v1",
      "published_date": "2025-04-29 12:39:07 UTC",
      "updated_date": "2025-04-29 12:39:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-01T02:31:31.937043"
    },
    {
      "arxiv_id": "2504.20699v1",
      "title": "Can LLMs Detect Intrinsic Hallucinations in Paraphrasing and Machine Translation?",
      "title_zh": "LLM能否检测释义和机器翻译中的内在幻觉？\n",
      "authors": [
        "Evangelia Gogoulou",
        "Shorouq Zahra",
        "Liane Guillou",
        "Luise Dürlich",
        "Joakim Nivre"
      ],
      "abstract": "A frequently observed problem with LLMs is their tendency to generate output\nthat is nonsensical, illogical, or factually incorrect, often referred to\nbroadly as hallucination. Building on the recently proposed HalluciGen task for\nhallucination detection and generation, we evaluate a suite of open-access LLMs\non their ability to detect intrinsic hallucinations in two conditional\ngeneration tasks: translation and paraphrasing. We study how model performance\nvaries across tasks and language and we investigate the impact of model size,\ninstruction tuning, and prompt choice. We find that performance varies across\nmodels but is consistent across prompts. Finally, we find that NLI models\nperform comparably well, suggesting that LLM-based detectors are not the only\nviable option for this specific task.",
      "tldr_zh": "该研究评估了一系列开源LLM在检测释义和机器翻译中内在幻觉的能力，使用了HalluciGen任务。研究考察了模型性能在不同任务和语言上的差异，并研究了模型大小、指令微调和提示选择的影响。结果表明，模型性能因模型而异，但在不同提示下保持一致。此外，研究发现NLI模型表现相当，表明基于LLM的检测器并非此任务的唯一选择。\n",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.20699v1",
      "published_date": "2025-04-29 12:30:05 UTC",
      "updated_date": "2025-04-29 12:30:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-01T02:31:43.754517"
    },
    {
      "arxiv_id": "2504.20676v1",
      "title": "The Limits of AI Explainability: An Algorithmic Information Theory Approach",
      "title_zh": "AI 可解释性的局限性：一种基于算法信息论的方法\n",
      "authors": [
        "Shrisha Rao"
      ],
      "abstract": "This paper establishes a theoretical foundation for understanding the\nfundamental limits of AI explainability through algorithmic information theory.\nWe formalize explainability as the approximation of complex models by simpler\nones, quantifying both approximation error and explanation complexity using\nKolmogorov complexity. Our key theoretical contributions include: (1) a\ncomplexity gap theorem proving that any explanation significantly simpler than\nthe original model must differ from it on some inputs; (2) precise bounds\nshowing that explanation complexity grows exponentially with input dimension\nbut polynomially with error tolerance for Lipschitz functions; and (3) a\ncharacterization of the gap between local and global explainability,\ndemonstrating that local explanations can be significantly simpler while\nmaintaining accuracy in relevant regions. We further establish a regulatory\nimpossibility theorem proving that no governance framework can simultaneously\npursue unrestricted AI capabilities, human-interpretable explanations, and\nnegligible error. These results highlight considerations likely to be relevant\nto the design, evaluation, and oversight of explainable AI systems.",
      "tldr_zh": "本文从算法信息论出发，为理解AI可解释性的根本局限性建立了理论基础。文章将可解释性形式化为用更简单的模型逼近复杂模型，并使用 Kolmogorov 复杂度量化逼近误差和解释复杂度。主要理论贡献包括：(1) 复杂性差距定理，证明任何比原始模型简单得多的解释，在某些输入上必然存在差异；(2) 精确的界限，表明对于 Lipschitz 函数，解释复杂度随输入维度呈指数增长，但随误差容限呈多项式增长；(3) 刻画了局部和全局可解释性之间的差距，证明局部解释可以显著简化，同时在相关区域保持准确性。此外，文章还建立了一个监管不可能定理，证明没有任何治理框架能够同时追求不受限制的AI能力、人类可解释的解释和可忽略的误差。这些结果突出了可能与可解释AI系统的设计、评估和监督相关的考虑因素。\n",
      "categories": [
        "cs.AI",
        "cs.CY",
        "cs.IT",
        "math.IT",
        "68Q30, 68T01",
        "I.2.0; H.1.1; K.4.1"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.20676v1",
      "published_date": "2025-04-29 11:58:37 UTC",
      "updated_date": "2025-04-29 11:58:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-01T02:31:56.260343"
    },
    {
      "arxiv_id": "2504.20673v1",
      "title": "CoCo-Bench: A Comprehensive Code Benchmark For Multi-task Large Language Model Evaluation",
      "title_zh": "CoCo-Bench：用于多任务大型语言模型评估的综合代码基准\n",
      "authors": [
        "Wenjing Yin",
        "Tianze Sun",
        "Yijiong Yu",
        "Jiawei Fang",
        "Guangyao Su",
        "Jiancheng Wang",
        "Zekun Wang",
        "Wei Wang",
        "Ran Chen",
        "Ziyun Dai",
        "Shuai Yuan",
        "Menghang Dong",
        "Peng Luo",
        "Dong Cao",
        "Da Lei",
        "Yajun Zhang",
        "Hao Chen",
        "Xiang Ma",
        "Yong Liu",
        "Weifeng Liu",
        "Yuanjian Xu",
        "Ji Pei"
      ],
      "abstract": "Large language models (LLMs) play a crucial role in software engineering,\nexcelling in tasks like code generation and maintenance. However, existing\nbenchmarks are often narrow in scope, focusing on a specific task and lack a\ncomprehensive evaluation framework that reflects real-world applications. To\naddress these gaps, we introduce CoCo-Bench (Comprehensive Code Benchmark),\ndesigned to evaluate LLMs across four critical dimensions: code understanding,\ncode generation, code modification, and code review. These dimensions capture\nessential developer needs, ensuring a more systematic and representative\nevaluation. CoCo-Bench includes multiple programming languages and varying task\ndifficulties, with rigorous manual review to ensure data quality and accuracy.\nEmpirical results show that CoCo-Bench aligns with existing benchmarks while\nuncovering significant variations in model performance, effectively\nhighlighting strengths and weaknesses. By offering a holistic and objective\nevaluation, CoCo-Bench provides valuable insights to guide future research and\ntechnological advancements in code-oriented LLMs, establishing a reliable\nbenchmark for the field.",
      "tldr_zh": "CoCo-Bench是一个综合性的代码基准测试，旨在更全面地评估大型语言模型(LLMs)在软件工程中的能力。它涵盖了代码理解、代码生成、代码修改和代码审查四个关键维度，模拟了开发者在实际应用中的需求。CoCo-Bench支持多种编程语言和不同难度的任务，并经过严格的人工审核以保证数据质量。实验结果表明，CoCo-Bench能够有效揭示LLMs在不同任务上的优势和劣势，为代码相关的LLMs研究提供有价值的指导，并为该领域建立可靠的基准。\n",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "Submitted to ACL 2025. Under review",
      "pdf_url": "http://arxiv.org/pdf/2504.20673v1",
      "published_date": "2025-04-29 11:57:23 UTC",
      "updated_date": "2025-04-29 11:57:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-01T02:32:07.914849"
    },
    {
      "arxiv_id": "2504.20669v1",
      "title": "Advance Fake Video Detection via Vision Transformers",
      "title_zh": "基于视觉 Transformer 的高级伪造视频检测\n",
      "authors": [
        "Joy Battocchio",
        "Stefano Dell'Anna",
        "Andrea Montibeller",
        "Giulia Boato"
      ],
      "abstract": "Recent advancements in AI-based multimedia generation have enabled the\ncreation of hyper-realistic images and videos, raising concerns about their\npotential use in spreading misinformation. The widespread accessibility of\ngenerative techniques, which allow for the production of fake multimedia from\nprompts or existing media, along with their continuous refinement, underscores\nthe urgent need for highly accurate and generalizable AI-generated media\ndetection methods, underlined also by new regulations like the European Digital\nAI Act. In this paper, we draw inspiration from Vision Transformer (ViT)-based\nfake image detection and extend this idea to video. We propose an {original}\n%innovative framework that effectively integrates ViT embeddings over time to\nenhance detection performance. Our method shows promising accuracy,\ngeneralization, and few-shot learning capabilities across a new, large and\ndiverse dataset of videos generated using five open source generative\ntechniques from the state-of-the-art, as well as a separate dataset containing\nvideos produced by proprietary generative methods.",
      "tldr_zh": "该论文提出了一种基于Vision Transformer (ViT)的先进伪造视频检测方法，旨在应对AI生成多媒体技术带来的虚假信息传播风险。该方法受到ViT在伪造图像检测中的启发，并将其扩展到视频领域，通过有效整合ViT嵌入向量随时间的变化来提高检测性能。实验结果表明，该方法在新构建的大型、多样化的数据集上，以及包含专有生成方法生成视频的独立数据集上，都展现出良好的准确性、泛化性和小样本学习能力。该研究对于应对欧洲数字AI法案等新法规提出的挑战具有重要意义。\n",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.MM"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.20669v1",
      "published_date": "2025-04-29 11:51:07 UTC",
      "updated_date": "2025-04-29 11:51:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-01T02:32:19.969259"
    },
    {
      "arxiv_id": "2504.20658v1",
      "title": "TrueFake: A Real World Case Dataset of Last Generation Fake Images also Shared on Social Networks",
      "title_zh": "TrueFake：新一代虚假图像的真实世界案例数据集，同时在社交网络上分享\n",
      "authors": [
        "Stefano Dell'Anna",
        "Andrea Montibeller",
        "Giulia Boato"
      ],
      "abstract": "AI-generated synthetic media are increasingly used in real-world scenarios,\noften with the purpose of spreading misinformation and propaganda through\nsocial media platforms, where compression and other processing can degrade fake\ndetection cues. Currently, many forensic tools fail to account for these\nin-the-wild challenges. In this work, we introduce TrueFake, a large-scale\nbenchmarking dataset of 600,000 images including top notch generative\ntechniques and sharing via three different social networks. This dataset allows\nfor rigorous evaluation of state-of-the-art fake image detectors under very\nrealistic and challenging conditions. Through extensive experimentation, we\nanalyze how social media sharing impacts detection performance, and identify\ncurrent most effective detection and training strategies. Our findings\nhighlight the need for evaluating forensic models in conditions that mirror\nreal-world use.",
      "tldr_zh": "该论文提出了TrueFake数据集，一个包含60万张图像的大规模基准数据集，旨在模拟AI生成图像在社交媒体上传播的真实场景。该数据集涵盖了最新的生成技术，并通过三个不同的社交网络进行分享，从而引入了压缩和处理等真实世界的挑战。研究人员利用TrueFake数据集评估了当前最先进的假图像检测器，并分析了社交媒体分享对检测性能的影响。实验结果表明，在真实场景下评估取证模型至关重要，并指出了当前最有效的检测和训练策略。该数据集为开发更具鲁棒性的假图像检测工具提供了宝贵的资源。\n",
      "categories": [
        "cs.MM",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.MM",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.20658v1",
      "published_date": "2025-04-29 11:33:52 UTC",
      "updated_date": "2025-04-29 11:33:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-01T02:32:32.022969"
    },
    {
      "arxiv_id": "2504.20656v1",
      "title": "Federated learning, ethics, and the double black box problem in medical AI",
      "title_zh": "联邦学习、伦理以及医学人工智能中的双重黑盒问题\n",
      "authors": [
        "Joshua Hatherley",
        "Anders Søgaard",
        "Angela Ballantyne",
        "Ruben Pauwels"
      ],
      "abstract": "Federated learning (FL) is a machine learning approach that allows multiple\ndevices or institutions to collaboratively train a model without sharing their\nlocal data with a third-party. FL is considered a promising way to address\npatient privacy concerns in medical artificial intelligence. The ethical risks\nof medical FL systems themselves, however, have thus far been underexamined.\nThis paper aims to address this gap. We argue that medical FL presents a new\nvariety of opacity -- federation opacity -- that, in turn, generates a\ndistinctive double black box problem in healthcare AI. We highlight several\ninstances in which the anticipated benefits of medical FL may be exaggerated,\nand conclude by highlighting key challenges that must be overcome to make FL\nethically feasible in medicine.",
      "tldr_zh": "本文探讨了联邦学习(Federated Learning, FL)在医疗人工智能领域中的伦理风险，指出医疗FL可能产生一种新的不透明性——联邦不透明性(federation opacity)，从而导致医疗AI中独特的双重黑盒问题(double black box problem)。文章分析了医疗FL的预期优势可能被夸大的几种情况，并强调了为使FL在医学上具有伦理可行性必须克服的关键挑战。该研究旨在弥补目前对医疗FL系统伦理风险研究不足的空白。\n",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CY",
        "cs.HC"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.20656v1",
      "published_date": "2025-04-29 11:31:48 UTC",
      "updated_date": "2025-04-29 11:31:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-01T02:32:43.806500"
    },
    {
      "arxiv_id": "2504.20648v1",
      "title": "SpaRE: Enhancing Spatial Reasoning in Vision-Language Models with Synthetic Data",
      "title_zh": "SpaRE：利用合成数据增强视觉-语言模型中的空间推理能力\n",
      "authors": [
        "Michael Ogezi",
        "Freda Shi"
      ],
      "abstract": "Vision-language models (VLMs) work well in tasks ranging from image\ncaptioning to visual question answering (VQA), yet they struggle with spatial\nreasoning, a key skill for understanding our physical world that humans excel\nat. We find that spatial relations are generally rare in widely used VL\ndatasets, with only a few being well represented, while most form a long tail\nof underrepresented relations. This gap leaves VLMs ill-equipped to handle\ndiverse spatial relationships. To bridge it, we construct a synthetic VQA\ndataset focused on spatial reasoning generated from hyper-detailed image\ndescriptions in Localized Narratives, DOCCI, and PixMo-Cap. Our dataset\nconsists of 455k samples containing 3.4 million QA pairs. Trained on this\ndataset, our Spatial-Reasoning Enhanced (SpaRE) VLMs show strong improvements\non spatial reasoning benchmarks, achieving up to a 49% performance gain on the\nWhat's Up benchmark, while maintaining strong results on general tasks. Our\nwork narrows the gap between human and VLM spatial reasoning and makes VLMs\nmore capable in real-world tasks such as robotics and navigation.",
      "tldr_zh": "该论文针对视觉语言模型(VLMs)在空间推理方面的不足，提出了一个名为SpaRE的增强方法。研究发现，现有VLM训练数据集中的空间关系数据存在长尾分布，导致模型难以处理多样的空间关系。为了解决这个问题，作者构建了一个合成的VQA数据集，专注于空间推理，该数据集包含455k个样本和340万个QA对，数据来源于Localized Narratives, DOCCI, 和 PixMo-Cap中高度详细的图像描述。通过在该数据集上训练，SpaRE VLMs在空间推理基准测试中表现出显著的提升，在What's Up基准测试中获得了高达49%的性能提升，同时保持了在通用任务上的良好表现。该研究缩小了人与VLM在空间推理方面的差距，并使VLM在机器人和导航等实际任务中更具能力。\n",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.20648v1",
      "published_date": "2025-04-29 11:18:38 UTC",
      "updated_date": "2025-04-29 11:18:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-01T02:32:56.908239"
    },
    {
      "arxiv_id": "2504.20643v1",
      "title": "Cooking Up Creativity: A Cognitively-Inspired Approach for Enhancing LLM Creativity through Structured Representations",
      "title_zh": "烹饪创意：一种通过结构化表示增强LLM创造力的认知启发方法\n",
      "authors": [
        "Moran Mizrahi",
        "Chen Shani",
        "Gabriel Stanovsky",
        "Dan Jurafsky",
        "Dafna Shahaf"
      ],
      "abstract": "Large Language Models (LLMs) excel at countless tasks, yet struggle with\ncreativity. In this paper, we introduce a novel approach that couples LLMs with\nstructured representations and cognitively inspired manipulations to generate\nmore creative and diverse ideas. Our notion of creativity goes beyond\nsuperficial token-level variations; rather, we explicitly recombine structured\nrepresentations of existing ideas, allowing our algorithm to effectively\nexplore the more abstract landscape of ideas. We demonstrate our approach in\nthe culinary domain with DishCOVER, a model that generates creative recipes.\nExperiments comparing our model's results to those of GPT-4o show greater\ndiversity. Domain expert evaluations reveal that our outputs, which are mostly\ncoherent and feasible culinary creations, significantly surpass GPT-4o in terms\nof novelty, thus outperforming it in creative generation. We hope our work\ninspires further research into structured creativity in AI.",
      "tldr_zh": "该论文提出了一种受认知启发的方法，通过结合大型语言模型(LLMs)与结构化表示，来提升LLMs的创造力。该方法不仅仅关注token层面的变化，而是通过重组现有想法的结构化表示，探索更抽象的想法空间。研究者在烹饪领域验证了该方法，提出了DishCOVER模型，用于生成创意菜谱。实验结果表明，DishCOVER在多样性方面优于GPT-4o，并且在领域专家评估中，其输出的新颖性显著超过GPT-4o，表明该方法在创意生成方面具有优势。\n",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "10 pages, 8 figures",
      "pdf_url": "http://arxiv.org/pdf/2504.20643v1",
      "published_date": "2025-04-29 11:13:06 UTC",
      "updated_date": "2025-04-29 11:13:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-01T02:33:08.142840"
    },
    {
      "arxiv_id": "2504.20634v1",
      "title": "On Stochastic Rounding with Few Random Bits",
      "title_zh": "关于使用少量随机比特的随机舍入\n",
      "authors": [
        "Andrew Fitzgibbon",
        "Stephen Felix"
      ],
      "abstract": "Large-scale numerical computations make increasing use of low-precision (LP)\nfloating point formats and mixed precision arithmetic, which can be enhanced by\nthe technique of stochastic rounding (SR), that is, rounding an intermediate\nhigh-precision value up or down randomly as a function of the value's distance\nto the two rounding candidates. Stochastic rounding requires, in addition to\nthe high-precision input value, a source of random bits. As the provision of\nhigh-quality random bits is an additional computational cost, it is of interest\nto require as few bits as possible while maintaining the desirable properties\nof SR in a given computation, or computational domain. This paper examines a\nnumber of possible implementations of few-bit stochastic rounding (FBSR), and\nshows how several natural implementations can introduce sometimes significant\nbias into the rounding process, which are not present in the case of\ninfinite-bit, infinite-precision examinations of these implementations. The\npaper explores the impact of these biases in machine learning examples, and\nhence opens another class of configuration parameters of which practitioners\nshould be aware when developing or adopting low-precision floating point. Code\nis available at\nhttp://github.com/graphcore-research/arith25-stochastic-rounding.",
      "tldr_zh": "本文研究了在低精度浮点数和混合精度计算中使用随机舍入(Stochastic Rounding, SR)时，如何减少所需的随机比特数。通过分析几种少比特随机舍入(Few-Bit Stochastic Rounding, FBSR)的实现方法，揭示了某些自然实现方式可能引入显著偏差，这在无限比特和无限精度分析中并不存在。该研究进一步探讨了这些偏差在机器学习示例中的影响，并指出在开发或采用低精度浮点数时，从业者应注意此类配置参数。相关代码已开源。\n",
      "categories": [
        "math.NA",
        "cs.AI",
        "cs.LG",
        "cs.MS",
        "cs.NA"
      ],
      "primary_category": "math.NA",
      "comment": "Published at ARITH 2025",
      "pdf_url": "http://arxiv.org/pdf/2504.20634v1",
      "published_date": "2025-04-29 11:04:25 UTC",
      "updated_date": "2025-04-29 11:04:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-01T02:33:19.920559"
    },
    {
      "arxiv_id": "2504.20629v1",
      "title": "AlignDiT: Multimodal Aligned Diffusion Transformer for Synchronized Speech Generation",
      "title_zh": "AlignDiT：用于同步语音生成的多模态对齐扩散Transformer\n",
      "authors": [
        "Jeongsoo Choi",
        "Ji-Hoon Kim",
        "Kim Sung-Bin",
        "Tae-Hyun Oh",
        "Joon Son Chung"
      ],
      "abstract": "In this paper, we address the task of multimodal-to-speech generation, which\naims to synthesize high-quality speech from multiple input modalities: text,\nvideo, and reference audio. This task has gained increasing attention due to\nits wide range of applications, such as film production, dubbing, and virtual\navatars. Despite recent progress, existing methods still suffer from\nlimitations in speech intelligibility, audio-video synchronization, speech\nnaturalness, and voice similarity to the reference speaker. To address these\nchallenges, we propose AlignDiT, a multimodal Aligned Diffusion Transformer\nthat generates accurate, synchronized, and natural-sounding speech from aligned\nmultimodal inputs. Built upon the in-context learning capability of the DiT\narchitecture, AlignDiT explores three effective strategies to align multimodal\nrepresentations. Furthermore, we introduce a novel multimodal classifier-free\nguidance mechanism that allows the model to adaptively balance information from\neach modality during speech synthesis. Extensive experiments demonstrate that\nAlignDiT significantly outperforms existing methods across multiple benchmarks\nin terms of quality, synchronization, and speaker similarity. Moreover,\nAlignDiT exhibits strong generalization capability across various multimodal\ntasks, such as video-to-speech synthesis and visual forced alignment,\nconsistently achieving state-of-the-art performance. The demo page is available\nat https://mm.kaist.ac.kr/projects/AlignDiT .",
      "tldr_zh": "本文提出AlignDiT，一种多模态对齐扩散Transformer，用于从文本、视频和参考音频等多模态输入中合成高质量语音。AlignDiT基于DiT架构的上下文学习能力，探索了三种有效的策略来对齐多模态表征，并引入了一种新的多模态无分类器引导机制，使模型能够自适应地平衡来自每种模态的信息。实验表明，AlignDiT在语音质量、同步性和说话人相似度方面显著优于现有方法，并在视频到语音合成和视觉强制对齐等多种多模态任务中表现出强大的泛化能力，始终达到state-of-the-art的性能。\n",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.MM"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.20629v1",
      "published_date": "2025-04-29 10:56:24 UTC",
      "updated_date": "2025-04-29 10:56:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-01T02:33:32.067466"
    },
    {
      "arxiv_id": "2504.20628v1",
      "title": "Cognitive maps are generative programs",
      "title_zh": "认知地图是生成程序",
      "authors": [
        "Marta Kryven",
        "Cole Wyeth",
        "Aidan Curtis",
        "Kevin Ellis"
      ],
      "abstract": "Making sense of the world and acting in it relies on building simplified\nmental representations that abstract away aspects of reality. This principle of\ncognitive mapping is universal to agents with limited resources. Living\norganisms, people, and algorithms all face the problem of forming functional\nrepresentations of their world under various computing constraints. In this\nwork, we explore the hypothesis that human resource-efficient planning may\narise from representing the world as predictably structured. Building on the\nmetaphor of concepts as programs, we propose that cognitive maps can take the\nform of generative programs that exploit predictability and redundancy, in\ncontrast to directly encoding spatial layouts. We use a behavioral experiment\nto show that people who navigate in structured spaces rely on modular planning\nstrategies that align with programmatic map representations. We describe a\ncomputational model that predicts human behavior in a variety of structured\nscenarios. This model infers a small distribution over possible programmatic\ncognitive maps conditioned on human prior knowledge of the world, and uses this\ndistribution to generate resource-efficient plans. Our models leverages a Large\nLanguage Model as an embedding of human priors, implicitly learned through\ntraining on a vast corpus of human data. Our model demonstrates improved\ncomputational efficiency, requires drastically less memory, and outperforms\nunstructured planning algorithms with cognitive constraints at predicting human\nbehavior, suggesting that human planning strategies rely on programmatic\ncognitive maps.",
      "tldr_zh": "该研究提出认知地图可以被视为生成程序，通过利用可预测的结构和冗余信息来高效地表示世界，从而实现资源高效的规划。研究者通过行为实验表明，在结构化空间中导航的人们依赖于模块化的规划策略，这与程序化的地图表示相一致。他们构建了一个计算模型，该模型基于人类先验知识推断可能的程序化认知地图的分布，并利用该分布生成资源高效的计划。该模型利用大型语言模型(LLM)作为人类先验知识的嵌入。实验结果表明，该模型在预测人类行为方面表现出更高的计算效率和更低的内存需求，并优于具有认知约束的非结构化规划算法，这表明人类规划策略依赖于程序化的认知地图。\n",
      "categories": [
        "cs.AI",
        "cs.ET"
      ],
      "primary_category": "cs.AI",
      "comment": "9 pages, 4 figures, to be published in Cognitive Sciences Society\n  proceedings",
      "pdf_url": "http://arxiv.org/pdf/2504.20628v1",
      "published_date": "2025-04-29 10:55:40 UTC",
      "updated_date": "2025-04-29 10:55:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-01T02:33:44.163725"
    },
    {
      "arxiv_id": "2504.20625v1",
      "title": "DiffusionRIR: Room Impulse Response Interpolation using Diffusion Models",
      "title_zh": "DiffusionRIR：使用扩散模型的房间脉冲响应插值",
      "authors": [
        "Sagi Della Torre",
        "Mirco Pezzoli",
        "Fabio Antonacci",
        "Sharon Gannot"
      ],
      "abstract": "Room Impulse Responses (RIRs) characterize acoustic environments and are\ncrucial in multiple audio signal processing tasks. High-quality RIR estimates\ndrive applications such as virtual microphones, sound source localization,\naugmented reality, and data augmentation. However, obtaining RIR measurements\nwith high spatial resolution is resource-intensive, making it impractical for\nlarge spaces or when dense sampling is required. This research addresses the\nchallenge of estimating RIRs at unmeasured locations within a room using\nDenoising Diffusion Probabilistic Models (DDPM). Our method leverages the\nanalogy between RIR matrices and image inpainting, transforming RIR data into a\nformat suitable for diffusion-based reconstruction.\n  Using simulated RIR data based on the image method, we demonstrate our\napproach's effectiveness on microphone arrays of different curvatures, from\nlinear to semi-circular. Our method successfully reconstructs missing RIRs,\neven in large gaps between microphones. Under these conditions, it achieves\naccurate reconstruction, significantly outperforming baseline Spline Cubic\nInterpolation in terms of Normalized Mean Square Error and Cosine Distance\nbetween actual and interpolated RIRs.\n  This research highlights the potential of using generative models for\neffective RIR interpolation, paving the way for generating additional data from\nlimited real-world measurements.",
      "tldr_zh": "该研究提出了一种基于去噪扩散概率模型(DDPM)的DiffusionRIR方法，用于在房间内未测量位置插值房间脉冲响应(RIR)。该方法将RIR矩阵类比于图像修复，将RIR数据转换为适合基于扩散重建的格式。通过在模拟RIR数据上进行实验，证明了该方法在不同曲率的麦克风阵列（从线性到半圆形）上的有效性，即使在麦克风之间存在较大间隙的情况下也能成功重建缺失的RIR。实验结果表明，DiffusionRIR在归一化均方误差和实际RIR与插值RIR之间的余弦距离方面，显著优于基线Spline Cubic插值方法。该研究突出了使用生成模型进行有效RIR插值的潜力，为从有限的真实世界测量中生成额外数据铺平了道路。\n",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.20625v1",
      "published_date": "2025-04-29 10:52:07 UTC",
      "updated_date": "2025-04-29 10:52:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-01T02:33:56.733839"
    },
    {
      "arxiv_id": "2504.20624v1",
      "title": "PaRT: Enhancing Proactive Social Chatbots with Personalized Real-Time Retrieval",
      "title_zh": "PaRT：通过个性化实时检索增强主动式社交聊天机器人\n",
      "authors": [
        "Zihan Niu",
        "Zheyong Xie",
        "Shaosheng Cao",
        "Chonggang Lu",
        "Zheyu Ye",
        "Tong Xu",
        "Zuozhu Liu",
        "Yan Gao",
        "Jia Chen",
        "Zhe Xu",
        "Yi Wu",
        "Yao Hu"
      ],
      "abstract": "Social chatbots have become essential intelligent companions in daily\nscenarios ranging from emotional support to personal interaction. However,\nconventional chatbots with passive response mechanisms usually rely on users to\ninitiate or sustain dialogues by bringing up new topics, resulting in\ndiminished engagement and shortened dialogue duration. In this paper, we\npresent PaRT, a novel framework enabling context-aware proactive dialogues for\nsocial chatbots through personalized real-time retrieval and generation.\nSpecifically, PaRT first integrates user profiles and dialogue context into a\nlarge language model (LLM), which is initially prompted to refine user queries\nand recognize their underlying intents for the upcoming conversation. Guided by\nrefined intents, the LLM generates personalized dialogue topics, which then\nserve as targeted queries to retrieve relevant passages from RedNote. Finally,\nwe prompt LLMs with summarized passages to generate knowledge-grounded and\nengagement-optimized responses. Our approach has been running stably in a\nreal-world production environment for more than 30 days, achieving a 21.77\\%\nimprovement in the average duration of dialogues.",
      "tldr_zh": "本文提出了PaRT，一个用于增强主动社交聊天机器人的框架，通过个性化的实时检索和生成来实现上下文感知的主动对话。PaRT将用户画像和对话上下文整合到大型语言模型(LLM)中，首先通过prompt优化用户查询并识别潜在意图。然后，LLM生成个性化的对话主题，并将其作为目标查询从RedNote中检索相关段落。最后，利用LLM和总结后的段落生成基于知识且优化参与度的回复。该方法已在实际生产环境中稳定运行超过30天，对话的平均持续时间提高了21.77%。\n",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.20624v1",
      "published_date": "2025-04-29 10:51:58 UTC",
      "updated_date": "2025-04-29 10:51:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-01T02:34:08.033269"
    },
    {
      "arxiv_id": "2504.20612v1",
      "title": "The Hidden Risks of LLM-Generated Web Application Code: A Security-Centric Evaluation of Code Generation Capabilities in Large Language Models",
      "title_zh": "LLM 生成的 Web 应用程序代码的隐藏风险：大型语言模型代码生成能力的安全中心评估\n",
      "authors": [
        "Swaroop Dora",
        "Deven Lunkad",
        "Naziya Aslam",
        "S. Venkatesan",
        "Sandeep Kumar Shukla"
      ],
      "abstract": "The rapid advancement of Large Language Models (LLMs) has enhanced software\ndevelopment processes, minimizing the time and effort required for coding and\nenhancing developer productivity. However, despite their potential benefits,\ncode generated by LLMs has been shown to generate insecure code in controlled\nenvironments, raising critical concerns about their reliability and security in\nreal-world applications. This paper uses predefined security parameters to\nevaluate the security compliance of LLM-generated code across multiple models,\nsuch as ChatGPT, DeepSeek, Claude, Gemini and Grok. The analysis reveals\ncritical vulnerabilities in authentication mechanisms, session management,\ninput validation and HTTP security headers. Although some models implement\nsecurity measures to a limited extent, none fully align with industry best\npractices, highlighting the associated risks in automated software development.\nOur findings underscore that human expertise is crucial to ensure secure\nsoftware deployment or review of LLM-generated code. Also, there is a need for\nrobust security assessment frameworks to enhance the reliability of\nLLM-generated code in real-world applications.",
      "tldr_zh": "该论文评估了大型语言模型(LLMs)生成的Web应用程序代码的安全性，揭示了其隐藏风险。通过预定义的安全性参数，研究分析了ChatGPT、DeepSeek、Claude、Gemini和Grok等多个LLM在身份验证、会话管理、输入验证和HTTP安全标头等方面的代码生成能力。结果表明，尽管某些模型在一定程度上实施了安全措施，但没有一个模型完全符合行业最佳实践，存在严重的安全漏洞。因此，论文强调在部署或审查LLM生成的代码时，人工专业知识至关重要，并呼吁建立强大的安全评估框架，以提高LLM生成代码在实际应用中的可靠性。\n",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.ET"
      ],
      "primary_category": "cs.CR",
      "comment": "9 pages",
      "pdf_url": "http://arxiv.org/pdf/2504.20612v1",
      "published_date": "2025-04-29 10:23:11 UTC",
      "updated_date": "2025-04-29 10:23:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-01T02:34:25.777287"
    },
    {
      "arxiv_id": "2504.20610v1",
      "title": "Information Retrieval in the Age of Generative AI: The RGB Model",
      "title_zh": "生成式人工智能时代的信息检索：RGB 模型\n",
      "authors": [
        "Michele Garetto",
        "Alessandro Cornacchia",
        "Franco Galante",
        "Emilio Leonardi",
        "Alessandro Nordio",
        "Alberto Tarable"
      ],
      "abstract": "The advent of Large Language Models (LLMs) and generative AI is fundamentally\ntransforming information retrieval and processing on the Internet, bringing\nboth great potential and significant concerns regarding content authenticity\nand reliability. This paper presents a novel quantitative approach to shed\nlight on the complex information dynamics arising from the growing use of\ngenerative AI tools. Despite their significant impact on the digital ecosystem,\nthese dynamics remain largely uncharted and poorly understood. We propose a\nstochastic model to characterize the generation, indexing, and dissemination of\ninformation in response to new topics. This scenario particularly challenges\ncurrent LLMs, which often rely on real-time Retrieval-Augmented Generation\n(RAG) techniques to overcome their static knowledge limitations. Our findings\nsuggest that the rapid pace of generative AI adoption, combined with increasing\nuser reliance, can outpace human verification, escalating the risk of\ninaccurate information proliferation across digital resources. An in-depth\nanalysis of Stack Exchange data confirms that high-quality answers inevitably\nrequire substantial time and human effort to emerge. This underscores the\nconsiderable risks associated with generating persuasive text in response to\nnew questions and highlights the critical need for responsible development and\ndeployment of future generative AI tools.",
      "tldr_zh": "本文提出了一个随机模型，即RGB模型，用于量化分析生成式AI时代信息检索中生成、索引和传播的复杂信息动态。该模型旨在应对大型语言模型(LLMs)依赖实时检索增强生成(RAG)技术时，因知识静态性而面临的挑战。研究发现，生成式AI的快速普及和用户依赖性的增加，可能超过人工验证的速度，从而加剧不准确信息在数字资源中的传播风险。对Stack Exchange数据的深入分析表明，高质量的答案需要大量时间和人力才能产生。因此，在响应新问题时生成具有说服力的文本存在相当大的风险，强调了负责任地开发和部署未来生成式AI工具的必要性。\n",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.PF"
      ],
      "primary_category": "cs.IR",
      "comment": "To be presented at ACM SIGIR 25",
      "pdf_url": "http://arxiv.org/pdf/2504.20610v1",
      "published_date": "2025-04-29 10:21:40 UTC",
      "updated_date": "2025-04-29 10:21:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-01T02:34:32.282200"
    },
    {
      "arxiv_id": "2504.20595v1",
      "title": "ReasonIR: Training Retrievers for Reasoning Tasks",
      "title_zh": "ReasonIR：训练用于推理任务的检索器\n",
      "authors": [
        "Rulin Shao",
        "Rui Qiao",
        "Varsha Kishore",
        "Niklas Muennighoff",
        "Xi Victoria Lin",
        "Daniela Rus",
        "Bryan Kian Hsiang Low",
        "Sewon Min",
        "Wen-tau Yih",
        "Pang Wei Koh",
        "Luke Zettlemoyer"
      ],
      "abstract": "We present ReasonIR-8B, the first retriever specifically trained for general\nreasoning tasks. Existing retrievers have shown limited gains on reasoning\ntasks, in part because existing training datasets focus on short factual\nqueries tied to documents that straightforwardly answer them. We develop a\nsynthetic data generation pipeline that, for each document, our pipeline\ncreates a challenging and relevant query, along with a plausibly related but\nultimately unhelpful hard negative. By training on a mixture of our synthetic\ndata and existing public data, ReasonIR-8B achieves a new state-of-the-art of\n29.9 nDCG@10 without reranker and 36.9 nDCG@10 with reranker on BRIGHT, a\nwidely-used reasoning-intensive information retrieval (IR) benchmark. When\napplied to RAG tasks, ReasonIR-8B improves MMLU and GPQA performance by 6.4%\nand 22.6% respectively, relative to the closed-book baseline, outperforming\nother retrievers and search engines. In addition, ReasonIR-8B uses test-time\ncompute more effectively: on BRIGHT, its performance consistently increases\nwith longer and more information-rich rewritten queries; it continues to\noutperform other retrievers when combined with an LLM reranker. Our training\nrecipe is general and can be easily extended to future LLMs; to this end, we\nopen-source our code, data, and model.",
      "tldr_zh": "该论文提出了ReasonIR-8B，一种专门为通用推理任务训练的检索器。为了解决现有检索器在推理任务上的局限性，研究者开发了一个合成数据生成流程，该流程为每个文档创建具有挑战性的相关查询以及看似相关但实际上无用的负样本。通过混合使用合成数据和现有公共数据进行训练，ReasonIR-8B在BRIGHT基准测试中取得了新的state-of-the-art，nDCG@10指标分别为29.9 (无reranker) 和 36.9 (有reranker)。在应用于RAG任务时，ReasonIR-8B相对于闭卷基线，在MMLU和GPQA性能上分别提高了6.4%和22.6%，优于其他检索器和搜索引擎。此外，ReasonIR-8B能更有效地利用测试时计算资源，并且其性能随着更长和信息更丰富的重写查询而持续提高。该研究开源了代码、数据和模型。\n",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.IR",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "Our code is released at\n  \\url{https://github.com/facebookresearch/ReasonIR}",
      "pdf_url": "http://arxiv.org/pdf/2504.20595v1",
      "published_date": "2025-04-29 09:49:28 UTC",
      "updated_date": "2025-04-29 09:49:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-01T02:34:44.555464"
    },
    {
      "arxiv_id": "2504.20571v1",
      "title": "Reinforcement Learning for Reasoning in Large Language Models with One Training Example",
      "title_zh": "使用单个训练样本对大型语言模型进行推理的强化学习\n",
      "authors": [
        "Yiping Wang",
        "Qing Yang",
        "Zhiyuan Zeng",
        "Liliang Ren",
        "Lucas Liu",
        "Baolin Peng",
        "Hao Cheng",
        "Xuehai He",
        "Kuan Wang",
        "Jianfeng Gao",
        "Weizhu Chen",
        "Shuohang Wang",
        "Simon Shaolei Du",
        "Yelong Shen"
      ],
      "abstract": "We show that reinforcement learning with verifiable reward using one training\nexample (1-shot RLVR) is effective in incentivizing the math reasoning\ncapabilities of large language models (LLMs). Applying RLVR to the base model\nQwen2.5-Math-1.5B, we identify a single example that elevates model performance\non MATH500 from 36.0% to 73.6%, and improves the average performance across six\ncommon mathematical reasoning benchmarks from 17.6% to 35.7%. This result\nmatches the performance obtained using the 1.2k DeepScaleR subset (MATH500:\n73.6%, average: 35.9%), which includes the aforementioned example. Similar\nsubstantial improvements are observed across various models (Qwen2.5-Math-7B,\nLlama3.2-3B-Instruct, DeepSeek-R1-Distill-Qwen-1.5B), RL algorithms (GRPO and\nPPO), and different math examples (many of which yield approximately 30% or\ngreater improvement on MATH500 when employed as a single training example). In\naddition, we identify some interesting phenomena during 1-shot RLVR, including\ncross-domain generalization, increased frequency of self-reflection, and\nsustained test performance improvement even after the training accuracy has\nsaturated, a phenomenon we term post-saturation generalization. Moreover, we\nverify that the effectiveness of 1-shot RLVR primarily arises from the policy\ngradient loss, distinguishing it from the \"grokking\" phenomenon. We also show\nthe critical role of promoting exploration (e.g., by adding entropy loss with\nan appropriate coefficient) in 1-shot RLVR training. As a bonus, we observe\nthat applying entropy loss alone, without any outcome reward, significantly\nenhances Qwen2.5-Math-1.5B's performance on MATH500 by 27.4%. These findings\ncan inspire future work on RLVR data efficiency and encourage a re-examination\nof both recent progress and the underlying mechanisms in RLVR. Our code, model,\nand data are open source at https://github.com/ypwang61/One-Shot-RLVR",
      "tldr_zh": "该论文提出了一种单样本强化学习与可验证奖励(1-shot RLVR)的方法，用于提升大型语言模型(LLMs)的数学推理能力。通过对Qwen2.5-Math-1.5B模型应用RLVR，仅使用一个训练样本，在MATH500数据集上的性能从36.0%提升至73.6%，并在六个数学推理基准测试上的平均性能从17.6%提升至35.7%。研究表明，策略梯度损失是1-shot RLVR有效性的主要来源，并强调了探索（例如，添加熵损失）在训练中的关键作用。此外，仅应用熵损失也能显著提升模型在MATH500上的性能。该研究为RLVR的数据效率和潜在机制提供了新的见解。\n",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "28 pages, 12 figures, link: https://github.com/ypwang61/One-Shot-RLVR",
      "pdf_url": "http://arxiv.org/pdf/2504.20571v1",
      "published_date": "2025-04-29 09:24:30 UTC",
      "updated_date": "2025-04-29 09:24:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-01T02:34:56.511255"
    },
    {
      "arxiv_id": "2504.20566v1",
      "title": "Inclusive Training Separation and Implicit Knowledge Interaction for Balanced Online Class-Incremental Learning",
      "title_zh": "包容性训练分离和隐式知识交互，实现平衡的在线类增量学习",
      "authors": [
        "Shunjie Wen",
        "Thomas Heinis",
        "Dong-Wan Choi"
      ],
      "abstract": "Online class-incremental learning (OCIL) focuses on gradually learning new\nclasses (called plasticity) from a stream of data in a single-pass, while\nconcurrently preserving knowledge of previously learned classes (called\nstability). The primary challenge in OCIL lies in maintaining a good balance\nbetween the knowledge of old and new classes within the continually updated\nmodel. Most existing methods rely on explicit knowledge interaction through\nexperience replay, and often employ exclusive training separation to address\nbias problems. Nevertheless, it still remains a big challenge to achieve a\nwell-balanced learner, as these methods often exhibit either reduced plasticity\nor limited stability due to difficulties in continually integrating knowledge\nin the OCIL setting. In this paper, we propose a novel replay-based method,\ncalled Balanced Online Incremental Learning (BOIL), which can achieve both high\nplasticity and stability, thus ensuring more balanced performance in OCIL. Our\nBOIL method proposes an inclusive training separation strategy using dual\nclassifiers so that knowledge from both old and new classes can effectively be\nintegrated into the model, while introducing implicit approaches for\ntransferring knowledge across the two classifiers. Extensive experimental\nevaluations over three widely-used OCIL benchmark datasets demonstrate the\nsuperiority of BOIL, showing more balanced yet better performance compared to\nstate-of-the-art replay-based OCIL methods.",
      "tldr_zh": "本文提出了一种名为Balanced Online Incremental Learning (BOIL) 的新型基于回放的在线类增量学习(OCIL)方法，旨在解决OCIL中新旧类别知识平衡问题。BOIL采用包含性的训练分离策略，使用双分类器有效整合新旧类别的知识，并引入隐式方法在两个分类器之间传递知识。通过在三个广泛使用的OCIL基准数据集上进行的大量实验评估表明，与最先进的基于回放的OCIL方法相比，BOIL表现出更平衡和更优越的性能，实现了更高的plasticity和stability。\n",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Under review",
      "pdf_url": "http://arxiv.org/pdf/2504.20566v1",
      "published_date": "2025-04-29 09:13:00 UTC",
      "updated_date": "2025-04-29 09:13:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-01T02:35:12.228461"
    },
    {
      "arxiv_id": "2504.20560v1",
      "title": "Generate more than one child in your co-evolutionary semi-supervised learning GAN",
      "title_zh": "在你的协同进化半监督学习 GAN 中生成多个子代\n",
      "authors": [
        "Francisco Sedeño",
        "Jamal Toutouh",
        "Francisco Chicano"
      ],
      "abstract": "Generative Adversarial Networks (GANs) are very useful methods to address\nsemi-supervised learning (SSL) datasets, thanks to their ability to generate\nsamples similar to real data. This approach, called SSL-GAN has attracted many\nresearchers in the last decade. Evolutionary algorithms have been used to guide\nthe evolution and training of SSL-GANs with great success. In particular,\nseveral co-evolutionary approaches have been applied where the two networks of\na GAN (the generator and the discriminator) are evolved in separate\npopulations. The co-evolutionary approaches published to date assume some\nspatial structure of the populations, based on the ideas of cellular\nevolutionary algorithms. They also create one single individual per generation\nand follow a generational replacement strategy in the evolution. In this paper,\nwe re-consider those algorithmic design decisions and propose a new\nco-evolutionary approach, called Co-evolutionary Elitist SSL-GAN (CE-SSLGAN),\nwith panmictic population, elitist replacement, and more than one individual in\nthe offspring. We evaluate the performance of our proposed method using three\nstandard benchmark datasets. The results show that creating more than one\noffspring per population and using elitism improves the results in comparison\nwith a classical SSL-GAN.",
      "tldr_zh": "本文提出了一种新的协同进化半监督学习GAN (CE-SSLGAN)方法，旨在改进传统SSL-GAN的训练。该方法采用全混合种群、精英替换策略，并在每次迭代中生成多个子代个体，从而克服了传统协同进化SSL-GAN算法中基于空间结构、单个体生成和世代替换的局限性。在三个标准benchmark数据集上的实验结果表明，与经典SSL-GAN相比，CE-SSLGAN通过生成多个后代和使用精英主义能够显著提升性能。该研究表明，在协同进化SSL-GAN中，增加子代数量和引入精英策略是有效的改进方向。\n",
      "categories": [
        "cs.NE",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.NE",
      "comment": "Submitted to The Leading European Event on Bio-Inspired AI (EvoStar\n  2025)",
      "pdf_url": "http://arxiv.org/pdf/2504.20560v1",
      "published_date": "2025-04-29 09:04:22 UTC",
      "updated_date": "2025-04-29 09:04:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-01T02:35:20.237101"
    },
    {
      "arxiv_id": "2504.20520v1",
      "title": "PRISM: Projection-based Reward Integration for Scene-Aware Real-to-Sim-to-Real Transfer with Few Demonstrations",
      "title_zh": "PRISM：基于投影的奖励集成，用于少量演示的场景感知型实物到仿真到实物迁移\n",
      "authors": [
        "Haowen Sun",
        "Han Wang",
        "Chengzhong Ma",
        "Shaolong Zhang",
        "Jiawei Ye",
        "Xingyu Chen",
        "Xuguang Lan"
      ],
      "abstract": "Learning from few demonstrations to develop policies robust to variations in\nrobot initial positions and object poses is a problem of significant practical\ninterest in robotics. Compared to imitation learning, which often struggles to\ngeneralize from limited samples, reinforcement learning (RL) can autonomously\nexplore to obtain robust behaviors. Training RL agents through direct\ninteraction with the real world is often impractical and unsafe, while building\nsimulation environments requires extensive manual effort, such as designing\nscenes and crafting task-specific reward functions. To address these\nchallenges, we propose an integrated real-to-sim-to-real pipeline that\nconstructs simulation environments based on expert demonstrations by\nidentifying scene objects from images and retrieving their corresponding 3D\nmodels from existing libraries. We introduce a projection-based reward model\nfor RL policy training that is supervised by a vision-language model (VLM)\nusing human-guided object projection relationships as prompts, with the policy\nfurther fine-tuned using expert demonstrations. In general, our work focuses on\nthe construction of simulation environments and RL-based policy training,\nultimately enabling the deployment of reliable robotic control policies in\nreal-world scenarios.",
      "tldr_zh": "该论文提出了一种基于投影奖励集成(PRISM)的真实-模拟-真实迁移学习框架，旨在解决机器人初始位置和物体姿态变化下的少量样本学习问题。PRISM通过从图像中识别场景物体并检索对应的3D模型，基于专家演示构建仿真环境。同时，引入了一种基于投影的奖励模型，该模型由视觉-语言模型(VLM)监督，使用人工引导的物体投影关系作为提示，并使用专家演示进一步微调策略。该方法能够构建仿真环境并进行基于强化学习(RL)的策略训练，最终实现可靠的机器人控制策略在真实世界中的部署。\n",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.20520v1",
      "published_date": "2025-04-29 08:01:27 UTC",
      "updated_date": "2025-04-29 08:01:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-01T02:35:32.155186"
    },
    {
      "arxiv_id": "2504.20505v1",
      "title": "MuRAL: A Multi-Resident Ambient Sensor Dataset Annotated with Natural Language for Activities of Daily Living",
      "title_zh": "MuRAL：一个多居民环境传感器数据集，使用自然语言标注日常生活活动",
      "authors": [
        "Xi Chen",
        "Julien Cumin",
        "Fano Ramparany",
        "Dominique Vaufreydaz"
      ],
      "abstract": "Recent advances in Large Language Models (LLMs) have shown promising\npotential for human activity recognition (HAR) using ambient sensors,\nespecially through natural language reasoning and zero-shot learning. However,\nexisting datasets such as CASAS, ARAS, and MARBLE were not originally designed\nwith LLMs in mind and therefore lack the contextual richness, complexity, and\nannotation granularity required to fully exploit LLM capabilities. In this\npaper, we introduce MuRAL, the first Multi-Resident Ambient sensor dataset with\nnatural Language, comprising over 21 hours of multi-user sensor data collected\nfrom 21 sessions in a smart-home environment. MuRAL is annotated with\nfine-grained natural language descriptions, resident identities, and high-level\nactivity labels, all situated in dynamic, realistic multi-resident settings. We\nbenchmark MuRAL using state-of-the-art LLMs for three core tasks: subject\nassignment, action description, and activity classification. Our results\ndemonstrate that while LLMs can provide rich semantic interpretations of\nambient data, current models still face challenges in handling multi-user\nambiguity and under-specified sensor contexts. We release MuRAL to support\nfuture research on LLM-powered, explainable, and socially aware activity\nunderstanding in smart environments. For access to the dataset, please reach\nout to us via the provided contact information. A direct link for dataset\nretrieval will be made available at this location in due course.",
      "tldr_zh": "该论文介绍了MuRAL，一个多住户环境传感器数据集，专为利用大型语言模型(LLMs)进行日常活动识别(HAR)而设计。MuRAL包含超过21小时的多用户传感器数据，来自智能家居环境中的21个会话，并带有细粒度的自然语言描述、住户身份和高层活动标签。研究者利用最先进的LLMs在MuRAL上进行了主体分配、动作描述和活动分类三个核心任务的基准测试。结果表明，LLMs能够提供丰富的语义解释，但在处理多用户歧义和欠指定传感器上下文方面仍面临挑战。MuRAL的发布旨在支持未来基于LLM的、可解释的、具有社会意识的智能环境活动理解研究。\n",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.20505v1",
      "published_date": "2025-04-29 07:46:14 UTC",
      "updated_date": "2025-04-29 07:46:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-01T02:35:44.243787"
    },
    {
      "arxiv_id": "2504.20493v1",
      "title": "Token-Efficient Prompt Injection Attack: Provoking Cessation in LLM Reasoning via Adaptive Token Compression",
      "title_zh": "Token高效的Prompt注入攻击：通过自适应Token压缩诱导LLM推理停止",
      "authors": [
        "Yu Cui",
        "Yujun Cai",
        "Yiwei Wang"
      ],
      "abstract": "While reasoning large language models (LLMs) demonstrate remarkable\nperformance across various tasks, they also contain notable security\nvulnerabilities. Recent research has uncovered a \"thinking-stopped\"\nvulnerability in DeepSeek-R1, where model-generated reasoning tokens can\nforcibly interrupt the inference process, resulting in empty responses that\ncompromise LLM-integrated applications. However, existing methods triggering\nthis vulnerability require complex mathematical word problems with long\nprompts--even exceeding 5,000 tokens. To reduce the token cost and formally\ndefine this vulnerability, we propose a novel prompt injection attack named\n\"Reasoning Interruption Attack\", based on adaptive token compression. We\ndemonstrate that simple standalone arithmetic tasks can effectively trigger\nthis vulnerability, and the prompts based on such tasks exhibit simpler logical\nstructures than mathematical word problems. We develop a systematic approach to\nefficiently collect attack prompts and an adaptive token compression framework\nthat utilizes LLMs to automatically compress these prompts. Experiments show\nour compression framework significantly reduces prompt length while maintaining\neffective attack capabilities. We further investigate the attack's performance\nvia output prefix and analyze the underlying causes of the vulnerability,\nproviding valuable insights for improving security in reasoning LLMs.",
      "tldr_zh": "该论文提出了一种名为“推理中断攻击 (Reasoning Interruption Attack)”的新型提示注入攻击，旨在利用大型语言模型 (LLM) 中存在的“thinking-stopped”漏洞。通过自适应 token 压缩技术，该攻击能够使用更短的提示（基于简单的算术任务）有效地中断 LLM 的推理过程，使其停止生成有效回复。研究人员系统地收集攻击提示，并利用 LLM 自动压缩这些提示，显著降低了提示长度，同时保持了攻击的有效性。实验结果表明，该方法能够成功触发 DeepSeek-R1 等模型的漏洞，并深入分析了该漏洞的潜在原因，为提升推理 LLM 的安全性提供了有价值的见解。\n",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.20493v1",
      "published_date": "2025-04-29 07:34:22 UTC",
      "updated_date": "2025-04-29 07:34:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-01T02:35:58.489303"
    },
    {
      "arxiv_id": "2504.20482v1",
      "title": "Group Relative Knowledge Distillation: Learning from Teacher's Relational Inductive Bias",
      "title_zh": "群体相对知识蒸馏：从教师模型的关联归纳偏置中学习\n",
      "authors": [
        "Chao Li",
        "Changhua Zhou",
        "Jia Chen"
      ],
      "abstract": "Knowledge distillation typically transfers knowledge from a teacher model to\na student model by minimizing differences between their output distributions.\nHowever, existing distillation approaches largely focus on mimicking absolute\nprobabilities and neglect the valuable relational inductive biases embedded in\nthe teacher's relative predictions, leading to exposure bias. In this paper, we\npropose Group Relative Knowledge Distillation (GRKD), a novel framework that\ndistills teacher knowledge by learning the relative ranking among classes,\nrather than directly fitting the absolute distribution. Specifically, we\nintroduce a group relative loss that encourages the student model to preserve\nthe pairwise preference orderings provided by the teacher's outputs. Extensive\nexperiments on classification benchmarks demonstrate that GRKD achieves\nsuperior generalization compared to existing methods, especially in tasks\nrequiring fine-grained class differentiation. Our method provides a new\nperspective on exploiting teacher knowledge, focusing on relational structure\nrather than absolute likelihood.",
      "tldr_zh": "该论文提出了一种新的知识蒸馏框架——Group Relative Knowledge Distillation (GRKD)，旨在通过学习教师模型预测的相对排序关系来传递知识，而非直接模仿绝对概率分布。GRKD引入了一种group relative loss，鼓励学生模型保留教师模型输出中蕴含的成对偏好排序信息。实验结果表明，在分类任务上，尤其是在需要细粒度类别区分的任务中，GRKD相比现有方法展现出更强的泛化能力。该方法为利用教师知识提供了一个新的视角，即关注关系结构而非绝对似然。\n",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.20482v1",
      "published_date": "2025-04-29 07:23:22 UTC",
      "updated_date": "2025-04-29 07:23:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-01T02:36:08.043552"
    },
    {
      "arxiv_id": "2504.20471v1",
      "title": "The Estimation of Continual Causal Effect for Dataset Shifting Streams",
      "title_zh": "数据集漂移流的持续因果效应估计\n",
      "authors": [
        "Baining Chen",
        "Yiming Zhang",
        "Yuqiao Han",
        "Ruyue Zhang",
        "Ruihuan Du",
        "Zhishuo Zhou",
        "Zhengdan Zhu",
        "Xun Liu",
        "Jiecheng Guo"
      ],
      "abstract": "Causal effect estimation has been widely used in marketing optimization. The\nframework of an uplift model followed by a constrained optimization algorithm\nis popular in practice. To enhance performance in the online environment, the\nframework needs to be improved to address the complexities caused by temporal\ndataset shift. This paper focuses on capturing the dataset shift from user\nbehavior and domain distribution changing over time. We propose an Incremental\nCausal Effect with Proxy Knowledge Distillation (ICE-PKD) framework to tackle\nthis challenge. The ICE-PKD framework includes two components: (i) a\nmulti-treatment uplift network that eliminates confounding bias using\ncounterfactual regression; (ii) an incremental training strategy that adapts to\nthe temporal dataset shift by updating with the latest data and protects\ngeneralization via replay-based knowledge distillation. We also revisit the\nuplift modeling metrics and introduce a novel metric for more precise online\nevaluation in multiple treatment scenarios. Extensive experiments on both\nsimulated and online datasets show that the proposed framework achieves better\nperformance. The ICE-PKD framework has been deployed in the marketing system of\nHuaxiaozhu, a ride-hailing platform in China.",
      "tldr_zh": "该论文提出了一种名为增量因果效应与代理知识蒸馏(ICE-PKD)的框架，用于解决营销优化中因果效应估计在时序数据集偏移下的问题。ICE-PKD框架包含一个多处理提升网络，该网络利用反事实回归消除混淆偏差，以及一个增量训练策略，通过最新的数据更新来适应时序数据集偏移，并通过基于重放的知识蒸馏来保护泛化能力。此外，论文还重新审视了提升建模指标，并引入了一种新的指标，用于在多处理场景中进行更精确的在线评估。在模拟和在线数据集上的大量实验表明，所提出的框架取得了更好的性能。ICE-PKD框架已部署在中国的网约车平台花小猪的营销系统中。\n",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ME"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.20471v1",
      "published_date": "2025-04-29 07:13:28 UTC",
      "updated_date": "2025-04-29 07:13:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-01T02:36:26.256354"
    },
    {
      "arxiv_id": "2504.20464v1",
      "title": "A Summary on GUI Agents with Foundation Models Enhanced by Reinforcement Learning",
      "title_zh": "基于强化学习增强的、以基础模型为动力的 GUI 智能体综述\n",
      "authors": [
        "Jiahao Li",
        "Kaer Huang"
      ],
      "abstract": "Graphical User Interface (GUI) agents, driven by Multi-modal Large Language\nModels (MLLMs), have emerged as a promising paradigm for enabling intelligent\ninteraction with digital systems. This paper provides a structured summary of\nrecent advances in GUI agents, focusing on architectures enhanced by\nReinforcement Learning (RL). We first formalize GUI agent tasks as Markov\nDecision Processes and discuss typical execution environments and evaluation\nmetrics. We then review the modular architecture of (M)LLM-based GUI agents,\ncovering Perception, Planning, and Acting modules, and trace their evolution\nthrough representative works. Furthermore, we categorize GUI agent training\nmethodologies into Prompt-based, Supervised Fine-Tuning (SFT)-based, and\nRL-based approaches, highlighting the progression from simple prompt\nengineering to dynamic policy learning via RL. Our summary illustrates how\nrecent innovations in multimodal perception, decision reasoning, and adaptive\naction generation have significantly improved the generalization and robustness\nof GUI agents in complex real-world environments. We conclude by identifying\nkey challenges and future directions for building more capable and reliable GUI\nagents.",
      "tldr_zh": "本文综述了基于多模态大型语言模型(MLLMs)并由强化学习(RL)增强的图形用户界面(GUI)智能体的最新进展。首先将GUI智能体任务形式化为马尔可夫决策过程，并讨论了典型的执行环境和评估指标。然后，回顾了基于(M)LLM的GUI智能体的模块化架构，包括感知、规划和行动模块，并追溯了它们在代表性工作中的演变。此外，将GUI智能体训练方法分为基于提示、基于监督微调(SFT)和基于RL的方法，重点介绍了从简单提示工程到通过RL进行动态策略学习的进展。总结表明，多模态感知、决策推理和自适应行动生成方面的最新创新显著提高了GUI智能体在复杂现实世界环境中的泛化性和鲁棒性。最后，总结了构建更强大和可靠的GUI智能体的关键挑战和未来方向。\n",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.20464v1",
      "published_date": "2025-04-29 06:55:15 UTC",
      "updated_date": "2025-04-29 06:55:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-01T02:36:34.632009"
    },
    {
      "arxiv_id": "2504.20462v2",
      "title": "TAMO:Fine-Grained Root Cause Analysis via Tool-Assisted LLM Agent with Multi-Modality Observation Data",
      "title_zh": "TAMO：通过工具辅助的LLM智能体和多模态观测数据进行细粒度根本原因分析\n",
      "authors": [
        "Qi Wang",
        "Xiao Zhang",
        "Mingyi Li",
        "Yuan Yuan",
        "Mengbai Xiao",
        "Fuzhen Zhuang",
        "Dongxiao Yu"
      ],
      "abstract": "With the development of distributed systems, microservices and cloud native\ntechnologies have become central to modern enterprise software development.\nDespite bringing significant advantages, these technologies also increase\nsystem complexity and operational challenges. Traditional root cause analysis\n(RCA) struggles to achieve automated fault response, heavily relying on manual\nintervention. In recent years, large language models (LLMs) have made\nbreakthroughs in contextual inference and domain knowledge integration,\nproviding new solutions for Artificial Intelligence for Operations (AIOps).\nHowever, Existing LLM-based approaches face three key challenges: text input\nconstraints, dynamic service dependency hallucinations, and context window\nlimitations. To address these issues, we propose a tool-assisted LLM agent with\nmulti-modality observation data, namely TAMO, for fine-grained RCA. It unifies\nmulti-modal observational data into time-aligned representations to extract\nconsistent features and employs specialized root cause localization and fault\nclassification tools for perceiving the contextual environment. This approach\novercomes the limitations of LLM in handling real-time changing service\ndependencies and raw observational data and guides LLM to generate repair\nstrategies aligned with system contexts by structuring key information into a\nprompt. Experimental results show that TAMO performs well in root cause\nanalysis when dealing with public datasets characterized by heterogeneity and\ncommon fault types, demonstrating its effectiveness.",
      "tldr_zh": "该论文提出了TAMO，一种工具辅助的LLM Agent，利用多模态观测数据进行细粒度的根因分析(RCA)。TAMO旨在解决传统RCA依赖人工干预，以及现有基于LLM的方法在文本输入约束、动态服务依赖幻觉和上下文窗口限制等方面的问题。TAMO统一多模态观测数据为时间对齐的表示，提取一致性特征，并采用专门的根因定位和故障分类工具来感知上下文环境。实验结果表明，TAMO在处理具有异构性和常见故障类型的公共数据集时表现良好，验证了其有效性。TAMO通过将关键信息结构化到提示中，引导LLM生成与系统上下文对齐的修复策略，从而克服了LLM在处理实时变化的服务依赖关系和原始观测数据方面的局限性。\n",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.20462v2",
      "published_date": "2025-04-29 06:50:48 UTC",
      "updated_date": "2025-04-30 10:20:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-01T02:36:44.296037"
    },
    {
      "arxiv_id": "2504.20452v1",
      "title": "Enhancing News Recommendation with Hierarchical LLM Prompting",
      "title_zh": "利用分层 LLM 提示增强新闻推荐\n",
      "authors": [
        "Hai-Dang Kieu",
        "Delvin Ce Zhang",
        "Minh Duc Nguyen",
        "Min Xu",
        "Qiang Wu",
        "Dung D. Le"
      ],
      "abstract": "Personalized news recommendation systems often struggle to effectively\ncapture the complexity of user preferences, as they rely heavily on shallow\nrepresentations, such as article titles and abstracts. To address this problem,\nwe introduce a novel method, namely PNR-LLM, for Large Language Models for\nPersonalized News Recommendation. Specifically, PNR-LLM harnesses the\ngeneration capabilities of LLMs to enrich news titles and abstracts, and\nconsequently improves recommendation quality. PNR-LLM contains a novel module,\nNews Enrichment via LLMs, which generates deeper semantic information and\nrelevant entities from articles, transforming shallow contents into richer\nrepresentations. We further propose an attention mechanism to aggregate\nenriched semantic- and entity-level data, forming unified user and news\nembeddings that reveal a more accurate user-news match. Extensive experiments\non MIND datasets show that PNR-LLM outperforms state-of-the-art baselines.\nMoreover, the proposed data enrichment module is model-agnostic, and we\nempirically show that applying our proposed module to multiple existing models\ncan further improve their performance, verifying the advantage of our design.",
      "tldr_zh": "该论文提出了一种名为PNR-LLM的新方法，利用大型语言模型(LLMs)增强个性化新闻推荐。PNR-LLM通过LLMs生成更深层次的语义信息和相关实体，从而丰富新闻标题和摘要等浅层内容。该方法包含一个新闻增强模块，将浅层内容转化为更丰富的表示。此外，还提出了一个注意力机制来聚合增强的语义和实体级别数据，形成统一的用户和新闻嵌入，从而更准确地匹配用户和新闻。在MIND数据集上的大量实验表明，PNR-LLM优于目前最先进的基线模型，并且数据增强模块具有模型无关性，可以提高现有模型的性能。\n",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.20452v1",
      "published_date": "2025-04-29 06:02:16 UTC",
      "updated_date": "2025-04-29 06:02:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-01T02:36:56.429430"
    },
    {
      "arxiv_id": "2504.20447v1",
      "title": "APG-MOS: Auditory Perception Guided-MOS Predictor for Synthetic Speech",
      "title_zh": "APG-MOS：合成语音的听觉感知引导 MOS 预测器\n",
      "authors": [
        "Zhicheng Lian",
        "Lizhi Wang",
        "Hua Huang"
      ],
      "abstract": "Automatic speech quality assessment aims to quantify subjective human\nperception of speech through computational models to reduce the need for\nlabor-consuming manual evaluations. While models based on deep learning have\nachieved progress in predicting mean opinion scores (MOS) to assess synthetic\nspeech, the neglect of fundamental auditory perception mechanisms limits\nconsistency with human judgments. To address this issue, we propose an auditory\nperception guided-MOS prediction model (APG-MOS) that synergistically\nintegrates auditory modeling with semantic analysis to enhance consistency with\nhuman judgments. Specifically, we first design a perceptual module, grounded in\nbiological auditory mechanisms, to simulate cochlear functions, which encodes\nacoustic signals into biologically aligned electrochemical representations.\nSecondly, we propose a residual vector quantization (RVQ)-based semantic\ndistortion modeling method to quantify the degradation of speech quality at the\nsemantic level. Finally, we design a residual cross-attention architecture,\ncoupled with a progressive learning strategy, to enable multimodal fusion of\nencoded electrochemical signals and semantic representations. Experiments\ndemonstrate that APG-MOS achieves superior performance on two primary\nbenchmarks. Our code and checkpoint will be available on a public repository\nupon publication.",
      "tldr_zh": "该论文提出了一种名为APG-MOS的语音质量评估模型，旨在更准确地预测合成语音的平均意见得分(MOS)。APG-MOS模型模仿人类听觉感知机制，通过听觉感知模块模拟耳蜗功能，将声学信号编码为生物电化学表示。同时，采用基于残差向量量化(RVQ)的语义失真建模方法，量化语义层面的语音质量退化。最后，利用残差交叉注意力架构和渐进学习策略，融合编码后的电化学信号和语义表示。实验结果表明，APG-MOS在两个基准测试中均表现出优越的性能，更贴合人类的主观评价。\n",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.20447v1",
      "published_date": "2025-04-29 05:45:09 UTC",
      "updated_date": "2025-04-29 05:45:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-01T02:37:08.390766"
    },
    {
      "arxiv_id": "2504.20445v1",
      "title": "Head-Tail-Aware KL Divergence in Knowledge Distillation for Spiking Neural Networks",
      "title_zh": "面向脉冲神经网络知识蒸馏的 Head-Tail-Aware KL 散度\n",
      "authors": [
        "Tianqing Zhang",
        "Zixin Zhu",
        "Kairong Yu",
        "Hongwei Wang"
      ],
      "abstract": "Spiking Neural Networks (SNNs) have emerged as a promising approach for\nenergy-efficient and biologically plausible computation. However, due to\nlimitations in existing training methods and inherent model constraints, SNNs\noften exhibit a performance gap when compared to Artificial Neural Networks\n(ANNs). Knowledge distillation (KD) has been explored as a technique to\ntransfer knowledge from ANN teacher models to SNN student models to mitigate\nthis gap. Traditional KD methods typically use Kullback-Leibler (KL) divergence\nto align output distributions. However, conventional KL-based approaches fail\nto fully exploit the unique characteristics of SNNs, as they tend to\noveremphasize high-probability predictions while neglecting low-probability\nones, leading to suboptimal generalization. To address this, we propose\nHead-Tail Aware Kullback-Leibler (HTA-KL) divergence, a novel KD method for\nSNNs. HTA-KL introduces a cumulative probability-based mask to dynamically\ndistinguish between high- and low-probability regions. It assigns adaptive\nweights to ensure balanced knowledge transfer, enhancing the overall\nperformance. By integrating forward KL (FKL) and reverse KL (RKL) divergence,\nour method effectively align both head and tail regions of the distribution. We\nevaluate our methods on CIFAR-10, CIFAR-100 and Tiny ImageNet datasets. Our\nmethod outperforms existing methods on most datasets with fewer timesteps.",
      "tldr_zh": "本文提出了一种名为Head-Tail Aware Kullback-Leibler (HTA-KL)散度的新型知识蒸馏(KD)方法，专门用于提升脉冲神经网络(SNNs)的性能。传统基于KL散度的KD方法在SNNs中表现不佳，因为它们过度强调高概率预测而忽略低概率预测。HTA-KL通过引入基于累积概率的掩码动态区分高低概率区域，并分配自适应权重以平衡知识转移。该方法结合了前向KL (FKL)和反向KL (RKL)散度，有效对齐分布的头部和尾部区域。在CIFAR-10、CIFAR-100和Tiny ImageNet数据集上的实验表明，HTA-KL在更少的时间步长下优于现有方法。\n",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted by IJCNN2025",
      "pdf_url": "http://arxiv.org/pdf/2504.20445v1",
      "published_date": "2025-04-29 05:36:32 UTC",
      "updated_date": "2025-04-29 05:36:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-01T02:37:20.378890"
    },
    {
      "arxiv_id": "2504.20444v1",
      "title": "On Psychology of AI -- Does Primacy Effect Affect ChatGPT and Other LLMs?",
      "title_zh": "关于人工智能心理学——首因效应会影响 ChatGPT 和其他大型语言模型吗？\n",
      "authors": [
        "Mika Hämäläinen"
      ],
      "abstract": "We study the primacy effect in three commercial LLMs: ChatGPT, Gemini and\nClaude. We do this by repurposing the famous experiment Asch (1946) conducted\nusing human subjects. The experiment is simple, given two candidates with equal\ndescriptions which one is preferred if one description has positive adjectives\nfirst before negative ones and another description has negative adjectives\nfollowed by positive ones. We test this in two experiments. In one experiment,\nLLMs are given both candidates simultaneously in the same prompt, and in\nanother experiment, LLMs are given both candidates separately. We test all the\nmodels with 200 candidate pairs. We found that, in the first experiment,\nChatGPT preferred the candidate with positive adjectives listed first, while\nGemini preferred both equally often. Claude refused to make a choice. In the\nsecond experiment, ChatGPT and Claude were most likely to rank both candidates\nequally. In the case where they did not give an equal rating, both showed a\nclear preference to a candidate that had negative adjectives listed first.\nGemini was most likely to prefer a candidate with negative adjectives listed\nfirst.",
      "tldr_zh": "该研究探讨了首因效应（Primacy Effect）是否会影响大型语言模型（LLMs），包括ChatGPT、Gemini和Claude。研究者通过改编Asch (1946) 的经典实验，测试LLMs在面对描述相同的两个候选人时，哪一个会因为正面形容词在前而被优先选择。实验分为两种设置：同时给出两个候选人描述和分别给出。结果表明，在同时给出的情况下，ChatGPT表现出首因效应，倾向于选择正面形容词在前的候选人，而Gemini则无明显偏好，Claude拒绝选择。在分别给出的情况下，ChatGPT和Claude更倾向于平等对待两个候选人，如果必须选择，则更偏好负面形容词在前的候选人。Gemini也更倾向于选择负面形容词在前的候选人。这项研究揭示了不同LLMs在面对信息呈现顺序时的不同偏好。\n",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.20444v1",
      "published_date": "2025-04-29 05:35:23 UTC",
      "updated_date": "2025-04-29 05:35:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-01T02:37:33.087665"
    },
    {
      "arxiv_id": "2504.20437v1",
      "title": "GaLore 2: Large-Scale LLM Pre-Training by Gradient Low-Rank Projection",
      "title_zh": "GaLore 2：通过梯度低秩投影进行大规模LLM预训练\n",
      "authors": [
        "DiJia Su",
        "Andrew Gu",
        "Jane Xu",
        "Yuandong Tian",
        "Jiawei Zhao"
      ],
      "abstract": "Large language models (LLMs) have revolutionized natural language\nunderstanding and generation but face significant memory bottlenecks during\ntraining. GaLore, Gradient Low-Rank Projection, addresses this issue by\nleveraging the inherent low-rank structure of weight gradients, enabling\nsubstantial memory savings without sacrificing performance. Recent works\nfurther extend GaLore from various aspects, including low-bit quantization and\nhigher-order tensor structures. However, there are several remaining challenges\nfor GaLore, such as the computational overhead of SVD for subspace updates and\nthe integration with state-of-the-art training parallelization strategies\n(e.g., FSDP). In this paper, we present GaLore 2, an efficient and scalable\nGaLore framework that addresses these challenges and incorporates recent\nadvancements. In addition, we demonstrate the scalability of GaLore 2 by\npre-training Llama 7B from scratch using up to 500 billion training tokens,\nhighlighting its potential impact on real LLM pre-training scenarios.",
      "tldr_zh": "该论文提出了GaLore 2，一个高效且可扩展的梯度低秩投影(GaLore)框架，用于大规模语言模型(LLM)的预训练。GaLore 2解决了GaLore在计算SVD进行子空间更新时的计算开销问题，并集成了最先进的训练并行化策略(如FSDP)。通过使用高达5000亿的训练tokens从头预训练Llama 7B，实验证明了GaLore 2的可扩展性及其在实际LLM预训练场景中的潜力。\n",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.20437v1",
      "published_date": "2025-04-29 05:27:02 UTC",
      "updated_date": "2025-04-29 05:27:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-01T02:37:44.072781"
    },
    {
      "arxiv_id": "2504.20434v1",
      "title": "ARCS: Agentic Retrieval-Augmented Code Synthesis with Iterative Refinement",
      "title_zh": "ARCS：基于迭代优化的 Agentic 检索增强代码合成\n",
      "authors": [
        "Manish Bhattarai",
        "Miguel Cordova",
        "Javier Santos",
        "Dan O'Malley"
      ],
      "abstract": "In supercomputing, efficient and optimized code generation is essential to\nleverage high-performance systems effectively. We propose Agentic\nRetrieval-Augmented Code Synthesis (ARCS), an advanced framework for accurate,\nrobust, and efficient code generation, completion, and translation. ARCS\nintegrates Retrieval-Augmented Generation (RAG) with Chain-of-Thought (CoT)\nreasoning to systematically break down and iteratively refine complex\nprogramming tasks. An agent-based RAG mechanism retrieves relevant code\nsnippets, while real-time execution feedback drives the synthesis of candidate\nsolutions. This process is formalized as a state-action search tree\noptimization, balancing code correctness with editing efficiency. Evaluations\non the Geeks4Geeks and HumanEval benchmarks demonstrate that ARCS significantly\noutperforms traditional prompting methods in translation and generation\nquality. By enabling scalable and precise code synthesis, ARCS offers\ntransformative potential for automating and optimizing code development in\nsupercomputing applications, enhancing computational resource utilization.",
      "tldr_zh": "该论文提出了Agentic Retrieval-Augmented Code Synthesis (ARCS)框架，用于高效、准确地生成、补全和翻译代码，尤其针对超级计算领域。ARCS结合了检索增强生成(RAG)和链式思考(CoT)推理，将复杂编程任务分解并迭代优化。该框架使用基于Agent的RAG机制检索相关代码片段，并利用实时执行反馈驱动候选解决方案的生成。整个过程被形式化为状态-动作搜索树优化，平衡了代码正确性和编辑效率。在Geeks4Geeks和HumanEval基准测试中，ARCS显著优于传统的prompting方法，提升了翻译和生成的质量，为超级计算应用中自动化和优化代码开发提供了潜力。\n",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.20434v1",
      "published_date": "2025-04-29 05:15:52 UTC",
      "updated_date": "2025-04-29 05:15:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-01T02:37:56.545445"
    },
    {
      "arxiv_id": "2504.20426v1",
      "title": "RV-Syn: Rational and Verifiable Mathematical Reasoning Data Synthesis based on Structured Function Library",
      "title_zh": "RV-Syn：基于结构化函数库的合理且可验证的数学推理数据合成\n",
      "authors": [
        "Jiapeng Wang",
        "Jinhao Jiang",
        "Zhiqiang Zhang",
        "Jun Zhou",
        "Wayne Xin Zhao"
      ],
      "abstract": "The advancement of reasoning capabilities in Large Language Models (LLMs)\nrequires substantial amounts of high-quality reasoning data, particularly in\nmathematics. Existing data synthesis methods, such as data augmentation from\nannotated training sets or direct question generation based on relevant\nknowledge points and documents, have expanded datasets but face challenges in\nmastering the inner logic of the problem during generation and ensuring the\nverifiability of the solutions. To address these issues, we propose RV-Syn, a\nnovel Rational and Verifiable mathematical Synthesis approach. RV-Syn\nconstructs a structured mathematical operation function library based on\ninitial seed problems and generates computational graphs as solutions by\ncombining Python-formatted functions from this library. These graphs are then\nback-translated into complex problems. Based on the constructed computation\ngraph, we achieve solution-guided logic-aware problem generation. Furthermore,\nthe executability of the computational graph ensures the verifiability of the\nsolving process. Experimental results show that RV-Syn surpasses existing\nsynthesis methods, including those involving human-generated problems,\nachieving greater efficient data scaling. This approach provides a scalable\nframework for generating high-quality reasoning datasets.",
      "tldr_zh": "该论文提出了RV-Syn，一种基于结构化数学运算函数库的理性且可验证的数学推理数据合成方法。RV-Syn通过结合Python格式的函数，构建计算图作为解决方案，并将其反向翻译成复杂问题，从而实现解引导的逻辑感知问题生成。计算图的可执行性保证了解决方案的可验证性。实验结果表明，RV-Syn超越了现有的合成方法，实现了更高效的数据扩展，为生成高质量的推理数据集提供了一个可扩展的框架。该方法旨在解决现有数据合成方法在掌握问题内在逻辑和确保解决方案可验证性方面的挑战。\n",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.20426v1",
      "published_date": "2025-04-29 04:42:02 UTC",
      "updated_date": "2025-04-29 04:42:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-01T02:38:08.320612"
    },
    {
      "arxiv_id": "2504.20412v1",
      "title": "CrashFixer: A crash resolution agent for the Linux kernel",
      "title_zh": "CrashFixer：Linux内核的崩溃修复代理",
      "authors": [
        "Alex Mathai",
        "Chenxi Huang",
        "Suwei Ma",
        "Jihwan Kim",
        "Hailie Mitchell",
        "Aleksandr Nogikh",
        "Petros Maniatis",
        "Franjo Ivančić",
        "Junfeng Yang",
        "Baishakhi Ray"
      ],
      "abstract": "Code large language models (LLMs) have shown impressive capabilities on a\nmultitude of software engineering tasks. In particular, they have demonstrated\nremarkable utility in the task of code repair. However, common benchmarks used\nto evaluate the performance of code LLMs are often limited to small-scale\nsettings. In this work, we build upon kGym, which shares a benchmark for\nsystem-level Linux kernel bugs and a platform to run experiments on the Linux\nkernel.\n  This paper introduces CrashFixer, the first LLM-based software repair agent\nthat is applicable to Linux kernel bugs. Inspired by the typical workflow of a\nkernel developer, we identify the key capabilities an expert developer\nleverages to resolve a kernel crash. Using this as our guide, we revisit the\nkGym platform and identify key system improvements needed to practically run\nLLM-based agents at the scale of the Linux kernel (50K files and 20M lines of\ncode). We implement these changes by extending kGym to create an improved\nplatform - called kGymSuite, which will be open-sourced. Finally, the paper\npresents an evaluation of various repair strategies for such complex kernel\nbugs and showcases the value of explicitly generating a hypothesis before\nattempting to fix bugs in complex systems such as the Linux kernel. We also\nevaluated CrashFixer's capabilities on still open bugs, and found at least two\npatch suggestions considered plausible to resolve the reported bug.",
      "tldr_zh": "本文介绍了CrashFixer，这是首个基于LLM的软件修复Agent，专门用于解决Linux内核中的错误。该Agent模拟内核开发人员的典型工作流程，识别关键能力，并基于此改进了kGym平台，创建了kGymSuite（将开源），以支持在Linux内核规模（50K文件和20M代码行）上运行LLM Agent。CrashFixer在复杂的内核错误修复策略上进行了评估，验证了在修复复杂系统（如Linux内核）中的错误之前，明确生成假设的重要性。对未解决的bug评估表明，CrashFixer至少提出了两个被认为可行的修复建议。\n",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.OS"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.20412v1",
      "published_date": "2025-04-29 04:18:51 UTC",
      "updated_date": "2025-04-29 04:18:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-01T02:38:20.401994"
    },
    {
      "arxiv_id": "2504.20408v1",
      "title": "FourierSpecNet: Neural Collision Operator Approximation Inspired by the Fourier Spectral Method for Solving the Boltzmann Equation",
      "title_zh": "FourierSpecNet：受傅里叶谱方法启发的神经碰撞算子近似，用于求解玻尔兹曼方程\n",
      "authors": [
        "Jae Yong Lee",
        "Gwang Jae Jung",
        "Byung Chan Lim",
        "Hyung Ju Hwang"
      ],
      "abstract": "The Boltzmann equation, a fundamental model in kinetic theory, describes the\nevolution of particle distribution functions through a nonlinear,\nhigh-dimensional collision operator. However, its numerical solution remains\ncomputationally demanding, particularly for inelastic collisions and\nhigh-dimensional velocity domains. In this work, we propose the Fourier Neural\nSpectral Network (FourierSpecNet), a hybrid framework that integrates the\nFourier spectral method with deep learning to approximate the collision\noperator in Fourier space efficiently. FourierSpecNet achieves\nresolution-invariant learning and supports zero-shot super-resolution, enabling\naccurate predictions at unseen resolutions without retraining. Beyond empirical\nvalidation, we establish a consistency result showing that the trained operator\nconverges to the spectral solution as the discretization is refined. We\nevaluate our method on several benchmark cases, including Maxwellian and\nhard-sphere molecular models, as well as inelastic collision scenarios. The\nresults demonstrate that FourierSpecNet offers competitive accuracy while\nsignificantly reducing computational cost compared to traditional spectral\nsolvers. Our approach provides a robust and scalable alternative for solving\nthe Boltzmann equation across both elastic and inelastic regimes.",
      "tldr_zh": "该论文提出了一种傅里叶神经谱网络(FourierSpecNet)，这是一种混合框架，它将傅里叶谱方法与深度学习相结合，以有效地逼近傅里叶空间中的Boltzmann方程的碰撞算子。FourierSpecNet实现了分辨率不变学习，并支持零样本超分辨率，从而能够在未见过的分辨率下进行准确预测，而无需重新训练。除了经验验证之外，论文还建立了一致性结果，表明随着离散化的改进，训练后的算子收敛到谱解。在包括Maxwellian和硬球分子模型以及非弹性碰撞场景在内的几个基准案例中评估了该方法。结果表明，与传统的谱求解器相比，FourierSpecNet在显着降低计算成本的同时，提供了具有竞争力的精度。该方法为解决弹性及非弹性状态下的Boltzmann方程提供了一种稳健且可扩展的替代方案。\n",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NA",
        "math.NA",
        "physics.comp-ph",
        "68T20, 35Q20, 35B40, 82C40"
      ],
      "primary_category": "cs.LG",
      "comment": "27 pages, 11 figures",
      "pdf_url": "http://arxiv.org/pdf/2504.20408v1",
      "published_date": "2025-04-29 04:07:03 UTC",
      "updated_date": "2025-04-29 04:07:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-01T02:38:38.987965"
    },
    {
      "arxiv_id": "2504.20406v1",
      "title": "Skill Discovery for Software Scripting Automation via Offline Simulations with LLMs",
      "title_zh": "利用LLM通过离线仿真进行软件脚本自动化技能发现\n",
      "authors": [
        "Paiheng Xu",
        "Gang Wu",
        "Xiang Chen",
        "Tong Yu",
        "Chang Xiao",
        "Franck Dernoncourt",
        "Tianyi Zhou",
        "Wei Ai",
        "Viswanathan Swaminathan"
      ],
      "abstract": "Scripting interfaces enable users to automate tasks and customize software\nworkflows, but creating scripts traditionally requires programming expertise\nand familiarity with specific APIs, posing barriers for many users. While Large\nLanguage Models (LLMs) can generate code from natural language queries, runtime\ncode generation is severely limited due to unverified code, security risks,\nlonger response times, and higher computational costs. To bridge the gap, we\npropose an offline simulation framework to curate a software-specific skillset,\na collection of verified scripts, by exploiting LLMs and publicly available\nscripting guides. Our framework comprises two components: (1) task creation,\nusing top-down functionality guidance and bottom-up API synergy exploration to\ngenerate helpful tasks; and (2) skill generation with trials, refining and\nvalidating scripts based on execution feedback. To efficiently navigate the\nextensive API landscape, we introduce a Graph Neural Network (GNN)-based link\nprediction model to capture API synergy, enabling the generation of skills\ninvolving underutilized APIs and expanding the skillset's diversity.\nExperiments with Adobe Illustrator demonstrate that our framework significantly\nimproves automation success rates, reduces response time, and saves runtime\ntoken costs compared to traditional runtime code generation. This is the first\nattempt to use software scripting interfaces as a testbed for LLM-based\nsystems, highlighting the advantages of leveraging execution feedback in a\ncontrolled environment and offering valuable insights into aligning AI\ncapabilities with user needs in specialized software domains.",
      "tldr_zh": "该论文提出了一种利用离线模拟和大型语言模型(LLMs)为软件脚本自动化发现技能的框架。该框架通过LLMs和公开的脚本指南，构建一个软件特定的、经过验证的脚本集合，称为skillset。框架包含任务创建和技能生成两个部分，前者利用自顶向下的功能指导和自底向上的API协同探索生成有用的任务，后者基于执行反馈提炼和验证脚本。为了高效地探索广泛的API，引入了基于图神经网络(GNN)的链接预测模型来捕捉API协同效应。在Adobe Illustrator上的实验表明，该框架显著提高了自动化成功率，减少了响应时间，并节省了运行时token成本。这项工作首次尝试使用软件脚本接口作为基于LLM的系统的试验平台，突出了在受控环境中利用执行反馈的优势。\n",
      "categories": [
        "cs.AI",
        "cs.SE"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.20406v1",
      "published_date": "2025-04-29 04:03:37 UTC",
      "updated_date": "2025-04-29 04:03:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-01T02:38:49.339779"
    },
    {
      "arxiv_id": "2504.20405v1",
      "title": "SCOPE-MRI: Bankart Lesion Detection as a Case Study in Data Curation and Deep Learning for Challenging Diagnoses",
      "title_zh": "SCOPE-MRI：Bankart损伤检测，作为数据管理和深度学习在挑战性诊断中的案例研究\n",
      "authors": [
        "Sahil Sethi",
        "Sai Reddy",
        "Mansi Sakarvadia",
        "Jordan Serotte",
        "Darlington Nwaudo",
        "Nicholas Maassen",
        "Lewis Shi"
      ],
      "abstract": "While deep learning has shown strong performance in musculoskeletal imaging,\nexisting work has largely focused on pathologies where diagnosis is not a\nclinical challenge, leaving more difficult problems underexplored, such as\ndetecting Bankart lesions (anterior-inferior glenoid labral tears) on standard\nMRIs. Diagnosing these lesions is challenging due to their subtle imaging\nfeatures, often leading to reliance on invasive MRI arthrograms (MRAs). This\nstudy introduces ScopeMRI, the first publicly available, expert-annotated\ndataset for shoulder pathologies, and presents a deep learning (DL) framework\nfor detecting Bankart lesions on both standard MRIs and MRAs. ScopeMRI includes\n586 shoulder MRIs (335 standard, 251 MRAs) from 558 patients who underwent\narthroscopy. Ground truth labels were derived from intraoperative findings, the\ngold standard for diagnosis. Separate DL models for MRAs and standard MRIs were\ntrained using a combination of CNNs and transformers. Predictions from\nsagittal, axial, and coronal views were ensembled to optimize performance. The\nmodels were evaluated on a 20% hold-out test set (117 MRIs: 46 MRAs, 71\nstandard MRIs). The models achieved an AUC of 0.91 and 0.93, sensitivity of 83%\nand 94%, and specificity of 91% and 86% for standard MRIs and MRAs,\nrespectively. Notably, model performance on non-invasive standard MRIs matched\nor surpassed radiologists interpreting MRAs. External validation demonstrated\ninitial generalizability across imaging protocols. This study demonstrates that\nDL models can achieve radiologist-level diagnostic performance on standard\nMRIs, reducing the need for invasive MRAs. By releasing ScopeMRI and a modular\ncodebase for training and evaluating deep learning models on 3D medical imaging\ndata, we aim to accelerate research in musculoskeletal imaging and support the\ndevelopment of new datasets for clinically challenging diagnostic tasks.",
      "tldr_zh": "该研究针对Bankart损伤（肩关节盂唇撕裂）这一临床诊断难题，提出了ScopeMRI数据集，这是首个公开的、专家标注的肩部病变数据集，包含586例肩部MRI（335例标准MRI，251例MRA）。研究人员利用CNN和Transformer组合构建深度学习(DL)框架，分别在标准MRI和MRA上训练Bankart损伤检测模型，并通过集成矢状、轴向和冠状视图的预测来优化性能。实验结果表明，模型在标准MRI上达到了0.91的AUC，83%的敏感性和91%的特异性，性能与放射科医生解读MRA的结果相当甚至更好，有望减少对侵入性MRA的需求。此外，研究还开源了ScopeMRI数据集和模块化代码库，旨在加速肌肉骨骼成像领域的研究。\n",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.20405v1",
      "published_date": "2025-04-29 04:02:44 UTC",
      "updated_date": "2025-04-29 04:02:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-01T02:38:58.802964"
    },
    {
      "arxiv_id": "2504.20368v1",
      "title": "AKIBoards: A Structure-Following Multiagent System for Predicting Acute Kidney Injury",
      "title_zh": "AKIBoards：一种用于预测急性肾损伤的结构跟随多智能体系统\n",
      "authors": [
        "David Gordon",
        "Panayiotis Petousis",
        "Susanne B. Nicholas",
        "Alex A. T. Bui"
      ],
      "abstract": "Diagnostic reasoning entails a physician's local (mental) model based on an\nassumed or known shared perspective (global model) to explain patient\nobservations with evidence assigned towards a clinical assessment. But in\nseveral (complex) medical situations, multiple experts work together as a team\nto optimize health evaluation and decision-making by leveraging different\nperspectives. Such consensus-driven reasoning reflects individual knowledge\ncontributing toward a broader perspective on the patient. In this light, we\nintroduce STRUCture-following for Multiagent Systems (STRUC-MAS), a framework\nautomating the learning of these global models and their incorporation as prior\nbeliefs for agents in multiagent systems (MAS) to follow. We demonstrate proof\nof concept with a prosocial MAS application for predicting acute kidney\ninjuries (AKIs). In this case, we found that incorporating a global structure\nenabled multiple agents to achieve better performance (average precision, AP)\nin predicting AKI 48 hours before onset (structure-following-fine-tuned, SF-FT,\nAP=0.195; SF-FT-retrieval-augmented generation, SF-FT-RAG, AP=0.194) vs.\nbaseline (non-structure-following-FT, NSF-FT, AP=0.141; NSF-FT-RAG, AP=0.180)\nfor balanced precision-weighted-recall-weighted voting. Markedly, SF-FT agents\nwith higher recall scores reported lower confidence levels in the initial round\non true positive and false negative cases. But after explicit interactions,\ntheir confidence in their decisions increased (suggesting reinforced belief).\nIn contrast, the SF-FT agent with the lowest recall decreased its confidence in\ntrue positive and false negative cases (suggesting a new belief). This approach\nsuggests that learning and leveraging global structures in MAS is necessary\nprior to achieving competitive classification and diagnostic reasoning\nperformance.",
      "tldr_zh": "该论文提出了STRUC-MAS框架，一种用于多智能体系统(MAS)的结构跟随方法，旨在模拟医生团队通过整合不同视角进行诊断推理的过程。该框架学习全局模型，并将其作为先验知识融入MAS中的智能体，用于预测急性肾损伤(AKI)。实验结果表明，在预测AKI发病前48小时，采用结构跟随微调(SF-FT)和结构跟随微调检索增强生成(SF-FT-RAG)的智能体比基线方法(NSF-FT和NSF-FT-RAG)在平均精度(AP)上表现更好。同时，该研究观察到智能体在交互后置信度的变化，表明学习和利用全局结构对于提升分类和诊断推理性能至关重要。该研究为构建协作式AI诊断系统提供了新的思路。\n",
      "categories": [
        "cs.MA",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.MA",
      "comment": "Accepted at International Conference on Autonomous Agents and\n  Multiagent Systems (AAMAS) Workshop, 2025",
      "pdf_url": "http://arxiv.org/pdf/2504.20368v1",
      "published_date": "2025-04-29 02:12:48 UTC",
      "updated_date": "2025-04-29 02:12:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-01T02:39:09.061210"
    },
    {
      "arxiv_id": "2504.20357v1",
      "title": "Automated Unit Test Case Generation: A Systematic Literature Review",
      "title_zh": "自动化单元测试用例生成：系统性文献综述\n",
      "authors": [
        "Jason Wang",
        "Basem Suleiman",
        "Muhammad Johan Alibasa"
      ],
      "abstract": "Software is omnipresent within all factors of society. It is thus important\nto ensure that software are well tested to mitigate bad user experiences as\nwell as the potential for severe financial and human losses. Software testing\nis however expensive and absorbs valuable time and resources. As a result, the\nfield of automated software testing has grown of interest to researchers in\npast decades. In our review of present and past research papers, we have\nidentified an information gap in the areas of improvement for the Genetic\nAlgorithm and Particle Swarm Optimisation. A gap in knowledge in the current\nchallenges that face automated testing has also been identified. We therefore\npresent this systematic literature review in an effort to consolidate existing\nknowledge in regards to the evolutionary approaches as well as their\nimprovements and resulting limitations. These improvements include hybrid\nalgorithm combinations as well as interoperability with mutation testing and\nneural networks. We will also explore the main test criterion that are used in\nthese algorithms alongside the challenges currently faced in the field related\nto readability, mocking and more.",
      "tldr_zh": "本文对自动化单元测试用例生成领域进行了系统性的文献综述，重点关注遗传算法(Genetic Algorithm)和粒子群优化(Particle Swarm Optimisation)等进化方法。研究发现，现有研究在这些算法的改进方向上存在信息缺口，并且对自动化测试当前面临的挑战缺乏足够的认识。该综述旨在整合现有知识，探讨进化方法的改进，包括混合算法组合、与变异测试(mutation testing)和神经网络的互操作性。此外，文章还探讨了算法中使用的主要测试标准，以及在可读性、模拟(mocking)等方面面临的挑战。\n",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.20357v1",
      "published_date": "2025-04-29 01:50:06 UTC",
      "updated_date": "2025-04-29 01:50:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-01T02:39:27.698288"
    },
    {
      "arxiv_id": "2504.20355v1",
      "title": "Local Prompt Optimization",
      "title_zh": "局部提示优化\n",
      "authors": [
        "Yash Jain",
        "Vishal Chowdhary"
      ],
      "abstract": "In recent years, the use of prompts to guide the output of Large Language\nModels have increased dramatically. However, even the best of experts struggle\nto choose the correct words to stitch up a prompt for the desired task. To\nsolve this, LLM driven prompt optimization emerged as an important problem.\nExisting prompt optimization methods optimize a prompt globally, where in all\nthe prompt tokens have to be optimized over a large vocabulary while solving a\ncomplex task. The large optimization space (tokens) leads to insufficient\nguidance for a better prompt. In this work, we introduce Local Prompt\nOptimization (LPO) that integrates with any general automatic prompt\nengineering method. We identify the optimization tokens in a prompt and nudge\nthe LLM to focus only on those tokens in its optimization step. We observe\nremarkable performance improvements on Math Reasoning (GSM8k and MultiArith)\nand BIG-bench Hard benchmarks across various automatic prompt engineering\nmethods. Further, we show that LPO converges to the optimal prompt faster than\nglobal methods.",
      "tldr_zh": "这篇论文提出了局部提示优化（Local Prompt Optimization，LPO）方法，旨在提升大型语言模型（LLM）的提示工程效果。与全局提示优化方法不同，LPO专注于识别并优化提示中的关键token，缩小了优化空间，从而为LLM提供更有效的指导。实验结果表明，LPO在数学推理（GSM8k和MultiArith）和BIG-bench Hard基准测试中，显著提高了各种自动提示工程方法的性能，并且比全局方法更快地收敛到最优提示。\n",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted as Oral at NAACL 2025 (Main Conference)",
      "pdf_url": "http://arxiv.org/pdf/2504.20355v1",
      "published_date": "2025-04-29 01:45:47 UTC",
      "updated_date": "2025-04-29 01:45:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-01T02:39:32.557787"
    },
    {
      "arxiv_id": "2504.20348v1",
      "title": "CarbonCall: Sustainability-Aware Function Calling for Large Language Models on Edge Devices",
      "title_zh": "CarbonCall：面向边缘设备上大型语言模型的可持续性感知函数调用\n",
      "authors": [
        "Varatheepan Paramanayakam",
        "Andreas Karatzas",
        "Iraklis Anagnostopoulos",
        "Dimitrios Stamoulis"
      ],
      "abstract": "Large Language Models (LLMs) enable real-time function calling in edge AI\nsystems but introduce significant computational overhead, leading to high power\nconsumption and carbon emissions. Existing methods optimize for performance\nwhile neglecting sustainability, making them inefficient for energy-constrained\nenvironments. We introduce CarbonCall, a sustainability-aware function-calling\nframework that integrates dynamic tool selection, carbon-aware execution, and\nquantized LLM adaptation. CarbonCall adjusts power thresholds based on\nreal-time carbon intensity forecasts and switches between model variants to\nsustain high tokens-per-second throughput under power constraints. Experiments\non an NVIDIA Jetson AGX Orin show that CarbonCall reduces carbon emissions by\nup to 52%, power consumption by 30%, and execution time by 30%, while\nmaintaining high efficiency.",
      "tldr_zh": "该论文提出了CarbonCall，一个面向边缘设备上LLM的可持续性函数调用框架。该框架通过整合动态工具选择、碳感知执行和量化LLM适配，旨在解决LLM在边缘AI系统中因计算开销带来的高功耗和碳排放问题。CarbonCall基于实时碳强度预测调整功率阈值，并在模型变体之间切换，以在功率约束下维持高tokens-per-second吞吐量。在NVIDIA Jetson AGX Orin上的实验表明，CarbonCall可以将碳排放量降低高达52%，功耗降低30%，执行时间降低30%，同时保持高效率。\n",
      "categories": [
        "cs.PF",
        "cs.AI",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.PF",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.20348v1",
      "published_date": "2025-04-29 01:37:08 UTC",
      "updated_date": "2025-04-29 01:37:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-01T02:39:44.514918"
    },
    {
      "arxiv_id": "2504.20342v1",
      "title": "Narrative-Centered Emotional Reflection: Scaffolding Autonomous Emotional Literacy with AI",
      "title_zh": "以叙事为中心的情感反思：利用 AI 搭建自主情感素养的桥梁\n",
      "authors": [
        "Shou-Tzu Han"
      ],
      "abstract": "Reflexion is an AI-powered platform designed to enable structured emotional\nself-reflection at scale. By integrating real-time emotion detection, layered\nreflective prompting, and metaphorical storytelling generation, Reflexion\nempowers users to engage in autonomous emotional exploration beyond basic\nsentiment categorization. Grounded in theories of expressive writing, cognitive\nrestructuring, self-determination, and critical consciousness development, the\nsystem scaffolds a progressive journey from surface-level emotional recognition\ntoward value-aligned action planning. Initial pilot studies with diverse\nparticipants demonstrate positive outcomes in emotional articulation, cognitive\nreframing, and perceived psychological resilience. Reflexion represents a\npromising direction for scalable, theory-informed affective computing\ninterventions aimed at fostering emotional literacy and psychological growth\nacross educational, therapeutic, and public health contexts.",
      "tldr_zh": "该论文介绍了一个名为Reflexion的AI平台，旨在通过叙事中心的情感反思来提升用户的情感素养。Reflexion集成了实时情感检测、分层反思提示和隐喻故事生成，引导用户进行自主的情感探索。该系统基于表达性写作、认知重构、自我决定和批判意识发展等理论，逐步引导用户从表层情感识别到价值对齐的行动计划。初步试验表明，Reflexion在情感表达、认知重构和心理韧性方面取得了积极成果，为在教育、治疗和公共卫生领域推广情感素养和心理成长提供了一个有前景的方向。\n",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CY",
        "H.5.2; H.1.2"
      ],
      "primary_category": "cs.HC",
      "comment": "10 pages, 5 figures, preliminary results, early-stage work intended\n  for future conference submission",
      "pdf_url": "http://arxiv.org/pdf/2504.20342v1",
      "published_date": "2025-04-29 01:24:46 UTC",
      "updated_date": "2025-04-29 01:24:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-01T02:39:56.773505"
    },
    {
      "arxiv_id": "2504.20340v1",
      "title": "A Picture is Worth a Thousand Prompts? Efficacy of Iterative Human-Driven Prompt Refinement in Image Regeneration Tasks",
      "title_zh": "一张图片胜过千言万语的提示？迭代式人工驱动提示改进在图像再生任务中的有效性\n",
      "authors": [
        "Khoi Trinh",
        "Scott Seidenberger",
        "Raveen Wijewickrama",
        "Murtuza Jadliwala",
        "Anindya Maiti"
      ],
      "abstract": "With AI-generated content becoming ubiquitous across the web, social media,\nand other digital platforms, it is vital to examine how such content are\ninspired and generated. The creation of AI-generated images often involves\nrefining the input prompt iteratively to achieve desired visual outcomes. This\nstudy focuses on the relatively underexplored concept of image regeneration\nusing AI, in which a human operator attempts to closely recreate a specific\ntarget image by iteratively refining their prompt. Image regeneration is\ndistinct from normal image generation, which lacks any predefined visual\nreference. A separate challenge lies in determining whether existing image\nsimilarity metrics (ISMs) can provide reliable, objective feedback in iterative\nworkflows, given that we do not fully understand if subjective human judgments\nof similarity align with these metrics. Consequently, we must first validate\ntheir alignment with human perception before assessing their potential as a\nfeedback mechanism in the iterative prompt refinement process. To address these\nresearch gaps, we present a structured user study evaluating how iterative\nprompt refinement affects the similarity of regenerated images relative to\ntheir targets, while also examining whether ISMs capture the same improvements\nperceived by human observers. Our findings suggest that incremental prompt\nadjustments substantially improve alignment, verified through both subjective\nevaluations and quantitative measures, underscoring the broader potential of\niterative workflows to enhance generative AI content creation across various\napplication domains.",
      "tldr_zh": "该研究探讨了在图像再生任务中，通过迭代式人工驱动的prompt优化来提高生成图像与目标图像相似度的有效性。研究重点关注图像再生，即通过不断优化prompt，使用AI尽可能逼真地重建特定目标图像。研究通过用户实验评估了迭代式prompt优化对再生图像相似度的影响，并检验了现有图像相似度指标(ISMs)是否能可靠地反映人类观察者感知到的改进。实验结果表明，迭代式的prompt调整显著提高了图像对齐度，无论是主观评估还是定量测量都证实了这一点，突出了迭代工作流程在增强生成式AI内容创建方面的潜力。\n",
      "categories": [
        "cs.AI",
        "cs.CV",
        "cs.HC"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.20340v1",
      "published_date": "2025-04-29 01:21:16 UTC",
      "updated_date": "2025-04-29 01:21:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-01T02:40:08.794097"
    },
    {
      "arxiv_id": "2504.20323v1",
      "title": "Labeling Case Similarity based on Co-Citation of Legal Articles in Judgment Documents with Empirical Dispute-Based Evaluation",
      "title_zh": "基于判决书中法律条文共引的案例相似性标注与基于经验争议的评估\n",
      "authors": [
        "Chao-Lin Liu",
        "Po-Hsien Wu",
        "Yi-Ting Yu"
      ],
      "abstract": "This report addresses the challenge of limited labeled datasets for\ndeveloping legal recommender systems, particularly in specialized domains like\nlabor disputes. We propose a new approach leveraging the co-citation of legal\narticles within cases to establish similarity and enable algorithmic\nannotation. This method draws a parallel to the concept of case co-citation,\nutilizing cited precedents as indicators of shared legal issues. To evaluate\nthe labeled results, we employ a system that recommends similar cases based on\nplaintiffs' accusations, defendants' rebuttals, and points of disputes. The\nevaluation demonstrates that the recommender, with finetuned text embedding\nmodels and a reasonable BiLSTM module can recommend labor cases whose\nsimilarity was measured by the co-citation of the legal articles. This research\ncontributes to the development of automated annotation techniques for legal\ndocuments, particularly in areas with limited access to comprehensive legal\ndatabases.",
      "tldr_zh": "该研究提出了一种新的方法，利用判决书中法律条款的共引关系来标注案例相似性，从而解决法律推荐系统，尤其是在劳动纠纷等专业领域中，标记数据集有限的问题。该方法借鉴了案例共引的概念，将引用的先例作为共同法律问题的指标。为了评估标注结果，研究采用了一个推荐系统，该系统基于原告的指控、被告的反驳和争议点推荐相似的案例。实验结果表明，通过微调文本嵌入模型和BiLSTM模块，该推荐系统能够推荐通过法律条款共引关系衡量的相似劳动案例。这项研究为法律文件的自动标注技术的发展做出了贡献，尤其是在难以获得全面法律数据库的领域。\n",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.DL",
        "cs.IR",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "16 pages, 9 figures, 2 tables, the Nineteenth International Workshop\n  on Juris-Informatics (JURISIN 2025), associated with the Seventeenth JSAI\n  International Symposium on AI (JSAI-isAI 2025)",
      "pdf_url": "http://arxiv.org/pdf/2504.20323v1",
      "published_date": "2025-04-29 00:26:37 UTC",
      "updated_date": "2025-04-29 00:26:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-01T02:40:20.774736"
    },
    {
      "arxiv_id": "2504.20318v1",
      "title": "Leveraging Action Relational Structures for Integrated Learning and Planning",
      "title_zh": "利用动作关系结构进行集成学习与规划\n",
      "authors": [
        "Ryan Xiao Wang",
        "Felipe Trevizan"
      ],
      "abstract": "Recent advances in planning have explored using learning methods to help\nplanning. However, little attention has been given to adapting search\nalgorithms to work better with learning systems. In this paper, we introduce\npartial-space search, a new search space for classical planning that leverages\nthe relational structure of actions given by PDDL action schemas -- a structure\noverlooked by traditional planning approaches. Partial-space search provides a\nmore granular view of the search space and allows earlier pruning of poor\nactions compared to state-space search. To guide partial-space search, we\nintroduce action set heuristics that evaluate sets of actions in a state. We\ndescribe how to automatically convert existing heuristics into action set\nheuristics. We also train action set heuristics from scratch using large\ntraining datasets from partial-space search. Our new planner, LazyLifted,\nexploits our better integrated search and learning heuristics and outperforms\nthe state-of-the-art ML-based heuristic on IPC 2023 learning track (LT)\nbenchmarks. We also show the efficiency of LazyLifted on high-branching factor\ntasks and show that it surpasses LAMA in the combined IPC 2023 LT and\nhigh-branching factor benchmarks.",
      "tldr_zh": "该论文提出了一种新的经典规划搜索空间——partial-space search，它利用了PDDL action schemas提供的动作关系结构。相较于传统的state-space search，partial-space search提供了更精细的搜索空间视图，并能更早地剪枝不良动作。为了指导partial-space search，论文引入了action set heuristics，用于评估状态中的动作集合。研究者展示了如何自动将现有启发式方法转换为action set heuristics，并使用来自partial-space search的大型训练数据集从头开始训练action set heuristics。提出的新规划器LazyLifted，通过集成的搜索和学习启发式方法，在IPC 2023 learning track (LT) benchmarks上优于最先进的基于ML的启发式方法，并在高分支因子任务中超越了LAMA。\n",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Extended version of ICAPS 2025 paper",
      "pdf_url": "http://arxiv.org/pdf/2504.20318v1",
      "published_date": "2025-04-29 00:10:14 UTC",
      "updated_date": "2025-04-29 00:10:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-01T02:40:33.834007"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 89,
  "processed_papers_count": 89,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-01T02:42:21.861195"
}