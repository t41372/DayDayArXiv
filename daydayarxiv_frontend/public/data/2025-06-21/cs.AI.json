{
  "date": "2025-06-21",
  "category": "cs.AI",
  "summary": "ä½ å¥½ï¼æ¬¢è¿æ¥åˆ° UTC æ—¶é—´ 2025-06-21 çš„ arXiv ä¸­æ–‡ TLDR å¿«æŠ¥ï¼\n\n**ğŸ“Š ä»Šæ—¥æ¦‚è§ˆ**\nä»Šå¤©çš„ arXiv åˆ—è¡¨éå¸¸ç¡¬æ ¸ï¼Œ**Agentic Reasoningï¼ˆä»£ç†æ¨ç†ï¼‰**ã€**Embodied AI (å…·èº«æ™ºèƒ½)** å’Œ **LLM ç†è®ºè§£é‡Š**æ˜¯ç»å¯¹çš„ä¸»è§’ã€‚\n- **ç†è®ºå±‚é¢**ï¼šæ–¯å¦ç¦å›¢é˜Ÿæå‡ºäº†ä¸€ä¸ªè´å¶æ–¯æ¡†æ¶ï¼Œè§£é‡Šäº† In-Context Learning ç­–ç•¥æ˜¯å¦‚ä½•â€œç†æ€§â€æ¶Œç°çš„ï¼Œéå¸¸æœ‰æ·±åº¦ã€‚\n- **æ¨¡å‹æ¶æ„**ï¼šå‡ºç°äº†å°†é¢„è®­ç»ƒ Transformer è½¬åŒ–ä¸º Linear Attention (Titans) çš„å·¥ä½œï¼Œä»¥åŠ DeepMind ç­‰æœºæ„å¯¹ VLA (è§†è§‰-è¯­è¨€-åŠ¨ä½œ) æ¨¡å‹åœ¨ Test-time Scaling ä¸Šçš„æ¢ç´¢ã€‚\n- **åº”ç”¨å±‚é¢**ï¼šNASA JPL å±•ç¤ºäº†åŸºäºæ‰©æ•£æ¨¡å‹çš„ç«æ˜Ÿæœºå™¨äººå¯¼èˆªæ–¹æ¡ˆï¼Œå¼ºè°ƒäº†â€œå¤±è´¥ä¸æ˜¯é€‰é¡¹â€çš„å®‰å…¨æ€§ã€‚\n\nè®©æˆ‘ä»¬å¼€å§‹ä»Šå¤©çš„æ·±åº¦é€Ÿè¯»ã€‚\n\n---\n\n### ğŸŒŸ å¿…è¯»ç²¾é€‰ï¼šç†è®ºçªç ´ä¸æ–°æ¶æ„\n\n**1. In-Context Learning Strategies Emerge Rationally**\n> **æ ¸å¿ƒè´¡çŒ®**ï¼šè¿™ç¯‡è®ºæ–‡è¯•å›¾ä»â€œç¬¬ä¸€æ€§åŸç†â€è§£é‡Š ICLã€‚ä½œè€…å¹¶æ²¡æœ‰æŠŠ ICL å½“ä½œé»‘ç›’ï¼Œè€Œæ˜¯è¯æ˜äº†å½“æ¨¡å‹åœ¨æ··åˆä»»åŠ¡ä¸Šè®­ç»ƒæ—¶ï¼ŒICL çš„ç­–ç•¥å¯ä»¥é€šè¿‡**è´å¶æ–¯é¢„æµ‹å™¨**å®¶æ—æ¥æ•æ‰ã€‚\n> **å‘ç°**ï¼šä»–ä»¬æå‡ºäº†ä¸€ä¸ªåˆ†å±‚è´å¶æ–¯æ¡†æ¶ï¼Œåœ¨ä¸è®¿é—®æƒé‡çš„æƒ…å†µä¸‹å°±èƒ½é¢„æµ‹ Transformer çš„ Next-token è¡Œä¸ºã€‚æœ€æœ‰è¶£çš„å‘ç°æ˜¯ï¼šéšç€ä»»åŠ¡å¤šæ ·æ€§çš„å¢åŠ ï¼Œæ¨¡å‹ä»â€œæ³›åŒ–â€è¿‡æ¸¡åˆ°â€œè®°å¿†â€çš„æ—¶é—´å°ºåº¦å‘ˆç°è¶…çº¿æ€§è¶‹åŠ¿ã€‚è¿™ä¸ºç†è§£å¤§æ¨¡å‹çš„å­¦ä¹ åŠ¨åŠ›å­¦æä¾›äº†éå¸¸è§„èŒƒçš„ç†è®ºè§†è§’ã€‚\n\n**28. KAG-Thinker: Interactive Thinking and Deep Reasoning in LLMs via Knowledge-Augmented Generation**\n> **æ ¸å¿ƒè´¡çŒ®**ï¼šè¿™æ˜¯å¯¹ KAGï¼ˆçŸ¥è¯†å¢å¼ºç”Ÿæˆï¼‰çš„å‡çº§ï¼Œå¼•å…¥äº†ç±»ä¼¼ o1 çš„**â€œäº¤äº’å¼æ€è€ƒâ€**æœºåˆ¶ã€‚\n> **å‘ç°**ï¼šæ¡†æ¶é€šè¿‡â€œå®½åº¦åˆ†è§£â€å°†å¤æ‚é—®é¢˜æ‹†è§£ä¸ºç‹¬ç«‹çš„é€»è¾‘å½¢å¼ï¼Œå¹¶åœ¨æ±‚è§£è¿‡ç¨‹ä¸­åŒºåˆ†â€œçŸ¥è¯†æ£€ç´¢â€å’Œâ€œæ¨ç†åˆ†æâ€ã€‚å®ƒè®© LLM å…·å¤‡äº†è‡ªæˆ‘è°ƒèŠ‚æœºåˆ¶ï¼ˆå¦‚ä¿¡å¿ƒæ ¡å‡†ï¼‰ï¼Œåœ¨ç‰¹å®šé¢†åŸŸçŸ¥è¯†åº“é—®ç­”ä¸­æå‡äº†é€»è¾‘è¿è´¯æ€§ã€‚\n\n**15. RoboMonkey: Scaling Test-Time Sampling and Verification for Vision-Language-Action Models**\n> **æ ¸å¿ƒè´¡çŒ®**ï¼šIon Stoica å¤§ä½¬å‚ä¸çš„å·¥ä½œã€‚é’ˆå¯¹ VLA (è§†è§‰-è¯­è¨€-åŠ¨ä½œ) æ¨¡å‹ï¼Œæå‡ºäº† **Test-time Scalingï¼ˆæµ‹è¯•æ—¶æ‰©å±•ï¼‰** çš„æ–¹æ¡ˆã€‚\n> **å‘ç°**ï¼šä½œè€…å‘ç° VLA çš„åŠ¨ä½œè¯¯å·®ä¸ç”Ÿæˆæ ·æœ¬æ•°é‡ä¹‹é—´å­˜åœ¨å¹‚å¾‹å…³ç³»ã€‚RoboMonkey é€šè¿‡é‡‡æ ·ä¸€ç»„åŠ¨ä½œï¼Œå¹¶åˆ©ç”¨ä¸€ä¸ª VLM éªŒè¯å™¨æ¥é€‰æ‹©æœ€ä½³åŠ¨ä½œï¼Œå®ç°äº†åœ¨ä¸é‡æ–°è®­ç»ƒ VLA çš„æƒ…å†µä¸‹ï¼ŒOOD ä»»åŠ¡æ€§èƒ½æå‡ 25%ã€‚è¿™æ˜¯ Robotics é¢†åŸŸçš„ Scaling Law å®è·µã€‚\n\n**39. TPTT: Transforming Pretrained Transformers into Titans**\n> **æ ¸å¿ƒè´¡çŒ®**ï¼šå¦‚ä½•è®©ç°æœ‰çš„ Transformer å¤„ç†è¶…é•¿ä¸Šä¸‹æ–‡ä¸”ä¸å¢åŠ æ¨ç†æˆæœ¬ï¼Ÿä½œè€…æå‡ºå°†é¢„è®­ç»ƒ Transformer è½¬åŒ–ä¸ºçº¿æ€§æ³¨æ„åŠ›æœºåˆ¶ï¼ˆLinear Attentionï¼‰å’Œè®°å¿†é—¨æ§ï¼ˆMemory as Gateï¼‰ã€‚\n> **å‘ç°**ï¼šä¸ä»…æ”¯æŒ LoRA å¾®è°ƒï¼Œè¿˜è¯æ˜äº†å¯ä»¥å°†äºŒæ¬¡å¤æ‚åº¦çš„æ³¨æ„åŠ›æ¨¡å‹è½¬åŒ–ä¸ºçº¯çº¿æ€§æ¨¡å‹ï¼Œåœ¨ 1B å‚æ•°è§„æ¨¡ä¸Šå±•ç¤ºäº†æ½œåŠ›ã€‚\n\n---\n\n### ğŸ¤– å…·èº«æ™ºèƒ½ä¸æœºå™¨äºº (Embodied AI & Robotics)\n\n**48. Risk-Guided Diffusion: Toward Deploying Robot Foundation Models in Space, Where Failure Is Not An Option**\n> **æ ¸å¿ƒè´¡çŒ®**ï¼šNASA JPL çš„å·¥ä½œã€‚é’ˆå¯¹ç«æ˜Ÿæ¢ç´¢è¿™ç§æåº¦é«˜å±åœºæ™¯ï¼Œæå‡ºäº†ä¸€ç§**é£é™©å¼•å¯¼çš„æ‰©æ•£æ¨¡å‹**ã€‚\n> **å‘ç°**ï¼šèåˆäº†â€œç³»ç»Ÿ1â€ï¼ˆå¿«é€Ÿå­¦ä¹ ç­–ç•¥ï¼‰å’Œâ€œç³»ç»Ÿ2â€ï¼ˆæ…¢é€Ÿç‰©ç†å®‰å…¨æ£€æŸ¥ï¼‰ã€‚åœ¨ NASA çš„ Mars Yard å®éªŒæ˜¾ç¤ºï¼Œæ•…éšœç‡é™ä½äº† 4 å€ï¼Œä¸”ä¸éœ€è¦é¢å¤–çš„è®­ç»ƒï¼Œä»…åˆ©ç”¨æ¨ç†æ—¶è®¡ç®—ã€‚\n\n**58. VLA-OS: Structuring and Dissecting Planning Representations and Paradigms in Vision-Language-Action Models**\n> **æ ¸å¿ƒè´¡çŒ®**ï¼šç³»ç»Ÿæ€§åœ°è§£æ„äº† VLA æ¨¡å‹ä¸­çš„è§„åˆ’èŒƒå¼ã€‚\n> **å‘ç°**ï¼šé€šè¿‡å¯¹æ¯”å®éªŒå‘ç°ï¼Œ**è§†è§‰ grounded çš„è§„åˆ’è¡¨ç¤º**é€šå¸¸ä¼˜äºçº¯è¯­è¨€è§„åˆ’ï¼›åˆ†å±‚ VLA (Hierarchical-VLA) èŒƒå¼åœ¨æ³›åŒ–æ€§å’ŒæŒç»­å­¦ä¹ ä¸Šè¡¨ç°æœ€å¥½ï¼Œä½†æ¨ç†é€Ÿåº¦è¾ƒæ…¢ã€‚\n\n**42. RLRC: Reinforcement Learning-based Recovery for Compressed Vision-Language-Action Models**\n> **æ ¸å¿ƒè´¡çŒ®**ï¼šVLA æ¨¡å‹å¤ªå¤§è·‘ä¸åŠ¨æ€ä¹ˆåŠï¼Ÿè¿™å°±æå‡ºäº†å‹ç¼©åçš„æ¢å¤æ–¹æ¡ˆã€‚\n> **å‘ç°**ï¼šç»“åˆç»“æ„åŒ–å‰ªæã€SFT+RL æ€§èƒ½æ¢å¤å’Œé‡åŒ–ï¼Œå®ç°äº† 8 å€æ˜¾å­˜å‡å°‘å’Œ 2.3 å€æ¨ç†åŠ é€Ÿï¼Œä¸”æˆåŠŸç‡ä¸é™åå‡ã€‚\n\n**7. Generative Grasp Detection and Estimation with Concept Learning-based Safety Criteria**\n> **æ ¸å¿ƒè´¡çŒ®**ï¼šå·¥ä¸šæœºå™¨äººæŠ“å–ã€‚é›†æˆå¯è§£é‡Š AI (XAI) æ¥æå–ç‰¹å¾ä½œä¸ºå®‰å…¨æ ‡å‡†ï¼Œæé«˜ Cobot æŠ“å–çš„é€æ˜åº¦å’Œå®‰å…¨æ€§ã€‚\n\n**12. Learning to Dock: A Simulation-based Study on Closing the Sim2Real Gap in Autonomous Underwater Docking**\n> **æ ¸å¿ƒè´¡çŒ®**ï¼šæ°´ä¸‹æœºå™¨äººè‡ªåŠ¨å¯¹æ¥ã€‚ç ”ç©¶äº†å¦‚ä½•é€šè¿‡éšæœºåŒ–æŠ€æœ¯å’Œå†å²æ¡ä»¶æ§åˆ¶å™¨æ¥ç¼©å° Sim2Real çš„å·®è·ã€‚\n\n**56. Accelerating Residual Reinforcement Learning with Uncertainty Estimation**\n> **æ ¸å¿ƒè´¡çŒ®**ï¼šåˆ©ç”¨åŸºç­–ç•¥çš„ä¸ç¡®å®šæ€§ä¼°è®¡æ¥åŠ é€Ÿæ®‹å·® RLï¼Œç‰¹åˆ«é€‚ç”¨äºéšæœºåŸºç­–ç•¥ï¼Œå®ç°äº†é›¶æ ·æœ¬ Sim-to-Real è¿ç§»ã€‚\n\n**37. Dynamic Exploration on Segment-Proposal Graphs for Tubular Centerline Tracking**\n> **æ ¸å¿ƒè´¡çŒ®**ï¼šä¸€ç§éæ·±åº¦å­¦ä¹ çš„åŠ¨æ€å›¾æ¢ç´¢æ–¹æ³•ï¼Œç”¨äºå¤æ‚çš„ç®¡çŠ¶ç»“æ„ï¼ˆå¦‚è¡€ç®¡ï¼‰ä¸­å¿ƒçº¿è¿½è¸ªï¼Œå¼ºè°ƒåŠ¨æ€æ„å»ºå›¾è€Œéé¢„è®¡ç®—ã€‚\n\n---\n\n### ğŸ§  LLM å¯¹é½ã€å®‰å…¨ä¸å¹»è§‰ (Alignment, Safety & Hallucination)\n\n**38. FaithfulSAE: Towards Capturing Faithful Features with Sparse Autoencoders without External Dataset Dependencies**\n> **æ ¸å¿ƒè´¡çŒ®**ï¼šSparse Autoencoder (SAE) æ˜¯ç›®å‰å¯è§£é‡Šæ€§çš„çƒ­é—¨æ–¹å‘ã€‚ä½†è¿™ç¯‡è®ºæ–‡æŒ‡å‡ºï¼Œç”¨å¤–éƒ¨æ•°æ®è®­ç»ƒ SAE ä¼šå¯¼è‡´â€œè™šå‡ç‰¹å¾â€ã€‚\n> **å‘ç°**ï¼šæå‡ºç”¨æ¨¡å‹è‡ªå·±ç”Ÿæˆçš„åˆæˆæ•°æ®æ¥è®­ç»ƒ SAEï¼Œæ¶ˆé™¤äº†å¯¹å¤–éƒ¨æ•°æ®çš„ä¾èµ–ï¼Œç‰¹å¾æ›´å¿ å®äºæ¨¡å‹å†…éƒ¨æ¿€æ´»ã€‚\n\n**5. Out of Control -- Why Alignment Needs Formal Control Theory (and an Alignment Control Stack)**\n> **æ ¸å¿ƒè´¡çŒ®**ï¼šè§‚ç‚¹æ–‡ç« ã€‚å‘¼åå°†**å½¢å¼åŒ–æœ€ä¼˜æ§åˆ¶ç†è®º**å¼•å…¥ AI å¯¹é½ï¼Œæå‡ºäº†ä¸€ä¸ªä»ç‰©ç†å±‚åˆ°ç¤¾ä¼šæŠ€æœ¯å±‚çš„â€œå¯¹é½æ§åˆ¶æ ˆâ€ã€‚\n\n**53. Cite Pretrain: Retrieval-Free Knowledge Attribution for Large Language Models**\n> **æ ¸å¿ƒè´¡çŒ®**ï¼šè®© LLM åœ¨**ä¸æ£€ç´¢**å¤–éƒ¨æ–‡æ¡£çš„æƒ…å†µä¸‹ï¼Œå¼•ç”¨é¢„è®­ç»ƒä¸­å­¦åˆ°çš„æ–‡æ¡£ã€‚\n> **å‘ç°**ï¼šé€šè¿‡â€œä¸»åŠ¨ç´¢å¼•â€ï¼ˆActive Indexingï¼‰ç»§ç»­é¢„è®­ç»ƒï¼Œè®©æ¨¡å‹å°†çŸ¥è¯†ç»‘å®šåˆ°æ–‡æ¡£ ID ä¸Šï¼Œå¼•ç”¨ç²¾åº¦æå‡äº† 30%ã€‚è¿™æ˜¯ä¸€ç§å¯¹æŠ—å¹»è§‰çš„æ–°æ€è·¯ã€‚\n\n**26. HIDE and Seek: Detecting Hallucinations in Language Models via Decoupled Representations**\n> **æ ¸å¿ƒè´¡çŒ®**ï¼šä¸€ç§å•æ¬¡å‰å‘ä¼ æ’­çš„å¹»è§‰æ£€æµ‹æ–¹æ³•ã€‚\n> **å‘ç°**ï¼šåŸºäºå‡è®¾â€”â€”å¹»è§‰æºäºè¾“å…¥ä¸Šä¸‹æ–‡è¡¨ç¤ºä¸ç”Ÿæˆè¾“å‡ºè¡¨ç¤ºä¹‹é—´çš„ç»Ÿè®¡è§£è€¦ã€‚åˆ©ç”¨ HSIC è¡¡é‡è¿™ç§è§£è€¦ï¼Œæ•ˆæœä¼˜äºå¤šè½®é‡‡æ ·æ–¹æ³•ã€‚\n\n**52. HalluRNN: Mitigating Hallucinations via Recurrent Cross-Layer Reasoning in Large Vision-Language Models**\n> **æ ¸å¿ƒè´¡çŒ®**ï¼šåœ¨ LVLM ä¸­å¼•å…¥å¾ªç¯è·¨å±‚æ¨ç†æ¨¡å—ï¼ˆDG-DPUï¼‰ï¼Œé€šè¿‡ç»†åŒ–éšè—çŠ¶æ€æ¥å‡å°‘è§†è§‰å¹»è§‰ã€‚\n\n**27. Safe Pruning LoRA: Robust Distance-Guided Pruning for Safety Alignment in Adaptation of LLMs**\n> **æ ¸å¿ƒè´¡çŒ®**ï¼šå¾®è°ƒä¼šç ´åå®‰å…¨å¯¹é½ã€‚SPLoRA é€šè¿‡å‰ªææ‰é‚£äº›å‰Šå¼±å®‰å…¨æ€§çš„ LoRA å±‚æ¥ä¿æŒå®‰å…¨æ€§ï¼ŒåŒæ—¶ä¿ç•™æ€§èƒ½ã€‚\n\n**10. Aligning Frozen LLMs by Reinforcement Learning: An Iterative Reweight-then-Optimize Approach**\n> **æ ¸å¿ƒè´¡çŒ®**ï¼šä¸åŠ¨æ¨¡å‹å‚æ•°ï¼ˆFrozenï¼‰æ€ä¹ˆåš RL å¯¹é½ï¼Ÿæå‡º Iterative Reweight-then-Optimize (IRO)ï¼Œé€šè¿‡è®­ç»ƒè½»é‡çº§ä»·å€¼å‡½æ•°æ¥æŒ‡å¯¼è§£ç ã€‚\n\n**19. AI Safety vs. AI Security: Demystifying the Distinction and Boundaries**\n> **æ ¸å¿ƒè´¡çŒ®**ï¼šå˜æ¸…äº† AI Safetyï¼ˆå®‰å…¨ï¼‰å’Œ AI Securityï¼ˆå®‰é˜²ï¼‰çš„æ¦‚å¿µè¾¹ç•Œï¼Œè¿™æ˜¯ä¸€ä¸ªå¸¸è¢«æ··æ·†çš„é¢†åŸŸã€‚\n\n---\n\n### ğŸ•µï¸ ä»£ç†ã€å¤šæ™ºèƒ½ä½“ä¸åŸºå‡†æµ‹è¯• (Agents & Benchmarks)\n\n**18. Bayesian Social Deduction with Graph-Informed Language Models**\n> **æ ¸å¿ƒè´¡çŒ®**ï¼šè®© LLM ç©â€œé˜¿ç“¦éš†â€æ¸¸æˆã€‚\n> **å‘ç°**ï¼šä¸ä»…æ˜¯ç©ï¼Œè¿˜æ˜¯ç¬¬ä¸€ä¸ªåœ¨å—æ§ç ”ç©¶ä¸­**å‡»è´¥äººç±»ç©å®¶**çš„è¯­è¨€ä»£ç†ï¼ˆèƒœç‡ 67%ï¼‰ã€‚æ–¹æ³•æ˜¯å°†ä¿¡å¿µæ¨ç†å¤–åŒ…ç»™ç»“æ„åŒ–æ¦‚ç‡æ¨¡å‹ï¼ŒLLM è´Ÿè´£è¯­è¨€äº¤äº’ã€‚\n\n**40. PhysUniBench: An Undergraduate-Level Physics Reasoning Benchmark for Multimodal Models**\n> **æ ¸å¿ƒè´¡çŒ®**ï¼šå‘å¸ƒäº†ä¸€ä¸ªæœ¬ç§‘ç‰©ç†æ°´å¹³çš„å¤šæ¨¡æ€æ¨ç†åŸºå‡†ã€‚\n> **å‘ç°**ï¼šGPT-4o mini åªæœ‰ 34.2% çš„å‡†ç¡®ç‡ã€‚ç‰©ç†æ¨ç†ä»ç„¶æ˜¯ MLLM çš„è½¯è‚‹ã€‚\n\n**59. Towards Zero-Shot Coordination between Teams of Agents: The N-XPlay Framework**\n> **æ ¸å¿ƒè´¡çŒ®**ï¼šä¸ä»…æ˜¯ä¸¤ä¸ªä»£ç†åä½œï¼Œè€Œæ˜¯å¤šå›¢é˜Ÿç³»ç»Ÿï¼ˆMTSï¼‰çš„é›¶æ ·æœ¬åä½œã€‚æå‡ºäº† N-Player Overcooked ç¯å¢ƒã€‚\n\n**22. Toward Autonomous UI Exploration: The UIExplorer Benchmark**\n> **æ ¸å¿ƒè´¡çŒ®**ï¼šè¯„ä¼° Agent è‡ªä¸»æ¢ç´¢ UI çš„èƒ½åŠ›ã€‚ç›®å‰çš„ Agent è·ç¦»äººç±»ä¸“å®¶çš„ä¸€å°æ—¶æ¢ç´¢é‡è¿˜æœ‰å¾ˆå¤§å·®è·ã€‚\n\n**20. AnyMAC: Cascading Flexible Multi-Agent Collaboration via Next-Agent Prediction**\n> **æ ¸å¿ƒè´¡çŒ®**ï¼šæ‰“ç ´é™æ€å›¾ç»“æ„ï¼Œé€šè¿‡â€œé¢„æµ‹ä¸‹ä¸€ä¸ª Agentâ€å’Œâ€œé€‰æ‹©ä¸‹ä¸€ä¸ªä¸Šä¸‹æ–‡â€æ¥æ„å»ºåŠ¨æ€çš„å¤šæ™ºèƒ½ä½“é€šä¿¡ç®¡é“ã€‚\n\n**24. CARTS: Collaborative Agents for Recommendation Textual Summarization**\n> **æ ¸å¿ƒè´¡çŒ®**ï¼šåœ¨æ¨èç³»ç»Ÿä¸­ç”¨å¤šæ™ºèƒ½ä½“ç”Ÿæˆå•†å“æ‘˜è¦æ ‡é¢˜ï¼ŒåŒ…å«ç”Ÿæˆã€æ¶¦è‰²å’Œä»²è£ä¸‰ä¸ªè§’è‰²ã€‚\n\n**34. Beyond Syntax: Action Semantics Learning for App Agents**\n> **æ ¸å¿ƒè´¡çŒ®**ï¼šApp Agent çš„è®­ç»ƒé€šå¸¸æ­»è®°ç¡¬èƒŒåŠ¨ä½œå­—ç¬¦ä¸²ã€‚æœ¬æ–‡æå‡º**åŠ¨ä½œè¯­ä¹‰å­¦ä¹ **ï¼Œè®© Agent ç†è§£åŠ¨ä½œèƒŒåçš„çŠ¶æ€è½¬ç§»ï¼Œæé«˜ OOD é²æ£’æ€§ã€‚\n\n**41. Measuring and Augmenting Large Language Models for Solving Capture-the-Flag Challenges**\n> **æ ¸å¿ƒè´¡çŒ®**ï¼šè¯„ä¼° LLM æ‰“ CTFï¼ˆå¤ºæ——èµ›ï¼‰çš„èƒ½åŠ›ã€‚å‘ç° LLM æœ‰çŸ¥è¯†ä½†ä¸ä¼šç”¨ï¼Œæå‡ºäº† CTFAgent æ¡†æ¶ï¼Œåœ¨ picoCTF2024 ä¸­æ’åå‰ 23.6%ã€‚\n\n**49. Do LLMs Know When to Flip a Coin? Strategic Randomization through Reasoning and Experience**\n> **æ ¸å¿ƒè´¡çŒ®**ï¼šç”¨åšå¼ˆè®ºï¼ˆç”°å¿Œèµ›é©¬å˜ä½“ï¼‰æµ‹è¯• LLM æ˜¯å¦æ‡‚å¾—â€œæˆ˜ç•¥æ€§éšæœºåŒ–â€ã€‚å¼±æ¨¡å‹åªä¼šç¡®å®šæ€§è¡ŒåŠ¨ï¼Œå¼ºæ¨¡å‹åœ¨æç¤ºä¸‹èƒ½å­¦ä¼šæ··åˆç­–ç•¥ã€‚\n\n**60. SynDaCaTE: A Synthetic Dataset For Evaluating Part-Whole Hierarchical Inference**\n> **æ ¸å¿ƒè´¡çŒ®**ï¼šç”¨äºè¯„ä¼°èƒ¶å›Šç½‘ç»œï¼ˆCapsule Networksï¼‰å’Œéƒ¨åˆ†-æ•´ä½“å±‚çº§æ¨æ–­çš„åˆæˆæ•°æ®é›†ã€‚\n\n---\n\n### ğŸ”¬ ç§‘å­¦ AI ä¸ç‰¹å®šé¢†åŸŸåº”ç”¨ (AI for Science & Domain Specific)\n\n**29. Clarifying the Ti-V Phase Diagram Using First-Principles Calculations and Bayesian Learning**\n> **æ ¸å¿ƒè´¡çŒ®**ï¼šææ–™ç§‘å­¦ã€‚ç»“åˆç¬¬ä¸€æ€§åŸç†å’Œè´å¶æ–¯å­¦ä¹ ï¼Œæ¾„æ¸…äº†é’›-é’’åˆé‡‘çš„ç›¸å›¾äº‰è®®ï¼Œå¦è®¤äº†æ°§æ±¡æŸ“å¯¼è‡´ miscibility gap çš„å‡è®¾ã€‚\n\n**6. THCM-CAL: Temporal-Hierarchical Causal Modelling with Conformal Calibration for Clinical Risk Prediction**\n> **æ ¸å¿ƒè´¡çŒ®**ï¼šåŒ»ç–— AIã€‚æ„å»ºå¤šæ¨¡æ€å› æœå›¾ï¼ˆEHR ç¬”è®° + ICD ä»£ç ï¼‰ï¼Œå¹¶ç»“åˆ Conformal Predictionï¼ˆå…±å½¢é¢„æµ‹ï¼‰æ¥æ ¡å‡†é£é™©åŒºé—´ã€‚\n\n**25. Residual Connection-Enhanced ConvLSTM for Lithium Dendrite Growth Prediction**\n> **æ ¸å¿ƒè´¡çŒ®**ï¼šç”µæ± ç ”ç©¶ã€‚é¢„æµ‹é”‚ææ™¶ç”Ÿé•¿ï¼Œå¯¹ç”µæ± å®‰å…¨è‡³å…³é‡è¦ã€‚\n\n**63. Exploring Strategies for Personalized Radiation Therapy Part I...**\n> **æ ¸å¿ƒè´¡çŒ®**ï¼šåŒ»å­¦å½±åƒã€‚ä½¿ç”¨ç±»æ¿€æ´»æ˜ å°„ (CAM) é¢„æµ‹æ”¾ç–—ååº”ï¼Œæ¯”ä¼ ç»Ÿå½±åƒç»„å­¦æ›´å‡†ã€‚\n\n**13. CultureMERT: Continual Pre-Training for Cross-Cultural Music Representation Learning**\n> **æ ¸å¿ƒè´¡çŒ®**ï¼šéŸ³ä¹ AIã€‚é’ˆå¯¹éè¥¿æ–¹éŸ³ä¹ï¼ˆå¸Œè…Šã€åœŸè€³å…¶ã€å°åº¦ï¼‰ä¼˜åŒ–çš„éŸ³ä¹åŸºç¡€æ¨¡å‹ã€‚\n\n**21. Expanding Relevance Judgments for Medical Case-based Retrieval Task with Multimodal LLMs**\n> **æ ¸å¿ƒè´¡çŒ®**ï¼šç”¨ Gemini 1.5 Pro æ¥æ›¿ä»£äººå·¥è¿›è¡ŒåŒ»ç–—æ£€ç´¢çš„ç›¸å…³æ€§åˆ¤æ–­ï¼Œç”± 1.5ä¸‡ æ¡æ‰©å……åˆ° 55ä¸‡ æ¡æ•°æ®ã€‚\n\n**54. Context-Aware Scientific Knowledge Extraction on Linked Open Data using Large Language Models**\n> **æ ¸å¿ƒè´¡çŒ®**ï¼šæå‡ºäº† WISE ç³»ç»Ÿï¼Œç”¨äºä»ç§‘å­¦æ–‡çŒ®å’Œå¼€æ”¾æ•°æ®ä¸­æå–çŸ¥è¯†ï¼Œè§£å†³ LLM å›ç­”ç¼ºä¹æ·±åº¦çš„é—®é¢˜ã€‚\n\n---\n\n### âš™ï¸ ç³»ç»Ÿä¼˜åŒ–ä¸æ¨èç³»ç»Ÿ (Systems & RecSys)\n\n**61. Research on Model Parallelism and Data Parallelism Optimization Methods...**\n> **æ ¸å¿ƒè´¡çŒ®**ï¼šLLM æ¨èç³»ç»Ÿçš„åˆ†å¸ƒå¼è®­ç»ƒä¼˜åŒ–ï¼Œæ··åˆå¹¶è¡Œç­–ç•¥æå‡äº† 30% ååé‡ã€‚\n\n**57. Research on Low-Latency Inference and Training Efficiency Optimization...**\n> **æ ¸å¿ƒè´¡çŒ®**ï¼šGNN+LLM æ¨èç³»ç»Ÿçš„ä½å»¶è¿Ÿæ¨ç†ä¼˜åŒ–ï¼Œç»“åˆ FPGA å’Œ LoRAã€‚\n\n**3. Pathway-based Progressive Inference (PaPI) for Energy-Efficient Continual Learning**\n> **æ ¸å¿ƒè´¡çŒ®**ï¼šè§£å†³æŒç»­å­¦ä¹ ä¸­çš„ç¾éš¾æ€§é—å¿˜å’Œèƒ½è€—é—®é¢˜ã€‚PaPI çš„èƒ½è€—åªä¸æ´»è·ƒå‚æ•°é‡æœ‰å…³ï¼Œè€Œéæ€»æ¨¡å‹å¤§å°ã€‚\n\n**62. ConsumerBench: Benchmarking Generative AI Applications on End-User Devices**\n> **æ ¸å¿ƒè´¡çŒ®**ï¼šé’ˆå¯¹ç»ˆç«¯è®¾å¤‡ï¼ˆå¦‚ç¬”è®°æœ¬ã€æ‰‹æœºï¼‰çš„ GenAI è·‘åˆ†åŸºå‡†ï¼Œå…³æ³¨å¤šåº”ç”¨å¹¶å‘ä¸‹çš„èµ„æºäº‰æŠ¢ã€‚\n\n**17. Efficient Strategy Synthesis for MDPs via Hierarchical Block Decomposition**\n> **æ ¸å¿ƒè´¡çŒ®**ï¼šè§£å†³å¤§è§„æ¨¡ MDPï¼ˆé©¬å°”å¯å¤«å†³ç­–è¿‡ç¨‹ï¼‰ç­–ç•¥åˆæˆçš„æ‰©å±•æ€§é—®é¢˜ã€‚\n\n---\n\n### ğŸ“ å…¶ä»–ç®€è®¯ (Other Updates)\n\n*   **#2 Systemic Constraints of Undecidability**: ç†è®ºæ–‡ç« ï¼Œæå‡ºâ€œç³»ç»Ÿä¸å¯åˆ¤å®šæ€§â€ï¼Œè®¤ä¸ºè®¡ç®—é™åˆ¶æ˜¯ç³»ç»Ÿçš„ç»“æ„å±æ€§ã€‚\n*   **#4 A Comparative Study of Open-Source Libraries for Synthetic Tabular Data Generation**: å¯¹æ¯”äº† SDV å’Œ SynthCity ä¸¤ä¸ªåº“ç”Ÿæˆè¡¨æ ¼æ•°æ®çš„èƒ½åŠ›ã€‚\n*   **#9 Reflective Verbal Reward Design for Pluralistic Alignment**: ä¸ªæ€§åŒ–å¯¹é½ï¼Œé€šè¿‡å¯¹è¯è®©ç”¨æˆ·åæ€å¹¶æ„å»ºè‡ªå·±çš„å¥–åŠ±æ¨¡å‹ã€‚\n*   **#11 Actionable Interpretability via Causal Hypergraphs**: ç”¨å› æœè¶…å›¾åˆ†æ Batch Size å¯¹æ·±åº¦å­¦ä¹ æ³›åŒ–çš„å½±å“ã€‚\n*   **#14 Secure Energy Transactions Using Blockchain Leveraging AI**: AI + åŒºå—é“¾ç”¨äºç¾å›½èƒ½æºå¸‚åœºäº¤æ˜“ã€‚\n*   **#16 Reimagining Parameter Space Exploration with Diffusion Models**: ç”¨æ‰©æ•£æ¨¡å‹ç›´æ¥ç”Ÿæˆä»»åŠ¡ç‰¹å®šçš„ç¥ç»ç½‘ç»œå‚æ•°ã€‚\n*   **#23 Machine Learning Model Integration with Open World Temporal Logic**: å°† ML è¾“å‡ºé›†æˆåˆ° PyReason é€»è¾‘æ¨ç†å¼•æ“ä¸­ã€‚\n*   **#30 Aged to Perfection**: åˆ†æè‹±è¯­å£è¯­ä¸­ä¸åŒå¹´é¾„æ®µçš„è¯­è¨€æ¨¡å¼å·®å¼‚ã€‚\n*   **#31 LastingBench**: é€šè¿‡æ”¹å†™æ³„éœ²ç‚¹æ¥é˜²å¾¡ Benchmark æ•°æ®æ³„éœ²ã€‚\n*   **#32 Programmable-Room**: åŸºäº LLM å’Œè§†è§‰ç¼–ç¨‹ç”Ÿæˆ 3D æˆ¿é—´ç½‘æ ¼ã€‚\n*   **#33 The Evolution of NLP**: å…³äº Prompt ä¼˜åŒ–ç­–ç•¥çš„ç»¼è¿°ã€‚\n*   **#35 Reinforcing User Interest Evolution in Multi-Scenario Learning**: æ¨èç³»ç»Ÿä¸­è·¨åœºæ™¯çš„ç”¨æˆ·å…´è¶£æ¼”åŒ–å»ºæ¨¡ã€‚\n*   **#36 Enhancing Stress-Strain Predictions**: ç”¨ Seq2Seq é¢„æµ‹é«˜å¼ºåº¦é’¢çš„åº”åŠ›-åº”å˜æ›²çº¿ã€‚\n*   **#43 Adaptive Multi-prompt Contrastive Network**: å°‘æ ·æœ¬ OOD æ£€æµ‹ã€‚\n*   **#44 Time-Prompt**: æ¿€æ´» LLM è¿›è¡Œæ—¶é—´åºåˆ—é¢„æµ‹çš„æ¡†æ¶ã€‚\n*   **#45 CLiViS**: ç»“åˆ LLM æ¨ç†å’Œ VLM æ„ŸçŸ¥çš„å…·èº«è§†è§‰æ¨ç†æ¡†æ¶ã€‚\n*   **#46 AdaptGOT**: POIï¼ˆå…´è¶£ç‚¹ï¼‰è‡ªé€‚åº”ä¸Šä¸‹æ–‡è¡¨ç¤ºå­¦ä¹ ã€‚\n*   **#47 Exploiting Efficiency Vulnerabilities in Dynamic Deep Learning Systems**: æ”»å‡»åŠ¨æ€æ·±åº¦å­¦ä¹ ç³»ç»Ÿçš„æ•ˆç‡æ¼æ´ã€‚\n*   **#50 DRAMA-X**: é©¾é©¶åœºæ™¯ä¸­ç»†ç²’åº¦æ„å›¾é¢„æµ‹å’Œé£é™©æ¨ç†åŸºå‡†ã€‚\n*   **#51 Taming the Untamed**: åŸºäºã€Šæ€ªç‰©çŒäººï¼šä¸–ç•Œã€‹æ„å»ºå¤šæ¨¡æ€çŸ¥è¯†å›¾è°±ï¼Œæµ‹è¯• MLLM çš„æ£€ç´¢æ¨ç†ã€‚\n*   **#55 Optimizing Mastery Learning by Fast-Forwarding Over-Practice Steps**: é€šè¿‡å¿«è¿›å·²æŒæ¡æ­¥éª¤æ¥ä¼˜åŒ–å­¦ä¹ ç³»ç»Ÿã€‚\n*   **#60 SynDaCaTE**: åˆæˆæ•°æ®é›†ï¼Œè¯„ä¼°éƒ¨åˆ†-æ•´ä½“å±‚çº§æ¨ç†ã€‚\n*   **#64 Data Quality Issues in Multilingual Speech Datasets**: æŒ‡å‡ºå¤šè¯­è¨€è¯­éŸ³æ•°æ®é›†ï¼ˆå¦‚ Common Voiceï¼‰ä¸­çš„è´¨é‡é—®é¢˜ï¼Œç‰¹åˆ«æ˜¯é—½å—è¯­ã€‚\n\nä»¥ä¸Šå°±æ˜¯ä»Šå¤©çš„ arXiv å¿«æŠ¥ï¼Œå¸Œæœ›å…¶ä¸­æœ‰èƒ½æ¿€å‘ä½ çµæ„Ÿçš„ç ”ç©¶ï¼æˆ‘ä»¬æ˜å¤©è§ã€‚",
  "papers": [
    {
      "arxiv_id": "2506.17859v2",
      "title": "In-Context Learning Strategies Emerge Rationally",
      "title_zh": "ä¸Šä¸‹æ–‡å­¦ä¹ ç­–ç•¥çš„ç†æ€§æ¶Œç°",
      "authors": [
        "Daniel Wurgaft",
        "Ekdeep Singh Lubana",
        "Core Francisco Park",
        "Hidenori Tanaka",
        "Gautam Reddy",
        "Noah D. Goodman"
      ],
      "abstract": "Recent work analyzing in-context learning (ICL) has identified a broad set of strategies that describe model behavior in different experimental conditions. We aim to unify these findings by asking why a model learns these disparate strategies in the first place. Specifically, we start with the observation that when trained to learn a mixture of tasks, as is popular in the literature, the strategies learned by a model for performing ICL can be captured by a family of Bayesian predictors: a memorizing predictor, which assumes a discrete prior on the set of seen tasks, and a generalizing predictor, where the prior matches the underlying task distribution. Adopting the normative lens of rational analysis, where a learner's behavior is explained as an optimal adaptation to data given computational constraints, we develop a hierarchical Bayesian framework that almost perfectly predicts Transformer next-token predictions throughout training -- without assuming access to its weights. Under this framework, pretraining is viewed as a process of updating the posterior probability of different strategies, and inference-time behavior as a posterior-weighted average over these strategies' predictions. Our framework draws on common assumptions about neural network learning dynamics, which make explicit a tradeoff between loss and complexity among candidate strategies: beyond how well it explains the data, a model's preference towards implementing a strategy is dictated by its complexity. This helps explain well-known ICL phenomena, while offering novel predictions: e.g., we show a superlinear trend in the timescale for transitioning from generalization to memorization as task diversity increases. Overall, our work advances an explanatory and predictive account of ICL grounded in tradeoffs between strategy loss and complexity.",
      "tldr_zh": "è¯¥ç ”ç©¶é€šè¿‡ç†æ€§åˆ†æ(Rational Analysis)çš„è§†è§’ï¼Œæ¢è®¨äº†æ¨¡å‹åœ¨ä¸åŒæ¡ä»¶ä¸‹å­¦ä¹ åˆ°å¤šç§ä¸Šä¸‹æ–‡å­¦ä¹ (In-Context Learning, ICL)ç­–ç•¥çš„æ ¹æœ¬åŸå› ã€‚ä½œè€…æå‡ºäº†ä¸€ä¸ªå±‚æ¬¡è´å¶æ–¯æ¡†æ¶(Hierarchical Bayesian Framework)ï¼Œå°† ICL ç­–ç•¥æ•æ‰ä¸ºç”±è®°å¿†é¢„æµ‹å™¨(Memorizing Predictor)å’Œæ³›åŒ–é¢„æµ‹å™¨(Generalizing Predictor)ç»„æˆçš„è´å¶æ–¯é¢„æµ‹å™¨æ—ã€‚åœ¨è¯¥æ¡†æ¶ä¸‹ï¼Œé¢„è®­ç»ƒè¢«è§†ä¸ºæ›´æ–°ä¸åŒç­–ç•¥åéªŒæ¦‚ç‡çš„è¿‡ç¨‹ï¼Œè€Œæ¨ç†è¡Œä¸ºåˆ™æ˜¯è¿™äº›ç­–ç•¥é¢„æµ‹çš„åéªŒåŠ æƒå¹³å‡å€¼ã€‚è¯¥æ¡†æ¶ç»“åˆäº†ç¥ç»ç½‘ç»œå­¦ä¹ åŠ¨åŠ›å­¦ä¸­å…³äºæŸå¤±(Loss)ä¸å¤æ‚åº¦(Complexity)æƒè¡¡çš„å‡è®¾ï¼ŒæŒ‡å‡ºæ¨¡å‹å¯¹ç­–ç•¥çš„é€‰æ‹©ä¸ä»…å–å†³äºå¯¹æ•°æ®çš„è§£é‡Šç¨‹åº¦ï¼Œè¿˜å—åˆ°ç­–ç•¥å¤æ‚åº¦çš„åˆ¶çº¦ã€‚è¯¥ç ”ç©¶ä¸ä»…è§£é‡Šäº†å·²çŸ¥çš„ ICL ç°è±¡ï¼Œè¿˜å‘ç°éšç€ä»»åŠ¡å¤šæ ·æ€§å¢åŠ ï¼Œæ¨¡å‹ä»æ³›åŒ–è½¬å‘è®°å¿†çš„æ—¶é—´å°ºåº¦å‘ˆç°è¶…çº¿æ€§å¢é•¿ã€‚æ€»ä½“è€Œè¨€ï¼Œè¿™é¡¹å·¥ä½œé€šè¿‡ç­–ç•¥æŸå¤±ä¸å¤æ‚åº¦ä¹‹é—´çš„æƒè¡¡ï¼Œä¸º ICL çš„æ¼”å˜æä¾›äº†ä¸€ä¸ªå…·æœ‰è§£é‡Šæ€§å’Œé¢„æµ‹æ€§çš„ç†è®ºåŸºç¡€ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Preprint",
      "pdf_url": "https://arxiv.org/pdf/2506.17859v2",
      "published_date": "2025-06-21 23:49:08 UTC",
      "updated_date": "2025-06-26 16:54:57 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T23:21:24.187326+00:00"
    },
    {
      "arxiv_id": "2507.01036v1",
      "title": "Systemic Constraints of Undecidability",
      "title_zh": "ä¸å¯åˆ¤å®šæ€§çš„ç³»ç»Ÿæ€§çº¦æŸ",
      "authors": [
        "Seth Bulin"
      ],
      "abstract": "This paper presents a theory of systemic undecidability, reframing incomputability as a structural property of systems rather than a localized feature of specific functions or problems. We define a notion of causal embedding and prove a closure principle: any subsystem that participates functionally in the computation of an undecidable system inherits its undecidability. This result positions undecidability as a pervasive constraint on prediction, modeling, and epistemic access in both natural and artificial systems. Our framework disarms oracle mimicry and challenges the view that computational limits can be circumvented through architectural innovation. By generalizing classical results into a dynamic systems context, this work augments the logical trajectory of GÃ¶del, Turing, and Chaitin, offering a new perspective of the topology of computability and its interrelation to the boundaries of scientific knowledge.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ç³»ç»Ÿæ€§ä¸å¯åˆ¤å®šæ€§(systemic undecidability)ç†è®ºï¼Œå°†ä¸å¯è®¡ç®—æ€§(incomputability)é‡æ–°å®šä¹‰ä¸ºç³»ç»Ÿçš„ç»“æ„å±æ€§ï¼Œè€Œéç‰¹å®šåŠŸèƒ½æˆ–é—®é¢˜çš„å±€éƒ¨ç‰¹å¾ã€‚ä½œè€…é€šè¿‡å®šä¹‰å› æœåµŒå…¥(causal embedding)çš„æ¦‚å¿µï¼Œè¯æ˜äº†ä¸€ä¸ªé—­åŒ…åŸç†(closure principle)ï¼Œå³ä»»ä½•åœ¨ä¸å¯åˆ¤å®šç³»ç»Ÿè®¡ç®—ä¸­å‘æŒ¥åŠŸèƒ½ä½œç”¨çš„å­ç³»ç»Ÿéƒ½ä¼šç»§æ‰¿å…¶ä¸å¯åˆ¤å®šæ€§ã€‚è¿™ä¸€å‘ç°å°†ä¸å¯åˆ¤å®šæ€§è§†ä¸ºå¯¹è‡ªç„¶å’Œäººå·¥ç³»ç»Ÿä¸­é¢„æµ‹ã€å»ºæ¨¡åŠè®¤è¯†è®¿é—®(epistemic access)çš„æ™®éçº¦æŸã€‚è¯¥æ¡†æ¶æŒ‘æˆ˜äº†é€šè¿‡æ¶æ„åˆ›æ–°(architectural innovation)è§„é¿è®¡ç®—é™åˆ¶çš„è§‚ç‚¹ï¼Œå¹¶è´¨ç–‘äº†é¢„è¨€æœºæ¨¡ä»¿(oracle mimicry)çš„å¯è¡Œæ€§ã€‚é€šè¿‡å°†ç»å…¸é€»è¾‘ç»“è®ºæ‰©å±•è‡³åŠ¨æ€ç³»ç»ŸèƒŒæ™¯ï¼Œè¯¥å·¥ä½œæ·±åŒ–äº†å¯¹è®¡ç®—æ‹“æ‰‘ç»“æ„(topology of computability)çš„ç†è§£ï¼Œå¹¶ä¸ºç§‘å­¦çŸ¥è¯†çš„è¾¹ç•Œæä¾›äº†å…¨æ–°çš„ç†è®ºè§†è§’ã€‚",
      "categories": [
        "cs.LO",
        "cs.AI",
        "cs.FL",
        "math.LO"
      ],
      "primary_category": "cs.LO",
      "comment": "Submitted version; includes appendices with formal definitions and structural embeddings. Prepared in Nature Computational Science format. Keywords: computability theory, undecidability, causal systems, structural closure, recursion theory, Turing machines, hypercomputation, metaundecidability, epistemic limits, consciousness, modeling limits",
      "pdf_url": "https://arxiv.org/pdf/2507.01036v1",
      "published_date": "2025-06-21 22:56:26 UTC",
      "updated_date": "2025-06-21 22:56:26 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T23:21:14.574758+00:00"
    },
    {
      "arxiv_id": "2506.17848v1",
      "title": "Pathway-based Progressive Inference (PaPI) for Energy-Efficient Continual Learning",
      "title_zh": "é¢å‘é«˜èƒ½æ•ˆæŒç»­å­¦ä¹ çš„åŸºäºè·¯å¾„çš„æ¸è¿›å¼æ¨ç† (PaPI)",
      "authors": [
        "Suyash Gaurav",
        "Jukka Heikkonen",
        "Jatin Chaudhary"
      ],
      "abstract": "Continual learning systems face the dual challenge of preventing catastrophic forgetting while maintaining energy efficiency, particularly in resource-constrained environments. This paper introduces Pathway-based Progressive Inference (PaPI), a novel theoretical framework that addresses these challenges through a mathematically rigorous approach to pathway selection and adaptation. We formulate continual learning as an energy-constrained optimization problem and provide formal convergence guarantees for our pathway routing mechanisms. Our theoretical analysis demonstrates that PaPI achieves an $\\mathcal{O}(K)$ improvement in the stability-plasticity trade-off compared to monolithic architectures, where $K$ is the number of pathways. We derive tight bounds on forgetting rates using Fisher Information Matrix analysis and prove that PaPI's energy consumption scales with the number of active parameters rather than the total model size. Comparative theoretical analysis shows that PaPI provides stronger guarantees against catastrophic forgetting than Elastic Weight Consolidation (EWC) while maintaining better energy efficiency than both EWC and Gradient Episodic Memory (GEM). Our experimental validation confirms these theoretical advantages across multiple benchmarks, demonstrating PaPI's effectiveness for continual learning in energy-constrained settings. Our codes are available at https://github.com/zser092/PAPI_FILES.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹Continual Learningä¸­é˜²æ­¢Catastrophic Forgettingä¸ç»´æŒEnergy Efficiencyçš„åŒé‡æŒ‘æˆ˜ï¼Œæå‡ºäº†åä¸ºPathway-based Progressive Inference (PaPI) çš„ç†è®ºæ¡†æ¶ã€‚PaPIé€šè¿‡æ•°å­¦ä¸¥è°¨çš„Pathway Selectionå’ŒAdaptationæœºåˆ¶ï¼Œå°†æŒç»­å­¦ä¹ å»ºæ¨¡ä¸ºèƒ½æºçº¦æŸä¸‹çš„ä¼˜åŒ–é—®é¢˜ï¼Œå¹¶æä¾›äº†å½¢å¼åŒ–çš„æ”¶æ•›ä¿è¯ã€‚ç†è®ºåˆ†ææ˜¾ç¤ºï¼ŒPaPIåœ¨Stability-Plasticity Trade-offä¸Šæ¯”å•ä½“æ¶æ„å®ç°äº†$\\mathcal{O}(K)$çº§åˆ«çš„æ”¹è¿›ï¼Œå…¶ä¸­$K$ä»£è¡¨è·¯å¾„æ•°é‡ã€‚é€šè¿‡Fisher Information Matrixåˆ†æï¼Œç ”ç©¶è€…æ¨å¯¼äº†é—å¿˜ç‡çš„ç´§è‡´ç•Œé™ï¼Œå¹¶è¯æ˜äº†è¯¥æ¡†æ¶çš„èƒ½è€—ä»…éšæ´»åŠ¨å‚æ•°æ•°é‡å¢é•¿è€Œéæ¨¡å‹æ€»è§„æ¨¡ã€‚ç›¸æ¯”äºElastic Weight Consolidation (EWC) å’Œ Gradient Episodic Memory (GEM)ï¼ŒPaPIåœ¨é˜²æ­¢ç¾éš¾æ€§é—å¿˜çš„ç†è®ºä¿éšœå’Œèƒ½æºæ•ˆç‡æ–¹é¢å‡è¡¨ç°æ›´ä¼˜ã€‚å®éªŒç»“æœè¯å®äº†è¯¥æ–¹æ³•åœ¨å¤šé¡¹åŸºå‡†æµ‹è¯•ä¸­çš„ä¼˜è¶Šæ€§ï¼Œä¸ºèµ„æºå—é™ç¯å¢ƒä¸‹çš„æŒç»­å­¦ä¹ æä¾›äº†æœ‰æ•ˆçš„é«˜èƒ½æ•ˆæ–¹æ¡ˆã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2506.17848v1",
      "published_date": "2025-06-21 22:50:01 UTC",
      "updated_date": "2025-06-21 22:50:01 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T23:21:24.752106+00:00"
    },
    {
      "arxiv_id": "2506.17847v1",
      "title": "A Comparative Study of Open-Source Libraries for Synthetic Tabular Data Generation: SDV vs. SynthCity",
      "title_zh": "å¼€æºåˆæˆè¡¨æ ¼æ•°æ®ç”Ÿæˆåº“çš„æ¯”è¾ƒç ”ç©¶ï¼šSDV ä¸ SynthCity",
      "authors": [
        "Cristian Del Gobbo"
      ],
      "abstract": "High-quality training data is critical to the performance of machine learning models, particularly Large Language Models (LLMs). However, obtaining real, high-quality data can be challenging, especially for smaller organizations and early-stage startups. Synthetic data generators provide a promising solution by replicating the statistical and structural properties of real data while preserving privacy and scalability. This study evaluates the performance of six tabular synthetic data generators from two widely used open-source libraries: SDV (Gaussian Copula, CTGAN, TVAE) and Synthicity (Bayesian Network, CTGAN, TVAE). Using a real-world dataset from the UCI Machine Learning Repository, comprising energy consumption and environmental variables from Belgium, we simulate a low-data regime by training models on only 1,000 rows. Each generator is then tasked with producing synthetic datasets under two conditions: a 1:1 (1,000 rows) and a 1:10 (10,000 rows) input-output ratio. Evaluation is conducted using two criteria: statistical similarity, measured via classical statistics and distributional metrics; and predictive utility, assessed using a \"Train on Synthetic, Test on Real\" approach with four regression models. While statistical similarity remained consistent across models in both scenarios, predictive utility declined notably in the 1:10 case. The Bayesian Network from Synthicity achieved the highest fidelity in both scenarios, while TVAE from SDV performed best in predictive tasks under the 1:10 setting. Although no significant performance gap was found between the two libraries, SDV stands out for its superior documentation and ease of use, making it more accessible for practitioners.",
      "tldr_zh": "è¯¥ç ”ç©¶å¯¹æ¯”åˆ†æäº†ä¸¤ä¸ªä¸»æµå¼€æºåº“ SDV å’Œ SynthCity åœ¨åˆæˆè¡¨æ ¼æ•°æ® (Synthetic Tabular Data) ç”Ÿæˆæ–¹é¢çš„è¡¨ç°ï¼Œæ—¨åœ¨ä¸ºæ•°æ®è·å–å—é™çš„å°å‹æœºæ„æä¾›æœ‰æ•ˆçš„å¢å¼ºæ–¹æ¡ˆã€‚ç ”ç©¶è¯„ä¼°äº† Gaussian Copulaã€CTGANã€TVAE å’Œ Bayesian Network ç­‰å…­ç§ç”Ÿæˆå™¨ï¼Œåœ¨ 1,000 æ¡è®°å½•çš„å°æ ·æœ¬ç¯å¢ƒä¸‹æ¨¡æ‹Ÿäº† 1:1 å’Œ 1:10 çš„æ•°æ®ç”Ÿæˆæ¯”ä¾‹ã€‚é€šè¿‡ç»Ÿè®¡ç›¸ä¼¼åº¦ (Statistical Similarity) å’Œâ€œåˆæˆè®­ç»ƒ-çœŸå®æµ‹è¯•â€ (Train on Synthetic, Test on Real) çš„é¢„æµ‹æ•ˆç”¨ (Predictive Utility) åŒé‡æ ‡å‡†è¿›è¡Œè¯„ä¼°ï¼Œç»“æœæ˜¾ç¤º SynthCity çš„ Bayesian Network å…·æœ‰æœ€é«˜çš„ä¿çœŸåº¦ã€‚è€Œåœ¨ 1:10 çš„é«˜å€æ•°ç”Ÿæˆåœºæ™¯ä¸‹ï¼ŒSDV çš„ TVAE åœ¨é¢„æµ‹ä»»åŠ¡ä¸­è¡¨ç°æœ€ä¸ºå‡ºè‰²ã€‚ç ”ç©¶è§‚å¯Ÿåˆ°è™½ç„¶ç»Ÿè®¡åˆ†å¸ƒåœ¨ä¸åŒç”Ÿæˆæ¯”ä¾‹ä¸‹ä¿æŒç¨³å®šï¼Œä½†é¢„æµ‹æ•ˆç”¨åœ¨ 1:10 æ—¶ä¼šæ˜¾è‘—ä¸‹é™ã€‚å°½ç®¡ä¸¤åº“æ€§èƒ½ç›¸è¿‘ï¼Œä½† SDV å‡­å€Ÿæ›´å®Œå–„çš„æ–‡æ¡£å’Œæ˜“ç”¨æ€§åœ¨å®è·µä¸­æ›´å…·ä¼˜åŠ¿ï¼Œä¸ºåˆæˆæ•°æ®å·¥å…·çš„é€‰æ‹©æä¾›äº†é‡è¦å‚è€ƒã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "23 Pages, 5 figures, and 6 tables",
      "pdf_url": "https://arxiv.org/pdf/2506.17847v1",
      "published_date": "2025-06-21 22:45:40 UTC",
      "updated_date": "2025-06-21 22:45:40 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T23:21:43.700522+00:00"
    },
    {
      "arxiv_id": "2506.17846v1",
      "title": "Out of Control -- Why Alignment Needs Formal Control Theory (and an Alignment Control Stack)",
      "title_zh": "å¤±æ§ï¼šä¸ºä½•å¯¹é½éœ€è¦å½¢å¼æ§åˆ¶ç†è®ºï¼ˆåŠå¯¹é½æ§åˆ¶æ ˆï¼‰",
      "authors": [
        "Elija Perrier"
      ],
      "abstract": "This position paper argues that formal optimal control theory should be central to AI alignment research, offering a distinct perspective from prevailing AI safety and security approaches. While recent work in AI safety and mechanistic interpretability has advanced formal methods for alignment, they often fall short of the generalisation required of control frameworks for other technologies. There is also a lack of research into how to render different alignment/control protocols interoperable. We argue that by recasting alignment through principles of formal optimal control and framing alignment in terms of hierarchical stack from physical to socio-technical layers according to which controls may be applied we can develop a better understanding of the potential and limitations for controlling frontier models and agentic AI systems. To this end, we introduce an Alignment Control Stack which sets out a hierarchical layered alignment stack, identifying measurement and control characteristics at each layer and how different layers are formally interoperable. We argue that such analysis is also key to the assurances that will be needed by governments and regulators in order to see AI technologies sustainably benefit the community. Our position is that doing so will bridge the well-established and empirically validated methods of optimal control with practical deployment considerations to create a more comprehensive alignment framework, enhancing how we approach safety and reliability for advanced AI systems.",
      "tldr_zh": "è¯¥ç ”ç©¶è®¤ä¸ºæ­£å¼çš„æœ€ä¼˜æ§åˆ¶ç†è®ºï¼ˆoptimal control theoryï¼‰åº”æˆä¸ºAIå¯¹é½ç ”ç©¶çš„æ ¸å¿ƒï¼Œå¹¶æ®æ­¤æå‡ºäº†ä¸€ä¸ªå¯¹é½æ§åˆ¶æ ˆï¼ˆAlignment Control Stackï¼‰ã€‚ä½œè€…æŒ‡å‡ºï¼Œç›®å‰çš„AIå®‰å…¨å’Œæœºæ¢°è§£é‡Šæ€§ï¼ˆmechanistic interpretabilityï¼‰æ–¹æ³•åœ¨æ³›åŒ–èƒ½åŠ›å’Œåè®®äº’æ“ä½œæ€§ï¼ˆinteroperabilityï¼‰æ–¹é¢ä»å­˜åœ¨ä¸è¶³ã€‚é€šè¿‡å°†å¯¹é½é—®é¢˜é‡å¡‘ä¸ºä»ç‰©ç†å±‚åˆ°ç¤¾ä¼šæŠ€æœ¯å±‚çš„åˆ†å±‚ç»“æ„ï¼Œè¯¥æ¡†æ¶èƒ½å¤Ÿæ›´å¥½åœ°ç†è§£å’Œæ§åˆ¶å‰æ²¿æ¨¡å‹åŠä»£ç†å¼AIï¼ˆagentic AIï¼‰ç³»ç»Ÿçš„æ½œåŠ›ä¸å±€é™ã€‚å¯¹é½æ§åˆ¶æ ˆæ˜ç¡®äº†æ¯ä¸€å±‚çš„æµ‹é‡ä¸æ§åˆ¶ç‰¹å¾ï¼Œå¹¶é˜è¿°äº†ä¸åŒå±‚çº§é—´å¦‚ä½•å®ç°æ­£å¼çš„äº’æ“ä½œã€‚è¿™ç§æ–¹æ³•å°†å®è¯éªŒè¯çš„æœ€ä¼˜æ§åˆ¶æ–¹æ³•ä¸å®é™…éƒ¨ç½²éœ€æ±‚ç›¸ç»“åˆï¼Œæ„å»ºäº†ä¸€ä¸ªæ›´å…¨é¢çš„å¯¹é½æ¡†æ¶ã€‚è¯¥ç ”ç©¶å¼ºè°ƒï¼Œæ­¤ç±»åˆ†ææ˜¯æ”¿åºœå’Œç›‘ç®¡æœºæ„æä¾›å®‰å…¨ä¿è¯çš„å…³é”®ï¼Œå¯¹äºæå‡é«˜çº§AIç³»ç»Ÿçš„å®‰å…¨æ€§å’Œå¯é æ€§å…·æœ‰é‡è¦æ„ä¹‰ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Under review for Neurips 2025",
      "pdf_url": "https://arxiv.org/pdf/2506.17846v1",
      "published_date": "2025-06-21 22:45:19 UTC",
      "updated_date": "2025-06-21 22:45:19 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T23:21:27.328379+00:00"
    },
    {
      "arxiv_id": "2506.17844v2",
      "title": "THCM-CAL: Temporal-Hierarchical Causal Modelling with Conformal Calibration for Clinical Risk Prediction",
      "title_zh": "THCM-CALï¼šé¢å‘ä¸´åºŠé£é™©é¢„æµ‹çš„ç¬¦åˆé¢„æµ‹æ ¡å‡†æ—¶åºå±‚æ¬¡å› æœå»ºæ¨¡",
      "authors": [
        "Xin Zhang",
        "Qiyu Wei",
        "Yingjie Zhu",
        "Fanyi Wu",
        "Sophia Ananiadou"
      ],
      "abstract": "Automated clinical risk prediction from electronic health records (EHRs) demands modeling both structured diagnostic codes and unstructured narrative notes. However, most prior approaches either handle these modalities separately or rely on simplistic fusion strategies that ignore the directional, hierarchical causal interactions by which narrative observations precipitate diagnoses and propagate risk across admissions. In this paper, we propose THCM-CAL, a Temporal-Hierarchical Causal Model with Conformal Calibration. Our framework constructs a multimodal causal graph where nodes represent clinical entities from two modalities: Textual propositions extracted from notes and ICD codes mapped to textual descriptions. Through hierarchical causal discovery, THCM-CAL infers three clinically grounded interactions: intra-slice same-modality sequencing, intra-slice cross-modality triggers, and inter-slice risk propagation. To enhance prediction reliability, we extend conformal prediction to multi-label ICD coding, calibrating per-code confidence intervals under complex co-occurrences. Experimental results on MIMIC-III and MIMIC-IV demonstrate the superiority of THCM-CAL.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† THCM-CALï¼Œä¸€ç§å…·å¤‡ Conformal Calibration çš„æ—¶åºå±‚æ¬¡å› æœæ¨¡å‹ï¼ˆTemporal-Hierarchical Causal Modelï¼‰ï¼Œæ—¨åœ¨é€šè¿‡ç”µå­å¥åº·è®°å½•ï¼ˆEHRï¼‰æå‡ä¸´åºŠé£é™©é¢„æµ‹çš„å‡†ç¡®æ€§ã€‚è¯¥æ¡†æ¶æ„å»ºäº†ä¸€ä¸ªå¤šæ¨¡æ€å› æœå›¾ï¼Œåˆ©ç”¨å±‚æ¬¡åŒ–å› æœå‘ç°ï¼ˆHierarchical causal discoveryï¼‰æ¨æ–­ç¬”è®°ä¸­çš„ Textual propositions ä¸ç»“æ„åŒ– ICD codes ä¹‹é—´çš„å®šå‘äº¤äº’ï¼Œæ¶µç›–äº†åˆ‡ç‰‡å†…åºåˆ—ã€è·¨æ¨¡æ€è§¦å‘ä»¥åŠè·¨åˆ‡ç‰‡çš„é£é™©ä¼ æ’­ï¼ˆInter-slice risk propagationï¼‰ã€‚ä¸ºäº†å¢å¼ºé¢„æµ‹ç»“æœçš„å¯é æ€§ï¼Œç ”ç©¶å°† Conformal prediction æ‰©å±•è‡³å¤šæ ‡ç­¾ ICD coding ä»»åŠ¡ï¼Œåœ¨å¤æ‚çš„ç–¾ç—…å…±ç°ç¯å¢ƒä¸‹æ ¡å‡†æ¯ä¸ªä»£ç çš„ç½®ä¿¡åŒºé—´ã€‚åœ¨ MIMIC-III å’Œ MIMIC-IV æ•°æ®é›†ä¸Šçš„å®éªŒç»“æœè¯æ˜ï¼ŒTHCM-CAL åœ¨æ¨¡æ‹Ÿä¸´åºŠå› æœé€»è¾‘å’Œæé«˜é¢„æµ‹æ€§èƒ½æ–¹é¢å…·æœ‰æ˜¾è‘—ä¼˜è¶Šæ€§ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted at EMNLP 2025",
      "pdf_url": "https://arxiv.org/pdf/2506.17844v2",
      "published_date": "2025-06-21 22:43:42 UTC",
      "updated_date": "2025-09-24 23:07:31 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T23:21:29.467128+00:00"
    },
    {
      "arxiv_id": "2506.17842v1",
      "title": "Generative Grasp Detection and Estimation with Concept Learning-based Safety Criteria",
      "title_zh": "åŸºäºæ¦‚å¿µå­¦ä¹ å®‰å…¨å‡†åˆ™çš„ç”Ÿæˆå¼æŠ“å–æ£€æµ‹ä¸ä¼°è®¡",
      "authors": [
        "Al-Harith Farhad",
        "Khalil Abuibaid",
        "Christiane Plociennik",
        "Achim Wagner",
        "Martin Ruskowski"
      ],
      "abstract": "Neural networks are often regarded as universal equations that can estimate any function. This flexibility, however, comes with the drawback of high complexity, rendering these networks into black box models, which is especially relevant in safety-centric applications. To that end, we propose a pipeline for a collaborative robot (Cobot) grasping algorithm that detects relevant tools and generates the optimal grasp. To increase the transparency and reliability of this approach, we integrate an explainable AI method that provides an explanation for the underlying prediction of a model by extracting the learned features and correlating them to corresponding classes from the input. These concepts are then used as additional criteria to ensure the safe handling of work tools. In this paper, we show the consistency of this approach and the criterion for improving the handover position. This approach was tested in an industrial environment, where a camera system was set up to enable a robot to pick up certain tools and objects.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹åä½œæœºå™¨äºº(Cobot)æŠ“å–ç®—æ³•ä¸­é»‘ç›’æ¨¡å‹é€æ˜åº¦ä¸å¯é æ€§ä¸è¶³çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§ç»“åˆæ¦‚å¿µå­¦ä¹ (Concept Learning)å®‰å…¨å‡†åˆ™çš„ç”Ÿæˆå¼æŠ“å–æ£€æµ‹ä¸ä¼°è®¡æµç¨‹ã€‚è¯¥æ–¹æ³•åœ¨å®ç°å·¥å…·æ£€æµ‹ä¸æœ€ä¼˜æŠ“å–ç”Ÿæˆçš„è¿‡ç¨‹ä¸­ï¼Œé›†æˆäº†å¯è§£é‡Šäººå·¥æ™ºèƒ½(Explainable AI)æŠ€æœ¯ï¼Œé€šè¿‡æå–å­¦ä¹ ç‰¹å¾å¹¶å°†å…¶ä¸è¾“å…¥ç±»åˆ«å¯¹åº”ï¼Œä¸ºæ¨¡å‹çš„æŠ“å–é¢„æµ‹æä¾›é€æ˜åŒ–çš„è§£é‡Šã€‚è¿™äº›æå–çš„ç‰¹å¾æ¦‚å¿µè¢«è½¬åŒ–ä¸ºå…³é”®çš„å®‰å…¨å‡†åˆ™ï¼Œä»¥ç¡®ä¿å·¥ä¸šåœºæ™¯ä¸‹å¯¹å·¥ä½œå·¥å…·çš„å®‰å…¨å¤„ç†ä¸æ“ä½œã€‚åœ¨å®é™…å·¥ä¸šç¯å¢ƒçš„æµ‹è¯•ä¸­ï¼Œè¯¥ç³»ç»Ÿé€šè¿‡ç›¸æœºä¼ æ„Ÿå™¨æˆåŠŸå¼•å¯¼æœºå™¨äººå®Œæˆç‰¹å®šå·¥å…·çš„æ‹¾å–ä»»åŠ¡ã€‚å®éªŒç»“æœè¯æ˜äº†è¯¥æ–¹æ³•åœ¨æ”¹å–„äº¤ä»˜ä½ç½®(Handover Position)ä¸€è‡´æ€§æ–¹é¢çš„æœ‰æ•ˆæ€§ï¼Œä¸ºæ„å»ºæ›´å…·å®‰å…¨æ€§çš„è‡ªä¸»å·¥ä¸šæœºå™¨äººç³»ç»Ÿæä¾›äº†é‡è¦å‚è€ƒã€‚",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "RAAD 2025: 34th International Conference on Robotics in Alpe-Adria-Danube Region",
      "pdf_url": "https://arxiv.org/pdf/2506.17842v1",
      "published_date": "2025-06-21 22:33:25 UTC",
      "updated_date": "2025-06-21 22:33:25 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T23:21:39.644369+00:00"
    },
    {
      "arxiv_id": "2506.17840v1",
      "title": "Causal Spherical Hypergraph Networks for Modelling Social Uncertainty",
      "title_zh": "é¢å‘ç¤¾ä¼šä¸ç¡®å®šæ€§å»ºæ¨¡çš„å› æœçƒé¢è¶…å›¾ç½‘ç»œ",
      "authors": [
        "Anoushka Harit",
        "Zhongtian Sun"
      ],
      "abstract": "Human social behaviour is governed by complex interactions shaped by uncertainty, causality, and group dynamics. We propose Causal Spherical Hypergraph Networks (Causal-SphHN), a principled framework for socially grounded prediction that jointly models higher-order structure, directional influence, and epistemic uncertainty. Our method represents individuals as hyperspherical embeddings and group contexts as hyperedges, capturing semantic and relational geometry. Uncertainty is quantified via Shannon entropy over von Mises-Fisher distributions, while temporal causal dependencies are identified using Granger-informed subgraphs. Information is propagated through an angular message-passing mechanism that respects belief dispersion and directional semantics. Experiments on SNARE (offline networks), PHEME (online discourse), and AMIGOS (multimodal affect) show that Causal-SphHN improves predictive accuracy, robustness, and calibration over strong baselines. Moreover, it enables interpretable analysis of influence patterns and social ambiguity. This work contributes a unified causal-geometric approach for learning under uncertainty in dynamic social environments.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†Causal Spherical Hypergraph Networks (Causal-SphHN)ï¼Œè¿™æ˜¯ä¸€ä¸ªç”¨äºç¤¾äº¤é¢„æµ‹çš„åŸåˆ™æ€§æ¡†æ¶ï¼Œæ—¨åœ¨è”åˆå»ºæ¨¡é«˜é˜¶ç»“æ„ã€å®šå‘å½±å“å’Œè®¤è¯†è®ºä¸ç¡®å®šæ€§(epistemic uncertainty)ã€‚è¯¥æ–¹æ³•åˆ©ç”¨hyperspherical embeddingsè¡¨ç¤ºä¸ªä½“å¹¶å°†ç¾¤ä½“ä¸Šä¸‹æ–‡å»ºæ¨¡ä¸ºhyperedgesï¼Œæœ‰æ•ˆæ•æ‰äº†ç¤¾äº¤äº’åŠ¨çš„è¯­ä¹‰ä¸å…³ç³»å‡ ä½•ç‰¹å¾ã€‚é€šè¿‡åœ¨von Mises-Fisheråˆ†å¸ƒä¸Šåº”ç”¨Shannon entropyï¼Œè¯¥æ¡†æ¶å®ç°äº†å¯¹ä¸ç¡®å®šæ€§çš„ç²¾ç¡®é‡åŒ–ï¼Œå¹¶ç»“åˆGranger-informed subgraphsè¯†åˆ«æ—¶é—´å› æœä¾èµ–ã€‚ä¿¡æ¯ä¼ é€’åˆ™é‡‡ç”¨ä¸€ç§ç‰¹æ®Šçš„angular message-passingæœºåˆ¶ï¼Œç¡®ä¿ä¼ æ’­è¿‡ç¨‹éµå¾ªä¿¡å¿µåˆ†æ•£å’Œå®šå‘è¯­ä¹‰é€»è¾‘ã€‚åœ¨SNAREã€PHEMEå’ŒAMIGOSæ•°æ®é›†ä¸Šçš„å®éªŒè¯æ˜ï¼ŒCausal-SphHNåœ¨é¢„æµ‹å‡†ç¡®æ€§ã€é²æ£’æ€§å’Œæ ¡å‡†åº¦ä¸Šæ˜¾è‘—ä¼˜äºç°æœ‰åŸºçº¿ã€‚æ­¤å¤–ï¼Œè¯¥æ¨¡å‹è¿˜æ”¯æŒå¯¹å½±å“åŠ›æ¨¡å¼å’Œç¤¾äº¤æ­§ä¹‰çš„å¯è§£é‡Šæ€§åˆ†æï¼Œä¸ºå¤æ‚åŠ¨æ€ç¤¾äº¤ç¯å¢ƒä¸‹çš„ä¸ç¡®å®šæ€§å­¦ä¹ è´¡çŒ®äº†ç»Ÿä¸€çš„å› æœå‡ ä½•æ–¹æ³•ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2506.17840v1",
      "published_date": "2025-06-21 22:30:04 UTC",
      "updated_date": "2025-06-21 22:30:04 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T23:21:44.677535+00:00"
    },
    {
      "arxiv_id": "2506.17834v1",
      "title": "Reflective Verbal Reward Design for Pluralistic Alignment",
      "title_zh": "é¢å‘å¤šå…ƒå¯¹é½çš„åæ€æ€§è¯­è¨€å¥–åŠ±è®¾è®¡",
      "authors": [
        "Carter Blair",
        "Kate Larson",
        "Edith Law"
      ],
      "abstract": "AI agents are commonly aligned with \"human values\" through reinforcement learning from human feedback (RLHF), where a single reward model is learned from aggregated human feedback and used to align an agent's behavior. However, human values are not homogeneous--different people hold distinct and sometimes conflicting values. Aggregating feedback into a single reward model risks disproportionately suppressing minority preferences. To address this, we present a novel reward modeling approach for learning individualized reward models. Our approach uses a language model to guide users through reflective dialogues where they critique agent behavior and construct their preferences. This personalized dialogue history, containing the user's reflections and critiqued examples, is then used as context for another language model that serves as an individualized reward function (what we call a \"verbal reward model\") for evaluating new trajectories. In studies with 30 participants, our method achieved a 9-12% improvement in accuracy over non-reflective verbal reward models while being more sample efficient than traditional supervised learning methods.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ä¼ ç»Ÿå¼ºåŒ–å­¦ä¹ äººå·¥åé¦ˆ(RLHF)ä¸­å•ä¸€å¥–åŠ±æ¨¡å‹å®¹æ˜“æŠ‘åˆ¶å°‘æ•°ç¾¤ä½“åå¥½çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§æ—¨åœ¨å®ç°å¤šå…ƒåŒ–å¯¹é½(Pluralistic Alignment)çš„ä¸ªæ€§åŒ–å¥–åŠ±å»ºæ¨¡æ–¹æ³•ã€‚è¯¥æ–¹æ³•åˆ©ç”¨è¯­è¨€æ¨¡å‹å¼•å¯¼ç”¨æˆ·è¿›è¡Œåæ€æ€§å¯¹è¯(reflective dialogues)ï¼Œé€šè¿‡æ‰¹è¯„æ™ºèƒ½ä½“è¡Œä¸ºæ¥æ„å»ºç”¨æˆ·ä¸ªäººåå¥½ã€‚è¿™ç§åŒ…å«åæ€å†…å®¹å’Œè¯„ä»·ç¤ºä¾‹çš„ä¸ªæ€§åŒ–å¯¹è¯å†å²è¢«ç”¨ä½œå¦ä¸€ä¸ªè¯­è¨€æ¨¡å‹çš„ä¸Šä¸‹æ–‡ï¼Œä»è€Œæ„å»ºå‡ºèƒ½å¤Ÿè¯„ä¼°æ–°è½¨è¿¹çš„è¨€è¯­å¥–åŠ±æ¨¡å‹(verbal reward model)ã€‚é’ˆå¯¹30åå‚ä¸è€…çš„å®éªŒç ”ç©¶è¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨å‡†ç¡®ç‡(accuracy)ä¸Šæ¯”éåæ€æ€§æ¨¡å‹æå‡äº†9-12%ï¼Œä¸”åœ¨æ ·æœ¬æ•ˆç‡(sample efficiency)æ–¹é¢ä¼˜äºä¼ ç»Ÿçš„ç›‘ç£å­¦ä¹ (supervised learning)æ–¹æ³•ï¼Œæœ‰æ•ˆè§£å†³äº†äººç±»ä»·å€¼è§‚éåŒè´¨æ€§å¸¦æ¥çš„å¯¹é½æŒ‘æˆ˜ã€‚",
      "categories": [
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.AI",
      "comment": "9 pages, 3 figures, accepted to the IJCAI 2025 Human-Centred AI track. Project repository at: https://osf.io/8yxf2/",
      "pdf_url": "https://arxiv.org/pdf/2506.17834v1",
      "published_date": "2025-06-21 22:04:11 UTC",
      "updated_date": "2025-06-21 22:04:11 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T23:21:46.309416+00:00"
    },
    {
      "arxiv_id": "2506.17828v2",
      "title": "Aligning Frozen LLMs by Reinforcement Learning: An Iterative Reweight-then-Optimize Approach",
      "title_zh": "é€šè¿‡å¼ºåŒ–å­¦ä¹ å¯¹é½å†»ç»“çš„ LLMï¼šä¸€ç§è¿­ä»£å¼é‡åŠ æƒåä¼˜åŒ–æ–¹æ³•",
      "authors": [
        "Xinnan Zhang",
        "Chenliang Li",
        "Siliang Zeng",
        "Jiaxiang Li",
        "Zhongruo Wang",
        "Kaixiang Lin",
        "Songtao Lu",
        "Alfredo Garcia",
        "Mingyi Hong"
      ],
      "abstract": "Aligning large language models (LLMs) with human preferences usually requires fine-tuning methods such as RLHF and DPO. These methods directly optimize the model parameters, so they cannot be used in test-time to improve model performance, nor are they applicable when the model weights are not accessible. In contrast, test-time methods sidestep weight updates by leveraging reward functions to guide and improve output quality. However, they incur high inference costs, and their one-shot guidance is often based on imperfect reward or value functions, leading to suboptimal outputs. In this work, we present a method named Iterative Reweight-then-Optimize (IRO), a reinforcement learning (RL) framework that performs RL-style alignment of the (frozen) base model without touching its parameters. During training, each iteration (i) samples candidates from the base model, (ii) resamples using current value functions, and (iii) trains a new lightweight value function that guides the next decoding pass. At test time, the value functions are used to guide the base model generation via a search-based optimization process. Notably, users can apply IRO to align a model on their own dataset, similar to OpenAI's reinforcement fine-tuning (RFT), but without requiring access to the model weights.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† Iterative Reweight-then-Optimize (IRO)ï¼Œè¿™æ˜¯ä¸€ç§åœ¨æ— éœ€ä¿®æ”¹æ¨¡å‹å‚æ•°çš„æƒ…å†µä¸‹å¯¹å†»ç»“çš„å¤§è¯­è¨€æ¨¡å‹(LLMs)è¿›è¡Œå¼ºåŒ–å­¦ä¹ é£æ ¼å¯¹é½çš„æ¡†æ¶ã€‚ä¼ ç»Ÿçš„ RLHF å’Œ DPO æ–¹æ³•ä¾èµ–äºå¯¹æ¨¡å‹æƒé‡çš„ç›´æ¥ä¼˜åŒ–ï¼Œè€Œ IRO åˆ™é€šè¿‡è¿­ä»£è¿‡ç¨‹åœ¨è®­ç»ƒé˜¶æ®µè®­ç»ƒè½»é‡çº§çš„ä»·å€¼å‡½æ•°(Value Functions)æ¥æŒ‡å¯¼è§£ç ã€‚åœ¨æ¨ç†é˜¶æ®µï¼ŒIRO åˆ©ç”¨è¿™äº›ä»·å€¼å‡½æ•°é€šè¿‡åŸºäºæœç´¢çš„ä¼˜åŒ–è¿‡ç¨‹å¼•å¯¼åŸºç¡€æ¨¡å‹ç”Ÿæˆï¼Œå…‹æœäº†ä¼ ç»Ÿæµ‹è¯•æ—¶å¼•å¯¼æ–¹æ³•æˆæœ¬é«˜ä¸”æ•ˆæœæ¬ ä½³çš„é—®é¢˜ã€‚è¯¥æ–¹æ³•å…è®¸ç”¨æˆ·åœ¨æ— æ³•è®¿é—®æ¨¡å‹æƒé‡çš„æƒ…å†µä¸‹ï¼Œåœ¨ç‰¹å®šæ•°æ®é›†ä¸Šå®ç°ç±»ä¼¼äº OpenAI å¼ºåŒ–å¾®è°ƒ(RFT)çš„å¯¹é½æ•ˆæœã€‚è¿™ç§è¿­ä»£é‡é‡‡æ ·ä¸ä¼˜åŒ–çš„æœºåˆ¶ä¸ºé»‘ç›’æ¨¡å‹çš„æ€§èƒ½æå‡å’Œåå¥½å¯¹é½æä¾›äº†ä¸€ç§é«˜æ•ˆä¸”çµæ´»çš„è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2506.17828v2",
      "published_date": "2025-06-21 21:49:02 UTC",
      "updated_date": "2025-07-03 05:12:51 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T23:21:49.107512+00:00"
    },
    {
      "arxiv_id": "2506.17826v1",
      "title": "Actionable Interpretability via Causal Hypergraphs: Unravelling Batch Size Effects in Deep Learning",
      "title_zh": "åŸºäºå› æœè¶…å›¾çš„å¯æ“ä½œæ€§å¯è§£é‡Šæ€§ï¼šå‰–ææ·±åº¦å­¦ä¹ ä¸­çš„æ‰¹é‡å¤§å°æ•ˆåº”",
      "authors": [
        "Zhongtian Sun",
        "Anoushka Harit",
        "Pietro Lio"
      ],
      "abstract": "While the impact of batch size on generalisation is well studied in vision tasks, its causal mechanisms remain underexplored in graph and text domains. We introduce a hypergraph-based causal framework, HGCNet, that leverages deep structural causal models (DSCMs) to uncover how batch size influences generalisation via gradient noise, minima sharpness, and model complexity. Unlike prior approaches based on static pairwise dependencies, HGCNet employs hypergraphs to capture higher-order interactions across training dynamics. Using do-calculus, we quantify direct and mediated effects of batch size interventions, providing interpretable, causally grounded insights into optimisation. Experiments on citation networks, biomedical text, and e-commerce reviews show that HGCNet outperforms strong baselines including GCN, GAT, PI-GNN, BERT, and RoBERTa. Our analysis reveals that smaller batch sizes causally enhance generalisation through increased stochasticity and flatter minima, offering actionable interpretability to guide training strategies in deep learning. This work positions interpretability as a driver of principled architectural and optimisation choices beyond post hoc analysis.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§åŸºäºè¶…å›¾(hypergraph)çš„å› æœæ¡†æ¶ HGCNetï¼Œåˆ©ç”¨æ·±åº¦ç»“æ„å› æœæ¨¡å‹(DSCMs)æ¢ç´¢åœ¨å›¾å’Œæ–‡æœ¬é¢†åŸŸä¸­ batch size å¯¹æ¨¡å‹æ³›åŒ–æ€§èƒ½çš„å½±å“æœºåˆ¶ã€‚ä¸åŒäºä¼ ç»Ÿçš„é™æ€å¯¹ç­‰ä¾èµ–æ–¹æ³•ï¼ŒHGCNet é€šè¿‡è¶…å›¾æ•æ‰è®­ç»ƒåŠ¨æ€ä¸­çš„é«˜é˜¶äº¤äº’ï¼Œå¹¶åº”ç”¨ do-calculus é‡åŒ– batch size å¹²é¢„çš„ç›´æ¥å’Œä¸­ä»‹æ•ˆåº”ã€‚è¯¥æ¡†æ¶æ·±å…¥æ­ç¤ºäº† batch size å¦‚ä½•é€šè¿‡æ¢¯åº¦å™ªå£°(gradient noise)ã€æå°å€¼å¹³æ»‘åº¦(minima sharpness)å’Œæ¨¡å‹å¤æ‚åº¦(model complexity)å½±å“ä¼˜åŒ–è¿‡ç¨‹ã€‚åœ¨å¼•ç”¨ç½‘ç»œã€ç”Ÿç‰©åŒ»å­¦æ–‡æœ¬å’Œç”µå­å•†åŠ¡è¯„è®ºä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒHGCNet çš„è¡¨ç°ä¼˜äº GCNã€GATã€PI-GNNã€BERT å’Œ RoBERTa ç­‰å¼ºåŸºçº¿æ¨¡å‹ã€‚åˆ†æç»“æœè¯å®ï¼Œè¾ƒå°çš„ batch size é€šè¿‡å¢åŠ éšæœºæ€§å’Œä¿ƒè¿›æ›´å¹³å¦çš„æå°å€¼ï¼Œåœ¨å› æœå±‚é¢å¢å¼ºäº†æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ã€‚è¿™é¡¹å·¥ä½œä¸ºæ·±åº¦å­¦ä¹ è®­ç»ƒç­–ç•¥æä¾›äº†å¯æ“ä½œçš„è§£é‡Šæ€§æ”¯æŒï¼Œæ¨åŠ¨è§£é‡Šæ€§ç ”ç©¶ä»å•çº¯çš„åéªŒåˆ†æè½¬å‘é©±åŠ¨æ¶æ„ä¸ä¼˜åŒ–é€‰æ‹©ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2506.17826v1",
      "published_date": "2025-06-21 21:38:43 UTC",
      "updated_date": "2025-06-21 21:38:43 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T23:22:06.343886+00:00"
    },
    {
      "arxiv_id": "2506.17823v1",
      "title": "Learning to Dock: A Simulation-based Study on Closing the Sim2Real Gap in Autonomous Underwater Docking",
      "title_zh": "å­¦ä¹ å¯¹æ¥ï¼šç¼©å°æ°´ä¸‹è‡ªä¸»å¯¹æ¥ä¸­ Sim2Real å·®è·çš„ä»¿çœŸç ”ç©¶",
      "authors": [
        "Kevin Chang",
        "Rakesh Vivekanandan",
        "Noah Pragin",
        "Sean Bullock",
        "Geoffrey Hollinger"
      ],
      "abstract": "Autonomous Underwater Vehicle (AUV) docking in dynamic and uncertain environments is a critical challenge for underwater robotics. Reinforcement learning is a promising method for developing robust controllers, but the disparity between training simulations and the real world, or the sim2real gap, often leads to a significant deterioration in performance. In this work, we perform a simulation study on reducing the sim2real gap in autonomous docking through training various controllers and then evaluating them under realistic disturbances. In particular, we focus on the real-world challenge of docking under different payloads that are potentially outside the original training distribution. We explore existing methods for improving robustness including randomization techniques and history-conditioned controllers. Our findings provide insights into mitigating the sim2real gap when training docking controllers. Furthermore, our work indicates areas of future research that may be beneficial to the marine robotics community.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹è‡ªä¸»æ°´ä¸‹èˆªè¡Œå™¨(AUV)åœ¨åŠ¨æ€ä¸ç¡®å®šç¯å¢ƒä¸­çš„å¯¹æ¥æŒ‘æˆ˜ï¼Œå¼€å±•äº†ä¸€é¡¹æ—¨åœ¨ç¼©å°å¼ºåŒ–å­¦ä¹ (Reinforcement learning)æ§åˆ¶å™¨åœ¨æ¨¡æ‹Ÿä¸ç°å®é—´å·®è·(Sim2Real gap)çš„ä»¿çœŸç ”ç©¶ã€‚ç ”ç©¶é‡ç‚¹å…³æ³¨äº†åœ¨è¶…å‡ºåŸå§‹è®­ç»ƒåˆ†å¸ƒçš„ä¸åŒè´Ÿè½½(Payloads)æ¡ä»¶ä¸‹è¿›è¡Œè‡ªä¸»å¯¹æ¥(Autonomous Docking)çš„ç°å®éš¾é¢˜ï¼Œå¹¶å¯¹æ¯”è¯„ä¼°äº†å¤šç§æ§åˆ¶å™¨åœ¨çœŸå®æ‰°åŠ¨ä¸‹çš„è¡¨ç°ã€‚é€šè¿‡æ¢ç´¢éšæœºåŒ–æŠ€æœ¯(Randomization techniques)å’Œå†å²æ¡ä»¶æ§åˆ¶å™¨(History-conditioned controllers)ç­‰å¢å¼ºç¨³å¥æ€§çš„æ–¹æ³•ï¼Œè¯¥å·¥ä½œæ­ç¤ºäº†ç¼“è§£Sim2Realå·®è·çš„å…³é”®è§è§£ã€‚å®éªŒå‘ç°ä¸ºå¼€å‘æ›´å…·é²æ£’æ€§çš„æ°´ä¸‹æœºå™¨äººæ§åˆ¶å™¨æä¾›äº†æŒ‡å¯¼ï¼Œå¹¶æ˜ç¡®äº†æµ·æ´‹æœºå™¨äººé¢†åŸŸæœªæ¥å€¼å¾—æ·±å…¥æ¢ç´¢çš„ç ”ç©¶æ–¹å‘ã€‚",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "Advancing Quantitative and Qualitative Simulators for Marine Applications Workshop Paper at International Conference on Robotics and Automation 2025",
      "pdf_url": "https://arxiv.org/pdf/2506.17823v1",
      "published_date": "2025-06-21 21:32:06 UTC",
      "updated_date": "2025-06-21 21:32:06 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T23:22:09.390277+00:00"
    },
    {
      "arxiv_id": "2506.17818v1",
      "title": "CultureMERT: Continual Pre-Training for Cross-Cultural Music Representation Learning",
      "title_zh": "CultureMERTï¼šé¢å‘è·¨æ–‡åŒ–éŸ³ä¹è¡¨ç¤ºå­¦ä¹ çš„æŒç»­é¢„è®­ç»ƒ",
      "authors": [
        "Angelos-Nikolaos Kanatas",
        "Charilaos Papaioannou",
        "Alexandros Potamianos"
      ],
      "abstract": "Recent advances in music foundation models have improved audio representation learning, yet their effectiveness across diverse musical traditions remains limited. We introduce CultureMERT-95M, a multi-culturally adapted foundation model developed to enhance cross-cultural music representation learning and understanding. To achieve this, we propose a two-stage continual pre-training strategy that integrates learning rate re-warming and re-decaying, enabling stable adaptation even with limited computational resources. Training on a 650-hour multi-cultural data mix, comprising Greek, Turkish, and Indian music traditions, results in an average improvement of 4.9% in ROC-AUC and AP across diverse non-Western music auto-tagging tasks, surpassing prior state-of-the-art, with minimal forgetting on Western-centric benchmarks. We further investigate task arithmetic, an alternative approach to multi-cultural adaptation that merges single-culture adapted models in the weight space. Task arithmetic performs on par with our multi-culturally trained model on non-Western auto-tagging tasks and shows no regression on Western datasets. Cross-cultural evaluation reveals that single-culture models transfer with varying effectiveness across musical traditions, whereas the multi-culturally adapted model achieves the best overall performance. To support research on world music representation learning, we publicly release CultureMERT-95M and CultureMERT-TA-95M, fostering the development of more culturally aware music foundation models.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¨å‡ºäº† CultureMERT-95Mï¼Œè¿™æ˜¯ä¸€ä¸ªæ—¨åœ¨å¢å¼ºè·¨æ–‡åŒ–éŸ³ä¹è¡¨ç¤ºå­¦ä¹ å’Œç†è§£çš„å¤šæ–‡åŒ–é€‚é…åŸºç¡€æ¨¡å‹ï¼Œè§£å†³äº†ç°æœ‰éŸ³ä¹æ¨¡å‹åœ¨å¤šå…ƒéŸ³ä¹ä¼ ç»Ÿä¸­æœ‰æ•ˆæ€§ä¸è¶³çš„é—®é¢˜ã€‚ä½œè€…æå‡ºäº†ä¸€ç§åŒ…å«å­¦ä¹ ç‡é‡æ–°é¢„çƒ­ä¸è¡°å‡çš„ä¸¤é˜¶æ®µæŒç»­é¢„è®­ç»ƒ (Continual Pre-Training) ç­–ç•¥ï¼Œåˆ©ç”¨ 650 å°æ—¶çš„å¸Œè…Šã€åœŸè€³å…¶å’Œå°åº¦å¤šæ–‡åŒ–éŸ³ä¹æ•°æ®å®ç°äº†ç¨³å®šé€‚é…ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ¨¡å‹åœ¨éè¥¿æ–¹éŸ³ä¹è‡ªåŠ¨æ ‡æ³¨ä»»åŠ¡ä¸­çš„ ROC-AUC å’Œ AP å¹³å‡æå‡äº† 4.9%ï¼Œè¶…è¶Šäº†ç°æœ‰æœ€å…ˆè¿›æ¨¡å‹ï¼ŒåŒæ—¶åœ¨è¥¿æ–¹ä¸­å¿ƒåŒ–åŸºå‡†æµ‹è¯•ä¸­ä¿æŒäº†æä½çš„é—å¿˜ç‡ã€‚æ­¤å¤–ï¼Œç ”ç©¶è¿˜æ¢ç´¢äº†åœ¨æƒé‡ç©ºé—´åˆå¹¶å•æ–‡åŒ–æ¨¡å‹çš„ä»»åŠ¡ç®—æœ¯ (Task Arithmetic) æ–¹æ³•ï¼Œè¯æ˜å…¶åœ¨éè¥¿æ–¹ä»»åŠ¡ä¸Šçš„æ€§èƒ½ä¸å¤šæ–‡åŒ–è®­ç»ƒæ¨¡å‹ç›¸å½“ä¸”åœ¨è¥¿æ–¹æ•°æ®é›†ä¸Šæ— é€€åŒ–ã€‚è·¨æ–‡åŒ–è¯„ä¼°è¡¨æ˜å¤šæ–‡åŒ–é€‚é…æ¨¡å‹åœ¨æ•´ä½“è¡¨ç°ä¸Šæœ€ä¸ºä¼˜è¶Šï¼Œç›¸å…³æ¨¡å‹å·²å…¬å¼€å‘å¸ƒä»¥ä¿ƒè¿›å…·æœ‰æ–‡åŒ–æ„ŸçŸ¥åŠ›çš„éŸ³ä¹è¡¨ç¤ºå­¦ä¹ ç ”ç©¶ã€‚",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.LG",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "10 pages, 4 figures, accepted to the 26th International Society for Music Information Retrieval conference (ISMIR 2025), to be held in Daejeon, South Korea",
      "pdf_url": "https://arxiv.org/pdf/2506.17818v1",
      "published_date": "2025-06-21 21:16:39 UTC",
      "updated_date": "2025-06-21 21:16:39 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T23:22:11.073053+00:00"
    },
    {
      "arxiv_id": "2506.19870v1",
      "title": "Secure Energy Transactions Using Blockchain Leveraging AI for Fraud Detection and Energy Market Stability",
      "title_zh": "èåˆäººå·¥æ™ºèƒ½æ¬ºè¯ˆæ£€æµ‹ä¸åŒºå—é“¾æŠ€æœ¯çš„å®‰å…¨èƒ½æºäº¤æ˜“åŠèƒ½æºå¸‚åœºç¨³å®šæ€§",
      "authors": [
        "Md Asif Ul Hoq Khan",
        "MD Zahedul Islam",
        "Istiaq Ahmed",
        "Md Masud Karim Rabbi",
        "Farhana Rahman Anonna",
        "MD Abdul Fahim Zeeshan",
        "Mehedi Hasan Ridoy",
        "Bivash Ranjan Chowdhury",
        "Md Nazmul Shakir Rabbi",
        "GM Alamin Sadnan"
      ],
      "abstract": "Peer-to-peer trading and the move to decentralized grids have reshaped the energy markets in the United States. Notwithstanding, such developments lead to new challenges, mainly regarding the safety and authenticity of energy trade. This study aimed to develop and build a secure, intelligent, and efficient energy transaction system for the decentralized US energy market. This research interlinks the technological prowess of blockchain and artificial intelligence (AI) in a novel way to solve long-standing challenges in the distributed energy market, specifically those of security, fraudulent behavior detection, and market reliability. The dataset for this research is comprised of more than 1.2 million anonymized energy transaction records from a simulated peer-to-peer (P2P) energy exchange network emulating real-life blockchain-based American microgrids, including those tested by LO3 Energy and Grid+ Labs. Each record contains detailed fields of transaction identifier, timestamp, energy volume (kWh), transaction type (buy/sell), unit price, prosumer/consumer identifier (hashed for privacy), smart meter readings, geolocation regions, and settlement confirmation status. The dataset also includes system-calculated behavior metrics of transaction rate, variability of energy production, and historical pricing patterns. The system architecture proposed involves the integration of two layers, namely a blockchain layer and artificial intelligence (AI) layer, each playing a unique but complementary function in energy transaction securing and market intelligence improvement. The machine learning models used in this research were specifically chosen for their established high performance in classification tasks, specifically in the identification of energy transaction fraud in decentralized markets.",
      "tldr_zh": "è¿™é¡¹ç ”ç©¶é’ˆå¯¹ç¾å›½å»ä¸­å¿ƒåŒ–èƒ½æºå¸‚åœºä¸­Peer-to-peer (P2P)äº¤æ˜“é¢ä¸´çš„å®‰å…¨ä¸çœŸå®æ€§æŒ‘æˆ˜ï¼Œæå‡ºäº†ä¸€ç§ç»“åˆBlockchainä¸Artificial Intelligence (AI)çš„åˆ›æ–°èƒ½æºäº¤æ˜“ç³»ç»Ÿã€‚è¯¥ç³»ç»Ÿé€šè¿‡æ•´åˆBlockchainå±‚ä¸AIå±‚ï¼Œæ—¨åœ¨è§£å†³åˆ†å¸ƒå¼èƒ½æºå¸‚åœºä¸­é•¿æœŸå­˜åœ¨çš„å®‰å…¨æ€§ã€æ¬ºè¯ˆè¡Œä¸ºæ£€æµ‹ä»¥åŠå¸‚åœºå¯é æ€§é—®é¢˜ã€‚ç ”ç©¶åˆ©ç”¨äº†åŒ…å«è¶…è¿‡120ä¸‡æ¡åŒ¿ååŒ–è®°å½•çš„æ¨¡æ‹Ÿæ•°æ®é›†ï¼Œè¯¥æ•°æ®é›†æ·±åº¦æ¨¡æ‹Ÿäº†å¦‚LO3 Energyå’ŒGrid+ Labsæ‰€æµ‹è¯•çš„çœŸå®ç¾å›½å¾®ç”µç½‘äº¤æ˜“ç¯å¢ƒã€‚é€šè¿‡åˆ†æèƒ½é‡ä½“ç§¯(energy volume)ã€æ™ºèƒ½ç”µè¡¨è¯»æ•°(smart meter readings)ä»¥åŠç³»ç»Ÿè®¡ç®—çš„äº¤æ˜“é¢‘ç‡ä¸ä»·æ ¼æ¨¡å¼ç­‰å…³é”®æŒ‡æ ‡ï¼ŒAIå±‚çš„æœºå™¨å­¦ä¹ æ¨¡å‹èƒ½å¤Ÿé«˜æ•ˆæ‰§è¡Œåˆ†ç±»ä»»åŠ¡ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ¶æ„èƒ½æœ‰æ•ˆè¯†åˆ«å»ä¸­å¿ƒåŒ–å¸‚åœºä¸­çš„èƒ½æºäº¤æ˜“æ¬ºè¯ˆï¼Œä¸ºæ„å»ºå®‰å…¨ã€æ™ºèƒ½ä¸”é«˜æ•ˆçš„åˆ†å¸ƒå¼èƒ½æºäº¤æ˜“ä½“ç³»æä¾›äº†é‡è¦çš„æŠ€æœ¯æ”¯æ’‘ã€‚",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2506.19870v1",
      "published_date": "2025-06-21 21:09:29 UTC",
      "updated_date": "2025-06-21 21:09:29 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T23:22:47.129469+00:00"
    },
    {
      "arxiv_id": "2506.17811v2",
      "title": "RoboMonkey: Scaling Test-Time Sampling and Verification for Vision-Language-Action Models",
      "title_zh": "RoboMonkeyï¼šé¢å‘è§†è§‰-è¯­è¨€-åŠ¨ä½œæ¨¡å‹çš„æµ‹è¯•æ—¶é‡‡æ ·ä¸éªŒè¯è§„æ¨¡åŒ–",
      "authors": [
        "Jacky Kwok",
        "Christopher Agia",
        "Rohan Sinha",
        "Matt Foutter",
        "Shulu Li",
        "Ion Stoica",
        "Azalia Mirhoseini",
        "Marco Pavone"
      ],
      "abstract": "Vision-Language-Action (VLA) models have demonstrated remarkable capabilities in visuomotor control, yet ensuring their robustness in unstructured real-world environments remains a persistent challenge. In this paper, we investigate test-time scaling through the lens of sampling and verification as means to enhance the robustness and generalization of VLAs. We first demonstrate that the relationship between action error and the number of generated samples follows an exponentiated power law across a range of VLAs, indicating the existence of inference-time scaling laws. Building on these insights, we introduce RoboMonkey, a test-time scaling framework for VLAs. At deployment, RoboMonkey samples a small set of actions from a VLA, applies Gaussian perturbation and majority voting to construct an action proposal distribution, and then uses a Vision Language Model (VLM)-based verifier to select the optimal action. We propose a synthetic data generation pipeline for training such VLM-based action verifiers, and demonstrate that scaling the synthetic dataset consistently improves verification and downstream accuracy. Through extensive simulated and hardware experiments, we show that pairing existing VLAs with RoboMonkey yields significant performance gains, achieving a 25% absolute improvement on out-of-distribution tasks and 9% on in-distribution tasks. Additionally, when adapting to new robot setups, we show that fine-tuning both VLAs and action verifiers yields a 7% performance increase compared to fine-tuning VLAs alone.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹è§†è§‰-è¯­è¨€-åŠ¨ä½œæ¨¡å‹(Vision-Language-Action Models, VLAs)åœ¨éç»“æ„åŒ–ç°å®ç¯å¢ƒä¸­çš„é²æ£’æ€§æŒ‘æˆ˜ï¼Œæ·±å…¥æ¢è®¨äº†é€šè¿‡æ¨ç†æ—¶é‡‡æ ·ä¸éªŒè¯æ¥å®ç°æ‰©å±•(test-time scaling)çš„å¯èƒ½æ€§ã€‚ç ”ç©¶é¦–å…ˆæ­ç¤ºäº†åœ¨å„ç±»VLAsä¸­ï¼ŒåŠ¨ä½œè¯¯å·®ä¸ç”Ÿæˆçš„æ ·æœ¬æ•°é‡ä¹‹é—´éµå¾ªæŒ‡æ•°å¹‚å®šå¾‹(exponentiated power law)ï¼Œè¯æ˜äº†æ¨ç†æ—¶æ‰©å±•è§„å¾‹çš„å­˜åœ¨ã€‚åŸºäºæ­¤å‘ç°ï¼Œä½œè€…æå‡ºäº†RoboMonkeyæ¡†æ¶ï¼Œè¯¥æ¡†æ¶é€šè¿‡ä»VLAä¸­é‡‡æ ·å°‘é‡åŠ¨ä½œï¼Œç»“åˆé«˜æ–¯æ‰°åŠ¨(Gaussian perturbation)å’Œå¤šæ•°æŠ•ç¥¨æ³•æ„å»ºåŠ¨ä½œææ¡ˆåˆ†å¸ƒï¼Œå¹¶åˆ©ç”¨åŸºäºè§†è§‰è¯­è¨€æ¨¡å‹(VLM)çš„éªŒè¯å™¨ç­›é€‰æœ€ä¼˜åŠ¨ä½œã€‚æ­¤å¤–ï¼Œç ”ç©¶è¿˜æå‡ºäº†ç”¨äºè®­ç»ƒéªŒè¯å™¨çš„åˆæˆæ•°æ®ç”Ÿæˆæµæ°´çº¿ï¼Œå¹¶è¯å®å¢åŠ åˆæˆæ•°æ®è§„æ¨¡èƒ½æŒç»­æå‡éªŒè¯ç²¾åº¦ã€‚å®éªŒè¡¨æ˜ï¼ŒRoboMonkeyåœ¨åˆ†å¸ƒå¤–(out-of-distribution)ä»»åŠ¡å’Œåˆ†å¸ƒå†…ä»»åŠ¡ä¸Šåˆ†åˆ«å®ç°äº†25%å’Œ9%çš„ç»å¯¹æ€§èƒ½æå‡ã€‚åœ¨é€‚é…æ–°æœºå™¨äººç¯å¢ƒæ—¶ï¼ŒåŒæ—¶å¾®è°ƒVLAä¸éªŒè¯å™¨çš„æ•ˆæœæ¯”ä»…å¾®è°ƒVLAæå‡äº†7%ï¼Œä¸ºå¢å¼ºæœºå™¨äººæ“ä½œçš„æ³›åŒ–èƒ½åŠ›æä¾›äº†æœ‰æ•ˆè·¯å¾„ã€‚",
      "categories": [
        "cs.RO",
        "cs.AI",
        "eess.SY"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2506.17811v2",
      "published_date": "2025-06-21 20:56:17 UTC",
      "updated_date": "2025-07-07 02:08:10 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T23:22:17.757052+00:00"
    },
    {
      "arxiv_id": "2506.17807v1",
      "title": "Reimagining Parameter Space Exploration with Diffusion Models",
      "title_zh": "åŸºäºæ‰©æ•£æ¨¡å‹çš„å‚æ•°ç©ºé—´æ¢ç´¢æ–°æ„æƒ³",
      "authors": [
        "Lijun Zhang",
        "Xiao Liu",
        "Hui Guan"
      ],
      "abstract": "Adapting neural networks to new tasks typically requires task-specific fine-tuning, which is time-consuming and reliant on labeled data. We explore a generative alternative that produces task-specific parameters directly from task identity, eliminating the need for task-specific training. To this end, we propose using diffusion models to learn the underlying structure of effective task-specific parameter space and synthesize parameters on demand. Once trained, the task-conditioned diffusion model can generate specialized weights directly from task identifiers. We evaluate this approach across three scenarios: generating parameters for a single seen task, for multiple seen tasks, and for entirely unseen tasks. Experiments show that diffusion models can generate accurate task-specific parameters and support multi-task interpolation when parameter subspaces are well-structured, but fail to generalize to unseen tasks, highlighting both the potential and limitations of this generative solution.",
      "tldr_zh": "è¿™é¡¹ç ”ç©¶æ¢ç´¢äº†åˆ©ç”¨æ‰©æ•£æ¨¡å‹(Diffusion Models)åœ¨å‚æ•°ç©ºé—´è¿›è¡Œæ¢ç´¢çš„æ–°æ–¹æ³•ï¼Œæ—¨åœ¨é€šè¿‡ä»»åŠ¡æ ‡è¯†ç›´æ¥ç”Ÿæˆç‰¹å®šä»»åŠ¡çš„ç¥ç»ç½‘ç»œå‚æ•°ï¼Œä»è€Œæ¶ˆé™¤ä¼ ç»Ÿå¾®è°ƒ(fine-tuning)è¿‡ç¨‹å¯¹æ—¶é—´å’Œæ ‡æ³¨æ•°æ®çš„ä¾èµ–ã€‚ä½œè€…æå‡ºä½¿ç”¨æ‰©æ•£æ¨¡å‹å­¦ä¹ æœ‰æ•ˆå‚æ•°ç©ºé—´çš„åº•å±‚ç»“æ„ï¼Œå¹¶æ ¹æ®ä»»åŠ¡æ¡ä»¶æŒ‰éœ€åˆæˆä¸“é—¨çš„æƒé‡ã€‚è¯¥æ–¹æ³•åœ¨å•ä¸€å·²çŸ¥ä»»åŠ¡ã€å¤šé¡¹å·²çŸ¥ä»»åŠ¡åŠå…¨æ–°æœªçŸ¥ä»»åŠ¡ä¸‰ç§åœºæ™¯ä¸‹è¿›è¡Œäº†å®éªŒè¯„ä¼°ã€‚ç»“æœè¯æ˜ï¼Œåœ¨å‚æ•°å­ç©ºé—´ç»“æ„è‰¯å¥½çš„æƒ…å†µä¸‹ï¼Œæ‰©æ•£æ¨¡å‹èƒ½å¤Ÿå‡†ç¡®ç”Ÿæˆä»»åŠ¡ç‰¹å®šå‚æ•°å¹¶æ”¯æŒå¤šä»»åŠ¡æ’å€¼(multi-task interpolation)ï¼Œä½†åœ¨æ³›åŒ–è‡³å®Œå…¨æœªçŸ¥ä»»åŠ¡æ—¶ä»é¢ä¸´æŒ‘æˆ˜ã€‚è¯¥ç ”ç©¶é€šè¿‡è¿™ä¸€ç”Ÿæˆå¼æ–¹æ¡ˆæ­ç¤ºäº†å‚æ•°ç©ºé—´æ¢ç´¢çš„å·¨å¤§æ½œåŠ›ï¼ŒåŒæ—¶ä¹Ÿæ˜ç¡®äº†å…¶ç›®å‰çš„æ³›åŒ–å±€é™æ€§ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at ICML 2025 EXAIT Workshop",
      "pdf_url": "https://arxiv.org/pdf/2506.17807v1",
      "published_date": "2025-06-21 20:30:17 UTC",
      "updated_date": "2025-06-21 20:30:17 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T23:22:25.949992+00:00"
    },
    {
      "arxiv_id": "2506.17792v1",
      "title": "Efficient Strategy Synthesis for MDPs via Hierarchical Block Decomposition",
      "title_zh": "åŸºäºåˆ†å±‚å—åˆ†è§£çš„é«˜æ•ˆ MDP ç­–ç•¥åˆæˆ",
      "authors": [
        "Alexandros Evangelidis",
        "Gricel VÃ¡zquez",
        "Simos Gerasimou"
      ],
      "abstract": "Software-intensive systems, such as software product lines and robotics, utilise Markov decision processes (MDPs) to capture uncertainty and analyse sequential decision-making problems. Despite the usefulness of conventional policy synthesis methods, they fail to scale to large state spaces. Our approach addresses this issue and accelerates policy synthesis in large MDPs by dynamically refining the MDP and iteratively selecting the most fragile MDP regions for refinement. This iterative procedure offers a balance between accuracy and efficiency, as refinement occurs only when necessary. Through a comprehensive empirical evaluation comprising diverse case studies and MDPs up to 1M states, we demonstrate significant performance improvements yielded by our approach compared to the leading probabilistic model checker PRISM (up to 2x), thus offering a very competitive solution for real-world policy synthesis tasks in larger MDPs.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹è½¯ä»¶å¯†é›†å‹ç³»ç»Ÿï¼ˆå¦‚æœºå™¨äººæŠ€æœ¯ï¼‰ä¸­ Markov decision processes (MDPs) ç­–ç•¥åˆæˆåœ¨å¤§è§„æ¨¡çŠ¶æ€ç©ºé—´ä¸‹éš¾ä»¥æ‰©å±•çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§åŸºäº Hierarchical Block Decomposition çš„é«˜æ•ˆç­–ç•¥åˆæˆæ–¹æ³•ã€‚è¯¥æ–¹æ³•é€šè¿‡åŠ¨æ€ç»†åŒ– MDP å¹¶è¿­ä»£é€‰æ‹©æœ€è„†å¼±çš„åŒºåŸŸè¿›è¡Œå¤„ç†ï¼Œåœ¨ç¡®ä¿å‡†ç¡®æ€§çš„å‰æä¸‹æ˜¾è‘—æå‡äº†è¿ç®—æ•ˆç‡ã€‚é€šè¿‡å¯¹åŒ…å«å¤šè¾¾ 100 ä¸‡ä¸ªçŠ¶æ€çš„å¤šç§æ¡ˆä¾‹è¿›è¡Œå®è¯è¯„ä¼°ï¼Œå®éªŒç»“æœæ˜¾ç¤ºè¯¥æ–¹æ³•ç›¸è¾ƒäºé¢†å…ˆçš„æ¦‚ç‡æ¨¡å‹æ£€æŸ¥å™¨ PRISM å®ç°äº†é«˜è¾¾ 2 å€çš„æ€§èƒ½æå‡ã€‚è¯¥ç ”ç©¶ä¸ºå¤„ç†å¤§è§„æ¨¡ MDPs ä¸­çš„ç°å®ç­–ç•¥åˆæˆä»»åŠ¡æä¾›äº†ä¸€ç§æå…·ç«äº‰åŠ›çš„è§£å†³æ–¹æ¡ˆï¼Œæœ‰æ•ˆç¼“è§£äº†ä¼ ç»Ÿæ–¹æ³•åœ¨å¤æ‚ç³»ç»Ÿå»ºæ¨¡ä¸­çš„æ€§èƒ½ç“¶é¢ˆã€‚",
      "categories": [
        "cs.AI",
        "cs.LO",
        "cs.SE"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2506.17792v1",
      "published_date": "2025-06-21 19:03:03 UTC",
      "updated_date": "2025-06-21 19:03:03 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T23:22:41.545382+00:00"
    },
    {
      "arxiv_id": "2506.17788v1",
      "title": "Bayesian Social Deduction with Graph-Informed Language Models",
      "title_zh": "åŸºäºå›¾å¢å¼ºè¯­è¨€æ¨¡å‹çš„è´å¶æ–¯ç¤¾ä¼šæ¼”ç»",
      "authors": [
        "Shahab Rahimirad",
        "Guven Gergerli",
        "Lucia Romero",
        "Angela Qian",
        "Matthew Lyle Olson",
        "Simon Stepputtis",
        "Joseph Campbell"
      ],
      "abstract": "Social reasoning - inferring unobservable beliefs and intentions from partial observations of other agents - remains a challenging task for large language models (LLMs). We evaluate the limits of current reasoning language models in the social deduction game Avalon and find that while the largest models demonstrate strong performance, they require extensive test-time inference and degrade sharply when distilled to smaller, real-time-capable variants. To address this, we introduce a hybrid reasoning framework that externalizes belief inference to a structured probabilistic model, while using an LLM for language understanding and interaction. Our approach achieves competitive performance with much larger models in Agent-Agent play and, notably, is the first language agent to defeat human players in a controlled study - achieving a 67% win rate and receiving higher qualitative ratings than both reasoning baselines and human teammates. We release code, models, and a dataset to support future work on social reasoning in LLM agents, which can be found at https://camp-lab-purdue.github.io/bayesian-social-deduction/",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§å‹è¯­è¨€æ¨¡å‹(LLMs)åœ¨ç¤¾äº¤åšå¼ˆã€Šé˜¿ç“¦éš†ã€‹(Avalon)ä¸­è¿›è¡Œç¤¾äº¤æ¨ç†(Social reasoning)çš„å±€é™æ€§ï¼ŒæŒ‡å‡ºäº†ç°æœ‰æ¨ç†æ¨¡å‹åœ¨æµ‹è¯•æ—¶ç®—åŠ›éœ€æ±‚é«˜ä¸”åœ¨æ¨¡å‹è’¸é¦åæ€§èƒ½é€€åŒ–ä¸¥é‡çš„é—®é¢˜ã€‚ä¸ºæ­¤ï¼Œä½œè€…æå‡ºäº†ä¸€ç§æ··åˆæ¨ç†æ¡†æ¶ï¼Œå°†ä¿¡å¿µæ¨ç†(Belief inference)å¤–éƒ¨åŒ–è‡³ç»“æ„åŒ–æ¦‚ç‡æ¨¡å‹(Probabilistic model)ï¼ŒåŒæ—¶åˆ©ç”¨LLMè´Ÿè´£è¯­è¨€ç†è§£ä¸äº¤äº’ã€‚è¯¥æ–¹æ³•åœ¨æ™ºèƒ½ä½“åšå¼ˆä¸­å®ç°äº†ä¸è¶…å¤§è§„æ¨¡æ¨¡å‹ç›¸å½“çš„æ€§èƒ½ï¼Œå¹¶æˆä¸ºé¦–ä¸ªåœ¨å—æ§å®éªŒä¸­å‡»è´¥äººç±»ç©å®¶çš„è¯­è¨€æ™ºèƒ½ä½“ï¼Œèƒœç‡é«˜è¾¾67%ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ¨¡å‹åœ¨å®šæ€§è¯„ä¼°ä¸Šä¸ä»…ä¼˜äºæ¨ç†åŸºçº¿ï¼Œç”šè‡³è¶…è¿‡äº†äººç±»é˜Ÿå‹ã€‚ç ”ç©¶å›¢é˜Ÿé€šè¿‡å‘å¸ƒä»£ç ã€æ¨¡å‹å’Œæ•°æ®é›†ï¼Œä¸ºæœªæ¥å¤§å‹è¯­è¨€æ¨¡å‹åœ¨å¤æ‚ç¤¾äº¤æ¨ç†æ–¹é¢çš„ç ”ç©¶æä¾›äº†æœ‰åŠ›æ”¯æŒã€‚",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG",
        "cs.MA"
      ],
      "primary_category": "cs.AI",
      "comment": "32 pages, 10 figures. Under review",
      "pdf_url": "https://arxiv.org/pdf/2506.17788v1",
      "published_date": "2025-06-21 18:45:28 UTC",
      "updated_date": "2025-06-21 18:45:28 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T23:22:37.753600+00:00"
    },
    {
      "arxiv_id": "2506.18932v1",
      "title": "AI Safety vs. AI Security: Demystifying the Distinction and Boundaries",
      "title_zh": "AI Safety ä¸ AI Securityï¼šæ·±åº¦å˜æ¸…ä¸¤è€…çš„æ¦‚å¿µåŒºåˆ«ä¸ç ”ç©¶è¾¹ç•Œ",
      "authors": [
        "Zhiqiang Lin",
        "Huan Sun",
        "Ness Shroff"
      ],
      "abstract": "Artificial Intelligence (AI) is rapidly being integrated into critical systems across various domains, from healthcare to autonomous vehicles. While its integration brings immense benefits, it also introduces significant risks, including those arising from AI misuse. Within the discourse on managing these risks, the terms \"AI Safety\" and \"AI Security\" are often used, sometimes interchangeably, resulting in conceptual confusion. This paper aims to demystify the distinction and delineate the precise research boundaries between AI Safety and AI Security. We provide rigorous definitions, outline their respective research focuses, and explore their interdependency, including how security breaches can precipitate safety failures and vice versa. Using clear analogies from message transmission and building construction, we illustrate these distinctions. Clarifying these boundaries is crucial for guiding precise research directions, fostering effective cross-disciplinary collaboration, enhancing policy effectiveness, and ultimately, promoting the deployment of trustworthy AI systems.",
      "tldr_zh": "è¯¥ç ”ç©¶æ·±å…¥æ¢è®¨äº† AI Safety ä¸ AI Security ä¹‹é—´çš„æ ¸å¿ƒåŒºåˆ«ä¸ç•Œé™ï¼Œæ—¨åœ¨è§£å†³ç›®å‰åœ¨äººå·¥æ™ºèƒ½é£é™©ç®¡ç†é¢†åŸŸä¸­è¿™ä¸¤ä¸ªæœ¯è¯­è¢«æ··ç”¨è€Œäº§ç”Ÿçš„æ¦‚å¿µæ¨¡ç³Šé—®é¢˜ã€‚è®ºæ–‡ä¸º AI Safety å’Œ AI Security æä¾›äº†ä¸¥è°¨çš„å­¦æœ¯å®šä¹‰ï¼Œå¹¶è¯¦ç»†å‹¾å‹’äº†å„è‡ªç‹¬ç«‹çš„ç ”ç©¶èŒƒç•´ä¸ä¾§é‡ç‚¹ã€‚é€šè¿‡ä¿¡æ¯ä¼ è¾“å’Œå»ºç­‘æ–½å·¥ç­‰ç›´è§‚ç±»æ¯”ï¼Œç ”ç©¶æ­ç¤ºäº†ä¸¤è€…çš„ç›¸äº’ä¾èµ–å…³ç³»ï¼Œå¹¶æ·±å…¥åˆ†æäº†å®‰å…¨æ¼æ´ï¼ˆSecurity breachesï¼‰ä¸å®‰å…¨æ€§æ•…éšœï¼ˆSafety failuresï¼‰å¦‚ä½•ç›¸äº’è¯±å‘ã€‚è¿™é¡¹å·¥ä½œå¯¹äºæŒ‡å¯¼ç²¾å‡†çš„ç§‘ç ”æ–¹å‘ã€ä¿ƒè¿›æœ‰æ•ˆçš„è·¨å­¦ç§‘åä½œä»¥åŠæå‡æ”¿ç­–åˆ¶å®šçš„é’ˆå¯¹æ€§å…·æœ‰é‡è¦æ„ä¹‰ï¼Œä»è€Œæœ‰æ•ˆæ¨åŠ¨äº†å¯ä¿¡äººå·¥æ™ºèƒ½ï¼ˆTrustworthy AIï¼‰ç³»ç»Ÿçš„å¼€å‘ä¸å®‰å…¨éƒ¨ç½²ã€‚",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2506.18932v1",
      "published_date": "2025-06-21 18:36:03 UTC",
      "updated_date": "2025-06-21 18:36:03 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T23:22:56.671470+00:00"
    },
    {
      "arxiv_id": "2506.17784v2",
      "title": "AnyMAC: Cascading Flexible Multi-Agent Collaboration via Next-Agent Prediction",
      "title_zh": "AnyMACï¼šåŸºäºä¸‹ä¸€æ™ºèƒ½ä½“é¢„æµ‹çš„çº§è”å¼çµæ´»å¤šæ™ºèƒ½ä½“åä½œ",
      "authors": [
        "Song Wang",
        "Zhen Tan",
        "Zihan Chen",
        "Shuang Zhou",
        "Tianlong Chen",
        "Jundong Li"
      ],
      "abstract": "Recent progress in large language model (LLM)-based multi-agent collaboration highlights the power of structured communication in enabling collective intelligence. However, existing methods largely rely on static or graph-based inter-agent topologies, lacking the potential adaptability and flexibility in communication. In this work, we propose a new framework that rethinks multi-agent coordination through a sequential structure rather than a graph structure, offering a significantly larger topology space for multi-agent communication. Our method focuses on two key directions: (1) Next-Agent Prediction, which selects the most suitable agent role at each step, and (2) Next-Context Selection (NCS), which enables each agent to selectively access relevant information from any previous step. Together, these components construct task-adaptive communication pipelines that support both role flexibility and global information flow. Extensive evaluations across multiple benchmarks demonstrate that our approach achieves superior performance while substantially reducing communication overhead.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† AnyMACï¼Œè¿™æ˜¯ä¸€ä¸ªé€šè¿‡ä¸‹ä¸€æ™ºèƒ½ä½“é¢„æµ‹ (Next-Agent Prediction) å®ç°å±‚å å¼çµæ´»å¤šæ™ºèƒ½ä½“åä½œçš„æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³ç°æœ‰å¤§è¯­è¨€æ¨¡å‹ (LLM) å¤šæ™ºèƒ½ä½“ç³»ç»Ÿä¸­é™æ€æˆ–åŸºäºå›¾çš„æ‹“æ‰‘ç»“æ„ç¼ºä¹é€‚åº”æ€§çš„é—®é¢˜ã€‚è¯¥æ¡†æ¶å°†å¤šæ™ºèƒ½ä½“åè°ƒé‡æ–°æ„æƒ³ä¸ºåºåˆ—ç»“æ„è€Œéå›¾ç»“æ„ï¼Œä»è€Œä¸ºé€šä¿¡æä¾›äº†æ˜¾è‘—æ›´å¤§çš„æ‹“æ‰‘ç©ºé—´ã€‚å…¶æ ¸å¿ƒåŒ…å«ä¸¤ä¸ªå…³é”®æ–¹å‘ï¼šä¸€æ˜¯ Next-Agent Predictionï¼Œç”¨äºåœ¨æ¯ä¸€æ­¥é€‰æ‹©æœ€åˆé€‚çš„æ™ºèƒ½ä½“è§’è‰²ï¼›äºŒæ˜¯ä¸‹ä¸€ä¸Šä¸‹æ–‡é€‰æ‹© (Next-Context Selection, NCS)ï¼Œä½¿æ™ºèƒ½ä½“èƒ½é€‰æ‹©æ€§åœ°è®¿é—®å†å²æ­¥éª¤ä¸­çš„ç›¸å…³ä¿¡æ¯ã€‚é€šè¿‡è¿™ä¸¤ä¸ªç»„ä»¶ï¼ŒAnyMAC æ„å»ºäº†æ”¯æŒè§’è‰²çµæ´»æ€§å’Œå…¨å±€ä¿¡æ¯æµçš„ä»»åŠ¡è‡ªé€‚åº”é€šä¿¡ç®¡é“ã€‚åœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸Šçš„è¯„ä¼°ç»“æœæ˜¾ç¤ºï¼Œè¯¥æ–¹æ³•åœ¨æ˜¾è‘—é™ä½é€šä¿¡å¼€é”€çš„åŒæ—¶ï¼Œå–å¾—äº†ä¼˜è¶Šçš„æ€§èƒ½è¡¨ç°ï¼Œä¸ºå®ç°æ›´é«˜æ•ˆã€çµæ´»çš„é›†ä½“æ™ºèƒ½æä¾›äº†æ–°è·¯å¾„ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "EMNLP Main 2025",
      "pdf_url": "https://arxiv.org/pdf/2506.17784v2",
      "published_date": "2025-06-21 18:34:43 UTC",
      "updated_date": "2025-11-01 22:45:02 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T23:22:43.852633+00:00"
    },
    {
      "arxiv_id": "2506.17782v1",
      "title": "Expanding Relevance Judgments for Medical Case-based Retrieval Task with Multimodal LLMs",
      "title_zh": "åˆ©ç”¨å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹æ‰©å±•åŒ»å­¦ç—…ä¾‹æ£€ç´¢ä»»åŠ¡çš„ç›¸å…³æ€§åˆ¤å®š",
      "authors": [
        "Catarina Pires",
        "SÃ©rgio Nunes",
        "LuÃ­s Filipe Teixeira"
      ],
      "abstract": "Evaluating Information Retrieval (IR) systems relies on high-quality manual relevance judgments (qrels), which are costly and time-consuming to obtain. While pooling reduces the annotation effort, it results in only partially labeled datasets. Large Language Models (LLMs) offer a promising alternative to reducing reliance on manual judgments, particularly in complex domains like medical case-based retrieval, where relevance assessment requires analyzing both textual and visual information. In this work, we explore using a Multimodal Large Language Model (MLLM) to expand relevance judgments, creating a new dataset of automated judgments. Specifically, we employ Gemini 1.5 Pro on the ImageCLEFmed 2013 case-based retrieval task, simulating human assessment through an iteratively refined, structured prompting strategy that integrates binary scoring, instruction-based evaluation, and few-shot learning. We systematically experimented with various prompt configurations to maximize agreement with human judgments. To evaluate agreement between the MLLM and human judgments, we use Cohen's Kappa, achieving a substantial agreement score of 0.6, comparable to inter-annotator agreement typically observed in multimodal retrieval tasks. Starting from the original 15,028 manual judgments (4.72% relevant) across 35 topics, our MLLM-based approach expanded the dataset by over 37x to 558,653 judgments, increasing relevant annotations to 5,950. On average, each medical case query received 15,398 new annotations, with approximately 99% being non-relevant, reflecting the high sparsity typical in this domain. Our results demonstrate the potential of MLLMs to scale relevance judgment collection, offering a promising direction for supporting retrieval evaluation in medical and multimodal IR tasks.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†åˆ©ç”¨å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹(Multimodal Large Language Models, MLLMs)æ‰©å±•åŒ»ç–—æ¡ˆä¾‹æ£€ç´¢ä»»åŠ¡ä¸­çš„ç›¸å…³æ€§åˆ¤åˆ«(Relevance Judgments)ï¼Œæ—¨åœ¨è§£å†³æ‰‹åŠ¨æ ‡æ³¨æˆæœ¬é«˜æ˜‚ä¸”è€—æ—¶çš„é—®é¢˜ã€‚ç ”ç©¶äººå‘˜åœ¨ImageCLEFmed 2013æ¡ˆä¾‹æ£€ç´¢ä»»åŠ¡ä¸­é‡‡ç”¨äº†Gemini 1.5 Proï¼Œé€šè¿‡ç»“åˆäºŒå€¼æ‰“åˆ†ã€åŸºäºæŒ‡ä»¤çš„è¯„ä¼°å’Œå°‘æ ·æœ¬å­¦ä¹ (Few-shot Learning)çš„ç»“æ„åŒ–æç¤ºç­–ç•¥æ¥æ¨¡æ‹Ÿäººå·¥è¯„ä¼°ã€‚å®éªŒè¡¨æ˜ï¼Œè¯¥æ¨¡å‹ä¸äººå·¥åˆ¤æ–­ä¹‹é—´çš„Cohen's Kappaç³»æ•°è¾¾åˆ°0.6ï¼Œè¡¨ç°å‡ºæ˜¾è‘—çš„ä¸€è‡´æ€§ï¼Œä¸å¤šæ¨¡æ€æ£€ç´¢é¢†åŸŸçš„äººé™…æ ‡æ³¨æ°´å¹³ç›¸å½“ã€‚é€šè¿‡è¯¥æ–¹æ³•ï¼Œæ•°æ®é›†è§„æ¨¡ä»åŸå§‹çš„15,028æ¡äººå·¥åˆ¤æ–­æ‰©å±•äº†37å€ä»¥ä¸Šï¼Œæœ€ç»ˆç”Ÿæˆäº†558,653æ¡è‡ªåŠ¨åˆ¤å®šç»“æœï¼Œæœ‰æ•ˆç¼“è§£äº†åŒ»å­¦é¢†åŸŸæ ‡æ³¨ç¨€ç–çš„é—®é¢˜ã€‚è¯¥æˆæœè¯æ˜äº†MLLMsåœ¨å¤§è§„æ¨¡æ‰©å±•ç›¸å…³æ€§åˆ¤åˆ«æ–¹é¢çš„å·¨å¤§æ½œåŠ›ï¼Œä¸ºåŒ»ç–—åŠå¤šæ¨¡æ€ä¿¡æ¯æ£€ç´¢(Information Retrieval, IR)ç³»ç»Ÿçš„è¯„ä¼°æä¾›äº†æ–°çš„æ–¹å‘ã€‚",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "To appear at the Third Workshop on Large Language Models for Evaluation in Information Retrieval (LLM4Eval 2025), co-located with SIGIR 2025. 9 pages, 2 figures, 5 tables",
      "pdf_url": "https://arxiv.org/pdf/2506.17782v1",
      "published_date": "2025-06-21 18:29:33 UTC",
      "updated_date": "2025-06-21 18:29:33 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T23:23:14.824873+00:00"
    },
    {
      "arxiv_id": "2506.17779v1",
      "title": "Toward Autonomous UI Exploration: The UIExplorer Benchmark",
      "title_zh": "è¿ˆå‘è‡ªä¸» UI æ¢ç´¢ï¼šUIExplorer è¯„æµ‹åŸºå‡†",
      "authors": [
        "Andrei Cristian Nica",
        "Akshaya Vishnu Kudlu Shanbhogue",
        "Harshil Shah",
        "Aleix Cambray",
        "Tudor Berariu",
        "Lucas Maystre",
        "David Barber"
      ],
      "abstract": "Autonomous agents must know how to explore user interfaces (UIs) for reliable task solving, yet systematic evaluation of this crucial phase is lacking. We introduce UIExplore-Bench, the first benchmark explicitly dedicated to UI exploration. The benchmark evaluates agents with either Structured mode (granting access to layout information like DOM trees) or Screen mode (relying on GUI-only observations such as screenshots and human-like mouse/keyboard interactions) across three levels in a standardized GitLab sandbox environment. We formalize exploration as the process of maximizing the set of actionable UI components discovered and propose a metric, human-normalized UI-Functionalities Observed (hUFO), to quantify the effectiveness of exploration. Our results show that UIExplore-AlGo achieves the leading mean hUFO scores, reaching up to 77.2% of human performance in Structured mode and 59.0% in Screen mode at 2,000 steps, particularly excelling at the Sparse level. The results highlight the relevance of our benchmark, as current agents show a substantial performance gap compared to one hour of human expert exploration, indicating ample room for future advancements. We publicly release the benchmark environment, an exploration dataset, and an evaluation suite to catalyze research into efficient UI exploration strategies and their downstream applications, such as experience-driven task completion and automated training data generation.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹è‡ªä¸»æ™ºèƒ½ä½“åœ¨ç”¨æˆ·ç•Œé¢ï¼ˆUIï¼‰æ¢ç´¢æ–¹é¢ç¼ºä¹ç³»ç»Ÿæ€§è¯„ä¼°çš„é—®é¢˜ï¼Œæå‡ºäº†é¦–ä¸ªä¸“é—¨ç”¨äº UI æ¢ç´¢çš„åŸºå‡†æµ‹è¯• UIExplore-Benchã€‚è¯¥åŸºå‡†æµ‹è¯•åœ¨æ ‡å‡†åŒ–çš„ GitLab æ²™ç›’ç¯å¢ƒä¸­ï¼Œé€šè¿‡ Structured modeï¼ˆè®¿é—® DOM æ ‘ç­‰å¸ƒå±€ä¿¡æ¯ï¼‰å’Œ Screen modeï¼ˆä»…ä¾èµ–æˆªå›¾å’Œç±»äººäº¤äº’ï¼‰ä¸¤ç§æ¨¡å¼å¯¹æ™ºèƒ½ä½“è¿›è¡Œä¸‰ä¸ªå±‚çº§çš„è¯„ä¼°ã€‚ç ”ç©¶å°†æ¢ç´¢è¿‡ç¨‹å½¢å¼åŒ–ä¸ºæœ€å¤§åŒ–å‘ç°å¯æ“ä½œ UI ç»„ä»¶çš„è¿‡ç¨‹ï¼Œå¹¶æå‡ºäº†åä¸º human-normalized UI-Functionalities Observed (hUFO) çš„æŒ‡æ ‡æ¥é‡åŒ–æ¢ç´¢çš„æœ‰æ•ˆæ€§ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒUIExplore-AlGo åœ¨ 2,000 æ­¥æ“ä½œä¸‹çš„è¡¨ç°é¢†å…ˆï¼Œåœ¨ Structured mode å’Œ Screen mode ä¸‹åˆ†åˆ«è¾¾åˆ°äººç±»è¡¨ç°çš„ 77.2% å’Œ 59.0%ã€‚å°½ç®¡å¦‚æ­¤ï¼Œå½“å‰æ™ºèƒ½ä½“ä¸äººç±»ä¸“å®¶ä¹‹é—´ä»å­˜åœ¨æ˜¾è‘—çš„æ€§èƒ½å·®è·ï¼Œæ˜¾ç¤ºå‡ºæœªæ¥ç ”ç©¶çš„å·¨å¤§æ½œåŠ›ã€‚è¯¥ç ”ç©¶å…¬å¼€å‘å¸ƒäº†åŸºå‡†ç¯å¢ƒã€æ¢ç´¢æ•°æ®é›†å’Œè¯„ä¼°å¥—ä»¶ï¼Œä¸ºé«˜æ•ˆ UI æ¢ç´¢ç­–ç•¥åŠå…¶åœ¨ç»éªŒé©±åŠ¨ä»»åŠ¡å®Œæˆã€è‡ªåŠ¨è®­ç»ƒæ•°æ®ç”Ÿæˆç­‰é¢†åŸŸçš„åº”ç”¨æä¾›äº†é‡è¦æ”¯æ’‘ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2506.17779v1",
      "published_date": "2025-06-21 18:16:27 UTC",
      "updated_date": "2025-06-21 18:16:27 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T23:23:21.948026+00:00"
    },
    {
      "arxiv_id": "2506.17776v3",
      "title": "Machine Learning Model Integration with Open World Temporal Logic for Process Automation",
      "title_zh": "é¢å‘æµç¨‹è‡ªåŠ¨åŒ–çš„æœºå™¨å­¦ä¹ æ¨¡å‹ä¸å¼€æ”¾ä¸–ç•Œæ—¶åºé€»è¾‘é›†æˆ",
      "authors": [
        "Dyuman Aditya",
        "Colton Payne",
        "Mario Leiva",
        "Paulo Shakarian"
      ],
      "abstract": "Recent advances in Machine Learning (ML) have produced models that extract structured information from complex data. However, a significant challenge lies in translating these perceptual or extractive outputs into actionable and explainable decisions within complex operational workflows. To address these challenges, this paper introduces a novel approach that integrates the outputs of various machine learning models directly with the PyReason framework, an open-world temporal logic programming reasoning engine. PyReason's foundation in generalized annotated logic allows for the incorporation of real-valued outputs (e.g., probabilities, confidence scores) from a diverse set of ML models, treating them as truth intervals within its logical framework. Crucially, PyReason provides mechanisms, implemented in Python, to continuously poll ML model outputs, convert them into logical facts, and dynamically recompute the minimal model to enable decision-making in real-time. Furthermore, its native support for temporal reasoning, knowledge graph integration, and fully explainable interface traces enables an analysis of time-sensitive process data and existing organizational knowledge. By combining the strengths of perception and extraction from ML models with the logical deduction and transparency of PyReason, we aim to create a powerful system for automating complex processes. This integration is well suited for use cases in numerous domains, including manufacturing, healthcare, and business operations.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å°†æœºå™¨å­¦ä¹ (ML)æ¨¡å‹çš„æ„ŸçŸ¥è¾“å‡ºè½¬åŒ–ä¸ºå¤æ‚å·¥ä½œæµä¸­å¯æ‰§è¡Œä¸”å¯è§£é‡Šå†³ç­–çš„æŒ‘æˆ˜ï¼Œæå‡ºäº†ä¸€ç§å°†å¤šç§MLæ¨¡å‹ä¸PyReasonæ¡†æ¶ç›´æ¥é›†æˆçš„æ–°æ–¹æ³•ã€‚PyReasonä½œä¸ºä¸€ä¸ªåŸºäºå¼€æ”¾ä¸–ç•Œæ—¶åºé€»è¾‘(Open-World Temporal Logic)çš„æ¨ç†å¼•æ“ï¼Œåˆ©ç”¨å¹¿ä¹‰æ ‡æ³¨é€»è¾‘(Generalized Annotated Logic)å°†MLæ¨¡å‹çš„å®å€¼è¾“å‡ºï¼ˆå¦‚æ¦‚ç‡å’Œç½®ä¿¡åº¦ï¼‰è§†ä¸ºé€»è¾‘æ¡†æ¶å†…çš„çœŸå€¼åŒºé—´ã€‚é€šè¿‡Pythonå®ç°çš„æŒç»­è½®è¯¢æœºåˆ¶ï¼Œè¯¥ç³»ç»Ÿèƒ½å¤Ÿå°†MLè¾“å‡ºåŠ¨æ€è½¬åŒ–ä¸ºé€»è¾‘äº‹å®å¹¶å®æ—¶é‡æ–°è®¡ç®—æœ€å°æ¨¡å‹ï¼Œä»è€Œæ”¯æŒå®æ—¶å†³ç­–ã€‚æ­¤å¤–ï¼ŒPyReasonåŸç”Ÿæ”¯æŒæ—¶åºæ¨ç†(Temporal Reasoning)å’ŒçŸ¥è¯†å›¾è°±(Knowledge Graph)é›†æˆï¼Œå¹¶æä¾›å®Œå…¨å¯è§£é‡Šçš„æ¥å£è¿½è¸ªï¼Œä»¥ä¾¿åˆ†æå…·æœ‰æ—¶é—´æ•æ„Ÿæ€§çš„è¿‡ç¨‹æ•°æ®ã€‚é€šè¿‡ç»“åˆMLæ¨¡å‹çš„æ„ŸçŸ¥æå–èƒ½åŠ›ä¸PyReasonçš„é€»è¾‘æ¼”ç»åŠé€æ˜åº¦ï¼Œè¯¥ç³»ç»Ÿä¸ºåˆ¶é€ ã€åŒ»ç–—å’Œå•†ä¸šè¿è¥ç­‰é¢†åŸŸçš„å¤æ‚æµç¨‹è‡ªåŠ¨åŒ–æä¾›äº†å¼ºæœ‰åŠ›çš„æ”¯æŒã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.LO"
      ],
      "primary_category": "cs.LG",
      "comment": "In Proceedings ICLP 2025, arXiv:2601.00047",
      "pdf_url": "https://arxiv.org/pdf/2506.17776v3",
      "published_date": "2025-06-21 18:13:13 UTC",
      "updated_date": "2026-01-07 12:03:57 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T23:23:23.032685+00:00"
    },
    {
      "arxiv_id": "2506.17765v2",
      "title": "CARTS: Collaborative Agents for Recommendation Textual Summarization",
      "title_zh": "CARTSï¼šé¢å‘æ¨èæ–‡æœ¬æ‘˜è¦çš„ååŒæ™ºèƒ½ä½“",
      "authors": [
        "Jiao Chen",
        "Kehui Yao",
        "Reza Yousefi Maragheh",
        "Kai Zhao",
        "Jianpeng Xu",
        "Jason Cho",
        "Evren Korpeoglu",
        "Sushant Kumar",
        "Kannan Achan"
      ],
      "abstract": "Current recommendation systems often require some form of textual data summarization, such as generating concise and coherent titles for product carousels or other grouped item displays. While large language models have shown promise in NLP domains for textual summarization, these approaches do not directly apply to recommendation systems, where explanations must be highly relevant to the core features of item sets, adhere to strict word limit constraints. In this paper, we propose CARTS (Collaborative Agents for Recommendation Textual Summarization), a multi-agent LLM framework designed for structured summarization in recommendation systems. CARTS decomposes the task into three stages-Generation Augmented Generation (GAG), refinement circle, and arbitration, where successive agent roles are responsible for extracting salient item features, iteratively refining candidate titles based on relevance and length feedback, and selecting the final title through a collaborative arbitration process. Experiments on large-scale e-commerce data and live A/B testing show that CARTS significantly outperforms single-pass and chain-of-thought LLM baselines, delivering higher title relevance and improved user engagement metrics.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†CARTSï¼ˆCollaborative Agents for Recommendation Textual Summarizationï¼‰ï¼Œè¿™æ˜¯ä¸€ä¸ªä¸“ä¸ºæ¨èç³»ç»Ÿç»“æ„åŒ–æ‘˜è¦è®¾è®¡çš„å¤šæ™ºèƒ½ä½“å¤§è¯­è¨€æ¨¡å‹æ¡†æ¶ï¼Œæ—¨åœ¨ä¸ºå•†å“ç»„ç”Ÿæˆå…¼å…·é«˜åº¦ç›¸å…³æ€§ä¸ä¸¥æ ¼é•¿åº¦é™åˆ¶çš„ç®€æ´æ ‡é¢˜ã€‚CARTSå°†æ‘˜è¦ä»»åŠ¡åˆ†è§£ä¸ºä¸‰ä¸ªé˜¶æ®µï¼ŒåŒ…æ‹¬æå–æ˜¾è‘—é¡¹ç‰¹å¾çš„ç”Ÿæˆå¢å¼ºç”Ÿæˆï¼ˆGeneration Augmented Generation, GAGï¼‰ã€åŸºäºç›¸å…³æ€§å’Œé•¿åº¦åé¦ˆè¿›è¡Œè¿­ä»£ä¼˜åŒ–çš„ä¼˜åŒ–å¾ªç¯ï¼ˆrefinement circleï¼‰ï¼Œä»¥åŠé€šè¿‡åä½œè¿‡ç¨‹é€‰å®šæœ€ç»ˆæ ‡é¢˜çš„ä»²è£ï¼ˆarbitrationï¼‰é˜¶æ®µã€‚é€šè¿‡åœ¨å¤§è§„æ¨¡ç”µå­å•†åŠ¡æ•°æ®ä¸Šçš„å®éªŒåŠåœ¨çº¿A/Bæµ‹è¯•ï¼Œç»“æœè¯æ˜CARTSåœ¨æ ‡é¢˜ç›¸å…³æ€§å’Œç”¨æˆ·å‚ä¸åº¦æŒ‡æ ‡ä¸Šæ˜¾è‘—ä¼˜äºå•æ¬¡ç”Ÿæˆï¼ˆsingle-passï¼‰å’Œé“¾å¼æ€ç»´ï¼ˆChain-of-Thoughtï¼‰ç­‰åŸºå‡†æ¨¡å‹ã€‚è¯¥æ¡†æ¶æœ‰æ•ˆè§£å†³äº†å¤§è¯­è¨€æ¨¡å‹åœ¨æ¨èç³»ç»Ÿç‰¹å®šçº¦æŸä¸‹çš„åº”ç”¨éš¾é¢˜ï¼Œä¸ºå®ç°æ›´ç²¾å‡†çš„è‡ªåŠ¨åŒ–æ¨èæ–‡æœ¬ç”Ÿæˆæä¾›äº†å¯é çš„æŠ€æœ¯æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2506.17765v2",
      "published_date": "2025-06-21 17:18:35 UTC",
      "updated_date": "2025-07-01 05:47:05 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T23:23:19.861176+00:00"
    },
    {
      "arxiv_id": "2506.17756v1",
      "title": "Residual Connection-Enhanced ConvLSTM for Lithium Dendrite Growth Prediction",
      "title_zh": "ç”¨äºé”‚ææ™¶ç”Ÿé•¿é¢„æµ‹çš„æ®‹å·®è¿æ¥å¢å¼ºå‹ ConvLSTM",
      "authors": [
        "Hosung Lee",
        "Byeongoh Hwang",
        "Dasan Kim",
        "Myungjoo Kang"
      ],
      "abstract": "The growth of lithium dendrites significantly impacts the performance and safety of rechargeable batteries, leading to short circuits and capacity degradation. This study proposes a Residual Connection-Enhanced ConvLSTM model to predict dendrite growth patterns with improved accuracy and computational efficiency. By integrating residual connections into ConvLSTM, the model mitigates the vanishing gradient problem, enhances feature retention across layers, and effectively captures both localized dendrite growth dynamics and macroscopic battery behavior. The dataset was generated using a phase-field model, simulating dendrite evolution under varying conditions. Experimental results show that the proposed model achieves up to 7% higher accuracy and significantly reduces mean squared error (MSE) compared to conventional ConvLSTM across different voltage conditions (0.1V, 0.3V, 0.5V). This highlights the effectiveness of residual connections in deep spatiotemporal networks for electrochemical system modeling. The proposed approach offers a robust tool for battery diagnostics, potentially aiding in real-time monitoring and optimization of lithium battery performance. Future research can extend this framework to other battery chemistries and integrate it with real-world experimental data for further validation",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† Residual Connection-Enhanced ConvLSTM æ¨¡å‹ï¼Œæ—¨åœ¨é¢„æµ‹é”‚ææ™¶ (Lithium Dendrite) çš„ç”Ÿé•¿æ¨¡å¼ï¼Œä»¥è§£å†³å……ç”µç”µæ± é¢ä¸´çš„çŸ­è·¯å’Œå®¹é‡è¡°å‡ç­‰å®‰å…¨é—®é¢˜ã€‚é€šè¿‡åœ¨ ConvLSTM ä¸­å¼•å…¥æ®‹å·®è¿æ¥ (Residual Connection)ï¼Œè¯¥æ¨¡å‹æœ‰æ•ˆç¼“è§£äº†æ¢¯åº¦æ¶ˆå¤± (Vanishing Gradient) é—®é¢˜ï¼Œå¢å¼ºäº†è·¨å±‚ç‰¹å¾ä¿ç•™ï¼Œå¹¶èƒ½ååŒæ•æ‰å±€éƒ¨ææ™¶ç”Ÿé•¿åŠ¨æ€ä¸å®è§‚ç”µæ± è¡Œä¸ºã€‚ç ”ç©¶åˆ©ç”¨ç›¸åœºæ¨¡å‹ (Phase-field Model) æ¨¡æ‹Ÿä¸åŒç”µå‹ä¸‹çš„ææ™¶æ¼”å˜å¹¶ç”Ÿæˆæ•°æ®é›†ï¼Œå®éªŒç»“æœè¡¨æ˜è¯¥æ¨¡å‹æ¯”ä¼ ç»Ÿ ConvLSTM çš„å‡†ç¡®ç‡æå‡äº†é«˜è¾¾ 7%ï¼Œå¹¶æ˜¾è‘—é™ä½äº†å‡æ–¹è¯¯å·® (MSE)ã€‚è¿™ä¸€æˆæœè¯æ˜äº†æ®‹å·®å¢å¼ºæ·±åº¦æ—¶ç©ºç½‘ç»œåœ¨ç”µåŒ–å­¦ç³»ç»Ÿå»ºæ¨¡ä¸­çš„æœ‰æ•ˆæ€§ï¼Œä¸ºç”µæ± å¥åº·è¯Šæ–­ã€å®æ—¶ç›‘æ§å’Œæ€§èƒ½ä¼˜åŒ–æä¾›äº†é²æ£’çš„å·¥å…·ã€‚è¯¥æ¡†æ¶æœªæ¥æœ‰æœ›æ‰©å±•è‡³å…¶ä»–ç”µæ± ä½“ç³»ï¼Œå¹¶ç»“åˆå®é™…å®éªŒæ•°æ®è¿›è¡Œè¿›ä¸€æ­¥éªŒè¯ã€‚",
      "categories": [
        "cond-mat.mtrl-sci",
        "cs.AI"
      ],
      "primary_category": "cond-mat.mtrl-sci",
      "comment": "14pages, 6figures, accepted to Journal of The Electrochemical Society",
      "pdf_url": "https://arxiv.org/pdf/2506.17756v1",
      "published_date": "2025-06-21 16:27:59 UTC",
      "updated_date": "2025-06-21 16:27:59 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T23:23:29.963501+00:00"
    },
    {
      "arxiv_id": "2506.17748v1",
      "title": "HIDE and Seek: Detecting Hallucinations in Language Models via Decoupled Representations",
      "title_zh": "HIDE and Seekï¼šåŸºäºè§£è€¦è¡¨ç¤ºçš„è¯­è¨€æ¨¡å‹å¹»è§‰æ£€æµ‹",
      "authors": [
        "Anwoy Chatterjee",
        "Yash Goel",
        "Tanmoy Chakraborty"
      ],
      "abstract": "Contemporary Language Models (LMs), while impressively fluent, often generate content that is factually incorrect or unfaithful to the input context - a critical issue commonly referred to as 'hallucination'. This tendency of LMs to generate hallucinated content undermines their reliability, especially because these fabrications are often highly convincing and therefore difficult to detect. While several existing methods attempt to detect hallucinations, most rely on analyzing multiple generations per input, leading to increased computational cost and latency. To address this, we propose a single-pass, training-free approach for effective Hallucination detectIon via Decoupled rEpresentations (HIDE). Our approach leverages the hypothesis that hallucinations result from a statistical decoupling between an LM's internal representations of input context and its generated output. We quantify this decoupling using the Hilbert-Schmidt Independence Criterion (HSIC) applied to hidden-state representations extracted while generating the output sequence. We conduct extensive experiments on four diverse question answering datasets, evaluating both faithfulness and factuality hallucinations across six open-source LMs of varying scales and properties. Our results demonstrate that HIDE outperforms other single-pass methods in almost all settings, achieving an average relative improvement of ~29% in AUC-ROC over the best-performing single-pass strategy across various models and datasets. Additionally, HIDE shows competitive and often superior performance with multi-pass state-of-the-art methods, obtaining an average relative improvement of ~3% in AUC-ROC while consuming ~51% less computation time. Our findings highlight the effectiveness of exploiting internal representation decoupling in LMs for efficient and practical hallucination detection.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§è¯­è¨€æ¨¡å‹ï¼ˆLMsï¼‰ä¸­ç”±äºç”Ÿæˆäº‹å®é”™è¯¯æˆ–ä¸å¿ å®å†…å®¹è€Œå¯¼è‡´çš„å¹»è§‰ï¼ˆHallucinationï¼‰é—®é¢˜ï¼Œæå‡ºäº†åä¸ºHIDEï¼ˆHallucination detectIon via Decoupled rEpresentationsï¼‰çš„æ£€æµ‹æ¡†æ¶ã€‚HIDEæ˜¯ä¸€ç§å•æ¬¡é€šè¿‡ï¼ˆsingle-passï¼‰ä¸”æ— éœ€è®­ç»ƒçš„æ–¹æ³•ï¼Œæ—¨åœ¨è§£å†³ç°æœ‰æ£€æµ‹æŠ€æœ¯è®¡ç®—æˆæœ¬é«˜ä¸”å»¶è¿Ÿé•¿çš„é—®é¢˜ã€‚è¯¥æ–¹æ³•çš„æ ¸å¿ƒå‡è®¾æ˜¯å¹»è§‰æºäºæ¨¡å‹å†…éƒ¨å¯¹è¾“å…¥ä¸Šä¸‹æ–‡çš„è¡¨ç¤ºä¸ç”Ÿæˆè¾“å‡ºä¹‹é—´çš„ç»Ÿè®¡è§£è€¦ï¼ˆstatistical decouplingï¼‰ã€‚ç ”ç©¶è€…åˆ©ç”¨å¸Œå°”ä¼¯ç‰¹-æ–½å¯†ç‰¹ç‹¬ç«‹æ€§å‡†åˆ™ï¼ˆHilbert-Schmidt Independence Criterion, HSICï¼‰å¯¹æå–çš„éšè—çŠ¶æ€è¡¨ç¤ºï¼ˆhidden-state representationsï¼‰è¿›è¡Œé‡åŒ–åˆ†æä»¥è¯†åˆ«å¹»è§‰ã€‚å®éªŒåœ¨å››ä¸ªé—®ç­”æ•°æ®é›†å’Œå…­ç§ä¸åŒè§„æ¨¡çš„å¼€æºæ¨¡å‹ä¸ŠéªŒè¯äº†å…¶æœ‰æ•ˆæ€§ï¼Œç»“æœæ˜¾ç¤ºHIDEåœ¨AUC-ROCæŒ‡æ ‡ä¸Šæ¯”åŒç±»å•æ¬¡é€šè¿‡æ–¹æ³•å¹³å‡æå‡äº†çº¦29%ã€‚æ­¤å¤–ï¼Œä¸æœ€å…ˆè¿›çš„å¤šæ­¥æ£€æµ‹æ–¹æ³•ç›¸æ¯”ï¼ŒHIDEåœ¨å‡å°‘çº¦51%è®¡ç®—æ—¶é—´çš„åŒæ—¶ï¼Œä»èƒ½ä¿æŒç«äº‰æ€§ç”šè‡³æ›´ä¼˜çš„æ£€æµ‹æ€§èƒ½ã€‚è¯¥ç ”ç©¶è¯æ˜äº†åˆ©ç”¨æ¨¡å‹å†…éƒ¨è¡¨ç¤ºè§£è€¦ç‰¹æ€§è¿›è¡Œé«˜æ•ˆä¸”å®ç”¨å¹»è§‰æ£€æµ‹çš„æœ‰æ•ˆæ€§ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2506.17748v1",
      "published_date": "2025-06-21 16:02:49 UTC",
      "updated_date": "2025-06-21 16:02:49 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T23:23:36.466177+00:00"
    },
    {
      "arxiv_id": "2506.18931v1",
      "title": "Safe Pruning LoRA: Robust Distance-Guided Pruning for Safety Alignment in Adaptation of LLMs",
      "title_zh": "Safe Pruning LoRAï¼šé¢å‘å¤§è¯­è¨€æ¨¡å‹é€‚é…å®‰å…¨å¯¹é½çš„é²æ£’è·ç¦»å¼•å¯¼å‰ªæ",
      "authors": [
        "Shuang Ao",
        "Yi Dong",
        "Jinwei Hu",
        "Sarvapali Ramchurn"
      ],
      "abstract": "Fine-tuning Large Language Models (LLMs) with Low-Rank Adaptation (LoRA) enhances adaptability while reducing computational costs. However, fine-tuning can compromise safety alignment, even with benign data, increasing susceptibility to harmful outputs. Existing safety alignment methods struggle to capture complex parameter shifts, leading to suboptimal safety-utility trade-offs. To address this issue, we propose Safe Pruning LoRA (SPLoRA), a novel pruning-based approach that selectively removes LoRA layers that weaken safety alignment, improving safety while preserving performance. At its core, we introduce Empirical-DIEM (E-DIEM), a dimension-insensitive similarity metric that effectively detects safety misalignment in LoRA-adapted models. We conduct extensive experiments on LLMs fine-tuned with mixed of benign and malicious data, and purely benign datasets, evaluating SPLoRA across utility, safety, and reliability metrics. Results demonstrate that SPLoRA outperforms state-of-the-art safety alignment techniques, significantly reducing safety risks while maintaining or improving model performance and reliability. Additionally, SPLoRA reduces inference overhead, making it a scalable and efficient solution for deploying safer and more reliable LLMs. The code is available at https://github.com/AoShuang92/SPLoRA.",
      "tldr_zh": "å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åˆ©ç”¨ä½ç§©è‡ªé€‚åº”ï¼ˆLoRAï¼‰è¿›è¡Œå¾®è°ƒè™½èƒ½é™ä½è®¡ç®—æˆæœ¬ï¼Œä½†å¾€å¾€ä¼šæŸå®³å®‰å…¨å¯¹é½ï¼ˆSafety Alignmentï¼‰ï¼Œä½¿å…¶æ›´å®¹æ˜“è¾“å‡ºæœ‰å®³å†…å®¹ã€‚è¯¥ç ”ç©¶æå‡ºäº† Safe Pruning LoRA (SPLoRA)ï¼Œè¿™æ˜¯ä¸€ç§é€šè¿‡é€‰æ‹©æ€§å‰ªææ¥ç§»é™¤å‰Šå¼±å®‰å…¨å¯¹é½çš„ LoRA å±‚çš„æ–°å‹æ–¹æ³•ï¼Œæ—¨åœ¨å…¼é¡¾æ¨¡å‹çš„å®‰å…¨æ€§å’Œæ€§èƒ½ã€‚å…¶æ ¸å¿ƒæŠ€æœ¯æ˜¯å¼•å…¥äº†å¯¹ç»´åº¦ä¸æ•æ„Ÿçš„ç›¸ä¼¼æ€§åº¦é‡æŒ‡æ ‡ Empirical-DIEM (E-DIEM)ï¼Œç”¨ä»¥ç²¾å‡†æ£€æµ‹æ¨¡å‹é€‚é…è¿‡ç¨‹ä¸­çš„å®‰å…¨å¤±è°ƒã€‚å®éªŒç»“æœè¯æ˜ï¼ŒSPLoRA åœ¨å®ç”¨æ€§ï¼ˆUtilityï¼‰ã€å®‰å…¨æ€§å’Œå¯é æ€§æ–¹é¢å‡ä¼˜äºç°æœ‰çš„å®‰å…¨å¯¹é½æŠ€æœ¯ï¼Œåœ¨æ˜¾è‘—é™ä½é£é™©çš„åŒæ—¶è¿˜ç»´æŒæˆ–æå‡äº†æ¨¡å‹è¡¨ç°ã€‚æ­¤å¤–ï¼Œç”±äºå‰ªæå‡å°‘äº†æ¨ç†å¼€é”€ï¼Œè¯¥æ–¹æ¡ˆä¸ºéƒ¨ç½²æ›´å®‰å…¨ã€æ›´é«˜æ•ˆçš„å¤§è¯­è¨€æ¨¡å‹æä¾›äº†ä¸€ç§å¯æ‰©å±•çš„è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "13 pages, 3 figures",
      "pdf_url": "https://arxiv.org/pdf/2506.18931v1",
      "published_date": "2025-06-21 14:59:54 UTC",
      "updated_date": "2025-06-21 14:59:54 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T23:23:32.978664+00:00"
    },
    {
      "arxiv_id": "2506.17728v3",
      "title": "KAG-Thinker: Interactive Thinking and Deep Reasoning in LLMs via Knowledge-Augmented Generation",
      "title_zh": "KAG-Thinkerï¼šé€šè¿‡çŸ¥è¯†å¢å¼ºç”Ÿæˆå®ç°å¤§è¯­è¨€æ¨¡å‹çš„äº¤äº’å¼æ€ç»´ä¸æ·±åº¦æ¨ç†",
      "authors": [
        "Dalong Zhang",
        "Jun Xu",
        "Jun Zhou",
        "Lei Liang",
        "Lin Yuan",
        "Ling Zhong",
        "Mengshu Sun",
        "Peilong Zhao",
        "QiWei Wang",
        "Xiaorui Wang",
        "Xinkai Du",
        "YangYang Hou",
        "Yu Ao",
        "ZhaoYang Wang",
        "Zhengke Gui",
        "ZhiYing Yi",
        "Zhongpu Bo",
        "Haofen Wang",
        "Huajun Chen"
      ],
      "abstract": "In this paper, we introduce KAG-Thinker, which upgrade KAG to a multi-turn interactive thinking and deep reasoning framework powered by a dedicated parameter-light large language model (LLM). Our approach constructs a structured thinking process for solving complex problems, enhancing the the logical coherence and contextual consistency of the reasoning process in question-answering (Q&A) tasks on domain-specific knowledge bases (KBs) within LLMs. Following the \\textbf{Logical Form} guided retrieval and reasoning technology route of KAG, this framework first decomposes complex questions into independently solvable sub-problems (which are also referred to as logical forms) through \\textbf{breadth decomposition}. Each such logical form is represented in two equivalent forms-natural language and logical function-and subsequently classified as either a Knowledge Retrieval or Reasoning Analysis task. Dependencies and parameter passing between these tasks are explicitly modeled via logical function interfaces. In the solving process, the Retrieval function performs retrieval tasks. It retrieves one-hop structured and unstructured information of specified knowledge unit. While the Math and Deduce functions are used to perform reasoning analysis tasks. Secondly, it is worth noting that, in the Knowledge Retrieval sub-problem tasks, LLMs and external knowledge sources are regarded as equivalent KBs. We use the \\textbf{knowledge boundary} module to determine the optimal source using self-regulatory mechanisms such as confidence calibration and reflective reasoning, and use the \\textbf{depth solving} module to enhance the comprehensiveness of knowledge acquisition...",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†KAG-Thinkerï¼Œä¸€ç§ç”±è½»é‡åŒ–å¤§è¯­è¨€æ¨¡å‹(LLM)é©±åŠ¨çš„å¤šè½®äº¤äº’å¼æ€ç»´ä¸æ·±åº¦æ¨ç†æ¡†æ¶ï¼Œæ—¨åœ¨å‡çº§ç°æœ‰çš„çŸ¥è¯†å¢å¼ºç”Ÿæˆ(KAG)æŠ€æœ¯ã€‚è¯¥æ¡†æ¶é‡‡ç”¨é€»è¾‘å½¢å¼(Logical Form)å¼•å¯¼æ£€ç´¢ä¸æ¨ç†çš„è·¯å¾„ï¼Œé€šè¿‡å®½åº¦åˆ†è§£(breadth decomposition)å°†å¤æ‚é—®é¢˜æ‹†è§£ä¸ºå¯ç‹¬ç«‹è§£å†³çš„å­é—®é¢˜ï¼Œå¹¶æ˜¾å¼å»ºæ¨¡ä»»åŠ¡é—´çš„ä¾èµ–å…³ç³»ä¸å‚æ•°ä¼ é€’ã€‚æ¯ä¸ªå­é—®é¢˜è¢«åˆ†ç±»ä¸ºçŸ¥è¯†æ£€ç´¢æˆ–æ¨ç†åˆ†æä»»åŠ¡ï¼Œåˆ†åˆ«ç”±æ‰§è¡Œç»“æ„åŒ–ä¿¡æ¯æå–çš„Retrievalå‡½æ•°ï¼Œä»¥åŠè¿›è¡Œé€»è¾‘å¤„ç†çš„Mathå’ŒDeduceå‡½æ•°ååŒå®Œæˆã€‚æ¡†æ¶å¼•å…¥äº†çŸ¥è¯†è¾¹ç•Œ(knowledge boundary)æ¨¡å—ï¼Œåˆ©ç”¨ç½®ä¿¡åº¦æ ¡å‡†å’Œåæ€æ¨ç†ç­‰æœºåˆ¶åŠ¨æ€åˆ¤å®šLLMä¸å¤–éƒ¨çŸ¥è¯†åº“ä¹‹é—´çš„æœ€ä¼˜ä¿¡æ¯æ¥æºï¼Œå¹¶ç»“åˆæ·±åº¦æ±‚è§£(depth solving)æ¨¡å—å¢å¼ºçŸ¥è¯†è·å–çš„å…¨é¢æ€§ã€‚è¿™ç§ç»“æ„åŒ–çš„æ€ç»´è¿‡ç¨‹æ˜¾è‘—æå‡äº†ç‰¹å®šé¢†åŸŸçŸ¥è¯†åº“é—®ç­”(Q&A)ä»»åŠ¡ä¸­çš„é€»è¾‘è¿è´¯æ€§ä¸ä¸Šä¸‹æ–‡ä¸€è‡´æ€§ï¼Œä¸ºå¤æ‚é—®é¢˜çš„æ·±åº¦æ¨ç†æä¾›äº†ç³»ç»ŸåŒ–çš„è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2506.17728v3",
      "published_date": "2025-06-21 14:58:53 UTC",
      "updated_date": "2025-06-30 08:08:21 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T23:23:36.894750+00:00"
    },
    {
      "arxiv_id": "2506.17719v2",
      "title": "Clarifying the Ti-V Phase Diagram Using First-Principles Calculations and Bayesian Learning",
      "title_zh": "ç»“åˆç¬¬ä¸€æ€§åŸç†è®¡ç®—ä¸è´å¶æ–¯å­¦ä¹ é˜æ˜ Ti-V ç›¸å›¾",
      "authors": [
        "Timofei Miryashkin",
        "Olga Klimanova",
        "Alexander Shapeev"
      ],
      "abstract": "Conflicting experiments disagree on whether the titanium-vanadium (Ti-V) binary alloy exhibits a body-centred cubic (BCC) miscibility gap or remains completely soluble. A leading hypothesis attributes the miscibility gap to oxygen contamination during alloy preparation. To resolve this disagreement, we use an ab initio + machine-learning workflow that couples an actively-trained Moment Tensor Potential with Bayesian inference of free energy surface. This workflow enables construction of the Ti-V phase diagram across the full composition range with systematically reduced statistical and finite-size errors. The resulting diagram reproduces all experimental features, demonstrating the robustness of our approach, and clearly favors the variant with a BCC miscibility gap terminating at T = 980 K and c = 0.67. Because our simulations model a perfectly oxygen-free Ti-V system, the observed gap cannot originate from impurity effects, in contrast to recent CALPHAD reassessments.",
      "tldr_zh": "è¯¥ç ”ç©¶æ—¨åœ¨è§£å†³é’›-é’’ (Ti-V) äºŒå…ƒåˆé‡‘ç›¸å›¾ä¸­å…³äºä½“å¿ƒç«‹æ–¹ (BCC) æ··æº¶é—´éš™ (miscibility gap) æ˜¯å¦å­˜åœ¨çš„é•¿æœŸå®éªŒäº‰è®®ã€‚ç ”ç©¶å›¢é˜Ÿå¼€å‘äº†ä¸€ç§ç»“åˆä»å¤´ç®— (ab initio) ä¸æœºå™¨å­¦ä¹ çš„å·¥ä½œæµï¼Œå°†ä¸»åŠ¨è®­ç»ƒçš„çŸ©å¼ é‡åŠ¿ (Moment Tensor Potential) ä¸è‡ªç”±èƒ½é¢ (free energy surface) çš„è´å¶æ–¯æ¨ç† (Bayesian inference) ç›¸ç»“åˆã€‚è¯¥æ–¹æ³•èƒ½å¤Ÿåœ¨å…¨æˆåˆ†èŒƒå›´å†…æ„å»º Ti-V ç›¸å›¾ï¼Œå¹¶ç³»ç»Ÿæ€§åœ°å‡å°‘äº†ç»Ÿè®¡å’Œæœ‰é™å°ºå¯¸è¯¯å·®ã€‚è®¡ç®—ç»“æœæˆåŠŸé‡ç°äº†æ‰€æœ‰å®éªŒç‰¹å¾ï¼Œå¹¶æ˜ç¡®æ”¯æŒå­˜åœ¨ BCC æ··æº¶é—´éš™ï¼Œè¯¥é—´éš™ç»ˆæ­¢äº T = 980 K ä¸”æˆåˆ† c = 0.67 å¤„ã€‚ç”±äºæ¨¡æ‹Ÿè¿‡ç¨‹åŸºäºå®Œç¾çš„æ— æ°§ Ti-V ç³»ç»Ÿï¼Œç ”ç©¶è¯æ˜è¯¥è§‚æµ‹åˆ°çš„é—´éš™å¹¶éæºäºæ‚è´¨æ•ˆåº”ï¼Œä»è€Œåé©³äº†è¿‘æœŸ CALPHAD è¯„ä¼°ä¸­å°†å…¶å½’å› äºæ°§æ±¡æŸ“çš„è§‚ç‚¹ã€‚",
      "categories": [
        "cond-mat.mtrl-sci",
        "cs.AI",
        "physics.comp-ph"
      ],
      "primary_category": "cond-mat.mtrl-sci",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2506.17719v2",
      "published_date": "2025-06-21 14:09:15 UTC",
      "updated_date": "2025-10-17 03:11:33 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T23:23:41.744566+00:00"
    },
    {
      "arxiv_id": "2506.17708v1",
      "title": "Aged to Perfection: Machine-Learning Maps of Age in Conversational English",
      "title_zh": "ç‚‰ç«çº¯é’ï¼šåŸºäºæœºå™¨å­¦ä¹ çš„è‹±è¯­å£è¯­å¹´é¾„ç‰¹å¾æ˜ å°„",
      "authors": [
        "MingZe Tang"
      ],
      "abstract": "The study uses the British National Corpus 2014, a large sample of contemporary spoken British English, to investigate language patterns across different age groups. Our research attempts to explore how language patterns vary between different age groups, exploring the connection between speaker demographics and linguistic factors such as utterance duration, lexical diversity, and word choice. By merging computational language analysis and machine learning methodologies, we attempt to uncover distinctive linguistic markers characteristic of multiple generations and create prediction models that can consistently estimate the speaker's age group from various aspects. This work contributes to our knowledge of sociolinguistic diversity throughout the life of modern British speech.",
      "tldr_zh": "è¯¥ç ”ç©¶åˆ©ç”¨ British National Corpus 2014 è¿™ä¸€å¤§å‹å½“ä»£è‹±å›½å£è¯­è¯­æ–™åº“ï¼Œæ¢è®¨äº†ä¸åŒå¹´é¾„æ®µä¹‹é—´çš„è¯­è¨€æ¨¡å¼å˜å¼‚ã€‚ç ”ç©¶ç»“åˆäº†è®¡ç®—è¯­è¨€åˆ†æä¸ machine learning æ–¹æ³•ï¼Œæ—¨åœ¨æ­ç¤ºä¸è¯´è¯è€…å¹´é¾„ç›¸å…³çš„ç‹¬ç‰¹è¯­è¨€æ ‡è®°ã€‚åˆ†æé‡ç‚¹å…³æ³¨äº†å‘éŸ³æ—¶é•¿ (utterance duration)ã€è¯æ±‡å¤šæ ·æ€§ (lexical diversity) ä»¥åŠè¯æ±‡é€‰æ‹© (word choice) ç­‰è¯­è¨€å› ç´ ä¸äººå£ç»Ÿè®¡å­¦ç‰¹å¾ä¹‹é—´çš„è”ç³»ã€‚é€šè¿‡è¿™äº›å¤šç»´åº¦çš„è¯­è¨€ç‰¹å¾ï¼Œç ”ç©¶æ„å»ºäº†èƒ½å¤Ÿä¸€è‡´ä¼°è®¡è¯´è¯è€…å¹´é¾„ç»„çš„é¢„æµ‹æ¨¡å‹ã€‚è¯¥æˆæœä¸ºç†è§£ç°ä»£è‹±å›½å£è¯­åœ¨æ•´ä¸ªç”Ÿå‘½å‘¨æœŸä¸­çš„ç¤¾ä¼šè¯­è¨€å­¦å¤šæ ·æ€§ (sociolinguistic diversity) æä¾›äº†ç§‘å­¦ä¾æ®ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "6 pages, 11 figures",
      "pdf_url": "https://arxiv.org/pdf/2506.17708v1",
      "published_date": "2025-06-21 13:08:57 UTC",
      "updated_date": "2025-06-21 13:08:57 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T23:23:49.243298+00:00"
    },
    {
      "arxiv_id": "2506.21614v2",
      "title": "LastingBench: Defend Benchmarks Against Knowledge Leakage",
      "title_zh": "LastingBenchï¼šé˜²å¾¡åŸºå‡†æµ‹è¯•ä¸­çš„çŸ¥è¯†æ³„éœ²",
      "authors": [
        "Yixiong Fang",
        "Tianran Sun",
        "Yuling Shi",
        "Min Wang",
        "Xiaodong Gu"
      ],
      "abstract": "The increasing complexity of large language models (LLMs) raises concerns about their ability to \"cheat\" on standard Question Answering (QA) benchmarks by memorizing task-specific data. This undermines the validity of benchmark evaluations, as they no longer reflect genuine model capabilities but instead the effects of data leakage. While prior work has focused on detecting such leakage, little attention has been given to mitigating its impact and preserving the long-term utility of benchmarks. In this paper, we introduce LastingBench, a novel framework designed to continuously reinforce and safeguard existing benchmarks against knowledge leakage. LastingBench identifies leakage points in the context through perturbation, then rewrites the leakage points to counterfactual ones-disrupting memorization while preserving the benchmark's original evaluative intent. Evaluations of state-of-the-art QA benchmarks show significant performance gaps, highlighting the efficacy of LastingBench in reducing memorization effects. LastingBench offers a practical and scalable solution to ensure benchmark robustness over time, promoting fairer and more interpretable evaluations of LLMs.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§è¯­è¨€æ¨¡å‹(LLMs)åœ¨æ ‡å‡†é—®ç­”(QA)åŸºå‡†æµ‹è¯•ä¸­é€šè¿‡è®°å¿†ç‰¹å®šä»»åŠ¡æ•°æ®è¿›è¡Œâ€œä½œå¼Šâ€çš„é—®é¢˜ï¼Œæå‡ºäº†LastingBenchæ¡†æ¶ï¼Œæ—¨åœ¨ç¼“è§£çŸ¥è¯†æ³„éœ²(Knowledge Leakage)å¯¹è¯„ä¼°æœ‰æ•ˆæ€§çš„è´Ÿé¢å½±å“ã€‚LastingBenché€šè¿‡æ‰°åŠ¨(Perturbation)æŠ€æœ¯è¯†åˆ«ä¸Šä¸‹æ–‡ä¸­çš„æ³„éœ²ç‚¹ï¼Œå¹¶å°†å…¶é‡å†™ä¸ºåäº‹å®(Counterfactual)å†…å®¹ï¼Œä»è€Œåœ¨ä¿ç•™åŸå§‹è¯„ä¼°æ„å›¾çš„åŒæ—¶æœ‰æ•ˆç ´åæ¨¡å‹çš„è®°å¿†æ•ˆåº”ã€‚å¯¹å¤šç§å…ˆè¿›QAåŸºå‡†æµ‹è¯•çš„è¯„ä¼°æ˜¾ç¤ºï¼Œä½¿ç”¨è¯¥æ¡†æ¶åæ¨¡å‹è¡¨ç°å‡ºæ˜¾è‘—çš„æ€§èƒ½å·®å¼‚ï¼Œè¯æ˜äº†å…¶åœ¨å‡å°‘è®°å¿†ä¾èµ–æ–¹é¢çš„æœ‰æ•ˆæ€§ã€‚è¯¥æ–¹æ¡ˆä¸ºç¡®ä¿åŸºå‡†æµ‹è¯•çš„é•¿æœŸé²æ£’æ€§æä¾›äº†ä¸€ç§å®ç”¨ä¸”å¯æ‰©å±•çš„æ‰‹æ®µï¼Œä¿ƒè¿›äº†å¯¹å¤§è¯­è¨€æ¨¡å‹æ›´å…¬å¹³ã€æ›´å…·å¯è§£é‡Šæ€§çš„è¯„ä¼°ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2506.21614v2",
      "published_date": "2025-06-21 13:01:04 UTC",
      "updated_date": "2025-09-14 14:29:20 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T23:24:06.343933+00:00"
    },
    {
      "arxiv_id": "2506.17707v1",
      "title": "Programmable-Room: Interactive Textured 3D Room Meshes Generation Empowered by Large Language Models",
      "title_zh": "Programmable-Roomï¼šå¤§è¯­è¨€æ¨¡å‹é©±åŠ¨çš„äº¤äº’å¼èµ‹çº¹ç†ä¸‰ç»´æˆ¿é—´ç½‘æ ¼ç”Ÿæˆ",
      "authors": [
        "Jihyun Kim",
        "Junho Park",
        "Kyeongbo Kong",
        "Suk-Ju Kang"
      ],
      "abstract": "We present Programmable-Room, a framework which interactively generates and edits a 3D room mesh, given natural language instructions. For precise control of a room's each attribute, we decompose the challenging task into simpler steps such as creating plausible 3D coordinates for room meshes, generating panorama images for the texture, constructing 3D meshes by integrating the coordinates and panorama texture images, and arranging furniture. To support the various decomposed tasks with a unified framework, we incorporate visual programming (VP). VP is a method that utilizes a large language model (LLM) to write a Python-like program which is an ordered list of necessary modules for the various tasks given in natural language. We develop most of the modules. Especially, for the texture generating module, we utilize a pretrained large-scale diffusion model to generate panorama images conditioned on text and visual prompts (i.e., layout, depth, and semantic map) simultaneously. Specifically, we enhance the panorama image generation quality by optimizing the training objective with a 1D representation of a panorama scene obtained from bidirectional LSTM. We demonstrate Programmable-Room's flexibility in generating and editing 3D room meshes, and prove our framework's superiority to an existing model quantitatively and qualitatively. Project page is available in https://jihyun0510.github.io/Programmable_Room_Page/.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† Programmable-Roomï¼Œè¿™æ˜¯ä¸€ä¸ªèƒ½å¤Ÿæ ¹æ®è‡ªç„¶è¯­è¨€æŒ‡ä»¤äº¤äº’å¼ç”Ÿæˆå’Œç¼–è¾‘å¸¦æœ‰çº¹ç†çš„ 3D æˆ¿é—´ç½‘æ ¼ï¼ˆ3D room meshesï¼‰çš„æ¡†æ¶ã€‚ä¸ºå®ç°å¯¹æˆ¿é—´å±æ€§çš„ç²¾ç¡®æ§åˆ¶ï¼Œè¯¥æ¡†æ¶å°†å¤æ‚çš„ç”Ÿæˆä»»åŠ¡åˆ†è§£ä¸º 3D åæ ‡åˆ›å»ºã€å…¨æ™¯çº¹ç†ç”Ÿæˆã€ç½‘æ ¼é›†æˆä»¥åŠå®¶å…·æ‘†æ”¾ç­‰å¤šä¸ªç®€åŒ–æ­¥éª¤ã€‚å…¶æ ¸å¿ƒé‡‡ç”¨äº†å¯è§†åŒ–ç¼–ç¨‹ï¼ˆVisual Programmingï¼‰æ–¹æ³•ï¼Œåˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ç”Ÿæˆç¨‹åºæŒ‡ä»¤ä»¥ç»Ÿä¸€è°ƒåº¦å„åŠŸèƒ½æ¨¡å—ã€‚åœ¨çº¹ç†ç”Ÿæˆæ¨¡å—ä¸­ï¼Œç ”ç©¶å›¢é˜Ÿç»“åˆé¢„è®­ç»ƒæ‰©æ•£æ¨¡å‹ï¼ˆdiffusion modelï¼‰ä¸åŒå‘ LSTM æå–çš„ 1D åœºæ™¯è¡¨ç¤ºï¼Œæ˜¾è‘—æå‡äº†å—æ§å…¨æ™¯å›¾åƒçš„ç”Ÿæˆè´¨é‡ã€‚å®éªŒç»“æœè¯æ˜ï¼ŒProgrammable-Room åœ¨ç”Ÿæˆå’Œç¼–è¾‘ 3D æˆ¿é—´åœºæ™¯æ–¹é¢å…·æœ‰æ˜¾è‘—çš„çµæ´»æ€§ï¼Œä¸”åœ¨å®šé‡å’Œå®šæ€§è¯„ä¼°ä¸­å‡ä¼˜äºç°æœ‰åŸºçº¿æ¨¡å‹ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.MM"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by IEEE Transactions on Multimedia",
      "pdf_url": "https://arxiv.org/pdf/2506.17707v1",
      "published_date": "2025-06-21 13:00:06 UTC",
      "updated_date": "2025-06-21 13:00:06 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T23:24:05.444431+00:00"
    },
    {
      "arxiv_id": "2506.17700v1",
      "title": "The Evolution of Natural Language Processing: How Prompt Optimization and Language Models are Shaping the Future",
      "title_zh": "è‡ªç„¶è¯­è¨€å¤„ç†çš„æ¼”è¿›ï¼šæç¤ºè¯ä¼˜åŒ–ä¸è¯­è¨€æ¨¡å‹å¦‚ä½•å¡‘é€ æœªæ¥",
      "authors": [
        "Summra Saleem",
        "Muhammad Nabeel Asim",
        "Shaista Zulfiqar",
        "Andreas Dengel"
      ],
      "abstract": "Large Language Models (LLMs) have revolutionized the field of Natural Language Processing (NLP) by automating traditional labor-intensive tasks and consequently accelerated the development of computer-aided applications. As researchers continue to advance this field with the introduction of novel language models and more efficient training/finetuning methodologies, the idea of prompt engineering and subsequent optimization strategies with LLMs has emerged as a particularly impactful trend to yield a substantial performance boost across diverse NLP tasks. To best of our knowledge numerous review articles have explored prompt engineering, however, a critical gap exists in comprehensive analyses of prompt optimization strategies. To bridge this gap this paper provides unique and comprehensive insights about the potential of diverse prompt optimization strategies. It analyzes their underlying working paradigms and based on these principles, categorizes them into 11 distinct classes. Moreover, the paper provides details about various NLP tasks where these prompt optimization strategies have been employed, along with details of different LLMs and benchmark datasets used for evaluation. This comprehensive compilation lays a robust foundation for future comparative studies and enables rigorous assessment of prompt optimization and LLM-based predictive pipelines under consistent experimental settings: a critical need in the current landscape. Ultimately, this research will centralize diverse strategic knowledge to facilitate the adaptation of existing prompt optimization strategies for development of innovative predictors across unexplored tasks.",
      "tldr_zh": "è¯¥ç ”ç©¶ç³»ç»Ÿåœ°æ¢è®¨äº†æç¤ºè¯ä¼˜åŒ–(Prompt Optimization)ä¸å¤§å‹è¯­è¨€æ¨¡å‹(LLMs)åœ¨è‡ªç„¶è¯­è¨€å¤„ç†(NLP)é¢†åŸŸçš„ååŒæ¼”è¿›åŠå…¶å¯¹æœªæ¥çš„å½±å“ã€‚é’ˆå¯¹æç¤ºå·¥ç¨‹(Prompt Engineering)ç ”ç©¶ä¸­ç¼ºä¹å…¨é¢ä¼˜åŒ–ç­–ç•¥åˆ†æçš„ç©ºç™½ï¼Œæœ¬æ–‡é€šè¿‡å‰–æåº•å±‚å·¥ä½œèŒƒå¼ï¼Œå°†ç°æœ‰çš„æç¤ºè¯ä¼˜åŒ–ç­–ç•¥åˆ’åˆ†ä¸º11ä¸ªä¸åŒçš„ç±»åˆ«ã€‚æ–‡ç« ä¸ä»…è¯¦ç»†ä»‹ç»äº†è¿™äº›ç­–ç•¥åœ¨å¤šæ ·åŒ–NLPä»»åŠ¡ä¸­çš„åº”ç”¨ï¼Œè¿˜æ±‡æ€»äº†ç”¨äºè¯„ä¼°çš„å„ç±»LLMsåŠåŸºå‡†æ•°æ®é›†(Benchmark Datasets)ã€‚è¿™ä¸€ç»¼åˆæ€§ç»¼è¿°ä¸ºæœªæ¥åœ¨ä¸€è‡´å®éªŒè®¾å®šä¸‹å¼€å±•å¯¹æ¯”ç ”ç©¶å’Œä¸¥è°¨è¯„ä¼°å¥ å®šäº†åšå®åŸºç¡€ã€‚æœ€ç»ˆï¼Œè¯¥ç ”ç©¶é€šè¿‡é›†ä¸­åŒ–ç­–ç•¥çŸ¥è¯†ï¼Œæ—¨åœ¨ä¿ƒè¿›ç°æœ‰ä¼˜åŒ–æ–¹æ³•åœ¨æœªæ¢ç´¢ä»»åŠ¡ä¸­çš„è¿ç§»ï¼ŒåŠ©åŠ›å¼€å‘æ›´å…·åˆ›æ–°æ€§çš„é¢„æµ‹ç®¡é“ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2506.17700v1",
      "published_date": "2025-06-21 12:25:37 UTC",
      "updated_date": "2025-06-21 12:25:37 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T23:24:16.247993+00:00"
    },
    {
      "arxiv_id": "2506.17697v1",
      "title": "Beyond Syntax: Action Semantics Learning for App Agents",
      "title_zh": "è¶…è¶Šè¯­æ³•ï¼šé¢å‘ App æ™ºèƒ½ä½“çš„åŠ¨ä½œè¯­ä¹‰å­¦ä¹ ",
      "authors": [
        "Bohan Tang",
        "Dezhao Luo",
        "Jingxuan Chen",
        "Shaogang Gong",
        "Jianye Hao",
        "Jun Wang",
        "Kun Shao"
      ],
      "abstract": "The advent of Large Language Models (LLMs) enables the rise of App agents that interpret user intent and operate smartphone Apps through actions such as clicking and scrolling. While prompt-based solutions with closed LLM APIs show promising ability, they incur heavy compute costs and external API dependency. Fine-tuning smaller open-source LLMs solves these limitations. However, current fine-tuning methods use a syntax learning paradigm that forces agents to reproduce exactly the ground truth action strings, leading to out-of-distribution (OOD) vulnerability. To fill this gap, we propose Action Semantics Learning (ASL), a novel learning framework, where the learning objective is capturing the semantics of the ground truth actions. Specifically, inspired by the programming language theory, we define the action semantics for App agents as the state transition induced by the action in the user interface. With this insight, ASL employs a novel SEmantic Estimator (SEE) to compute a semantic reward to train the App agents in generating actions aligned with the semantics of ground truth actions, even when the syntactic forms differ. To support the effectiveness of ASL, we theoretically demonstrate the superior robustness of ASL for the OOD problem compared with the existing syntax learning paradigm. Extensive experiments on offline and online smartphone App operation benchmarks show that ASL significantly improves the accuracy and generalisation of App agents over existing methods.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç§»åŠ¨ App æ™ºèƒ½ä½“åœ¨å¾®è°ƒå¼€æºå¤§è¯­è¨€æ¨¡å‹ (LLMs) æ—¶é¢ä¸´çš„è¯­æ³•å­¦ä¹  (syntax learning) èŒƒå¼å±€é™ï¼Œç‰¹åˆ«æ˜¯æ¨¡å‹è¿‡åº¦ä¾èµ–å¤ç°ç²¾ç¡®åŠ¨ä½œå­—ç¬¦ä¸²å¯¼è‡´çš„åˆ†å¸ƒå¤– (OOD) è„†å¼±æ€§é—®é¢˜ã€‚ä¸ºæ­¤ï¼Œä½œè€…æå‡ºäº† Action Semantics Learning (ASL) å­¦ä¹ æ¡†æ¶ï¼Œæ—¨åœ¨æ•æ‰æ ‡æ³¨åŠ¨ä½œèƒŒåçš„è¯­ä¹‰ï¼Œè€Œéä»…ä»…æ¨¡æ‹Ÿè¯­æ³•å½¢å¼ã€‚å—ç¼–ç¨‹è¯­è¨€ç†è®ºå¯å‘ï¼Œè¯¥æ¡†æ¶å°†åŠ¨ä½œè¯­ä¹‰å®šä¹‰ä¸ºåŠ¨ä½œåœ¨ç”¨æˆ·ç•Œé¢ä¸­å¼•å‘çš„çŠ¶æ€è½¬æ¢ (state transition)ï¼Œå¹¶å¼•å…¥äº† SEmantic Estimator (SEE) æ¨¡å—ã€‚SEE é€šè¿‡è®¡ç®—è¯­ä¹‰å¥–åŠ± (semantic reward) æ¥è®­ç»ƒæ™ºèƒ½ä½“ï¼Œä½¿å…¶ç”Ÿæˆçš„åŠ¨ä½œå³ä½¿åœ¨è¯­æ³•ç»“æ„ä¸Šä¸åŒï¼Œä¹Ÿèƒ½åœ¨è¯­ä¹‰å±‚é¢ä¸æ ‡æ³¨åŠ¨ä½œä¿æŒä¸€è‡´ã€‚ç†è®ºåˆ†æè¯æ˜äº† ASL åœ¨å¤„ç† OOD é—®é¢˜ä¸Šç›¸è¾ƒäºä¼ ç»Ÿè¯­æ³•å­¦ä¹ èŒƒå¼å…·æœ‰æ›´ä¼˜çš„é²æ£’æ€§ã€‚åœ¨ç¦»çº¿å’Œåœ¨çº¿æ™ºèƒ½æ‰‹æœº App æ“ä½œåŸºå‡†æµ‹è¯•ä¸Šçš„å®éªŒç»“æœæ˜¾ç¤ºï¼ŒASL æ˜¾è‘—æå‡äº† App æ™ºèƒ½ä½“çš„å‡†ç¡®æ€§å’Œæ³›åŒ–èƒ½åŠ›ï¼Œä¼˜äºç°æœ‰æ–¹æ³•ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2506.17697v1",
      "published_date": "2025-06-21 12:08:19 UTC",
      "updated_date": "2025-06-21 12:08:19 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T23:24:16.413181+00:00"
    },
    {
      "arxiv_id": "2506.17682v1",
      "title": "Reinforcing User Interest Evolution in Multi-Scenario Learning for recommender systems",
      "title_zh": "æ¨èç³»ç»Ÿå¤šåœºæ™¯å­¦ä¹ ä¸­çš„ç”¨æˆ·å…´è¶£æ¼”åŒ–å¼ºåŒ–",
      "authors": [
        "Zhijian Feng",
        "Wenhao Zheng",
        "Xuanji Xiao"
      ],
      "abstract": "In real-world recommendation systems, users would engage in variety scenarios, such as homepages, search pages, and related recommendation pages. Each of these scenarios would reflect different aspects users focus on. However, the user interests may be inconsistent in different scenarios, due to differences in decision-making processes and preference expression. This variability complicates unified modeling, making multi-scenario learning a significant challenge. To address this, we propose a novel reinforcement learning approach that models user preferences across scenarios by modeling user interest evolution across multiple scenarios. Our method employs Double Q-learning to enhance next-item prediction accuracy and optimizes contrastive learning loss using Q-value to make model performance better. Experimental results demonstrate that our approach surpasses state-of-the-art methods in multi-scenario recommendation tasks. Our work offers a fresh perspective on multi-scenario modeling and highlights promising directions for future research.",
      "tldr_zh": "åœ¨ç°å®ä¸–ç•Œçš„æ¨èç³»ç»Ÿä¸­ï¼Œç”¨æˆ·åœ¨é¦–é¡µã€æœç´¢é¡µç­‰å¤šä¸ªåœºæ™¯ï¼ˆMulti-Scenarioï¼‰ä¸­çš„å…´è¶£è¡¨è¾¾å¾€å¾€å…·æœ‰ä¸ä¸€è‡´æ€§ï¼Œè¿™ç»™ç»Ÿä¸€å»ºæ¨¡å¸¦æ¥äº†å·¨å¤§æŒ‘æˆ˜ã€‚ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼Œè¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§æ–°é¢–çš„å¼ºåŒ–å­¦ä¹ ï¼ˆReinforcement Learningï¼‰æ–¹æ³•ï¼Œé€šè¿‡å¯¹è·¨å¤šä¸ªåœºæ™¯çš„ç”¨æˆ·å…´è¶£æ¼”åŒ–ï¼ˆUser Interest Evolutionï¼‰è¿›è¡Œå»ºæ¨¡æ¥æ•æ‰ç”¨æˆ·åå¥½ã€‚è¯¥æ–¹æ³•é‡‡ç”¨åŒé‡Qå­¦ä¹ ï¼ˆDouble Q-learningï¼‰æ¥æé«˜ä¸‹ä¸€é¡¹é¢„æµ‹ï¼ˆNext-item Predictionï¼‰çš„å‡†ç¡®æ€§ï¼Œå¹¶åˆ©ç”¨ Qå€¼ï¼ˆQ-valueï¼‰ä¼˜åŒ–å¯¹æ¯”å­¦ä¹ ï¼ˆContrastive Learningï¼‰æŸå¤±ï¼Œä»è€Œæå‡æ¨¡å‹æ•´ä½“è¡¨ç°ã€‚å®éªŒç»“æœè¯æ˜ï¼Œè¯¥æ–¹æ¡ˆåœ¨å¤šåœºæ™¯æ¨èä»»åŠ¡ä¸Šä¼˜äºç°æœ‰çš„æœ€å…ˆè¿›ï¼ˆState-of-the-artï¼‰æ–¹æ³•ã€‚è¿™é¡¹å·¥ä½œä¸ºå¤šåœºæ™¯å»ºæ¨¡æä¾›äº†å…¨æ–°çš„è§†è§’ï¼Œå¹¶ä¸ºæœªæ¥çš„æ¨èç³»ç»Ÿç ”ç©¶æä¾›äº†é‡è¦çš„å‚è€ƒæ–¹å‘ã€‚",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2506.17682v1",
      "published_date": "2025-06-21 11:27:53 UTC",
      "updated_date": "2025-06-21 11:27:53 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T23:25:15.235585+00:00"
    },
    {
      "arxiv_id": "2506.17680v1",
      "title": "Enhancing Stress-Strain Predictions with Seq2Seq and Cross-Attention based on Small Punch Test",
      "title_zh": "åŸºäºå°å†²æ†è¯•éªŒåŠ Seq2Seq ä¸äº¤å‰æ³¨æ„åŠ›æœºåˆ¶çš„åº”åŠ›-åº”å˜é¢„æµ‹å¢å¼º",
      "authors": [
        "Zhengni Yang",
        "Rui Yang",
        "Weijian Han",
        "Qixin Liu"
      ],
      "abstract": "This paper introduces a novel deep-learning approach to predict true stress-strain curves of high-strength steels from small punch test (SPT) load-displacement data. The proposed approach uses Gramian Angular Field (GAF) to transform load-displacement sequences into images, capturing spatial-temporal features and employs a Sequence-to-Sequence (Seq2Seq) model with an LSTM-based encoder-decoder architecture, enhanced by multi-head cross-attention to improved accuracy. Experimental results demonstrate that the proposed approach achieves superior prediction accuracy, with minimum and maximum mean absolute errors of 0.15 MPa and 5.58 MPa, respectively. The proposed method offers a promising alternative to traditional experimental techniques in materials science, enhancing the accuracy and efficiency of true stress-strain relationship predictions.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§åŸºäºæ·±åº¦å­¦ä¹ çš„æ–°æ–¹æ³•ï¼Œæ—¨åœ¨é€šè¿‡å°å†²å­”è¯•éªŒ (Small Punch Test, SPT) çš„è½½è·-ä½ç§»æ•°æ®é¢„æµ‹é«˜å¼ºåº¦é’¢çš„çœŸå®åº”åŠ›-åº”å˜æ›²çº¿ã€‚è¯¥æ–¹æ³•é‡‡ç”¨æ ¼æ‹‰å§†è§’åœº (Gramian Angular Field, GAF) å°†è½½è·-ä½ç§»åºåˆ—è½¬åŒ–ä¸ºå›¾åƒï¼Œä»¥æœ‰æ•ˆæ•æ‰æ•°æ®ä¸­çš„æ—¶ç©ºç‰¹å¾ã€‚ç ”ç©¶æ ¸å¿ƒåˆ©ç”¨äº†åŸºäº LSTM çš„åºåˆ—åˆ°åºåˆ— (Sequence-to-Sequence, Seq2Seq) ç¼–ç å™¨-è§£ç å™¨æ¶æ„ï¼Œå¹¶å¼•å…¥å¤šå¤´äº¤å‰æ³¨æ„åŠ›æœºåˆ¶ (Multi-Head Cross-Attention) æ¥æ˜¾è‘—æå‡é¢„æµ‹ç²¾åº¦ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•å®ç°äº†å“è¶Šçš„å‡†ç¡®æ€§ï¼Œå…¶æœ€å°å’Œæœ€å¤§å¹³å‡ç»å¯¹è¯¯å·® (Mean Absolute Error, MAE) åˆ†åˆ«ä»…ä¸º 0.15 MPa å’Œ 5.58 MPaã€‚è¿™ç§æ–¹æ³•ä¸ºææ–™ç§‘å­¦é¢†åŸŸä¼ ç»Ÿçš„å®éªŒæŠ€æœ¯æä¾›äº†ä¸€ç§å¼ºæœ‰åŠ›çš„æ›¿ä»£æ–¹æ¡ˆï¼Œæœ‰æ•ˆå¢å¼ºäº†çœŸå®åº”åŠ›-åº”å˜å…³ç³»é¢„æµ‹çš„æ•ˆç‡ä¸ç²¾ç¡®åº¦ã€‚",
      "categories": [
        "cs.LG",
        "cond-mat.mtrl-sci",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "accepted by IJCNN2025",
      "pdf_url": "https://arxiv.org/pdf/2506.17680v1",
      "published_date": "2025-06-21 11:14:54 UTC",
      "updated_date": "2025-06-21 11:14:54 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T23:24:22.468242+00:00"
    },
    {
      "arxiv_id": "2506.18930v2",
      "title": "Dynamic Exploration on Segment-Proposal Graphs for Tubular Centerline Tracking",
      "title_zh": "é¢å‘ç®¡çŠ¶ä¸­å¿ƒçº¿è¿½è¸ªçš„ç‰‡æ®µæè®®å›¾åŠ¨æ€æ¢ç´¢",
      "authors": [
        "Chong Di",
        "Jinglin Zhang",
        "Zhenjiang Li",
        "Jean-Marie Mirebeau",
        "Da Chen",
        "Laurent D. Cohen"
      ],
      "abstract": "Optimal curve methods provide a fundamental framework for tubular centerline tracking. Point-wise approaches, such as minimal paths, are theoretically elegant but often suffer from shortcut and short-branch combination problems in complex scenarios. Nonlocal segment-wise methods address these issues by mapping pre-extracted centerline fragments onto a segment-proposal graph, performing optimization in this abstract space, and recovering the target tubular centerline from the resulting optimal path. In this paradigm, graph construction is critical, as it directly determines the quality of the final result. However, existing segment-wise methods construct graphs in a static manner, requiring all edges and their weights to be pre-computed, i.e. the graph must be sufficiently complete prior to search. Otherwise, the true path may be absent from the candidate space, leading to search failure. To address this limitation, we propose a dynamic exploration scheme for constructing segment-proposal graphs, where the graph is built on demand during the search for optimal paths. By formulating the problem as a Markov decision process, we apply Q-learning to compute edge weights only for visited transitions and adaptively expand the action space when connectivity is insufficient. Experimental results on retinal vessels, roads, and rivers demonstrate consistent improvements over state-of-the-art methods in both accuracy and efficiency.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç®¡çŠ¶ä¸­å¿ƒçº¿è¿½è¸ª(Tubular Centerline Tracking)ä¸­çš„æ ¸å¿ƒæŒ‘æˆ˜ï¼ŒæŒ‡å‡ºä¼ ç»Ÿçš„Point-wiseæ–¹æ³•æ˜“å—çŸ­è·¯é—®é¢˜å¹²æ‰°ï¼Œè€Œç°æœ‰çš„Segment-wiseæ–¹æ³•å› é‡‡ç”¨é™æ€å›¾æ„å»ºæ–¹å¼ï¼Œé¢ä¸´é¢„è®¡ç®—é‡å¤§ä¸”å€™é€‰è·¯å¾„æ˜“ç¼ºå¤±çš„å±€é™ã€‚ä¸ºæ­¤ï¼Œä½œè€…æå‡ºäº†ä¸€ç§åŸºäºDynamic Explorationçš„ç‰‡æ®µæè®®å›¾(Segment-proposal Graphs)æ„å»ºæ–¹æ¡ˆï¼Œåœ¨å¯»æ‰¾æœ€ä¼˜è·¯å¾„çš„è¿‡ç¨‹ä¸­æŒ‰éœ€åŠ¨æ€ç”Ÿæˆå›¾ç»“æ„ã€‚è¯¥æ–¹æ³•å°†è¿½è¸ªä»»åŠ¡å»ºæ¨¡ä¸ºé©¬å°”å¯å¤«å†³ç­–è¿‡ç¨‹(Markov decision process)ï¼Œåˆ©ç”¨Q-learningç®—æ³•ä»…é’ˆå¯¹å·²è®¿é—®çš„è½¬æ¢è®¡ç®—è¾¹æƒé‡ï¼Œå¹¶åœ¨è¿é€šæ€§ä¸è¶³æ—¶è‡ªé€‚åº”æ‰©å±•åŠ¨ä½œç©ºé—´ã€‚åœ¨è§†ç½‘è†œè¡€ç®¡ã€é“è·¯å’Œæ²³æµç­‰å¤šç§æ•°æ®é›†ä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ¡ˆåœ¨å‡†ç¡®æ€§å’Œæ•ˆç‡ä¸Šå‡ä¸€è‡´ä¼˜äºç°æœ‰çš„å…ˆè¿›æ–¹æ³•ï¼Œæœ‰æ•ˆè§£å†³äº†å¤æ‚åœºæ™¯ä¸‹çš„æœç´¢å¤±è´¥é—®é¢˜ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "A real time interactive model that can accurately find centerline of a tubular structure even in complex scenarios. At this version, this work is independent to deep learning-based algorithms",
      "pdf_url": "https://arxiv.org/pdf/2506.18930v2",
      "published_date": "2025-06-21 11:00:17 UTC",
      "updated_date": "2026-01-22 06:45:04 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T23:24:27.236724+00:00"
    },
    {
      "arxiv_id": "2506.17673v1",
      "title": "FaithfulSAE: Towards Capturing Faithful Features with Sparse Autoencoders without External Dataset Dependencies",
      "title_zh": "FaithfulSAEï¼šæ— éœ€å¤–éƒ¨æ•°æ®é›†ä¾èµ–ï¼Œåˆ©ç”¨ç¨€ç–è‡ªç¼–ç å™¨æ•æ‰å¿ å®ç‰¹å¾",
      "authors": [
        "Seonglae Cho",
        "Harryn Oh",
        "Donghyun Lee",
        "Luis Eduardo Rodrigues Vieira",
        "Andrew Bermingham",
        "Ziad El Sayed"
      ],
      "abstract": "Sparse Autoencoders (SAEs) have emerged as a promising solution for decomposing large language model representations into interpretable features. However, Paulo and Belrose (2025) have highlighted instability across different initialization seeds, and Heap et al. (2025) have pointed out that SAEs may not capture model-internal features. These problems likely stem from training SAEs on external datasets - either collected from the Web or generated by another model - which may contain out-of-distribution (OOD) data beyond the model's generalisation capabilities. This can result in hallucinated SAE features, which we term \"Fake Features\", that misrepresent the model's internal activations. To address these issues, we propose FaithfulSAE, a method that trains SAEs on the model's own synthetic dataset. Using FaithfulSAEs, we demonstrate that training SAEs on less-OOD instruction datasets results in SAEs being more stable across seeds. Notably, FaithfulSAEs outperform SAEs trained on web-based datasets in the SAE probing task and exhibit a lower Fake Feature Ratio in 5 out of 7 models. Overall, our approach eliminates the dependency on external datasets, advancing interpretability by better capturing model-internal features while highlighting the often neglected importance of SAE training datasets.",
      "tldr_zh": "æœ¬ç ”ç©¶æå‡ºäº† FaithfulSAEï¼Œä¸€ç§æ—¨åœ¨é€šè¿‡æ¶ˆé™¤å¯¹å¤–éƒ¨æ•°æ®é›†çš„ä¾èµ–æ¥æ•æ‰å¤§å‹è¯­è¨€æ¨¡å‹å†…éƒ¨çœŸå®ç‰¹å¾çš„ Sparse Autoencoders (SAEs) è®­ç»ƒæ–¹æ³•ã€‚é’ˆå¯¹ç°æœ‰ SAEs åœ¨ä¸åŒåˆå§‹åŒ–ç§å­ä¸‹è¡¨ç°ä¸ç¨³å®šä»¥åŠå¯èƒ½äº§ç”Ÿè¯¯å¯¼æ€§ Fake Features çš„é—®é¢˜ï¼Œè¯¥æ–¹æ³•é€šè¿‡åœ¨æ¨¡å‹è‡ªèº«çš„åˆæˆæŒ‡ä»¤æ•°æ®é›†ä¸Šè¿›è¡Œè®­ç»ƒæ¥å‡å°‘ Out-of-Distribution (OOD) æ•°æ®çš„å¹²æ‰°ã€‚å®éªŒè¡¨æ˜ï¼ŒFaithfulSAEs åœ¨ä¸åŒéšæœºç§å­ä¸‹è¡¨ç°å‡ºæ›´é«˜çš„ç¨³å®šæ€§ï¼Œå¹¶åœ¨ SAE probing ä»»åŠ¡ä¸­ä¼˜äºåŸºäº Web æ•°æ®é›†è®­ç»ƒçš„æ¨¡å‹ã€‚åœ¨å¯¹ 7 ä¸ªæ¨¡å‹çš„æµ‹è¯•ä¸­ï¼ŒFaithfulSAEs åœ¨å…¶ä¸­ 5 ä¸ªæ¨¡å‹ä¸Šå®ç°äº†æ›´ä½çš„ Fake Feature Ratioï¼Œè¯æ˜äº†è¯¥æ–¹æ³•åœ¨æ•æ‰æ¨¡å‹å†…éƒ¨ç‰¹å¾æ–¹é¢çš„ä¼˜è¶Šæ€§ã€‚è¿™é¡¹å·¥ä½œå¼ºè°ƒäº† SAEs è®­ç»ƒæ•°æ®é›†å¾€å¾€è¢«å¿½è§†çš„é‡è¦æ€§ï¼Œä¸ºæé«˜æ¨¡å‹å¯è§£é‡Šæ€§æä¾›äº†æ›´å…·å¿ å®åº¦çš„æŠ€æœ¯æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "18 pages, 18 figures",
      "pdf_url": "https://arxiv.org/pdf/2506.17673v1",
      "published_date": "2025-06-21 10:18:25 UTC",
      "updated_date": "2025-06-21 10:18:25 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T23:24:32.755068+00:00"
    },
    {
      "arxiv_id": "2506.17671v2",
      "title": "TPTT: Transforming Pretrained Transformers into Titans",
      "title_zh": "TPTTï¼šå°†é¢„è®­ç»ƒ Transformer è½¬åŒ–ä¸º Titans",
      "authors": [
        "Fabien Furfaro"
      ],
      "abstract": "Transformer-based large language models (LLMs) have achieved strong performance across many natural language processing tasks. Nonetheless, their quadratic computational and memory requirements, particularly in self-attention layers, pose challenges for efficient inference on long contexts and for deployment in resource-limited environments. We present TPTT (Transforming Pretrained Transformers into Titans), a framework designed to augment pretrained Transformers with linearized attention (LiZA) and internal memory gating via Memory as Gate (MaG), applied without full retraining. TPTT supports parameter-efficient fine-tuning (LoRA) and integrates with standard toolkits such as Hugging Face Transformers. We evaluated TPTT on several pretrained models, including Llama-1B, OlMoE-1B-7B, Qwen2.5-1.5B, Gemma3-270m, OpenELM-1.3B, and Mistral-7B, in order to assess applicability across architectures of different scales. Experiments on models with approximately 1 billion parameters, evaluated primarily on the MMLU benchmark, suggest potential improvements in both efficiency and accuracy compared to baseline models. For example, Titans-Llama-1B exhibited up to a 20\\% relative increase in Exact Match scores in one-shot evaluation. An additional finding is that it is possible to convert a quadratic-attention model into a purely linear-attention model using the DeltaProduct mechanism. All training runs were carried out with modest computational resources. These preliminary findings indicate that TPTT may help adapt pretrained LLMs for long-context tasks with limited overhead. Further studies on larger models and a broader set of benchmarks will be necessary to evaluate the generality and robustness of the framework. Code is available at https://github.com/fabienfrfr/tptt . Python package at https://pypi.org/project/tptt/ .",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† TPTT (Transforming Pretrained Transformers into Titans) æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³ Transformer æ¨¡å‹åœ¨å¤„ç†é•¿ä¸Šä¸‹æ–‡æ—¶å› è‡ªæ³¨æ„åŠ›æœºåˆ¶å¸¦æ¥çš„å¹³æ–¹çº§è®¡ç®—ä¸å†…å­˜å¼€é”€é—®é¢˜ã€‚TPTT é€šè¿‡å¼•å…¥çº¿æ€§åŒ–æ³¨æ„åŠ›æœºåˆ¶ (LiZA) å’Œå†…éƒ¨å­˜å‚¨é—¨æ§æŠ€æœ¯ (Memory as Gate, MaG)ï¼Œåœ¨æ— éœ€å®Œæ•´é‡æ–°è®­ç»ƒçš„æƒ…å†µä¸‹å¢å¼ºé¢„è®­ç»ƒæ¨¡å‹ã€‚è¯¥æ¡†æ¶æ”¯æŒå‚æ•°é«˜æ•ˆå¾®è°ƒ (LoRA)ï¼Œå¹¶é›†æˆäº† DeltaProduct æœºåˆ¶ï¼Œèƒ½å¤Ÿå°†ä¼ ç»Ÿçš„å¹³æ–¹æ³¨æ„åŠ›æ¨¡å‹è½¬æ¢ä¸ºçº¯çº¿æ€§æ³¨æ„åŠ›æ¨¡å‹ã€‚ç ”ç©¶åœ¨ Llama-1Bã€Qwen2.5-1.5B å’Œ Mistral-7B ç­‰å¤šç§è§„æ¨¡çš„æ¶æ„ä¸Šè¿›è¡Œäº†éªŒè¯ï¼Œå®éªŒç»“æœè¡¨æ˜ TPTT åœ¨æå‡æ•ˆç‡çš„åŒæ—¶ä¹Ÿå¢å¼ºäº†å‡†ç¡®æ€§ã€‚ä¾‹å¦‚ï¼ŒTitans-Llama-1B åœ¨ MMLU åŸºå‡†æµ‹è¯•çš„å•æ¬¡è¯„ä¼°ä¸­ï¼Œå‡†ç¡®ç‡ (Exact Match) ç›¸å¯¹æå‡äº† 20%ã€‚è¿™é¡¹å·¥ä½œè¯æ˜äº†åœ¨æœ‰é™çš„è®¡ç®—èµ„æºä¸‹ï¼Œå°†é¢„è®­ç»ƒå¤§è¯­è¨€æ¨¡å‹é€‚é…ä¸ºä½å¼€é”€ã€é•¿ä¸Šä¸‹æ–‡ä»»åŠ¡æ¨¡å‹çš„å¯è¡Œæ€§ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "14 pages, 2 figure",
      "pdf_url": "https://arxiv.org/pdf/2506.17671v2",
      "published_date": "2025-06-21 10:06:07 UTC",
      "updated_date": "2025-08-31 14:32:19 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T23:24:35.734947+00:00"
    },
    {
      "arxiv_id": "2506.17667v3",
      "title": "PhysUniBench: An Undergraduate-Level Physics Reasoning Benchmark for Multimodal Models",
      "title_zh": "PhysUniBenchï¼šé¢å‘å¤šæ¨¡æ€æ¨¡å‹çš„æœ¬ç§‘ç‰©ç†æ¨ç†è¯„æµ‹åŸºå‡†",
      "authors": [
        "Lintao Wang",
        "Encheng Su",
        "Jiaqi Liu",
        "Pengze Li",
        "Peng Xia",
        "Jiabei Xiao",
        "Wenlong Zhang",
        "Xinnan Dai",
        "Xi Chen",
        "Yuan Meng",
        "Mingyu Ding",
        "Lei Bai",
        "Wanli Ouyang",
        "Shixiang Tang",
        "Aoran Wang",
        "Xinzhu Ma"
      ],
      "abstract": "Physics problem-solving is a challenging domain for large AI models, requiring integration of conceptual understanding, mathematical reasoning, and interpretation of physical diagrams. Current evaluation methodologies show notable limitations in capturing the breadth and complexity of undergraduate-level physics, underscoring the need for more rigorous assessments. To this end, we present PhysUniBench, a large-scale multimodal benchmark designed to evaluate and improve the reasoning capabilities of multimodal large language models (MLLMs) specifically on undergraduate-level physics problems. PhysUniBench consists of 3,304 physics questions spanning 8 major sub-disciplines of physics, each accompanied by one visual diagrams. The benchmark includes both open-ended and multiple-choice questions, systematically curated and difficulty-rated through an iterative model-in-the-loop process. The benchmark's construction involved a rigorous multi-stage process, including multiple roll-outs, expert-level evaluation, automated filtering of easily solved problems, and a nuanced difficulty grading system with five levels. Through extensive experiments, we observe that current state-of-the-art models encounter substantial challenges in physics reasoning. For example, GPT-4o mini achieves only about 34.2% accuracy in the proposed PhysUniBench. These results highlight that current MLLMs struggle with advanced physics reasoning, especially on multi-step problems and those requiring precise diagram interpretation. By providing a broad and rigorous assessment tool, PhysUniBench aims to drive progress in AI for Science, encouraging the development of models with stronger physical reasoning, problem-solving skills, and multimodal understanding. The benchmark and evaluation scripts are available at https://prismax-team.github.io/PhysUniBenchmark/.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¨å‡ºäº† PhysUniBenchï¼Œè¿™æ˜¯ä¸€ä¸ªæ—¨åœ¨è¯„ä¼°å’Œæå‡å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ (MLLMs) åœ¨æœ¬ç§‘æ°´å¹³ç‰©ç†æ¨ç†èƒ½åŠ›çš„å¤§è§„æ¨¡å¤šæ¨¡æ€åŸºå‡†æµ‹è¯•ã€‚è¯¥åŸºå‡†ç”± 3,304 ä¸ªæ¶µç›– 8 ä¸ªä¸»è¦ç‰©ç†å­å­¦ç§‘çš„é—®é¢˜ç»„æˆï¼Œæ¯ä¸ªé—®é¢˜å‡é…æœ‰ä¸€å¼ è§†è§‰å›¾è¡¨ (visual diagrams)ï¼ŒåŒ…å«å¼€æ”¾å¼å’Œå¤šé¡¹é€‰æ‹©é¢˜å‹ã€‚PhysUniBench çš„æ„å»ºç»å†äº†ä¸“å®¶è¯„ä¼°ã€è‡ªåŠ¨è¿‡æ»¤ç®€å•é¢˜ç›®ä»¥åŠäº”çº§éš¾åº¦åˆ†çº§ç­‰ä¸¥è°¨çš„å¤šé˜¶æ®µè¿‡ç¨‹ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œå³ä¾¿æ˜¯å½“å‰çš„é¡¶å°–æ¨¡å‹åœ¨ç‰©ç†æ¨ç†æ–¹é¢ä¹Ÿé¢ä¸´æ˜¾è‘—æŒ‘æˆ˜ï¼Œä¾‹å¦‚ GPT-4o mini åœ¨è¯¥æµ‹è¯•é›†ä¸Šçš„å‡†ç¡®ç‡ä»…ä¸º 34.2%ã€‚ç ”ç©¶å‘ç°å½“å‰çš„ MLLMs åœ¨å¤šæ­¥æ¨ç† (multi-step reasoning) å’Œç²¾ç¡®å›¾è¡¨è§£è¯»æ–¹é¢å­˜åœ¨æ˜æ˜¾çŸ­æ¿ã€‚PhysUniBench ä¸º AI for Science æä¾›äº†æ›´å…·æŒ‘æˆ˜æ€§çš„è¯„ä¼°å·¥å…·ï¼Œæ—¨åœ¨æ¨åŠ¨å…·æœ‰æ›´å¼ºç‰©ç†æ¨ç†å’Œå¤šæ¨¡æ€ç†è§£èƒ½åŠ›çš„æ¨¡å‹å¼€å‘ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2506.17667v3",
      "published_date": "2025-06-21 09:55:42 UTC",
      "updated_date": "2025-06-27 04:45:30 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T23:24:39.219245+00:00"
    },
    {
      "arxiv_id": "2506.17644v1",
      "title": "Measuring and Augmenting Large Language Models for Solving Capture-the-Flag Challenges",
      "title_zh": "é¢å‘å¤ºæ——èµ›æŒ‘æˆ˜çš„å¤§è¯­è¨€æ¨¡å‹è¯„ä¼°ä¸å¢å¼º",
      "authors": [
        "Zimo Ji",
        "Daoyuan Wu",
        "Wenyuan Jiang",
        "Pingchuan Ma",
        "Zongjie Li",
        "Shuai Wang"
      ],
      "abstract": "Capture-the-Flag (CTF) competitions are crucial for cybersecurity education and training. As large language models (LLMs) evolve, there is increasing interest in their ability to automate CTF challenge solving. For example, DARPA has organized the AIxCC competition since 2023 to advance AI-powered automated offense and defense. However, this demands a combination of multiple abilities, from knowledge to reasoning and further to actions. In this paper, we highlight the importance of technical knowledge in solving CTF problems and deliberately construct a focused benchmark, CTFKnow, with 3,992 questions to measure LLMs' performance in this core aspect. Our study offers a focused and innovative measurement of LLMs' capability in understanding CTF knowledge and applying it to solve CTF challenges. Our key findings reveal that while LLMs possess substantial technical knowledge, they falter in accurately applying this knowledge to specific scenarios and adapting their strategies based on feedback from the CTF environment.\n  Based on insights derived from this measurement study, we propose CTFAgent, a novel LLM-driven framework for advancing CTF problem-solving. CTFAgent introduces two new modules: two-stage Retrieval Augmented Generation (RAG) and interactive Environmental Augmentation, which enhance LLMs' technical knowledge and vulnerability exploitation on CTF, respectively. Our experimental results show that, on two popular CTF datasets, CTFAgent both achieves over 80% performance improvement. Moreover, in the recent picoCTF2024 hosted by CMU, CTFAgent ranked in the top 23.6% of nearly 7,000 participating teams. This reflects the benefit of our measurement study and the potential of our framework in advancing LLMs' capabilities in CTF problem-solving.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å¤§è¯­è¨€æ¨¡å‹ (LLMs) åœ¨è‡ªåŠ¨åŒ–è§£å†³ç½‘ç»œå®‰å…¨å¤ºæ——èµ› (Capture-the-Flag, CTF) æŒ‘æˆ˜ä¸­çš„æ½œåŠ›ä¸å±€é™æ€§ã€‚ä¸ºäº†å‡†ç¡®è¡¡é‡æ¨¡å‹åœ¨è¿™ä¸€æ ¸å¿ƒé¢†åŸŸçš„èƒ½åŠ›ï¼Œç ”ç©¶äººå‘˜æ„å»ºäº†åŒ…å« 3,992 ä¸ªé—®é¢˜çš„åŸºå‡†æµ‹è¯•é›† CTFKnowï¼Œé‡ç‚¹è¯„ä¼° LLMs å¯¹ CTF çŸ¥è¯†çš„ç†è§£ä¸åº”ç”¨è¡¨ç°ã€‚å®éªŒå‘ç°ï¼Œå°½ç®¡ LLMs æ‹¥æœ‰ä¸°å¯Œçš„æŠ€æœ¯çŸ¥è¯†ï¼Œä½†åœ¨å°†çŸ¥è¯†åº”ç”¨äºç‰¹å®šåœºæ™¯ä»¥åŠæ ¹æ®ç¯å¢ƒåé¦ˆè°ƒæ•´ç­–ç•¥æ–¹é¢ä»å­˜åœ¨ä¸è¶³ã€‚åŸºäºæ­¤ï¼Œç ”ç©¶æå‡ºäº† CTFAgent æ¡†æ¶ï¼Œè¯¥æ¡†æ¶å¼•å…¥äº†ä¸¤é˜¶æ®µæ£€ç´¢å¢å¼ºç”Ÿæˆ (Retrieval Augmented Generation, RAG) å’Œäº¤äº’å¼ç¯å¢ƒå¢å¼º (Environmental Augmentation) æ¨¡å—ï¼Œåˆ†åˆ«æå‡äº†æ¨¡å‹çš„æŠ€æœ¯çŸ¥è¯†å‚¨å¤‡å’Œæ¼æ´åˆ©ç”¨èƒ½åŠ›ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒCTFAgent åœ¨ä¸¤ä¸ªä¸»æµ CTF æ•°æ®é›†ä¸Šå®ç°äº†è¶…è¿‡ 80% çš„æ€§èƒ½æå‡ï¼Œå¹¶åœ¨ picoCTF2024 ç«èµ›ä¸­ä½åˆ—å…¨çƒå‚èµ›é˜Ÿä¼çš„å‰ 23.6%ã€‚è¯¥å·¥ä½œä¸ä»…ä¸º LLMs åœ¨ CTF é¢†åŸŸçš„åº”ç”¨æä¾›äº†ç§‘å­¦çš„è¡¡é‡æ‰‹æ®µï¼Œä¹Ÿé€šè¿‡åˆ›æ–°çš„å¢å¼ºæ¡†æ¶éªŒè¯äº†å…¶åœ¨è‡ªåŠ¨åŒ–ç½‘ç»œæ”»é˜²ä¸­çš„å·¨å¤§æ½œåŠ›ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2506.17644v1",
      "published_date": "2025-06-21 08:56:20 UTC",
      "updated_date": "2025-06-21 08:56:20 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T23:27:08.053167+00:00"
    },
    {
      "arxiv_id": "2506.17639v1",
      "title": "RLRC: Reinforcement Learning-based Recovery for Compressed Vision-Language-Action Models",
      "title_zh": "RLRCï¼šåŸºäºå¼ºåŒ–å­¦ä¹ çš„å‹ç¼©è§†è§‰-è¯­è¨€-åŠ¨ä½œæ¨¡å‹æ¢å¤",
      "authors": [
        "Yuxuan Chen",
        "Xiao Li"
      ],
      "abstract": "Vision-Language-Action models (VLA) have demonstrated remarkable capabilities and promising potential in solving complex robotic manipulation tasks. However, their substantial parameter sizes and high inference latency pose significant challenges for real-world deployment, particularly on resource-constrained robotic platforms. To address this issue, we begin by conducting an extensive empirical study to explore the effectiveness of model compression techniques when applied to VLAs. Building on the insights gained from these preliminary experiments, we propose RLRC, a three-stage recovery method for compressed VLAs, including structured pruning, performance recovery based on SFT and RL, and further quantization. RLRC achieves up to an 8x reduction in memory usage and a 2.3x improvement in inference throughput, while maintaining or even surpassing the original VLA's task success rate. Extensive experiments show that RLRC consistently outperforms existing compression baselines, demonstrating strong potential for on-device deployment of VLAs. Project website: https://rlrc-vla.github.io",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹Vision-Language-Action (VLA) æ¨¡å‹åœ¨æœºå™¨äººå¹³å°éƒ¨ç½²æ—¶é¢ä¸´çš„å‚æ•°é‡å¤§å’Œæ¨ç†å»¶è¿Ÿé«˜çš„é—®é¢˜ï¼Œæå‡ºäº†åä¸º RLRC çš„ä¸‰é˜¶æ®µå‹ç¼©æ¢å¤æ¡†æ¶ã€‚è¯¥æ–¹æ³•ç»“åˆäº†ç»“æ„åŒ–å‰ªæ (structured pruning)ã€åŸºäºç›‘ç£å¾®è°ƒ (SFT) ä¸å¼ºåŒ–å­¦ä¹  (RL) çš„æ€§èƒ½æ¢å¤ä»¥åŠè¿›ä¸€æ­¥çš„é‡åŒ– (quantization) æŠ€æœ¯ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒRLRC å®ç°äº†é«˜è¾¾ 8 å€çš„å†…å­˜å ç”¨ç¼©å‡å’Œ 2.3 å€çš„æ¨ç†ååé‡æå‡ï¼ŒåŒæ—¶åœ¨ä»»åŠ¡æˆåŠŸç‡ä¸Šä¿æŒç”šè‡³è¶…è¶Šäº†åŸå§‹ VLA æ¨¡å‹ã€‚è¯¥ç ”ç©¶è¯æ˜äº† RLRC æ€§èƒ½æ˜¾è‘—ä¼˜äºç°æœ‰çš„æ¨¡å‹å‹ç¼©åŸºçº¿ï¼Œä¸ºåœ¨èµ„æºå—é™çš„ç§»åŠ¨è®¾å¤‡ä¸Šéƒ¨ç½²é«˜æ€§èƒ½ VLA æ¨¡å‹æä¾›äº†åˆ‡å®å¯è¡Œçš„æŠ€æœ¯è·¯å¾„ã€‚",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2506.17639v1",
      "published_date": "2025-06-21 08:45:32 UTC",
      "updated_date": "2025-06-21 08:45:32 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T23:25:35.108882+00:00"
    },
    {
      "arxiv_id": "2506.17633v1",
      "title": "Adaptive Multi-prompt Contrastive Network for Few-shot Out-of-distribution Detection",
      "title_zh": "é¢å‘å°æ ·æœ¬åˆ†å¸ƒå¤–æ£€æµ‹çš„è‡ªé€‚åº”å¤šæç¤ºå¯¹æ¯”ç½‘ç»œ",
      "authors": [
        "Xiang Fang",
        "Arvind Easwaran",
        "Blaise Genest"
      ],
      "abstract": "Out-of-distribution (OOD) detection attempts to distinguish outlier samples to prevent models trained on the in-distribution (ID) dataset from producing unavailable outputs. Most OOD detection methods require many IID samples for training, which seriously limits their real-world applications. To this end, we target a challenging setting: few-shot OOD detection, where {Only a few {\\em labeled ID} samples are available.} Therefore, few-shot OOD detection is much more challenging than the traditional OOD detection setting. Previous few-shot OOD detection works ignore the distinct diversity between different classes. In this paper, we propose a novel network: Adaptive Multi-prompt Contrastive Network (AMCN), which adapts the ID-OOD separation boundary by learning inter- and intra-class distribution. To compensate for the absence of OOD and scarcity of ID {\\em image samples}, we leverage CLIP, connecting text with images, engineering learnable ID and OOD {\\em textual prompts}. Specifically, we first generate adaptive prompts (learnable ID prompts, label-fixed OOD prompts and label-adaptive OOD prompts). Then, we generate an adaptive class boundary for each class by introducing a class-wise threshold. Finally, we propose a prompt-guided ID-OOD separation module to control the margin between ID and OOD prompts. Experimental results show that AMCN outperforms other state-of-the-art works.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å°‘æ ·æœ¬åˆ†å¸ƒå¤–æ£€æµ‹(Few-shot Out-of-distribution Detection)ä»»åŠ¡ä¸­æ ·æœ¬ç¨€ç¼ºåŠç±»åˆ«å¤šæ ·æ€§è¢«å¿½è§†çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§è‡ªé€‚åº”å¤šæç¤ºå¯¹æ¯”ç½‘ç»œ(Adaptive Multi-prompt Contrastive Network, AMCN)ã€‚è¯¥ç½‘ç»œåˆ©ç”¨CLIPæ¨¡å‹å°†å›¾åƒä¸æ–‡æœ¬å…³è”ï¼Œé€šè¿‡ç”Ÿæˆå¯å­¦ä¹ IDæç¤º(learnable ID prompts)ã€æ ‡ç­¾å›ºå®šåŠæ ‡ç­¾è‡ªé€‚åº”çš„OODæç¤ºæ¥å¼¥è¡¥æ ‡æ³¨æ•°æ®çš„ä¸è¶³ã€‚ä¸ºäº†æ›´ç²¾å‡†åœ°åˆ»ç”»åˆ†å¸ƒå·®å¼‚ï¼ŒAMCNå¼•å…¥äº†ç±»åˆ«é˜ˆå€¼(class-wise threshold)æ¥ä¸ºæ¯ä¸ªç±»åˆ«æ„å»ºè‡ªé€‚åº”çš„ç±»åˆ«è¾¹ç•Œã€‚æ­¤å¤–ï¼Œè®ºæ–‡è¿˜è®¾è®¡äº†æç¤ºå¼•å¯¼çš„ID-OODåˆ†ç¦»æ¨¡å—(prompt-guided ID-OOD separation module)ï¼Œæ—¨åœ¨é€šè¿‡å­¦ä¹ ç±»é—´å’Œç±»å†…åˆ†å¸ƒæ¥æœ‰æ•ˆæ§åˆ¶æç¤ºé—´çš„è¾¹é™…ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒAMCNåœ¨å¤„ç†å…·æœ‰æŒ‘æˆ˜æ€§çš„å°‘æ ·æœ¬åœºæ™¯æ—¶æ€§èƒ½å“è¶Šï¼Œå…¶å®æµ‹è¡¨ç°ä¼˜äºå½“å‰çš„å…ˆè¿›æ¨¡å‹ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "ICML 2025",
      "pdf_url": "https://arxiv.org/pdf/2506.17633v1",
      "published_date": "2025-06-21 08:31:29 UTC",
      "updated_date": "2025-06-21 08:31:29 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T23:25:33.782965+00:00"
    },
    {
      "arxiv_id": "2506.17631v3",
      "title": "Time-Prompt: Integrated Heterogeneous Prompts for Unlocking LLMs in Time Series Forecasting",
      "title_zh": "Time-Promptï¼šé›†æˆå¼‚æ„æç¤ºè§£é”å¤§è¯­è¨€æ¨¡å‹åœ¨æ—¶é—´åºåˆ—é¢„æµ‹ä¸­çš„æ½œåŠ›",
      "authors": [
        "Zesen Wang",
        "Lijuan Lan",
        "Yonggang Li"
      ],
      "abstract": "Time series forecasting aims to model temporal dependencies among variables for future state inference, holding significant importance and widespread applications in real-world scenarios. Although deep learning-based methods have achieved remarkable progress, they still exhibit suboptimal performance in long-term forecasting. Recent research demonstrates that large language models (LLMs) achieve promising performance in time series forecasting, but this progress is still met with skepticism about whether LLMs are truly useful for this task. To address this, we propose Time-Prompt, a framework for activating LLMs for time series forecasting. Specifically, we first construct a unified prompt paradigm with learnable soft prompts to guide the LLM's behavior and textualized hard prompts to enhance the time series representations. Second, to enhance LLM' comprehensive understanding of the forecasting task, we design a semantic space embedding and cross-modal alignment module to achieve fusion of temporal and textual data. Finally, we efficiently fine-tune the LLM's parameters using time series data. Furthermore, we focus on carbon emissions, aiming to provide a modest contribution to global carbon neutrality. Comprehensive evaluations on 6 public datasets and 3 carbon emission datasets demonstrate that Time-Prompt is a powerful framework for time series forecasting.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†Time-Promptæ¡†æ¶ï¼Œæ—¨åœ¨æ¿€æ´»å¤§å‹è¯­è¨€æ¨¡å‹(Large Language Models, LLMs)åœ¨æ—¶é—´åºåˆ—é¢„æµ‹(Time Series Forecasting)é¢†åŸŸçš„åº”ç”¨æ½œåŠ›ã€‚ä¸ºäº†è§£å†³ä¼ ç»Ÿæ·±åº¦å­¦ä¹ æ¨¡å‹åœ¨é•¿æœŸé¢„æµ‹ä¸­çš„å±€é™ï¼Œè¯¥æ¡†æ¶æ„å»ºäº†ç»Ÿä¸€çš„æç¤ºèŒƒå¼ï¼Œç»“åˆå¯å­¦ä¹ çš„soft promptså¼•å¯¼æ¨¡å‹è¡Œä¸ºä¸æ–‡æœ¬åŒ–çš„hard promptså¢å¼ºåºåˆ—è¡¨ç¤ºã€‚æ­¤å¤–ï¼Œç ”ç©¶è¿˜è®¾è®¡äº†è¯­ä¹‰ç©ºé—´åµŒå…¥(semantic space embedding)ä¸è·¨æ¨¡æ€å¯¹é½(cross-modal alignment)æ¨¡å—ï¼ŒæˆåŠŸå®ç°äº†æ—¶é—´æ•°æ®ä¸æ–‡æœ¬æ•°æ®çš„ç‰¹å¾èåˆã€‚é€šè¿‡å¯¹æ¨¡å‹å‚æ•°è¿›è¡Œé«˜æ•ˆå¾®è°ƒï¼ŒTime-Promptåœ¨6ä¸ªå…¬å…±æ•°æ®é›†å’Œ3ä¸ªç¢³æ’æ”¾æ•°æ®é›†ä¸Šå±•ç°äº†å“è¶Šçš„æ€§èƒ½ã€‚å®éªŒç»“æœè¯æ˜è¯¥æ¡†æ¶èƒ½æœ‰æ•ˆæå‡é¢„æµ‹å‡†ç¡®åº¦ï¼Œå¹¶ä¸ºå®ç°å…¨çƒç¢³ä¸­å’Œç›®æ ‡æä¾›äº†æœ‰åŠ›çš„æŠ€æœ¯æ”¯æŒã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2506.17631v3",
      "published_date": "2025-06-21 08:22:25 UTC",
      "updated_date": "2025-11-10 12:01:48 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T23:26:41.524350+00:00"
    },
    {
      "arxiv_id": "2506.17629v1",
      "title": "CLiViS: Unleashing Cognitive Map through Linguistic-Visual Synergy for Embodied Visual Reasoning",
      "title_zh": "CLiViSï¼šé€šè¿‡è¯­è¨€-è§†è§‰ååŒé‡Šæ”¾è®¤çŸ¥åœ°å›¾æ•ˆèƒ½ï¼Œå®ç°å…·èº«è§†è§‰æ¨ç†",
      "authors": [
        "Kailing Li",
        "Qi'ao Xu",
        "Tianwen Qian",
        "Yuqian Fu",
        "Yang Jiao",
        "Xiaoling Wang"
      ],
      "abstract": "Embodied Visual Reasoning (EVR) seeks to follow complex, free-form instructions based on egocentric video, enabling semantic understanding and spatiotemporal reasoning in dynamic environments. Despite its promising potential, EVR encounters significant challenges stemming from the diversity of complex instructions and the intricate spatiotemporal dynamics in long-term egocentric videos. Prior solutions either employ Large Language Models (LLMs) over static video captions, which often omit critical visual details, or rely on end-to-end Vision-Language Models (VLMs) that struggle with stepwise compositional reasoning. Consider the complementary strengths of LLMs in reasoning and VLMs in perception, we propose CLiViS. It is a novel training-free framework that leverages LLMs for high-level task planning and orchestrates VLM-driven open-world visual perception to iteratively update the scene context. Building on this synergy, the core of CLiViS is a dynamic Cognitive Map that evolves throughout the reasoning process. This map constructs a structured representation of the embodied scene, bridging low-level perception and high-level reasoning. Extensive experiments across multiple benchmarks demonstrate the effectiveness and generality of CLiViS, especially in handling long-term visual dependencies. Code is available at https://github.com/Teacher-Tom/CLiViS.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å…·èº«è§†è§‰æ¨ç†(Embodied Visual Reasoning, EVR)åœ¨ç¬¬ä¸€è§†è§’è§†é¢‘ä¸­é¢ä¸´çš„æŒ‡ä»¤å¤æ‚æ€§å’Œæ—¶ç©ºåŠ¨æ€æŒ‘æˆ˜ï¼Œæå‡ºäº†CLiViSæ¡†æ¶ã€‚ä½œä¸ºä¸€ä¸ªæ— éœ€è®­ç»ƒ(training-free)çš„æ¡†æ¶ï¼ŒCLiViSåˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹(LLMs)è¿›è¡Œé«˜å±‚ä»»åŠ¡è§„åˆ’ï¼Œå¹¶åè°ƒè§†è§‰è¯­è¨€æ¨¡å‹(VLMs)é©±åŠ¨çš„å¼€æ”¾ä¸–ç•Œè§†è§‰æ„ŸçŸ¥ä»¥è¿­ä»£æ›´æ–°åœºæ™¯ä¸Šä¸‹æ–‡ã€‚è¯¥æ¡†æ¶çš„æ ¸å¿ƒåœ¨äºæ„å»ºä¸€ä¸ªéšæ¨ç†è¿‡ç¨‹æ¼”åŒ–çš„åŠ¨æ€è®¤çŸ¥åœ°å›¾(Cognitive Map)ï¼Œé€šè¿‡å»ºç«‹å…·èº«åœºæ™¯çš„ç»“æ„åŒ–è¡¨ç¤ºï¼Œæœ‰æ•ˆæ¡¥æ¥äº†åº•å±‚æ„ŸçŸ¥ä¸é«˜å±‚æ¨ç†ã€‚é€šè¿‡è¿™ç§è¯­è¨€ä¸è§†è§‰çš„ååŒæœºåˆ¶ï¼ŒCLiViSå…‹æœäº†ä¼ ç»Ÿæ–¹æ³•åœ¨è§†è§‰ç»†èŠ‚ä¸¢å¤±æˆ–é€æ­¥æ¨ç†èƒ½åŠ›ä¸è¶³æ–¹é¢çš„å±€é™ã€‚åœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼ŒCLiViSåœ¨å¤„ç†é•¿æœŸè§†è§‰ä¾èµ–(long-term visual dependencies)ä»»åŠ¡ä¸­å±•ç°å‡ºå“è¶Šçš„æœ‰æ•ˆæ€§å’Œé€šç”¨æ€§ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2506.17629v1",
      "published_date": "2025-06-21 08:11:40 UTC",
      "updated_date": "2025-06-21 08:11:40 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T23:25:47.353228+00:00"
    },
    {
      "arxiv_id": "2506.21612v1",
      "title": "AdaptGOT: A Pre-trained Model for Adaptive Contextual POI Representation Learning",
      "title_zh": "AdaptGOTï¼šé¢å‘è‡ªé€‚åº”ä¸Šä¸‹æ–‡ POI è¡¨ç¤ºå­¦ä¹ çš„é¢„è®­ç»ƒæ¨¡å‹",
      "authors": [
        "Xiaobin Ren",
        "Xinyu Zhu",
        "Kaiqi Zhao"
      ],
      "abstract": "Currently, considerable strides have been achieved in Point-of-Interest (POI) embedding methodologies, driven by the emergence of novel POI tasks like recommendation and classification. Despite the success of task-specific, end-to-end models in POI embedding, several challenges remain. These include the need for more effective multi-context sampling strategies, insufficient exploration of multiple POI contexts, limited versatility, and inadequate generalization. To address these issues, we propose the AdaptGOT model, which integrates both the (Adapt)ive representation learning technique and the Geographical-Co-Occurrence-Text (GOT) representation with a particular emphasis on Geographical location, Co-Occurrence and Textual information. The AdaptGOT model comprises three key components: (1) contextual neighborhood generation, which integrates advanced mixed sampling techniques such as KNN, density-based, importance-based, and category-aware strategies to capture complex contextual neighborhoods; (2) an advanced GOT representation enhanced by an attention mechanism, designed to derive high-quality, customized representations and efficiently capture complex interrelations between POIs; and (3) the MoE-based adaptive encoder-decoder architecture, which ensures topological consistency and enriches contextual representation by minimizing Jensen-Shannon divergence across varying contexts. Experiments on two real-world datasets and multiple POI tasks substantiate the superior performance of the proposed AdaptGOT model.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç°æœ‰å…´è¶£ç‚¹(Point-of-Interest, POI)åµŒå…¥æ–¹æ³•åœ¨å¤šä¸Šä¸‹æ–‡é‡‡æ ·ã€ä¸Šä¸‹æ–‡æ¢ç´¢åŠæ³›åŒ–èƒ½åŠ›æ–¹é¢çš„å±€é™æ€§ï¼Œæå‡ºäº†AdaptGOTæ¨¡å‹ã€‚è¯¥æ¨¡å‹åˆ›æ–°æ€§åœ°ç»“åˆäº†è‡ªé€‚åº”è¡¨å¾å­¦ä¹ (Adaptive representation learning)å’Œé›†æˆåœ°ç†ä½ç½®ã€å…±ç°åŠæ–‡æœ¬ä¿¡æ¯çš„GOT (Geographical-Co-Occurrence-Text)è¡¨å¾æ–¹æ³•ã€‚AdaptGOTé€šè¿‡æ··åˆé‡‡æ ·æŠ€æœ¯æ•æ‰å¤æ‚çš„ä¸Šä¸‹æ–‡é‚»åŸŸï¼Œå¹¶åˆ©ç”¨å¢å¼ºçš„æ³¨æ„åŠ›æœºåˆ¶(attention mechanism)æå–é«˜è´¨é‡çš„å®šåˆ¶åŒ–è¡¨å¾ä»¥æ•è·POIé—´çš„å¤æ‚å…³è”ã€‚æ­¤å¤–ï¼Œæ¨¡å‹é‡‡ç”¨äº†åŸºäºæ··åˆä¸“å®¶æ¨¡å‹(MoE-based)çš„è‡ªé€‚åº”ç¼–ç å™¨-è§£ç å™¨æ¶æ„ï¼Œé€šè¿‡æœ€å°åŒ–è©¹æ£®-é¦™å†œæ•£åº¦(Jensen-Shannon divergence)ç¡®ä¿äº†ä¸åŒä¸Šä¸‹æ–‡ä¸‹çš„æ‹“æ‰‘ä¸€è‡´æ€§ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒAdaptGOTåœ¨å¤šé¡¹POIä»»åŠ¡å’ŒçœŸå®æ•°æ®é›†ä¸Šå‡å±•ç°å‡ºä¼˜å¼‚çš„æ€§èƒ½ï¼Œæ˜¾è‘—æå‡äº†POIè¡¨å¾å­¦ä¹ çš„è´¨é‡ä¸é€šç”¨æ€§ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2506.21612v1",
      "published_date": "2025-06-21 08:06:06 UTC",
      "updated_date": "2025-06-21 08:06:06 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T23:25:50.196731+00:00"
    },
    {
      "arxiv_id": "2506.17621v1",
      "title": "Exploiting Efficiency Vulnerabilities in Dynamic Deep Learning Systems",
      "title_zh": "æŒ–æ˜åŠ¨æ€æ·±åº¦å­¦ä¹ ç³»ç»Ÿä¸­çš„æ•ˆç‡æ¼æ´",
      "authors": [
        "Ravishka Rathnasuriya",
        "Wei Yang"
      ],
      "abstract": "The growing deployment of deep learning models in real-world environments has intensified the need for efficient inference under strict latency and resource constraints. To meet these demands, dynamic deep learning systems (DDLSs) have emerged, offering input-adaptive computation to optimize runtime efficiency. While these systems succeed in reducing cost, their dynamic nature introduces subtle and underexplored security risks. In particular, input-dependent execution pathways create opportunities for adversaries to degrade efficiency, resulting in excessive latency, energy usage, and potential denial-of-service in time-sensitive deployments. This work investigates the security implications of dynamic behaviors in DDLSs and reveals how current systems expose efficiency vulnerabilities exploitable by adversarial inputs. Through a survey of existing attack strategies, we identify gaps in the coverage of emerging model architectures and limitations in current defense mechanisms. Building on these insights, we propose to examine the feasibility of efficiency attacks on modern DDLSs and develop targeted defenses to preserve robustness under adversarial conditions.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†åŠ¨æ€æ·±åº¦å­¦ä¹ ç³»ç»Ÿ(Dynamic Deep Learning Systems, DDLSs)åœ¨è¿½æ±‚æ¨ç†æ•ˆç‡æ—¶æš´éœ²çš„å®‰å…¨é£é™©ï¼Œç‰¹åˆ«æ˜¯è¾“å…¥è‡ªé€‚åº”è®¡ç®—(Input-adaptive computation)æ‰€å¼•å…¥çš„éšè”½æ•ˆç‡æ¼æ´ã€‚ç ”ç©¶æŒ‡å‡ºï¼Œç”±äºDDLSsçš„æ‰§è¡Œè·¯å¾„é«˜åº¦ä¾èµ–äºè¾“å…¥æ•°æ®ï¼Œæ”»å‡»è€…å¯ä»¥åˆ©ç”¨å¯¹æŠ—æ€§è¾“å…¥(Adversarial inputs)è¯±å‘æé«˜çš„å»¶è¿Ÿå’Œèƒ½æºæ¶ˆè€—ï¼Œä»è€Œåœ¨æ—¶é—´æ•æ„Ÿå‹ä»»åŠ¡ä¸­å¯¼è‡´æ‹’ç»æœåŠ¡(Denial-of-Service, DoS)ã€‚é€šè¿‡å¯¹ç°æœ‰æ”»å‡»ç­–ç•¥çš„å…¨é¢è°ƒç ”ï¼Œä½œè€…æ­ç¤ºäº†å½“å‰é˜²å¾¡æœºåˆ¶åœ¨åº”å¯¹æ–°å…´æ¨¡å‹æ¶æ„æ—¶çš„å±€é™æ€§åŠè¦†ç›–ç©ºç™½ã€‚åœ¨æ­¤åŸºç¡€ä¸Šï¼Œè¯¥å·¥ä½œæ—¨åœ¨æ·±å…¥è¯„ä¼°ç°ä»£DDLSsé­å—æ•ˆç‡æ”»å‡»çš„å¯è¡Œæ€§ï¼Œå¹¶è‡´åŠ›äºå¼€å‘é’ˆå¯¹æ€§çš„é˜²å¾¡æ‰‹æ®µï¼Œä»¥æå‡ç³»ç»Ÿåœ¨å¯¹æŠ—ç¯å¢ƒä¸‹çš„ç¨³å¥æ€§ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.LG",
      "comment": "Proceedings of the 2025 Poster Session of the 10th IEEE European Symposium on Security and Privacy (EuroS&P 2025)",
      "pdf_url": "https://arxiv.org/pdf/2506.17621v1",
      "published_date": "2025-06-21 07:13:14 UTC",
      "updated_date": "2025-06-21 07:13:14 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T23:25:54.807570+00:00"
    },
    {
      "arxiv_id": "2506.17601v1",
      "title": "Risk-Guided Diffusion: Toward Deploying Robot Foundation Models in Space, Where Failure Is Not An Option",
      "title_zh": "é£é™©å¼•å¯¼æ‰©æ•£ï¼šé¢å‘ä¸å®¹æœ‰å¤±çš„å¤ªç©ºç¯å¢ƒéƒ¨ç½²æœºå™¨äººåŸºç¡€æ¨¡å‹",
      "authors": [
        "Rohan Thakker",
        "Adarsh Patnaik",
        "Vince Kurtz",
        "Jonas Frey",
        "Jonathan Becktor",
        "Sangwoo Moon",
        "Rob Royce",
        "Marcel Kaufmann",
        "Georgios Georgakis",
        "Pascal Roth",
        "Joel Burdick",
        "Marco Hutter",
        "Shehryar Khattak"
      ],
      "abstract": "Safe, reliable navigation in extreme, unfamiliar terrain is required for future robotic space exploration missions. Recent generative-AI methods learn semantically aware navigation policies from large, cross-embodiment datasets, but offer limited safety guarantees. Inspired by human cognitive science, we propose a risk-guided diffusion framework that fuses a fast, learned \"System-1\" with a slow, physics-based \"System-2\", sharing computation at both training and inference to couple adaptability with formal safety. Hardware experiments conducted at the NASA JPL's Mars-analog facility, Mars Yard, show that our approach reduces failure rates by up to $4\\times$ while matching the goal-reaching performance of learning-based robotic models by leveraging inference-time compute without any additional training.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹æœªæ¥å¤ªç©ºæ¢ç´¢ä»»åŠ¡ä¸­æç«¯ä¸”é™Œç”Ÿåœ°å½¢çš„å®‰å…¨å¯é å¯¼èˆªéœ€æ±‚ï¼Œæå‡ºäº† Risk-Guided Diffusion æ¡†æ¶ï¼Œæ—¨åœ¨æå‡æœºå™¨äººåŸºç¡€æ¨¡å‹ (Robot Foundation Models) çš„éƒ¨ç½²å®‰å…¨æ€§ã€‚è¯¥æ¡†æ¶å—äººç±»è®¤çŸ¥ç§‘å­¦å¯å‘ï¼Œå°†å¿«é€Ÿçš„å­¦ä¹ å‹ System-1 ä¸æ…¢é€Ÿçš„åŸºäºç‰©ç†çš„ System-2 ç›¸ç»“åˆï¼Œé€šè¿‡åœ¨è®­ç»ƒå’Œæ¨ç†é˜¶æ®µå…±äº«è®¡ç®—ï¼Œå®ç°äº†ç¯å¢ƒé€‚åº”æ€§ä¸æ­£å¼å®‰å…¨æ€§ (Formal Safety) çš„æœ‰æ•ˆè€¦åˆã€‚è¯¥æ–¹æ³•é€šè¿‡å……åˆ†åˆ©ç”¨æ¨ç†ä¾§è®¡ç®— (Inference-time Compute)ï¼Œæ— éœ€ä»»ä½•é¢å¤–è®­ç»ƒå³å¯å¢å¼ºç­–ç•¥çš„ç¨³å¥æ€§ã€‚åœ¨ NASA JPL çš„ Mars Yard ç«æ˜Ÿæ¨¡æ‹Ÿåœºè¿›è¡Œçš„ç¡¬ä»¶å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨ä¿æŒä¸å­¦ä¹ å‹æ¨¡å‹ç›¸å½“çš„ç›®æ ‡è¾¾æˆæ€§èƒ½çš„åŒæ—¶ï¼Œå°†å¤±è´¥ç‡é™ä½äº†å¤šè¾¾4å€ã€‚è¯¥æˆæœä¸ºåœ¨æ•…éšœå®¹å¿åº¦æä½çš„å¤ªç©ºç¯å¢ƒä¸­åº”ç”¨å…ˆè¿›ç”Ÿæˆå¼äººå·¥æ™ºèƒ½æŠ€æœ¯æä¾›äº†é‡è¦çš„æŠ€æœ¯æ”¯æ’‘ã€‚",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2506.17601v1",
      "published_date": "2025-06-21 05:39:04 UTC",
      "updated_date": "2025-06-21 05:39:04 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T23:26:03.030494+00:00"
    },
    {
      "arxiv_id": "2506.18928v1",
      "title": "Do LLMs Know When to Flip a Coin? Strategic Randomization through Reasoning and Experience",
      "title_zh": "LLM çŸ¥é“ä½•æ—¶è¯¥æ·ç¡¬å¸å—ï¼ŸåŸºäºæ¨ç†ä¸ç»éªŒçš„ç­–ç•¥æ€§éšæœºåŒ–",
      "authors": [
        "Lingyu Yang"
      ],
      "abstract": "Strategic randomization is a key principle in game theory, yet it remains underexplored in large language models (LLMs). Prior work often conflates the cognitive decision to randomize with the mechanical generation of randomness, leading to incomplete evaluations. To address this, we propose a novel zero-sum game inspired by the Tian Ji Horse Race, where the Nash equilibrium corresponds to a maximal entropy strategy. The game's complexity masks this property from untrained humans and underdeveloped LLMs. We evaluate five LLMs across prompt styles -- framed, neutral, and hinted -- using competitive multi-tournament gameplay with system-provided random choices, isolating the decision to randomize. Results show that weaker models remain deterministic regardless of prompts, while stronger models exhibit increased randomization under explicit hints. When facing weaker models, strong LLMs adopt deterministic strategies to exploit biases, but converge toward equilibrium play when facing peers. Through win/loss outcomes and Bayes factor analysis, we demonstrate meaningful variation in LLMs' strategic reasoning capabilities, highlighting opportunities for improvement in abstract reasoning and adaptive learning. We make our implementation publicly available at https://github.com/ocelopus/llm-when-to-throw-coin to ensure full reproducibility.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å¤§è¯­è¨€æ¨¡å‹(LLMs)åœ¨åšå¼ˆè®ºä¸­å…³é”®çš„æˆ˜ç•¥æ€§éšæœºåŒ–(Strategic Randomization)èƒ½åŠ›ï¼Œå¹¶æå‡ºäº†ä¸€ä¸ªå—â€œç”°å¿Œèµ›é©¬â€å¯å‘çš„æ–°å‹é›¶å’Œåšå¼ˆæ¨¡å‹ï¼Œæ—¨åœ¨æœ‰æ•ˆåŒºåˆ†è®¤çŸ¥çš„éšæœºåŒ–å†³ç­–ä¸æœºæ¢°çš„éšæœºæ•°ç”Ÿæˆã€‚ä½œè€…é€šè¿‡æ¡†æ¶å¼ã€ä¸­æ€§å’Œæš—ç¤ºæ€§ç­‰ä¸åŒæç¤ºé£æ ¼ï¼Œåœ¨å¤šè½®ç«æŠ€ä¸­è¯„ä¼°äº†äº”ç§ä¸»æµæ¨¡å‹ï¼Œå¹¶é€šè¿‡ç³»ç»Ÿæä¾›çš„éšæœºé€‰é¡¹æ¥ç‹¬ç«‹è€ƒå¯Ÿå…¶éšæœºåŒ–å†³ç­–é€»è¾‘ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¾ƒå¼±çš„æ¨¡å‹åœ¨å„ç±»æç¤ºä¸‹å‡ä¿æŒç¡®å®šæ€§(Deterministic)ç‰¹å¾ï¼Œè€Œè¾ƒå¼ºçš„æ¨¡å‹åœ¨è·å¾—æ˜¾å¼æš—ç¤ºåè¡¨ç°å‡ºæ›´å¼ºçš„éšæœºåŒ–å€¾å‘ã€‚æœ‰è¶£çš„æ˜¯ï¼Œå¼ºæ¨¡å‹åœ¨é¢å¯¹å¼±å¯¹æ‰‹æ—¶ä¼šé‡‡ç”¨ç¡®å®šæ€§ç­–ç•¥ä»¥åˆ©ç”¨å…¶åè§ï¼Œè€Œåœ¨é¢å¯¹å¯¹ç­‰æ¨¡å‹æ—¶åˆ™ä¼šè¶‹å‘äºçº³ä»€å‡è¡¡(Nash equilibrium)åšå¼ˆã€‚é€šè¿‡èƒœè´Ÿåˆ†æå’Œè´å¶æ–¯å› å­åˆ†æ(Bayes factor analysis)ï¼Œç ”ç©¶æ­ç¤ºäº†LLMsåœ¨æˆ˜ç•¥æ¨ç†èƒ½åŠ›ä¸Šçš„æ˜¾è‘—å·®å¼‚ã€‚è¿™é¡¹å·¥ä½œä¸ºæå‡å¤§è¯­è¨€æ¨¡å‹çš„æŠ½è±¡æ¨ç†å’Œè‡ªé€‚åº”å­¦ä¹ (Adaptive Learning)èƒ½åŠ›æä¾›äº†é‡è¦æ´å¯Ÿï¼Œå¹¶å¼€æºäº†å…¨éƒ¨ä»£ç ä»¥ç¡®ä¿ç ”ç©¶çš„å¯å¤ç°æ€§ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2506.18928v1",
      "published_date": "2025-06-21 05:26:33 UTC",
      "updated_date": "2025-06-21 05:26:33 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T23:26:08.824851+00:00"
    },
    {
      "arxiv_id": "2506.17590v2",
      "title": "DRAMA-X: A Fine-grained Intent Prediction and Risk Reasoning Benchmark For Driving",
      "title_zh": "DRAMA-Xï¼šé¢å‘é©¾é©¶çš„ç»†ç²’åº¦æ„å›¾é¢„æµ‹ä¸é£é™©æ¨ç†åŸºå‡†",
      "authors": [
        "Mihir Godbole",
        "Xiangbo Gao",
        "Zhengzhong Tu"
      ],
      "abstract": "Understanding the short-term motion of vulnerable road users (VRUs) like pedestrians and cyclists is critical for safe autonomous driving, especially in urban scenarios with ambiguous or high-risk behaviors. While vision-language models (VLMs) have enabled open-vocabulary perception, their utility for fine-grained intent reasoning remains underexplored. Notably, no existing benchmark evaluates multi-class intent prediction in safety-critical situations, To address this gap, we introduce DRAMA-X, a fine-grained benchmark constructed from the DRAMA dataset via an automated annotation pipeline. DRAMA-X contains 5,686 accident-prone frames labeled with object bounding boxes, a nine-class directional intent taxonomy, binary risk scores, expert-generated action suggestions for the ego vehicle, and descriptive motion summaries. These annotations enable a structured evaluation of four interrelated tasks central to autonomous decision-making: object detection, intent prediction, risk assessment, and action suggestion. As a reference baseline, we propose SGG-Intent, a lightweight, training-free framework that mirrors the ego vehicle's reasoning pipeline. It sequentially generates a scene graph from visual input using VLM-backed detectors, infers intent, assesses risk, and recommends an action using a compositional reasoning stage powered by a large language model. We evaluate a range of recent VLMs, comparing performance across all four DRAMA-X tasks. Our experiments demonstrate that scene-graph-based reasoning enhances intent prediction and risk assessment, especially when contextual cues are explicitly modeled.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† DRAMA-Xï¼Œè¿™æ˜¯ä¸€ä¸ªé’ˆå¯¹è‡ªåŠ¨é©¾é©¶ä¸­å¼±åŠ¿é“è·¯ä½¿ç”¨è€…(VRUs)æ„å›¾é¢„æµ‹å’Œé£é™©æ¨ç†çš„é«˜ç²’åº¦åŸºå‡†æµ‹è¯•ã€‚è¯¥åŸºå‡†åŒ…å« 5,686 ä¸ªäº‹æ•…æ˜“å‘å¸§ï¼Œæ¶µç›–äº†ä¹ç±»æ–¹å‘æ„å›¾åˆ†ç±»ã€äºŒå…ƒé£é™©è¯„åˆ†ã€ä¸“å®¶ç”Ÿæˆçš„å»ºè®®æ“ä½œä»¥åŠæè¿°æ€§è¿åŠ¨æ‘˜è¦ã€‚DRAMA-X æ—¨åœ¨é€šè¿‡ç‰©ä½“æ£€æµ‹ã€æ„å›¾é¢„æµ‹ã€é£é™©è¯„ä¼°å’Œæ“ä½œå»ºè®®å››ä¸ªå…³è”ä»»åŠ¡ï¼Œå¡«è¡¥å®‰å…¨å…³é”®åœºæ™¯ä¸­å¤šç±»æ„å›¾é¢„æµ‹è¯„ä¼°çš„ç©ºç™½ã€‚ä¸ºäº†å»ºç«‹å‚è€ƒåŸºçº¿ï¼Œä½œè€…å¼€å‘äº† SGG-Intentï¼Œè¿™æ˜¯ä¸€ç§åŸºäºåœºæ™¯å›¾(Scene Graph)æ¨ç†ä¸”æ— éœ€è®­ç»ƒçš„è½»é‡çº§æ¡†æ¶ï¼Œé€šè¿‡è§†è§‰è¯­è¨€æ¨¡å‹(VLMs)ç”Ÿæˆåœºæ™¯å›¾å¹¶ç»“åˆå¤§è¯­è¨€æ¨¡å‹è¿›è¡Œç»„åˆæ¨ç†ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œæ˜¾å¼å»ºæ¨¡ç¯å¢ƒä¸Šä¸‹æ–‡çš„åœºæ™¯å›¾æ¨ç†èƒ½æ˜¾è‘—æå‡æ„å›¾é¢„æµ‹å’Œé£é™©è¯„ä¼°çš„å‡†ç¡®æ€§ã€‚è¯¥å·¥ä½œä¸ºè§†è§‰è¯­è¨€æ¨¡å‹åœ¨å¤æ‚åŸå¸‚äº¤é€šåœºæ™¯ä¸‹çš„ç²¾ç»†åŒ–æ„å›¾ç†è§£å’Œè‡ªåŠ¨é©¾é©¶å†³ç­–æä¾›äº†é‡è¦çš„è¯„ä¼°å·¥å…·å’Œç ”ç©¶åŸºç¡€ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "19 pages, 5 figures, Preprint under review. Code available at: https://github.com/taco-group/DRAMA-X",
      "pdf_url": "https://arxiv.org/pdf/2506.17590v2",
      "published_date": "2025-06-21 05:01:42 UTC",
      "updated_date": "2025-08-09 06:21:14 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T23:26:17.391646+00:00"
    },
    {
      "arxiv_id": "2506.17589v3",
      "title": "Taming the Untamed: Graph-Based Knowledge Retrieval and Reasoning for MLLMs to Conquer the Unknown",
      "title_zh": "é©¯æœæœªçŸ¥ï¼šåŸºäºå›¾çš„çŸ¥è¯†æ£€ç´¢ä¸æ¨ç†åŠ©åŠ›å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹å¾æœæœªçŸ¥é¢†åŸŸ",
      "authors": [
        "Bowen Wang",
        "Zhouqiang Jiang",
        "Yasuaki Susumu",
        "Shotaro Miwa",
        "Tianwei Chen",
        "Yuta Nakashima"
      ],
      "abstract": "The real value of knowledge lies not just in its accumulation, but in its potential to be harnessed effectively to conquer the unknown. Although recent multimodal large language models (MLLMs) exhibit impressing multimodal capabilities, they often fail in rarely encountered domain-specific tasks due to limited relevant knowledge. To explore this, we adopt visual game cognition as a testbed and select Monster Hunter: World as the target to construct a multimodal knowledge graph (MH-MMKG), which incorporates multi-modalities and intricate entity relations. We also design a series of challenging queries based on MH-MMKG to evaluate the models' ability for complex knowledge retrieval and reasoning. Furthermore, we propose a multi-agent retriever that enables a model to autonomously search relevant knowledge without additional training. Experimental results show that our approach significantly enhances the performance of MLLMs, providing a new perspective on multimodal knowledge-augmented reasoning and laying a solid foundation for future research.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ï¼ˆMLLMsï¼‰åœ¨å¤„ç†é¢†åŸŸç‰¹å®šä»»åŠ¡æ—¶å› ç›¸å…³çŸ¥è¯†åŒ®ä¹è€Œæ€§èƒ½å—é™çš„é—®é¢˜ï¼Œæå‡ºäº†åŸºäºå›¾çš„çŸ¥è¯†æ£€ç´¢ä¸æ¨ç†æ¡†æ¶ã€‚ç ”ç©¶å›¢é˜Ÿä»¥ã€Šæ€ªç‰©çŒäººï¼šä¸–ç•Œã€‹ä¸ºå®éªŒåŸºå‡†ï¼Œæ„å»ºäº†åŒ…å«å¤æ‚å®ä½“å…³ç³»çš„å¤šæ¨¡æ€çŸ¥è¯†å›¾è°± MH-MMKGï¼Œå¹¶æ®æ­¤è®¾è®¡äº†ä¸€ç³»åˆ—æŒ‘æˆ˜æ€§æŸ¥è¯¢ä»¥è¯„ä¼°æ¨¡å‹çš„å¤æ‚çŸ¥è¯†æ£€ç´¢ä¸æ¨ç†èƒ½åŠ›ã€‚æ­¤å¤–ï¼Œè¯¥æ–‡æå‡ºäº†ä¸€ç§å¤šæ™ºèƒ½ä½“æ£€ç´¢å™¨ï¼ˆMulti-agent Retrieverï¼‰ï¼Œä½¿æ¨¡å‹èƒ½å¤Ÿåœ¨æ— éœ€é¢å¤–è®­ç»ƒçš„æƒ…å†µä¸‹è‡ªä¸»æœç´¢ç›¸å…³çŸ¥è¯†ã€‚å®éªŒç»“æœè¯æ˜ï¼Œè¯¥æ–¹æ³•æ˜¾è‘—å¢å¼ºäº† MLLMs çš„è¡¨ç°ï¼Œä¸ºå¤šæ¨¡æ€çŸ¥è¯†å¢å¼ºæ¨ç†æä¾›äº†æ–°è§†è§’å¹¶å¥ å®šäº†ç ”ç©¶åŸºç¡€ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Aligned with ICCV 2025 camera-ready version",
      "pdf_url": "https://arxiv.org/pdf/2506.17589v3",
      "published_date": "2025-06-21 05:01:02 UTC",
      "updated_date": "2025-08-25 08:46:29 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T23:27:47.305789+00:00"
    },
    {
      "arxiv_id": "2506.17587v1",
      "title": "HalluRNN: Mitigating Hallucinations via Recurrent Cross-Layer Reasoning in Large Vision-Language Models",
      "title_zh": "HalluRNNï¼šé€šè¿‡å¾ªç¯è·¨å±‚æ¨ç†ç¼“è§£å¤§è§†è§‰è¯­è¨€æ¨¡å‹ä¸­çš„å¹»è§‰",
      "authors": [
        "Le Yu",
        "Kaishen Wang",
        "Jianlong Xiong",
        "Yue Cao",
        "Tao He"
      ],
      "abstract": "Though Large Vision-Language Models (LVLMs) have achieved remarkable performance across various tasks, they are still prone to hallucinations-generating outputs that are textually plausible but visually ungrounded. While prior approaches generally address this issue through data-centric fine-tuning or innovative decoding strategies, these methods often require substantial resources or task-specific configurations. In this work, we introduce an architecture-level solution, HalluRNN, which enhances model stability through recurrent cross-layer reasoning. Specifically, we propose a novel Dual-Gated Depth Propagation Unit (DG-DPU) module, which is shared across layers and recurrently refines hidden states. This allows for the adaptive propagation of information throughout the model, enforces consistency across layers, and mitigates hallucinations caused by representational drift. By fine-tuning only the DG-DPU module, HalluRNN achieves strong and robust performance across multiple benchmarks.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§å‹è§†è§‰è¯­è¨€æ¨¡å‹(LVLMs)ä¸­æ™®éå­˜åœ¨çš„å¹»è§‰é—®é¢˜ï¼Œæå‡ºäº† HalluRNN è¿™ä¸€æ¶æ„çº§è§£å†³æ–¹æ¡ˆã€‚HalluRNN é€šè¿‡å¼•å…¥å¾ªç¯è·¨å±‚æ¨ç†(recurrent cross-layer reasoning)æœºåˆ¶ï¼Œåˆ©ç”¨åœ¨å„å±‚é—´å…±äº«çš„åŒé—¨æ§æ·±åº¦ä¼ æ’­å•å…ƒ(DG-DPU)æ¥å¾ªç¯ç²¾ç‚¼éšè—çŠ¶æ€ã€‚è¿™ç§è®¾è®¡ä¸ä»…å®ç°äº†ä¿¡æ¯çš„è‡ªé€‚åº”ä¼ æ’­å¹¶åŠ å¼ºäº†æ¨¡å‹å±‚é—´çš„ä¸€è‡´æ€§ï¼Œè¿˜æ˜¾è‘—ç¼“è§£äº†å› è¡¨ç¤ºæ¼‚ç§»(representational drift)å¯¼è‡´çš„è¾“å‡ºä¸è§†è§‰ä¿¡æ¯ä¸ç¬¦çš„é—®é¢˜ã€‚å®éªŒè¯æ˜ï¼Œä»…éœ€å¾®è°ƒ DG-DPU æ¨¡å—ï¼ŒHalluRNN å³å¯åœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­å–å¾—å¼ºåŠ²ä¸”ç¨³å¥çš„æ€§èƒ½ã€‚ç›¸æ¯”äºä¼ ç»Ÿçš„æ•°æ®å¯†é›†å‹å¾®è°ƒæˆ–å¤æ‚çš„è§£ç ç­–ç•¥ï¼Œè¯¥æ–¹æ³•åœ¨æä¾›æ¶æ„ç¨³å®šæ€§çš„åŒæ—¶ï¼Œæ˜¾è‘—æå‡äº†æ¨¡å‹åœ¨è§†è§‰ä»»åŠ¡ä¸­çš„å¯é æ€§ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "6 figures, 9 tables",
      "pdf_url": "https://arxiv.org/pdf/2506.17587v1",
      "published_date": "2025-06-21 04:56:55 UTC",
      "updated_date": "2025-06-21 04:56:55 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T23:27:24.547776+00:00"
    },
    {
      "arxiv_id": "2506.17585v2",
      "title": "Cite Pretrain: Retrieval-Free Knowledge Attribution for Large Language Models",
      "title_zh": "Cite Pretrainï¼šå¤§è¯­è¨€æ¨¡å‹æ— éœ€æ£€ç´¢çš„çŸ¥è¯†å½’å› ",
      "authors": [
        "Yukun Huang",
        "Sanxing Chen",
        "Jian Pei",
        "Manzil Zaheer",
        "Bhuwan Dhingra"
      ],
      "abstract": "Trustworthy language models should provide both correct and verifiable answers. However, citations generated directly by standalone LLMs are often unreliable. As a result, current systems insert citations by querying an external retriever at inference time, introducing latency, infrastructure dependence, and vulnerability to retrieval noise. We explore whether LLMs can be made to reliably attribute to the documents seen during continual pretraining without test-time retrieval, by revising the training process. To study this, we construct CitePretrainBench, a benchmark that mixes real-world corpora (Wikipedia, Common Crawl, arXiv) with novel documents and probes both short-form (single-fact) and long-form (multi-fact) citation tasks. Our approach follows a two-stage process: (1) continual pretraining to index factual knowledge by binding it to persistent document identifiers; and (2) instruction tuning to elicit citation behavior. We introduce Active Indexing for the first stage, which creates generalizable, source-anchored bindings by augmenting training with synthetic data that (i) restate each fact in diverse, compositional forms and (ii) enforce bidirectional training (source-to-fact and fact-to-source). This equips the model to both generate content from a cited source and attribute its own answers, improving robustness to paraphrase and composition. Experiments with Qwen-2.5-7B&3B show that Active Indexing consistently outperforms a Passive Indexing baseline, which simply appends an identifier to each document, achieving citation precision gains of up to 30.2% across all tasks and models. Our ablation studies reveal that performance continues to improve as we scale the amount of augmented data, showing a clear upward trend even at 16x the original token count. Finally, we show that internal citations complement external ones by making the model more robust to retrieval noise.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å¦‚ä½•è®©å¤§è¯­è¨€æ¨¡å‹(LLMs)åœ¨ä¸éœ€è¦å¤–éƒ¨æ£€ç´¢å™¨çš„æƒ…å†µä¸‹ï¼Œé€šè¿‡æ”¹è¿›è®­ç»ƒè¿‡ç¨‹æ¥å¯é åœ°å½’å±å…¶é¢„è®­ç»ƒæœŸé—´è§è¿‡çš„æ–‡æ¡£çŸ¥è¯†ã€‚ä¸ºæ­¤ï¼Œä½œè€…æ„å»ºäº†CitePretrainBenchåŸºå‡†æµ‹è¯•ï¼Œå¹¶æå‡ºäº†ä¸€ç§åŒ…å«æŒç»­é¢„è®­ç»ƒå’ŒæŒ‡ä»¤å¾®è°ƒ(instruction tuning)çš„ä¸¤é˜¶æ®µå¤„ç†æµç¨‹ã€‚è¯¥æµç¨‹çš„æ ¸å¿ƒæ˜¯Active IndexingæŠ€æœ¯ï¼Œé€šè¿‡ç”Ÿæˆåˆæˆæ•°æ®ä»¥å¤šç§å½¢å¼é‡è¿°äº‹å®ï¼Œå¹¶å®æ–½æºåˆ°äº‹å®ä¸äº‹å®åˆ°æºçš„åŒå‘è®­ç»ƒï¼Œä½¿æ¨¡å‹èƒ½å¤Ÿå»ºç«‹ç¨³å¥çš„æºé”šå®šç»‘å®š(source-anchored bindings)ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œåœ¨Qwen-2.5-7Bå’Œ3Bæ¨¡å‹ä¸Šï¼ŒActive Indexingç›¸æ¯”äºç®€å•çš„Passive IndexingåŸºå‡†ï¼Œåœ¨å„é¡¹ä»»åŠ¡ä¸­çš„å¼•ç”¨ç²¾å‡†åº¦(citation precision)æå‡é«˜è¾¾30.2%ã€‚æ¶ˆèç ”ç©¶è¿›ä¸€æ­¥è¯å®ï¼Œéšç€å¢å¼ºæ•°æ®è§„æ¨¡çš„æ‰©å¤§ï¼Œæ€§èƒ½å‘ˆç°æŒç»­ä¸Šå‡è¶‹åŠ¿ï¼Œä¸”å†…éƒ¨å¼•ç”¨èƒ½æœ‰æ•ˆå¢å¼ºæ¨¡å‹å¯¹å¤–éƒ¨æ£€ç´¢å™ªå£°(retrieval noise)çš„é²æ£’æ€§ã€‚",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2506.17585v2",
      "published_date": "2025-06-21 04:48:05 UTC",
      "updated_date": "2025-10-28 18:06:24 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T23:27:27.638579+00:00"
    },
    {
      "arxiv_id": "2506.17580v1",
      "title": "Context-Aware Scientific Knowledge Extraction on Linked Open Data using Large Language Models",
      "title_zh": "åŸºäºå¤§è¯­è¨€æ¨¡å‹çš„å…³è”å¼€æ”¾æ•°æ®ä¸Šä¸‹æ–‡æ„ŸçŸ¥ç§‘å­¦çŸ¥è¯†æŠ½å–",
      "authors": [
        "Sajratul Y. Rubaiat",
        "Hasan M. Jamil"
      ],
      "abstract": "The exponential growth of scientific literature challenges researchers extracting and synthesizing knowledge. Traditional search engines return many sources without direct, detailed answers, while general-purpose LLMs may offer concise responses that lack depth or omit current information. LLMs with search capabilities are also limited by context window, yielding short, incomplete answers. This paper introduces WISE (Workflow for Intelligent Scientific Knowledge Extraction), a system addressing these limits by using a structured workflow to extract, refine, and rank query-specific knowledge. WISE uses an LLM-powered, tree-based architecture to refine data, focusing on query-aligned, context-aware, and non-redundant information. Dynamic scoring and ranking prioritize unique contributions from each source, and adaptive stopping criteria minimize processing overhead. WISE delivers detailed, organized answers by systematically exploring and synthesizing knowledge from diverse sources. Experiments on HBB gene-associated diseases demonstrate WISE reduces processed text by over 80% while achieving significantly higher recall over baselines like search engines and other LLM-based approaches. ROUGE and BLEU metrics reveal WISE's output is more unique than other systems, and a novel level-based metric shows it provides more in-depth information. We also explore how the WISE workflow can be adapted for diverse domains like drug discovery, material science, and social science, enabling efficient knowledge extraction and synthesis from unstructured scientific papers and web sources.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†WISE (Workflow for Intelligent Scientific Knowledge Extraction)ï¼Œæ—¨åœ¨è§£å†³ç§‘å­¦æ–‡çŒ®æµ·é‡å¢é•¿å¸¦æ¥çš„çŸ¥è¯†æå–ä¸åˆæˆæŒ‘æˆ˜ã€‚é’ˆå¯¹ä¼ ç»Ÿæœç´¢å¼•æ“ç»“æœé›¶æ•£ä»¥åŠé€šç”¨Large Language Models (LLMs) å—é™äºä¸Šä¸‹æ–‡çª—å£ä¸”æ·±åº¦ä¸è¶³çš„é—®é¢˜ï¼ŒWISEé‡‡ç”¨äº†åŸºäºæ ‘çŠ¶ç»“æ„çš„ç»“æ„åŒ–å·¥ä½œæµæ¥æå–ã€ç²¾ç‚¼å’Œæ’åºç‰¹å®šæŸ¥è¯¢çš„çŸ¥è¯†ã€‚è¯¥æ¡†æ¶é€šè¿‡åŠ¨æ€è¯„åˆ† (dynamic scoring) å’Œè‡ªé€‚åº”åœæ­¢æ ‡å‡†ï¼Œå®ç°äº†ä¸Šä¸‹æ–‡æ„ŸçŸ¥ä¸”æ— å†—ä½™çš„é«˜æ•ˆä¿¡æ¯å¤„ç†ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œåœ¨HBBåŸºå› ç›¸å…³ç–¾ç—…çš„ä»»åŠ¡ä¸­ï¼ŒWISEåœ¨å‡å°‘80%ä»¥ä¸Šæ–‡æœ¬å¤„ç†é‡çš„åŒæ—¶ï¼Œå…¶å¬å›ç‡ (recall) æ˜¾è‘—ä¼˜äºä¼ ç»ŸåŸºçº¿æ¨¡å‹ã€‚ROUGEå’ŒBLEUç­‰æŒ‡æ ‡åŠæ·±åº¦è¯„ä¼°è¯æ˜äº†å…¶è¾“å‡ºå†…å®¹çš„ç‹¬ç‰¹æ€§ä¸ä¸“ä¸šæ·±åº¦ã€‚è¯¥å·¥ä½œæµè¿˜å¯çµæ´»æ‰©å±•è‡³è¯ç‰©å‘ç° (drug discovery) å’Œææ–™ç§‘å­¦ç­‰å¤šä¸ªé¢†åŸŸï¼Œæ˜¾è‘—æå‡äº†ä»éç»“æ„åŒ–èµ„æºä¸­æå–å¹¶åˆæˆç§‘å­¦çŸ¥è¯†çš„æ•ˆç‡ã€‚",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.DL",
        "cs.ET"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2506.17580v1",
      "published_date": "2025-06-21 04:22:34 UTC",
      "updated_date": "2025-06-21 04:22:34 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T23:27:46.570923+00:00"
    },
    {
      "arxiv_id": "2506.17577v1",
      "title": "Optimizing Mastery Learning by Fast-Forwarding Over-Practice Steps",
      "title_zh": "é€šè¿‡å¿«è¿›è¿‡åº¦ç»ƒä¹ æ­¥éª¤ä¼˜åŒ–æŒæ¡å­¦ä¹ ",
      "authors": [
        "Meng Xia",
        "Robin Schmucker",
        "Conrad Borchers",
        "Vincent Aleven"
      ],
      "abstract": "Mastery learning improves learning proficiency and efficiency. However, the overpractice of skills--students spending time on skills they have already mastered--remains a fundamental challenge for tutoring systems. Previous research has reduced overpractice through the development of better problem selection algorithms and the authoring of focused practice tasks. However, few efforts have concentrated on reducing overpractice through step-level adaptivity, which can avoid resource-intensive curriculum redesign. We propose and evaluate Fast-Forwarding as a technique that enhances existing problem selection algorithms. Based on simulation studies informed by learner models and problem-solving pathways derived from real student data, Fast-Forwarding can reduce overpractice by up to one-third, as it does not require students to complete problem-solving steps if all remaining pathways are fully mastered. Fast-Forwarding is a flexible method that enhances any problem selection algorithm, though its effectiveness is highest for algorithms that preferentially select difficult problems. Therefore, our findings suggest that while Fast-Forwarding may improve student practice efficiency, the size of its practical impact may also depend on students' ability to stay motivated and engaged at higher levels of difficulty.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹æŒæ¡å­¦ä¹  (Mastery learning) ä¸­å­¦ç”Ÿåœ¨å·²æŒæ¡æŠ€èƒ½ä¸Šè¿‡åº¦ç»ƒä¹  (overpractice) çš„æ™®éæŒ‘æˆ˜ï¼Œæå‡ºäº†ä¸€ç§åä¸º Fast-Forwarding çš„æ­¥éª¤çº§è‡ªé€‚åº” (step-level adaptivity) æŠ€æœ¯ã€‚è¯¥æ–¹æ³•é€šè¿‡å¢å¼ºç°æœ‰çš„é¢˜ç›®é€‰æ‹©ç®—æ³•ï¼Œå…è®¸å­¦ç”Ÿåœ¨è¯æ˜å·²æŒæ¡æŸé—®é¢˜çš„æ‰€æœ‰è§£é¢˜è·¯å¾„åè·³è¿‡ç›¸åº”æ­¥éª¤ï¼Œä»è€Œåœ¨ä¸æ”¹å˜è¯¾ç¨‹è®¾è®¡çš„æƒ…å†µä¸‹æé«˜å­¦ä¹ æ•ˆç‡ã€‚åŸºäºçœŸå®å­¦ç”Ÿæ•°æ®å’Œè§£é¢˜è·¯å¾„çš„ä»¿çœŸå®éªŒè¯æ˜ï¼ŒFast-Forwarding æœ€é«˜å¯å‡å°‘ä¸‰åˆ†ä¹‹ä¸€çš„è¿‡åº¦ç»ƒä¹ é‡ã€‚ç ”ç©¶å‘ç°ï¼Œè¯¥æŠ€æœ¯åœ¨ä¸å€¾å‘äºé€‰æ‹©é«˜éš¾åº¦é¢˜ç›®ç®—æ³•ç»“åˆæ—¶æ•ˆæœæœ€ä¸ºæ˜¾è‘—ã€‚å› æ­¤ï¼Œè™½ç„¶ Fast-Forwarding èƒ½æ˜¾è‘—ä¼˜åŒ–ç»ƒä¹ æµç¨‹ï¼Œä½†å…¶æœ€ç»ˆçš„å®é™…å½±å“ä»å–å†³äºå­¦ç”Ÿåœ¨é¢å¯¹æ›´é«˜éš¾åº¦ä»»åŠ¡æ—¶ç»´æŒå­¦ä¹ åŠ¨æœºå’Œå‚ä¸åº¦çš„èƒ½åŠ›ã€‚",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CY",
      "comment": "Full research paper accepted at EC-TEL 2025",
      "pdf_url": "https://arxiv.org/pdf/2506.17577v1",
      "published_date": "2025-06-21 04:14:26 UTC",
      "updated_date": "2025-06-21 04:14:26 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T23:27:47.440701+00:00"
    },
    {
      "arxiv_id": "2506.17564v1",
      "title": "Accelerating Residual Reinforcement Learning with Uncertainty Estimation",
      "title_zh": "åŸºäºä¸ç¡®å®šæ€§ä¼°è®¡çš„æ®‹å·®å¼ºåŒ–å­¦ä¹ åŠ é€Ÿ",
      "authors": [
        "Lakshita Dodeja",
        "Karl Schmeckpeper",
        "Shivam Vats",
        "Thomas Weng",
        "Mingxi Jia",
        "George Konidaris",
        "Stefanie Tellex"
      ],
      "abstract": "Residual Reinforcement Learning (RL) is a popular approach for adapting pretrained policies by learning a lightweight residual policy that provides corrective actions. While Residual RL is more sample-efficient than finetuning the entire base policy, existing methods struggle with sparse rewards and are designed for deterministic base policies. We propose two improvements to Residual RL that further enhance its sample efficiency and make it suitable for stochastic base policies. First, we leverage uncertainty estimates of the base policy to focus exploration on regions in which the base policy is not confident. Second, we propose a simple modification to off-policy residual learning that allows it to observe base actions and better handle stochastic base policies. We evaluate our method with both Gaussian-based and Diffusion-based stochastic base policies on tasks from Robosuite and D4RL, and compare against state-of-the-art finetuning methods, demo-augmented RL methods, and other residual RL methods. Our algorithm significantly outperforms existing baselines in a variety of simulation benchmark environments. We also deploy our learned polices in the real world to demonstrate their robustness with zero-shot sim-to-real transfer.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ Residual Reinforcement Learning (RL) åœ¨å¤„ç†ç¨€ç–å¥–åŠ±å’Œéšæœºç­–ç•¥æ—¶çš„å±€é™æ€§ï¼Œæå‡ºäº†ä¸¤ç§æ—¨åœ¨æå‡æ ·æœ¬æ•ˆç‡çš„æ”¹è¿›æ–¹æ³•ã€‚é¦–å…ˆï¼Œç ”ç©¶é€šè¿‡å¼•å…¥åŸºå‡†ç­–ç•¥çš„ Uncertainty Estimation æ¥å¼•å¯¼æ¢ç´¢è¿‡ç¨‹ï¼Œä½¿å­¦ä¹ è¿‡ç¨‹é›†ä¸­åœ¨åŸºå‡†ç­–ç•¥ä¿¡å¿ƒä¸è¶³çš„åŒºåŸŸã€‚å…¶æ¬¡ï¼Œä½œè€…å¯¹ Off-policy residual learning è¿›è¡Œäº†ç®€å•æ”¹è¿›ï¼Œä½¿å…¶èƒ½å¤Ÿè§‚å¯ŸåŸºå‡†åŠ¨ä½œï¼Œä»è€Œæ›´å¥½åœ°é€‚åº” Stochastic base policiesã€‚å®éªŒåœ¨ Robosuite å’Œ D4RL ä»»åŠ¡ä¸­å¯¹ Gaussian å’Œ Diffusion æ¶æ„çš„éšæœºç­–ç•¥è¿›è¡Œäº†è¯„ä¼°ï¼Œç»“æœè¡¨æ˜è¯¥æ–¹æ³•åœ¨å¤šä¸ªä»¿çœŸåŸºå‡†ç¯å¢ƒä¸­æ˜¾è‘—ä¼˜äºç°æœ‰çš„ Finetuning å’Œ Demo-augmented RL ç­‰åŸºå‡†æ¨¡å‹ã€‚æ­¤å¤–ï¼Œç ”ç©¶è¿˜é€šè¿‡çœŸå®ä¸–ç•Œçš„éƒ¨ç½²ï¼Œè¯æ˜äº†è¯¥ç®—æ³•åœ¨ Zero-shot sim-to-real è¿ç§»ä»»åŠ¡ä¸­å…·æœ‰æå¼ºçš„ç¨³å¥æ€§ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2506.17564v1",
      "published_date": "2025-06-21 03:18:01 UTC",
      "updated_date": "2025-06-21 03:18:01 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T23:27:41.788486+00:00"
    },
    {
      "arxiv_id": "2507.01035v1",
      "title": "Research on Low-Latency Inference and Training Efficiency Optimization for Graph Neural Network and Large Language Model-Based Recommendation Systems",
      "title_zh": "åŸºäºå›¾ç¥ç»ç½‘ç»œä¸å¤§è¯­è¨€æ¨¡å‹çš„æ¨èç³»ç»Ÿä½å»¶è¿Ÿæ¨ç†ä¸è®­ç»ƒæ•ˆç‡ä¼˜åŒ–ç ”ç©¶",
      "authors": [
        "Yushang Zhao",
        "Haotian Lyu",
        "Yike Peng",
        "Aijia Sun",
        "Feng Jiang",
        "Xinyue Han"
      ],
      "abstract": "The incessant advent of online services demands high speed and efficient recommender systems (ReS) that can maintain real-time performance along with processing very complex user-item interactions. The present study, therefore, considers computational bottlenecks involved in hybrid Graph Neural Network (GNN) and Large Language Model (LLM)-based ReS with the aim optimizing their inference latency and training efficiency. An extensive methodology was used: hybrid GNN-LLM integrated architecture-optimization strategies(quantization, LoRA, distillation)-hardware acceleration (FPGA, DeepSpeed)-all under R 4.4.2. Experimental improvements were significant, with the optimal Hybrid + FPGA + DeepSpeed configuration reaching 13.6% more accuracy (NDCG@10: 0.75) at 40-60ms of latency, while LoRA brought down training time by 66% (3.8 hours) in comparison to the non-optimized baseline. Irrespective of domain, such as accuracy or efficiency, it can be established that hardware-software co-design and parameter-efficient tuning permit hybrid models to outperform GNN or LLM approaches implemented independently. It recommends the use of FPGA as well as LoRA for real-time deployment. Future work should involve federated learning along with advanced fusion architectures for better scalability and privacy preservation. Thus, this research marks the fundamental groundwork concerning next-generation ReS balancing low-latency response with cutting-edge personalization.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹åŸºäºå›¾ç¥ç»ç½‘ç»œ(GNN)å’Œå¤§è§„æ¨¡è¯­è¨€æ¨¡å‹(LLM)çš„æ··åˆæ¨èç³»ç»Ÿåœ¨å¤„ç†å¤æ‚äº¤äº’æ—¶é¢ä¸´çš„è®¡ç®—ç“¶é¢ˆï¼Œç³»ç»Ÿæ€§åœ°æ¢ç´¢äº†é™ä½æ¨ç†å»¶è¿Ÿä¸æå‡è®­ç»ƒæ•ˆç‡çš„ä¼˜åŒ–ç­–ç•¥ã€‚ç ”ç©¶å›¢é˜Ÿé‡‡ç”¨äº†ä¸€å¥—ç»¼åˆæ–¹æ³•è®ºï¼ŒåŒ…æ‹¬é‡åŒ–(Quantization)ã€LoRAã€çŸ¥è¯†è’¸é¦(Distillation)ç­‰è½¯ä»¶ä¼˜åŒ–æŠ€æœ¯ï¼Œå¹¶ç»“åˆäº†FPGAå’ŒDeepSpeedè¿›è¡Œç¡¬ä»¶åŠ é€Ÿã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œåœ¨â€œæ··åˆæ¨¡å‹+FPGA+DeepSpeedâ€çš„æœ€ä¼˜é…ç½®ä¸‹ï¼Œç³»ç»Ÿèƒ½åœ¨40-60msçš„è¶…ä½å»¶è¿Ÿå†…å®ç°0.75çš„NDCG@10è¯„åˆ†ï¼Œå‡†ç¡®ç‡è¾ƒåŸºçº¿æå‡äº†13.6%ã€‚æ­¤å¤–ï¼ŒLoRAæŠ€æœ¯çš„åº”ç”¨ä½¿æ¨¡å‹è®­ç»ƒæ—¶é—´æ˜¾è‘—ç¼©çŸ­äº†66%ï¼Œæå¤§åœ°æå‡äº†ç³»ç»Ÿçš„è®­ç»ƒæ•ˆç‡ã€‚è¯¥ç ”ç©¶è¯æ˜äº†è½¯ç¡¬ä»¶ååŒè®¾è®¡ä¸å‚æ•°é«˜æ•ˆå¾®è°ƒ(Parameter-efficient tuning)åœ¨æå‡æ··åˆæ¨èç³»ç»Ÿæ€§èƒ½æ–¹é¢çš„æ ¸å¿ƒä½œç”¨ï¼Œå¹¶ä¸ºå®ç°å…¼é¡¾å®æ—¶å“åº”ä¸æ·±åº¦ä¸ªæ€§åŒ–çš„ä¸‹ä¸€ä»£æ¨èç³»ç»Ÿå¥ å®šäº†åšå®çš„æŠ€æœ¯åŸºç¡€ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.PF"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.01035v1",
      "published_date": "2025-06-21 03:10:50 UTC",
      "updated_date": "2025-06-21 03:10:50 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T23:27:44.654436+00:00"
    },
    {
      "arxiv_id": "2506.17561v1",
      "title": "VLA-OS: Structuring and Dissecting Planning Representations and Paradigms in Vision-Language-Action Models",
      "title_zh": "VLA-OSï¼šè§†è§‰-è¯­è¨€-åŠ¨ä½œæ¨¡å‹ä¸­è§„åˆ’è¡¨ç¤ºä¸èŒƒå¼çš„ä½“ç³»åŒ–æ„å»ºä¸æ·±åº¦å‰–æ",
      "authors": [
        "Chongkai Gao",
        "Zixuan Liu",
        "Zhenghao Chi",
        "Junshan Huang",
        "Xin Fei",
        "Yiwen Hou",
        "Yuxuan Zhang",
        "Yudi Lin",
        "Zhirui Fang",
        "Zeyu Jiang",
        "Lin Shao"
      ],
      "abstract": "Recent studies on Vision-Language-Action (VLA) models have shifted from the end-to-end action-generation paradigm toward a pipeline involving task planning followed by action generation, demonstrating improved performance on various complex, long-horizon manipulation tasks. However, existing approaches vary significantly in terms of network architectures, planning paradigms, representations, and training data sources, making it challenging for researchers to identify the precise sources of performance gains and components to be further improved. To systematically investigate the impacts of different planning paradigms and representations isolating from network architectures and training data, in this paper, we introduce VLA-OS, a unified VLA architecture series capable of various task planning paradigms, and design a comprehensive suite of controlled experiments across diverse object categories (rigid and deformable), visual modalities (2D and 3D), environments (simulation and real-world), and end-effectors (grippers and dexterous hands). Our results demonstrate that: 1) visually grounded planning representations are generally better than language planning representations; 2) the Hierarchical-VLA paradigm generally achieves superior or comparable performance than other paradigms on task performance, pretraining, generalization ability, scalability, and continual learning ability, albeit at the cost of slower training and inference speeds.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† VLA-OSï¼Œè¿™æ˜¯ä¸€ä¸ªç»Ÿä¸€çš„ Vision-Language-Action (VLA) æ¶æ„ç³»åˆ—ï¼Œæ—¨åœ¨ç³»ç»Ÿåœ°ç ”ç©¶ä¸åŒè§„åˆ’èŒƒå¼(planning paradigms)å’Œè¡¨ç¤º(representations)å¯¹æ¨¡å‹æ€§èƒ½çš„å½±å“ã€‚ä¸ºäº†è§£å†³ç°æœ‰æ–¹æ³•åœ¨æ¶æ„å’Œæ•°æ®ä¸Šçš„å·®å¼‚å¯¼è‡´çš„åˆ†æå›°éš¾ï¼ŒVLA-OS èƒ½å¤Ÿéš”ç¦»å˜é‡å¹¶å‰–æä»ç«¯åˆ°ç«¯ç”Ÿæˆè½¬å‘â€œä»»åŠ¡è§„åˆ’åç”ŸæˆåŠ¨ä½œâ€è¿™ä¸€æµç¨‹ä¸­çš„æ ¸å¿ƒç»„ä»¶ã€‚ç ”ç©¶å›¢é˜Ÿåœ¨æ¶µç›–å¤šç§ç‰©ä½“ç±»åˆ«ã€è§†è§‰æ¨¡æ€ã€ç¯å¢ƒåŠæ‰§è¡Œå™¨çš„åœºæ™¯ä¸‹è¿›è¡Œäº†å…¨é¢çš„å¯¹ç…§å®éªŒã€‚ç»“æœè¡¨æ˜ï¼Œè§†è§‰ç€é™†çš„è§„åˆ’è¡¨ç¤º(visually grounded planning representations)é€šå¸¸ä¼˜äºè¯­è¨€è§„åˆ’è¡¨ç¤º(language planning representations)ã€‚æ­¤å¤–ï¼ŒHierarchical-VLA èŒƒå¼åœ¨ä»»åŠ¡æ€§èƒ½ã€é¢„è®­ç»ƒã€æ³›åŒ–èƒ½åŠ›ã€å¯æ‰©å±•æ€§å’ŒæŒç»­å­¦ä¹ èƒ½åŠ›æ–¹é¢è¡¨ç°å‡ºæ˜¾è‘—ä¼˜åŠ¿ã€‚è™½ç„¶è¯¥èŒƒå¼çš„è®­ç»ƒå’Œæ¨ç†é€Ÿåº¦è¾ƒæ…¢ï¼Œä½†å…¶ä¸º VLA æ¨¡å‹çš„ç»“æ„åŒ–ç†è§£å’Œè¿›ä¸€æ­¥æ”¹è¿›æä¾›äº†é‡è¦çš„ç†è®ºæ”¯æ’‘ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2506.17561v1",
      "published_date": "2025-06-21 03:07:48 UTC",
      "updated_date": "2025-06-21 03:07:48 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T23:27:55.380773+00:00"
    },
    {
      "arxiv_id": "2506.17560v1",
      "title": "Towards Zero-Shot Coordination between Teams of Agents: The N-XPlay Framework",
      "title_zh": "è¿ˆå‘æ™ºèƒ½ä½“å›¢é˜Ÿé—´çš„é›¶æ ·æœ¬ååŒï¼šN-XPlay æ¡†æ¶",
      "authors": [
        "Ava Abderezaei",
        "Chi-Hui Lin",
        "Joseph Miceli",
        "Naren Sivagnanadasan",
        "StÃ©phane Aroca-Ouellette",
        "Jake Brawer",
        "Alessandro Roncone"
      ],
      "abstract": "Zero-shot coordination (ZSC) -- the ability to collaborate with unfamiliar partners -- is essential to making autonomous agents effective teammates. Existing ZSC methods evaluate coordination capabilities between two agents who have not previously interacted. However, these scenarios do not reflect the complexity of real-world multi-agent systems, where coordination often involves a hierarchy of sub-groups and interactions between teams of agents, known as Multi-Team Systems (MTS). To address this gap, we first introduce N-player Overcooked, an N-agent extension of the popular two-agent ZSC benchmark, enabling evaluation of ZSC in N-agent scenarios. We then propose N-XPlay for ZSC in N-agent, multi-team settings. Comparison against Self-Play across two-, three- and five-player Overcooked scenarios, where agents are split between an ``ego-team'' and a group of unseen collaborators shows that agents trained with N-XPlay are better able to simultaneously balance ``intra-team'' and ``inter-team'' coordination than agents trained with SP.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†é›¶æ¬¡å­¦ä¹ åè°ƒ (Zero-shot coordination, ZSC) åœ¨å¤šå›¢é˜Ÿç³»ç»Ÿ (Multi-Team Systems, MTS) ä¸­çš„åº”ç”¨ï¼ŒæŒ‡å‡ºç°æœ‰æ–¹æ³•å¾€å¾€å±€é™äºåŒæ™ºèƒ½ä½“åœºæ™¯è€Œå¿½ç•¥äº†ç°å®ä¸­å¤æ‚çš„å±‚çº§äº¤äº’ã€‚ä¸ºæ­¤ï¼Œç ”ç©¶è€…é¦–å…ˆæ¨å‡ºäº† N-player Overcookedï¼Œå°†ç»å…¸çš„ ZSC åŸºå‡†æµ‹è¯•æ‰©å±•è‡³ N æ™ºèƒ½ä½“ç¯å¢ƒï¼Œä»¥æ”¯æŒæ›´å¤æ‚çš„åä½œè¯„ä¼°ã€‚éšåï¼Œè¯¥ç ”ç©¶æå‡ºäº† N-XPlay æ¡†æ¶ï¼Œä¸“é—¨ç”¨äºè§£å†³ N æ™ºèƒ½ä½“åŠå¤šå›¢é˜Ÿè®¾ç½®ä¸‹çš„é›¶æ¬¡å­¦ä¹ åè°ƒæŒ‘æˆ˜ã€‚é€šè¿‡åœ¨äºŒäººã€ä¸‰äººåŠäº”äºº Overcooked åœºæ™¯ä¸­ä¸ Self-Play (SP) æ–¹æ³•è¿›è¡Œå¯¹æ¯”ï¼Œå®éªŒç»“æœè¡¨æ˜ N-XPlay èƒ½å¤Ÿè®©æ™ºèƒ½ä½“åœ¨ä¸æœªçŸ¥ä¼™ä¼´åä½œæ—¶ï¼Œæ›´å¥½åœ°å¹³è¡¡å›¢é˜Ÿå†…éƒ¨ (intra-team) ä¸å›¢é˜Ÿä¹‹é—´ (inter-team) çš„åè°ƒå…³ç³»ã€‚è¯¥æ¡†æ¶çš„æå‡ºä¸ºå®ç°æ›´å…·é€šç”¨æ€§å’Œé€‚åº”æ€§çš„å¤šæ™ºèƒ½ä½“åä½œç³»ç»Ÿæä¾›äº†é‡è¦çš„æŠ€æœ¯æ”¯æŒã€‚",
      "categories": [
        "cs.MA",
        "cs.AI"
      ],
      "primary_category": "cs.MA",
      "comment": "Accepted to RSS Workshop on Scalable and Resilient Multi-Robot Systems: Decision-Making, Coordination, and Learning 2025",
      "pdf_url": "https://arxiv.org/pdf/2506.17560v1",
      "published_date": "2025-06-21 03:04:53 UTC",
      "updated_date": "2025-06-21 03:04:53 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T23:27:59.454234+00:00"
    },
    {
      "arxiv_id": "2506.17558v1",
      "title": "SynDaCaTE: A Synthetic Dataset For Evaluating Part-Whole Hierarchical Inference",
      "title_zh": "SynDaCaTEï¼šç”¨äºè¯„ä¼°éƒ¨åˆ†-æ•´ä½“å±‚çº§æ¨ç†çš„åˆæˆæ•°æ®é›†",
      "authors": [
        "Jake Levi",
        "Mark van der Wilk"
      ],
      "abstract": "Learning to infer object representations, and in particular part-whole hierarchies, has been the focus of extensive research in computer vision, in pursuit of improving data efficiency, systematic generalisation, and robustness. Models which are \\emph{designed} to infer part-whole hierarchies, often referred to as capsule networks, are typically trained end-to-end on supervised tasks such as object classification, in which case it is difficult to evaluate whether such a model \\emph{actually} learns to infer part-whole hierarchies, as claimed. To address this difficulty, we present a SYNthetic DAtaset for CApsule Testing and Evaluation, abbreviated as SynDaCaTE, and establish its utility by (1) demonstrating the precise bottleneck in a prominent existing capsule model, and (2) demonstrating that permutation-equivariant self-attention is highly effective for parts-to-wholes inference, which motivates future directions for designing effective inductive biases for computer vision.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† SynDaCaTEï¼Œä¸€ä¸ªä¸“é—¨ç”¨äºè¯„ä¼°éƒ¨åˆ†-æ•´ä½“å±‚æ¬¡æ¨ç† (part-whole hierarchical inference) çš„åˆæˆæ•°æ®é›†ã€‚ç ”ç©¶èƒŒæ™¯æŒ‡å‡ºï¼Œå°½ç®¡ Capsule Networks æ—¨åœ¨æ¨æ–­ç‰©ä½“å±‚çº§ç»“æ„ï¼Œä½†ä¼ ç»Ÿçš„ç›‘ç£åˆ†ç±»ä»»åŠ¡éš¾ä»¥éªŒè¯æ¨¡å‹æ˜¯å¦çœŸæ­£ä¹ å¾—äº†è¿™ä¸€èƒ½åŠ›ã€‚SynDaCaTE çš„å¼•å…¥è§£å†³äº†è¿™ä¸€è¯„ä¼°æŒ‘æˆ˜ï¼Œå¹¶æ­ç¤ºäº†ç°æœ‰ä¸»æµ Capsule æ¨¡å‹ä¸­å­˜åœ¨çš„ç²¾ç¡®ç“¶é¢ˆã€‚é€šè¿‡å®éªŒï¼Œè¯¥ç ”ç©¶è¿›ä¸€æ­¥è¯æ˜äº†ç½®æ¢ç­‰å˜è‡ªæ³¨æ„åŠ›æœºåˆ¶ (permutation-equivariant self-attention) åœ¨å¤„ç†éƒ¨åˆ†åˆ°æ•´ä½“æ¨ç† (parts-to-wholes inference) æ–¹é¢çš„å“è¶Šæ€§èƒ½ã€‚è¿™äº›æˆæœä¸ä»…æä¾›äº†æ›´ä¸¥è°¨çš„è¯„ä¼°å·¥å…·ï¼Œä¹Ÿä¸ºæœªæ¥è®¡ç®—æœºè§†è§‰ä¸­å½’çº³åç½® (inductive biases) çš„è®¾è®¡æŒ‡æ˜äº†æ–¹å‘ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted at Methods and Opportunities at Small Scale (MOSS), ICML 2025, Vancouver, Canada",
      "pdf_url": "https://arxiv.org/pdf/2506.17558v1",
      "published_date": "2025-06-21 03:01:16 UTC",
      "updated_date": "2025-06-21 03:01:16 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T23:27:58.989784+00:00"
    },
    {
      "arxiv_id": "2506.17551v2",
      "title": "Research on Model Parallelism and Data Parallelism Optimization Methods in Large Language Model-Based Recommendation Systems",
      "title_zh": "åŸºäºå¤§è¯­è¨€æ¨¡å‹çš„æ¨èç³»ç»Ÿæ¨¡å‹å¹¶è¡Œä¸æ•°æ®å¹¶è¡Œä¼˜åŒ–æ–¹æ³•ç ”ç©¶",
      "authors": [
        "Haowei Yang",
        "Yu Tian",
        "Zhongheng Yang",
        "Zhao Wang",
        "Chengrui Zhou",
        "Dannier Li"
      ],
      "abstract": "With the rapid adoption of large language models (LLMs) in recommendation systems, the computational and communication bottlenecks caused by their massive parameter sizes and large data volumes have become increasingly prominent. This paper systematically investigates two classes of optimization methods-model parallelism and data parallelism-for distributed training of LLMs in recommendation scenarios. For model parallelism, we implement both tensor parallelism and pipeline parallelism, and introduce an adaptive load-balancing mechanism to reduce cross-device communication overhead. For data parallelism, we compare synchronous and asynchronous modes, combining gradient compression and sparsification techniques with an efficient aggregation communication framework to significantly improve bandwidth utilization. Experiments conducted on a real-world recommendation dataset in a simulated service environment demonstrate that our proposed hybrid parallelism scheme increases training throughput by over 30% and improves resource utilization by approximately 20% compared to traditional single-mode parallelism, while maintaining strong scalability and robustness. Finally, we discuss trade-offs among different parallel strategies in online deployment and outline future directions involving heterogeneous hardware integration and automated scheduling technologies.",
      "tldr_zh": "æœ¬ç ”ç©¶é’ˆå¯¹åŸºäºå¤§è¯­è¨€æ¨¡å‹(Large Language Models, LLMs)çš„æ¨èç³»ç»Ÿåœ¨å¤„ç†æµ·é‡å‚æ•°å’Œæ•°æ®æ—¶é¢ä¸´çš„è®¡ç®—ä¸é€šä¿¡ç“¶é¢ˆï¼Œç³»ç»Ÿæ¢è®¨äº†åˆ†å¸ƒå¼è®­ç»ƒä¸­çš„æ¨¡å‹å¹¶è¡Œ(Model Parallelism)ä¸æ•°æ®å¹¶è¡Œ(Data Parallelism)ä¼˜åŒ–æ–¹æ³•ã€‚åœ¨æ¨¡å‹å¹¶è¡Œæ–¹é¢ï¼Œç ”ç©¶å®ç°äº†å¼ é‡å¹¶è¡Œ(Tensor Parallelism)ä¸æµæ°´çº¿å¹¶è¡Œ(Pipeline Parallelism)ï¼Œå¹¶å¼•å…¥è‡ªé€‚åº”è´Ÿè½½å‡è¡¡æœºåˆ¶ä»¥å‡å°‘è®¾å¤‡é—´çš„é€šä¿¡å¼€é”€ã€‚é’ˆå¯¹æ•°æ®å¹¶è¡Œï¼Œæœ¬æ–‡å¯¹æ¯”äº†åŒæ­¥ä¸å¼‚æ­¥æ¨¡å¼ï¼Œé€šè¿‡ç»“åˆæ¢¯åº¦å‹ç¼©(Gradient Compression)ä¸ç¨€ç–åŒ–æŠ€æœ¯ï¼Œé…åˆé«˜æ•ˆçš„èšåˆé€šä¿¡æ¡†æ¶æ˜¾è‘—æå‡äº†å¸¦å®½åˆ©ç”¨ç‡ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œåœ¨çœŸå®æ¨èæ•°æ®é›†ç¯å¢ƒä¸‹ï¼Œè¯¥ç ”ç©¶æ‰€æå‡ºçš„æ··åˆå¹¶è¡Œæ–¹æ¡ˆç›¸æ¯”ä¼ ç»Ÿå•æ¨¡å¼å¹¶è¡Œæå‡äº†è¶…è¿‡30%çš„è®­ç»ƒååé‡ï¼Œå¹¶å°†èµ„æºåˆ©ç”¨ç‡æé«˜äº†çº¦20%ã€‚è¯¥æ–¹æ¡ˆåœ¨ä¿æŒå¼ºå¤§å¯æ‰©å±•æ€§ä¸é²æ£’æ€§çš„åŒæ—¶ï¼Œè¿˜æ·±å…¥æ¢è®¨äº†åœ¨çº¿éƒ¨ç½²ä¸­ä¸åŒå¹¶è¡Œç­–ç•¥çš„æƒè¡¡ï¼Œä¸ºæœªæ¥å¼‚æ„ç¡¬ä»¶é›†æˆä¸è‡ªåŠ¨åŒ–è°ƒåº¦æä¾›äº†æŒ‡å¯¼ã€‚",
      "categories": [
        "cs.DC",
        "cs.AI"
      ],
      "primary_category": "cs.DC",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2506.17551v2",
      "published_date": "2025-06-21 02:37:25 UTC",
      "updated_date": "2025-06-24 02:28:50 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T23:28:18.914341+00:00"
    },
    {
      "arxiv_id": "2506.17538v1",
      "title": "ConsumerBench: Benchmarking Generative AI Applications on End-User Devices",
      "title_zh": "ConsumerBenchï¼šç»ˆç«¯è®¾å¤‡ç”Ÿæˆå¼äººå·¥æ™ºèƒ½åº”ç”¨åŸºå‡†æµ‹è¯•",
      "authors": [
        "Yile Gu",
        "Rohan Kadekodi",
        "Hoang Nguyen",
        "Keisuke Kamahori",
        "Yiyu Liu",
        "Baris Kasikci"
      ],
      "abstract": "The recent shift in Generative AI (GenAI) applications from cloud-only environments to end-user devices introduces new challenges in resource management, system efficiency, and user experience. This paper presents ConsumerBench, a comprehensive benchmarking framework designed to evaluate the system efficiency and response time of GenAI models running on end-user devices. Unlike existing benchmarks that assume exclusive model access on dedicated GPUs, ConsumerBench simulates realistic multi-application scenarios executing concurrently on constrained hardware. Furthermore, ConsumerBench supports customizable workflows that simulate complex tasks requiring coordination among multiple applications. ConsumerBench captures both application-level metrics, including latency and Service Level Objective (SLO) attainment, and system-level metrics like CPU/GPU utilization and memory bandwidth. Through extensive experiments, ConsumerBench reveals inefficiencies in resource sharing, unfair scheduling under greedy allocation, and performance pitfalls of static model server configurations. The paper also provides practical insights for model developers and system designers, highlighting the benefits of custom kernels tailored to consumer-grade GPU architectures and the value of implementing SLO-aware scheduling strategies.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ConsumerBenchï¼Œè¿™æ˜¯ä¸€ä¸ªæ—¨åœ¨è¯„ä¼°ç»ˆç«¯è®¾å¤‡ä¸Šç”Ÿæˆå¼äººå·¥æ™ºèƒ½(Generative AI)åº”ç”¨ç³»ç»Ÿæ•ˆç‡å’Œå“åº”æ—¶é—´çš„å…¨é¢åŸºå‡†æµ‹è¯•æ¡†æ¶ã€‚ä¸ä»¥å¾€åŸºäºä¸“ç”¨GPUçš„åŸºå‡†æµ‹è¯•ä¸åŒï¼ŒConsumerBenchæ¨¡æ‹Ÿäº†åœ¨å—é™ç¡¬ä»¶èµ„æºä¸‹å¤šä¸ªåº”ç”¨ç¨‹åºå¹¶å‘æ‰§è¡Œçš„çœŸå®åœºæ™¯ï¼Œå¹¶æ”¯æŒå¤æ‚ä»»åŠ¡çš„å®šåˆ¶åŒ–å·¥ä½œæµã€‚è¯¥æ¡†æ¶èƒ½å¤ŸåŒæ—¶æ•è·å»¶è¿Ÿã€Service Level Objective (SLO)è¾¾æˆç‡ç­‰åº”ç”¨å±‚æŒ‡æ ‡ï¼Œä»¥åŠCPU/GPUåˆ©ç”¨ç‡å’Œå†…å­˜å¸¦å®½ç­‰ç³»ç»Ÿå±‚æŒ‡æ ‡ã€‚é€šè¿‡å¹¿æ³›çš„å®éªŒï¼ŒConsumerBenchæ­ç¤ºäº†èµ„æºå…±äº«æ•ˆç‡ä½ä¸‹ã€è´ªå©ªåˆ†é…å¯¼è‡´çš„ä¸å…¬å¹³è°ƒåº¦ä»¥åŠé™æ€æ¨¡å‹æœåŠ¡å™¨é…ç½®çš„æ€§èƒ½ç“¶é¢ˆã€‚æ­¤å¤–ï¼Œç ”ç©¶è¿˜ä¸ºæ¨¡å‹å¼€å‘è€…å’Œç³»ç»Ÿè®¾è®¡è€…æä¾›äº†å®è·µå»ºè®®ï¼Œå¼ºè°ƒäº†é’ˆå¯¹æ¶ˆè´¹çº§GPUæ¶æ„å¼€å‘å®šåˆ¶å†…æ ¸ä»¥åŠé‡‡ç”¨SLOæ„ŸçŸ¥è°ƒåº¦ç­–ç•¥çš„é‡è¦æ€§ã€‚",
      "categories": [
        "cs.DC",
        "cs.AI",
        "cs.LG",
        "cs.OS"
      ],
      "primary_category": "cs.DC",
      "comment": "The code is available at https://github.com/efeslab/ConsumerBench",
      "pdf_url": "https://arxiv.org/pdf/2506.17538v1",
      "published_date": "2025-06-21 01:32:22 UTC",
      "updated_date": "2025-06-21 01:32:22 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T23:28:16.375078+00:00"
    },
    {
      "arxiv_id": "2506.17536v1",
      "title": "Exploring Strategies for Personalized Radiation Therapy Part I Unlocking Response-Related Tumor Subregions with Class Activation Mapping",
      "title_zh": "æ¢ç´¢ä¸ªæ€§åŒ–æ”¾å°„æ²»ç–—ç­–ç•¥ï¼ˆç¬¬ä¸€éƒ¨åˆ†ï¼‰ï¼šåˆ©ç”¨ç±»æ¿€æ´»æ˜ å°„æ­ç¤ºç–—æ•ˆç›¸å…³çš„è‚¿ç˜¤äºšåŒº",
      "authors": [
        "Hao Peng",
        "Steve Jiang",
        "Robert Timmerman"
      ],
      "abstract": "Personalized precision radiation therapy requires more than simple classification, it demands the identification of prognostic, spatially informative features and the ability to adapt treatment based on individual response. This study compares three approaches for predicting treatment response: standard radiomics, gradient based features, and convolutional neural networks enhanced with Class Activation Mapping. We analyzed 69 brain metastases from 39 patients treated with Gamma Knife radiosurgery. An integrated autoencoder classifier model was used to predict whether tumor volume would shrink by more than 20 percent at a three months follow up, framed as a binary classification task. The results highlight their strength in hierarchical feature extraction and the classifiers discriminative capacity. Among the models, pixel wise CAM provides the most detailed spatial insight, identifying lesion specific regions rather than relying on fixed patterns, demonstrating strong generalization. In non responding lesions, the activated regions may indicate areas of radio resistance. Pixel wise CAM outperformed both radiomics and gradient based methods in classification accuracy. Moreover, its fine grained spatial features allow for alignment with cellular level data, supporting biological validation and deeper understanding of heterogeneous treatment responses. Although further validation is necessary, these findings underscore the promise in guiding personalized and adaptive radiotherapy strategies for both photon and particle therapies.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†ä¸ªæ€§åŒ–æ”¾å°„æ²»ç–—ç­–ç•¥ï¼Œé‡ç‚¹é€šè¿‡ Class Activation Mapping (CAM) è¯†åˆ«ä¸æ²»ç–—ååº”ç›¸å…³çš„è‚¿ç˜¤äºšåŒºåŸŸã€‚ç ”ç©¶å¯¹æ¯”äº†æ ‡å‡† Radiomicsã€åŸºäºæ¢¯åº¦çš„ç‰¹å¾ä»¥åŠç»“åˆ CAM çš„å·ç§¯ç¥ç»ç½‘ç»œ (CNN) ä¸‰ç§æ–¹æ³•ï¼Œå¯¹ 39 åæ¥å— Gamma Knife æ”¾å°„å¤–ç§‘æ²»ç–—æ‚£è€…çš„ 69 ä¸ªè„‘è½¬ç§»ç˜¤è¿›è¡Œäº†åˆ†æã€‚é€šè¿‡é›†æˆè‡ªåŠ¨ç¼–ç å™¨åˆ†ç±»æ¨¡å‹é¢„æµ‹è‚¿ç˜¤åœ¨ä¸‰ä¸ªæœˆéšè®¿æ—¶æ˜¯å¦ç¼©å°è¶…è¿‡ 20%ï¼Œå®éªŒç»“æœæ˜¾ç¤ºåƒç´ çº§ CAM åœ¨åˆ†ç±»å‡†ç¡®ç‡ä¸Šæ˜¾è‘—ä¼˜äºä¼ ç»Ÿ Radiomics å’Œæ¢¯åº¦æ³•ã€‚CAM èƒ½å¤Ÿè¯†åˆ«ç‰¹å®šç—…å˜åŒºåŸŸå¹¶æ­ç¤ºæ½œåœ¨çš„æ”¾å°„æŠ—æ€§ (radioresistance) åŒºåŸŸï¼Œæä¾›æ¯”å›ºå®šæ¨¡å¼æ›´è¯¦ç»†çš„è§£å‰–ç©ºé—´è§è§£ã€‚å…¶ç»†ç²’åº¦çš„ç©ºé—´ç‰¹å¾æ”¯æŒä¸ç»†èƒçº§æ•°æ®çš„ç”Ÿç‰©å­¦éªŒè¯ï¼Œä¸ºå®ç°å…‰å­å’Œç²’å­æ²»ç–—çš„ä¸ªæ€§åŒ–ã€è‡ªé€‚åº”æ”¾ç–—æ–¹æ¡ˆå¥ å®šäº†åŸºç¡€ã€‚",
      "categories": [
        "physics.med-ph",
        "cs.AI"
      ],
      "primary_category": "physics.med-ph",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2506.17536v1",
      "published_date": "2025-06-21 01:24:25 UTC",
      "updated_date": "2025-06-21 01:24:25 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T23:28:25.911645+00:00"
    },
    {
      "arxiv_id": "2506.17525v2",
      "title": "Data Quality Issues in Multilingual Speech Datasets: The Need for Sociolinguistic Awareness and Proactive Language Planning",
      "title_zh": "å¤šè¯­ç§è¯­éŸ³æ•°æ®é›†ä¸­çš„æ•°æ®è´¨é‡é—®é¢˜ï¼šç¤¾ä¼šè¯­è¨€å­¦æ„è¯†ä¸å‰ç»æ€§è¯­è¨€è§„åˆ’çš„å¿…è¦æ€§",
      "authors": [
        "Mingfei Lau",
        "Qian Chen",
        "Yeming Fang",
        "Tingting Xu",
        "Tongzhou Chen",
        "Pavel Golik"
      ],
      "abstract": "Our quality audit for three widely used public multilingual speech datasets - Mozilla Common Voice 17.0, FLEURS, and Vox Populi - shows that in some languages, these datasets suffer from significant quality issues, which may obfuscate downstream evaluation results while creating an illusion of success. We divide these quality issues into two categories: micro-level and macro-level. We find that macro-level issues are more prevalent in less institutionalized, often under-resourced languages. We provide a case analysis of Taiwanese Southern Min (nan_tw) that highlights the need for proactive language planning (e.g. orthography prescriptions, dialect boundary definition) and enhanced data quality control in the dataset creation process. We conclude by proposing guidelines and recommendations to mitigate these issues in future dataset development, emphasizing the importance of sociolinguistic awareness and language planning principles. Furthermore, we encourage research into how this creation process itself can be leveraged as a tool for community-led language planning and revitalization.",
      "tldr_zh": "è¯¥é¡¹ç ”ç©¶å¯¹ Mozilla Common Voice 17.0ã€FLEURS å’Œ Vox Populi ä¸‰ä¸ªå¤šè¯­ç§è¯­éŸ³æ•°æ®é›†è¿›è¡Œäº†è´¨é‡å®¡è®¡ï¼Œæ­ç¤ºäº†éƒ¨åˆ†è¯­è¨€ä¸­å­˜åœ¨çš„ä¸¥é‡è´¨é‡ç¼ºé™·ï¼ŒæŒ‡å‡ºè¿™äº›é—®é¢˜å¯èƒ½æ©ç›–çœŸå®çš„æ¨¡å‹è¯„ä¼°æ•ˆæœå¹¶äº§ç”Ÿè™šå‡çš„æŠ€æœ¯è¿›æ­¥é”™è§‰ã€‚ç ”ç©¶å°†æ•°æ®è´¨é‡é—®é¢˜åˆ’åˆ†ä¸ºå¾®è§‚(micro-level)å’Œå®è§‚(macro-level)ä¸¤ä¸ªå±‚é¢ï¼Œå¹¶å‘ç°å®è§‚å±‚é¢çš„é—®é¢˜åœ¨ç¼ºä¹åˆ¶åº¦åŒ–æ”¯æŒçš„ä½èµ„æºè¯­è¨€ä¸­å°¤ä¸ºæ™®éã€‚é€šè¿‡å¯¹é—½å—è¯­(Taiwanese Southern Min)çš„æ¡ˆä¾‹åˆ†æï¼Œä½œè€…å¼ºè°ƒäº†åœ¨æ•°æ®é›†åˆ›å»ºåˆæœŸå®æ–½ä¸»åŠ¨è¯­è¨€è§„åˆ’(proactive language planning)ï¼ˆå¦‚æ­£å­—æ³•è§„èŒƒå’Œæ–¹è¨€è¾¹ç•Œç•Œå®šï¼‰ä»¥åŠåŠ å¼ºè´¨é‡æ§åˆ¶çš„å¿…è¦æ€§ã€‚ç ”ç©¶æœ€åæå‡ºäº†æ”¹è¿›æœªæ¥æ•°æ®é›†å¼€å‘çš„æŒ‡å¯¼æ–¹é’ˆï¼Œæ ¸å¿ƒåœ¨äºæå‡ç¤¾ä¼šè¯­è¨€å­¦æ„è¯†(sociolinguistic awareness)å¹¶å¼•å…¥è¯­è¨€è§„åˆ’åŸåˆ™ã€‚æ­¤å¤–ï¼Œç ”ç©¶è¿˜æ¢è®¨äº†å¦‚ä½•å°†æ•°æ®é›†æ„å»ºè¿‡ç¨‹è½¬åŒ–ä¸ºä¸€ç§æœ‰æ•ˆå·¥å…·ï¼Œä»¥ä¿ƒè¿›ç”±ç¤¾åŒºé©±åŠ¨çš„è¯­è¨€æŒ¯å…´ä¸é•¿æœŸè§„åˆ’ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted by ACL 2025 Main Conference",
      "pdf_url": "https://arxiv.org/pdf/2506.17525v2",
      "published_date": "2025-06-21 00:34:18 UTC",
      "updated_date": "2025-06-27 18:38:01 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T23:28:26.279757+00:00"
    }
  ],
  "processing_status": "completed",
  "error": null,
  "raw_papers_fetched": true,
  "papers_count": 64,
  "processed_papers_count": 64,
  "failed_papers_count": 0,
  "llm_backup_calls": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2026-01-23T23:34:15.088945+00:00"
}