{
  "date": "2024-05-15",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-05-15 的 arXiv 中文 TLDR 快报！今天 arXiv 的论文主要聚焦于 AI 和机器学习领域，包括大型语言模型（LLM）的公平性、对齐和知识编辑、视频推理基准、强化学习应用，以及医疗和图像处理创新。其中，令人印象深刻的文章有 Spectral Editing of Activations for Large Language Model Alignment（探讨 LLM 对齐机制）和 Benchmark Early and Red Team Often（提出 AI 双用途风险评估框架），这些工作由知名学者如 Anna Korhonen 和 Joshua B. Tenenbaum 等参与，突显了 AI 安全和多模态理解的热点。\n\n下面，我将逐一简要概述今日论文，先优先讨论重要、话题度高的文章（如 LLM 相关和 AI 基准），然后快速掠过其他领域的内容。每个条目包括论文标题（中文 + 英文）和核心贡献。\n\n### LLM 和 AI 安全相关（重点讨论）\n- **公平性调查：A survey on fairness of large language models in e-commerce**  \n  这篇论文调查了 LLM 在电商中的公平性问题，包括应用（如产品推荐和评论分析）和挑战（如数据偏差），主要发现是 LLM 可能强化刻板印象并影响消费者信任，建议未来研究聚焦于减少偏差以实现更公平的系统。\n\n- **激活谱编辑：Spectral Editing of Activations for Large Language Model Alignment**  \n  作者包括 Anna Korhonen 和 Edoardo M. Ponti，该工作提出了一种新方法 SEA，通过投影激活以最小化负面行为（如幻觉生成），主要贡献是提升 LLM 的真实性和泛化能力，同时减少计算开销，并在多个基准上表现出色。\n\n- **AI 双用途风险基准：Benchmark Early and Red Team Often: A Framework for Assessing and Managing Dual-Use Hazards of AI Foundation Models**  \n  这篇论文由 Anthony M. Barrett 等学者撰写，提出结合公开基准和红队评估的方法来评估 AI 模型的双用途风险（如用于攻击），关键发现是这种框架能高效识别高风险模型，并为 AI 安全管理提供实用指导。\n\n- **LoRA 改进：LoRA Learns Less and Forgets Less**  \n  作者包括 Jonathan Frankle，该研究分析了 LoRA 在参数高效微调中的表现，发现 LoRA 能减少遗忘并保持模型多样性，主要贡献是通过实验证明 LoRA 在编程和数学任务中优于全微调，同时提供最佳实践建议。\n\n- **世界知识评估：Elements of World Knowledge (EWOK): A cognition-inspired framework for evaluating basic world knowledge in language models**  \n  作者团队包括 Joshua Tenenbaum，该框架测试 LLM 的世界知识能力（如常识推理），主要发现是现有模型在动态知识领域表现欠佳，并通过新基准数据集强调了 LLM 改进的必要性。\n\n### 视频和图像处理基准（高话题度）\n- **SOK-Bench：SOK-Bench: A Situated Video Reasoning Benchmark with Aligned Open-World Knowledge**  \n  这篇论文（CVPR 相关）提出一个新基准 SOK-Bench，包括 44K 问题和 10K 视频，聚焦视频中情境推理，主要贡献是通过 LLM 和多模态模型自动生成数据，提升了模型在真实世界知识上的泛化能力。\n\n- **STAR 基准：STAR: A Benchmark for Situated Reasoning in Real-World Videos**  \n  作者包括 Chuang Gan 和 Joshua B. Tenenbaum，该工作引入 STAR 基准，用于评估视频中的情境推理，主要发现是现有模型在动态情境下表现不足，并提出神经符号模型来改进推理准确性。\n\n### 强化学习和多模态应用（创新性强）\n- **多代理强化学习：Fully Distributed Fog Load Balancing with Multi-Agent Reinforcement Learning**  \n  该论文提出 MARL 框架优化雾计算资源分配，主要贡献是通过转移学习最小化等待时间，并在分布式环境中提升性能，适用于 IoT 负载平衡。\n\n- **视频生成创新：Dance Any Beat: Blending Beats with Visuals in Dance Video Generation**  \n  工作引入 DabFusion 模型，使用音乐特征生成个性化舞蹈视频，主要发现是模型能处理未见个体并提升音乐-动作对齐，实验在 AIST++ 数据集上表现出色。\n\n### 其他领域快速概述\n- **IoT 设备识别：Leveraging Machine Learning for Accurate IoT Device Identification in Dynamic Wireless Contexts**  \n  该论文使用机器学习识别 IoT 设备，主要贡献是通过“accumulation score”处理无线动态，提升 F1 分数至 97%，但在实际应用中可能受限于环境噪声。\n\n- **医学图像处理：Content-Based Image Retrieval for Multi-Class Volumetric Radiology Images: A Benchmark Study**  \n  工作建立放射图像检索基准，主要发现是预训练模型在多器官检索中有效，但整体性能需进一步优化。\n\n- **生成模型优化：ReconBoost: Boosting Can Achieve Modality Reconcilement**  \n  提出多模态学习框架，主要贡献是提升模态对齐，但实验仅限于特定数据集，泛化性有待验证。\n\n其他论文如神经网络理论、数据增强或特定领域优化（如强化学习在机器人或医疗中的应用），虽有贡献但相对常规，我这里仅快速提及：例如，**神经平衡理论：A Theory of Synaptic Neural Balance** 探讨了神经网络平衡机制；**图像分割：Fourier Boundary Features Network with Wider Catchers for Glass Segmentation** 改进玻璃图像分割；这些工作在各自领域有小幅提升，但未见重大突破，故从简。\n\n总之，今天的 arXiv 论文突显了 AI 领域的快速演进，尤其在 LLM 和多模态任务上。感兴趣的读者可关注上述关键文章，以探索实际应用和潜在风险。明日见！",
  "papers": [
    {
      "arxiv_id": "2405.12236v2",
      "title": "Fully Distributed Fog Load Balancing with Multi-Agent Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Maad Ebrahim",
        "Abdelhakim Hafid"
      ],
      "abstract": "Real-time Internet of Things (IoT) applications require real-time support to\nhandle the ever-growing demand for computing resources to process IoT\nworkloads. Fog Computing provides high availability of such resources in a\ndistributed manner. However, these resources must be efficiently managed to\ndistribute unpredictable traffic demands among heterogeneous Fog resources.\nThis paper proposes a fully distributed load-balancing solution with\nMulti-Agent Reinforcement Learning (MARL) that intelligently distributes IoT\nworkloads to optimize the waiting time while providing fair resource\nutilization in the Fog network. These agents use transfer learning for\nlife-long self-adaptation to dynamic changes in the environment. By leveraging\ndistributed decision-making, MARL agents effectively minimize the waiting time\ncompared to a single centralized agent solution and other baselines, enhancing\nend-to-end execution delay. Besides performance gain, a fully distributed\nsolution allows for a global-scale implementation where agents can work\nindependently in small collaboration regions, leveraging nearby local\nresources. Furthermore, we analyze the impact of a realistic frequency to\nobserve the state of the environment, unlike the unrealistic common assumption\nin the literature of having observations readily available in real-time for\nevery required action. The findings highlight the trade-off between realism and\nperformance using an interval-based Gossip-based multi-casting protocol against\nassuming real-time observation availability for every generated workload.",
      "tldr_zh": "本研究针对物联网（IoT）应用的实时计算需求，提出了一种完全分布式的负载均衡解决方案，利用 Multi-Agent Reinforcement Learning (MARL) 在 Fog Computing 环境中智能分配工作负载，以优化等待时间并实现公平资源利用。MARL 代理通过 transfer learning 实现终身自适应，处理动态环境变化，并与集中式方案相比显著减少端到端执行延迟，在实验中表现出色。论文还分析了观察环境状态频率的现实影响，使用基于 Gossip 的多播协议突显了现实性与性能之间的权衡，为大规模分布式实现提供了可行基础。",
      "categories": [
        "cs.AI",
        "cs.DC",
        "cs.LG",
        "cs.MA"
      ],
      "primary_category": "cs.AI",
      "comment": "Submitted to IEEE TNSM with 14 pages, 11 figures, and 3 tables",
      "pdf_url": "http://arxiv.org/pdf/2405.12236v2",
      "published_date": "2024-05-15 23:44:06 UTC",
      "updated_date": "2025-03-26 14:25:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:33:45.849578"
    },
    {
      "arxiv_id": "2405.13025v2",
      "title": "A survey on fairness of large language models in e-commerce: progress, application, and challenge",
      "title_zh": "翻译失败",
      "authors": [
        "Qingyang Ren",
        "Zilin Jiang",
        "Jinghan Cao",
        "Sijia Li",
        "Chiqu Li",
        "Yiyang Liu",
        "Shuning Huo",
        "Tiange He",
        "Yuan Chen"
      ],
      "abstract": "This survey explores the fairness of large language models (LLMs) in\ne-commerce, examining their progress, applications, and the challenges they\nface. LLMs have become pivotal in the e-commerce domain, offering innovative\nsolutions and enhancing customer experiences. This work presents a\ncomprehensive survey on the applications and challenges of LLMs in e-commerce.\nThe paper begins by introducing the key principles underlying the use of LLMs\nin e-commerce, detailing the processes of pretraining, fine-tuning, and\nprompting that tailor these models to specific needs. It then explores the\nvaried applications of LLMs in e-commerce, including product reviews, where\nthey synthesize and analyze customer feedback; product recommendations, where\nthey leverage consumer data to suggest relevant items; product information\ntranslation, enhancing global accessibility; and product question and answer\nsections, where they automate customer support. The paper critically addresses\nthe fairness challenges in e-commerce, highlighting how biases in training data\nand algorithms can lead to unfair outcomes, such as reinforcing stereotypes or\ndiscriminating against certain groups. These issues not only undermine consumer\ntrust, but also raise ethical and legal concerns. Finally, the work outlines\nfuture research directions, emphasizing the need for more equitable and\ntransparent LLMs in e-commerce. It advocates for ongoing efforts to mitigate\nbiases and improve the fairness of these systems, ensuring they serve diverse\nglobal markets effectively and ethically. Through this comprehensive analysis,\nthe survey provides a holistic view of the current landscape of LLMs in\ne-commerce, offering insights into their potential and limitations, and guiding\nfuture endeavors in creating fairer and more inclusive e-commerce environments.",
      "tldr_zh": "这篇调查论文探讨了大语言模型 (LLMs) 在电子商务领域的公平性，包括其进展、应用和挑战。论文详细介绍了 LLMs 的关键原则，如预训练、微调和提示技术，并阐述了其在产品评论、推荐、翻译以及问答等电子商务应用中的创新作用。作者突出了公平性问题，例如训练数据和算法中的偏见可能导致不公平结果、强化刻板印象或歧视特定群体，从而影响消费者信任和引发伦理法律担忧。未来研究方向强调需要开发更公平、透明的 LLMs 系统，以缓解偏见并促进更具包容性的全球电子商务环境。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.CL",
      "comment": "21 pages, 9 figures",
      "pdf_url": "http://arxiv.org/pdf/2405.13025v2",
      "published_date": "2024-05-15 23:25:19 UTC",
      "updated_date": "2024-06-21 21:26:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:33:56.568169"
    },
    {
      "arxiv_id": "2405.17442v1",
      "title": "Leveraging Machine Learning for Accurate IoT Device Identification in Dynamic Wireless Contexts",
      "title_zh": "利用机器学习在动态无线环境中实现准确的 IoT 设备识别",
      "authors": [
        "Bhagyashri Tushir",
        "Vikram K Ramanna",
        "Yuhong Liu",
        "Behnam Dezfouli"
      ],
      "abstract": "Identifying IoT devices is crucial for network monitoring, security\nenforcement, and inventory tracking. However, most existing identification\nmethods rely on deep packet inspection, which raises privacy concerns and adds\ncomputational complexity. More importantly, existing works overlook the impact\nof wireless channel dynamics on the accuracy of layer-2 features, thereby\nlimiting their effectiveness in real-world scenarios. In this work, we define\nand use the latency of specific probe-response packet exchanges, referred to as\n\"device latency,\" as the main feature for device identification. Additionally,\nwe reveal the critical impact of wireless channel dynamics on the accuracy of\ndevice identification based on device latency. Specifically, this work\nintroduces \"accumulation score\" as a novel approach to capturing fine-grained\nchannel dynamics and their impact on device latency when training machine\nlearning models. We implement the proposed methods and measure the accuracy and\noverhead of device identification in real-world scenarios. The results confirm\nthat by incorporating the accumulation score for balanced data collection and\ntraining machine learning algorithms, we achieve an F1 score of over 97% for\ndevice identification, even amidst wireless channel dynamics, a significant\nimprovement over the 75% F1 score achieved by disregarding the impact of\nchannel dynamics on data collection and device latency.",
      "tldr_zh": "本文提出了一种利用机器学习改进 IoT 设备识别的方法，针对现有依赖 deep packet inspection 的方法存在的隐私问题和计算复杂性，以及忽略无线通道动态的影响问题。核心创新包括定义 device latency 作为主要特征，并引入 accumulation score 来捕捉细粒度的通道动态，从而优化数据收集和模型训练。实验结果显示，该方法在真实场景中实现了超过 97% 的 F1 score，即使在动态无线环境中，也比忽略通道动态的基线方法提高了 22%。",
      "categories": [
        "cs.NI",
        "cs.AI",
        "cs.LG",
        "cs.OS"
      ],
      "primary_category": "cs.NI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.17442v1",
      "published_date": "2024-05-15 22:34:52 UTC",
      "updated_date": "2024-05-15 22:34:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:34:09.921433"
    },
    {
      "arxiv_id": "2405.09719v3",
      "title": "Spectral Editing of Activations for Large Language Model Alignment",
      "title_zh": "翻译失败",
      "authors": [
        "Yifu Qiu",
        "Zheng Zhao",
        "Yftah Ziser",
        "Anna Korhonen",
        "Edoardo M. Ponti",
        "Shay B. Cohen"
      ],
      "abstract": "Large language models (LLMs) often exhibit undesirable behaviours, such as\ngenerating untruthful or biased content. Editing their internal representations\nhas been shown to be effective in mitigating such behaviours on top of the\nexisting alignment methods. We propose a novel inference-time editing method,\nnamely spectral editing of activations (SEA), to project the input\nrepresentations into directions with maximal covariance with the positive\ndemonstrations (e.g., truthful) while minimising covariance with the negative\ndemonstrations (e.g., hallucinated). We also extend our method to non-linear\nediting using feature functions. We run extensive experiments on benchmarks\nconcerning truthfulness and bias with six open-source LLMs of different sizes\nand model families. The results demonstrate the superiority of SEA in\neffectiveness, generalisation to similar tasks, as well as computation and data\nefficiency. We also show that SEA editing only has a limited negative impact on\nother model capabilities.",
      "tldr_zh": "本研究提出了一种新的推理时编辑方法，Spectral Editing of Activations (SEA)，用于对齐大型语言模型 (LLMs)，以减轻其生成不真实或有偏见内容的不期望行为。SEA 通过投影输入表示，使其与正面演示（如真实性）最大化协方差，同时最小化与负面演示（如幻觉）的协方差，并扩展到非线性编辑以提升灵活性。在六种不同大小和家族的开源 LLMs 上进行的广泛实验显示，SEA 在真实性和偏见基准上表现出色，具有更高的有效性、泛化能力，以及计算和数据效率；此外，该方法对模型其他能力的影响较小。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "24 pages, NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2405.09719v3",
      "published_date": "2024-05-15 22:28:23 UTC",
      "updated_date": "2024-11-03 11:12:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:34:22.961704"
    },
    {
      "arxiv_id": "2405.09713v2",
      "title": "SOK-Bench: A Situated Video Reasoning Benchmark with Aligned Open-World Knowledge",
      "title_zh": "翻译失败",
      "authors": [
        "Andong Wang",
        "Bo Wu",
        "Sunli Chen",
        "Zhenfang Chen",
        "Haotian Guan",
        "Wei-Ning Lee",
        "Li Erran Li",
        "Chuang Gan"
      ],
      "abstract": "Learning commonsense reasoning from visual contexts and scenes in real-world\nis a crucial step toward advanced artificial intelligence. However, existing\nvideo reasoning benchmarks are still inadequate since they were mainly designed\nfor factual or situated reasoning and rarely involve broader knowledge in the\nreal world. Our work aims to delve deeper into reasoning evaluations,\nspecifically within dynamic, open-world, and structured context knowledge. We\npropose a new benchmark (SOK-Bench), consisting of 44K questions and 10K\nsituations with instance-level annotations depicted in the videos. The\nreasoning process is required to understand and apply situated knowledge and\ngeneral knowledge for problem-solving. To create such a dataset, we propose an\nautomatic and scalable generation method to generate question-answer pairs,\nknowledge graphs, and rationales by instructing the combinations of LLMs and\nMLLMs. Concretely, we first extract observable situated entities, relations,\nand processes from videos for situated knowledge and then extend to open-world\nknowledge beyond the visible content. The task generation is facilitated\nthrough multiple dialogues as iterations and subsequently corrected and refined\nby our designed self-promptings and demonstrations. With a corpus of both\nexplicit situated facts and implicit commonsense, we generate associated\nquestion-answer pairs and reasoning processes, finally followed by manual\nreviews for quality assurance. We evaluated recent mainstream large\nvision-language models on the benchmark and found several insightful\nconclusions. For more information, please refer to our benchmark at\nwww.bobbywu.com/SOKBench.",
      "tldr_zh": "本研究提出SOK-Bench，一种新的视频推理基准，旨在评估模型在动态开放世界中理解和应用situated knowledge与open-world knowledge的能力，以弥补现有基准的不足。该基准包含44K个问题和10K个情境视频，并通过提取视频中的situated entities、relations和processes，再扩展到更广泛的知识，使用LLMs和MLLMs结合多轮对话、自提示和演示自动生成问题-答案对、知识图谱及推理过程，并经手动审查确保质量。实验评估了主流大型视觉语言模型，发现了模型在处理真实世界推理时的关键洞见，有助于推进人工智能的常识推理发展。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "CVPR",
      "pdf_url": "http://arxiv.org/pdf/2405.09713v2",
      "published_date": "2024-05-15 21:55:31 UTC",
      "updated_date": "2024-05-17 02:18:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:34:33.086031"
    },
    {
      "arxiv_id": "2405.09711v1",
      "title": "STAR: A Benchmark for Situated Reasoning in Real-World Videos",
      "title_zh": "翻译失败",
      "authors": [
        "Bo Wu",
        "Shoubin Yu",
        "Zhenfang Chen",
        "Joshua B Tenenbaum",
        "Chuang Gan"
      ],
      "abstract": "Reasoning in the real world is not divorced from situations. How to capture\nthe present knowledge from surrounding situations and perform reasoning\naccordingly is crucial and challenging for machine intelligence. This paper\nintroduces a new benchmark that evaluates the situated reasoning ability via\nsituation abstraction and logic-grounded question answering for real-world\nvideos, called Situated Reasoning in Real-World Videos (STAR Benchmark). This\nbenchmark is built upon the real-world videos associated with human actions or\ninteractions, which are naturally dynamic, compositional, and logical. The\ndataset includes four types of questions, including interaction, sequence,\nprediction, and feasibility. We represent the situations in real-world videos\nby hyper-graphs connecting extracted atomic entities and relations (e.g.,\nactions, persons, objects, and relationships). Besides visual perception,\nsituated reasoning also requires structured situation comprehension and logical\nreasoning. Questions and answers are procedurally generated. The answering\nlogic of each question is represented by a functional program based on a\nsituation hyper-graph. We compare various existing video reasoning models and\nfind that they all struggle on this challenging situated reasoning task. We\nfurther propose a diagnostic neuro-symbolic model that can disentangle visual\nperception, situation abstraction, language understanding, and functional\nreasoning to understand the challenges of this benchmark.",
      "tldr_zh": "这篇论文引入了 STAR Benchmark，这是一个用于评估真实世界视频中情境推理能力的基准，通过情境抽象和基于逻辑的问题回答来测试模型。基准基于动态的视频数据（如人类动作或互动），使用 hyper-graphs 连接实体和关系（如 actions、persons、objects）来表示情境，并通过 functional program 程序生成四种问题类型：interaction、sequence、prediction 和 feasibility。实验结果显示，现有的视频推理模型在这一挑战性任务上表现不佳，而论文提出的诊断性神经符号模型能够解耦视觉感知、情境抽象、语言理解和功能推理，揭示了基准的核心难题。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.CV"
      ],
      "primary_category": "cs.AI",
      "comment": "NeurIPS",
      "pdf_url": "http://arxiv.org/pdf/2405.09711v1",
      "published_date": "2024-05-15 21:53:54 UTC",
      "updated_date": "2024-05-15 21:53:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:34:45.627532"
    },
    {
      "arxiv_id": "2405.09708v1",
      "title": "No More Mumbles: Enhancing Robot Intelligibility through Speech Adaptation",
      "title_zh": "翻译失败",
      "authors": [
        "Qiaoqiao Ren",
        "Yuanbo Hou",
        "Dick Botteldooren",
        "Tony Belpaeme"
      ],
      "abstract": "Spoken language interaction is at the heart of interpersonal communication,\nand people flexibly adapt their speech to different individuals and\nenvironments. It is surprising that robots, and by extension other digital\ndevices, are not equipped to adapt their speech and instead rely on fixed\nspeech parameters, which often hinder comprehension by the user. We conducted a\nspeech comprehension study involving 39 participants who were exposed to\ndifferent environmental and contextual conditions. During the experiment, the\nrobot articulated words using different vocal parameters, and the participants\nwere tasked with both recognising the spoken words and rating their subjective\nimpression of the robot's speech. The experiment's primary outcome shows that\nspaces with good acoustic quality positively correlate with intelligibility and\nuser experience. However, increasing the distance between the user and the\nrobot exacerbated the user experience, while distracting background sounds\nsignificantly reduced speech recognition accuracy and user satisfaction. We\nnext built an adaptive voice for the robot. For this, the robot needs to know\nhow difficult it is for a user to understand spoken language in a particular\nsetting. We present a prediction model that rates how annoying the ambient\nacoustic environment is and, consequentially, how hard it is to understand\nsomeone in this setting. Then, we develop a convolutional neural network model\nto adapt the robot's speech parameters to different users and spaces, while\ntaking into account the influence of ambient acoustics on intelligibility.\nFinally, we present an evaluation with 27 users, demonstrating superior\nintelligibility and user experience with adaptive voice parameters compared to\nfixed voice.",
      "tldr_zh": "该研究探讨了机器人语音适应性，以提升其可理解性（intelligibility）。通过一项涉及39名参与者的实验，发现良好声学环境提升了语音识别准确性和用户体验，而距离增加和背景噪音则显著降低满意度。研究构建了一个预测模型评估环境噪音的烦扰程度，并开发了基于卷积神经网络（convolutional neural network）的模型，使机器人语音参数能根据用户和空间动态调整。最终实验显示，与固定语音相比，适应性语音在27名用户中显著提高了语音清晰度和整体用户体验。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "stat.CO"
      ],
      "primary_category": "cs.RO",
      "comment": "IEEE Robotics and Automation Letters (IEEE RAL)",
      "pdf_url": "http://arxiv.org/pdf/2405.09708v1",
      "published_date": "2024-05-15 21:28:55 UTC",
      "updated_date": "2024-05-15 21:28:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:34:57.083915"
    },
    {
      "arxiv_id": "2405.09691v2",
      "title": "Modeling User Preferences via Brain-Computer Interfacing",
      "title_zh": "翻译失败",
      "authors": [
        "Luis A. Leiva",
        "V. Javier Traver",
        "Alexandra Kawala-Sterniuk",
        "Tuukka Ruotsalo"
      ],
      "abstract": "Present Brain-Computer Interfacing (BCI) technology allows inference and\ndetection of cognitive and affective states, but fairly little has been done to\nstudy scenarios in which such information can facilitate new applications that\nrely on modeling human cognition. One state that can be quantified from various\nphysiological signals is attention. Estimates of human attention can be used to\nreveal preferences and novel dimensions of user experience. Previous approaches\nhave tackled these incredibly challenging tasks using a variety of behavioral\nsignals, from dwell-time to click-through data, and computational models of\nvisual correspondence to these behavioral signals. However, behavioral signals\nare only rough estimations of the real underlying attention and affective\npreferences of the users. Indeed, users may attend to some content simply\nbecause it is salient, but not because it is really interesting, or simply\nbecause it is outrageous. With this paper, we put forward a research agenda and\nexample work using BCI to infer users' preferences, their attentional\ncorrelates towards visual content, and their associations with affective\nexperience. Subsequently, we link these to relevant applications, such as\ninformation retrieval, personalized steering of generative models, and\ncrowdsourcing population estimates of affective experiences.",
      "tldr_zh": "本文提出使用 Brain-Computer Interfacing (BCI) 技术来更准确地建模用户偏好，通过分析生理信号推断用户的注意力和情感状态，以克服传统行为信号（如点击数据）的局限性。相较于基于视觉对应或行为估计的方法，BCI 可以揭示用户真实注意力与偏好的潜在维度，例如区分显眼内容与真正感兴趣的内容。论文还概述了研究议程，并探讨其在信息检索、个性化生成模型引导以及众包情感体验评估中的应用潜力。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.09691v2",
      "published_date": "2024-05-15 20:41:46 UTC",
      "updated_date": "2024-05-31 16:57:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:35:09.684757"
    },
    {
      "arxiv_id": "2405.09689v1",
      "title": "Generalized Holographic Reduced Representations",
      "title_zh": "翻译失败",
      "authors": [
        "Calvin Yeung",
        "Zhuowen Zou",
        "Mohsen Imani"
      ],
      "abstract": "Deep learning has achieved remarkable success in recent years. Central to its\nsuccess is its ability to learn representations that preserve task-relevant\nstructure. However, massive energy, compute, and data costs are required to\nlearn general representations. This paper explores Hyperdimensional Computing\n(HDC), a computationally and data-efficient brain-inspired alternative. HDC\nacts as a bridge between connectionist and symbolic approaches to artificial\nintelligence (AI), allowing explicit specification of representational\nstructure as in symbolic approaches while retaining the flexibility of\nconnectionist approaches. However, HDC's simplicity poses challenges for\nencoding complex compositional structures, especially in its binding operation.\nTo address this, we propose Generalized Holographic Reduced Representations\n(GHRR), an extension of Fourier Holographic Reduced Representations (FHRR), a\nspecific HDC implementation. GHRR introduces a flexible, non-commutative\nbinding operation, enabling improved encoding of complex data structures while\npreserving HDC's desirable properties of robustness and transparency. In this\nwork, we introduce the GHRR framework, prove its theoretical properties and its\nadherence to HDC properties, explore its kernel and binding characteristics,\nand perform empirical experiments showcasing its flexible non-commutativity,\nenhanced decoding accuracy for compositional structures, and improved\nmemorization capacity compared to FHRR.",
      "tldr_zh": "本研究探讨了深度学习在学习通用表示时的资源消耗问题，并引入 Hyperdimensional Computing (HDC) 作为一种计算和数据高效的脑启发替代方案，以桥接连接主义和符号主义人工智能方法。针对 HDC 在编码复杂组合结构时存在的绑定操作挑战，作者提出 Generalized Holographic Reduced Representations (GHRR)，这是对 Fourier Holographic Reduced Representations (FHRR) 的扩展，引入灵活的非交换绑定操作，同时保持 HDC 的鲁棒性和透明性。通过理论证明和实证实验，GHRR 展示了更高的解码准确性、增强的记忆容量以及对复杂数据结构的更好处理能力。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.SC"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.09689v1",
      "published_date": "2024-05-15 20:37:48 UTC",
      "updated_date": "2024-05-15 20:37:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:35:21.348792"
    },
    {
      "arxiv_id": "2405.10986v1",
      "title": "Benchmark Early and Red Team Often: A Framework for Assessing and Managing Dual-Use Hazards of AI Foundation Models",
      "title_zh": "翻译失败",
      "authors": [
        "Anthony M. Barrett",
        "Krystal Jackson",
        "Evan R. Murphy",
        "Nada Madkour",
        "Jessica Newman"
      ],
      "abstract": "A concern about cutting-edge or \"frontier\" AI foundation models is that an\nadversary may use the models for preparing chemical, biological, radiological,\nnuclear, (CBRN), cyber, or other attacks. At least two methods can identify\nfoundation models with potential dual-use capability; each has advantages and\ndisadvantages: A. Open benchmarks (based on openly available questions and\nanswers), which are low-cost but accuracy-limited by the need to omit\nsecurity-sensitive details; and B. Closed red team evaluations (based on\nprivate evaluation by CBRN and cyber experts), which are higher-cost but can\nachieve higher accuracy by incorporating sensitive details. We propose a\nresearch and risk-management approach using a combination of methods including\nboth open benchmarks and closed red team evaluations, in a way that leverages\nadvantages of both methods. We recommend that one or more groups of researchers\nwith sufficient resources and access to a range of near-frontier and frontier\nfoundation models run a set of foundation models through dual-use capability\nevaluation benchmarks and red team evaluations, then analyze the resulting sets\nof models' scores on benchmark and red team evaluations to see how correlated\nthose are. If, as we expect, there is substantial correlation between the\ndual-use potential benchmark scores and the red team evaluation scores, then\nimplications include the following: The open benchmarks should be used\nfrequently during foundation model development as a quick, low-cost measure of\na model's dual-use potential; and if a particular model gets a high score on\nthe dual-use potential benchmark, then more in-depth red team assessments of\nthat model's dual-use capability should be performed. We also discuss\nlimitations and mitigations for our approach, e.g., if model developers try to\ngame benchmarks by including a version of benchmark test data in a model's\ntraining data.",
      "tldr_zh": "该论文提出了一种框架，用于评估和管理AI基础模型（AI foundation models）的双重用途风险，特别是潜在用于化学、生物、放射性、核（CBRN）、网络或其他攻击的危害。该框架结合了低成本的公开基准（open benchmarks）和高准确性的封闭红队评估（closed red team evaluations），建议通过运行多种模型的评估来分析二者相关性。如果相关性强，则推荐在模型开发过程中早期使用公开基准作为快速筛查工具，并在基准得分高的模型上进行深入红队评估。该方法有助于降低风险，但需注意可能的局限性，如模型开发者试图通过训练数据作弊基准。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CY",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "62 pages",
      "pdf_url": "http://arxiv.org/pdf/2405.10986v1",
      "published_date": "2024-05-15 20:28:15 UTC",
      "updated_date": "2024-05-15 20:28:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:35:33.823922"
    },
    {
      "arxiv_id": "2405.09688v4",
      "title": "A Theory of Synaptic Neural Balance: From Local to Global Order",
      "title_zh": "翻译失败",
      "authors": [
        "Pierre Baldi",
        "Antonios Alexos",
        "Ian Domingo",
        "Alireza Rahmansetayesh"
      ],
      "abstract": "We develop a general theory of synaptic neural balance and how it can emerge\nor be enforced in neural networks. For a given regularizer, a neuron is said to\nbe in balance if the total cost of its input weights is equal to the total cost\nof its output weights. The basic example is provided by feedforward networks of\nReLU units trained with $L_2$ regularizers, which exhibit balance after proper\ntraining. The theory explains this phenomenon and extends it in several\ndirections. The first direction is the extension to bilinear and other\nactivation functions. The second direction is the extension to more general\nregularizers, including all $L_p$ regularizers. The third direction is the\nextension to non-layered architectures, recurrent architectures, convolutional\narchitectures, as well as architectures with mixed activation functions.\nGradient descent on the error function alone does not converge in general to a\nbalanced state, where every neuron is in balance, even when starting from a\nbalanced state. However, gradient descent on the regularized error function\nought to converge to a balanced state, and thus network balance can be used to\nassess learning progress. The theory is based on two local neuronal operations:\nscaling which is commutative, and balancing which is not commutative. Given any\ninitial set of weights, when local balancing operations are applied to each\nneuron in a stochastic manner, global order always emerges through the\nconvergence of the stochastic balancing algorithm to the same unique set of\nbalanced weights. The reason for this is the existence of an underlying\nstrictly convex optimization problem where the relevant variables are\nconstrained to a linear, only architecture-dependent, manifold. Simulations\nshow that balancing neurons prior to learning, or during learning in\nalternation with gradient descent steps, can improve learning speed and final\nperformance.",
      "tldr_zh": "这篇论文提出了一种关于突触神经平衡(Synaptic Neural Balance)的通用理论，定义为神经元的输入权重总成本等于输出权重总成本，并解释了这种平衡如何在神经网络中出现或被强制，例如在ReLU单位和L2 regularizers训练的网络中。理论扩展到双线性激活函数、各种L_p regularizers、非层级架构、循环架构和卷积架构等，并通过scaling和balancing局部操作来实现全局秩序。模拟结果显示，在学习过程中交替应用平衡操作与gradient descent步骤，能改善学习速度和最终性能。",
      "categories": [
        "cs.NE",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.NE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.09688v4",
      "published_date": "2024-05-15 20:27:56 UTC",
      "updated_date": "2024-10-31 02:01:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:35:46.238601"
    },
    {
      "arxiv_id": "2407.04712v1",
      "title": "Sensing technologies and machine learning methods for emotion recognition in autism: Systematic review",
      "title_zh": "自闭症情绪识别的传感技术和机器学习方法：系统综述",
      "authors": [
        "Oresti Banos",
        "Zhoe Comas-González",
        "Javier Medina",
        "Aurora Polo-Rodríguez",
        "David Gil",
        "Jesús Peral",
        "Sandra Amador",
        "Claudia Villalonga"
      ],
      "abstract": "Background: Human Emotion Recognition (HER) has been a popular field of study\nin the past years. Despite the great progresses made so far, relatively little\nattention has been paid to the use of HER in autism. People with autism are\nknown to face problems with daily social communication and the prototypical\ninterpretation of emotional responses, which are most frequently exerted via\nfacial expressions. This poses significant practical challenges to the\napplication of regular HER systems, which are normally developed for and by\nneurotypical people. Objective: This study reviews the literature on the use of\nHER systems in autism, particularly with respect to sensing technologies and\nmachine learning methods, as to identify existing barriers and possible future\ndirections. Methods: We conducted a systematic review of articles published\nbetween January 2011 and June 2023 according to the 2020 PRISMA guidelines.\nManuscripts were identified through searching Web of Science and Scopus\ndatabases. Manuscripts were included when related to emotion recognition, used\nsensors and machine learning techniques, and involved children with autism,\nyoung, or adults. Results: The search yielded 346 articles. A total of 65\npublications met the eligibility criteria and were included in the review.\nConclusions: Studies predominantly used facial expression techniques as the\nemotion recognition method. Consequently, video cameras were the most widely\nused devices across studies, although a growing trend in the use of\nphysiological sensors was observed lately. Happiness, sadness, anger, fear,\ndisgust, and surprise were most frequently addressed. Classical supervised\nmachine learning techniques were primarily used at the expense of unsupervised\napproaches or more recent deep learning models.",
      "tldr_zh": "本研究通过系统审阅探讨了在自闭症中应用 Human Emotion Recognition (HER) 的 sensing technologies 和 machine learning methods，旨在识别现有障碍并提出未来方向。研究根据 2020 PRISMA 指南，从 Web of Science 和 Scopus 数据库中筛选了 2011-2023 年间 346 篇文章，最终纳入 65 篇相关文献，主要关注面部表情技术、传感器和机器学习技术。结果显示，视频摄像头是最常用设备，生理传感器使用呈上升趋势，而常见情绪如 happiness、sadness、anger、fear、disgust 和 surprise 主要通过经典监督 machine learning 方法进行识别。该审阅强调了针对自闭症人群开发更具包容性的 HER 系统的重要性，以提升情感解读的准确性和实用性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "21 pages, 9 figures",
      "pdf_url": "http://arxiv.org/pdf/2407.04712v1",
      "published_date": "2024-05-15 19:48:04 UTC",
      "updated_date": "2024-05-15 19:48:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:36:00.015604"
    },
    {
      "arxiv_id": "2405.09679v2",
      "title": "Simulating Policy Impacts: Developing a Generative Scenario Writing Method to Evaluate the Perceived Effects of Regulation",
      "title_zh": "翻译失败",
      "authors": [
        "Julia Barnett",
        "Kimon Kieslich",
        "Nicholas Diakopoulos"
      ],
      "abstract": "The rapid advancement of AI technologies yields numerous future impacts on\nindividuals and society. Policymakers are tasked to react quickly and establish\npolicies that mitigate those impacts. However, anticipating the effectiveness\nof policies is a difficult task, as some impacts might only be observable in\nthe future and respective policies might not be applicable to the future\ndevelopment of AI. In this work we develop a method for using large language\nmodels (LLMs) to evaluate the efficacy of a given piece of policy at mitigating\nspecified negative impacts. We do so by using GPT-4 to generate scenarios both\npre- and post-introduction of policy and translating these vivid stories into\nmetrics based on human perceptions of impacts. We leverage an already\nestablished taxonomy of impacts of generative AI in the media environment to\ngenerate a set of scenario pairs both mitigated and non-mitigated by the\ntransparency policy in Article 50 of the EU AI Act. We then run a user study\n(n=234) to evaluate these scenarios across four risk-assessment dimensions:\nseverity, plausibility, magnitude, and specificity to vulnerable populations.\nWe find that this transparency legislation is perceived to be effective at\nmitigating harms in areas such as labor and well-being, but largely ineffective\nin areas such as social cohesion and security. Through this case study we\ndemonstrate the efficacy of our method as a tool to iterate on the\neffectiveness of policy for mitigating various negative impacts. We expect this\nmethod to be useful to researchers or other stakeholders who want to brainstorm\nthe potential utility of different pieces of policy or other mitigation\nstrategies.",
      "tldr_zh": "该研究开发了一种生成式场景写作方法，使用大型语言模型 (LLMs) 如 GPT-4 来模拟和评估政策对负面 AI 影响的缓解效果。方法包括生成政策引入前后场景，并基于人类感知转化为指标，包括 severity（严重性）、plausibility（合理性）、magnitude（规模）和 specificity to vulnerable populations（对易受损人群的特定性）。通过针对欧盟 AI 法案第 50 条透明度政策的用户研究（n=234），发现该政策在劳动和福祉领域有效，但在社会凝聚力和安全领域无效。该方法为研究人员和利益相关者提供了一个工具，用于迭代优化政策策略。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "To be published in the proceedings of the Seventh AAAI/ACM Conference\n  on AI, Ethics, and Society",
      "pdf_url": "http://arxiv.org/pdf/2405.09679v2",
      "published_date": "2024-05-15 19:44:54 UTC",
      "updated_date": "2024-07-26 21:23:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:36:11.411674"
    },
    {
      "arxiv_id": "2405.09673v2",
      "title": "LoRA Learns Less and Forgets Less",
      "title_zh": "翻译失败",
      "authors": [
        "Dan Biderman",
        "Jacob Portes",
        "Jose Javier Gonzalez Ortiz",
        "Mansheej Paul",
        "Philip Greengard",
        "Connor Jennings",
        "Daniel King",
        "Sam Havens",
        "Vitaliy Chiley",
        "Jonathan Frankle",
        "Cody Blakeney",
        "John P. Cunningham"
      ],
      "abstract": "Low-Rank Adaptation (LoRA) is a widely-used parameter-efficient finetuning\nmethod for large language models. LoRA saves memory by training only low rank\nperturbations to selected weight matrices. In this work, we compare the\nperformance of LoRA and full finetuning on two target domains, programming and\nmathematics. We consider both the instruction finetuning (approximately 100K\nprompt-response pairs) and continued pretraining (20B unstructured tokens) data\nregimes. Our results show that, in the standard low-rank settings, LoRA\nsubstantially underperforms full finetuning. Nevertheless, LoRA better\nmaintains the base model's performance on tasks outside the target domain. We\nshow that LoRA mitigates forgetting more than common regularization techniques\nsuch as weight decay and dropout; it also helps maintain more diverse\ngenerations. Finally, we show that full finetuning learns perturbations with a\nrank that is 10-100X greater than typical LoRA configurations, possibly\nexplaining some of the reported gaps. We conclude by proposing best practices\nfor finetuning with LoRA.",
      "tldr_zh": "本研究比较了 Low-Rank Adaptation (LoRA) 与全量微调 (full finetuning) 在大型语言模型上的性能，聚焦于编程和数学领域，包括指令微调 (instruction finetuning) 和继续预训练 (continued pretraining) 场景。结果显示，在标准低秩设置下，LoRA 的表现显著低于全量微调，但 LoRA 更有效地缓解了模型遗忘，并比权重衰减 (weight decay) 和 dropout 等正则化技术更好地维持生成内容的多样性。全量微调学到的扰动秩比典型 LoRA 配置高 10-100 倍，论文据此提出了 LoRA 的最佳实践建议。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "Final version with new experiments and analyses, as accepted to\n  Transactions on Machine Learning Research, August 2024 (Featured\n  Certification). https://openreview.net/forum?id=aloEru2qCG&noteId=Jb3PQNQDI2",
      "pdf_url": "http://arxiv.org/pdf/2405.09673v2",
      "published_date": "2024-05-15 19:27:45 UTC",
      "updated_date": "2024-09-20 21:21:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:36:24.106834"
    },
    {
      "arxiv_id": "2405.09657v1",
      "title": "Detecting Continuous Integration Skip : A Reinforcement Learning-based Approach",
      "title_zh": "翻译失败",
      "authors": [
        "Hajer Mhalla",
        "Mohamed Aymen Saied"
      ],
      "abstract": "The software industry is experiencing a surge in the adoption of Continuous\nIntegration (CI) practices, both in commercial and open-source environments. CI\npractices facilitate the seamless integration of code changes by employing\nautomated building and testing processes. Some frameworks, such as Travis CI\nand GitHub Actions have significantly contributed to simplifying and enhancing\nthe CI process, rendering it more accessible and efficient for development\nteams. Despite the availability these CI tools , developers continue to\nencounter difficulties in accurately flagging commits as either suitable for CI\nexecution or as candidates for skipping especially for large projects with many\ndependencies. Inaccurate flagging of commits can lead to resource-intensive\ntest and build processes, as even minor commits may inadvertently trigger the\nContinuous Integration process. The problem of detecting CI-skip commits, can\nbe modeled as binary classification task where we decide to either build a\ncommit or to skip it. This study proposes a novel solution that leverages Deep\nReinforcement Learning techniques to construct an optimal Decision Tree\nclassifier that addresses the imbalanced nature of the data. We evaluate our\nsolution by running a within and a cross project validation benchmark on\ndiverse range of Open-Source projects hosted on GitHub which showcased superior\nresults when compared with existing state-of-the-art methods.",
      "tldr_zh": "本研究针对 Continuous Integration (CI) 实践中开发人员难以准确标记提交是否跳过的挑战，提出了一种基于 Deep Reinforcement Learning 的新颖方法。方法将 CI-skip 检测建模为二元分类任务，并使用深度强化学习技术构建最优 Decision Tree 分类器，以处理数据不平衡问题。在 GitHub 开源项目上进行的内部和跨项目验证显示，该方法比现有最先进方法表现出色，证明了其有效性。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.09657v1",
      "published_date": "2024-05-15 18:48:57 UTC",
      "updated_date": "2024-05-15 18:48:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:36:32.914000"
    },
    {
      "arxiv_id": "2405.09528v1",
      "title": "Energy-Efficient Sleep Mode Optimization of 5G mmWave Networks Using Deep Contextual MAB",
      "title_zh": "翻译失败",
      "authors": [
        "Saad Masrur",
        "Ismail Guvenc",
        "David Lopez-Perez"
      ],
      "abstract": "Millimeter-wave (mmWave) networks, integral to 5G communication, offer a vast\nspectrum that addresses the issue of spectrum scarcity and enhances peak rate\nand capacity. However, their dense deployment, necessary to counteract\npropagation losses, leads to high power consumption. An effective strategy to\nreduce this energy consumption in mobile networks is the sleep mode\noptimization (SMO) of base stations (BSs). In this paper, we propose a novel\nSMO approach for mmWave BSs in a 3D urban environment. This approach, which\nincorporates a neural network (NN) based contextual multi-armed bandit (C-MAB)\nwith an epsilon decay algorithm, accommodates the dynamic and diverse traffic\nof user equipment (UE) by clustering the UEs in their respective tracking areas\n(TAs). Our strategy includes beamforming, which helps reduce energy consumption\nfrom the UE side, while SMO minimizes energy use from the BS perspective. We\nextended our investigation to include Random, Epsilon Greedy, Upper Confidence\nBound (UCB), and Load Based sleep mode (SM) strategies. We compared the\nperformance of our proposed C-MAB based SM algorithm with those of All On and\nother alternative approaches. Simulation results show that our proposed method\noutperforms all other SM strategies in terms of the $10^{th}$ percentile of\nuser rate and average throughput while demonstrating comparable average\nthroughput to the All On approach. Importantly, it outperforms all approaches\nin terms of energy efficiency (EE).",
      "tldr_zh": "这篇论文针对5G mmWave网络的密集部署导致的高功耗问题，提出了一种基于神经网络（NN）的上下文多臂赌博机（C-MAB）算法，结合epsilon衰减算法、用户设备（UE）聚类和波束成形（beamforming），在3D城市环境中优化基站（BSs）的睡眠模式（SMO）。该方法通过动态处理UE流量，实现BS能耗最小化，同时保持高效的网络性能。模拟结果显示，与Random、Epsilon Greedy、UCB和Load Based等策略相比，该算法在用户速率的10th percentile、平均吞吐量和能量效率（EE）上表现出色，尤其在EE方面显著优于其他方法。",
      "categories": [
        "eess.SP",
        "cs.AI"
      ],
      "primary_category": "eess.SP",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.09528v1",
      "published_date": "2024-05-15 17:37:28 UTC",
      "updated_date": "2024-05-15 17:37:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:36:47.687724"
    },
    {
      "arxiv_id": "2405.09521v3",
      "title": "Declarative Design of Neural Predicates in Neuro-Symbolic Systems",
      "title_zh": "翻译失败",
      "authors": [
        "Tilman Hinnerichs",
        "Robin Manhaeve",
        "Giuseppe Marra",
        "Sebastijan Dumancic"
      ],
      "abstract": "Neuro-symbolic systems (NeSy), which claim to combine the best of both\nlearning and reasoning capabilities of artificial intelligence, are missing a\ncore property of reasoning systems: Declarativeness. The lack of\ndeclarativeness is caused by the functional nature of neural predicates\ninherited from neural networks. We propose and implement a general framework\nfor fully declarative neural predicates, which hence extends to fully\ndeclarative NeSy frameworks. We first show that the declarative extension\npreserves the learning and reasoning capabilities while being able to answer\narbitrary queries while only being trained on a single query type.",
      "tldr_zh": "这篇论文指出，Neuro-symbolic systems (NeSy) 由于神经谓词(neural predicates)的功能性而缺乏声明性(declarative)，这阻碍了其推理系统的核心特性。研究者提出并实现了一个通用框架，用于构建完全声明式的神经谓词，从而扩展到全声明式的 NeSy 框架。该框架保留了学习和推理能力，仅通过训练一种查询类型即可回答任意查询。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.09521v3",
      "published_date": "2024-05-15 17:24:34 UTC",
      "updated_date": "2025-01-30 13:51:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:36:57.753956"
    },
    {
      "arxiv_id": "2405.09605v1",
      "title": "Elements of World Knowledge (EWOK): A cognition-inspired framework for evaluating basic world knowledge in language models",
      "title_zh": "世界知识元素 (EWOK)：一个受认知启发的框架，用于评估语言模型中的基本世界知识",
      "authors": [
        "Anna A. Ivanova",
        "Aalok Sathe",
        "Benjamin Lipkin",
        "Unnathi Kumar",
        "Setayesh Radkani",
        "Thomas H. Clark",
        "Carina Kauf",
        "Jennifer Hu",
        "R. T. Pramod",
        "Gabriel Grand",
        "Vivian Paulun",
        "Maria Ryskina",
        "Ekin Akyürek",
        "Ethan Wilcox",
        "Nafisa Rashid",
        "Leshem Choshen",
        "Roger Levy",
        "Evelina Fedorenko",
        "Joshua Tenenbaum",
        "Jacob Andreas"
      ],
      "abstract": "The ability to build and leverage world models is essential for a\ngeneral-purpose AI agent. Testing such capabilities is hard, in part because\nthe building blocks of world models are ill-defined. We present Elements of\nWorld Knowledge (EWOK), a framework for evaluating world modeling in language\nmodels by testing their ability to use knowledge of a concept to match a target\ntext with a plausible/implausible context. EWOK targets specific concepts from\nmultiple knowledge domains known to be vital for world modeling in humans.\nDomains range from social interactions (help/hinder) to spatial relations\n(left/right). Both, contexts and targets are minimal pairs. Objects, agents,\nand locations in the items can be flexibly filled in enabling easy generation\nof multiple controlled datasets. We then introduce EWOK-CORE-1.0, a dataset of\n4,374 items covering 11 world knowledge domains. We evaluate 20 openweights\nlarge language models (1.3B--70B parameters) across a battery of evaluation\nparadigms along with a human norming study comprising 12,480 measurements. The\noverall performance of all tested models is worse than human performance, with\nresults varying drastically across domains. These data highlight simple cases\nwhere even large models fail and present rich avenues for targeted research on\nLLM world modeling capabilities.",
      "tldr_zh": "本研究提出了一种受认知启发的框架 Elements of World Knowledge (EWOK)，用于评估语言模型的基本世界知识能力，通过测试模型利用概念知识匹配目标文本与合理/不合理上下文。EWOK 涵盖多个知识领域，如社会互动（help/hinder）和空间关系（left/right），并使用最小对（minimal pairs）设计灵活的测试项，便于生成控制数据集。研究引入了 EWOK-CORE-1.0 数据集，包含 4,374 项数据，覆盖 11 个世界知识领域，并评估了 20 个开源大语言模型（1.3B--70B 参数）。结果显示，所有模型的表现均逊于人类基准，且在不同领域差异显著，突显了模型在简单任务上的局限性，并为针对性提升语言模型的世界建模能力提供研究方向。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "21 pages (11 main), 7 figures. Authors Anna Ivanova, Aalok Sathe,\n  Benjamin Lipkin contributed equally",
      "pdf_url": "http://arxiv.org/pdf/2405.09605v1",
      "published_date": "2024-05-15 17:19:42 UTC",
      "updated_date": "2024-05-15 17:19:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:37:11.203068"
    },
    {
      "arxiv_id": "2405.09507v1",
      "title": "QueryNER: Segmentation of E-commerce Queries",
      "title_zh": "翻译失败",
      "authors": [
        "Chester Palen-Michel",
        "Lizzie Liang",
        "Zhe Wu",
        "Constantine Lignos"
      ],
      "abstract": "We present QueryNER, a manually-annotated dataset and accompanying model for\ne-commerce query segmentation. Prior work in sequence labeling for e-commerce\nhas largely addressed aspect-value extraction which focuses on extracting\nportions of a product title or query for narrowly defined aspects. Our work\ninstead focuses on the goal of dividing a query into meaningful chunks with\nbroadly applicable types. We report baseline tagging results and conduct\nexperiments comparing token and entity dropping for null and low recall query\nrecovery. Challenging test sets are created using automatic transformations and\nshow how simple data augmentation techniques can make the models more robust to\nnoise. We make the QueryNER dataset publicly available.",
      "tldr_zh": "本研究提出了 QueryNER，一个手动标注的数据集和配套模型，用于电商查询的分割（segmentation），旨在将查询分成有意义的块并赋予广泛适用的类型，与以往的 aspect-value extraction 工作不同。实验包括报告基线 tagging 结果，并比较 token dropping 和 entity dropping 方法来处理 null 和 low recall 查询恢复，同时通过数据增强技术（如自动转换）提升模型对噪声的鲁棒性。QueryNER 数据集已公开可用，这有助于改进电商查询处理的应用。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to LREC-COLING 2024",
      "pdf_url": "http://arxiv.org/pdf/2405.09507v1",
      "published_date": "2024-05-15 16:58:35 UTC",
      "updated_date": "2024-05-15 16:58:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:37:23.164497"
    },
    {
      "arxiv_id": "2405.09496v1",
      "title": "ParaNames 1.0: Creating an Entity Name Corpus for 400+ Languages using Wikidata",
      "title_zh": "ParaNames 1.0：使用 Wikidata 为 400+ 语言创建实体名称语料库",
      "authors": [
        "Jonne Sälevä",
        "Constantine Lignos"
      ],
      "abstract": "We introduce ParaNames, a massively multilingual parallel name resource\nconsisting of 140 million names spanning over 400 languages. Names are provided\nfor 16.8 million entities, and each entity is mapped from a complex type\nhierarchy to a standard type (PER/LOC/ORG). Using Wikidata as a source, we\ncreate the largest resource of this type to date. We describe our approach to\nfiltering and standardizing the data to provide the best quality possible.\nParaNames is useful for multilingual language processing, both in defining\ntasks for name translation/transliteration and as supplementary data for tasks\nsuch as named entity recognition and linking. We demonstrate the usefulness of\nParaNames on two tasks. First, we perform canonical name translation between\nEnglish and 17 other languages. Second, we use it as a gazetteer for\nmultilingual named entity recognition, obtaining performance improvements on\nall 10 languages evaluated.",
      "tldr_zh": "本研究介绍了 ParaNames 1.0，这是一个覆盖 400 多种语言的巨量多语言平行名称资源，包含 1.4 亿个名称，并为 1680 万个实体提供了 PER/LOC/ORG 等标准类型映射。研究团队使用 Wikidata 作为数据来源，通过过滤和标准化方法确保了资源的高质量。该资源可应用于多语言处理任务，如名称翻译和命名实体识别(named entity recognition)，并在实验中展示了其实用性：在英语与其他 17 种语言的规范名称翻译中表现突出，并在 10 种语言的 multilingual named entity recognition 中提升了性能。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to LREC-COLING 2024. arXiv admin note: text overlap with\n  arXiv:2202.14035",
      "pdf_url": "http://arxiv.org/pdf/2405.09496v1",
      "published_date": "2024-05-15 16:44:54 UTC",
      "updated_date": "2024-05-15 16:44:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:37:35.385874"
    },
    {
      "arxiv_id": "2405.09477v1",
      "title": "Harmonizing Human Insights and AI Precision: Hand in Hand for Advancing Knowledge Graph Task",
      "title_zh": "翻译失败",
      "authors": [
        "Shurong Wang",
        "Yufei Zhang",
        "Xuliang Huang",
        "Hongwei Wang"
      ],
      "abstract": "Knowledge graph embedding (KGE) has caught significant interest for its\neffectiveness in knowledge graph completion (KGC), specifically link prediction\n(LP), with recent KGE models cracking the LP benchmarks. Despite the rapidly\ngrowing literature, insufficient attention has been paid to the cooperation\nbetween humans and AI on KG. However, humans' capability to analyze graphs\nconceptually may further improve the efficacy of KGE models with semantic\ninformation. To this effect, we carefully designed a human-AI team (HAIT)\nsystem dubbed KG-HAIT, which harnesses the human insights on KG by leveraging\nfully human-designed ad-hoc dynamic programming (DP) on KG to produce human\ninsightful feature (HIF) vectors that capture the subgraph structural feature\nand semantic similarities. By integrating HIF vectors into the training of KGE\nmodels, notable improvements are observed across various benchmarks and\nmetrics, accompanied by accelerated model convergence. Our results underscore\nthe effectiveness of human-designed DP in the task of LP, emphasizing the\npivotal role of collaboration between humans and AI on KG. We open avenues for\nfurther exploration and innovation through KG-HAIT, paving the way towards more\neffective and insightful KG analysis techniques.",
      "tldr_zh": "本研究探讨了知识图谱嵌入 (KGE) 在链接预测 (LP) 任务中的应用，并强调了人类洞见与 AI 精确性的合作。论文提出 KG-HAIT 系统，通过人类设计的 ad-hoc 动态规划 (DP) 生成人类洞见特征 (HIF) 向量，这些向量捕捉子图结构特征和语义相似性，并将其整合到 KGE 模型训练中。实验结果显示，该方法在各种基准和指标上实现了显著性能提升，同时加速了模型收敛。总之，KG-HAIT 突出了人类-AI 团队在知识图谱 (KG) 分析中的关键作用，为未来创新提供了新路径。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.09477v1",
      "published_date": "2024-05-15 16:16:37 UTC",
      "updated_date": "2024-05-15 16:16:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:37:49.015273"
    },
    {
      "arxiv_id": "2405.09459v2",
      "title": "Fourier Boundary Features Network with Wider Catchers for Glass Segmentation",
      "title_zh": "翻译失败",
      "authors": [
        "Xiaolin Qin",
        "Jiacen Liu",
        "Qianlei Wang",
        "Shaolin Zhang",
        "Fei Zhu",
        "Zhang Yi"
      ],
      "abstract": "Glass largely blurs the boundary between the real world and the reflection.\nThe special transmittance and reflectance quality have confused the semantic\ntasks related to machine vision. Therefore, how to clear the boundary built by\nglass, and avoid over-capturing features as false positive information in deep\nstructure, matters for constraining the segmentation of reflection surface and\npenetrating glass. We proposed the Fourier Boundary Features Network with Wider\nCatchers (FBWC), which might be the first attempt to utilize sufficiently wide\nhorizontal shallow branches without vertical deepening for guiding the fine\ngranularity segmentation boundary through primary glass semantic information.\nSpecifically, we designed the Wider Coarse-Catchers (WCC) for anchoring large\narea segmentation and reducing excessive extraction from a structural\nperspective. We embed fine-grained features by Cross Transpose Attention (CTA),\nwhich is introduced to avoid the incomplete area within the boundary caused by\nreflection noise. For excavating glass features and balancing high-low layers\ncontext, a learnable Fourier Convolution Controller (FCC) is proposed to\nregulate information integration robustly. The proposed method has been\nvalidated on three different public glass segmentation datasets. Experimental\nresults reveal that the proposed method yields better segmentation performance\ncompared with the state-of-the-art (SOTA) methods in glass image segmentation.",
      "tldr_zh": "本论文针对玻璃的透过性和反射性导致的机器视觉边界模糊问题，提出了一种Fourier Boundary Features Network with Wider Catchers (FBWC)框架，这是首次利用宽水平浅层分支来指导细粒度玻璃分割。框架的关键组件包括Wider Coarse-Catchers (WCC)用于锚定大面积分割并减少过度提取、Cross Transpose Attention (CTA)来嵌入细粒度特征并避免反射噪声引起的边界不完整，以及learnable Fourier Convolution Controller (FCC)来挖掘玻璃特征并平衡高低层上下文。实验在三个公共玻璃分割数据集上验证，FBWC 的分割性能优于现有最先进 (SOTA) 方法。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.09459v2",
      "published_date": "2024-05-15 15:52:27 UTC",
      "updated_date": "2024-12-05 05:37:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:38:00.628088"
    },
    {
      "arxiv_id": "2405.09444v1",
      "title": "Desk-AId: Humanitarian Aid Desk Assessment with Geospatial AI for Predicting Landmine Areas",
      "title_zh": "翻译失败",
      "authors": [
        "Flavio Cirillo",
        "Gürkan Solmaz",
        "Yi-Hsuan Peng",
        "Christian Bizer",
        "Martin Jebens"
      ],
      "abstract": "The process of clearing areas, namely demining, starts by assessing and\nprioritizing potential hazardous areas (i.e., desk assessment) to go under\nthorough investigation of experts, who confirm the risk and proceed with the\nmines clearance operations. This paper presents Desk-AId that supports the desk\nassessment phase by estimating landmine risks using geospatial data and\nsocioeconomic information. Desk-AId uses a Geospatial AI approach specialized\nto landmines. The approach includes mixed data sampling strategies and\ncontext-enrichment by historical conflicts and key multi-domain facilities\n(e.g., buildings, roads, health sites). The proposed system addresses the issue\nof having only ground-truth for confirmed hazardous areas by implementing a new\nhard-negative data sampling strategy, where negative points are sampled in the\nvicinity of hazardous areas. Experiments validate Desk-Aid in two domains for\nlandmine risk assessment: 1) country-wide, and 2) uncharted study areas). The\nproposed approach increases the estimation accuracies up to 92%, for different\nclassification models such as RandomForest (RF), Feedforward Neural Networks\n(FNN), and Graph Neural Networks (GNN).",
      "tldr_zh": "本研究提出Desk-AId系统，利用Geospatial AI技术结合地理空间数据和socioeconomic信息，对潜在地雷风险区域进行评估和优先排序，以支持人道主义援助中的desk assessment阶段。系统采用混合数据采样策略和上下文丰富方法，包括历史冲突数据以及关键设施（如建筑、道路、健康站点），并通过新的hard-negative数据采样策略在危险区域附近生成负样本，以解决ground-truth数据有限的问题。实验在两个领域（全国范围和未勘探区域）中验证了该系统，使用RandomForest (RF)、Feedforward Neural Networks (FNN)和Graph Neural Networks (GNN)等模型，准确率最高达到92%。这项工作为高效的地雷风险评估提供了可扩展的工具。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.09444v1",
      "published_date": "2024-05-15 15:39:35 UTC",
      "updated_date": "2024-05-15 15:39:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:38:11.905617"
    },
    {
      "arxiv_id": "2405.09439v1",
      "title": "Facilitating Opinion Diversity through Hybrid NLP Approaches",
      "title_zh": "通过混合 NLP",
      "authors": [
        "Michiel van der Meer"
      ],
      "abstract": "Modern democracies face a critical issue of declining citizen participation\nin decision-making. Online discussion forums are an important avenue for\nenhancing citizen participation. This thesis proposal 1) identifies the\nchallenges involved in facilitating large-scale online discussions with Natural\nLanguage Processing (NLP), 2) suggests solutions to these challenges by\nincorporating hybrid human-AI technologies, and 3) investigates what these\ntechnologies can reveal about individual perspectives in online discussions. We\npropose a three-layered hierarchy for representing perspectives that can be\nobtained by a mixture of human intelligence and large language models. We\nillustrate how these representations can draw insights into the diversity of\nperspectives and allow us to investigate interactions in online discussions.",
      "tldr_zh": "这篇论文探讨了现代民主中公民参与决策下降的问题，并提出通过混合人类-AI 技术来促进在线讨论论坛中的意见多样性。论文识别了使用 Natural Language Processing (NLP) 进行大规模在线讨论的挑战，并建议解决方案，包括整合人类智能和大型语言模型。最终，它提出一个三层层次结构来表示观点，从而揭示在线讨论中的个体视角多样性和互动模式，为提升公民参与提供新洞见。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted at NAACL 2024, Student Research Workshop",
      "pdf_url": "http://arxiv.org/pdf/2405.09439v1",
      "published_date": "2024-05-15 15:30:17 UTC",
      "updated_date": "2024-05-15 15:30:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:38:25.483910"
    },
    {
      "arxiv_id": "2405.09602v1",
      "title": "Improving Label Error Detection and Elimination with Uncertainty Quantification",
      "title_zh": "通过不确定性量化改进标签错误检测和消除",
      "authors": [
        "Johannes Jakubik",
        "Michael Vössing",
        "Manil Maskey",
        "Christopher Wölfle",
        "Gerhard Satzger"
      ],
      "abstract": "Identifying and handling label errors can significantly enhance the accuracy\nof supervised machine learning models. Recent approaches for identifying label\nerrors demonstrate that a low self-confidence of models with respect to a\ncertain label represents a good indicator of an erroneous label. However,\nlatest work has built on softmax probabilities to measure self-confidence. In\nthis paper, we argue that -- as softmax probabilities do not reflect a model's\npredictive uncertainty accurately -- label error detection requires more\nsophisticated measures of model uncertainty. Therefore, we develop a range of\nnovel, model-agnostic algorithms for Uncertainty Quantification-Based Label\nError Detection (UQ-LED), which combine the techniques of confident learning\n(CL), Monte Carlo Dropout (MCD), model uncertainty measures (e.g., entropy),\nand ensemble learning to enhance label error detection. We comprehensively\nevaluate our algorithms on four image classification benchmark datasets in two\nstages. In the first stage, we demonstrate that our UQ-LED algorithms\noutperform state-of-the-art confident learning in identifying label errors. In\nthe second stage, we show that removing all identified errors from the training\ndata based on our approach results in higher accuracies than training on all\navailable labeled data. Importantly, besides our contributions to the detection\nof label errors, we particularly propose a novel approach to generate\nrealistic, class-dependent label errors synthetically. Overall, our study\ndemonstrates that selectively cleaning datasets with UQ-LED algorithms leads to\nmore accurate classifications than using larger, noisier datasets.",
      "tldr_zh": "本研究针对监督机器学习中标签错误的检测和消除问题，指出传统方法依赖softmax概率来衡量模型自信心不够准确，因此提出Uncertainty Quantification-Based Label Error Detection (UQ-LED)算法。该算法结合confident learning (CL)、Monte Carlo Dropout (MCD)、不确定性度量（如entropy）和ensemble learning等技术，实现了模型无关的标签错误识别。在四个图像分类基准数据集上的实验显示，UQ-LED在检测标签错误方面优于现有方法，且移除错误标签后，模型准确率显著提升。此外，研究还引入了一种生成真实类依赖标签错误的方法，证明选择性清理数据集能比使用更大噪声数据集获得更精确的分类结果。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Under single blinded review",
      "pdf_url": "http://arxiv.org/pdf/2405.09602v1",
      "published_date": "2024-05-15 15:17:52 UTC",
      "updated_date": "2024-05-15 15:17:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:38:36.790021"
    },
    {
      "arxiv_id": "2405.09415v3",
      "title": "On the Correspondence of Non-flat Assumption-based Argumentation and Logic Programming with Negation as Failure in the Head",
      "title_zh": "翻译失败",
      "authors": [
        "Anna Rapberger",
        "Markus Ulbricht",
        "Francesca Toni"
      ],
      "abstract": "The relation between (a fragment of) assumption-based argumentation (ABA) and\nlogic programs (LPs) under stable model semantics is well-studied. However, for\nobtaining this relation, the ABA framework needs to be restricted to being\nflat, i.e., a fragment where the (defeasible) assumptions can never be\nentailed, only assumed to be true or false. Here, we remove this restriction\nand show a correspondence between non-flat ABA and LPs with negation as failure\nin their head. We then extend this result to so-called set-stable ABA\nsemantics, originally defined for the fragment of non-flat ABA called bipolar\nABA. We showcase how to define set-stable semantics for LPs with negation as\nfailure in their head and show the correspondence to set-stable ABA semantics.",
      "tldr_zh": "本文研究了 non-flat assumption-based argumentation (ABA) 与 logic programming (LPs) with negation as failure in the head 之间的对应关系，扩展了传统框架中对 flat ABA 的限制。研究首先证明了 non-flat ABA 可以与这种 LPs 相对应，然后将其扩展到 set-stable ABA semantics（原本定义于 bipolar ABA）。最后，作者为 LPs with negation as failure in the head 定义了 set-stable semantics，并展示了其与 set-stable ABA semantics 的对应关系，从而为论证理论和逻辑编程的整合提供了新见解。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.09415v3",
      "published_date": "2024-05-15 15:10:03 UTC",
      "updated_date": "2024-08-13 15:32:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:38:48.967943"
    },
    {
      "arxiv_id": "2405.13024v1",
      "title": "Intelligent Tutor: Leveraging ChatGPT and Microsoft Copilot Studio to Deliver a Generative AI Student Support and Feedback System within Teams",
      "title_zh": "翻译失败",
      "authors": [
        "Wei-Yu Chen"
      ],
      "abstract": "This study explores the integration of the ChatGPT API with GPT-4 model and\nMicrosoft Copilot Studio on the Microsoft Teams platform to develop an\nintelligent tutoring system. Designed to provide instant support to students,\nthe system dynamically adjusts educational content in response to the learners'\nprogress and feedback. Utilizing advancements in natural language processing\nand machine learning, it interprets student inquiries, offers tailored\nfeedback, and facilitates the educational journey. Initial implementation\nhighlights the system's potential in boosting students' motivation and\nengagement, while equipping educators with critical insights into the learning\nprocess, thus promoting tailored educational experiences and enhancing\ninstructional effectiveness.",
      "tldr_zh": "这项研究开发了一个名为 Intelligent Tutor 的智能辅导系统，通过整合 ChatGPT API 和 GPT-4 模型与 Microsoft Copilot Studio，在 Microsoft Teams 平台上提供生成式 AI 支持。系统利用自然语言处理和机器学习技术，动态调整教育内容、解释学生查询并提供个性化反馈，以促进学习过程。初步实施结果表明，该系统提高了学生的动机和参与度，并为教育者提供关键学习洞见，从而提升个性化教育体验和教学效果。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.13024v1",
      "published_date": "2024-05-15 15:09:41 UTC",
      "updated_date": "2024-05-15 15:09:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:38:59.373588"
    },
    {
      "arxiv_id": "2405.09396v1",
      "title": "$O_2$ is a multiple context-free grammar: an implementation-, formalisation-friendly proof",
      "title_zh": "翻译失败",
      "authors": [
        "Marco B. Caminati"
      ],
      "abstract": "Classifying formal languages according to the expressiveness of grammars able\nto generate them is a fundamental problem in computational linguistics and,\ntherefore, in the theory of computation. Furthermore, such kind of analysis can\ngive insight into the classification of abstract algebraic structure such as\ngroups, for example through the correspondence given by the word problem. While\nmany such classification problems remain open, others have been settled.\nRecently, it was proved that $n$-balanced languages (i.e., whose strings\ncontain the same occurrences of letters $a_i$ and $A_i$ with $1\\leq i \\leq n$)\ncan be generated by multiple context-free grammars (MCFGs), which are one of\nthe several slight extensions of context free grammars added to the classical\nChomsky hierarchy to make the mentioned classification more precise. This paper\nanalyses the existing proofs from the computational and the proof-theoretical\npoint of views, systematically studying whether each proof can lead to a\nverified (i.e., checked by a proof assistant) algorithm parsing balanced\nlanguages via MCFGs. We conclude that none of the existing proofs is\nrealistically suitable against this practical goal, and proceed to provide a\nradically new, elementary, extremely short proof for the crucial case $n \\leq\n2$. A comparative analysis with respect to the existing proofs is finally\nperformed to justify why the proposed proof is a substantial step towards\nconcretely obtaining a verified parsing algorithm for $O_2$.",
      "tldr_zh": "这篇论文证明了 $O_2$ 语言（即 n-balanced 语言中 n ≤ 2 的情况）可以由 multiple context-free grammars (MCFGs) 生成，并提供了一个新颖、元素化的证明，该证明易于实现和形式化。作者首先分析了现有证明在计算和证明理论方面的局限性，指出它们不适合用于开发验证的解析算法。相比现有方法，该新证明更简短且实用，为创建可由证明助手检查的 $O_2$ 语言解析算法奠定了基础，从而推进形式语言分类和抽象代数结构研究的进展。",
      "categories": [
        "cs.FL",
        "cs.AI",
        "cs.LO",
        "math.LO"
      ],
      "primary_category": "cs.FL",
      "comment": "dlt 2024",
      "pdf_url": "http://arxiv.org/pdf/2405.09396v1",
      "published_date": "2024-05-15 14:51:11 UTC",
      "updated_date": "2024-05-15 14:51:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:39:13.000502"
    },
    {
      "arxiv_id": "2405.09395v2",
      "title": "Matching domain experts by training from scratch on domain knowledge",
      "title_zh": "翻译失败",
      "authors": [
        "Xiaoliang Luo",
        "Guangzhi Sun",
        "Bradley C. Love"
      ],
      "abstract": "Recently, large language models (LLMs) have outperformed human experts in\npredicting the results of neuroscience experiments (Luo et al., 2024). What is\nthe basis for this performance? One possibility is that statistical patterns in\nthat specific scientific literature, as opposed to emergent reasoning abilities\narising from broader training, underlie LLMs' performance. To evaluate this\npossibility, we trained (next word prediction) a relatively small\n124M-parameter GPT-2 model on 1.3 billion tokens of domain-specific knowledge.\nDespite being orders of magnitude smaller than larger LLMs trained on trillions\nof tokens, small models achieved expert-level performance in predicting\nneuroscience results. Small models trained on the neuroscience literature\nsucceeded when they were trained from scratch using a tokenizer specifically\ntrained on neuroscience text or when the neuroscience literature was used to\nfinetune a pretrained GPT-2. Our results indicate that expert-level performance\nmay be attained by even small LLMs through domain-specific, auto-regressive\ntraining approaches.",
      "tldr_zh": "本研究探讨了大型语言模型（LLMs）在预测神经科学实验结果上超越人类专家的性能基础，假设这可能源于特定科学文献的统计模式而非更广泛的推理能力。研究者训练了一个124M参数的GPT-2模型，使用1.3亿tokens的神经科学领域知识，从零开始训练或通过专门tokenizer处理，或对预训练模型进行微调。结果显示，即使是小规模LLMs，通过领域特定的自回归训练方法，也能达到专家级性能，表明这种方法可有效提升模型在专业领域的表现。",
      "categories": [
        "q-bio.NC",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "q-bio.NC",
      "comment": "ICML 2024 (Large Language Models and Cognition)",
      "pdf_url": "http://arxiv.org/pdf/2405.09395v2",
      "published_date": "2024-05-15 14:50:51 UTC",
      "updated_date": "2024-07-02 16:42:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:39:24.785001"
    },
    {
      "arxiv_id": "2405.09600v1",
      "title": "Aggregate Representation Measure for Predictive Model Reusability",
      "title_zh": "翻译失败",
      "authors": [
        "Vishwesh Sangarya",
        "Richard Bradford",
        "Jung-Eun Kim"
      ],
      "abstract": "In this paper, we propose a predictive quantifier to estimate the retraining\ncost of a trained model in distribution shifts. The proposed Aggregated\nRepresentation Measure (ARM) quantifies the change in the model's\nrepresentation from the old to new data distribution. It provides, before\nactually retraining the model, a single concise index of resources - epochs,\nenergy, and carbon emissions - required for the retraining. This enables reuse\nof a model with a much lower cost than training a new model from scratch. The\nexperimental results indicate that ARM reasonably predicts retraining costs for\nvarying noise intensities and enables comparisons among multiple model\narchitectures to determine the most cost-effective and sustainable option.",
      "tldr_zh": "本文提出了一种名为 Aggregated Representation Measure (ARM) 的预测量化器，用于估计训练模型在 distribution shifts 下的重新训练成本。ARM 通过量化模型表示从旧数据分布到新数据分布的变化，提供一个简洁指标，包括所需的 epochs、能量和碳排放，从而实现模型重用而非从零开始训练。实验结果显示，ARM 能准确预测不同噪声强度的重新训练成本，并支持比较多种模型架构，以选择最经济和可持续的选项。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV",
        "cs.CY"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.09600v1",
      "published_date": "2024-05-15 14:14:34 UTC",
      "updated_date": "2024-05-15 14:14:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:39:35.837730"
    },
    {
      "arxiv_id": "2405.09355v1",
      "title": "Vision-Based Neurosurgical Guidance: Unsupervised Localization and Camera-Pose Prediction",
      "title_zh": "基于视觉的神经外科指导：无监督定位和相机位姿预测",
      "authors": [
        "Gary Sarwin",
        "Alessandro Carretta",
        "Victor Staartjes",
        "Matteo Zoli",
        "Diego Mazzatenta",
        "Luca Regli",
        "Carlo Serra",
        "Ender Konukoglu"
      ],
      "abstract": "Localizing oneself during endoscopic procedures can be problematic due to the\nlack of distinguishable textures and landmarks, as well as difficulties due to\nthe endoscopic device such as a limited field of view and challenging lighting\nconditions. Expert knowledge shaped by years of experience is required for\nlocalization within the human body during endoscopic procedures. In this work,\nwe present a deep learning method based on anatomy recognition, that constructs\na surgical path in an unsupervised manner from surgical videos, modelling\nrelative location and variations due to different viewing angles. At inference\ntime, the model can map an unseen video's frames on the path and estimate the\nviewing angle, aiming to provide guidance, for instance, to reach a particular\ndestination. We test the method on a dataset consisting of surgical videos of\ntranssphenoidal adenomectomies, as well as on a synthetic dataset. An online\ntool that lets researchers upload their surgical videos to obtain anatomy\ndetections and the weights of the trained YOLOv7 model are available at:\nhttps://surgicalvision.bmic.ethz.ch.",
      "tldr_zh": "该论文针对内镜手术中定位困难的问题（如缺乏纹理地标和有限视野），提出了一种基于深度学习的无监督方法，通过解剖结构识别从手术视频构建手术路径，并建模相对位置和视角变化。模型在推理时能将未见视频帧映射到路径上，并预测相机姿态，提供手术指导，例如帮助到达特定目标。实验在经蝶窦腺瘤切除术数据集和合成数据集上验证了方法的有效性，并公开了YOLOv7模型权重和在线工具。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Early Accept at MICCAI 2024",
      "pdf_url": "http://arxiv.org/pdf/2405.09355v1",
      "published_date": "2024-05-15 14:09:11 UTC",
      "updated_date": "2024-05-15 14:09:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:39:48.446450"
    },
    {
      "arxiv_id": "2405.09598v1",
      "title": "Properties that allow or prohibit transferability of adversarial attacks among quantized networks",
      "title_zh": "翻译失败",
      "authors": [
        "Abhishek Shrestha",
        "Jürgen Großmann"
      ],
      "abstract": "Deep Neural Networks (DNNs) are known to be vulnerable to adversarial\nexamples. Further, these adversarial examples are found to be transferable from\nthe source network in which they are crafted to a black-box target network. As\nthe trend of using deep learning on embedded devices grows, it becomes relevant\nto study the transferability properties of adversarial examples among\ncompressed networks. In this paper, we consider quantization as a network\ncompression technique and evaluate the performance of transfer-based attacks\nwhen the source and target networks are quantized at different bitwidths. We\nexplore how algorithm specific properties affect transferability by considering\nvarious adversarial example generation algorithms. Furthermore, we examine\ntransferability in a more realistic scenario where the source and target\nnetworks may differ in bitwidth and other model-related properties like\ncapacity and architecture. We find that although quantization reduces\ntransferability, certain attack types demonstrate an ability to enhance it.\nAdditionally, the average transferability of adversarial examples among\nquantized versions of a network can be used to estimate the transferability to\nquantized target networks with varying capacity and architecture.",
      "tldr_zh": "本研究探讨了对抗攻击(adversarial attacks)在量化网络(quantized networks)间的转移性(properties that allow or prohibit transferability)，重点评估Deep Neural Networks (DNNs)中对抗样本在不同位宽(bitwidth)下从源网络向目标网络的转移性能。研究方法包括使用多种对抗样本生成算法，分析网络的位宽、容量和架构差异对转移性的影响。结果显示，量化操作降低了转移性，但某些攻击类型能增强这一效果；此外，量化网络版本间的平均转移性可用于预测到其他架构和容量目标网络的转移性，从而为提升嵌入式设备的安全性提供指导。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.09598v1",
      "published_date": "2024-05-15 14:06:28 UTC",
      "updated_date": "2024-05-15 14:06:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:40:01.241888"
    },
    {
      "arxiv_id": "2406.16895v1",
      "title": "Coronary Artery Disease Classification Using One-dimensional Convolutional Neural Network",
      "title_zh": "翻译失败",
      "authors": [
        "Atitaya Phoemsuk",
        "Vahid Abolghasemi"
      ],
      "abstract": "Coronary Artery Disease (CAD) diagnostic to be a major global cause of death,\nnecessitating innovative solutions. Addressing the critical importance of early\nCAD detection and its impact on the mortality rate, we propose the potential of\none-dimensional convolutional neural networks (1D-CNN) to enhance detection\naccuracy and reduce network complexity. This study goes beyond traditional\ndiagnostic methodologies, leveraging the remarkable ability of 1D-CNN to\ninterpret complex patterns within Electrocardiogram (ECG) signals without\ndepending on feature extraction techniques. We explore the impact of varying\nsample lengths on model performance and conduct experiments involving layers\nreduction. The ECG data employed were obtained from the PhysioNet databases,\nnamely the MIMIC III and Fantasia datasets, with respective sampling\nfrequencies of 125 Hz and 250 Hz. The highest accuracy for unseen data obtained\nwith a sample length of 250. These initial findings demonstrate the potential\nof 1D-CNNs in CAD diagnosis using ECG signals and highlight the sample size's\nrole in achieving high accuracy.",
      "tldr_zh": "本研究针对冠状动脉疾病 (Coronary Artery Disease, CAD) 作为全球主要死亡原因，提出使用一维卷积神经网络 (1D-CNN) 来提升检测准确率并简化网络复杂度。方法直接从心电图 (ECG) 信号中解读复杂模式，而非依赖传统特征提取技术，并探讨了不同样本长度和层数减少对模型性能的影响。实验基于 PhysioNet 数据库的 MIMIC III 和 Fantasia 数据集（采样频率分别为 125 Hz 和 250 Hz），在样本长度为 250 时实现了最高准确率。这些初步发现突显了 1D-CNN 在 CAD 诊断中的潜力，并强调了样本大小对准确性的关键作用。",
      "categories": [
        "eess.SP",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "eess.SP",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.16895v1",
      "published_date": "2024-05-15 13:51:02 UTC",
      "updated_date": "2024-05-15 13:51:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:40:14.021856"
    },
    {
      "arxiv_id": "2405.09597v3",
      "title": "When AI Eats Itself: On the Caveats of AI Autophagy",
      "title_zh": "翻译失败",
      "authors": [
        "Xiaodan Xing",
        "Fadong Shi",
        "Jiahao Huang",
        "Yinzhe Wu",
        "Yang Nan",
        "Sheng Zhang",
        "Yingying Fang",
        "Mike Roberts",
        "Carola-Bibiane Schönlieb",
        "Javier Del Ser",
        "Guang Yang"
      ],
      "abstract": "Generative Artificial Intelligence (AI) technologies and large models are\nproducing realistic outputs across various domains, such as images, text,\nspeech, and music. Creating these advanced generative models requires\nsignificant resources, particularly large and high-quality datasets. To\nminimise training expenses, many algorithm developers use data created by the\nmodels themselves as a cost-effective training solution. However, not all\nsynthetic data effectively improve model performance, necessitating a strategic\nbalance in the use of real versus synthetic data to optimise outcomes.\nCurrently, the previously well-controlled integration of real and synthetic\ndata is becoming uncontrollable. The widespread and unregulated dissemination\nof synthetic data online leads to the contamination of datasets traditionally\ncompiled through web scraping, now mixed with unlabeled synthetic data. This\ntrend, known as the AI autophagy phenomenon, suggests a future where generative\nAI systems may increasingly consume their own outputs without discernment,\nraising concerns about model performance, reliability, and ethical\nimplications. What will happen if generative AI continuously consumes itself\nwithout discernment? What measures can we take to mitigate the potential\nadverse effects? To address these research questions, this study examines the\nexisting literature, delving into the consequences of AI autophagy, analyzing\nthe associated risks, and exploring strategies to mitigate its impact. Our aim\nis to provide a comprehensive perspective on this phenomenon advocating for a\nbalanced approach that promotes the sustainable development of generative AI\ntechnologies in the era of large models.",
      "tldr_zh": "生成式 AI 技术在创建大型模型时，越来越多地使用合成数据来降低训练成本，但这可能导致 AI Autophagy 现象，即模型自我消耗合成数据，造成数据集污染和性能下降。论文通过审视现有文献，分析了这一现象的后果，包括模型可靠性降低和伦理问题，并探讨了风险评估策略。研究者主张平衡真实数据和合成数据的使用，以促进生成式 AI 的可持续发展和长期优化。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.09597v3",
      "published_date": "2024-05-15 13:50:23 UTC",
      "updated_date": "2024-11-08 10:51:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:40:22.469964"
    },
    {
      "arxiv_id": "2405.09341v2",
      "title": "Large Language Model Bias Mitigation from the Perspective of Knowledge Editing",
      "title_zh": "翻译失败",
      "authors": [
        "Ruizhe Chen",
        "Yichen Li",
        "Zikai Xiao",
        "Zuozhu Liu"
      ],
      "abstract": "Existing debiasing methods inevitably make unreasonable or undesired\npredictions as they are designated and evaluated to achieve parity across\ndifferent social groups but leave aside individual facts, resulting in modified\nexisting knowledge. In this paper, we first establish a new bias mitigation\nbenchmark BiasKE leveraging existing and additional constructed datasets, which\nsystematically assesses debiasing performance by complementary metrics on\nfairness, specificity, and generalization. Meanwhile, we propose a novel\ndebiasing method, Fairness Stamp (FAST), which enables editable fairness\nthrough fine-grained calibration on individual biased knowledge. Comprehensive\nexperiments demonstrate that FAST surpasses state-of-the-art baselines with\nremarkable debiasing performance while not hampering overall model capability\nfor knowledge preservation, highlighting the prospect of fine-grained debiasing\nstrategies for editable fairness in LLMs.",
      "tldr_zh": "这篇论文从知识编辑视角探讨大型语言模型(LLMs)的偏见缓解问题，指出现有去偏见(debiasing)方法在追求群体公平性时往往忽略个体事实，导致不合理的预测。作者建立了新的基准BiasKE，利用现有和新增数据集，通过公平性、具体性和泛化性指标系统评估去偏见性能。论文提出了一种创新方法Fairness Stamp (FAST)，通过对个体偏见知识进行细粒度校准，实现可编辑的公平性。实验结果表明，FAST 超过了最先进基线，在提升去偏见性能的同时，不损害模型的整体知识保留能力，并为 LLMs 的细粒度去偏见策略提供了新前景。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.09341v2",
      "published_date": "2024-05-15 13:44:13 UTC",
      "updated_date": "2024-06-29 05:50:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:40:37.112565"
    },
    {
      "arxiv_id": "2405.09596v2",
      "title": "Enhancing Maritime Trajectory Forecasting via H3 Index and Causal Language Modelling (CLM)",
      "title_zh": "通过 H3 指数和因果语言建模（CLM）增强海洋轨迹预测",
      "authors": [
        "Nicolas Drapier",
        "Aladine Chetouani",
        "Aurélien Chateigner"
      ],
      "abstract": "The prediction of ship trajectories is a growing field of study in artificial\nintelligence. Traditional methods rely on the use of LSTM, GRU networks, and\neven Transformer architectures for the prediction of spatio-temporal series.\nThis study proposes a viable alternative for predicting these trajectories\nusing only GNSS positions. It considers this spatio-temporal problem as a\nnatural language processing problem. The latitude/longitude coordinates of AIS\nmessages are transformed into cell identifiers using the H3 index. Thanks to\nthe pseudo-octal representation, it becomes easier for language models to learn\nthe spatial hierarchy of the H3 index. The method is compared with a classical\nKalman filter, widely used in the maritime domain, and introduces the Fr\\'echet\ndistance as the main evaluation metric. We show that it is possible to predict\nship trajectories quite precisely up to 8 hours ahead with 30 minutes of\ncontext, using solely GNSS positions, without relying on any additional\ninformation such as speed, course, or external conditions - unlike many\ntraditional methods. We demonstrate that this alternative works well enough to\npredict trajectories worldwide.",
      "tldr_zh": "这篇论文提出了一种增强海事轨迹预测的方法，通过 H3 Index 和 Causal Language Modelling (CLM)，将船只的时空轨迹问题转化为自然语言处理任务，仅使用 GNSS 位置数据。方法将纬度/经度坐标转换为 H3 单元标识符，利用其伪八进制表示来帮助语言模型学习空间层次结构。相比传统的 Kalman filter，该方法在 Fréchet distance 评估指标下表现出色，能基于 30 分钟上下文精确预测长达 8 小时的轨迹，且无需额外信息如速度、航向或外部条件。该方法在全球范围内证明了其有效性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ME"
      ],
      "primary_category": "cs.LG",
      "comment": "28 pages, 18 figures",
      "pdf_url": "http://arxiv.org/pdf/2405.09596v2",
      "published_date": "2024-05-15 13:43:07 UTC",
      "updated_date": "2024-11-14 18:57:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:40:49.754784"
    },
    {
      "arxiv_id": "2405.09334v2",
      "title": "Content-Based Image Retrieval for Multi-Class Volumetric Radiology Images: A Benchmark Study",
      "title_zh": "翻译失败",
      "authors": [
        "Farnaz Khun Jush",
        "Steffen Vogler",
        "Tuan Truong",
        "Matthias Lenga"
      ],
      "abstract": "While content-based image retrieval (CBIR) has been extensively studied in\nnatural image retrieval, its application to medical images presents ongoing\nchallenges, primarily due to the 3D nature of medical images. Recent studies\nhave shown the potential use of pre-trained vision embeddings for CBIR in the\ncontext of radiology image retrieval. However, a benchmark for the retrieval of\n3D volumetric medical images is still lacking, hindering the ability to\nobjectively evaluate and compare the efficiency of proposed CBIR approaches in\nmedical imaging. In this study, we extend previous work and establish a\nbenchmark for region-based and localized multi-organ retrieval using the\nTotalSegmentator dataset (TS) with detailed multi-organ annotations. We\nbenchmark embeddings derived from pre-trained supervised models on medical\nimages against embeddings derived from pre-trained unsupervised models on\nnon-medical images for 29 coarse and 104 detailed anatomical structures in\nvolume and region levels. For volumetric image retrieval, we adopt a late\ninteraction re-ranking method inspired by text matching. We compare it against\nthe original method proposed for volume and region retrieval and achieve a\nretrieval recall of 1.0 for diverse anatomical regions with a wide size range.\nThe findings and methodologies presented in this paper provide insights and\nbenchmarks for further development and evaluation of CBIR approaches in the\ncontext of medical imaging.",
      "tldr_zh": "本文针对基于内容的图像检索 (CBIR) 在 3D 体医学图像中的应用，建立了一个基准，使用 TotalSegmentator 数据集进行多器官区域和局部检索。研究比较了预训练监督模型（针对医学图像）和非监督模型（针对非医学图像）的 embeddings，并在 29 个粗略和 104 个详细解剖结构上进行评估，采用晚交互重新排序方法。结果显示，该方法在体积和区域级别实现了 1.0 的检索召回率，为 CBIR 在医学成像领域的进一步发展和评估提供了宝贵的见解和基准。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.CV",
      "comment": "34 pages, 12 Figures, 22 Tables",
      "pdf_url": "http://arxiv.org/pdf/2405.09334v2",
      "published_date": "2024-05-15 13:34:07 UTC",
      "updated_date": "2024-07-04 09:00:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:41:03.016661"
    },
    {
      "arxiv_id": "2405.09595v1",
      "title": "Simplicity within biological complexity",
      "title_zh": "生物复杂性中的简单性",
      "authors": [
        "Natasa Przulj",
        "Noel Malod-Dognin"
      ],
      "abstract": "Heterogeneous, interconnected, systems-level, molecular data have become\nincreasingly available and key in precision medicine. We need to utilize them\nto better stratify patients into risk groups, discover new biomarkers and\ntargets, repurpose known and discover new drugs to personalize medical\ntreatment. Existing methodologies are limited and a paradigm shift is needed to\nachieve quantitative and qualitative breakthroughs. In this perspective paper,\nwe survey the literature and argue for the development of a comprehensive,\ngeneral framework for embedding of multi-scale molecular network data that\nwould enable their explainable exploitation in precision medicine in linear\ntime. Network embedding methods map nodes to points in low-dimensional space,\nso that proximity in the learned space reflects the network's topology-function\nrelationships. They have recently achieved unprecedented performance on hard\nproblems of utilizing few omic data in various biomedical applications.\nHowever, research thus far has been limited to special variants of the problems\nand data, with the performance depending on the underlying topology-function\nnetwork biology hypotheses, the biomedical applications and evaluation metrics.\nThe availability of multi-omic data, modern graph embedding paradigms and\ncompute power call for a creation and training of efficient, explainable and\ncontrollable models, having no potentially dangerous, unexpected behaviour,\nthat make a qualitative breakthrough. We propose to develop a general,\ncomprehensive embedding framework for multi-omic network data, from models to\nefficient and scalable software implementation, and to apply it to biomedical\ninformatics. It will lead to a paradigm shift in computational and biomedical\nunderstanding of data and diseases that will open up ways to solving some of\nthe major bottlenecks in precision medicine and other domains.",
      "tldr_zh": "本论文讨论了异构、互联的系统级分子数据在precision medicine中的关键作用，强调需要利用这些数据来分层患者风险组、发现新生物标志物和靶点，以及重用或发现新药物以实现个性化治疗，但现有方法存在局限，需要范式转变。作者主张开发一个全面的框架，用于多尺度分子network embedding，将节点映射到低维空间以反映网络的拓扑-功能关系，从而在线性时间内实现这些数据的可解释利用。论文提出创建高效、可解释、可控的模型，应用于multi-omic data和生物医学信息学，这将带来计算与生物医学理解的重大突破，并解决precision medicine中的核心瓶颈。",
      "categories": [
        "q-bio.OT",
        "cs.AI",
        "I.2; J.3"
      ],
      "primary_category": "q-bio.OT",
      "comment": "29 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2405.09595v1",
      "published_date": "2024-05-15 13:32:45 UTC",
      "updated_date": "2024-05-15 13:32:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:41:13.530717"
    },
    {
      "arxiv_id": "2405.09321v1",
      "title": "ReconBoost: Boosting Can Achieve Modality Reconcilement",
      "title_zh": "翻译失败",
      "authors": [
        "Cong Hua",
        "Qianqian Xu",
        "Shilong Bao",
        "Zhiyong Yang",
        "Qingming Huang"
      ],
      "abstract": "This paper explores a novel multi-modal alternating learning paradigm\npursuing a reconciliation between the exploitation of uni-modal features and\nthe exploration of cross-modal interactions. This is motivated by the fact that\ncurrent paradigms of multi-modal learning tend to explore multi-modal features\nsimultaneously. The resulting gradient prohibits further exploitation of the\nfeatures in the weak modality, leading to modality competition, where the\ndominant modality overpowers the learning process. To address this issue, we\nstudy the modality-alternating learning paradigm to achieve reconcilement.\nSpecifically, we propose a new method called ReconBoost to update a fixed\nmodality each time. Herein, the learning objective is dynamically adjusted with\na reconcilement regularization against competition with the historical models.\nBy choosing a KL-based reconcilement, we show that the proposed method\nresembles Friedman's Gradient-Boosting (GB) algorithm, where the updated\nlearner can correct errors made by others and help enhance the overall\nperformance. The major difference with the classic GB is that we only preserve\nthe newest model for each modality to avoid overfitting caused by ensembling\nstrong learners. Furthermore, we propose a memory consolidation scheme and a\nglobal rectification scheme to make this strategy more effective. Experiments\nover six multi-modal benchmarks speak to the efficacy of the method. We release\nthe code at https://github.com/huacong/ReconBoost.",
      "tldr_zh": "本论文探讨了多模态学习中的模态竞争问题，即当前范式同时探索多模态特征，导致弱模态特征利用不足。为解决此问题，提出 ReconBoost 方法，通过模态交替学习范式，每次更新一个固定模态的学习目标，并引入基于 KL 散度的调节正则化，类似于 Gradient-Boosting (GB) 算法，但仅保留每个模态的最新模型以避免过拟合。进一步，方法还包括记忆巩固方案和全局修正方案，以提升整体性能。实验在六个多模态基准上验证了 ReconBoost 的有效性，并开源了代码。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "cs.MM"
      ],
      "primary_category": "cs.CV",
      "comment": "This paper has been accepted by ICML2024",
      "pdf_url": "http://arxiv.org/pdf/2405.09321v1",
      "published_date": "2024-05-15 13:22:39 UTC",
      "updated_date": "2024-05-15 13:22:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:41:25.403903"
    },
    {
      "arxiv_id": "2405.09308v1",
      "title": "TimeX++: Learning Time-Series Explanations with Information Bottleneck",
      "title_zh": "翻译失败",
      "authors": [
        "Zichuan Liu",
        "Tianchun Wang",
        "Jimeng Shi",
        "Xu Zheng",
        "Zhuomin Chen",
        "Lei Song",
        "Wenqian Dong",
        "Jayantha Obeysekera",
        "Farhad Shirani",
        "Dongsheng Luo"
      ],
      "abstract": "Explaining deep learning models operating on time series data is crucial in\nvarious applications of interest which require interpretable and transparent\ninsights from time series signals. In this work, we investigate this problem\nfrom an information theoretic perspective and show that most existing measures\nof explainability may suffer from trivial solutions and distributional shift\nissues. To address these issues, we introduce a simple yet practical objective\nfunction for time series explainable learning. The design of the objective\nfunction builds upon the principle of information bottleneck (IB), and modifies\nthe IB objective function to avoid trivial solutions and distributional shift\nissues. We further present TimeX++, a novel explanation framework that\nleverages a parametric network to produce explanation-embedded instances that\nare both in-distributed and label-preserving. We evaluate TimeX++ on both\nsynthetic and real-world datasets comparing its performance against leading\nbaselines, and validate its practical efficacy through case studies in a\nreal-world environmental application. Quantitative and qualitative evaluations\nshow that TimeX++ outperforms baselines across all datasets, demonstrating a\nsubstantial improvement in explanation quality for time series data. The source\ncode is available at \\url{https://github.com/zichuan-liu/TimeXplusplus}.",
      "tldr_zh": "该论文从信息理论视角探讨了时间序列数据上深度学习模型的解释问题，指出现有解释方法可能面临琐碎解决方案和分布偏移问题。作者引入了一个基于信息瓶颈(Information Bottleneck)原则的改进目标函数，以避免这些问题，并提出TimeX++框架，该框架利用参数网络生成分布内且标签保留的解释嵌入实例。在合成和真实数据集上的实验对比显示，TimeX++在解释质量上显著优于基线模型，并通过真实环境应用案例验证了其实际效能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by International Conference on Machine Learning (ICML 2024)",
      "pdf_url": "http://arxiv.org/pdf/2405.09308v1",
      "published_date": "2024-05-15 13:03:41 UTC",
      "updated_date": "2024-05-15 13:03:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:41:37.054346"
    },
    {
      "arxiv_id": "2407.12135v1",
      "title": "Trustworthy AI in practice: an analysis of practitioners' needs and challenges",
      "title_zh": "翻译失败",
      "authors": [
        "Maria Teresa Baldassarre",
        "Domenico Gigante",
        "Marcos Kalinowski",
        "Azzurra Ragone",
        "Sara Tibidò"
      ],
      "abstract": "Recently, there has been growing attention on behalf of both academic and\npractice communities towards the ability of Artificial Intelligence (AI)\nsystems to operate responsibly and ethically. As a result, a plethora of\nframeworks and guidelines have appeared to support practitioners in\nimplementing Trustworthy AI applications (TAI). However, little research has\nbeen done to investigate whether such frameworks are being used and how. In\nthis work, we study the vision AI practitioners have on TAI principles, how\nthey address them, and what they would like to have - in terms of tools,\nknowledge, or guidelines - when they attempt to incorporate such principles\ninto the systems they develop. Through a survey and semi-structured interviews,\nwe systematically investigated practitioners' challenges and needs in\ndeveloping TAI systems. Based on these practical findings, we highlight\nrecommendations to help AI practitioners develop Trustworthy AI applications.",
      "tldr_zh": "这项研究调查了AI从业者在实践Trustworthy AI (TAI)时面临的实际需求和挑战，尽管已有众多框架和指南出现，但使用情况鲜有研究。研究者通过问卷调查和半结构化访谈，探讨了视觉AI从业者对TAI原则的看法、处理方式，以及他们所需的工具、知识或指南。结果显示，从业者存在显著障碍，如资源不足和指导缺失；基于这些发现，论文提出了具体推荐，以帮助开发更可靠的TAI应用。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.SE"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.12135v1",
      "published_date": "2024-05-15 13:02:46 UTC",
      "updated_date": "2024-05-15 13:02:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:41:49.289096"
    },
    {
      "arxiv_id": "2405.09300v1",
      "title": "Comparing the Efficacy of GPT-4 and Chat-GPT in Mental Health Care: A Blind Assessment of Large Language Models for Psychological Support",
      "title_zh": "比较 GPT-4 与 Chat-GPT 在心理健康护理中的功效：大型语言模型用于心理支持的盲评估",
      "authors": [
        "Birger Moell"
      ],
      "abstract": "Background: Rapid advancements in natural language processing have led to the\ndevelopment of large language models with the potential to revolutionize mental\nhealth care. These models have shown promise in assisting clinicians and\nproviding support to individuals experiencing various psychological challenges.\n  Objective: This study aims to compare the performance of two large language\nmodels, GPT-4 and Chat-GPT, in responding to a set of 18 psychological prompts,\nto assess their potential applicability in mental health care settings.\n  Methods: A blind methodology was employed, with a clinical psychologist\nevaluating the models' responses without knowledge of their origins. The\nprompts encompassed a diverse range of mental health topics, including\ndepression, anxiety, and trauma, to ensure a comprehensive assessment.\n  Results: The results demonstrated a significant difference in performance\nbetween the two models (p > 0.05). GPT-4 achieved an average rating of 8.29 out\nof 10, while Chat-GPT received an average rating of 6.52. The clinical\npsychologist's evaluation suggested that GPT-4 was more effective at generating\nclinically relevant and empathetic responses, thereby providing better support\nand guidance to potential users.\n  Conclusions: This study contributes to the growing body of literature on the\napplicability of large language models in mental health care settings. The\nfindings underscore the importance of continued research and development in the\nfield to optimize these models for clinical use. Further investigation is\nnecessary to understand the specific factors underlying the performance\ndifferences between the two models and to explore their generalizability across\nvarious populations and mental health conditions.",
      "tldr_zh": "这篇论文比较了 GPT-4 和 Chat-GPT 在心理健康护理中的效能，通过盲评估方法评估它们对 18 个心理提示（如抑郁、焦虑和创伤）的响应。研究由临床心理学家匿名评分，结果显示 GPT-4 的平均评分达 8.29 分，而 Chat-GPT 为 6.52 分，表明 GPT-4 在生成临床相关和移情的响应方面更胜一筹。主要贡献在于突显大型语言模型在心理支持中的潜力，并呼吁进一步研究以优化其临床应用和泛化性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.09300v1",
      "published_date": "2024-05-15 12:44:54 UTC",
      "updated_date": "2024-05-15 12:44:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:42:02.718666"
    },
    {
      "arxiv_id": "2405.13021v1",
      "title": "IM-RAG: Multi-Round Retrieval-Augmented Generation Through Learning Inner Monologues",
      "title_zh": "IM-RAG：通过学习内部独白的多轮检索增强生成",
      "authors": [
        "Diji Yang",
        "Jinmeng Rao",
        "Kezhen Chen",
        "Xiaoyuan Guo",
        "Yawen Zhang",
        "Jie Yang",
        "Yi Zhang"
      ],
      "abstract": "Although the Retrieval-Augmented Generation (RAG) paradigms can use external\nknowledge to enhance and ground the outputs of Large Language Models (LLMs) to\nmitigate generative hallucinations and static knowledge base problems, they\nstill suffer from limited flexibility in adopting Information Retrieval (IR)\nsystems with varying capabilities, constrained interpretability during the\nmulti-round retrieval process, and a lack of end-to-end optimization. To\naddress these challenges, we propose a novel LLM-centric approach, IM-RAG, that\nintegrates IR systems with LLMs to support multi-round RAG through learning\nInner Monologues (IM, i.e., the human inner voice that narrates one's\nthoughts). During the IM process, the LLM serves as the core reasoning model\n(i.e., Reasoner) to either propose queries to collect more information via the\nRetriever or to provide a final answer based on the conversational context. We\nalso introduce a Refiner that improves the outputs from the Retriever,\neffectively bridging the gap between the Reasoner and IR modules with varying\ncapabilities and fostering multi-round communications. The entire IM process is\noptimized via Reinforcement Learning (RL) where a Progress Tracker is\nincorporated to provide mid-step rewards, and the answer prediction is further\nseparately optimized via Supervised Fine-Tuning (SFT). We conduct extensive\nexperiments with the HotPotQA dataset, a popular benchmark for retrieval-based,\nmulti-step question-answering. The results show that our approach achieves\nstate-of-the-art (SOTA) performance while providing high flexibility in\nintegrating IR modules as well as strong interpretability exhibited in the\nlearned inner monologues.",
      "tldr_zh": "该研究提出了一种新型框架 IM-RAG，通过学习内部独白（Inner Monologues）来增强多轮检索增强生成（RAG），以解决现有 RAG 范式在灵活性、解释性和端到端优化方面的局限性。IM-RAG 以大型语言模型（LLMs）为核心推理模型（Reasoner），结合检索器（Retriever）和优化器（Refiner），允许模型在对话上下文中提出查询或生成最终答案，并通过强化学习（RL）和监督微调（SFT）进行优化。实验在 HotPotQA 数据集上显示，IM-RAG 实现了最先进（SOTA）的性能，同时提高了 IR 模块的集成灵活性和过程的可解释性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.CL",
      "comment": "Proceedings of the 47th International ACM SIGIR 2024",
      "pdf_url": "http://arxiv.org/pdf/2405.13021v1",
      "published_date": "2024-05-15 12:41:20 UTC",
      "updated_date": "2024-05-15 12:41:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:42:13.469308"
    },
    {
      "arxiv_id": "2405.09293v1",
      "title": "Do language models capture implied discourse meanings? An investigation with exhaustivity implicatures of Korean morphology",
      "title_zh": "翻译失败",
      "authors": [
        "Hagyeong Shin",
        "Sean Trott"
      ],
      "abstract": "Markedness in natural language is often associated with non-literal meanings\nin discourse. Differential Object Marking (DOM) in Korean is one instance of\nthis phenomenon, where post-positional markers are selected based on both the\nsemantic features of the noun phrases and the discourse features that are\northogonal to the semantic features. Previous work has shown that\ndistributional models of language recover certain semantic features of words --\ndo these models capture implied discourse-level meanings as well? We evaluate\nwhether a set of large language models are capable of associating discourse\nmeanings with different object markings in Korean. Results suggest that\ndiscourse meanings of a grammatical marker can be more challenging to encode\nthan that of a discourse marker.",
      "tldr_zh": "这篇论文探讨了大型语言模型是否能捕捉韩语形态中的隐含话语意义，特别是与 Differential Object Marking (DOM) 相关的 exhaustivity implicatures。研究以韩语的宾语标记为例，评估模型是否能将话语特征与语义特征关联起来。结果表明，语言模型在编码语法标记的话语含义方面比编码话语标记更具挑战性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Proceedings of the Society for Computation in Linguistics (SCiL)\n  2024, Association for Computational Linguistics (ACL) Anthology",
      "pdf_url": "http://arxiv.org/pdf/2405.09293v1",
      "published_date": "2024-05-15 12:34:40 UTC",
      "updated_date": "2024-05-15 12:34:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:42:25.087713"
    },
    {
      "arxiv_id": "2405.09292v1",
      "title": "Attribute reduction algorithm of rough sets based on spatial optimization",
      "title_zh": "基于空间优化的粗糙集属性约简算法",
      "authors": [
        "Xuchang Guo",
        "Houbiao Li"
      ],
      "abstract": "Rough set is one of the important methods for rule acquisition and attribute\nreduction. The current goal of rough set attribute reduction focuses more on\nminimizing the number of reduced attributes, but ignores the spatial similarity\nbetween reduced and decision attributes, which may lead to problems such as\nincreased number of rules and limited generality. In this paper, a rough set\nattribute reduction algorithm based on spatial optimization is proposed. By\nintroducing the concept of spatial similarity, to find the reduction with the\nhighest spatial similarity, so that the spatial similarity between reduction\nand decision attributes is higher, and more concise and widespread rules are\nobtained. In addition, a comparative experiment with the traditional rough set\nattribute reduction algorithms is designed to prove the effectiveness of the\nrough set attribute reduction algorithm based on spatial optimization, which\nhas made significant improvements on many datasets.",
      "tldr_zh": "本文提出了一种基于空间优化的 Rough Set 属性约简算法，以解决传统方法过度关注属性数量最小化而忽略约简属性与决策属性之间空间相似性的问题。算法通过引入空间相似性概念，优化约简过程以寻找最高空间相似性的属性子集，从而生成更简洁且泛化性更强的规则。实验结果表明，该算法在多个数据集上与传统 Rough Set 属性约简算法相比，取得了显著改进，包括减少规则数量并提升整体性能。",
      "categories": [
        "cs.AI",
        "I.2.4"
      ],
      "primary_category": "cs.AI",
      "comment": "7 pages, 2 figures, 1 table",
      "pdf_url": "http://arxiv.org/pdf/2405.09292v1",
      "published_date": "2024-05-15 12:30:19 UTC",
      "updated_date": "2024-05-15 12:30:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:42:37.784281"
    },
    {
      "arxiv_id": "2405.09291v1",
      "title": "Sensitivity Decouple Learning for Image Compression Artifacts Reduction",
      "title_zh": "翻译失败",
      "authors": [
        "Li Ma",
        "Yifan Zhao",
        "Peixi Peng",
        "Yonghong Tian"
      ],
      "abstract": "With the benefit of deep learning techniques, recent researches have made\nsignificant progress in image compression artifacts reduction. Despite their\nimproved performances, prevailing methods only focus on learning a mapping from\nthe compressed image to the original one but ignore the intrinsic attributes of\nthe given compressed images, which greatly harms the performance of downstream\nparsing tasks. Different from these methods, we propose to decouple the\nintrinsic attributes into two complementary features for artifacts\nreduction,ie, the compression-insensitive features to regularize the high-level\nsemantic representations during training and the compression-sensitive features\nto be aware of the compression degree. To achieve this, we first employ\nadversarial training to regularize the compressed and original encoded features\nfor retaining high-level semantics, and we then develop the compression\nquality-aware feature encoder for compression-sensitive features. Based on\nthese dual complementary features, we propose a Dual Awareness Guidance Network\n(DAGN) to utilize these awareness features as transformation guidance during\nthe decoding phase. In our proposed DAGN, we develop a cross-feature fusion\nmodule to maintain the consistency of compression-insensitive features by\nfusing compression-insensitive features into the artifacts reduction baseline.\nOur method achieves an average 2.06 dB PSNR gains on BSD500, outperforming\nstate-of-the-art methods, and only requires 29.7 ms to process one image on\nBSD500. Besides, the experimental results on LIVE1 and LIU4K also demonstrate\nthe efficiency, effectiveness, and superiority of the proposed method in terms\nof quantitative metrics, visual quality, and downstream machine vision tasks.",
      "tldr_zh": "本文提出了一种名为 Sensitivity Decouple Learning 的方法，用于减少图像压缩伪影（Image Compression Artifacts Reduction）。该方法将压缩图像的内在属性解耦为 compression-insensitive features（用于保留高层次语义）和 compression-sensitive features（用于感知压缩程度），通过对抗训练和 compression quality-aware feature encoder 来实现特征正则化和感知。基于这些特征，作者开发了 Dual Awareness Guidance Network (DAGN)，包括 cross-feature fusion module，以在解码阶段提供指导，提升图像质量。实验结果显示，该方法在 BSD500 数据集上平均 PSNR 提升 2.06 dB，比现有最先进方法表现更好，且处理速度仅需 29.7 ms/图像，在 LIVE1 和 LIU4K 数据集上也表现出色，尤其在下游机器视觉任务中。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "eess.IV"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by Transactions on Image Processing",
      "pdf_url": "http://arxiv.org/pdf/2405.09291v1",
      "published_date": "2024-05-15 12:29:35 UTC",
      "updated_date": "2024-05-15 12:29:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:42:50.267692"
    },
    {
      "arxiv_id": "2405.09593v1",
      "title": "SQL-to-Schema Enhances Schema Linking in Text-to-SQL",
      "title_zh": "SQL-to-Schema 增强了 Text-to-SQL 中的模式链接",
      "authors": [
        "Sun Yang",
        "Qiong Su",
        "Zhishuai Li",
        "Ziyue Li",
        "Hangyu Mao",
        "Chenxi Liu",
        "Rui Zhao"
      ],
      "abstract": "In sophisticated existing Text-to-SQL methods exhibit errors in various\nproportions, including schema-linking errors (incorrect columns, tables, or\nextra columns), join errors, nested errors, and group-by errors. Consequently,\nthere is a critical need to filter out unnecessary tables and columns,\ndirecting the language models attention to relevant tables and columns with\nschema-linking, to reduce errors during SQL generation. Previous approaches\nhave involved sorting tables and columns based on their relevance to the\nquestion, selecting the top-ranked ones for sorting, or directly identifying\nthe necessary tables and columns for SQL generation. However, these methods\nface challenges such as lengthy model training times, high consumption of\nexpensive GPT-4 tokens in few-shot prompts, or suboptimal performance in schema\nlinking. Therefore, we propose an inventive schema linking method in two steps:\nFirstly, generate an initial SQL query by utilizing the complete database\nschema. Subsequently, extract tables and columns from the initial SQL query to\ncreate a concise schema. Using CodeLlama-34B, when comparing the schemas\nobtained by mainstream methods with ours for SQL generation, our schema\nperforms optimally. Leveraging GPT4, our SQL generation method achieved results\nthat are comparable to mainstream Text-to-SQL methods on the Spider dataset.",
      "tldr_zh": "本研究针对Text-to-SQL任务中的schema-linking错误（如错误列、表或多余列）等问题，提出了一种SQL-to-Schema方法，以过滤不必要表和列并提升SQL生成准确性。该方法分为两步：首先利用完整数据库schema生成初始SQL查询；其次，从初始SQL中提取相关表和列创建简洁schema。实验结果显示，使用CodeLlama-34B时，该schema在SQL生成中表现最佳，而使用GPT4在Spider数据集上，其性能与主流Text-to-SQL方法相当，从而有效减少错误并优化模型效率。",
      "categories": [
        "cs.DB",
        "cs.AI"
      ],
      "primary_category": "cs.DB",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.09593v1",
      "published_date": "2024-05-15 12:22:48 UTC",
      "updated_date": "2024-05-15 12:22:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:43:02.444166"
    },
    {
      "arxiv_id": "2405.09592v1",
      "title": "A Survey of Generative Techniques for Spatial-Temporal Data Mining",
      "title_zh": "生成技术在时空数据",
      "authors": [
        "Qianru Zhang",
        "Haixin Wang",
        "Cheng Long",
        "Liangcai Su",
        "Xingwei He",
        "Jianlong Chang",
        "Tailin Wu",
        "Hongzhi Yin",
        "Siu-Ming Yiu",
        "Qi Tian",
        "Christian S. Jensen"
      ],
      "abstract": "This paper focuses on the integration of generative techniques into\nspatial-temporal data mining, considering the significant growth and diverse\nnature of spatial-temporal data. With the advancements in RNNs, CNNs, and other\nnon-generative techniques, researchers have explored their application in\ncapturing temporal and spatial dependencies within spatial-temporal data.\nHowever, the emergence of generative techniques such as LLMs, SSL, Seq2Seq and\ndiffusion models has opened up new possibilities for enhancing spatial-temporal\ndata mining further. The paper provides a comprehensive analysis of generative\ntechnique-based spatial-temporal methods and introduces a standardized\nframework specifically designed for the spatial-temporal data mining pipeline.\nBy offering a detailed review and a novel taxonomy of spatial-temporal\nmethodology utilizing generative techniques, the paper enables a deeper\nunderstanding of the various techniques employed in this field. Furthermore,\nthe paper highlights promising future research directions, urging researchers\nto delve deeper into spatial-temporal data mining. It emphasizes the need to\nexplore untapped opportunities and push the boundaries of knowledge to unlock\nnew insights and improve the effectiveness and efficiency of spatial-temporal\ndata mining. By integrating generative techniques and providing a standardized\nframework, the paper contributes to advancing the field and encourages\nresearchers to explore the vast potential of generative techniques in\nspatial-temporal data mining.",
      "tldr_zh": "这篇论文调查了生成技术（如 LLMs、SSL、Seq2Seq 和 diffusion models）在空间-时间数据挖掘中的应用，强调了这些技术相对于传统方法（如 RNNs 和 CNNs）在捕捉时空依赖方面的优势。论文提供了全面分析和一个标准化的空间-时间数据挖掘框架，并引入了新颖的分类法，以加深对该领域的理解。最终，它指出了未来研究方向，鼓励探索生成技术的潜力来提升数据挖掘的有效性和效率。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CE"
      ],
      "primary_category": "cs.LG",
      "comment": "19 pages",
      "pdf_url": "http://arxiv.org/pdf/2405.09592v1",
      "published_date": "2024-05-15 12:07:43 UTC",
      "updated_date": "2024-05-15 12:07:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:43:14.740193"
    },
    {
      "arxiv_id": "2405.09591v3",
      "title": "A Comprehensive Survey on Data Augmentation",
      "title_zh": "翻译失败",
      "authors": [
        "Zaitian Wang",
        "Pengfei Wang",
        "Kunpeng Liu",
        "Pengyang Wang",
        "Yanjie Fu",
        "Chang-Tien Lu",
        "Charu C. Aggarwal",
        "Jian Pei",
        "Yuanchun Zhou"
      ],
      "abstract": "Data augmentation is a series of techniques that generate high-quality\nartificial data by manipulating existing data samples. By leveraging data\naugmentation techniques, AI models can achieve significantly improved\napplicability in tasks involving scarce or imbalanced datasets, thereby\nsubstantially enhancing AI models' generalization capabilities. Existing\nliterature surveys only focus on a certain type of specific modality data, and\ncategorize these methods from modality-specific and operation-centric\nperspectives, which lacks a consistent summary of data augmentation methods\nacross multiple modalities and limits the comprehension of how existing data\nsamples serve the data augmentation process. To bridge this gap, we propose a\nmore enlightening taxonomy that encompasses data augmentation techniques for\ndifferent common data modalities. Specifically, from a data-centric\nperspective, this survey proposes a modality-independent taxonomy by\ninvestigating how to take advantage of the intrinsic relationship between data\nsamples, including single-wise, pair-wise, and population-wise sample data\naugmentation methods. Additionally, we categorize data augmentation methods\nacross five data modalities through a unified inductive approach.",
      "tldr_zh": "这篇论文对数据 augmentation 进行了全面调查，强调这些技术通过操作现有数据样本生成高质量人工数据，以提升 AI 模型在稀缺或不平衡数据集上的泛化能力。现有文献主要从模态特定视角分类方法，导致跨模态总结不足；为此，论文提出一个模态无关的 taxonomy，从数据中心视角（data-centric）将方法分为 single-wise、pair-wise 和 population-wise 类型，基于数据样本间的内在关系。最终，该框架统一应用于五种数据模态，帮助更好地理解和应用数据 augmentation 过程。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.09591v3",
      "published_date": "2024-05-15 11:58:08 UTC",
      "updated_date": "2025-05-02 03:47:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:43:26.357749"
    },
    {
      "arxiv_id": "2405.09279v1",
      "title": "Sign of the Times: Evaluating the use of Large Language Models for Idiomaticity Detection",
      "title_zh": "时代的迹象：评估大型语言模型在习惯用语",
      "authors": [
        "Dylan Phelps",
        "Thomas Pickard",
        "Maggie Mi",
        "Edward Gow-Smith",
        "Aline Villavicencio"
      ],
      "abstract": "Despite the recent ubiquity of large language models and their high zero-shot\nprompted performance across a wide range of tasks, it is still not known how\nwell they perform on tasks which require processing of potentially idiomatic\nlanguage. In particular, how well do such models perform in comparison to\nencoder-only models fine-tuned specifically for idiomaticity tasks? In this\nwork, we attempt to answer this question by looking at the performance of a\nrange of LLMs (both local and software-as-a-service models) on three\nidiomaticity datasets: SemEval 2022 Task 2a, FLUTE, and MAGPIE. Overall, we\nfind that whilst these models do give competitive performance, they do not\nmatch the results of fine-tuned task-specific models, even at the largest\nscales (e.g. for GPT-4). Nevertheless, we do see consistent performance\nimprovements across model scale. Additionally, we investigate prompting\napproaches to improve performance, and discuss the practicalities of using LLMs\nfor these tasks.",
      "tldr_zh": "本研究评估了大型语言模型 (LLMs) 在成语检测 (idiomaticity detection) 任务上的性能，比较了其零样本提示表现与专门微调的编码器模型。研究使用了 SemEval 2022 Task 2a、FLUTE 和 MAGPIE 等三个数据集，结果显示 LLMs 的表现虽具竞争力，但即使在大型模型如 GPT-4 上，也不如针对任务微调的模型。作者观察到模型规模越大，性能越稳定，并探讨了各种提示方法来提升 LLMs 的实际应用效果。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Presented at the MWE-UD Workshop at LREC-COLING 2024",
      "pdf_url": "http://arxiv.org/pdf/2405.09279v1",
      "published_date": "2024-05-15 11:55:14 UTC",
      "updated_date": "2024-05-15 11:55:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:43:37.600764"
    },
    {
      "arxiv_id": "2405.09276v2",
      "title": "Dual-Segment Clustering Strategy for Hierarchical Federated Learning in Heterogeneous Wireless Environments",
      "title_zh": "异构无线环境下的分层联邦学习双段聚类",
      "authors": [
        "Pengcheng Sun",
        "Erwu Liu",
        "Wei Ni",
        "Kanglei Yu",
        "Xinyu Qu",
        "Rui Wang",
        "Yanlong Bi",
        "Chuanchun Zhang",
        "Abbas Jamalipour"
      ],
      "abstract": "Non-independent and identically distributed (Non- IID) data adversely affects\nfederated learning (FL) while heterogeneity in communication quality can\nundermine the reliability of model parameter transmission, potentially\ndegrading wireless FL convergence. This paper proposes a novel dual-segment\nclustering (DSC) strategy that jointly addresses communication and data\nheterogeneity in FL. This is achieved by defining a new signal-to-noise ratio\n(SNR) matrix and information quantity matrix to capture the communication and\ndata heterogeneity, respectively. The celebrated affinity propagation algorithm\nis leveraged to iteratively refine the clustering of clients based on the newly\ndefined matrices effectively enhancing model aggregation in heterogeneous\nenvironments. The convergence analysis and experimental results show that the\nDSC strategy can improve the convergence rate of wireless FL and demonstrate\nsuperior accuracy in heterogeneous environments compared to classical\nclustering methods.",
      "tldr_zh": "本论文针对非独立同分布（Non-IID）数据和通信质量异质性对联邦学习（FL）造成的不利影响，提出了一种新型双段聚类（DSC）策略，以提升无线异质环境下的模型聚合效率。该策略通过定义信噪比（SNR）矩阵和信息量矩阵来分别捕捉通信和数据异质性，并利用亲和传播算法对客户端进行迭代优化聚类。实验结果显示，DSC 策略显著提高了无线 FL 的收敛率，并在异质环境中比传统聚类方法表现出更高的准确性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DC"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.09276v2",
      "published_date": "2024-05-15 11:46:47 UTC",
      "updated_date": "2024-11-14 08:06:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:43:50.656725"
    },
    {
      "arxiv_id": "2405.09266v3",
      "title": "Dance Any Beat: Blending Beats with Visuals in Dance Video Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Xuanchen Wang",
        "Heng Wang",
        "Dongnan Liu",
        "Weidong Cai"
      ],
      "abstract": "Generating dance from music is crucial for advancing automated choreography.\nCurrent methods typically produce skeleton keypoint sequences instead of dance\nvideos and lack the capability to make specific individuals dance, which\nreduces their real-world applicability. These methods also require precise\nkeypoint annotations, complicating data collection and limiting the use of\nself-collected video datasets. To overcome these challenges, we introduce a\nnovel task: generating dance videos directly from images of individuals guided\nby music. This task enables the dance generation of specific individuals\nwithout requiring keypoint annotations, making it more versatile and applicable\nto various situations. Our solution, the Dance Any Beat Diffusion model\n(DabFusion), utilizes a reference image and a music piece to generate dance\nvideos featuring various dance types and choreographies. The music is analyzed\nby our specially designed music encoder, which identifies essential features\nincluding dance style, movement, and rhythm. DabFusion excels in generating\ndance videos not only for individuals in the training dataset but also for any\npreviously unseen person. This versatility stems from its approach of\ngenerating latent optical flow, which contains all necessary motion information\nto animate any person in the image. We evaluate DabFusion's performance using\nthe AIST++ dataset, focusing on video quality, audio-video synchronization, and\nmotion-music alignment. We propose a 2D Motion-Music Alignment Score (2D-MM\nAlign), which builds on the Beat Alignment Score to more effectively evaluate\nmotion-music alignment for this new task. Experiments show that our DabFusion\nestablishes a solid baseline for this innovative task. Video results can be\nfound on our project page: https://DabFusion.github.io.",
      "tldr_zh": "本文提出一个新任务：直接从个体图像和音乐生成舞蹈视频，解决现有方法仅产生骨骼关键点序列、无法针对特定个体且需精确关键点标注的局限性。DabFusion 模型作为解决方案，利用参考图像和专门设计的音乐编码器提取音乐特征（如舞蹈风格、动作和节奏），通过生成 latent optical flow 来实现任意人物的舞蹈动画。模型不仅适用于训练数据集中的个体，还能处理未见过的人。实验在 AIST++ 数据集上评估了视频质量、音频视频同步和动作音乐对齐，使用新指标 2D-MM Align 进行量化，结果显示 DabFusion 为这一创新任务建立了可靠的基准。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.MM",
        "cs.SD",
        "eess.AS"
      ],
      "primary_category": "cs.CV",
      "comment": "WACV2025, 11 pages, 7 figures, demo page: https://DabFusion.github.io",
      "pdf_url": "http://arxiv.org/pdf/2405.09266v3",
      "published_date": "2024-05-15 11:33:07 UTC",
      "updated_date": "2024-11-28 10:30:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:44:05.687947"
    },
    {
      "arxiv_id": "2405.13020v1",
      "title": "Using Combinatorial Optimization to Design a High quality LLM Solution",
      "title_zh": "利用组合优化设计高质量LLM解决方案",
      "authors": [
        "Samuel Ackerman",
        "Eitan Farchi",
        "Rami Katan",
        "Orna Raz"
      ],
      "abstract": "We introduce a novel LLM based solution design approach that utilizes\ncombinatorial optimization and sampling. Specifically, a set of factors that\ninfluence the quality of the solution are identified. They typically include\nfactors that represent prompt types, LLM inputs alternatives, and parameters\ngoverning the generation and design alternatives. Identifying the factors that\ngovern the LLM solution quality enables the infusion of subject matter expert\nknowledge. Next, a set of interactions between the factors are defined and\ncombinatorial optimization is used to create a small subset $P$ that ensures\nall desired interactions occur in $P$. Each element $p \\in P$ is then developed\ninto an appropriate benchmark. Applying the alternative solutions on each\ncombination, $p \\in P$ and evaluating the results facilitate the design of a\nhigh quality LLM solution pipeline. The approach is especially applicable when\nthe design and evaluation of each benchmark in $P$ is time-consuming and\ninvolves manual steps and human evaluation. Given its efficiency the approach\ncan also be used as a baseline to compare and validate an autoML approach that\nsearches over the factors governing the solution.",
      "tldr_zh": "该论文提出了一种利用组合优化和采样的新型方法，用于设计高质量的LLM解决方案。具体地，该方法先识别影响解决方案质量的因素（如提示类型、LLM输入备选方案和生成参数），并注入主题专家知识，然后定义因素间的交互，通过组合优化创建子集P，并将其转化为基准测试。最终，通过在各子集上评估备选方案，该方法能高效构建LLM解决方案管道，尤其适用于耗时手动评估的场景，并可作为autoML方法的比较基线。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.13020v1",
      "published_date": "2024-05-15 11:13:39 UTC",
      "updated_date": "2024-05-15 11:13:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:44:14.477816"
    },
    {
      "arxiv_id": "2406.16893v1",
      "title": "A Survey on Transformers in NLP with Focus on Efficiency",
      "title_zh": "翻译失败",
      "authors": [
        "Wazib Ansar",
        "Saptarsi Goswami",
        "Amlan Chakrabarti"
      ],
      "abstract": "The advent of transformers with attention mechanisms and associated\npre-trained models have revolutionized the field of Natural Language Processing\n(NLP). However, such models are resource-intensive due to highly complex\narchitecture. This limits their application to resource-constrained\nenvironments. While choosing an appropriate NLP model, a major trade-off exists\nover choosing accuracy over efficiency and vice versa. This paper presents a\ncommentary on the evolution of NLP and its applications with emphasis on their\naccuracy as-well-as efficiency. Following this, a survey of research\ncontributions towards enhancing the efficiency of transformer-based models at\nvarious stages of model development along with hardware considerations has been\nconducted. The goal of this survey is to determine how current NLP techniques\ncontribute towards a sustainable society and to establish a foundation for\nfuture research.",
      "tldr_zh": "这篇论文调查了Transformer模型在自然语言处理(NLP)中的应用，强调了其通过attention mechanisms和预训练模型带来的革命性变革，同时指出了这些模型因复杂架构而资源密集的问题，导致在资源受限环境中应用受限。论文分析了准确性和效率之间的权衡，并回顾了提升Transformer模型效率的相关研究，包括模型开发各阶段的优化策略和硬件考虑。最终，该调查旨在评估这些NLP技术对可持续社会的贡献，并为未来研究奠定基础。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.16893v1",
      "published_date": "2024-05-15 10:32:41 UTC",
      "updated_date": "2024-05-15 10:32:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:44:24.880705"
    },
    {
      "arxiv_id": "2407.06115v1",
      "title": "Infer Induced Sentiment of Comment Response to Video: A New Task, Dataset and Baseline",
      "title_zh": "翻译失败",
      "authors": [
        "Qi Jia",
        "Baoyu Fan",
        "Cong Xu",
        "Lu Liu",
        "Liang Jin",
        "Guoguang Du",
        "Zhenhua Guo",
        "Yaqian Zhao",
        "Xuanjing Huang",
        "Rengang Li"
      ],
      "abstract": "Existing video multi-modal sentiment analysis mainly focuses on the sentiment\nexpression of people within the video, yet often neglects the induced sentiment\nof viewers while watching the videos. Induced sentiment of viewers is essential\nfor inferring the public response to videos, has broad application in analyzing\npublic societal sentiment, effectiveness of advertising and other areas. The\nmicro videos and the related comments provide a rich application scenario for\nviewers induced sentiment analysis. In light of this, we introduces a novel\nresearch task, Multi-modal Sentiment Analysis for Comment Response of Video\nInduced(MSA-CRVI), aims to inferring opinions and emotions according to the\ncomments response to micro video. Meanwhile, we manually annotate a dataset\nnamed Comment Sentiment toward to Micro Video (CSMV) to support this research.\nIt is the largest video multi-modal sentiment dataset in terms of scale and\nvideo duration to our knowledge, containing 107,267 comments and 8,210 micro\nvideos with a video duration of 68.83 hours. To infer the induced sentiment of\ncomment should leverage the video content, so we propose the Video\nContent-aware Comment Sentiment Analysis (VC-CSA) method as baseline to address\nthe challenges inherent in this new task. Extensive experiments demonstrate\nthat our method is showing significant improvements over other established\nbaselines.",
      "tldr_zh": "该论文引入了一个新任务Multi-modal Sentiment Analysis for Comment Response of Video Induced (MSA-CRVI)，旨在分析观看微视频时观众的诱导情感，从而评估公众对视频的反应，并在社会情感分析和广告效果等领域有广泛应用。研究者构建了最大的视频多模态情感数据集Comment Sentiment toward to Micro Video (CSMV)，包含107,267条评论和8,210个微视频，总时长达68.83小时。论文提出了一种基线方法Video Content-aware Comment Sentiment Analysis (VC-CSA)，通过整合视频内容来推断评论情感，并通过实验证明该方法显著优于现有基线。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.06115v1",
      "published_date": "2024-05-15 10:24:54 UTC",
      "updated_date": "2024-05-15 10:24:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:44:38.349995"
    },
    {
      "arxiv_id": "2405.09589v4",
      "title": "A Comprehensive Survey of Hallucination in Large Language, Image, Video and Audio Foundation Models",
      "title_zh": "翻译失败",
      "authors": [
        "Pranab Sahoo",
        "Prabhash Meharia",
        "Akash Ghosh",
        "Sriparna Saha",
        "Vinija Jain",
        "Aman Chadha"
      ],
      "abstract": "The rapid advancement of foundation models (FMs) across language, image,\naudio, and video domains has shown remarkable capabilities in diverse tasks.\nHowever, the proliferation of FMs brings forth a critical challenge: the\npotential to generate hallucinated outputs, particularly in high-stakes\napplications. The tendency of foundation models to produce hallucinated content\narguably represents the biggest hindrance to their widespread adoption in\nreal-world scenarios, especially in domains where reliability and accuracy are\nparamount. This survey paper presents a comprehensive overview of recent\ndevelopments that aim to identify and mitigate the problem of hallucination in\nFMs, spanning text, image, video, and audio modalities. By synthesizing recent\nadvancements in detecting and mitigating hallucination across various\nmodalities, the paper aims to provide valuable insights for researchers,\ndevelopers, and practitioners. Essentially, it establishes a clear framework\nencompassing definition, taxonomy, and detection strategies for addressing\nhallucination in multimodal foundation models, laying the foundation for future\nresearch in this pivotal area.",
      "tldr_zh": "这篇调查论文全面审视了Large Language Models、Image、Video和Audio Foundation Models中生成的Hallucination问题，强调这是阻碍这些模型在高风险应用中广泛采用的主要挑战。论文通过合成跨模态的最新进展，提供识别和缓解Hallucination的策略，包括定义、Taxonomy和检测框架。最终，它为研究者、开发者和从业者提供了宝贵见解，并为未来多模态Foundation Models的研究奠定基础。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.CV",
        "cs.SD",
        "eess.AS"
      ],
      "primary_category": "cs.LG",
      "comment": "EMNLP 2024 Findings",
      "pdf_url": "http://arxiv.org/pdf/2405.09589v4",
      "published_date": "2024-05-15 10:16:25 UTC",
      "updated_date": "2024-10-03 09:00:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:44:50.447942"
    },
    {
      "arxiv_id": "2405.09224v1",
      "title": "Perception-Inspired Graph Convolution for Music Understanding Tasks",
      "title_zh": "翻译失败",
      "authors": [
        "Emmanouil Karystinaios",
        "Francesco Foscarin",
        "Gerhard Widmer"
      ],
      "abstract": "We propose a new graph convolutional block, called MusGConv, specifically\ndesigned for the efficient processing of musical score data and motivated by\ngeneral perceptual principles. It focuses on two fundamental dimensions of\nmusic, pitch and rhythm, and considers both relative and absolute\nrepresentations of these components. We evaluate our approach on four different\nmusical understanding problems: monophonic voice separation, harmonic analysis,\ncadence detection, and composer identification which, in abstract terms,\ntranslate to different graph learning problems, namely, node classification,\nlink prediction, and graph classification. Our experiments demonstrate that\nMusGConv improves the performance on three of the aforementioned tasks while\nbeing conceptually very simple and efficient. We interpret this as evidence\nthat it is beneficial to include perception-informed processing of fundamental\nmusical concepts when developing graph network applications on musical score\ndata.",
      "tldr_zh": "本文提出了一种基于感知原则的图卷积块 MusGConv，用于高效处理乐谱数据，聚焦于 pitch 和 rhythm 的相对与绝对表示。研究在四个音乐理解任务上进行评估，包括 monophonic voice separation、harmonic analysis、cadence detection 和 composer identification，这些任务分别对应节点分类（node classification）、链接预测（link prediction）和图分类（graph classification）。实验结果显示，MusGConv 在三个任务上显著提升了性能，同时保持简单高效，证明了在音乐图网络应用中纳入感知启发的音乐概念处理具有显著益处。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.LG",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "Accepted at the 33rd International Joint Conference on Artificial\n  Intelligence (IJCAI-24)",
      "pdf_url": "http://arxiv.org/pdf/2405.09224v1",
      "published_date": "2024-05-15 10:04:44 UTC",
      "updated_date": "2024-05-15 10:04:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:45:03.377604"
    },
    {
      "arxiv_id": "2405.09223v2",
      "title": "Word Alignment as Preference for Machine Translation",
      "title_zh": "翻译失败",
      "authors": [
        "Qiyu Wu",
        "Masaaki Nagata",
        "Zhongtao Miao",
        "Yoshimasa Tsuruoka"
      ],
      "abstract": "The problem of hallucination and omission, a long-standing problem in machine\ntranslation (MT), is more pronounced when a large language model (LLM) is used\nin MT because an LLM itself is susceptible to these phenomena. In this work, we\nmitigate the problem in an LLM-based MT model by guiding it to better word\nalignment. We first study the correlation between word alignment and the\nphenomena of hallucination and omission in MT. Then we propose to utilize word\nalignment as preference to optimize the LLM-based MT model. The preference data\nare constructed by selecting chosen and rejected translations from multiple MT\ntools. Subsequently, direct preference optimization is used to optimize the\nLLM-based model towards the preference signal. Given the absence of evaluators\nspecifically designed for hallucination and omission in MT, we further propose\nselecting hard instances and utilizing GPT-4 to directly evaluate the\nperformance of the models in mitigating these issues. We verify the rationality\nof these designed evaluation methods by experiments, followed by extensive\nresults demonstrating the effectiveness of word alignment-based preference\noptimization to mitigate hallucination and omission. On the other hand,\nalthough it shows promise in mitigating hallucination and omission, the overall\nperformance of MT in different language directions remains mixed, with slight\nincreases in BLEU and decreases in COMET.",
      "tldr_zh": "本文提出一种利用词对齐（word alignment）作为偏好信号的方法，来缓解机器翻译（MT）中使用大型语言模型（LLM）时常见的幻觉（hallucination）和遗漏（omission）问题。首先，研究了词对齐与这些现象的相关性，并通过从多个MT工具中选择优选和拒绝翻译构建偏好数据，然后采用直接偏好优化（direct preference optimization）优化LLM-based MT模型。实验验证了评估方法的合理性，包括使用GPT-4评估困难实例，结果显示该方法显著降低了幻觉和遗漏，但整体MT性能在不同语言方向上表现不一，BLEU略有提升而COMET略有下降。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "EMNLP 2024 Main",
      "pdf_url": "http://arxiv.org/pdf/2405.09223v2",
      "published_date": "2024-05-15 10:04:19 UTC",
      "updated_date": "2024-11-20 23:06:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:45:16.332103"
    },
    {
      "arxiv_id": "2405.09221v1",
      "title": "Bridging the gap in online hate speech detection: a comparative analysis of BERT and traditional models for homophobic content identification on X/Twitter",
      "title_zh": "翻译失败",
      "authors": [
        "Josh McGiff",
        "Nikola S. Nikolov"
      ],
      "abstract": "Our study addresses a significant gap in online hate speech detection\nresearch by focusing on homophobia, an area often neglected in sentiment\nanalysis research. Utilising advanced sentiment analysis models, particularly\nBERT, and traditional machine learning methods, we developed a nuanced approach\nto identify homophobic content on X/Twitter. This research is pivotal due to\nthe persistent underrepresentation of homophobia in detection models. Our\nfindings reveal that while BERT outperforms traditional methods, the choice of\nvalidation technique can impact model performance. This underscores the\nimportance of contextual understanding in detecting nuanced hate speech. By\nreleasing the largest open-source labelled English dataset for homophobia\ndetection known to us, an analysis of various models' performance and our\nstrongest BERT-based model, we aim to enhance online safety and inclusivity.\nFuture work will extend to broader LGBTQIA+ hate speech detection, addressing\nthe challenges of sourcing diverse datasets. Through this endeavour, we\ncontribute to the larger effort against online hate, advocating for a more\ninclusive digital landscape. Our study not only offers insights into the\neffective detection of homophobic content by improving on previous research\nresults, but it also lays groundwork for future advancements in hate speech\nanalysis.",
      "tldr_zh": "本研究针对在线仇恨言论检测中的空白，专注于同性恋恐惧（homophobia）内容识别，这在情感分析研究中常被忽略。通过比较BERT模型与传统机器学习方法，该团队开发了一种细致的方法，用于在X/Twitter平台上识别同性恋恐惧言论，结果显示BERT的表现优于传统模型，但验证技术的选择会影响性能。研究发布目前已知最大的开源标记英语数据集，并提供最强的BERT-based模型，以提升在线安全性和包容性；未来工作将扩展到更广泛的LGBTQIA+仇恨言论检测，为仇恨分析领域奠定基础。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG",
        "H.5; I.2; J.5"
      ],
      "primary_category": "cs.CL",
      "comment": "6 pages, Homophobia detection model available at:\n  https://huggingface.co/JoshMcGiff/homophobiaBERT. The dataset used for this\n  study is available at:\n  https://huggingface.co/datasets/JoshMcGiff/HomophobiaDetectionTwitterX - This\n  paper has been accepted by the 6th International Conference on Computing and\n  Data Science (CONF-CDS 2024)",
      "pdf_url": "http://arxiv.org/pdf/2405.09221v1",
      "published_date": "2024-05-15 10:02:47 UTC",
      "updated_date": "2024-05-15 10:02:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:45:27.241189"
    },
    {
      "arxiv_id": "2405.09220v3",
      "title": "ALPINE: Unveiling the Planning Capability of Autoregressive Learning in Language Models",
      "title_zh": "ALPINE：揭示自回归学习在语言模型中的规划能力",
      "authors": [
        "Siwei Wang",
        "Yifei Shen",
        "Shi Feng",
        "Haoran Sun",
        "Shang-Hua Teng",
        "Wei Chen"
      ],
      "abstract": "Planning is a crucial element of both human intelligence and contemporary\nlarge language models (LLMs). In this paper, we initiate a theoretical\ninvestigation into the emergence of planning capabilities in Transformer-based\nLLMs via their next-word prediction mechanisms. We model planning as a network\npath-finding task, where the objective is to generate a valid path from a\nspecified source node to a designated target node. Our mathematical\ncharacterization shows that Transformer architectures can execute path-finding\nby embedding the adjacency and reachability matrices within their weights.\nFurthermore, our theoretical analysis of gradient-based learning dynamics\nreveals that LLMs can learn both the adjacency and a limited form of the\nreachability matrices. These theoretical insights are then validated through\nexperiments, which demonstrate that Transformer architectures indeed learn the\nadjacency and an incomplete reachability matrices, consistent with our\ntheoretical predictions. When applying our methodology to the real-world\nplanning benchmark Blocksworld, our observations remain consistent.\nAdditionally, our analyses uncover a fundamental limitation of current\nTransformer architectures in path-finding: these architectures cannot identify\nreachability relationships through transitivity, which leads to failures in\ngenerating paths when concatenation is required. These findings provide new\ninsights into how the internal mechanisms of autoregressive learning facilitate\nintelligent planning and deepen our understanding of how future LLMs might\nachieve more advanced and general planning-and-reasoning capabilities across\ndiverse applications.",
      "tldr_zh": "本论文探讨了Transformer-based 大语言模型 (LLMs) 在规划能力方面的表现，通过autoregressive learning的次词预测机制进行理论分析。研究将规划建模为网络路径查找任务，证明LLMs可通过嵌入邻接矩阵和可达性矩阵来执行路径查找，并分析梯度学习动态以揭示其学习邻接矩阵和有限可达性矩阵的能力。实验验证了这些理论预测，在Blocksworld基准上显示一致结果，但也暴露了Transformer架构的局限性，即无法通过传递性识别可达性关系，导致在需要路径连接时失败。这些发现深化了对autoregressive learning在智能规划中的作用，并为未来LLMs实现更高级的规划和推理能力提供指导。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.09220v3",
      "published_date": "2024-05-15 09:59:37 UTC",
      "updated_date": "2024-11-11 09:16:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:45:38.812177"
    },
    {
      "arxiv_id": "2405.09215v3",
      "title": "Xmodel-VLM: A Simple Baseline for Multimodal Vision Language Model",
      "title_zh": "Xmodel-VLM：多模态视觉语言模型的一个简单基准",
      "authors": [
        "Wanting Xu",
        "Yang Liu",
        "Langping He",
        "Xucheng Huang",
        "Ling Jiang"
      ],
      "abstract": "We introduce Xmodel-VLM, a cutting-edge multimodal vision language model. It\nis designed for efficient deployment on consumer GPU servers. Our work directly\nconfronts a pivotal industry issue by grappling with the prohibitive service\ncosts that hinder the broad adoption of large-scale multimodal systems. Through\nrigorous training, we have developed a 1B-scale language model from the ground\nup, employing the LLaVA paradigm for modal alignment. The result, which we call\nXmodel-VLM, is a lightweight yet powerful multimodal vision language model.\nExtensive testing across numerous classic multimodal benchmarks has revealed\nthat despite its smaller size and faster execution, Xmodel-VLM delivers\nperformance comparable to that of larger models. Our model checkpoints and code\nare publicly available on GitHub at https://github.com/XiaoduoAILab/XmodelVLM.",
      "tldr_zh": "我们介绍了 Xmodel-VLM，这是一个简单且高效的多模态视觉语言模型（multimodal vision language model），旨在解决大规模系统的高服务成本问题，使其适合在消费级 GPU 服务器上部署。该模型从零开始训练了一个 1B 规模的语言模型，使用 LLaVA 范式进行模态对齐，从而实现轻量级设计。在多个经典多模态基准测试中，Xmodel-VLM 尽管体积小和执行速度快，却表现出与更大模型相当的性能，且模型检查点和代码已在 GitHub 上公开。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.09215v3",
      "published_date": "2024-05-15 09:47:59 UTC",
      "updated_date": "2024-06-20 07:31:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:45:51.175079"
    },
    {
      "arxiv_id": "2405.09588v1",
      "title": "Training Deep Learning Models with Hybrid Datasets for Robust Automatic Target Detection on real SAR images",
      "title_zh": "利用混合数据集训练深度学习模型，用于真实 SAR 图像上的鲁棒自动目标检测",
      "authors": [
        "Benjamin Camus",
        "Théo Voillemin",
        "Corentin Le Barbu",
        "Jean-Christophe Louvigné",
        "Carole Belloni",
        "Emmanuel Vallée"
      ],
      "abstract": "In this work, we propose to tackle several challenges hindering the\ndevelopment of Automatic Target Detection (ATD) algorithms for ground targets\nin SAR images. To address the lack of representative training data, we propose\na Deep Learning approach to train ATD models with synthetic target signatures\nproduced with the MOCEM simulator. We define an incrustation pipeline to\nincorporate synthetic targets into real backgrounds. Using this hybrid dataset,\nwe train ATD models specifically tailored to bridge the domain gap between\nsynthetic and real data. Our approach notably relies on massive physics-based\ndata augmentation techniques and Adversarial Training of two deep-learning\ndetection architectures. We then test these models on several datasets,\nincluding (1) patchworks of real SAR images, (2) images with the incrustation\nof real targets in real backgrounds, and (3) images with the incrustation of\nsynthetic background objects in real backgrounds. Results show that the\nproduced hybrid datasets are exempt from image overlay bias. Our approach can\nreach up to 90% of Average Precision on real data while exclusively using\nsynthetic targets for training.",
      "tldr_zh": "本论文针对 SAR 图像中 Automatic Target Detection (ATD) 的挑战，特别是训练数据不足的问题，提出一种使用混合数据集训练深度学习模型的方法。研究利用 MOCEM 模拟器生成合成目标签名，并通过 incrustation pipeline 将其嵌入真实背景中，结合海量基于物理的数据增强技术和 Adversarial Training 优化两个深度学习检测架构。实验结果表明，该方法成功桥接了合成与真实数据之间的领域差距，在仅使用合成目标训练的情况下，在真实 SAR 图像数据集上达到高达 90% 的 Average Precision。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "eess.SP"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.09588v1",
      "published_date": "2024-05-15 09:26:24 UTC",
      "updated_date": "2024-05-15 09:26:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:46:05.464385"
    },
    {
      "arxiv_id": "2405.10343v1",
      "title": "UniCorn: A Unified Contrastive Learning Approach for Multi-view Molecular Representation Learning",
      "title_zh": "UniCorn：一种用于多视图分子表示学习的统一对比学习方法",
      "authors": [
        "Shikun Feng",
        "Yuyan Ni",
        "Minghao Li",
        "Yanwen Huang",
        "Zhi-Ming Ma",
        "Wei-Ying Ma",
        "Yanyan Lan"
      ],
      "abstract": "Recently, a noticeable trend has emerged in developing pre-trained foundation\nmodels in the domains of CV and NLP. However, for molecular pre-training, there\nlacks a universal model capable of effectively applying to various categories\nof molecular tasks, since existing prevalent pre-training methods exhibit\neffectiveness for specific types of downstream tasks. Furthermore, the lack of\nprofound understanding of existing pre-training methods, including 2D graph\nmasking, 2D-3D contrastive learning, and 3D denoising, hampers the advancement\nof molecular foundation models. In this work, we provide a unified\ncomprehension of existing pre-training methods through the lens of contrastive\nlearning. Thus their distinctions lie in clustering different views of\nmolecules, which is shown beneficial to specific downstream tasks. To achieve a\ncomplete and general-purpose molecular representation, we propose a novel\npre-training framework, named UniCorn, that inherits the merits of the three\nmethods, depicting molecular views in three different levels. SOTA performance\nacross quantum, physicochemical, and biological tasks, along with comprehensive\nablation study, validate the universality and effectiveness of UniCorn.",
      "tldr_zh": "本研究提出UniCorn，一种统一的对比学习(contrastive learning)方法，用于多视图分子表示学习，以解决现有分子预训练模型缺乏通用性的问题。通过对比学习的视角，作者统一理解了现有方法（如2D图遮盖、2D-3D对比学习和3D去噪），并发现它们在不同分子视图聚类方面的差异。UniCorn框架继承这些方法的优点，在三个不同级别描绘分子视图，实现全面的分子表示。实验结果显示，UniCorn在量子、物理化学和生物任务上达到SOTA性能，并通过消融研究验证了其通用性和有效性。",
      "categories": [
        "q-bio.BM",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "q-bio.BM",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.10343v1",
      "published_date": "2024-05-15 09:20:02 UTC",
      "updated_date": "2024-05-15 09:20:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:46:14.693004"
    },
    {
      "arxiv_id": "2405.09190v1",
      "title": "Advancing Explainable AI with Causal Analysis in Large-Scale Fuzzy Cognitive Maps",
      "title_zh": "利用因果分析推进大规模模糊认知地图中的解释性 AI",
      "authors": [
        "Marios Tyrovolas",
        "Nikolaos D. Kallimanis",
        "Chrysostomos Stylios"
      ],
      "abstract": "In the quest for accurate and interpretable AI models, eXplainable AI (XAI)\nhas become crucial. Fuzzy Cognitive Maps (FCMs) stand out as an advanced XAI\nmethod because of their ability to synergistically combine and exploit both\nexpert knowledge and data-driven insights, providing transparency and intrinsic\ninterpretability. This letter introduces and investigates the \"Total Causal\nEffect Calculation for FCMs\" (TCEC-FCM) algorithm, an innovative approach that,\nfor the first time, enables the efficient calculation of total causal effects\namong concepts in large-scale FCMs by leveraging binary search and graph\ntraversal techniques, thereby overcoming the challenge of exhaustive causal\npath exploration that hinder existing methods. We evaluate the proposed method\nacross various synthetic FCMs that demonstrate TCEC-FCM's superior performance\nover exhaustive methods, marking a significant advancement in causal effect\nanalysis within FCMs, thus broadening their usability for modern complex XAI\napplications.",
      "tldr_zh": "这篇论文探讨了在大型 Fuzzy Cognitive Maps (FCMs) 中应用因果分析来推进 Explainable AI (XAI)，强调 FCMs 能结合专家知识和数据驱动洞见，提供透明度和内在可解释性。论文引入了 Total Causal Effect Calculation for FCMs (TCEC-FCM) 算法，该方法首次利用二分搜索和图遍历技术，实现高效计算概念之间的总因果效应，避免了传统方法的穷尽路径探索挑战。在各种合成 FCMs 的评估中，TCEC-FCM 显著优于现有方法，提升了性能，从而扩展了 FCMs 在复杂 XAI 应用中的实用性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "6 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2405.09190v1",
      "published_date": "2024-05-15 08:53:47 UTC",
      "updated_date": "2024-05-15 08:53:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:46:28.108132"
    },
    {
      "arxiv_id": "2405.09586v2",
      "title": "Factual Serialization Enhancement: A Key Innovation for Chest X-ray Report Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Kang Liu",
        "Zhuoqi Ma",
        "Mengmeng Liu",
        "Zhicheng Jiao",
        "Xiaolu Kang",
        "Qiguang Miao",
        "Kun Xie"
      ],
      "abstract": "A radiology report comprises presentation-style vocabulary, which ensures\nclarity and organization, and factual vocabulary, which provides accurate and\nobjective descriptions based on observable findings. While manually writing\nthese reports is time-consuming and labor-intensive, automatic report\ngeneration offers a promising alternative. A critical step in this process is\nto align radiographs with their corresponding reports. However, existing\nmethods often rely on complete reports for alignment, overlooking the impact of\npresentation-style vocabulary. To address this issue, we propose FSE, a\ntwo-stage Factual Serialization Enhancement method. In Stage 1, we introduce\nfactuality-guided contrastive learning for visual representation by maximizing\nthe semantic correspondence between radiographs and corresponding factual\ndescriptions. In Stage 2, we present evidence-driven report generation that\nenhances diagnostic accuracy by integrating insights from similar historical\ncases structured as factual serialization. Experiments on MIMIC-CXR and IU\nX-ray datasets across specific and general scenarios demonstrate that FSE\noutperforms state-of-the-art approaches in both natural language generation and\nclinical efficacy metrics. Ablation studies further emphasize the positive\neffects of factual serialization in Stage 1 and Stage 2. The code is available\nat https://github.com/mk-runner/FSE.",
      "tldr_zh": "该论文提出 FSE（Factual Serialization Enhancement）方法，作为胸部 X 光报告生成的关键创新，旨在解决现有方法忽略 presentation-style vocabulary 对报告对齐的影响。FSE 采用两阶段策略：Stage 1 通过 factuality-guided contrastive learning 最大化 radiographs 与对应 factual descriptions 的语义对应，以指导视觉表示；Stage 2 则利用 evidence-driven report generation 整合类似历史病例的见解，形成结构化的 factual serialization，提升诊断准确性。在 MIMIC-CXR 和 IU X-ray 数据集上的实验显示，FSE 在自然语言生成和临床效能指标上优于现有方法，消融研究进一步验证了各阶段的积极作用。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "code is available at https://github.com/mk-runner/FSE",
      "pdf_url": "http://arxiv.org/pdf/2405.09586v2",
      "published_date": "2024-05-15 07:56:38 UTC",
      "updated_date": "2024-09-12 03:11:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:46:39.447549"
    },
    {
      "arxiv_id": "2405.13019v2",
      "title": "A Comprehensive Survey of Accelerated Generation Techniques in Large Language Models",
      "title_zh": "大型语言模型中加速生成技术的全面综述",
      "authors": [
        "Mahsa Khoshnoodi",
        "Vinija Jain",
        "Mingye Gao",
        "Malavika Srikanth",
        "Aman Chadha"
      ],
      "abstract": "Despite the crucial importance of accelerating text generation in large\nlanguage models (LLMs) for efficiently producing content, the sequential nature\nof this process often leads to high inference latency, posing challenges for\nreal-time applications. Various techniques have been proposed and developed to\naddress these challenges and improve efficiency. This paper presents a\ncomprehensive survey of accelerated generation techniques in autoregressive\nlanguage models, aiming to understand the state-of-the-art methods and their\napplications. We categorize these techniques into several key areas:\nspeculative decoding, early exiting mechanisms, and non-autoregressive methods.\nWe discuss each category's underlying principles, advantages, limitations, and\nrecent advancements. Through this survey, we aim to offer insights into the\ncurrent landscape of techniques in LLMs and provide guidance for future\nresearch directions in this critical area of natural language processing.",
      "tldr_zh": "这篇论文对 Large Language Models (LLMs) 中加速文本生成的技术的现状进行了全面调查，旨在解决LLMs的顺序生成过程导致的高推理延迟问题，以支持实时应用。论文将这些技术分为三大类：speculative decoding、early exiting mechanisms 和 non-autoregressive methods，并详细讨论了每类的原理、优势、限制以及最新进展。通过此调查，论文提供了对当前LLMs加速领域的深刻洞见，并为未来自然语言处理研究方向提供了指导。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.13019v2",
      "published_date": "2024-05-15 07:36:56 UTC",
      "updated_date": "2024-05-24 07:40:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:46:50.656213"
    },
    {
      "arxiv_id": "2405.09585v3",
      "title": "An Embarrassingly Simple Approach to Enhance Transformer Performance in Genomic Selection for Crop Breeding",
      "title_zh": "翻译失败",
      "authors": [
        "Renqi Chen",
        "Wenwei Han",
        "Haohao Zhang",
        "Haoyang Su",
        "Zhefan Wang",
        "Xiaolei Liu",
        "Hao Jiang",
        "Wanli Ouyang",
        "Nanqing Dong"
      ],
      "abstract": "Genomic selection (GS), as a critical crop breeding strategy, plays a key\nrole in enhancing food production and addressing the global hunger crisis. The\npredominant approaches in GS currently revolve around employing statistical\nmethods for prediction. However, statistical methods often come with two main\nlimitations: strong statistical priors and linear assumptions. A recent trend\nis to capture the non-linear relationships between markers by deep learning.\nHowever, as crop datasets are commonly long sequences with limited samples, the\nrobustness of deep learning models, especially Transformers, remains a\nchallenge. In this work, to unleash the unexplored potential of attention\nmechanism for the task of interest, we propose a simple yet effective\nTransformer-based framework that enables end-to-end training of the whole\nsequence. Via experiments on rice3k and wheat3k datasets, we show that, with\nsimple tricks such as k-mer tokenization and random masking, Transformer can\nachieve overall superior performance against seminal methods on GS tasks of\ninterest.",
      "tldr_zh": "本研究针对基因组选择(Genomic Selection, GS)中统计方法的局限性（如强统计先验和线性假设），提出了一种简单有效的Transformer-based框架，以捕捉标记之间的非线性关系。框架通过k-mer tokenization和random masking等技巧，实现序列的端到端训练，提升Transformer在作物数据集（如长序列和样本有限场景）下的鲁棒性。在rice3k和wheat3k数据集上的实验表明，该方法在GS任务中整体性能优于现有基准方法，展示了Transformer潜力的新应用。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by IJCAI2024. Code is available at\n  https://github.com/RenqiChen/Genomic-Selection",
      "pdf_url": "http://arxiv.org/pdf/2405.09585v3",
      "published_date": "2024-05-15 07:31:06 UTC",
      "updated_date": "2024-06-24 09:56:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:47:03.281853"
    },
    {
      "arxiv_id": "2405.13018v1",
      "title": "Continued Pretraining for Domain Adaptation of Wav2vec2.0 in Automatic Speech Recognition for Elementary Math Classroom Settings",
      "title_zh": "翻译失败",
      "authors": [
        "Ahmed Adel Attia",
        "Dorottya Demszky",
        "Tolulope Ogunremi",
        "Jing Liu",
        "Carol Espy-Wilson"
      ],
      "abstract": "Creating Automatic Speech Recognition (ASR) systems that are robust and\nresilient to classroom conditions is paramount to the development of AI tools\nto aid teachers and students. In this work, we study the efficacy of continued\npretraining (CPT) in adapting Wav2vec2.0 to the classroom domain. We show that\nCPT is a powerful tool in that regard and reduces the Word Error Rate (WER) of\nWav2vec2.0-based models by upwards of 10%. More specifically, CPT improves the\nmodel's robustness to different noises, microphones, classroom conditions as\nwell as classroom demographics. Our CPT models show improved ability to\ngeneralize to different demographics unseen in the labeled finetuning data.",
      "tldr_zh": "本研究探讨了在小学数学课堂环境中，通过持续预训练（CPT）来适应 Wav2vec2.0 模型，以提升自动语音识别（ASR）系统的鲁棒性。结果显示，CPT 显著降低了 Wav2vec2.0 模型的词错误率（WER）高达 10%，并增强了其对不同噪音、麦克风、课堂条件和人口统计学的适应能力。该方法还提高了模型对未见标签微调数据中的人口统计学的泛化性能，为开发适用于课堂的 AI 辅助工具提供了有效途径。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.13018v1",
      "published_date": "2024-05-15 06:59:33 UTC",
      "updated_date": "2024-05-15 06:59:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:47:14.700106"
    },
    {
      "arxiv_id": "2405.09125v1",
      "title": "HAAP: Vision-context Hierarchical Attention Autoregressive with Adaptive Permutation for Scene Text Recognition",
      "title_zh": "翻译失败",
      "authors": [
        "Honghui Chen",
        "Yuhang Qiu",
        "Jiabao Wang",
        "Pingping Chen",
        "Nam Ling"
      ],
      "abstract": "Internal Language Model (LM)-based methods use permutation language modeling\n(PLM) to solve the error correction caused by conditional independence in\nexternal LM-based methods. However, random permutations of human interference\ncause fit oscillations in the model training, and Iterative Refinement (IR)\noperation to improve multimodal information decoupling also introduces\nadditional overhead. To address these issues, this paper proposes the\nHierarchical Attention autoregressive Model with Adaptive Permutation (HAAP) to\nenhance the location-context-image interaction capability, improving\nautoregressive generalization with internal LM. First, we propose Implicit\nPermutation Neurons (IPN) to generate adaptive attention masks to dynamically\nexploit token dependencies. The adaptive masks increase the diversity of\ntraining data and prevent model dependency on a specific order. It reduces the\ntraining overhead of PLM while avoiding training fit oscillations. Second, we\ndevelop Cross-modal Hierarchical Attention mechanism (CHA) to couple context\nand image features. This processing establishes rich positional semantic\ndependencies between context and image while avoiding IR. Extensive\nexperimental results show the proposed HAAP achieves state-of-the-art (SOTA)\nperformance in terms of accuracy, complexity, and latency on several datasets.",
      "tldr_zh": "该论文提出HAAP（Hierarchical Attention Autoregressive Model with Adaptive Permutation），一种用于场景文本识别的模型，旨在解决Permutation Language Modeling (PLM)中随机排列导致的训练拟合震荡（fit oscillations）以及Iterative Refinement (IR)操作带来的额外开销问题。HAAP通过Implicit Permutation Neurons (IPN)生成自适应注意力掩码，动态利用token依赖性，增加训练数据多样性并减少开销，同时避免模型对特定顺序的依赖。论文还引入Cross-modal Hierarchical Attention mechanism (CHA)，耦合上下文和图像特征，建立丰富的语义依赖，而无需IR操作。实验结果显示，HAAP在多个数据集上实现了state-of-the-art (SOTA)性能，在准确性、复杂性和延迟方面均表现出色。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "68T01",
        "I.2.10"
      ],
      "primary_category": "cs.CV",
      "comment": "12 pages, 10 figures",
      "pdf_url": "http://arxiv.org/pdf/2405.09125v1",
      "published_date": "2024-05-15 06:41:43 UTC",
      "updated_date": "2024-05-15 06:41:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:47:28.132905"
    },
    {
      "arxiv_id": "2405.09118v2",
      "title": "BonnBot-I Plus: A Bio-diversity Aware Precise Weed Management Robotic Platform",
      "title_zh": "翻译失败",
      "authors": [
        "Alireza Ahmadi",
        "Michael Halstead",
        "Claus Smitt",
        "Chris McCool"
      ],
      "abstract": "In this article, we focus on the critical tasks of plant protection in arable\nfarms, addressing a modern challenge in agriculture: integrating ecological\nconsiderations into the operational strategy of precision weeding robots like\n\\bbot. This article presents the recent advancements in weed management\nalgorithms and the real-world performance of \\bbot\\ at the University of Bonn's\nKlein-Altendorf campus. We present a novel Rolling-view observation model for\nthe BonnBot-Is weed monitoring section which leads to an average absolute\nweeding performance enhancement of $3.4\\%$. Furthermore, for the first time, we\nshow how precision weeding robots could consider bio-diversity-aware concerns\nin challenging weeding scenarios. We carried out comprehensive weeding\nexperiments in sugar-beet fields, covering both weed-only and mixed crop-weed\nsituations, and introduced a new dataset compatible with precision weeding. Our\nreal-field experiments revealed that our weeding approach is capable of\nhandling diverse weed distributions, with a minimal loss of only $11.66\\%$\nattributable to intervention planning and $14.7\\%$ to vision system limitations\nhighlighting required improvements of the vision system.",
      "tldr_zh": "本研究介绍了 BonnBot-I Plus，一种考虑生物多样性的精密除草机器人平台，旨在将生态因素整合到农业植物保护策略中。论文提出了一种新型 Rolling-view observation model，用于提升 BonnBot-I 的杂草监测性能，导致除草准确率平均提高 3.4%。通过在糖用甜菜田的真实实验，包括杂草-only 和混合作物-杂草场景，该方法成功处理了多样杂草分布，仅有 11.66% 的损失归因于干预规划和 14.7% 归因于视觉系统限制，并引入了一个新的兼容精密除草的数据集，为可持续农业机器人技术提供了重要基础。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG",
        "cs.MA"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.09118v2",
      "published_date": "2024-05-15 06:23:59 UTC",
      "updated_date": "2024-07-04 20:49:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:47:39.756682"
    },
    {
      "arxiv_id": "2405.09111v2",
      "title": "CarDreamer: Open-Source Learning Platform for World Model based Autonomous Driving",
      "title_zh": "Car",
      "authors": [
        "Dechen Gao",
        "Shuangyu Cai",
        "Hanchu Zhou",
        "Hang Wang",
        "Iman Soltani",
        "Junshan Zhang"
      ],
      "abstract": "To safely navigate intricate real-world scenarios, autonomous vehicles must\nbe able to adapt to diverse road conditions and anticipate future events. World\nmodel (WM) based reinforcement learning (RL) has emerged as a promising\napproach by learning and predicting the complex dynamics of various\nenvironments. Nevertheless, to the best of our knowledge, there does not exist\nan accessible platform for training and testing such algorithms in\nsophisticated driving environments. To fill this void, we introduce CarDreamer,\nthe first open-source learning platform designed specifically for developing WM\nbased autonomous driving algorithms. It comprises three key components: 1)\nWorld model backbone: CarDreamer has integrated some state-of-the-art WMs,\nwhich simplifies the reproduction of RL algorithms. The backbone is decoupled\nfrom the rest and communicates using the standard Gym interface, so that users\ncan easily integrate and test their own algorithms. 2) Built-in tasks:\nCarDreamer offers a comprehensive set of highly configurable driving tasks\nwhich are compatible with Gym interfaces and are equipped with empirically\noptimized reward functions. 3) Task development suite: This suite streamlines\nthe creation of driving tasks, enabling easy definition of traffic flows and\nvehicle routes, along with automatic collection of multi-modal observation\ndata. A visualization server allows users to trace real-time agent driving\nvideos and performance metrics through a browser. Furthermore, we conduct\nextensive experiments using built-in tasks to evaluate the performance and\npotential of WMs in autonomous driving. Thanks to the richness and flexibility\nof CarDreamer, we also systematically study the impact of observation modality,\nobservability, and sharing of vehicle intentions on AV safety and efficiency.\nAll code and documents are accessible on\nhttps://github.com/ucd-dare/CarDreamer.",
      "tldr_zh": "该研究引入了CarDreamer，一个开源学习平台，旨在支持基于World Model (WM) 的强化学习 (RL) 算法在自动驾驶领域的开发，帮助车辆适应复杂路况并预测未来事件。平台包括三个核心组件：WM backbone（整合先进WM并通过Gym接口便于算法集成）、内置任务（提供可配置的驾驶任务及优化奖励函数），以及任务开发套件（简化任务创建、支持多模态数据收集和实时可视化）。通过广泛实验，CarDreamer评估了WM在自动驾驶中的性能，并系统研究了观察模态、observability和车辆意图共享对安全和效率的影响。总之，该平台为WM-based自主驾驶算法的训练和测试提供了灵活、可访问的工具，所有代码已在GitHub上公开。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "Dechen Gao, Shuangyu Cai, Hanchu Zhou, Hang Wang contributed equally",
      "pdf_url": "http://arxiv.org/pdf/2405.09111v2",
      "published_date": "2024-05-15 05:57:20 UTC",
      "updated_date": "2024-07-25 23:02:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:47:53.300907"
    },
    {
      "arxiv_id": "2405.09109v2",
      "title": "Motion Prediction with Gaussian Processes for Safe Human-Robot Interaction in Virtual Environments",
      "title_zh": "基于高斯过程的运动预测，用于虚拟环境中的安全人-机器人交互",
      "authors": [
        "Stanley Mugisha",
        "Vamsi Krishna Guda",
        "Christine Chevallereau",
        "Damien Chablat",
        "Matteo Zoppi"
      ],
      "abstract": "Humans use collaborative robots as tools for accomplishing various tasks. The\ninteraction between humans and robots happens in tight shared workspaces.\nHowever, these machines must be safe to operate alongside humans to minimize\nthe risk of accidental collisions. Ensuring safety imposes many constraints,\nsuch as reduced torque and velocity limits during operation, thus increasing\nthe time to accomplish many tasks. However, for applications such as using\ncollaborative robots as haptic interfaces with intermittent contacts for\nvirtual reality applications, speed limitations result in poor user\nexperiences. This research aims to improve the efficiency of a collaborative\nrobot while improving the safety of the human user. We used Gaussian process\nmodels to predict human hand motion and developed strategies for human\nintention detection based on hand motion and gaze to improve the time for the\nrobot and human security in a virtual environment. We then studied the effect\nof prediction. Results from comparisons show that the prediction models\nimproved the robot time by 3\\% and safety by 17\\%. When used alongside gaze,\nprediction with Gaussian process models resulted in an improvement of the robot\ntime by 2\\% and the safety by 13\\%.",
      "tldr_zh": "这篇论文针对虚拟环境中的人机互动安全问题，提出使用高斯过程（Gaussian Processes）模型预测人类手部运动，并结合手部运动和注视数据开发意图检测策略，以提高机器人效率同时确保用户安全。研究方法通过预测模型优化机器人操作，减少速度限制带来的负面影响。结果显示，单纯预测模型使机器人操作时间改善3%和安全提升17%；当结合注视时，进一步将机器人时间改善2%和安全提升13%。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG",
        "I.2.6; I.2.9; I.3.2; H.5.2"
      ],
      "primary_category": "cs.RO",
      "comment": "16 pages",
      "pdf_url": "http://arxiv.org/pdf/2405.09109v2",
      "published_date": "2024-05-15 05:51:41 UTC",
      "updated_date": "2024-05-18 17:47:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:48:05.803090"
    },
    {
      "arxiv_id": "2405.09086v1",
      "title": "Chaos-based reinforcement learning with TD3",
      "title_zh": "基于混沌的强化学习与 TD3",
      "authors": [
        "Toshitaka Matsuki",
        "Yusuke Sakemi",
        "Kazuyuki Aihara"
      ],
      "abstract": "Chaos-based reinforcement learning (CBRL) is a method in which the agent's\ninternal chaotic dynamics drives exploration. This approach offers a model for\nconsidering how the biological brain can create variability in its behavior and\nlearn in an exploratory manner. At the same time, it is a learning model that\nhas the ability to automatically switch between exploration and exploitation\nmodes and the potential to realize higher explorations that reflect what it has\nlearned so far. However, the learning algorithms in CBRL have not been\nwell-established in previous studies and have yet to incorporate recent\nadvances in reinforcement learning. This study introduced Twin Delayed Deep\nDeterministic Policy Gradients (TD3), which is one of the state-of-the-art deep\nreinforcement learning algorithms that can treat deterministic and continuous\naction spaces, to CBRL. The validation results provide several insights. First,\nTD3 works as a learning algorithm for CBRL in a simple goal-reaching task.\nSecond, CBRL agents with TD3 can autonomously suppress their exploratory\nbehavior as learning progresses and resume exploration when the environment\nchanges. Finally, examining the effect of the agent's chaoticity on learning\nshows that extremely strong chaos negatively impacts the flexible switching\nbetween exploration and exploitation.",
      "tldr_zh": "本研究将 Twin Delayed Deep Deterministic Policy Gradients (TD3) 算法引入 Chaos-based reinforcement learning (CBRL)，以利用代理的内部混沌动态驱动探索，并自动在探索和利用模式之间切换。CBRL 通过模仿生物大脑的行为变异，增强了强化学习的灵活性，并在简单目标到达任务中证明了 TD3 的有效性。实验结果显示，CBRL 代理能随着学习进展自主抑制探索行为，并在环境变化时恢复探索；然而，过强的混沌性会负面影响探索与利用的灵活切换，从而为改进 CBRL 提供了关键洞见。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NE"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.09086v1",
      "published_date": "2024-05-15 04:47:31 UTC",
      "updated_date": "2024-05-15 04:47:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:48:16.649913"
    },
    {
      "arxiv_id": "2405.09081v2",
      "title": "Explainable AI for Ship Collision Avoidance: Decoding Decision-Making Processes and Behavioral Intentions",
      "title_zh": "可解释 AI 用于船舶碰撞避免：解码决策过程和行为意图",
      "authors": [
        "Hitoshi Yoshioka",
        "Hirotada Hashimoto"
      ],
      "abstract": "This study developed an explainable AI for ship collision avoidance.\nInitially, a critic network composed of sub-task critic networks was proposed\nto individually evaluate each sub-task in collision avoidance to clarify the AI\ndecision-making processes involved. Additionally, an attempt was made to\ndiscern behavioral intentions through a Q-value analysis and an Attention\nmechanism. The former focused on interpreting intentions by examining the\nincrement of the Q-value resulting from AI actions, while the latter\nincorporated the significance of other ships in the decision-making process for\ncollision avoidance into the learning objective. AI's behavioral intentions in\ncollision avoidance were visualized by combining the perceived collision danger\nwith the degree of attention to other ships. The proposed method was evaluated\nthrough a numerical experiment. The developed AI was confirmed to be able to\nsafely avoid collisions under various congestion levels, and AI's\ndecision-making process was rendered comprehensible to humans. The proposed\nmethod not only facilitates the understanding of DRL-based controllers/systems\nin the ship collision avoidance task but also extends to any task comprising\nsub-tasks.",
      "tldr_zh": "本研究开发了一种可解释 AI 系统，用于船舶碰撞避免，旨在解码 AI 的决策过程和行为意图。研究提出一个由子任务批评网络(critic network)组成的框架，来评估每个子任务的决策细节，同时通过 Q-value 分析和 Attention 机制来辨别行为意图，前者基于 AI 动作导致的 Q-value 增量，后者将其他船只的重要性融入学习目标。实验结果显示，该 AI 能够在各种拥挤条件下安全避撞，并通过可视化感知的碰撞危险和关注度，使决策过程对人类可理解；此外，该方法不仅适用于 DRL-based controllers 的船舶任务，还可扩展到其他包含子任务的领域。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.RO",
      "comment": "24 pases and 15 figures. If you need the program, please contuct us",
      "pdf_url": "http://arxiv.org/pdf/2405.09081v2",
      "published_date": "2024-05-15 04:09:46 UTC",
      "updated_date": "2024-05-20 02:31:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:48:28.285827"
    },
    {
      "arxiv_id": "2405.09056v1",
      "title": "CTS: A Consistency-Based Medical Image Segmentation Model",
      "title_zh": "CTS: 一种基于一致性的医学图像分割模型",
      "authors": [
        "Kejia Zhang",
        "Lan Zhang",
        "Haiwei Pan",
        "Baolong Yu"
      ],
      "abstract": "In medical image segmentation tasks, diffusion models have shown significant\npotential. However, mainstream diffusion models suffer from drawbacks such as\nmultiple sampling times and slow prediction results. Recently, consistency\nmodels, as a standalone generative network, have resolved this issue. Compared\nto diffusion models, consistency models can reduce the sampling times to once,\nnot only achieving similar generative effects but also significantly speeding\nup training and prediction. However, they are not suitable for image\nsegmentation tasks, and their application in the medical imaging field has not\nyet been explored. Therefore, this paper applies the consistency model to\nmedical image segmentation tasks, designing multi-scale feature signal\nsupervision modes and loss function guidance to achieve model convergence.\nExperiments have verified that the CTS model can obtain better medical image\nsegmentation results with a single sampling during the test phase.",
      "tldr_zh": "本文提出CTS模型，将Consistency Models应用于医疗图像分割任务，以解决主流diffusion models的缺点，如多次采样和慢速预测。模型通过设计多尺度特征信号监督模式和损失函数指导，实现高效的模型收敛。实验结果表明，CTS模型在测试阶段只需单次采样即可获得比diffusion models更优的分割性能。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.09056v1",
      "published_date": "2024-05-15 03:07:42 UTC",
      "updated_date": "2024-05-15 03:07:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:48:39.682282"
    },
    {
      "arxiv_id": "2405.09049v2",
      "title": "Perception Without Vision for Trajectory Prediction: Ego Vehicle Dynamics as Scene Representation for Efficient Active Learning in Autonomous Driving",
      "title_zh": "翻译失败",
      "authors": [
        "Ross Greer",
        "Mohan Trivedi"
      ],
      "abstract": "This study investigates the use of trajectory and dynamic state information\nfor efficient data curation in autonomous driving machine learning tasks. We\npropose methods for clustering trajectory-states and sampling strategies in an\nactive learning framework, aiming to reduce annotation and data costs while\nmaintaining model performance. Our approach leverages trajectory information to\nguide data selection, promoting diversity in the training data. We demonstrate\nthe effectiveness of our methods on the trajectory prediction task using the\nnuScenes dataset, showing consistent performance gains over random sampling\nacross different data pool sizes, and even reaching sub-baseline displacement\nerrors at just 50% of the data cost. Our results suggest that sampling typical\ndata initially helps overcome the ''cold start problem,'' while introducing\nnovelty becomes more beneficial as the training pool size increases. By\nintegrating trajectory-state-informed active learning, we demonstrate that more\nefficient and robust autonomous driving systems are possible and practical\nusing low-cost data curation strategies.",
      "tldr_zh": "本研究探讨了在自动驾驶中，使用轨迹和动态状态信息作为场景表示来进行高效的主动学习(active learning)，以优化数据整理过程并减少标注成本。研究提出轨迹状态聚类和采样策略，利用轨迹信息指导数据选择，促进训练数据的多样性。在 nuScenes 数据集的轨迹预测任务上，实验结果显示，该方法比随机采样有持续性能提升，仅用50%数据就达到低于基线的位移错误。该方法还揭示，初始采样典型数据可解决“冷启动问题”，而随着训练池大小增加，引入新颖数据更具优势，从而实现更高效、鲁棒的自动驾驶系统。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV",
        "cs.RO"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.09049v2",
      "published_date": "2024-05-15 02:54:11 UTC",
      "updated_date": "2024-05-20 10:52:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:48:53.633990"
    },
    {
      "arxiv_id": "2405.09037v1",
      "title": "Unmasking Efficiency: Learning Salient Sparse Models in Non-IID Federated Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Riyasat Ohib",
        "Bishal Thapaliya",
        "Gintare Karolina Dziugaite",
        "Jingyu Liu",
        "Vince Calhoun",
        "Sergey Plis"
      ],
      "abstract": "In this work, we propose Salient Sparse Federated Learning (SSFL), a\nstreamlined approach for sparse federated learning with efficient\ncommunication. SSFL identifies a sparse subnetwork prior to training,\nleveraging parameter saliency scores computed separately on local client data\nin non-IID scenarios, and then aggregated, to determine a global mask. Only the\nsparse model weights are communicated each round between the clients and the\nserver. We validate SSFL's effectiveness using standard non-IID benchmarks,\nnoting marked improvements in the sparsity--accuracy trade-offs. Finally, we\ndeploy our method in a real-world federated learning framework and report\nimprovement in communication time.",
      "tldr_zh": "本研究提出了一种名为 SSFL（Salient Sparse Federated Learning）的稀疏联邦学习方法，旨在在 non-IID（非独立同分布）场景中提升通信效率。该方法在训练前通过本地客户端数据计算参数显著性分数，并聚合这些分数以确定全局掩码，从而仅通信稀疏模型权重。实验结果显示，SSFL 在标准 non-IID 基准上显著改善了稀疏性与准确性的权衡，并在真实世界联邦学习框架中降低了通信时间。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DC"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.09037v1",
      "published_date": "2024-05-15 02:13:51 UTC",
      "updated_date": "2024-05-15 02:13:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T08:49:04.232973"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 77,
  "processed_papers_count": 77,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-18T08:49:27.857955"
}