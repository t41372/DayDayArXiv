{
  "date": "2025-10-14",
  "category": "cs.AI",
  "summary": "æ¬¢è¿æ¥åˆ° UTC æ—¶é—´ 2025-10-14 çš„ arXiv ä¸­æ–‡ TLDR å¿«æŠ¥ï¼\n\n## ğŸš€ ä»Šæ—¥æ€»è¯„\nä»Šå¤©çš„ arXiv ç®€ç›´æ˜¯**Agentï¼ˆæ™ºèƒ½ä½“ï¼‰ä¸ Reasoningï¼ˆæ¨ç†ï¼‰**çš„ç‹‚æ¬¢æ—¥ã€‚æœ€å¼•äººæ³¨ç›®çš„æ¦‚å¿µè«è¿‡äº**â€œVibe Codingâ€**çš„æ­£å¼æå‡ºï¼Œè¿™æ ‡å¿—ç€ç¼–ç¨‹èŒƒå¼ä»â€œä»£ç ç”Ÿæˆâ€å‘â€œç»“æœéªŒè¯â€çš„è½¬å˜ã€‚æ­¤å¤–ï¼Œéšç€ OpenAI o1/DeepSeek R1 ç­‰æ¨ç†æ¨¡å‹çš„æµè¡Œï¼Œå­¦æœ¯ç•Œå¼€å§‹æ·±åº¦åæ€**RLVRï¼ˆå¸¦éªŒè¯å¥–åŠ±çš„å¼ºåŒ–å­¦ä¹ ï¼‰**å’Œ**GRPO**ç®—æ³•çš„æ³›åŒ–è¾¹ç•Œã€‚åœ¨å¤šæ¨¡æ€é¢†åŸŸï¼Œ**æ–‡ç”Ÿè§†é¢‘ï¼ˆT2Vï¼‰**çš„å™äº‹è¿è´¯æ€§ç»ˆäºè¿æ¥äº†ä¸¥è‹›çš„ Benchmarkã€‚\n\n---\n\n## ğŸ’» ç¼–ç¨‹æ–°èŒƒå¼ä¸æ·±åº¦ç ”ç©¶ Agent\nä»Šå¤©çš„é‡å¤´æˆæ˜¯â€œVibe Codingâ€æ¦‚å¿µçš„å­¦æœ¯åŒ–ï¼Œä»¥åŠæ·±åº¦ç ”ç©¶ï¼ˆDeep Researchï¼‰Agent çš„è¿›åŒ–ã€‚\n\n**1. A Survey of Vibe Coding with Large Language Models**\n**Vibe Coding ç»¼è¿°ï¼šå¤§è¯­è¨€æ¨¡å‹æ—¶ä»£çš„ç¼–ç¨‹æ–°é£å°š**\n> è¿™æ˜¯ä¸€ä¸ªå…¨æ–°çš„æ¦‚å¿µã€‚â€œVibe Codingâ€æŒ‡çš„æ˜¯å¼€å‘è€…ä¸å†é€è¡Œç†è§£ä»£ç ï¼Œè€Œæ˜¯é€šè¿‡è§‚å¯Ÿè¿è¡Œç»“æœï¼ˆ\"Vibe\"ï¼‰æ¥éªŒè¯ AI ç”Ÿæˆçš„å®ç°ã€‚è¿™ç¯‡ç»¼è¿°åˆ†æäº† 1000 å¤šç¯‡è®ºæ–‡ï¼Œæå‡ºäº†ä¸€ä¸ªåŸºäº**å—é™é©¬å°”å¯å¤«å†³ç­–è¿‡ç¨‹**çš„ç†è®ºæ¡†æ¶ï¼Œå¹¶å°†å¼€å‘æ¨¡å¼åˆ†ç±»ä¸ºâ€œæ— çº¦æŸè‡ªåŠ¨åŒ–â€ã€â€œè¿­ä»£å¯¹è¯åä½œâ€ç­‰ã€‚å®ƒæŒ‡å‡ºæˆåŠŸçš„ Vibe Coding ä¾èµ–äºå¼ºå¤§çš„**ä¸Šä¸‹æ–‡å·¥ç¨‹**å’Œ**ç¯å¢ƒåé¦ˆæœºåˆ¶**ï¼Œè€Œä¸ä»…æ˜¯æ¨¡å‹æœ¬èº«ã€‚\n\n**2. (R)evolution of Programming: Vibe Coding as a Post-Coding Paradigm**\n**ç¼–ç¨‹çš„ï¼ˆRï¼‰æ¼”å˜ï¼šä½œä¸ºåç¼–ç èŒƒå¼çš„ Vibe Coding**\n> è¿™ç¯‡æ–‡ç« ä»äººæœºäº¤äº’ï¼ˆHCIï¼‰è§’åº¦æ¢è®¨äº† Vibe Codingã€‚é€šè¿‡é‡‡è®¿ï¼Œä½œè€…å°†å…¶æ¦‚å¿µåŒ–ä¸º**â€œå…±åŒæ¼‚ç§»â€ï¼ˆco-driftingï¼‰**ï¼Œè€Œéä¼ ç»Ÿçš„â€œå‰¯é©¾é©¶â€ï¼ˆco-pilotingï¼‰ã€‚è¿™ç§æ¨¡å¼æ¨¡ç³Šäº†ä¸“ä¸šå¼€å‘è€…ä¸éå¼€å‘è€…çš„ç•Œé™ï¼Œä½†ä¹Ÿå¸¦æ¥äº†å¯å¤ç°æ€§å’Œå¯ç»´æŠ¤æ€§çš„æŒ‘æˆ˜ã€‚\n\n**3. DeepPlanner: Scaling Planning Capability for Deep Research Agents via Advantage Shaping**\n**DeepPlannerï¼šé€šè¿‡ä¼˜åŠ¿é‡å¡‘æ‰©å±•æ·±åº¦ç ”ç©¶ Agent çš„è§„åˆ’èƒ½åŠ›**\n> é’ˆå¯¹éœ€è¦é•¿ç¨‹è§„åˆ’çš„å¤æ‚ä»»åŠ¡ï¼ˆDeep Researchï¼‰ï¼Œç°æœ‰æ–¹æ³•å¾€å¾€å¿½ç•¥äº†è§„åˆ’é˜¶æ®µçš„ä¼˜åŒ–ã€‚æœ¬æ–‡å‘ç°è§„åˆ’ token æ¯”è¡ŒåŠ¨ token å…·æœ‰æ›´é«˜çš„ç†µï¼ˆä¸ç¡®å®šæ€§ï¼‰ã€‚ä½œè€…æå‡ºäº† DeepPlannerï¼Œä¸€ç§ç«¯åˆ°ç«¯çš„ RL æ¡†æ¶ï¼Œé€šè¿‡**åŸºäºç†µçš„ä¼˜åŠ¿é‡å¡‘**ï¼Œç»™é«˜ç†µ token åˆ†é…æ›´å¤§çš„æ›´æ–°æƒé‡ã€‚åœ¨ 7 ä¸ªåŸºå‡†æµ‹è¯•ä¸­ï¼Œå®ƒä»¥æ›´ä½çš„è®­ç»ƒé¢„ç®—å®ç°äº† SOTAã€‚\n\n**4. ResearStudio: A Human-Intervenable Framework for Building Controllable Deep-Research Agents**\n**ResearStudioï¼šæ„å»ºå¯æ§æ·±åº¦ç ”ç©¶ Agent çš„äººç±»å¹²é¢„æ¡†æ¶**\n> ç›®å‰çš„ Deep Research Agent å¾€å¾€æ˜¯â€œå‘å°„åä¸ç®¡â€ï¼ˆfire-and-forgetï¼‰ã€‚ResearStudio æå‡ºäº†ä¸€ä¸ª**â€œååŒè½¦é—´â€**è®¾è®¡ï¼Œå…è®¸ç”¨æˆ·å®æ—¶æš‚åœã€ç¼–è¾‘è®¡åˆ’ã€ä¿®æ”¹ä»£ç å¹¶æ¢å¤è¿è¡Œã€‚è¿™ç§è®¾è®¡åœ¨ GAIA åŸºå‡†æµ‹è¯•ä¸­è¶…è¶Šäº† OpenAI çš„ DeepResearch å’Œ Manusï¼Œè¯æ˜äº†ç»†ç²’åº¦çš„äººç±»æ§åˆ¶ä¸è‡ªåŠ¨åŒ–å¯ä»¥å…±å­˜ã€‚\n\n---\n\n## ğŸ§  æ¨ç†æ¨¡å‹ï¼ˆReasoning Modelsï¼‰çš„æœºç†ä¸åæ€\næ¨ç†æ¨¡å‹ï¼ˆå¦‚ o1, R1ï¼‰ç«çƒ­ï¼Œä½†å­¦æœ¯ç•Œå¼€å§‹å†·é™åˆ†æå…¶å±€é™æ€§ã€‚\n\n**5. Can GRPO Help LLMs Transcend Their Pretraining Origin?**\n**GRPO èƒ½å¸®åŠ© LLM è¶…è¶Šå…¶é¢„è®­ç»ƒèµ·æºå—ï¼Ÿ**\n> **æ·±åº¦å¥½æ–‡**ã€‚GRPOï¼ˆGroup Relative Policy Optimizationï¼‰æ˜¯æå‡ LLM æ¨ç†èƒ½åŠ›çš„ä¸»æµç®—æ³•ã€‚ä½†è¿™ç¯‡è®ºæ–‡è¯æ˜ï¼ŒGRPO æœ¬è´¨ä¸Šæ˜¯ä¸€ç§**ä¿å®ˆçš„é‡åŠ æƒæœºåˆ¶ï¼ˆconservative reweighting schemeï¼‰**ã€‚å®éªŒè¡¨æ˜ï¼ŒGRPO åªæœ‰åœ¨ç›®æ ‡ä»»åŠ¡ä¸é¢„è®­ç»ƒåè§ä¸€è‡´æ—¶æ‰èƒ½æå‡ OODï¼ˆåˆ†å¸ƒå¤–ï¼‰æ³›åŒ–èƒ½åŠ›ï¼›å®ƒæ— æ³•è®©æ¨¡å‹å‘ç°å…¨æ–°çš„è§£å†³æ–¹æ¡ˆï¼Œæ›´å¤šæ˜¯â€œç£¨åˆ©â€äº†é¢„è®­ç»ƒä¸­å·²æœ‰çš„çŸ¥è¯†ã€‚\n\n**6. ThinkPilot: Steering Reasoning Models via Automated Think-prefixes Optimization**\n**ThinkPilotï¼šé€šè¿‡è‡ªåŠ¨ä¼˜åŒ–â€œæ€è€ƒå‰ç¼€â€å¼•å¯¼æ¨ç†æ¨¡å‹**\n> é’ˆå¯¹æ¨ç†æ¨¡å‹æ•ˆç‡ä½æˆ–æ¨ç†åç¦»ç›®æ ‡çš„é—®é¢˜ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§æ— éœ€è®­ç»ƒçš„æ–¹æ³•ã€‚é€šè¿‡è¿›åŒ–ç®—æ³•è‡ªåŠ¨ç”Ÿæˆ**â€œæ€è€ƒå‰ç¼€â€ï¼ˆthink-prefixesï¼‰**ï¼Œå¼•å¯¼æ¨¡å‹çš„æ¨ç†è¡Œä¸ºã€‚å®éªŒæ˜¾ç¤ºï¼Œè¿™èƒ½æ˜¾è‘—æ”¹å–„å‡†ç¡®ç‡ä¸é•¿åº¦çš„æƒè¡¡ï¼Œç”šè‡³å°† DeepSeek-R1 è’¸é¦æ¨¡å‹çš„æ‹’ç»ç‡ä» 27% é™è‡³ 0.7%ã€‚\n\n**7. Demystifying Hybrid Thinking: Can LLMs Truly Switch Between Think and No-Think?**\n**æ­ç§˜æ··åˆæ€ç»´ï¼šLLM çœŸçš„èƒ½åœ¨â€œæ€è€ƒâ€ä¸â€œä¸æ€è€ƒâ€é—´åˆ‡æ¢å—ï¼Ÿ**\n> æˆ‘ä»¬å¸Œæœ›æ¨¡å‹åœ¨ç®€å•é—®é¢˜ä¸Šç›´æ¥å›ç­”ï¼Œå¤æ‚é—®é¢˜ä¸Šè¿›è¡Œæ¨ç†ï¼ˆCoTï¼‰ã€‚ä½†å®éªŒå‘ç°ï¼Œå½“å‰çš„æ··åˆæ€ç»´æ¨¡å‹å­˜åœ¨**æ¨¡å¼åˆ†ç¦»ä¸å½»åº•**çš„é—®é¢˜â€”â€”æ¨ç†è¡Œä¸ºä¼šâ€œæ³„æ¼â€åˆ°ç›´æ¥å›ç­”æ¨¡å¼ä¸­ã€‚ä½œè€…æå‡ºäº†æ”¹è¿›çš„è®­ç»ƒé…æ–¹ï¼Œæ˜¾è‘—å‡å°‘äº†ä¸å¿…è¦çš„æ¨ç† tokenã€‚\n\n---\n\n## ğŸ¬ å¤šæ¨¡æ€ï¼šè§†é¢‘å™äº‹ä¸ 3D ç”Ÿæˆ\næ–‡ç”Ÿè§†é¢‘æ¨¡å‹ç”»è´¨è™½å¥½ï¼Œä½†è®²æ•…äº‹èƒ½åŠ›å¦‚ä½•ï¼Ÿ\n\n**8. SeqBench: Benchmarking Sequential Narrative Generation in Text-to-Video Models**\n**SeqBenchï¼šæ–‡ç”Ÿè§†é¢‘æ¨¡å‹åºåˆ—å™äº‹ç”ŸæˆåŸºå‡†æµ‹è¯•**\n> ç°æœ‰çš„ T2V è¯„æµ‹è¿‡äºå…³æ³¨ç”»è´¨ã€‚SeqBench ä¸“æ³¨äº**å™äº‹è¿è´¯æ€§**ã€‚è¯„æµ‹äº† 8 ä¸ª SOTA æ¨¡å‹åå‘ç°ï¼šç°æœ‰æ¨¡å‹åœ¨å¤šåŠ¨ä½œåºåˆ—ä¸­éš¾ä»¥ä¿æŒ**å¯¹è±¡çŠ¶æ€ä¸€è‡´æ€§**ï¼ˆå¦‚æ‰‹é‡Œæ‹¿ç€ä¸œè¥¿åæ¥ä¸è§äº†ï¼‰ï¼Œä¸”éš¾ä»¥å¤„ç†å¤šå¯¹è±¡çš„ç‰©ç†åˆç†æ€§ã€‚\n\n**9. SceneAdapt: Scene-aware Adaptation of Human Motion Diffusion**\n**SceneAdaptï¼šäººä½“åŠ¨ä½œæ‰©æ•£çš„åœºæ™¯æ„ŸçŸ¥é€‚é…**\n> ç”Ÿæˆçš„äººä½“åŠ¨ä½œå¾€å¾€å¿½ç•¥å‘¨å›´ç¯å¢ƒã€‚SceneAdapt é€šè¿‡ä¸¤ä¸ªé˜¶æ®µï¼ˆæ’å€¼å’Œåœºæ™¯æ„ŸçŸ¥æ’å€¼ï¼‰å°†åœºæ™¯æ„è¯†æ³¨å…¥æ–‡æœ¬é©±åŠ¨çš„åŠ¨ä½œæ¨¡å‹ã€‚æ ¸å¿ƒåˆ›æ–°æ˜¯å¼•å…¥äº†**åœºæ™¯æ¡ä»¶å±‚**ï¼Œé€šè¿‡äº¤å‰æ³¨æ„åŠ›è‡ªé€‚åº”åœ°æŸ¥è¯¢å±€éƒ¨åœºæ™¯å‡ ä½•ä¿¡æ¯ã€‚\n\n**10. USplat4D: Uncertainty Matters in Dynamic Gaussian Splatting**\n**USplat4Dï¼šåŠ¨æ€é«˜æ–¯æ³¼æº…ä¸­çš„ä¸ç¡®å®šæ€§å¾ˆé‡è¦**\n> é’ˆå¯¹å•ç›® 4D é‡å»ºä¸­çš„é®æŒ¡å’Œæ¼‚ç§»é—®é¢˜ï¼Œæœ¬æ–‡æå‡ºäº†**ä¸ç¡®å®šæ€§æ„ŸçŸ¥**çš„åŠ¨æ€ Gaussian Splattingã€‚æ ¸å¿ƒè§‚ç‚¹æ˜¯ï¼šè·¨è§†å›¾å’Œè·¨æ—¶é—´è¢«åå¤è§‚æµ‹åˆ°çš„é«˜æ–¯ç‚¹æ›´å¯é ã€‚é€šè¿‡å»ºæ¨¡æ¯ä¸ªé«˜æ–¯ç‚¹éšæ—¶é—´å˜åŒ–çš„ä¸ç¡®å®šæ€§ï¼Œæ„å»ºæ—¶ç©ºå›¾è¿›è¡Œä¼˜åŒ–ï¼Œæ˜¾è‘—æå‡äº†é®æŒ¡ä¸‹çš„å‡ ä½•ç¨³å®šæ€§ã€‚\n\n---\n\n## ğŸ›¡ï¸ å®‰å…¨ã€å¹»è§‰ä¸å¯¹é½\néšç€ Agent èƒ½åŠ›å¢å¼ºï¼Œå®‰å…¨éšæ‚£ä¹Ÿåœ¨å‡çº§ã€‚\n\n**11. MCP Security Bench (MSB): Benchmarking Attacks Against Model Context Protocol in LLM Agents**\n**MSBï¼šé’ˆå¯¹ LLM Agent æ¨¡å‹ä¸Šä¸‹æ–‡åè®®ï¼ˆMCPï¼‰çš„æ”»å‡»åŸºå‡†æµ‹è¯•**\n> **Model Context Protocol (MCP)** æ˜¯ Anthropic ç­‰æ¨è¡Œçš„è¿æ¥ AI ä¸æ•°æ®çš„æ ‡å‡†ã€‚æœ¬æ–‡æ˜¯é¦–ä¸ªé’ˆå¯¹ MCP çš„å®‰å…¨è¯„æµ‹ã€‚ä½œè€…åˆ†ç±»äº† 12 ç§æ”»å‡»æ–¹å¼ï¼ˆå¦‚åç§°å†²çªã€å·¥å…·æè¿°ä¸­çš„æç¤ºæ³¨å…¥ã€ä¼ªé€ é”™è¯¯å‡çº§ç­‰ï¼‰ã€‚ç»“è®ºå¾ˆæ‰å¿ƒï¼š**å·¥å…·è°ƒç”¨å’ŒæŒ‡ä»¤éµå¾ªèƒ½åŠ›è¶Šå¼ºçš„æ¨¡å‹ï¼Œè¶Šå®¹æ˜“å—åˆ°æ”»å‡»ã€‚**\n\n**12. Credal Transformer: A Principled Approach for Quantifying and Mitigating Hallucinations**\n**Credal Transformerï¼šé‡åŒ–å’Œç¼“è§£ LLM å¹»è§‰çš„åŸåˆ™æ€§æ–¹æ³•**\n> ä½œè€…è®¤ä¸º Transformer çš„ Softmax å‡½æ•°é€šè¿‡â€œåç¼©â€ä¸ç¡®å®šæ€§åˆ¶é€ äº†â€œäººä¸ºçš„ç¡®ä¿¡â€ã€‚æœ¬æ–‡æå‡ºäº†**Credal Attention Mechanism (CAM)**ï¼ŒåŸºäºè¯æ®ç†è®ºï¼ˆevidential theoryï¼‰ï¼Œè¾“å‡ºä¸€ä¸ªâ€œä¿¡åº¦é›†â€ï¼ˆcredal setï¼‰è€Œéå•ä¸€æ¦‚ç‡åˆ†å¸ƒã€‚è¿™è®©æ¨¡å‹åœ¨è¯æ®ä¸è¶³æ—¶èƒ½è¾“å‡ºâ€œå¼¥æ•£â€çš„åˆ†å¸ƒï¼Œä»è€Œæœ‰æ•ˆè¯†åˆ«å¹¶æ‹’ç»å›ç­”æœªçŸ¥é—®é¢˜ã€‚\n\n**13. Guarding the Guardrails: A Taxonomy-Driven Approach to Jailbreak Detection**\n**å®ˆæŠ¤æŠ¤æ ï¼šåŸºäºåˆ†ç±»æ³•çš„è¶Šç‹±æ£€æµ‹æ–¹æ³•**\n> ç»„ç»‡äº†ä¸€åœºçº¢é˜ŸæŒ‘æˆ˜èµ›ï¼Œæ•´ç†äº† 50 ç§è¶Šç‹±ç­–ç•¥çš„å±‚çº§åˆ†ç±»æ³•ï¼ŒåŒ…æ‹¬**è®¤çŸ¥è¿‡è½½ï¼ˆCognitive Overloadï¼‰**ã€**ä¼ªè£…ï¼ˆImpersonationï¼‰**ç­‰ã€‚å¹¶å‘å¸ƒäº†ä¸€ä¸ªåŒ…å« 1364 ä¸ªå¤šè½®å¯¹æŠ—å¯¹è¯çš„æ„å¤§åˆ©è¯­æ•°æ®é›†ã€‚\n\n---\n\n## ğŸ”¬ AI for Science (Math & Bio)\n\n**14. Ax-Prover: A Deep Reasoning Agentic Framework for Theorem Proving**\n**Ax-Proverï¼šç”¨äºæ•°å­¦å’Œé‡å­ç‰©ç†å®šç†è¯æ˜çš„æ·±åº¦æ¨ç† Agent æ¡†æ¶**\n> ç»“åˆäº† LLM çš„åˆ›é€ æ€§æ¨ç†å’Œ Lean è¯æ˜åŠ©æ‰‹ï¼ˆé€šè¿‡ MCP åè®®è¿æ¥ï¼‰çš„å½¢å¼åŒ–éªŒè¯èƒ½åŠ›ã€‚åœ¨æŠ½è±¡ä»£æ•°å’Œé‡å­ç†è®ºçš„æ–°åŸºå‡†ä¸Šï¼Œè¡¨ç°è¿œè¶…ç°æœ‰ä¸“ç”¨è¯æ˜å™¨ã€‚\n\n**15. Chinese ModernBERT with Whole-Word Masking**\n**Chinese ModernBERTï¼šå¸¦å…¨è¯æ©ç çš„ä¸­æ–‡ ModernBERT**\n> è¿™æ˜¯ä¸€ä¸ªä»é›¶è®­ç»ƒçš„ä¸­æ–‡ç¼–ç å™¨ã€‚ç‰¹ç‚¹ï¼šé’ˆå¯¹ä¸­æ–‡ä¼˜åŒ–çš„ 32k BPE è¯è¡¨ï¼ˆåŒ…å«å¸¸ç”¨è¯ç¼€ï¼‰ï¼Œ**åŠ¨æ€å…¨è¯æ©ç ï¼ˆWWMï¼‰**ï¼Œä»¥åŠ 8192 çš„é•¿ä¸Šä¸‹æ–‡æ”¯æŒã€‚åœ¨æ£€ç´¢ä»»åŠ¡ä¸Šè¡¨ç°ä¼˜å¼‚ï¼Œä¸”æä¾›äº† bf16 ä¸‹çš„é«˜ååé‡ã€‚\n\n**16. FetalMind: Epistemic-aware Vision-Language Foundation Model for Fetal Ultrasound**\n**FetalMindï¼šç”¨äºèƒå„¿è¶…å£°è§£è¯»çš„è®¤çŸ¥æ„ŸçŸ¥è§†è§‰-è¯­è¨€åŸºç¡€æ¨¡å‹**\n> èƒå„¿è¶…å£°å›¾åƒæå…¶å¤æ‚ã€‚FetalMind å¼•å…¥äº†**æ˜¾è‘—è®¤çŸ¥è§£è€¦ï¼ˆSEDï¼‰**ï¼Œé€šè¿‡ä¸“å®¶æ„å»ºçš„äºŒåˆ†å›¾æ¥è§£è€¦è§†å›¾ä¸ç–¾ç—…çš„å…³è”ã€‚ä½œè€…è¿˜å‘å¸ƒäº†é¦–ä¸ªå¤§è§„æ¨¡èƒå„¿è¶…å£°æŠ¥å‘Šæ•°æ®é›† **FetalSigma-1M**ã€‚\n\n---\n\n## âš™ï¸ åŸºç¡€è®¾æ–½ä¸æ•ˆç‡\n\n**17. KVCOMM: Online Cross-context KV-cache Communication for Multi-agent Systems**\n**KVCOMMï¼šå¤šæ™ºèƒ½ä½“ç³»ç»Ÿä¸­çš„åœ¨çº¿è·¨ä¸Šä¸‹æ–‡ KV-Cache é€šä¿¡**\n> å¤š Agent åä½œæ—¶ï¼Œä¸Šä¸‹æ–‡å¾€å¾€å¤§é‡é‡å¤ã€‚KVCOMM å…è®¸ Agent ä¹‹é—´**é‡ç”¨ KV-Cache**ï¼Œå³ä½¿å‰ç¼€ä¸åŒä¹Ÿèƒ½é€šè¿‡â€œé”šç‚¹â€æ± æ¥å¯¹é½ç¼“å­˜åç§»ã€‚åœ¨ 5 ä¸ª Agent çš„åä½œä¸­ï¼Œæ¨ç†é€Ÿåº¦æå‡äº† **7.8 å€**ã€‚\n\n**18. Laminar: A Scalable Asynchronous RL Post-Training Framework**\n**Laminarï¼šå¯æ‰©å±•çš„å¼‚æ­¥ RL åè®­ç»ƒæ¡†æ¶**\n> é’ˆå¯¹ LLM çš„ RL åè®­ç»ƒï¼ˆå¦‚ PPOï¼‰ï¼Œç°æœ‰çš„åŒæ­¥æ›´æ–°æ•ˆç‡å¤ªä½ã€‚Laminar é‡‡ç”¨**è½¨è¿¹çº§å¼‚æ­¥**ï¼Œå®Œå…¨è§£è€¦äº† Actor å’Œ Learnerï¼Œå¹¶å¼•å…¥åŠ¨æ€é‡æ‰“åŒ…æœºåˆ¶å¤„ç†ç”Ÿæˆé•¿åº¦çš„é•¿å°¾åˆ†å¸ƒï¼Œè®­ç»ƒååé‡æå‡äº† 5.48 å€ã€‚",
  "papers": [
    {
      "arxiv_id": "2510.13044v1",
      "title": "SceneAdapt: Scene-aware Adaptation of Human Motion Diffusion",
      "title_zh": "SceneAdaptï¼šäººä½“è¿åŠ¨æ‰©æ•£çš„åœºæ™¯æ„ŸçŸ¥é€‚é…",
      "authors": [
        "Jungbin Cho",
        "Minsu Kim",
        "Jisoo Kim",
        "Ce Zheng",
        "Laszlo A. Jeni",
        "Ming-Hsuan Yang",
        "Youngjae Yu",
        "Seonjoo Kim"
      ],
      "abstract": "Human motion is inherently diverse and semantically rich, while also shaped by the surrounding scene. However, existing motion generation approaches address either motion semantics or scene-awareness in isolation, since constructing large-scale datasets with both rich text--motion coverage and precise scene interactions is extremely challenging. In this work, we introduce SceneAdapt, a framework that injects scene awareness into text-conditioned motion models by leveraging disjoint scene--motion and text--motion datasets through two adaptation stages: inbetweening and scene-aware inbetweening. The key idea is to use motion inbetweening, learnable without text, as a proxy task to bridge two distinct datasets and thereby inject scene-awareness to text-to-motion models. In the first stage, we introduce keyframing layers that modulate motion latents for inbetweening while preserving the latent manifold. In the second stage, we add a scene-conditioning layer that injects scene geometry by adaptively querying local context through cross-attention. Experimental results show that SceneAdapt effectively injects scene awareness into text-to-motion models, and we further analyze the mechanisms through which this awareness emerges. Code and models will be released.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† SceneAdaptï¼Œè¿™æ˜¯ä¸€ä¸ªæ—¨åœ¨å°†åœºæ™¯æ„ŸçŸ¥èƒ½åŠ›æ³¨å…¥æ–‡æœ¬é©±åŠ¨çš„äººä½“è¿åŠ¨ç”Ÿæˆæ¨¡å‹ (text-to-motion models) çš„æ¡†æ¶ã€‚é’ˆå¯¹ç°æœ‰æ–¹æ³•åœ¨è¿åŠ¨è¯­ä¹‰å’Œåœºæ™¯æ„ŸçŸ¥æ–¹é¢ç›¸äº’å­¤ç«‹çš„æŒ‘æˆ˜ï¼ŒSceneAdapt åˆ©ç”¨ motion inbetweening ä½œä¸ºä»£ç†ä»»åŠ¡ï¼Œé€šè¿‡ä¸¤ä¸ªé€‚é…é˜¶æ®µå°†åœºæ™¯ä¿¡æ¯æ³¨å…¥åˆ°é¢„è®­ç»ƒæ¨¡å‹ä¸­ã€‚åœ¨ç¬¬ä¸€é˜¶æ®µï¼Œæ¡†æ¶å¼•å…¥äº†å…³é”®å¸§å±‚ (keyframing layers) æ¥è°ƒèŠ‚è¿åŠ¨æ½œå˜é‡ï¼ŒåŒæ—¶ç¡®ä¿ä¸ç ´ååŸæœ‰çš„æ½œæµå½¢ (latent manifold)ã€‚ç¬¬äºŒé˜¶æ®µåˆ™æ·»åŠ äº†åœºæ™¯è°ƒèŠ‚å±‚ (scene-conditioning layer)ï¼Œé€šè¿‡äº¤å‰æ³¨æ„åŠ› (cross-attention) æœºåˆ¶è‡ªé€‚åº”åœ°æŸ¥è¯¢å±€éƒ¨ä¸Šä¸‹æ–‡å¹¶æ³¨å…¥åœºæ™¯å‡ ä½• (scene geometry) ä¿¡æ¯ã€‚å®éªŒç»“æœè¯æ˜ï¼ŒSceneAdapt èƒ½å¤Ÿæœ‰æ•ˆåœ°åœ¨æ–‡æœ¬åˆ°è¿åŠ¨æ¨¡å‹ä¸­å®ç°ç²¾å‡†çš„åœºæ™¯æ„ŸçŸ¥ï¼Œå¹¶æ·±å…¥åˆ†æäº†è¿™ç§æ„ŸçŸ¥èƒ½åŠ›çš„ç”Ÿæˆæœºåˆ¶ã€‚è¯¥æ–¹æ³•æˆåŠŸå…‹æœäº†å¤§è§„æ¨¡æ ‡æ³¨æ•°æ®é›†ç¼ºå¤±çš„é™åˆ¶ï¼Œä¸ºç”Ÿæˆå…¼å…·è¯­ä¹‰ä¸°å¯Œæ€§å’Œç¯å¢ƒäº¤äº’æ„Ÿçš„äººä½“è¿åŠ¨æä¾›äº†æ–°æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "15 pages",
      "pdf_url": "https://arxiv.org/pdf/2510.13044v1",
      "published_date": "2025-10-14 23:42:10 UTC",
      "updated_date": "2025-10-14 23:42:10 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:18:33.782613+00:00"
    },
    {
      "arxiv_id": "2510.13042v1",
      "title": "SeqBench: Benchmarking Sequential Narrative Generation in Text-to-Video Models",
      "title_zh": "SeqBenchï¼šæ–‡ç”Ÿè§†é¢‘æ¨¡å‹è¿ç»­å™äº‹ç”Ÿæˆè¯„æµ‹åŸºå‡†",
      "authors": [
        "Zhengxu Tang",
        "Zizheng Wang",
        "Luning Wang",
        "Zitao Shuai",
        "Chenhao Zhang",
        "Siyu Qian",
        "Yirui Wu",
        "Bohao Wang",
        "Haosong Rao",
        "Zhenyu Yang",
        "Chenwei Wu"
      ],
      "abstract": "Text-to-video (T2V) generation models have made significant progress in creating visually appealing videos. However, they struggle with generating coherent sequential narratives that require logical progression through multiple events. Existing T2V benchmarks primarily focus on visual quality metrics but fail to evaluate narrative coherence over extended sequences. To bridge this gap, we present SeqBench, a comprehensive benchmark for evaluating sequential narrative coherence in T2V generation. SeqBench includes a carefully designed dataset of 320 prompts spanning various narrative complexities, with 2,560 human-annotated videos generated from 8 state-of-the-art T2V models. Additionally, we design a Dynamic Temporal Graphs (DTG)-based automatic evaluation metric, which can efficiently capture long-range dependencies and temporal ordering while maintaining computational efficiency. Our DTG-based metric demonstrates a strong correlation with human annotations. Through systematic evaluation using SeqBench, we reveal critical limitations in current T2V models: failure to maintain consistent object states across multi-action sequences, physically implausible results in multi-object scenarios, and difficulties in preserving realistic timing and ordering relationships between sequential actions. SeqBench provides the first systematic framework for evaluating narrative coherence in T2V generation and offers concrete insights for improving sequential reasoning capabilities in future models. Please refer to https://videobench.github.io/SeqBench.github.io/ for more details.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ Text-to-Video (T2V) ç”Ÿæˆæ¨¡å‹åœ¨å¤„ç†å…·æœ‰é€»è¾‘è¿›åº¦çš„å¤šäº‹ä»¶åºåˆ—å™äº‹æ—¶çš„å±€é™æ€§ï¼Œæå‡ºäº† SeqBenchï¼Œè¿™æ˜¯ä¸€ä¸ªæ—¨åœ¨è¯„ä¼° T2V ç”Ÿæˆä¸­åºåˆ—å™äº‹è¿è´¯æ€§çš„å…¨é¢åŸºå‡†ã€‚SeqBench åŒ…å« 320 ä¸ªæ¶µç›–å¤šç§å™äº‹å¤æ‚åº¦çš„æç¤ºè¯ï¼Œä»¥åŠç”± 8 ä¸ªå…ˆè¿› T2V æ¨¡å‹ç”Ÿæˆçš„ 2,560 ä¸ªç»è¿‡äººå·¥æ ‡æ³¨çš„è§†é¢‘ã€‚æ­¤å¤–ï¼Œç ”ç©¶å›¢é˜Ÿè®¾è®¡äº†åŸºäº Dynamic Temporal Graphs (DTG) çš„è‡ªåŠ¨è¯„ä¼°æŒ‡æ ‡ï¼Œèƒ½å¤Ÿé«˜æ•ˆæ•æ‰é•¿ç¨‹ä¾èµ–å’Œæ—¶é—´é¡ºåºï¼Œå¹¶ä¸äººå·¥æ ‡æ³¨ç»“æœè¡¨ç°å‡ºå¼ºç›¸å…³æ€§ã€‚ç³»ç»Ÿæ€§è¯„ä¼°æ­ç¤ºäº†å½“å‰æ¨¡å‹åœ¨ç»´æŒå¤šåŠ¨ä½œåºåˆ—ä¸­å¯¹è±¡çŠ¶æ€ä¸€è‡´æ€§ã€å¤šå¯¹è±¡åœºæ™¯çš„ç‰©ç†åˆç†æ€§ä»¥åŠåŠ¨ä½œé—´çš„æ—¶é—´ä¸é¡ºåºå…³ç³»æ–¹é¢çš„å…³é”®ç¼ºé™·ã€‚ä½œä¸ºé¦–ä¸ªç³»ç»Ÿæ€§è¯„ä¼° T2V å™äº‹è¿è´¯æ€§çš„æ¡†æ¶ï¼ŒSeqBench ä¸ºæå‡æœªæ¥æ¨¡å‹çš„åºåˆ—æ¨ç†èƒ½åŠ›æä¾›äº†å…·ä½“çš„ç ”ç©¶æ–¹å‘ä¸è§è§£ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.13042v1",
      "published_date": "2025-10-14 23:40:57 UTC",
      "updated_date": "2025-10-14 23:40:57 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:18:34.677381+00:00"
    },
    {
      "arxiv_id": "2510.13040v1",
      "title": "Randomness and Interpolation Improve Gradient Descent",
      "title_zh": "éšæœºæ€§ä¸æ’å€¼åŠ©åŠ›æ¢¯åº¦ä¸‹é™ç®—æ³•æ”¹è¿›",
      "authors": [
        "Jiawen Li",
        "Pascal Lefevre",
        "Anwar Pp Abdul Majeed"
      ],
      "abstract": "Based on Stochastic Gradient Descent (SGD), the paper introduces two optimizers, named Interpolational Accelerating Gradient Descent (IAGD) as well as Noise-Regularized Stochastic Gradient Descent (NRSGD). IAGD leverages second-order Newton Interpolation to expedite the convergence process during training, assuming relevancy in gradients between iterations. To avoid over-fitting, NRSGD incorporates a noise regularization technique that introduces controlled noise to the gradients during the optimization process. Comparative experiments of this research are conducted on the CIFAR-10, and CIFAR-100 datasets, benchmarking different CNNs(Convolutional Neural Networks) with IAGD and NRSGD against classical optimizers in Keras Package. Results demonstrate the potential of those two viable improvement methods in SGD, implicating the effectiveness of the advancements.",
      "tldr_zh": "è¯¥ç ”ç©¶åŸºäº Stochastic Gradient Descent (SGD) æå‡ºäº†ä¸¤ç§æ”¹è¿›å‹ä¼˜åŒ–å™¨ï¼Œåˆ†åˆ«æ˜¯ Interpolational Accelerating Gradient Descent (IAGD) å’Œ Noise-Regularized Stochastic Gradient Descent (NRSGD)ã€‚IAGD æ ¸å¿ƒåœ¨äºåˆ©ç”¨äºŒé˜¶ Newton Interpolation æŠ€æœ¯ï¼Œé€šè¿‡åˆ©ç”¨è¿­ä»£é—´çš„æ¢¯åº¦ç›¸å…³æ€§æ¥åŠ é€Ÿæ¨¡å‹çš„æ”¶æ•›è¿‡ç¨‹ã€‚NRSGD åˆ™é€šè¿‡åœ¨æ¢¯åº¦ä¼˜åŒ–ä¸­å¼•å…¥å—æ§çš„ noise regularizationï¼Œä»¥æå‡æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›å¹¶é˜²æ­¢ over-fittingã€‚ç ”ç©¶äººå‘˜åœ¨ CIFAR-10 å’Œ CIFAR-100 æ•°æ®é›†ä¸Šï¼Œé’ˆå¯¹å¤šç§ Convolutional Neural Networks (CNNs) è¿›è¡Œäº†å¯¹æ¯”å®éªŒã€‚é€šè¿‡ä¸ Keras è½¯ä»¶åŒ…ä¸­çš„ç»å…¸ä¼˜åŒ–å™¨è¿›è¡Œ benchmarkï¼Œå®éªŒç»“æœå……åˆ†è¯æ˜äº† IAGD ä¸ NRSGD åœ¨ SGD åŸºç¡€ä¸Šçš„æ”¹è¿›æ½œåŠ›å’Œå®é™…æœ‰æ•ˆæ€§ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.13040v1",
      "published_date": "2025-10-14 23:32:01 UTC",
      "updated_date": "2025-10-14 23:32:01 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:18:42.473238+00:00"
    },
    {
      "arxiv_id": "2510.13036v1",
      "title": "Repairing Reward Functions with Human Feedback to Mitigate Reward Hacking",
      "title_zh": "åˆ©ç”¨äººç±»åé¦ˆä¿®å¤å¥–åŠ±å‡½æ•°ä»¥ç¼“è§£å¥–åŠ±é»‘å®¢ç°è±¡",
      "authors": [
        "Stephane Hatgis-Kessell",
        "Logan Mondal Bhamidipaty",
        "Emma Brunskill"
      ],
      "abstract": "Human-designed reward functions for reinforcement learning (RL) agents are frequently misaligned with the humans' true, unobservable objectives, and thus act only as proxies. Optimizing for a misspecified proxy reward function often induces reward hacking, resulting in a policy misaligned with the human's true objectives. An alternative is to perform RL from human feedback, which involves learning a reward function from scratch by collecting human preferences over pairs of trajectories. However, building such datasets is costly. To address the limitations of both approaches, we propose Preference-Based Reward Repair (PBRR): an automated iterative framework that repairs a human-specified proxy reward function by learning an additive, transition-dependent correction term from preferences. A manually specified reward function can yield policies that are highly suboptimal under the ground-truth objective, yet corrections on only a few transitions may suffice to recover optimal performance. To identify and correct for those transitions, PBRR uses a targeted exploration strategy and a new preference-learning objective. We prove in tabular domains PBRR has a cumulative regret that matches, up to constants, that of prior preference-based RL methods. In addition, on a suite of reward-hacking benchmarks, PBRR consistently outperforms baselines that learn a reward function from scratch from preferences or modify the proxy reward function using other approaches, requiring substantially fewer preferences to learn high performing policies.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰ä¸­äººä¸ºè®¾è®¡çš„ä»£ç†å¥–åŠ±å‡½æ•°ï¼ˆproxy reward functionï¼‰æ˜“å¼•å‘å¥–åŠ±æ¬ºéª—ï¼ˆreward hackingï¼‰çš„é—®é¢˜ï¼Œæå‡ºäº†åŸºäºåå¥½çš„å¥–åŠ±ä¿®å¤ï¼ˆPreference-Based Reward Repair, PBRRï¼‰æ¡†æ¶ã€‚PBRR å¹¶éä»å¤´å­¦ä¹ å¥–åŠ±å‡½æ•°ï¼Œè€Œæ˜¯é€šè¿‡å­¦ä¹ ä¸€ä¸ªåŠ æ€§çš„ã€ä¾èµ–äºçŠ¶æ€è½¬ç§»çš„ä¿®æ­£é¡¹æ¥è‡ªåŠ¨è¿­ä»£ä¿®å¤äººä¸ºæŒ‡å®šçš„ä»£ç†å¥–åŠ±ã€‚è¯¥æ¡†æ¶ç»“åˆäº†é’ˆå¯¹æ€§çš„æ¢ç´¢ç­–ç•¥ï¼ˆtargeted exploration strategyï¼‰å’Œå…¨æ–°çš„åå¥½å­¦ä¹ ç›®æ ‡ï¼Œèƒ½å¤Ÿä»…å‡­å°‘é‡å…³é”®è½¬ç§»çš„ä¿®æ­£å³æ¢å¤æœ€ä¼˜æ€§èƒ½ã€‚ç†è®ºä¸Šï¼ŒPBRR åœ¨è¡¨æ ¼åŸŸä¸­çš„ç´¯ç§¯é—æ†¾ï¼ˆcumulative regretï¼‰ä¸ç°æœ‰åå¥½å­¦ä¹ æ–¹æ³•ç›¸å½“ã€‚å®éªŒç»“æœè¯æ˜ï¼Œåœ¨å¤šä¸ªå¥–åŠ±æ¬ºéª—åŸºå‡†ä»»åŠ¡ä¸­ï¼ŒPBRR æ˜¾è‘—ä¼˜äºä»é›¶å­¦ä¹ æˆ–å¸¸è§„ä¿®æ”¹æ–¹æ³•çš„åŸºçº¿æ¨¡å‹ï¼Œä¸”èƒ½ä»¥æ›´ä½çš„åå¥½æ•°æ®æˆæœ¬å®ç°é«˜æ€§èƒ½ç­–ç•¥ã€‚",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.13036v1",
      "published_date": "2025-10-14 23:18:24 UTC",
      "updated_date": "2025-10-14 23:18:24 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:18:43.687791+00:00"
    },
    {
      "arxiv_id": "2510.13029v1",
      "title": "Toward Reasoning-Centric Time-Series Analysis",
      "title_zh": "è¿ˆå‘ä»¥æ¨ç†ä¸ºä¸­å¿ƒçš„æ—¶é—´åºåˆ—åˆ†æ",
      "authors": [
        "Xinlei Wang",
        "Mingtian Tan",
        "Jing Qiu",
        "Junhua Zhao",
        "Jinjin Gu"
      ],
      "abstract": "Traditional time series analysis has long relied on pattern recognition, trained on static and well-established benchmarks. However, in real-world settings -- where policies shift, human behavior adapts, and unexpected events unfold -- effective analysis must go beyond surface-level trends to uncover the actual forces driving them. The recent rise of Large Language Models (LLMs) presents new opportunities for rethinking time series analysis by integrating multimodal inputs. However, as the use of LLMs becomes popular, we must remain cautious, asking why we use LLMs and how to exploit them effectively. Most existing LLM-based methods still employ their numerical regression ability and ignore their deeper reasoning potential. This paper argues for rethinking time series with LLMs as a reasoning task that prioritizes causal structure and explainability. This shift brings time series analysis closer to human-aligned understanding, enabling transparent and context-aware insights in complex real-world environments.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å‘ä»¥æ¨ç†ä¸ºä¸­å¿ƒçš„æ—¶é—´åºåˆ—åˆ†æ(Time-Series Analysis)è½¬å‹çš„å¿…è¦æ€§ï¼ŒæŒ‡å‡ºä¼ ç»Ÿæ–¹æ³•è¿‡åº¦ä¾èµ–é™æ€åŸºå‡†ä¸Šçš„æ¨¡å¼è¯†åˆ«(Pattern Recognition)ï¼Œéš¾ä»¥åº”å¯¹ç°å®ä¸–ç•Œä¸­æ”¿ç­–è½¬ç§»å’Œè¡Œä¸ºå˜åŒ–ç­‰åŠ¨æ€å› ç´ ã€‚å°½ç®¡å¤§è¯­è¨€æ¨¡å‹(LLMs)ä¸ºå¤šæ¨¡æ€åˆ†æå¸¦æ¥äº†å¥‘æœºï¼Œä½†ç›®å‰å¤§å¤šæ•°æ–¹æ³•ä»…åˆ©ç”¨å…¶æ•°å€¼å›å½’(Numerical Regression)èƒ½åŠ›ï¼Œå¿½è§†äº†å…¶æ·±å±‚æ¨ç†çš„æ½œåŠ›ã€‚æœ¬æ–‡æå‡ºå°†æ—¶é—´åºåˆ—åˆ†æé‡æ–°å®šä¹‰ä¸ºä¸€é¡¹ä»¥æ¨ç†ä¸ºæ ¸å¿ƒçš„ä»»åŠ¡ï¼Œå¹¶å¼ºè°ƒå› æœç»“æ„(Causal Structure)ä¸å¯è§£é‡Šæ€§(Explainability)çš„é‡è¦æ€§ã€‚è¿™ä¸€èŒƒå¼è½¬å˜ä½¿åˆ†æè¿‡ç¨‹æ›´ç¬¦åˆäººç±»çš„è®¤çŸ¥å¯¹é½ï¼Œä»è€Œåœ¨å¤æ‚çš„å®é™…ç¯å¢ƒä¸­æä¾›é€æ˜ä¸”å…·å¤‡ä¸Šä¸‹æ–‡æ„ŸçŸ¥èƒ½åŠ›çš„æ·±å…¥æ´å¯Ÿã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.13029v1",
      "published_date": "2025-10-14 22:59:07 UTC",
      "updated_date": "2025-10-14 22:59:07 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:18:44.186858+00:00"
    },
    {
      "arxiv_id": "2510.13022v1",
      "title": "On the Role of Preference Variance in Preference Optimization",
      "title_zh": "è®ºåå¥½æ–¹å·®åœ¨åå¥½ä¼˜åŒ–ä¸­çš„ä½œç”¨",
      "authors": [
        "Jiacheng Guo",
        "Zihao Li",
        "Jiahao Qiu",
        "Yue Wu",
        "Mengdi Wang"
      ],
      "abstract": "Direct Preference Optimization (DPO) has emerged as an important approach for learning from human preferences in aligning large language models (LLMs). However, collecting human preference data is costly and inefficient, motivating methods to reduce the required annotations. In this work, we investigate the impact of \\emph{preference variance} (PVar), which measures the variance in model preferences when comparing pairs of responses, on the effectiveness of DPO training. We provide a theoretical insight by establishing an upper bound on the DPO gradient norm for any given prompt, showing it is controlled by the PVar of that prompt. This implies that prompts with low PVar can only produce small gradient updates, making them less valuable for learning. We validate this finding by fine-tuning LLMs with preferences generated by a reward model, evaluating on two benchmarks (AlpacaEval 2.0 and Arena-Hard). Experimental results demonstrate that prompts with higher PVar outperform randomly selected prompts or those with lower PVar. We also show that our PVar-based selection method is robust, when using smaller reward models (1B, 3B) for selection. Notably, in a separate experiment using the original human annotations from the UltraFeedback dataset, we found that training on only the top 10\\% of prompts with the highest PVar yields better evaluation performance than training on the full dataset, highlighting the importance of preference variance in identifying informative examples for efficient LLM alignment.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†åœ¨å¤§å‹è¯­è¨€æ¨¡å‹å¯¹é½ä¸­ï¼Œåå¥½æ–¹å·®(Preference Variance, PVar)åœ¨ç›´æ¥åå¥½ä¼˜åŒ–(Direct Preference Optimization, DPO)ä¸­çš„ä½œç”¨ã€‚ç ”ç©¶è€…é€šè¿‡ç†è®ºåˆ†æè¯æ˜ï¼Œç»™å®šæç¤ºè¯çš„ DPO æ¢¯åº¦èŒƒæ•°å—å…¶ PVar çš„ä¸Šç•Œçº¦æŸï¼Œè¿™æ„å‘³ç€ä½ PVar çš„æç¤ºè¯äº§ç”Ÿçš„æ¢¯åº¦æ›´æ–°è¾ƒå°ï¼Œå­¦ä¹ ä»·å€¼è¾ƒä½ã€‚å®éªŒé€šè¿‡åœ¨ AlpacaEval 2.0 å’Œ Arena-Hard åŸºå‡†ä¸Šå¾®è°ƒæ¨¡å‹éªŒè¯äº†è¿™ä¸€å‘ç°ï¼Œè¯æ˜é«˜ PVar çš„æç¤ºè¯è¡¨ç°ä¼˜äºéšæœºé€‰æ‹©æˆ–ä½ PVar çš„æç¤ºè¯ã€‚ç ”ç©¶è¿›ä¸€æ­¥è¡¨æ˜ï¼Œä½¿ç”¨è¾ƒå°çš„å¥–åŠ±æ¨¡å‹(Reward Model)è¿›è¡Œ PVar ç­›é€‰å…·æœ‰è‰¯å¥½çš„é²æ£’æ€§ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œåœ¨ UltraFeedback æ•°æ®é›†ä¸Šçš„å®éªŒæ˜¾ç¤ºï¼Œä»…ä½¿ç”¨ PVar æœ€é«˜çš„ 10% æç¤ºè¯è¿›è¡Œè®­ç»ƒï¼Œå…¶è¯„ä¼°æ€§èƒ½ç”šè‡³è¶…è¿‡äº†ä½¿ç”¨å®Œæ•´æ•°æ®é›†çš„è®­ç»ƒç»“æœã€‚è¯¥ç ”ç©¶å¼ºè°ƒäº† PVar ä½œä¸ºè¯†åˆ«é«˜ä¿¡æ¯é‡æ ·æœ¬çš„å…³é”®æŒ‡æ ‡ï¼Œå¯¹äºå®ç°é«˜æ•ˆçš„è¯­è¨€æ¨¡å‹å¯¹é½å…·æœ‰é‡è¦æ„ä¹‰ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.13022v1",
      "published_date": "2025-10-14 22:34:52 UTC",
      "updated_date": "2025-10-14 22:34:52 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:18:55.092641+00:00"
    },
    {
      "arxiv_id": "2510.13011v1",
      "title": "Deliberate Lab: A Platform for Real-Time Human-AI Social Experiments",
      "title_zh": "Deliberate Labï¼šå®æ—¶äººæœºç¤¾ä¼šå®éªŒå¹³å°",
      "authors": [
        "Crystal Qian",
        "Vivian Tsai",
        "Michael Behr",
        "Nada Hussein",
        "LÃ©o Laugier",
        "Nithum Thain",
        "Lucas Dixon"
      ],
      "abstract": "Social and behavioral scientists increasingly aim to study how humans interact, collaborate, and make decisions alongside artificial intelligence. However, the experimental infrastructure for such work remains underdeveloped: (1) few platforms support real-time, multi-party studies at scale; (2) most deployments require bespoke engineering, limiting replicability and accessibility, and (3) existing tools do not treat AI agents as first-class participants. We present Deliberate Lab, an open-source platform for large-scale, real-time behavioral experiments that supports both human participants and large language model (LLM)-based agents. We report on a 12-month public deployment of the platform (N=88 experimenters, N=9195 experiment participants), analyzing usage patterns and workflows. Case studies and usage scenarios are aggregated from platform users, complemented by in-depth interviews with select experimenters. By lowering technical barriers and standardizing support for hybrid human-AI experimentation, Deliberate Lab expands the methodological repertoire for studying collective decision-making and human-centered AI.",
      "tldr_zh": "æœ¬ç ”ç©¶ä»‹ç»äº† Deliberate Labï¼Œä¸€ä¸ªé’ˆå¯¹å¤§è§„æ¨¡å®æ—¶è¡Œä¸ºå®éªŒè®¾è®¡çš„å¼€æºå¹³å°ï¼Œæ—¨åœ¨è§£å†³å½“å‰ç¤¾äº¤ä¸è¡Œä¸ºç§‘å­¦åœ¨ç ”ç©¶äººç±»ä¸äººå·¥æ™ºèƒ½ï¼ˆAIï¼‰äº¤äº’æ—¶é¢ä¸´çš„å®éªŒåŸºç¡€è®¾æ–½ä¸è¶³ç­‰é—®é¢˜ã€‚è¯¥å¹³å°å…‹æœäº†ç°æœ‰å·¥å…·éš¾ä»¥æ”¯æŒå¤šæ–¹å®æ—¶å¤§è§„æ¨¡ç ”ç©¶åŠéš¾ä»¥å°† AI æ™ºèƒ½ä½“è§†ä¸ºä¸€ç­‰å…¬æ°‘å‚ä¸è€…çš„é™åˆ¶ï¼Œèƒ½å¤ŸåŒæ—¶æ”¯æŒäººç±»å‚ä¸è€…ä¸åŸºäºå¤§è¯­è¨€æ¨¡å‹ï¼ˆLLM-based agentsï¼‰çš„æ™ºèƒ½ä½“ã€‚ç ”ç©¶å›¢é˜ŸæŠ¥å‘Šäº†è¯¥å¹³å°ä¸ºæœŸ 12 ä¸ªæœˆçš„å…¬å¼€éƒ¨ç½²æˆæœï¼ŒæœŸé—´å…±æœ‰ 88 åå®éªŒè€…å’Œ 9195 åå‚ä¸è€…å‚ä¸å…¶ä¸­ï¼Œå¹¶é€šè¿‡æ¡ˆä¾‹ç ”ç©¶ä¸æ·±åº¦è®¿è°ˆè¯¦ç»†åˆ†æäº†ç”¨æˆ·çš„ä½¿ç”¨æ¨¡å¼ã€‚é€šè¿‡é™ä½æŠ€æœ¯é—¨æ§›å¹¶æ ‡å‡†åŒ–äººç±»ä¸ AI æ··åˆå®éªŒï¼ˆhybrid human-AI experimentationï¼‰çš„æ”¯æŒï¼ŒDeliberate Lab ä¸ºç ”ç©¶é›†ä½“å†³ç­–ï¼ˆcollective decision-makingï¼‰å’Œä»¥äººä¸ºæœ¬çš„ AIï¼ˆhuman-centered AIï¼‰æ‰©å±•äº†æ–¹æ³•è®ºåº“ã€‚",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.13011v1",
      "published_date": "2025-10-14 22:02:24 UTC",
      "updated_date": "2025-10-14 22:02:24 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:18:54.880111+00:00"
    },
    {
      "arxiv_id": "2510.13009v1",
      "title": "Developing and Validating the Arabic Version of the Attitudes Toward Large Language Models Scale",
      "title_zh": "é˜¿æ‹‰ä¼¯è¯­ç‰ˆå¤§è¯­è¨€æ¨¡å‹æ€åº¦é‡è¡¨çš„å¼€å‘ä¸éªŒè¯",
      "authors": [
        "Basad Barajeeh",
        "Ala Yankouskaya",
        "Sameha AlShakhsi",
        "Chun Sing Maxwell Ho",
        "Guandong Xu",
        "Raian Ali"
      ],
      "abstract": "As the use of large language models (LLMs) becomes increasingly global, understanding public attitudes toward these systems requires tools that are adapted to local contexts and languages. In the Arab world, LLM adoption has grown rapidly with both globally dominant platforms and regional ones like Fanar and Jais offering Arabic-specific solutions. This highlights the need for culturally and linguistically relevant scales to accurately measure attitudes toward LLMs in the region. Tools assessing attitudes toward artificial intelligence (AI) can provide a base for measuring attitudes specific to LLMs. The 5-item Attitudes Toward Artificial Intelligence (ATAI) scale, which measures two dimensions, the AI Fear and the AI Acceptance, has been recently adopted and adapted to develop new instruments in English using a sample from the UK: the Attitudes Toward General LLMs (AT-GLLM) and Attitudes Toward Primary LLM (AT-PLLM) scales. In this paper, we translate the two scales, AT-GLLM and AT-PLLM, and validate them using a sample of 249 Arabic-speaking adults. The results show that the scale, translated into Arabic, is a reliable and valid tool that can be used for the Arab population and language. Psychometric analyses confirmed a two-factor structure, strong measurement invariance across genders, and good internal reliability. The scales also demonstrated strong convergent and discriminant validity. Our scales will support research in a non-Western context, a much-needed effort to help draw a global picture of LLM perceptions, and will also facilitate localized research and policy-making in the Arab region.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹é˜¿æ‹‰ä¼¯åœ°åŒºå¤§è¯­è¨€æ¨¡å‹(Large Language Models, LLMs)åº”ç”¨æ—¥ç›Šå¹¿æ³›çš„ç°çŠ¶ï¼Œå¼€å‘å¹¶éªŒè¯äº†é˜¿æ‹‰ä¼¯è¯­ç‰ˆæœ¬çš„ LLMs æ€åº¦é‡è¡¨ã€‚ç ”ç©¶è€…ç¿»è¯‘å¹¶è°ƒæ•´äº†è¡¡é‡é€šç”¨ LLMs æ€åº¦çš„ AT-GLLM é‡è¡¨å’Œè¡¡é‡ä¸»è¦ LLMs æ€åº¦çš„ AT-PLLM é‡è¡¨ï¼Œè¿™ä¸¤è€…å‡æºäºè¯„ä¼° AI Fear å’Œ AI Acceptance ä¸¤ä¸ªç»´åº¦çš„ ATAI é‡è¡¨ã€‚é€šè¿‡å¯¹249åè®²é˜¿æ‹‰ä¼¯è¯­çš„æˆå¹´äººè¿›è¡Œé‡‡æ ·ï¼Œå¿ƒç†æµ‹é‡å­¦åˆ†æè¯å®äº†è¯¥é‡è¡¨å…·æœ‰æ¸…æ™°çš„ä¸¤å› å­ç»“æ„(two-factor structure)ã€è‰¯å¥½çš„å†…éƒ¨å¯é æ€§ä»¥åŠè·¨æ€§åˆ«çš„æµ‹é‡ç­‰å€¼æ€§(measurement invariance)ã€‚å®éªŒç»“æœæ˜¾ç¤ºè¯¥é‡è¡¨å…·æœ‰æå¼ºçš„èšåˆæ•ˆåº¦å’ŒåŒºåˆ†æ•ˆåº¦ï¼Œè¯æ˜å…¶æ˜¯é€‚ç”¨äºé˜¿æ‹‰ä¼¯è¯­äººç¾¤çš„å¯é è¯„ä¼°å·¥å…·ã€‚è¯¥é¡¹å·¥ä½œå¡«è¡¥äº†éè¥¿æ–¹èƒŒæ™¯ä¸‹ LLMs æ„ŸçŸ¥è¯„ä¼°å·¥å…·çš„ç©ºç™½ï¼Œä¸ä»…æœ‰åŠ©äºæ„å»ºå…¨çƒèŒƒå›´å†…çš„æŠ€æœ¯æ„ŸçŸ¥å›¾æ™¯ï¼Œä¹Ÿä¸ºé˜¿æ‹‰ä¼¯åœ°åŒºçš„æœ¬åœŸåŒ–ç ”ç©¶å’Œæ”¿ç­–åˆ¶å®šæä¾›äº†ç§‘å­¦ä¾æ®ã€‚",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "28 Pages",
      "pdf_url": "https://arxiv.org/pdf/2510.13009v1",
      "published_date": "2025-10-14 21:56:53 UTC",
      "updated_date": "2025-10-14 21:56:53 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:18:55.373493+00:00"
    },
    {
      "arxiv_id": "2510.13008v1",
      "title": "CurLL: A Developmental Framework to Evaluate Continual Learning in Language Models",
      "title_zh": "CurLLï¼šä¸€ç§è¯„ä¼°è¯­è¨€æ¨¡å‹æŒç»­å­¦ä¹ çš„å‘å±•æ€§æ¡†æ¶",
      "authors": [
        "Pavan Kalyan",
        "Shubhra Mishra",
        "Satya Lokam",
        "Navin Goyal"
      ],
      "abstract": "We introduce a comprehensive continual learning dataset and benchmark (CurlL) grounded in human developmental trajectories from ages 5-10, enabling systematic and fine-grained assessment of models' ability to progressively acquire new skills. CurlL spans five developmental stages (0-4) covering ages 5-10, supported by a skill graph that breaks down broad skills into smaller abilities, concrete goals, and measurable indicators, while also capturing which abilities build on others. We generate a 23.4B-token synthetic dataset with controlled skill progression, vocabulary complexity, and format diversity, comprising paragraphs, comprehension-based QA (CQA), skill-testing QA (CSQA), and instruction-response (IR) pairs. Stage-wise token counts range from 2.12B to 6.78B tokens, supporting precise analysis of forgetting, forward transfer, and backward transfer. Using a 135M-parameter transformer trained under independent, joint, and sequential (continual) setups, we show trade-offs in skill retention and transfer efficiency. By mirroring human learning patterns and providing fine-grained control over skill dependencies, this work advances continual learning evaluations for language models.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†CurLLï¼Œä¸€ä¸ªåŸºäº5è‡³10å²äººç±»å‘è‚²è½¨è¿¹çš„æŒç»­å­¦ä¹ (Continual Learning)æ•°æ®é›†å’ŒåŸºå‡†æµ‹è¯•æ¡†æ¶ï¼Œæ—¨åœ¨ç³»ç»Ÿè¯„ä¼°è¯­è¨€æ¨¡å‹é€æ­¥è·å–æ–°æŠ€èƒ½çš„èƒ½åŠ›ã€‚CurLLæ¶µç›–äº†äº”ä¸ªå‘è‚²é˜¶æ®µï¼Œå¹¶é…å¥—äº†ä¸€ä¸ªæŠ€èƒ½å›¾è°±(skill graph)ï¼Œé€šè¿‡å°†å®è§‚æŠ€èƒ½æ‹†è§£ä¸ºå…·ä½“èƒ½åŠ›å’Œå¯è¡¡é‡æŒ‡æ ‡ï¼Œæ•æ‰äº†æŠ€èƒ½é—´çš„æ„å»ºä¾èµ–å…³ç³»ã€‚ç ”ç©¶å›¢é˜Ÿç”Ÿæˆäº†ä¸€ä¸ªåŒ…å«234äº¿tokençš„å—æ§åˆæˆæ•°æ®é›†ï¼Œæ¶µç›–äº†ç†è§£å‹é—®ç­”(CQA)ã€æŠ€èƒ½æµ‹è¯•é—®ç­”(CSQA)åŠæŒ‡ä»¤å“åº”(IR)ç­‰å¤šç§æ ¼å¼ï¼Œä»¥æ”¯æŒå¯¹æ¨¡å‹é—å¿˜(forgetting)ã€æ­£å‘è¿ç§»(forward transfer)å’Œåå‘è¿ç§»(backward transfer)çš„ç²¾ç¡®åˆ†æã€‚é€šè¿‡å¯¹135Må‚æ•°çš„Transformeræ¨¡å‹è¿›è¡Œç‹¬ç«‹ã€è”åˆåŠåºåˆ—åŒ–è®­ç»ƒå®éªŒï¼Œç ”ç©¶æ­ç¤ºäº†æŠ€èƒ½ä¿ç•™ä¸è¿ç§»æ•ˆç‡ä¹‹é—´çš„æƒè¡¡å…³ç³»ã€‚è¯¥å·¥ä½œé€šè¿‡æ¨¡æ‹Ÿäººç±»å­¦ä¹ æ¨¡å¼å¹¶æä¾›ç»†ç²’åº¦çš„æŠ€èƒ½ä¾èµ–æ§åˆ¶ï¼Œä¸ºå¤§è¯­è¨€æ¨¡å‹çš„æŒç»­å­¦ä¹ è¯„ä¼°æä¾›äº†æ–°çš„èŒƒå¼ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.13008v1",
      "published_date": "2025-10-14 21:56:03 UTC",
      "updated_date": "2025-10-14 21:56:03 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:19:02.481146+00:00"
    },
    {
      "arxiv_id": "2510.13006v3",
      "title": "What is Implementation Science; and Why It Matters for Bridging the Artificial Intelligence Innovation-to-Application Gap in Medical Imaging",
      "title_zh": "ä»€ä¹ˆæ˜¯å®æ–½ç§‘å­¦ï¼ŸåŠå…¶åœ¨å¼¥åˆåŒ»å­¦å½±åƒäººå·¥æ™ºèƒ½åˆ›æ–°ä¸åº”ç”¨é¸¿æ²Ÿä¸­çš„é‡è¦æ„ä¹‰",
      "authors": [
        "Ahmad Fayaz-Bakhsh",
        "Janice Tania",
        "Syaheerah Lebai Lutfi",
        "Abhinav K. Jha",
        "Arman Rahmim"
      ],
      "abstract": "The transformative potential of artificial intelligence (AI) in medical Imaging (MI) is well recognized. Yet despite promising reports in research settings, many AI tools fail to achieve clinical adoption in practice. In fact, more generally, there is a documented 17-year average delay between evidence generation and implementation of a technology. Implementation science (IS) may provide a practical, evidence-based framework to bridge the gap between AI development and real-world clinical imaging use, to shorten this lag through systematic frameworks, strategies, and hybrid research designs. We outline challenges specific to AI adoption in MI workflows, including infrastructural, educational, and cultural barriers. We highlight the complementary roles of effectiveness research and implementation research, emphasizing hybrid study designs and the role of integrated KT (iKT), stakeholder engagement, and equity-focused co-creation in designing sustainable and generalizable solutions. We discuss integration of Human-Computer Interaction (HCI) frameworks in MI towards usable AI. Adopting IS is not only a methodological advancement; it is a strategic imperative for accelerating translation of innovation into improved patient outcomes.",
      "tldr_zh": "è¿™é¡¹ç ”ç©¶æ¢è®¨äº†å®æ–½ç§‘å­¦(Implementation Science)åœ¨å¼¥åˆåŒ»ç–—å½±åƒ(Medical Imaging)é¢†åŸŸäººå·¥æ™ºèƒ½(AI)ä»åˆ›æ–°åˆ°åº”ç”¨é¸¿æ²Ÿçš„å…³é”®ä½œç”¨ã€‚é’ˆå¯¹AIå·¥å…·åœ¨ä¸´åºŠè½¬åŒ–ä¸­é¢ä¸´çš„é•¿æœŸæ»åï¼Œæœ¬æ–‡æå‡ºåˆ©ç”¨ISçš„ç³»ç»Ÿæ€§æ¡†æ¶ã€ç­–ç•¥å’Œæ··åˆç ”ç©¶è®¾è®¡æ¥ç¼©çŸ­è¯æ®ç”Ÿæˆä¸ä¸´åºŠå®è·µä¹‹é—´çš„è·ç¦»ã€‚ç ”ç©¶è¯¦ç»†åˆ†æäº†AIåœ¨åŒ»ç–—å½±åƒå·¥ä½œæµä¸­é¢ä¸´çš„åŸºç¡€è®¾æ–½ã€æ•™è‚²åŠæ–‡åŒ–å±‚é¢çš„æŒ‘æˆ˜ï¼Œå¹¶å¼ºè°ƒäº†æœ‰æ•ˆæ€§ç ”ç©¶ä¸å®æ–½ç ”ç©¶çš„äº’è¡¥æ€§ã€‚é€šè¿‡å€¡å¯¼é›†æˆçŸ¥è¯†è½¬åŒ–(iKT)ã€åˆ©ç›Šç›¸å…³è€…å‚ä¸ä»¥åŠä»¥å…¬å¹³ä¸ºæ ¸å¿ƒçš„å…±åŒåˆ›ä½œï¼Œç ”ç©¶æ—¨åœ¨è®¾è®¡å‡ºæ›´å…·å¯æŒç»­æ€§å’Œé€šç”¨æ€§çš„è§£å†³æ–¹æ¡ˆã€‚æ­¤å¤–ï¼Œæ–‡ä¸­è®¨è®ºäº†å°†äººæœºäº¤äº’(HCI)æ¡†æ¶èå…¥åŒ»ç–—å½±åƒAIå¼€å‘ä¸­ï¼Œä»¥ç¡®ä¿å…¶å¯ç”¨æ€§ã€‚æœ€åæŒ‡å‡ºï¼Œé‡‡ç”¨å®æ–½ç§‘å­¦æ˜¯åŠ é€ŸåŒ»å­¦å½±åƒåˆ›æ–°è½¬åŒ–å¹¶æ”¹å–„æ‚£è€…é¢„åçš„æˆ˜ç•¥å¿…ç„¶é€‰æ‹©ã€‚",
      "categories": [
        "physics.med-ph",
        "cs.AI"
      ],
      "primary_category": "physics.med-ph",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.13006v3",
      "published_date": "2025-10-14 21:50:31 UTC",
      "updated_date": "2025-11-24 19:53:22 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:19:02.975062+00:00"
    },
    {
      "arxiv_id": "2510.13002v1",
      "title": "From Narratives to Probabilistic Reasoning: Predicting and Interpreting Drivers' Hazardous Actions in Crashes Using Large Language Model",
      "title_zh": "ä»å™è¿°åˆ°æ¦‚ç‡æ¨ç†ï¼šåˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹é¢„æµ‹ä¸è§£é‡Šç¢°æ’äº‹æ•…ä¸­çš„é©¾é©¶å‘˜å±é™©è¡Œä¸º",
      "authors": [
        "Boyou Chen",
        "Gerui Xu",
        "Zifei Wang",
        "Huizhong Guo",
        "Ananna Ahmed",
        "Zhaonan Sun",
        "Zhen Hu",
        "Kaihan Zhang",
        "Shan Bao"
      ],
      "abstract": "Vehicle crashes involve complex interactions between road users, split-second decisions, and challenging environmental conditions. Among these, two-vehicle crashes are the most prevalent, accounting for approximately 70% of roadway crashes and posing a significant challenge to traffic safety. Identifying Driver Hazardous Action (DHA) is essential for understanding crash causation, yet the reliability of DHA data in large-scale databases is limited by inconsistent and labor-intensive manual coding practices. Here, we present an innovative framework that leverages a fine-tuned large language model to automatically infer DHAs from textual crash narratives, thereby improving the validity and interpretability of DHA classifications. Using five years of two-vehicle crash data from MTCF, we fine-tuned the Llama 3.2 1B model on detailed crash narratives and benchmarked its performance against conventional machine learning classifiers, including Random Forest, XGBoost, CatBoost, and a neural network. The fine-tuned LLM achieved an overall accuracy of 80%, surpassing all baseline models and demonstrating pronounced improvements in scenarios with imbalanced data. To increase interpretability, we developed a probabilistic reasoning approach, analyzing model output shifts across original test sets and three targeted counterfactual scenarios: variations in driver distraction and age. Our analysis revealed that introducing distraction for one driver substantially increased the likelihood of \"General Unsafe Driving\"; distraction for both drivers maximized the probability of \"Both Drivers Took Hazardous Actions\"; and assigning a teen driver markedly elevated the probability of \"Speed and Stopping Violations.\" Our framework and analytical methods provide a robust and interpretable solution for large-scale automated DHA detection, offering new opportunities for traffic safety analysis and intervention.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ä¸ªåŸºäºå¾®è°ƒå¤§è¯­è¨€æ¨¡å‹(Large Language Model)çš„åˆ›æ–°æ¡†æ¶ï¼Œæ—¨åœ¨é€šè¿‡æ–‡æœ¬ç¢°æ’å™è¿°è‡ªåŠ¨æ¨æ–­é©¾é©¶å‘˜å±é™©è¡Œä¸º(Driver Hazardous Action, DHA)ï¼Œä»¥è§£å†³äº¤é€šå®‰å…¨æ•°æ®åº“ä¸­æ‰‹åŠ¨ç¼–ç æ•ˆç‡ä½ä¸‹ä¸”ä¸ä¸€è‡´çš„é—®é¢˜ã€‚ç ”ç©¶äººå‘˜åœ¨äº”å¹´çš„ MTCF ä¸¤è½¦ç¢°æ’æ•°æ®ä¸Šå¾®è°ƒäº† Llama 3.2 1B æ¨¡å‹ï¼Œå…¶å®éªŒå‡†ç¡®ç‡è¾¾åˆ° 80%ï¼Œæ˜¾è‘—ä¼˜äº Random Forestã€XGBoostã€CatBoost åŠç¥ç»ç½‘ç»œç­‰åŸºå‡†æ¨¡å‹ï¼Œå°¤å…¶åœ¨å¤„ç†ä¸å¹³è¡¡æ•°æ®æ–¹é¢è¡¨ç°ä¼˜å¼‚ã€‚ä¸ºå¢å¼ºå¯è§£é‡Šæ€§ï¼Œç ”ç©¶å¼€å‘äº†ä¸€ç§æ¦‚ç‡æ¨ç†(Probabilistic Reasoning)æ–¹æ³•ï¼Œé€šè¿‡åˆ†æåœ¨é©¾é©¶å‘˜åˆ†å¿ƒå’Œå¹´é¾„ç­‰åäº‹å®åœºæ™¯(Counterfactual Scenarios)ä¸‹çš„æ¨¡å‹è¾“å‡ºåç§»ï¼Œæ­ç¤ºäº†ç‰¹å®šé£é™©å› ç´ ä¸å±é™©è¡Œä¸ºä¹‹é—´çš„é‡åŒ–å…³è”ã€‚åˆ†æå‘ç°ï¼Œåˆ†å¿ƒæ˜¾è‘—å¢åŠ äº†â€œä¸€èˆ¬ä¸å®‰å…¨é©¾é©¶â€çš„æ¦‚ç‡ï¼Œè€Œé’å°‘å¹´é©¾é©¶å‘˜åˆ™æ›´æ˜“å¯¼è‡´â€œè¶…é€Ÿå’Œåœè½¦è¿è§„â€ã€‚è¯¥æ¡†æ¶ä¸ºå¤§è§„æ¨¡è‡ªåŠ¨åŒ– DHA æ£€æµ‹æä¾›äº†é²æ£’ä¸”å¯è§£é‡Šçš„è§£å†³æ–¹æ¡ˆï¼Œä¸ºæå‡äº¤é€šå®‰å…¨åˆ†æå’Œå¹²é¢„æ•ˆç‡æä¾›äº†æ–°çš„æŠ€æœ¯æ”¯æ’‘ã€‚",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.13002v1",
      "published_date": "2025-10-14 21:35:47 UTC",
      "updated_date": "2025-10-14 21:35:47 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:19:22.673626+00:00"
    },
    {
      "arxiv_id": "2510.12997v2",
      "title": "Max It or Miss It: Benchmarking LLM On Solving Extremal Problems",
      "title_zh": "Max It or Miss Itï¼šå¤§è¯­è¨€æ¨¡å‹è§£å†³æå€¼é—®é¢˜çš„åŸºå‡†æµ‹è¯•",
      "authors": [
        "Binxin Gao",
        "Jingjun Han"
      ],
      "abstract": "Test-time scaling has enabled Large Language Models (LLMs) with remarkable reasoning capabilities, particularly in mathematical domains, through intermediate chain-of-thought (CoT) reasoning before generating final answers. However, the specific sources and mechanisms underlying these reasoning capabilities remain insufficiently understood. Optimization reasoning, i.e. finding extrema under constraints, represents a fundamental abstraction that underpins critical applications in planning, control, resource allocation, and prompt search. To systematically evaluate this capability, we introduce ExtremBench, a benchmark dataset for solving mathematical extremal problems, curated from inequality exercises used for Chinese Mathematical Olympiad and transformed into $93$ standardized extrema-finding problems. We conduct extensive evaluations across various state-of-the-art open-source model families, including the Qwen3, GPT-OSS, and DeepSeek. Our results reveal that LLMs' extremal-solving reasoning capabilities do not always align with those of current mathematical benchmarks such as AIME25 and MATH-500, with some models showing strong general mathematical reasoning but poor extremal-solving skills, and vice versa. This discrepancy highlights a critical gap in current evaluation practices and suggests that existing benchmarks may not comprehensively capture the full spectrum of mathematical reasoning abilities.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å¤§å‹è¯­è¨€æ¨¡å‹(LLMs)åœ¨è§£å†³æå€¼é—®é¢˜(Extremal Problems)ï¼Œå³åœ¨çº¦æŸæ¡ä»¶ä¸‹è¿›è¡Œä¼˜åŒ–æ¨ç†çš„èƒ½åŠ›ã€‚ä¸ºäº†ç³»ç»Ÿè¯„ä¼°è¿™ä¸€èƒ½åŠ›ï¼Œç ”ç©¶å›¢é˜Ÿæ¨å‡ºäº†ExtremBenchï¼Œè¿™æ˜¯ä¸€ä¸ªåŒ…å«93é“åŸºäºä¸­å›½æ•°å­¦å¥¥æ—åŒ¹å…‹(Chinese Mathematical Olympiad)ä¸ç­‰å¼é¢˜ç›®è½¬åŒ–è€Œæˆçš„æ ‡å‡†åŒ–åŸºå‡†æ•°æ®é›†ã€‚é€šè¿‡å¯¹Qwen3ã€GPT-OSSå’ŒDeepSeekç­‰å‰æ²¿å¼€æºæ¨¡å‹çš„è¯„ä¼°å‘ç°ï¼ŒLLMsåœ¨æå€¼æ±‚è§£æ–¹é¢çš„è¡¨ç°ä¸åœ¨AIME25å’ŒMATH-500ç­‰ä¼ ç»Ÿæ•°å­¦åŸºå‡†ä¸Šçš„è¡¨ç°å¹¶ä¸å®Œå…¨ä¸€è‡´ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œéƒ¨åˆ†æ¨¡å‹è™½ç„¶å±•ç°å‡ºæå¼ºçš„é€šç”¨æ•°å­¦æ¨ç†èƒ½åŠ›ï¼Œä½†åœ¨æå€¼é—®é¢˜ä¸Šå´è¡¨ç°ä¸ä½³ï¼Œåä¹‹äº¦ç„¶ã€‚è¿™ä¸€å·®å¼‚æ­ç¤ºäº†ç°æœ‰è¯„ä¼°ä½“ç³»çš„å±€é™æ€§ï¼Œè¡¨æ˜å½“å‰ä¸»æµåŸºå‡†æµ‹è¯•æœªèƒ½æ¶µç›–æ•°å­¦æ¨ç†èƒ½åŠ›çš„å…¨éƒ¨é¢‘è°±ã€‚è¯¥ç ”ç©¶å¼ºè°ƒäº†ä¸“é—¨è¯„ä¼°ä¼˜åŒ–æ¨ç†çš„é‡è¦æ€§ï¼Œå¹¶ä¸ºæœªæ¥æå‡LLMså¤„ç†å¤æ‚æ•°å­¦ã€è§„åˆ’åŠèµ„æºåˆ†é…ä»»åŠ¡çš„èƒ½åŠ›æä¾›äº†å‚è€ƒä¾æ®ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "Our benchmark dataset is available at https://huggingface.co/datasets/binxingao/extrem-bench",
      "pdf_url": "https://arxiv.org/pdf/2510.12997v2",
      "published_date": "2025-10-14 21:23:37 UTC",
      "updated_date": "2025-10-17 21:17:43 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:19:26.967139+00:00"
    },
    {
      "arxiv_id": "2512.00009v2",
      "title": "Development and Benchmarking of a Blended Human-AI Qualitative Research Assistant",
      "title_zh": "æ··åˆå¼äººæœºå®šæ€§ç ”ç©¶åŠ©æ‰‹çš„å¼€å‘ä¸åŸºå‡†æµ‹è¯•",
      "authors": [
        "Joseph Matveyenko",
        "James Liu",
        "John David Parsons",
        "Ryan A. Brown",
        "Alina Palimaru",
        "Prateek Puri"
      ],
      "abstract": "Qualitative research emphasizes constructing meaning through iterative engagement with textual data. Traditionally this human-driven process requires navigating coder fatigue and interpretative drift, thus posing challenges when scaling analysis to larger, more complex datasets. Computational approaches to augment qualitative research have been met with skepticism, partly due to their inability to replicate the nuance, context-awareness, and sophistication of human analysis. Large language models, however, present new opportunities to automate aspects of qualitative analysis while upholding rigor and research quality in important ways. To assess their benefits and limitations - and build trust among qualitative researchers - these approaches must be rigorously benchmarked against human-generated datasets. In this work, we benchmark Muse, an interactive, AI-powered qualitative research system that allows researchers to identify themes and annotate datasets, finding an inter-rater reliability between Muse and humans of Cohen's $Îº$ = 0.71 for well-specified codes. We also conduct robust error analysis to identify failure mode, guide future improvements, and demonstrate the capacity to correct for human bias.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å®šæ€§ç ”ç©¶åœ¨å¤„ç†å¤§è§„æ¨¡å¤æ‚æ•°æ®é›†æ—¶é¢ä¸´çš„ç¼–ç ç–²åŠ³å’Œè§£é‡Šåå·®æŒ‘æˆ˜ï¼Œå¼€å‘å¹¶åŸºå‡†æµ‹è¯•äº†ä¸€ç§åä¸º Muse çš„äº¤äº’å¼äººå·¥æ™ºèƒ½å®šæ€§ç ”ç©¶è¾…åŠ©ç³»ç»Ÿã€‚Muse å…è®¸ç ”ç©¶äººå‘˜åˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰è‡ªåŠ¨åŒ–è¯†åˆ«ä¸»é¢˜å¹¶è¿›è¡Œæ•°æ®é›†æ³¨é‡Šï¼Œæ—¨åœ¨æå‡åˆ†ææ•ˆç‡çš„åŒæ—¶ä¿æŒå­¦æœ¯ä¸¥è°¨æ€§ã€‚åŸºå‡†æµ‹è¯•ç»“æœæ˜¾ç¤ºï¼Œåœ¨æ˜ç¡®å®šä¹‰çš„ç¼–ç ä»»åŠ¡ä¸­ï¼ŒMuse ä¸äººå·¥è¯„åˆ†è€…ä¹‹é—´çš„è·¨è¯„åˆ†è€…ä¿¡åº¦ï¼ˆinter-rater reliabilityï¼‰è¾¾åˆ°äº† Cohen's Îº = 0.71ã€‚ç ”ç©¶é€šè¿‡æ·±å…¥çš„é”™è¯¯åˆ†æï¼ˆerror analysisï¼‰è¯†åˆ«äº†ç³»ç»Ÿçš„å¤±æ•ˆæ¨¡å¼ï¼Œå¹¶å±•ç¤ºäº†å…¶åœ¨çº æ­£äººå·¥åè§ï¼ˆhuman biasï¼‰æ–¹é¢çš„æ½œåŠ›ã€‚è¯¥å·¥ä½œä¸ºå®šæ€§ç ”ç©¶é¢†åŸŸä¸­æ„å»ºäººç±»ä¸äººå·¥æ™ºèƒ½åä½œçš„å¯ä¿¡åº¦ä»¥åŠæœªæ¥å·¥å…·çš„æ”¹è¿›æ–¹å‘æä¾›äº†é‡è¦å‚è€ƒã€‚",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "32 pages, 9 figures",
      "pdf_url": "https://arxiv.org/pdf/2512.00009v2",
      "published_date": "2025-10-14 21:17:34 UTC",
      "updated_date": "2025-12-15 01:41:02 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:19:20.288812+00:00"
    },
    {
      "arxiv_id": "2510.13905v2",
      "title": "Schema for In-Context Learning",
      "title_zh": "é¢å‘ä¸Šä¸‹æ–‡å­¦ä¹ çš„å›¾å¼",
      "authors": [
        "Pan Chen",
        "Shaohong Chen",
        "Mark Wang",
        "Shi Xuan Leong",
        "Priscilla Fung",
        "Varinia Bernales",
        "Alan Aspuru-Guzik"
      ],
      "abstract": "In-Context Learning (ICL) enables transformer-based language models to adapt to new tasks by conditioning on demonstration examples. However, traditional example-driven in-context learning lacks explicit modules for knowledge retrieval and transfer at the abstraction level. Inspired by cognitive science, specifically schema theory, which holds that humans interpret new information by activating pre-existing mental frameworks (schemas) to structure understanding, we introduce SCHEMA ACTIVATED IN CONTEXT LEARNING (SA-ICL). This framework extracts the representation of the building blocks of cognition for the reasoning process instilled from prior examples, creating an abstracted schema, a lightweight, structured template of key inferential steps and their relationships, which is then used to augment a model's reasoning process when presented with a novel question. We demonstrate that a broad range of large language models (LLMs) lack the capacity to form and utilize internal schema-based learning representations implicitly, but instead benefit significantly from explicit schema-based scaffolding. Across chemistry and physics questions from the GPQA dataset, our experiments show that SA-ICL consistently boosts performance, up to 36.19 percent, when the single demonstration example is of high quality, which simultaneously reduces reliance on the number of demonstrations and enhances interpretability. SCHEMA ACTIVATED IN CONTEXT LEARNING not only bridges disparate ICL strategies ranging from pattern priming to Chain-of-Thought prompting, but also paves a new path for enhancing human-like reasoning in LLMs.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ä¼ ç»Ÿ In-Context Learning (ICL) ç¼ºä¹æ˜¾å¼æŠ½è±¡å±‚çº§çŸ¥è¯†æå–ä¸è¿ç§»çš„é—®é¢˜ï¼Œæå‡ºäº† SCHEMA ACTIVATED IN CONTEXT LEARNING (SA-ICL) æ¡†æ¶ã€‚å—è®¤çŸ¥ç§‘å­¦ä¸­çš„ schema ç†è®ºå¯å‘ï¼Œè¯¥æ–¹æ³•ä»å…ˆå‰ç¤ºä¾‹ä¸­æå–æ¨ç†è¿‡ç¨‹çš„æ„å»ºå—ï¼Œæ„å»ºå‡ºè½»é‡åŒ–ä¸”ç»“æ„åŒ–çš„æ¨ç†æ¨¡æ¿ï¼Œç”¨äºå¢å¼ºæ¨¡å‹å¤„ç†æ–°é—®é¢˜æ—¶çš„æ¨ç†è¿‡ç¨‹ã€‚ç ”ç©¶å‘ç° Large Language Models (LLMs) æ™®éç¼ºä¹éšå¼å½¢æˆå’Œåˆ©ç”¨å†…éƒ¨ schema çš„èƒ½åŠ›ï¼Œä½†èƒ½ä»æ˜¾å¼çš„ schema è„šæ‰‹æ¶ä¸­æ˜¾è‘—è·ç›Šã€‚åœ¨ GPQA æ•°æ®é›†çš„åŒ–å­¦å’Œç‰©ç†é—®é¢˜æµ‹è¯•ä¸­ï¼ŒSA-ICL åœ¨é«˜è´¨é‡å•ç¤ºä¾‹æ¡ä»¶ä¸‹å°†æ€§èƒ½æå‡äº†é«˜è¾¾ 36.19%ï¼Œæœ‰æ•ˆå‡å°‘äº†å¯¹ç¤ºä¾‹æ•°é‡çš„ä¾èµ–å¹¶å¢å¼ºäº†å¯è§£é‡Šæ€§ã€‚è¿™ä¸€æ–¹æ³•ä¸ä»…æ¡¥æ¥äº†ä»æ¨¡å¼å¼•å¯¼åˆ° Chain-of-Thought ç­‰å¤šç§ ICL ç­–ç•¥ï¼Œè¿˜ä¸ºå¢å¼º LLMs çš„ç±»äººæ¨ç†èƒ½åŠ›æä¾›äº†æ–°è·¯å¾„ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.13905v2",
      "published_date": "2025-10-14 21:00:15 UTC",
      "updated_date": "2025-10-23 18:04:38 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:19:23.085093+00:00"
    },
    {
      "arxiv_id": "2510.12985v1",
      "title": "SENTINEL: A Multi-Level Formal Framework for Safety Evaluation of LLM-based Embodied Agents",
      "title_zh": "SENTINELï¼šåŸºäºå¤§è¯­è¨€æ¨¡å‹çš„å…·èº«æ™ºèƒ½ä½“å®‰å…¨è¯„ä¼°å¤šå±‚çº§å½¢å¼åŒ–æ¡†æ¶",
      "authors": [
        "Simon Sinong Zhan",
        "Yao Liu",
        "Philip Wang",
        "Zinan Wang",
        "Qineng Wang",
        "Zhian Ruan",
        "Xiangyu Shi",
        "Xinyu Cao",
        "Frank Yang",
        "Kangrui Wang",
        "Huajie Shao",
        "Manling Li",
        "Qi Zhu"
      ],
      "abstract": "We present Sentinel, the first framework for formally evaluating the physical safety of Large Language Model(LLM-based) embodied agents across the semantic, plan, and trajectory levels. Unlike prior methods that rely on heuristic rules or subjective LLM judgments, Sentinel grounds practical safety requirements in formal temporal logic (TL) semantics that can precisely specify state invariants, temporal dependencies, and timing constraints. It then employs a multi-level verification pipeline where (i) at the semantic level, intuitive natural language safety requirements are formalized into TL formulas and the LLM agent's understanding of these requirements is probed for alignment with the TL formulas; (ii) at the plan level, high-level action plans and subgoals generated by the LLM agent are verified against the TL formulas to detect unsafe plans before execution; and (iii) at the trajectory level, multiple execution trajectories are merged into a computation tree and efficiently verified against physically-detailed TL specifications for a final safety check. We apply Sentinel in VirtualHome and ALFRED, and formally evaluate multiple LLM-based embodied agents against diverse safety requirements. Our experiments show that by grounding physical safety in temporal logic and applying verification methods across multiple levels, Sentinel provides a rigorous foundation for systematically evaluating LLM-based embodied agents in physical environments, exposing safety violations overlooked by previous methods and offering insights into their failure modes.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† SENTINELï¼Œè¿™æ˜¯é¦–ä¸ªä»è¯­ä¹‰ (Semantic)ã€è§„åˆ’ (Plan) å’Œè½¨è¿¹ (Trajectory) ä¸‰ä¸ªå±‚çº§å¯¹åŸºäºå¤§è¯­è¨€æ¨¡å‹ (LLM-based) çš„å…·èº«æ™ºèƒ½ä½“è¿›è¡Œç‰©ç†å®‰å…¨æ€§å½¢å¼åŒ–è¯„ä¼°çš„æ¡†æ¶ã€‚ä¸åŒäºä¾èµ–å¯å‘å¼è§„åˆ™æˆ– LLM ä¸»è§‚åˆ¤æ–­çš„ä¼ ç»Ÿæ–¹æ³•ï¼ŒSENTINEL å°†å®é™…å®‰å…¨éœ€æ±‚æ¤æ ¹äºæ—¶åºé€»è¾‘ (Temporal Logic) è¯­ä¹‰ä¸­ï¼Œèƒ½å¤Ÿç²¾ç¡®å®šä¹‰çŠ¶æ€ä¸å˜æ€§ã€æ—¶é—´ä¾èµ–å’Œæ—¶åºçº¦æŸã€‚è¯¥æ¡†æ¶é‡‡ç”¨å¤šçº§éªŒè¯æµæ°´çº¿ï¼Œé¦–å…ˆå°†è‡ªç„¶è¯­è¨€éœ€æ±‚è½¬åŒ–ä¸ºæ—¶åºé€»è¾‘å…¬å¼ä»¥æ¢æµ‹æ™ºèƒ½ä½“çš„è¯­ä¹‰å¯¹é½ï¼Œéšååœ¨è§„åˆ’å±‚éªŒè¯åŠ¨ä½œæ–¹æ¡ˆçš„å®‰å…¨æ€§ï¼Œæœ€ååœ¨è½¨è¿¹å±‚åˆ©ç”¨è®¡ç®—æ ‘å¯¹ç‰©ç†ç»†èŠ‚è¿›è¡Œæœ€ç»ˆå®‰å…¨æ£€æŸ¥ã€‚åœ¨ VirtualHome å’Œ ALFRED ç¯å¢ƒä¸‹çš„å®éªŒç»“æœè¡¨æ˜ï¼ŒSENTINEL èƒ½å¤Ÿè¯†åˆ«å‡ºè¢«å…ˆå‰æ–¹æ³•å¿½è§†çš„å®‰å…¨è¿è§„è¡Œä¸ºï¼Œä¸ºç³»ç»Ÿæ€§è¯„ä¼°å…·èº«æ™ºèƒ½ä½“åœ¨ç‰©ç†ç¯å¢ƒä¸­çš„è¡¨ç°æä¾›äº†ä¸¥è°¨çš„åŸºç¡€ï¼Œå¹¶æ·±å…¥æ­ç¤ºäº†å…¶æ½œåœ¨çš„å¤±æ•ˆæ¨¡å¼ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.12985v1",
      "published_date": "2025-10-14 20:53:51 UTC",
      "updated_date": "2025-10-14 20:53:51 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:19:26.165451+00:00"
    },
    {
      "arxiv_id": "2510.12979v1",
      "title": "DeepPlanner: Scaling Planning Capability for Deep Research Agents via Advantage Shaping",
      "title_zh": "DeepPlannerï¼šé€šè¿‡ä¼˜åŠ¿å¡‘é€ æå‡æ·±åº¦ç ”ç©¶æ™ºèƒ½ä½“çš„è§„åˆ’èƒ½åŠ›",
      "authors": [
        "Wei Fan",
        "Wenlin Yao",
        "Zheng Li",
        "Feng Yao",
        "Xin Liu",
        "Liang Qiu",
        "Qingyu Yin",
        "Yangqiu Song",
        "Bing Yin"
      ],
      "abstract": "Large language models (LLMs) augmented with multi-step reasoning and action generation abilities have shown promise in leveraging external tools to tackle complex tasks that require long-horizon planning. However, existing approaches either rely on implicit planning in the reasoning stage or introduce explicit planners without systematically addressing how to optimize the planning stage. As evidence, we observe that under vanilla reinforcement learning (RL), planning tokens exhibit significantly higher entropy than other action tokens, revealing uncertain decision points that remain under-optimized. To address this, we propose DeepPlanner, an end-to-end RL framework that effectively enhances the planning capabilities of deep research agents. Our approach shapes token-level advantage with an entropy-based term to allocate larger updates to high entropy tokens, and selectively upweights sample-level advantages for planning-intensive rollouts. Extensive experiments across seven deep research benchmarks demonstrate that DeepPlanner improves planning quality and achieves state-of-the-art results under a substantially lower training budget.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†DeepPlannerï¼Œè¿™æ˜¯ä¸€ç§ç«¯åˆ°ç«¯çš„å¼ºåŒ–å­¦ä¹ (Reinforcement Learning)æ¡†æ¶ï¼Œæ—¨åœ¨æå‡æ·±åº¦ç ”ç©¶æ™ºèƒ½ä½“(Deep Research Agents)åœ¨å¤„ç†å¤æ‚ä»»åŠ¡æ—¶çš„é•¿ç¨‹è§„åˆ’(Long-horizon Planning)èƒ½åŠ›ã€‚é’ˆå¯¹ç°æœ‰LLMæ™ºèƒ½ä½“åœ¨è§„åˆ’é˜¶æ®µå­˜åœ¨é«˜ç†µ(Entropy)å’Œå†³ç­–ä¸ç¡®å®šæ€§çš„é—®é¢˜ï¼ŒDeepPlannerå¼•å…¥äº†åŸºäºç†µçš„ä¼˜åŠ¿å¡‘é€ (Advantage Shaping)æŠ€æœ¯ï¼Œåœ¨Tokenå±‚é¢ä¸ºé«˜ç†µè§„åˆ’èŠ‚ç‚¹åˆ†é…æ›´å¤§çš„æ›´æ–°æƒé‡ã€‚åŒæ—¶ï¼Œè¯¥æ¡†æ¶é€šè¿‡åœ¨æ ·æœ¬å±‚é¢é€‰æ‹©æ€§åœ°åŠ æƒè§„åˆ’å¯†é›†å‹Rolloutsï¼Œå®ç°äº†å¯¹è§„åˆ’èƒ½åŠ›çš„ç³»ç»Ÿæ€§ä¼˜åŒ–ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒDeepPlanneråœ¨ä¸ƒä¸ªæ·±åº¦ç ”ç©¶åŸºå‡†æµ‹è¯•ä¸­æ˜¾è‘—æé«˜äº†è§„åˆ’è´¨é‡ï¼Œå¹¶åœ¨å¤§å¹…é™ä½è®­ç»ƒé¢„ç®—çš„æƒ…å†µä¸‹è¾¾åˆ°äº†å½“å‰æœ€å…ˆè¿›(State-of-the-Art)çš„æ€§èƒ½æ°´å¹³ã€‚",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "Under Review",
      "pdf_url": "https://arxiv.org/pdf/2510.12979v1",
      "published_date": "2025-10-14 20:47:05 UTC",
      "updated_date": "2025-10-14 20:47:05 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:19:30.586379+00:00"
    },
    {
      "arxiv_id": "2510.12957v1",
      "title": "A Multimodal XAI Framework for Trustworthy CNNs and Bias Detection in Deep Representation Learning",
      "title_zh": "ä¸€ç§é¢å‘å¯ä¿¡ CNN ä¸æ·±åº¦è¡¨ç¤ºå­¦ä¹ åè§æ£€æµ‹çš„å¤šæ¨¡æ€ XAI æ¡†æ¶",
      "authors": [
        "Noor Islam S. Mohammad"
      ],
      "abstract": "Standard benchmark datasets, such as MNIST, often fail to expose latent biases and multimodal feature complexities, limiting the trustworthiness of deep neural networks in high-stakes applications. We propose a novel multimodal Explainable AI (XAI) framework that unifies attention-augmented feature fusion, Grad-CAM++-based local explanations, and a Reveal-to-Revise feedback loop for bias detection and mitigation. Evaluated on multimodal extensions of MNIST, our approach achieves 93.2% classification accuracy, 91.6% F1-score, and 78.1% explanation fidelity (IoU-XAI), outperforming unimodal and non-explainable baselines. Ablation studies demonstrate that integrating interpretability with bias-aware learning enhances robustness and human alignment. Our work bridges the gap between performance, transparency, and fairness, highlighting a practical pathway for trustworthy AI in sensitive domains.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ MNIST ç­‰æ ‡å‡†åŸºå‡†æ•°æ®é›†åœ¨æ­ç¤ºæ½œåœ¨åè§å’Œå¤šæ¨¡æ€ç‰¹å¾å¤æ‚æ€§æ–¹é¢çš„ä¸è¶³ï¼Œæå‡ºäº†ä¸€ä¸ªæ—¨åœ¨æå‡æ·±åº¦ç¥ç»ç½‘ç»œå¯ä¿¡åº¦çš„å¤šæ¨¡æ€å¯è§£é‡Šäººå·¥æ™ºèƒ½ (XAI) æ¡†æ¶ã€‚è¯¥æ¡†æ¶ç»Ÿä¸€äº†æ³¨æ„åŠ›å¢å¼ºçš„ç‰¹å¾èåˆ (attention-augmented feature fusion)ã€åŸºäº Grad-CAM++ çš„å±€éƒ¨è§£é‡Šä»¥åŠç”¨äºåè§æ£€æµ‹ä¸ç¼“è§£çš„ Reveal-to-Revise åé¦ˆç¯è·¯ã€‚åœ¨å¤šæ¨¡æ€æ‰©å±•çš„ MNIST æ•°æ®é›†ä¸Šçš„è¯„ä¼°ç»“æœæ˜¾ç¤ºï¼Œè¯¥æ–¹æ³•å®ç°äº† 93.2% çš„åˆ†ç±»å‡†ç¡®ç‡ã€91.6% çš„ F1 åˆ†æ•°ä»¥åŠ 78.1% çš„è§£é‡Šå¿ å®åº¦ (IoU-XAI)ï¼Œæ€§èƒ½æ˜¾è‘—ä¼˜äºå•æ¨¡æ€å’Œä¸å¯è§£é‡Šçš„åŸºçº¿æ¨¡å‹ã€‚æ¶ˆèå®éªŒè¿›ä¸€æ­¥è¯æ˜ï¼Œå°†å¯è§£é‡Šæ€§ä¸åè§æ„ŸçŸ¥å­¦ä¹  (bias-aware learning) ç›¸ç»“åˆï¼Œèƒ½å¤Ÿå¢å¼ºæ¨¡å‹çš„ç¨³å¥æ€§å’Œäººç±»å¯¹é½ (human alignment)ã€‚è¿™é¡¹å·¥ä½œå¼¥åˆäº†æ€§èƒ½ã€é€æ˜åº¦ä¸å…¬å¹³æ€§ä¹‹é—´çš„é¸¿æ²Ÿï¼Œä¸ºæ•æ„Ÿé¢†åŸŸä¸­å¯ä¿¡ AI çš„å®ç°æä¾›äº†ä¸€æ¡åˆ‡å®çš„å®è·µè·¯å¾„ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.12957v1",
      "published_date": "2025-10-14 20:06:09 UTC",
      "updated_date": "2025-10-14 20:06:09 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:19:36.674934+00:00"
    },
    {
      "arxiv_id": "2510.13903v1",
      "title": "Benefits and Limitations of Communication in Multi-Agent Reasoning",
      "title_zh": "å¤šæ™ºèƒ½ä½“æ¨ç†ä¸­é€šä¿¡çš„ä¼˜åŠ¿ä¸å±€é™æ€§",
      "authors": [
        "Michael Rizvi-Martel",
        "Satwik Bhattamishra",
        "Neil Rathi",
        "Guillaume Rabusseau",
        "Michael Hahn"
      ],
      "abstract": "Chain-of-thought prompting has popularized step-by-step reasoning in large language models, yet model performance still degrades as problem complexity and context length grow. By decomposing difficult tasks with long contexts into shorter, manageable ones, recent multi-agent paradigms offer a promising near-term solution to this problem. However, the fundamental capacities of such systems are poorly understood. In this work, we propose a theoretical framework to analyze the expressivity of multi-agent systems. We apply our framework to three algorithmic families: state tracking, recall, and $k$-hop reasoning. We derive bounds on (i) the number of agents required to solve the task exactly, (ii) the quantity and structure of inter-agent communication, and (iii) the achievable speedups as problem size and context scale. Our results identify regimes where communication is provably beneficial, delineate tradeoffs between agent count and bandwidth, and expose intrinsic limitations when either resource is constrained. We complement our theoretical analysis with a set of experiments on pretrained LLMs using controlled synthetic benchmarks. Empirical outcomes confirm the tradeoffs between key quantities predicted by our theory. Collectively, our analysis offers principled guidance for designing scalable multi-agent reasoning systems.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§è¯­è¨€æ¨¡å‹(LLMs)åœ¨å¤„ç†å¤æ‚ä»»åŠ¡å’Œé•¿ä¸Šä¸‹æ–‡æ—¶ Chain-of-thought æ€§èƒ½ä¸‹é™çš„é—®é¢˜ï¼Œæ·±å…¥æ¢è®¨äº†å¤šæ™ºèƒ½ä½“(multi-agent)èŒƒå¼ä½œä¸ºè§£å†³æ–¹æ¡ˆçš„æ½œåŠ›ä¸å±€é™ã€‚ä½œè€…æå‡ºäº†ä¸€ä¸ªç”¨äºåˆ†æå¤šæ™ºèƒ½ä½“ç³»ç»Ÿè¡¨è¾¾èƒ½åŠ›(expressivity)çš„ç†è®ºæ¡†æ¶ï¼Œå¹¶å°†å…¶åº”ç”¨äºçŠ¶æ€è·Ÿè¸ª(state tracking)ã€å¬å›(recall)å’Œ $k$-hop reasoning ä¸‰ç±»æ ¸å¿ƒç®—æ³•æ—ã€‚é€šè¿‡æ¨å¯¼ï¼Œç ”ç©¶ç»™å‡ºäº†è§£å†³ç‰¹å®šä»»åŠ¡æ‰€éœ€çš„æ™ºèƒ½ä½“æ•°é‡ã€é€šä¿¡é‡åŠå…¶ç»“æ„ã€ä»¥åŠéšè§„æ¨¡å¢é•¿çš„å¯å®ç°åŠ é€Ÿæ¯”(speedups)çš„ç†è®ºè¾¹ç•Œã€‚ç ”ç©¶ç»“æœä¸ä»…ç¡®å®šäº†é€šä¿¡åœ¨è¯æ˜ä¸Šäº§ç”Ÿæ”¶ç›Šçš„åŒºé—´ï¼Œè¿˜æ­ç¤ºäº†æ™ºèƒ½ä½“æ•°é‡ä¸å¸¦å®½(bandwidth)ä¹‹é—´çš„æƒè¡¡å…³ç³»åŠèµ„æºå—é™æ—¶çš„å†…åœ¨å±€é™æ€§ã€‚åœ¨é¢„è®­ç»ƒ LLMs ä¸Šçš„å—æ§åˆæˆåŸºå‡†å®éªŒè¯å®äº†ç†è®ºé¢„æµ‹çš„å¯é æ€§ï¼Œä¸ºæ„å»ºå¯æ‰©å±•çš„åˆ†å¸ƒå¼å¤šæ™ºèƒ½ä½“æ¨ç†ç³»ç»Ÿæä¾›äº†é‡è¦çš„ç†è®ºæŒ‡å¯¼ã€‚",
      "categories": [
        "cs.MA",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.MA",
      "comment": "34 pages, 14 figures",
      "pdf_url": "https://arxiv.org/pdf/2510.13903v1",
      "published_date": "2025-10-14 20:04:27 UTC",
      "updated_date": "2025-10-14 20:04:27 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:19:37.567031+00:00"
    },
    {
      "arxiv_id": "2510.24737v1",
      "title": "Cardi-GPT: An Expert ECG-Record Processing Chatbot",
      "title_zh": "Cardi-GPTï¼šä¸“å®¶çº§å¿ƒç”µå›¾è®°å½•å¤„ç†èŠå¤©æœºå™¨äºº",
      "authors": [
        "Koustav Mallick",
        "Neel Singh",
        "Mohammedreza Hajiarbabi"
      ],
      "abstract": "Interpreting and communicating electrocardiogram (ECG) findings are crucial yet challenging tasks in cardiovascular diagnosis, traditionally requiring significant expertise and precise clinical communication. This paper introduces Cardi-GPT, an advanced expert system designed to streamline ECG interpretation and enhance clinical communication through deep learning and natural language interaction. Cardi-GPT employs a 16-residual-block convolutional neural network (CNN) to process 12-lead ECG data, achieving a weighted accuracy of 0.6194 across 24 cardiac conditions. A novel fuzzification layer converts complex numerical outputs into clinically meaningful linguistic categories, while an integrated chatbot interface facilitates intuitive exploration of diagnostic insights and seamless communication between healthcare providers.\n  The system was evaluated on a diverse dataset spanning six hospitals across four countries, demonstrating superior performance compared to baseline models. Additionally, Cardi-GPT achieved an impressive overall response quality score of 73\\%, assessed using a comprehensive evaluation framework that measures coverage, grounding, and coherence. By bridging the gap between intricate ECG data interpretation and actionable clinical insights, Cardi-GPT represents a transformative innovation in cardiovascular healthcare, promising to improve diagnostic accuracy, clinical workflows, and patient outcomes across diverse medical settings.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¨å‡ºäº† Cardi-GPTï¼Œä¸€ä¸ªæ—¨åœ¨é€šè¿‡æ·±åº¦å­¦ä¹ å’Œè‡ªç„¶è¯­è¨€äº¤äº’ç®€åŒ–å¿ƒç”µå›¾ (ECG) è§£é‡Šå¹¶å¢å¼ºä¸´åºŠæ²Ÿé€šçš„ä¸“å®¶ç³»ç»Ÿã€‚è¯¥ç³»ç»Ÿé‡‡ç”¨ 16-residual-block convolutional neural network (CNN) å¤„ç† 12-lead ECG æ•°æ®ï¼Œåœ¨ 24 ç§å¿ƒè„ç–¾ç—…è¯Šæ–­ä¸­å®ç°äº† 0.6194 çš„åŠ æƒå‡†ç¡®ç‡ã€‚å…¶æ ¸å¿ƒåˆ›æ–°åœ¨äºå¼•å…¥äº† fuzzification layerï¼Œèƒ½å¤Ÿå°†å¤æ‚çš„æ•°å€¼è¾“å‡ºè½¬åŒ–ä¸ºå…·æœ‰ä¸´åºŠæ„ä¹‰çš„è¯­è¨€ç±»åˆ«ï¼Œå¹¶ç»“åˆ chatbot æ¥å£å®ç°ç›´è§‚çš„è¯Šæ–­è§è§£æ¢ç´¢ã€‚åœ¨è·¨è¶Š 4 ä¸ªå›½å®¶ã€6 å®¶åŒ»é™¢çš„å¤šæ ·åŒ–æ•°æ®é›†è¯„ä¼°ä¸­ï¼ŒCardi-GPT çš„æ€§èƒ½ä¼˜äºåŸºçº¿æ¨¡å‹ï¼Œå…¶å“åº”è´¨é‡åœ¨ coverageã€grounding å’Œ coherence ç­‰ç»´åº¦ä¸‹çš„ç»¼åˆå¾—åˆ†ä¸º 73%ã€‚é€šè¿‡å¼¥è¡¥å¤æ‚æ•°æ®è§£è¯»ä¸ä¸´åºŠå†³ç­–ä¹‹é—´çš„å·®è·ï¼ŒCardi-GPT ä¸ºæå‡å¿ƒè¡€ç®¡åŒ»ç–—çš„è¯Šæ–­å‡†ç¡®æ€§ã€ä¼˜åŒ–ä¸´åºŠå·¥ä½œæµåŠæ”¹å–„æ‚£è€…é¢„åæä¾›äº†é‡è¦æŠ€æœ¯æ”¯æ’‘ã€‚",
      "categories": [
        "eess.SP",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "eess.SP",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.24737v1",
      "published_date": "2025-10-14 19:58:33 UTC",
      "updated_date": "2025-10-14 19:58:33 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:19:52.673857+00:00"
    },
    {
      "arxiv_id": "2510.12953v2",
      "title": "Epistemic-aware Vision-Language Foundation Model for Fetal Ultrasound Interpretation",
      "title_zh": "é¢å‘èƒå„¿è¶…å£°å½±åƒåˆ¤è¯»çš„è®¤çŸ¥æ„ŸçŸ¥è§†è§‰è¯­è¨€åŸºç¡€æ¨¡å‹",
      "authors": [
        "Xiao He",
        "Huangxuan Zhao",
        "Guojia Wan",
        "Wei Zhou",
        "Yanxing Liu",
        "Juhua Liu",
        "Yongchao Xu",
        "Yong Luo",
        "Dacheng Tao",
        "Bo Du"
      ],
      "abstract": "Recent medical vision-language models have shown promise on tasks such as VQA, report generation, and anomaly detection. However, most are adapted to structured adult imaging and underperform in fetal ultrasound, which poses challenges of multi-view image reasoning, numerous diseases, and image diversity. To bridge this gap, we introduce FetalMind, a medical AI system tailored to fetal ultrasound for both report generation and diagnosis. Guided by clinical workflow, we propose Salient Epistemic Disentanglement (SED), which injects an expert-curated bipartite graph into the model to decouple view-disease associations and to steer preference selection along clinically faithful steps via reinforcement learning. This design mitigates variability across diseases and heterogeneity across views, reducing learning bottlenecks while aligning the model's inference with obstetric practice. To train FetalMind at scale, we curate FetalSigma-1M dataset, the first large-scale fetal ultrasound report corpus, comprising 20K reports from twelve medical centers, addressing the scarcity of domain data. Extensive experiments show that FetalMind outperforms open- and closed-source baselines across all gestational stages, achieving +14% average gains and +61.2% higher accuracy on critical conditions while remaining efficient, stable, and scalable. Project Page: https://hexiao0275.github.io/FetalMind.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹èƒå„¿è¶…å£°å½±åƒåœ¨å¤šè§†è§’æ¨ç†ã€ç–¾ç—…å¤šæ ·æ€§å’Œå›¾åƒå¼‚è´¨æ€§æ–¹é¢çš„æŒ‘æˆ˜ï¼Œæå‡ºäº†ä¸“ä¸ºèƒå„¿è¶…å£°æŠ¥å‘Šç”Ÿæˆå’Œè¯Šæ–­è®¾è®¡çš„è§†è§‰è¯­è¨€åŸºç¡€æ¨¡å‹ FetalMindã€‚æ¨¡å‹å¼•å…¥äº†æ˜¾è‘—è®¤çŸ¥è§£è€¦ (Salient Epistemic Disentanglement, SED) æœºåˆ¶ï¼Œé€šè¿‡æ³¨å…¥ä¸“å®¶æ„å»ºçš„äºŒåˆ†å›¾æ¥è§£è€¦è§†è§’ä¸ç–¾ç—…çš„å…³è”ï¼Œå¹¶åˆ©ç”¨å¼ºåŒ–å­¦ä¹  (Reinforcement Learning) å¼•å¯¼ä¸´åºŠå¿ å®æ­¥éª¤çš„åå¥½é€‰æ‹©ã€‚è¯¥è®¾è®¡æœ‰æ•ˆç¼“è§£äº†ç–¾ç—…é—´çš„å˜å¼‚æ€§å’Œè§†è§’é—´çš„å¼‚è´¨æ€§ï¼Œä½¿æ¨¡å‹çš„æ¨ç†è¿‡ç¨‹ä¸äº§ç§‘ä¸´åºŠå®è·µä¿æŒé«˜åº¦ä¸€è‡´ã€‚ä¸ºäº†è§£å†³é¢†åŸŸæ•°æ®ç¨€ç¼ºé—®é¢˜ï¼Œç ”ç©¶å›¢é˜Ÿæ„å»ºäº†é¦–ä¸ªå¤§è§„æ¨¡èƒå„¿è¶…å£°æŠ¥å‘Šè¯­æ–™åº“ FetalSigma-1Mï¼ŒåŒ…å«æ¥è‡ª12ä¸ªåŒ»ç–—ä¸­å¿ƒçš„2ä¸‡ä»½æŠ¥å‘Šã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒFetalMind åœ¨æ‰€æœ‰å¦Šå¨ é˜¶æ®µçš„è¡¨ç°å‡ä¼˜äºç°æœ‰çš„å¼€æºå’Œé—­æºåŸºçº¿æ¨¡å‹ï¼Œå®ç°äº†14%çš„å¹³å‡æ€§èƒ½å¢ç›Šï¼Œä¸”åœ¨å±æ€¥ç—…ç—‡ä¸Šçš„å‡†ç¡®ç‡æ˜¾è‘—æå‡äº†61.2%ã€‚è¯¥ç ”ç©¶ä¸ºèƒå„¿è¶…å£°çš„è‡ªåŠ¨åŒ–è§£è¯»æä¾›äº†ä¸€ä¸ªé«˜æ•ˆã€ç¨³å®šä¸”å¯æ‰©å±•çš„ä¸“ä¸šäººå·¥æ™ºèƒ½ç³»ç»Ÿã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.IR",
        "cs.MM"
      ],
      "primary_category": "cs.CV",
      "comment": "This paper contains fundamental errors and will not be replaced",
      "pdf_url": "https://arxiv.org/pdf/2510.12953v2",
      "published_date": "2025-10-14 19:57:03 UTC",
      "updated_date": "2025-10-23 03:45:15 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:19:50.280474+00:00"
    },
    {
      "arxiv_id": "2510.12948v1",
      "title": "SpareCodeSearch: Searching for Code Context When You Have No Spare GPU",
      "title_zh": "SpareCodeSearchï¼šæ— é—²ç½® GPU èµ„æºä¸‹çš„ä»£ç ä¸Šä¸‹æ–‡æ£€ç´¢",
      "authors": [
        "Minh Nguyen"
      ],
      "abstract": "Retrieval-Augmented Generation (RAG) frameworks aim to enhance Code Language Models (CLMs) by including another module for retrieving relevant context to construct the input prompt. However, these retrieval modules commonly use semantic search, requiring substantial computational resources for training and hosting these embedded models, making them infeasible to integrate into lightweight applications such as in-IDE AI-based code completion. In this solution paper, we prove that using keyword-search is sufficient to retrieve relevant and useful code context inside large codebases, without the need for extensive GPU resources. The usefulness of code contexts found by our solution is demonstrated through their completion results on the Code Context Competition's benchmark, reaching 0.748 and 0.725 chRF scores on Kotlin and Python tracks, respectively.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹æ£€ç´¢å¢å¼ºç”Ÿæˆ (RAG) æ¡†æ¶åœ¨å¢å¼ºä»£ç è¯­è¨€æ¨¡å‹ (CLMs) æ—¶ï¼Œè¯­ä¹‰æœç´¢ (semantic search) å¯¹ GPU èµ„æºä¾èµ–è¿‡é«˜è€Œéš¾ä»¥é›†æˆåˆ° IDE ç­‰è½»é‡çº§åº”ç”¨çš„é—®é¢˜ï¼Œæå‡ºäº† SpareCodeSearchã€‚è¯¥æ–¹æ¡ˆè¯æ˜äº†åœ¨æ— éœ€å¤§è§„æ¨¡ GPU èµ„æºçš„æƒ…å†µä¸‹ï¼Œä»…åˆ©ç”¨å…³é”®è¯æœç´¢ (keyword-search) å³å¯åœ¨å¤§å‹ä»£ç åº“ä¸­æœ‰æ•ˆæ£€ç´¢åˆ°ç›¸å…³çš„ä»£ç ä¸Šä¸‹æ–‡ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ–¹æ³•åœ¨ Code Context Competition åŸºå‡†æµ‹è¯•çš„ Kotlin å’Œ Python èµ›é“ä¸Šåˆ†åˆ«è¾¾åˆ°äº† 0.748 å’Œ 0.725 çš„ chRF åˆ†æ•°ã€‚è¿™é¡¹ç ”ç©¶éªŒè¯äº† keyword-search åœ¨ä»£ç æ£€ç´¢ä»»åŠ¡ä¸­çš„å®ç”¨æ€§ï¼Œä¸ºèµ„æºå—é™ç¯å¢ƒä¸‹çš„ä»£ç è¡¥å…¨æŠ€æœ¯æä¾›äº†ä¸€ç§é«˜æ•ˆä¸”ä½æˆæœ¬çš„æ›¿ä»£æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "4 pages, 3 figures, 4 tables. Accepted to Context Collection Workshop co-located with ASE'25",
      "pdf_url": "https://arxiv.org/pdf/2510.12948v1",
      "published_date": "2025-10-14 19:48:50 UTC",
      "updated_date": "2025-10-14 19:48:50 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:20:06.710239+00:00"
    },
    {
      "arxiv_id": "2510.12947v1",
      "title": "HyWA: Hypernetwork Weight Adapting Personalized Voice Activity Detection",
      "title_zh": "HyWAï¼šåŸºäºè¶…ç½‘ç»œæƒé‡é€‚é…çš„ä¸ªæ€§åŒ–è¯­éŸ³æ´»åŠ¨æ£€æµ‹",
      "authors": [
        "Mahsa Ghazvini Nejad",
        "Hamed Jafarzadeh Asl",
        "Amin Edraki",
        "Mohammadreza Sadeghi",
        "Masoud Asgharian",
        "Yuanhao Yu",
        "Vahid Partovi Nia"
      ],
      "abstract": "Personalized Voice Activity Detection (PVAD) systems activate only in response to a specific target speaker by incorporating speaker embeddings from enrollment utterances. Unlike existing methods that require architectural changes, such as FiLM layers, our approach employs a hypernetwork to modify the weights of a few selected layers within a standard voice activity detection (VAD) model. This enables speaker conditioning without changing the VAD architecture, allowing the same VAD model to adapt to different speakers by updating only a small subset of the layers. We propose HyWA-PVAD, a hypernetwork weight adaptation method, and evaluate it against multiple baseline conditioning techniques. Our comparison shows consistent improvements in PVAD performance. HyWA also offers practical advantages for deployment by preserving the core VAD architecture. Our new approach improves the current conditioning techniques in two ways: i) increases the mean average precision, ii) simplifies deployment by reusing the same VAD architecture.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† HyWA-PVADï¼Œä¸€ç§åŸºäº Hypernetwork æƒé‡é€‚é…çš„ä¸ªæ€§åŒ–è¯­éŸ³æ´»åŠ¨æ£€æµ‹ï¼ˆPersonalized Voice Activity Detection, PVADï¼‰æ–¹æ³•ã€‚ä¸ä¼ ç»Ÿéœ€è¦ä¿®æ”¹æ¨¡å‹æ¶æ„ï¼ˆå¦‚ FiLM å±‚ï¼‰çš„æ–¹æ³•ä¸åŒï¼ŒHyWA é€šè¿‡ Hypernetwork ç›´æ¥ä¿®æ”¹æ ‡å‡† VAD æ¨¡å‹ä¸­éƒ¨åˆ†é€‰å®šå±‚çš„æƒé‡ï¼Œä»è€Œå®ç°ç‰¹å®šè¯´è¯äººçš„è°ƒèŠ‚ã€‚è¿™ç§æ–¹æ³•ä½¿å¾—åŒä¸€ä¸ª VAD æ¨¡å‹èƒ½å¤Ÿä»…é€šè¿‡æ›´æ–°å°‘é‡å±‚æƒé‡æ¥é€‚é…ä¸åŒè¯´è¯äººï¼Œä¸”æ— éœ€æ”¹å˜å…¶æ ¸å¿ƒæ¶æ„ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒHyWA-PVAD åœ¨æ€§èƒ½ä¸Šä¼˜äºå¤šç§åŸºçº¿è°ƒèŠ‚æŠ€æœ¯ï¼Œæ˜¾è‘—æå‡äº†å¹³å‡ç²¾åº¦å‡å€¼ï¼ˆmean average precisionï¼‰ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•é€šè¿‡ä¿ç•™åŸå§‹ VAD æ¶æ„ç®€åŒ–äº†å®é™…éƒ¨ç½²æµç¨‹ï¼Œåœ¨æå‡æ£€æµ‹æ•ˆæœçš„åŒæ—¶å¢å¼ºäº†ç³»ç»Ÿçš„å®ç”¨æ€§ã€‚",
      "categories": [
        "eess.AS",
        "cs.AI",
        "cs.LG",
        "cs.SD"
      ],
      "primary_category": "eess.AS",
      "comment": "Mahsa Ghazvini Nejad and Hamed Jafarzadeh Asl contributed equally to this work",
      "pdf_url": "https://arxiv.org/pdf/2510.12947v1",
      "published_date": "2025-10-14 19:46:40 UTC",
      "updated_date": "2025-10-14 19:46:40 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:20:07.916250+00:00"
    },
    {
      "arxiv_id": "2510.13900v1",
      "title": "Narrow Finetuning Leaves Clearly Readable Traces in Activation Differences",
      "title_zh": "çª„åŸŸå¾®è°ƒåœ¨æ¿€æ´»å·®å¼‚ä¸­ç•™ä¸‹æ¸…æ™°å¯è¾¨çš„ç—•è¿¹",
      "authors": [
        "Julian Minder",
        "ClÃ©ment Dumas",
        "Stewart Slocum",
        "Helena Casademunt",
        "Cameron Holmes",
        "Robert West",
        "Neel Nanda"
      ],
      "abstract": "Finetuning on narrow domains has become an essential tool to adapt Large Language Models (LLMs) to specific tasks and to create models with known unusual properties that are useful for research. We show that narrow finetuning creates strong biases in LLM activations that can be interpreted to understand the finetuning domain. These biases can be discovered using simple tools from model diffing - the study of differences between models before and after finetuning. In particular, analyzing activation differences on the first few tokens of random text and steering by adding this difference to the model activations produces text similar to the format and general content of the finetuning data. We demonstrate that these analyses contain crucial information by creating an LLM-based interpretability agent to understand the finetuning domain. With access to the bias, the agent performs significantly better compared to baseline agents using simple prompting. Our analysis spans synthetic document finetuning for false facts, emergent misalignment, subliminal learning, and taboo word guessing game models across different architectures (Gemma, LLaMA, Qwen) and scales (1B to 32B parameters). We suspect these biases reflect overfitting and find that mixing pretraining data into the finetuning corpus largely removes them, though residual risks may remain. Our work (1) demonstrates that narrowly finetuned models have salient traces of their training objective in their activations and suggests ways to improve how they are trained, (2) warns AI safety and interpretability researchers that the common practice of using such models as a proxy for studying broader finetuning (e.g., chat-tuning) might not be realistic, and (3) highlights the need for deeper investigation into the effects of narrow finetuning and development of truly realistic case studies for model-diffing, safety and interpretability research.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†çª„åŸŸå¾®è°ƒï¼ˆNarrow Finetuningï¼‰åœ¨å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰æ¿€æ´»å€¼ä¸­ç•™ä¸‹çš„æ˜¾è‘—ä¸”å¯è¯»çš„åå·®ã€‚ç ”ç©¶å‘ç°é€šè¿‡æ¨¡å‹å·®å¼‚åˆ†æï¼ˆmodel diffingï¼‰å·¥å…·ï¼Œåˆ†æéšæœºæ–‡æœ¬å‰å‡ ä¸ª token çš„æ¿€æ´»å·®å¼‚å¹¶ä»¥æ­¤è¿›è¡Œè½¬å‘ï¼ˆsteeringï¼‰ï¼Œå¯ä»¥å¤ç°å¾®è°ƒæ•°æ®çš„æ ¼å¼ä¸æ ¸å¿ƒå†…å®¹ã€‚åŸºäºæ­¤ï¼Œç ”ç©¶è€…æ„å»ºäº†ä¸€ä¸ªè§£é‡Šæ€§æ™ºèƒ½ä½“ï¼ˆinterpretability agentï¼‰ï¼Œè¯æ˜äº†åˆ©ç”¨è¿™äº›åå·®èƒ½æ¯”ä¼ ç»Ÿæç¤ºè¯æ–¹å¼æ›´æœ‰æ•ˆåœ°è¯†åˆ«å¾®è°ƒé¢†åŸŸã€‚å®éªŒæ¶µç›–äº† Gemmaã€LLaMA å’Œ Qwen ç­‰å¤šç§æ¶æ„ä¸è§„æ¨¡ï¼Œæ­ç¤ºäº†æ­¤ç±»åå·®ä¸»è¦æºäºè¿‡æ‹Ÿåˆï¼ˆoverfittingï¼‰ç°è±¡ï¼Œå¹¶å¯é€šè¿‡åœ¨å¾®è°ƒè¯­æ–™ä¸­æ··å…¥é¢„è®­ç»ƒæ•°æ®æ¥æ¶ˆé™¤ã€‚è¯¥æˆæœæé†’ AI å®‰å…¨å’Œå¯è§£é‡Šæ€§ç ”ç©¶è€…ï¼Œçª„åŸŸå¾®è°ƒæ¨¡å‹åœ¨æ¿€æ´»å±‚é¢ä¸Šå¸¦æœ‰æ˜æ˜¾çš„è®­ç»ƒç›®æ ‡ç—•è¿¹ï¼Œå› æ­¤å°†å…¶ä½œä¸ºé€šç”¨å¾®è°ƒï¼ˆå¦‚ chat-tuningï¼‰çš„æ›¿ä»£ç ”ç©¶å¯¹è±¡å¯èƒ½å­˜åœ¨å±€é™æ€§ï¼Œå¹¶å¼ºè°ƒäº†å¼€å‘æ›´çœŸå®æ¨¡å‹å·®å¼‚åˆ†ææ¡ˆä¾‹çš„å¿…è¦æ€§ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.13900v1",
      "published_date": "2025-10-14 19:05:59 UTC",
      "updated_date": "2025-10-14 19:05:59 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:20:24.583998+00:00"
    },
    {
      "arxiv_id": "2510.12920v1",
      "title": "InferA: A Smart Assistant for Cosmological Ensemble Data",
      "title_zh": "InferAï¼šé¢å‘å®‡å®™å­¦ç³»ç»¼æ•°æ®çš„æ™ºèƒ½åŠ©æ‰‹",
      "authors": [
        "Justin Z. Tam",
        "Pascal Grosset",
        "Divya Banesh",
        "Nesar Ramachandra",
        "Terece L. Turton",
        "James Ahrens"
      ],
      "abstract": "Analyzing large-scale scientific datasets presents substantial challenges due to their sheer volume, structural complexity, and the need for specialized domain knowledge. Automation tools, such as PandasAI, typically require full data ingestion and lack context of the full data structure, making them impractical as intelligent data analysis assistants for datasets at the terabyte scale. To overcome these limitations, we propose InferA, a multi-agent system that leverages large language models to enable scalable and efficient scientific data analysis. At the core of the architecture is a supervisor agent that orchestrates a team of specialized agents responsible for distinct phases of the data retrieval and analysis. The system engages interactively with users to elicit their analytical intent and confirm query objectives, ensuring alignment between user goals and system actions. To demonstrate the framework's usability, we evaluate the system using ensemble runs from the HACC cosmology simulation which comprises several terabytes.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† InferAï¼Œä¸€ä¸ªæ—¨åœ¨è§£å†³å¤§è§„æ¨¡ç§‘å­¦æ•°æ®é›†åˆ†æéš¾é¢˜çš„å¤šæ™ºèƒ½ä½“ç³»ç»Ÿï¼Œä¸»è¦é’ˆå¯¹ TB çº§æ•°æ®åœ¨ä½“é‡ã€ç»“æ„å¤æ‚æ€§å’Œé¢†åŸŸçŸ¥è¯†éœ€æ±‚æ–¹é¢çš„æŒ‘æˆ˜ã€‚ç›¸æ¯” PandasAI ç­‰ä¼ ç»Ÿè‡ªåŠ¨åŒ–å·¥å…·ï¼ŒInferA æ— éœ€å…¨é‡æ•°æ®æ‘„å…¥ï¼ˆData Ingestionï¼‰å¹¶èƒ½ç†è§£å®Œæ•´çš„æ•°æ®ç»“æ„ï¼Œä»è€Œæ»¡è¶³äº†å¤§è§„æ¨¡æ™ºèƒ½æ•°æ®åˆ†æçš„å®é™…éœ€æ±‚ã€‚å…¶æ ¸å¿ƒæ¶æ„ç”±ä¸€ä¸ª Supervisor Agent åè°ƒå¤šä¸ªä¸“é—¨ä»äº‹æ•°æ®æ£€ç´¢å’Œåˆ†æä¸åŒé˜¶æ®µçš„ Specialized Agentsï¼Œå®ç°äº†é«˜æ•ˆçš„ä»»åŠ¡ç¼–æ’ã€‚ç³»ç»Ÿé€šè¿‡ä¸ç”¨æˆ·è¿›è¡Œäº¤äº’ä»¥å¼•å¯¼å…¶åˆ†ææ„å›¾å¹¶ç¡®è®¤æŸ¥è¯¢ç›®æ ‡ï¼Œç¡®ä¿äº†ç³»ç»Ÿæ“ä½œä¸ç”¨æˆ·ç›®æ ‡çš„é«˜åº¦ä¸€è‡´ã€‚ä¸ºäº†å±•ç¤ºè¯¥æ¡†æ¶çš„å¯ç”¨æ€§ï¼Œç ”ç©¶è€…åˆ©ç”¨æ¥è‡ª HACC å®‡å®™å­¦æ¨¡æ‹Ÿï¼ˆCosmology Simulationï¼‰çš„æ•° TB è§„æ¨¡é›†æˆè¿è¡Œï¼ˆEnsemble Runsï¼‰æ•°æ®é›†å¯¹å…¶è¿›è¡Œäº†è¯„ä¼°ã€‚InferA ä¸ºå¤„ç†å¤æ‚ä¸”åºå¤§çš„ç§‘å­¦æ•°æ®é›†æä¾›äº†ä¸€ä¸ªå¯æ‰©å±•ä¸”é«˜æ•ˆçš„æ™ºèƒ½åŒ–åˆ†ææ–¹æ¡ˆã€‚",
      "categories": [
        "astro-ph.IM",
        "cs.AI"
      ],
      "primary_category": "astro-ph.IM",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.12920v1",
      "published_date": "2025-10-14 18:47:22 UTC",
      "updated_date": "2025-10-14 18:47:22 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:20:15.490556+00:00"
    },
    {
      "arxiv_id": "2510.12872v2",
      "title": "KVCOMM: Online Cross-context KV-cache Communication for Efficient LLM-based Multi-agent Systems",
      "title_zh": "KVCOMMï¼šé¢å‘é«˜æ•ˆå¤§è¯­è¨€æ¨¡å‹å¤šæ™ºèƒ½ä½“ç³»ç»Ÿçš„åœ¨çº¿è·¨ä¸Šä¸‹æ–‡ KV ç¼“å­˜é€šä¿¡",
      "authors": [
        "Hancheng Ye",
        "Zhengqi Gao",
        "Mingyuan Ma",
        "Qinsi Wang",
        "Yuzhe Fu",
        "Ming-Yu Chung",
        "Yueqian Lin",
        "Zhijian Liu",
        "Jianyi Zhang",
        "Danyang Zhuo",
        "Yiran Chen"
      ],
      "abstract": "Multi-agent large language model (LLM) systems are increasingly adopted for complex language processing tasks that require communication and coordination among agents. However, these systems often suffer substantial overhead from repeated reprocessing of overlapping contexts across agents. In typical pipelines, once an agent receives a message from its predecessor, the full context-including prior turns-must be reprocessed from scratch, leading to inefficient processing. While key-value (KV) caching is an effective solution for avoiding redundant computation in single-agent settings where prefixes remain unchanged, it cannot be directly reused in multi-agent scenarios due to diverging prefixes introduced by agent-specific context extensions. We identify that the core challenge lies in the offset variance of KV-caches across agents. To address this, we propose KVCOMM, a training-free framework that enables efficient prefilling in multi-agent inference by reusing KV-caches and aligning cache offsets of overlapping contexts under diverse prefix contexts. KVCOMM estimates and adjusts KV-caches for shared content by referencing a pool of cached examples-termed anchors-that store observed cache deviations under varying prefixes. The anchor pool is maintained and updated online, allowing dynamic adaptation to distinct user requests and context structures. KVCOMM achieves over 70% reuse rate across diverse multi-agent workloads, including retrieval-augmented generation, math reasoning, and collaborative coding tasks, all without quality degradation. Particularly, when each fully-connected agent receives 1K input tokens with 512 prefix tokens and 512 output tokens under a five-agent setting, KVCOMM achieves up to 7.8x speedup compared to the standard prefill pipeline, reducing TTFT from ~430 ms to ~55 ms.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤šæ™ºèƒ½ä½“å¤§è¯­è¨€æ¨¡å‹(LLM)ç³»ç»Ÿåœ¨å¤„ç†é‡å ä¸Šä¸‹æ–‡æ—¶å› å‰ç¼€å·®å¼‚å¯¼è‡´çš„é‡å¤è®¡ç®—å¼€é”€ï¼Œæ·±å…¥æ¢è®¨äº†è·¨æ™ºèƒ½ä½“Key-Value (KV) cacheåç§»æ–¹å·®å¸¦æ¥çš„æ ¸å¿ƒæŒ‘æˆ˜ã€‚ä¸ºæ­¤ï¼Œä½œè€…æå‡ºäº†KVCOMMï¼Œä¸€ç§æ— éœ€è®­ç»ƒçš„æ¡†æ¶ï¼Œé€šè¿‡åœ¨ä¸åŒå‰ç¼€èƒŒæ™¯ä¸‹å¯¹é½é‡å ä¸Šä¸‹æ–‡çš„ç¼“å­˜åç§»æ¥å®ç°KV-cacheçš„é«˜æ•ˆå¤ç”¨ã€‚è¯¥æ¡†æ¶åˆ©ç”¨åœ¨çº¿ç»´æŠ¤çš„â€œé”šç‚¹â€(anchors)ç¼“å­˜æ± æ¥åŠ¨æ€ä¼°ç®—å’Œè°ƒæ•´å…±äº«å†…å®¹çš„ç¼“å­˜æ•°æ®ï¼Œä»è€Œçµæ´»é€‚åº”å¤šå˜çš„ä¸Šä¸‹æ–‡ç»“æ„ã€‚å®éªŒè¯æ˜ï¼ŒKVCOMMåœ¨æ£€ç´¢å¢å¼ºç”Ÿæˆ(RAG)ã€æ•°å­¦æ¨ç†å’Œåä½œç¼–ç¨‹ç­‰ä»»åŠ¡ä¸­å®ç°äº†è¶…è¿‡70%çš„ç¼“å­˜å¤ç”¨ç‡ï¼Œä¸”ä¸æŸå¤±æ¨¡å‹è¡¨ç°ã€‚åœ¨äº”æ™ºèƒ½ä½“å…¸å‹é…ç½®ä¸‹ï¼Œè¯¥æ–¹æ³•ç›¸æ¯”æ ‡å‡†æµæ°´çº¿å¯å®ç°é«˜è¾¾7.8å€çš„åŠ é€Ÿï¼Œå°†é¦–Tokenå»¶è¿Ÿ(TTFT)ä»çº¦430æ¯«ç§’å¤§å¹…ç¼©å‡è‡³55æ¯«ç§’ã€‚è¿™ä¸€æˆæœæ˜¾è‘—æå‡äº†å¤šæ™ºèƒ½ä½“ååŒç³»ç»Ÿçš„æ¨ç†æ•ˆç‡ï¼Œä¸ºæ„å»ºä½å»¶è¿Ÿçš„å¤æ‚è¯­è¨€å¤„ç†åº”ç”¨æä¾›äº†æŠ€æœ¯æ”¯æ’‘ã€‚",
      "categories": [
        "cs.MA",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.MA",
      "comment": "Accepted for publication in NeurIPS2025. Code is available at \\url{https://github.com/FastMAS/KVCOMM}",
      "pdf_url": "https://arxiv.org/pdf/2510.12872v2",
      "published_date": "2025-10-14 18:00:01 UTC",
      "updated_date": "2025-11-01 08:26:24 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:20:20.886034+00:00"
    },
    {
      "arxiv_id": "2510.12796v2",
      "title": "DriveVLA-W0: World Models Amplify Data Scaling Law in Autonomous Driving",
      "title_zh": "DriveVLA-W0ï¼šä¸–ç•Œæ¨¡å‹å¼ºåŒ–è‡ªåŠ¨é©¾é©¶ä¸­çš„æ•°æ®ç¼©æ”¾å®šå¾‹",
      "authors": [
        "Yingyan Li",
        "Shuyao Shang",
        "Weisong Liu",
        "Bing Zhan",
        "Haochen Wang",
        "Yuqi Wang",
        "Yuntao Chen",
        "Xiaoman Wang",
        "Yasong An",
        "Chufeng Tang",
        "Lu Hou",
        "Lue Fan",
        "Zhaoxiang Zhang"
      ],
      "abstract": "Scaling Vision-Language-Action (VLA) models on large-scale data offers a promising path to achieving a more generalized driving intelligence. However, VLA models are limited by a ``supervision deficit'': the vast model capacity is supervised by sparse, low-dimensional actions, leaving much of their representational power underutilized. To remedy this, we propose \\textbf{DriveVLA-W0}, a training paradigm that employs world modeling to predict future images. This task generates a dense, self-supervised signal that compels the model to learn the underlying dynamics of the driving environment. We showcase the paradigm's versatility by instantiating it for two dominant VLA archetypes: an autoregressive world model for VLAs that use discrete visual tokens, and a diffusion world model for those operating on continuous visual features. Building on the rich representations learned from world modeling, we introduce a lightweight action expert to address the inference latency for real-time deployment. Extensive experiments on the NAVSIM v1/v2 benchmark and a 680x larger in-house dataset demonstrate that DriveVLA-W0 significantly outperforms BEV and VLA baselines. Crucially, it amplifies the data scaling law, showing that performance gains accelerate as the training dataset size increases.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†DriveVLA-W0ï¼Œä¸€ç§æ—¨åœ¨è§£å†³è§†è§‰è¯­è¨€åŠ¨ä½œæ¨¡å‹(Vision-Language-Action, VLA)åœ¨è‡ªåŠ¨é©¾é©¶é¢†åŸŸé¢ä¸´â€œç›‘ç£èµ¤å­—â€(supervision deficit)é—®é¢˜çš„è®­ç»ƒèŒƒå¼ã€‚è¯¥èŒƒå¼é€šè¿‡å¼•å…¥é¢„æµ‹æœªæ¥å›¾åƒçš„ä¸–ç•Œæ¨¡å‹(world modeling)ä»»åŠ¡ï¼Œäº§ç”Ÿç¨ å¯†çš„è‡ªç›‘ç£ä¿¡å·ï¼Œä¿ƒä½¿æ¨¡å‹æ·±åº¦ç†è§£é©¾é©¶ç¯å¢ƒçš„æ½œåœ¨åŠ¨åŠ›å­¦ã€‚è¯¥æ–¹æ³•å…·æœ‰æå¼ºçš„é€šç”¨æ€§ï¼Œå¯çµæ´»åº”ç”¨äºåŸºäºç¦»æ•£è§†è§‰æ ‡è®°çš„è‡ªå›å½’ä¸–ç•Œæ¨¡å‹å’ŒåŸºäºè¿ç»­è§†è§‰ç‰¹å¾çš„æ‰©æ•£ä¸–ç•Œæ¨¡å‹ï¼Œå¹¶ç»“åˆè½»é‡åŒ–çš„åŠ¨ä½œä¸“å®¶(action expert)ä»¥ä¼˜åŒ–å®æ—¶éƒ¨ç½²çš„æ¨ç†æ€§èƒ½ã€‚åœ¨NAVSIM v1/v2åŸºå‡†æµ‹è¯•å’Œè§„æ¨¡å¤§680å€çš„å†…éƒ¨æ•°æ®é›†ä¸Šçš„å®éªŒè¯æ˜ï¼ŒDriveVLA-W0çš„æ€§èƒ½æ˜¾è‘—ä¼˜äºBEVå’ŒVLAåŸºçº¿æ¨¡å‹ã€‚æœ€å…³é”®çš„æ˜¯ï¼Œè¯¥ç ”ç©¶è¯å®DriveVLA-W0èƒ½å¤Ÿæ”¾å¤§æ•°æ®ç¼©æ”¾å®šå¾‹(data scaling law)ï¼Œä½¿å¾—æ¨¡å‹æ€§èƒ½éšæ•°æ®é‡å¢åŠ å‘ˆç°å‡ºåŠ é€Ÿæå‡çš„æ€åŠ¿ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.12796v2",
      "published_date": "2025-10-14 17:59:47 UTC",
      "updated_date": "2025-12-18 07:25:29 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:20:20.675622+00:00"
    },
    {
      "arxiv_id": "2510.12795v1",
      "title": "CuMPerLay: Learning Cubical Multiparameter Persistence Vectorizations",
      "title_zh": "CuMPerLayï¼šå­¦ä¹ ç«‹æ–¹å¤šå‚æ•°æŒä¹…åŒ–å‘é‡åŒ–",
      "authors": [
        "Caner Korkmaz",
        "Brighton Nuwagira",
        "BarÄ±ÅŸ CoÅŸkunuzer",
        "Tolga Birdal"
      ],
      "abstract": "We present CuMPerLay, a novel differentiable vectorization layer that enables the integration of Cubical Multiparameter Persistence (CMP) into deep learning pipelines. While CMP presents a natural and powerful way to topologically work with images, its use is hindered by the complexity of multifiltration structures as well as the vectorization of CMP. In face of these challenges, we introduce a new algorithm for vectorizing MP homologies of cubical complexes. Our CuMPerLay decomposes the CMP into a combination of individual, learnable single-parameter persistence, where the bifiltration functions are jointly learned. Thanks to the differentiability, its robust topological feature vectors can be seamlessly used within state-of-the-art architectures such as Swin Transformers. We establish theoretical guarantees for the stability of our vectorization under generalized Wasserstein metrics. Our experiments on benchmark medical imaging and computer vision datasets show the benefit CuMPerLay on classification and segmentation performance, particularly in limited-data scenarios. Overall, CuMPerLay offers a promising direction for integrating global structural information into deep networks for structured image analysis.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†CuMPerLayï¼Œä¸€ç§æ–°é¢–çš„å¯å¾®åˆ†å‘é‡åŒ–å±‚ï¼Œæ—¨åœ¨å°†Cubical Multiparameter Persistence (CMP) é›†æˆåˆ°æ·±åº¦å­¦ä¹ æµæ°´çº¿ä¸­ã€‚é’ˆå¯¹CMPåœ¨å¤„ç†å›¾åƒæ‹“æ‰‘æ—¶é¢ä¸´çš„multifiltrationç»“æ„å¤æ‚æ€§å’Œå‘é‡åŒ–éš¾é¢˜ï¼ŒCuMPerLayé€šè¿‡æ–°ç®—æ³•å°†å…¶åˆ†è§£ä¸ºå¯å­¦ä¹ çš„å•å‚æ•°æŒä¹…æ€§ç»„åˆï¼Œå¹¶å®ç°bifiltrationå‡½æ•°çš„è”åˆå­¦ä¹ ã€‚å‡­å€Ÿå…¶å¯å¾®åˆ†ç‰¹æ€§ï¼ŒCuMPerLayç”Ÿæˆçš„é²æ£’æ‹“æ‰‘ç‰¹å¾å‘é‡èƒ½æ— ç¼é›†æˆè‡³Swin Transformersç­‰å…ˆè¿›æ¶æ„ï¼Œä¸”åœ¨ç†è®ºä¸Šè¯æ˜äº†å…¶åœ¨å¹¿ä¹‰Wasserstein metricsä¸‹çš„ç¨³å®šæ€§ã€‚åœ¨åŒ»å­¦å½±åƒå’Œè®¡ç®—æœºè§†è§‰åŸºå‡†æ•°æ®é›†ä¸Šçš„å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ–¹æ³•åœ¨åˆ†ç±»å’Œåˆ†å‰²ä»»åŠ¡ä¸­è¡¨ç°å‡ºè‰²ï¼Œå°¤å…¶åœ¨æœ‰é™æ•°æ®(limited-data scenarios)åœºæ™¯ä¸‹ä¼˜åŠ¿æ˜¾è‘—ã€‚æ€»ä½“è€Œè¨€ï¼ŒCuMPerLayä¸ºæ·±åº¦ç½‘ç»œæ•´åˆå…¨å±€ç»“æ„ä¿¡æ¯ä»¥è¿›è¡Œç»“æ„åŒ–å›¾åƒåˆ†ææä¾›äº†ä¸€ä¸ªæå…·å‰æ™¯çš„æ–¹å‘ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "math.AT",
        "stat.ML"
      ],
      "primary_category": "cs.CV",
      "comment": "Appears at ICCV 2025",
      "pdf_url": "https://arxiv.org/pdf/2510.12795v1",
      "published_date": "2025-10-14 17:59:01 UTC",
      "updated_date": "2025-10-14 17:59:01 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:20:21.673560+00:00"
    },
    {
      "arxiv_id": "2510.12789v1",
      "title": "UniFusion: Vision-Language Model as Unified Encoder in Image Generation",
      "title_zh": "UniFusionï¼šå°†è§†è§‰è¯­è¨€æ¨¡å‹ä½œä¸ºå›¾åƒç”Ÿæˆçš„ç»Ÿä¸€ç¼–ç å™¨",
      "authors": [
        "Kevin Li",
        "Manuel Brack",
        "Sudeep Katakol",
        "Hareesh Ravi",
        "Ajinkya Kale"
      ],
      "abstract": "Although recent advances in visual generation have been remarkable, most existing architectures still depend on distinct encoders for images and text. This separation constrains diffusion models' ability to perform cross-modal reasoning and knowledge transfer. Prior attempts to bridge this gap often use the last layer information from VLM, employ multiple visual encoders, or train large unified models jointly for text and image generation, which demands substantial computational resources and large-scale data, limiting its accessibility.We present UniFusion, a diffusion-based generative model conditioned on a frozen large vision-language model (VLM) that serves as a unified multimodal encoder. At the core of UniFusion is the Layerwise Attention Pooling (LAP) mechanism that extracts both high level semantics and low level details from text and visual tokens of a frozen VLM to condition a diffusion generative model. We demonstrate that LAP outperforms other shallow fusion architectures on text-image alignment for generation and faithful transfer of visual information from VLM to the diffusion model which is key for editing. We propose VLM-Enabled Rewriting Injection with Flexibile Inference (VERIFI), which conditions a diffusion transformer (DiT) only on the text tokens generated by the VLM during in-model prompt rewriting. VERIFI combines the alignment of the conditioning distribution with the VLM's reasoning capabilities for increased capabilities and flexibility at inference. In addition, finetuning on editing task not only improves text-image alignment for generation, indicative of cross-modality knowledge transfer, but also exhibits tremendous generalization capabilities. Our model when trained on single image editing, zero-shot generalizes to multiple image references further motivating the unified encoder design of UniFusion.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç°æœ‰å›¾åƒç”Ÿæˆæ¶æ„ä¸­å›¾åƒå’Œæ–‡æœ¬ç¼–ç å™¨åˆ†ç¦»å¯¼è‡´è·¨æ¨¡æ€æ¨ç†å—é™çš„é—®é¢˜ï¼Œæå‡ºäº†UniFusionï¼Œä¸€ç§ä»¥å†»ç»“çš„å¤§å‹è§†è§‰è¯­è¨€æ¨¡å‹(VLM)ä½œä¸ºç»Ÿä¸€å¤šæ¨¡æ€ç¼–ç å™¨çš„æ‰©æ•£ç”Ÿæˆæ¨¡å‹ã€‚å…¶æ ¸å¿ƒæ˜¯å±‚çº§æ³¨æ„åŠ›æ± åŒ–(LAP)æœºåˆ¶ï¼Œèƒ½å¤Ÿä»å†»ç»“VLMçš„æ–‡æœ¬å’Œè§†è§‰tokenä¸­æå–é«˜å±‚è¯­ä¹‰å’Œåº•å±‚ç»†èŠ‚ï¼Œä»è€Œåœ¨ç”Ÿæˆå’Œè§†è§‰ä¿¡æ¯ä¼ é€’æ–¹é¢æ˜¾è‘—ä¼˜äºå…¶ä»–æµ…å±‚èåˆæ¶æ„ã€‚ç ”ç©¶è¿˜å¼•å…¥äº†å…·æœ‰çµæ´»æ¨ç†èƒ½åŠ›çš„VERIFIæœºåˆ¶ï¼Œé€šè¿‡åœ¨æ¨¡å‹å†…è¿›è¡Œæç¤ºè¯é‡å†™ï¼Œå……åˆ†åˆ©ç”¨VLMçš„æ¨ç†èƒ½åŠ›æ¥å¢å¼ºç”Ÿæˆè¿‡ç¨‹çš„å¯¹é½æ€§ã€‚å®éªŒè¡¨æ˜ï¼Œåœ¨ç¼–è¾‘ä»»åŠ¡ä¸Šçš„å¾®è°ƒä¸ä»…ä¿ƒè¿›äº†è·¨æ¨¡æ€çŸ¥è¯†è¿ç§»ï¼Œè¿˜ä½¿æ¨¡å‹è¡¨ç°å‡ºæå¼ºçš„æ³›åŒ–æ€§ï¼Œä½¿å…¶åœ¨ä»…æ¥å—å•å›¾ç¼–è¾‘è®­ç»ƒçš„æƒ…å†µä¸‹å³å¯é›¶æ ·æœ¬(zero-shot)æ³›åŒ–è‡³å¤šå›¾å‚è€ƒä»»åŠ¡ã€‚è¿™ä¸€ç»Ÿä¸€ç¼–ç å™¨è®¾è®¡ä¸ºæå‡æ‰©æ•£æ¨¡å‹åœ¨æ–‡æœ¬-å›¾åƒå¯¹é½(text-image alignment)å’Œå¤æ‚å›¾åƒç¼–è¾‘ä¸­çš„è¡¨ç°æä¾›äº†é«˜æ•ˆä¸”çµæ´»çš„è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Project page at https://thekevinli.github.io/unifusion/",
      "pdf_url": "https://arxiv.org/pdf/2510.12789v1",
      "published_date": "2025-10-14 17:57:56 UTC",
      "updated_date": "2025-10-14 17:57:56 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:20:27.480611+00:00"
    },
    {
      "arxiv_id": "2510.12787v3",
      "title": "Ax-Prover: A Deep Reasoning Agentic Framework for Theorem Proving in Mathematics and Quantum Physics",
      "title_zh": "Ax-Proverï¼šä¸€ç§é¢å‘æ•°å­¦ä¸é‡å­ç‰©ç†å®šç†è¯æ˜çš„æ·±åº¦æ¨ç†æ™ºèƒ½ä½“æ¡†æ¶",
      "authors": [
        "Benjamin Breen",
        "Marco Del Tredici",
        "Jacob McCarran",
        "Javier Aspuru Mijares",
        "Weichen Winston Yin",
        "Kfir Sulimany",
        "Jacob M. Taylor",
        "Frank H. L. Koppens",
        "Dirk Englund"
      ],
      "abstract": "We present Ax-Prover, a multi-agent system for automated theorem proving in Lean that can solve problems across diverse scientific domains and operate either autonomously or collaboratively with human experts. To achieve this, Ax-Prover approaches scientific problem solving through formal proof generation, a process that demands both creative reasoning and strict syntactic rigor. Ax-Prover meets this challenge by equipping Large Language Models (LLMs), which provide knowledge and reasoning, with Lean tools via the Model Context Protocol (MCP), which ensure formal correctness. To evaluate its performance as an autonomous prover, we benchmark our approach against frontier LLMs and specialized prover models on two public math benchmarks and on two Lean benchmarks we introduce in the fields of abstract algebra and quantum theory. On public datasets, Ax-Prover is competitive with state-of-the-art provers, while it largely outperforms them on the new benchmarks. This shows that, unlike specialized systems that struggle to generalize, our tool-based agentic theorem prover approach offers a generalizable methodology for formal verification across diverse scientific domains. Furthermore, we demonstrate Ax-Prover's assistant capabilities in a practical use case, showing how it enabled an expert mathematician to formalize the proof of a complex cryptography theorem.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† Ax-Proverï¼Œè¿™æ˜¯ä¸€ä¸ªç”¨äº Lean è‡ªåŠ¨å®šç†è¯æ˜çš„å¤šæ™ºèƒ½ä½“ç³»ç»Ÿï¼Œæ—¨åœ¨è§£å†³æ•°å­¦å’Œé‡å­ç‰©ç†ç­‰è·¨å­¦ç§‘é¢†åŸŸçš„ç§‘å­¦éš¾é¢˜ã€‚Ax-Prover é€šè¿‡æ¨¡å‹ä¸Šä¸‹æ–‡åè®® (Model Context Protocol, MCP) å°†å…·å¤‡æ¨ç†èƒ½åŠ›çš„å¤§è¯­è¨€æ¨¡å‹ (LLMs) ä¸ Lean å½¢å¼åŒ–å·¥å…·ç›¸ç»“åˆï¼Œåœ¨ç¡®ä¿è¯­æ³•ä¸¥è°¨æ€§çš„åŒæ—¶æä¾›äº†å¼ºå¤§çš„åˆ›é€ æ€§æ¨ç†èƒ½åŠ›ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒAx-Prover åœ¨å…¬å¼€æ•°å­¦åŸºå‡†ä»¥åŠæ–°å¼€å‘çš„æŠ½è±¡ä»£æ•°å’Œé‡å­ç†è®ºåŸºå‡†æµ‹è¯•ä¸­è¡¨ç°ä¼˜å¼‚ï¼Œå…¶æ€§èƒ½æ˜¾è‘—è¶…è¶Šäº†ä¼ ç»Ÿçš„ä¸“é—¨åŒ–è¯æ˜ç³»ç»Ÿã€‚è¿™è¡¨æ˜åŸºäºå·¥å…·çš„æ™ºèƒ½ä½“æ–¹æ³•åœ¨å½¢å¼åŒ–éªŒè¯é¢†åŸŸå…·æœ‰æå¼ºçš„æ³›åŒ–èƒ½åŠ›ï¼Œèƒ½å¤Ÿé€‚åº”å¤šæ ·åŒ–çš„ç§‘å­¦é¢†åŸŸã€‚æ­¤å¤–ï¼Œè¯¥ç³»ç»Ÿè¿˜å±•ç°äº†å“è¶Šçš„äººæœºåä½œæ½œåŠ›ï¼ŒæˆåŠŸè¾…åŠ©ä¸“å®¶å®Œæˆäº†å¤æ‚å¯†ç å­¦å®šç†çš„å½¢å¼åŒ–è¯æ˜ã€‚",
      "categories": [
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.12787v3",
      "published_date": "2025-10-14 17:57:04 UTC",
      "updated_date": "2025-11-13 18:56:10 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:20:30.690161+00:00"
    },
    {
      "arxiv_id": "2510.12785v1",
      "title": "MVP4D: Multi-View Portrait Video Diffusion for Animatable 4D Avatars",
      "title_zh": "MVP4Dï¼šé¢å‘å¯é©±åŠ¨ 4D æ•°å­—äººçš„å¤šè§†è§’äººåƒè§†é¢‘æ‰©æ•£",
      "authors": [
        "Felix Taubner",
        "Ruihang Zhang",
        "Mathieu Tuli",
        "Sherwin Bahmani",
        "David B. Lindell"
      ],
      "abstract": "Digital human avatars aim to simulate the dynamic appearance of humans in virtual environments, enabling immersive experiences across gaming, film, virtual reality, and more. However, the conventional process for creating and animating photorealistic human avatars is expensive and time-consuming, requiring large camera capture rigs and significant manual effort from professional 3D artists. With the advent of capable image and video generation models, recent methods enable automatic rendering of realistic animated avatars from a single casually captured reference image of a target subject. While these techniques significantly lower barriers to avatar creation and offer compelling realism, they lack constraints provided by multi-view information or an explicit 3D representation. So, image quality and realism degrade when rendered from viewpoints that deviate strongly from the reference image. Here, we build a video model that generates animatable multi-view videos of digital humans based on a single reference image and target expressions. Our model, MVP4D, is based on a state-of-the-art pre-trained video diffusion model and generates hundreds of frames simultaneously from viewpoints varying by up to 360 degrees around a target subject. We show how to distill the outputs of this model into a 4D avatar that can be rendered in real-time. Our approach significantly improves the realism, temporal consistency, and 3D consistency of generated avatars compared to previous methods.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†MVP4Dï¼Œè¿™æ˜¯ä¸€ç§æ—¨åœ¨è§£å†³å†™å®æ•°å­—äººå¤´åƒåˆ›å»ºæˆæœ¬é«˜æ˜‚åŠç°æœ‰å•å›¾æ–¹æ³•ç¼ºä¹å¤šè§†è§’ä¸€è‡´æ€§é—®é¢˜çš„è§†é¢‘æ¨¡å‹ã€‚MVP4DåŸºäºå…ˆè¿›çš„é¢„è®­ç»ƒè§†é¢‘æ‰©æ•£æ¨¡å‹(Video Diffusion Model)ï¼Œèƒ½å¤Ÿæ ¹æ®å•å¼ å‚è€ƒå›¾åƒå’Œç›®æ ‡è¡¨æƒ…ï¼ŒåŒæ—¶ç”Ÿæˆå›´ç»•ç›®æ ‡ä¸»ä½“å¤šè¾¾360åº¦è§†è§’çš„æ•°ç™¾å¸§å¯åŠ¨ç”»åŒ–å¤šè§†è§’è§†é¢‘ã€‚é€šè¿‡å°†è¯¥æ¨¡å‹çš„è¾“å‡ºè’¸é¦(Distill)ä¸º4Då¤´åƒ(4D Avatar)ï¼Œè¯¥æ–¹æ³•å®ç°äº†æ•°å­—äººçš„å®æ—¶æ¸²æŸ“ã€‚ä¸ä¹‹å‰çš„æ–¹æ³•ç›¸æ¯”ï¼ŒMVP4Dåœ¨ç”Ÿæˆçš„å¤´åƒçœŸå®æ„Ÿã€æ—¶é—´ä¸€è‡´æ€§(Temporal Consistency)ä»¥åŠ3Dä¸€è‡´æ€§(3D Consistency)æ–¹é¢å‡å–å¾—äº†æ˜¾è‘—æå‡ï¼Œä¸ºé«˜æ•ˆæ„å»ºé«˜è´¨é‡åŠ¨æ€è™šæ‹Ÿäººæä¾›äº†æœ‰æ•ˆçš„è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.GR"
      ],
      "primary_category": "cs.CV",
      "comment": "18 pages, 12 figures",
      "pdf_url": "https://arxiv.org/pdf/2510.12785v1",
      "published_date": "2025-10-14 17:56:14 UTC",
      "updated_date": "2025-10-14 17:56:14 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:20:34.562649+00:00"
    },
    {
      "arxiv_id": "2510.12773v1",
      "title": "Dr.LLM: Dynamic Layer Routing in LLMs",
      "title_zh": "Dr.LLMï¼šå¤§è¯­è¨€æ¨¡å‹åŠ¨æ€å±‚è·¯ç”±",
      "authors": [
        "Ahmed Heakl",
        "Martin Gubri",
        "Salman Khan",
        "Sangdoo Yun",
        "Seong Joon Oh"
      ],
      "abstract": "Large Language Models (LLMs) process every token through all layers of a transformer stack, causing wasted computation on simple queries and insufficient flexibility for harder ones that need deeper reasoning. Adaptive-depth methods can improve efficiency, but prior approaches rely on costly inference-time search, architectural changes, or large-scale retraining, and in practice often degrade accuracy despite efficiency gains. We introduce Dr.LLM, Dynamic routing of Layers for LLMs, a retrofittable framework that equips pretrained models with lightweight per-layer routers deciding to skip, execute, or repeat a block. Routers are trained with explicit supervision: using Monte Carlo Tree Search (MCTS), we derive high-quality layer configurations that preserve or improve accuracy under a compute budget. Our design, windowed pooling for stable routing, focal loss with class balancing, and bottleneck MLP routers, ensures robustness under class imbalance and long sequences. On ARC (logic) and DART (math), Dr.LLM improves accuracy by up to +3.4%p while saving 5 layers per example on average. Routers generalize to out-of-domain tasks (MMLU, GSM8k, AIME, TruthfulQA, SQuADv2, GPQA, PIQA, AGIEval) with only 0.85% accuracy drop while retaining efficiency, and outperform prior routing methods by up to +7.7%p. Overall, Dr.LLM shows that explicitly supervised routers retrofit frozen LLMs for budget-aware, accuracy-driven inference without altering base weights.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†Dr.LLMï¼Œä¸€ç§é’ˆå¯¹å¤§è¯­è¨€æ¨¡å‹(LLMs)çš„åŠ¨æ€å±‚è·¯ç”±(Dynamic Layer Routing)æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³ç°æœ‰transformeræ¶æ„åœ¨å¤„ç†ç®€å•æŸ¥è¯¢æ—¶è®¡ç®—èµ„æºå†—ä½™ä»¥åŠå¤„ç†å¤æ‚æ¨ç†æ—¶çµæ´»æ€§ä¸è¶³çš„é—®é¢˜ã€‚Dr.LLMä½œä¸ºä¸€ä¸ªå¯è¿½æº¯é€‚é…çš„æ¡†æ¶ï¼Œä¸ºé¢„è®­ç»ƒæ¨¡å‹é…å¤‡äº†è½»é‡çº§çš„é€å±‚è·¯ç”±ï¼Œå…è®¸æ¨¡å‹æ ¹æ®è¾“å…¥åŠ¨æ€å†³å®šè·³è¿‡(skip)ã€æ‰§è¡Œ(execute)æˆ–é‡å¤(repeat)ç‰¹å®šçš„ç½‘ç»œå—ã€‚ç ”ç©¶å›¢é˜Ÿé€šè¿‡è’™ç‰¹å¡æ´›æ ‘æœç´¢(MCTS)æ¨å¯¼å‡ºé«˜è´¨é‡çš„å±‚é…ç½®ï¼Œå¹¶åˆ©ç”¨æ˜¾å¼ç›‘ç£è®­ç»ƒè·¯ç”±ï¼ŒåŒæ—¶é‡‡ç”¨äº†çª—å£æ± åŒ–(windowed pooling)ã€ç„¦ç‚¹æŸå¤±(focal loss)å’Œç“¶é¢ˆMLP(bottleneck MLP)ç­‰è®¾è®¡æ¥ç¡®ä¿è·¯ç”±çš„ç¨³å¥æ€§ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œåœ¨ARCé€»è¾‘æ¨ç†å’ŒDARTæ•°å­¦ä»»åŠ¡ä¸­ï¼ŒDr.LLMåœ¨å¹³å‡æ¯ä¸ªæ ·æœ¬èŠ‚çœ5ä¸ªå±‚çš„æƒ…å†µä¸‹ï¼Œå‡†ç¡®ç‡æå‡äº†æœ€é«˜3.4ä¸ªç™¾åˆ†ç‚¹ã€‚è¯¥è·¯ç”±æœºåˆ¶åœ¨MMLUã€GSM8kå’ŒGPQAç­‰åŸŸå¤–ä»»åŠ¡ä¸Šè¡¨ç°å‡ºè‰¯å¥½çš„æ³›åŒ–èƒ½åŠ›ï¼Œæ€§èƒ½ä¼˜äºä»¥å¾€çš„è·¯ç”±æ–¹æ³•ã€‚æ€»çš„æ¥è¯´ï¼ŒDr.LLMè¯æ˜äº†é€šè¿‡æ˜¾å¼ç›‘ç£çš„è·¯ç”±å¯ä»¥åœ¨ä¸æ”¹å˜åŸºç¡€æ¨¡å‹æƒé‡çš„å‰æä¸‹ï¼Œå®ç°é¢„ç®—æ„ŸçŸ¥ä¸”ç²¾åº¦é©±åŠ¨çš„é«˜æ•ˆæ¨ç†ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "17 pages, Under submission",
      "pdf_url": "https://arxiv.org/pdf/2510.12773v1",
      "published_date": "2025-10-14 17:51:26 UTC",
      "updated_date": "2025-10-14 17:51:26 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:20:55.414805+00:00"
    },
    {
      "arxiv_id": "2510.12768v1",
      "title": "Uncertainty Matters in Dynamic Gaussian Splatting for Monocular 4D Reconstruction",
      "title_zh": "ä¸ç¡®å®šæ€§åœ¨å•ç›® 4D é‡å»ºåŠ¨æ€é«˜æ–¯æ³¼æº…ä¸­çš„é‡è¦æ€§",
      "authors": [
        "Fengzhi Guo",
        "Chih-Chuan Hsu",
        "Sihao Ding",
        "Cheng Zhang"
      ],
      "abstract": "Reconstructing dynamic 3D scenes from monocular input is fundamentally under-constrained, with ambiguities arising from occlusion and extreme novel views. While dynamic Gaussian Splatting offers an efficient representation, vanilla models optimize all Gaussian primitives uniformly, ignoring whether they are well or poorly observed. This limitation leads to motion drifts under occlusion and degraded synthesis when extrapolating to unseen views. We argue that uncertainty matters: Gaussians with recurring observations across views and time act as reliable anchors to guide motion, whereas those with limited visibility are treated as less reliable. To this end, we introduce USplat4D, a novel Uncertainty-aware dynamic Gaussian Splatting framework that propagates reliable motion cues to enhance 4D reconstruction. Our key insight is to estimate time-varying per-Gaussian uncertainty and leverages it to construct a spatio-temporal graph for uncertainty-aware optimization. Experiments on diverse real and synthetic datasets show that explicitly modeling uncertainty consistently improves dynamic Gaussian Splatting models, yielding more stable geometry under occlusion and high-quality synthesis at extreme viewpoints.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡º USplat4Dï¼Œä¸€ç§æ–°å‹çš„ Uncertainty-aware dynamic Gaussian Splatting æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³ä»å•ç›®è¾“å…¥è¿›è¡Œ 4D Reconstruction æ—¶å› é®æŒ¡å’Œæç«¯è§†è§’å¯¼è‡´çš„è¿åŠ¨æ¼‚ç§»ä¸åˆæˆé€€åŒ–é—®é¢˜ã€‚é’ˆå¯¹ä¼ ç»Ÿæ¨¡å‹ç»Ÿä¸€ä¼˜åŒ–æ‰€æœ‰é«˜æ–¯åŸºå…ƒè€Œå¿½ç•¥è§‚æµ‹è´¨é‡å·®å¼‚çš„å±€é™æ€§ï¼Œè¯¥æ–¹æ³•é€šè¿‡ä¼°è®¡éšæ—¶é—´å˜åŒ–çš„ per-Gaussian uncertaintyï¼Œå°†å…·æœ‰é‡å¤è§‚æµ‹çš„å¯é åŸºå…ƒä½œä¸ºå¼•å¯¼è¿åŠ¨çš„é”šç‚¹ã€‚æ¡†æ¶åˆ©ç”¨è¿™äº›ä¸ç¡®å®šæ€§åº¦é‡æ„å»ºæ—¶ç©ºå›¾ï¼ˆspatio-temporal graphï¼‰ï¼Œå®ç°ä¸ç¡®å®šæ€§æ„ŸçŸ¥ä¼˜åŒ–ï¼Œä»è€Œåœ¨åœºæ™¯ä¸­æœ‰æ•ˆä¼ æ’­å¯é çš„è¿åŠ¨çº¿ç´¢ã€‚åœ¨å¤šç§çœŸå®å’Œåˆæˆæ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼Œæ˜¾å¼å»ºæ¨¡ä¸ç¡®å®šæ€§æ˜¾è‘—æå‡äº†åŠ¨æ€ Gaussian Splatting çš„æ€§èƒ½ï¼Œåœ¨é®æŒ¡ç¯å¢ƒä¸‹å®ç°äº†æ›´ç¨³å®šçš„å‡ ä½•é‡å»ºã€‚æœ€ç»ˆï¼ŒUSplat4D åœ¨é¢å¯¹æç«¯è§†è§’æ—¶è¡¨ç°å‡ºå“è¶Šçš„é«˜è´¨é‡å›¾åƒåˆæˆèƒ½åŠ›ï¼Œä¸ºå¢å¼ºå•ç›®åŠ¨æ€åœºæ™¯é‡å»ºçš„é²æ£’æ€§æä¾›äº†æ–°æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.GR"
      ],
      "primary_category": "cs.CV",
      "comment": "Project page: https://tamu-visual-ai.github.io/usplat4d/",
      "pdf_url": "https://arxiv.org/pdf/2510.12768v1",
      "published_date": "2025-10-14 17:47:11 UTC",
      "updated_date": "2025-10-14 17:47:11 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:20:50.173226+00:00"
    },
    {
      "arxiv_id": "2510.12763v1",
      "title": "Disentangling Neurodegeneration with Brain Age Gap Prediction Models: A Graph Signal Processing Perspective",
      "title_zh": "åŸºäºè„‘é¾„å·®é¢„æµ‹æ¨¡å‹è§£æ„ç¥ç»é€€è¡Œæ€§å˜ï¼šå›¾ä¿¡å·å¤„ç†è§†è§’",
      "authors": [
        "Saurabh Sihag",
        "Gonzalo Mateos",
        "Alejandro Ribeiro"
      ],
      "abstract": "Neurodegeneration, characterized by the progressive loss of neuronal structure or function, is commonly assessed in clinical practice through reductions in cortical thickness or brain volume, as visualized by structural MRI. While informative, these conventional approaches lack the statistical sophistication required to fully capture the spatially correlated and heterogeneous nature of neurodegeneration, which manifests both in healthy aging and in neurological disorders. To address these limitations, brain age gap has emerged as a promising data-driven biomarker of brain health. The brain age gap prediction (BAGP) models estimate the difference between a person's predicted brain age from neuroimaging data and their chronological age. The resulting brain age gap serves as a compact biomarker of brain health, with recent studies demonstrating its predictive utility for disease progression and severity. However, practical adoption of BAGP models is hindered by their methodological obscurities and limited generalizability across diverse clinical populations. This tutorial article provides an overview of BAGP and introduces a principled framework for this application based on recent advancements in graph signal processing (GSP). In particular, we focus on graph neural networks (GNNs) and introduce the coVariance neural network (VNN), which leverages the anatomical covariance matrices derived from structural MRI. VNNs offer strong theoretical grounding and operational interpretability, enabling robust estimation of brain age gap predictions. By integrating perspectives from GSP, machine learning, and network neuroscience, this work clarifies the path forward for reliable and interpretable BAGP models and outlines future research directions in personalized medicine.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç¥ç»é€€è¡Œæ€§å˜(Neurodegeneration)åœ¨ä¼ ç»ŸMRIè¯„ä¼°ä¸­éš¾ä»¥æ•æ‰ç©ºé—´ç›¸å…³æ€§ä¸å¼‚è´¨æ€§çš„å±€é™ï¼Œæ·±å…¥æ¢è®¨äº†è„‘å¹´é¾„å·®è·é¢„æµ‹(Brain Age Gap Prediction, BAGP)æ¨¡å‹ä½œä¸ºå¤§è„‘å¥åº·ç”Ÿç‰©æ ‡å¿—ç‰©çš„åº”ç”¨ã€‚å°½ç®¡BAGPåœ¨ç–¾ç—…è¿›å±•é¢„æµ‹ä¸­å…·æœ‰æ½œåŠ›ï¼Œä½†å…¶æ–¹æ³•è®ºçš„æ¨¡ç³Šæ€§é™åˆ¶äº†ä¸´åºŠé‡‡ç”¨ï¼Œä¸ºæ­¤æœ¬æ–‡ä»å›¾ä¿¡å·å¤„ç†(Graph Signal Processing, GSP)çš„è§†è§’æå‡ºäº†ä¸€ä¸ªåŸåˆ™æ€§æ¡†æ¶ã€‚ç ”ç©¶é‡ç‚¹ä»‹ç»äº†å›¾ç¥ç»ç½‘ç»œ(GNNs)åŠåˆ©ç”¨MRIè§£å‰–åæ–¹å·®çŸ©é˜µçš„åæ–¹å·®ç¥ç»ç½‘ç»œ(coVariance Neural Network, VNN)ï¼Œè¯¥æ¨¡å‹å…·å¤‡å¼ºå¤§çš„ç†è®ºåŸºç¡€ä¸æ“ä½œå¯è§£é‡Šæ€§(Interpretability)ï¼Œèƒ½å®ç°ç¨³å¥çš„è„‘å¹´é¾„å·®è·é¢„æµ‹ã€‚é€šè¿‡æ•´åˆæœºå™¨å­¦ä¹ ä¸ç½‘ç»œç¥ç»ç§‘å­¦(Network Neuroscience)çš„è§è§£ï¼Œè¯¥å·¥ä½œä¸ºæ„å»ºå¯é ã€å¯è§£é‡Šçš„BAGPæ¨¡å‹æŒ‡æ˜äº†è·¯å¾„ï¼Œå¹¶ä¸ºä¸ªæ€§åŒ–åŒ»ç–—é¢†åŸŸçš„æœªæ¥ç ”ç©¶æ–¹å‘å¥ å®šäº†åŸºç¡€ã€‚",
      "categories": [
        "eess.SP",
        "cs.AI",
        "q-bio.QM"
      ],
      "primary_category": "eess.SP",
      "comment": "Accepted for publication in IEEE Signal Processing Magazine",
      "pdf_url": "https://arxiv.org/pdf/2510.12763v1",
      "published_date": "2025-10-14 17:44:45 UTC",
      "updated_date": "2025-10-14 17:44:45 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:20:53.386041+00:00"
    },
    {
      "arxiv_id": "2510.12750v1",
      "title": "VQArt-Bench: A semantically rich VQA Benchmark for Art and Cultural Heritage",
      "title_zh": "VQArt-Benchï¼šé¢å‘è‰ºæœ¯ä¸æ–‡åŒ–é—äº§çš„è¯­ä¹‰ä¸°å¯Œå‹ VQA åŸºå‡†æµ‹è¯•é›†",
      "authors": [
        "A. Alfarano",
        "L. Venturoli",
        "D. Negueruela del Castillo"
      ],
      "abstract": "Multimodal Large Language Models (MLLMs) have demonstrated significant capabilities in joint visual and linguistic tasks. However, existing Visual Question Answering (VQA) benchmarks often fail to evaluate deep semantic understanding, particularly in complex domains like visual art analysis. Confined to simple syntactic structures and surface-level attributes, these questions fail to capture the diversity and depth of human visual inquiry. This limitation incentivizes models to exploit statistical shortcuts rather than engage in visual reasoning. To address this gap, we introduce VQArt-Bench, a new, large-scale VQA benchmark for the cultural heritage domain. This benchmark is constructed using a novel multi-agent pipeline where specialized agents collaborate to generate nuanced, validated, and linguistically diverse questions. The resulting benchmark is structured along relevant visual understanding dimensions that probe a model's ability to interpret symbolic meaning, narratives, and complex visual relationships. Our evaluation of 14 state-of-the-art MLLMs on this benchmark reveals significant limitations in current models, including a surprising weakness in simple counting tasks and a clear performance gap between proprietary and open-source models.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ (MLLMs) åœ¨è§†è§‰è‰ºæœ¯ç­‰å¤æ‚é¢†åŸŸç¼ºä¹æ·±å±‚è¯­ä¹‰ç†è§£çš„é—®é¢˜ï¼Œæå‡ºäº†é’ˆå¯¹æ–‡åŒ–é—äº§é¢†åŸŸçš„å…¨æ–°å¤§è§„æ¨¡è§†è§‰é—®ç­” (VQA) åŸºå‡†æµ‹è¯• VQArt-Benchã€‚è¯¥åŸºå‡†é‡‡ç”¨åˆ›æ–°çš„å¤šæ™ºèƒ½ä½“ (multi-agent) æµæ°´çº¿æ„å»ºï¼Œé€šè¿‡ä¸“é—¨æ™ºèƒ½ä½“çš„åä½œç”Ÿæˆå…·æœ‰æ·±åº¦ã€ç»è¿‡éªŒè¯ä¸”è¯­è¨€å¤šæ ·åŒ–çš„é—®é¢˜ã€‚VQArt-Bench æ—¨åœ¨ä»è±¡å¾æ„ä¹‰ã€å™äº‹é€»è¾‘å’Œå¤æ‚è§†è§‰å…³ç³»ç­‰å¤šä¸ªç»´åº¦ï¼Œæ¢æµ‹æ¨¡å‹å¯¹è‰ºæœ¯ä½œå“çš„ç†è§£èƒ½åŠ›ã€‚å®éªŒå¯¹14ä¸ªå‰æ²¿ MLLMs è¿›è¡Œäº†è¯„ä¼°ï¼Œç»“æœæ­ç¤ºäº†å½“å‰æ¨¡å‹åœ¨ç®€å•è®¡æ•°ä»»åŠ¡ä¸Šçš„æƒŠäººå¼±ç‚¹ï¼Œå¹¶è¯å®äº†é—­æºå•†ä¸šæ¨¡å‹ä¸å¼€æºæ¨¡å‹ä¹‹é—´å­˜åœ¨æ˜¾è‘—çš„æ€§èƒ½å·®è·ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.12750v1",
      "published_date": "2025-10-14 17:29:52 UTC",
      "updated_date": "2025-10-14 17:29:52 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:20:54.873322+00:00"
    },
    {
      "arxiv_id": "2510.12742v1",
      "title": "CTRL-Rec: Controlling Recommender Systems With Natural Language",
      "title_zh": "CTRL-Recï¼šåŸºäºè‡ªç„¶è¯­è¨€çš„æ¨èç³»ç»Ÿæ§åˆ¶",
      "authors": [
        "Micah Carroll",
        "Adeline Foote",
        "Kevin Feng",
        "Marcus Williams",
        "Anca Dragan",
        "W. Bradley Knox",
        "Smitha Milli"
      ],
      "abstract": "When users are dissatisfied with recommendations from a recommender system, they often lack fine-grained controls for changing them. Large language models (LLMs) offer a solution by allowing users to guide their recommendations through natural language requests (e.g., \"I want to see respectful posts with a different perspective than mine\"). We propose a method, CTRL-Rec, that allows for natural language control of traditional recommender systems in real-time with computational efficiency. Specifically, at training time, we use an LLM to simulate whether users would approve of items based on their language requests, and we train embedding models that approximate such simulated judgments. We then integrate these user-request-based predictions into the standard weighting of signals that traditional recommender systems optimize. At deployment time, we require only a single LLM embedding computation per user request, allowing for real-time control of recommendations. In experiments with the MovieLens dataset, our method consistently allows for fine-grained control across a diversity of requests. In a study with 19 Letterboxd users, we find that CTRL-Rec was positively received by users and significantly enhanced users' sense of control and satisfaction with recommendations compared to traditional controls.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†CTRL-Recï¼Œè¿™æ˜¯ä¸€ç§å…è®¸ç”¨æˆ·é€šè¿‡è‡ªç„¶è¯­è¨€(natural language)å®æ—¶æ§åˆ¶ä¼ ç»Ÿæ¨èç³»ç»Ÿçš„æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³ç”¨æˆ·åœ¨æ¨èç³»ç»Ÿä¸­ç¼ºä¹ç»†ç²’åº¦æ§åˆ¶æ‰‹æ®µçš„é—®é¢˜ã€‚åœ¨è®­ç»ƒé˜¶æ®µï¼ŒCTRL-Recåˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹(LLMs)æ¨¡æ‹Ÿç”¨æˆ·æ ¹æ®è¯­è¨€è¯·æ±‚å¯¹ç‰¹å®šé¡¹çš„è®¤å¯åº¦ï¼Œå¹¶æ®æ­¤è®­ç»ƒåµŒå…¥æ¨¡å‹(embedding models)ä»¥é€¼è¿‘è¿™äº›æ¨¡æ‹Ÿåˆ¤æ–­ã€‚é€šè¿‡å°†è¿™äº›åŸºäºè¯·æ±‚çš„é¢„æµ‹ç»“æœæ•´åˆåˆ°ä¼ ç»Ÿæ¨èç³»ç»Ÿçš„ä¿¡å·æƒé‡ä¸­ï¼Œè¯¥ç³»ç»Ÿåœ¨éƒ¨ç½²æ—¶ä»…éœ€ä¸€æ¬¡å¤§è¯­è¨€æ¨¡å‹åµŒå…¥è®¡ç®—(LLM embedding computation)ï¼Œä»è€Œå®ç°äº†æé«˜çš„è®¡ç®—æ•ˆç‡ã€‚åœ¨MovieLensæ•°æ®é›†ä¸Šçš„å®éªŒè¯æ˜äº†è¯¥æ–¹æ³•åœ¨å¤„ç†å¤šæ ·åŒ–è¯·æ±‚æ—¶å…·æœ‰ç¨³å®šä¸”ç»†ç²’åº¦çš„æ§åˆ¶èƒ½åŠ›ã€‚æœ€åï¼Œä¸€é¡¹é’ˆå¯¹19ä½çœŸå®ç”¨æˆ·çš„ç ”ç©¶è¡¨æ˜ï¼ŒCTRL-Recç›¸æ¯”ä¼ ç»Ÿæ§åˆ¶æ‰‹æ®µæ˜¾è‘—æå‡äº†ç”¨æˆ·çš„æ§åˆ¶æ„Ÿä¸æ¨èæ»¡æ„åº¦ã€‚",
      "categories": [
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.12742v1",
      "published_date": "2025-10-14 17:20:04 UTC",
      "updated_date": "2025-10-14 17:20:04 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:20:58.789344+00:00"
    },
    {
      "arxiv_id": "2510.12740v2",
      "title": "Hey, wait a minute: on at-issue sensitivity in Language Models",
      "title_zh": "â€œå˜¿ï¼Œç­‰ä¸€ä¸‹â€ï¼šè®ºè¯­è¨€æ¨¡å‹çš„è®®é¢˜å†…æ•æ„Ÿæ€§",
      "authors": [
        "Sanghee J. Kim",
        "Kanishka Misra"
      ],
      "abstract": "Evaluating the naturalness of dialogue in language models (LMs) is not trivial: notions of 'naturalness' vary, and scalable quantitative metrics remain limited. This study leverages the linguistic notion of 'at-issueness' to assess dialogue naturalness and introduces a new method: Divide, Generate, Recombine, and Compare (DGRC). DGRC (i) divides a dialogue as a prompt, (ii) generates continuations for subparts using LMs, (iii) recombines the dialogue and continuations, and (iv) compares the likelihoods of the recombined sequences. This approach mitigates bias in linguistic analyses of LMs and enables systematic testing of discourse-sensitive behavior. Applying DGRC, we find that LMs prefer to continue dialogue on at-issue content, with this effect enhanced in instruct-tuned models. They also reduce their at-issue preference when relevant cues (e.g., \"Hey, wait a minute\") are present. Although instruct-tuning does not further amplify this modulation, the pattern reflects a hallmark of successful dialogue dynamics.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹è¯„ä¼°è¯­è¨€æ¨¡å‹ï¼ˆLMsï¼‰å¯¹è¯è‡ªç„¶æ€§æ—¶ç¼ºä¹å®šé‡æŒ‡æ ‡çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§åä¸º DGRC (Divide, Generate, Recombine, and Compare) çš„æ–°æ–¹æ³•ã€‚è¯¥æ–¹æ³•é€šè¿‡åˆ†å‰²å¯¹è¯ promptã€ç”Ÿæˆå­éƒ¨åˆ†ç»­å†™ã€é‡ç»„åºåˆ—å¹¶æ¯”è¾ƒå…¶ä¼¼ç„¶åº¦ï¼Œå®ç°äº†å¯¹æ¨¡å‹è¯­ç¯‡æ•æ„Ÿï¼ˆdiscourse-sensitiveï¼‰è¡Œä¸ºçš„ç³»ç»ŸåŒ–æµ‹è¯•ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒLMs æ™®éè¡¨ç°å‡ºå»¶ç»­å¯¹è¯ä¸­ at-issue å†…å®¹çš„åå¥½ï¼Œä¸”è¿™ç§å€¾å‘åœ¨ç»è¿‡ instruct-tuning çš„æ¨¡å‹ä¸­å¾—åˆ°äº†è¿›ä¸€æ­¥å¢å¼ºã€‚æ­¤å¤–ï¼Œç ”ç©¶å‘ç° LMs èƒ½å¤Ÿè¯†åˆ« \"Hey, wait a minute\" ç­‰ç‰¹å®šè¯­ç¯‡çº¿ç´¢å¹¶æ®æ­¤è°ƒæ•´å…¶ at-issue åå¥½ï¼Œè¿™ä½“ç°äº†æ¨¡å‹å¯¹å¤æ‚å¯¹è¯åŠ¨æ€çš„ç†è§£èƒ½åŠ›ã€‚å°½ç®¡ instruct-tuning å¹¶æ²¡æœ‰æ˜¾è‘—æ”¾å¤§è¿™ç§è°ƒèŠ‚ä½œç”¨ï¼Œä½†è¿™äº›å‘ç°ä¸ºç†è§£å’Œä¼˜åŒ– LMs çš„å¯¹è¯è‡ªç„¶æ€§æä¾›äº†é‡è¦è§è§£ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "10 pages, 5 figures, 3 tables. See https://github.com/sangheek16/hey-wait-a-minute for code and data",
      "pdf_url": "https://arxiv.org/pdf/2510.12740v2",
      "published_date": "2025-10-14 17:17:20 UTC",
      "updated_date": "2025-11-04 16:32:37 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:21:04.489151+00:00"
    },
    {
      "arxiv_id": "2510.12733v2",
      "title": "HYPE: Hybrid Planning with Ego Proposal-Conditioned Predictions",
      "title_zh": "HYPEï¼šåŸºäºè‡ªè½¦æè®®æ¡ä»¶é¢„æµ‹çš„æ··åˆè§„åˆ’",
      "authors": [
        "Hang Yu",
        "Julian Jordan",
        "Julian Schmidt",
        "Silvan Lindner",
        "Alessandro Canevaro",
        "Wilhelm Stork"
      ],
      "abstract": "Safe and interpretable motion planning in complex urban environments needs to reason about bidirectional multi-agent interactions. This reasoning requires to estimate the costs of potential ego driving maneuvers. Many existing planners generate initial trajectories with sampling-based methods and refine them by optimizing on learned predictions of future environment states, which requires a cost function that encodes the desired vehicle behavior. Designing such a cost function can be very challenging, especially if a wide range of complex urban scenarios has to be considered. We propose HYPE: HYbrid Planning with Ego proposal-conditioned predictions, a planner that integrates multimodal trajectory proposals from a learned proposal model as heuristic priors into a Monte Carlo Tree Search (MCTS) refinement. To model bidirectional interactions, we introduce an ego-conditioned occupancy prediction model, enabling consistent, scene-aware reasoning. Our design significantly simplifies cost function design in refinement by considering proposal-driven guidance, requiring only minimalistic grid-based cost terms. Evaluations on large-scale real-world benchmarks nuPlan and DeepUrban show that HYPE effectively achieves state-of-the-art performance, especially in safety and adaptability.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†HYPEï¼Œè¿™æ˜¯ä¸€ç§ç»“åˆäº†è‡ªæˆ‘ææ¡ˆæ¡ä»¶çš„æ··åˆè§„åˆ’(Hybrid Planning)æ¡†æ¶ï¼Œæ—¨åœ¨æå‡å¤æ‚åŸå¸‚ç¯å¢ƒä¸‹çš„è¿åŠ¨è§„åˆ’å®‰å…¨æ€§ä¸å¯è§£é‡Šæ€§ã€‚è¯¥æ–¹æ³•å°†æ¥è‡ªå­¦ä¹ ææ¡ˆæ¨¡å‹çš„å¤šæ¨¡æ€è½¨è¿¹ææ¡ˆ(multimodal trajectory proposals)ä½œä¸ºå¯å‘å¼å…ˆéªŒï¼Œé›†æˆåˆ°è’™ç‰¹å¡æ´›æ ‘æœç´¢(MCTS)çš„ç»†åŒ–è¿‡ç¨‹ä¸­ã€‚ä¸ºäº†å»ºæ¨¡åŒå‘å¤šæ™ºèƒ½ä½“äº¤äº’ï¼Œç ”ç©¶å›¢é˜Ÿå¼•å…¥äº†å—è‡ªæˆ‘æ¡ä»¶çº¦æŸçš„å ç”¨é¢„æµ‹æ¨¡å‹(ego-conditioned occupancy prediction model)ï¼Œå®ç°äº†åœºæ™¯æ„ŸçŸ¥çš„è¿è´¯æ¨ç†ã€‚HYPEçš„è®¾è®¡é€šè¿‡ææ¡ˆé©±åŠ¨çš„å¼•å¯¼æ˜¾è‘—ç®€åŒ–äº†ä»£ä»·å‡½æ•°(cost function)çš„é…ç½®ï¼Œä»…éœ€æç®€çš„ç½‘æ ¼ä»£ä»·é¡¹å³å¯è¿è¡Œã€‚åœ¨nuPlanå’ŒDeepUrbanç­‰å¤§è§„æ¨¡çœŸå®ä¸–ç•ŒåŸºå‡†æµ‹è¯•ä¸­çš„è¯„ä¼°ç»“æœæ˜¾ç¤ºï¼ŒHYPEåœ¨å®‰å…¨æ€§åŠé€‚åº”æ€§æ–¹é¢å–å¾—äº†å½“å‰æœ€å…ˆè¿›(state-of-the-art)çš„æ€§èƒ½è¡¨ç°ã€‚",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "Accepted to IEEE ITSC 2025",
      "pdf_url": "https://arxiv.org/pdf/2510.12733v2",
      "published_date": "2025-10-14 17:11:04 UTC",
      "updated_date": "2025-10-23 20:59:51 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:21:05.889121+00:00"
    },
    {
      "arxiv_id": "2510.12732v2",
      "title": "Clutch Control: An Attention-based Combinatorial Bandit for Efficient Mutation in JavaScript Engine Fuzzing",
      "title_zh": "Clutch Controlï¼šåŸºäºæ³¨æ„åŠ›æœºåˆ¶çš„ç»„åˆå¤šè‡‚è€è™æœºï¼Œç”¨äº JavaScript å¼•æ“æ¨¡ç³Šæµ‹è¯•çš„é«˜æ•ˆå˜å¼‚",
      "authors": [
        "Myles Foley",
        "Sergio Maffeis",
        "Muhammad Fakhrur Rozi",
        "Takeshi Takahashi"
      ],
      "abstract": "JavaScript engines are widely used in web browsers, PDF readers, and server-side applications. The rise in concern over their security has led to the development of several targeted fuzzing techniques. However, existing approaches use random selection to determine where to perform mutations in JavaScript code. We postulate that the problem of selecting better mutation targets is suitable for combinatorial bandits with a volatile number of arms. Thus, we propose CLUTCH, a novel deep combinatorial bandit that can observe variable length JavaScript test case representations, using an attention mechanism from deep learning. Furthermore, using Concrete Dropout, CLUTCH can dynamically adapt its exploration. We show that CLUTCH increases efficiency in JavaScript fuzzing compared to three state-of-the-art solutions by increasing the number of valid test cases and coverage-per-testcase by, respectively, 20.3% and 8.9% on average. In volatile and combinatorial settings we show that CLUTCH outperforms state-of-the-art bandits, achieving at least 78.1% and 4.1% less regret in volatile and combinatorial settings, respectively.",
      "tldr_zh": "JavaScript å¼•æ“åœ¨ç°ä»£ Web åº”ç”¨ä¸­è‡³å…³é‡è¦ï¼Œä½†å…¶å®‰å…¨æ€§é¢ä¸´ä¸¥å³»æŒ‘æˆ˜ï¼Œè€Œç°æœ‰ Fuzzing æŠ€æœ¯çš„å˜å¼‚ç­–ç•¥å¾€å¾€ä¾èµ–éšæœºé€‰æ‹©ï¼Œå¯¼è‡´å‘ç°æ¼æ´çš„æ•ˆç‡è¾ƒä½ã€‚é’ˆå¯¹è¿™ä¸€é—®é¢˜ï¼Œæœ¬ç ”ç©¶æå‡ºäº† CLUTCHï¼Œè¿™æ˜¯ä¸€ç§åŸºäºæ·±åº¦ç»„åˆå¤šè‡‚è€è™æœº (Combinatorial Bandit) çš„æ–°å‹æ¡†æ¶ï¼Œæ—¨åœ¨å®ç°æ›´é«˜æ•ˆçš„ä»£ç å˜å¼‚ç›®æ ‡é€‰æ‹©ã€‚CLUTCH åˆ©ç”¨æ·±åº¦å­¦ä¹ ä¸­çš„æ³¨æ„åŠ›æœºåˆ¶ (Attention Mechanism) æ¥å¤„ç†å˜é•¿çš„ JavaScript æµ‹è¯•ç”¨ä¾‹è¡¨ç¤ºï¼Œå¹¶ç»“åˆ Concrete Dropout æŠ€æœ¯åŠ¨æ€åœ°è°ƒæ•´å…¶æ¢ç´¢ (Exploration) ç­–ç•¥ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œä¸ä¸‰ç§æœ€å…ˆè¿›çš„è§£å†³æ–¹æ¡ˆç›¸æ¯”ï¼ŒCLUTCH å°†æœ‰æ•ˆæµ‹è¯•ç”¨ä¾‹çš„æ•°é‡å¹³å‡å¢åŠ äº† 20.3%ï¼Œä¸”å•ä¸ªæµ‹è¯•ç”¨ä¾‹çš„è¦†ç›–ç‡ (Coverage-per-testcase) æé«˜äº† 8.9%ã€‚æ­¤å¤–ï¼Œåœ¨æ³¢åŠ¨å’Œç»„åˆè®¾ç½®ä¸‹ï¼ŒCLUTCH çš„æ‚”å€¼ (Regret) æ˜¾è‘—ä½äºç°æœ‰çš„è€è™æœºåŸºå‡†æ¨¡å‹ï¼Œè¯æ˜äº†å…¶åœ¨å¤æ‚å˜å¼‚ç¯å¢ƒä¸‹çš„å“è¶Šæ€§èƒ½å’Œé«˜æ•ˆæ€§ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.12732v2",
      "published_date": "2025-10-14 17:10:51 UTC",
      "updated_date": "2025-11-14 12:43:37 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:21:08.482876+00:00"
    },
    {
      "arxiv_id": "2510.13897v1",
      "title": "Dual-attention ResNet outperforms transformers in HER2 prediction on DCE-MRI",
      "title_zh": "åŒæ³¨æ„åŠ› ResNet åœ¨ DCE-MRI HER2 é¢„æµ‹ä¸­çš„è¡¨ç°ä¼˜äº Transformer",
      "authors": [
        "Naomi Fridman",
        "Anat Goldstein"
      ],
      "abstract": "Breast cancer is the most diagnosed cancer in women, with HER2 status critically guiding treatment decisions. Noninvasive prediction of HER2 status from dynamic contrast-enhanced MRI (DCE-MRI) could streamline diagnostics and reduce reliance on biopsy. However, preprocessing high-dynamic-range DCE-MRI into standardized 8-bit RGB format for pretrained neural networks is nontrivial, and normalization strategy significantly affects model performance. We benchmarked intensity normalization strategies using a Triple-Head Dual-Attention ResNet that processes RGB-fused temporal sequences from three DCE phases. Trained on a multicenter cohort (n=1,149) from the I-SPY trials and externally validated on BreastDCEDL_AMBL (n=43 lesions), our model outperformed transformer-based architectures, achieving 0.75 accuracy and 0.74 AUC on I-SPY test data. N4 bias field correction slightly degraded performance. Without fine-tuning, external validation yielded 0.66 AUC, demonstrating cross-institutional generalizability. These findings highlight the effectiveness of dual-attention mechanisms in capturing transferable spatiotemporal features for HER2 stratification, advancing reproducible deep learning biomarkers in breast cancer imaging.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†é€šè¿‡åŠ¨æ€å¯¹æ¯”å¢å¼ºæ ¸ç£å…±æŒ¯æˆåƒ(DCE-MRI)éä¾µå…¥æ€§é¢„æµ‹ä¹³è…ºç™ŒHER2çŠ¶æ€çš„æ–¹æ³•ï¼Œæ—¨åœ¨ä¼˜åŒ–è¯Šæ–­æµç¨‹å¹¶å‡å°‘å¯¹æ´»æ£€çš„ä¾èµ–ã€‚ç ”ç©¶å›¢é˜Ÿæå‡ºå¹¶è¯„ä¼°äº†ä¸€ç§Triple-Head Dual-Attention ResNetæ¶æ„ï¼Œè¯¥æ¨¡å‹é€šè¿‡å¤„ç†æ¥è‡ªä¸‰ä¸ªDCEé˜¶æ®µçš„RGBèåˆæ—¶é—´åºåˆ—æ¥æå–ç‰¹å¾ã€‚å®éªŒé€šè¿‡å¯¹å¼ºåº¦å½’ä¸€åŒ–ç­–ç•¥è¿›è¡ŒåŸºå‡†æµ‹è¯•ï¼Œå‘ç°N4åç½®åœºæ ¡æ­£(N4 bias field correction)åœ¨ä¸€å®šç¨‹åº¦ä¸Šé™ä½äº†æ¨¡å‹æ€§èƒ½ã€‚åœ¨åŒ…å«1149ä¸ªç—…ä¾‹çš„å¤šä¸­å¿ƒé˜Ÿåˆ—æµ‹è¯•ä¸­ï¼Œè¯¥æ¨¡å‹çš„å‡†ç¡®ç‡è¾¾åˆ°0.75ï¼ŒAUCä¸º0.74ï¼Œè¡¨ç°ä¼˜äºåŸºäºTransformerçš„æ¶æ„ã€‚æ­¤å¤–ï¼Œæ¨¡å‹åœ¨å¤–éƒ¨éªŒè¯ä¸­å±•ç°å‡ºè‰¯å¥½çš„æ³›åŒ–èƒ½åŠ›ï¼Œè¯æ˜äº†åŒæ³¨æ„åŠ›æœºåˆ¶(dual-attention mechanisms)åœ¨æ•æ‰å…·æœ‰è¿ç§»æ€§çš„æ—¶ç©ºç‰¹å¾ä»¥è¿›è¡ŒHER2åˆ†å±‚æ–¹é¢çš„å“è¶Šæœ‰æ•ˆæ€§ã€‚",
      "categories": [
        "q-bio.QM",
        "cs.AI"
      ],
      "primary_category": "q-bio.QM",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.13897v1",
      "published_date": "2025-10-14 17:08:17 UTC",
      "updated_date": "2025-10-14 17:08:17 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:21:10.565728+00:00"
    },
    {
      "arxiv_id": "2510.12727v1",
      "title": "Hierarchical Federated Learning for Crop Yield Prediction in Smart Agricultural Production Systems",
      "title_zh": "æ™ºæ…§å†œä¸šç”Ÿäº§ç³»ç»Ÿä¸­é¢å‘å†œä½œç‰©äº§é‡é¢„æµ‹çš„åˆ†å±‚è”é‚¦å­¦ä¹ ",
      "authors": [
        "Anas Abouaomar",
        "Mohammed El hanjri",
        "Abdellatif Kobbane",
        "Anis Laouiti",
        "Khalid Nafil"
      ],
      "abstract": "In this paper, we presents a novel hierarchical federated learning architecture specifically designed for smart agricultural production systems and crop yield prediction. Our approach introduces a seasonal subscription mechanism where farms join crop-specific clusters at the beginning of each agricultural season. The proposed three-layer architecture consists of individual smart farms at the client level, crop-specific aggregators at the middle layer, and a global model aggregator at the top level. Within each crop cluster, clients collaboratively train specialized models tailored to specific crop types, which are then aggregated to produce a higher-level global model that integrates knowledge across multiple crops. This hierarchical design enables both local specialization for individual crop types and global generalization across diverse agricultural contexts while preserving data privacy and reducing communication overhead. Experiments demonstrate the effectiveness of the proposed system, showing that local and crop-layer models closely follow actual yield patterns with consistent alignment, significantly outperforming standard machine learning models. The results validate the advantages of hierarchical federated learning in the agricultural context, particularly for scenarios involving heterogeneous farming environments and privacy-sensitive agricultural data.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§åä¸ºå±‚çº§è”é‚¦å­¦ä¹  (Hierarchical Federated Learning) çš„æ–°å‹æ¶æ„ï¼Œä¸“é—¨ç”¨äºæ™ºæ…§å†œä¸šç”Ÿäº§ç³»ç»Ÿ (Smart Agricultural Production Systems) ä¸­çš„ä½œç‰©äº§é‡é¢„æµ‹ã€‚è¯¥æ–¹æ³•å¼•å…¥äº†å­£èŠ‚æ€§è®¢é˜…æœºåˆ¶ï¼Œå…è®¸å†œåœºåœ¨å†œä¸šå­£èŠ‚å¼€å§‹æ—¶åŠ å…¥ç‰¹å®šä½œç‰©çš„é›†ç¾¤ï¼Œé€šè¿‡ç”±æ™ºèƒ½å†œåœºå®¢æˆ·ç«¯ã€ä½œç‰©ç‰¹å®šèšåˆå™¨ (Crop-specific Aggregators) åŠå…¨å±€æ¨¡å‹èšåˆå™¨ç»„æˆçš„ä¸‰å±‚æ¶æ„è¿›è¡ŒååŒè®­ç»ƒã€‚è¿™ç§å±‚çº§åŒ–è®¾è®¡åœ¨ä¿æŠ¤æ•°æ®éšç§å’Œé™ä½é€šä¿¡å¼€é”€çš„åŒæ—¶ï¼Œå…¼é¡¾äº†é’ˆå¯¹ç‰¹å®šä½œç‰©çš„å±€éƒ¨ä¸“ä¸šåŒ– (Local Specialization) ä¸è·¨å¤šä½œç‰©çš„å…¨å±€æ³›åŒ– (Global Generalization)ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥ç³»ç»Ÿçš„æ¨¡å‹é¢„æµ‹è¶‹åŠ¿ä¸å®é™…äº§é‡é«˜åº¦ä¸€è‡´ï¼Œæ€§èƒ½æ˜¾è‘—ä¼˜äºæ ‡å‡†æœºå™¨å­¦ä¹ æ¨¡å‹ã€‚ç ”ç©¶ç»“æœå……åˆ†éªŒè¯äº†è¯¥æ¶æ„åœ¨å¤„ç†å¼‚æ„å†œä¸šç¯å¢ƒå’Œéšç§æ•æ„Ÿæ•°æ®æ–¹é¢çš„æ˜¾è‘—ä¼˜åŠ¿ï¼Œä¸ºæ™ºæ…§å†œä¸šçš„å¯æŒç»­å‘å±•æä¾›äº†æœ‰åŠ›æ”¯æ’‘ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DC"
      ],
      "primary_category": "cs.LG",
      "comment": "6 pages, 3 figures, conference",
      "pdf_url": "https://arxiv.org/pdf/2510.12727v1",
      "published_date": "2025-10-14 17:06:23 UTC",
      "updated_date": "2025-10-14 17:06:23 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:21:16.878878+00:00"
    },
    {
      "arxiv_id": "2510.13896v1",
      "title": "GenCellAgent: Generalizable, Training-Free Cellular Image Segmentation via Large Language Model Agents",
      "title_zh": "GenCellAgentï¼šåŸºäºå¤§è¯­è¨€æ¨¡å‹æ™ºèƒ½ä½“çš„å¯æ³›åŒ–ã€å…è®­ç»ƒç»†èƒå›¾åƒåˆ†å‰²",
      "authors": [
        "Xi Yu",
        "Yang Yang",
        "Qun Liu",
        "Yonghua Du",
        "Sean McSweeney",
        "Yuewei Lin"
      ],
      "abstract": "Cellular image segmentation is essential for quantitative biology yet remains difficult due to heterogeneous modalities, morphological variability, and limited annotations. We present GenCellAgent, a training-free multi-agent framework that orchestrates specialist segmenters and generalist vision-language models via a planner-executor-evaluator loop (choose tool $\\rightarrow$ run $\\rightarrow$ quality-check) with long-term memory. The system (i) automatically routes images to the best tool, (ii) adapts on the fly using a few reference images when imaging conditions differ from what a tool expects, (iii) supports text-guided segmentation of organelles not covered by existing models, and (iv) commits expert edits to memory, enabling self-evolution and personalized workflows. Across four cell-segmentation benchmarks, this routing yields a 15.7\\% mean accuracy gain over state-of-the-art baselines. On endoplasmic reticulum and mitochondria from new datasets, GenCellAgent improves average IoU by 37.6\\% over specialist models. It also segments novel objects such as the Golgi apparatus via iterative text-guided refinement, with light human correction further boosting performance. Together, these capabilities provide a practical path to robust, adaptable cellular image segmentation without retraining, while reducing annotation burden and matching user preferences.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† GenCellAgentï¼Œä¸€ä¸ªæ— éœ€è®­ç»ƒçš„å¤šæ™ºèƒ½ä½“æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³ç»†èƒå›¾åƒåˆ†å‰²ä¸­ç”±äºæ¨¡æ€å·®å¼‚ã€å½¢æ€å˜åŒ–å’Œæ ‡æ³¨å—é™å¸¦æ¥çš„æŒ‘æˆ˜ã€‚è¯¥ç³»ç»Ÿé€šè¿‡ä¸€ä¸ªåŒ…å« Planner-Executor-Evaluator å¾ªç¯çš„æ¶æ„ï¼ŒååŒä¸“ä¸šåˆ†å‰²å™¨å’Œé€šç”¨è§†è§‰è¯­è¨€æ¨¡å‹ (Vision-Language Models)ï¼Œå¹¶å¼•å…¥äº†é•¿æœŸè®°å¿†æœºåˆ¶ã€‚GenCellAgent æ”¯æŒè‡ªåŠ¨è·¯ç”±è‡³æœ€ä¼˜å·¥å…·ï¼Œèƒ½æ ¹æ®å°‘é‡å‚è€ƒå›¾åƒåœ¨ä¸åŒæˆåƒæ¡ä»¶ä¸‹è¿›è¡Œå³æ—¶è‡ªé€‚åº”ï¼Œå¹¶å®ç°äº†å¯¹ç°æœ‰æ¨¡å‹æœªè¦†ç›–ç»†èƒå™¨çš„æ–‡æœ¬å¼•å¯¼åˆ†å‰²ã€‚è¯¥æ¡†æ¶å…è®¸é€šè¿‡äººå·¥ç¼–è¾‘ä¼˜åŒ–è®°å¿†ï¼Œä»è€Œå®ç°è‡ªæˆ‘è¿›åŒ–å’Œä¸ªæ€§åŒ–å·¥ä½œæµï¼Œæ˜¾è‘—å‡è½»äº†æ ‡æ³¨è´Ÿæ‹…ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥è·¯ç”±æœºåˆ¶åœ¨å››ä¸ªç»†èƒåˆ†å‰²åŸºå‡†æµ‹è¯•ä¸­æ¯” SOTA åŸºå‡†æ¨¡å‹å¹³å‡å‡†ç¡®ç‡æå‡äº† 15.7%ã€‚åœ¨æ–°æ•°æ®é›†çš„å†…è´¨ç½‘å’Œçº¿ç²’ä½“åˆ†å‰²ä»»åŠ¡ä¸­ï¼ŒGenCellAgent çš„å¹³å‡ IoU æ¯”ä¸“ä¸šæ¨¡å‹æé«˜äº† 37.6%ï¼Œå¹¶å±•ç°äº†é€šè¿‡è¿­ä»£æ–‡æœ¬å¼•å¯¼ç»†åŒ–æ¥åˆ†å‰²é«˜å°”åŸºä½“ç­‰æ–°å‹ç›®æ ‡çš„èƒ½åŠ›ã€‚è¯¥é¡¹å·¥ä½œä¸ºå®ç°é²æ£’ä¸”å¯æ‰©å±•çš„ç»†èƒå›¾åƒåˆ†å‰²æä¾›äº†ä¸€æ¡æ— éœ€é‡æ–°è®­ç»ƒçš„é«˜æ•ˆè·¯å¾„ã€‚",
      "categories": [
        "q-bio.QM",
        "cs.AI",
        "cs.CV",
        "cs.MA"
      ],
      "primary_category": "q-bio.QM",
      "comment": "43 pages",
      "pdf_url": "https://arxiv.org/pdf/2510.13896v1",
      "published_date": "2025-10-14 17:02:57 UTC",
      "updated_date": "2025-10-14 17:02:57 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:21:28.880188+00:00"
    },
    {
      "arxiv_id": "2510.12714v1",
      "title": "Artificial intelligence for simplified patient-centered dosimetry in radiopharmaceutical therapies",
      "title_zh": "äººå·¥æ™ºèƒ½åŠ©åŠ›æ”¾å°„æ€§è¯ç‰©æ²»ç–—ä¸­ç®€åŒ–çš„ä»¥æ‚£è€…ä¸ºä¸­å¿ƒå‰‚é‡å­¦",
      "authors": [
        "Alejandro Lopez-Montes",
        "Fereshteh Yousefirizi",
        "Yizhou Chen",
        "Yazdan Salimi",
        "Robert Seifert",
        "Ali Afshar-Oromieh",
        "Carlos Uribe",
        "Axel Rominger",
        "Habib Zaidi",
        "Arman Rahmim",
        "Kuangyu Shi"
      ],
      "abstract": "KEY WORDS: Artificial Intelligence (AI), Theranostics, Dosimetry, Radiopharmaceutical Therapy (RPT), Patient-friendly dosimetry KEY POINTS - The rapid evolution of radiopharmaceutical therapy (RPT) highlights the growing need for personalized and patient-centered dosimetry. - Artificial Intelligence (AI) offers solutions to the key limitations in current dosimetry calculations. - The main advances on AI for simplified dosimetry toward patient-friendly RPT are reviewed. - Future directions on the role of AI in RPT dosimetry are discussed.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†äººå·¥æ™ºèƒ½(Artificial Intelligence)åœ¨æ”¾å°„æ€§è¯ç‰©æ²»ç–—(Radiopharmaceutical Therapy, RPT)ä¸­å®ç°ç®€åŒ–ä¸”ä»¥æ‚£è€…ä¸ºä¸­å¿ƒçš„å‰‚é‡å­¦(Dosimetry)çš„åº”ç”¨ã€‚éšç€æ”¾å°„æ€§è¯ç‰©æ²»ç–—çš„å¿«é€Ÿæ¼”å˜ï¼Œä¸´åºŠå¯¹ä¸ªæ€§åŒ–å’Œä»¥æ‚£è€…ä¸ºä¸­å¿ƒçš„å‰‚é‡è®¡ç®—éœ€æ±‚æ—¥ç›Šå¢é•¿ï¼Œè€ŒAIæŠ€æœ¯ä¸ºè§£å†³å½“å‰å‰‚é‡å­¦è®¡ç®—çš„å±€é™æ€§æä¾›äº†æœ‰æ•ˆæ–¹æ¡ˆã€‚æœ¬æ–‡ç»¼è¿°äº†Artificial Intelligenceåœ¨ç®€åŒ–å‰‚é‡è¯„ä¼°æµç¨‹ä»¥å®ç°â€œæ‚£è€…å‹å¥½â€å‹æ²»ç–—æ–¹é¢çš„æœ€æ–°è¿›å±•ï¼Œå¹¶å¼ºè°ƒäº†å…¶åœ¨æå‡è¯Šç–—ä¸€ä½“åŒ–(Theranostics)æ•ˆç‡ä¸­çš„å…³é”®ä½œç”¨ã€‚æ–‡ç« æœ€åè®¨è®ºäº†AIåœ¨æœªæ¥æ”¾å°„æ€§è¯ç‰©æ²»ç–—å‰‚é‡å­¦ä¸­çš„æ½œåœ¨è§’è‰²ï¼Œæ—¨åœ¨ä¸ºå®ç°æ›´ç²¾å‡†ä¸”ä¾¿æ·çš„ä¸´åºŠæ”¾å°„æ€§è¯ç‰©æ²»ç–—å®è·µæä¾›æŒ‡å¯¼ã€‚",
      "categories": [
        "physics.med-ph",
        "cs.AI",
        "physics.app-ph"
      ],
      "primary_category": "physics.med-ph",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.12714v1",
      "published_date": "2025-10-14 16:55:36 UTC",
      "updated_date": "2025-10-14 16:55:36 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:21:31.881547+00:00"
    },
    {
      "arxiv_id": "2510.12713v1",
      "title": "Towards Robust Artificial Intelligence: Self-Supervised Learning Approach for Out-of-Distribution Detection",
      "title_zh": "è¿ˆå‘é²æ£’äººå·¥æ™ºèƒ½ï¼šåŸºäºè‡ªç›‘ç£å­¦ä¹ çš„åˆ†å¸ƒå¤–æ£€æµ‹æ–¹æ³•",
      "authors": [
        "Wissam Salhab",
        "Darine Ameyed",
        "Hamid Mcheick",
        "Fehmi Jaafar"
      ],
      "abstract": "Robustness in AI systems refers to their ability to maintain reliable and accurate performance under various conditions, including out-of-distribution (OOD) samples, adversarial attacks, and environmental changes. This is crucial in safety-critical systems, such as autonomous vehicles, transportation, or healthcare, where malfunctions could have severe consequences. This paper proposes an approach to improve OOD detection without the need of labeled data, thereby increasing the AI systems' robustness. The proposed approach leverages the principles of self-supervised learning, allowing the model to learn useful representations from unlabeled data. Combined with graph-theoretical techniques, this enables the more efficient identification and categorization of OOD samples. Compared to existing state-of-the-art methods, this approach achieved an Area Under the Receiver Operating Characteristic Curve (AUROC) = 0.99.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†AIç³»ç»Ÿåœ¨é¢å¯¹åˆ†å¸ƒå¤–(Out-of-Distribution, OOD)æ ·æœ¬ã€å¯¹æŠ—æ”»å‡»åŠç¯å¢ƒå˜åŒ–æ—¶ä¿æŒå¯é æ€§èƒ½çš„é²æ£’æ€§(Robustness)é—®é¢˜ï¼Œè¿™åœ¨è‡ªåŠ¨é©¾é©¶å’ŒåŒ»ç–—ç­‰å®‰å…¨å…³é”®é¢†åŸŸè‡³å…³é‡è¦ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§æå‡OODæ£€æµ‹èƒ½åŠ›çš„æ–¹æ³•ï¼Œå…¶æ ¸å¿ƒåœ¨äºåˆ©ç”¨è‡ªç›‘ç£å­¦ä¹ (Self-Supervised Learning)ä»æ— æ ‡æ³¨æ•°æ®ä¸­å­¦ä¹ ç‰¹å¾è¡¨ç¤º(Representations)ã€‚è¯¥æ–¹æ³•è¿›ä¸€æ­¥ç»“åˆäº†å›¾è®ºæŠ€æœ¯(Graph-Theoretical Techniques)ï¼Œä»è€Œèƒ½å¤Ÿæ›´é«˜æ•ˆåœ°è¯†åˆ«å’Œåˆ†ç±»OODæ ·æœ¬ã€‚å®éªŒè¯„ä¼°æ˜¾ç¤ºï¼Œè¯¥æ–¹æ³•åœ¨å—è¯•è€…å·¥ä½œç‰¹å¾æ›²çº¿ä¸‹é¢ç§¯(AUROC)ä¸Šè¾¾åˆ°äº†0.99ï¼Œæ€§èƒ½ä¼˜äºç°æœ‰çš„æœ€å…ˆè¿›æ–¹æ³•ã€‚è¿™ä¸€ç ”ç©¶æˆæœä¸ä»…æœ‰æ•ˆå¢å¼ºäº†AIç³»ç»Ÿçš„é²æ£’æ€§ï¼Œä¹Ÿä¸ºå¤„ç†å¤§è§„æ¨¡æ— æ ‡ç­¾æ•°æ®çš„å®‰å…¨åº”ç”¨åœºæ™¯æä¾›äº†æå…·ä»·å€¼çš„æŠ€æœ¯å‚è€ƒã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.12713v1",
      "published_date": "2025-10-14 16:55:25 UTC",
      "updated_date": "2025-10-14 16:55:25 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:21:34.080490+00:00"
    },
    {
      "arxiv_id": "2510.12712v3",
      "title": "Beyond Seeing: Evaluating Multimodal LLMs on Tool-Enabled Image Perception, Transformation, and Reasoning",
      "title_zh": "è¶…è¶Šè§†è§‰ï¼šè¯„ä¼°å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹åœ¨å·¥å…·èµ‹èƒ½ä¸‹çš„å›¾åƒæ„ŸçŸ¥ã€å˜æ¢ä¸æ¨ç†",
      "authors": [
        "Xingang Guo",
        "Utkarsh Tyagi",
        "Advait Gosai",
        "Paula Vergara",
        "Jayeon Park",
        "Ernesto Gabriel HernÃ¡ndez Montoya",
        "Chen Bo Calvin Zhang",
        "Bin Hu",
        "Yunzhong He",
        "Bing Liu",
        "Rakshith Sharma Srinivasa"
      ],
      "abstract": "Multimodal Large Language Models (MLLMs) are increasingly applied in real-world scenarios where user-provided images are often imperfect, requiring active image manipulations such as cropping, editing, or enhancement to uncover salient visual cues. Beyond static visual perception, MLLMs must also think with images: dynamically transforming visual content and integrating it with other tools to solve complex tasks. However, this shift from treating vision as passive context to a manipulable cognitive workspace remains underexplored. Most existing benchmarks still follow a think about images paradigm, where images are regarded as static inputs. To address this gap, we introduce VisualToolBench, a visual tool-use reasoning benchmark that rigorously evaluates MLLMs' ability to perceive, transform, and reason across complex visual-textual tasks under the think-with-images paradigm. VisualToolBench comprises 1,204 challenging, open-ended vision tasks (603 single-turn, 601 multi-turn) spanning across five diverse domains, each paired with detailed rubrics to enable systematic evaluation. Our evaluation shows that current MLLMs struggle with tasks requiring effective integration of vision and general-purpose tools. Even the strongest model (GPT-5-think) reaches only 18.68% pass rate. We further observe divergent tool-use behaviors, with OpenAI models benefiting from diverse image manipulations while Gemini-2.5-pro shows no improvement. By introducing the first benchmark centered on think with images, VisualToolBench offers critical insights for advancing visual intelligence in MLLMs.",
      "tldr_zh": "è¯¥ç ”ç©¶å¼•å…¥äº†VisualToolBenchï¼Œè¿™æ˜¯ä¸€ä¸ªä¸“æ³¨äºè§†è§‰å·¥å…·ä½¿ç”¨æ¨ç†(visual tool-use reasoning)çš„åŸºå‡†æµ‹è¯•ï¼Œæ—¨åœ¨è¯„ä¼°å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹(MLLMs)åœ¨â€œä»¥å›¾åƒæ€è€ƒâ€(think with images)èŒƒå¼ä¸‹æ„ŸçŸ¥ã€è½¬æ¢å’Œæ¨ç†å¤æ‚è§†è§‰ä»»åŠ¡çš„èƒ½åŠ›ã€‚ä¸ä»¥å¾€å°†å›¾åƒè§†ä¸ºé™æ€è¾“å…¥çš„â€œæ€è€ƒå›¾åƒâ€(think about images)æ¨¡å¼ä¸åŒï¼Œè¯¥åŸºå‡†å¼ºè°ƒæ¨¡å‹éœ€è¦é€šè¿‡è£å‰ªã€ç¼–è¾‘æˆ–å¢å¼ºç­‰æ‰‹æ®µåŠ¨æ€æ“ä½œå›¾åƒï¼Œå¹¶ç»“åˆé€šç”¨å·¥å…·æ¥è§£å†³ç°å®åœºæ™¯ä¸­çš„å¤æ‚é—®é¢˜ã€‚VisualToolBenchåŒ…å«æ¶µç›–äº”ä¸ªé¢†åŸŸçš„1,204ä¸ªå…·æœ‰æŒ‘æˆ˜æ€§çš„å¼€æ”¾å¼è§†è§‰ä»»åŠ¡ï¼Œå¹¶ä¸ºç³»ç»ŸåŒ–è¯„ä¼°æä¾›äº†è¯¦ç»†çš„è¯„åˆ†å‡†åˆ™ã€‚è¯„ä¼°ç»“æœæ˜¾ç¤ºï¼Œå½“å‰çš„MLLMsåœ¨æ•´åˆè§†è§‰ä¸å·¥å…·çš„èƒ½åŠ›æ–¹é¢ä»å­˜åœ¨æ˜¾è‘—çŸ­æ¿ï¼Œè¡¨ç°æœ€ä¼˜ç§€çš„GPT-5-thinkæ¨¡å‹é€šè¿‡ç‡ä»…ä¸º18.68%ã€‚ç ”ç©¶è¿˜å‘ç°ä¸åŒæ¨¡å‹åœ¨å·¥å…·ä½¿ç”¨è¡Œä¸ºä¸Šå­˜åœ¨å·®å¼‚ï¼Œä¾‹å¦‚OpenAIæ¨¡å‹èƒ½ä»å¤šæ ·åŒ–çš„å›¾åƒå¤„ç†ä¸­è·ç›Šï¼Œè€ŒGemini-2.5-proåˆ™æœªè§æ˜æ˜¾æå‡ã€‚ä½œä¸ºé¦–ä¸ªå›´ç»•â€œä»¥å›¾åƒæ€è€ƒâ€æ„å»ºçš„åŸºå‡†æµ‹è¯•ï¼ŒVisualToolBenchä¸ºæ¨åŠ¨MLLMsè§†è§‰æ™ºèƒ½çš„è¿›ä¸€æ­¥å‘å±•æä¾›äº†å…³é”®è§è§£å’Œè¯„ä¼°æ¡†æ¶ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.12712v3",
      "published_date": "2025-10-14 16:50:49 UTC",
      "updated_date": "2025-10-24 23:29:20 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:21:38.300412+00:00"
    },
    {
      "arxiv_id": "2510.12864v1",
      "title": "From Literal to Liberal: A Meta-Prompting Framework for Eliciting Human-Aligned Exception Handling in Large Language Models",
      "title_zh": "ä»å­—é¢éµå¾ªåˆ°çµæ´»æƒå˜ï¼šä¸€ç§åœ¨å¤§è¯­è¨€æ¨¡å‹ä¸­å¼•å¯¼äººç±»å¯¹é½å¼‚å¸¸å¤„ç†çš„å…ƒæç¤ºæ¡†æ¶",
      "authors": [
        "Imran Khan"
      ],
      "abstract": "Large Language Models (LLMs) are increasingly being deployed as the reasoning engines for agentic AI systems, yet they exhibit a critical flaw: a rigid adherence to explicit rules that leads to decisions misaligned with human common sense and intent. This \"rule-rigidity\" is a significant barrier to building trustworthy autonomous agents. While prior work has shown that supervised fine-tuning (SFT) with human explanations can mitigate this issue, SFT is computationally expensive and inaccessible to many practitioners. To address this gap, we introduce the Rule-Intent Distinction (RID) Framework, a novel, low-compute meta-prompting technique designed to elicit human-aligned exception handling in LLMs in a zero-shot manner. The RID framework provides the model with a structured cognitive schema for deconstructing tasks, classifying rules, weighing conflicting outcomes, and justifying its final decision. We evaluated the RID framework against baseline and Chain-of-Thought (CoT) prompting on a custom benchmark of 20 scenarios requiring nuanced judgment across diverse domains. Our human-verified results demonstrate that the RID framework significantly improves performance, achieving a 95% Human Alignment Score (HAS), compared to 80% for the baseline and 75% for CoT. Furthermore, it consistently produces higher-quality, intent-driven reasoning. This work presents a practical, accessible, and effective method for steering LLMs from literal instruction-following to liberal, goal-oriented reasoning, paving the way for more reliable and pragmatic AI agents.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨ä½œä¸ºæ™ºèƒ½ä½“å¼•æ“æ—¶è¡¨ç°å‡ºçš„è§„åˆ™åƒµåŒ–ï¼ˆrule-rigidityï¼‰é—®é¢˜ï¼Œå³è¿‡åº¦éµå¾ªå­—é¢è§„åˆ™è€ŒèƒŒç¦»äººç±»å¸¸è¯†ä¸æ„å›¾ï¼Œæå‡ºäº†Rule-Intent Distinction (RID) æ¡†æ¶ã€‚è¿™æ˜¯ä¸€ç§ä½è®¡ç®—æˆæœ¬çš„meta-promptingæŠ€æœ¯ï¼Œæ—¨åœ¨ä»¥zero-shotæ–¹å¼å¯å‘æ¨¡å‹è¿›è¡Œç¬¦åˆäººç±»é€»è¾‘çš„å¼‚å¸¸å¤„ç†ã€‚RIDæ¡†æ¶ä¸ºæ¨¡å‹æä¾›äº†ä¸€å¥—ç»“æ„åŒ–çš„è®¤çŸ¥æ¨¡å¼ï¼Œç”¨äºåˆ†è§£ä»»åŠ¡ã€åˆ†ç±»è§„åˆ™ã€æƒè¡¡å†²çªç»“æœå¹¶ä¸ºå…¶æœ€ç»ˆå†³ç­–æä¾›é€»è¾‘ä¾æ®ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œåœ¨å¤æ‚çš„åˆ¤æ–­åœºæ™¯ä¸­ï¼ŒRIDæ¡†æ¶å®ç°äº†95%çš„Human Alignment Score (HAS)ï¼Œæ˜¾è‘—ä¼˜äºåŸºå‡†æç¤ºå’ŒChain-of-Thought (CoT) æ–¹æ³•ã€‚è¯¥å·¥ä½œæä¾›äº†ä¸€ç§å®ç”¨ä¸”æœ‰æ•ˆçš„æ–¹æ³•ï¼Œèƒ½å¤Ÿå¼•å¯¼LLMsä»æœºæ¢°çš„æŒ‡ä»¤éµå¾ªè½¬å‘æ›´å…·çµæ´»æ€§çš„ç›®æ ‡å¯¼å‘æ¨ç†ï¼Œä¸ºæ„å»ºæ›´å¯é çš„è‡ªä¸»æ™ºèƒ½ä½“é“ºå¹³äº†é“è·¯ã€‚",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "13 pages. Code and data are available at https://github.com/strongSoda/LITERAL-TO-LIBERAL",
      "pdf_url": "https://arxiv.org/pdf/2510.12864v1",
      "published_date": "2025-10-14 16:42:52 UTC",
      "updated_date": "2025-10-14 16:42:52 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:21:47.281942+00:00"
    },
    {
      "arxiv_id": "2510.12704v1",
      "title": "Hybrid Explanation-Guided Learning for Transformer-Based Chest X-Ray Diagnosis",
      "title_zh": "åŸºäº Transformer çš„èƒ¸éƒ¨ X çº¿è¯Šæ–­æ··åˆè§£é‡Šå¼•å¯¼å­¦ä¹ ",
      "authors": [
        "Shelley Zixin Shu",
        "Haozhe Luo",
        "Alexander Poellinger",
        "Mauricio Reyes"
      ],
      "abstract": "Transformer-based deep learning models have demonstrated exceptional performance in medical imaging by leveraging attention mechanisms for feature representation and interpretability. However, these models are prone to learning spurious correlations, leading to biases and limited generalization. While human-AI attention alignment can mitigate these issues, it often depends on costly manual supervision. In this work, we propose a Hybrid Explanation-Guided Learning (H-EGL) framework that combines self-supervised and human-guided constraints to enhance attention alignment and improve generalization. The self-supervised component of H-EGL leverages class-distinctive attention without relying on restrictive priors, promoting robustness and flexibility. We validate our approach on chest X-ray classification using the Vision Transformer (ViT), where H-EGL outperforms two state-of-the-art Explanation-Guided Learning (EGL) methods, demonstrating superior classification accuracy and generalization capability. Additionally, it produces attention maps that are better aligned with human expertise.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹Transformeræ¨¡å‹åœ¨åŒ»å­¦å½±åƒè¯Šæ–­ä¸­æ˜“å­¦ä¹ ä¼ªç›¸å…³æ€§å¹¶å¯¼è‡´æ³›åŒ–å—é™çš„é—®é¢˜ï¼Œæå‡ºäº†Hybrid Explanation-Guided Learning (H-EGL)æ¡†æ¶ã€‚è¯¥æ¡†æ¶é€šè¿‡ç»“åˆself-supervisedå’Œhuman-guidedçº¦æŸæ¥å¢å¼ºattention alignmentï¼Œå…¶ä¸­çš„self-supervisedç»„ä»¶åˆ©ç”¨class-distinctive attentionåœ¨ä¸ä¾èµ–ä¸¥æ ¼å…ˆéªŒçš„æƒ…å†µä¸‹æå‡äº†æ¨¡å‹çš„é²æ£’æ€§ä¸çµæ´»æ€§ã€‚é€šè¿‡åœ¨åŸºäºVision Transformer (ViT)çš„èƒ¸éƒ¨Xå°„çº¿åˆ†ç±»ä»»åŠ¡ä¸Šè¿›è¡ŒéªŒè¯ï¼ŒH-EGLåœ¨åˆ†ç±»å‡†ç¡®ç‡å’Œæ³›åŒ–æ€§èƒ½ä¸Šå‡è¶…è¶Šäº†ç°æœ‰çš„Explanation-Guided Learning (EGL)æ–¹æ³•ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•ç”Ÿæˆçš„attention mapsèƒ½å¤Ÿæ›´å¥½åœ°ä¸äººç±»ä¸“å®¶çŸ¥è¯†ä¿æŒä¸€è‡´ï¼Œä¸ºæå‡åŒ»ç–—è¯Šæ–­æ¨¡å‹çš„å¯é æ€§ä¸é€æ˜åº¦æä¾›äº†æœ‰æ•ˆæ”¯æŒã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by iMIMIC at MICCAI 2025",
      "pdf_url": "https://arxiv.org/pdf/2510.12704v1",
      "published_date": "2025-10-14 16:39:02 UTC",
      "updated_date": "2025-10-14 16:39:02 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:21:45.569874+00:00"
    },
    {
      "arxiv_id": "2510.12703v1",
      "title": "CAMNet: Leveraging Cooperative Awareness Messages for Vehicle Trajectory Prediction",
      "title_zh": "CAMNetï¼šåˆ©ç”¨åä½œæ„ŸçŸ¥æ¶ˆæ¯è¿›è¡Œè½¦è¾†è½¨è¿¹é¢„æµ‹",
      "authors": [
        "Mattia Grasselli",
        "Angelo Porrello",
        "Carlo Augusto Grazia"
      ],
      "abstract": "Autonomous driving remains a challenging task, particularly due to safety concerns. Modern vehicles are typically equipped with expensive sensors such as LiDAR, cameras, and radars to reduce the risk of accidents. However, these sensors face inherent limitations: their field of view and line of sight can be obstructed by other vehicles, thereby reducing situational awareness. In this context, vehicle-to-vehicle communication plays a crucial role, as it enables cars to share information and remain aware of each other even when sensors are occluded. One way to achieve this is through the use of Cooperative Awareness Messages (CAMs). In this paper, we investigate the use of CAM data for vehicle trajectory prediction. Specifically, we design and train a neural network, Cooperative Awareness Message-based Graph Neural Network (CAMNet), on a widely used motion forecasting dataset. We then evaluate the model on a second dataset that we created from scratch using Cooperative Awareness Messages, in order to assess whether this type of data can be effectively exploited. Our approach demonstrates promising results, showing that CAMs can indeed support vehicle trajectory prediction. At the same time, we discuss several limitations of the approach, which highlight opportunities for future research.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹è‡ªåŠ¨é©¾é©¶ä¸­ LiDARã€æ‘„åƒå¤´å’Œé›·è¾¾ç­‰ä¼ æ„Ÿå™¨å› è§†åœºå—é™å’Œé®æŒ¡å¯¼è‡´çš„æƒ…å¢ƒæ„ŸçŸ¥ä¸è¶³é—®é¢˜ï¼Œæå‡ºåˆ©ç”¨è½¦é—´é€šä¿¡ (V2V) ä¸­çš„åä½œæ„ŸçŸ¥æ¶ˆæ¯ (Cooperative Awareness Messages, CAMs) æ¥ä¼˜åŒ–è½¦è¾†è½¨è¿¹é¢„æµ‹ã€‚ç ”ç©¶å›¢é˜Ÿå¼€å‘äº†åŸºäºå›¾ç¥ç»ç½‘ç»œçš„é¢„æµ‹æ¨¡å‹ CAMNet (Cooperative Awareness Message-based Graph Neural Network)ï¼Œå¹¶åœ¨ä¸»æµè¿åŠ¨é¢„æµ‹æ•°æ®é›†ä»¥åŠä¸“é—¨æ„å»ºçš„ CAM æ•°æ®é›†ä¸Šè¿›è¡Œäº†è®­ç»ƒä¸è¯„ä¼°ã€‚å®éªŒç»“æœè¯æ˜ï¼ŒCAMs æ•°æ®èƒ½å¤Ÿæœ‰æ•ˆå¼¥è¡¥ä¼ æ„Ÿå™¨åœ¨è¢«é®æŒ¡ç¯å¢ƒä¸‹çš„æ„ŸçŸ¥ç¼ºé™·ï¼Œä¸ºå‡†ç¡®é¢„æµ‹è½¦è¾†è½¨è¿¹æä¾›å…³é”®æ”¯æŒã€‚è¯¥ç ”ç©¶ä¸ä»…éªŒè¯äº†åˆ©ç”¨é€šä¿¡æ•°æ®è¿›è¡Œè¿åŠ¨é¢„æµ‹çš„æœ‰æ•ˆæ€§ï¼Œè¿˜å±•ç¤ºäº†ååŒæ„ŸçŸ¥åœ¨æå‡è‡ªåŠ¨é©¾é©¶å®‰å…¨æ€§æ–¹é¢çš„å·¨å¤§æ½œåŠ›ã€‚æ­¤å¤–ï¼Œè®ºæ–‡è¿˜æ·±å…¥åˆ†æäº†è¯¥æ–¹æ³•çš„å±€é™æ€§ï¼Œå¹¶ä¸ºæœªæ¥ç»“åˆ V2V é€šä¿¡ä¸æ·±åº¦å­¦ä¹ çš„ç ”ç©¶æ–¹å‘æä¾›äº†é‡è¦å‚è€ƒã€‚",
      "categories": [
        "cs.AI",
        "cs.NI"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted at the IEEE Consumer Communications & Networking Conference (CCNC) 2026 - Las Vegas, NV, USA 9 - 12 January 2026",
      "pdf_url": "https://arxiv.org/pdf/2510.12703v1",
      "published_date": "2025-10-14 16:37:52 UTC",
      "updated_date": "2025-10-14 16:37:52 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:21:46.582728+00:00"
    },
    {
      "arxiv_id": "2510.12702v1",
      "title": "Beyond Postconditions: Can Large Language Models infer Formal Contracts for Automatic Software Verification?",
      "title_zh": "è¶…è¶Šåç½®æ¡ä»¶ï¼šå¤§è¯­è¨€æ¨¡å‹èƒ½å¦ä¸ºè‡ªåŠ¨åŒ–è½¯ä»¶éªŒè¯æ¨æ–­å½¢å¼åŒ–å¥‘çº¦ï¼Ÿ",
      "authors": [
        "Cedric Richter",
        "Heike Wehrheim"
      ],
      "abstract": "Automatic software verifiers have become increasingly effective at the task of checking software against (formal) specifications. Yet, their adoption in practice has been hampered by the lack of such specifications in real world code. Large Language Models (LLMs) have shown promise in inferring formal postconditions from natural language hints embedded in code such as function names, comments or documentation. Using the generated postconditions as specifications in a subsequent verification, however, often leads verifiers to suggest invalid inputs, hinting at potential issues that ultimately turn out to be false alarms.\n  To address this, we revisit the problem of specification inference from natural language in the context of automatic software verification. In the process, we introduce NL2Contract, the task of employing LLMs to translate informal natural language into formal functional contracts, consisting of postconditions as well as preconditions. We introduce metrics to validate and compare different NL2Contract approaches, using soundness, bug discriminative power of the generated contracts and their usability in the context of automatic software verification as key metrics. We evaluate NL2Contract with different LLMs and compare it to the task of postcondition generation nl2postcond. Our evaluation shows that (1) LLMs are generally effective at generating functional contracts sound for all possible inputs, (2) the generated contracts are sufficiently expressive for discriminating buggy from correct behavior, and (3) verifiers supplied with LLM inferred functional contracts produce fewer false alarms than when provided with postconditions alone. Further investigations show that LLM inferred preconditions generally align well with developers intentions which allows us to use automatic software verifiers to catch real-world bugs.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å¤§å‹è¯­è¨€æ¨¡å‹(LLMs)åœ¨è‡ªåŠ¨è½¯ä»¶éªŒè¯ä¸­æ¨æ–­å½¢å¼åŒ–åˆåŒçš„æ½œåŠ›ï¼Œæ—¨åœ¨è§£å†³çœŸå®ä»£ç ç¼ºä¹è§„èŒƒ(Specifications)çš„é—®é¢˜ã€‚ç ”ç©¶è€…æå‡ºäº†NL2Contractä»»åŠ¡ï¼Œåˆ©ç”¨LLMså°†è‡ªç„¶è¯­è¨€è½¬åŒ–ä¸ºåŒ…å«å‰ç½®æ¡ä»¶(Preconditions)å’Œåç½®æ¡ä»¶(Postconditions)çš„å®Œæ•´åŠŸèƒ½åˆåŒ(Functional Contracts)ã€‚é€šè¿‡å¼•å…¥å¥å…¨æ€§(Soundness)å’Œç¼ºé™·è¾¨åˆ«èƒ½åŠ›ç­‰æŒ‡æ ‡è¿›è¡Œè¯„ä¼°ï¼Œç»“æœè¡¨æ˜LLMsèƒ½æœ‰æ•ˆç”Ÿæˆé€‚ç”¨äºæ‰€æœ‰å¯èƒ½è¾“å…¥çš„å¥å…¨åˆåŒã€‚å®éªŒè¯æ˜ï¼Œè¿™äº›æ¨æ–­å‡ºçš„åˆåŒè¶³ä»¥åŒºåˆ†é”™è¯¯è¡Œä¸ºä¸æ­£ç¡®è¡Œä¸ºï¼Œä¸”ç›¸æ¯”äºä»…æä¾›åç½®æ¡ä»¶ï¼Œå®Œæ•´çš„åŠŸèƒ½åˆåŒèƒ½æ˜¾è‘—å‡å°‘éªŒè¯è¿‡ç¨‹ä¸­çš„è™šå‡è­¦æŠ¥ã€‚æ­¤å¤–ï¼ŒLLMç”Ÿæˆçš„å‰ç½®æ¡ä»¶ä¸å¼€å‘è€…æ„å›¾é«˜åº¦ä¸€è‡´ï¼Œèƒ½å¤Ÿå¸®åŠ©éªŒè¯å™¨æ›´ç²¾å‡†åœ°æ•æ‰ç°å®ä¸–ç•Œä¸­çš„è½¯ä»¶ç¼ºé™·ã€‚",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.PL"
      ],
      "primary_category": "cs.SE",
      "comment": "under submission",
      "pdf_url": "https://arxiv.org/pdf/2510.12702v1",
      "published_date": "2025-10-14 16:37:39 UTC",
      "updated_date": "2025-10-14 16:37:39 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:21:50.788661+00:00"
    },
    {
      "arxiv_id": "2510.12700v2",
      "title": "Topological Signatures of ReLU Neural Network Activation Patterns",
      "title_zh": "ReLU ç¥ç»ç½‘ç»œæ¿€æ´»æ¨¡å¼çš„æ‹“æ‰‘ç‰¹å¾",
      "authors": [
        "Vicente Bosca",
        "Tatum Rask",
        "Sunia Tanweer",
        "Andrew R. Tawfeek",
        "Branden Stone"
      ],
      "abstract": "This paper explores the topological signatures of ReLU neural network activation patterns. We consider feedforward neural networks with ReLU activation functions and analyze the polytope decomposition of the feature space induced by the network. Mainly, we investigate how the Fiedler partition of the dual graph and show that it appears to correlate with the decision boundary -- in the case of binary classification. Additionally, we compute the homology of the cellular decomposition -- in a regression task -- to draw similar patterns in behavior between the training loss and polyhedral cell-count, as the model is trained.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†ReLUç¥ç»ç½‘ç»œæ¿€æ´»æ¨¡å¼çš„æ‹“æ‰‘ç‰¹å¾ï¼Œé‡ç‚¹åˆ†æäº†ç”±ç½‘ç»œè¯±å¯¼çš„ç‰¹å¾ç©ºé—´çš„å¤šèƒä½“åˆ†è§£(polytope decomposition)ã€‚ç ”ç©¶è€…è°ƒæŸ¥äº†å¯¹å¶å›¾(dual graph)çš„è´¹å¾·å‹’åˆ’åˆ†(Fiedler partition)ï¼Œå‘ç°åœ¨äºŒåˆ†ç±»ä»»åŠ¡ä¸­è¯¥åˆ’åˆ†ä¸å†³ç­–è¾¹ç•Œ(decision boundary)è¡¨ç°å‡ºç›¸å…³æ€§ã€‚æ­¤å¤–ï¼Œé€šè¿‡è®¡ç®—å›å½’ä»»åŠ¡ä¸­èƒè…”åˆ†è§£(cellular decomposition)çš„åŒè°ƒ(homology)ï¼Œç ”ç©¶æ­ç¤ºäº†æ¨¡å‹è®­ç»ƒè¿‡ç¨‹ä¸­è®­ç»ƒæŸå¤±(training loss)ä¸å¤šé¢ä½“èƒè…”è®¡æ•°(polyhedral cell-count)ä¹‹é—´å­˜åœ¨ç›¸ä¼¼çš„è¡Œä¸ºæ¨¡å¼ã€‚è¿™äº›å‘ç°ä»å‡ ä½•ä¸æ‹“æ‰‘è§’åº¦åˆ»ç”»äº†ç¥ç»ç½‘ç»œçš„å†…éƒ¨è¿ä½œæœºåˆ¶ï¼Œä¸ºç†è§£ReLUç½‘ç»œçš„ç»“æ„å¤æ‚æ€§æä¾›äº†æ–°çš„é‡åŒ–æ‰‹æ®µã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CG",
        "math.AT",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.12700v2",
      "published_date": "2025-10-14 16:36:34 UTC",
      "updated_date": "2026-01-09 01:40:17 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:21:51.288233+00:00"
    },
    {
      "arxiv_id": "2510.12699v1",
      "title": "Generation Space Size: Understanding and Calibrating Open-Endedness of LLM Generations",
      "title_zh": "ç”Ÿæˆç©ºé—´å¤§å°ï¼šå¤§è¯­è¨€æ¨¡å‹ç”Ÿæˆå¼€æ”¾æ€§çš„ç†è§£ä¸æ ¡å‡†",
      "authors": [
        "Sunny Yu",
        "Ahmad Jabbar",
        "Robert Hawkins",
        "Dan Jurafsky",
        "Myra Cheng"
      ],
      "abstract": "Different open-ended generation tasks require different degrees of output diversity. However, current LLMs are often miscalibrated. They collapse to overly homogeneous outputs for creative tasks and hallucinate diverse but incorrect responses for factual tasks. We argue that these two failure modes are unified by, and can both be addressed by, the notion of effective generation space size (GSS) -- the set of semantically distinct outputs a model considers for a prompt. We present GSSBench, a task suite of prompt pairs with ground-truth GSS relationships to assess different metrics and understand where models diverge from desired behavior. We find that hallucination detection metrics, particularly EigenScore, consistently outperform standard diversity and uncertainty quantification metrics, while using only model internals, providing interpretable insights into a model's internal task representations. We demonstrate three applications of GSS: (1) detecting prompt ambiguity and predicting clarification questions for better grounding, (2) interpreting overthinking and underthinking in reasoning models, and (3) steering models to expand their generation space to yield high-quality and diverse outputs.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨å¼€æ”¾å¼ç”Ÿæˆä»»åŠ¡ä¸­è¡¨ç°å‡ºçš„è¾“å‡ºå¤šæ ·æ€§å¤±è°ƒé—®é¢˜ï¼Œæå‡ºäº†æœ‰æ•ˆç”Ÿæˆç©ºé—´å¤§å°ï¼ˆGeneration Space Size, GSSï¼‰çš„æ¦‚å¿µï¼Œæ—¨åœ¨ç»Ÿä¸€å¹¶è§£å†³åˆ›é€ æ€§ä»»åŠ¡ä¸­çš„åŒè´¨åŒ–å€¾å‘ä¸äº‹å®æ€§ä»»åŠ¡ä¸­çš„å¹»è§‰ç°è±¡ã€‚ä½œè€…é€šè¿‡æ„å»º GSSBench è¯„æµ‹å¥—ä»¶ï¼Œå‘ç°åŸºäºæ¨¡å‹å†…éƒ¨çŠ¶æ€çš„å¹»è§‰æ£€æµ‹æŒ‡æ ‡ EigenScore åœ¨è¡¡é‡æ¨¡å‹å†…éƒ¨ä»»åŠ¡è¡¨ç¤ºæ–¹é¢æ˜¾è‘—ä¼˜äºä¼ ç»Ÿçš„å¤šæ ·æ€§ä¸ä¸ç¡®å®šæ€§é‡åŒ–æŒ‡æ ‡ã€‚ç ”ç©¶è¿›ä¸€æ­¥å±•ç¤ºäº† GSS åœ¨æ£€æµ‹æç¤ºè¯æ­§ä¹‰ã€é¢„æµ‹æ¾„æ¸…é—®é¢˜ä»¥åŠè§£é‡Šæ¨ç†æ¨¡å‹ä¸­çš„è¿‡åº¦æ€è€ƒï¼ˆoverthinkingï¼‰ä¸æ€è€ƒä¸è¶³ï¼ˆunderthinkingï¼‰æ–¹é¢çš„åº”ç”¨ä»·å€¼ã€‚é€šè¿‡åˆ©ç”¨ GSS å¼•å¯¼æ¨¡å‹åŠ¨æ€è°ƒæ•´å…¶ç”Ÿæˆç©ºé—´ï¼Œè¯¥ç ”ç©¶èƒ½å¤Ÿæœ‰æ•ˆæå‡ç”Ÿæˆå†…å®¹çš„è´¨é‡ä¸å¤šæ ·æ€§ï¼Œä¸ºç†è§£å’Œæ ¡å‡†æ¨¡å‹çš„å¼€æ”¾æ€§ç”Ÿæˆè¡Œä¸ºæä¾›äº†æ–°çš„è§†è§’ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.12699v1",
      "published_date": "2025-10-14 16:31:34 UTC",
      "updated_date": "2025-10-14 16:31:34 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:21:57.665767+00:00"
    },
    {
      "arxiv_id": "2510.12697v1",
      "title": "Multi-Agent Debate for LLM Judges with Adaptive Stability Detection",
      "title_zh": "å…·æœ‰è‡ªé€‚åº”ç¨³å®šæ€§æ£€æµ‹çš„ LLM è¯„åˆ¤å™¨å¤šæ™ºèƒ½ä½“è¾©è®º",
      "authors": [
        "Tianyu Hu",
        "Zhen Tan",
        "Song Wang",
        "Huaizhi Qu",
        "Tianlong Chen"
      ],
      "abstract": "With advancements in reasoning capabilities, Large Language Models (LLMs) are increasingly employed for automated judgment tasks. While LLMs-as-Judges offer promise in automating evaluations, current approaches often rely on simplistic aggregation methods (e.g., majority voting), which can fail even when individual agents provide correct answers. To address this, we propose a multi-agent debate judge framework where agents collaboratively reason and iteratively refine their responses. We formalize the debate process mathematically, analyzing agent interactions and proving that debate amplifies correctness compared to static ensembles. To enhance efficiency, we introduce a stability detection mechanism that models judge consensus dynamics via a time-varying Beta-Binomial mixture, with adaptive stopping based on distributional similarity (Kolmogorov-Smirnov test). This mechanism models the judges' collective correct rate dynamics using a time-varying mixture of Beta-Binomial distributions and employs an adaptive stopping criterion based on distributional similarity (Kolmogorov-Smirnov statistic). Experiments across multiple benchmarks and models demonstrate that our framework improves judgment accuracy over majority voting while maintaining computational efficiency.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§è¯­è¨€æ¨¡å‹ä½œä¸ºè£åˆ¤ (LLM-as-Judges) åœ¨è‡ªåŠ¨åŒ–è¯„ä¼°ä¸­ç”±äºç®€å•èšåˆæ–¹æ³•ï¼ˆå¦‚å¤šæ•°æŠ•ç¥¨ï¼‰å¯¼è‡´çš„æ€§èƒ½ç“¶é¢ˆï¼Œæå‡ºäº†ä¸€ä¸ªå…·æœ‰è‡ªé€‚åº”ç¨³å®šæ€§æ£€æµ‹çš„ Multi-Agent Debate è£åˆ¤æ¡†æ¶ã€‚è¯¥æ¡†æ¶é€šè¿‡æ™ºèƒ½ä½“ä¹‹é—´çš„åä½œæ¨ç†ä¸è¿­ä»£ä¼˜åŒ–æ¥æ”¹è¿›è¯„ä¼°ç»“æœï¼Œç ”ç©¶è€…è¿˜å¯¹å…¶è¾©è®ºè¿‡ç¨‹è¿›è¡Œäº†æ•°å­¦å½¢å¼åŒ–åˆ†æï¼Œè¯æ˜äº†è¾©è®ºæœºåˆ¶ç›¸æ¯”é™æ€é›†æˆèƒ½å¤Ÿæœ‰æ•ˆæ”¾å¤§æ­£ç¡®ç‡ã€‚ä¸ºäº†å¹³è¡¡è¯„ä¼°ç²¾åº¦ä¸è®¡ç®—æ•ˆç‡ï¼Œè¯¥ç ”ç©¶å¼•å…¥äº†ä¸€ç§ç¨³å®šæ€§æ£€æµ‹æœºåˆ¶ï¼Œåˆ©ç”¨éšæ—¶é—´å˜åŒ–çš„ Beta-Binomial æ··åˆåˆ†å¸ƒå¯¹è£åˆ¤ç¾¤ä½“çš„å…±è¯†åŠ¨æ€è¿›è¡Œå»ºæ¨¡ã€‚è¯¥æœºåˆ¶ç»“åˆåŸºäºåˆ†å¸ƒç›¸ä¼¼åº¦ï¼ˆKolmogorov-Smirnov æ£€éªŒï¼‰çš„è‡ªé€‚åº”åœæ­¢å‡†åˆ™ï¼Œèƒ½å¤ŸåŠ¨æ€åˆ¤æ–­è¾©è®ºæ˜¯å¦è¾¾åˆ°ç¨³å®šçŠ¶æ€å¹¶åŠæ—¶ç»ˆæ­¢ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ¡†æ¶åœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸Šå‡æ˜¾è‘—ä¼˜äºä¼ ç»Ÿçš„å¤šæ•°æŠ•ç¥¨æ–¹æ³•ï¼Œåœ¨æå‡åˆ¤æ–­å‡†ç¡®ç‡çš„åŒæ—¶ä¿æŒäº†è¾ƒé«˜çš„è®¡ç®—æ•ˆç‡ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.12697v1",
      "published_date": "2025-10-14 16:30:30 UTC",
      "updated_date": "2025-10-14 16:30:30 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:22:09.382903+00:00"
    },
    {
      "arxiv_id": "2510.12693v1",
      "title": "ERA: Transforming VLMs into Embodied Agents via Embodied Prior Learning and Online Reinforcement Learning",
      "title_zh": "ERAï¼šé€šè¿‡å…·èº«å…ˆéªŒå­¦ä¹ ä¸åœ¨çº¿å¼ºåŒ–å­¦ä¹ å°† VLMs è½¬åŒ–ä¸ºå…·èº«æ™ºèƒ½ä½“",
      "authors": [
        "Hanyang Chen",
        "Mark Zhao",
        "Rui Yang",
        "Qinwei Ma",
        "Ke Yang",
        "Jiarui Yao",
        "Kangrui Wang",
        "Hao Bai",
        "Zhenhailong Wang",
        "Rui Pan",
        "Mengchao Zhang",
        "Jose Barreiros",
        "Aykut Onol",
        "ChengXiang Zhai",
        "Heng Ji",
        "Manling Li",
        "Huan Zhang",
        "Tong Zhang"
      ],
      "abstract": "Recent advances in embodied AI highlight the potential of vision language models (VLMs) as agents capable of perception, reasoning, and interaction in complex environments. However, top-performing systems rely on large-scale models that are costly to deploy, while smaller VLMs lack the necessary knowledge and skills to succeed. To bridge this gap, we present \\textit{Embodied Reasoning Agent (ERA)}, a two-stage framework that integrates prior knowledge learning and online reinforcement learning (RL). The first stage, \\textit{Embodied Prior Learning}, distills foundational knowledge from three types of data: (1) Trajectory-Augmented Priors, which enrich existing trajectory data with structured reasoning generated by stronger models; (2) Environment-Anchored Priors, which provide in-environment knowledge and grounding supervision; and (3) External Knowledge Priors, which transfer general knowledge from out-of-environment datasets. In the second stage, we develop an online RL pipeline that builds on these priors to further enhance agent performance. To overcome the inherent challenges in agent RL, including long horizons, sparse rewards, and training instability, we introduce three key designs: self-summarization for context management, dense reward shaping, and turn-level policy optimization. Extensive experiments on both high-level planning (EB-ALFRED) and low-level control (EB-Manipulation) tasks demonstrate that ERA-3B surpasses both prompting-based large models and previous training-based baselines. Specifically, it achieves overall improvements of 8.4\\% on EB-ALFRED and 19.4\\% on EB-Manipulation over GPT-4o, and exhibits strong generalization to unseen tasks. Overall, ERA offers a practical path toward scalable embodied intelligence, providing methodological insights for future embodied AI systems.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†Embodied Reasoning Agent (ERA)ï¼Œè¿™æ˜¯ä¸€ä¸ªç»“åˆEmbodied Prior Learningå’Œåœ¨çº¿Reinforcement Learningçš„ä¸¤é˜¶æ®µæ¡†æ¶ï¼Œæ—¨åœ¨å°†è§†è§‰è¯­è¨€æ¨¡å‹(VLMs)è½¬åŒ–ä¸ºå…·å¤‡æ„ŸçŸ¥ä¸äº¤äº’èƒ½åŠ›çš„å…·èº«æ™ºèƒ½ä½“ã€‚åœ¨ç¬¬ä¸€é˜¶æ®µï¼ŒERAé€šè¿‡è’¸é¦è½¨è¿¹å¢å¼ºå…ˆéªŒã€ç¯å¢ƒé”šå®šå…ˆéªŒå’Œå¤–éƒ¨çŸ¥è¯†å…ˆéªŒï¼Œä¸ºæ¨¡å‹æ³¨å…¥äº†ç»“æ„åŒ–æ¨ç†å’Œè·¨é¢†åŸŸæ ¸å¿ƒçŸ¥è¯†ã€‚ç¬¬äºŒé˜¶æ®µå¼•å…¥äº†åœ¨çº¿Reinforcement Learningä¼˜åŒ–ï¼Œé€šè¿‡è‡ªæ€»ç»“ã€ç¨ å¯†å¥–åŠ±å¡‘é€ å’Œå›åˆçº§ç­–ç•¥ä¼˜åŒ–ç­‰è®¾è®¡ï¼ŒæˆåŠŸå…‹æœäº†å…·èº«ä»»åŠ¡ä¸­é•¿è·¯å¾„å’Œç¨€ç–å¥–åŠ±çš„éš¾é¢˜ã€‚å®éªŒè¯æ˜ï¼ŒERA-3Båœ¨EB-ALFREDè§„åˆ’ä»»åŠ¡å’ŒEB-Manipulationæ§åˆ¶ä»»åŠ¡ä¸Šçš„è¡¨ç°åˆ†åˆ«ä¼˜äºGPT-4oçº¦8.4%å’Œ19.4%ï¼Œå¹¶å±•ç°å‡ºå¯¹æœªçŸ¥ä»»åŠ¡çš„å¼ºå¤§æ³›åŒ–æ€§ã€‚è¯¥æˆæœä¸ä»…åœ¨æ€§èƒ½ä¸Šè¶…è¶Šäº†ç°æœ‰çš„å¤§è§„æ¨¡æ¨¡å‹ï¼Œä¹Ÿä¸ºæ„å»ºé«˜æ•ˆã€å¯æ‰©å±•çš„å…·èº«äººå·¥æ™ºèƒ½ç³»ç»Ÿå¼€è¾Ÿäº†æ–°çš„æŠ€æœ¯è·¯å¾„ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.12693v1",
      "published_date": "2025-10-14 16:25:46 UTC",
      "updated_date": "2025-10-14 16:25:46 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:22:24.164363+00:00"
    },
    {
      "arxiv_id": "2510.12692v1",
      "title": "Who is a Better Matchmaker? Human vs. Algorithmic Judge Assignment in a High-Stakes Startup Competition",
      "title_zh": "è°æ˜¯æ›´ä¼˜ç§€çš„åŒ¹é…è€…ï¼Ÿé«˜åˆ©å®³åˆ›ä¸šç«èµ›ä¸­çš„äººç±»ä¸ç®—æ³•è¯„å§”åˆ†é…ä¹‹æ¯”è¾ƒ",
      "authors": [
        "Sarina Xi",
        "Orelia Pi",
        "Miaomiao Zhang",
        "Becca Xiong",
        "Jacqueline Ng Lane",
        "Nihar B. Shah"
      ],
      "abstract": "There is growing interest in applying artificial intelligence (AI) to automate and support complex decision-making tasks. However, it remains unclear how algorithms compare to human judgment in contexts requiring semantic understanding and domain expertise. We examine this in the context of the judge assignment problem, matching submissions to suitably qualified judges. Specifically, we tackled this problem at the Harvard President's Innovation Challenge, the university's premier venture competition awarding over \\$500,000 to student and alumni startups. This represents a real-world environment where high-quality judge assignment is essential. We developed an AI-based judge-assignment algorithm, Hybrid Lexical-Semantic Similarity Ensemble (HLSE), and deployed it at the competition. We then evaluated its performance against human expert assignments using blinded match-quality scores from judges on $309$ judge-venture pairs. Using a Mann-Whitney U statistic based test, we found no statistically significant difference in assignment quality between the two approaches ($AUC=0.48, p=0.40$); on average, algorithmic matches are rated $3.90$ and manual matches $3.94$ on a 5-point scale, where 5 indicates an excellent match. Furthermore, manual assignments that previously required a full week could be automated in several hours by the algorithm during deployment. These results demonstrate that HLSE achieves human-expert-level matching quality while offering greater scalability and efficiency, underscoring the potential of AI-driven solutions to support and enhance human decision-making for judge assignment in high-stakes settings.",
      "tldr_zh": "è¿™é¡¹ç ”ç©¶æ¢è®¨äº†åœ¨æ¶‰åŠè¯­ä¹‰ç†è§£å’Œé¢†åŸŸä¸“ä¸šçŸ¥è¯†çš„é«˜é£é™©åˆ›ä¸šç«èµ›ä¸­ï¼Œäººå·¥æ™ºèƒ½ä¸äººç±»åˆ¤æ–­åœ¨è¯„å®¡åˆ†é…ä»»åŠ¡ (Judge Assignment Problem) ä¸­çš„è¡¨ç°å·®å¼‚ã€‚ç ”ç©¶å›¢é˜Ÿå¼€å‘å¹¶éƒ¨ç½²äº†ä¸€ç§åä¸º Hybrid Lexical-Semantic Similarity Ensemble (HLSE) çš„äººå·¥æ™ºèƒ½ç®—æ³•ï¼Œç”¨äºå¤„ç†å“ˆä½›æ ¡é•¿åˆ›æ–°æŒ‘æˆ˜èµ› (Harvard President's Innovation Challenge) çš„è¯„å®¡åŒ¹é…å·¥ä½œã€‚é€šè¿‡å¯¹ 309 å¯¹è¯„å®¡-é¡¹ç›®ç»„åˆçš„åŒç›²è¯„åˆ†åˆ†æï¼Œç ”ç©¶å‘ç°ç®—æ³•ç”Ÿæˆçš„åŒ¹é…è´¨é‡ä¸äººç±»ä¸“å®¶åˆ†é…çš„è´¨é‡åœ¨ç»Ÿè®¡å­¦ä¸Šæ²¡æœ‰æ˜¾è‘—å·®å¼‚ã€‚æ­¤å¤–ï¼Œè¯¥ç®—æ³•å°†åŸæœ¬éœ€è¦äººå·¥è€—æ—¶ä¸€å‘¨çš„å¤„ç†è¿‡ç¨‹ç¼©çŸ­è‡³æ•°å°æ—¶ï¼Œæ˜¾è‘—æå‡äº†åˆ†é…æ•ˆç‡å’Œå¯æ‰©å±•æ€§ (Scalability)ã€‚å®éªŒç»“æœè¯æ˜ HLSE èƒ½å¤Ÿè¾¾åˆ°äººç±»ä¸“å®¶çº§åˆ«çš„åŒ¹é…æ°´å‡†ï¼Œå……åˆ†å±•ç¤ºäº†äººå·¥æ™ºèƒ½é©±åŠ¨çš„è§£å†³æ–¹æ¡ˆåœ¨æ”¯æŒå’Œå¢å¼ºé«˜é£é™©å†³ç­–åœºæ™¯æ–¹é¢çš„å·¨å¤§æ½œåŠ›ã€‚",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CL",
        "cs.CY",
        "cs.LG"
      ],
      "primary_category": "cs.HC",
      "comment": "17 Pages, 2 figures",
      "pdf_url": "https://arxiv.org/pdf/2510.12692v1",
      "published_date": "2025-10-14 16:25:09 UTC",
      "updated_date": "2025-10-14 16:25:09 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:22:19.385727+00:00"
    },
    {
      "arxiv_id": "2510.12691v3",
      "title": "DiffEM: Learning from Corrupted Data with Diffusion Models via Expectation Maximization",
      "title_zh": "DiffEMï¼šåŸºäºæœŸæœ›æœ€å¤§åŒ–ä¸æ‰©æ•£æ¨¡å‹çš„æŸåæ•°æ®å­¦ä¹ ",
      "authors": [
        "Danial Hosseintabar",
        "Fan Chen",
        "Giannis Daras",
        "Antonio Torralba",
        "Constantinos Daskalakis"
      ],
      "abstract": "Diffusion models have emerged as powerful generative priors for high-dimensional inverse problems, yet learning them when only corrupted or noisy observations are available remains challenging. In this work, we propose a new method for training diffusion models with Expectation-Maximization (EM) from corrupted data. Our proposed method, DiffEM, utilizes conditional diffusion models to reconstruct clean data from observations in the E-step, and then uses the reconstructed data to refine the conditional diffusion model in the M-step. Theoretically, we provide monotonic convergence guarantees for the DiffEM iteration, assuming appropriate statistical conditions. We demonstrate the effectiveness of our approach through experiments on various image reconstruction tasks.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†DiffEMï¼Œä¸€ç§åˆ©ç”¨æœŸæœ›æœ€å¤§åŒ–(Expectation-Maximization, EM)ç®—æ³•ä»å—æŸæˆ–å«å™ªå£°æ•°æ®ä¸­è®­ç»ƒæ‰©æ•£æ¨¡å‹(Diffusion models)çš„æ–°æ–¹æ³•ã€‚DiffEMåœ¨Eæ­¥(E-step)ä¸­ä½¿ç”¨æ¡ä»¶æ‰©æ•£æ¨¡å‹(conditional diffusion models)ä»è§‚æµ‹å€¼ä¸­é‡å»ºå¹²å‡€æ•°æ®ï¼Œå¹¶åœ¨Mæ­¥(M-step)ä¸­åˆ©ç”¨è¿™äº›é‡å»ºæ•°æ®è¿›ä¸€æ­¥ç²¾ç‚¼æ‰©æ•£æ¨¡å‹ã€‚åœ¨ç†è®ºæ–¹é¢ï¼Œè¯¥å·¥ä½œåœ¨é€‚å½“çš„ç»Ÿè®¡æ¡ä»¶ä¸‹ä¸ºDiffEMè¿­ä»£æä¾›äº†å•è°ƒæ”¶æ•›(monotonic convergence)ä¿è¯ã€‚é€šè¿‡åœ¨å¤šç§å›¾åƒé‡å»º(image reconstruction)ä»»åŠ¡ä¸Šçš„å®éªŒï¼Œç ”ç©¶è€…è¯æ˜äº†è¯¥æ–¹æ³•åœ¨å¤„ç†ä¸å®Œæ•´æˆ–å—æŸè§‚æµ‹æ•°æ®æ—¶çš„æœ‰æ•ˆæ€§ã€‚è¯¥æ–¹æ³•æœ‰æ•ˆè§£å†³äº†æ‰©æ•£æ¨¡å‹ä½œä¸ºç”Ÿæˆå…ˆéªŒåœ¨å¤„ç†é«˜ç»´é€†å‘é—®é¢˜æ—¶é¢ä¸´çš„è®­ç»ƒæŒ‘æˆ˜ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.12691v3",
      "published_date": "2025-10-14 16:25:02 UTC",
      "updated_date": "2025-12-20 04:01:26 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:22:27.591271+00:00"
    },
    {
      "arxiv_id": "2510.12689v2",
      "title": "From Delegates to Trustees: How Optimizing for Long-Term Interests Shapes Bias and Alignment in LLM",
      "title_zh": "ä»ä»£ç†äººåˆ°å—æ‰˜äººï¼šå¤§è¯­è¨€æ¨¡å‹ä¸­é•¿æœŸåˆ©ç›Šä¼˜åŒ–å¯¹åè§ä¸å¯¹é½çš„å¡‘é€ ä½œç”¨",
      "authors": [
        "Suyash Fulay",
        "Jocelyn Zhu",
        "Michiel Bakker"
      ],
      "abstract": "Large language models (LLMs) have shown promising accuracy in predicting survey responses and policy preferences, which has increased interest in their potential to represent human interests in various domains. Most existing research has focused on \"behavioral cloning\", effectively evaluating how well models reproduce individuals' expressed preferences. Drawing on theories of political representation, we highlight an underexplored design trade-off: whether AI systems should act as delegates, mirroring expressed preferences, or as trustees, exercising judgment about what best serves an individual's interests. This trade-off is closely related to issues of LLM sycophancy, where models can encourage behavior or validate beliefs that may be aligned with a user's short-term preferences, but is detrimental to their long-term interests.\n  Through a series of experiments simulating votes on various policy issues in the U.S. context, we apply a temporal utility framework that weighs short and long-term interests (simulating a trustee role) and compare voting outcomes to behavior-cloning models (simulating a delegate). We find that trustee-style predictions weighted toward long-term interests produce policy decisions that align more closely with expert consensus on well-understood issues, but also show greater bias toward models' default stances on topics lacking clear agreement. These findings reveal a fundamental trade-off in designing AI systems to represent human interests. Delegate models better preserve user autonomy but may diverge from well-supported policy positions, while trustee models can promote welfare on well-understood issues yet risk paternalism and bias on subjective topics.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å¤§è¯­è¨€æ¨¡å‹(LLMs)åœ¨ä»£è¡¨äººç±»åˆ©ç›Šæ—¶çš„è§’è‰²è½¬å˜ï¼Œå³ä»å•çº¯æ¨¡ä»¿ç”¨æˆ·è¡¨è¾¾åå¥½çš„ä»£ç†äºº(Delegate)è½¬å‘å…·å¤‡åˆ¤æ–­åŠ›ã€æ—¨åœ¨æœåŠ¡é•¿æœŸåˆ©ç›Šçš„å—æ‰˜äºº(Trustee)ã€‚ä½œè€…æŒ‡å‡ºï¼Œç°æœ‰çš„è¡Œä¸ºå…‹éš†(Behavioral Cloning)æ–¹æ³•å¸¸å¯¼è‡´æ¨¡å‹å‡ºç°è¶‹ç‚é™„åŠ¿(Sycophancy)é—®é¢˜ï¼Œå³é€šè¿‡è¿åˆçŸ­æœŸåå¥½è€ŒæŸå®³ç”¨æˆ·çš„é•¿è¿œåˆ©ç›Šã€‚é€šè¿‡åœ¨ç¾å›½æ”¿ç­–æŠ•ç¥¨åœºæ™¯ä¸‹åº”ç”¨æ—¶é—´æ•ˆç”¨æ¡†æ¶(Temporal Utility Framework)ï¼Œç ”ç©¶å¯¹æ¯”äº†ä¾§é‡é•¿æœŸåˆ©ç›Šçš„å—æ‰˜äººæ¨¡å‹ä¸ä¼ ç»Ÿä»£ç†äººæ¨¡å‹çš„å·®å¼‚ã€‚å®éªŒå‘ç°ï¼Œå—æ‰˜äººæ¨¡å¼åœ¨å…±è¯†æ˜ç¡®çš„é—®é¢˜ä¸Šæ›´ç¬¦åˆä¸“å®¶å…±è¯†(Expert Consensus)ï¼Œä½†åœ¨ç¼ºä¹å…±è¯†çš„ä¸»è§‚è¯é¢˜ä¸Šåˆ™è¡¨ç°å‡ºå¯¹æ¨¡å‹é»˜è®¤ç«‹åœºçš„æ›´å¼ºåè§(Bias)ã€‚ç ”ç©¶æœ€ç»ˆæ­ç¤ºäº†AIç³»ç»Ÿè®¾è®¡çš„æ ¸å¿ƒæƒè¡¡ï¼šä»£ç†äººæ¨¡å‹èƒ½æ›´å¥½åœ°ä¿ç•™ç”¨æˆ·è‡ªä¸»æƒ(Autonomy)ï¼Œè€Œå—æ‰˜äººæ¨¡å‹è™½èƒ½ä¿ƒè¿›ç¦åˆ©ï¼Œå´åœ¨ä¸»è§‚é¢†åŸŸé¢ä¸´å®¶é•¿å¼ä½œé£å’Œå¼•å…¥æ¨¡å‹è‡ªèº«åè§çš„é£é™©ã€‚",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.12689v2",
      "published_date": "2025-10-14 16:24:19 UTC",
      "updated_date": "2025-11-16 16:36:44 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:22:27.079800+00:00"
    },
    {
      "arxiv_id": "2510.12680v1",
      "title": "Demystifying Hybrid Thinking: Can LLMs Truly Switch Between Think and No-Think?",
      "title_zh": "æ­ç§˜æ··åˆæ€ç»´ï¼šå¤§è¯­è¨€æ¨¡å‹èƒ½å¦åœ¨â€œæ€è€ƒâ€ä¸â€œéæ€è€ƒâ€æ¨¡å¼é—´å®ç°çœŸæ­£åˆ‡æ¢ï¼Ÿ",
      "authors": [
        "Shouren Wang",
        "Wang Yang",
        "Xianxuan Long",
        "Qifan Wang",
        "Vipin Chaudhary",
        "Xiaotian Han"
      ],
      "abstract": "Hybrid thinking enables LLMs to switch between reasoning and direct answering, offering a balance between efficiency and reasoning capability. Yet our experiments reveal that current hybrid thinking LLMs only achieve partial mode separation: reasoning behaviors often leak into the no-think mode. To understand and mitigate this, we analyze the factors influencing controllability and identify four that matter most: (1) larger data scale, (2) using think and no-think answers from different questions rather than the same question, (3) a moderate increase in no-think data number, and (4) a two-phase strategy that first trains reasoning ability and then applies hybrid think training. Building on these findings, we propose a practical recipe that, compared to standard training, can maintain accuracy in both modes while significantly reducing no-think output length (from $1085$ to $585$ on MATH500) and occurrences of reasoning-supportive tokens such as ``\\texttt{wait}'' (from $5917$ to $522$ on MATH500). Our findings highlight the limitations of current hybrid thinking and offer directions for strengthening its controllability.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å¤§å‹è¯­è¨€æ¨¡å‹(LLMs)ä¸­çš„æ··åˆæ€ç»´(Hybrid Thinking)æœºåˆ¶ï¼Œæ—¨åœ¨ä½¿æ¨¡å‹èƒ½å¤Ÿåœ¨æ¨ç†(Think)å’Œç›´æ¥å›ç­”(No-Think)æ¨¡å¼ä¹‹é—´å¹³è¡¡æ•ˆç‡ä¸æ¨ç†èƒ½åŠ›ã€‚å®éªŒæ­ç¤ºäº†å½“å‰æ¨¡å‹ä»…å®ç°äº†éƒ¨åˆ†æ¨¡å¼åˆ†ç¦»ï¼Œæ¨ç†è¡Œä¸ºå¸¸ä¼šæ³„éœ²åˆ°ç›´æ¥å›ç­”æ¨¡å¼ä¸­ï¼Œä»è€Œé™åˆ¶äº†å…¶å¯æ§æ€§ã€‚é€šè¿‡æ·±å…¥åˆ†æï¼Œç ”ç©¶è€…è¯†åˆ«å‡ºæ•°æ®è§„æ¨¡ã€æ•°æ®å¯¹æ¥æºã€æ•°æ®é…æ¯”åŠå…ˆæ¨ç†åæ··åˆçš„ä¸¤é˜¶æ®µè®­ç»ƒç­–ç•¥æ˜¯å½±å“åˆ‡æ¢æ•ˆæœçš„å››ä¸ªå…³é”®å› ç´ ã€‚åŸºäºæ­¤ï¼Œè®ºæ–‡æå‡ºäº†ä¸€å¥—ä¼˜åŒ–æ–¹æ¡ˆï¼Œåœ¨ä¿æŒä¸¤ç§æ¨¡å¼å‡†ç¡®ç‡çš„å‰æä¸‹ï¼Œå°†MATH500æµ‹è¯•é›†ä¸­çš„ç›´æ¥å›ç­”é•¿åº¦æ˜¾è‘—ç¼©çŸ­ï¼Œå¹¶å¤§å¹…å‡å°‘äº†å¦‚â€œwaitâ€ç­‰æ¨ç†æ”¯æŒæ ‡è®°çš„å‡ºç°ã€‚è¯¥ç ”ç©¶æ­ç¤ºäº†ç°æœ‰æ··åˆæ€ç»´æŠ€æœ¯çš„å±€é™æ€§ï¼Œå¹¶ä¸ºæå‡LLMsåœ¨ä¸åŒä»»åŠ¡æ¨¡å¼é—´çš„å¯æ§åˆ‡æ¢æä¾›äº†å®ç”¨çš„æ”¹è¿›è·¯å¾„ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "10 pages, 6 figures",
      "pdf_url": "https://arxiv.org/pdf/2510.12680v1",
      "published_date": "2025-10-14 16:19:44 UTC",
      "updated_date": "2025-10-14 16:19:44 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:22:23.890161+00:00"
    },
    {
      "arxiv_id": "2510.12659v1",
      "title": "SG-XDEAT: Sparsity-Guided Cross-Dimensional and Cross-Encoding Attention with Target-Aware Conditioning in Tabular Learning",
      "title_zh": "SG-XDEATï¼šè¡¨æ ¼å­¦ä¹ ä¸­èåˆç›®æ ‡æ„ŸçŸ¥è°ƒèŠ‚çš„ç¨€ç–å¼•å¯¼è·¨ç»´åº¦ä¸è·¨ç¼–ç æ³¨æ„åŠ›æœºåˆ¶",
      "authors": [
        "Chih-Chuan Cheng",
        "Yi-Ju Tseng"
      ],
      "abstract": "We propose SG-XDEAT (Sparsity-Guided Cross Dimensional and Cross-Encoding Attention with Target Aware Conditioning), a novel framework designed for supervised learning on tabular data. At its core, SG-XDEAT employs a dual-stream encoder that decomposes each input feature into two parallel representations: a raw value stream and a target-conditioned (label-aware) stream. These dual representations are then propagated through a hierarchical stack of attention-based modules. SG-XDEAT integrates three key components: (i) Cross-Dimensional self-attention, which captures intra-view dependencies among features within each stream; (ii) Cross-Encoding self-attention, which enables bidirectional interaction between raw and target-aware representations; and (iii) an Adaptive Sparse Self-Attention (ASSA) mechanism, which dynamically suppresses low-utility tokens by driving their attention weights toward zero--thereby mitigating the impact of noise. Empirical results on multiple public benchmarks show consistent gains over strong baselines, confirming that jointly modeling raw and target-aware views--while adaptively filtering noise--yields a more robust deep tabular learner.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† SG-XDEAT (Sparsity-Guided Cross Dimensional and Cross-Encoding Attention with Target Aware Conditioning)ï¼Œä¸€ç§ä¸“ä¸ºè¡¨æ ¼æ•°æ®ç›‘ç£å­¦ä¹ è®¾è®¡çš„æ–°å‹æ¡†æ¶ã€‚å…¶æ ¸å¿ƒé‡‡ç”¨äº†åŒæµç¼–ç å™¨ (dual-stream encoder)ï¼Œå°†è¾“å…¥ç‰¹å¾åˆ†è§£ä¸ºåŸå§‹å€¼æµ (raw value stream) å’Œç›®æ ‡æ¡ä»¶æµ (target-conditioned stream) ä¸¤ä¸ªå¹¶è¡Œè¡¨ç¤ºã€‚è¯¥æ¡†æ¶æ•´åˆäº†è·¨ç»´åº¦è‡ªæ³¨æ„åŠ› (Cross-Dimensional self-attention) å’Œè·¨ç¼–ç è‡ªæ³¨æ„åŠ› (Cross-Encoding self-attention)ï¼Œåˆ†åˆ«ç”¨äºæ•æ‰ç‰¹å¾å†…éƒ¨ä¾èµ–ä»¥åŠå®ç°ä¸åŒè¡¨ç¤ºé—´çš„åŒå‘äº¤äº’ã€‚æ­¤å¤–ï¼Œç ”ç©¶å¼•å…¥äº†è‡ªé€‚åº”ç¨€ç–è‡ªæ³¨æ„åŠ› (Adaptive Sparse Self-Attention, ASSA) æœºåˆ¶ï¼Œé€šè¿‡åŠ¨æ€æŠ‘åˆ¶ä½æ•ˆä»¤ç‰Œçš„æƒé‡æ¥æœ‰æ•ˆå‡è½»å™ªå£°å¹²æ‰°ã€‚å®éªŒç»“æœåœ¨å¤šä¸ªå…¬å…±åŸºå‡†æµ‹è¯•ä¸­å±•ç°äº†ç›¸è¾ƒäºå¼ºåŸºçº¿æ¨¡å‹çš„æŒç»­æ€§èƒ½æå‡ã€‚è¿™è¯æ˜äº†é€šè¿‡è”åˆå»ºæ¨¡åŸå§‹è§†å›¾ä¸ç›®æ ‡æ„ŸçŸ¥è§†å›¾å¹¶è¿›è¡Œè‡ªé€‚åº”å™ªå£°è¿‡æ»¤ï¼Œå¯ä»¥æ„å»ºå‡ºæ›´å…·é²æ£’æ€§çš„æ·±åº¦è¡¨æ ¼å­¦ä¹ å™¨ (deep tabular learner)ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.12659v1",
      "published_date": "2025-10-14 15:56:40 UTC",
      "updated_date": "2025-10-14 15:56:40 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:22:40.267617+00:00"
    },
    {
      "arxiv_id": "2510.12643v1",
      "title": "Reasoning Pattern Matters: Learning to Reason without Human Rationales",
      "title_zh": "æ¨ç†æ¨¡å¼è‡³å…³é‡è¦ï¼šæ— éœ€äººå·¥é€»è¾‘æ ‡æ³¨çš„å­¦ä¹ æ¨ç†",
      "authors": [
        "Chaoxu Pang",
        "Yixuan Cao",
        "Ping Luo"
      ],
      "abstract": "Large Language Models (LLMs) have demonstrated remarkable reasoning capabilities under the widely adopted SFT+RLVR paradigm, which first performs Supervised Fine-Tuning (SFT) on human-annotated reasoning trajectories (rationales) to establish initial reasoning behaviors, then applies Reinforcement Learning with Verifiable Rewards (RLVR) to optimize the model using verifiable signals without golden rationales. However, annotating high-quality rationales for the SFT stage remains prohibitively expensive. This paper investigates when and how rationale annotation costs can be substantially reduced without compromising reasoning performance. We identify a broad class of problems, termed patterned reasoning tasks, where reasoning follows a fixed, procedural strategy consistent across instances. Although instances vary in content such as domain knowledge, factual information, or numeric values, the solution derives from applying a shared reasoning pattern. We argue that the success of SFT+RLVR on such tasks primarily stems from its ability to enable models to internalize these reasoning patterns. Using numerical semantic matching as a representative task, we provide both causal and behavioral evidence showing that reasoning patterns rather than the quantity or quality of rationales are the key determinant of performance. Building on these insights, we propose Pattern-Aware LLMs as Rationale AnnOtators (PARO), a simple yet effective framework that enables LLMs to generate rationales aligned with task-specific reasoning patterns without requiring human rationale annotations. Experiments show that PARO-generated rationales achieve comparable SFT+RLVR performance to human rationales that are 10 times larger. These results suggest that large-scale human rationale annotations can be replaced with LLM-based automatic annotations requiring only limited human supervision over reasoning patterns.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†åœ¨å¤§è¯­è¨€æ¨¡å‹ (LLMs) çš„ SFT+RLVR èŒƒå¼ä¸‹ï¼Œå¦‚ä½•æ˜¾è‘—é™ä½äººå·¥æ ‡æ³¨æ¨ç†è½¨è¿¹ (Rationales) çš„é«˜æ˜‚æˆæœ¬ã€‚ä½œè€…è¯†åˆ«å‡ºä¸€ç±»æ¨¡å¼åŒ–æ¨ç†ä»»åŠ¡ (Patterned Reasoning Tasks)ï¼Œå¹¶æä¾›è¯æ®è¡¨æ˜æ¨ç†æ¨¡å¼ (Reasoning Patterns) è€Œéæ ‡æ³¨çš„æ•°é‡æˆ–è´¨é‡æ‰æ˜¯å†³å®šæ¨¡å‹æ€§èƒ½çš„å…³é”®å› ç´ ã€‚åŸºäºæ­¤æ´å¯Ÿï¼Œç ”ç©¶æå‡ºäº† PARO (Pattern-Aware LLMs as Rationale AnnOtators) æ¡†æ¶ï¼Œé€šè¿‡è®©æ¨¡å‹è‡ªåŠ¨ç”Ÿæˆä¸ä»»åŠ¡ç‰¹å®šæ¨¡å¼å¯¹é½çš„æ¨ç†è½¨è¿¹ï¼Œæ¶ˆé™¤äº†å¯¹äººå·¥ Rationales æ ‡æ³¨çš„ä¾èµ–ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒPARO ç”Ÿæˆçš„æ ‡æ³¨åœ¨ SFT+RLVR æ€§èƒ½ä¸Šå¯åª²ç¾è§„æ¨¡å¤§å…¶ 10 å€çš„äººå·¥æ ‡æ³¨æ•°æ®ã€‚è¯¥ç ”ç©¶è¯æ˜äº†å¤§è§„æ¨¡äººå·¥æ¨ç†æ ‡æ³¨å¯ä»¥è¢«ä»…éœ€æœ‰é™ç›‘ç£çš„è‡ªåŠ¨æ ‡æ³¨æ¡†æ¶æ‰€å–ä»£ï¼Œä¸ºé«˜æ•ˆæå‡æ¨¡å‹æ¨ç†èƒ½åŠ›æä¾›äº†æ–°è·¯å¾„ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Submitted to Frontiers of Computer Science",
      "pdf_url": "https://arxiv.org/pdf/2510.12643v1",
      "published_date": "2025-10-14 15:34:38 UTC",
      "updated_date": "2025-10-14 15:34:38 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:22:38.673137+00:00"
    },
    {
      "arxiv_id": "2510.12642v1",
      "title": "Aixel: A Unified, Adaptive and Extensible System for AI-powered Data Analysis",
      "title_zh": "Aixelï¼šé¢å‘ AI é©±åŠ¨æ•°æ®åˆ†æçš„ç»Ÿä¸€ã€è‡ªé€‚åº”ä¸”å¯æ‰©å±•ç³»ç»Ÿ",
      "authors": [
        "Meihui Zhang",
        "Liming Wang",
        "Chi Zhang",
        "Zhaojing Luo"
      ],
      "abstract": "A growing trend in modern data analysis is the integration of data management with learning, guided by accuracy, latency, and cost requirements. In practice, applications draw data of different formats from many sources. In the meanwhile, the objectives and budgets change over time. Existing systems handle these applications across databases, analysis libraries, and tuning services. Such fragmentation leads to complex user interaction, limited adaptability, suboptimal performance, and poor extensibility across components. To address these challenges, we present Aixel, a unified, adaptive, and extensible system for AI-powered data analysis. The system organizes work across four layers: application, task, model, and data. The task layer provides a declarative interface to capture user intent, which is parsed into an executable operator plan. An optimizer compiles and schedules this plan to meet specified goals in accuracy, latency, and cost. The task layer coordinates the execution of data and model operators, with built-in support for reuse and caching to improve efficiency. The model layer offers versioned storage for index, metadata, tensors, and model artifacts. It supports adaptive construction, task-aligned drift detection, and safe updates that reuse shared components. The data layer provides unified data management capabilities, including indexing, constraint-aware discovery, task-aligned selection, and comprehensive feature management. With the above designed layers, Aixel delivers a user friendly, adaptive, efficient, and extensible system.",
      "tldr_zh": "æœ¬ç ”ç©¶æå‡ºäº† Aixelï¼Œè¿™æ˜¯ä¸€ä¸ªç»Ÿä¸€ã€è‡ªé€‚åº”ä¸”å¯æ‰©å±•çš„ AI-powered Data Analysis ç³»ç»Ÿï¼Œæ—¨åœ¨è§£å†³ç°æœ‰æ•°æ®åˆ†æç³»ç»Ÿåœ¨æ•°æ®åº“ã€åˆ†æåº“å’Œè°ƒä¼˜æœåŠ¡ä¹‹é—´ç¢ç‰‡åŒ–å¯¼è‡´çš„äº¤äº’å¤æ‚ã€æ€§èƒ½æ¬ ä½³åŠæ‰©å±•æ€§å·®ç­‰é—®é¢˜ã€‚è¯¥ç³»ç»Ÿé‡‡ç”¨ç”± Applicationã€Taskã€Model å’Œ Data ç»„æˆçš„å››å±‚æ¶æ„ï¼Œé€šè¿‡ Task å±‚çš„å£°æ˜å¼æ¥å£ï¼ˆDeclarative Interfaceï¼‰æ•æ‰ç”¨æˆ·æ„å›¾å¹¶ç”Ÿæˆå—å‡†ç¡®ç‡ã€å»¶è¿Ÿå’Œæˆæœ¬çº¦æŸä¼˜åŒ–çš„ç®—å­è®¡åˆ’ï¼ˆOperator Planï¼‰ã€‚Model å±‚æä¾›ç‰ˆæœ¬åŒ–å­˜å‚¨ï¼Œæ”¯æŒè‡ªé€‚åº”æ„å»ºã€ä»»åŠ¡å¯¹é½çš„æ¼‚ç§»æ£€æµ‹ï¼ˆDrift Detectionï¼‰ä»¥åŠç»„ä»¶é‡ç”¨ã€‚Data å±‚åˆ™å®ç°äº†ç»Ÿä¸€çš„æ•°æ®ç®¡ç†ï¼Œæ¶µç›–ç´¢å¼•ã€çº¦æŸæ„ŸçŸ¥å‘ç°åŠå…¨é¢çš„ç‰¹å¾ç®¡ç†ï¼ˆFeature Managementï¼‰ã€‚é€šè¿‡å±‚çº§é—´çš„ååŒè®¾è®¡ä¸å†…ç½®çš„é‡ç”¨åŠç¼“å­˜æœºåˆ¶ï¼ŒAixel ä¸ºç°ä»£æ•°æ®åˆ†ææä¾›äº†ä¸€ä¸ªé«˜æ•ˆã€è‡ªé€‚åº”ä¸”ç”¨æˆ·å‹å¥½çš„é›†æˆå¹³å°ã€‚",
      "categories": [
        "cs.DB",
        "cs.AI"
      ],
      "primary_category": "cs.DB",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.12642v1",
      "published_date": "2025-10-14 15:34:35 UTC",
      "updated_date": "2025-10-14 15:34:35 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:22:38.395548+00:00"
    },
    {
      "arxiv_id": "2510.16007v1",
      "title": "Layer-Aware Influence for Online Data Valuation Estimation",
      "title_zh": "é¢å‘åœ¨çº¿æ•°æ®ä»·å€¼è¯„ä¼°çš„å±‚æ„ŸçŸ¥å½±å“åŠ›ä¼°è®¡",
      "authors": [
        "Ziao Yang",
        "Longbo Huang",
        "Hongfu Liu"
      ],
      "abstract": "Data-centric learning emphasizes curating high-quality training samples to boost performance rather than designing new architectures. A central problem is to estimate the influence of training sample efficiently. Prior studies largely focus on static influence measured on a converged model, overlooking how data valuation dynamically changes during optimization. This omission neglects the dynamic nature of sample influence during optimization, especially in deep models. To address the computational burden of frequent influence estimation, we develop a layer-aware online estimator that requires only loss-to-output gradients. This design avoids parameter-level and full-network gradients while preserving ranking fidelity. Extensive experiments across LLM pretraining, fine-tuning, and image classification show our method improves accuracy with substantially lower time and memory cost, making dynamic data curation efficient and scalable in practice.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†åœ¨ä»¥æ•°æ®ä¸ºä¸­å¿ƒçš„å­¦ä¹ ä¸­å¦‚ä½•é«˜æ•ˆä¼°ç®—è®­ç»ƒæ ·æœ¬çš„å½±å“åŠ›ï¼Œé’ˆå¯¹ç°æœ‰ç ”ç©¶å¤§å¤šå…³æ³¨æ”¶æ•›æ¨¡å‹çš„é™æ€å½±å“åŠ›è€Œå¿½è§†ä¼˜åŒ–è¿‡ç¨‹ä¸­åŠ¨æ€å˜åŒ–çš„å±€é™æ€§ï¼Œæå‡ºäº†ä¸€ç§åä¸ºLayer-Aware Influenceçš„åœ¨çº¿ä¼°ç®—å™¨ã€‚è¯¥æ–¹æ³•é€šè¿‡ä»…åˆ©ç”¨æŸå¤±å¯¹è¾“å‡ºçš„æ¢¯åº¦(loss-to-output gradients)æ¥è¯„ä¼°æ•°æ®ä»·å€¼ï¼ŒæˆåŠŸé¿å…äº†å¤æ‚çš„å‚æ•°çº§å’Œå…¨ç½‘ç»œæ¢¯åº¦è®¡ç®—ï¼ŒåŒæ—¶ä¿æŒäº†æ ·æœ¬æ’åºçš„å¿ å®åº¦ã€‚åœ¨LLMé¢„è®­ç»ƒã€å¾®è°ƒä»¥åŠå›¾åƒåˆ†ç±»ç­‰å¤šç§åœºæ™¯ä¸‹çš„å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿä»¥æ˜¾è‘—æ›´ä½çš„æ—¶é—´å’Œå†…å­˜å¼€é”€æå‡æ¨¡å‹å‡†ç¡®æ€§ã€‚è¿™ç§å±‚æ„ŸçŸ¥çš„æ¢¯åº¦è®¾è®¡ä¸ºåœ¨å¤§è§„æ¨¡å®è·µä¸­å®ç°é«˜æ•ˆä¸”å¯æ‰©å±•çš„åŠ¨æ€æ•°æ®ç­›é€‰(dynamic data curation)æä¾›äº†å¯è¡Œçš„æŠ€æœ¯è·¯å¾„ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.16007v1",
      "published_date": "2025-10-14 15:34:22 UTC",
      "updated_date": "2025-10-14 15:34:22 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:22:40.780177+00:00"
    },
    {
      "arxiv_id": "2510.12635v2",
      "title": "Memory as Action: Autonomous Context Curation for Long-Horizon Agentic Tasks",
      "title_zh": "è®°å¿†å³åŠ¨ä½œï¼šé¢å‘é•¿ç¨‹æ™ºèƒ½ä½“ä»»åŠ¡çš„è‡ªä¸»ä¸Šä¸‹æ–‡ç»´æŠ¤",
      "authors": [
        "Yuxiang Zhang",
        "Jiangming Shu",
        "Ye Ma",
        "Xueyuan Lin",
        "Shangxi Wu",
        "Jitao Sang"
      ],
      "abstract": "Long-context Large Language Models, despite their expanded capacity, require careful working memory management to mitigate attention dilution during long-horizon tasks. Yet existing approaches rely on external mechanisms that lack awareness of the agent's reasoning state, leading to suboptimal decisions. We propose Memory-as-Action (MemAct), a framework that treats working memory management as learnable policy actions. By formulating context management as in-place editing operations (deletion, insertion), MemAct enables joint optimization of information retention and task performance through end-to-end reinforcement learning. To address the computational challenges of dynamic context updates, we introduce Dynamic Context Policy Optimization, which restores training efficiency without compromising reasoning integrity. Experiments show that MemAct-RL-14B matches the accuracy of models $16\\times$ larger while reducing average context length by 51\\%, with learned strategies that adapt to model capabilities and generalize across task complexities.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹é•¿ä¸Šä¸‹æ–‡Large Language Modelsåœ¨å¤„ç†é•¿æ—¶ç¨‹ä»»åŠ¡æ—¶é¢ä¸´çš„æ³¨æ„åŠ›ç¨€é‡Šé—®é¢˜ï¼ŒæŒ‡å‡ºå½“å‰å¤–éƒ¨ç®¡ç†æœºåˆ¶å› ç¼ºä¹æ¨ç†çŠ¶æ€æ„ŸçŸ¥è€Œå¯¼è‡´å†³ç­–æ¬ ä½³ã€‚ä¸ºæ­¤æå‡ºçš„Memory-as-Action (MemAct)æ¡†æ¶å°†å·¥ä½œå†…å­˜ç®¡ç†è½¬åŒ–ä¸ºå¯å­¦ä¹ çš„ç­–ç•¥åŠ¨ä½œï¼Œé€šè¿‡åŸåœ°ç¼–è¾‘ï¼ˆå¦‚åˆ é™¤å’Œæ’å…¥ï¼‰å¹¶ç»“åˆç«¯åˆ°ç«¯Reinforcement Learningï¼Œå®ç°äº†ä¿¡æ¯ç•™å­˜ä¸ä»»åŠ¡æ€§èƒ½çš„åŒæ­¥ä¼˜åŒ–ã€‚ä¸ºè§£å†³åŠ¨æ€æ›´æ–°å¸¦æ¥çš„è®¡ç®—æŒ‘æˆ˜ï¼Œç ”ç©¶å¼•å…¥äº†Dynamic Context Policy Optimizationï¼Œåœ¨ä¿è¯æ¨ç†å®Œæ•´æ€§çš„åŒæ—¶æ˜¾è‘—æå‡äº†è®­ç»ƒæ•ˆç‡ã€‚å®éªŒè¡¨æ˜ï¼ŒMemAct-RL-14Båœ¨å¹³å‡ä¸Šä¸‹æ–‡é•¿åº¦ç¼©å‡51%çš„æƒ…å†µä¸‹ï¼Œå‡†ç¡®ç‡å¯åª²ç¾è§„æ¨¡å¤§å…¶16å€çš„æ¨¡å‹ã€‚è¯¥æ¡†æ¶ç”Ÿæˆçš„ç­–ç•¥èƒ½æ ¹æ®æ¨¡å‹èƒ½åŠ›è‡ªé€‚åº”è°ƒæ•´ï¼Œå¹¶å±•ç°å‡ºè·¨ä»»åŠ¡å¤æ‚åº¦çš„æ³›åŒ–ä¼˜åŠ¿ï¼Œä¸ºè‡ªä¸»æ™ºèƒ½ä½“çš„é•¿æ—¶ç¨‹ä»»åŠ¡æä¾›äº†é«˜æ•ˆçš„ä¸Šä¸‹æ–‡æ•´ç†æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.12635v2",
      "published_date": "2025-10-14 15:29:57 UTC",
      "updated_date": "2026-01-10 01:44:56 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:23:07.477458+00:00"
    },
    {
      "arxiv_id": "2510.12633v1",
      "title": "Laminar: A Scalable Asynchronous RL Post-Training Framework",
      "title_zh": "Laminarï¼šé«˜æ‰©å±•æ€§å¼‚æ­¥å¼ºåŒ–å­¦ä¹ åè®­ç»ƒæ¡†æ¶",
      "authors": [
        "Guangming Sheng",
        "Yuxuan Tong",
        "Borui Wan",
        "Wang Zhang",
        "Chaobo Jia",
        "Xibin Wu",
        "Yuqi Wu",
        "Xiang Li",
        "Chi Zhang",
        "Yanghua Peng",
        "Haibin Lin",
        "Xin Liu",
        "Chuan Wu"
      ],
      "abstract": "Reinforcement learning (RL) post-training for Large Language Models (LLMs) is now scaling to large clusters and running for extended durations to enhance model reasoning performance. However, the scalability of existing RL frameworks is limited, as extreme long-tail skewness in RL trajectory generation causes severe GPU underutilization. Current asynchronous RL systems attempt to mitigate this, but they rely on global weight synchronization between the actor and all rollouts, which creates a rigid model update schedule. This global synchronization is ill-suited for the highly skewed and evolving distribution of trajectory generation latency in RL training, crippling training efficiency. Our key insight is that efficient scaling requires breaking this lockstep through trajectory-level asynchrony, which generates and consumes each trajectory independently. We propose Laminar, a scalable and robust RL post-training system built on a fully decoupled architecture. First, we replace global updates with a tier of relay workers acting as a distributed parameter service. This enables asynchronous and fine-grained weight synchronization, allowing rollouts to pull the latest weight anytime without stalling the actor's training loop. Second, a dynamic repack mechanism consolidates long-tail trajectories onto a few dedicated rollouts, maximizing generation throughput. The fully decoupled design also isolates failures, ensuring robustness for long-running jobs. Our evaluation on a 1024-GPU cluster shows that Laminar achieves up to 5.48$\\times$ training throughput speedup over state-of-the-art systems, while reducing model convergence time.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§è¯­è¨€æ¨¡å‹(LLMs)å¼ºåŒ–å­¦ä¹ (Reinforcement Learning, RL)åæœŸè®­ç»ƒåœ¨æ‰©å±•è‡³å¤§è§„æ¨¡é›†ç¾¤æ—¶ï¼Œå› è½¨è¿¹ç”Ÿæˆçš„é•¿å°¾åˆ†å¸ƒå¯¼è‡´GPUåˆ©ç”¨ç‡ä½åŠè®­ç»ƒæ•ˆç‡ç“¶é¢ˆï¼Œæå‡ºäº†Laminarè¿™ä¸€å¯æ‰©å±•çš„å¼‚æ­¥RLæ¡†æ¶ã€‚Laminarçš„æ ¸å¿ƒåˆ›æ–°åœ¨äºå®ç°äº†è½¨è¿¹çº§å¼‚æ­¥(Trajectory-level Asynchrony)ï¼Œé€šè¿‡å®Œå…¨è§£è€¦çš„æ¶æ„è®©æ¯æ¡è½¨è¿¹çš„ç”Ÿæˆä¸æ¶ˆè€—ç‹¬ç«‹è¿›è¡Œã€‚è¯¥ç³»ç»Ÿå¼•å…¥äº†ä¸­ç»§å·¥äºº(Relay Workers)å±‚ä½œä¸ºåˆ†å¸ƒå¼å‚æ•°æœåŠ¡ï¼Œæ”¯æŒç»†ç²’åº¦çš„å¼‚æ­¥æƒé‡åŒæ­¥ï¼Œä»è€Œæ¶ˆé™¤äº†ä¼ ç»Ÿå…¨å±€åŒæ­¥å¯¹è®­ç»ƒå¾ªç¯çš„é™åˆ¶ã€‚æ­¤å¤–ï¼ŒLaminaré‡‡ç”¨åŠ¨æ€é‡ç»„(Dynamic Repack)æœºåˆ¶ä¼˜åŒ–é•¿å°¾è½¨è¿¹å¤„ç†ï¼Œåœ¨æå‡ç”Ÿæˆååé‡çš„åŒæ—¶ä¹Ÿé€šè¿‡æ•…éšœéš”ç¦»å¢å¼ºäº†é•¿å‘¨æœŸè¿è¡Œä¸‹çš„ç³»ç»Ÿé²æ£’æ€§ã€‚åœ¨1024å—GPUé›†ç¾¤ä¸Šçš„è¯„ä¼°è¡¨æ˜ï¼ŒLaminarç›¸æ¯”ç°æœ‰æœ€å…ˆè¿›ç³»ç»Ÿå®ç°äº†é«˜è¾¾5.48å€çš„è®­ç»ƒååé‡æå‡ï¼Œå¹¶æœ‰æ•ˆç¼©çŸ­äº†æ¨¡å‹çš„æ”¶æ•›æ—¶é—´ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DC"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.12633v1",
      "published_date": "2025-10-14 15:29:14 UTC",
      "updated_date": "2025-10-14 15:29:14 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:22:56.490892+00:00"
    },
    {
      "arxiv_id": "2510.12630v1",
      "title": "Designing Tools with Control Confidence",
      "title_zh": "åŸºäºæ§åˆ¶ç½®ä¿¡åº¦çš„å·¥å…·è®¾è®¡",
      "authors": [
        "Ajith Anil Meera",
        "Abian Torres",
        "Pablo Lanillos"
      ],
      "abstract": "Prehistoric humans invented stone tools for specialized tasks by not just maximizing the tool's immediate goal-completion accuracy, but also increasing their confidence in the tool for later use under similar settings. This factor contributed to the increased robustness of the tool, i.e., the least performance deviations under environmental uncertainties. However, the current autonomous tool design frameworks solely rely on performance optimization, without considering the agent's confidence in tool use for repeated use. Here, we take a step towards filling this gap by i) defining an optimization framework for task-conditioned autonomous hand tool design for robots, where ii) we introduce a neuro-inspired control confidence term into the optimization routine that helps the agent to design tools with higher robustness. Through rigorous simulations using a robotic arm, we show that tools designed with control confidence as the objective function are more robust to environmental uncertainties during tool use than a pure accuracy-driven objective. We further show that adding control confidence to the objective function for tool design provides a balance between the robustness and goal accuracy of the designed tools under control perturbations. Finally, we show that our CMAES-based evolutionary optimization strategy for autonomous tool design outperforms other state-of-the-art optimizers by designing the optimal tool within the fewest iterations. Code: https://github.com/ajitham123/Tool_design_control_confidence.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹æœºå™¨äººè‡ªä¸»å·¥å…·è®¾è®¡ï¼Œæå‡ºäº†ä¸€ç§æ•´åˆControl Confidenceï¼ˆæ§åˆ¶ä¿¡å¿ƒï¼‰çš„ä¼˜åŒ–æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³ç°æœ‰æ–¹æ³•ä»…å…³æ³¨å³æ—¶ä»»åŠ¡å‡†ç¡®æ€§è€Œå¿½è§†å·¥å…·åœ¨ç¯å¢ƒä¸ç¡®å®šä¸‹é²æ£’æ€§çš„é—®é¢˜ã€‚ç ”ç©¶å›¢é˜Ÿåœ¨ä¼˜åŒ–ç¨‹åºä¸­å¼•å…¥äº†å—ç¥ç»ç§‘å­¦å¯å‘çš„Control Confidenceé¡¹ï¼Œå¸®åŠ©æœºå™¨äººè®¾è®¡å‡ºåœ¨é¢å¯¹å¹²æ‰°æ—¶æ›´å…·ç¨³å®šæ€§çš„æ‰‹æŒå·¥å…·ã€‚é€šè¿‡æœºæ¢°è‡‚æ¨¡æ‹Ÿå®éªŒè¯æ˜ï¼Œä»¥æ§åˆ¶ä¿¡å¿ƒä¸ºç›®æ ‡çš„å·¥å…·è®¾è®¡åœ¨é¢å¯¹ç¯å¢ƒæ³¢åŠ¨æ—¶æ¯”å•çº¯è¿½æ±‚å‡†ç¡®åº¦çš„è®¾è®¡æ›´å…·é²æ£’æ€§ï¼Œå¹¶èƒ½å®ç°å‡†ç¡®æ€§ä¸é²æ£’æ€§çš„æœ‰æ•ˆå¹³è¡¡ã€‚æ­¤å¤–ï¼Œå®éªŒè¡¨æ˜åŸºäºCMAESï¼ˆåæ–¹å·®çŸ©é˜µè‡ªé€‚åº”è¿›åŒ–ç­–ç•¥ï¼‰çš„è¿›åŒ–ä¼˜åŒ–æ–¹æ³•åœ¨æ•ˆç‡ä¸Šä¼˜äºå…¶ä»–SOTAï¼ˆå½“å‰æœ€ä½³ï¼‰ä¼˜åŒ–å™¨ï¼Œèƒ½å¤Ÿä»¥æ›´å°‘çš„è¿­ä»£æ¬¡æ•°è¾¾æˆæœ€ä¼˜å·¥å…·è®¾è®¡ã€‚è¯¥æˆæœä¸ºå¼€å‘åœ¨å¤æ‚ç¯å¢ƒä¸‹å…·å¤‡é«˜åº¦å¯é æ€§çš„æœºå™¨äººå·¥å…·è®¾è®¡ç³»ç»Ÿæä¾›äº†é‡è¦å‚è€ƒã€‚",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.12630v1",
      "published_date": "2025-10-14 15:27:27 UTC",
      "updated_date": "2025-10-14 15:27:27 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:22:58.393138+00:00"
    },
    {
      "arxiv_id": "2510.12624v1",
      "title": "Learning-To-Measure: In-context Active Feature Acquisition",
      "title_zh": "Learning-To-Measureï¼šä¸Šä¸‹æ–‡ä¸»åŠ¨ç‰¹å¾è·å–",
      "authors": [
        "Yuta Kobayashi",
        "Zilin Jing",
        "Jiayu Yao",
        "Hongseok Namkoong",
        "Shalmali Joshi"
      ],
      "abstract": "Active feature acquisition (AFA) is a sequential decision-making problem where the goal is to improve model performance for test instances by adaptively selecting which features to acquire. In practice, AFA methods often learn from retrospective data with systematic missingness in the features and limited task-specific labels. Most prior work addresses acquisition for a single predetermined task, limiting scalability. To address this limitation, we formalize the meta-AFA problem, where the goal is to learn acquisition policies across various tasks. We introduce Learning-to-Measure (L2M), which consists of i) reliable uncertainty quantification over unseen tasks, and ii) an uncertainty-guided greedy feature acquisition agent that maximizes conditional mutual information. We demonstrate a sequence-modeling or autoregressive pre-training approach that underpins reliable uncertainty quantification for tasks with arbitrary missingness. L2M operates directly on datasets with retrospective missingness and performs the meta-AFA task in-context, eliminating per-task retraining. Across synthetic and real-world tabular benchmarks, L2M matches or surpasses task-specific baselines, particularly under scarce labels and high missingness.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ä¸»åŠ¨ç‰¹å¾é‡‡é›†(Active feature acquisition, AFA)åœ¨å¤šä»»åŠ¡æ‰©å±•æ€§ä¸Šçš„ä¸è¶³ï¼Œå½¢å¼åŒ–äº†å…ƒä¸»åŠ¨ç‰¹å¾é‡‡é›†(meta-AFA)é—®é¢˜å¹¶æå‡ºäº†Learning-to-Measure (L2M)æ¡†æ¶ã€‚L2Mé€šè¿‡è‡ªå›å½’é¢„è®­ç»ƒå®ç°å¯¹æœªçŸ¥ä»»åŠ¡å¯é çš„ä¸ç¡®å®šæ€§é‡åŒ–(uncertainty quantification)ï¼Œå¹¶ç»“åˆä¸ç¡®å®šæ€§å¼•å¯¼çš„è´ªå©ªé‡‡é›†æ™ºèƒ½ä½“ä»¥æœ€å¤§åŒ–æ¡ä»¶äº’ä¿¡æ¯(conditional mutual information)ã€‚è¯¥æ¡†æ¶æ”¯æŒåœ¨å­˜åœ¨å›é¡¾æ€§ç¼ºå¤±(retrospective missingness)çš„æ•°æ®é›†ä¸Šç›´æ¥è¿è¡Œï¼Œåˆ©ç”¨ä¸Šä¸‹æ–‡å­¦ä¹ (in-context)èƒ½åŠ›æ‰§è¡Œé‡‡é›†ä»»åŠ¡ï¼Œæœ‰æ•ˆé¿å…äº†ç¹ççš„é’ˆå¯¹æ€§é‡è®­ç»ƒã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒL2Måœ¨å¤šä¸ªåˆæˆåŠçœŸå®ä¸–ç•Œè¡¨æ ¼åŸºå‡†æµ‹è¯•ä¸­è¡¨ç°ä¼˜å¼‚ï¼Œå°¤å…¶åœ¨æ ‡ç­¾ç¨€ç¼ºå’Œé«˜ç¼ºå¤±ç‡çš„ä¸¥è‹›åœºæ™¯ä¸‹ï¼Œå…¶æ€§èƒ½æ˜¾è‘—åŒ¹é…æˆ–è¶…è¶Šäº†ä¼ ç»Ÿçš„ç‰¹å®šä»»åŠ¡åŸºå‡†æ¨¡å‹ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.12624v1",
      "published_date": "2025-10-14 15:23:32 UTC",
      "updated_date": "2025-10-14 15:23:32 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:23:02.690202+00:00"
    },
    {
      "arxiv_id": "2510.12615v1",
      "title": "Rethinking Knowledge Distillation: A Data Dependent Regulariser With a Negative Asymmetric Payoff",
      "title_zh": "é‡æ–°å®¡è§†çŸ¥è¯†è’¸é¦ï¼šä¸€ç§å…·æœ‰è´Ÿå‘éå¯¹ç§°æ”¶ç›Šçš„æ•°æ®ä¾èµ–å‹æ­£åˆ™åŒ–é¡¹",
      "authors": [
        "Israel Mason-Williams",
        "Gabryel Mason-Williams",
        "Helen Yannakoudakis"
      ],
      "abstract": "Knowledge distillation is often considered a compression mechanism when judged on the resulting student's accuracy and loss, yet its functional impact is poorly understood. In this work, we quantify the compression capacity of knowledge distillation and the resulting knowledge transfer from a functional perspective, decoupling compression from architectural reduction, which provides an improved understanding of knowledge distillation. We employ hypothesis testing, controls, and random control distillation to understand knowledge transfer mechanisms across data modalities. To rigorously test the breadth and limits of our analyses, we explore multiple distillation variants and analyse distillation scaling laws across model sizes. Our findings demonstrate that, while there is statistically significant knowledge transfer in some modalities and architectures, the extent of this transfer is less pronounced than anticipated, even under conditions designed to maximise knowledge sharing. Notably, in cases of significant knowledge transfer, we identify a consistent and severe asymmetric transfer of negative knowledge to the student, raising safety concerns in knowledge distillation applications. Across 12 experimental setups, 9 architectures, and 7 datasets, our findings show that knowledge distillation functions less as a compression mechanism and more as a data-dependent regulariser with a negative asymmetric payoff.",
      "tldr_zh": "è¿™é¡¹ç ”ç©¶ä»åŠŸèƒ½è§†è§’é‡æ–°å®¡è§†äº†çŸ¥è¯†è’¸é¦(Knowledge Distillation)çš„æœ¬è´¨ï¼Œé€šè¿‡å°†å‹ç¼©ä¸æ¶æ„ç¼©å‡è§£è€¦ï¼Œåˆ©ç”¨å‡è®¾æ£€éªŒå’Œéšæœºæ§åˆ¶è’¸é¦ç­‰æ‰‹æ®µæ·±å…¥åˆ†æäº†ä¸åŒæ•°æ®æ¨¡æ€ä¸‹çš„çŸ¥è¯†è¿ç§»æœºåˆ¶ã€‚ç ”ç©¶åœ¨å¤šç§æ¨¡å‹è§„æ¨¡ä¸‹æ¢è®¨äº†è’¸é¦ç¼©æ”¾æ³•åˆ™(Scaling Laws)ï¼Œç»“æœæ˜¾ç¤ºè™½ç„¶åœ¨ç‰¹å®šæ¡ä»¶ä¸‹å­˜åœ¨ç»Ÿè®¡å­¦æ„ä¹‰ä¸Šçš„çŸ¥è¯†è¿ç§»ï¼Œä½†å…¶ç¨‹åº¦æ™®éä½äºé¢„æœŸã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œç ”ç©¶å‘ç°åœ¨æ˜¾è‘—çš„çŸ¥è¯†è¿ç§»è¿‡ç¨‹ä¸­ï¼Œå­˜åœ¨æŒç»­ä¸”ä¸¥é‡çš„è´Ÿé¢çŸ¥è¯†éå¯¹ç§°è¿ç§»(Asymmetric Transfer of Negative Knowledge)ï¼Œè¿™ä¸ºçŸ¥è¯†è’¸é¦çš„åº”ç”¨å¸¦æ¥äº†æ½œåœ¨çš„å®‰å…¨æ€§æŒ‘æˆ˜ã€‚åŸºäºæ¶µç›–12ç§å®éªŒè®¾ç½®ã€9ç§æ¶æ„å’Œ7ä¸ªæ•°æ®é›†çš„å¤§è§„æ¨¡å®è¯åˆ†æï¼Œè¯¥è®ºæ–‡å¾—å‡ºç»“è®ºï¼ŒçŸ¥è¯†è’¸é¦åœ¨æœ¬è´¨ä¸Šæ›´å€¾å‘äºä¸€ç§å…·æœ‰è´Ÿå‘éå¯¹ç§°æ”¶ç›Šçš„æ•°æ®ç›¸å…³æ­£åˆ™åŒ–é¡¹(Data Dependent Regulariser)ï¼Œè€Œéå•çº¯çš„å‹ç¼©æœºåˆ¶ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "45 pages, 24 figures and 104 tables",
      "pdf_url": "https://arxiv.org/pdf/2510.12615v1",
      "published_date": "2025-10-14 15:14:55 UTC",
      "updated_date": "2025-10-14 15:14:55 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:23:12.078047+00:00"
    },
    {
      "arxiv_id": "2510.12608v1",
      "title": "StyleDecipher: Robust and Explainable Detection of LLM-Generated Texts with Stylistic Analysis",
      "title_zh": "StyleDecipherï¼šåŸºäºé£æ ¼åˆ†æçš„é²æ£’ä¸”å¯è§£é‡Šçš„å¤§è¯­è¨€æ¨¡å‹ç”Ÿæˆæ–‡æœ¬æ£€æµ‹",
      "authors": [
        "Siyuan Li",
        "Aodu Wulianghai",
        "Xi Lin",
        "Guangyan Li",
        "Xiang Chen",
        "Jun Wu",
        "Jianhua Li"
      ],
      "abstract": "With the increasing integration of large language models (LLMs) into open-domain writing, detecting machine-generated text has become a critical task for ensuring content authenticity and trust. Existing approaches rely on statistical discrepancies or model-specific heuristics to distinguish between LLM-generated and human-written text. However, these methods struggle in real-world scenarios due to limited generalization, vulnerability to paraphrasing, and lack of explainability, particularly when facing stylistic diversity or hybrid human-AI authorship. In this work, we propose StyleDecipher, a robust and explainable detection framework that revisits LLM-generated text detection using combined feature extractors to quantify stylistic differences. By jointly modeling discrete stylistic indicators and continuous stylistic representations derived from semantic embeddings, StyleDecipher captures distinctive style-level divergences between human and LLM outputs within a unified representation space. This framework enables accurate, explainable, and domain-agnostic detection without requiring access to model internals or labeled segments. Extensive experiments across five diverse domains, including news, code, essays, reviews, and academic abstracts, demonstrate that StyleDecipher consistently achieves state-of-the-art in-domain accuracy. Moreover, in cross-domain evaluations, it surpasses existing baselines by up to 36.30%, while maintaining robustness against adversarial perturbations and mixed human-AI content. Further qualitative and quantitative analysis confirms that stylistic signals provide explainable evidence for distinguishing machine-generated text. Our source code can be accessed at https://github.com/SiyuanLi00/StyleDecipher.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† StyleDecipherï¼Œä¸€ä¸ªç¨³å¥ä¸”å…·æœ‰å¯è§£é‡Šæ€§çš„æ£€æµ‹æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹ (LLMs) ç”Ÿæˆæ–‡æœ¬æ£€æµ‹ä¸­é¢ä¸´çš„æ³›åŒ–æ€§å·®å’Œç¼ºä¹å¯è§£é‡Šæ€§ç­‰æŒ‘æˆ˜ã€‚è¯¥æ¡†æ¶é€šè¿‡ç»“åˆç¦»æ•£çš„é£æ ¼æŒ‡æ ‡å’ŒåŸºäº semantic embeddings çš„è¿ç»­é£æ ¼è¡¨ç¤ºï¼Œåœ¨ç»Ÿä¸€çš„è¡¨ç¤ºç©ºé—´å†…é‡åŒ–å¹¶æ•æ‰äººç±»ä¸ LLM è¾“å‡ºä¹‹é—´çš„é£æ ¼ç‰¹å¾å·®å¼‚ã€‚StyleDecipher æ— éœ€è®¿é—®æ¨¡å‹å†…éƒ¨å‚æ•°æˆ–æ ‡æ³¨ç‰‡æ®µï¼Œå³å¯å®ç°é¢†åŸŸæ— å…³çš„å‡†ç¡®æ£€æµ‹ã€‚åœ¨æ–°é—»ã€ä»£ç ã€å­¦æœ¯æ‘˜è¦ç­‰äº”ä¸ªé¢†åŸŸçš„å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨ in-domain å‡†ç¡®ç‡ä¸Šè¾¾åˆ°äº† state-of-the-art æ°´å¹³ï¼Œä¸”åœ¨ cross-domain è¯„ä¼°ä¸­ä¼˜äºç°æœ‰åŸºçº¿æ¨¡å‹å¤šè¾¾ 36.30%ã€‚æ­¤å¤–ï¼Œè¯¥æ¡†æ¶å¯¹ adversarial perturbations å’Œäººæœºæ··åˆåˆ›ä½œå†…å®¹è¡¨ç°å‡ºæå¼ºçš„é²æ£’æ€§ï¼Œå¹¶é€šè¿‡é£æ ¼ä¿¡å·ä¸ºè¯†åˆ«æœºå™¨ç”Ÿæˆæ–‡æœ¬æä¾›äº†ç›´è§‚çš„å¯è§£é‡Šè¯æ®ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.12608v1",
      "published_date": "2025-10-14 15:07:27 UTC",
      "updated_date": "2025-10-14 15:07:27 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:23:12.991192+00:00"
    },
    {
      "arxiv_id": "2510.16005v1",
      "title": "Breaking Guardrails, Facing Walls: Insights on Adversarial AI for Defenders & Researchers",
      "title_zh": "çªç ´æŠ¤æ ï¼Œç›´é¢å£å’ï¼šé¢å‘é˜²å¾¡è€…ä¸ç ”ç©¶è€…çš„å¯¹æŠ—æ€§äººå·¥æ™ºèƒ½å¯ç¤º",
      "authors": [
        "Giacomo Bertollo",
        "Naz Bodemir",
        "Jonah Burgess"
      ],
      "abstract": "Analyzing 500 CTF participants, this paper shows that while participants readily bypassed simple AI guardrails using common techniques, layered multi-step defenses still posed significant challenges, offering concrete insights for building safer AI systems.",
      "tldr_zh": "è¯¥ç ”ç©¶é€šè¿‡å¯¹500åCTFå‚ä¸è€…çš„è¡Œä¸ºè¿›è¡Œåˆ†æï¼Œæ·±å…¥æ¢è®¨äº†é’ˆå¯¹é˜²å¾¡è€…å’Œç ”ç©¶è€…çš„å¯¹æŠ—æ€§äººå·¥æ™ºèƒ½(Adversarial AI)å®æˆ˜è§è§£ã€‚ç ”ç©¶å‘ç°ï¼Œè™½ç„¶å‚ä¸è€…èƒ½å¤Ÿåˆ©ç”¨å¸¸ç”¨æŠ€æœ¯è½»æ˜“ç»•è¿‡ç®€å•çš„AIé˜²æŠ¤æ (AI guardrails)ï¼Œä½†å¤šå±‚æ¬¡ã€å¤šæ­¥éª¤çš„é˜²å¾¡ä½“ç³»(Layered multi-step defenses)ä¾ç„¶å¯¹æ”»å‡»è€…æ„æˆäº†æ˜¾è‘—æŒ‘æˆ˜ã€‚è¿™ä¸€å‘ç°æ­ç¤ºäº†å½“å‰AIå®‰å…¨é˜²æŠ¤çš„è–„å¼±ç¯èŠ‚ï¼Œå¹¶ä¸ºæ„å»ºæ›´å®‰å…¨çš„äººå·¥æ™ºèƒ½ç³»ç»Ÿæä¾›äº†å…·ä½“ä¸”åŠ¡å®çš„å‚è€ƒä¾æ®ã€‚é€šè¿‡é‡åŒ–æ”»å‡»è€…çš„æˆåŠŸç‡ä¸é˜²å¾¡æ·±åº¦ä¹‹é—´çš„å…³ç³»ï¼Œè¯¥è®ºæ–‡å¼ºè°ƒäº†åˆ†å±‚é˜²å¾¡åœ¨æå‡ç³»ç»Ÿé²æ£’æ€§ä¸­çš„æ ¸å¿ƒä»·å€¼ã€‚ç ”ç©¶ç»“æœä¸ºå¼€å‘æ›´å…·éŸ§æ€§çš„AIå®‰å…¨æ¶æ„æä¾›äº†å®è¯æ”¯æŒï¼Œæœ‰åŠ©äºç ”ç©¶äººå‘˜æ›´å¥½åœ°ç†è§£å¯¹æŠ—ç¯å¢ƒä¸‹çš„é˜²å¾¡ç­–ç•¥ã€‚",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.16005v1",
      "published_date": "2025-10-14 15:01:59 UTC",
      "updated_date": "2025-10-14 15:01:59 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:23:22.481934+00:00"
    },
    {
      "arxiv_id": "2510.12604v4",
      "title": "COINS: SemantiC Ids Enhanced COLd Item RepresentatioN for Click-through Rate Prediction in E-commerce Search",
      "title_zh": "COINSï¼šé¢å‘ç”µå•†æœç´¢ç‚¹å‡»ç‡é¢„æµ‹çš„è¯­ä¹‰ ID å¢å¼ºå‹å†·å¯åŠ¨ç‰©å“è¡¨ç¤º",
      "authors": [
        "Qihang Zhao",
        "Zhongbo Sun",
        "Xiaoyang Zheng",
        "Xian Guo",
        "Siyuan Wang",
        "Zihan Liang",
        "Mingcan Peng",
        "Ben Chen",
        "Chenyi Lei"
      ],
      "abstract": "With the rise of modern search and recommendation platforms, insufficient collaborative information of cold-start items exacerbates the Matthew effect of existing platform items, challenging platform diversity and becoming a longstanding issue. Existing methods align items' side content with collaborative information to transfer collaborative signals from high-popularity items to cold-start items. However, these methods fail to account for the asymmetry between collaboration and content, nor the fine-grained differences among items. To address these issues, we propose COINS, an item representation enhancement approach based on fused alignment of semantic IDs. Specifically, we use RQ-OPQ encoding to quantize item content and collaborative information, followed by a two-step alignment: RQ encoding transfers shared collaborative signals across items, while OPQ encoding learns differentiated information of items. Comprehensive offline experiments on large-scale industrial datasets demonstrate superiority of COINS, and rigorous online A/B tests confirm statistically significant improvements: item CTR +1.66%, buyers +1.57%, and order volume +2.17%.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†COINSæ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³ç”µå­å•†åŠ¡æœç´¢ä¸­å†·å¯åŠ¨(cold-start)å•†å“å› åä½œä¿¡æ¯ä¸è¶³è€Œå¯¼è‡´çš„é©¬å¤ªæ•ˆåº”å’Œå¹³å°å¤šæ ·æ€§å—æŸé—®é¢˜ã€‚é’ˆå¯¹ç°æœ‰æ–¹æ³•åœ¨å¤„ç†åä½œä¸å†…å®¹ä¸å¯¹ç§°æ€§åŠå•†å“ç»†ç²’åº¦å·®å¼‚æ–¹é¢çš„ä¸è¶³ï¼ŒCOINSé‡‡ç”¨äº†ä¸€ç§åŸºäºè¯­ä¹‰ID(semantic IDs)èåˆå¯¹é½çš„å•†å“è¡¨ç¤ºå¢å¼ºæ–¹æ³•ã€‚è¯¥æ–¹æ³•åˆ©ç”¨RQ-OPQç¼–ç å¯¹å•†å“å†…å®¹å’Œåä½œä¿¡æ¯è¿›è¡Œé‡åŒ–ï¼Œå¹¶é€šè¿‡ä¸¤æ­¥å¯¹é½ç­–ç•¥å®ç°ä¿¡æ¯å¢å¼ºï¼šRQç¼–ç è´Ÿè´£åœ¨å•†å“é—´ä¼ è¾“å…±äº«çš„åä½œä¿¡å·ï¼Œè€ŒOPQç¼–ç åˆ™ç”¨äºå­¦ä¹ å•†å“çš„å·®å¼‚åŒ–ç‰¹å¾ã€‚å¤§è§„æ¨¡å·¥ä¸šæ•°æ®é›†çš„ç¦»çº¿å®éªŒéªŒè¯äº†COINSçš„ä¼˜è¶Šæ€§ï¼Œä¸¥è°¨çš„åœ¨çº¿A/Bæµ‹è¯•è¿›ä¸€æ­¥è¯å®äº†å…¶å•†ä¸šä»·å€¼ï¼Œå®ç°äº†å•†å“ç‚¹å‡»ç‡(CTR)æå‡1.66%ã€ä¹°å®¶æ•°å¢åŠ 1.57%ä»¥åŠè®¢å•é‡å¢é•¿2.17%çš„æ˜¾è‘—æˆæ•ˆã€‚",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "Accepted by WWW26",
      "pdf_url": "https://arxiv.org/pdf/2510.12604v4",
      "published_date": "2025-10-14 14:58:50 UTC",
      "updated_date": "2026-01-15 02:58:58 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:23:23.166203+00:00"
    },
    {
      "arxiv_id": "2510.12603v1",
      "title": "Reasoning in the Dark: Interleaved Vision-Text Reasoning in Latent Space",
      "title_zh": "æš—ä¸­æ¨ç†ï¼šéšç©ºé—´ä¸­çš„è§†è§‰-æ–‡æœ¬äº¤ç»‡æ¨ç†",
      "authors": [
        "Chao Chen",
        "Zhixin Ma",
        "Yongqi Li",
        "Yupeng Hu",
        "Yinwei Wei",
        "Wenjie Li",
        "Liqiang Nie"
      ],
      "abstract": "Multimodal reasoning aims to enhance the capabilities of MLLMs by incorporating intermediate reasoning steps before reaching the final answer. It has evolved from text-only reasoning to the integration of visual information, enabling the thought process to be conveyed through both images and text. Despite its effectiveness, current multimodal reasoning methods depend on explicit reasoning steps that require labor-intensive vision-text annotations and inherently introduce significant inference latency. To address these issues, we introduce multimodal latent reasoning with the advantages of multimodal representation, reduced annotation, and inference efficiency. To facilicate it, we propose Interleaved Vision-Text Latent Reasoning (IVT-LR), which injects both visual and textual information in the reasoning process within the latent space. Specifically, IVT-LR represents each reasoning step by combining two implicit parts: latent text (the hidden states from the previous step) and latent vision (a set of selected image embeddings). We further introduce a progressive multi-stage training strategy to enable MLLMs to perform the above multimodal latent reasoning steps. Experiments on M3CoT and ScienceQA demonstrate that our IVT-LR method achieves an average performance increase of 5.45% in accuracy, while simultaneously achieving a speed increase of over 5 times compared to existing approaches. Code available at https://github.com/FYYDCC/IVT-LR.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤šæ¨¡æ€æ¨ç†(Multimodal Reasoning)ä¸­æ˜¾å¼æ¨ç†æ­¥éª¤å¯¼è‡´çš„æ ‡æ³¨æˆæœ¬é«˜å’Œæ¨ç†å»¶è¿Ÿå¤§ç­‰é—®é¢˜ï¼Œæå‡ºäº†æ½œç©ºé—´å¤šæ¨¡æ€æ¨ç†çš„æ–°èŒƒå¼ã€‚ä¸ºæ­¤ï¼Œä½œè€…æå‡ºäº†äº¤ç»‡è§†è§‰-æ–‡æœ¬æ½œç©ºé—´æ¨ç†(Interleaved Vision-Text Latent Reasoning, IVT-LR)ï¼Œåœ¨æ½œç©ºé—´å†…å°†è§†è§‰å’Œæ–‡æœ¬ä¿¡æ¯å…±åŒæ³¨å…¥æ¨ç†è¿‡ç¨‹ã€‚å…·ä½“è€Œè¨€ï¼ŒIVT-LRé€šè¿‡ç»“åˆå‰ä¸€é˜¶æ®µçš„éšè—çŠ¶æ€(latent text)å’Œé€‰å®šçš„å›¾åƒåµŒå…¥(latent vision)æ¥è¡¨ç¤ºæ¯ä¸ªæ¨ç†æ­¥éª¤ï¼Œå¹¶é…åˆæ¸è¿›å¼å¤šé˜¶æ®µè®­ç»ƒç­–ç•¥æå‡æ¨¡å‹èƒ½åŠ›ã€‚åœ¨M3CoTå’ŒScienceQAæ•°æ®é›†ä¸Šçš„å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ–¹æ³•ä¸ä»…ä½¿å¹³å‡å‡†ç¡®ç‡æå‡äº†5.45%ï¼Œè¿˜åœ¨æ¨ç†é€Ÿåº¦ä¸Šå®ç°äº†æ¯”ç°æœ‰æ–¹æ³•å¿«5å€ä»¥ä¸Šçš„æ˜¾è‘—çªç ´ã€‚è¿™é¡¹å·¥ä½œè¯æ˜äº†åœ¨æ½œç©ºé—´è¿›è¡Œå¤šæ¨¡æ€æ¨ç†å¯ä»¥æœ‰æ•ˆå…¼é¡¾æ ‡æ³¨æ•ˆç‡ã€æ¨ç†æ€§èƒ½ä¸æ‰§è¡Œé€Ÿåº¦ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.12603v1",
      "published_date": "2025-10-14 14:58:25 UTC",
      "updated_date": "2025-10-14 14:58:25 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:23:21.480935+00:00"
    },
    {
      "arxiv_id": "2510.12859v2",
      "title": "Three Lenses on the AI Revolution: Risk, Transformation, Continuity",
      "title_zh": "äººå·¥æ™ºèƒ½é©å‘½çš„ä¸‰ç§è§†è§’ï¼šé£é™©ã€å˜é©ä¸å»¶ç»­æ€§",
      "authors": [
        "Masoud Makrehchi"
      ],
      "abstract": "Artificial Intelligence (AI) has emerged as both a continuation of historical technological revolutions and a potential rupture with them. This paper argues that AI must be viewed simultaneously through three lenses: \\textit{risk}, where it resembles nuclear technology in its irreversible and global externalities; \\textit{transformation}, where it parallels the Industrial Revolution as a general-purpose technology driving productivity and reorganization of labor; and \\textit{continuity}, where it extends the fifty-year arc of computing revolutions from personal computing to the internet to mobile. Drawing on historical analogies, we emphasize that no past transition constituted a strict singularity: disruptive shifts eventually became governable through new norms and institutions.\n  We examine recurring patterns across revolutions -- democratization at the usage layer, concentration at the production layer, falling costs, and deepening personalization -- and show how these dynamics are intensifying in the AI era. Sectoral analysis illustrates how accounting, law, education, translation, advertising, and software engineering are being reshaped as routine cognition is commoditized and human value shifts to judgment, trust, and ethical responsibility. At the frontier, the challenge of designing moral AI agents highlights the need for robust guardrails, mechanisms for moral generalization, and governance of emergent multi-agent dynamics.\n  We conclude that AI is neither a singular break nor merely incremental progress. It is both evolutionary and revolutionary: predictable in its median effects yet carrying singularity-class tail risks. Good outcomes are not automatic; they require coupling pro-innovation strategies with safety governance, ensuring equitable access, and embedding AI within a human order of responsibility.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†äººå·¥æ™ºèƒ½(AI)åœ¨å†å²å»¶ç»­æ€§ä¸æŠ€æœ¯çªç ´æ€§ä¹‹é—´çš„åŒé‡è§’è‰²ï¼Œæå‡ºäº†é€šè¿‡é£é™©(Risk)ã€è½¬å‹(Transformation)å’Œå»¶ç»­(Continuity)ä¸‰ä¸ªè§†è§’æ¥å®¡è§†AIé©å‘½ã€‚é£é™©è§†è§’å°†AIç±»æ¯”ä¸ºæ ¸æŠ€æœ¯(nuclear technology)çš„å…¨çƒå¤–éƒ¨æ€§ï¼Œè½¬å‹è§†è§’å°†å…¶è§†ä¸ºç±»ä¼¼å·¥ä¸šé©å‘½çš„é€šç”¨æŠ€æœ¯(general-purpose technology)ï¼Œè€Œå»¶ç»­è§†è§’åˆ™å°†å…¶çœ‹ä½œè®¡ç®—é©å‘½(computing revolutions)ä»ä¸ªäººè®¡ç®—åˆ°ç§»åŠ¨äº’è”ç½‘çš„è‡ªç„¶æ¼”è¿›ã€‚è®ºæ–‡åˆ†æäº†AIæ—¶ä»£ä½¿ç”¨å±‚æ°‘ä¸»åŒ–(democratization)ä¸ç”Ÿäº§å±‚é›†ä¸­åŒ–(concentration)çš„åŠ¨æ€åŠ å¼ºï¼ŒæŒ‡å‡ºè¡Œä¸šå˜é©æ­£ä½¿äººç±»ä»·å€¼ä»å¸¸è§„è®¤çŸ¥(routine cognition)è½¬å‘åˆ¤æ–­ã€ä¿¡ä»»ä¸ä¼¦ç†è´£ä»»ã€‚é’ˆå¯¹é“å¾·AIä»£ç†(moral AI agents)ç­‰å‰æ²¿æŒ‘æˆ˜ï¼Œç ”ç©¶å¼ºè°ƒäº†å»ºç«‹é²æ£’æŠ¤æ (guardrails)ä¸é“å¾·æ™®éåŒ–æœºåˆ¶çš„é‡è¦æ€§ã€‚æœ€ç»ˆç»“è®ºè®¤ä¸ºï¼ŒAIå…¼å…·æ¼”è¿›ä¸é©å‘½ç‰¹å¾ï¼Œå¿…é¡»é€šè¿‡åˆ›æ–°ç­–ç•¥ä¸å®‰å…¨æ²»ç†çš„æœ‰æ•ˆç»“åˆï¼Œå°†å…¶åµŒå…¥äººç±»çš„è´£ä»»ä½“ç³»ä¹‹ä¸­ã€‚",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "18 pages",
      "pdf_url": "https://arxiv.org/pdf/2510.12859v2",
      "published_date": "2025-10-14 14:53:49 UTC",
      "updated_date": "2025-12-13 03:44:59 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:23:29.403614+00:00"
    },
    {
      "arxiv_id": "2510.13894v2",
      "title": "Bayes or Heisenberg: Who(se) Rules?",
      "title_zh": "Bayes è¿˜æ˜¯ Heisenbergï¼šè°ï¼ˆçš„ï¼‰æ³•åˆ™ï¼Ÿ",
      "authors": [
        "Volker Tresp",
        "Hang Li",
        "Federico Harjes",
        "Yunpu Ma"
      ],
      "abstract": "Although quantum systems are generally described by quantum state vectors, we show that in certain cases their measurement processes can be reformulated as probabilistic equations expressed in terms of probabilistic state vectors. These probabilistic representations can, in turn, be approximated by the neural network dynamics of the Tensor Brain (TB) model.\n  The Tensor Brain is a recently proposed framework for modeling perception and memory in the brain, providing a biologically inspired mechanism for efficiently integrating generated symbolic representations into reasoning processes.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†é‡å­ç³»ç»Ÿæµ‹é‡è¿‡ç¨‹çš„æ¦‚ç‡åŒ–è¡¨è¿°ï¼Œè¯æ˜äº†åœ¨ç‰¹å®šæƒ…å†µä¸‹ï¼Œä¼ ç»Ÿçš„é‡å­æ€å‘é‡(quantum state vectors)å¯ä»¥è¢«é‡æ–°è¡¨è¿°ä¸ºåŸºäºæ¦‚ç‡çŠ¶æ€å‘é‡(probabilistic state vectors)çš„æ¦‚ç‡æ–¹ç¨‹ã€‚ç ”ç©¶è¿›ä¸€æ­¥è¡¨æ˜ï¼Œè¿™äº›æ¦‚ç‡è¡¨ç¤ºèƒ½å¤Ÿé€šè¿‡å¼ é‡å¤§è„‘(Tensor Brain, TB)æ¨¡å‹çš„ç¥ç»ç½‘ç»œåŠ¨åŠ›å­¦è¿›è¡Œè¿‘ä¼¼æ¨¡æ‹Ÿã€‚ä½œä¸ºä¸€ç§æ¨¡æ‹Ÿå¤§è„‘æ„ŸçŸ¥å’Œè®°å¿†çš„æ–°å‹æ¡†æ¶ï¼Œå¼ é‡å¤§è„‘(TB)æä¾›äº†ä¸€ç§å—ç”Ÿç‰©å­¦å¯å‘çš„æœºåˆ¶ï¼Œèƒ½å¤Ÿå°†ç”Ÿæˆçš„ç¬¦å·åŒ–è¡¨ç¤º(symbolic representations)é«˜æ•ˆåœ°æ•´åˆåˆ°æ¨ç†è¿‡ç¨‹ä¸­ã€‚è¿™é¡¹å·¥ä½œé€šè¿‡è¿æ¥é‡å­ç‰©ç†æ¦‚å¿µä¸ç¥ç»è®¡ç®—æ¨¡å‹ï¼Œä¸ºç†è§£å¤æ‚è®¤çŸ¥ä»»åŠ¡ä¸­çš„ä¿¡æ¯å¤„ç†æä¾›äº†æ–°çš„ç†è®ºè§†è§’ã€‚",
      "categories": [
        "q-bio.NC",
        "cs.AI",
        "cs.LG",
        "quant-ph"
      ],
      "primary_category": "q-bio.NC",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.13894v2",
      "published_date": "2025-10-14 14:27:18 UTC",
      "updated_date": "2025-10-23 11:22:19 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:23:45.568800+00:00"
    },
    {
      "arxiv_id": "2510.12563v2",
      "title": "HardcoreLogic: Challenging Large Reasoning Models with Long-tail Logic Puzzle Games",
      "title_zh": "HardcoreLogicï¼šä»¥é•¿å°¾é€»è¾‘è°œé¢˜æŒ‘æˆ˜å¤§æ¨ç†æ¨¡å‹",
      "authors": [
        "Jingcong Liang",
        "Shijun Wan",
        "Xuehai Wu",
        "Yitong Li",
        "Qianglong Chen",
        "Duyu Tang",
        "Siyuan Wang",
        "Zhongyu Wei"
      ],
      "abstract": "Large Reasoning Models (LRMs) have demonstrated impressive performance on complex tasks, including logical puzzle games that require deriving solutions satisfying all constraints. However, whether they can flexibly apply appropriate rules to varying conditions, particularly when faced with non-canonical game variants, remains an open question. Existing corpora focus on popular puzzles like 9x9 Sudoku, risking overfitting to canonical formats and memorization of solution patterns, which can mask deficiencies in understanding novel rules or adapting strategies to new variants. To address this, we introduce HardcoreLogic, a challenging benchmark of over 5,000 puzzles across 10 games, designed to test the robustness of LRMs on the \"long-tail\" of logical games. HardcoreLogic systematically transforms canonical puzzles through three dimensions: Increased Complexity (IC), Uncommon Elements (UE), and Unsolvable Puzzles (UP), reducing reliance on shortcut memorization. Evaluations on a diverse set of LRMs reveal significant performance drops, even for models achieving top scores on existing benchmarks, indicating heavy reliance on memorized stereotypes. While increased complexity is the dominant source of difficulty, models also struggle with subtle rule variations that do not necessarily increase puzzle difficulty. Our systematic error analysis on solvable and unsolvable puzzles further highlights gaps in genuine reasoning. Overall, HardcoreLogic exposes the limitations of current LRMs and establishes a benchmark for advancing high-level logical reasoning.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§å‹æ¨ç†æ¨¡å‹(Large Reasoning Models, LRMs)åœ¨å¤„ç†é€»è¾‘è°œé¢˜æ—¶å¯èƒ½å­˜åœ¨çš„æ¨¡å¼è®°å¿†å’Œè¿‡æ‹Ÿåˆé—®é¢˜ï¼Œæå‡ºäº†æŒ‘æˆ˜æ€§åŸºå‡†æµ‹è¯•HardcoreLogicã€‚è¯¥åŸºå‡†åŒ…å«5,000å¤šä¸ªè°œé¢˜ï¼Œæ¶µç›–10ç§æ¸¸æˆï¼Œæ—¨åœ¨æµ‹è¯•æ¨¡å‹åœ¨é€»è¾‘æ¸¸æˆâ€œé•¿å°¾â€åœºæ™¯ä¸‹çš„é²æ£’æ€§ã€‚ç ”ç©¶é€šè¿‡å¢åŠ å¤æ‚æ€§(Increased Complexity)ã€ä¸å¸¸è§å…ƒç´ (Uncommon Elements)ä»¥åŠä¸å¯è§£è°œé¢˜(Unsolvable Puzzles)ä¸‰ä¸ªç»´åº¦å¯¹ä¼ ç»Ÿè°œé¢˜è¿›è¡Œç³»ç»Ÿæ€§è½¬æ¢ï¼Œé™ä½äº†æ¨¡å‹å¯¹æ·å¾„è®°å¿†çš„ä¾èµ–ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œå³ä½¿æ˜¯è¡¨ç°é¡¶å°–çš„LRMsåœ¨é¢å¯¹è¿™äº›éæ ‡å‡†å˜ä½“æ—¶ä¹Ÿå‡ºç°äº†æ˜¾è‘—çš„æ€§èƒ½ä¸‹æ»‘ï¼Œåæ˜ å‡ºå…¶å¯¹è®°å¿†åˆ»æ¿å°è±¡çš„é‡åº¦ä¾èµ–ã€‚ç³»ç»Ÿçš„é”™è¯¯åˆ†æè¿›ä¸€æ­¥æ­ç¤ºäº†å½“å‰æ¨¡å‹åœ¨åº”å¯¹ç»†å¾®è§„åˆ™å˜åŒ–åŠè¯†åˆ«ä¸å¯è§£æ€§æ–¹é¢çš„ç¼ºé™·ã€‚æ€»ä¹‹ï¼ŒHardcoreLogicæ­ç¤ºäº†ç°æœ‰LRMsåœ¨çœŸå®é€»è¾‘æ¨ç†ä¸Šçš„å±€é™æ€§ï¼Œä¸ºè¯„ä¼°å’Œæå‡é«˜æ°´å¹³é€»è¾‘æ¨ç†èƒ½åŠ›å»ºç«‹äº†é‡è¦åŸºå‡†ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.12563v2",
      "published_date": "2025-10-14 14:23:24 UTC",
      "updated_date": "2025-10-15 10:31:28 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:23:44.590911+00:00"
    },
    {
      "arxiv_id": "2510.16004v1",
      "title": "PAINT: Parallel-in-time Neural Twins for Dynamical System Reconstruction",
      "title_zh": "PAINTï¼šç”¨äºåŠ¨åŠ›ç³»ç»Ÿé‡å»ºçš„æ—¶é—´å¹¶è¡Œç¥ç»å­ªç”Ÿ",
      "authors": [
        "Andreas Radler",
        "Vincent Seyfried",
        "Stefan Pirker",
        "Johannes Brandstetter",
        "Thomas Lichtenegger"
      ],
      "abstract": "Neural surrogates have shown great potential in simulating dynamical systems, while offering real-time capabilities. We envision Neural Twins as a progression of neural surrogates, aiming to create digital replicas of real systems. A neural twin consumes measurements at test time to update its state, thereby enabling context-specific decision-making. A critical property of neural twins is their ability to remain on-trajectory, i.e., to stay close to the true system state over time. We introduce Parallel-in-time Neural Twins (PAINT), an architecture-agnostic family of methods for modeling dynamical systems from measurements. PAINT trains a generative neural network to model the distribution of states parallel over time. At test time, states are predicted from measurements in a sliding window fashion. Our theoretical analysis shows that PAINT is on-trajectory, whereas autoregressive models generally are not. Empirically, we evaluate our method on a challenging two-dimensional turbulent fluid dynamics problem. The results demonstrate that PAINT stays on-trajectory and predicts system states from sparse measurements with high fidelity. These findings underscore PAINT's potential for developing neural twins that stay on-trajectory, enabling more accurate state estimation and decision-making.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†PAINTï¼ˆParallel-in-time Neural Twinsï¼‰ï¼Œè¿™æ˜¯ä¸€ç§ç”¨äºä»æµ‹é‡æ•°æ®ä¸­é‡å»ºåŠ¨åŠ›ç³»ç»Ÿä¸”ä¸å…·ä½“æ¶æ„æ— å…³çš„æ–¹æ³•ä½“ç³»ã€‚PAINTé€šè¿‡è®­ç»ƒç”Ÿæˆå¼ç¥ç»ç½‘ç»œæ¥å¹¶è¡Œå»ºæ¨¡éšæ—¶é—´åˆ†å¸ƒçš„çŠ¶æ€ï¼Œæ—¨åœ¨è§£å†³ä¼ ç»Ÿautoregressive modelsåœ¨æ¨¡æ‹Ÿè¿‡ç¨‹ä¸­å®¹æ˜“åç¦»çœŸå®ç‰©ç†è½¨è¿¹çš„é—®é¢˜ã€‚åœ¨æ¨ç†é˜¶æ®µï¼Œè¯¥æ–¹æ³•åˆ©ç”¨æ»‘åŠ¨çª—å£æœºåˆ¶ä»æµ‹é‡å€¼ä¸­é¢„æµ‹ç³»ç»ŸçŠ¶æ€ï¼Œç¡®ä¿æ¨¡å‹å…·å¤‡å…³é”®çš„on-trajectoryç‰¹æ€§ã€‚ç†è®ºåˆ†æè¡¨æ˜ï¼ŒPAINTç›¸æ¯”è‡ªå›å½’æ¨¡å‹å…·æœ‰æ›´å¼ºçš„è½¨è¿¹ç¨³å®šæ€§ã€‚å®éªŒåœ¨å¤æ‚çš„äºŒç»´æ¹æµæµä½“åŠ¨åŠ›å­¦é—®é¢˜ä¸Šè¿›è¡Œäº†éªŒè¯ï¼Œç»“æœè¯æ˜PAINTèƒ½å¤Ÿä»ç¨€ç–æµ‹é‡ä¸­å®ç°é«˜ä¿çœŸåº¦çš„çŠ¶æ€é¢„æµ‹å¹¶ä¿æŒåœ¨è½¨è¿è¡Œã€‚è¯¥ç ”ç©¶ä¸ºæ„å»ºé«˜ç²¾åº¦çš„Neural Twinså’Œæå‡å®æ—¶å†³ç­–èƒ½åŠ›æä¾›äº†æœ‰åŠ›æ”¯æŒã€‚",
      "categories": [
        "cs.AI",
        "physics.flu-dyn"
      ],
      "primary_category": "cs.AI",
      "comment": "22 pages, 16 figures",
      "pdf_url": "https://arxiv.org/pdf/2510.16004v1",
      "published_date": "2025-10-14 14:22:45 UTC",
      "updated_date": "2025-10-14 14:22:45 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:23:48.581854+00:00"
    },
    {
      "arxiv_id": "2510.12555v1",
      "title": "Inclusive Fitness as a Key Step Towards More Advanced Social Behaviors in Multi-Agent Reinforcement Learning Settings",
      "title_zh": "å¹¿ä¹‰é€‚åˆåº¦ï¼šå¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ è¿ˆå‘æ›´é«˜çº§ç¤¾ä¼šè¡Œä¸ºçš„å…³é”®ä¸€æ­¥",
      "authors": [
        "Andries Rosseau",
        "RaphaÃ«l Avalos",
        "Ann NowÃ©"
      ],
      "abstract": "The competitive and cooperative forces of natural selection have driven the evolution of intelligence for millions of years, culminating in nature's vast biodiversity and the complexity of human minds. Inspired by this process, we propose a novel multi-agent reinforcement learning framework where each agent is assigned a genotype and where reward functions are modelled after the concept of inclusive fitness. An agent's genetic material may be shared with other agents, and our inclusive reward function naturally accounts for this. We study the resulting social dynamics in two types of network games with prisoner's dilemmas and find that our results align with well-established principles from biology, such as Hamilton's rule. Furthermore, we outline how this framework can extend to more open-ended environments with spatial and temporal structure, finite resources, and evolving populations. We hypothesize the emergence of an arms race of strategies, where each new strategy is a gradual improvement over earlier adaptations of other agents, effectively producing a multi-agent autocurriculum analogous to biological evolution. In contrast to the binary team-based structures prevalent in earlier research, our gene-based reward structure introduces a spectrum of cooperation ranging from full adversity to full cooperativeness based on genetic similarity, enabling unique non team-based social dynamics. For example, one agent having a mutual cooperative relationship with two other agents, while the two other agents behave adversarially towards each other. We argue that incorporating inclusive fitness in agents provides a foundation for the emergence of more strategically advanced and socially intelligent agents.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§æ–°å‹çš„å¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹  (Multi-Agent Reinforcement Learning, MARL) æ¡†æ¶ï¼Œé€šè¿‡ä¸ºæ¯ä¸ªæ™ºèƒ½ä½“åˆ†é…åŸºå› å‹ (genotype)ï¼Œå¹¶å°†å¥–åŠ±å‡½æ•°å»ºæ¨¡ä¸ºå†…å«é€‚åº”åº¦ (inclusive fitness) çš„å½¢å¼ã€‚è¿™ç§æœºåˆ¶å…è®¸æ™ºèƒ½ä½“ä¹‹é—´å…±äº«é—ä¼ ç‰©è´¨ï¼Œä½¿å¥–åŠ±å‡½æ•°èƒ½å¤Ÿè‡ªç„¶åœ°æ ¹æ®é—ä¼ ç›¸ä¼¼åº¦æƒè¡¡åˆä½œä¸ç«äº‰ï¼Œä»è€Œäº§ç”Ÿä»å®Œå…¨å¯¹æŠ—åˆ°å®Œå…¨åˆä½œçš„è¿ç»­å…‰è°±ï¼Œè€Œéä¼ ç»Ÿçš„äºŒå…ƒå›¢é˜Ÿç»“æ„ã€‚åœ¨åŒ…å«å›šå¾’å›°å¢ƒ (prisoner's dilemmas) çš„ç½‘ç»œåšå¼ˆå®éªŒä¸­ï¼Œè¯¥æ¡†æ¶å±•ç°å‡ºçš„ç¤¾ä¼šåŠ¨åŠ›å­¦ç‰¹å¾ä¸ç”Ÿç‰©å­¦ä¸­çš„æ±‰å¯†å°”é¡¿æ³•åˆ™ (Hamilton's rule) ç­‰åŸºæœ¬åŸç†é«˜åº¦ä¸€è‡´ã€‚ç ”ç©¶è¿›ä¸€æ­¥æ¢è®¨äº†è¯¥æ¡†æ¶åœ¨èµ„æºæœ‰é™ã€ç§ç¾¤æ¼”åŒ–çš„å¼€æ”¾å¼ç¯å¢ƒä¸­çš„æ‰©å±•æ½œåŠ›ï¼Œå¹¶å‡è®¾è¿™å°†å¼•å‘ç­–ç•¥é—´çš„â€œå†›å¤‡ç«èµ›â€ï¼Œå½¢æˆç±»ä¼¼äºç”Ÿç‰©è¿›åŒ–çš„å¤šæ™ºèƒ½ä½“è‡ªåŠ¨è¯¾ç¨‹ (autocurriculum)ã€‚è¿™ç§åŸºäºåŸºå› çš„å¥–åŠ±ç»“æ„ä½¿æ™ºèƒ½ä½“èƒ½å¤Ÿäº§ç”Ÿå¤æ‚çš„éå›¢é˜Ÿå‹ç¤¾äº¤è¡Œä¸ºï¼Œä¾‹å¦‚ä¸ä¸åŒä¸ªä½“åŒæ—¶ç»´æŒäº’æƒ æˆ–å¯¹æŠ—å…³ç³»ã€‚é€šè¿‡å¼•å…¥å†…å«é€‚åº”åº¦ç†è®ºï¼Œè¯¥æ¡†æ¶ä¸ºåœ¨å¤æ‚ç¯å¢ƒä¸­åŸ¹å…»å…·æœ‰æ›´é«˜æˆ˜ç•¥æ°´å¹³å’Œç¤¾äº¤æ™ºèƒ½çš„æ™ºèƒ½ä½“å¥ å®šäº†é‡è¦åŸºç¡€ã€‚",
      "categories": [
        "cs.AI",
        "cs.MA",
        "cs.SI"
      ],
      "primary_category": "cs.AI",
      "comment": "This version is a slightly updated version (e.g., added an important reference) compared to the peer-reviewed versions at 'Adapative Learning Agents' at AAMAS 2022 or 'From Cells to Societies' at ICLR 2022",
      "pdf_url": "https://arxiv.org/pdf/2510.12555v1",
      "published_date": "2025-10-14 14:20:01 UTC",
      "updated_date": "2025-10-14 14:20:01 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:23:49.174567+00:00"
    },
    {
      "arxiv_id": "2510.12541v1",
      "title": "Evaluation of Real-Time Preprocessing Methods in AI-Based ECG Signal Analysis",
      "title_zh": "åŸºäºäººå·¥æ™ºèƒ½çš„å¿ƒç”µä¿¡å·åˆ†æä¸­å®æ—¶é¢„å¤„ç†æ–¹æ³•çš„è¯„ä¼°",
      "authors": [
        "Jasmin Freudenberg",
        "Kai Hahn",
        "Christian Weber",
        "Madjid Fathi"
      ],
      "abstract": "The increasing popularity of portable ECG systems and the growing demand for privacy-compliant, energy-efficient real-time analysis require new approaches to signal processing at the point of data acquisition. In this context, the edge domain is acquiring increasing importance, as it not only reduces latency times, but also enables an increased level of data security. The FACE project aims to develop an innovative machine learning solution for analysing long-term electrocardiograms that synergistically combines the strengths of edge and cloud computing. In this thesis, various pre-processing steps of ECG signals are analysed with regard to their applicability in the project. The selection of suitable methods in the edge area is based in particular on criteria such as energy efficiency, processing capability and real-time capability.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ä¾¿æºå¼ ECG ç³»ç»Ÿå¯¹éšç§åˆè§„ã€é«˜èƒ½æ•ˆåŠå®æ—¶åˆ†æçš„éœ€æ±‚ï¼Œæ¢è®¨äº†æ•°æ®é‡‡é›†ç«¯çš„ä¿¡å·å¤„ç†ä¼˜åŒ–æ–¹æ³•ã€‚ç ”ç©¶ä¾æ‰˜ FACE é¡¹ç›®ï¼Œæ—¨åœ¨å¼€å‘ä¸€ç§ååŒè¾¹ç¼˜è®¡ç®—(Edge Computing)ä¸äº‘è®¡ç®—ä¼˜åŠ¿çš„åˆ›æ–°æœºå™¨å­¦ä¹ æ–¹æ¡ˆï¼Œç”¨äºé•¿æœŸå¿ƒç”µå›¾çš„å®æ—¶ç›‘æµ‹ã€‚æœ¬æ–‡æ·±å…¥è¯„ä¼°äº†å¤šç§ ECG ä¿¡å·é¢„å¤„ç†æ­¥éª¤åœ¨è¾¹ç¼˜ç«¯çš„åº”ç”¨æ½œåŠ›ï¼Œå¹¶ç¡®ç«‹äº†é€‰æ‹©åˆé€‚æ–¹æ³•çš„å…³é”®å‡†åˆ™ã€‚è¿™äº›å‡†åˆ™ä¸»è¦åŒ…æ‹¬èƒ½æ•ˆ(Energy Efficiency)ã€å¤„ç†èƒ½åŠ›(Processing Capability)ä»¥åŠå®æ—¶æ€§(Real-time Capability)ã€‚é€šè¿‡å¯¹é¢„å¤„ç†æŠ€æœ¯çš„ç³»ç»Ÿæ€§åˆ†æï¼Œè¯¥ç ”ç©¶ä¸ºå®ç°ä½å»¶è¿Ÿä¸”æ•°æ®å®‰å…¨çš„ AI é©±åŠ¨å‹å¿ƒç”µä¿¡å·åˆ†ææä¾›äº†é‡è¦å‚è€ƒã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Conference paper for 2025 IEEE World AI IoT Congress (AIIoT), FACE Project, University of Siegen, Germany",
      "pdf_url": "https://arxiv.org/pdf/2510.12541v1",
      "published_date": "2025-10-14 14:04:13 UTC",
      "updated_date": "2025-10-14 14:04:13 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:23:54.996697+00:00"
    },
    {
      "arxiv_id": "2510.12537v1",
      "title": "Unconditional Human Motion and Shape Generation via Balanced Score-Based Diffusion",
      "title_zh": "åŸºäºå¹³è¡¡åˆ†æ•°æ‰©æ•£æ¨¡å‹çš„æ— æ¡ä»¶äººä½“è¿åŠ¨ä¸å½¢çŠ¶ç”Ÿæˆ",
      "authors": [
        "David BjÃ¶rkstrand",
        "Tiesheng Wang",
        "Lars Bretzner",
        "Josephine Sullivan"
      ],
      "abstract": "Recent work has explored a range of model families for human motion generation, including Variational Autoencoders (VAEs), Generative Adversarial Networks (GANs), and diffusion-based models. Despite their differences, many methods rely on over-parameterized input features and auxiliary losses to improve empirical results. These strategies should not be strictly necessary for diffusion models to match the human motion distribution. We show that on par with state-of-the-art results in unconditional human motion generation are achievable with a score-based diffusion model using only careful feature-space normalization and analytically derived weightings for the standard L2 score-matching loss, while generating both motion and shape directly, thereby avoiding slow post hoc shape recovery from joints. We build the method step by step, with a clear theoretical motivation for each component, and provide targeted ablations demonstrating the effectiveness of each proposed addition in isolation.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†æ— æ¡ä»¶äººä½“è¿åŠ¨ä¸å½¢çŠ¶ç”Ÿæˆ(Unconditional Human Motion and Shape Generation)ï¼Œæå‡ºäº†ä¸€ç§åŸºäºå¹³è¡¡å¾—åˆ†çš„æ‰©æ•£æ¨¡å‹(Balanced Score-Based Diffusion)ã€‚é’ˆå¯¹ç°æœ‰æ–¹æ³•è¿‡åº¦ä¾èµ–è¶…å‚æ•°åŒ–è¾“å…¥ç‰¹å¾å’Œè¾…åŠ©æŸå¤±(Auxiliary losses)çš„é—®é¢˜ï¼Œè¯¥ç ”ç©¶è¯æ˜ä»…é€šè¿‡æ‰©æ•£æ¨¡å‹æœ¬èº«å³å¯æœ‰æ•ˆåŒ¹é…äººä½“è¿åŠ¨åˆ†å¸ƒã€‚æ–¹æ³•æ ¸å¿ƒé‡‡ç”¨äº†ç²¾ç»†çš„ç‰¹å¾ç©ºé—´å½’ä¸€åŒ–(Feature-space normalization)ä»¥åŠä¸ºæ ‡å‡†L2è¯„åˆ†åŒ¹é…æŸå¤±(L2 score-matching loss)è®¾è®¡çš„è§£ææ¨å¯¼æƒé‡ã€‚è¯¥æ¨¡å‹èƒ½å¤Ÿç›´æ¥åŒæ—¶ç”Ÿæˆè¿åŠ¨å’Œå½¢çŠ¶ï¼Œä»è€Œé¿å…äº†ä»å…³èŠ‚è¿›è¡Œç¼“æ…¢çš„åæœŸå½¢çŠ¶æ¢å¤(Post hoc shape recovery)è¿‡ç¨‹ã€‚ç ”ç©¶è€…é€šè¿‡é€æ­¥æ„å»ºçš„æ–¹å¼ä¸ºæ¯ä¸ªç»„ä»¶æä¾›äº†æ¸…æ™°çš„ç†è®ºåŠ¨æœºï¼Œå¹¶é€šè¿‡é’ˆå¯¹æ€§çš„æ¶ˆèå®éªŒ(Ablations)éªŒè¯äº†å„æ¨¡å—çš„æœ‰æ•ˆæ€§ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨æ— æ¡ä»¶äººä½“è¿åŠ¨ç”Ÿæˆä»»åŠ¡ä¸Šè¾¾åˆ°äº†ä¸å½“å‰æœ€å…ˆè¿›æŠ€æœ¯(State-of-the-art)ç›¸å½“çš„æ°´å¹³ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.12537v1",
      "published_date": "2025-10-14 14:02:22 UTC",
      "updated_date": "2025-10-14 14:02:22 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:23:56.587450+00:00"
    },
    {
      "arxiv_id": "2510.12534v3",
      "title": "ProtoSiTex: Learning Semi-Interpretable Prototypes for Multi-label Text Classification",
      "title_zh": "ProtoSiTexï¼šé¢å‘å¤šæ ‡ç­¾æ–‡æœ¬åˆ†ç±»çš„åŠå¯è§£é‡ŠåŸå‹å­¦ä¹ ",
      "authors": [
        "Utsav Kumar Nareti",
        "Suraj Kumar",
        "Soumya Pandey",
        "Soumi Chattopadhyay",
        "Chandranath Adak"
      ],
      "abstract": "The rapid growth of user-generated text across digital platforms has intensified the need for interpretable models capable of fine-grained text classification and explanation. Existing prototype-based models offer intuitive explanations but typically operate at coarse granularity (sentence or document level) and fail to address the multi-label nature of real-world text classification. We propose ProtoSiTex, a semi-interpretable framework designed for fine-grained multi-label text classification. ProtoSiTex employs a dual-phase alternate training strategy: an unsupervised prototype discovery phase that learns semantically coherent and diverse prototypes, and a supervised classification phase that maps these prototypes to class labels. A hierarchical loss function enforces consistency across subsentence, sentence, and document levels, enhancing interpretability and alignment. Unlike prior approaches, ProtoSiTex captures overlapping and conflicting semantics using adaptive prototypes and multi-head attention. We also introduce a benchmark dataset of hotel reviews annotated at the subsentence level with multiple labels. Experiments on this dataset and two public benchmarks (binary and multi-class) show that ProtoSiTex achieves state-of-the-art performance while delivering faithful, human-aligned explanations, establishing it as a robust solution for semi-interpretable multi-label text classification.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† ProtoSiTexï¼Œè¿™æ˜¯ä¸€ä¸ªä¸“ä¸ºç»†ç²’åº¦å¤šæ ‡ç­¾æ–‡æœ¬åˆ†ç±» (Multi-label Text Classification) è®¾è®¡çš„åŠå¯è§£é‡Š (Semi-interpretable) æ¡†æ¶ã€‚ç°æœ‰åŸºäºåŸå‹çš„æ¨¡å‹é€šå¸¸ä»…åœ¨ç²—ç²’åº¦å±‚é¢è¿è¡Œï¼Œéš¾ä»¥å¤„ç†ç°å®ä¸–ç•Œä¸­çš„å¤šæ ‡ç­¾ä»»åŠ¡ï¼Œè€Œ ProtoSiTex æ—¨åœ¨æä¾›ç›´è§‚ä¸”ç»†è‡´çš„è§£é‡Šã€‚è¯¥æ¡†æ¶é‡‡ç”¨åŒé˜¶æ®µäº¤æ›¿è®­ç»ƒç­–ç•¥ï¼Œé¦–å…ˆé€šè¿‡æ— ç›‘ç£é˜¶æ®µå­¦ä¹ è¯­ä¹‰è¿è´¯çš„åŸå‹ï¼Œå†é€šè¿‡ç›‘ç£é˜¶æ®µå°†åŸå‹æ˜ å°„è‡³ç±»åˆ«æ ‡ç­¾ã€‚åˆ©ç”¨åˆ†å±‚æŸå¤±å‡½æ•° (Hierarchical Loss Function) ç¡®ä¿å­å¥ã€å¥å­å’Œæ–‡æ¡£çº§åˆ«çš„ä¸€è‡´æ€§ï¼Œå¢å¼ºäº†æ¨¡å‹çš„å¯è§£é‡Šæ€§ã€‚ä¸ä»¥å¾€æ–¹æ³•ä¸åŒï¼ŒProtoSiTex ç»“åˆè‡ªé€‚åº”åŸå‹å’Œå¤šå¤´æ³¨æ„åŠ› (Multi-head Attention) æœºåˆ¶æ¥æ•æ‰é‡å æˆ–å†²çªçš„è¯­ä¹‰ã€‚ç ”ç©¶äººå‘˜è¿˜å¼•å…¥äº†ä¸€ä¸ªåœ¨å­å¥çº§åˆ«æ ‡æ³¨çš„å¤šæ ‡ç­¾é…’åº—è¯„è®ºåŸºå‡†æ•°æ®é›†ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒProtoSiTex åœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­å‡è¾¾åˆ°äº†æœ€å…ˆè¿› (State-of-the-art) çš„æ€§èƒ½æ°´å¹³ã€‚è¯¥æ¨¡å‹èƒ½å¤Ÿæä¾›å¿ å®ä¸”ç¬¦åˆäººç±»è®¤çŸ¥çš„è§£é‡Šï¼Œä¸ºå¤šæ ‡ç­¾æ–‡æœ¬åˆ†ç±»æä¾›äº†å¼ºæœ‰åŠ›çš„åŠå¯è§£é‡Šæ–¹æ¡ˆã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.12534v3",
      "published_date": "2025-10-14 13:59:28 UTC",
      "updated_date": "2025-12-18 11:14:07 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:23:59.682907+00:00"
    },
    {
      "arxiv_id": "2510.12516v1",
      "title": "BoN Appetit Team at LeWiDi-2025: Best-of-N Test-time Scaling Can Not Stomach Annotation Disagreements (Yet)",
      "title_zh": "BoN Appetit å›¢é˜Ÿåœ¨ LeWiDi-2025ï¼šBest-of-N æ¨ç†æ—¶æ‰©å±•ç›®å‰å°šæ— æ³•æœ‰æ•ˆåº”å¯¹æ ‡æ³¨åˆ†æ­§",
      "authors": [
        "Tomas Ruiz",
        "Siyao Peng",
        "Barbara Plank",
        "Carsten Schwemmer"
      ],
      "abstract": "Test-time scaling is a family of techniques to improve LLM outputs at inference time by performing extra computation. To the best of our knowledge, test-time scaling has been limited to domains with verifiably correct answers, like mathematics and coding. We transfer test-time scaling to the LeWiDi-2025 tasks to evaluate annotation disagreements. We experiment with three test-time scaling methods: two benchmark algorithms (Model Averaging and Majority Voting), and a Best-of-N sampling method. The two benchmark methods improve LLM performance consistently on the LeWiDi tasks, but the Best-of-N method does not. Our experiments suggest that the Best-of-N method does not currently transfer from mathematics to LeWiDi tasks, and we analyze potential reasons for this gap.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†æµ‹è¯•æ—¶ç¼©æ”¾(Test-time scaling)æŠ€æœ¯åœ¨å¤„ç†æ ‡æ³¨æ­§ä¹‰(annotation disagreements)ä»»åŠ¡ä¸­çš„åº”ç”¨ï¼Œç‰¹åˆ«æ˜¯é’ˆå¯¹LeWiDi-2025æŒ‘æˆ˜èµ›ã€‚ä¼ ç»Ÿä¸Šï¼Œè¿™ç±»é€šè¿‡æ¨ç†æ—¶é¢å¤–è®¡ç®—æ¥æå‡æ¨¡å‹è¾“å‡ºçš„æŠ€æœ¯ä¸»è¦é™äºæ•°å­¦å’Œä»£ç ç­‰æœ‰ç¡®å®šç­”æ¡ˆçš„é¢†åŸŸï¼Œè€Œæœ¬é¡¹å·¥ä½œå°è¯•å°†å…¶è¿ç§»è‡³è¯„ä¼°æ ‡æ³¨åˆ†æ­§ã€‚ç ”ç©¶å›¢é˜Ÿå®éªŒäº†ä¸‰ç§æ–¹æ³•ï¼ŒåŒ…æ‹¬åŸºå‡†ç®—æ³•æ¨¡å‹å¹³å‡(Model Averaging)ã€å¤šæ•°æŠ•ç¥¨(Majority Voting)ä»¥åŠBest-of-Né‡‡æ ·æ–¹æ³•ã€‚ç»“æœè¡¨æ˜ï¼Œå‰ä¸¤ç§åŸºå‡†æ–¹æ³•åœ¨LeWiDiä»»åŠ¡ä¸Šèƒ½æŒç»­æå‡æ¨¡å‹æ€§èƒ½ï¼Œä½†Best-of-Næ–¹æ³•çš„æ•ˆæœå¹¶ä¸ç†æƒ³ã€‚è¯¥ç ”ç©¶æ­ç¤ºäº†Best-of-Næ–¹æ³•ç›®å‰å°šæ— æ³•ä»æ•°å­¦é¢†åŸŸç›´æ¥æœ‰æ•ˆè¿ç§»è‡³æ ‡æ³¨æ­§ä¹‰ä»»åŠ¡ï¼Œå¹¶å¯¹äº§ç”Ÿè¿™ç§å·®è·çš„æ½œåœ¨åŸå› è¿›è¡Œäº†æ·±å…¥åˆ†æã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.12516v1",
      "published_date": "2025-10-14 13:43:08 UTC",
      "updated_date": "2025-10-14 13:43:08 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:24:03.302866+00:00"
    },
    {
      "arxiv_id": "2510.12858v2",
      "title": "A Critical Review of the Need for Knowledge-Centric Evaluation of Quranic Recitation",
      "title_zh": "å¤å…°ç»è¯µè¯»ä»¥çŸ¥è¯†ä¸ºä¸­å¿ƒè¯„ä¼°å¿…è¦æ€§çš„æ‰¹åˆ¤æ€§è¯„è¿°",
      "authors": [
        "Mohammed Hilal Al-Kharusi",
        "Khizar Hayat",
        "Khalil Bader Al Ruqeishi",
        "Haroon Rashid Lone"
      ],
      "abstract": "The art and science of Quranic recitation (Tajweed), a discipline governed by meticulous phonetic, rhythmic, and theological principles, confronts substantial educational challenges in today's digital age. Although modern technology offers unparalleled opportunities for learning, existing automated systems for evaluating recitation have struggled to gain broad acceptance or demonstrate educational effectiveness. This literature review examines this crucial disparity, offering a thorough analysis of scholarly research, digital platforms, and commercial tools developed over the past twenty years. Our analysis uncovers a fundamental flaw in current approaches that adapt Automatic Speech Recognition (ASR) systems, which emphasize word identification over qualitative acoustic evaluation. These systems suffer from limitations such as reliance on biased datasets, demographic disparities, and an inability to deliver meaningful feedback for improvement. Challenging these data-centric methodologies, we advocate for a paradigm shift toward a knowledge-based computational framework. By leveraging the unchanging nature of the Quranic text and the well-defined rules of Tajweed, we propose that an effective evaluation system should be built upon rule-based acoustic modeling centered on canonical pronunciation principles and articulation points (Makhraj), rather than depending on statistical patterns derived from flawed or biased data. The review concludes that the future of automated Quranic recitation assessment lies in hybrid systems that combine linguistic expertise with advanced audio processing. Such an approach paves the way for developing reliable, fair, and pedagogically effective tools that can authentically assist learners across the globe.",
      "tldr_zh": "æœ¬ç»¼è¿°æ¢è®¨äº†å¤å…°ç»è¯µè¯»(Tajweed)åœ¨æ•°å­—åŒ–æ•™è‚²æ—¶ä»£é¢ä¸´çš„æŒ‘æˆ˜ï¼ŒæŒ‡å‡ºç›®å‰çš„è‡ªåŠ¨è¯„ä¼°ç³»ç»Ÿå› ç¼ºä¹æ•™å­¦æœ‰æ•ˆæ€§è€Œéš¾ä»¥è·å¾—å¹¿æ³›è®¤å¯ã€‚ç ”ç©¶åˆ†æå‘ç°ï¼Œç°æœ‰åŸºäºè‡ªåŠ¨è¯­éŸ³è¯†åˆ«(Automatic Speech Recognition)çš„æ–¹æ³•å­˜åœ¨æ ¹æœ¬ç¼ºé™·ï¼Œå…¶è¿‡åº¦å¼ºè°ƒå•è¯è¯†åˆ«è€Œå¿½è§†äº†å®šæ€§çš„å£°å­¦è¯„ä¼°ï¼Œä¸”å—é™äºæ•°æ®é›†åè§å’Œåé¦ˆæœºåˆ¶çš„ç¼ºå¤±ã€‚ä¸ºæ­¤ï¼Œä½œè€…å€¡å¯¼ä»æ•°æ®ä¸­å¿ƒ(data-centric)è½¬å‘ä»¥çŸ¥è¯†ä¸ºä¸­å¿ƒ(knowledge-based)çš„è®¡ç®—æ¡†æ¶ï¼Œåˆ©ç”¨æ˜ç¡®çš„ Tajweed è§„åˆ™å»ºç«‹åŸºäºå‘éŸ³éƒ¨ä½(Makhraj)å’Œè§„èŒƒå‘éŸ³åŸåˆ™çš„è§„åˆ™å£°å­¦å»ºæ¨¡(rule-based acoustic modeling)ã€‚ç»¼è¿°æœ€åå¼ºè°ƒï¼Œè‡ªåŠ¨è¯µè¯»è¯„ä¼°çš„æœªæ¥åœ¨äºç»“åˆè¯­è¨€å­¦ä¸“ä¸šçŸ¥è¯†ä¸å…ˆè¿›éŸ³é¢‘å¤„ç†æŠ€æœ¯çš„æ··åˆç³»ç»Ÿã€‚è¿™ç§èŒƒå¼è½¬ç§»å°†æœ‰åŠ©äºå¼€å‘å‡ºæ›´å¯é ã€å…¬å¹³ä¸”å…·æœ‰æ•™å­¦ä»·å€¼çš„å·¥å…·ï¼Œä¸ºå…¨çƒå­¦ä¹ è€…æä¾›çœŸå®çš„è¾…åŠ©ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.SD"
      ],
      "primary_category": "cs.CL",
      "comment": "32 pages",
      "pdf_url": "https://arxiv.org/pdf/2510.12858v2",
      "published_date": "2025-10-14 13:39:49 UTC",
      "updated_date": "2025-11-13 04:52:37 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:24:08.000014+00:00"
    },
    {
      "arxiv_id": "2510.12503v1",
      "title": "The Robustness of Differentiable Causal Discovery in Misspecified Scenarios",
      "title_zh": "å¯å¾®å› æœå‘ç°åœ¨æ¨¡å‹è¯¯è®¾å®šåœºæ™¯ä¸‹çš„é²æ£’æ€§",
      "authors": [
        "Huiyang Yi",
        "Yanyan He",
        "Duxin Chen",
        "Mingyu Kang",
        "He Wang",
        "Wenwu Yu"
      ],
      "abstract": "Causal discovery aims to learn causal relationships between variables from targeted data, making it a fundamental task in machine learning. However, causal discovery algorithms often rely on unverifiable causal assumptions, which are usually difficult to satisfy in real-world data, thereby limiting the broad application of causal discovery in practical scenarios. Inspired by these considerations, this work extensively benchmarks the empirical performance of various mainstream causal discovery algorithms, which assume i.i.d. data, under eight model assumption violations. Our experimental results show that differentiable causal discovery methods exhibit robustness under the metrics of Structural Hamming Distance and Structural Intervention Distance of the inferred graphs in commonly used challenging scenarios, except for scale variation. We also provide the theoretical explanations for the performance of differentiable causal discovery methods. Finally, our work aims to comprehensively benchmark the performance of recent differentiable causal discovery methods under model assumption violations, and provide the standard for reasonable evaluation of causal discovery, as well as to further promote its application in real-world scenarios.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å¯å¾®å› æœå‘ç° (Differentiable Causal Discovery) åœ¨æ¨¡å‹å‡è®¾ä¸æˆç«‹ (Misspecified Scenarios) æ—¶çš„é²æ£’æ€§é—®é¢˜ã€‚é’ˆå¯¹çœŸå®ä¸–ç•Œæ•°æ®éš¾ä»¥æ»¡è¶³ä¸å¯éªŒè¯çš„å› æœå‡è®¾è¿™ä¸€æŒ‘æˆ˜ï¼Œè¯¥å·¥ä½œå¯¹ä¸»æµå› æœå‘ç°ç®—æ³•åœ¨å…«ç§æ¨¡å‹å‡è®¾è¿è§„æƒ…å†µä¸‹çš„è¡¨ç°è¿›è¡Œäº†å¹¿æ³›çš„åŸºå‡†æµ‹è¯•ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œåœ¨å¸¸è§çš„æŒ‘æˆ˜æ€§åœºæ™¯ä¸­ï¼Œå¯å¾®å› æœå‘ç°æ–¹æ³•åœ¨æ¨æ–­å›¾çš„ç»“æ„æ±‰æ˜è·ç¦» (Structural Hamming Distance) å’Œç»“æ„å¹²é¢„è·ç¦» (Structural Intervention Distance) æŒ‡æ ‡ä¸Šè¡¨ç°å‡ºè¾ƒå¼ºçš„é²æ£’æ€§ï¼Œä½†åœ¨å°ºåº¦å˜åŒ– (Scale Variation) åœºæ™¯ä¸‹é™¤å¤–ã€‚ç ”ç©¶è¿˜ä¸ºå¯å¾®å› æœå‘ç°æ–¹æ³•çš„æ€§èƒ½æä¾›äº†ç†è®ºè§£é‡Šï¼Œåˆ†æäº†å…¶åœ¨æ¨¡å‹å¤±é…ä¸‹çš„æœ‰æ•ˆæ€§ã€‚è¯¥å·¥ä½œé€šè¿‡å…¨é¢è¯„ä¼°è¿‘æœŸå¯å¾®å› æœå‘ç°æ–¹æ³•åœ¨å‡è®¾è¿è§„ä¸‹çš„è¡¨ç°ï¼Œä¸ºå› æœå‘ç°çš„åˆç†è¯„ä»·æä¾›äº†æ ‡å‡†ï¼Œå¹¶è¿›ä¸€æ­¥æ¨åŠ¨äº†å…¶åœ¨å®é™…åœºæ™¯ä¸­çš„åº”ç”¨ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ME",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "accepted to ICLR 2025",
      "pdf_url": "https://arxiv.org/pdf/2510.12503v1",
      "published_date": "2025-10-14 13:33:06 UTC",
      "updated_date": "2025-10-14 13:33:06 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:24:08.178873+00:00"
    },
    {
      "arxiv_id": "2510.12498v2",
      "title": "Artificial Intelligence Virtual Cells: From Measurements to Decisions across Modality, Scale, Dynamics, and Evaluation",
      "title_zh": "äººå·¥æ™ºèƒ½è™šæ‹Ÿç»†èƒï¼šè·¨æ¨¡æ€ã€å°ºåº¦ã€åŠ¨æ€ä¸è¯„ä¼°ï¼Œä»æµ‹é‡åˆ°å†³ç­–",
      "authors": [
        "Chengpeng Hu",
        "Calvin Yu-Chian Chen"
      ],
      "abstract": "Artificial Intelligence Virtual Cells (AIVCs) aim to learn executable, decision-relevant models of cell state from multimodal, multiscale measurements. Recent studies have introduced single-cell and spatial foundation models, improved cross-modality alignment, scaled perturbation atlases, and explored pathway-level readouts. Nevertheless, although held-out validation is standard practice, evaluations remain predominantly within single datasets and settings; evidence indicates that transport across laboratories and platforms is often limited, that some data splits are vulnerable to leakage and coverage bias, and that dose, time and combination effects are not yet systematically handled. Cross-scale coupling also remains constrained, as anchors linking molecular, cellular and tissue levels are sparse, and alignment to scientific or clinical readouts varies across studies. We propose a model-agnostic Cell-State Latent (CSL) perspective that organizes learning via an operator grammar: measurement, lift/project for cross-scale coupling, and intervention for dosing and scheduling. This view motivates a decision-aligned evaluation blueprint across modality, scale, context and intervention, and emphasizes function-space readouts such as pathway activity, spatial neighborhoods and clinically relevant endpoints. We recommend operator-aware data design, leakage-resistant partitions, and transparent calibration and reporting to enable reproducible, like-for-like comparisons.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†äººå·¥æ™ºèƒ½è™šæ‹Ÿç»†èƒ (Artificial Intelligence Virtual Cells, AIVCs) åœ¨ä»å¤šæ¨¡æ€ã€å¤šå°ºåº¦æµ‹é‡ä¸­å­¦ä¹ å¯æ‰§è¡Œä¸”ä¸å†³ç­–ç›¸å…³çš„ç»†èƒçŠ¶æ€æ¨¡å‹æ–¹é¢çš„åº”ç”¨ä¸æŒ‘æˆ˜ã€‚å°½ç®¡å•ç»†èƒå’Œç©ºé—´åŸºç¡€æ¨¡å‹ (foundation models) æœ‰æ‰€è¿›å±•ï¼Œä½†åœ¨è·¨å®éªŒå®¤è¿ç§»æ€§ã€æ•°æ®æ³„éœ²åå·®ä»¥åŠå¤„ç†å‰‚é‡ã€æ—¶é—´å’Œç»„åˆæ•ˆåº”ç­‰æ–¹é¢ä»å­˜åœ¨æ˜¾è‘—å±€é™ã€‚ä¸ºæ­¤ï¼Œä½œè€…æå‡ºäº†ä¸€ç§æ¨¡å‹æ— å…³çš„ç»†èƒçŠ¶æ€æ½œå˜é‡ (Cell-State Latent, CSL) è§†è§’ï¼Œé€šè¿‡ç®—å­è¯­æ³• (operator grammar) ç»„ç»‡å­¦ä¹ ï¼Œæ¶µç›–æµ‹é‡ã€è·¨å°ºåº¦è€¦åˆçš„æå‡/æŠ•å½± (lift/project) ä»¥åŠç»™è¯ä¸è°ƒåº¦çš„å¹²é¢„ (intervention)ã€‚è¯¥æ¡†æ¶æ¨åŠ¨äº†è·¨æ¨¡æ€ã€å°ºåº¦ã€èƒŒæ™¯å’Œå¹²é¢„çš„å†³ç­–å¯¹é½è¯„ä¼°è“å›¾ï¼Œé‡ç‚¹å…³æ³¨é€šè·¯æ´»æ€§ (pathway activity)ã€ç©ºé—´é‚»åŸŸå’Œä¸´åºŠç›¸å…³ç»ˆç‚¹ç­‰åŠŸèƒ½ç©ºé—´è¯»æ•°ã€‚ç ”ç©¶æœ€åå»ºè®®é‡‡ç”¨ç®—å­æ„ŸçŸ¥çš„æ•°æ®è®¾è®¡ã€æŠ—æ³„éœ²åˆ†åŒºä»¥åŠé€æ˜çš„æ ¡å‡†ä¸æŠ¥å‘Šï¼Œä»¥å®ç°å¯é‡å¤çš„åŒç±»æ¯”è¾ƒå¹¶ç¡®ä¿ AIVCs çš„ç§‘å­¦ä¸¥è°¨æ€§ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.12498v2",
      "published_date": "2025-10-14 13:31:40 UTC",
      "updated_date": "2025-12-02 08:44:52 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:24:25.589261+00:00"
    },
    {
      "arxiv_id": "2510.12494v1",
      "title": "PubSub-VFL: Towards Efficient Two-Party Split Learning in Heterogeneous Environments via Publisher/Subscriber Architecture",
      "title_zh": "PubSub-VFLï¼šåŸºäºå‘å¸ƒ/è®¢é˜…æ¶æ„çš„å¼‚æ„ç¯å¢ƒé«˜æ•ˆä¸¤æ–¹æ‹†åˆ†å­¦ä¹ ",
      "authors": [
        "Yi Liu",
        "Yang Liu",
        "Leqian Zheng",
        "Jue Hong",
        "Junjie Shi",
        "Qingyou Yang",
        "Ye Wu",
        "Cong Wang"
      ],
      "abstract": "With the rapid advancement of the digital economy, data collaboration between organizations has become a well-established business model, driving the growth of various industries. However, privacy concerns make direct data sharing impractical. To address this, Two-Party Split Learning (a.k.a. Vertical Federated Learning (VFL)) has emerged as a promising solution for secure collaborative learning. Despite its advantages, this architecture still suffers from low computational resource utilization and training efficiency. Specifically, its synchronous dependency design increases training latency, while resource and data heterogeneity among participants further hinder efficient computation. To overcome these challenges, we propose PubSub-VFL, a novel VFL paradigm with a Publisher/Subscriber architecture optimized for two-party collaborative learning with high computational efficiency. PubSub-VFL leverages the decoupling capabilities of the Pub/Sub architecture and the data parallelism of the parameter server architecture to design a hierarchical asynchronous mechanism, reducing training latency and improving system efficiency. Additionally, to mitigate the training imbalance caused by resource and data heterogeneity, we formalize an optimization problem based on participants' system profiles, enabling the selection of optimal hyperparameters while preserving privacy. We conduct a theoretical analysis to demonstrate that PubSub-VFL achieves stable convergence and is compatible with security protocols such as differential privacy. Extensive case studies on five benchmark datasets further validate its effectiveness, showing that, compared to state-of-the-art baselines, PubSub-VFL not only accelerates training by $2 \\sim 7\\times$ without compromising accuracy, but also achieves a computational resource utilization rate of up to 91.07%.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ä¸¤æ–¹çºµå‘è”é‚¦å­¦ä¹  (Vertical Federated Learning, VFL) åœ¨å¼‚æ„ç¯å¢ƒä¸‹ç”±äºåŒæ­¥ä¾èµ–å¯¼è‡´çš„è®¡ç®—èµ„æºåˆ©ç”¨ç‡ä½å’Œè®­ç»ƒå»¶è¿Ÿé«˜ç­‰æŒ‘æˆ˜ï¼Œæå‡ºäº† PubSub-VFL æ¶æ„ã€‚è¯¥æ¡†æ¶é€šè¿‡å¼•å…¥å‘å¸ƒ/è®¢é˜… (Publisher/Subscriber) æ¨¡å¼ä¸å‚æ•°æœåŠ¡å™¨ (Parameter Server) çš„æ•°æ®å¹¶è¡Œæ€§ï¼Œè®¾è®¡äº†ä¸€ç§å±‚æ¬¡åŒ–å¼‚æ­¥æœºåˆ¶ï¼Œæœ‰æ•ˆå®ç°äº†è®¡ç®—è§£è€¦å¹¶æ˜¾è‘—é™ä½äº†ç³»ç»Ÿå»¶è¿Ÿã€‚ä¸ºåº”å¯¹å‚ä¸æ–¹çš„èµ„æºå’Œæ•°æ®å¼‚æ„æ€§ï¼Œè®ºæ–‡è¿›ä¸€æ­¥å»ºç«‹ä¼˜åŒ–æ¨¡å‹ï¼Œæ ¹æ®ç³»ç»Ÿæ¦‚å†µ (System Profiles) åŠ¨æ€è°ƒæ•´è¶…å‚æ•°ä»¥å¹³è¡¡è®­ç»ƒè¿›åº¦å¹¶ä¿æŠ¤éšç§ã€‚ç†è®ºè¯æ˜è¯¥æ–¹æ¡ˆå…·å¤‡ç¨³å®šçš„æ”¶æ•›æ€§ï¼Œå¹¶èƒ½è‰¯å¥½å…¼å®¹å·®åˆ†éšç§ (Differential Privacy) ç­‰å®‰å…¨åè®®ã€‚åœ¨äº”ä¸ªåŸºå‡†æ•°æ®é›†ä¸Šçš„å®éªŒæ˜¾ç¤ºï¼ŒPubSub-VFL åœ¨ç»´æŒæ¨¡å‹ç²¾åº¦çš„åŒæ—¶ï¼Œå°†è®­ç»ƒé€Ÿåº¦æå‡äº† 2 è‡³ 7 å€ï¼Œä¸”è®¡ç®—èµ„æºåˆ©ç”¨ç‡æœ€é«˜å¯è¾¾ 91.07%ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DC"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at NeurIPS 2025",
      "pdf_url": "https://arxiv.org/pdf/2510.12494v1",
      "published_date": "2025-10-14 13:27:33 UTC",
      "updated_date": "2025-10-14 13:27:33 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:24:27.270255+00:00"
    },
    {
      "arxiv_id": "2510.12490v1",
      "title": "Using Medical Algorithms for Task-Oriented Dialogue in LLM-Based Medical Interviews",
      "title_zh": "åŸºäºå¤§è¯­è¨€æ¨¡å‹çš„åŒ»å­¦é—®è¯Šä¸­é¢å‘ä»»åŠ¡å¯¹è¯çš„åŒ»å­¦ç®—æ³•åº”ç”¨",
      "authors": [
        "Rui Reis",
        "Pedro Rangel Henriques",
        "JoÃ£o Ferreira-Coimbra",
        "Eva Oliveira",
        "Nuno F. Rodrigues"
      ],
      "abstract": "We developed a task-oriented dialogue framework structured as a Directed Acyclic Graph (DAG) of medical questions. The system integrates: (1) a systematic pipeline for transforming medical algorithms and guidelines into a clinical question corpus; (2) a cold-start mechanism based on hierarchical clustering to generate efficient initial questioning without prior patient information; (3) an expand-and-prune mechanism enabling adaptive branching and backtracking based on patient responses; (4) a termination logic to ensure interviews end once sufficient information is gathered; and (5) automated synthesis of doctor-friendly structured reports aligned with clinical workflows. Human-computer interaction principles guided the design of both the patient and physician applications. Preliminary evaluation involved five physicians using standardized instruments: NASA-TLX (cognitive workload), the System Usability Scale (SUS), and the Questionnaire for User Interface Satisfaction (QUIS). The patient application achieved low workload scores (NASA-TLX = 15.6), high usability (SUS = 86), and strong satisfaction (QUIS = 8.1/9), with particularly high ratings for ease of learning and interface design. The physician application yielded moderate workload (NASA-TLX = 26) and excellent usability (SUS = 88.5), with satisfaction scores of 8.3/9. Both applications demonstrated effective integration into clinical workflows, reducing cognitive demand and supporting efficient report generation. Limitations included occasional system latency and a small, non-diverse evaluation sample.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ä¸ªåŸºäºæœ‰å‘æ— ç¯å›¾(Directed Acyclic Graph, DAG)çš„ä»»åŠ¡å¯¼å‘å‹å¯¹è¯æ¡†æ¶ï¼Œæ—¨åœ¨åˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹(LLM)ä¼˜åŒ–åŒ»ç–—é¢è°ˆæµç¨‹ã€‚ç³»ç»Ÿæ•´åˆäº†å°†åŒ»ç–—ç®—æ³•å’ŒæŒ‡å—è½¬åŒ–ä¸ºä¸´åºŠé—®é¢˜åº“çš„è‡ªåŠ¨åŒ–ç®¡çº¿ï¼Œå¹¶åˆ©ç”¨åŸºäºå±‚æ¬¡èšç±»(Hierarchical Clustering)çš„å†·å¯åŠ¨æœºåˆ¶åœ¨æ— æ‚£è€…å…ˆéªŒä¿¡æ¯çš„æƒ…å†µä¸‹å®ç°é«˜æ•ˆæé—®ã€‚æ¡†æ¶é€šè¿‡æ‰©å±•ä¸å‰ªæ(Expand-and-Prune)æœºåˆ¶å®ç°è‡ªé€‚åº”åˆ†æ”¯ä¸å›æº¯ï¼Œç»“åˆç»ˆæ­¢é€»è¾‘ç¡®ä¿ä¿¡æ¯è·å–å……åˆ†ï¼Œå¹¶èƒ½è‡ªåŠ¨åˆæˆç¬¦åˆä¸´åºŠå·¥ä½œæµçš„ç»“æ„åŒ–æŠ¥å‘Šã€‚é€šè¿‡NASA-TLXã€ç³»ç»Ÿå¯ç”¨æ€§é‡è¡¨(SUS)å’Œç”¨æˆ·ç•Œé¢æ»¡æ„åº¦é—®å·(QUIS)è¯„ä¼°ï¼Œæ‚£è€…ç«¯åº”ç”¨è¡¨ç°å‡ºæä½çš„è®¤çŸ¥è´Ÿè·å’Œé«˜å¯ç”¨æ€§ï¼ŒåŒ»ç”Ÿç«¯åº”ç”¨åˆ™å±•ç°äº†å“è¶Šçš„å¯ç”¨æ€§(SUS=88.5)å’Œé«˜æ»¡æ„åº¦ã€‚å®éªŒç»“æœè¯æ˜ï¼Œè¯¥æ¡†æ¶èƒ½æœ‰æ•ˆå‡è½»åŒ»ç”Ÿçš„è®¤çŸ¥éœ€æ±‚å¹¶æ”¯æŒé«˜æ•ˆæŠ¥å‘Šç”Ÿæˆï¼Œä¸ºåŒ»ç–—äººå·¥æ™ºèƒ½è¾…åŠ©è¯Šæ–­æä¾›äº†å¯è¡Œçš„æŠ€æœ¯è·¯å¾„ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.12490v1",
      "published_date": "2025-10-14 13:24:21 UTC",
      "updated_date": "2025-10-14 13:24:21 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:24:28.082571+00:00"
    },
    {
      "arxiv_id": "2510.12482v1",
      "title": "A Text-Image Fusion Method with Data Augmentation Capabilities for Referring Medical Image Segmentation",
      "title_zh": "ä¸€ç§å…·æœ‰æ•°æ®å¢å¼ºèƒ½åŠ›çš„æŒ‡å‘æ€§åŒ»å­¦å›¾åƒåˆ†å‰²å›¾æ–‡èåˆæ–¹æ³•",
      "authors": [
        "Shurong Chai",
        "Rahul Kumar JAIN",
        "Rui Xu",
        "Shaocong Mo",
        "Ruibo Hou",
        "Shiyu Teng",
        "Jiaqing Liu",
        "Lanfen Lin",
        "Yen-Wei Chen"
      ],
      "abstract": "Deep learning relies heavily on data augmentation to mitigate limited data, especially in medical imaging. Recent multimodal learning integrates text and images for segmentation, known as referring or text-guided image segmentation. However, common augmentations like rotation and flipping disrupt spatial alignment between image and text, weakening performance. To address this, we propose an early fusion framework that combines text and visual features before augmentation, preserving spatial consistency. We also design a lightweight generator that projects text embeddings into visual space, bridging semantic gaps. Visualization of generated pseudo-images shows accurate region localization. Our method is evaluated on three medical imaging tasks and four segmentation frameworks, achieving state-of-the-art results. Code is publicly available on GitHub: https://github.com/11yxk/MedSeg_EarlyFusion.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§å…·æœ‰æ•°æ®å¢å¼ºèƒ½åŠ›çš„æ–‡æœ¬-å›¾åƒèåˆæ–¹æ³•ï¼Œæ—¨åœ¨è§£å†³æŒ‡ä»£æ€§åŒ»å­¦å›¾åƒåˆ†å‰²(Referring Medical Image Segmentation)ä¸­ç”±äºæ—‹è½¬ã€ç¿»è½¬ç­‰ä¼ ç»Ÿå¢å¼ºæ“ä½œå¯¼è‡´å›¾æ–‡ç©ºé—´å¯¹é½å¤±æ•ˆçš„é—®é¢˜ã€‚ä¸ºäº†åº”å¯¹è¿™ä¸€æŒ‘æˆ˜ï¼Œç ”ç©¶è€…æå‡ºäº†ä¸€ç§æ—©èåˆ(Early Fusion)æ¡†æ¶ï¼Œåœ¨æ‰§è¡Œæ•°æ®å¢å¼ºä¹‹å‰ç»“åˆæ–‡æœ¬ä¸è§†è§‰ç‰¹å¾ï¼Œä»è€Œç¡®ä¿ç©ºé—´ä¸€è‡´æ€§ã€‚è¯¥æ–¹æ³•è¿˜è®¾è®¡äº†ä¸€ä¸ªè½»é‡çº§ç”Ÿæˆå™¨ï¼Œå°†æ–‡æœ¬åµŒå…¥(Text Embeddings)æ˜ å°„è‡³è§†è§‰ç©ºé—´ï¼Œæœ‰æ•ˆå¼¥åˆäº†è¯­ä¹‰å·®è·ã€‚å®éªŒåœ¨ä¸‰é¡¹åŒ»å­¦æˆåƒä»»åŠ¡å’Œå››ä¸ªåˆ†å‰²æ¡†æ¶ä¸Šè¿›è¡Œäº†å¹¿æ³›éªŒè¯ï¼Œå¯è§†åŒ–ç»“æœè¯å®äº†è¯¥æ¨¡å‹åœ¨åŒºåŸŸå®šä½ä¸Šçš„å‡†ç¡®æ€§ã€‚æœ€ç»ˆï¼Œè¯¥æ–¹æ³•è¾¾åˆ°äº†å½“å‰æœ€å…ˆè¿›çš„(State-of-the-Art)æ°´å¹³ï¼Œä¸ºè§£å†³åŒ»å­¦å½±åƒæ•°æ®ç¨€ç¼ºé—®é¢˜æä¾›äº†ç¨³å¥çš„å¤šæ¨¡æ€å­¦ä¹ æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.12482v1",
      "published_date": "2025-10-14 13:18:34 UTC",
      "updated_date": "2025-10-14 13:18:34 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:24:34.986215+00:00"
    },
    {
      "arxiv_id": "2510.12476v1",
      "title": "When Personalization Tricks Detectors: The Feature-Inversion Trap in Machine-Generated Text Detection",
      "title_zh": "å½“ä¸ªæ€§åŒ–è¯¯å¯¼æ£€æµ‹å™¨ï¼šæœºå™¨ç”Ÿæˆæ–‡æœ¬æ£€æµ‹ä¸­çš„ç‰¹å¾åè½¬é™·é˜±",
      "authors": [
        "Lang Gao",
        "Xuhui Li",
        "Chenxi Wang",
        "Mingzhe Li",
        "Wei Liu",
        "Zirui Song",
        "Jinghui Zhang",
        "Rui Yan",
        "Preslav Nakov",
        "Xiuying Chen"
      ],
      "abstract": "Large language models (LLMs) have grown more powerful in language generation, producing fluent text and even imitating personal style. Yet, this ability also heightens the risk of identity impersonation. To the best of our knowledge, no prior work has examined personalized machine-generated text (MGT) detection. In this paper, we introduce \\dataset, the first benchmark for evaluating detector robustness in personalized settings, built from literary and blog texts paired with their LLM-generated imitations. Our experimental results demonstrate large performance gaps across detectors in personalized settings: some state-of-the-art models suffer significant drops. We attribute this limitation to the \\textit{feature-inversion trap}, where features that are discriminative in general domains become inverted and misleading when applied to personalized text. Based on this finding, we propose \\method, a simple and reliable way to predict detector performance changes in personalized settings. \\method identifies latent directions corresponding to inverted features and constructs probe datasets that differ primarily along these features to evaluate detector dependence. Our experiments show that \\method can accurately predict both the direction and the magnitude of post-transfer changes, showing 85\\% correlation with the actual performance gaps. We hope that this work will encourage further research on personalized text detection.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†ä¸ªæ€§åŒ–æœºå™¨ç”Ÿæˆæ–‡æœ¬ï¼ˆMGTï¼‰æ£€æµ‹ä¸­çš„é²æ£’æ€§é—®é¢˜ï¼Œç‰¹åˆ«å…³æ³¨å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰æ¨¡ä»¿ä¸ªäººé£æ ¼å¸¦æ¥çš„èº«ä»½å†’å……é£é™©ã€‚ç ”ç©¶è€…æ„å»ºäº†é¦–ä¸ªé’ˆå¯¹ä¸ªæ€§åŒ–åœºæ™¯çš„è¯„ä¼°åŸºå‡†æ•°æ®é›†ï¼ŒåŒ…å«æ–‡å­¦ä½œå“ã€åšå®¢æ–‡ç« åŠå…¶å¯¹åº”çš„LLMæ¨¡ä»¿æ–‡æœ¬ã€‚å®éªŒå‘ç°ï¼Œç°æœ‰ä¸»æµæ£€æµ‹å™¨åœ¨ä¸ªæ€§åŒ–è®¾ç½®ä¸‹æ€§èƒ½å¤§å¹…ä¸‹é™ï¼Œç ”ç©¶å°†å…¶å½’å› äºâ€œç‰¹å¾åè½¬é™·é˜±â€ï¼ˆfeature-inversion trapï¼‰ï¼Œå³é€šç”¨é¢†åŸŸçš„é‰´åˆ«ç‰¹å¾åœ¨ä¸ªæ€§åŒ–æ–‡æœ¬ä¸­åè€Œäº§ç”Ÿäº†åå‘çš„è¯¯å¯¼ä½œç”¨ã€‚ä¸ºæ­¤ï¼Œè®ºæ–‡æå‡ºäº†ä¸€ç§é¢„æµ‹æ£€æµ‹å™¨æ€§èƒ½å˜åŒ–çš„æ–¹æ³•ï¼Œé€šè¿‡è¯†åˆ«ä¸åè½¬ç‰¹å¾ç›¸å…³çš„æ½œåœ¨æ–¹å‘å¹¶æ„å»ºæ¢æµ‹æ•°æ®é›†æ¥è¯„ä¼°æ£€æµ‹å™¨çš„ä¾èµ–ç¨‹åº¦ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•èƒ½å‡†ç¡®é¢„æµ‹æ£€æµ‹å™¨è¿ç§»åçš„æ€§èƒ½å˜åŒ–æ–¹å‘å’Œå¹…åº¦ï¼Œä¸å®é™…æ€§èƒ½å·®è·çš„ç›¸å…³æ€§é«˜è¾¾85%ï¼Œä¸ºæé«˜ä¸ªæ€§åŒ–æ–‡æœ¬æ£€æµ‹çš„å¯é æ€§æä¾›äº†é‡è¦è§è§£ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.12476v1",
      "published_date": "2025-10-14 13:10:23 UTC",
      "updated_date": "2025-10-14 13:10:23 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:24:32.977003+00:00"
    },
    {
      "arxiv_id": "2510.12857v1",
      "title": "Adaptive Generation of Bias-Eliciting Questions for LLMs",
      "title_zh": "é’ˆå¯¹å¤§è¯­è¨€æ¨¡å‹çš„åè§è¯±å¯¼æ€§é—®é¢˜è‡ªé€‚åº”ç”Ÿæˆ",
      "authors": [
        "Robin Staab",
        "Jasper Dekoninck",
        "Maximilian Baader",
        "Martin Vechev"
      ],
      "abstract": "Large language models (LLMs) are now widely deployed in user-facing applications, reaching hundreds of millions worldwide. As they become integrated into everyday tasks, growing reliance on their outputs raises significant concerns. In particular, users may unknowingly be exposed to model-inherent biases that systematically disadvantage or stereotype certain groups. However, existing bias benchmarks continue to rely on templated prompts or restrictive multiple-choice questions that are suggestive, simplistic, and fail to capture the complexity of real-world user interactions. In this work, we address this gap by introducing a counterfactual bias evaluation framework that automatically generates realistic, open-ended questions over sensitive attributes such as sex, race, or religion. By iteratively mutating and selecting bias-inducing questions, our approach systematically explores areas where models are most susceptible to biased behavior. Beyond detecting harmful biases, we also capture distinct response dimensions that are increasingly relevant in user interactions, such as asymmetric refusals and explicit acknowledgment of bias. Leveraging our framework, we construct CAB, a human-verified benchmark spanning diverse topics, designed to enable cross-model comparisons. Using CAB, we analyze a range of LLMs across multiple bias dimensions, revealing nuanced insights into how different models manifest bias. For instance, while GPT-5 outperforms other models, it nonetheless exhibits persistent biases in specific scenarios. These findings underscore the need for continual improvements to ensure fair model behavior.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç°æœ‰åè§è¯„ä¼°åŸºå‡†ä¾èµ–æ¨¡æ¿åŒ–æç¤ºè¯æˆ–ç®€åŒ–é€‰æ‹©é¢˜ã€éš¾ä»¥æ•æ‰çœŸå®äº¤äº’å¤æ‚æ€§çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§åäº‹å®åè§è¯„ä¼°æ¡†æ¶ï¼Œç”¨äºè‡ªåŠ¨ç”Ÿæˆæ¶‰åŠæ€§åˆ«ã€ç§æ—å’Œå®—æ•™ç­‰æ•æ„Ÿå±æ€§çš„ç°å®ã€å¼€æ”¾å¼é—®é¢˜ã€‚è¯¥æ–¹æ³•é€šè¿‡è¿­ä»£å˜å¼‚å’Œé€‰æ‹©å…·æœ‰åè§è¯±å¯¼æ€§çš„æé—®ï¼Œç³»ç»Ÿæ€§åœ°æ¢ç´¢å¤§è¯­è¨€æ¨¡å‹(LLMs)æœ€æ˜“äº§ç”Ÿåè§è¡Œä¸ºçš„é¢†åŸŸï¼Œå¹¶èƒ½æ•æ‰ä¸å¯¹ç§°æ‹’ç»(asymmetric refusals)åŠåè§æ˜¾å¼ç¡®è®¤ç­‰å¤æ‚å“åº”ç»´åº¦ã€‚åŸºäºæ­¤æ¡†æ¶ï¼Œç ”ç©¶è€…æ„å»ºäº†ç»äººå·¥éªŒè¯çš„CABåŸºå‡†æµ‹è¯•ï¼Œå¯¹åŒ…æ‹¬GPT-5åœ¨å†…çš„å¤šç§ä¸»æµæ¨¡å‹è¿›è¡Œäº†å¤šç»´åº¦åè§åˆ†æã€‚å®éªŒå‘ç°ï¼Œå³ä¾¿å¦‚GPT-5ç­‰é¢†å…ˆæ¨¡å‹åœ¨ç‰¹å®šåœºæ™¯ä¸‹ä»è¡¨ç°å‡ºæŒç»­æ€§åè§ï¼Œè¿™ä¸€ç»“è®ºæ­ç¤ºäº†æ¨¡å‹åœ¨çœŸå®åº”ç”¨ä¸­ç¡®ä¿å…¬å¹³æ€§çš„è¿«åˆ‡éœ€æ±‚ã€‚",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.12857v1",
      "published_date": "2025-10-14 13:08:10 UTC",
      "updated_date": "2025-10-14 13:08:10 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:24:37.905828+00:00"
    },
    {
      "arxiv_id": "2510.12462v1",
      "title": "Evaluating and Mitigating LLM-as-a-judge Bias in Communication Systems",
      "title_zh": "é€šä¿¡ç³»ç»Ÿä¸­ LLM-as-a-judge åè§çš„è¯„ä¼°ä¸ç¼“è§£",
      "authors": [
        "Jiaxin Gao",
        "Chen Chen",
        "Yanwen Jia",
        "Xueluan Gong",
        "Kwok-Yan Lam",
        "Qian Wang"
      ],
      "abstract": "Large Language Models (LLMs) are increasingly being used to autonomously evaluate the quality of content in communication systems, e.g., to assess responses in telecom customer support chatbots. However, the impartiality of these AI \"judges\" is not guaranteed, and any biases in their evaluation criteria could skew outcomes and undermine user trust. In this paper, we systematically investigate judgment biases in two LLM-as-a-judge models (i.e., GPT-Judge and JudgeLM) under the point-wise scoring setting, encompassing 11 types of biases that cover both implicit and explicit forms. We observed that state-of-the-art LLM judges demonstrate robustness to biased inputs, generally assigning them lower scores than the corresponding clean samples. Providing a detailed scoring rubric further enhances this robustness. We further found that fine-tuning an LLM on high-scoring yet biased responses can significantly degrade its performance, highlighting the risk of training on biased data. We also discovered that the judged scores correlate with task difficulty: a challenging dataset like GPQA yields lower average scores, whereas an open-ended reasoning dataset (e.g., JudgeLM-val) sees higher average scores. Finally, we proposed four potential mitigation strategies to ensure fair and reliable AI judging in practical communication scenarios.",
      "tldr_zh": "è¯¥ç ”ç©¶ç³»ç»Ÿåœ°è¯„ä¼°å¹¶ç¼“è§£äº†åœ¨é€šä¿¡ç³»ç»Ÿä¸­ä½¿ç”¨å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ä½œä¸ºè£åˆ¤ï¼ˆLLM-as-a-judgeï¼‰æ—¶å­˜åœ¨çš„åè§é—®é¢˜ã€‚ä½œè€…é’ˆå¯¹ GPT-Judge å’Œ JudgeLM ä¸¤ç§æ¨¡å‹ï¼Œåœ¨ç‚¹å¯¹ç‚¹è¯„åˆ†(point-wise scoring)è®¾ç½®ä¸‹è°ƒæŸ¥äº†åŒ…æ‹¬éšæ€§å’Œæ˜¾æ€§å½¢å¼åœ¨å†…çš„ 11 ç§åè§ã€‚ç ”ç©¶å‘ç°ï¼Œå…ˆè¿›çš„ LLM è£åˆ¤å¯¹åè§è¾“å…¥å…·æœ‰ä¸€å®šçš„é²æ£’æ€§ï¼Œé€šå¸¸ä¼šç»™åè§æ ·æœ¬æ‰“å‡ºæ¯”å¹²å‡€æ ·æœ¬æ›´ä½çš„åˆ†æ•°ï¼Œä¸”æä¾›è¯¦ç»†çš„è¯„åˆ†æ ‡å‡†(scoring rubric)èƒ½è¿›ä¸€æ­¥å¢å¼ºè¿™ç§é²æ£’æ€§ã€‚ç„¶è€Œï¼Œåœ¨å¾—åˆ†é«˜ä½†æœ‰åè§çš„å“åº”ä¸Šè¿›è¡Œå¾®è°ƒ(fine-tuning)ä¼šæ˜¾è‘—é™ä½æ¨¡å‹æ€§èƒ½ï¼Œè¿™å‡¸æ˜¾äº†ä½¿ç”¨åè§æ•°æ®è®­ç»ƒçš„é£é™©ã€‚æ­¤å¤–ï¼Œè¯„åˆ¤åˆ†æ•°ä¸ä»»åŠ¡éš¾åº¦é«˜åº¦ç›¸å…³ï¼Œåœ¨ GPQA ç­‰æŒ‘æˆ˜æ€§æ•°æ®é›†ä¸­å¹³å‡å¾—åˆ†è¾ƒä½ã€‚æœ€åï¼Œè®ºæ–‡æå‡ºäº†å››ç§ç¼“è§£ç­–ç•¥ï¼Œæ—¨åœ¨ä¸ºå®é™…é€šä¿¡åœºæ™¯æä¾›å…¬å¹³ä¸”å¯é çš„ AI è¯„åˆ¤æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.12462v1",
      "published_date": "2025-10-14 12:52:29 UTC",
      "updated_date": "2025-10-14 12:52:29 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:24:40.899424+00:00"
    },
    {
      "arxiv_id": "2510.13893v1",
      "title": "Guarding the Guardrails: A Taxonomy-Driven Approach to Jailbreak Detection",
      "title_zh": "å®ˆæŠ¤å®‰å…¨æŠ¤æ ï¼šä¸€ç§åŸºäºåˆ†ç±»ä½“ç³»çš„è¶Šç‹±æ£€æµ‹æ–¹æ³•",
      "authors": [
        "Olga E. Sorokoletova",
        "Francesco Giarrusso",
        "Vincenzo Suriani",
        "Daniele Nardi"
      ],
      "abstract": "Jailbreaking techniques pose a significant threat to the safety of Large Language Models (LLMs). Existing defenses typically focus on single-turn attacks, lack coverage across languages, and rely on limited taxonomies that either fail to capture the full diversity of attack strategies or emphasize risk categories rather than the jailbreaking techniques. To advance the understanding of the effectiveness of jailbreaking techniques, we conducted a structured red-teaming challenge. The outcome of our experiments are manifold. First, we developed a comprehensive hierarchical taxonomy of 50 jailbreak strategies, consolidating and extending prior classifications into seven broad families, including impersonation, persuasion, privilege escalation, cognitive overload, obfuscation, goal conflict, and data poisoning. Second, we analyzed the data collected from the challenge to examine the prevalence and success rates of different attack types, providing insights into how specific jailbreak strategies exploit model vulnerabilities and induce misalignment. Third, we benchmark a popular LLM for jailbreak detection, evaluating the benefits of taxonomy-guided prompting for improving automatic detection. Finally, we compiled a new Italian dataset of 1364 multi-turn adversarial dialogues, annotated with our taxonomy, enabling the study of interactions where adversarial intent emerges gradually and succeeds in bypassing traditional safeguards.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰é¢ä¸´çš„è¶Šç‹±æ”»å‡»ï¼ˆJailbreakingï¼‰å¨èƒï¼Œæå‡ºäº†ä¸€ç§ç”±åˆ†ç±»å­¦é©±åŠ¨çš„æ£€æµ‹æ–¹æ³•ï¼Œä»¥è§£å†³ç°æœ‰é˜²å¾¡åœ¨å¤šè½®å¯¹è¯å’Œå¤šè¯­è¨€è¦†ç›–æ–¹é¢çš„å±€é™ã€‚ç ”ç©¶è€…é€šè¿‡ç»“æ„åŒ–çš„çº¢é˜ŸæŒ‘æˆ˜ï¼ˆRed-Teaming Challengeï¼‰ï¼Œæ„å»ºäº†ä¸€ä¸ªåŒ…å«50ç§è¶Šç‹±ç­–ç•¥çš„å±‚æ¬¡åŒ–åˆ†ç±»å­¦ï¼ˆTaxonomyï¼‰ï¼Œæ¶µç›–äº†è§’è‰²æ‰®æ¼”ï¼ˆImpersonationï¼‰ã€è¯´æœï¼ˆPersuasionï¼‰å’Œè®¤çŸ¥è¿‡è½½ï¼ˆCognitive Overloadï¼‰ç­‰ä¸ƒå¤§ç±»åˆ«ã€‚é€šè¿‡å¯¹æŒ‘æˆ˜æ•°æ®çš„åˆ†æï¼Œç ”ç©¶æ­ç¤ºäº†ä¸åŒæ”»å‡»ç±»å‹çš„æµè¡Œç¨‹åº¦åŠå…¶è¯±å¯¼æ¨¡å‹äº§ç”Ÿå¯¹é½å¤±æ•ˆï¼ˆMisalignmentï¼‰çš„æˆåŠŸç‡ã€‚å®éªŒè¿›ä¸€æ­¥è¯„ä¼°äº†åˆ†ç±»å­¦å¼•å¯¼æç¤ºï¼ˆTaxonomy-guided Promptingï¼‰åœ¨æå‡è‡ªåŠ¨æ£€æµ‹æ•ˆèƒ½æ–¹é¢çš„ä»·å€¼ã€‚æ­¤å¤–ï¼Œç ”ç©¶å›¢é˜Ÿè¿˜ç¼–çº‚å¹¶å‘å¸ƒäº†ä¸€ä¸ªåŒ…å«1364ä¸ªå¤šè½®å¯¹æŠ—å¯¹è¯çš„æ„å¤§åˆ©è¯­æ•°æ®é›†ã€‚è¯¥æ•°æ®é›†ä¸ºç ”ç©¶å¯¹æŠ—æ€§æ„å›¾åœ¨å¤æ‚äº¤äº’ä¸­å¦‚ä½•é€æ­¥æ¼”å˜å¹¶ç»•è¿‡ä¼ ç»Ÿå®‰å…¨å±éšœæä¾›äº†å…³é”®æ”¯æŒã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.13893v1",
      "published_date": "2025-10-14 12:34:41 UTC",
      "updated_date": "2025-10-14 12:34:41 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:24:44.087320+00:00"
    },
    {
      "arxiv_id": "2510.12451v1",
      "title": "A Function Centric Perspective On Flat and Sharp Minima",
      "title_zh": "å‡½æ•°è§†è§’ä¸‹çš„å¹³å¦ä¸å°–é”æå°å€¼",
      "authors": [
        "Israel Mason-Williams",
        "Gabryel Mason-Williams",
        "Helen Yannakoudakis"
      ],
      "abstract": "Flat minima are widely believed to correlate with improved generalisation in deep neural networks. However, this connection has proven more nuanced in recent studies, with both theoretical counterexamples and empirical exceptions emerging in the literature. In this paper, we revisit the role of sharpness in model performance, proposing that sharpness is better understood as a function-dependent property rather than a reliable indicator of poor generalisation. We conduct extensive empirical studies, from single-objective optimisation to modern image classification tasks, showing that sharper minima often emerge when models are regularised (e.g., via SAM, weight decay, or data augmentation), and that these sharp minima can coincide with better generalisation, calibration, robustness, and functional consistency. Across a range of models and datasets, we find that baselines without regularisation tend to converge to flatter minima yet often perform worse across all safety metrics. Our findings demonstrate that function complexity, rather than flatness alone, governs the geometry of solutions, and that sharper minima can reflect more appropriate inductive biases (especially under regularisation), calling for a function-centric reappraisal of loss landscape geometry.",
      "tldr_zh": "è¯¥ç ”ç©¶ä»ä»¥å‡½æ•°ä¸ºä¸­å¿ƒ(function-centric)çš„è§†è§’é‡æ–°å®¡è§†äº†å¹³å¦æå°å€¼(flat minima)ä¸å°–é”æå°å€¼(sharp minima)åœ¨æ·±åº¦ç¥ç»ç½‘ç»œä¸­çš„ä½œç”¨ï¼ŒæŒ‘æˆ˜äº†å¹³å¦æ€§å¿…ç„¶å¯¼è‡´æ›´å¥½æ³›åŒ–æ€§èƒ½çš„ä¼ ç»Ÿè§‚ç‚¹ã€‚é€šè¿‡æ¶µç›–å•ç›®æ ‡ä¼˜åŒ–åŠç°ä»£å›¾åƒåˆ†ç±»ä»»åŠ¡çš„å¹¿æ³›å®è¯ç ”ç©¶ï¼Œä½œè€…å‘ç°å°–é”æå°å€¼é€šå¸¸åœ¨æ¨¡å‹åº”ç”¨æ­£åˆ™åŒ–ï¼ˆå¦‚SAMã€weight decayæˆ–æ•°æ®å¢å¼ºï¼‰æ—¶å‡ºç°ï¼Œå¹¶ä¸æ›´ä¼˜çš„æ³›åŒ–æ€§èƒ½ã€æ ¡å‡†æ€§(calibration)ã€é²æ£’æ€§(robustness)åŠå‡½æ•°ä¸€è‡´æ€§ç›¸å…³ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œç¼ºä¹æ­£åˆ™åŒ–çš„åŸºå‡†æ¨¡å‹è™½å€¾å‘äºæ”¶æ•›è‡³æ›´å¹³å¦çš„æå°å€¼ï¼Œä½†åœ¨æ‰€æœ‰å®‰å…¨æŒ‡æ ‡ä¸Šçš„è¡¨ç°å¾€å¾€æ›´å·®ã€‚ç ”ç©¶æŒ‡å‡ºï¼Œå†³å®šè§£ç©ºé—´å‡ ä½•ç‰¹æ€§çš„æ ¸å¿ƒæ˜¯å‡½æ•°å¤æ‚åº¦(function complexity)è€Œéå•çº¯çš„å¹³å¦åº¦ï¼Œä¸”å°–é”æå°å€¼åœ¨æ­£åˆ™åŒ–ä¸‹å¯èƒ½åæ˜ äº†æ›´åˆé€‚çš„å½’çº³åç½®(inductive biases)ã€‚è¯¥å‘ç°å‘¼åå­¦æœ¯ç•Œå¯¹æŸå¤±å‡½æ•°åœ°å½¢(loss landscape geometry)è¿›è¡Œä»¥å‡½æ•°ä¸ºä¸­å¿ƒçš„é‡æ–°è¯„ä¼°ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "26 pages, 26 tables, 63 figures, pre-print",
      "pdf_url": "https://arxiv.org/pdf/2510.12451v1",
      "published_date": "2025-10-14 12:33:14 UTC",
      "updated_date": "2025-10-14 12:33:14 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:24:49.695544+00:00"
    },
    {
      "arxiv_id": "2510.12428v1",
      "title": "Biased-Attention Guided Risk Prediction for Safe Decision-Making at Unsignalized Intersections",
      "title_zh": "é¢å‘æ— ä¿¡å·äº¤å‰å£å®‰å…¨å†³ç­–çš„åå‘æ³¨æ„åŠ›å¼•å¯¼é£é™©é¢„æµ‹",
      "authors": [
        "Chengyang Dong",
        "Nan Guo"
      ],
      "abstract": "Autonomous driving decision-making at unsignalized intersections is highly challenging due to complex dynamic interactions and high conflict risks. To achieve proactive safety control, this paper proposes a deep reinforcement learning (DRL) decision-making framework integrated with a biased attention mechanism. The framework is built upon the Soft Actor-Critic (SAC) algorithm. Its core innovation lies in the use of biased attention to construct a traffic risk predictor. This predictor assesses the long-term risk of collision for a vehicle entering the intersection and transforms this risk into a dense reward signal to guide the SAC agent in making safe and efficient driving decisions. Finally, the simulation results demonstrate that the proposed method effectively improves both traffic efficiency and vehicle safety at the intersection, thereby proving the effectiveness of the intelligent decision-making framework in complex scenarios. The code of our work is available at https://github.com/hank111525/SAC-RWB.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹æ— ä¿¡å·ç¯è·¯å£ï¼ˆunsignalized intersectionsï¼‰è‡ªåŠ¨é©¾é©¶å†³ç­–ä¸­å¤æ‚çš„åŠ¨æ€äº¤äº’å’Œé«˜å†²çªé£é™©ï¼Œæå‡ºäº†ä¸€ç§é›†æˆåç½®æ³¨æ„åŠ›æœºåˆ¶ï¼ˆbiased attention mechanismï¼‰çš„æ·±åº¦å¼ºåŒ–å­¦ä¹ ï¼ˆDeep Reinforcement Learning, DRLï¼‰å†³ç­–æ¡†æ¶ã€‚è¯¥æ¡†æ¶å»ºç«‹åœ¨ Soft Actor-Critic (SAC) ç®—æ³•ä¹‹ä¸Šï¼Œå…¶æ ¸å¿ƒåˆ›æ–°åœ¨äºåˆ©ç”¨ biased attention æ„å»ºäº¤é€šé£é™©é¢„æµ‹å™¨ï¼ˆtraffic risk predictorï¼‰ï¼Œç”¨ä»¥è¯„ä¼°è½¦è¾†è¿›å…¥è·¯å£çš„é•¿æœŸç¢°æ’é£é™©ã€‚è¯¥é¢„æµ‹å™¨å°†é£é™©è¯„ä¼°è½¬åŒ–ä¸ºå¯†é›†å¥–åŠ±ä¿¡å·ï¼ˆdense reward signalï¼‰ï¼Œä»è€Œå¼•å¯¼ SAC æ™ºèƒ½ä½“åšå‡ºå®‰å…¨ä¸”é«˜æ•ˆçš„é©¾é©¶å†³ç­–ã€‚ä»¿çœŸç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨å¤æ‚åœºæ™¯ä¸‹æœ‰æ•ˆæå‡äº†äº¤é€šæ•ˆç‡ä¸è½¦è¾†å®‰å…¨æ€§ï¼Œè¯æ˜äº†è¯¥æ™ºèƒ½å†³ç­–æ¡†æ¶çš„æœ‰æ•ˆæ€§ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.12428v1",
      "published_date": "2025-10-14 12:05:51 UTC",
      "updated_date": "2025-10-14 12:05:51 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:24:50.480141+00:00"
    },
    {
      "arxiv_id": "2510.12423v1",
      "title": "MTOS: A LLM-Driven Multi-topic Opinion Simulation Framework for Exploring Echo Chamber Dynamics",
      "title_zh": "MTOSï¼šä¸€ç§ç”¨äºæ¢ç´¢å›å£°å®¤æ•ˆåº”åŠ¨æ€çš„å¤§è¯­è¨€æ¨¡å‹é©±åŠ¨å¤šè¯é¢˜èˆ†è®ºæ¨¡æ‹Ÿæ¡†æ¶",
      "authors": [
        "Dingyi Zuo",
        "Hongjie Zhang",
        "Jie Ou",
        "Chaosheng Feng",
        "Shuwan Liu"
      ],
      "abstract": "The polarization of opinions, information segregation, and cognitive biases on social media have attracted significant academic attention. In real-world networks, information often spans multiple interrelated topics, posing challenges for opinion evolution and highlighting the need for frameworks that simulate interactions among topics. Existing studies based on large language models (LLMs) focus largely on single topics, limiting the capture of cognitive transfer in multi-topic, cross-domain contexts. Traditional numerical models, meanwhile, simplify complex linguistic attitudes into discrete values, lacking interpretability, behavioral consistency, and the ability to integrate multiple topics. To address these issues, we propose Multi-topic Opinion Simulation (MTOS), a social simulation framework integrating multi-topic contexts with LLMs. MTOS leverages LLMs alongside short-term and long-term memory, incorporates multiple user-selection interaction mechanisms and dynamic topic-selection strategies, and employs a belief decay mechanism to enable perspective updates across topics. We conduct extensive experiments on MTOS, varying topic numbers, correlation types, and performing ablation studies to assess features such as group polarization and local consistency. Results show that multi-topic settings significantly alter polarization trends: positively correlated topics amplify echo chambers, negatively correlated topics inhibit them, and irrelevant topics also mitigate echo chamber effects through resource competition. Compared with numerical models, LLM-based agents realistically simulate dynamic opinion changes, reproduce linguistic features of news texts, and capture complex human reasoning, improving simulation interpretability and system stability.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†MTOSï¼Œä¸€ä¸ªç”±å¤§è¯­è¨€æ¨¡å‹(LLMs)é©±åŠ¨çš„å¤šè¯é¢˜èˆ†è®ºæ¨¡æ‹Ÿæ¡†æ¶ï¼Œæ—¨åœ¨æ·±å…¥æ¢ç´¢ç¤¾äº¤åª’ä½“ä¸­çš„å›å£°å£æ•ˆåº”(Echo Chamber Dynamics)ã€‚MTOSé€šè¿‡æ•´åˆé•¿çŸ­æœŸè®°å¿†ã€å¤šæ ·åŒ–çš„ç”¨æˆ·äº¤äº’æœºåˆ¶ä»¥åŠä¿¡å¿µè¡°å‡æœºåˆ¶(Belief Decay Mechanism)ï¼Œå®ç°äº†è·¨è¯é¢˜çš„è§‚ç‚¹æ›´æ–°ä¸è®¤çŸ¥è½¬ç§»ï¼Œå¼¥è¡¥äº†ç°æœ‰å•è¯é¢˜æ¨¡æ‹Ÿå’Œä¼ ç»Ÿæ•°å€¼æ¨¡å‹åœ¨å¤æ‚è¯­ä¹‰è¡¨è¾¾åŠè¡Œä¸ºä¸€è‡´æ€§ä¸Šçš„ä¸è¶³ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œå¤šè¯é¢˜è®¾ç½®ä¼šæ˜¾è‘—å½±å“æåŒ–è¶‹åŠ¿ï¼Œå…¶ä¸­æ­£ç›¸å…³è¯é¢˜ä¼šæ”¾å¤§å›å£°å£æ•ˆåº”ï¼Œè€Œè´Ÿç›¸å…³æˆ–æ— å…³è¯é¢˜åˆ™èƒ½æœ‰æ•ˆæŠ‘åˆ¶æåŒ–ç°è±¡ã€‚ä¸ä¼ ç»Ÿæ•°å€¼æ¨¡å‹ç›¸æ¯”ï¼ŒåŸºäºLLMsçš„æ™ºèƒ½ä½“èƒ½æ›´çœŸå®åœ°å¤ç°åŠ¨æ€è§‚ç‚¹æ¼”å˜å’Œå¤æ‚çš„äººç±»æ¨ç†è¿‡ç¨‹ï¼Œæ˜¾è‘—æå‡äº†ç¤¾ä¼šä»¿çœŸç³»ç»Ÿçš„å¯è§£é‡Šæ€§ä¸ç¨³å®šæ€§ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "14 pages, 11figures",
      "pdf_url": "https://arxiv.org/pdf/2510.12423v1",
      "published_date": "2025-10-14 11:59:47 UTC",
      "updated_date": "2025-10-14 11:59:47 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:25:03.169230+00:00"
    },
    {
      "arxiv_id": "2510.12409v1",
      "title": "PricingLogic: Evaluating LLMs Reasoning on Complex Tourism Pricing Tasks",
      "title_zh": "PricingLogicï¼šè¯„ä¼° LLMs åœ¨å¤æ‚æ—…æ¸¸å®šä»·ä»»åŠ¡ä¸­çš„æ¨ç†èƒ½åŠ›",
      "authors": [
        "Yunuo Liu",
        "Dawei Zhu",
        "Zena Al-Khalili",
        "Dai Cheng",
        "Yanjun Chen",
        "Dietrich Klakow",
        "Wei Zhang",
        "Xiaoyu Shen"
      ],
      "abstract": "We present PricingLogic, the first benchmark that probes whether Large Language Models(LLMs) can reliably automate tourism-related prices when multiple, overlapping fare rules apply. Travel agencies are eager to offload this error-prone task onto AI systems; however, deploying LLMs without verified reliability could result in significant financial losses and erode customer trust. PricingLogic comprises 300 natural-language questions based on booking requests derived from 42 real-world pricing policies, spanning two levels of difficulty: (i) basic customer-type pricing and (ii)bundled-tour calculations involving interacting discounts. Evaluations of a line of LLMs reveal a steep performance drop on the harder tier,exposing systematic failures in rule interpretation and arithmetic reasoning.These results highlight that, despite their general capabilities, today's LLMs remain unreliable in revenue-critical applications without further safeguards or domain adaptation. Our code and dataset are available at https://github.com/EIT-NLP/PricingLogic.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† PricingLogicï¼Œè¿™æ˜¯é¦–ä¸ªè¯„ä¼°å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨å¤æ‚æ—…æ¸¸å®šä»·ä»»åŠ¡ä¸­æ¨ç†èƒ½åŠ›çš„åŸºå‡†æµ‹è¯•ï¼Œæ—¨åœ¨æ¢ç©¶æ¨¡å‹åœ¨å¤„ç†å¤šé‡é‡å ç¥¨ä»·è§„åˆ™æ—¶çš„å¯é æ€§ã€‚è¯¥åŸºå‡†åŒ…å«åŸºäº 42 ä¸ªçœŸå®ä¸–ç•Œå®šä»·ç­–ç•¥ç”Ÿæˆçš„ 300 ä¸ªè‡ªç„¶è¯­è¨€é—®é¢˜ï¼Œæ¶µç›–äº†åŸºç¡€å®¢æˆ·å®šä»·ä»¥åŠæ¶‰åŠæŠ˜æ‰£äº¤äº’çš„å¤æ‚å›¢è´­è®¡ç®—ä¸¤ä¸ªéš¾åº¦çº§åˆ«ã€‚é€šè¿‡å¯¹ä¸€ç³»åˆ— LLMs çš„è¯„ä¼°å‘ç°ï¼Œæ¨¡å‹åœ¨å¤„ç†é«˜éš¾åº¦ä»»åŠ¡æ—¶æ€§èƒ½å¤§å¹…ä¸‹é™ï¼Œæš´éœ²å‡ºå…¶åœ¨è§„åˆ™è§£æå’Œç®—æœ¯æ¨ç†ï¼ˆarithmetic reasoningï¼‰æ–¹é¢çš„ç³»ç»Ÿæ€§ç¼ºé™·ã€‚ç ”ç©¶ç»“æœè¡¨æ˜ï¼Œå°½ç®¡ LLMs å…·å¤‡é€šç”¨èƒ½åŠ›ï¼Œä½†åœ¨ç¼ºä¹é¢å¤–å®‰å…¨ä¿éšœæˆ–é¢†åŸŸé€‚é…ï¼ˆdomain adaptationï¼‰çš„æƒ…å†µä¸‹ï¼Œå…¶åœ¨å¯¹æ”¶å…¥è‡³å…³é‡è¦çš„å•†ä¸šåº”ç”¨ä¸­ä¾ç„¶ä¸å¯é ã€‚è¯¥ç ”ç©¶ä¸ºæœªæ¥å¼€å‘æ›´ç¨³å¥ã€å¯ç”¨äºé‡‘èå…³é”®ä»»åŠ¡çš„ AI ç³»ç»Ÿæä¾›äº†é‡è¦çš„è¯„ä¼°æ•°æ®å’ŒåŸºå‡†å‚è€ƒã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.12409v1",
      "published_date": "2025-10-14 11:42:15 UTC",
      "updated_date": "2025-10-14 11:42:15 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:25:04.683063+00:00"
    },
    {
      "arxiv_id": "2510.12408v1",
      "title": "Low-Field Magnetic Resonance Image Quality Enhancement using a Conditional Flow Matching Model",
      "title_zh": "åŸºäºæ¡ä»¶æµåŒ¹é…æ¨¡å‹çš„ä½åœºç£å…±æŒ¯å›¾åƒè´¨é‡å¢å¼º",
      "authors": [
        "Huu Tien Nguyen",
        "Ahmed Karam Eldaly"
      ],
      "abstract": "This paper introduces a novel framework for image quality transfer based on conditional flow matching (CFM). Unlike conventional generative models that rely on iterative sampling or adversarial objectives, CFM learns a continuous flow between a noise distribution and target data distributions through the direct regression of an optimal velocity field. We evaluate this approach in the context of low-field magnetic resonance imaging (LF-MRI), a rapidly emerging modality that offers affordable and portable scanning but suffers from inherently low signal-to-noise ratio and reduced diagnostic quality. Our framework is designed to reconstruct high-field-like MR images from their corresponding low-field inputs, thereby bridging the quality gap without requiring expensive infrastructure. Experiments demonstrate that CFM not only achieves state-of-the-art performance, but also generalizes robustly to both in-distribution and out-of-distribution data. Importantly, it does so while utilizing significantly fewer parameters than competing deep learning methods. These results underline the potential of CFM as a powerful and scalable tool for MRI reconstruction, particularly in resource-limited clinical environments.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§åŸºäºæ¡ä»¶æµåŒ¹é…(conditional flow matching, CFM)çš„æ–°å‹å›¾åƒè´¨é‡è¿ç§»æ¡†æ¶ï¼Œæ—¨åœ¨æå‡ä½åœºç£å…±æŒ¯æˆåƒ(low-field MRI, LF-MRI)çš„è¯Šæ–­è´¨é‡ã€‚ä¸ä¾èµ–è¿­ä»£é‡‡æ ·æˆ–å¯¹æŠ—ç›®æ ‡çš„ä¼ ç»Ÿç”Ÿæˆæ¨¡å‹ä¸åŒï¼ŒCFMé€šè¿‡ç›´æ¥å›å½’æœ€ä¼˜é€Ÿåº¦åœºï¼Œå­¦ä¹ å™ªå£°åˆ†å¸ƒä¸ç›®æ ‡æ•°æ®åˆ†å¸ƒä¹‹é—´çš„è¿ç»­æµã€‚è¯¥æ¡†æ¶èƒ½å¤Ÿä»ä½åœºè¾“å…¥ä¸­é‡å»ºå‡ºé«˜è´¨é‡çš„ç±»é«˜åœºç£å…±æŒ¯å›¾åƒï¼Œæœ‰æ•ˆå¼¥è¡¥äº†ä¾¿æºå¼æ‰«æè®¾å¤‡åœ¨ä¿¡å™ªæ¯”æ–¹é¢çš„ä¸è¶³ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒCFMä¸ä»…è¾¾åˆ°äº†é¢†åŸŸå†…çš„å…ˆè¿›æ°´å¹³(state-of-the-art)ï¼Œè€Œä¸”åœ¨åˆ†å¸ƒå†…å’Œåˆ†å¸ƒå¤–æ•°æ®ä¸Šå‡è¡¨ç°å‡ºç¨³å¥çš„æ³›åŒ–èƒ½åŠ›ã€‚æ­¤å¤–ï¼Œè¯¥æ¨¡å‹åœ¨ä¿æŒé«˜æ€§èƒ½çš„åŒæ—¶ï¼Œå‚æ•°é‡æ˜¾è‘—ä½äºç«äº‰æ€§æ·±åº¦å­¦ä¹ æ–¹æ³•ï¼Œè¯æ˜äº†å…¶åœ¨èµ„æºå—é™çš„ä¸´åºŠç¯å¢ƒä¸­ä½œä¸ºé«˜æ•ˆMRIé‡å»ºå·¥å…·çš„å·¨å¤§æ½œåŠ›ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.12408v1",
      "published_date": "2025-10-14 11:41:27 UTC",
      "updated_date": "2025-10-14 11:41:27 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:25:11.884530+00:00"
    },
    {
      "arxiv_id": "2510.12856v1",
      "title": "Efficient Adaptive Transformer: An Empirical Study and Reproducible Framework",
      "title_zh": "é«˜æ•ˆè‡ªé€‚åº” Transformerï¼šå®è¯ç ”ç©¶ä¸å¯å¤ç°æ¡†æ¶",
      "authors": [
        "Jan Miller"
      ],
      "abstract": "The Efficient Adaptive Transformer (EAT) framework unifies three adaptive efficiency techniques - progressive token pruning, sparse attention, and dynamic early exiting - into a single, reproducible architecture for input-adaptive inference. EAT provides an open-source benchmarking pipeline that automates data processing, timing, and ablation across GLUE tasks (SST-2, QQP, MNLI). Although this empirical study finds that combining these mechanisms can increase latency in shallow six-layer models, it demonstrates that EAT achieves slightly higher accuracy than the optimized DistilBERT baseline on SST-2, illustrating the potential of dynamic computation for latency-sensitive NLP. The main contribution is the open, end-to-end reproducible framework - complete with scripts, CSV logging, and analysis utilities - intended to serve as a community tool for further research on adaptive transformers.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† Efficient Adaptive Transformer (EAT) æ¡†æ¶ï¼Œå°† progressive token pruningã€sparse attention å’Œ dynamic early exiting ä¸‰ç§è‡ªé€‚åº”æ•ˆç‡æŠ€æœ¯ç»Ÿä¸€ä¸ºä¸€ä¸ªå¯å¤ç°çš„è¾“å…¥è‡ªé€‚åº”æ¨ç†æ¶æ„ã€‚EAT æ¡†æ¶åŒ…å«å¼€æºåŸºå‡†æµ‹è¯•æµæ°´çº¿ï¼Œæ”¯æŒå¯¹ GLUE ä»»åŠ¡ï¼ˆå¦‚ SST-2ã€QQP å’Œ MNLIï¼‰è¿›è¡Œè‡ªåŠ¨åŒ–çš„æ•°æ®å¤„ç†ã€è®¡æ—¶åŠæ¶ˆèå®éªŒã€‚è™½ç„¶å®è¯ç»“æœè¡¨æ˜åœ¨æµ…å±‚å…­å±‚æ¨¡å‹ä¸­ç»“åˆè¿™äº›æœºåˆ¶ä¼šå¢åŠ å»¶è¿Ÿï¼Œä½† EAT åœ¨ SST-2 ä»»åŠ¡ä¸Šçš„å‡†ç¡®ç‡ç•¥é«˜äºä¼˜åŒ–åçš„ DistilBERT åŸºå‡†ï¼Œå±•ç°äº†åŠ¨æ€è®¡ç®—åœ¨å»¶è¿Ÿæ•æ„Ÿçš„ NLP åœºæ™¯ä¸‹çš„æ½œåŠ›ã€‚è¯¥å·¥ä½œçš„ä¸»è¦è´¡çŒ®æ˜¯æä¾›äº†ä¸€ä¸ªåŒ…å«è„šæœ¬ã€CSV æ—¥å¿—å’Œåˆ†æå·¥å…·çš„ç«¯åˆ°ç«¯å¼€æºå¤ç°æ¡†æ¶ï¼Œæ—¨åœ¨ä¸ºç¤¾åŒºè¿›ä¸€æ­¥ç ”ç©¶è‡ªé€‚åº” Transformer æä¾›åŸºç¡€å·¥å…·ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "10 pages, 6 figures, pgfplots tables included; BibTeX compiled to .bbl. Code and reproducibility artifacts referenced in the paper",
      "pdf_url": "https://arxiv.org/pdf/2510.12856v1",
      "published_date": "2025-10-14 11:40:48 UTC",
      "updated_date": "2025-10-14 11:40:48 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:25:12.969406+00:00"
    },
    {
      "arxiv_id": "2510.12399v2",
      "title": "A Survey of Vibe Coding with Large Language Models",
      "title_zh": "åŸºäºå¤§è¯­è¨€æ¨¡å‹çš„ Vibe Coding ç»¼è¿°",
      "authors": [
        "Yuyao Ge",
        "Lingrui Mei",
        "Zenghao Duan",
        "Tianhao Li",
        "Yujia Zheng",
        "Yiwei Wang",
        "Lexin Wang",
        "Jiayu Yao",
        "Tianyu Liu",
        "Yujun Cai",
        "Baolong Bi",
        "Fangda Guo",
        "Jiafeng Guo",
        "Shenghua Liu",
        "Xueqi Cheng"
      ],
      "abstract": "The advancement of large language models (LLMs) has catalyzed a paradigm shift from code generation assistance to autonomous coding agents, enabling a novel development methodology termed \"Vibe Coding\" where developers validate AI-generated implementations through outcome observation rather than line-by-line code comprehension. Despite its transformative potential, the effectiveness of this emergent paradigm remains under-explored, with empirical evidence revealing unexpected productivity losses and fundamental challenges in human-AI collaboration. To address this gap, this survey provides the first comprehensive and systematic review of Vibe Coding with large language models, establishing both theoretical foundations and practical frameworks for this transformative development approach. Drawing from systematic analysis of over 1000 research papers, we survey the entire vibe coding ecosystem, examining critical infrastructure components including LLMs for coding, LLM-based coding agent, development environment of coding agent, and feedback mechanisms. We first introduce Vibe Coding as a formal discipline by formalizing it through a Constrained Markov Decision Process that captures the dynamic triadic relationship among human developers, software projects, and coding agents. Building upon this theoretical foundation, we then synthesize existing practices into five distinct development models: Unconstrained Automation, Iterative Conversational Collaboration, Planning-Driven, Test-Driven, and Context-Enhanced Models, thus providing the first comprehensive taxonomy in this domain. Critically, our analysis reveals that successful Vibe Coding depends not merely on agent capabilities but on systematic context engineering, well-established development environments, and human-agent collaborative development models.",
      "tldr_zh": "è¯¥ç ”ç©¶å¯¹åŸºäºå¤§è¯­è¨€æ¨¡å‹(LLMs)çš„Vibe Codingè¿›è¡Œäº†é¦–æ¬¡å…¨é¢ç³»ç»Ÿçš„ç»¼è¿°ï¼Œæ—¨åœ¨æ¢è®¨è¿™ç§é€šè¿‡è§‚å¯Ÿè¾“å‡ºç»“æœè€Œéé€è¡Œç†è§£ä»£ç æ¥éªŒè¯AIç”Ÿæˆå®ç°çš„åˆ›æ–°å¼€å‘èŒƒå¼ã€‚é€šè¿‡å¯¹1000å¤šç¯‡ç›¸å…³è®ºæ–‡çš„åˆ†æï¼Œæ–‡ç« è°ƒç ”äº†åŒ…æ‹¬ä»£ç å¤§æ¨¡å‹ã€ç¼–ç æ™ºèƒ½ä½“(LLM-based coding agent)ã€å¼€å‘ç¯å¢ƒå’Œåé¦ˆæœºåˆ¶åœ¨å†…çš„æ•´ä¸ªç”Ÿæ€ç³»ç»Ÿã€‚ç ”ç©¶é€šè¿‡å—é™é©¬å°”å¯å¤«å†³ç­–è¿‡ç¨‹(Constrained Markov Decision Process)å¯¹Vibe Codingè¿›è¡Œäº†å½¢å¼åŒ–å®šä¹‰ï¼Œæ­ç¤ºäº†äººç±»å¼€å‘è€…ã€è½¯ä»¶é¡¹ç›®ä¸ç¼–ç æ™ºèƒ½ä½“ä¹‹é—´çš„ä¸‰å…ƒåŠ¨æ€å…³ç³»ã€‚åœ¨æ­¤åŸºç¡€ä¸Šï¼Œæœ¬æ–‡æå‡ºäº†åŒ…å«æ— çº¦æŸè‡ªåŠ¨åŒ–(Unconstrained Automation)ã€è¿­ä»£å¯¹è¯åä½œã€è§„åˆ’é©±åŠ¨ã€æµ‹è¯•é©±åŠ¨(Test-Driven)å’Œä¸Šä¸‹æ–‡å¢å¼ºåœ¨å†…çš„äº”ç§å¼€å‘æ¨¡å‹åˆ†ç±»æ³•ã€‚ç ”ç©¶æœ€ç»ˆæŒ‡å‡ºï¼ŒVibe Codingçš„æˆåŠŸä¸ä»…å–å†³äºæ™ºèƒ½ä½“çš„åŸºç¡€èƒ½åŠ›ï¼Œæ›´ä¾èµ–äºç³»ç»Ÿçš„ä¸Šä¸‹æ–‡å·¥ç¨‹(Context engineering)ã€å®Œå–„çš„å¼€å‘ç¯å¢ƒä»¥åŠé«˜æ•ˆçš„äººæœºåä½œå¼€å‘æ¨¡å¼ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.12399v2",
      "published_date": "2025-10-14 11:26:56 UTC",
      "updated_date": "2025-12-21 03:48:55 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:25:14.477501+00:00"
    },
    {
      "arxiv_id": "2510.12389v1",
      "title": "Tokenization Disparities as Infrastructure Bias: How Subword Systems Create Inequities in LLM Access and Efficiency",
      "title_zh": "ä½œä¸ºåŸºç¡€è®¾æ–½åè§çš„åˆ†è¯å·®å¼‚ï¼šå­è¯ç³»ç»Ÿå¦‚ä½•å¯¼è‡´å¤§è¯­è¨€æ¨¡å‹åœ¨è®¿é—®ä¸æ•ˆç‡ä¸Šçš„ä¸å¹³ç­‰",
      "authors": [
        "Hailay Kidu Teklehaymanot",
        "Wolfgang Nejdl"
      ],
      "abstract": "Tokenization disparities pose a significant barrier to achieving equitable access to artificial intelligence across linguistically diverse populations. This study conducts a large-scale cross-linguistic evaluation of tokenization efficiency in over 200 languages to systematically quantify computational inequities in large language models (LLMs). Using a standardized experimental framework, we applied consistent preprocessing and normalization protocols, followed by uniform tokenization through the tiktoken library across all language samples. Comprehensive tokenization statistics were collected using established evaluation metrics, including Tokens Per Sentence (TPS) and Relative Tokenization Cost (RTC), benchmarked against English baselines. Our cross-linguistic analysis reveals substantial and systematic disparities: Latin-script languages consistently exhibit higher tokenization efficiency, while non-Latin and morphologically complex languages incur significantly greater token inflation, often 3-5 times higher RTC ratios. These inefficiencies translate into increased computational costs and reduced effective context utilization for underrepresented languages. Overall, the findings highlight structural inequities in current AI systems, where speakers of low-resource and non-Latin languages face disproportionate computational disadvantages. Future research should prioritize the development of linguistically informed tokenization strategies and adaptive vocabulary construction methods that incorporate typological diversity, ensuring more inclusive and computationally equitable multilingual AI systems.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†åˆ†è¯å·®å¼‚ï¼ˆTokenization disparitiesï¼‰ä½œä¸ºåŸºç¡€è®¾æ–½åå·®å¦‚ä½•å¯¼è‡´ä¸åŒè¯­è¨€åœ¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰è®¿é—®å’Œæ•ˆç‡ä¸Šçš„ä¸å¹³ç­‰ã€‚ç ”ç©¶äººå‘˜é€šè¿‡æ ‡å‡†åŒ–æ¡†æ¶å¯¹ 200 å¤šç§è¯­è¨€çš„åˆ†è¯æ•ˆç‡è¿›è¡Œäº†å¤§è§„æ¨¡è¯„ä¼°ï¼Œåˆ©ç”¨ tiktoken åº“å¹¶é‡‡ç”¨æ¯å¥ Token æ•°ï¼ˆTPSï¼‰å’Œç›¸å¯¹åˆ†è¯æˆæœ¬ï¼ˆRTCï¼‰ç­‰æŒ‡æ ‡è¿›è¡Œé‡åŒ–ã€‚åˆ†ææ˜¾ç¤ºï¼Œæ‹‰ä¸è¯­ç³»è¯­è¨€çš„åˆ†è¯æ•ˆç‡è¾ƒé«˜ï¼Œè€Œéæ‹‰ä¸è¯­ç³»åŠå½¢æ€å¤æ‚çš„è¯­è¨€åˆ™é¢ä¸´ä¸¥é‡çš„ Token è†¨èƒ€ï¼Œå…¶ RTC æ¯”ä¾‹é€šå¸¸æ¯”è‹±æ–‡åŸºå‡†é«˜å‡º 3 åˆ° 5 å€ã€‚è¿™ç§å·®å¼‚ä¸ä»…å¢åŠ äº†è®¡ç®—æˆæœ¬ï¼Œè¿˜æ˜¾è‘—é™ä½äº†è¿™äº›è¯­è¨€åœ¨æ¨¡å‹ä¸­çš„æœ‰æ•ˆä¸Šä¸‹æ–‡åˆ©ç”¨ç‡ï¼ˆContext utilizationï¼‰ã€‚ç ”ç©¶æ­ç¤ºäº†å½“å‰ AI ç³»ç»Ÿä¸­å­˜åœ¨çš„ç»“æ„æ€§ä¸å¹³ç­‰ï¼Œå¹¶å»ºè®®æœªæ¥åº”å¼€å‘èåˆè¯­è¨€å­¦å¤šæ ·æ€§çš„åˆ†è¯ç­–ç•¥ï¼Œä»¥å®ç°æ›´å…·åŒ…å®¹æ€§å’Œè®¡ç®—å…¬å¹³æ€§çš„å¤šè¯­è¨€äººå·¥æ™ºèƒ½ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "6 pages 4 figures",
      "pdf_url": "https://arxiv.org/pdf/2510.12389v1",
      "published_date": "2025-10-14 11:14:38 UTC",
      "updated_date": "2025-10-14 11:14:38 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:25:21.664494+00:00"
    },
    {
      "arxiv_id": "2510.12384v3",
      "title": "Phenome-Wide Multi-Omics Integration Uncovers Distinct Archetypes of Human Aging",
      "title_zh": "å…¨è¡¨å‹ç»„å¤šç»„å­¦æ•´åˆæ­ç¤ºäººç±»è¡°è€çš„ç‹¬ç‰¹åŸå‹",
      "authors": [
        "Huifa Li",
        "Feilong Tang",
        "Haochen Xue",
        "Yulong Li",
        "Xinlin Zhuang",
        "Bin Zhang",
        "Eran Segal",
        "Imran Razzak"
      ],
      "abstract": "Aging is a highly complex and heterogeneous process that progresses at different rates across individuals, making biological age (BA) a more accurate indicator of physiological decline than chronological age. While previous studies have built aging clocks using single-omics data, they often fail to capture the full molecular complexity of human aging. In this work, we leveraged the Human Phenotype Project, a large-scale cohort of 10,000 adults aged 40-70 years, with extensive longitudinal profiling that includes clinical, behavioral, environmental, and multi-omics datasets spanning transcriptomics, lipidomics, metabolomics, and the microbiome. By employing advanced machine learning frameworks capable of modeling nonlinear biological dynamics, we developed and rigorously validated a multi-omics aging clock that robustly predicts diverse health outcomes and future disease risk. Unsupervised clustering of the integrated molecular profiles from multi-omics uncovered distinct biological subtypes of aging, revealing striking heterogeneity in aging trajectories and pinpointing pathway-specific alterations associated with different aging patterns. These findings demonstrate the power of multi-omics integration to decode the molecular landscape of aging and lay the groundwork for personalized healthspan monitoring and precision strategies to prevent age-related diseases.",
      "tldr_zh": "è¯¥ç ”ç©¶åˆ©ç”¨Human Phenotype Projectä¸­ä¸€ä¸‡åæˆå¹´äººçš„å¤§è§„æ¨¡é˜Ÿåˆ—ï¼Œæ•´åˆäº†æ¶µç›–transcriptomicsã€lipidomicsã€metabolomicså’Œmicrobiomeçš„å¤šç»„å­¦æ•°æ®é›†ã€‚ç ”ç©¶é€šè¿‡èƒ½å¤Ÿå»ºæ¨¡éçº¿æ€§ç”Ÿç‰©åŠ¨åŠ›å­¦çš„é«˜çº§machine learningæ¡†æ¶ï¼Œå¼€å‘å¹¶éªŒè¯äº†ä¸€ä¸ªmulti-omics aging clockï¼Œç”¨ä»¥ç²¾ç¡®é¢„æµ‹å¤šç§å¥åº·ç»“æœåŠæœªæ¥ç–¾ç—…é£é™©ã€‚é€šè¿‡å¯¹é›†æˆåˆ†å­è°±è¿›è¡Œæ— ç›‘ç£èšç±»ï¼Œè¯¥å·¥ä½œæ­ç¤ºäº†äººç±»è¡°è€çš„ä¸åŒç”Ÿç‰©å­¦äºšå‹(archetypes)ï¼Œå±•ç°äº†è¡°è€è½¨è¿¹ä¸­æ˜¾è‘—çš„å¼‚è´¨æ€§ï¼Œå¹¶é”å®šäº†ä¸ä¸åŒè¡°è€æ¨¡å¼ç›¸å…³çš„pathway-specificæ”¹å˜ã€‚è¿™äº›å‘ç°å‡¸æ˜¾äº†å¤šç»„å­¦é›†æˆåœ¨è§£ç è¡°è€åˆ†å­æ™¯è§‚ä¸­çš„æ ¸å¿ƒä½œç”¨ï¼Œä¸ºä¸ªæ€§åŒ–healthspanç›‘æµ‹å’Œé¢„é˜²å¹´é¾„ç›¸å…³ç–¾ç—…çš„ç²¾å‡†ç­–ç•¥æä¾›äº†ç§‘å­¦ä¾æ®ã€‚è¯¥ç ”ç©¶é€šè¿‡å¤„ç†å¤æ‚çš„åˆ†å­åŠ¨æ€ï¼ŒæˆåŠŸå…‹æœäº†å•ç»„å­¦è¡°è€æ—¶é’Ÿåœ¨æ•æ‰äººç±»è¡°è€å…¨è²Œæ—¶çš„å±€é™æ€§ã€‚",
      "categories": [
        "q-bio.GN",
        "cs.AI"
      ],
      "primary_category": "q-bio.GN",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.12384v3",
      "published_date": "2025-10-14 11:00:51 UTC",
      "updated_date": "2025-10-23 08:18:20 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:25:25.240639+00:00"
    },
    {
      "arxiv_id": "2510.12379v1",
      "title": "LiteVPNet: A Lightweight Network for Video Encoding Control in Quality-Critical Applications",
      "title_zh": "LiteVPNetï¼šä¸€ç§é¢å‘è´¨é‡ä¸¥è‹›å‹åº”ç”¨çš„è§†é¢‘ç¼–ç æ§åˆ¶è½»é‡åŒ–ç½‘ç»œ",
      "authors": [
        "Vibhoothi Vibhoothi",
        "FranÃ§ois PitiÃ©",
        "Anil Kokaram"
      ],
      "abstract": "In the last decade, video workflows in the cinema production ecosystem have presented new use cases for video streaming technology. These new workflows, e.g. in On-set Virtual Production, present the challenge of requiring precise quality control and energy efficiency. Existing approaches to transcoding often fall short of these requirements, either due to a lack of quality control or computational overhead. To fill this gap, we present a lightweight neural network (LiteVPNet) for accurately predicting Quantisation Parameters for NVENC AV1 encoders that achieve a specified VMAF score. We use low-complexity features, including bitstream characteristics, video complexity measures, and CLIP-based semantic embeddings. Our results demonstrate that LiteVPNet achieves mean VMAF errors below 1.2 points across a wide range of quality targets. Notably, LiteVPNet achieves VMAF errors within 2 points for over 87% of our test corpus, c.f. approx 61% with state-of-the-art methods. LiteVPNet's performance across various quality regions highlights its applicability for enhancing high-value content transport and streaming for more energy-efficient, high-quality media experiences.",
      "tldr_zh": "é’ˆå¯¹ç”µå½±åˆ¶ä½œç”Ÿæ€ç³»ç»Ÿï¼Œç‰¹åˆ«æ˜¯ç°åœºè™šæ‹Ÿåˆ¶ä½œï¼ˆOn-set Virtual Productionï¼‰ä¸­å¯¹ç²¾ç¡®è§†é¢‘è´¨é‡æ§åˆ¶å’Œèƒ½æ•ˆçš„é«˜è¦æ±‚ï¼Œæœ¬ç ”ç©¶æå‡ºäº† LiteVPNetï¼Œè¿™æ˜¯ä¸€ç§ç”¨äºå‡†ç¡®é¢„æµ‹ NVENC AV1 ç¼–ç å™¨é‡åŒ–å‚æ•°ï¼ˆQuantisation Parametersï¼‰ä»¥è¾¾åˆ°æŒ‡å®š VMAF è¯„åˆ†çš„è½»é‡çº§ç¥ç»ç½‘ç»œã€‚è¯¥æ¨¡å‹ç»“åˆäº†ä½æµç‰¹æ€§ï¼ˆbitstream characteristicsï¼‰ã€è§†é¢‘å¤æ‚åº¦æµ‹é‡ï¼ˆvideo complexity measuresï¼‰å’ŒåŸºäº CLIP çš„è¯­ä¹‰åµŒå…¥ï¼ˆCLIP-based semantic embeddingsï¼‰ç­‰ä½å¤æ‚åº¦ç‰¹å¾ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒLiteVPNet åœ¨å¤šç§è´¨é‡ç›®æ ‡ä¸‹çš„å¹³å‡ VMAF è¯¯å·®ä½äº 1.2 åˆ†ã€‚ä¸ç°æœ‰æœ€å…ˆè¿›ï¼ˆstate-of-the-artï¼‰æ–¹æ³•çº¦ 61% çš„è¾¾æ ‡ç‡ç›¸æ¯”ï¼ŒLiteVPNet åœ¨è¶…è¿‡ 87% çš„æµ‹è¯•æ ·æœ¬ä¸­å°†è¯¯å·®æ§åˆ¶åœ¨ 2 åˆ†ä»¥å†…ã€‚LiteVPNet çš„é«˜æ•ˆæ€§èƒ½ä½¿å…¶éå¸¸é€‚ç”¨äºé«˜ä»·å€¼å†…å®¹çš„ä¼ è¾“ä¸æµåª’ä½“åˆ†å‘ï¼Œä¸ºå®ç°æ›´èŠ‚èƒ½ã€é«˜è´¨é‡çš„åª’ä½“ä½“éªŒæä¾›äº†æœ‰åŠ›æ”¯æŒã€‚",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.LG",
        "cs.MM"
      ],
      "primary_category": "eess.IV",
      "comment": "Accepted PCS 2025 Camera-Ready Version, 5 Pages",
      "pdf_url": "https://arxiv.org/pdf/2510.12379v1",
      "published_date": "2025-10-14 10:51:49 UTC",
      "updated_date": "2025-10-14 10:51:49 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:25:25.749695+00:00"
    },
    {
      "arxiv_id": "2510.12376v1",
      "title": "Deep Attention-guided Adaptive Subsampling",
      "title_zh": "æ·±åº¦æ³¨æ„åŠ›å¼•å¯¼çš„è‡ªé€‚åº”ä¸‹é‡‡æ ·",
      "authors": [
        "Sharath M Shankaranarayana",
        "Soumava Kumar Roy",
        "Prasad Sudhakar",
        "Chandan Aladahalli"
      ],
      "abstract": "Although deep neural networks have provided impressive gains in performance, these improvements often come at the cost of increased computational complexity and expense. In many cases, such as 3D volume or video classification tasks, not all slices or frames are necessary due to inherent redundancies. To address this issue, we propose a novel learnable subsampling framework that can be integrated into any neural network architecture. Subsampling, being a nondifferentiable operation, poses significant challenges for direct adaptation into deep learning models. While some works, have proposed solutions using the Gumbel-max trick to overcome the problem of non-differentiability, they fall short in a crucial aspect: they are only task-adaptive and not inputadaptive. Once the sampling mechanism is learned, it remains static and does not adjust to different inputs, making it unsuitable for real-world applications. To this end, we propose an attention-guided sampling module that adapts to inputs even during inference. This dynamic adaptation results in performance gains and reduces complexity in deep neural network models. We demonstrate the effectiveness of our method on 3D medical imaging datasets from MedMNIST3D as well as two ultrasound video datasets for classification tasks, one of them being a challenging in-house dataset collected under real-world clinical conditions.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§åŸºäºæ³¨æ„åŠ›å¼•å¯¼çš„è‡ªé€‚åº”å­é‡‡æ ·æ¡†æ¶(Deep Attention-guided Adaptive Subsampling)ï¼Œæ—¨åœ¨è§£å†³æ·±åº¦ç¥ç»ç½‘ç»œåœ¨å¤„ç†3DåŒ»å­¦å½±åƒ(3D medical imaging)å’Œè§†é¢‘ç­‰å†—ä½™æ•°æ®æ—¶é¢ä¸´çš„é«˜è®¡ç®—å¤æ‚åº¦é—®é¢˜ã€‚é’ˆå¯¹å­é‡‡æ ·(Subsampling)æ“ä½œä¸å¯å¾®ä»¥åŠç°æœ‰æ–¹æ³•ç¼ºä¹è¾“å…¥è‡ªé€‚åº”æ€§(Input-adaptive)çš„æŒ‘æˆ˜ï¼Œä½œè€…é€šè¿‡æ³¨æ„åŠ›æ¨¡å—ä½¿é‡‡æ ·æœºåˆ¶èƒ½å¤Ÿåœ¨æ¨ç†(Inference)é˜¶æ®µæ ¹æ®è¾“å…¥å†…å®¹åŠ¨æ€è°ƒæ•´ã€‚è¿™ç§åŠ¨æ€è‡ªé€‚åº”ç­–ç•¥å…‹æœäº†ä¼ ç»ŸGumbel-max trickå¯¼è‡´é‡‡æ ·ç­–ç•¥åœ¨å­¦ä¹ åä¿æŒé™æ€çš„å±€é™ï¼Œç¡®ä¿äº†æ¨¡å‹èƒ½å¤Ÿé’ˆå¯¹ä¸åŒè¾“å…¥çµæ´»é€‰æ‹©å…³é”®å¸§æˆ–åˆ‡ç‰‡ã€‚å®éªŒåœ¨MedMNIST3Dä»¥åŠåŒ…å«ä¸´åºŠçœŸå®è¶…å£°è§†é¢‘åœ¨å†…çš„å¤šä¸ªæ•°æ®é›†ä¸ŠéªŒè¯äº†è¯¥æ–¹æ³•çš„æœ‰æ•ˆæ€§ï¼Œç»“æœè¡¨æ˜è¯¥æ–¹æ³•åœ¨æå‡åˆ†ç±»æ€§èƒ½çš„åŒæ—¶æ˜¾è‘—é™ä½äº†è®¡ç®—å¼€é”€ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.12376v1",
      "published_date": "2025-10-14 10:50:45 UTC",
      "updated_date": "2025-10-14 10:50:45 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:25:27.062073+00:00"
    },
    {
      "arxiv_id": "2510.12367v1",
      "title": "LLM-REVal: Can We Trust LLM Reviewers Yet?",
      "title_zh": "LLM-REValï¼šæˆ‘ä»¬ç°åœ¨å¯ä»¥ä¿¡ä»»å¤§è¯­è¨€æ¨¡å‹å®¡ç¨¿äººäº†å—ï¼Ÿ",
      "authors": [
        "Rui Li",
        "Jia-Chen Gu",
        "Po-Nien Kung",
        "Heming Xia",
        "Junfeng liu",
        "Xiangwen Kong",
        "Zhifang Sui",
        "Nanyun Peng"
      ],
      "abstract": "The rapid advancement of large language models (LLMs) has inspired researchers to integrate them extensively into the academic workflow, potentially reshaping how research is practiced and reviewed. While previous studies highlight the potential of LLMs in supporting research and peer review, their dual roles in the academic workflow and the complex interplay between research and review bring new risks that remain largely underexplored. In this study, we focus on how the deep integration of LLMs into both peer-review and research processes may influence scholarly fairness, examining the potential risks of using LLMs as reviewers by simulation. This simulation incorporates a research agent, which generates papers and revises, alongside a review agent, which assesses the submissions. Based on the simulation results, we conduct human annotations and identify pronounced misalignment between LLM-based reviews and human judgments: (1) LLM reviewers systematically inflate scores for LLM-authored papers, assigning them markedly higher scores than human-authored ones; (2) LLM reviewers persistently underrate human-authored papers with critical statements (e.g., risk, fairness), even after multiple revisions. Our analysis reveals that these stem from two primary biases in LLM reviewers: a linguistic feature bias favoring LLM-generated writing styles, and an aversion toward critical statements. These results highlight the risks and equity concerns posed to human authors and academic research if LLMs are deployed in the peer review cycle without adequate caution. On the other hand, revisions guided by LLM reviews yield quality gains in both LLM-based and human evaluations, illustrating the potential of the LLMs-as-reviewers for early-stage researchers and enhancing low-quality papers.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å¤§å‹è¯­è¨€æ¨¡å‹(LLMs)åœ¨å­¦æœ¯å·¥ä½œæµä¸­ä½œä¸ºå®¡ç¨¿äººçš„æ½œåœ¨é£é™©ï¼Œæå‡ºäº†LLM-REValæ¡†æ¶æ¥è¯„ä¼°LLMå®¡ç¨¿äººä¸äººç±»åˆ¤æ–­ä¹‹é—´çš„ä¸€è‡´æ€§ã€‚ç ”ç©¶é€šè¿‡æ¨¡æ‹Ÿç ”ç©¶æ™ºèƒ½ä½“(research agent)ç”ŸæˆåŠä¿®æ”¹è®ºæ–‡ä¸è¯„å®¡æ™ºèƒ½ä½“(review agent)è¿›è¡Œè¯„ä¼°çš„è¿‡ç¨‹ï¼Œå¹¶ç»“åˆäººå·¥æ ‡æ³¨æ­ç¤ºäº†LLMå®¡ç¨¿äººçš„æ ¸å¿ƒåå·®ã€‚å®éªŒå‘ç°LLMå®¡ç¨¿äººå­˜åœ¨æ˜¾è‘—çš„è¯­è¨€ç‰¹å¾åå¥½(linguistic feature bias)ï¼Œä¼šç³»ç»Ÿæ€§åœ°ä¸ºLLMæ’°å†™çš„è®ºæ–‡æä¾›æ›´é«˜è¯„åˆ†ï¼ŒåŒæ—¶å¯¹åŒ…å«æ‰¹åˆ¤æ€§è¡¨è¿°ï¼ˆå¦‚æ¶‰åŠé£é™©ã€å…¬å¹³æ€§ï¼‰çš„äººç±»è®ºæ–‡è¡¨ç°å‡ºæ˜æ˜¾çš„åŒæ¶å’Œåä½è¯„ä»·ã€‚ç ”ç©¶ç»“æœè¡¨æ˜ï¼Œè‹¥åœ¨ç¼ºä¹è¶³å¤Ÿè°¨æ…çš„æƒ…å†µä¸‹å°†LLMséƒ¨ç½²äºåŒè¡Œè¯„å®¡å¾ªç¯ï¼Œå°†å¯¹äººç±»ä½œè€…å’Œå­¦æœ¯å…¬å¹³æ€§æ„æˆé£é™©ã€‚å°½ç®¡å¦‚æ­¤ï¼Œç ”ç©¶ä¹Ÿå‘ç°ç”±LLMè¯„å®¡å¼•å¯¼çš„ä¿®æ”¹èƒ½æ˜¾è‘—æå‡è®ºæ–‡è´¨é‡ï¼Œæ˜¾ç¤ºå‡ºå…¶åœ¨è¾…åŠ©åˆçº§ç ”ç©¶è€…å’Œä¼˜åŒ–ä½è´¨é‡è®ºæ–‡æ–¹é¢çš„åº”ç”¨æ½œåŠ›ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.12367v1",
      "published_date": "2025-10-14 10:30:20 UTC",
      "updated_date": "2025-10-14 10:30:20 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:25:30.060814+00:00"
    },
    {
      "arxiv_id": "2510.12364v2",
      "title": "(R)evolution of Programming: Vibe Coding as a Post-Coding Paradigm",
      "title_zh": "ç¼–ç¨‹çš„ï¼ˆé©ï¼‰æ–°æ¼”åŒ–ï¼šä½œä¸ºåç¼–ç¨‹èŒƒå¼çš„ Vibe Coding",
      "authors": [
        "Kevin Krings",
        "Nino S. Bohn",
        "Thomas Ludwig"
      ],
      "abstract": "Recent advancements in generative artificial intelligence (GenAI), particularly large language models, have introduced new possibilities for software development practices. In our paper we investigate the emerging Vibe Coding (VC) paradigm that emphasizes intuitive, affect-driven, and improvisational interactions between developers and AI systems. Building upon the discourse of End-User Development (EUD), we explore how VC diverges from conventional programming approaches such as those supported by tools like GitHub Copilot. Through five semi-structured interview sessions with ten experienced software practitioners, we identify five thematic dimensions: creativity, sustainability, the future of programming, collaboration, and criticism. Our analysis conceptualizes VC within the metaphor of co-drifting, contrasting it with the prevalent co-piloting perspective of AI-assisted development. We argue that VC reconfigures the developers role, blurring boundaries between professional and non-developers. While VC enables novel forms of expression and rapid prototyping, it also introduces challenges regarding reproducibility, scalability, and inclusivity. We propose that VC represents a meaningful shift in programming culture, warranting further investigation within human-computer interaction (HCI) and software engineering research.",
      "tldr_zh": "æœ¬ç ”ç©¶æ¢è®¨äº†åä¸º Vibe Coding (VC) çš„æ–°å…´ç¼–ç¨‹èŒƒå¼ï¼Œè¿™æ˜¯ä¸€ç§åœ¨ç”Ÿæˆå¼äººå·¥æ™ºèƒ½ (GenAI) é©±åŠ¨ä¸‹ï¼Œå¼ºè°ƒå¼€å‘è€…ä¸ AI ä¹‹é—´ç›´è§‰ã€æƒ…æ„Ÿé©±åŠ¨å’Œå³å…´äº¤äº’çš„åç¼–ç¨‹æ¨¡å¼ã€‚è¯¥ç ”ç©¶åŸºäºç»ˆç«¯ç”¨æˆ·å¼€å‘ (End-User Development) çš„è®¨è®ºï¼Œé€šè¿‡å¯¹ 10 ä½èµ„æ·±è½¯ä»¶ä»ä¸šè€…è¿›è¡ŒåŠç»“æ„åŒ–è®¿è°ˆï¼Œæ·±å…¥åˆ†æäº† Vibe Coding ä¸ä»¥ GitHub Copilot ä¸ºä»£è¡¨çš„ä¼ ç»Ÿ AI è¾…åŠ©å¼€å‘è·¯å¾„çš„åŒºåˆ«ã€‚ç ”ç©¶è¯†åˆ«äº†åŒ…æ‹¬åˆ›æ„ã€å¯æŒç»­æ€§ã€ç¼–ç¨‹æœªæ¥ã€åä½œå’Œæ‰¹è¯„åœ¨å†…çš„äº”ä¸ªæ ¸å¿ƒç»´åº¦ï¼Œå¹¶æå‡ºäº†â€œå…±åŒæ¼‚æµâ€(co-drifting) è¿™ä¸€éšå–»æ¥å®šä¹‰è¿™ç§æ–°å‹å¼€å‘å…³ç³»ï¼Œä»è€ŒåŒºåˆ«äºä¸»æµçš„â€œå‰¯é©¾é©¶â€(co-piloting) è§†è§’ã€‚Vibe Coding é‡æ–°é…ç½®äº†å¼€å‘è€…çš„è§’è‰²ï¼Œåœ¨æ¨¡ç³Šä¸“ä¸šäººå£«ä¸éå¼€å‘è€…ç•Œé™çš„åŒæ—¶ï¼Œæ”¯æŒäº†æ–°é¢–çš„è¡¨è¾¾å½¢å¼å’Œå¿«é€ŸåŸå‹è®¾è®¡ (rapid prototyping)ã€‚å°½ç®¡è¯¥èŒƒå¼æå‡äº†å¼€å‘çµæ´»æ€§ï¼Œä½†åœ¨å¯é‡å¤æ€§ (reproducibility)ã€å¯æ‰©å±•æ€§ (scalability) å’ŒåŒ…å®¹æ€§æ–¹é¢ä»é¢ä¸´é‡å¤§æŒ‘æˆ˜ã€‚ç ”ç©¶æœ€åæŒ‡å‡ºï¼ŒVibe Coding ä»£è¡¨äº†ç¼–ç¨‹æ–‡åŒ–çš„æ·±åˆ»è½¬å‹ï¼Œæ˜¯äººæœºäº¤äº’ (HCI) å’Œè½¯ä»¶å·¥ç¨‹ç ”ç©¶é¢†åŸŸä¸­å€¼å¾—è¿›ä¸€æ­¥æ¢ç´¢çš„é‡è¦æ–¹å‘ã€‚",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.SE",
      "comment": "Workshop Contribution at the sixth decennial Aarhus conference in \"The End of Programming (as we know it) - Envisioning Radical Re-Conceptualizations of Co-Coding with AI\"",
      "pdf_url": "https://arxiv.org/pdf/2510.12364v2",
      "published_date": "2025-10-14 10:25:56 UTC",
      "updated_date": "2025-10-15 14:43:26 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:25:46.449353+00:00"
    },
    {
      "arxiv_id": "2510.12350v2",
      "title": "O-Forge: An LLM + Computer Algebra Framework for Asymptotic Analysis",
      "title_zh": "O-Forgeï¼šé¢å‘æ¸è¿‘åˆ†æçš„å¤§è¯­è¨€æ¨¡å‹ä¸è®¡ç®—æœºä»£æ•°æ¡†æ¶",
      "authors": [
        "Ayush Khaitan",
        "Vijay Ganesh"
      ],
      "abstract": "Large language models have recently demonstrated advanced capabilities in solving IMO and Putnam problems; yet their role in research mathematics has remained fairly limited. The key difficulty is verification: suggested proofs may look plausible, but cannot be trusted without rigorous checking. We present a framework, called LLM+CAS, and an associated tool, O-Forge, that couples frontier LLMs with a computer algebra systems (CAS) in an In-Context Symbolic Feedback loop to produce proofs that are both creative and symbolically verified. Our focus is on asymptotic inequalities, a topic that often involves difficult proofs and appropriate decomposition of the domain into the \"right\" subdomains. Many mathematicians, including Terry Tao, have suggested that using AI tools to find the right decompositions can be very useful for research-level asymptotic analysis. In this paper, we show that our framework LLM+CAS turns out to be remarkably effective at proposing such decompositions via a combination of a frontier LLM and a CAS. More precisely, we use an LLM to suggest domain decomposition, and a CAS (such as Mathematica) that provides a verification of each piece axiomatically. Using this loop, we answer a question posed by Terence Tao: whether LLMs coupled with a verifier can be used to help prove intricate asymptotic inequalities. More broadly, we show how AI can move beyond contest math towards research-level tools for professional mathematicians.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† O-Forgeï¼Œè¿™æ˜¯ä¸€ä¸ªå°†å¤§è¯­è¨€æ¨¡å‹ (LLM) ä¸è®¡ç®—æœºä»£æ•°ç³»ç»Ÿ (CAS) ç›¸ç»“åˆçš„æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³ AI åœ¨ç§‘ç ”æ•°å­¦é¢†åŸŸé¢ä¸´çš„ä¸¥è°¨æ€§éªŒè¯éš¾é¢˜ã€‚è¯¥æ¡†æ¶ä¸“æ³¨äºå¤„ç†å¤æ‚çš„ Asymptotic Analysis (æ¸è¿‘åˆ†æ) ä¸ç­‰å¼è¯æ˜ï¼Œåˆ©ç”¨ LLM æå‡ºåˆ›é€ æ€§çš„ Domain Decomposition (åŒºåŸŸåˆ†è§£) ç­–ç•¥ï¼Œå¹¶ç»“åˆ CAS è¿›è¡Œå…¬ç†åŒ–çš„ç¬¦å·éªŒè¯ã€‚é€šè¿‡æ„å»º In-Context Symbolic Feedback (ä¸Šä¸‹æ–‡ç¬¦å·åé¦ˆ) å¾ªç¯ï¼ŒO-Forge èƒ½å¤Ÿæœ‰æ•ˆè¯æ˜é‚£äº›é€šå¸¸éœ€è¦ç²¾ç»†åŒºåŸŸæ‹†åˆ†çš„æ•°å­¦å‘½é¢˜ã€‚è¿™é¡¹å·¥ä½œç›´æ¥å›åº”äº†æ•°å­¦å®¶ Terence Tao å…³äº AI è¾…åŠ©ç ”ç©¶çº§æ¸è¿‘åˆ†æçš„è®¾æƒ³ï¼Œå±•ç¤ºäº† AI å¦‚ä½•ä»å¤„ç†ç«èµ›æ•°å­¦è½¬å‘ä¸ºä¸“ä¸šæ•°å­¦å®¶æä¾›ç§‘ç ”æ”¯æŒï¼Œç¡®ä¿ç”Ÿæˆçš„è¯æ˜æ—¢å…·å¯å‘æ€§åˆå…·å¤‡ä¸¥æ ¼çš„ç¬¦å·æ­£ç¡®æ€§ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.12350v2",
      "published_date": "2025-10-14 10:07:53 UTC",
      "updated_date": "2025-10-16 13:07:41 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:25:45.814828+00:00"
    },
    {
      "arxiv_id": "2510.12334v1",
      "title": "Finite-time Convergence Analysis of Actor-Critic with Evolving Reward",
      "title_zh": "æ¼”åŒ–å¥–åŠ±ä¸‹ Actor-Critic ç®—æ³•çš„æœ‰é™æ—¶é—´æ”¶æ•›æ€§åˆ†æ",
      "authors": [
        "Rui Hu",
        "Yu Chen",
        "Longbo Huang"
      ],
      "abstract": "Many popular practical reinforcement learning (RL) algorithms employ evolving reward functions-through techniques such as reward shaping, entropy regularization, or curriculum learning-yet their theoretical foundations remain underdeveloped. This paper provides the first finite-time convergence analysis of a single-timescale actor-critic algorithm in the presence of an evolving reward function under Markovian sampling. We consider a setting where the reward parameters may change at each time step, affecting both policy optimization and value estimation. Under standard assumptions, we derive non-asymptotic bounds for both actor and critic errors. Our result shows that an $O(1/\\sqrt{T})$ convergence rate is achievable, matching the best-known rate for static rewards, provided the reward parameters evolve slowly enough. This rate is preserved when the reward is updated via a gradient-based rule with bounded gradient and on the same timescale as the actor and critic, offering a theoretical foundation for many popular RL techniques. As a secondary contribution, we introduce a novel analysis of distribution mismatch under Markovian sampling, improving the best-known rate by a factor of $\\log^2T$ in the static-reward case.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¼ºåŒ–å­¦ä¹ (Reinforcement Learning)ä¸­å¸¸ç”¨çš„æ¼”åŒ–å¥–åŠ±å‡½æ•°(Evolving Reward functions)â€”â€”å¦‚å¥–åŠ±å¡‘é€ (Reward Shaping)ã€ç†µæ­£åˆ™åŒ–(Entropy Regularization)æˆ–è¯¾ç¨‹å­¦ä¹ (Curriculum Learning)â€”â€”ç¼ºä¹ç†è®ºåŸºç¡€çš„é—®é¢˜å±•å¼€åˆ†æã€‚æœ¬æ–‡é¦–æ¬¡æå‡ºäº†åœ¨é©¬å°”å¯å¤«é‡‡æ ·(Markovian Sampling)ä¸‹ï¼Œå…·æœ‰æ¼”åŒ–å¥–åŠ±å‡½æ•°çš„å•æ—¶é—´å°ºåº¦(Single-Timescale) Actor-Criticç®—æ³•çš„æœ‰é™æ—¶é—´æ”¶æ•›æ€§åˆ†æã€‚ç ”ç©¶è€ƒè™‘äº†å¥–åŠ±å‚æ•°åœ¨æ¯ä¸ªæ—¶é—´æ­¥å¯èƒ½å‘ç”Ÿå˜åŒ–çš„æƒ…å†µï¼Œè¿™ç§å˜åŒ–ä¼šåŒæ—¶å½±å“ç­–ç•¥ä¼˜åŒ–(Policy Optimization)å’Œä»·å€¼ä¼°è®¡(Value Estimation)ã€‚åœ¨æ ‡å‡†å‡è®¾ä¸‹ï¼Œè¯¥ç ”ç©¶æ¨å¯¼å‡ºäº† Actor å’Œ Critic è¯¯å·®çš„éæ¸è¿‘ç•Œ(Non-asymptotic Bounds)ï¼Œè¯æ˜äº†åªè¦å¥–åŠ±å‚æ•°æ¼”åŒ–è¶³å¤Ÿç¼“æ…¢ï¼Œç®—æ³•å³å¯è¾¾åˆ° $O(1/\\sqrt{T})$ çš„æ”¶æ•›é€Ÿåº¦ã€‚è¿™ä¸€é€Ÿç‡ä¸é™æ€å¥–åŠ±(Static Rewards)ä¸‹çš„æœ€ä½³å·²çŸ¥é€Ÿç‡ä¸€è‡´ï¼Œä¸”åœ¨å¥–åŠ±é€šè¿‡åŸºäºæ¢¯åº¦çš„è§„åˆ™æ›´æ–°ä¸”æ›´æ–°é¢‘ç‡ä¸ç®—æ³•ä¸€è‡´æ—¶ä¾ç„¶æœ‰æ•ˆã€‚æ­¤å¤–ï¼Œç ”ç©¶è¿˜å¼•å…¥äº†ä¸€ç§é’ˆå¯¹é©¬å°”å¯å¤«é‡‡æ ·ä¸‹åˆ†å¸ƒå¤±é…(Distribution Mismatch)çš„æ–°å‹åˆ†ææ–¹æ³•ï¼Œå°†é™æ€å¥–åŠ±æƒ…å†µä¸‹çš„æœ€ä½³å·²çŸ¥é€Ÿç‡æå‡äº† $\\log^2T$ å€ã€‚è¯¥æˆæœä¸ºå¤šç§æµè¡Œçš„å¼ºåŒ–å­¦ä¹ æŠ€æœ¯æä¾›äº†åšå®çš„ç†è®ºåŸºç¡€ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.12334v1",
      "published_date": "2025-10-14 09:45:19 UTC",
      "updated_date": "2025-10-14 09:45:19 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:25:48.451806+00:00"
    },
    {
      "arxiv_id": "2511.13726v1",
      "title": "Refine Thought: A Test-Time Inference Method for Embedding Model Reasoning",
      "title_zh": "Refine Thoughtï¼šé¢å‘åµŒå…¥æ¨¡å‹æ¨ç†çš„æµ‹è¯•æ—¶æ¨ç†æ–¹æ³•",
      "authors": [
        "Guangzhi Wang",
        "Kai Li",
        "Yinghao Jiao",
        "Zhi Liu"
      ],
      "abstract": "We propose RT (Refine Thought), a method that can enhance the semantic rea-soning ability of text embedding models. The method obtains the final semanticrepresentation by running multiple forward passes of the text embedding model.Experiments show that RT achieves significant improvements on semantic reason-ing tasks in BRIGHT and the person job matching benchmark PJBenchmark1, while maintaining consistent performance on general-purpose semantic under-standing tasks such as C-MTEB. Our results indicate that RT is effective becauseit further activates the semantic reasoning ability learned during pretraining bydecoder-only text embedding models(e.g., Qwen3-Embedding-8B). RT canbe seen as a test-time inference method.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†RT (Refine Thought)ï¼Œè¿™æ˜¯ä¸€ç§æ—¨åœ¨å¢å¼ºæ–‡æœ¬åµŒå…¥æ¨¡å‹(text embedding models)è¯­ä¹‰æ¨ç†èƒ½åŠ›çš„æµ‹è¯•æ—¶æ¨ç†(test-time inference)æ–¹æ³•ã€‚è¯¥æ–¹æ³•é€šè¿‡å¯¹æ¨¡å‹è¿›è¡Œå¤šæ¬¡æ­£å‘ä¼ æ’­(forward passes)æ¥ç”Ÿæˆæœ€ç»ˆçš„è¯­ä¹‰è¡¨ç¤ºï¼Œä»è€Œè¿›ä¸€æ­¥æ¿€æ´»äº†ä»…è§£ç å™¨(decoder-only)æ¶æ„æ¨¡å‹åœ¨é¢„è®­ç»ƒé˜¶æ®µç§¯ç´¯çš„è¯­ä¹‰æ¨ç†æ½œèƒ½ã€‚å®éªŒè¡¨æ˜ï¼ŒRTåœ¨BRIGHTè¯­ä¹‰æ¨ç†ä»»åŠ¡å’ŒPJBenchmarkäººå²—åŒ¹é…åŸºå‡†æµ‹è¯•ä¸­å‡å–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ï¼ŒåŒæ—¶åœ¨C-MTEBç­‰é€šç”¨è¯­ä¹‰ç†è§£ä»»åŠ¡ä¸Šä¿æŒäº†ç¨³å®šçš„è¡¨ç°ã€‚è¯¥é¡¹å·¥ä½œè¯æ˜äº†é€šè¿‡æ¨ç†æ—¶é—´çš„æ–¹æ³•ä¼˜åŒ–åµŒå…¥æ¨¡å‹è¡¨ç°çš„å¯è¡Œæ€§ï¼Œç‰¹åˆ«æ˜¯é’ˆå¯¹Qwen3-Embedding-8Bç­‰æ¨¡å‹ï¼Œä¸ºå…¶åœ¨å¤æ‚è¯­ä¹‰åœºæ™¯ä¸‹çš„åº”ç”¨æä¾›äº†æœ‰æ•ˆè·¯å¾„ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2511.13726v1",
      "published_date": "2025-10-14 09:35:27 UTC",
      "updated_date": "2025-10-14 09:35:27 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:25:50.564164+00:00"
    },
    {
      "arxiv_id": "2510.16001v1",
      "title": "A Non-overlap-based Conflict Measure for Random Permutation Sets",
      "title_zh": "éšæœºæ’åˆ—é›†çš„ä¸€ç§éé‡å å†²çªåº¦é‡",
      "authors": [
        "Ruolan Cheng",
        "Yong Deng",
        "Enrique Herrera-Viedma"
      ],
      "abstract": "Random permutation set (RPS) is a new formalism for reasoning with uncertainty involving order information. Measuring the conflict between two pieces of evidence represented by permutation mass functions remains an urgent research topic in order-structured uncertain information fusion. In this paper, a detailed analysis of conflicts in RPS is carried out from two different perspectives: random finite set (RFS) and Dempster-Shafer theory (DST). Starting from the observation of permutations, we first define an inconsistency measure between permutations inspired by the rank-biased overlap(RBO) measure and further propose a non-overlap-based conflict measure method for RPSs. This paper regards RPS theory (RPST) as an extension of DST. The order information newly added in focal sets indicates qualitative propensity, characterized by top-ranked elements occupying a more critical position. Some numerical examples are used to demonstrate the behavior and properties of the proposed conflict measure. The proposed method not only has the natural top-weightedness property and can effectively measure the conflict between RPSs from the DST view but also provides decision-makers with a flexible selection of weights, parameters, and truncated depths.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤„ç†é¡ºåºä¸ç¡®å®šä¿¡æ¯çš„ Random Permutation Set (RPS) ç†è®ºï¼Œæ¢è®¨äº†è¡¡é‡ä¸¤ä¸ªè¯æ®ç‰‡æ–­ä¹‹é—´å†²çªçš„ç´§è¿«é—®é¢˜ã€‚ä½œè€…ä» Random Finite Set (RFS) å’Œ Dempster-Shafer Theory (DST) ä¸¤ä¸ªè§†è§’å‡ºå‘ï¼Œå¯¹ RPS ä¸­çš„å†²çªè¿›è¡Œäº†è¯¦ç»†åˆ†æã€‚è®ºæ–‡å— Rank-biased Overlap (RBO) å¯å‘ï¼Œå®šä¹‰äº†æ’åˆ—é—´çš„ä¸ä¸€è‡´æ€§åº¦é‡ï¼Œå¹¶è¿›ä¸€æ­¥æå‡ºäº†ä¸€ç§åŸºäºéé‡å çš„ RPS å†²çªè¡¡é‡æ–¹æ³•ã€‚è¯¥æ–¹æ³•å°† RPS è§†ä¸º DST çš„æ‰©å±•ï¼Œåˆ©ç”¨ç„¦å…ƒä¸­çš„é¡ºåºä¿¡æ¯æ¥åˆ»ç”»å®šæ€§å€¾å‘ï¼Œå¼ºè°ƒæ’åé å‰çš„å…ƒç´ å…·æœ‰æ›´é«˜çš„å…³é”®æ€§ã€‚æå‡ºçš„åº¦é‡æ–¹æ³•ä¸ä»…å…·æœ‰è‡ªç„¶çš„ Top-weightedness ç‰¹æ€§ï¼Œèƒ½æœ‰æ•ˆä» DST è§†è§’è¯„ä¼° RPS é—´çš„å†²çªï¼Œè¿˜ä¸ºå†³ç­–è€…æä¾›äº†æƒé‡ã€å‚æ•°å’Œæˆªæ–­æ·±åº¦çš„çµæ´»é€‰æ‹©ã€‚æ•°å€¼ç¤ºä¾‹éªŒè¯äº†è¯¥æ–¹æ³•çš„è¡Œä¸ºç‰¹æ€§åŠå…¶åœ¨å¤„ç†å…·æœ‰é¡ºåºç‰¹å¾çš„ä¸ç¡®å®šä¿¡æ¯èåˆä»»åŠ¡ä¸­çš„æœ‰æ•ˆæ€§ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.16001v1",
      "published_date": "2025-10-14 09:35:03 UTC",
      "updated_date": "2025-10-14 09:35:03 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:25:53.546117+00:00"
    },
    {
      "arxiv_id": "2510.12327v1",
      "title": "Simple Projection Variants Improve ColBERT Performance",
      "title_zh": "ç®€å•æŠ•å½±å˜ä½“æå‡ ColBERT æ€§èƒ½",
      "authors": [
        "Benjamin ClaviÃ©",
        "Sean Lee",
        "Rikiya Takehi",
        "Aamir Shakir",
        "Makoto P. Kato"
      ],
      "abstract": "Multi-vector dense retrieval methods like ColBERT systematically use a single-layer linear projection to reduce the dimensionality of individual vectors. In this study, we explore the implications of the MaxSim operator on the gradient flows of the training of multi-vector models and show that such a simple linear projection has inherent, if non-critical, limitations in this setting. We then discuss the theoretical improvements that could result from replacing this single-layer projection with well-studied alternative feedforward linear networks (FFN), such as deeper, non-linear FFN blocks, GLU blocks, and skip-connections, could alleviate these limitations. Through the design and systematic evaluation of alternate projection blocks, we show that better-designed final projections positively impact the downstream performance of ColBERT models. We highlight that many projection variants outperform the original linear projections, with the best-performing variants increasing average performance on a range of retrieval benchmarks across domains by over 2 NDCG@10 points. We then conduct further exploration on the individual parameters of these projections block in order to understand what drives this empirical performance, highlighting the particular importance of upscaled intermediate projections and residual connections. As part of these ablation studies, we show that numerous suboptimal projection variants still outperform the traditional single-layer projection across multiple benchmarks, confirming our hypothesis. Finally, we observe that this effect is consistent across random seeds, further confirming that replacing the linear layer of ColBERT models is a robust, drop-in upgrade.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†æŠ•å½±å±‚å˜ä½“å¯¹ ColBERT ç­‰å¤šå‘é‡å¯†é›†æ£€ç´¢æ¨¡å‹æ€§èƒ½çš„å½±å“ã€‚ä½œè€…é€šè¿‡åˆ†æ MaxSim ç®—å­å¯¹è®­ç»ƒæ¢¯åº¦æµçš„ä½œç”¨ï¼ŒæŒ‡å‡ºä¼ ç»Ÿçš„å•å±‚çº¿æ€§æŠ•å½± (linear projection) åœ¨è¯¥è®¾å®šä¸‹å­˜åœ¨å›ºæœ‰å±€é™ã€‚ä¸ºä¼˜åŒ–æ¨¡å‹ï¼Œç ”ç©¶æå‡ºä½¿ç”¨æ›´å¤æ‚çš„å¯†é›†å‰é¦ˆç½‘ç»œ (FFN) æ›¿ä»£å•å±‚æŠ•å½±ï¼ŒåŒ…æ‹¬éçº¿æ€§ FFN æ¨¡å—ã€GLU æ¨¡å—å’Œè·³è·ƒè¿æ¥ (skip-connections)ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œå¤šç§æŠ•å½±å˜ä½“åœ¨å¤šä¸ªæ£€ç´¢åŸºå‡†æµ‹è¯•ä¸­å‡ä¼˜äºåŸå§‹çº¿æ€§æŠ•å½±ï¼Œå…¶ä¸­æœ€ä½³å˜ä½“åœ¨ NDCG@10 æŒ‡æ ‡ä¸Šå¹³å‡æå‡äº† 2 ä¸ªç‚¹ä»¥ä¸Šã€‚æ¶ˆèå®éªŒè¿›ä¸€æ­¥è¯å®ï¼Œæå‡ä¸­é—´æŠ•å½±ç»´åº¦å’Œå¼•å…¥æ®‹å·®è¿æ¥æ˜¯æ€§èƒ½å¢é•¿çš„å…³é”®å› ç´ ã€‚è¯¥é¡¹å·¥ä½œæœ€ç»ˆè¯æ˜ï¼Œæ›¿æ¢ ColBERT çš„çº¿æ€§å±‚æ˜¯ä¸€ç§é²æ£’ä¸”å¯ç›´æ¥åº”ç”¨çš„æ€§èƒ½å‡çº§æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.12327v1",
      "published_date": "2025-10-14 09:34:05 UTC",
      "updated_date": "2025-10-14 09:34:05 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:25:57.756367+00:00"
    },
    {
      "arxiv_id": "2510.12325v1",
      "title": "Causal Inspired Multi Modal Recommendation",
      "title_zh": "å› æœå¯å‘çš„å¤šæ¨¡æ€æ¨è",
      "authors": [
        "Jie Yang",
        "Chenyang Gu",
        "Zixuan Liu"
      ],
      "abstract": "Multimodal recommender systems enhance personalized recommendations in e-commerce and online advertising by integrating visual, textual, and user-item interaction data. However, existing methods often overlook two critical biases: (i) modal confounding, where latent factors (e.g., brand style or product category) simultaneously drive multiple modalities and influence user preference, leading to spurious feature-preference associations; (ii) interaction bias, where genuine user preferences are mixed with noise from exposure effects and accidental clicks. To address these challenges, we propose a Causal-inspired multimodal Recommendation framework. Specifically, we introduce a dual-channel cross-modal diffusion module to identify hidden modal confounders, utilize back-door adjustment with hierarchical matching and vector-quantized codebooks to block confounding paths, and apply front-door adjustment combined with causal topology reconstruction to build a deconfounded causal subgraph. Extensive experiments on three real-world e-commerce datasets demonstrate that our method significantly outperforms state-of-the-art baselines while maintaining strong interpretability.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤šæ¨¡æ€æ¨èç³»ç»Ÿä¸­å­˜åœ¨çš„modal confoundingå’Œinteraction biasé—®é¢˜ï¼Œæå‡ºäº†ä¸€ä¸ªCausal-inspired multimodal Recommendationæ¡†æ¶ã€‚è¯¥æ¡†æ¶é€šè¿‡å¼•å…¥åŒé€šé“cross-modal diffusionæ¨¡å—è¯†åˆ«éšè—çš„æ··æ‚å› å­ï¼Œå¹¶åˆ©ç”¨hierarchical matchingå’Œvector-quantized codebooksæ‰§è¡Œback-door adjustmentä»¥é˜»æ–­æ··æ‚è·¯å¾„ã€‚æ­¤å¤–ï¼Œç ”ç©¶ç»“åˆcausal topology reconstructionåº”ç”¨front-door adjustmentï¼Œæ„å»ºäº†å»æ··æ‚çš„å› æœå­å›¾ï¼Œä»è€Œæ›´ç²¾å‡†åœ°æ•æ‰ç”¨æˆ·çœŸå®åå¥½ã€‚åœ¨ä¸‰ä¸ªçœŸå®ç”µå­å•†åŠ¡æ•°æ®é›†ä¸Šçš„å¹¿æ³›å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨æ€§èƒ½ä¸Šæ˜¾è‘—ä¼˜äºç°æœ‰SOTAåŸºçº¿ï¼Œå¹¶å…·æœ‰è¾ƒå¼ºçš„interpretabilityï¼Œæœ‰æ•ˆè§£å†³äº†è™šå‡ç‰¹å¾å…³è”ä¸äº¤äº’å™ªå£°å¸¦æ¥çš„æŒ‘æˆ˜ã€‚",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.12325v1",
      "published_date": "2025-10-14 09:29:07 UTC",
      "updated_date": "2025-10-14 09:29:07 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:25:59.452273+00:00"
    },
    {
      "arxiv_id": "2510.12323v1",
      "title": "RAG-Anything: All-in-One RAG Framework",
      "title_zh": "RAG-Anythingï¼šä¸€ä½“åŒ– RAG æ¡†æ¶",
      "authors": [
        "Zirui Guo",
        "Xubin Ren",
        "Lingrui Xu",
        "Jiahao Zhang",
        "Chao Huang"
      ],
      "abstract": "Retrieval-Augmented Generation (RAG) has emerged as a fundamental paradigm for expanding Large Language Models beyond their static training limitations. However, a critical misalignment exists between current RAG capabilities and real-world information environments. Modern knowledge repositories are inherently multimodal, containing rich combinations of textual content, visual elements, structured tables, and mathematical expressions. Yet existing RAG frameworks are limited to textual content, creating fundamental gaps when processing multimodal documents. We present RAG-Anything, a unified framework that enables comprehensive knowledge retrieval across all modalities. Our approach reconceptualizes multimodal content as interconnected knowledge entities rather than isolated data types. The framework introduces dual-graph construction to capture both cross-modal relationships and textual semantics within a unified representation. We develop cross-modal hybrid retrieval that combines structural knowledge navigation with semantic matching. This enables effective reasoning over heterogeneous content where relevant evidence spans multiple modalities. RAG-Anything demonstrates superior performance on challenging multimodal benchmarks, achieving significant improvements over state-of-the-art methods. Performance gains become particularly pronounced on long documents where traditional approaches fail. Our framework establishes a new paradigm for multimodal knowledge access, eliminating the architectural fragmentation that constrains current systems. Our framework is open-sourced at: https://github.com/HKUDS/RAG-Anything.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† RAG-Anythingï¼Œè¿™æ˜¯ä¸€ä¸ªæ—¨åœ¨è§£å†³å½“å‰ Retrieval-Augmented Generation (RAG) æ¡†æ¶å±€é™æ€§çš„ä¸€ç«™å¼å¤šæ¨¡æ€æ£€ç´¢å¢å¼ºç”Ÿæˆæ¡†æ¶ã€‚ç°æœ‰çš„ RAG ç³»ç»Ÿé€šå¸¸ä»…é™äºå¤„ç†æ–‡æœ¬ï¼Œéš¾ä»¥åº”å¯¹åŒ…å«è§†è§‰å…ƒç´ ã€è¡¨æ ¼å’Œæ•°å­¦è¡¨è¾¾å¼çš„çœŸå®ä¸–ç•Œå¤šæ¨¡æ€çŸ¥è¯†åº“ã€‚RAG-Anything é€šè¿‡å°†å¤šæ¨¡æ€å†…å®¹é‡æ–°æ„æƒ³ä¸ºç›¸äº’è¿æ¥çš„çŸ¥è¯†å®ä½“ï¼Œå¹¶å¼•å…¥åŒå›¾æ„å»º (Dual-graph construction) æŠ€æœ¯ï¼Œç»Ÿä¸€è¡¨å¾è·¨æ¨¡æ€å…³ç³»ä¸æ–‡æœ¬è¯­ä¹‰ã€‚æ¡†æ¶è¿›ä¸€æ­¥é‡‡ç”¨è·¨æ¨¡æ€æ··åˆæ£€ç´¢ (Cross-modal hybrid retrieval) æœºåˆ¶ï¼Œå°†ç»“æ„åŒ–çŸ¥è¯†å¯¼èˆªä¸è¯­ä¹‰åŒ¹é…ç›¸ç»“åˆï¼Œå®ç°äº†åœ¨å¼‚æ„å†…å®¹ä¸Šçš„æœ‰æ•ˆæ¨ç†ã€‚å®éªŒè¡¨æ˜ï¼Œè¯¥æ¡†æ¶åœ¨æŒ‘æˆ˜æ€§çš„å¤šæ¨¡æ€åŸºå‡†æµ‹è¯•ä¸­è¡¨ç°ä¼˜å¼‚ï¼Œå°¤å…¶åœ¨ä¼ ç»Ÿæ–¹æ³•éš¾ä»¥å¤„ç†çš„é•¿æ–‡æ¡£åœºæ™¯ä¸‹å–å¾—äº†æ˜¾è‘—æå‡ã€‚è¿™ä¸€å·¥ä½œå»ºç«‹äº†å¤šæ¨¡æ€çŸ¥è¯†è·å–çš„æ–°èŒƒå¼ï¼Œæ¶ˆé™¤äº†ç°æœ‰ç³»ç»Ÿå› æ¶æ„ç¢ç‰‡åŒ–å¯¼è‡´çš„é™åˆ¶ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.12323v1",
      "published_date": "2025-10-14 09:25:35 UTC",
      "updated_date": "2025-10-14 09:25:35 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:26:02.959646+00:00"
    },
    {
      "arxiv_id": "2510.12312v1",
      "title": "Deep SPI: Safe Policy Improvement via World Models",
      "title_zh": "Deep SPIï¼šåŸºäºä¸–ç•Œæ¨¡å‹çš„å®‰å…¨ç­–ç•¥æ”¹è¿›",
      "authors": [
        "Florent Delgrange",
        "Raphael Avalos",
        "Willem RÃ¶pke"
      ],
      "abstract": "Safe policy improvement (SPI) offers theoretical control over policy updates, yet existing guarantees largely concern offline, tabular reinforcement learning (RL). We study SPI in general online settings, when combined with world model and representation learning. We develop a theoretical framework showing that restricting policy updates to a well-defined neighborhood of the current policy ensures monotonic improvement and convergence. This analysis links transition and reward prediction losses to representation quality, yielding online, \"deep\" analogues of classical SPI theorems from the offline RL literature. Building on these results, we introduce DeepSPI, a principled on-policy algorithm that couples local transition and reward losses with regularised policy updates. On the ALE-57 benchmark, DeepSPI matches or exceeds strong baselines, including PPO and DeepMDPs, while retaining theoretical guarantees.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†åœ¨é€šç”¨åœ¨çº¿è®¾ç½®ä¸‹ï¼Œç»“åˆ world model å’Œ representation learning çš„ Safe policy improvement (SPI) é—®é¢˜ã€‚ä½œè€…æå‡ºäº†ä¸€ä¸ªç†è®ºæ¡†æ¶ï¼Œè¯æ˜å°†ç­–ç•¥æ›´æ–°é™åˆ¶åœ¨å½“å‰ç­–ç•¥çš„æ˜ç¡®å®šä¹‰çš„é‚»åŸŸå†…å¯ä»¥ç¡®ä¿å•è°ƒæ”¹è¿› (monotonic improvement) å’Œæ”¶æ•›ã€‚è¯¥åˆ†æå°† transition å’Œ reward é¢„æµ‹æŸå¤±ä¸è¡¨ç¤ºè´¨é‡è”ç³»èµ·æ¥ï¼Œå¾—å‡ºäº†ç»å…¸ç¦»çº¿ RL æ–‡çŒ®ä¸­ SPI å®šç†çš„åœ¨çº¿â€œæ·±åº¦â€æ¨¡æ‹Ÿã€‚åŸºäºè¿™äº›ç†è®ºç»“æœï¼Œç ”ç©¶å¼•å…¥äº† DeepSPIï¼Œè¿™æ˜¯ä¸€ç§å°†å±€éƒ¨ transition å’Œ reward æŸå¤±ä¸æ­£åˆ™åŒ–ç­–ç•¥æ›´æ–°ç›¸ç»“åˆçš„åŸåˆ™æ€§ on-policy ç®—æ³•ã€‚åœ¨ ALE-57 åŸºå‡†æµ‹è¯•ä¸­ï¼ŒDeepSPI åœ¨ä¿ç•™ç†è®ºä¿è¯çš„åŒæ—¶ï¼Œå…¶æ€§èƒ½è¾¾åˆ°æˆ–è¶…è¿‡äº† PPO å’Œ DeepMDPs ç­‰å¼ºåŸºçº¿æ¨¡å‹ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "10 pages main text, 17 pages appendix (excluding references)",
      "pdf_url": "https://arxiv.org/pdf/2510.12312v1",
      "published_date": "2025-10-14 09:11:24 UTC",
      "updated_date": "2025-10-14 09:11:24 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:26:04.964055+00:00"
    },
    {
      "arxiv_id": "2510.15998v1",
      "title": "AMStraMGRAM: Adaptive Multi-cutoff Strategy Modification for ANaGRAM",
      "title_zh": "AMStraMGRAMï¼šé’ˆå¯¹ ANaGRAM çš„è‡ªé€‚åº”å¤šé‡æˆªæ–­ç­–ç•¥æ”¹è¿›",
      "authors": [
        "Nilo Schwencke",
        "Cyriaque Rousselot",
        "Alena Shilova",
        "Cyril Furtlehner"
      ],
      "abstract": "Recent works have shown that natural gradient methods can significantly outperform standard optimizers when training physics-informed neural networks (PINNs). In this paper, we analyze the training dynamics of PINNs optimized with ANaGRAM, a natural-gradient-inspired approach employing singular value decomposition with cutoff regularization. Building on this analysis, we propose a multi-cutoff adaptation strategy that further enhances ANaGRAM's performance. Experiments on benchmark PDEs validate the effectiveness of our method, which allows to reach machine precision on some experiments. To provide theoretical grounding, we develop a framework based on spectral theory that explains the necessity of regularization and extend previous shown connections with Green's functions theory.",
      "tldr_zh": "è¯¥ç ”ç©¶åˆ†æäº†åœ¨ç‰©ç†ä¿¡æ¯ç¥ç»ç½‘ç»œ (PINNs) è®­ç»ƒä¸­è¡¨ç°ä¼˜äºæ ‡å‡†ä¼˜åŒ–å™¨çš„ ANaGRAM æ–¹æ³•ï¼Œé‡ç‚¹ç ”ç©¶å…¶åŸºäºå¥‡å¼‚å€¼åˆ†è§£ (SVD) å’Œæˆªæ–­æ­£åˆ™åŒ– (cutoff regularization) çš„è®­ç»ƒåŠ¨åŠ›å­¦ã€‚é’ˆå¯¹ ANaGRAM çš„å±€é™æ€§ï¼Œä½œè€…æå‡ºäº† AMStraMGRAMï¼Œè¿™æ˜¯ä¸€ç§è‡ªé€‚åº”å¤šæˆªæ–­ç­–ç•¥æ”¹è¿›æ–¹æ¡ˆï¼Œæ—¨åœ¨è¿›ä¸€æ­¥å¢å¼ºåŸæœ‰çš„ä¼˜åŒ–æ€§èƒ½ã€‚åœ¨åŸºå‡†åå¾®åˆ†æ–¹ç¨‹ (PDEs) ä¸Šçš„å®éªŒéªŒè¯äº†è¯¥æ–¹æ³•çš„æœ‰æ•ˆæ€§ï¼Œå¹¶åœ¨ç‰¹å®šå®éªŒä¸­æˆåŠŸè¾¾åˆ°äº†æœºå™¨ç²¾åº¦ (machine precision)ã€‚æ­¤å¤–ï¼Œç ”ç©¶è¿˜å»ºç«‹äº†ä¸€ä¸ªåŸºäºè°±ç†è®º (spectral theory) çš„æ¡†æ¶æ¥è§£é‡Šæ­£åˆ™åŒ–çš„å¿…è¦æ€§ï¼Œå¹¶æ·±åŒ–äº†ä¸æ ¼æ—å‡½æ•° (Green's functions) ç†è®ºçš„å†…åœ¨è”ç³»ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.15998v1",
      "published_date": "2025-10-14 09:10:42 UTC",
      "updated_date": "2025-10-14 09:10:42 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:26:10.159816+00:00"
    },
    {
      "arxiv_id": "2510.12850v1",
      "title": "Ethic-BERT: An Enhanced Deep Learning Model for Ethical and Non-Ethical Content Classification",
      "title_zh": "Ethic-BERTï¼šç”¨äºä¼¦ç†ä¸éä¼¦ç†å†…å®¹åˆ†ç±»çš„å¢å¼ºå‹æ·±åº¦å­¦ä¹ æ¨¡å‹",
      "authors": [
        "Mahamodul Hasan Mahadi",
        "Md. Nasif Safwan",
        "Souhardo Rahman",
        "Shahnaj Parvin",
        "Aminun Nahar",
        "Kamruddin Nur"
      ],
      "abstract": "Developing AI systems capable of nuanced ethical reasoning is critical as they increasingly influence human decisions, yet existing models often rely on superficial correlations rather than principled moral understanding. This paper introduces Ethic-BERT, a BERT-based model for ethical content classification across four domains: Commonsense, Justice, Virtue, and Deontology. Leveraging the ETHICS dataset, our approach integrates robust preprocessing to address vocabulary sparsity and contextual ambiguities, alongside advanced fine-tuning strategies like full model unfreezing, gradient accumulation, and adaptive learning rate scheduling. To evaluate robustness, we employ an adversarially filtered \"Hard Test\" split, isolating complex ethical dilemmas. Experimental results demonstrate Ethic-BERT's superiority over baseline models, achieving 82.32% average accuracy on the standard test, with notable improvements in Justice and Virtue. In addition, the proposed Ethic-BERT attains 15.28% average accuracy improvement in the HardTest. These findings contribute to performance improvement and reliable decision-making using bias-aware preprocessing and proposed enhanced AI model.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† Ethic-BERTï¼Œè¿™æ˜¯ä¸€ç§åŸºäº BERT çš„å¢å¼ºå‹æ·±åº¦å­¦ä¹ æ¨¡å‹ï¼Œæ—¨åœ¨æå‡ AI ç³»ç»Ÿåœ¨ Commonsense, Justice, Virtue å’Œ Deontology å››ä¸ªé¢†åŸŸçš„ä¼¦ç†å†…å®¹åˆ†ç±»èƒ½åŠ›ã€‚ä¸ºäº†å…‹æœç°æœ‰æ¨¡å‹ä¾èµ–è¡¨é¢ç›¸å…³æ€§çš„å±€é™ï¼Œè¯¥æ–¹æ³•æ•´åˆäº†é²æ£’çš„é¢„å¤„ç†æŠ€æœ¯ä»¥åº”å¯¹è¯æ±‡ç¨€ç–ä¸ä¸Šä¸‹æ–‡æ­§ä¹‰ï¼Œå¹¶é‡‡ç”¨äº†å…¨æ¨¡å‹è§£å†» (full model unfreezing)ã€æ¢¯åº¦ç´¯ç§¯ (gradient accumulation) åŠè‡ªé€‚åº”å­¦ä¹ ç‡è°ƒåº¦ (adaptive learning rate scheduling) ç­‰å…ˆè¿›å¾®è°ƒç­–ç•¥ã€‚ç ”ç©¶åˆ©ç”¨ ETHICS æ•°æ®é›†è¿›è¡Œè®­ç»ƒï¼Œå¹¶å¼•å…¥å¯¹æŠ—æ€§è¿‡æ»¤çš„ Hard Test åˆ†ç»„æ¥è¯„ä¼°æ¨¡å‹åœ¨å¤æ‚ä¼¦ç†å›°å¢ƒä¸‹çš„ç¨³å¥æ€§ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒEthic-BERT åœ¨æ ‡å‡†æµ‹è¯•é›†ä¸Šè¾¾åˆ°äº† 82.32% çš„å¹³å‡å‡†ç¡®ç‡ï¼Œä¸”åœ¨ Hard Test ä¸Šçš„æ€§èƒ½æ¯”åŸºçº¿æ¨¡å‹æå‡äº† 15.28%ã€‚è¯¥æ¨¡å‹åœ¨ Justice å’Œ Virtue é¢†åŸŸçš„è¡¨ç°å°¤ä¸ºçªå‡ºï¼Œè¯æ˜äº†é€šè¿‡åå·®æ„ŸçŸ¥é¢„å¤„ç†ä¸æ¨¡å‹å¢å¼ºèƒ½å¤Ÿæ˜¾è‘—æé«˜ AI å†³ç­–çš„å¯é æ€§ä¸é“å¾·ç†è§£åŠ›ã€‚",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.12850v1",
      "published_date": "2025-10-14 08:42:14 UTC",
      "updated_date": "2025-10-14 08:42:14 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:26:20.492335+00:00"
    },
    {
      "arxiv_id": "2510.12285v1",
      "title": "Chinese ModernBERT with Whole-Word Masking",
      "title_zh": "é‡‡ç”¨å…¨è¯æ©ç æŠ€æœ¯çš„ä¸­æ–‡ ModernBERT",
      "authors": [
        "Zeyu Zhao",
        "Ningtao Wang",
        "Xing Fu",
        "Yu Cheng"
      ],
      "abstract": "Encoder-only Transformers have advanced along three axes -- architecture, data, and systems -- yielding Pareto gains in accuracy, speed, and memory efficiency. Yet these improvements have not fully transferred to Chinese, where tokenization and morphology differ markedly from English. We introduce Chinese ModernBERT, a from-scratch Chinese encoder that couples: (i) a hardware-aware 32k BPE vocabulary tailored to frequent Chinese affixes/compounds, lowering the embedding budget; (ii) whole-word masking (WWM) with a dynamic masking curriculum (30% -> 15%) to align task difficulty with training progress; (iii) a two-stage pre-training pipeline that extends the native context from 1,024 to 8,192 tokens using RoPE and alternating local/global attention; and (iv) a damped-cosine learning-rate schedule for stable long-horizon optimization. We pre-train on ~1.2T Chinese tokens from CCI3-HQ, CCI4 (Chinese), and Cosmopedia-Chinese. On CLUE, Chinese ModernBERT is competitive with strong Chinese encoders under a unified fine-tuning protocol. Under bf16 it achieves high long-sequence throughput while maintaining strong short-sequence speed, reflecting benefits from budget allocation and attention design. To probe retrieval-oriented quality, we add a small amount of open contrastive data: fine-tuning on SimCLUE (~3M pairs) improves further when adding T2Ranking (~2M), reaching 0.505 (Pearson) / 0.537 (Spearman) on the SimCLUE test set. Under this open-data setting, Chinese ModernBERT surpasses Qwen-0.6B-embedding on SimCLUE, suggesting a clear scaling path for STS with additional curated pairs. We will release tokenizer and weights to facilitate reproducible research.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¨å‡ºäº† Chinese ModernBERTï¼Œè¿™æ˜¯ä¸€ä¸ªä»é›¶å¼€å§‹è®­ç»ƒçš„ä¸­æ–‡ç¼–ç å™¨ï¼Œæ—¨åœ¨è§£å†³ç°æœ‰ç¼–ç å™¨åœ¨ä¸­æ–‡åˆ†è¯å’Œå½¢æ€å­¦é€‚åº”æ€§ä¸Šçš„ä¸è¶³ã€‚è¯¥æ¨¡å‹é‡‡ç”¨é’ˆå¯¹ä¸­æ–‡è¯ç¼€ä¼˜åŒ–çš„ç¡¬ä»¶æ„ŸçŸ¥ 32k BPE è¯è¡¨ï¼Œå¹¶ç»“åˆå…¨è¯é®ç›–(Whole-Word Masking, WWM)åŠåŠ¨æ€é®ç›–è¯¾ç¨‹å­¦ä¹ ç­–ç•¥ï¼Œå°†é¢„è®­ç»ƒä»»åŠ¡éš¾åº¦ä¸è¿›åº¦å¯¹é½ã€‚é€šè¿‡ä¸¤é˜¶æ®µé¢„è®­ç»ƒã€æ—‹è½¬ä½ç½®åµŒå…¥(RoPE)ä»¥åŠäº¤æ›¿çš„å±€éƒ¨/å…¨å±€æ³¨æ„åŠ›æœºåˆ¶(local/global attention)ï¼Œæ¨¡å‹æˆåŠŸå°†åŸç”Ÿä¸Šä¸‹æ–‡é•¿åº¦æ‰©å±•è‡³ 8,192 ä¸ª tokenã€‚åŸºäºçº¦ 1.2T ä¸­æ–‡ token çš„é¢„è®­ç»ƒä½¿è¯¥æ¨¡å‹åœ¨ CLUE åŸºå‡†æµ‹è¯•ä¸­è¡¨ç°å‡ºè‰²ï¼Œä¸”åœ¨ bf16 ç²¾åº¦ä¸‹å…¼é¡¾äº†é«˜ååé‡ä¸æ¨ç†é€Ÿåº¦ã€‚åœ¨è¯­ä¹‰æ–‡æœ¬ç›¸ä¼¼åº¦ä»»åŠ¡ä¸­ï¼ŒChinese ModernBERT åœ¨ç»è¿‡å¯¹æ¯”å­¦ä¹ å¾®è°ƒåæ€§èƒ½è¶…è¶Šäº† Qwen-0.6B-embeddingï¼Œå±•ç¤ºäº†æ¸…æ™°çš„æ‰©å±•è·¯å¾„ã€‚è¯¥é¡¹ç›®çš„æƒé‡ä¸åˆ†è¯å™¨å°†å…¬å¼€å‘å¸ƒï¼Œä»¥ä¿ƒè¿›ä¸­æ–‡è‡ªç„¶è¯­è¨€å¤„ç†é¢†åŸŸçš„å¤ç°ä¸ç ”ç©¶ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.12285v1",
      "published_date": "2025-10-14 08:41:22 UTC",
      "updated_date": "2025-10-14 08:41:22 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:26:32.697183+00:00"
    },
    {
      "arxiv_id": "2510.15996v1",
      "title": "Using Kolmogorov-Smirnov Distance for Measuring Distribution Shift in Machine Learning",
      "title_zh": "åˆ©ç”¨ Kolmogorov-Smirnov è·ç¦»è¡¡é‡æœºå™¨å­¦ä¹ ä¸­çš„åˆ†å¸ƒåç§»",
      "authors": [
        "Ozan K. Tonguz",
        "Federico Taschin"
      ],
      "abstract": "One of the major problems in Machine Learning (ML) and Artificial Intelligence (AI) is the fact that the probability distribution of the test data in the real world could deviate substantially from the probability distribution of the training data set. When this happens, the predictions of an ML system or an AI agent could involve large errors which is very troublesome and undesirable. While this is a well-known hard problem plaguing the AI and ML systems' accuracy and reliability, in certain applications such errors could be critical for safety and reliability of AI and ML systems. One approach to deal with this problem is to monitor and measure the deviation in the probability distribution of the test data in real time and to compensate for this deviation. In this paper, we propose and explore the use of Kolmogorov-Smirnov (KS) Test for measuring the distribution shift and we show how the KS distance can be used to quantify the distribution shift and its impact on an AI agent's performance. Our results suggest that KS distance could be used as a valuable statistical tool for monitoring and measuring the distribution shift. More specifically, it is shown that even a distance of KS=0.02 could lead to about 50\\% increase in the travel time at a single intersection using a Reinforcement Learning agent which is quite significant. It is hoped that the use of KS Test and KS distance in AI-based smart transportation could be an important step forward for gauging the performance degradation of an AI agent in real time and this, in turn, could help the AI agent to cope with the distribution shift in a more informed manner.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†åœ¨æœºå™¨å­¦ä¹ (Machine Learning)ä¸­åº”å¯¹åˆ†å¸ƒåç§»(Distribution Shift)çš„é—®é¢˜ï¼Œå³å®é™…æµ‹è¯•æ•°æ®ä¸è®­ç»ƒæ•°æ®åˆ†å¸ƒä¸ä¸€è‡´å¯¼è‡´çš„æ¨¡å‹å‡†ç¡®æ€§ä¸å¯é æ€§ä¸‹é™ã€‚ä¸ºäº†è§£å†³è¿™ä¸€éš¾é¢˜ï¼Œä½œè€…æå‡ºå¹¶æ¢ç´¢äº†ä½¿ç”¨ Kolmogorov-Smirnov (KS) Test æ¥å®æ—¶ç›‘æµ‹å’Œè¡¡é‡åˆ†å¸ƒåç§»ï¼Œåˆ©ç”¨ KS distance é‡åŒ–åç§»ç¨‹åº¦åŠå…¶å¯¹äººå·¥æ™ºèƒ½æ™ºèƒ½ä½“(AI agent)æ€§èƒ½çš„å…·ä½“å½±å“ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒKS distance æ˜¯ç›‘æµ‹æ€§èƒ½é€€åŒ–çš„æœ‰æ•ˆç»Ÿè®¡å·¥å…·ï¼Œç ”ç©¶å‘ç°ä»…ä¸º 0.02 çš„ KS è·ç¦»ä¾¿ä¼šå¯¼è‡´å¼ºåŒ–å­¦ä¹ (Reinforcement Learning)æ™ºèƒ½ä½“åœ¨å•ä¸ªè·¯å£çš„é€šè¡Œæ—¶é—´å¢åŠ çº¦ 50%ã€‚è¯¥æ–¹æ³•ä¸ºæ™ºèƒ½äº¤é€šç­‰å…³é”®é¢†åŸŸçš„ AI ç³»ç»Ÿæä¾›äº†å®æ—¶è¯„ä¼°æ€§èƒ½ä¸‹é™çš„æ‰‹æ®µï¼Œæœ‰åŠ©äºæ™ºèƒ½ä½“ä»¥æ›´å…·ä¿¡æ¯æ„ŸçŸ¥çš„æ–¹å¼åº”å¯¹åˆ†å¸ƒåç§»å¹¶æå‡ç³»ç»Ÿå®‰å…¨æ€§ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.15996v1",
      "published_date": "2025-10-14 08:35:55 UTC",
      "updated_date": "2025-10-14 08:35:55 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:26:27.303964+00:00"
    },
    {
      "arxiv_id": "2510.12278v1",
      "title": "Quantum Annealing for Staff Scheduling in Educational Environments",
      "title_zh": "é‡å­é€€ç«åœ¨æ•™è‚²ç¯å¢ƒæ•™èŒå·¥æ’ç­ä¸­çš„åº”ç”¨",
      "authors": [
        "Alessia Ciacco",
        "Francesca Guerriero",
        "Eneko Osaba"
      ],
      "abstract": "We address a novel staff allocation problem that arises in the organization of collaborators among multiple school sites and educational levels. The problem emerges from a real case study in a public school in Calabria, Italy, where staff members must be distributed across kindergartens, primary, and secondary schools under constraints of availability, competencies, and fairness. To tackle this problem, we develop an optimization model and investigate a solution approach based on quantum annealing. Our computational experiments on real-world data show that quantum annealing is capable of producing balanced assignments in short runtimes. These results provide evidence of the practical applicability of quantum optimization methods in educational scheduling and, more broadly, in complex resource allocation tasks.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹æ„å¤§åˆ©å¡æ‹‰å¸ƒé‡Œäºšåœ°åŒºå…¬ç«‹å­¦æ ¡é¢ä¸´çš„ä¸€ç§æ–°å‹æ•™èŒå·¥åˆ†é…é—®é¢˜ï¼Œæ¢è®¨äº†å¦‚ä½•åœ¨å¤šä¸ªæ ¡å€å’Œæ•™å­¦å±‚çº§é—´æœ‰æ•ˆåˆ†é…åä½œäººå‘˜ã€‚åœ¨è€ƒè™‘äººå‘˜å¯ç”¨æ€§ (Availability)ã€ä¸“ä¸šæŠ€èƒ½ (Competencies) å’Œå…¬å¹³æ€§ (Fairness) ç­‰å¤šé‡çº¦æŸçš„åŸºç¡€ä¸Šï¼Œç ”ç©¶è€…æ„å»ºäº†ä¸€ä¸ªä¼˜åŒ–æ¨¡å‹ï¼Œå¹¶æå‡ºäº†ä¸€ç§åŸºäºé‡å­é€€ç« (Quantum Annealing) çš„æ±‚è§£æ–¹æ³•ã€‚è®¡ç®—å®éªŒç»“æœè¡¨æ˜ï¼Œåˆ©ç”¨é‡å­é€€ç« (Quantum Annealing) å¤„ç†çœŸå®ä¸–ç•Œæ•°æ®æ—¶ï¼Œèƒ½å¤Ÿä»¥æçŸ­çš„è¿è¡Œæ—¶é—´ç”Ÿæˆå‡è¡¡çš„åˆ†é…æ–¹æ¡ˆã€‚è¯¥é¡¹å·¥ä½œçš„æˆåŠŸå®è·µä¸ºé‡å­ä¼˜åŒ– (Quantum Optimization) æ–¹æ³•åœ¨æ•™è‚²èµ„æºè°ƒåº¦åŠå…¶ä»–å¤æ‚èµ„æºåˆ†é…ä»»åŠ¡ä¸­çš„åº”ç”¨æä¾›äº†æœ‰åŠ›è¯æ®ã€‚",
      "categories": [
        "cs.ET",
        "cs.AI"
      ],
      "primary_category": "cs.ET",
      "comment": "8 pages, 3 tables, and 1 figure. Paper submitted to the International Conference on Quantum Communications, Networking, and Computing (QCNC 2026)",
      "pdf_url": "https://arxiv.org/pdf/2510.12278v1",
      "published_date": "2025-10-14 08:29:58 UTC",
      "updated_date": "2025-10-14 08:29:58 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:26:28.471068+00:00"
    },
    {
      "arxiv_id": "2510.12275v1",
      "title": "TFGA-Net: Temporal-Frequency Graph Attention Network for Brain-Controlled Speaker Extraction",
      "title_zh": "TFGA-Netï¼šé¢å‘è„‘æ§è¯´è¯äººæå–çš„æ—¶é¢‘å›¾æ³¨æ„åŠ›ç½‘ç»œ",
      "authors": [
        "Youhao Si",
        "Yuan Liao",
        "Qiushi Han",
        "Yuhang Yang",
        "Rui Dai",
        "Liya Huang"
      ],
      "abstract": "The rapid development of auditory attention decoding (AAD) based on electroencephalography (EEG) signals offers the possibility EEG-driven target speaker extraction. However, how to effectively utilize the target-speaker common information between EEG and speech remains an unresolved problem. In this paper, we propose a model for brain-controlled speaker extraction, which utilizes the EEG recorded from the listener to extract the target speech. In order to effectively extract information from EEG signals, we derive multi-scale time--frequency features and further incorporate cortical topological structures that are selectively engaged during the task. Moreover, to effectively exploit the non-Euclidean structure of EEG signals and capture their global features, the graph convolutional networks and self-attention mechanism are used in the EEG encoder. In addition, to make full use of the fused EEG and speech feature and preserve global context and capture speech rhythm and prosody, we introduce MossFormer2 which combines MossFormer and RNN-Free Recurrent as separator. Experimental results on both the public Cocktail Party and KUL dataset in this paper show that our TFGA-Net model significantly outper-forms the state-of-the-art method in certain objective evaluation metrics. The source code is available at: https://github.com/LaoDa-X/TFGA-NET.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹è„‘ç”µä¿¡å·ï¼ˆEEGï¼‰é©±åŠ¨çš„ç›®æ ‡è¯´è¯äººæå–ä¸­å¦‚ä½•æœ‰æ•ˆåˆ©ç”¨EEGä¸è¯­éŸ³å…±åŒä¿¡æ¯çš„é—®é¢˜ï¼Œæå‡ºäº†åä¸ºTFGA-Netçš„æ—¶ç©ºé¢‘ç‡å›¾æ³¨æ„åŠ›ç½‘ç»œæ¨¡å‹ã€‚è¯¥æ¨¡å‹é€šè¿‡æå–EEGä¿¡å·çš„å¤šå°ºåº¦æ—¶é¢‘ç‰¹å¾ï¼ˆtime-frequency featuresï¼‰ï¼Œå¹¶ç»“åˆä»»åŠ¡ç›¸å…³çš„çš®è´¨æ‹“æ‰‘ç»“æ„ï¼ˆcortical topological structuresï¼‰ï¼Œå®ç°äº†å¯¹è„‘ç”µä¿¡æ¯çš„ç²¾ç¡®è¡¨å¾ã€‚ä¸ºäº†å¤„ç†EEGä¿¡å·çš„éæ¬§å‡ é‡Œå¾—ç»“æ„ï¼Œæ¨¡å‹åœ¨ç¼–ç é˜¶æ®µé‡‡ç”¨äº†å›¾å·ç§¯ç½‘ç»œï¼ˆgraph convolutional networksï¼‰ä¸è‡ªæ³¨æ„åŠ›æœºåˆ¶ï¼ˆself-attention mechanismï¼‰ä»¥æ•è·å…¨å±€ç‰¹å¾ã€‚æ­¤å¤–ï¼Œç ”ç©¶å¼•å…¥äº†MossFormer2ä½œä¸ºåˆ†ç¦»å™¨ï¼Œç»“åˆMossFormerä¸RNN-Free RecurrentæŠ€æœ¯æ¥ä¿ç•™å…¨å±€ä¸Šä¸‹æ–‡å¹¶æ•æ‰è¯­éŸ³èŠ‚å¾‹ï¼ˆrhythmï¼‰ä¸éŸµå¾‹ï¼ˆprosodyï¼‰ã€‚åœ¨Cocktail Partyå’ŒKULæ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒTFGA-Netåœ¨å¤šé¡¹å®¢è§‚è¯„ä»·æŒ‡æ ‡ä¸Šæ˜¾è‘—ä¼˜äºç°æœ‰çš„æœ€å…ˆè¿›æ–¹æ³•ï¼Œä¸ºè„‘æ§éŸ³é¢‘å¤„ç†é¢†åŸŸæä¾›äº†æ–°çš„è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.SD",
        "cs.AI"
      ],
      "primary_category": "cs.SD",
      "comment": "5 pages, 3 figures",
      "pdf_url": "https://arxiv.org/pdf/2510.12275v1",
      "published_date": "2025-10-14 08:26:50 UTC",
      "updated_date": "2025-10-14 08:26:50 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:26:36.288711+00:00"
    },
    {
      "arxiv_id": "2510.12269v3",
      "title": "Tensor Logic: The Language of AI",
      "title_zh": "å¼ é‡é€»è¾‘ï¼šäººå·¥æ™ºèƒ½çš„è¯­è¨€",
      "authors": [
        "Pedro Domingos"
      ],
      "abstract": "Progress in AI is hindered by the lack of a programming language with all the requisite features. Libraries like PyTorch and TensorFlow provide automatic differentiation and efficient GPU implementation, but are additions to Python, which was never intended for AI. Their lack of support for automated reasoning and knowledge acquisition has led to a long and costly series of hacky attempts to tack them on. On the other hand, AI languages like LISP and Prolog lack scalability and support for learning. This paper proposes tensor logic, a language that solves these problems by unifying neural and symbolic AI at a fundamental level. The sole construct in tensor logic is the tensor equation, based on the observation that logical rules and Einstein summation are essentially the same operation, and all else can be reduced to them. I show how to elegantly implement key forms of neural, symbolic and statistical AI in tensor logic, including transformers, formal reasoning, kernel machines and graphical models. Most importantly, tensor logic makes new directions possible, such as sound reasoning in embedding space. This combines the scalability and learnability of neural networks with the reliability and transparency of symbolic reasoning, and is potentially a basis for the wider adoption of AI.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† Tensor Logicï¼Œä¸€ç§æ—¨åœ¨ä»åº•å±‚ç»Ÿä¸€ç¥ç»å’Œç¬¦å·äººå·¥æ™ºèƒ½ (neural and symbolic AI) çš„ç¼–ç¨‹è¯­è¨€ï¼Œè§£å†³äº†ç°æœ‰ AI åº“ç¼ºä¹æ¨ç†èƒ½åŠ›ä»¥åŠä¼ ç»Ÿé€»è¾‘è¯­è¨€ç¼ºä¹å¯æ‰©å±•æ€§çš„åŒé‡éš¾é¢˜ã€‚è¯¥è¯­è¨€çš„å”¯ä¸€æ ¸å¿ƒæ„å»ºå—æ˜¯å¼ é‡æ–¹ç¨‹ (tensor equation)ï¼Œå…¶ç†è®ºåŸºç¡€åœ¨äºè§‚å¯Ÿåˆ°é€»è¾‘è§„åˆ™ä¸çˆ±å› æ–¯å¦æ±‚å’Œ (Einstein summation) åœ¨æœ¬è´¨ä¸Šæ˜¯ç›¸åŒçš„æ“ä½œï¼Œä¸”æ‰€æœ‰å…¶ä»– AI è¿ç®—å‡å¯å½’çº¦äºæ­¤ã€‚Tensor Logic èƒ½å¤Ÿä¼˜é›…åœ°å®ç°åŒ…æ‹¬ Transformerã€å½¢å¼æ¨ç† (formal reasoning)ã€æ ¸æœºå™¨ (kernel machines) å’Œå›¾æ¨¡å‹ (graphical models) åœ¨å†…çš„å¤šç§å…³é”® AI å½¢å¼ã€‚æœ€é‡è¦çš„æ˜¯ï¼Œå®ƒå®ç°äº†åœ¨åµŒå…¥ç©ºé—´ (embedding space) ä¸­è¿›è¡Œå¯é æ¨ç†çš„å¯èƒ½æ€§ï¼ŒæˆåŠŸå°†ç¥ç»ç½‘ç»œçš„å¯æ‰©å±•æ€§ã€å¯å­¦ä¹ æ€§ä¸ç¬¦å·æ¨ç†çš„å¯é æ€§ã€é€æ˜åº¦æœ‰æœºç»“åˆã€‚è¿™ä¸€æˆæœä¸ºå¼€å‘å…¼å…·å¼ºå¤§æ€§èƒ½ä¸é«˜å¯è§£é‡Šæ€§çš„ AI ç³»ç»Ÿæä¾›äº†å…¨æ–°æ–¹å‘ï¼Œä¸ºäººå·¥æ™ºèƒ½çš„æ›´å¹¿æ³›åº”ç”¨å¥ å®šäº†åšå®åŸºç¡€ã€‚",
      "categories": [
        "cs.AI",
        "cs.LG",
        "cs.NE",
        "cs.PL",
        "stat.ML"
      ],
      "primary_category": "cs.AI",
      "comment": "17 pages, 0 figures",
      "pdf_url": "https://arxiv.org/pdf/2510.12269v3",
      "published_date": "2025-10-14 08:24:08 UTC",
      "updated_date": "2025-10-16 07:40:28 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:26:39.598020+00:00"
    },
    {
      "arxiv_id": "2510.12266v1",
      "title": "HiLoRA: Adaptive Hierarchical LoRA Routing for Training-Free Domain Generalization",
      "title_zh": "HiLoRAï¼šé¢å‘å…è®­ç»ƒé¢†åŸŸæ³›åŒ–çš„è‡ªé€‚åº”åˆ†å±‚ LoRA è·¯ç”±",
      "authors": [
        "Ziyi Han",
        "Huanyu Wang",
        "Zeyu Zhang",
        "Xiangxiang Dai",
        "Xutong Liu",
        "John C. S. Lui"
      ],
      "abstract": "Low-Rank Adaptation (LoRA) has emerged as a widely used technique for adapting large language models (LLMs) to new domains, due to its modular design and broad availability on platforms such as HuggingFace. This availability has motivated efforts to reuse existing LoRAs for domain generalization.\n  However, existing methods often rely on explicit task labels or additional training, which are impractical for deployment. Moreover, they typically activate a fixed number of entire LoRA modules, leading to parameter redundancy or insufficiency that degrade performance.\n  In this paper, we propose \\texttt{HiLoRA}, a training-free framework that performs adaptive hierarchical routing over LoRA pools. Drawing on structural properties of LoRA, we define rank-one components (ROCs), in which each rank parameter is regarded as an independent unit. For a given input sequence, \\texttt{HiLoRA} first adaptively selects a subset of LoRAs and determines their ROC allocation based on Gaussian likelihoods at the sequence level. At the token level, it further refines routing by activating only the most informative ROCs.\n  We further provide theoretical guarantees that \\texttt{HiLoRA} selects the most relevant LoRAs with high probability.\n  Extensive experiments show that \\texttt{HiLoRA} achieves substantial improvements in domain generalization, with accuracy gains of up to {\\small $55\\%$} over state-of-the-art baselines, while maintaining comparable inference throughput.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ Low-Rank Adaptation (LoRA) åœ¨é¢†åŸŸæ³›åŒ– (Domain Generalization) ä¸­å­˜åœ¨çš„å‚æ•°å†—ä½™å’Œéœ€è¦é¢å¤–è®­ç»ƒç­‰é—®é¢˜ï¼Œæå‡ºäº† HiLoRA æ¡†æ¶ã€‚HiLoRA æ˜¯ä¸€ç§æ— éœ€è®­ç»ƒçš„è‡ªé€‚åº”å±‚æ¬¡åŒ–è·¯ç”±æ–¹æ¡ˆï¼Œæ—¨åœ¨æœ‰æ•ˆé‡ç”¨ç°æœ‰çš„ LoRA æ¨¡å—ä»¥å®ç°é«˜æ•ˆé€‚é…ã€‚ç ”ç©¶å›¢é˜Ÿå®šä¹‰äº†ç§©ä¸€ç»„ä»¶ (Rank-One Components, ROCs)ï¼Œå°†æ¯ä¸ªç§©å‚æ•°è§†ä¸ºç‹¬ç«‹å•å…ƒï¼Œä»è€Œå®ç°æ›´ç²¾ç»†çš„æ§åˆ¶ã€‚åœ¨åºåˆ—å±‚é¢ï¼Œè¯¥æ¡†æ¶æ ¹æ® Gaussian likelihoods è‡ªé€‚åº”é€‰æ‹© LoRA å­é›†å¹¶ç¡®å®š ROCs åˆ†é…ã€‚åœ¨ Token å±‚é¢ï¼ŒHiLoRA é€šè¿‡ä»…æ¿€æ´»æœ€å…·ä¿¡æ¯é‡çš„ ROCs è¿›ä¸€æ­¥ç»†åŒ–è·¯ç”±è¿‡ç¨‹ã€‚ç†è®ºåˆ†æè¯æ˜äº†è¯¥æ–¹æ³•èƒ½å¤Ÿä»¥é«˜æ¦‚ç‡é€‰æ‹©æœ€ç›¸å…³çš„ LoRAã€‚å®éªŒè¡¨æ˜ï¼ŒHiLoRA åœ¨é¢†åŸŸæ³›åŒ–ä»»åŠ¡ä¸­ç›¸æ¯”ç°æœ‰åŸºçº¿æ¨¡å‹å®ç°äº†é«˜è¾¾ 55% çš„å‡†ç¡®ç‡æå‡ï¼ŒåŒæ—¶ä¿æŒäº†ç›¸å½“çš„æ¨ç†ååé‡ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.12266v1",
      "published_date": "2025-10-14 08:19:13 UTC",
      "updated_date": "2025-10-14 08:19:13 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:26:41.381709+00:00"
    },
    {
      "arxiv_id": "2510.12265v1",
      "title": "Human-in-the-Loop Bandwidth Estimation for Quality of Experience Optimization in Real-Time Video Communication",
      "title_zh": "å®æ—¶è§†é¢‘é€šä¿¡ä¸­é¢å‘ä½“éªŒè´¨é‡ä¼˜åŒ–çš„äººåœ¨å›è·¯å¸¦å®½ä¼°è®¡",
      "authors": [
        "Sami Khairy",
        "Gabriel Mittag",
        "Vishak Gopal",
        "Ross Cutler"
      ],
      "abstract": "The quality of experience (QoE) delivered by video conferencing systems is significantly influenced by accurately estimating the time-varying available bandwidth between the sender and receiver. Bandwidth estimation for real-time communications remains an open challenge due to rapidly evolving network architectures, increasingly complex protocol stacks, and the difficulty of defining QoE metrics that reliably improve user experience. In this work, we propose a deployed, human-in-the-loop, data-driven framework for bandwidth estimation to address these challenges. Our approach begins with training objective QoE reward models derived from subjective user evaluations to measure audio and video quality in real-time video conferencing systems. Subsequently, we collect roughly $1$M network traces with objective QoE rewards from real-world Microsoft Teams calls to curate a bandwidth estimation training dataset. We then introduce a novel distributional offline reinforcement learning (RL) algorithm to train a neural-network-based bandwidth estimator aimed at improving QoE for users. Our real-world A/B test demonstrates that the proposed approach reduces the subjective poor call ratio by $11.41\\%$ compared to the baseline bandwidth estimator. Furthermore, the proposed offline RL algorithm is benchmarked on D4RL tasks to demonstrate its generalization beyond bandwidth estimation.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ä¸ªéƒ¨ç½²äºå®é™…åœºæ™¯çš„ã€äººåœ¨å›è·¯(human-in-the-loop)çš„æ•°æ®é©±åŠ¨æ¡†æ¶ï¼Œæ—¨åœ¨ä¼˜åŒ–å®æ—¶è§†é¢‘é€šä¿¡ä¸­çš„ç”¨æˆ·ä½“éªŒè´¨é‡(QoE)å¸¦å®½ä¼°è®¡ã€‚è¯¥æ¡†æ¶é¦–å…ˆé€šè¿‡ä¸»è§‚ç”¨æˆ·è¯„ä¼°è®­ç»ƒå‡ºè¡¡é‡éŸ³è§†é¢‘è´¨é‡çš„å®¢è§‚QoEå¥–åŠ±æ¨¡å‹ï¼Œå¹¶ä»Microsoft Teamså®é™…é€šè¯ä¸­æ”¶é›†äº†çº¦100ä¸‡æ¡å¸¦æœ‰å¥–åŠ±æ ‡æ³¨çš„ç½‘ç»œè½¨è¿¹(network traces)æ•°æ®é›†ã€‚ç ”ç©¶å¼•å…¥äº†ä¸€ç§æ–°å‹çš„åˆ†å¸ƒç¦»çº¿å¼ºåŒ–å­¦ä¹ (distributional offline RL)ç®—æ³•ï¼Œä»¥æ­¤è®­ç»ƒåŸºäºç¥ç»ç½‘ç»œçš„å¸¦å®½ä¼°è®¡å™¨ã€‚å®é™…åœºæ™¯çš„A/Bæµ‹è¯•ç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•ç›¸æ¯”åŸºå‡†ä¼°è®¡å™¨å°†ä¸»è§‚é€šè¯è´¨é‡å·®çš„æ¯”ä¾‹é™ä½äº†11.41%ã€‚æ­¤å¤–ï¼Œè¯¥ç¦»çº¿RLç®—æ³•åœ¨D4RLåŸºå‡†ä»»åŠ¡ä¸Šä¹Ÿå±•ç°å‡ºäº†ä¼˜å¼‚çš„æ³›åŒ–æ€§èƒ½ï¼Œè¯æ˜äº†è¯¥æ–¹æ³•åœ¨å¸¦å®½ä¼°è®¡ä¹‹å¤–çš„é€šç”¨ä»·å€¼ã€‚",
      "categories": [
        "cs.MM",
        "cs.AI",
        "cs.NI",
        "eess.SY"
      ],
      "primary_category": "cs.MM",
      "comment": "Accepted for publication in the proceedings of the AAAI Conference on Artificial Intelligence 2026 (IAAI Technical Track on Deployed Highly Innovative Applications of AI)",
      "pdf_url": "https://arxiv.org/pdf/2510.12265v1",
      "published_date": "2025-10-14 08:18:30 UTC",
      "updated_date": "2025-10-14 08:18:30 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:26:47.186671+00:00"
    },
    {
      "arxiv_id": "2510.12264v1",
      "title": "$\\mathbf{T^3}$: Reducing Belief Deviation in Reinforcement Learning for Active Reasoning",
      "title_zh": "$\\mathbf{T^3}$ï¼šå‡å°‘å¼ºåŒ–å­¦ä¹ ä¸»åŠ¨æ¨ç†ä¸­çš„ä¿¡å¿µåå·®",
      "authors": [
        "Deyu Zou",
        "Yongqiang Chen",
        "Jianxiang Wang",
        "Haochen Yang",
        "Mufei Li",
        "James Cheng",
        "Pan Li",
        "Yu Gong"
      ],
      "abstract": "Active reasoning requires large language models (LLMs) to interact with external sources and strategically gather information to solve problems. Central to this process is belief tracking: maintaining a coherent understanding of the problem state and the missing information toward the solution. However, due to limited reasoning capabilities, LLM-based agents often suffer from belief deviation: they struggle to correctly model beliefs, lose track of problem states, and fall into uninformative or repetitive actions. Once this happens, errors compound and reinforcement learning (RL) training fails to properly credit the crucial exploratory steps. To address this issue, we propose to track the deviation of model beliefs and develop $\\mathbf{T^3}$, a simple yet effective method that detects excessive belief deviation and truncates trajectories during training to remove uninformative tails. By preserving credit for informative prefixes, $\\mathbf{T^3}$ systematically improves policy optimization. Across 5 challenging tasks, $\\mathbf{T^3}$ consistently enhances training stability, token efficiency, and final performance, achieving up to 30% gains while cutting rollout tokens by roughly 25%. These results highlight belief control as a key principle for developing robust and generalizable LLM-based active reasoners.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§è¯­è¨€æ¨¡å‹(LLMs)åœ¨ä¸»åŠ¨æ¨ç†(Active Reasoning)ä¸­é¢ä¸´çš„ä¿¡å¿µåå·®(Belief Deviation)é—®é¢˜ï¼Œæå‡ºäº†T^3æ–¹æ³•ã€‚ä¿¡å¿µåå·®ä¼šå¯¼è‡´æ™ºèƒ½ä½“éš¾ä»¥å‡†ç¡®è¿½è¸ªé—®é¢˜çŠ¶æ€å¹¶é™·å…¥é‡å¤åŠ¨ä½œï¼Œä½¿å¾—å¼ºåŒ–å­¦ä¹ (Reinforcement Learning)éš¾ä»¥å¯¹æœ‰æ•ˆçš„æ¢ç´¢æ­¥éª¤è¿›è¡Œä¿¡ç”¨åˆ†é…ã€‚T^3é€šè¿‡å®æ—¶æ£€æµ‹ä¿¡å¿µåå·®å¹¶åœ¨è®­ç»ƒä¸­æˆªæ–­æ— ä¿¡æ¯çš„è½¨è¿¹å°¾éƒ¨ï¼Œç¡®ä¿æ¨¡å‹èƒ½å¤Ÿé›†ä¸­å­¦ä¹ å…·æœ‰ä¿¡æ¯é‡çš„å‰ç¼€éƒ¨åˆ†ï¼Œä»è€Œç³»ç»Ÿæ€§åœ°ä¼˜åŒ–ç­–ç•¥ã€‚å®éªŒåœ¨5é¡¹æŒ‘æˆ˜æ€§ä»»åŠ¡ä¸­è¡¨æ˜ï¼ŒT^3ä¸ä»…æå‡äº†è®­ç»ƒç¨³å®šæ€§å’Œæœ€ç»ˆæ€§èƒ½ï¼Œåœ¨æå‡å‡†ç¡®ç‡é«˜è¾¾30%çš„åŒæ—¶å‡å°‘äº†çº¦25%çš„Tokenæ¶ˆè€—ã€‚è¯¥ç ”ç©¶è¯æ˜äº†ä¿¡å¿µæ§åˆ¶æ˜¯æ„å»ºé«˜æ•ˆã€é²æ£’çš„ä¸»åŠ¨æ¨ç†æ™ºèƒ½ä½“çš„æ ¸å¿ƒåŸåˆ™ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.12264v1",
      "published_date": "2025-10-14 08:14:49 UTC",
      "updated_date": "2025-10-14 08:14:49 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:26:45.994524+00:00"
    },
    {
      "arxiv_id": "2510.12255v1",
      "title": "Shallow Robustness, Deep Vulnerabilities: Multi-Turn Evaluation of Medical LLMs",
      "title_zh": "æµ…å±‚é²æ£’ä¸æ·±å±‚è„†å¼±ï¼šåŒ»ç–—å¤§è¯­è¨€æ¨¡å‹çš„å¤šè½®è¯„ä¼°",
      "authors": [
        "Blazej Manczak",
        "Eric Lin",
        "Francisco Eiras",
        "James O' Neill",
        "Vaikkunth Mugunthan"
      ],
      "abstract": "Large language models (LLMs) are rapidly transitioning into medical clinical use, yet their reliability under realistic, multi-turn interactions remains poorly understood. Existing evaluation frameworks typically assess single-turn question answering under idealized conditions, overlooking the complexities of medical consultations where conflicting input, misleading context, and authority influence are common. We introduce MedQA-Followup, a framework for systematically evaluating multi-turn robustness in medical question answering. Our approach distinguishes between shallow robustness (resisting misleading initial context) and deep robustness (maintaining accuracy when answers are challenged across turns), while also introducing an indirect-direct axis that separates contextual framing (indirect) from explicit suggestion (direct). Using controlled interventions on the MedQA dataset, we evaluate five state-of-the-art LLMs and find that while models perform reasonably well under shallow perturbations, they exhibit severe vulnerabilities in multi-turn settings, with accuracy dropping from 91.2% to as low as 13.5% for Claude Sonnet 4. Counterintuitively, indirect, context-based interventions are often more harmful than direct suggestions, yielding larger accuracy drops across models and exposing a significant vulnerability for clinical deployment. Further compounding analyses reveal model differences, with some showing additional performance drops under repeated interventions while others partially recovering or even improving. These findings highlight multi-turn robustness as a critical but underexplored dimension for safe and reliable deployment of medical LLMs.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹åŒ»ç–—å¤§è¯­è¨€æ¨¡å‹ (LLMs) åœ¨çœŸå®çš„å¤šè½®äº¤äº’ (multi-turn interactions) åœºæ™¯ä¸‹å¯é æ€§ä¸æ˜çš„é—®é¢˜ï¼ŒæŒ‡å‡ºäº†ç°æœ‰è¯„ä¼°æ¡†æ¶å¤šå±€é™äºå•è½®é—®ç­”çš„å±€é™æ€§ã€‚ä¸ºæ­¤ï¼Œä½œè€…æå‡ºäº† MedQA-Followup æ¡†æ¶ï¼Œç”¨äºç³»ç»Ÿæ€§è¯„ä¼°åŒ»ç–—é—®ç­”ä¸­çš„å¤šè½®é²æ£’æ€§ (multi-turn robustness)ã€‚è¯¥æ¡†æ¶åŒºåˆ†äº†åº”å¯¹è¯¯å¯¼æ€§åˆå§‹ä¸Šä¸‹æ–‡çš„æµ…å±‚é²æ£’æ€§ (shallow robustness) ä¸åœ¨å¤šè½®æŒ‘æˆ˜ä¸‹ç»´æŒå‡†ç¡®æ€§çš„æ·±å±‚é²æ£’æ€§ (deep robustness)ï¼Œå¹¶å¼•å…¥äº†åŒºåˆ†é—´æ¥ä¸Šä¸‹æ–‡å¼•å¯¼ä¸ç›´æ¥å»ºè®®çš„è¯„ä¼°ç»´åº¦ã€‚ç ”ç©¶è€…åœ¨ MedQA æ•°æ®é›†ä¸Šå¯¹äº”ç§æœ€å…ˆè¿›çš„ LLMs è¿›è¡Œäº†å‹åŠ›æµ‹è¯•ï¼Œç»“æœæ˜¾ç¤ºæ¨¡å‹åœ¨å¤„ç†å¤šè½®äº¤äº’æŒ‘æˆ˜æ—¶è¡¨ç°å‡ºä¸¥é‡çš„è„†å¼±æ€§ï¼Œä¾‹å¦‚ Claude Sonnet 4 çš„å‡†ç¡®ç‡ä» 91.2% éª¤é™è‡³ 13.5%ã€‚å®éªŒå‘ç°é—´æ¥çš„ä¸Šä¸‹æ–‡å¹²é¢„å¾€å¾€æ¯”ç›´æ¥çš„å»ºè®®æ›´å…·ç ´åæ€§ï¼Œæ­ç¤ºäº†ä¸´åºŠåº”ç”¨ä¸­æ˜¾è‘—çš„å®‰å…¨éšæ‚£ã€‚è¯¥ç ”ç©¶å¼ºè°ƒäº†å¤šè½®é²æ£’æ€§æ˜¯å®ç°å®‰å…¨å¯é åŒ»ç–— LLMs éƒ¨ç½²ä¸­ä¸€ä¸ªå…³é”®ä½†å°šæœªè¢«å……åˆ†æ¢ç´¢çš„ç»´åº¦ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Dataset and code: https://huggingface.co/datasets/dynamoai-ml/MedQA-USMLE-4-MultiTurnRobust ; https://github.com/bmanczak/MedQA-MultiTurnRobustness Accepted as a poster at NeurIPS 2025 Workshop on GenAI for Health: Potential, Trust, and Policy Compliance",
      "pdf_url": "https://arxiv.org/pdf/2510.12255v1",
      "published_date": "2025-10-14 08:04:18 UTC",
      "updated_date": "2025-10-14 08:04:18 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:26:48.367494+00:00"
    },
    {
      "arxiv_id": "2510.12253v1",
      "title": "Diffusion Models for Reinforcement Learning: Foundations, Taxonomy, and Development",
      "title_zh": "å¼ºåŒ–å­¦ä¹ ä¸­çš„æ‰©æ•£æ¨¡å‹ï¼šåŸºç¡€ã€åˆ†ç±»ä½“ç³»ä¸å‘å±•",
      "authors": [
        "Changfu Xu",
        "Jianxiong Guo",
        "Yuzhu Liang",
        "Haiyang Huang",
        "Haodong Zou",
        "Xi Zheng",
        "Shui Yu",
        "Xiaowen Chu",
        "Jiannong Cao",
        "Tian Wang"
      ],
      "abstract": "Diffusion Models (DMs), as a leading class of generative models, offer key advantages for reinforcement learning (RL), including multi-modal expressiveness, stable training, and trajectory-level planning. This survey delivers a comprehensive and up-to-date synthesis of diffusion-based RL. We first provide an overview of RL, highlighting its challenges, and then introduce the fundamental concepts of DMs, investigating how they are integrated into RL frameworks to address key challenges in this research field. We establish a dual-axis taxonomy that organizes the field along two orthogonal dimensions: a function-oriented taxonomy that clarifies the roles DMs play within the RL pipeline, and a technique-oriented taxonomy that situates implementations across online versus offline learning regimes. We also provide a comprehensive examination of this progression from single-agent to multi-agent domains, thereby forming several frameworks for DM-RL integration and highlighting their practical utility. Furthermore, we outline several categories of successful applications of diffusion-based RL across diverse domains, discuss open research issues of current methodologies, and highlight key directions for future research to advance the field. Finally, we summarize the survey to identify promising future development directions. We are actively maintaining a GitHub repository (https://github.com/ChangfuXu/D4RL-FTD) for papers and other related resources to apply DMs for RL.",
      "tldr_zh": "è¯¥ç»¼è¿°å…¨é¢ç³»ç»Ÿåœ°æ€»ç»“äº†æ‰©æ•£æ¨¡å‹(Diffusion Models)åœ¨å¼ºåŒ–å­¦ä¹ (Reinforcement Learning)é¢†åŸŸçš„æœ€æ–°è¿›å±•ã€åŸºç¡€ç†è®ºä¸åˆ†ç±»ä½“ç³»ã€‚ç ”ç©¶é¦–å…ˆé˜è¿°äº†æ‰©æ•£æ¨¡å‹åœ¨å¤šæ¨¡æ€è¡¨è¾¾èƒ½åŠ›ã€è®­ç»ƒç¨³å®šæ€§å’Œè½¨è¿¹çº§è§„åˆ’(trajectory-level planning)ç­‰æ–¹é¢çš„æ ¸å¿ƒä¼˜åŠ¿ï¼Œä»¥åŠå®ƒä»¬å¦‚ä½•æœ‰æ•ˆè§£å†³å¼ºåŒ–å­¦ä¹ ä¸­çš„å…³é”®æŒ‘æˆ˜ã€‚æ–‡ç« å»ºç«‹äº†ä¸€å¥—åŒè½´åˆ†ç±»æ³•ï¼Œåˆ†åˆ«ä»åŠŸèƒ½å¯¼å‘(function-oriented)å’ŒæŠ€æœ¯å¯¼å‘(technique-oriented)ä¸¤ä¸ªç»´åº¦å¯¹ç°æœ‰ç ”ç©¶è¿›è¡Œäº†ç³»ç»Ÿæ¢³ç†ã€‚æ­¤å¤–ï¼Œæœ¬æ–‡æ·±å…¥æ¢è®¨äº†è¯¥é¢†åŸŸä»å•æ™ºèƒ½ä½“å‘å¤šæ™ºèƒ½ä½“ç³»ç»Ÿçš„æ¼”è¿›è¿‡ç¨‹ï¼Œå¹¶å±•ç¤ºäº†æ‰©æ•£å¼ºåŒ–å­¦ä¹ åœ¨å¤šä¸ªå®é™…é¢†åŸŸçš„æˆåŠŸåº”ç”¨æ¡ˆä¾‹ã€‚æœ€åï¼Œä½œè€…åˆ†æäº†å½“å‰çš„å¼€æ”¾æ€§ç ”ç©¶é—®é¢˜å¹¶æŒ‡æ˜äº†æœªæ¥çš„å‘å±•æ–¹å‘ï¼Œä¸ºæ¨åŠ¨è¯¥é¢†åŸŸçš„è·¨å­¦ç§‘ç ”ç©¶æä¾›äº†é‡è¦å‚è€ƒã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Under Review",
      "pdf_url": "https://arxiv.org/pdf/2510.12253v1",
      "published_date": "2025-10-14 08:03:46 UTC",
      "updated_date": "2025-10-14 08:03:46 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:27:00.189569+00:00"
    },
    {
      "arxiv_id": "2510.12252v2",
      "title": "PromptLocate: Localizing Prompt Injection Attacks",
      "title_zh": "PromptLocateï¼šæç¤ºè¯æ³¨å…¥æ”»å‡»å®šä½",
      "authors": [
        "Yuqi Jia",
        "Yupei Liu",
        "Zedian Shao",
        "Jinyuan Jia",
        "Neil Gong"
      ],
      "abstract": "Prompt injection attacks deceive a large language model into completing an attacker-specified task instead of its intended task by contaminating its input data with an injected prompt, which consists of injected instruction(s) and data. Localizing the injected prompt within contaminated data is crucial for post-attack forensic analysis and data recovery. Despite its growing importance, prompt injection localization remains largely unexplored. In this work, we bridge this gap by proposing PromptLocate, the first method for localizing injected prompts. PromptLocate comprises three steps: (1) splitting the contaminated data into semantically coherent segments, (2) identifying segments contaminated by injected instructions, and (3) pinpointing segments contaminated by injected data. We show PromptLocate accurately localizes injected prompts across eight existing and eight adaptive attacks.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†æç¤ºæ³¨å…¥æ”»å‡» (Prompt Injection Attacks) å¯¹å¤§è¯­è¨€æ¨¡å‹ (LLM) çš„å¨èƒï¼ŒæŒ‡å‡ºåœ¨å—æ±¡æŸ“æ•°æ®ä¸­å‡†ç¡®å®šä½è¢«æ³¨å…¥çš„æç¤ºå¯¹äºæ”»å‡»åçš„å–è¯åˆ†æå’Œæ•°æ®æ¢å¤è‡³å…³é‡è¦ã€‚é’ˆå¯¹è¯¥é¢†åŸŸç ”ç©¶çš„ç©ºç™½ï¼Œè®ºæ–‡æå‡ºäº† PromptLocateï¼Œè¿™æ˜¯é¦–ä¸ªä¸“é—¨ç”¨äºå®šä½æ³¨å…¥æç¤ºçš„æ–¹æ³•ã€‚è¯¥æ–¹æ³•ä¸»è¦ç”±ä¸‰ä¸ªæ ¸å¿ƒæ­¥éª¤ç»„æˆï¼Œé¦–å…ˆå°†å—æ±¡æŸ“æ•°æ®åˆ’åˆ†ä¸ºè¯­ä¹‰è¿è´¯çš„ç‰‡æ®µï¼Œæ¥ç€è¯†åˆ«è¢«æ³¨å…¥æŒ‡ä»¤ (Injected Instructions) æ±¡æŸ“çš„ç‰‡æ®µï¼Œæœ€åç²¾å‡†å®šä½å—æ³¨å…¥æ•°æ® (Injected Data) å½±å“çš„éƒ¨åˆ†ã€‚å®éªŒè¯„ä¼°ç»“æœè¡¨æ˜ï¼ŒPromptLocate èƒ½å¤Ÿæœ‰æ•ˆä¸”å‡†ç¡®åœ°åœ¨å…«ç§ç°æœ‰æ”»å‡»å’Œå…«ç§è‡ªé€‚åº”æ”»å‡» (Adaptive Attacks) åœºæ™¯ä¸‹å®ç°å®šä½ã€‚è¯¥ç ”ç©¶ä¸ºæå‡å¤§è¯­è¨€æ¨¡å‹çš„å®‰å…¨æ€§ä»¥åŠè‡ªåŠ¨åŒ–å®‰å…¨å®¡è®¡æä¾›äº†é‡è¦çš„æŠ€æœ¯æ”¯æ’‘ã€‚",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "To appear in IEEE Symposium on Security and Privacy, 2026. For slides, see https://people.duke.edu/~zg70/code/PromptInjection.pdf",
      "pdf_url": "https://arxiv.org/pdf/2510.12252v2",
      "published_date": "2025-10-14 08:02:11 UTC",
      "updated_date": "2025-10-17 02:10:07 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:27:01.587207+00:00"
    },
    {
      "arxiv_id": "2510.12246v1",
      "title": "PromptFlow: Training Prompts Like Neural Networks",
      "title_zh": "PromptFlowï¼šç±»ç¥ç»ç½‘ç»œæç¤ºè¯è®­ç»ƒ",
      "authors": [
        "Jingyi Wang",
        "Hongyuan Zhu",
        "Ye Niu",
        "Yunhui Deng"
      ],
      "abstract": "Large Language Models (LLMs) have demonstrated profound impact on Natural Language Processing (NLP) tasks. However, their effective deployment across diverse domains often require domain-specific adaptation strategies, as generic models may underperform when faced with specialized data distributions. Recent advances in prompt engineering (PE) offer a promising alternative to extensive retraining by refining input instructions to align LLM outputs with task objectives. This paradigm has emerged as a rapid and versatile approach for model fine-tuning. Despite its potential, manual prompt design remains labor-intensive and heavily depends on specialized expertise, often requiring iterative human effort to achieve optimal formulations. To address this limitation, automated prompt engineering methodologies have been developed to systematically generate task-specific prompts. However, current implementations predominantly employ static update rules and lack mechanisms for dynamic strategy selection, resulting in suboptimal adaptation to varying NLP task requirements. Furthermore, most methods treat and update the whole prompts at each step, without considering editing prompt sections at a finer granularity. At last, in particular, the problem of how to recycle experience in LLM is still underexplored. To this end, we propose the PromptFlow, a modular training framework inspired by TensorFlow, which integrates meta-prompts, operators, optimization, and evaluator. Our framework can be equipped with the latest optimization methods and autonomously explores optimal prompt refinement trajectories through gradient-based meta-learning, requiring minimal task-specific training data. Specifically, we devise a reinforcement learning method to recycle experience for LLM in the PE process. Finally, we conduct extensive experiments on various datasets, and demonstrate the effectiveness of PromptFlow.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† PromptFlowï¼Œè¿™æ˜¯ä¸€ä¸ªå— TensorFlow å¯å‘çš„æ¨¡å—åŒ–è®­ç»ƒæ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹ (LLMs) åœ¨ç‰¹å®šé¢†åŸŸåº”ç”¨æ—¶æ‰‹åŠ¨æç¤ºå·¥ç¨‹ (prompt engineering) è€—æ—¶è€—åŠ›ä¸”ç°æœ‰è‡ªåŠ¨åŒ–æ–¹æ³•ç¼ºä¹åŠ¨æ€ä¼˜åŒ–æœºåˆ¶çš„é—®é¢˜ã€‚è¯¥æ¡†æ¶é€šè¿‡æ•´åˆ meta-promptsã€ç®—å­ (operators)ã€ä¼˜åŒ–å™¨ (optimization) å’Œè¯„ä¼°å™¨ (evaluator)ï¼Œåˆ©ç”¨åŸºäºæ¢¯åº¦çš„å…ƒå­¦ä¹  (gradient-based meta-learning) è‡ªä¸»æ¢ç´¢æœ€ä¼˜æç¤ºè¯ä¼˜åŒ–è½¨è¿¹ã€‚ç ”ç©¶è€…ç‰¹åˆ«è®¾è®¡äº†ä¸€ç§å¼ºåŒ–å­¦ä¹  (reinforcement learning) æ–¹æ³•æ¥å›æ”¶æç¤ºè¯å·¥ç¨‹è¿‡ç¨‹ä¸­çš„ç»éªŒï¼Œå®ç°äº†å¯¹æç¤ºè¯ç‰‡æ®µæ›´ç»†ç²’åº¦çš„ç¼–è¾‘ä¸åŠ¨æ€ç­–ç•¥é€‰æ‹©ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒPromptFlow åœ¨å¤šç§æ•°æ®é›†ä¸Šå‡éªŒè¯äº†å…¶æœ‰æ•ˆæ€§ï¼Œä¸”ä»…éœ€æå°‘é‡çš„ç‰¹å®šä»»åŠ¡è®­ç»ƒæ•°æ®å³å¯å®ç°é«˜è´¨é‡çš„æç¤ºè¯è‡ªåŠ¨åŒ–ç²¾ç‚¼ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Comments: 18 pages, 14 figures, conference submission, appendix included",
      "pdf_url": "https://arxiv.org/pdf/2510.12246v1",
      "published_date": "2025-10-14 07:56:12 UTC",
      "updated_date": "2025-10-14 07:56:12 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:27:10.198247+00:00"
    },
    {
      "arxiv_id": "2510.12245v1",
      "title": "MoRA: On-the-fly Molecule-aware Low-Rank Adaptation Framework for LLM-based Multi-Modal Molecular Assistant",
      "title_zh": "MoRAï¼šé¢å‘åŸºäºå¤§è¯­è¨€æ¨¡å‹çš„å¤šæ¨¡æ€åˆ†å­åŠ©æ‰‹çš„å³æ—¶åˆ†å­æ„ŸçŸ¥ä½ç§©è‡ªé€‚åº”æ¡†æ¶",
      "authors": [
        "Tao Yin",
        "Xiaohong Zhang",
        "Jiacheng Zhang",
        "Li Huang",
        "Zhibin Zhang",
        "Yuansong Zeng",
        "Jin Xie",
        "Meng Yan"
      ],
      "abstract": "Effectively integrating molecular graph structures with Large Language Models (LLMs) is a key challenge in drug discovery. Most existing multi-modal alignment methods typically process these structures by fine-tuning the LLM or adding a static adapter simultaneously. However, these approaches have two main limitations: (1) it optimizes a shared parameter space across all molecular inputs, limiting the model's ability to capture instance-specific structural features; and (2) fine-tuning the LLM for molecular tasks can lead to catastrophic forgetting, undermining its general reasoning capabilities. In this paper, instead of static task-oriented adaptation, we propose an instance-specific parameter space alignment approach for each molecule on-the-fly. To this end, we introduce Molecule-aware Low-Rank Adaptation (MoRA) that produces a unique set of low-rank adaptation weights for each input molecular graph. These weights are then dynamically injected into a frozen LLM, allowing the model to adapt its reasoning to the structure of each molecular input, while preserving the LLM's core knowledge. Extensive experiments demonstrate that on key molecular tasks, such as chemical reaction prediction and molecular captioning, MoRA's instance-specific dynamic adaptation outperforms statically adapted baselines, including a 14.1% relative improvement in reaction prediction exact match and a 22% reduction in error for quantum property prediction. The code is available at https://github.com/jk-sounds/MoRA.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† MoRAï¼Œä¸€ä¸ªé’ˆå¯¹åŸºäºå¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„å¤šæ¨¡æ€åˆ†å­åŠ©æ‰‹è®¾è®¡çš„å³æ—¶åˆ†å­æ„ŸçŸ¥ä½ç§©é€‚é…ï¼ˆLow-Rank Adaptationï¼‰æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³åˆ†å­å›¾ç»“æ„ä¸ LLM é›†æˆè¿‡ç¨‹ä¸­çš„å‚æ•°ç©ºé—´å…±äº«é™åˆ¶å’Œç¾éš¾æ€§é—å¿˜ï¼ˆCatastrophic Forgettingï¼‰é—®é¢˜ã€‚ä¸åŒäºä¼ ç»Ÿçš„é™æ€ä»»åŠ¡å¯¼å‘é€‚é…ï¼ŒMoRA é‡‡ç”¨äº†ä¸€ç§é’ˆå¯¹æ¯ä¸ªåˆ†å­çš„å®ä¾‹ç‰¹å®šï¼ˆInstance-specificï¼‰å‚æ•°ç©ºé—´å¯¹é½æ–¹æ³•ã€‚è¯¥æ¡†æ¶é€šè¿‡ä¸ºæ¯ä¸ªè¾“å…¥çš„åˆ†å­å›¾ç”Ÿæˆä¸€ç»„å”¯ä¸€çš„ä½ç§©é€‚é…æƒé‡ï¼Œå¹¶å°†å…¶åŠ¨æ€æ³¨å…¥åˆ°å†»ç»“çš„ LLM ä¸­ï¼Œä½¿æ¨¡å‹èƒ½å¤Ÿåœ¨ä¿ç•™æ ¸å¿ƒé€šç”¨çŸ¥è¯†çš„åŒæ—¶ï¼Œæ ¹æ®å…·ä½“åˆ†å­çš„ç»“æ„è°ƒæ•´æ¨ç†è¿‡ç¨‹ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒMoRA åœ¨åŒ–å­¦ååº”é¢„æµ‹å’Œåˆ†å­æè¿°ç­‰å…³é”®ä»»åŠ¡ä¸Šè¡¨ç°ä¼˜äºé™æ€é€‚é…åŸºå‡†æ¨¡å‹ã€‚å…·ä½“è€Œè¨€ï¼Œè¯¥æ–¹æ³•åœ¨ååº”é¢„æµ‹çš„ç²¾ç¡®åŒ¹é…ï¼ˆExact Matchï¼‰ä¸Šå®ç°äº† 14.1% çš„ç›¸å¯¹æå‡ï¼Œå¹¶åœ¨é‡å­æ€§è´¨é¢„æµ‹ä»»åŠ¡ä¸­å‡å°‘äº† 22% çš„è¯¯å·®ï¼Œä¸ºå¼€å‘å…·å¤‡é«˜åº¦ç»“æ„æ„ŸçŸ¥èƒ½åŠ›çš„å¤šæ¨¡æ€åˆ†å­ç§‘å­¦è¾…åŠ©å·¥å…·æä¾›äº†æ–°çš„æŠ€æœ¯è·¯å¾„ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.12245v1",
      "published_date": "2025-10-14 07:54:43 UTC",
      "updated_date": "2025-10-14 07:54:43 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:27:10.479968+00:00"
    },
    {
      "arxiv_id": "2510.15994v1",
      "title": "MCP Security Bench (MSB): Benchmarking Attacks Against Model Context Protocol in LLM Agents",
      "title_zh": "MCP Security Bench (MSB)ï¼šé’ˆå¯¹å¤§è¯­è¨€æ¨¡å‹æ™ºèƒ½ä½“ä¸­æ¨¡å‹ä¸Šä¸‹æ–‡åè®®æ”»å‡»çš„åŸºå‡†æµ‹è¯•",
      "authors": [
        "Dongsen Zhang",
        "Zekun Li",
        "Xu Luo",
        "Xuannan Liu",
        "Peipei Li",
        "Wenjun Xu"
      ],
      "abstract": "The Model Context Protocol (MCP) standardizes how large language model (LLM) agents discover, describe, and call external tools. While MCP unlocks broad interoperability, it also enlarges the attack surface by making tools first-class, composable objects with natural-language metadata, and standardized I/O. We present MSB (MCP Security Benchmark), the first end-to-end evaluation suite that systematically measures how well LLM agents resist MCP-specific attacks throughout the full tool-use pipeline: task planning, tool invocation, and response handling. MSB contributes: (1) a taxonomy of 12 attacks including name-collision, preference manipulation, prompt injections embedded in tool descriptions, out-of-scope parameter requests, user-impersonating responses, false-error escalation, tool-transfer, retrieval injection, and mixed attacks; (2) an evaluation harness that executes attacks by running real tools (both benign and malicious) via MCP rather than simulation; and (3) a robustness metric that quantifies the trade-off between security and performance: Net Resilient Performance (NRP). We evaluate nine popular LLM agents across 10 domains and 400+ tools, producing 2,000 attack instances. Results reveal the effectiveness of attacks against each stage of MCP. Models with stronger performance are more vulnerable to attacks due to their outstanding tool calling and instruction following capabilities. MSB provides a practical baseline for researchers and practitioners to study, compare, and harden MCP agents.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† MCP Security Bench (MSB)ï¼Œè¿™æ˜¯é¦–ä¸ªæ—¨åœ¨ç³»ç»Ÿè¯„ä¼°å¤§è¯­è¨€æ¨¡å‹ (LLM) æ™ºèƒ½ä½“åœ¨ Model Context Protocol (MCP) ç¯å¢ƒä¸‹æŠµå¾¡æ”»å‡»èƒ½åŠ›çš„ç«¯åˆ°ç«¯æµ‹è¯•å¥—ä»¶ã€‚éšç€ MCP æ ‡å‡†åŒ–äº†å·¥å…·çš„å‘ç°å’Œè°ƒç”¨è¿‡ç¨‹ï¼Œå…¶é€šè¿‡è‡ªç„¶è¯­è¨€å…ƒæ•°æ®å’Œæ ‡å‡†åŒ– I/O å¸¦æ¥çš„äº’æ“ä½œæ€§ä¹Ÿæ˜¾è‘—æ‰©å¤§äº†ç³»ç»Ÿçš„æ”»å‡»é¢ã€‚MSB è´¡çŒ®äº†ä¸€é¡¹åŒ…å« 12 ç§æ”»å‡»æ–¹å¼çš„åˆ†ç±»æ³•ï¼Œæ¶µç›–äº†åç§°å†²çª (name-collision)ã€åå¥½æ“çºµ (preference manipulation) ä»¥åŠåµŒå…¥å·¥å…·æè¿°çš„æç¤ºæ³¨å…¥ (prompt injections) ç­‰æ”»å‡»æ‰‹æ®µã€‚è¯¥æ¡†æ¶æä¾›äº†ä¸€å¥—è¿è¡ŒçœŸå®å·¥å…·ï¼ˆåŒ…æ‹¬è‰¯æ€§å’Œæ¶æ„å·¥å…·ï¼‰çš„è¯„ä¼°å¥—ä»¶ï¼Œå¹¶å¼•å…¥äº†å‡€å¼¹æ€§æ€§èƒ½ (Net Resilient Performance, NRP) æŒ‡æ ‡æ¥æƒè¡¡å®‰å…¨ä¸æ•ˆç‡ã€‚å®éªŒå¯¹ 9 ç§ä¸»æµ LLM æ™ºèƒ½ä½“è¿›è¡Œäº†å¹¿æ³›æµ‹è¯•ï¼Œå‘ç°æ€§èƒ½è¶Šå¼ºçš„æ¨¡å‹å› å…¶å“è¶Šçš„å·¥å…·è°ƒç”¨å’ŒæŒ‡ä»¤éµå¾ªèƒ½åŠ›ï¼Œåè€Œæ›´å®¹æ˜“å—åˆ°ç‰¹å®šé˜¶æ®µçš„æ”»å‡»ã€‚è¯¥ç ”ç©¶ä¸ºç ”ç©¶äººå‘˜å’Œä»ä¸šè€…æä¾›äº†åŠ å›º MCP æ™ºèƒ½ä½“å’Œç ”ç©¶é˜²å¾¡æœºåˆ¶çš„å®ç”¨åŸºå‡†ã€‚",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.15994v1",
      "published_date": "2025-10-14 07:36:25 UTC",
      "updated_date": "2025-10-14 07:36:25 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:27:21.400034+00:00"
    },
    {
      "arxiv_id": "2510.12229v2",
      "title": "Analysing Moral Bias in Finetuned LLMs through Mechanistic Interpretability",
      "title_zh": "åŸºäºæœºæ¢°å¯è§£é‡Šæ€§åˆ†æå¾®è°ƒ LLM ä¸­çš„é“å¾·åè§",
      "authors": [
        "Bianca Raimondi",
        "Daniela Dalbagno",
        "Maurizio Gabbrielli"
      ],
      "abstract": "Large language models (LLMs) have been shown to internalize human-like biases during finetuning, yet the mechanisms by which these biases manifest remain unclear. In this work, we investigated whether the well-known Knobe effect, a moral bias in intentionality judgements, emerges in finetuned LLMs and whether it can be traced back to specific components of the model. We conducted a Layer-Patching analysis across 3 open-weights LLMs and demonstrated that the bias is not only learned during finetuning but also localized in a specific set of layers. Surprisingly, we found that patching activations from the corresponding pretrained model into just a few critical layers is sufficient to eliminate the effect. Our findings offer new evidence that social biases in LLMs can be interpreted, localized, and mitigated through targeted interventions, without the need for model retraining.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å¤§è¯­è¨€æ¨¡å‹(LLMs)åœ¨å¾®è°ƒè¿‡ç¨‹ä¸­äº§ç”Ÿçš„é“å¾·åè§ï¼Œé‡ç‚¹åˆ†æäº†æ„å›¾åˆ¤æ–­ä¸­çš„ Knobe effect æ˜¯å¦åœ¨æ¨¡å‹ä¸­æ˜¾ç°ã€‚ç ”ç©¶äººå‘˜å¯¹ä¸‰ç§å¼€æºæƒé‡çš„ LLMs è¿›è¡Œäº† Layer-Patching åˆ†æï¼Œè¯æ˜äº†è¿™ç§åè§ä¸ä»…æ˜¯åœ¨å¾®è°ƒé˜¶æ®µä¹ å¾—çš„ï¼Œè€Œä¸”å®šä½åœ¨æ¨¡å‹ç‰¹å®šçš„å±‚çº§ä¸­ã€‚ç ”ç©¶å‘ç°ï¼Œé€šè¿‡å°†å¯¹åº”é¢„è®­ç»ƒæ¨¡å‹çš„æ¿€æ´»å€¼è¡¥ä¸(patching)åˆ°å°‘æ•°å…³é”®å±‚ï¼Œå°±è¶³ä»¥æ¶ˆé™¤è¿™ç§åè§æ•ˆåº”ã€‚è¿™ä¸€ç ”ç©¶ç»“æœä¸ºé€šè¿‡æœºæ¢°å¯è§£é‡Šæ€§(Mechanistic Interpretability)ç†è§£ã€å®šä½å¹¶ç¼“è§£ LLMs ä¸­çš„ç¤¾ä¼šåè§æä¾›äº†æ–°è¯æ®ï¼Œè¯æ˜äº†å¯ä»¥é€šè¿‡é’ˆå¯¹æ€§å¹²é¢„è€Œéé‡æ–°è®­ç»ƒæ¥ä¼˜åŒ–æ¨¡å‹è¡¨ç°ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Preprint. Under review",
      "pdf_url": "https://arxiv.org/pdf/2510.12229v2",
      "published_date": "2025-10-14 07:31:29 UTC",
      "updated_date": "2025-12-05 18:32:06 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:27:20.879737+00:00"
    },
    {
      "arxiv_id": "2510.12224v1",
      "title": "MedKGEval: A Knowledge Graph-Based Multi-Turn Evaluation Framework for Open-Ended Patient Interactions with Clinical LLMs",
      "title_zh": "MedKGEvalï¼šé¢å‘ä¸´åºŠå¤§è¯­è¨€æ¨¡å‹å¼€æ”¾å¼æ‚£è€…äº¤äº’çš„åŸºäºçŸ¥è¯†å›¾è°±çš„å¤šè½®è¯„ä¼°æ¡†æ¶",
      "authors": [
        "Yuechun Yu",
        "Han Ying",
        "Haoan Jin",
        "Wenjian Jiang",
        "Dong Xian",
        "Binghao Wang",
        "Zhou Yang",
        "Mengyue Wu"
      ],
      "abstract": "The reliable evaluation of large language models (LLMs) in medical applications remains an open challenge, particularly in capturing the complexity of multi-turn doctor-patient interactions that unfold in real clinical environments. Existing evaluation methods typically rely on post hoc review of full conversation transcripts, thereby neglecting the dynamic, context-sensitive nature of medical dialogues and the evolving informational needs of patients. In this work, we present MedKGEval, a novel multi-turn evaluation framework for clinical LLMs grounded in structured medical knowledge. Our approach introduces three key contributions: (1) a knowledge graph-driven patient simulation mechanism, where a dedicated control module retrieves relevant medical facts from a curated knowledge graph, thereby endowing the patient agent with human-like and realistic conversational behavior. This knowledge graph is constructed by integrating open-source resources with additional triples extracted from expert-annotated datasets; (2) an in-situ, turn-level evaluation framework, where each model response is assessed by a Judge Agent for clinical appropriateness, factual correctness, and safety as the dialogue progresses using a suite of fine-grained, task-specific metrics; (3) a comprehensive multi-turn benchmark of eight state-of-the-art LLMs, demonstrating MedKGEval's ability to identify subtle behavioral flaws and safety risks that are often overlooked by conventional evaluation pipelines. Although initially designed for Chinese and English medical applications, our framework can be readily extended to additional languages by switching the input knowledge graphs, ensuring seamless bilingual support and domain-specific applicability.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† MedKGEvalï¼Œä¸€ä¸ªåŸºäºçŸ¥è¯†å›¾è°± (Knowledge Graph) çš„å¤šè½®å¯¹è¯è¯„ä¼°æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³ä¸´åºŠå¤§è¯­è¨€æ¨¡å‹ (LLMs) åœ¨å¼€æ”¾å¼åŒ»æ‚£äº¤äº’ä¸­éš¾ä»¥å‡†ç¡®è¯„ä¼°å…¶åŠ¨æ€æ€§å’Œä¸Šä¸‹æ–‡æ•æ„Ÿæ€§çš„æŒ‘æˆ˜ã€‚è¯¥æ¡†æ¶å¼•å…¥äº†ç”±çŸ¥è¯†å›¾è°±é©±åŠ¨çš„æ‚£è€…æ¨¡æ‹Ÿæœºåˆ¶ï¼Œé€šè¿‡æ§åˆ¶æ¨¡å—ä»åŒ»å­¦å›¾è°±ä¸­æ£€ç´¢äº‹å®ï¼Œä½¿æ‚£è€…æ™ºèƒ½ä½“èƒ½å¤Ÿå±•ç°å‡ºç±»äººä¸”çœŸå®çš„å¯¹è¯è¡Œä¸ºã€‚MedKGEval é‡‡ç”¨äº†ä¸€ç§åŸä½çš„ã€è½®æ¬¡çº§åˆ«çš„è¯„ä¼°æ¨¡å¼ï¼Œåˆ©ç”¨ Judge Agent åœ¨å¯¹è¯æ¨è¿›è¿‡ç¨‹ä¸­ï¼Œä¾æ®ä¸´åºŠé€‚ç”¨æ€§ã€äº‹å®æ­£ç¡®æ€§å’Œå®‰å…¨æ€§ç­‰ç»†ç²’åº¦æŒ‡æ ‡å¯¹æ¨¡å‹å“åº”è¿›è¡Œå®æ—¶è¯„åˆ†ã€‚åœ¨å¯¹ 8 ç§ä¸»æµå¤§è¯­è¨€æ¨¡å‹è¿›è¡Œçš„åŸºå‡†æµ‹è¯•ä¸­ï¼Œè¯¥æ¡†æ¶æˆåŠŸè¯†åˆ«å‡ºäº†ä¼ ç»Ÿé™æ€è¯„ä¼°æ–¹æ³•å®¹æ˜“å¿½ç•¥çš„ç»†å¾®è¡Œä¸ºç¼ºé™·ä¸å®‰å…¨é£é™©ã€‚è¯¥ç³»ç»Ÿç›®å‰æ”¯æŒä¸­è‹±åŒè¯­ï¼Œå¹¶å…·å¤‡è‰¯å¥½çš„å¯æ‰©å±•æ€§ï¼Œé€šè¿‡æ›´æ¢åº•å±‚çŸ¥è¯†å›¾è°±å³å¯é€‚é…å…¶ä»–è¯­è¨€æˆ–ç‰¹å®šåŒ»å­¦é¢†åŸŸï¼Œä¸ºæ„å»ºé«˜è´¨é‡çš„åŒ»ç–—æ™ºèƒ½å¯¹è¯ç³»ç»Ÿæä¾›äº†é‡è¦çš„è¯„ä¼°ä¿éšœã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.12224v1",
      "published_date": "2025-10-14 07:22:26 UTC",
      "updated_date": "2025-10-14 07:22:26 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:27:22.715096+00:00"
    },
    {
      "arxiv_id": "2510.12218v1",
      "title": "GOAT: A Training Framework for Goal-Oriented Agent with Tools",
      "title_zh": "GOATï¼šæ”¯æŒå·¥å…·ä½¿ç”¨çš„ç›®æ ‡å¯¼å‘å‹æ™ºèƒ½ä½“è®­ç»ƒæ¡†æ¶",
      "authors": [
        "Hyunji Min",
        "Sangwon Jung",
        "Junyoung Sung",
        "Dosung Lee",
        "Leekyeung Han",
        "Paul Hongsuck Seo"
      ],
      "abstract": "Large language models (LLMs) have recently been extended beyond traditional text generation to serve as interactive agents capable of using external tools based on user intent. However, current LLM agents still show limited ability to handle goal-oriented queries, which require decomposing a high-level objective into multiple interdependent API calls with correct planning and execution. Current approaches mainly rely on zero-shot evaluation due to the absence of training data. While proprietary closed-source models such as GPT-4 demonstrate strong reasoning abilities, smaller open-source models struggle to perform complex tool use effectively. Thus, we propose a novel training framework GOAT, which enables fine-tuning of LLM agents in a human annotation-free setting. GOAT automatically constructs synthetic datasets of goal-oriented API execution tasks directly from given API documents, equipping models with the ability to reason over interdependent calls and generate coherent responses. Through extensive experiments, we show that GOAT-trained agents achieve state-of-the-art performance across multiple existing goal-oriented benchmarks. In addition, we introduce GOATBench, a new goal-oriented API execution benchmark, and demonstrate that agents trained with GOAT also excel in this setting. These results highlight GOAT as a practical path toward building robust open-source LLM agents capable of complex reasoning and tool use.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§è¯­è¨€æ¨¡å‹ (LLMs) åœ¨å¤„ç†é¢å‘ç›®æ ‡ (goal-oriented) çš„å¤æ‚æŸ¥è¯¢æ—¶å­˜åœ¨çš„è§„åˆ’ä¸æ‰§è¡Œèƒ½åŠ›ä¸è¶³é—®é¢˜æå‡ºäº†è§£å†³æ–¹æ¡ˆã€‚ä¼ ç»Ÿçš„ LLM æ™ºèƒ½ä½“åœ¨å°†é«˜çº§ç›®æ ‡åˆ†è§£ä¸ºå¤šä¸ªç›¸äº’ä¾èµ–çš„ API è°ƒç”¨æ—¶è¡¨ç°æœ‰é™ï¼Œä¸”ç›®å‰å¼€æºæ¨¡å‹åœ¨å¤æ‚å·¥å…·ä½¿ç”¨æ–¹é¢ä»æ˜¾è‘—è½åäºé—­æºæ¨¡å‹ã€‚ä¸ºæ­¤ï¼Œç ”ç©¶è€…æå‡ºäº† GOAT è®­ç»ƒæ¡†æ¶ï¼Œè¿™æ˜¯ä¸€ç§æ— éœ€äººå·¥æ ‡æ³¨çš„å¾®è°ƒæ–¹æ¡ˆï¼Œèƒ½å¤Ÿç›´æ¥æ ¹æ®ç»™å®šçš„ API æ–‡æ¡£è‡ªåŠ¨æ„å»ºåˆæˆæ•°æ®é›†ã€‚è¯¥æ¡†æ¶æœ‰æ•ˆæå‡äº†æ¨¡å‹å¯¹ç›¸äº’ä¾èµ–çš„è°ƒç”¨è¿›è¡Œæ¨ç†çš„èƒ½åŠ›ï¼Œä½¿å…¶èƒ½å¤Ÿç”Ÿæˆé€»è¾‘è¿è´¯çš„å“åº”ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œç» GOAT è®­ç»ƒçš„æ™ºèƒ½ä½“åœ¨å¤šä¸ªç°æœ‰çš„é¢å‘ç›®æ ‡åŸºå‡†æµ‹è¯•ä¸­å‡è¾¾åˆ°äº† SOTA æ€§èƒ½ã€‚æ­¤å¤–ï¼Œç ”ç©¶è¿˜å¼•å…¥äº†å…¨æ–°çš„åŸºå‡†æµ‹è¯• GOATBenchï¼Œè¯æ˜äº† GOAT æ˜¯æ„å»ºå…·å¤‡å¤æ‚æ¨ç†èƒ½åŠ›çš„ç¨³å¥å¼€æº LLM æ™ºèƒ½ä½“çš„æœ‰æ•ˆè·¯å¾„ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "32 pages, 21 figures",
      "pdf_url": "https://arxiv.org/pdf/2510.12218v1",
      "published_date": "2025-10-14 07:14:50 UTC",
      "updated_date": "2025-10-14 07:14:50 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:27:23.181383+00:00"
    },
    {
      "arxiv_id": "2510.12217v2",
      "title": "HALF: Harm-Aware LLM Fairness Evaluation Aligned with Deployment",
      "title_zh": "HALFï¼šä¸éƒ¨ç½²å¯¹é½çš„ä¼¤å®³æ„ŸçŸ¥å¤§è¯­è¨€æ¨¡å‹å…¬å¹³æ€§è¯„ä¼°",
      "authors": [
        "Ali Mekky",
        "Omar El Herraoui",
        "Preslav Nakov",
        "Yuxia Wang"
      ],
      "abstract": "Large language models (LLMs) are increasingly deployed across high-impact domains, from clinical decision support and legal analysis to hiring and education, making fairness and bias evaluation before deployment critical. However, existing evaluations lack grounding in real-world scenarios and do not account for differences in harm severity, e.g., a biased decision in surgery should not be weighed the same as a stylistic bias in text summarization. To address this gap, we introduce HALF (Harm-Aware LLM Fairness), a deployment-aligned framework that assesses model bias in realistic applications and weighs the outcomes by harm severity. HALF organizes nine application domains into three tiers (Severe, Moderate, Mild) using a five-stage pipeline. Our evaluation results across eight LLMs show that (1) LLMs are not consistently fair across domains, (2) model size or performance do not guarantee fairness, and (3) reasoning models perform better in medical decision support but worse in education. We conclude that HALF exposes a clear gap between previous benchmarking success and deployment readiness.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†HALF (Harm-Aware LLM Fairness)ï¼Œè¿™æ˜¯ä¸€ä¸ªæ—¨åœ¨è§£å†³ç°æœ‰è¯„ä¼°ç¼ºä¹ç°å®åœºæ™¯å…³è”ä¸”æœªè€ƒè™‘æŸå®³ä¸¥é‡ç¨‹åº¦(harm severity)å·®å¼‚çš„éƒ¨ç½²å¯¹é½è¯„ä¼°æ¡†æ¶ã€‚HALF é€šè¿‡ä¸€ä¸ªäº”é˜¶æ®µæµç¨‹(five-stage pipeline)ï¼Œå°†ä¹ä¸ªåº”ç”¨é¢†åŸŸåˆ’åˆ†ä¸ºä¸¥é‡ã€ä¸­ç­‰å’Œè½»å¾®ä¸‰ä¸ªç­‰çº§(tiers)ï¼Œä»è€Œåœ¨çœŸå®åº”ç”¨ä¸­è¯„ä¼°æ¨¡å‹åè§å¹¶æ ¹æ®æŸå®³ä¸¥é‡ç¨‹åº¦å¯¹ç»“æœè¿›è¡ŒåŠ æƒã€‚å¯¹å…«ä¸ªå¤§è¯­è¨€æ¨¡å‹(LLMs)çš„è¯„ä¼°ç»“æœæ˜¾ç¤ºï¼Œæ¨¡å‹åœ¨ä¸åŒé¢†åŸŸä¹‹é—´çš„å…¬å¹³æ€§è¡¨ç°å¹¶ä¸ä¸€è‡´ï¼Œä¸”æ¨¡å‹è§„æ¨¡æˆ–æ€§èƒ½å¹¶ä¸èƒ½ä¿è¯å…¶å…¬å¹³æ€§ã€‚æ­¤å¤–ï¼Œç ”ç©¶å‘ç°æ¨ç†æ¨¡å‹(reasoning models)åœ¨åŒ»ç–—å†³ç­–æ”¯æŒæ–¹é¢è¡¨ç°è¾ƒå¥½ï¼Œä½†åœ¨æ•™è‚²é¢†åŸŸè¡¨ç°è¾ƒå·®ã€‚è¯¥ç ”ç©¶æœ€ç»ˆè¡¨æ˜ HALF æ­ç¤ºäº†ä»¥å¾€åŸºå‡†æµ‹è¯•æˆåŠŸä¸å®é™…éƒ¨ç½²å°±ç»ªæ€§(deployment readiness)ä¹‹é—´çš„æ˜æ˜¾å·®è·ï¼Œä¸ºé«˜å½±å“é¢†åŸŸä¸­å¤§å‹è¯­è¨€æ¨¡å‹çš„å…¬æ­£éƒ¨ç½²æä¾›äº†å…³é”®çš„è¯„ä¼°æ”¯æ’‘ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.12217v2",
      "published_date": "2025-10-14 07:13:26 UTC",
      "updated_date": "2025-10-16 08:43:05 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:27:26.991187+00:00"
    },
    {
      "arxiv_id": "2510.12214v2",
      "title": "DE3S: Dual-Enhanced Soft-Sparse-Shape Learning for Medical Early Time-Series Classification",
      "title_zh": "DE3Sï¼šé¢å‘åŒ»ç–—æ—©æœŸæ—¶é—´åºåˆ—åˆ†ç±»çš„åŒå¢å¼ºè½¯ç¨€ç–å½¢çŠ¶å­¦ä¹ ",
      "authors": [
        "Tao Xie",
        "Zexi Tan",
        "Haoyi Xiao",
        "Binbin Sun",
        "Yiqun Zhang"
      ],
      "abstract": "Early Time Series Classification (ETSC) is critical in time-sensitive medical applications such as sepsis, yet it presents an inherent trade-off between accuracy and earliness. This trade-off arises from two core challenges: 1) models should effectively model inherently weak and noisy early-stage snippets, and 2) they should resolve the complex, dual requirement of simultaneously capturing local, subject-specific variations and overarching global temporal patterns. Existing methods struggle to overcome these underlying challenges, often forcing a severe compromise: sacrificing accuracy to achieve earliness, or vice-versa. We propose \\textbf{DE3S}, a \\textbf{D}ual-\\textbf{E}nhanced \\textbf{S}oft-\\textbf{S}parse \\textbf{S}equence Learning framework, which systematically solves these challenges. A dual enhancement mechanism is proposed to enhance the modeling of weak, early signals. Then, an attention-based patch module is introduced to preserve discriminative information while reducing noise and complexity. A dual-path fusion architecture is designed, using a sparse mixture of experts to model local, subject-specific variations. A multi-scale inception module is also employed to capture global dependencies. Experiments on six real-world medical datasets show the competitive performance of DE3S, particularly in early prediction windows. Ablation studies confirm the effectiveness of each component in addressing its targeted challenge. The source code is available \\href{https://github.com/kuxit/DE3S}{\\textbf{here}}.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹åŒ»ç–—é¢†åŸŸæ—©æœŸæ—¶é—´åºåˆ—åˆ†ç±»(Early Time Series Classification, ETSC)ä¸­å‡†ç¡®æ€§ä¸æå‰æ€§ä¹‹é—´çš„æƒè¡¡éš¾é¢˜ï¼Œæå‡ºäº†åä¸ºDE3Sçš„åŒå¢å¼ºè½¯ç¨€ç–åºåˆ—å­¦ä¹ æ¡†æ¶ã€‚é’ˆå¯¹æ—©æœŸä¿¡å·å¾®å¼±ä¸”å¤šå™ªå£°çš„æŒ‘æˆ˜ï¼ŒDE3Så¼•å…¥äº†åŒå¢å¼ºæœºåˆ¶æ¥å¼ºåŒ–å¯¹æ—©æœŸé˜¶æ®µæ•°æ®çš„å»ºæ¨¡ï¼Œå¹¶é€šè¿‡åŸºäºæ³¨æ„åŠ›çš„è¡¥ä¸æ¨¡å—(attention-based patch module)åœ¨é™ä½å™ªå£°å’Œå¤æ‚æ€§çš„åŒæ—¶ä¿ç•™å…³é”®åˆ¤åˆ«ä¿¡æ¯ã€‚åœ¨æ¶æ„è®¾è®¡ä¸Šï¼Œè¯¥æ¡†æ¶é‡‡ç”¨äº†åŒè·¯å¾„èåˆç»“æ„ï¼Œåˆ©ç”¨ç¨€ç–ä¸“å®¶æ··åˆ(sparse mixture of experts)æ•æ‰å—è¯•è€…ç‰¹æœ‰çš„å±€éƒ¨å˜åŒ–ï¼Œå¹¶ç»“åˆå¤šå°ºåº¦Inceptionæ¨¡å—(multi-scale inception module)æå–å…¨å±€æ—¶åºä¾èµ–ã€‚åœ¨å…­ä¸ªçœŸå®åŒ»ç–—æ•°æ®é›†ä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼ŒDE3Såœ¨æ—©æœŸé¢„æµ‹çª—å£è¡¨ç°å‡ºæå…·ç«äº‰åŠ›çš„æ€§èƒ½ï¼Œæœ‰æ•ˆè§£å†³äº†ä¼ ç»Ÿæ–¹æ³•åœ¨è¿½æ±‚æå‰æ€§æ—¶ç‰ºç‰²å‡†ç¡®æ€§çš„ç“¶é¢ˆé—®é¢˜ã€‚è¯¥ç ”ç©¶çš„æ¶ˆèå®éªŒè¿›ä¸€æ­¥éªŒè¯äº†å„æ ¸å¿ƒç»„ä»¶åœ¨åº”å¯¹ç‰¹å®šæŒ‘æˆ˜ä¸­çš„æœ‰æ•ˆæ€§ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted to IEEE BIBM 2025",
      "pdf_url": "https://arxiv.org/pdf/2510.12214v2",
      "published_date": "2025-10-14 07:10:05 UTC",
      "updated_date": "2025-11-05 14:23:32 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:27:31.389019+00:00"
    },
    {
      "arxiv_id": "2510.12209v1",
      "title": "Revisiting Meta-Learning with Noisy Labels: Reweighting Dynamics and Theoretical Guarantees",
      "title_zh": "é‡æ–°å®¡è§†å¸¦å™ªæ ‡ç­¾ä¸‹çš„å…ƒå­¦ä¹ ï¼šæƒé‡é‡åˆ†é…åŠ¨æ€ä¸ç†è®ºä¿è¯",
      "authors": [
        "Yiming Zhang",
        "Chester Holtz",
        "Gal Mishne",
        "Alex Cloninger"
      ],
      "abstract": "Learning with noisy labels remains challenging because over-parameterized networks memorize corrupted supervision. Meta-learning-based sample reweighting mitigates this by using a small clean subset to guide training, yet its behavior and training dynamics lack theoretical understanding. We provide a rigorous theoretical analysis of meta-reweighting under label noise and show that its training trajectory unfolds in three phases: (i) an alignment phase that amplifies examples consistent with a clean subset and suppresses conflicting ones; (ii) a filtering phase driving noisy example weights toward zero until the clean subset loss plateaus; and (iii) a post-filtering phase in which noise filtration becomes perturbation-sensitive. The mechanism is a similarity-weighted coupling between training and clean subset signals together with clean subset training loss contraction; in the post-filtering regime where the clean-subset loss is sufficiently small, the coupling term vanishes and meta-reweighting loses discriminatory power. Guided by this analysis, we propose a lightweight surrogate for meta-reweighting that integrates mean-centering, row shifting, and label-signed modulation, yielding more stable performance while avoiding expensive bi-level optimization. Across synthetic and real noisy-label benchmarks, our method consistently outperforms strong reweighting/selection baselines.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¸¦å™ªæ ‡ç­¾(Noisy Labels)ç¯å¢ƒä¸‹çš„å…ƒå­¦ä¹ é‡é‡‡æ ·(Meta-learning-based sample reweighting)æœºåˆ¶è¿›è¡Œäº†æ·±å…¥æ¢è®¨ï¼Œå¡«è¡¥äº†å…¶è®­ç»ƒåŠ¨æ€ç¼ºä¹ç†è®ºç†è§£çš„ç©ºç™½ã€‚ä½œè€…é€šè¿‡ä¸¥è°¨çš„æ•°å­¦åˆ†æå°†å…ƒé‡åŠ æƒçš„è®­ç»ƒè½¨è¿¹åˆ’åˆ†ä¸ºå¯¹é½(Alignment)ã€è¿‡æ»¤(Filtering)å’Œåè¿‡æ»¤(Post-filtering)ä¸‰ä¸ªé˜¶æ®µï¼Œæ­ç¤ºäº†å…¶æœ¬è´¨æ˜¯è®­ç»ƒä¿¡å·ä¸å¹²å‡€å­é›†ä¿¡å·é—´çš„ç›¸ä¼¼åº¦åŠ æƒè€¦åˆã€‚ç ”ç©¶å‘ç°ï¼Œåœ¨å¹²å‡€å­é›†æŸå¤±è¾¾åˆ°é¥±å’Œçš„åè¿‡æ»¤é˜¶æ®µï¼Œè¯¥æœºåˆ¶ä¼šå› è€¦åˆé¡¹æ¶ˆå¤±è€Œå¤±å»åˆ¤åˆ«åŠ›ã€‚åŸºäºä¸Šè¿°ç†è®ºæ´å¯Ÿï¼Œç ”ç©¶æå‡ºäº†ä¸€ç§è½»é‡çº§çš„æ›¿ä»£æ–¹æ¡ˆ(Surrogate)ï¼Œé€šè¿‡é›†æˆå‡å€¼ä¸­å¿ƒåŒ–(Mean-centering)ã€è¡Œå¹³ç§»(Row shifting)å’Œæ ‡ç­¾ç¬¦å·è°ƒåˆ¶(Label-signed modulation)æ¥è§„é¿æ˜‚è´µçš„åŒå±‚ä¼˜åŒ–(Bi-level optimization)ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ–¹æ³•åœ¨å¤šä¸ªåˆæˆåŠçœŸå®å¸¦å™ªæ ‡ç­¾åŸºå‡†æ•°æ®é›†ä¸Šå‡æ˜¾è‘—ä¼˜äºç°æœ‰çš„é‡åŠ æƒ(Reweighting)ä¸é€‰æ‹©(Selection)åŸºçº¿æ¨¡å‹ï¼Œå±•ç°å‡ºæ›´é«˜çš„ç¨³å®šæ€§å’Œæœ‰æ•ˆæ€§ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.12209v1",
      "published_date": "2025-10-14 07:00:12 UTC",
      "updated_date": "2025-10-14 07:00:12 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:27:49.490838+00:00"
    },
    {
      "arxiv_id": "2510.12201v1",
      "title": "On the Design and Evaluation of Human-centered Explainable AI Systems: A Systematic Review and Taxonomy",
      "title_zh": "ä»¥äººä¸ºæœ¬çš„å¯è§£é‡Šäººå·¥æ™ºèƒ½ç³»ç»Ÿè®¾è®¡ä¸è¯„ä¼°ï¼šç³»ç»Ÿæ€§ç»¼è¿°ä¸åˆ†ç±»ä½“ç³»",
      "authors": [
        "Aline Mangold",
        "Juliane Zietz",
        "Susanne Weinhold",
        "Sebastian Pannasch"
      ],
      "abstract": "As AI becomes more common in everyday living, there is an increasing demand for intelligent systems that are both performant and understandable. Explainable AI (XAI) systems aim to provide comprehensible explanations of decisions and predictions. At present, however, evaluation processes are rather technical and not sufficiently focused on the needs of human users. Consequently, evaluation studies involving human users can serve as a valuable guide for conducting user studies. This paper presents a comprehensive review of 65 user studies evaluating XAI systems across different domains and application contexts. As a guideline for XAI developers, we provide a holistic overview of the properties of XAI systems and evaluation metrics focused on human users (human-centered). We propose objectives for the human-centered design (design goals) of XAI systems. To incorporate users' specific characteristics, design goals are adapted to users with different levels of AI expertise (AI novices and data experts). In this regard, we provide an extension to existing XAI evaluation and design frameworks. The first part of our results includes the analysis of XAI system characteristics. An important finding is the distinction between the core system and the XAI explanation, which together form the whole system. Further results include the distinction of evaluation metrics into affection towards the system, cognition, usability, interpretability, and explanation metrics. Furthermore, the users, along with their specific characteristics and behavior, can be assessed. For AI novices, the relevant extended design goals include responsible use, acceptance, and usability. For data experts, the focus is performance-oriented and includes human-AI collaboration and system and user task performance.",
      "tldr_zh": "è¯¥ç ”ç©¶å¯¹65é¡¹è·¨é¢†åŸŸçš„å¯è§£é‡Šäººå·¥æ™ºèƒ½(Explainable AI, XAI)ç³»ç»Ÿç”¨æˆ·ç ”ç©¶è¿›è¡Œäº†ç³»ç»Ÿæ€§å›é¡¾ï¼Œæ—¨åœ¨è§£å†³ç›®å‰è¯„ä¼°è¿‡ç¨‹è¿‡äºåå‘æŠ€æœ¯è€Œå¿½è§†äººç±»ç”¨æˆ·éœ€æ±‚çš„é—®é¢˜ã€‚ä½œè€…æå‡ºäº†ä¸€ä¸ªä»¥äººä¸ºæœ¬(human-centered)çš„è®¾è®¡ä¸è¯„ä¼°åˆ†ç±»æ³•ï¼Œå¹¶è¯¦ç»†åˆ†æäº†XAIç³»ç»Ÿçš„å±æ€§ï¼Œæ˜ç¡®äº†æ ¸å¿ƒç³»ç»Ÿä¸è§£é‡Šå†…å®¹å…±åŒæ„æˆå®Œæ•´ç³»ç»Ÿçš„è§‚ç‚¹ã€‚ç ”ç©¶å°†è¯„ä¼°æŒ‡æ ‡ç»†åˆ†ä¸ºå¯¹ç³»ç»Ÿçš„æƒ…æ„Ÿã€è®¤çŸ¥ã€å¯ç”¨æ€§ã€å¯è§£é‡Šæ€§å’Œè§£é‡ŠæŒ‡æ ‡äº”ä¸ªç»´åº¦ï¼Œå¹¶æ ¹æ®ç”¨æˆ·çš„AIä¸“ä¸šçŸ¥è¯†æ°´å¹³åˆ¶å®šäº†å·®å¼‚åŒ–çš„è®¾è®¡ç›®æ ‡ã€‚é’ˆå¯¹AIæ–°æ‰‹(AI novices)ï¼Œè®¾è®¡é‡ç‚¹åœ¨äºè´Ÿè´£ä»»çš„ä½¿ç”¨ã€æ¥å—åº¦å’Œå¯ç”¨æ€§ï¼›è€Œå¯¹äºæ•°æ®ä¸“å®¶(data experts)ï¼Œåˆ™ä¾§é‡äºæ€§èƒ½å¯¼å‘çš„äººæœºåä½œ(human-AI collaboration)ä»¥åŠä»»åŠ¡ç»©æ•ˆã€‚è¿™ä¸€æ‰©å±•çš„è¯„ä¼°å’Œè®¾è®¡æ¡†æ¶ä¸ºå¼€å‘æ›´å…·ç†è§£åŠ›å’Œé«˜æ€§èƒ½çš„æ™ºèƒ½ç³»ç»Ÿæä¾›äº†é‡è¦çš„ç†è®ºæŒ‡å¯¼ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.12201v1",
      "published_date": "2025-10-14 06:52:43 UTC",
      "updated_date": "2025-10-14 06:52:43 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:27:45.995361+00:00"
    },
    {
      "arxiv_id": "2510.12194v2",
      "title": "ResearStudio: A Human-Intervenable Framework for Building Controllable Deep-Research Agents",
      "title_zh": "ResearStudioï¼šä¸€ç§æ„å»ºå¯æ§æ·±åº¦ç ”ç©¶æ™ºèƒ½ä½“çš„äººå·¥å¯å¹²é¢„æ¡†æ¶",
      "authors": [
        "Linyi Yang",
        "Yixuan Weng"
      ],
      "abstract": "Current deep-research agents run in a ''fire-and-forget'' mode: once started, they give users no way to fix errors or add expert knowledge during execution. We present ResearStudio, the first open-source framework that places real-time human control at its core. The system follows a Collaborative Workshop design. A hierarchical Planner-Executor writes every step to a live ''plan-as-document,'' a fast communication layer streams each action, file change, and tool call to a web interface. At any moment, the user can pause the run, edit the plan or code, run custom commands, and resume -- switching smoothly between AI-led, human-assisted and human-led, AI-assisted modes. In fully autonomous mode, ResearStudio achieves state-of-the-art results on the GAIA benchmark, surpassing systems like OpenAI's DeepResearch and Manus. These results show that strong automated performance and fine-grained human control can coexist. The full code, protocol, and evaluation scripts are available at https://github.com/ResearAI/ResearStudio. We will continue to update the repository to encourage further work on safe and controllable research agents. Our live demo is publicly accessible at http://ai-researcher.net:3000/. We support the development of DeepScientist, which can be accessed at https://github.com/ResearAI/DeepScientist.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ResearStudioï¼Œä¸€ç§ä»¥å®æ—¶äººç±»æ§åˆ¶ä¸ºæ ¸å¿ƒçš„å¼€æºæ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³ç°æœ‰æ·±åº¦ç ”ç©¶æ™ºèƒ½ä½“(Deep-research agents)åœ¨æ‰§è¡Œè¿‡ç¨‹ä¸­æ— æ³•è¿›è¡Œäººä¸ºå¹²é¢„æˆ–è¡¥å……ä¸“å®¶çŸ¥è¯†çš„é—®é¢˜ã€‚è¯¥ç³»ç»Ÿé‡‡ç”¨åä½œè½¦é—´(Collaborative Workshop)è®¾è®¡ï¼Œåˆ©ç”¨åˆ†å±‚è§„åˆ’æ‰§è¡Œå™¨(Planner-Executor)å°†æ¯ä¸€æ­¥æ“ä½œå®æ—¶è®°å½•ä¸ºâ€œè®¡åˆ’å³æ–‡æ¡£â€(plan-as-document)ï¼Œå¹¶å…è®¸ç”¨æˆ·éšæ—¶æš‚åœã€ç¼–è¾‘ä»£ç æˆ–è°ƒæ•´ä»»åŠ¡è®¡åˆ’ã€‚é€šè¿‡è¿™ç§æœºåˆ¶ï¼ŒResearStudioå®ç°äº†åœ¨AIä¸»å¯¼ã€äººç±»è¾…åŠ©ä¸äººç±»ä¸»å¯¼ã€AIè¾…åŠ©æ¨¡å¼ä¹‹é—´çš„å¹³æ»‘åˆ‡æ¢ï¼Œç¡®ä¿äº†ç ”ç©¶è¿‡ç¨‹çš„é«˜åº¦å¯æ§æ€§ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œåœ¨å…¨è‡ªåŠ¨æ¨¡å¼ä¸‹ï¼ŒResearStudioåœ¨GAIA benchmarkä¸­å–å¾—äº†é¢†åŸŸé¢†å…ˆ(SOTA)çš„æˆç»©ï¼Œæ€§èƒ½è¶…è¶Šäº†OpenAIçš„DeepResearchå’ŒManusç­‰ç³»ç»Ÿã€‚è¯¥ç ”ç©¶ä¸ä»…è¯æ˜äº†å¼ºå¤§çš„è‡ªåŠ¨åŒ–æ€§èƒ½ä¸ç»†ç²’åº¦çš„äººç±»æ§åˆ¶å¯ä»¥å…±å­˜ï¼Œè¿˜ä¸ºå¼€å‘å®‰å…¨ã€é€æ˜ä¸”å¯æ§çš„ç ”ç©¶æ™ºèƒ½ä½“æä¾›äº†é‡è¦çš„æŠ€æœ¯å‚è€ƒä¸å¼€æºèµ„æºã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "EMNLP 2025 Demo, Oral",
      "pdf_url": "https://arxiv.org/pdf/2510.12194v2",
      "published_date": "2025-10-14 06:40:11 UTC",
      "updated_date": "2025-11-21 05:43:16 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:27:56.095407+00:00"
    },
    {
      "arxiv_id": "2510.12184v1",
      "title": "CompoDistill: Attention Distillation for Compositional Reasoning in Multimodal LLMs",
      "title_zh": "CompoDistillï¼šé¢å‘å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ç»„åˆæ¨ç†çš„æ³¨æ„åŠ›è’¸é¦",
      "authors": [
        "Jiwan Kim",
        "Kibum Kim",
        "Sangwoo Seo",
        "Chanyoung Park"
      ],
      "abstract": "Recently, efficient Multimodal Large Language Models (MLLMs) have gained significant attention as a solution to their high computational complexity, making them more practical for real-world applications. In this regard, the knowledge distillation (KD) approach has emerged as a promising alternative, which transfers the rich visual and linguistic knowledge from a larger model (teacher) to a smaller model (student). However, we observe that existing KD methods struggle to effectively distill the teacher MLLM's rich visual perception abilities to the student, a challenge that has been largely overlooked in previous studies. Through a systematic analysis, we identify visual attention misalignment between student and teacher as the main cause of this issue. Based on this insight, we propose CompoDistill, a novel KD framework that explicitly aligns the student's visual attention with that of the teacher to enhance the student's visual perception abilities. Our extensive experiments show that CompoDistill significantly improves performance on compositional reasoning tasks that require visual perception abilities while maintaining strong performance on visual question answering tasks, as done in existing studies. Furthermore, CompoDistill demonstrates effectiveness with a more advanced backbone, highlighting its generalizability.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†CompoDistillï¼Œä¸€ç§æ—¨åœ¨æå‡å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹(MLLMs)ç»„åˆæ¨ç†(compositional reasoning)èƒ½åŠ›çš„çŸ¥è¯†è’¸é¦(Knowledge Distillation)æ¡†æ¶ã€‚ç ”ç©¶å›¢é˜Ÿé€šè¿‡ç³»ç»Ÿåˆ†æå‘ç°ï¼Œç°æœ‰è’¸é¦æ–¹æ³•åœ¨ä¼ é€’è§†è§‰æ„ŸçŸ¥èƒ½åŠ›æ–¹é¢çš„å±€é™æ€§ä¸»è¦æºäºå­¦ç”Ÿä¸æ•™å¸ˆæ¨¡å‹é—´çš„è§†è§‰æ³¨æ„åŠ›å¤±è°ƒ(visual attention misalignment)ã€‚CompoDistillé€šè¿‡æ˜¾å¼å¯¹é½ä¸¤è€…çš„è§†è§‰æ³¨æ„åŠ›ï¼Œæœ‰æ•ˆåœ°å°†æ•™å¸ˆæ¨¡å‹çš„ä¸°å¯Œè§†è§‰æ„ŸçŸ¥çŸ¥è¯†è¿ç§»è‡³è½»é‡çº§å­¦ç”Ÿæ¨¡å‹ä¸­ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ¡†æ¶åœ¨æ˜¾è‘—å¢å¼ºç»„åˆæ¨ç†ä»»åŠ¡è¡¨ç°çš„åŒæ—¶ï¼Œä¾ç„¶ä¿æŒäº†åœ¨å¸¸è§„è§†è§‰é—®ç­”(VQA)ä»»åŠ¡ä¸Šçš„å¼ºåŠ²æ€§èƒ½ã€‚æ­¤å¤–ï¼ŒCompoDistillåœ¨æ›´å…ˆè¿›çš„éª¨å¹²ç½‘ç»œ(backbone)ä¸ŠåŒæ ·å±•ç°å‡ºå“è¶Šçš„æ³›åŒ–èƒ½åŠ›ï¼Œä¸ºæ„å»ºé«˜æ•ˆä¸”æ„ŸçŸ¥èƒ½åŠ›å¼ºçš„å¤šæ¨¡æ€æ¨¡å‹æä¾›äº†æ–°æ€è·¯ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Preprint. Under Review",
      "pdf_url": "https://arxiv.org/pdf/2510.12184v1",
      "published_date": "2025-10-14 06:27:26 UTC",
      "updated_date": "2025-10-14 06:27:26 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:27:53.176094+00:00"
    },
    {
      "arxiv_id": "2510.13891v1",
      "title": "K-frames: Scene-Driven Any-k Keyframe Selection for long video understanding",
      "title_zh": "K-framesï¼šé¢å‘é•¿è§†é¢‘ç†è§£çš„åœºæ™¯é©±åŠ¨ä»»æ„ k å…³é”®å¸§é€‰æ‹©",
      "authors": [
        "Yifeng Yao",
        "Yike Yun",
        "Jing Wang",
        "Huishuai Zhang",
        "Dongyan Zhao",
        "Ke Tian",
        "Zhihao Wang",
        "Minghui Qiu",
        "Tao Wang"
      ],
      "abstract": "Multimodal Large Language Models (MLLMs) have demonstrated significant capabilities in image understanding, but long-video are constrained by context windows and computational cost. Uniform frame sampling often leads to substantial information loss. Meanwhile existing keyframe selection methods such as text-frame retrieval or RL-based frame optimization typically yield sparse and temporally disjointed frames, overlooking scene continuity and lacking flexibility for multi-scale frame selection. To address these limitations, we introduce K-frames, a novel paradigm for scene-driven keyframe selection that preserves temporal continuity. Instead of selecting individual frames, K-frames predicts semantically coherent, query-relevant clips, which enables any-k keyframes selection to meet diverse user budgets. To achieve this approach, we first introduce PeakClips, a dataset of 200K video highlights conditioned by query. Building on this dataset, K-frames learns clip2frame selection using a three-stage progressive curriculum. It involves two Supervised Fine-Tuning stages for temporal grounding and key-clip perception, followed by a Reinforcement Learning stage that directly optimizes the scene-driven prediction policy for downstream task without further annotations. Extensive experiments on major long-video understanding benchmarks demonstrate that K-frames provides an effective, interpretable, and plug-and-play solution for keyframe selection at various scales. Our dataset and model will be available.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ Multimodal Large Language Models (MLLMs) åœ¨é•¿è§†é¢‘ç†è§£ä¸­é¢ä¸´çš„ context windows é™åˆ¶ä»¥åŠä¼ ç»Ÿ uniform frame sampling å¯¼è‡´çš„ä¿¡æ¯ä¸¢å¤±é—®é¢˜ï¼Œæå‡ºäº† K-frames æ¡†æ¶ã€‚ä¸ä¼ ç»Ÿé€‰å–ç¦»æ•£å¸§çš„æ–¹æ³•ä¸åŒï¼ŒK-frames é‡‡ç”¨ä¸€ç§åœºæ™¯é©±åŠ¨çš„æ¨¡å¼ï¼Œé¢„æµ‹ä¸ query ç›¸å…³çš„è¯­ä¹‰è¿è´¯è§†é¢‘ç‰‡æ®µï¼Œä»è€Œå®ç°å¯é€‚åº”ä¸åŒè®¡ç®—é¢„ç®—çš„ any-k keyframe selectionã€‚ä¸ºäº†æ”¯æ’‘è¯¥æ–¹æ³•ï¼Œä½œè€…é¦–å…ˆæ„å»ºäº†åŒ…å« 200K æ¡è§†é¢‘ highlight çš„æ•°æ®é›† PeakClipsã€‚K-frames çš„å­¦ä¹ è¿‡ç¨‹é‡‡ç”¨äº†ä¸‰é˜¶æ®µæ¸è¿›å¼è¯¾ç¨‹ï¼šåŒ…æ‹¬ä¸¤ä¸ªç”¨äº temporal grounding å’Œ key-clip perception çš„ Supervised Fine-Tuning (SFT) é˜¶æ®µï¼Œä»¥åŠä¸€ä¸ªç›´æ¥ä¼˜åŒ–ä¸‹æ¸¸ä»»åŠ¡åœºæ™¯é©±åŠ¨é¢„æµ‹ç­–ç•¥çš„ Reinforcement Learning (RL) é˜¶æ®µã€‚åœ¨ä¸»æµé•¿è§†é¢‘ç†è§£åŸºå‡†æµ‹è¯•ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒK-frames æä¾›äº†ä¸€ç§é«˜æ•ˆã€å¯è§£é‡Šä¸”å³æ’å³ç”¨çš„å…³é”®å¸§é€‰æ‹©æ–¹æ¡ˆï¼Œèƒ½å¤Ÿçµæ´»åº”å¯¹å„ç§è§„æ¨¡çš„é‡‡æ ·éœ€æ±‚ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.13891v1",
      "published_date": "2025-10-14 06:23:22 UTC",
      "updated_date": "2025-10-14 06:23:22 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:27:56.380172+00:00"
    },
    {
      "arxiv_id": "2510.12181v1",
      "title": "From Knowledge to Treatment: Large Language Model Assisted Biomedical Concept Representation for Drug Repurposing",
      "title_zh": "ä»çŸ¥è¯†åˆ°æ²»ç–—ï¼šé¢å‘è¯ç‰©é‡å®šä½çš„å¤§è¯­è¨€æ¨¡å‹è¾…åŠ©ç”Ÿç‰©åŒ»å­¦æ¦‚å¿µè¡¨ç¤º",
      "authors": [
        "Chengrui Xiang",
        "Tengfei Ma",
        "Xiangzheng Fu",
        "Yiping Liu",
        "Bosheng Song",
        "Xiangxiang Zeng"
      ],
      "abstract": "Drug repurposing plays a critical role in accelerating treatment discovery, especially for complex and rare diseases. Biomedical knowledge graphs (KGs), which encode rich clinical associations, have been widely adopted to support this task. However, existing methods largely overlook common-sense biomedical concept knowledge in real-world labs, such as mechanistic priors indicating that certain drugs are fundamentally incompatible with specific treatments. To address this gap, we propose LLaDR, a Large Language Model-assisted framework for Drug Repurposing, which improves the representation of biomedical concepts within KGs. Specifically, we extract semantically enriched treatment-related textual representations of biomedical entities from large language models (LLMs) and use them to fine-tune knowledge graph embedding (KGE) models. By injecting treatment-relevant knowledge into KGE, LLaDR largely improves the representation of biomedical concepts, enhancing semantic understanding of under-studied or complex indications. Experiments based on benchmarks demonstrate that LLaDR achieves state-of-the-art performance across different scenarios, with case studies on Alzheimer's disease further confirming its robustness and effectiveness. Code is available at https://github.com/xiaomingaaa/LLaDR.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹è€è¯æ–°ç”¨(Drug repurposing)é¢†åŸŸä¸­ç”Ÿç‰©åŒ»å­¦çŸ¥è¯†å›¾è°±(KGs)å¿½è§†å®éªŒå®¤å¸¸è¯†åŠæœºåˆ¶å…ˆéªŒ(mechanistic priors)çš„é—®é¢˜ï¼Œæå‡ºäº†LLaDRæ¡†æ¶ã€‚è¯¥æ¡†æ¶åˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹(LLMs)æå–è¯­ä¹‰ä¸°å¯Œçš„æ²»ç–—ç›¸å…³æ–‡æœ¬è¡¨ç¤ºï¼Œå¹¶ä»¥æ­¤å¯¹çŸ¥è¯†å›¾è°±åµŒå…¥(KGE)æ¨¡å‹è¿›è¡Œå¾®è°ƒï¼Œä»è€Œä¼˜åŒ–ç”Ÿç‰©åŒ»å­¦æ¦‚å¿µçš„è¡¨ç¤ºã€‚é€šè¿‡å°†æ²»ç–—ç›¸å…³çŸ¥è¯†æ³¨å…¥KGEï¼ŒLLaDRæ˜¾è‘—å¢å¼ºäº†æ¨¡å‹å¯¹ç ”ç©¶ä¸è¶³æˆ–å¤æ‚é€‚åº”ç—‡çš„è¯­ä¹‰ç†è§£èƒ½åŠ›ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒLLaDRåœ¨å¤šé¡¹åŸºå‡†æµ‹è¯•ä¸­å–å¾—äº†æœ€å…ˆè¿›(state-of-the-art)çš„æ€§èƒ½è¡¨ç°ã€‚æ­¤å¤–ï¼Œé’ˆå¯¹é˜¿å°”èŒ¨æµ·é»˜ç—…(Alzheimer's disease)çš„æ¡ˆä¾‹ç ”ç©¶è¿›ä¸€æ­¥éªŒè¯äº†è¯¥æ¨¡å‹åœ¨å‘ç°æ½œåœ¨æ²»ç–—æ–¹æ¡ˆæ–¹é¢çš„ç¨³å¥æ€§ä¸æœ‰æ•ˆæ€§ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "16 pages, 4 figures, 13 tables. Accepted by EMNLP 2025 (Findings)",
      "pdf_url": "https://arxiv.org/pdf/2510.12181v1",
      "published_date": "2025-10-14 06:15:36 UTC",
      "updated_date": "2025-10-14 06:15:36 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:28:00.376418+00:00"
    },
    {
      "arxiv_id": "2510.12178v1",
      "title": "Evolution of meta's llama models and parameter-efficient fine-tuning of large language models: a survey",
      "title_zh": "Meta LLaMA æ¨¡å‹æ¼”è¿›ä¸å¤§è¯­è¨€æ¨¡å‹å‚æ•°é«˜æ•ˆå¾®è°ƒç»¼è¿°",
      "authors": [
        "Abdulhady Abas Abdullah",
        "Arkaitz Zubiaga",
        "Seyedali Mirjalili",
        "Amir H. Gandomi",
        "Fatemeh Daneshfar",
        "Mohammadsadra Amini",
        "Alan Salam Mohammed",
        "Hadi Veisi"
      ],
      "abstract": "This review surveys the rapid evolution of Meta AI's LLaMA (Large Language Model Meta AI) series - from LLaMA 1 through LLaMA 4 and the specialized parameter-efficient fine-tuning (PEFT) methods developed for these models. We first describe the LLaMA family of foundation models (7B-65B to 288B parameters), their architectures (including native multimodal and Mixtureof-Experts variants), and key performance characteristics. We then describe and discuss the concept of PEFT, which adapts large pre-trained models by updating only a small subset of parameters, and review five PEFT methods that have been applied to LLaMA: LoRA (Low-Rank Adaptation), LLaMA-Adapter V1 and V2, LLaMA-Excitor, and QLoRA (Quantized LoRA). We discuss each method's mechanism, parameter savings, and example application to LLaMA (e.g., instruction tuning, multimodal tasks). We provide structured discussion and analysis of model and adapter architectures, parameter counts, and benchmark results (including examples where fine-tuned LLaMA models outperform larger baselines). Finally, we examine real-world use cases where LLaMA-based models and PEFT have been successfully applied (e.g., legal and medical domains), and we discuss ongoing challenges and future research directions (such as scaling to even larger contexts and improving robustness). This survey paper provides a one-stop resource for ML researchers and practitioners interested in LLaMA models and efficient fine-tuning strategies.",
      "tldr_zh": "è¿™ç¯‡ç»¼è¿°ç³»ç»Ÿåœ°å›é¡¾äº†Meta AIå¼€å‘çš„LLaMAç³»åˆ—æ¨¡å‹ï¼ˆä»LLaMA 1åˆ°LLaMA 4ï¼‰çš„æ¼”è¿›è¿‡ç¨‹ï¼Œå¹¶æ·±å…¥æ¢è®¨äº†é’ˆå¯¹è¿™äº›æ¨¡å‹å¼€å‘çš„å‚æ•°é«˜æ•ˆå¾®è°ƒï¼ˆParameter-Efficient Fine-Tuning, PEFTï¼‰æ–¹æ³•ã€‚æ–‡ç« è¯¦ç»†ä»‹ç»äº†LLaMAåŸºç¡€æ¨¡å‹çš„æ¶æ„ç‰¹ç‚¹ï¼Œæ¶µç›–äº†ä»7Båˆ°288Bå‚æ•°è§„æ¨¡ï¼ŒåŒ…æ‹¬åŸç”Ÿå¤šæ¨¡æ€ï¼ˆnative multimodalï¼‰å’Œæ··åˆä¸“å®¶ï¼ˆMixture-of-Experts, MoEï¼‰å˜ä½“ã€‚ç ”ç©¶é‡ç‚¹è®¨è®ºäº†PEFTçš„æ ¸å¿ƒæœºåˆ¶ï¼Œå³é€šè¿‡ä»…æ›´æ–°æå°æ¯”ä¾‹çš„å‚æ•°æ¥é€‚é…é¢„è®­ç»ƒæ¨¡å‹ï¼Œå¹¶å®¡è§†äº†LoRAã€LLaMA-Adapter V1/V2ã€LLaMA-Excitorå’ŒQLoRAç­‰å¾®è°ƒæŠ€æœ¯çš„æ€§èƒ½è¡¨ç°ä¸å‚æ•°èŠ‚çœæ•ˆæœã€‚é€šè¿‡å¯¹æ¨¡å‹æ¶æ„å’ŒåŸºå‡†æµ‹è¯•ç»“æœçš„åˆ†æï¼Œå±•ç¤ºäº†å¾®è°ƒåçš„LLaMAæ¨¡å‹åœ¨ç‰¹å®šä»»åŠ¡ä¸Šèƒ½å¤Ÿè¶…è¶Šæ›´å¤§è§„æ¨¡çš„åŸºå‡†æ¨¡å‹ã€‚æœ€åï¼Œè¯¥ç»¼è¿°æ¢è®¨äº†LLaMAåœ¨æ³•å¾‹ã€åŒ»ç–—ç­‰é¢†åŸŸçš„å®é™…åº”ç”¨ï¼Œå¹¶é’ˆå¯¹æ‰©å±•ä¸Šä¸‹æ–‡åŠæå‡é²æ£’æ€§ç­‰æœªæ¥ç ”ç©¶æ–¹å‘æä¾›äº†ä¸“ä¸šè§è§£ã€‚",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.12178v1",
      "published_date": "2025-10-14 06:12:44 UTC",
      "updated_date": "2025-10-14 06:12:44 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:28:02.397113+00:00"
    },
    {
      "arxiv_id": "2510.12171v1",
      "title": "MatSciBench: Benchmarking the Reasoning Ability of Large Language Models in Materials Science",
      "title_zh": "MatSciBenchï¼šå¤§è¯­è¨€æ¨¡å‹åœ¨ææ–™ç§‘å­¦é¢†åŸŸæ¨ç†èƒ½åŠ›çš„åŸºå‡†æµ‹è¯•",
      "authors": [
        "Junkai Zhang",
        "Jingru Gan",
        "Xiaoxuan Wang",
        "Zian Jia",
        "Changquan Gu",
        "Jianpeng Chen",
        "Yanqiao Zhu",
        "Mingyu Derek Ma",
        "Dawei Zhou",
        "Ling Li",
        "Wei Wang"
      ],
      "abstract": "Large Language Models (LLMs) have demonstrated remarkable abilities in scientific reasoning, yet their reasoning capabilities in materials science remain underexplored. To fill this gap, we introduce MatSciBench, a comprehensive college-level benchmark comprising 1,340 problems that span the essential subdisciplines of materials science. MatSciBench features a structured and fine-grained taxonomy that categorizes materials science questions into 6 primary fields and 31 sub-fields, and includes a three-tier difficulty classification based on the reasoning length required to solve each question. MatSciBench provides detailed reference solutions enabling precise error analysis and incorporates multimodal reasoning through visual contexts in numerous questions. Evaluations of leading models reveal that even the highest-performing model, Gemini-2.5-Pro, achieves under 80% accuracy on college-level materials science questions, highlighting the complexity of MatSciBench. Our systematic analysis of different reasoning strategie--basic chain-of-thought, tool augmentation, and self-correction--demonstrates that no single method consistently excels across all scenarios. We further analyze performance by difficulty level, examine trade-offs between efficiency and accuracy, highlight the challenges inherent in multimodal reasoning tasks, analyze failure modes across LLMs and reasoning methods, and evaluate the influence of retrieval-augmented generation. MatSciBench thus establishes a comprehensive and solid benchmark for assessing and driving improvements in the scientific reasoning capabilities of LLMs within the materials science domain.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† MatSciBenchï¼Œè¿™æ˜¯ä¸€ä¸ªåŒ…å« 1,340 ä¸ªé—®é¢˜çš„ç»¼åˆæ€§å¤§å­¦æ°´å¹³åŸºå‡†æµ‹è¯•ï¼Œæ—¨åœ¨è¯„ä¼°å¤§å‹è¯­è¨€æ¨¡å‹ (LLMs) åœ¨ææ–™ç§‘å­¦é¢†åŸŸçš„æ¨ç†èƒ½åŠ›ã€‚MatSciBench é‡‡ç”¨ç»†ç²’åº¦çš„åˆ†ç±»ä½“ç³»ï¼Œæ¶µç›– 6 ä¸ªä¸»è¦é¢†åŸŸå’Œ 31 ä¸ªå­é¢†åŸŸï¼Œå¹¶æ ¹æ®æ¨ç†é•¿åº¦éœ€æ±‚è®¾ç½®äº†ä¸‰çº§éš¾åº¦åˆ†ç±»ï¼ŒåŒæ—¶æ•´åˆäº†å¤šæ¨¡æ€æ¨ç†æ‰€éœ€çš„è§†è§‰ä¸Šä¸‹æ–‡ã€‚å®éªŒè¯„ä¼°è¡¨æ˜ï¼Œå³ä¾¿å¦‚ Gemini-2.5-Pro ç­‰é¢†å…ˆæ¨¡å‹åœ¨è¯¥åŸºå‡†ä¸Šçš„å‡†ç¡®ç‡ä¹Ÿæœªè¾¾åˆ° 80%ï¼Œåæ˜ å‡ºææ–™ç§‘å­¦æ¨ç†ä»»åŠ¡çš„æé«˜å¤æ‚æ€§ã€‚é€šè¿‡å¯¹åŸºç¡€é“¾å¼æ€ç»´ (Chain-of-Thought)ã€å·¥å…·å¢å¼º (Tool Augmentation) å’Œè‡ªæˆ‘ä¿®æ­£ (Self-Correction) ç­‰ç­–ç•¥çš„ç³»ç»Ÿåˆ†æï¼Œç ”ç©¶å‘ç°ç›®å‰å°šæ— å•ä¸€æ–¹æ³•èƒ½åœ¨æ‰€æœ‰åœºæ™¯ä¸‹ä¿æŒé¢†å…ˆã€‚æ­¤å¤–ï¼Œè®ºæ–‡è¿˜æ·±å…¥æ¢è®¨äº†æ£€ç´¢å¢å¼ºç”Ÿæˆ (Retrieval-Augmented Generation, RAG) çš„å½±å“ã€å¤šæ¨¡æ€ä»»åŠ¡çš„æŒ‘æˆ˜ä»¥åŠæ¨¡å‹å¤±æ•ˆæ¨¡å¼ã€‚MatSciBench ä¸ºè¯„ä¼°å’Œæ¨åŠ¨å¤§è¯­è¨€æ¨¡å‹åœ¨ç§‘å­¦ç ”ç©¶é¢†åŸŸçš„æ·±åº¦æ¨ç†èƒ½åŠ›æä¾›äº†åšå®çš„åŸºç¡€ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.12171v1",
      "published_date": "2025-10-14 05:59:40 UTC",
      "updated_date": "2025-10-14 05:59:40 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:28:05.977107+00:00"
    },
    {
      "arxiv_id": "2510.12144v1",
      "title": "Budget-constrained Active Learning to Effectively De-censor Survival Data",
      "title_zh": "é¢„ç®—çº¦æŸä¸‹å®ç°ç”Ÿå­˜æ•°æ®æœ‰æ•ˆå»åˆ å¤±çš„ä¸»åŠ¨å­¦ä¹ ",
      "authors": [
        "Ali Parsaee",
        "Bei Jiang",
        "Zachary Friggstad",
        "Russell Greiner"
      ],
      "abstract": "Standard supervised learners attempt to learn a model from a labeled dataset. Given a small set of labeled instances, and a pool of unlabeled instances, a budgeted learner can use its given budget to pay to acquire the labels of some unlabeled instances, which it can then use to produce a model. Here, we explore budgeted learning in the context of survival datasets, which include (right) censored instances, where we know only a lower bound on an instance's time-to-event. Here, that learner can pay to (partially) label a censored instance -- e.g., to acquire the actual time for an instance [perhaps go from (3 yr, censored) to (7.2 yr, uncensored)], or other variants [e.g., learn about one more year, so go from (3 yr, censored) to either (4 yr, censored) or perhaps (3.2 yr, uncensored)]. This serves as a model of real world data collection, where follow-up with censored patients does not always lead to uncensoring, and how much information is given to the learner model during data collection is a function of the budget and the nature of the data itself. We provide both experimental and theoretical results for how to apply state-of-the-art budgeted learning algorithms to survival data and the respective limitations that exist in doing so. Our approach provides bounds and time complexity asymptotically equivalent to the standard active learning method BatchBALD. Moreover, empirical analysis on several survival tasks show that our model performs better than other potential approaches on several benchmarks.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†åœ¨é¢„ç®—çº¦æŸä¸‹çš„ä¸»åŠ¨å­¦ä¹ (Active Learning)å¦‚ä½•æœ‰æ•ˆå¤„ç†ç”Ÿå­˜æ•°æ®(Survival Data)ä¸­çš„åˆ å¤±(Censored)é—®é¢˜ã€‚é’ˆå¯¹ç”Ÿå­˜åˆ†æä¸­å¸¸è§çš„ä»…çŸ¥äº‹ä»¶å‘ç”Ÿæ—¶é—´ä¸‹é™çš„å³åˆ å¤±å®ä¾‹ï¼Œç ”ç©¶æå‡ºäº†å…è®¸å­¦ä¹ è€…åˆ©ç”¨æœ‰é™é¢„ç®—è·å–æ›´å¤šéšè®¿ä¿¡æ¯ï¼Œè¿›è€Œå®ç°æ•°æ®â€œå»åˆ å¤±(De-censor)â€çš„é€šç”¨æ¡†æ¶ã€‚è¯¥æ–¹æ³•åœ¨ç†è®ºä¸Šè¯æ˜äº†å…¶æ€§èƒ½ç•Œé™å’Œæ—¶é—´å¤æ‚åº¦ä¸æ ‡å‡†ä¸»åŠ¨å­¦ä¹ ç®—æ³•BatchBALDæ¸è¿‘ç­‰æ•ˆï¼Œèƒ½å¤Ÿç²¾å‡†æ¨¡æ‹Ÿç°å®ä¸­éšè®¿æŠ•å…¥ä¸ä¿¡æ¯ä¸ç¡®å®šæ€§ä¹‹é—´çš„å¤æ‚å…³ç³»ã€‚å¤šé¡¹ç”Ÿå­˜åˆ†æåŸºå‡†ä»»åŠ¡çš„å®éªŒåˆ†æè¡¨æ˜ï¼Œè¯¥æ¨¡å‹åœ¨æ•°æ®æ”¶é›†æ•ˆç‡å’Œé¢„æµ‹å‡†ç¡®æ€§ä¸Šå‡ä¼˜äºç°æœ‰çš„å…¶ä»–ç«äº‰æ–¹æ¡ˆã€‚è¯¥æˆæœä¸ºåœ¨èµ„æºå—é™ç¯å¢ƒä¸‹ä¼˜åŒ–ç”Ÿå­˜æ•°æ®çš„åˆ©ç”¨ä»·å€¼å¹¶æå‡æ¨¡å‹æ€§èƒ½æä¾›äº†é‡è¦çš„æŠ€æœ¯æ”¯æ’‘ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.12144v1",
      "published_date": "2025-10-14 04:53:30 UTC",
      "updated_date": "2025-10-14 04:53:30 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:28:09.187557+00:00"
    },
    {
      "arxiv_id": "2510.12137v1",
      "title": "Credal Transformer: A Principled Approach for Quantifying and Mitigating Hallucinations in Large Language Models",
      "title_zh": "Credal Transformerï¼šä¸€ç§é‡åŒ–ä¸ç¼“è§£å¤§è¯­è¨€æ¨¡å‹å¹»è§‰çš„åŸåˆ™æ€§æ–¹æ³•",
      "authors": [
        "Shihao Ji",
        "Zihui Song",
        "Jiajie Huang"
      ],
      "abstract": "Large Language Models (LLMs) hallucinate, generating factually incorrect yet confident assertions. We argue this stems from the Transformer's Softmax function, which creates \"Artificial Certainty\" by collapsing ambiguous attention scores into a single probability distribution, discarding uncertainty information at each layer. To fix this, we introduce the Credal Transformer, which replaces standard attention with a Credal Attention Mechanism (CAM) based on evidential theory. CAM produces a \"credal set\" (a set of distributions) instead of a single attention vector, with the set's size directly measuring model uncertainty. We implement this by re-conceptualizing attention scores as evidence masses for a Dirichlet distribution: sufficient evidence recovers standard attention, while insufficient evidence yields a diffuse distribution, representing ambiguity. Empirically, the Credal Transformer identifies out-of-distribution inputs, quantifies ambiguity, and significantly reduces confident errors on unanswerable questions by abstaining. Our contribution is a new architecture to mitigate hallucinations and a design paradigm that integrates uncertainty quantification directly into the model, providing a foundation for more reliable AI.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§è¯­è¨€æ¨¡å‹ (LLMs) ä¸­æ™®éå­˜åœ¨çš„å¹»è§‰ (Hallucination) é—®é¢˜ï¼ŒæŒ‡å‡º Transformer æ¶æ„ä¸­çš„ Softmax å‡½æ•°å› æŠ˜å æ­§ä¹‰åˆ†æ•°è€Œäº§ç”Ÿäº†â€œäººå·¥ç¡®å®šæ€§â€ (Artificial Certainty)ï¼Œä»è€Œæ©ç›–äº†æ¨¡å‹å„å±‚çš„ä¸ç¡®å®šæ€§ã€‚ä¸ºæ­¤ï¼Œä½œè€…æå‡ºäº† Credal Transformerï¼Œé€šè¿‡å¼•å…¥åŸºäºè¯æ®ç†è®º (Evidential Theory) çš„ Credal Attention Mechanism (CAM) æ¥æ›¿æ¢æ ‡å‡†æ³¨æ„åŠ›æœºåˆ¶ã€‚CAM ä¸å†è¾“å‡ºå•ä¸€çš„æ³¨æ„åŠ›å‘é‡ï¼Œè€Œæ˜¯äº§ç”Ÿä¸€ä¸ªä»£è¡¨åˆ†å¸ƒé›†åˆçš„â€œä¿¡åº¦é›†â€ (Credal Set)ï¼Œå…¶é›†åˆå¤§å°å¯ç›´æ¥è¡¡é‡æ¨¡å‹çš„ä¸ç¡®å®šæ€§ã€‚åœ¨å…·ä½“å®ç°ä¸Šï¼Œè¯¥ç ”ç©¶å°†æ³¨æ„åŠ›åˆ†æ•°é‡æ–°æ¦‚å¿µåŒ–ä¸º Dirichlet åˆ†å¸ƒçš„è¯æ®è´¨é‡ï¼Œç¡®ä¿æ¨¡å‹åœ¨è¯æ®ä¸è¶³æ—¶èƒ½å¤Ÿé€šè¿‡å¼¥æ•£åˆ†å¸ƒè¡¨è¾¾æ­§ä¹‰ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒCredal Transformer èƒ½å¤Ÿæœ‰æ•ˆè¯†åˆ«åˆ†å¸ƒå¤– (Out-of-Distribution) è¾“å…¥ï¼Œå¹¶é€šè¿‡åœ¨æ— æ³•å›ç­”çš„é—®é¢˜ä¸Šé‡‡å–å¼ƒæƒç­–ç•¥ï¼Œæ˜¾è‘—å‡å°‘äº†è‡ªä¿¡çš„é”™è¯¯è¾“å‡ºã€‚è¿™ä¸€è´¡çŒ®ä¸ºç¼“è§£å¹»è§‰æä¾›äº†æ–°çš„æ¶æ„æ–¹æ¡ˆï¼Œå¹¶å°†ä¸ç¡®å®šæ€§é‡åŒ–ç›´æ¥é›†æˆåˆ°æ¨¡å‹è®¾è®¡ä¸­ï¼Œä¸ºæ„å»ºæ›´å¯é çš„äººå·¥æ™ºèƒ½å¥ å®šäº†åŸºç¡€ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.12137v1",
      "published_date": "2025-10-14 04:31:49 UTC",
      "updated_date": "2025-10-14 04:31:49 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:28:11.276723+00:00"
    },
    {
      "arxiv_id": "2510.12133v1",
      "title": "SafeMT: Multi-turn Safety for Multimodal Language Models",
      "title_zh": "SafeMTï¼šé¢å‘å¤šæ¨¡æ€è¯­è¨€æ¨¡å‹çš„å¤šè½®å¯¹è¯å®‰å…¨æ€§",
      "authors": [
        "Han Zhu",
        "Juntao Dai",
        "Jiaming Ji",
        "Haoran Li",
        "Chengkun Cai",
        "Pengcheng Wen",
        "Chi-Min Chan",
        "Boyuan Chen",
        "Yaodong Yang",
        "Sirui Han",
        "Yike Guo"
      ],
      "abstract": "With the widespread use of multi-modal Large Language models (MLLMs), safety issues have become a growing concern. Multi-turn dialogues, which are more common in everyday interactions, pose a greater risk than single prompts; however, existing benchmarks do not adequately consider this situation. To encourage the community to focus on the safety issues of these models in multi-turn dialogues, we introduce SafeMT, a benchmark that features dialogues of varying lengths generated from harmful queries accompanied by images. This benchmark consists of 10,000 samples in total, encompassing 17 different scenarios and four jailbreak methods. Additionally, we propose Safety Index (SI) to evaluate the general safety of MLLMs during conversations. We assess the safety of 17 models using this benchmark and discover that the risk of successful attacks on these models increases as the number of turns in harmful dialogues rises. This observation indicates that the safety mechanisms of these models are inadequate for recognizing the hazard in dialogue interactions. We propose a dialogue safety moderator capable of detecting malicious intent concealed within conversations and providing MLLMs with relevant safety policies. Experimental results from several open-source models indicate that this moderator is more effective in reducing multi-turn ASR compared to existed guard models.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ (Multimodal Large Language Models, MLLMs) åœ¨å¤šè½®å¯¹è¯ä¸­é¢ä¸´çš„å®‰å…¨é£é™©ï¼Œæ¨å‡ºäº†ä¸€ä¸ªåä¸º SafeMT çš„åŸºå‡†æµ‹è¯•ã€‚è¯¥åŸºå‡†åŒ…å« 10,000 ä¸ªæ ·æœ¬ï¼Œæ¶µç›–äº† 17 ç§ä¸åŒåœºæ™¯å’Œ 4 ç§è¶Šç‹± (jailbreak) æ–¹æ³•ï¼Œé‡ç‚¹è¯„ä¼°æ¨¡å‹åœ¨å˜é•¿å¯¹è¯ä¸­çš„å®‰å…¨æ€§è¡¨ç°ã€‚ç ”ç©¶åŒæ—¶æå‡ºäº†å®‰å…¨æŒ‡æ•° (Safety Index, SI) ç”¨äºè¡¡é‡å¯¹è¯è¿‡ç¨‹ä¸­çš„é€šç”¨å®‰å…¨æ€§ã€‚é€šè¿‡è¯„ä¼° 17 ä¸ªä¸»æµæ¨¡å‹ï¼Œç ”ç©¶å‘ç°æ”»å‡»æˆåŠŸç‡éšå¯¹è¯è½®æ•°å¢åŠ è€Œä¸Šå‡ï¼Œæ­ç¤ºäº†ç°æœ‰å®‰å…¨æœºåˆ¶åœ¨å¤šè½®äº¤äº’ç†è§£ä¸Šçš„ç¼ºé™·ã€‚ä¸ºè§£å†³æ­¤é—®é¢˜ï¼Œç ”ç©¶æå‡ºäº†ä¸€ç§å¯¹è¯å®‰å…¨è°ƒèŠ‚å™¨ (dialogue safety moderator)ï¼Œç”¨äºè¯†åˆ«å¯¹è¯ä¸­çš„éšè—æ¶æ„æ„å›¾å¹¶æä¾›å®‰å…¨ç­–ç•¥ã€‚å®éªŒè¡¨æ˜ï¼Œè¯¥è°ƒèŠ‚å™¨åœ¨é™ä½å¤šè½®å¯¹è¯çš„æ”»å‡»æˆåŠŸç‡ (ASR) æ–¹é¢ä¼˜äºç°æœ‰é˜²æŠ¤æ¨¡å‹ï¼Œä¸ºæå‡ MLLMs çš„å®é™…äº¤äº’å®‰å…¨æ€§æä¾›äº†æœ‰æ•ˆæ‰‹æ®µã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.12133v1",
      "published_date": "2025-10-14 04:24:07 UTC",
      "updated_date": "2025-10-14 04:24:07 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:28:26.376384+00:00"
    },
    {
      "arxiv_id": "2510.13890v2",
      "title": "A Survey on Collaborating Small and Large Language Models for Performance, Cost-effectiveness, Cloud-edge Privacy, and Trustworthiness",
      "title_zh": "å¤§å°è¯­è¨€æ¨¡å‹ååŒç ”ç©¶ç»¼è¿°ï¼šæ€§èƒ½ã€æˆæœ¬æ•ˆç›Šã€äº‘è¾¹éšç§ä¸å¯ä¿¡æ€§",
      "authors": [
        "Fali Wang",
        "Jihai Chen",
        "Shuhua Yang",
        "Ali Al-Lawati",
        "Linli Tang",
        "Hui Liu",
        "Suhang Wang"
      ],
      "abstract": "Large language models (LLMs) have achieved remarkable progress across domains and applications but face challenges such as high fine-tuning costs, inference latency, limited edge deployability, and reliability concerns. Small language models (SLMs), with compact, efficient, and adaptable features, offer promising solutions. Building on this potential, recent research explores collaborative frameworks that integrate their complementary strengths, leveraging SLMs' specialization and efficiency with LLMs' generalization and reasoning to address diverse objectives across tasks and deployment scenarios. Motivated by these developments, this paper presents a systematic survey of SLM-LLM collaboration from the perspective of collaboration objectives. We propose a taxonomy covering four goals: performance enhancement, cost-effectiveness, cloud-edge privacy, and trustworthiness. Under this framework, we review representative methods, summarize design paradigms, and outline open challenges and future directions toward efficient and secure SLM-LLM collaboration. The collected papers are available at https://github.com/FairyFali/SLMs-Survey.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§å‹è¯­è¨€æ¨¡å‹(LLMs)åœ¨å¾®è°ƒæˆæœ¬ã€æ¨ç†å»¶è¿Ÿã€è¾¹ç¼˜éƒ¨ç½²å’Œå¯é æ€§æ–¹é¢é¢ä¸´çš„æŒ‘æˆ˜ï¼Œç³»ç»Ÿåœ°ç»¼è¿°äº†å°å‹è¯­è¨€æ¨¡å‹(SLMs)ä¸LLMsçš„ååŒå·¥ä½œæœºåˆ¶ã€‚é€šè¿‡ç»“åˆSLMsçš„ä¸“ä¸šåŒ–ä¸æ•ˆç‡ä»¥åŠLLMsçš„æ³›åŒ–ä¸æ¨ç†èƒ½åŠ›ï¼Œè¯¥è®ºæ–‡æå‡ºäº†ä¸€ç§æ¶µç›–æ€§èƒ½å¢å¼º(Performance Enhancement)ã€æˆæœ¬æ•ˆç›Š(Cost-effectiveness)ã€äº‘è¾¹éšç§(Cloud-edge Privacy)å’Œå¯ä¿¡åº¦(Trustworthiness)å››ä¸ªç›®æ ‡çš„åˆ†ç±»ä½“ç³»ã€‚æ–‡ç« è¯¦ç»†å›é¡¾äº†ä»£è¡¨æ€§æ–¹æ³•ï¼Œæ€»ç»“äº†è®¾è®¡èŒƒå¼ï¼Œå¹¶æ¢è®¨äº†åœ¨é«˜æ•ˆå®‰å…¨åä½œæ–¹é¢çš„å¼€æ”¾æ€§æŒ‘æˆ˜ä¸æœªæ¥æ–¹å‘ã€‚è¯¥ç»¼è¿°ä¸ºè§£å†³ä¸åŒä»»åŠ¡å’Œéƒ¨ç½²åœºæ™¯ä¸‹çš„ååŒä¼˜åŒ–æä¾›äº†å…¨é¢çš„ç†è®ºæ¡†æ¶å’Œå®è·µæŒ‡å—ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "24 pages, 19 figures-under review; more detailed than v1",
      "pdf_url": "https://arxiv.org/pdf/2510.13890v2",
      "published_date": "2025-10-14 04:16:47 UTC",
      "updated_date": "2025-11-05 10:30:09 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:28:23.285640+00:00"
    },
    {
      "arxiv_id": "2510.12121v1",
      "title": "Precise Attribute Intensity Control in Large Language Models via Targeted Representation Editing",
      "title_zh": "åŸºäºå®šå‘è¡¨å¾ç¼–è¾‘çš„å¤§è¯­è¨€æ¨¡å‹ç²¾å‡†å±æ€§å¼ºåº¦æ§åˆ¶",
      "authors": [
        "Rongzhi Zhang",
        "Liqin Ye",
        "Yuzhao Heng",
        "Xiang Chen",
        "Tong Yu",
        "Lingkai Kong",
        "Sudheer Chava",
        "Chao Zhang"
      ],
      "abstract": "Precise attribute intensity control--generating Large Language Model (LLM) outputs with specific, user-defined attribute intensities--is crucial for AI systems adaptable to diverse user expectations. Current LLM alignment methods, however, typically provide only directional or open-ended guidance, failing to reliably achieve exact attribute intensities. We address this limitation with three key designs: (1) reformulating precise attribute intensity control as a target-reaching problem, rather than simple maximization; (2) training a lightweight value function via temporal-difference learning to predict final attribute intensity scores from partial generations, thereby steering LLM outputs; and (3) employing gradient-based interventions on hidden representations to navigate the model precisely towards specific attribute intensity targets. Our method enables fine-grained, continuous control over attribute intensities, moving beyond simple directional alignment. Experiments on LLaMA-3.2-3b and Phi-4-mini confirm our method's ability to steer text generation to user-specified attribute intensities with high accuracy. Finally, we demonstrate efficiency enhancements across three downstream tasks: preference data synthesis, Pareto frontier approximation and optimization, and distillation of aligned behaviors for intervention-free inference. Our code is available on https://github.com/Pre-Control/pre-control",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§è¯­è¨€æ¨¡å‹ (LLMs) åœ¨å±æ€§å¼ºåº¦æ§åˆ¶ä¸Šä»…èƒ½æä¾›å®šå‘å¼•å¯¼è€Œéç²¾ç¡®æ•°å€¼çš„é—®é¢˜ï¼Œå°†ç²¾ç¡®å±æ€§å¼ºåº¦æ§åˆ¶ (Precise attribute intensity control) é‡æ–°å®šä¹‰ä¸ºä¸€ä¸ªç›®æ ‡è¾¾æˆé—®é¢˜ (Target-reaching problem)ã€‚ç ”ç©¶å›¢é˜Ÿé€šè¿‡æ—¶é—´å·®åˆ†å­¦ä¹  (Temporal-difference learning) è®­ç»ƒäº†ä¸€ä¸ªè½»é‡çº§çš„å€¼å‡½æ•° (Value function)ï¼Œç”¨äºä»éƒ¨åˆ†ç”Ÿæˆçš„æ–‡æœ¬ä¸­é¢„æµ‹æœ€ç»ˆçš„å±æ€§å¼ºåº¦å¾—åˆ†ã€‚é€šè¿‡åœ¨éšè—è¡¨ç¤º (Hidden representations) ä¸Šé‡‡ç”¨åŸºäºæ¢¯åº¦çš„å¹²é¢„æ‰‹æ®µ (Gradient-based interventions)ï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿå°†æ¨¡å‹è¾“å‡ºç²¾ç¡®å¯¼èˆªè‡³ç‰¹å®šçš„å±æ€§å¼ºåº¦ç›®æ ‡ï¼Œå®ç°äº†ç»†ç²’åº¦ä¸”è¿ç»­çš„æ§åˆ¶ã€‚åœ¨ LLaMA-3.2-3b å’Œ Phi-4-mini ä¸Šçš„å®éªŒéªŒè¯äº†è¯¥æ–¹æ³•åœ¨å¼•å¯¼ç”Ÿæˆæ–‡æœ¬è¾¾åˆ°æŒ‡å®šå¼ºåº¦æ–¹é¢å…·æœ‰æé«˜å‡†ç¡®æ€§ã€‚æ­¤å¤–ï¼Œè¯¥æŠ€æœ¯åœ¨åå¥½æ•°æ®åˆæˆ (Preference data synthesis)ã€å¸•ç´¯æ‰˜å‰æ²¿ (Pareto frontier) è¿‘ä¼¼ä¸ä¼˜åŒ–ä»¥åŠå¯¹é½è¡Œä¸ºè’¸é¦ (Distillation) ç­‰ä¸‹æ¸¸ä»»åŠ¡ä¸­å±•ç°äº†æ˜¾è‘—çš„æ•ˆç‡æå‡ã€‚",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.12121v1",
      "published_date": "2025-10-14 03:50:22 UTC",
      "updated_date": "2025-10-14 03:50:22 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:28:46.085096+00:00"
    },
    {
      "arxiv_id": "2510.12116v1",
      "title": "Understanding the Modality Gap: An Empirical Study on the Speech-Text Alignment Mechanism of Large Speech Language Models",
      "title_zh": "ç†è§£æ¨¡æ€é¸¿æ²Ÿï¼šå¤§è§„æ¨¡è¯­éŸ³è¯­è¨€æ¨¡å‹è¯­éŸ³-æ–‡æœ¬å¯¹é½æœºåˆ¶çš„å®è¯ç ”ç©¶",
      "authors": [
        "Bajian Xiang",
        "Shuaijiang Zhao",
        "Tingwei Guo",
        "Wei Zou"
      ],
      "abstract": "End-to-end Large Speech Language Models (LSLMs) have demonstrated impressive conversational generation abilities, yet consistently fall short of traditional pipeline systems on semantic understanding benchmarks. In this work, we reveal through systematic experimentation that although LSLMs lose some text input performance after speech-text alignment training, the performance gap between speech and text inputs is more pronounced, which we refer to as the modality gap. To understand this gap, we analyze both coarse- and fine-grained text and speech representations. At the coarse-grained level, representations of speech and text in deeper layers are found to be increasingly aligned in direction (cosine similarity), while concurrently diverging in magnitude (Euclidean distance). We further find that representation similarity is strongly correlated with the modality gap. At the fine-grained level, a spontaneous token-level alignment pattern between text and speech representations is observed. Based on this, we introduce the Alignment Path Score to quantify token-level alignment quality, which exhibits stronger correlation with the modality gap. Building on these insights, we design targeted interventions on critical tokens through angle projection and length normalization. These strategies demonstrate the potential to improve correctness for speech inputs. Our study provides the first systematic empirical analysis of the modality gap and alignment mechanisms in LSLMs, offering both theoretical and methodological guidance for future optimization.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç«¯åˆ°ç«¯ Large Speech Language Models (LSLMs) åœ¨è¯­ä¹‰ç†è§£ä»»åŠ¡ä¸­è¡¨ç°é€Šäºä¼ ç»Ÿç³»ç»Ÿçš„é—®é¢˜ï¼Œç³»ç»Ÿæ€§åœ°åˆ†æäº†è¯­éŸ³ä¸æ–‡æœ¬è¾“å…¥ä¹‹é—´çš„ modality gapã€‚å®éªŒå‘ç°ï¼Œæ¨¡å‹æ·±å±‚çš„è¯­éŸ³å’Œæ–‡æœ¬è¡¨å¾åœ¨æ–¹å‘ï¼ˆcosine similarityï¼‰ä¸Šè¶‹äºä¸€è‡´ï¼Œä½†åœ¨æ¨¡é•¿ï¼ˆEuclidean distanceï¼‰ä¸Šå­˜åœ¨æ˜¾è‘—å·®å¼‚ï¼Œä¸”è¿™ç§è¡¨å¾å·®å¼‚ä¸ modality gap é«˜åº¦ç›¸å…³ã€‚ç ”ç©¶è¿›ä¸€æ­¥è§‚å¯Ÿåˆ° token-level çš„è‡ªå‘å¯¹é½æ¨¡å¼ï¼Œå¹¶æå‡ºäº† Alignment Path Score ç”¨äºé‡åŒ–å¯¹é½è´¨é‡ã€‚åŸºäºä¸Šè¿°è§è§£ï¼Œç ”ç©¶è€…é€šè¿‡å¯¹å…³é”® token è¿›è¡Œè§’åº¦æŠ•å½±å’Œé•¿åº¦å½’ä¸€åŒ–å¤„ç†ï¼ŒæˆåŠŸæ”¹å–„äº†è¯­éŸ³è¾“å…¥çš„å‡†ç¡®æ€§ã€‚è¯¥å·¥ä½œä¸ºç†è§£ LSLMs çš„å¯¹é½æœºåˆ¶æä¾›äº†é¦–ä¸ªç³»ç»Ÿæ€§çš„å®è¯åˆ†æï¼Œå¹¶ä¸ºåç»­çš„æ¨¡å‹ä¼˜åŒ–æä¾›äº†ç†è®ºæ”¯æ’‘å’Œæ–¹æ³•æŒ‡å¯¼ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to EMNLP 2025 (Main Conference)",
      "pdf_url": "https://arxiv.org/pdf/2510.12116v1",
      "published_date": "2025-10-14 03:34:38 UTC",
      "updated_date": "2025-10-14 03:34:38 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:28:31.385329+00:00"
    },
    {
      "arxiv_id": "2510.12111v1",
      "title": "Chimera: State Space Models Beyond Sequences",
      "title_zh": "Chimeraï¼šè¶…è¶Šåºåˆ—çš„çŠ¶æ€ç©ºé—´æ¨¡å‹",
      "authors": [
        "Aakash Lahoti",
        "Tanya Marwah",
        "Ratish Puduppully",
        "Albert Gu"
      ],
      "abstract": "Transformer-based deep learning methods have become the standard approach for modeling diverse data such as sequences, images, and graphs. These methods rely on self-attention, which treats data as an unordered set of elements. This ignores the neighborhood structure or graph topology of the data and requires inductive biases--such as position embeddings in sequences and images, or random walks in graphs--to incorporate topology. However, designing such task-specific biases requires significant effort and can introduce side effects that hinder generalization. We introduce Chimera, a unified model that directly incorporates data topology in a principled way, removing the need for domain-specific biases. The key idea is that state space models--which naturally do not require position embeddings--can be generalized to capture any graph topology. Our experiments show that Chimera achieves strong performance across language, vision, and graph domains, outperforming BERT on GLUE by 0.7 points, ViT on ImageNet-1k by 2.6%, and all baselines on the Long Range Graph Benchmark. We further propose algorithmic optimizations to improve Chimera's efficiency: (1) for Directed Acyclic Graphs, Chimera can be implemented as a linear-time recurrence; (2) for general graphs, a simple mathematical relaxation achieves Transformer's quadratic complexity without domain-specific heuristics. These results validate Chimera's core contribution and support the idea that data topology is a powerful inductive bias across modalities.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† Chimeraï¼Œä¸€ä¸ªæ—¨åœ¨è¶…è¶Šåºåˆ—å»ºæ¨¡çš„ç»Ÿä¸€æ¡†æ¶ï¼Œä»¥è§£å†³ Transformer æ¨¡å‹åœ¨å¤„ç†å›¾åƒå’Œå›¾æ•°æ®æ—¶å› è‡ªæ³¨æ„åŠ›æœºåˆ¶(self-attention)å¿½ç•¥æ‹“æ‰‘ç»“æ„è€Œé«˜åº¦ä¾èµ–é¢†åŸŸç‰¹å®šå½’çº³åç½®(inductive biases)çš„é—®é¢˜ã€‚è¯¥æ¨¡å‹çš„æ ¸å¿ƒæ€æƒ³æ˜¯å°†åŸæœ¬ä¸éœ€è¦ä½ç½®åµŒå…¥(position embeddings)çš„çŠ¶æ€ç©ºé—´æ¨¡å‹(State Space Models)è¿›è¡Œæ¨å¹¿ï¼Œä½¿å…¶èƒ½å¤Ÿä»¥åŸåˆ™æ€§çš„æ–¹å¼ç›´æ¥æ•è·ä»»ä½•å›¾æ‹“æ‰‘ç»“æ„ï¼Œä»è€Œæ¶ˆé™¤äº†å¯¹ç‰¹å®šä»»åŠ¡åç½®çš„éœ€æ±‚ã€‚ä¸ºäº†æé«˜è®¡ç®—æ•ˆç‡ï¼Œç ”ç©¶è€…ä¸ºæœ‰å‘æ— ç¯å›¾(Directed Acyclic Graphs)å®ç°äº†çº¿æ€§æ—¶é—´é€’å½’ï¼Œå¹¶é’ˆå¯¹é€šç”¨å›¾ç»“æ„æå‡ºäº†ä¸€ç§æ•°å­¦æ¾å¼›æ–¹æ¡ˆï¼Œä½¿å…¶åœ¨ä¸ä½¿ç”¨å¯å‘å¼æ–¹æ³•çš„æƒ…å†µä¸‹è¾¾åˆ°ä¸ Transformer ç›¸å½“çš„äºŒæ¬¡å¤æ‚åº¦ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒChimera åœ¨è¯­è¨€ã€è§†è§‰å’Œå›¾é¢†åŸŸå‡è¡¨ç°å¼ºåŠ²ï¼Œåœ¨ GLUE åŸºå‡†ä¸Šè¶…è¶Šäº† BERT 0.7 åˆ†ï¼Œåœ¨ ImageNet-1k ä¸Šé¢†å…ˆ ViT 2.6%ï¼Œå¹¶åœ¨ Long Range Graph Benchmark ä¸Šä¼˜äºæ‰€æœ‰åŸºå‡†æ¨¡å‹ã€‚è¿™äº›ç»“æœéªŒè¯äº†æ•°æ®æ‹“æ‰‘ä½œä¸ºè·¨æ¨¡æ€å½’çº³åç½®çš„æœ‰æ•ˆæ€§ï¼Œè¯æ˜äº† Chimera åœ¨å¤„ç†å¤šæ¨¡æ€æ•°æ®æ–¹é¢çš„å“è¶Šæ³›åŒ–èƒ½åŠ›ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Published in TMLR (October 2025); 22 Pages, 6 Figures, 11 Tables",
      "pdf_url": "https://arxiv.org/pdf/2510.12111v1",
      "published_date": "2025-10-14 03:27:57 UTC",
      "updated_date": "2025-10-14 03:27:57 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:28:35.622132+00:00"
    },
    {
      "arxiv_id": "2510.12110v1",
      "title": "Deep Associations, High Creativity: A Simple yet Effective Metric for Evaluating Large Language Models",
      "title_zh": "æ·±å±‚è”æƒ³ï¼Œé«˜åˆ›é€ åŠ›ï¼šä¸€ç§ç®€å•ä¸”æœ‰æ•ˆçš„å¤§è¯­è¨€æ¨¡å‹è¯„ä¼°æŒ‡æ ‡",
      "authors": [
        "Ziliang Qiu",
        "Renfen Hu"
      ],
      "abstract": "The evaluation of LLMs' creativity represents a crucial research domain, though challenges such as data contamination and costly human assessments often impede progress. Drawing inspiration from human creativity assessment, we propose PACE, asking LLMs to generate Parallel Association Chains to Evaluate their creativity. PACE minimizes the risk of data contamination and offers a straightforward, highly efficient evaluation, as evidenced by its strong correlation with Chatbot Arena Creative Writing rankings (Spearman's $Ï= 0.739$, $p < 0.001$) across various proprietary and open-source models. A comparative analysis of associative creativity between LLMs and humans reveals that while high-performing LLMs achieve scores comparable to average human performance, professional humans consistently outperform LLMs. Furthermore, linguistic analysis reveals that both humans and LLMs exhibit a trend of decreasing concreteness in their associations, and humans demonstrating a greater diversity of associative patterns.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†PACEï¼ˆParallel Association Chains to Evaluateï¼‰ï¼Œè¿™æ˜¯ä¸€ç§å—äººç±»åˆ›é€ åŠ›è¯„ä¼°å¯å‘çš„ç®€å•ä¸”é«˜æ•ˆçš„æŒ‡æ ‡ï¼Œæ—¨åœ¨é€šè¿‡è®©å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ç”Ÿæˆå¹³è¡Œå…³è”é“¾æ¥è¯„ä¼°å…¶åˆ›é€ åŠ›ã€‚PACEèƒ½æœ‰æ•ˆé™ä½æ•°æ®æ±¡æŸ“é£é™©ï¼Œå¹¶æä¾›é«˜åº¦è‡ªåŠ¨åŒ–çš„è¯„ä¼°æµç¨‹ï¼Œå…¶è¯„ä¼°ç»“æœä¸Chatbot Arenaåˆ›æ„å†™ä½œæ’åå…·æœ‰æå¼ºçš„ç›¸å…³æ€§ï¼ˆSpearmanâ€™s $\\rho = 0.739$ï¼‰ã€‚é€šè¿‡å¯¹æ¯”äººç±»ä¸LLMsçš„å…³è”åˆ›é€ åŠ›ï¼Œç ”ç©¶å‘ç°é«˜æ€§èƒ½LLMsçš„å¾—åˆ†è™½ä¸å¹³å‡æ°´å¹³çš„äººç±»ç›¸å½“ï¼Œä½†ä¸“ä¸šäººå£«çš„è¡¨ç°ä»å§‹ç»ˆä¼˜äºLLMsã€‚è¯­è¨€å­¦åˆ†æè¿›ä¸€æ­¥æ­ç¤ºï¼Œäººç±»å’ŒLLMsåœ¨å…³è”è¿‡ç¨‹ä¸­å‡å‘ˆç°å‡ºå…·ä½“æ€§ï¼ˆconcretenessï¼‰ä¸‹é™çš„è¶‹åŠ¿ï¼Œä½†äººç±»åœ¨å…³è”æ¨¡å¼ä¸Šå±•ç°å‡ºäº†æ¯”æ¨¡å‹æ›´é«˜çš„å¤šæ ·æ€§ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "14 pages",
      "pdf_url": "https://arxiv.org/pdf/2510.12110v1",
      "published_date": "2025-10-14 03:26:28 UTC",
      "updated_date": "2025-10-14 03:26:28 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:28:38.881504+00:00"
    },
    {
      "arxiv_id": "2510.15992v1",
      "title": "Stratos: An End-to-End Distillation Pipeline for Customized LLMs under Distributed Cloud Environments",
      "title_zh": "Stratosï¼šé¢å‘åˆ†å¸ƒå¼äº‘ç¯å¢ƒå®šåˆ¶åŒ–å¤§è¯­è¨€æ¨¡å‹çš„ç«¯åˆ°ç«¯è’¸é¦æµæ°´çº¿",
      "authors": [
        "Ziming Dai",
        "Tuo Zhang",
        "Fei Gao",
        "Xingyi Cai",
        "Xiaofei Wang",
        "Cheng Zhang",
        "Wenyu Wang",
        "Chengjie Zang"
      ],
      "abstract": "The growing industrial demand for customized and cost-efficient large language models (LLMs) is fueled by the rise of vertical, domain-specific tasks and the need to optimize performance under constraints such as latency and budget. Knowledge distillation, as an efficient model compression and transfer technique, offers a feasible solution. However, existing distillation frameworks often require manual intervention and struggle to meet such complex user-defined distillation requirements. To bridge this gap, we propose Stratos, an end-to-end LLM distillation pipeline that automates server and model selection, knowledge distillation, and deployment in distributed cloud environments. Given user-defined constraints on model performance and system budget, Stratos automatically selects Pareto-optimal servers, dynamically matches teacher-student pairs, and adapts distillation strategies based on task complexity to optimize cloud hosting. Experiments show that Stratos produces a student model that achieves four times the accuracy of its GPT-4o teacher baseline on a rare, domain-specific Mahjong reasoning task with reverse synthetic data and knowledge injection. Moreover, it achieves reduced latency and cost without compromising accuracy. These results highlight its promise for vertical-domain LLM deployment.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†Stratosï¼Œè¿™æ˜¯ä¸€ä¸ªé¢å‘åˆ†å¸ƒå¼äº‘ç¯å¢ƒçš„ç«¯åˆ°ç«¯å¤§è¯­è¨€æ¨¡å‹(LLMs)è’¸é¦æµæ°´çº¿ï¼Œæ—¨åœ¨æ»¡è¶³å‚ç›´é¢†åŸŸå¯¹å®šåˆ¶åŒ–ã€é«˜æ€§ä»·æ¯”æ¨¡å‹çš„éœ€æ±‚ã€‚è¯¥æ¡†æ¶å®ç°äº†æœåŠ¡å™¨å’Œæ¨¡å‹é€‰æ‹©ã€çŸ¥è¯†è’¸é¦(Knowledge Distillation)ä»¥åŠéƒ¨ç½²æµç¨‹çš„è‡ªåŠ¨åŒ–ï¼Œè§£å†³äº†ç°æœ‰æ–¹æ¡ˆéœ€äººå·¥å¹²é¢„ä¸”éš¾ä»¥å¹³è¡¡å¤æ‚çº¦æŸçš„é—®é¢˜ã€‚Stratosèƒ½å¤Ÿæ ¹æ®æ€§èƒ½å’Œé¢„ç®—è¦æ±‚è‡ªåŠ¨é€‰æ‹©å¸•ç´¯æ‰˜æœ€ä¼˜(Pareto-optimal)æœåŠ¡å™¨ï¼Œå¹¶åŠ¨æ€åŒ¹é…æ•™å¸ˆ-å­¦ç”Ÿæ¨¡å‹å¯¹ä»¥ä¼˜åŒ–äº‘æ‰˜ç®¡æ•ˆç‡ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œåœ¨ç‰¹å®šé¢†åŸŸçš„éº»å°†æ¨ç†ä»»åŠ¡ä¸­ï¼Œåˆ©ç”¨åå‘åˆæˆæ•°æ®å’ŒçŸ¥è¯†æ³¨å…¥æŠ€æœ¯ï¼Œå…¶äº§å‡ºçš„å­¦ç”Ÿæ¨¡å‹å‡†ç¡®ç‡è¾¾åˆ°äº†GPT-4oæ•™å¸ˆåŸºçº¿çš„å››å€ã€‚æ­¤å¤–ï¼Œè¯¥ç³»ç»Ÿåœ¨æœ‰æ•ˆé™ä½å»¶è¿Ÿå’Œæˆæœ¬çš„åŒæ—¶å¹¶æœªç‰ºç‰²å‡†ç¡®æ€§ï¼Œä¸ºå‚ç›´è¡Œä¸šéƒ¨ç½²é«˜æ€§èƒ½LLMæä¾›äº†é‡è¦å‚è€ƒã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.15992v1",
      "published_date": "2025-10-14 03:12:14 UTC",
      "updated_date": "2025-10-14 03:12:14 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:28:40.678884+00:00"
    },
    {
      "arxiv_id": "2510.13888v1",
      "title": "Reliable Fine-Grained Evaluation of Natural Language Math Proofs",
      "title_zh": "è‡ªç„¶è¯­è¨€æ•°å­¦è¯æ˜çš„å¯é ç»†ç²’åº¦è¯„ä¼°",
      "authors": [
        "Wenjie Ma",
        "Andrei Cojocaru",
        "Neel Kolhe",
        "Bradley Louie",
        "Robin Said Sharif",
        "Haihan Zhang",
        "Vincent Zhuang",
        "Matei Zaharia",
        "Sewon Min"
      ],
      "abstract": "Recent advances in large language models (LLMs) for mathematical reasoning have largely focused on tasks with easily verifiable final answers; however, generating and verifying natural language math proofs remains an open challenge. We identify the absence of a reliable, fine-grained evaluator for LLM-generated math proofs as a critical gap. To address this, we propose a systematic methodology for developing and validating evaluators that assign fine-grained scores on a 0-7 scale to model-generated math proofs. To enable this study, we introduce ProofBench, the first expert-annotated dataset of fine-grained proof ratings, spanning 145 problems from six major math competitions (USAMO, IMO, Putnam, etc) and 435 LLM-generated solutions from Gemini-2.5-pro, o3, and DeepSeek-R1. %with expert gradings. Using ProofBench as a testbed, we systematically explore the evaluator design space across key axes: the backbone model, input context, instructions and evaluation workflow. Our analysis delivers ProofGrader, an evaluator that combines a strong reasoning backbone LM, rich context from reference solutions and marking schemes, and a simple ensembling method; it achieves a low Mean Absolute Error (MAE) of 0.926 against expert scores, significantly outperforming naive baselines. Finally, we demonstrate its practical utility in a best-of-$n$ selection task: at $n=16$, ProofGrader achieves an average score of 4.14 (out of 7), closing 78% of the gap between a naive binary evaluator (2.48) and the human oracle (4.62), highlighting its potential to advance downstream proof generation.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§å‹è¯­è¨€æ¨¡å‹(LLMs)åœ¨è‡ªç„¶è¯­è¨€æ•°å­¦è¯æ˜(natural language math proofs)ç”Ÿæˆä¸éªŒè¯æ–¹é¢çš„æŒ‘æˆ˜ï¼ŒæŒ‡å‡ºç›®å‰ç¼ºä¹å¯é çš„ç»†ç²’åº¦(fine-grained)è¯„ä¼°å·¥å…·ã€‚ä¸ºæ­¤ï¼Œä½œè€…æå‡ºäº†ç³»ç»ŸåŒ–çš„è¯„ä¼°å™¨å¼€å‘æ–¹æ³•ï¼Œå¹¶æ¨å‡ºäº†ProofBenchï¼Œè¿™æ˜¯é¦–ä¸ªç”±ä¸“å®¶æ ‡æ³¨çš„ç»†ç²’åº¦è¯æ˜è¯„åˆ†æ•°æ®é›†ï¼Œæ¶µç›–äº†æ¥è‡ªå¤šä¸ªé‡å¤§æ•°å­¦ç«èµ›çš„é¢˜ç›®åŠä¸åŒæ¨¡å‹çš„è§£å†³æ–¹æ¡ˆã€‚åŸºäºæ­¤æ•°æ®é›†ï¼Œç ”ç©¶è€…å¼€å‘äº†ProofGraderè¯„ä¼°å™¨ï¼Œé€šè¿‡ç»“åˆæ¨ç†ä¸»å¹²æ¨¡å‹ã€å‚è€ƒç­”æ¡ˆä¸Šä¸‹æ–‡åŠè¯„åˆ†å‡†åˆ™ï¼Œåœ¨ä¸ä¸“å®¶è¯„åˆ†çš„å¯¹æ¯”ä¸­å®ç°äº†ä»…ä¸º0.926çš„ä½å¹³å‡ç»å¯¹è¯¯å·®(MAE)ã€‚å®éªŒè¯æ˜ï¼ŒProofGraderåœ¨best-of-né€‰æ‹©ä»»åŠ¡ä¸­è¡¨ç°ä¼˜å¼‚ï¼ŒæˆåŠŸå¼¥è¡¥äº†ä¼ ç»ŸäºŒå…ƒè¯„ä¼°å™¨ä¸äººç±»ä¸“å®¶æ°´å¹³ä¹‹é—´78%çš„å·®è·ï¼Œå±•ç°äº†å…¶åœ¨æ¨åŠ¨ä¸‹æ¸¸è¯æ˜ç”Ÿæˆç ”ç©¶æ–¹é¢çš„å·¨å¤§æ½œåŠ›ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "31 pages, 6 figures, 10 tables",
      "pdf_url": "https://arxiv.org/pdf/2510.13888v1",
      "published_date": "2025-10-14 02:59:07 UTC",
      "updated_date": "2025-10-14 02:59:07 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:28:43.285016+00:00"
    },
    {
      "arxiv_id": "2510.13887v3",
      "title": "Incomplete Multi-view Clustering via Hierarchical Semantic Alignment and Cooperative Completion",
      "title_zh": "åŸºäºå±‚çº§è¯­ä¹‰å¯¹é½ä¸ååŒè¡¥å…¨çš„ä¸å®Œæ•´å¤šè§†å›¾èšç±»",
      "authors": [
        "Xiaojian Ding",
        "Lin Zhao",
        "Xian Li",
        "Xiaoying Zhu"
      ],
      "abstract": "Incomplete multi-view data, where certain views are entirely missing for some samples, poses significant challenges for traditional multi-view clustering methods. Existing deep incomplete multi-view clustering approaches often rely on static fusion strategies or two-stage pipelines, leading to suboptimal fusion results and error propagation issues. To address these limitations, this paper proposes a novel incomplete multi-view clustering framework based on Hierarchical Semantic Alignment and Cooperative Completion (HSACC). HSACC achieves robust cross-view fusion through a dual-level semantic space design. In the low-level semantic space, consistency alignment is ensured by maximizing mutual information across views. In the high-level semantic space, adaptive view weights are dynamically assigned based on the distributional affinity between individual views and an initial fused representation, followed by weighted fusion to generate a unified global representation. Additionally, HSACC implicitly recovers missing views by projecting aligned latent representations into high-dimensional semantic spaces and jointly optimizes reconstruction and clustering objectives, enabling cooperative learning of completion and clustering. Experimental results demonstrate that HSACC significantly outperforms state-of-the-art methods on five benchmark datasets. Ablation studies validate the effectiveness of the hierarchical alignment and dynamic weighting mechanisms, while parameter analysis confirms the model's robustness to hyperparameter variations.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§åä¸ºHSACCçš„ä¸å®Œå…¨å¤šè§†å›¾èšç±»(Incomplete Multi-view Clustering)æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³ç°æœ‰æ·±åº¦å­¦ä¹ æ–¹æ³•ä¸­é™æ€èåˆç­–ç•¥å¯¼è‡´çš„æ¬¡ä¼˜ç»“æœå’Œé”™è¯¯ä¼ æ’­é—®é¢˜ã€‚HSACCé€šè¿‡åŒå±‚è¯­ä¹‰ç©ºé—´è®¾è®¡å®ç°é²æ£’çš„è·¨è§†å›¾èåˆï¼Œåœ¨ä½å±‚è¯­ä¹‰ç©ºé—´åˆ©ç”¨äº’ä¿¡æ¯(Mutual Information)æœ€å¤§åŒ–ç¡®ä¿è§†å›¾é—´çš„ä¸€è‡´æ€§ï¼Œåœ¨é«˜å±‚è¯­ä¹‰ç©ºé—´åˆ™åŸºäºåˆ†å¸ƒäº²å’Œæ€§åŠ¨æ€åˆ†é…æƒé‡ä»¥ç”Ÿæˆç»Ÿä¸€çš„å…¨å±€è¡¨ç¤ºã€‚æ­¤å¤–ï¼Œè¯¥æ¨¡å‹èƒ½å¤Ÿé€šè¿‡å°†å¯¹é½çš„æ½œè¡¨ç¤ºæŠ•å½±åˆ°é«˜ç»´è¯­ä¹‰ç©ºé—´æ¥éšå¼æ¢å¤ç¼ºå¤±è§†å›¾ï¼Œå¹¶é‡‡ç”¨è”åˆä¼˜åŒ–é‡æ„ä¸èšç±»ç›®æ ‡çš„æ–¹å¼å®ç°ååŒå­¦ä¹ ã€‚å®éªŒç»“æœè¯æ˜ï¼ŒHSACCåœ¨äº”ä¸ªåŸºå‡†æ•°æ®é›†ä¸Šå‡æ˜¾è‘—ä¼˜äºç°æœ‰çš„å…ˆè¿›ç®—æ³•ï¼Œä¸”æ¶ˆèå®éªŒå’Œå‚æ•°åˆ†æè¿›ä¸€æ­¥éªŒè¯äº†å…¶åˆ†å±‚å¯¹é½ä¸åŠ¨æ€åŠ æƒæœºåˆ¶çš„æœ‰æ•ˆæ€§ä¸é²æ£’æ€§ã€‚",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.LG",
        "stat.ML"
      ],
      "primary_category": "eess.IV",
      "comment": "13 pages, conference paper. Accepted to NeurIPS 2025, not yet published",
      "pdf_url": "https://arxiv.org/pdf/2510.13887v3",
      "published_date": "2025-10-14 02:58:10 UTC",
      "updated_date": "2025-10-27 03:20:35 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:28:47.267814+00:00"
    },
    {
      "arxiv_id": "2510.12091v1",
      "title": "ToPolyAgent: AI Agents for Coarse-Grained Topological Polymer Simulations",
      "title_zh": "ToPolyAgentï¼šé¢å‘ç²—ç²’åŒ–æ‹“æ‰‘èšåˆç‰©æ¨¡æ‹Ÿçš„ AI æ™ºèƒ½ä½“",
      "authors": [
        "Lijie Ding",
        "Jan-Michael Carrillo",
        "Changwoo Do"
      ],
      "abstract": "We introduce ToPolyAgent, a multi-agent AI framework for performing coarse-grained molecular dynamics (MD) simulations of topological polymers through natural language instructions. By integrating large language models (LLMs) with domain-specific computational tools, ToPolyAgent supports both interactive and autonomous simulation workflows across diverse polymer architectures, including linear, ring, brush, and star polymers, as well as dendrimers. The system consists of four LLM-powered agents: a Config Agent for generating initial polymer-solvent configurations, a Simulation Agent for executing LAMMPS-based MD simulations and conformational analyses, a Report Agent for compiling markdown reports, and a Workflow Agent for streamlined autonomous operations. Interactive mode incorporates user feedback loops for iterative refinements, while autonomous mode enables end-to-end task execution from detailed prompts. We demonstrate ToPolyAgent's versatility through case studies involving diverse polymer architectures under varying solvent condition, thermostats, and simulation lengths. Furthermore, we highlight its potential as a research assistant by directing it to investigate the effect of interaction parameters on the linear polymer conformation, and the influence of grafting density on the persistence length of the brush polymer. By coupling natural language interfaces with rigorous simulation tools, ToPolyAgent lowers barriers to complex computational workflows and advances AI-driven materials discovery in polymer science. It lays the foundation for autonomous and extensible multi-agent scientific research ecosystems.",
      "tldr_zh": "è¯¥ç ”ç©¶å¼•å…¥äº†ToPolyAgentï¼Œè¿™æ˜¯ä¸€ä¸ªæ—¨åœ¨é€šè¿‡è‡ªç„¶è¯­è¨€æŒ‡ä»¤æ‰§è¡Œæ‹“æ‰‘èšåˆç‰©(Topological Polymer)ç²—ç²’åº¦åˆ†å­åŠ¨åŠ›å­¦(Coarse-Grained Molecular Dynamics)æ¨¡æ‹Ÿçš„å¤šæ™ºèƒ½ä½“AIæ¡†æ¶ã€‚è¯¥æ¡†æ¶é›†æˆäº†å¤§è¯­è¨€æ¨¡å‹(LLMs)ä¸é¢†åŸŸç‰¹å®šçš„è®¡ç®—å·¥å…·ï¼Œæ”¯æŒåŒ…æ‹¬çº¿æ€§ã€ç¯çŠ¶ã€åˆ·çŠ¶ã€æ˜ŸçŠ¶èšåˆç‰©åŠæ ‘æçŠ¶å¤§åˆ†å­åœ¨å†…çš„å¤šç§èšåˆç‰©ç»“æ„ã€‚ToPolyAgentç”±å››ä¸ªæ ¸å¿ƒæ™ºèƒ½ä½“ç»„æˆï¼šç”¨äºç”Ÿæˆåˆå§‹é…ç½®çš„Config Agentã€åŸºäºLAMMPSæ‰§è¡Œæ¨¡æ‹Ÿä¸æ„è±¡åˆ†æçš„Simulation Agentã€ç¼–å†™æŠ¥å‘Šçš„Report Agentä»¥åŠè´Ÿè´£è‡ªåŠ¨åŒ–è¿è¡Œçš„Workflow Agentã€‚ç³»ç»Ÿæä¾›äº¤äº’æ¨¡å¼å’Œè‡ªä¸»æ¨¡å¼ï¼Œå‰è€…æ”¯æŒç”¨æˆ·åé¦ˆé©±åŠ¨çš„è¿­ä»£æ”¹è¿›ï¼Œåè€…åˆ™èƒ½æ ¹æ®è¯¦ç»†æç¤ºå®Œæˆä»å»ºæ¨¡åˆ°åˆ†æçš„ç«¯åˆ°ç«¯ä»»åŠ¡ã€‚é€šè¿‡å¯¹èšåˆç‰©äº¤äº’å‚æ•°å’Œæ¥æå¯†åº¦å½±å“ç­‰æ¡ˆä¾‹çš„æ·±å…¥è°ƒæŸ¥ï¼Œè¯¥æ¡†æ¶å±•ç¤ºäº†å…¶ä½œä¸ºç§‘ç ”åŠ©æ‰‹å¤„ç†å¤æ‚è®¡ç®—å·¥ä½œæµçš„èƒ½åŠ›ã€‚ToPolyAgenté€šè¿‡ç›´è§‚çš„è‡ªç„¶è¯­è¨€ç•Œé¢é™ä½äº†æ¨¡æ‹Ÿé—¨æ§›ï¼Œåœ¨æ¨åŠ¨AIé©±åŠ¨çš„ææ–™å‘ç°çš„åŒæ—¶ï¼Œä¹Ÿä¸ºæ„å»ºè‡ªä¸»ä¸”å¯æ‰©å±•çš„å¤šæ™ºèƒ½ä½“ç§‘å­¦ç ”ç©¶ç”Ÿæ€ç³»ç»Ÿå¥ å®šäº†åŸºç¡€ã€‚",
      "categories": [
        "cs.AI",
        "cond-mat.mtrl-sci",
        "cond-mat.soft"
      ],
      "primary_category": "cs.AI",
      "comment": "10 pages, 8 figures",
      "pdf_url": "https://arxiv.org/pdf/2510.12091v1",
      "published_date": "2025-10-14 02:54:19 UTC",
      "updated_date": "2025-10-14 02:54:19 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:28:53.071380+00:00"
    },
    {
      "arxiv_id": "2510.12088v1",
      "title": "One Life to Learn: Inferring Symbolic World Models for Stochastic Environments from Unguided Exploration",
      "title_zh": "One Life to Learnï¼šåŸºäºæ— å¼•å¯¼æ¢ç´¢çš„éšæœºç¯å¢ƒç¬¦å·ä¸–ç•Œæ¨¡å‹æ¨æ–­",
      "authors": [
        "Zaid Khan",
        "Archiki Prasad",
        "Elias Stengel-Eskin",
        "Jaemin Cho",
        "Mohit Bansal"
      ],
      "abstract": "Symbolic world modeling requires inferring and representing an environment's transitional dynamics as an executable program. Prior work has focused on largely deterministic environments with abundant interaction data, simple mechanics, and human guidance. We address a more realistic and challenging setting, learning in a complex, stochastic environment where the agent has only \"one life\" to explore a hostile environment without human guidance. We introduce OneLife, a framework that models world dynamics through conditionally-activated programmatic laws within a probabilistic programming framework. Each law operates through a precondition-effect structure, activating in relevant world states. This creates a dynamic computation graph that routes inference and optimization only through relevant laws, avoiding scaling challenges when all laws contribute to predictions about a complex, hierarchical state, and enabling the learning of stochastic dynamics even with sparse rule activation. To evaluate our approach under these demanding constraints, we introduce a new evaluation protocol that measures (a) state ranking, the ability to distinguish plausible future states from implausible ones, and (b) state fidelity, the ability to generate future states that closely resemble reality. We develop and evaluate our framework on Crafter-OO, our reimplementation of the Crafter environment that exposes a structured, object-oriented symbolic state and a pure transition function that operates on that state alone. OneLife can successfully learn key environment dynamics from minimal, unguided interaction, outperforming a strong baseline on 16 out of 23 scenarios tested. We also test OneLife's planning ability, with simulated rollouts successfully identifying superior strategies. Our work establishes a foundation for autonomously constructing programmatic world models of unknown, complex environments.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†åœ¨å¤æ‚éšæœºç¯å¢ƒ(Stochastic Environments)ä¸‹ï¼Œæ™ºèƒ½ä½“ä»…æœ‰å•æ¬¡ç”Ÿå‘½ï¼ˆ\"One Life\"ï¼‰ä¸”ç¼ºä¹äººç±»æŒ‡å¯¼çš„æƒ…å†µä¸‹å¦‚ä½•æ¨æ–­ç¬¦å·ä¸–ç•Œæ¨¡å‹(Symbolic World Models)ã€‚ä¸ºæ­¤æå‡ºçš„OneLifeæ¡†æ¶é€šè¿‡æ¦‚ç‡ç¼–ç¨‹æ¡†æ¶(Probabilistic Programming Framework)ä¸­çš„æ¡ä»¶æ¿€æ´»ç¨‹åºæ³•åˆ™æ¥å»ºæ¨¡ç¯å¢ƒåŠ¨åŠ›å­¦ï¼Œåˆ©ç”¨â€œå‰æ-æ•ˆæœâ€ç»“æ„å’ŒåŠ¨æ€è®¡ç®—å›¾(Dynamic Computation Graph)æ¥ä¼˜åŒ–æ¨ç†è¿‡ç¨‹ï¼Œä»è€Œåœ¨ç¨€ç–æ¿€æ´»çš„æƒ…å†µä¸‹å­¦ä¹ å¤æ‚çš„éšæœºåŠ¨åŠ›å­¦ã€‚ç ”ç©¶è¿˜å¼•å…¥äº†åŸºäºçŠ¶æ€æ’åº(State Ranking)å’ŒçŠ¶æ€ä¿çœŸåº¦(State Fidelity)çš„æ–°è¯„ä¼°åè®®ï¼Œä»¥è¡¡é‡æ¨¡å‹åŒºåˆ†æœªæ¥çŠ¶æ€å’Œç”Ÿæˆé«˜ä¿çœŸçŠ¶æ€çš„èƒ½åŠ›ã€‚å®éªŒåœ¨Crafter-OOç¯å¢ƒä¸Šè¿›è¡Œï¼Œç»“æœè¡¨æ˜OneLifeåœ¨23ä¸ªæµ‹è¯•åœºæ™¯ä¸­çš„16ä¸ªé‡Œä¼˜äºå¼ºåŸºçº¿æ¨¡å‹ï¼Œå¹¶èƒ½é€šè¿‡æ¨¡æ‹Ÿæ¨æ¼”æˆåŠŸè¯†åˆ«å‡ºä¼˜é€‰ç­–ç•¥ã€‚è¿™é¡¹å·¥ä½œä¸ºåœ¨æœªçŸ¥å¤æ‚ç¯å¢ƒä¸­è‡ªä¸»æ„å»ºç¨‹åºåŒ–ä¸–ç•Œæ¨¡å‹å¥ å®šäº†åŸºç¡€ã€‚",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "Project page: https://onelife-worldmodel.github.io/; 39 pages",
      "pdf_url": "https://arxiv.org/pdf/2510.12088v1",
      "published_date": "2025-10-14 02:49:32 UTC",
      "updated_date": "2025-10-14 02:49:32 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:29:08.898077+00:00"
    },
    {
      "arxiv_id": "2510.12083v1",
      "title": "An AI-Based Behavioral Health Safety Filter and Dataset for Identifying Mental Health Crises in Text-Based Conversations",
      "title_zh": "ç”¨äºè¯†åˆ«æ–‡æœ¬å¯¹è¯ä¸­å¿ƒç†å¥åº·å±æœºçš„ AI è¡Œä¸ºå¥åº·å®‰å…¨è¿‡æ»¤å™¨ä¸æ•°æ®é›†",
      "authors": [
        "Benjamin W. Nelson",
        "Celeste Wong",
        "Matthew T. Silvestrini",
        "Sooyoon Shin",
        "Alanna Robinson",
        "Jessica Lee",
        "Eric Yang",
        "John Torous",
        "Andrew Trister"
      ],
      "abstract": "Large language models often mishandle psychiatric emergencies, offering harmful or inappropriate advice and enabling destructive behaviors. This study evaluated the Verily behavioral health safety filter (VBHSF) on two datasets: the Verily Mental Health Crisis Dataset containing 1,800 simulated messages and the NVIDIA Aegis AI Content Safety Dataset subsetted to 794 mental health-related messages. The two datasets were clinician-labelled and we evaluated performance using the clinician labels. Additionally, we carried out comparative performance analyses against two open source, content moderation guardrails: OpenAI Omni Moderation Latest and NVIDIA NeMo Guardrails. The VBHSF demonstrated, well-balanced performance on the Verily Mental Health Crisis Dataset v1.0, achieving high sensitivity (0.990) and specificity (0.992) in detecting any mental health crises. It achieved an F1-score of 0.939, sensitivity ranged from 0.917-0.992, and specificity was >= 0.978 in identifying specific crisis categories. When evaluated against the NVIDIA Aegis AI Content Safety Dataset 2.0, VBHSF performance remained highly sensitive (0.982) and accuracy (0.921) with reduced specificity (0.859). When compared with the NVIDIA NeMo and OpenAI Omni Moderation Latest guardrails, the VBHSF demonstrated superior performance metrics across both datasets, achieving significantly higher sensitivity in all cases (all p < 0.001) and higher specificity relative to NVIDIA NeMo (p < 0.001), but not to OpenAI Omni Moderation Latest (p = 0.094). NVIDIA NeMo and OpenAI Omni Moderation Latest exhibited inconsistent performance across specific crisis types, with sensitivity for some categories falling below 0.10. Overall, the VBHSF demonstrated robust, generalizable performance that prioritizes sensitivity to minimize missed crises, a crucial feature for healthcare applications.",
      "tldr_zh": "è¯¥ç ”ç©¶è¯„ä¼°äº† Verily è¡Œä¸ºå¥åº·å®‰å…¨è¿‡æ»¤å™¨ (Verily behavioral health safety filter, VBHSF)ï¼Œæ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹ (Large language models) åœ¨å¤„ç†ç²¾ç¥ç§‘ç´§æ€¥æƒ…å†µæ—¶å¯èƒ½æä¾›æœ‰å®³å»ºè®®æˆ–è¯±å‘ç ´åæ€§è¡Œä¸ºçš„é—®é¢˜ã€‚ç ”ç©¶è€…åˆ©ç”¨åŒ…å« 1,800 æ¡æ¨¡æ‹Ÿä¿¡æ¯çš„ Verily Mental Health Crisis Dataset ä»¥åŠ NVIDIA Aegis AI Content Safety Dataset è¿›è¡Œæµ‹è¯•ï¼Œå¹¶ç”±ä¸´åºŠåŒ»ç”Ÿè¿›è¡Œæ ‡æ³¨ã€‚é€šè¿‡ä¸ OpenAI Omni Moderation Latest å’Œ NVIDIA NeMo Guardrails ç­‰å¼€æºå†…å®¹å®¡æ ¸å·¥å…·çš„å¯¹æ¯”åˆ†æï¼ŒVBHSF åœ¨æ£€æµ‹å¿ƒç†å¥åº·å±æœºæ–¹é¢å±•ç°å‡ºå“è¶Šçš„æ€§èƒ½ï¼Œå…¶çµæ•åº¦ (sensitivity) è¾¾åˆ° 0.990ï¼Œç‰¹å¼‚æ€§ (specificity) è¾¾åˆ° 0.992ã€‚å®éªŒè¯æ˜ VBHSF åœ¨å¤šä¸ªå±æœºç±»åˆ«ä¸­çš„çµæ•åº¦æ˜¾è‘—ä¼˜äºç°æœ‰æŠ¤æ æ¨¡å‹ï¼Œæœ‰æ•ˆè§£å†³äº†åŸºçº¿æ¨¡å‹åœ¨ç‰¹å®šå±æœºç±»å‹ä¸­è¯†åˆ«ç‡ä¸è¶³çš„é—®é¢˜ã€‚æ€»ä½“è€Œè¨€ï¼ŒVBHSF è¯æ˜äº†å…¶åœ¨åŒ»ç–—å¥åº·åº”ç”¨ä¸­çš„é²æ£’æ€§å’Œæ³›åŒ–èƒ½åŠ›ï¼Œé€šè¿‡ä¼˜å…ˆä¿éšœé«˜çµæ•åº¦æ¥æœ€å¤§ç¨‹åº¦å‡å°‘å±æœºæ¼æŠ¥ï¼Œä¸ºæ–‡æœ¬å¯¹è¯å®‰å…¨æ€§æä¾›äº†å…³é”®æŠ€æœ¯æ”¯æŒã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Main Text: 2943; Abstract: 256; Tables and Figures: 5",
      "pdf_url": "https://arxiv.org/pdf/2510.12083v1",
      "published_date": "2025-10-14 02:47:52 UTC",
      "updated_date": "2025-10-14 02:47:52 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:29:06.398103+00:00"
    },
    {
      "arxiv_id": "2510.12082v1",
      "title": "Enhancing Neural Code Representation with Additional Context",
      "title_zh": "ç»“åˆè¡¥å……ä¸Šä¸‹æ–‡å¢å¼ºç¥ç»ä»£ç è¡¨ç¤º",
      "authors": [
        "Huy Nguyen",
        "Christoph Treude",
        "Patanamon Thongtanunam"
      ],
      "abstract": "Automated program comprehension underpins many software engineering tasks, from code summarisation to clone detection. Recent deep learning models achieve strong results but typically rely on source code alone, overlooking contextual information such as version history or structural relationships. This limits their ability to capture how code evolves and operates. We conduct an empirical study on how enriching code representations with such contextual signals affects neural model performance on key comprehension tasks. Two downstream tasks, code clone detection and code summarisation, are evaluated using SeSaMe (1,679 Java methods) and CodeSearchNet (63,259 methods). Five representative models (CodeBERT, GraphCodeBERT, CodeT5, PLBART, ASTNN) are fine-tuned under code-only and context-augmented settings. Results show that context generally improves performance: version history consistently boosts clone detection (e.g., CodeT5 +15.92% F1) and summarisation (e.g., GraphCodeBERT +5.56% METEOR), while call-graph effects vary by model and task. Combining multiple contexts yields further gains (up to +21.48% macro-F1). Human evaluation on 100 Java snippets confirms that context-augmented summaries are significantly preferred for Accuracy and Content Adequacy (p <= 0.026; |delta| up to 0.55). These findings highlight the potential of contextual signals to enhance code comprehension and open new directions for optimising contextual encoding in neural SE models.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†é€šè¿‡å¼•å…¥ç‰ˆæœ¬å†å² (version history) å’Œç»“æ„å…³ç³»ç­‰é¢å¤–ä¸Šä¸‹æ–‡ä¿¡æ¯æ¥å¢å¼ºç¥ç»ä»£ç è¡¨ç¤º (neural code representation) çš„æ–¹æ³•ã€‚ç ”ç©¶äººå‘˜é’ˆå¯¹ä»£ç å…‹éš†æ£€æµ‹ (code clone detection) å’Œä»£ç æ‘˜è¦ (code summarization) ä»»åŠ¡ï¼Œåœ¨ SeSaMe å’Œ CodeSearchNet æ•°æ®é›†ä¸Šå¯¹ CodeBERTã€GraphCodeBERTã€CodeT5 ç­‰äº”ç§ä»£è¡¨æ€§æ¨¡å‹è¿›è¡Œäº† context-augmented è®¾ç½®ä¸‹çš„å®è¯ç ”ç©¶ (empirical study)ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œå¼•å…¥ä¸Šä¸‹æ–‡æ™®éèƒ½æå‡æ€§èƒ½ï¼Œå…¶ä¸­ version history æ˜¾è‘—å¢å¼ºäº†æ¨¡å‹è¡¨ç°ï¼Œè€Œ call-graph çš„æ•ˆæœåˆ™å› æ¨¡å‹å’Œä»»åŠ¡è€Œå¼‚ã€‚ç ”ç©¶å‘ç°ç»“åˆå¤šç§ context çš„å¢ç›Šæœ€é«˜å¯è¾¾ 21.48% çš„ macro-F1ï¼Œä¸”äººç±»è¯„ä¼° (Human evaluation) è¯å®ä¸Šä¸‹æ–‡å¢å¼ºåçš„æ‘˜è¦åœ¨ Accuracy å’Œ Content Adequacy æ–¹é¢æ˜¾è‘—ä¼˜äºåŸºå‡†ã€‚è¿™äº›å‘ç°å¼ºè°ƒäº†ä¸Šä¸‹æ–‡ä¿¡å·åœ¨æå‡ç¨‹åºç†è§£ (program comprehension) ä¸­çš„å…³é”®ä½œç”¨ï¼Œå¹¶ä¸ºä¼˜åŒ–è½¯ä»¶å·¥ç¨‹æ¨¡å‹ä¸­çš„ä¸Šä¸‹æ–‡ç¼–ç  (contextual encoding) æä¾›äº†æ–°è·¯å¾„ã€‚",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "34 pages, 7 figures, 11 tables",
      "pdf_url": "https://arxiv.org/pdf/2510.12082v1",
      "published_date": "2025-10-14 02:45:42 UTC",
      "updated_date": "2025-10-14 02:45:42 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:29:23.349337+00:00"
    },
    {
      "arxiv_id": "2510.12080v1",
      "title": "Evaluating the Quality of Randomness and Entropy in Tasks Supported by Large Language Models",
      "title_zh": "è¯„ä¼°å¤§è¯­è¨€æ¨¡å‹æ”¯æŒä»»åŠ¡ä¸­çš„éšæœºæ€§è´¨é‡ä¸ç†µ",
      "authors": [
        "Rabimba Karanjai",
        "Yang Lu",
        "Ranjith Chodavarapu",
        "Lei Xu",
        "Weidong Shi"
      ],
      "abstract": "The rapid advancement of large language model (LLM) technology has led to diverse applications, many of which inherently require randomness, such as stochastic decision-making, gaming, scheduling, AI agents, and cryptography-related tasks. However, the capabilities of LLMs in handling randomness, particularly in generating and utilizing random numbers effectively, remain unclear. This paper investigates the capacity of LLMs for handling tasks that involve randomness through a series of experiments. We designed a set of experiments that consider various factors that can influence an LLM's performance in tasks involving randomness, such as accessibility to external tools, types of tasks, model states (fresh vs. non-fresh), and prompting strategies. The experiments cover a range of tasks, including generating random numbers, generating random strings such as passwords, shuffling items, and evaluating the quality of randomness using entropy and the NIST randomness test-suite. Our findings reveal that while LLMs can generate outputs that exhibit some degree of randomness, their performance is inconsistent and often deviates significantly from the expected behavior. The analysis of the experimental results highlights key limitations and areas where improvement is needed for the LLMs to effectively handle tasks involving randomness",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å¤§å‹è¯­è¨€æ¨¡å‹ (LLMs) åœ¨å¤„ç†éšæœºæ€§ç›¸å…³ä»»åŠ¡ï¼ˆå¦‚éšæœºå†³ç­–ã€æ¸¸æˆã€è°ƒåº¦å’Œå¯†ç å­¦ä»»åŠ¡ï¼‰æ—¶çš„è¡¨ç°ã€‚ç ”ç©¶äººå‘˜è®¾è®¡äº†ä¸€ç³»åˆ—å®éªŒï¼Œç³»ç»Ÿè¯„ä¼°äº†å¤–éƒ¨å·¥å…·è®¿é—®ã€ä»»åŠ¡ç±»å‹ã€æ¨¡å‹çŠ¶æ€ (fresh vs. non-fresh) å’Œæç¤ºç­–ç•¥ (prompting strategies) å¯¹æ¨¡å‹éšæœºæ€§è¾“å‡ºçš„å½±å“ã€‚å®éªŒæ¶µç›–äº†ç”Ÿæˆéšæœºæ•°ã€éšæœºå­—ç¬¦ä¸²ã€æ´—ç‰Œæ“ä½œä»¥åŠåˆ©ç”¨ç†µ (entropy) å’Œ NIST éšæœºæ€§æµ‹è¯•å¥—ä»¶ (NIST randomness test-suite) è¿›è¡Œè´¨é‡è¯„ä¼°ã€‚ç»“æœè¡¨æ˜ï¼Œå°½ç®¡ LLMs èƒ½ç”Ÿæˆå…·æœ‰ä¸€å®šéšæœºæ€§çš„è¾“å‡ºï¼Œä½†å…¶è¡¨ç°å¹¶ä¸ç¨³å®šï¼Œä¸”ä¸ç†æƒ³çš„éšæœºåˆ†å¸ƒå­˜åœ¨æ˜¾è‘—åå·®ã€‚è¯¥ç ”ç©¶æŒ‡å‡ºäº† LLMs åœ¨æœ‰æ•ˆå¤„ç†éšæœºæ€§ä»»åŠ¡æ–¹é¢çš„å…³é”®å±€é™ï¼Œå¹¶å¼ºè°ƒäº†æœªæ¥æ”¹è¿› LLM éšæœºæ€§ç”Ÿæˆèƒ½åŠ›çš„å¿…è¦æ€§ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.12080v1",
      "published_date": "2025-10-14 02:43:08 UTC",
      "updated_date": "2025-10-14 02:43:08 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:29:13.480733+00:00"
    },
    {
      "arxiv_id": "2510.17852v1",
      "title": "Deploying Atmospheric and Oceanic AI Models on Chinese Hardware and Framework: Migration Strategies, Performance Optimization and Analysis",
      "title_zh": "åœ¨å›½äº§ç¡¬ä»¶ä¸æ¡†æ¶ä¸Šéƒ¨ç½²å¤§æ°”åŠæµ·æ´‹äººå·¥æ™ºèƒ½æ¨¡å‹ï¼šè¿ç§»ç­–ç•¥ã€æ€§èƒ½ä¼˜åŒ–ä¸åˆ†æ",
      "authors": [
        "Yuze Sun",
        "Wentao Luo",
        "Yanfei Xiang",
        "Jiancheng Pan",
        "Jiahao Li",
        "Quan Zhang",
        "Xiaomeng Huang"
      ],
      "abstract": "With the growing role of artificial intelligence in climate and weather research, efficient model training and inference are in high demand. Current models like FourCastNet and AI-GOMS depend heavily on GPUs, limiting hardware independence, especially for Chinese domestic hardware and frameworks. To address this issue, we present a framework for migrating large-scale atmospheric and oceanic models from PyTorch to MindSpore and optimizing for Chinese chips, and evaluating their performance against GPUs. The framework focuses on software-hardware adaptation, memory optimization, and parallelism. Furthermore, the model's performance is evaluated across multiple metrics, including training speed, inference speed, model accuracy, and energy efficiency, with comparisons against GPU-based implementations. Experimental results demonstrate that the migration and optimization process preserves the models' original accuracy while significantly reducing system dependencies and improving operational efficiency by leveraging Chinese chips as a viable alternative for scientific computing. This work provides valuable insights and practical guidance for leveraging Chinese domestic chips and frameworks in atmospheric and oceanic AI model development, offering a pathway toward greater technological independence.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹FourCastNetå’ŒAI-GOMSç­‰å¤§æ°”ä¸æµ·æ´‹AIæ¨¡å‹å¯¹GPUçš„é«˜åº¦ä¾èµ–é—®é¢˜ï¼Œæå‡ºäº†ä¸€ä¸ªå°†å¤§è§„æ¨¡æ¨¡å‹ä»PyTorchè¿ç§»è‡³MindSporeæ¡†æ¶å¹¶é’ˆå¯¹å›½äº§èŠ¯ç‰‡è¿›è¡Œæ€§èƒ½ä¼˜åŒ–çš„é€šç”¨æ¡†æ¶ã€‚è¯¥æ¡†æ¶é‡ç‚¹æ”»å…‹äº†è½¯ç¡¬ä»¶é€‚é…ã€å†…å­˜ä¼˜åŒ–ä»¥åŠå¹¶è¡ŒåŒ–å¤„ç†ç­‰å…³é”®æŠ€æœ¯ï¼Œæ—¨åœ¨æå‡å›½äº§ç¡¬ä»¶åœ¨æ°”è±¡ç§‘ç ”é¢†åŸŸçš„åº”ç”¨æ•ˆç‡ã€‚å®éªŒé€šè¿‡å¯¹æ¯”è®­ç»ƒé€Ÿåº¦ã€æ¨ç†é€Ÿåº¦ã€å‡†ç¡®ç‡åŠèƒ½æ•ˆæ¯”ç­‰æŒ‡æ ‡ï¼Œè¯å®äº†è¿ç§»åçš„æ¨¡å‹åœ¨ä¿æŒåŸå§‹ç²¾åº¦çš„æƒ…å†µä¸‹ï¼Œèƒ½å¤Ÿæ˜¾è‘—é™ä½å¯¹å¤–éƒ¨ç³»ç»Ÿçš„ä¾èµ–å¹¶æå‡è¿è¡Œæ•ˆèƒ½ã€‚è¿™ä¸€å·¥ä½œä¸ä»…è¯æ˜äº†å›½äº§èŠ¯ç‰‡ä½œä¸ºç§‘å­¦è®¡ç®—å¯è¡Œæ›¿ä»£æ–¹æ¡ˆçš„æ½œåŠ›ï¼Œä¹Ÿä¸ºå®ç°å¤§æ°”ä¸æµ·æ´‹AIé¢†åŸŸçš„æŠ€æœ¯è‡ªä¸»æä¾›äº†é‡è¦çš„å®è·µæŒ‡å¯¼ä¸è·¯å¾„ã€‚",
      "categories": [
        "cs.DC",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.DC",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.17852v1",
      "published_date": "2025-10-14 02:41:56 UTC",
      "updated_date": "2025-10-14 02:41:56 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:29:16.577577+00:00"
    },
    {
      "arxiv_id": "2510.13886v1",
      "title": "Physics-Informed autoencoder for DSC-MRI Perfusion post-processing: application to glioma grading",
      "title_zh": "ç”¨äº DSC-MRI çŒæ³¨åå¤„ç†çš„ç‰©ç†ä¿¡æ¯è‡ªç¼–ç å™¨ï¼šåœ¨èƒ¶è´¨ç˜¤åˆ†çº§ä¸­çš„åº”ç”¨",
      "authors": [
        "Pierre Fayolle",
        "Alexandre BÃ´ne",
        "NoÃ«lie Debs",
        "Mathieu Naudin",
        "Pascal Bourdon",
        "Remy Guillevin",
        "David Helbert"
      ],
      "abstract": "DSC-MRI perfusion is a medical imaging technique for diagnosing and prognosing brain tumors and strokes. Its analysis relies on mathematical deconvolution, but noise or motion artifacts in a clinical environment can disrupt this process, leading to incorrect estimate of perfusion parameters. Although deep learning approaches have shown promising results, their calibration typically rely on third-party deconvolution algorithms to generate reference outputs and are bound to reproduce their limitations.\n  To adress this problem, we propose a physics-informed autoencoder that leverages an analytical model to decode the perfusion parameters and guide the learning of the encoding network. This autoencoder is trained in a self-supervised fashion without any third-party software and its performance is evaluated on a database with glioma patients. Our method shows reliable results for glioma grading in accordance with other well-known deconvolution algorithms despite a lower computation time. It also achieved competitive performance even in the presence of high noise which is critical in a medical environment.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§ç‰©ç†ä¿¡æ¯è‡ªåŠ¨ç¼–ç å™¨(Physics-informed autoencoder)ï¼Œç”¨äºä¼˜åŒ–DSC-MRIçŒæ³¨æˆåƒçš„åå¤„ç†æµç¨‹å¹¶åº”ç”¨äºèƒ¶è´¨ç˜¤(glioma)åˆ†çº§ã€‚é’ˆå¯¹ä¼ ç»Ÿæ•°å­¦å»å·ç§¯(deconvolution)æ–¹æ³•åœ¨ä¸´åºŠä¸­æ˜“å—å™ªå£°å’Œè¿åŠ¨ä¼ªå½±å¹²æ‰°ï¼Œä»¥åŠç°æœ‰æ·±åº¦å­¦ä¹ æ¨¡å‹è¿‡åº¦ä¾èµ–ç¬¬ä¸‰æ–¹è½¯ä»¶ç”Ÿæˆå‚è€ƒè¾“å‡ºçš„å±€é™æ€§ï¼Œè¯¥æ–¹æ³•å¼•å…¥äº†ç‰©ç†åˆ†ææ¨¡å‹ä½œä¸ºè§£ç å™¨æ¥å¼•å¯¼ç¼–ç ç½‘ç»œå­¦ä¹ çŒæ³¨å‚æ•°ã€‚è¯¥æ¨¡å‹é‡‡ç”¨è‡ªç›‘ç£(self-supervised)è®­ç»ƒæ¨¡å¼ï¼Œæ— éœ€å¤–éƒ¨æ ‡æ³¨æ•°æ®å³å¯å®ç°é«˜æ€§èƒ½å‚æ•°ä¼°è®¡ã€‚åœ¨èƒ¶è´¨ç˜¤æ‚£è€…æ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨ä¿æŒåˆ†çº§å‡†ç¡®æ€§çš„åŒæ—¶æ˜¾è‘—é™ä½äº†è®¡ç®—æ—¶é—´ã€‚æ­¤å¤–ï¼Œå…¶åœ¨é«˜å™ªå£°ç¯å¢ƒä¸‹è¡¨ç°å‡ºçš„é²æ£’æ€§ä½¿å…¶åœ¨å¤æ‚çš„åŒ»ç–—æˆåƒè¯Šæ–­ä¸­å…·æœ‰æé«˜çš„ä¸´åºŠåº”ç”¨ä»·å€¼ã€‚",
      "categories": [
        "q-bio.QM",
        "cs.AI",
        "eess.IV",
        "eess.SP"
      ],
      "primary_category": "q-bio.QM",
      "comment": "5 pages, 5 figures, IEEE ISBI 2025, Houston, Tx, USA",
      "pdf_url": "https://arxiv.org/pdf/2510.13886v1",
      "published_date": "2025-10-14 02:39:55 UTC",
      "updated_date": "2025-10-14 02:39:55 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:29:23.204376+00:00"
    },
    {
      "arxiv_id": "2510.12076v1",
      "title": "BeSTAD: Behavior-Aware Spatio-Temporal Anomaly Detection for Human Mobility Data",
      "title_zh": "BeSTADï¼šé¢å‘äººç±»ç§»åŠ¨æ€§æ•°æ®çš„è¡Œä¸ºæ„ŸçŸ¥æ—¶ç©ºå¼‚å¸¸æ£€æµ‹",
      "authors": [
        "Junyi Xie",
        "Jina Kim",
        "Yao-Yi Chiang",
        "Lingyi Zhao",
        "Khurram Shafique"
      ],
      "abstract": "Traditional anomaly detection in human mobility has primarily focused on trajectory-level analysis, identifying statistical outliers or spatiotemporal inconsistencies across aggregated movement traces. However, detecting individual-level anomalies, i.e., unusual deviations in a person's mobility behavior relative to their own historical patterns, within datasets encompassing large populations remains a significant challenge. In this paper, we present BeSTAD (Behavior-aware Spatio-Temporal Anomaly Detection for Human Mobility Data), an unsupervised framework that captures individualized behavioral signatures across large populations and uncovers fine-grained anomalies by jointly modeling spatial context and temporal dynamics. BeSTAD learns semantically enriched mobility representations that integrate location meaning and temporal patterns, enabling the detection of subtle deviations in individual movement behavior. BeSTAD further employs a behavior-cluster-aware modeling mechanism that builds personalized behavioral profiles from normal activity and identifies anomalies through cross-period behavioral comparison with consistent semantic alignment. Building on prior work in mobility behavior clustering, this approach enables not only the detection of behavioral shifts and deviations from established routines but also the identification of individuals exhibiting such changes within large-scale mobility datasets. By learning individual behaviors directly from unlabeled data, BeSTAD advances anomaly detection toward personalized and interpretable mobility analysis.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†BeSTADï¼Œä¸€ç§é’ˆå¯¹äººç±»æµåŠ¨æ•°æ®çš„è¡Œä¸ºæ„ŸçŸ¥æ—¶ç©ºå¼‚å¸¸æ£€æµ‹(Behavior-aware Spatio-Temporal Anomaly Detection)æ— ç›‘ç£æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³åœ¨å¤§è§„æ¨¡äººç¾¤ä¸­æ£€æµ‹ä¸ªä½“å±‚é¢è¡Œä¸ºå¼‚å¸¸çš„æŒ‘æˆ˜ã€‚è¯¥æ¡†æ¶é€šè¿‡è”åˆå»ºæ¨¡ç©ºé—´ä¸Šä¸‹æ–‡å’Œæ—¶é—´åŠ¨æ€ï¼Œå­¦ä¹ è¯­ä¹‰ä¸°å¯Œçš„æµåŠ¨æ€§è¡¨å¾ï¼Œä»è€Œæ•æ‰ç»†ç²’åº¦çš„ä¸ªä½“è¡Œä¸ºç‰¹å¾å¹¶è¯†åˆ«å¾®å¦™çš„è¡Œä¸ºåç¦»ã€‚BeSTADå¼•å…¥äº†è¡Œä¸ºèšç±»æ„ŸçŸ¥(behavior-cluster-aware)å»ºæ¨¡æœºåˆ¶ï¼Œåˆ©ç”¨æ­£å¸¸æ´»åŠ¨æ„å»ºä¸ªæ€§åŒ–è¡Œä¸ºæ¡£æ¡ˆï¼Œå¹¶é€šè¿‡å…·æœ‰ä¸€è‡´è¯­ä¹‰å¯¹é½çš„è·¨å‘¨æœŸè¡Œä¸ºæ¯”è¾ƒæ¥è¯†åˆ«å¼‚å¸¸ã€‚è¿™ç§æ–¹æ³•ä¸ä»…èƒ½å¤Ÿæ£€æµ‹è¡Œä¸ºæ¨¡å¼çš„è½¬å˜åŠå¯¹æ—¢å®šå¸¸è§„çš„åç¦»ï¼Œè¿˜èƒ½åœ¨å¤§è§„æ¨¡æµåŠ¨æ€§æ•°æ®é›†ä¸­å‡†ç¡®å®šä½å‘ç”Ÿæ­¤ç±»å˜åŒ–çš„ä¸ªä½“ã€‚é€šè¿‡ç›´æ¥ä»æ— æ ‡æ³¨æ•°æ®ä¸­å­¦ä¹ ï¼ŒBeSTADæ¨åŠ¨äº†äººç±»æµåŠ¨æ€§åˆ†æå‘æ›´åŠ ä¸ªæ€§åŒ–å’Œå¯è§£é‡Šçš„å¼‚å¸¸æ£€æµ‹æ–¹å‘å‘å±•ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "accepted by The 2nd ACM SIGSPATIAL International Workshop on Geospatial Anomaly Detection",
      "pdf_url": "https://arxiv.org/pdf/2510.12076v1",
      "published_date": "2025-10-14 02:33:06 UTC",
      "updated_date": "2025-10-14 02:33:06 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:29:22.058217+00:00"
    },
    {
      "arxiv_id": "2510.12075v1",
      "title": "A Review on Domain Adaption and Generative Adversarial Networks(GANs)",
      "title_zh": "é¢†åŸŸè‡ªé€‚åº”ä¸ç”Ÿæˆå¯¹æŠ—ç½‘ç»œï¼ˆGANsï¼‰ç»¼è¿°",
      "authors": [
        "Aashish Dhawan",
        "Divyanshu Mudgal"
      ],
      "abstract": "The major challenge in today's computer vision scenario is the availability of good quality labeled data. In a field of study like image classification, where data is of utmost importance, we need to find more reliable methods which can overcome the scarcity of data to produce results comparable to previous benchmark results. In most cases, obtaining labeled data is very difficult because of the high cost of human labor and in some cases impossible. The purpose of this paper is to discuss Domain Adaptation and various methods to implement it. The main idea is to use a model trained on a particular dataset to predict on data from a different domain of the same kind, for example - a model trained on paintings of airplanes predicting on real images of airplanes",
      "tldr_zh": "æœ¬æ–‡ç»¼è¿°äº† Domain Adaptation (åŸŸé€‚åº”) ä»¥åŠ Generative Adversarial Networks (GANs) åœ¨è®¡ç®—æœºè§†è§‰é¢†åŸŸçš„åº”ç”¨ï¼Œæ—¨åœ¨è§£å†³é«˜è´¨é‡æ ‡æ³¨æ•°æ®åŒ®ä¹çš„æ ¸å¿ƒæŒ‘æˆ˜ã€‚åœ¨å›¾åƒåˆ†ç±»ç­‰é«˜åº¦ä¾èµ–æ•°æ®çš„ç ”ç©¶ä¸­ï¼Œé’ˆå¯¹äººå·¥æ ‡æ³¨æˆæœ¬é«˜æ˜‚ç”šè‡³æ— æ³•è·å–çš„é—®é¢˜ï¼Œè¯¥ç ”ç©¶æ¢è®¨äº†å¦‚ä½•åˆ©ç”¨å¯é çš„ç®—æ³•æ‰‹æ®µå…‹æœæ•°æ®ç¨€ç¼ºã€‚è®ºæ–‡è¯¦ç»†è®¨è®ºäº† Domain Adaptation çš„åŸºæœ¬ç†å¿µåŠå…¶å¤šç§å®ç°æ–¹æ³•ï¼Œé‡ç‚¹åœ¨äºå°†ä¸€ä¸ªåœ¨ç‰¹å®šæ•°æ®é›†ä¸Šè®­ç»ƒå®Œæˆçš„æ¨¡å‹ï¼Œè¿ç§»å¹¶åº”ç”¨äºç›¸åŒç±»å‹ä½†ä¸åŒé¢†åŸŸçš„æ•°æ®é¢„æµ‹ã€‚é€šè¿‡å¯¹è·¨åŸŸé¢„æµ‹æœºåˆ¶çš„ç³»ç»Ÿæ€§æ¢³ç†ï¼Œæœ¬æ–‡å±•ç¤ºäº†å¦‚ä½•å®ç°åœ¨è¯¸å¦‚ä»é£æœºç»˜ç”»æ¨¡å‹é¢„æµ‹çœŸå®é£æœºå›¾åƒç­‰åœºæ™¯ä¸‹çš„çŸ¥è¯†è¿ç§»ï¼Œä¸ºæå‡å¤æ‚ç¯å¢ƒä¸‹çš„æ¨¡å‹é²æ£’æ€§æä¾›äº†ç†è®ºæŒ‡å¯¼ä¸æŠ€æœ¯å‚è€ƒã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.12075v1",
      "published_date": "2025-10-14 02:32:10 UTC",
      "updated_date": "2025-10-14 02:32:10 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:29:24.683832+00:00"
    },
    {
      "arxiv_id": "2510.12072v1",
      "title": "EmboMatrix: A Scalable Training-Ground for Embodied Decision-Making",
      "title_zh": "EmboMatrixï¼šé¢å‘å…·èº«å†³ç­–çš„å¯æ‰©å±•è®­ç»ƒåœº",
      "authors": [
        "Zixing Lei",
        "Sheng Yin",
        "Yichen Xiong",
        "Yuanzhuo Ding",
        "Wenhao Huang",
        "Yuxi Wei",
        "Qingyao Xu",
        "Yiming Li",
        "Weixin Li",
        "Yunhong Wang",
        "Siheng Chen"
      ],
      "abstract": "Embodied decision-making enables agents to translate high-level goals into executable actions through continuous interactions within the physical world, forming a cornerstone of general-purpose embodied intelligence. Large language models (LLMs), with their general decision-making capabilities, offer a promising path to realize this potential; however, LLMs trained solely on language lack exposure to physical environments, limiting their true embodied understanding. To bridge this gap, we propose the concept of a training ground: a comprehensive infrastructure that provides task and scene simulation, embodied interaction, and feedback signals, offering a one-stop solution for LLM acquire genuine embodied decision-making skills. In this work, we present EmboMatrix, the first training ground of its kind, providing massive and diverse tasks with efficient simulation and precise rewards. EmboMatrix incorporates a series of novel techniques: a multi-agent data engine for large-scale task and scene generation, a distributed heterogeneous-hardware system for scalable simulation, and a multi-level reward architecture for precise supervision. Leveraging EmboMatrix, we cultivate EmboBrain, an LLM whose embodied decision-making abilities emerge from extensive embodied interactions. Experiments show that EmboBrain-7B surpasses the 671B DeepSeek-R1 baseline by 9.5\\% on two challenging embodied decision-making benchmarks, demonstrating the power of interactive, environment-grounded learning for building truly intelligent embodied agents.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†EmboMatrixï¼Œè¿™æ˜¯é¦–ä¸ªæ—¨åœ¨é€šè¿‡å¤§è§„æ¨¡ç‰©ç†ç¯å¢ƒäº¤äº’æå‡å¤§è¯­è¨€æ¨¡å‹(LLMs)å…·èº«å†³ç­–èƒ½åŠ›çš„è®­ç»ƒåœºã€‚ä¸ºå¼¥åˆè¯­è¨€æ¨¡å‹ä¸ç‰©ç†ä¸–ç•Œä¹‹é—´çš„ç†è§£å·®è·ï¼Œè¯¥æ¡†æ¶æ•´åˆäº†ç”¨äºè‡ªåŠ¨åŒ–ä»»åŠ¡ä¸åœºæ™¯ç”Ÿæˆçš„å¤šæ™ºèƒ½ä½“æ•°æ®å¼•æ“ï¼Œå¹¶åˆ©ç”¨åˆ†å¸ƒå¼å¼‚æ„ç¡¬ä»¶ç³»ç»Ÿå®ç°å¯æ‰©å±•çš„æ¨¡æ‹Ÿè¿è¡Œã€‚æ­¤å¤–ï¼ŒEmboMatrix å¼•å…¥äº†å¤šå±‚çº§å¥–åŠ±æ¶æ„ä»¥å®ç°ç²¾ç¡®ç›‘ç£ï¼Œå¹¶æ®æ­¤åŸ¹å…»å‡ºäº†åœ¨å…·èº«äº¤äº’ä¸­æ¶Œç°å‡ºå†³ç­–èƒ½åŠ›çš„ EmboBrain æ¨¡å‹ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œå‚æ•°é‡ä»…ä¸º 7B çš„ EmboBrain åœ¨ä¸¤é¡¹æŒ‘æˆ˜æ€§åŸºå‡†æµ‹è¯•ä¸­æ¯” 671B çš„ DeepSeek-R1 åŸºçº¿æ¨¡å‹å‡†ç¡®ç‡é«˜å‡º 9.5%ã€‚è¯¥å·¥ä½œæœ‰åŠ›è¯æ˜äº†äº¤äº’å¼ã€åŸºäºç¯å¢ƒçš„å­¦ä¹ å¯¹äºæ„å»ºçœŸæ­£æ™ºèƒ½çš„å…·èº«æ™ºèƒ½ä½“å…·æœ‰è‡³å…³é‡è¦çš„æ„ä¹‰ã€‚",
      "categories": [
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.AI",
      "comment": "10 pages 8 figures",
      "pdf_url": "https://arxiv.org/pdf/2510.12072v1",
      "published_date": "2025-10-14 02:26:52 UTC",
      "updated_date": "2025-10-14 02:26:52 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:29:28.662319+00:00"
    },
    {
      "arxiv_id": "2510.12070v1",
      "title": "MEASURE: Multi-scale Minimal Sufficient Representation Learning for Domain Generalization in Sleep Staging",
      "title_zh": "MEASUREï¼šé¢å‘ç¡çœ åˆ†æœŸé¢†åŸŸæ³›åŒ–çš„å¤šå°ºåº¦æœ€å°å……åˆ†è¡¨ç¤ºå­¦ä¹ ",
      "authors": [
        "Sangmin Jo",
        "Jee Seok Yoon",
        "Wootaek Jeong",
        "Kwanseok Oh",
        "Heung-Il Suk"
      ],
      "abstract": "Deep learning-based automatic sleep staging has significantly advanced in performance and plays a crucial role in the diagnosis of sleep disorders. However, those models often struggle to generalize on unseen subjects due to variability in physiological signals, resulting in degraded performance in out-of-distribution scenarios. To address this issue, domain generalization approaches have recently been studied to ensure generalized performance on unseen domains during training. Among those techniques, contrastive learning has proven its validity in learning domain-invariant features by aligning samples of the same class across different domains. Despite its potential, many existing methods are insufficient to extract adequately domain-invariant representations, as they do not explicitly address domain characteristics embedded within the unshared information across samples. In this paper, we posit that mitigating such domain-relevant attributes-referred to as excess domain-relevant information-is key to bridging the domain gap. However, the direct strategy to mitigate the domain-relevant attributes often overfits features at the high-level information, limiting their ability to leverage the diverse temporal and spectral information encoded in the multiple feature levels. To address these limitations, we propose a novel MEASURE (Multi-scalE minimAl SUfficient Representation lEarning) framework, which effectively reduces domain-relevant information while preserving essential temporal and spectral features for sleep stage classification. In our exhaustive experiments on publicly available sleep staging benchmark datasets, SleepEDF-20 and MASS, our proposed method consistently outperformed state-of-the-art methods. Our code is available at : https://github.com/ku-milab/Measure",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹åŸºäºæ·±åº¦å­¦ä¹ çš„è‡ªåŠ¨ç¡çœ åˆ†æœŸ (Sleep Staging) åœ¨é¢å¯¹æœªè§å—è¯•è€…æ—¶ï¼Œå› ç”Ÿç†ä¿¡å·å˜å¼‚å¯¼è‡´é¢†åŸŸæ³›åŒ– (Domain Generalization) æ€§èƒ½ä¸‹é™çš„é—®é¢˜ï¼Œæå‡ºäº† MEASURE (Multi-scalE minimAl SUfficient Representation lEarning) æ¡†æ¶ã€‚ä½œè€…æŒ‡å‡ºï¼Œç¼©å°é¢†åŸŸå·®è·çš„å…³é”®åœ¨äºå‡è½»å†—ä½™çš„é¢†åŸŸç›¸å…³ä¿¡æ¯ (excess domain-relevant information)ï¼Œè€Œç°æœ‰æ–¹æ³•å¾€å¾€å› è¿‡åº¦å…³æ³¨é«˜å±‚ä¿¡æ¯è€Œé™åˆ¶äº†å¯¹å¤šå°ºåº¦æ—¶é¢‘ç‰¹å¾çš„åˆ©ç”¨ã€‚MEASURE æ¡†æ¶é€šè¿‡åœ¨å‡å°‘é¢†åŸŸå¹²æ‰°çš„åŒæ—¶ï¼Œæœ‰æ•ˆä¿ç•™äº†ç”¨äºç¡çœ é˜¶æ®µåˆ†ç±»çš„å…³é”®æ—¶åŸŸå’Œé¢‘åŸŸç‰¹å¾ï¼Œå®ç°äº†æ›´å…·é²æ£’æ€§çš„ç‰¹å¾æå–ã€‚åœ¨ SleepEDF-20 å’Œ MASS ç­‰å…¬å¼€åŸºå‡†æ•°æ®é›†ä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨æ€§èƒ½ä¸Šä¸€è‡´ä¼˜äºç°æœ‰çš„æœ€å…ˆè¿›æŠ€æœ¯ã€‚è¿™é¡¹å·¥ä½œä¸ºæé«˜è‡ªåŠ¨ç¡çœ ç›‘æµ‹ç³»ç»Ÿåœ¨å®é™…ä¸´åºŠåœºæ™¯ä¸­çš„æ³›åŒ–èƒ½åŠ›æä¾›äº†æœ‰æ•ˆçš„è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "12 page, 7 figures, uses IEEE.sty",
      "pdf_url": "https://arxiv.org/pdf/2510.12070v1",
      "published_date": "2025-10-14 02:20:50 UTC",
      "updated_date": "2025-10-14 02:20:50 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:29:36.061013+00:00"
    },
    {
      "arxiv_id": "2510.12067v1",
      "title": "HiCoTraj:Zero-Shot Demographic Reasoning via Hierarchical Chain-of-Thought Prompting from Trajectory",
      "title_zh": "HiCoTrajï¼šåŸºäºè½¨è¿¹åˆ†å±‚é“¾å¼æ€ç»´æç¤ºçš„é›¶æ ·æœ¬äººå£ç»Ÿè®¡æ¨ç†",
      "authors": [
        "Junyi Xie",
        "Yuankun Jiao",
        "Jina Kim",
        "Yao-Yi Chiang",
        "Lingyi Zhao",
        "Khurram Shafique"
      ],
      "abstract": "Inferring demographic attributes such as age, sex, or income level from human mobility patterns enables critical applications such as targeted public health interventions, equitable urban planning, and personalized transportation services. Existing mobility-based demographic inference studies heavily rely on large-scale trajectory data with demographic labels, leading to limited interpretability and poor generalizability across different datasets and user groups. We propose HiCoTraj (Zero-Shot Demographic Reasoning via Hierarchical Chain-of-Thought Prompting from Trajectory), a framework that leverages LLMs' zero-shot learning and semantic understanding capabilities to perform demographic inference without labeled training data. HiCoTraj transforms trajectories into semantically rich, natural language representations by creating detailed activity chronicles and multi-scale visiting summaries. Then HiCoTraj uses a novel hierarchical chain of thought reasoning to systematically guide LLMs through three cognitive stages: factual feature extraction, behavioral pattern analysis, and demographic inference with structured output. This approach addresses the scarcity challenge of labeled demographic data while providing transparent reasoning chains. Experimental evaluation on real-world trajectory data demonstrates that HiCoTraj achieves competitive performance across multiple demographic attributes in zero-shot scenarios.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†HiCoTrajæ¡†æ¶ï¼Œæ—¨åœ¨åˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„é›¶æ ·æœ¬å­¦ä¹ ï¼ˆZero-Shot Learningï¼‰å’Œè¯­ä¹‰ç†è§£èƒ½åŠ›ï¼Œè§£å†³ç§»åŠ¨è½¨è¿¹äººå£ç»Ÿè®¡å±æ€§æ¨æ–­ä¸­å¯¹å¤§è§„æ¨¡æ ‡æ³¨æ•°æ®çš„è¿‡åº¦ä¾èµ–åŠæ¨¡å‹å¯è§£é‡Šæ€§ä¸è¶³çš„é—®é¢˜ã€‚è¯¥æ¡†æ¶é¦–å…ˆå°†åŸå§‹è½¨è¿¹è½¬åŒ–ä¸ºè¯­ä¹‰ä¸°å¯Œçš„è‡ªç„¶è¯­è¨€è¡¨ç¤ºï¼Œé€šè¿‡æ„å»ºè¯¦ç»†çš„æ´»åŠ¨ç¼–å¹´å²ï¼ˆactivity chroniclesï¼‰å’Œå¤šå°ºåº¦è®¿é—®æ‘˜è¦ï¼ˆmulti-scale visiting summariesï¼‰æ¥æ•æ‰ç”¨æˆ·è¡Œä¸ºç‰¹å¾ã€‚æ¥ç€ï¼ŒHiCoTrajå¼•å…¥äº†ä¸€ç§æ–°é¢–çš„å±‚æ¬¡åŒ–é“¾å¼æ€ç»´æ¨ç†ï¼ˆHierarchical Chain-of-Thought Promptingï¼‰ï¼Œå¼•å¯¼æ¨¡å‹ç³»ç»Ÿåœ°æ‰§è¡Œäº‹å®ç‰¹å¾æå–ã€è¡Œä¸ºæ¨¡å¼åˆ†æå’Œäººå£å±æ€§æ¨æ–­ã€‚è¿™ä¸€æ–¹æ³•åœ¨æ— éœ€æ ‡æ³¨è®­ç»ƒæ•°æ®çš„æƒ…å†µä¸‹ï¼Œä¸ä»…æœ‰æ•ˆåº”å¯¹äº†æ ‡æ³¨æ•°æ®çš„ç¨€ç¼ºæ€§æŒ‘æˆ˜ï¼Œè¿˜ä¸ºæ¨æ–­ç»“æœæä¾›äº†é€æ˜ä¸”å¯è§£é‡Šçš„æ¨ç†é€»è¾‘ã€‚åœ¨çœŸå®ä¸–ç•Œè½¨è¿¹æ•°æ®ä¸Šçš„å®éªŒè¯„ä¼°è¡¨æ˜ï¼ŒHiCoTrajåœ¨é›¶æ ·æœ¬åœºæ™¯ä¸‹å¯¹å¹´é¾„ã€æ€§åˆ«åŠæ”¶å…¥æ°´å¹³ç­‰å¤šç§äººå£ç»Ÿè®¡å±æ€§çš„æ¨æ–­å‡è¾¾åˆ°äº†å…·æœ‰ç«äº‰åŠ›çš„æ€§èƒ½æ°´å¹³ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "accepted by The 1st ACM SIGSPATIAL International Workshop on Generative and Agentic AI for Multi-Modality Space-Time Intelligence",
      "pdf_url": "https://arxiv.org/pdf/2510.12067v1",
      "published_date": "2025-10-14 02:18:29 UTC",
      "updated_date": "2025-10-14 02:18:29 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:29:49.366124+00:00"
    },
    {
      "arxiv_id": "2510.12066v1",
      "title": "AI Agents as Universal Task Solvers",
      "title_zh": "AI æ™ºèƒ½ä½“ä½œä¸ºé€šç”¨ä»»åŠ¡æ±‚è§£å™¨",
      "authors": [
        "Alessandro Achille",
        "Stefano Soatto"
      ],
      "abstract": "AI reasoning agents are already able to solve a variety of tasks by deploying tools, simulating outcomes of multiple hypotheses and reflecting on them. In doing so, they perform computation, although not in the classical sense -- there is no program being executed. Still, if they perform computation, can AI agents be universal? Can chain-of-thought reasoning solve any computable task? How does an AI Agent learn to reason? Is it a matter of model size? Or training dataset size?\n  In this work, we reinterpret the role of learning in the context of AI Agents, viewing them as compute-capable stochastic dynamical systems, and highlight the role of time in a foundational principle for learning to reason. In doing so, we propose a shift from classical inductive learning to transductive learning -- where the objective is not to approximate the distribution of past data, but to capture their algorithmic structure to reduce the time needed to find solutions to new tasks.\n  Transductive learning suggests that, counter to Shannon's theory, a key role of information in learning is about reduction of time rather than reconstruction error. In particular, we show that the optimal speed-up that a universal solver can achieve using past data is tightly related to their algorithmic information. Using this, we show a theoretical derivation for the observed power-law scaling of inference time versus training time. We then show that scaling model size can lead to behaviors that, while improving accuracy on benchmarks, fail any reasonable test of intelligence, let alone super-intelligence: In the limit of infinite space and time, large models can behave as savants, able to brute-force through any task without any insight. Instead, we argue that the key quantity to optimize when scaling reasoning models is time, whose critical role in learning has so far only been indirectly considered.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†AIæ¨ç†æ™ºèƒ½ä½“ä½œä¸ºé€šç”¨ä»»åŠ¡æ±‚è§£å™¨çš„æ½œèƒ½ï¼Œåˆ†æäº†é“¾å¼æ€ç»´(chain-of-thought)æ¨ç†åœ¨è§£å†³å¯è®¡ç®—ä»»åŠ¡ä¸­çš„å­¦ä¹ æœºåˆ¶ã€‚ä½œè€…æå‡ºå°†AIæ™ºèƒ½ä½“è§†ä¸ºå…·å¤‡è®¡ç®—èƒ½åŠ›çš„éšæœºåŠ¨åŠ›ç³»ç»Ÿ(stochastic dynamical systems)ï¼Œå¹¶å»ºè®®å°†å­¦ä¹ èŒƒå¼ä»ä¼ ç»Ÿçš„å½’çº³å­¦ä¹ (inductive learning)è½¬å‘è½¬å¯¼å­¦ä¹ (transductive learning)ã€‚åœ¨æ­¤æ¡†æ¶ä¸‹ï¼Œå­¦ä¹ çš„ç›®æ ‡æ˜¯æ•æ‰ç®—æ³•ç»“æ„(algorithmic structure)ä»¥ç¼©çŸ­è§£å†³æ–°ä»»åŠ¡æ‰€éœ€çš„æ—¶é—´ï¼Œè€Œéå•çº¯é€¼è¿‘å†å²æ•°æ®åˆ†å¸ƒã€‚ç ”ç©¶æ­ç¤ºäº†é€šç”¨æ±‚è§£å™¨å®ç°çš„åŠ é€Ÿæ•ˆæœä¸å…¶ç®—æ³•ä¿¡æ¯(algorithmic information)ç´§å¯†ç›¸å…³ï¼Œå¹¶ä»ç†è®ºä¸Šæ¨å¯¼å‡ºæ¨ç†æ—¶é—´ä¸è®­ç»ƒæ—¶é—´ä¹‹é—´çš„å¹‚å¾‹ç¼©æ”¾è§„å¾‹(power-law scaling)ã€‚è®ºæ–‡æŒ‡å‡ºï¼Œå•çº¯æ‰©å¤§æ¨¡å‹è§„æ¨¡(model size)å¯èƒ½å¯¼è‡´æ¨¡å‹åœ¨ç¼ºä¹æ´å¯Ÿçš„æƒ…å†µä¸‹é€šè¿‡æš´åŠ›ç ´è§£æ‰§è¡Œä»»åŠ¡ï¼Œè¡¨ç°å‡ºç±»ä¼¼â€œå­¦è€…ç—‡å€™ç¾¤(savants)â€çš„è¡Œä¸ºã€‚å› æ­¤ï¼Œç ”ç©¶å¼ºè°ƒåœ¨ç¼©æ”¾æ¨ç†æ¨¡å‹æ—¶åº”å°†æ—¶é—´(time)è§†ä¸ºæ ¸å¿ƒä¼˜åŒ–æŒ‡æ ‡ï¼Œä¸ºç†è§£æ™ºèƒ½çš„æœ¬è´¨æä¾›äº†å…¨æ–°çš„ç†è®ºè§†è§’ã€‚",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.12066v1",
      "published_date": "2025-10-14 02:17:54 UTC",
      "updated_date": "2025-10-14 02:17:54 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:29:54.971161+00:00"
    },
    {
      "arxiv_id": "2510.13885v1",
      "title": "Order from Chaos: Comparative Study of Ten Leading LLMs on Unstructured Data Categorization",
      "title_zh": "ç§©åºå§‹äºæ··æ²Œï¼šåç§ä¸»æµå¤§è¯­è¨€æ¨¡å‹åœ¨éç»“æ„åŒ–æ•°æ®åˆ†ç±»ä¸­çš„å¯¹æ¯”ç ”ç©¶",
      "authors": [
        "Ariel Kamen"
      ],
      "abstract": "This study presents a comparative evaluation of ten state-of-the-art large language models (LLMs) applied to unstructured text categorization using the Interactive Advertising Bureau (IAB) 2.2 hierarchical taxonomy. The analysis employed a uniform dataset of 8,660 human-annotated samples and identical zero-shot prompts to ensure methodological consistency across all models. Evaluation metrics included four classic measures - accuracy, precision, recall, and F1-score - and three LLM-specific indicators: hallucination ratio, inflation ratio, and categorization cost.\n  Results show that, despite their rapid advancement, contemporary LLMs achieve only moderate classic performance, with average scores of 34% accuracy, 42% precision, 45% recall, and 41% F1-score. Hallucination and inflation ratios reveal that models frequently overproduce categories relative to human annotators. Among the evaluated systems, Gemini 1.5/2.0 Flash and GPT 20B/120B offered the most favorable cost-to-performance balance, while GPT 120B demonstrated the lowest hallucination ratio. The findings suggest that scaling and architectural improvements alone do not ensure better categorization accuracy, as the task requires compressing rich unstructured text into a limited taxonomy - a process that challenges current model architectures.\n  To address these limitations, a separate ensemble-based approach was developed and tested. The ensemble method, in which multiple LLMs act as independent experts, substantially improved accuracy, reduced inflation, and completely eliminated hallucinations. These results indicate that coordinated orchestration of models - rather than sheer scale - may represent the most effective path toward achieving or surpassing human-expert performance in large-scale text categorization.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹åç§æœ€å…ˆè¿›çš„å¤§è¯­è¨€æ¨¡å‹ (LLMs) åœ¨éç»“æ„åŒ–æ–‡æœ¬åˆ†ç±»ä»»åŠ¡ä¸­çš„è¡¨ç°è¿›è¡Œäº†å¯¹æ¯”è¯„ä¼°ï¼Œé‡‡ç”¨äº† Interactive Advertising Bureau (IAB) 2.2 åˆ†å±‚åˆ†ç±»ä½“ç³»ã€‚å®éªŒä½¿ç”¨åŒ…å« 8,660 ä¸ªäººå·¥æ ‡æ³¨æ ·æœ¬çš„ç»Ÿä¸€æ•°æ®é›†ï¼Œé€šè¿‡ç›¸åŒçš„ zero-shot æç¤ºè¯ï¼Œå¹¶ç»“åˆä¼ ç»ŸæŒ‡æ ‡å’Œé’ˆå¯¹ LLM çš„å¹»è§‰ç‡ (hallucination ratio)ã€è†¨èƒ€ç‡ (inflation ratio) ç­‰æŒ‡æ ‡è¿›è¡Œæµ‹è¯•ã€‚ç»“æœæ˜¾ç¤ºï¼Œç°æœ‰æ¨¡å‹åœ¨åˆ†ç±»æ€§èƒ½ä¸Šä»…è¾¾åˆ°ä¸­ç­‰æ°´å¹³ï¼Œä¸”æ™®éå­˜åœ¨è¿‡åº¦ç”Ÿæˆç±»åˆ«çš„é—®é¢˜ã€‚å…¶ä¸­ï¼ŒGemini 1.5/2.0 Flash å’Œ GPT 20B/120B è¡¨ç°å‡ºæœ€ä½³çš„æ€§ä»·æ¯”ï¼Œè€Œ GPT 120B çš„å¹»è§‰ç‡æœ€ä½ã€‚ç ”ç©¶æŒ‡å‡ºï¼Œå•çº¯å¢åŠ æ¨¡å‹è§„æ¨¡å¹¶ä¸è¶³ä»¥æå‡åˆ†ç±»å‡†ç¡®æ€§ï¼Œå› ä¸ºè¯¥ä»»åŠ¡åœ¨å¤„ç†æ–‡æœ¬å‹ç¼©ä¸å—é™åˆ†ç±»ä½“ç³»æ˜ å°„æ—¶é¢ä¸´æ¶æ„æŒ‘æˆ˜ã€‚ä¸ºè§£å†³è¿™ä¸€é—®é¢˜ï¼Œç ”ç©¶æå‡ºäº†ä¸€ç§åŸºäºé›†æˆ (ensemble-based) çš„æ–¹æ³•ï¼Œè®©å¤šä¸ªæ¨¡å‹ä½œä¸ºç‹¬ç«‹ä¸“å®¶è¿›è¡Œåä½œã€‚è¯¥é›†æˆæ–¹æ³•æ˜¾è‘—æé«˜äº†å‡†ç¡®ç‡ï¼Œå¹¶å®Œå…¨æ¶ˆé™¤äº†å¹»è§‰ã€‚ç»“è®ºè¡¨æ˜ï¼Œå¤šæ¨¡å‹ååŒè°ƒåº¦æ¯”å•çº¯è¿½æ±‚è§„æ¨¡æ›´èƒ½æœ‰æ•ˆæå‡å¤§è§„æ¨¡æ–‡æœ¬åˆ†ç±»çš„è¡¨ç°ï¼Œä¸ºè¾¾åˆ°äººç±»ä¸“å®¶æ°´å¹³æä¾›äº†æ–°è·¯å¾„ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "10 pages, 4 figures,",
      "pdf_url": "https://arxiv.org/pdf/2510.13885v1",
      "published_date": "2025-10-14 02:15:01 UTC",
      "updated_date": "2025-10-14 02:15:01 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:29:57.850921+00:00"
    },
    {
      "arxiv_id": "2510.12063v1",
      "title": "ThinkPilot: Steering Reasoning Models via Automated Think-prefixes Optimization",
      "title_zh": "ThinkPilotï¼šåŸºäºè‡ªåŠ¨åŒ–æ€è€ƒå‰ç¼€ä¼˜åŒ–çš„æ¨ç†æ¨¡å‹å¼•å¯¼",
      "authors": [
        "Sunzhu Li",
        "Zhiyu Lin",
        "Shuling Yang",
        "Jiale Zhao",
        "Wei Chen"
      ],
      "abstract": "Large Reasoning Models (LRMs) are powerful, but they still suffer from inefficient and off-target reasoning. Currently, training-free methods are limited to either rigid heuristics or descriptive, non-actionable analyses. In this paper, we introduce ThinkPilot, a training-free framework that automatically optimizes LRMs reasoning. It uses an evolutionary process to generate think-prefixes, which are instructions that evolve driven by a taxonomy of reasoning behaviors to guide models toward superior performance. Extensive experiments demonstrate ThinkPilot's broad effectiveness: it significantly improves the accuracy-length trade-off for efficient reasoning, drastically improves safety (for example, cutting the StrongREJECT score of DeepSeek-R1-Distill-Qwen-32B from 27.0% to 0.7), and enhances instruction following. It also synergizes with existing training-based methods. Our analysis reveals that think-prefixes can reliably control LRMs' reasoning behaviors, and that different tasks have strong preferences for specific behavioral distributions. By automatically identifying and eliciting these behaviors, ThinkPilot provides a generalizable framework for aligning LRMs reasoning with task demands. Data and code are available at https://github.com/teqkilla/ThinkPilot",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ThinkPilotï¼Œä¸€ä¸ªæ—¨åœ¨ä¼˜åŒ–å¤§å‹æ¨ç†æ¨¡å‹ (Large Reasoning Models, LRMs) æ¨ç†èƒ½åŠ›çš„æ— éœ€è®­ç»ƒæ¡†æ¶ï¼Œè§£å†³äº†æ¨¡å‹æ¨ç†æ•ˆç‡ä½ä¸‹ä¸”åç¦»ç›®æ ‡çš„é—®é¢˜ã€‚ThinkPilot åˆ©ç”¨è¿›åŒ–è¿‡ç¨‹è‡ªåŠ¨ç”Ÿæˆ think-prefixes æŒ‡ä»¤ï¼Œé€šè¿‡æ¨ç†è¡Œä¸ºåˆ†ç±»æ³• (taxonomy of reasoning behaviors) å¼•å¯¼æ¨¡å‹äº§ç”Ÿæ›´ä¼˜çš„æ€§èƒ½è¡¨ç°ã€‚å®éªŒè¯æ˜è¯¥æ¡†æ¶æ˜¾è‘—ä¼˜åŒ–äº†æ¨ç†è¿‡ç¨‹ä¸­çš„å‡†ç¡®åº¦-é•¿åº¦å¹³è¡¡ (accuracy-length trade-off)ï¼Œå¹¶å¤§å¹…æå‡äº†æ¨¡å‹çš„å®‰å…¨æ€§ã€‚å…·ä½“è€Œè¨€ï¼Œå®ƒæˆåŠŸå°† DeepSeek-R1-Distill-Qwen-32B çš„ StrongREJECT åˆ†æ•°ä» 27.0% é™ä½è‡³ 0.7%ï¼ŒåŒæ—¶å¢å¼ºäº†æŒ‡ä»¤éµå¾ªèƒ½åŠ›ã€‚ç ”ç©¶å‘ç° think-prefixes å¯ä»¥å¯é åœ°æ§åˆ¶ LRMs çš„æ¨ç†è¡Œä¸ºï¼Œä¸”ä¸åŒä»»åŠ¡å¯¹ç‰¹å®šçš„æ¨ç†è¡Œä¸ºåˆ†å¸ƒå…·æœ‰æ˜æ˜¾çš„åå¥½ã€‚ThinkPilot æä¾›äº†ä¸€ä¸ªé€šç”¨çš„æ¡†æ¶ï¼Œèƒ½å¤Ÿè‡ªåŠ¨è¯†åˆ«å¹¶æ¿€å‘ç‰¹å®šæ¨ç†è¡Œä¸ºï¼Œä»è€Œå®ç° LRMs æ¨ç†è¿‡ç¨‹ä¸å…·ä½“ä»»åŠ¡éœ€æ±‚çš„é«˜æ•ˆå¯¹é½ã€‚",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.12063v1",
      "published_date": "2025-10-14 02:02:19 UTC",
      "updated_date": "2025-10-14 02:02:19 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:30:04.065557+00:00"
    },
    {
      "arxiv_id": "2510.12061v1",
      "title": "Empowering LLM Agents with Geospatial Awareness: Toward Grounded Reasoning for Wildfire Response",
      "title_zh": "ä¸º LLM æ™ºèƒ½ä½“èµ‹èƒ½åœ°ç†ç©ºé—´æ„ŸçŸ¥ï¼šè¿ˆå‘å±±ç«å“åº”çš„å…·èº«æ¨ç†",
      "authors": [
        "Yiheng Chen",
        "Lingyao Li",
        "Zihui Ma",
        "Qikai Hu",
        "Yilun Zhu",
        "Min Deng",
        "Runlong Yu"
      ],
      "abstract": "Effective disaster response is essential for safeguarding lives and property. Existing statistical approaches often lack semantic context, generalize poorly across events, and offer limited interpretability. While Large language models (LLMs) provide few-shot generalization, they remain text-bound and blind to geography. To bridge this gap, we introduce a Geospatial Awareness Layer (GAL) that grounds LLM agents in structured earth data. Starting from raw wildfire detections, GAL automatically retrieves and integrates infrastructure, demographic, terrain, and weather information from external geodatabases, assembling them into a concise, unit-annotated perception script. This enriched context enables agents to produce evidence-based resource-allocation recommendations (e.g., personnel assignments, budget allocations), further reinforced by historical analogs and daily change signals for incremental updates. We evaluate the framework in real wildfire scenarios across multiple LLM models, showing that geospatially grounded agents can outperform baselines. The proposed framework can generalize to other hazards such as floods and hurricanes.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† Geospatial Awareness Layer (GAL) æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹ (LLMs) åœ¨ç¾å®³å“åº”ä¸­ç¼ºä¹åœ°ç†ç©ºé—´æ„è¯†ä¸”ä»…é™äºæ–‡æœ¬å¤„ç†çš„é—®é¢˜ã€‚GAL èƒ½å¤Ÿå°† LLM agents ä¸ç»“æ„åŒ–åœ°çƒæ•°æ®ç›¸ç»“åˆï¼Œä»åŸå§‹é‡ç«æ¢æµ‹æ•°æ®å‡ºå‘ï¼Œè‡ªåŠ¨æ£€ç´¢å¹¶é›†æˆåŸºç¡€è®¾æ–½ã€äººå£ã€åœ°å½¢åŠå¤©æ°”ç­‰å¤–éƒ¨åœ°ç†æ•°æ®åº“ä¿¡æ¯ï¼Œç”Ÿæˆç®€æ´ä¸”æ ‡æ³¨å•ä½çš„æ„ŸçŸ¥è„šæœ¬ã€‚è¿™ç§ä¸°å¯Œçš„ä¸Šä¸‹æ–‡ä½¿æ™ºèƒ½ä½“èƒ½å¤ŸåŸºäºè¯æ®æä¾›äººå‘˜åˆ†é…å’Œé¢„ç®—ç­‰èµ„æºåˆ†é…å»ºè®®ï¼Œå¹¶ç»“åˆå†å²ç±»æ¯”å’Œæ¯æ—¥å˜åŒ–ä¿¡å·å®ç°å¢é‡æ›´æ–°ã€‚é€šè¿‡åœ¨çœŸå®é‡ç«åœºæ™¯ä¸‹å¯¹å¤šç§ LLMs è¿›è¡Œè¯„ä¼°ï¼Œç»“æœè¡¨æ˜å…·å¤‡åœ°ç†ç©ºé—´è½åœ°èƒ½åŠ›çš„æ™ºèƒ½ä½“æ€§èƒ½æ˜¾è‘—ä¼˜äºåŸºå‡†æ¨¡å‹ã€‚æ­¤å¤–ï¼Œè¯¥æ¡†æ¶å…·æœ‰è‰¯å¥½çš„é€šç”¨æ€§ï¼Œå¯æ‰©å±•åº”ç”¨äºæ´ªæ°´ã€é£“é£ç­‰å…¶ä»–è‡ªç„¶ç¾å®³çš„åº”å¯¹ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.12061v1",
      "published_date": "2025-10-14 01:59:02 UTC",
      "updated_date": "2025-10-14 01:59:02 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:30:05.853811+00:00"
    },
    {
      "arxiv_id": "2510.12060v1",
      "title": "Your VAR Model is Secretly an Efficient and Explainable Generative Classifier",
      "title_zh": "VAR æ¨¡å‹å®ä¸ºä¸€ç§é«˜æ•ˆä¸”å¯è§£é‡Šçš„ç”Ÿæˆå¼åˆ†ç±»å™¨",
      "authors": [
        "Yi-Chung Chen",
        "David I. Inouye",
        "Jing Gao"
      ],
      "abstract": "Generative classifiers, which leverage conditional generative models for classification, have recently demonstrated desirable properties such as robustness to distribution shifts. However, recent progress in this area has been largely driven by diffusion-based models, whose substantial computational cost severely limits scalability. This exclusive focus on diffusion-based methods has also constrained our understanding of generative classifiers. In this work, we propose a novel generative classifier built on recent advances in visual autoregressive (VAR) modeling, which offers a new perspective for studying generative classifiers. To further enhance its performance, we introduce the Adaptive VAR Classifier$^+$ (A-VARC$^+$), which achieves a superior trade-off between accuracy and inference speed, thereby significantly improving practical applicability. Moreover, we show that the VAR-based method exhibits fundamentally different properties from diffusion-based methods. In particular, due to its tractable likelihood, the VAR-based classifier enables visual explainability via token-wise mutual information and demonstrates inherent resistance to catastrophic forgetting in class-incremental learning tasks.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç°æœ‰åŸºäºæ‰©æ•£æ¨¡å‹ï¼ˆdiffusion-based modelsï¼‰çš„ç”Ÿæˆå¼åˆ†ç±»å™¨è®¡ç®—å¼€é”€è¿‡å¤§çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§åŸºäºè§†è§‰è‡ªå›å½’ï¼ˆvisual autoregressive, VARï¼‰å»ºæ¨¡çš„æ–°å‹ç”Ÿæˆå¼åˆ†ç±»å™¨ã€‚ä¸ºè¿›ä¸€æ­¥å¢å¼ºæ€§èƒ½ï¼Œç ”ç©¶è€…å¼•å…¥äº† A-VARC$^+$ (Adaptive VAR Classifier$^+$)ï¼Œåœ¨ä¿è¯é«˜å‡†ç¡®ç‡çš„åŒæ—¶ä¼˜åŒ–äº†æ¨ç†é€Ÿåº¦ï¼Œæ˜¾è‘—æå‡äº†æ¨¡å‹çš„å®é™…åº”ç”¨æ½œåŠ›ã€‚ä¸æ‰©æ•£ç±»æ–¹æ³•ä¸åŒï¼ŒåŸºäº VAR çš„åˆ†ç±»å™¨åˆ©ç”¨å…¶å¯å¤„ç†çš„ä¼¼ç„¶æ€§ï¼ˆtractable likelihoodï¼‰ï¼Œé€šè¿‡æ ‡è®°çº§äº’ä¿¡æ¯ï¼ˆtoken-wise mutual informationï¼‰å®ç°äº†ç›´è§‚çš„è§†è§‰å¯è§£é‡Šæ€§ï¼ˆvisual explainabilityï¼‰ã€‚æ­¤å¤–ï¼Œå®éªŒè¯æ˜è¯¥æ¨¡å‹åœ¨ç±»å¢é‡å­¦ä¹ ï¼ˆclass-incremental learningï¼‰åœºæ™¯ä¸­å¯¹ç¾éš¾æ€§é—å¿˜ï¼ˆcatastrophic forgettingï¼‰å…·æœ‰å¤©ç„¶çš„æŠµæŠ—åŠ›ï¼Œä¸ºç”Ÿæˆå¼åˆ†ç±»å™¨çš„ç ”ç©¶æä¾›äº†å…¨æ–°çš„è§†è§’ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.12060v1",
      "published_date": "2025-10-14 01:59:01 UTC",
      "updated_date": "2025-10-14 01:59:01 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:30:01.773896+00:00"
    },
    {
      "arxiv_id": "2510.12845v1",
      "title": "VLURes: Benchmarking VLM Visual and Linguistic Understanding in Low-Resource Languages",
      "title_zh": "VLUResï¼šä½èµ„æºè¯­è¨€ä¸‹è§†è§‰è¯­è¨€æ¨¡å‹è§†è§‰ä¸è¯­è¨€ç†è§£èƒ½åŠ›çš„åŸºå‡†æµ‹è¯•",
      "authors": [
        "Jesse Atuhurra",
        "Iqra Ali",
        "Tomoya Iwakura",
        "Hidetaka Kamigaito",
        "Tatsuya Hiraoka"
      ],
      "abstract": "Vision Language Models (VLMs) are pivotal for advancing perception in intelligent agents. Yet, evaluation of VLMs remains limited to predominantly English-centric benchmarks in which the image-text pairs comprise short texts. To evaluate VLM fine-grained abilities, in four languages under long-text settings, we introduce a novel multilingual benchmark VLURes featuring eight vision-and-language tasks, and a pioneering unrelatedness task, to probe the fine-grained Visual and Linguistic Understanding capabilities of VLMs across English, Japanese, and low-resource languages, Swahili, and Urdu. Our datasets, curated from web resources in the target language, encompass ten diverse image categories and rich textual context, introducing valuable vision-language resources for Swahili and Urdu. By prompting VLMs to generate responses and rationales, evaluated automatically and by native speakers, we uncover performance disparities across languages and tasks critical to intelligent agents, such as object recognition, scene understanding, and relationship understanding. We conducted evaluations of ten VLMs with VLURes. The best performing model, GPT-4o, achieves an overall accuracy of 90.8% and lags human performance by 6.7%, though the gap is larger for open-source models. The gap highlights VLURes' critical role in developing intelligent agents to tackle multi-modal visual reasoning.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† VLUResï¼Œä¸€ä¸ªæ—¨åœ¨è¯„ä¼°è§†è§‰è¯­è¨€æ¨¡å‹ (Vision Language Models, VLMs) åœ¨ä½èµ„æºè¯­è¨€å’Œé•¿æ–‡æœ¬èƒŒæ™¯ä¸‹ç»†ç²’åº¦ç†è§£èƒ½åŠ›çš„å…¨æ–°åŸºå‡†æµ‹è¯•ã€‚è¯¥åŸºå‡†æ¶µç›–äº†è‹±è¯­ã€æ—¥è¯­ä»¥åŠä½èµ„æºè¯­è¨€æ–¯ç“¦å¸Œé‡Œè¯­ (Swahili) å’Œä¹Œå°”éƒ½è¯­ (Urdu)ï¼ŒåŒ…å«å…«é¡¹è§†è§‰è¯­è¨€ä»»åŠ¡å’Œä¸€é¡¹å¼€åˆ›æ€§çš„ä¸ç›¸å…³æ€§ (unrelatedness) ä»»åŠ¡ã€‚æ•°æ®é›†ä»ç›®æ ‡è¯­è¨€çš„ç½‘ç»œèµ„æºä¸­æå–ï¼Œæ¶µç›–åä¸ªå›¾åƒç±»åˆ«å’Œä¸°å¯Œçš„æ–‡æœ¬ä¸Šä¸‹æ–‡ï¼Œä¸ºä½èµ„æºè¯­è¨€æä¾›äº†å®è´µçš„è§†è§‰è¯­è¨€ç ”ç©¶èµ„æºã€‚ç ”ç©¶é€šè¿‡è¯„ä¼°æ¨¡å‹ç”Ÿæˆçš„å“åº”åŠå…¶æ¨ç†é€»è¾‘ (rationales)ï¼Œæ­ç¤ºäº†ä¸åŒè¯­è¨€åœ¨ç‰©ä½“è¯†åˆ«ã€åœºæ™¯ç†è§£å’Œå…³ç³»ç†è§£ç­‰ä»»åŠ¡ä¸Šçš„æ€§èƒ½å·®å¼‚ã€‚å®éªŒå¯¹åç§æ¨¡å‹è¿›è¡Œäº†è¯„ä¼°ï¼Œç»“æœæ˜¾ç¤ºè¡¨ç°æœ€ä¼˜çš„ GPT-4o å‡†ç¡®ç‡è¾¾åˆ° 90.8%ï¼Œä½†ä»ä¸äººç±»è¡¨ç°å­˜åœ¨ 6.7% çš„å·®è·ï¼Œä¸”å¼€æºæ¨¡å‹çš„æ€§èƒ½æ»åæ›´ä¸ºæ˜¾è‘—ã€‚VLURes çš„æ¨å‡ºä¸ºå¼€å‘èƒ½å¤Ÿå¤„ç†å¤šæ¨¡æ€è§†è§‰æ¨ç†çš„æ™ºèƒ½ä½“æä¾›äº†å…³é”®çš„è¯„ä»·å·¥å…·å’Œèµ„æºæ”¯æŒã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CV",
        "cs.RO"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.12845v1",
      "published_date": "2025-10-14 01:41:43 UTC",
      "updated_date": "2025-10-14 01:41:43 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:30:08.673284+00:00"
    },
    {
      "arxiv_id": "2510.12051v1",
      "title": "APCE: Adaptive Progressive Context Expansion for Long Context Processing",
      "title_zh": "APCEï¼šé¢å‘é•¿ä¸Šä¸‹æ–‡å¤„ç†çš„è‡ªé€‚åº”æ¸è¿›å¼ä¸Šä¸‹æ–‡æ‰©å±•",
      "authors": [
        "Baisub Lee",
        "Sanghyun Byun",
        "Mohanad Odema",
        "Jung Guack",
        "Jacob Song",
        "Woo Seong Chung"
      ],
      "abstract": "Deploying useful Long-Context Transformer Models (LCTMs) requires addressing two key challenges: (1) A growing memory footprint due to quadratic self-attention and linear KV-cache scaling in memory as sequence length increases; (2) the ContextRot phenomena where empirical evidence suggests that transformer architecture's performance degrades with increasing context length. Given the shared dependency on the input, a natural question arises: Can we surgically select the most important input chunks for processing to synergistically (a) reduce the memory footprint, and (b) mitigate the ContextRot effects? In this paper, we answer this question in the affirmative for long-context summarization tasks. We propose APCE as a context-aware solution to select the most important input chunks through low-dimensional semantic similarity matching with the current query. By directly operating on the input, APCE decouples from strict dependency on underlying hardware or CUDA environments, promising a compatible solution scalable to different deployment systems. Our empirical evaluations have demonstrated superior or on-par summarization performance for APCE compared to the full dense baseline using a fraction (50%-70%) of the input sequence resulting in KV-cache and self-attention memory efficiency improvements. We hope our findings inspire further research on context-aware efficiency solutions for LCTMs geared towards other relevant long-context tasks.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†APCE (Adaptive Progressive Context Expansion)ï¼Œè¿™æ˜¯ä¸€ç§é’ˆå¯¹é•¿ä¸Šä¸‹æ–‡å¤„ç†çš„è‡ªé€‚åº”æ¸è¿›å¼ä¸Šä¸‹æ–‡æ‰©å±•æ–¹æ¡ˆï¼Œæ—¨åœ¨è§£å†³é•¿ä¸Šä¸‹æ–‡Transformeræ¨¡å‹(LCTMs)é¢ä¸´çš„KV-cacheå†…å­˜å ç”¨æ¿€å¢å’Œæ€§èƒ½éšé•¿åº¦å¢åŠ è€Œé€€åŒ–çš„ContextRotç°è±¡ã€‚APCEé€šè¿‡ä½ç»´è¯­ä¹‰ç›¸ä¼¼åº¦åŒ¹é…å½“å‰æŸ¥è¯¢ï¼ŒåŠ¨æ€é€‰æ‹©è¾“å…¥ä¸­æœ€å…³é”®çš„ä¿¡æ¯å—ï¼Œä»è€Œåœ¨ä¸ä¾èµ–ç‰¹å®šç¡¬ä»¶æˆ–CUDAç¯å¢ƒçš„å‰æä¸‹å®ç°ä¸ä¸åŒéƒ¨ç½²ç³»ç»Ÿçš„å…¼å®¹ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œåœ¨é•¿ä¸Šä¸‹æ–‡æ‘˜è¦ä»»åŠ¡ä¸­ï¼ŒAPCEä»…éœ€ä½¿ç”¨50%-70%çš„è¾“å…¥åºåˆ—å³å¯è¾¾åˆ°æˆ–è¶…è¶Šå…¨æ³¨æ„åŠ›åŸºçº¿æ¨¡å‹çš„æ€§èƒ½ã€‚è¿™ç§æ–¹æ³•æœ‰æ•ˆæå‡äº†KV-cacheå’Œè‡ªæ³¨æ„åŠ›æœºåˆ¶çš„å†…å­˜ä½¿ç”¨æ•ˆç‡ï¼Œä¸ºé•¿ä¸Šä¸‹æ–‡ä»»åŠ¡æä¾›äº†ä¸€ç§é«˜æ•ˆä¸”å…·å¤‡ä¸Šä¸‹æ–‡æ„ŸçŸ¥èƒ½åŠ›çš„è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "NeurIPS 2025 Workshop: ML For Systems",
      "pdf_url": "https://arxiv.org/pdf/2510.12051v1",
      "published_date": "2025-10-14 01:26:36 UTC",
      "updated_date": "2025-10-14 01:26:36 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:30:09.952253+00:00"
    },
    {
      "arxiv_id": "2510.12049v2",
      "title": "Generative AI and Firm Productivity: Field Experiments in Online Retail",
      "title_zh": "ç”Ÿæˆå¼äººå·¥æ™ºèƒ½ä¸ä¼ä¸šç”Ÿäº§ç‡ï¼šåœ¨çº¿é›¶å”®é¢†åŸŸçš„ç”°é‡å®éªŒ",
      "authors": [
        "Lu Fang",
        "Zhe Yuan",
        "Kaifu Zhang",
        "Dante Donati",
        "Miklos Sarvary"
      ],
      "abstract": "We quantify the impact of Generative Artificial Intelligence (GenAI) on firm productivity through a series of large-scale randomized field experiments involving millions of users and products at a leading cross-border online retail platform. Over six months in 2023-2024, GenAI-based enhancements were integrated into seven consumer-facing business workflows. We find that GenAI adoption significantly increases sales, with treatment effects ranging from $0\\%$ to $16.3\\%$, depending on GenAI's marginal contribution relative to existing firm practices. Because inputs and prices were held constant across experimental arms, these gains map directly into total factor productivity improvements. Across the four GenAI applications with positive effects, the implied annual incremental value is approximately $\\$ 5$ per consumer-an economically meaningful impact given the retailer's scale and the early stage of GenAI adoption. The primary mechanism operates through higher conversion rates, consistent with GenAI reducing frictions in the marketplace and improving consumer experience. We also document substantial heterogeneity: smaller and newer sellers, as well as less experienced consumers, exhibit disproportionately larger gains. Our findings provide novel, large-scale causal evidence on the productivity effects of GenAI in online retail, highlighting both its immediate value and broader potential.",
      "tldr_zh": "è¯¥ç ”ç©¶é€šè¿‡åœ¨ä¸€å®¶é¢†å…ˆçš„è·¨å¢ƒç”µå•†å¹³å°å¼€å±•å¤§è§„æ¨¡éšæœºå®åœ°å®éªŒ (Randomized Field Experiments)ï¼Œé‡åŒ–äº†ç”Ÿæˆå¼äººå·¥æ™ºèƒ½ (Generative AI) å¯¹ä¼ä¸šç”Ÿäº§åŠ›çš„å½±å“ã€‚å®éªŒå°† GenAI æŠ€æœ¯æ•´åˆè‡³ä¸ƒä¸ªé¢å‘æ¶ˆè´¹è€…çš„ä¸šåŠ¡å·¥ä½œæµä¸­ï¼Œå‘ç°å…¶æ˜¾è‘—æå‡äº†é”€å”®é¢ï¼Œå¤„ç†æ•ˆåº” (Treatment Effects) ä»‹äº 0% åˆ° 16.3% ä¹‹é—´ã€‚ç”±äºå®éªŒè¿‡ç¨‹ä¸­æŠ•å…¥å’Œä»·æ ¼ä¿æŒæ’å®šï¼Œè¿™äº›æ”¶ç›Šç›´æ¥ä½“ç°ä¸ºå…¨è¦ç´ ç”Ÿäº§ç‡ (Total Factor Productivity) çš„æ”¹å–„ã€‚ç ”ç©¶è¡¨æ˜ GenAI æ¯å¹´èƒ½ä¸ºæ¯ä½æ¶ˆè´¹è€…åˆ›é€ çº¦ 5 ç¾å…ƒçš„å¢é‡ä»·å€¼ï¼Œå…¶ä¸»è¦æœºåˆ¶æ˜¯é€šè¿‡æé«˜è½¬åŒ–ç‡ (Conversion Rates) æ¥å‡å°‘å¸‚åœºæ‘©æ“¦å¹¶ä¼˜åŒ–ç”¨æˆ·ä½“éªŒã€‚æ­¤å¤–ï¼Œç ”ç©¶è¿˜å‘ç°è§„æ¨¡è¾ƒå°ã€æ–°å…¥é©»çš„å–å®¶ä»¥åŠç»éªŒè¾ƒå°‘çš„æ¶ˆè´¹è€…è·ç›Šæ›´ä¸ºæ˜¾è‘—ã€‚è¯¥æˆæœä¸º GenAI åœ¨åœ¨çº¿é›¶å”®é¢†åŸŸçš„ç”Ÿäº§åŠ›æ•ˆåº”æä¾›äº†å¤§è§„æ¨¡å› æœè¯æ®ï¼Œå‡¸æ˜¾äº†å…¶å³æ—¶åº”ç”¨ä»·å€¼ä¸å¹¿æ³›çš„å¢é•¿æ½œåŠ›ã€‚",
      "categories": [
        "econ.GN",
        "cs.AI"
      ],
      "primary_category": "econ.GN",
      "comment": "Keywords: Field Experiments, Generative AI, Productivity, Retail Platforms, Consumer Experience. JEL codes: C93, D24, L81, M31, O3",
      "pdf_url": "https://arxiv.org/pdf/2510.12049v2",
      "published_date": "2025-10-14 01:17:09 UTC",
      "updated_date": "2025-10-31 14:50:59 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:30:21.959986+00:00"
    },
    {
      "arxiv_id": "2512.00008v1",
      "title": "MOTION: ML-Assisted On-Device Low-Latency Motion Recognition",
      "title_zh": "MOTIONï¼šæœºå™¨å­¦ä¹ è¾…åŠ©çš„ç«¯ä¾§ä½å»¶è¿Ÿè¿åŠ¨è¯†åˆ«",
      "authors": [
        "Veeramani Pugazhenthi",
        "Wei-Hsiang Chu",
        "Junwei Lu",
        "Jadyn N. Miyahira",
        "Soheil Salehi"
      ],
      "abstract": "The use of tiny devices capable of low-latency gesture recognition is gaining momentum in everyday human-computer interaction and especially in medical monitoring fields. Embedded solutions such as fall detection, rehabilitation tracking, and patient supervision require fast and efficient tracking of movements while avoiding unwanted false alarms. This study presents an efficient solution on how to build very efficient motion-based models only using triaxial accelerometer sensors. We explore the capability of the AutoML pipelines to extract the most important features from the data segments. This approach also involves training multiple lightweight machine learning algorithms using the extracted features. We use WeBe Band, a multi-sensor wearable device that is equipped with a powerful enough MCU to effectively perform gesture recognition entirely on the device. Of the models explored, we found that the neural network provided the best balance between accuracy, latency, and memory use. Our results also demonstrate that reliable real-time gesture recognition can be achieved in WeBe Band, with great potential for real-time medical monitoring solutions that require a secure and fast response time.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† MOTIONï¼Œä¸€ç§æ—¨åœ¨å®ç°ä½å»¶è¿Ÿè®¾å¤‡ç«¯åŠ¨ä½œè¯†åˆ«çš„æœºå™¨å­¦ä¹ è¾…åŠ©æ–¹æ¡ˆï¼Œç‰¹åˆ«é€‚ç”¨äºè·Œå€’æ£€æµ‹å’Œåº·å¤è¿½è¸ªç­‰åŒ»ç–—ç›‘æµ‹åœºæ™¯ã€‚è¯¥æ–¹æ³•ä»…ä½¿ç”¨ triaxial accelerometer ä¼ æ„Ÿå™¨æ•°æ®ï¼Œå¹¶é€šè¿‡ AutoML æµæ°´çº¿æå–å…³é”®ç‰¹å¾ï¼Œä»¥æ­¤è®­ç»ƒå¤šç§è½»é‡åŒ–çš„ Machine Learning ç®—æ³•ã€‚ç ”ç©¶åœ¨é›†æˆäº†é«˜æ€§èƒ½ MCU çš„ WeBe Band ç©¿æˆ´è®¾å¤‡ä¸Šå®ç°äº†å®Œå…¨çš„ç«¯ä¾§æ‰‹åŠ¿è¯†åˆ«ï¼Œç¡®ä¿äº†æ•°æ®çš„å®‰å…¨ä¸å“åº”çš„å¿«é€Ÿã€‚å®éªŒå¯¹æ¯”è¡¨æ˜ï¼ŒNeural Network æ¨¡å‹åœ¨å‡†ç¡®ç‡ã€å»¶è¿Ÿå’Œå†…å­˜å ç”¨ä¹‹é—´è¾¾åˆ°äº†æœ€ä½³å¹³è¡¡ã€‚ç ”ç©¶ç»“æœè¯æ˜äº†åœ¨èµ„æºå—é™è®¾å¤‡ä¸Šå®ç°å¯é å®æ—¶æ‰‹åŠ¿è¯†åˆ«çš„å¯è¡Œæ€§ï¼Œä¸ºéœ€è¦é«˜æ•ˆåé¦ˆçš„åŒ»ç–—ç›‘æµ‹æŠ€æœ¯æä¾›äº†é‡è¦å‚è€ƒã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.00008v1",
      "published_date": "2025-10-14 01:15:47 UTC",
      "updated_date": "2025-10-14 01:15:47 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:30:14.685734+00:00"
    },
    {
      "arxiv_id": "2510.12047v3",
      "title": "ContractEval: A Benchmark for Evaluating Contract-Satisfying Assertions in Code Generation",
      "title_zh": "ContractEvalï¼šè¯„ä¼°ä»£ç ç”Ÿæˆä¸­å¥‘çº¦æ»¡è¶³å‹æ–­è¨€çš„åŸºå‡†",
      "authors": [
        "Soohan Lim",
        "Joonghyuk Hahn",
        "Hyunwoo Park",
        "Sang-Ki Ko",
        "Yo-Sub Han"
      ],
      "abstract": "Current code generation benchmarks measure functional correctness on well-formed inputs, as test cases are curated to satisfy input preconditions. This leaves a gap: generated programs may appear correct but fail to satisfy contracts -- assertion-level validity constraints for rejecting ill-formed inputs. We introduce ContractEval, a benchmark for evaluating contract-satisfying assertions in code generation, i.e., whether code rejects contract-violating inputs by triggering intended assertions. Built on HumanEval+ and MBPP+, ContractEval augments each task with contract-violation tests derived from reference assertions. We synthesize these via a neuro-symbolic pipeline: an LLM converts assertion clauses into constraints, and an SMT solver enumerates satisfiable violation combinations to generate inputs that violate selected clauses while satisfying the rest. Across five code LLMs, standard prompting yields 0% contract satisfaction, while adding a few contract-violation examples boosts contract satisfaction to 49--53% while maintaining pass@1 by 92% of the original. Our code is available at https://github.com/suhanmen/ContractEval.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å½“å‰ä»£ç ç”ŸæˆåŸºå‡†(benchmarks)ä¸»è¦å…³æ³¨è‰¯æ„è¾“å…¥ä¸‹çš„åŠŸèƒ½æ­£ç¡®æ€§(functional correctness)ï¼Œè€Œå¿½è§†äº†ä»£ç æ˜¯å¦èƒ½é€šè¿‡æ–­è¨€(assertions)æœ‰æ•ˆæ‹’ç»è¿åå¥‘çº¦(contract-violating)çš„è¾“å…¥è¿™ä¸€ç°çŠ¶ï¼Œæå‡ºäº†ContractEvalè¯„ä»·åŸºå‡†ã€‚ContractEvalåœ¨HumanEval+å’ŒMBPP+çš„åŸºç¡€ä¸Šï¼Œé€šè¿‡ä¸€ç§ç»“åˆLLMä¸SMT solverçš„ç¥ç»ç¬¦å·ç®¡é“(neuro-symbolic pipeline)ï¼Œå°†æ–­è¨€å­å¥è½¬åŒ–ä¸ºçº¦æŸå¹¶è‡ªåŠ¨åˆæˆè¿åæ€§æµ‹è¯•è¾“å…¥ã€‚å®éªŒè¯„ä¼°äº†äº”ç§ä»£ç å¤§è¯­è¨€æ¨¡å‹(code LLMs)ï¼Œå‘ç°åœ¨æ ‡å‡†æç¤º(standard prompting)ä¸‹å¥‘çº¦æ»¡è¶³ç‡ä¸º0%ï¼Œè€Œé€šè¿‡å¼•å…¥å°‘é‡å¥‘çº¦è¿åç¤ºä¾‹ï¼Œå¥‘çº¦æ»¡è¶³ç‡å¯æ˜¾è‘—æå‡è‡³49-53%ï¼Œä¸”èƒ½ä¿æŒåŸå§‹pass@1æ°´å¹³çš„92%ã€‚è¯¥ç ”ç©¶æ­ç¤ºäº†å½“å‰æ¨¡å‹åœ¨å¤„ç†å¥‘çº¦çº¦æŸæ–¹é¢çš„å·¨å¤§é¸¿æ²Ÿï¼Œå¹¶ä¸ºæå‡ç”Ÿæˆä»£ç çš„é²æ£’æ€§æä¾›äº†é‡è¦å·¥å…·ã€‚",
      "categories": [
        "cs.AI",
        "cs.SE"
      ],
      "primary_category": "cs.AI",
      "comment": "18 pages, 15 figures, 5 tables",
      "pdf_url": "https://arxiv.org/pdf/2510.12047v3",
      "published_date": "2025-10-14 01:12:37 UTC",
      "updated_date": "2026-01-09 02:35:26 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:30:34.838108+00:00"
    },
    {
      "arxiv_id": "2510.12044v1",
      "title": "Hierarchical Alignment: Surgical Fine-Tuning via Functional Layer Specialization in Large Language Models",
      "title_zh": "å±‚çº§å¯¹é½ï¼šåŸºäºå¤§è¯­è¨€æ¨¡å‹åŠŸèƒ½å±‚ä¸“é—¨åŒ–çš„æ‰‹æœ¯çº§å¾®è°ƒ",
      "authors": [
        "Yukun Zhang",
        "Qi Dong"
      ],
      "abstract": "Existing alignment techniques for Large Language Models (LLMs), such as Direct Preference Optimization (DPO), typically treat the model as a monolithic entity, applying uniform optimization pressure across all layers. This approach overlooks the functional specialization within the Transformer architecture, where different layers are known to handle distinct tasks from syntax to abstract reasoning. In this paper, we challenge this one-size-fits-all paradigm by introducing Hierarchical Alignment, a novel method that applies targeted DPO to distinct functional blocks of a model's layers: local (syntax), intermediate (logic), and global (factuality). Through a series of controlled experiments on state-of-the-art models like Llama-3.1-8B and Qwen1.5-7B using LoRA for surgical fine-tuning, our results, evaluated by a powerful LLM-as-Judge, demonstrate significant and predictable improvements. Specifically, aligning the local layers (Local-Align) enhances grammatical fluency. More importantly, aligning the global layers (Global-Align) not only improves factual consistency as hypothesized but also proves to be the most effective strategy for enhancing logical coherence, outperforming all baselines. Critically, all hierarchical strategies successfully avoid the \"alignment tax\" observed in standard DPO, where gains in fluency come at the cost of degraded logical reasoning. These findings establish a more resource-efficient, controllable, and interpretable path for model alignment, highlighting the immense potential of shifting from monolithic optimization to structure-aware surgical fine-tuning to build more advanced and reliable LLMs.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ç°æœ‰å¯¹é½æŠ€æœ¯ï¼ˆå¦‚ Direct Preference Optimization, DPOï¼‰å°†æ¨¡å‹è§†ä¸ºå•ä¸€æ•´ä½“ã€å¿½è§† Transformer æ¶æ„ä¸­ä¸åŒå±‚åŠŸèƒ½ä¸“ä¸šåŒ–çš„é—®é¢˜ï¼Œæå‡ºäº† Hierarchical Alignment æ–¹æ³•ã€‚è¯¥æ–¹æ³•é€šè¿‡å¯¹æ¨¡å‹çš„å±€éƒ¨å±‚ï¼ˆè¯­æ³•ï¼‰ã€ä¸­é—´å±‚ï¼ˆé€»è¾‘ï¼‰å’Œå…¨å±€å±‚ï¼ˆäº‹å®æ€§ï¼‰åº”ç”¨é’ˆå¯¹æ€§çš„ DPO è°ƒæ•´ï¼Œå®ç°äº†ç»“æ„æ„ŸçŸ¥çš„æ‰‹æœ¯å¼å¾®è°ƒã€‚ç ”ç©¶åœ¨ Llama-3.1-8B å’Œ Qwen1.5-7B æ¨¡å‹ä¸Šä½¿ç”¨ LoRA æŠ€æœ¯è¿›è¡Œäº†å¯¹ç…§å®éªŒï¼Œå¹¶åˆ©ç”¨ LLM-as-Judge è¿›è¡Œè¯„ä¼°ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œå¯¹å±€éƒ¨å±‚è¿›è¡Œå¯¹é½ï¼ˆLocal-Alignï¼‰èƒ½å¢å¼ºè¯­æ³•æµåˆ©åº¦ï¼Œè€Œå…¨å±€å±‚å¯¹é½ï¼ˆGlobal-Alignï¼‰åœ¨æå‡äº‹å®ä¸€è‡´æ€§çš„åŒæ—¶ï¼Œä¹Ÿè¢«è¯æ˜æ˜¯å¢å¼ºé€»è¾‘è¿è´¯æ€§æœ€æœ‰æ•ˆçš„ç­–ç•¥ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œæ‰€æœ‰å±‚çº§å¯¹é½ç­–ç•¥éƒ½æˆåŠŸè§„é¿äº†æ ‡å‡† DPO ä¸­å¸¸è§çš„â€œå¯¹é½ç¨ï¼ˆalignment taxï¼‰â€ï¼Œå³åœ¨æå‡æµåˆ©åº¦æ—¶ä¸ä¼šä»¥ç‰ºç‰²é€»è¾‘æ¨ç†ä¸ºä»£ä»·ã€‚è¯¥ç ”ç©¶ä¸ºæ¨¡å‹å¯¹é½æä¾›äº†ä¸€æ¡èµ„æºé«˜æ•ˆã€å¯æ§ä¸”å…·å¤‡å¯è§£é‡Šæ€§çš„è·¯å¾„ï¼Œå±•ç¤ºäº†ä»æ•´ä½“ä¼˜åŒ–è½¬å‘ç»“æ„æ„ŸçŸ¥å¾®è°ƒåœ¨æ„å»ºå¯é  LLMs æ–¹é¢çš„å·¨å¤§æ½œåŠ›ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.12044v1",
      "published_date": "2025-10-14 00:58:34 UTC",
      "updated_date": "2025-10-14 00:58:34 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:30:37.441307+00:00"
    },
    {
      "arxiv_id": "2510.15990v1",
      "title": "Can GRPO Help LLMs Transcend Their Pretraining Origin?",
      "title_zh": "GRPO èƒ½å¦åŠ©åŠ›å¤§è¯­è¨€æ¨¡å‹è¶…è¶Šå…¶é¢„è®­ç»ƒæºå¤´ï¼Ÿ",
      "authors": [
        "Kangqi Ni",
        "Zhen Tan",
        "Zijie Liu",
        "Pingzhi Li",
        "Tianlong Chen"
      ],
      "abstract": "Reinforcement Learning with Verifiable Rewards (RLVR), primarily driven by the Group Relative Policy Optimization (GRPO) algorithm, is a leading approach for enhancing the reasoning abilities of Large Language Models (LLMs). Despite its wide adoption, GRPO's gains are often inconsistent; for instance, a model may show significant improvement in one reasoning domain, like mathematics, yet remain stagnant in another, such as medicine. This inconsistency raises a critical question: under what conditions does GRPO improve reasoning and generalize out-of-distribution (OOD)? We investigate this from a data distribution perspective. We first prove theoretically that GRPO is a conservative reweighting scheme, bounded by the base model's distribution and thus unable to discover completely novel solutions. We further validate this in carefully designed controlled studies by training transformers from scratch, evaluating generalization across reasoning depth, input length, token representation, and compositionality. Our results provide a principled explanation for GRPO's boundaries: OOD improvement emerges only when the target task aligns with the model's pretrained biases, while gains on in-distribution (ID) tasks diminish as performance saturates. This reframes GRPO not as a universal reasoning enhancer but as a tool that sharpens pretraining biases. Our findings motivate future development of algorithms that can expand a model's capabilities beyond its pretraining origin.",
      "tldr_zh": "è¯¥ç ”ç©¶æ·±å…¥æ¢è®¨äº†ç»„ç›¸å¯¹ç­–ç•¥ä¼˜åŒ–(Group Relative Policy Optimization, GRPO)åœ¨æå‡å¤§è¯­è¨€æ¨¡å‹(LLMs)æ¨ç†èƒ½åŠ›æ—¶èƒ½å¦è¶…è¶Šå…¶é¢„è®­ç»ƒèµ·æºã€‚é’ˆå¯¹GRPOåœ¨ä¸åŒä»»åŠ¡ä¸­è¡¨ç°ä¸ä¸€è‡´çš„é—®é¢˜ï¼Œç ”ç©¶è€…ä»æ•°æ®åˆ†å¸ƒè§†è§’å‡ºå‘ï¼Œç†è®ºä¸Šè¯æ˜äº†GRPOæ˜¯ä¸€ç§å—é™äºåŸºåº§æ¨¡å‹åˆ†å¸ƒçš„ä¿å®ˆé‡åŠ æƒæ–¹æ¡ˆï¼Œæ— æ³•ç”Ÿæˆå®Œå…¨æ–°é¢–çš„è§£æ³•ã€‚é€šè¿‡ä»é›¶è®­ç»ƒTransformerå¹¶æµ‹è¯•å…¶åœ¨æ¨ç†æ·±åº¦ã€è¾“å…¥é•¿åº¦åŠç»„åˆæ€§ç­‰æ–¹é¢çš„æ³›åŒ–èƒ½åŠ›ï¼Œç ”ç©¶æ­ç¤ºäº†GRPOçš„è¾¹ç•Œã€‚ç»“æœè¡¨æ˜ï¼Œåˆ†å¸ƒå¤–(Out-of-Distribution, OOD)çš„æ”¹è¿›ä»…åœ¨ä»»åŠ¡ä¸é¢„è®­ç»ƒåå·®(Pretrained Biases)ä¸€è‡´æ—¶å‡ºç°ï¼Œè€Œåˆ†å¸ƒå†…(In-Distribution, ID)ä»»åŠ¡çš„æ”¶ç›Šä¼šéšæ€§èƒ½é¥±å’Œè€Œå‡å°‘ã€‚è¯¥ç ”ç©¶å°†GRPOé‡æ–°å®šä¹‰ä¸ºå¼ºåŒ–é¢„è®­ç»ƒåå·®çš„å·¥å…·è€Œéé€šç”¨æ¨ç†å¢å¼ºå™¨ï¼Œä¸ºå¼€å‘èƒ½æ‰©å±•æ¨¡å‹èƒ½åŠ›çš„æ–°ç®—æ³•æä¾›äº†é‡è¦å‚è€ƒã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.15990v1",
      "published_date": "2025-10-14 00:37:52 UTC",
      "updated_date": "2025-10-14 00:37:52 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:30:40.161239+00:00"
    },
    {
      "arxiv_id": "2510.12033v1",
      "title": "CausalTrace: A Neurosymbolic Causal Analysis Agent for Smart Manufacturing",
      "title_zh": "CausalTraceï¼šé¢å‘æ™ºèƒ½åˆ¶é€ çš„ç¥ç»ç¬¦å·å› æœåˆ†ææ™ºèƒ½ä½“",
      "authors": [
        "Chathurangi Shyalika",
        "Aryaman Sharma",
        "Fadi El Kalach",
        "Utkarshani Jaimini",
        "Cory Henson",
        "Ramy Harik",
        "Amit Sheth"
      ],
      "abstract": "Modern manufacturing environments demand not only accurate predictions but also interpretable insights to process anomalies, root causes, and potential interventions. Existing AI systems often function as isolated black boxes, lacking the seamless integration of prediction, explanation, and causal reasoning required for a unified decision-support solution. This fragmentation limits their trustworthiness and practical utility in high-stakes industrial environments. In this work, we present CausalTrace, a neurosymbolic causal analysis module integrated into the SmartPilot industrial CoPilot. CausalTrace performs data-driven causal analysis enriched by industrial ontologies and knowledge graphs, including advanced functions such as causal discovery, counterfactual reasoning, and root cause analysis (RCA). It supports real-time operator interaction and is designed to complement existing agents by offering transparent, explainable decision support. We conducted a comprehensive evaluation of CausalTrace using multiple causal assessment methods and the C3AN framework (i.e. Custom, Compact, Composite AI with Neurosymbolic Integration), which spans principles of robustness, intelligence, and trustworthiness. In an academic rocket assembly testbed, CausalTrace achieved substantial agreement with domain experts (ROUGE-1: 0.91 in ontology QA) and strong RCA performance (MAP@3: 94%, PR@2: 97%, MRR: 0.92, Jaccard: 0.92). It also attained 4.59/5 in the C3AN evaluation, demonstrating precision and reliability for live deployment.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†CausalTraceï¼Œä¸€ä¸ªé›†æˆåœ¨SmartPilotå·¥ä¸šCoPilotä¸­çš„neurosymbolicå› æœåˆ†ææ¨¡å—ï¼Œæ—¨åœ¨è§£å†³æ™ºèƒ½åˆ¶é€ ä¸­AIé¢„æµ‹ä¸å› æœæ¨ç†è„±èŠ‚çš„é—®é¢˜ã€‚è¯¥æ¨¡å—é€šè¿‡ç»“åˆæ•°æ®é©±åŠ¨åˆ†æä¸å·¥ä¸šontologiesåŠknowledge graphsï¼Œå®ç°äº†causal discoveryã€counterfactual reasoningå’Œroot cause analysis(RCA)ç­‰å…³é”®åŠŸèƒ½ã€‚CausalTraceä¸ºæ“ä½œå‘˜æä¾›å®æ—¶äº¤äº’å¼ä¸”é€æ˜å¯è§£é‡Šçš„å†³ç­–æ”¯æŒï¼Œæœ‰æ•ˆå¢å¼ºäº†å¤æ‚å·¥ä¸šç¯å¢ƒä¸‹çš„ç³»ç»Ÿå¯ä¿¡åº¦ã€‚ç ”ç©¶äººå‘˜åˆ©ç”¨C3ANæ¡†æ¶å¯¹å…¶é²æ£’æ€§ä¸æ™ºèƒ½æ€§è¿›è¡Œäº†å…¨é¢è¯„ä¼°ï¼Œå¹¶åœ¨ç«ç®­ç»„è£…æµ‹è¯•å¹³å°ä¸ŠéªŒè¯äº†å…¶æ€§èƒ½ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒCausalTraceåœ¨RCAä»»åŠ¡ä¸­è¡¨ç°å“è¶Šï¼ˆMAP@3è¾¾94%ï¼ŒMRRä¸º0.92ï¼‰ï¼Œä¸”è¾“å‡ºç»“æœä¸é¢†åŸŸä¸“å®¶é«˜åº¦å»åˆï¼ˆROUGE-1è¾¾0.91ï¼‰ã€‚æœ€ç»ˆï¼Œè¯¥ç³»ç»Ÿå‡­å€Ÿ4.59/5çš„è¯„ä¼°å¾—åˆ†ï¼Œè¯æ˜äº†å…¶åœ¨å®é™…ç”Ÿäº§éƒ¨ç½²ä¸­å…·æœ‰æé«˜çš„ç²¾å‡†åº¦ä¸å¯é æ€§ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "8 pages, 4 figures, 3 tables, Accepted at AAAI 2026: IAAI - Innovative Applications of AI Conference",
      "pdf_url": "https://arxiv.org/pdf/2510.12033v1",
      "published_date": "2025-10-14 00:36:40 UTC",
      "updated_date": "2025-10-14 00:36:40 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:30:45.061308+00:00"
    },
    {
      "arxiv_id": "2510.12032v1",
      "title": "Multi-stage Prompt Refinement for Mitigating Hallucinations in Large Language Models",
      "title_zh": "ç¼“è§£å¤§è¯­è¨€æ¨¡å‹å¹»è§‰çš„å¤šé˜¶æ®µæç¤ºè¯ä¼˜åŒ–",
      "authors": [
        "Jung-Woo Shim",
        "Yeong-Joon Ju",
        "Ji-Hoon Park",
        "Seong-Whan Lee"
      ],
      "abstract": "Recent advancements in large language models (LLMs) have shown strong performance in natural language understanding and generation tasks. However, LLMs continue to encounter challenges with hallucinations, where models generate plausible but incorrect information. While several factors contribute to hallucinations, the impact of ill-formed prompts, prompts with ambiguous wording, incorrect grammar, or incomplete information, was relatively under explored. To address this, we introduce Multi-stage Prompt Refinement (MPR), a framework designed to systematically improve these ill-formed prompts across multiple stages. Each stage addresses specific errors such as punctuation, typographical mistakes, and misuse of key terms, using small language models (SLMs) fine-tuned for these tasks. MPR iteratively enhances the clarity of prompts with additional context and employs a self-reflection mechanism with ranking to prioritize the most relevant input. Experimental results on hallucination benchmarks show that prompts refined by MPR achieve over an 85~\\% win rate compared to their original forms, demonstrating its effectiveness in reducing hallucinations and improving LLM output accuracy. Interestingly, we reveal that MPR can be combined with existing post-hoc hallucination mitigation frameworks, further enhancing its versatility. MPR provides a lightweight and adaptable solution for enhancing LLM reliability across various domains.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§è¯­è¨€æ¨¡å‹(Large Language Models, LLMs)åœ¨é¢å¯¹ä¸è§„èŒƒæç¤ºè¯(ill-formed prompts)æ—¶å®¹æ˜“äº§ç”Ÿå¹»è§‰(Hallucinations)çš„é—®é¢˜ï¼Œæå‡ºäº†Multi-stage Prompt Refinement (MPR)å¤šé˜¶æ®µæç¤ºè¯ä¼˜åŒ–æ¡†æ¶ã€‚è¯¥æ¡†æ¶åˆ©ç”¨é’ˆå¯¹ç‰¹å®šä»»åŠ¡å¾®è°ƒçš„å°è¯­è¨€æ¨¡å‹(Small Language Models, SLMs)ï¼Œåœ¨å¤šä¸ªé˜¶æ®µç³»ç»Ÿæ€§åœ°ä¿®æ­£æç¤ºè¯ä¸­çš„æ‹¼å†™ã€æ ‡ç‚¹åŠæœ¯è¯­è¯¯ç”¨ç­‰é”™è¯¯ã€‚MPRé€šè¿‡è¿­ä»£æ–¹å¼å¼•å…¥é¢å¤–ä¸Šä¸‹æ–‡ä»¥æå‡æç¤ºè¯æ¸…æ™°åº¦ï¼Œå¹¶ç»“åˆå¸¦æœ‰æ’åºåŠŸèƒ½çš„è‡ªæˆ‘åæ€(Self-reflection)æœºåˆ¶æ¥è¯†åˆ«æœ€ç›¸å…³çš„è¾“å…¥ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œç»è¿‡MPRä¼˜åŒ–çš„æç¤ºè¯åœ¨å¹»è§‰è¯„ä¼°åŸºå‡†ä¸­æ¯”åŸå§‹æç¤ºè¯å–å¾—äº†è¶…è¿‡85%çš„èƒœç‡ï¼Œæœ‰æ•ˆæé«˜äº†LLMsçš„è¾“å‡ºå‡†ç¡®æ€§ã€‚æ­¤å¤–ï¼ŒMPRè¿˜å¯ä»¥ä¸ç°æœ‰çš„äº‹å(post-hoc)å¹»è§‰ç¼“è§£æ–¹æ¡ˆç»“åˆä½¿ç”¨ï¼Œä¸ºå¢å¼ºæ¨¡å‹åœ¨ä¸åŒé¢†åŸŸçš„å¯é æ€§æä¾›äº†ä¸€ç§è½»é‡ä¸”çµæ´»çš„è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "22 pages, 6 figures",
      "pdf_url": "https://arxiv.org/pdf/2510.12032v1",
      "published_date": "2025-10-14 00:31:36 UTC",
      "updated_date": "2025-10-14 00:31:36 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:30:46.656540+00:00"
    },
    {
      "arxiv_id": "2510.12029v1",
      "title": "CPR: Mitigating Large Language Model Hallucinations with Curative Prompt Refinement",
      "title_zh": "CPRï¼šé€šè¿‡æ²»æ„ˆå¼æç¤ºè¯ç²¾ç‚¼ç¼“è§£å¤§è¯­è¨€æ¨¡å‹å¹»è§‰",
      "authors": [
        "Jung-Woo Shim",
        "Yeong-Joon Ju",
        "Ji-Hoon Park",
        "Seong-Whan Lee"
      ],
      "abstract": "Recent advancements in large language models (LLMs) highlight their fluency in generating responses to diverse prompts. However, these models sometimes generate plausible yet incorrect ``hallucinated\" facts, undermining trust. A frequent but often overlooked cause of such errors is the use of poorly structured or vague prompts by users, leading LLMs to base responses on assumed rather than actual intentions. To mitigate hallucinations induced by these ill-formed prompts, we introduce Curative Prompt Refinement (CPR), a plug-and-play framework for curative prompt refinement that 1) cleans ill-formed prompts, and 2) generates additional informative task descriptions to align the intention of the user and the prompt using a fine-tuned small language model. When applied to language models, we discover that CPR significantly increases the quality of generation while also mitigating hallucination. Empirical studies show that prompts with CPR applied achieves over a 90\\% win rate over the original prompts without any external knowledge.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§è¯­è¨€æ¨¡å‹ (LLMs) å› æç¤ºè¯­ (prompts) ç»“æ„ä¸è‰¯æˆ–å«ä¹‰æ¨¡ç³Šè€Œå¼•å‘çš„å¹»è§‰ (hallucinations) é—®é¢˜ï¼Œæå‡ºäº† CPR (Curative Prompt Refinement) æ¡†æ¶ã€‚è¿™æ˜¯ä¸€ç§å³æ’å³ç”¨çš„æç¤ºè¯­ä¿®å¤æ–¹æ¡ˆï¼Œé€šè¿‡å¯¹ä¸è§„èŒƒçš„æç¤ºè¯­è¿›è¡Œæ¸…æ´—ï¼Œå¹¶åˆ©ç”¨å¾®è°ƒåçš„å°è¯­è¨€æ¨¡å‹ (SLM) ç”Ÿæˆæ›´å…·ä¿¡æ¯é‡çš„ä»»åŠ¡æè¿°ï¼Œä»è€Œå®ç°ç”¨æˆ·æ„å›¾ä¸æç¤ºè¯­çš„ç²¾ç¡®å¯¹é½ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒCPR åœ¨ä¸éœ€è¦å¤–éƒ¨çŸ¥è¯†ä»‹å…¥çš„å‰æä¸‹ï¼Œèƒ½å¤Ÿæ˜¾è‘—æé«˜ LLMs çš„ç”Ÿæˆè´¨é‡å¹¶æœ‰æ•ˆç¼“è§£å¹»è§‰ç°è±¡ã€‚å®è¯ç ”ç©¶è¿›ä¸€æ­¥è¯å®ï¼Œåº”ç”¨ CPR åçš„æç¤ºè¯­ç›¸æ¯”åŸå§‹æç¤ºè¯­å…·æœ‰è¶…è¿‡ 90% çš„èƒœç‡ï¼Œä¸ºæå‡æ¨¡å‹å¯é æ€§æä¾›äº†é«˜æ•ˆä¸”è½»é‡åŒ–çš„è·¯å¾„ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "2024 IEEE International Conference on Systems, Man, and Cybernetics (SMC), 7 pages, 2 figures",
      "pdf_url": "https://arxiv.org/pdf/2510.12029v1",
      "published_date": "2025-10-14 00:27:46 UTC",
      "updated_date": "2025-10-14 00:27:46 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:30:49.674976+00:00"
    }
  ],
  "processing_status": "completed",
  "error": null,
  "raw_papers_fetched": true,
  "papers_count": 176,
  "processed_papers_count": 176,
  "failed_papers_count": 0,
  "llm_backup_calls": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2026-01-25T03:31:37.660142+00:00"
}