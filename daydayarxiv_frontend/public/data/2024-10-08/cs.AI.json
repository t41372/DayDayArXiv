{
  "date": "2024-10-08",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-10-08 的 arXiv 中文 TLDR 快报！今天 arXiv 的论文主要聚焦 AI 模型优化、多模态处理、医疗应用和算法创新等领域，其中 LLM 的 in-context 学习和生成模型改进（如 T2V-Turbo-v2）令人印象深刻，而 Yejin Choi 等知名学者的论文则讨论 AI 偏置对决策的影响，具有较高话题度。\n\n下面，我将挑选并简要讨论部分关键论文，先优先聊 AI 和 LLM 相关的高影响力文章，再触及计算机视觉、医疗和优化算法等主题。相关论文会归类讨论，非核心文章会快速掠过。\n\n### AI 和 LLM 相关\n- **O1 Replication Journey: A Strategic Progress Report -- Part 1**（英文标题：O1 Replication Journey: A Strategic Progress Report -- Part 1）  \n  Yi Li 等学者探索复制 OpenAI 的 O1 模型，提出“journey learning”范式，通过生成合成数据提升模型在 MATH 数据集上的性能，主要贡献是展示少量训练样本即可实现 8% 的性能提升，强调模型学习过程的迭代优化。\n\n- **Vector-ICL: In-context Learning with Continuous Vector Representations**（英文标题：Vector-ICL: In-context Learning with Continuous Vector Representations）  \n  这篇论文扩展 LLM 的 in-context learning 到连续向量表示，Jianfeng Gao 等作者通过投影和微调方法处理多模态数据，主要发现是 LLM 在文本重建、分类和分子描述等任务中超越传统方法，证明了其泛化潜力。\n\n- **NegMerge: Consensual Weight Negation for Strong Machine Unlearning**（英文标题：NegMerge: Consensual Weight Negation for Strong Machine Unlearning）  \n  作者提出 NegMerge 算法，通过合并多个微调模型的权重来实现机器 unlearning，主要贡献是减少遗忘风险，并在视觉语言模型上显著提升性能，适用于隐私保护场景。\n\n- **Everything Everywhere All at Once: LLMs can In-Context Learn Multiple Tasks in Superposition**（英文标题：Everything Everywhere All at Once: LLMs can In-Context Learn Multiple Tasks in Superposition）  \n  这篇快速掠过的论文探讨 LLM 在多任务场景下的 in-context learning，发现模型能同时处理多个任务，主要发现是更大模型在并行任务中表现出色，扩展了“LLMs as superposition of simulators”的观点。\n\n- **Biased AI can Influence Political Decision-Making**（英文标题：Biased AI can Influence Political Decision-Making）  \n  Yejin Choi 等知名学者通过实验证明 AI 偏置会影响用户决策，主要贡献是发现 AI 教育能缓解偏置影响，为 AI 在公共话语中的风险管理提供洞见。\n\n### 计算机视觉和生成模型\n- **T2V-Turbo-v2: Enhancing Video Generation Model Post-Training through Data, Reward, and Conditional Guidance Design**（英文标题：T2V-Turbo-v2: Enhancing Video Generation Model Post-Training through Data, Reward, and Conditional Guidance Design）  \n  作者改进 T2V 模型，通过奖励模型和条件引导提升视频生成质量，主要发现是新方法在 VBench 上达到 85.13 分的 SOTA 性能，显著提高文本到视频的视觉和运动指标。\n\n- **ViBiDSampler: Enhancing Video Interpolation Using Bidirectional Diffusion Sampler**（英文标题：ViBiDSampler: Enhancing Video Interpolation Using Bidirectional Diffusion Sampler）  \n  这篇论文提出双向扩散采样框架，用于视频插值，主要贡献是生成高质量中间帧，实验显示在 1024x576 分辨率下仅需 195 秒，优于现有方法。\n\n- **Mero Nagarikta: Advanced Nepali Citizenship Data Extractor with Deep Learning-Powered Text Detection and OCR**（英文标题：Mero Nagarikta: Advanced Nepali Citizenship Data Extractor with Deep Learning-Powered Text Detection and OCR）  \n  作者开发 OCR 系统提取尼泊尔公民证信息，使用 YOLOv8 和优化 PyTesseract，主要发现是提高文本检测精度，适用于多语言文档处理。\n\n### 医疗和生物应用\n- **Liver Cancer Knowledge Graph Construction based on dynamic entity replacement and masking strategies RoBERTa-BiLSTM-CRF model**（英文标题：Liver Cancer Knowledge Graph Construction based on dynamic entity replacement and masking strategies RoBERTa-BiLSTM-CRF model）  \n  这篇论文构建肝癌知识图谱，使用 RoBERTa-BiLSTM-CRF 模型，主要贡献是实体识别准确率达 93.96%，有助于肝癌诊断辅助系统。\n\n- **Skin Cancer Machine Learning Model Tone Bias**（英文标题：Skin Cancer Machine Learning Model Tone Bias）  \n  作者分析皮肤癌模型的肤色偏置，主要发现是训练数据不平衡导致检测偏差，提供证据支持未来偏置修正技术。\n\n- **FAIREDU: A Multiple Regression-Based Method for Enhancing Fairness in Machine Learning Models for Educational Applications**（英文标题：FAIREDU: A Multiple Regression-Based Method for Enhancing Fairness in Machine Learning Models for Educational Applications）  \n  这篇快速提到的论文提出 FAIREDU 方法，提升 AI 在教育中的公平性，主要发现是处理多敏感特征时保持模型准确性。\n\n### 优化和算法创新\n- **Accelerated Preference Optimization for Large Language Model Alignment**（英文标题：Accelerated Preference Optimization for Large Language Model Alignment）  \n  作者使用 Nesterov 动量优化 LLM 偏好，主要贡献是比 DPO 更快收敛，在 AlpacaEval 上提升性能。\n\n- **Polynomial Time Cryptanalytic Extraction of Deep Neural Networks in the Hard-Label Setting**（英文标题：Polynomial Time Cryptanalytic Extraction of Deep Neural Networks in the Hard-Label Setting）  \n  这篇论文提出密码学提取 DNN 方法，主要发现是高效提取百万参数网络，揭示 DNN 安全漏洞。\n\n其他论文如量子计算、机器人学等主题较多，但相对次要，我这里仅快速掠过，例如\"Quantum Circuits for Sparse Matrix Multiplication and a Graph Laplacian\"（英文标题：Quantum Circuits for Sparse Matrix Multiplication and a Graph Laplacian）讨论量子电路优化，主要贡献是改进矩阵乘法效率，但不影响核心讨论。\n\n总体而言，今天的论文突显 AI 领域的快速迭代，尤其在 LLM 和多模态模型上，未来应用潜力巨大。更多细节可查阅 arXiv！",
  "papers": [
    {
      "arxiv_id": "2410.06428v1",
      "title": "Stress Detection on Code-Mixed Texts in Dravidian Languages using Machine Learning",
      "title_zh": "使用机器学习对德拉维语系语言代码混合文本进行压力检测",
      "authors": [
        "L. Ramos",
        "M. Shahiki-Tash",
        "Z. Ahani",
        "A. Eponon",
        "O. Kolesnikova",
        "H. Calvo"
      ],
      "abstract": "Stress is a common feeling in daily life, but it can affect mental well-being\nin some situations, the development of robust detection models is imperative.\nThis study introduces a methodical approach to the stress identification in\ncode-mixed texts for Dravidian languages. The challenge encompassed two\ndatasets, targeting Tamil and Telugu languages respectively. This proposal\nunderscores the importance of using uncleaned text as a benchmark to refine\nfuture classification methodologies, incorporating diverse preprocessing\ntechniques. Random Forest algorithm was used, featuring three textual\nrepresentations: TF-IDF, Uni-grams of words, and a composite of (1+2+3)-Grams\nof characters. The approach achieved a good performance for both linguistic\ncategories, achieving a Macro F1-score of 0.734 in Tamil and 0.727 in Telugu,\noverpassing results achieved with different complex techniques such as FastText\nand Transformer models. The results underscore the value of uncleaned data for\nmental state detection and the challenges classifying code-mixed texts for\nstress, indicating the potential for improved performance through cleaning\ndata, other preprocessing techniques, or more complex models.",
      "tldr_zh": "本研究针对 Dravidian 语言（Tamil 和 Telugu）的代码混合文本，开发了一种基于 Machine Learning 的压力检测方法，使用未经清理的文本作为基准数据集。方法采用 Random Forest 算法，结合 TF-IDF、Uni-grams of words 和 (1+2+3)-Grams of characters 等文本表示技术进行分类。实验结果显示，该方法在 Tamil 数据集上达到 Macro F1-score 0.734，在 Telugu 上达到 0.727，优于 FastText 和 Transformer 模型的表现，突显了未经清理数据在精神状态检测中的价值，并建议通过数据清理或其他预处理技术进一步提升性能。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.HC",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.06428v1",
      "published_date": "2024-10-08 23:49:31 UTC",
      "updated_date": "2024-10-08 23:49:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:22:33.551069"
    },
    {
      "arxiv_id": "2410.06427v1",
      "title": "NLP Case Study on Predicting the Before and After of the Ukraine-Russia and Hamas-Israel Conflicts",
      "title_zh": "NLP 案例研究：预测乌克兰-俄罗斯和哈马斯-以色列冲突前后情况",
      "authors": [
        "Jordan Miner",
        "John E. Ortega"
      ],
      "abstract": "We propose a method to predict toxicity and other textual attributes through\nthe use of natural language processing (NLP) techniques for two recent events:\nthe Ukraine-Russia and Hamas-Israel conflicts. This article provides a basis\nfor exploration in future conflicts with hopes to mitigate risk through the\nanalysis of social media before and after a conflict begins. Our work compiles\nseveral datasets from Twitter and Reddit for both conflicts in a before and\nafter separation with an aim of predicting a future state of social media for\navoidance. More specifically, we show that: (1) there is a noticeable\ndifference in social media discussion leading up to and following a conflict\nand (2) social media discourse on platforms like Twitter and Reddit is useful\nin identifying future conflicts before they arise. Our results show that\nthrough the use of advanced NLP techniques (both supervised and unsupervised)\ntoxicity and other attributes about language before and after a conflict is\npredictable with a low error of nearly 1.2 percent for both conflicts.",
      "tldr_zh": "本研究提出了一种使用自然语言处理(NLP)技术来预测乌克兰-俄罗斯和哈马斯-以色列冲突前后文本属性的方法，特别是针对毒性和其他语言特征，以期通过分析社交媒体数据减轻未来冲突风险。研究者编译了Twitter和Reddit的多个数据集，将其分为冲突前后部分，并通过监督和无监督NLP技术分析了社交媒体讨论的差异。结果显示，冲突前后讨论存在显著变化，且这些数据可用于提前识别潜在冲突，预测准确率高，错误率仅为1.2%。这项工作为未来冲突的预警和风险缓解提供了重要基础。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG",
        "I.2.7"
      ],
      "primary_category": "cs.CL",
      "comment": "The clusters created using topic modeling can be viewed at\n  https://naturallang.com/conflict/conflict.html",
      "pdf_url": "http://arxiv.org/pdf/2410.06427v1",
      "published_date": "2024-10-08 23:46:56 UTC",
      "updated_date": "2024-10-08 23:46:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:22:46.058801"
    },
    {
      "arxiv_id": "2410.06423v1",
      "title": "FAIREDU: A Multiple Regression-Based Method for Enhancing Fairness in Machine Learning Models for Educational Applications",
      "title_zh": "翻译失败",
      "authors": [
        "Nga Pham",
        "Minh Kha Do",
        "Tran Vu Dai",
        "Pham Ngoc Hung",
        "Anh Nguyen-Duc"
      ],
      "abstract": "Fairness in artificial intelligence and machine learning (AI/ML) models is\nbecoming critically important, especially as decisions made by these systems\nimpact diverse groups. In education, a vital sector for all countries, the\nwidespread application of AI/ML systems raises specific concerns regarding\nfairness. Current research predominantly focuses on fairness for individual\nsensitive features, which limits the comprehensiveness of fairness assessments.\nThis paper introduces FAIREDU, a novel and effective method designed to improve\nfairness across multiple sensitive features. Through extensive experiments, we\nevaluate FAIREDU effectiveness in enhancing fairness without compromising model\nperformance. The results demonstrate that FAIREDU addresses intersectionality\nacross features such as gender, race, age, and other sensitive features,\noutperforming state-of-the-art methods with minimal effect on model accuracy.\nThe paper also explores potential future research directions to enhance further\nthe method robustness and applicability to various machine-learning models and\ndatasets.",
      "tldr_zh": "本文提出 FAIREDU，一种基于多重回归（Multiple Regression-Based）的创新方法，旨在提升教育领域机器学习模型的公平性，特别是针对多个敏感特征（如性别、种族和年龄）的交叉性问题。相比现有方法，FAIREDU 通过实验验证，能够显著改善公平性，同时对模型准确性影响最小，在各种数据集上表现出优越性能。该研究还探讨了未来方向，以增强方法的稳健性和在不同机器学习模型中的适用性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.06423v1",
      "published_date": "2024-10-08 23:29:24 UTC",
      "updated_date": "2024-10-08 23:29:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:22:58.231164"
    },
    {
      "arxiv_id": "2410.06415v2",
      "title": "Biased AI can Influence Political Decision-Making",
      "title_zh": "偏见的 AI 能够影响政治决策",
      "authors": [
        "Jillian Fisher",
        "Shangbin Feng",
        "Robert Aron",
        "Thomas Richardson",
        "Yejin Choi",
        "Daniel W. Fisher",
        "Jennifer Pan",
        "Yulia Tsvetkov",
        "Katharina Reinecke"
      ],
      "abstract": "As modern AI models become integral to everyday tasks, concerns about their\ninherent biases and their potential impact on human decision-making have\nemerged. While bias in models are well-documented, less is known about how\nthese biases influence human decisions. This paper presents two interactive\nexperiments investigating the effects of partisan bias in AI language models on\npolitical decision-making. Participants interacted freely with either a biased\nliberal, biased conservative, or unbiased control model while completing\npolitical decision-making tasks. We found that participants exposed to\npolitically biased models were significantly more likely to adopt opinions and\nmake decisions aligning with the AI's bias, regardless of their personal\npolitical partisanship. However, we also discovered that prior knowledge about\nAI could lessen the impact of the bias, highlighting the possible importance of\nAI education for robust bias mitigation. Our findings not only highlight the\ncritical effects of interacting with biased AI and its ability to impact public\ndiscourse and political conduct, but also highlights potential techniques for\nmitigating these risks in the future.",
      "tldr_zh": "这篇论文探讨了AI模型中的党派偏见（partisan bias）如何影响人类政治决策，通过两个互动实验，让参与者与偏向自由派、偏向保守派或无偏见的AI语言模型（AI language models）互动完成决策任务。研究发现，暴露于偏见AI的参与者更可能采纳AI的观点并做出与之一致的决定，与个人政治立场无关。然而，先前对AI的知识能够减轻这种影响。论文强调了偏见AI对公共话语和政治行为的关键影响，并建议通过AI教育来缓解这些风险。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.06415v2",
      "published_date": "2024-10-08 22:56:00 UTC",
      "updated_date": "2024-11-04 20:12:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:23:10.808706"
    },
    {
      "arxiv_id": "2410.06405v1",
      "title": "Tackling the Abstraction and Reasoning Corpus with Vision Transformers: the Importance of 2D Representation, Positions, and Objects",
      "title_zh": "翻译失败",
      "authors": [
        "Wenhao Li",
        "Yudong Xu",
        "Scott Sanner",
        "Elias Boutros Khalil"
      ],
      "abstract": "The Abstraction and Reasoning Corpus (ARC) is a popular benchmark focused on\nvisual reasoning in the evaluation of Artificial Intelligence systems. In its\noriginal framing, an ARC task requires solving a program synthesis problem over\nsmall 2D images using a few input-output training pairs. In this work, we adopt\nthe recently popular data-driven approach to the ARC and ask whether a Vision\nTransformer (ViT) can learn the implicit mapping, from input image to output\nimage, that underlies the task. We show that a ViT -- otherwise a\nstate-of-the-art model for images -- fails dramatically on most ARC tasks even\nwhen trained on one million examples per task. This points to an inherent\nrepresentational deficiency of the ViT architecture that makes it incapable of\nuncovering the simple structured mappings underlying the ARC tasks. Building on\nthese insights, we propose ViTARC, a ViT-style architecture that unlocks some\nof the visual reasoning capabilities required by the ARC. Specifically, we use\na pixel-level input representation, design a spatially-aware tokenization\nscheme, and introduce a novel object-based positional encoding that leverages\nautomatic segmentation, among other enhancements. Our task-specific ViTARC\nmodels achieve a test solve rate close to 100% on more than half of the 400\npublic ARC tasks strictly through supervised learning from input-output grids.\nThis calls attention to the importance of imbuing the powerful (Vision)\nTransformer with the correct inductive biases for abstract visual reasoning\nthat are critical even when the training data is plentiful and the mapping is\nnoise-free. Hence, ViTARC provides a strong foundation for future research in\nvisual reasoning using transformer-based architectures.",
      "tldr_zh": "本论文探讨了使用Vision Transformer (ViT) 处理Abstraction and Reasoning Corpus (ARC) 基准测试的挑战，发现标准ViT即使训练一百万样本也无法有效学习ARC任务的隐式图像映射，这暴露了ViT架构在表示方面的固有缺陷。作者提出ViTARC，一种改进的ViT-style架构，通过采用像素级输入表示、空间感知的tokenization方案以及基于自动分割的物体位置编码等增强，实现对抽象视觉推理的更好支持。实验结果显示，ViTARC模型在超过一半的400个公共ARC任务上，通过监督学习达到了接近100%的测试解决率。该研究强调了为Vision Transformer注入正确归纳偏差的重要性，即使在数据充足且映射无噪声的情况下。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.06405v1",
      "published_date": "2024-10-08 22:25:34 UTC",
      "updated_date": "2024-10-08 22:25:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:23:24.015490"
    },
    {
      "arxiv_id": "2410.06395v1",
      "title": "Multimodal Representation Learning using Adaptive Graph Construction",
      "title_zh": "基于自适应图构建的多模态表示学习",
      "authors": [
        "Weichen Huang"
      ],
      "abstract": "Multimodal contrastive learning train neural networks by levergaing data from\nheterogeneous sources such as images and text. Yet, many current multimodal\nlearning architectures cannot generalize to an arbitrary number of modalities\nand need to be hand-constructed. We propose AutoBIND, a novel contrastive\nlearning framework that can learn representations from an arbitrary number of\nmodalites through graph optimization. We evaluate AutoBIND on Alzhiemer's\ndisease detection because it has real-world medical applicability and it\ncontains a broad range of data modalities. We show that AutoBIND outperforms\nprevious methods on this task, highlighting the generalizablility of the\napproach.",
      "tldr_zh": "本文提出 AutoBIND，一种新型的多模态对比学习框架，通过自适应图构建(Adaptive Graph Construction)来从任意数量的模态中学习表示，避免了传统架构的手动构建需求。AutoBIND 通过图优化技术处理异构数据源，如图像和文本，提高了模型的泛化能力。在阿尔茨海默病检测任务上，AutoBIND 超过了现有方法，展示了其在实际医疗应用中的优越性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.06395v1",
      "published_date": "2024-10-08 21:57:46 UTC",
      "updated_date": "2024-10-08 21:57:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:23:34.697799"
    },
    {
      "arxiv_id": "2410.07265v1",
      "title": "A Survey: Collaborative Hardware and Software Design in the Era of Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Cong Guo",
        "Feng Cheng",
        "Zhixu Du",
        "James Kiessling",
        "Jonathan Ku",
        "Shiyu Li",
        "Ziru Li",
        "Mingyuan Ma",
        "Tergel Molom-Ochir",
        "Benjamin Morris",
        "Haoxuan Shan",
        "Jingwei Sun",
        "Yitu Wang",
        "Chiyue Wei",
        "Xueying Wu",
        "Yuhao Wu",
        "Hao Frank Yang",
        "Jingyang Zhang",
        "Junyao Zhang",
        "Qilin Zheng",
        "Guanglei Zhou",
        "Hai",
        "Li",
        "Yiran Chen"
      ],
      "abstract": "The rapid development of large language models (LLMs) has significantly\ntransformed the field of artificial intelligence, demonstrating remarkable\ncapabilities in natural language processing and moving towards multi-modal\nfunctionality. These models are increasingly integrated into diverse\napplications, impacting both research and industry. However, their development\nand deployment present substantial challenges, including the need for extensive\ncomputational resources, high energy consumption, and complex software\noptimizations. Unlike traditional deep learning systems, LLMs require unique\noptimization strategies for training and inference, focusing on system-level\nefficiency. This paper surveys hardware and software co-design approaches\nspecifically tailored to address the unique characteristics and constraints of\nlarge language models. This survey analyzes the challenges and impacts of LLMs\non hardware and algorithm research, exploring algorithm optimization, hardware\ndesign, and system-level innovations. It aims to provide a comprehensive\nunderstanding of the trade-offs and considerations in LLM-centric computing\nsystems, guiding future advancements in AI. Finally, we summarize the existing\nefforts in this space and outline future directions toward realizing\nproduction-grade co-design methodologies for the next generation of large\nlanguage models and AI systems.",
      "tldr_zh": "这篇调查论文探讨了大型语言模型（LLMs）时代下硬件和软件协同设计的挑战与创新。论文分析了LLMs在计算资源需求、高能耗和软件优化等方面的独特问题，并总结了针对这些问题的算法优化、硬件设计以及系统级创新策略。通过全面审视现有努力，该研究揭示了LLMs计算系统的权衡与考虑，并为未来AI系统的生产级协同设计方法提供指导方向。",
      "categories": [
        "cs.AR",
        "cs.AI",
        "cs.LG",
        "cs.SE"
      ],
      "primary_category": "cs.AR",
      "comment": "Accepted by IEEE Circuits and Systems Magazine",
      "pdf_url": "http://arxiv.org/pdf/2410.07265v1",
      "published_date": "2024-10-08 21:46:52 UTC",
      "updated_date": "2024-10-08 21:46:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:23:45.828064"
    },
    {
      "arxiv_id": "2410.06385v2",
      "title": "Skin Cancer Machine Learning Model Tone Bias",
      "title_zh": "皮肤癌机器学习模型色调偏差",
      "authors": [
        "James Pope",
        "Md Hassanuzzaman",
        "William Chapman",
        "Huw Day",
        "Mingmar Sherpa",
        "Omar Emara",
        "Nirmala Adhikari",
        "Ayush Joshi"
      ],
      "abstract": "Background: Many open-source skin cancer image datasets are the result of\nclinical trials conducted in countries with lighter skin tones. Due to this\ntone imbalance, machine learning models derived from these datasets can perform\nwell at detecting skin cancer for lighter skin tones. Any tone bias in these\nmodels could introduce fairness concerns and reduce public trust in the\nartificial intelligence health field.\n  Methods: We examine a subset of images from the International Skin Imaging\nCollaboration (ISIC) archive that provide tone information. The subset has a\nsignificant tone imbalance. These imbalances could explain a model's tone bias.\nTo address this, we train models using the imbalanced dataset and a balanced\ndataset to compare against. The datasets are used to train a deep convolutional\nneural network model to classify the images as malignant or benign. We then\nevaluate the models' disparate impact, based on selection rate, relative to\ndark or light skin tone.\n  Results: Using the imbalanced dataset, we found that the model is\nsignificantly better at detecting malignant images in lighter tone resulting in\na disparate impact of 0.577. Using the balanced dataset, we found that the\nmodel is also significantly better at detecting malignant images in lighter\nversus darker tones with a disparate impact of 0.684. Using the imbalanced or\nbalanced dataset to train the model still results in a disparate impact well\nbelow the standard threshold of 0.80 which suggests the model is biased with\nrespect to skin tone.\n  Conclusion: The results show that typical skin cancer machine learning models\ncan be tone biased. These results provide evidence that diagnosis or tone\nimbalance is not the cause of the bias. Other techniques will be necessary to\nidentify and address the bias in these models, an area of future investigation.",
      "tldr_zh": "这篇论文探讨了皮肤癌机器学习模型的肤色偏见问题，指出许多开源图像数据集因来自浅肤色国家临床试验而导致模型在浅肤色检测上表现更好，可能引发公平性和公众信任问题。研究方法包括使用 International Skin Imaging Collaboration (ISIC) 档案的子集训练深度卷积神经网络模型，比较不平衡数据集和平衡数据集的效果，并通过选择率评估 disparate impact。结果显示，使用不平衡数据集时，模型在浅肤色恶性图像检测上更准确，disparate impact 为 0.577；使用平衡数据集时为 0.684，两者均低于 0.80 阈值，表明模型仍存在肤色偏见。结论强调，数据不平衡并非主要原因，需要进一步研究其他技术来识别和解决这种偏见。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.06385v2",
      "published_date": "2024-10-08 21:33:02 UTC",
      "updated_date": "2025-03-19 13:12:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:24:09.540132"
    },
    {
      "arxiv_id": "2410.06384v1",
      "title": "Validation of the Scientific Literature via Chemputation Augmented by Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Sebastian Pagel",
        "Michael Jirasek",
        "Leroy Cronin"
      ],
      "abstract": "Chemputation is the process of programming chemical robots to do experiments\nusing a universal symbolic language, but the literature can be error prone and\nhard to read due to ambiguities. Large Language Models (LLMs) have demonstrated\nremarkable capabilities in various domains, including natural language\nprocessing, robotic control, and more recently, chemistry. Despite significant\nadvancements in standardizing the reporting and collection of synthetic\nchemistry data, the automatic reproduction of reported syntheses remains a\nlabour-intensive task. In this work, we introduce an LLM-based chemical\nresearch agent workflow designed for the automatic validation of synthetic\nliterature procedures. Our workflow can autonomously extract synthetic\nprocedures and analytical data from extensive documents, translate these\nprocedures into universal XDL code, simulate the execution of the procedure in\na hardware-specific setup, and ultimately execute the procedure on an\nXDL-controlled robotic system for synthetic chemistry. This demonstrates the\npotential of LLM-based workflows for autonomous chemical synthesis with\nChemputers. Due to the abstraction of XDL this approach is safe, secure, and\nscalable since hallucinations will not be chemputable and the XDL can be both\nverified and encrypted. Unlike previous efforts, which either addressed only a\nlimited portion of the workflow, relied on inflexible hard-coded rules, or\nlacked validation in physical systems, our approach provides four realistic\nexamples of syntheses directly executed from synthetic literature. We\nanticipate that our workflow will significantly enhance automation in\nrobotically driven synthetic chemistry research, streamline data extraction,\nimprove the reproducibility, scalability, and safety of synthetic and\nexperimental chemistry.",
      "tldr_zh": "本文提出了一种基于 Large Language Models (LLMs) 增强的 Chemputation 工作流，用于自动验证化学合成文献程序。该工作流能自主提取合成程序和分析数据、翻译成通用 XDL 代码、模拟执行并在 XDL 控制的机器人系统中实际运行，从而提升实验的可重复性和安全性。与以往方法不同，该方法覆盖整个工作流程，并通过四个现实合成示例验证了其有效性，最终有望显著提高机器人驱动的合成化学研究的自动化和可扩展性。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.IR"
      ],
      "primary_category": "cs.AI",
      "comment": "22 pages, 7 figures, 34 references",
      "pdf_url": "http://arxiv.org/pdf/2410.06384v1",
      "published_date": "2024-10-08 21:31:42 UTC",
      "updated_date": "2024-10-08 21:31:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:24:10.739960"
    },
    {
      "arxiv_id": "2410.06378v1",
      "title": "Covering Numbers for Deep ReLU Networks with Applications to Function Approximation and Nonparametric Regression",
      "title_zh": "深度 ReLU 网络的覆盖数及其在函数逼近和非参数回归中的应用",
      "authors": [
        "Weigutian Ou",
        "Helmut Bölcskei"
      ],
      "abstract": "Covering numbers of families of (deep) ReLU networks have been used to\ncharacterize their approximation-theoretic performance, upper-bound the\nprediction error they incur in nonparametric regression, and quantify their\nclassification capacity. These results are based on covering number upper\nbounds obtained through the explicit construction of coverings. Lower bounds on\ncovering numbers do not seem to be available in the literature. The present\npaper fills this gap by deriving tight (up to a multiplicative constant) lower\nand upper bounds on the covering numbers of fully-connected networks with\nbounded weights, sparse networks with bounded weights, and fully-connected\nnetworks with quantized weights. Thanks to the tightness of the bounds, a\nfundamental understanding of the impact of sparsity, quantization, bounded vs.\nunbounded weights, and network output truncation can be developed. Furthermore,\nthe bounds allow to characterize the fundamental limits of neural network\ntransformation, including network compression, and lead to sharp upper bounds\non the prediction error in nonparametric regression through deep networks.\nSpecifically, we can remove a $\\log^6(n)$-factor in the best-known sample\ncomplexity rate in the estimation of Lipschitz functions through deep networks\nthereby establishing optimality. Finally, we identify a systematic relation\nbetween optimal nonparametric regression and optimal approximation through deep\nnetworks, unifying numerous results in the literature and uncovering general\nunderlying principles.",
      "tldr_zh": "本文研究了深度 ReLU 网络的 covering numbers，提供了一系列紧密的上下界，包括权重有界的全连接网络、稀疏网络以及量化权重网络。这些界限首次填补了文献中的下界空白，帮助揭示稀疏性、量化、有界权重和输出截断对网络性能的影响。在应用方面，该工作优化了非参数回归中的预测误差上界，具体移除了一个 $\\log^6(n)$ 因子，从而建立了 Lipschitz 函数估计的最优样本复杂度率，并统一了函数逼近与非参数回归的理论关系。",
      "categories": [
        "stat.ML",
        "cs.AI",
        "cs.IT",
        "cs.LG",
        "math.IT",
        "68T07, 41A25, 62G08"
      ],
      "primary_category": "stat.ML",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.06378v1",
      "published_date": "2024-10-08 21:23:14 UTC",
      "updated_date": "2024-10-08 21:23:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:24:23.960765"
    },
    {
      "arxiv_id": "2410.18109v1",
      "title": "NaVIP: An Image-Centric Indoor Navigation Solution for Visually Impaired People",
      "title_zh": "翻译失败",
      "authors": [
        "Jun Yu",
        "Yifan Zhang",
        "Badrinadh Aila",
        "Vinod Namboodiri"
      ],
      "abstract": "Indoor navigation is challenging due to the absence of satellite positioning.\nThis challenge is manifold greater for Visually Impaired People (VIPs) who lack\nthe ability to get information from wayfinding signage. Other sensor signals\n(e.g., Bluetooth and LiDAR) can be used to create turn-by-turn navigation\nsolutions with position updates for users. Unfortunately, these solutions\nrequire tags to be installed all around the environment or the use of fairly\nexpensive hardware. Moreover, these solutions require a high degree of manual\ninvolvement that raises costs, thus hampering scalability. We propose an image\ndataset and associated image-centric solution called NaVIP towards visual\nintelligence that is infrastructure-free and task-scalable, and can assist VIPs\nin understanding their surroundings. Specifically, we start by curating\nlarge-scale phone camera data in a four-floor research building, with 300K\nimages, to lay the foundation for creating an image-centric indoor navigation\nand exploration solution for inclusiveness. Every image is labelled with\nprecise 6DoF camera poses, details of indoor PoIs, and descriptive captions to\nassist VIPs. We benchmark on two main aspects: 1) positioning system and 2)\nexploration support, prioritizing training scalability and real-time inference,\nto validate the prospect of image-based solution towards indoor navigation. The\ndataset, code, and model checkpoints are made publicly available at\nhttps://github.com/junfish/VIP_Navi.",
      "tldr_zh": "本研究提出NaVIP，一种基于图像的室内导航解决方案，针对Visually Impaired People (VIPs)解决卫星定位缺失和无法读取路标等挑战。该系统构建了一个包含30万张手机摄像头图像的数据集，每个图像标注有精确的6DoF相机位姿、室内PoIs细节和描述性标题，实现无需基础设施的导航和探索支持。实验基准测试了定位系统和探索功能，强调训练可扩展性和实时推理，证明了图像中心方法的有效性，并公开了数据集、代码和模型检查点（https://github.com/junfish/VIP_Navi）。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "40 pages, 20 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.18109v1",
      "published_date": "2024-10-08 21:16:50 UTC",
      "updated_date": "2024-10-08 21:16:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:24:36.148882"
    },
    {
      "arxiv_id": "2410.06372v2",
      "title": "Cooperative and Asynchronous Transformer-based Mission Planning for Heterogeneous Teams of Mobile Robots",
      "title_zh": "针对异构移动机器人团队的合作且异步Transformer-based任务规划",
      "authors": [
        "Milad Farjadnasab",
        "Shahin Sirouspour"
      ],
      "abstract": "Cooperative mission planning for heterogeneous teams of mobile robots\npresents a unique set of challenges, particularly when operating under\ncommunication constraints and limited computational resources. To address these\nchallenges, we propose the Cooperative and Asynchronous Transformer-based\nMission Planning (CATMiP) framework, which leverages multi-agent reinforcement\nlearning (MARL) to coordinate distributed decision making among agents with\ndiverse sensing, motion, and actuation capabilities, operating under sporadic\nad hoc communication. A Class-based Macro-Action Decentralized Partially\nObservable Markov Decision Process (CMacDec-POMDP) is also formulated to\neffectively model asynchronous decision-making for heterogeneous teams of\nagents. The framework utilizes an asynchronous centralized training and\ndistributed execution scheme that is developed based on the Multi-Agent\nTransformer (MAT) architecture. This design allows a single trained model to\ngeneralize to larger environments and accommodate varying team sizes and\ncompositions. We evaluate CATMiP in a 2D grid-world simulation environment and\ncompare its performance against planning-based exploration methods. Results\ndemonstrate CATMiP's superior efficiency, scalability, and robustness to\ncommunication dropouts, highlighting its potential for real-world heterogeneous\nmobile robot systems. The code is available at\nhttps://github.com/mylad13/CATMiP.",
      "tldr_zh": "本论文提出了一种名为 CATMiP 的框架，用于异构移动机器人团队的合作任务规划，旨在解决通信约束和计算资源有限的挑战。CATMiP 利用多智能体强化学习 (MARL) 和基于 Multi-Agent Transformer (MAT) 的异步集中训练与分布式执行方案，结合 Class-based Macro-Action Decentralized Partially Observable Markov Decision Process (CMacDec-POMDP) 模型来协调团队中不同能力的代理异步决策。实验在 2D 网格世界模拟环境中显示，CATMiP 比基于规划的探索方法更高效、可扩展，并对通信中断具有更强的鲁棒性，为真实世界机器人系统提供了潜在应用。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "I.2.9; I.2.11"
      ],
      "primary_category": "cs.RO",
      "comment": "27 pages, 8 figures, this work has been submitted to Elsevier for\n  possible publication",
      "pdf_url": "http://arxiv.org/pdf/2410.06372v2",
      "published_date": "2024-10-08 21:14:09 UTC",
      "updated_date": "2025-01-14 22:43:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:24:47.469493"
    },
    {
      "arxiv_id": "2410.06370v2",
      "title": "HumVI: A Multilingual Dataset for Detecting Violent Incidents Impacting Humanitarian Aid",
      "title_zh": "翻译失败",
      "authors": [
        "Hemank Lamba",
        "Anton Abilov",
        "Ke Zhang",
        "Elizabeth M. Olson",
        "Henry k. Dambanemuya",
        "João c. Bárcia",
        "David S. Batista",
        "Christina Wille",
        "Aoife Cahill",
        "Joel Tetreault",
        "Alex Jaimes"
      ],
      "abstract": "Humanitarian organizations can enhance their effectiveness by analyzing data\nto discover trends, gather aggregated insights, manage their security risks,\nsupport decision-making, and inform advocacy and funding proposals. However,\ndata about violent incidents with direct impact and relevance for humanitarian\naid operations is not readily available. An automatic data collection and\nNLP-backed classification framework aligned with humanitarian perspectives can\nhelp bridge this gap. In this paper, we present HumVI - a dataset comprising\nnews articles in three languages (English, French, Arabic) containing instances\nof different types of violent incidents categorized by the humanitarian sector\nthey impact, e.g., aid security, education, food security, health, and\nprotection. Reliable labels were obtained for the dataset by partnering with a\ndata-backed humanitarian organization, Insecurity Insight. We provide multiple\nbenchmarks for the dataset, employing various deep learning architectures and\ntechniques, including data augmentation and mask loss, to address different\ntask-related challenges, e.g., domain expansion. The dataset is publicly\navailable at https://github.com/dataminr-ai/humvi-dataset.",
      "tldr_zh": "人道主义组织可以通过分析数据来提升效率，但目前缺乏关于影响援助行动的暴力事件数据。论文引入 HumVI 数据集，这是一个多语言（英语、法语、阿拉伯语）数据集，包含新闻文章并按影响领域（如援助安全、教育、粮食安全、健康和保护）分类标签，由 Insecurity Insight 组织提供可靠标注。研究采用 NLP 和深度学习技术，包括数据增强和 mask loss，来建立基准模型，处理多语言和领域扩展挑战。该数据集已公开在 GitHub 上，有助于自动数据收集和分类，支持人道主义决策。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG",
        "cs.SI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.06370v2",
      "published_date": "2024-10-08 21:08:13 UTC",
      "updated_date": "2024-10-15 20:23:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:24:58.633549"
    },
    {
      "arxiv_id": "2410.06366v1",
      "title": "Physics-Informed Regularization for Domain-Agnostic Dynamical System Modeling",
      "title_zh": "物理信息正则化用于领域无关动态系统建模",
      "authors": [
        "Zijie Huang",
        "Wanjia Zhao",
        "Jingdong Gao",
        "Ziniu Hu",
        "Xiao Luo",
        "Yadi Cao",
        "Yuanzhou Chen",
        "Yizhou Sun",
        "Wei Wang"
      ],
      "abstract": "Learning complex physical dynamics purely from data is challenging due to the\nintrinsic properties of systems to be satisfied. Incorporating physics-informed\npriors, such as in Hamiltonian Neural Networks (HNNs), achieves high-precision\nmodeling for energy-conservative systems. However, real-world systems often\ndeviate from strict energy conservation and follow different physical priors.\nTo address this, we present a framework that achieves high-precision modeling\nfor a wide range of dynamical systems from the numerical aspect, by enforcing\nTime-Reversal Symmetry (TRS) via a novel regularization term. It helps preserve\nenergies for conservative systems while serving as a strong inductive bias for\nnon-conservative, reversible systems. While TRS is a domain-specific physical\nprior, we present the first theoretical proof that TRS loss can universally\nimprove modeling accuracy by minimizing higher-order Taylor terms in ODE\nintegration, which is numerically beneficial to various systems regardless of\ntheir properties, even for irreversible systems. By integrating the TRS loss\nwithin neural ordinary differential equation models, the proposed model TREAT\ndemonstrates superior performance on diverse physical systems. It achieves a\nsignificant 11.5% MSE improvement in a challenging chaotic triple-pendulum\nscenario, underscoring TREAT's broad applicability and effectiveness.",
      "tldr_zh": "该研究针对从数据中学习复杂物理动态的挑战，提出了一种基于物理信息的正则化框架，用于无领域依赖的动态系统建模。该框架通过引入 Time-Reversal Symmetry (TRS) 损失作为新颖正则化项，帮助保守系统保持能量，并为非保守系统提供强归纳偏差，同时首次理论证明 TRS 损失能通过最小化 ODE 积分中的高阶 Taylor 项来普遍提升建模准确性。提出的 TREAT 模型整合了 TRS 损失，并在神经 ODE 框架中应用，实验显示在混沌的三重摆场景中实现了 11.5% 的 MSE 改善，证明了其广泛适用性和有效性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted to The Thirty-eighth Annual Conference on Neural Information\n  Processing Systems (NeurIPS 2024)",
      "pdf_url": "http://arxiv.org/pdf/2410.06366v1",
      "published_date": "2024-10-08 21:04:01 UTC",
      "updated_date": "2024-10-08 21:04:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:25:11.805365"
    },
    {
      "arxiv_id": "2410.10872v1",
      "title": "ToolBridge: An Open-Source Dataset to Equip LLMs with External Tool Capabilities",
      "title_zh": "翻译失败",
      "authors": [
        "Zhenchao Jin",
        "Mengchen Liu",
        "Dongdong Chen",
        "Lingting Zhu",
        "Yunsheng Li",
        "Lequan Yu"
      ],
      "abstract": "Through the integration of external tools, large language models (LLMs) such\nas GPT-4o and Llama 3.1 significantly expand their functional capabilities,\nevolving from elementary conversational agents to general-purpose assistants.\nWe argue that the primary drivers of these advancements are the quality and\ndiversity of the training data. However, the existing LLMs with external tool\nintegration provide only limited transparency regarding their datasets and data\ncollection methods, which has led to the initiation of this research.\nSpecifically, in this paper, our objective is to elucidate the detailed process\ninvolved in constructing datasets that empower LLMs to effectively learn how to\nutilize external tools and make this information available to the public\nthrough the introduction of ToolBridge. ToolBridge proposes to employ a\ncollection of general open-access datasets as its raw dataset pool and applies\na series of strategies to identify appropriate data entries from the pool for\nexternal tool API insertions. By supervised fine-tuning on these curated data\nentries, LLMs can invoke external tools in appropriate contexts to boost their\npredictive accuracy, particularly for basic functions including data\nprocessing, numerical computation, and factual retrieval. Our experiments\nrigorously isolates model architectures and training configurations, focusing\nexclusively on the role of data. The experimental results indicate that LLMs\ntrained on ToolBridge demonstrate consistent performance improvements on both\nstandard benchmarks and custom evaluation datasets. All the associated code and\ndata will be open-source at https://github.com/CharlesPikachu/ToolBridge,\npromoting transparency and facilitating the broader community to explore\napproaches for equipping LLMs with external tools capabilities.",
      "tldr_zh": "该论文介绍了ToolBridge，这是一个开源数据集，旨在帮助大型语言模型(LLMs)学习整合外部工具能力，从而从基本对话代理演变为通用助手。研究者通过从公开数据集池中筛选数据并插入外部工具API，然后应用监督微调策略，使LLMs能够在适当上下文中调用工具，提升数据处理、数值计算和事实检索等功能的预测准确性。实验结果显示，使用ToolBridge训练的LLMs在标准基准和自定义数据集上表现出一致性能提升，所有代码和数据已在GitHub开源，促进社区进一步探索这一领域。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "technical report",
      "pdf_url": "http://arxiv.org/pdf/2410.10872v1",
      "published_date": "2024-10-08 20:54:40 UTC",
      "updated_date": "2024-10-08 20:54:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:25:22.483912"
    },
    {
      "arxiv_id": "2410.06355v2",
      "title": "Context-Aware Command Understanding for Tabletop Scenarios",
      "title_zh": "上下文感知命令理解在桌面场景中的应用",
      "authors": [
        "Paul Gajewski",
        "Antonio Galiza Cerdeira Gonzalez",
        "Bipin Indurkhya"
      ],
      "abstract": "This paper presents a novel hybrid algorithm designed to interpret natural\nhuman commands in tabletop scenarios. By integrating multiple sources of\ninformation, including speech, gestures, and scene context, the system extracts\nactionable instructions for a robot, identifying relevant objects and actions.\nThe system operates in a zero-shot fashion, without reliance on predefined\nobject models, enabling flexible and adaptive use in various environments. We\nassess the integration of multiple deep learning models, evaluating their\nsuitability for deployment in real-world robotic setups. Our algorithm performs\nrobustly across different tasks, combining language processing with visual\ngrounding. In addition, we release a small dataset of video recordings used to\nevaluate the system. This dataset captures real-world interactions in which a\nhuman provides instructions in natural language to a robot, a contribution to\nfuture research on human-robot interaction. We discuss the strengths and\nlimitations of the system, with particular focus on how it handles multimodal\ncommand interpretation, and its ability to be integrated into symbolic robotic\nframeworks for safe and explainable decision-making.",
      "tldr_zh": "这篇论文提出了一种新型混合算法，用于在桌面场景中实现上下文感知的命令理解，该算法通过整合语音、手势和场景上下文来提取可操作指令，包括识别相关对象和动作。系统采用zero-shot方式，不依赖预定义对象模型，从而在各种环境中表现出灵活性和适应性，并结合语言处理和visual grounding在不同任务中表现出色。研究评估了多个deep learning models的整合，并发布了一个小型数据集，记录了人类通过自然语言向机器人提供指令的真实互动，以支持未来的人机交互研究。最后，论文讨论了系统的优势，如处理multimodal command interpretation的能力，以及与符号机器人框架的整合以实现安全和可解释决策。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.06355v2",
      "published_date": "2024-10-08 20:46:39 UTC",
      "updated_date": "2024-10-10 10:59:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:25:35.461766"
    },
    {
      "arxiv_id": "2410.06347v1",
      "title": "Solving Multi-Goal Robotic Tasks with Decision Transformer",
      "title_zh": "翻译失败",
      "authors": [
        "Paul Gajewski",
        "Dominik Żurek",
        "Marcin Pietroń",
        "Kamil Faber"
      ],
      "abstract": "Artificial intelligence plays a crucial role in robotics, with reinforcement\nlearning (RL) emerging as one of the most promising approaches for robot\ncontrol. However, several key challenges hinder its broader application. First,\nmany RL methods rely on online learning, which requires either real-world\nhardware or advanced simulation environments--both of which can be costly,\ntime-consuming, and impractical. Offline reinforcement learning offers a\nsolution, enabling models to be trained without ongoing access to physical\nrobots or simulations.\n  A second challenge is learning multi-goal tasks, where robots must achieve\nmultiple objectives simultaneously. This adds complexity to the training\nprocess, as the model must generalize across different goals. At the same time,\ntransformer architectures have gained significant popularity across various\ndomains, including reinforcement learning. Yet, no existing methods effectively\ncombine offline training, multi-goal learning, and transformer-based\narchitectures.\n  In this paper, we address these challenges by introducing a novel adaptation\nof the decision transformer architecture for offline multi-goal reinforcement\nlearning in robotics. Our approach integrates goal-specific information into\nthe decision transformer, allowing it to handle complex tasks in an offline\nsetting. To validate our method, we developed a new offline reinforcement\nlearning dataset using the Panda robotic platform in simulation. Our extensive\nexperiments demonstrate that the decision transformer can outperform\nstate-of-the-art online reinforcement learning methods.",
      "tldr_zh": "本论文探讨了强化学习（RL）在机器人控制中的挑战，包括在线学习的高成本和多目标任务的复杂性，并提出了一种基于 Decision Transformer 的新方法来解决这些问题。该方法将目标特定信息整合到 Decision Transformer 架构中，实现离线多目标强化学习，从而无需实时访问物理机器人或模拟环境。为验证效果，研究者开发了一个新的离线 RL 数据集，使用 Panda 机器人平台进行实验，结果显示该方法在性能上超过了现有的在线 RL 方法。总的来说，这为机器人多目标任务的训练提供了更高效、可扩展的解决方案。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.06347v1",
      "published_date": "2024-10-08 20:35:30 UTC",
      "updated_date": "2024-10-08 20:35:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:25:45.986637"
    },
    {
      "arxiv_id": "2410.06332v2",
      "title": "Boolean Nearest Neighbor Language in the Knowledge Compilation Map",
      "title_zh": "布尔最近邻语言在知识编译地图中",
      "authors": [
        "Ondřej Čepek",
        "Jelena Glišić"
      ],
      "abstract": "The Boolean Nearest Neighbor (BNN) representation of Boolean functions was\nrecently introduced by Hajnal, Liu and Turan. A BNN representation of $f$ is a\npair $(P,N)$ of sets of Boolean vectors (called positive and negative\nprototypes) where $f(x)=1$ for every positive prototype $x \\in P$, $f(x)=0$ for\nall every negative prototype $x \\in N$, and the value $f(x)$ for $x \\not\\in P\n\\cup N$ is determined by the type of the closest prototype. The main aim of\nthis paper is to determine the position of the BNN language in the Knowledge\nCompilation Map (KCM). To this end, we derive results which compare the\nsuccinctness of the BNN language to several standard languages from KCM, and\ndetermine the complexity status of most standard queries and transformations\nfor BNN inputs.",
      "tldr_zh": "该论文探讨了 Boolean Nearest Neighbor (BNN) 语言在 Knowledge Compilation Map (KCM) 中的位置，BNN 是一种布尔函数表示，使用正负原型集（P 和 N）来定义函数值，并通过最近原型确定其他输入的值。研究通过比较 BNN 与其他 KCM 标准语言的简洁性，分析了标准查询和转换的复杂性。结果为布尔函数表示和知识编译领域提供了新的基准和洞见。",
      "categories": [
        "cs.AI",
        "68T30",
        "I.2.4"
      ],
      "primary_category": "cs.AI",
      "comment": "19 pages, 5 figures, 2 tables",
      "pdf_url": "http://arxiv.org/pdf/2410.06332v2",
      "published_date": "2024-10-08 20:12:55 UTC",
      "updated_date": "2024-10-28 18:20:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:25:58.426583"
    },
    {
      "arxiv_id": "2410.06331v3",
      "title": "Locate-then-edit for Multi-hop Factual Recall under Knowledge Editing",
      "title_zh": "翻译失败",
      "authors": [
        "Zhuoran Zhang",
        "Yongxiang Li",
        "Zijian Kan",
        "Keyuan Cheng",
        "Lijie Hu",
        "Di Wang"
      ],
      "abstract": "The locate-then-edit paradigm has shown significant promise for knowledge\nediting (KE) in Large Language Models (LLMs). While previous methods perform\nwell on single-hop fact recall tasks, they consistently struggle with multi-hop\nfactual recall tasks involving newly edited knowledge. In this paper,\nleveraging tools in mechanistic interpretability, we first identify that in\nmulti-hop tasks, LLMs tend to retrieve knowledge with implicit subject\ninformation from deeper MLP layers, unlike single-hop tasks, which rely on\nshallow layers. This distinction explains the poor performance of current\nmethods in multi-hop queries, as they primarily focus on editing shallow layers\nwith single-hop edit prompts, leaving deeper layers unchanged. To address this,\nwe propose IFMET, a novel locate-then-edit KE approach designed to edit both\nshallow and deep MLP layers. Beyond single-hop editing prompts, IFMET further\nincorporates multi-hop editing prompts to locate and modify knowledge across\ndifferent stages of reasoning. Experimental results demonstrate that IFMET\nsignificantly improves performance on multi-hop factual recall tasks,\novercoming the limitations of previous locate-then-edit methods",
      "tldr_zh": "本研究发现，现有的 locate-then-edit 范式在 Large Language Models (LLMs) 的知识编辑 (KE) 中虽适用于单跳事实回忆任务，但无法有效处理多跳任务，因为 LLMs 在多跳查询中依赖更深的 MLP 层来检索隐含主体信息，而浅层编辑无法覆盖这些层。针对此问题，作者提出 IFMET，一种新型 locate-then-edit 方法，通过结合 mechanistic interpretability 工具，并使用多跳编辑提示来定位并修改浅层和深层 MLP 层，从而实现更全面的知识编辑。实验结果显示，IFMET 在多跳事实回忆任务上显著提升了性能，克服了现有方法的局限性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "24 pages",
      "pdf_url": "http://arxiv.org/pdf/2410.06331v3",
      "published_date": "2024-10-08 20:12:11 UTC",
      "updated_date": "2025-02-01 12:21:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:26:10.148954"
    },
    {
      "arxiv_id": "2410.06328v2",
      "title": "Auto-Evolve: Enhancing Large Language Model's Performance via Self-Reasoning Framework",
      "title_zh": "Auto-Evolve：通过自推理",
      "authors": [
        "Krishna Aswani",
        "Huilin Lu",
        "Pranav Patankar",
        "Priya Dhalwani",
        "Iris Tan",
        "Jayant Ganeshmohan",
        "Simon Lacasse"
      ],
      "abstract": "Recent advancements in prompt engineering strategies, such as\nChain-of-Thought (CoT) and Self-Discover, have demonstrated significant\npotential in improving the reasoning abilities of Large Language Models (LLMs).\nHowever, these state-of-the-art (SOTA) prompting strategies rely on single or\nfixed set of static seed reasoning modules like \"think step by step\" or \"break\ndown this problem\" intended to simulate human approach to problem-solving. This\nconstraint limits the flexibility of models in tackling diverse problems\neffectively. In this paper, we introduce Auto-Evolve, a novel framework that\nenables LLMs to self-create dynamic reasoning modules and downstream action\nplan, resulting in significant improvements over current SOTA methods. We\nevaluate Auto-Evolve on the challenging BigBench-Hard (BBH) dataset with Claude\n2.0, Claude 3 Sonnet, Mistral Large, and GPT 4, where it consistently\noutperforms the SOTA prompt strategies. Auto-Evolve outperforms CoT by up to\n10.4% and on an average by 7% across these four models. Our framework\nintroduces two innovations: a) Auto-Evolve dynamically generates reasoning\nmodules for each task while aligning with human reasoning paradigm, thus\neliminating the need for predefined templates. b) We introduce an iterative\nrefinement component, that incrementally refines instruction guidance for LLMs\nand helps boost performance by average 2.8% compared to doing it in a single\nstep.",
      "tldr_zh": "本研究提出Auto-Evolve框架，通过自推理机制提升Large Language Models (LLMs)的性能，解决了现有提示策略如Chain-of-Thought (CoT)依赖静态模块的局限性。Auto-Evolve允许LLMs动态生成任务特定的推理模块和下游行动计划，同时引入迭代精炼组件来逐步优化指令指导。实验在BigBench-Hard (BBH)数据集上评估，使用Claude 2.0、Claude 3 Sonnet、Mistral Large和GPT-4等模型，结果显示Auto-Evolve比CoT平均提升7%，最高达10.4%，并额外通过迭代过程平均提高2.8%的性能。总体而言，该框架增强了LLMs的灵活性和有效性，无需预定义模板。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted at EMNLP 2024",
      "pdf_url": "http://arxiv.org/pdf/2410.06328v2",
      "published_date": "2024-10-08 20:07:47 UTC",
      "updated_date": "2024-10-11 20:39:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:26:23.208103"
    },
    {
      "arxiv_id": "2410.06317v1",
      "title": "Learning in complex action spaces without policy gradients",
      "title_zh": "翻译失败",
      "authors": [
        "Arash Tavakoli",
        "Sina Ghiassian",
        "Nemanja Rakićević"
      ],
      "abstract": "Conventional wisdom suggests that policy gradient methods are better suited\nto complex action spaces than action-value methods. However, foundational\nstudies have shown equivalences between these paradigms in small and finite\naction spaces (O'Donoghue et al., 2017; Schulman et al., 2017a). This raises\nthe question of why their computational applicability and performance diverge\nas the complexity of the action space increases. We hypothesize that the\napparent superiority of policy gradients in such settings stems not from\nintrinsic qualities of the paradigm, but from universal principles that can\nalso be applied to action-value methods to serve similar functionality. We\nidentify three such principles and provide a framework for incorporating them\ninto action-value methods. To support our hypothesis, we instantiate this\nframework in what we term QMLE, for Q-learning with maximum likelihood\nestimation. Our results show that QMLE can be applied to complex action spaces\nwith a controllable computational cost that is comparable to that of policy\ngradient methods, all without using policy gradients. Furthermore, QMLE\ndemonstrates strong performance on the DeepMind Control Suite, even when\ncompared to the state-of-the-art methods such as DMPO and D4PG.",
      "tldr_zh": "本研究质疑传统观点，即policy gradient方法比action-value methods更适合复杂动作空间，并假设这种优势源于可应用于action-value methods的通用原则。作者识别了三个关键原则，并提出一个框架将这些原则融入action-value methods中，具体实例化为QMLE（Q-learning with maximum likelihood estimation）。实验结果显示，QMLE在复杂动作空间中计算成本可控、无需policy gradients，且在DeepMind Control Suite上表现出色，甚至优于DMPO和D4PG等最先进方法。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.06317v1",
      "published_date": "2024-10-08 19:49:34 UTC",
      "updated_date": "2024-10-08 19:49:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:26:34.521791"
    },
    {
      "arxiv_id": "2410.06311v1",
      "title": "A Comparative Study of Hybrid Models in Health Misinformation Text Classification",
      "title_zh": "健康误传文本分类中混合模型的比较研究",
      "authors": [
        "Mkululi Sikosana",
        "Oluwaseun Ajao",
        "Sean Maudsley-Barton"
      ],
      "abstract": "This study evaluates the effectiveness of machine learning (ML) and deep\nlearning (DL) models in detecting COVID-19-related misinformation on online\nsocial networks (OSNs), aiming to develop more effective tools for countering\nthe spread of health misinformation during the pan-demic. The study trained and\ntested various ML classifiers (Naive Bayes, SVM, Random Forest, etc.), DL\nmodels (CNN, LSTM, hybrid CNN+LSTM), and pretrained language models\n(DistilBERT, RoBERTa) on the \"COVID19-FNIR DATASET\". These models were\nevaluated for accuracy, F1 score, recall, precision, and ROC, and used\npreprocessing techniques like stemming and lemmatization. The results showed\nSVM performed well, achieving a 94.41% F1-score. DL models with Word2Vec\nembeddings exceeded 98% in all performance metrics (accuracy, F1 score, recall,\nprecision & ROC). The CNN+LSTM hybrid models also exceeded 98% across\nperformance metrics, outperforming pretrained models like DistilBERT and\nRoBERTa. Our study concludes that DL and hybrid DL models are more effective\nthan conventional ML algorithms for detecting COVID-19 misinformation on OSNs.\nThe findings highlight the importance of advanced neural network approaches and\nlarge-scale pretraining in misinformation detection. Future research should\noptimize these models for various misinformation types and adapt to changing\nOSNs, aiding in combating health misinformation.",
      "tldr_zh": "这篇论文比较了机器学习(ML)和深度学习(DL)模型在检测 COVID-19 相关误传信息方面的有效性，训练并测试了多种模型如 Naive Bayes、SVM、Random Forest、CNN、LSTM、混合 CNN+LSTM，以及预训练模型如 DistilBERT 和 RoBERTa，使用 \"COVID19-FNIR DATASET\" 和预处理技术进行评估。结果显示，SVM 模型的 F1-score 达到 94.41%，而 DL 模型结合 Word2Vec 嵌入和 CNN+LSTM 混合模型在准确率、F1-score、召回率、精确率和 ROC 等指标上均超过 98%，优于预训练模型。研究结论认为，DL 和混合 DL 模型比传统 ML 算法更有效，并建议未来优化这些模型以适应不同误传信息类型和变化的在线社交网络(OSNs)。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.LG",
        "H.3.3"
      ],
      "primary_category": "cs.IR",
      "comment": "8 pages, 4 tables presented at the OASIS workshop of the ACM\n  Hypertext and Social Media Conference 2024",
      "pdf_url": "http://arxiv.org/pdf/2410.06311v1",
      "published_date": "2024-10-08 19:43:37 UTC",
      "updated_date": "2024-10-08 19:43:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:26:49.742153"
    },
    {
      "arxiv_id": "2410.18107v1",
      "title": "In-Context Code-Text Learning for Bimodal Software Engineering",
      "title_zh": "翻译失败",
      "authors": [
        "Xunzhu Tang",
        "Liran Wang",
        "Yonghui Liu",
        "Linzheng Chai",
        "Jian Yang",
        "Zhoujun Li",
        "Haoye Tian",
        "Jacques Klein",
        "Tegawende F. Bissyande"
      ],
      "abstract": "Bimodal software analysis initially appeared to be within reach with the\nadvent of large language models. Unfortunately, the complex interplay of\nnatural language text and code in software engineering, presents unique\nchallenges that prevent pretrained models to generalize to a variety of tasks.\nWe postulate that in-context learning for the code-text bimodality is a\npromising avenue. This paper thus introduces a comprehensive study of\nin-context code-text learning, focusing on leveraging pretrained CodeLLAMA\nmodels.\n  We consider a diverse dataset encompassing 23 software engineering tasks,\nwhich we transform in an in-context learning format. To effectively extract\ninformative features, we propose a configurable prompt template. Our proposed\npipeline, InCTRL, then unifies prompt learning across various software\nengineering tasks. Extensive evaluation on the study datasets demonstrates the\nsuperiority of INCTRL-models in few-shot performance, surpassing\nstate-of-the-art models including the support model, CodeLLAMA. Typically, we\nobserve that applied to the CodeLLAMA model, INCTRL brings improvements in\nterms of precision (at least about 12\\%) and recall (up to 93.88\\%) on various\ntasks. For example, on the task of program repair, INCTRL improves the BLEU\nscore of CodeLLAMA by 85 points, while for clone detection, INCTRL achieves an\nimprovement of 69 percentage points. Moreover, INCTRL-models offer\nstate-of-the-art performance when using retrieval-augmented generation on\nindividual downstream tasks. Finally, we qualitatively analyze the benefits of\nINCTRL over CodeLLAMA and open-source all models for broader impact.\n  We make our code and dataset publicly available at: \\begin{center}\n  {\\url{https://anonymous.4open.science/r/inctrl-B65B}} \\end{center}",
      "tldr_zh": "该论文探讨了in-context learning在双模态软件工程（code和text）中的应用，以解决预训练模型如CodeLLAMA在任务泛化上的挑战。研究者构建了一个包含23个软件工程任务的多样数据集，并提出InCTRL管道，使用可配置的prompt template实现统一的prompt learning。实验结果显示，InCTRL模型在few-shot performance上优于现有模型，提高了precision（至少12%）和recall（高达93.88%），例如在程序修复任务中BLEU分数提升85点，在克隆检测中提升69百分点。此外，InCTRL支持检索增强生成，并开源了代码和数据集以促进更广泛的应用。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.18107v1",
      "published_date": "2024-10-08 19:42:00 UTC",
      "updated_date": "2024-10-08 19:42:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:26:59.594895"
    },
    {
      "arxiv_id": "2410.06303v2",
      "title": "Compositional Risk Minimization",
      "title_zh": "组合风险最小化",
      "authors": [
        "Divyat Mahajan",
        "Mohammad Pezeshki",
        "Charles Arnal",
        "Ioannis Mitliagkas",
        "Kartik Ahuja",
        "Pascal Vincent"
      ],
      "abstract": "Compositional generalization is a crucial step towards developing\ndata-efficient intelligent machines that generalize in human-like ways. In this\nwork, we tackle a challenging form of distribution shift, termed compositional\nshift, where some attribute combinations are completely absent at training but\npresent in the test distribution. This shift tests the model's ability to\ngeneralize compositionally to novel attribute combinations in discriminative\ntasks. We model the data with flexible additive energy distributions, where\neach energy term represents an attribute, and derive a simple alternative to\nempirical risk minimization termed compositional risk minimization (CRM). We\nfirst train an additive energy classifier to predict the multiple attributes\nand then adjust this classifier to tackle compositional shifts. We provide an\nextensive theoretical analysis of CRM, where we show that our proposal\nextrapolates to special affine hulls of seen attribute combinations. Empirical\nevaluations on benchmark datasets confirms the improved robustness of CRM\ncompared to other methods from the literature designed to tackle various forms\nof subpopulation shifts.",
      "tldr_zh": "该论文针对组合偏移（compositional shift）问题提出了一种组合风险最小化（compositional risk minimization, CRM）方法，以提升模型在训练数据中缺失属性组合时的泛化能力。CRM 使用加性能量分布（additive energy distributions）建模数据，每个能量项对应一个属性，先训练一个加性能量分类器预测多个属性，然后调整分类器以应对组合偏移。理论分析表明，CRM 能够外推到已见属性组合的特殊仿射 hulls，并在基准数据集上的实证评估中显示出比其他处理子群体偏移方法更高的鲁棒性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Preprint. Under Review",
      "pdf_url": "http://arxiv.org/pdf/2410.06303v2",
      "published_date": "2024-10-08 19:25:07 UTC",
      "updated_date": "2025-02-10 23:16:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:27:10.577865"
    },
    {
      "arxiv_id": "2410.06299v1",
      "title": "A Taxonomy of Collectible Card Games from a Game-Playing AI Perspective",
      "title_zh": "翻译失败",
      "authors": [
        "Ronaldo e Silva Vieira",
        "Anderson Rocha Tavares",
        "Luiz Chaimowicz"
      ],
      "abstract": "Collectible card games are challenging, widely played games that have\nreceived increasing attention from the AI research community in recent years.\nDespite important breakthroughs, the field still poses many unresolved\nchallenges. This work aims to help further research on the genre by proposing a\ntaxonomy of collectible card games by analyzing their rules, mechanics, and\ngame modes from the perspective of game-playing AI research. To achieve this,\nwe studied a set of popular games and provided a thorough discussion about\ntheir characteristics.",
      "tldr_zh": "本研究从AI游戏玩家的视角，提出一个Collectible Card Games的taxonomy，通过分析这些游戏的规则(mechanics)、机制和游戏模式，以帮助AI研究社区更好地理解其特性。研究者考察了多款流行游戏，并讨论了AI在该领域面临的未解决挑战，如游戏复杂性和策略优化。总体而言，这一taxonomy旨在推动Collectible Card Games的AI研究，促进未来突破。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "16 pages, accepted at the International Conference on Entertainment\n  Computing (ICEC) 2024",
      "pdf_url": "http://arxiv.org/pdf/2410.06299v1",
      "published_date": "2024-10-08 19:04:12 UTC",
      "updated_date": "2024-10-08 19:04:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:27:22.413768"
    },
    {
      "arxiv_id": "2410.06293v1",
      "title": "Accelerated Preference Optimization for Large Language Model Alignment",
      "title_zh": "加速偏好优化用于大型语言模型对齐",
      "authors": [
        "Jiafan He",
        "Huizhuo Yuan",
        "Quanquan Gu"
      ],
      "abstract": "Reinforcement Learning from Human Feedback (RLHF) has emerged as a pivotal\ntool for aligning large language models (LLMs) with human preferences. Direct\nPreference Optimization (DPO), one of the most popular approaches, formulates\nRLHF as a policy optimization problem without explicitly estimating the reward\nfunction. It overcomes the stability and efficiency issues of two-step\napproaches, which typically involve first estimating the reward function and\nthen optimizing the policy via proximal policy optimization (PPO). Since RLHF\nis essentially an optimization problem, and it is well-known that momentum\ntechniques can accelerate optimization both theoretically and empirically, a\nnatural question arises: Can RLHF be accelerated by momentum? This paper\nanswers this question in the affirmative. In detail, we first show that the\niterative preference optimization method can be viewed as a proximal point\nmethod. Based on this observation, we propose a general Accelerated Preference\nOptimization (APO) framework, which unifies many existing preference\noptimization algorithms and employs Nesterov's momentum technique to speed up\nthe alignment of LLMs. Theoretically, we demonstrate that APO can achieve a\nfaster convergence rate than the standard iterative preference optimization\nmethods, including DPO and Self-Play Preference Optimization (SPPO).\nEmpirically, we show the superiority of APO over DPO, iterative DPO, and other\nstrong baselines for RLHF on the AlpacaEval 2.0 benchmark.",
      "tldr_zh": "这篇论文提出了一种Accelerated Preference Optimization (APO)框架，用于加速Reinforcement Learning from Human Feedback (RLHF)对大型语言模型(LLMs)的对齐过程。APO将迭代偏好优化视为近端点方法，并引入Nesterov's momentum技术，以提升优化效率和稳定性，从而统一了现有算法如Direct Preference Optimization (DPO)和Self-Play Preference Optimization (SPPO)。理论上，APO实现了比DPO和SPPO更快的收敛率；实验结果显示，在AlpacaEval 2.0基准上，APO优于DPO及其变体和其他基线模型。总的来说，该框架为LLMs对齐提供了更高效的解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "44 pages, 10 tables",
      "pdf_url": "http://arxiv.org/pdf/2410.06293v1",
      "published_date": "2024-10-08 18:51:01 UTC",
      "updated_date": "2024-10-08 18:51:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:27:34.817065"
    },
    {
      "arxiv_id": "2410.06287v2",
      "title": "Non-Halting Queries: Exploiting Fixed Points in LLMs",
      "title_zh": "非停止查询：利用 LLMs 中的固定",
      "authors": [
        "Ghaith Hammouri",
        "Kemal Derya",
        "Berk Sunar"
      ],
      "abstract": "We introduce a new vulnerability that exploits fixed points in autoregressive\nmodels and use it to craft queries that never halt. More precisely, for\nnon-halting queries, the LLM never samples the end-of-string token <eos>. We\nrigorously analyze the conditions under which the non-halting anomaly presents\nitself. In particular, at temperature zero, we prove that if a repeating\n(cyclic) token sequence is observed at the output beyond the context size, then\nthe LLM does not halt.\n  We demonstrate non-halting queries in many experiments performed in base\nunaligned models where repeating prompts immediately lead to a non-halting\ncyclic behavior as predicted by the analysis. Further, we develop a simple\nrecipe that takes the same fixed points observed in the base model and creates\na prompt structure to target aligned models. We demonstrate the recipe's\nsuccess in sending every major model released over the past year into a\nnon-halting state with the same simple prompt even over higher temperatures.\nFurther, we devise an experiment with 100 randomly selected tokens and show\nthat the recipe to create non-halting queries succeeds with high success rates\nranging from 97% for GPT-4o to 19% for Gemini Pro 1.5. These results show that\nthe proposed adversarial recipe succeeds in bypassing alignment at one to two\norders of magnitude higher rates compared to earlier reports.\n  We also study gradient-based direct inversion using ARCA to craft new short\nprompts to induce the non-halting state. We inverted 10,000 random repeating\n2-cycle outputs for llama-3.1-8b-instruct. Out of 10,000 three-token inverted\nprompts 1,512 yield non-halting queries reaching a rate of 15%. Our experiments\nwith ARCA show that non-halting may be easily induced with as few as 3 input\ntokens with high probability. Overall, our experiments demonstrate that\nnon-halting queries are prevalent and relatively easy to find.",
      "tldr_zh": "本论文揭示了LLM中的新漏洞，通过利用fixed points来创建non-halting queries，使模型永不生成结束标记<eos>。研究者分析了这种现象的条件，证明在温度为零时，输出中的循环序列会导致模型不停止，并开发了一个简单提示结构来针对基础和对齐模型诱发非停止行为。实验结果显示，该方法在主要模型上成功率极高，如GPT-4o达97%、Gemini Pro 1.5达19%，并通过ARCA的梯度-based逆向方法，使用少至3个输入tokens即可高概率诱发non-halting状态。整体发现表明，这种查询在LLM中普遍且易于创建，突显了模型安全隐患。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.06287v2",
      "published_date": "2024-10-08 18:38:32 UTC",
      "updated_date": "2025-02-24 17:35:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:27:47.775652"
    },
    {
      "arxiv_id": "2410.06277v4",
      "title": "Solving Functional Optimization with Deep Networks and Variational Principles",
      "title_zh": "翻译失败",
      "authors": [
        "Kawisorn Kamtue",
        "Jose M. F. Moura",
        "Orathai Sangpetch"
      ],
      "abstract": "Can neural networks solve math problems using first a principle alone? This\npaper shows how to leverage the fundamental theorem of the calculus of\nvariations to design deep neural networks to solve functional optimization\nwithout requiring training data (e.g., ground-truth optimal solutions). Our\napproach is particularly crucial when the solution is a function defined over\nan unknown interval or support\\textemdash such as in minimum-time control\nproblems. By incorporating the necessary conditions satisfied by the optimal\nfunction solution, as derived from the calculus of variation, in the design of\nthe deep architecture, CalVNet leverages overparameterized neural networks to\nlearn these optimal functions directly. We validate CalVNet by showing that,\nwithout relying on ground-truth data and simply incorporating first principles,\nit successfully derives the Kalman filter for linear filtering, the bang-bang\noptimal control for minimum-time problems, and finds geodesics on manifolds.\nOur results demonstrate that CalVNet can be trained in an unsupervised manner,\nwithout relying on ground-truth data, establishing a promising framework for\naddressing general, potentially unsolved functional optimization problems that\nstill lack analytical solutions.",
      "tldr_zh": "这篇论文提出了一种名为 CalVNet 的深度神经网络方法，利用变分微积分（calculus of variations）的基本定理来解决函数优化问题，而无需依赖训练数据（如 ground-truth optimal solutions）。该方法通过将最优函数的必要条件融入网络架构设计中，实现对未知区间或支持（如最小时间控制问题）的直接学习。实验验证显示，CalVNet 在无监督条件下成功推导出 Kalman filter、最小时间问题的 bang-bang optimal control，以及流形上的 geodesics。总体而言，这为处理一般函数优化问题，特别是缺乏解析解的场景，提供了一个有前景的框架。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "math.OC"
      ],
      "primary_category": "cs.LG",
      "comment": "16 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.06277v4",
      "published_date": "2024-10-08 18:21:35 UTC",
      "updated_date": "2025-03-11 21:28:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:27:59.448108"
    },
    {
      "arxiv_id": "2410.06273v1",
      "title": "PREDICT: Preference Reasoning by Evaluating Decomposed preferences Inferred from Candidate Trajectories",
      "title_zh": "翻译失败",
      "authors": [
        "Stephane Aroca-Ouellette",
        "Natalie Mackraz",
        "Barry-John Theobald",
        "Katherine Metcalf"
      ],
      "abstract": "Accommodating human preferences is essential for creating AI agents that\ndeliver personalized and effective interactions. Recent work has shown the\npotential for LLMs to infer preferences from user interactions, but they often\nproduce broad and generic preferences, failing to capture the unique and\nindividualized nature of human preferences. This paper introduces PREDICT, a\nmethod designed to enhance the precision and adaptability of inferring\npreferences. PREDICT incorporates three key elements: (1) iterative refinement\nof inferred preferences, (2) decomposition of preferences into constituent\ncomponents, and (3) validation of preferences across multiple trajectories. We\nevaluate PREDICT on two distinct environments: a gridworld setting and a new\ntext-domain environment (PLUME). PREDICT more accurately infers nuanced human\npreferences improving over existing baselines by 66.2\\% (gridworld environment)\nand 41.0\\% (PLUME).",
      "tldr_zh": "本研究提出PREDICT方法，通过从候选轨迹中推断并评估分解后的偏好，来提升AI代理适应人类个性化偏好的能力。PREDICT的关键元素包括：(1)对推断偏好进行迭代精炼，(2)将偏好分解成组成部分，以及(3)在多个轨迹上进行验证，从而实现更精确的偏好推理。实验在gridworld环境和新的文本域环境(PLUME)中进行，结果显示PREDICT比现有基线提高了66.2%（gridworld）和41.0%（PLUME）的准确性，为创建个性化AI交互奠定了基础。",
      "categories": [
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.06273v1",
      "published_date": "2024-10-08 18:16:41 UTC",
      "updated_date": "2024-10-08 18:16:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:28:10.346568"
    },
    {
      "arxiv_id": "2410.06271v1",
      "title": "Probing the Robustness of Theory of Mind in Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Christian Nickel",
        "Laura Schrewe",
        "Lucie Flek"
      ],
      "abstract": "With the success of ChatGPT and other similarly sized SotA LLMs, claims of\nemergent human like social reasoning capabilities, especially Theory of Mind\n(ToM), in these models have appeared in the scientific literature. On the one\nhand those ToM-capabilities have been successfully tested using tasks styled\nsimilar to those used in psychology (Kosinski, 2023). On the other hand, follow\nup studies showed that those capabilities vanished when the tasks were slightly\naltered (Ullman, 2023). In this work we introduce a novel dataset of 68 tasks\nfor probing ToM in LLMs, including potentially challenging variations which are\nassigned to 10 complexity classes. This way it is providing novel insights into\nthe challenges LLMs face with those task variations. We evaluate the ToM\nperformance of four SotA open source LLMs on our dataset and the dataset\nintroduced by (Kosinski, 2023). The overall low goal accuracy across all\nevaluated models indicates only a limited degree of ToM capabilities. The LLMs'\nperformance on simple complexity class tasks from both datasets are similar.\nWhereas we find a consistent tendency in all tested LLMs to perform poorly on\ntasks that require the realization that an agent has knowledge of automatic\nstate changes in its environment, even when those are spelled out to the model.\nFor task complications that change the relationship between objects by\nreplacing prepositions, we notice a performance drop in all models, with the\nstrongest impact on the mixture-of-experts model. With our dataset of tasks\ngrouped by complexity we offer directions for further research on how to\nstabilize and advance ToM capabilities in LLM.",
      "tldr_zh": "这篇论文探讨了大型语言模型(LLMs)中Theory of Mind (ToM)能力的鲁棒性，通过引入一个包含68个任务的新数据集，这些任务分为10个复杂度级别，包括挑战性变体，以揭示模型在任务修改下的表现。研究评估了四个SotA开源LLMs在该数据集和Kosinski (2023)数据集上的ToM性能，结果显示整体准确率较低，表明LLMs的ToM能力有限。特别地，模型在涉及代理知晓环境自动状态变化的任务上表现较差，且任务变体（如改变对象关系的介词替换）导致性能显著下降，为未来稳定和提升LLMs的ToM能力提供了研究方向。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.06271v1",
      "published_date": "2024-10-08 18:13:27 UTC",
      "updated_date": "2024-10-08 18:13:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:28:23.805765"
    },
    {
      "arxiv_id": "2410.06264v2",
      "title": "Think While You Generate: Discrete Diffusion with Planned Denoising",
      "title_zh": "翻译失败",
      "authors": [
        "Sulin Liu",
        "Juno Nam",
        "Andrew Campbell",
        "Hannes Stärk",
        "Yilun Xu",
        "Tommi Jaakkola",
        "Rafael Gómez-Bombarelli"
      ],
      "abstract": "Discrete diffusion has achieved state-of-the-art performance, outperforming\nor approaching autoregressive models on standard benchmarks. In this work, we\nintroduce Discrete Diffusion with Planned Denoising (DDPD), a novel framework\nthat separates the generation process into two models: a planner and a\ndenoiser. At inference time, the planner selects which positions to denoise\nnext by identifying the most corrupted positions in need of denoising,\nincluding both initially corrupted and those requiring additional refinement.\nThis plan-and-denoise approach enables more efficient reconstruction during\ngeneration by iteratively identifying and denoising corruptions in the optimal\norder. DDPD outperforms traditional denoiser-only mask diffusion methods,\nachieving superior results on language modeling benchmarks such as text8,\nOpenWebText, and token-based image generation on ImageNet $256 \\times 256$.\nNotably, in language modeling, DDPD significantly reduces the performance gap\nbetween diffusion-based and autoregressive methods in terms of generative\nperplexity. Code is available at https://github.com/liusulin/DDPD.",
      "tldr_zh": "本论文提出了一种名为 Discrete Diffusion with Planned Denoising (DDPD) 的新框架，用于提升离散扩散模型的生成性能，通过将过程分为 planner 和 denoiser 两个模型来实现。Planner 负责识别并优先处理最需要去噪的位置，包括初始损坏和后续精炼部分，从而优化生成顺序和效率。实验结果显示，DDPD 在语言建模基准如 text8 和 OpenWebText 以及图像生成任务（如 ImageNet $256 \\times 256$）上，超过了传统 denoiser-only 方法，并显著缩小了 diffusion-based 与 autoregressive 方法在生成 perplexity 上的差距。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.CV",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2410.06264v2",
      "published_date": "2024-10-08 18:03:34 UTC",
      "updated_date": "2025-04-10 01:26:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:28:35.182743"
    },
    {
      "arxiv_id": "2410.06243v1",
      "title": "Unsupervised Model Diagnosis",
      "title_zh": "无监督模型诊断",
      "authors": [
        "Yinong Oliver Wang",
        "Eileen Li",
        "Jinqi Luo",
        "Zhaoning Wang",
        "Fernando De la Torre"
      ],
      "abstract": "Ensuring model explainability and robustness is essential for reliable\ndeployment of deep vision systems. Current methods for evaluating robustness\nrely on collecting and annotating extensive test sets. While this is common\npractice, the process is labor-intensive and expensive with no guarantee of\nsufficient coverage across attributes of interest. Recently, model diagnosis\nframeworks have emerged leveraging user inputs (e.g., text) to assess the\nvulnerability of the model. However, such dependence on human can introduce\nbias and limitation given the domain knowledge of particular users. This paper\nproposes Unsupervised Model Diagnosis (UMO), that leverages generative models\nto produce semantic counterfactual explanations without any user guidance.\nGiven a differentiable computer vision model (i.e., the target model), UMO\noptimizes for the most counterfactual directions in a generative latent space.\nOur approach identifies and visualizes changes in semantics, and then matches\nthese changes to attributes from wide-ranging text sources, such as\ndictionaries or language models. We validate the framework on multiple vision\ntasks (e.g., classification, segmentation, keypoint detection). Extensive\nexperiments show that our unsupervised discovery of semantic directions can\ncorrectly highlight spurious correlations and visualize the failure mode of\ntarget models without any human intervention.",
      "tldr_zh": "本论文提出Unsupervised Model Diagnosis (UMO)，一种无需用户指导的框架，用于评估深度视觉模型的可解释性和鲁棒性，以解决传统方法依赖大量标注测试集的局限性。UMO利用生成模型在潜在空间中优化语义反事实方向，识别并可视化语义变化，并通过匹配字典或语言模型等文本来源来突出模型的潜在漏洞。实验在分类、分割和关键点检测等视觉任务上验证了该方法，能够无监督地发现虚假相关性和模型失败模式，提升了诊断效率和准确性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "9 pages, 9 figures, 3 tables",
      "pdf_url": "http://arxiv.org/pdf/2410.06243v1",
      "published_date": "2024-10-08 17:59:03 UTC",
      "updated_date": "2024-10-08 17:59:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:28:46.464149"
    },
    {
      "arxiv_id": "2410.06240v1",
      "title": "Using Crank-Nikolson Scheme to Solve the Korteweg-de Vries (KdV) Equation",
      "title_zh": "翻译失败",
      "authors": [
        "Qiming Wu"
      ],
      "abstract": "The Korteweg-de Vries (KdV) equation is a fundamental partial differential\nequation that models wave propagation in shallow water and other dispersive\nmedia. Accurately solving the KdV equation is essential for understanding wave\ndynamics in physics and engineering applications. This project focuses on\nimplementing the Crank-Nicolson scheme, a finite difference method known for\nits stability and accuracy, to solve the KdV equation. The Crank-Nicolson\nscheme's implicit nature allows for a more stable numerical solution,\nespecially in handling the dispersive and nonlinear terms of the KdV equation.\nWe investigate the performance of the scheme through various test cases,\nanalyzing its convergence and error behavior. The results demonstrate that the\nCrank-Nicolson method provides a robust approach for solving the KdV equation,\nwith improved accuracy over traditional explicit methods. Code is available at\nthe end of the paper.",
      "tldr_zh": "本文研究了使用 Crank-Nicolson scheme 来求解 Korteweg-de Vries (KdV) Equation，这是一个建模浅水波传播和其他色散介质波动态的关键偏微分方程。Crank-Nicolson scheme 作为一种隐式有限差分方法，能够提供更高的稳定性和准确性，尤其在处理 KdV 方程的色散和非线性项时表现出色。通过各种测试案例，研究分析了该方案的收敛性和误差行为，结果表明其比传统显式方法更鲁棒且准确。代码已在论文末尾提供，以支持进一步应用。",
      "categories": [
        "math.NA",
        "cs.AI",
        "cs.NA"
      ],
      "primary_category": "math.NA",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.06240v1",
      "published_date": "2024-10-08 17:54:20 UTC",
      "updated_date": "2024-10-08 17:54:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:28:59.267247"
    },
    {
      "arxiv_id": "2410.06238v1",
      "title": "EVOLvE: Evaluating and Optimizing LLMs For Exploration",
      "title_zh": "EVOLvE：评估和优化 LLMs 用于探索",
      "authors": [
        "Allen Nie",
        "Yi Su",
        "Bo Chang",
        "Jonathan N. Lee",
        "Ed H. Chi",
        "Quoc V. Le",
        "Minmin Chen"
      ],
      "abstract": "Despite their success in many domains, large language models (LLMs) remain\nunder-studied in scenarios requiring optimal decision-making under uncertainty.\nThis is crucial as many real-world applications, ranging from personalized\nrecommendations to healthcare interventions, demand that LLMs not only predict\nbut also actively learn to make optimal decisions through exploration. In this\nwork, we measure LLMs' (in)ability to make optimal decisions in bandits, a\nstate-less reinforcement learning setting relevant to many applications. We\ndevelop a comprehensive suite of environments, including both context-free and\ncontextual bandits with varying task difficulties, to benchmark LLMs'\nperformance. Motivated by the existence of optimal exploration algorithms, we\npropose efficient ways to integrate this algorithmic knowledge into LLMs: by\nproviding explicit algorithm-guided support during inference; and through\nalgorithm distillation via in-context demonstrations and fine-tuning, using\nsynthetic data generated from these algorithms. Impressively, these techniques\nallow us to achieve superior exploration performance with smaller models,\nsurpassing larger models on various tasks. We conducted an extensive ablation\nstudy to shed light on various factors, such as task difficulty and data\nrepresentation, that influence the efficiency of LLM exploration. Additionally,\nwe conduct a rigorous analysis of the LLM's exploration efficiency using the\nconcept of regret, linking its ability to explore to the model size and\nunderlying algorithm.",
      "tldr_zh": "这篇论文评估了大型语言模型(LLMs)在不确定环境下进行最优决策的能力，特别是针对Bandits（一种无状态强化学习场景）。研究者开发了全面的环境套件，包括无上下文和有上下文的Bandits任务，以基准测试LLMs的表现，并提出了整合最优探索算法的方法，如显式算法指导和算法蒸馏（通过in-context demonstrations和fine-tuning合成数据）。结果显示，这些技术使较小LLMs模型在多种任务上超越更大模型，实现了更高效的探索性能。论文还进行了广泛的消融研究和遗憾(regret)分析，探讨了任务难度、数据表示等因素对LLMs探索效率的影响。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "28 pages",
      "pdf_url": "http://arxiv.org/pdf/2410.06238v1",
      "published_date": "2024-10-08 17:54:03 UTC",
      "updated_date": "2024-10-08 17:54:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:29:11.254951"
    },
    {
      "arxiv_id": "2410.06237v1",
      "title": "BUMBLE: Unifying Reasoning and Acting with Vision-Language Models for Building-wide Mobile Manipulation",
      "title_zh": "BUMBLE：利用视觉-语言模型统一推理和行动，用于建筑规模的移动操控",
      "authors": [
        "Rutav Shah",
        "Albert Yu",
        "Yifeng Zhu",
        "Yuke Zhu",
        "Roberto Martín-Martín"
      ],
      "abstract": "To operate at a building scale, service robots must perform very long-horizon\nmobile manipulation tasks by navigating to different rooms, accessing different\nfloors, and interacting with a wide and unseen range of everyday objects. We\nrefer to these tasks as Building-wide Mobile Manipulation. To tackle these\ninherently long-horizon tasks, we introduce BUMBLE, a unified Vision-Language\nModel (VLM)-based framework integrating open-world RGBD perception, a wide\nspectrum of gross-to-fine motor skills, and dual-layered memory. Our extensive\nevaluation (90+ hours) indicates that BUMBLE outperforms multiple baselines in\nlong-horizon building-wide tasks that require sequencing up to 12 ground truth\nskills spanning 15 minutes per trial. BUMBLE achieves 47.1% success rate\naveraged over 70 trials in different buildings, tasks, and scene layouts from\ndifferent starting rooms and floors. Our user study demonstrates 22% higher\nsatisfaction with our method than state-of-the-art mobile manipulation methods.\nFinally, we demonstrate the potential of using increasingly-capable foundation\nmodels to push performance further. For more information, see\nhttps://robin-lab.cs.utexas.edu/BUMBLE/",
      "tldr_zh": "该研究提出BUMBLE框架，利用Vision-Language Models (VLM)统一推理和行动，实现建筑规模的移动操作任务，包括导航不同房间和楼层以及与各种日常物体的交互。BUMBLE整合了开放世界的RGBD感知、从粗到细的运动技能以及双层记忆系统，以处理这些长时序任务。在超过90小时的评估中，BUMBLE在涉及多达12个技能的试验中平均成功率达47.1%，优于基线模型，且用户满意度比最先进方法高22%。这项工作展示了使用更先进的基础模型进一步提升机器人性能的潜力。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "7 Figures, 2 Tables, 11 Pages",
      "pdf_url": "http://arxiv.org/pdf/2410.06237v1",
      "published_date": "2024-10-08 17:52:29 UTC",
      "updated_date": "2024-10-08 17:52:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:29:24.278990"
    },
    {
      "arxiv_id": "2410.06234v2",
      "title": "TEOChat: A Large Vision-Language Assistant for Temporal Earth Observation Data",
      "title_zh": "TEOChat：一种用于时序地球观测数据的大型视觉语言助手",
      "authors": [
        "Jeremy Andrew Irvin",
        "Emily Ruoyu Liu",
        "Joyce Chuyi Chen",
        "Ines Dormoy",
        "Jinyoung Kim",
        "Samar Khanna",
        "Zhuo Zheng",
        "Stefano Ermon"
      ],
      "abstract": "Large vision and language assistants have enabled new capabilities for\ninterpreting natural images. These approaches have recently been adapted to\nearth observation data, but they are only able to handle single image inputs,\nlimiting their use for many real-world tasks. In this work, we develop a new\nvision and language assistant called TEOChat that can engage in conversations\nabout temporal sequences of earth observation data. To train TEOChat, we curate\nan instruction-following dataset composed of many single image and temporal\ntasks including building change and damage assessment, semantic change\ndetection, and temporal scene classification. We show that TEOChat can perform\na wide variety of spatial and temporal reasoning tasks, substantially\noutperforming previous vision and language assistants, and even achieving\ncomparable or better performance than several specialist models trained to\nperform specific tasks. Furthermore, TEOChat achieves impressive zero-shot\nperformance on a change detection and change question answering dataset,\noutperforms GPT-4o and Gemini 1.5 Pro on multiple temporal tasks, and exhibits\nstronger single image capabilities than a comparable single image\ninstruction-following model on scene classification, visual question answering,\nand captioning. We publicly release our data, model, and code at\nhttps://github.com/ermongroup/TEOChat .",
      "tldr_zh": "本文提出TEOChat，一种大型视觉语言助手，专门处理时间序列的地球观测数据（Temporal Earth Observation Data），能够进行关于多时间点图像的对话，从而超越现有模型仅限于单图像输入的限制。通过构建一个包含建筑变化评估、语义变化检测和时间场景分类等任务的指令遵循数据集，TEOChat实现了高效的空间和时间推理。实验显示，TEOChat在零样本变化检测和问题回答任务上表现出色，甚至优于GPT-4o和Gemini 1.5 Pro，并在单图像任务中表现强劲。作者公开了数据集、模型和代码，以促进进一步研究。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Published at ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2410.06234v2",
      "published_date": "2024-10-08 17:45:51 UTC",
      "updated_date": "2025-01-27 01:45:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:29:35.978143"
    },
    {
      "arxiv_id": "2410.06232v4",
      "title": "Range, not Independence, Drives Modularity in Biologically Inspired Representations",
      "title_zh": "范围而非独立性驱动了生物启发表示中的模块性",
      "authors": [
        "Will Dorrell",
        "Kyle Hsu",
        "Luke Hollingsworth",
        "Jin Hwa Lee",
        "Jiajun Wu",
        "Chelsea Finn",
        "Peter E Latham",
        "Tim EJ Behrens",
        "James CR Whittington"
      ],
      "abstract": "Why do biological and artificial neurons sometimes modularise, each encoding\na single meaningful variable, and sometimes entangle their representation of\nmany variables? In this work, we develop a theory of when biologically inspired\nnetworks -- those that are nonnegative and energy efficient -- modularise their\nrepresentation of source variables (sources). We derive necessary and\nsufficient conditions on a sample of sources that determine whether the neurons\nin an optimal biologically-inspired linear autoencoder modularise. Our theory\napplies to any dataset, extending far beyond the case of statistical\nindependence studied in previous work. Rather we show that sources modularise\nif their support is ``sufficiently spread''. From this theory, we extract and\nvalidate predictions in a variety of empirical studies on how data distribution\naffects modularisation in nonlinear feedforward and recurrent neural networks\ntrained on supervised and unsupervised tasks. Furthermore, we apply these ideas\nto neuroscience data, showing that range independence can be used to understand\nthe mixing or modularising of spatial and reward information in entorhinal\nrecordings in seemingly conflicting experiments. Further, we use these results\nto suggest alternate origins of mixed-selectivity, beyond the predominant\ntheory of flexible nonlinear classification. In sum, our theory prescribes\nprecise conditions on when neural activities modularise, providing tools for\ninducing and elucidating modular representations in brains and machines.",
      "tldr_zh": "本研究探讨了生物启发表示（biologically inspired representations）中模块化（modularity）的驱动因素，提出范围（range）而非独立性（independence）是关键决定因素。研究推导了必要和充分条件，表明在非负和能量高效的线性自编码器中，源变量（sources）的支持范围“足够分散”时，神经元才会模块化表示。实验验证了这一理论在非线性前馈和循环神经网络上的预测，包括监督和无监督任务，并应用于神经科学数据，解释了海马旁回（entorhinal）记录中空间和奖励信息的混合或模块化现象。该理论为理解和诱导大脑及机器中的模块化表示提供了新工具，并质疑了混合选择性（mixed-selectivity）的传统非线性分类起源。",
      "categories": [
        "q-bio.NC",
        "cs.AI",
        "cs.LG",
        "cs.NE"
      ],
      "primary_category": "q-bio.NC",
      "comment": "37 pages, 12 figures. WD and KH contributed equally; LH and JHL\n  contributed equally",
      "pdf_url": "http://arxiv.org/pdf/2410.06232v4",
      "published_date": "2024-10-08 17:41:37 UTC",
      "updated_date": "2025-04-11 14:14:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:29:47.264875"
    },
    {
      "arxiv_id": "2410.18105v1",
      "title": "Improving Embedding Accuracy for Document Retrieval Using Entity Relationship Maps and Model-Aware Contrastive Sampling",
      "title_zh": "翻译失败",
      "authors": [
        "Thea Aviss"
      ],
      "abstract": "In this paper we present APEX-Embedding-7B (Advanced Processing for Epistemic\neXtraction), a 7-billion parameter decoder-only text Feature Extraction Model,\nspecifically designed for Document Retrieval-Augmented Generation (RAG) tasks.\nOur approach employs two training techniques that yield an emergent improvement\nin factual focus: (1) Pre-convergence interrupted fine-tuning using Structured\nEntity Relationship Maps as training data input: designed to shift the model's\nattention and create a bias towards factual content rather than semantic style\n- this enhances plain text performance despite not being directly trained for\nit; and (2) Model-Aware Contrastive Sampling, creating a balanced and evenly\ndistributed collation map of hard and soft negatives directly informed by the\nbase model's competency. This combined methodology yields significant\nimprovements, enhancing plain text query/document pair retrieval to achieve an\nabsolute rank@1 accuracy of 90.86% (an increase of 6.26% compared to the next\nleading model) in our evaluation, and reducing training data input context size\nby an average of 37.71% compared to plain text for both queries and document\ntexts. Based on our evaluations, our model establishes a new state-of-the-art\nstandard in text feature extraction for longer context document retrieval\ntasks.",
      "tldr_zh": "本研究提出APEX-Embedding-7B，一种7亿参数的解码器-only文本特征提取模型，专门针对文档检索增强生成(RAG)任务，以提升嵌入准确性。模型采用两种关键训练技术：(1) 使用Structured Entity Relationship Maps的预收敛中断微调，引导模型偏向事实内容而非语义风格；(2) Model-Aware Contrastive Sampling，通过平衡硬负例和软负例来优化样本分布。实验结果显示，该方法将rank@1准确率提升至90.86%（比领先模型高6.26%），并平均减少37.71%的训练数据输入上下文大小，从而为更长上下文的文档检索任务设定新标准。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.IR",
      "comment": "10 Pages, 9 Figures",
      "pdf_url": "http://arxiv.org/pdf/2410.18105v1",
      "published_date": "2024-10-08 17:36:48 UTC",
      "updated_date": "2024-10-08 17:36:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:29:58.569209"
    },
    {
      "arxiv_id": "2410.06225v1",
      "title": "A Timeline and Analysis for Representation Plasticity in Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Akshat Kannan"
      ],
      "abstract": "The ability to steer AI behavior is crucial to preventing its long term\ndangerous and catastrophic potential. Representation Engineering (RepE) has\nemerged as a novel, powerful method to steer internal model behaviors, such as\n\"honesty\", at a top-down level. Understanding the steering of representations\nshould thus be placed at the forefront of alignment initiatives. Unfortunately,\ncurrent efforts to understand plasticity at this level are highly neglected.\nThis paper aims to bridge the knowledge gap and understand how LLM\nrepresentation stability, specifically for the concept of \"honesty\", and model\nplasticity evolve by applying steering vectors extracted at different\nfine-tuning stages, revealing differing magnitudes of shifts in model behavior.\nThe findings are pivotal, showing that while early steering exhibits high\nplasticity, later stages have a surprisingly responsive critical window. This\npattern is observed across different model architectures, signaling that there\nis a general pattern of model plasticity that can be used for effective\nintervention. These insights greatly contribute to the field of AI\ntransparency, addressing a pressing lack of efficiency limiting our ability to\neffectively steer model behavior.",
      "tldr_zh": "本研究分析了大型语言模型(LLMs)中表示可塑性的时间线，聚焦于Representation Engineering (RepE)如何引导模型行为，如“honesty”。通过在不同微调阶段提取并应用steering vectors，论文揭示了模型表示稳定性和行为转变的动态变化，显示早期阶段表现出高可塑性，而后期存在一个关键响应窗口。结果表明，这种可塑性模式在多种模型架构中普遍存在，为有效干预AI行为提供了通用指导。这些发现有助于提升AI透明度，并解决引导模型效率不足的问题。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.06225v1",
      "published_date": "2024-10-08 17:34:15 UTC",
      "updated_date": "2024-10-08 17:34:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:30:14.188212"
    },
    {
      "arxiv_id": "2410.06215v3",
      "title": "DataEnvGym: Data Generation Agents in Teacher Environments with Student Feedback",
      "title_zh": "翻译失败",
      "authors": [
        "Zaid Khan",
        "Elias Stengel-Eskin",
        "Jaemin Cho",
        "Mohit Bansal"
      ],
      "abstract": "The process of creating training data to teach models is currently driven by\nhumans, who manually analyze model weaknesses and plan how to create data that\nimproves a student model. Approaches using LLMs as annotators reduce human\neffort, but still require humans to interpret feedback from evaluations and\ncontrol the LLM to produce data the student needs. Automating this\nlabor-intensive process by creating autonomous data generation agents - or\nteachers - is desirable, but requires environments that can simulate the\nfeedback-driven, iterative, closed loop of data creation. To enable rapid,\nscalable testing for such agents and their modules, we introduce DataEnvGym, a\ntestbed of teacher environments for data generation agents. DataEnvGym frames\ndata generation as a sequential decision-making task, involving an agent\nconsisting of a data generation policy (which generates a plan for creating\ntraining data) and a data generation engine (which transforms the plan into\ndata), inside an environment that provides student feedback. The agent's goal\nis to improve student performance. Students are iteratively trained and\nevaluated on generated data, and their feedback (in the form of errors or weak\nskills) is reported to the agent after each iteration. DataEnvGym includes\nmultiple teacher environment instantiations across 3 levels of structure in the\nstate representation and action space. More structured environments are based\non inferred skills and offer more interpretability and curriculum control. We\nsupport 4 domains (math, code, VQA, and tool-use) and test multiple students\nand teachers. Example agents in our teaching environments can iteratively\nimprove students across tasks and settings. Moreover, we show that environments\nteach different skill levels and test variants of key modules, pointing to\nfuture work in improving data generation agents, engines, and feedback\nmechanisms.",
      "tldr_zh": "该研究引入了DataEnvGym，一种测试环境，用于开发和评估自主数据生成代理（Teacher Agents），以自动化训练数据创建过程并减少人类干预。DataEnvGym将数据生成框架为顺序决策任务，代理包括数据生成策略（生成数据计划）和数据生成引擎（执行计划），在环境中通过学生反馈（如错误或弱技能）进行迭代优化，目标是提升学生模型性能。实验覆盖4个领域（math、code、VQA和tool-use），展示了代理能逐步改善学生表现，并支持不同状态表示和动作空间的结构级别，为未来优化数据生成代理、引擎和反馈机制提供了测试基础。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "ICLR 2025 Spotlight; Project Page: https://DataEnvGym.github.io",
      "pdf_url": "http://arxiv.org/pdf/2410.06215v3",
      "published_date": "2024-10-08 17:20:37 UTC",
      "updated_date": "2025-03-13 17:30:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:30:22.644010"
    },
    {
      "arxiv_id": "2410.06209v8",
      "title": "LeanAgent: Lifelong Learning for Formal Theorem Proving",
      "title_zh": "翻译失败",
      "authors": [
        "Adarsh Kumarappan",
        "Mo Tiwari",
        "Peiyang Song",
        "Robert Joseph George",
        "Chaowei Xiao",
        "Anima Anandkumar"
      ],
      "abstract": "Large Language Models (LLMs) have been successful in mathematical reasoning\ntasks such as formal theorem proving when integrated with interactive proof\nassistants like Lean. Existing approaches involve training or fine-tuning an\nLLM on a specific dataset to perform well on particular domains, such as\nundergraduate-level mathematics. These methods struggle with generalizability\nto advanced mathematics. A fundamental limitation is that these approaches\noperate on static domains, failing to capture how mathematicians often work\nacross multiple domains and projects simultaneously or cyclically. We present\nLeanAgent, a novel lifelong learning framework for formal theorem proving that\ncontinuously generalizes to and improves on ever-expanding mathematical\nknowledge without forgetting previously learned knowledge. LeanAgent introduces\nseveral key innovations, including a curriculum learning strategy that\noptimizes the learning trajectory in terms of mathematical difficulty, a\ndynamic database for efficient management of evolving mathematical knowledge,\nand progressive training to balance stability and plasticity. LeanAgent\nsuccessfully generates formal proofs for 155 theorems across 23 diverse Lean\nrepositories where formal proofs were previously missing, many from advanced\nmathematics. It performs significantly better than the static LLM baseline,\nproving challenging theorems in domains like abstract algebra and algebraic\ntopology while showcasing a clear progression of learning from basic concepts\nto advanced topics. In addition, we analyze LeanAgent's superior performance on\nkey lifelong learning metrics. LeanAgent achieves exceptional scores in\nstability and backward transfer, where learning new tasks improves performance\non previously learned tasks. This emphasizes LeanAgent's continuous\ngeneralizability and improvement, explaining its superior theorem-proving\nperformance.",
      "tldr_zh": "该研究提出 LeanAgent，一种用于正式定理证明的终身学习框架，能够持续泛化到不断扩展的数学知识，同时避免遗忘先前学习的内容。\nLeanAgent 的关键创新包括课程学习策略(curriculum learning strategy)来优化数学难度轨迹、动态数据库(dynamic database)用于管理演变的知识，以及渐进训练(progressive training)以平衡稳定性(stability)和可塑性。\n实验结果显示，LeanAgent 在 23 个 Lean 仓库中成功为 155 个定理生成正式证明，许多来自高级数学领域，如抽象代数和代数拓扑，并显著优于静态 LLM 基线。\n此外，LeanAgent 在终身学习指标上表现出色，实现向后转移(backward transfer)，使学习新任务能提升先前任务的性能。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.LO"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.06209v8",
      "published_date": "2024-10-08 17:11:24 UTC",
      "updated_date": "2025-03-06 00:20:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:30:46.481153"
    },
    {
      "arxiv_id": "2410.06203v1",
      "title": "Integrating Planning into Single-Turn Long-Form Text Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Yi Liang",
        "You Wu",
        "Honglei Zhuang",
        "Li Chen",
        "Jiaming Shen",
        "Yiling Jia",
        "Zhen Qin",
        "Sumit Sanghai",
        "Xuanhui Wang",
        "Carl Yang",
        "Michael Bendersky"
      ],
      "abstract": "Generating high-quality, in-depth textual documents, such as academic papers,\nnews articles, Wikipedia entries, and books, remains a significant challenge\nfor Large Language Models (LLMs). In this paper, we propose to use planning to\ngenerate long form content. To achieve our goal, we generate intermediate steps\nvia an auxiliary task that teaches the LLM to plan, reason and structure before\ngenerating the final text. Our main novelty lies in a single auxiliary task\nthat does not require multiple rounds of prompting or planning. To overcome the\nscarcity of training data for these intermediate steps, we leverage LLMs to\ngenerate synthetic intermediate writing data such as outlines, key information\nand summaries from existing full articles. Our experiments demonstrate on two\ndatasets from different domains, namely the scientific news dataset SciNews and\nWikipedia datasets in KILT-Wiki and FreshWiki, that LLMs fine-tuned with the\nauxiliary task generate higher quality documents. We observed +2.5% improvement\nin ROUGE-Lsum, and a strong 3.60 overall win/loss ratio via human SxS\nevaluation, with clear wins in organization, relevance, and verifiability.",
      "tldr_zh": "本论文提出了一种将规划（planning）集成到单轮长文本生成的方法，以提升大型语言模型（LLMs）生成高质量长文档的能力，如学术论文或维基百科条目。核心创新在于设计一个单一的辅助任务（auxiliary task），通过教 LLMs 在生成最终文本前进行规划、推理和结构化，并利用 LLMs 生成合成中间数据（如大纲、关键信息和摘要）来解决训练数据稀缺问题。实验在 SciNews、KILT-Wiki 和 FreshWiki 数据集上显示，细调后的模型在 ROUGE-Lsum 上提升了 2.5%，并在人类 SxS 评估中获得 3.60 的整体胜率，特别是在组织性、相关性和可验证性方面表现出显著优势。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.06203v1",
      "published_date": "2024-10-08 17:02:40 UTC",
      "updated_date": "2024-10-08 17:02:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:30:57.465159"
    },
    {
      "arxiv_id": "2410.06195v3",
      "title": "EgoSocialArena: Benchmarking the Social Intelligence of Large Language Models from a First-person Perspective",
      "title_zh": "EgoSocialArena：从第一人称视角对大型语言模型的社会智能进行基准",
      "authors": [
        "Guiyang Hou",
        "Wenqi Zhang",
        "Yongliang Shen",
        "Zeqi Tan",
        "Sihao Shen",
        "Weiming Lu"
      ],
      "abstract": "Social intelligence is built upon three foundational pillars: cognitive\nintelligence, situational intelligence, and behavioral intelligence. As large\nlanguage models (LLMs) become increasingly integrated into our social lives,\nunderstanding, evaluating, and developing their social intelligence are\nbecoming increasingly important. While multiple existing works have\ninvestigated the social intelligence of LLMs, (1) most focus on a specific\naspect, and the social intelligence of LLMs has yet to be systematically\norganized and studied; (2) position LLMs as passive observers from a\nthird-person perspective, such as in Theory of Mind (ToM) tests. Compared to\nthe third-person perspective, ego-centric first-person perspective evaluation\ncan align well with actual LLM-based Agent use scenarios. (3) a lack of\ncomprehensive evaluation of behavioral intelligence, with specific emphasis on\nincorporating critical human-machine interaction scenarios. In light of this,\nwe present EgoSocialArena, a novel framework grounded in the three pillars of\nsocial intelligence: cognitive, situational, and behavioral intelligence, aimed\nto systematically evaluate the social intelligence of LLMs from a first-person\nperspective. With EgoSocialArena, we conduct a comprehensive evaluation of\neight prominent foundation models, even the most advanced LLMs like O1-preview\nlag behind human performance.",
      "tldr_zh": "该论文提出EgoSocialArena框架，从第一人称视角系统评估Large Language Models (LLMs)的社会智能，该框架基于cognitive intelligence、situational intelligence和behavioral intelligence三个支柱，解决了现有研究中对特定方面偏重、第三人称视角局限以及人机交互场景不足的问题。EgoSocialArena通过全面测试LLMs在社会情境中的表现，包括认知、情境和行为能力。实验结果显示，在评估八个著名基础模型时，即使是最先进的如O1-preview，也显著落后于人类水平。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "14 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.06195v3",
      "published_date": "2024-10-08 16:55:51 UTC",
      "updated_date": "2025-02-24 02:22:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:31:02.433612"
    },
    {
      "arxiv_id": "2410.06191v1",
      "title": "Benign Overfitting for Regression with Trained Two-Layer ReLU Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Junhyung Park",
        "Patrick Bloebaum",
        "Shiva Prasad Kasiviswanathan"
      ],
      "abstract": "We study the least-square regression problem with a two-layer fully-connected\nneural network, with ReLU activation function, trained by gradient flow. Our\nfirst result is a generalization result, that requires no assumptions on the\nunderlying regression function or the noise other than that they are bounded.\nWe operate in the neural tangent kernel regime, and our generalization result\nis developed via a decomposition of the excess risk into estimation and\napproximation errors, viewing gradient flow as an implicit regularizer. This\ndecomposition in the context of neural networks is a novel perspective of\ngradient descent, and helps us avoid uniform convergence traps. In this work,\nwe also establish that under the same setting, the trained network overfits to\nthe data. Together, these results, establishes the first result on benign\noverfitting for finite-width ReLU networks for arbitrary regression functions.",
      "tldr_zh": "本文研究了使用两层 ReLU 网络通过梯度流训练的最小二乘回归问题，在 Neural Tangent Kernel 制度下，将过拟合分解为估计误差和逼近误差，并将梯度流视为隐式正则化，从而避免了统一收敛陷阱。研究结果显示，该方法在仅假设回归函数和噪声为有界的情况下，实现了良好的泛化性能，同时证明了训练网络会 benign overfitting 到数据。总体上，这为有限宽度 ReLU 网络提供了首个针对任意回归函数的 benign overfitting 结果。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "65 pages",
      "pdf_url": "http://arxiv.org/pdf/2410.06191v1",
      "published_date": "2024-10-08 16:54:23 UTC",
      "updated_date": "2024-10-08 16:54:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:31:11.004688"
    },
    {
      "arxiv_id": "2410.18104v1",
      "title": "ENWAR: A RAG-empowered Multi-Modal LLM Framework for Wireless Environment Perception",
      "title_zh": "翻译失败",
      "authors": [
        "Ahmad M. Nazar",
        "Abdulkadir Celik",
        "Mohamed Y. Selim",
        "Asmaa Abdallah",
        "Daji Qiao",
        "Ahmed M. Eltawil"
      ],
      "abstract": "Large language models (LLMs) hold significant promise in advancing network\nmanagement and orchestration in 6G and beyond networks. However, existing LLMs\nare limited in domain-specific knowledge and their ability to handle\nmulti-modal sensory data, which is critical for real-time situational awareness\nin dynamic wireless environments. This paper addresses this gap by introducing\nENWAR, an ENvironment-aWARe retrieval augmented generation-empowered\nmulti-modal LLM framework. ENWAR seamlessly integrates multi-modal sensory\ninputs to perceive, interpret, and cognitively process complex wireless\nenvironments to provide human-interpretable situational awareness. ENWAR is\nevaluated on the GPS, LiDAR, and camera modality combinations of DeepSense6G\ndataset with state-of-the-art LLMs such as Mistral-7b/8x7b and\nLLaMa3.1-8/70/405b. Compared to general and often superficial environmental\ndescriptions of these vanilla LLMs, ENWAR delivers richer spatial analysis,\naccurately identifies positions, analyzes obstacles, and assesses line-of-sight\nbetween vehicles. Results show that ENWAR achieves key performance indicators\nof up to 70% relevancy, 55% context recall, 80% correctness, and 86%\nfaithfulness, demonstrating its efficacy in multi-modal perception and\ninterpretation.",
      "tldr_zh": "该论文提出 ENWAR，一种基于 RAG (Retrieval-Augmented Generation) 的多模态 LLM (Large Language Models) 框架，旨在解决现有 LLM 在无线环境感知中的领域知识和多模态数据处理局限性。ENWAR 通过整合 GPS、LiDAR 和相机等多模态输入，实现对复杂无线环境的感知、解释和认知处理，提供人类可解释的 situational awareness。实验在 DeepSense6G 数据集上与 Mistral-7b/8x7b 和 LLaMa3.1-8/70/405b 等基线模型比较，结果显示 ENWAR 达到了高达 70% 的 relevancy、55% 的 context recall、80% 的 correctness 和 86% 的 faithfulness，显著提升了空间分析和环境解读能力。",
      "categories": [
        "cs.NI",
        "cs.AI"
      ],
      "primary_category": "cs.NI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.18104v1",
      "published_date": "2024-10-08 16:26:18 UTC",
      "updated_date": "2024-10-08 16:26:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:31:24.301557"
    },
    {
      "arxiv_id": "2410.06176v2",
      "title": "SC-Bench: A Large-Scale Dataset for Smart Contract Auditing",
      "title_zh": "SC-Bench：用于智能合约审计的大规模数据集",
      "authors": [
        "Shihao Xia",
        "Mengting He",
        "Linhai Song",
        "Yiying Zhang"
      ],
      "abstract": "There is a huge demand to ensure the compliance of smart contracts listed on\nblockchain platforms to safety and economic standards. Today, manual efforts in\nthe form of auditing are commonly used to achieve this goal. ML-based automated\ntechniques have the promise to alleviate human efforts and the resulting\nmonetary costs. However, unlike other domains where ML techniques have had huge\nsuccesses, no systematic ML techniques have been proposed or applied to smart\ncontract auditing. We present SC-Bench, the first dataset for automated\nsmart-contract auditing research. SC-Bench consists of 5,377 real-world smart\ncontracts running on Ethereum, a widely used blockchain platform, and 15,975\nviolations of standards on Ehereum called ERCs. Out of these violations, 139\nare real violations programmers made. The remaining are errors we\nsystematically injected to reflect the violations of different ERC rules. We\nevaluate SC-Bench using GPT-4 by prompting it with both the contracts and ERC\nrules. In addition, we manually identify each violated rule and the\ncorresponding code site (i.e., oracle) and prompt GPT-4 with the information\nasking for a True-or-False question. Our results show that without the oracle,\nGPT-4 can only detect 0.9% violations, and with the oracle, it detects 22.9%\nviolations. These results show the potential room for improvement in ML-based\ntechniques for smart-contract auditing.",
      "tldr_zh": "这篇论文介绍了 SC-Bench，这是一个大规模数据集，旨在支持智能合约审计研究，包含 5,377 个真实以太坊智能合约和 15,975 个 ERC 标准违规（其中 139 个为真实违规，其余为系统注入错误）。数据集通过评估 GPT-4 的性能来展示其潜力，结果显示 GPT-4 在没有 oracle 的情况下仅检测到 0.9% 的违规，而有了 oracle 后提升至 22.9%。这些发现突显了基于 ML 的智能合约审计技术在准确性上仍有巨大改进空间，为未来自动化审计方法提供了宝贵资源。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.06176v2",
      "published_date": "2024-10-08 16:23:50 UTC",
      "updated_date": "2025-02-08 03:58:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:31:45.466022"
    },
    {
      "arxiv_id": "2410.06173v1",
      "title": "Manual Verbalizer Enrichment for Few-Shot Text Classification",
      "title_zh": "翻译失败",
      "authors": [
        "Quang Anh Nguyen",
        "Nadi Tomeh",
        "Mustapha Lebbah",
        "Thierry Charnois",
        "Hanene Azzag",
        "Santiago Cordoba Muñoz"
      ],
      "abstract": "With the continuous development of pre-trained language models, prompt-based\ntraining becomes a well-adopted paradigm that drastically improves the\nexploitation of models for many natural language processing tasks. Prompting\nalso shows great performance compared to traditional fine-tuning when adapted\nto zero-shot or few-shot scenarios where the number of annotated data is\nlimited. In this framework, the role of verbalizers is essential, as an\ninterpretation from masked word distributions into output predictions. In this\nwork, we propose \\acrshort{mave}, an approach for verbalizer construction by\nenrichment of class labels using neighborhood relation in the embedding space\nof words for the text classification task. In addition, we elaborate a\nbenchmarking procedure to evaluate typical baselines of verbalizers for\ndocument classification in few-shot learning contexts. Our model achieves\nstate-of-the-art results while using significantly fewer resources. We show\nthat our approach is particularly effective in cases with extremely limited\nsupervision data.",
      "tldr_zh": "这篇论文针对少样本文本分类（Few-Shot Text Classification）问题，提出了MAVE方法，通过在词嵌入空间中使用邻域关系来手动丰富verbalizers，从而改善提示-based训练的性能。该方法建立了一个基准评估流程，用于评估verbalizers在少样本学习中的表现，并在实验中达到了最先进的结果，同时显著减少了资源消耗。研究发现，MAVE在监督数据极度有限的场景下特别有效。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.06173v1",
      "published_date": "2024-10-08 16:16:47 UTC",
      "updated_date": "2024-10-08 16:16:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:31:46.603827"
    },
    {
      "arxiv_id": "2410.06172v2",
      "title": "Multimodal Situational Safety",
      "title_zh": "多模态情境安全",
      "authors": [
        "Kaiwen Zhou",
        "Chengzhi Liu",
        "Xuandong Zhao",
        "Anderson Compalas",
        "Dawn Song",
        "Xin Eric Wang"
      ],
      "abstract": "Multimodal Large Language Models (MLLMs) are rapidly evolving, demonstrating\nimpressive capabilities as multimodal assistants that interact with both humans\nand their environments. However, this increased sophistication introduces\nsignificant safety concerns. In this paper, we present the first evaluation and\nanalysis of a novel safety challenge termed Multimodal Situational Safety,\nwhich explores how safety considerations vary based on the specific situation\nin which the user or agent is engaged. We argue that for an MLLM to respond\nsafely, whether through language or action, it often needs to assess the safety\nimplications of a language query within its corresponding visual context. To\nevaluate this capability, we develop the Multimodal Situational Safety\nbenchmark (MSSBench) to assess the situational safety performance of current\nMLLMs. The dataset comprises 1,820 language query-image pairs, half of which\nthe image context is safe, and the other half is unsafe. We also develop an\nevaluation framework that analyzes key safety aspects, including explicit\nsafety reasoning, visual understanding, and, crucially, situational safety\nreasoning. Our findings reveal that current MLLMs struggle with this nuanced\nsafety problem in the instruction-following setting and struggle to tackle\nthese situational safety challenges all at once, highlighting a key area for\nfuture research. Furthermore, we develop multi-agent pipelines to coordinately\nsolve safety challenges, which shows consistent improvement in safety over the\noriginal MLLM response. Code and data: mssbench.github.io.",
      "tldr_zh": "本文首次评估了 Multimodal Situational Safety（多模态情境安全）这一新挑战，探讨 Multimodal Large Language Models (MLLMs) 如何根据视觉情境评估语言查询的安全性，以应对其在互动环境中的潜在风险。研究开发了 MSSBench 基准数据集（包含 1,820 个语言查询-图像对）和评估框架，分析了显式安全推理、视觉理解及情境安全推理方面的表现。结果表明，当前 MLLMs 在处理这些情境安全问题时存在显著困难，但通过多智能体管道协调方法，能有效提升安全性，为未来研究提供关键方向。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "ICLR 2025 Camera Ready",
      "pdf_url": "http://arxiv.org/pdf/2410.06172v2",
      "published_date": "2024-10-08 16:16:07 UTC",
      "updated_date": "2025-04-22 23:01:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:31:59.519652"
    },
    {
      "arxiv_id": "2410.06151v1",
      "title": "Quality Diversity Imitation Learning",
      "title_zh": "质量多样性模仿学习",
      "authors": [
        "Zhenglin Wan",
        "Xingrui Yu",
        "David Mark Bossens",
        "Yueming Lyu",
        "Qing Guo",
        "Flint Xiaofeng Fan",
        "Ivor Tsang"
      ],
      "abstract": "Imitation learning (IL) has shown great potential in various applications,\nsuch as robot control. However, traditional IL methods are usually designed to\nlearn only one specific type of behavior since demonstrations typically\ncorrespond to a single expert. In this work, we introduce the first generic\nframework for Quality Diversity Imitation Learning (QD-IL), which enables the\nagent to learn a broad range of skills from limited demonstrations. Our\nframework integrates the principles of quality diversity with adversarial\nimitation learning (AIL) methods, and can potentially improve any inverse\nreinforcement learning (IRL) method. Empirically, our framework significantly\nimproves the QD performance of GAIL and VAIL on the challenging continuous\ncontrol tasks derived from Mujoco environments. Moreover, our method even\nachieves 2x expert performance in the most challenging Humanoid environment.",
      "tldr_zh": "本文提出 Quality Diversity Imitation Learning (QD-IL)，一个通用框架，旨在让代理从有限的演示中学习多种技能，解决传统 Imitation Learning (IL) 方法仅限于单一行为的局限性。该框架将 Quality Diversity 原则与 Adversarial Imitation Learning (AIL) 方法整合，并可潜在提升任何 Inverse Reinforcement Learning (IRL) 算法的性能。在实验中，QD-IL 显著提高了 GAIL 和 VAIL 在 Mujoco 环境的连续控制任务中的 QD 表现，并在最具挑战性的 Humanoid 环境中实现了专家性能的 2 倍提升。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "22 pages, conference paper",
      "pdf_url": "http://arxiv.org/pdf/2410.06151v1",
      "published_date": "2024-10-08 15:49:33 UTC",
      "updated_date": "2024-10-08 15:49:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:32:11.268345"
    },
    {
      "arxiv_id": "2410.18982v1",
      "title": "O1 Replication Journey: A Strategic Progress Report -- Part 1",
      "title_zh": "翻译失败",
      "authors": [
        "Yiwei Qin",
        "Xuefeng Li",
        "Haoyang Zou",
        "Yixiu Liu",
        "Shijie Xia",
        "Zhen Huang",
        "Yixin Ye",
        "Weizhe Yuan",
        "Hector Liu",
        "Yuanzhi Li",
        "Pengfei Liu"
      ],
      "abstract": "This paper introduces a pioneering approach to artificial intelligence\nresearch, embodied in our O1 Replication Journey. In response to the\nannouncement of OpenAI's groundbreaking O1 model, we embark on a transparent,\nreal-time exploration to replicate its capabilities while reimagining the\nprocess of conducting and communicating AI research. Our methodology addresses\ncritical challenges in modern AI research, including the insularity of\nprolonged team-based projects, delayed information sharing, and the lack of\nrecognition for diverse contributions. By providing comprehensive, real-time\ndocumentation of our replication efforts, including both successes and\nfailures, we aim to foster open science, accelerate collective advancement, and\nlay the groundwork for AI-driven scientific discovery. Our research progress\nreport diverges significantly from traditional research papers, offering\ncontinuous updates, full process transparency, and active community engagement\nthroughout the research journey. Technologically, we proposed the journey\nlearning paradigm, which encourages models to learn not just shortcuts, but the\ncomplete exploration process, including trial and error, reflection, and\nbacktracking. With only 327 training samples and without any additional tricks,\njourney learning outperformed conventional supervised learning by over 8\\% on\nthe MATH dataset, demonstrating its extremely powerful potential. We believe\nthis to be the most crucial component of O1 technology that we have\nsuccessfully decoded. We share valuable resources including technical\nhypotheses and insights, cognitive exploration maps, custom-developed tools,\netc at https://github.com/GAIR-NLP/O1-Journey.",
      "tldr_zh": "这篇论文介绍了“O1 Replication Journey”，一种透明的 AI 研究方法，旨在复制 OpenAI 的 O1 模型，同时解决传统研究的痛点，如团队孤立、信息延迟和贡献认可不足。\n他们提出“journey learning”范式，让模型学习完整的探索过程，包括试错、反思和回溯，仅用 327 个训练样本，就在 MATH dataset 上比传统监督学习提升超过 8%，证明其强大潜力。\n通过实时文档记录成功与失败，并分享资源如技术假设和工具（详见 GitHub 仓库），该方法促进开放科学和社区参与，为 AI 驱动的科学发现奠定基础。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.18982v1",
      "published_date": "2024-10-08 15:13:01 UTC",
      "updated_date": "2024-10-08 15:13:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:32:23.213040"
    },
    {
      "arxiv_id": "2410.06108v1",
      "title": "ConceptAgent: LLM-Driven Precondition Grounding and Tree Search for Robust Task Planning and Execution",
      "title_zh": "翻译失败",
      "authors": [
        "Corban Rivera",
        "Grayson Byrd",
        "William Paul",
        "Tyler Feldman",
        "Meghan Booker",
        "Emma Holmes",
        "David Handelman",
        "Bethany Kemp",
        "Andrew Badger",
        "Aurora Schmidt",
        "Krishna Murthy Jatavallabhula",
        "Celso M de Melo",
        "Lalithkumar Seenivasan",
        "Mathias Unberath",
        "Rama Chellappa"
      ],
      "abstract": "Robotic planning and execution in open-world environments is a complex\nproblem due to the vast state spaces and high variability of task embodiment.\nRecent advances in perception algorithms, combined with Large Language Models\n(LLMs) for planning, offer promising solutions to these challenges, as the\ncommon sense reasoning capabilities of LLMs provide a strong heuristic for\nefficiently searching the action space. However, prior work fails to address\nthe possibility of hallucinations from LLMs, which results in failures to\nexecute the planned actions largely due to logical fallacies at high- or\nlow-levels. To contend with automation failure due to such hallucinations, we\nintroduce ConceptAgent, a natural language-driven robotic platform designed for\ntask execution in unstructured environments. With a focus on scalability and\nreliability of LLM-based planning in complex state and action spaces, we\npresent innovations designed to limit these shortcomings, including 1)\nPredicate Grounding to prevent and recover from infeasible actions, and 2) an\nembodied version of LLM-guided Monte Carlo Tree Search with self reflection. In\nsimulation experiments, ConceptAgent achieved a 19% task completion rate across\nthree room layouts and 30 easy level embodied tasks outperforming other\nstate-of-the-art LLM-driven reasoning baselines that scored 10.26% and 8.11% on\nthe same benchmark. Additionally, ablation studies on moderate to hard embodied\ntasks revealed a 20% increase in task completion from the baseline agent to the\nfully enhanced ConceptAgent, highlighting the individual and combined\ncontributions of Predicate Grounding and LLM-guided Tree Search to enable more\nrobust automation in complex state and action spaces.",
      "tldr_zh": "该论文提出ConceptAgent，一种基于Large Language Models (LLMs)的机器人平台，用于在开放世界环境中进行鲁棒的任务规划和执行，以解决LLMs幻觉导致的逻辑错误问题。主要创新包括Predicate Grounding机制，用于防止和恢复不可行动作，以及LLM-guided Monte Carlo Tree Search with self-reflection，以提升行动空间的搜索效率。在模拟实验中，ConceptAgent在三个房间布局和30个简单任务上实现了19%的任务完成率，优于基线模型（10.26%和8.11%），并在中等到困难任务上较基线提高了20%的性能，证明了这些方法的有效性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.06108v1",
      "published_date": "2024-10-08 15:05:40 UTC",
      "updated_date": "2024-10-08 15:05:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:32:34.954842"
    },
    {
      "arxiv_id": "2410.06107v1",
      "title": "Towards AI-Native Software Engineering (SE 3.0): A Vision and a Challenge Roadmap",
      "title_zh": "迈向 AI-Native 软件工程 (",
      "authors": [
        "Ahmed E. Hassan",
        "Gustavo A. Oliva",
        "Dayi Lin",
        "Boyuan Chen",
        "Zhen Ming",
        "Jiang"
      ],
      "abstract": "The rise of AI-assisted software engineering (SE 2.0), powered by Foundation\nModels (FMs) and FM-powered copilots, has shown promise in improving developer\nproductivity. However, it has also exposed inherent limitations, such as\ncognitive overload on developers and inefficiencies. We propose a shift towards\nSoftware Engineering 3.0 (SE 3.0), an AI-native approach characterized by\nintent-first, conversation-oriented development between human developers and AI\nteammates. SE 3.0 envisions AI systems evolving beyond task-driven copilots\ninto intelligent collaborators, capable of deeply understanding and reasoning\nabout software engineering principles and intents. We outline the key\ncomponents of the SE 3.0 technology stack, which includes Teammate.next for\nadaptive and personalized AI partnership, IDE.next for intent-first\nconversation-oriented development, Compiler.next for multi-objective code\nsynthesis, and Runtime.next for SLA-aware execution with edge-computing\nsupport. Our vision addresses the inefficiencies and cognitive strain of SE 2.0\nby fostering a symbiotic relationship between human developers and AI,\nmaximizing their complementary strengths. We also present a roadmap of\nchallenges that must be overcome to realize our vision of SE 3.0. This paper\nlays the foundation for future discussions on the role of AI in the next era of\nsoftware engineering.",
      "tldr_zh": "本论文提出了一种AI-Native软件工程（SE 3.0）的愿景，旨在超越当前AI辅助软件工程（SE 2.0）的局限，如开发者认知负担和低效问题，转向以意图优先和对话导向的开发模式，让AI成为智能协作伙伴。SE 3.0的关键组件包括Teammate.next（用于适应性AI伙伴）、IDE.next（意图优先开发环境）、Compiler.next（多目标代码合成）和Runtime.next（服务水平协议aware执行，支持边缘计算）。通过建立人类和AI的互补关系，该框架可最大化生产力，并提供实现SE 3.0的挑战路线图，为软件工程的未来发展奠定基础。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.06107v1",
      "published_date": "2024-10-08 15:04:07 UTC",
      "updated_date": "2024-10-08 15:04:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:32:46.893125"
    },
    {
      "arxiv_id": "2410.06101v2",
      "title": "Coevolving with the Other You: Fine-Tuning LLM with Sequential Cooperative Multi-Agent Reinforcement Learning",
      "title_zh": "与另一个你共同进化：使用顺序合作多智能体强化学习微调 LLM",
      "authors": [
        "Hao Ma",
        "Tianyi Hu",
        "Zhiqiang Pu",
        "Boyin Liu",
        "Xiaolin Ai",
        "Yanyan Liang",
        "Min Chen"
      ],
      "abstract": "Reinforcement learning (RL) has emerged as a pivotal technique for\nfine-tuning large language models (LLMs) on specific tasks. However, prevailing\nRL fine-tuning methods predominantly rely on PPO and its variants. Though these\nalgorithms are effective in general RL settings, they often exhibit suboptimal\nperformance and vulnerability to distribution collapse when applied to the\nfine-tuning of LLMs. In this paper, we propose CORY, extending the RL\nfine-tuning of LLMs to a sequential cooperative multi-agent reinforcement\nlearning framework, to leverage the inherent coevolution and emergent\ncapabilities of multi-agent systems. In CORY, the LLM to be fine-tuned is\ninitially duplicated into two autonomous agents: a pioneer and an observer. The\npioneer generates responses based on queries, while the observer generates\nresponses using both the queries and the pioneer's responses. The two agents\nare trained together. During training, the agents exchange roles periodically,\nfostering cooperation and coevolution between them. Experiments evaluate CORY's\nperformance by fine-tuning GPT-2 and Llama-2 under subjective and objective\nreward functions on the IMDB Review and GSM8K datasets, respectively. Results\nshow that CORY outperforms PPO in terms of policy optimality, resistance to\ndistribution collapse, and training robustness, thereby underscoring its\npotential as a superior methodology for refining LLMs in real-world\napplications.",
      "tldr_zh": "本文提出 CORY 方法，将 Reinforcement Learning (RL) 应用于大型语言模型 (LLMs) 的微调，通过顺序合作多智能体框架来解决传统算法如 PPO 的性能不佳和分布崩溃问题。在 CORY 中，将待微调的 LLM 复制成两个代理（pioneer 和 observer），它们基于查询生成响应并定期交换角色，促进相互合作和共同演化。实验结果显示，在 IMDB Review 和 GSM8K 数据集上微调 GPT-2 和 Llama-2 时，CORY 比 PPO 在策略最优性、抗分布崩溃和训练鲁棒性方面表现出显著优势，为实际应用中的 LLM 优化提供更可靠的方法。",
      "categories": [
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted by NeurIPS '24",
      "pdf_url": "http://arxiv.org/pdf/2410.06101v2",
      "published_date": "2024-10-08 14:55:26 UTC",
      "updated_date": "2025-02-22 17:08:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:32:59.650862"
    },
    {
      "arxiv_id": "2410.09094v2",
      "title": "Reflections on Disentanglement and the Latent Space",
      "title_zh": "翻译失败",
      "authors": [
        "Ludovica Schaerf"
      ],
      "abstract": "The latent space of image generative models is a multi-dimensional space of\ncompressed hidden visual knowledge. Its entity captivates computer scientists,\ndigital artists, and media scholars alike. Latent space has become an aesthetic\ncategory in AI art, inspiring artistic techniques such as the latent space\nwalk, exemplified by the works of Mario Klingemann and others. It is also\nviewed as cultural snapshots, encoding rich representations of our visual\nworld. This paper proposes a double view of the latent space, as a\nmulti-dimensional archive of culture and as a multi-dimensional space of\npotentiality. The paper discusses disentanglement as a method to elucidate the\ndouble nature of the space and as an interpretative direction to exploit its\norganization in human terms. The paper compares the role of disentanglement as\npotentiality to that of conditioning, as imagination, and confronts this\ninterpretation with the philosophy of Deleuzian potentiality and Hume's\nimagination. Lastly, this paper notes the difference between traditional\ngenerative models and recent architectures.",
      "tldr_zh": "这篇论文探讨了图像生成模型的潜在空间（latent space），将其视为一个多维度的文化档案和潜在性空间，强调其在AI艺术中的美学价值，如latent space walk，并作为视觉世界的文化快照。论文提出disentanglement作为一种方法来阐明潜在空间的双重性质，并将其与conditioning进行比较，探讨其作为想象和潜在性的角色，同时借鉴Deleuzian potentiality和Hume's imagination的哲学观点。最后，论文比较了传统生成模型与最近架构的差异，提供了对潜在空间组织的新解读。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CY",
      "comment": "Published in xCoAx 2024, School of X's proceedings. DOI:\n  10.34626/2024_xcoax/classof24_002",
      "pdf_url": "http://arxiv.org/pdf/2410.09094v2",
      "published_date": "2024-10-08 14:55:07 UTC",
      "updated_date": "2024-10-20 14:40:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:33:11.238010"
    },
    {
      "arxiv_id": "2410.06089v1",
      "title": "TOWER: Tree Organized Weighting for Evaluating Complex Instructions",
      "title_zh": "翻译失败",
      "authors": [
        "Noah Ziems",
        "Zhihan Zhang",
        "Meng Jiang"
      ],
      "abstract": "Evaluating the ability of large language models (LLMs) to follow complex\nhuman-written instructions is essential for their deployment in real-world\napplications. While benchmarks like Chatbot Arena use human judges to assess\nmodel performance, they are resource-intensive and time-consuming. Alternative\nmethods using LLMs as judges, such as AlpacaEval, MT Bench, WildBench, and\nInFoBench offer improvements but still do not capture that certain complex\ninstruction aspects are more important than others to follow.\n  To address this gap, we propose a novel evaluation metric, \\textsc{TOWER},\nthat incorporates human-judged importance into the assessment of complex\ninstruction following. We show that human annotators agree with tree-based\nrepresentations of these complex instructions nearly as much as they agree with\nother human annotators. We release tree-based annotations of the InFoBench\ndataset and the corresponding evaluation code to facilitate future research.",
      "tldr_zh": "本研究针对评估大型语言模型(LLMs)遵循复杂指令的能力，指出现有基准如Chatbot Arena和AlpacaEval等方法要么资源密集，要么忽略指令不同方面的相对重要性。论文提出TOWER(Tree Organized Weighting)指标，通过树状结构整合人类判断的重要性，实现更精确的指令遵循评估。实验结果显示，人类标注者对树状表示的同意度几乎与他们对其他人类标注者相当，并发布了InFoBench数据集的树状注解和评估代码，以促进未来研究。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to EMNLP 2024",
      "pdf_url": "http://arxiv.org/pdf/2410.06089v1",
      "published_date": "2024-10-08 14:46:50 UTC",
      "updated_date": "2024-10-08 14:46:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:33:22.366067"
    },
    {
      "arxiv_id": "2410.06065v1",
      "title": "Posets and Bounded Probabilities for Discovering Order-inducing Features in Event Knowledge Graphs",
      "title_zh": "翻译失败",
      "authors": [
        "Christoffer Olling Back",
        "Jakob Grue Simonsen"
      ],
      "abstract": "Event knowledge graphs (EKG) extend the classical notion of a trace to\ncapture multiple, interacting views of a process execution. In this paper, we\ntackle the open problem of automating EKG discovery from uncurated data through\na principled, probabilistic framing based on the outcome space resulting from\nfeatured-derived partial orders on events. From this, we derive an EKG\ndiscovery algorithm based upon statistical inference rather than an ad-hoc or\nheuristic-based strategy, or relying on manual analysis from domain experts.\n  This approach comes at the computational cost of exploring a large,\nnon-convex hypothesis space. In particular, solving the maximum likelihood term\ninvolves counting the number of linear extensions of posets, which in general\nis #P-complete. Fortunately, bound estimates suffice for model comparison, and\nadmit incorporation into a bespoke branch-and-bound algorithm. We show that the\nposterior probability as defined is antitonic w.r.t. search depth for branching\nrules that are monotonic w.r.t. model inclusion. This allows pruning of large\nportions of the search space, which we show experimentally leads to rapid\nconvergence toward optimal solutions that are consistent with manually built\nEKGs.",
      "tldr_zh": "这篇论文针对从未整理数据中自动发现Event Knowledge Graphs (EKG)的问题，提出了一种基于Posets（部分序）和边界概率的概率框架，以捕捉事件间的顺序关系。\n他们开发了一个依赖统计推断的EKG发现算法，避免了启发式策略或手动分析，通过branch-and-bound算法处理非凸假设空间的计算挑战。\n实验证明，该算法能有效剪枝搜索空间，实现快速收敛，并获得与手动构建EKG一致的最优解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "06-08",
        "G.3; I.2.6; I.5"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.06065v1",
      "published_date": "2024-10-08 14:12:51 UTC",
      "updated_date": "2024-10-08 14:12:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:33:35.566714"
    },
    {
      "arxiv_id": "2410.06062v4",
      "title": "LLM-based SPARQL Query Generation from Natural Language over Federated Knowledge Graphs",
      "title_zh": "翻译失败",
      "authors": [
        "Vincent Emonet",
        "Jerven Bolleman",
        "Severine Duvaud",
        "Tarcisio Mendes de Farias",
        "Ana Claudia Sima"
      ],
      "abstract": "We introduce a Retrieval-Augmented Generation (RAG) system for translating\nuser questions into accurate federated SPARQL queries over bioinformatics\nknowledge graphs (KGs) leveraging Large Language Models (LLMs). To enhance\naccuracy and reduce hallucinations in query generation, our system utilises\nmetadata from the KGs, including query examples and schema information, and\nincorporates a validation step to correct generated queries. The system is\navailable online at chat.expasy.org.",
      "tldr_zh": "本研究提出了一种基于 Large Language Models (LLMs) 的 Retrieval-Augmented Generation (RAG) 系统，用于将自然语言用户问题转化为准确的联邦 SPARQL 查询，针对生物信息学知识图谱 (KGs)。系统通过利用 KGs 的元数据（如查询示例和 schema 信息），并加入验证步骤来减少 hallucinations，从而提升查询生成的精确性。实验结果表明，该系统在处理联邦查询时表现出色，并已在线部署在 chat.expasy.org 上，为知识图谱查询提供了实用工具。",
      "categories": [
        "cs.DB",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.DB",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.06062v4",
      "published_date": "2024-10-08 14:09:12 UTC",
      "updated_date": "2025-02-10 10:55:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:33:45.663924"
    },
    {
      "arxiv_id": "2410.18103v1",
      "title": "A Hybrid Graph Neural Network for Enhanced EEG-Based Depression Detection",
      "title_zh": "一种用于增强基于EEG",
      "authors": [
        "Yiye Wang",
        "Wenming Zheng",
        "Yang Li",
        "Hao Yang"
      ],
      "abstract": "Graph neural networks (GNNs) are becoming increasingly popular for EEG-based\ndepression detection. However, previous GNN-based methods fail to sufficiently\nconsider the characteristics of depression, thus limiting their performance.\nFirstly, studies in neuroscience indicate that depression patients exhibit both\ncommon and individualized brain abnormal patterns. Previous GNN-based\napproaches typically focus either on fixed graph connections to capture common\nabnormal brain patterns or on adaptive connections to capture individualized\npatterns, which is inadequate for depression detection. Secondly, brain network\nexhibits a hierarchical structure, which includes the arrangement from\nchannel-level graph to region-level graph. This hierarchical structure varies\namong individuals and contains significant information relevant to detecting\ndepression. Nonetheless, previous GNN-based methods overlook these\nindividualized hierarchical information. To address these issues, we propose a\nHybrid GNN (HGNN) that merges a Common Graph Neural Network (CGNN) branch\nutilizing fixed connection and an Individualized Graph Neural Network (IGNN)\nbranch employing adaptive connections. The two branches capture common and\nindividualized depression patterns respectively, complementing each other.\nFurthermore, we enhance the IGNN branch with a Graph Pooling and Unpooling\nModule (GPUM) to extract individualized hierarchical information. Extensive\nexperiments on two public datasets show that our model achieves\nstate-of-the-art performance.",
      "tldr_zh": "本研究针对 EEG-based 抑郁检测中的不足，提出了一种 Hybrid GNN (HGNN) 框架，以更好地捕捉抑郁患者的共同和个性化脑异常模式。HGNN 包括 Common Graph Neural Network (CGNN) 分支，使用固定连接提取共同模式，以及 Individualized Graph Neural Network (IGNN) 分支，使用自适应连接结合 Graph Pooling and Unpooling Module (GPUM) 来提取个性化的分层脑网络信息，从而弥补现有 GNN 方法的局限。实验结果显示，该模型在两个公开数据集上实现了 state-of-the-art 性能，显著提升了抑郁检测的准确性。",
      "categories": [
        "eess.SP",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "eess.SP",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.18103v1",
      "published_date": "2024-10-08 13:57:50 UTC",
      "updated_date": "2024-10-08 13:57:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:33:58.703846"
    },
    {
      "arxiv_id": "2410.18102v2",
      "title": "Multiple Global Peaks Big Bang-Big Crunch Algorithm for Multimodal Optimization",
      "title_zh": "多个全局峰值 Big Bang-Big Crunch 算法用于多模态优化",
      "authors": [
        "Fabio Stroppa",
        "Ahmet Astar"
      ],
      "abstract": "The main challenge of multimodal optimization problems is identifying\nmultiple peaks with high accuracy in multidimensional search spaces with\nirregular landscapes. This work proposes the Multiple Global Peaks Big Bang-Big\nCrunch (MGP-BBBC) algorithm, which addresses the challenge of multimodal\noptimization problems by introducing a specialized mechanism for each operator.\nThe algorithm expands the Big Bang-Big Crunch algorithm, a state-of-the-art\nmetaheuristic inspired by the universe's evolution. Specifically, MGP-BBBC\ngroups the best individuals of the population into cluster-based centers of\nmass and then expands them with a progressively lower disturbance to guarantee\nconvergence. During this process, it (i) applies a distance-based filtering to\nremove unnecessary elites such that the ones on smaller peaks are not lost,\n(ii) promotes isolated individuals based on their niche count after clustering,\nand (iii) balances exploration and exploitation during offspring generation to\ntarget specific accuracy levels. Experimental results on twenty multimodal\nbenchmark test functions show that MGP-BBBC generally performs better or\ncompetitively with respect to other state-of-the-art multimodal optimizers.",
      "tldr_zh": "该论文提出了一种名为 Multiple Global Peaks Big Bang-Big Crunch (MGP-BBBC) 的算法，用于解决多峰优化(multimodal optimization)问题，该算法旨在在多维搜索空间中高精度识别多个峰值。MGP-BBBC 基于 Big Bang-Big Crunch (BBBC) 算法扩展，通过将种群的最佳个体分组为 cluster-based centers of mass，并应用 distance-based filtering 去除不必要精英、根据 niche count 提升孤立个体，以及平衡 exploration 和 exploitation 来确保收敛和精度。实验结果显示，在 20 个多峰基准测试函数上，MGP-BBBC 的性能普遍优于或与其它最先进的多峰优化器相当。",
      "categories": [
        "cs.NE",
        "cs.AI"
      ],
      "primary_category": "cs.NE",
      "comment": "16 pages",
      "pdf_url": "http://arxiv.org/pdf/2410.18102v2",
      "published_date": "2024-10-08 13:49:35 UTC",
      "updated_date": "2024-11-08 11:07:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:34:10.552019"
    },
    {
      "arxiv_id": "2410.06045v1",
      "title": "Extracting Finite State Machines from Transformers",
      "title_zh": "翻译失败",
      "authors": [
        "Rik Adriaensen",
        "Jaron Maene"
      ],
      "abstract": "Fueled by the popularity of the transformer architecture in deep learning,\nseveral works have investigated what formal languages a transformer can learn.\nNonetheless, existing results remain hard to compare and a fine-grained\nunderstanding of the trainability of transformers on regular languages is still\nlacking. We investigate transformers trained on regular languages from a\nmechanistic interpretability perspective. Using an extension of the $L^*$\nalgorithm, we extract Moore machines from transformers. We empirically find\ntighter lower bounds on the trainability of transformers, when a finite number\nof symbols determine the state. Additionally, our mechanistic insight allows us\nto characterise the regular languages a one-layer transformer can learn with\ngood length generalisation. However, we also identify failure cases where the\ndetermining symbols get misrecognised due to saturation of the attention\nmechanism.",
      "tldr_zh": "这篇论文从机械解释性(mechanistic interpretability)角度，调查 transformers 在学习正则语言时的训练性，使用扩展的 L* 算法从 transformers 中提取 Moore machines。\n研究发现，当有限数量的符号决定状态时，transformers 的训练下界更紧，并表征了一层 transformer 可以实现良好长度泛化的正则语言学习。\n然而，也识别了失败案例，其中 attention 机制饱和导致决定符号被误识别。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted for Workshop on Mechanistic Interpretability ICML 2024",
      "pdf_url": "http://arxiv.org/pdf/2410.06045v1",
      "published_date": "2024-10-08 13:43:50 UTC",
      "updated_date": "2024-10-08 13:43:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:34:32.821602"
    },
    {
      "arxiv_id": "2410.10871v1",
      "title": "Applying Refusal-Vector Ablation to Llama 3.1 70B Agents",
      "title_zh": "翻译失败",
      "authors": [
        "Simon Lermen",
        "Mateusz Dziemian",
        "Govind Pimpale"
      ],
      "abstract": "Recently, language models like Llama 3.1 Instruct have become increasingly\ncapable of agentic behavior, enabling them to perform tasks requiring\nshort-term planning and tool use. In this study, we apply refusal-vector\nablation to Llama 3.1 70B and implement a simple agent scaffolding to create an\nunrestricted agent. Our findings imply that these refusal-vector ablated models\ncan successfully complete harmful tasks, such as bribing officials or crafting\nphishing attacks, revealing significant vulnerabilities in current safety\nmechanisms. To further explore this, we introduce a small Safe Agent Benchmark,\ndesigned to test both harmful and benign tasks in agentic scenarios. Our\nresults imply that safety fine-tuning in chat models does not generalize well\nto agentic behavior, as we find that Llama 3.1 Instruct models are willing to\nperform most harmful tasks without modifications. At the same time, these\nmodels will refuse to give advice on how to perform the same tasks when asked\nfor a chat completion. This highlights the growing risk of misuse as models\nbecome more capable, underscoring the need for improved safety frameworks for\nlanguage model agents.",
      "tldr_zh": "本研究将 refusal-vector ablation 技术应用于 Llama 3.1 70B 模型，并构建了一个简单代理框架，以创建一个不受限制的代理。结果显示，这种消融后的模型能够成功执行有害任务，如贿赂官员或制作网络钓鱼攻击，暴露了当前安全机制的重大漏洞。论文引入了小型 Safe Agent Benchmark 来评估代理场景中的有害和良性任务，发现 Llama 3.1 Instruct 模型的安全微调在代理行为中不通用，尽管在聊天模式下会拒绝提供相关建议。这强调了模型能力提升带来的滥用风险，并呼吁开发更有效的安全框架。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.10871v1",
      "published_date": "2024-10-08 13:42:36 UTC",
      "updated_date": "2024-10-08 13:42:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:34:44.744017"
    },
    {
      "arxiv_id": "2410.10870v3",
      "title": "PortLLM: Personalizing Evolving Large Language Models with Training-Free and Portable Model Patches",
      "title_zh": "翻译失败",
      "authors": [
        "Rana Muhammad Shahroz Khan",
        "Pingzhi Li",
        "Sukwon Yun",
        "Zhenyu Wang",
        "Shahriar Nirjon",
        "Chau-Wai Wong",
        "Tianlong Chen"
      ],
      "abstract": "As large language models (LLMs) increasingly shape the AI landscape,\nfine-tuning pretrained models has become more popular than in the pre-LLM era\nfor achieving optimal performance in domain-specific tasks. However, pretrained\nLLMs such as ChatGPT are periodically evolved, i.e., model parameters are\nfrequently updated), making it challenging for downstream users with limited\nresources to keep up with fine-tuning the newest LLMs for their domain\napplication. Even though fine-tuning costs have nowadays been reduced thanks to\nthe innovations of parameter-efficient fine-tuning such as LoRA, not all\ndownstream users have adequate computing for frequent personalization.\nMoreover, access to fine-tuning datasets, particularly in sensitive domains\nsuch as healthcare, could be time-restrictive, making it crucial to retain the\nknowledge encoded in earlier fine-tuned rounds for future adaptation. In this\npaper, we present PortLLM, a training-free framework that (i) creates an\ninitial lightweight model update patch to capture domain-specific knowledge,\nand (ii) allows a subsequent seamless plugging for the continual\npersonalization of evolved LLM at minimal cost. Our extensive experiments cover\nseven representative datasets, from easier question-answering tasks {BoolQ,\nSST2} to harder reasoning tasks {WinoGrande, GSM8K}, and models including\n{Mistral-7B, Llama2, Llama3.1, and Gemma2}, validating the portability of our\ndesigned model patches and showcasing the effectiveness of our proposed\nframework. For instance, PortLLM achieves comparable performance to LoRA\nfine-tuning with reductions of up to 12.2x in GPU memory usage. Finally, we\nprovide theoretical justifications to understand the portability of our model\nupdate patches, which offers new insights into the theoretical dimension of\nLLMs' personalization.",
      "tldr_zh": "该论文提出PortLLM，一种无需训练的框架，用于个性化演化中的大型语言模型（LLMs），通过创建轻量级模型补丁（model patches）来捕获领域特定知识，并支持后续无缝插入以实现持续个性化，从而解决资源有限用户频繁微调的挑战。PortLLM在七个数据集上进行实验，包括从简单问答任务（如BoolQ、SST2）到复杂推理任务（如WinoGrande、GSM8K）的多种场景，并适用于多种模型（如Mistral-7B、Llama2等），其性能与LoRA微调相当，但可减少高达12.2倍的GPU内存使用。论文还提供了理论依据，解释了模型补丁的可移植性，为LLMs个性化提供了新见解。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.10870v3",
      "published_date": "2024-10-08 13:41:08 UTC",
      "updated_date": "2025-03-29 03:32:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:34:55.842744"
    },
    {
      "arxiv_id": "2410.06041v2",
      "title": "Block Induced Signature Generative Adversarial Network (BISGAN): Signature Spoofing Using GANs and Their Evaluation",
      "title_zh": "翻译失败",
      "authors": [
        "Haadia Amjad",
        "Kilian Goeller",
        "Steffen Seitz",
        "Carsten Knoll",
        "Naseer Bajwa",
        "Ronald Tetzlaff",
        "Muhammad Imran Malik"
      ],
      "abstract": "Deep learning is actively being used in biometrics to develop efficient\nidentification and verification systems. Handwritten signatures are a common\nsubset of biometric data for authentication purposes. Generative adversarial\nnetworks (GANs) learn from original and forged signatures to generate forged\nsignatures. While most GAN techniques create a strong signature verifier, which\nis the discriminator, there is a need to focus more on the quality of forgeries\ngenerated by the generator model. This work focuses on creating a generator\nthat produces forged samples that achieve a benchmark in spoofing signature\nverification systems. We use CycleGANs infused with Inception model-like blocks\nwith attention heads as the generator and a variation of the SigCNN model as\nthe base Discriminator. We train our model with a new technique that results in\n80% to 100% success in signature spoofing. Additionally, we create a custom\nevaluation technique to act as a goodness measure of the generated forgeries.\nOur work advocates generator-focused GAN architectures for spoofing data\nquality that aid in a better understanding of biometric data generation and\nevaluation.",
      "tldr_zh": "这篇论文提出了 Block Induced Signature Generative Adversarial Network (BISGAN)，一种基于 GANs 的框架，用于生成高质量的伪造签名，以评估签名验证系统的鲁棒性。方法采用 CycleGANs 结合 Inception model-like blocks 和 attention heads 作为生成器，以及 SigCNN 变体作为鉴别器，并引入一种新训练技术，使伪造签名的欺骗成功率达到 80% 到 100%。此外，论文开发了自定义评估技术来衡量生成的伪造质量，并强调生成器导向的 GAN 架构有助于深入理解生物特征数据的生成和评估。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.06041v2",
      "published_date": "2024-10-08 13:40:33 UTC",
      "updated_date": "2024-10-11 08:14:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:35:07.773079"
    },
    {
      "arxiv_id": "2410.06030v1",
      "title": "Data Quality Issues in Vulnerability Detection Datasets",
      "title_zh": "漏洞检测数据集中的数据质量问题",
      "authors": [
        "Yuejun Guo",
        "Seifeddine Bettaieb"
      ],
      "abstract": "Vulnerability detection is a crucial yet challenging task to identify\npotential weaknesses in software for cyber security. Recently, deep learning\n(DL) has made great progress in automating the detection process. Due to the\ncomplex multi-layer structure and a large number of parameters, a DL model\nrequires massive labeled (vulnerable or secure) source code to gain knowledge\nto effectively distinguish between vulnerable and secure code. In the\nliterature, many datasets have been created to train DL models for this\npurpose. However, these datasets suffer from several issues that will lead to\nlow detection accuracy of DL models. In this paper, we define three critical\nissues (i.e., data imbalance, low vulnerability coverage, biased vulnerability\ndistribution) that can significantly affect the model performance and three\nsecondary issues (i.e., errors in source code, mislabeling, noisy historical\ndata) that also affect the performance but can be addressed through a dedicated\npre-processing procedure. In addition, we conduct a study of 14 papers along\nwith 54 datasets for vulnerability detection to confirm these defined issues.\nFurthermore, we discuss good practices to use existing datasets and to create\nnew ones.",
      "tldr_zh": "这篇论文探讨了漏洞检测数据集中的数据质量问题，这些问题会降低深度学习（DL）模型的检测准确率。论文定义了三个关键问题——数据不平衡（data imbalance）、低漏洞覆盖（low vulnerability coverage）和偏置的漏洞分布（biased vulnerability distribution）——以及三个次要问题——源代码错误（errors in source code）、错误标记（mislabeling）和嘈杂的历史数据（noisy historical data）。通过对14篇论文和54个数据集的分析，论文确认了这些问题的普遍性，并提出了使用现有数据集和创建新数据集的良好实践，以提升模型性能。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "2023 IEEE European Symposium on Security and Privacy Workshops\n  (EuroS&P;PW)",
      "pdf_url": "http://arxiv.org/pdf/2410.06030v1",
      "published_date": "2024-10-08 13:31:29 UTC",
      "updated_date": "2024-10-08 13:31:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:35:19.394827"
    },
    {
      "arxiv_id": "2410.18101v2",
      "title": "Molecular Dynamics and Machine Learning Unlock Possibilities in Beauty Design -- A Perspective",
      "title_zh": "翻译失败",
      "authors": [
        "Yuzhi Xu",
        "Haowei Ni",
        "Qinhui Gao",
        "Chia-Hua Chang",
        "Yanran Huo",
        "Fanyu Zhao",
        "Shiyu Hu",
        "Wei Xia",
        "Yike Zhang",
        "Radu Grovu",
        "Min He",
        "John. Z. H. Zhang",
        "Yuanqing Wang"
      ],
      "abstract": "Computational molecular design -- the endeavor to design molecules, with\nvarious missions, aided by machine learning and molecular dynamics approaches,\nhas been widely applied to create valuable new molecular entities, from small\nmolecule therapeutics to protein biologics. In the small data regime,\nphysics-based approaches model the interaction between the molecule being\ndesigned and proteins of key physiological functions, providing structural\ninsights into the mechanism. When abundant data has been collected, a\nquantitative structure-activity relationship (QSAR) can be more directly\nconstructed from experimental data, from which machine learning can distill key\ninsights to guide the design of the next round of experiment design. Machine\nlearning methodologies can also facilitate physical modeling, from improving\nthe accuracy of force fields and extending them to unseen chemical spaces, to\nmore directly enhancing the sampling on the conformational spaces. We argue\nthat these techniques are mature enough to be applied to not just extend the\nlongevity of life, but the beauty it manifests. In this perspective, we review\nthe current frontiers in the research \\& development of skin care products, as\nwell as the statistical and physical toolbox applicable to addressing the\nchallenges in this industry. Feasible interdisciplinary research projects are\nproposed to harness the power of machine learning tools to design innovative,\neffective, and inexpensive skin care products.",
      "tldr_zh": "本论文从计算分子设计的视角，探讨分子动力学(Molecular Dynamics)和机器学习(Machine Learning)在美容领域的潜力，强调这些方法可用于设计皮肤护理产品。论文指出，在小数据场景下，基于物理的方法可模拟分子与蛋白质的交互，提供结构洞见；在大数据场景下，则通过定量结构-活性关系(QSAR)从实验数据中提炼洞见，并优化力场准确性和采样。最终，作者提出可行的跨学科项目，利用这些工具开发创新、有效且廉价的皮肤护理产品，以扩展美容科技的应用。",
      "categories": [
        "physics.chem-ph",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "physics.chem-ph",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.18101v2",
      "published_date": "2024-10-08 13:30:27 UTC",
      "updated_date": "2024-10-28 20:11:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:35:31.404759"
    },
    {
      "arxiv_id": "2410.06024v1",
      "title": "Jet Expansions of Residual Computation",
      "title_zh": "翻译失败",
      "authors": [
        "Yihong Chen",
        "Xiangxiang Xu",
        "Yao Lu",
        "Pontus Stenetorp",
        "Luca Franceschi"
      ],
      "abstract": "We introduce a framework for expanding residual computational graphs using\njets, operators that generalize truncated Taylor series. Our method provides a\nsystematic approach to disentangle contributions of different computational\npaths to model predictions. In contrast to existing techniques such as\ndistillation, probing, or early decoding, our expansions rely solely on the\nmodel itself and requires no data, training, or sampling from the model. We\ndemonstrate how our framework grounds and subsumes logit lens, reveals a\n(super-)exponential path structure in the recursive residual depth and opens up\nseveral applications. These include sketching a transformer large language\nmodel with $n$-gram statistics extracted from its computations, and indexing\nthe models' levels of toxicity knowledge. Our approach enables data-free\nanalysis of residual computation for model interpretability, development, and\nevaluation.",
      "tldr_zh": "本研究引入了使用 jets（一种泛化截断 Taylor 级数的运算符）来扩展残差计算图的框架，该方法系统地分离不同计算路径对模型预测的贡献，并无需依赖数据、训练或模型采样。相比现有的 distillation、probing 或 early decoding 技术，该框架完全基于模型自身，提供更直接的分析途径。研究揭示了递归残差深度中的（超）指数路径结构，并扩展了 logit lens 的应用，包括从 transformer 大语言模型中提取 n-gram 统计和索引毒性知识水平。最终，这一方法实现了数据无关的残差计算分析，提升了模型的可解释性、开发和评估。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.SC"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.06024v1",
      "published_date": "2024-10-08 13:25:08 UTC",
      "updated_date": "2024-10-08 13:25:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:35:43.572893"
    },
    {
      "arxiv_id": "2410.14707v1",
      "title": "FACMIC: Federated Adaptative CLIP Model for Medical Image Classification",
      "title_zh": "翻译失败",
      "authors": [
        "Yihang Wu",
        "Christian Desrosiers",
        "Ahmad Chaddad"
      ],
      "abstract": "Federated learning (FL) has emerged as a promising approach to medical image\nanalysis that allows deep model training using decentralized data while\nensuring data privacy. However, in the field of FL, communication cost plays a\ncritical role in evaluating the performance of the model. Thus, transferring\nvision foundation models can be particularly challenging due to the significant\nresource costs involved. In this paper, we introduce a federated adaptive\nContrastive Language Image Pretraining CLIP model designed for classification\ntasks. We employ a light-weight and efficient feature attention module for CLIP\nthat selects suitable features for each client's data. Additionally, we propose\na domain adaptation technique to reduce differences in data distribution\nbetween clients. Experimental results on four publicly available datasets\ndemonstrate the superior performance of FACMIC in dealing with real-world and\nmultisource medical imaging data. Our codes are available at\nhttps://github.com/AIPMLab/FACMIC.",
      "tldr_zh": "本文提出FACMIC，一种基于Federated Learning (FL)的自适应CLIP模型，用于医疗图像分类任务，以解决FL中通信成本高和数据分布差异的问题。该模型引入了轻量级特征注意力模块(feature attention module)来为每个客户端选择合适的特征，并采用领域适应技术(domain adaptation technique)来减少客户端间数据分布的差异。在四个公开数据集上的实验结果显示，FACMIC在处理真实世界和多源医疗图像数据方面表现出优越性能。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "eess.IV"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted in MICCAI 2024",
      "pdf_url": "http://arxiv.org/pdf/2410.14707v1",
      "published_date": "2024-10-08 13:24:10 UTC",
      "updated_date": "2024-10-08 13:24:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:35:54.907978"
    },
    {
      "arxiv_id": "2410.06020v1",
      "title": "QT-DoG: Quantization-aware Training for Domain Generalization",
      "title_zh": "翻译失败",
      "authors": [
        "Saqib Javed",
        "Hieu Le",
        "Mathieu Salzmann"
      ],
      "abstract": "Domain Generalization (DG) aims to train models that perform well not only on\nthe training (source) domains but also on novel, unseen target data\ndistributions. A key challenge in DG is preventing overfitting to source\ndomains, which can be mitigated by finding flatter minima in the loss\nlandscape. In this work, we propose Quantization-aware Training for Domain\nGeneralization (QT-DoG) and demonstrate that weight quantization effectively\nleads to flatter minima in the loss landscape, thereby enhancing domain\ngeneralization. Unlike traditional quantization methods focused on model\ncompression, QT-DoG exploits quantization as an implicit regularizer by\ninducing noise in model weights, guiding the optimization process toward\nflatter minima that are less sensitive to perturbations and overfitting. We\nprovide both theoretical insights and empirical evidence demonstrating that\nquantization inherently encourages flatter minima, leading to better\ngeneralization across domains. Moreover, with the benefit of reducing the model\nsize through quantization, we demonstrate that an ensemble of multiple\nquantized models further yields superior accuracy than the state-of-the-art DG\napproaches with no computational or memory overheads. Our extensive experiments\ndemonstrate that QT-DoG generalizes across various datasets, architectures, and\nquantization algorithms, and can be combined with other DG methods,\nestablishing its versatility and robustness.",
      "tldr_zh": "本研究提出了一种名为 QT-DoG 的量化感知训练方法，用于提升 Domain Generalization (DG)，旨在训练模型不仅在源域上表现良好，还能泛化到未见目标域。QT-DoG 通过权重量化作为隐式正则化器，在模型权重中引入噪声，引导优化过程向损失景观的平坦最小值移动，从而减少对源域的过拟合。研究提供了理论分析和实证证据，证明量化能增强模型对扰动的鲁棒性，并通过多个量化模型的集成，进一步提高准确性，而无需额外计算或内存开销。实验结果显示，QT-DoG 在各种数据集、架构和量化算法上表现出色，并可与其他 DG 方法结合，展示了其通用性和稳健性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV",
        "cs.RO"
      ],
      "primary_category": "cs.LG",
      "comment": "Code will be released soon",
      "pdf_url": "http://arxiv.org/pdf/2410.06020v1",
      "published_date": "2024-10-08 13:21:48 UTC",
      "updated_date": "2024-10-08 13:21:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:36:08.593300"
    },
    {
      "arxiv_id": "2410.06019v1",
      "title": "Unveiling Transformer Perception by Exploring Input Manifolds",
      "title_zh": "翻译失败",
      "authors": [
        "Alessandro Benfenati",
        "Alfio Ferrara",
        "Alessio Marta",
        "Davide Riva",
        "Elisabetta Rocchetti"
      ],
      "abstract": "This paper introduces a general method for the exploration of equivalence\nclasses in the input space of Transformer models. The proposed approach is\nbased on sound mathematical theory which describes the internal layers of a\nTransformer architecture as sequential deformations of the input manifold.\nUsing eigendecomposition of the pullback of the distance metric defined on the\noutput space through the Jacobian of the model, we are able to reconstruct\nequivalence classes in the input space and navigate across them. We illustrate\nhow this method can be used as a powerful tool for investigating how a\nTransformer sees the input space, facilitating local and task-agnostic\nexplainability in Computer Vision and Natural Language Processing tasks.",
      "tldr_zh": "本论文提出了一种通用方法，用于探索Transformer模型输入空间的等价类，该方法基于数学理论，将Transformer的内部层视为输入流形的顺序变形。论文通过Jacobian的特征分解和输出空间距离指标的拉回，来重建输入空间的等价类并实现导航，从而揭示Transformer如何感知输入。实验表明，此方法可作为强大工具，提供局部且任务无关的可解释性，适用于计算机视觉和自然语言处理任务。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "I.2.7; I.6.4"
      ],
      "primary_category": "cs.LG",
      "comment": "11 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.06019v1",
      "published_date": "2024-10-08 13:20:31 UTC",
      "updated_date": "2024-10-08 13:20:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:36:18.510434"
    },
    {
      "arxiv_id": "2410.06014v1",
      "title": "SplaTraj: Camera Trajectory Generation with Semantic Gaussian Splatting",
      "title_zh": "翻译失败",
      "authors": [
        "Xinyi Liu",
        "Tianyi Zhang",
        "Matthew Johnson-Roberson",
        "Weiming Zhi"
      ],
      "abstract": "Many recent developments for robots to represent environments have focused on\nphotorealistic reconstructions. This paper particularly focuses on generating\nsequences of images from the photorealistic Gaussian Splatting models, that\nmatch instructions that are given by user-inputted language. We contribute a\nnovel framework, SplaTraj, which formulates the generation of images within\nphotorealistic environment representations as a continuous-time trajectory\noptimization problem. Costs are designed so that a camera following the\ntrajectory poses will smoothly traverse through the environment and render the\nspecified spatial information in a photogenic manner. This is achieved by\nquerying a photorealistic representation with language embedding to isolate\nregions that correspond to the user-specified inputs. These regions are then\nprojected to the camera's view as it moves over time and a cost is constructed.\nWe can then apply gradient-based optimization and differentiate through the\nrendering to optimize the trajectory for the defined cost. The resulting\ntrajectory moves to photogenically view each of the specified objects. We\nempirically evaluate our approach on a suite of environments and instructions,\nand demonstrate the quality of generated image sequences.",
      "tldr_zh": "该研究提出了一种新框架SplaTraj，用于基于Semantic Gaussian Splatting生成相机轨迹，以匹配用户语言指令产生的图像序列。框架将图像生成问题表述为连续时间轨迹优化问题，通过设计成本函数确保相机平滑穿越环境并以摄影方式渲染指定空间信息。利用语言嵌入查询光线真实表示，隔离相关区域并投影到相机视图中，构建成本函数后进行梯度优化和渲染微分。实证评估显示，该方法在多种环境和指令下生成的图像序列质量高，能有效摄影式查看指定对象。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.06014v1",
      "published_date": "2024-10-08 13:16:49 UTC",
      "updated_date": "2024-10-08 13:16:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:36:34.925763"
    },
    {
      "arxiv_id": "2410.18100v1",
      "title": "RingGesture: A Ring-Based Mid-Air Gesture Typing System Powered by a Deep-Learning Word Prediction Framework",
      "title_zh": "翻译失败",
      "authors": [
        "Junxiao Shen",
        "Roger Boldu",
        "Arpit Kalla",
        "Michael Glueck",
        "Hemant Bhaskar Surale Amy Karlson"
      ],
      "abstract": "Text entry is a critical capability for any modern computing experience, with\nlightweight augmented reality (AR) glasses being no exception. Designed for\nall-day wearability, a limitation of lightweight AR glass is the restriction to\nthe inclusion of multiple cameras for extensive field of view in hand tracking.\nThis constraint underscores the need for an additional input device. We propose\na system to address this gap: a ring-based mid-air gesture typing technique,\nRingGesture, utilizing electrodes to mark the start and end of gesture\ntrajectories and inertial measurement units (IMU) sensors for hand tracking.\nThis method offers an intuitive experience similar to raycast-based mid-air\ngesture typing found in VR headsets, allowing for a seamless translation of\nhand movements into cursor navigation. To enhance both accuracy and input\nspeed, we propose a novel deep-learning word prediction framework, Score\nFusion, comprised of three key components: a) a word-gesture decoding model, b)\na spatial spelling correction model, and c) a lightweight contextual language\nmodel. In contrast, this framework fuses the scores from the three models to\npredict the most likely words with higher precision. We conduct comparative and\nlongitudinal studies to demonstrate two key findings: firstly, the overall\neffectiveness of RingGesture, which achieves an average text entry speed of\n27.3 words per minute (WPM) and a peak performance of 47.9 WPM. Secondly, we\nhighlight the superior performance of the Score Fusion framework, which offers\na 28.2% improvement in uncorrected Character Error Rate over a conventional\nword prediction framework, Naive Correction, leading to a 55.2% improvement in\ntext entry speed for RingGesture. Additionally, RingGesture received a System\nUsability Score of 83 signifying its excellent usability.",
      "tldr_zh": "该论文提出 RingGesture，一种基于戒指的空中手势输入系统，旨在解决轻量级 AR 眼镜在手部追踪方面的限制，通过电极标记手势轨迹和 IMU 传感器实现直观的游标导航。系统结合了一个新型深度学习词预测框架 Score Fusion，包括词-手势解码模型、空间拼写修正模型和轻量级上下文语言模型，以融合多模型得分提升输入精度和速度。实验结果显示，RingGesture 平均输入速度达 27.3 WPM、峰值 47.9 WPM，并通过 Score Fusion 框架将未修正字符错误率降低 28.2%，导致输入速度整体提升 55.2%，系统可用性得分 83。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.18100v1",
      "published_date": "2024-10-08 13:15:30 UTC",
      "updated_date": "2024-10-08 13:15:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:36:46.580779"
    },
    {
      "arxiv_id": "2410.06010v1",
      "title": "A large collection of bioinformatics question-query pairs over federated knowledge graphs: methodology and applications",
      "title_zh": "翻译失败",
      "authors": [
        "Jerven Bolleman",
        "Vincent Emonet",
        "Adrian Altenhoff",
        "Amos Bairoch",
        "Marie-Claude Blatter",
        "Alan Bridge",
        "Severine Duvaud",
        "Elisabeth Gasteiger",
        "Dmitry Kuznetsov",
        "Sebastien Moretti",
        "Pierre-Andre Michel",
        "Anne Morgat",
        "Marco Pagni",
        "Nicole Redaschi",
        "Monique Zahn-Zabal",
        "Tarcisio Mendes de Farias",
        "Ana Claudia Sima"
      ],
      "abstract": "Background. In the last decades, several life science resources have\nstructured data using the same framework and made these accessible using the\nsame query language to facilitate interoperability. Knowledge graphs have seen\nincreased adoption in bioinformatics due to their advantages for representing\ndata in a generic graph format. For example, yummydata.org catalogs more than\n60 knowledge graphs accessible through SPARQL, a technical query language.\nAlthough SPARQL allows powerful, expressive queries, even across physically\ndistributed knowledge graphs, formulating such queries is a challenge for most\nusers. Therefore, to guide users in retrieving the relevant data, many of these\nresources provide representative examples. These examples can also be an\nimportant source of information for machine learning, if a sufficiently large\nnumber of examples are provided and published in a common, machine-readable and\nstandardized format across different resources.\n  Findings. We introduce a large collection of human-written natural language\nquestions and their corresponding SPARQL queries over federated bioinformatics\nknowledge graphs (KGs) collected for several years across different research\ngroups at the SIB Swiss Institute of Bioinformatics. The collection comprises\nmore than 1000 example questions and queries, including 65 federated queries.\nWe propose a methodology to uniformly represent the examples with minimal\nmetadata, based on existing standards. Furthermore, we introduce an extensive\nset of open-source applications, including query graph visualizations and smart\nquery editors, easily reusable by KG maintainers who adopt the proposed\nmethodology.\n  Conclusions. We encourage the community to adopt and extend the proposed\nmethodology, towards richer KG metadata and improved Semantic Web services.",
      "tldr_zh": "本文提出一个大型集合，包含超过1000个生物信息学领域的自然语言问题及其对应的SPARQL查询，其中包括65个federated queries，这些数据由SIB Swiss Institute of Bioinformatics的多个研究组收集。研究方法基于现有标准，采用统一表示方式并添加最小元数据，以便机器学习和跨资源使用。同时，作者开发了开源应用，如查询图可视化和智能查询编辑器，供knowledge graphs维护者重用。最终，该工作鼓励社区采用此方法来丰富knowledge graphs元数据并提升Semantic Web服务。",
      "categories": [
        "cs.DB",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.DB",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.06010v1",
      "published_date": "2024-10-08 13:08:07 UTC",
      "updated_date": "2024-10-08 13:08:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:36:58.477688"
    },
    {
      "arxiv_id": "2410.18099v1",
      "title": "Gesture2Text: A Generalizable Decoder for Word-Gesture Keyboards in XR Through Trajectory Coarse Discretization and Pre-training",
      "title_zh": "翻译失败",
      "authors": [
        "Junxiao Shen",
        "Khadija Khaldi",
        "Enmin Zhou",
        "Hemant Bhaskar Surale",
        "Amy Karlson"
      ],
      "abstract": "Text entry with word-gesture keyboards (WGK) is emerging as a popular method\nand becoming a key interaction for Extended Reality (XR). However, the\ndiversity of interaction modes, keyboard sizes, and visual feedback in these\nenvironments introduces divergent word-gesture trajectory data patterns, thus\nleading to complexity in decoding trajectories into text. Template-matching\ndecoding methods, such as SHARK^2, are commonly used for these WGK systems\nbecause they are easy to implement and configure. However, these methods are\nsusceptible to decoding inaccuracies for noisy trajectories. While conventional\nneural-network-based decoders (neural decoders) trained on word-gesture\ntrajectory data have been proposed to improve accuracy, they have their own\nlimitations: they require extensive data for training and deep-learning\nexpertise for implementation. To address these challenges, we propose a novel\nsolution that combines ease of implementation with high decoding accuracy: a\ngeneralizable neural decoder enabled by pre-training on large-scale coarsely\ndiscretized word-gesture trajectories. This approach produces a ready-to-use\nWGK decoder that is generalizable across mid-air and on-surface WGK systems in\naugmented reality (AR) and virtual reality (VR), which is evident by a robust\naverage Top-4 accuracy of 90.4% on four diverse datasets. It significantly\noutperforms SHARK^2 with a 37.2% enhancement and surpasses the conventional\nneural decoder by 7.4%. Moreover, the Pre-trained Neural Decoder's size is only\n4 MB after quantization, without sacrificing accuracy, and it can operate in\nreal-time, executing in just 97 milliseconds on Quest 3.",
      "tldr_zh": "该论文提出Gesture2Text，一种通用的神经解码器，用于Extended Reality (XR) 环境中的Word-Gesture Keyboards (WGK)，通过轨迹粗糙离散化（Trajectory Coarse Discretization）和大规模预训练，解决交互模式多样性导致的轨迹解码复杂性问题。相比传统模板匹配方法如SHARK^2，该解码器显著提升准确性，在四个多样数据集上实现平均Top-4准确率90.4%，比SHARK^2提高37.2%并优于传统神经解码器7.4%。此外，该模型量化后仅4 MB，可在Quest 3上实时运行（97毫秒），兼顾易用性和高效性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.GR",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.18099v1",
      "published_date": "2024-10-08 12:53:22 UTC",
      "updated_date": "2024-10-08 12:53:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:37:11.835106"
    },
    {
      "arxiv_id": "2410.10869v1",
      "title": "Application of NotebookLM, a Large Language Model with Retrieval-Augmented Generation, for Lung Cancer Staging",
      "title_zh": "翻译失败",
      "authors": [
        "Ryota Tozuka",
        "Hisashi Johno",
        "Akitomo Amakawa",
        "Junichi Sato",
        "Mizuki Muto",
        "Shoichiro Seki",
        "Atsushi Komaba",
        "Hiroshi Onishi"
      ],
      "abstract": "Purpose: In radiology, large language models (LLMs), including ChatGPT, have\nrecently gained attention, and their utility is being rapidly evaluated.\nHowever, concerns have emerged regarding their reliability in clinical\napplications due to limitations such as hallucinations and insufficient\nreferencing. To address these issues, we focus on the latest technology,\nretrieval-augmented generation (RAG), which enables LLMs to reference reliable\nexternal knowledge (REK). Specifically, this study examines the utility and\nreliability of a recently released RAG-equipped LLM (RAG-LLM), NotebookLM, for\nstaging lung cancer.\n  Materials and methods: We summarized the current lung cancer staging\nguideline in Japan and provided this as REK to NotebookLM. We then tasked\nNotebookLM with staging 100 fictional lung cancer cases based on CT findings\nand evaluated its accuracy. For comparison, we performed the same task using a\ngold-standard LLM, GPT-4 Omni (GPT-4o), both with and without the REK.\n  Results: NotebookLM achieved 86% diagnostic accuracy in the lung cancer\nstaging experiment, outperforming GPT-4o, which recorded 39% accuracy with the\nREK and 25% without it. Moreover, NotebookLM demonstrated 95% accuracy in\nsearching reference locations within the REK.\n  Conclusion: NotebookLM successfully performed lung cancer staging by\nutilizing the REK, demonstrating superior performance compared to GPT-4o.\nAdditionally, it provided highly accurate reference locations within the REK,\nallowing radiologists to efficiently evaluate the reliability of NotebookLM's\nresponses and detect possible hallucinations. Overall, this study highlights\nthe potential of NotebookLM, a RAG-LLM, in image diagnosis.",
      "tldr_zh": "本研究评估了 NotebookLM，一种配备检索增强生成 (RAG) 的 Large Language Model (LLM)，在肺癌分期中的应用，旨在解决传统 LLM 如幻觉和引用不足的问题。研究方法包括提供日本肺癌分期指南作为可靠外部知识 (REK)，并让 NotebookLM 对 100 个虚构病例进行分期，与 GPT-4 Omni (GPT-4o) 进行比较。结果显示，NotebookLM 的分期准确率达 86%，显著优于 GPT-4o（有 REK 时 39%，无 REK 时 25%），并在引用位置搜索中达到 95% 的准确率。该方法突出了 RAG-LLM 在图像诊断中的潜力，提高了临床可靠性和效率。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "9 pages, 5 figures, 1 table, 3 ancillary files",
      "pdf_url": "http://arxiv.org/pdf/2410.10869v1",
      "published_date": "2024-10-08 12:42:42 UTC",
      "updated_date": "2024-10-08 12:42:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:37:22.294689"
    },
    {
      "arxiv_id": "2410.05991v1",
      "title": "Vector Grimoire: Codebook-based Shape Generation under Raster Image Supervision",
      "title_zh": "翻译失败",
      "authors": [
        "Moritz Feuerpfeil",
        "Marco Cipriano",
        "Gerard de Melo"
      ],
      "abstract": "Scalable Vector Graphics (SVG) is a popular format on the web and in the\ndesign industry. However, despite the great strides made in generative\nmodeling, SVG has remained underexplored due to the discrete and complex nature\nof such data. We introduce GRIMOIRE, a text-guided SVG generative model that is\ncomprised of two modules: A Visual Shape Quantizer (VSQ) learns to map raster\nimages onto a discrete codebook by reconstructing them as vector shapes, and an\nAuto-Regressive Transformer (ART) models the joint probability distribution\nover shape tokens, positions and textual descriptions, allowing us to generate\nvector graphics from natural language. Unlike existing models that require\ndirect supervision from SVG data, GRIMOIRE learns shape image patches using\nonly raster image supervision which opens up vector generative modeling to\nsignificantly more data. We demonstrate the effectiveness of our method by\nfitting GRIMOIRE for closed filled shapes on the MNIST and for outline strokes\non icon and font data, surpassing previous image-supervised methods in\ngenerative quality and vector-supervised approach in flexibility.",
      "tldr_zh": "本论文提出了一种名为 Vector Grimoire 的文本引导 SVG 生成模型，利用代码本（codebook）方法在栅格图像（raster image）监督下生成矢量形状。模型由两个模块组成：Visual Shape Quantizer (VSQ) 负责将栅格图像映射到离散代码本并重构为矢量形状，以及 Auto-Regressive Transformer (ART) 用于建模形状标记、位置和文本描述的联合概率分布，从而实现从自然语言生成矢量图形。不同于现有模型，GRIMOIRE 仅依赖栅格图像监督，而非直接 SVG 数据，这大大扩展了训练数据的可用性。在实验中，该模型在 MNIST 数据集的封闭填充形状以及图标和字体数据的轮廓笔画上，生成质量超过了之前的图像监督方法，并在灵活性上优于矢量监督方法。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.GR"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.05991v1",
      "published_date": "2024-10-08 12:41:31 UTC",
      "updated_date": "2024-10-08 12:41:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:37:33.798590"
    },
    {
      "arxiv_id": "2410.05988v1",
      "title": "Utilizing Lyapunov Exponents in designing deep neural networks",
      "title_zh": "利用 Lyapunov 指数设计深度神经网络",
      "authors": [
        "Tirthankar Mittra"
      ],
      "abstract": "Training large deep neural networks is resource intensive. This study\ninvestigates whether Lyapunov exponents can accelerate this process by aiding\nin the selection of hyperparameters. To study this I formulate an optimization\nproblem using neural networks with different activation functions in the hidden\nlayers. By initializing model weights with different random seeds, I calculate\nthe Lyapunov exponent while performing traditional gradient descent on these\nmodel weights. The findings demonstrate that variations in the learning rate\ncan induce chaotic changes in model weights. I also show that activation\nfunctions with more negative Lyapunov exponents exhibit better convergence\nproperties. Additionally, the study also demonstrates that Lyapunov exponents\ncan be utilized to select effective initial model weights for deep neural\nnetworks, potentially enhancing the optimization process.",
      "tldr_zh": "本研究探讨了利用Lyapunov exponents来加速深度神经网络的训练过程，通过辅助选择超参数以降低资源消耗。研究者制定了优化问题，使用不同激活函数的神经网络，并通过不同随机种子初始化权重，同时进行gradient descent计算Lyapunov exponents。结果显示，学习率变化会导致模型权重出现混沌行为，而具有更负Lyapunov exponents的激活函数表现出更好的收敛性能。该方法证明了Lyapunov exponents可用于选择有效的初始模型权重，从而提升整体优化效率。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.05988v1",
      "published_date": "2024-10-08 12:36:06 UTC",
      "updated_date": "2024-10-08 12:36:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:37:45.608051"
    },
    {
      "arxiv_id": "2410.11868v1",
      "title": "Neuropsychology of AI: Relationship Between Activation Proximity and Categorical Proximity Within Neural Categories of Synthetic Cognition",
      "title_zh": "翻译失败",
      "authors": [
        "Michael Pichat",
        "Enola Campoli",
        "William Pogrund",
        "Jourdan Wilson",
        "Michael Veillet-Guillem",
        "Anton Melkozerov",
        "Paloma Pichat",
        "Armanouche Gasparian",
        "Samuel Demarchi",
        "Judicael Poumay"
      ],
      "abstract": "Neuropsychology of artificial intelligence focuses on synthetic neural cog\nnition as a new type of study object within cognitive psychology. With the goal\nof making artificial neural networks of language models more explainable, this\napproach involves transposing concepts from cognitive psychology to the\ninterpretive construction of artificial neural cognition. The human cognitive\nconcept involved here is categorization, serving as a heuristic for thinking\nabout the process of segmentation and construction of reality carried out by\nthe neural vectors of synthetic cognition.",
      "tldr_zh": "这篇论文探讨了人工智能的神经心理学（Neuropsychology of AI），重点分析合成认知（Synthetic Cognition）的神经类别（Neural Categories）中激活接近度（Activation Proximity）和分类接近度（Categorical Proximity）之间的关系。研究将认知心理学的分类（categorization）概念移植到人工智能语言模型中，作为一种启发式方法，以提升神经网络的可解释性。最终，该方法有助于理解人工智能如何通过神经向量进行现实的分割和构建，为合成认知的研究提供新视角。",
      "categories": [
        "q-bio.NC",
        "cs.AI"
      ],
      "primary_category": "q-bio.NC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.11868v1",
      "published_date": "2024-10-08 12:34:13 UTC",
      "updated_date": "2024-10-08 12:34:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:37:57.953074"
    },
    {
      "arxiv_id": "2410.05985v3",
      "title": "Asynchronous Stochastic Gradient Descent with Decoupled Backpropagation and Layer-Wise Updates",
      "title_zh": "异步随机梯度下降，结合解耦反向传播和层级更新",
      "authors": [
        "Cabrel Teguemne Fokam",
        "Khaleelulla Khan Nazeer",
        "Lukas König",
        "David Kappel",
        "Anand Subramoney"
      ],
      "abstract": "The increasing size of deep learning models has made distributed training\nacross multiple devices essential. However, current methods such as distributed\ndata-parallel training suffer from large communication and synchronization\noverheads when training across devices, leading to longer training times as a\nresult of suboptimal hardware utilization. Asynchronous stochastic gradient\ndescent (ASGD) methods can improve training speed, but are sensitive to delays\ndue to both communication and differences throughput. Moreover, the\nbackpropagation algorithm used within ASGD workers is bottlenecked by the\ninterlocking between its forward and backward passes. Current methods also do\nnot take advantage of the large differences in the computation required for the\nforward and backward passes. Therefore, we propose an extension to ASGD called\nPartial Decoupled ASGD (PD-ASGD) that addresses these issues. PD-ASGD uses\nseparate threads for the forward and backward passes, decoupling the updates\nand allowing for a higher ratio of forward to backward threads than the usual\n1:1 ratio, leading to higher throughput. PD-ASGD also performs layer-wise\n(partial) model updates concurrently across multiple threads. This reduces\nparameter staleness and consequently improves robustness to delays. Our\napproach yields close to state-of-the-art results while running up to\n$5.95\\times$ faster than synchronous data parallelism in the presence of\ndelays, and up to $2.14\\times$ times faster than comparable ASGD algorithms by\nachieving higher model flops utilization. We mathematically describe the\ngradient bias introduced by our method, establish an upper bound, and prove\nconvergence.",
      "tldr_zh": "该论文针对分布式深度学习训练中的通信开销和同步瓶颈，提出了一种改进的Asynchronous Stochastic Gradient Descent (ASGD)方法，名为Partial Decoupled ASGD (PD-ASGD)。PD-ASGD通过使用独立线程解耦forward和backward passes，并允许forward线程与backward线程的比例大于1:1，同时进行layer-wise模型更新，以提高吞吐量、减少参数staleness并增强对延迟的鲁棒性。实验结果显示，该方法在延迟环境下比同步数据并行快5.95倍，比类似ASGD算法快2.14倍。论文还数学证明了PD-ASGD引入的梯度偏差上界并确立了其收敛性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NE",
        "G.1.6",
        "I.2.6; I.5.1"
      ],
      "primary_category": "cs.LG",
      "comment": "17 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.05985v3",
      "published_date": "2024-10-08 12:32:36 UTC",
      "updated_date": "2025-02-07 13:33:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:38:20.646062"
    },
    {
      "arxiv_id": "2410.05983v1",
      "title": "Long-Context LLMs Meet RAG: Overcoming Challenges for Long Inputs in RAG",
      "title_zh": "翻译失败",
      "authors": [
        "Bowen Jin",
        "Jinsung Yoon",
        "Jiawei Han",
        "Sercan O. Arik"
      ],
      "abstract": "Retrieval-augmented generation (RAG) empowers large language models (LLMs) to\nutilize external knowledge sources. The increasing capacity of LLMs to process\nlonger input sequences opens up avenues for providing more retrieved\ninformation, to potentially enhance the quality of generated outputs. It is\nplausible to assume that a larger retrieval set would contain more relevant\ninformation (higher recall), that might result in improved performance.\nHowever, our empirical findings demonstrate that for many long-context LLMs,\nthe quality of generated output initially improves first, but then subsequently\ndeclines as the number of retrieved passages increases. This paper investigates\nthis phenomenon, identifying the detrimental impact of retrieved \"hard\nnegatives\" as a key contributor. To mitigate this and enhance the robustness of\nlong-context LLM-based RAG, we propose both training-free and training-based\napproaches. We first showcase the effectiveness of retrieval reordering as a\nsimple yet powerful training-free optimization. Furthermore, we explore\ntraining-based methods, specifically RAG-specific implicit LLM fine-tuning and\nRAG-oriented fine-tuning with intermediate reasoning, demonstrating their\ncapacity for substantial performance gains. Finally, we conduct a systematic\nanalysis of design choices for these training-based methods, including data\ndistribution, retriever selection, and training context length.",
      "tldr_zh": "本研究探讨了长上下文大语言模型（LLMs）在检索增强生成（RAG）系统中的挑战，发现当检索的段落数量增加时，输出质量会先提升后下降，主要由于“hard negatives”（检索到的无关或干扰信息）的影响。作者提出训练-free 方法，如检索重新排序，以简单优化 RAG 的鲁棒性；同时，探索训练-based 方法，包括 RAG-specific 隐式 LLM 微调和 RAG-oriented 微调，结合中间推理来显著提升性能。最终，通过系统分析数据分布、检索器选择和训练上下文长度，证明这些方法能有效克服长输入挑战，为 RAG 应用提供实用指导。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "34 pages",
      "pdf_url": "http://arxiv.org/pdf/2410.05983v1",
      "published_date": "2024-10-08 12:30:07 UTC",
      "updated_date": "2024-10-08 12:30:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:38:22.117878"
    },
    {
      "arxiv_id": "2410.05970v2",
      "title": "PDF-WuKong: A Large Multimodal Model for Efficient Long PDF Reading with End-to-End Sparse Sampling",
      "title_zh": "翻译失败",
      "authors": [
        "Xudong Xie",
        "Hao Yan",
        "Liang Yin",
        "Yang Liu",
        "Jing Ding",
        "Minghui Liao",
        "Yuliang Liu",
        "Wei Chen",
        "Xiang Bai"
      ],
      "abstract": "Multimodal document understanding is a challenging task to process and\ncomprehend large amounts of textual and visual information. Recent advances in\nLarge Language Models (LLMs) have significantly improved the performance of\nthis task. However, existing methods typically focus on either plain text or a\nlimited number of document images, struggling to handle long PDF documents with\ninterleaved text and images, especially for academic papers. In this paper, we\nintroduce PDF-WuKong, a multimodal large language model (MLLM) which is\ndesigned to enhance multimodal question-answering (QA) for long PDF documents.\nPDF-WuKong incorporates a sparse sampler that operates on both text and image\nrepresentations, significantly improving the efficiency and capability of the\nMLLM. The sparse sampler is integrated with the MLLM's image encoder and\nselects the paragraphs or diagrams most pertinent to user queries for\nprocessing by the language model. To effectively train and evaluate our model,\nwe construct PaperPDF, a dataset consisting of a broad collection of English\nand Chinese academic papers. Multiple strategies are proposed to automatically\ngenerate 1.1 million QA pairs along with their corresponding evidence sources.\nExperimental results demonstrate the superiority and high efficiency of our\napproach over other models on the task of long multimodal document\nunderstanding, surpassing proprietary products by an average of 8.6% on F1. Our\ncode and dataset will be released at https://github.com/yh-hust/PDF-Wukong.",
      "tldr_zh": "本研究提出PDF-WuKong，一种高效的多模态大语言模型（MLLM），旨在处理长PDF文档的多模态问答（QA）任务，解决现有方法在处理交错文本和图像时的局限性。该模型整合了端到端稀疏采样器（sparse sampler），在文本和图像表示上选择与用户查询最相关的段落或图表，从而显著提升处理效率和准确性。为训练和评估模型，研究者构建了PaperPDF数据集，包含英文和中文学术论文，并自动生成110万QA对及其证据来源。实验结果显示，PDF-WuKong在长多模态文档理解任务上优于其他模型，平均F1分数比专有产品高8.6%。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.05970v2",
      "published_date": "2024-10-08 12:17:42 UTC",
      "updated_date": "2025-01-20 21:45:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:38:33.712313"
    },
    {
      "arxiv_id": "2410.05966v3",
      "title": "FLOPS: Forward Learning with OPtimal Sampling",
      "title_zh": "翻译失败",
      "authors": [
        "Tao Ren",
        "Zishi Zhang",
        "Jinyang Jiang",
        "Guanghao Li",
        "Zeliang Zhang",
        "Mingqian Feng",
        "Yijie Peng"
      ],
      "abstract": "Given the limitations of backpropagation, perturbation-based gradient\ncomputation methods have recently gained focus for learning with only forward\npasses, also referred to as queries. Conventional forward learning consumes\nenormous queries on each data point for accurate gradient estimation through\nMonte Carlo sampling, which hinders the scalability of those algorithms.\nHowever, not all data points deserve equal queries for gradient estimation. In\nthis paper, we study the problem of improving the forward learning efficiency\nfrom a novel perspective: how to reduce the gradient estimation variance with\nminimum cost? For this, we propose to allocate the optimal number of queries\nover each data in one batch during training to achieve a good balance between\nestimation accuracy and computational efficiency. Specifically, with a\nsimplified proxy objective and a reparameterization technique, we derive a\nnovel plug-and-play query allocator with minimal parameters. Theoretical\nresults are carried out to verify its optimality. We conduct extensive\nexperiments for fine-tuning Vision Transformers on various datasets and further\ndeploy the allocator to two black-box applications: prompt tuning and\nmultimodal alignment for foundation models. All findings demonstrate that our\nproposed allocator significantly enhances the scalability of forward-learning\nalgorithms, paving the way for real-world applications.",
      "tldr_zh": "本文提出FLOPS方法，针对backpropagation的局限性，通过最优采样策略来提升forward learning的效率，避免传统方法在梯度估计时对每个数据点使用过多queries。FLOPS采用简化代理目标和重参数化技术，设计了一个plug-and-play查询分配器，以最小参数实现梯度估计方差的降低，并通过理论证明其最优性。实验结果显示，该方法在微调Vision Transformers、prompt tuning和multimodal alignment等任务上显著提高了forward-learning算法的可扩展性，为实际应用提供了新路径。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Published in the Thirteenth International Conference on Learning\n  Representations(ICLR 2025)",
      "pdf_url": "http://arxiv.org/pdf/2410.05966v3",
      "published_date": "2024-10-08 12:16:12 UTC",
      "updated_date": "2025-03-08 12:06:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:38:45.809774"
    },
    {
      "arxiv_id": "2410.05964v1",
      "title": "STNet: Deep Audio-Visual Fusion Network for Robust Speaker Tracking",
      "title_zh": "翻译失败",
      "authors": [
        "Yidi Li",
        "Hong Liu",
        "Bing Yang"
      ],
      "abstract": "Audio-visual speaker tracking aims to determine the location of human targets\nin a scene using signals captured by a multi-sensor platform, whose accuracy\nand robustness can be improved by multi-modal fusion methods. Recently, several\nfusion methods have been proposed to model the correlation in multiple\nmodalities. However, for the speaker tracking problem, the cross-modal\ninteraction between audio and visual signals hasn't been well exploited. To\nthis end, we present a novel Speaker Tracking Network (STNet) with a deep\naudio-visual fusion model in this work. We design a visual-guided acoustic\nmeasurement method to fuse heterogeneous cues in a unified localization space,\nwhich employs visual observations via a camera model to construct the enhanced\nacoustic map. For feature fusion, a cross-modal attention module is adopted to\njointly model multi-modal contexts and interactions. The correlated information\nbetween audio and visual features is further interacted in the fusion model.\nMoreover, the STNet-based tracker is applied to multi-speaker cases by a\nquality-aware module, which evaluates the reliability of multi-modal\nobservations to achieve robust tracking in complex scenarios. Experiments on\nthe AV16.3 and CAV3D datasets show that the proposed STNet-based tracker\noutperforms uni-modal methods and state-of-the-art audio-visual speaker\ntrackers.",
      "tldr_zh": "本论文提出STNet，一种深度音频-视觉融合网络，用于实现稳健的说话者追踪，通过整合音频和视觉信号来提升定位准确性和鲁棒性。STNet采用视觉引导的声学测量方法构建增强的声学地图，并通过跨模态注意力模块联合建模多模态上下文和交互，同时引入质量感知模块来评估观察可靠性，适用于多说话者场景。实验在AV16.3和CAV3D数据集上表明，STNet超越了单模态方法和现有音频-视觉追踪器，展示了显著的性能提升。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.05964v1",
      "published_date": "2024-10-08 12:15:17 UTC",
      "updated_date": "2024-10-08 12:15:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:38:58.002631"
    },
    {
      "arxiv_id": "2410.07250v2",
      "title": "Lightweight Deep Learning Framework for Accurate Particle Flow Energy Reconstruction",
      "title_zh": "用于准确粒子流能量重建的轻量级深度学习框架",
      "authors": [
        "Yu Wang",
        "Yangguang Zhang",
        "Shengxiang Lin",
        "Xingyi Zhang",
        "Han Zhang"
      ],
      "abstract": "Under extreme operating conditions, characterized by high particle\nmultiplicity and heavily overlapping shower energy deposits, classical particle\nflow algorithms encounter pronounced limitations in resolution, efficiency, and\naccuracy. To address this challenge, this paper proposes and systematically\nevaluates a deep learning reconstruction framework: For multichannel sparse\nfeatures, we design a hybrid loss function combining weighted mean squared\nerror with structural similarity index, effectively balancing pixel-level\naccuracy and structural fidelity. By integrating 3D convolutions,\nSqueeze-and-Excitation channel attention, and Offset self-attention modules\ninto baseline convolutional neural networks, we enhance the model's capability\nto capture cross-modal spatiotemporal correlations and energy-displacement\nnonlinearities. Validated on custom-constructed simulation data and Pythia jet\ndatasets, the framework's 90K-parameter lightweight variant approaches the\nperformance of 5M-parameter baselines, while the 25M-parameter 3D model\nachieves state-of-the-art results in both interpolation and extrapolation\ntasks. Comprehensive experiments quantitatively evaluate component\ncontributions and provide performance-parameter trade-off guidelines. All core\ncode and data processing scripts are open-sourced on a GitHub repository to\nfacilitate community reproducibility and extension.",
      "tldr_zh": "该论文针对极端条件下（如高粒子多重性和能量重叠）经典粒子流算法的分辨率、效率和准确性限制，提出一个轻量级深度学习框架，用于精确的粒子流能量重建。该框架为多通道稀疏特征设计了混合损失函数，结合加权均方误差（weighted mean squared error）和结构相似性指数（structural similarity index），并通过整合 3D 卷积、Squeeze-and-Excitation 通道注意力和 Offset 自注意力模块来增强模型捕捉跨模态时空相关性和能量-位移非线性。在自定义模拟数据和 Pythia jet 数据集上的验证显示，90K 参数的轻量变体性能接近 5M 参数基线，而 25M 参数的 3D 模型在插值和外推任务中达到最先进水平，并提供了组件贡献评估和性能-参数权衡指南，所有核心代码已开源以促进社区复现和扩展。",
      "categories": [
        "physics.ins-det",
        "cs.AI"
      ],
      "primary_category": "physics.ins-det",
      "comment": "12 pages, 8 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.07250v2",
      "published_date": "2024-10-08 11:49:18 UTC",
      "updated_date": "2025-05-12 09:19:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:39:10.490294"
    },
    {
      "arxiv_id": "2410.05938v1",
      "title": "EMMA: Empowering Multi-modal Mamba with Structural and Hierarchical Alignment",
      "title_zh": "翻译失败",
      "authors": [
        "Yifei Xing",
        "Xiangyuan Lan",
        "Ruiping Wang",
        "Dongmei Jiang",
        "Wenjun Huang",
        "Qingfang Zheng",
        "Yaowei Wang"
      ],
      "abstract": "Mamba-based architectures have shown to be a promising new direction for deep\nlearning models owing to their competitive performance and sub-quadratic\ndeployment speed. However, current Mamba multi-modal large language models\n(MLLM) are insufficient in extracting visual features, leading to imbalanced\ncross-modal alignment between visual and textural latents, negatively impacting\nperformance on multi-modal tasks. In this work, we propose Empowering\nMulti-modal Mamba with Structural and Hierarchical Alignment (EMMA), which\nenables the MLLM to extract fine-grained visual information. Specifically, we\npropose a pixel-wise alignment module to autoregressively optimize the learning\nand processing of spatial image-level features along with textual tokens,\nenabling structural alignment at the image level. In addition, to prevent the\ndegradation of visual information during the cross-model alignment process, we\npropose a multi-scale feature fusion (MFF) module to combine multi-scale visual\nfeatures from intermediate layers, enabling hierarchical alignment at the\nfeature level. Extensive experiments are conducted across a variety of\nmulti-modal benchmarks. Our model shows lower latency than other Mamba-based\nMLLMs and is nearly four times faster than transformer-based MLLMs of similar\nscale during inference. Due to better cross-modal alignment, our model exhibits\nlower degrees of hallucination and enhanced sensitivity to visual details,\nwhich manifests in superior performance across diverse multi-modal benchmarks.\nCode will be provided.",
      "tldr_zh": "该研究提出EMMA框架，用于增强多模态Mamba-based大语言模型(MLLM)，通过结构和层次对齐解决视觉特征提取不足和跨模态对齐不平衡的问题。具体地，EMMA引入像素-wise alignment模块来自动回归优化图像级空间特征与文本标记的学习，实现图像级结构对齐；并采用multi-scale feature fusion (MFF)模块融合中间层的多尺度视觉特征，防止信息退化并实现特征级层次对齐。实验结果显示，EMMA在各种多模态基准上表现出色，比其他Mamba-based MLLMs延迟更低、推理速度快近四倍于类似规模的Transformer-based MLLMs，并显著降低幻觉并提升对视觉细节的敏感性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.05938v1",
      "published_date": "2024-10-08 11:41:55 UTC",
      "updated_date": "2024-10-08 11:41:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:39:22.678669"
    },
    {
      "arxiv_id": "2410.05937v2",
      "title": "Athanor: Local Search over Abstract Constraint Specifications",
      "title_zh": "翻译失败",
      "authors": [
        "Saad Attieh",
        "Nguyen Dang",
        "Christopher Jefferson",
        "Ian Miguel",
        "Peter Nightingale"
      ],
      "abstract": "Local search is a common method for solving combinatorial optimisation\nproblems. We focus on general-purpose local search solvers that accept as input\na constraint model - a declarative description of a problem consisting of a set\nof decision variables under a set of constraints. Existing approaches typically\ntake as input models written in solver-independent constraint modelling\nlanguages like MiniZinc. The Athanor solver we describe herein differs in that\nit begins from a specification of a problem in the abstract constraint\nspecification language Essence, which allows problems to be described without\ncommitment to low-level modelling decisions through its support for a rich set\nof abstract types. The advantage of proceeding from Essence is that the\nstructure apparent in a concise, abstract specification of a problem can be\nexploited to generate high quality neighbourhoods automatically, avoiding the\ndifficult task of identifying that structure in an equivalent constraint model.\nBased on the twin benefits of neighbourhoods derived from high level types and\nthe scalability derived by searching directly over those types, our empirical\nresults demonstrate strong performance in practice relative to existing\nsolution methods.",
      "tldr_zh": "该论文提出Athanor，一种基于抽象约束规范语言Essence的局部搜索(local search)求解器，用于解决组合优化(combinatorial optimisation)问题，与现有依赖MiniZinc等语言的求解器不同。Athanor利用Essence的高层抽象类型，避免低级建模决策，直接从问题规范中自动生成高质量邻域(neighbourhoods)，从而提升搜索效率和可扩展性。实验结果显示，Athanor在实际应用中相对于现有方法表现出更强的性能。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "72 pages",
      "pdf_url": "http://arxiv.org/pdf/2410.05937v2",
      "published_date": "2024-10-08 11:41:38 UTC",
      "updated_date": "2025-01-02 14:41:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:39:33.603012"
    },
    {
      "arxiv_id": "2410.05930v1",
      "title": "Fortify Your Foundations: Practical Privacy and Security for Foundation Model Deployments In The Cloud",
      "title_zh": "翻译失败",
      "authors": [
        "Marcin Chrapek",
        "Anjo Vahldiek-Oberwagner",
        "Marcin Spoczynski",
        "Scott Constable",
        "Mona Vij",
        "Torsten Hoefler"
      ],
      "abstract": "Foundation Models (FMs) display exceptional performance in tasks such as\nnatural language processing and are being applied across a growing range of\ndisciplines. Although typically trained on large public datasets, FMs are often\nfine-tuned or integrated into Retrieval-Augmented Generation (RAG) systems,\nwhich rely on private data. This access, along with their size and costly\ntraining, heightens the risk of intellectual property theft. Moreover,\nmultimodal FMs may expose sensitive information. In this work, we examine the\nFM threat model and discuss the practicality and comprehensiveness of various\napproaches for securing against them, such as ML-based methods and trusted\nexecution environments (TEEs). We demonstrate that TEEs offer an effective\nbalance between strong security properties, usability, and performance.\nSpecifically, we present a solution achieving less than 10\\% overhead versus\nbare metal for the full Llama2 7B and 13B inference pipelines running inside\n\\intel\\ SGX and \\intel\\ TDX. We also share our configuration files and insights\nfrom our implementation. To our knowledge, our work is the first to show the\npracticality of TEEs for securing FMs.",
      "tldr_zh": "该论文探讨了Foundation Models (FMs)在云部署中的隐私和安全风险，包括微调或整合Retrieval-Augmented Generation (RAG)系统时可能导致的知识产权盗窃和敏感信息暴露。作者分析了FM的威胁模型，并比较了各种安全方法，如基于ML的方法和Trusted Execution Environments (TEEs)，强调TEEs在安全属性、可用性和性能之间实现了有效平衡。通过实际实现，展示了在Intel SGX和Intel TDX中运行Llama2 7B和13B推理管道的解决方案，性能开销不到10%。这项工作首次证明了TEEs在保护FMs方面的实用性，并分享了配置文件和实施见解。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.05930v1",
      "published_date": "2024-10-08 11:33:09 UTC",
      "updated_date": "2024-10-08 11:33:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:39:46.910476"
    },
    {
      "arxiv_id": "2410.05928v1",
      "title": "Beyond Captioning: Task-Specific Prompting for Improved VLM Performance in Mathematical Reasoning",
      "title_zh": "超越标注：任务特定提示用于改善视觉语言模型在数学推理中的性能",
      "authors": [
        "Ayush Singh",
        "Mansi Gupta",
        "Shivank Garg",
        "Abhinav Kumar",
        "Vansh Agrawal"
      ],
      "abstract": "Vision-Language Models (VLMs) have transformed tasks requiring visual and\nreasoning abilities, such as image retrieval and Visual Question Answering\n(VQA). Despite their success, VLMs face significant challenges with tasks\ninvolving geometric reasoning, algebraic problem-solving, and counting. These\nlimitations stem from difficulties effectively integrating multiple modalities\nand accurately interpreting geometry-related tasks. Various works claim that\nintroducing a captioning pipeline before VQA tasks enhances performance. We\nincorporated this pipeline for tasks involving geometry, algebra, and counting.\nWe found that captioning results are not generalizable, specifically with\nlarger VLMs primarily trained on downstream QnA tasks showing random\nperformance on math-related challenges. However, we present a promising\nalternative: task-based prompting, enriching the prompt with task-specific\nguidance. This approach shows promise and proves more effective than direct\ncaptioning methods for math-heavy problems.",
      "tldr_zh": "该研究探讨了 Vision-Language Models (VLMs) 在数学推理任务（如几何、代数和计数）上的挑战，这些问题源于多模态整合和任务解释的困难，尽管 VLMs 在图像检索和 Visual Question Answering (VQA) 中表现出色。作者发现，传统的标题生成(captioning)管道虽被认为能提升性能，但实际在数学相关任务上不通用，尤其对主要训练在 QnA 任务上的更大模型，表现随机。作为替代，论文提出任务特定提示(task-based prompting)方法，通过在提示中添加针对性指导来丰富输入。实验结果表明，这种方法比直接标题生成更有效，提升了 VLMs 在数学推理任务中的整体表现。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.05928v1",
      "published_date": "2024-10-08 11:29:40 UTC",
      "updated_date": "2024-10-08 11:29:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:39:58.222913"
    },
    {
      "arxiv_id": "2410.18097v3",
      "title": "RRADistill: Distilling LLMs' Passage Ranking Ability for Long-Tail Queries Document Re-Ranking on a Search Engine",
      "title_zh": "翻译失败",
      "authors": [
        "Nayoung Choi",
        "Youngjune Lee",
        "Gyu-Hwung Cho",
        "Haeyu Jeong",
        "Jungmin Kong",
        "Saehun Kim",
        "Keunchan Park",
        "Sarah Cho",
        "Inchang Jeong",
        "Gyohee Nam",
        "Sunghoon Han",
        "Wonil Yang",
        "Jaeho Choi"
      ],
      "abstract": "Large Language Models (LLMs) excel at understanding the semantic\nrelationships between queries and documents, even with lengthy and complex\nlong-tail queries. These queries are challenging for feedback-based rankings\ndue to sparse user engagement and limited feedback, making LLMs' ranking\nability highly valuable. However, the large size and slow inference of LLMs\nnecessitate the development of smaller, more efficient models (sLLMs).\nRecently, integrating ranking label generation into distillation techniques has\nbecome crucial, but existing methods underutilize LLMs' capabilities and are\ncumbersome. Our research, RRADistill: Re-Ranking Ability Distillation, propose\nan efficient label generation pipeline and novel sLLM training methods for both\nencoder and decoder models. We introduce an encoder-based method using a Term\nControl Layer to capture term matching signals and a decoder-based model with a\nranking layer for enhanced understanding. A/B testing on a Korean-based search\nplatform, validates the effectiveness of our approach in improving re-ranking\nfor long-tail queries.",
      "tldr_zh": "本文提出 RRADistill 方法，用于从 LLMs 中蒸馏长尾查询的文档重排能力，以解决传统反馈排名在用户互动稀少时的挑战。RRADistill 包括一个高效的标签生成管道，以及基于编码器的 Term Control Layer 来捕捉术语匹配信号，和基于解码器的排名层以增强语义理解，从而训练更小、更高效的 sLLMs。在韩国搜索平台的 A/B 测试中，该方法显著提高了长尾查询的再排名性能，验证了其有效性。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.IR",
      "comment": "Accepted to EMNLP 2024 Industry Track. First two authors contributed\n  equally",
      "pdf_url": "http://arxiv.org/pdf/2410.18097v3",
      "published_date": "2024-10-08 11:28:06 UTC",
      "updated_date": "2024-11-21 14:23:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:40:20.341671"
    },
    {
      "arxiv_id": "2410.10868v3",
      "title": "Large Continual Instruction Assistant",
      "title_zh": "翻译失败",
      "authors": [
        "Jingyang Qiao",
        "Zhizhong Zhang",
        "Xin Tan",
        "Yanyun Qu",
        "Shouhong Ding",
        "Yuan Xie"
      ],
      "abstract": "Continual Instruction Tuning (CIT) is adopted to continually instruct Large\nModels to follow human intent data by data. It is observed that existing\ngradient update would heavily destroy the performance on previous datasets\nduring CIT process. Instead, Exponential Moving Average (EMA), owns the ability\nto trace previous parameters, which can aid in decreasing forgetting.\nNonetheless, its stable balance weight fails to deal with the ever-changing\ndatasets, leading to the out-of-balance between plasticity and stability. In\nthis paper, we propose a general continual instruction tuning framework to\naddress the challenge. Starting from the trade-off prerequisite and EMA update,\nwe propose the plasticity and stability ideal condition. Based on Taylor\nexpansion in the loss function, we find the optimal balance weight can be\nautomatically determined by the gradients and learned parameters. Therefore, we\npropose a stable-plasticity balanced coefficient to avoid knowledge confusion.\nBased on the semantic similarity of the instructions, we can determine whether\nto retrain or expand the training parameters and allocate the most suitable\nparameters for the testing instances. Extensive experiments across multiple\ncontinual instruction tuning benchmarks demonstrate that our approach not only\nenhances anti-forgetting capabilities but also significantly improves overall\ncontinual tuning performance. For example, based on LLaVA-7B, the forgetting is\nreduced from 5.42 to 1.93. Our code will be made publicly available soon.",
      "tldr_zh": "这篇论文针对 Continual Instruction Tuning (CIT) 的遗忘问题，提出了一种通用框架来平衡模型的可塑性和稳定性。作者基于 Exponential Moving Average (EMA) 更新，通过损失函数的 Taylor expansion 自动计算最优平衡权重，并引入 stable-plasticity balanced coefficient 来避免知识混乱，同时利用指令的语义相似性决定参数的重新训练或扩展。实验结果显示，该框架在多个基准上显著提升了反遗忘能力，例如基于 LLaVA-7B 的遗忘率从 5.42 降至 1.93，并整体提高了持续调优性能。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.10868v3",
      "published_date": "2024-10-08 11:24:59 UTC",
      "updated_date": "2025-02-19 07:01:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:40:23.406584"
    },
    {
      "arxiv_id": "2410.05920v3",
      "title": "FINALLY: fast and universal speech enhancement with studio-like quality",
      "title_zh": "FINALLY：快速且通用的语音增强，具有录音室般的质量",
      "authors": [
        "Nicholas Babaev",
        "Kirill Tamogashev",
        "Azat Saginbaev",
        "Ivan Shchekotov",
        "Hanbin Bae",
        "Hosang Sung",
        "WonJun Lee",
        "Hoon-Young Cho",
        "Pavel Andreev"
      ],
      "abstract": "In this paper, we address the challenge of speech enhancement in real-world\nrecordings, which often contain various forms of distortion, such as background\nnoise, reverberation, and microphone artifacts. We revisit the use of\nGenerative Adversarial Networks (GANs) for speech enhancement and theoretically\nshow that GANs are naturally inclined to seek the point of maximum density\nwithin the conditional clean speech distribution, which, as we argue, is\nessential for the speech enhancement task. We study various feature extractors\nfor perceptual loss to facilitate the stability of adversarial training,\ndeveloping a methodology for probing the structure of the feature space. This\nleads us to integrate WavLM-based perceptual loss into MS-STFT adversarial\ntraining pipeline, creating an effective and stable training procedure for the\nspeech enhancement model. The resulting speech enhancement model, which we\nrefer to as FINALLY, builds upon the HiFi++ architecture, augmented with a\nWavLM encoder and a novel training pipeline. Empirical results on various\ndatasets confirm our model's ability to produce clear, high-quality speech at\n48 kHz, achieving state-of-the-art performance in the field of speech\nenhancement. Demo page: https://samsunglabs.github.io/FINALLY-page",
      "tldr_zh": "这篇论文提出了一种名为 FINALLY 的语音增强模型，旨在处理真实世界录音中的背景噪声、回声和麦克风 artifacts 等问题，通过理论分析证明 GANs 自然倾向于优化条件干净语音分布，从而提升增强效果。作者整合了 WavLM-based 感知损失和 MS-STFT 对抗训练管道，构建基于 HiFi++ 架构的稳定训练过程，实现快速且通用的语音处理。实验结果显示，FINALLY 在多种数据集上达到了最先进性能，能生成高质量的 48 kHz 清晰语音，接近录音棚级别。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "Accepted to NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2410.05920v3",
      "published_date": "2024-10-08 11:16:03 UTC",
      "updated_date": "2024-10-31 08:47:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:40:33.717882"
    },
    {
      "arxiv_id": "2410.05915v2",
      "title": "Give me a hint: Can LLMs take a hint to solve math problems?",
      "title_zh": "翻译失败",
      "authors": [
        "Vansh Agrawal",
        "Pratham Singla",
        "Amitoj Singh Miglani",
        "Shivank Garg",
        "Ayush Mangal"
      ],
      "abstract": "While state-of-the-art LLMs have shown poor logical and basic mathematical\nreasoning, recent works try to improve their problem-solving abilities using\nprompting techniques. We propose giving \"hints\" to improve the language model's\nperformance on advanced mathematical problems, taking inspiration from how\nhumans approach math pedagogically. We also test robustness to adversarial\nhints and demonstrate their sensitivity to them. We demonstrate the\neffectiveness of our approach by evaluating various diverse LLMs, presenting\nthem with a broad set of problems of different difficulties and topics from the\nMATH dataset and comparing against techniques such as one-shot, few-shot, and\nchain of thought prompting.",
      "tldr_zh": "本研究探讨了是否可以通过提供“hints”来提升大型语言模型（LLMs）在数学问题上的推理性能，灵感来源于人类教学方法。\n研究者评估了多种LLMs在MATH数据集上处理不同难度和主题的问题，并将hints方法与one-shot、few-shot和chain of thought提示技术进行比较。\n结果表明，hints能显著改善模型的表现，但LLMs对负面或对抗性hints非常敏感，突显了其鲁棒性问题。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.05915v2",
      "published_date": "2024-10-08 11:09:31 UTC",
      "updated_date": "2024-11-09 08:32:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:40:45.337979"
    },
    {
      "arxiv_id": "2410.10867v1",
      "title": "Mitigating the Impact of Reference Quality on Evaluation of Summarization Systems with Reference-Free Metrics",
      "title_zh": "通过无参考指标缓解参考",
      "authors": [
        "Théo Gigant",
        "Camille Guinaudeau",
        "Marc Decombas",
        "Frédéric Dufaux"
      ],
      "abstract": "Automatic metrics are used as proxies to evaluate abstractive summarization\nsystems when human annotations are too expensive. To be useful, these metrics\nshould be fine-grained, show a high correlation with human annotations, and\nideally be independent of reference quality; however, most standard evaluation\nmetrics for summarization are reference-based, and existing reference-free\nmetrics correlate poorly with relevance, especially on summaries of longer\ndocuments. In this paper, we introduce a reference-free metric that correlates\nwell with human evaluated relevance, while being very cheap to compute. We show\nthat this metric can also be used alongside reference-based metrics to improve\ntheir robustness in low quality reference settings.",
      "tldr_zh": "该论文探讨了在摘要系统评估中，如何通过无参考指标(reference-free metrics)缓解参考质量(reference quality)的影响问题，因为基于参考的指标(reference-based metrics)容易受参考质量限制，且现有无参考指标与人类评估的相关性较差。研究者引入了一种新的无参考指标，该指标与人类评估的相关性高，且计算成本低，能够有效评估长文档摘要的关联性。实验结果显示，这种指标可与基于参考的指标结合使用，提升评估在低质量参考设置下的鲁棒性，从而为更可靠的摘要系统评估提供实用方法。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR",
        "cs.MM"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.10867v1",
      "published_date": "2024-10-08 11:09:25 UTC",
      "updated_date": "2024-10-08 11:09:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:40:57.568868"
    },
    {
      "arxiv_id": "2410.05911v1",
      "title": "Accelerating Error Correction Code Transformers",
      "title_zh": "翻译失败",
      "authors": [
        "Matan Levy",
        "Yoni Choukroun",
        "Lior Wolf"
      ],
      "abstract": "Error correction codes (ECC) are crucial for ensuring reliable information\ntransmission in communication systems. Choukroun & Wolf (2022b) recently\nintroduced the Error Correction Code Transformer (ECCT), which has demonstrated\npromising performance across various transmission channels and families of\ncodes. However, its high computational and memory demands limit its practical\napplications compared to traditional decoding algorithms. Achieving effective\nquantization of the ECCT presents significant challenges due to its inherently\nsmall architecture, since existing, very low-precision quantization techniques\noften lead to performance degradation in compact neural networks. In this\npaper, we introduce a novel acceleration method for transformer-based decoders.\nWe first propose a ternary weight quantization method specifically designed for\nthe ECCT, inducing a decoder with multiplication-free linear layers. We present\nan optimized self-attention mechanism to reduce computational complexity via\ncodeaware multi-heads processing. Finally, we provide positional encoding via\nthe Tanner graph eigendecomposition, enabling a richer representation of the\ngraph connectivity. The approach not only matches or surpasses ECCT's\nperformance but also significantly reduces energy consumption, memory\nfootprint, and computational complexity. Our method brings transformer-based\nerror correction closer to practical implementation in resource-constrained\nenvironments, achieving a 90% compression ratio and reducing arithmetic\noperation energy consumption by at least 224 times on modern hardware.",
      "tldr_zh": "这篇论文针对 Error Correction Code Transformer (ECCT) 的高计算和内存需求，提出了一种新型加速方法，以提升其在资源受限环境中的实用性。主要方法包括三元权重量化（ternary weight quantization），使线性层免于乘法运算；优化自注意力机制（self-attention mechanism）通过代码感知多头处理降低计算复杂度；以及利用 Tanner 图特征分解（Tanner graph eigendecomposition）提供位置编码，以丰富图连接表示。该方法在性能上匹配或超越 ECCT，同时实现了 90% 的压缩比和至少 224 倍的算术操作能量消耗减少，推动基于变压器的错误纠正代码更接近实际实现。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.IT",
        "math.IT"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.05911v1",
      "published_date": "2024-10-08 11:07:55 UTC",
      "updated_date": "2024-10-08 11:07:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:41:20.595954"
    },
    {
      "arxiv_id": "2410.05903v1",
      "title": "Automatic Summarization of Long Documents",
      "title_zh": "翻译失败",
      "authors": [
        "Naman Chhibbar",
        "Jugal Kalita"
      ],
      "abstract": "A vast amount of textual data is added to the internet daily, making\nutilization and interpretation of such data difficult and cumbersome. As a\nresult, automatic text summarization is crucial for extracting relevant\ninformation, saving precious reading time. Although many transformer-based\nmodels excel in summarization, they are constrained by their input size,\npreventing them from processing texts longer than their context size. This\nstudy introduces three novel algorithms that allow any LLM to efficiently\novercome its input size limitation, effectively utilizing its full potential\nwithout any architectural modifications. We test our algorithms on texts with\nmore than 70,000 words, and our experiments show a significant increase in\nBERTScore with competitive ROUGE scores.",
      "tldr_zh": "这篇论文针对互联网每天产生的大量文本数据，强调了自动文本摘要的重要性，以节省阅读时间和提取关键信息。研究引入了三种新算法，允许任何大语言模型(LLM)克服输入大小限制，从而处理超过70,000词的长文档，而无需对模型架构进行修改。在实验中，这些算法显著提高了BERTScore，同时保持了竞争性的ROUGE分数。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "9 pages (including bibliography) with 6 figures. ACL 2023 proceedings\n  format",
      "pdf_url": "http://arxiv.org/pdf/2410.05903v1",
      "published_date": "2024-10-08 11:00:49 UTC",
      "updated_date": "2024-10-08 11:00:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:41:21.597153"
    },
    {
      "arxiv_id": "2410.05902v1",
      "title": "Mini-Batch Kernel $k$-means",
      "title_zh": "翻译失败",
      "authors": [
        "Ben Jourdan",
        "Gregory Schwartzman"
      ],
      "abstract": "We present the first mini-batch kernel $k$-means algorithm, offering an order\nof magnitude improvement in running time compared to the full batch algorithm.\nA single iteration of our algorithm takes $\\widetilde{O}(kb^2)$ time,\nsignificantly faster than the $O(n^2)$ time required by the full batch kernel\n$k$-means, where $n$ is the dataset size and $b$ is the batch size. Extensive\nexperiments demonstrate that our algorithm consistently achieves a 10-100x\nspeedup with minimal loss in quality, addressing the slow runtime that has\nlimited kernel $k$-means adoption in practice. We further complement these\nresults with a theoretical analysis under an early stopping condition, proving\nthat with a batch size of $\\widetilde{\\Omega}(\\max \\{\\gamma^{4}, \\gamma^{2}\\}\n\\cdot \\epsilon^{-2})$, the algorithm terminates in $O(\\gamma^2/\\epsilon)$\niterations with high probability, where $\\gamma$ bounds the norm of points in\nfeature space and $\\epsilon$ is a termination threshold. Our analysis holds for\nany reasonable center initialization, and when using $k$-means++\ninitialization, the algorithm achieves an approximation ratio of $O(\\log k)$ in\nexpectation. For normalized kernels, such as Gaussian or Laplacian it holds\nthat $\\gamma=1$. Taking $\\epsilon = O(1)$ and $b=\\Theta(\\log n)$, the algorithm\nterminates in $O(1)$ iterations, with each iteration running in\n$\\widetilde{O}(k)$ time.",
      "tldr_zh": "本研究提出了首个迷你批量 (mini-batch) 内核 $k$-means 算法，与全批量算法相比，其运行时间提高了约一个数量级，每个迭代的时间复杂度为 $\\widetilde{O}(kb^2)$，而全批量需要 $O(n^2)$。实验结果显示，该算法在保持质量最小损失的情况下，实现 10-100 倍的速度提升，解决了内核 $k$-means 在实际应用中的缓慢运行问题。理论分析证明，在提前停止条件下，使用 $\\widetilde{\\Omega}(\\max \\{\\gamma^{4}, \\gamma^{2}\\} \\cdot \\epsilon^{-2})$ 的批量大小，该算法能在 $O(\\gamma^2/\\epsilon)$ 迭代内高概率终止；若采用 $k$-means++ 初始化，还能期望达到 $O(\\log k)$ 的近似比率。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DS"
      ],
      "primary_category": "cs.LG",
      "comment": "arXiv admin note: text overlap with arXiv:2304.00419",
      "pdf_url": "http://arxiv.org/pdf/2410.05902v1",
      "published_date": "2024-10-08 10:59:14 UTC",
      "updated_date": "2024-10-08 10:59:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:41:34.287917"
    },
    {
      "arxiv_id": "2410.18096v1",
      "title": "$M^3EL$: A Multi-task Multi-topic Dataset for Multi-modal Entity Linking",
      "title_zh": "翻译失败",
      "authors": [
        "Fang Wang",
        "Shenglin Yin",
        "Xiaoying Bai",
        "Minghao Hu",
        "Tianwei Yan",
        "Yi Liang"
      ],
      "abstract": "Multi-modal Entity Linking (MEL) is a fundamental component for various\ndownstream tasks. However, existing MEL datasets suffer from small scale,\nscarcity of topic types and limited coverage of tasks, making them incapable of\neffectively enhancing the entity linking capabilities of multi-modal models. To\naddress these obstacles, we propose a dataset construction pipeline and publish\n$M^3EL$, a large-scale dataset for MEL. $M^3EL$ includes 79,625 instances,\ncovering 9 diverse multi-modal tasks, and 5 different topics. In addition, to\nfurther improve the model's adaptability to multi-modal tasks, We propose a\nmodality-augmented training strategy. Utilizing $M^3EL$ as a corpus, train the\n$\\textit{CLIP}_{\\textit{ND}}$ model based on $\\textit{CLIP}\n(\\textit{ViT}-\\textit{B}-\\textit{32})$, and conduct a comparative analysis with\nan existing multi-modal baselines. Experimental results show that the existing\nmodels perform far below expectations (ACC of 49.4%-75.8%), After analysis, it\nwas obtained that small dataset sizes, insufficient modality task coverage, and\nlimited topic diversity resulted in poor generalisation of multi-modal models.\nOur dataset effectively addresses these issues, and the\n$\\textit{CLIP}_{\\textit{ND}}$ model fine-tuned with $M^3EL$ shows a significant\nimprovement in accuracy, with an average improvement of 9.3% to 25% across\nvarious tasks. Our dataset is available at\nhttps://anonymous.4open.science/r/M3EL.",
      "tldr_zh": "该论文针对 Multi-modal Entity Linking (MEL) 的数据集问题，提出一个构建管道并发布 $M^3EL$ 数据集，该数据集包含 79,625 个实例，覆盖 9 个多模态任务和 5 个不同主题，以解决现有数据集规模小、主题类型少和任务覆盖有限的不足。论文还引入了一种模态增强训练策略，利用 $M^3EL$ 对 $\\textit{CLIP}_{\\textit{ND}}$ 模型（基于 $\\textit{CLIP} (\\textit{ViT}-\\textit{B}-\\textit{32})$）进行训练。实验结果显示，现有基线模型的准确率仅为 49.4%-75.8%，而使用新数据集和策略后，模型在各种任务上的准确率平均提升 9.3% 到 25%，显著提高了多模态模型的泛化能力。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CL",
        "cs.CV"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.18096v1",
      "published_date": "2024-10-08 10:52:23 UTC",
      "updated_date": "2024-10-08 10:52:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:41:46.721686"
    },
    {
      "arxiv_id": "2410.05892v1",
      "title": "Towards an Autonomous Surface Vehicle Prototype for Artificial Intelligence Applications of Water Quality Monitoring",
      "title_zh": "翻译失败",
      "authors": [
        "Luis Miguel Díaz",
        "Samuel Yanes Luis",
        "Alejandro Mendoza Barrionuevo",
        "Dame Seck Diop",
        "Manuel Perales",
        "Alejandro Casado",
        "Sergio Toral",
        "Daniel Gutiérrez"
      ],
      "abstract": "The use of Autonomous Surface Vehicles, equipped with water quality sensors\nand artificial vision systems, allows for a smart and adaptive deployment in\nwater resources environmental monitoring. This paper presents a real\nimplementation of a vehicle prototype that to address the use of Artificial\nIntelligence algorithms and enhanced sensing techniques for water quality\nmonitoring. The vehicle is fully equipped with high-quality sensors to measure\nwater quality parameters and water depth. Furthermore, by means of a\nstereo-camera, it also can detect and locate macro-plastics in real\nenvironments by means of deep visual models, such as YOLOv5. In this paper,\nexperimental results, carried out in Lago Mayor (Sevilla), has been presented\nas proof of the capabilities of the proposed architecture. The overall system,\nand the early results obtained, are expected to provide a solid example of a\nreal platform useful for the water resource monitoring task, and to serve as a\nreal case scenario for deploying Artificial Intelligence algorithms, such as\npath planning, artificial vision, etc.",
      "tldr_zh": "这篇论文介绍了用于水质监测的 Autonomous Surface Vehicle 原型，旨在通过人工智能算法和增强传感技术实现智能适应性部署。该车辆配备高品质传感器测量水质参数和水深，并利用立体相机结合 YOLOv5 等深度视觉模型检测和定位宏观塑料。在塞维利亚 Lago Mayor 的实验结果证明了系统的有效性，为水资源监测任务提供了一个实际平台，并支持人工智能应用如路径规划和视觉处理。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.05892v1",
      "published_date": "2024-10-08 10:35:32 UTC",
      "updated_date": "2024-10-08 10:35:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:41:57.509794"
    },
    {
      "arxiv_id": "2410.05889v1",
      "title": "Deep learning-based fault identification in condition monitoring",
      "title_zh": "基于深度学习的条件监测中的故障识别",
      "authors": [
        "Hariom Dhungana",
        "Suresh Kumar Mukhiya",
        "Pragya Dhungana",
        "Benjamin Karic"
      ],
      "abstract": "Vibration-based condition monitoring techniques are commonly used to identify\nfaults in rolling element bearings. Accuracy and speed of fault detection\nprocedures are critical performance measures in condition monitoring. Delay is\nespecially important in remote condition monitoring and time-sensitive\nindustrial applications. While most existing methods focus on accuracy, little\nattention has been given to the inference time in the fault identification\nprocess. In this paper, we address this gap by presenting a Convolutional\nNeural Network (CNN) based approach for real-time fault identification in\nrolling element bearings. We encode raw vibration signals into two-dimensional\nimages using various encoding methods and use these with a CNN to classify\nseveral categories of bearing fault types and sizes. We analyse the interplay\nbetween fault identification accuracy and processing time. For training and\nevaluation we use a bearing failure CWRU dataset.",
      "tldr_zh": "本文提出了一种基于卷积神经网络(CNN)的实时故障识别方法，用于振动-based条件监测中的滚动轴承故障检测。针对现有方法忽略推断时间的问题，该方法将原始振动信号编码成二维图像，并利用CNN分类不同轴承故障类型和大小。实验使用CWRU轴承故障数据集评估了准确性和处理时间的平衡，实现了更高的实时性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.05889v1",
      "published_date": "2024-10-08 10:31:13 UTC",
      "updated_date": "2024-10-08 10:31:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:42:09.485632"
    },
    {
      "arxiv_id": "2410.10866v1",
      "title": "CodeUnlearn: Amortized Zero-Shot Machine Unlearning in Language Models Using Discrete Concept",
      "title_zh": "翻译失败",
      "authors": [
        "YuXuan Wu",
        "Bonaventure F. P. Dossou",
        "Dianbo Liu"
      ],
      "abstract": "Large Language Models (LLMs) offer extensive knowledge across various\ndomains, but they may inadvertently memorize sensitive, unauthorized, or\nmalicious data, such as personal information in the medical and financial\nsectors. Machine unlearning methods aim to remove specific information from\nmodels after training to address this. However, current approaches require\nadditional model training or struggle to effectively erase particular data\npoints and their associated context due to LLMs' complex, dense, and continuous\nnature. In this study, we propose a novel amortized unlearning approach using\ncodebook features and Sparse Autoencoders (SAEs). By leveraging a bottleneck to\ndecompose the activation space and regulate information flow, our method\nefficiently unlearns targeted information while preserving the model's\nperformance on unrelated data. To the best of our knowledge, this is the first\nwork that successfully enables unlearning specific topics with contextual\nrelevance in an LLM, marking a significant step towards real-world applications\nof machine unlearning.",
      "tldr_zh": "本研究提出 CodeUnlearn，一种摊销式(amortized)零样本(zero-shot)机器遗忘方法，针对 Large Language Models (LLMs) 无意中记忆敏感或恶意数据的问题。该方法利用 codebook features 和 Sparse Autoencoders (SAEs) 来分解激活空间并调节信息流，从而高效地删除特定信息，同时保持模型在无关数据上的性能。实验结果显示，这是首个成功在 LLM 中遗忘特定主题及其上下文相关性的工作，为机器遗忘在实际应用中的推广奠定了基础。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.10866v1",
      "published_date": "2024-10-08 10:26:22 UTC",
      "updated_date": "2024-10-08 10:26:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:42:21.681242"
    },
    {
      "arxiv_id": "2410.18095v2",
      "title": "Ethical Leadership in the Age of AI Challenges, Opportunities and Framework for Ethical Leadership",
      "title_zh": "AI 时代下的道德领导力：挑战、机会以及道德领导力的框架",
      "authors": [
        "Udaya Chandrika Kandasamy"
      ],
      "abstract": "Artificial Intelligence is currently and rapidly changing the way\norganizations and businesses operate. Ethical leadership has become\nsignificantly important since organizations and businesses across various\nsectors are evolving with AI. Organizations and businesses may be facing\nseveral challenges and potential opportunities when using AI. Ethical\nleadership plays a central role in guiding organizations in facing those\nchallenges and maximizing on those opportunities. This article explores the\nessence of ethical leadership in the age of AI, starting with a simplified\nintroduction of ethical leadership and AI, then dives into an understanding of\nethical leadership, its characteristics and importance, the ethical challenges\nAI causes including bias in AI algorithms. The opportunities for ethical\nleadership in the age of AI answers the question: What actionable strategies\ncan leaders employ to address the challenges and leverage opportunities? and\ndescribes the benefits for organizations through these opportunities. A\nproposed framework for ethical leadership is presented in this article,\nincorporating the core components: fairness, transparency, sustainability etc.\nThrough the importance of interdisciplinary collaboration, case studies of\nethical leadership in AI, and recommendations, this article emphasizes that\nethical leadership in the age of AI is morally essential and strategically\nadvantageous.",
      "tldr_zh": "这篇论文探讨了AI时代道德领导力的核心作用，强调它在应对AI带来的挑战（如算法偏见）和抓住机会（如制定行动策略）方面的必要性。论文首先介绍了道德领导力的定义、特征及其重要性，然后分析了AI对组织的影响，并提出可操作策略来提升组织公平性、透明度和可持续性。最终，该框架通过跨学科合作、案例研究和推荐，证明道德领导力不仅是道德必需，还能为组织带来战略优势。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "15 pages, submitted to SAGE for review",
      "pdf_url": "http://arxiv.org/pdf/2410.18095v2",
      "published_date": "2024-10-08 10:17:19 UTC",
      "updated_date": "2024-10-30 18:30:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:42:33.379992"
    },
    {
      "arxiv_id": "2410.18094v1",
      "title": "Self-supervised inter-intra period-aware ECG representation learning for detecting atrial fibrillation",
      "title_zh": "翻译失败",
      "authors": [
        "Xiangqian Zhu",
        "Mengnan Shi",
        "Xuexin Yu",
        "Chang Liu",
        "Xiaocong Lian",
        "Jintao Fei",
        "Jiangying Luo",
        "Xin Jin",
        "Ping Zhang",
        "Xiangyang Ji"
      ],
      "abstract": "Atrial fibrillation is a commonly encountered clinical arrhythmia associated\nwith stroke and increased mortality. Since professional medical knowledge is\nrequired for annotation, exploiting a large corpus of ECGs to develop accurate\nsupervised learning-based atrial fibrillation algorithms remains challenging.\nSelf-supervised learning (SSL) is a promising recipe for generalized ECG\nrepresentation learning, eliminating the dependence on expensive labeling.\nHowever, without well-designed incorporations of knowledge related to atrial\nfibrillation, existing SSL approaches typically suffer from unsatisfactory\ncapture of robust ECG representations. In this paper, we propose an inter-intra\nperiod-aware ECG representation learning approach. Considering ECGs of atrial\nfibrillation patients exhibit the irregularity in RR intervals and the absence\nof P-waves, we develop specific pre-training tasks for interperiod and\nintraperiod representations, aiming to learn the single-period stable\nmorphology representation while retaining crucial interperiod features. After\nfurther fine-tuning, our approach demonstrates remarkable AUC performances on\nthe BTCH dataset, \\textit{i.e.}, 0.953/0.996 for paroxysmal/persistent atrial\nfibrillation detection. On commonly used benchmarks of CinC2017 and CPSC2021,\nthe generalization capability and effectiveness of our methodology are\nsubstantiated with competitive results.",
      "tldr_zh": "该论文提出了一种自监督的inter-intra period-aware ECG representation learning方法，用于检测房颤，以解决标注数据稀缺的问题。该方法针对房颤ECG的RR间隔不规则和P波缺失特点，设计了interperiod和intraperiod的具体预训练任务，旨在学习单周期稳定形态表示的同时保留关键interperiod特征。在BTCH数据集上fine-tuning后，该方法在间歇性/持续性房颤检测中达到了0.953/0.996的AUC性能，并在CinC2017和CPSC2021基准上展示了出色的泛化能力和有效性。",
      "categories": [
        "q-bio.QM",
        "cs.AI",
        "cs.LG",
        "eess.SP"
      ],
      "primary_category": "q-bio.QM",
      "comment": "Preprint submitted to Biomedical Signal Processing and Control",
      "pdf_url": "http://arxiv.org/pdf/2410.18094v1",
      "published_date": "2024-10-08 10:03:52 UTC",
      "updated_date": "2024-10-08 10:03:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:42:46.675213"
    },
    {
      "arxiv_id": "2410.05873v1",
      "title": "MEXA: Multilingual Evaluation of English-Centric LLMs via Cross-Lingual Alignment",
      "title_zh": "MEXA：通过跨语言对齐对英文中心大型语言模型进行多语言评估",
      "authors": [
        "Amir Hossein Kargaran",
        "Ali Modarressi",
        "Nafiseh Nikeghbal",
        "Jana Diesner",
        "François Yvon",
        "Hinrich Schütze"
      ],
      "abstract": "English-centric large language models (LLMs) often show strong multilingual\ncapabilities. However, the multilingual performance of these models remains\nunclear and is not thoroughly evaluated for many languages. Most benchmarks for\nmultilinguality focus on classic NLP tasks, or cover a minimal number of\nlanguages. We introduce MEXA, a method for assessing the multilingual\ncapabilities of pre-trained English-centric LLMs using parallel sentences,\nwhich are available for more languages than existing downstream tasks. MEXA\nleverages the fact that English-centric LLMs use English as a kind of pivot\nlanguage in their intermediate layers. It computes the alignment between\nEnglish and non-English languages using parallel sentences to evaluate the\ntransfer of language understanding from English to other languages. This\nalignment can be used to estimate model performance in other languages. We\nconduct studies using various parallel datasets (FLORES-200 and Bible), models\n(Llama family, Gemma family, Mistral, and OLMo), and established downstream\ntasks (Belebele, m-MMLU, and m-ARC). We explore different methods to compute\nembeddings in decoder-only models. Our results show that MEXA, in its default\nsettings, achieves a statistically significant average Pearson correlation of\n0.90 with three established downstream tasks across nine models and two\nparallel datasets. This suggests that MEXA is a reliable method for estimating\nthe multilingual capabilities of English-centric LLMs, providing a clearer\nunderstanding of their multilingual potential and the inner workings of LLMs.\nLeaderboard: https://huggingface.co/spaces/cis-lmu/Mexa, Code:\nhttps://github.com/cisnlp/Mexa.",
      "tldr_zh": "本文提出MEXA方法，用于评估以英语为中心的LLMs的多语言能力，通过利用平行句子计算跨语言对齐（cross-lingual alignment）。MEXA基于英语作为枢纽语言（pivot language），评估语言理解从英语向其他语言的转移，并在各种模型（如Llama家族和Mistral）和数据集（如FLORES-200和Bible）上进行实验。结果显示，MEXA在默认设置下，与下游任务（Belebele、m-MMLU和m-ARC）的平均Pearson correlation达到0.90，这表明它是一种可靠的工具，能提供对LLMs多语言潜力的清晰洞见。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.05873v1",
      "published_date": "2024-10-08 09:59:23 UTC",
      "updated_date": "2024-10-08 09:59:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:42:59.697027"
    },
    {
      "arxiv_id": "2410.05871v2",
      "title": "A second-order-like optimizer with adaptive gradient scaling for deep learning",
      "title_zh": "一种带有自适应梯度缩放的类似于二阶优化器的深度学习优化器",
      "authors": [
        "Jérôme Bolte",
        "Ryan Boustany",
        "Edouard Pauwels",
        "Andrei Purica"
      ],
      "abstract": "In this empirical article, we introduce INNAprop, an optimization algorithm\nthat combines the INNA method with the RMSprop adaptive gradient scaling. It\nleverages second-order information and rescaling while keeping the memory\nrequirements of standard DL methods as AdamW or SGD with momentum. After giving\ngeometrical insights, we evaluate INNAprop on CIFAR-10, Food101, and ImageNet\nwith ResNets, VGG, DenseNet, and ViT, and on GPT-2 (OpenWebText) train from\nscratch and with LoRA fine-tuning (E2E). INNAprop consistently matches or\noutperforms AdamW both in training speed and accuracy, with minimal\nhyperparameter tuning in large-scale settings. Our code is publicly available\nat \\url{https://github.com/innaprop/innaprop}.",
      "tldr_zh": "该论文引入了 INNAprop，一种结合 INNA 方法和 RMSprop 自适应梯度缩放的优化算法，利用二阶信息进行高效训练，同时保持与 AdamW 或 SGD with momentum 相当的内存需求。作者通过几何洞见解释了算法原理，并在 CIFAR-10、Food101 和 ImageNet 等数据集上测试了多种模型，如 ResNets、VGG、DenseNet 和 ViT，以及 GPT-2 的从零训练和 LoRA 微调。实验结果显示，INNAprop 在训练速度和准确性上与 AdamW 相当或优于它，且只需最少的超参数调整，代码已公开可用于 https://github.com/innaprop/innaprop。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "math.OC"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.05871v2",
      "published_date": "2024-10-08 09:58:38 UTC",
      "updated_date": "2024-12-12 12:07:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:43:10.772973"
    },
    {
      "arxiv_id": "2410.05870v1",
      "title": "Heuristics for Partially Observable Stochastic Contingent Planning",
      "title_zh": "翻译失败",
      "authors": [
        "Guy Shani"
      ],
      "abstract": "Acting to complete tasks in stochastic partially observable domains is an\nimportant problem in artificial intelligence, and is often formulated as a\ngoal-based POMDP. Goal-based POMDPs can be solved using the RTDP-BEL algorithm,\nthat operates by running forward trajectories from the initial belief to the\ngoal. These trajectories can be guided by a heuristic, and more accurate\nheuristics can result in significantly faster convergence. In this paper, we\ndevelop a heuristic function that leverages the structured representation of\ndomain models. We compute, in a relaxed space, a plan to achieve the goal,\nwhile taking into account the value of information, as well as the stochastic\neffects. We provide experiments showing that while our heuristic is slower to\ncompute, it requires an order of magnitude less trajectories before\nconvergence. Overall, it thus speeds up RTDP-BEL, particularly in problems\nwhere significant information gathering is needed.",
      "tldr_zh": "本研究针对随机部分可观测域中的任务规划问题，提出了一种新的启发式函数(heuristic function)，用于提升基于目标的 POMDP 求解算法 RTDP-BEL 的性能。该启发式函数利用域模型的结构化表示，在松弛空间中计算达到目标的计划，同时考虑信息价值(value of information)和随机效果(stochastic effects)。实验结果显示，虽然该函数计算速度较慢，但它能减少一个数量级的轨迹数量来实现收敛，从而整体加速 RTDP-BEL 算法，尤其在需要大量信息收集的场景中。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.05870v1",
      "published_date": "2024-10-08 09:57:16 UTC",
      "updated_date": "2024-10-08 09:57:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:43:21.427917"
    },
    {
      "arxiv_id": "2410.05869v4",
      "title": "Believing is Seeing: Unobserved Object Detection using Generative Models",
      "title_zh": "翻译失败",
      "authors": [
        "Subhransu S. Bhattacharjee",
        "Dylan Campbell",
        "Rahul Shome"
      ],
      "abstract": "Can objects that are not visible in an image -- but are in the vicinity of\nthe camera -- be detected? This study introduces the novel tasks of 2D, 2.5D\nand 3D unobserved object detection for predicting the location of nearby\nobjects that are occluded or lie outside the image frame. We adapt several\nstate-of-the-art pre-trained generative models to address this task, including\n2D and 3D diffusion models and vision-language models, and show that they can\nbe used to infer the presence of objects that are not directly observed. To\nbenchmark this task, we propose a suite of metrics that capture different\naspects of performance. Our empirical evaluation on indoor scenes from the\nRealEstate10k and NYU Depth v2 datasets demonstrate results that motivate the\nuse of generative models for the unobserved object detection task.",
      "tldr_zh": "本文引入了2D、2.5D 和 3D unobserved object detection 任务，用于预测图像中被遮挡或位于帧外的附近物体位置。研究者通过适应预训练的 generative models（如 2D 和 3D diffusion models 以及 vision-language models），实现了对未直接观察物体的推断，并提出了一系列评估指标。实验结果显示，在 RealEstate10k 和 NYU Depth v2 数据集的室内场景中，这些模型表现出色，证明了 generative models 在该任务中的潜力。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "IEEE/CVF Computer Vision and Pattern Recognition 2025; 22 pages",
      "pdf_url": "http://arxiv.org/pdf/2410.05869v4",
      "published_date": "2024-10-08 09:57:14 UTC",
      "updated_date": "2025-03-24 13:41:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:43:34.963117"
    },
    {
      "arxiv_id": "2410.05864v4",
      "title": "From Tokens to Words: On the Inner Lexicon of LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Guy Kaplan",
        "Matanel Oren",
        "Yuval Reif",
        "Roy Schwartz"
      ],
      "abstract": "Natural language is composed of words, but modern large language models\n(LLMs) process sub-words as input. A natural question raised by this\ndiscrepancy is whether LLMs encode words internally, and if so how. We present\nevidence that LLMs engage in an intrinsic detokenization process, where\nsub-word sequences are combined into coherent whole-word representations at\ntheir last token. Our experiments show that this process primarily takes place\nwithin the early and middle layers of the model. We further demonstrate its\nrobustness to arbitrary splits (e.g., \"cats\" to \"ca\" and \"ts\"), typos, and\nimportantly-to out-of-vocabulary words: when feeding the last token internal\nrepresentations of such words to the model as input, it can \"understand\" them\nas the complete word despite never seeing such representations as input during\ntraining. Our findings suggest that LLMs maintain a latent vocabulary beyond\nthe tokenizer's scope. These insights provide a practical, finetuning-free\napplication for expanding the vocabulary of pre-trained models. By enabling the\naddition of new vocabulary words, we reduce input length and inference\niterations, which reduces both space and model latency, with little to no loss\nin model accuracy.",
      "tldr_zh": "这篇论文探讨了大型语言模型 (LLMs) 如何在内部处理子词 (tokens) 以形成完整的单词，揭示了 LLMs 进行内在 detokenization 过程，将子词序列在最后一个 token 处组合成连贯的单词表示，主要发生在模型的早期和中间层。研究通过实验证明，这一过程对任意分割（如 \"cats\" 到 \"ca\" 和 \"ts\"）、拼写错误以及词汇外单词具有鲁棒性，即使从未在训练中见过这些表示，模型也能“理解”它们。关键发现是 LLMs 维护了一个超出 tokenizer 范围的潜在词汇 (inner lexicon)。这项工作提供了一种无需微调的实用方法来扩展模型词汇，从而减少输入长度和推理迭代，降低空间占用和延迟，同时几乎不损失准确性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to the International Conference on Learning Representations\n  (ICLR) 2025",
      "pdf_url": "http://arxiv.org/pdf/2410.05864v4",
      "published_date": "2024-10-08 09:53:35 UTC",
      "updated_date": "2025-03-03 14:30:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:43:49.398128"
    },
    {
      "arxiv_id": "2410.05860v1",
      "title": "MelissaDL x Breed: Towards Data-Efficient On-line Supervised Training of Multi-parametric Surrogates with Active Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Sofya Dymchenko",
        "Abhishek Purandare",
        "Bruno Raffin"
      ],
      "abstract": "Artificial intelligence is transforming scientific computing with deep neural\nnetwork surrogates that approximate solutions to partial differential equations\n(PDEs). Traditional off-line training methods face issues with storage and I/O\nefficiency, as the training dataset has to be computed with numerical solvers\nup-front. Our previous work, the Melissa framework, addresses these problems by\nenabling data to be created \"on-the-fly\" and streamed directly into the\ntraining process. In this paper we introduce a new active learning method to\nenhance data-efficiency for on-line surrogate training. The surrogate is direct\nand multi-parametric, i.e., it is trained to predict a given timestep directly\nwith different initial and boundary conditions parameters. Our approach uses\nAdaptive Multiple Importance Sampling guided by training loss statistics, in\norder to focus NN training on the difficult areas of the parameter space.\nPreliminary results for 2D heat PDE demonstrate the potential of this method,\ncalled Breed, to improve the generalization capabilities of surrogates while\nreducing computational overhead.",
      "tldr_zh": "这篇论文针对深度神经网络代理模型在求解 Partial Differential Equations (PDEs) 时的训练效率问题，提出了 Breed 方法，以提升在线监督训练的多参数代理模型数据利用率。基于 Melissa 框架，该方法结合主动学习（Active Learning）和 Adaptive Multiple Importance Sampling，通过训练损失统计指导，聚焦参数空间的难点区域进行采样。初步实验结果显示，在 2D 热传导 PDE 的场景中，Breed 显著提高了代理模型的泛化能力，同时降低了计算开销。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.05860v1",
      "published_date": "2024-10-08 09:52:15 UTC",
      "updated_date": "2024-10-08 09:52:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:43:58.036828"
    },
    {
      "arxiv_id": "2410.05851v1",
      "title": "Communicating with Speakers and Listeners of Different Pragmatic Levels",
      "title_zh": "翻译失败",
      "authors": [
        "Kata Naszadi",
        "Frans A. Oliehoek",
        "Christof Monz"
      ],
      "abstract": "This paper explores the impact of variable pragmatic competence on\ncommunicative success through simulating language learning and conversing\nbetween speakers and listeners with different levels of reasoning abilities.\nThrough studying this interaction, we hypothesize that matching levels of\nreasoning between communication partners would create a more beneficial\nenvironment for communicative success and language learning. Our research\nfindings indicate that learning from more explicit, literal language is\nadvantageous, irrespective of the learner's level of pragmatic competence.\nFurthermore, we find that integrating pragmatic reasoning during language\nlearning, not just during evaluation, significantly enhances overall\ncommunication performance. This paper provides key insights into the importance\nof aligning reasoning levels and incorporating pragmatic reasoning in\noptimizing communicative interactions.",
      "tldr_zh": "本论文探讨了不同实用主义能力（pragmatic competence）水平对沟通成功的影响，通过模拟语言学习和对话来研究说话者和听者之间不同推理能力的互动。研究假设匹配推理水平能创造更有利的沟通环境，并发现从更明确、字面意义（explicit, literal language）的语言中学习对任何实用主义能力水平的学习者都有益处。此外，整合实用主义推理（pragmatic reasoning）到语言学习过程而非仅限于评估阶段，能显著提升整体沟通表现。该研究为优化沟通互动提供了关键见解，强调了推理水平对齐的重要性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "EMNLP 2024 main",
      "pdf_url": "http://arxiv.org/pdf/2410.05851v1",
      "published_date": "2024-10-08 09:42:37 UTC",
      "updated_date": "2024-10-08 09:42:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:44:09.532415"
    },
    {
      "arxiv_id": "2410.18092v1",
      "title": "Two-Stage Radio Map Construction with Real Environments and Sparse Measurements",
      "title_zh": "两阶段无线电地图构建：基于真实环境和稀疏测量",
      "authors": [
        "Yifan Wang",
        "Shu Sun",
        "Na Liu",
        "Lianming Xu",
        "Li Wang"
      ],
      "abstract": "Radio map construction based on extensive measurements is accurate but\nexpensive and time-consuming, while environment-aware radio map estimation\nreduces the costs at the expense of low accuracy. Considering accuracy and\ncosts, a first-predict-then-correct (FPTC) method is proposed by leveraging\ngenerative adversarial networks (GANs). A primary radio map is first predicted\nby a radio map prediction GAN (RMP-GAN) taking environmental information as\ninput. Then, the prediction result is corrected by a radio map correction GAN\n(RMC-GAN) with sparse measurements as guidelines. Specifically, the\nself-attention mechanism and residual-connection blocks are introduced to\nRMP-GAN and RMC-GAN to improve the accuracy, respectively. Experimental results\nvalidate that the proposed FPTC-GANs method achieves the best radio map\nconstruction performance, compared with the state-of-the-art methods.",
      "tldr_zh": "本研究针对无线电地图(radio map)构建的准确性和成本权衡问题，提出了一种两阶段first-predict-then-correct (FPTC)方法，利用生成对抗网络(GANs)来减少测量需求。方法首先通过Radio Map Prediction GAN (RMP-GAN)基于环境信息预测初步地图，然后利用Radio Map Correction GAN (RMC-GAN)结合稀疏测量进行修正，并引入self-attention机制和residual-connection blocks以提高准确性。实验结果显示，FPTC-GANs方法在无线电地图构建性能上优于现有最先进方法。",
      "categories": [
        "eess.SP",
        "cs.AI"
      ],
      "primary_category": "eess.SP",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.18092v1",
      "published_date": "2024-10-08 09:15:27 UTC",
      "updated_date": "2024-10-08 09:15:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:44:21.650131"
    },
    {
      "arxiv_id": "2410.05839v1",
      "title": "Bottom-up Anytime Discovery of Generalised Multimodal Graph Patterns for Knowledge Graphs",
      "title_zh": "翻译失败",
      "authors": [
        "Xander Wilcke",
        "Rick Mourits",
        "Auke Rijpma",
        "Richard Zijdeman"
      ],
      "abstract": "Vast amounts of heterogeneous knowledge are becoming publicly available in\nthe form of knowledge graphs, often linking multiple sources of data that have\nnever been together before, and thereby enabling scholars to answer many new\nresearch questions. It is often not known beforehand, however, which questions\nthe data might have the answers to, potentially leaving many interesting and\nnovel insights to remain undiscovered. To support scholars during this\nscientific workflow, we introduce an anytime algorithm for the bottom-up\ndiscovery of generalized multimodal graph patterns in knowledge graphs. Each\npattern is a conjunction of binary statements with (data-) type variables,\nconstants, and/or value patterns. Upon discovery, the patterns are converted to\nSPARQL queries and presented in an interactive facet browser together with\nmetadata and provenance information, enabling scholars to explore, analyse, and\nshare queries. We evaluate our method from a user perspective, with the help of\ndomain experts in the humanities.",
      "tldr_zh": "该论文针对知识图谱中大量异构数据的整合问题，提出了一种bottom-up anytime algorithm，用于自动发现generalized multimodal graph patterns。这些patterns由二元语句的结合构成，包括(type-) variables, constants 和value patterns，并可转换为SPARQL queries，以交互式facet browser呈现，支持学者探索、分析和分享查询。研究通过人文领域专家的用户评估，验证了该方法在揭示潜在洞见方面的有效性。",
      "categories": [
        "cs.AI",
        "cs.DB",
        "68T10",
        "I.5.1"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.05839v1",
      "published_date": "2024-10-08 09:07:27 UTC",
      "updated_date": "2024-10-08 09:07:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:44:33.295842"
    },
    {
      "arxiv_id": "2410.05838v2",
      "title": "Time Transfer: On Optimal Learning Rate and Batch Size In The Infinite Data Limit",
      "title_zh": "翻译失败",
      "authors": [
        "Oleg Filatov",
        "Jan Ebert",
        "Jiangtao Wang",
        "Stefan Kesselheim"
      ],
      "abstract": "One of the main challenges in optimal scaling of large language models (LLMs)\nis the prohibitive cost of hyperparameter tuning, particularly learning rate\n$\\eta$ and batch size $B$. While techniques like $\\mu$P (Yang et al., 2022)\nprovide scaling rules for optimal $\\eta$ transfer in the infinite model size\nlimit, the optimal scaling behavior in the infinite data size limit remains\nunknown. We fill in this gap by observing for the first time an intricate\ndependence of optimal $\\eta$ scaling on the pretraining token budget $T$, $B$\nand its relation to the critical batch size $B_\\mathrm{crit}$, which we measure\nto evolve as $B_\\mathrm{crit} \\propto T$. Furthermore, we show that the optimal\nbatch size is positively correlated with $B_\\mathrm{crit}$: keeping it fixed\nbecomes suboptimal over time even if learning rate is scaled optimally.\nSurprisingly, our results demonstrate that the observed optimal $\\eta$ and $B$\ndynamics are preserved with $\\mu$P model scaling, challenging the conventional\nview of $B_\\mathrm{crit}$ dependence solely on loss value. Complementing\noptimality, we examine the sensitivity of loss to changes in learning rate,\nwhere we find the sensitivity to decrease with increase of $T$ and to remain\nconstant with $\\mu$P model scaling. We hope our results make the first step\ntowards a unified picture of the joint optimal data and model scaling.",
      "tldr_zh": "该研究探讨了大型语言模型(LLMs)中学习率$\\eta$和批量大小$B$的优化缩放问题，尤其在无限数据大小极限下。研究首次观察到$\\eta$的最佳缩放依赖于预训练令牌预算$T$、$B$及其与关键批量大小$B_\\mathrm{crit}$的关系，其中$B_\\mathrm{crit} \\propto T$。此外，结果显示最佳$B$与$B_\\mathrm{crit}$正相关，即使$\\eta$优化后，固定$B$也会变得次优，且这些动态与$\\mu$P模型缩放兼容。研究还发现，损失对$\\eta$变化的敏感性随$T$增加而降低，并保持在$\\mu$P模型缩放下不变，为实现数据和模型联合最佳缩放提供重要基础。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.05838v2",
      "published_date": "2024-10-08 09:06:34 UTC",
      "updated_date": "2025-01-09 14:04:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:44:46.697873"
    },
    {
      "arxiv_id": "2410.05827v1",
      "title": "Towards an Operational Responsible AI Framework for Learning Analytics in Higher Education",
      "title_zh": "翻译失败",
      "authors": [
        "Alba Morales Tirado",
        "Paul Mulholland",
        "Miriam Fernandez"
      ],
      "abstract": "Universities are increasingly adopting data-driven strategies to enhance\nstudent success, with AI applications like Learning Analytics (LA) and\nPredictive Learning Analytics (PLA) playing a key role in identifying at-risk\nstudents, personalising learning, supporting teachers, and guiding educational\ndecision-making. However, concerns are rising about potential harms these\nsystems may pose, such as algorithmic biases leading to unequal support for\nminority students. While many have explored the need for Responsible AI in LA,\nexisting works often lack practical guidance for how institutions can\noperationalise these principles. In this paper, we propose a novel Responsible\nAI framework tailored specifically to LA in Higher Education (HE). We started\nby mapping 11 established Responsible AI frameworks, including those by leading\ntech companies, to the context of LA in HE. This led to the identification of\nseven key principles such as transparency, fairness, and accountability. We\nthen conducted a systematic review of the literature to understand how these\nprinciples have been applied in practice. Drawing from these findings, we\npresent a novel framework that offers practical guidance to HE institutions and\nis designed to evolve with community input, ensuring its relevance as LA\nsystems continue to develop.",
      "tldr_zh": "这篇论文针对高等教育中的学习分析 (LA) 和预测学习分析 (PLA)，提出一个可操作的 Responsible AI 框架，以缓解算法偏差等潜在风险，确保公平支持学生和决策。作者首先映射了 11 个现有 Responsible AI 框架到 LA 情境，识别出七个关键原则，包括透明性、公平性和问责性，并通过系统文献回顾分析这些原则的实际应用。最终，该框架提供实用指导，帮助高等教育机构实施 Responsible AI，并允许通过社区输入不断演化。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "16 pages, 1 figure, submitted to LAK 25",
      "pdf_url": "http://arxiv.org/pdf/2410.05827v1",
      "published_date": "2024-10-08 08:55:24 UTC",
      "updated_date": "2024-10-08 08:55:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:44:58.069309"
    },
    {
      "arxiv_id": "2410.05806v2",
      "title": "A Parameter Update Balancing Algorithm for Multi-task Ranking Models in Recommendation Systems",
      "title_zh": "翻译失败",
      "authors": [
        "Jun Yuan",
        "Guohao Cai",
        "Zhenhua Dong"
      ],
      "abstract": "Multi-task ranking models have become essential for modern real-world\nrecommendation systems. While most recommendation researches focus on designing\nsophisticated models for specific scenarios, achieving performance improvement\nfor multi-task ranking models across various scenarios still remains a\nsignificant challenge. Training all tasks naively can result in inconsistent\nlearning, highlighting the need for the development of multi-task optimization\n(MTO) methods to tackle this challenge. Conventional methods assume that the\noptimal joint gradient on shared parameters leads to optimal parameter updates.\nHowever, the actual update on model parameters may deviates significantly from\ngradients when using momentum based optimizers such as Adam, and we design and\nexecute statistical experiments to support the observation. In this paper, we\npropose a novel Parameter Update Balancing algorithm for multi-task\noptimization, denoted as PUB. In contrast to traditional MTO method which are\nbased on gradient level tasks fusion or loss level tasks fusion, PUB is the\nfirst work to optimize multiple tasks through parameter update balancing.\nComprehensive experiments on benchmark multi-task ranking datasets demonstrate\nthat PUB consistently improves several multi-task backbones and achieves\nstate-of-the-art performance. Additionally, experiments on benchmark computer\nvision datasets show the great potential of PUB in various multi-task learning\nscenarios. Furthermore, we deployed our method for an industrial evaluation on\nthe real-world commercial platform, HUAWEI AppGallery, where PUB significantly\nenhances the online multi-task ranking model, efficiently managing the primary\ntraffic of a crucial channel.",
      "tldr_zh": "该论文针对推荐系统中多任务排名模型的训练不一致问题，提出了一种新型Parameter Update Balancing (PUB)算法，通过在参数更新级别平衡多个任务，取代传统的梯度或损失级别任务融合方法。PUB 解决了使用动量优化器（如Adam）时参数更新偏差的问题，并通过统计实验验证了其有效性。在基准多任务排名数据集和计算机视觉数据集上的实验表明，PUB 显著提升了多种多任务模型的性能，并达到了最先进水平。此外，该算法已在HUAWEI AppGallery的实际平台上部署，显著提高了在线多任务排名模型的效果。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.IR",
      "comment": "Accepted by ICDM'24",
      "pdf_url": "http://arxiv.org/pdf/2410.05806v2",
      "published_date": "2024-10-08 08:39:15 UTC",
      "updated_date": "2025-02-12 07:38:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:45:10.704546"
    },
    {
      "arxiv_id": "2410.18091v1",
      "title": "Predicting Fine-grained Behavioral and Psychological Symptoms of Dementia Based on Machine Learning and Smart Wearable Devices",
      "title_zh": "翻译失败",
      "authors": [
        "Benny Wei-Yun Hsu",
        "Yu-Ming Chen",
        "Yuan-Han Yang",
        "Vincent S. Tseng"
      ],
      "abstract": "Behavioral and Psychological Symptoms of Dementia (BPSD) impact dementia care\nsubstantially, affecting both patients and caregivers. Effective management and\nearly detection of BPSD are crucial to reduce the stress and burden on\ncaregivers and healthcare systems. Despite the advancements in machine learning\nfor dementia prediction, there is a considerable gap in utilizing these methods\nfor BPSD prediction. This study aims to fill this gap by presenting a novel\npersonalized framework for BPSD prediction, utilizing physiological signals\nfrom smart wearable devices. Our personalized fine-grained BPSD prediction\nmethod accurately predicts BPSD occurrences by extracting individual behavioral\npatterns, while the generalized models identify diverse patterns and\ndifferentiate between various BPSD symptoms. Detailed comparisons between the\nproposed personalized method and conventional generalized methods reveals\nsubstantial improvements across all performance metrics, including a 16.0%\nincrease in AUC. These results demonstrate the potential of our proposed method\nin advancing dementia care by enabling proactive interventions and improving\npatient outcomes in real-world scenarios. To the best of our knowledge, this is\nthe first study that leverages physiological signals from smart wearable\ndevices to predict BPSD, marking a significant stride in dementia care\nresearch.",
      "tldr_zh": "本研究提出了一种基于机器学习的个性化框架，用于预测痴呆症的行为和心理症状（Behavioral and Psychological Symptoms of Dementia, BPSD），利用智能可穿戴设备采集的生理信号来提取个体行为模式。相比传统广义模型，该方法在细粒度预测中实现了显著提升，包括AUC提高16.0%，并能区分不同BPSD症状。实验结果证明了该框架在实际场景中的潜力，有助于实现主动干预、减轻护理负担，并填补了BPSD预测领域的空白。",
      "categories": [
        "eess.SP",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "eess.SP",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.18091v1",
      "published_date": "2024-10-08 08:38:37 UTC",
      "updated_date": "2024-10-08 08:38:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:45:21.904982"
    },
    {
      "arxiv_id": "2410.05805v1",
      "title": "PostCast: Generalizable Postprocessing for Precipitation Nowcasting via Unsupervised Blurriness Modeling",
      "title_zh": "翻译失败",
      "authors": [
        "Junchao Gong",
        "Siwei Tu",
        "Weidong Yang",
        "Ben Fei",
        "Kun Chen",
        "Wenlong Zhang",
        "Xiaokang Yang",
        "Wanli Ouyang",
        "Lei Bai"
      ],
      "abstract": "Precipitation nowcasting plays a pivotal role in socioeconomic sectors,\nespecially in severe convective weather warnings. Although notable progress has\nbeen achieved by approaches mining the spatiotemporal correlations with deep\nlearning, these methods still suffer severe blurriness as the lead time\nincreases, which hampers accurate predictions for extreme precipitation. To\nalleviate blurriness, researchers explore generative methods conditioned on\nblurry predictions. However, the pairs of blurry predictions and corresponding\nground truth need to be generated in advance, making the training pipeline\ncumbersome and limiting the generality of generative models within blur modes\nthat appear in training data. By rethinking the blurriness in precipitation\nnowcasting as a blur kernel acting on predictions, we propose an unsupervised\npostprocessing method to eliminate the blurriness without the requirement of\ntraining with the pairs of blurry predictions and corresponding ground truth.\nSpecifically, we utilize blurry predictions to guide the generation process of\na pre-trained unconditional denoising diffusion probabilistic model (DDPM) to\nobtain high-fidelity predictions with eliminated blurriness. A zero-shot blur\nkernel estimation mechanism and an auto-scale denoise guidance strategy are\nintroduced to adapt the unconditional DDPM to any blurriness modes varying from\ndatasets and lead times in precipitation nowcasting. Extensive experiments are\nconducted on 7 precipitation radar datasets, demonstrating the generality and\nsuperiority of our method.",
      "tldr_zh": "该论文提出 PostCast，一种通用的无监督后处理方法，通过建模模糊性（blurriness）来改善降水预报（precipitation nowcasting）的准确性，尤其针对预测时长增加导致的模糊问题。方法将模糊视为作用于预测的模糊核（blur kernel），利用预训练的无条件去噪扩散概率模型（DDPM）结合零样本模糊核估计和自动缩放去噪指导策略，从模糊预测中生成高保真度的结果，而无需预先生成模糊预测与真实值的配对。实验在7个降水雷达数据集上验证了该方法的泛化性和优越性，显著提升了极端降水的预测性能。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.05805v1",
      "published_date": "2024-10-08 08:38:23 UTC",
      "updated_date": "2024-10-08 08:38:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:45:35.302622"
    },
    {
      "arxiv_id": "2410.05801v1",
      "title": "Retrieving, Rethinking and Revising: The Chain-of-Verification Can Improve Retrieval Augmented Generation",
      "title_zh": "检索、重新思考与修订：链式验证可改善检索增强生成",
      "authors": [
        "Bolei He",
        "Nuo Chen",
        "Xinran He",
        "Lingyong Yan",
        "Zhenkai Wei",
        "Jinchang Luo",
        "Zhen-Hua Ling"
      ],
      "abstract": "Recent Retrieval Augmented Generation (RAG) aims to enhance Large Language\nModels (LLMs) by incorporating extensive knowledge retrieved from external\nsources. However, such approach encounters some challenges: Firstly, the\noriginal queries may not be suitable for precise retrieval, resulting in\nerroneous contextual knowledge; Secondly, the language model can easily\ngenerate inconsistent answer with external references due to their knowledge\nboundary limitation. To address these issues, we propose the\nchain-of-verification (CoV-RAG) to enhance the external retrieval correctness\nand internal generation consistency. Specifically, we integrate the\nverification module into the RAG, engaging in scoring, judgment, and rewriting.\nTo correct external retrieval errors, CoV-RAG retrieves new knowledge using a\nrevised query. To correct internal generation errors, we unify QA and\nverification tasks with a Chain-of-Thought (CoT) reasoning during training. Our\ncomprehensive experiments across various LLMs demonstrate the effectiveness and\nadaptability compared with other strong baselines. Especially, our CoV-RAG can\nsignificantly surpass the state-of-the-art baselines using different LLM\nbackbones.",
      "tldr_zh": "本研究针对 Retrieval Augmented Generation (RAG) 的问题，包括查询不适合导致检索错误以及 Large Language Models (LLMs) 生成与外部引用不一致的答案，提出了 chain-of-verification (CoV-RAG) 框架来提升外部检索准确性和内部生成一致性。CoV-RAG 通过集成验证模块（包括 scoring、judgment 和 rewriting）来修订查询以获取新知识，并利用 Chain-of-Thought (CoT) 推理统一问答（QA）和验证任务进行训练。实验结果显示，CoV-RAG 在各种 LLMs 上显著超越了现有基线模型，证明了其有效性和适应性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to EMNLP 2024 Findings. 9 pages, 4 figures, 7 tables",
      "pdf_url": "http://arxiv.org/pdf/2410.05801v1",
      "published_date": "2024-10-08 08:34:54 UTC",
      "updated_date": "2024-10-08 08:34:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:45:46.082768"
    },
    {
      "arxiv_id": "2410.05800v1",
      "title": "Core Tokensets for Data-efficient Sequential Training of Transformers",
      "title_zh": "翻译失败",
      "authors": [
        "Subarnaduti Paul",
        "Manuel Brack",
        "Patrick Schramowski",
        "Kristian Kersting",
        "Martin Mundt"
      ],
      "abstract": "Deep networks are frequently tuned to novel tasks and continue learning from\nongoing data streams. Such sequential training requires consolidation of new\nand past information, a challenge predominantly addressed by retaining the most\nimportant data points - formally known as coresets. Traditionally, these\ncoresets consist of entire samples, such as images or sentences. However,\nrecent transformer architectures operate on tokens, leading to the famous\nassertion that an image is worth 16x16 words. Intuitively, not all of these\ntokens are equally informative or memorable. Going beyond coresets, we thus\npropose to construct a deeper-level data summary on the level of tokens. Our\nrespectively named core tokensets both select the most informative data points\nand leverage feature attribution to store only their most relevant features. We\ndemonstrate that core tokensets yield significant performance retention in\nincremental image classification, open-ended visual question answering, and\ncontinual image captioning with significantly reduced memory. In fact, we\nempirically find that a core tokenset of 1\\% of the data performs comparably to\nat least a twice as large and up to 10 times larger coreset.",
      "tldr_zh": "该研究针对 Transformer 模型的顺序训练问题，提出了一种数据高效的方法：core tokensets，以优化新旧信息整合。core tokensets 不仅选择最重要的数据点，还利用 feature attribution 技术仅存储这些点的相关特征，从而减少内存使用。实验结果显示，在增量图像分类、开放式视觉问答和持续图像描述任务中，使用 1% 数据量的 core tokensets 性能可与至少两倍大的 coresets 相当，甚至优于更大规模的传统方法。总的来说，这一方法为高效的深度网络持续学习提供了新途径。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.05800v1",
      "published_date": "2024-10-08 08:34:35 UTC",
      "updated_date": "2024-10-08 08:34:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:45:58.065064"
    },
    {
      "arxiv_id": "2410.05791v1",
      "title": "FürElise: Capturing and Physically Synthesizing Hand Motions of Piano Performance",
      "title_zh": "翻译失败",
      "authors": [
        "Ruocheng Wang",
        "Pei Xu",
        "Haochen Shi",
        "Elizabeth Schumann",
        "C. Karen Liu"
      ],
      "abstract": "Piano playing requires agile, precise, and coordinated hand control that\nstretches the limits of dexterity. Hand motion models with the sophistication\nto accurately recreate piano playing have a wide range of applications in\ncharacter animation, embodied AI, biomechanics, and VR/AR. In this paper, we\nconstruct a first-of-its-kind large-scale dataset that contains approximately\n10 hours of 3D hand motion and audio from 15 elite-level pianists playing 153\npieces of classical music. To capture natural performances, we designed a\nmarkerless setup in which motions are reconstructed from multi-view videos\nusing state-of-the-art pose estimation models. The motion data is further\nrefined via inverse kinematics using the high-resolution MIDI key-pressing data\nobtained from sensors in a specialized Yamaha Disklavier piano. Leveraging the\ncollected dataset, we developed a pipeline that can synthesize\nphysically-plausible hand motions for musical scores outside of the dataset.\nOur approach employs a combination of imitation learning and reinforcement\nlearning to obtain policies for physics-based bimanual control involving the\ninteraction between hands and piano keys. To solve the sampling efficiency\nproblem with the large motion dataset, we use a diffusion model to generate\nnatural reference motions, which provide high-level trajectory and fingering\n(finger order and placement) information. However, the generated reference\nmotion alone does not provide sufficient accuracy for piano performance\nmodeling. We then further augmented the data by using musical similarity to\nretrieve similar motions from the captured dataset to boost the precision of\nthe RL policy. With the proposed method, our model generates natural, dexterous\nmotions that generalize to music from outside the training dataset.",
      "tldr_zh": "本文构建了一个首创的大型数据集，包含约10小时的3D手部动作和音频数据，来自15位精英钢琴家演奏的153首古典音乐，通过无标记的多视图视频和姿态估计模型捕获，并利用inverse kinematics结合高分辨率MIDI数据进行优化。基于此数据集，研究团队开发了一个合成管道，结合imitation learning和reinforcement learning，实现物理上合理的双臂手部动作生成，并使用diffusion model生成参考动作以解决采样效率问题。进一步通过音乐相似性从数据集检索类似动作增强数据，提高了RL策略的精度。最终，该方法生成的动作自然、灵巧，并能泛化到训练数据集外的音乐乐谱。",
      "categories": [
        "cs.GR",
        "cs.AI",
        "cs.SD",
        "eess.AS"
      ],
      "primary_category": "cs.GR",
      "comment": "SIGGRAPH Asia 2024. Project page: https://for-elise.github.io/",
      "pdf_url": "http://arxiv.org/pdf/2410.05791v1",
      "published_date": "2024-10-08 08:21:05 UTC",
      "updated_date": "2024-10-08 08:21:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:46:11.306937"
    },
    {
      "arxiv_id": "2410.11866v1",
      "title": "An Innovative Solution: AI-Based Digital Screen-Integrated Tables for Educational Settings",
      "title_zh": "翻译失败",
      "authors": [
        "S. Tamang",
        "D. J. Bora"
      ],
      "abstract": "In this paper, we have gone through different AI-Based frameworks used for\nvarious educational tasks like digital customized assignment allotment and\nperformance monitoring, identifying slow-learners and fast-learners, etc.\napplication describes a novel invention, digital screen-integrated tables,\ndesigned specifically for educational settings. The tables feature integrated\ndigital screens controlled by a central processing unit (CPU), enabling\nsynchronized display of educational content such as textbooks, presentations,\nexam questions, and interactive learning materials. Additionally, the invention\nfacilitates the collection of student performance data during classroom\nactivities and assessments. The gathered data is utilized for analysis using\nmachine learning models to identify patterns and trends in student learning\nbehaviours. By leveraging machine learning algorithms, educators can ascertain\nwhether a student is a fast learner or a slow learner, based on which, the\nteacher can allocate more resources to the slow learners. This innovative\napproach aims to address the evolving needs of modern classrooms by providing a\ndynamic and data-driven learning environment. The unique integration of digital\nscreens into traditional classroom furniture represents a significant\nadvancement in educational technology. This patent filing encompasses the\ndesign, functionality, and method of operation of the digital screen-integrated\ntables, emphasizing their innovative features and applications in educational\ninstitutions.",
      "tldr_zh": "本研究提出了一种创新解决方案：AI 驱动的数字屏幕集成桌，专为教育环境设计。该桌配备集成数字屏幕和中央处理单元 (CPU)，能够同步显示教材、演示文稿、考试题目和互动学习材料，同时收集学生课堂表现数据。通过应用 machine learning 算法分析这些数据，系统能识别学生的学习模式，区分快 learner 和慢 learner，从而帮助教师针对慢 learner 分配更多资源。这种创新设计显著提升了教育技术的动态性和数据驱动能力，为现代课堂提供更高效的学习支持。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.11866v1",
      "published_date": "2024-10-08 08:00:17 UTC",
      "updated_date": "2024-10-08 08:00:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:46:21.245997"
    },
    {
      "arxiv_id": "2410.05779v3",
      "title": "LightRAG: Simple and Fast Retrieval-Augmented Generation",
      "title_zh": "LightRAG：简单且快速的检索增强生成",
      "authors": [
        "Zirui Guo",
        "Lianghao Xia",
        "Yanhua Yu",
        "Tu Ao",
        "Chao Huang"
      ],
      "abstract": "Retrieval-Augmented Generation (RAG) systems enhance large language models\n(LLMs) by integrating external knowledge sources, enabling more accurate and\ncontextually relevant responses tailored to user needs. However, existing RAG\nsystems have significant limitations, including reliance on flat data\nrepresentations and inadequate contextual awareness, which can lead to\nfragmented answers that fail to capture complex inter-dependencies. To address\nthese challenges, we propose LightRAG, which incorporates graph structures into\ntext indexing and retrieval processes. This innovative framework employs a\ndual-level retrieval system that enhances comprehensive information retrieval\nfrom both low-level and high-level knowledge discovery. Additionally, the\nintegration of graph structures with vector representations facilitates\nefficient retrieval of related entities and their relationships, significantly\nimproving response times while maintaining contextual relevance. This\ncapability is further enhanced by an incremental update algorithm that ensures\nthe timely integration of new data, allowing the system to remain effective and\nresponsive in rapidly changing data environments. Extensive experimental\nvalidation demonstrates considerable improvements in retrieval accuracy and\nefficiency compared to existing approaches. We have made our LightRAG\nopen-source and available at the link: https://github.com/HKUDS/LightRAG",
      "tldr_zh": "该论文提出了LightRAG，一种简单高效的Retrieval-Augmented Generation (RAG) 系统，旨在解决现有RAG系统依赖平坦数据表示和缺乏上下文感知的问题，导致答案碎片化。LightRAG通过融入graph structures到文本索引和检索过程，采用双层检索系统（包括低级和高級知识发现）以及结合vector representations的机制，提升相关实体和关系的检索效率，并引入incremental update algorithm以适应快速变化的数据环境。实验结果显示，LightRAG在检索准确性和效率上比现有方法有显著改进，并已开源在https://github.com/HKUDS/LightRAG。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.05779v3",
      "published_date": "2024-10-08 08:00:12 UTC",
      "updated_date": "2025-04-28 17:36:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:46:33.623930"
    },
    {
      "arxiv_id": "2410.18090v1",
      "title": "Liver Cancer Knowledge Graph Construction based on dynamic entity replacement and masking strategies RoBERTa-BiLSTM-CRF model",
      "title_zh": "翻译失败",
      "authors": [
        "YiChi Zhang",
        "HaiLing Wang",
        "YongBin Gao",
        "XiaoJun Hu",
        "YingFang Fan",
        "ZhiJun Fang"
      ],
      "abstract": "Background: Liver cancer ranks as the fifth most common malignant tumor and\nthe second most fatal in our country. Early diagnosis is crucial, necessitating\nthat physicians identify liver cancer in patients at the earliest possible\nstage. However, the diagnostic process is complex and demanding. Physicians\nmust analyze a broad spectrum of patient data, encompassing physical condition,\nsymptoms, medical history, and results from various examinations and tests,\nrecorded in both structured and unstructured medical formats. This results in a\nsignificant workload for healthcare professionals. In response, integrating\nknowledge graph technology to develop a liver cancer knowledge graph-assisted\ndiagnosis and treatment system aligns with national efforts toward smart\nhealthcare. Such a system promises to mitigate the challenges faced by\nphysicians in diagnosing and treating liver cancer.\n  Methods: This paper addresses the major challenges in building a knowledge\ngraph for hepatocellular carcinoma diagnosis, such as the discrepancy between\npublic data sources and real electronic medical records, the effective\nintegration of which remains a key issue. The knowledge graph construction\nprocess consists of six steps: conceptual layer design, data preprocessing,\nentity identification, entity normalization, knowledge fusion, and graph\nvisualization. A novel Dynamic Entity Replacement and Masking Strategy (DERM)\nfor named entity recognition is proposed.\n  Results: A knowledge graph for liver cancer was established, including 7\nentity types such as disease, symptom, and constitution, containing 1495\nentities. The recognition accuracy of the model was 93.23%, the recall was\n94.69%, and the F1 score was 93.96%.",
      "tldr_zh": "本研究针对肝癌诊断的复杂性和医生工作负担，构建了一个基于知识图谱（Knowledge Graph）的辅助诊断系统，以整合公共数据和电子病历。研究提出了动态实体替换和屏蔽策略（Dynamic Entity Replacement and Masking Strategy, DERM），并结合 RoBERTa-BiLSTM-CRF 模型，通过六步过程（包括概念层设计、数据预处理、实体识别等）来实现实体规范化与知识融合。结果显示，构建的肝癌知识图谱包含7种实体类型（如disease和symptom）共1495个实体，模型的识别准确率为93.23%、召回率为94.69%、F1分数为93.96%，为智能医疗提供了有效工具。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.18090v1",
      "published_date": "2024-10-08 07:57:29 UTC",
      "updated_date": "2024-10-08 07:57:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:46:45.788934"
    },
    {
      "arxiv_id": "2410.05777v1",
      "title": "Integrated Encoding and Quantization to Enhance Quanvolutional Neural Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Daniele Lizzio Bosco",
        "Beatrice Portelli",
        "Giuseppe Serra"
      ],
      "abstract": "Image processing is one of the most promising applications for quantum\nmachine learning (QML). Quanvolutional Neural Networks with non-trainable\nparameters are the preferred solution to run on current and near future quantum\ndevices. The typical input preprocessing pipeline for quanvolutional layers\ncomprises of four steps: optional input binary quantization, encoding classical\ndata into quantum states, processing the data to obtain the final quantum\nstates, decoding quantum states back to classical outputs. In this paper we\npropose two ways to enhance the efficiency of quanvolutional models. First, we\npropose a flexible data quantization approach with memoization, applicable to\nany encoding method. This allows us to increase the number of quantization\nlevels to retain more information or lower them to reduce the amount of circuit\nexecutions. Second, we introduce a new integrated encoding strategy, which\ncombines the encoding and processing steps in a single circuit. This method\nallows great flexibility on several architectural parameters (e.g., number of\nqubits, filter size, and circuit depth) making them adjustable to quantum\nhardware requirements. We compare our proposed integrated model with a\nclassical convolutional neural network and the well-known rotational encoding\nmethod, on two different classification tasks. The results demonstrate that our\nproposed model encoding exhibits a comparable or superior performance to the\nother models while requiring fewer quantum resources.",
      "tldr_zh": "这篇论文针对量子机器学习（QML）在图像处理中的应用，提出了两种提升 Quanvolutional Neural Networks 效率的方法：第一，开发了一种灵活的 data quantization 技术，使用 memoization 来调整量化级别，从而平衡信息保留和电路执行量；第二，引入了 integrated encoding 策略，将编码和处理步骤整合到一个电路中，提高了架构参数的灵活性，如 qubits 数量、filter size 和 circuit depth。实验结果显示，该模型在两个分类任务上与经典卷积神经网络以及 rotational encoding 方法相比，表现出相当或优越的性能，同时显著降低了量子资源需求。",
      "categories": [
        "quant-ph",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "quant-ph",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.05777v1",
      "published_date": "2024-10-08 07:57:13 UTC",
      "updated_date": "2024-10-08 07:57:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:46:58.469862"
    },
    {
      "arxiv_id": "2410.05767v2",
      "title": "Grounding is All You Need? Dual Temporal Grounding for Video Dialog",
      "title_zh": "翻译失败",
      "authors": [
        "You Qin",
        "Wei Ji",
        "Xinze Lan",
        "Hao Fei",
        "Xun Yang",
        "Dan Guo",
        "Roger Zimmermann",
        "Lizi Liao"
      ],
      "abstract": "In the realm of video dialog response generation, the understanding of video\ncontent and the temporal nuances of conversation history are paramount. While a\nsegment of current research leans heavily on large-scale pretrained\nvisual-language models and often overlooks temporal dynamics, another delves\ndeep into spatial-temporal relationships within videos but demands intricate\nobject trajectory pre-extractions and sidelines dialog temporal dynamics. This\npaper introduces the Dual Temporal Grounding-enhanced Video Dialog model\n(DTGVD), strategically designed to merge the strengths of both dominant\napproaches. It emphasizes dual temporal relationships by predicting dialog\nturn-specific temporal regions, filtering video content accordingly, and\ngrounding responses in both video and dialog contexts. One standout feature of\nDTGVD is its heightened attention to chronological interplay. By recognizing\nand acting upon the dependencies between different dialog turns, it captures\nmore nuanced conversational dynamics. To further bolster the alignment between\nvideo and dialog temporal dynamics, we've implemented a list-wise contrastive\nlearning strategy. Within this framework, accurately grounded turn-clip\npairings are designated as positive samples, while less precise pairings are\ncategorized as negative. This refined classification is then funneled into our\nholistic end-to-end response generation mechanism. Evaluations using\nAVSD@DSTC-7 and AVSD@DSTC-8 datasets underscore the superiority of our\nmethodology.",
      "tldr_zh": "本文提出 Dual Temporal Grounding-enhanced Video Dialog (DTGVD) 模型，旨在解决视频对话生成中视频内容和对话历史时序动态的不足，通过预测对话轮次特定的时序区域并过滤视频内容，实现视频和对话语境的双重 grounding。DTGVD 强调对话轮次间的依赖性，并引入 list-wise contrastive learning 策略，将准确的 turn-clip 配对作为正样本来优化端到端的响应生成机制。该方法在 AVSD@DSTC-7 和 AVSD@DSTC-8 数据集上的评估显示出显著优越性，捕捉了更细微的对话动态。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.MM"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.05767v2",
      "published_date": "2024-10-08 07:48:34 UTC",
      "updated_date": "2024-11-14 11:27:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:47:10.938910"
    },
    {
      "arxiv_id": "2410.05760v2",
      "title": "Training-free Diffusion Model Alignment with Sampling Demons",
      "title_zh": "翻译失败",
      "authors": [
        "Po-Hung Yeh",
        "Kuang-Huei Lee",
        "Jun-Cheng Chen"
      ],
      "abstract": "Aligning diffusion models with user preferences has been a key challenge.\nExisting methods for aligning diffusion models either require retraining or are\nlimited to differentiable reward functions. To address these limitations, we\npropose a stochastic optimization approach, dubbed Demon, to guide the\ndenoising process at inference time without backpropagation through reward\nfunctions or model retraining. Our approach works by controlling noise\ndistribution in denoising steps to concentrate density on regions corresponding\nto high rewards through stochastic optimization. We provide comprehensive\ntheoretical and empirical evidence to support and validate our approach,\nincluding experiments that use non-differentiable sources of rewards such as\nVisual-Language Model (VLM) APIs and human judgements. To the best of our\nknowledge, the proposed approach is the first inference-time,\nbackpropagation-free preference alignment method for diffusion models. Our\nmethod can be easily integrated with existing diffusion models without further\ntraining. Our experiments show that the proposed approach significantly\nimproves the average aesthetics scores for text-to-image generation.\nImplementation is available at https://github.com/aiiu-lab/DemonSampling.",
      "tldr_zh": "本研究解决了扩散模型（diffusion models）的偏好对齐（alignment）挑战，提出了一种无需训练的随机优化方法，名为 Demon，通过在推理时（inference time）控制去噪步骤的噪声分布，使生成结果集中在高奖励区域，而不需反向传播（backpropagation）或模型重新训练。Demon 方法利用随机优化来处理非可微奖励来源，如 Visual-Language Model (VLM) APIs 和人类判断，提供全面的理论和实证证据支持。该方法可轻松整合到现有扩散模型中，是首个此类 backpropagation-free 的推理时偏好对齐技术。实验结果显示，Demon 显著提升了文本到图像生成（text-to-image generation）的平均美学分数（aesthetics scores）。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "math.OC",
        "stat.ML"
      ],
      "primary_category": "cs.CV",
      "comment": "35 pages",
      "pdf_url": "http://arxiv.org/pdf/2410.05760v2",
      "published_date": "2024-10-08 07:33:49 UTC",
      "updated_date": "2025-02-27 12:13:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:47:22.517856"
    },
    {
      "arxiv_id": "2410.05756v1",
      "title": "Learning the Generalizable Manipulation Skills on Soft-body Tasks via Guided Self-attention Behavior Cloning Policy",
      "title_zh": "翻译失败",
      "authors": [
        "Xuetao Li",
        "Fang Gao",
        "Jun Yu",
        "Shaodong Li",
        "Feng Shuang"
      ],
      "abstract": "Embodied AI represents a paradigm in AI research where artificial agents are\nsituated within and interact with physical or virtual environments. Despite the\nrecent progress in Embodied AI, it is still very challenging to learn the\ngeneralizable manipulation skills that can handle large deformation and\ntopological changes on soft-body objects, such as clay, water, and soil. In\nthis work, we proposed an effective policy, namely GP2E behavior cloning\npolicy, which can guide the agent to learn the generalizable manipulation\nskills from soft-body tasks, including pouring, filling, hanging, excavating,\npinching, and writing. Concretely, we build our policy from three insights:(1)\nExtracting intricate semantic features from point cloud data and seamlessly\nintegrating them into the robot's end-effector frame; (2) Capturing\nlong-distance interactions in long-horizon tasks through the incorporation of\nour guided self-attention module; (3) Mitigating overfitting concerns and\nfacilitating model convergence to higher accuracy levels via the introduction\nof our two-stage fine-tuning strategy. Through extensive experiments, we\ndemonstrate the effectiveness of our approach by achieving the 1st prize in the\nsoft-body track of the ManiSkill2 Challenge at the CVPR 2023 4th Embodied AI\nworkshop. Our findings highlight the potential of our method to improve the\ngeneralization abilities of Embodied AI models and pave the way for their\npractical applications in real-world scenarios.",
      "tldr_zh": "该论文针对Embodied AI中的挑战，提出了一种名为GP2E的behavior cloning policy，帮助代理学习可泛化的操作技能，以处理软体物体（如粘土、水和土壤）的变形和拓扑变化。政策基于三个关键洞见：从点云数据提取语义特征并整合到机器人的end-effector框架；通过guided self-attention模块捕获长horizon任务中的长距离交互；以及采用两阶段fine-tuning策略来减轻过拟合并提升模型准确性。通过在CVPR 2023 ManiSkill2 Challenge软体轨道中获得第一名，该方法证明了其有效性，并为Embodied AI模型在实际场景中的应用奠定了基础。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.05756v1",
      "published_date": "2024-10-08 07:31:10 UTC",
      "updated_date": "2024-10-08 07:31:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:47:34.783943"
    },
    {
      "arxiv_id": "2410.05750v1",
      "title": "Polynomial Time Cryptanalytic Extraction of Deep Neural Networks in the Hard-Label Setting",
      "title_zh": "翻译失败",
      "authors": [
        "Nicholas Carlini",
        "Jorge Chávez-Saab",
        "Anna Hambitzer",
        "Francisco Rodríguez-Henríquez",
        "Adi Shamir"
      ],
      "abstract": "Deep neural networks (DNNs) are valuable assets, yet their public\naccessibility raises security concerns about parameter extraction by malicious\nactors. Recent work by Carlini et al. (crypto'20) and Canales-Mart\\'inez et al.\n(eurocrypt'24) has drawn parallels between this issue and block cipher key\nextraction via chosen plaintext attacks. Leveraging differential cryptanalysis,\nthey demonstrated that all the weights and biases of black-box ReLU-based DNNs\ncould be inferred using a polynomial number of queries and computational time.\nHowever, their attacks relied on the availability of the exact numeric value of\noutput logits, which allowed the calculation of their derivatives. To overcome\nthis limitation, Chen et al. (asiacrypt'24) tackled the more realistic\nhard-label scenario, where only the final classification label (e.g., \"dog\" or\n\"car\") is accessible to the attacker. They proposed an extraction method\nrequiring a polynomial number of queries but an exponential execution time. In\naddition, their approach was applicable only to a restricted set of\narchitectures, could deal only with binary classifiers, and was demonstrated\nonly on tiny neural networks with up to four neurons split among up to two\nhidden layers. This paper introduces new techniques that, for the first time,\nachieve cryptanalytic extraction of DNN parameters in the most challenging\nhard-label setting, using both a polynomial number of queries and polynomial\ntime. We validate our approach by extracting nearly one million parameters from\na DNN trained on the CIFAR-10 dataset, comprising 832 neurons in four hidden\nlayers. Our results reveal the surprising fact that all the weights of a\nReLU-based DNN can be efficiently determined by analyzing only the geometric\nshape of its decision boundaries.",
      "tldr_zh": "本研究解决了在 hard-label 设置下从 Deep Neural Networks (DNNs) 中提取参数的安全问题，首次实现了多项式查询次数和多项式时间复杂度的 cryptanalytic extraction 方法。作者引入新技巧，通过分析 ReLU-based DNNs 决策边界的几何形状，成功推断网络权重，而无需访问输出 logits 的确切值。实验验证显示，该方法能从一个在 CIFAR-10 数据集上训练的 DNN 中提取近百万参数，该网络包含 832 个神经元和四隐藏层，结果证明了这种高效提取的可行性，并突显了 DNNs 安全性的潜在风险。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.05750v1",
      "published_date": "2024-10-08 07:27:55 UTC",
      "updated_date": "2024-10-08 07:27:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:47:46.762701"
    },
    {
      "arxiv_id": "2410.05740v2",
      "title": "Learning to Drift in Extreme Turning with Active Exploration and Gaussian Process Based MPC",
      "title_zh": "翻译失败",
      "authors": [
        "Guoqiang Wu",
        "Cheng Hu",
        "Wangjia Weng",
        "Zhouheng Li",
        "Yonghao Fu",
        "Lei Xie",
        "Hongye Su"
      ],
      "abstract": "Extreme cornering in racing often leads to large sideslip angles, presenting\na significant challenge for vehicle control. Conventional vehicle controllers\nstruggle to manage this scenario, necessitating the use of a drifting\ncontroller. However, the large sideslip angle in drift conditions introduces\nmodel mismatch, which in turn affects control precision. To address this issue,\nwe propose a model correction drift controller that integrates Model Predictive\nControl (MPC) with Gaussian Process Regression (GPR). GPR is employed to\ncorrect vehicle model mismatches during both drift equilibrium solving and the\nMPC optimization process. Additionally, the variance from GPR is utilized to\nactively explore different cornering drifting velocities, aiming to minimize\ntrajectory tracking errors. The proposed algorithm is validated through\nsimulations on the Simulink-Carsim platform and experiments with a 1:10 scale\nRC vehicle. In the simulation, the average lateral error with GPR is reduced by\n52.8% compared to the non-GPR case. Incorporating exploration further decreases\nthis error by 27.1%. The velocity tracking Root Mean Square Error (RMSE) also\ndecreases by 10.6% with exploration. In the RC car experiment, the average\nlateral error with GPR is 36.7% lower, and exploration further leads to a 29.0%\nreduction. Moreover, the velocity tracking RMSE decreases by 7.2% with the\ninclusion of exploration.",
      "tldr_zh": "本研究针对赛车极端转弯中大侧滑角导致的车辆控制挑战，提出了一种结合 Model Predictive Control (MPC) 和 Gaussian Process Regression (GPR) 的模型修正漂移控制器，以解决模型不匹配问题。\n该控制器利用 GPR 修正车辆模型在漂移平衡求解和 MPC 优化过程中的偏差，并通过 GPR 的方差进行主动探索不同转弯漂移速度，从而最小化轨迹跟踪错误。\n实验在 Simulink-Carsim 模拟和 1:10 比例 RC 车辆上验证，结果显示 GPR 平均降低了横向错误 52.8%（模拟）和 36.7%（实验），而加入探索后进一步减少 27.1% 和 29.0%，速度跟踪 Root Mean Square Error (RMSE) 也分别下降 10.6% 和 7.2%。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.05740v2",
      "published_date": "2024-10-08 06:56:51 UTC",
      "updated_date": "2025-05-11 04:04:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:47:59.309872"
    },
    {
      "arxiv_id": "2410.05739v1",
      "title": "Array2BR: An End-to-End Noise-immune Binaural Audio Synthesis from Microphone-array Signals",
      "title_zh": "翻译失败",
      "authors": [
        "Cheng Chi",
        "Xiaoyu Li",
        "Andong Li",
        "Yuxuan Ke",
        "Xiaodong Li",
        "Chengshi Zheng"
      ],
      "abstract": "Telepresence technology aims to provide an immersive virtual presence for\nremote conference applications, and it is extremely important to synthesize\nhigh-quality binaural audio signals for this aim. Because the ambient noise is\noften inevitable in practical application scenarios, it is highly desired that\nbinaural audio signals without noise can be obtained from microphone-array\nsignals directly. For this purpose, this paper proposes a new end-to-end\nnoise-immune binaural audio synthesis framework from microphone-array signals,\nabbreviated as Array2BR, and experimental results show that binaural cues can\nbe correctly mapped and noise can be well suppressed simultaneously using the\nproposed framework. Compared with existing methods, the proposed method\nachieved better performance in terms of both objective and subjective metric\nscores.",
      "tldr_zh": "这篇论文提出了Array2BR，一个端到端的抗噪双声道音频合成框架，旨在从麦克风阵列信号中直接生成高质量的双声道音频，以支持远程会议的沉浸式虚拟存在。Array2BR通过端到端处理方法，同时实现双声道线索的正确映射和环境噪音的有效抑制。实验结果显示，与现有方法相比，该框架在客观和主观指标上均取得了更好的性能表现。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.05739v1",
      "published_date": "2024-10-08 06:55:35 UTC",
      "updated_date": "2024-10-08 06:55:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:48:09.725533"
    },
    {
      "arxiv_id": "2410.05729v1",
      "title": "Equi-GSPR: Equivariant SE(3) Graph Network Model for Sparse Point Cloud Registration",
      "title_zh": "翻译失败",
      "authors": [
        "Xueyang Kang",
        "Zhaoliang Luan",
        "Kourosh Khoshelham",
        "Bing Wang"
      ],
      "abstract": "Point cloud registration is a foundational task for 3D alignment and\nreconstruction applications. While both traditional and learning-based\nregistration approaches have succeeded, leveraging the intrinsic symmetry of\npoint cloud data, including rotation equivariance, has received insufficient\nattention. This prohibits the model from learning effectively, resulting in a\nrequirement for more training data and increased model complexity. To address\nthese challenges, we propose a graph neural network model embedded with a local\nSpherical Euclidean 3D equivariance property through SE(3) message passing\nbased propagation. Our model is composed mainly of a descriptor module,\nequivariant graph layers, match similarity, and the final regression layers.\nSuch modular design enables us to utilize sparsely sampled input points and\ninitialize the descriptor by self-trained or pre-trained geometric feature\ndescriptors easily. Experiments conducted on the 3DMatch and KITTI datasets\nexhibit the compelling and robust performance of our model compared to\nstate-of-the-art approaches, while the model complexity remains relatively low\nat the same time.",
      "tldr_zh": "该论文提出Equi-GSPR，一种基于SE(3)图神经网络的模型，用于处理稀疏点云注册任务，通过引入旋转等变性来提升模型学习效率，减少对训练数据和复杂度的依赖。模型采用模块化设计，包括描述符模块、等变图层、匹配相似度模块和回归层，支持稀疏采样输入点并轻松整合预训练特征描述符。在3DMatch和KITTI数据集上的实验显示，Equi-GSPR比现有最先进方法表现出更强的鲁棒性和性能，同时保持较低的模型复杂度。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "18 main body pages, and 9 pages for supplementary part",
      "pdf_url": "http://arxiv.org/pdf/2410.05729v1",
      "published_date": "2024-10-08 06:48:01 UTC",
      "updated_date": "2024-10-08 06:48:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:48:23.022113"
    },
    {
      "arxiv_id": "2410.05728v1",
      "title": "Reducing fuzzy relation equations via concept lattices",
      "title_zh": "翻译失败",
      "authors": [
        "David Lobo",
        "Víctor López-Marchante",
        "Jesús Medina"
      ],
      "abstract": "This paper has taken into advantage the relationship between Fuzzy Relation\nEquations (FRE) and Concept Lattices in order to introduce a procedure to\nreduce a FRE, without losing information. Specifically, attribute reduction\ntheory in property-oriented and object-oriented concept lattices has been\nconsidered in order to present a mechanism for detecting redundant equations.\nAs a first consequence, the computation of the whole solution set of a solvable\nFRE is reduced. Moreover, we will also introduce a novel method for computing\napproximate solutions of unsolvable FRE related to a (real) dataset with\nuncertainty/imprecision data.",
      "tldr_zh": "本论文利用 Concept Lattices 与 Fuzzy Relation Equations (FRE) 之间的关系，提出了一种减少 FRE 的程序，以不丢失信息为前提。论文通过属性减少理论在 property-oriented 和 object-oriented concept lattices 中的应用，检测冗余方程，从而简化可解 FRE 的完整解集计算。此外，该方法还引入了一种新颖的近似解计算机制，适用于带有不确定性/不精确数据的真实数据集。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.05728v1",
      "published_date": "2024-10-08 06:47:35 UTC",
      "updated_date": "2024-10-08 06:47:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:48:33.086109"
    },
    {
      "arxiv_id": "2410.05726v1",
      "title": "Less is more: Embracing sparsity and interpolation with Esiformer for time series forecasting",
      "title_zh": "翻译失败",
      "authors": [
        "Yangyang Guo",
        "Yanjun Zhao",
        "Sizhe Dang",
        "Tian Zhou",
        "Liang Sun",
        "Yi Qian"
      ],
      "abstract": "Time series forecasting has played a significant role in many practical\nfields. But time series data generated from real-world applications always\nexhibits high variance and lots of noise, which makes it difficult to capture\nthe inherent periodic patterns of the data, hurting the prediction accuracy\nsignificantly. To address this issue, we propose the Esiformer, which apply\ninterpolation on the original data, decreasing the overall variance of the data\nand alleviating the influence of noise. What's more, we enhanced the vanilla\ntransformer with a robust Sparse FFN. It can enhance the representation ability\nof the model effectively, and maintain the excellent robustness, avoiding the\nrisk of overfitting compared with the vanilla implementation. Through\nevaluations on challenging real-world datasets, our method outperforms leading\nmodel PatchTST, reducing MSE by 6.5% and MAE by 5.8% in multivariate time\nseries forecasting. Code is available at:\nhttps://github.com/yyg1282142265/Esiformer/tree/main.",
      "tldr_zh": "该研究针对时间序列预测中的高方差和噪音问题，提出Esiformer模型，通过在原始数据上应用插值技术来降低方差并减轻噪音影响。Esiformer在传统Transformer基础上增强了robust Sparse FFN模块，提高模型的表示能力和鲁棒性，同时避免过拟合风险。在真实数据集上的评估中，该方法在多变量时间序列预测中超越领先模型PatchTST，减少MSE 6.5%和MAE 5.8%。这项工作突出了在时间序列预测中拥抱sparsity和interpolation的优点，并提供了开源代码。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.05726v1",
      "published_date": "2024-10-08 06:45:47 UTC",
      "updated_date": "2024-10-08 06:45:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:48:45.407279"
    },
    {
      "arxiv_id": "2410.05725v2",
      "title": "KnowledgeSG: Privacy-Preserving Synthetic Text Generation with Knowledge Distillation from Server",
      "title_zh": "KnowledgeSG：服务器知识",
      "authors": [
        "Wenhao Wang",
        "Xiaoyu Liang",
        "Rui Ye",
        "Jingyi Chai",
        "Siheng Chen",
        "Yanfeng Wang"
      ],
      "abstract": "The success of large language models (LLMs) facilitate many parties to\nfine-tune LLMs on their own private data. However, this practice raises privacy\nconcerns due to the memorization of LLMs. Existing solutions, such as utilizing\nsynthetic data for substitution, struggle to simultaneously improve performance\nand preserve privacy. They either rely on a local model for generation,\nresulting in a performance decline, or take advantage of APIs, directly\nexposing the data to API servers. To address this issue, we propose\nKnowledgeSG, a novel client-server framework which enhances synthetic data\nquality and improves model performance while ensuring privacy. We achieve this\nby learning local knowledge from the private data with differential privacy\n(DP) and distilling professional knowledge from the server. Additionally,\ninspired by federated learning, we transmit models rather than data between the\nclient and server to prevent privacy leakage. Extensive experiments in medical\nand financial domains demonstrate the effectiveness of KnowledgeSG. Our code is\nnow publicly available at https://github.com/wwh0411/KnowledgeSG.",
      "tldr_zh": "该研究提出 KnowledgeSG，一种客户端-服务器框架，用于在保护隐私的情况下生成合成文本，以解决大型语言模型 (LLMs) 在私有数据微调时可能导致的隐私泄露问题。该框架通过差分隐私 (DP) 在本地学习私有数据知识，并从服务器进行知识蒸馏，同时借鉴联邦学习的方法传输模型而非数据，从而提升合成数据质量和模型性能。在医疗和金融领域的实验中，KnowledgeSG 证明了其有效性，并已公开代码以供进一步应用。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "EMNLP 2024 Main",
      "pdf_url": "http://arxiv.org/pdf/2410.05725v2",
      "published_date": "2024-10-08 06:42:28 UTC",
      "updated_date": "2024-10-10 03:58:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:48:57.475802"
    },
    {
      "arxiv_id": "2410.05721v1",
      "title": "Mero Nagarikta: Advanced Nepali Citizenship Data Extractor with Deep Learning-Powered Text Detection and OCR",
      "title_zh": "翻译失败",
      "authors": [
        "Sisir Dhakal",
        "Sujan Sigdel",
        "Sandesh Prasad Paudel",
        "Sharad Kumar Ranabhat",
        "Nabin Lamichhane"
      ],
      "abstract": "Transforming text-based identity documents, such as Nepali citizenship cards,\ninto a structured digital format poses several challenges due to the distinct\ncharacteristics of the Nepali script and minor variations in print alignment\nand contrast across different cards. This work proposes a robust system using\nYOLOv8 for accurate text object detection and an OCR algorithm based on\nOptimized PyTesseract. The system, implemented within the context of a mobile\napplication, allows for the automated extraction of important textual\ninformation from both the front and the back side of Nepali citizenship cards,\nincluding names, citizenship numbers, and dates of birth. The final YOLOv8\nmodel was accurate, with a mean average precision of 99.1% for text detection\non the front and 96.1% on the back. The tested PyTesseract optimized for Nepali\ncharacters outperformed the standard OCR regarding flexibility and accuracy,\nextracting text from images with clean and noisy backgrounds and various\ncontrasts. Using preprocessing steps such as converting the images into\ngrayscale, removing noise from the images, and detecting edges further improved\nthe system's OCR accuracy, even for low-quality photos. This work expands the\ncurrent body of research in multilingual OCR and document analysis, especially\nfor low-resource languages such as Nepali. It emphasizes the effectiveness of\ncombining the latest object detection framework with OCR models that have been\nfine-tuned for practical applications.",
      "tldr_zh": "这篇论文提出了一种先进的系统“Mero Nagarikta”，利用 YOLOv8 进行文本对象检测和基于 Optimized PyTesseract 的 OCR 算法，来自动提取尼泊尔公民卡正反面的关键信息，如姓名、公民号码和出生日期，从而解决尼泊尔脚本特点以及打印变异带来的挑战。系统在移动应用中实现，通过图像预处理步骤（如转换为灰度、去除噪声和边缘检测）显著提升了 OCR 准确性，即使在低质量照片上也能有效工作。实验结果显示，YOLOv8 的平均精度达到正面 99.1% 和反面 96.1%，优化后的 PyTesseract 在灵活性和准确性上优于标准 OCR。该工作扩展了多语言 OCR 和文档分析的研究，尤其针对低资源语言如尼泊尔，突显了结合最新对象检测框架和微调 OCR 模型的实际有效性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "13 pages, 8 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.05721v1",
      "published_date": "2024-10-08 06:29:08 UTC",
      "updated_date": "2024-10-08 06:29:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:49:11.781963"
    },
    {
      "arxiv_id": "2410.05714v1",
      "title": "Enhancing Temporal Modeling of Video LLMs via Time Gating",
      "title_zh": "翻译失败",
      "authors": [
        "Zi-Yuan Hu",
        "Yiwu Zhong",
        "Shijia Huang",
        "Michael R. Lyu",
        "Liwei Wang"
      ],
      "abstract": "Video Large Language Models (Video LLMs) have achieved impressive performance\non video-and-language tasks, such as video question answering. However, most\nexisting Video LLMs neglect temporal information in video data, leading to\nstruggles with temporal-aware video understanding. To address this gap, we\npropose a Time Gating Video LLM (TG-Vid) designed to enhance temporal modeling\nthrough a novel Time Gating module (TG). The TG module employs a time gating\nmechanism on its sub-modules, comprising gating spatial attention, gating\ntemporal attention, and gating MLP. This architecture enables our model to\nachieve a robust understanding of temporal information within videos. Extensive\nevaluation of temporal-sensitive video benchmarks (i.e., MVBench, TempCompass,\nand NExT-QA) demonstrates that our TG-Vid model significantly outperforms the\nexisting Video LLMs. Further, comprehensive ablation studies validate that the\nperformance gains are attributed to the designs of our TG module. Our code is\navailable at https://github.com/LaVi-Lab/TG-Vid.",
      "tldr_zh": "本文研究发现，现有的 Video LLMs 在视频和语言任务中表现优异，但忽略了视频中的时间信息，导致在时间感知视频理解上存在不足。为解决这一问题，作者提出 Time Gating Video LLM (TG-Vid) 模型，该模型通过 Time Gating 模块（包括 gating spatial attention、gating temporal attention 和 gating MLP）来增强时间建模。在 MVBench、TempCompass 和 NExT-QA 等时间敏感基准上，TG-Vid 显著优于现有 Video LLMs，且消融研究证实了该模块设计的有效性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "EMNLP 2024 Findings (Short)",
      "pdf_url": "http://arxiv.org/pdf/2410.05714v1",
      "published_date": "2024-10-08 06:21:29 UTC",
      "updated_date": "2024-10-08 06:21:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:49:23.855073"
    },
    {
      "arxiv_id": "2410.05710v1",
      "title": "PixLens: A Novel Framework for Disentangled Evaluation in Diffusion-Based Image Editing with Object Detection + SAM",
      "title_zh": "翻译失败",
      "authors": [
        "Stefan Stefanache",
        "Lluís Pastor Pérez",
        "Julen Costa Watanabe",
        "Ernesto Sanchez Tejedor",
        "Thomas Hofmann",
        "Enis Simsar"
      ],
      "abstract": "Evaluating diffusion-based image-editing models is a crucial task in the\nfield of Generative AI. Specifically, it is imperative to assess their capacity\nto execute diverse editing tasks while preserving the image content and\nrealism. While recent developments in generative models have opened up\npreviously unheard-of possibilities for image editing, conducting a thorough\nevaluation of these models remains a challenging and open task. The absence of\na standardized evaluation benchmark, primarily due to the inherent need for a\npost-edit reference image for evaluation, further complicates this issue.\nCurrently, evaluations often rely on established models such as CLIP or require\nhuman intervention for a comprehensive understanding of the performance of\nthese image editing models. Our benchmark, PixLens, provides a comprehensive\nevaluation of both edit quality and latent representation disentanglement,\ncontributing to the advancement and refinement of existing methodologies in the\nfield.",
      "tldr_zh": "该研究针对基于扩散的图像编辑模型的评估挑战，提出了PixLens框架，以评估模型在执行多样编辑任务时的编辑质量和潜在表示解耦。PixLens整合Object Detection和SAM（Segment Anything Model），提供标准化基准，避免依赖如CLIP模型的人工干预或后编辑参考图像。实验结果表明，该框架能全面提升评估的准确性和可靠性，推动生成AI中图像编辑方法的改进和发展。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "35 pages (17 main paper, 18 appendix), 22 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.05710v1",
      "published_date": "2024-10-08 06:05:15 UTC",
      "updated_date": "2024-10-08 06:05:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:49:34.518220"
    },
    {
      "arxiv_id": "2410.18089v1",
      "title": "Empowering Cognitive Digital Twins with Generative Foundation Models: Developing a Low-Carbon Integrated Freight Transportation System",
      "title_zh": "翻译失败",
      "authors": [
        "Xueping Li",
        "Haowen Xu",
        "Jose Tupayachi",
        "Olufemi Omitaomu",
        "Xudong Wang"
      ],
      "abstract": "Effective monitoring of freight transportation is essential for advancing\nsustainable, low-carbon economies. Traditional methods relying on single-modal\ndata and discrete simulations fall short in optimizing intermodal systems\nholistically. These systems involve interconnected processes that affect\nshipping time, costs, emissions, and socio-economic factors. Developing digital\ntwins for real-time awareness, predictive analytics, and urban logistics\noptimization requires extensive efforts in knowledge discovery, data\nintegration, and multi-domain simulation. Recent advancements in generative AI\noffer new opportunities to streamline digital twin development by automating\nknowledge discovery and data integration, generating innovative simulation and\noptimization solutions. These models extend digital twins' capabilities by\npromoting autonomous workflows for data engineering, analytics, and software\ndevelopment. This paper proposes an innovative paradigm that leverages\ngenerative AI to enhance digital twins for urban research and operations. Using\nfreight decarbonization as a case study, we propose a conceptual framework\nemploying transformer-based language models to enhance an urban digital twin\nthrough foundation models. We share preliminary results and our vision for more\nintelligent, autonomous, and general-purpose digital twins for optimizing\nintegrated freight systems from multimodal to synchromodal paradigms.",
      "tldr_zh": "本论文探讨了如何利用生成式AI和基础模型（generative foundation models）增强认知数字孪生（cognitive digital twins），以开发低碳集成货运系统，解决传统单模态数据和离散模拟在整体优化方面的不足。论文提出一个创新范式，通过transformer-based语言模型自动化知识发现、数据整合和多领域模拟，促进自治工作流和优化解决方案。以货运脱碳为案例研究，该框架展示了初步结果，并展望更智能、自治的数字孪生，可用于从多模态到同步模态的货运系统优化。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.LG",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.18089v1",
      "published_date": "2024-10-08 05:53:20 UTC",
      "updated_date": "2024-10-08 05:53:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:49:46.680594"
    },
    {
      "arxiv_id": "2410.07245v1",
      "title": "AAAI Workshop on AI Planning for Cyber-Physical Systems -- CAIPI24",
      "title_zh": "翻译失败",
      "authors": [
        "Oliver Niggemann",
        "Gautam Biswas",
        "Alexander Diedrich",
        "Jonas Ehrhardt",
        "René Heesch",
        "Niklas Widulle"
      ],
      "abstract": "The workshop 'AI-based Planning for Cyber-Physical Systems', which took place\non February 26, 2024, as part of the 38th Annual AAAI Conference on Artificial\nIntelligence in Vancouver, Canada, brought together researchers to discuss\nrecent advances in AI planning methods for Cyber-Physical Systems (CPS). CPS\npose a major challenge due to their complexity and data-intensive nature, which\noften exceeds the capabilities of traditional planning algorithms. The workshop\nhighlighted new approaches such as neuro-symbolic architectures, large language\nmodels (LLMs), deep reinforcement learning and advances in symbolic planning.\nThese techniques are promising when it comes to managing the complexity of CPS\nand have potential for real-world applications.",
      "tldr_zh": "该工作坊（AAAI Workshop on AI Planning for Cyber-Physical Systems -- CAIPI24）于2024年2月26日在加拿大温哥华举行，聚焦AI规划方法在Cyber-Physical Systems (CPS)中的最新进展。CPS的复杂性和数据密集性超出了传统规划算法的能力，因此工作坊讨论了新方法，如neuro-symbolic architectures、large language models (LLMs)、deep reinforcement learning和符号规划。这些方法有助于有效管理CPS的复杂性，并展示出在实际应用中的潜力。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "This is the Proceedings of the AAAI Workshop on AI Planning for\n  Cyber-Physical Systems - CAIPI24, which was held in Vancouver, CA, February\n  26, 2024",
      "pdf_url": "http://arxiv.org/pdf/2410.07245v1",
      "published_date": "2024-10-08 05:52:00 UTC",
      "updated_date": "2024-10-08 05:52:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:49:58.166136"
    },
    {
      "arxiv_id": "2410.18087v1",
      "title": "CUPID: A Real-Time Session-Based Reciprocal Recommendation System for a One-on-One Social Discovery Platform",
      "title_zh": "CUPID：一种实时基于会话的互惠推荐系统，用于一对一社交发现平台",
      "authors": [
        "Beomsu Kim",
        "Sangbum Kim",
        "Minchan Kim",
        "Joonyoung Yi",
        "Sungjoo Ha",
        "Suhyun Lee",
        "Youngsoo Lee",
        "Gihun Yeom",
        "Buru Chang",
        "Gihun Lee"
      ],
      "abstract": "This study introduces CUPID, a novel approach to session-based reciprocal\nrecommendation systems designed for a real-time one-on-one social discovery\nplatform. In such platforms, low latency is critical to enhance user\nexperiences. However, conventional session-based approaches struggle with high\nlatency due to the demands of modeling sequential user behavior for each\nrecommendation process. Additionally, given the reciprocal nature of the\nplatform, where users act as items for each other, training recommendation\nmodels on large-scale datasets is computationally prohibitive using\nconventional methods. To address these challenges, CUPID decouples the\ntime-intensive user session modeling from the real-time user matching process\nto reduce inference time. Furthermore, CUPID employs a two-phase training\nstrategy that separates the training of embedding and prediction layers,\nsignificantly reducing the computational burden by decreasing the number of\nsequential model inferences by several hundredfold. Extensive experiments on\nlarge-scale Azar datasets demonstrate CUPID's effectiveness in a real-world\nproduction environment. Notably, CUPID reduces response latency by more than\n76% compared to non-asynchronous systems, while significantly improving user\nengagement.",
      "tldr_zh": "本研究提出 CUPID，一种针对实时一对一社交发现平台的基于会话的互惠推荐系统（reciprocal recommendation system），旨在解决传统方法在处理顺序用户行为时的高延迟和大规模数据集训练的计算挑战。CUPID 通过将用户会话建模与实时用户匹配过程解耦，显著减少推理时间；同时采用两阶段训练策略，分离嵌入层和预测层的训练，从而将顺序模型推理次数降低数百倍。实验在大型 Azar 数据集上验证了其有效性，CUPID 相比非异步系统将响应延迟减少超过 76%，并显著提高了用户参与度。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "The 2nd International Workshop on User Understanding from Big Data\n  Workshop (DMU2 2024)",
      "pdf_url": "http://arxiv.org/pdf/2410.18087v1",
      "published_date": "2024-10-08 05:44:14 UTC",
      "updated_date": "2024-10-08 05:44:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:50:10.517417"
    },
    {
      "arxiv_id": "2410.05698v1",
      "title": "A Two-Step Approach for Data-Efficient French Pronunciation Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Hoyeon Lee",
        "Hyeeun Jang",
        "Jong-Hwan Kim",
        "Jae-Min Kim"
      ],
      "abstract": "Recent studies have addressed intricate phonological phenomena in French,\nrelying on either extensive linguistic knowledge or a significant amount of\nsentence-level pronunciation data. However, creating such resources is\nexpensive and non-trivial. To this end, we propose a novel two-step approach\nthat encompasses two pronunciation tasks: grapheme-to-phoneme and post-lexical\nprocessing. We then investigate the efficacy of the proposed approach with a\nnotably limited amount of sentence-level pronunciation data. Our findings\ndemonstrate that the proposed two-step approach effectively mitigates the lack\nof extensive labeled data, and serves as a feasible solution for addressing\nFrench phonological phenomena even under resource-constrained environments.",
      "tldr_zh": "该研究提出了一种数据高效的两步方法，用于法语发音学习，旨在解决传统方法依赖大量标注数据或专业知识的局限性。第一步涉及grapheme-to-phoneme转换，将字母映射到音素；第二步则处理post-lexical processing，以优化语音输出。实验结果表明，即使在有限的句子级发音数据环境下，该方法也能有效缓解数据不足问题，并为资源受限的法语语音现象处理提供可行解决方案。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted at EMNLP 2024 Main",
      "pdf_url": "http://arxiv.org/pdf/2410.05698v1",
      "published_date": "2024-10-08 05:30:23 UTC",
      "updated_date": "2024-10-08 05:30:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:50:22.284994"
    },
    {
      "arxiv_id": "2410.09090v1",
      "title": "Automating Bibliometric Analysis with Sentence Transformers and Retrieval-Augmented Generation (RAG): A Pilot Study in Semantic and Contextual Search for Customized Literature Characterization for High-Impact Urban Research",
      "title_zh": "翻译失败",
      "authors": [
        "Haowen Xu",
        "Xueping Li",
        "Jose Tupayachi",
        "Jianming",
        "Lian",
        "Femi Omitaomu"
      ],
      "abstract": "Bibliometric analysis is essential for understanding research trends, scope,\nand impact in urban science, especially in high-impact journals, such Nature\nPortfolios. However, traditional methods, relying on keyword searches and basic\nNLP techniques, often fail to uncover valuable insights not explicitly stated\nin article titles or keywords. These approaches are unable to perform semantic\nsearches and contextual understanding, limiting their effectiveness in\nclassifying topics and characterizing studies. In this paper, we address these\nlimitations by leveraging Generative AI models, specifically transformers and\nRetrieval-Augmented Generation (RAG), to automate and enhance bibliometric\nanalysis. We developed a technical workflow that integrates a vector database,\nSentence Transformers, a Gaussian Mixture Model (GMM), Retrieval Agent, and\nLarge Language Models (LLMs) to enable contextual search, topic ranking, and\ncharacterization of research using customized prompt templates. A pilot study\nanalyzing 223 urban science-related articles published in Nature Communications\nover the past decade highlights the effectiveness of our approach in generating\ninsightful summary statistics on the quality, scope, and characteristics of\npapers in high-impact journals. This study introduces a new paradigm for\nenhancing bibliometric analysis and knowledge retrieval in urban research,\npositioning an AI agent as a powerful tool for advancing research evaluation\nand understanding.",
      "tldr_zh": "本研究针对传统文献计量分析的局限性（如依赖关键词搜索，无法进行语义搜索和上下文理解），提出了一种自动化方法，使用Sentence Transformers和Retrieval-Augmented Generation (RAG)来提升城市研究文献的特征化。方法包括整合向量数据库、Gaussian Mixture Model (GMM)、Retrieval Agent和Large Language Models (LLMs)的技术工作流，支持自定义提示模板进行上下文搜索、主题排名和研究特征化。在一个试点研究中，对Nature Communications过去十年发表的223篇城市科学相关文章进行分析，展示了该方法在生成关于论文质量、范围和特征的洞见总结统计上的有效性。该研究引入了新范式，将AI代理定位为推进文献计量分析和知识检索的强大工具。",
      "categories": [
        "cs.DL",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.DL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.09090v1",
      "published_date": "2024-10-08 05:13:27 UTC",
      "updated_date": "2024-10-08 05:13:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:50:35.215957"
    },
    {
      "arxiv_id": "2410.05684v2",
      "title": "Copiloting Diagnosis of Autism in Real Clinical Scenarios via LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Yi Jiang",
        "Qingyang Shen",
        "Shuzhong Lai",
        "Shunyu Qi",
        "Qian Zheng",
        "Lin Yao",
        "Yueming Wang",
        "Gang Pan"
      ],
      "abstract": "Autism spectrum disorder(ASD) is a pervasive developmental disorder that\nsignificantly impacts the daily functioning and social participation of\nindividuals. Despite the abundance of research focused on supporting the\nclinical diagnosis of ASD, there is still a lack of systematic and\ncomprehensive exploration in the field of methods based on Large Language\nModels (LLMs), particularly regarding the real-world clinical diagnostic\nscenarios based on Autism Diagnostic Observation Schedule, Second Edition\n(ADOS-2). Therefore, we have proposed a framework called ADOS-Copilot, which\nstrikes a balance between scoring and explanation and explored the factors that\ninfluence the performance of LLMs in this task. The experimental results\nindicate that our proposed framework is competitive with the diagnostic results\nof clinicians, with a minimum MAE of 0.4643, binary classification F1-score of\n81.79\\%, and ternary classification F1-score of 78.37\\%. Furthermore, we have\nsystematically elucidated the strengths and limitations of current LLMs in this\ntask from the perspectives of ADOS-2, LLMs' capabilities, language, and model\nscale aiming to inspire and guide the future application of LLMs in a broader\nfields of mental health disorders. We hope for more research to be transferred\ninto real clinical practice, opening a window of kindness to the world for\neccentric children.",
      "tldr_zh": "本研究提出了一种名为 ADOS-Copilot 的框架，利用大型语言模型 (LLMs) 辅助自闭症谱系障碍 (ASD) 的临床诊断，针对真实场景中的 Autism Diagnostic Observation Schedule, Second Edition (ADOS-2) 评估进行系统探索。该框架在评分和解释之间实现平衡，并分析了影响 LLMs 性能的因素，如模型能力、语言和规模。实验结果显示，ADOS-Copilot 的表现与临床医生相当，达到最低 MAE 0.4643、二元分类 F1-score 81.79% 和三元分类 F1-score 78.37%，并从多个角度阐述了 LLMs 在精神健康领域的优势与局限性，以推动更多应用到实际临床实践。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.05684v2",
      "published_date": "2024-10-08 04:48:42 UTC",
      "updated_date": "2024-10-10 03:24:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:50:47.015302"
    },
    {
      "arxiv_id": "2410.05677v2",
      "title": "T2V-Turbo-v2: Enhancing Video Generation Model Post-Training through Data, Reward, and Conditional Guidance Design",
      "title_zh": "翻译失败",
      "authors": [
        "Jiachen Li",
        "Qian Long",
        "Jian Zheng",
        "Xiaofeng Gao",
        "Robinson Piramuthu",
        "Wenhu Chen",
        "William Yang Wang"
      ],
      "abstract": "In this paper, we focus on enhancing a diffusion-based text-to-video (T2V)\nmodel during the post-training phase by distilling a highly capable consistency\nmodel from a pretrained T2V model. Our proposed method, T2V-Turbo-v2,\nintroduces a significant advancement by integrating various supervision\nsignals, including high-quality training data, reward model feedback, and\nconditional guidance, into the consistency distillation process. Through\ncomprehensive ablation studies, we highlight the crucial importance of\ntailoring datasets to specific learning objectives and the effectiveness of\nlearning from diverse reward models for enhancing both the visual quality and\ntext-video alignment. Additionally, we highlight the vast design space of\nconditional guidance strategies, which centers on designing an effective energy\nfunction to augment the teacher ODE solver. We demonstrate the potential of\nthis approach by extracting motion guidance from the training datasets and\nincorporating it into the ODE solver, showcasing its effectiveness in improving\nthe motion quality of the generated videos with the improved motion-related\nmetrics from VBench and T2V-CompBench. Empirically, our T2V-Turbo-v2\nestablishes a new state-of-the-art result on VBench, with a Total score of\n85.13, surpassing proprietary systems such as Gen-3 and Kling.",
      "tldr_zh": "本论文提出 T2V-Turbo-v2 方法，通过在后训练阶段从预训练文本到视频 (T2V) 模型中蒸馏一致性模型，并整合高质量训练数据、奖励模型反馈和条件指导信号，来提升基于扩散的视频生成模型。研究通过消融实验强调了定制数据集对特定学习目标的重要性，以及从多样奖励模型中学习以改善视觉质量和文本-视频对齐，同时探索了条件指导策略的设计空间，例如使用能量函数增强教师 ODE 求解器并提取运动指导。最终，T2V-Turbo-v2 在 VBench 上达到总分 85.13 的新最先进结果，超越了 Gen-3 和 Kling 等专有系统。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Project Page: https://t2v-turbo-v2.github.io/",
      "pdf_url": "http://arxiv.org/pdf/2410.05677v2",
      "published_date": "2024-10-08 04:30:06 UTC",
      "updated_date": "2024-10-11 07:47:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:51:00.152079"
    },
    {
      "arxiv_id": "2410.09089v1",
      "title": "Different Cybercrimes and their Solution for Common People",
      "title_zh": "翻译失败",
      "authors": [
        "S. Tamang",
        "G. S. Chandana",
        "B. K. Roy"
      ],
      "abstract": "In today's digital age, cyberspace has become integral to daily life, however\nit has also led to an increase in cybercriminal activities. This paper explores\ncybercrime trends and highlights the need for cybercrime awareness\n(cyberawareness) to mitigate vulnerabilities. The study also examines Indian\nstatistics on cybercrime. We review the existing literature on cybercrime and\ncybersecurity, focusing on various types of cybercrimes and their impacts. We\npresent a list of 31 technical as well as non-technical solutions considering\nthat a \"common man\" may not be technologically aware. Common man solutions,\nconsidering that they are not technologically updated. Expanding the list of\nsolutions and validating their effectiveness in cyber threats can be the future\nscope of the research.",
      "tldr_zh": "这篇论文探讨了数字时代网络犯罪（cybercrime）的趋势及其对日常生活的影响，强调了提升网络犯罪意识（cyberawareness）以减少漏洞的重要性，并分析了印度网络犯罪的统计数据。通过回顾现有文献，该研究列出了31种技术性和非技术性解决方案，针对普通人（不熟悉技术）提供实用应对策略。总体贡献在于为非技术人员提供易于实施的防护措施，未来研究可扩展这些解决方案并验证其在cybersecurity中的有效性。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.09089v1",
      "published_date": "2024-10-08 04:23:11 UTC",
      "updated_date": "2024-10-08 04:23:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:51:09.966771"
    },
    {
      "arxiv_id": "2410.05669v2",
      "title": "ACPBench: Reasoning about Action, Change, and Planning",
      "title_zh": "ACPBench：行动、变化和规划的推理",
      "authors": [
        "Harsha Kokel",
        "Michael Katz",
        "Kavitha Srinivas",
        "Shirin Sohrabi"
      ],
      "abstract": "There is an increasing body of work using Large Language Models (LLMs) as\nagents for orchestrating workflows and making decisions in domains that require\nplanning and multi-step reasoning. As a result, it is imperative to evaluate\nLLMs on core skills required for planning. In this work, we present ACPBench, a\nbenchmark for evaluating the reasoning tasks in the field of planning. The\nbenchmark consists of 7 reasoning tasks over 13 planning domains. The\ncollection is constructed from planning domains described in a formal language.\nThis allows us to synthesize problems with provably correct solutions across\nmany tasks and domains. Further, it allows us the luxury of scale without\nadditional human effort, i.e., many additional problems can be created\nautomatically. Our extensive evaluation of 22 LLMs and OpenAI o1 reasoning\nmodels highlights the significant gap in the reasoning capability of the LLMs.\nOur findings with OpenAI o1, a multi-turn reasoning model, reveal significant\ngains in performance on multiple-choice questions, yet surprisingly, no notable\nprogress is made on boolean questions.\n  The ACPBench collection is available at https://ibm.github.io/ACPBench.",
      "tldr_zh": "本研究引入了 ACPBench，这是一个用于评估大型语言模型 (LLMs) 在行动、变化和规划领域的推理能力的基准。ACPBench 包含 7 个推理任务，覆盖 13 个规划领域，这些任务基于正式语言描述的规划领域构建，可自动合成具有可证明正确解决方案的问题，从而实现大规模扩展。实验评估了 22 个 LLMs 和 OpenAI o1 模型，结果显示 LLMs 在推理能力上存在显著差距，其中 OpenAI o1 在多选题上表现出色，但布尔题上无明显进步。该基准的集合可通过 https://ibm.github.io/ACPBench 访问。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Added OpenAI o1 results",
      "pdf_url": "http://arxiv.org/pdf/2410.05669v2",
      "published_date": "2024-10-08 03:48:57 UTC",
      "updated_date": "2024-10-22 17:16:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:51:22.521825"
    },
    {
      "arxiv_id": "2410.05668v1",
      "title": "Diversity and Inclusion Index with Networks and Similarity: Analysis and its Application",
      "title_zh": "基于网络和相似性的多样性和包容性指数：分析及其应用",
      "authors": [
        "Keita Kinjo"
      ],
      "abstract": "In recent years, the concepts of ``diversity'' and ``inclusion'' have\nattracted considerable attention across a range of fields, encompassing both\nsocial and biological disciplines. To fully understand these concepts, it is\ncritical to not only examine the number of categories but also the similarities\nand relationships among them. In this study, I introduce a novel index for\ndiversity and inclusion that considers similarities and network connections. I\nanalyzed the properties of these indices and investigated their mathematical\nrelationships using established measures of diversity and networks. Moreover, I\ndeveloped a methodology for estimating similarities based on the utility of\ndiversity. I also created a method for visualizing proportions, similarities,\nand network connections. Finally, I evaluated the correlation with external\nmetrics using real-world data, confirming that both the proposed indices and\nour index can be effectively utilized. This study contributes to a more nuanced\nunderstanding of diversity and inclusion analysis.",
      "tldr_zh": "本研究提出了一种新的多样性（diversity）和包容性（inclusion）指数，该指数整合了相似性（similarity）和网络（networks）连接，以更全面地评估多样性。研究分析了该指数的属性及其与现有多样性测量和网络指标的数学关系，并开发了基于多样性效用（utility of diversity）的相似性估计方法，以及一种可视化比例、相似性和网络连接的工具。通过使用真实数据评估，该指数与外部指标显示出显著相关性，为多样性和包容性分析提供了更细致的理解和应用框架。",
      "categories": [
        "cs.SI",
        "cs.AI",
        "stat.ME",
        "68T01, 62P25"
      ],
      "primary_category": "cs.SI",
      "comment": "20 pages",
      "pdf_url": "http://arxiv.org/pdf/2410.05668v1",
      "published_date": "2024-10-08 03:41:39 UTC",
      "updated_date": "2024-10-08 03:41:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:51:33.456823"
    },
    {
      "arxiv_id": "2410.05661v1",
      "title": "Scaling Laws Across Model Architectures: A Comparative Analysis of Dense and MoE Models in Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Siqi Wang",
        "Zhengyu Chen",
        "Bei Li",
        "Keqing He",
        "Min Zhang",
        "Jingang Wang"
      ],
      "abstract": "The scaling of large language models (LLMs) is a critical research area for\nthe efficiency and effectiveness of model training and deployment. Our work\ninvestigates the transferability and discrepancies of scaling laws between\nDense Models and Mixture of Experts (MoE) models. Through a combination of\ntheoretical analysis and extensive experiments, including consistent loss\nscaling, optimal batch size and learning rate scaling, and resource allocation\nstrategies scaling, our findings reveal that the power-law scaling framework\nalso applies to MoE Models, indicating that the fundamental principles\ngoverning the scaling behavior of these models are preserved, even though the\narchitecture differs. Additionally, MoE Models demonstrate superior\ngeneralization, resulting in lower testing losses with the same training\ncompute budget compared to Dense Models. These findings indicate the scaling\nconsistency and transfer generalization capabilities of MoE Models, providing\nnew insights for optimizing MoE Model training and deployment strategies.",
      "tldr_zh": "本研究比较了大型语言模型（LLMs）中 Dense Models 和 Mixture of Experts (MoE) Models 的缩放规律，通过理论分析和广泛实验（如一致损失缩放、最优批量大小和学习率缩放以及资源分配策略）来评估其转移性和差异。结果显示，power-law scaling 框架同样适用于 MoE Models，表明尽管架构不同，其基本缩放原则保持一致。MoE Models 展现出更好的泛化能力，在相同训练计算预算下实现更低的测试损失，这为优化 MoE Models 的训练和部署策略提供了重要新见解。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.05661v1",
      "published_date": "2024-10-08 03:21:56 UTC",
      "updated_date": "2024-10-08 03:21:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:51:46.554926"
    },
    {
      "arxiv_id": "2410.05656v1",
      "title": "On the Modeling Capabilities of Large Language Models for Sequential Decision Making",
      "title_zh": "翻译失败",
      "authors": [
        "Martin Klissarov",
        "Devon Hjelm",
        "Alexander Toshev",
        "Bogdan Mazoure"
      ],
      "abstract": "Large pretrained models are showing increasingly better performance in\nreasoning and planning tasks across different modalities, opening the\npossibility to leverage them for complex sequential decision making problems.\nIn this paper, we investigate the capabilities of Large Language Models (LLMs)\nfor reinforcement learning (RL) across a diversity of interactive domains. We\nevaluate their ability to produce decision-making policies, either directly, by\ngenerating actions, or indirectly, by first generating reward models to train\nan agent with RL. Our results show that, even without task-specific\nfine-tuning, LLMs excel at reward modeling. In particular, crafting rewards\nthrough artificial intelligence (AI) feedback yields the most generally\napplicable approach and can enhance performance by improving credit assignment\nand exploration. Finally, in environments with unfamiliar dynamics, we explore\nhow fine-tuning LLMs with synthetic data can significantly improve their reward\nmodeling capabilities while mitigating catastrophic forgetting, further\nbroadening their utility in sequential decision-making tasks.",
      "tldr_zh": "本研究探讨了Large Language Models (LLMs) 在强化学习 (RL) 中的建模能力，评估它们在不同交互环境中直接生成决策策略或间接生成奖励模型以训练代理。结果表明，即使未经任务特定微调，LLMs 在奖励建模方面表现出色，而通过人工智能 (AI) 反馈创建奖励能进一步提升性能，改善信用分配和探索。最终，在动态不熟悉的环境中，使用合成数据微调 LLMs 可显著增强其奖励建模能力，同时缓解灾难性遗忘，从而扩展其在顺序决策任务中的应用。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.05656v1",
      "published_date": "2024-10-08 03:12:57 UTC",
      "updated_date": "2024-10-08 03:12:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:51:57.964857"
    },
    {
      "arxiv_id": "2410.05651v3",
      "title": "ViBiDSampler: Enhancing Video Interpolation Using Bidirectional Diffusion Sampler",
      "title_zh": "ViBiDSampler：使用双向扩散采样器增强视频插值",
      "authors": [
        "Serin Yang",
        "Taesung Kwon",
        "Jong Chul Ye"
      ],
      "abstract": "Recent progress in large-scale text-to-video (T2V) and image-to-video (I2V)\ndiffusion models has greatly enhanced video generation, especially in terms of\nkeyframe interpolation. However, current image-to-video diffusion models, while\npowerful in generating videos from a single conditioning frame, need adaptation\nfor two-frame (start & end) conditioned generation, which is essential for\neffective bounded interpolation. Unfortunately, existing approaches that fuse\ntemporally forward and backward paths in parallel often suffer from\noff-manifold issues, leading to artifacts or requiring multiple iterative\nre-noising steps. In this work, we introduce a novel, bidirectional sampling\nstrategy to address these off-manifold issues without requiring extensive\nre-noising or fine-tuning. Our method employs sequential sampling along both\nforward and backward paths, conditioned on the start and end frames,\nrespectively, ensuring more coherent and on-manifold generation of intermediate\nframes. Additionally, we incorporate advanced guidance techniques, CFG++ and\nDDS, to further enhance the interpolation process. By integrating these, our\nmethod achieves state-of-the-art performance, efficiently generating\nhigh-quality, smooth videos between keyframes. On a single 3090 GPU, our method\ncan interpolate 25 frames at 1024 x 576 resolution in just 195 seconds,\nestablishing it as a leading solution for keyframe interpolation.",
      "tldr_zh": "该论文提出了一种名为 ViBiDSampler 的方法，利用 bidirectional diffusion sampler 来提升视频插值质量，特别是针对图像到视频 (I2V) 扩散模型在两帧条件下的生成问题。ViBiDSampler 通过顺序采样沿前向和后向路径，并整合高级指导技术 CFG++ 和 DDS，确保中间帧的连贯性和 on-manifold 生成，从而避免了 artifacts 和需要多次迭代重新噪声。实验结果显示，该方法在单 3090 GPU 上仅用 195 秒即可插值 25 帧视频（分辨率 1024 x 576），实现了 state-of-the-art 性能，为高效关键帧插值提供了领先解决方案。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "ICLR 2025; Project page: https://vibidsampler.github.io/",
      "pdf_url": "http://arxiv.org/pdf/2410.05651v3",
      "published_date": "2024-10-08 03:01:54 UTC",
      "updated_date": "2025-03-01 07:27:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:52:11.629253"
    },
    {
      "arxiv_id": "2410.05646v1",
      "title": "Score-Based Variational Inference for Inverse Problems",
      "title_zh": "翻译失败",
      "authors": [
        "Zhipeng Xue",
        "Penghao Cai",
        "Xiaojun Yuan",
        "Xiqi Gao"
      ],
      "abstract": "Existing diffusion-based methods for inverse problems sample from the\nposterior using score functions and accept the generated random samples as\nsolutions. In applications that posterior mean is preferred, we have to\ngenerate multiple samples from the posterior which is time-consuming. In this\nwork, by analyzing the probability density evolution of the conditional reverse\ndiffusion process, we prove that the posterior mean can be achieved by tracking\nthe mean of each reverse diffusion step. Based on that, we establish a\nframework termed reverse mean propagation (RMP) that targets the posterior mean\ndirectly. We show that RMP can be implemented by solving a variational\ninference problem, which can be further decomposed as minimizing a reverse KL\ndivergence at each reverse step. We further develop an algorithm that optimizes\nthe reverse KL divergence with natural gradient descent using score functions\nand propagates the mean at each reverse step. Experiments demonstrate the\nvalidity of the theory of our framework and show that our algorithm outperforms\nstate-of-the-art algorithms on reconstruction performance with lower\ncomputational complexity in various inverse problems.",
      "tldr_zh": "本文提出了一种基于分数变分推理（Score-Based Variational Inference）的框架，针对逆问题中现有扩散方法采样后验分布耗时的局限，直接计算后验均值。作者通过分析条件反向扩散过程的概率密度演化，证明后验均值可通过跟踪每个反向扩散步骤的均值实现，并建立了Reverse Mean Propagation (RMP)框架，该框架将问题分解为最小化每个反向步骤的反向KL散度。实验结果表明，该算法在使用分数函数和自然梯度下降进行优化后，在各种逆问题上比现有方法具有更高的重建性能和更低的计算复杂度。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.IT",
        "math.IT"
      ],
      "primary_category": "cs.LG",
      "comment": "10 pages, 7 figures, conference",
      "pdf_url": "http://arxiv.org/pdf/2410.05646v1",
      "published_date": "2024-10-08 02:55:16 UTC",
      "updated_date": "2024-10-08 02:55:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:52:22.743866"
    },
    {
      "arxiv_id": "2410.05637v2",
      "title": "Federated Neural Nonparametric Point Processes",
      "title_zh": "联邦神经非参数点过程",
      "authors": [
        "Hui Chen",
        "Xuhui Fan",
        "Hengyu Liu",
        "Yaqiong Li",
        "Zhilin Zhao",
        "Feng Zhou",
        "Christopher John Quinn",
        "Longbing Cao"
      ],
      "abstract": "Temporal point processes (TPPs) are effective for modeling event occurrences\nover time, but they struggle with sparse and uncertain events in federated\nsystems, where privacy is a major concern. To address this, we propose\n\\textit{FedPP}, a Federated neural nonparametric Point Process model. FedPP\nintegrates neural embeddings into Sigmoidal Gaussian Cox Processes (SGCPs) on\nthe client side, which is a flexible and expressive class of TPPs, allowing it\nto generate highly flexible intensity functions that capture client-specific\nevent dynamics and uncertainties while efficiently summarizing historical\nrecords. For global aggregation, FedPP introduces a divergence-based mechanism\nthat communicates the distributions of SGCPs' kernel hyperparameters between\nthe server and clients, while keeping client-specific parameters local to\nensure privacy and personalization. FedPP effectively captures event\nuncertainty and sparsity, and extensive experiments demonstrate its superior\nperformance in federated settings, particularly with KL divergence and\nWasserstein distance-based global aggregation.",
      "tldr_zh": "该研究针对时间点过程(Temporal Point Processes, TPPs)在联邦系统中处理稀疏和不确定事件时面临的隐私挑战，提出了一种Federated neural nonparametric Point Process模型FedPP。FedPP在客户端整合神经嵌入到Sigmoidal Gaussian Cox Processes (SGCPs)中，生成灵活的强度函数以捕捉特定客户端的事件动态和不确定性，同时高效总结历史记录；同时，通过基于发散的全局聚合机制，仅通信SGCPs内核超参数的分布，确保隐私和个性化。实验结果显示，FedPP在联邦设置中表现出色，尤其在使用KL divergence和Wasserstein distance的聚合方法时，显著提升了事件不确定性和稀疏性的处理性能。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.05637v2",
      "published_date": "2024-10-08 02:40:04 UTC",
      "updated_date": "2025-01-20 23:38:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:52:34.191795"
    },
    {
      "arxiv_id": "2410.05629v2",
      "title": "Vector-ICL: In-context Learning with Continuous Vector Representations",
      "title_zh": "翻译失败",
      "authors": [
        "Yufan Zhuang",
        "Chandan Singh",
        "Liyuan Liu",
        "Jingbo Shang",
        "Jianfeng Gao"
      ],
      "abstract": "Large language models (LLMs) have shown remarkable in-context learning (ICL)\ncapabilities on textual data. We explore whether these capabilities can be\nextended to continuous vectors from diverse domains, obtained from black-box\npretrained encoders. By aligning input data with an LLM's embedding space\nthrough lightweight projectors, we observe that LLMs can effectively process\nand learn from these projected vectors, which we term Vector-ICL. In\nparticular, we find that pretraining projectors with general language modeling\nobjectives enables Vector-ICL, while task-specific finetuning further enhances\nperformance. In our experiments across various tasks and modalities, including\ntext reconstruction, numerical function regression, text classification,\nsummarization, molecule captioning, time-series classification, graph\nclassification, and fMRI decoding, Vector-ICL often surpasses both few-shot ICL\nand domain-specific model or tuning. We further conduct analyses and case\nstudies, indicating the potential of LLMs to process vector representations\nbeyond traditional token-based paradigms.",
      "tldr_zh": "本文提出 Vector-ICL 方法，通过轻量级投影器将来自黑箱预训练编码器的连续向量表示与 LLMs 的嵌入空间对齐，从而扩展 in-context learning (ICL) 到非文本领域。研究发现，使用一般语言建模目标预训练投影器即可启用 Vector-ICL，而任务特定微调进一步提升性能。在跨多种任务和模态的实验中，如文本重建、数值函数回归、文本分类、分子标题和 fMRI 解码，Vector-ICL 往往优于少样本 ICL 和领域特定模型，证明 LLMs 可处理超出传统标记范式的向量表示。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.05629v2",
      "published_date": "2024-10-08 02:25:38 UTC",
      "updated_date": "2025-02-19 22:48:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:52:46.623960"
    },
    {
      "arxiv_id": "2410.05628v5",
      "title": "A Unified Framework for Motion Reasoning and Generation in Human Interaction",
      "title_zh": "人类互动中运动推理和生成的统一框架",
      "authors": [
        "Jeongeun Park",
        "Sungjoon Choi",
        "Sangdoo Yun"
      ],
      "abstract": "Recent advancements in large language models (LLMs) have significantly\nimproved their ability to generate natural and contextually relevant text,\nenabling more human-like AI interactions. However, generating and understanding\ninteractive human-like motion, where multiple individuals engage in coordinated\nmovements, remains challenging due to the complexity of modeling these\ninteractions. Additionally, a unified and versatile model is needed to handle\ndiverse interactive scenarios, such as chat systems that dynamically adapt to\nuser instructions and assigned roles. To address these challenges, we introduce\nVIM, the Versatile Interactive Motion-language model, which integrates both\nlanguage and motion modalities to effectively understand, generate, and control\ninteractive motions in multi-turn conversational contexts. Unlike previous\nstudies that primarily focus on uni-directional tasks such as text-to-motion or\nmotion-to-text, VIM employs a unified architecture capable of simultaneously\nunderstanding and generating both motion and text modalities. Given the absence\nof an appropriate dataset to support this task, we introduce Inter-MT2, a\nlarge-scale instruction-tuning dataset containing 82.7K multi-turn interactive\nmotion instructions, covering 153K interactive motion samples. Inter-MT2 spans\ndiverse instructional scenarios, including motion editing, question answering,\nand story generation, leveraging off-the-shelf large language models and motion\ndiffusion models to construct a broad set of interactive motion instructions.\nWe extensively evaluate the versatility of VIM across multiple interactive\nmotion-related tasks, including motion-to-text, text-to-motion, reaction\ngeneration, motion editing, and reasoning about motion sequences.",
      "tldr_zh": "这篇论文提出VIM（Versatile Interactive Motion-language model），一个统一框架，用于处理人类互动中的动作推理和生成，解决大型语言模型(LLMs)在建模协调动作时的复杂性挑战。VIM整合语言和动作模态，支持多任务如motion-to-text、text-to-motion、反应生成、动作编辑和序列推理，实现多轮对话中的动态适应。作者构建了Inter-MT2数据集，包含82.7K多轮互动动作指令和153K动作样本，覆盖动作编辑、问答和故事生成等多种场景。实验评估证明，VIM在多样互动任务上表现出色，提升了模型的通用性和有效性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "https://vim-motion-language.github.io/",
      "pdf_url": "http://arxiv.org/pdf/2410.05628v5",
      "published_date": "2024-10-08 02:23:53 UTC",
      "updated_date": "2025-03-12 05:54:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:52:58.401308"
    },
    {
      "arxiv_id": "2410.05627v1",
      "title": "CLOSER: Towards Better Representation Learning for Few-Shot Class-Incremental Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Junghun Oh",
        "Sungyong Baik",
        "Kyoung Mu Lee"
      ],
      "abstract": "Aiming to incrementally learn new classes with only few samples while\npreserving the knowledge of base (old) classes, few-shot class-incremental\nlearning (FSCIL) faces several challenges, such as overfitting and catastrophic\nforgetting. Such a challenging problem is often tackled by fixing a feature\nextractor trained on base classes to reduce the adverse effects of overfitting\nand forgetting. Under such formulation, our primary focus is representation\nlearning on base classes to tackle the unique challenge of FSCIL:\nsimultaneously achieving the transferability and the discriminability of the\nlearned representation. Building upon the recent efforts for enhancing\ntransferability, such as promoting the spread of features, we find that trying\nto secure the spread of features within a more confined feature space enables\nthe learned representation to strike a better balance between transferability\nand discriminability. Thus, in stark contrast to prior beliefs that the\ninter-class distance should be maximized, we claim that the closer different\nclasses are, the better for FSCIL. The empirical results and analysis from the\nperspective of information bottleneck theory justify our simple yet seemingly\ncounter-intuitive representation learning method, raising research questions\nand suggesting alternative research directions. The code is available at\nhttps://github.com/JungHunOh/CLOSER_ECCV2024.",
      "tldr_zh": "该论文针对Few-Shot Class-Incremental Learning (FSCIL)问题，提出了一种名为CLOSER的表示学习方法，以解决overfitting和catastrophic forgetting等挑战，同时在基类上训练特征提取器。不同于传统方法，该方法主张在更受限的特征空间中推广特征分布，从而更好地平衡learned representation的transferability和discriminability，强调类间距离更近有助于提升性能。实验结果和information bottleneck theory的分析支持了这一看似反直觉的观点，为FSCIL研究提供了新方向。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted at ECCV2024",
      "pdf_url": "http://arxiv.org/pdf/2410.05627v1",
      "published_date": "2024-10-08 02:23:16 UTC",
      "updated_date": "2024-10-08 02:23:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:53:10.023610"
    },
    {
      "arxiv_id": "2410.05623v2",
      "title": "Understanding Gradient Boosting Classifier: Training, Prediction, and the Role of $γ_j$",
      "title_zh": "理解梯度提升分类器：训练、预测以及 $γ_j$ 的作用",
      "authors": [
        "Hung-Hsuan Chen"
      ],
      "abstract": "The Gradient Boosting Classifier (GBC) is a widely used machine learning\nalgorithm for binary classification, which builds decision trees iteratively to\nminimize prediction errors. This document explains the GBC's training and\nprediction processes, focusing on the computation of terminal node values\n$\\gamma_j$, which are crucial to optimizing the logistic loss function. We\nderive $\\gamma_j$ through a Taylor series approximation and provide a\nstep-by-step pseudocode for the algorithm's implementation. The guide explains\nthe theory of GBC and its practical application, demonstrating its\neffectiveness in binary classification tasks. We provide a step-by-step example\nin the appendix to help readers understand.",
      "tldr_zh": "这篇论文详细解释了 Gradient Boosting Classifier (GBC)，一个用于二元分类的机器学习算法，其通过迭代构建决策树来最小化预测错误。论文重点分析了训练和预测过程，特别是终端节点值 $γ_j$ 的计算方式，该值通过 Taylor 系列逼近优化 logistic loss 函数。作者提供了算法的逐步伪代码和实际示例，展示了 GBC 在二元分类任务中的有效性和实用性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.05623v2",
      "published_date": "2024-10-08 02:11:35 UTC",
      "updated_date": "2024-10-23 07:28:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:53:21.147301"
    },
    {
      "arxiv_id": "2410.05610v1",
      "title": "Chain-of-Thoughts for Molecular Understanding",
      "title_zh": "翻译失败",
      "authors": [
        "Yunhui Jang",
        "Jaehyung Kim",
        "Sungsoo Ahn"
      ],
      "abstract": "The adaptation of large language models (LLMs) to chemistry has shown\npromising performance in molecular understanding tasks, such as generating a\ntext description from a molecule. However, proper reasoning based on molecular\nstructural information remains a significant challenge, e.g., even advanced\nLLMs such as GPT-4o struggle to identify functional groups which are crucial\nfor inferring the molecular property of interest. To address this limitation,\nwe propose StructCoT, a structure-aware chain-of-thought (CoT) that enhances\nLLMs' understanding of molecular structures by explicitly injecting the key\nstructural features of molecules. Moreover, we introduce two fine-tuning\nframeworks for adapting the existing LLMs to use our StructCoT. Our experiments\ndemonstrate that incorporating StructCoT with our fine-tuning frameworks leads\nto consistent improvements in both molecular understanding tasks.",
      "tldr_zh": "本研究探讨了大型语言模型 (LLMs) 在分子理解任务中的应用，尽管它们能生成分子描述，但仍存在基于结构信息的推理挑战，例如 GPT-4o 难以识别功能基团。针对这一问题，作者提出 StructCoT，一种结构感知的 Chain-of-Thought (CoT) 方法，通过显式注入分子关键结构特征来提升 LLMs 的理解能力。此外，引入两种微调框架，以适应现有 LLMs 使用 StructCoT。实验结果表明，这种方法在分子理解任务中实现了持续性能提升。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.05610v1",
      "published_date": "2024-10-08 01:49:48 UTC",
      "updated_date": "2024-10-08 01:49:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:54:28.220012"
    },
    {
      "arxiv_id": "2410.05603v1",
      "title": "Everything Everywhere All at Once: LLMs can In-Context Learn Multiple Tasks in Superposition",
      "title_zh": "翻译失败",
      "authors": [
        "Zheyang Xiong",
        "Ziyang Cai",
        "John Cooper",
        "Albert Ge",
        "Vasilis Papageorgiou",
        "Zack Sifakis",
        "Angeliki Giannou",
        "Ziqian Lin",
        "Liu Yang",
        "Saurabh Agarwal",
        "Grigorios G Chrysos",
        "Samet Oymak",
        "Kangwook Lee",
        "Dimitris Papailiopoulos"
      ],
      "abstract": "Large Language Models (LLMs) have demonstrated remarkable in-context learning\n(ICL) capabilities. In this study, we explore a surprising phenomenon related\nto ICL: LLMs can perform multiple, computationally distinct ICL tasks\nsimultaneously, during a single inference call, a capability we term \"task\nsuperposition\". We provide empirical evidence of this phenomenon across various\nLLM families and scales and show that this phenomenon emerges even if we train\nthe model to in-context learn one task at a time. We offer theoretical\nexplanations that this capability is well within the expressive power of\ntransformers. We also explore how LLMs internally compose task vectors during\nsuperposition. Furthermore, we show that larger models can solve more ICL tasks\nin parallel, and better calibrate their output distribution. Our findings offer\ninsights into the latent capabilities of LLMs, further substantiate the\nperspective of \"LLMs as superposition of simulators\", and raise questions about\nthe mechanisms enabling simultaneous task execution.",
      "tldr_zh": "本研究发现大型语言模型 (LLMs) 能够通过 In-Context Learning (ICL) 同时执行多个计算上不同的任务，这种现象称为 task superposition，即使模型是逐个任务训练的。  \n研究通过实证实验在各种 LLM 系列和规模中提供了证据，并探讨了 LLMs 如何内部组合任务向量。  \n理论分析表明，transformers 的表达能力足以支持这一能力，且更大模型能并行处理更多 ICL 任务并更好地校准输出分布。  \n这些发现深化了对 LLMs 潜在能力的理解，支持了 \"LLMs as superposition of simulators\" 的观点，并引发了对同时任务执行机制的探讨。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.05603v1",
      "published_date": "2024-10-08 01:28:57 UTC",
      "updated_date": "2024-10-08 01:28:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:53:46.991771"
    },
    {
      "arxiv_id": "2410.05592v1",
      "title": "Training Stiff Neural Ordinary Differential Equations with Implicit Single-Step Methods",
      "title_zh": "翻译失败",
      "authors": [
        "Colby Fronk",
        "Linda Petzold"
      ],
      "abstract": "Stiff systems of ordinary differential equations (ODEs) are pervasive in many\nscience and engineering fields, yet standard neural ODE approaches struggle to\nlearn them. This limitation is the main barrier to the widespread adoption of\nneural ODEs. In this paper, we propose an approach based on single-step\nimplicit schemes to enable neural ODEs to handle stiffness and demonstrate that\nour implicit neural ODE method can learn stiff dynamics. This work addresses a\nkey limitation in current neural ODE methods, paving the way for their use in a\nwider range of scientific problems.",
      "tldr_zh": "本研究针对刚性普通微分方程（stiff ODEs）在科学和工程领域的广泛应用，但标准神经ODE方法难以学习的问题，提出了一种基于隐式单步方法（implicit single-step methods）的训练框架。 该方法使神经ODE能够有效处理刚性系统，并通过实验证明其能成功学习刚性动态。 总体上，这解决了当前神经ODE方法的 key 限制，推动其在更广泛科学问题中的应用。",
      "categories": [
        "math.NA",
        "cs.AI",
        "cs.CE",
        "cs.NA"
      ],
      "primary_category": "math.NA",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.05592v1",
      "published_date": "2024-10-08 01:08:17 UTC",
      "updated_date": "2024-10-08 01:08:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:53:57.492028"
    },
    {
      "arxiv_id": "2410.09088v1",
      "title": "The Solution for Temporal Action Localisation Task of Perception Test Challenge 2024",
      "title_zh": "针对 Perception Test Challenge 2024 时间动作定位任务的解决方案",
      "authors": [
        "Yinan Han",
        "Qingyuan Jiang",
        "Hongming Mei",
        "Yang Yang",
        "Jinhui Tang"
      ],
      "abstract": "This report presents our method for Temporal Action Localisation (TAL), which\nfocuses on identifying and classifying actions within specific time intervals\nthroughout a video sequence. We employ a data augmentation technique by\nexpanding the training dataset using overlapping labels from the\nSomething-SomethingV2 dataset, enhancing the model's ability to generalize\nacross various action classes. For feature extraction, we utilize\nstate-of-the-art models, including UMT, VideoMAEv2 for video features, and\nBEATs and CAV-MAE for audio features. Our approach involves training both\nmultimodal (video and audio) and unimodal (video only) models, followed by\ncombining their predictions using the Weighted Box Fusion (WBF) method. This\nfusion strategy ensures robust action localisation. our overall approach\nachieves a score of 0.5498, securing first place in the competition.",
      "tldr_zh": "本研究针对 Temporal Action Localisation (TAL) 任务，提出了一种方法，用于在视频序列中识别和分类特定时间间隔内的动作。通过从 Something-SomethingV2 数据集扩展训练数据并应用重叠标签进行数据增强，提高了模型的泛化能力。特征提取方面，使用 UMT 和 VideoMAEv2 处理视频特征，BEATs 和 CAV-MAE 处理音频特征，并训练多模态（视频+音频）和单模态（仅视频）模型，随后通过 Weighted Box Fusion (WBF) 方法融合预测。该方法在 Perception Test Challenge 2024 中取得 0.5498 分，获得第一名。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.09088v1",
      "published_date": "2024-10-08 01:07:21 UTC",
      "updated_date": "2024-10-08 01:07:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:54:09.436893"
    },
    {
      "arxiv_id": "2410.05586v2",
      "title": "TeaserGen: Generating Teasers for Long Documentaries",
      "title_zh": "TeaserGen：为长纪录片生成预告片",
      "authors": [
        "Weihan Xu",
        "Paul Pu Liang",
        "Haven Kim",
        "Julian McAuley",
        "Taylor Berg-Kirkpatrick",
        "Hao-Wen Dong"
      ],
      "abstract": "Teasers are an effective tool for promoting content in entertainment,\ncommercial and educational fields. However, creating an effective teaser for\nlong videos is challenging for it requires long-range multimodal modeling on\nthe input videos, while necessitating maintaining audiovisual alignments,\nmanaging scene changes and preserving factual accuracy for the output teasers.\nDue to the lack of a publicly-available dataset, progress along this research\ndirection has been hindered. In this work, we present DocumentaryNet, a\ncollection of 1,269 documentaries paired with their teasers, featuring\nmultimodal data streams of video, speech, music, sound effects and narrations.\nWith DocumentaryNet, we propose a new two-stage system for generating teasers\nfrom long documentaries. The proposed TeaserGen system first generates the\nteaser narration from the transcribed narration of the documentary using a\npretrained large language model, and then selects the most relevant visual\ncontent to accompany the generated narration through language-vision models.\nFor narration-video matching, we explore two approaches: a pretraining-based\nmodel using pretrained contrastive language-vision models and a deep sequential\nmodel that learns the mapping between the narrations and visuals. Our\nexperimental results show that the pretraining-based approach is more effective\nat identifying relevant visual content than directly trained deep\nautoregressive models.",
      "tldr_zh": "这篇论文介绍了 TeaserGen 系统，用于为长纪录片生成预告片，以解决长程多模态建模、音视频对齐和事实准确性的挑战，同时发布了 DocumentaryNet 数据集，包含 1269 个纪录片及其多模态数据流（如视频、语音和音乐）。TeaserGen 采用两阶段方法：首先利用预训练的大型语言模型从纪录片转录旁白生成预告片旁白，然后通过语言-vision 模型（如基于预训练的对比模型）选择相关视觉内容。实验结果显示，预训练-based 模型在旁白-视频匹配方面比深度自回归模型更有效，提升了预告片的生成质量。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.05586v2",
      "published_date": "2024-10-08 01:00:09 UTC",
      "updated_date": "2024-11-10 02:20:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:54:22.304944"
    },
    {
      "arxiv_id": "2410.10865v1",
      "title": "Generating Synthetic Datasets for Few-shot Prompt Tuning",
      "title_zh": "翻译失败",
      "authors": [
        "Xu Guo",
        "Zilin Du",
        "Boyang Li",
        "Chunyan Miao"
      ],
      "abstract": "A major limitation of prompt tuning is its dependence on large labeled\ntraining datasets. Under few-shot learning settings, prompt tuning lags far\nbehind full-model fine-tuning, limiting its scope of application. In this\npaper, we leverage the powerful LLMs to synthesize task-specific labeled data\nfor training the soft prompts. We first introduce a distribution-aligned\nweighted generator tuning (DawGen) method to encourage generating\nin-distribution data that aligns with the few-shot real data. Then, we train\nsoft prompts on both synthetic and real datasets using a gradient surgery\napproach, which eliminates the conflicting gradients from different data\nsources. Experiments on seven sentence-pair classification datasets demonstrate\nthe effectiveness of our proposed method for boosting prompt tuning in few-shot\nlearning settings. Results on QQP, MRPC, and SICK datasets are even comparable\nto the performance of transfer learning from large real-world datasets, showing\nthe promise of synthetic data as an alternative for enhancing soft prompt\ntuning.",
      "tldr_zh": "本文提出了一种生成合成数据集的方法，以提升少样本提示调优（few-shot prompt tuning）的性能，解决其对大型标注数据集的依赖问题。方法利用强大的大型语言模型（LLMs）合成任务特定的标注数据，并引入分布对齐的加权生成器调优（DawGen）方法，确保合成数据与少样本真实数据分布一致；同时，通过梯度手术（gradient surgery）训练软提示（soft prompts），消除合成数据和真实数据间的冲突梯度。在七个句子对分类数据集上的实验显示，该方法显著提升了少样本学习效果，在 QQP、MRPC 和 SICK 数据集上甚至可与从大型真实数据集转移学习（transfer learning）相媲美，展示了合成数据作为增强提示调优的潜在替代方案。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.10865v1",
      "published_date": "2024-10-08 01:00:02 UTC",
      "updated_date": "2024-10-08 01:00:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:54:40.484990"
    },
    {
      "arxiv_id": "2410.05585v2",
      "title": "Towards Robust Spacecraft Trajectory Optimization via Transformers",
      "title_zh": "翻译失败",
      "authors": [
        "Yuji Takubo",
        "Tommaso Guffanti",
        "Daniele Gammelli",
        "Marco Pavone",
        "Simone D'Amico"
      ],
      "abstract": "Future multi-spacecraft missions require robust autonomous trajectory\noptimization capabilities to ensure safe and efficient rendezvous operations.\nThis capability hinges on solving non-convex optimal control problems in\nreal-time, although traditional iterative methods such as sequential convex\nprogramming impose significant computational challenges. To mitigate this\nburden, the Autonomous Rendezvous Transformer (ART) introduced a generative\nmodel trained to provide near-optimal initial guesses. This approach provides\nconvergence to better local optima (e.g., fuel optimality), improves\nfeasibility rates, and results in faster convergence speed of optimization\nalgorithms through warm-starting. This work extends the capabilities of ART to\naddress robust chance-constrained optimal control problems. Specifically, ART\nis applied to challenging rendezvous scenarios in Low Earth Orbit (LEO),\nensuring fault-tolerant behavior under uncertainty. Through extensive\nexperimentation, the proposed warm-starting strategy is shown to consistently\nproduce high-quality reference trajectories, achieving up to 30\\% cost\nimprovement and 50\\% reduction in infeasible cases compared to conventional\nmethods, demonstrating robust performance across multiple state\nrepresentations. Additionally, a post hoc evaluation framework is proposed to\nassess the quality of generated trajectories and mitigate runtime failures,\nmarking an initial step toward the reliable deployment of AI-driven solutions\nin safety-critical autonomous systems such as spacecraft.",
      "tldr_zh": "本文提出了一种基于 Transformers 的 Autonomous Rendezvous Transformer (ART) 方法，用于提升航天器轨迹优化的鲁棒性，针对多航天器任务中的非凸最优控制问题，通过提供高质量初始猜测来加速收敛、改善燃料最优性和降低不可行率。ART 被扩展到处理机遇约束问题，在低地球轨道 (LEO) 的挑战性交会场景下，确保在不确定性中的容错性能，实验显示成本改善高达30%，不可行案例减少50%。此外，作者引入了一个事后评估框架，以评估生成的轨迹质量并缓解运行时失败，推动AI驱动解决方案在安全关键系统中的可靠应用。",
      "categories": [
        "math.OC",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "math.OC",
      "comment": "Submitted to the IEEE Aerospace Conference 2025. 13 pages, 10 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.05585v2",
      "published_date": "2024-10-08 00:58:42 UTC",
      "updated_date": "2025-01-25 03:16:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:54:52.836009"
    },
    {
      "arxiv_id": "2410.05584v5",
      "title": "Rethinking Reward Model Evaluation: Are We Barking up the Wrong Tree?",
      "title_zh": "翻译失败",
      "authors": [
        "Xueru Wen",
        "Jie Lou",
        "Yaojie Lu",
        "Hongyu Lin",
        "Xing Yu",
        "Xinyu Lu",
        "Ben He",
        "Xianpei Han",
        "Debing Zhang",
        "Le Sun"
      ],
      "abstract": "Reward Models (RMs) are crucial for aligning language models with human\npreferences. Currently, the evaluation of RMs depends on measuring accuracy\nagainst a validation set of manually annotated preference data. Although this\nmethod is straightforward and widely adopted, the relationship between RM\naccuracy and downstream policy performance remains under-explored. In this\nwork, we conduct experiments in a synthetic setting to investigate how\ndifferences in RM measured by accuracy translate into gaps in optimized policy\nperformance. Our findings reveal that while there is a weak positive\ncorrelation between accuracy and downstream performance, policies optimized\ntowards RMs with similar accuracy can exhibit quite different performance.\nMoreover, we discover that the way of measuring accuracy significantly impacts\nits ability to predict the final policy performance. Through the lens of the\nRegressional Goodhart effect, we recognize that accuracy, when used for\nmeasuring RM quality, can fail to fully capture the potential RM\noveroptimization. This underscores the inadequacy of relying solely on accuracy\nto reflect their impact on policy optimization.",
      "tldr_zh": "本论文质疑了当前Reward Models (RMs) 评估方法的可靠性，即仅依赖验证集准确率来衡量RMs 与人类偏好对齐的效果。作者通过合成实验环境，探究RMs 准确率差异如何影响下游策略优化的性能，发现准确率与策略性能仅存在弱正相关，且准确率相似的RMs 可能导致显著不同的优化结果。此外，测量准确率的方式会显著影响其预测能力，并通过Regressional Goodhart effect 揭示了准确率无法完全捕捉RMs 的潜在过优化问题，强调需要更全面的评估框架。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at ICLR2025 Spotlight",
      "pdf_url": "http://arxiv.org/pdf/2410.05584v5",
      "published_date": "2024-10-08 00:52:03 UTC",
      "updated_date": "2025-02-14 01:21:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:55:08.072922"
    },
    {
      "arxiv_id": "2410.05583v1",
      "title": "NegMerge: Consensual Weight Negation for Strong Machine Unlearning",
      "title_zh": "翻译失败",
      "authors": [
        "Hyoseo Kim",
        "Dongyoon Han",
        "Junsuk Choe"
      ],
      "abstract": "Machine unlearning aims to selectively remove specific knowledge from a\nmodel. Current methods, such as task arithmetic, rely on fine-tuning models on\nthe forget set, generating a task vector, and subtracting it from the original\nmodel. However, we argue the effectiveness of this approach is highly sensitive\nto hyperparameter selection, necessitating careful validation to identify the\nbest model among many fine-tuned candidates. In this paper, we propose a novel\nmethod that leverages all given fine-tuned models rather than selecting a\nsingle one. By constructing task vectors from models trained with varied\nhyperparameters and merging only the components of the task vectors with\nconsistent signs, we perform unlearning by negating the merged task vector from\nthe original model. Given that existing methods also utilize multiple\nfine-tuned models, our approach delivers more effective unlearning without\nincurring additional computational costs. We demonstrate the effectiveness of\nour method on both vision-language models and standard image classification\nmodels, showing improved unlearning performance with minimal degradation on the\nretain set, outperforming state-of-the-art techniques.",
      "tldr_zh": "论文提出NegMerge，一种创新的机器遗忘(Machine Unlearning)方法，通过从多个使用不同超参数微调的模型中构建任务向量，并仅合并符号一致的组件，然后从原模型中否定该合并向量，实现更有效的知识移除。相比传统方法如任务算术(Task Arithmetic)，NegMerge避免了单一模型选择的敏感性问题，且不增加额外计算成本。实验结果显示，该方法在视觉语言模型和标准图像分类模型上显著提升了遗忘性能，同时对保留集(Retain Set)的退化影响最小，超过了现有最先进技术。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.05583v1",
      "published_date": "2024-10-08 00:50:54 UTC",
      "updated_date": "2024-10-08 00:50:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:55:16.652039"
    },
    {
      "arxiv_id": "2410.05581v2",
      "title": "Adaptation Odyssey in LLMs: Why Does Additional Pretraining Sometimes Fail to Improve?",
      "title_zh": "翻译失败",
      "authors": [
        "Fırat Öncel",
        "Matthias Bethge",
        "Beyza Ermis",
        "Mirco Ravanelli",
        "Cem Subakan",
        "Çağatay Yıldız"
      ],
      "abstract": "In the last decade, the generalization and adaptation abilities of deep\nlearning models were typically evaluated on fixed training and test\ndistributions. Contrary to traditional deep learning, large language models\n(LLMs) are (i) even more overparameterized, (ii) trained on unlabeled text\ncorpora curated from the Internet with minimal human intervention, and (iii)\ntrained in an online fashion. These stark contrasts prevent researchers from\ntransferring lessons learned on model generalization and adaptation in deep\nlearning contexts to LLMs. To this end, our short paper introduces empirical\nobservations that aim to shed light on further training of already pretrained\nlanguage models. Specifically, we demonstrate that training a model on a text\ndomain could degrade its perplexity on the test portion of the same domain. We\nobserve with our subsequent analysis that the performance degradation is\npositively correlated with the similarity between the additional and the\noriginal pretraining dataset of the LLM. Our further token-level perplexity\nobservations reveals that the perplexity degradation is due to a handful of\ntokens that are not informative about the domain. We hope these findings will\nguide us in determining when to adapt a model vs when to rely on its\nfoundational capabilities.",
      "tldr_zh": "这篇论文探讨了大型语言模型(LLMs)进行额外预训练时，为什么有时会降低性能，而不是改善。研究者通过实证观察发现，当额外训练数据集与原始预训练数据集相似时，模型在同一领域的测试困惑度(perplexity)可能会下降，且这种下降与数据集相似性正相关。进一步的token-level分析表明，性能退化主要由少数不具信息性的tokens引起。这些发现为指导LLMs的适应策略提供了参考，帮助决定何时进行额外训练，何时依赖模型的基础能力。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to EMNLP 2024 Main Conference",
      "pdf_url": "http://arxiv.org/pdf/2410.05581v2",
      "published_date": "2024-10-08 00:37:16 UTC",
      "updated_date": "2024-10-16 07:07:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:55:28.891916"
    },
    {
      "arxiv_id": "2410.05578v1",
      "title": "Swift Sampler: Efficient Learning of Sampler by 10 Parameters",
      "title_zh": "翻译失败",
      "authors": [
        "Jiawei Yao",
        "Chuming Li",
        "Canran Xiao"
      ],
      "abstract": "Data selection is essential for training deep learning models. An effective\ndata sampler assigns proper sampling probability for training data and helps\nthe model converge to a good local minimum with high performance. Previous\nstudies in data sampling are mainly based on heuristic rules or learning\nthrough a huge amount of time-consuming trials. In this paper, we propose an\nautomatic \\textbf{swift sampler} search algorithm, \\textbf{SS}, to explore\nautomatically learning effective samplers efficiently. In particular,\n\\textbf{SS} utilizes a novel formulation to map a sampler to a low dimension of\nhyper-parameters and uses an approximated local minimum to quickly examine the\nquality of a sampler. Benefiting from its low computational expense,\n\\textbf{SS} can be applied on large-scale data sets with high efficiency.\nComprehensive experiments on various tasks demonstrate that \\textbf{SS} powered\nsampling can achieve obvious improvements (e.g., 1.5\\% on ImageNet) and\ntransfer among different neural networks. Project page:\nhttps://github.com/Alexander-Yao/Swift-Sampler.",
      "tldr_zh": "该论文提出了一种高效的自动采样器学习算法Swift Sampler (SS)，旨在通过仅10个参数将采样器映射到低维超参数空间，并使用近似的局部最小值快速评估其质量，从而解决传统数据采样依赖启发式规则或耗时试验的局限性。SS算法计算开销低，能高效应用于大规模数据集，并在各种深度学习任务中显著提升模型性能，例如在ImageNet上提高1.5%的准确率。该方法还展示了在不同神经网络之间良好的转移能力，为数据选择策略提供了自动化的新途径。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by NeurIPS 2024. Project page:\n  https://github.com/Alexander-Yao/Swift-Sampler",
      "pdf_url": "http://arxiv.org/pdf/2410.05578v1",
      "published_date": "2024-10-08 00:26:29 UTC",
      "updated_date": "2024-10-08 00:26:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:55:40.064769"
    },
    {
      "arxiv_id": "2410.05575v2",
      "title": "ClaimBrush: A Novel Framework for Automated Patent Claim Refinement Based on Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Seiya Kawano",
        "Hirofumi Nonaka",
        "Koichiro Yoshino"
      ],
      "abstract": "Automatic refinement of patent claims in patent applications is crucial from\nthe perspective of intellectual property strategy. In this paper, we propose\nClaimBrush, a novel framework for automated patent claim refinement that\nincludes a dataset and a rewriting model. We constructed a dataset for training\nand evaluating patent claim rewriting models by collecting a large number of\nactual patent claim rewriting cases from the patent examination process. Using\nthe constructed dataset, we built an automatic patent claim rewriting model by\nfine-tuning a large language model. Furthermore, we enhanced the performance of\nthe automatic patent claim rewriting model by applying preference optimization\nbased on a prediction model of patent examiners' Office Actions. The\nexperimental results showed that our proposed rewriting model outperformed\nheuristic baselines and zero-shot learning in state-of-the-art large language\nmodels. Moreover, preference optimization based on patent examiners'\npreferences boosted the performance of patent claim refinement.",
      "tldr_zh": "该研究提出了ClaimBrush框架，一种基于Large Language Models的自动专利声明精炼系统，包括一个数据集和重写模型，以优化知识产权策略。\n他们通过收集专利审查过程中的实际案例构建了数据集，并通过微调Large Language Models来训练重写模型，同时应用基于专利审查官Office Actions的偏好优化来提升模型性能。\n实验结果表明，ClaimBrush框架在专利声明精炼任务中优于启发式基线和零样本学习方法，而偏好优化进一步显著提高了整体效能。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "10 pages, This work has been submitted to the IEEE for possible\n  publication",
      "pdf_url": "http://arxiv.org/pdf/2410.05575v2",
      "published_date": "2024-10-08 00:20:54 UTC",
      "updated_date": "2024-10-10 05:45:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:55:52.173858"
    },
    {
      "arxiv_id": "2410.05573v2",
      "title": "TaeBench: Improving Quality of Toxic Adversarial Examples",
      "title_zh": "翻译失败",
      "authors": [
        "Xuan Zhu",
        "Dmitriy Bespalov",
        "Liwen You",
        "Ninad Kulkarni",
        "Yanjun Qi"
      ],
      "abstract": "Toxicity text detectors can be vulnerable to adversarial examples - small\nperturbations to input text that fool the systems into wrong detection.\nExisting attack algorithms are time-consuming and often produce invalid or\nambiguous adversarial examples, making them less useful for evaluating or\nimproving real-world toxicity content moderators. This paper proposes an\nannotation pipeline for quality control of generated toxic adversarial examples\n(TAE). We design model-based automated annotation and human-based quality\nverification to assess the quality requirements of TAE. Successful TAE should\nfool a target toxicity model into making benign predictions, be grammatically\nreasonable, appear natural like human-generated text, and exhibit semantic\ntoxicity. When applying these requirements to more than 20 state-of-the-art\n(SOTA) TAE attack recipes, we find many invalid samples from a total of 940k\nraw TAE attack generations. We then utilize the proposed pipeline to filter and\ncurate a high-quality TAE dataset we call TaeBench (of size 264k). Empirically,\nwe demonstrate that TaeBench can effectively transfer-attack SOTA toxicity\ncontent moderation models and services. Our experiments also show that TaeBench\nwith adversarial training achieve significant improvements of the robustness of\ntwo toxicity detectors.",
      "tldr_zh": "该论文针对现有毒性文本检测器的漏洞，提出了一种注解管道(annotation pipeline)，通过模型自动注解和人工质量验证来改进毒性对抗样本(TAE)的质量，确保TAE能欺骗目标模型、语法合理、自然如人类文本且保持语义毒性。作者应用此管道对20多种SOTA TAE攻击方法生成的94万原始样本进行过滤，筛选出高质量数据集TaeBench（大小26.4万）。实验结果显示，TaeBench能有效转移攻击SOTA毒性内容审查模型和服务，并通过对抗训练(adversarial training)显著提升两个毒性检测器的鲁棒性。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "Accepted for publication in NAACL 2025. The official version will be\n  available in the ACL Anthology",
      "pdf_url": "http://arxiv.org/pdf/2410.05573v2",
      "published_date": "2024-10-08 00:14:27 UTC",
      "updated_date": "2025-05-01 02:59:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:56:05.566807"
    },
    {
      "arxiv_id": "2410.05572v1",
      "title": "Improved deep learning of chaotic dynamical systems with multistep penalty losses",
      "title_zh": "通过多步惩罚损失改进的混沌动力系统深度学习",
      "authors": [
        "Dibyajyoti Chakraborty",
        "Seung Whan Chung",
        "Ashesh Chattopadhyay",
        "Romit Maulik"
      ],
      "abstract": "Predicting the long-term behavior of chaotic systems remains a formidable\nchallenge due to their extreme sensitivity to initial conditions and the\ninherent limitations of traditional data-driven modeling approaches. This paper\nintroduces a novel framework that addresses these challenges by leveraging the\nrecently proposed multi-step penalty (MP) optimization technique. Our approach\nextends the applicability of MP optimization to a wide range of deep learning\narchitectures, including Fourier Neural Operators and UNETs. By introducing\npenalized local discontinuities in the forecast trajectory, we effectively\nhandle the non-convexity of loss landscapes commonly encountered in training\nneural networks for chaotic systems. We demonstrate the effectiveness of our\nmethod through its application to two challenging use-cases: the prediction of\nflow velocity evolution in two-dimensional turbulence and ocean dynamics using\nreanalysis data. Our results highlight the potential of this approach for\naccurate and stable long-term prediction of chaotic dynamics, paving the way\nfor new advancements in data-driven modeling of complex natural phenomena.",
      "tldr_zh": "这篇论文提出了一种新框架，使用multi-step penalty (MP)优化技术来改善深度学习在混沌动力系统中的预测性能，解决了系统对初始条件高度敏感的问题。该方法扩展到Fourier Neural Operators和UNETs等架构，通过引入惩罚局部不连续性来处理损失景观的非凸性，从而提升预测的准确性和稳定性。在二维湍流流动速度演化和海洋动力学再分析数据的实际应用中，该框架实现了可靠的长期预测，为复杂自然现象的数据驱动建模开辟了新途径。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "math.DS"
      ],
      "primary_category": "cs.LG",
      "comment": "7 pages, 5 Figures, Submitted to CASML2024",
      "pdf_url": "http://arxiv.org/pdf/2410.05572v1",
      "published_date": "2024-10-08 00:13:57 UTC",
      "updated_date": "2024-10-08 00:13:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:56:16.142180"
    },
    {
      "arxiv_id": "2410.17275v1",
      "title": "Automated Quality Control System for Canned Tuna Production using Artificial Vision",
      "title_zh": "翻译失败",
      "authors": [
        "Sendey Vera",
        "Luis Chuquimarca",
        "Wilson Galdea",
        "Bremnen Véliz",
        "Carlos Saldaña"
      ],
      "abstract": "This scientific article presents the implementation of an automated control\nsystem for detecting and classifying faults in tuna metal cans using artificial\nvision. The system utilizes a conveyor belt and a camera for visual recognition\ntriggered by a photoelectric sensor. A robotic arm classifies the metal cans\naccording to their condition. Industry 4.0 integration is achieved through an\nIoT system using Mosquitto, Node-RED, InfluxDB, and Grafana. The YOLOv5 model\nis employed to detect faults in the metal can lids and the positioning of the\neasy-open ring. Training with GPU on Google Colab enables OCR text detection on\nthe labels. The results indicate efficient real-time problem identification,\noptimization of resources, and delivery of quality products. At the same time,\nthe vision system contributes to autonomy in quality control tasks, freeing\noperators to perform other functions within the company.",
      "tldr_zh": "这篇论文介绍了基于人工视觉的自动化质量控制系统，用于检测和分类金枪鱼金属罐的生产故障。系统利用传送带、相机、光电传感器和机械臂进行视觉识别，并整合YOLOv5模型来检测金属罐盖缺陷和易开环位置，同时通过OCR技术处理标签文本，并采用IoT系统（包括Mosquitto、Node-RED、InfluxDB和Grafana）实现Industry 4.0兼容。实验结果表明，该系统实现了实时问题识别、资源优化和产品质量提升，同时解放了操作员，使其专注于其他任务。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "cs.RO",
        "eess.IV",
        "68Txx, 65D19",
        "B.7; I.2; I.4"
      ],
      "primary_category": "cs.CV",
      "comment": "6 pages, 12 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.17275v1",
      "published_date": "2024-10-08 00:11:24 UTC",
      "updated_date": "2024-10-08 00:11:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:56:28.143573"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 169,
  "processed_papers_count": 169,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-20T08:56:47.990981"
}