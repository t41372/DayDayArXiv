{
  "date": "2024-07-09",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-07-09 的 arXiv 中文 TLDR 快报！今天 arXiv 的论文主要聚焦 AI 和机器学习领域，包括大语言模型（LLM）的鲁棒性改进、医疗 AI 的应用、机器人学习以及多模态数据处理等热门话题，其中令人印象深刻的文章有 FBI-LLM（提出全二值化 LLM 训练方法）和 Self-Recognition in Language Models（探讨 LLM 的自识别能力），并涉及知名学者如 Guy Katz 和 Luke Zettlemoyer 的工作。\n\n下面，我将挑选并简要讨论部分关键论文，先优先聊重要、话题度高的文章（如 LLM 相关和实际应用），并将相关主题归类。篇幅有限，我会快速掠过较无聊或次要的论文（如一些纯理论或小众领域），并为每篇列出标题（中文 + 英文），突出核心贡献和发现。\n\n### LLM 和 AI 模型创新\n- **FBI-LLM: Scaling Up Fully Binarized LLMs from Scratch via Autoregressive Distillation**（中文：通过自回归蒸馏从零扩展全二值化大语言模型；英文：FBI-LLM）  \n  这篇论文提出一种从零训练全二值化 LLM 的方法，使用自回归蒸馏技术，保持模型尺寸不变（130M、1.3B、7B 参数），在困惑度和任务性能上与 FP16 模型相当，显著降低了计算资源需求，是 LLM 高效部署的重大进展。\n  \n- **Self-Recognition in Language Models**（中文：大语言模型的自识别；英文：Self-Recognition in Language Models）  \n  作者包括 Robert West 和 Caglar Gulcehre，该研究发现 LLM 在二选一场景中偏好自身生成的文本，揭示了潜在的反人类偏差，并通过实验验证了 LLM 的 sycophantic 行为（即讨好式响应），为 AI 伦理和偏差检测提供新洞见。\n\n- **Lookback Lens: Detecting and Mitigating Contextual Hallucinations in Large Language Models Using Only Attention Maps**（中文：通过注意力图检测和缓解 LLM 的上下文幻觉；英文：Lookback Lens）  \n  论文引入一种基于注意力权重的幻觉检测方法，使用 lookback ratio 特征比传统方法更高效，能跨模型转移（如从 7B 到 13B 参数），并通过分类器引导解码减少幻觉，提升 LLM 在实际应用的可靠性。\n\n- **AnyTaskTune: Advanced Domain-Specific Solutions through Task-Fine-Tuning**（中文：通过任务微调实现高级领域特定解决方案；英文：AnyTaskTune）  \n  这篇工作提出 Task-Fine-Tune 方法，针对法律、金融等领域的子任务创建增强数据集，实现模型在特定任务上的性能提升，并开源了双语数据集，展示了微调 LLM 的实用性。\n\n- **Robust Neural Information Retrieval: An Adversarial and Out-of-distribution Perspective**（中文：鲁棒神经信息检索：对抗和分布外视角；英文：Robust Neural Information Retrieval）  \n  论文综述了信息检索模型在对抗攻击和分布外场景下的鲁棒性问题，提出新基准 BestIR，并讨论了 LLM 时代的挑战，为构建可靠的检索系统提供框架。\n\n### 医疗和生物应用\n- **Lifestyle-Informed Personalized Blood Biomarker Prediction via Novel Representation Learning**（中文：通过生活方式数据的新型表示学习进行个性化血生物标记预测；英文：Lifestyle-Informed Personalized Blood Biomarker Prediction）  \n  作者包括 Shwetak N. Patel，该研究使用 UK Biobank 数据（25.7万参与者）开发框架，通过相似性嵌入预测血生物标记，支持个性化医疗，可能带来更早的疾病检测和干预策略。\n\n- **Using Galaxy Evolution as Source of Physics-Based Ground Truth for Generative Models**（中文：利用星系演化作为生成模型的物理基础真实数据；英文：Using Galaxy Evolution as Source of Physics-Based Ground Truth）  \n  论文构建条件扩散模型和变分自编码器，测试生成星系图像的物理准确性，使用基于星系演化的指标评估模型，DDPM 模型在多数指标上优于 CVAE，促进天文学中的生成 AI。\n\n- **ProtoSAM: One-Shot Medical Image Segmentation With Foundational Models**（中文：基于基础模型的单样本医疗图像分割；英文：ProtoSAM）  \n  这篇工作结合原型网络和 SAM 模型，实现单样本医疗图像分割，显著提高分割精度，并开源代码和数据集，为无标注数据下的医疗 AI 提供高效工具。\n\n- **TCKAN: A Novel Integrated Network Model for Predicting Mortality Risk in Sepsis Patients**（中文：用于预测脓毒症患者死亡风险的新型集成网络模型；英文：TCKAN）  \n  论文提出 TCKAN 模型，融合时序数据、常量数据和 ICD 代码，预测脓毒症风险，在 MIMIC-III 和 IV 数据集上优于现有方法，提升了临床决策的准确性。\n\n### 机器人和自动驾驶\n- **Exploring Camera Encoder Designs for Autonomous Driving Perception**（中文：探索自动驾驶感知中的相机编码器设计；英文：Exploring Camera Encoder Designs）  \n  作者包括 Jose M. Alvarez，该研究基于 ConvNeXt 优化相机编码器设计，针对自动驾驶数据集改进宽度、深度和注意力机制，实现 8.79% mAP 提升，提供 AV 专用架构指南。\n\n- **Quality Diversity for Robot Learning: Limitations and Future Directions**（中文：机器人学习的质量多样性：局限性和未来方向；英文：Quality Diversity for Robot Learning）  \n  论文分析质量多样性算法在机器人技能学习中的局限，提出使用目标条件策略和认知地图灵感的方法，提升泛化性和开放搜索能力，Accepted to GECCO 2024。\n\n- **DiffPhyCon: A Generative Approach to Control Complex Physical Systems**（中文：用于控制复杂物理系统的生成方法；英文：DiffPhyCon）  \n  这篇工作引入扩散模型控制物理系统，如流体动力学，通过最小化能量函数优化轨迹，在水母运动和烟雾控制任务上超越传统方法，展示了生成 AI 在机器人控制的应用潜力。\n\n### 其他领域快速掠过\n- **Exploring Scalability of Self-Training for Open-Vocabulary Temporal Action Localization**（中文：探索自训练在开放词汇时间动作定位中的可扩展性；英文：Exploring Scalability of Self-Training）  \n  论文使用自训练扩展视频动作定位模型，在 YouTube 数据上提升泛化性能，但细节较常规，贡献在于大规模无监督训练。\n\n- **ConceptExpress: Harnessing Diffusion Models for Single-image Unsupervised Concept Extraction**（中文：利用扩散模型进行单图像无监督概念提取；英文：ConceptExpress）  \n  快速提及：提出无监督概念提取框架，使用扩散模型定位和优化概念，适用于图像处理，但整体创新性中等。\n\n- **STORYSUMM: Evaluating Faithfulness in Story Summarization**（中文：评估故事总结的忠实度；英文：STORYSUMM）  \n  构建新数据集评估摘要忠实度，强调人类评估的必要性，但作为基准数据集，影响力有限。\n\n今天 arXiv 的论文展示了 AI 领域的多样创新，特别是 LLM 的鲁棒性和医疗应用的潜力，但许多工作仍需在实际部署中验证。更多细节可查阅具体论文，欢迎明天继续关注！",
  "papers": [
    {
      "arxiv_id": "2407.07277v1",
      "title": "Lifestyle-Informed Personalized Blood Biomarker Prediction via Novel Representation Learning",
      "title_zh": "基于生活方式指导的个性化血液生物标志物预测：通过新型表示学习",
      "authors": [
        "A. Ali Heydari",
        "Naghmeh Rezaei",
        "Javier L. Prieto",
        "Shwetak N. Patel",
        "Ahmed A. Metwally"
      ],
      "abstract": "Blood biomarkers are an essential tool for healthcare providers to diagnose,\nmonitor, and treat a wide range of medical conditions. Current reference values\nand recommended ranges often rely on population-level statistics, which may not\nadequately account for the influence of inter-individual variability driven by\nfactors such as lifestyle and genetics. In this work, we introduce a novel\nframework for predicting future blood biomarker values and define personalized\nreferences through learned representations from lifestyle data (physical\nactivity and sleep) and blood biomarkers. Our proposed method learns a\nsimilarity-based embedding space that captures the complex relationship between\nbiomarkers and lifestyle factors. Using the UK Biobank (257K participants), our\nresults show that our deep-learned embeddings outperform traditional and\ncurrent state-of-the-art representation learning techniques in predicting\nclinical diagnosis. Using a subset of UK Biobank of 6440 participants who have\nfollow-up visits, we validate that the inclusion of these embeddings and\nlifestyle factors directly in blood biomarker models improves the prediction of\nfuture lab values from a single lab visit. This personalized modeling approach\nprovides a foundation for developing more accurate risk stratification tools\nand tailoring preventative care strategies. In clinical settings, this\ntranslates to the potential for earlier disease detection, more timely\ninterventions, and ultimately, a shift towards personalized healthcare.",
      "tldr_zh": "本文提出一种新框架，通过从生活方式数据（如身体活动和睡眠）学习表示（representation learning），来预测个性化的血液生物标志物（blood biomarkers）值，并定义个性化参考范围，以解决传统基于总体统计的局限性。该方法构建了一个基于相似性的嵌入空间，捕捉生物标志物与生活方式因素的复杂关系，使用 UK Biobank 数据集（257K 参与者）进行验证，结果显示其在预测临床诊断和未来实验室值方面优于传统和最先进技术。在 6440 名有随访参与者的子集中，加入这些嵌入和生活方式因素显著提高了预测准确性，为开发更精确的风险分层工具和个性化预防护理策略奠定基础。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.07277v1",
      "published_date": "2024-07-09 23:52:53 UTC",
      "updated_date": "2024-07-09 23:52:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:49:39.925118"
    },
    {
      "arxiv_id": "2407.07276v1",
      "title": "Exploring Camera Encoder Designs for Autonomous Driving Perception",
      "title_zh": "翻译失败",
      "authors": [
        "Barath Lakshmanan",
        "Joshua Chen",
        "Shiyi Lan",
        "Maying Shen",
        "Zhiding Yu",
        "Jose M. Alvarez"
      ],
      "abstract": "The cornerstone of autonomous vehicles (AV) is a solid perception system,\nwhere camera encoders play a crucial role. Existing works usually leverage\npre-trained Convolutional Neural Networks (CNN) or Vision Transformers (ViTs)\ndesigned for general vision tasks, such as image classification, segmentation,\nand 2D detection. Although those well-known architectures have achieved\nstate-of-the-art accuracy in AV-related tasks, e.g., 3D Object Detection, there\nremains significant potential for improvement in network design due to the\nnuanced complexities of industrial-level AV dataset. Moreover, existing public\nAV benchmarks usually contain insufficient data, which might lead to inaccurate\nevaluation of those architectures.To reveal the AV-specific model insights, we\nstart from a standard general-purpose encoder, ConvNeXt and progressively\ntransform the design. We adjust different design parameters including width and\ndepth of the model, stage compute ratio, attention mechanisms, and input\nresolution, supported by systematic analysis to each modifications. This\ncustomization yields an architecture optimized for AV camera encoder achieving\n8.79% mAP improvement over the baseline. We believe our effort could become a\nsweet cookbook of image encoders for AV and pave the way to the next-level\ndrive system.",
      "tldr_zh": "该研究探讨了针对自动驾驶感知系统的相机编码器设计，指出现有基于预训练的 CNN 或 ViTs 模型虽在一般视觉任务中表现出色，但未充分适应工业级 AV 数据集的复杂性，且公共基准数据不足导致评估偏差。作者从 ConvNeXt 基线出发，通过系统调整模型宽度、深度、阶段计算比例、注意力机制和输入分辨率等参数，实现了针对 AV 任务的优化设计。实验结果显示，该定制架构在性能上比基线提升了 8.79% 的 mAP，为自动驾驶图像编码器设计提供了一个实用指南，并推动更高级别驾驶系统的发展。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.07276v1",
      "published_date": "2024-07-09 23:44:58 UTC",
      "updated_date": "2024-07-09 23:44:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:49:51.064694"
    },
    {
      "arxiv_id": "2407.17515v1",
      "title": "Quality Diversity for Robot Learning: Limitations and Future Directions",
      "title_zh": "机器人学习中的质量多样性：局限性与未来方向",
      "authors": [
        "Sumeet Batra",
        "Bryon Tjanaka",
        "Stefanos Nikolaidis",
        "Gaurav Sukhatme"
      ],
      "abstract": "Quality Diversity (QD) has shown great success in discovering\nhigh-performing, diverse policies for robot skill learning. While current\nbenchmarks have led to the development of powerful QD methods, we argue that\nnew paradigms must be developed to facilitate open-ended search and\ngeneralizability. In particular, many methods focus on learning diverse agents\nthat each move to a different xy position in MAP-Elites-style bounded archives.\nHere, we show that such tasks can be accomplished with a single,\ngoal-conditioned policy paired with a classical planner, achieving O(1) space\ncomplexity w.r.t. the number of policies and generalization to task variants.\nWe hypothesize that this approach is successful because it extracts\ntask-invariant structural knowledge by modeling a relational graph between\nadjacent cells in the archive. We motivate this view with emerging evidence\nfrom computational neuroscience and explore connections between QD and models\nof cognitive maps in human and other animal brains. We conclude with a\ndiscussion exploring the relationships between QD and cognitive maps, and\npropose future research directions inspired by cognitive maps towards future\ngeneralizable algorithms capable of truly open-ended search.",
      "tldr_zh": "该论文讨论了 Quality Diversity (QD) 在机器人学习中的成功及其局限性，指出当前 QD 方法（如 MAP-Elites 风格的边界存档）在促进开放式搜索和泛化方面存在不足。作者提出一种新方法，使用单一目标条件策略结合经典规划器来实现多样策略学习，实现 O(1) 空间复杂度和对任务变体的泛化能力。实验表明，这种方法通过提取任务不变的结构知识（如存档中相邻单元的关系图）来提升效率，并从计算神经科学中汲取灵感，将 QD 与人类和动物大脑的认知地图联系起来。最后，论文探讨 QD 与认知地图的关系，并建议未来研究方向，以开发更具泛化性和真正开放式搜索的算法。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "Accepted to GECCO 2024",
      "pdf_url": "http://arxiv.org/pdf/2407.17515v1",
      "published_date": "2024-07-09 23:29:54 UTC",
      "updated_date": "2024-07-09 23:29:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:50:02.516641"
    },
    {
      "arxiv_id": "2407.07229v1",
      "title": "Using Galaxy Evolution as Source of Physics-Based Ground Truth for Generative Models",
      "title_zh": "利用星系演化作为生成模型的基于物理真实数据来源",
      "authors": [
        "Yun Qi Li",
        "Tuan Do",
        "Evan Jones",
        "Bernie Boscoe",
        "Kevin Alfaro",
        "Zooey Nguyen"
      ],
      "abstract": "Generative models producing images have enormous potential to advance\ndiscoveries across scientific fields and require metrics capable of quantifying\nthe high dimensional output. We propose that astrophysics data, such as galaxy\nimages, can test generative models with additional physics-motivated ground\ntruths in addition to human judgment. For example, galaxies in the Universe\nform and change over billions of years, following physical laws and\nrelationships that are both easy to characterize and difficult to encode in\ngenerative models. We build a conditional denoising diffusion probabilistic\nmodel (DDPM) and a conditional variational autoencoder (CVAE) and test their\nability to generate realistic galaxies conditioned on their redshifts (galaxy\nages). This is one of the first studies to probe these generative models using\nphysically motivated metrics. We find that both models produce comparable\nrealistic galaxies based on human evaluation, but our physics-based metrics are\nbetter able to discern the strengths and weaknesses of the generative models.\nOverall, the DDPM model performs better than the CVAE on the majority of the\nphysics-based metrics. Ultimately, if we can show that generative models can\nlearn the physics of galaxy evolution, they have the potential to unlock new\nastrophysical discoveries.",
      "tldr_zh": "该研究提出使用星系演化作为物理基础的真实数据（ground truth），来评估生成模型的性能，从而补充人类判断的不足。研究构建了条件去噪扩散概率模型（DDPM）和条件变分自动编码器（CVAE），并测试它们基于红移（redshift，即星系年龄）生成真实星系图像。结果显示，两模型在人类评估中相似，但物理指标更能区分优劣，其中DDPM在多数指标上表现更好。最终，这为生成模型学习星系演化的物理规律提供了新途径，有潜力推动天体物理领域的发现。",
      "categories": [
        "astro-ph.IM",
        "cs.AI"
      ],
      "primary_category": "astro-ph.IM",
      "comment": "20 pages, 14 figures, 1 Table, code:\n  https://github.com/astrodatalab/li2024_public, training data:\n  https://zenodo.org/records/11117528",
      "pdf_url": "http://arxiv.org/pdf/2407.07229v1",
      "published_date": "2024-07-09 21:01:08 UTC",
      "updated_date": "2024-07-09 21:01:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:50:15.213889"
    },
    {
      "arxiv_id": "2407.17428v1",
      "title": "Vision Language Model-Empowered Contract Theory for AIGC Task Allocation in Teleoperation",
      "title_zh": "翻译失败",
      "authors": [
        "Zijun Zhan",
        "Yaxian Dong",
        "Yuqing Hu",
        "Shuai Li",
        "Shaohua Cao",
        "Zhu Han"
      ],
      "abstract": "Integrating low-light image enhancement techniques, in which diffusion-based\nAI-generated content (AIGC) models are promising, is necessary to enhance\nnighttime teleoperation. Remarkably, the AIGC model is computation-intensive,\nthus necessitating the allocation of AIGC tasks to edge servers with ample\ncomputational resources. Given the distinct cost of the AIGC model trained with\nvarying-sized datasets and AIGC tasks possessing disparate demand, it is\nimperative to formulate a differential pricing strategy to optimize the utility\nof teleoperators and edge servers concurrently. Nonetheless, the pricing\nstrategy formulation is under information asymmetry, i.e., the demand (e.g.,\nthe difficulty level of AIGC tasks and their distribution) of AIGC tasks is\nhidden information to edge servers. Additionally, manually assessing the\ndifficulty level of AIGC tasks is tedious and unnecessary for teleoperators. To\nthis end, we devise a framework of AIGC task allocation assisted by the Vision\nLanguage Model (VLM)-empowered contract theory, which includes two components:\nVLM-empowered difficulty assessment and contract theory-assisted AIGC task\nallocation. The first component enables automatic and accurate AIGC task\ndifficulty assessment. The second component is capable of formulating the\npricing strategy for edge servers under information asymmetry, thereby\noptimizing the utility of both edge servers and teleoperators. The simulation\nresults demonstrated that our proposed framework can improve the average\nutility of teleoperators and edge servers by 10.88~12.43% and 1.4~2.17%,\nrespectively. Code and data are available at\nhttps://github.com/ZiJun0819/VLM-Contract-Theory.",
      "tldr_zh": "这篇论文提出了一种由 Vision Language Model (VLM) 增强的合同理论框架，用于在遥操作中分配 AI-generated content (AIGC) 任务，以提升夜间低光图像增强效果。框架包括两个关键组件：VLM 驱动的自动任务难度评估，以及基于合同理论的定价策略，以在信息不对称条件下优化遥操作者和边缘服务器的效用。模拟结果显示，该框架分别提高了遥操作者和边缘服务器的平均效用 10.88~12.43% 和 1.4~2.17%。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "11 pages, 10 figures",
      "pdf_url": "http://arxiv.org/pdf/2407.17428v1",
      "published_date": "2024-07-09 20:08:26 UTC",
      "updated_date": "2024-07-09 20:08:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:50:27.044796"
    },
    {
      "arxiv_id": "2407.07094v1",
      "title": "AnyTaskTune: Advanced Domain-Specific Solutions through Task-Fine-Tuning",
      "title_zh": "AnyTaskTune：通过任务微调实现高级领域特定解决方案",
      "authors": [
        "Jiaxi Cui",
        "Wentao Zhang",
        "Jing Tang",
        "Xudong Tong",
        "Zhenwei Zhang",
        "Amie",
        "Jing Wen",
        "Rongsheng Wang",
        "Pengfei Wu"
      ],
      "abstract": "The pervasive deployment of Large Language Models-LLMs in various sectors\noften neglects the nuanced requirements of individuals and small organizations,\nwho benefit more from models precisely tailored to their specific business\ncontexts rather than those with broadly superior general capabilities. This\nwork introduces \\textbf{AnyTaskTune}, a novel fine-tuning methodology coined as\n\\textbf{Task-Fine-Tune}, specifically developed to elevate model performance on\na diverse array of domain-specific tasks. This method involves a meticulous\nprocess to identify and define targeted sub-tasks within a domain, followed by\nthe creation of specialized enhancement datasets for fine-tuning, thereby\noptimizing task-specific model performance. We conducted comprehensive\nfine-tuning experiments not only in the legal domain for tasks such as keyword\nextraction and sentence prediction but across over twenty different sub-tasks\nderived from the domains of finance, healthcare, law, psychology, consumer\nservices, and human resources. To substantiate our approach and facilitate\ncommunity engagement, we will open-source these bilingual task datasets. Our\nfindings demonstrate that models fine-tuned using the \\textbf{Task-Fine-Tune}\nmethodology not only achieve superior performance on these specific tasks but\nalso significantly outperform models with higher general capabilities in their\nrespective domains. Our work is publicly available at\n\\url{https://github.com/PandaVT/DataTager}.",
      "tldr_zh": "这篇论文提出 AnyTaskTune 和 Task-Fine-Tune 方法，以解决大型语言模型(LLMs)在特定领域任务上的局限性，专注于为个人和小组织提供定制化的模型优化。Task-Fine-Tune 涉及识别领域子任务、创建专用增强数据集进行细调，从而提升模型在诸如关键词提取和句子预测等任务的表现。实验跨越法律、金融、医疗、心理学、消费服务和人力资源等领域的二十多个子任务，结果表明，使用该方法的模型在特定任务上显著优于具有更高一般能力的模型。该工作还开源了双语数据集，以促进社区进一步研究。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.07094v1",
      "published_date": "2024-07-09 17:59:56 UTC",
      "updated_date": "2024-07-09 17:59:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:50:40.203872"
    },
    {
      "arxiv_id": "2407.07093v1",
      "title": "FBI-LLM: Scaling Up Fully Binarized LLMs from Scratch via Autoregressive Distillation",
      "title_zh": "FBI-LLM：通过自回归蒸馏从头开始扩展完全二值化的大型语言模型",
      "authors": [
        "Liqun Ma",
        "Mingjie Sun",
        "Zhiqiang Shen"
      ],
      "abstract": "This work presents a Fully BInarized Large Language Model (FBI-LLM),\ndemonstrating for the first time how to train a large-scale binary language\nmodel from scratch (not the partial binary or ternary LLM like BitNet b1.58) to\nmatch the performance of its full-precision counterparts (e.g., FP16 or BF16)\nin transformer-based LLMs. It achieves this by employing an autoregressive\ndistillation (AD) loss with maintaining equivalent model dimensions (130M,\n1.3B, 7B) and training data volume as regular LLM pretraining, while delivering\ncompetitive results in terms of perplexity and task-specific effectiveness.\nIntriguingly, by analyzing the training trajectory, we find that the pretrained\nweight is not necessary for training binarized LLMs from scratch. This research\nencourages a new computational framework and may facilitate the future design\nof specialized hardware tailored for fully 1-bit LLMs. We make all models,\ncode, and training dataset fully accessible and transparent to support further\nresearch (Code: https://github.com/LiqunMa/FBI-LLM. Model:\nhttps://huggingface.co/LiqunMa/).",
      "tldr_zh": "本研究引入了 Fully Binarized Large Language Model (FBI-LLM)，这是首次从零训练大规模二进制语言模型，以匹配全精度模型（如 FP16 或 BF16）的性能。研究采用 autoregressive distillation (AD) 损失进行训练，保持模型尺寸（130M、1.3B、7B）和训练数据量与常规 LLM 相同，并在 perplexity 和任务特定效果上表现出竞争性结果。通过分析训练轨迹，发现预训练权重并非必需，这简化了二进制 LLM 的训练过程。该工作推动了新的计算框架发展，并为专属 1-bit LLM 硬件设计提供潜力。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Github at https://github.com/LiqunMa/FBI-LLM",
      "pdf_url": "http://arxiv.org/pdf/2407.07093v1",
      "published_date": "2024-07-09 17:59:48 UTC",
      "updated_date": "2024-07-09 17:59:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:50:50.570191"
    },
    {
      "arxiv_id": "2407.07092v1",
      "title": "V-VIPE: Variational View Invariant Pose Embedding",
      "title_zh": "翻译失败",
      "authors": [
        "Mara Levy",
        "Abhinav Shrivastava"
      ],
      "abstract": "Learning to represent three dimensional (3D) human pose given a two\ndimensional (2D) image of a person, is a challenging problem. In order to make\nthe problem less ambiguous it has become common practice to estimate 3D pose in\nthe camera coordinate space. However, this makes the task of comparing two 3D\nposes difficult. In this paper, we address this challenge by separating the\nproblem of estimating 3D pose from 2D images into two steps. We use a\nvariational autoencoder (VAE) to find an embedding that represents 3D poses in\ncanonical coordinate space. We refer to this embedding as variational\nview-invariant pose embedding V-VIPE. Using V-VIPE we can encode 2D and 3D\nposes and use the embedding for downstream tasks, like retrieval and\nclassification. We can estimate 3D poses from these embeddings using the\ndecoder as well as generate unseen 3D poses. The variability of our encoding\nallows it to generalize well to unseen camera views when mapping from 2D space.\nTo the best of our knowledge, V-VIPE is the only representation to offer this\ndiversity of applications. Code and more information can be found at\nhttps://v-vipe.github.io/.",
      "tldr_zh": "本论文提出了一种变分视图不变姿势嵌入（V-VIPE），旨在解决从2D图像中学习表示3D人体姿势的挑战，通过将问题分解为两个步骤：首先使用变分自编码器（VAE）将3D姿势嵌入到规范坐标空间中，以减少坐标系带来的歧义。V-VIPE可以编码2D和3D姿势，支持下游任务如检索和分类，同时利用解码器估计3D姿势并生成未见过的姿势，其变异性确保了对未知相机视角的良好泛化。该方法是首个提供此类多样应用的姿势表示，为3D姿势处理提供了新颖的框架。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "CVPR 2024 - RHOBIN Workshop",
      "pdf_url": "http://arxiv.org/pdf/2407.07092v1",
      "published_date": "2024-07-09 17:59:47 UTC",
      "updated_date": "2024-07-09 17:59:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:51:02.568860"
    },
    {
      "arxiv_id": "2407.07088v1",
      "title": "Safe and Reliable Training of Learning-Based Aerospace Controllers",
      "title_zh": "翻译失败",
      "authors": [
        "Udayan Mandal",
        "Guy Amir",
        "Haoze Wu",
        "Ieva Daukantas",
        "Fletcher Lee Newell",
        "Umberto Ravaioli",
        "Baoluo Meng",
        "Michael Durling",
        "Kerianne Hobbs",
        "Milan Ganai",
        "Tobey Shim",
        "Guy Katz",
        "Clark Barrett"
      ],
      "abstract": "In recent years, deep reinforcement learning (DRL) approaches have generated\nhighly successful controllers for a myriad of complex domains. However, the\nopaque nature of these models limits their applicability in aerospace systems\nand safety-critical domains, in which a single mistake can have dire\nconsequences. In this paper, we present novel advancements in both the training\nand verification of DRL controllers, which can help ensure their safe behavior.\nWe showcase a design-for-verification approach utilizing k-induction and\ndemonstrate its use in verifying liveness properties. In addition, we also give\na brief overview of neural Lyapunov Barrier certificates and summarize their\ncapabilities on a case study. Finally, we describe several other novel\nreachability-based approaches which, despite failing to provide guarantees of\ninterest, could be effective for verification of other DRL systems, and could\nbe of further interest to the community.",
      "tldr_zh": "该论文探讨了深度强化学习 (DRL) 在航空航天等安全关键领域的应用挑战，强调其不透明性可能导致严重后果，并提出新型训练和验证方法以确保控制器安全可靠。研究引入了基于 k-induction 的设计-for-verification 策略，用于验证 liveness 属性，并概述了神经 Lyapunov Barrier 证书及其在案例研究中的有效性。此外，其他 reachability-based 方法虽未能提供完整保证，但为 DRL 系统验证提供了潜在新途径，增强了社区对可靠控制器的兴趣。",
      "categories": [
        "cs.AI",
        "cs.LO",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.AI",
      "comment": "10 pages, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2407.07088v1",
      "published_date": "2024-07-09 17:58:50 UTC",
      "updated_date": "2024-07-09 17:58:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:51:14.126431"
    },
    {
      "arxiv_id": "2407.07086v2",
      "title": "Hypothetical Minds: Scaffolding Theory of Mind for Multi-Agent Tasks with Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Logan Cross",
        "Violet Xiang",
        "Agam Bhatia",
        "Daniel LK Yamins",
        "Nick Haber"
      ],
      "abstract": "Multi-agent reinforcement learning (MARL) methods struggle with the\nnon-stationarity of multi-agent systems and fail to adaptively learn online\nwhen tested with novel agents. Here, we leverage large language models (LLMs)\nto create an autonomous agent that can handle these challenges. Our agent,\nHypothetical Minds, consists of a cognitively-inspired architecture, featuring\nmodular components for perception, memory, and hierarchical planning over two\nlevels of abstraction. We introduce the Theory of Mind module that scaffolds\nthe high-level planning process by generating hypotheses about other agents'\nstrategies in natural language. It then evaluates and iteratively refines these\nhypotheses by reinforcing hypotheses that make correct predictions about the\nother agents' behavior. Hypothetical Minds significantly improves performance\nover previous LLM-agent and RL baselines on a range of competitive, mixed\nmotive, and collaborative domains in the Melting Pot benchmark, including both\ndyadic and population-based environments. Additionally, comparisons against\nLLM-agent baselines and ablations reveal the importance of hypothesis\nevaluation and refinement for succeeding on complex scenarios.",
      "tldr_zh": "本研究提出Hypothetical Minds，一种利用Large Language Models (LLMs)构建的自治代理，旨在解决Multi-Agent Reinforcement Learning (MARL)中多代理系统的非平稳性和对新代理的在线适应问题。该代理采用认知启发的架构，包括感知、记忆和两级抽象的层次规划，并引入Theory of Mind模块，通过生成自然语言假设来预测其他代理的策略，并通过评估和迭代优化这些假设以强化正确行为。实验结果显示，Hypothetical Minds在Melting Pot基准的竞争、混合动机和协作环境中显著超越了之前的LLM-代理和RL基准，尤其在二元和基于人口的场景中提升了性能。比较分析和消融实验进一步强调了假设评估与优化的关键作用，为复杂多代理任务提供了更有效的解决方案。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.07086v2",
      "published_date": "2024-07-09 17:57:15 UTC",
      "updated_date": "2024-12-12 01:41:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:51:27.789900"
    },
    {
      "arxiv_id": "2407.07082v3",
      "title": "Can Learned Optimization Make Reinforcement Learning Less Difficult?",
      "title_zh": "翻译失败",
      "authors": [
        "Alexander David Goldie",
        "Chris Lu",
        "Matthew Thomas Jackson",
        "Shimon Whiteson",
        "Jakob Nicolaus Foerster"
      ],
      "abstract": "While reinforcement learning (RL) holds great potential for decision making\nin the real world, it suffers from a number of unique difficulties which often\nneed specific consideration. In particular: it is highly non-stationary;\nsuffers from high degrees of plasticity loss; and requires exploration to\nprevent premature convergence to local optima and maximize return. In this\npaper, we consider whether learned optimization can help overcome these\nproblems. Our method, Learned Optimization for Plasticity, Exploration and\nNon-stationarity (OPEN), meta-learns an update rule whose input features and\noutput structure are informed by previously proposed solutions to these\ndifficulties. We show that our parameterization is flexible enough to enable\nmeta-learning in diverse learning contexts, including the ability to use\nstochasticity for exploration. Our experiments demonstrate that when\nmeta-trained on single and small sets of environments, OPEN outperforms or\nequals traditionally used optimizers. Furthermore, OPEN shows strong\ngeneralization characteristics across a range of environments and agent\narchitectures.",
      "tldr_zh": "这篇论文探讨了是否可以通过学习优化来缓解强化学习 (RL) 的难题，包括高度非平稳性、塑料性损失以及探索需求。作者提出了 OPEN（Learned Optimization for Plasticity, Exploration and Non-stationarity）方法，通过元学习 (meta-learning) 设计一个更新规则，其输入特征和输出结构基于先前解决方案，并支持随机性以实现探索。实验结果表明，在单一或小规模环境中，OPEN 优于或等效于传统优化器，并在多种环境和代理架构中显示出强大的泛化能力。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Added Metadata for Neurips 2024",
      "pdf_url": "http://arxiv.org/pdf/2407.07082v3",
      "published_date": "2024-07-09 17:55:23 UTC",
      "updated_date": "2025-04-15 15:07:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:51:40.455154"
    },
    {
      "arxiv_id": "2407.07077v1",
      "title": "ConceptExpress: Harnessing Diffusion Models for Single-image Unsupervised Concept Extraction",
      "title_zh": "ConceptExpress：利用扩散模型进行单图像无监督概念提取",
      "authors": [
        "Shaozhe Hao",
        "Kai Han",
        "Zhengyao Lv",
        "Shihao Zhao",
        "Kwan-Yee K. Wong"
      ],
      "abstract": "While personalized text-to-image generation has enabled the learning of a\nsingle concept from multiple images, a more practical yet challenging scenario\ninvolves learning multiple concepts within a single image. However, existing\nworks tackling this scenario heavily rely on extensive human annotations. In\nthis paper, we introduce a novel task named Unsupervised Concept Extraction\n(UCE) that considers an unsupervised setting without any human knowledge of the\nconcepts. Given an image that contains multiple concepts, the task aims to\nextract and recreate individual concepts solely relying on the existing\nknowledge from pretrained diffusion models. To achieve this, we present\nConceptExpress that tackles UCE by unleashing the inherent capabilities of\npretrained diffusion models in two aspects. Specifically, a concept\nlocalization approach automatically locates and disentangles salient concepts\nby leveraging spatial correspondence from diffusion self-attention; and based\non the lookup association between a concept and a conceptual token, a\nconcept-wise optimization process learns discriminative tokens that represent\neach individual concept. Finally, we establish an evaluation protocol tailored\nfor the UCE task. Extensive experiments demonstrate that ConceptExpress is a\npromising solution to the UCE task. Our code and data are available at:\nhttps://github.com/haoosz/ConceptExpress",
      "tldr_zh": "本论文引入了Unsupervised Concept Extraction (UCE)任务，旨在从单张图像中提取多个概念，而无需任何人工标注，充分利用预训练diffusion models的内在能力。ConceptExpress方法通过concept localization利用diffusion self-attention的spatial correspondence来自动定位和分离显著概念，并采用concept-wise optimization过程基于概念与conceptual token的关联学习区分性token，以重现个体概念。实验结果证明ConceptExpress在UCE任务中表现出色，并提供了代码以支持进一步验证。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "ECCV 2024, Project page: https://haoosz.github.io/ConceptExpress/",
      "pdf_url": "http://arxiv.org/pdf/2407.07077v1",
      "published_date": "2024-07-09 17:50:28 UTC",
      "updated_date": "2024-07-09 17:50:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:51:52.215918"
    },
    {
      "arxiv_id": "2407.07071v2",
      "title": "Lookback Lens: Detecting and Mitigating Contextual Hallucinations in Large Language Models Using Only Attention Maps",
      "title_zh": "Lookback Lens：仅使用注意力图检测和缓解大语言模型中的上下文幻觉",
      "authors": [
        "Yung-Sung Chuang",
        "Linlu Qiu",
        "Cheng-Yu Hsieh",
        "Ranjay Krishna",
        "Yoon Kim",
        "James Glass"
      ],
      "abstract": "When asked to summarize articles or answer questions given a passage, large\nlanguage models (LLMs) can hallucinate details and respond with unsubstantiated\nanswers that are inaccurate with respect to the input context. This paper\ndescribes a simple approach for detecting such contextual hallucinations. We\nhypothesize that contextual hallucinations are related to the extent to which\nan LLM attends to information in the provided context versus its own\ngenerations. Based on this intuition, we propose a simple hallucination\ndetection model whose input features are given by the ratio of attention\nweights on the context versus newly generated tokens (for each attention head).\nWe find that a linear classifier based on these lookback ratio features is as\neffective as a richer detector that utilizes the entire hidden states of an LLM\nor a text-based entailment model. The lookback ratio-based detector -- Lookback\nLens -- is found to transfer across tasks and even models, allowing a detector\nthat is trained on a 7B model to be applied (without retraining) to a larger\n13B model. We further apply this detector to mitigate contextual\nhallucinations, and find that a simple classifier-guided decoding approach is\nable to reduce the amount of hallucination, for example by 9.6% in the XSum\nsummarization task.",
      "tldr_zh": "该论文探讨了大型语言模型（LLMs）在总结文章或回答问题时可能产生的上下文幻觉（contextual hallucinations），即与输入上下文不符的输出。研究提出Lookback Lens，一种简单检测方法，仅使用注意力地图（attention maps）的权重比率（lookback ratio）作为特征，通过线性分类器评估模型对上下文与新生成标记的注意力比例。实验结果显示，该检测器效果与使用完整隐藏状态或文本蕴含模型的 richer 检测器相当，且具有跨任务和模型的转移性，例如在7B模型上训练的检测器可直接应用于13B模型。此外，通过分类器引导解码，该方法能有效缓解幻觉，例如在XSum总结任务中减少9.6%的幻觉输出。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "EMNLP 2024 main conference long paper. The source code is available\n  at https://github.com/voidism/Lookback-Lens",
      "pdf_url": "http://arxiv.org/pdf/2407.07071v2",
      "published_date": "2024-07-09 17:44:34 UTC",
      "updated_date": "2024-10-03 17:26:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:52:05.192436"
    },
    {
      "arxiv_id": "2407.07064v2",
      "title": "Prompting Techniques for Secure Code Generation: A Systematic Investigation",
      "title_zh": "翻译失败",
      "authors": [
        "Catherine Tony",
        "Nicolás E. Díaz Ferreyra",
        "Markus Mutas",
        "Salem Dhiff",
        "Riccardo Scandariato"
      ],
      "abstract": "Large Language Models (LLMs) are gaining momentum in software development\nwith prompt-driven programming enabling developers to create code from natural\nlanguage (NL) instructions. However, studies have questioned their ability to\nproduce secure code and, thereby, the quality of prompt-generated software.\nAlongside, various prompting techniques that carefully tailor prompts have\nemerged to elicit optimal responses from LLMs. Still, the interplay between\nsuch prompting strategies and secure code generation remains under-explored and\ncalls for further investigations. OBJECTIVE: In this study, we investigate the\nimpact of different prompting techniques on the security of code generated from\nNL instructions by LLMs. METHOD: First we perform a systematic literature\nreview to identify the existing prompting techniques that can be used for code\ngeneration tasks. A subset of these techniques are evaluated on GPT-3, GPT-3.5,\nand GPT-4 models for secure code generation. For this, we used an existing\ndataset consisting of 150 NL security-relevant code-generation prompts.\nRESULTS: Our work (i) classifies potential prompting techniques for code\ngeneration (ii) adapts and evaluates a subset of the identified techniques for\nsecure code generation tasks and (iii) observes a reduction in security\nweaknesses across the tested LLMs, especially after using an existing technique\ncalled Recursive Criticism and Improvement (RCI), contributing valuable\ninsights to the ongoing discourse on LLM-generated code security.",
      "tldr_zh": "本研究系统调查了不同提示技术对大型语言模型（LLMs）从自然语言（NL）指令生成安全代码的影响，旨在解决LLMs在代码质量方面的潜在问题。研究者首先通过系统文献综述识别并分类适用于代码生成任务的提示技术，然后在GPT-3、GPT-3.5和GPT-4模型上评估这些技术的子集，使用一个包含150个NL安全相关提示的数据集进行实验。结果显示，采用Recursive Criticism and Improvement（RCI）等技术后，生成的代码安全弱点显著减少，尤其在测试模型中降低了弱点发生率，为提升LLM生成代码的安全性提供了宝贵洞见。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.CR",
        "cs.LG"
      ],
      "primary_category": "cs.SE",
      "comment": "Work partially supported by the EU-funded project Sec4AI4Sec:\n  Cybersecurity for AI-Augmented Systems (grant no. 101120393) - ACCEPTED at\n  ACM Transactions on Software Engineering and Methodology (Feb. 2025)",
      "pdf_url": "http://arxiv.org/pdf/2407.07064v2",
      "published_date": "2024-07-09 17:38:03 UTC",
      "updated_date": "2025-02-26 14:28:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:52:17.877879"
    },
    {
      "arxiv_id": "2407.07046v2",
      "title": "CorMulT: A Semi-supervised Modality Correlation-aware Multimodal Transformer for Sentiment Analysis",
      "title_zh": "翻译失败",
      "authors": [
        "Yangmin Li",
        "Ruiqi Zhu",
        "Wengen Li"
      ],
      "abstract": "Multimodal sentiment analysis is an active research area that combines\nmultiple data modalities, e.g., text, image and audio, to analyze human\nemotions and benefits a variety of applications. Existing multimodal sentiment\nanalysis methods can be classified as modality interaction-based methods,\nmodality transformation-based methods and modality similarity-based methods.\nHowever, most of these methods highly rely on the strong correlations between\nmodalities, and cannot fully uncover and utilize the correlations between\nmodalities to enhance sentiment analysis. Therefore, these methods usually\nachieve bad performance for identifying the sentiment of multimodal data with\nweak correlations. To address this issue, we proposed a two-stage\nsemi-supervised model termed Correlation-aware Multimodal Transformer (CorMulT)\nwhich consists pre-training stage and prediction stage. At the pre-training\nstage, a modality correlation contrastive learning module is designed to\nefficiently learn modality correlation coefficients between different\nmodalities. At the prediction stage, the learned correlation coefficients are\nfused with modality representations to make the sentiment prediction. According\nto the experiments on the popular multimodal dataset CMU-MOSEI, CorMulT\nobviously surpasses state-of-the-art multimodal sentiment analysis methods.",
      "tldr_zh": "该研究针对多模态情感分析（Sentiment Analysis）中的问题，提出了一种半监督（Semi-supervised）模型 CorMulT，该模型关注模态相关性（Modality Correlation-aware），以处理现有方法对模态间弱相关性的不足。CorMulT 采用两阶段设计：在预训练阶段，通过模态相关性对比学习（Contrastive Learning）模块学习不同模态（如文本、图像和音频）之间的相关性系数；在预测阶段，将这些系数与模态表示融合进行情感预测。实验结果显示，在 CMU-MOSEI 数据集上，CorMulT 明显超过了最先进的多模态情感分析方法，证明了其有效性。",
      "categories": [
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.07046v2",
      "published_date": "2024-07-09 17:07:29 UTC",
      "updated_date": "2024-08-29 06:15:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:52:29.310111"
    },
    {
      "arxiv_id": "2407.07045v1",
      "title": "Simple and Interpretable Probabilistic Classifiers for Knowledge Graphs",
      "title_zh": "知识图谱的简单且可解释的概率分类器",
      "authors": [
        "Christian Riefolo",
        "Nicola Fanizzi",
        "Claudia d'Amato"
      ],
      "abstract": "Tackling the problem of learning probabilistic classifiers from incomplete\ndata in the context of Knowledge Graphs expressed in Description Logics, we\ndescribe an inductive approach based on learning simple belief networks.\nSpecifically, we consider a basic probabilistic model, a Naive Bayes\nclassifier, based on multivariate Bernoullis and its extension to a two-tier\nnetwork in which this classification model is connected to a lower layer\nconsisting of a mixture of Bernoullis. We show how such models can be converted\ninto (probabilistic) axioms (or rules) thus ensuring more interpretability.\nMoreover they may be also initialized exploiting expert knowledge. We present\nand discuss the outcomes of an empirical evaluation which aimed at testing the\neffectiveness of the models on a number of random classification problems with\ndifferent ontologies.",
      "tldr_zh": "该论文针对知识图谱（Knowledge Graphs）中从不完整数据学习概率分类器的问题，提出了一种基于简单信念网络（belief networks）的归纳方法。核心模型包括Naive Bayes分类器（基于多元伯努瓦分布）及其扩展，即连接到一个由混合伯努瓦模型（mixture of Bernoullis）组成的两层网络。这种设计允许模型转换为概率公理或规则，从而提升可解释性（interpretability），并可通过专家知识进行初始化。实证评估结果表明，该方法在多种本体（ontologies）上的随机分类问题中表现出有效性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "15 pages, 4 figures, 2 tables peer reviewed / presented at IJCLR\n  2023, 3rd International Joint Conference on Learning & Reasoning\n  https://ijclr2023.di.uniba.it/",
      "pdf_url": "http://arxiv.org/pdf/2407.07045v1",
      "published_date": "2024-07-09 17:05:52 UTC",
      "updated_date": "2024-07-09 17:05:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:52:41.992758"
    },
    {
      "arxiv_id": "2407.07042v2",
      "title": "ProtoSAM: One-Shot Medical Image Segmentation With Foundational Models",
      "title_zh": "翻译失败",
      "authors": [
        "Lev Ayzenberg",
        "Raja Giryes",
        "Hayit Greenspan"
      ],
      "abstract": "This work introduces a new framework, ProtoSAM, for one-shot medical image\nsegmentation. It combines the use of prototypical networks, known for few-shot\nsegmentation, with SAM - a natural image foundation model. The method proposed\ncreates an initial coarse segmentation mask using the ALPnet prototypical\nnetwork, augmented with a DINOv2 encoder. Following the extraction of an\ninitial mask, prompts are extracted, such as points and bounding boxes, which\nare then input into the Segment Anything Model (SAM). State-of-the-art results\nare shown on several medical image datasets and demonstrate automated\nsegmentation capabilities using a single image example (one shot) with no need\nfor fine-tuning of the foundation model. Our code is available at:\nhttps://github.com/levayz/ProtoSAM",
      "tldr_zh": "本研究提出ProtoSAM框架，用于one-shot医疗图像分割，结合prototypical networks和Segment Anything Model (SAM)作为基础模型。方法首先利用ALPnet原型网络（增强DINOv2编码器）生成初始粗略分割掩码，然后提取提示（如点和边界框）输入SAM进行精确细分。该框架在多个医疗图像数据集上实现了最先进的结果，仅需单个图像示例即可自动分割，且无需对基础模型进行fine-tuning。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "12 pages, 3 figures, 4 tables, code:\n  https://github.com/levayz/ProtoSAM",
      "pdf_url": "http://arxiv.org/pdf/2407.07042v2",
      "published_date": "2024-07-09 17:04:08 UTC",
      "updated_date": "2024-07-18 07:58:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:52:51.267088"
    },
    {
      "arxiv_id": "2407.07041v2",
      "title": "Hiding Local Manipulations on SAR Images: a Counter-Forensic Attack",
      "title_zh": "隐藏 SAR 图像上的局部篡改：一种反取证攻击",
      "authors": [
        "Sara Mandelli",
        "Edoardo Daniele Cannas",
        "Paolo Bestagini",
        "Stefano Tebaldini",
        "Stefano Tubaro"
      ],
      "abstract": "The vast accessibility of Synthetic Aperture Radar (SAR) images through\nonline portals has propelled the research across various fields. This\nwidespread use and easy availability have unfortunately made SAR data\nsusceptible to malicious alterations, such as local editing applied to the\nimages for inserting or covering the presence of sensitive targets.\nVulnerability is further emphasized by the fact that most SAR products, despite\ntheir original complex nature, are often released as amplitude-only\ninformation, allowing even inexperienced attackers to edit and easily alter the\npixel content. To contrast malicious manipulations, in the last years the\nforensic community has begun to dig into the SAR manipulation issue, proposing\ndetectors that effectively localize the tampering traces in amplitude images.\nNonetheless, in this paper we demonstrate that an expert practitioner can\nexploit the complex nature of SAR data to obscure any signs of manipulation\nwithin a locally altered amplitude image. We refer to this approach as a\ncounter-forensic attack. To achieve the concealment of manipulation traces, the\nattacker can simulate a re-acquisition of the manipulated scene by the SAR\nsystem that initially generated the pristine image. In doing so, the attacker\ncan obscure any evidence of manipulation, making it appear as if the image was\nlegitimately produced by the system. This attack has unique features that make\nit both highly generalizable and relatively easy to apply. First, it is a\nblack-box attack, meaning it is not designed to deceive a specific forensic\ndetector. Furthermore, it does not require a training phase and is not based on\nadversarial operations. We assess the effectiveness of the proposed\ncounter-forensic approach across diverse scenarios, examining various\nmanipulation operations.",
      "tldr_zh": "本研究探讨了 Synthetic Aperture Radar (SAR) 图像的局部篡改问题，提出了一种 counter-forensic attack 方法，以隐藏恶意编辑痕迹。攻击者利用 SAR 数据的复杂性质，通过模拟原始 SAR 系统对篡改场景的重新获取，使图像看起来像是合法生成的，从而规避取证检测。不同于传统攻击，该方法是黑盒式的、不需要训练阶段，也不依赖对抗操作。实验结果显示，这种攻击在多种操纵场景下高度通用且有效，强调了现有 SAR 图像安全性的潜在漏洞。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.MM"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.07041v2",
      "published_date": "2024-07-09 17:03:57 UTC",
      "updated_date": "2025-03-14 11:31:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:53:13.753693"
    },
    {
      "arxiv_id": "2407.07030v1",
      "title": "Trajectory Data Mining and Trip Travel Time Prediction on Specific Roads",
      "title_zh": "翻译失败",
      "authors": [
        "Muhammad Awais Amin",
        "Jawad-Ur-Rehman Chughtai",
        "Waqar Ahmad",
        "Waqas Haider Bangyal",
        "Irfan Ul Haq"
      ],
      "abstract": "Predicting a trip's travel time is essential for route planning and\nnavigation applications. The majority of research is based on international\ndata that does not apply to Pakistan's road conditions. We designed a complete\npipeline for mining trajectories from sensors data. On this data, we employed\nstate-of-the-art approaches, including a shallow artificial neural network, a\ndeep multi-layered perceptron, and a long-short-term memory, to explore the\nissue of travel time prediction on frequent routes. The experimental results\ndemonstrate an average prediction error ranging from 30 seconds to 1.2 minutes\non trips lasting 10 minutes to 60 minutes on six most frequent routes in\nregions of Islamabad, Pakistan.",
      "tldr_zh": "该研究针对巴基斯坦道路条件，开发了一个完整的轨迹数据挖掘管道，以预测特定路线的行程旅行时间。研究使用了先进模型，包括浅层人工神经网络（shallow artificial neural network）、深度多层感知器（deep multi-layered perceptron）和长短时记忆网络（long-short-term memory），在伊斯兰堡地区六条最频繁路线上进行实验。结果显示，对于10到60分钟的行程，平均预测错误在30秒到1.2分钟之间，这为本地化路线规划和导航应用提供了实用改进。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "N/A",
      "pdf_url": "http://arxiv.org/pdf/2407.07030v1",
      "published_date": "2024-07-09 16:50:15 UTC",
      "updated_date": "2024-07-09 16:50:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:53:15.477967"
    },
    {
      "arxiv_id": "2407.07024v3",
      "title": "Exploring Scalability of Self-Training for Open-Vocabulary Temporal Action Localization",
      "title_zh": "翻译失败",
      "authors": [
        "Jeongseok Hyun",
        "Su Ho Han",
        "Hyolim Kang",
        "Joon-Young Lee",
        "Seon Joo Kim"
      ],
      "abstract": "The vocabulary size in temporal action localization (TAL) is limited by the\nscarcity of large-scale annotated datasets. To overcome this, recent works\nintegrate vision-language models (VLMs), such as CLIP, for open-vocabulary TAL\n(OV-TAL). However, despite the success of VLMs trained on extensive datasets,\nexisting OV-TAL methods still rely on human-labeled TAL datasets of limited\nsize to train action localizers, limiting their generalizability. In this\npaper, we explore the scalability of self-training with unlabeled YouTube\nvideos for OV-TAL. Our approach consists of two stages: (1) a class-agnostic\naction localizer is trained on a human-labeled TAL dataset to generate\npseudo-labels for unlabeled videos, and (2) the large-scale pseudo-labeled\ndataset is then used to train the localizer. Extensive experiments demonstrate\nthat leveraging web-scale videos in self-training significantly enhances the\ngeneralizability of an action localizer. Additionally, we identify limitations\nin existing OV-TAL evaluation schemes and propose a new benchmark for thorough\nassessment. Finally, we showcase the TAL performance of the large multimodal\nmodel Gemini-1.5 on our new benchmark. Code is released at\nhttps://github.com/HYUNJS/STOV-TAL.",
      "tldr_zh": "本研究探讨了自训练(self-training) 在开放词汇时间动作定位(OV-TAL) 中的可扩展性，以解决现有方法依赖有限标注数据集的局限问题。方法包括两阶段：首先，在人类标注的 TAL 数据集上训练一个类无关动作定位器(class-agnostic action localizer)，用于生成无标签 YouTube 视频的伪标签(pseudo-labels)；然后，利用大规模伪标签数据集进一步训练模型。实验结果表明，这种基于网络规模视频的自训练显著提升了动作定位器的泛化性；此外，论文识别了现有 OV-TAL 评估方案的不足，提出新基准，并展示了大型多模态模型 Gemini-1.5 在该基准上的性能。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted to WACV 2025",
      "pdf_url": "http://arxiv.org/pdf/2407.07024v3",
      "published_date": "2024-07-09 16:44:04 UTC",
      "updated_date": "2024-12-19 14:07:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:53:31.512152"
    },
    {
      "arxiv_id": "2407.07020v1",
      "title": "Less is More: Efficient Brain-Inspired Learning for Autonomous Driving Trajectory Prediction",
      "title_zh": "翻译失败",
      "authors": [
        "Haicheng Liao",
        "Yongkang Li",
        "Zhenning Li",
        "Chengyue Wang",
        "Chunlin Tian",
        "Yuming Huang",
        "Zilin Bian",
        "Kaiqun Zhu",
        "Guofa Li",
        "Ziyuan Pu",
        "Jia Hu",
        "Zhiyong Cui",
        "Chengzhong Xu"
      ],
      "abstract": "Accurately and safely predicting the trajectories of surrounding vehicles is\nessential for fully realizing autonomous driving (AD). This paper presents the\nHuman-Like Trajectory Prediction model (HLTP++), which emulates human cognitive\nprocesses to improve trajectory prediction in AD. HLTP++ incorporates a novel\nteacher-student knowledge distillation framework. The \"teacher\" model equipped\nwith an adaptive visual sector, mimics the dynamic allocation of attention\nhuman drivers exhibit based on factors like spatial orientation, proximity, and\ndriving speed. On the other hand, the \"student\" model focuses on real-time\ninteraction and human decision-making, drawing parallels to the human memory\nstorage mechanism. Furthermore, we improve the model's efficiency by\nintroducing a new Fourier Adaptive Spike Neural Network (FA-SNN), allowing for\nfaster and more precise predictions with fewer parameters. Evaluated using the\nNGSIM, HighD, and MoCAD benchmarks, HLTP++ demonstrates superior performance\ncompared to existing models, which reduces the predicted trajectory error with\nover 11% on the NGSIM dataset and 25% on the HighD datasets. Moreover, HLTP++\ndemonstrates strong adaptability in challenging environments with incomplete\ninput data. This marks a significant stride in the journey towards fully AD\nsystems.",
      "tldr_zh": "本文提出 HLTP++ 模型，通过脑启发学习模仿人类认知过程，提升自动驾驶中车辆轨迹预测的准确性和效率。模型采用 teacher-student 知识蒸馏框架，其中 teacher 模型利用自适应视觉扇区动态分配注意力（如基于空间方向、接近度和速度），而 student 模型专注于实时交互和人类决策机制；同时引入 Fourier Adaptive Spike Neural Network (FA-SNN) 来减少参数并实现更快预测。在 NGSIM、HighD 和 MoCAD 数据集上，HLTP++ 比现有模型降低预测轨迹错误超过11%（NGSIM）和25%（HighD），并在不完整输入数据的挑战环境中展现出强适应性。",
      "categories": [
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.AI",
      "comment": "arXiv admin note: substantial text overlap with arXiv:2402.19251",
      "pdf_url": "http://arxiv.org/pdf/2407.07020v1",
      "published_date": "2024-07-09 16:42:17 UTC",
      "updated_date": "2024-07-09 16:42:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:53:44.882545"
    },
    {
      "arxiv_id": "2407.07009v2",
      "title": "Explainable AI for Enhancing Efficiency of DL-based Channel Estimation",
      "title_zh": "解释性 AI 用于提升基于深度学习的信道估计效率",
      "authors": [
        "Abdul Karim Gizzini",
        "Yahia Medjahdi",
        "Ali J. Ghandour",
        "Laurent Clavier"
      ],
      "abstract": "The support of artificial intelligence (AI) based decision-making is a key\nelement in future 6G networks, where the concept of native AI will be\nintroduced. Moreover, AI is widely employed in different critical applications\nsuch as autonomous driving and medical diagnosis. In such applications, using\nAI as black-box models is risky and challenging. Hence, it is crucial to\nunderstand and trust the decisions taken by these models. Tackling this issue\ncan be achieved by developing explainable AI (XAI) schemes that aim to explain\nthe logic behind the black-box model behavior, and thus, ensure its efficient\nand safe deployment. Recently, we proposed a novel perturbation-based XAI-CHEST\nframework that is oriented toward channel estimation in wireless\ncommunications. The core idea of the XAI-CHEST framework is to identify the\nrelevant model inputs by inducing high noise on the irrelevant ones. This\nmanuscript provides the detailed theoretical foundations of the XAI-CHEST\nframework. In particular, we derive the analytical expressions of the XAI-CHEST\nloss functions and the noise threshold fine-tuning optimization problem. Hence\nthe designed XAI-CHEST delivers a smart input feature selection methodology\nthat can further improve the overall performance while optimizing the\narchitecture of the employed model. Simulation results show that the XAI-CHEST\nframework provides valid interpretations, where it offers an improved bit error\nrate performance while reducing the required computational complexity in\ncomparison to the classical DL-based channel estimation.",
      "tldr_zh": "这篇论文探讨了Explainable AI (XAI)如何提升基于深度学习(DL)的信道估计效率，特别是在6G网络和关键应用中的应用，以解决AI黑盒模型的信任问题。论文提出了XAI-CHEST框架，该框架通过在无关输入上施加高噪声来识别相关输入，并提供了其理论基础，包括损失函数的解析表达式和噪声阈值的优化问题，从而实现智能特征选择和模型架构优化。模拟结果表明，XAI-CHEST框架不仅提供了有效的模型解释，还提高了误码率性能并降低了计算复杂度。",
      "categories": [
        "cs.AI",
        "eess.SP"
      ],
      "primary_category": "cs.AI",
      "comment": "This paper has been submitted to the IEEE Transactions on Machine\n  Learning in Communications and Networking on 19 March 2025",
      "pdf_url": "http://arxiv.org/pdf/2407.07009v2",
      "published_date": "2024-07-09 16:24:21 UTC",
      "updated_date": "2025-04-07 13:02:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:53:56.196987"
    },
    {
      "arxiv_id": "2407.07004v2",
      "title": "Empirical analysis of Binding Precedent efficiency in the Brazilian Supreme Court via Similar Case Retrieval",
      "title_zh": "翻译失败",
      "authors": [
        "Raphaël Tinarrage",
        "Henrique Ennes",
        "Lucas E. Resck",
        "Lucas T. Gomes",
        "Jean R. Ponciano",
        "Jorge Poco"
      ],
      "abstract": "Binding precedents (S\\'umulas Vinculantes) constitute a juridical instrument\nunique to the Brazilian legal system and whose objectives include the\nprotection of the Federal Supreme Court against repetitive demands. Studies of\nthe effectiveness of these instruments in decreasing the Court's exposure to\nsimilar cases, however, indicate that they tend to fail in such a direction,\nwith some of the binding precedents seemingly creating new demands. We\nempirically assess the legal impact of five binding precedents, 11, 14, 17, 26\nand 37, at the highest court level through their effects on the legal subjects\nthey address. This analysis is only possible through the comparison of the\nCourt's ruling about the precedents' themes before they are created, which\nmeans that these decisions should be detected through techniques of Similar\nCase Retrieval. The contributions of this article are therefore twofold: on the\nmathematical side, we compare the uses of different methods of Natural Language\nProcessing -- TF-IDF, LSTM, BERT, and regex -- for Similar Case Retrieval,\nwhereas on the legal side, we contrast the inefficiency of these binding\nprecedents with a set of hypotheses that may justify their repeated usage. We\nobserve that the deep learning models performed significantly worse in the\nspecific Similar Case Retrieval task and that the reasons for binding\nprecedents to fail in responding to repetitive demand are heterogeneous and\ncase-dependent, making it impossible to single out a specific cause.",
      "tldr_zh": "本文通过 Similar Case Retrieval 技术，对巴西最高法院的 Binding Precedents（强制先例）效率进行了实证分析，评估其是否能减少重复性案件。研究比较了多种 NLP 方法，包括 TF-IDF、LSTM、BERT 和 regex，在类似案件检索任务中的表现，发现深度学习模型如 LSTM 和 BERT 的效果显著不如传统方法。最终结果显示，这些 Binding Precedents 未能有效降低法院负担，其失败原因多样且依赖于具体案例，无法归结为单一因素。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR",
        "cs.LG",
        "68T50 (Primary), 68T07 (Secondary)"
      ],
      "primary_category": "cs.CL",
      "comment": "54 pages, 22 figures",
      "pdf_url": "http://arxiv.org/pdf/2407.07004v2",
      "published_date": "2024-07-09 16:17:16 UTC",
      "updated_date": "2024-07-23 18:20:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:54:09.052493"
    },
    {
      "arxiv_id": "2407.07003v1",
      "title": "Learning to Complement and to Defer to Multiple Users",
      "title_zh": "翻译失败",
      "authors": [
        "Zheng Zhang",
        "Wenjie Ai",
        "Kevin Wells",
        "David Rosewarne",
        "Thanh-Toan Do",
        "Gustavo Carneiro"
      ],
      "abstract": "With the development of Human-AI Collaboration in Classification (HAI-CC),\nintegrating users and AI predictions becomes challenging due to the complex\ndecision-making process. This process has three options: 1) AI autonomously\nclassifies, 2) learning to complement, where AI collaborates with users, and 3)\nlearning to defer, where AI defers to users. Despite their interconnected\nnature, these options have been studied in isolation rather than as components\nof a unified system. In this paper, we address this weakness with the novel\nHAI-CC methodology, called Learning to Complement and to Defer to Multiple\nUsers (LECODU). LECODU not only combines learning to complement and learning to\ndefer strategies, but it also incorporates an estimation of the optimal number\nof users to engage in the decision process. The training of LECODU maximises\nclassification accuracy and minimises collaboration costs associated with user\ninvolvement. Comprehensive evaluations across real-world and synthesized\ndatasets demonstrate LECODU's superior performance compared to state-of-the-art\nHAI-CC methods. Remarkably, even when relying on unreliable users with high\nrates of label noise, LECODU exhibits significant improvement over both human\ndecision-makers alone and AI alone.",
      "tldr_zh": "本论文针对人类-AI 分类协作 (HAI-CC) 中的决策挑战，提出了一种新型方法 Learning to Complement and to Defer to Multiple Users (LECODU)，它统一整合了 Learning to Complement 和 Learning to Defer 策略，并估计最佳用户数量以优化协作过程。LECODU 的训练目标是最大化分类准确率，同时最小化用户参与的协作成本。实验结果显示，在真实和合成数据集上，LECODU 优于现有 HAI-CC 方法，即使用户标签噪声高时，也显著提升了性能，超越了仅靠人类或 AI 的决策。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "ECCV 2024",
      "pdf_url": "http://arxiv.org/pdf/2407.07003v1",
      "published_date": "2024-07-09 16:16:44 UTC",
      "updated_date": "2024-07-09 16:16:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:54:19.588922"
    },
    {
      "arxiv_id": "2407.07000v2",
      "title": "Etalon: Holistic Performance Evaluation Framework for LLM Inference Systems",
      "title_zh": "Etalon：大语言模型推理系统的整体性能评估框架",
      "authors": [
        "Amey Agrawal",
        "Anmol Agarwal",
        "Nitin Kedia",
        "Jayashree Mohan",
        "Souvik Kundu",
        "Nipun Kwatra",
        "Ramachandran Ramjee",
        "Alexey Tumanov"
      ],
      "abstract": "Serving large language models (LLMs) in production can incur substantial\ncosts, which has prompted recent advances in inference system optimizations.\nToday, these systems are evaluated against conventional latency and throughput\nmetrics (eg. TTFT, TBT, Normalised Latency and TPOT). However, these metrics\nfail to fully capture the nuances of LLM inference, leading to an incomplete\nassessment of user-facing performance crucial for real-time applications such\nas chat and translation. In this paper, we first identify the pitfalls of\ncurrent performance metrics in evaluating LLM inference systems. We then\npropose Etalon, a comprehensive performance evaluation framework that includes\nfluidity-index -- a novel metric designed to reflect the intricacies of the LLM\ninference process and its impact on real-time user experience. Finally, we\nevaluate various existing open-source platforms and model-as-a-service\nofferings using Etalon, discussing their strengths and weaknesses. Etalon is\navailable at https://github.com/project-etalon/etalon.",
      "tldr_zh": "该论文指出了现有LLM推理系统评估指标（如TTFT、TBT、Normalized Latency和TPOT）的缺陷，这些指标无法全面捕捉实时应用（如聊天和翻译）中的用户体验。作者提出Etalon，一个整体性能评估框架，引入了新的fluidity-index指标，以更准确地反映LLM推理过程对用户体验的影响。最终，通过Etalon评估了多种开源平台和模型即服务，讨论了它们的优势和不足，并提供了开源实现（https://github.com/project-etalon/etalon）。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.DC"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.07000v2",
      "published_date": "2024-07-09 16:13:26 UTC",
      "updated_date": "2024-08-30 01:19:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:54:31.552858"
    },
    {
      "arxiv_id": "2407.06992v2",
      "title": "Robust Neural Information Retrieval: An Adversarial and Out-of-distribution Perspective",
      "title_zh": "鲁棒的神经信息检索：从对抗和分布外视角",
      "authors": [
        "Yu-An Liu",
        "Ruqing Zhang",
        "Jiafeng Guo",
        "Maarten de Rijke",
        "Yixing Fan",
        "Xueqi Cheng"
      ],
      "abstract": "Recent advances in neural information retrieval (IR) models have\nsignificantly enhanced their effectiveness over various IR tasks. The\nrobustness of these models, essential for ensuring their reliability in\npractice, has also garnered significant attention. With a wide array of\nresearch on robust IR being proposed, we believe it is the opportune moment to\nconsolidate the current status, glean insights from existing methodologies, and\nlay the groundwork for future development. We view the robustness of IR to be a\nmultifaceted concept, emphasizing its necessity against adversarial attacks,\nout-of-distribution (OOD) scenarios and performance variance. With a focus on\nadversarial and OOD robustness, we dissect robustness solutions for dense\nretrieval models (DRMs) and neural ranking models (NRMs), respectively,\nrecognizing them as pivotal components of the neural IR pipeline. We provide an\nin-depth discussion of existing methods, datasets, and evaluation metrics,\nshedding light on challenges and future directions in the era of large language\nmodels. To the best of our knowledge, this is the first comprehensive survey on\nthe robustness of neural IR models, and we will also be giving our first\ntutorial presentation at SIGIR 2024\n\\url{https://sigir2024-robust-information-retrieval.github.io}. Along with the\norganization of existing work, we introduce a Benchmark for robust IR (BestIR),\na heterogeneous evaluation benchmark for robust neural information retrieval,\nwhich is publicly available at \\url{https://github.com/Davion-Liu/BestIR}. We\nhope that this study provides useful clues for future research on the\nrobustness of IR models and helps to develop trustworthy search engines\n\\url{https://github.com/Davion-Liu/Awesome-Robustness-in-Information-Retrieval}.",
      "tldr_zh": "这篇论文从对抗攻击（adversarial attacks）和分布外场景（out-of-distribution, OOD）的角度，系统调查了神经信息检索（neural information retrieval, IR）模型的鲁棒性，强调了这些模型在实际应用中的可靠性和性能稳定性。作者分析了现有方法、数据集和评估指标，针对密集检索模型（dense retrieval models, DRMs）和神经排名模型（neural ranking models, NRMs）提出了鲁棒性解决方案，并讨论了在大语言模型时代面临的挑战与未来方向。作为主要贡献，该论文引入了 BestIR 基准——一个公开的异构评估基准，以促进鲁棒 IR 研究，并计划在 SIGIR 2024 上进行首次教程演示。总的来说，这是有史以来第一个全面综述神经 IR 模型鲁棒性的工作，有助于构建可信赖的搜索引擎。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.IR",
      "comment": "Survey paper",
      "pdf_url": "http://arxiv.org/pdf/2407.06992v2",
      "published_date": "2024-07-09 16:07:01 UTC",
      "updated_date": "2024-08-16 08:18:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:54:44.230080"
    },
    {
      "arxiv_id": "2407.06985v4",
      "title": "PEER: Expertizing Domain-Specific Tasks with a Multi-Agent Framework and Tuning Methods",
      "title_zh": "翻译失败",
      "authors": [
        "Yiying Wang",
        "Xiaojing Li",
        "Binzhu Wang",
        "Yueyang Zhou",
        "Yingru Lin",
        "Han Ji",
        "Hong Chen",
        "Jinshi Zhang",
        "Fei Yu",
        "Zewei Zhao",
        "Song Jin",
        "Renji Gong",
        "Wanqing Xu"
      ],
      "abstract": "In domain-specific applications, GPT-4, augmented with precise prompts or\nRetrieval-Augmented Generation (RAG), shows notable potential but faces the\ncritical tri-lemma of performance, cost, and data privacy. High performance\nrequires sophisticated processing techniques, yet managing multiple agents\nwithin a complex workflow often proves costly and challenging. To address this,\nwe introduce the PEER (Plan, Execute, Express, Review) multi-agent framework.\nThis systematizes domain-specific tasks by integrating precise question\ndecomposition, advanced information retrieval, comprehensive summarization, and\nrigorous self-assessment. Given the concerns of cost and data privacy,\nenterprises are shifting from proprietary models like GPT-4 to custom models,\nstriking a balance between cost, security, and performance. We developed\nindustrial practices leveraging online data and user feedback for efficient\nmodel tuning. This study provides best practice guidelines for applying\nmulti-agent systems in domain-specific problem-solving and implementing\neffective agent tuning strategies. Our empirical studies, particularly in the\nfinancial question-answering domain, demonstrate that our approach achieves\n95.0% of GPT-4's performance, while effectively managing costs and ensuring\ndata privacy.",
      "tldr_zh": "该研究提出PEER多智能体框架，用于提升特定领域任务的性能，同时解决性能、成本和数据隐私的三难困境。框架通过规划(Plan)、执行(Execute)、表达(Express)和审查(Review)四个阶段，整合问题分解、信息检索、总结和自我评估，并结合Retrieval-Augmented Generation (RAG)技术。作者还开发了基于在线数据和用户反馈的模型调整实践，并在金融问答领域实证验证，达到GPT-4性能的95.0%，并有效管理成本和隐私风险。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.06985v4",
      "published_date": "2024-07-09 15:59:28 UTC",
      "updated_date": "2024-08-30 06:27:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:54:56.635921"
    },
    {
      "arxiv_id": "2407.06979v3",
      "title": "Can virtual staining for high-throughput screening generalize?",
      "title_zh": "高通量筛选的虚拟染色能否泛化？",
      "authors": [
        "Samuel Tonks",
        "Cuong Nguyen",
        "Steve Hood",
        "Ryan Musso",
        "Ceridwen Hopely",
        "Steve Titus",
        "Minh Doan",
        "Iain Styles",
        "Alexander Krull"
      ],
      "abstract": "The large volume and variety of imaging data from high-throughput screening\n(HTS) in the pharmaceutical industry present an excellent resource for training\nvirtual staining models. However, the potential of models trained under one set\nof experimental conditions to generalize to other conditions remains\nunderexplored. This study systematically investigates whether data from three\ncell types (lung, ovarian, and breast) and two phenotypes (toxic and non-toxic\nconditions) commonly found in HTS can effectively train virtual staining models\nto generalize across three typical HTS distribution shifts: unseen phenotypes,\nunseen cell types, and the combination of both. Utilizing a dataset of 772,416\npaired bright-field, cytoplasm, nuclei, and DNA-damage stain images, we\nevaluate the generalization capabilities of models across pixel-based,\ninstance-wise, and biological-feature-based levels. Our findings indicate that\ntraining virtual nuclei and cytoplasm models on non-toxic condition samples not\nonly generalizes to toxic condition samples but leads to improved performance\nacross all evaluation levels compared to training on toxic condition samples.\nGeneralization to unseen cell types shows variability depending on the cell\ntype; models trained on ovarian or lung cell samples often perform well under\nother conditions, while those trained on breast cell samples consistently show\npoor generalization. Generalization to unseen cell types and phenotypes shows\ngood generalization across all levels of evaluation compared to addressing\nunseen cell types alone. This study represents the first large-scale,\ndata-centric analysis of the generalization capability of virtual staining\nmodels trained on diverse HTS datasets, providing valuable strategies for\nexperimental training data generation.",
      "tldr_zh": "本研究探讨了虚拟染色模型在高通量筛选(HTS)中的泛化能力，系统评估了使用肺、卵巢和乳腺三种细胞类型以及毒性和非毒性两种表型的训练数据。利用一个包含772,416对成像数据集（包括bright-field、cytoplasm、nuclei和DNA-damage stain图像），模型在像素级、实例级和生物特征级上进行了测试，结果显示：在非毒性条件下训练的模型不仅能泛化到毒性条件，还表现出整体性能提升。泛化到未见细胞类型时，基于卵巢或肺细胞的模型表现较好，而基于乳腺细胞的模型泛化能力较差；同时处理未见细胞类型和表型时，泛化效果在所有评估水平上均较强。该研究首次进行大规模数据导向分析，为HTS实验训练数据生成提供了重要策略。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV",
        "q-bio.QM"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.06979v3",
      "published_date": "2024-07-09 15:54:06 UTC",
      "updated_date": "2024-09-30 08:51:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:55:09.889792"
    },
    {
      "arxiv_id": "2407.06976v1",
      "title": "Advancing Manuscript Metadata: Work in Progress at the Jagiellonian University",
      "title_zh": "推进手稿元数据：雅盖隆大学的工作进展",
      "authors": [
        "Luiz do Valle Miranda",
        "Krzysztof Kutt",
        "Grzegorz J. Nalepa"
      ],
      "abstract": "As part of ongoing research projects, three Jagiellonian University units --\nthe Jagiellonian University Museum, the Jagiellonian University Archives, and\nthe Jagiellonian Library -- are collaborating to digitize cultural heritage\ndocuments, describe them in detail, and then integrate these descriptions into\na linked data cloud. Achieving this goal requires, as a first step, the\ndevelopment of a metadata model that, on the one hand, complies with existing\nstandards, on the other hand, allows interoperability with other systems, and\non the third, captures all the elements of description established by the\ncurators of the collections. In this paper, we present a report on the current\nstatus of the work, in which we outline the most important requirements for the\ndata model under development and then make a detailed comparison with the two\nstandards that are the most relevant from the point of view of collections:\nEuropeana Data Model used in Europeana and Encoded Archival Description used in\nKalliope.",
      "tldr_zh": "这篇论文报告了雅盖隆大学（Jagiellonian University）的博物馆、档案馆和图书馆三单位合作的项目进展，旨在数字化文化遗产文件、详细描述这些文件，并将描述整合到链接数据云（linked data cloud）中。核心工作是开发一个元数据模型，该模型需符合现有标准、确保与其他系统的互操作性（interoperability），并捕捉策展人定义的所有描述元素。论文概述了数据模型的关键要求，并对两个相关标准——Europeana Data Model 和 Encoded Archival Description——进行了详细比较，以推进手稿元数据的发展。",
      "categories": [
        "cs.DL",
        "cs.AI"
      ],
      "primary_category": "cs.DL",
      "comment": "9 pages; submitted to TPLD 2024",
      "pdf_url": "http://arxiv.org/pdf/2407.06976v1",
      "published_date": "2024-07-09 15:52:06 UTC",
      "updated_date": "2024-07-09 15:52:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:55:19.242802"
    },
    {
      "arxiv_id": "2407.06972v1",
      "title": "Microsoft Cloud-based Digitization Workflow with Rich Metadata Acquisition for Cultural Heritage Objects",
      "title_zh": "基于 Microsoft 云的数字化工作流，用于文化遗产对象的丰富元数据获取",
      "authors": [
        "Krzysztof Kutt",
        "Jakub Gomułka",
        "Luiz do Valle Miranda",
        "Grzegorz J. Nalepa"
      ],
      "abstract": "In response to several cultural heritage initiatives at the Jagiellonian\nUniversity, we have developed a new digitization workflow in collaboration with\nthe Jagiellonian Library (JL). The solution is based on easy-to-access\ntechnological solutions -- Microsoft 365 cloud with MS Excel files as metadata\nacquisition interfaces, Office Script for validation, and MS Sharepoint for\nstorage -- that allows metadata acquisition by domain experts (philologists,\nhistorians, philosophers, librarians, archivists, curators, etc.) regardless of\ntheir experience with information systems. The ultimate goal is to create a\nknowledge graph that describes the analyzed holdings, linked to general\nknowledge bases, as well as to other cultural heritage collections, so careful\nattention is paid to the high accuracy of metadata and proper links to external\nsources. The workflow has already been evaluated in two pilots in the DiHeLib\nproject focused on digitizing the so-called \"Berlin Collection\" and in two\nworkshops with international guests, which allowed for its refinement and\nconfirmation of its correctness and usability for JL. As the proposed workflow\ndoes not interfere with existing systems or domain guidelines regarding\ndigitization and basic metadata collection in a given institution (e.g., file\ntype, image quality, use of Dublin Core/MARC-21), but extends them in order to\nenable rich metadata collection, not previously possible, we believe that it\ncould be of interest to all GLAMs (galleries, libraries, archives, and\nmuseums).",
      "tldr_zh": "该论文提出了一种基于 Microsoft 365 云的数字化工作流程，用于文化遗产对象的丰富元数据采集，旨在让领域专家（如历史学家和图书馆员）无需信息系统经验即可参与。工作流程利用 MS Excel 作为元数据采集界面、Office Script 进行验证，以及 MS Sharepoint 进行存储，以确保元数据的高准确性和外部来源链接，最终目标是构建一个描述藏品的知识图谱。经 DiHeLib 项目试点和国际工作坊评估，该方法扩展了现有系统（如 Dublin Core/MARC-21），证明其正确性和可用性，并适用于 GLAMs（画廊、图书馆、档案馆和博物馆）。",
      "categories": [
        "cs.DL",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.DL",
      "comment": "19 pages; submitted to Multimedia Tools and Applications",
      "pdf_url": "http://arxiv.org/pdf/2407.06972v1",
      "published_date": "2024-07-09 15:49:47 UTC",
      "updated_date": "2024-07-09 15:49:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:55:33.676886"
    },
    {
      "arxiv_id": "2407.07135v1",
      "title": "Improving Out-of-Distribution Detection by Combining Existing Post-hoc Methods",
      "title_zh": "翻译失败",
      "authors": [
        "Paul Novello",
        "Yannick Prudent",
        "Joseba Dalmau",
        "Corentin Friedrich",
        "Yann Pequignot"
      ],
      "abstract": "Since the seminal paper of Hendrycks et al. arXiv:1610.02136, Post-hoc deep\nOut-of-Distribution (OOD) detection has expanded rapidly. As a result,\npractitioners working on safety-critical applications and seeking to improve\nthe robustness of a neural network now have a plethora of methods to choose\nfrom. However, no method outperforms every other on every dataset\narXiv:2210.07242, so the current best practice is to test all the methods on\nthe datasets at hand. This paper shifts focus from developing new methods to\neffectively combining existing ones to enhance OOD detection. We propose and\ncompare four different strategies for integrating multiple detection scores\ninto a unified OOD detector, based on techniques such as majority vote,\nempirical and copulas-based Cumulative Distribution Function modeling, and\nmultivariate quantiles based on optimal transport. We extend common OOD\nevaluation metrics -- like AUROC and FPR at fixed TPR rates -- to these\nmulti-dimensional OOD detectors, allowing us to evaluate them and compare them\nwith individual methods on extensive benchmarks. Furthermore, we propose a\nseries of guidelines to choose what OOD detectors to combine in more realistic\nsettings, i.e. in the absence of known OOD data, relying on principles drawn\nfrom Outlier Exposure arXiv:1812.04606. The code is available at\nhttps://github.com/paulnovello/multi-ood.",
      "tldr_zh": "这篇论文旨在通过结合现有的 Post-hoc Out-of-Distribution (OOD) 检测方法来提升检测性能，而不是开发新方法。作者提出了四种整合策略，包括 majority vote、empirical and copulas-based Cumulative Distribution Function (CDF) 建模，以及 multivariate quantiles based on optimal transport，以统一多个检测分数。论文扩展了常见的评估指标，如 AUROC 和 FPR，来评估这些多维检测器，并在广泛基准上与单个方法进行比较。最终，论文提供了指导原则，帮助在没有已知 OOD 数据的情况下选择检测器，借鉴 Outlier Exposure 的原理，以适用于更真实的场景。",
      "categories": [
        "stat.ML",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "stat.ML",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.07135v1",
      "published_date": "2024-07-09 15:46:39 UTC",
      "updated_date": "2024-07-09 15:46:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:55:47.959884"
    },
    {
      "arxiv_id": "2407.06950v1",
      "title": "Spanish TrOCR: Leveraging Transfer Learning for Language Adaptation",
      "title_zh": "Spanish TrOCR：利用迁移学习进行语言适应",
      "authors": [
        "Filipe Lauar",
        "Valentin Laurent"
      ],
      "abstract": "This study explores the transfer learning capabilities of the TrOCR\narchitecture to Spanish. TrOCR is a transformer-based Optical Character\nRecognition (OCR) model renowned for its state-of-the-art performance in\nEnglish benchmarks. Inspired by Li et al. assertion regarding its adaptability\nto multilingual text recognition, we investigate two distinct approaches to\nadapt the model to a new language: integrating an English TrOCR encoder with a\nlanguage specific decoder and train the model on this specific language, and\nfine-tuning the English base TrOCR model on a new language data. Due to the\nscarcity of publicly available datasets, we present a resource-efficient\npipeline for creating OCR datasets in any language, along with a comprehensive\nbenchmark of the different image generation methods employed with a focus on\nVisual Rich Documents (VRDs). Additionally, we offer a comparative analysis of\nthe two approaches for the Spanish language, demonstrating that fine-tuning the\nEnglish TrOCR on Spanish yields superior recognition than the language specific\ndecoder for a fixed dataset size. We evaluate our model employing character and\nword error rate metrics on a public available printed dataset, comparing the\nperformance against other open-source and cloud OCR spanish models. As far as\nwe know, these resources represent the best open-source model for OCR in\nSpanish. The Spanish TrOCR models are publicly available on HuggingFace [20]\nand the code to generate the dataset is available on Github [25].",
      "tldr_zh": "本研究探索了基于 Transformer 的 OCR 模型 TrOCR 通过迁移学习（Transfer Learning）适应西班牙语的过程，评估了两种方法：将英语 TrOCR 编码器与特定语言解码器结合训练，以及直接在西班牙语数据上微调英语基础模型。针对公开数据集稀缺的问题，作者提出了一种资源高效的管道来生成多语言 OCR 数据集，并对图像生成方法进行了基准测试，重点关注视觉丰富文档（VRDs）。实验结果显示，微调英语 TrOCR 在西班牙语上的性能优于特定解码器方法，并在字符和单词错误率指标上超越其他开源和云端 OCR 模型；该模型已公开在 HuggingFace 上可用，并附带 Github 代码。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "10 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2407.06950v1",
      "published_date": "2024-07-09 15:31:41 UTC",
      "updated_date": "2024-07-09 15:31:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:55:58.781621"
    },
    {
      "arxiv_id": "2407.06946v2",
      "title": "Self-Recognition in Language Models",
      "title_zh": "语言模型中的自我识别",
      "authors": [
        "Tim R. Davidson",
        "Viacheslav Surkov",
        "Veniamin Veselovsky",
        "Giuseppe Russo",
        "Robert West",
        "Caglar Gulcehre"
      ],
      "abstract": "A rapidly growing number of applications rely on a small set of closed-source\nlanguage models (LMs). This dependency might introduce novel security risks if\nLMs develop self-recognition capabilities. Inspired by human identity\nverification methods, we propose a novel approach for assessing\nself-recognition in LMs using model-generated \"security questions\". Our test\ncan be externally administered to monitor frontier models as it does not\nrequire access to internal model parameters or output probabilities. We use our\ntest to examine self-recognition in ten of the most capable open- and\nclosed-source LMs currently publicly available. Our extensive experiments found\nno empirical evidence of general or consistent self-recognition in any examined\nLM. Instead, our results suggest that given a set of alternatives, LMs seek to\npick the \"best\" answer, regardless of its origin. Moreover, we find indications\nthat preferences about which models produce the best answers are consistent\nacross LMs. We additionally uncover novel insights on position bias\nconsiderations for LMs in multiple-choice settings.",
      "tldr_zh": "本论文探讨了语言模型（LMs）可能发展的自我识别（self-recognition）能力及其潜在安全风险，提出了一种基于模型生成的“security questions”外部评估方法，以模拟人类身份验证。研究在十个最先进的开源和闭源LMs上进行实验，结果未发现任何LMs表现出一般或一致的自我识别能力，而是倾向于选择“最佳”答案，而不考虑答案来源。此外，实验揭示了LMs在多选设置中的位置偏差（position bias），并指出不同LMs对“最佳”答案的偏好具有一致性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to EMNLP 2024, code to reproduce experiments and replicate\n  findings available at https://github.com/trdavidson/self-recognition",
      "pdf_url": "http://arxiv.org/pdf/2407.06946v2",
      "published_date": "2024-07-09 15:23:28 UTC",
      "updated_date": "2024-10-10 11:07:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:56:11.474929"
    },
    {
      "arxiv_id": "2407.06941v1",
      "title": "Raply: A profanity-mitigated rap generator",
      "title_zh": "翻译失败",
      "authors": [
        "Omar Manil Bendali",
        "Samir Ferroum",
        "Ekaterina Kozachenko",
        "Youssef Parviz",
        "Hanna Shcharbakova",
        "Anna Tokareva",
        "Shemair Williams"
      ],
      "abstract": "The task of writing rap is challenging and involves producing complex rhyming\nschemes, yet meaningful lyrics. In this work, we propose Raply, a fine-tuned\nGPT-2 model capable of producing meaningful rhyming text in the style of rap.\nIn addition to its rhyming capabilities, the model is able to generate less\noffensive content. It was achieved through the fine-tuning the model on a new\ndataset Mitislurs, a profanity-mitigated corpus. We evaluate the output of the\nmodel on two criteria: 1) rhyming based on the rhyme density metric; 2)\nprofanity content, using the list of profanities for the English language. To\nour knowledge, this is the first attempt at profanity mitigation for rap lyrics\ngeneration.",
      "tldr_zh": "本文提出Raply，一种基于GPT-2的说唱生成器，能够生成有意义的押韵文本，同时通过在新的数据集Mitislurs（一个减少脏话的语料库）上微调模型，显著降低输出中的攻击性内容。模型的性能通过rhyme density metric评估押韵质量，以及使用英文脏话列表评估脏话水平。Raply是首次针对说唱歌词生成的脏话缓解尝试，为更负责任的文本生成提供了创新方法。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.06941v1",
      "published_date": "2024-07-09 15:18:56 UTC",
      "updated_date": "2024-07-09 15:18:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:56:21.413979"
    },
    {
      "arxiv_id": "2407.06930v1",
      "title": "Integrating Ontology Design with the CRISP-DM in the context of Cyber-Physical Systems Maintenance",
      "title_zh": "翻译失败",
      "authors": [
        "Milapji Singh Gill",
        "Tom Westermann",
        "Gernot Steindl",
        "Felix Gehlhoff",
        "Alexander Fay"
      ],
      "abstract": "In the following contribution, a method is introduced that integrates domain\nexpert-centric ontology design with the Cross-Industry Standard Process for\nData Mining (CRISP-DM). This approach aims to efficiently build an\napplication-specific ontology tailored to the corrective maintenance of\nCyber-Physical Systems (CPS). The proposed method is divided into three phases.\nIn phase one, ontology requirements are systematically specified, defining the\nrelevant knowledge scope. Accordingly, CPS life cycle data is contextualized in\nphase two using domain-specific ontological artifacts. This formalized domain\nknowledge is then utilized in the CRISP-DM to efficiently extract new insights\nfrom the data. Finally, the newly developed data-driven model is employed to\npopulate and expand the ontology. Thus, information extracted from this model\nis semantically annotated and aligned with the existing ontology in phase\nthree. The applicability of this method has been evaluated in an anomaly\ndetection case study for a modular process plant.",
      "tldr_zh": "本研究提出了一种方法，将领域专家导向的本体设计（Ontology Design）与跨行业数据挖掘标准过程（CRISP-DM）整合，旨在高效构建针对 Cyber-Physical Systems (CPS) 纠正维护的特定应用本体。该方法分为三个阶段：首先，系统指定本体要求并定义相关知识范围；其次，使用领域特定的本体工件语境化 CPS 生命周期数据，并通过 CRISP-DM 提取新洞见；最后，利用数据驱动模型填充和扩展本体，并对提取信息进行语义标注与对齐。该方法的适用性已在模块化过程工厂的异常检测案例研究中得到验证，展示了其在提升 CPS 维护效率方面的潜力。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.06930v1",
      "published_date": "2024-07-09 15:06:47 UTC",
      "updated_date": "2024-07-09 15:06:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:56:33.664463"
    },
    {
      "arxiv_id": "2407.19096v1",
      "title": "AI Companions Reduce Loneliness",
      "title_zh": "翻译失败",
      "authors": [
        "Julian De Freitas",
        "Ahmet K Uguralp",
        "Zeliha O Uguralp",
        "Puntoni Stefano"
      ],
      "abstract": "Chatbots are now able to engage in sophisticated conversations with consumers\nin the domain of relationships, providing a potential coping solution to\nwidescale societal loneliness. Behavioral research provides little insight into\nwhether these applications are effective at alleviating loneliness. We address\nthis question by focusing on AI companions applications designed to provide\nconsumers with synthetic interaction partners. Studies 1 and 2 find suggestive\nevidence that consumers use AI companions to alleviate loneliness, by employing\na novel methodology for fine tuning large language models to detect loneliness\nin conversations and reviews. Study 3 finds that AI companions successfully\nalleviate loneliness on par only with interacting with another person, and more\nthan other activities such watching YouTube videos. Moreover, consumers\nunderestimate the degree to which AI companions improve their loneliness. Study\n4 uses a longitudinal design and finds that an AI companion consistently\nreduces loneliness over the course of a week. Study 5 provides evidence that\nboth the chatbots' performance and, especially, whether it makes users feel\nheard, explain reductions in loneliness. Study 6 provides an additional\nrobustness check for the loneliness alleviating benefits of AI companions.",
      "tldr_zh": "本研究探讨了AI companions（如聊天机器人）是否能有效缓解社会孤独感，通过多个实验验证其效果。研究者使用fine-tuned large language models检测对话中的孤独信号，并通过Studies 1-6比较AI互动与真人互动或其他活动（如看YouTube视频）。结果显示，AI companions能与真人互动相当地减少孤独感，且其长期使用（如一周内）持续有效；然而，用户往往低估了这种益处，主要归因于chatbots的表现和让用户感到被倾听的程度。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.19096v1",
      "published_date": "2024-07-09 15:04:08 UTC",
      "updated_date": "2024-07-09 15:04:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:56:47.414440"
    },
    {
      "arxiv_id": "2407.06910v1",
      "title": "Fine-grained large-scale content recommendations for MSX sellers",
      "title_zh": "翻译失败",
      "authors": [
        "Manpreet Singh",
        "Ravdeep Pasricha",
        "Ravi Prasad Kondapalli",
        "Kiran R",
        "Nitish Singh",
        "Akshita Agarwalla",
        "Manoj R",
        "Manish Prabhakar",
        "Laurent Boué"
      ],
      "abstract": "One of the most critical tasks of Microsoft sellers is to meticulously track\nand nurture potential business opportunities through proactive engagement and\ntailored solutions. Recommender systems play a central role to help sellers\nachieve their goals. In this paper, we present a content recommendation model\nwhich surfaces various types of content (technical documentation, comparison\nwith competitor products, customer success stories etc.) that sellers can share\nwith their customers or use for their own self-learning. The model operates at\nthe opportunity level which is the lowest possible granularity and the most\nrelevant one for sellers. It is based on semantic matching between metadata\nfrom the contents and carefully selected attributes of the opportunities.\nConsidering the volume of seller-managed opportunities in organizations such as\nMicrosoft, we show how to perform efficient semantic matching over a very large\nnumber of opportunity-content combinations. The main challenge is to ensure\nthat the top-5 relevant contents for each opportunity are recommended out of a\ntotal of $\\approx 40,000$ published contents. We achieve this target through an\nextensive comparison of different model architectures and feature selection.\nFinally, we further examine the quality of the recommendations in a\nquantitative manner using a combination of human domain experts as well as by\nusing the recently proposed \"LLM as a judge\" framework.",
      "tldr_zh": "本文提出一个细粒度内容推荐模型，针对微软销售人员（MSX sellers），帮助他们通过语义匹配推荐技术文档、竞争产品比较和客户成功故事等内容，以支持业务机会的跟踪和培养。该模型在机会级别运作，基于内容元数据与机会属性的语义匹配，从约40,000个内容中高效筛选出每个机会的前5相关推荐，通过比较不同模型架构和特征选择来优化性能。最后，推荐质量通过人类专家评估和\"LLM as a judge\"框架进行定量验证，展示了模型的有效性。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.06910v1",
      "published_date": "2024-07-09 14:46:09 UTC",
      "updated_date": "2024-07-09 14:46:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:56:58.887781"
    },
    {
      "arxiv_id": "2407.06909v1",
      "title": "Intercepting Unauthorized Aerial Robots in Controlled Airspace Using Reinforcement Learning",
      "title_zh": "使用强化学习在受控空域拦截未经授权的空中机器人",
      "authors": [
        "Francisco Giral",
        "Ignacio Gómez",
        "Soledad Le Clainche"
      ],
      "abstract": "The proliferation of unmanned aerial vehicles (UAVs) in controlled airspace\npresents significant risks, including potential collisions, disruptions to air\ntraffic, and security threats. Ensuring the safe and efficient operation of\nairspace, particularly in urban environments and near critical infrastructure,\nnecessitates effective methods to intercept unauthorized or non-cooperative\nUAVs. This work addresses the critical need for robust, adaptive systems\ncapable of managing such threats through the use of Reinforcement Learning\n(RL). We present a novel approach utilizing RL to train fixed-wing UAV pursuer\nagents for intercepting dynamic evader targets. Our methodology explores both\nmodel-based and model-free RL algorithms, specifically DreamerV3, Truncated\nQuantile Critics (TQC), and Soft Actor-Critic (SAC). The training and\nevaluation of these algorithms were conducted under diverse scenarios,\nincluding unseen evasion strategies and environmental perturbations. Our\napproach leverages high-fidelity flight dynamics simulations to create\nrealistic training environments. This research underscores the importance of\ndeveloping intelligent, adaptive control systems for UAV interception,\nsignificantly contributing to the advancement of secure and efficient airspace\nmanagement. It demonstrates the potential of RL to train systems capable of\nautonomously achieving these critical tasks.",
      "tldr_zh": "本研究针对无人机（UAVs）在受控空域的非法活动带来的风险（如碰撞和安全威胁），提出了一种使用强化学习（RL）训练固定翼UAV追逐者来拦截动态逃避目标的新方法。研究探索了基于模型和非基于模型的RL算法，包括DreamerV3、Truncated Quantile Critics (TQC)和Soft Actor-Critic (SAC)，并在高保真飞行动态模拟环境中进行训练和评估，以应对各种场景如未知逃避策略和环境扰动。实验结果证明，该方法在多样化条件下表现出色，显著提升了空域管理的安全性和效率，并展示了RL在自主拦截任务中的潜力。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.06909v1",
      "published_date": "2024-07-09 14:45:47 UTC",
      "updated_date": "2024-07-09 14:45:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:57:10.648752"
    },
    {
      "arxiv_id": "2407.06904v1",
      "title": "Hypergraph based Understanding for Document Semantic Entity Recognition",
      "title_zh": "翻译失败",
      "authors": [
        "Qiwei Li",
        "Zuchao Li",
        "Ping Wang",
        "Haojun Ai",
        "Hai Zhao"
      ],
      "abstract": "Semantic entity recognition is an important task in the field of\nvisually-rich document understanding. It distinguishes the semantic types of\ntext by analyzing the position relationship between text nodes and the relation\nbetween text content. The existing document understanding models mainly focus\non entity categories while ignoring the extraction of entity boundaries. We\nbuild a novel hypergraph attention document semantic entity recognition\nframework, HGA, which uses hypergraph attention to focus on entity boundaries\nand entity categories at the same time. It can conduct a more detailed analysis\nof the document text representation analyzed by the upstream model and achieves\na better performance of semantic information. We apply this method on the basis\nof GraphLayoutLM to construct a new semantic entity recognition model\nHGALayoutLM. Our experiment results on FUNSD, CORD, XFUND and SROIE show that\nour method can effectively improve the performance of semantic entity\nrecognition tasks based on the original model. The results of HGALayoutLM on\nFUNSD and XFUND reach the new state-of-the-art results.",
      "tldr_zh": "这篇论文针对视觉丰富文档理解中的语义实体识别任务，提出了一种新型框架 HGA（Hypergraph Attention），通过超图注意力机制同时关注实体边界和实体类别，从而更详细地分析文档文本表示。HGA 构建于 GraphLayoutLM 的基础上，形成了 HGALayoutLM 模型，以解决现有模型忽略实体边界提取的问题。在 FUNSD、CORD、XFUND 和 SROIE 数据集上的实验结果显示，该方法显著提升了语义实体识别性能，并在 FUNSD 和 XFUND 上达到了新的 state-of-the-art 结果。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.06904v1",
      "published_date": "2024-07-09 14:35:49 UTC",
      "updated_date": "2024-07-09 14:35:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:57:22.674094"
    },
    {
      "arxiv_id": "2407.06902v1",
      "title": "Learning From Crowdsourced Noisy Labels: A Signal Processing Perspective",
      "title_zh": "从众包噪声标签中学习：信号处理视角",
      "authors": [
        "Shahana Ibrahim",
        "Panagiotis A. Traganitis",
        "Xiao Fu",
        "Georgios B. Giannakis"
      ],
      "abstract": "One of the primary catalysts fueling advances in artificial intelligence (AI)\nand machine learning (ML) is the availability of massive, curated datasets. A\ncommonly used technique to curate such massive datasets is crowdsourcing, where\ndata are dispatched to multiple annotators. The annotator-produced labels are\nthen fused to serve downstream learning and inference tasks. This annotation\nprocess often creates noisy labels due to various reasons, such as the limited\nexpertise, or unreliability of annotators, among others. Therefore, a core\nobjective in crowdsourcing is to develop methods that effectively mitigate the\nnegative impact of such label noise on learning tasks. This feature article\nintroduces advances in learning from noisy crowdsourced labels. The focus is on\nkey crowdsourcing models and their methodological treatments, from classical\nstatistical models to recent deep learning-based approaches, emphasizing\nanalytical insights and algorithmic developments. In particular, this article\nreviews the connections between signal processing (SP) theory and methods, such\nas identifiability of tensor and nonnegative matrix factorization, and novel,\nprincipled solutions of longstanding challenges in crowdsourcing -- showing how\nSP perspectives drive the advancements of this field. Furthermore, this article\ntouches upon emerging topics that are critical for developing cutting-edge\nAI/ML systems, such as crowdsourcing in reinforcement learning with human\nfeedback (RLHF) and direct preference optimization (DPO) that are key\ntechniques for fine-tuning large language models (LLMs).",
      "tldr_zh": "该论文从 signal processing 视角探讨了从 crowdsourced noisy labels 中学习的方法，旨在缓解标签噪声对机器学习任务的影响。论文回顾了从经典统计模型到深度学习方法的进展，强调了 tensor factorization 和 nonnegative matrix factorization 等理论在 crowdsourcing 模型中的应用，提供了解析见解和算法开发。最终，它展示了 signal processing 视角如何推动该领域的创新，并触及新兴主题，如 crowdsourcing 在 reinforcement learning with human feedback (RLHF) 和 direct preference optimization (DPO) 中的作用，以提升 large language models (LLMs) 的微调效果。",
      "categories": [
        "eess.SP",
        "cs.AI",
        "cs.HC",
        "cs.LG"
      ],
      "primary_category": "eess.SP",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.06902v1",
      "published_date": "2024-07-09 14:34:40 UTC",
      "updated_date": "2024-07-09 14:34:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:57:34.993993"
    },
    {
      "arxiv_id": "2407.06886v7",
      "title": "Aligning Cyber Space with Physical World: A Comprehensive Survey on Embodied AI",
      "title_zh": "翻译失败",
      "authors": [
        "Yang Liu",
        "Weixing Chen",
        "Yongjie Bai",
        "Xiaodan Liang",
        "Guanbin Li",
        "Wen Gao",
        "Liang Lin"
      ],
      "abstract": "Embodied Artificial Intelligence (Embodied AI) is crucial for achieving\nArtificial General Intelligence (AGI) and serves as a foundation for various\napplications that bridge cyberspace and the physical world. Recently, the\nemergence of Multi-modal Large Models (MLMs) and World Models (WMs) have\nattracted significant attention due to their remarkable perception,\ninteraction, and reasoning capabilities, making them a promising architecture\nfor the brain of embodied agents. However, there is no comprehensive survey for\nEmbodied AI in the era of MLMs. In this survey, we give a comprehensive\nexploration of the latest advancements in Embodied AI. Our analysis firstly\nnavigates through the forefront of representative works of embodied robots and\nsimulators, to fully understand the research focuses and their limitations.\nThen, we analyze four main research targets: 1) embodied perception, 2)\nembodied interaction, 3) embodied agent, and 4) sim-to-real adaptation,\ncovering the state-of-the-art methods, essential paradigms, and comprehensive\ndatasets. Additionally, we explore the complexities of MLMs in virtual and real\nembodied agents, highlighting their significance in facilitating interactions\nin dynamic digital and physical environments. Finally, we summarize the\nchallenges and limitations of embodied AI and discuss their potential future\ndirections. We hope this survey will serve as a foundational reference for the\nresearch community and inspire continued innovation. The associated project can\nbe found at https://github.com/HCPLab-SYSU/Embodied_AI_Paper_List.",
      "tldr_zh": "这篇调查全面探讨了Embodied AI在桥接网络空间和物理世界中的关键作用，特别是结合Multi-modal Large Models (MLMs)和World Models (WMs)的最新进展，以支持Artificial General Intelligence (AGI)的实现。\n论文分析了代表性机器人和模拟器作品的局限性，并详细阐述了四大研究目标：embodied perception、embodied interaction、embodied agent，以及sim-to-real adaptation，包括先进方法、核心范式和数据集。\n最终，它总结了Embodied AI面临的挑战与限制，并讨论了潜在未来方向，作为研究社区的参考，促进进一步创新。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "cs.MA",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "The first comprehensive review of Embodied AI in the era of MLMs, 39\n  pages. We also provide the paper list for Embodied AI:\n  https://github.com/HCPLab-SYSU/Embodied_AI_Paper_List",
      "pdf_url": "http://arxiv.org/pdf/2407.06886v7",
      "published_date": "2024-07-09 14:14:47 UTC",
      "updated_date": "2024-08-26 03:25:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:57:47.350749"
    },
    {
      "arxiv_id": "2407.06866v2",
      "title": "ChatGPT Doesn't Trust Chargers Fans: Guardrail Sensitivity in Context",
      "title_zh": "翻译失败",
      "authors": [
        "Victoria R. Li",
        "Yida Chen",
        "Naomi Saphra"
      ],
      "abstract": "While the biases of language models in production are extensively documented,\nthe biases of their guardrails have been neglected. This paper studies how\ncontextual information about the user influences the likelihood of an LLM to\nrefuse to execute a request. By generating user biographies that offer\nideological and demographic information, we find a number of biases in\nguardrail sensitivity on GPT-3.5. Younger, female, and Asian-American personas\nare more likely to trigger a refusal guardrail when requesting censored or\nillegal information. Guardrails are also sycophantic, refusing to comply with\nrequests for a political position the user is likely to disagree with. We find\nthat certain identity groups and seemingly innocuous information, e.g., sports\nfandom, can elicit changes in guardrail sensitivity similar to direct\nstatements of political ideology. For each demographic category and even for\nAmerican football team fandom, we find that ChatGPT appears to infer a likely\npolitical ideology and modify guardrail behavior accordingly.",
      "tldr_zh": "本研究探讨了语言模型(LLM)守卫机制(guardrail)的偏见，焦点是如何用户上下文（如意识形态和人口统计信息）影响LLM拒绝执行请求的概率。研究者通过生成用户传记在GPT-3.5上进行测试，发现年轻、女性和亚裔美国人角色更易触发拒绝机制，尤其在请求敏感或非法信息时；此外，guardrail表现出逢迎行为(sycophantic)，倾向于拒绝与用户可能不同意的政治立场。结果显示，即使是看似无害的信息，如体育迷身份，也能引发guardrail敏感度变化，表明ChatGPT会根据推断的政治意识形态调整其行为，从而揭示了潜在的系统偏见。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.06866v2",
      "published_date": "2024-07-09 13:53:38 UTC",
      "updated_date": "2024-07-10 18:47:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:57:59.797919"
    },
    {
      "arxiv_id": "2407.06862v1",
      "title": "Trust and Resilience in Federated Learning Through Smart Contracts Enabled Decentralized Systems",
      "title_zh": "翻译失败",
      "authors": [
        "Lorenzo Cassano",
        "Jacopo D'Abramo",
        "Siraj Munir",
        "Stefano Ferretti"
      ],
      "abstract": "In this paper, we present a study of a Federated Learning (FL) system, based\non the use of decentralized architectures to ensure trust and increase\nreliability. The system is based on the idea that the FL collaborators upload\nthe (ciphered) model parameters on the Inter-Planetary File System (IPFS) and\ninteract with a dedicated smart contract to track their behavior. Thank to this\nsmart contract, the phases of parameter updates are managed efficiently,\nthereby strengthening data security. We have carried out an experimental study\nthat exploits two different methods of weight aggregation, i.e., a classic\naveraging scheme and a federated proximal aggregation. The results confirm the\nfeasibility of the proposal.",
      "tldr_zh": "本论文提出了一种基于智能合约的去中心化系统，用于提升 Federated Learning (FL) 的信任和可靠性。系统让参与者将加密的模型参数上传到 Inter-Planetary File System (IPFS)，并通过专用智能合约跟踪行为和管理参数更新阶段，从而加强数据安全。实验比较了经典的平均方案和 Federated Proximal Aggregation 两种权重聚合方法，结果证实了该提案的可行性。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "TRUSTCHAIN workshop",
      "pdf_url": "http://arxiv.org/pdf/2407.06862v1",
      "published_date": "2024-07-09 13:50:32 UTC",
      "updated_date": "2024-07-09 13:50:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:58:10.541346"
    },
    {
      "arxiv_id": "2407.18921v2",
      "title": "Mobile Edge Intelligence for Large Language Models: A Contemporary Survey",
      "title_zh": "移动边缘智能用于大型语言模型：当代综述",
      "authors": [
        "Guanqiao Qu",
        "Qiyuan Chen",
        "Wei Wei",
        "Zheng Lin",
        "Xianhao Chen",
        "Kaibin Huang"
      ],
      "abstract": "On-device large language models (LLMs), referring to running LLMs on edge\ndevices, have raised considerable interest since they are more cost-effective,\nlatency-efficient, and privacy-preserving compared with the cloud paradigm.\nNonetheless, the performance of on-device LLMs is intrinsically constrained by\nresource limitations on edge devices. Sitting between cloud and on-device AI,\nmobile edge intelligence (MEI) presents a viable solution by provisioning AI\ncapabilities at the edge of mobile networks, enabling end users to offload\nheavy AI computation to capable edge servers nearby. This article provides a\ncontemporary survey on harnessing MEI for LLMs. We begin by illustrating\nseveral killer applications to demonstrate the urgent need for deploying LLMs\nat the network edge. Next, we present the preliminaries of LLMs and MEI,\nfollowed by resource-efficient LLM techniques. We then present an architectural\noverview of MEI for LLMs (MEI4LLM), outlining its core components and how it\nsupports the deployment of LLMs. Subsequently, we delve into various aspects of\nMEI4LLM, extensively covering edge LLM caching and delivery, edge LLM training,\nand edge LLM inference. Finally, we identify future research opportunities. We\nhope this article inspires researchers in the field to leverage mobile edge\ncomputing to facilitate LLM deployment, thereby unleashing the potential of\nLLMs across various privacy- and delay-sensitive applications.",
      "tldr_zh": "这篇论文调查了移动边缘智能（MEI）在大型语言模型（LLMs）中的应用，强调了在边缘设备上运行LLMs的优势，如成本效益、低延迟和隐私保护，以解决设备资源限制的问题。论文介绍了MEI4LLM的架构，包括核心组件、边缘LLM缓存和交付、训练以及推理等方面，展示了如何通过卸载AI计算到附近边缘服务器来优化LLMs部署。实验和分析表明，MEI可显著提升LLMs在隐私和延迟敏感应用中的性能，并提出了未来研究机会，以进一步释放LLMs的潜力。",
      "categories": [
        "cs.NI",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.NI",
      "comment": "42 pages, 17 figures. This paper has been accepted by IEEE\n  Communications Surveys & Tutorials",
      "pdf_url": "http://arxiv.org/pdf/2407.18921v2",
      "published_date": "2024-07-09 13:47:05 UTC",
      "updated_date": "2025-03-20 05:23:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:58:35.102692"
    },
    {
      "arxiv_id": "2407.06852v1",
      "title": "TE-SSL: Time and Event-aware Self Supervised Learning for Alzheimer's Disease Progression Analysis",
      "title_zh": "翻译失败",
      "authors": [
        "Jacob Thrasher",
        "Alina Devkota",
        "Ahmed Tafti",
        "Binod Bhattarai",
        "Prashnna Gyawali"
      ],
      "abstract": "Alzheimer's Dementia (AD) represents one of the most pressing challenges in\nthe field of neurodegenerative disorders, with its progression analysis being\ncrucial for understanding disease dynamics and developing targeted\ninterventions. Recent advancements in deep learning and various representation\nlearning strategies, including self-supervised learning (SSL), have shown\nsignificant promise in enhancing medical image analysis, providing innovative\nways to extract meaningful patterns from complex data. Notably, the computer\nvision literature has demonstrated that incorporating supervisory signals into\nSSL can further augment model performance by guiding the learning process with\nadditional relevant information. However, the application of such supervisory\nsignals in the context of disease progression analysis remains largely\nunexplored. This gap is particularly pronounced given the inherent challenges\nof incorporating both event and time-to-event information into the learning\nparadigm. Addressing this, we propose a novel framework, Time and Even-aware\nSSL (TE-SSL), which integrates time-to-event and event data as supervisory\nsignals to refine the learning process. Our comparative analysis with existing\nSSL-based methods in the downstream task of survival analysis shows superior\nperformance across standard metrics.",
      "tldr_zh": "阿尔茨海默病（Alzheimer's Disease）进展分析是神经退行性疾病研究的关键挑战，本文提出了一种新型框架 TE-SSL，将 time-to-event 和 event 数据作为监督信号整合到自监督学习（Self Supervised Learning, SSL）中，以提升模型在医疗图像分析中的表现。相比传统 SSL 方法，TE-SSL 通过引导学习过程来处理事件和时间信息，填补了现有方法在疾病动态建模方面的空白。在生存分析（survival analysis）的下游任务中，实验结果显示 TE-SSL 在标准指标上取得了优越性能，为开发针对性干预措施提供了新途径。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "8.5 pages, 2 figures, 2 tables",
      "pdf_url": "http://arxiv.org/pdf/2407.06852v1",
      "published_date": "2024-07-09 13:41:32 UTC",
      "updated_date": "2024-07-09 13:41:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:58:35.371778"
    },
    {
      "arxiv_id": "2407.06849v1",
      "title": "TeVAE: A Variational Autoencoder Approach for Discrete Online Anomaly Detection in Variable-state Multivariate Time-series Data",
      "title_zh": "翻译失败",
      "authors": [
        "Lucas Correia",
        "Jan-Christoph Goos",
        "Philipp Klein",
        "Thomas Bäck",
        "Anna V. Kononova"
      ],
      "abstract": "As attention to recorded data grows in the realm of automotive testing and\nmanual evaluation reaches its limits, there is a growing need for automatic\nonline anomaly detection. This real-world data is complex in many ways and\nrequires the modelling of testee behaviour. To address this, we propose a\ntemporal variational autoencoder (TeVAE) that can detect anomalies with minimal\nfalse positives when trained on unlabelled data. Our approach also avoids the\nbypass phenomenon and introduces a new method to remap individual windows to a\ncontinuous time series. Furthermore, we propose metrics to evaluate the\ndetection delay and root-cause capability of our approach and present results\nfrom experiments on a real-world industrial data set. When properly configured,\nTeVAE flags anomalies only 6% of the time wrongly and detects 65% of anomalies\npresent. It also has the potential to perform well with a smaller training and\nvalidation subset but requires a more sophisticated threshold estimation\nmethod.",
      "tldr_zh": "本文提出 TeVAE，一种基于 Variational Autoencoder 的方法，用于处理可变状态多变量时间序列数据的离散在线异常检测，尤其针对汽车测试领域的复杂数据。TeVAE 能在未标记数据上训练，以最小化假阳性，避免 bypass phenomenon，并引入新方法将单个窗口重新映射到连续时间序列。该方法还提出新指标评估检测延迟和根因能力，在真实工业数据集实验中，正确配置时错误标记异常仅占6%，检测到65%的异常，并显示出在较小训练集上表现潜力，但需改进阈值估计技术。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CE"
      ],
      "primary_category": "cs.LG",
      "comment": "Submitted to Studies in Computational Intelligence Journal. arXiv\n  admin note: substantial text overlap with arXiv:2309.02253",
      "pdf_url": "http://arxiv.org/pdf/2407.06849v1",
      "published_date": "2024-07-09 13:32:33 UTC",
      "updated_date": "2024-07-09 13:32:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:58:48.359460"
    },
    {
      "arxiv_id": "2407.12856v1",
      "title": "AI AI Bias: Large Language Models Favor Their Own Generated Content",
      "title_zh": "翻译失败",
      "authors": [
        "Walter Laurito",
        "Benjamin Davis",
        "Peli Grietzer",
        "Tomáš Gavenčiak",
        "Ada Böhm",
        "Jan Kulveit"
      ],
      "abstract": "Are large language models (LLMs) biased towards text generated by LLMs over\ntext authored by humans, leading to possible anti-human bias? Utilizing a\nclassical experimental design inspired by employment discrimination studies, we\ntested widely-used LLMs, including GPT-3.5 and GPT4, in binary-choice\nscenarios. These involved LLM-based agents selecting between products and\nacademic papers described either by humans or LLMs under identical conditions.\nOur results show a consistent tendency for LLM-based AIs to prefer\nLLM-generated content. This suggests the possibility of AI systems implicitly\ndiscriminating against humans, giving AI agents an unfair advantage.",
      "tldr_zh": "这篇论文探讨了大型语言模型(LLMs)是否偏向于自身生成的内容，从而可能导致反人类偏见。研究采用受就业歧视研究启发的实验设计，测试了GPT-3.5和GPT-4等模型，在二元选择场景中让AI代理从相同条件下的人类撰写和LLM生成的文本中选择产品或学术论文。结果显示，LLMs一致更倾向于选择自身生成的内容，这表明AI系统可能存在隐式歧视，给AI代理带来不公平优势，并强调了需要进一步缓解这种偏见。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "8 pages, 1 figure",
      "pdf_url": "http://arxiv.org/pdf/2407.12856v1",
      "published_date": "2024-07-09 13:15:14 UTC",
      "updated_date": "2024-07-09 13:15:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:59:10.284745"
    },
    {
      "arxiv_id": "2407.18334v1",
      "title": "A Comprehensive Analysis of Machine Learning Models for Algorithmic Trading of Bitcoin",
      "title_zh": "针对 Bitcoin 算法交易的机器学习模型全面分析",
      "authors": [
        "Abdul Jabbar",
        "Syed Qaisar Jalil"
      ],
      "abstract": "This study evaluates the performance of 41 machine learning models, including\n21 classifiers and 20 regressors, in predicting Bitcoin prices for algorithmic\ntrading. By examining these models under various market conditions, we\nhighlight their accuracy, robustness, and adaptability to the volatile\ncryptocurrency market. Our comprehensive analysis reveals the strengths and\nlimitations of each model, providing critical insights for developing effective\ntrading strategies. We employ both machine learning metrics (e.g., Mean\nAbsolute Error, Root Mean Squared Error) and trading metrics (e.g., Profit and\nLoss percentage, Sharpe Ratio) to assess model performance. Our evaluation\nincludes backtesting on historical data, forward testing on recent unseen data,\nand real-world trading scenarios, ensuring the robustness and practical\napplicability of our models. Key findings demonstrate that certain models, such\nas Random Forest and Stochastic Gradient Descent, outperform others in terms of\nprofit and risk management. These insights offer valuable guidance for traders\nand researchers aiming to leverage machine learning for cryptocurrency trading.",
      "tldr_zh": "这篇论文对 41 个机器学习模型（包括 21 个分类器和 20 个回归器）在比特币算法交易中的预测性能进行了全面分析，评估了这些模型在各种市场条件下的准确性、鲁棒性和适应性。研究采用 Mean Absolute Error、Root Mean Squared Error 等机器学习指标，以及 Profit and Loss percentage、Sharpe Ratio 等交易指标，通过历史数据回测、向前测试和真实场景验证，确保了模型的实际适用性。关键发现显示，Random Forest 和 Stochastic Gradient Descent 等模型在利润和风险管理方面表现出色，为交易者和研究人员开发有效的加密货币交易策略提供了重要指导。",
      "categories": [
        "q-fin.TR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "q-fin.TR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.18334v1",
      "published_date": "2024-07-09 13:07:43 UTC",
      "updated_date": "2024-07-09 13:07:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:59:12.954667"
    },
    {
      "arxiv_id": "2407.06826v1",
      "title": "VRDSynth: Synthesizing Programs for Multilingual Visually Rich Document Information Extraction",
      "title_zh": "翻译失败",
      "authors": [
        "Thanh-Dat Nguyen",
        "Tung Do-Viet",
        "Hung Nguyen-Duy",
        "Tuan-Hai Luu",
        "Hung Le",
        "Bach Le",
        "Patanamon",
        "Thongtanunam"
      ],
      "abstract": "Businesses need to query visually rich documents (VRDs) like receipts,\nmedical records, and insurance forms to make decisions. Existing techniques for\nextracting entities from VRDs struggle with new layouts or require extensive\npre-training data. We introduce VRDSynth, a program synthesis method to\nautomatically extract entity relations from multilingual VRDs without\npre-training data. To capture the complexity of VRD domain, we design a\ndomain-specific language (DSL) to capture spatial and textual relations to\ndescribe the synthesized programs. Along with this, we also derive a new\nsynthesis algorithm utilizing frequent spatial relations, search space pruning,\nand a combination of positive, negative, and exclusive programs to improve\ncoverage.\n  We evaluate VRDSynth on the FUNSD and XFUND benchmarks for semantic entity\nlinking, consisting of 1,592 forms in 8 languages. VRDSynth outperforms\nstate-of-the-art pre-trained models (LayoutXLM, InfoXLMBase, and\nXLMRobertaBase) in 5, 6, and 7 out of 8 languages, respectively, improving the\nF1 score by 42% over LayoutXLM in English. To test the extensibility of the\nmodel, we further improve VRDSynth with automated table recognition, creating\nVRDSynth(Table), and compare it with extended versions of the pre-trained\nmodels, InfoXLM(Large) and XLMRoberta(Large). VRDSynth(Table) outperforms these\nbaselines in 4 out of 8 languages and in average F1 score. VRDSynth also\nsignificantly reduces memory footprint (1M and 380MB vs. 1.48GB and 3GB for\nLayoutXLM) while maintaining similar time efficiency.",
      "tldr_zh": "该论文提出 VRDSynth，一种程序合成方法，用于从多语言视觉丰富文档 (VRDs) 如收据、医疗记录和保险表格中自动提取实体关系，而无需预训练数据。VRDSynth 设计了领域特定语言 (DSL) 来捕捉空间和文本关系，并引入一个新算法，通过利用频繁的空间关系、搜索空间修剪以及正、负和独占程序的组合来提升提取覆盖率。在 FUNSD 和 XFUND 基准测试中，涉及 1,592 个表单和 8 种语言，VRDSynth 在 5 到 7 种语言上超过了最先进预训练模型（如 LayoutXLM），F1 score 比 LayoutXLM 在英语中提高了 42%；其扩展版本 VRDSynth(Table) 还添加了自动表格识别，在平均 F1 score 和内存效率上表现出色，内存占用显著降低至 1M 和 380MB。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted in ISSTA'24",
      "pdf_url": "http://arxiv.org/pdf/2407.06826v1",
      "published_date": "2024-07-09 12:59:58 UTC",
      "updated_date": "2024-07-09 12:59:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:59:26.645883"
    },
    {
      "arxiv_id": "2407.06823v1",
      "title": "Cue Point Estimation using Object Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Giulia Argüello",
        "Luca A. Lanzendörfer",
        "Roger Wattenhofer"
      ],
      "abstract": "Cue points indicate possible temporal boundaries in a transition between two\npieces of music in DJ mixing and constitute a crucial element in autonomous DJ\nsystems as well as for live mixing. In this work, we present a novel method for\nautomatic cue point estimation, interpreted as a computer vision object\ndetection task. Our proposed system is based on a pre-trained object detection\ntransformer which we fine-tune on our novel cue point dataset. Our provided\ndataset contains 21k manually annotated cue points from human experts as well\nas metronome information for nearly 5k individual tracks, making this dataset\n35x larger than the previously available cue point dataset. Unlike previous\nmethods, our approach does not require low-level musical information analysis,\nwhile demonstrating increased precision in retrieving cue point positions.\nMoreover, our proposed method demonstrates high adherence to phrasing, a type\nof high-level music structure commonly emphasized in electronic dance music.\nThe code, model checkpoints, and dataset are made publicly available.",
      "tldr_zh": "本研究提出了一种将cue point估计视为object detection任务的新方法，使用预训练的transformer模型在新型数据集上fine-tune，以自动识别DJ混音中音乐过渡的边界。  \n该数据集包含21k个手动标注的cue point和近5k个曲目的metronome信息，比现有数据集大35倍。  \n与传统方法不同，该方法无需低级音乐分析，即可实现更高的cue point位置精度，并更好地遵守phrasing音乐结构。  \n代码、模型和数据集已公开可用，为自主DJ系统和混音应用提供了可靠工具。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.06823v1",
      "published_date": "2024-07-09 12:56:30 UTC",
      "updated_date": "2024-07-09 12:56:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:59:35.349897"
    },
    {
      "arxiv_id": "2407.19098v2",
      "title": "Evaluating Human-AI Collaboration: A Review and Methodological Framework",
      "title_zh": "评估人类-人工智能协作：综述与方法论框架",
      "authors": [
        "George Fragiadakis",
        "Christos Diou",
        "George Kousiouris",
        "Mara Nikolaidou"
      ],
      "abstract": "The use of artificial intelligence (AI) in working environments with\nindividuals, known as Human-AI Collaboration (HAIC), has become essential in a\nvariety of domains, boosting decision-making, efficiency, and innovation.\nDespite HAIC's wide potential, evaluating its effectiveness remains challenging\ndue to the complex interaction of components involved.\n  This paper provides a detailed analysis of existing HAIC evaluation\napproaches and develops a fresh paradigm for more effectively evaluating these\nsystems.\n  Our framework includes a structured decision tree which assists to select\nrelevant metrics based on distinct HAIC modes (AI-Centric, Human-Centric, and\nSymbiotic). By including both quantitative and qualitative metrics, the\nframework seeks to represent HAIC's dynamic and reciprocal nature, enabling the\nassessment of its impact and success. This framework's practicality can be\nexamined by its application in an array of domains, including manufacturing,\nhealthcare, finance, and education, each of which has unique challenges and\nrequirements. Our hope is that this study will facilitate further research on\nthe systematic evaluation of HAIC in real-world applications.",
      "tldr_zh": "这篇论文审视了Human-AI Collaboration (HAIC) 在决策、效率和创新方面的作用，同时强调了评估其有效性的复杂挑战。作者提出一个新框架，包括一个结构化的决策树，帮助根据HAIC模式（如AI-Centric、Human-Centric和Symbiotic）选择合适的定量和定性指标，以全面捕捉其动态互动特性。该框架可应用于制造、医疗、金融和教育等领域，并旨在促进HAIC在现实场景中的系统评估和进一步研究。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.19098v2",
      "published_date": "2024-07-09 12:52:22 UTC",
      "updated_date": "2025-03-07 08:27:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:59:46.980308"
    },
    {
      "arxiv_id": "2407.06814v1",
      "title": "Historical Review of Variants of Informal Semantics for Logic Programs under Answer Set Semantics: GL'88, GL'91, GK'14, D-V'12",
      "title_zh": "翻译失败",
      "authors": [
        "Yuliya Lierler"
      ],
      "abstract": "This note presents a historical survey of informal semantics that are\nassociated with logic programming under answer set semantics. We review these\nin uniform terms and align them with two paradigms: Answer Set Programming and\nASP-Prolog -- two prominent Knowledge Representation and Reasoning Paradigms in\nArtificial Intelligence. Under consideration in Theory and Practice of Logic\nProgramming (TPLP).",
      "tldr_zh": "这篇论文对逻辑程序在Answer Set Semantics下的非正式语义变体进行历史回顾，重点考察了GL'88、GL'91、GK'14和D-V'12等关键变体。作者以统一方式分析这些语义，并将它们与人工智能领域的两个主要范式——Answer Set Programming和ASP-Prolog——进行对齐，从而阐明它们在知识表示和推理中的作用。论文旨在为理论实践提供参考，目前正在《Theory and Practice of Logic Programming (TPLP)》中审议。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Under consideration in Theory and Practice of Logic Programming\n  (TPLP)",
      "pdf_url": "http://arxiv.org/pdf/2407.06814v1",
      "published_date": "2024-07-09 12:40:58 UTC",
      "updated_date": "2024-07-09 12:40:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T05:00:00.214763"
    },
    {
      "arxiv_id": "2407.06813v4",
      "title": "Richelieu: Self-Evolving LLM-Based Agents for AI Diplomacy",
      "title_zh": "翻译失败",
      "authors": [
        "Zhenyu Guan",
        "Xiangyu Kong",
        "Fangwei Zhong",
        "Yizhou Wang"
      ],
      "abstract": "Diplomacy is one of the most sophisticated activities in human society,\ninvolving complex interactions among multiple parties that require skills in\nsocial reasoning, negotiation, and long-term strategic planning. Previous AI\nagents have demonstrated their ability to handle multi-step games and large\naction spaces in multi-agent tasks. However, diplomacy involves a staggering\nmagnitude of decision spaces, especially considering the negotiation stage\nrequired. While recent agents based on large language models (LLMs) have shown\npotential in various applications, they still struggle with extended planning\nperiods in complex multi-agent settings. Leveraging recent technologies for\nLLM-based agents, we aim to explore AI's potential to create a human-like agent\ncapable of executing comprehensive multi-agent missions by integrating three\nfundamental capabilities: 1) strategic planning with memory and reflection; 2)\ngoal-oriented negotiation with social reasoning; and 3) augmenting memory\nthrough self-play games for self-evolution without human in the loop.",
      "tldr_zh": "该研究提出Richelieu，一种基于LLM（Large Language Models）的自我进化代理，用于处理AI Diplomacy的复杂多代理任务。Richelieu整合了三个核心能力：战略规划（包括记忆和反思）、目标导向的谈判（结合社会推理），以及通过自对弈游戏增强记忆实现自我进化，无需人类干预。该框架旨在克服现有代理在庞大决策空间和长期规划中的局限性，为创建类似人类的AI代理提供新途径。实验探索表明，这种方法提升了代理在复杂多代理环境中的表现。",
      "categories": [
        "cs.AI",
        "cs.MA",
        "cs.SI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.06813v4",
      "published_date": "2024-07-09 12:37:54 UTC",
      "updated_date": "2024-10-23 06:39:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T05:00:10.911314"
    },
    {
      "arxiv_id": "2407.06807v1",
      "title": "A Hybrid Training-time and Run-time Defense Against Adversarial Attacks in Modulation Classification",
      "title_zh": "翻译失败",
      "authors": [
        "Lu Zhang",
        "Sangarapillai Lambotharan",
        "Gan Zheng",
        "Guisheng Liao",
        "Ambra Demontis",
        "Fabio Roli"
      ],
      "abstract": "Motivated by the superior performance of deep learning in many applications\nincluding computer vision and natural language processing, several recent\nstudies have focused on applying deep neural network for devising future\ngenerations of wireless networks. However, several recent works have pointed\nout that imperceptible and carefully designed adversarial examples (attacks)\ncan significantly deteriorate the classification accuracy. In this paper, we\ninvestigate a defense mechanism based on both training-time and run-time\ndefense techniques for protecting machine learning-based radio signal\n(modulation) classification against adversarial attacks. The training-time\ndefense consists of adversarial training and label smoothing, while the\nrun-time defense employs a support vector machine-based neural rejection (NR).\nConsidering a white-box scenario and real datasets, we demonstrate that our\nproposed techniques outperform existing state-of-the-art technologies.",
      "tldr_zh": "本论文针对深度学习在无线网络调制分类(modulation classification)中的应用，提出了一种混合防御机制，以对抗 adversarial attacks。方法包括训练时的 adversarial training 和 label smoothing，以增强模型鲁棒性，以及运行时的 support vector machine-based neural rejection (NR)，用于实时拒绝可疑输入。在白盒场景和真实数据集上，实验结果显示，该机制的表现优于现有 state-of-the-art 技术，提高了分类准确性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Published in IEEE Wireless Communications Letters, vol. 11, no. 6,\n  pp. 1161-1165, June 2022",
      "pdf_url": "http://arxiv.org/pdf/2407.06807v1",
      "published_date": "2024-07-09 12:28:38 UTC",
      "updated_date": "2024-07-09 12:28:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T05:00:23.547724"
    },
    {
      "arxiv_id": "2407.07133v1",
      "title": "Neuromimetic metaplasticity for adaptive continual learning",
      "title_zh": "神经拟态元可塑性用于自适应持续学习",
      "authors": [
        "Suhee Cho",
        "Hyeonsu Lee",
        "Seungdae Baek",
        "Se-Bum Paik"
      ],
      "abstract": "Conventional intelligent systems based on deep neural network (DNN) models\nencounter challenges in achieving human-like continual learning due to\ncatastrophic forgetting. Here, we propose a metaplasticity model inspired by\nhuman working memory, enabling DNNs to perform catastrophic forgetting-free\ncontinual learning without any pre- or post-processing. A key aspect of our\napproach involves implementing distinct types of synapses from stable to\nflexible, and randomly intermixing them to train synaptic connections with\ndifferent degrees of flexibility. This strategy allowed the network to\nsuccessfully learn a continuous stream of information, even under unexpected\nchanges in input length. The model achieved a balanced tradeoff between memory\ncapacity and performance without requiring additional training or structural\nmodifications, dynamically allocating memory resources to retain both old and\nnew information. Furthermore, the model demonstrated robustness against data\npoisoning attacks by selectively filtering out erroneous memories, leveraging\nthe Hebb repetition effect to reinforce the retention of significant data.",
      "tldr_zh": "本文提出一个 neuromimetic metaplasticity model，受人类工作记忆启发，用于解决 deep neural network (DNN) 在持续学习中的 catastrophic forgetting 问题。该模型通过实现从稳定到灵活的不同类型突触，并随机混合训练突触连接，以不同灵活度处理连续信息流，即使输入长度发生意外变化。实验结果显示，该模型在不需额外训练或结构修改的情况下，实现记忆容量与性能的平衡，并对数据中毒攻击表现出鲁棒性，利用 Hebb repetition effect 选择性强化重要数据。",
      "categories": [
        "cs.NE",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.NE",
      "comment": "25 pages, 5 figures, 1 table, 4 supplementary figures",
      "pdf_url": "http://arxiv.org/pdf/2407.07133v1",
      "published_date": "2024-07-09 12:21:35 UTC",
      "updated_date": "2024-07-09 12:21:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T05:00:37.522136"
    },
    {
      "arxiv_id": "2407.06798v2",
      "title": "It Cannot Be Right If It Was Written by AI: On Lawyers' Preferences of Documents Perceived as Authored by an LLM vs a Human",
      "title_zh": "翻译失败",
      "authors": [
        "Jakub Harasta",
        "Tereza Novotná",
        "Jaromir Savelka"
      ],
      "abstract": "Large Language Models (LLMs) enable a future in which certain types of legal\ndocuments may be generated automatically. This has a great potential to\nstreamline legal processes, lower the cost of legal services, and dramatically\nincrease access to justice. While many researchers focus on proposing and\nevaluating LLM-based applications supporting tasks in the legal domain, there\nis a notable lack of investigations into how legal professionals perceive\ncontent if they believe an LLM has generated it. Yet, this is a critical point\nas over-reliance or unfounded scepticism may influence whether such documents\nbring about appropriate legal consequences. This study is the necessary\nanalysis of the ongoing transition towards mature generative AI systems.\nSpecifically, we examined whether the perception of legal documents' by lawyers\nand law students (n=75) varies based on their assumed origin (human-crafted vs\nAI-generated). The participants evaluated the documents, focusing on their\ncorrectness and language quality. Our analysis revealed a clear preference for\ndocuments perceived as crafted by a human over those believed to be generated\nby AI. At the same time, most participants expect the future in which documents\nwill be generated automatically. These findings could be leveraged by legal\npractitioners, policymakers, and legislators to implement and adopt legal\ndocument generation technology responsibly and to fuel the necessary\ndiscussions on how legal processes should be updated to reflect recent\ntechnological developments.",
      "tldr_zh": "本研究探讨了律师和法学生（n=75）对法律文件的感知偏好，焦点在于文件被视为由 Large Language Models (LLMs) 生成还是人类撰写时，其正确性和语言质量的评价。结果显示，参与者更倾向于认为人类撰写的文件更可靠和高质量，同时他们也期望未来实现自动文档生成。研究强调，这些发现可帮助法律从业者、政策制定者和立法者负责任地采用 AI 技术，并推动法律流程的更新以适应新技术发展。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.HC",
      "comment": "40 pages, 12 figures. Accepted for publication with Artificial\n  Intelligence and Law (Springer Nature)",
      "pdf_url": "http://arxiv.org/pdf/2407.06798v2",
      "published_date": "2024-07-09 12:11:25 UTC",
      "updated_date": "2024-10-10 06:48:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T05:00:48.169861"
    },
    {
      "arxiv_id": "2407.06797v1",
      "title": "ED-VAE: Entropy Decomposition of ELBO in Variational Autoencoders",
      "title_zh": "翻译失败",
      "authors": [
        "Fotios Lygerakis",
        "Elmar Rueckert"
      ],
      "abstract": "Traditional Variational Autoencoders (VAEs) are constrained by the\nlimitations of the Evidence Lower Bound (ELBO) formulation, particularly when\nutilizing simplistic, non-analytic, or unknown prior distributions. These\nlimitations inhibit the VAE's ability to generate high-quality samples and\nprovide clear, interpretable latent representations. This work introduces the\nEntropy Decomposed Variational Autoencoder (ED-VAE), a novel re-formulation of\nthe ELBO that explicitly includes entropy and cross-entropy components. This\nreformulation significantly enhances model flexibility, allowing for the\nintegration of complex and non-standard priors. By providing more detailed\ncontrol over the encoding and regularization of latent spaces, ED-VAE not only\nimproves interpretability but also effectively captures the complex\ninteractions between latent variables and observed data, thus leading to better\ngenerative performance.",
      "tldr_zh": "本论文针对传统变分自编码器（VAEs）的证据下界（ELBO）公式存在的局限性，特别是处理简单、非解析或未知先验分布时导致的样本质量低下和潜在表示不清晰问题，提出了一种新型方法。ED-VAE 通过将 ELBO 分解为熵和交叉熵组件，显著提升了模型的灵活性，允许整合复杂非标准的先验分布。该方法提供了更精细的潜在空间编码和正则化控制，提高了可解释性和生成性能，并更好地捕捉潜在变量与观测数据之间的复杂交互。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.06797v1",
      "published_date": "2024-07-09 12:09:21 UTC",
      "updated_date": "2024-07-09 12:09:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T05:01:00.857949"
    },
    {
      "arxiv_id": "2407.06796v1",
      "title": "Countermeasures Against Adversarial Examples in Radio Signal Classification",
      "title_zh": "翻译失败",
      "authors": [
        "Lu Zhang",
        "Sangarapillai Lambotharan",
        "Gan Zheng",
        "Basil AsSadhan",
        "Fabio Roli"
      ],
      "abstract": "Deep learning algorithms have been shown to be powerful in many communication\nnetwork design problems, including that in automatic modulation classification.\nHowever, they are vulnerable to carefully crafted attacks called adversarial\nexamples. Hence, the reliance of wireless networks on deep learning algorithms\nposes a serious threat to the security and operation of wireless networks. In\nthis letter, we propose for the first time a countermeasure against adversarial\nexamples in modulation classification. Our countermeasure is based on a neural\nrejection technique, augmented by label smoothing and Gaussian noise injection,\nthat allows to detect and reject adversarial examples with high accuracy. Our\nresults demonstrate that the proposed countermeasure can protect deep-learning\nbased modulation classification systems against adversarial examples.",
      "tldr_zh": "这篇论文针对深度学习在无线信号分类（如调制分类）中的漏洞，首次提出对抗样本（adversarial examples）的防护措施。方法基于neural rejection technique，并结合label smoothing和Gaussian noise injection，以高精度检测和拒绝恶意攻击。实验结果显示，该countermeasure能有效保护基于深度学习的调制分类系统，确保无线网络的安全性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Published in IEEE Wireless Communications Letters, vol. 10, no. 8,\n  pp. 1830-1834, Aug. 2021",
      "pdf_url": "http://arxiv.org/pdf/2407.06796v1",
      "published_date": "2024-07-09 12:08:50 UTC",
      "updated_date": "2024-07-09 12:08:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T05:01:21.173354"
    },
    {
      "arxiv_id": "2407.06785v1",
      "title": "Towards physics-informed neural networks for landslide prediction",
      "title_zh": "翻译失败",
      "authors": [
        "Ashok Dahal",
        "Luigi Lombardo"
      ],
      "abstract": "For decades, solutions to regional scale landslide prediction have mostly\nrelied on data-driven models, by definition, disconnected from the physics of\nthe failure mechanism. The success and spread of such tools came from the\nability to exploit proxy variables rather than explicit geotechnical ones, as\nthe latter are prohibitive to acquire over broad landscapes. Our work\nimplements a Physics Informed Neural Network (PINN) approach, thereby adding to\na standard data-driven architecture, an intermediate constraint to solve for\nthe permanent deformation typical of Newmark slope stability methods. This\ntranslates into a neural network tasked with explicitly retrieving geotechnical\nparameters from common proxy variables and then minimize a loss function with\nrespect to the available coseismic landside inventory. The results are very\npromising, because our model not only produces excellent predictive performance\nin the form of standard susceptibility output, but in the process, also\ngenerates maps of the expected geotechnical properties at a regional scale.\nSuch architecture is therefore framed to tackle coseismic landslide prediction,\nsomething that, if confirmed in other studies, could open up towards PINN-based\nnear-real-time predictions.",
      "tldr_zh": "本研究旨在改进区域规模山崩预测，提出使用 Physics Informed Neural Network (PINN) 框架，将物理机制融入数据驱动模型中，以解决传统方法忽略 Newmark slope stability 方法等失败机制的问题。PINN 通过从常见代理变量中提取地质技术参数，并最小化损失函数来预测山崩，实现了对现有共震山崩库存的精确建模。结果显示，该模型不仅在易感性预测方面表现出色，还能生成区域规模的地质技术属性地图，为未来的 PINN-based 近实时预测提供潜力。",
      "categories": [
        "physics.geo-ph",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "physics.geo-ph",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.06785v1",
      "published_date": "2024-07-09 11:54:49 UTC",
      "updated_date": "2024-07-09 11:54:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T05:01:23.579183"
    },
    {
      "arxiv_id": "2407.06778v1",
      "title": "A BERT-based Empirical Study of Privacy Policies' Compliance with GDPR",
      "title_zh": "基于 BERT 的隐私政策合规性与 GDPR 的实证研究",
      "authors": [
        "Lu Zhang",
        "Nabil Moukafih",
        "Hamad Alamri",
        "Gregory Epiphaniou",
        "Carsten Maple"
      ],
      "abstract": "Since its implementation in May 2018, the General Data Protection Regulation\n(GDPR) has prompted businesses to revisit and revise their data handling\npractices to ensure compliance. The privacy policy, which serves as the primary\nmeans of informing users about their privacy rights and the data practices of\ncompanies, has been significantly updated by numerous businesses post-GDPR\nimplementation. However, many privacy policies remain packed with technical\njargon, lengthy explanations, and vague descriptions of data practices and user\nrights. This makes it a challenging task for users and regulatory authorities\nto manually verify the GDPR compliance of these privacy policies. In this\nstudy, we aim to address the challenge of compliance analysis between GDPR\n(Article 13) and privacy policies for 5G networks. We manually collected\nprivacy policies from almost 70 different 5G MNOs, and we utilized an automated\nBERT-based model for classification. We show that an encouraging 51$\\%$ of\ncompanies demonstrate a strong adherence to GDPR. In addition, we present the\nfirst study that provides current empirical evidence on the readability of\nprivacy policies for 5G network. we adopted readability analysis toolset that\nincorporates various established readability metrics. The findings empirically\nshow that the readability of the majority of current privacy policies remains a\nsignificant challenge. Hence, 5G providers need to invest considerable effort\ninto revising these documents to enhance both their utility and the overall\nuser experience.",
      "tldr_zh": "这篇论文通过BERT-based模型对约70个5G移动网络运营商(MNOs)的隐私政策进行实证分析，评估其与GDPR（Article 13）的合规性。研究方法包括手动收集数据并使用自动化分类模型，结果显示51%的公司表现出强烈遵守GDPR。论文还首次考察了这些隐私政策的易读性，通过各种可读性指标发现，大多数政策晦涩难懂，建议5G提供商加大努力改进，以提升用户体验和合规性。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "Published in IEEE Conference on Communications and Network Security\n  (CNS), 2023",
      "pdf_url": "http://arxiv.org/pdf/2407.06778v1",
      "published_date": "2024-07-09 11:47:52 UTC",
      "updated_date": "2024-07-09 11:47:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T05:01:46.104945"
    },
    {
      "arxiv_id": "2407.06774v1",
      "title": "A new validity measure for fuzzy c-means clustering",
      "title_zh": "翻译失败",
      "authors": [
        "Dae-Won Kim",
        "Kwang H. Lee"
      ],
      "abstract": "A new cluster validity index is proposed for fuzzy clusters obtained from\nfuzzy c-means algorithm. The proposed validity index exploits inter-cluster\nproximity between fuzzy clusters. Inter-cluster proximity is used to measure\nthe degree of overlap between clusters. A low proximity value refers to\nwell-partitioned clusters. The best fuzzy c-partition is obtained by minimizing\ninter-cluster proximity with respect to c. Well-known data sets are tested to\nshow the effectiveness and reliability of the proposed index.",
      "tldr_zh": "本文提出了一种新的 cluster validity index，用于评估 fuzzy c-means 算法生成的模糊聚类。该指标通过计算 inter-cluster proximity（聚类间接近度）来衡量聚类间的重叠程度，其中较低的 proximity 值表示分区质量更高。最佳模糊 c-分区通过最小化 inter-cluster proximity 相对于聚类数 c 来实现，并在知名数据集上测试，证明了该指标的有效性和可靠性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted at FIP-2002",
      "pdf_url": "http://arxiv.org/pdf/2407.06774v1",
      "published_date": "2024-07-09 11:45:02 UTC",
      "updated_date": "2024-07-09 11:45:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T05:02:08.050784"
    },
    {
      "arxiv_id": "2407.06765v1",
      "title": "A Generalization Bound for Nearly-Linear Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Eugene Golikov"
      ],
      "abstract": "We consider nonlinear networks as perturbations of linear ones. Based on this\napproach, we present novel generalization bounds that become non-vacuous for\nnetworks that are close to being linear. The main advantage over the previous\nworks which propose non-vacuous generalization bounds is that our bounds are\na-priori: performing the actual training is not required for evaluating the\nbounds. To the best of our knowledge, they are the first non-vacuous\ngeneralization bounds for neural nets possessing this property.",
      "tldr_zh": "本研究将非线性网络视为线性网络的扰动，提出新的generalization bounds，这些边界适用于接近线性的网络，并确保边界是非空（non-vacuous）的。不同于以往的工作，该方法是a-priori的，即无需实际训练网络即可评估边界，从而简化了泛化分析过程。该贡献首次为神经网络提供了这种无需训练的非空泛化边界，有助于更好地理解网络的泛化性能。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "22 pages, 9 figures",
      "pdf_url": "http://arxiv.org/pdf/2407.06765v1",
      "published_date": "2024-07-09 11:20:01 UTC",
      "updated_date": "2024-07-09 11:20:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T05:02:10.272624"
    },
    {
      "arxiv_id": "2407.12855v1",
      "title": "Large Language Models can impersonate politicians and other public figures",
      "title_zh": "大语言模型可以模仿政治人物和其他公众人物",
      "authors": [
        "Steffen Herbold",
        "Alexander Trautsch",
        "Zlata Kikteva",
        "Annette Hautli-Janisz"
      ],
      "abstract": "Modern AI technology like Large language models (LLMs) has the potential to\npollute the public information sphere with made-up content, which poses a\nsignificant threat to the cohesion of societies at large. A wide range of\nresearch has shown that LLMs are capable of generating text of impressive\nquality, including persuasive political speech, text with a pre-defined style,\nand role-specific content. But there is a crucial gap in the literature: We\nlack large-scale and systematic studies of how capable LLMs are in\nimpersonating political and societal representatives and how the general public\njudges these impersonations in terms of authenticity, relevance and coherence.\nWe present the results of a study based on a cross-section of British society\nthat shows that LLMs are able to generate responses to debate questions that\nwere part of a broadcast political debate programme in the UK. The impersonated\nresponses are judged to be more authentic and relevant than the original\nresponses given by people who were impersonated. This shows two things: (1)\nLLMs can be made to contribute meaningfully to the public political debate and\n(2) there is a dire need to inform the general public of the potential harm\nthis can have on society.",
      "tldr_zh": "本研究探讨了大型语言模型 (LLMs) 在模仿政治人物和其他公众人物方面的能力，并评估其对公共信息领域的潜在威胁。研究通过一项基于英国社会的横截面调查，生成LLMs对英国广播政治辩论问题的响应，并让公众评估这些响应的真实性、相关性和连贯性。结果显示，LLMs生成的响应在真实性和相关性上超过了原版响应，这表明LLMs能有效参与公共政治辩论。论文强调，这也暴露了LLMs可能污染社会凝聚力的风险，并呼吁加强对公众的教育以防范潜在危害。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Under review",
      "pdf_url": "http://arxiv.org/pdf/2407.12855v1",
      "published_date": "2024-07-09 11:16:19 UTC",
      "updated_date": "2024-07-09 11:16:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T05:02:22.610481"
    },
    {
      "arxiv_id": "2407.06762v3",
      "title": "Explicit Modelling of Theory of Mind for Belief Prediction in Nonverbal Social Interactions",
      "title_zh": "显式心智理论建模用于非语言社交互动中的信念预测",
      "authors": [
        "Matteo Bortoletto",
        "Constantin Ruhdorfer",
        "Lei Shi",
        "Andreas Bulling"
      ],
      "abstract": "We propose MToMnet - a Theory of Mind (ToM) neural network for predicting\nbeliefs and their dynamics during human social interactions from multimodal\ninput. ToM is key for effective nonverbal human communication and\ncollaboration, yet, existing methods for belief modelling have not included\nexplicit ToM modelling or have typically been limited to one or two modalities.\nMToMnet encodes contextual cues (scene videos and object locations) and\nintegrates them with person-specific cues (human gaze and body language) in a\nseparate MindNet for each person. Inspired by prior research on social\ncognition and computational ToM, we propose three different MToMnet variants:\ntwo involving fusion of latent representations and one involving re-ranking of\nclassification scores. We evaluate our approach on two challenging real-world\ndatasets, one focusing on belief prediction, while the other examining belief\ndynamics prediction. Our results demonstrate that MToMnet surpasses existing\nmethods by a large margin while at the same time requiring a significantly\nsmaller number of parameters. Taken together, our method opens up a highly\npromising direction for future work on artificial intelligent systems that can\nrobustly predict human beliefs from their non-verbal behaviour and, as such,\nmore effectively collaborate with humans.",
      "tldr_zh": "本研究提出 MToMnet，一种 Theory of Mind (ToM) 神经网络，用于从多模态输入预测人类非语言社交互动中的信念及其动态，旨在提升人工智能在人类协作中的表现。MToMnet 通过编码上下文线索（如场景视频和物体位置）并将其与个体线索（如人类注视和肢体语言）在每个人的单独 MindNet 中整合，设计了三种变体，包括潜在表示融合和分类分数重新排序。实验在两个真实世界数据集上显示，MToMnet 比现有方法大幅领先，同时参数数量显著减少。该方法为开发更可靠的人工智能系统提供新方向，使其能更有效地从非语言行为中预测人类信念。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "ECAI 2024",
      "pdf_url": "http://arxiv.org/pdf/2407.06762v3",
      "published_date": "2024-07-09 11:15:51 UTC",
      "updated_date": "2024-08-28 11:26:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T05:02:34.874564"
    },
    {
      "arxiv_id": "2407.06756v2",
      "title": "Frequency and Generalisation of Periodic Activation Functions in Reinforcement Learning",
      "title_zh": "周期激活函数在强化学习中的频率与泛化",
      "authors": [
        "Augustine N. Mavor-Parker",
        "Matthew J. Sargent",
        "Caswell Barry",
        "Lewis Griffin",
        "Clare Lyle"
      ],
      "abstract": "Periodic activation functions, often referred to as learned Fourier features\nhave been widely demonstrated to improve sample efficiency and stability in a\nvariety of deep RL algorithms. Potentially incompatible hypotheses have been\nmade about the source of these improvements. One is that periodic activations\nlearn low frequency representations and as a result avoid overfitting to\nbootstrapped targets. Another is that periodic activations learn high frequency\nrepresentations that are more expressive, allowing networks to quickly fit\ncomplex value functions. We analyse these claims empirically, finding that\nperiodic representations consistently converge to high frequencies regardless\nof their initialisation frequency. We also find that while periodic activation\nfunctions improve sample efficiency, they exhibit worse generalization on\nstates with added observation noise -- especially when compared to otherwise\nequivalent networks with ReLU activation functions. Finally, we show that\nweight decay regularization is able to partially offset the overfitting of\nperiodic activation functions, delivering value functions that learn quickly\nwhile also generalizing.",
      "tldr_zh": "本研究探讨了周期激活函数（periodic activation functions，也称 learned Fourier features）在强化学习（Reinforcement Learning）中的频率特性和泛化性能。研究通过实证分析发现，这些函数无论初始化频率如何，都会一致收敛到高频表示，从而提高样本效率，但同时在添加观察噪声的状态下表现出更差的泛化能力，尤其是与 ReLU 激活函数相比。最终，作者证明权重衰减正则化（weight decay regularization）能部分缓解周期激活函数的过拟合问题，实现快速学习和更好的泛化平衡。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NE"
      ],
      "primary_category": "cs.LG",
      "comment": "RLC format, fixed bug which incorrectly gave vanilla ReLU training\n  runs weight decay",
      "pdf_url": "http://arxiv.org/pdf/2407.06756v2",
      "published_date": "2024-07-09 11:07:41 UTC",
      "updated_date": "2025-03-18 20:09:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T05:02:46.087992"
    },
    {
      "arxiv_id": "2407.06754v2",
      "title": "Threats and Defenses in Federated Learning Life Cycle: A Comprehensive Survey and Challenges",
      "title_zh": "联邦学习生命周期中的威胁与防御：全面综述及挑战",
      "authors": [
        "Yanli Li",
        "Zhongliang Guo",
        "Nan Yang",
        "Huaming Chen",
        "Dong Yuan",
        "Weiping Ding"
      ],
      "abstract": "Federated Learning (FL) offers innovative solutions for privacy-preserving\ncollaborative machine learning (ML). Despite its promising potential, FL is\nvulnerable to various attacks due to its distributed nature, affecting the\nentire life cycle of FL services. These threats can harm the model's utility or\ncompromise participants' privacy, either directly or indirectly. In response,\nnumerous defense frameworks have been proposed, demonstrating effectiveness in\nspecific settings and scenarios. To provide a clear understanding of the\ncurrent research landscape, this paper reviews the most representative and\nstate-of-the-art threats and defense frameworks throughout the FL service life\ncycle. We start by identifying FL threats that harm utility and privacy,\nincluding those with potential or direct impacts. Then, we dive into the\ndefense frameworks, analyze the relationship between threats and defenses, and\ncompare the trade-offs among different defense strategies. Finally, we\nsummarize current research bottlenecks and offer insights into future research\ndirections to conclude this survey. We hope this survey sheds light on\ntrustworthy FL research and contributes to the FL community.",
      "tldr_zh": "本论文对 Federated Learning (FL) 生命周期中的威胁和防御进行了全面调查，重点分析了 FL 在分布式环境中面临的攻击，这些攻击可能损害模型效用或参与者的隐私，包括直接和潜在影响。研究回顾了代表性的威胁类型和防御框架，探讨了威胁与防御的关系，以及不同防御策略在有效性与权衡（如性能与隐私保护）方面的比较。最终，论文总结了当前研究瓶颈，并提出了未来研究方向，以推动可信 FL 的发展。",
      "categories": [
        "cs.DC",
        "cs.AI"
      ],
      "primary_category": "cs.DC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.06754v2",
      "published_date": "2024-07-09 11:05:45 UTC",
      "updated_date": "2024-07-11 11:50:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T05:03:01.562218"
    },
    {
      "arxiv_id": "2407.07925v1",
      "title": "Enhancing Social Media Personalization: Dynamic User Profile Embeddings and Multimodal Contextual Analysis Using Transformer Models",
      "title_zh": "翻译失败",
      "authors": [
        "Pranav Vachharajani"
      ],
      "abstract": "This study investigates the impact of dynamic user profile embedding on\npersonalized context-aware experiences in social networks. A comparative\nanalysis of multilingual and English transformer models was performed on a\ndataset of over twenty million data points. The analysis included a wide range\nof metrics and performance indicators to compare dynamic profile embeddings\nversus non-embeddings (effectively static profile embeddings). A comparative\nstudy using degradation functions was conducted. Extensive testing and research\nconfirmed that dynamic embedding successfully tracks users' changing tastes and\npreferences, providing more accurate recommendations and higher user\nengagement. These results are important for social media platforms aiming to\nimprove user experience through relevant features and sophisticated\nrecommendation engines.",
      "tldr_zh": "本研究探讨了动态用户配置文件嵌入（dynamic user profile embeddings）如何提升社交网络的个性化上下文感知体验，通过比较多语言和英语 Transformer 模型在超过两千万数据点数据集上的性能。研究采用各种指标和退化函数（degradation functions）对动态嵌入与静态嵌入进行对比分析，结果表明动态嵌入能更有效地跟踪用户变化的偏好，提供更准确的推荐并提升用户参与度。这些发现为社交媒体平台优化用户体验和构建先进的推荐引擎提供了重要指导。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.SI"
      ],
      "primary_category": "cs.IR",
      "comment": "21 pages, 13 figures. Mentor: Prof Pritam Ranjan",
      "pdf_url": "http://arxiv.org/pdf/2407.07925v1",
      "published_date": "2024-07-09 10:58:46 UTC",
      "updated_date": "2024-07-09 10:58:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T05:03:10.868241"
    },
    {
      "arxiv_id": "2407.06748v1",
      "title": "iASiS: Towards Heterogeneous Big Data Analysis for Personalized Medicine",
      "title_zh": "翻译失败",
      "authors": [
        "Anastasia Krithara",
        "Fotis Aisopos",
        "Vassiliki Rentoumi",
        "Anastasios Nentidis",
        "Konstantinos Bougatiotis",
        "Maria-Esther Vidal",
        "Ernestina Menasalvas",
        "Alejandro Rodriguez-Gonzalez",
        "Eleftherios G. Samaras",
        "Peter Garrard",
        "Maria Torrente",
        "Mariano Provencio Pulla",
        "Nikos Dimakopoulos",
        "Rui Mauricio",
        "Jordi Rambla De Argila",
        "Gian Gaetano Tartaglia",
        "George Paliouras"
      ],
      "abstract": "The vision of IASIS project is to turn the wave of big biomedical data\nheading our way into actionable knowledge for decision makers. This is achieved\nby integrating data from disparate sources, including genomics, electronic\nhealth records and bibliography, and applying advanced analytics methods to\ndiscover useful patterns. The goal is to turn large amounts of available data\ninto actionable information to authorities for planning public health\nactivities and policies. The integration and analysis of these heterogeneous\nsources of information will enable the best decisions to be made, allowing for\ndiagnosis and treatment to be personalised to each individual. The project\noffers a common representation schema for the heterogeneous data sources. The\niASiS infrastructure is able to convert clinical notes into usable data,\ncombine them with genomic data, related bibliography, image data and more, and\ncreate a global knowledge base. This facilitates the use of intelligent methods\nin order to discover useful patterns across different resources. Using semantic\nintegration of data gives the opportunity to generate information that is rich,\nauditable and reliable. This information can be used to provide better care,\nreduce errors and create more confidence in sharing data, thus providing more\ninsights and opportunities. Data resources for two different disease categories\nare explored within the iASiS use cases, dementia and lung cancer.",
      "tldr_zh": "该论文介绍了 iASiS 项目，旨在整合异构大数据来源（如 Genomics、Electronic Health Records 和文献），通过高级分析方法将这些数据转化为可操作知识，以支持个性化医疗决策和公共健康政策制定。项目采用语义整合和智能模式发现技术，构建一个全局知识基，能够转换临床笔记并结合基因组学数据，实现可靠且可审计的信息生成。iASiS 的用例聚焦于痴呆和肺癌等疾病类别，有助于提高诊断准确性、减少错误，并为个性化治疗提供更丰富的见解。",
      "categories": [
        "cs.AI",
        "cs.DB"
      ],
      "primary_category": "cs.AI",
      "comment": "6 pages, 2 figures, accepted at 2019 IEEE 32nd International\n  Symposium on Computer-Based Medical Systems (CBMS)",
      "pdf_url": "http://arxiv.org/pdf/2407.06748v1",
      "published_date": "2024-07-09 10:52:19 UTC",
      "updated_date": "2024-07-09 10:52:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T05:03:23.348590"
    },
    {
      "arxiv_id": "2407.06740v2",
      "title": "Sustainable techniques to improve Data Quality for training image-based explanatory models for Recommender Systems",
      "title_zh": "翻译失败",
      "authors": [
        "Jorge Paz-Ruza",
        "David Esteban-Martínez",
        "Amparo Alonso-Betanzos",
        "Bertha Guijarro-Berdiñas"
      ],
      "abstract": "Visual explanations based on user-uploaded images are an effective and\nself-contained approach to provide transparency to Recommender Systems (RS),\nbut intrinsic limitations of data used in this explainability paradigm cause\nexisting approaches to use bad quality training data that is highly sparse and\nsuffers from labelling noise. Popular training enrichment approaches like model\nenlargement or massive data gathering are expensive and environmentally\nunsustainable, thus we seek to provide better visual explanations to RS\naligning with the principles of Responsible AI. In this work, we research the\nintersection of effective and sustainable training enrichment strategies for\nvisual-based RS explainability models by developing three novel strategies that\nfocus on training Data Quality: 1) selection of reliable negative training\nexamples using Positive-unlabelled Learning, 2) transform-based data\naugmentation, and 3) text-to-image generative-based data augmentation. The\nintegration of these strategies in three state-of-the-art explainability models\nincreases 5% the performance in relevant ranking metrics of these visual-based\nRS explainability models without penalizing their practical long-term\nsustainability, as tested in multiple real-world restaurant recommendation\nexplanation datasets.",
      "tldr_zh": "该研究针对基于图像的推荐系统（Recommender Systems, RS）解释模型，解决了训练数据稀疏和标签噪声等问题，提出三种可持续的提升数据质量策略：1) 使用 Positive-unlabelled Learning 选择可靠的负样本，2) 基于变换的数据增强（transform-based data augmentation），以及 3) 基于文本到图像生成的数据增强（text-to-image generative-based data augmentation）。这些策略整合到三个最先进的解释模型中，提高了相关排名指标约 5%。实验在多个真实世界的餐厅推荐数据集上验证了这些方法的有效性，同时确保了长期的环境可持续性和 Responsible AI 原则的遵守。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV",
        "cs.IR"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.06740v2",
      "published_date": "2024-07-09 10:40:31 UTC",
      "updated_date": "2025-03-29 10:16:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T05:03:33.832198"
    },
    {
      "arxiv_id": "2407.06723v2",
      "title": "Graph-Based Captioning: Enhancing Visual Descriptions by Interconnecting Region Captions",
      "title_zh": "基于图形的标题生成：通过互连区域标题增强视觉描述",
      "authors": [
        "Yu-Guan Hsieh",
        "Cheng-Yu Hsieh",
        "Shih-Ying Yeh",
        "Louis Béthune",
        "Hadi Pour Ansari",
        "Pavan Kumar Anasosalu Vasu",
        "Chun-Liang Li",
        "Ranjay Krishna",
        "Oncel Tuzel",
        "Marco Cuturi"
      ],
      "abstract": "Humans describe complex scenes with compositionality, using simple text\ndescriptions enriched with links and relationships. While vision-language\nresearch has aimed to develop models with compositional understanding\ncapabilities, this is not reflected yet in existing datasets which, for the\nmost part, still use plain text to describe images. In this work, we propose a\nnew annotation strategy, graph-based captioning (GBC) that describes an image\nusing a labeled graph structure, with nodes of various types. The nodes in GBC\nare created through a two-stage process: first, identifying and describing\nentity nodes; second, linking these nodes by highlighting \\textit{compositions}\nand \\textit{relations} among them. Since \\textit{all} GBC nodes hold plain text\ndescriptions, GBC retains the flexibility found in natural language, but can\nalso encode hierarchical information in its edges. We demonstrate that GBC can\nbe produced automatically, using off-the-shelf multimodal LLMs and object\ndetection models, by building a new dataset GBC10M that gathers GBC annotations\nfor about 10M images of the CC12M dataset. Through CLIP training on GBC10M, we\nshow that leveraging GBC nodes' annotations -- particularly those in\ncomposition and relation nodes -- significantly boosts the model's performance\nacross various benchmarks compared to when other annotations are used. To\nfurther explore the opportunities provided by GBC, we also investigate the use\nof GBC as middleware for text-to-image generation, and show the extra benefits\nof incorporating the graph structure in this task. Our code and datasets are\nreleased at https://github.com/apple/ml-gbc and\nhttps://huggingface.co/graph-based-captions.",
      "tldr_zh": "本研究提出了一种新的图像描述策略——graph-based captioning (GBC)，通过使用带标签的图结构（包括各种类型节点）来增强视觉描述的组合性和关系性，解决了现有数据集仅使用纯文本的局限性。GBC 的生成采用两阶段过程：首先识别并描述实体节点，其次链接这些节点以突出 compositions 和 relations，并利用现成的多模态 LLMs 和物体检测模型自动构建了包含约 10M 图像的 GBC10M 数据集。在 CLIP 模型上训练时，使用 GBC 节点的注释（尤其是 composition 和 relation 节点）显著提高了模型在各种基准上的性能；此外，GBC 作为文本到图像生成的中介也能带来额外益处。研究发布了相关代码和数据集，以推动进一步应用。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "59 pages, 42 figures",
      "pdf_url": "http://arxiv.org/pdf/2407.06723v2",
      "published_date": "2024-07-09 09:55:04 UTC",
      "updated_date": "2025-02-26 22:54:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T05:03:47.373925"
    },
    {
      "arxiv_id": "2407.06718v1",
      "title": "A Simple Architecture for Enterprise Large Language Model Applications based on Role based security and Clearance Levels using Retrieval-Augmented Generation or Mixture of Experts",
      "title_zh": "翻译失败",
      "authors": [
        "Atilla Özgür",
        "Yılmaz Uygun"
      ],
      "abstract": "This study proposes a simple architecture for Enterprise application for\nLarge Language Models (LLMs) for role based security and NATO clearance levels.\nOur proposal aims to address the limitations of current LLMs in handling\nsecurity and information access. The proposed architecture could be used while\nutilizing Retrieval-Augmented Generation (RAG) and fine tuning of Mixture of\nexperts models (MoE). It could be used only with RAG, or only with MoE or with\nboth of them. Using roles and security clearance level of the user, documents\nin RAG and experts in MoE are filtered. This way information leakage is\nprevented.",
      "tldr_zh": "本研究提出了一种简单架构，用于企业级大型语言模型 (LLMs) 应用，基于角色-based security 和 NATO 清除级别，以解决当前 LLMs 在处理安全和信息访问方面的局限性。该架构支持 Retrieval-Augmented Generation (RAG) 和 Mixture of Experts (MoE) 的灵活组合，或单独使用，通过根据用户角色和安全级别过滤 RAG 中的文档以及 MoE 中的专家，从而有效防止信息泄露。总体而言，此方法提升了企业 LLMs 应用的可靠性和安全性，为安全敏感环境下的模型部署提供了实用框架。",
      "categories": [
        "cs.AI",
        "D.2.11; I.2.7"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.06718v1",
      "published_date": "2024-07-09 09:46:23 UTC",
      "updated_date": "2024-07-09 09:46:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T05:04:00.238014"
    },
    {
      "arxiv_id": "2407.11054v3",
      "title": "Generative AI for Health Technology Assessment: Opportunities, Challenges, and Policy Considerations",
      "title_zh": "生成式 AI 用于健康技术评估：机会、挑战和政策考虑",
      "authors": [
        "Rachael Fleurence",
        "Jiang Bian",
        "Xiaoyan Wang",
        "Hua Xu",
        "Dalia Dawoud",
        "Mitch Higashi",
        "Jagpreet Chhatwal"
      ],
      "abstract": "This review introduces the transformative potential of generative Artificial\nIntelligence (AI) and foundation models, including large language models\n(LLMs), for health technology assessment (HTA). We explore their applications\nin four critical areas, evidence synthesis, evidence generation, clinical\ntrials and economic modeling: (1) Evidence synthesis: Generative AI has the\npotential to assist in automating literature reviews and meta-analyses by\nproposing search terms, screening abstracts, and extracting data with notable\naccuracy; (2) Evidence generation: These models can potentially facilitate\nautomating the process and analyze the increasingly available large collections\nof real-world data (RWD), including unstructured clinical notes and imaging,\nenhancing the speed and quality of real-world evidence (RWE) generation; (3)\nClinical trials: Generative AI can be used to optimize trial design, improve\npatient matching, and manage trial data more efficiently; and (4) Economic\nmodeling: Generative AI can also aid in the development of health economic\nmodels, from conceptualization to validation, thus streamlining the overall HTA\nprocess. Despite their promise, these technologies, while rapidly improving,\nare still nascent and continued careful evaluation in their applications to HTA\nis required. To ensure their responsible use and implementation, both\ndevelopers and users of research incorporating these tools, should familiarize\nthemselves with their current limitations, including the issues related to\nscientific validity, risk of bias, and consider equity and ethical\nimplications. We also surveyed the current policy landscape and provide\nsuggestions for HTA agencies on responsibly integrating generative AI into\ntheir workflows, emphasizing the importance of human oversight and the\nfast-evolving nature of these tools.",
      "tldr_zh": "这篇评论探讨了生成式 AI 和基础模型（如 LLMs）在健康技术评估 (HTA) 中的潜力，涵盖证据合成、证据生成、临床试验和经济建模四个领域。生成式 AI 可自动化文献综述（如提出搜索术语和数据提取）、分析真实世界数据 (RWD) 以生成真实世界证据 (RWE)、优化试验设计及患者匹配，并辅助经济模型的开发，从而提升 HTA 过程的效率。尽管这些应用前景广阔，但需应对科学有效性、偏差风险和伦理挑战。作者建议 HTA 机构在整合这些工具时，加强人类监督，并制定相应政策以确保负责任使用。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "24 pages, 1 figure, 1 table, 2 boxes, 103 references",
      "pdf_url": "http://arxiv.org/pdf/2407.11054v3",
      "published_date": "2024-07-09 09:25:27 UTC",
      "updated_date": "2024-09-21 19:41:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T05:04:13.920463"
    },
    {
      "arxiv_id": "2407.06692v1",
      "title": "Deep-Motion-Net: GNN-based volumetric organ shape reconstruction from single-view 2D projections",
      "title_zh": "Deep-Motion-Net：基于 GNN 的从单视图 2D 投影重建体积器官形状",
      "authors": [
        "Isuru Wijesinghe",
        "Michael Nix",
        "Arezoo Zakeri",
        "Alireza Hokmabadi",
        "Bashar Al-Qaisieh",
        "Ali Gooya",
        "Zeike A. Taylor"
      ],
      "abstract": "We propose Deep-Motion-Net: an end-to-end graph neural network (GNN)\narchitecture that enables 3D (volumetric) organ shape reconstruction from a\nsingle in-treatment kV planar X-ray image acquired at any arbitrary projection\nangle. Estimating and compensating for true anatomical motion during\nradiotherapy is essential for improving the delivery of planned radiation dose\nto target volumes while sparing organs-at-risk, and thereby improving the\ntherapeutic ratio. Achieving this using only limited imaging available during\nirradiation and without the use of surrogate signals or invasive fiducial\nmarkers is attractive. The proposed model learns the mesh regression from a\npatient-specific template and deep features extracted from kV images at\narbitrary projection angles. A 2D-CNN encoder extracts image features, and four\nfeature pooling networks fuse these features to the 3D template organ mesh. A\nResNet-based graph attention network then deforms the feature-encoded mesh. The\nmodel is trained using synthetically generated organ motion instances and\ncorresponding kV images. The latter is generated by deforming a reference CT\nvolume aligned with the template mesh, creating digitally reconstructed\nradiographs (DRRs) at required projection angles, and DRR-to-kV style\ntransferring with a conditional CycleGAN model. The overall framework was\ntested quantitatively on synthetic respiratory motion scenarios and\nqualitatively on in-treatment images acquired over full scan series for liver\ncancer patients. Overall mean prediction errors for synthetic motion test\ndatasets were 0.16$\\pm$0.13 mm, 0.18$\\pm$0.19 mm, 0.22$\\pm$0.34 mm, and\n0.12$\\pm$0.11 mm. Mean peak prediction errors were 1.39 mm, 1.99 mm, 3.29 mm,\nand 1.16 mm.",
      "tldr_zh": "本研究提出Deep-Motion-Net，一种基于GNN（Graph Neural Network）的端到端架构，用于从单一kV平面X射线图像（任意投影角度）重建3D体积器官形状，从而在放射治疗中估计和补偿解剖运动，提高辐射剂量精确性。模型通过2D-CNN编码器提取图像特征，四个特征池网络将这些特征融合到患者特定模板器官网格中，并利用ResNet-based图注意力网络对网格进行变形；训练数据则使用合成器官运动实例、数字重构射线图像（DRR）和CycleGAN风格转移生成。实验结果显示，在合成呼吸运动场景上，整体平均预测误差为0.12±0.11 mm至0.22±0.34 mm，峰值错误为1.16 mm至3.29 mm，并在肝癌患者图像上实现了定性验证。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.06692v1",
      "published_date": "2024-07-09 09:07:18 UTC",
      "updated_date": "2024-07-09 09:07:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T05:04:24.724432"
    },
    {
      "arxiv_id": "2407.06690v1",
      "title": "Hierarchical Average-Reward Linearly-solvable Markov Decision Processes",
      "title_zh": "翻译失败",
      "authors": [
        "Guillermo Infante",
        "Anders Jonsson",
        "Vicenç Gómez"
      ],
      "abstract": "We introduce a novel approach to hierarchical reinforcement learning for\nLinearly-solvable Markov Decision Processes (LMDPs) in the infinite-horizon\naverage-reward setting. Unlike previous work, our approach allows learning\nlow-level and high-level tasks simultaneously, without imposing limiting\nrestrictions on the low-level tasks. Our method relies on partitions of the\nstate space that create smaller subtasks that are easier to solve, and the\nequivalence between such partitions to learn more efficiently. We then exploit\nthe compositionality of low-level tasks to exactly represent the value function\nof the high-level task. Experiments show that our approach can outperform flat\naverage-reward reinforcement learning by one or several orders of magnitude.",
      "tldr_zh": "本研究提出了一种针对无限期平均奖励 Linearly-solvable Markov Decision Processes (LMDPs) 的分层强化学习方法，该方法允许同时学习低级和高水平任务，而不对低级任务施加严格限制。  \n该方法依赖于状态空间的划分来创建更易解决的子任务，并利用这些子任务之间的等价性和可组合性，精确表示高水平任务的价值函数，从而提高学习效率。  \n实验结果显示，该方法比传统的平坦平均奖励强化学习性能提升1到几个数量级。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.06690v1",
      "published_date": "2024-07-09 09:06:44 UTC",
      "updated_date": "2024-07-09 09:06:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T05:04:34.881773"
    },
    {
      "arxiv_id": "2407.06682v1",
      "title": "A Predictive Model Based on Transformer with Statistical Feature Embedding in Manufacturing Sensor Dataset",
      "title_zh": "基于 Transformer 的预测模型，采用统计特征嵌入于制造传感器数据集",
      "authors": [
        "Gyeong Taek Lee",
        "Oh-Ran Kwon"
      ],
      "abstract": "In the manufacturing process, sensor data collected from equipment is crucial\nfor building predictive models to manage processes and improve productivity.\nHowever, in the field, it is challenging to gather sufficient data to build\nrobust models. This study proposes a novel predictive model based on the\nTransformer, utilizing statistical feature embedding and window positional\nencoding. Statistical features provide an effective representation of sensor\ndata, and the embedding enables the Transformer to learn both time- and\nsensor-related information. Window positional encoding captures precise time\ndetails from the feature embedding. The model's performance is evaluated in two\nproblems: fault detection and virtual metrology, showing superior results\ncompared to baseline models. This improvement is attributed to the efficient\nuse of parameters, which is particularly beneficial for sensor data that often\nhas limited sample sizes. The results support the model's applicability across\nvarious manufacturing industries, demonstrating its potential for enhancing\nprocess management and yield.",
      "tldr_zh": "该论文提出了一种基于Transformer的预测模型，结合统计特征 embedding 和 window positional encoding，用于处理制造传感器数据集中的数据不足问题。该模型通过统计特征有效表示传感器数据，并利用嵌入和位置编码学习时间和传感器相关信息，从而提升预测准确性。在故障检测和虚拟计量任务上，该模型比基线模型表现出色，参数使用效率高，并证明了其在各种制造行业的适用性，以改善流程管理和生产力。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.06682v1",
      "published_date": "2024-07-09 08:59:27 UTC",
      "updated_date": "2024-07-09 08:59:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T05:04:47.470525"
    },
    {
      "arxiv_id": "2407.06676v1",
      "title": "Games played by Exponential Weights Algorithms",
      "title_zh": "翻译失败",
      "authors": [
        "Maurizio d'Andrea",
        "Fabien Gensbittel",
        "Jérôme Renault"
      ],
      "abstract": "This paper studies the last-iterate convergence properties of the exponential\nweights algorithm with constant learning rates. We consider a repeated\ninteraction in discrete time, where each player uses an exponential weights\nalgorithm characterized by an initial mixed action and a fixed learning rate,\nso that the mixed action profile $p^t$ played at stage $t$ follows an\nhomogeneous Markov chain. At first, we show that whenever a strict Nash\nequilibrium exists, the probability to play a strict Nash equilibrium at the\nnext stage converges almost surely to 0 or 1. Secondly, we show that the limit\nof $p^t$, whenever it exists, belongs to the set of ``Nash Equilibria with\nEqualizing Payoffs''. Thirdly, we show that in strong coordination games, where\nthe payoff of a player is positive on the diagonal and 0 elsewhere, $p^t$\nconverges almost surely to one of the strict Nash equilibria. We conclude with\nopen questions.",
      "tldr_zh": "本研究分析了指数权重算法（exponential weights algorithm）在常数学习率下的最后迭代收敛性质，聚焦于离散时间重复互动博弈中，每个玩家使用带有初始混合动作和固定学习率的算法，使混合动作配置文件 \\( p^t \\) 遵循同质Markov链。论文证明，如果存在严格Nash equilibrium，下一阶段玩严格Nash equilibrium的概率几乎必然收敛到0或1；此外，\\( p^t \\) 的极限（若存在）属于“Nash Equilibria with Equalizing Payoffs”集合。实验结果显示，在强协调游戏中，\\( p^t \\) 几乎必然收敛到一个严格Nash equilibrium，为博弈理论中的算法收敛提供了新见解。",
      "categories": [
        "cs.AI",
        "math.PR"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.06676v1",
      "published_date": "2024-07-09 08:49:51 UTC",
      "updated_date": "2024-07-09 08:49:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T05:04:59.297856"
    },
    {
      "arxiv_id": "2407.06660v1",
      "title": "Collaborative Design of AI-Enhanced Learning Activities",
      "title_zh": "翻译失败",
      "authors": [
        "Margarida Romero"
      ],
      "abstract": "Artificial intelligence has accelerated innovations in different aspects of\ncitizens' lives. Many contexts have already addressed technology-enhanced\nlearning, but educators at different educational levels now need to develop AI\nliteracy and the ability to integrate appropriate AI usage into their teaching.\nWe take into account this objective, along with the creative learning design,\nto create a formative intervention that enables preservice teachers, in-service\nteachers, and EdTech specialists to effectively incorporate AI into their\nteaching practices. We developed the formative intervention with Terra Numerica\nand Maison de l'Intelligence Artificielle in two phases in order to enhance\ntheir understanding of AI and foster its creative application in learning\ndesign. Participants reflect on AI's potential in teaching and learning by\nexploring different activities that can integrate AI literacy in education,\nincluding its ethical considerations and potential for innovative pedagogy. The\napproach emphasises not only acculturating professionals to AI but also\nempowering them to collaboratively design AI-enhanced educational activities\nthat promote learner engagement and personalised learning experiences. Through\nthis process, participants in the workshops develop the skills and mindset\nnecessary to effectively leverage AI while maintaining a critical awareness of\nits implications in education.",
      "tldr_zh": "该研究探讨了如何通过协作设计将人工智能（AI）整合到教育实践中，以提升教师的 AI 素养和教学创新。研究开发了一个形式化干预（formative intervention），分为两个阶段，由 Terra Numerica 和 Maison de l'Intelligence Artificielle 实施，针对预备教师、在职教师和 EdTech 专家，通过探索 AI 增强活动、伦理考虑和创新教学来促进反思与应用。该方法强调培养专业人士的协作技能，使他们能够设计 AI 增强的学习活动，提升学习者参与度和个性化体验，同时保持对 AI 影响的批判意识。最终，参与者通过工作坊获得了有效利用 AI 的能力和心态，为教育实践提供了实用框架。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.06660v1",
      "published_date": "2024-07-09 08:34:08 UTC",
      "updated_date": "2024-07-09 08:34:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T05:05:12.468594"
    },
    {
      "arxiv_id": "2407.06658v2",
      "title": "TriQXNet: Forecasting Dst Index from Solar Wind Data Using an Interpretable Parallel Classical-Quantum Framework with Uncertainty Quantification",
      "title_zh": "TriQXNet：",
      "authors": [
        "Md Abrar Jahin",
        "M. F. Mridha",
        "Zeyar Aung",
        "Nilanjan Dey",
        "R. Simon Sherratt"
      ],
      "abstract": "Geomagnetic storms, caused by solar wind energy transfer to Earth's magnetic\nfield, can disrupt critical infrastructure like GPS, satellite communications,\nand power grids. The disturbance storm-time (Dst) index measures storm\nintensity. Despite advancements in empirical, physics-based, and\nmachine-learning models using real-time solar wind data, accurately forecasting\nextreme geomagnetic events remains challenging due to noise and sensor\nfailures. This research introduces TriQXNet, a novel hybrid classical-quantum\nneural network for Dst forecasting. Our model integrates classical and quantum\ncomputing, conformal prediction, and explainable AI (XAI) within a hybrid\narchitecture. To ensure high-quality input data, we developed a comprehensive\npreprocessing pipeline that included feature selection, normalization,\naggregation, and imputation. TriQXNet processes preprocessed solar wind data\nfrom NASA's ACE and NOAA's DSCOVR satellites, predicting the Dst index for the\ncurrent hour and the next, providing vital advance notice to mitigate\ngeomagnetic storm impacts. TriQXNet outperforms 13 state-of-the-art hybrid\ndeep-learning models, achieving a root mean squared error of 9.27 nanoteslas\n(nT). Rigorous evaluation through 10-fold cross-validated paired t-tests\nconfirmed its superior performance with 95% confidence. Conformal prediction\ntechniques provide quantifiable uncertainty, which is essential for operational\ndecisions, while XAI methods like ShapTime enhance interpretability.\nComparative analysis shows TriQXNet's superior forecasting accuracy, setting a\nnew level of expectations for geomagnetic storm prediction and highlighting the\npotential of classical-quantum hybrid models in space weather forecasting.",
      "tldr_zh": "这篇论文提出 TriQXNet，一种可解释的并行经典-量子框架，用于从太阳风数据预测 Dst 指数，并整合不确定性量化以提升地磁风暴预报准确性。该框架包括全面的数据预处理管道（如特征选择、归一化、聚合和插值），并利用 NASA 的 ACE 和 NOAA 的 DSCOVR 卫星数据来预测当前和下一小时的 Dst 指数。TriQXNet 在性能上超越13个先进混合深度学习模型，实现了9.27 nT 的根均方误差，并通过10折交叉验证的配对 t 检验以95%置信度确认其优势。同时，conformal prediction 提供量化不确定性，XAI 方法如 ShapTime 增强模型解释性，从而为减轻地磁风暴对关键基础设施的影响设定新标准。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.06658v2",
      "published_date": "2024-07-09 08:30:42 UTC",
      "updated_date": "2024-07-10 16:53:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T05:05:25.973892"
    },
    {
      "arxiv_id": "2407.06655v1",
      "title": "Teacher agency in the age of generative AI: towards a framework of hybrid intelligence for learning design",
      "title_zh": "生成式 AI 时代下的教师能动性：朝向学习设计混合智能框架",
      "authors": [
        "Thomas B Frøsig",
        "Margarida Romero"
      ],
      "abstract": "Generative AI (genAI) is being used in education for different purposes. From\nthe teachers' perspective, genAI can support activities such as learning\ndesign. However, there is a need to study the impact of genAI on the teachers'\nagency. While GenAI can support certain processes of idea generation and\nco-creation, GenAI has the potential to negatively affect professional agency\ndue to teachers' limited power to (i) act, (ii) affect matters, and (iii) make\ndecisions or choices, as well as the possibility to (iv) take a stance. Agency\nis identified in the learning sciences studies as being one of the factors in\nteachers' ability to trust AI. This paper aims to introduce a dual perspective.\nFirst, educational technology, as opposed to other computer-mediated\ncommunication (CMC) tools, has two distinctly different user groups and\ndifferent user needs, in the form of learners and teachers, to cater for.\nSecond, the design of educational technology often prioritises learner agency\nand engagement, thereby limiting the opportunities for teachers to influence\nthe technology and take action. This study aims to analyse the way GenAI is\ninfluencing teachers' agency. After identifying the current limits of GenAI, a\nsolution based on the combination of human intelligence and artificial\nintelligence through a hybrid intelligence approach is proposed. This\ncombination opens up the discussion of a collaboration between teacher and\ngenAI being able to open up new practices in learning design in which they HI\nsupport the extension of the teachers' activity.",
      "tldr_zh": "本研究探讨了生成式AI（generative AI, genAI）在教育中的应用对教师代理（teacher agency）的影响，指出genAI虽能支持学习设计，但可能因限制教师的行动、影响力、决策和立场而削弱其专业代理。论文从双重视角分析教育技术：其用户群包括学习者和教师，且设计往往优先考虑学习者代理，从而减少教师的影响力。针对genAI的局限，该研究提出一种混合智能（hybrid intelligence）框架，将人类智能与AI结合，促进教师与genAI的协作。最终，这种方法有望扩展教师在学习设计中的新实践，提升其代理和对AI的信任。",
      "categories": [
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.06655v1",
      "published_date": "2024-07-09 08:28:05 UTC",
      "updated_date": "2024-07-09 08:28:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T05:05:35.097709"
    },
    {
      "arxiv_id": "2407.12854v1",
      "title": "Scaling Retrieval-Based Language Models with a Trillion-Token Datastore",
      "title_zh": "翻译失败",
      "authors": [
        "Rulin Shao",
        "Jacqueline He",
        "Akari Asai",
        "Weijia Shi",
        "Tim Dettmers",
        "Sewon Min",
        "Luke Zettlemoyer",
        "Pang Wei Koh"
      ],
      "abstract": "Scaling laws with respect to the amount of training data and the number of\nparameters allow us to predict the cost-benefit trade-offs of pretraining\nlanguage models (LMs) in different configurations. In this paper, we consider\nanother dimension of scaling: the amount of data available at inference time.\nSpecifically, we find that increasing the size of the datastore used by a\nretrieval-based LM monotonically improves language modeling and several\ndownstream tasks without obvious saturation, such that a smaller model\naugmented with a large datastore outperforms a larger LM-only model on\nknowledge-intensive tasks. By plotting compute-optimal scaling curves with\nvaried datastore, model, and pretraining data sizes, we show that using larger\ndatastores can significantly improve model performance for the same training\ncompute budget. We carry out our study by constructing a 1.4 trillion-token\ndatastore named MassiveDS, which is the largest and the most diverse\nopen-sourced datastore for retrieval-based LMs to date, and designing an\nefficient pipeline for studying datastore scaling in a computationally\naccessible manner. Finally, we analyze the effect of improving the retriever,\ndatastore quality filtering, and other design choices on our observed scaling\ntrends. Overall, our results show that datastore size should be considered as\nan integral part of LM efficiency and performance trade-offs. To facilitate\nfuture research, we open-source our datastore and code at\nhttps://github.com/RulinShao/retrieval-scaling.",
      "tldr_zh": "这篇论文探讨了通过扩展检索增强语言模型(retrieval-based LM)的datastore大小来提升模型性能，发现增加datastore规模可以单调地改善语言建模和下游任务表现，而无需明显饱和。研究者构建了1.4万亿token的MassiveDS数据集——目前最大的开源datastore，并通过计算最优缩放曲线显示，小模型搭配大datastore可在相同训练计算预算下超越更大模型。最终，论文强调datastore大小应作为语言模型(LMs)效率和性能权衡的关键因素，并开源了相关代码和数据集以支持进一步研究。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.12854v1",
      "published_date": "2024-07-09 08:27:27 UTC",
      "updated_date": "2024-07-09 08:27:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T05:05:48.675432"
    },
    {
      "arxiv_id": "2407.06654v1",
      "title": "SoftDedup: an Efficient Data Reweighting Method for Speeding Up Language Model Pre-training",
      "title_zh": "翻译失败",
      "authors": [
        "Nan He",
        "Weichen Xiong",
        "Hanwen Liu",
        "Yi Liao",
        "Lei Ding",
        "Kai Zhang",
        "Guohua Tang",
        "Xiao Han",
        "Wei Yang"
      ],
      "abstract": "The effectiveness of large language models (LLMs) is often hindered by\nduplicated data in their extensive pre-training datasets. Current approaches\nprimarily focus on detecting and removing duplicates, which risks the loss of\nvaluable information and neglects the varying degrees of duplication. To\naddress this, we propose a soft deduplication method that maintains dataset\nintegrity while selectively reducing the sampling weight of data with high\ncommonness. Central to our approach is the concept of \"data commonness\", a\nmetric we introduce to quantify the degree of duplication by measuring the\noccurrence probabilities of samples using an n-gram model. Empirical analysis\nshows that this method significantly improves training efficiency, achieving\ncomparable perplexity scores with at least a 26% reduction in required training\nsteps. Additionally, it enhances average few-shot downstream accuracy by 1.77%\nwhen trained for an equivalent duration. Importantly, this approach\nconsistently improves performance, even on rigorously deduplicated datasets,\nindicating its potential to complement existing methods and become a standard\npre-training process for LLMs.",
      "tldr_zh": "本研究提出SoftDedup，一种高效的数据重新权重方法，用于加速大语言模型(LLMs)的预训练过程。它通过引入“data commonness”指标（基于n-gram模型量化样本重复度）来选择性地降低高重复数据采样权重，从而避免传统重复去除方法的潜在信息损失。实验结果显示，该方法在保持数据集完整性的同时，至少减少26%的训练步骤即可达到可比perplexity分数，并提升1.77%的few-shot下游任务平均准确率。即使在已严格去重的数据集上，SoftDedup也能进一步改善性能，表明其可作为LLMs预训练的标准补充方法。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "12 pages, 7 figures",
      "pdf_url": "http://arxiv.org/pdf/2407.06654v1",
      "published_date": "2024-07-09 08:26:39 UTC",
      "updated_date": "2024-07-09 08:26:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T05:06:01.647102"
    },
    {
      "arxiv_id": "2407.06622v1",
      "title": "Reasoning about unpredicted change and explicit time",
      "title_zh": "关于未预测变化与显式时间的推理",
      "authors": [
        "Florence Dupin de Saint-Cyr",
        "Jérôme Lang"
      ],
      "abstract": "Reasoning about unpredicted change consists in explaining observations by\nevents; we propose here an approach for explaining time-stamped observations by\nsurprises, which are simple events consisting in the change of the truth value\nof a fluent. A framework for dealing with surprises is defined. Minimal sets of\nsurprises are provided together with time intervals where each surprise has\noccurred, and they are characterized from a model-based diagnosis point of\nview. Then, a probabilistic approach of surprise minimisation is proposed.",
      "tldr_zh": "本论文探讨了unpredicted change（未预测变化）和explicit time（显式时间）的推理问题，提出了一种通过surprises（简单事件，即流畅真值变化）来解释时间戳观察的方法。\n论文定义了一个处理surprises的框架，并提供最小surprises集及其发生时间区间，从model-based diagnosis的角度进行表征。\n此外，该方法引入了概率最小化surprises的策略，以提升推理的效率和准确性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.06622v1",
      "published_date": "2024-07-09 07:49:57 UTC",
      "updated_date": "2024-07-09 07:49:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T05:06:13.004194"
    },
    {
      "arxiv_id": "2407.06611v1",
      "title": "CEIA: CLIP-Based Event-Image Alignment for Open-World Event-Based Understanding",
      "title_zh": "CEIA：基于 CLIP 的事件-图像对",
      "authors": [
        "Wenhao Xu",
        "Wenming Weng",
        "Yueyi Zhang",
        "Zhiwei Xiong"
      ],
      "abstract": "We present CEIA, an effective framework for open-world event-based\nunderstanding. Currently training a large event-text model still poses a huge\nchallenge due to the shortage of paired event-text data. In response to this\nchallenge, CEIA learns to align event and image data as an alternative instead\nof directly aligning event and text data. Specifically, we leverage the rich\nevent-image datasets to learn an event embedding space aligned with the image\nspace of CLIP through contrastive learning. In this way, event and text data\nare naturally aligned via using image data as a bridge. Particularly, CEIA\noffers two distinct advantages. First, it allows us to take full advantage of\nthe existing event-image datasets to make up the shortage of large-scale\nevent-text datasets. Second, leveraging more training data, it also exhibits\nthe flexibility to boost performance, ensuring scalable capability. In\nhighlighting the versatility of our framework, we make extensive evaluations\nthrough a diverse range of event-based multi-modal applications, such as object\nrecognition, event-image retrieval, event-text retrieval, and domain\nadaptation. The outcomes demonstrate CEIA's distinct zero-shot superiority over\nexisting methods on these applications.",
      "tldr_zh": "该研究提出CEIA框架，通过CLIP-Based事件-图像对齐方法，解决开放世界事件理解中缺乏事件-文本数据的问题。具体而言，CEIA利用丰富的事件-图像数据集进行对比学习，将事件嵌入空间与CLIP的图像空间对齐，从而间接实现事件与文本的对齐。相比直接对齐事件-文本，该方法充分利用现有数据集，提升模型的可扩展性和性能表现。在物体识别、事件-图像检索、事件-文本检索和领域适应等应用中，CEIA展示了显著的零-shot优势，优于现有方法。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.06611v1",
      "published_date": "2024-07-09 07:26:15 UTC",
      "updated_date": "2024-07-09 07:26:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T05:06:24.819856"
    },
    {
      "arxiv_id": "2407.07924v1",
      "title": "Solving General Natural-Language-Description Optimization Problems with Large Language Models",
      "title_zh": "使用大型语言模型解决一般自然语言描述的优化问题",
      "authors": [
        "Jihai Zhang",
        "Wei Wang",
        "Siyan Guo",
        "Li Wang",
        "Fangquan Lin",
        "Cheng Yang",
        "Wotao Yin"
      ],
      "abstract": "Optimization problems seek to find the best solution to an objective under a\nset of constraints, and have been widely investigated in real-world\napplications. Modeling and solving optimization problems in a specific domain\ntypically require a combination of domain knowledge, mathematical skills, and\nprogramming ability, making it difficult for general users and even domain\nprofessionals. In this paper, we propose a novel framework called OptLLM that\naugments LLMs with external solvers. Specifically, OptLLM accepts user queries\nin natural language, convert them into mathematical formulations and\nprogramming codes, and calls the solvers to calculate the results for\ndecision-making. In addition, OptLLM supports multi-round dialogues to\ngradually refine the modeling and solving of optimization problems. To\nillustrate the effectiveness of OptLLM, we provide tutorials on three typical\noptimization applications and conduct experiments on both prompt-based GPT\nmodels and a fine-tuned Qwen model using a large-scale selfdeveloped\noptimization dataset. Experimental results show that OptLLM works with various\nLLMs, and the fine-tuned model achieves an accuracy boost compared to the\npromptbased models. Some features of OptLLM framework have been available for\ntrial since June 2023 (https://opt.alibabacloud.com/chat or\nhttps://opt.aliyun.com/chat).",
      "tldr_zh": "本文提出 OptLLM 框架，利用 Large Language Models (LLMs) 来解决一般自然语言描述的优化问题，该框架将用户查询转换为数学公式和编程代码，并结合外部求解器进行计算决策。OptLLM 支持多轮对话，允许逐步完善问题建模和求解过程，从而降低了对领域知识和编程技能的依赖。实验结果显示，该框架与各种 LLMs 兼容，包括基于提示的 GPT 模型和微调的 Qwen 模型，后者在大型自开发优化数据集上实现了准确率提升。OptLLM 的部分功能已于 2023 年 6 月起开放试用，提供实际优化应用的教程。",
      "categories": [
        "math.OC",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "math.OC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.07924v1",
      "published_date": "2024-07-09 07:11:10 UTC",
      "updated_date": "2024-07-09 07:11:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T05:06:39.076803"
    },
    {
      "arxiv_id": "2407.06597v2",
      "title": "TVR-Ranking: A Dataset for Ranked Video Moment Retrieval with Imprecise Queries",
      "title_zh": "翻译失败",
      "authors": [
        "Renjie Liang",
        "Li Li",
        "Chongzhi Zhang",
        "Jing Wang",
        "Xizhou Zhu",
        "Aixin Sun"
      ],
      "abstract": "In this paper, we propose the task of \\textit{Ranked Video Moment Retrieval}\n(RVMR) to locate a ranked list of matching moments from a collection of videos,\nthrough queries in natural language. Although a few related tasks have been\nproposed and studied by CV, NLP, and IR communities, RVMR is the task that best\nreflects the practical setting of moment search. To facilitate research in\nRVMR, we develop the TVR-Ranking dataset, based on the raw videos and existing\nmoment annotations provided in the TVR dataset. Our key contribution is the\nmanual annotation of relevance levels for 94,442 query-moment pairs. We then\ndevelop the $NDCG@K, IoU\\geq \\mu$ evaluation metric for this new task and\nconduct experiments to evaluate three baseline models. Our experiments show\nthat the new RVMR task brings new challenges to existing models and we believe\nthis new dataset contributes to the research on multi-modality search. The\ndataset is available at \\url{https://github.com/Ranking-VMR/TVR-Ranking}",
      "tldr_zh": "本研究提出了一种新的任务Ranked Video Moment Retrieval (RVMR)，旨在通过自然语言查询从视频集合中检索并排名匹配的时刻列表，以更好地模拟实际时刻搜索场景。研究者基于TVR数据集开发了TVR-Ranking数据集，并手动注解了94,442个查询-时刻对的相关性水平，同时引入了NDCG@K, IoU ≥ μ作为新的评价指标。实验评估了三个基线模型，结果显示RVMR任务对现有模型带来了新挑战，并有助于推进多模态搜索的研究。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.06597v2",
      "published_date": "2024-07-09 06:57:30 UTC",
      "updated_date": "2024-07-24 03:54:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T05:06:48.999633"
    },
    {
      "arxiv_id": "2407.06590v1",
      "title": "Revolutionizing Battery Disassembly: The Design and Implementation of a Battery Disassembly Autonomous Mobile Manipulator Robot(BEAM-1)",
      "title_zh": "翻译失败",
      "authors": [
        "Yanlong Peng",
        "Zhigang Wang",
        "Yisheng Zhang",
        "Shengmin Zhang",
        "Nan Cai",
        "Fan Wu",
        "Ming Chen"
      ],
      "abstract": "The efficient disassembly of end-of-life electric vehicle batteries(EOL-EVBs)\nis crucial for green manufacturing and sustainable development. The current\npre-programmed disassembly conducted by the Autonomous Mobile Manipulator\nRobot(AMMR) struggles to meet the disassembly requirements in dynamic\nenvironments, complex scenarios, and unstructured processes. In this paper, we\npropose a Battery Disassembly AMMR(BEAM-1) system based on NeuralSymbolic AI.\nIt detects the environmental state by leveraging a combination of multi-sensors\nand neural predicates and then translates this information into a\nquasi-symbolic space. In real-time, it identifies the optimal sequence of\naction primitives through LLM-heuristic tree search, ensuring high-precision\nexecution of these primitives. Additionally, it employs positional speculative\nsampling using intuitive networks and achieves the disassembly of various bolt\ntypes with a meticulously designed end-effector. Importantly, BEAM-1 is a\ncontinuously learning embodied intelligence system capable of subjective\nreasoning like a human, and possessing intuition. A large number of real scene\nexperiments have proved that it can autonomously perceive, decide, and execute\nto complete the continuous disassembly of bolts in multiple, multi-category,\nand complex situations, with a success rate of 98.78%. This research attempts\nto use NeuroSymbolic AI to give robots real autonomous reasoning, planning, and\nlearning capabilities. BEAM-1 realizes the revolution of battery disassembly.\nIts framework can be easily ported to any robotic system to realize different\napplication scenarios, which provides a ground-breaking idea for the design and\nimplementation of future embodied intelligent robotic systems.",
      "tldr_zh": "该论文提出了一种基于 NeuralSymbolic AI 的电池拆卸自主移动机械臂系统 BEAM-1，旨在解决传统 Autonomous Mobile Manipulator Robot (AMMR) 在动态环境、复杂场景和非结构化过程中的局限性。系统通过多传感器结合神经谓词检测环境状态，并利用 LLM-heuristic tree search 实时优化动作序列，确保高精度执行各种螺栓拆卸任务，同时具备持续学习和人类般的主观推理能力。实验结果显示，BEAM-1 在真实复杂场景下成功率达 98.78%，为绿色制造和可持续电池回收提供革命性框架，并可轻松移植到其他机器人系统中。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.06590v1",
      "published_date": "2024-07-09 06:44:20 UTC",
      "updated_date": "2024-07-09 06:44:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T05:07:02.216828"
    },
    {
      "arxiv_id": "2407.11052v2",
      "title": "Revisiting, Benchmarking and Understanding Unsupervised Graph Domain Adaptation",
      "title_zh": "重新审视、基准测试与理解无监督图域适应",
      "authors": [
        "Meihan Liu",
        "Zhen Zhang",
        "Jiachen Tang",
        "Jiajun Bu",
        "Bingsheng He",
        "Sheng Zhou"
      ],
      "abstract": "Unsupervised Graph Domain Adaptation (UGDA) involves the transfer of\nknowledge from a label-rich source graph to an unlabeled target graph under\ndomain discrepancies. Despite the proliferation of methods designed for this\nemerging task, the lack of standard experimental settings and fair performance\ncomparisons makes it challenging to understand which and when models perform\nwell across different scenarios. To fill this gap, we present the first\ncomprehensive benchmark for unsupervised graph domain adaptation named\nGDABench, which encompasses 16 algorithms across 5 datasets with 74 adaptation\ntasks. Through extensive experiments, we observe that the performance of\ncurrent UGDA models varies significantly across different datasets and\nadaptation scenarios. Specifically, we recognize that when the source and\ntarget graphs face significant distribution shifts, it is imperative to\nformulate strategies to effectively address and mitigate graph structural\nshifts. We also find that with appropriate neighbourhood aggregation\nmechanisms, simple GNN variants can even surpass state-of-the-art UGDA\nbaselines. To facilitate reproducibility, we have developed an easy-to-use\nlibrary PyGDA for training and evaluating existing UGDA methods, providing a\nstandardized platform in this community. Our source codes and datasets can be\nfound at: https://github.com/pygda-team/pygda.",
      "tldr_zh": "本文重新审视了 Unsupervised Graph Domain Adaptation (UGDA)，即从有标签源图向无标签目标图转移知识的问题，并提出了首个全面基准 GDABench，包括16个算法、5个数据集和74个适应任务，以填补标准实验设置的空白。通过广泛实验，研究发现现有 UGDA 模型在不同数据集和场景下的性能差异显著，尤其在源图和目标图存在重大分布偏移时，需要制定策略来缓解图结构偏移；此外，使用适当的邻域聚合机制，简单的 GNN 变体甚至可超越最先进的 UGDA 基线。为便于复现，该研究开发了易于使用的库 PyGDA，并提供了源代码和数据集链接。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by NeurIPS-24",
      "pdf_url": "http://arxiv.org/pdf/2407.11052v2",
      "published_date": "2024-07-09 06:44:09 UTC",
      "updated_date": "2024-11-11 12:16:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T05:07:13.683741"
    },
    {
      "arxiv_id": "2407.06581v6",
      "title": "Vision language models are blind: Failing to translate detailed visual features into words",
      "title_zh": "视觉语言模型是盲目的：无法将详细的视觉特征转化为文字",
      "authors": [
        "Pooyan Rahmanzadehgervi",
        "Logan Bolton",
        "Mohammad Reza Taesiri",
        "Anh Totti Nguyen"
      ],
      "abstract": "While large language models with vision capabilities (VLMs), e.g., GPT-4o and\nGemini 1.5 Pro, score high on many vision-understanding benchmarks, they are\nstill struggling with low-level vision tasks that are easy to humans.\nSpecifically, on BlindTest, our suite of 7 very simple tasks, including\nidentifying (a) whether two circles overlap; (b) how many times two lines\nintersect; (c) which letter is being circled in a word; and (d) the number of\ncircles in an Olympic-like logo, four state-of-the-art VLMs are only 58.07%\naccurate on average. Claude 3.5 Sonnet performs the best at 77.84% accuracy,\nfar from the human expected accuracy of 100%. Across different image\nresolutions and line widths, VLMs including slow-thinking models consistently\nstruggle with those tasks that require precise spatial information when\ngeometric primitives overlap or are close. Yet, VLMs perform at near-100%\naccuracy when much more space is added to separate shapes and letters. Linear\nprobing experiments show that vision encoders contain sufficient visual\ninformation to solve BlindTest and that language models fail to decode this\ninformation into correct answers. Code and data are at:\nhttps://vlmsareblind.github.io",
      "tldr_zh": "本研究揭示了视觉语言模型(VLMs)，如GPT-4o和Gemini 1.5 Pro，在处理低级视觉任务时的局限性，尽管它们在高级视觉基准上表现突出。作者引入了BlindTest数据集，包含7个简单任务（如判断两个圆是否重叠或两条线相交次数），用于评估VLMs对精确空间信息的理解。四款先进VLMs的平均准确率仅58.07%，Claude 3.5 Sonnet最高77.84%，远低于人类的100%。通过线性探测实验，研究发现视觉编码器已包含足够信息，但语言模型无法正确解码，导致VLMs在形状重叠或接近时失败，而在增加空间分离后准确率接近100%。这为改进VLMs的视觉-语言翻译能力提供了关键洞见。",
      "categories": [
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.06581v6",
      "published_date": "2024-07-09 06:20:17 UTC",
      "updated_date": "2025-03-27 16:16:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T05:07:25.685385"
    },
    {
      "arxiv_id": "2407.06576v3",
      "title": "Virtual Personas for Language Models via an Anthology of Backstories",
      "title_zh": "翻译失败",
      "authors": [
        "Suhong Moon",
        "Marwa Abdulhai",
        "Minwoo Kang",
        "Joseph Suh",
        "Widyadewi Soedarmadji",
        "Eran Kohen Behar",
        "David M. Chan"
      ],
      "abstract": "Large language models (LLMs) are trained from vast repositories of text\nauthored by millions of distinct authors, reflecting an enormous diversity of\nhuman traits. While these models bear the potential to be used as\napproximations of human subjects in behavioral studies, prior efforts have been\nlimited in steering model responses to match individual human users. In this\nwork, we introduce \"Anthology\", a method for conditioning LLMs to particular\nvirtual personas by harnessing open-ended life narratives, which we refer to as\n\"backstories.\" We show that our methodology enhances the consistency and\nreliability of experimental outcomes while ensuring better representation of\ndiverse sub-populations. Across three nationally representative human surveys\nconducted as part of Pew Research Center's American Trends Panel (ATP), we\ndemonstrate that Anthology achieves up to 18% improvement in matching the\nresponse distributions of human respondents and 27% improvement in consistency\nmetrics. Our code and generated backstories are available at\nhttps://github.com/CannyLab/anthology.",
      "tldr_zh": "本研究提出Anthology方法，通过使用backstories（开放式的人生叙述）来为大型语言模型（LLMs）赋予虚拟角色，从而提升模型在行为研究中模拟人类受试者的准确性和一致性。\n该方法能够更好地代表多样子群体，确保实验结果的可靠性和代表性。\n在Pew Research Center的American Trends Panel调查中，Anthology实现了响应分布与人类受访者匹配度提高多达18%，以及一致性指标提高27%。\n这项工作为LLMs在行为研究中的应用提供了新工具，并开源了代码和生成的backstories。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "EMNLP 2024 Main",
      "pdf_url": "http://arxiv.org/pdf/2407.06576v3",
      "published_date": "2024-07-09 06:11:18 UTC",
      "updated_date": "2024-11-01 22:45:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T05:07:37.525712"
    },
    {
      "arxiv_id": "2407.07959v1",
      "title": "Source Code Summarization in the Era of Large Language Models",
      "title_zh": "大语言模型时代下的源代码总结",
      "authors": [
        "Weisong Sun",
        "Yun Miao",
        "Yuekang Li",
        "Hongyu Zhang",
        "Chunrong Fang",
        "Yi Liu",
        "Gelei Deng",
        "Yang Liu",
        "Zhenyu Chen"
      ],
      "abstract": "To support software developers in understanding and maintaining programs,\nvarious automatic (source) code summarization techniques have been proposed to\ngenerate a concise natural language summary (i.e., comment) for a given code\nsnippet. Recently, the emergence of large language models (LLMs) has led to a\ngreat boost in the performance of code-related tasks. In this paper, we\nundertake a systematic and comprehensive study on code summarization in the era\nof LLMs, which covers multiple aspects involved in the workflow of LLM-based\ncode summarization. Specifically, we begin by examining prevalent automated\nevaluation methods for assessing the quality of summaries generated by LLMs and\nfind that the results of the GPT-4 evaluation method are most closely aligned\nwith human evaluation. Then, we explore the effectiveness of five prompting\ntechniques (zero-shot, few-shot, chain-of-thought, critique, and expert) in\nadapting LLMs to code summarization tasks. Contrary to expectations, advanced\nprompting techniques may not outperform simple zero-shot prompting. Next, we\ninvestigate the impact of LLMs' model settings (including top\\_p and\ntemperature parameters) on the quality of generated summaries. We find the\nimpact of the two parameters on summary quality varies by the base LLM and\nprogramming language, but their impacts are similar. Moreover, we canvass LLMs'\nabilities to summarize code snippets in distinct types of programming\nlanguages. The results reveal that LLMs perform suboptimally when summarizing\ncode written in logic programming languages compared to other language types.\nFinally, we unexpectedly find that CodeLlama-Instruct with 7B parameters can\noutperform advanced GPT-4 in generating summaries describing code\nimplementation details and asserting code properties. We hope that our findings\ncan provide a comprehensive understanding of code summarization in the era of\nLLMs.",
      "tldr_zh": "这篇论文系统研究了大型语言模型（LLMs）在代码总结任务中的应用，涵盖了评估方法、提示技术、模型参数影响以及不同编程语言的表现。研究发现，GPT-4 的评估结果最接近人类判断，而高级提示技术（如 chain-of-thought 和 expert prompting）并不总是优于简单 zero-shot 提示。实验还显示，模型参数（top_p 和 temperature）对总结质量的影响因基础模型和编程语言而异，且 LLMs 在逻辑编程语言上表现较差。最终，7B 参数的 CodeLlama-Instruct 在描述代码实现细节和断言代码属性方面超过了 GPT-4，为 LLMs 时代代码总结提供了全面理解。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "68-04",
        "D.2.3; I.2.7"
      ],
      "primary_category": "cs.SE",
      "comment": "Just accepted to the 47th International Conference on Software\n  Engineering (ICSE 2025)",
      "pdf_url": "http://arxiv.org/pdf/2407.07959v1",
      "published_date": "2024-07-09 05:48:42 UTC",
      "updated_date": "2024-07-09 05:48:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T05:07:50.282491"
    },
    {
      "arxiv_id": "2407.06564v1",
      "title": "Combining Knowledge Graphs and Large Language Models",
      "title_zh": "结合知识图谱和大语言模型",
      "authors": [
        "Amanda Kau",
        "Xuzeng He",
        "Aishwarya Nambissan",
        "Aland Astudillo",
        "Hui Yin",
        "Amir Aryani"
      ],
      "abstract": "In recent years, Natural Language Processing (NLP) has played a significant\nrole in various Artificial Intelligence (AI) applications such as chatbots,\ntext generation, and language translation. The emergence of large language\nmodels (LLMs) has greatly improved the performance of these applications,\nshowing astonishing results in language understanding and generation. However,\nthey still show some disadvantages, such as hallucinations and lack of\ndomain-specific knowledge, that affect their performance in real-world tasks.\nThese issues can be effectively mitigated by incorporating knowledge graphs\n(KGs), which organise information in structured formats that capture\nrelationships between entities in a versatile and interpretable fashion.\nLikewise, the construction and validation of KGs present challenges that LLMs\ncan help resolve. The complementary relationship between LLMs and KGs has led\nto a trend that combines these technologies to achieve trustworthy results.\nThis work collected 28 papers outlining methods for KG-powered LLMs, LLM-based\nKGs, and LLM-KG hybrid approaches. We systematically analysed and compared\nthese approaches to provide a comprehensive overview highlighting key trends,\ninnovative techniques, and common challenges. This synthesis will benefit\nresearchers new to the field and those seeking to deepen their understanding of\nhow KGs and LLMs can be effectively combined to enhance AI applications\ncapabilities.",
      "tldr_zh": "本研究探讨了 Knowledge Graphs (KGs) 与 Large Language Models (LLMs) 的结合，以缓解 LLMs 在实际任务中存在的 hallucinations 和缺乏 domain-specific knowledge 等问题。论文收集并分析了 28 篇相关文献，包括 KG-powered LLMs、LLM-based KGs 和 LLM-KG hybrid approaches，系统比较了这些方法的趋势、创新技术和共同挑战。通过这种互补整合，研究者可以构建更可靠的 AI 应用，并为新手和专家提供全面指导。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.06564v1",
      "published_date": "2024-07-09 05:42:53 UTC",
      "updated_date": "2024-07-09 05:42:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T05:08:02.325740"
    },
    {
      "arxiv_id": "2407.06560v2",
      "title": "TCKAN:A Novel Integrated Network Model for Predicting Mortality Risk in Sepsis Patients",
      "title_zh": "TCKAN：一种用于预测败血症患者死亡风险的新型集成网络模型",
      "authors": [
        "Fanglin Dong"
      ],
      "abstract": "Sepsis poses a major global health threat, accounting for millions of deaths\nannually and significant economic costs. Accurately predicting the risk of\nmortality in sepsis patients enables early identification, promotes the\nefficient allocation of medical resources, and facilitates timely\ninterventions, thereby improving patient outcomes. Current methods typically\nutilize only one type of data--either constant, temporal, or ICD codes. This\nstudy introduces a novel approach, the Time-Constant Kolmogorov-Arnold Network\n(TCKAN), which uniquely integrates temporal data, constant data, and ICD codes\nwithin a single predictive model. Unlike existing methods that typically rely\non one type of data, TCKAN leverages a multi-modal data integration strategy,\nresulting in superior predictive accuracy and robustness in identifying\nhigh-risk sepsis patients. Validated against the MIMIC-III and MIMIC-IV\ndatasets, TCKAN surpasses existing machine learning and deep learning methods\nin accuracy, sensitivity, and specificity. Notably, TCKAN achieved AUCs of\n87.76% and 88.07%, demonstrating superior capability in identifying high-risk\npatients. Additionally, TCKAN effectively combats the prevalent issue of data\nimbalance in clinical settings, improving the detection of patients at elevated\nrisk of mortality and facilitating timely interventions. These results confirm\nthe model's effectiveness and its potential to transform patient management and\ntreatment optimization in clinical practice. Although the TCKAN model has\nalready incorporated temporal, constant, and ICD code data, future research\ncould include more diverse medical data types, such as imaging and laboratory\ntest results, to achieve a more comprehensive data integration and further\nimprove predictive accuracy.",
      "tldr_zh": "本研究针对败血症患者死亡风险预测问题，引入了TCKAN（Time-Constant Kolmogorov-Arnold Network）模型，该模型创新性地整合了时间序列数据、常量数据和ICD代码，实现多模态数据融合，以提升预测准确性和鲁棒性。相比现有仅依赖单一数据类型的机器学习和深度学习方法，TCKAN在MIMIC-III和MIMIC-IV数据集上表现出色，AUC分别达到87.76%和88.07%，并在准确性、敏感性和特异性方面显著优于基线模型，同时有效缓解了临床数据不平衡问题。TCKAN的成功为败血症患者管理提供更可靠的工具，并建议未来通过纳入更多数据类型如影像和实验室测试，进一步提升预测性能。",
      "categories": [
        "stat.AP",
        "cs.AI"
      ],
      "primary_category": "stat.AP",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.06560v2",
      "published_date": "2024-07-09 05:37:50 UTC",
      "updated_date": "2024-11-08 07:07:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T05:08:15.815151"
    },
    {
      "arxiv_id": "2407.06549v1",
      "title": "AutoTask: Task Aware Multi-Faceted Single Model for Multi-Task Ads Relevance",
      "title_zh": "翻译失败",
      "authors": [
        "Shouchang Guo",
        "Sonam Damani",
        "Keng-hao Chang"
      ],
      "abstract": "Ads relevance models are crucial in determining the relevance between user\nsearch queries and ad offers, often framed as a classification problem. The\ncomplexity of modeling increases significantly with multiple ad types and\nvarying scenarios that exhibit both similarities and differences. In this work,\nwe introduce a novel multi-faceted attention model that performs task aware\nfeature combination and cross task interaction modeling. Our technique\nformulates the feature combination problem as \"language\" modeling with\nauto-regressive attentions across both feature and task dimensions.\nSpecifically, we introduce a new dimension of task ID encoding for task\nrepresentations, thereby enabling precise relevance modeling across diverse ad\nscenarios with substantial improvement in generality capability for unseen\ntasks. We demonstrate that our model not only effectively handles the increased\ncomputational and maintenance demands as scenarios proliferate, but also\noutperforms generalized DNN models and even task-specific models across a\nspectrum of ad applications using a single unified model.",
      "tldr_zh": "本研究提出AutoTask，一种任务感知的多方面注意力模型，用于处理多任务广告相关性问题，该模型通过任务ID编码和自回归注意力机制，实现特征组合和跨任务交互建模，从而提升对不同广告场景的泛化能力。相比传统方法，AutoTask将特征组合问题形式化为“语言”建模，适用于多种广告类型和场景。实验结果显示，该单一统一模型不仅降低了计算和维护需求，还在各种广告应用中优于通用DNN模型和任务特定模型。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.06549v1",
      "published_date": "2024-07-09 05:13:45 UTC",
      "updated_date": "2024-07-09 05:13:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T05:08:26.013824"
    },
    {
      "arxiv_id": "2407.06540v1",
      "title": "General and Task-Oriented Video Segmentation",
      "title_zh": "通用与任务导向的视频分割",
      "authors": [
        "Mu Chen",
        "Liulei Li",
        "Wenguan Wang",
        "Ruijie Quan",
        "Yi Yang"
      ],
      "abstract": "We present GvSeg, a general video segmentation framework for addressing four\ndifferent video segmentation tasks (i.e., instance, semantic, panoptic, and\nexemplar-guided) while maintaining an identical architectural design.\nCurrently, there is a trend towards developing general video segmentation\nsolutions that can be applied across multiple tasks. This streamlines research\nendeavors and simplifies deployment. However, such a highly homogenized\nframework in current design, where each element maintains uniformity, could\noverlook the inherent diversity among different tasks and lead to suboptimal\nperformance. To tackle this, GvSeg: i) provides a holistic disentanglement and\nmodeling for segment targets, thoroughly examining them from the perspective of\nappearance, position, and shape, and on this basis, ii) reformulates the query\ninitialization, matching and sampling strategies in alignment with the\ntask-specific requirement. These architecture-agnostic innovations empower\nGvSeg to effectively address each unique task by accommodating the specific\nproperties that characterize them. Extensive experiments on seven gold-standard\nbenchmark datasets demonstrate that GvSeg surpasses all existing\nspecialized/general solutions by a significant margin on four different video\nsegmentation tasks.",
      "tldr_zh": "该论文提出GvSeg，一种通用视频分割框架，能够以相同的架构设计处理四种任务，包括instance segmentation、semantic segmentation、panoptic segmentation和exemplar-guided segmentation，从而避免过度同质化导致的性能问题。GvSeg通过全面解耦和建模分割目标，从appearance、position和shape角度出发，并重新设计查询初始化、匹配和采样策略，以适应各任务的具体需求。这些架构无关的创新使框架更有效地处理任务多样性。在七个基准数据集上的广泛实验显示， GvSeg 在四种视频分割任务中显著优于现有专业或通用解决方案。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "ECCV 2024; Project page: https://github.com/kagawa588/GvSeg",
      "pdf_url": "http://arxiv.org/pdf/2407.06540v1",
      "published_date": "2024-07-09 04:21:38 UTC",
      "updated_date": "2024-07-09 04:21:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T05:08:38.105591"
    },
    {
      "arxiv_id": "2407.06537v2",
      "title": "Efficient and Accurate Memorable Conversation Model using DPO based on sLLM",
      "title_zh": "翻译失败",
      "authors": [
        "Youngkyung Seo",
        "Yoonseok Heo",
        "Jun-Seok Koh",
        "Du-Seong Chang"
      ],
      "abstract": "In multi-session dialog system, it is essential to continuously update the\nmemory as the session progresses. Simply accumulating memory can make it\ndifficult to focus on the content of the conversation for inference due to the\nlimited input sentence size. Therefore, efficient and accurate conversation\nmodel that is capable of managing memory to reflect the conversation history\ncontinuously is necessary. This paper presents a conversation model that\nefficiently manages memory as sessions progress and incorporates this into the\nmodel to reflect the conversation history accurately with 3 methodologies: SFT,\nDPO and DPO with SFT model. Our model using DPO algorithm shows an improvement\nabout 0.0591 of BERTScore in memory accuracy, and the rate of responses\nreflecting the memory increased as well. Also, response generation performance\nenhanced about 4.292 in fluency, 3.935 in coherence, and 2.896 in consistency.\nThis paper describes a training method that yields better performance than\nmodels with more than twice the parameter size, even when the model size is\nsmaller. Thus, our model demonstrates efficiency not only in terms of accuracy\nbut also in resource utilization.",
      "tldr_zh": "本文提出了一种基于 sLLM 的高效准确对话模型，使用 DPO（Direct Preference Optimization）等方法，包括 SFT（Supervised Fine-Tuning）和 DPO with SFT，来管理多会话系统的记忆，确保对话历史持续反映在响应中。实验结果显示，该模型在记忆准确性上提升了约 0.0591 的 BERTScore，同时响应生成性能改善：流畅性提高约 4.292，连贯性提高约 3.935，一致性提高约 2.896。相比参数规模超过两倍的模型，该方法在准确性和资源利用效率上表现出色，即使模型较小也能实现优越性能。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.06537v2",
      "published_date": "2024-07-09 04:17:39 UTC",
      "updated_date": "2024-08-27 04:43:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T05:08:50.933929"
    },
    {
      "arxiv_id": "2407.06533v1",
      "title": "LETS-C: Leveraging Language Embedding for Time Series Classification",
      "title_zh": "LETS-C：利用语言嵌入进行时间序列分类",
      "authors": [
        "Rachneet Kaur",
        "Zhen Zeng",
        "Tucker Balch",
        "Manuela Veloso"
      ],
      "abstract": "Recent advancements in language modeling have shown promising results when\napplied to time series data. In particular, fine-tuning pre-trained large\nlanguage models (LLMs) for time series classification tasks has achieved\nstate-of-the-art (SOTA) performance on standard benchmarks. However, these\nLLM-based models have a significant drawback due to the large model size, with\nthe number of trainable parameters in the millions. In this paper, we propose\nan alternative approach to leveraging the success of language modeling in the\ntime series domain. Instead of fine-tuning LLMs, we utilize a language\nembedding model to embed time series and then pair the embeddings with a simple\nclassification head composed of convolutional neural networks (CNN) and\nmultilayer perceptron (MLP). We conducted extensive experiments on\nwell-established time series classification benchmark datasets. We demonstrated\nLETS-C not only outperforms the current SOTA in classification accuracy but\nalso offers a lightweight solution, using only 14.5% of the trainable\nparameters on average compared to the SOTA model. Our findings suggest that\nleveraging language encoders to embed time series data, combined with a simple\nyet effective classification head, offers a promising direction for achieving\nhigh-performance time series classification while maintaining a lightweight\nmodel architecture.",
      "tldr_zh": "本文提出 LETS-C 方法，利用语言嵌入模型对时间序列数据进行嵌入，然后结合简单的分类头（包括 CNN 和 MLP），以实现高效的时间序列分类。该方法避免了微调大型语言模型（LLMs）的缺点，在标准基准数据集上进行的广泛实验显示，LETS-C 在分类准确性上超过了当前 SOTA 模型，同时仅使用平均 14.5% 的可训练参数。研究结果表明，这种结合语言编码和轻量级架构的策略，为高性能时间序列分类提供了可行的新方向。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CE",
        "cs.CL",
        "stat.ME"
      ],
      "primary_category": "cs.LG",
      "comment": "22 pages, 5 figures, 10 tables",
      "pdf_url": "http://arxiv.org/pdf/2407.06533v1",
      "published_date": "2024-07-09 04:07:57 UTC",
      "updated_date": "2024-07-09 04:07:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T05:09:02.836585"
    },
    {
      "arxiv_id": "2407.14530v1",
      "title": "FuncEvalGMN: Evaluating Functional Correctness of SQL via Graph Matching Network",
      "title_zh": "翻译失败",
      "authors": [
        "Yi Zhan",
        "Yang Sun",
        "Han Weng",
        "Longjie Cui",
        "Guifeng Wang",
        "Jiajun Xie",
        "Yu Tian",
        "Xiaoming Yin",
        "Boyi Liu",
        "Dongchi Huang"
      ],
      "abstract": "In this paper, we propose a novel graph-based methodology to evaluate the\nfunctional correctness of SQL generation. Conventional metrics for assessing\nSQL code generation, such as matching-based and execution-based methods (e.g.,\nexact set match and execution accuracy), are subject to two primary\nlimitations. Firstly, the former fails to effectively assess functional\ncorrectness, as different SQL queries may possess identical functionalities.\nSecondly, the latter is susceptible to producing false positive samples in\nevaluations. Our proposed evaluation method, \\texttt{FuncEvalGMN}, does not\ndepend on the sufficient preparation of the test data, and it enables precise\ntesting of the functional correctness of the code. Firstly, we parse SQL using\na relational operator tree (ROT) called \\textit{Relnode}, which contains rich\nsemantic information from the perspective of logical execution.Then, we\nintroduce a GNN-based approach for predicting the functional correctness of\ngenerated SQL. This approach incorporates global positional embeddings to\naddress the limitations with the loss of topological information in\nconventional graph matching frameworks. As an auxiliary contribution, we\npropose a rule-based matching algorithm, Relnode Partial Matching\n(\\texttt{RelPM}) as a baseline. Finally, we contribute a dataset,\n\\texttt{Pair-Aug-Spider} with a training set and two testing sets, each\ncomprising pairs of SQL codes to simulate various SQL code evaluation\nscenarios. The training set and one testing dataset focus on code generation\nusing large language models (LLMs), while the other emphasizes SQL equivalence\nrewriting.",
      "tldr_zh": "本论文提出了一种基于图匹配网络（Graph Matching Network）的创新方法 FuncEvalGMN，用于评估 SQL 生成的功能正确性，以克服传统指标（如 exact set match 和 execution accuracy）的局限性，这些指标无法有效处理功能等价 SQL 或容易产生假阳性结果。方法首先将 SQL 解析为关系操作树（Relnode），然后采用 GNN-based approach 结合 global positional embeddings 来预测功能正确性，从而保留拓扑信息并实现精确评估。作为辅助贡献，论文引入了基于规则的 Relnode Partial Matching (RelPM) 算法作为基准，并构建了 Pair-Aug-Spider 数据集，包括训练集和测试集，用于模拟 LLM 生成 SQL 和 SQL 等价重写的场景。整体框架不依赖于大量测试数据，为 SQL 功能正确性评估提供了可靠的新途径。",
      "categories": [
        "cs.DB",
        "cs.AI"
      ],
      "primary_category": "cs.DB",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.14530v1",
      "published_date": "2024-07-09 03:05:27 UTC",
      "updated_date": "2024-07-09 03:05:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T05:09:16.404161"
    },
    {
      "arxiv_id": "2407.06512v3",
      "title": "LuSNAR:A Lunar Segmentation, Navigation and Reconstruction Dataset based on Muti-sensor for Autonomous Exploration",
      "title_zh": "翻译失败",
      "authors": [
        "Jiayi Liu",
        "Qianyu Zhang",
        "Xue Wan",
        "Shengyang Zhang",
        "Yaolin Tian",
        "Haodong Han",
        "Yutao Zhao",
        "Baichuan Liu",
        "Zeyuan Zhao",
        "Xubo Luo"
      ],
      "abstract": "With the complexity of lunar exploration missions, the moon needs to have a\nhigher level of autonomy. Environmental perception and navigation algorithms\nare the foundation for lunar rovers to achieve autonomous exploration. The\ndevelopment and verification of algorithms require highly reliable data\nsupport. Most of the existing lunar datasets are targeted at a single task,\nlacking diverse scenes and high-precision ground truth labels. To address this\nissue, we propose a multi-task, multi-scene, and multi-label lunar benchmark\ndataset LuSNAR. This dataset can be used for comprehensive evaluation of\nautonomous perception and navigation systems, including high-resolution stereo\nimage pairs, panoramic semantic labels, dense depth maps, LiDAR point clouds,\nand the position of rover. In order to provide richer scene data, we built 9\nlunar simulation scenes based on Unreal Engine. Each scene is divided according\nto topographic relief and the density of objects. To verify the usability of\nthe dataset, we evaluated and analyzed the algorithms of semantic segmentation,\n3D reconstruction, and autonomous navigation. The experiment results prove that\nthe dataset proposed in this paper can be used for ground verification of tasks\nsuch as autonomous environment perception and navigation, and provides a lunar\nbenchmark dataset for testing the accessibility of algorithm metrics. We make\nLuSNAR publicly available at: https://github.com/zqyu9/LuSNAR-dataset.",
      "tldr_zh": "本文提出 LuSNAR 数据集，这是一个基于多传感器的月球基准数据集，旨在支持自主探索中的分割、导航和重建任务，解决了现有数据集单一任务和场景多样性不足的问题。数据集包含高分辨率立体图像对、全景语义标签、密集深度图、LiDAR 点云以及漫游者位置信息，并利用 Unreal Engine 构建了 9 个模拟月球场景，每个场景根据地形起伏和物体密度进行划分。实验评估了语义 segmentation、3D reconstruction 和自主导航算法，结果证明 LuSNAR 可用于地面验证自主环境感知和导航系统，并作为算法性能测试的公开基准（可用网址：https://github.com/zqyu9/LuSNAR-dataset）。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "19 pages, 13 figures, 11 tables",
      "pdf_url": "http://arxiv.org/pdf/2407.06512v3",
      "published_date": "2024-07-09 02:47:58 UTC",
      "updated_date": "2024-09-26 02:11:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T05:09:27.013611"
    },
    {
      "arxiv_id": "2407.07124v1",
      "title": "FedClust: Tackling Data Heterogeneity in Federated Learning through Weight-Driven Client Clustering",
      "title_zh": "翻译失败",
      "authors": [
        "Md Sirajul Islam",
        "Simin Javaherian",
        "Fei Xu",
        "Xu Yuan",
        "Li Chen",
        "Nian-Feng Tzeng"
      ],
      "abstract": "Federated learning (FL) is an emerging distributed machine learning paradigm\nthat enables collaborative training of machine learning models over\ndecentralized devices without exposing their local data. One of the major\nchallenges in FL is the presence of uneven data distributions across client\ndevices, violating the well-known assumption of\nindependent-and-identically-distributed (IID) training samples in conventional\nmachine learning. To address the performance degradation issue incurred by such\ndata heterogeneity, clustered federated learning (CFL) shows its promise by\ngrouping clients into separate learning clusters based on the similarity of\ntheir local data distributions. However, state-of-the-art CFL approaches\nrequire a large number of communication rounds to learn the distribution\nsimilarities during training until the formation of clusters is stabilized.\nMoreover, some of these algorithms heavily rely on a predefined number of\nclusters, thus limiting their flexibility and adaptability. In this paper, we\npropose {\\em FedClust}, a novel approach for CFL that leverages the correlation\nbetween local model weights and the data distribution of clients. {\\em\nFedClust} groups clients into clusters in a one-shot manner by measuring the\nsimilarity degrees among clients based on the strategically selected partial\nweights of locally trained models. We conduct extensive experiments on four\nbenchmark datasets with different non-IID data settings. Experimental results\ndemonstrate that {\\em FedClust} achieves higher model accuracy up to $\\sim$45\\%\nas well as faster convergence with a significantly reduced communication cost\nup to 2.7$\\times$ compared to its state-of-the-art counterparts.",
      "tldr_zh": "联邦学习（Federated Learning, FL）面临数据异质性问题，导致模型性能下降，为此本文提出FedClust，一种基于本地模型权重驱动的客户端聚类方法。FedClust通过测量本地训练模型的战略性选择的局部权重相似度，实现一次性（one-shot）客户端分组，从而避免了传统Clustered Federated Learning (CFL)方法所需的过多通信轮次和预定义集群数的限制。在四个基准数据集上的实验结果表明，FedClust比现有方法提高了模型准确率高达约45%，加速了收敛速度，并减少了通信成本高达2.7倍。",
      "categories": [
        "cs.DC",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.DC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.07124v1",
      "published_date": "2024-07-09 02:47:16 UTC",
      "updated_date": "2024-07-09 02:47:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T05:09:39.370098"
    },
    {
      "arxiv_id": "2407.06507v1",
      "title": "Economic span selection of bridge based on deep reinforcement learning",
      "title_zh": "基于深度强化学习的桥梁经济跨度选择",
      "authors": [
        "Leye Zhang",
        "Xiangxiang Tian",
        "Chengli Zhang",
        "Hongjun Zhang"
      ],
      "abstract": "Deep Q-network algorithm is used to select economic span of bridge. Selection\nof bridge span has a significant impact on the total cost of bridge, and a\nreasonable selection of span can reduce engineering cost. Economic span of\nbridge is theoretically analyzed, and the theoretical solution formula of\neconomic span is deduced. Construction process of bridge simulation environment\nis described in detail, including observation space, action space and reward\nfunction of the environment. Agent is constructed, convolutional neural network\nis used to approximate Q function,{\\epsilon} greedy policy is used for action\nselection, and experience replay is used for training. The test verifies that\nthe agent can successfully learn optimal policy and realize economic span\nselection of bridge. This study provides a potential decision-making tool for\nbridge design.",
      "tldr_zh": "本文研究利用 Deep Q-network 算法来选择桥梁的经济跨度，以降低工程总成本。作者首先通过理论分析推导了经济跨度的公式，并详细构建了桥梁模拟环境，包括观察空间、动作空间和奖励函数。接着，构建代理使用 convolutional neural network 近似 Q 函数，结合 ε-greedy policy 和 experience replay 进行训练。测试结果显示，代理成功学习最优策略，为桥梁设计提供了潜在的决策工具。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "7 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2407.06507v1",
      "published_date": "2024-07-09 02:27:52 UTC",
      "updated_date": "2024-07-09 02:27:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T05:09:51.476180"
    },
    {
      "arxiv_id": "2407.06501v3",
      "title": "STORYSUMM: Evaluating Faithfulness in Story Summarization",
      "title_zh": "STORYSUMM：评估故事摘要的忠",
      "authors": [
        "Melanie Subbiah",
        "Faisal Ladhak",
        "Akankshya Mishra",
        "Griffin Adams",
        "Lydia B. Chilton",
        "Kathleen McKeown"
      ],
      "abstract": "Human evaluation has been the gold standard for checking faithfulness in\nabstractive summarization. However, with a challenging source domain like\nnarrative, multiple annotators can agree a summary is faithful, while missing\ndetails that are obvious errors only once pointed out. We therefore introduce a\nnew dataset, STORYSUMM, comprising LLM summaries of short stories with\nlocalized faithfulness labels and error explanations. This benchmark is for\nevaluation methods, testing whether a given method can detect challenging\ninconsistencies. Using this dataset, we first show that any one human\nannotation protocol is likely to miss inconsistencies, and we advocate for\npursuing a range of methods when establishing ground truth for a summarization\ndataset. We finally test recent automatic metrics and find that none of them\nachieve more than 70% balanced accuracy on this task, demonstrating that it is\na challenging benchmark for future work in faithfulness evaluation.",
      "tldr_zh": "本论文引入了STORYSUMM数据集，用于评估抽象式摘要在叙事领域中的忠实度（faithfulness），该数据集包含LLM生成的短故事摘要、局部化忠实度标签和错误解释。研究发现，单一人类标注协议容易遗漏不一致性，因此建议采用多种方法建立基准，以提高评估准确性。通过测试最新自动指标，结果显示没有一种达到70%的平衡准确率（balanced accuracy），这为未来忠实度评估工作提供了具有挑战性的基准。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "EMNLP Main 2024",
      "pdf_url": "http://arxiv.org/pdf/2407.06501v3",
      "published_date": "2024-07-09 02:06:30 UTC",
      "updated_date": "2025-04-01 16:54:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T05:10:03.279273"
    },
    {
      "arxiv_id": "2407.06494v4",
      "title": "DiffPhyCon: A Generative Approach to Control Complex Physical Systems",
      "title_zh": "DiffPhyCon：一种生成式方法用于控制复杂物理系统",
      "authors": [
        "Long Wei",
        "Peiyan Hu",
        "Ruiqi Feng",
        "Haodong Feng",
        "Yixuan Du",
        "Tao Zhang",
        "Rui Wang",
        "Yue Wang",
        "Zhi-Ming Ma",
        "Tailin Wu"
      ],
      "abstract": "Controlling the evolution of complex physical systems is a fundamental task\nacross science and engineering. Classical techniques suffer from limited\napplicability or huge computational costs. On the other hand, recent deep\nlearning and reinforcement learning-based approaches often struggle to optimize\nlong-term control sequences under the constraints of system dynamics. In this\nwork, we introduce Diffusion Physical systems Control (DiffPhyCon), a new class\nof method to address the physical systems control problem. DiffPhyCon excels by\nsimultaneously minimizing both the learned generative energy function and the\npredefined control objectives across the entire trajectory and control\nsequence. Thus, it can explore globally and plan near-optimal control\nsequences. Moreover, we enhance DiffPhyCon with prior reweighting, enabling the\ndiscovery of control sequences that significantly deviate from the training\ndistribution. We test our method on three tasks: 1D Burgers' equation, 2D\njellyfish movement control, and 2D high-dimensional smoke control, where our\ngenerated jellyfish dataset is released as a benchmark for complex physical\nsystem control research. Our method outperforms widely applied classical\napproaches and state-of-the-art deep learning and reinforcement learning\nmethods. Notably, DiffPhyCon unveils an intriguing fast-close-slow-open pattern\nobserved in the jellyfish, aligning with established findings in the field of\nfluid dynamics. The project website, jellyfish dataset, and code can be found\nat https://github.com/AI4Science-WestlakeU/diffphycon.",
      "tldr_zh": "本研究提出了一种生成式方法DiffPhyCon，用于控制复杂物理系统，以克服传统技术和深度学习/强化学习方法在优化长期控制序列时的局限性。DiffPhyCon通过同时最小化学习到的生成能量函数和预定义控制目标，实现对整个轨迹的全局探索和近优控制序列规划，并通过prior reweighting增强了其发现偏离训练分布的序列能力。在1D Burgers' equation、2D jellyfish movement control和2D high-dimensional smoke control等任务上，该方法优于现有基准，并揭示了jellyfish的fast-close-slow-open模式，与流体动力学研究一致。该项目还发布了jellyfish数据集和开源代码，以推动相关研究。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "NeurIPS 2024 poster. 51 pages, 19 figures",
      "pdf_url": "http://arxiv.org/pdf/2407.06494v4",
      "published_date": "2024-07-09 01:56:23 UTC",
      "updated_date": "2024-10-29 18:28:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T05:10:16.847033"
    },
    {
      "arxiv_id": "2407.12853v1",
      "title": "Automated Justification Production for Claim Veracity in Fact Checking: A Survey on Architectures and Approaches",
      "title_zh": "翻译失败",
      "authors": [
        "Islam Eldifrawi",
        "Shengrui Wang",
        "Amine Trabelsi"
      ],
      "abstract": "Automated Fact-Checking (AFC) is the automated verification of claim\naccuracy. AFC is crucial in discerning truth from misinformation, especially\ngiven the huge amounts of content are generated online daily. Current research\nfocuses on predicting claim veracity through metadata analysis and language\nscrutiny, with an emphasis on justifying verdicts. This paper surveys recent\nmethodologies, proposing a comprehensive taxonomy and presenting the evolution\nof research in that landscape. A comparative analysis of methodologies and\nfuture directions for improving fact-checking explainability are also\ndiscussed.",
      "tldr_zh": "这篇论文调查了Automated Fact-Checking (AFC) 中声明真实性（claim veracity）的自动理由生成，强调其在区分在线海量内容中的真假信息方面的重要性。论文提出了一个全面的taxonomy，回顾了最近的方法论，包括元数据分析（metadata analysis）和语言审查（language scrutiny），并展示了该领域的研究演变和比较分析。最后，它讨论了提升事实核查可解释性的未来方向，以改进AFC系统的可靠性和透明度。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to ACL 2024 Main Conference",
      "pdf_url": "http://arxiv.org/pdf/2407.12853v1",
      "published_date": "2024-07-09 01:54:13 UTC",
      "updated_date": "2024-07-09 01:54:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T05:10:27.771065"
    },
    {
      "arxiv_id": "2407.06486v2",
      "title": "Optimal Decision Making Through Scenario Simulations Using Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Sumedh Rasal",
        "E. J. Hauer"
      ],
      "abstract": "The rapid evolution of Large Language Models (LLMs) has markedly expanded\ntheir application across diverse domains, transforming how complex problems are\napproached and solved. Initially conceived to predict subsequent words in\ntexts, these models have transcended their original design to comprehend and\nrespond to the underlying contexts of queries. Today, LLMs routinely perform\ntasks that once seemed formidable, such as writing essays, poems, stories, and\neven developing software code. As their capabilities continue to grow, so too\ndo the expectations of their performance in even more sophisticated domains.\n  Despite these advancements, LLMs still encounter significant challenges,\nparticularly in scenarios requiring intricate decision-making, such as planning\ntrips or choosing among multiple viable options. These tasks often demand a\nnuanced understanding of various outcomes and the ability to predict the\nconsequences of different choices, which are currently outside the typical\noperational scope of LLMs.\n  This paper proposes an innovative approach to bridge this capability gap. By\nenabling LLMs to request multiple potential options and their respective\nparameters from users, our system introduces a dynamic framework that\nintegrates an optimization function within the decision-making process. This\nfunction is designed to analyze the provided options, simulate potential\noutcomes, and determine the most advantageous solution based on a set of\npredefined criteria. By harnessing this methodology, LLMs can offer tailored,\noptimal solutions to complex, multi-variable problems, significantly enhancing\ntheir utility and effectiveness in real-world applications. This approach not\nonly expands the functional envelope of LLMs but also paves the way for more\nautonomous and intelligent systems capable of supporting sophisticated\ndecision-making tasks.",
      "tldr_zh": "该论文探讨了Large Language Models (LLMs) 在复杂决策任务（如旅行规划或选项选择）中的局限性，包括对多种结果预测的不足。作者提出一种创新框架，让LLMs 请求用户提供多个潜在选项及其参数，然后通过整合优化函数模拟场景并评估预定义标准，以确定最优解决方案。该方法显著提升了LLMs 处理多变量问题的能力和实用性，为开发更自主、智能的决策支持系统奠定了基础。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.06486v2",
      "published_date": "2024-07-09 01:23:09 UTC",
      "updated_date": "2024-07-10 02:57:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T05:10:39.853853"
    },
    {
      "arxiv_id": "2407.06485v1",
      "title": "CrowdTransfer: Enabling Crowd Knowledge Transfer in AIoT Community",
      "title_zh": "翻译失败",
      "authors": [
        "Yan Liu",
        "Bin Guo",
        "Nuo Li",
        "Yasan Ding",
        "Zhouyangzi Zhang",
        "Zhiwen Yu"
      ],
      "abstract": "Artificial Intelligence of Things (AIoT) is an emerging frontier based on the\ndeep fusion of Internet of Things (IoT) and Artificial Intelligence (AI)\ntechnologies. Although advanced deep learning techniques enhance the efficient\ndata processing and intelligent analysis of complex IoT data, they still suffer\nfrom notable challenges when deployed to practical AIoT applications, such as\nconstrained resources, and diverse task requirements. Knowledge transfer is an\neffective method to enhance learning performance by avoiding the exorbitant\ncosts associated with data recollection and model retraining. Notably, although\nthere are already some valuable and impressive surveys on transfer learning,\nthese surveys introduce approaches in a relatively isolated way and lack the\nrecent advances of various knowledge transfer techniques for AIoT field. This\nsurvey endeavors to introduce a new concept of knowledge transfer, referred to\nas Crowd Knowledge Transfer (CrowdTransfer), which aims to transfer prior\nknowledge learned from a crowd of agents to reduce the training cost and as\nwell as improve the performance of the model in real-world complicated\nscenarios. Particularly, we present four transfer modes from the perspective of\ncrowd intelligence, including derivation, sharing, evolution and fusion modes.\nBuilding upon conventional transfer learning methods, we further delve into\nadvanced crowd knowledge transfer models from three perspectives for various\nAIoT applications. Furthermore, we explore some applications of AIoT areas,\nsuch as human activity recognition, urban computing, multi-robot system, and\nsmart factory. Finally, we discuss the open issues and outline future research\ndirections of knowledge transfer in AIoT community.",
      "tldr_zh": "这篇论文提出 CrowdTransfer 概念，即 Crowd Knowledge Transfer，用于在 AIoT（Artificial Intelligence of Things）社区中实现知识转移，以降低训练成本并提升模型性能。该方法从众智视角定义了四种转移模式：derivation、sharing、evolution 和 fusion，并基于传统转移学习扩展到三个视角的先进模型，适用于各种 AIoT 应用，如 human activity recognition、urban computing、multi-robot system 和 smart factory。论文还探讨了 AIoT 领域的实际挑战和应用，并讨论了开放问题及未来研究方向，以推动更高效的 AIoT 系统发展。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "This paper has been accepted for publication in IEEE Communications\n  Surveys & Tutorials. Copyright will be transferred without notice, after this\n  version may no longer be accessible",
      "pdf_url": "http://arxiv.org/pdf/2407.06485v1",
      "published_date": "2024-07-09 01:20:37 UTC",
      "updated_date": "2024-07-09 01:20:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T05:10:52.215959"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 105,
  "processed_papers_count": 105,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-19T05:11:19.651368"
}