[
  {
    "arxiv_id": "2502.09819v1",
    "title": "A Solver-Aided Hierarchical Language for LLM-Driven CAD Design",
    "authors": [
      "Benjamin T. Jones",
      "Felix HÃ¤hnlein",
      "Zihan Zhang",
      "Maaz Ahmad",
      "Vladimir Kim",
      "Adriana Schulz"
    ],
    "abstract": "Large language models (LLMs) have been enormously successful in solving a\nwide variety of structured and unstructured generative tasks, but they struggle\nto generate procedural geometry in Computer Aided Design (CAD). These\ndifficulties arise from an inability to do spatial reasoning and the necessity\nto guide a model through complex, long range planning to generate complex\ngeometry. We enable generative CAD Design with LLMs through the introduction of\na solver-aided, hierarchical domain specific language (DSL) called AIDL, which\noffloads the spatial reasoning requirements to a geometric constraint solver.\nAdditionally, we show that in the few-shot regime, AIDL outperforms even a\nlanguage with in-training data (OpenSCAD), both in terms of generating visual\nresults closer to the prompt and creating objects that are easier to\npost-process and reason about.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.GR",
      "cs.LG",
      "cs.PL"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.09819v1",
    "published_date": "2025-02-13 23:31:30 UTC",
    "updated_date": "2025-02-13 23:31:30 UTC"
  },
  {
    "arxiv_id": "2502.09809v1",
    "title": "AgentGuard: Repurposing Agentic Orchestrator for Safety Evaluation of Tool Orchestration",
    "authors": [
      "Jizhou Chen",
      "Samuel Lee Cong"
    ],
    "abstract": "The integration of tool use into large language models (LLMs) enables agentic\nsystems with real-world impact. In the meantime, unlike standalone LLMs,\ncompromised agents can execute malicious workflows with more consequential\nimpact, signified by their tool-use capability. We propose AgentGuard, a\nframework to autonomously discover and validate unsafe tool-use workflows,\nfollowed by generating safety constraints to confine the behaviors of agents,\nachieving the baseline of safety guarantee at deployment. AgentGuard leverages\nthe LLM orchestrator's innate capabilities - knowledge of tool functionalities,\nscalable and realistic workflow generation, and tool execution privileges - to\nact as its own safety evaluator. The framework operates through four phases:\nidentifying unsafe workflows, validating them in real-world execution,\ngenerating safety constraints, and validating constraint efficacy. The output,\nan evaluation report with unsafe workflows, test cases, and validated\nconstraints, enables multiple security applications. We empirically demonstrate\nAgentGuard's feasibility with experiments. With this exploratory work, we hope\nto inspire the establishment of standardized testing and hardening procedures\nfor LLM agents to enhance their trustworthiness in real-world applications.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "Project report of AgentGuard in LLM Agent MOOC Hackathon hosted by UC\n  Berkeley in 2024",
    "pdf_url": "http://arxiv.org/pdf/2502.09809v1",
    "published_date": "2025-02-13 23:00:33 UTC",
    "updated_date": "2025-02-13 23:00:33 UTC"
  },
  {
    "arxiv_id": "2502.09804v1",
    "title": "Acute Lymphoblastic Leukemia Diagnosis Employing YOLOv11, YOLOv8, ResNet50, and Inception-ResNet-v2 Deep Learning Models",
    "authors": [
      "Alaa Awad",
      "Salah A. Aly"
    ],
    "abstract": "Thousands of individuals succumb annually to leukemia alone. As artificial\nintelligence-driven technologies continue to evolve and advance, the question\nof their applicability and reliability remains unresolved. This study aims to\nutilize image processing and deep learning methodologies to achieve\nstate-of-the-art results for the detection of Acute Lymphoblastic Leukemia\n(ALL) using data that best represents real-world scenarios. ALL is one of\nseveral types of blood cancer, and it is an aggressive form of leukemia. In\nthis investigation, we examine the most recent advancements in ALL detection,\nas well as the latest iteration of the YOLO series and its performance. We\naddress the question of whether white blood cells are malignant or benign.\nAdditionally, the proposed models can identify different ALL stages, including\nearly stages. Furthermore, these models can detect hematogones despite their\nfrequent misclassification as ALL. By utilizing advanced deep learning models,\nnamely, YOLOv8, YOLOv11, ResNet50 and Inception-ResNet-v2, the study achieves\naccuracy rates as high as 99.7%, demonstrating the effectiveness of these\nalgorithms across multiple datasets and various real-world situations.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "eess.IV",
    "comment": "12 pages, 28 figures, 5 tables",
    "pdf_url": "http://arxiv.org/pdf/2502.09804v1",
    "published_date": "2025-02-13 22:43:28 UTC",
    "updated_date": "2025-02-13 22:43:28 UTC"
  },
  {
    "arxiv_id": "2502.09799v1",
    "title": "Co-designing Large Language Model Tools for Project-Based Learning with K12 Educators",
    "authors": [
      "Prerna Ravi",
      "John Masla",
      "Gisella Kakoti",
      "Grace Lin",
      "Emma Anderson",
      "Matt Taylor",
      "Anastasia Ostrowski",
      "Cynthia Breazeal",
      "Eric Klopfer",
      "Hal Abelson"
    ],
    "abstract": "The emergence of generative AI, particularly large language models (LLMs),\nhas opened the door for student-centered and active learning methods like\nproject-based learning (PBL). However, PBL poses practical implementation\nchallenges for educators around project design and management, assessment, and\nbalancing student guidance with student autonomy. The following research\ndocuments a co-design process with interdisciplinary K-12 teachers to explore\nand address the current PBL challenges they face. Through teacher-driven\ninterviews, collaborative workshops, and iterative design of wireframes, we\ngathered evidence for ways LLMs can support teachers in implementing\nhigh-quality PBL pedagogy by automating routine tasks and enhancing\npersonalized learning. Teachers in the study advocated for supporting their\nprofessional growth and augmenting their current roles without replacing them.\nThey also identified affordances and challenges around classroom integration,\nincluding resource requirements and constraints, ethical concerns, and\npotential immediate and long-term impacts. Drawing on these, we propose design\nguidelines for future deployment of LLM tools in PBL.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.HC",
    "comment": "25 pages",
    "pdf_url": "http://arxiv.org/pdf/2502.09799v1",
    "published_date": "2025-02-13 22:23:08 UTC",
    "updated_date": "2025-02-13 22:23:08 UTC"
  },
  {
    "arxiv_id": "2502.09797v2",
    "title": "A Survey on LLM-based News Recommender Systems",
    "authors": [
      "Rongyao Wang",
      "Veronica Liesaputra",
      "Zhiyi Huang"
    ],
    "abstract": "News recommender systems play a critical role in mitigating the information\noverload problem. In recent years, due to the successful applications of large\nlanguage model technologies, researchers have utilized Discriminative Large\nLanguage Models (DLLMs) or Generative Large Language Models (GLLMs) to improve\nthe performance of news recommender systems. Although several recent surveys\nreview significant challenges for deep learning-based news recommender systems,\nsuch as fairness, privacy-preserving, and responsibility, there is a lack of a\nsystematic survey on Large Language Model (LLM)-based news recommender systems.\nIn order to review different core methodologies and explore potential issues\nsystematically, we categorize DLLM-based and GLLM-based news recommender\nsystems under the umbrella of LLM-based news recommender systems. In this\nsurvey, we first overview the development of deep learning-based news\nrecommender systems. Then, we review LLM-based news recommender systems based\non three aspects: news-oriented modeling, user-oriented modeling, and\nprediction-oriented modeling. Next, we examine the challenges from various\nperspectives, including datasets, benchmarking tools, and methodologies.\nFurthermore, we conduct extensive experiments to analyze how large language\nmodel technologies affect the performance of different news recommender\nsystems. Finally, we comprehensively explore the future directions for\nLLM-based news recommendations in the era of LLMs.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "20 pages",
    "pdf_url": "http://arxiv.org/pdf/2502.09797v2",
    "published_date": "2025-02-13 22:13:59 UTC",
    "updated_date": "2025-02-21 22:24:23 UTC"
  },
  {
    "arxiv_id": "2504.05307v1",
    "title": "Toward Total Recall: Enhancing FAIRness through AI-Driven Metadata Standardization",
    "authors": [
      "Sowmya S Sundaram",
      "Mark A Musen"
    ],
    "abstract": "Current metadata often suffer from incompleteness, inconsistency, and\nincorrect formatting, hindering effective data reuse and discovery. Using GPT-4\nand a metadata knowledge base (CEDAR), we devised a method that standardizes\nmetadata in scientific data sets, ensuring the adherence to community\nstandards. The standardization process involves correcting and refining\nmetadata entries to conform to established guidelines, significantly improving\nsearch performance and recall metrics. The investigation uses BioSample and GEO\nrepositories to demonstrate the impact of these enhancements, showcasing how\nstandardized metadata lead to better retrieval outcomes. The average recall\nimproves significantly, rising from 17.65\\% with the baseline raw datasets of\nBioSample and GEO to 62.87\\% with our proposed metadata standardization\npipeline. This finding highlights the transformative impact of integrating\nadvanced AI models with structured metadata curation tools in achieving more\neffective and reliable data retrieval.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.05307v1",
    "published_date": "2025-02-13 21:58:27 UTC",
    "updated_date": "2025-02-13 21:58:27 UTC"
  },
  {
    "arxiv_id": "2502.09787v1",
    "title": "TableTalk: Scaffolding Spreadsheet Development with a Language Agent",
    "authors": [
      "Jenny T. Liang",
      "Aayush Kumar",
      "Yasharth Bajpai",
      "Sumit Gulwani",
      "Vu Le",
      "Chris Parnin",
      "Arjun Radhakrishna",
      "Ashish Tiwari",
      "Emerson Murphy-Hill",
      "Guastavo Soares"
    ],
    "abstract": "Despite its ubiquity in the workforce, spreadsheet programming remains\nchallenging as programmers need both spreadsheet-specific knowledge (e.g., APIs\nto write formulas) and problem-solving skills to create complex spreadsheets.\nLarge language models (LLMs) can help automate aspects of this process, and\nrecent advances in planning and reasoning have enabled language agents, which\ndynamically plan, use tools, and take iterative actions to complete complex\ntasks. These agents observe, plan, and act, making them well-suited to scaffold\nspreadsheet programming by following expert processes.\n  We present TableTalk, a language agent that helps programmers build\nspreadsheets conversationally. Its design reifies three design principles --\nscaffolding, flexibility, and incrementality -- which we derived from two\nstudies of seven programmers and 62 Excel templates. TableTalk structures\nspreadsheet development by generating step-by-step plans and suggesting three\nnext steps users can choose from. It also integrates tools that enable\nincremental spreadsheet construction. A user study with 20 programmers shows\nthat TableTalk produces spreadsheets 2.3 times more likely to be preferred over\na baseline agent, while reducing cognitive load and time spent reasoning about\nspreadsheet actions by 12.6%. TableTalk's approach has implications for\nhuman-agent collaboration. This includes providing persistent direct\nmanipulation interfaces for stopping or undoing agent actions, while ensuring\nthat such interfaces for accepting actions can be deactivated.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.09787v1",
    "published_date": "2025-02-13 21:43:51 UTC",
    "updated_date": "2025-02-13 21:43:51 UTC"
  },
  {
    "arxiv_id": "2502.09782v3",
    "title": "Improving Acoustic Side-Channel Attacks on Keyboards Using Transformers and Large Language Models",
    "authors": [
      "Jin Hyun Park",
      "Seyyed Ali Ayati",
      "Yichen Cai"
    ],
    "abstract": "The increasing prevalence of microphones in everyday devices and the growing\nreliance on online services have amplified the risk of acoustic side-channel\nattacks (ASCAs) targeting keyboards. This study explores deep learning\ntechniques, specifically vision transformers (VTs) and large language models\n(LLMs), to enhance the effectiveness and applicability of such attacks. We\npresent substantial improvements over prior research, with the CoAtNet model\nachieving state-of-the-art performance. Our CoAtNet shows a 5.0% improvement\nfor keystrokes recorded via smartphone (Phone) and 5.9% for those recorded via\nZoom compared to previous benchmarks. We also evaluate transformer\narchitectures and language models, with the best VT model matching CoAtNet's\nperformance. A key advancement is the introduction of a noise mitigation method\nfor real-world scenarios. By using LLMs for contextual understanding, we detect\nand correct erroneous keystrokes in noisy environments, enhancing ASCA\nperformance. Additionally, fine-tuned lightweight language models with Low-Rank\nAdaptation (LoRA) deliver comparable performance to heavyweight models with 67X\nmore parameters. This integration of VTs and LLMs improves the practical\napplicability of ASCA mitigation, marking the first use of these technologies\nto address ASCAs and error correction in real-world scenarios.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "eess.AS"
    ],
    "primary_category": "cs.LG",
    "comment": "We would like to withdraw our paper due to a significant error in the\n  experimental methodology, which impacts the validity of our results. The\n  error specifically affects the analysis presented in Section 4, where an\n  incorrect dataset preprocessing step led to misleading conclusions",
    "pdf_url": "http://arxiv.org/pdf/2502.09782v3",
    "published_date": "2025-02-13 21:33:57 UTC",
    "updated_date": "2025-02-18 21:39:49 UTC"
  },
  {
    "arxiv_id": "2502.09780v1",
    "title": "Incentivize without Bonus: Provably Efficient Model-based Online Multi-agent RL for Markov Games",
    "authors": [
      "Tong Yang",
      "Bo Dai",
      "Lin Xiao",
      "Yuejie Chi"
    ],
    "abstract": "Multi-agent reinforcement learning (MARL) lies at the heart of a plethora of\napplications involving the interaction of a group of agents in a shared unknown\nenvironment. A prominent framework for studying MARL is Markov games, with the\ngoal of finding various notions of equilibria in a sample-efficient manner,\nsuch as the Nash equilibrium (NE) and the coarse correlated equilibrium (CCE).\nHowever, existing sample-efficient approaches either require tailored\nuncertainty estimation under function approximation, or careful coordination of\nthe players. In this paper, we propose a novel model-based algorithm, called\nVMG, that incentivizes exploration via biasing the empirical estimate of the\nmodel parameters towards those with a higher collective best-response values of\nall the players when fixing the other players' policies, thus encouraging the\npolicy to deviate from its current equilibrium for more exploration. VMG is\noblivious to different forms of function approximation, and permits\nsimultaneous and uncoupled policy updates of all players. Theoretically, we\nalso establish that VMG achieves a near-optimal regret for finding both the NEs\nof two-player zero-sum Markov games and CCEs of multi-player general-sum Markov\ngames under linear function approximation in an online environment, which\nnearly match their counterparts with sophisticated uncertainty quantification.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.GT",
      "math.OC"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.09780v1",
    "published_date": "2025-02-13 21:28:51 UTC",
    "updated_date": "2025-02-13 21:28:51 UTC"
  },
  {
    "arxiv_id": "2502.09777v1",
    "title": "On the existence of EFX allocations in multigraphs",
    "authors": [
      "Alkmini Sgouritsa",
      "Minas Marios Sotiriou"
    ],
    "abstract": "We study the problem of \"fairly\" dividing indivisible goods to several agents\nthat have valuation set functions over the sets of goods. As fair we consider\nthe allocations that are envy-free up to any good (EFX), i.e., no agent envies\nany proper subset of the goods given to any other agent. The existence or not\nof EFX allocations is a major open problem in Fair Division, and there are only\npositive results for special cases.\n  [George Christodoulou, Amos Fiat, Elias Koutsoupias, Alkmini Sgouritsa 2023]\nintroduced a restriction on the agents' valuations according to a graph\nstructure: the vertices correspond to agents and the edges to goods, and each\nvertex/agent has zero marginal value (or in other words, they are indifferent)\nfor the edges/goods that are not adjacent to them. The existence of EFX\nallocations has been shown for simple graphs with general monotone valuations\n[George Christodoulou, Amos Fiat, Elias Koutsoupias, Alkmini Sgouritsa 2023],\nand for multigraphs for restricted additive valuations [Alireza Kaviani, Masoud\nSeddighin, Amir Mohammad Shahrezaei 2024].\n  In this work, we push the state-of-the-art further, and show that the EFX\nallocations always exists in multigraphs and general monotone valuations if any\nof the following three conditions hold: either (a) the multigraph is bipartite,\nor (b) each agent has at most $\\lceil \\frac{n}{4} \\rceil -1$ neighbors, where\n$n$ is the total number of agents, or (c) the shortest cycle with non-parallel\nedges has length at least 6.",
    "categories": [
      "cs.GT",
      "cs.AI"
    ],
    "primary_category": "cs.GT",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.09777v1",
    "published_date": "2025-02-13 21:16:27 UTC",
    "updated_date": "2025-02-13 21:16:27 UTC"
  },
  {
    "arxiv_id": "2502.15761v1",
    "title": "LoXR: Performance Evaluation of Locally Executing LLMs on XR Devices",
    "authors": [
      "Dawar Khan",
      "Xinyu Liu",
      "Omar Mena",
      "Donggang Jia",
      "Alexandre Kouyoumdjian",
      "Ivan Viola"
    ],
    "abstract": "The deployment of large language models (LLMs) on extended reality (XR)\ndevices has great potential to advance the field of human-AI interaction. In\nthe case of direct, on-device model inference, selecting the appropriate model\nand device for specific tasks remains challenging. In this paper, we deploy 17\nLLMs across four XR devices--Magic Leap 2, Meta Quest 3, Vivo X100s Pro, and\nApple Vision Pro, and conduct a comprehensive evaluation. We devise an\nexperimental setup and evaluate performance on four key metrics: performance\nconsistency, processing speed, memory usage, and battery consumption. For each\nof the 68 model-device pairs, we assess performance under varying string\nlengths, batch sizes, and thread counts, analyzing the trade-offs for real-time\nXR applications. We finally propose a unified evaluation method based on the\nPareto Optimality theory to select the optimal device-model pairs from the\nquality and speed objectives. We believe our findings offer valuable insights\nto guide future optimization efforts for LLM deployment on XR devices. Our\nevaluation method can be followed as standard groundwork for further research\nand development in this emerging field. All supplemental materials are\navailable at www.nanovis.org/Loxr.html.",
    "categories": [
      "cs.DC",
      "cs.AI",
      "cs.GR",
      "cs.HC"
    ],
    "primary_category": "cs.DC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.15761v1",
    "published_date": "2025-02-13 20:55:48 UTC",
    "updated_date": "2025-02-13 20:55:48 UTC"
  },
  {
    "arxiv_id": "2502.09767v1",
    "title": "Non-Markovian Discrete Diffusion with Causal Language Models",
    "authors": [
      "Yangtian Zhang",
      "Sizhuang He",
      "Daniel Levine",
      "Lawrence Zhao",
      "David Zhang",
      "Syed A Rizvi",
      "Emanuele Zappala",
      "Rex Ying",
      "David van Dijk"
    ],
    "abstract": "Discrete diffusion models have emerged as a flexible and controllable\nparadigm for structured sequence modeling, yet they still lag behind causal\nlanguage models in expressiveness. To bridge the gap between two paradigms, we\nintroduce CaDDi, a causal discrete diffusion model that unifies sequential and\ntemporal modeling within a non-Markovian diffusion framework. Unlike\nconventional diffusion models that operate step by step with no access to prior\nstates, CaDDi integrates the temporal trajectory, enabling more expressive and\ncontrollable generation. Our approach also treats causal language models as a\nspecial case, allowing seamless adoption of pretrained large language models\n(LLMs) for discrete diffusion without the need for architectural modifications.\nEmpirically, we demonstrate that CaDDi outperforms state-of-the-art discrete\ndiffusion models on both natural language and biological sequence tasks,\nnarrowing the gap between diffusion-based methods and large-scale\nautoregressive transformers.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "Under Review",
    "pdf_url": "http://arxiv.org/pdf/2502.09767v1",
    "published_date": "2025-02-13 20:51:25 UTC",
    "updated_date": "2025-02-13 20:51:25 UTC"
  },
  {
    "arxiv_id": "2502.09765v2",
    "title": "Differential Adjusted Parity for Learning Fair Representations",
    "authors": [
      "Bucher Sahyouni",
      "Matthew Vowels",
      "Liqun Chen",
      "Simon Hadfield"
    ],
    "abstract": "The development of fair and unbiased machine learning models remains an\nongoing objective for researchers in the field of artificial intelligence. We\nintroduce the Differential Adjusted Parity (DAP) loss to produce unbiased\ninformative representations. It utilises a differentiable variant of the\nadjusted parity metric to create a unified objective function. By combining\ndownstream task classification accuracy and its inconsistency across sensitive\nfeature domains, it provides a single tool to increase performance and mitigate\nbias. A key element in this approach is the use of soft balanced accuracies. In\ncontrast to previous non-adversarial approaches, DAP does not suffer a\ndegeneracy where the metric is satisfied by performing equally poorly across\nall sensitive domains. It outperforms several adversarial models on downstream\ntask accuracy and fairness in our analysis. Specifically, it improves the\ndemographic parity, equalized odds and sensitive feature accuracy by as much as\n22.5\\%, 44.1\\% and 40.1\\%, respectively, when compared to the best performing\nadversarial approaches on these metrics. Overall, the DAP loss and its\nassociated metric can play a significant role in creating more fair machine\nlearning models.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.09765v2",
    "published_date": "2025-02-13 20:48:26 UTC",
    "updated_date": "2025-04-09 13:19:22 UTC"
  },
  {
    "arxiv_id": "2502.09762v2",
    "title": "AT-Drone: Benchmarking Adaptive Teaming in Multi-Drone Pursuit",
    "authors": [
      "Yang Li",
      "Junfan Chen",
      "Feng Xue",
      "Jiabin Qiu",
      "Wenbin Li",
      "Qingrui Zhang",
      "Ying Wen",
      "Wei Pan"
    ],
    "abstract": "Adaptive teaming-the capability of agents to effectively collaborate with\nunfamiliar teammates without prior coordination-is widely explored in virtual\nvideo games but overlooked in real-world multi-robot contexts. Yet, such\nadaptive collaboration is crucial for real-world applications, including border\nsurveillance, search-and-rescue, and counter-terrorism operations. To address\nthis gap, we introduce AT-Drone, the first dedicated benchmark explicitly\ndesigned to facilitate comprehensive training and evaluation of adaptive\nteaming strategies in multi-drone pursuit scenarios. AT-Drone makes the\nfollowing key contributions: (1) An adaptable simulation environment\nconfigurator that enables intuitive and rapid setup of adaptive teaming\nmulti-drone pursuit tasks, including four predefined pursuit environments. (2)\nA streamlined real-world deployment pipeline that seamlessly translates\nsimulation insights into practical drone evaluations using edge devices and\nCrazyflie drones. (3) A novel algorithm zoo integrated with a distributed\ntraining framework, featuring diverse algorithms explicitly tailored, for the\nfirst time, to multi-pursuer and multi-evader settings. (4) Standardized\nevaluation protocols with newly designed unseen drone zoos, explicitly designed\nto rigorously assess the performance of adaptive teaming. Comprehensive\nexperimental evaluations across four progressively challenging multi-drone\npursuit scenarios confirm AT-Drone's effectiveness in advancing adaptive\nteaming research. Real-world drone experiments further validate its practical\nfeasibility and utility for realistic robotic operations. Videos, code and\nweights are available at \\url{https://sites.google.com/view/at-drone}.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "18 pages",
    "pdf_url": "http://arxiv.org/pdf/2502.09762v2",
    "published_date": "2025-02-13 20:45:48 UTC",
    "updated_date": "2025-05-02 10:33:06 UTC"
  },
  {
    "arxiv_id": "2502.09757v1",
    "title": "The AI-Therapist Duo: Exploring the Potential of Human-AI Collaboration in Personalized Art Therapy for PICS Intervention",
    "authors": [
      "Bereket A. Yilma",
      "Chan Mi Kim",
      "Geke Ludden",
      "Thomas van Rompay",
      "Luis A. Leiva"
    ],
    "abstract": "Post-intensive care syndrome (PICS) is a multifaceted condition that arises\nfrom prolonged stays in an intensive care unit (ICU). While preventing PICS\namong ICU patients is becoming increasingly important, interventions remain\nlimited. Building on evidence supporting the effectiveness of art exposure in\naddressing the psychological aspects of PICS, we propose a novel art therapy\nsolution through a collaborative Human-AI approach that enhances personalized\ntherapeutic interventions using state-of-the-art Visual Art Recommendation\nSystems. We developed two Human-in-the-Loop (HITL) personalization methods and\nassessed their impact through a large-scale user study (N=150). Our findings\ndemonstrate that this Human-AI collaboration not only enhances the\npersonalization and effectiveness of art therapy but also supports therapists\nby streamlining their workload. While our study centres on PICS intervention,\nthe results suggest that human-AI collaborative Art therapy could potentially\nbenefit other areas where emotional support is critical, such as cases of\nanxiety and depression.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.09757v1",
    "published_date": "2025-02-13 20:31:28 UTC",
    "updated_date": "2025-02-13 20:31:28 UTC"
  },
  {
    "arxiv_id": "2502.09749v1",
    "title": "Vote-Tree-Planner: Optimizing Execution Order in LLM-based Task Planning Pipeline via Voting",
    "authors": [
      "Chaoyuan Zhang",
      "Zhaowei Li",
      "Wentao Yuan"
    ],
    "abstract": "Integrating large language models (LLMs) into closed-loop robotic task\nplanning has become increasingly popular within embodied artificial\nintelligence. Previous efforts mainly focused on leveraging the strong\nreasoning abilities of LLMs to enhance task planning performance while often\noverlooking task planning efficiency and executability due to repetitive\nqueries to LLMs. This paper addresses the synergy between LLMs and task\nplanning systems, aiming to minimize redundancy while enhancing planning\neffectiveness. Specifically, building upon Prog-Prompt and the high-level\nconcept of Tree-Planner, we propose Vote-Tree-Planner. This sampling strategy\nutilizes votes to guide plan traversal during the decision-making process. Our\napproach is motivated by a straightforward observation: assigning weights to\nagents during decision-making enables the evaluation of critical paths before\nexecution. With this simple vote-tree construction, our method further improves\nthe success rate and reduces the number of queries to LLMs. The experimental\nresults highlight that our Vote-Tree-Planner demonstrates greater stability and\nshows a higher average success rate and goal condition recall on the unseen\ndataset compared with previous baseline methods. These findings underscore the\npotential of the Vote-Tree-Planner to enhance planning accuracy, reliability,\nand efficiency in LLM-based planning systems.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "Accepted to RSS24-W: TaskSpec",
    "pdf_url": "http://arxiv.org/pdf/2502.09749v1",
    "published_date": "2025-02-13 20:08:06 UTC",
    "updated_date": "2025-02-13 20:08:06 UTC"
  },
  {
    "arxiv_id": "2502.12173v1",
    "title": "nanoML for Human Activity Recognition",
    "authors": [
      "Alan T. L. Bacellar",
      "Mugdha P. Jadhao",
      "Shashank Nag",
      "Priscila M. V. Lima",
      "Felipe M. G. Franca",
      "Lizy K. John"
    ],
    "abstract": "Human Activity Recognition (HAR) is critical for applications in healthcare,\nfitness, and IoT, but deploying accurate models on resource-constrained devices\nremains challenging due to high energy and memory demands. This paper\ndemonstrates the application of Differentiable Weightless Neural Networks\n(DWNs) to HAR, achieving competitive accuracies of 96.34% and 96.67% while\nconsuming only 56nJ and 104nJ per sample, with an inference time of just 5ns\nper sample. The DWNs were implemented and evaluated on an FPGA, showcasing\ntheir practical feasibility for energy-efficient hardware deployment. DWNs\nachieve up to 926,000x energy savings and 260x memory reduction compared to\nstate-of-the-art deep learning methods. These results position DWNs as a\nnano-machine learning nanoML model for HAR, setting a new benchmark in energy\nefficiency and compactness for edge and wearable devices, paving the way for\nultra-efficient edge AI.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted as a full paper by the 2025 EDGE AI FOUNDATION Austin",
    "pdf_url": "http://arxiv.org/pdf/2502.12173v1",
    "published_date": "2025-02-13 19:40:03 UTC",
    "updated_date": "2025-02-13 19:40:03 UTC"
  },
  {
    "arxiv_id": "2502.09731v1",
    "title": "A CNN Approach to Automated Detection and Classification of Brain Tumors",
    "authors": [
      "Md. Zahid Hasan",
      "Abdullah Tamim",
      "D. M. Asadujjaman",
      "Md. Mahfujur Rahman",
      "Md. Abu Ahnaf Mollick",
      "Nosin Anjum Dristi",
      "Abdullah-Al-Noman"
    ],
    "abstract": "Brain tumors require an assessment to ensure timely diagnosis and effective\npatient treatment. Morphological factors such as size, location, texture, and\nvariable appearance complicate tumor inspection. Medical imaging presents\nchallenges, including noise and incomplete images. This research article\npresents a methodology for processing Magnetic Resonance Imaging (MRI) data,\nencompassing techniques for image classification and denoising. The effective\nuse of MRI images allows medical professionals to detect brain disorders,\nincluding tumors. This research aims to categorize healthy brain tissue and\nbrain tumors by analyzing the provided MRI data. Unlike alternative methods\nlike Computed Tomography (CT), MRI technology offers a more detailed\nrepresentation of internal anatomical components, making it a suitable option\nfor studying data related to brain tumors. The MRI picture is first subjected\nto a denoising technique utilizing an Anisotropic diffusion filter. The dataset\nutilized for the models creation is a publicly accessible and validated Brain\nTumour Classification (MRI) database, comprising 3,264 brain MRI scans. SMOTE\nwas employed for data augmentation and dataset balancing. Convolutional Neural\nNetworks(CNN) such as ResNet152V2, VGG, ViT, and EfficientNet were employed for\nthe classification procedure. EfficientNet attained an accuracy of 98%, the\nhighest recorded.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "68T07",
      "J.3"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.09731v1",
    "published_date": "2025-02-13 19:33:26 UTC",
    "updated_date": "2025-02-13 19:33:26 UTC"
  },
  {
    "arxiv_id": "2502.10477v1",
    "title": "Knowledge Integration Strategies in Autonomous Vehicle Prediction and Planning: A Comprehensive Survey",
    "authors": [
      "Kumar Manas",
      "Adrian Paschke"
    ],
    "abstract": "This comprehensive survey examines the integration of knowledge-based\napproaches into autonomous driving systems, with a focus on trajectory\nprediction and planning. We systematically review methodologies for\nincorporating domain knowledge, traffic rules, and commonsense reasoning into\nthese systems, spanning purely symbolic representations to hybrid\nneuro-symbolic architectures. In particular, we analyze recent advancements in\nformal logic and differential logic programming, reinforcement learning\nframeworks, and emerging techniques that leverage large foundation models and\ndiffusion models for knowledge representation. Organized under a unified\nliterature survey section, our discussion synthesizes the state-of-the-art into\na high-level overview, supported by a detailed comparative table that maps key\nworks to their respective methodological categories. This survey not only\nhighlights current trends -- including the growing emphasis on interpretable\nAI, formal verification in safety-critical systems, and the increased use of\ngenerative models in prediction and planning -- but also outlines the\nchallenges and opportunities for developing robust, knowledge-enhanced\nautonomous driving systems.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.10477v1",
    "published_date": "2025-02-13 19:32:41 UTC",
    "updated_date": "2025-02-13 19:32:41 UTC"
  },
  {
    "arxiv_id": "2502.09723v2",
    "title": "Making Them a Malicious Database: Exploiting Query Code to Jailbreak Aligned Large Language Models",
    "authors": [
      "Qingsong Zou",
      "Jingyu Xiao",
      "Qing Li",
      "Zhi Yan",
      "Yuhang Wang",
      "Li Xu",
      "Wenxuan Wang",
      "Kuofeng Gao",
      "Ruoyu Li",
      "Yong Jiang"
    ],
    "abstract": "Recent advances in large language models (LLMs) have demonstrated remarkable\npotential in the field of natural language processing. Unfortunately, LLMs face\nsignificant security and ethical risks. Although techniques such as safety\nalignment are developed for defense, prior researches reveal the possibility of\nbypassing such defenses through well-designed jailbreak attacks. In this paper,\nwe propose QueryAttack, a novel framework to examine the generalizability of\nsafety alignment. By treating LLMs as knowledge databases, we translate\nmalicious queries in natural language into structured non-natural query\nlanguage to bypass the safety alignment mechanisms of LLMs. We conduct\nextensive experiments on mainstream LLMs, and the results show that QueryAttack\nnot only can achieve high attack success rates (ASRs), but also can jailbreak\nvarious defense methods. Furthermore, we tailor a defense method against\nQueryAttack, which can reduce ASR by up to 64% on GPT-4-1106. Our code is\navailable at https://github.com/horizonsinzqs/QueryAttack.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CR",
    "comment": "15 pages, 11 figures",
    "pdf_url": "http://arxiv.org/pdf/2502.09723v2",
    "published_date": "2025-02-13 19:13:03 UTC",
    "updated_date": "2025-02-20 07:19:05 UTC"
  },
  {
    "arxiv_id": "2502.09720v1",
    "title": "NestQuant: Nested Lattice Quantization for Matrix Products and LLMs",
    "authors": [
      "Semyon Savkin",
      "Eitan Porat",
      "Or Ordentlich",
      "Yury Polyanskiy"
    ],
    "abstract": "Post-training quantization (PTQ) has emerged as a critical technique for\nefficient deployment of large language models (LLMs). This work proposes\nNestQuant, a novel PTQ scheme for weights and activations that is based on\nself-similar nested lattices. Recent work have mathematically shown such\nquantizers to be information-theoretically optimal for low-precision matrix\nmultiplication. We implement a practical low-complexity version of NestQuant\nbased on Gosset lattice, making it a drop-in quantizer for any matrix\nmultiplication step (e.g., in self-attention, MLP etc). For example, NestQuant\nquantizes weights, KV-cache, and activations of Llama-3-8B to 4 bits, achieving\nperplexity of 6.6 on wikitext2. This represents more than 55% reduction in\nperplexity gap with respect to unquantized model (perplexity of 6.14) compared\nto state-of-the-art Meta's SpinQuant (perplexity 7.3). Comparisons on various\nLLM evaluation benchmarks also show a reduction in performance degradation\ninduced by quantization.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.IT",
      "math.IT"
    ],
    "primary_category": "cs.LG",
    "comment": "16 pages",
    "pdf_url": "http://arxiv.org/pdf/2502.09720v1",
    "published_date": "2025-02-13 19:11:40 UTC",
    "updated_date": "2025-02-13 19:11:40 UTC"
  },
  {
    "arxiv_id": "2502.09715v1",
    "title": "Evaluating GPT's Capability in Identifying Stages of Cognitive Impairment from Electronic Health Data",
    "authors": [
      "Yu Leng",
      "Yingnan He",
      "Colin Magdamo",
      "Ana-Maria Vranceanu",
      "Christine S. Ritchie",
      "Shibani S. Mukerji",
      "Lidia M. V. R. Moura",
      "John R. Dickson",
      "Deborah Blacker",
      "Sudeshna Das"
    ],
    "abstract": "Identifying cognitive impairment within electronic health records (EHRs) is\ncrucial not only for timely diagnoses but also for facilitating research.\nInformation about cognitive impairment often exists within unstructured\nclinician notes in EHRs, but manual chart reviews are both time-consuming and\nerror-prone. To address this issue, our study evaluates an automated approach\nusing zero-shot GPT-4o to determine stage of cognitive impairment in two\ndifferent tasks. First, we evaluated the ability of GPT-4o to determine the\nglobal Clinical Dementia Rating (CDR) on specialist notes from 769 patients who\nvisited the memory clinic at Massachusetts General Hospital (MGH), and achieved\na weighted kappa score of 0.83. Second, we assessed GPT-4o's ability to\ndifferentiate between normal cognition, mild cognitive impairment (MCI), and\ndementia on all notes in a 3-year window from 860 Medicare patients. GPT-4o\nattained a weighted kappa score of 0.91 in comparison to specialist chart\nreviews and 0.96 on cases that the clinical adjudicators rated with high\nconfidence. Our findings demonstrate GPT-4o's potential as a scalable chart\nreview tool for creating research datasets and assisting diagnosis in clinical\nsettings in the future.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "Findings paper presented at Machine Learning for Health (ML4H)\n  symposium 2024, December 15-16, 2024, Vancouver, Canada, 7 pages",
    "pdf_url": "http://arxiv.org/pdf/2502.09715v1",
    "published_date": "2025-02-13 19:04:47 UTC",
    "updated_date": "2025-02-13 19:04:47 UTC"
  },
  {
    "arxiv_id": "2502.10476v1",
    "title": "Multi-Objective Planning with Contextual Lexicographic Reward Preferences",
    "authors": [
      "Pulkit Rustagi",
      "Yashwanthi Anand",
      "Sandhya Saisubramanian"
    ],
    "abstract": "Autonomous agents are often required to plan under multiple objectives whose\npreference ordering varies based on context. The agent may encounter multiple\ncontexts during its course of operation, each imposing a distinct lexicographic\nordering over the objectives, with potentially different reward functions\nassociated with each context. Existing approaches to multi-objective planning\ntypically consider a single preference ordering over the objectives, across the\nstate space, and do not support planning under multiple objective orderings\nwithin an environment. We present Contextual Lexicographic Markov Decision\nProcess (CLMDP), a framework that enables planning under varying lexicographic\nobjective orderings, depending on the context. In a CLMDP, both the objective\nordering at a state and the associated reward functions are determined by the\ncontext. We employ a Bayesian approach to infer a state-context mapping from\nexpert trajectories. Our algorithm to solve a CLMDP first computes a policy for\neach objective ordering and then combines them into a single context-aware\npolicy that is valid and cycle-free. The effectiveness of the proposed approach\nis evaluated in simulation and using a mobile robot.",
    "categories": [
      "cs.AI",
      "cs.RO",
      "cs.SY"
    ],
    "primary_category": "cs.AI",
    "comment": "9 pages, 5 figures, 2 tables, To appear in Proceedings of the 24th\n  International Conference on Autonomous Agents and Multiagent Systems (AAMAS)\n  2025",
    "pdf_url": "http://arxiv.org/pdf/2502.10476v1",
    "published_date": "2025-02-13 19:04:22 UTC",
    "updated_date": "2025-02-13 19:04:22 UTC"
  },
  {
    "arxiv_id": "2502.09622v1",
    "title": "Theoretical Benefit and Limitation of Diffusion Language Model",
    "authors": [
      "Guhao Feng",
      "Yihan Geng",
      "Jian Guan",
      "Wei Wu",
      "Liwei Wang",
      "Di He"
    ],
    "abstract": "Diffusion language models have emerged as a promising approach for text\ngeneration. One would naturally expect this method to be an efficient\nreplacement for autoregressive models since multiple tokens can be sampled in\nparallel during each diffusion step. However, its efficiency-accuracy trade-off\nis not yet well understood. In this paper, we present a rigorous theoretical\nanalysis of a widely used type of diffusion language model, the Masked\nDiffusion Model (MDM), and find that its effectiveness heavily depends on the\ntarget evaluation metric. Under mild conditions, we prove that when using\nperplexity as the metric, MDMs can achieve near-optimal perplexity in sampling\nsteps regardless of sequence length, demonstrating that efficiency can be\nachieved without sacrificing performance. However, when using the sequence\nerror rate--which is important for understanding the \"correctness\" of a\nsequence, such as a reasoning chain--we show that the required sampling steps\nmust scale linearly with sequence length to obtain \"correct\" sequences, thereby\neliminating MDM's efficiency advantage over autoregressive models. Our analysis\nestablishes the first theoretical foundation for understanding the benefits and\nlimitations of MDMs. All theoretical findings are supported by empirical\nstudies.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "32 pages, 3 figures",
    "pdf_url": "http://arxiv.org/pdf/2502.09622v1",
    "published_date": "2025-02-13 18:59:47 UTC",
    "updated_date": "2025-02-13 18:59:47 UTC"
  },
  {
    "arxiv_id": "2502.09621v1",
    "title": "MME-CoT: Benchmarking Chain-of-Thought in Large Multimodal Models for Reasoning Quality, Robustness, and Efficiency",
    "authors": [
      "Dongzhi Jiang",
      "Renrui Zhang",
      "Ziyu Guo",
      "Yanwei Li",
      "Yu Qi",
      "Xinyan Chen",
      "Liuhui Wang",
      "Jianhan Jin",
      "Claire Guo",
      "Shen Yan",
      "Bo Zhang",
      "Chaoyou Fu",
      "Peng Gao",
      "Hongsheng Li"
    ],
    "abstract": "Answering questions with Chain-of-Thought (CoT) has significantly enhanced\nthe reasoning capabilities of Large Language Models (LLMs), yet its impact on\nLarge Multimodal Models (LMMs) still lacks a systematic assessment and in-depth\ninvestigation. In this paper, we introduce MME-CoT, a specialized benchmark\nevaluating the CoT reasoning performance of LMMs, spanning six domains: math,\nscience, OCR, logic, space-time, and general scenes. As the first comprehensive\nstudy in this area, we propose a thorough evaluation suite incorporating three\nnovel metrics that assess the reasoning quality, robustness, and efficiency at\na fine-grained level. Leveraging curated high-quality data and a unique\nevaluation strategy, we conduct an in-depth analysis of state-of-the-art LMMs,\nuncovering several key insights: 1) Models with reflection mechanism\ndemonstrate a superior CoT quality, with Kimi k1.5 outperforming GPT-4o and\ndemonstrating the highest quality results; 2) CoT prompting often degrades LMM\nperformance on perception-heavy tasks, suggesting a potentially harmful\noverthinking behavior; and 3) Although the CoT quality is high, LMMs with\nreflection exhibit significant inefficiency in both normal response and\nself-correction phases. We hope MME-CoT serves as a foundation for advancing\nmultimodal reasoning in LMMs. Project Page: https://mmecot.github.io/",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CV",
    "comment": "Project Page: https://mmecot.github.io/",
    "pdf_url": "http://arxiv.org/pdf/2502.09621v1",
    "published_date": "2025-02-13 18:59:46 UTC",
    "updated_date": "2025-02-13 18:59:46 UTC"
  },
  {
    "arxiv_id": "2502.09620v2",
    "title": "Exploring the Potential of Encoder-free Architectures in 3D LMMs",
    "authors": [
      "Yiwen Tang",
      "Zoey Guo",
      "Zhuhao Wang",
      "Ray Zhang",
      "Qizhi Chen",
      "Junli Liu",
      "Delin Qu",
      "Zhigang Wang",
      "Dong Wang",
      "Xuelong Li",
      "Bin Zhao"
    ],
    "abstract": "Encoder-free architectures have been preliminarily explored in the 2D visual\ndomain, yet it remains an open question whether they can be effectively applied\nto 3D understanding scenarios. In this paper, we present the first\ncomprehensive investigation into the potential of encoder-free architectures to\nalleviate the challenges of encoder-based 3D Large Multimodal Models (LMMs).\nThese challenges include the failure to adapt to varying point cloud\nresolutions and the point features from the encoder not meeting the semantic\nneeds of Large Language Models (LLMs). We identify key aspects for 3D LMMs to\nremove the encoder and enable the LLM to assume the role of the 3D encoder: 1)\nWe propose the LLM-embedded Semantic Encoding strategy in the pre-training\nstage, exploring the effects of various point cloud self-supervised losses. And\nwe present the Hybrid Semantic Loss to extract high-level semantics. 2) We\nintroduce the Hierarchical Geometry Aggregation strategy in the instruction\ntuning stage. This incorporates inductive bias into the LLM layers to focus on\nthe local details of the point clouds. To the end, we present the first\nEncoder-free 3D LMM, ENEL. Our 7B model rivals the current state-of-the-art\nmodel, ShapeLLM-13B, achieving 55.10%, 50.98%, and 43.10% on the\nclassification, captioning, and VQA tasks, respectively. Our results\ndemonstrate that the encoder-free architecture is highly promising for\nreplacing encoder-based architectures in the field of 3D understanding. The\ncode is released at https://github.com/Ivan-Tang-3D/ENEL",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CV",
    "comment": "The code is released at https://github.com/Ivan-Tang-3D/ENEL",
    "pdf_url": "http://arxiv.org/pdf/2502.09620v2",
    "published_date": "2025-02-13 18:59:45 UTC",
    "updated_date": "2025-05-17 03:38:29 UTC"
  },
  {
    "arxiv_id": "2502.09614v1",
    "title": "DexTrack: Towards Generalizable Neural Tracking Control for Dexterous Manipulation from Human References",
    "authors": [
      "Xueyi Liu",
      "Jianibieke Adalibieke",
      "Qianwei Han",
      "Yuzhe Qin",
      "Li Yi"
    ],
    "abstract": "We address the challenge of developing a generalizable neural tracking\ncontroller for dexterous manipulation from human references. This controller\naims to manage a dexterous robot hand to manipulate diverse objects for various\npurposes defined by kinematic human-object interactions. Developing such a\ncontroller is complicated by the intricate contact dynamics of dexterous\nmanipulation and the need for adaptivity, generalizability, and robustness.\nCurrent reinforcement learning and trajectory optimization methods often fall\nshort due to their dependence on task-specific rewards or precise system\nmodels. We introduce an approach that curates large-scale successful robot\ntracking demonstrations, comprising pairs of human references and robot\nactions, to train a neural controller. Utilizing a data flywheel, we\niteratively enhance the controller's performance, as well as the number and\nquality of successful tracking demonstrations. We exploit available tracking\ndemonstrations and carefully integrate reinforcement learning and imitation\nlearning to boost the controller's performance in dynamic environments. At the\nsame time, to obtain high-quality tracking demonstrations, we individually\noptimize per-trajectory tracking by leveraging the learned tracking controller\nin a homotopy optimization method. The homotopy optimization, mimicking\nchain-of-thought, aids in solving challenging trajectory tracking problems to\nincrease demonstration diversity. We showcase our success by training a\ngeneralizable neural controller and evaluating it in both simulation and real\nworld. Our method achieves over a 10% improvement in success rates compared to\nleading baselines. The project website with animated results is available at\nhttps://meowuu7.github.io/DexTrack/.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "Accepted to ICLR 2025. Website: https://meowuu7.github.io/DexTrack/\n  Code: https://github.com/Meowuu7/DexTrack/ Video:\n  https://youtu.be/zru1Z-DaiWE",
    "pdf_url": "http://arxiv.org/pdf/2502.09614v1",
    "published_date": "2025-02-13 18:59:13 UTC",
    "updated_date": "2025-02-13 18:59:13 UTC"
  },
  {
    "arxiv_id": "2502.09609v2",
    "title": "Score-of-Mixture Training: Training One-Step Generative Models Made Simple via Score Estimation of Mixture Distributions",
    "authors": [
      "Tejas Jayashankar",
      "J. Jon Ryu",
      "Gregory Wornell"
    ],
    "abstract": "We propose Score-of-Mixture Training (SMT), a novel framework for training\none-step generative models by minimizing a class of divergences called the\n$\\alpha$-skew Jensen-Shannon divergence. At its core, SMT estimates the score\nof mixture distributions between real and fake samples across multiple noise\nlevels. Similar to consistency models, our approach supports both training from\nscratch (SMT) and distillation using a pretrained diffusion model, which we\ncall Score-of-Mixture Distillation (SMD). It is simple to implement, requires\nminimal hyperparameter tuning, and ensures stable training. Experiments on\nCIFAR-10 and ImageNet 64x64 show that SMT/SMD are competitive with and can even\noutperform existing methods.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "27 pages, 9 figures. Title updated to match the title of the\n  manuscript, otherwise identical to v1",
    "pdf_url": "http://arxiv.org/pdf/2502.09609v2",
    "published_date": "2025-02-13 18:57:20 UTC",
    "updated_date": "2025-02-14 02:32:22 UTC"
  },
  {
    "arxiv_id": "2502.09606v2",
    "title": "Human-LLM Coevolution: Evidence from Academic Writing",
    "authors": [
      "Mingmeng Geng",
      "Roberto Trotta"
    ],
    "abstract": "With a statistical analysis of arXiv paper abstracts, we report a marked drop\nin the frequency of several words previously identified as overused by ChatGPT,\nsuch as \"delve\", starting soon after they were pointed out in early 2024. The\nfrequency of certain other words favored by ChatGPT, such as \"significant\", has\ninstead kept increasing. These phenomena suggest that some authors of academic\npapers have adapted their use of large language models (LLMs), for example, by\nselecting outputs or applying modifications to the LLM-generated content. Such\ncoevolution and cooperation of humans and LLMs thus introduce additional\nchallenges to the detection of machine-generated text in real-world scenarios.\nEstimating the impact of LLMs on academic writing by examining word frequency\nremains feasible, and more attention should be paid to words that were already\nfrequently employed, including those that have decreased in frequency due to\nLLMs' disfavor.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CY",
      "cs.DL",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.09606v2",
    "published_date": "2025-02-13 18:55:56 UTC",
    "updated_date": "2025-02-17 18:48:26 UTC"
  },
  {
    "arxiv_id": "2502.09604v1",
    "title": "SelfCite: Self-Supervised Alignment for Context Attribution in Large Language Models",
    "authors": [
      "Yung-Sung Chuang",
      "Benjamin Cohen-Wang",
      "Shannon Zejiang Shen",
      "Zhaofeng Wu",
      "Hu Xu",
      "Xi Victoria Lin",
      "James Glass",
      "Shang-Wen Li",
      "Wen-tau Yih"
    ],
    "abstract": "We introduce SelfCite, a novel self-supervised approach that aligns LLMs to\ngenerate high-quality, fine-grained, sentence-level citations for the\nstatements in their generated responses. Instead of only relying on costly and\nlabor-intensive annotations, SelfCite leverages a reward signal provided by the\nLLM itself through context ablation: If a citation is necessary, removing the\ncited text from the context should prevent the same response; if sufficient,\nretaining the cited text alone should preserve the same response. This reward\ncan guide the inference-time best-of-N sampling strategy to improve citation\nquality significantly, as well as be used in preference optimization to\ndirectly fine-tune the models for generating better citations. The\neffectiveness of SelfCite is demonstrated by increasing citation F1 up to 5.3\npoints on the LongBench-Cite benchmark across five long-form question answering\ntasks.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Implementation available at https://github.com/voidism/SelfCite",
    "pdf_url": "http://arxiv.org/pdf/2502.09604v1",
    "published_date": "2025-02-13 18:55:13 UTC",
    "updated_date": "2025-02-13 18:55:13 UTC"
  },
  {
    "arxiv_id": "2502.09601v1",
    "title": "CoT-Valve: Length-Compressible Chain-of-Thought Tuning",
    "authors": [
      "Xinyin Ma",
      "Guangnian Wan",
      "Runpeng Yu",
      "Gongfan Fang",
      "Xinchao Wang"
    ],
    "abstract": "Chain-of-Thought significantly enhances a model's reasoning capability, but\nit also comes with a considerable increase in inference costs due to long\nchains. With the observation that the reasoning path can be easily compressed\nunder easy tasks but struggle on hard tasks, we explore the feasibility of\nelastically controlling the length of reasoning paths with only one model,\nthereby reducing the inference overhead of reasoning models dynamically based\non task difficulty. We introduce a new tuning and inference strategy named\nCoT-Valve, designed to allow models to generate reasoning chains of varying\nlengths. To achieve this, we propose to identify a direction in the parameter\nspace that, when manipulated, can effectively control the length of generated\nCoT. Moreover, we show that this property is valuable for compressing the\nreasoning chain. We construct datasets with chains from long to short for the\nsame questions and explore two enhanced strategies for CoT-Valve: (1) a precise\nlength-compressible CoT tuning method, and (2) a progressive chain length\ncompression approach. Our experiments show that CoT-Valve successfully enables\ncontrollability and compressibility of the chain and shows better performance\nthan the prompt-based control. We applied this method to QwQ-32B-Preview,\nreducing reasoning chains on GSM8K from 741 to 225 tokens with a minor\nperformance drop (95.07% to 94.92%) and on AIME from 6827 to 4629 tokens, with\nonly one additional incorrect answer.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "Work in progress. Code will be released at\n  https://github.com/horseee/CoT-Valve",
    "pdf_url": "http://arxiv.org/pdf/2502.09601v1",
    "published_date": "2025-02-13 18:52:36 UTC",
    "updated_date": "2025-02-13 18:52:36 UTC"
  },
  {
    "arxiv_id": "2502.09596v1",
    "title": "KIMAs: A Configurable Knowledge Integrated Multi-Agent System",
    "authors": [
      "Zitao Li",
      "Fei Wei",
      "Yuexiang Xie",
      "Dawei Gao",
      "Weirui Kuang",
      "Zhijian Ma",
      "Bingchen Qian",
      "Yaliang Li",
      "Bolin Ding"
    ],
    "abstract": "Knowledge-intensive conversations supported by large language models (LLMs)\nhave become one of the most popular and helpful applications that can assist\npeople in different aspects. Many current knowledge-intensive applications are\ncentered on retrieval-augmented generation (RAG) techniques. While many\nopen-source RAG frameworks facilitate the development of RAG-based\napplications, they often fall short in handling practical scenarios complicated\nby heterogeneous data in topics and formats, conversational context management,\nand the requirement of low-latency response times. This technical report\npresents a configurable knowledge integrated multi-agent system, KIMAs, to\naddress these challenges. KIMAs features a flexible and configurable system for\nintegrating diverse knowledge sources with 1) context management and query\nrewrite mechanisms to improve retrieval accuracy and multi-turn conversational\ncoherency, 2) efficient knowledge routing and retrieval, 3) simple but\neffective filter and reference generation mechanisms, and 4) optimized\nparallelizable multi-agent pipeline execution. Our work provides a scalable\nframework for advancing the deployment of LLMs in real-world settings. To show\nhow KIMAs can help developers build knowledge-intensive applications with\ndifferent scales and emphases, we demonstrate how we configure the system to\nthree applications already running in practice with reliable performance.",
    "categories": [
      "cs.AI",
      "cs.MA"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.09596v1",
    "published_date": "2025-02-13 18:51:12 UTC",
    "updated_date": "2025-02-13 18:51:12 UTC"
  },
  {
    "arxiv_id": "2502.09567v1",
    "title": "MorphNLI: A Stepwise Approach to Natural Language Inference Using Text Morphing",
    "authors": [
      "Vlad Andrei Negru",
      "Robert Vacareanu",
      "Camelia Lemnaru",
      "Mihai Surdeanu",
      "Rodica Potolea"
    ],
    "abstract": "We introduce MorphNLI, a modular step-by-step approach to natural language\ninference (NLI). When classifying the premise-hypothesis pairs into\n{entailment, contradiction, neutral}, we use a language model to generate the\nnecessary edits to incrementally transform (i.e., morph) the premise into the\nhypothesis. Then, using an off-the-shelf NLI model we track how the entailment\nprogresses with these atomic changes, aggregating these intermediate labels\ninto a final output. We demonstrate the advantages of our proposed method\nparticularly in realistic cross-domain settings, where our method always\noutperforms strong baselines with improvements up to 12.6% (relative). Further,\nour proposed approach is explainable as the atomic edits can be used to\nunderstand the overall NLI label.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "16 pages, 11 figures, 8 tables. Accepted for NAACL 2025 Findings",
    "pdf_url": "http://arxiv.org/pdf/2502.09567v1",
    "published_date": "2025-02-13 18:22:31 UTC",
    "updated_date": "2025-02-13 18:22:31 UTC"
  },
  {
    "arxiv_id": "2502.09565v1",
    "title": "MDCrow: Automating Molecular Dynamics Workflows with Large Language Models",
    "authors": [
      "Quintina Campbell",
      "Sam Cox",
      "Jorge Medina",
      "Brittany Watterson",
      "Andrew D. White"
    ],
    "abstract": "Molecular dynamics (MD) simulations are essential for understanding\nbiomolecular systems but remain challenging to automate. Recent advances in\nlarge language models (LLM) have demonstrated success in automating complex\nscientific tasks using LLM-based agents. In this paper, we introduce MDCrow, an\nagentic LLM assistant capable of automating MD workflows. MDCrow uses\nchain-of-thought over 40 expert-designed tools for handling and processing\nfiles, setting up simulations, analyzing the simulation outputs, and retrieving\nrelevant information from literature and databases. We assess MDCrow's\nperformance across 25 tasks of varying required subtasks and difficulty, and we\nevaluate the agent's robustness to both difficulty and prompt style.\n\\texttt{gpt-4o} is able to complete complex tasks with low variance, followed\nclosely by \\texttt{llama3-405b}, a compelling open-source model. While prompt\nstyle does not influence the best models' performance, it has significant\neffects on smaller models.",
    "categories": [
      "cs.AI",
      "physics.chem-ph"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.09565v1",
    "published_date": "2025-02-13 18:19:20 UTC",
    "updated_date": "2025-02-13 18:19:20 UTC"
  },
  {
    "arxiv_id": "2502.09560v2",
    "title": "EmbodiedBench: Comprehensive Benchmarking Multi-modal Large Language Models for Vision-Driven Embodied Agents",
    "authors": [
      "Rui Yang",
      "Hanyang Chen",
      "Junyu Zhang",
      "Mark Zhao",
      "Cheng Qian",
      "Kangrui Wang",
      "Qineng Wang",
      "Teja Venkat Koripella",
      "Marziyeh Movahedi",
      "Manling Li",
      "Heng Ji",
      "Huan Zhang",
      "Tong Zhang"
    ],
    "abstract": "Leveraging Multi-modal Large Language Models (MLLMs) to create embodied\nagents offers a promising avenue for tackling real-world tasks. While\nlanguage-centric embodied agents have garnered substantial attention,\nMLLM-based embodied agents remain underexplored due to the lack of\ncomprehensive evaluation frameworks. To bridge this gap, we introduce\nEmbodiedBench, an extensive benchmark designed to evaluate vision-driven\nembodied agents. EmbodiedBench features: (1) a diverse set of 1,128 testing\ntasks across four environments, ranging from high-level semantic tasks (e.g.,\nhousehold) to low-level tasks involving atomic actions (e.g., navigation and\nmanipulation); and (2) six meticulously curated subsets evaluating essential\nagent capabilities like commonsense reasoning, complex instruction\nunderstanding, spatial awareness, visual perception, and long-term planning.\nThrough extensive experiments, we evaluated 19 leading proprietary and\nopen-source MLLMs within EmbodiedBench. Our findings reveal that: MLLMs excel\nat high-level tasks but struggle with low-level manipulation, with the best\nmodel, GPT-4o, scoring only 28.9% on average. EmbodiedBench provides a\nmultifaceted standardized evaluation platform that not only highlights existing\nchallenges but also offers valuable insights to advance MLLM-based embodied\nagents. Our code is available at https://embodiedbench.github.io.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.CV"
    ],
    "primary_category": "cs.AI",
    "comment": "52 pages",
    "pdf_url": "http://arxiv.org/pdf/2502.09560v2",
    "published_date": "2025-02-13 18:11:34 UTC",
    "updated_date": "2025-02-23 07:30:59 UTC"
  },
  {
    "arxiv_id": "2502.10475v2",
    "title": "X-SG$^2$S: Safe and Generalizable Gaussian Splatting with X-dimensional Watermarks",
    "authors": [
      "Zihang Cheng",
      "Huiping Zhuang",
      "Chun Li",
      "Xin Meng",
      "Ming Li",
      "Fei Richard Yu",
      "Liqiang Nie"
    ],
    "abstract": "3D Gaussian Splatting (3DGS) has been widely used in 3D reconstruction and 3D\ngeneration. Training to get a 3DGS scene often takes a lot of time and\nresources and even valuable inspiration. The increasing amount of 3DGS digital\nasset have brought great challenges to the copyright protection. However, it\nstill lacks profound exploration targeted at 3DGS. In this paper, we propose a\nnew framework X-SG$^2$S which can simultaneously watermark 1 to 3D messages\nwhile keeping the original 3DGS scene almost unchanged. Generally, we have a\nX-SG$^2$S injector for adding multi-modal messages simultaneously and an\nextractor for extract them. Specifically, we first split the watermarks into\nmessage patches in a fixed manner and sort the 3DGS points. A self-adaption\ngate is used to pick out suitable location for watermarking. Then use a\nXD(multi-dimension)-injection heads to add multi-modal messages into sorted\n3DGS points. A learnable gate can recognize the location with extra messages\nand XD-extraction heads can restore hidden messages from the location\nrecommended by the learnable gate. Extensive experiments demonstrated that the\nproposed X-SG$^2$S can effectively conceal multi modal messages without\nchanging pretrained 3DGS pipeline or the original form of 3DGS parameters.\nMeanwhile, with simple and efficient model structure and high practicality,\nX-SG$^2$S still shows good performance in hiding and extracting multi-modal\ninner structured or unstructured messages. X-SG$^2$S is the first to unify 1 to\n3D watermarking model for 3DGS and the first framework to add multi-modal\nwatermarks simultaneous in one 3DGS which pave the wave for later researches.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.10475v2",
    "published_date": "2025-02-13 17:59:15 UTC",
    "updated_date": "2025-04-23 06:38:28 UTC"
  },
  {
    "arxiv_id": "2502.09692v1",
    "title": "NeuralCFD: Deep Learning on High-Fidelity Automotive Aerodynamics Simulations",
    "authors": [
      "Maurits Bleeker",
      "Matthias Dorfer",
      "Tobias Kronlachner",
      "Reinhard Sonnleitner",
      "Benedikt Alkin",
      "Johannes Brandstetter"
    ],
    "abstract": "Recent advancements in neural operator learning are paving the way for\ntransformative innovations in fields such as automotive aerodynamics. However,\nkey challenges must be overcome before neural network-based simulation\nsurrogates can be implemented at an industry scale. First, surrogates must\nbecome scalable to large surface and volume meshes, especially when using raw\ngeometry inputs only, i.e., without relying on the simulation mesh. Second,\nsurrogates must be trainable with a limited number of high-fidelity numerical\nsimulation samples while still reaching the required performance levels. To\nthis end, we introduce Geometry-preserving Universal Physics Transformer\n(GP-UPT), which separates geometry encoding and physics predictions, ensuring\nflexibility with respect to geometry representations and surface sampling\nstrategies. GP-UPT enables independent scaling of the respective parts of the\nmodel according to practical requirements, offering scalable solutions to open\nchallenges. GP-UPT circumvents the creation of high-quality simulation meshes,\nenables accurate 3D velocity field predictions at 20 million mesh cells, and\nexcels in transfer learning from low-fidelity to high-fidelity simulation\ndatasets, requiring less than half of the high-fidelity data to match the\nperformance of models trained from scratch.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Preprint",
    "pdf_url": "http://arxiv.org/pdf/2502.09692v1",
    "published_date": "2025-02-13 17:58:07 UTC",
    "updated_date": "2025-02-13 17:58:07 UTC"
  },
  {
    "arxiv_id": "2502.09532v1",
    "title": "Mind the Gap! Choice Independence in Using Multilingual LLMs for Persuasive Co-Writing Tasks in Different Languages",
    "authors": [
      "Shreyan Biswas",
      "Alexander Erlei",
      "Ujwal Gadiraju"
    ],
    "abstract": "Recent advances in generative AI have precipitated a proliferation of novel\nwriting assistants. These systems typically rely on multilingual large language\nmodels (LLMs), providing globalized workers the ability to revise or create\ndiverse forms of content in different languages. However, there is substantial\nevidence indicating that the performance of multilingual LLMs varies between\nlanguages. Users who employ writing assistance for multiple languages are\ntherefore susceptible to disparate output quality. Importantly, recent research\nhas shown that people tend to generalize algorithmic errors across independent\ntasks, violating the behavioral axiom of choice independence. In this paper, we\nanalyze whether user utilization of novel writing assistants in a charity\nadvertisement writing task is affected by the AI's performance in a second\nlanguage. Furthermore, we quantify the extent to which these patterns translate\ninto the persuasiveness of generated charity advertisements, as well as the\nrole of peoples' beliefs about LLM utilization in their donation choices. Our\nresults provide evidence that writers who engage with an LLM-based writing\nassistant violate choice independence, as prior exposure to a Spanish LLM\nreduces subsequent utilization of an English LLM. While these patterns do not\naffect the aggregate persuasiveness of the generated advertisements, people's\nbeliefs about the source of an advertisement (human versus AI) do. In\nparticular, Spanish-speaking female participants who believed that they read an\nAI-generated advertisement strongly adjusted their donation behavior downwards.\nFurthermore, people are generally not able to adequately differentiate between\nhuman-generated and LLM-generated ads. Our work has important implications for\nthe design, development, integration, and adoption of multilingual LLMs as\nassistive agents -- particularly in writing tasks.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.09532v1",
    "published_date": "2025-02-13 17:49:30 UTC",
    "updated_date": "2025-02-13 17:49:30 UTC"
  },
  {
    "arxiv_id": "2502.09511v1",
    "title": "Diffusion Models for Molecules: A Survey of Methods and Tasks",
    "authors": [
      "Liang Wang",
      "Chao Song",
      "Zhiyuan Liu",
      "Yu Rong",
      "Qiang Liu",
      "Shu Wu",
      "Liang Wang"
    ],
    "abstract": "Generative tasks about molecules, including but not limited to molecule\ngeneration, are crucial for drug discovery and material design, and have\nconsistently attracted significant attention. In recent years, diffusion models\nhave emerged as an impressive class of deep generative models, sparking\nextensive research and leading to numerous studies on their application to\nmolecular generative tasks. Despite the proliferation of related work, there\nremains a notable lack of up-to-date and systematic surveys in this area.\nParticularly, due to the diversity of diffusion model formulations, molecular\ndata modalities, and generative task types, the research landscape is\nchallenging to navigate, hindering understanding and limiting the area's\ngrowth. To address this, this paper conducts a comprehensive survey of\ndiffusion model-based molecular generative methods. We systematically review\nthe research from the perspectives of methodological formulations, data\nmodalities, and task types, offering a novel taxonomy. This survey aims to\nfacilitate understanding and further flourishing development in this area. The\nrelevant papers are summarized at:\nhttps://github.com/AzureLeon1/awesome-molecular-diffusion-models.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CE"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.09511v1",
    "published_date": "2025-02-13 17:22:50 UTC",
    "updated_date": "2025-02-13 17:22:50 UTC"
  },
  {
    "arxiv_id": "2502.09503v2",
    "title": "AttentionSmithy: A Modular Framework for Rapid Transformer Development and Customization",
    "authors": [
      "Caleb Cranney",
      "Jesse G. Meyer"
    ],
    "abstract": "Transformer architectures have transformed AI applications but remain complex\nto customize for domain experts lacking low-level implementation expertise. We\nintroduce AttentionSmithy, a modular software package that simplifies\ntransformer innovation by breaking down key components into reusable building\nblocks: attention modules, feed-forward networks, normalization layers, and\npositional encodings. Users can rapidly prototype and evaluate transformer\nvariants without extensive coding. Our framework supports four positional\nencoding strategies and integrates with neural architecture search for\nautomated design. We validate AttentionSmithy by replicating the original\ntransformer under resource constraints and optimizing translation performance\nby combining positional encodings. Additionally, we demonstrate its\nadaptability in gene-specific modeling, achieving over 95% accuracy in cell\ntype classification. These case studies highlight AttentionSmithy's potential\nto accelerate research across diverse fields by removing framework\nimplementation barriers.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.09503v2",
    "published_date": "2025-02-13 17:15:26 UTC",
    "updated_date": "2025-02-14 21:38:39 UTC"
  },
  {
    "arxiv_id": "2502.09497v1",
    "title": "Improve LLM-based Automatic Essay Scoring with Linguistic Features",
    "authors": [
      "Zhaoyi Joey Hou",
      "Alejandro Ciuba",
      "Xiang Lorraine Li"
    ],
    "abstract": "Automatic Essay Scoring (AES) assigns scores to student essays, reducing the\ngrading workload for instructors. Developing a scoring system capable of\nhandling essays across diverse prompts is challenging due to the flexibility\nand diverse nature of the writing task. Existing methods typically fall into\ntwo categories: supervised feature-based approaches and large language model\n(LLM)-based methods. Supervised feature-based approaches often achieve higher\nperformance but require resource-intensive training. In contrast, LLM-based\nmethods are computationally efficient during inference but tend to suffer from\nlower performance. This paper combines these approaches by incorporating\nlinguistic features into LLM-based scoring. Experimental results show that this\nhybrid method outperforms baseline models for both in-domain and out-of-domain\nwriting prompts.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "To be published in the workshop Innovation and Responsibility in\n  AI-Supported Education (iRaise) at the 2025 Conference on Artificial\n  Intelligence (AAAI)",
    "pdf_url": "http://arxiv.org/pdf/2502.09497v1",
    "published_date": "2025-02-13 17:09:52 UTC",
    "updated_date": "2025-02-13 17:09:52 UTC"
  },
  {
    "arxiv_id": "2502.09690v1",
    "title": "Trust at Your Own Peril: A Mixed Methods Exploration of the Ability of Large Language Models to Generate Expert-Like Systems Engineering Artifacts and a Characterization of Failure Modes",
    "authors": [
      "Taylan G. Topcu",
      "Mohammed Husain",
      "Max Ofsa",
      "Paul Wach"
    ],
    "abstract": "Multi-purpose Large Language Models (LLMs), a subset of generative Artificial\nIntelligence (AI), have recently made significant progress. While expectations\nfor LLMs to assist systems engineering (SE) tasks are paramount; the\ninterdisciplinary and complex nature of systems, along with the need to\nsynthesize deep-domain knowledge and operational context, raise questions\nregarding the efficacy of LLMs to generate SE artifacts, particularly given\nthat they are trained using data that is broadly available on the internet. To\nthat end, we present results from an empirical exploration, where a human\nexpert-generated SE artifact was taken as a benchmark, parsed, and fed into\nvarious LLMs through prompt engineering to generate segments of typical SE\nartifacts. This procedure was applied without any fine-tuning or calibration to\ndocument baseline LLM performance. We then adopted a two-fold mixed-methods\napproach to compare AI generated artifacts against the benchmark. First, we\nquantitatively compare the artifacts using natural language processing\nalgorithms and find that when prompted carefully, the state-of-the-art\nalgorithms cannot differentiate AI-generated artifacts from the human-expert\nbenchmark. Second, we conduct a qualitative deep dive to investigate how they\ndiffer in terms of quality. We document that while the two-material appear very\nsimilar, AI generated artifacts exhibit serious failure modes that could be\ndifficult to detect. We characterize these as: premature requirements\ndefinition, unsubstantiated numerical estimates, and propensity to overspecify.\nWe contend that this study tells a cautionary tale about why the SE community\nmust be more cautious adopting AI suggested feedback, at least when generated\nby multi-purpose LLMs.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "41 pages, 10 figures",
    "pdf_url": "http://arxiv.org/pdf/2502.09690v1",
    "published_date": "2025-02-13 17:05:18 UTC",
    "updated_date": "2025-02-13 17:05:18 UTC"
  },
  {
    "arxiv_id": "2502.09495v1",
    "title": "Cracking the Code: Enhancing Development finance understanding with artificial intelligence",
    "authors": [
      "Pierre Beaucoral"
    ],
    "abstract": "Analyzing development projects is crucial for understanding donors aid\nstrategies, recipients priorities, and to assess development finance capacity\nto adress development issues by on-the-ground actions. In this area, the\nOrganisation for Economic Co-operation and Developments (OECD) Creditor\nReporting System (CRS) dataset is a reference data source. This dataset\nprovides a vast collection of project narratives from various sectors\n(approximately 5 million projects). While the OECD CRS provides a rich source\nof information on development strategies, it falls short in informing project\npurposes due to its reporting process based on donors self-declared main\nobjectives and pre-defined industrial sectors. This research employs a novel\napproach that combines Machine Learning (ML) techniques, specifically Natural\nLanguage Processing (NLP), an innovative Python topic modeling technique called\nBERTopic, to categorise (cluster) and label development projects based on their\nnarrative descriptions. By revealing existing yet hidden topics of development\nfinance, this application of artificial intelligence enables a better\nunderstanding of donor priorities and overall development funding and provides\nmethods to analyse public and private projects narratives.",
    "categories": [
      "econ.GN",
      "cs.AI",
      "cs.LG",
      "q-fin.EC"
    ],
    "primary_category": "econ.GN",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.09495v1",
    "published_date": "2025-02-13 17:01:45 UTC",
    "updated_date": "2025-02-13 17:01:45 UTC"
  },
  {
    "arxiv_id": "2502.09487v1",
    "title": "Objective quantification of mood states using large language models",
    "authors": [
      "Jakub Onysk",
      "Quentin Huys"
    ],
    "abstract": "Emotional states influence human behaviour and cognition, leading to diverse\nthought trajectories. Similarly, Large Language Models (LLMs) showcase an\nexcellent level of response consistency across wide-ranging contexts (prompts).\nWe leverage these parallels to establish a framework for quantifying mental\nstates. Our approach utilises self-report questionnaires that reliably assess\nthese states due to their inherent sensitivity to patterns of co-occurring\nresponses. Specifically, we recruited a large sample of participants (N=422) to\ninvestigate how well an LLM (Mistral-7B-OpenOrca) quantifies a heterogenous set\nof depressive mood states measured with participants' open-ended responses to a\ndepression questionnaire. We show LLM responses to held-out multiple-choice\nquestions, given participants' open-ended answers, correlate strongly (r:\n0.52-0.84) with true questionnaire scores, demonstrating LLM's generalisation\nfrom mood representations. We explore a link between these representations and\nfactor analysis. Using ridge regression, we find depression-related subspaces\nwithin LLM hidden states. We show these subspaces to be predictive of\nparticipants' \"Depression\" and \"Somatic & Emotional Distress\" factor scores, as\nwell as suicidality severity. Overall, LLMs can provide quantitative measures\nof mental states. The reliability of these hinges upon how informative the\nquestions we ask participants are. Used correctly, this approach could\nsupplement mental state assessment in a variety of settings.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "main text - 9 pages, 5 figures;",
    "pdf_url": "http://arxiv.org/pdf/2502.09487v1",
    "published_date": "2025-02-13 16:52:06 UTC",
    "updated_date": "2025-02-13 16:52:06 UTC"
  },
  {
    "arxiv_id": "2502.09484v1",
    "title": "PenTest++: Elevating Ethical Hacking with AI and Automation",
    "authors": [
      "Haitham S. Al-Sinani",
      "Chris J. Mitchell"
    ],
    "abstract": "Traditional ethical hacking relies on skilled professionals and\ntime-intensive command management, which limits its scalability and efficiency.\nTo address these challenges, we introduce PenTest++, an AI-augmented system\nthat integrates automation with generative AI (GenAI) to optimise ethical\nhacking workflows. Developed in a controlled virtual environment, PenTest++\nstreamlines critical penetration testing tasks, including reconnaissance,\nscanning, enumeration, exploitation, and documentation, while maintaining a\nmodular and adaptable design. The system balances automation with human\noversight, ensuring informed decision-making at key stages, and offers\nsignificant benefits such as enhanced efficiency, scalability, and\nadaptability. However, it also raises ethical considerations, including privacy\nconcerns and the risks of AI-generated inaccuracies (hallucinations). This\nresearch underscores the potential of AI-driven systems like PenTest++ to\ncomplement human expertise in cybersecurity by automating routine tasks,\nenabling professionals to focus on strategic decision-making. By incorporating\nrobust ethical safeguards and promoting ongoing refinement, PenTest++\ndemonstrates how AI can be responsibly harnessed to address operational and\nethical challenges in the evolving cybersecurity landscape.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "27 pages, 6 figures",
    "pdf_url": "http://arxiv.org/pdf/2502.09484v1",
    "published_date": "2025-02-13 16:46:23 UTC",
    "updated_date": "2025-02-13 16:46:23 UTC"
  },
  {
    "arxiv_id": "2502.09471v1",
    "title": "Wholly-WOOD: Wholly Leveraging Diversified-quality Labels for Weakly-supervised Oriented Object Detection",
    "authors": [
      "Yi Yu",
      "Xue Yang",
      "Yansheng Li",
      "Zhenjun Han",
      "Feipeng Da",
      "Junchi Yan"
    ],
    "abstract": "Accurately estimating the orientation of visual objects with compact rotated\nbounding boxes (RBoxes) has become a prominent demand, which challenges\nexisting object detection paradigms that only use horizontal bounding boxes\n(HBoxes). To equip the detectors with orientation awareness, supervised\nregression/classification modules have been introduced at the high cost of\nrotation annotation. Meanwhile, some existing datasets with oriented objects\nare already annotated with horizontal boxes or even single points. It becomes\nattractive yet remains open for effectively utilizing weaker single point and\nhorizontal annotations to train an oriented object detector (OOD). We develop\nWholly-WOOD, a weakly-supervised OOD framework, capable of wholly leveraging\nvarious labeling forms (Points, HBoxes, RBoxes, and their combination) in a\nunified fashion. By only using HBox for training, our Wholly-WOOD achieves\nperformance very close to that of the RBox-trained counterpart on remote\nsensing and other areas, significantly reducing the tedious efforts on\nlabor-intensive annotation for oriented objects. The source codes are available\nat https://github.com/VisionXLab/whollywood (PyTorch-based) and\nhttps://github.com/VisionXLab/whollywood-jittor (Jittor-based).",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "18 pages, 9 figures, 9 tables, accepted by TPAMI",
    "pdf_url": "http://arxiv.org/pdf/2502.09471v1",
    "published_date": "2025-02-13 16:34:59 UTC",
    "updated_date": "2025-02-13 16:34:59 UTC"
  },
  {
    "arxiv_id": "2502.09460v1",
    "title": "Metamorphic Testing for Pose Estimation Systems",
    "authors": [
      "Matias Duran",
      "Thomas Laurent",
      "Ellen Rushe",
      "Anthony Ventresque"
    ],
    "abstract": "Pose estimation systems are used in a variety of fields, from sports\nanalytics to livestock care. Given their potential impact, it is paramount to\nsystematically test their behaviour and potential for failure. This is a\ncomplex task due to the oracle problem and the high cost of manual labelling\nnecessary to build ground truth keypoints. This problem is exacerbated by the\nfact that different applications require systems to focus on different subjects\n(e.g., human versus animal) or landmarks (e.g., only extremities versus whole\nbody and face), which makes labelled test data rarely reusable. To combat these\nproblems we propose MET-POSE, a metamorphic testing framework for pose\nestimation systems that bypasses the need for manual annotation while assessing\nthe performance of these systems under different circumstances. MET-POSE thus\nallows users of pose estimation systems to assess the systems in conditions\nthat more closely relate to their application without having to label an ad-hoc\ntest dataset or rely only on available datasets, which may not be adapted to\ntheir application domain. While we define MET-POSE in general terms, we also\npresent a non-exhaustive list of metamorphic rules that represent common\nchallenges in computer vision applications, as well as a specific way to\nevaluate these rules. We then experimentally show the effectiveness of MET-POSE\nby applying it to Mediapipe Holistic, a state of the art human pose estimation\nsystem, with the FLIC and PHOENIX datasets. With these experiments, we outline\nnumerous ways in which the outputs of MET-POSE can uncover faults in pose\nestimation systems at a similar or higher rate than classic testing using hand\nlabelled data, and show that users can tailor the rule set they use to the\nfaults and level of accuracy relevant to their application.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.SE",
    "comment": "Accepted for publication at 2025 IEEE Conference on Software Testing,\n  Verification and Validation (ICST)",
    "pdf_url": "http://arxiv.org/pdf/2502.09460v1",
    "published_date": "2025-02-13 16:27:23 UTC",
    "updated_date": "2025-02-13 16:27:23 UTC"
  },
  {
    "arxiv_id": "2502.09443v1",
    "title": "Relational Conformal Prediction for Correlated Time Series",
    "authors": [
      "Andrea Cini",
      "Alexander Jenkins",
      "Danilo Mandic",
      "Cesare Alippi",
      "Filippo Maria Bianchi"
    ],
    "abstract": "We address the problem of uncertainty quantification in time series\nforecasting by exploiting observations at correlated sequences. Relational deep\nlearning methods leveraging graph representations are among the most effective\ntools for obtaining point estimates from spatiotemporal data and correlated\ntime series. However, the problem of exploiting relational structures to\nestimate the uncertainty of such predictions has been largely overlooked in the\nsame context. To this end, we propose a novel distribution-free approach based\non the conformal prediction framework and quantile regression. Despite the\nrecent applications of conformal prediction to sequential data, existing\nmethods operate independently on each target time series and do not account for\nrelationships among them when constructing the prediction interval. We fill\nthis void by introducing a novel conformal prediction method based on graph\ndeep learning operators. Our method, named Conformal Relational Prediction\n(CoRel), does not require the relational structure (graph) to be known as a\nprior and can be applied on top of any pre-trained time series predictor.\nAdditionally, CoRel includes an adaptive component to handle non-exchangeable\ndata and changes in the input time series. Our approach provides accurate\ncoverage and archives state-of-the-art uncertainty quantification in relevant\nbenchmarks.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.09443v1",
    "published_date": "2025-02-13 16:12:17 UTC",
    "updated_date": "2025-02-13 16:12:17 UTC"
  },
  {
    "arxiv_id": "2502.09436v2",
    "title": "Variable Stiffness for Robust Locomotion through Reinforcement Learning",
    "authors": [
      "Dario Spoljaric",
      "Yashuai Yan",
      "Dongheui Lee"
    ],
    "abstract": "Reinforcement-learned locomotion enables legged robots to perform highly\ndynamic motions but often accompanies time-consuming manual tuning of joint\nstiffness. This paper introduces a novel control paradigm that integrates\nvariable stiffness into the action space alongside joint positions, enabling\ngrouped stiffness control such as per-joint stiffness (PJS), per-leg stiffness\n(PLS) and hybrid joint-leg stiffness (HJLS). We show that variable stiffness\npolicies, with grouping in per-leg stiffness (PLS), outperform position-based\ncontrol in velocity tracking and push recovery. In contrast, HJLS excels in\nenergy efficiency. Despite the fact that our policy is trained on flat floor\nonly, our method showcases robust walking behaviour on diverse outdoor\nterrains, indicating robust sim-to-real transfer. Our approach simplifies\ndesign by eliminating per-joint stiffness tuning while keeping competitive\nresults with various metrics.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "accepted to IFAC Joint Symposia on Mechatronics & Robotics",
    "pdf_url": "http://arxiv.org/pdf/2502.09436v2",
    "published_date": "2025-02-13 16:00:46 UTC",
    "updated_date": "2025-04-22 06:55:59 UTC"
  },
  {
    "arxiv_id": "2502.09432v1",
    "title": "Dual Formulation for Non-Rectangular Lp Robust Markov Decision Processes",
    "authors": [
      "Navdeep Kumar",
      "Adarsh Gupta",
      "Maxence Mohamed Elfatihi",
      "Giorgia Ramponi",
      "Kfir Yehuda Levy",
      "Shie Mannor"
    ],
    "abstract": "We study robust Markov decision processes (RMDPs) with non-rectangular\nuncertainty sets, which capture interdependencies across states unlike\ntraditional rectangular models. While non-rectangular robust policy evaluation\nis generally NP-hard, even in approximation, we identify a powerful class of\n$L_p$-bounded uncertainty sets that avoid these complexity barriers due to\ntheir structural simplicity. We further show that this class can be decomposed\ninto infinitely many \\texttt{sa}-rectangular $L_p$-bounded sets and leverage\nits structural properties to derive a novel dual formulation for $L_p$ RMDPs.\nThis formulation provides key insights into the adversary's strategy and\nenables the development of the first robust policy evaluation algorithms for\nnon-rectangular RMDPs. Empirical results demonstrate that our approach\nsignificantly outperforms brute-force methods, establishing a promising\nfoundation for future investigation into non-rectangular robust MDPs.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.09432v1",
    "published_date": "2025-02-13 15:55:00 UTC",
    "updated_date": "2025-02-13 15:55:00 UTC"
  },
  {
    "arxiv_id": "2502.09688v1",
    "title": "Towards Virtual Clinical Trials of Radiology AI with Conditional Generative Modeling",
    "authors": [
      "Benjamin D. Killeen",
      "Bohua Wan",
      "Aditya V. Kulkarni",
      "Nathan Drenkow",
      "Michael Oberst",
      "Paul H. Yi",
      "Mathias Unberath"
    ],
    "abstract": "Artificial intelligence (AI) is poised to transform healthcare by enabling\npersonalized and efficient care through data-driven insights. Although\nradiology is at the forefront of AI adoption, in practice, the potential of AI\nmodels is often overshadowed by severe failures to generalize: AI models can\nhave performance degradation of up to 20% when transitioning from controlled\ntest environments to clinical use by radiologists. This mismatch raises\nconcerns that radiologists will be misled by incorrect AI predictions in\npractice and/or grow to distrust AI, rendering these promising technologies\npractically ineffectual. Exhaustive clinical trials of AI models on abundant\nand diverse data is thus critical to anticipate AI model degradation when\nencountering varied data samples. Achieving these goals, however, is\nchallenging due to the high costs of collecting diverse data samples and\ncorresponding annotations. To overcome these limitations, we introduce a novel\nconditional generative AI model designed for virtual clinical trials (VCTs) of\nradiology AI, capable of realistically synthesizing full-body CT images of\npatients with specified attributes. By learning the joint distribution of\nimages and anatomical structures, our model enables precise replication of\nreal-world patient populations with unprecedented detail at this scale. We\ndemonstrate meaningful evaluation of radiology AI models through VCTs powered\nby our synthetic CT study populations, revealing model degradation and\nfacilitating algorithmic auditing for bias-inducing data attributes. Our\ngenerative AI approach to VCTs is a promising avenue towards a scalable\nsolution to assess model robustness, mitigate biases, and safeguard patient\ncare by enabling simpler testing and evaluation of AI models in any desired\nrange of diverse patient populations.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "35 pages",
    "pdf_url": "http://arxiv.org/pdf/2502.09688v1",
    "published_date": "2025-02-13 15:53:52 UTC",
    "updated_date": "2025-02-13 15:53:52 UTC"
  },
  {
    "arxiv_id": "2502.10473v1",
    "title": "Diverse Transformer Decoding for Offline Reinforcement Learning Using Financial Algorithmic Approaches",
    "authors": [
      "Dan Elbaz",
      "Oren Salzman"
    ],
    "abstract": "Offline Reinforcement Learning (RL) algorithms learn a policy using a fixed\ntraining dataset, which is then deployed online to interact with the\nenvironment and make decisions. Transformers, a standard choice for modeling\ntime-series data, are gaining popularity in offline RL. In this context, Beam\nSearch (BS), an approximate inference algorithm, is the go-to decoding method.\nOffline RL eliminates the need for costly or risky online data collection.\nHowever, the restricted dataset induces uncertainty as the agent may encounter\nunfamiliar sequences of states and actions during execution that were not\ncovered in the training data. In this context, BS lacks two important\nproperties essential for offline RL: It does not account for the aforementioned\nuncertainty, and its greedy left-right search approach often results in\nsequences with minimal variations, failing to explore potentially better\nalternatives.\n  To address these limitations, we propose Portfolio Beam Search (PBS), a\nsimple-yet-effective alternative to BS that balances exploration and\nexploitation within a Transformer model during decoding. We draw inspiration\nfrom financial economics and apply these principles to develop an\nuncertainty-aware diversification mechanism, which we integrate into a\nsequential decoding algorithm at inference time. We empirically demonstrate the\neffectiveness of PBS on the D4RL locomotion benchmark, where it achieves higher\nreturns and significantly reduces outcome variability.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.10473v1",
    "published_date": "2025-02-13 15:51:46 UTC",
    "updated_date": "2025-02-13 15:51:46 UTC"
  },
  {
    "arxiv_id": "2502.09423v1",
    "title": "Transformer-Enhanced Variational Autoencoder for Crystal Structure Prediction",
    "authors": [
      "Ziyi Chen",
      "Yang Yuan",
      "Siming Zheng",
      "Jialong Guo",
      "Sihan Liang",
      "Yangang Wang",
      "Zongguo Wang"
    ],
    "abstract": "Crystal structure forms the foundation for understanding the physical and\nchemical properties of materials. Generative models have emerged as a new\nparadigm in crystal structure prediction(CSP), however, accurately capturing\nkey characteristics of crystal structures, such as periodicity and symmetry,\nremains a significant challenge. In this paper, we propose a\nTransformer-Enhanced Variational Autoencoder for Crystal Structure Prediction\n(TransVAE-CSP), who learns the characteristic distribution space of stable\nmaterials, enabling both the reconstruction and generation of crystal\nstructures. TransVAE-CSP integrates adaptive distance expansion with\nirreducible representation to effectively capture the periodicity and symmetry\nof crystal structures, and the encoder is a transformer network based on an\nequivariant dot product attention mechanism. Experimental results on the\ncarbon_24, perov_5, and mp_20 datasets demonstrate that TransVAE-CSP\noutperforms existing methods in structure reconstruction and generation tasks\nunder various modeling metrics, offering a powerful tool for crystal structure\ndesign and optimization.",
    "categories": [
      "cond-mat.mtrl-sci",
      "cs.AI"
    ],
    "primary_category": "cond-mat.mtrl-sci",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.09423v1",
    "published_date": "2025-02-13 15:45:36 UTC",
    "updated_date": "2025-02-13 15:45:36 UTC"
  },
  {
    "arxiv_id": "2502.09417v1",
    "title": "A Survey of Reinforcement Learning for Optimization in Automation",
    "authors": [
      "Ahmad Farooq",
      "Kamran Iqbal"
    ],
    "abstract": "Reinforcement Learning (RL) has become a critical tool for optimization\nchallenges within automation, leading to significant advancements in several\nareas. This review article examines the current landscape of RL within\nautomation, with a particular focus on its roles in manufacturing, energy\nsystems, and robotics. It discusses state-of-the-art methods, major challenges,\nand upcoming avenues of research within each sector, highlighting RL's capacity\nto solve intricate optimization challenges. The paper reviews the advantages\nand constraints of RL-driven optimization methods in automation. It points out\nprevalent challenges encountered in RL optimization, including issues related\nto sample efficiency and scalability; safety and robustness; interpretability\nand trustworthiness; transfer learning and meta-learning; and real-world\ndeployment and integration. It further explores prospective strategies and\nfuture research pathways to navigate these challenges. Additionally, the survey\nincludes a comprehensive list of relevant research papers, making it an\nindispensable guide for scholars and practitioners keen on exploring this\ndomain.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.NE",
      "cs.RO",
      "cs.SY",
      "eess.SY",
      "68T05, 90C40, 49M37",
      "I.2.6; I.2.8; I.2.9; G.1.6; C.4; J.6"
    ],
    "primary_category": "cs.LG",
    "comment": "8 pages, 4 tables, and 1 figure. Accepted at IEEE 20th International\n  Conference on Automation Science and Engineering (CASE) 2024",
    "pdf_url": "http://arxiv.org/pdf/2502.09417v1",
    "published_date": "2025-02-13 15:40:39 UTC",
    "updated_date": "2025-02-13 15:40:39 UTC"
  },
  {
    "arxiv_id": "2503.16440v1",
    "title": "Cause-effect perception in an object place task",
    "authors": [
      "Nikolai Bahr",
      "Christoph Zetzsche",
      "Jaime Maldonado",
      "Kerstin Schill"
    ],
    "abstract": "Algorithmic causal discovery is based on formal reasoning and provably\nconverges toward the optimal solution. However, since some of the underlying\nassumptions are often not met in practice no applications for autonomous\neveryday life competence are yet available. Humans on the other hand possess\nfull everyday competence and develop cognitive models in a data efficient\nmanner with the ability to transfer knowledge between and to new situations.\nHere we investigate the causal discovery capabilities of humans in an object\nplace task in virtual reality (VR) with haptic feedback and compare the results\nto the state of the art causal discovery algorithms FGES, PC and FCI. In\naddition we use the algorithms to analyze causal relations between sensory\ninformation and the kinematic parameters of human behavior.\n  Our findings show that the majority of participants were able to determine\nwhich variables are causally related. This is in line with causal discovery\nalgorithms like PC, which recover causal dependencies in the first step.\nHowever, unlike such algorithms which can identify causes and effects in our\ntest configuration, humans are unsure in determining a causal direction.\nRegarding the relation between the sensory information provided to the\nparticipants and their placing actions (i.e. their kinematic parameters) the\ndata yields a surprising dissociation of the subjects knowledge and the\nsensorimotor level. Knowledge of the cause-effect pairs, though undirected,\nshould suffice to improve subject's movements. Yet a detailed causal analysis\nprovides little evidence for any such influence. This, together with the\nreports of the participants, implies that instead of exploiting their\nconsciously perceived information they leave it to the sensorimotor level to\ncontrol the movement.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "11 pages, 9 figures, submitted to: Frontiers in Cognition",
    "pdf_url": "http://arxiv.org/pdf/2503.16440v1",
    "published_date": "2025-02-13 15:33:10 UTC",
    "updated_date": "2025-02-13 15:33:10 UTC"
  },
  {
    "arxiv_id": "2502.09687v1",
    "title": "Mind What You Ask For: Emotional and Rational Faces of Persuasion by Large Language Models",
    "authors": [
      "Wiktoria Mieleszczenko-Kowszewicz",
      "Beata Bajcar",
      "Jolanta Babiak",
      "Berenika Dyczek",
      "Jakub Åwistak",
      "PrzemysÅaw Biecek"
    ],
    "abstract": "Be careful what you ask for, you just might get it. This saying fits with the\nway large language models (LLMs) are trained, which, instead of being rewarded\nfor correctness, are increasingly rewarded for pleasing the recipient. So, they\nare increasingly effective at persuading us that their answers are valuable.\nBut what tricks do they use in this persuasion? In this study, we examine what\nare the psycholinguistic features of the responses used by twelve different\nlanguage models. By grouping response content according to rational or\nemotional prompts and exploring social influence principles employed by LLMs,\nwe ask whether and how we can mitigate the risks of LLM-driven mass\nmisinformation. We position this study within the broader discourse on\nhuman-centred AI, emphasizing the need for interdisciplinary approaches to\nmitigate cognitive and societal risks posed by persuasive AI responses.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.09687v1",
    "published_date": "2025-02-13 15:15:53 UTC",
    "updated_date": "2025-02-13 15:15:53 UTC"
  },
  {
    "arxiv_id": "2502.09390v1",
    "title": "SQuARE: Sequential Question Answering Reasoning Engine for Enhanced Chain-of-Thought in Large Language Models",
    "authors": [
      "Daniel Fleischer",
      "Moshe Berchansky",
      "Gad Markovits",
      "Moshe Wasserblat"
    ],
    "abstract": "In the rapidly evolving field of Natural Language Processing, Large Language\nModels (LLMs) are tasked with increasingly complex reasoning challenges.\nTraditional methods like chain-of-thought prompting have shown promise but\noften fall short in fully leveraging a model's reasoning capabilities. This\npaper introduces SQuARE (Sequential Question Answering Reasoning Engine), a\nnovel prompting technique designed to improve reasoning through a\nself-interrogation paradigm. Building upon CoT frameworks, SQuARE prompts\nmodels to generate and resolve multiple auxiliary questions before tackling the\nmain query, promoting a more thorough exploration of various aspects of a\ntopic. Our expansive evaluations, conducted with Llama 3 and GPT-4o models\nacross multiple question-answering datasets, demonstrate that SQuARE\nsignificantly surpasses traditional CoT prompts and existing\nrephrase-and-respond methods. By systematically decomposing queries, SQuARE\nadvances LLM capabilities in reasoning tasks. The code is publicly available at\nhttps://github.com/IntelLabs/RAG-FiT/tree/square.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "14 pages",
    "pdf_url": "http://arxiv.org/pdf/2502.09390v1",
    "published_date": "2025-02-13 15:07:20 UTC",
    "updated_date": "2025-02-13 15:07:20 UTC"
  },
  {
    "arxiv_id": "2502.09389v2",
    "title": "S$^2$-Diffusion: Generalizing from Instance-level to Category-level Skills in Robot Manipulation",
    "authors": [
      "Quantao Yang",
      "Michael C. Welle",
      "Danica Kragic",
      "Olov Andersson"
    ],
    "abstract": "Recent advances in skill learning has propelled robot manipulation to new\nheights by enabling it to learn complex manipulation tasks from a practical\nnumber of demonstrations. However, these skills are often limited to the\nparticular action, object, and environment \\textit{instances} that are shown in\nthe training data, and have trouble transferring to other instances of the same\ncategory. In this work we present an open-vocabulary Spatial-Semantic Diffusion\npolicy (S$^2$-Diffusion) which enables generalization from instance-level\ntraining data to category-level, enabling skills to be transferable between\ninstances of the same category. We show that functional aspects of skills can\nbe captured via a promptable semantic module combined with a spatial\nrepresentation. We further propose leveraging depth estimation networks to\nallow the use of only a single RGB camera. Our approach is evaluated and\ncompared on a diverse number of robot manipulation tasks, both in simulation\nand in the real world. Our results show that S$^2$-Diffusion is invariant to\nchanges in category-irrelevant factors as well as enables satisfying\nperformance on other instances within the same category, even if it was not\ntrained on that specific instance. Full videos of all real-world experiments\nare available in the supplementary material.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.09389v2",
    "published_date": "2025-02-13 15:06:42 UTC",
    "updated_date": "2025-02-17 08:38:28 UTC"
  },
  {
    "arxiv_id": "2502.09387v2",
    "title": "Truth Knows No Language: Evaluating Truthfulness Beyond English",
    "authors": [
      "Blanca Calvo Figueras",
      "Eneko Sagarzazu",
      "Julen Etxaniz",
      "Jeremy Barnes",
      "Pablo Gamallo",
      "Iria De Dios Flores",
      "Rodrigo Agerri"
    ],
    "abstract": "We introduce a professionally translated extension of the TruthfulQA\nbenchmark designed to evaluate truthfulness in Basque, Catalan, Galician, and\nSpanish. Truthfulness evaluations of large language models (LLMs) have\nprimarily been conducted in English. However, the ability of LLMs to maintain\ntruthfulness across languages remains under-explored. Our study evaluates 12\nstate-of-the-art open LLMs, comparing base and instruction-tuned models using\nhuman evaluation, multiple-choice metrics, and LLM-as-a-Judge scoring. Our\nfindings reveal that, while LLMs perform best in English and worst in Basque\n(the lowest-resourced language), overall truthfulness discrepancies across\nlanguages are smaller than anticipated. Furthermore, we show that\nLLM-as-a-Judge correlates more closely with human judgments than\nmultiple-choice metrics, and that informativeness plays a critical role in\ntruthfulness assessment. Our results also indicate that machine translation\nprovides a viable approach for extending truthfulness benchmarks to additional\nlanguages, offering a scalable alternative to professional translation.\nFinally, we observe that universal knowledge questions are better handled\nacross languages than context- and time-dependent ones, highlighting the need\nfor truthfulness evaluations that account for cultural and temporal\nvariability. Dataset and code are publicly available under open licenses.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.CL",
    "comment": "14 pages, 6 figures, 8 tables",
    "pdf_url": "http://arxiv.org/pdf/2502.09387v2",
    "published_date": "2025-02-13 15:04:53 UTC",
    "updated_date": "2025-02-18 09:35:45 UTC"
  },
  {
    "arxiv_id": "2502.09379v2",
    "title": "TRIFFID: Autonomous Robotic Aid For Increasing First Responders Efficiency",
    "authors": [
      "Jorgen Cani",
      "Panagiotis Koletsis",
      "Konstantinos Foteinos",
      "Ioannis Kefaloukos",
      "Lampros Argyriou",
      "Manolis Falelakis",
      "IvÃ¡n Del Pino",
      "Angel Santamaria-Navarro",
      "Martin Äech",
      "OndÅej Severa",
      "Alessandro Umbrico",
      "Francesca Fracasso",
      "AndreA Orlandini",
      "Dimitrios Drakoulis",
      "Evangelos Markakis",
      "Iraklis Varlamis",
      "Georgios Th. Papadopoulos"
    ],
    "abstract": "The increasing complexity of natural disaster incidents demands innovative\ntechnological solutions to support first responders in their efforts. This\npaper introduces the TRIFFID system, a comprehensive technical framework that\nintegrates unmanned ground and aerial vehicles with advanced artificial\nintelligence functionalities to enhance disaster response capabilities across\nwildfires, urban floods, and post-earthquake search and rescue missions. By\nleveraging state-of-the-art autonomous navigation, semantic perception, and\nhuman-robot interaction technologies, TRIFFID provides a sophisticated system\ncomposed of the following key components: hybrid robotic platform, centralized\nground station, custom communication infrastructure, and smartphone\napplication. The defined research and development activities demonstrate how\ndeep neural networks, knowledge graphs, and multimodal information fusion can\nenable robots to autonomously navigate and analyze disaster environments,\nreducing personnel risks and accelerating response times. The proposed system\nenhances emergency response teams by providing advanced mission planning,\nsafety monitoring, and adaptive task execution capabilities. Moreover, it\nensures real-time situational awareness and operational support in complex and\nrisky situations, facilitating rapid and precise information collection and\ncoordinated actions.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.09379v2",
    "published_date": "2025-02-13 14:46:40 UTC",
    "updated_date": "2025-02-27 09:07:06 UTC"
  },
  {
    "arxiv_id": "2502.09378v1",
    "title": "A Deep Inverse-Mapping Model for a Flapping Robotic Wing",
    "authors": [
      "Hadar Sharvit",
      "Raz Karl",
      "Tsevi Beatus"
    ],
    "abstract": "In systems control, the dynamics of a system are governed by modulating its\ninputs to achieve a desired outcome. For example, to control the thrust of a\nquad-copter propeller the controller modulates its rotation rate, relying on a\nstraightforward mapping between the input rotation rate and the resulting\nthrust. This mapping can be inverted to determine the rotation rate needed to\ngenerate a desired thrust. However, in complex systems, such as flapping-wing\nrobots where intricate fluid motions are involved, mapping inputs (wing\nkinematics) to outcomes (aerodynamic forces) is nontrivial and inverting this\nmapping for real-time control is computationally impractical. Here, we report a\nmachine-learning solution for the inverse mapping of a flapping-wing system\nbased on data from an experimental system we have developed. Our model learns\nthe input wing motion required to generate a desired aerodynamic force outcome.\nWe used a sequence-to-sequence model tailored for time-series data and\naugmented it with a novel adaptive-spectrum layer that implements\nrepresentation learning in the frequency domain. To train our model, we\ndeveloped a flapping wing system that simultaneously measures the wing's\naerodynamic force and its 3D motion using high-speed cameras. We demonstrate\nthe performance of our system on an additional open-source dataset of a\nflapping wing in a different flow regime. Results show superior performance\ncompared with more complex state-of-the-art transformer-based models, with 11%\nimprovement on the test datasets median loss. Moreover, our model shows\nsuperior inference time, making it practical for onboard robotic control. Our\nopen-source data and framework may improve modeling and real-time control of\nsystems governed by complex dynamics, from biomimetic robots to biomedical\ndevices.",
    "categories": [
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted to ICLR 2025. 10 Pages 5 figures + 2 figures in appendix",
    "pdf_url": "http://arxiv.org/pdf/2502.09378v1",
    "published_date": "2025-02-13 14:46:04 UTC",
    "updated_date": "2025-02-13 14:46:04 UTC"
  },
  {
    "arxiv_id": "2502.09369v1",
    "title": "Language Agents as Digital Representatives in Collective Decision-Making",
    "authors": [
      "Daniel Jarrett",
      "Miruna PÃ®slar",
      "Michiel A. Bakker",
      "Michael Henry Tessler",
      "Raphael KÃ¶ster",
      "Jan Balaguer",
      "Romuald Elie",
      "Christopher Summerfield",
      "Andrea Tacchetti"
    ],
    "abstract": "Consider the process of collective decision-making, in which a group of\nindividuals interactively select a preferred outcome from among a universe of\nalternatives. In this context, \"representation\" is the activity of making an\nindividual's preferences present in the process via participation by a proxy\nagent -- i.e. their \"representative\". To this end, learned models of human\nbehavior have the potential to fill this role, with practical implications for\nmulti-agent scenario studies and mechanism design. In this work, we investigate\nthe possibility of training \\textit{language agents} to behave in the capacity\nof representatives of human agents, appropriately expressing the preferences of\nthose individuals whom they stand for. First, we formalize the setting of\n\\textit{collective decision-making} -- as the episodic process of interaction\nbetween a group of agents and a decision mechanism. On this basis, we then\nformalize the problem of \\textit{digital representation} -- as the simulation\nof an agent's behavior to yield equivalent outcomes from the mechanism.\nFinally, we conduct an empirical case study in the setting of\n\\textit{consensus-finding} among diverse humans, and demonstrate the\nfeasibility of fine-tuning large language models to act as digital\nrepresentatives.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.CY"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.09369v1",
    "published_date": "2025-02-13 14:35:40 UTC",
    "updated_date": "2025-02-13 14:35:40 UTC"
  },
  {
    "arxiv_id": "2502.09365v1",
    "title": "Simple Path Structural Encoding for Graph Transformers",
    "authors": [
      "Louis Airale",
      "Antonio Longa",
      "Mattia Rigon",
      "Andrea Passerini",
      "Roberto Passerone"
    ],
    "abstract": "Graph transformers extend global self-attention to graph-structured data,\nachieving notable success in graph learning. Recently, random walk structural\nencoding (RWSE) has been found to further enhance their predictive power by\nencoding both structural and positional information into the edge\nrepresentation. However, RWSE cannot always distinguish between edges that\nbelong to different local graph patterns, which reduces its ability to capture\nthe full structural complexity of graphs. This work introduces Simple Path\nStructural Encoding (SPSE), a novel method that utilizes simple path counts for\nedge encoding. We show theoretically and experimentally that SPSE overcomes the\nlimitations of RWSE, providing a richer representation of graph structures,\nparticularly for capturing local cyclic patterns. To make SPSE computationally\ntractable, we propose an efficient approximate algorithm for simple path\ncounting. SPSE demonstrates significant performance improvements over RWSE on\nvarious benchmarks, including molecular and long-range graph datasets,\nachieving statistically significant gains in discriminative tasks. These\nresults pose SPSE as a powerful edge encoding alternative for enhancing the\nexpressivity of graph transformers.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.09365v1",
    "published_date": "2025-02-13 14:33:02 UTC",
    "updated_date": "2025-02-13 14:33:02 UTC"
  },
  {
    "arxiv_id": "2502.09341v1",
    "title": "Neural Spatiotemporal Point Processes: Trends and Challenges",
    "authors": [
      "Sumantrak Mukherjee",
      "Mouad Elhamdi",
      "George Mohler",
      "David A. Selby",
      "Yao Xie",
      "Sebastian Vollmer",
      "Gerrit Grossmann"
    ],
    "abstract": "Spatiotemporal point processes (STPPs) are probabilistic models for events\noccurring in continuous space and time. Real-world event data often exhibit\nintricate dependencies and heterogeneous dynamics. By incorporating modern deep\nlearning techniques, STPPs can model these complexities more effectively than\ntraditional approaches. Consequently, the fusion of neural methods with STPPs\nhas become an active and rapidly evolving research area. In this review, we\ncategorize existing approaches, unify key design choices, and explain the\nchallenges of working with this data modality. We further highlight emerging\ntrends and diverse application domains. Finally, we identify open challenges\nand gaps in the literature.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.09341v1",
    "published_date": "2025-02-13 14:01:15 UTC",
    "updated_date": "2025-02-13 14:01:15 UTC"
  },
  {
    "arxiv_id": "2502.09335v1",
    "title": "Graph Diffusion Network for Drug-Gene Prediction",
    "authors": [
      "Jiayang Wu",
      "Wensheng Gan",
      "Philip S. Yu"
    ],
    "abstract": "Predicting drug-gene associations is crucial for drug development and disease\ntreatment. While graph neural networks (GNN) have shown effectiveness in this\ntask, they face challenges with data sparsity and efficient contrastive\nlearning implementation. We introduce a graph diffusion network for drug-gene\nprediction (GDNDGP), a framework that addresses these limitations through two\nkey innovations. First, it employs meta-path-based homogeneous graph learning\nto capture drug-drug and gene-gene relationships, ensuring similar entities\nshare embedding spaces. Second, it incorporates a parallel diffusion network\nthat generates hard negative samples during training, eliminating the need for\nexhaustive negative sample retrieval. Our model achieves superior performance\non the DGIdb 4.0 dataset and demonstrates strong generalization capability on\ntripartite drug-gene-disease networks. Results show significant improvements\nover existing methods in drug-gene prediction tasks, particularly in handling\ncomplex heterogeneous relationships. The source code is publicly available at\nhttps://github.com/csjywu1/GDNDGP.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "IEEE/ACM TCBB. 14 pages",
    "pdf_url": "http://arxiv.org/pdf/2502.09335v1",
    "published_date": "2025-02-13 13:54:58 UTC",
    "updated_date": "2025-02-13 13:54:58 UTC"
  },
  {
    "arxiv_id": "2502.09307v1",
    "title": "When the LM misunderstood the human chuckled: Analyzing garden path effects in humans and language models",
    "authors": [
      "Samuel Joseph Amouyal",
      "Aya Meltzer-Asscher",
      "Jonathan Berant"
    ],
    "abstract": "Modern Large Language Models (LLMs) have shown human-like abilities in many\nlanguage tasks, sparking interest in comparing LLMs' and humans' language\nprocessing. In this paper, we conduct a detailed comparison of the two on a\nsentence comprehension task using garden-path constructions, which are\nnotoriously challenging for humans. Based on psycholinguistic research, we\nformulate hypotheses on why garden-path sentences are hard, and test these\nhypotheses on human participants and a large suite of LLMs using comprehension\nquestions. Our findings reveal that both LLMs and humans struggle with specific\nsyntactic complexities, with some models showing high correlation with human\ncomprehension. To complement our findings, we test LLM comprehension of\ngarden-path constructions with paraphrasing and text-to-image generation tasks,\nand find that the results mirror the sentence comprehension question results,\nfurther validating our findings on LLM understanding of these constructions.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.09307v1",
    "published_date": "2025-02-13 13:19:33 UTC",
    "updated_date": "2025-02-13 13:19:33 UTC"
  },
  {
    "arxiv_id": "2502.09305v1",
    "title": "Predicting Drive Test Results in Mobile Networks Using Optimization Techniques",
    "authors": [
      "MohammadJava Taheri",
      "Abolfazl Diyanat",
      "MortezaAli Ahmadi",
      "Ali Nazari"
    ],
    "abstract": "Mobile network operators constantly optimize their networks to ensure\nsuperior service quality and coverage. This optimization is crucial for\nmaintaining an optimal user experience and requires extensive data collection\nand analysis. One of the primary methods for gathering this data is through\ndrive tests, where technical teams use specialized equipment to collect signal\ninformation across various regions. However, drive tests are both costly and\ntime-consuming, and they face challenges such as traffic conditions,\nenvironmental factors, and limited access to certain areas. These constraints\nmake it difficult to replicate drive tests under similar conditions. In this\nstudy, we propose a method that enables operators to predict received signal\nstrength at specific locations using data from other drive test points. By\nreducing the need for widespread drive tests, this approach allows operators to\nsave time and resources while still obtaining the necessary data to optimize\ntheir networks and mitigate the challenges associated with traditional drive\ntests.",
    "categories": [
      "cs.NI",
      "cs.AI",
      "cs.SE"
    ],
    "primary_category": "cs.NI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.09305v1",
    "published_date": "2025-02-13 13:17:31 UTC",
    "updated_date": "2025-02-13 13:17:31 UTC"
  },
  {
    "arxiv_id": "2502.09294v1",
    "title": "Indeterminacy in Affective Computing: Considering Meaning and Context in Data Collection Practices",
    "authors": [
      "Bernd Dudzik",
      "Tiffany Matej Hrkalovic",
      "Chenxu Hao",
      "Chirag Raman",
      "Masha Tsfasman"
    ],
    "abstract": "Automatic Affect Prediction (AAP) uses computational analysis of input data\nsuch as text, speech, images, and physiological signals to predict various\naffective phenomena (e.g., emotions or moods). These models are typically\nconstructed using supervised machine-learning algorithms, which rely heavily on\nlabeled training datasets. In this position paper, we posit that all AAP\ntraining data are derived from human Affective Interpretation Processes,\nresulting in a form of Affective Meaning. Research on human affect indicates a\nform of complexity that is fundamental to such meaning: it can possess what we\nrefer to here broadly as Qualities of Indeterminacy (QIs) - encompassing\nSubjectivity (meaning depends on who is interpreting), Uncertainty (lack of\nconfidence regarding meanings' correctness), Ambiguity (meaning contains\nmutually exclusive concepts) and Vagueness (meaning is situated at different\nlevels in a nested hierarchy). Failing to appropriately consider QIs leads to\nresults incapable of meaningful and reliable predictions. Based on this\npremise, we argue that a crucial step in adequately addressing indeterminacy in\nAAP is the development of data collection practices for modeling corpora that\ninvolve the systematic consideration of 1) a relevant set of QIs and 2) context\nfor the associated interpretation processes. To this end, we are 1) outlining a\nconceptual model of AIPs and the QIs associated with the meaning these produce\nand a conceptual structure of relevant context, supporting understanding of its\nrole. Finally, we use our framework for 2) discussing examples of\ncontext-sensitivity-related challenges for addressing QIs in data collection\nsetups. We believe our efforts can stimulate a structured discussion of both\nthe role of aspects of indeterminacy and context in research on AAP, informing\nthe development of better practices for data collection and analysis.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted at: 12th International Conference on Affective Computing and\n  Intelligent Interaction Workshops and Demos (ACIIW)",
    "pdf_url": "http://arxiv.org/pdf/2502.09294v1",
    "published_date": "2025-02-13 13:08:42 UTC",
    "updated_date": "2025-02-13 13:08:42 UTC"
  },
  {
    "arxiv_id": "2502.09284v2",
    "title": "SparQLe: Speech Queries to Text Translation Through LLMs",
    "authors": [
      "Amirbek Djanibekov",
      "Hanan Aldarmaki"
    ],
    "abstract": "With the growing influence of Large Language Models (LLMs), there is\nincreasing interest in integrating speech representations with them to enable\nmore seamless multi-modal processing and speech understanding. This study\nintroduces a novel approach that leverages self-supervised speech\nrepresentations in combination with instruction-tuned LLMs for speech-to-text\ntranslation. The proposed approach leverages a modality adapter to align\nextracted speech features with instruction-tuned LLMs using English-language\ndata. Our experiments demonstrate that this method effectively preserves the\nsemantic content of the input speech and serves as an effective bridge between\nself-supervised speech models and instruction-tuned LLMs, offering a promising\nsolution for various speech understanding applications.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.09284v2",
    "published_date": "2025-02-13 12:57:15 UTC",
    "updated_date": "2025-04-19 20:20:36 UTC"
  },
  {
    "arxiv_id": "2502.09271v3",
    "title": "LiSA: Leveraging Link Recommender to Attack Graph Neural Networks via Subgraph Injection",
    "authors": [
      "Wenlun Zhang",
      "Enyan Dai",
      "Kentaro Yoshioka"
    ],
    "abstract": "Graph Neural Networks (GNNs) have demonstrated remarkable proficiency in\nmodeling data with graph structures, yet recent research reveals their\nsusceptibility to adversarial attacks. Traditional attack methodologies, which\nrely on manipulating the original graph or adding links to artificially created\nnodes, often prove impractical in real-world settings. This paper introduces a\nnovel adversarial scenario involving the injection of an isolated subgraph to\ndeceive both the link recommender and the node classifier within a GNN system.\nSpecifically, the link recommender is mislead to propose links between targeted\nvictim nodes and the subgraph, encouraging users to unintentionally establish\nconnections and that would degrade the node classification accuracy, thereby\nfacilitating a successful attack. To address this, we present the LiSA\nframework, which employs a dual surrogate model and bi-level optimization to\nsimultaneously meet two adversarial objectives. Extensive experiments on\nreal-world datasets demonstrate the effectiveness of our method.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "PAKDD 2025",
    "pdf_url": "http://arxiv.org/pdf/2502.09271v3",
    "published_date": "2025-02-13 12:33:39 UTC",
    "updated_date": "2025-02-25 07:50:20 UTC"
  },
  {
    "arxiv_id": "2503.16439v1",
    "title": "DreamLLM-3D: Affective Dream Reliving using Large Language Model and 3D Generative AI",
    "authors": [
      "Pinyao Liu",
      "Keon Ju Lee",
      "Alexander Steinmaurer",
      "Claudia Picard-Deland",
      "Michelle Carr",
      "Alexandra Kitson"
    ],
    "abstract": "We present DreamLLM-3D, a composite multimodal AI system behind an immersive\nart installation for dream re-experiencing. It enables automated dream content\nanalysis for immersive dream-reliving, by integrating a Large Language Model\n(LLM) with text-to-3D Generative AI. The LLM processes voiced dream reports to\nidentify key dream entities (characters and objects), social interaction, and\ndream sentiment. The extracted entities are visualized as dynamic 3D point\nclouds, with emotional data influencing the color and soundscapes of the\nvirtual dream environment. Additionally, we propose an experiential\nAI-Dreamworker Hybrid paradigm. Our system and paradigm could potentially\nfacilitate a more emotionally engaging dream-reliving experience, enhancing\npersonal insights and creativity.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.MM"
    ],
    "primary_category": "cs.HC",
    "comment": "8 pages, 3 figures, Accepted by NeurIPS creative AI track 2024",
    "pdf_url": "http://arxiv.org/pdf/2503.16439v1",
    "published_date": "2025-02-13 12:29:55 UTC",
    "updated_date": "2025-02-13 12:29:55 UTC"
  },
  {
    "arxiv_id": "2502.09257v1",
    "title": "Bandit Multiclass List Classification",
    "authors": [
      "Liad Erez",
      "Tomer Koren"
    ],
    "abstract": "We study the problem of multiclass list classification with (semi-)bandit\nfeedback, where input examples are mapped into subsets of size $m$ of a\ncollection of $K$ possible labels, and the feedback consists of the predicted\nlabels which lie in the set of true labels of the given example. Our main\nresult is for the $(\\varepsilon,\\delta)$-PAC variant of the problem for which\nwe design an algorithm that returns an $\\varepsilon$-optimal hypothesis with\nhigh probability using a sample complexity of $O \\big( (\\mathrm{poly}(K/m) + sm\n/ \\varepsilon^2) \\log (|H|/\\delta) \\big)$ where $H$ is the underlying (finite)\nhypothesis class and $s$ is an upper bound on the number of true labels for a\ngiven example. This bound improves upon known bounds for combinatorial\nsemi-bandits whenever $s \\ll K$. Moreover, in the regime where $s = O(1)$ the\nleading terms in our bound match the corresponding full-information rates,\nimplying that bandit feedback essentially comes at no cost. Our PAC learning\nalgorithm is also computationally efficient given access to an ERM oracle for\n$H$. Additionally, we consider the regret minimization setting where data can\nbe generated adversarially, and establish a regret bound of $\\widetilde O(|H| +\n\\sqrt{smT \\log |H|})$. Our results generalize and extend those of Erez et al.\n(2024) who consider the simpler single-label setting corresponding to $s=m=1$,\nand in fact hold for the more general contextual combinatorial semi-bandit\nproblem with $s$-sparse rewards.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.09257v1",
    "published_date": "2025-02-13 12:13:25 UTC",
    "updated_date": "2025-02-13 12:13:25 UTC"
  },
  {
    "arxiv_id": "2502.09256v1",
    "title": "DynSegNet:Dynamic Architecture Adjustment for Adversarial Learning in Segmenting Hemorrhagic Lesions from Fundus Images",
    "authors": [
      "Zesheng Li",
      "Minwen Liao",
      "Haoran Chen",
      "Yan Su",
      "Chengchang Pan",
      "Honggang Qi"
    ],
    "abstract": "The hemorrhagic lesion segmentation plays a critical role in ophthalmic\ndiagnosis, directly influencing early disease detection, treatment planning,\nand therapeutic efficacy evaluation. However, the task faces significant\nchallenges due to lesion morphological variability, indistinct boundaries, and\nlow contrast with background tissues. To improve diagnostic accuracy and\ntreatment outcomes, developing advanced segmentation techniques remains\nimperative. This paper proposes an adversarial learning-based dynamic\narchitecture adjustment approach that integrates hierarchical U-shaped\nencoder-decoder, residual blocks, attention mechanisms, and ASPP modules. By\ndynamically optimizing feature fusion, our method enhances segmentation\nperformance. Experimental results demonstrate a Dice coefficient of 0.6802, IoU\nof 0.5602, Recall of 0.766, Precision of 0.6525, and Accuracy of 0.9955,\neffectively addressing the challenges in fundus image hemorrhage\nsegmentation.[* Corresponding author.]",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "12 pages,4 figures",
    "pdf_url": "http://arxiv.org/pdf/2502.09256v1",
    "published_date": "2025-02-13 12:11:58 UTC",
    "updated_date": "2025-02-13 12:11:58 UTC"
  },
  {
    "arxiv_id": "2502.09254v1",
    "title": "AnomalyGFM: Graph Foundation Model for Zero/Few-shot Anomaly Detection",
    "authors": [
      "Hezhe Qiao",
      "Chaoxi Niu",
      "Ling Chen",
      "Guansong Pang"
    ],
    "abstract": "Graph anomaly detection (GAD) aims to identify abnormal nodes that differ\nfrom the majority of the nodes in a graph, which has been attracting\nsignificant attention in recent years. Existing generalist graph models have\nachieved remarkable success in different graph tasks but struggle to generalize\nto the GAD task. This limitation arises from their difficulty in learning\ngeneralized knowledge for capturing the inherently infrequent, irregular and\nheterogeneous abnormality patterns in graphs from different domains. To address\nthis challenge, we propose AnomalyGFM, a GAD-oriented graph foundation model\nthat supports zero-shot inference and few-shot prompt tuning for GAD in diverse\ngraph datasets. One key insight is that graph-agnostic representations for\nnormal and abnormal classes are required to support effective zero/few-shot GAD\nacross different graphs. Motivated by this, AnomalyGFM is pre-trained to align\ndata-independent, learnable normal and abnormal class prototypes with node\nrepresentation residuals (i.e., representation deviation of a node from its\nneighbors). The residual features essentially project the node information into\na unified feature space where we can effectively measure the abnormality of\nnodes from different graphs in a consistent way. This provides a driving force\nfor the learning of graph-agnostic, discriminative prototypes for the normal\nand abnormal classes, which can be used to enable zero-shot GAD on new graphs,\nincluding very large-scale graphs. If there are few-shot labeled normal nodes\navailable in the new graphs, AnomalyGFM can further support prompt tuning to\nleverage these nodes for better adaptation. Comprehensive experiments on 11\nwidely-used GAD datasets with real anomalies, demonstrate that AnomalyGFM\nsignificantly outperforms state-of-the-art competing methods under both zero-\nand few-shot GAD settings.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "14 pages",
    "pdf_url": "http://arxiv.org/pdf/2502.09254v1",
    "published_date": "2025-02-13 12:10:05 UTC",
    "updated_date": "2025-02-13 12:10:05 UTC"
  },
  {
    "arxiv_id": "2502.09247v1",
    "title": "The Joint Entity-Relation Extraction Model Based on Span and Interactive Fusion Representation for Chinese Medical Texts with Complex Semantics",
    "authors": [
      "Danni Feng",
      "Runzhi Li",
      "Jing Wang",
      "Siyu Yan",
      "Lihong Ma",
      "Yunli Xing"
    ],
    "abstract": "Joint entity-relation extraction is a critical task in transforming\nunstructured or semi-structured text into triplets, facilitating the\nconstruction of large-scale knowledge graphs, and supporting various downstream\napplications. Despite its importance, research on Chinese text, particularly\nwith complex semantics in specialized domains like medicine, remains limited.\nTo address this gap, we introduce the CH-DDI, a Chinese drug-drug interactions\ndataset designed to capture the intricacies of medical text. Leveraging the\nstrengths of attention mechanisms in capturing long-range dependencies, we\npropose the SEA module, which enhances the extraction of complex contextual\nsemantic information, thereby improving entity recognition and relation\nextraction. Additionally, to address the inefficiencies of existing methods in\nfacilitating information exchange between entity recognition and relation\nextraction, we present an interactive fusion representation module. This module\nemploys Cross Attention for bidirectional information exchange between the\ntasks and further refines feature extraction through BiLSTM. Experimental\nresults on both our CH-DDI dataset and public CoNLL04 dataset demonstrate that\nour model exhibits strong generalization capabilities. On the CH-DDI dataset,\nour model achieves an F1-score of 96.73% for entity recognition and 78.43% for\nrelation extraction. On the CoNLL04 dataset, it attains an entity recognition\nprecision of 89.54% and a relation extraction accuracy of 71.64%.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.09247v1",
    "published_date": "2025-02-13 12:03:36 UTC",
    "updated_date": "2025-02-13 12:03:36 UTC"
  },
  {
    "arxiv_id": "2502.09242v1",
    "title": "From large language models to multimodal AI: A scoping review on the potential of generative AI in medicine",
    "authors": [
      "Lukas Buess",
      "Matthias Keicher",
      "Nassir Navab",
      "Andreas Maier",
      "Soroosh Tayebi Arasteh"
    ],
    "abstract": "Generative artificial intelligence (AI) models, such as diffusion models and\nOpenAI's ChatGPT, are transforming medicine by enhancing diagnostic accuracy\nand automating clinical workflows. The field has advanced rapidly, evolving\nfrom text-only large language models for tasks such as clinical documentation\nand decision support to multimodal AI systems capable of integrating diverse\ndata modalities, including imaging, text, and structured data, within a single\nmodel. The diverse landscape of these technologies, along with rising interest,\nhighlights the need for a comprehensive review of their applications and\npotential. This scoping review explores the evolution of multimodal AI,\nhighlighting its methods, applications, datasets, and evaluation in clinical\nsettings. Adhering to PRISMA-ScR guidelines, we systematically queried PubMed,\nIEEE Xplore, and Web of Science, prioritizing recent studies published up to\nthe end of 2024. After rigorous screening, 144 papers were included, revealing\nkey trends and challenges in this dynamic field. Our findings underscore a\nshift from unimodal to multimodal approaches, driving innovations in diagnostic\nsupport, medical report generation, drug discovery, and conversational AI.\nHowever, critical challenges remain, including the integration of heterogeneous\ndata types, improving model interpretability, addressing ethical concerns, and\nvalidating AI systems in real-world clinical settings. This review summarizes\nthe current state of the art, identifies critical gaps, and provides insights\nto guide the development of scalable, trustworthy, and clinically impactful\nmultimodal AI solutions in healthcare.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.09242v1",
    "published_date": "2025-02-13 11:57:51 UTC",
    "updated_date": "2025-02-13 11:57:51 UTC"
  },
  {
    "arxiv_id": "2502.09235v1",
    "title": "Hybrid Answer Set Programming: Foundations and Applications",
    "authors": [
      "Nicolas RÃ¼hling"
    ],
    "abstract": "Answer Set Programming (ASP) is a powerful tool for solving real-world\nproblems. However, many problems involve numeric values and complex constraints\nbeyond the capabilities of standard ASP solvers. Hybrid solvers like CLINGCON\nand CLINGO[DL] address this by using specialized methods for specific\nconstraints. However, these solvers lack a strong theoretical foundation.\n  This issue has first been addressed by introducing the Logic of\nHere-and-There with constraints (HT_c) as an extension of the Logic of\nHere-and-There (HT) and its non-monotone extension Equilibrium Logic. Nowadays,\nHT serves as a logical foundation for ASP and has facilitated a broader\nunderstanding of this paradigm. The idea is that HTC (and other extensions)\nplay an analogous role for hybrid ASP.\n  There remain many open questions about these logics regarding their\nfundamental characteristics as well as their practical use in solvers, ie. how\nthey can guide the implementation.\n  Having a formal understanding of these hybrid logics is also needed to better\nunderstand the inherent structure of the (real-world) problems they are applied\nto and to improve their representations in ASP. As an example of an application\nof ASP we use product configuration.",
    "categories": [
      "cs.AI",
      "cs.LO"
    ],
    "primary_category": "cs.AI",
    "comment": "In Proceedings ICLP 2024, arXiv:2502.08453",
    "pdf_url": "http://arxiv.org/pdf/2502.09235v1",
    "published_date": "2025-02-13 11:53:57 UTC",
    "updated_date": "2025-02-13 11:53:57 UTC"
  },
  {
    "arxiv_id": "2502.09233v1",
    "title": "Commonsense Reasoning-Aided Autonomous Vehicle Systems",
    "authors": [
      "Keegan Kimbrell"
    ],
    "abstract": "Autonomous Vehicle (AV) systems have been developed with a strong reliance on\nmachine learning techniques. While machine learning approaches, such as deep\nlearning, are extremely effective at tasks that involve observation and\nclassification, they struggle when it comes to performing higher level\nreasoning about situations on the road. This research involves incorporating\ncommonsense reasoning models that use image data to improve AV systems. This\nwill allow AV systems to perform more accurate reasoning while also making them\nmore adjustable, explainable, and ethical. This paper will discuss the findings\nso far and motivate its direction going forward.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "In Proceedings ICLP 2024, arXiv:2502.08453",
    "pdf_url": "http://arxiv.org/pdf/2502.09233v1",
    "published_date": "2025-02-13 11:53:25 UTC",
    "updated_date": "2025-02-13 11:53:25 UTC"
  },
  {
    "arxiv_id": "2502.09232v1",
    "title": "Logical foundations of Smart Contracts",
    "authors": [
      "Kalonji Kalala"
    ],
    "abstract": "Nowadays, sophisticated domains are emerging which require appropriate\nformalisms to be specified accurately in order to reason about them. One such\ndomain is constituted of smart contracts that have emerged in cyber physical\nsystems as a way of enforcing formal agreements between components of these\nsystems. Smart contracts self-execute to run and share business processes\nthrough blockchain, in decentralized systems, with many different participants.\nLegal contracts are in many cases complex documents, with a number of\nexceptions, and many subcontracts. The implementation of smart contracts based\non legal contracts is a long and laborious task, that needs to include all\nactions, procedures, and the effects of actions related to the execution of the\ncontract. An ongoing open problem in this area is to formally account for smart\ncontracts using a uniform and somewhat universal formalism. This thesis\nproposes logical foundations to smart contracts using the Situation Calculus, a\nlogic for reasoning about actions. Situation Calculus is one of the prominent\nlogic-based artificial intelligence approaches that provides enough logical\nmechanism to specify and implement dynamic and complex systems such as\ncontracts. Situation Calculus is suitable to show how worlds dynamically\nchange. Smart contracts are going to be implement with Golog (written en\nProlog), a Situation Calculus-based programming language for modeling complex\nand dynamic behaviors.",
    "categories": [
      "cs.LO",
      "cs.AI"
    ],
    "primary_category": "cs.LO",
    "comment": "In Proceedings ICLP 2024, arXiv:2502.08453",
    "pdf_url": "http://arxiv.org/pdf/2502.09232v1",
    "published_date": "2025-02-13 11:53:10 UTC",
    "updated_date": "2025-02-13 11:53:10 UTC"
  },
  {
    "arxiv_id": "2502.09230v1",
    "title": "Relating Answer Set Programming and Many-sorted Logics for Formal Verification",
    "authors": [
      "Zachary Hansen"
    ],
    "abstract": "Answer Set Programming (ASP) is an important logic programming paradigm\nwithin the field of Knowledge Representation and Reasoning. As a concise,\nhuman-readable, declarative language, ASP is an excellent tool for developing\ntrustworthy (especially, artificially intelligent) software systems. However,\nformally verifying ASP programs offers some unique challenges, such as\n  1. a lack of modularity (the meanings of rules are difficult to define in\nisolation from the enclosing program),\n  2. the ground-and-solve semantics (the meanings of rules are dependent on the\ninput data with which the program is grounded), and\n  3. limitations of existing tools.\n  My research agenda has been focused on addressing these three issues with the\nintention of making ASP verification an accessible, routine task that is\nregularly performed alongside program development. In this vein, I have\ninvestigated alternative semantics for ASP based on translations into the logic\nof here-and-there and many-sorted first-order logic. These semantics promote a\nmodular understanding of logic programs, bypass grounding, and enable us to use\nautomated theorem provers to automatically verify properties of programs.",
    "categories": [
      "cs.LO",
      "cs.AI",
      "cs.PL"
    ],
    "primary_category": "cs.LO",
    "comment": "In Proceedings ICLP 2024, arXiv:2502.08453",
    "pdf_url": "http://arxiv.org/pdf/2502.09230v1",
    "published_date": "2025-02-13 11:52:40 UTC",
    "updated_date": "2025-02-13 11:52:40 UTC"
  },
  {
    "arxiv_id": "2502.09228v1",
    "title": "Computational methods for Dynamic Answer Set Programming",
    "authors": [
      "Susana Hahn"
    ],
    "abstract": "In our daily lives and industrial settings, we often encounter dynamic\nproblems that require reasoning over time and metric constraints. These include\ntasks such as scheduling, routing, and production sequencing. Dynamic logics\nhave traditionally addressed these needs but often lack the flexibility and\nintegration required for comprehensive problem modeling. This research aims to\nextend Answer Set Programming (ASP), a powerful declarative problem-solving\napproach, to handle dynamic domains effectively. By integrating concepts from\ndynamic, temporal, and metric logics into ASP, we seek to develop robust\nsystems capable of modeling complex dynamic problems and performing efficient\nreasoning tasks, thereby enhancing ASPs applicability in industrial contexts.",
    "categories": [
      "cs.AI",
      "cs.FL",
      "cs.LO",
      "I.2.4; I.2.8"
    ],
    "primary_category": "cs.AI",
    "comment": "In Proceedings ICLP 2024, arXiv:2502.08453",
    "pdf_url": "http://arxiv.org/pdf/2502.09228v1",
    "published_date": "2025-02-13 11:52:25 UTC",
    "updated_date": "2025-02-13 11:52:25 UTC"
  },
  {
    "arxiv_id": "2502.09226v1",
    "title": "Generating Causally Compliant Counterfactual Explanations using ASP",
    "authors": [
      "Sopam Dasgupta"
    ],
    "abstract": "This research is focused on generating achievable counterfactual\nexplanations. Given a negative outcome computed by a machine learning model or\na decision system, the novel CoGS approach generates (i) a counterfactual\nsolution that represents a positive outcome and (ii) a path that will take us\nfrom the negative outcome to the positive one, where each node in the path\nrepresents a change in an attribute (feature) value. CoGS computes paths that\nrespect the causal constraints among features. Thus, the counterfactuals\ncomputed by CoGS are realistic. CoGS utilizes rule-based machine learning\nalgorithms to model causal dependencies between features. The paper discusses\nthe current status of the research and the preliminary results obtained.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "In Proceedings ICLP 2024, arXiv:2502.08453",
    "pdf_url": "http://arxiv.org/pdf/2502.09226v1",
    "published_date": "2025-02-13 11:51:53 UTC",
    "updated_date": "2025-02-13 11:51:53 UTC"
  },
  {
    "arxiv_id": "2502.09224v1",
    "title": "Order-Sorted Intensional Logic: Expressing Subtyping Polymorphism with Typing Assertions and Quantification over Concepts",
    "authors": [
      "ÄorÄe MarkoviÄ",
      "Marc Denecker"
    ],
    "abstract": "Subtyping, also known as subtype polymorphism, is a concept extensively\nstudied in programming language theory, delineating the substitutability\nrelation among datatypes. This property ensures that programs designed for\nsupertype objects remain compatible with their subtypes.\n  In this paper, we explore the capability of order-sorted logic for utilizing\nthese ideas in the context of Knowledge Representation. We recognize two\nfundamental limitations: First, the inability of this logic to address the\nconcept rather than the value of non-logical symbols, and second, the lack of\nlanguage constructs for constraining the type of terms. Consequently, we\npropose guarded order-sorted intensional logic, where guards are language\nconstructs for annotating typing information and intensional logic provides\nsupport for quantification over concepts.",
    "categories": [
      "cs.AI",
      "cs.LO"
    ],
    "primary_category": "cs.AI",
    "comment": "In Proceedings ICLP 2024, arXiv:2502.08453",
    "pdf_url": "http://arxiv.org/pdf/2502.09224v1",
    "published_date": "2025-02-13 11:51:22 UTC",
    "updated_date": "2025-02-13 11:51:22 UTC"
  },
  {
    "arxiv_id": "2502.09222v1",
    "title": "ASP-driven User-interaction with Clinguin",
    "authors": [
      "Alexander Beiser",
      "Susana Hahn",
      "Torsten Schaub"
    ],
    "abstract": "We present clinguin, a system for ASP-driven user interface design. Clinguin\nstreamlines the development of user interfaces for ASP developers by letting\nthem build interactive prototypes directly in ASP, eliminating the need for\nseparate frontend languages. To this end, clinguin uses a few dedicated\npredicates to define user interfaces and the treatment of user-triggered\nevents. This simple design greatly facilitates the specification of user\ninteractions with an ASP system, in our case clingo.",
    "categories": [
      "cs.AI",
      "cs.HC",
      "cs.LO",
      "cs.SE",
      "D.1.6"
    ],
    "primary_category": "cs.AI",
    "comment": "In Proceedings ICLP 2024, arXiv:2502.08453",
    "pdf_url": "http://arxiv.org/pdf/2502.09222v1",
    "published_date": "2025-02-13 11:50:51 UTC",
    "updated_date": "2025-02-13 11:50:51 UTC"
  },
  {
    "arxiv_id": "2502.09221v1",
    "title": "Pearce's Characterisation in an Epistemic Domain",
    "authors": [
      "Ezgi Iraz Su"
    ],
    "abstract": "Answer-set programming (ASP) is a successful problem-solving approach in\nlogic-based AI. In ASP, problems are represented as declarative logic programs,\nand solutions are identified through their answer sets. Equilibrium logic (EL)\nis a general-purpose nonmonotonic reasoning formalism, based on a monotonic\nlogic called here-and-there logic. EL was basically proposed by Pearce as a\nfoundational framework of ASP. Epistemic specifications (ES) are extensions of\nASP-programs with subjective literals. These new modal constructs in the\nASP-language make it possible to check whether a regular literal of ASP is true\nin every (or some) answer-set of a program. ES-programs are interpreted by\nworld-views, which are essentially collections of answer-sets. (Reflexive)\nautoepistemic logic is a nonmonotonic formalism, modeling self-belief\n(knowledge) of ideally rational agents. A relatively new semantics for ES is\nbased on a combination of EL and (reflexive) autoepistemic logic. In this\npaper, we first propose an overarching framework in the epistemic ASP domain.\nWe then establish a correspondence between existing (reflexive) (auto)epistemic\nequilibrium logics and our easily-adaptable comprehensive framework, building\non Pearce's characterisation of answer-sets as equilibrium models. We achieve\nthis by extending Ferraris' work on answer sets for propositional theories to\nthe epistemic case and reveal the relationship between some ES-semantic\nproposals.",
    "categories": [
      "cs.AI",
      "cs.LO",
      "cs.PL"
    ],
    "primary_category": "cs.AI",
    "comment": "In Proceedings ICLP 2024, arXiv:2502.08453",
    "pdf_url": "http://arxiv.org/pdf/2502.09221v1",
    "published_date": "2025-02-13 11:50:36 UTC",
    "updated_date": "2025-02-13 11:50:36 UTC"
  },
  {
    "arxiv_id": "2502.09220v1",
    "title": "Graphical Conditions for the Existence, Unicity and Number of Regular Models",
    "authors": [
      "Van-Giang Trinh",
      "Belaid Benhamou",
      "Sylvain Soliman",
      "FranÃ§ois Fages"
    ],
    "abstract": "The regular models of a normal logic program are a particular type of partial\n(i.e. 3-valued) models which correspond to stable partial models with minimal\nundefinedness. In this paper, we explore graphical conditions on the dependency\ngraph of a finite ground normal logic program to analyze the existence, unicity\nand number of regular models for the program. We show three main results: 1) a\nnecessary condition for the existence of non-trivial (i.e. non-2-valued)\nregular models, 2) a sufficient condition for the unicity of regular models,\nand 3) two upper bounds for the number of regular models based on positive\nfeedback vertex sets. The first two conditions generalize the finite cases of\nthe two existing results obtained by You and Yuan (1994) for normal logic\nprograms with well-founded stratification. The third result is also new to the\nbest of our knowledge. Key to our proofs is a connection that we establish\nbetween finite ground normal logic programs and Boolean network theory.",
    "categories": [
      "cs.LO",
      "cs.AI",
      "cs.DM"
    ],
    "primary_category": "cs.LO",
    "comment": "In Proceedings ICLP 2024, arXiv:2502.08453",
    "pdf_url": "http://arxiv.org/pdf/2502.09220v1",
    "published_date": "2025-02-13 11:50:20 UTC",
    "updated_date": "2025-02-13 11:50:20 UTC"
  },
  {
    "arxiv_id": "2502.09219v1",
    "title": "Abduction of Domain Relationships from Data for VQA",
    "authors": [
      "Al Mehdi Saadat Chowdhury",
      "Paulo Shakarian",
      "Gerardo I. Simari"
    ],
    "abstract": "In this paper, we study the problem of visual question answering (VQA) where\nthe image and query are represented by ASP programs that lack domain data. We\nprovide an approach that is orthogonal and complementary to existing knowledge\naugmentation techniques where we abduce domain relationships of image\nconstructs from past examples. After framing the abduction problem, we provide\na baseline approach, and an implementation that significantly improves the\naccuracy of query answering yet requires few examples.",
    "categories": [
      "cs.LO",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.LO",
    "comment": "In Proceedings ICLP 2024, arXiv:2502.08453",
    "pdf_url": "http://arxiv.org/pdf/2502.09219v1",
    "published_date": "2025-02-13 11:50:04 UTC",
    "updated_date": "2025-02-13 11:50:04 UTC"
  },
  {
    "arxiv_id": "2502.09218v1",
    "title": "Data2Concept2Text: An Explainable Multilingual Framework for Data Analysis Narration",
    "authors": [
      "Flavio Bertini",
      "Alessandro Dal PalÃ¹",
      "Federica Zaglio",
      "Francesco Fabiano",
      "Andrea Formisano"
    ],
    "abstract": "This paper presents a complete explainable system that interprets a set of\ndata, abstracts the underlying features and describes them in a natural\nlanguage of choice. The system relies on two crucial stages: (i) identifying\nemerging properties from data and transforming them into abstract concepts, and\n(ii) converting these concepts into natural language. Despite the impressive\nnatural language generation capabilities demonstrated by Large Language Models,\ntheir statistical nature and the intricacy of their internal mechanism still\nforce us to employ these techniques as black boxes, forgoing trustworthiness.\nDeveloping an explainable pipeline for data interpretation would allow\nfacilitating its use in safety-critical environments like processing medical\ninformation and allowing non-experts and visually impaired people to access\nnarrated information. To this end, we believe that the fields of knowledge\nrepresentation and automated reasoning research could present a valid\nalternative. Expanding on prior research that tackled the first stage (i), we\nfocus on the second stage, named Concept2Text. Being explainable, data\ntranslation is easily modeled through logic-based rules, once again emphasizing\nthe role of declarative programming in achieving AI explainability. This paper\nexplores a Prolog/CLP-based rewriting system to interpret concepts-articulated\nin terms of classes and relations, plus common knowledge-derived from a generic\nontology, generating natural language text. Its main features include\nhierarchical tree rewritings, modular multilingual generation, support for\nequivalent variants across semantic, grammar, and lexical levels, and a\ntransparent rule-based system. We outline the architecture and demonstrate its\nflexibility through some examples capable of generating numerous diverse and\nequivalent rewritings based on the input concept.",
    "categories": [
      "cs.LO",
      "cs.AI"
    ],
    "primary_category": "cs.LO",
    "comment": "In Proceedings ICLP 2024, arXiv:2502.08453",
    "pdf_url": "http://arxiv.org/pdf/2502.09218v1",
    "published_date": "2025-02-13 11:49:48 UTC",
    "updated_date": "2025-02-13 11:49:48 UTC"
  },
  {
    "arxiv_id": "2502.09216v1",
    "title": "Mind the Gaps: Logical English, Prolog, and Multi-agent Systems for Autonomous Vehicles",
    "authors": [
      "Galileo Sartor",
      "Adam Wyner",
      "Giuseppe Contissa"
    ],
    "abstract": "In this paper, we present a modular system for representing and reasoning\nwith legal aspects of traffic rules for autonomous vehicles. We focus on a\nsubset of the United Kingdom's Highway Code (HC) related to junctions. As human\ndrivers and automated vehicles (AVs) will interact on the roads, especially in\nurban environments, we claim that an accessible, unitary, high-level\ncomputational model should exist and be applicable to both users. Autonomous\nvehicles introduce a shift in liability that should not bring disadvantages or\nincreased burden on human drivers. We develop a system \"in silico\" of the\nmodel. The proposed system is built of three main components: a natural\nlanguage interface, using Logical English, which encodes the rules; an internal\nrepresentation of the rules in Prolog; and an multi-agent-based simulation\nenvironment, built in NetLogo. The three components interact: Logical English\nis translated into and out of Prolog (along with some support code); Prolog and\nNetLogo interface via predicates. Such a modular approach enables the different\ncomponents to carry different \"burdens\" in the overall system; it also allows\nswapping of modules. Given NetLogo, we can visualize the effect of the modeled\nrules as well as validate the system with a simple dynamic running scenario.\nDesignated agents monitor the behaviour of the vehicles for compliance and\nrecord potential violations where they occur. The information on potential\nviolations is then utilized by Validators, to determine whether the violation\nis punishable, differentiating between exceptions and cases.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LO",
      "cs.MA"
    ],
    "primary_category": "cs.AI",
    "comment": "In Proceedings ICLP 2024, arXiv:2502.08453",
    "pdf_url": "http://arxiv.org/pdf/2502.09216v1",
    "published_date": "2025-02-13 11:49:17 UTC",
    "updated_date": "2025-02-13 11:49:17 UTC"
  },
  {
    "arxiv_id": "2502.09215v1",
    "title": "Architecture for Simulating Behavior Mode Changes in Norm-Aware Autonomous Agents",
    "authors": [
      "Sean Glaze",
      "Daniela Inclezan"
    ],
    "abstract": "This paper presents an architecture for simulating the actions of a\nnorm-aware intelligent agent whose behavior with respect to norm compliance is\nset, and can later be changed, by a human controller. Updating an agent's\nbehavior mode from a norm-abiding to a riskier one may be relevant when the\nagent is involved in time-sensitive rescue operations, for example. We base our\nwork on the Authorization and Obligation Policy Language AOPL designed by\nGelfond and Lobo for the specification of norms. We introduce an architecture\nand a prototype software system that can be used to simulate an agent's plans\nunder different behavior modes that can later be changed by the controller. We\nenvision such software to be useful to policy makers, as they can more readily\nunderstand how agents may act in certain situations based on the agents'\nattitudes towards norm-compliance. Policy makers may then refine their policies\nif simulations show unwanted consequences.",
    "categories": [
      "cs.LO",
      "cs.AI",
      "D.1.6; D.3"
    ],
    "primary_category": "cs.LO",
    "comment": "In Proceedings ICLP 2024, arXiv:2502.08453",
    "pdf_url": "http://arxiv.org/pdf/2502.09215v1",
    "published_date": "2025-02-13 11:49:02 UTC",
    "updated_date": "2025-02-13 11:49:02 UTC"
  },
  {
    "arxiv_id": "2502.09212v1",
    "title": "LP-LM: No Hallucinations in Question Answering with Logic Programming",
    "authors": [
      "Katherine Wu",
      "Yanhong A. Liu"
    ],
    "abstract": "Large language models (LLMs) are able to generate human-like responses to\nuser queries. However, LLMs exhibit inherent limitations, especially because\nthey hallucinate. This paper introduces LP-LM, a system that grounds answers to\nquestions in known facts contained in a knowledge base (KB), facilitated\nthrough semantic parsing in Prolog, and always produces answers that are\nreliable.\n  LP-LM generates a most probable constituency parse tree along with a\ncorresponding Prolog term for an input question via Prolog definite clause\ngrammar (DCG) parsing. The term is then executed against a KB of natural\nlanguage sentences also represented as Prolog terms for question answering. By\nleveraging DCG and tabling, LP-LM runs in linear time in the size of input\nsentences for sufficiently many grammar rules. Performing experiments comparing\nLP-LM with current well-known LLMs in accuracy, we show that LLMs hallucinate\non even simple questions, unlike LP-LM.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "In Proceedings ICLP 2024, arXiv:2502.08453",
    "pdf_url": "http://arxiv.org/pdf/2502.09212v1",
    "published_date": "2025-02-13 11:48:31 UTC",
    "updated_date": "2025-02-13 11:48:31 UTC"
  },
  {
    "arxiv_id": "2502.09211v1",
    "title": "Visual Graph Question Answering with ASP and LLMs for Language Parsing",
    "authors": [
      "Jakob Johannes Bauer",
      "Thomas Eiter",
      "Nelson Higuera Ruiz",
      "Johannes Oetsch"
    ],
    "abstract": "Visual Question Answering (VQA) is a challenging problem that requires to\nprocess multimodal input. Answer-Set Programming (ASP) has shown great\npotential in this regard to add interpretability and explainability to modular\nVQA architectures. In this work, we address the problem of how to integrate ASP\nwith modules for vision and natural language processing to solve a new and\ndemanding VQA variant that is concerned with images of graphs (not graphs in\nsymbolic form). Images containing graph-based structures are an ubiquitous and\npopular form of visualisation. Here, we deal with the particular problem of\ngraphs inspired by transit networks, and we introduce a novel dataset that\namends an existing one by adding images of graphs that resemble metro lines.\nOur modular neuro-symbolic approach combines optical graph recognition for\ngraph parsing, a pretrained optical character recognition neural network for\nparsing labels, Large Language Models (LLMs) for language processing, and ASP\nfor reasoning. This method serves as a first baseline and achieves an overall\naverage accuracy of 73% on the dataset. Our evaluation provides further\nevidence of the potential of modular neuro-symbolic systems, in particular with\npretrained models that do not involve any further training and logic\nprogramming for reasoning, to solve complex VQA tasks.",
    "categories": [
      "cs.AI",
      "cs.CV",
      "cs.LO",
      "D.1.6; I.2.10"
    ],
    "primary_category": "cs.AI",
    "comment": "In Proceedings ICLP 2024, arXiv:2502.08453. This work was partially\n  funded from the Bosch Center for AI",
    "pdf_url": "http://arxiv.org/pdf/2502.09211v1",
    "published_date": "2025-02-13 11:47:59 UTC",
    "updated_date": "2025-02-13 11:47:59 UTC"
  },
  {
    "arxiv_id": "2502.09209v1",
    "title": "On LLM-generated Logic Programs and their Inference Execution Methods",
    "authors": [
      "Paul Tarau"
    ],
    "abstract": "Large Language Models (LLMs) trained on petabytes of data are highly\ncompressed repositories of a significant proportion of the knowledge\naccumulated and distilled so far. In this paper we study techniques to elicit\nthis knowledge in the form of several classes of logic programs, including\npropositional Horn clauses, Dual Horn clauses, relational triplets and Definite\nClause Grammars. Exposing this knowledge as logic programs enables sound\nreasoning methods that can verify alignment of LLM outputs to their intended\nuses and extend their inference capabilities. We study new execution methods\nfor the generated programs, including soft-unification of abducible facts\nagainst LLM-generated content stored in a vector database as well as GPU-based\nacceleration of minimal model computation that supports inference with large\nLLM-generated programs.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "In Proceedings ICLP 2024, arXiv:2502.08453",
    "pdf_url": "http://arxiv.org/pdf/2502.09209v1",
    "published_date": "2025-02-13 11:47:44 UTC",
    "updated_date": "2025-02-13 11:47:44 UTC"
  },
  {
    "arxiv_id": "2502.09206v1",
    "title": "Efficient OWL2QL Meta-reasoning Using ASP-based Hybrid Knowledge Bases",
    "authors": [
      "Haya Majid Qureshi",
      "Wolfgang Faber"
    ],
    "abstract": "Metamodeling refers to scenarios in ontologies in which classes and roles can\nbe members of classes or occur in roles. This is a desirable modelling feature\nin several applications, but allowing it without restrictions is problematic\nfor several reasons, mainly because it causes undecidability. Therefore,\npractical languages either forbid metamodeling explicitly or treat occurrences\nof classes as instances to be semantically different from other occurrences,\nthereby not allowing metamodeling semantically. Several extensions have been\nproposed to provide metamodeling to some extent. Building on earlier work that\nreduces metamodeling query answering to Datalog query answering, recently\nreductions to query answering over hybrid knowledge bases were proposed with\nthe aim of using the Datalog transformation only where necessary. Preliminary\nwork showed that the approach works, but the hoped-for performance improvements\nwere not observed yet. In this work we expand on this body of work by improving\nthe theoretical basis of the reductions and by using alternative tools that\nshow competitive performance.",
    "categories": [
      "cs.LO",
      "cs.AI",
      "cs.SC"
    ],
    "primary_category": "cs.LO",
    "comment": "In Proceedings ICLP 2024, arXiv:2502.08453",
    "pdf_url": "http://arxiv.org/pdf/2502.09206v1",
    "published_date": "2025-02-13 11:46:10 UTC",
    "updated_date": "2025-02-13 11:46:10 UTC"
  },
  {
    "arxiv_id": "2502.09205v1",
    "title": "Counterfactual Explanations as Plans",
    "authors": [
      "Vaishak Belle"
    ],
    "abstract": "There has been considerable recent interest in explainability in AI,\nespecially with black-box machine learning models. As correctly observed by the\nplanning community, when the application at hand is not a single-shot decision\nor prediction, but a sequence of actions that depend on observations, a richer\nnotion of explanations are desirable.\n  In this paper, we look to provide a formal account of ``counterfactual\nexplanations,\" based in terms of action sequences. We then show that this\nnaturally leads to an account of model reconciliation, which might take the\nform of the user correcting the agent's model, or suggesting actions to the\nagent's plan. For this, we will need to articulate what is true versus what is\nknown, and we appeal to a modal fragment of the situation calculus to formalise\nthese intuitions. We consider various settings: the agent knowing partial\ntruths, weakened truths and having false beliefs, and show that our definitions\neasily generalize to these different settings.",
    "categories": [
      "cs.AI",
      "cs.LO"
    ],
    "primary_category": "cs.AI",
    "comment": "In Proceedings ICLP 2024, arXiv:2502.08453",
    "pdf_url": "http://arxiv.org/pdf/2502.09205v1",
    "published_date": "2025-02-13 11:45:54 UTC",
    "updated_date": "2025-02-13 11:45:54 UTC"
  },
  {
    "arxiv_id": "2502.09204v1",
    "title": "Logical Lease Litigation: Prolog and LLMs for Rental Law Compliance in New York",
    "authors": [
      "Sanskar Sehgal",
      "Yanhong A. Liu"
    ],
    "abstract": "Legal cases require careful logical reasoning following the laws, whereas\ninteractions with non-technical users must be in natural language. As an\napplication combining logical reasoning using Prolog and natural language\nprocessing using large language models (LLMs), this paper presents a novel\napproach and system, LogicLease, to automate the analysis of landlord-tenant\nlegal cases in the state of New York. LogicLease determines compliance with\nrelevant legal requirements by analyzing case descriptions and citing all\nrelevant laws. It leverages LLMs for information extraction and Prolog for\nlegal reasoning. By separating information extraction from legal reasoning,\nLogicLease achieves greater transparency and control over the legal logic\napplied to each case. We evaluate the accuracy, efficiency, and robustness of\nLogicLease through a series of tests, achieving 100% accuracy and an average\nprocessing time of 2.57 seconds. LogicLease presents advantages over\nstate-of-the-art LLM-based legal analysis systems by providing clear,\nstep-by-step reasoning, citing specific laws, and distinguishing itself by its\nability to avoid hallucinations -- a common issue in LLMs.",
    "categories": [
      "cs.AI",
      "cs.LO"
    ],
    "primary_category": "cs.AI",
    "comment": "In Proceedings ICLP 2024, arXiv:2502.08453",
    "pdf_url": "http://arxiv.org/pdf/2502.09204v1",
    "published_date": "2025-02-13 11:45:38 UTC",
    "updated_date": "2025-02-13 11:45:38 UTC"
  },
  {
    "arxiv_id": "2502.09680v1",
    "title": "Object-Centric Latent Action Learning",
    "authors": [
      "Albina Klepach",
      "Alexander Nikulin",
      "Ilya Zisman",
      "Denis Tarasov",
      "Alexander Derevyagin",
      "Andrei Polubarov",
      "Nikita Lyubaykin",
      "Vladislav Kurenkov"
    ],
    "abstract": "Leveraging vast amounts of internet video data for Embodied AI is currently\nbottle-necked by the lack of action annotations and the presence of\naction-correlated distractors. We propose a novel object-centric latent action\nlearning approach, based on VideoSaur and LAPO, that employs self-supervised\ndecomposition of scenes into object representations and annotates video data\nwith proxy-action labels. This method effectively disentangles causal\nagent-object interactions from irrelevant background noise and reduces the\nperformance degradation of latent action learning approaches caused by\ndistractors. Our preliminary experiments with the Distracting Control Suite\nshow that latent action pretraining based on object decompositions improve the\nquality of inferred latent actions by x2.7 and efficiency of downstream\nfine-tuning with a small set of labeled actions, increasing return by x2.6 on\naverage.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Preprint. In review",
    "pdf_url": "http://arxiv.org/pdf/2502.09680v1",
    "published_date": "2025-02-13 11:27:05 UTC",
    "updated_date": "2025-02-13 11:27:05 UTC"
  },
  {
    "arxiv_id": "2502.09188v1",
    "title": "Matina: A Large-Scale 73B Token Persian Text Corpus",
    "authors": [
      "Sara Bourbour Hosseinbeigi",
      "Fatemeh Taherinezhad",
      "Heshaam Faili",
      "Hamed Baghbani",
      "Fatemeh Nadi",
      "Mostafa Amiri"
    ],
    "abstract": "Text corpora are essential for training models used in tasks like\nsummarization, translation, and large language models (LLMs). While various\nefforts have been made to collect monolingual and multilingual datasets in many\nlanguages, Persian has often been underrepresented due to limited resources for\ndata collection and preprocessing. Existing Persian datasets are typically\nsmall and lack content diversity, consisting mainly of weblogs and news\narticles. This shortage of high-quality, varied data has slowed the development\nof NLP models and open-source LLMs for Persian. Since model performance depends\nheavily on the quality of training data, we address this gap by introducing the\nMatina corpus, a new Persian dataset of 72.9B tokens, carefully preprocessed\nand deduplicated to ensure high data quality. We further assess its\neffectiveness by training and evaluating transformer-based models on key NLP\ntasks. Both the dataset and preprocessing codes are publicly available,\nenabling researchers to build on and improve this resource for future Persian\nNLP advancements.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.09188v1",
    "published_date": "2025-02-13 11:22:19 UTC",
    "updated_date": "2025-02-13 11:22:19 UTC"
  },
  {
    "arxiv_id": "2502.09183v1",
    "title": "RefineCoder: Iterative Improving of Large Language Models via Adaptive Critique Refinement for Code Generation",
    "authors": [
      "Changzhi Zhou",
      "Xinyu Zhang",
      "Dandan Song",
      "Xiancai Chen",
      "Wanli Gu",
      "Huipeng Ma",
      "Yuhang Tian",
      "Mengdi Zhang",
      "Linmei Hu"
    ],
    "abstract": "Code generation has attracted increasing attention with the rise of Large\nLanguage Models (LLMs). Many studies have developed powerful code LLMs by\nsynthesizing code-related instruction data and applying supervised fine-tuning.\nHowever, these methods are limited by teacher model distillation and ignore the\npotential of iterative refinement by self-generated code. In this paper, we\npropose Adaptive Critique Refinement (ACR), which enables the model to refine\nitself by self-generated code and external critique, rather than directly\nimitating the code responses of the teacher model. Concretely, ACR includes a\ncomposite scoring system with LLM-as-a-Judge to evaluate the quality of code\nresponses and a selective critique strategy with LLM-as-a-Critic to critique\nself-generated low-quality code responses. We develop the RefineCoder series by\niteratively applying ACR, achieving continuous performance improvement on\nmultiple code generation benchmarks. Compared to the baselines of the same\nsize, our proposed RefineCoder series can achieve comparable or even superior\nperformance using less data.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "work in process",
    "pdf_url": "http://arxiv.org/pdf/2502.09183v1",
    "published_date": "2025-02-13 11:17:53 UTC",
    "updated_date": "2025-02-13 11:17:53 UTC"
  },
  {
    "arxiv_id": "2502.09175v1",
    "title": "FLAME: Flexible LLM-Assisted Moderation Engine",
    "authors": [
      "Ivan Bakulin",
      "Ilia Kopanichuk",
      "Iaroslav Bespalov",
      "Nikita Radchenko",
      "Vladimir Shaposhnikov",
      "Dmitry Dylov",
      "Ivan Oseledets"
    ],
    "abstract": "The rapid advancement of Large Language Models (LLMs) has introduced\nsignificant challenges in moderating user-model interactions. While LLMs\ndemonstrate remarkable capabilities, they remain vulnerable to adversarial\nattacks, particularly ``jailbreaking'' techniques that bypass content safety\nmeasures. Current content moderation systems, which primarily rely on input\nprompt filtering, have proven insufficient, with techniques like Best-of-N\n(BoN) jailbreaking achieving success rates of 80% or more against popular LLMs.\nIn this paper, we introduce Flexible LLM-Assisted Moderation Engine (FLAME): a\nnew approach that shifts the focus from input filtering to output moderation.\nUnlike traditional circuit-breaking methods that analyze user queries, FLAME\nevaluates model responses, offering several key advantages: (1) computational\nefficiency in both training and inference, (2) enhanced resistance to BoN\njailbreaking attacks, and (3) flexibility in defining and updating safety\ncriteria through customizable topic filtering. Our experiments demonstrate that\nFLAME significantly outperforms current moderation systems. For example, FLAME\nreduces attack success rate in GPT-4o-mini and DeepSeek-v3 by a factor of ~9,\nwhile maintaining low computational overhead. We provide comprehensive\nevaluation on various LLMs and analyze the engine's efficiency against the\nstate-of-the-art jailbreaking. This work contributes to the development of more\nrobust and adaptable content moderation systems for LLMs.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.09175v1",
    "published_date": "2025-02-13 11:05:55 UTC",
    "updated_date": "2025-02-13 11:05:55 UTC"
  },
  {
    "arxiv_id": "2502.09173v1",
    "title": "Two-Stage Representation Learning for Analyzing Movement Behavior Dynamics in People Living with Dementia",
    "authors": [
      "Jin Cui",
      "Alexander Capstick",
      "Payam Barnaghi",
      "Gregory Scott"
    ],
    "abstract": "In remote healthcare monitoring, time series representation learning reveals\ncritical patient behavior patterns from high-frequency data. This study\nanalyzes home activity data from individuals living with dementia by proposing\na two-stage, self-supervised learning approach tailored to uncover low-rank\nstructures. The first stage converts time-series activities into text sequences\nencoded by a pre-trained language model, providing a rich, high-dimensional\nlatent state space using a PageRank-based method. This PageRank vector captures\nlatent state transitions, effectively compressing complex behaviour data into a\nsuccinct form that enhances interpretability. This low-rank representation not\nonly enhances model interpretability but also facilitates clustering and\ntransition analysis, revealing key behavioral patterns correlated with\nclinicalmetrics such as MMSE and ADAS-COG scores. Our findings demonstrate the\nframework's potential in supporting cognitive status prediction, personalized\ncare interventions, and large-scale health monitoring.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "AAAI 2025 Workshop on Large Language Models and Generative AI for\n  Health",
    "pdf_url": "http://arxiv.org/pdf/2502.09173v1",
    "published_date": "2025-02-13 10:57:25 UTC",
    "updated_date": "2025-02-13 10:57:25 UTC"
  },
  {
    "arxiv_id": "2502.12171v1",
    "title": "GoRA: Gradient-driven Adaptive Low Rank Adaptation",
    "authors": [
      "Haonan He",
      "Peng Ye",
      "Yuchen Ren",
      "Yuan Yuan",
      "Lei Chen"
    ],
    "abstract": "Low-Rank Adaptation (LoRA) is a crucial method for efficiently fine-tuning\npretrained large language models (LLMs), with its performance largely\ninfluenced by two key factors: rank and initialization strategy. Numerous LoRA\nvariants have been proposed to enhance its performance by addressing these\nfactors. However, these variants often compromise LoRA's usability or\nefficiency. In this paper, we analyze the fundamental limitations of existing\nmethods and introduce a novel approach, GoRA (Gradient-driven Adaptive Low Rank\nAdaptation), which adaptively assigns ranks and initializes weights for\nlow-rank adapters simultaneously based on gradient information. Extensive\nexperimental results demonstrate that GoRA significantly improves performance\nwhile preserving the high usability and efficiency of LoRA. On the T5 model\nfine-tuned for the GLUE benchmark, GoRA achieves a 5.88-point improvement over\nLoRA and slightly surpasses full fine-tuning. Similarly, on the\nLlama3.1-8B-Base model fine-tuned for GSM8k tasks, GoRA outperforms LoRA with a\n5.13-point improvement and exceeds full fine-tuning in high-rank settings by a\nmargin of 2.05 points.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.12171v1",
    "published_date": "2025-02-13 10:33:58 UTC",
    "updated_date": "2025-02-13 10:33:58 UTC"
  },
  {
    "arxiv_id": "2502.12170v1",
    "title": "MUDDFormer: Breaking Residual Bottlenecks in Transformers via Multiway Dynamic Dense Connections",
    "authors": [
      "Da Xiao",
      "Qingye Meng",
      "Shengping Li",
      "Xingyuan Yuan"
    ],
    "abstract": "We propose MUltiway Dynamic Dense (MUDD) connections, a simple yet effective\nmethod to address the limitations of residual connections and enhance\ncross-layer information flow in Transformers. Unlike existing dense connection\napproaches with static and shared connection weights, MUDD generates connection\nweights dynamically depending on hidden states at each sequence position and\nfor each decoupled input stream (the query, key, value or residual) of a\nTransformer block. MUDD connections can be seamlessly integrated into any\nTransformer architecture to create MUDDFormer. Extensive experiments show that\nMUDDFormer significantly outperforms Transformers across various model\narchitectures and scales in language modeling, achieving the performance of\nTransformers trained with 1.8X-2.4X compute. Notably, MUDDPythia-2.8B matches\nPythia-6.9B in pretraining ppl and downstream tasks and even rivals Pythia-12B\nin five-shot settings, while adding only 0.23% parameters and 0.4% computation.\nCode in JAX and PyTorch and pre-trained models are available at\nhttps://github.com/Caiyun-AI/MUDDFormer .",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.12170v1",
    "published_date": "2025-02-13 10:26:27 UTC",
    "updated_date": "2025-02-13 10:26:27 UTC"
  },
  {
    "arxiv_id": "2502.09125v1",
    "title": "Automatic Pruning via Structured Lasso with Class-wise Information",
    "authors": [
      "Xiang Liu",
      "Mingchen Li",
      "Xia Li",
      "Leigang Qu",
      "Zifan Peng",
      "Yijun Song",
      "Zemin Liu",
      "Linshan Jiang",
      "Jialin Li"
    ],
    "abstract": "Most pruning methods concentrate on unimportant filters of neural networks.\nHowever, they face the loss of statistical information due to a lack of\nconsideration for class-wise data. In this paper, from the perspective of\nleveraging precise class-wise information for model pruning, we utilize\nstructured lasso with guidance from Information Bottleneck theory. Our approach\nensures that statistical information is retained during the pruning process.\nWith these techniques, we introduce two innovative adaptive network pruning\nschemes: sparse graph-structured lasso pruning with Information Bottleneck\n(\\textbf{sGLP-IB}) and sparse tree-guided lasso pruning with Information\nBottleneck (\\textbf{sTLP-IB}). The key aspect is pruning model filters using\nsGLP-IB and sTLP-IB to better capture class-wise relatedness. Compared to\nmultiple state-of-the-art methods, our approaches demonstrate superior\nperformance across three datasets and six model architectures in extensive\nexperiments. For instance, using the VGG16 model on the CIFAR-10 dataset, we\nachieve a parameter reduction of 85%, a decrease in FLOPs by 61%, and maintain\nan accuracy of 94.10% (0.14% higher than the original model); we reduce the\nparameters by 55% with the accuracy at 76.12% using the ResNet architecture on\nImageNet (only drops 0.03%). In summary, we successfully reduce model size and\ncomputational resource usage while maintaining accuracy. Our codes are at\nhttps://anonymous.4open.science/r/IJCAI-8104.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "11 pages, 2 figures",
    "pdf_url": "http://arxiv.org/pdf/2502.09125v1",
    "published_date": "2025-02-13 10:03:29 UTC",
    "updated_date": "2025-02-13 10:03:29 UTC"
  },
  {
    "arxiv_id": "2502.09122v1",
    "title": "Improving Deep Regression with Tightness",
    "authors": [
      "Shihao Zhang",
      "Yuguang Yan",
      "Angela Yao"
    ],
    "abstract": "For deep regression, preserving the ordinality of the targets with respect to\nthe feature representation improves performance across various tasks. However,\na theoretical explanation for the benefits of ordinality is still lacking. This\nwork reveals that preserving ordinality reduces the conditional entropy\n$H(Z|Y)$ of representation $Z$ conditional on the target $Y$. However, our\nfindings reveal that typical regression losses do little to reduce $H(Z|Y)$,\neven though it is vital for generalization performance. With this motivation,\nwe introduce an optimal transport-based regularizer to preserve the similarity\nrelationships of targets in the feature space to reduce $H(Z|Y)$. Additionally,\nwe introduce a simple yet efficient strategy of duplicating the regressor\ntargets, also with the aim of reducing $H(Z|Y)$. Experiments on three\nreal-world regression tasks verify the effectiveness of our strategies to\nimprove deep regression. Code:\nhttps://github.com/needylove/Regression_tightness.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "ICLR 2025, Code: https://github.com/needylove/Regression_tightness",
    "pdf_url": "http://arxiv.org/pdf/2502.09122v1",
    "published_date": "2025-02-13 09:57:25 UTC",
    "updated_date": "2025-02-13 09:57:25 UTC"
  },
  {
    "arxiv_id": "2502.09104v1",
    "title": "One-shot Federated Learning Methods: A Practical Guide",
    "authors": [
      "Xiang Liu",
      "Zhenheng Tang",
      "Xia Li",
      "Yijun Song",
      "Sijie Ji",
      "Zemin Liu",
      "Bo Han",
      "Linshan Jiang",
      "Jialin Li"
    ],
    "abstract": "One-shot Federated Learning (OFL) is a distributed machine learning paradigm\nthat constrains client-server communication to a single round, addressing\nprivacy and communication overhead issues associated with multiple rounds of\ndata exchange in traditional Federated Learning (FL). OFL demonstrates the\npractical potential for integration with future approaches that require\ncollaborative training models, such as large language models (LLMs). However,\ncurrent OFL methods face two major challenges: data heterogeneity and model\nheterogeneity, which result in subpar performance compared to conventional FL\nmethods. Worse still, despite numerous studies addressing these limitations, a\ncomprehensive summary is still lacking. To address these gaps, this paper\npresents a systematic analysis of the challenges faced by OFL and thoroughly\nreviews the current methods. We also offer an innovative categorization method\nand analyze the trade-offs of various techniques. Additionally, we discuss the\nmost promising future directions and the technologies that should be integrated\ninto the OFL field. This work aims to provide guidance and insights for future\nresearch.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "10 pages, 1 figure",
    "pdf_url": "http://arxiv.org/pdf/2502.09104v1",
    "published_date": "2025-02-13 09:26:44 UTC",
    "updated_date": "2025-02-13 09:26:44 UTC"
  },
  {
    "arxiv_id": "2502.10470v3",
    "title": "MetaDE: Evolving Differential Evolution by Differential Evolution",
    "authors": [
      "Minyang Chen",
      "Chenchen Feng",
      "and Ran Cheng"
    ],
    "abstract": "As a cornerstone in the Evolutionary Computation (EC) domain, Differential\nEvolution (DE) is known for its simplicity and effectiveness in handling\nchallenging black-box optimization problems. While the advantages of DE are\nwell-recognized, achieving peak performance heavily depends on its\nhyperparameters such as the mutation factor, crossover probability, and the\nselection of specific DE strategies. Traditional approaches to this\nhyperparameter dilemma have leaned towards parameter tuning or adaptive\nmechanisms. However, identifying the optimal settings tailored for specific\nproblems remains a persistent challenge. In response, we introduce MetaDE, an\napproach that evolves DE's intrinsic hyperparameters and strategies using DE\nitself at a meta-level. A pivotal aspect of MetaDE is a specialized\nparameterization technique, which endows it with the capability to dynamically\nmodify DE's parameters and strategies throughout the evolutionary process. To\naugment computational efficiency, MetaDE incorporates a design that leverages\nparallel processing through a GPU-accelerated computing framework. Within such\na framework, DE is not just a solver but also an optimizer for its own\nconfigurations, thus streamlining the process of hyperparameter optimization\nand problem-solving into a cohesive and automated workflow. Extensive\nevaluations on the CEC2022 benchmark suite demonstrate MetaDE's promising\nperformance. Moreover, when applied to robot control via evolutionary\nreinforcement learning, MetaDE also demonstrates promising performance. The\nsource code of MetaDE is publicly accessible at:\nhttps://github.com/EMI-Group/metade.",
    "categories": [
      "cs.NE",
      "cs.AI"
    ],
    "primary_category": "cs.NE",
    "comment": "Accepted by IEEE TEVC",
    "pdf_url": "http://arxiv.org/pdf/2502.10470v3",
    "published_date": "2025-02-13 09:24:47 UTC",
    "updated_date": "2025-03-26 08:06:11 UTC"
  },
  {
    "arxiv_id": "2502.09100v1",
    "title": "Logical Reasoning in Large Language Models: A Survey",
    "authors": [
      "Hanmeng Liu",
      "Zhizhang Fu",
      "Mengru Ding",
      "Ruoxi Ning",
      "Chaoli Zhang",
      "Xiaozhang Liu",
      "Yue Zhang"
    ],
    "abstract": "With the emergence of advanced reasoning models like OpenAI o3 and\nDeepSeek-R1, large language models (LLMs) have demonstrated remarkable\nreasoning capabilities. However, their ability to perform rigorous logical\nreasoning remains an open question. This survey synthesizes recent advancements\nin logical reasoning within LLMs, a critical area of AI research. It outlines\nthe scope of logical reasoning in LLMs, its theoretical foundations, and the\nbenchmarks used to evaluate reasoning proficiency. We analyze existing\ncapabilities across different reasoning paradigms - deductive, inductive,\nabductive, and analogical - and assess strategies to enhance reasoning\nperformance, including data-centric tuning, reinforcement learning, decoding\nstrategies, and neuro-symbolic approaches. The review concludes with future\ndirections, emphasizing the need for further exploration to strengthen logical\nreasoning in AI systems.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.09100v1",
    "published_date": "2025-02-13 09:19:14 UTC",
    "updated_date": "2025-02-13 09:19:14 UTC"
  },
  {
    "arxiv_id": "2502.09675v1",
    "title": "Multi-level Conflict-Aware Network for Multi-modal Sentiment Analysis",
    "authors": [
      "Yubo Gao",
      "Haotian Wu",
      "Lei Zhang"
    ],
    "abstract": "Multimodal Sentiment Analysis (MSA) aims to recognize human emotions by\nexploiting textual, acoustic, and visual modalities, and thus how to make full\nuse of the interactions between different modalities is a central challenge of\nMSA. Interaction contains alignment and conflict aspects. Current works mainly\nemphasize alignment and the inherent differences between unimodal modalities,\nneglecting the fact that there are also potential conflicts between bimodal\ncombinations. Additionally, multi-task learning-based conflict modeling methods\noften rely on the unstable generated labels. To address these challenges, we\npropose a novel multi-level conflict-aware network (MCAN) for multimodal\nsentiment analysis, which progressively segregates alignment and conflict\nconstituents from unimodal and bimodal representations, and further exploits\nthe conflict constituents with the conflict modeling branch. In the conflict\nmodeling branch, we conduct discrepancy constraints at both the representation\nand predicted output levels, avoiding dependence on the generated labels.\nExperimental results on the CMU-MOSI and CMU-MOSEI datasets demonstrate the\neffectiveness of the proposed MCAN.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "5 pages, 1 figure",
    "pdf_url": "http://arxiv.org/pdf/2502.09675v1",
    "published_date": "2025-02-13 09:14:36 UTC",
    "updated_date": "2025-02-13 09:14:36 UTC"
  },
  {
    "arxiv_id": "2502.09083v1",
    "title": "Show Me the Work: Fact-Checkers' Requirements for Explainable Automated Fact-Checking",
    "authors": [
      "Greta Warren",
      "Irina Shklovski",
      "Isabelle Augenstein"
    ],
    "abstract": "The pervasiveness of large language models and generative AI in online media\nhas amplified the need for effective automated fact-checking to assist\nfact-checkers in tackling the increasing volume and sophistication of\nmisinformation. The complex nature of fact-checking demands that automated\nfact-checking systems provide explanations that enable fact-checkers to\nscrutinise their outputs. However, it is unclear how these explanations should\nalign with the decision-making and reasoning processes of fact-checkers to be\neffectively integrated into their workflows. Through semi-structured interviews\nwith fact-checking professionals, we bridge this gap by: (i) providing an\naccount of how fact-checkers assess evidence, make decisions, and explain their\nprocesses; (ii) examining how fact-checkers use automated tools in practice;\nand (iii) identifying fact-checker explanation requirements for automated\nfact-checking tools. The findings show unmet explanation needs and identify\nimportant criteria for replicable fact-checking explanations that trace the\nmodel's reasoning path, reference specific evidence, and highlight uncertainty\nand information gaps.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.HC",
    "comment": "Conditionally accepted to CHI'25",
    "pdf_url": "http://arxiv.org/pdf/2502.09083v1",
    "published_date": "2025-02-13 08:56:25 UTC",
    "updated_date": "2025-02-13 08:56:25 UTC"
  },
  {
    "arxiv_id": "2502.09082v1",
    "title": "CoSER: Coordinating LLM-Based Persona Simulation of Established Roles",
    "authors": [
      "Xintao Wang",
      "Heng Wang",
      "Yifei Zhang",
      "Xinfeng Yuan",
      "Rui Xu",
      "Jen-tse Huang",
      "Siyu Yuan",
      "Haoran Guo",
      "Jiangjie Chen",
      "Wei Wang",
      "Yanghua Xiao",
      "Shuchang Zhou"
    ],
    "abstract": "Role-playing language agents (RPLAs) have emerged as promising applications\nof large language models (LLMs). However, simulating established characters\npresents a challenging task for RPLAs, due to the lack of authentic character\ndatasets and nuanced evaluation methods using such data. In this paper, we\npresent CoSER, a collection of a high-quality dataset, open models, and an\nevaluation protocol towards effective RPLAs of established characters. The\nCoSER dataset covers 17,966 characters from 771 renowned books. It provides\nauthentic dialogues with real-world intricacies, as well as diverse data types\nsuch as conversation setups, character experiences and internal thoughts.\nDrawing from acting methodology, we introduce given-circumstance acting for\ntraining and evaluating role-playing LLMs, where LLMs sequentially portray\nmultiple characters in book scenes. Using our dataset, we develop CoSER 8B and\nCoSER 70B, i.e., advanced open role-playing LLMs built on LLaMA-3.1 models.\nExtensive experiments demonstrate the value of the CoSER dataset for RPLA\ntraining, evaluation and retrieval. Moreover, CoSER 70B exhibits\nstate-of-the-art performance surpassing or matching GPT-4o on our evaluation\nand three existing benchmarks, i.e., achieving 75.80% and 93.47% accuracy on\nthe InCharacter and LifeChoice benchmarks respectively.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.09082v1",
    "published_date": "2025-02-13 08:55:24 UTC",
    "updated_date": "2025-02-13 08:55:24 UTC"
  },
  {
    "arxiv_id": "2502.17470v3",
    "title": "MC2SleepNet: Multi-modal Cross-masking with Contrastive Learning for Sleep Stage Classification",
    "authors": [
      "Younghoon Na",
      "Hyun Keun Ahn",
      "Hyun-Kyung Lee",
      "Yoongeol Lee",
      "Seung Hun Oh",
      "Hongkwon Kim",
      "Jeong-Gun Lee"
    ],
    "abstract": "Sleep profoundly affects our health, and sleep deficiency or disorders can\ncause physical and mental problems. Despite significant findings from previous\nstudies, challenges persist in optimizing deep learning models, especially in\nmulti-modal learning for high-accuracy sleep stage classification. Our research\nintroduces MC2SleepNet (Multi-modal Cross-masking with Contrastive learning for\nSleep stage classification Network). It aims to facilitate the effective\ncollaboration between Convolutional Neural Networks (CNNs) and Transformer\narchitectures for multi-modal training with the help of contrastive learning\nand cross-masking. Raw single channel EEG signals and corresponding spectrogram\ndata provide differently characterized modalities for multi-modal learning. Our\nMC2SleepNet has achieved state-of-the-art performance with an accuracy of both\n84.6% on the SleepEDF-78 and 88.6% accuracy on the Sleep Heart Health Study\n(SHHS). These results demonstrate the effective generalization of our proposed\nnetwork across both small and large datasets.",
    "categories": [
      "eess.SP",
      "cs.AI"
    ],
    "primary_category": "eess.SP",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.17470v3",
    "published_date": "2025-02-13 08:33:38 UTC",
    "updated_date": "2025-02-27 02:23:20 UTC"
  },
  {
    "arxiv_id": "2502.09056v3",
    "title": "Adapting Language-Specific LLMs to a Reasoning Model in One Day via Model Merging -- An Open Recipe",
    "authors": [
      "Kunat Pipatanakul",
      "Pittawat Taveekitworachai",
      "Potsawee Manakul",
      "Kasima Tharnpipitchai"
    ],
    "abstract": "This paper investigates data selection and model merging methodologies aimed\nat incorporating advanced reasoning capabilities such as those of DeepSeek R1\ninto language-specific large language models (LLMs), with a particular focus on\nthe Thai LLM. Our goal is to enhance the reasoning capabilities of\nlanguage-specific LLMs while maintaining their target language abilities.\nDeepSeek R1 excels in reasoning but primarily benefits high-resource languages\nsuch as English and Chinese. However, low-resource languages remain underserved\ndue to the dominance of English-centric training data and model optimizations,\nwhich limit performance in these languages. This limitation results in\nunreliable code-switching and diminished effectiveness on tasks in low-resource\nlanguages. Meanwhile, local and regional LLM initiatives have attempted to\nbridge this gap by developing language-specific LLMs that focus on improving\nlocal linguistic fidelity. We demonstrate that, with only publicly available\ndatasets and a computational budget of $120, it is possible to enhance the\nreasoning capabilities of language-specific LLMs to match the level of DeepSeek\nR1, without compromising their performance on target language tasks.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "9 pages",
    "pdf_url": "http://arxiv.org/pdf/2502.09056v3",
    "published_date": "2025-02-13 08:10:45 UTC",
    "updated_date": "2025-03-27 06:45:16 UTC"
  },
  {
    "arxiv_id": "2502.09055v1",
    "title": "Exploring the Needs of Practising Musicians in Co-Creative AI Through Co-Design",
    "authors": [
      "Stephen James Krol",
      "Maria Teresa Llano Rodriguez",
      "Miguel Loor Paredes"
    ],
    "abstract": "Recent advances in generative AI music have resulted in new technologies that\nare being framed as co-creative tools for musicians with early work\ndemonstrating their potential to add to music practice. While the field has\nseen many valuable contributions, work that involves practising musicians in\nthe design and development of these tools is limited, with the majority of work\nincluding them only once a tool has been developed. In this paper, we present a\ncase study that explores the needs of practising musicians through the\nco-design of a musical variation system, highlighting the importance of\ninvolving a diverse range of musicians throughout the design process and\nuncovering various design insights. This was achieved through two workshops and\na two week ecological evaluation, where musicians from different musical\nbackgrounds offered valuable insights not only on a musical system's design but\nalso on how a musical AI could be integrated into their musical practices.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "Paper accepted into CHI 2025, Yokohama Japan, April 26th - May 1st",
    "pdf_url": "http://arxiv.org/pdf/2502.09055v1",
    "published_date": "2025-02-13 08:10:07 UTC",
    "updated_date": "2025-02-13 08:10:07 UTC"
  },
  {
    "arxiv_id": "2502.17469v2",
    "title": "PixleepFlow: A Pixel-Based Lifelog Framework for Predicting Sleep Quality and Stress Level",
    "authors": [
      "Younghoon Na",
      "Seunghun Oh",
      "Seongji Ko",
      "Hyunkyung Lee"
    ],
    "abstract": "The analysis of lifelogs can yield valuable insights into an individual's\ndaily life, particularly with regard to their health and well-being. The\naccurate assessment of quality of life is necessitated by the use of diverse\nsensors and precise synchronization. To rectify this issue, this study proposes\nthe image-based sleep quality and stress level estimation flow (PixleepFlow).\nPixleepFlow employs a conversion methodology into composite image data to\nexamine sleep patterns and their impact on overall health. Experiments were\nconducted using lifelog datasets to ascertain the optimal combination of data\nformats. In addition, we identified which sensor information has the greatest\ninfluence on the quality of life through Explainable Artificial\nIntelligence(XAI). As a result, PixleepFlow produced more significant results\nthan various data formats. This study was part of a written-based competition,\nand the additional findings from the lifelog dataset are detailed in Section\nSection IV. More information about PixleepFlow can be found at\nhttps://github.com/seongjiko/Pixleep.",
    "categories": [
      "eess.SP",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "eess.SP",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.17469v2",
    "published_date": "2025-02-13 08:09:15 UTC",
    "updated_date": "2025-02-26 03:32:26 UTC"
  },
  {
    "arxiv_id": "2502.09054v2",
    "title": "Cost-Saving LLM Cascades with Early Abstention",
    "authors": [
      "Michael J. Zellinger",
      "Rex Liu",
      "Matt Thomson"
    ],
    "abstract": "LLM cascades deploy small LLMs to answer most queries, limiting the use of\nlarge and expensive LLMs to difficult queries. This approach can significantly\nreduce costs without impacting performance. However, risk-sensitive domains\nsuch as finance or medicine place an additional premium on avoiding model\nerrors. Since even the most expensive models are susceptible to making\nmistakes, applications in these domains benefit from allowing LLM systems to\ncompletely abstain from answering difficult queries. Introducing abstention\nposes a design question for LLM cascades: should abstention only be allowed at\nthe final model or also at earlier models? Since the error patterns of small\nand large models are correlated, allowing earlier models to abstain may reduce\ninference costs and latency by anticipating abstention decisions by expensive\nand slow models, thus avoiding the need to run these models. We investigate the\nbenefits of such \"early abstention\" in LLM cascades and find that it reduces\noverall test loss by 2.2% on average across six benchmarks (GSM8K, MedMCQA,\nMMLU, TriviaQA, TruthfulQA, and XSum). These gains result from a more effective\nuse of abstention, trading a 4.1% average increase in the overall abstention\nrate for a 13.0% reduction in cost and a 5.0% reduction in error rate. Our\nfindings demonstrate the possibility of leveraging correlations between the\nerror patterns of different language models to drive performance improvements\nfor LLM systems with abstention.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "9 pages, 3 figures",
    "pdf_url": "http://arxiv.org/pdf/2502.09054v2",
    "published_date": "2025-02-13 08:08:39 UTC",
    "updated_date": "2025-03-29 01:19:05 UTC"
  },
  {
    "arxiv_id": "2502.09053v1",
    "title": "Game Theory Meets Large Language Models: A Systematic Survey",
    "authors": [
      "Haoran Sun",
      "Yusen Wu",
      "Yukun Cheng",
      "Xu Chu"
    ],
    "abstract": "Game theory establishes a fundamental framework for analyzing strategic\ninteractions among rational decision-makers. The rapid advancement of large\nlanguage models (LLMs) has sparked extensive research exploring the\nintersection of these two fields. Specifically, game-theoretic methods are\nbeing applied to evaluate and enhance LLM capabilities, while LLMs themselves\nare reshaping classic game models. This paper presents a comprehensive survey\nof the intersection of these fields, exploring a bidirectional relationship\nfrom three perspectives: (1) Establishing standardized game-based benchmarks\nfor evaluating LLM behavior; (2) Leveraging game-theoretic methods to improve\nLLM performance through algorithmic innovations; (3) Characterizing the\nsocietal impacts of LLMs through game modeling. Among these three aspects, we\nalso highlight how the equilibrium analysis for traditional game models is\nimpacted by LLMs' advanced language understanding, which in turn extends the\nstudy of game theory. Finally, we identify key challenges and future research\ndirections, assessing their feasibility based on the current state of the\nfield. By bridging theoretical rigor with emerging AI capabilities, this survey\naims to foster interdisciplinary collaboration and drive progress in this\nevolving research area.",
    "categories": [
      "cs.AI",
      "cs.GT",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "10 pages",
    "pdf_url": "http://arxiv.org/pdf/2502.09053v1",
    "published_date": "2025-02-13 08:08:27 UTC",
    "updated_date": "2025-02-13 08:08:27 UTC"
  },
  {
    "arxiv_id": "2502.09051v1",
    "title": "AIDE: Agentically Improve Visual Language Model with Domain Experts",
    "authors": [
      "Ming-Chang Chiu",
      "Fuxiao Liu",
      "Karan Sapra",
      "Andrew Tao",
      "Yaser Jacoob",
      "Xuezhe Ma",
      "Zhiding Yu",
      "Guilin Liu"
    ],
    "abstract": "The enhancement of Visual Language Models (VLMs) has traditionally relied on\nknowledge distillation from larger, more capable models. This dependence\ncreates a fundamental bottleneck for improving state-of-the-art systems,\nparticularly when no superior models exist. We introduce AIDE (Agentic\nImprovement through Domain Experts), a novel framework that enables VLMs to\nautonomously enhance their capabilities by leveraging specialized domain expert\nmodels. AIDE operates through a four-stage process: (1) identifying instances\nfor refinement, (2) engaging domain experts for targeted analysis, (3)\nsynthesizing expert outputs with existing data, and (4) integrating enhanced\ninstances into the training pipeline. Experiments on multiple benchmarks,\nincluding MMMU, MME, MMBench, etc., demonstrate AIDE's ability to achieve\nnotable performance gains without relying on larger VLMs nor human supervision.\nOur framework provides a scalable, resource-efficient approach to continuous\nVLM improvement, addressing critical limitations in current methodologies,\nparticularly valuable when larger models are unavailable to access.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.MA"
    ],
    "primary_category": "cs.CV",
    "comment": "6 pages, 4 figures, 2 tables",
    "pdf_url": "http://arxiv.org/pdf/2502.09051v1",
    "published_date": "2025-02-13 08:05:44 UTC",
    "updated_date": "2025-02-13 08:05:44 UTC"
  },
  {
    "arxiv_id": "2502.09050v1",
    "title": "Leveraging Member-Group Relations via Multi-View Graph Filtering for Effective Group Recommendation",
    "authors": [
      "Chae-Hyun Kim",
      "Yoon-Ryung Choi",
      "Jin-Duk Park",
      "Won-Yong Shin"
    ],
    "abstract": "Group recommendation aims at providing optimized recommendations tailored to\ndiverse groups, enabling groups to enjoy appropriate items. On the other hand,\nmost existing group recommendation methods are built upon deep neural network\n(DNN) architectures designed to capture the intricate relationships between\nmember-level and group-level interactions. While these DNN-based approaches\nhave proven their effectiveness, they require complex and expensive training\nprocedures to incorporate group-level interactions in addition to member-level\ninteractions. To overcome such limitations, we introduce Group-GF, a new\napproach for extremely fast recommendations of items to each group via\nmulti-view graph filtering (GF) that offers a holistic view of complex\nmember-group dynamics, without the need for costly model training.\nSpecifically, in Group-GF, we first construct three item similarity graphs\nmanifesting different viewpoints for GF. Then, we discover a distinct\npolynomial graph filter for each similarity graph and judiciously aggregate the\nthree graph filters. Extensive experiments demonstrate the effectiveness of\nGroup-GF in terms of significantly reducing runtime and achieving\nstate-of-the-art recommendation accuracy.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.IT",
      "cs.LG",
      "cs.SI",
      "math.IT"
    ],
    "primary_category": "cs.IR",
    "comment": "5 pages, 3 figures, 4 tables; ACM Web Conference (WWW 2025) (to\n  appear) (Please cite our conference version.)",
    "pdf_url": "http://arxiv.org/pdf/2502.09050v1",
    "published_date": "2025-02-13 08:05:14 UTC",
    "updated_date": "2025-02-13 08:05:14 UTC"
  },
  {
    "arxiv_id": "2502.09046v1",
    "title": "Criteria-Aware Graph Filtering: Extremely Fast Yet Accurate Multi-Criteria Recommendation",
    "authors": [
      "Jin-Duk Park",
      "Jaemin Yoo",
      "Won-Yong Shin"
    ],
    "abstract": "Multi-criteria (MC) recommender systems, which utilize MC rating information\nfor recommendation, are increasingly widespread in various e-commerce domains.\nHowever, the MC recommendation using training-based collaborative filtering,\nrequiring consideration of multiple ratings compared to single-criterion\ncounterparts, often poses practical challenges in achieving state-of-the-art\nperformance along with scalable model training. To solve this problem, we\npropose CA-GF, a training-free MC recommendation method, which is built upon\ncriteria-aware graph filtering for efficient yet accurate MC recommendations.\nSpecifically, first, we construct an item-item similarity graph using an MC\nuser-expansion graph. Next, we design CA-GF composed of the following key\ncomponents, including 1) criterion-specific graph filtering where the optimal\nfilter for each criterion is found using various types of polynomial low-pass\nfilters and 2) criteria preference-infused aggregation where the smoothed\nsignals from each criterion are aggregated. We demonstrate that CA-GF is (a)\nefficient: providing the computational efficiency, offering the extremely fast\nruntime of less than 0.2 seconds even on the largest benchmark dataset, (b)\naccurate: outperforming benchmark MC recommendation methods, achieving\nsubstantial accuracy gains up to 24% compared to the best competitor, and (c)\ninterpretable: providing interpretations for the contribution of each criterion\nto the model prediction based on visualizations.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.IT",
      "cs.LG",
      "cs.SI",
      "math.IT"
    ],
    "primary_category": "cs.IR",
    "comment": "12 pages, 8 figures, 7 tables; ACM Web Conference (WWW 2025) (to\n  appear) (Please cite our conference version.)",
    "pdf_url": "http://arxiv.org/pdf/2502.09046v1",
    "published_date": "2025-02-13 08:01:38 UTC",
    "updated_date": "2025-02-13 08:01:38 UTC"
  },
  {
    "arxiv_id": "2502.09042v2",
    "title": "Typhoon T1: An Open Thai Reasoning Model",
    "authors": [
      "Pittawat Taveekitworachai",
      "Potsawee Manakul",
      "Kasima Tharnpipitchai",
      "Kunat Pipatanakul"
    ],
    "abstract": "This paper introduces Typhoon T1, an open effort to develop an open Thai\nreasoning model. A reasoning model is a relatively new type of generative model\nbuilt on top of large language models (LLMs). A reasoning model generates a\nlong chain of thought before arriving at a final answer, an approach found to\nimprove performance on complex tasks. However, details on developing such a\nmodel are limited, especially for reasoning models that can generate traces in\na low-resource language. Typhoon T1 presents an open effort that dives into the\ndetails of developing a reasoning model in a more cost-effective way by\nleveraging supervised fine-tuning using open datasets, instead of reinforcement\nlearning. This paper shares the details about synthetic data generation and\ntraining, as well as our dataset and model weights. Additionally, we provide\ninsights gained from developing a reasoning model that generalizes across\ndomains and is capable of generating reasoning traces in a low-resource\nlanguage, using Thai as an example. We hope this open effort provides a\nfoundation for further research in this field.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "25 pages, 6 figures",
    "pdf_url": "http://arxiv.org/pdf/2502.09042v2",
    "published_date": "2025-02-13 07:55:54 UTC",
    "updated_date": "2025-03-27 06:45:15 UTC"
  },
  {
    "arxiv_id": "2502.09039v1",
    "title": "Large Images are Gaussians: High-Quality Large Image Representation with Levels of 2D Gaussian Splatting",
    "authors": [
      "Lingting Zhu",
      "Guying Lin",
      "Jinnan Chen",
      "Xinjie Zhang",
      "Zhenchao Jin",
      "Zhao Wang",
      "Lequan Yu"
    ],
    "abstract": "While Implicit Neural Representations (INRs) have demonstrated significant\nsuccess in image representation, they are often hindered by large training\nmemory and slow decoding speed. Recently, Gaussian Splatting (GS) has emerged\nas a promising solution in 3D reconstruction due to its high-quality novel view\nsynthesis and rapid rendering capabilities, positioning it as a valuable tool\nfor a broad spectrum of applications. In particular, a GS-based representation,\n2DGS, has shown potential for image fitting. In our work, we present\n\\textbf{L}arge \\textbf{I}mages are \\textbf{G}aussians (\\textbf{LIG}), which\ndelves deeper into the application of 2DGS for image representations,\naddressing the challenge of fitting large images with 2DGS in the situation of\nnumerous Gaussian points, through two distinct modifications: 1) we adopt a\nvariant of representation and optimization strategy, facilitating the fitting\nof a large number of Gaussian points; 2) we propose a Level-of-Gaussian\napproach for reconstructing both coarse low-frequency initialization and fine\nhigh-frequency details. Consequently, we successfully represent large images as\nGaussian points and achieve high-quality large image representation,\ndemonstrating its efficacy across various types of large images. Code is\navailable at\n{\\href{https://github.com/HKU-MedAI/LIG}{https://github.com/HKU-MedAI/LIG}}.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted by 39th Annual AAAI Conference on Artificial Intelligence\n  (AAAI 2025). 10 pages, 4 figures",
    "pdf_url": "http://arxiv.org/pdf/2502.09039v1",
    "published_date": "2025-02-13 07:48:56 UTC",
    "updated_date": "2025-02-13 07:48:56 UTC"
  },
  {
    "arxiv_id": "2502.09038v1",
    "title": "AoI-Sensitive Data Forwarding with Distributed Beamforming in UAV-Assisted IoT",
    "authors": [
      "Zifan Lang",
      "Guixia Liu",
      "Geng Sun",
      "Jiahui Li",
      "Zemin Sun",
      "Jiacheng Wang",
      "Victor C. M. Leung"
    ],
    "abstract": "This paper proposes a UAV-assisted forwarding system based on distributed\nbeamforming to enhance age of information (AoI) in Internet of Things (IoT).\nSpecifically, UAVs collect and relay data between sensor nodes (SNs) and the\nremote base station (BS). However, flight delays increase the AoI and degrade\nthe network performance. To mitigate this, we adopt distributed beamforming to\nextend the communication range, reduce the flight frequency and ensure the\ncontinuous data relay and efficient energy utilization. Then, we formulate an\noptimization problem to minimize AoI and UAV energy consumption, by jointly\noptimizing the UAV trajectories and communication schedules. The problem is\nnon-convex and with high dynamic, and thus we propose a deep reinforcement\nlearning (DRL)-based algorithm to solve the problem, thereby enhancing the\nstability and accelerate convergence speed. Simulation results show that the\nproposed algorithm effectively addresses the problem and outperforms other\nbenchmark algorithms.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "6 pages, 4 figures, ICC2025",
    "pdf_url": "http://arxiv.org/pdf/2502.09038v1",
    "published_date": "2025-02-13 07:48:36 UTC",
    "updated_date": "2025-02-13 07:48:36 UTC"
  },
  {
    "arxiv_id": "2502.09022v2",
    "title": "Mechanistic Unveiling of Transformer Circuits: Self-Influence as a Key to Model Reasoning",
    "authors": [
      "Lin Zhang",
      "Lijie Hu",
      "Di Wang"
    ],
    "abstract": "Transformer-based language models have achieved significant success; however,\ntheir internal mechanisms remain largely opaque due to the complexity of\nnon-linear interactions and high-dimensional operations. While previous studies\nhave demonstrated that these models implicitly embed reasoning trees, humans\ntypically employ various distinct logical reasoning mechanisms to complete the\nsame task. It is still unclear which multi-step reasoning mechanisms are used\nby language models to solve such tasks. In this paper, we aim to address this\nquestion by investigating the mechanistic interpretability of language models,\nparticularly in the context of multi-step reasoning tasks. Specifically, we\nemploy circuit analysis and self-influence functions to evaluate the changing\nimportance of each token throughout the reasoning process, allowing us to map\nthe reasoning paths adopted by the model. We apply this methodology to the\nGPT-2 model on a prediction task (IOI) and demonstrate that the underlying\ncircuits reveal a human-interpretable reasoning process used by the model.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted by NAACL2025",
    "pdf_url": "http://arxiv.org/pdf/2502.09022v2",
    "published_date": "2025-02-13 07:19:05 UTC",
    "updated_date": "2025-02-14 05:46:53 UTC"
  },
  {
    "arxiv_id": "2502.09020v1",
    "title": "EventSTR: A Benchmark Dataset and Baselines for Event Stream based Scene Text Recognition",
    "authors": [
      "Xiao Wang",
      "Jingtao Jiang",
      "Dong Li",
      "Futian Wang",
      "Lin Zhu",
      "Yaowei Wang",
      "Yongyong Tian",
      "Jin Tang"
    ],
    "abstract": "Mainstream Scene Text Recognition (STR) algorithms are developed based on RGB\ncameras which are sensitive to challenging factors such as low illumination,\nmotion blur, and cluttered backgrounds. In this paper, we propose to recognize\nthe scene text using bio-inspired event cameras by collecting and annotating a\nlarge-scale benchmark dataset, termed EventSTR. It contains 9,928\nhigh-definition (1280 * 720) event samples and involves both Chinese and\nEnglish characters. We also benchmark multiple STR algorithms as the baselines\nfor future works to compare. In addition, we propose a new event-based scene\ntext recognition framework, termed SimC-ESTR. It first extracts the event\nfeatures using a visual encoder and projects them into tokens using a Q-former\nmodule. More importantly, we propose to augment the vision tokens based on a\nmemory mechanism before feeding into the large language models. A\nsimilarity-based error correction mechanism is embedded within the large\nlanguage model to correct potential minor errors fundamentally based on\ncontextual information. Extensive experiments on the newly proposed EventSTR\ndataset and two simulation STR datasets fully demonstrate the effectiveness of\nour proposed model. We believe that the dataset and algorithmic model can\ninnovatively propose an event-based STR task and are expected to accelerate the\napplication of event cameras in various industries. The source code and\npre-trained models will be released on https://github.com/Event-AHU/EventSTR",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "In Peer Review",
    "pdf_url": "http://arxiv.org/pdf/2502.09020v1",
    "published_date": "2025-02-13 07:16:16 UTC",
    "updated_date": "2025-02-13 07:16:16 UTC"
  },
  {
    "arxiv_id": "2502.09018v1",
    "title": "Zero-shot Concept Bottleneck Models",
    "authors": [
      "Shin'ya Yamaguchi",
      "Kosuke Nishida",
      "Daiki Chijiwa",
      "Yasutoshi Ida"
    ],
    "abstract": "Concept bottleneck models (CBMs) are inherently interpretable and\nintervenable neural network models, which explain their final label prediction\nby the intermediate prediction of high-level semantic concepts. However, they\nrequire target task training to learn input-to-concept and concept-to-label\nmappings, incurring target dataset collections and training resources. In this\npaper, we present \\textit{zero-shot concept bottleneck models} (Z-CBMs), which\npredict concepts and labels in a fully zero-shot manner without training neural\nnetworks. Z-CBMs utilize a large-scale concept bank, which is composed of\nmillions of vocabulary extracted from the web, to describe arbitrary input in\nvarious domains. For the input-to-concept mapping, we introduce concept\nretrieval, which dynamically finds input-related concepts by the cross-modal\nsearch on the concept bank. In the concept-to-label inference, we apply concept\nregression to select essential concepts from the retrieved concepts by sparse\nlinear regression. Through extensive experiments, we confirm that our Z-CBMs\nprovide interpretable and intervenable concepts without any additional\ntraining. Code will be available at https://github.com/yshinya6/zcbm.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "14 pages, 8 figures",
    "pdf_url": "http://arxiv.org/pdf/2502.09018v1",
    "published_date": "2025-02-13 07:11:07 UTC",
    "updated_date": "2025-02-13 07:11:07 UTC"
  },
  {
    "arxiv_id": "2502.09003v2",
    "title": "RoSTE: An Efficient Quantization-Aware Supervised Fine-Tuning Approach for Large Language Models",
    "authors": [
      "Quan Wei",
      "Chung-Yiu Yau",
      "Hoi-To Wai",
      "Yang Katie Zhao",
      "Dongyeop Kang",
      "Youngsuk Park",
      "Mingyi Hong"
    ],
    "abstract": "Supervised fine-tuning is a standard method for adapting pre-trained large\nlanguage models (LLMs) to downstream tasks. Quantization has been recently\nstudied as a post-training technique for efficient LLM deployment. To obtain\nquantized fine-tuned LLMs, conventional pipelines would first fine-tune the\npre-trained models, followed by post-training quantization. This often yields\nsuboptimal performance as it fails to leverage the synergy between fine-tuning\nand quantization. To effectively realize low-bit quantization of weights,\nactivations, and KV caches in LLMs, we propose an algorithm named Rotated\nStraight-Through-Estimator (RoSTE), which combines quantization-aware\nsupervised fine-tuning (QA-SFT) with an adaptive rotation strategy that\nidentifies an effective rotation configuration to reduce activation outliers.\nWe provide theoretical insights on RoSTE by analyzing its prediction error when\napplied to an overparameterized least square quantized training problem. Our\nfindings reveal that the prediction error is directly proportional to the\nquantization error of the converged weights, which can be effectively managed\nthrough an optimized rotation configuration. Experiments on Pythia, Qwen and\nLlama models of different sizes demonstrate the effectiveness of RoSTE.\nCompared to existing post-SFT quantization baselines, our method consistently\nachieves superior performances across various tasks and different LLM\narchitectures.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "20 pages, 7 figures",
    "pdf_url": "http://arxiv.org/pdf/2502.09003v2",
    "published_date": "2025-02-13 06:44:33 UTC",
    "updated_date": "2025-03-21 19:26:12 UTC"
  },
  {
    "arxiv_id": "2502.09674v2",
    "title": "The Hidden Dimensions of LLM Alignment: A Multi-Dimensional Safety Analysis",
    "authors": [
      "Wenbo Pan",
      "Zhichao Liu",
      "Qiguang Chen",
      "Xiangyang Zhou",
      "Haining Yu",
      "Xiaohua Jia"
    ],
    "abstract": "Large Language Models' safety-aligned behaviors, such as refusing harmful\nqueries, can be represented by linear directions in activation space. Previous\nresearch modeled safety behavior with a single direction, limiting mechanistic\nunderstanding to an isolated safety feature. In this work, we discover that\nsafety-aligned behavior is jointly controlled by multi-dimensional directions.\nNamely, we study the vector space of representation shifts during safety\nfine-tuning on Llama 3 8B for refusing jailbreaks. By studying orthogonal\ndirections in the space, we first find that a dominant direction governs the\nmodel's refusal behavior, while multiple smaller directions represent distinct\nand interpretable features like hypothetical narrative and role-playing. We\nthen measure how different directions promote or suppress the dominant\ndirection, showing the important role of secondary directions in shaping the\nmodel's refusal representation. Finally, we demonstrate that removing certain\ntrigger tokens in harmful queries can mitigate these directions to bypass the\nlearned safety capability, providing new insights on understanding safety\nalignment vulnerability from a multi-dimensional perspective. Code and\nartifacts are available at https://github.com/BMPixel/safety-residual-space.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Code and artifacts: https://github.com/BMPixel/safety-residual-space",
    "pdf_url": "http://arxiv.org/pdf/2502.09674v2",
    "published_date": "2025-02-13 06:39:22 UTC",
    "updated_date": "2025-02-18 03:24:45 UTC"
  },
  {
    "arxiv_id": "2502.09673v2",
    "title": "Are Smarter LLMs Safer? Exploring Safety-Reasoning Trade-offs in Prompting and Fine-Tuning",
    "authors": [
      "Ang Li",
      "Yichuan Mo",
      "Mingjie Li",
      "Yifei Wang",
      "Yisen Wang"
    ],
    "abstract": "Large Language Models (LLMs) have demonstrated remarkable success across\nvarious NLP benchmarks. However, excelling in complex tasks that require\nnuanced reasoning and precise decision-making demands more than raw language\nproficiency--LLMs must reason, i.e., think logically, draw from past\nexperiences, and synthesize information to reach conclusions and take action.\nTo enhance reasoning abilities, approaches such as prompting and fine-tuning\nhave been widely explored. While these methods have led to clear improvements\nin reasoning, their impact on LLM safety remains less understood. In this work,\nwe investigate the interplay between reasoning and safety in LLMs. We highlight\nthe latent safety risks that arise as reasoning capabilities improve, shedding\nlight on previously overlooked vulnerabilities. At the same time, we explore\nhow reasoning itself can be leveraged to enhance safety, uncovering potential\nmitigation strategies. By examining both the risks and opportunities in\nreasoning-driven LLM safety, our study provides valuable insights for\ndeveloping models that are not only more capable but also more trustworthy in\nreal-world deployments.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.09673v2",
    "published_date": "2025-02-13 06:37:28 UTC",
    "updated_date": "2025-02-21 03:12:17 UTC"
  },
  {
    "arxiv_id": "2502.08995v1",
    "title": "PixLift: Accelerating Web Browsing via AI Upscaling",
    "authors": [
      "Yonas Atinafu",
      "Sarthak Malla",
      "HyunSeok Daniel Jang",
      "Nouar Aldahoul",
      "Matteo Varvello",
      "Yasir Zaki"
    ],
    "abstract": "Accessing the internet in regions with expensive data plans and limited\nconnectivity poses significant challenges, restricting information access and\neconomic growth. Images, as a major contributor to webpage sizes, exacerbate\nthis issue, despite advances in compression formats like WebP and AVIF. The\ncontinued growth of complex and curated web content, coupled with suboptimal\noptimization practices in many regions, has prevented meaningful reductions in\nweb page sizes. This paper introduces PixLift, a novel solution to reduce\nwebpage sizes by downscaling their images during transmission and leveraging AI\nmodels on user devices to upscale them. By trading computational resources for\nbandwidth, PixLift enables more affordable and inclusive web access. We address\nkey challenges, including the feasibility of scaled image requests on popular\nwebsites, the implementation of PixLift as a browser extension, and its impact\non user experience. Through the analysis of 71.4k webpages, evaluations of\nthree mainstream upscaling models, and a user study, we demonstrate PixLift's\nability to significantly reduce data usage without compromising image quality,\nfostering a more equitable internet.",
    "categories": [
      "cs.PF",
      "cs.AI"
    ],
    "primary_category": "cs.PF",
    "comment": "9 pages, 2 figures",
    "pdf_url": "http://arxiv.org/pdf/2502.08995v1",
    "published_date": "2025-02-13 06:14:59 UTC",
    "updated_date": "2025-02-13 06:14:59 UTC"
  },
  {
    "arxiv_id": "2502.08989v2",
    "title": "RLSA-PFL: Robust Lightweight Secure Aggregation with Model Inconsistency Detection in Privacy-Preserving Federated Learning",
    "authors": [
      "Nazatul H. Sultan",
      "Yan Bo",
      "Yansong Gao",
      "Seyit Camtepe",
      "Arash Mahboubi",
      "Hang Thanh Bui",
      "Aufeef Chauhan",
      "Hamed Aboutorab",
      "Michael Bewong",
      "Dineshkumar Singh",
      "Praveen Gauravaram",
      "Rafiqul Islam",
      "Sharif Abuadbba"
    ],
    "abstract": "Federated Learning (FL) allows users to collaboratively train a global\nmachine learning model by sharing local model only, without exposing their\nprivate data to a central server. This distributed learning is particularly\nappealing in scenarios where data privacy is crucial, and it has garnered\nsubstantial attention from both industry and academia. However, studies have\nrevealed privacy vulnerabilities in FL, where adversaries can potentially infer\nsensitive information from the shared model parameters. In this paper, we\npresent an efficient masking-based secure aggregation scheme utilizing\nlightweight cryptographic primitives to mitigate privacy risks. Our scheme\noffers several advantages over existing methods. First, it requires only a\nsingle setup phase for the entire FL training session, significantly reducing\ncommunication overhead. Second, it minimizes user-side overhead by eliminating\nthe need for user-to-user interactions, utilizing an intermediate server layer\nand a lightweight key negotiation method. Third, the scheme is highly resilient\nto user dropouts, and the users can join at any FL round. Fourth, it can detect\nand defend against malicious server activities, including recently discovered\nmodel inconsistency attacks. Finally, our scheme ensures security in both\nsemi-honest and malicious settings. We provide security analysis to formally\nprove the robustness of our approach. Furthermore, we implemented an end-to-end\nprototype of our scheme. We conducted comprehensive experiments and\ncomparisons, which show that it outperforms existing solutions in terms of\ncommunication and computation overhead, functionality, and security.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "68P27",
      "E.3"
    ],
    "primary_category": "cs.CR",
    "comment": "16 pages, 10 Figures",
    "pdf_url": "http://arxiv.org/pdf/2502.08989v2",
    "published_date": "2025-02-13 06:01:09 UTC",
    "updated_date": "2025-04-16 11:52:45 UTC"
  },
  {
    "arxiv_id": "2502.08987v2",
    "title": "Neural Force Field: Learning Generalized Physical Representation from a Few Examples",
    "authors": [
      "Shiqian Li",
      "Ruihong Shen",
      "Chi Zhang",
      "Yixin Zhu"
    ],
    "abstract": "Physical reasoning is a remarkable human ability that enables rapid learning\nand generalization from limited experience. Current AI models, despite\nextensive training, still struggle to achieve similar generalization,\nespecially in Out-of-distribution (OOD) settings. This limitation stems from\ntheir inability to abstract core physical principles from observations. A key\nchallenge is developing representations that can efficiently learn and\ngeneralize physical dynamics from minimal data. Here we present Neural Force\nField (NFF) a modeling framework built on Neural Ordinary Differential Equation\n(NODE) that learns interpretable force field representations which can be\nefficiently integrated through an Ordinary Differential Equation ( ODE) solver\nto predict object trajectories. Unlike existing approaches that rely on\nhigh-dimensional latent spaces, NFF captures fundamental physical concepts such\nas gravity, support, and collision in an interpretable manner. Experiments on\ntwo challenging physical reasoning tasks demonstrate that NFF, trained with\nonly a few examples, achieves strong generalization to unseen scenarios. This\nphysics-grounded representation enables efficient forward-backward planning and\nrapid adaptation through interactive refinement. Our work suggests that\nincorporating physics-inspired representations into learning systems can help\nbridge the gap between artificial and human physical reasoning capabilities.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "20 pages",
    "pdf_url": "http://arxiv.org/pdf/2502.08987v2",
    "published_date": "2025-02-13 05:50:13 UTC",
    "updated_date": "2025-02-14 06:29:09 UTC"
  },
  {
    "arxiv_id": "2502.08985v1",
    "title": "Few is More: Task-Efficient Skill-Discovery for Multi-Task Offline Multi-Agent Reinforcement Learning",
    "authors": [
      "Xun Wang",
      "Zhuoran Li",
      "Hai Zhong",
      "Longbo Huang"
    ],
    "abstract": "As a data-driven approach, offline MARL learns superior policies solely from\noffline datasets, ideal for domains rich in historical data but with high\ninteraction costs and risks. However, most existing methods are task-specific,\nrequiring retraining for new tasks, leading to redundancy and inefficiency. To\naddress this issue, in this paper, we propose a task-efficient multi-task\noffline MARL algorithm, Skill-Discovery Conservative Q-Learning (SD-CQL).\nUnlike existing offline skill-discovery methods, SD-CQL discovers skills by\nreconstructing the next observation. It then evaluates fixed and variable\nactions separately and employs behavior-regularized conservative Q-learning to\nexecute the optimal action for each skill. This approach eliminates the need\nfor local-global alignment and enables strong multi-task generalization from\nlimited small-scale source tasks. Substantial experiments on StarCraftII\ndemonstrates the superior generalization performance and task-efficiency of\nSD-CQL. It achieves the best performance on $\\textbf{10}$ out of $14$ task\nsets, with up to $\\textbf{65%}$ improvement on individual task sets, and is\nwithin $4\\%$ of the best baseline on the remaining four.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.MA"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.08985v1",
    "published_date": "2025-02-13 05:47:57 UTC",
    "updated_date": "2025-02-13 05:47:57 UTC"
  },
  {
    "arxiv_id": "2502.08972v3",
    "title": "Tuning-Free Personalized Alignment via Trial-Error-Explain In-Context Learning",
    "authors": [
      "Hyundong Cho",
      "Karishma Sharma",
      "Nicolaas Jedema",
      "Leonardo F. R. Ribeiro",
      "Alessandro Moschitti",
      "Ravi Krishnan",
      "Jonathan May"
    ],
    "abstract": "Language models are aligned to the collective voice of many, resulting in\ngeneric outputs that do not align with specific users' styles. In this work, we\npresent Trial-Error-Explain In-Context Learning (TICL), a tuning-free method\nthat personalizes language models for text generation tasks with fewer than 10\nexamples per user. TICL iteratively expands an in-context learning prompt via a\ntrial-error-explain process, adding model-generated negative samples and\nexplanations that provide fine-grained guidance towards a specific user's\nstyle. TICL achieves favorable win rates on pairwise comparisons with\nLLM-as-a-judge up to 91.5% against the previous state-of-the-art and\noutperforms competitive tuning-free baselines for personalized alignment tasks\nof writing emails, essays and news articles. Both lexical and qualitative\nanalyses show that the negative samples and explanations enable language models\nto learn stylistic context more effectively and overcome the bias towards\nstructural and formal phrases observed in their zero-shot outputs. By\nfront-loading inference compute to create a user-specific in-context learning\nprompt that does not require extra generation steps at test time, TICL presents\na novel yet simple approach for personalized alignment.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "NAACL 2025 Findings",
    "pdf_url": "http://arxiv.org/pdf/2502.08972v3",
    "published_date": "2025-02-13 05:20:21 UTC",
    "updated_date": "2025-04-05 11:57:48 UTC"
  },
  {
    "arxiv_id": "2502.08969v1",
    "title": "SkyRover: A Modular Simulator for Cross-Domain Pathfinding",
    "authors": [
      "Wenhui Ma",
      "Wenhao Li",
      "Bo Jin",
      "Changhong Lu",
      "Xiangfeng Wang"
    ],
    "abstract": "Unmanned Aerial Vehicles (UAVs) and Automated Guided Vehicles (AGVs)\nincreasingly collaborate in logistics, surveillance, inspection tasks and etc.\nHowever, existing simulators often focus on a single domain, limiting\ncross-domain study. This paper presents the SkyRover, a modular simulator for\nUAV-AGV multi-agent pathfinding (MAPF). SkyRover supports realistic agent\ndynamics, configurable 3D environments, and convenient APIs for external\nsolvers and learning methods. By unifying ground and aerial operations, it\nfacilitates cross-domain algorithm design, testing, and benchmarking.\nExperiments highlight SkyRover's capacity for efficient pathfinding and\nhigh-fidelity simulations in UAV-AGV coordination. Project is available at\nhttps://sites.google.com/view/mapf3d/home.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG",
      "cs.MA"
    ],
    "primary_category": "cs.RO",
    "comment": "9 pages",
    "pdf_url": "http://arxiv.org/pdf/2502.08969v1",
    "published_date": "2025-02-13 05:13:21 UTC",
    "updated_date": "2025-02-13 05:13:21 UTC"
  },
  {
    "arxiv_id": "2502.08966v2",
    "title": "RTBAS: Defending LLM Agents Against Prompt Injection and Privacy Leakage",
    "authors": [
      "Peter Yong Zhong",
      "Siyuan Chen",
      "Ruiqi Wang",
      "McKenna McCall",
      "Ben L. Titzer",
      "Heather Miller",
      "Phillip B. Gibbons"
    ],
    "abstract": "Tool-Based Agent Systems (TBAS) allow Language Models (LMs) to use external\ntools for tasks beyond their standalone capabilities, such as searching\nwebsites, booking flights, or making financial transactions. However, these\ntools greatly increase the risks of prompt injection attacks, where malicious\ncontent hijacks the LM agent to leak confidential data or trigger harmful\nactions. Existing defenses (OpenAI GPTs) require user confirmation before every\ntool call, placing onerous burdens on users. We introduce Robust TBAS (RTBAS),\nwhich automatically detects and executes tool calls that preserve integrity and\nconfidentiality, requiring user confirmation only when these safeguards cannot\nbe ensured. RTBAS adapts Information Flow Control to the unique challenges\npresented by TBAS. We present two novel dependency screeners, using\nLM-as-a-judge and attention-based saliency, to overcome these challenges.\nExperimental results on the AgentDojo Prompt Injection benchmark show RTBAS\nprevents all targeted attacks with only a 2% loss of task utility when under\nattack, and further tests confirm its ability to obtain near-oracle performance\non detecting both subtle and direct privacy leaks.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.08966v2",
    "published_date": "2025-02-13 05:06:22 UTC",
    "updated_date": "2025-02-14 04:16:40 UTC"
  },
  {
    "arxiv_id": "2502.08958v1",
    "title": "Biologically Plausible Brain Graph Transformer",
    "authors": [
      "Ciyuan Peng",
      "Yuelong Huang",
      "Qichao Dong",
      "Shuo Yu",
      "Feng Xia",
      "Chengqi Zhang",
      "Yaochu Jin"
    ],
    "abstract": "State-of-the-art brain graph analysis methods fail to fully encode the\nsmall-world architecture of brain graphs (accompanied by the presence of hubs\nand functional modules), and therefore lack biological plausibility to some\nextent. This limitation hinders their ability to accurately represent the\nbrain's structural and functional properties, thereby restricting the\neffectiveness of machine learning models in tasks such as brain disorder\ndetection. In this work, we propose a novel Biologically Plausible Brain Graph\nTransformer (BioBGT) that encodes the small-world architecture inherent in\nbrain graphs. Specifically, we present a network entanglement-based node\nimportance encoding technique that captures the structural importance of nodes\nin global information propagation during brain graph communication,\nhighlighting the biological properties of the brain structure. Furthermore, we\nintroduce a functional module-aware self-attention to preserve the functional\nsegregation and integration characteristics of brain graphs in the learned\nrepresentations. Experimental results on three benchmark datasets demonstrate\nthat BioBGT outperforms state-of-the-art models, enhancing biologically\nplausible brain graph representations for various brain graph analytical tasks",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "27pages, 16figures, published as a conference paper at ICLR 2025",
    "pdf_url": "http://arxiv.org/pdf/2502.08958v1",
    "published_date": "2025-02-13 04:51:18 UTC",
    "updated_date": "2025-02-13 04:51:18 UTC"
  },
  {
    "arxiv_id": "2502.20408v1",
    "title": "Brain-Inspired Exploration of Functional Networks and Key Neurons in Large Language Models",
    "authors": [
      "Yiheng Liu",
      "Xiaohui Gao",
      "Haiyang Sun",
      "Bao Ge",
      "Tianming Liu",
      "Junwei Han",
      "Xintao Hu"
    ],
    "abstract": "In recent years, the rapid advancement of large language models (LLMs) in\nnatural language processing has sparked significant interest among researchers\nto understand their mechanisms and functional characteristics. Although\nexisting studies have attempted to explain LLM functionalities by identifying\nand interpreting specific neurons, these efforts mostly focus on individual\nneuron contributions, neglecting the fact that human brain functions are\nrealized through intricate interaction networks. Inspired by cognitive\nneuroscience research on functional brain networks (FBNs), this study\nintroduces a novel approach to investigate whether similar functional networks\nexist within LLMs. We use methods similar to those in the field of functional\nneuroimaging analysis to locate and identify functional networks in LLM.\nExperimental results show that, similar to the human brain, LLMs contain\nfunctional networks that frequently recur during operation. Further analysis\nshows that these functional networks are crucial for LLM performance. Masking\nkey functional networks significantly impairs the model's performance, while\nretaining just a subset of these networks is adequate to maintain effective\noperation. This research provides novel insights into the interpretation of\nLLMs and the lightweighting of LLMs for certain downstream tasks. Code is\navailable at https://github.com/WhatAboutMyStar/LLM_ACTIVATION.",
    "categories": [
      "q-bio.NC",
      "cs.AI",
      "cs.CL",
      "cs.LG",
      "I.2.0"
    ],
    "primary_category": "q-bio.NC",
    "comment": "13 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2502.20408v1",
    "published_date": "2025-02-13 04:42:39 UTC",
    "updated_date": "2025-02-13 04:42:39 UTC"
  },
  {
    "arxiv_id": "2503.11660v1",
    "title": "A 28 nm AI microcontroller with tightly coupled zero-standby power weight memory featuring standard logic compatible 4 Mb 4-bits/cell embedded flash technology",
    "authors": [
      "Daewung Kim",
      "Seong Hwan Jeon",
      "Young Hee Jeon",
      "Kyung-Bae Kwon",
      "Jigon Kim",
      "Yeounghun Choi",
      "Hyunseung Cha",
      "Kitae Kwon",
      "Daesik Park",
      "Jongseuk Lee",
      "Sihwan Kim",
      "Seung-Hwan Song"
    ],
    "abstract": "This study introduces a novel AI microcontroller optimized for\ncost-effective, battery-powered edge AI applications. Unlike traditional single\nbit/cell memory configurations, the proposed microcontroller integrates\nzero-standby power weight memory featuring standard logic compatible\n4-bits/cell embedded flash technology tightly coupled to a Near-Memory\nComputing Unit. This architecture enables efficient and low-power AI\nacceleration. Advanced state mapping and an overstress-free word line (WL)\ndriver circuit extend verify levels, ensuring robust 16 state cell margin. A\nping-pong buffer reduces internal data movement while supporting simultaneous\nmulti-bit processing. The fabricated microcontroller demonstrated high\nreliability, maintaining accuracy after 160 hours of unpowered baking at\n125$^\\circ$C.",
    "categories": [
      "cs.AR",
      "cs.AI"
    ],
    "primary_category": "cs.AR",
    "comment": "6 pages, 8 figures, Accepted as a full paper by the 2025 EDGE AI\n  FOUNDATION Austin",
    "pdf_url": "http://arxiv.org/pdf/2503.11660v1",
    "published_date": "2025-02-13 04:16:34 UTC",
    "updated_date": "2025-02-13 04:16:34 UTC"
  },
  {
    "arxiv_id": "2502.08946v1",
    "title": "The Stochastic Parrot on LLM's Shoulder: A Summative Assessment of Physical Concept Understanding",
    "authors": [
      "Mo Yu",
      "Lemao Liu",
      "Junjie Wu",
      "Tsz Ting Chung",
      "Shunchi Zhang",
      "Jiangnan Li",
      "Dit-Yan Yeung",
      "Jie Zhou"
    ],
    "abstract": "In a systematic way, we investigate a widely asked question: Do LLMs really\nunderstand what they say?, which relates to the more familiar term Stochastic\nParrot. To this end, we propose a summative assessment over a carefully\ndesigned physical concept understanding task, PhysiCo. Our task alleviates the\nmemorization issue via the usage of grid-format inputs that abstractly describe\nphysical phenomena. The grids represents varying levels of understanding, from\nthe core phenomenon, application examples to analogies to other abstract\npatterns in the grid world. A comprehensive study on our task demonstrates: (1)\nstate-of-the-art LLMs, including GPT-4o, o1 and Gemini 2.0 flash thinking, lag\nbehind humans by ~40%; (2) the stochastic parrot phenomenon is present in LLMs,\nas they fail on our grid task but can describe and recognize the same concepts\nwell in natural language; (3) our task challenges the LLMs due to intrinsic\ndifficulties rather than the unfamiliar grid format, as in-context learning and\nfine-tuning on same formatted data added little to their performance.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "NAACL 2025 Main Conference. First 5 authors contributed equally.\n  Project page: https://physico-benchmark.github.io/",
    "pdf_url": "http://arxiv.org/pdf/2502.08946v1",
    "published_date": "2025-02-13 04:00:03 UTC",
    "updated_date": "2025-02-13 04:00:03 UTC"
  },
  {
    "arxiv_id": "2502.08943v2",
    "title": "Beyond the Singular: The Essential Role of Multiple Generations in Effective Benchmark Evaluation and Analysis",
    "authors": [
      "Wenbo Zhang",
      "Hengrui Cai",
      "Wenyu Chen"
    ],
    "abstract": "Large language models (LLMs) have demonstrated significant utilities in\nreal-world applications, exhibiting impressive capabilities in natural language\nprocessing and understanding. Benchmark evaluations are crucial for assessing\nthe capabilities of LLMs as they can provide a comprehensive assessment of\ntheir strengths and weaknesses. However, current evaluation methods often\noverlook the inherent randomness of LLMs by employing deterministic generation\nstrategies or relying on a single random sample, resulting in unaccounted\nsampling variance and unreliable benchmark score estimates. In this paper, we\npropose a hierarchical statistical model that provides a more comprehensive\nrepresentation of the benchmarking process by incorporating both benchmark\ncharacteristics and LLM randomness. We show that leveraging multiple\ngenerations improves the accuracy of estimating the benchmark score and reduces\nvariance. We also introduce $\\mathbb P\\left(\\text{correct}\\right)$, a\nprompt-level difficulty score based on correct ratios, providing fine-grained\ninsights into individual prompts. Additionally, we create a data map that\nvisualizes difficulty and semantic prompts, enabling error detection and\nquality control in benchmark construction.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "10 pages, 1 table, 4 Figures",
    "pdf_url": "http://arxiv.org/pdf/2502.08943v2",
    "published_date": "2025-02-13 03:43:33 UTC",
    "updated_date": "2025-02-14 06:10:00 UTC"
  },
  {
    "arxiv_id": "2502.08942v1",
    "title": "Language in the Flow of Time: Time-Series-Paired Texts Weaved into a Unified Temporal Narrative",
    "authors": [
      "Zihao Li",
      "Xiao Lin",
      "Zhining Liu",
      "Jiaru Zou",
      "Ziwei Wu",
      "Lecheng Zheng",
      "Dongqi Fu",
      "Yada Zhu",
      "Hendrik Hamann",
      "Hanghang Tong",
      "Jingrui He"
    ],
    "abstract": "While many advances in time series models focus exclusively on numerical\ndata, research on multimodal time series, particularly those involving\ncontextual textual information commonly encountered in real-world scenarios,\nremains in its infancy. Consequently, effectively integrating the text modality\nremains challenging. In this work, we highlight an intuitive yet significant\nobservation that has been overlooked by existing works: time-series-paired\ntexts exhibit periodic properties that closely mirror those of the original\ntime series. Building on this insight, we propose a novel framework, Texts as\nTime Series (TaTS), which considers the time-series-paired texts to be\nauxiliary variables of the time series. TaTS can be plugged into any existing\nnumerical-only time series models and enable them to handle time series data\nwith paired texts effectively. Through extensive experiments on both multimodal\ntime series forecasting and imputation tasks across benchmark datasets with\nvarious existing time series models, we demonstrate that TaTS can enhance\npredictive performance and achieve outperformance without modifying model\narchitectures.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Preprint, 37 pages",
    "pdf_url": "http://arxiv.org/pdf/2502.08942v1",
    "published_date": "2025-02-13 03:43:27 UTC",
    "updated_date": "2025-02-13 03:43:27 UTC"
  },
  {
    "arxiv_id": "2502.08941v2",
    "title": "Analysis of Off-Policy $n$-Step TD-Learning with Linear Function Approximation",
    "authors": [
      "Han-Dong Lim",
      "Donghwan Lee"
    ],
    "abstract": "This paper analyzes multi-step temporal difference (TD)-learning algorithms\nwithin the ``deadly triad'' scenario, characterized by linear function\napproximation, off-policy learning, and bootstrapping. In particular, we prove\nthat $n$-step TD-learning algorithms converge to a solution as the sampling\nhorizon $n$ increases sufficiently. The paper is divided into two parts. In the\nfirst part, we comprehensively examine the fundamental properties of their\nmodel-based deterministic counterparts, including projected value iteration,\ngradient descent algorithms, which can be viewed as prototype deterministic\nalgorithms whose analysis plays a pivotal role in understanding and developing\ntheir model-free reinforcement learning counterparts. In particular, we prove\nthat these algorithms converge to meaningful solutions when $n$ is sufficiently\nlarge. Based on these findings, in the second part, two $n$-step TD-learning\nalgorithms are proposed and analyzed, which can be seen as the model-free\nreinforcement learning counterparts of the model-based deterministic\nalgorithms.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Removed colored text. arXiv admin note: substantial text overlap with\n  arXiv:2402.15781",
    "pdf_url": "http://arxiv.org/pdf/2502.08941v2",
    "published_date": "2025-02-13 03:43:13 UTC",
    "updated_date": "2025-02-14 05:46:10 UTC"
  },
  {
    "arxiv_id": "2502.08939v1",
    "title": "TokenSynth: A Token-based Neural Synthesizer for Instrument Cloning and Text-to-Instrument",
    "authors": [
      "Kyungsu Kim",
      "Junghyun Koo",
      "Sungho Lee",
      "Haesun Joung",
      "Kyogu Lee"
    ],
    "abstract": "Recent advancements in neural audio codecs have enabled the use of tokenized\naudio representations in various audio generation tasks, such as\ntext-to-speech, text-to-audio, and text-to-music generation. Leveraging this\napproach, we propose TokenSynth, a novel neural synthesizer that utilizes a\ndecoder-only transformer to generate desired audio tokens from MIDI tokens and\nCLAP (Contrastive Language-Audio Pretraining) embedding, which has\ntimbre-related information. Our model is capable of performing instrument\ncloning, text-to-instrument synthesis, and text-guided timbre manipulation\nwithout any fine-tuning. This flexibility enables diverse sound design and\nintuitive timbre control. We evaluated the quality of the synthesized audio,\nthe timbral similarity between synthesized and target audio/text, and synthesis\naccuracy (i.e., how accurately it follows the input MIDI) using objective\nmeasures. TokenSynth demonstrates the potential of leveraging advanced neural\naudio codecs and transformers to create powerful and versatile neural\nsynthesizers. The source code, model weights, and audio demos are available at:\nhttps://github.com/KyungsuKim42/tokensynth",
    "categories": [
      "cs.SD",
      "cs.AI"
    ],
    "primary_category": "cs.SD",
    "comment": "5 pages, 1 figure, to be published in ICASSP 2025",
    "pdf_url": "http://arxiv.org/pdf/2502.08939v1",
    "published_date": "2025-02-13 03:40:30 UTC",
    "updated_date": "2025-02-13 03:40:30 UTC"
  },
  {
    "arxiv_id": "2502.08932v1",
    "title": "On the Promise for Assurance of Differentiable Neurosymbolic Reasoning Paradigms",
    "authors": [
      "Luke E. Richards",
      "Jessie Yaros",
      "Jasen Babcock",
      "Coung Ly",
      "Robin Cosbey",
      "Timothy Doster",
      "Cynthia Matuszek"
    ],
    "abstract": "To create usable and deployable Artificial Intelligence (AI) systems, there\nrequires a level of assurance in performance under many different conditions.\nMany times, deployed machine learning systems will require more classic logic\nand reasoning performed through neurosymbolic programs jointly with artificial\nneural network sensing. While many prior works have examined the assurance of a\nsingle component of the system solely with either the neural network alone or\nentire enterprise systems, very few works have examined the assurance of\nintegrated neurosymbolic systems. Within this work, we assess the assurance of\nend-to-end fully differentiable neurosymbolic systems that are an emerging\nmethod to create data-efficient and more interpretable models. We perform this\ninvestigation using Scallop, an end-to-end neurosymbolic library, across\nclassification and reasoning tasks in both the image and audio domains. We\nassess assurance across adversarial robustness, calibration, user performance\nparity, and interpretability of solutions for catching misaligned solutions. We\nfind end-to-end neurosymbolic methods present unique opportunities for\nassurance beyond their data efficiency through our empirical results but not\nacross the board. We find that this class of neurosymbolic models has higher\nassurance in cases where arithmetic operations are defined and where there is\nhigh dimensionality to the input space, where fully neural counterparts\nstruggle to learn robust reasoning operations. We identify the relationship\nbetween neurosymbolic models' interpretability to catch shortcuts that later\nresult in increased adversarial vulnerability despite performance parity.\nFinally, we find that the promise of data efficiency is typically only in the\ncase of class imbalanced reasoning problems.",
    "categories": [
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.08932v1",
    "published_date": "2025-02-13 03:29:42 UTC",
    "updated_date": "2025-02-13 03:29:42 UTC"
  },
  {
    "arxiv_id": "2502.08924v1",
    "title": "Escaping Collapse: The Strength of Weak Data for Large Language Model Training",
    "authors": [
      "Kareem Amin",
      "Sara Babakniya",
      "Alex Bie",
      "Weiwei Kong",
      "Umar Syed",
      "Sergei Vassilvitskii"
    ],
    "abstract": "Synthetically-generated data plays an increasingly larger role in training\nlarge language models. However, while synthetic data has been found to be\nuseful, studies have also shown that without proper curation it can cause LLM\nperformance to plateau, or even \"collapse\", after many training iterations. In\nthis paper, we formalize this question and develop a theoretical framework to\ninvestigate how much curation is needed in order to ensure that LLM performance\ncontinually improves. We find that the requirements are nearly minimal. We\ndescribe a training procedure that converges to an optimal LLM even if almost\nall of the non-synthetic training data is of poor quality. Our analysis is\ninspired by boosting, a classic machine learning technique that leverages a\nvery weak learning algorithm to produce an arbitrarily good classifier. Our\ntraining procedure subsumes many recently proposed methods for training LLMs on\nsynthetic data, and thus our analysis sheds light on why they are successful,\nand also suggests opportunities for future improvement. We present experiments\nthat validate our theory, and show that dynamically focusing labeling resources\non the most challenging examples -- in much the same way that boosting focuses\nthe efforts of the weak learner -- leads to improved performance.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.08924v1",
    "published_date": "2025-02-13 03:20:37 UTC",
    "updated_date": "2025-02-13 03:20:37 UTC"
  },
  {
    "arxiv_id": "2502.08923v1",
    "title": "CopySpec: Accelerating LLMs with Speculative Copy-and-Paste Without Compromising Quality",
    "authors": [
      "Razvan-Gabriel Dumitru",
      "Minglai Yang",
      "Vikas Yadav",
      "Mihai Surdeanu"
    ],
    "abstract": "We introduce CopySpec, an innovative technique designed to tackle the\ninefficiencies LLMs face when generating responses that closely resemble\nprevious outputs. CopySpec identifies repeated sequences in the model's chat\nhistory and speculates that the same tokens will follow, enabling seamless\ncopying without compromising output quality or requiring additional GPU memory.\nTo evaluate the effectiveness of our approach, we conducted experiments using\nfive LLMs and five datasets: MT-Bench, CNN/DM, GSM-8K, HumanEval, and our newly\ncreated dataset, MT-Redundant. MT-Redundant, introduced in this paper,\ntransforms the second turn of MT-Bench into a request for variations of the\nfirst turn's answer, simulating real-world scenarios where users request\nmodifications to prior responses. Our results demonstrate significant\nspeed-ups: up to 2.35x on CNN/DM, 3.08x on the second turn of select\nMT-Redundant categories, and 2.66x on the third turn of GSM-8K's\nself-correction tasks. Moreover, we show that CopySpec integrates seamlessly\nwith speculative decoding, yielding an average 49% additional speed-up over\nspeculative decoding for the second turn of MT-Redundant across all eight\ncategories. While LLMs, even with speculative decoding, suffer from slower\ninference as context sizes grow, CopySpec leverages the expanded context to\naccelerate inference, making it faster as the context size increases. Our code\nand dataset are publicly available at https://github.com/RazvanDu/CopySpec.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG",
      "I.2.7; I.2.0"
    ],
    "primary_category": "cs.CL",
    "comment": "33 pages, 18 figures, 19 tables",
    "pdf_url": "http://arxiv.org/pdf/2502.08923v1",
    "published_date": "2025-02-13 03:19:50 UTC",
    "updated_date": "2025-02-13 03:19:50 UTC"
  },
  {
    "arxiv_id": "2502.08922v1",
    "title": "Self-Consistency of the Internal Reward Models Improves Self-Rewarding Language Models",
    "authors": [
      "Xin Zhou",
      "Yiwen Guo",
      "Ruotian Ma",
      "Tao Gui",
      "Qi Zhang",
      "Xuanjing Huang"
    ],
    "abstract": "Aligning Large Language Models (LLMs) with human preferences is crucial for\ntheir deployment in real-world applications. Recent advancements in\nSelf-Rewarding Language Models suggest that an LLM can use its internal reward\nmodels (such as LLM-as-a-Judge) \\cite{yuanself} to generate preference data,\nimproving alignment performance without costly human annotation. However, we\nfind that different internal reward models within the same LLM often generate\ninconsistent preferences. This inconsistency raises concerns about the\nreliability of self-generated preference data, hinders overall alignment\nperformance, and highlights the need for further research to ensure reliable\nand coherent alignment with human preferences. To address this limitation, we\npropose Self-Consistent Internal Rewards (SCIR), a novel framework designed to\nenhance consistency among internal reward models during training. In each\ntraining step, we collect preference predictions from multiple pre-defined\ninternal reward models and enforce consistency and confidence through an\ninconsistency penalty mechanism, thereby improving the reliability of these\ninternal reward models. We selectively use data with consistent predictions for\npreference optimization, ensuring the quality of the preference data. By\nemploying self-consistent internal rewards, our method significantly improves\nthe alignment performance and reward modeling capability of LLMs, outperforming\nbaseline methods by a notable margin.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.08922v1",
    "published_date": "2025-02-13 03:15:31 UTC",
    "updated_date": "2025-02-13 03:15:31 UTC"
  },
  {
    "arxiv_id": "2502.08920v1",
    "title": "Exploring Emotion-Sensitive LLM-Based Conversational AI",
    "authors": [
      "Antonin Brun",
      "Ruying Liu",
      "Aryan Shukla",
      "Frances Watson",
      "Jonathan Gratch"
    ],
    "abstract": "Conversational AI chatbots have become increasingly common within the\ncustomer service industry. Despite improvements in their emotional development,\nthey often lack the authenticity of real customer service interactions or the\ncompetence of service providers. By comparing emotion-sensitive and\nemotion-insensitive LLM-based chatbots across 30 participants, we aim to\nexplore how emotional sensitivity in chatbots influences perceived competence\nand overall customer satisfaction in service interactions. Additionally, we\nemploy sentiment analysis techniques to analyze and interpret the emotional\ncontent of user inputs. We highlight that perceptions of chatbot\ntrustworthiness and competence were higher in the case of the emotion-sensitive\nchatbot, even if issue resolution rates were not affected. We discuss\nimplications of improved user satisfaction from emotion-sensitive chatbots and\npotential applications in support services.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "7 pages, 2 figures, 1 table",
    "pdf_url": "http://arxiv.org/pdf/2502.08920v1",
    "published_date": "2025-02-13 03:13:38 UTC",
    "updated_date": "2025-02-13 03:13:38 UTC"
  },
  {
    "arxiv_id": "2502.12167v1",
    "title": "TastepepAI, An artificial intelligence platform for taste peptide de novo design",
    "authors": [
      "Jianda Yue",
      "Tingting Li",
      "Jian Ouyang",
      "Jiawei Xu",
      "Hua Tan",
      "Zihui Chen",
      "Changsheng Han",
      "Huanyu Li",
      "Songping Liang",
      "Zhonghua Liu",
      "Zhonghua Liu",
      "Ying Wang"
    ],
    "abstract": "Taste peptides have emerged as promising natural flavoring agents attributed\nto their unique organoleptic properties, high safety profile, and potential\nhealth benefits. However, the de novo identification of taste peptides derived\nfrom animal, plant, or microbial sources remains a time-consuming and\nresource-intensive process, significantly impeding their widespread application\nin the food industry. Here, we present TastePepAI, a comprehensive artificial\nintelligence framework for customized taste peptide design and safety\nassessment. As the key element of this framework, a loss-supervised adaptive\nvariational autoencoder (LA-VAE) is implemented to efficiently optimizes the\nlatent representation of sequences during training and facilitates the\ngeneration of target peptides with desired taste profiles. Notably, our model\nincorporates a novel taste-avoidance mechanism, allowing for selective flavor\nexclusion. Subsequently, our in-house developed toxicity prediction algorithm\n(SpepToxPred) is integrated in the framework to undergo rigorous safety\nevaluation of generated peptides. Using this integrated platform, we\nsuccessfully identified 73 peptides exhibiting sweet, salty, and umami,\nsignificantly expanding the current repertoire of taste peptides. This work\ndemonstrates the potential of TastePepAI in accelerating taste peptide\ndiscovery for food applications and provides a versatile framework adaptable to\nbroader peptide engineering challenges.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "40 pages, 6 figures, research article",
    "pdf_url": "http://arxiv.org/pdf/2502.12167v1",
    "published_date": "2025-02-13 03:09:14 UTC",
    "updated_date": "2025-02-13 03:09:14 UTC"
  },
  {
    "arxiv_id": "2502.08916v1",
    "title": "PathFinder: A Multi-Modal Multi-Agent System for Medical Diagnostic Decision-Making Applied to Histopathology",
    "authors": [
      "Fatemeh Ghezloo",
      "Mehmet Saygin Seyfioglu",
      "Rustin Soraki",
      "Wisdom O. Ikezogwo",
      "Beibin Li",
      "Tejoram Vivekanandan",
      "Joann G. Elmore",
      "Ranjay Krishna",
      "Linda Shapiro"
    ],
    "abstract": "Diagnosing diseases through histopathology whole slide images (WSIs) is\nfundamental in modern pathology but is challenged by the gigapixel scale and\ncomplexity of WSIs. Trained histopathologists overcome this challenge by\nnavigating the WSI, looking for relevant patches, taking notes, and compiling\nthem to produce a final holistic diagnostic. Traditional AI approaches, such as\nmultiple instance learning and transformer-based models, fail short of such a\nholistic, iterative, multi-scale diagnostic procedure, limiting their adoption\nin the real-world. We introduce PathFinder, a multi-modal, multi-agent\nframework that emulates the decision-making process of expert pathologists.\nPathFinder integrates four AI agents, the Triage Agent, Navigation Agent,\nDescription Agent, and Diagnosis Agent, that collaboratively navigate WSIs,\ngather evidence, and provide comprehensive diagnoses with natural language\nexplanations. The Triage Agent classifies the WSI as benign or risky; if risky,\nthe Navigation and Description Agents iteratively focus on significant regions,\ngenerating importance maps and descriptive insights of sampled patches.\nFinally, the Diagnosis Agent synthesizes the findings to determine the\npatient's diagnostic classification. Our Experiments show that PathFinder\noutperforms state-of-the-art methods in skin melanoma diagnosis by 8% while\noffering inherent explainability through natural language descriptions of\ndiagnostically relevant patches. Qualitative analysis by pathologists shows\nthat the Description Agent's outputs are of high quality and comparable to\nGPT-4o. PathFinder is also the first AI-based system to surpass the average\nperformance of pathologists in this challenging melanoma classification task by\n9%, setting a new record for efficient, accurate, and interpretable AI-assisted\ndiagnostics in pathology. Data, code and models available at\nhttps://pathfinder-dx.github.io/",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL",
      "cs.MA"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.08916v1",
    "published_date": "2025-02-13 03:08:02 UTC",
    "updated_date": "2025-02-13 03:08:02 UTC"
  },
  {
    "arxiv_id": "2502.08914v1",
    "title": "Diffusion Models Through a Global Lens: Are They Culturally Inclusive?",
    "authors": [
      "Zahra Bayramli",
      "Ayhan Suleymanzade",
      "Na Min An",
      "Huzama Ahmad",
      "Eunsu Kim",
      "Junyeong Park",
      "James Thorne",
      "Alice Oh"
    ],
    "abstract": "Text-to-image diffusion models have recently enabled the creation of visually\ncompelling, detailed images from textual prompts. However, their ability to\naccurately represent various cultural nuances remains an open question. In our\nwork, we introduce CultDiff benchmark, evaluating state-of-the-art diffusion\nmodels whether they can generate culturally specific images spanning ten\ncountries. We show that these models often fail to generate cultural artifacts\nin architecture, clothing, and food, especially for underrepresented country\nregions, by conducting a fine-grained analysis of different similarity aspects,\nrevealing significant disparities in cultural relevance, description fidelity,\nand realism compared to real-world reference images. With the collected human\nevaluations, we develop a neural-based image-image similarity metric, namely,\nCultDiff-S, to predict human judgment on real and generated images with\ncultural artifacts. Our work highlights the need for more inclusive generative\nAI systems and equitable dataset representation over a wide range of cultures.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "17 pages, 17 figures, 3 tables",
    "pdf_url": "http://arxiv.org/pdf/2502.08914v1",
    "published_date": "2025-02-13 03:05:42 UTC",
    "updated_date": "2025-02-13 03:05:42 UTC"
  },
  {
    "arxiv_id": "2502.08909v1",
    "title": "Towards Automated Fact-Checking of Real-World Claims: Exploring Task Formulation and Assessment with LLMs",
    "authors": [
      "Premtim Sahitaj",
      "Iffat Maab",
      "Junichi Yamagishi",
      "Jawan Kolanowski",
      "Sebastian MÃ¶ller",
      "Vera Schmitt"
    ],
    "abstract": "Fact-checking is necessary to address the increasing volume of\nmisinformation. Traditional fact-checking relies on manual analysis to verify\nclaims, but it is slow and resource-intensive. This study establishes baseline\ncomparisons for Automated Fact-Checking (AFC) using Large Language Models\n(LLMs) across multiple labeling schemes (binary, three-class, five-class) and\nextends traditional claim verification by incorporating analysis, verdict\nclassification, and explanation in a structured setup to provide comprehensive\njustifications for real-world claims. We evaluate Llama-3 models of varying\nsizes (3B, 8B, 70B) on 17,856 claims collected from PolitiFact (2007-2024)\nusing evidence retrieved via restricted web searches. We utilize TIGERScore as\na reference-free evaluation metric to score the justifications. Our results\nshow that larger LLMs consistently outperform smaller LLMs in classification\naccuracy and justification quality without fine-tuning. We find that smaller\nLLMs in a one-shot scenario provide comparable task performance to fine-tuned\nSmall Language Models (SLMs) with large context sizes, while larger LLMs\nconsistently surpass them. Evidence integration improves performance across all\nmodels, with larger LLMs benefiting most. Distinguishing between nuanced labels\nremains challenging, emphasizing the need for further exploration of labeling\nschemes and alignment with evidences. Our findings demonstrate the potential of\nretrieval-augmented AFC with LLMs.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.08909v1",
    "published_date": "2025-02-13 02:51:17 UTC",
    "updated_date": "2025-02-13 02:51:17 UTC"
  },
  {
    "arxiv_id": "2502.08908v1",
    "title": "Reinforced Large Language Model is a formal theorem prover",
    "authors": [
      "Zhiling Luo"
    ],
    "abstract": "To take advantage of Large Language Model in theorem formalization and proof,\nwe propose a reinforcement learning framework to iteratively optimize the\npretrained LLM by rolling out next tactics and comparing them with the expected\nones. The experiment results show that it helps to achieve a higher accuracy\ncompared with directly fine-tuned LLM.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.08908v1",
    "published_date": "2025-02-13 02:49:58 UTC",
    "updated_date": "2025-02-13 02:49:58 UTC"
  },
  {
    "arxiv_id": "2502.08904v3",
    "title": "MIH-TCCT: Mitigating Inconsistent Hallucinations in LLMs via Event-Driven Text-Code Cyclic Training",
    "authors": [
      "Xinxin You",
      "Xien Liu",
      "Qixin Sun",
      "Huan Zhang",
      "Kaiyin Zhou",
      "Shaohui Liu",
      "GuoPing Hu",
      "ShiJin Wang",
      "Si Liu",
      "Ji Wu"
    ],
    "abstract": "Recent methodologies utilizing synthetic datasets have aimed to address\ninconsistent hallucinations in large language models (LLMs); however,these\napproaches are primarily tailored to specific tasks, limiting their\ngeneralizability. Inspired by the strong performance of code-trained models in\nlogic-intensive domains, we propose a novel framework that leverages\nevent-based text to generate corresponding code and employs cyclic training to\ntransfer the logical consistency of code to natural language effectively. Our\nmethod significantly reduces inconsistent hallucinations across three leading\nLLMs and two categories of natural language tasks while maintaining overall\nperformance. This framework effectively alleviates hallucinations without\nnecessitating adaptation to downstream tasks, demonstrating generality and\nproviding new perspectives to tackle the challenge of inconsistent\nhallucinations.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.08904v3",
    "published_date": "2025-02-13 02:40:33 UTC",
    "updated_date": "2025-02-27 01:49:15 UTC"
  },
  {
    "arxiv_id": "2502.08903v1",
    "title": "3D-Grounded Vision-Language Framework for Robotic Task Planning: Automated Prompt Synthesis and Supervised Reasoning",
    "authors": [
      "Guoqin Tang",
      "Qingxuan Jia",
      "Zeyuan Huang",
      "Gang Chen",
      "Ning Ji",
      "Zhipeng Yao"
    ],
    "abstract": "Vision-language models (VLMs) have achieved remarkable success in scene\nunderstanding and perception tasks, enabling robots to plan and execute actions\nadaptively in dynamic environments. However, most multimodal large language\nmodels lack robust 3D scene localization capabilities, limiting their\neffectiveness in fine-grained robotic operations. Additionally, challenges such\nas low recognition accuracy, inefficiency, poor transferability, and\nreliability hinder their use in precision tasks. To address these limitations,\nwe propose a novel framework that integrates a 2D prompt synthesis module by\nmapping 2D images to point clouds, and incorporates a small language model\n(SLM) for supervising VLM outputs. The 2D prompt synthesis module enables VLMs,\ntrained on 2D images and text, to autonomously extract precise 3D spatial\ninformation without manual intervention, significantly enhancing 3D scene\nunderstanding. Meanwhile, the SLM supervises VLM outputs, mitigating\nhallucinations and ensuring reliable, executable robotic control code\ngeneration. Our framework eliminates the need for retraining in new\nenvironments, thereby improving cost efficiency and operational robustness.\nExperimental results that the proposed framework achieved a 96.0\\% Task Success\nRate (TSR), outperforming other methods. Ablation studies demonstrated the\ncritical role of both the 2D prompt synthesis module and the output supervision\nmodule (which, when removed, caused a 67\\% TSR drop). These findings validate\nthe framework's effectiveness in improving 3D recognition, task planning, and\nrobotic task execution.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.08903v1",
    "published_date": "2025-02-13 02:40:19 UTC",
    "updated_date": "2025-02-13 02:40:19 UTC"
  },
  {
    "arxiv_id": "2502.08898v1",
    "title": "Learning in Strategic Queuing Systems with Small Buffers",
    "authors": [
      "Ariana Abel",
      "Yoav Kolumbus",
      "Jeronimo Martin Duque",
      "Eva Tardos"
    ],
    "abstract": "Routers in networking use simple learning algorithms to find the best way to\ndeliver packets to their desired destination. This simple, myopic and\ndistributed decision system makes large queuing systems simple to operate, but\nat the same time, the system needs more capacity than would be required if all\ntraffic were centrally coordinated. In a recent paper, Gaitonde and Tardos (EC\n2020 and JACM 2023) initiate the study of such systems, modeling them as an\ninfinitely repeated game in which routers compete for servers and the system\nmaintains a state (number of packets held by each queue) resulting from\noutcomes of previous rounds. Queues get to send a packet at each step to one of\nthe servers, and servers attempt to process only one of the arriving packets,\nmodeling routers. However, their model assumes that servers have no buffers at\nall, so queues have to resend all packets that were not served successfully.\nThey show that, even with hugely increased server capacity relative to what is\nneeded in the centrally-coordinated case, ensuring that the system is stable\nrequires using timestamps and priority for older packets. We consider a system\nwith two important changes, which make the model more realistic: first we add a\nvery small buffer to each server, allowing it to hold on to a single packet to\nbe served later (even if it fails to serve it); and second, we do not require\ntimestamps or priority for older packets. Our main result is to show that when\nqueues are learning, a small constant factor increase in server capacity,\ncompared to what would be needed if centrally coordinating, suffices to keep\nthe system stable, even if servers select randomly among packets arriving\nsimultaneously. This work contributes to the growing literature on the impact\nof selfish learning in systems with carryover effects between rounds: when\noutcomes in the present round affect the game in the future.",
    "categories": [
      "cs.GT",
      "cs.AI",
      "cs.MA"
    ],
    "primary_category": "cs.GT",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.08898v1",
    "published_date": "2025-02-13 02:23:23 UTC",
    "updated_date": "2025-02-13 02:23:23 UTC"
  },
  {
    "arxiv_id": "2502.08896v1",
    "title": "Communication is All You Need: Persuasion Dataset Construction via Multi-LLM Communication",
    "authors": [
      "Weicheng Ma",
      "Hefan Zhang",
      "Ivory Yang",
      "Shiyu Ji",
      "Joice Chen",
      "Farnoosh Hashemi",
      "Shubham Mohole",
      "Ethan Gearey",
      "Michael Macy",
      "Saeed Hassanpour",
      "Soroush Vosoughi"
    ],
    "abstract": "Large Language Models (LLMs) have shown proficiency in generating persuasive\ndialogue, yet concerns about the fluency and sophistication of their outputs\npersist. This paper presents a multi-LLM communication framework designed to\nenhance the generation of persuasive data automatically. This framework\nfacilitates the efficient production of high-quality, diverse linguistic\ncontent with minimal human oversight. Through extensive evaluations, we\ndemonstrate that the generated data excels in naturalness, linguistic\ndiversity, and the strategic use of persuasion, even in complex scenarios\ninvolving social taboos. The framework also proves adept at generalizing across\nnovel contexts. Our results highlight the framework's potential to\nsignificantly advance research in both computational and social science domains\nconcerning persuasive communication.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted to NAACL 2025 Main Conference",
    "pdf_url": "http://arxiv.org/pdf/2502.08896v1",
    "published_date": "2025-02-13 02:22:48 UTC",
    "updated_date": "2025-02-13 02:22:48 UTC"
  },
  {
    "arxiv_id": "2502.08886v1",
    "title": "Generative AI for Internet of Things Security: Challenges and Opportunities",
    "authors": [
      "Yan Lin Aung",
      "Ivan Christian",
      "Ye Dong",
      "Xiaodong Ye",
      "Sudipta Chattopadhyay",
      "Jianying Zhou"
    ],
    "abstract": "As Generative AI (GenAI) continues to gain prominence and utility across\nvarious sectors, their integration into the realm of Internet of Things (IoT)\nsecurity evolves rapidly. This work delves into an examination of the\nstate-of-the-art literature and practical applications on how GenAI could\nimprove and be applied in the security landscape of IoT. Our investigation aims\nto map the current state of GenAI implementation within IoT security, exploring\ntheir potential to fortify security measures further. Through the compilation,\nsynthesis, and analysis of the latest advancements in GenAI technologies\napplied to IoT, this paper not only introduces fresh insights into the field,\nbut also lays the groundwork for future research directions. It explains the\nprevailing challenges within IoT security, discusses the effectiveness of GenAI\nin addressing these issues, and identifies significant research gaps through\nMITRE Mitigations. Accompanied with three case studies, we provide a\ncomprehensive overview of the progress and future prospects of GenAI\napplications in IoT security. This study serves as a foundational resource to\nimprove IoT security through the innovative application of GenAI, thus\ncontributing to the broader discourse on IoT security and technology\nintegration.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.08886v1",
    "published_date": "2025-02-13 01:55:43 UTC",
    "updated_date": "2025-02-13 01:55:43 UTC"
  },
  {
    "arxiv_id": "2502.08884v1",
    "title": "ShapeLib: designing a library of procedural 3D shape abstractions with Large Language Models",
    "authors": [
      "R. Kenny Jones",
      "Paul Guerrero",
      "Niloy J. Mitra",
      "Daniel Ritchie"
    ],
    "abstract": "Procedural representations are desirable, versatile, and popular shape\nencodings. Authoring them, either manually or using data-driven procedures,\nremains challenging, as a well-designed procedural representation should be\ncompact, intuitive, and easy to manipulate. A long-standing problem in shape\nanalysis studies how to discover a reusable library of procedural functions,\nwith semantically aligned exposed parameters, that can explain an entire shape\nfamily. We present ShapeLib as the first method that leverages the priors of\nfrontier LLMs to design a library of 3D shape abstraction functions. Our system\naccepts two forms of design intent: text descriptions of functions to include\nin the library and a seed set of exemplar shapes. We discover procedural\nabstractions that match this design intent by proposing, and then validating,\nfunction applications and implementations. The discovered shape functions in\nthe library are not only expressive but also generalize beyond the seed set to\na full family of shapes. We train a recognition network that learns to infer\nshape programs based on our library from different visual modalities\n(primitives, voxels, point clouds). Our shape functions have parameters that\nare semantically interpretable and can be modified to produce plausible shape\nvariations. We show that this allows inferred programs to be successfully\nmanipulated by an LLM given a text prompt. We evaluate ShapeLib on different\ndatasets and show clear advantages over existing methods and alternative\nformulations.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.GR"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.08884v1",
    "published_date": "2025-02-13 01:52:02 UTC",
    "updated_date": "2025-02-13 01:52:02 UTC"
  },
  {
    "arxiv_id": "2502.08874v1",
    "title": "Data Sensor Fusion In Digital Twin Technology For Enhanced Capabilities In A Home Environment",
    "authors": [
      "Benjamin Momoh",
      "Salisu Yahaya"
    ],
    "abstract": "This paper investigates the integration of data sensor fusion in digital twin\ntechnology to bolster home environment capabilities, particularly in the\ncontext of challenges brought on by the coronavirus pandemic and its economic\neffects. The study underscores the crucial role of digital transformation in\nnot just adapting to, but also mitigating disruptions during the fourth\nindustrial revolution. Using the Wit Motion sensor, data was collected for\nactivities such as walking, working, sitting, and lying, with sensors measuring\naccelerometers, gyroscopes, and magnetometers. The research integrates\nCyber-physical systems, IoT, AI, and robotics to fortify digital twin\ncapabilities.\n  The paper compares sensor fusion methods, including feature-level fusion,\ndecision-level fusion, and Kalman filter fusion, alongside machine learning\nmodels like SVM, GBoost, and Random Forest to assess model effectiveness.\nResults show that sensor fusion significantly improves the accuracy and\nreliability of these models, as it compensates for individual sensor\nweaknesses, particularly with magnetometers. Despite higher accuracy in ideal\nconditions, integrating data from multiple sensors ensures more consistent and\nreliable results in real-world settings, thereby establishing a robust system\nthat can be confidently applied in practical scenarios.",
    "categories": [
      "cs.AI",
      "cs.LG",
      "eess.SP"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.08874v1",
    "published_date": "2025-02-13 01:14:30 UTC",
    "updated_date": "2025-02-13 01:14:30 UTC"
  },
  {
    "arxiv_id": "2502.08869v1",
    "title": "Harnessing Vision Models for Time Series Analysis: A Survey",
    "authors": [
      "Jingchao Ni",
      "Ziming Zhao",
      "ChengAo Shen",
      "Hanghang Tong",
      "Dongjin Song",
      "Wei Cheng",
      "Dongsheng Luo",
      "Haifeng Chen"
    ],
    "abstract": "Time series analysis has witnessed the inspiring development from traditional\nautoregressive models, deep learning models, to recent Transformers and Large\nLanguage Models (LLMs). Efforts in leveraging vision models for time series\nanalysis have also been made along the way but are less visible to the\ncommunity due to the predominant research on sequence modeling in this domain.\nHowever, the discrepancy between continuous time series and the discrete token\nspace of LLMs, and the challenges in explicitly modeling the correlations of\nvariates in multivariate time series have shifted some research attentions to\nthe equally successful Large Vision Models (LVMs) and Vision Language Models\n(VLMs). To fill the blank in the existing literature, this survey discusses the\nadvantages of vision models over LLMs in time series analysis. It provides a\ncomprehensive and in-depth overview of the existing methods, with dual views of\ndetailed taxonomy that answer the key research questions including how to\nencode time series as images and how to model the imaged time series for\nvarious tasks. Additionally, we address the challenges in the pre- and\npost-processing steps involved in this framework and outline future directions\nto further advance time series analysis with vision models.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.08869v1",
    "published_date": "2025-02-13 00:42:11 UTC",
    "updated_date": "2025-02-13 00:42:11 UTC"
  },
  {
    "arxiv_id": "2502.08864v1",
    "title": "Off-Switching Not Guaranteed",
    "authors": [
      "Sven Neth"
    ],
    "abstract": "Hadfield-Menell et al. (2017) propose the Off-Switch Game, a model of\nHuman-AI cooperation in which AI agents always defer to humans because they are\nuncertain about our preferences. I explain two reasons why AI agents might not\ndefer. First, AI agents might not value learning. Second, even if AI agents\nvalue learning, they might not be certain to learn our actual preferences.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Forthcoming in Philosophical Studies",
    "pdf_url": "http://arxiv.org/pdf/2502.08864v1",
    "published_date": "2025-02-13 00:31:21 UTC",
    "updated_date": "2025-02-13 00:31:21 UTC"
  },
  {
    "arxiv_id": "2502.08859v2",
    "title": "EnigmaEval: A Benchmark of Long Multimodal Reasoning Challenges",
    "authors": [
      "Clinton J. Wang",
      "Dean Lee",
      "Cristina Menghini",
      "Johannes Mols",
      "Jack Doughty",
      "Adam Khoja",
      "Jayson Lynch",
      "Sean Hendryx",
      "Summer Yue",
      "Dan Hendrycks"
    ],
    "abstract": "As language models master existing reasoning benchmarks, we need new\nchallenges to evaluate their cognitive frontiers. Puzzle-solving events are\nrich repositories of challenging multimodal problems that test a wide range of\nadvanced reasoning and knowledge capabilities, making them a unique testbed for\nevaluating frontier language models. We introduce EnigmaEval, a dataset of\nproblems and solutions derived from puzzle competitions and events that probes\nmodels' ability to perform implicit knowledge synthesis and multi-step\ndeductive reasoning. Unlike existing reasoning and knowledge benchmarks, puzzle\nsolving challenges models to discover hidden connections between seemingly\nunrelated pieces of information to uncover solution paths. The benchmark\ncomprises 1184 puzzles of varying complexity -- each typically requiring teams\nof skilled solvers hours to days to complete -- with unambiguous, verifiable\nsolutions that enable efficient evaluation. State-of-the-art language models\nachieve extremely low accuracy on these puzzles, even lower than other\ndifficult benchmarks such as Humanity's Last Exam, unveiling models'\nshortcomings when challenged with problems requiring unstructured and lateral\nreasoning.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.08859v2",
    "published_date": "2025-02-13 00:18:34 UTC",
    "updated_date": "2025-02-14 16:40:15 UTC"
  },
  {
    "arxiv_id": "2502.08858v1",
    "title": "Estimating Probabilities of Causation with Machine Learning Models",
    "authors": [
      "Shuai Wang",
      "Ang Li"
    ],
    "abstract": "Probabilities of causation play a crucial role in modern decision-making.\nThis paper addresses the challenge of predicting probabilities of causation for\nsubpopulations with insufficient data using machine learning models. Tian and\nPearl first defined and derived tight bounds for three fundamental\nprobabilities of causation: the probability of necessity and sufficiency (PNS),\nthe probability of sufficiency (PS), and the probability of necessity (PN).\nHowever, estimating these probabilities requires both experimental and\nobservational distributions specific to each subpopulation, which are often\nunavailable or impractical to obtain with limited population-level data. We\nassume that the probabilities of causation for each subpopulation are\ndetermined by its characteristics. To estimate these probabilities for\nsubpopulations with insufficient data, we propose using machine learning models\nthat draw insights from subpopulations with sufficient data. Our evaluation of\nmultiple machine learning models indicates that, given sufficient\npopulation-level data and an appropriate choice of machine learning model and\nactivation function, PNS can be effectively predicted. Through simulation\nstudies, we show that our multilayer perceptron (MLP) model with the Mish\nactivation function achieves a mean absolute error (MAE) of approximately 0.02\nin predicting PNS for 32,768 subpopulations using data from around 2,000\nsubpopulations.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "8 pages + 2 pages reference + 3 pages supplementary material, 5\n  figures, submitted to UAI 2025",
    "pdf_url": "http://arxiv.org/pdf/2502.08858v1",
    "published_date": "2025-02-13 00:18:08 UTC",
    "updated_date": "2025-02-13 00:18:08 UTC"
  }
]