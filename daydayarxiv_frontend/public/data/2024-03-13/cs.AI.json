{
  "date": "2024-03-13",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-03-13 的 arXiv 中文 TLDR 快报！\n\n今天 arXiv 的更新聚焦于 AI 模型的优化、安全应用和跨领域创新，特别是大型语言模型（LLMs）的增强策略、图像处理和生成模型的进展，以及强化学习在多代理系统的应用。其中，Google 团队发布的 Gemma 模型（论文 31）最为引人注目，它基于 Gemini 技术构建开源高效模型；其他亮点包括 AutoDev 的自动化软件开发框架（论文 85）和各种 LLM 提示工程方法，这些论文展示了 AI 在实际场景中的潜力。\n\n以下是今日主要论文的简要概述，我优先选取了影响力大、话题度高或创新性强的文章（如 LLM 相关和图像生成），并将相关主题归类讨论。其他较常规或理论导向的论文（如一些强化学习或数据处理方法）将快速掠过，只提及关键点。\n\n### LLM 和 AI 应用创新\n- **Gemma: Open Models Based on Gemini Research and Technology（Gemma: 基于 Gemini 研究和技术开源模型）**（论文 31）：Google 团队提出 Gemma 系列轻量级模型，基于 Gemini 技术，在语言理解、推理和安全基准上超越同规模开源模型。贡献包括发布 2B 和 7B 参数的预训练和微调版本，支持高效 AI 部署。\n- **AutoDev: Automated AI-Driven Development（AutoDev: 自动化 AI 驱动开发）**（论文 85）：提出一个自主 AI 代理框架，用于软件工程任务的规划和执行。关键发现是通过 Docker 容器实现安全开发，显著提升代码生成和测试性能，适用于资源受限环境。\n- **Prompting Fairness: Integrating Causality to Debias Large Language Models（Prompting Fairness: 通过因果关系整合消除大型语言模型偏差）**（论文 33）：探索因果提示策略减少 LLM 的社会偏差。贡献在于设计基于因果路径的提示方法，提高模型在多样任务中的公平性，并在多数据集上验证其鲁棒性。\n- **AutoTRIZ: Automating Engineering Innovation with TRIZ and Large Language Models（AutoTRIZ: 使用 TRIZ 和大型语言模型自动化工程创新）**（论文 82）：整合 LLM 和 TRIZ 方法自动化创新过程。发现能生成结构化解决方案，提升产品设计效率，实验在电池热管理系统上证明其实用性。\n- **Language-based game theory in the age of artificial intelligence（基于语言的博弈论在人工智能时代）**（论文 13）：Valerio Capraro 等学者研究语言在决策中的作用。贡献包括使用情感分析解释人类行为，扩展博弈论模型，适用于 AI 辅助决策。\n- 其他 LLM 相关论文（如论文 2、6、11、23、39、40、44、69、99、100、101、106、107、109、111、113、115、116）快速掠过：这些工作主要优化提示工程和反馈机制，例如论文 2 使用 GPT-4 提升编程教育反馈，但整体创新不如上述几篇显著。\n\n### 图像处理和生成模型\n- **GaussianImage: 1000 FPS Image Representation and Compression by 2D Gaussian Splatting（GaussianImage: 使用 2D 高斯散射的 1000 FPS 图像表示和压缩）**（论文 52）：提出高斯散射框架，实现高效图像表示和压缩。发现能在低内存下渲染 1500-2000 FPS，优于传统隐式神经表示方法。\n- **SM4Depth: Seamless Monocular Metric Depth Estimation across Multiple Cameras and Scenes by One Model（SM4Depth: 使用单目度量深度估计的统一模型跨多相机和场景）**（论文 18）：开发一个单模型框架，实现无缝单目深度估计。贡献包括变异深度 bin 和子空间分解，实验在室内外数据集上提升精度。\n- **CAMSIC: Content-aware Masked Image Modeling Transformer for Stereo Image Compression（CAMSIC: 基于内容感知掩码图像建模的立体图像压缩 Transformer）**（论文 55）：引入内容感知掩码技术优化立体图像压缩。发现能捕获空间和视差依赖，提升压缩效率，在 Cityscapes 数据集上达到最优率失真性能。\n- 其他图像论文（如论文 4、5、7、8、9、17、24、28、35、56、58、59、60、62、63、64、65、68、70、71、72、74、75、76、79、80、81、83、84、86、88、89、90、91、92、93、94、95、96、97、98）快速掠过：这些工作涉及深度估计和生成模型优化，但多数为技术改进，如论文 7 的多模态框架，仅在特定任务中表现良好。\n\n### 强化学习和多代理系统\n- **Towards Efficient Risk-Sensitive Policy Gradient: An Iteration Complexity Analysis（高效风险敏感策略梯度：迭代复杂度分析）**（论文 10）：分析风险敏感强化学习算法的迭代复杂度。贡献包括证明 REINFORCE 算法的 O(ε^{-2}) 复杂度，并在实验中验证风险厌恶策略的更快收敛。\n- **Beyond Joint Demonstrations: Personalized Expert Guidance for Efficient Multi-Agent Reinforcement Learning（超越联合演示：用于高效多代理强化学习的个性化专家指导）**（论文 16）：提出 PegMARL 框架，使用个性化演示提升多代理协作。发现能处理异构代理，并在离散和连续环境中超越现有方法。\n- 其他强化学习论文（如论文 19、22、25、27、32、34、36、37、38、41、42、43、45、46、47、48、49、50、51、53、54、57、61、66、67、69、73、77、78、82）快速掠过：这些多为算法分析或应用扩展，如论文 27 的多目标优化，仅在特定场景有效。\n\n### 其他领域快速掠过\n- 医疗和机器人相关（如论文 12、20、26、43、50、51、57、61、66、67、73、77、78、82）：论文 43 的医疗响应框架使用 LLM 生成患者中心化回答，贡献在于多源上下文增强，但整体影响有限。\n- 理论和数据处理（如论文 14、26、39、46、48、49、54、71、73、87、102、105、108、110、112、114）：这些论文多为综述或方法优化，例如论文 14 的最大团问题回顾，仅提供基准分析，无重大突破。\n\n总之，今天的更新强调了 AI 模型的实用性和扩展性，LLM 领域的进展尤为活跃。Gemma 模型和 AutoDev 等工作可能引发更多讨论，值得关注。如果您对特定主题感兴趣，建议查看这些核心论文的完整摘要！",
  "papers": [
    {
      "arxiv_id": "2403.13004v1",
      "title": "(Beyond) Reasonable Doubt: Challenges that Public Defenders Face in Scrutinizing AI in Court",
      "title_zh": "翻译失败",
      "authors": [
        "Angela Jin",
        "Niloufar Salehi"
      ],
      "abstract": "Accountable use of AI systems in high-stakes settings relies on making\nsystems contestable. In this paper we study efforts to contest AI systems in\npractice by studying how public defenders scrutinize AI in court. We present\nfindings from interviews with 17 people in the U.S. public defense community to\nunderstand their perceptions of and experiences scrutinizing computational\nforensic software (CFS) -- automated decision systems that the government uses\nto convict and incarcerate, such as facial recognition, gunshot detection, and\nprobabilistic genotyping tools. We find that our participants faced challenges\nassessing and contesting CFS reliability due to difficulties (a) navigating how\nCFS is developed and used, (b) overcoming judges and jurors' non-critical\nperceptions of CFS, and (c) gathering CFS expertise. To conclude, we provide\nrecommendations that center the technical, social, and institutional context to\nbetter position interventions such as performance evaluations to support\ncontestability in practice.",
      "tldr_zh": "这篇论文探讨了公设辩护人在法庭中审视AI系统（如计算取证软件CFS，包括面部识别、枪声检测和概率基因分型工具）所面临的挑战，通过对17名美国公设辩护社区成员的采访，揭示了他们在评估CFS可靠性时遇到的三大困难：导航CFS的开发和使用、克服法官和陪审员的非批判性态度，以及获取专业知识。研究发现，这些挑战阻碍了AI系统的实际可争辩性。论文最终提供以技术、社会和机构背景为中心的推荐，以支持更有效的AI问责制干预。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.HC",
        "K.4.0"
      ],
      "primary_category": "cs.CY",
      "comment": "29 pages, 4 figures. To appear in Proceedings of the CHI Conference\n  on Human Factors in Computing Systems (CHI '24)",
      "pdf_url": "http://arxiv.org/pdf/2403.13004v1",
      "published_date": "2024-03-13 23:19:46 UTC",
      "updated_date": "2024-03-13 23:19:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:55:54.184014"
    },
    {
      "arxiv_id": "2403.09744v1",
      "title": "Evaluating the Application of Large Language Models to Generate Feedback in Programming Education",
      "title_zh": "翻译失败",
      "authors": [
        "Sven Jacobs",
        "Steffen Jaschke"
      ],
      "abstract": "This study investigates the application of large language models,\nspecifically GPT-4, to enhance programming education. The research outlines the\ndesign of a web application that uses GPT-4 to provide feedback on programming\ntasks, without giving away the solution. A web application for working on\nprogramming tasks was developed for the study and evaluated with 51 students\nover the course of one semester. The results show that most of the feedback\ngenerated by GPT-4 effectively addressed code errors. However, challenges with\nincorrect suggestions and hallucinated issues indicate the need for further\nimprovements.",
      "tldr_zh": "该研究评估了大型语言模型（Large Language Models），特别是GPT-4，在编程教育中的应用，通过设计一个网络应用来提供编程任务反馈，而不直接泄露解决方案。研究开发了该应用，并通过51名学生在一学期内的实际使用进行评估，结果显示GPT-4生成的反馈有效解决了大部分代码错误。然而，存在不正确建议和幻觉问题（如hallucinated issues），表明需要进一步优化以提升其可靠性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY",
        "cs.HC"
      ],
      "primary_category": "cs.CL",
      "comment": "accepted at IEEE Global Engineering Education Conference 2024, Kos,\n  Greece",
      "pdf_url": "http://arxiv.org/pdf/2403.09744v1",
      "published_date": "2024-03-13 23:14:35 UTC",
      "updated_date": "2024-03-13 23:14:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:56:03.518865"
    },
    {
      "arxiv_id": "2403.14689v2",
      "title": "Developing and Deploying Industry Standards for Artificial Intelligence in Education (AIED): Challenges, Strategies, and Future Directions",
      "title_zh": "翻译失败",
      "authors": [
        "Richard Tong",
        "Haoyang Li",
        "Joleen Liang",
        "Qingsong Wen"
      ],
      "abstract": "The adoption of Artificial Intelligence in Education (AIED) holds the promise\nof revolutionizing educational practices by offering personalized learning\nexperiences, automating administrative and pedagogical tasks, and reducing the\ncost of content creation. However, the lack of standardized practices in the\ndevelopment and deployment of AIED solutions has led to fragmented ecosystems,\nwhich presents challenges in interoperability, scalability, and ethical\ngovernance. This article aims to address the critical need to develop and\nimplement industry standards in AIED, offering a comprehensive analysis of the\ncurrent landscape, challenges, and strategic approaches to overcome these\nobstacles. We begin by examining the various applications of AIED in various\neducational settings and identify key areas lacking in standardization,\nincluding system interoperability, ontology mapping, data integration,\nevaluation, and ethical governance. Then, we propose a multi-tiered framework\nfor establishing robust industry standards for AIED. In addition, we discuss\nmethodologies for the iterative development and deployment of standards,\nincorporating feedback loops from real-world applications to refine and adapt\nstandards over time. The paper also highlights the role of emerging\ntechnologies and pedagogical theories in shaping future standards for AIED.\nFinally, we outline a strategic roadmap for stakeholders to implement these\nstandards, fostering a cohesive and ethical AIED ecosystem. By establishing\ncomprehensive industry standards, such as those by IEEE Artificial Intelligence\nStandards Committee (AISC) and International Organization for Standardization\n(ISO), we can accelerate and scale AIED solutions to improve educational\noutcomes, ensuring that technological advances align with the principles of\ninclusivity, fairness, and educational excellence.",
      "tldr_zh": "这篇论文探讨了在教育领域部署人工智能(AIED)时制定行业标准的需求，分析了当前面临的挑战，如系统互操作性、数据集成、评估和伦理治理的碎片化问题。作者提出一个多层框架和迭代开发方法，包括结合反馈循环来完善标准，并强调新兴技术和教学理论的作用。最终，通过战略路线图和机构如IEEE Artificial Intelligence Standards Committee (AISC)及International Organization for Standardization (ISO)的努力，论文旨在推动AIED生态系统的统一与伦理化，提升教育公平性和成果。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CY",
      "comment": "12 pages",
      "pdf_url": "http://arxiv.org/pdf/2403.14689v2",
      "published_date": "2024-03-13 22:38:08 UTC",
      "updated_date": "2024-03-25 04:21:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:56:16.305019"
    },
    {
      "arxiv_id": "2403.08984v1",
      "title": "Safe Road-Crossing by Autonomous Wheelchairs: a Novel Dataset and its Experimental Evaluation",
      "title_zh": "自主轮椅的安全道路穿越：一个新颖的数据集及其实验评估",
      "authors": [
        "Carlo Grigioni",
        "Franca Corradini",
        "Alessandro Antonucci",
        "Jérôme Guzzi",
        "Francesco Flammini"
      ],
      "abstract": "Safe road-crossing by self-driving vehicles is a crucial problem to address\nin smart-cities. In this paper, we introduce a multi-sensor fusion approach to\nsupport road-crossing decisions in a system composed by an autonomous\nwheelchair and a flying drone featuring a robust sensory system made of diverse\nand redundant components. To that aim, we designed an analytical danger\nfunction based on explainable physical conditions evaluated by single sensors,\nincluding those using machine learning and artificial vision. As a\nproof-of-concept, we provide an experimental evaluation in a laboratory\nenvironment, showing the advantages of using multiple sensors, which can\nimprove decision accuracy and effectively support safety assessment. We made\nthe dataset available to the scientific community for further experimentation.\nThe work has been developed in the context of an European project named\nREXASI-PRO, which aims to develop trustworthy artificial intelligence for\nsocial navigation of people with reduced mobility.",
      "tldr_zh": "本文提出了一种多传感器融合方法，支持自主轮椅和飞行无人机在道路交叉口的决策安全评估。研究设计了一个基于可解释物理条件的分析危险函数（analytical danger function），整合机器学习和人工智能视觉（artificial vision）等传感器，以提高决策准确性。实验在实验室环境中进行，结果显示该方法比单一传感器方案提升了29.32%的准确率，并公开了数据集供科学社区进一步实验。该工作是欧洲项目 REXASI-PRO 的成果，旨在为行动不便人士的社交导航开发可信赖的人工智能。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.MA",
        "68T45",
        "I.2.10; C.4; I.2.9; I.4.8"
      ],
      "primary_category": "cs.RO",
      "comment": "14 pages, 8 figures",
      "pdf_url": "http://arxiv.org/pdf/2403.08984v1",
      "published_date": "2024-03-13 22:19:06 UTC",
      "updated_date": "2024-03-13 22:19:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:56:29.197013"
    },
    {
      "arxiv_id": "2403.08974v3",
      "title": "$TrIND$: Representing Anatomical Trees by Denoising Diffusion of Implicit Neural Fields",
      "title_zh": "TrIND：通过隐式神经场的去噪扩散表示解剖树",
      "authors": [
        "Ashish Sinha",
        "Ghassan Hamarneh"
      ],
      "abstract": "Anatomical trees play a central role in clinical diagnosis and treatment\nplanning. However, accurately representing anatomical trees is challenging due\nto their varying and complex topology and geometry. Traditional methods for\nrepresenting tree structures, captured using medical imaging, while invaluable\nfor visualizing vascular and bronchial networks, exhibit drawbacks in terms of\nlimited resolution, flexibility, and efficiency. Recently, implicit neural\nrepresentations (INRs) have emerged as a powerful tool for representing shapes\naccurately and efficiently. We propose a novel approach, $TrIND$, for\nrepresenting anatomical trees using INR, while also capturing the distribution\nof a set of trees via denoising diffusion in the space of INRs. We accurately\ncapture the intricate geometries and topologies of anatomical trees at any\ndesired resolution. Through extensive qualitative and quantitative evaluation,\nwe demonstrate high-fidelity tree reconstruction with arbitrary resolution yet\ncompact storage, and versatility across anatomical sites and tree complexities.\nThe code is available at:\n\\texttt{\\url{https://github.com/sinashish/TreeDiffusion}}.",
      "tldr_zh": "本论文针对解剖树的复杂拓扑和几何表示挑战，提出了一种新方法 $TrIND$，利用隐式神经表示 (INRs) 来精确捕捉树结构，并通过去噪扩散 (denoising diffusion) 在 INRs 空间中捕获多棵树的分布。$TrIND$ 实现了任意分辨率下的高保真重建，同时保持紧凑存储和高效性。实验评估显示，该方法在不同解剖部位和树复杂性上表现出色，提供了一种灵活的工具，支持临床诊断和治疗规划。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted to MICCAI 2024",
      "pdf_url": "http://arxiv.org/pdf/2403.08974v3",
      "published_date": "2024-03-13 21:43:24 UTC",
      "updated_date": "2024-06-18 23:32:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:56:41.882577"
    },
    {
      "arxiv_id": "2403.09743v1",
      "title": "The Human Factor in Detecting Errors of Large Language Models: A Systematic Literature Review and Future Research Directions",
      "title_zh": "大语言模型错误检测中的人类因素：系统文献综述与未来研究方向",
      "authors": [
        "Christian A. Schiller"
      ],
      "abstract": "The launch of ChatGPT by OpenAI in November 2022 marked a pivotal moment for\nArtificial Intelligence, introducing Large Language Models (LLMs) to the\nmainstream and setting new records in user adoption. LLMs, particularly\nChatGPT, trained on extensive internet data, demonstrate remarkable\nconversational capabilities across various domains, suggesting a significant\nimpact on the workforce. However, these models are susceptible to errors -\n\"hallucinations\" and omissions, generating incorrect or incomplete information.\nThis poses risks especially in contexts where accuracy is crucial, such as\nlegal compliance, medicine or fine-grained process frameworks.\n  There are both technical and human solutions to cope with this isse. This\npaper explores the human factors that enable users to detect errors in LLM\noutputs, a critical component in mitigating risks associated with their use in\nprofessional settings. Understanding these factors is essential for\norganizations aiming to leverage LLM technology efficiently, guiding targeted\ntraining and deployment strategies to enhance error detection by users. This\napproach not only aims to optimize the use of LLMs but also to prevent\npotential downstream issues stemming from reliance on inaccurate model\nresponses. The research emphasizes the balance between technological\nadvancement and human insight in maximizing the benefits of LLMs while\nminimizing the risks, particularly in areas where precision is paramount.\n  This paper performs a systematic literature research on this research topic,\nanalyses and synthesizes the findings, and outlines future research directions.\nLiterature selection cut-off date is January 11th 2024.",
      "tldr_zh": "这篇论文探讨了人类因素在检测Large Language Models (LLMs) 错误中的作用，特别是针对LLMs如ChatGPT的hallucinations和omissions问题，这些错误在法律、医学等领域可能带来风险。研究通过系统文献综述（截止2024年1月11日）分析了用户检测LLM输出错误的心理和行为因素，并提出这些因素可指导组织制定针对性训练和部署策略，以优化LLM应用。结果强调了技术进步与人类洞见的平衡，有助于减少依赖不准确模型响应带来的潜在问题。未来研究方向包括进一步探索人类干预机制，以提升LLMs在高精度领域的可靠性和安全性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "21 papers analysed and synthesized in detail from a total search\n  result size of 594 (raw results) / 61 (scanned) / 28 (selected)",
      "pdf_url": "http://arxiv.org/pdf/2403.09743v1",
      "published_date": "2024-03-13 21:39:39 UTC",
      "updated_date": "2024-03-13 21:39:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:56:52.958252"
    },
    {
      "arxiv_id": "2403.08967v2",
      "title": "PathM3: A Multimodal Multi-Task Multiple Instance Learning Framework for Whole Slide Image Classification and Captioning",
      "title_zh": "翻译失败",
      "authors": [
        "Qifeng Zhou",
        "Wenliang Zhong",
        "Yuzhi Guo",
        "Michael Xiao",
        "Hehuan Ma",
        "Junzhou Huang"
      ],
      "abstract": "In the field of computational histopathology, both whole slide images (WSIs)\nand diagnostic captions provide valuable insights for making diagnostic\ndecisions. However, aligning WSIs with diagnostic captions presents a\nsignificant challenge. This difficulty arises from two main factors: 1)\nGigapixel WSIs are unsuitable for direct input into deep learning models, and\nthe redundancy and correlation among the patches demand more attention; and 2)\nAuthentic WSI diagnostic captions are extremely limited, making it difficult to\ntrain an effective model. To overcome these obstacles, we present PathM3, a\nmultimodal, multi-task, multiple instance learning (MIL) framework for WSI\nclassification and captioning. PathM3 adapts a query-based transformer to\neffectively align WSIs with diagnostic captions. Given that histopathology\nvisual patterns are redundantly distributed across WSIs, we aggregate each\npatch feature with MIL method that considers the correlations among instances.\nFurthermore, our PathM3 overcomes data scarcity in WSI-level captions by\nleveraging limited WSI diagnostic caption data in the manner of multi-task\njoint learning. Extensive experiments with improved classification accuracy and\ncaption generation demonstrate the effectiveness of our method on both WSI\nclassification and captioning task.",
      "tldr_zh": "本研究提出PathM3框架，这是一个多模态、多任务、Multiple Instance Learning (MIL)系统，用于Whole Slide Image (WSI)分类和说明生成，以解决WSI输入冗余、补丁相关性和数据稀缺的挑战。PathM3采用基于查询的transformer模型来对齐WSI与诊断说明，并通过MIL方法聚合补丁特征以考虑实例间的相关性，同时利用多任务联合学习从有限的WSI诊断数据中提升模型性能。实验结果显示，该框架显著提高了WSI分类准确性和说明生成质量，证明了其在计算病理学领域的有效性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.08967v2",
      "published_date": "2024-03-13 21:19:12 UTC",
      "updated_date": "2024-07-23 20:14:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:57:04.738857"
    },
    {
      "arxiv_id": "2403.08962v1",
      "title": "Using Deep Learning for Morphological Classification in Pigs with a Focus on Sanitary Monitoring",
      "title_zh": "使用深度学习进行猪只形态分类，重点关注卫生监测",
      "authors": [
        "Eduardo Bedin",
        "Junior Silva Souza",
        "Gabriel Toshio Hirokawa Higa",
        "Alexandre Pereira",
        "Charles Kiefer",
        "Newton Loebens",
        "Hemerson Pistori"
      ],
      "abstract": "The aim of this paper is to evaluate the use of D-CNN (Deep Convolutional\nNeural Networks) algorithms to classify pig body conditions in normal or not\nnormal conditions, with a focus on characteristics that are observed in\nsanitary monitoring, and were used six different algorithms to do this task.\nThe study focused on five pig characteristics, being these caudophagy, ear\nhematoma, scratches on the body, redness, and natural stains (brown or black).\nThe results of the study showed that D-CNN was effective in classifying\ndeviations in pig body morphologies related to skin characteristics. The\nevaluation was conducted by analyzing the performance metrics Precision,\nRecall, and F-score, as well as the statistical analyses ANOVA and the\nScott-Knott test. The contribution of this article is characterized by the\nproposal of using D-CNN networks for morphological classification in pigs, with\na focus on characteristics identified in sanitary monitoring. Among the best\nresults, the average Precision metric of 80.6\\% to classify caudophagy was\nachieved for the InceptionResNetV2 network, indicating the potential use of\nthis technology for the proposed task. Additionally, a new image database was\ncreated, containing various pig's distinct body characteristics, which can\nserve as data for future research.",
      "tldr_zh": "这篇论文评估了 D-CNN（Deep Convolutional Neural Networks）算法用于分类猪身体状况（正常或不正常）的效果，重点关注卫生监测中的特征，包括 caudophagy、ear hematoma、scratches on the body、redness 和 natural stains。研究采用了六种不同算法进行分类，并通过 Precision、Recall、F-score 指标以及 ANOVA 和 Scott-Knott test 统计分析，证明 D-CNN 在识别皮肤相关形态偏差方面有效，其中 InceptionResNetV2 网络在 caudophagy 分类上达到了 80.6% 的平均 Precision。该工作的主要贡献是提出 D-CNN 用于猪形态分类的应用，并创建了一个新的猪图像数据库，以支持未来研究。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.08962v1",
      "published_date": "2024-03-13 21:05:34 UTC",
      "updated_date": "2024-03-13 21:05:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:57:18.721557"
    },
    {
      "arxiv_id": "2403.08956v1",
      "title": "AI coach for badminton",
      "title_zh": "AI 羽毛球教练",
      "authors": [
        "Dhruv Toshniwal",
        "Arpit Patil",
        "Nancy Vachhani"
      ],
      "abstract": "In the competitive realm of sports, optimal performance necessitates rigorous\nmanagement of nutrition and physical conditioning. Specifically, in badminton,\nthe agility and precision required make it an ideal candidate for motion\nanalysis through video analytics. This study leverages advanced neural network\nmethodologies to dissect video footage of badminton matches, aiming to extract\ndetailed insights into player kinetics and biomechanics. Through the analysis\nof stroke mechanics, including hand-hip coordination, leg positioning, and the\nexecution angles of strokes, the research aims to derive predictive models that\ncan suggest improvements in stance, technique, and muscle orientation. These\nrecommendations are designed to mitigate erroneous techniques, reduce the risk\nof joint fatigue, and enhance overall performance. Utilizing a vast array of\ndata available online, this research correlates players' physical attributes\nwith their in-game movements to identify muscle activation patterns during\nplay. The goal is to offer personalized training and nutrition strategies that\nalign with the specific biomechanical demands of badminton, thereby\nfacilitating targeted performance enhancements.",
      "tldr_zh": "这项研究开发了一种AI教练系统，针对羽毛球运动，通过视频分析和高级neural network技术提取球员的运动学和生物力学洞见。系统重点分析击球力学，包括hand-hip coordination、腿部位置和击球角度，构建预测模型以提供个性化建议，帮助改善姿势、技术和肌肉方向。最终目标是通过这些推荐减少错误技术、降低关节疲劳风险，并优化训练和营养策略，以提升球员整体表现。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "7 pages, 11 figures. https://ieeexplore.ieee.org/document/9825164",
      "pdf_url": "http://arxiv.org/pdf/2403.08956v1",
      "published_date": "2024-03-13 20:51:21 UTC",
      "updated_date": "2024-03-13 20:51:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:57:29.167166"
    },
    {
      "arxiv_id": "2403.08955v3",
      "title": "Towards Efficient Risk-Sensitive Policy Gradient: An Iteration Complexity Analysis",
      "title_zh": "翻译失败",
      "authors": [
        "Rui Liu",
        "Anish Gupta",
        "Erfaun Noorani",
        "Pratap Tokekar"
      ],
      "abstract": "Reinforcement Learning (RL) has shown exceptional performance across various\napplications, enabling autonomous agents to learn optimal policies through\ninteraction with their environments. However, traditional RL frameworks often\nface challenges in terms of iteration efficiency and robustness. Risk-sensitive\npolicy gradient methods, which incorporate both expected return and risk\nmeasures, have been explored for their ability to yield more robust policies,\nyet their iteration complexity remains largely underexplored. In this work, we\nconduct a rigorous iteration complexity analysis for the risk-sensitive policy\ngradient method, focusing on the REINFORCE algorithm with an exponential\nutility function. We establish an iteration complexity of\n$\\mathcal{O}(\\epsilon^{-2})$ to reach an $\\epsilon$-approximate first-order\nstationary point (FOSP). Furthermore, we investigate whether risk-sensitive\nalgorithms can achieve better iteration complexity compared to their\nrisk-neutral counterparts. Our analysis indicates that risk-sensitive REINFORCE\ncan potentially converge faster. To validate our analysis, we empirically\nevaluate the learning performance and convergence efficiency of the\nrisk-neutral and risk-sensitive REINFORCE algorithms in multiple environments:\nCartPole, MiniGrid, and Robot Navigation. Empirical results confirm that\nrisk-averse cases can converge and stabilize faster compared to their\nrisk-neutral counterparts. More details can be found on our website\nhttps://ruiiu.github.io/riskrl.",
      "tldr_zh": "本研究分析了风险敏感策略梯度方法的迭代复杂度，旨在提升强化学习 (RL) 的效率和鲁棒性。作者针对 REINFORCE 算法结合指数效用函数，证明了达到 ε-approximate first-order stationary point (FOSP) 的迭代复杂度为 $\\mathcal{O}(\\epsilon^{-2})$，并发现风险敏感算法可能比风险中性算法收敛更快。通过在 CartPole、MiniGrid 和 Robot Navigation 等环境中进行的实验验证，风险厌恶版本显示出更快的收敛和稳定性，为更可靠的 RL 策略优化提供了理论和实证支持。更多细节可参考论文网站。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "math.OC"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.08955v3",
      "published_date": "2024-03-13 20:50:49 UTC",
      "updated_date": "2025-04-06 03:22:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:57:41.258492"
    },
    {
      "arxiv_id": "2403.08950v1",
      "title": "Exploring Prompt Engineering Practices in the Enterprise",
      "title_zh": "翻译失败",
      "authors": [
        "Michael Desmond",
        "Michelle Brachman"
      ],
      "abstract": "Interaction with Large Language Models (LLMs) is primarily carried out via\nprompting. A prompt is a natural language instruction designed to elicit\ncertain behaviour or output from a model. In theory, natural language prompts\nenable non-experts to interact with and leverage LLMs. However, for complex\ntasks and tasks with specific requirements, prompt design is not trivial.\nCreating effective prompts requires skill and knowledge, as well as significant\niteration in order to determine model behavior, and guide the model to\naccomplish a particular goal. We hypothesize that the way in which users\niterate on their prompts can provide insight into how they think prompting and\nmodels work, as well as the kinds of support needed for more efficient prompt\nengineering. To better understand prompt engineering practices, we analyzed\nsessions of prompt editing behavior, categorizing the parts of prompts users\niterated on and the types of changes they made. We discuss design implications\nand future directions based on these prompt engineering practices.",
      "tldr_zh": "这篇论文探讨了企业在使用大型语言模型(LLMs)时，提示工程(prompt engineering)的实践，强调设计有效提示需要技能、知识和多次迭代，尤其在复杂任务中。作者假设，用户迭代提示的过程能揭示他们对模型行为的认知以及支持需求，并通过分析提示编辑会话、分类迭代的部分和变化类型来进行研究。最终，论文基于这些发现讨论了设计含义和未来方向，以提升提示工程的效率和可用性。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.08950v1",
      "published_date": "2024-03-13 20:32:32 UTC",
      "updated_date": "2024-03-13 20:32:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:57:54.488183"
    },
    {
      "arxiv_id": "2403.12090v1",
      "title": "Foundation Models and Information Retrieval in Digital Pathology",
      "title_zh": "基础模型和信息",
      "authors": [
        "H. R. Tizhoosh"
      ],
      "abstract": "The paper reviews the state-of-the-art of foundation models, LLMs, generative\nAI, information retrieval and CBIR in digital pathology",
      "tldr_zh": "本文综述了Foundation Models、LLMs、Generative AI、Information Retrieval 和 CBIR 在 Digital Pathology 领域的最新进展。论文探讨了这些技术如何应用于数字病理学，包括图像检索和人工智能辅助诊断等方面。通过全面回顾，研究为推动该领域的创新和应用提供了宝贵见解。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CV",
        "cs.LG",
        "eess.IV"
      ],
      "primary_category": "cs.IR",
      "comment": "This is the preprint of a book chapter to appear in \"Artificial\n  Intelligence in Pathology\" by Stanley Cohen and Chhavi Chauhan",
      "pdf_url": "http://arxiv.org/pdf/2403.12090v1",
      "published_date": "2024-03-13 20:28:08 UTC",
      "updated_date": "2024-03-13 20:28:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:58:05.226702"
    },
    {
      "arxiv_id": "2403.08944v1",
      "title": "Language-based game theory in the age of artificial intelligence",
      "title_zh": "人工智能时代中的基于语言的博弈论",
      "authors": [
        "Valerio Capraro",
        "Roberto Di Paolo",
        "Matjaz Perc",
        "Veronica Pizziol"
      ],
      "abstract": "Understanding human behaviour in decision problems and strategic interactions\nhas wide-ranging applications in economics, psychology, and artificial\nintelligence. Game theory offers a robust foundation for this understanding,\nbased on the idea that individuals aim to maximize a utility function. However,\nthe exact factors influencing strategy choices remain elusive. While\ntraditional models try to explain human behaviour as a function of the outcomes\nof available actions, recent experimental research reveals that linguistic\ncontent significantly impacts decision-making, thus prompting a paradigm shift\nfrom outcome-based to language-based utility functions. This shift is more\nurgent than ever, given the advancement of generative AI, which has the\npotential to support humans in making critical decisions through language-based\ninteractions. We propose sentiment analysis as a fundamental tool for this\nshift and take an initial step by analyzing 61 experimental instructions from\nthe dictator game, an economic game capturing the balance between self-interest\nand the interest of others, which is at the core of many social interactions.\nOur meta-analysis shows that sentiment analysis can explain human behaviour\nbeyond economic outcomes. We discuss future research directions. We hope this\nwork sets the stage for a novel game theoretical approach that emphasizes the\nimportance of language in human decisions.",
      "tldr_zh": "该论文探讨了在AI时代，游戏理论如何从基于结果的效用函数转向基于语言的效用函数，以更好地理解语言内容对人类决策的影响。作者提出情感分析(sentiment analysis)作为关键工具，并通过对独裁者游戏(dictator game)的61个实验指令进行元分析(meta-analysis)，发现情感分析能解释人类行为超出经济结果的范围。研究强调生成AI在语言互动中的潜力，并为未来游戏理论研究提供新方向，推动更注重语言的决策模型发展。",
      "categories": [
        "cs.GT",
        "cs.AI",
        "cs.CY",
        "econ.TH"
      ],
      "primary_category": "cs.GT",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.08944v1",
      "published_date": "2024-03-13 20:21:20 UTC",
      "updated_date": "2024-03-13 20:21:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:58:17.634425"
    },
    {
      "arxiv_id": "2403.09742v1",
      "title": "A Short Review on Novel Approaches for Maximum Clique Problem: from Classical algorithms to Graph Neural Networks and Quantum algorithms",
      "title_zh": "最大团问题新颖方法的简短综述：从经典算法到图神经网络和量子算法",
      "authors": [
        "Raffaele Marino",
        "Lorenzo Buffoni",
        "Bogdan Zavalnij"
      ],
      "abstract": "This manuscript provides a comprehensive review of the Maximum Clique\nProblem, a computational problem that involves finding subsets of vertices in a\ngraph that are all pairwise adjacent to each other. The manuscript covers in a\nsimple way classical algorithms for solving the problem and includes a review\nof recent developments in graph neural networks and quantum algorithms. The\nreview concludes with benchmarks for testing classical as well as new learning,\nand quantum algorithms.",
      "tldr_zh": "这篇综述文章简要回顾了Maximum Clique Problem（最大团问题），即在图中找到所有顶点互连的子集问题。文章涵盖了从经典算法到Graph Neural Networks和Quantum algorithms的多种方法，并以简单方式介绍这些算法的最新发展。最后，它提供了基准测试，用于评估传统算法以及新型学习和量子算法的性能。",
      "categories": [
        "cs.AI",
        "cond-mat.dis-nn",
        "cs.DS",
        "cs.LG",
        "math.OC",
        "quant-ph"
      ],
      "primary_category": "cs.AI",
      "comment": "24 pages",
      "pdf_url": "http://arxiv.org/pdf/2403.09742v1",
      "published_date": "2024-03-13 20:12:05 UTC",
      "updated_date": "2024-03-13 20:12:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:58:28.770086"
    },
    {
      "arxiv_id": "2403.08937v2",
      "title": "Bugs in Large Language Models Generated Code: An Empirical Study",
      "title_zh": "大语言模型生成代码中的错误：一项实证研究",
      "authors": [
        "Florian Tambon",
        "Arghavan Moradi Dakhel",
        "Amin Nikanjam",
        "Foutse Khomh",
        "Michel C. Desmarais",
        "Giuliano Antoniol"
      ],
      "abstract": "Large Language Models (LLMs) for code have gained significant attention\nrecently. They can generate code in different programming languages based on\nprovided prompts, fulfilling a long-lasting dream in Software Engineering (SE),\ni.e., automatic code generation. Similar to human-written code, LLM-generated\ncode is prone to bugs, and these bugs have not yet been thoroughly examined by\nthe community. Given the increasing adoption of LLM-based code generation tools\n(e.g., GitHub Copilot) in SE activities, it is critical to understand the\ncharacteristics of bugs contained in code generated by LLMs. This paper\nexamines a sample of 333 bugs collected from code generated using three leading\nLLMs (i.e., CodeGen, PanGu-Coder, and Codex) and identifies the following 10\ndistinctive bug patterns: Misinterpretations, Syntax Error, Silly Mistake,\nPrompt-biased code, Missing Corner Case, Wrong Input Type, Hallucinated Object,\nWrong Attribute, Incomplete Generation, and Non-Prompted Consideration. The bug\npatterns are presented in the form of a taxonomy. The identified bug patterns\nare validated using an online survey with 34 LLM practitioners and researchers.\nThe surveyed participants generally asserted the significance and prevalence of\nthe bug patterns. Researchers and practitioners can leverage these findings to\ndevelop effective quality assurance techniques for LLM-generated code. This\nstudy sheds light on the distinctive characteristics of LLM-generated code.",
      "tldr_zh": "本研究通过实证分析，调查了 Large Language Models (LLMs) 生成代码中的 bug，基于从 CodeGen、PanGu-Coder 和 Codex 等模型中收集的 333 个 bug 样本。研究者识别出 10 种独特 bug 模式，包括 Misinterpretations、Syntax Error、Silly Mistake、Prompt-biased code、Missing Corner Case、Wrong Input Type、Hallucinated Object、Wrong Attribute、Incomplete Generation 和 Non-Prompted Consideration，并以分类法形式呈现。这些 bug 模式经 34 名 LLM 从业者和研究人员的在线调查验证，确认其显著性和普遍性，为开发针对 LLM 生成代码的质量保障技术提供重要指导。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "47 pages, 7 figures",
      "pdf_url": "http://arxiv.org/pdf/2403.08937v2",
      "published_date": "2024-03-13 20:12:01 UTC",
      "updated_date": "2024-03-18 14:34:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:58:43.126091"
    },
    {
      "arxiv_id": "2403.08936v3",
      "title": "Beyond Joint Demonstrations: Personalized Expert Guidance for Efficient Multi-Agent Reinforcement Learning",
      "title_zh": "超越联合演示：个性化的专家指导用于高效的多智能体强化学习",
      "authors": [
        "Peihong Yu",
        "Manav Mishra",
        "Alec Koppel",
        "Carl Busart",
        "Priya Narayan",
        "Dinesh Manocha",
        "Amrit Bedi",
        "Pratap Tokekar"
      ],
      "abstract": "Multi-Agent Reinforcement Learning (MARL) algorithms face the challenge of\nefficient exploration due to the exponential increase in the size of the joint\nstate-action space. While demonstration-guided learning has proven beneficial\nin single-agent settings, its direct applicability to MARL is hindered by the\npractical difficulty of obtaining joint expert demonstrations. In this work, we\nintroduce a novel concept of personalized expert demonstrations, tailored for\neach individual agent or, more broadly, each individual type of agent within a\nheterogeneous team. These demonstrations solely pertain to single-agent\nbehaviors and how each agent can achieve personal goals without encompassing\nany cooperative elements, thus naively imitating them will not achieve\ncooperation due to potential conflicts. To this end, we propose an approach\nthat selectively utilizes personalized expert demonstrations as guidance and\nallows agents to learn to cooperate, namely personalized expert-guided MARL\n(PegMARL). This algorithm utilizes two discriminators: the first provides\nincentives based on the alignment of individual agent behavior with\ndemonstrations, and the second regulates incentives based on whether the\nbehaviors lead to the desired outcome. We evaluate PegMARL using personalized\ndemonstrations in both discrete and continuous environments. The experimental\nresults demonstrate that PegMARL outperforms state-of-the-art MARL algorithms\nin solving coordinated tasks, achieving strong performance even when provided\nwith suboptimal personalized demonstrations. We also showcase PegMARL's\ncapability of leveraging joint demonstrations in the StarCraft scenario and\nconverging effectively even with demonstrations from non-co-trained policies.",
      "tldr_zh": "该论文解决了 Multi-Agent Reinforcement Learning (MARL) 中高效探索的挑战，提出了一种超越联合演示的创新方法：使用个性化专家演示（personalized expert demonstrations），这些演示仅针对单个智能体的行为和个人目标，而非合作元素。作者引入了 PegMARL 算法，该算法采用两个鉴别器——一个基于智能体行为与演示的匹配提供激励，另一个根据行为是否实现期望结果进行调节——来帮助智能体学习合作。实验结果表明，PegMARL 在离散和连续环境中优于现有 MARL 算法，即使使用次优演示也能有效完成协调任务，并在 StarCraft 场景中表现出强健性能。",
      "categories": [
        "cs.MA",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.MA",
      "comment": "accepted in Transactions on Machine Learning Research",
      "pdf_url": "http://arxiv.org/pdf/2403.08936v3",
      "published_date": "2024-03-13 20:11:20 UTC",
      "updated_date": "2025-01-04 03:15:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:58:56.076907"
    },
    {
      "arxiv_id": "2403.08933v1",
      "title": "Unveiling the Truth: Exploring Human Gaze Patterns in Fake Images",
      "title_zh": "揭示真相：探索人类在假图像中的目光模式",
      "authors": [
        "Giuseppe Cartella",
        "Vittorio Cuculo",
        "Marcella Cornia",
        "Rita Cucchiara"
      ],
      "abstract": "Creating high-quality and realistic images is now possible thanks to the\nimpressive advancements in image generation. A description in natural language\nof your desired output is all you need to obtain breathtaking results. However,\nas the use of generative models grows, so do concerns about the propagation of\nmalicious content and misinformation. Consequently, the research community is\nactively working on the development of novel fake detection techniques,\nprimarily focusing on low-level features and possible fingerprints left by\ngenerative models during the image generation process. In a different vein, in\nour work, we leverage human semantic knowledge to investigate the possibility\nof being included in frameworks of fake image detection. To achieve this, we\ncollect a novel dataset of partially manipulated images using diffusion models\nand conduct an eye-tracking experiment to record the eye movements of different\nobservers while viewing real and fake stimuli. A preliminary statistical\nanalysis is conducted to explore the distinctive patterns in how humans\nperceive genuine and altered images. Statistical findings reveal that, when\nperceiving counterfeit samples, humans tend to focus on more confined regions\nof the image, in contrast to the more dispersed observational pattern observed\nwhen viewing genuine images. Our dataset is publicly available at:\nhttps://github.com/aimagelab/unveiling-the-truth.",
      "tldr_zh": "这篇论文探讨了人类在查看真实和假图像时的注视模式，以辅助假图像检测。研究者收集了一个新数据集，使用diffusion models部分操纵图像，并通过eye-tracking实验记录不同观察者在观看真实和假刺激时的眼动。初步统计分析发现，人类在感知假图像时倾向于聚焦于更局促的区域，而真实图像则显示出更分散的观察模式。该数据集已公开可用，网址为https://github.com/aimagelab/unveiling-the-truth。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted to IEEE Signal Processing Letters 2024",
      "pdf_url": "http://arxiv.org/pdf/2403.08933v1",
      "published_date": "2024-03-13 19:56:30 UTC",
      "updated_date": "2024-03-13 19:56:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:59:06.041035"
    },
    {
      "arxiv_id": "2403.08915v1",
      "title": "Cross-Modal Learning of Housing Quality in Amsterdam",
      "title_zh": "翻译失败",
      "authors": [
        "Alex Levering",
        "Diego Marcos",
        "Devis Tuia"
      ],
      "abstract": "In our research we test data and models for the recognition of housing\nquality in the city of Amsterdam from ground-level and aerial imagery. For\nground-level images we compare Google StreetView (GSV) to Flickr images. Our\nresults show that GSV predicts the most accurate building quality scores,\napproximately 30% better than using only aerial images. However, we find that\nthrough careful filtering and by using the right pre-trained model, Flickr\nimage features combined with aerial image features are able to halve the\nperformance gap to GSV features from 30% to 15%. Our results indicate that\nthere are viable alternatives to GSV for liveability factor prediction, which\nis encouraging as GSV images are more difficult to acquire and not always\navailable.",
      "tldr_zh": "本研究探讨了使用跨模态学习（Cross-Modal Learning）从地面和航拍图像中识别阿姆斯特丹房屋质量，比较了 Google StreetView (GSV) 和 Flickr 图像作为数据来源。结果显示，GSV 预测房屋质量得分最准确，比仅用航拍图像高出约 30%。通过仔细过滤图像并应用合适的预训练模型，Flickr 图像特征与航拍图像特征相结合，能将性能差距缩小一半，从 30% 到 15%，从而为 GSV 的替代方案提供了更易获取的可行选项。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Presented at SIGSpatial GeoAI workshop '21",
      "pdf_url": "http://arxiv.org/pdf/2403.08915v1",
      "published_date": "2024-03-13 19:11:58 UTC",
      "updated_date": "2024-03-13 19:11:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:59:19.102847"
    },
    {
      "arxiv_id": "2403.08910v1",
      "title": "Meta-operators for Enabling Parallel Planning Using Deep Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Ángel Aso-Mollar",
        "Eva Onaindia"
      ],
      "abstract": "There is a growing interest in the application of Reinforcement Learning (RL)\ntechniques to AI planning with the aim to come up with general policies.\nTypically, the mapping of the transition model of AI planning to the state\ntransition system of a Markov Decision Process is established by assuming a\none-to-one correspondence of the respective action spaces. In this paper, we\nintroduce the concept of meta-operator as the result of simultaneously applying\nmultiple planning operators, and we show that including meta-operators in the\nRL action space enables new planning perspectives to be addressed using RL,\nsuch as parallel planning. Our research aims to analyze the performance and\ncomplexity of including meta-operators in the RL process, concretely in domains\nwhere satisfactory outcomes have not been previously achieved using usual\ngeneralized planning models. The main objective of this article is thus to pave\nthe way towards a redefinition of the RL action space in a manner that is more\nclosely aligned with the planning perspective.",
      "tldr_zh": "这篇论文引入了meta-operator的概念，即同时应用多个AI规划操作符，以扩展Reinforcement Learning (RL) 在AI规划中的应用。作者通过将meta-operator纳入RL的动作空间，实现了平行规划等新视角，并分析了其在性能和复杂性方面的影响，尤其针对之前使用常规广义规划模型未获满意结果的领域。总体贡献在于重新定义RL的动作空间，使其更紧密地与规划视角对齐，从而为更有效的通用策略铺平道路。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "9 pages. Submitted to PRL workshop at ICAPS 2023",
      "pdf_url": "http://arxiv.org/pdf/2403.08910v1",
      "published_date": "2024-03-13 19:00:36 UTC",
      "updated_date": "2024-03-13 19:00:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:59:29.709195"
    },
    {
      "arxiv_id": "2403.10557v1",
      "title": "Second-Order Information Matters: Revisiting Machine Unlearning for Large Language Models",
      "title_zh": "二阶信息至关重要：重新审视大型语言模型的机器遗忘",
      "authors": [
        "Kang Gu",
        "Md Rafi Ur Rashid",
        "Najrin Sultana",
        "Shagufta Mehnaz"
      ],
      "abstract": "With the rapid development of Large Language Models (LLMs), we have witnessed\nintense competition among the major LLM products like ChatGPT, LLaMa, and\nGemini. However, various issues (e.g. privacy leakage and copyright violation)\nof the training corpus still remain underexplored. For example, the Times sued\nOpenAI and Microsoft for infringing on its copyrights by using millions of its\narticles for training. From the perspective of LLM practitioners, handling such\nunintended privacy violations can be challenging. Previous work addressed the\n``unlearning\" problem of LLMs using gradient information, while they mostly\nintroduced significant overheads like data preprocessing or lacked robustness.\nIn this paper, contrasting with the methods based on first-order information,\nwe revisit the unlearning problem via the perspective of second-order\ninformation (Hessian). Our unlearning algorithms, which are inspired by classic\nNewton update, are not only data-agnostic/model-agnostic but also proven to be\nrobust in terms of utility preservation or privacy guarantee. Through a\ncomprehensive evaluation with four NLP datasets as well as a case study on\nreal-world datasets, our methods consistently show superiority over the\nfirst-order methods.",
      "tldr_zh": "这篇论文重新审视了 Large Language Models (LLMs) 中的机器 unlearning 问题，强调 second-order information (如 Hessian) 的重要性，以解决隐私泄露和版权侵犯等挑战。作者提出了一种受经典 Newton 更新启发的 unlearning 算法，该算法是 data-agnostic 和 model-agnostic，能够在 utility preservation 和 privacy guarantee 方面实现更高的鲁棒性。实验结果显示，在四个 NLP 数据集以及真实世界数据集上的评估中，该方法比基于 first-order information 的方法表现出色，证明了其优越性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.10557v1",
      "published_date": "2024-03-13 18:57:30 UTC",
      "updated_date": "2024-03-13 18:57:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:59:42.755016"
    },
    {
      "arxiv_id": "2403.09740v1",
      "title": "Teaching Machines to Code: Smart Contract Translation with LLMs",
      "title_zh": "教机器编写代码：使用 LLMs 进行智能合约翻译",
      "authors": [
        "Rabimba Karanjai",
        "Lei Xu",
        "Weidong Shi"
      ],
      "abstract": "The advent of large language models (LLMs) has marked a significant milestone\nin the realm of artificial intelligence, with their capabilities often matching\nor surpassing human expertise in various domains. Among these achievements,\ntheir adeptness in translation tasks stands out, closely mimicking the\nintricate and preliminary processes undertaken by human translators to ensure\nthe fidelity and quality of the translated content. Despite the advancements in\nutilizing LLMs for translating programming code across different languages, the\ndomain of smart contract translation, particularly into languages not\npreviously encountered by the LLM, remains largely unexplored. In our research,\nwe present a pioneering approach, SolMover, which harnesses the synergy of two\ndistinct LLMs within a unified framework. This framework is designed to grasp\ncoding principles and apply this understanding to the translation of code into\nan unfamiliar language. Our study delves into the capacity of LLMs to mimic\nhuman learning processes, offering an in-depth evaluation of our methodology\nfor converting smart contracts written in Solidity to Move, a language with\nlimited resources. The framework employs one LLM to decipher coding conventions\nfor the new language, creating a blueprint for the second LLM, which, lacking\nplanning abilities, possesses coding expertise. The empirical evidence from our\nexperiments suggests that SolMover substantially enhances performance compared\nto gpt-3.5-turbo-1106, and achieves superior results over competitors such as\nPalm2 and Mixtral-8x7B-Instruct. Additionally, our analysis highlights the\nefficacy of our bug mitigation strategy in elevating code quality across all\nmodels, even outside the SolMover framework.",
      "tldr_zh": "本研究探讨了使用大型语言模型（LLMs）来翻译智能合约，特别是将 Solidity 代码转换为资源有限的 Move 语言，以填补这一领域的空白。研究提出了一种创新框架 SolMover，该框架协同两个 LLMs：一个负责学习新语言的编码约定并创建蓝图，另一个则利用这些信息进行实际翻译，从而模仿人类学习过程。实验结果显示，SolMover 显著优于 gpt-3.5-turbo-1106 等竞争模型，并在代码质量上通过 bug 缓解策略进一步提升性能，为机器自动代码翻译提供了新路径。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.09740v1",
      "published_date": "2024-03-13 18:55:20 UTC",
      "updated_date": "2024-03-13 18:55:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:59:55.599816"
    },
    {
      "arxiv_id": "2403.08906v3",
      "title": "Strategizing against Q-learners: A Control-theoretical Approach",
      "title_zh": "翻译失败",
      "authors": [
        "Yuksel Arslantas",
        "Ege Yuceel",
        "Muhammed O. Sayin"
      ],
      "abstract": "In this paper, we explore the susceptibility of the independent Q-learning\nalgorithms (a classical and widely used multi-agent reinforcement learning\nmethod) to strategic manipulation of sophisticated opponents in normal-form\ngames played repeatedly. We quantify how much strategically sophisticated\nagents can exploit naive Q-learners if they know the opponents' Q-learning\nalgorithm. To this end, we formulate the strategic actors' interactions as a\nstochastic game (whose state encompasses Q-function estimates of the\nQ-learners) as if the Q-learning algorithms are the underlying dynamical\nsystem. We also present a quantization-based approximation scheme to tackle the\ncontinuum state space and analyze its performance for two competing strategic\nactors and a single strategic actor both analytically and numerically.",
      "tldr_zh": "这篇论文探讨了 Q-learning 算法在重复博弈中的易受战略操纵问题，量化了战略性代理如何利用对手的 Q-learning 算法来获得优势。作者将这些互动建模为一个随机博弈(stochastic game)，其中状态包括 Q-learners 的 Q 函数估计，并引入基于量化的近似方案(quantization-based approximation scheme)来处理连续状态空间。研究通过分析和数值方法评估了这一方法的性能，包括两个竞争战略代理和一个战略代理的场景，为理解多智能体强化学习中的策略性漏洞提供了新见解。",
      "categories": [
        "cs.GT",
        "cs.AI",
        "math.OC"
      ],
      "primary_category": "cs.GT",
      "comment": "The extended arXiv version of the original paper to appear in IEEE\n  L-CSS",
      "pdf_url": "http://arxiv.org/pdf/2403.08906v3",
      "published_date": "2024-03-13 18:54:27 UTC",
      "updated_date": "2024-07-16 07:13:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T15:00:07.500567"
    },
    {
      "arxiv_id": "2403.09738v4",
      "title": "Evaluating Large Language Models as Generative User Simulators for Conversational Recommendation",
      "title_zh": "评估大语言模型作为生成式用户模拟器用于对话式推荐",
      "authors": [
        "Se-eun Yoon",
        "Zhankui He",
        "Jessica Maria Echterhoff",
        "Julian McAuley"
      ],
      "abstract": "Synthetic users are cost-effective proxies for real users in the evaluation\nof conversational recommender systems. Large language models show promise in\nsimulating human-like behavior, raising the question of their ability to\nrepresent a diverse population of users. We introduce a new protocol to measure\nthe degree to which language models can accurately emulate human behavior in\nconversational recommendation. This protocol is comprised of five tasks, each\ndesigned to evaluate a key property that a synthetic user should exhibit:\nchoosing which items to talk about, expressing binary preferences, expressing\nopen-ended preferences, requesting recommendations, and giving feedback.\nThrough evaluation of baseline simulators, we demonstrate these tasks\neffectively reveal deviations of language models from human behavior, and offer\ninsights on how to reduce the deviations with model selection and prompting\nstrategies.",
      "tldr_zh": "这篇论文评估了Large Language Models作为生成式用户模拟器在对话推荐系统中的表现，旨在检验它们是否能准确模拟多样化的人类行为。研究者引入了一个新协议，包括五个关键任务：选择讨论的物品、表达二元偏好、表达开放式偏好、请求推荐以及给出反馈。这些任务通过基线模拟器的实验，揭示了语言模型与人类行为的偏差，并提供了模型选择和提示策略来减少这些偏差的见解。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.CL",
      "comment": "NAACL 2024",
      "pdf_url": "http://arxiv.org/pdf/2403.09738v4",
      "published_date": "2024-03-13 18:16:21 UTC",
      "updated_date": "2024-03-25 23:53:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T15:00:19.034123"
    },
    {
      "arxiv_id": "2403.08885v1",
      "title": "SLCF-Net: Sequential LiDAR-Camera Fusion for Semantic Scene Completion using a 3D Recurrent U-Net",
      "title_zh": "翻译失败",
      "authors": [
        "Helin Cao",
        "Sven Behnke"
      ],
      "abstract": "We introduce SLCF-Net, a novel approach for the Semantic Scene Completion\n(SSC) task that sequentially fuses LiDAR and camera data. It jointly estimates\nmissing geometry and semantics in a scene from sequences of RGB images and\nsparse LiDAR measurements. The images are semantically segmented by a\npre-trained 2D U-Net and a dense depth prior is estimated from a\ndepth-conditioned pipeline fueled by Depth Anything. To associate the 2D image\nfeatures with the 3D scene volume, we introduce Gaussian-decay Depth-prior\nProjection (GDP). This module projects the 2D features into the 3D volume along\nthe line of sight with a Gaussian-decay function, centered around the depth\nprior. Volumetric semantics is computed by a 3D U-Net. We propagate the hidden\n3D U-Net state using the sensor motion and design a novel loss to ensure\ntemporal consistency. We evaluate our approach on the SemanticKITTI dataset and\ncompare it with leading SSC approaches. The SLCF-Net excels in all SSC metrics\nand shows great temporal consistency.",
      "tldr_zh": "本研究提出SLCF-Net，一种顺序融合LiDAR和相机数据的创新框架，用于Semantic Scene Completion (SSC)任务，能够从RGB图像序列和稀疏LiDAR测量中联合估计场景的缺失几何和语义。框架利用预训练的2D U-Net进行图像语义分割，并通过Depth Anything驱动的深度条件管道估计密集深度先验，然后引入Gaussian-decay Depth-prior Projection (GDP)模块，将2D特征投影到3D体积中，同时使用3D U-Net计算体积语义并通过传感器运动传播隐藏状态，以确保时间一致性。实验在SemanticKITTI数据集上显示，SLCF-Net在所有SSC指标上优于领先方法，并表现出色的时间一致性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "2024 IEEE International Conference on Robotics and Automation\n  (ICRA2024), Yokohama, Japan, May 2024",
      "pdf_url": "http://arxiv.org/pdf/2403.08885v1",
      "published_date": "2024-03-13 18:12:53 UTC",
      "updated_date": "2024-03-13 18:12:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T15:00:32.265769"
    },
    {
      "arxiv_id": "2403.08882v1",
      "title": "Cultural evolution in populations of Large Language Models",
      "title_zh": "大型语言模型种群中的文化演化",
      "authors": [
        "Jérémy Perez",
        "Corentin Léger",
        "Marcela Ovando-Tellez",
        "Chris Foulon",
        "Joan Dussauld",
        "Pierre-Yves Oudeyer",
        "Clément Moulin-Frier"
      ],
      "abstract": "Research in cultural evolution aims at providing causal explanations for the\nchange of culture over time. Over the past decades, this field has generated an\nimportant body of knowledge, using experimental, historical, and computational\nmethods. While computational models have been very successful at generating\ntestable hypotheses about the effects of several factors, such as population\nstructure or transmission biases, some phenomena have so far been more complex\nto capture using agent-based and formal models. This is in particular the case\nfor the effect of the transformations of social information induced by evolved\ncognitive mechanisms. We here propose that leveraging the capacity of Large\nLanguage Models (LLMs) to mimic human behavior may be fruitful to address this\ngap. On top of being an useful approximation of human cultural dynamics,\nmulti-agents models featuring generative agents are also important to study for\ntheir own sake. Indeed, as artificial agents are bound to participate more and\nmore to the evolution of culture, it is crucial to better understand the\ndynamics of machine-generated cultural evolution. We here present a framework\nfor simulating cultural evolution in populations of LLMs, allowing the\nmanipulation of variables known to be important in cultural evolution, such as\nnetwork structure, personality, and the way social information is aggregated\nand transformed. The software we developed for conducting these simulations is\nopen-source and features an intuitive user-interface, which we hope will help\nto build bridges between the fields of cultural evolution and generative\nartificial intelligence.",
      "tldr_zh": "该研究探讨了在 Large Language Models (LLMs) 种群中模拟文化演变，以弥补传统计算模型在捕捉认知机制对社会信息转换影响方面的不足。论文提出一个框架，利用 LLMs 的能力来模仿人类行为，允许操纵关键变量如网络结构、个性和社会信息聚合方式，从而生成更准确的文化动态假设。除了模拟人类文化演变外，该框架还有助于研究机器生成的文化演变动态。研究团队开发了开源软件，配备直观的用户界面，以促进文化演变和生成式人工智能领域之间的合作。",
      "categories": [
        "cs.MA",
        "cs.AI",
        "q-bio.PE",
        "68T50",
        "I.2.7"
      ],
      "primary_category": "cs.MA",
      "comment": "17 pages, 20 figures. Open-source code available at\n  https://github.com/jeremyperez2/LLM-Culture",
      "pdf_url": "http://arxiv.org/pdf/2403.08882v1",
      "published_date": "2024-03-13 18:11:17 UTC",
      "updated_date": "2024-03-13 18:11:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T15:00:42.840809"
    },
    {
      "arxiv_id": "2403.14687v1",
      "title": "On the Performance of Imputation Techniques for Missing Values on Healthcare Datasets",
      "title_zh": "翻译失败",
      "authors": [
        "Luke Oluwaseye Joel",
        "Wesley Doorsamy",
        "Babu Sena Paul"
      ],
      "abstract": "Missing values or data is one popular characteristic of real-world datasets,\nespecially healthcare data. This could be frustrating when using machine\nlearning algorithms on such datasets, simply because most machine learning\nmodels perform poorly in the presence of missing values. The aim of this study\nis to compare the performance of seven imputation techniques, namely Mean\nimputation, Median Imputation, Last Observation carried Forward (LOCF)\nimputation, K-Nearest Neighbor (KNN) imputation, Interpolation imputation,\nMissforest imputation, and Multiple imputation by Chained Equations (MICE), on\nthree healthcare datasets. Some percentage of missing values - 10\\%, 15\\%, 20\\%\nand 25\\% - were introduced into the dataset, and the imputation techniques were\nemployed to impute these missing values. The comparison of their performance\nwas evaluated by using root mean squared error (RMSE) and mean absolute error\n(MAE). The results show that Missforest imputation performs the best followed\nby MICE imputation. Additionally, we try to determine whether it is better to\nperform feature selection before imputation or vice versa by using the\nfollowing metrics - the recall, precision, f1-score and accuracy. Due to the\nfact that there are few literature on this and some debate on the subject among\nresearchers, we hope that the results from this experiment will encourage data\nscientists and researchers to perform imputation first before feature selection\nwhen dealing with data containing missing values.",
      "tldr_zh": "本研究比较了七种缺失值插补技术（Mean imputation、Median Imputation、LOCF imputation、KNN imputation、Interpolation imputation、Missforest imputation 和 MICE）在三个医疗数据集上的性能，针对10%、15%、20%和25%的缺失值进行评估。使用 RMSE 和 MAE 作为指标，结果表明 Missforest imputation 表现最佳，其次是 MICE imputation。论文还探讨了插补与特征选择的顺序，发现先进行插补再特征选择可提升模型表现（如 recall、precision、f1-score 和 accuracy），并建议数据科学家优先采用此策略。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.14687v1",
      "published_date": "2024-03-13 18:07:17 UTC",
      "updated_date": "2024-03-13 18:07:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T15:00:55.828522"
    },
    {
      "arxiv_id": "2403.08879v1",
      "title": "Multi-Objective Optimization Using Adaptive Distributed Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Jing Tan",
        "Ramin Khalili",
        "Holger Karl"
      ],
      "abstract": "The Intelligent Transportation System (ITS) environment is known to be\ndynamic and distributed, where participants (vehicle users, operators, etc.)\nhave multiple, changing and possibly conflicting objectives. Although\nReinforcement Learning (RL) algorithms are commonly applied to optimize ITS\napplications such as resource management and offloading, most RL algorithms\nfocus on single objectives. In many situations, converting a multi-objective\nproblem into a single-objective one is impossible, intractable or insufficient,\nmaking such RL algorithms inapplicable. We propose a multi-objective,\nmulti-agent reinforcement learning (MARL) algorithm with high learning\nefficiency and low computational requirements, which automatically triggers\nadaptive few-shot learning in a dynamic, distributed and noisy environment with\nsparse and delayed reward. We test our algorithm in an ITS environment with\nedge cloud computing. Empirical results show that the algorithm is quick to\nadapt to new environments and performs better in all individual and system\nmetrics compared to the state-of-the-art benchmark. Our algorithm also\naddresses various practical concerns with its modularized and asynchronous\nonline training method. In addition to the cloud simulation, we test our\nalgorithm on a single-board computer and show that it can make inference in 6\nmilliseconds.",
      "tldr_zh": "本研究提出了一种自适应分布式多智能体强化学习(MARL)算法，用于处理智能交通系统(ITS)中多目标优化问题，该算法能够自动触发自适应少样本学习，以应对动态、分布式的噪声环境中的稀疏和延迟奖励。算法设计强调高学习效率和低计算需求，通过模块化和异步在线训练方法，实现快速适应新环境，并在边缘云计算模拟中优于最先进基准，在所有个体和系统指标上表现出色。此外，在实际测试中，该算法在单板计算机上仅需6毫秒即可完成推理，展示了其在实际ITS应用中的可行性和高效性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.MA",
        "math.OC"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.08879v1",
      "published_date": "2024-03-13 18:05:16 UTC",
      "updated_date": "2024-03-13 18:05:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T15:01:07.235578"
    },
    {
      "arxiv_id": "2403.08770v1",
      "title": "FastMAC: Stochastic Spectral Sampling of Correspondence Graph",
      "title_zh": "FastMAC: 对应关系图的随机谱采样",
      "authors": [
        "Yifei Zhang",
        "Hao Zhao",
        "Hongyang Li",
        "Siheng Chen"
      ],
      "abstract": "3D correspondence, i.e., a pair of 3D points, is a fundamental concept in\ncomputer vision. A set of 3D correspondences, when equipped with compatibility\nedges, forms a correspondence graph. This graph is a critical component in\nseveral state-of-the-art 3D point cloud registration approaches, e.g., the one\nbased on maximal cliques (MAC). However, its properties have not been well\nunderstood. So we present the first study that introduces graph signal\nprocessing into the domain of correspondence graph. We exploit the generalized\ndegree signal on correspondence graph and pursue sampling strategies that\npreserve high-frequency components of this signal. To address time-consuming\nsingular value decomposition in deterministic sampling, we resort to a\nstochastic approximate sampling strategy. As such, the core of our method is\nthe stochastic spectral sampling of correspondence graph. As an application, we\nbuild a complete 3D registration algorithm termed as FastMAC, that reaches\nreal-time speed while leading to little to none performance drop. Through\nextensive experiments, we validate that FastMAC works for both indoor and\noutdoor benchmarks. For example, FastMAC can accelerate MAC by 80 times while\nmaintaining high registration success rate on KITTI. Codes are publicly\navailable at https://github.com/Forrest-110/FastMAC.",
      "tldr_zh": "本研究首次将图信号处理引入3D对应图领域，通过利用对应图上的广义度信号（generalized degree signal），开发了随机谱采样（stochastic spectral sampling）策略，以保留高频成分并避免耗时的奇异值分解（singular value decomposition）。该方法的核心应用于构建FastMAC算法，一种完整的3D点云注册（3D point cloud registration）系统，实现实时速度，同时几乎不降低性能。实验结果显示，FastMAC在室内和室外基准（如KITTI数据集）上表现优异，能将基于最大团（maximal cliques, MAC）的基线方法加速80倍，同时保持高注册成功率，代码已在GitHub公开。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "CVPR 2024, Code: https://github.com/Forrest-110/FastMAC",
      "pdf_url": "http://arxiv.org/pdf/2403.08770v1",
      "published_date": "2024-03-13 17:59:56 UTC",
      "updated_date": "2024-03-13 17:59:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T15:01:19.141622"
    },
    {
      "arxiv_id": "2403.08763v4",
      "title": "Simple and Scalable Strategies to Continually Pre-train Large Language Models",
      "title_zh": "简单且可扩展的策略用于持续预训练大型语言模型",
      "authors": [
        "Adam Ibrahim",
        "Benjamin Thérien",
        "Kshitij Gupta",
        "Mats L. Richter",
        "Quentin Anthony",
        "Timothée Lesort",
        "Eugene Belilovsky",
        "Irina Rish"
      ],
      "abstract": "Large language models (LLMs) are routinely pre-trained on billions of tokens,\nonly to start the process over again once new data becomes available. A much\nmore efficient solution is to continually pre-train these models, saving\nsignificant compute compared to re-training. However, the distribution shift\ninduced by new data typically results in degraded performance on previous data\nor poor adaptation to the new data. In this work, we show that a simple and\nscalable combination of learning rate (LR) re-warming, LR re-decaying, and\nreplay of previous data is sufficient to match the performance of fully\nre-training from scratch on all available data, as measured by the final loss\nand the average score on several language model (LM) evaluation benchmarks.\nSpecifically, we show this for a weak but realistic distribution shift between\ntwo commonly used LLM pre-training datasets (English$\\rightarrow$English) and a\nstronger distribution shift (English$\\rightarrow$German) at the $405$M\nparameter model scale with large dataset sizes (hundreds of billions of\ntokens). Selecting the weak but realistic shift for larger-scale experiments,\nwe also find that our continual learning strategies match the re-training\nbaseline for a 10B parameter LLM. Our results demonstrate that LLMs can be\nsuccessfully updated via simple and scalable continual learning strategies,\nmatching the re-training baseline using only a fraction of the compute.\nFinally, inspired by previous work, we propose alternatives to the cosine\nlearning rate schedule that help circumvent forgetting induced by LR re-warming\nand that are not bound to a fixed token budget.",
      "tldr_zh": "该论文提出简单且可扩展的策略，用于持续预训练大型语言模型（LLMs），以避免因新数据而从头重新训练的高计算成本。策略包括学习率（LR）重新加热、LR 重新衰减以及之前数据的重放（replay），这些方法在弱分布偏移（English 到 English）和强分布偏移（English 到 German）的实验中，匹配了从头重新训练的性能指标，如最终损失和语言模型评估基准。结果显示，在405M和10B参数规模的模型上，该方法仅使用部分计算资源即可实现等效效果；此外，论文还探索了替代余弦学习率调度的方案，以减少LR重新加热引发的遗忘问题。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.08763v4",
      "published_date": "2024-03-13 17:58:57 UTC",
      "updated_date": "2024-09-04 16:13:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T15:01:33.136032"
    },
    {
      "arxiv_id": "2403.08755v2",
      "title": "DAM: Dynamic Adapter Merging for Continual Video QA Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Feng Cheng",
        "Ziyang Wang",
        "Yi-Lin Sung",
        "Yan-Bo Lin",
        "Mohit Bansal",
        "Gedas Bertasius"
      ],
      "abstract": "We present a parameter-efficient method for continual video\nquestion-answering (VidQA) learning. Our method, named DAM, uses the proposed\nDynamic Adapter Merging to (i) mitigate catastrophic forgetting, (ii) enable\nefficient adaptation to continually arriving datasets, (iii) handle inputs from\nunknown datasets during inference, and (iv) enable knowledge sharing across\nsimilar dataset domains. Given a set of continually streaming VidQA datasets,\nwe sequentially train dataset-specific adapters for each dataset while freezing\nthe parameters of a large pretrained video-language backbone. During inference,\ngiven a video-question sample from an unknown domain, our method first uses the\nproposed non-parametric router function to compute a probability for each\nadapter, reflecting how relevant that adapter is to the current video-question\ninput instance. Subsequently, the proposed dynamic adapter merging scheme\naggregates all the adapter weights into a new adapter instance tailored for\nthat particular test sample to compute the final VidQA prediction, mitigating\nthe impact of inaccurate router predictions and facilitating knowledge sharing\nacross domains. Our DAM model outperforms prior state-of-the-art continual\nlearning approaches by 9.1% while exhibiting 1.9% less forgetting on 6 VidQA\ndatasets spanning various domains. We further extend DAM to continual image\nclassification and image QA and outperform prior methods by a large margin. The\ncode is publicly available at: https://github.com/klauscc/DAM",
      "tldr_zh": "该研究提出了一种参数高效的方法 DAM（Dynamic Adapter Merging），用于持续视频问答（VidQA）学习，通过动态适配器合并技术缓解 catastrophic forgetting，并高效适应不断到来的数据集，同时处理未知域输入并促进知识共享。方法涉及依次训练数据集特定适配器，同时冻结预训练视频-语言主干模型，并在推理时使用非参数路由器函数计算适配器相关概率，然后聚合适配器权重以生成定制预测。实验结果显示，DAM 在 6 个 VidQA 数据集上比现有最先进方法提高 9.1%，遗忘率降低 1.9%，并扩展到持续图像分类和图像 QA 领域，表现出色。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "The first two authors contribute equally",
      "pdf_url": "http://arxiv.org/pdf/2403.08755v2",
      "published_date": "2024-03-13 17:53:47 UTC",
      "updated_date": "2024-04-22 19:17:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T15:01:45.357809"
    },
    {
      "arxiv_id": "2404.10179v3",
      "title": "Scaling Instructable Agents Across Many Simulated Worlds",
      "title_zh": "跨多个模拟世界扩展可指令代理",
      "authors": [
        "SIMA Team",
        "Maria Abi Raad",
        "Arun Ahuja",
        "Catarina Barros",
        "Frederic Besse",
        "Andrew Bolt",
        "Adrian Bolton",
        "Bethanie Brownfield",
        "Gavin Buttimore",
        "Max Cant",
        "Sarah Chakera",
        "Stephanie C. Y. Chan",
        "Jeff Clune",
        "Adrian Collister",
        "Vikki Copeman",
        "Alex Cullum",
        "Ishita Dasgupta",
        "Dario de Cesare",
        "Julia Di Trapani",
        "Yani Donchev",
        "Emma Dunleavy",
        "Martin Engelcke",
        "Ryan Faulkner",
        "Frankie Garcia",
        "Charles Gbadamosi",
        "Zhitao Gong",
        "Lucy Gonzales",
        "Kshitij Gupta",
        "Karol Gregor",
        "Arne Olav Hallingstad",
        "Tim Harley",
        "Sam Haves",
        "Felix Hill",
        "Ed Hirst",
        "Drew A. Hudson",
        "Jony Hudson",
        "Steph Hughes-Fitt",
        "Danilo J. Rezende",
        "Mimi Jasarevic",
        "Laura Kampis",
        "Rosemary Ke",
        "Thomas Keck",
        "Junkyung Kim",
        "Oscar Knagg",
        "Kavya Kopparapu",
        "Rory Lawton",
        "Andrew Lampinen",
        "Shane Legg",
        "Alexander Lerchner",
        "Marjorie Limont",
        "Yulan Liu",
        "Maria Loks-Thompson",
        "Joseph Marino",
        "Kathryn Martin Cussons",
        "Loic Matthey",
        "Siobhan Mcloughlin",
        "Piermaria Mendolicchio",
        "Hamza Merzic",
        "Anna Mitenkova",
        "Alexandre Moufarek",
        "Valeria Oliveira",
        "Yanko Oliveira",
        "Hannah Openshaw",
        "Renke Pan",
        "Aneesh Pappu",
        "Alex Platonov",
        "Ollie Purkiss",
        "David Reichert",
        "John Reid",
        "Pierre Harvey Richemond",
        "Tyson Roberts",
        "Giles Ruscoe",
        "Jaume Sanchez Elias",
        "Tasha Sandars",
        "Daniel P. Sawyer",
        "Tim Scholtes",
        "Guy Simmons",
        "Daniel Slater",
        "Hubert Soyer",
        "Heiko Strathmann",
        "Peter Stys",
        "Allison C. Tam",
        "Denis Teplyashin",
        "Tayfun Terzi",
        "Davide Vercelli",
        "Bojan Vujatovic",
        "Marcus Wainwright",
        "Jane X. Wang",
        "Zhengdong Wang",
        "Daan Wierstra",
        "Duncan Williams",
        "Nathaniel Wong",
        "Sarah York",
        "Nick Young"
      ],
      "abstract": "Building embodied AI systems that can follow arbitrary language instructions\nin any 3D environment is a key challenge for creating general AI. Accomplishing\nthis goal requires learning to ground language in perception and embodied\nactions, in order to accomplish complex tasks. The Scalable, Instructable,\nMultiworld Agent (SIMA) project tackles this by training agents to follow\nfree-form instructions across a diverse range of virtual 3D environments,\nincluding curated research environments as well as open-ended, commercial video\ngames. Our goal is to develop an instructable agent that can accomplish\nanything a human can do in any simulated 3D environment. Our approach focuses\non language-driven generality while imposing minimal assumptions. Our agents\ninteract with environments in real-time using a generic, human-like interface:\nthe inputs are image observations and language instructions and the outputs are\nkeyboard-and-mouse actions. This general approach is challenging, but it allows\nagents to ground language across many visually complex and semantically rich\nenvironments while also allowing us to readily run agents in new environments.\nIn this paper we describe our motivation and goal, the initial progress we have\nmade, and promising preliminary results on several diverse research\nenvironments and a variety of commercial video games.",
      "tldr_zh": "该研究旨在构建可指令AI代理（instructable agents），能够遵循任意语言指令在多种模拟3D环境（3D environments）中执行任务，从而推动通用AI的发展。研究引入了Scalable, Instructable, Multiworld Agent (SIMA)项目，通过训练代理使用图像观察和语言指令作为输入，输出键盘和鼠标动作，实现语言与感知及动作的结合，而不强加过多假设。实验结果显示，SIMA代理在多样化的研究环境和商业视频游戏中取得了有前景的初步进展，提升了代理的泛化能力和任务完成效率。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.HC",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.10179v3",
      "published_date": "2024-03-13 17:50:32 UTC",
      "updated_date": "2024-10-11 16:30:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T15:01:57.606372"
    },
    {
      "arxiv_id": "2405.15771v2",
      "title": "Adaptive Splitting of Reusable Temporal Monitors for Rare Traffic Violations",
      "title_zh": "自适应分割可重用时序监控器用于罕见交通违规",
      "authors": [
        "Craig Innes",
        "Subramanian Ramamoorthy"
      ],
      "abstract": "Autonomous Vehicles (AVs) are often tested in simulation to estimate the\nprobability they will violate safety specifications. Two common issues arise\nwhen using existing techniques to produce this estimation: If violations occur\nrarely, simple Monte-Carlo sampling techniques can fail to produce efficient\nestimates; if simulation horizons are too long, importance sampling techniques\n(which learn proposal distributions from past simulations) can fail to\nconverge. This paper addresses both issues by interleaving rare-event sampling\ntechniques with online specification monitoring algorithms. We use adaptive\nmulti-level splitting to decompose simulations into partial trajectories, then\ncalculate the distance of those partial trajectories to failure by leveraging\nrobustness metrics from Signal Temporal Logic (STL). By caching those partial\nrobustness metric values, we can efficiently re-use computations across\nmultiple sampling stages. Our experiments on an interstate lane-change scenario\nshow our method is viable for testing simulated AV-pipelines, efficiently\nestimating failure probabilities for STL specifications based on real traffic\nrules. We produce better estimates than Monte-Carlo and importance sampling in\nfewer simulations.",
      "tldr_zh": "本研究针对自动驾驶车辆 (AVs) 在模拟环境中估算稀有交通违规概率时面临的挑战，包括简单 Monte-Carlo sampling 效率低下和 importance sampling 在长模拟中收敛失败的问题。论文提出了一种自适应多级分割方法，将模拟分解为部分轨迹，并利用 Signal Temporal Logic (STL) 的鲁棒性指标计算这些轨迹到失败的距离，同时通过缓存部分鲁棒性值实现计算重用。实验结果显示，在州际换道场景中，该方法比传统 Monte-Carlo 和 importance sampling 在更少的模拟次数下提供了更准确的失败概率估计，从而提高了 AV 安全测试的效率。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.15771v2",
      "published_date": "2024-03-13 17:47:39 UTC",
      "updated_date": "2024-07-24 12:56:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T15:02:11.697885"
    },
    {
      "arxiv_id": "2403.08743v2",
      "title": "Prompting Fairness: Integrating Causality to Debias Large Language Models",
      "title_zh": "提示公平性：整合因果性以去偏",
      "authors": [
        "Jingling Li",
        "Zeyu Tang",
        "Xiaoyu Liu",
        "Peter Spirtes",
        "Kun Zhang",
        "Liu Leqi",
        "Yang Liu"
      ],
      "abstract": "Large language models (LLMs), despite their remarkable capabilities, are\nsusceptible to generating biased and discriminatory responses. As LLMs\nincreasingly influence high-stakes decision-making (e.g., hiring and\nhealthcare), mitigating these biases becomes critical. In this work, we propose\na causality-guided debiasing framework to tackle social biases, aiming to\nreduce the objectionable dependence between LLMs' decisions and the social\ninformation in the input. Our framework introduces a novel perspective to\nidentify how social information can affect an LLM's decision through different\ncausal pathways. Leveraging these causal insights, we outline principled\nprompting strategies that regulate these pathways through selection mechanisms.\nThis framework not only unifies existing prompting-based debiasing techniques,\nbut also opens up new directions for reducing bias by encouraging the model to\nprioritize fact-based reasoning over reliance on biased social cues. We\nvalidate our framework through extensive experiments on real-world datasets\nacross multiple domains, demonstrating its effectiveness in debiasing LLM\ndecisions, even with only black-box access to the model.",
      "tldr_zh": "本研究针对大型语言模型 (LLMs) 在决策中存在的社会偏见问题，提出了一种基于因果关系的去偏框架，以减少模型对输入社会信息的依赖。该框架通过识别社会信息影响LLMs决策的各种因果路径，并采用原则性的提示策略（如选择机制）来调节这些路径，从而鼓励模型优先使用基于事实的推理而非偏见线索。该方法不仅统一了现有的基于提示的去偏技术，还为进一步减少偏见提供了新方向；实验在多个领域的真实数据集上验证了其有效性，即使仅通过黑箱访问模型也能显著提升决策公平性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "24 pages, 10 figures",
      "pdf_url": "http://arxiv.org/pdf/2403.08743v2",
      "published_date": "2024-03-13 17:46:28 UTC",
      "updated_date": "2025-03-02 17:33:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T15:02:21.902697"
    },
    {
      "arxiv_id": "2403.08739v1",
      "title": "The Garden of Forking Paths: Observing Dynamic Parameters Distribution in Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Carlo Nicolini",
        "Jacopo Staiano",
        "Bruno Lepri",
        "Raffaele Marino"
      ],
      "abstract": "A substantial gap persists in understanding the reasons behind the\nexceptional performance of the Transformer architecture in NLP. A particularly\nunexplored area involves the mechanistic description of how the distribution of\nparameters evolves over time during training. In this work we suggest that\nlooking at the time evolution of the statistic distribution of model\nparameters, and specifically at bifurcation effects, can help understanding the\nmodel quality, potentially reducing training costs and evaluation efforts and\nempirically showing the reasons behind the effectiveness of weights\nsparsification.",
      "tldr_zh": "该研究探讨了Transformer架构在NLP中的出色性能背后的原因，特别关注模型参数分布在训练过程中的动态演变。论文提出，通过观察参数的统计分布演变，尤其是bifurcation effects，可以更好地理解模型质量，从而潜在降低训练成本和评估努力。实验结果显示，这种方法有助于解释weights sparsification的有效性，并为提升大型语言模型的效率提供新见解。",
      "categories": [
        "cs.CL",
        "cond-mat.dis-nn",
        "cond-mat.stat-mech",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "15 pages",
      "pdf_url": "http://arxiv.org/pdf/2403.08739v1",
      "published_date": "2024-03-13 17:42:32 UTC",
      "updated_date": "2024-03-13 17:42:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T15:02:32.944815"
    },
    {
      "arxiv_id": "2403.08728v2",
      "title": "Ambient Diffusion Posterior Sampling: Solving Inverse Problems with Diffusion Models Trained on Corrupted Data",
      "title_zh": "Ambient Diffusion Posterior Sampling：利用",
      "authors": [
        "Asad Aali",
        "Giannis Daras",
        "Brett Levac",
        "Sidharth Kumar",
        "Alexandros G. Dimakis",
        "Jonathan I. Tamir"
      ],
      "abstract": "We provide a framework for solving inverse problems with diffusion models\nlearned from linearly corrupted data. Firstly, we extend the Ambient Diffusion\nframework to enable training directly from measurements corrupted in the\nFourier domain. Subsequently, we train diffusion models for MRI with access\nonly to Fourier subsampled multi-coil measurements at acceleration factors R=\n2,4,6,8. Secondly, we propose Ambient Diffusion Posterior Sampling (A-DPS), a\nreconstruction algorithm that leverages generative models pre-trained on one\ntype of corruption (e.g. image inpainting) to perform posterior sampling on\nmeasurements from a different forward process (e.g. image blurring). For MRI\nreconstruction in high acceleration regimes, we observe that A-DPS models\ntrained on subsampled data are better suited to solving inverse problems than\nmodels trained on fully sampled data. We also test the efficacy of A-DPS on\nnatural image datasets (CelebA, FFHQ, and AFHQ) and show that A-DPS can\nsometimes outperform models trained on clean data for several image restoration\ntasks in both speed and performance.",
      "tldr_zh": "该论文扩展了Ambient Diffusion框架，允许直接从Fourier域受损数据中训练扩散模型，例如在MRI应用中，仅使用加速因子R=2,4,6,8的子采样多线圈测量进行训练。论文提出Ambient Diffusion Posterior Sampling (A-DPS)算法，该算法利用在一种腐败类型（如图像修复）上预训练的生成模型，对不同前向过程（如图像模糊）的测量进行后验采样。实验结果显示，在高加速MRI重建和自然图像数据集（CelebA, FFHQ, AFHQ）上，A-DPS比用完全采样数据训练的模型在速度和性能上更出色，尤其适合逆问题解决。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.08728v2",
      "published_date": "2024-03-13 17:28:20 UTC",
      "updated_date": "2025-04-21 23:33:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T15:02:46.686131"
    },
    {
      "arxiv_id": "2403.08699v1",
      "title": "Implicit Regularization of Gradient Flow on One-Layer Softmax Attention",
      "title_zh": "翻译失败",
      "authors": [
        "Heejune Sheen",
        "Siyu Chen",
        "Tianhao Wang",
        "Harrison H. Zhou"
      ],
      "abstract": "We study gradient flow on the exponential loss for a classification problem\nwith a one-layer softmax attention model, where the key and query weight\nmatrices are trained separately. Under a separability assumption on the data,\nwe show that when gradient flow achieves the minimal loss value, it further\nimplicitly minimizes the nuclear norm of the product of the key and query\nweight matrices. Such implicit regularization can be described by a Support\nVector Machine (SVM) problem with respect to the attention weights. This\nfinding contrasts with prior results showing that the gradient descent induces\nan implicit regularization on the Frobenius norm on the product weight matrix\nwhen the key and query matrices are combined into a single weight matrix for\ntraining. For diagonal key and query matrices, our analysis builds upon the\nreparameterization technique and exploits approximate KKT conditions of the SVM\nassociated with the classification data. Moreover, the results are extended to\ngeneral weights configurations given proper alignment of the weight matrices'\nsingular spaces with the data features at initialization.",
      "tldr_zh": "这篇论文研究了在一层 softmax attention 模型中，梯度流对分类问题的隐式正则化，假设数据可分离时，关键和查询权重矩阵分开训练。研究发现，当梯度流达到最小损失时，它会隐式最小化关键和查询权重矩阵乘积的 nuclear norm，这种正则化等价于一个基于注意力权重的 Support Vector Machine (SVM) 问题，与之前针对合并权重矩阵的 Frobenius norm 正则化形成鲜明对比。通过重参数化和近似 KKT conditions 的分析，论文扩展了这一结果到对角矩阵和一般权重配置。实验验证了该框架的有效性，为注意力模型的训练提供了新见解。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "math.OC",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "34 pages",
      "pdf_url": "http://arxiv.org/pdf/2403.08699v1",
      "published_date": "2024-03-13 17:02:27 UTC",
      "updated_date": "2024-03-13 17:02:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T15:02:59.023823"
    },
    {
      "arxiv_id": "2403.08688v1",
      "title": "Token Alignment via Character Matching for Subword Completion",
      "title_zh": "翻译失败",
      "authors": [
        "Ben Athiwaratkun",
        "Shiqi Wang",
        "Mingyue Shang",
        "Yuchen Tian",
        "Zijian Wang",
        "Sujan Kumar Gonugondla",
        "Sanjay Krishna Gouda",
        "Rob Kwiatowski",
        "Ramesh Nallapati",
        "Bing Xiang"
      ],
      "abstract": "Generative models, widely utilized in various applications, can often\nstruggle with prompts corresponding to partial tokens. This struggle stems from\ntokenization, where partial tokens fall out of distribution during inference,\nleading to incorrect or nonsensical outputs. This paper examines a technique to\nalleviate the tokenization artifact on text completion in generative models,\nmaintaining performance even in regular non-subword cases. The method, termed\ntoken alignment, involves backtracking to the last complete tokens and ensuring\nthe model's generation aligns with the prompt. This approach showcases marked\nimprovement across many partial token scenarios, including nuanced cases like\nspace-prefix and partial indentation, with only a minor time increase. The\ntechnique and analysis detailed in this paper contribute to the continuous\nadvancement of generative models in handling partial inputs, bearing relevance\nfor applications like code completion and text autocompletion.",
      "tldr_zh": "本文研究了生成模型（Generative models）在处理部分 token 的提示时面临的 tokenization 问题，导致输出错误或无意义。作者提出 Token Alignment 方法，通过字符匹配回溯到最后一个完整 token，并确保模型生成与提示对齐，从而改善了 Subword Completion 的性能。该方法在多种部分 token 场景（如 space-prefix 和 partial indentation）中显著提升准确性，仅带来微小的时间开销，并为代码补全和文本自动补全等应用提供了重要贡献。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.08688v1",
      "published_date": "2024-03-13 16:44:39 UTC",
      "updated_date": "2024-03-13 16:44:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T15:03:10.151972"
    },
    {
      "arxiv_id": "2403.08845v2",
      "title": "Bifurcated Attention: Accelerating Massively Parallel Decoding with Shared Prefixes in LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Ben Athiwaratkun",
        "Sujan Kumar Gonugondla",
        "Sanjay Krishna Gouda",
        "Haifeng Qian",
        "Hantian Ding",
        "Qing Sun",
        "Jun Wang",
        "Jiacheng Guo",
        "Liangfu Chen",
        "Parminder Bhatia",
        "Ramesh Nallapati",
        "Sudipta Sengupta",
        "Bing Xiang"
      ],
      "abstract": "This study introduces bifurcated attention, a method designed to enhance\nlanguage model inference in shared-context batch decoding scenarios. Our\napproach addresses the challenge of redundant memory IO costs, a critical\nfactor contributing to latency in high batch sizes and extended context\nlengths. Bifurcated attention achieves this by strategically dividing the\nattention mechanism during incremental decoding into two separate GEMM\noperations: one focusing on the KV cache from prefill, and another on the\ndecoding process itself. While maintaining the computational load (FLOPs) of\nstandard attention mechanisms, bifurcated attention ensures precise computation\nwith significantly reduced memory IO. Our empirical results show over\n2.1$\\times$ speedup when sampling 16 output sequences and more than 6.2$\\times$\nspeedup when sampling 32 sequences at context lengths exceeding 8k tokens on a\n7B model that uses multi-head attention. The efficiency gains from bifurcated\nattention translate into lower latency, making it particularly suitable for\nreal-time applications. For instance, it enables massively parallel answer\ngeneration without substantially increasing latency, thus enhancing performance\nwhen integrated with post-processing techniques such as re-ranking.",
      "tldr_zh": "这篇论文引入了 bifurcated attention 方法，以加速大型语言模型(LLMs)在共享前缀的批量解码场景中的推理效率，针对冗余内存 IO 成本导致的延迟问题。方法通过将注意力机制分为两个 GEMM 操作——一个处理预填充的 KV cache，另一个专注于解码过程——来减少内存 IO，同时保持标准注意力的计算负载(FLOPs)。实验结果显示，在 7B 模型上，采样 16 个输出序列时加速超过 2.1 倍，采样 32 个序列时超过 6.2 倍，尤其在上下文长度超过 8k tokens 时。这种效率提升降低了延迟，适用于实时应用，如大规模并行答案生成，并可与 re-ranking 等后处理技术结合。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.08845v2",
      "published_date": "2024-03-13 16:30:57 UTC",
      "updated_date": "2024-07-11 20:07:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T15:03:23.762956"
    },
    {
      "arxiv_id": "2403.08844v1",
      "title": "AcademiaOS: Automating Grounded Theory Development in Qualitative Research with Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Thomas Übellacker"
      ],
      "abstract": "AcademiaOS is a first attempt to automate grounded theory development in\nqualitative research with large language models. Using recent large language\nmodels' language understanding, generation, and reasoning capabilities,\nAcademiaOS codes curated qualitative raw data such as interview transcripts and\ndevelops themes and dimensions to further develop a grounded theoretical model,\naffording novel insights. A user study (n=19) suggests that the system finds\nacceptance in the academic community and exhibits the potential to augment\nhumans in qualitative research. AcademiaOS has been made open-source for others\nto build upon and adapt to their use cases.",
      "tldr_zh": "本研究引入了AcademiaOS系统，利用Large Language Models的语言理解、生成和推理能力，自动化定性研究中的Grounded Theory开发过程，包括对访谈记录等原始数据的编码、主题和维度的提取，从而构建Grounded Theoretical Model。系统通过用户研究（n=19）证明了其在学术界的可接受性和潜力，能有效增强人类在定性研究中的工作效率。作为开源工具，AcademiaOS允许他人基于其进行扩展和适应。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.HC",
      "comment": "Live version: https://academia-os.org Source code:\n  https://github.com/thomasuebi/academia-os",
      "pdf_url": "http://arxiv.org/pdf/2403.08844v1",
      "published_date": "2024-03-13 15:54:49 UTC",
      "updated_date": "2024-03-13 15:54:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T15:03:34.339094"
    },
    {
      "arxiv_id": "2403.08635v1",
      "title": "Human Alignment of Large Language Models through Online Preference Optimisation",
      "title_zh": "翻译失败",
      "authors": [
        "Daniele Calandriello",
        "Daniel Guo",
        "Remi Munos",
        "Mark Rowland",
        "Yunhao Tang",
        "Bernardo Avila Pires",
        "Pierre Harvey Richemond",
        "Charline Le Lan",
        "Michal Valko",
        "Tianqi Liu",
        "Rishabh Joshi",
        "Zeyu Zheng",
        "Bilal Piot"
      ],
      "abstract": "Ensuring alignment of language models' outputs with human preferences is\ncritical to guarantee a useful, safe, and pleasant user experience. Thus, human\nalignment has been extensively studied recently and several methods such as\nReinforcement Learning from Human Feedback (RLHF), Direct Policy Optimisation\n(DPO) and Sequence Likelihood Calibration (SLiC) have emerged. In this paper,\nour contribution is two-fold. First, we show the equivalence between two recent\nalignment methods, namely Identity Policy Optimisation (IPO) and Nash Mirror\nDescent (Nash-MD). Second, we introduce a generalisation of IPO, named IPO-MD,\nthat leverages the regularised sampling approach proposed by Nash-MD.\n  This equivalence may seem surprising at first sight, since IPO is an offline\nmethod whereas Nash-MD is an online method using a preference model. However,\nthis equivalence can be proven when we consider the online version of IPO, that\nis when both generations are sampled by the online policy and annotated by a\ntrained preference model. Optimising the IPO loss with such a stream of data\nbecomes then equivalent to finding the Nash equilibrium of the preference model\nthrough self-play. Building on this equivalence, we introduce the IPO-MD\nalgorithm that generates data with a mixture policy (between the online and\nreference policy) similarly as the general Nash-MD algorithm. We compare\nonline-IPO and IPO-MD to different online versions of existing losses on\npreference data such as DPO and SLiC on a summarisation task.",
      "tldr_zh": "本论文探讨了通过在线偏好优化实现大型语言模型(Large Language Models)的人类对齐，以确保模型输出符合人类偏好。作者证明了Identity Policy Optimisation (IPO)和Nash Mirror Descent (Nash-MD)方法的等价性，并引入了IPO的泛化版本IPO-MD，该方法利用正则化采样和混合策略生成数据。实验结果显示，在摘要任务上，online-IPO和IPO-MD与现有方法如Direct Policy Optimisation (DPO)和Sequence Likelihood Calibration (SLiC)相比，表现出更高的性能。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.08635v1",
      "published_date": "2024-03-13 15:47:26 UTC",
      "updated_date": "2024-03-13 15:47:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T15:03:46.416492"
    },
    {
      "arxiv_id": "2403.08618v2",
      "title": "SAP: Corrective Machine Unlearning with Scaled Activation Projection for Label Noise Robustness",
      "title_zh": "翻译失败",
      "authors": [
        "Sangamesh Kodge",
        "Deepak Ravikumar",
        "Gobinda Saha",
        "Kaushik Roy"
      ],
      "abstract": "Label corruption, where training samples are mislabeled due to non-expert\nannotation or adversarial attacks, significantly degrades model performance.\nAcquiring large, perfectly labeled datasets is costly, and retraining models\nfrom scratch is computationally expensive. To address this, we introduce Scaled\nActivation Projection (SAP), a novel SVD (Singular Value Decomposition)-based\ncorrective machine unlearning algorithm. SAP mitigates label noise by\nidentifying a small subset of trusted samples using cross-entropy loss and\nprojecting model weights onto a clean activation space estimated using SVD on\nthese trusted samples. This process suppresses the noise introduced in\nactivations due to the mislabeled samples. In our experiments, we demonstrate\nSAP's effectiveness on synthetic noise with different settings and real-world\nlabel noise. SAP applied to the CIFAR dataset with 25% synthetic corruption\nshow upto 6% generalization improvements. Additionally, SAP can improve the\ngeneralization over noise robust training approaches on CIFAR dataset by ~3.2%\non average. Further, we observe generalization improvements of 2.31% for a\nVision Transformer model trained on naturally corrupted Clothing1M.",
      "tldr_zh": "这篇论文提出了一种名为 Scaled Activation Projection (SAP) 的校正机器遗忘算法，利用 SVD (Singular Value Decomposition) 来提升模型对标签噪声的鲁棒性。SAP 通过识别交叉熵损失下的可信样本，并将模型权重投影到基于这些样本估计的干净激活空间，从而抑制误标签带来的噪声影响。实验结果显示，在 CIFAR 数据集上，SAP 在 25% 合成噪声场景下提高了 6% 的泛化性能，比传统噪声鲁棒训练方法平均提升 3.2%；此外，在实际噪声数据集 Clothing1M 上，Vision Transformer 模型的泛化性能提升了 2.31%。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.08618v2",
      "published_date": "2024-03-13 15:32:08 UTC",
      "updated_date": "2025-01-02 15:08:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T15:03:59.733962"
    },
    {
      "arxiv_id": "2403.08613v1",
      "title": "Link Prediction for Social Networks using Representation Learning and Heuristic-based Features",
      "title_zh": "翻译失败",
      "authors": [
        "Samarth Khanna",
        "Sree Bhattacharyya",
        "Sudipto Ghosh",
        "Kushagra Agarwal",
        "Asit Kumar Das"
      ],
      "abstract": "The exponential growth in scale and relevance of social networks enable them\nto provide expansive insights. Predicting missing links in social networks\nefficiently can help in various modern-day business applications ranging from\ngenerating recommendations to influence analysis. Several categories of\nsolutions exist for the same. Here, we explore various feature extraction\ntechniques to generate representations of nodes and edges in a social network\nthat allow us to predict missing links. We compare the results of using ten\nfeature extraction techniques categorized across Structural embeddings,\nNeighborhood-based embeddings, Graph Neural Networks, and Graph Heuristics,\nfollowed by modeling with ensemble classifiers and custom Neural Networks.\nFurther, we propose combining heuristic-based features and learned\nrepresentations that demonstrate improved performance for the link prediction\ntask on social network datasets. Using this method to generate accurate\nrecommendations for many applications is a matter of further study that appears\nvery promising. The code for all the experiments has been made public.",
      "tldr_zh": "该研究探讨了社交网络的链接预测（Link Prediction），通过各种特征提取技术生成节点和边的表示（Representation Learning）。作者比较了十种技术，包括结构嵌入（Structural embeddings）、基于邻域的嵌入（Neighborhood-based embeddings）、图神经网络（Graph Neural Networks）和图启发式方法（Graph Heuristics），并使用集成分类器和自定义神经网络进行建模。论文提出了一种结合启发式特征（Heuristic-based Features）和学习表示的新方法，在社交网络数据集上实现了性能提升。实验结果显示该方法前景广阔，可用于推荐系统等领域，相关代码已公开以便进一步研究。",
      "categories": [
        "cs.SI",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.SI",
      "comment": "Accepted to the MAISoN Workshop at IJCAI 2023",
      "pdf_url": "http://arxiv.org/pdf/2403.08613v1",
      "published_date": "2024-03-13 15:23:55 UTC",
      "updated_date": "2024-03-13 15:23:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T15:04:11.350500"
    },
    {
      "arxiv_id": "2403.08607v1",
      "title": "MedInsight: A Multi-Source Context Augmentation Framework for Generating Patient-Centric Medical Responses using Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Subash Neupane",
        "Shaswata Mitra",
        "Sudip Mittal",
        "Noorbakhsh Amiri Golilarz",
        "Shahram Rahimi",
        "Amin Amirlatifi"
      ],
      "abstract": "Large Language Models (LLMs) have shown impressive capabilities in generating\nhuman-like responses. However, their lack of domain-specific knowledge limits\ntheir applicability in healthcare settings, where contextual and comprehensive\nresponses are vital. To address this challenge and enable the generation of\npatient-centric responses that are contextually relevant and comprehensive, we\npropose MedInsight:a novel retrieval augmented framework that augments LLM\ninputs (prompts) with relevant background information from multiple sources.\nMedInsight extracts pertinent details from the patient's medical record or\nconsultation transcript. It then integrates information from authoritative\nmedical textbooks and curated web resources based on the patient's health\nhistory and condition. By constructing an augmented context combining the\npatient's record with relevant medical knowledge, MedInsight generates\nenriched, patient-specific responses tailored for healthcare applications such\nas diagnosis, treatment recommendations, or patient education. Experiments on\nthe MTSamples dataset validate MedInsight's effectiveness in generating\ncontextually appropriate medical responses. Quantitative evaluation using the\nRagas metric and TruLens for answer similarity and answer correctness\ndemonstrates the model's efficacy. Furthermore, human evaluation studies\ninvolving Subject Matter Expert (SMEs) confirm MedInsight's utility, with\nmoderate inter-rater agreement on the relevance and correctness of the\ngenerated responses.",
      "tldr_zh": "该研究提出MedInsight框架，一种多源上下文增强方法，用于提升Large Language Models (LLMs)在医疗领域的性能，通过检索相关背景信息生成以患者为中心的响应。MedInsight从患者医疗记录或咨询记录中提取关键细节，并整合权威医疗教科书和网络资源的知识，构建增强的上下文以支持诊断、治疗推荐和患者教育。实验在MTSamples数据集上验证了其有效性，使用Ragas metric和TruLens评估显示了答案相似性和正确性的显著改善，而人类评估由Subject Matter Expert (SMEs)进行，确认了生成的响应在相关性和准确性方面的实用性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.08607v1",
      "published_date": "2024-03-13 15:20:30 UTC",
      "updated_date": "2024-03-13 15:20:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T15:04:23.324145"
    },
    {
      "arxiv_id": "2403.08593v2",
      "title": "Call Me When Necessary: LLMs can Efficiently and Faithfully Reason over Structured Environments",
      "title_zh": "必要时再呼叫我：LLMs 能够高效且可靠地在结构化环境中进行推理",
      "authors": [
        "Sitao Cheng",
        "Ziyuan Zhuang",
        "Yong Xu",
        "Fangkai Yang",
        "Chaoyun Zhang",
        "Xiaoting Qin",
        "Xiang Huang",
        "Ling Chen",
        "Qingwei Lin",
        "Dongmei Zhang",
        "Saravan Rajmohan",
        "Qi Zhang"
      ],
      "abstract": "Large Language Models (LLMs) have shown potential in reasoning over\nstructured environments, e.g., knowledge graph and table. Such tasks typically\nrequire multi-hop reasoning, i.e., match natural language utterance with\ninstances in the environment. Previous methods leverage LLMs to incrementally\nbuild a reasoning path, where the LLMs either invoke tools or pick up schemas\nby step-by-step interacting with the environment. We propose\nReasoning-Path-Editing (Readi), a novel framework where LLMs can efficiently\nand faithfully reason over structured environments. In Readi, LLMs initially\ngenerate a reasoning path given a query, and edit the path only when necessary.\nWe instantiate the path on structured environments and provide feedback to edit\nthe path if anything goes wrong. Experimental results on three KGQA and two\nTableQA datasets show the effectiveness of Readi, significantly surpassing\nprevious LLM-based methods (by 9.1% Hit@1 on WebQSP, 12.4% on MQA-3H and 9.5%\non WTQ), comparable with state-of-the-art fine-tuned methods (67% on CWQ and\n74.7% on WebQSP) and substantially boosting the vanilla LLMs (by 14.9% on CWQ).\nOur code will be available on https://aka.ms/readi.",
      "tldr_zh": "本研究探讨Large Language Models (LLMs) 在结构化环境（如知识图谱和表格）中的多跳推理问题，提出了一种高效且可靠的框架Reasoning-Path-Editing (Readi)。在Readi中，LLMs先生成初始推理路径，然后仅在必要时通过环境反馈进行编辑，从而避免了步步互动的低效。实验结果显示，Readi在KGQA数据集（如WebQSP上Hit@1提高9.1%、MQA-3H上提高12.4%）和TableQA数据集（如WTQ上提高9.5%）上显著优于现有LLM方法，与最先进微调模型相当，并将原始LLMs性能提升14.9%。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted by ACL 2024 Findings. 21 pages, 7 figures, 17 tables",
      "pdf_url": "http://arxiv.org/pdf/2403.08593v2",
      "published_date": "2024-03-13 14:59:07 UTC",
      "updated_date": "2024-07-03 15:23:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T15:04:36.069747"
    },
    {
      "arxiv_id": "2403.08843v1",
      "title": "Fuzzy Fault Trees Formalized",
      "title_zh": "模糊故障树形式化",
      "authors": [
        "Thi Kim Nhung Dang",
        "Milan Lopuhaä-Zwakenberg",
        "Mariëlle Stoelinga"
      ],
      "abstract": "Fault tree analysis is a vital method of assessing safety risks. It helps to\nidentify potential causes of accidents, assess their likelihood and severity,\nand suggest preventive measures. Quantitative analysis of fault trees is often\ndone via the dependability metrics that compute the system's failure behaviour\nover time. However, the lack of precise data is a major obstacle to\nquantitative analysis, and so to reliability analysis. Fuzzy logic is a popular\nframework for dealing with ambiguous values and has applications in many\ndomains. A number of fuzzy approaches have been proposed to fault tree\nanalysis, but -- to the best of our knowledge -- none of them provide rigorous\ndefinitions or algorithms for computing fuzzy unreliability values. In this\npaper, we define a rigorous framework for fuzzy unreliability values. In\naddition, we provide a bottom-up algorithm to efficiently calculate fuzzy\nreliability for a system. The algorithm incorporates the concept of\n$\\alpha$-cuts method. That is, performing binary algebraic operations on\nintervals on horizontally discretised $\\alpha$-cut representations of fuzzy\nnumbers. The method preserves the nonlinearity of fuzzy unreliability. Finally,\nwe illustrate the results obtained from two case studies.",
      "tldr_zh": "该论文正式化了模糊故障树（Fuzzy Fault Trees）分析框架，以解决传统故障树分析（Fault tree analysis）中数据不精确导致的量化困难。作者定义了严格的模糊不可靠性值（fuzzy unreliability values）框架，并提出一个自底向上的算法，利用 α-cuts 方法对模糊数的水平离散表示进行二元代数运算，从而高效计算系统的模糊可靠性，同时保留其非线性。实验通过两个案例研究验证了该方法的有效性，为处理模糊数据的安全风险评估提供了可靠工具。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "14 pages",
      "pdf_url": "http://arxiv.org/pdf/2403.08843v1",
      "published_date": "2024-03-13 14:45:54 UTC",
      "updated_date": "2024-03-13 14:45:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T15:04:47.018031"
    },
    {
      "arxiv_id": "2403.09735v1",
      "title": "A Sophisticated Framework for the Accurate Detection of Phishing Websites",
      "title_zh": "翻译失败",
      "authors": [
        "Asif Newaz",
        "Farhan Shahriyar Haq",
        "Nadim Ahmed"
      ],
      "abstract": "Phishing is an increasingly sophisticated form of cyberattack that is\ninflicting huge financial damage to corporations throughout the globe while\nalso jeopardizing individuals' privacy. Attackers are constantly devising new\nmethods of launching such assaults and detecting them has become a daunting\ntask. Many different techniques have been suggested, each with its own pros and\ncons. While machine learning-based techniques have been most successful in\nidentifying such attacks, they continue to fall short in terms of performance\nand generalizability. This paper proposes a comprehensive methodology for\ndetecting phishing websites. The goal is to design a system that is capable of\naccurately distinguishing phishing websites from legitimate ones and provides\ngeneralized performance over a broad variety of datasets. A combination of\nfeature selection, greedy algorithm, cross-validation, and deep learning\nmethods have been utilized to construct a sophisticated stacking ensemble\nclassifier. Extensive experimentation on four different phishing datasets was\nconducted to evaluate the performance of the proposed technique. The proposed\nalgorithm outperformed the other existing phishing detection models obtaining\naccuracy of 97.49%, 98.23%, 97.48%, and 98.20% on dataset-1 (UCI Phishing\nWebsites Dataset), dataset-2 (Phishing Dataset for Machine Learning: Feature\nEvaluation), dataset-3 (Phishing Websites Dataset), and dataset-4 (Web page\nphishing detection), respectively. The high accuracy values obtained across all\ndatasets imply the models' generalizability and effectiveness in the accurate\nidentification of phishing websites.",
      "tldr_zh": "这篇论文针对日益复杂的网络钓鱼(Phishing)攻击及其对企业和个人隐私的威胁，提出了一种先进的框架，用于准确区分钓鱼网站和合法网站。框架结合了特征选择(feature selection)、贪婪算法(greedy algorithm)、交叉验证(cross-validation)和深度学习方法，构建了一个复杂的堆叠集成分类器(stacking ensemble classifier)，以提升检测性能和泛化能力。在四个不同数据集上的实验中，该方法分别取得了97.49%、98.23%、97.48%和98.20%的准确率，显著优于现有模型，并证明了其有效性。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.09735v1",
      "published_date": "2024-03-13 14:26:25 UTC",
      "updated_date": "2024-03-13 14:26:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T15:05:00.032916"
    },
    {
      "arxiv_id": "2403.08564v3",
      "title": "Generalizing Fairness to Generative Language Models via Reformulation of Non-discrimination Criteria",
      "title_zh": "翻译失败",
      "authors": [
        "Sara Sterlie",
        "Nina Weng",
        "Aasa Feragen"
      ],
      "abstract": "Generative AI, such as large language models, has undergone rapid development\nwithin recent years. As these models become increasingly available to the\npublic, concerns arise about perpetuating and amplifying harmful biases in\napplications. Gender stereotypes can be harmful and limiting for the\nindividuals they target, whether they consist of misrepresentation or\ndiscrimination. Recognizing gender bias as a pervasive societal construct, this\npaper studies how to uncover and quantify the presence of gender biases in\ngenerative language models. In particular, we derive generative AI analogues of\nthree well-known non-discrimination criteria from classification, namely\nindependence, separation and sufficiency. To demonstrate these criteria in\naction, we design prompts for each of the criteria with a focus on occupational\ngender stereotype, specifically utilizing the medical test to introduce the\nground truth in the generative AI context. Our results address the presence of\noccupational gender bias within such conversational language models.",
      "tldr_zh": "这篇论文探讨了如何将公平性扩展到生成式语言模型中，针对性别偏见问题，通过改革分类任务中的非歧视标准（independence、separation和sufficiency）。作者定义了这些标准的生成AI版本，并设计了针对职业性别刻板印象的提示，使用医疗测试作为真实性基准来检测偏见。实验结果揭示了对话语言模型中存在的显著职业性别偏见，为缓解AI中的有害偏见提供了量化方法。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.08564v3",
      "published_date": "2024-03-13 14:19:08 UTC",
      "updated_date": "2024-09-02 11:09:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T15:05:11.836760"
    },
    {
      "arxiv_id": "2403.08562v1",
      "title": "Structural perspective on constraint-based learning of Markov networks",
      "title_zh": "基于约束的学习马尔可夫网络的结构视角",
      "authors": [
        "Tuukka Korhonen",
        "Fedor V. Fomin",
        "Pekka Parviainen"
      ],
      "abstract": "Markov networks are probabilistic graphical models that employ undirected\ngraphs to depict conditional independence relationships among variables. Our\nfocus lies in constraint-based structure learning, which entails learning the\nundirected graph from data through the execution of conditional independence\ntests. We establish theoretical limits concerning two critical aspects of\nconstraint-based learning of Markov networks: the number of tests and the sizes\nof the conditioning sets. These bounds uncover an exciting interplay between\nthe structural properties of the graph and the amount of tests required to\nlearn a Markov network. The starting point of our work is that the graph\nparameter maximum pairwise connectivity, $\\kappa$, that is, the maximum number\nof vertex-disjoint paths connecting a pair of vertices in the graph, is\nresponsible for the sizes of independence tests required to learn the graph. On\none hand, we show that at least one test with the size of the conditioning set\nat least $\\kappa$ is always necessary. On the other hand, we prove that any\ngraph can be learned by performing tests of size at most $\\kappa$. This\ncompletely resolves the question of the minimum size of conditioning sets\nrequired to learn the graph. When it comes to the number of tests, our upper\nbound on the sizes of conditioning sets implies that every $n$-vertex graph can\nbe learned by at most $n^{\\kappa}$ tests with conditioning sets of sizes at\nmost $\\kappa$. We show that for any upper bound $q$ on the sizes of the\nconditioning sets, there exist graphs with $O(n q)$ vertices that require at\nleast $n^{\\Omega(\\kappa)}$ tests to learn. This lower bound holds even when the\ntreewidth and the maximum degree of the graph are at most $\\kappa+2$. On the\npositive side, we prove that every graph of bounded treewidth can be learned by\na polynomial number of tests with conditioning sets of sizes at most $2\\kappa$.",
      "tldr_zh": "本论文探讨了基于约束的 Markov 网络结构学习，聚焦于从数据中通过条件独立测试学习无向图。论文引入最大成对连通性参数 κ，证明至少需要一个条件集大小至少 κ 的测试，且任何图均可通过大小最多 κ 的测试学习，从而完全解析了最小条件集大小问题。对于 n 顶点图，测试数量上限为 n^κ；同时，某些图需至少 n^Ω(κ) 测试，即使 treewidth 和最大度不超过 κ+2。论文进一步证明，有界 treewidth 的图可通过多项式数量的测试（条件集大小最多 2κ）学习，为高效学习 Markov 网络提供了结构洞见。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DM"
      ],
      "primary_category": "cs.LG",
      "comment": "AISTATS 2024",
      "pdf_url": "http://arxiv.org/pdf/2403.08562v1",
      "published_date": "2024-03-13 14:14:47 UTC",
      "updated_date": "2024-03-13 14:14:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T15:05:24.611624"
    },
    {
      "arxiv_id": "2403.08556v2",
      "title": "SM4Depth: Seamless Monocular Metric Depth Estimation across Multiple Cameras and Scenes by One Model",
      "title_zh": "SM4Depth：通过一个",
      "authors": [
        "Yihao Liu",
        "Feng Xue",
        "Anlong Ming",
        "Mingshuai Zhao",
        "Huadong Ma",
        "Nicu Sebe"
      ],
      "abstract": "In the last year, universal monocular metric depth estimation (universal\nMMDE) has gained considerable attention, serving as the foundation model for\nvarious multimedia tasks, such as video and image editing. Nonetheless, current\napproaches face challenges in maintaining consistent accuracy across diverse\nscenes without scene-specific parameters and pre-training, hindering the\npracticality of MMDE. Furthermore, these methods rely on extensive datasets\ncomprising millions, if not tens of millions, of data for training, leading to\nsignificant time and hardware expenses. This paper presents SM$^4$Depth, a\nmodel that seamlessly works for both indoor and outdoor scenes, without needing\nextensive training data and GPU clusters. Firstly, to obtain consistent depth\nacross diverse scenes, we propose a novel metric scale modeling, i.e.,\nvariation-based unnormalized depth bins. It reduces the ambiguity of the\nconventional metric bins and enables better adaptation to large depth gaps of\nscenes during training. Secondly, we propose a \"divide and conquer\" solution to\nreduce reliance on massive training data. Instead of estimating directly from\nthe vast solution space, the metric bins are estimated from multiple solution\nsub-spaces to reduce complexity. Additionally, we introduce an uncut depth\ndataset, BUPT Depth, to evaluate the depth accuracy and consistency across\nvarious indoor and outdoor scenes. Trained on a consumer-grade GPU using just\n150K RGB-D pairs, SM$^4$Depth achieves outstanding performance on the most\nnever-before-seen datasets, especially maintaining consistent accuracy across\nindoors and outdoors. The code can be found\nhttps://github.com/mRobotit/SM4Depth.",
      "tldr_zh": "该论文提出SM4Depth模型，实现无缝单目度量深度估计（monocular metric depth estimation），适用于多个相机和室内外场景，而无需场景特定参数或海量训练数据。核心创新包括variation-based unnormalized depth bins方法，以减少深度bins的模糊性并适应不同场景的深度差距，以及“divide and conquer”策略，通过在多个子空间估计度量bins来降低训练复杂度。实验显示，该模型仅使用150K RGB-D pairs在消费级GPU上训练，即在从未见过的测试数据集上表现出色，尤其在室内外场景中保持一致的高准确性，并引入BUPT Depth数据集用于评估。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by ACM MultiMedia 24, Project Page:\n  xuefeng-cvr.github.io/SM4Depth",
      "pdf_url": "http://arxiv.org/pdf/2403.08556v2",
      "published_date": "2024-03-13 14:08:25 UTC",
      "updated_date": "2024-08-15 03:30:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T15:05:35.804911"
    },
    {
      "arxiv_id": "2403.14685v1",
      "title": "Cyclical Log Annealing as a Learning Rate Scheduler",
      "title_zh": "循环对数退火作为学习率调度器",
      "authors": [
        "Philip Naveen"
      ],
      "abstract": "A learning rate scheduler is a predefined set of instructions for varying\nsearch stepsizes during model training processes. This paper introduces a new\nlogarithmic method using harsh restarting of step sizes through stochastic\ngradient descent. Cyclical log annealing implements the restart pattern more\naggressively to maybe allow the usage of more greedy algorithms on the online\nconvex optimization framework. The algorithm was tested on the CIFAR-10 image\ndatasets, and seemed to perform analogously with cosine annealing on large\ntransformer-enhanced residual neural networks. Future experiments would involve\ntesting the scheduler in generative adversarial networks and finding the best\nparameters for the scheduler with more experiments.",
      "tldr_zh": "本文提出了一种新的学习率调度器，名为 Cyclical Log Annealing，通过对数方法和严厉的重启（harsh restarting）来调整随机梯度下降（stochastic gradient descent）中的步长，从而可能支持在线凸优化框架中使用更贪婪的算法。在 CIFAR-10 数据集上的实验显示，该调度器在大规模 Transformer 增强的残差神经网络上与 Cosine Annealing 表现类似。未来工作包括测试其在 Generative Adversarial Networks 中的应用，并通过更多实验优化参数。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.14685v1",
      "published_date": "2024-03-13 14:07:20 UTC",
      "updated_date": "2024-03-13 14:07:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T15:05:58.455977"
    },
    {
      "arxiv_id": "2403.08554v1",
      "title": "Federated Knowledge Graph Unlearning via Diffusion Model",
      "title_zh": "基于扩散模型的联邦知识图谱遗忘",
      "authors": [
        "Bingchen Liu",
        "Yuanyuan Fang"
      ],
      "abstract": "Federated learning (FL) promotes the development and application of\nartificial intelligence technologies by enabling model sharing and\ncollaboration while safeguarding data privacy. Knowledge graph (KG) embedding\nrepresentation provides a foundation for knowledge reasoning and applications\nby mapping entities and relations into vector space. Federated KG embedding\nenables the utilization of knowledge from diverse client sources while\nsafeguarding the privacy of local data. However, due to demands such as privacy\nprotection and the need to adapt to dynamic data changes, investigations into\nmachine unlearning (MU) have been sparked. However, it is challenging to\nmaintain the performance of KG embedding models while forgetting the influence\nof specific forgotten data on the model. In this paper, we propose FedDM, a\nnovel framework tailored for machine unlearning in federated knowledge graphs.\nLeveraging diffusion models, we generate noisy data to sensibly mitigate the\ninfluence of specific knowledge on FL models while preserving the overall\nperformance concerning the remaining data. We conduct experimental evaluations\non benchmark datasets to assess the efficacy of the proposed model. Extensive\nexperiments demonstrate that FedDM yields promising results in knowledge\nforgetting.",
      "tldr_zh": "该论文探讨了联邦学习（FL）中知识图（KG）嵌入的机器遗忘（MU）问题，旨在在保护数据隐私的同时处理动态数据变化。作者提出FedDM框架，利用扩散模型生成噪声数据，以有效减轻特定知识对FL模型的影响，同时保持剩余数据的整体性能。实验结果表明，FedDM在基准数据集上表现出色，在知识遗忘任务中取得了显著的成效。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.08554v1",
      "published_date": "2024-03-13 14:06:51 UTC",
      "updated_date": "2024-03-13 14:06:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T15:06:21.851315"
    },
    {
      "arxiv_id": "2403.08551v5",
      "title": "GaussianImage: 1000 FPS Image Representation and Compression by 2D Gaussian Splatting",
      "title_zh": "翻译失败",
      "authors": [
        "Xinjie Zhang",
        "Xingtong Ge",
        "Tongda Xu",
        "Dailan He",
        "Yan Wang",
        "Hongwei Qin",
        "Guo Lu",
        "Jing Geng",
        "Jun Zhang"
      ],
      "abstract": "Implicit neural representations (INRs) recently achieved great success in\nimage representation and compression, offering high visual quality and fast\nrendering speeds with 10-1000 FPS, assuming sufficient GPU resources are\navailable. However, this requirement often hinders their use on low-end devices\nwith limited memory. In response, we propose a groundbreaking paradigm of image\nrepresentation and compression by 2D Gaussian Splatting, named GaussianImage.\nWe first introduce 2D Gaussian to represent the image, where each Gaussian has\n8 parameters including position, covariance and color. Subsequently, we unveil\na novel rendering algorithm based on accumulated summation. Remarkably, our\nmethod with a minimum of 3$\\times$ lower GPU memory usage and 5$\\times$ faster\nfitting time not only rivals INRs (e.g., WIRE, I-NGP) in representation\nperformance, but also delivers a faster rendering speed of 1500-2000 FPS\nregardless of parameter size. Furthermore, we integrate existing vector\nquantization technique to build an image codec. Experimental results\ndemonstrate that our codec attains rate-distortion performance comparable to\ncompression-based INRs such as COIN and COIN++, while facilitating decoding\nspeeds of approximately 2000 FPS. Additionally, preliminary proof of concept\nshows that our codec surpasses COIN and COIN++ in performance when using\npartial bits-back coding. Code is available at\nhttps://github.com/Xinjie-Q/GaussianImage.",
      "tldr_zh": "本研究提出GaussianImage，一种基于2D Gaussian Splatting的图像表示和压缩新范式，使用每个Gaussian的8个参数（包括位置、协方差和颜色）来表示图像，并引入基于累积求和的渲染算法。相比隐式神经表示(INRs)如WIRE和I-NGP，该方法在降低至少3倍GPU内存使用和5倍拟合时间的同时，实现1500-2000 FPS的渲染速度，并在表示性能上不相上下。进一步整合向量量化技术构建图像编解码器，实验显示其速率-失真性能与COIN和COIN++相当，但解码速度达约2000 FPS；在部分bits-back编码场景下，GaussianImage的性能优于现有方法。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV",
        "cs.MM"
      ],
      "primary_category": "eess.IV",
      "comment": "Accepted by ECCV 2024. Project\n  Page:https://xingtongge.github.io/GaussianImage-page/ Code:\n  https://github.com/Xinjie-Q/GaussianImage",
      "pdf_url": "http://arxiv.org/pdf/2403.08551v5",
      "published_date": "2024-03-13 14:02:54 UTC",
      "updated_date": "2024-07-09 15:48:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T15:06:23.992989"
    },
    {
      "arxiv_id": "2403.08536v1",
      "title": "HOLMES: HOLonym-MEronym based Semantic inspection for Convolutional Image Classifiers",
      "title_zh": "翻译失败",
      "authors": [
        "Francesco Dibitonto",
        "Fabio Garcea",
        "André Panisson",
        "Alan Perotti",
        "Lia Morra"
      ],
      "abstract": "Convolutional Neural Networks (CNNs) are nowadays the model of choice in\nComputer Vision, thanks to their ability to automatize the feature extraction\nprocess in visual tasks. However, the knowledge acquired during training is\nfully subsymbolic, and hence difficult to understand and explain to end users.\nIn this paper, we propose a new technique called HOLMES (HOLonym-MEronym based\nSemantic inspection) that decomposes a label into a set of related concepts,\nand provides component-level explanations for an image classification model.\nSpecifically, HOLMES leverages ontologies, web scraping and transfer learning\nto automatically construct meronym (parts)-based detectors for a given holonym\n(class). Then, it produces heatmaps at the meronym level and finally, by\nprobing the holonym CNN with occluded images, it highlights the importance of\neach part on the classification output. Compared to state-of-the-art saliency\nmethods, HOLMES takes a step further and provides information about both where\nand what the holonym CNN is looking at, without relying on densely annotated\ndatasets and without forcing concepts to be associated to single computational\nunits. Extensive experimental evaluation on different categories of objects\n(animals, tools and vehicles) shows the feasibility of our approach. On\naverage, HOLMES explanations include at least two meronyms, and the ablation of\na single meronym roughly halves the holonym model confidence. The resulting\nheatmaps were quantitatively evaluated using the\ndeletion/insertion/preservation curves. All metrics were comparable to those\nachieved by GradCAM, while offering the advantage of further decomposing the\nheatmap in human-understandable concepts, thus highlighting both the relevance\nof meronyms to object classification, as well as HOLMES ability to capture it.\nThe code is available at https://github.com/FrancesC0de/HOLMES.",
      "tldr_zh": "本论文提出HOLMES，一种基于holonym（整体概念）和meronym（部分概念）的语义检查技术，用于解释Convolutional Neural Networks (CNNs)在图像分类中的决策过程。HOLMES通过将标签分解成相关概念，利用本体论、网页抓取和迁移学习自动构建meronym检测器，并生成meronym级别的热力图，同时通过遮挡图像评估每个部分的分类重要性。与现有saliency方法如GradCAM相比，HOLMES不仅显示模型关注的位置，还提供具体概念解释，而无需密集标注数据集。实验在动物、工具和车辆类别上验证了其可行性，移除单个meronym可使模型置信度降低约一半，且热力图指标与GradCAM相当，但增加了人类可理解的概念分解。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "This work has been accepted to be presented to The 1st World\n  Conference on eXplainable Artificial Intelligence (xAI 2023), July 26-28,\n  2023 - Lisboa, Portugal",
      "pdf_url": "http://arxiv.org/pdf/2403.08536v1",
      "published_date": "2024-03-13 13:51:02 UTC",
      "updated_date": "2024-03-13 13:51:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T15:06:36.626865"
    },
    {
      "arxiv_id": "2403.08528v1",
      "title": "Pig aggression classification using CNN, Transformers and Recurrent Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Junior Silva Souza",
        "Eduardo Bedin",
        "Gabriel Toshio Hirokawa Higa",
        "Newton Loebens",
        "Hemerson Pistori"
      ],
      "abstract": "The development of techniques that can be used to analyze and detect animal\nbehavior is a crucial activity for the livestock sector, as it is possible to\nmonitor the stress and animal welfare and contributes to decision making in the\nfarm. Thus, the development of applications can assist breeders in making\ndecisions to improve production performance and reduce costs, once the animal\nbehavior is analyzed by humans and this can lead to susceptible errors and time\nconsumption. Aggressiveness in pigs is an example of behavior that is studied\nto reduce its impact through animal classification and identification. However,\nthis process is laborious and susceptible to errors, which can be reduced\nthrough automation by visually classifying videos captured in controlled\nenvironment. The captured videos can be used for training and, as a result, for\nclassification through computer vision and artificial intelligence, employing\nneural network techniques. The main techniques utilized in this study are\nvariants of transformers: STAM, TimeSformer, and ViViT, as well as techniques\nusing convolutions, such as ResNet3D2, Resnet(2+1)D, and CnnLstm. These\ntechniques were employed for pig video classification with the objective of\nidentifying aggressive and non-aggressive behaviors. In this work, various\ntechniques were compared to analyze the contribution of using transformers, in\naddition to the effectiveness of the convolution technique in video\nclassification. The performance was evaluated using accuracy, precision, and\nrecall. The TimerSformer technique showed the best results in video\nclassification, with median accuracy of 0.729.",
      "tldr_zh": "本研究旨在通过计算机视觉和人工智能自动检测猪的攻击行为，以改善畜牧业中的动物福利决策，减少传统人工分析的错误和耗时问题。主要方法包括使用Transformer变体（如STAM、TimeSformer和ViViT）以及卷积网络（如ResNet3D2、Resnet(2+1)D和CnnLstm）对猪视频进行分类，并比较这些技术的性能。实验结果显示，TimeSformer在准确率、精确率和召回率指标上表现出色，达到0.729的中位准确率，证明了其在视频行为分类中的有效性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.08528v1",
      "published_date": "2024-03-13 13:38:58 UTC",
      "updated_date": "2024-03-13 13:38:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T15:06:47.850914"
    },
    {
      "arxiv_id": "2403.08505v5",
      "title": "CAMSIC: Content-aware Masked Image Modeling Transformer for Stereo Image Compression",
      "title_zh": "翻译失败",
      "authors": [
        "Xinjie Zhang",
        "Shenyuan Gao",
        "Zhening Liu",
        "Jiawei Shao",
        "Xingtong Ge",
        "Dailan He",
        "Tongda Xu",
        "Yan Wang",
        "Jun Zhang"
      ],
      "abstract": "Existing learning-based stereo image codec adopt sophisticated transformation\nwith simple entropy models derived from single image codecs to encode latent\nrepresentations. However, those entropy models struggle to effectively capture\nthe spatial-disparity characteristics inherent in stereo images, which leads to\nsuboptimal rate-distortion results. In this paper, we propose a stereo image\ncompression framework, named CAMSIC. CAMSIC independently transforms each image\nto latent representation and employs a powerful decoder-free Transformer\nentropy model to capture both spatial and disparity dependencies, by\nintroducing a novel content-aware masked image modeling (MIM) technique. Our\ncontent-aware MIM facilitates efficient bidirectional interaction between prior\ninformation and estimated tokens, which naturally obviates the need for an\nextra Transformer decoder. Experiments show that our stereo image codec\nachieves state-of-the-art rate-distortion performance on two stereo image\ndatasets Cityscapes and InStereo2K with fast encoding and decoding speed. Code\nis available at https://github.com/Xinjie-Q/CAMSIC.",
      "tldr_zh": "论文提出 CAMSIC，一种用于立体图像压缩的框架，针对现有方法在捕捉立体图像的空间-视差特性方面存在的不足，采用了 content-aware masked image modeling (MIM) 技术和无解码器 Transformer 熵模型。CAMSIC 通过独立转换图像为潜在表示，并实现先验信息与估计标记之间的高效双向交互，从而无需额外解码器，提高了压缩效率。实验结果显示，该框架在 Cityscapes 和 InStereo2K 数据集上实现了最先进的 rate-distortion 性能，同时保持快速的编码和解码速度。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV",
        "cs.MM"
      ],
      "primary_category": "eess.IV",
      "comment": "Accepted by AAAI 2025",
      "pdf_url": "http://arxiv.org/pdf/2403.08505v5",
      "published_date": "2024-03-13 13:12:57 UTC",
      "updated_date": "2025-02-08 09:33:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T15:07:00.488803"
    },
    {
      "arxiv_id": "2403.08502v1",
      "title": "Masked Generative Story Transformer with Character Guidance and Caption Augmentation",
      "title_zh": "翻译失败",
      "authors": [
        "Christos Papadimitriou",
        "Giorgos Filandrianos",
        "Maria Lymperaiou",
        "Giorgos Stamou"
      ],
      "abstract": "Story Visualization (SV) is a challenging generative vision task, that\nrequires both visual quality and consistency between different frames in\ngenerated image sequences. Previous approaches either employ some kind of\nmemory mechanism to maintain context throughout an auto-regressive generation\nof the image sequence, or model the generation of the characters and their\nbackground separately, to improve the rendering of characters. On the contrary,\nwe embrace a completely parallel transformer-based approach, exclusively\nrelying on Cross-Attention with past and future captions to achieve\nconsistency. Additionally, we propose a Character Guidance technique to focus\non the generation of characters in an implicit manner, by forming a combination\nof text-conditional and character-conditional logits in the logit space. We\nalso employ a caption-augmentation technique, carried out by a Large Language\nModel (LLM), to enhance the robustness of our approach. The combination of\nthese methods culminates into state-of-the-art (SOTA) results over various\nmetrics in the most prominent SV benchmark (Pororo-SV), attained with\nconstraint resources while achieving superior computational complexity compared\nto previous arts. The validity of our quantitative results is supported by a\nhuman survey.",
      "tldr_zh": "本文提出了一种 Masked Generative Story Transformer 方法，用于 Story Visualization (SV) 任务，通过 Cross-Attention 与过去和未来的标题实现图像序列的一致性，同时采用完全并行的 transformer-based 框架。作者引入了 Character Guidance 技术，在 logit 空间结合 text-conditional 和 character-conditional 信息来隐式优化人物生成，并使用 Large Language Model (LLM) 进行 caption-augmentation 以增强模型鲁棒性。该方法在 Pororo-SV 基准上达到了 state-of-the-art (SOTA) 结果，使用有限资源并显示出更好的计算复杂度，且通过人类调查验证了其有效性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.08502v1",
      "published_date": "2024-03-13 13:10:20 UTC",
      "updated_date": "2024-03-13 13:10:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T15:07:12.447744"
    },
    {
      "arxiv_id": "2403.08840v1",
      "title": "NoiseDiffusion: Correcting Noise for Image Interpolation with Diffusion Models beyond Spherical Linear Interpolation",
      "title_zh": "翻译失败",
      "authors": [
        "PengFei Zheng",
        "Yonggang Zhang",
        "Zhen Fang",
        "Tongliang Liu",
        "Defu Lian",
        "Bo Han"
      ],
      "abstract": "Image interpolation based on diffusion models is promising in creating fresh\nand interesting images. Advanced interpolation methods mainly focus on\nspherical linear interpolation, where images are encoded into the noise space\nand then interpolated for denoising to images. However, existing methods face\nchallenges in effectively interpolating natural images (not generated by\ndiffusion models), thereby restricting their practical applicability. Our\nexperimental investigations reveal that these challenges stem from the\ninvalidity of the encoding noise, which may no longer obey the expected noise\ndistribution, e.g., a normal distribution. To address these challenges, we\npropose a novel approach to correct noise for image interpolation,\nNoiseDiffusion. Specifically, NoiseDiffusion approaches the invalid noise to\nthe expected distribution by introducing subtle Gaussian noise and introduces a\nconstraint to suppress noise with extreme values. In this context, promoting\nnoise validity contributes to mitigating image artifacts, but the constraint\nand introduced exogenous noise typically lead to a reduction in signal-to-noise\nratio, i.e., loss of original image information. Hence, NoiseDiffusion performs\ninterpolation within the noisy image space and injects raw images into these\nnoisy counterparts to address the challenge of information loss. Consequently,\nNoiseDiffusion enables us to interpolate natural images without causing\nartifacts or information loss, thus achieving the best interpolation results.",
      "tldr_zh": "本研究针对基于扩散模型（diffusion models）的图像插值问题，指出现有方法依赖球形线性插值（spherical linear interpolation）时，编码噪声不服从预期分布（如正态分布），导致自然图像插值出现伪影和无效性。论文提出NoiseDiffusion方法，通过引入微小Gaussian噪声修正无效噪声，并添加约束抑制极端值，同时在噪声图像空间进行插值并注入原始图像，以避免信息丢失。结果显示，NoiseDiffusion实现了无伪影、无信息损失的最佳图像插值效果，提升了实际应用潜力。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "ICLR 2024",
      "pdf_url": "http://arxiv.org/pdf/2403.08840v1",
      "published_date": "2024-03-13 12:32:25 UTC",
      "updated_date": "2024-03-13 12:32:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T15:07:23.305904"
    },
    {
      "arxiv_id": "2403.08838v2",
      "title": "Predictive Clustering of Vessel Behavior Based on Hierarchical Trajectory Representation",
      "title_zh": "基于分层轨迹表示的船舶行为预测聚类",
      "authors": [
        "Rui Zhang",
        "Hanyue Wu",
        "Zhenzhong Yin",
        "Zhu Xiao",
        "Yong Xiong",
        "Kezhong Liu"
      ],
      "abstract": "Vessel trajectory clustering, which aims to find similar trajectory patterns,\nhas been widely leveraged in overwater applications. Most traditional methods\nuse predefined rules and thresholds to identify discrete vessel behaviors. They\naim for high-quality clustering and conduct clustering on entire sequences,\nwhether the original trajectory or its sub-trajectories, failing to represent\ntheir evolution. To resolve this problem, we propose a Predictive Clustering of\nHierarchical Vessel Behavior (PC-HiV). PC-HiV first uses hierarchical\nrepresentations to transform every trajectory into a behavioral sequence. Then,\nit predicts evolution at each timestamp of the sequence based on the\nrepresentations. By applying predictive clustering and latent encoding, PC-HiV\nimproves clustering and predictions simultaneously. Experiments on real AIS\ndatasets demonstrate PC-HiV's superiority over existing methods, showcasing its\neffectiveness in capturing behavioral evolution discrepancies between vessel\ntypes (tramp vs. liner) and within emission control areas. Results show that\nour method outperforms NN-Kmeans and Robust DAA by 3.9% and 6.4% of the purity\nscore.",
      "tldr_zh": "本文提出了一种基于分层轨迹表示的预测聚类方法 PC-HiV，用于解决传统船舶轨迹聚类无法捕捉行为演变的问题。PC-HiV 先将每条轨迹转化为行为序列，然后通过分层表示在每个时间戳预测序列的演变，并结合预测聚类和潜在编码同时提升聚类和预测准确性。在真实 AIS 数据集上的实验显示，该方法在纯度分数上比 NN-Kmeans 和 Robust DAA 分别提高了 3.9% 和 6.4%，并更有效地捕捉不同船舶类型（如 tramp vs. liner）和排放控制区域内的行为差异。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.08838v2",
      "published_date": "2024-03-13 12:05:02 UTC",
      "updated_date": "2024-03-15 06:22:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T15:07:36.674733"
    },
    {
      "arxiv_id": "2403.08438v2",
      "title": "Reproducibility and Geometric Intrinsic Dimensionality: An Investigation on Graph Neural Network Research",
      "title_zh": "翻译失败",
      "authors": [
        "Tobias Hille",
        "Maximilian Stubbemann",
        "Tom Hanika"
      ],
      "abstract": "Difficulties in replication and reproducibility of empirical evidences in\nmachine learning research have become a prominent topic in recent years.\nEnsuring that machine learning research results are sound and reliable requires\nreproducibility, which verifies the reliability of research findings using the\nsame code and data. This promotes open and accessible research, robust\nexperimental workflows, and the rapid integration of new findings. Evaluating\nthe degree to which research publications support these different aspects of\nreproducibility is one goal of the present work. For this we introduce an\nontology of reproducibility in machine learning and apply it to methods for\ngraph neural networks. Building on these efforts we turn towards another\ncritical challenge in machine learning, namely the curse of dimensionality,\nwhich poses challenges in data collection, representation, and analysis, making\nit harder to find representative data and impeding the training and inference\nprocesses. Using the closely linked concept of geometric intrinsic dimension we\ninvestigate to which extend the used machine learning models are influenced by\nthe intrinsic dimension of the data sets they are trained on.",
      "tldr_zh": "这篇论文探讨了机器学习研究中的再现性（Reproducibility）和几何内在维度（Geometric Intrinsic Dimensionality）对图神经网络（Graph Neural Networks）的影响，旨在评估研究结果的可靠性和可复制性。研究者引入了一个再现性本体（ontology），并将其应用于图神经网络方法，以检查出版物对再现性的支持，包括实验工作流的稳健性。论文还调查了维度诅咒（curse of dimensionality）对模型的影响，通过分析数据几何内在维度，揭示了模型训练和推理过程如何受数据内在维度影响，从而促进更可靠的机器学习实践。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "68T01 68T07 68T09 51F99",
        "I.2.6"
      ],
      "primary_category": "cs.LG",
      "comment": "39 pages, 9 figures",
      "pdf_url": "http://arxiv.org/pdf/2403.08438v2",
      "published_date": "2024-03-13 11:44:30 UTC",
      "updated_date": "2024-03-19 10:54:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T15:07:48.076956"
    },
    {
      "arxiv_id": "2403.08430v1",
      "title": "Search-based Optimisation of LLM Learning Shots for Story Point Estimation",
      "title_zh": "翻译失败",
      "authors": [
        "Vali Tawosi",
        "Salwa Alamir",
        "Xiaomo Liu"
      ],
      "abstract": "One of the ways Large Language Models (LLMs) are used to perform machine\nlearning tasks is to provide them with a few examples before asking them to\nproduce a prediction. This is a meta-learning process known as few-shot\nlearning. In this paper, we use available Search-Based methods to optimise the\nnumber and combination of examples that can improve an LLM's estimation\nperformance, when it is used to estimate story points for new agile tasks. Our\npreliminary results show that our SBSE technique improves the estimation\nperformance of the LLM by 59.34% on average (in terms of mean absolute error of\nthe estimation) over three datasets against a zero-shot setting.",
      "tldr_zh": "该论文探讨了使用搜索-based 方法（SBSE）优化大型语言模型（LLMs）的少样本学习（few-shot learning）示例，以提升其在敏捷任务故事点估算（story point estimation）中的性能。具体而言，研究者通过调整示例的数量和组合，帮助LLMs更好地预测新任务的故事点。初步实验结果显示，与零样本设置（zero-shot setting）相比，该优化技术在三个数据集上平均将估算的均方绝对误差降低了59.34%。这项工作为基于LLMs的敏捷开发工具提供了更有效的meta-learning策略。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "6 pages, Accepted at SSBSE'23 NIER Track",
      "pdf_url": "http://arxiv.org/pdf/2403.08430v1",
      "published_date": "2024-03-13 11:29:37 UTC",
      "updated_date": "2024-03-13 11:29:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T15:07:59.147041"
    },
    {
      "arxiv_id": "2403.08429v1",
      "title": "Software Vulnerability and Functionality Assessment using LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Rasmus Ingemann Tuffveson Jensen",
        "Vali Tawosi",
        "Salwa Alamir"
      ],
      "abstract": "While code review is central to the software development process, it can be\ntedious and expensive to carry out. In this paper, we investigate whether and\nhow Large Language Models (LLMs) can aid with code reviews. Our investigation\nfocuses on two tasks that we argue are fundamental to good reviews: (i)\nflagging code with security vulnerabilities and (ii) performing software\nfunctionality validation, i.e., ensuring that code meets its intended\nfunctionality. To test performance on both tasks, we use zero-shot and\nchain-of-thought prompting to obtain final ``approve or reject''\nrecommendations. As data, we employ seminal code generation datasets (HumanEval\nand MBPP) along with expert-written code snippets with security vulnerabilities\nfrom the Common Weakness Enumeration (CWE). Our experiments consider a mixture\nof three proprietary models from OpenAI and smaller open-source LLMs. We find\nthat the former outperforms the latter by a large margin. Motivated by\npromising results, we finally ask our models to provide detailed descriptions\nof security vulnerabilities. Results show that 36.7% of LLM-generated\ndescriptions can be associated with true CWE vulnerabilities.",
      "tldr_zh": "本研究探讨了使用大型语言模型（LLMs）辅助代码审查，焦点在于检测软件安全漏洞和验证功能性。研究采用零-shot 和 chain-of-thought 提示方法，对 HumanEval、MBPP 和 CWE 数据集进行测试，结果显示 OpenAI 的专有模型显著优于开源模型。实验表明，LLMs 能为36.7%的安全漏洞生成准确描述，从而为高效代码审查提供潜在工具。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "4 pages, accepted to NLBSE'24",
      "pdf_url": "http://arxiv.org/pdf/2403.08429v1",
      "published_date": "2024-03-13 11:29:13 UTC",
      "updated_date": "2024-03-13 11:29:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T15:08:21.438817"
    },
    {
      "arxiv_id": "2403.08426v1",
      "title": "Language-Driven Visual Consensus for Zero-Shot Semantic Segmentation",
      "title_zh": "基于语言驱动的视觉共识的零样本语义分割",
      "authors": [
        "Zicheng Zhang",
        "Tong Zhang",
        "Yi Zhu",
        "Jianzhuang Liu",
        "Xiaodan Liang",
        "QiXiang Ye",
        "Wei Ke"
      ],
      "abstract": "The pre-trained vision-language model, exemplified by CLIP, advances\nzero-shot semantic segmentation by aligning visual features with class\nembeddings through a transformer decoder to generate semantic masks. Despite\nits effectiveness, prevailing methods within this paradigm encounter\nchallenges, including overfitting on seen classes and small fragmentation in\nmasks. To mitigate these issues, we propose a Language-Driven Visual Consensus\n(LDVC) approach, fostering improved alignment of semantic and visual\ninformation.Specifically, we leverage class embeddings as anchors due to their\ndiscrete and abstract nature, steering vision features toward class embeddings.\nMoreover, to circumvent noisy alignments from the vision part due to its\nredundant nature, we introduce route attention into self-attention for finding\nvisual consensus, thereby enhancing semantic consistency within the same\nobject. Equipped with a vision-language prompting strategy, our approach\nsignificantly boosts the generalization capacity of segmentation models for\nunseen classes. Experimental results underscore the effectiveness of our\napproach, showcasing mIoU gains of 4.5 on the PASCAL VOC 2012 and 3.6 on the\nCOCO-Stuff 164k for unseen classes compared with the state-of-the-art methods.",
      "tldr_zh": "本研究针对基于预训练视觉语言模型（如 CLIP）的零样本语义分割（zero-shot semantic segmentation）问题，提出 Language-Driven Visual Consensus (LDVC) 方法，以解决现有方法在已见类别（seen classes）过拟合和小碎片掩码的问题。LDVC 通过将 class embeddings 作为 anchors 引导视觉特征对齐，并引入 route attention 到 self-attention 中，减少视觉噪声并提升语义一致性，同时结合 vision-language prompting 策略增强模型对未见类别的泛化能力。实验结果显示，该方法在 PASCAL VOC 2012 上使 mIoU 提升 4.5，在 COCO-Stuff 164k 上提升 3.6，显著超越现有最先进方法。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.08426v1",
      "published_date": "2024-03-13 11:23:55 UTC",
      "updated_date": "2024-03-13 11:23:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T15:08:24.001861"
    },
    {
      "arxiv_id": "2403.08425v3",
      "title": "Specification Overfitting in Artificial Intelligence",
      "title_zh": "人工智能中的规范过拟合",
      "authors": [
        "Benjamin Roth",
        "Pedro Henrique Luz de Araujo",
        "Yuxi Xia",
        "Saskia Kaltenbrunner",
        "Christoph Korab"
      ],
      "abstract": "Machine learning (ML) and artificial intelligence (AI) approaches are often\ncriticized for their inherent bias and for their lack of control,\naccountability, and transparency. Consequently, regulatory bodies struggle with\ncontaining this technology's potential negative side effects. High-level\nrequirements such as fairness and robustness need to be formalized into\nconcrete specification metrics, imperfect proxies that capture isolated aspects\nof the underlying requirements. Given possible trade-offs between different\nmetrics and their vulnerability to over-optimization, integrating specification\nmetrics in system development processes is not trivial. This paper defines\nspecification overfitting, a scenario where systems focus excessively on\nspecified metrics to the detriment of high-level requirements and task\nperformance. We present an extensive literature survey to categorize how\nresearchers propose, measure, and optimize specification metrics in several AI\nfields (e.g., natural language processing, computer vision, reinforcement\nlearning). Using a keyword-based search on papers from major AI conferences and\njournals between 2018 and mid-2023, we identify and analyze 74 papers that\npropose or optimize specification metrics. We find that although most papers\nimplicitly address specification overfitting (e.g., by reporting more than one\nspecification metric), they rarely discuss which role specification metrics\nshould play in system development or explicitly define the scope and\nassumptions behind metric formulations.",
      "tldr_zh": "这篇论文探讨了人工智能（AI）中 specification overfitting 的问题，即系统过度优化具体规格化指标（如 fairness 和 robustness 的代理指标），从而损害高水平要求和任务性能。作者通过对 2018-2023 年主要 AI 会议和期刊的文献调查，识别并分析了 74 篇论文，涵盖自然语言处理、计算机视觉和强化学习等领域。调查发现，虽然大多数论文隐式处理了这一问题（如报告多个 specification metrics），但很少明确讨论这些指标在系统开发中的作用、范围和假设。总体而言，该研究强调了在 AI 开发中整合 specification metrics 的复杂性，以避免潜在的负面影响。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "41 pages, 2 figures. This version of the article has been accepted\n  for publication, after peer review but is not the Version of Record and does\n  not reflect post-acceptance improvements, or any corrections. The Version of\n  Record is available online at: https://doi.org/10.1007/s10462-024-11040-6",
      "pdf_url": "http://arxiv.org/pdf/2403.08425v3",
      "published_date": "2024-03-13 11:20:34 UTC",
      "updated_date": "2025-01-02 21:45:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T15:08:36.930572"
    },
    {
      "arxiv_id": "2403.08424v2",
      "title": "Distract Large Language Models for Automatic Jailbreak Attack",
      "title_zh": "翻译失败",
      "authors": [
        "Zeguan Xiao",
        "Yan Yang",
        "Guanhua Chen",
        "Yun Chen"
      ],
      "abstract": "Extensive efforts have been made before the public release of Large language\nmodels (LLMs) to align their behaviors with human values. However, even\nmeticulously aligned LLMs remain vulnerable to malicious manipulations such as\njailbreaking, leading to unintended behaviors. In this work, we propose a novel\nblack-box jailbreak framework for automated red teaming of LLMs. We designed\nmalicious content concealing and memory reframing with an iterative\noptimization algorithm to jailbreak LLMs, motivated by the research about the\ndistractibility and over-confidence phenomenon of LLMs. Extensive experiments\nof jailbreaking both open-source and proprietary LLMs demonstrate the\nsuperiority of our framework in terms of effectiveness, scalability and\ntransferability. We also evaluate the effectiveness of existing jailbreak\ndefense methods against our attack and highlight the crucial need to develop\nmore effective and practical defense strategies.",
      "tldr_zh": "本研究提出了一种基于黑盒框架的自动Jailbreak攻击方法，旨在利用大型语言模型(LLMs)的分心(distractibility)和过度自信(over-confidence)现象来规避其行为对齐。框架通过恶意内容隐藏(malicious content concealing)和记忆重构(memory reframing)结合迭代优化算法，实现对LLMs的自动Red Teaming攻击。实验结果显示，该方法在开源和专有LLMs上表现出色，具有较高的有效性、可扩展性和可转移性；同时，评估了现有Jailbreak防御策略的不足，强调了开发更有效防御措施的紧迫性。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CR",
      "comment": "EMNLP 2024",
      "pdf_url": "http://arxiv.org/pdf/2403.08424v2",
      "published_date": "2024-03-13 11:16:43 UTC",
      "updated_date": "2024-09-30 14:25:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T15:08:47.533863"
    },
    {
      "arxiv_id": "2403.08414v1",
      "title": "Causal Graph Neural Networks for Wildfire Danger Prediction",
      "title_zh": "因果图神经网络用于野火危险预测",
      "authors": [
        "Shan Zhao",
        "Ioannis Prapas",
        "Ilektra Karasante",
        "Zhitong Xiong",
        "Ioannis Papoutsis",
        "Gustau Camps-Valls",
        "Xiao Xiang Zhu"
      ],
      "abstract": "Wildfire forecasting is notoriously hard due to the complex interplay of\ndifferent factors such as weather conditions, vegetation types and human\nactivities. Deep learning models show promise in dealing with this complexity\nby learning directly from data. However, to inform critical decision making, we\nargue that we need models that are right for the right reasons; that is, the\nimplicit rules learned should be grounded by the underlying processes driving\nwildfires. In that direction, we propose integrating causality with Graph\nNeural Networks (GNNs) that explicitly model the causal mechanism among complex\nvariables via graph learning. The causal adjacency matrix considers the\nsynergistic effect among variables and removes the spurious links from highly\ncorrelated impacts. Our methodology's effectiveness is demonstrated through\nsuperior performance forecasting wildfire patterns in the European boreal and\nmediterranean biome. The gain is especially prominent in a highly imbalanced\ndataset, showcasing an enhanced robustness of the model to adapt to regime\nshifts in functional relationships. Furthermore, SHAP values from our trained\nmodel further enhance our understanding of the model's inner workings.",
      "tldr_zh": "本论文针对野火预测的复杂性（如天气、植被和人类活动的影响），提出了一种因果 Graph Neural Networks (GNNs) 方法，通过图学习显式建模变量间的因果机制。方法利用因果邻接矩阵考虑变量的协同效应，并去除高度相关但虚假的关联，从而确保模型基于正确的底层过程。实验结果显示，该方法在欧洲北方和地中海生物群落的野火模式预测中，显著优于基线模型，尤其在高度不平衡数据集上展现出更高的鲁棒性。最终，通过 SHAP values 分析，进一步提升了对模型内部机制的理解和可解释性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by ICLR 2024 Machine Learning for Remote Sensing (ML4RS)\n  Workshop",
      "pdf_url": "http://arxiv.org/pdf/2403.08414v1",
      "published_date": "2024-03-13 10:58:55 UTC",
      "updated_date": "2024-03-13 10:58:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T15:09:01.202835"
    },
    {
      "arxiv_id": "2403.08386v1",
      "title": "Optimizing Risk-averse Human-AI Hybrid Teams",
      "title_zh": "翻译失败",
      "authors": [
        "Andrew Fuchs",
        "Andrea Passarella",
        "Marco Conti"
      ],
      "abstract": "We anticipate increased instances of humans and AI systems working together\nin what we refer to as a hybrid team. The increase in collaboration is expected\nas AI systems gain proficiency and their adoption becomes more widespread.\nHowever, their behavior is not error-free, making hybrid teams a very suitable\nsolution. As such, we consider methods for improving performance for these\nteams of humans and AI systems. For hybrid teams, we will refer to both the\nhumans and AI systems as agents. To improve team performance over that seen for\nagents operating individually, we propose a manager which learns, through a\nstandard Reinforcement Learning scheme, how to best delegate, over time, the\nresponsibility of taking a decision to any of the agents. We further guide the\nmanager's learning so they also minimize how many changes in delegation are\nmade resulting from undesirable team behavior. We demonstrate the optimality of\nour manager's performance in several grid environments which include failure\nstates which terminate an episode and should be avoided. We perform our\nexperiments with teams of agents with varying degrees of acceptable risk, in\nthe form of proximity to a failure state, and measure the manager's ability to\nmake effective delegation decisions with respect to its own risk-based\nconstraints, then compare these to the optimal decisions. Our results show our\nmanager can successfully learn desirable delegations which result in team paths\nnear/exactly optimal with respect to path length and number of delegations.",
      "tldr_zh": "本研究针对人类和AI系统作为混合团队（Hybrid Teams）的协作，提出了一种风险规避优化方法。研究设计了一个基于强化学习（Reinforcement Learning）的管理器，用于动态分配决策责任给团队中的人类或AI代理，同时最小化不必要的委托变化，以提升整体性能。在包含失败状态的网格环境中，实验验证了该管理器在不同风险容忍度下，能够学习出接近最优的委托决策，使团队路径长度和委托次数达到理想水平。结果表明，该方法显著改善了风险规避型混合团队的效率和可靠性。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.08386v1",
      "published_date": "2024-03-13 09:49:26 UTC",
      "updated_date": "2024-03-13 09:49:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T15:09:11.163388"
    },
    {
      "arxiv_id": "2403.09734v2",
      "title": "Do Large Language Models Solve ARC Visual Analogies Like People Do?",
      "title_zh": "大型语言模型",
      "authors": [
        "Gustaw Opiełka",
        "Hannes Rosenbusch",
        "Veerle Vijverberg",
        "Claire E. Stevenson"
      ],
      "abstract": "The Abstraction Reasoning Corpus (ARC) is a visual analogical reasoning test\ndesigned for humans and machines (Chollet, 2019). We compared human and large\nlanguage model (LLM) performance on a new child-friendly set of ARC items.\nResults show that both children and adults outperform most LLMs on these tasks.\nError analysis revealed a similar \"fallback\" solution strategy in LLMs and\nyoung children, where part of the analogy is simply copied. In addition, we\nfound two other error types, one based on seemingly grasping key concepts\n(e.g., Inside-Outside) and the other based on simple combinations of analogy\ninput matrices. On the whole, \"concept\" errors were more common in humans, and\n\"matrix\" errors were more common in LLMs. This study sheds new light on LLM\nreasoning ability and the extent to which we can use error analyses and\ncomparisons with human development to understand how LLMs solve visual\nanalogies.",
      "tldr_zh": "这篇论文比较了大型语言模型（LLMs）和人类在抽象推理语料库（ARC）的视觉类比任务上的表现，使用了一个新的儿童友好型任务集。结果显示，儿童和成人比大多数LLMs表现更好。错误分析揭示了LLMs和年轻儿童的相似“回退”策略，即简单复制部分类比，而人类更常犯基于概念（如Inside-Outside）的错误，LLMs则更常犯基于输入矩阵组合的错误。该研究通过人类发展比较，揭示了LLMs的推理能力局限，并为理解其解决视觉类比的方式提供了新见解。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Changes (based on CogSci 2024 reviewers): - Shortened Intro - Added a\n  table summarizing children performance across age - Added Theoretical\n  discussion in the Discussion section - Corrected the naming of plots - Small\n  clarifications in the Methods section",
      "pdf_url": "http://arxiv.org/pdf/2403.09734v2",
      "published_date": "2024-03-13 09:48:13 UTC",
      "updated_date": "2024-05-13 11:20:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T15:09:25.323897"
    },
    {
      "arxiv_id": "2403.08375v1",
      "title": "Translating between SQL Dialects for Cloud Migration",
      "title_zh": "翻译失败",
      "authors": [
        "Ran Zmigrod",
        "Salwa Alamir",
        "Xiaomo Liu"
      ],
      "abstract": "Migrations of systems from on-site premises to the cloud has been a\nfundamental endeavor by many industrial institutions. A crucial component of\nsuch cloud migrations is the transition of databases to be hosted online. In\nthis work, we consider the difficulties of this migration for SQL databases.\nWhile SQL is one of the prominent methods for storing database procedures,\nthere are a plethora of different SQL dialects (e.g., MySQL, Postgres, etc.)\nwhich can complicate migrations when the on-premise SQL dialect differs to the\ndialect hosted on the cloud. Tools exist by common cloud provides such as AWS\nand Azure to aid in translating between dialects in order to mitigate the\nmajority of the difficulties. However, these tools do not successfully\ntranslate $100\\%$ of the code. Consequently, software engineers must manually\nconvert the remainder of the untranslated database. For large organizations,\nthis task quickly becomes intractable and so more innovative solutions are\nrequired. We consider this challenge a novel yet vital industrial research\nproblem for any large corporation that is considering cloud migrations.\nFurthermore, we introduce potential avenues of research to tackle this\nchallenge that have yielded promising preliminary results.",
      "tldr_zh": "本研究探讨了将系统从本地迁移到云端时，SQL 方言（如 MySQL 和 Postgres）之间转换的挑战，这是一个关键的数据库迁移问题。现有工具（如 AWS 和 Azure 提供的工具）虽然能缓解部分困难，但无法完全翻译代码，导致软件工程师需手动处理剩余部分，对大型组织而言效率低下。论文将此视为一个新型工业研究问题，并提出潜在的研究途径，包括创新解决方案，以简化迁移过程。这些途径已显示出初步的积极结果，有望提升云迁移的可行性和效率。",
      "categories": [
        "cs.DB",
        "cs.AI",
        "cs.CL",
        "cs.SE"
      ],
      "primary_category": "cs.DB",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.08375v1",
      "published_date": "2024-03-13 09:38:39 UTC",
      "updated_date": "2024-03-13 09:38:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T15:09:36.015288"
    },
    {
      "arxiv_id": "2403.08370v3",
      "title": "SMART: Submodular Data Mixture Strategy for Instruction Tuning",
      "title_zh": "SMART：子模数据混合策略用于指令调优",
      "authors": [
        "H S V N S Kowndinya Renduchintala",
        "Sumit Bhatia",
        "Ganesh Ramakrishnan"
      ],
      "abstract": "Instruction Tuning involves finetuning a language model on a collection of\ninstruction-formatted datasets in order to enhance the generalizability of the\nmodel to unseen tasks. Studies have shown the importance of balancing different\ntask proportions during finetuning, but finding the right balance remains\nchallenging. Unfortunately, there's currently no systematic method beyond\nmanual tuning or relying on practitioners' intuition. In this paper, we\nintroduce SMART (Submodular data Mixture strAtegy for instRuction Tuning) - a\nnovel data mixture strategy which makes use of a submodular function to assign\nimportance scores to tasks which are then used to determine the mixture\nweights. Given a fine-tuning budget, SMART redistributes the budget among tasks\nand selects non-redundant samples from each task. Experimental results\ndemonstrate that SMART significantly outperforms traditional methods such as\nexamples proportional mixing and equal mixing. Furthermore, SMART facilitates\nthe creation of data mixtures based on a few representative subsets of tasks\nalone and through task pruning analysis, we reveal that in a limited budget\nsetting, allocating budget among a subset of representative tasks yields\nsuperior performance compared to distributing the budget among all tasks. The\ncode for reproducing our results is open-sourced at\nhttps://github.com/kowndinya-renduchintala/SMART.",
      "tldr_zh": "该论文提出了一种名为 SMART 的数据混合策略，用于优化 Instruction Tuning 过程，以提升语言模型在未见任务上的泛化能力。SMART 通过 submodular function 分配任务重要性分数，进而确定混合权重，并在给定预算下重新分配资源并选择非冗余样本。实验结果显示，SMART 显著优于传统方法如 examples proportional mixing 和 equal mixing；此外，在有限预算设置下，仅对代表性任务子集分配预算即可实现更好的性能。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.08370v3",
      "published_date": "2024-03-13 09:31:50 UTC",
      "updated_date": "2024-07-13 11:01:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T15:09:47.501087"
    },
    {
      "arxiv_id": "2403.08364v1",
      "title": "Decoupled Federated Learning on Long-Tailed and Non-IID data with Feature Statistics",
      "title_zh": "翻译失败",
      "authors": [
        "Zhuoxin Chen",
        "Zhenyu Wu",
        "Yang Ji"
      ],
      "abstract": "Federated learning is designed to enhance data security and privacy, but\nfaces challenges when dealing with heterogeneous data in long-tailed and\nnon-IID distributions. This paper explores an overlooked scenario where tail\nclasses are sparsely distributed over a few clients, causing the models trained\nwith these classes to have a lower probability of being selected during client\naggregation, leading to slower convergence rates and poorer model performance.\nTo address this issue, we propose a two-stage Decoupled Federated learning\nframework using Feature Statistics (DFL-FS). In the first stage, the server\nestimates the client's class coverage distributions through masked local\nfeature statistics clustering to select models for aggregation to accelerate\nconvergence and enhance feature learning without privacy leakage. In the second\nstage, DFL-FS employs federated feature regeneration based on global feature\nstatistics and utilizes resampling and weighted covariance to calibrate the\nglobal classifier to enhance the model's adaptability to long-tailed data\ndistributions. We conducted experiments on CIFAR10-LT and CIFAR100-LT datasets\nwith various long-tailed rates. The results demonstrate that our method\noutperforms state-of-the-art methods in both accuracy and convergence rate.",
      "tldr_zh": "这篇论文针对联邦学习（Federated Learning）在长尾（Long-Tailed）和非IID数据上的挑战，提出了一种两阶段的Decoupled Federated Learning框架，使用Feature Statistics（DFL-FS），以解决尾类稀疏分布导致的模型收敛慢和性能差问题。在第一阶段，服务器通过masked local feature statistics clustering估计客户端的类覆盖分布，选择模型进行聚合，从而加速收敛并增强特征学习，同时避免隐私泄露。在第二阶段，框架采用federated feature regeneration基于全局特征统计，并通过resampling和weighted covariance校准全局分类器，提高模型对长尾数据分布的适应性。实验结果显示，在CIFAR10-LT和CIFAR100-LT数据集上，DFL-FS在准确性和收敛率方面均优于现有最先进方法。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.08364v1",
      "published_date": "2024-03-13 09:24:59 UTC",
      "updated_date": "2024-03-13 09:24:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T15:10:02.129496"
    },
    {
      "arxiv_id": "2403.08352v3",
      "title": "Data augmentation with automated machine learning: approaches and performance comparison with classical data augmentation methods",
      "title_zh": "基于自动机器学习的数据增强：方法及与经典数据增强方法的性能比较",
      "authors": [
        "Alhassan Mumuni",
        "Fuseini Mumuni"
      ],
      "abstract": "Data augmentation is arguably the most important regularization technique\ncommonly used to improve generalization performance of machine learning models.\nIt primarily involves the application of appropriate data transformation\noperations to create new data samples with desired properties. Despite its\neffectiveness, the process is often challenging because of the time-consuming\ntrial and error procedures for creating and testing different candidate\naugmentations and their hyperparameters manually. State-of-the-art approaches\nare increasingly relying on automated machine learning (AutoML) principles.\nThis work presents a comprehensive survey of AutoML-based data augmentation\ntechniques. We discuss various approaches for accomplishing data augmentation\nwith AutoML, including data manipulation, data integration and data synthesis\ntechniques. The focus of this work is on image data augmentation methods.\nNonetheless, we cover other data modalities, especially in cases where the\nspecific data augmentations techniques being discussed are more suitable for\nthese other modalities. For instance, since automated data integration methods\nare more suitable for tabular data, we cover tabular data in the discussion of\ndata integration methods. The work also presents extensive discussion of\ntechniques for accomplishing each of the major subtasks of the image data\naugmentation process: search space design, hyperparameter optimization and\nmodel evaluation. Finally, we carried out an extensive comparison and analysis\nof the performance of automated data augmentation techniques and\nstate-of-the-art methods based on classical augmentation approaches. The\nresults show that AutoML methods for data augmentation currently outperform\nstate-of-the-art techniques based on conventional approaches.",
      "tldr_zh": "这篇论文调查了使用自动化机器学习（AutoML）进行数据增强的方法，包括数据操作、数据整合和数据合成技术，重点关注图像数据增强，同时覆盖其他数据模态如表格数据。论文详细讨论了数据增强过程的关键子任务，如搜索空间设计、超参数优化和模型评估，以减少手动试错的挑战。最终，通过广泛的性能比较，研究发现AutoML-based数据增强方法优于传统方法，在提高机器学习模型的泛化性能方面表现出显著优势。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV",
        "cs.NE"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.08352v3",
      "published_date": "2024-03-13 09:00:38 UTC",
      "updated_date": "2025-03-05 22:04:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T15:10:16.051220"
    },
    {
      "arxiv_id": "2403.08337v2",
      "title": "LLM-Assisted Light: Leveraging Large Language Model Capabilities for Human-Mimetic Traffic Signal Control in Complex Urban Environments",
      "title_zh": "翻译失败",
      "authors": [
        "Maonan Wang",
        "Aoyu Pang",
        "Yuheng Kan",
        "Man-On Pun",
        "Chung Shue Chen",
        "Bo Huang"
      ],
      "abstract": "Traffic congestion in metropolitan areas presents a formidable challenge with\nfar-reaching economic, environmental, and societal ramifications. Therefore,\neffective congestion management is imperative, with traffic signal control\n(TSC) systems being pivotal in this endeavor. Conventional TSC systems,\ndesigned upon rule-based algorithms or reinforcement learning (RL), frequently\nexhibit deficiencies in managing the complexities and variabilities of urban\ntraffic flows, constrained by their limited capacity for adaptation to\nunfamiliar scenarios. In response to these limitations, this work introduces an\ninnovative approach that integrates Large Language Models (LLMs) into TSC,\nharnessing their advanced reasoning and decision-making faculties.\nSpecifically, a hybrid framework that augments LLMs with a suite of perception\nand decision-making tools is proposed, facilitating the interrogation of both\nthe static and dynamic traffic information. This design places the LLM at the\ncenter of the decision-making process, combining external traffic data with\nestablished TSC methods. Moreover, a simulation platform is developed to\ncorroborate the efficacy of the proposed framework. The findings from our\nsimulations attest to the system's adeptness in adjusting to a multiplicity of\ntraffic environments without the need for additional training. Notably, in\ncases of Sensor Outage (SO), our approach surpasses conventional RL-based\nsystems by reducing the average waiting time by $20.4\\%$. This research\nsignifies a notable advance in TSC strategies and paves the way for the\nintegration of LLMs into real-world, dynamic scenarios, highlighting their\npotential to revolutionize traffic management. The related code is available at\nhttps://github.com/Traffic-Alpha/LLM-Assisted-Light.",
      "tldr_zh": "本研究提出了一种名为 LLM-Assisted Light 的创新框架，利用 Large Language Models (LLMs) 的高级推理和决策能力，模拟人类决策来优化复杂城市环境的交通信号控制 (TSC)，以解决传统基于规则或 reinforcement learning (RL) 系统的适应性不足问题。该框架将 LLMs 作为决策核心，结合感知和决策工具，处理静态和动态交通信息，从而无需额外训练即可适应多种交通场景。在模拟实验中，该方法在 Sensor Outage (SO) 情况下，比传统 RL 系统减少平均等待时间 20.4%，显著提升了拥堵管理效率。该研究标志着 TSC 策略的重大进展，并为 LLMs 在真实世界动态交通管理中的应用铺平道路。",
      "categories": [
        "eess.SY",
        "cs.AI",
        "cs.LG",
        "cs.SY"
      ],
      "primary_category": "eess.SY",
      "comment": "20 pages, 11 figures",
      "pdf_url": "http://arxiv.org/pdf/2403.08337v2",
      "published_date": "2024-03-13 08:41:55 UTC",
      "updated_date": "2024-06-12 14:53:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T15:10:29.573912"
    },
    {
      "arxiv_id": "2403.08335v2",
      "title": "A Sparsity Principle for Partially Observable Causal Representation Learning",
      "title_zh": "部分可观测因果表示学习的稀疏性原则",
      "authors": [
        "Danru Xu",
        "Dingling Yao",
        "Sébastien Lachapelle",
        "Perouz Taslakian",
        "Julius von Kügelgen",
        "Francesco Locatello",
        "Sara Magliacane"
      ],
      "abstract": "Causal representation learning aims at identifying high-level causal\nvariables from perceptual data. Most methods assume that all latent causal\nvariables are captured in the high-dimensional observations. We instead\nconsider a partially observed setting, in which each measurement only provides\ninformation about a subset of the underlying causal state. Prior work has\nstudied this setting with multiple domains or views, each depending on a fixed\nsubset of latents. Here, we focus on learning from unpaired observations from a\ndataset with an instance-dependent partial observability pattern. Our main\ncontribution is to establish two identifiability results for this setting: one\nfor linear mixing functions without parametric assumptions on the underlying\ncausal model, and one for piecewise linear mixing functions with Gaussian\nlatent causal variables. Based on these insights, we propose two methods for\nestimating the underlying causal variables by enforcing sparsity in the\ninferred representation. Experiments on different simulated datasets and\nestablished benchmarks highlight the effectiveness of our approach in\nrecovering the ground-truth latents.",
      "tldr_zh": "该论文探讨了部分可观察的因果表示学习（Causal Representation Learning），旨在从感知数据中识别高层次因果变量，但每个测量仅提供部分潜在因果状态的信息。作者建立了两个可识别性结果：一个针对线性混合函数（无对底层因果模型的参数假设），另一个针对分段线性混合函数（带有高斯潜在因果变量）。基于这些洞见，他们提出两种方法，通过在推断表示中强制稀疏性（Sparsity Principle）来估计底层因果变量，并在模拟数据集和基准实验中证明了该方法在恢复真实潜在变量方面的有效性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "45 pages, 32 figures, 16 tables",
      "pdf_url": "http://arxiv.org/pdf/2403.08335v2",
      "published_date": "2024-03-13 08:40:49 UTC",
      "updated_date": "2024-06-15 13:06:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T15:10:39.132623"
    },
    {
      "arxiv_id": "2403.08837v1",
      "title": "Cyclic Data Parallelism for Efficient Parallelism of Deep Neural Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Louis Fournier",
        "Edouard Oyallon"
      ],
      "abstract": "Training large deep learning models requires parallelization techniques to\nscale. In existing methods such as Data Parallelism or ZeRO-DP, micro-batches\nof data are processed in parallel, which creates two drawbacks: the total\nmemory required to store the model's activations peaks at the end of the\nforward pass, and gradients must be simultaneously averaged at the end of the\nbackpropagation step. We propose Cyclic Data Parallelism, a novel paradigm\nshifting the execution of the micro-batches from simultaneous to sequential,\nwith a uniform delay. At the cost of a slight gradient delay, the total memory\ntaken by activations is constant, and the gradient communications are balanced\nduring the training step. With Model Parallelism, our technique reduces the\nnumber of GPUs needed, by sharing GPUs across micro-batches. Within the ZeRO-DP\nframework, our technique allows communication of the model states with\npoint-to-point operations rather than a collective broadcast operation. We\nillustrate the strength of our approach on the CIFAR-10 and ImageNet datasets.",
      "tldr_zh": "该论文提出了一种名为 Cyclic Data Parallelism 的新并行化范式，用于高效训练大型深度神经网络模型。现有方法如 Data Parallelism 和 ZeRO-DP 在处理微批次数据时会导致正向传播结束时的内存峰值和反向传播结束时的梯度平均问题，而新方法通过将微批次执行从同时变为顺序并引入均匀延迟，显著降低了激活内存占用并平衡了梯度通信。实验结果显示，该技术与 Model Parallelism 结合可减少所需 GPUs 数量，并在 ZeRO-DP 框架中使用点对点操作优化通信，在 CIFAR-10 和 ImageNet 数据集上表现出色。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DC",
        "cs.NE",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.08837v1",
      "published_date": "2024-03-13 08:39:21 UTC",
      "updated_date": "2024-03-13 08:39:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T15:10:52.107935"
    },
    {
      "arxiv_id": "2403.08333v3",
      "title": "Fast Inference of Removal-Based Node Influence",
      "title_zh": "翻译失败",
      "authors": [
        "Weikai Li",
        "Zhiping Xiao",
        "Xiao Luo",
        "Yizhou Sun"
      ],
      "abstract": "Graph neural networks (GNNs) are widely utilized to capture the information\nspreading patterns in graphs. While remarkable performance has been achieved,\nthere is a new trending topic of evaluating node influence. We propose a new\nmethod of evaluating node influence, which measures the prediction change of a\ntrained GNN model caused by removing a node. A real-world application is, \"In\nthe task of predicting Twitter accounts' polarity, had a particular account\nbeen removed, how would others' polarity change?\". We use the GNN as a\nsurrogate model whose prediction could simulate the change of nodes or edges\ncaused by node removal. Our target is to obtain the influence score for every\nnode, and a straightforward way is to alternately remove every node and apply\nthe trained GNN on the modified graph to generate new predictions. It is\nreliable but time-consuming, so we need an efficient method. The related lines\nof work, such as graph adversarial attack and counterfactual explanation,\ncannot directly satisfy our needs, since their problem settings are different.\nWe propose an efficient, intuitive, and effective method, NOde-Removal-based\nfAst GNN inference (NORA), which uses the gradient information to approximate\nthe node-removal influence. It only costs one forward propagation and one\nbackpropagation to approximate the influence score for all nodes. Extensive\nexperiments on six datasets and six GNN models verify the effectiveness of\nNORA. Our code is available at https://github.com/weikai-li/NORA.git.",
      "tldr_zh": "该论文提出了一种基于移除节点的节点影响快速推断方法，名为 NORA，用于评估移除特定节点后对训练好 GNN（Graph Neural Networks）模型预测的影响，例如在预测 Twitter 账户极性任务中移除一个账户后的变化。NORA 通过利用梯度信息来近似计算所有节点的影響分数，仅需一次前向传播和一次后向传播，从而显著提高了效率。实验在六个数据集和六个 GNN 模型上验证了 NORA 的有效性，并提供了开源代码。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Published in the Web Conference 2024",
      "pdf_url": "http://arxiv.org/pdf/2403.08333v3",
      "published_date": "2024-03-13 08:37:31 UTC",
      "updated_date": "2024-05-31 22:36:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T15:11:02.941992"
    },
    {
      "arxiv_id": "2403.08332v1",
      "title": "Autoregressive Score Generation for Multi-trait Essay Scoring",
      "title_zh": "翻译失败",
      "authors": [
        "Heejin Do",
        "Yunsu Kim",
        "Gary Geunbae Lee"
      ],
      "abstract": "Recently, encoder-only pre-trained models such as BERT have been successfully\napplied in automated essay scoring (AES) to predict a single overall score.\nHowever, studies have yet to explore these models in multi-trait AES, possibly\ndue to the inefficiency of replicating BERT-based models for each trait.\nBreaking away from the existing sole use of encoder, we propose an\nautoregressive prediction of multi-trait scores (ArTS), incorporating a\ndecoding process by leveraging the pre-trained T5. Unlike prior regression or\nclassification methods, we redefine AES as a score-generation task, allowing a\nsingle model to predict multiple scores. During decoding, the subsequent trait\nprediction can benefit by conditioning on the preceding trait scores.\nExperimental results proved the efficacy of ArTS, showing over 5% average\nimprovements in both prompts and traits.",
      "tldr_zh": "本研究提出了一种自回归多特征分数预测(ArTS)方法，用于自动作文评分(AES)，以解决现有encoder-only模型如BERT在多特征评分中的效率问题。ArTS利用预训练的T5模型，将AES重新定义为分数生成任务，通过解码过程使后续特征分数预测基于前一个分数进行条件化，从而实现单一模型的多特征预测。实验结果表明，该方法在提示和特征上平均提高了5%以上，证明了其有效性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted at EACL2024 Findings",
      "pdf_url": "http://arxiv.org/pdf/2403.08332v1",
      "published_date": "2024-03-13 08:34:53 UTC",
      "updated_date": "2024-03-13 08:34:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T15:11:15.646702"
    },
    {
      "arxiv_id": "2403.08836v1",
      "title": "Structural Positional Encoding for knowledge integration in transformer-based medical process monitoring",
      "title_zh": "结构化位置编码在基于Transformer的医疗过程监控中用于知识整合",
      "authors": [
        "Christopher Irwin",
        "Marco Dossena",
        "Giorgio Leonardi",
        "Stefania Montani"
      ],
      "abstract": "Predictive process monitoring is a process mining task aimed at forecasting\ninformation about a running process trace, such as the most correct next\nactivity to be executed. In medical domains, predictive process monitoring can\nprovide valuable decision support in atypical and nontrivial situations.\nDecision support and quality assessment in medicine cannot ignore domain\nknowledge, in order to be grounded on all the available information (which is\nnot limited to data) and to be really acceptable by end users.\n  In this paper, we propose a predictive process monitoring approach relying on\nthe use of a {\\em transformer}, a deep learning architecture based on the\nattention mechanism. A major contribution of our work lies in the incorporation\nof ontological domain-specific knowledge, carried out through a graph\npositional encoding technique. The paper presents and discusses the encouraging\nexperimental result we are collecting in the domain of stroke management.",
      "tldr_zh": "这篇论文提出了一种基于Transformer的预测过程监控方法，旨在在医疗领域预测运行中的过程轨迹（如下一个活动），并通过整合本体论领域的特定知识来提供决策支持。核心贡献在于引入图结构位置编码（graph positional encoding）技术，将领域知识融入Transformer模型，确保监控结果更全面和可接受。在卒中管理领域的实验中，该方法显示出令人鼓舞的性能提升。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.08836v1",
      "published_date": "2024-03-13 08:15:18 UTC",
      "updated_date": "2024-03-13 08:15:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T15:11:25.827077"
    },
    {
      "arxiv_id": "2403.08835v1",
      "title": "Stacking-based deep neural network for player scouting in football 1",
      "title_zh": "翻译失败",
      "authors": [
        "Simon Lacan"
      ],
      "abstract": "Datascouting is one of the most known data applications in professional\nsport, and specifically football. Its objective is to analyze huge database of\nplayers in order to detect high potentials that can be then individually\nconsidered by human scouts. In this paper, we propose a stacking-based deep\nlearning model to detect high potential football players. Applied on\nopen-source database, our model obtains significantly better results that\nclassical statistical methods.",
      "tldr_zh": "本研究针对足球领域的球员侦查（Datascouting），提出了一种基于 stacking 的深度神经网络模型，用于分析球员数据库并识别高潜力球员。该模型通过集成学习技术整合多种深度学习组件，在开源数据库上进行应用。实验结果显示，该方法比传统的统计方法取得了显著更好的性能，为专业足球人才选拔提供了更高效的数据驱动工具。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.08835v1",
      "published_date": "2024-03-13 08:10:18 UTC",
      "updated_date": "2024-03-13 08:10:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T15:11:37.230085"
    },
    {
      "arxiv_id": "2403.08834v1",
      "title": "Predictive Analysis of Tuberculosis Treatment Outcomes Using Machine Learning: A Karnataka TB Data Study at a Scale",
      "title_zh": "翻译失败",
      "authors": [
        "SeshaSai Nath Chinagudaba",
        "Darshan Gera",
        "Krishna Kiran Vamsi Dasu",
        "Uma Shankar S",
        "Kiran K",
        "Anil Singarajpure",
        "Shivayogappa. U",
        "Somashekar N",
        "Vineet Kumar Chadda",
        "Sharath B N"
      ],
      "abstract": "Tuberculosis (TB) remains a global health threat, ranking among the leading\ncauses of mortality worldwide. In this context, machine learning (ML) has\nemerged as a transformative force, providing innovative solutions to the\ncomplexities associated with TB treatment.This study explores how machine\nlearning, especially with tabular data, can be used to predict Tuberculosis\n(TB) treatment outcomes more accurately. It transforms this prediction task\ninto a binary classification problem, generating risk scores from patient data\nsourced from NIKSHAY, India's national TB control program, which includes over\n500,000 patient records.\n  Data preprocessing is a critical component of the study, and the model\nachieved an recall of 98% and an AUC-ROC score of 0.95 on the validation set,\nwhich includes 20,000 patient records.We also explore the use of Natural\nLanguage Processing (NLP) for improved model learning. Our results,\ncorroborated by various metrics and ablation studies, validate the\neffectiveness of our approach. The study concludes by discussing the potential\nramifications of our research on TB eradication efforts and proposing potential\navenues for future work. This study marks a significant stride in the battle\nagainst TB, showcasing the potential of machine learning in healthcare.",
      "tldr_zh": "本研究利用 Machine Learning (ML) 对结核病(Tuberculosis, TB)治疗结果进行预测分析，基于印度 NIKSHAY 国家 TB 控制程序的超过50万患者记录，将任务转化为二元分类问题，并通过数据预处理实现了验证集上的98% recall 和0.95 AUC-ROC 分数。研究还整合 Natural Language Processing (NLP) 来提升模型学习效果，并通过各种指标和消融研究验证了方法的有效性。该工作展示了 ML 在医疗保健中的潜力，为 TB 根除努力提供新洞见，并提出未来研究方向。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.08834v1",
      "published_date": "2024-03-13 08:04:00 UTC",
      "updated_date": "2024-03-13 08:04:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T15:11:52.245704"
    },
    {
      "arxiv_id": "2403.08319v2",
      "title": "Knowledge Conflicts for LLMs: A Survey",
      "title_zh": "翻译失败",
      "authors": [
        "Rongwu Xu",
        "Zehan Qi",
        "Zhijiang Guo",
        "Cunxiang Wang",
        "Hongru Wang",
        "Yue Zhang",
        "Wei Xu"
      ],
      "abstract": "This survey provides an in-depth analysis of knowledge conflicts for large\nlanguage models (LLMs), highlighting the complex challenges they encounter when\nblending contextual and parametric knowledge. Our focus is on three categories\nof knowledge conflicts: context-memory, inter-context, and intra-memory\nconflict. These conflicts can significantly impact the trustworthiness and\nperformance of LLMs, especially in real-world applications where noise and\nmisinformation are common. By categorizing these conflicts, exploring the\ncauses, examining the behaviors of LLMs under such conflicts, and reviewing\navailable solutions, this survey aims to shed light on strategies for improving\nthe robustness of LLMs, thereby serving as a valuable resource for advancing\nresearch in this evolving area.",
      "tldr_zh": "这篇调查综述了大型语言模型（LLMs）在融合上下文和参数知识时面临的知识冲突问题，重点分为三种类别：context-memory conflict、inter-context conflict 和 intra-memory conflict。这些冲突可能导致LLMs在真实世界应用中性能下降，尤其是在噪声和错误信息环境下。通过分析冲突的原因、LLMs的行为表现以及现有解决方案，该调查为提升LLMs的鲁棒性提供了宝贵策略和研究方向。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Our GitHub repo is available at\n  https://github.com/pillowsofwind/Knowledge-Conflicts-Survey",
      "pdf_url": "http://arxiv.org/pdf/2403.08319v2",
      "published_date": "2024-03-13 08:02:23 UTC",
      "updated_date": "2024-06-22 08:31:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T15:12:02.031590"
    },
    {
      "arxiv_id": "2403.09733v1",
      "title": "OverleafCopilot: Empowering Academic Writing in Overleaf with Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Haomin Wen",
        "Zhenjie Wei",
        "Yan Lin",
        "Jiyuan Wang",
        "Yuxuan Liang",
        "Huaiyu Wan"
      ],
      "abstract": "The rapid development of Large Language Models (LLMs) has facilitated a\nvariety of applications from different domains. In this technical report, we\nexplore the integration of LLMs and the popular academic writing tool,\nOverleaf, to enhance the efficiency and quality of academic writing. To achieve\nthe above goal, there are three challenges: i) including seamless interaction\nbetween Overleaf and LLMs, ii) establishing reliable communication with the LLM\nprovider, and iii) ensuring user privacy. To address these challenges, we\npresent OverleafCopilot, the first-ever tool (i.e., a browser extension) that\nseamlessly integrates LLMs and Overleaf, enabling researchers to leverage the\npower of LLMs while writing papers. Specifically, we first propose an effective\nframework to bridge LLMs and Overleaf. Then, we developed PromptGenius, a\nwebsite for researchers to easily find and share high-quality up-to-date\nprompts. Thirdly, we propose an agent command system to help researchers\nquickly build their customizable agents. OverleafCopilot\n(https://chromewebstore.google.com/detail/overleaf-copilot/eoadabdpninlhkkbhngoddfjianhlghb\n) has been on the Chrome Extension Store, which now serves thousands of\nresearchers. Additionally, the code of PromptGenius is released at\nhttps://github.com/wenhaomin/ChatGPT-PromptGenius. We believe our work has the\npotential to revolutionize academic writing practices, empowering researchers\nto produce higher-quality papers in less time.",
      "tldr_zh": "该论文介绍了 OverleafCopilot，一种浏览器扩展工具，利用 Large Language Models (LLMs) 提升 Overleaf 中的学术写作效率和质量，解决了无缝交互、可靠通信和用户隐私的三大挑战。具体方法包括构建一个桥接框架、开发 PromptGenius 网站用于分享高质量提示，以及提出代理命令系统以帮助用户自定义代理。OverleafCopilot 已发布在 Chrome 扩展商店并服务数千研究者，其开源代码可从 GitHub 获取，有潜力革新学术写作实践，让研究者更高效地产出高质量论文。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.09733v1",
      "published_date": "2024-03-13 07:52:31 UTC",
      "updated_date": "2024-03-13 07:52:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T15:12:15.513766"
    },
    {
      "arxiv_id": "2403.08312v3",
      "title": "StreamingDialogue: Prolonged Dialogue Learning via Long Context Compression with Minimal Losses",
      "title_zh": "StreamingDialogue：通过长上下文压缩以最小损失实现持久对话学习",
      "authors": [
        "Jia-Nan Li",
        "Quan Tu",
        "Cunli Mao",
        "Zhengtao Yu",
        "Ji-Rong Wen",
        "Rui Yan"
      ],
      "abstract": "Standard Large Language Models (LLMs) struggle with handling dialogues with\nlong contexts due to efficiency and consistency issues. According to our\nobservation, dialogue contexts are highly structured, and the special token of\n\\textit{End-of-Utterance} (EoU) in dialogues has the potential to aggregate\ninformation. We refer to the EoU tokens as ``conversational attention sinks''\n(conv-attn sinks). Accordingly, we introduce StreamingDialogue, which\ncompresses long dialogue history into conv-attn sinks with minimal losses, and\nthus reduces computational complexity quadratically with the number of sinks\n(i.e., the number of utterances). Current LLMs already demonstrate the ability\nto handle long context window, e.g., a window size of 200K or more. To this\nend, by compressing utterances into EoUs, our method has the potential to\nhandle more than 200K of utterances, resulting in a prolonged dialogue\nlearning. In order to minimize information losses from reconstruction after\ncompression, we design two learning strategies of short-memory reconstruction\n(SMR) and long-memory reactivation (LMR). Our method outperforms strong\nbaselines in dialogue tasks and achieves a 4 $\\times$ speedup while reducing\nmemory usage by 18 $\\times$ compared to dense attention recomputation.",
      "tldr_zh": "本研究针对标准LLMs在处理长对话上下文时存在的效率和一致性问题，提出StreamingDialogue方法，通过将对话历史压缩到EoU标记（即conversational attention sinks）中，实现最小损失的上下文压缩，从而将计算复杂度与话语数量的平方成反比。方法利用当前LLMs的长上下文能力（如200K+窗口），支持处理超过200K的话语，实现延长对话学习。为最小化压缩后的信息损失，该框架设计了短记忆重建(SMR)和长记忆再激活(LMR)两种学习策略。实验结果显示，StreamingDialogue在对话任务中优于强基线模型，速度提升4倍，同时内存使用减少18倍。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.08312v3",
      "published_date": "2024-03-13 07:44:14 UTC",
      "updated_date": "2024-11-04 09:17:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T15:12:28.955998"
    },
    {
      "arxiv_id": "2403.08309v2",
      "title": "HRLAIF: Improvements in Helpfulness and Harmlessness in Open-domain Reinforcement Learning From AI Feedback",
      "title_zh": "HRLAIF：开放域基于",
      "authors": [
        "Ang Li",
        "Qiugen Xiao",
        "Peng Cao",
        "Jian Tang",
        "Yi Yuan",
        "Zijie Zhao",
        "Xiaoyuan Chen",
        "Liang Zhang",
        "Xiangyang Li",
        "Kaitong Yang",
        "Weidong Guo",
        "Yukang Gan",
        "Xu Yu",
        "Daniell Wang",
        "Ying Shan"
      ],
      "abstract": "Reinforcement Learning from AI Feedback (RLAIF) has the advantages of shorter\nannotation cycles and lower costs over Reinforcement Learning from Human\nFeedback (RLHF), making it highly efficient during the rapid strategy iteration\nperiods of large language model (LLM) training. Using ChatGPT as a labeler to\nprovide feedback on open-domain prompts in RLAIF training, we observe an\nincrease in human evaluators' preference win ratio for model responses, but a\ndecrease in evaluators' satisfaction rate. Analysis suggests that the decrease\nin satisfaction rate is mainly due to some responses becoming less helpful,\nparticularly in terms of correctness and truthfulness, highlighting practical\nlimitations of basic RLAIF. In this paper, we propose Hybrid Reinforcement\nLearning from AI Feedback (HRLAIF). This method enhances the accuracy of AI\nannotations for responses, making the model's helpfulness more robust in\ntraining process. Additionally, it employs AI for Red Teaming, further\nimproving the model's harmlessness. Human evaluation results show that HRLAIF\ninherits the ability of RLAIF to enhance human preference for outcomes at a low\ncost while also improving the satisfaction rate of responses. Compared to the\npolicy model before Reinforcement Learning (RL), it achieves an increase of\n2.08\\% in satisfaction rate, effectively addressing the issue of a decrease of\n4.58\\% in satisfaction rate after basic RLAIF.",
      "tldr_zh": "该研究探讨了基于AI反馈的强化学习（RLAIF）在训练大型语言模型（LLM）中的优势，如更短的标注周期和更低成本，但发现它会导致模型响应的人类满意度下降，主要由于正确性和真实性方面的帮助性不足。为解决这一问题，作者提出混合强化学习从AI反馈（HRLAIF）方法，该方法通过提升AI注解的准确性和使用AI进行Red Teaming，增强模型的帮助性和无害性。实验结果显示，HRLAIF在保持RLAIF低成本优势的同时，提高了人类满意度，与强化学习前模型相比增加2.08%，并有效逆转了基本RLAIF导致的满意度下降4.58%。这为更可靠的开放域AI训练提供了重要改进。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "18 pages, 7 figures",
      "pdf_url": "http://arxiv.org/pdf/2403.08309v2",
      "published_date": "2024-03-13 07:38:20 UTC",
      "updated_date": "2024-03-14 04:24:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T15:12:39.277578"
    },
    {
      "arxiv_id": "2405.00689v1",
      "title": "Anti-Jamming Path Planning Using GCN for Multi-UAV",
      "title_zh": "基于 GCN 的多无人机反干扰路径规划",
      "authors": [
        "Haechan Jeong"
      ],
      "abstract": "This paper addresses the increasing significance of UAVs (Unmanned Aerial\nVehicles) and the emergence of UAV swarms for collaborative operations in\nvarious domains. However, the effectiveness of UAV swarms can be severely\ncompromised by jamming technology, necessitating robust antijamming strategies.\nWhile existing methods such as frequency hopping and physical path planning\nhave been explored, there remains a gap in research on path planning for UAV\nswarms when the jammer's location is unknown. To address this, a novel\napproach, where UAV swarms leverage collective intelligence to predict jamming\nareas, evade them, and efficiently reach target destinations, is proposed. This\napproach utilizes Graph Convolutional Networks (GCN) to predict the location\nand intensity of jamming areas based on information gathered from each UAV. A\nmulti-agent control algorithm is then employed to disperse the UAV swarm, avoid\njamming, and regroup upon reaching the target. Through simulations, the\neffectiveness of the proposed method is demonstrated, showcasing accurate\nprediction of jamming areas and successful evasion through obstacle avoidance\nalgorithms, ultimately achieving the mission objective. Proposed method offers\nrobustness, scalability, and computational efficiency, making it applicable\nacross various scenarios where UAV swarms operate in potentially hostile\nenvironments.",
      "tldr_zh": "本论文针对多UAV（Unmanned Aerial Vehicles）群在未知干扰器位置下的路径规划问题，提出了一种新型反干扰策略，利用GCN（Graph Convolutional Networks）基于各UAV收集的信息预测干扰区域的位置和强度。方法结合多智能体控制算法，使UAV群实现分散避让、干扰规避和目标重新集合，确保高效完成任务。通过模拟实验，证明该方法能准确预测干扰区域并成功避开，最终提升UAV群的鲁棒性、可扩展性和计算效率，适用于各种敌对环境。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.00689v1",
      "published_date": "2024-03-13 07:28:05 UTC",
      "updated_date": "2024-03-13 07:28:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T15:12:51.309904"
    },
    {
      "arxiv_id": "2403.08299v1",
      "title": "AutoDev: Automated AI-Driven Development",
      "title_zh": "AutoDev：自动化的 AI 驱动开发",
      "authors": [
        "Michele Tufano",
        "Anisha Agarwal",
        "Jinu Jang",
        "Roshanak Zilouchian Moghaddam",
        "Neel Sundaresan"
      ],
      "abstract": "The landscape of software development has witnessed a paradigm shift with the\nadvent of AI-powered assistants, exemplified by GitHub Copilot. However,\nexisting solutions are not leveraging all the potential capabilities available\nin an IDE such as building, testing, executing code, git operations, etc.\nTherefore, they are constrained by their limited capabilities, primarily\nfocusing on suggesting code snippets and file manipulation within a chat-based\ninterface. To fill this gap, we present AutoDev, a fully automated AI-driven\nsoftware development framework, designed for autonomous planning and execution\nof intricate software engineering tasks. AutoDev enables users to define\ncomplex software engineering objectives, which are assigned to AutoDev's\nautonomous AI Agents to achieve. These AI agents can perform diverse operations\non a codebase, including file editing, retrieval, build processes, execution,\ntesting, and git operations. They also have access to files, compiler output,\nbuild and testing logs, static analysis tools, and more. This enables the AI\nAgents to execute tasks in a fully automated manner with a comprehensive\nunderstanding of the contextual information required. Furthermore, AutoDev\nestablishes a secure development environment by confining all operations within\nDocker containers. This framework incorporates guardrails to ensure user\nprivacy and file security, allowing users to define specific permitted or\nrestricted commands and operations within AutoDev. In our evaluation, we tested\nAutoDev on the HumanEval dataset, obtaining promising results with 91.5% and\n87.8% of Pass@1 for code generation and test generation respectively,\ndemonstrating its effectiveness in automating software engineering tasks while\nmaintaining a secure and user-controlled development environment.",
      "tldr_zh": "本文提出 AutoDev，一种自动化 AI-Driven 软件开发框架，旨在通过自主 AI Agents 实现复杂软件工程任务的规划和执行，超越现有工具如 GitHub Copilot 的局限性。AutoDev 允许 AI Agents 访问文件、编译输出、构建日志、测试结果和静态分析工具等资源，进行文件编辑、构建、测试及 git 操作等全面功能，并在 Docker containers 中运行以确保安全和用户隐私控制。用户可定义特定权限，限制操作范围。该框架在 HumanEval 数据集上的评估显示，代码生成和测试生成的 Pass@1 分别为 91.5% 和 87.8%，证明其在自动化开发任务中的高效性和可靠性。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.08299v1",
      "published_date": "2024-03-13 07:12:03 UTC",
      "updated_date": "2024-03-13 07:12:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T15:13:04.391854"
    },
    {
      "arxiv_id": "2403.08295v4",
      "title": "Gemma: Open Models Based on Gemini Research and Technology",
      "title_zh": "Gemma：基于 Gemini 研究和技术的",
      "authors": [
        "Gemma Team",
        "Thomas Mesnard",
        "Cassidy Hardin",
        "Robert Dadashi",
        "Surya Bhupatiraju",
        "Shreya Pathak",
        "Laurent Sifre",
        "Morgane Rivière",
        "Mihir Sanjay Kale",
        "Juliette Love",
        "Pouya Tafti",
        "Léonard Hussenot",
        "Pier Giuseppe Sessa",
        "Aakanksha Chowdhery",
        "Adam Roberts",
        "Aditya Barua",
        "Alex Botev",
        "Alex Castro-Ros",
        "Ambrose Slone",
        "Amélie Héliou",
        "Andrea Tacchetti",
        "Anna Bulanova",
        "Antonia Paterson",
        "Beth Tsai",
        "Bobak Shahriari",
        "Charline Le Lan",
        "Christopher A. Choquette-Choo",
        "Clément Crepy",
        "Daniel Cer",
        "Daphne Ippolito",
        "David Reid",
        "Elena Buchatskaya",
        "Eric Ni",
        "Eric Noland",
        "Geng Yan",
        "George Tucker",
        "George-Christian Muraru",
        "Grigory Rozhdestvenskiy",
        "Henryk Michalewski",
        "Ian Tenney",
        "Ivan Grishchenko",
        "Jacob Austin",
        "James Keeling",
        "Jane Labanowski",
        "Jean-Baptiste Lespiau",
        "Jeff Stanway",
        "Jenny Brennan",
        "Jeremy Chen",
        "Johan Ferret",
        "Justin Chiu",
        "Justin Mao-Jones",
        "Katherine Lee",
        "Kathy Yu",
        "Katie Millican",
        "Lars Lowe Sjoesund",
        "Lisa Lee",
        "Lucas Dixon",
        "Machel Reid",
        "Maciej Mikuła",
        "Mateo Wirth",
        "Michael Sharman",
        "Nikolai Chinaev",
        "Nithum Thain",
        "Olivier Bachem",
        "Oscar Chang",
        "Oscar Wahltinez",
        "Paige Bailey",
        "Paul Michel",
        "Petko Yotov",
        "Rahma Chaabouni",
        "Ramona Comanescu",
        "Reena Jana",
        "Rohan Anil",
        "Ross McIlroy",
        "Ruibo Liu",
        "Ryan Mullins",
        "Samuel L Smith",
        "Sebastian Borgeaud",
        "Sertan Girgin",
        "Sholto Douglas",
        "Shree Pandya",
        "Siamak Shakeri",
        "Soham De",
        "Ted Klimenko",
        "Tom Hennigan",
        "Vlad Feinberg",
        "Wojciech Stokowiec",
        "Yu-hui Chen",
        "Zafarali Ahmed",
        "Zhitao Gong",
        "Tris Warkentin",
        "Ludovic Peran",
        "Minh Giang",
        "Clément Farabet",
        "Oriol Vinyals",
        "Jeff Dean",
        "Koray Kavukcuoglu",
        "Demis Hassabis",
        "Zoubin Ghahramani",
        "Douglas Eck",
        "Joelle Barral",
        "Fernando Pereira",
        "Eli Collins",
        "Armand Joulin",
        "Noah Fiedel",
        "Evan Senter",
        "Alek Andreev",
        "Kathleen Kenealy"
      ],
      "abstract": "This work introduces Gemma, a family of lightweight, state-of-the art open\nmodels built from the research and technology used to create Gemini models.\nGemma models demonstrate strong performance across academic benchmarks for\nlanguage understanding, reasoning, and safety. We release two sizes of models\n(2 billion and 7 billion parameters), and provide both pretrained and\nfine-tuned checkpoints. Gemma outperforms similarly sized open models on 11 out\nof 18 text-based tasks, and we present comprehensive evaluations of safety and\nresponsibility aspects of the models, alongside a detailed description of model\ndevelopment. We believe the responsible release of LLMs is critical for\nimproving the safety of frontier models, and for enabling the next wave of LLM\ninnovations.",
      "tldr_zh": "本研究介绍了Gemma，一系列基于Gemini研究和技术的轻量级开源模型，这些模型在语言理解、推理和安全方面的学术基准上表现出色。Gemma提供了2 billion和7 billion参数的预训练和微调版本，并在18个基于文本的任务中胜过同规模开源模型的11个任务。研究还进行了全面的安全和责任评估，并详细描述了模型开发过程，以推动大型语言模型(LLMs)的安全提升和创新浪潮。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.08295v4",
      "published_date": "2024-03-13 06:59:16 UTC",
      "updated_date": "2024-04-16 12:52:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T15:13:15.420585"
    },
    {
      "arxiv_id": "2403.08293v3",
      "title": "Generative Pretrained Structured Transformers: Unsupervised Syntactic Language Models at Scale",
      "title_zh": "翻译失败",
      "authors": [
        "Xiang Hu",
        "Pengyu Ji",
        "Qingyang Zhu",
        "Wei Wu",
        "Kewei Tu"
      ],
      "abstract": "A syntactic language model (SLM) incrementally generates a sentence with its\nsyntactic tree in a left-to-right manner. We present Generative Pretrained\nStructured Transformers (GPST), an unsupervised SLM at scale capable of being\npre-trained from scratch on raw texts with high parallelism. GPST circumvents\nthe limitations of previous SLMs such as relying on gold trees and sequential\ntraining. It consists of two components, a usual SLM supervised by a\nuni-directional language modeling loss, and an additional composition model,\nwhich induces syntactic parse trees and computes constituent representations,\nsupervised by a bi-directional language modeling loss. We propose a\nrepresentation surrogate to enable joint parallel training of the two models in\na hard-EM fashion. We pre-train GPST on OpenWebText, a corpus with $9$ billion\ntokens, and demonstrate the superiority of GPST over GPT-2 with a comparable\nsize in numerous tasks covering both language understanding and language\ngeneration. Meanwhile, GPST also significantly outperforms existing\nunsupervised SLMs on left-to-right grammar induction, while holding a\nsubstantial acceleration on training.",
      "tldr_zh": "该论文提出了 Generative Pretrained Structured Transformers (GPST)，一种可从原始文本 unsupervised 预训练的 syntactic language model (SLM)，能够以高并行性生成句子及其语法树。GPST 包括一个由 uni-directional language modeling loss 监督的 SLM 和一个由 bi-directional language modeling loss 监督的 composition model，通过 representation surrogate 实现 hard-EM 风格的联合训练，从而克服了传统 SLM 的依赖金标准树和顺序训练的局限。实验结果显示，在 OpenWebText 上预训练的 GPST 在语言理解和生成任务上优于类似规模的 GPT-2，并在 left-to-right grammar induction 上显著超越现有 unsupervised SLMs，同时大幅加速训练过程。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "accepted by ACL 2024",
      "pdf_url": "http://arxiv.org/pdf/2403.08293v3",
      "published_date": "2024-03-13 06:54:47 UTC",
      "updated_date": "2024-06-17 16:22:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T15:13:29.046914"
    },
    {
      "arxiv_id": "2403.08292v1",
      "title": "Weak Collocation Regression for Inferring Stochastic Dynamics with Lévy Noise",
      "title_zh": "翻译失败",
      "authors": [
        "Liya Guo",
        "Liwei Lu",
        "Zhijun Zeng",
        "Pipi Hu",
        "Yi Zhu"
      ],
      "abstract": "With the rapid increase of observational, experimental and simulated data for\nstochastic systems, tremendous efforts have been devoted to identifying\ngoverning laws underlying the evolution of these systems. Despite the broad\napplications of non-Gaussian fluctuations in numerous physical phenomena, the\ndata-driven approaches to extracting stochastic dynamics with L\\'{e}vy noise\nare relatively few. In this work, we propose a Weak Collocation Regression\n(WCR) to explicitly reveal unknown stochastic dynamical systems, i.e., the\nStochastic Differential Equation (SDE) with both $\\alpha$-stable L\\'{e}vy noise\nand Gaussian noise, from discrete aggregate data. This method utilizes the\nevolution equation of the probability distribution function, i.e., the\nFokker-Planck (FP) equation. With the weak form of the FP equation, the WCR\nconstructs a linear system of unknown parameters where all integrals are\nevaluated by Monte Carlo method with the observations. Then, the unknown\nparameters are obtained by a sparse linear regression. For a SDE with L\\'{e}vy\nnoise, the corresponding FP equation is a partial integro-differential equation\n(PIDE), which contains nonlocal terms, and is difficult to deal with. The weak\nform can avoid complicated multiple integrals. Our approach can simultaneously\ndistinguish mixed noise types, even in multi-dimensional problems. Numerical\nexperiments demonstrate that our method is accurate and computationally\nefficient.",
      "tldr_zh": "本研究提出了一种Weak Collocation Regression (WCR)方法，用于从离散聚合数据中推断带有α-stable Lévy噪声和高斯噪声的随机动力学系统，即Stochastic Differential Equation (SDE)。该方法基于Fokker-Planck (FP)方程的弱形式，构建一个线性系统，通过Monte Carlo方法评估积分，并采用稀疏线性回归求解未知参数，从而避免处理部分积分微分方程 (PIDE) 的复杂非局部项。WCR能同时区分混合噪声类型，并适用于多维问题；数值实验表明，该方法准确性高且计算效率佳，为提取非高斯波动系统提供了有效工具。",
      "categories": [
        "math.NA",
        "cs.AI",
        "cs.NA",
        "math.DS"
      ],
      "primary_category": "math.NA",
      "comment": "19 pages, 5 figures, 10 tables",
      "pdf_url": "http://arxiv.org/pdf/2403.08292v1",
      "published_date": "2024-03-13 06:54:38 UTC",
      "updated_date": "2024-03-13 06:54:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T15:13:38.950233"
    },
    {
      "arxiv_id": "2403.08291v3",
      "title": "CleanAgent: Automating Data Standardization with LLM-based Agents",
      "title_zh": "翻译失败",
      "authors": [
        "Danrui Qi",
        "Zhengjie Miao",
        "Jiannan Wang"
      ],
      "abstract": "Data standardization is a crucial part of the data science life cycle. While\ntools like Pandas offer robust functionalities, their complexity and the manual\neffort required for customizing code to diverse column types pose significant\nchallenges. Although large language models (LLMs) like ChatGPT have shown\npromise in automating this process through natural language understanding and\ncode generation, it still demands expert-level programming knowledge and\ncontinuous interaction for prompt refinement. To solve these challenges, our\nkey idea is to propose a Python library with declarative, unified APIs for\nstandardizing different column types, simplifying the LLM's code generation\nwith concise API calls. We first propose Dataprep.Clean, a component of the\nDataprep Python Library, significantly reduces the coding complexity by\nenabling the standardization of specific column types with a single line of\ncode. Then, we introduce the CleanAgent framework integrating Dataprep.Clean\nand LLM-based agents to automate the data standardization process. With\nCleanAgent, data scientists only need to provide their requirements once,\nallowing for a hands-free process. To demonstrate the practical utility of\nCleanAgent, we developed a user-friendly web application, allowing attendees to\ninteract with it using real-world datasets.",
      "tldr_zh": "本文研究了数据标准化的挑战，包括工具如 Pandas 的复杂性和手动代码定制需求，以及 LLM（如 ChatGPT）在自动化中仍需专家编程和持续交互的问题。论文提出 Dataprep.Clean 组件，这是一个 Python 库的子模块，通过声明式统一 API 和单行代码简化不同列类型的标准化过程。随后，引入 CleanAgent 框架，将 Dataprep.Clean 与 LLM-based agents 整合，实现完全自动化的数据标准化，用户只需提供一次要求即可。实验通过一个用户友好的 web 应用演示了 CleanAgent 在真实数据集上的实用性和效率提升。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.08291v3",
      "published_date": "2024-03-13 06:54:15 UTC",
      "updated_date": "2025-03-07 19:01:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T15:13:51.462616"
    },
    {
      "arxiv_id": "2403.10555v1",
      "title": "KARINA: An Efficient Deep Learning Model for Global Weather Forecast",
      "title_zh": "KARINA：用于全球天气预报的高效深度学习模型",
      "authors": [
        "Minjong Cheon",
        "Yo-Hwan Choi",
        "Seon-Yu Kang",
        "Yumi Choi",
        "Jeong-Gil Lee",
        "Daehyun Kang"
      ],
      "abstract": "Deep learning-based, data-driven models are gaining prevalence in climate\nresearch, particularly for global weather prediction. However, training the\nglobal weather data at high resolution requires massive computational\nresources. Therefore, we present a new model named KARINA to overcome the\nsubstantial computational demands typical of this field. This model achieves\nforecasting accuracy comparable to higher-resolution counterparts with\nsignificantly less computational resources, requiring only 4 NVIDIA A100 GPUs\nand less than 12 hours of training. KARINA combines ConvNext, SENet, and\nGeocyclic Padding to enhance weather forecasting at a 2.5{\\deg} resolution,\nwhich could filter out high-frequency noise. Geocyclic Padding preserves pixels\nat the lateral boundary of the input image, thereby maintaining atmospheric\nflow continuity in the spherical Earth. SENet dynamically improves feature\nresponse, advancing atmospheric process modeling, particularly in the vertical\ncolumn process as numerous channels. In this vein, KARINA sets new benchmarks\nin weather forecasting accuracy, surpassing existing models like the ECMWF S2S\nreforecasts at a lead time of up to 7 days. Remarkably, KARINA achieved\ncompetitive performance even when compared to the recently developed models\n(Pangu-Weather, GraphCast, ClimaX, and FourCastNet) trained with\nhigh-resolution data having 100 times larger pixels. Conclusively, KARINA\nsignificantly advances global weather forecasting by efficiently modeling\nEarth's atmosphere with improved accuracy and resource efficiency.",
      "tldr_zh": "这篇论文介绍了 KARINA，一种高效的深度学习模型，用于全球天气预测，旨在减少高分辨率数据训练的计算资源需求。KARINA 结合 ConvNext、SENet 和 Geocyclic Padding 等技术，在 2.5° 分辨率下过滤高频噪声并维持大气流动连续性，仅需 4 个 NVIDIA A100 GPU 和不到 12 小时的训练时间。实验结果显示，该模型在 7 天预测中超过了 ECMWF S2S 的基准，并与高分辨率模型（如 Pangu-Weather、GraphCast 等）相比表现出竞争性准确性。总体上，KARINA 通过提升资源效率和准确性，为全球天气预报领域设定了新标准。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV",
        "physics.ao-ph"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.10555v1",
      "published_date": "2024-03-13 06:41:37 UTC",
      "updated_date": "2024-03-13 06:41:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T15:14:04.329454"
    },
    {
      "arxiv_id": "2403.08281v4",
      "title": "Mastering Text, Code and Math Simultaneously via Fusing Highly Specialized Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Ning Ding",
        "Yulin Chen",
        "Ganqu Cui",
        "Xingtai Lv",
        "Weilin Zhao",
        "Ruobing Xie",
        "Bowen Zhou",
        "Zhiyuan Liu",
        "Maosong Sun"
      ],
      "abstract": "Underlying data distributions of natural language, programming code, and\nmathematical symbols vary vastly, presenting a complex challenge for large\nlanguage models (LLMs) that strive to achieve high performance across all three\ndomains simultaneously. Achieving a very high level of proficiency for an LLM\nwithin a specific domain often requires extensive training with relevant\ncorpora, which is typically accompanied by a sacrifice in performance in other\ndomains. In this paper, we propose to fuse models that are already\nhighly-specialized directly. The proposed fusing framework, UltraFuser,\nconsists of three distinct specialists that are already sufficiently trained on\nlanguage, coding, and mathematics. A token-level gating mechanism is introduced\nto blend the specialists' outputs. A two-stage training strategy accompanied by\nbalanced sampling is designed to ensure stability. To effectively train the\nfused model, we further construct a high-quality supervised instruction tuning\ndataset, UltraChat 2, which includes text, code, and mathematical content. This\ndataset comprises approximately 300,000 instructions and covers a wide range of\ntopics in each domain. Experiments show that our model could simultaneously\nachieve mastery of the three crucial domains.",
      "tldr_zh": "本研究提出了一种名为UltraFuser的框架，用于同时掌握自然语言、编程代码和数学领域的专长，以解决大型语言模型（LLMs）在多领域性能上的挑战。该框架通过融合已高度专业化的语言、代码和数学专家模型，并引入token-level gating mechanism来混合输出，辅以两阶段训练策略和平衡采样，确保模型的稳定性和高效性。为支持训练，研究者构建了UltraChat 2数据集，包含约30万条高质量指令，覆盖各领域的广泛主题。实验结果表明，该模型成功实现了在文本、代码和数学三个领域的同步高性能。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.08281v4",
      "published_date": "2024-03-13 06:18:48 UTC",
      "updated_date": "2024-03-26 09:29:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T15:14:17.246974"
    },
    {
      "arxiv_id": "2403.08273v1",
      "title": "LiqD: A Dynamic Liquid Level Detection Model under Tricky Small Containers",
      "title_zh": "LiqD：针对棘手小容器的动态液位检测模型",
      "authors": [
        "Yukun Ma",
        "Zikun Mao"
      ],
      "abstract": "In daily life and industrial production, it is crucial to accurately detect\nchanges in liquid level in containers. Traditional contact measurement methods\nhave some limitations, while emerging non-contact image processing technology\nshows good application prospects. This paper proposes a container dynamic\nliquid level detection model based on U^2-Net. This model uses the SAM model to\ngenerate an initial data set, and then evaluates and filters out high-quality\npseudo-label images through the SemiReward framework to build an exclusive data\nset. The model uses U^2-Net to extract mask images of containers from the data\nset, and uses morphological processing to compensate for mask defects.\nSubsequently, the model calculates the grayscale difference between adjacent\nvideo frame images at the same position, segments the liquid level change area\nby setting a difference threshold, and finally uses a lightweight neural\nnetwork to classify the liquid level state. This approach not only mitigates\nthe impact of intricate surroundings, but also reduces the demand for training\ndata, showing strong robustness and versatility. A large number of experimental\nresults show that the proposed model can effectively detect the dynamic liquid\nlevel changes of the liquid in the container, providing a novel and efficient\nsolution for related fields.",
      "tldr_zh": "本论文提出LiqD模型，用于在复杂微小容器中检测动态液位变化，旨在解决传统接触式测量方法的局限性。模型首先利用SAM生成初始数据集，并通过SemiReward框架筛选高质伪标签图像构建专属数据集；随后，采用U^2-Net提取容器掩码图像，并结合形态学处理、灰度差异计算和差异阈值分割来识别液位变化区域，最后使用轻量级神经网络分类液位状态。该方法减少了对训练数据的依赖，提升了鲁棒性和通用性，实验结果表明LiqD模型能有效检测容器中液体的动态变化，为相关领域提供高效解决方案。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "I.4.6; I.5.2"
      ],
      "primary_category": "cs.CV",
      "comment": "7pages, 7 Figures",
      "pdf_url": "http://arxiv.org/pdf/2403.08273v1",
      "published_date": "2024-03-13 05:53:25 UTC",
      "updated_date": "2024-03-13 05:53:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T15:14:28.749937"
    },
    {
      "arxiv_id": "2403.08271v2",
      "title": "Efficient Prompt Tuning of Large Vision-Language Model for Fine-Grained Ship Classification",
      "title_zh": "高效的提示微调用于大型视觉语言模型的细粒度船舶分类",
      "authors": [
        "Long Lan",
        "Fengxiang Wang",
        "Xiangtao Zheng",
        "Zengmao Wang",
        "Xinwang Liu"
      ],
      "abstract": "Fine-grained ship classification in remote sensing (RS-FGSC) poses a\nsignificant challenge due to the high similarity between classes and the\nlimited availability of labeled data, limiting the effectiveness of traditional\nsupervised classification methods. Recent advancements in large pre-trained\nVision-Language Models (VLMs) have demonstrated impressive capabilities in\nfew-shot or zero-shot learning, particularly in understanding image content.\nThis study delves into harnessing the potential of VLMs to enhance\nclassification accuracy for unseen ship categories, which holds considerable\nsignificance in scenarios with restricted data due to cost or privacy\nconstraints. Directly fine-tuning VLMs for RS-FGSC often encounters the\nchallenge of overfitting the seen classes, resulting in suboptimal\ngeneralization to unseen classes, which highlights the difficulty in\ndifferentiating complex backgrounds and capturing distinct ship features. To\naddress these issues, we introduce a novel prompt tuning technique that employs\na hierarchical, multi-granularity prompt design. Our approach integrates remote\nsensing ship priors through bias terms, learned from a small trainable network.\nThis strategy enhances the model's generalization capabilities while improving\nits ability to discern intricate backgrounds and learn discriminative ship\nfeatures. Furthermore, we contribute to the field by introducing a\ncomprehensive dataset, FGSCM-52, significantly expanding existing datasets with\nmore extensive data and detailed annotations for less common ship classes.\nExtensive experimental evaluations demonstrate the superiority of our proposed\nmethod over current state-of-the-art techniques. The source code will be made\npublicly available.",
      "tldr_zh": "该研究针对遥感细粒度船舶分类（RS-FGSC）的挑战，如类别间高度相似和标签数据有限的问题，提出了一种高效的提示调整（prompt tuning）技术，以提升大型视觉语言模型（VLMs）的分类准确性。该方法采用分层、多粒度提示设计，并通过小型可训练网络学习遥感船舶先验偏置项，从而增强模型的泛化能力、区分复杂背景并提取区分性船舶特征。作为贡献，该研究引入了一个新的全面数据集FGSCM-52，包含更多数据和详细标注，以支持少见船舶类别的研究。实验结果显示，该方法优于现有最先进技术，为数据受限场景下的船舶分类提供了有效解决方案。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "It has been accepted by TGRS",
      "pdf_url": "http://arxiv.org/pdf/2403.08271v2",
      "published_date": "2024-03-13 05:48:58 UTC",
      "updated_date": "2024-11-29 03:12:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T15:14:41.191105"
    },
    {
      "arxiv_id": "2403.14683v1",
      "title": "A Moral Imperative: The Need for Continual Superalignment of Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Gokul Puthumanaillam",
        "Manav Vora",
        "Pranay Thangeda",
        "Melkior Ornik"
      ],
      "abstract": "This paper examines the challenges associated with achieving life-long\nsuperalignment in AI systems, particularly large language models (LLMs).\nSuperalignment is a theoretical framework that aspires to ensure that\nsuperintelligent AI systems act in accordance with human values and goals.\nDespite its promising vision, we argue that achieving superalignment requires\nsubstantial changes in the current LLM architectures due to their inherent\nlimitations in comprehending and adapting to the dynamic nature of these human\nethics and evolving global scenarios. We dissect the challenges of encoding an\never-changing spectrum of human values into LLMs, highlighting the\ndiscrepancies between static AI models and the dynamic nature of human\nsocieties. To illustrate these challenges, we analyze two distinct examples:\none demonstrates a qualitative shift in human values, while the other presents\na quantifiable change. Through these examples, we illustrate how LLMs,\nconstrained by their training data, fail to align with contemporary human\nvalues and scenarios. The paper concludes by exploring potential strategies to\naddress and possibly mitigate these alignment discrepancies, suggesting a path\nforward in the pursuit of more adaptable and responsive AI systems.",
      "tldr_zh": "这篇论文强调了在大型语言模型（LLMs）中实现终身超对齐（superalignment）的道德必要性，以确保超级智能 AI 系统始终符合人类价值观和目标。论文分析了当前 LLM 架构的局限性，包括无法适应人类伦理的动态变化，并通过两个示例（一个定性价值观转变和一个定量变化）说明这些模型因训练数据限制而无法与当代社会对齐。最终，论文提出潜在策略，如改进 LLM 设计，以开发更具适应性和响应性的 AI 系统，从而缓解这些对齐问题。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.14683v1",
      "published_date": "2024-03-13 05:44:50 UTC",
      "updated_date": "2024-03-13 05:44:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T15:14:52.655837"
    },
    {
      "arxiv_id": "2403.15426v2",
      "title": "CodingTeachLLM: Empowering LLM's Coding Ability via AST Prior Knowledge",
      "title_zh": "翻译失败",
      "authors": [
        "Zhangquan Chen",
        "Chunjiang Liu",
        "Haobin Duan"
      ],
      "abstract": "In this paper, we introduce CodingTeachLLM, a large language model (LLM)\ndesigned for coding teaching. Specially, we aim to enhance the coding ability\nof LLM and lead it to better teaching mode in education context. Thus, we\npropose an end-to-end prior-based three-phases supervised fine-tuned model,\nwhich is proved more competitive than traditional fine-tuning method. More\nspecifically, our model realizes the structural disassembly and incremental\nguided output of educational knowledge. To this end, we robustify data\nclassification of three types via a sampler and overlap estimation neural\nnetwork, and inject the preprocessing datasets into pre-trained model in three\nbatches for LORA fine-tuning. Then, we design a prior module couples system\nprompt, vector databases, and abstract syntax tree task segmentation. Finally,\nthe compression method and regularization constraint are applied to the\nprior-based fine-tuned model, followed by text filter at the output end to\nobtain incremental guided results. Our model represents the first research\neffort to truly embody the tutor role with the features of abundant educational\nknowledge, step-by-step incremental guided outputs and non-disclosure of\nanswers. Extensive experiments report that our model also achieves\nstate-of-the-art in code abilities compared to open-source models, reaching an\nimpressive 75.10% on the HumanEval (@pass 1) benchmark. Additionally, our model\nmaintains strong conversational capabilities, with the 13B quantized version\nachieving scores of 56.34, 50.60, and 45.27 respectively on the MMLU, C-Eval,\nand AGIEval (5 shot) dialogue evaluation benchmarks.",
      "tldr_zh": "本文提出 CodingTeachLLM，一种通过 AST 先验知识增强 LLM 编码能力的模型，旨在使其在教育环境中更好地担任教学角色，提供丰富的教育知识、逐步增量引导输出和不泄露答案等特征。模型采用端到端的三阶段监督微调方法，包括数据分类（使用采样器和重叠估计神经网络）、LORA 微调以及先验模块的设计（如系统提示、向量数据库和 AST 任务分割），并应用压缩方法和正规化约束以优化输出。实验结果显示，该模型在 HumanEval (@pass 1) 基准上达到 75.10% 的出色性能，并在 MMLU、C-Eval 和 AGIEval 对话评估上取得高分，超越了开源模型。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "I.2.7"
      ],
      "primary_category": "cs.LG",
      "comment": "9 pages, 2 figures",
      "pdf_url": "http://arxiv.org/pdf/2403.15426v2",
      "published_date": "2024-03-13 05:38:39 UTC",
      "updated_date": "2025-04-01 03:53:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T15:15:06.808624"
    },
    {
      "arxiv_id": "2403.08265v2",
      "title": "Random Search as a Baseline for Sparse Neural Network Architecture Search",
      "title_zh": "随机搜索作为稀疏神经网络架构搜索的基准",
      "authors": [
        "Rezsa Farahani"
      ],
      "abstract": "Sparse neural networks have shown similar or better generalization\nperformance than their dense counterparts while having higher parameter\nefficiency. This has motivated a number of works to learn or search for high\nperforming sparse networks. While reports of task performance or efficiency\ngains are impressive, standard baselines are lacking leading to poor\ncomparability and unreliable reproducibility across methods. In this work, we\npropose Random Search as a baseline algorithm for finding good sparse\nconfigurations and study its performance. We apply Random Search on the node\nspace of an overparameterized network with the goal of finding better\ninitialized sparse sub-networks that are positioned more advantageously in the\nloss landscape. We record the post-training performances of the found sparse\nnetworks and at various levels of sparsity, and compare against both their\nfully connected parent networks and random sparse configurations at the same\nsparsity levels. First, we demonstrate performance at different levels of\nsparsity and highlight that a significant level of performance can still be\npreserved even when the network is highly sparse. Second, we observe that for\nthis sparse architecture search task, initialized sparse networks found by\nRandom Search neither perform better nor converge more efficiently than their\nrandom counterparts. Thus we conclude that Random Search may be viewed as a\nreasonable neutral baseline for sparsity search methods.",
      "tldr_zh": "本文提出 Random Search 作为 Sparse Neural Network Architecture Search 的基准算法，以解决现有方法缺乏标准基准导致的可比性和可重复性问题。研究在过参数化网络的节点空间中应用 Random Search，寻找更好的初始化稀疏子网络，并与完全连接网络及相同稀疏水平的随机配置进行性能比较。结果显示，即使在高稀疏水平下，网络性能仍能保持显著，而 Random Search 找到的稀疏网络并不优于随机对应物，因此可作为稀疏搜索方法的合理中性基准。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NE",
        "I.2.8; I.5.1"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.08265v2",
      "published_date": "2024-03-13 05:32:13 UTC",
      "updated_date": "2024-03-14 05:18:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T15:15:17.684750"
    },
    {
      "arxiv_id": "2403.08264v1",
      "title": "GPT, Ontology, and CAABAC: A Tripartite Personalized Access Control Model Anchored by Compliance, Context and Attribute",
      "title_zh": "翻译失败",
      "authors": [
        "Raza Nowrozy",
        "Khandakar Ahmed",
        "Hua Wang"
      ],
      "abstract": "As digital healthcare evolves, the security of electronic health records\n(EHR) becomes increasingly crucial. This study presents the GPT-Onto-CAABAC\nframework, integrating Generative Pretrained Transformer (GPT), medical-legal\nontologies and Context-Aware Attribute-Based Access Control (CAABAC) to enhance\nEHR access security. Unlike traditional models, GPT-Onto-CAABAC dynamically\ninterprets policies and adapts to changing healthcare and legal environments,\noffering customized access control solutions. Through empirical evaluation,\nthis framework is shown to be effective in improving EHR security by accurately\naligning access decisions with complex regulatory and situational requirements.\nThe findings suggest its broader applicability in sectors where access control\nmust meet stringent compliance and adaptability standards.",
      "tldr_zh": "本研究提出了一种三元个性化访问控制模型GPT-Onto-CAABAC，旨在提升电子健康记录(EHR)的安全，通过整合Generative Pretrained Transformer (GPT)、医疗法律Ontology和Context-Aware Attribute-Based Access Control (CAABAC)，实现动态政策解释和适应医疗环境的变化。不同于传统模型，该框架提供定制化的访问控制解决方案，能准确对齐复杂的监管和情境需求。实证评估显示，GPT-Onto-CAABAC显著提高了EHR的安全性，并具有更广泛的应用潜力，尤其在需要严格合规和适应性的领域。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.08264v1",
      "published_date": "2024-03-13 05:30:30 UTC",
      "updated_date": "2024-03-13 05:30:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T15:15:29.122777"
    },
    {
      "arxiv_id": "2403.08261v1",
      "title": "CoroNetGAN: Controlled Pruning of GANs via Hypernetworks",
      "title_zh": "翻译失败",
      "authors": [
        "Aman Kumar",
        "Khushboo Anand",
        "Shubham Mandloi",
        "Ashutosh Mishra",
        "Avinash Thakur",
        "Neeraj Kasera",
        "Prathosh A P"
      ],
      "abstract": "Generative Adversarial Networks (GANs) have proven to exhibit remarkable\nperformance and are widely used across many generative computer vision\napplications. However, the unprecedented demand for the deployment of GANs on\nresource-constrained edge devices still poses a challenge due to huge number of\nparameters involved in the generation process. This has led to focused\nattention on the area of compressing GANs. Most of the existing works use\nknowledge distillation with the overhead of teacher dependency. Moreover, there\nis no ability to control the degree of compression in these methods. Hence, we\npropose CoroNet-GAN for compressing GAN using the combined strength of\ndifferentiable pruning method via hypernetworks. The proposed method provides\nthe advantage of performing controllable compression while training along with\nreducing training time by a substantial factor. Experiments have been done on\nvarious conditional GAN architectures (Pix2Pix and CycleGAN) to signify the\neffectiveness of our approach on multiple benchmark datasets such as\nEdges-to-Shoes, Horse-to-Zebra and Summer-to-Winter. The results obtained\nillustrate that our approach succeeds to outperform the baselines on\nZebra-to-Horse and Summer-to-Winter achieving the best FID score of 32.3 and\n72.3 respectively, yielding high-fidelity images across all the datasets.\nAdditionally, our approach also outperforms the state-of-the-art methods in\nachieving better inference time on various smart-phone chipsets and data-types\nmaking it a feasible solution for deployment on edge devices.",
      "tldr_zh": "这篇论文提出了 CoroNetGAN，一种通过超网络(Hypernetworks)实现 GANs (Generative Adversarial Networks) 的可控修剪方法，以解决 GANs 参数过多导致的边缘设备部署难题。不同于依赖教师模型的知识蒸馏，该方法结合可微修剪(differentiable pruning)，允许在训练过程中精确控制压缩程度，并显著减少训练时间。实验在 Pix2Pix 和 CycleGAN 等条件 GAN 架构上进行，使用 Edges-to-Shoes、Horse-to-Zebra 和 Summer-to-Winter 数据集，结果显示 CoroNetGAN 优于基线模型，在 Zebra-to-Horse 和 Summer-to-Winter 任务上获得最佳 FID score 分别为 32.3 和 72.3，并提供更快的推理时间，适合智能手机芯片等资源受限环境。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "eess.IV"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.08261v1",
      "published_date": "2024-03-13 05:24:28 UTC",
      "updated_date": "2024-03-13 05:24:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T15:15:44.302943"
    },
    {
      "arxiv_id": "2403.08833v1",
      "title": "TINA: Think, Interaction, and Action Framework for Zero-Shot Vision Language Navigation",
      "title_zh": "翻译失败",
      "authors": [
        "Dingbang Li",
        "Wenzhou Chen",
        "Xin Lin"
      ],
      "abstract": "Zero-shot navigation is a critical challenge in Vision-Language Navigation\n(VLN) tasks, where the ability to adapt to unfamiliar instructions and to act\nin unknown environments is essential. Existing supervised learning-based\nmodels, trained using annotated data through reinforcement learning, exhibit\nlimitations in generalization capabilities. Large Language Models (LLMs), with\ntheir extensive knowledge and emergent reasoning abilities, present a potential\npathway for achieving zero-shot navigation. This paper presents a VLN agent\nbased on LLMs, exploring approaches to the zero-shot navigation problem. To\ncompensate for the shortcomings of LLMs in environmental perception, we propose\nthe Thinking, Interacting, and Action (TINA) framework. TINA enables the agent\nto scrutinize perceptual information and autonomously query key clues within\nthe environment through an introduced question-answering module, thereby\naligning instructions with specific perceptual data. The navigation agent's\nperceptual abilities are enhanced through the TINA framework, while the\nexplicit thought and query processes also improve the navigational procedure's\nexplainability and transparency. We evaluate the performance of our method on\nthe Room-to-Room dataset. The experiment results indicate that our approach\nimproves the navigation performance of LLM-based agents. Our approach also\noutperformed some supervised learning-based methods, highlighting its efficacy\nin zero-shot navigation.",
      "tldr_zh": "本论文提出 TINA 框架（Think, Interaction, and Action），用于实现零样本视觉语言导航（Zero-Shot Vision Language Navigation），通过利用大型语言模型（LLMs）的推理能力来处理未知指令和环境。TINA 框架包括思考模块分析感知信息、互动模块通过问答查询关键环境线索，以及行动模块执行导航，从而提升指令与感知数据的对齐，并提高过程的可解释性和透明度。在 Room-to-Room 数据集上的实验结果表明，该方法显著改善了 LLM 代理的导航性能，甚至超过了部分监督学习方法。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.08833v1",
      "published_date": "2024-03-13 05:22:39 UTC",
      "updated_date": "2024-03-13 05:22:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T15:15:54.452451"
    },
    {
      "arxiv_id": "2403.08251v4",
      "title": "Emergence of Social Norms in Generative Agent Societies: Principles and Architecture",
      "title_zh": "生成式代理社会中的社会规范涌现：原则和架构",
      "authors": [
        "Siyue Ren",
        "Zhiyao Cui",
        "Ruiqi Song",
        "Zhen Wang",
        "Shuyue Hu"
      ],
      "abstract": "Social norms play a crucial role in guiding agents towards understanding and\nadhering to standards of behavior, thus reducing social conflicts within\nmulti-agent systems (MASs). However, current LLM-based (or generative) MASs\nlack the capability to be normative. In this paper, we propose a novel\narchitecture, named CRSEC, to empower the emergence of social norms within\ngenerative MASs. Our architecture consists of four modules: Creation &\nRepresentation, Spreading, Evaluation, and Compliance. This addresses several\nimportant aspects of the emergent processes all in one: (i) where social norms\ncome from, (ii) how they are formally represented, (iii) how they spread\nthrough agents' communications and observations, (iv) how they are examined\nwith a sanity check and synthesized in the long term, and (v) how they are\nincorporated into agents' planning and actions. Our experiments deployed in the\nSmallville sandbox game environment demonstrate the capability of our\narchitecture to establish social norms and reduce social conflicts within\ngenerative MASs. The positive outcomes of our human evaluation, conducted with\n30 evaluators, further affirm the effectiveness of our approach. Our project\ncan be accessed via the following link: https://github.com/sxswz213/CRSEC.",
      "tldr_zh": "这篇论文提出CRSEC架构，以在基于LLM的生成式多智能体系统(MASs)中实现社会规范的涌现，从而指导代理行为并减少社会冲突。架构包括四个模块：Creation & Representation（创建与表示）、Spreading（传播）、Evaluation（评估）和Compliance（遵守），分别处理规范的来源、表示、传播、检查合成以及融入代理的规划和行动。实验在Smallville sandbox游戏环境中进行，展示了CRSEC能有效建立社会规范并降低冲突，且通过30名评估者的正面反馈确认了其实际效果。",
      "categories": [
        "cs.MA",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.MA",
      "comment": "Published as a conference paper at IJCAI 2024",
      "pdf_url": "http://arxiv.org/pdf/2403.08251v4",
      "published_date": "2024-03-13 05:08:10 UTC",
      "updated_date": "2024-08-30 04:14:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T15:16:06.006073"
    },
    {
      "arxiv_id": "2403.08238v1",
      "title": "A Novel Feature Learning-based Bio-inspired Neural Network for Real-time Collision-free Rescue of Multi-Robot Systems",
      "title_zh": "一种新型基于特征学习的生物启发神经网络，用于多机器人系统的实时无碰撞救援",
      "authors": [
        "Junfei Li",
        "Simon X. Yang"
      ],
      "abstract": "Natural disasters and urban accidents drive the demand for rescue robots to\nprovide safer, faster, and more efficient rescue trajectories. In this paper, a\nfeature learning-based bio-inspired neural network (FLBBINN) is proposed to\nquickly generate a heuristic rescue path in complex and dynamic environments,\nas traditional approaches usually cannot provide a satisfactory solution to\nreal-time responses to sudden environmental changes. The neurodynamic model is\nincorporated into the feature learning method that can use environmental\ninformation to improve path planning strategies. Task assignment and\ncollision-free rescue trajectory are generated through robot poses and the\ndynamic landscape of neural activity. A dual-channel scale filter, a neural\nactivity channel, and a secondary distance fusion are employed to extract and\nfilter feature neurons. After completion of the feature learning process, a\nneurodynamics-based feature matrix is established to quickly generate the new\nheuristic rescue paths with parameter-driven topological adaptability. The\nproposed FLBBINN aims to reduce the computational complexity of the neural\nnetwork-based approach and enable the feature learning method to achieve\nreal-time responses to environmental changes. Several simulations and\nexperiments have been conducted to evaluate the performance of the proposed\nFLBBINN. The results show that the proposed FLBBINN would significantly improve\nthe speed, efficiency, and optimality for rescue operations.",
      "tldr_zh": "该论文提出了一种新型基于特征学习的生物启发神经网络（FLBBINN），旨在为多机器人系统在复杂动态环境中提供实时无碰撞救援路径，以应对自然灾害和城市事故的需求。FLBBINN 将神经动力学模型融入特征学习过程，通过机器人姿态和神经活动动态景观生成任务分配和优化轨迹，并采用双通道尺度过滤器、神经活动通道以及次级距离融合来提取和过滤特征神经元，从而建立参数驱动的拓扑适应性特征矩阵。实验结果显示，该方法显著降低了计算复杂性，实现对环境变化的实时响应，并提高了救援操作的速度、效率和最优性。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.RO",
      "comment": "This paper is accepted to publish in IEEE Transactions on Industrial\n  Electronics",
      "pdf_url": "http://arxiv.org/pdf/2403.08238v1",
      "published_date": "2024-03-13 04:43:10 UTC",
      "updated_date": "2024-03-13 04:43:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T15:16:19.483063"
    },
    {
      "arxiv_id": "2403.08222v2",
      "title": "Robust Decision Aggregation with Adversarial Experts",
      "title_zh": "翻译失败",
      "authors": [
        "Yongkang Guo",
        "Yuqing Kong"
      ],
      "abstract": "We consider a robust aggregation problem in the presence of both truthful and\nadversarial experts. The truthful experts will report their private signals\ntruthfully, while the adversarial experts can report arbitrarily. We assume\nexperts are marginally symmetric in the sense that they share the same common\nprior and marginal posteriors. The rule maker needs to design an aggregator to\npredict the true world state from these experts' reports, without knowledge of\nthe underlying information structures or adversarial strategies. We aim to find\nthe optimal aggregator that outputs a forecast minimizing regret under the\nworst information structure and adversarial strategies. The regret is defined\nby the difference in expected loss between the aggregator and a benchmark who\naggregates optimally given the information structure and reports of truthful\nexperts.\n  We focus on binary states and reports. Under L1 loss, we show that the\ntruncated mean aggregator is optimal. When there are at most k adversaries,\nthis aggregator discards the k lowest and highest reported values and averages\nthe remaining ones. For L2 loss, the optimal aggregators are piecewise linear\nfunctions. All the optimalities hold when the ratio of adversaries is bounded\nabove by a value determined by the experts' priors and posteriors. The regret\nonly depends on the ratio of adversaries, not on their total number. For hard\naggregators that output a decision, we prove that a random version of the\ntruncated mean is optimal for both L1 and L2. This aggregator randomly follows\na remaining value after discarding the $k$ lowest and highest reported values.\nWe extend the hard aggregator to multi-state setting. We evaluate our\naggregators numerically in an ensemble learning task. We also obtain negative\nresults for general adversarial aggregation problems under broader information\nstructures and report spaces.",
      "tldr_zh": "这篇论文研究了在存在真实专家和对抗专家的情况下，如何设计鲁棒的决策聚合器。真实专家诚实报告信号，而对抗专家可任意报告；聚合器目标是最小化 regret（遗憾），即与理想基准的预期损失差，而不依赖底层信息结构。针对二元状态和报告，对于 L1 loss，最优聚合器是 truncated mean，它丢弃 k 个最低和最高报告值后平均剩余值；对于 L2 loss，最优聚合器是分段线性函数。这些最优性在对抗专家比例受限时成立，并通过数值评估在集成学习任务中证明其有效性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.08222v2",
      "published_date": "2024-03-13 03:47:08 UTC",
      "updated_date": "2025-02-06 02:49:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T15:16:33.401868"
    },
    {
      "arxiv_id": "2405.18434v1",
      "title": "Modeling the Feedback of AI Price Estimations on Actual Market Values",
      "title_zh": "AI 价格估算反馈对实际市场价值的影响建模",
      "authors": [
        "Viorel Silaghi",
        "Zobaida Alssadi",
        "Ben Mathew",
        "Majed Alotaibi",
        "Ali Alqarni",
        "Marius Silaghi"
      ],
      "abstract": "Public availability of Artificial Intelligence generated information can\nchange the markets forever, and its factoring into economical dynamics may take\neconomists by surprise, out-dating models and schools of thought. Real estate\nhyper-inflation is not a new phenomenon but its consistent and almost\nmonotonous persistence over 12 years, coinciding with prominence of public\nestimation information from Zillow, a successful Mass Real Estate Estimator\n(MREE), could not escape unobserved. What we model is a repetitive theoretical\ngame between the MREE and the home owners, where each player has secret\ninformation and expertise. If the intention is to keep housing affordable and\nmaintain old American lifestyle with broad home-ownership, new challenges are\ndefined. Simulations show that a simple restriction of MREE-style price\nestimation availability to opt-in properties may help partially reduce feedback\nloop by acting on its likely causes, as suggested by experimental simulation\nmodels. The conjecture that the MREE pressure on real estate inflation rate is\ncorrelated with the absolute MREE estimation errors, which is logically\nexplainable, is then validated in simulations.",
      "tldr_zh": "该研究探讨了AI价格估算对实际市场价值的反馈效应，特别是Zillow这样的Mass Real Estate Estimator (MREE)如何可能加剧房地产通胀。论文构建了一个理论游戏模型，模拟MREE和房主之间的互动，其中每个参与者拥有隐藏信息和专业知识。模拟结果显示，通过限制MREE-style价格估算仅适用于选择加入的房产，可以部分减少反馈循环。最终，研究验证了MREE对通胀压力的相关性与估算错误的绝对值有关，这为保持住房负担能力和市场稳定提供了新见解。",
      "categories": [
        "econ.GN",
        "cs.AI",
        "cs.CE",
        "cs.CY",
        "cs.GT",
        "q-fin.EC"
      ],
      "primary_category": "econ.GN",
      "comment": "On February 15, 2022 we uploaded in overleaf the first draft of this\n  paper under the name \"Public AI on house price estimations through Zillow may\n  influence a monotonic house price increase and inflation forever according to\n  simulations\", https://www.overleaf.com/read/yttcffkrhvjf\\#7120e1",
      "pdf_url": "http://arxiv.org/pdf/2405.18434v1",
      "published_date": "2024-03-13 03:44:13 UTC",
      "updated_date": "2024-03-13 03:44:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T15:16:42.357129"
    },
    {
      "arxiv_id": "2403.10553v1",
      "title": "Learning to Watermark LLM-generated Text via Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Xiaojun Xu",
        "Yuanshun Yao",
        "Yang Liu"
      ],
      "abstract": "We study how to watermark LLM outputs, i.e. embedding algorithmically\ndetectable signals into LLM-generated text to track misuse. Unlike the current\nmainstream methods that work with a fixed LLM, we expand the watermark design\nspace by including the LLM tuning stage in the watermark pipeline. While prior\nworks focus on token-level watermark that embeds signals into the output, we\ndesign a model-level watermark that embeds signals into the LLM weights, and\nsuch signals can be detected by a paired detector. We propose a co-training\nframework based on reinforcement learning that iteratively (1) trains a\ndetector to detect the generated watermarked text and (2) tunes the LLM to\ngenerate text easily detectable by the detector while keeping its normal\nutility. We empirically show that our watermarks are more accurate, robust, and\nadaptable (to new attacks). It also allows watermarked model open-sourcing. In\naddition, if used together with alignment, the extra overhead introduced is low\n- only training an extra reward model (i.e. our detector). We hope our work can\nbring more effort into studying a broader watermark design that is not limited\nto working with a fixed LLM. We open-source the code:\nhttps://github.com/xiaojunxu/learning-to-watermark-llm .",
      "tldr_zh": "本文提出了一种通过强化学习（Reinforcement Learning）为大型语言模型（LLM）生成文本添加水印的方法，以追踪文本误用，并扩展了水印设计空间，将LLM微调阶段纳入其中。不同于传统的标记级水印，该方法采用模型级水印（model-level watermark），通过强化学习的联合训练框架迭代训练检测器（detector）来识别水印文本，同时微调LLM以确保生成文本易于检测且保持正常功能。实验结果表明，这种水印更准确、鲁棒且能适应新攻击，并允许水印模型开源；此外，与对齐技术结合时，额外开销较低，仅需训练一个额外的奖励模型（reward model）。这项工作呼吁更多研究探索更广泛的水印设计，不限于固定LLM，并提供了开源代码。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.10553v1",
      "published_date": "2024-03-13 03:43:39 UTC",
      "updated_date": "2024-03-13 03:43:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T15:16:56.307966"
    },
    {
      "arxiv_id": "2403.08215v2",
      "title": "LIX: Implicitly Infusing Spatial Geometric Prior Knowledge into Visual Semantic Segmentation for Autonomous Driving",
      "title_zh": "翻译失败",
      "authors": [
        "Sicen Guo",
        "Ziwei Long",
        "Zhiyuan Wu",
        "Qijun Chen",
        "Ioannis Pitas",
        "Rui Fan"
      ],
      "abstract": "Despite the impressive performance achieved by data-fusion networks with\nduplex encoders for visual semantic segmentation, they become ineffective when\nspatial geometric data are not available. Implicitly infusing the spatial\ngeometric prior knowledge acquired by a data-fusion teacher network into a\nsingle-modal student network is a practical, albeit less explored research\navenue. This article delves into this topic and resorts to knowledge\ndistillation approaches to address this problem. We introduce the Learning to\nInfuse ''X'' (LIX) framework, with novel contributions in both logit\ndistillation and feature distillation aspects. We present a mathematical proof\nthat underscores the limitation of using a single, fixed weight in decoupled\nknowledge distillation and introduce a logit-wise dynamic weight controller as\na solution to this issue. Furthermore, we develop an adaptively-recalibrated\nfeature distillation algorithm, including two novel techniques: feature\nrecalibration via kernel regression and in-depth feature consistency\nquantification via centered kernel alignment. Extensive experiments conducted\nwith intermediate-fusion and late-fusion networks across various public\ndatasets provide both quantitative and qualitative evaluations, demonstrating\nthe superior performance of our LIX framework when compared to other\nstate-of-the-art approaches.",
      "tldr_zh": "本研究提出 LIX 框架，通过知识 distillation 方法隐式地将空间几何先验知识从数据融合教师网络注入到单模态学生网络中，提升自主驾驶场景下的 visual semantic segmentation 性能。\n在 logit distillation 方面，该框架证明了使用固定权重的局限性，并引入 logit-wise 动态权重控制器作为解决方案；在 feature distillation 方面，开发了自适应重新校准算法，包括 feature recalibration via kernel regression 和 in-depth feature consistency quantification via centered kernel alignment。\n实验结果显示，LIX 在多个公共数据集上的 intermediate-fusion 和 late-fusion 网络中，表现出色，优于其他最先进方法。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "13 pages, 7 figures, 5 tables",
      "pdf_url": "http://arxiv.org/pdf/2403.08215v2",
      "published_date": "2024-03-13 03:24:36 UTC",
      "updated_date": "2025-03-14 09:24:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T15:17:08.308948"
    },
    {
      "arxiv_id": "2403.08214v3",
      "title": "P2LHAP:Wearable sensor-based human activity recognition, segmentation and forecast through Patch-to-Label Seq2Seq Transformer",
      "title_zh": "翻译失败",
      "authors": [
        "Shuangjian Li",
        "Tao Zhu",
        "Mingxing Nie",
        "Huansheng Ning",
        "Zhenyu Liu",
        "Liming Chen"
      ],
      "abstract": "Traditional deep learning methods struggle to simultaneously segment,\nrecognize, and forecast human activities from sensor data. This limits their\nusefulness in many fields such as healthcare and assisted living, where\nreal-time understanding of ongoing and upcoming activities is crucial. This\npaper introduces P2LHAP, a novel Patch-to-Label Seq2Seq framework that tackles\nall three tasks in a efficient single-task model. P2LHAP divides sensor data\nstreams into a sequence of \"patches\", served as input tokens, and outputs a\nsequence of patch-level activity labels including the predicted future\nactivities. A unique smoothing technique based on surrounding patch labels, is\nproposed to identify activity boundaries accurately. Additionally, P2LHAP\nlearns patch-level representation by sensor signal channel-independent\nTransformer encoders and decoders. All channels share embedding and Transformer\nweights across all sequences. Evaluated on three public datasets, P2LHAP\nsignificantly outperforms the state-of-the-art in all three tasks,\ndemonstrating its effectiveness and potential for real-world applications.",
      "tldr_zh": "本文提出 P2LHAP，一种基于 Patch-to-Label Seq2Seq Transformer 的框架，用于从可穿戴传感器数据中同时实现人类活动识别、分割和预测，解决了传统深度学习方法无法高效处理这些任务的局限性。P2LHAP 将传感器数据流分成补丁序列作为输入，并输出补丁级别的活动标签，同时引入基于周围补丁标签的平滑技术来准确识别活动边界，所有传感器通道共享 Transformer 权重以提升效率。在三个公共数据集上，该框架在所有任务上显著优于现有最先进方法，展示了其在医疗和辅助生活等领域的实际应用潜力。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.08214v3",
      "published_date": "2024-03-13 03:23:50 UTC",
      "updated_date": "2024-09-21 14:53:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T15:17:20.576110"
    },
    {
      "arxiv_id": "2403.10552v1",
      "title": "Training Self-localization Models for Unseen Unfamiliar Places via Teacher-to-Student Data-Free Knowledge Transfer",
      "title_zh": "翻译失败",
      "authors": [
        "Kenta Tsukahara",
        "Kanji Tanaka",
        "Daiki Iwata"
      ],
      "abstract": "A typical assumption in state-of-the-art self-localization models is that an\nannotated training dataset is available in the target workspace. However, this\ndoes not always hold when a robot travels in a general open-world. This study\nintroduces a novel training scheme for open-world distributed robot systems. In\nour scheme, a robot (\"student\") can ask the other robots it meets at unfamiliar\nplaces (\"teachers\") for guidance. Specifically, a pseudo-training dataset is\nreconstructed from the teacher model and thereafter used for continual learning\nof the student model. Unlike typical knowledge transfer schemes, our scheme\nintroduces only minimal assumptions on the teacher model, such that it can\nhandle various types of open-set teachers, including uncooperative, untrainable\n(e.g., image retrieval engines), and blackbox teachers (i.e., data privacy).\nRather than relying on the availability of private data of teachers as in\nexisting methods, we propose to exploit an assumption that holds universally in\nself-localization tasks: \"The teacher model is a self-localization system\" and\nto reuse the self-localization system of a teacher as a sole accessible\ncommunication channel. We particularly focus on designing an excellent\nstudent/questioner whose interactions with teachers can yield effective\nquestion-and-answer sequences that can be used as pseudo-training datasets for\nthe student self-localization model. When applied to a generic recursive\nknowledge distillation scenario, our approach exhibited stable and consistent\nperformance improvement.",
      "tldr_zh": "本文提出了一种无需标注数据集的训练方案，用于在未知环境中训练self-localization模型，通过teacher-to-student的数据无知识转移实现。学生机器人通过与遇到的老师机器人互动，从老师模型重建伪训练数据集，用于自身的持续学习，该方法仅假设老师是self-localization系统，从而支持不合作、不可训练或黑箱老师的开放集场景。实验结果显示，该方法在递归知识蒸馏场景中实现了稳定的性能提升。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV",
        "cs.RO"
      ],
      "primary_category": "cs.LG",
      "comment": "7 pages, 3 figures, technical report",
      "pdf_url": "http://arxiv.org/pdf/2403.10552v1",
      "published_date": "2024-03-13 03:20:47 UTC",
      "updated_date": "2024-03-13 03:20:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T15:17:31.296864"
    },
    {
      "arxiv_id": "2403.08211v3",
      "title": "Large Language Models are Contrastive Reasoners",
      "title_zh": "大型语言模型是对比推理器",
      "authors": [
        "Liang Yao"
      ],
      "abstract": "Prompting methods play a crucial role in enhancing the capabilities of\npre-trained large language models (LLMs). We explore how contrastive prompting\n(CP) significantly improves the ability of large language models to perform\ncomplex reasoning. We demonstrate that LLMs are decent contrastive reasoners by\nsimply adding \"Let's give a correct and a wrong answer.\" before LLMs provide\nanswers. Experiments on various large language models show that zero-shot\ncontrastive prompting improves the performance of standard zero-shot prompting\non a range of arithmetic, commonsense, and symbolic reasoning tasks without any\nhand-crafted few-shot examples, such as increasing the accuracy on GSM8K from\n35.9% to 88.8% and AQUA-RAT from 41.3% to 62.2% with the state-of-the-art GPT-4\nmodel. Our method not only surpasses zero-shot CoT and few-shot CoT in most\narithmetic and commonsense reasoning tasks but also can seamlessly integrate\nwith existing prompting methods, resulting in improved or comparable results\nwhen compared to state-of-the-art methods. Our code is available at\nhttps://github.com/yao8839836/cp",
      "tldr_zh": "这篇论文探讨了对比提示（Contrastive Prompting, CP）如何显著提升大型语言模型（LLMs）的复杂推理能力，通过简单添加“Let's give a correct and a wrong answer.”的指令，让模型生成正确和错误答案进行对比。实验结果显示，零样本 CP 在算术、常识和符号推理任务上优于标准零样本提示，例如使用 GPT-4 在 GSM8K 的准确率从 35.9% 提高到 88.8%，在 AQUA-RAT 从 41.3% 提高到 62.2%。该方法不仅超越了零样本和少样本 Chain-of-Thought（CoT）提示，还能无缝整合现有提示技术，提供更高效的推理性能。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.08211v3",
      "published_date": "2024-03-13 03:15:05 UTC",
      "updated_date": "2025-02-17 06:40:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T15:17:44.753261"
    },
    {
      "arxiv_id": "2403.08199v3",
      "title": "Deep Submodular Peripteral Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Gantavya Bhatt",
        "Arnav Das",
        "Jeff Bilmes"
      ],
      "abstract": "Submodular functions, crucial for various applications, often lack practical\nlearning methods for their acquisition. Seemingly unrelated, learning a scaling\nfrom oracles offering graded pairwise preferences (GPC) is underexplored,\ndespite a rich history in psychometrics. In this paper, we introduce deep\nsubmodular peripteral networks (DSPNs), a novel parametric family of submodular\nfunctions, and methods for their training using a GPC-based strategy to connect\nand then tackle both of the above challenges. We introduce newly devised\nGPC-style ``peripteral'' loss which leverages numerically graded relationships\nbetween pairs of objects (sets in our case). Unlike traditional contrastive\nlearning, or RHLF preference ranking, our method utilizes graded comparisons,\nextracting more nuanced information than just binary-outcome comparisons, and\ncontrasts sets of any size (not just two). We also define a novel suite of\nautomatic sampling strategies for training, including active-learning inspired\nsubmodular feedback. We demonstrate DSPNs' efficacy in learning submodularity\nfrom a costly target submodular function and demonstrate its superiority both\nfor experimental design and online streaming applications.",
      "tldr_zh": "本论文引入了 deep submodular peripteral networks (DSPNs)，一种新的参数化 submodular functions 家族，用于解决 submodular functions 学习缺乏实用方法的挑战，并通过 graded pairwise preferences (GPC) 策略进行训练。\nDSPNs 采用创新的 peripteral loss，利用成对对象（包括任意大小的集合）的数值化关系进行更细致的对比学习，结合新型自动采样策略（如受 active-learning 启发的 submodular feedback）。\n实验结果表明，DSPNs 在从昂贵的目标 submodular function 学习 submodularity 方面表现出色，并在实验设计和在线流式应用中优于传统方法。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at NeurIPS 2024 as spotlight presentation",
      "pdf_url": "http://arxiv.org/pdf/2403.08199v3",
      "published_date": "2024-03-13 02:53:52 UTC",
      "updated_date": "2024-10-31 23:34:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T15:17:56.601716"
    },
    {
      "arxiv_id": "2403.13002v4",
      "title": "AutoTRIZ: Automating Engineering Innovation with TRIZ and Large Language Models",
      "title_zh": "AutoTRIZ：",
      "authors": [
        "Shuo Jiang",
        "Weifeng Li",
        "Yuping Qian",
        "Yangjun Zhang",
        "Jianxi Luo"
      ],
      "abstract": "Various ideation methods, such as morphological analysis and\ndesign-by-analogy, have been developed to aid creative problem-solving and\ninnovation. Among them, the Theory of Inventive Problem Solving (TRIZ) stands\nout as one of the best-known methods. However, the complexity of TRIZ and its\nreliance on users' knowledge, experience, and reasoning capabilities limit its\npracticality. To address this, we introduce AutoTRIZ, an artificial ideation\nsystem that integrates Large Language Models (LLMs) to automate and enhance the\nTRIZ methodology. By leveraging LLMs' vast pre-trained knowledge and advanced\nreasoning capabilities, AutoTRIZ offers a novel, generative, and interpretable\napproach to engineering innovation. AutoTRIZ takes a problem statement from the\nuser as its initial input, automatically conduct the TRIZ reasoning process and\ngenerates a structured solution report. We demonstrate and evaluate the\neffectiveness of AutoTRIZ through comparative experiments with textbook cases\nand a real-world application in the design of a Battery Thermal Management\nSystem (BTMS). Moreover, the proposed LLM-based framework holds the potential\nfor extension to automate other knowledge-based ideation methods, such as\nSCAMPER, Design Heuristics, and Design-by-Analogy, paving the way for a new era\nof AI-driven innovation tools.",
      "tldr_zh": "本研究提出AutoTRIZ系统，通过整合Large Language Models (LLMs)，自动化并提升TRIZ（Theory of Inventive Problem Solving）方法，以解决其复杂性和对用户知识的依赖问题。AutoTRIZ以用户问题语句为输入，自动进行TRIZ推理过程，并生成结构化的解决方案报告，利用LLMs的预训练知识和高级推理能力提供生成式和可解释的创新途径。通过与教科书案例和实际应用（如Battery Thermal Management System的设计）的比较实验，证明AutoTRIZ的有效性，并展示其扩展潜力至其他构想方法，如SCAMPER、Design Heuristics和Design-by-Analogy，从而推动AI驱动的工程创新新时代。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CL",
        "I.2.7; I.2.1"
      ],
      "primary_category": "cs.HC",
      "comment": "28 pages, 12 figures",
      "pdf_url": "http://arxiv.org/pdf/2403.13002v4",
      "published_date": "2024-03-13 02:53:36 UTC",
      "updated_date": "2025-03-24 12:10:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T15:18:07.730294"
    },
    {
      "arxiv_id": "2403.08197v1",
      "title": "PAGE: Domain-Incremental Adaptation with Past-Agnostic Generative Replay for Smart Healthcare",
      "title_zh": "翻译失败",
      "authors": [
        "Chia-Hao Li",
        "Niraj K. Jha"
      ],
      "abstract": "We propose PAGE, a domain-incremental adaptation strategy with past-agnostic\ngenerative replay for smart healthcare. PAGE enables generative replay without\nthe aid of any preserved data or information from prior domains. When adapting\nto a new domain, it exploits real data from the new distribution and the\ncurrent model to generate synthetic data that retain the learned knowledge of\nprevious domains. By replaying the synthetic data with the new real data during\ntraining, PAGE achieves a good balance between domain adaptation and knowledge\nretention. In addition, we incorporate an extended inductive conformal\nprediction (EICP) method into PAGE to produce a confidence score and a\ncredibility value for each detection result. This makes the predictions\ninterpretable and provides statistical guarantees for disease detection in\nsmart healthcare applications. We demonstrate PAGE's effectiveness in\ndomain-incremental disease detection with three distinct disease datasets\ncollected from commercially available WMSs. PAGE achieves highly competitive\nperformance against state-of-the-art with superior scalability, data privacy,\nand feasibility. Furthermore, PAGE can enable up to 75% reduction in clinical\nworkload with the help of EICP.",
      "tldr_zh": "该研究提出了 PAGE，一种在智能医疗领域用于域增量适应的策略，通过 past-agnostic generative replay 实现生成重放，而无需保存先前域的数据，利用新域的真实数据和当前模型生成合成数据，以平衡域适应和知识保留。PAGE 还整合了 extended inductive conformal prediction (EICP) 方法，为每个检测结果提供置信分数和可信度值，提升预测的可解释性和统计可靠性。实验在三个疾病数据集上证明，PAGE 与最先进方法相比具有高度竞争性能，并可减少高达 75% 的临床工作量，同时提升数据隐私和可扩展性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "30 pages, 7 figures. arXiv admin note: text overlap with\n  arXiv:2305.05738",
      "pdf_url": "http://arxiv.org/pdf/2403.08197v1",
      "published_date": "2024-03-13 02:44:33 UTC",
      "updated_date": "2024-03-13 02:44:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T15:18:22.810726"
    },
    {
      "arxiv_id": "2403.09732v4",
      "title": "PET-SQL: A Prompt-Enhanced Two-Round Refinement of Text-to-SQL with Cross-consistency",
      "title_zh": "翻译失败",
      "authors": [
        "Zhishuai Li",
        "Xiang Wang",
        "Jingjing Zhao",
        "Sun Yang",
        "Guoqing Du",
        "Xiaoru Hu",
        "Bin Zhang",
        "Yuxiao Ye",
        "Ziyue Li",
        "Rui Zhao",
        "Hangyu Mao"
      ],
      "abstract": "Recent advancements in Text-to-SQL (Text2SQL) emphasize stimulating the large\nlanguage models (LLM) on in-context learning, achieving significant results.\nNevertheless, they face challenges when dealing with verbose database\ninformation and complex user intentions. This paper presents a two-stage\nframework to enhance the performance of current LLM-based natural language to\nSQL systems. We first introduce a novel prompt representation, called\nreference-enhanced representation, which includes schema information and\nrandomly sampled cell values from tables to instruct LLMs in generating SQL\nqueries. Then, in the first stage, question-SQL pairs are retrieved as few-shot\ndemonstrations, prompting the LLM to generate a preliminary SQL (PreSQL). After\nthat, the mentioned entities in PreSQL are parsed to conduct schema linking,\nwhich can significantly compact the useful information. In the second stage,\nwith the linked schema, we simplify the prompt's schema information and\ninstruct the LLM to produce the final SQL. Finally, as the post-refinement\nmodule, we propose using cross-consistency across different LLMs rather than\nself-consistency within a particular LLM. Our methods achieve new SOTA results\non the Spider benchmark, with an execution accuracy of 87.6%.",
      "tldr_zh": "本研究提出了一种名为 PET-SQL 的框架，通过提示增强和两轮精炼方法来提升 Text-to-SQL (Text2SQL) 系统的性能，针对冗长数据库信息和复杂用户意图的挑战。框架首先使用 reference-enhanced representation 结合 schema 信息和随机采样单元格值，以及 question-SQL pairs 作为 few-shot demonstrations，生成初步 SQL (PreSQL)，随后通过 schema linking 解析实体以简化信息；在第二轮中，利用链接后的 schema 进一步简化提示生成最终 SQL。作为后处理模块，该框架采用跨不同 LLMs 的 cross-consistency 而非单一 LLM 的 self-consistency，以提高一致性。该方法在 Spider benchmark 上实现了 87.6% 的执行准确率，取得了新的 SOTA 结果。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.09732v4",
      "published_date": "2024-03-13 02:32:41 UTC",
      "updated_date": "2024-06-02 02:58:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T15:18:33.867021"
    },
    {
      "arxiv_id": "2403.10550v1",
      "title": "Semi-Supervised Learning for Anomaly Traffic Detection via Bidirectional Normalizing Flows",
      "title_zh": "翻译失败",
      "authors": [
        "Zhangxuan Dang",
        "Yu Zheng",
        "Xinglin Lin",
        "Chunlei Peng",
        "Qiuyu Chen",
        "Xinbo Gao"
      ],
      "abstract": "With the rapid development of the Internet, various types of anomaly traffic\nare threatening network security. We consider the problem of anomaly network\ntraffic detection and propose a three-stage anomaly detection framework using\nonly normal traffic. Our framework can generate pseudo anomaly samples without\nprior knowledge of anomalies to achieve the detection of anomaly data. Firstly,\nwe employ a reconstruction method to learn the deep representation of normal\nsamples. Secondly, these representations are normalized to a standard normal\ndistribution using a bidirectional flow module. To simulate anomaly samples, we\nadd noises to the normalized representations which are then passed through the\ngeneration direction of the bidirectional flow module. Finally, a simple\nclassifier is trained to differentiate the normal samples and pseudo anomaly\nsamples in the latent space. During inference, our framework requires only two\nmodules to detect anomalous samples, leading to a considerable reduction in\nmodel size. According to the experiments, our method achieves the state\nof-the-art results on the common benchmarking datasets of anomaly network\ntraffic detection. The code is given in the\nhttps://github.com/ZxuanDang/ATD-via-Flows.git",
      "tldr_zh": "本研究提出了一种基于Bidirectional Normalizing Flows的半监督学习框架，用于异常流量检测，该框架仅使用正常流量生成伪异常样本以实现检测。方法包括三个阶段：首先，通过重构方法学习正常样本的深度表示；其次，使用双向流模块将这些表示标准化为标准正态分布；最后，向标准化表示添加噪声生成伪异常样本，并训练一个简单分类器在潜在空间区分正常和伪异常样本。实验结果显示，该框架在常见异常网络流量基准数据集上达到了最先进性能，同时显著减少了模型大小。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.10550v1",
      "published_date": "2024-03-13 02:10:32 UTC",
      "updated_date": "2024-03-13 02:10:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T15:18:44.735903"
    },
    {
      "arxiv_id": "2403.08174v1",
      "title": "Rethinking Loss Functions for Fact Verification",
      "title_zh": "翻译失败",
      "authors": [
        "Yuta Mukobara",
        "Yutaro Shigeto",
        "Masashi Shimbo"
      ],
      "abstract": "We explore loss functions for fact verification in the FEVER shared task.\nWhile the cross-entropy loss is a standard objective for training verdict\npredictors, it fails to capture the heterogeneity among the FEVER verdict\nclasses. In this paper, we develop two task-specific objectives tailored to\nFEVER. Experimental results confirm that the proposed objective functions\noutperform the standard cross-entropy. Performance is further improved when\nthese objectives are combined with simple class weighting, which effectively\novercomes the imbalance in the training data. The souce code is available at\nhttps://github.com/yuta-mukobara/RLF-KGAT",
      "tldr_zh": "本论文重新审视了事实验证任务中损失函数的设计，针对FEVER共享任务指出标准cross-entropy loss无法捕捉判决类别间的异质性。研究者开发了两个针对FEVER的任务特定目标函数，并通过简单类别加权来解决训练数据的不平衡问题。实验结果显示，这些新目标函数优于cross-entropy loss，且结合类别加权后进一步提升了性能，为事实验证模型优化提供了实用方法。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to EACL 2024 (short paper). The souce code is available at\n  https://github.com/yuta-mukobara/RLF-KGAT",
      "pdf_url": "http://arxiv.org/pdf/2403.08174v1",
      "published_date": "2024-03-13 01:56:32 UTC",
      "updated_date": "2024-03-13 01:56:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T15:18:56.034013"
    },
    {
      "arxiv_id": "2403.13001v1",
      "title": "Fundamental Components of Deep Learning: A category-theoretic approach",
      "title_zh": "深度学习的根本组成部分：基于范畴论的方法",
      "authors": [
        "Bruno Gavranović"
      ],
      "abstract": "Deep learning, despite its remarkable achievements, is still a young field.\nLike the early stages of many scientific disciplines, it is marked by the\ndiscovery of new phenomena, ad-hoc design decisions, and the lack of a uniform\nand compositional mathematical foundation. From the intricacies of the\nimplementation of backpropagation, through a growing zoo of neural network\narchitectures, to the new and poorly understood phenomena such as double\ndescent, scaling laws or in-context learning, there are few unifying principles\nin deep learning. This thesis develops a novel mathematical foundation for deep\nlearning based on the language of category theory. We develop a new framework\nthat is a) end-to-end, b) unform, and c) not merely descriptive, but\nprescriptive, meaning it is amenable to direct implementation in programming\nlanguages with sufficient features. We also systematise many existing\napproaches, placing many existing constructions and concepts from the\nliterature under the same umbrella. In Part I we identify and model two main\nproperties of deep learning systems parametricity and bidirectionality by we\nexpand on the previously defined construction of actegories and Para to study\nthe former, and define weighted optics to study the latter. Combining them\nyields parametric weighted optics, a categorical model of artificial neural\nnetworks, and more. Part II justifies the abstractions from Part I, applying\nthem to model backpropagation, architectures, and supervised learning. We\nprovide a lens-theoretic axiomatisation of differentiation, covering not just\nsmooth spaces, but discrete settings of boolean circuits as well. We survey\nexisting, and develop new categorical models of neural network architectures.\nWe formalise the notion of optimisers and lastly, combine all the existing\nconcepts together, providing a uniform and compositional framework for\nsupervised learning.",
      "tldr_zh": "本论文探讨了深度学习缺乏统一数学基础的问题，并提出一种基于 category theory 的新框架，以系统化该领域的核心组件。该框架是 end-to-end、uniform 且 prescriptive，可直接在编程语言中实现，包括使用 actegories、Para 和 weighted optics 来建模深度学习的 parametricity 和 bidirectionality。在 Part II 中，作者应用这一框架来 axiomatise backpropagation（覆盖 smooth 和 discrete 设置，如 boolean circuits）、神经网络架构和 supervised learning，提供了一个统一的组合式模型。该方法不仅系统化了现有方法，还为深度学习的数学基础奠定了坚实基础。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "math.CT"
      ],
      "primary_category": "cs.LG",
      "comment": "PhD Thesis defended at University of Strathclyde",
      "pdf_url": "http://arxiv.org/pdf/2403.13001v1",
      "published_date": "2024-03-13 01:29:40 UTC",
      "updated_date": "2024-03-13 01:29:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T15:19:08.310924"
    },
    {
      "arxiv_id": "2403.08161v1",
      "title": "LAFS: Landmark-based Facial Self-supervised Learning for Face Recognition",
      "title_zh": "翻译失败",
      "authors": [
        "Zhonglin Sun",
        "Chen Feng",
        "Ioannis Patras",
        "Georgios Tzimiropoulos"
      ],
      "abstract": "In this work we focus on learning facial representations that can be adapted\nto train effective face recognition models, particularly in the absence of\nlabels. Firstly, compared with existing labelled face datasets, a vastly larger\nmagnitude of unlabeled faces exists in the real world. We explore the learning\nstrategy of these unlabeled facial images through self-supervised pretraining\nto transfer generalized face recognition performance. Moreover, motivated by\none recent finding, that is, the face saliency area is critical for face\nrecognition, in contrast to utilizing random cropped blocks of images for\nconstructing augmentations in pretraining, we utilize patches localized by\nextracted facial landmarks. This enables our method - namely LAndmark-based\nFacial Self-supervised learning LAFS), to learn key representation that is more\ncritical for face recognition. We also incorporate two landmark-specific\naugmentations which introduce more diversity of landmark information to further\nregularize the learning. With learned landmark-based facial representations, we\nfurther adapt the representation for face recognition with regularization\nmitigating variations in landmark positions. Our method achieves significant\nimprovement over the state-of-the-art on multiple face recognition benchmarks,\nespecially on more challenging few-shot scenarios.",
      "tldr_zh": "这篇论文提出了一种基于地标的面部自监督学习方法（LAFS），旨在通过无标签面部图像的预训练来提升面部识别性能，特别是解决标签缺失的问题。LAFS创新性地利用提取的面部landmarks来定位图像补丁，而不是随机裁剪，并引入两种landmark-specific augmentations来增加地标信息的多样性，以学习更关键的面部表示。随后，通过正则化处理landmark位置的变化，该方法在多个面部识别基准上实现了显著改进，尤其在few-shot场景中表现突出。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "accepted to CVPR 2024",
      "pdf_url": "http://arxiv.org/pdf/2403.08161v1",
      "published_date": "2024-03-13 01:07:55 UTC",
      "updated_date": "2024-03-13 01:07:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T15:19:21.297687"
    },
    {
      "arxiv_id": "2403.08153v2",
      "title": "The Runtime of Random Local Search on the Generalized Needle Problem",
      "title_zh": "随机局部搜索在广义针问题上的运行时间",
      "authors": [
        "Benjamin Doerr",
        "Andrew James Kelley"
      ],
      "abstract": "In their recent work, C. Doerr and Krejca (Transactions on Evolutionary\nComputation, 2023) proved upper bounds on the expected runtime of the\nrandomized local search heuristic on generalized Needle functions. Based on\nthese upper bounds, they deduce in a not fully rigorous manner a drastic\ninfluence of the needle radius $k$ on the runtime.\n  In this short article, we add the missing lower bound necessary to determine\nthe influence of parameter $k$ on the runtime. To this aim, we derive an exact\ndescription of the expected runtime, which also significantly improves the\nupper bound given by C. Doerr and Krejca. We also describe asymptotic estimates\nof the expected runtime.",
      "tldr_zh": "这篇论文针对随机局部搜索(randomized local search)算法在广义 Needle 函数(generalized Needle functions)上的预期运行时(expected runtime)进行了分析。作者补充了先前由 C. Doerr 和 Krejca 提出的上界，并首次提供了必要的下界，以精确确定 needle radius $k$ 参数对运行时的影响。论文还导出了预期运行时的精确描述，显著改善了现有上界，并给出了渐近估计(asymptotic estimates)。",
      "categories": [
        "cs.NE",
        "cs.AI",
        "cs.DS"
      ],
      "primary_category": "cs.NE",
      "comment": "18 pages",
      "pdf_url": "http://arxiv.org/pdf/2403.08153v2",
      "published_date": "2024-03-13 00:30:47 UTC",
      "updated_date": "2024-03-20 00:18:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T15:19:33.137822"
    },
    {
      "arxiv_id": "2403.08151v1",
      "title": "Measuring the Energy Consumption and Efficiency of Deep Neural Networks: An Empirical Analysis and Design Recommendations",
      "title_zh": "测量深度神经网络的能耗和效率：一项经验分析和设计建议",
      "authors": [
        "Charles Edison Tripp",
        "Jordan Perr-Sauer",
        "Jamil Gafur",
        "Amabarish Nag",
        "Avi Purkayastha",
        "Sagi Zisman",
        "Erik A. Bensen"
      ],
      "abstract": "Addressing the so-called ``Red-AI'' trend of rising energy consumption by\nlarge-scale neural networks, this study investigates the actual energy\nconsumption, as measured by node-level watt-meters, of training various fully\nconnected neural network architectures. We introduce the BUTTER-E dataset, an\naugmentation to the BUTTER Empirical Deep Learning dataset, containing energy\nconsumption and performance data from 63,527 individual experimental runs\nspanning 30,582 distinct configurations: 13 datasets, 20 sizes (number of\ntrainable parameters), 8 network ``shapes'', and 14 depths on both CPU and GPU\nhardware collected using node-level watt-meters. This dataset reveals the\ncomplex relationship between dataset size, network structure, and energy use,\nand highlights the impact of cache effects. We propose a straightforward and\neffective energy model that accounts for network size, computing, and memory\nhierarchy. Our analysis also uncovers a surprising, hardware-mediated\nnon-linear relationship between energy efficiency and network design,\nchallenging the assumption that reducing the number of parameters or FLOPs is\nthe best way to achieve greater energy efficiency. Highlighting the need for\ncache-considerate algorithm development, we suggest a combined approach to\nenergy efficient network, algorithm, and hardware design. This work contributes\nto the fields of sustainable computing and Green AI, offering practical\nguidance for creating more energy-efficient neural networks and promoting\nsustainable AI.",
      "tldr_zh": "本研究针对大规模神经网络的能源消耗（Red-AI 趋势）进行实证分析，使用节点级瓦特计测量各种全连接神经网络架构的训练能源消耗，并引入了BUTTER-E数据集，涵盖63,527个实验运行的数据，包括13个数据集、20个网络大小、8个形状和14个深度，在CPU和GPU硬件上收集。\n分析揭示了数据集大小、网络结构与能源使用之间的复杂关系，以及缓存效果的显著影响，挑战了减少参数或FLOPs是最佳能源效率策略的假设。\n研究提出一个简单有效的能源模型，考虑网络大小、计算和内存层次，并建议结合网络、算法和硬件设计的方法，以推动可持续计算和Green AI的发展。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NE"
      ],
      "primary_category": "cs.LG",
      "comment": "25 pages, 8 figures, for associated dataset see\n  https://data.openei.org/submissions/5991",
      "pdf_url": "http://arxiv.org/pdf/2403.08151v1",
      "published_date": "2024-03-13 00:27:19 UTC",
      "updated_date": "2024-03-13 00:27:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T15:19:47.790036"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 118,
  "processed_papers_count": 118,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-17T15:20:23.810219"
}