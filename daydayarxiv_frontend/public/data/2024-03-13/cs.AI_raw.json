[
  {
    "arxiv_id": "2403.13004v1",
    "title": "(Beyond) Reasonable Doubt: Challenges that Public Defenders Face in Scrutinizing AI in Court",
    "authors": [
      "Angela Jin",
      "Niloufar Salehi"
    ],
    "abstract": "Accountable use of AI systems in high-stakes settings relies on making\nsystems contestable. In this paper we study efforts to contest AI systems in\npractice by studying how public defenders scrutinize AI in court. We present\nfindings from interviews with 17 people in the U.S. public defense community to\nunderstand their perceptions of and experiences scrutinizing computational\nforensic software (CFS) -- automated decision systems that the government uses\nto convict and incarcerate, such as facial recognition, gunshot detection, and\nprobabilistic genotyping tools. We find that our participants faced challenges\nassessing and contesting CFS reliability due to difficulties (a) navigating how\nCFS is developed and used, (b) overcoming judges and jurors' non-critical\nperceptions of CFS, and (c) gathering CFS expertise. To conclude, we provide\nrecommendations that center the technical, social, and institutional context to\nbetter position interventions such as performance evaluations to support\ncontestability in practice.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.HC",
      "K.4.0"
    ],
    "primary_category": "cs.CY",
    "comment": "29 pages, 4 figures. To appear in Proceedings of the CHI Conference\n  on Human Factors in Computing Systems (CHI '24)",
    "pdf_url": "http://arxiv.org/pdf/2403.13004v1",
    "published_date": "2024-03-13 23:19:46 UTC",
    "updated_date": "2024-03-13 23:19:46 UTC"
  },
  {
    "arxiv_id": "2403.09744v1",
    "title": "Evaluating the Application of Large Language Models to Generate Feedback in Programming Education",
    "authors": [
      "Sven Jacobs",
      "Steffen Jaschke"
    ],
    "abstract": "This study investigates the application of large language models,\nspecifically GPT-4, to enhance programming education. The research outlines the\ndesign of a web application that uses GPT-4 to provide feedback on programming\ntasks, without giving away the solution. A web application for working on\nprogramming tasks was developed for the study and evaluated with 51 students\nover the course of one semester. The results show that most of the feedback\ngenerated by GPT-4 effectively addressed code errors. However, challenges with\nincorrect suggestions and hallucinated issues indicate the need for further\nimprovements.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CY",
      "cs.HC"
    ],
    "primary_category": "cs.CL",
    "comment": "accepted at IEEE Global Engineering Education Conference 2024, Kos,\n  Greece",
    "pdf_url": "http://arxiv.org/pdf/2403.09744v1",
    "published_date": "2024-03-13 23:14:35 UTC",
    "updated_date": "2024-03-13 23:14:35 UTC"
  },
  {
    "arxiv_id": "2403.14689v2",
    "title": "Developing and Deploying Industry Standards for Artificial Intelligence in Education (AIED): Challenges, Strategies, and Future Directions",
    "authors": [
      "Richard Tong",
      "Haoyang Li",
      "Joleen Liang",
      "Qingsong Wen"
    ],
    "abstract": "The adoption of Artificial Intelligence in Education (AIED) holds the promise\nof revolutionizing educational practices by offering personalized learning\nexperiences, automating administrative and pedagogical tasks, and reducing the\ncost of content creation. However, the lack of standardized practices in the\ndevelopment and deployment of AIED solutions has led to fragmented ecosystems,\nwhich presents challenges in interoperability, scalability, and ethical\ngovernance. This article aims to address the critical need to develop and\nimplement industry standards in AIED, offering a comprehensive analysis of the\ncurrent landscape, challenges, and strategic approaches to overcome these\nobstacles. We begin by examining the various applications of AIED in various\neducational settings and identify key areas lacking in standardization,\nincluding system interoperability, ontology mapping, data integration,\nevaluation, and ethical governance. Then, we propose a multi-tiered framework\nfor establishing robust industry standards for AIED. In addition, we discuss\nmethodologies for the iterative development and deployment of standards,\nincorporating feedback loops from real-world applications to refine and adapt\nstandards over time. The paper also highlights the role of emerging\ntechnologies and pedagogical theories in shaping future standards for AIED.\nFinally, we outline a strategic roadmap for stakeholders to implement these\nstandards, fostering a cohesive and ethical AIED ecosystem. By establishing\ncomprehensive industry standards, such as those by IEEE Artificial Intelligence\nStandards Committee (AISC) and International Organization for Standardization\n(ISO), we can accelerate and scale AIED solutions to improve educational\noutcomes, ensuring that technological advances align with the principles of\ninclusivity, fairness, and educational excellence.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CY",
    "comment": "12 pages",
    "pdf_url": "http://arxiv.org/pdf/2403.14689v2",
    "published_date": "2024-03-13 22:38:08 UTC",
    "updated_date": "2024-03-25 04:21:13 UTC"
  },
  {
    "arxiv_id": "2403.08984v1",
    "title": "Safe Road-Crossing by Autonomous Wheelchairs: a Novel Dataset and its Experimental Evaluation",
    "authors": [
      "Carlo Grigioni",
      "Franca Corradini",
      "Alessandro Antonucci",
      "Jérôme Guzzi",
      "Francesco Flammini"
    ],
    "abstract": "Safe road-crossing by self-driving vehicles is a crucial problem to address\nin smart-cities. In this paper, we introduce a multi-sensor fusion approach to\nsupport road-crossing decisions in a system composed by an autonomous\nwheelchair and a flying drone featuring a robust sensory system made of diverse\nand redundant components. To that aim, we designed an analytical danger\nfunction based on explainable physical conditions evaluated by single sensors,\nincluding those using machine learning and artificial vision. As a\nproof-of-concept, we provide an experimental evaluation in a laboratory\nenvironment, showing the advantages of using multiple sensors, which can\nimprove decision accuracy and effectively support safety assessment. We made\nthe dataset available to the scientific community for further experimentation.\nThe work has been developed in the context of an European project named\nREXASI-PRO, which aims to develop trustworthy artificial intelligence for\nsocial navigation of people with reduced mobility.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.MA",
      "68T45",
      "I.2.10; C.4; I.2.9; I.4.8"
    ],
    "primary_category": "cs.RO",
    "comment": "14 pages, 8 figures",
    "pdf_url": "http://arxiv.org/pdf/2403.08984v1",
    "published_date": "2024-03-13 22:19:06 UTC",
    "updated_date": "2024-03-13 22:19:06 UTC"
  },
  {
    "arxiv_id": "2403.08974v3",
    "title": "$TrIND$: Representing Anatomical Trees by Denoising Diffusion of Implicit Neural Fields",
    "authors": [
      "Ashish Sinha",
      "Ghassan Hamarneh"
    ],
    "abstract": "Anatomical trees play a central role in clinical diagnosis and treatment\nplanning. However, accurately representing anatomical trees is challenging due\nto their varying and complex topology and geometry. Traditional methods for\nrepresenting tree structures, captured using medical imaging, while invaluable\nfor visualizing vascular and bronchial networks, exhibit drawbacks in terms of\nlimited resolution, flexibility, and efficiency. Recently, implicit neural\nrepresentations (INRs) have emerged as a powerful tool for representing shapes\naccurately and efficiently. We propose a novel approach, $TrIND$, for\nrepresenting anatomical trees using INR, while also capturing the distribution\nof a set of trees via denoising diffusion in the space of INRs. We accurately\ncapture the intricate geometries and topologies of anatomical trees at any\ndesired resolution. Through extensive qualitative and quantitative evaluation,\nwe demonstrate high-fidelity tree reconstruction with arbitrary resolution yet\ncompact storage, and versatility across anatomical sites and tree complexities.\nThe code is available at:\n\\texttt{\\url{https://github.com/sinashish/TreeDiffusion}}.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted to MICCAI 2024",
    "pdf_url": "http://arxiv.org/pdf/2403.08974v3",
    "published_date": "2024-03-13 21:43:24 UTC",
    "updated_date": "2024-06-18 23:32:30 UTC"
  },
  {
    "arxiv_id": "2403.09743v1",
    "title": "The Human Factor in Detecting Errors of Large Language Models: A Systematic Literature Review and Future Research Directions",
    "authors": [
      "Christian A. Schiller"
    ],
    "abstract": "The launch of ChatGPT by OpenAI in November 2022 marked a pivotal moment for\nArtificial Intelligence, introducing Large Language Models (LLMs) to the\nmainstream and setting new records in user adoption. LLMs, particularly\nChatGPT, trained on extensive internet data, demonstrate remarkable\nconversational capabilities across various domains, suggesting a significant\nimpact on the workforce. However, these models are susceptible to errors -\n\"hallucinations\" and omissions, generating incorrect or incomplete information.\nThis poses risks especially in contexts where accuracy is crucial, such as\nlegal compliance, medicine or fine-grained process frameworks.\n  There are both technical and human solutions to cope with this isse. This\npaper explores the human factors that enable users to detect errors in LLM\noutputs, a critical component in mitigating risks associated with their use in\nprofessional settings. Understanding these factors is essential for\norganizations aiming to leverage LLM technology efficiently, guiding targeted\ntraining and deployment strategies to enhance error detection by users. This\napproach not only aims to optimize the use of LLMs but also to prevent\npotential downstream issues stemming from reliance on inaccurate model\nresponses. The research emphasizes the balance between technological\nadvancement and human insight in maximizing the benefits of LLMs while\nminimizing the risks, particularly in areas where precision is paramount.\n  This paper performs a systematic literature research on this research topic,\nanalyses and synthesizes the findings, and outlines future research directions.\nLiterature selection cut-off date is January 11th 2024.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "21 papers analysed and synthesized in detail from a total search\n  result size of 594 (raw results) / 61 (scanned) / 28 (selected)",
    "pdf_url": "http://arxiv.org/pdf/2403.09743v1",
    "published_date": "2024-03-13 21:39:39 UTC",
    "updated_date": "2024-03-13 21:39:39 UTC"
  },
  {
    "arxiv_id": "2403.08967v2",
    "title": "PathM3: A Multimodal Multi-Task Multiple Instance Learning Framework for Whole Slide Image Classification and Captioning",
    "authors": [
      "Qifeng Zhou",
      "Wenliang Zhong",
      "Yuzhi Guo",
      "Michael Xiao",
      "Hehuan Ma",
      "Junzhou Huang"
    ],
    "abstract": "In the field of computational histopathology, both whole slide images (WSIs)\nand diagnostic captions provide valuable insights for making diagnostic\ndecisions. However, aligning WSIs with diagnostic captions presents a\nsignificant challenge. This difficulty arises from two main factors: 1)\nGigapixel WSIs are unsuitable for direct input into deep learning models, and\nthe redundancy and correlation among the patches demand more attention; and 2)\nAuthentic WSI diagnostic captions are extremely limited, making it difficult to\ntrain an effective model. To overcome these obstacles, we present PathM3, a\nmultimodal, multi-task, multiple instance learning (MIL) framework for WSI\nclassification and captioning. PathM3 adapts a query-based transformer to\neffectively align WSIs with diagnostic captions. Given that histopathology\nvisual patterns are redundantly distributed across WSIs, we aggregate each\npatch feature with MIL method that considers the correlations among instances.\nFurthermore, our PathM3 overcomes data scarcity in WSI-level captions by\nleveraging limited WSI diagnostic caption data in the manner of multi-task\njoint learning. Extensive experiments with improved classification accuracy and\ncaption generation demonstrate the effectiveness of our method on both WSI\nclassification and captioning task.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.08967v2",
    "published_date": "2024-03-13 21:19:12 UTC",
    "updated_date": "2024-07-23 20:14:17 UTC"
  },
  {
    "arxiv_id": "2403.08962v1",
    "title": "Using Deep Learning for Morphological Classification in Pigs with a Focus on Sanitary Monitoring",
    "authors": [
      "Eduardo Bedin",
      "Junior Silva Souza",
      "Gabriel Toshio Hirokawa Higa",
      "Alexandre Pereira",
      "Charles Kiefer",
      "Newton Loebens",
      "Hemerson Pistori"
    ],
    "abstract": "The aim of this paper is to evaluate the use of D-CNN (Deep Convolutional\nNeural Networks) algorithms to classify pig body conditions in normal or not\nnormal conditions, with a focus on characteristics that are observed in\nsanitary monitoring, and were used six different algorithms to do this task.\nThe study focused on five pig characteristics, being these caudophagy, ear\nhematoma, scratches on the body, redness, and natural stains (brown or black).\nThe results of the study showed that D-CNN was effective in classifying\ndeviations in pig body morphologies related to skin characteristics. The\nevaluation was conducted by analyzing the performance metrics Precision,\nRecall, and F-score, as well as the statistical analyses ANOVA and the\nScott-Knott test. The contribution of this article is characterized by the\nproposal of using D-CNN networks for morphological classification in pigs, with\na focus on characteristics identified in sanitary monitoring. Among the best\nresults, the average Precision metric of 80.6\\% to classify caudophagy was\nachieved for the InceptionResNetV2 network, indicating the potential use of\nthis technology for the proposed task. Additionally, a new image database was\ncreated, containing various pig's distinct body characteristics, which can\nserve as data for future research.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.08962v1",
    "published_date": "2024-03-13 21:05:34 UTC",
    "updated_date": "2024-03-13 21:05:34 UTC"
  },
  {
    "arxiv_id": "2403.08956v1",
    "title": "AI coach for badminton",
    "authors": [
      "Dhruv Toshniwal",
      "Arpit Patil",
      "Nancy Vachhani"
    ],
    "abstract": "In the competitive realm of sports, optimal performance necessitates rigorous\nmanagement of nutrition and physical conditioning. Specifically, in badminton,\nthe agility and precision required make it an ideal candidate for motion\nanalysis through video analytics. This study leverages advanced neural network\nmethodologies to dissect video footage of badminton matches, aiming to extract\ndetailed insights into player kinetics and biomechanics. Through the analysis\nof stroke mechanics, including hand-hip coordination, leg positioning, and the\nexecution angles of strokes, the research aims to derive predictive models that\ncan suggest improvements in stance, technique, and muscle orientation. These\nrecommendations are designed to mitigate erroneous techniques, reduce the risk\nof joint fatigue, and enhance overall performance. Utilizing a vast array of\ndata available online, this research correlates players' physical attributes\nwith their in-game movements to identify muscle activation patterns during\nplay. The goal is to offer personalized training and nutrition strategies that\nalign with the specific biomechanical demands of badminton, thereby\nfacilitating targeted performance enhancements.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "7 pages, 11 figures. https://ieeexplore.ieee.org/document/9825164",
    "pdf_url": "http://arxiv.org/pdf/2403.08956v1",
    "published_date": "2024-03-13 20:51:21 UTC",
    "updated_date": "2024-03-13 20:51:21 UTC"
  },
  {
    "arxiv_id": "2403.08955v3",
    "title": "Towards Efficient Risk-Sensitive Policy Gradient: An Iteration Complexity Analysis",
    "authors": [
      "Rui Liu",
      "Anish Gupta",
      "Erfaun Noorani",
      "Pratap Tokekar"
    ],
    "abstract": "Reinforcement Learning (RL) has shown exceptional performance across various\napplications, enabling autonomous agents to learn optimal policies through\ninteraction with their environments. However, traditional RL frameworks often\nface challenges in terms of iteration efficiency and robustness. Risk-sensitive\npolicy gradient methods, which incorporate both expected return and risk\nmeasures, have been explored for their ability to yield more robust policies,\nyet their iteration complexity remains largely underexplored. In this work, we\nconduct a rigorous iteration complexity analysis for the risk-sensitive policy\ngradient method, focusing on the REINFORCE algorithm with an exponential\nutility function. We establish an iteration complexity of\n$\\mathcal{O}(\\epsilon^{-2})$ to reach an $\\epsilon$-approximate first-order\nstationary point (FOSP). Furthermore, we investigate whether risk-sensitive\nalgorithms can achieve better iteration complexity compared to their\nrisk-neutral counterparts. Our analysis indicates that risk-sensitive REINFORCE\ncan potentially converge faster. To validate our analysis, we empirically\nevaluate the learning performance and convergence efficiency of the\nrisk-neutral and risk-sensitive REINFORCE algorithms in multiple environments:\nCartPole, MiniGrid, and Robot Navigation. Empirical results confirm that\nrisk-averse cases can converge and stabilize faster compared to their\nrisk-neutral counterparts. More details can be found on our website\nhttps://ruiiu.github.io/riskrl.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "math.OC"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.08955v3",
    "published_date": "2024-03-13 20:50:49 UTC",
    "updated_date": "2025-04-06 03:22:06 UTC"
  },
  {
    "arxiv_id": "2403.08950v1",
    "title": "Exploring Prompt Engineering Practices in the Enterprise",
    "authors": [
      "Michael Desmond",
      "Michelle Brachman"
    ],
    "abstract": "Interaction with Large Language Models (LLMs) is primarily carried out via\nprompting. A prompt is a natural language instruction designed to elicit\ncertain behaviour or output from a model. In theory, natural language prompts\nenable non-experts to interact with and leverage LLMs. However, for complex\ntasks and tasks with specific requirements, prompt design is not trivial.\nCreating effective prompts requires skill and knowledge, as well as significant\niteration in order to determine model behavior, and guide the model to\naccomplish a particular goal. We hypothesize that the way in which users\niterate on their prompts can provide insight into how they think prompting and\nmodels work, as well as the kinds of support needed for more efficient prompt\nengineering. To better understand prompt engineering practices, we analyzed\nsessions of prompt editing behavior, categorizing the parts of prompts users\niterated on and the types of changes they made. We discuss design implications\nand future directions based on these prompt engineering practices.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.08950v1",
    "published_date": "2024-03-13 20:32:32 UTC",
    "updated_date": "2024-03-13 20:32:32 UTC"
  },
  {
    "arxiv_id": "2403.12090v1",
    "title": "Foundation Models and Information Retrieval in Digital Pathology",
    "authors": [
      "H. R. Tizhoosh"
    ],
    "abstract": "The paper reviews the state-of-the-art of foundation models, LLMs, generative\nAI, information retrieval and CBIR in digital pathology",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.CV",
      "cs.LG",
      "eess.IV"
    ],
    "primary_category": "cs.IR",
    "comment": "This is the preprint of a book chapter to appear in \"Artificial\n  Intelligence in Pathology\" by Stanley Cohen and Chhavi Chauhan",
    "pdf_url": "http://arxiv.org/pdf/2403.12090v1",
    "published_date": "2024-03-13 20:28:08 UTC",
    "updated_date": "2024-03-13 20:28:08 UTC"
  },
  {
    "arxiv_id": "2403.08944v1",
    "title": "Language-based game theory in the age of artificial intelligence",
    "authors": [
      "Valerio Capraro",
      "Roberto Di Paolo",
      "Matjaz Perc",
      "Veronica Pizziol"
    ],
    "abstract": "Understanding human behaviour in decision problems and strategic interactions\nhas wide-ranging applications in economics, psychology, and artificial\nintelligence. Game theory offers a robust foundation for this understanding,\nbased on the idea that individuals aim to maximize a utility function. However,\nthe exact factors influencing strategy choices remain elusive. While\ntraditional models try to explain human behaviour as a function of the outcomes\nof available actions, recent experimental research reveals that linguistic\ncontent significantly impacts decision-making, thus prompting a paradigm shift\nfrom outcome-based to language-based utility functions. This shift is more\nurgent than ever, given the advancement of generative AI, which has the\npotential to support humans in making critical decisions through language-based\ninteractions. We propose sentiment analysis as a fundamental tool for this\nshift and take an initial step by analyzing 61 experimental instructions from\nthe dictator game, an economic game capturing the balance between self-interest\nand the interest of others, which is at the core of many social interactions.\nOur meta-analysis shows that sentiment analysis can explain human behaviour\nbeyond economic outcomes. We discuss future research directions. We hope this\nwork sets the stage for a novel game theoretical approach that emphasizes the\nimportance of language in human decisions.",
    "categories": [
      "cs.GT",
      "cs.AI",
      "cs.CY",
      "econ.TH"
    ],
    "primary_category": "cs.GT",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.08944v1",
    "published_date": "2024-03-13 20:21:20 UTC",
    "updated_date": "2024-03-13 20:21:20 UTC"
  },
  {
    "arxiv_id": "2403.09742v1",
    "title": "A Short Review on Novel Approaches for Maximum Clique Problem: from Classical algorithms to Graph Neural Networks and Quantum algorithms",
    "authors": [
      "Raffaele Marino",
      "Lorenzo Buffoni",
      "Bogdan Zavalnij"
    ],
    "abstract": "This manuscript provides a comprehensive review of the Maximum Clique\nProblem, a computational problem that involves finding subsets of vertices in a\ngraph that are all pairwise adjacent to each other. The manuscript covers in a\nsimple way classical algorithms for solving the problem and includes a review\nof recent developments in graph neural networks and quantum algorithms. The\nreview concludes with benchmarks for testing classical as well as new learning,\nand quantum algorithms.",
    "categories": [
      "cs.AI",
      "cond-mat.dis-nn",
      "cs.DS",
      "cs.LG",
      "math.OC",
      "quant-ph"
    ],
    "primary_category": "cs.AI",
    "comment": "24 pages",
    "pdf_url": "http://arxiv.org/pdf/2403.09742v1",
    "published_date": "2024-03-13 20:12:05 UTC",
    "updated_date": "2024-03-13 20:12:05 UTC"
  },
  {
    "arxiv_id": "2403.08937v2",
    "title": "Bugs in Large Language Models Generated Code: An Empirical Study",
    "authors": [
      "Florian Tambon",
      "Arghavan Moradi Dakhel",
      "Amin Nikanjam",
      "Foutse Khomh",
      "Michel C. Desmarais",
      "Giuliano Antoniol"
    ],
    "abstract": "Large Language Models (LLMs) for code have gained significant attention\nrecently. They can generate code in different programming languages based on\nprovided prompts, fulfilling a long-lasting dream in Software Engineering (SE),\ni.e., automatic code generation. Similar to human-written code, LLM-generated\ncode is prone to bugs, and these bugs have not yet been thoroughly examined by\nthe community. Given the increasing adoption of LLM-based code generation tools\n(e.g., GitHub Copilot) in SE activities, it is critical to understand the\ncharacteristics of bugs contained in code generated by LLMs. This paper\nexamines a sample of 333 bugs collected from code generated using three leading\nLLMs (i.e., CodeGen, PanGu-Coder, and Codex) and identifies the following 10\ndistinctive bug patterns: Misinterpretations, Syntax Error, Silly Mistake,\nPrompt-biased code, Missing Corner Case, Wrong Input Type, Hallucinated Object,\nWrong Attribute, Incomplete Generation, and Non-Prompted Consideration. The bug\npatterns are presented in the form of a taxonomy. The identified bug patterns\nare validated using an online survey with 34 LLM practitioners and researchers.\nThe surveyed participants generally asserted the significance and prevalence of\nthe bug patterns. Researchers and practitioners can leverage these findings to\ndevelop effective quality assurance techniques for LLM-generated code. This\nstudy sheds light on the distinctive characteristics of LLM-generated code.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "47 pages, 7 figures",
    "pdf_url": "http://arxiv.org/pdf/2403.08937v2",
    "published_date": "2024-03-13 20:12:01 UTC",
    "updated_date": "2024-03-18 14:34:13 UTC"
  },
  {
    "arxiv_id": "2403.08936v3",
    "title": "Beyond Joint Demonstrations: Personalized Expert Guidance for Efficient Multi-Agent Reinforcement Learning",
    "authors": [
      "Peihong Yu",
      "Manav Mishra",
      "Alec Koppel",
      "Carl Busart",
      "Priya Narayan",
      "Dinesh Manocha",
      "Amrit Bedi",
      "Pratap Tokekar"
    ],
    "abstract": "Multi-Agent Reinforcement Learning (MARL) algorithms face the challenge of\nefficient exploration due to the exponential increase in the size of the joint\nstate-action space. While demonstration-guided learning has proven beneficial\nin single-agent settings, its direct applicability to MARL is hindered by the\npractical difficulty of obtaining joint expert demonstrations. In this work, we\nintroduce a novel concept of personalized expert demonstrations, tailored for\neach individual agent or, more broadly, each individual type of agent within a\nheterogeneous team. These demonstrations solely pertain to single-agent\nbehaviors and how each agent can achieve personal goals without encompassing\nany cooperative elements, thus naively imitating them will not achieve\ncooperation due to potential conflicts. To this end, we propose an approach\nthat selectively utilizes personalized expert demonstrations as guidance and\nallows agents to learn to cooperate, namely personalized expert-guided MARL\n(PegMARL). This algorithm utilizes two discriminators: the first provides\nincentives based on the alignment of individual agent behavior with\ndemonstrations, and the second regulates incentives based on whether the\nbehaviors lead to the desired outcome. We evaluate PegMARL using personalized\ndemonstrations in both discrete and continuous environments. The experimental\nresults demonstrate that PegMARL outperforms state-of-the-art MARL algorithms\nin solving coordinated tasks, achieving strong performance even when provided\nwith suboptimal personalized demonstrations. We also showcase PegMARL's\ncapability of leveraging joint demonstrations in the StarCraft scenario and\nconverging effectively even with demonstrations from non-co-trained policies.",
    "categories": [
      "cs.MA",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.MA",
    "comment": "accepted in Transactions on Machine Learning Research",
    "pdf_url": "http://arxiv.org/pdf/2403.08936v3",
    "published_date": "2024-03-13 20:11:20 UTC",
    "updated_date": "2025-01-04 03:15:45 UTC"
  },
  {
    "arxiv_id": "2403.08933v1",
    "title": "Unveiling the Truth: Exploring Human Gaze Patterns in Fake Images",
    "authors": [
      "Giuseppe Cartella",
      "Vittorio Cuculo",
      "Marcella Cornia",
      "Rita Cucchiara"
    ],
    "abstract": "Creating high-quality and realistic images is now possible thanks to the\nimpressive advancements in image generation. A description in natural language\nof your desired output is all you need to obtain breathtaking results. However,\nas the use of generative models grows, so do concerns about the propagation of\nmalicious content and misinformation. Consequently, the research community is\nactively working on the development of novel fake detection techniques,\nprimarily focusing on low-level features and possible fingerprints left by\ngenerative models during the image generation process. In a different vein, in\nour work, we leverage human semantic knowledge to investigate the possibility\nof being included in frameworks of fake image detection. To achieve this, we\ncollect a novel dataset of partially manipulated images using diffusion models\nand conduct an eye-tracking experiment to record the eye movements of different\nobservers while viewing real and fake stimuli. A preliminary statistical\nanalysis is conducted to explore the distinctive patterns in how humans\nperceive genuine and altered images. Statistical findings reveal that, when\nperceiving counterfeit samples, humans tend to focus on more confined regions\nof the image, in contrast to the more dispersed observational pattern observed\nwhen viewing genuine images. Our dataset is publicly available at:\nhttps://github.com/aimagelab/unveiling-the-truth.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted to IEEE Signal Processing Letters 2024",
    "pdf_url": "http://arxiv.org/pdf/2403.08933v1",
    "published_date": "2024-03-13 19:56:30 UTC",
    "updated_date": "2024-03-13 19:56:30 UTC"
  },
  {
    "arxiv_id": "2403.08915v1",
    "title": "Cross-Modal Learning of Housing Quality in Amsterdam",
    "authors": [
      "Alex Levering",
      "Diego Marcos",
      "Devis Tuia"
    ],
    "abstract": "In our research we test data and models for the recognition of housing\nquality in the city of Amsterdam from ground-level and aerial imagery. For\nground-level images we compare Google StreetView (GSV) to Flickr images. Our\nresults show that GSV predicts the most accurate building quality scores,\napproximately 30% better than using only aerial images. However, we find that\nthrough careful filtering and by using the right pre-trained model, Flickr\nimage features combined with aerial image features are able to halve the\nperformance gap to GSV features from 30% to 15%. Our results indicate that\nthere are viable alternatives to GSV for liveability factor prediction, which\nis encouraging as GSV images are more difficult to acquire and not always\navailable.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Presented at SIGSpatial GeoAI workshop '21",
    "pdf_url": "http://arxiv.org/pdf/2403.08915v1",
    "published_date": "2024-03-13 19:11:58 UTC",
    "updated_date": "2024-03-13 19:11:58 UTC"
  },
  {
    "arxiv_id": "2403.08910v1",
    "title": "Meta-operators for Enabling Parallel Planning Using Deep Reinforcement Learning",
    "authors": [
      "Ángel Aso-Mollar",
      "Eva Onaindia"
    ],
    "abstract": "There is a growing interest in the application of Reinforcement Learning (RL)\ntechniques to AI planning with the aim to come up with general policies.\nTypically, the mapping of the transition model of AI planning to the state\ntransition system of a Markov Decision Process is established by assuming a\none-to-one correspondence of the respective action spaces. In this paper, we\nintroduce the concept of meta-operator as the result of simultaneously applying\nmultiple planning operators, and we show that including meta-operators in the\nRL action space enables new planning perspectives to be addressed using RL,\nsuch as parallel planning. Our research aims to analyze the performance and\ncomplexity of including meta-operators in the RL process, concretely in domains\nwhere satisfactory outcomes have not been previously achieved using usual\ngeneralized planning models. The main objective of this article is thus to pave\nthe way towards a redefinition of the RL action space in a manner that is more\nclosely aligned with the planning perspective.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "9 pages. Submitted to PRL workshop at ICAPS 2023",
    "pdf_url": "http://arxiv.org/pdf/2403.08910v1",
    "published_date": "2024-03-13 19:00:36 UTC",
    "updated_date": "2024-03-13 19:00:36 UTC"
  },
  {
    "arxiv_id": "2403.10557v1",
    "title": "Second-Order Information Matters: Revisiting Machine Unlearning for Large Language Models",
    "authors": [
      "Kang Gu",
      "Md Rafi Ur Rashid",
      "Najrin Sultana",
      "Shagufta Mehnaz"
    ],
    "abstract": "With the rapid development of Large Language Models (LLMs), we have witnessed\nintense competition among the major LLM products like ChatGPT, LLaMa, and\nGemini. However, various issues (e.g. privacy leakage and copyright violation)\nof the training corpus still remain underexplored. For example, the Times sued\nOpenAI and Microsoft for infringing on its copyrights by using millions of its\narticles for training. From the perspective of LLM practitioners, handling such\nunintended privacy violations can be challenging. Previous work addressed the\n``unlearning\" problem of LLMs using gradient information, while they mostly\nintroduced significant overheads like data preprocessing or lacked robustness.\nIn this paper, contrasting with the methods based on first-order information,\nwe revisit the unlearning problem via the perspective of second-order\ninformation (Hessian). Our unlearning algorithms, which are inspired by classic\nNewton update, are not only data-agnostic/model-agnostic but also proven to be\nrobust in terms of utility preservation or privacy guarantee. Through a\ncomprehensive evaluation with four NLP datasets as well as a case study on\nreal-world datasets, our methods consistently show superiority over the\nfirst-order methods.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.10557v1",
    "published_date": "2024-03-13 18:57:30 UTC",
    "updated_date": "2024-03-13 18:57:30 UTC"
  },
  {
    "arxiv_id": "2403.09740v1",
    "title": "Teaching Machines to Code: Smart Contract Translation with LLMs",
    "authors": [
      "Rabimba Karanjai",
      "Lei Xu",
      "Weidong Shi"
    ],
    "abstract": "The advent of large language models (LLMs) has marked a significant milestone\nin the realm of artificial intelligence, with their capabilities often matching\nor surpassing human expertise in various domains. Among these achievements,\ntheir adeptness in translation tasks stands out, closely mimicking the\nintricate and preliminary processes undertaken by human translators to ensure\nthe fidelity and quality of the translated content. Despite the advancements in\nutilizing LLMs for translating programming code across different languages, the\ndomain of smart contract translation, particularly into languages not\npreviously encountered by the LLM, remains largely unexplored. In our research,\nwe present a pioneering approach, SolMover, which harnesses the synergy of two\ndistinct LLMs within a unified framework. This framework is designed to grasp\ncoding principles and apply this understanding to the translation of code into\nan unfamiliar language. Our study delves into the capacity of LLMs to mimic\nhuman learning processes, offering an in-depth evaluation of our methodology\nfor converting smart contracts written in Solidity to Move, a language with\nlimited resources. The framework employs one LLM to decipher coding conventions\nfor the new language, creating a blueprint for the second LLM, which, lacking\nplanning abilities, possesses coding expertise. The empirical evidence from our\nexperiments suggests that SolMover substantially enhances performance compared\nto gpt-3.5-turbo-1106, and achieves superior results over competitors such as\nPalm2 and Mixtral-8x7B-Instruct. Additionally, our analysis highlights the\nefficacy of our bug mitigation strategy in elevating code quality across all\nmodels, even outside the SolMover framework.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.09740v1",
    "published_date": "2024-03-13 18:55:20 UTC",
    "updated_date": "2024-03-13 18:55:20 UTC"
  },
  {
    "arxiv_id": "2403.08906v3",
    "title": "Strategizing against Q-learners: A Control-theoretical Approach",
    "authors": [
      "Yuksel Arslantas",
      "Ege Yuceel",
      "Muhammed O. Sayin"
    ],
    "abstract": "In this paper, we explore the susceptibility of the independent Q-learning\nalgorithms (a classical and widely used multi-agent reinforcement learning\nmethod) to strategic manipulation of sophisticated opponents in normal-form\ngames played repeatedly. We quantify how much strategically sophisticated\nagents can exploit naive Q-learners if they know the opponents' Q-learning\nalgorithm. To this end, we formulate the strategic actors' interactions as a\nstochastic game (whose state encompasses Q-function estimates of the\nQ-learners) as if the Q-learning algorithms are the underlying dynamical\nsystem. We also present a quantization-based approximation scheme to tackle the\ncontinuum state space and analyze its performance for two competing strategic\nactors and a single strategic actor both analytically and numerically.",
    "categories": [
      "cs.GT",
      "cs.AI",
      "math.OC"
    ],
    "primary_category": "cs.GT",
    "comment": "The extended arXiv version of the original paper to appear in IEEE\n  L-CSS",
    "pdf_url": "http://arxiv.org/pdf/2403.08906v3",
    "published_date": "2024-03-13 18:54:27 UTC",
    "updated_date": "2024-07-16 07:13:25 UTC"
  },
  {
    "arxiv_id": "2403.09738v4",
    "title": "Evaluating Large Language Models as Generative User Simulators for Conversational Recommendation",
    "authors": [
      "Se-eun Yoon",
      "Zhankui He",
      "Jessica Maria Echterhoff",
      "Julian McAuley"
    ],
    "abstract": "Synthetic users are cost-effective proxies for real users in the evaluation\nof conversational recommender systems. Large language models show promise in\nsimulating human-like behavior, raising the question of their ability to\nrepresent a diverse population of users. We introduce a new protocol to measure\nthe degree to which language models can accurately emulate human behavior in\nconversational recommendation. This protocol is comprised of five tasks, each\ndesigned to evaluate a key property that a synthetic user should exhibit:\nchoosing which items to talk about, expressing binary preferences, expressing\nopen-ended preferences, requesting recommendations, and giving feedback.\nThrough evaluation of baseline simulators, we demonstrate these tasks\neffectively reveal deviations of language models from human behavior, and offer\ninsights on how to reduce the deviations with model selection and prompting\nstrategies.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.CL",
    "comment": "NAACL 2024",
    "pdf_url": "http://arxiv.org/pdf/2403.09738v4",
    "published_date": "2024-03-13 18:16:21 UTC",
    "updated_date": "2024-03-25 23:53:01 UTC"
  },
  {
    "arxiv_id": "2403.08885v1",
    "title": "SLCF-Net: Sequential LiDAR-Camera Fusion for Semantic Scene Completion using a 3D Recurrent U-Net",
    "authors": [
      "Helin Cao",
      "Sven Behnke"
    ],
    "abstract": "We introduce SLCF-Net, a novel approach for the Semantic Scene Completion\n(SSC) task that sequentially fuses LiDAR and camera data. It jointly estimates\nmissing geometry and semantics in a scene from sequences of RGB images and\nsparse LiDAR measurements. The images are semantically segmented by a\npre-trained 2D U-Net and a dense depth prior is estimated from a\ndepth-conditioned pipeline fueled by Depth Anything. To associate the 2D image\nfeatures with the 3D scene volume, we introduce Gaussian-decay Depth-prior\nProjection (GDP). This module projects the 2D features into the 3D volume along\nthe line of sight with a Gaussian-decay function, centered around the depth\nprior. Volumetric semantics is computed by a 3D U-Net. We propagate the hidden\n3D U-Net state using the sensor motion and design a novel loss to ensure\ntemporal consistency. We evaluate our approach on the SemanticKITTI dataset and\ncompare it with leading SSC approaches. The SLCF-Net excels in all SSC metrics\nand shows great temporal consistency.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.CV",
    "comment": "2024 IEEE International Conference on Robotics and Automation\n  (ICRA2024), Yokohama, Japan, May 2024",
    "pdf_url": "http://arxiv.org/pdf/2403.08885v1",
    "published_date": "2024-03-13 18:12:53 UTC",
    "updated_date": "2024-03-13 18:12:53 UTC"
  },
  {
    "arxiv_id": "2403.08882v1",
    "title": "Cultural evolution in populations of Large Language Models",
    "authors": [
      "Jérémy Perez",
      "Corentin Léger",
      "Marcela Ovando-Tellez",
      "Chris Foulon",
      "Joan Dussauld",
      "Pierre-Yves Oudeyer",
      "Clément Moulin-Frier"
    ],
    "abstract": "Research in cultural evolution aims at providing causal explanations for the\nchange of culture over time. Over the past decades, this field has generated an\nimportant body of knowledge, using experimental, historical, and computational\nmethods. While computational models have been very successful at generating\ntestable hypotheses about the effects of several factors, such as population\nstructure or transmission biases, some phenomena have so far been more complex\nto capture using agent-based and formal models. This is in particular the case\nfor the effect of the transformations of social information induced by evolved\ncognitive mechanisms. We here propose that leveraging the capacity of Large\nLanguage Models (LLMs) to mimic human behavior may be fruitful to address this\ngap. On top of being an useful approximation of human cultural dynamics,\nmulti-agents models featuring generative agents are also important to study for\ntheir own sake. Indeed, as artificial agents are bound to participate more and\nmore to the evolution of culture, it is crucial to better understand the\ndynamics of machine-generated cultural evolution. We here present a framework\nfor simulating cultural evolution in populations of LLMs, allowing the\nmanipulation of variables known to be important in cultural evolution, such as\nnetwork structure, personality, and the way social information is aggregated\nand transformed. The software we developed for conducting these simulations is\nopen-source and features an intuitive user-interface, which we hope will help\nto build bridges between the fields of cultural evolution and generative\nartificial intelligence.",
    "categories": [
      "cs.MA",
      "cs.AI",
      "q-bio.PE",
      "68T50",
      "I.2.7"
    ],
    "primary_category": "cs.MA",
    "comment": "17 pages, 20 figures. Open-source code available at\n  https://github.com/jeremyperez2/LLM-Culture",
    "pdf_url": "http://arxiv.org/pdf/2403.08882v1",
    "published_date": "2024-03-13 18:11:17 UTC",
    "updated_date": "2024-03-13 18:11:17 UTC"
  },
  {
    "arxiv_id": "2403.14687v1",
    "title": "On the Performance of Imputation Techniques for Missing Values on Healthcare Datasets",
    "authors": [
      "Luke Oluwaseye Joel",
      "Wesley Doorsamy",
      "Babu Sena Paul"
    ],
    "abstract": "Missing values or data is one popular characteristic of real-world datasets,\nespecially healthcare data. This could be frustrating when using machine\nlearning algorithms on such datasets, simply because most machine learning\nmodels perform poorly in the presence of missing values. The aim of this study\nis to compare the performance of seven imputation techniques, namely Mean\nimputation, Median Imputation, Last Observation carried Forward (LOCF)\nimputation, K-Nearest Neighbor (KNN) imputation, Interpolation imputation,\nMissforest imputation, and Multiple imputation by Chained Equations (MICE), on\nthree healthcare datasets. Some percentage of missing values - 10\\%, 15\\%, 20\\%\nand 25\\% - were introduced into the dataset, and the imputation techniques were\nemployed to impute these missing values. The comparison of their performance\nwas evaluated by using root mean squared error (RMSE) and mean absolute error\n(MAE). The results show that Missforest imputation performs the best followed\nby MICE imputation. Additionally, we try to determine whether it is better to\nperform feature selection before imputation or vice versa by using the\nfollowing metrics - the recall, precision, f1-score and accuracy. Due to the\nfact that there are few literature on this and some debate on the subject among\nresearchers, we hope that the results from this experiment will encourage data\nscientists and researchers to perform imputation first before feature selection\nwhen dealing with data containing missing values.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.14687v1",
    "published_date": "2024-03-13 18:07:17 UTC",
    "updated_date": "2024-03-13 18:07:17 UTC"
  },
  {
    "arxiv_id": "2403.08879v1",
    "title": "Multi-Objective Optimization Using Adaptive Distributed Reinforcement Learning",
    "authors": [
      "Jing Tan",
      "Ramin Khalili",
      "Holger Karl"
    ],
    "abstract": "The Intelligent Transportation System (ITS) environment is known to be\ndynamic and distributed, where participants (vehicle users, operators, etc.)\nhave multiple, changing and possibly conflicting objectives. Although\nReinforcement Learning (RL) algorithms are commonly applied to optimize ITS\napplications such as resource management and offloading, most RL algorithms\nfocus on single objectives. In many situations, converting a multi-objective\nproblem into a single-objective one is impossible, intractable or insufficient,\nmaking such RL algorithms inapplicable. We propose a multi-objective,\nmulti-agent reinforcement learning (MARL) algorithm with high learning\nefficiency and low computational requirements, which automatically triggers\nadaptive few-shot learning in a dynamic, distributed and noisy environment with\nsparse and delayed reward. We test our algorithm in an ITS environment with\nedge cloud computing. Empirical results show that the algorithm is quick to\nadapt to new environments and performs better in all individual and system\nmetrics compared to the state-of-the-art benchmark. Our algorithm also\naddresses various practical concerns with its modularized and asynchronous\nonline training method. In addition to the cloud simulation, we test our\nalgorithm on a single-board computer and show that it can make inference in 6\nmilliseconds.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.MA",
      "math.OC"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.08879v1",
    "published_date": "2024-03-13 18:05:16 UTC",
    "updated_date": "2024-03-13 18:05:16 UTC"
  },
  {
    "arxiv_id": "2403.08770v1",
    "title": "FastMAC: Stochastic Spectral Sampling of Correspondence Graph",
    "authors": [
      "Yifei Zhang",
      "Hao Zhao",
      "Hongyang Li",
      "Siheng Chen"
    ],
    "abstract": "3D correspondence, i.e., a pair of 3D points, is a fundamental concept in\ncomputer vision. A set of 3D correspondences, when equipped with compatibility\nedges, forms a correspondence graph. This graph is a critical component in\nseveral state-of-the-art 3D point cloud registration approaches, e.g., the one\nbased on maximal cliques (MAC). However, its properties have not been well\nunderstood. So we present the first study that introduces graph signal\nprocessing into the domain of correspondence graph. We exploit the generalized\ndegree signal on correspondence graph and pursue sampling strategies that\npreserve high-frequency components of this signal. To address time-consuming\nsingular value decomposition in deterministic sampling, we resort to a\nstochastic approximate sampling strategy. As such, the core of our method is\nthe stochastic spectral sampling of correspondence graph. As an application, we\nbuild a complete 3D registration algorithm termed as FastMAC, that reaches\nreal-time speed while leading to little to none performance drop. Through\nextensive experiments, we validate that FastMAC works for both indoor and\noutdoor benchmarks. For example, FastMAC can accelerate MAC by 80 times while\nmaintaining high registration success rate on KITTI. Codes are publicly\navailable at https://github.com/Forrest-110/FastMAC.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.CV",
    "comment": "CVPR 2024, Code: https://github.com/Forrest-110/FastMAC",
    "pdf_url": "http://arxiv.org/pdf/2403.08770v1",
    "published_date": "2024-03-13 17:59:56 UTC",
    "updated_date": "2024-03-13 17:59:56 UTC"
  },
  {
    "arxiv_id": "2403.08763v4",
    "title": "Simple and Scalable Strategies to Continually Pre-train Large Language Models",
    "authors": [
      "Adam Ibrahim",
      "Benjamin Thérien",
      "Kshitij Gupta",
      "Mats L. Richter",
      "Quentin Anthony",
      "Timothée Lesort",
      "Eugene Belilovsky",
      "Irina Rish"
    ],
    "abstract": "Large language models (LLMs) are routinely pre-trained on billions of tokens,\nonly to start the process over again once new data becomes available. A much\nmore efficient solution is to continually pre-train these models, saving\nsignificant compute compared to re-training. However, the distribution shift\ninduced by new data typically results in degraded performance on previous data\nor poor adaptation to the new data. In this work, we show that a simple and\nscalable combination of learning rate (LR) re-warming, LR re-decaying, and\nreplay of previous data is sufficient to match the performance of fully\nre-training from scratch on all available data, as measured by the final loss\nand the average score on several language model (LM) evaluation benchmarks.\nSpecifically, we show this for a weak but realistic distribution shift between\ntwo commonly used LLM pre-training datasets (English$\\rightarrow$English) and a\nstronger distribution shift (English$\\rightarrow$German) at the $405$M\nparameter model scale with large dataset sizes (hundreds of billions of\ntokens). Selecting the weak but realistic shift for larger-scale experiments,\nwe also find that our continual learning strategies match the re-training\nbaseline for a 10B parameter LLM. Our results demonstrate that LLMs can be\nsuccessfully updated via simple and scalable continual learning strategies,\nmatching the re-training baseline using only a fraction of the compute.\nFinally, inspired by previous work, we propose alternatives to the cosine\nlearning rate schedule that help circumvent forgetting induced by LR re-warming\nand that are not bound to a fixed token budget.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.08763v4",
    "published_date": "2024-03-13 17:58:57 UTC",
    "updated_date": "2024-09-04 16:13:18 UTC"
  },
  {
    "arxiv_id": "2403.08755v2",
    "title": "DAM: Dynamic Adapter Merging for Continual Video QA Learning",
    "authors": [
      "Feng Cheng",
      "Ziyang Wang",
      "Yi-Lin Sung",
      "Yan-Bo Lin",
      "Mohit Bansal",
      "Gedas Bertasius"
    ],
    "abstract": "We present a parameter-efficient method for continual video\nquestion-answering (VidQA) learning. Our method, named DAM, uses the proposed\nDynamic Adapter Merging to (i) mitigate catastrophic forgetting, (ii) enable\nefficient adaptation to continually arriving datasets, (iii) handle inputs from\nunknown datasets during inference, and (iv) enable knowledge sharing across\nsimilar dataset domains. Given a set of continually streaming VidQA datasets,\nwe sequentially train dataset-specific adapters for each dataset while freezing\nthe parameters of a large pretrained video-language backbone. During inference,\ngiven a video-question sample from an unknown domain, our method first uses the\nproposed non-parametric router function to compute a probability for each\nadapter, reflecting how relevant that adapter is to the current video-question\ninput instance. Subsequently, the proposed dynamic adapter merging scheme\naggregates all the adapter weights into a new adapter instance tailored for\nthat particular test sample to compute the final VidQA prediction, mitigating\nthe impact of inaccurate router predictions and facilitating knowledge sharing\nacross domains. Our DAM model outperforms prior state-of-the-art continual\nlearning approaches by 9.1% while exhibiting 1.9% less forgetting on 6 VidQA\ndatasets spanning various domains. We further extend DAM to continual image\nclassification and image QA and outperform prior methods by a large margin. The\ncode is publicly available at: https://github.com/klauscc/DAM",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "The first two authors contribute equally",
    "pdf_url": "http://arxiv.org/pdf/2403.08755v2",
    "published_date": "2024-03-13 17:53:47 UTC",
    "updated_date": "2024-04-22 19:17:49 UTC"
  },
  {
    "arxiv_id": "2404.10179v3",
    "title": "Scaling Instructable Agents Across Many Simulated Worlds",
    "authors": [
      "SIMA Team",
      "Maria Abi Raad",
      "Arun Ahuja",
      "Catarina Barros",
      "Frederic Besse",
      "Andrew Bolt",
      "Adrian Bolton",
      "Bethanie Brownfield",
      "Gavin Buttimore",
      "Max Cant",
      "Sarah Chakera",
      "Stephanie C. Y. Chan",
      "Jeff Clune",
      "Adrian Collister",
      "Vikki Copeman",
      "Alex Cullum",
      "Ishita Dasgupta",
      "Dario de Cesare",
      "Julia Di Trapani",
      "Yani Donchev",
      "Emma Dunleavy",
      "Martin Engelcke",
      "Ryan Faulkner",
      "Frankie Garcia",
      "Charles Gbadamosi",
      "Zhitao Gong",
      "Lucy Gonzales",
      "Kshitij Gupta",
      "Karol Gregor",
      "Arne Olav Hallingstad",
      "Tim Harley",
      "Sam Haves",
      "Felix Hill",
      "Ed Hirst",
      "Drew A. Hudson",
      "Jony Hudson",
      "Steph Hughes-Fitt",
      "Danilo J. Rezende",
      "Mimi Jasarevic",
      "Laura Kampis",
      "Rosemary Ke",
      "Thomas Keck",
      "Junkyung Kim",
      "Oscar Knagg",
      "Kavya Kopparapu",
      "Rory Lawton",
      "Andrew Lampinen",
      "Shane Legg",
      "Alexander Lerchner",
      "Marjorie Limont",
      "Yulan Liu",
      "Maria Loks-Thompson",
      "Joseph Marino",
      "Kathryn Martin Cussons",
      "Loic Matthey",
      "Siobhan Mcloughlin",
      "Piermaria Mendolicchio",
      "Hamza Merzic",
      "Anna Mitenkova",
      "Alexandre Moufarek",
      "Valeria Oliveira",
      "Yanko Oliveira",
      "Hannah Openshaw",
      "Renke Pan",
      "Aneesh Pappu",
      "Alex Platonov",
      "Ollie Purkiss",
      "David Reichert",
      "John Reid",
      "Pierre Harvey Richemond",
      "Tyson Roberts",
      "Giles Ruscoe",
      "Jaume Sanchez Elias",
      "Tasha Sandars",
      "Daniel P. Sawyer",
      "Tim Scholtes",
      "Guy Simmons",
      "Daniel Slater",
      "Hubert Soyer",
      "Heiko Strathmann",
      "Peter Stys",
      "Allison C. Tam",
      "Denis Teplyashin",
      "Tayfun Terzi",
      "Davide Vercelli",
      "Bojan Vujatovic",
      "Marcus Wainwright",
      "Jane X. Wang",
      "Zhengdong Wang",
      "Daan Wierstra",
      "Duncan Williams",
      "Nathaniel Wong",
      "Sarah York",
      "Nick Young"
    ],
    "abstract": "Building embodied AI systems that can follow arbitrary language instructions\nin any 3D environment is a key challenge for creating general AI. Accomplishing\nthis goal requires learning to ground language in perception and embodied\nactions, in order to accomplish complex tasks. The Scalable, Instructable,\nMultiworld Agent (SIMA) project tackles this by training agents to follow\nfree-form instructions across a diverse range of virtual 3D environments,\nincluding curated research environments as well as open-ended, commercial video\ngames. Our goal is to develop an instructable agent that can accomplish\nanything a human can do in any simulated 3D environment. Our approach focuses\non language-driven generality while imposing minimal assumptions. Our agents\ninteract with environments in real-time using a generic, human-like interface:\nthe inputs are image observations and language instructions and the outputs are\nkeyboard-and-mouse actions. This general approach is challenging, but it allows\nagents to ground language across many visually complex and semantically rich\nenvironments while also allowing us to readily run agents in new environments.\nIn this paper we describe our motivation and goal, the initial progress we have\nmade, and promising preliminary results on several diverse research\nenvironments and a variety of commercial video games.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.HC",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.10179v3",
    "published_date": "2024-03-13 17:50:32 UTC",
    "updated_date": "2024-10-11 16:30:24 UTC"
  },
  {
    "arxiv_id": "2405.15771v2",
    "title": "Adaptive Splitting of Reusable Temporal Monitors for Rare Traffic Violations",
    "authors": [
      "Craig Innes",
      "Subramanian Ramamoorthy"
    ],
    "abstract": "Autonomous Vehicles (AVs) are often tested in simulation to estimate the\nprobability they will violate safety specifications. Two common issues arise\nwhen using existing techniques to produce this estimation: If violations occur\nrarely, simple Monte-Carlo sampling techniques can fail to produce efficient\nestimates; if simulation horizons are too long, importance sampling techniques\n(which learn proposal distributions from past simulations) can fail to\nconverge. This paper addresses both issues by interleaving rare-event sampling\ntechniques with online specification monitoring algorithms. We use adaptive\nmulti-level splitting to decompose simulations into partial trajectories, then\ncalculate the distance of those partial trajectories to failure by leveraging\nrobustness metrics from Signal Temporal Logic (STL). By caching those partial\nrobustness metric values, we can efficiently re-use computations across\nmultiple sampling stages. Our experiments on an interstate lane-change scenario\nshow our method is viable for testing simulated AV-pipelines, efficiently\nestimating failure probabilities for STL specifications based on real traffic\nrules. We produce better estimates than Monte-Carlo and importance sampling in\nfewer simulations.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.15771v2",
    "published_date": "2024-03-13 17:47:39 UTC",
    "updated_date": "2024-07-24 12:56:41 UTC"
  },
  {
    "arxiv_id": "2403.08743v2",
    "title": "Prompting Fairness: Integrating Causality to Debias Large Language Models",
    "authors": [
      "Jingling Li",
      "Zeyu Tang",
      "Xiaoyu Liu",
      "Peter Spirtes",
      "Kun Zhang",
      "Liu Leqi",
      "Yang Liu"
    ],
    "abstract": "Large language models (LLMs), despite their remarkable capabilities, are\nsusceptible to generating biased and discriminatory responses. As LLMs\nincreasingly influence high-stakes decision-making (e.g., hiring and\nhealthcare), mitigating these biases becomes critical. In this work, we propose\na causality-guided debiasing framework to tackle social biases, aiming to\nreduce the objectionable dependence between LLMs' decisions and the social\ninformation in the input. Our framework introduces a novel perspective to\nidentify how social information can affect an LLM's decision through different\ncausal pathways. Leveraging these causal insights, we outline principled\nprompting strategies that regulate these pathways through selection mechanisms.\nThis framework not only unifies existing prompting-based debiasing techniques,\nbut also opens up new directions for reducing bias by encouraging the model to\nprioritize fact-based reasoning over reliance on biased social cues. We\nvalidate our framework through extensive experiments on real-world datasets\nacross multiple domains, demonstrating its effectiveness in debiasing LLM\ndecisions, even with only black-box access to the model.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "24 pages, 10 figures",
    "pdf_url": "http://arxiv.org/pdf/2403.08743v2",
    "published_date": "2024-03-13 17:46:28 UTC",
    "updated_date": "2025-03-02 17:33:03 UTC"
  },
  {
    "arxiv_id": "2403.08739v1",
    "title": "The Garden of Forking Paths: Observing Dynamic Parameters Distribution in Large Language Models",
    "authors": [
      "Carlo Nicolini",
      "Jacopo Staiano",
      "Bruno Lepri",
      "Raffaele Marino"
    ],
    "abstract": "A substantial gap persists in understanding the reasons behind the\nexceptional performance of the Transformer architecture in NLP. A particularly\nunexplored area involves the mechanistic description of how the distribution of\nparameters evolves over time during training. In this work we suggest that\nlooking at the time evolution of the statistic distribution of model\nparameters, and specifically at bifurcation effects, can help understanding the\nmodel quality, potentially reducing training costs and evaluation efforts and\nempirically showing the reasons behind the effectiveness of weights\nsparsification.",
    "categories": [
      "cs.CL",
      "cond-mat.dis-nn",
      "cond-mat.stat-mech",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "15 pages",
    "pdf_url": "http://arxiv.org/pdf/2403.08739v1",
    "published_date": "2024-03-13 17:42:32 UTC",
    "updated_date": "2024-03-13 17:42:32 UTC"
  },
  {
    "arxiv_id": "2403.08728v2",
    "title": "Ambient Diffusion Posterior Sampling: Solving Inverse Problems with Diffusion Models Trained on Corrupted Data",
    "authors": [
      "Asad Aali",
      "Giannis Daras",
      "Brett Levac",
      "Sidharth Kumar",
      "Alexandros G. Dimakis",
      "Jonathan I. Tamir"
    ],
    "abstract": "We provide a framework for solving inverse problems with diffusion models\nlearned from linearly corrupted data. Firstly, we extend the Ambient Diffusion\nframework to enable training directly from measurements corrupted in the\nFourier domain. Subsequently, we train diffusion models for MRI with access\nonly to Fourier subsampled multi-coil measurements at acceleration factors R=\n2,4,6,8. Secondly, we propose Ambient Diffusion Posterior Sampling (A-DPS), a\nreconstruction algorithm that leverages generative models pre-trained on one\ntype of corruption (e.g. image inpainting) to perform posterior sampling on\nmeasurements from a different forward process (e.g. image blurring). For MRI\nreconstruction in high acceleration regimes, we observe that A-DPS models\ntrained on subsampled data are better suited to solving inverse problems than\nmodels trained on fully sampled data. We also test the efficacy of A-DPS on\nnatural image datasets (CelebA, FFHQ, and AFHQ) and show that A-DPS can\nsometimes outperform models trained on clean data for several image restoration\ntasks in both speed and performance.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.08728v2",
    "published_date": "2024-03-13 17:28:20 UTC",
    "updated_date": "2025-04-21 23:33:05 UTC"
  },
  {
    "arxiv_id": "2403.08699v1",
    "title": "Implicit Regularization of Gradient Flow on One-Layer Softmax Attention",
    "authors": [
      "Heejune Sheen",
      "Siyu Chen",
      "Tianhao Wang",
      "Harrison H. Zhou"
    ],
    "abstract": "We study gradient flow on the exponential loss for a classification problem\nwith a one-layer softmax attention model, where the key and query weight\nmatrices are trained separately. Under a separability assumption on the data,\nwe show that when gradient flow achieves the minimal loss value, it further\nimplicitly minimizes the nuclear norm of the product of the key and query\nweight matrices. Such implicit regularization can be described by a Support\nVector Machine (SVM) problem with respect to the attention weights. This\nfinding contrasts with prior results showing that the gradient descent induces\nan implicit regularization on the Frobenius norm on the product weight matrix\nwhen the key and query matrices are combined into a single weight matrix for\ntraining. For diagonal key and query matrices, our analysis builds upon the\nreparameterization technique and exploits approximate KKT conditions of the SVM\nassociated with the classification data. Moreover, the results are extended to\ngeneral weights configurations given proper alignment of the weight matrices'\nsingular spaces with the data features at initialization.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "math.OC",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "34 pages",
    "pdf_url": "http://arxiv.org/pdf/2403.08699v1",
    "published_date": "2024-03-13 17:02:27 UTC",
    "updated_date": "2024-03-13 17:02:27 UTC"
  },
  {
    "arxiv_id": "2403.08688v1",
    "title": "Token Alignment via Character Matching for Subword Completion",
    "authors": [
      "Ben Athiwaratkun",
      "Shiqi Wang",
      "Mingyue Shang",
      "Yuchen Tian",
      "Zijian Wang",
      "Sujan Kumar Gonugondla",
      "Sanjay Krishna Gouda",
      "Rob Kwiatowski",
      "Ramesh Nallapati",
      "Bing Xiang"
    ],
    "abstract": "Generative models, widely utilized in various applications, can often\nstruggle with prompts corresponding to partial tokens. This struggle stems from\ntokenization, where partial tokens fall out of distribution during inference,\nleading to incorrect or nonsensical outputs. This paper examines a technique to\nalleviate the tokenization artifact on text completion in generative models,\nmaintaining performance even in regular non-subword cases. The method, termed\ntoken alignment, involves backtracking to the last complete tokens and ensuring\nthe model's generation aligns with the prompt. This approach showcases marked\nimprovement across many partial token scenarios, including nuanced cases like\nspace-prefix and partial indentation, with only a minor time increase. The\ntechnique and analysis detailed in this paper contribute to the continuous\nadvancement of generative models in handling partial inputs, bearing relevance\nfor applications like code completion and text autocompletion.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.08688v1",
    "published_date": "2024-03-13 16:44:39 UTC",
    "updated_date": "2024-03-13 16:44:39 UTC"
  },
  {
    "arxiv_id": "2403.08845v2",
    "title": "Bifurcated Attention: Accelerating Massively Parallel Decoding with Shared Prefixes in LLMs",
    "authors": [
      "Ben Athiwaratkun",
      "Sujan Kumar Gonugondla",
      "Sanjay Krishna Gouda",
      "Haifeng Qian",
      "Hantian Ding",
      "Qing Sun",
      "Jun Wang",
      "Jiacheng Guo",
      "Liangfu Chen",
      "Parminder Bhatia",
      "Ramesh Nallapati",
      "Sudipta Sengupta",
      "Bing Xiang"
    ],
    "abstract": "This study introduces bifurcated attention, a method designed to enhance\nlanguage model inference in shared-context batch decoding scenarios. Our\napproach addresses the challenge of redundant memory IO costs, a critical\nfactor contributing to latency in high batch sizes and extended context\nlengths. Bifurcated attention achieves this by strategically dividing the\nattention mechanism during incremental decoding into two separate GEMM\noperations: one focusing on the KV cache from prefill, and another on the\ndecoding process itself. While maintaining the computational load (FLOPs) of\nstandard attention mechanisms, bifurcated attention ensures precise computation\nwith significantly reduced memory IO. Our empirical results show over\n2.1$\\times$ speedup when sampling 16 output sequences and more than 6.2$\\times$\nspeedup when sampling 32 sequences at context lengths exceeding 8k tokens on a\n7B model that uses multi-head attention. The efficiency gains from bifurcated\nattention translate into lower latency, making it particularly suitable for\nreal-time applications. For instance, it enables massively parallel answer\ngeneration without substantially increasing latency, thus enhancing performance\nwhen integrated with post-processing techniques such as re-ranking.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.08845v2",
    "published_date": "2024-03-13 16:30:57 UTC",
    "updated_date": "2024-07-11 20:07:30 UTC"
  },
  {
    "arxiv_id": "2403.08844v1",
    "title": "AcademiaOS: Automating Grounded Theory Development in Qualitative Research with Large Language Models",
    "authors": [
      "Thomas Übellacker"
    ],
    "abstract": "AcademiaOS is a first attempt to automate grounded theory development in\nqualitative research with large language models. Using recent large language\nmodels' language understanding, generation, and reasoning capabilities,\nAcademiaOS codes curated qualitative raw data such as interview transcripts and\ndevelops themes and dimensions to further develop a grounded theoretical model,\naffording novel insights. A user study (n=19) suggests that the system finds\nacceptance in the academic community and exhibits the potential to augment\nhumans in qualitative research. AcademiaOS has been made open-source for others\nto build upon and adapt to their use cases.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.HC",
    "comment": "Live version: https://academia-os.org Source code:\n  https://github.com/thomasuebi/academia-os",
    "pdf_url": "http://arxiv.org/pdf/2403.08844v1",
    "published_date": "2024-03-13 15:54:49 UTC",
    "updated_date": "2024-03-13 15:54:49 UTC"
  },
  {
    "arxiv_id": "2403.08635v1",
    "title": "Human Alignment of Large Language Models through Online Preference Optimisation",
    "authors": [
      "Daniele Calandriello",
      "Daniel Guo",
      "Remi Munos",
      "Mark Rowland",
      "Yunhao Tang",
      "Bernardo Avila Pires",
      "Pierre Harvey Richemond",
      "Charline Le Lan",
      "Michal Valko",
      "Tianqi Liu",
      "Rishabh Joshi",
      "Zeyu Zheng",
      "Bilal Piot"
    ],
    "abstract": "Ensuring alignment of language models' outputs with human preferences is\ncritical to guarantee a useful, safe, and pleasant user experience. Thus, human\nalignment has been extensively studied recently and several methods such as\nReinforcement Learning from Human Feedback (RLHF), Direct Policy Optimisation\n(DPO) and Sequence Likelihood Calibration (SLiC) have emerged. In this paper,\nour contribution is two-fold. First, we show the equivalence between two recent\nalignment methods, namely Identity Policy Optimisation (IPO) and Nash Mirror\nDescent (Nash-MD). Second, we introduce a generalisation of IPO, named IPO-MD,\nthat leverages the regularised sampling approach proposed by Nash-MD.\n  This equivalence may seem surprising at first sight, since IPO is an offline\nmethod whereas Nash-MD is an online method using a preference model. However,\nthis equivalence can be proven when we consider the online version of IPO, that\nis when both generations are sampled by the online policy and annotated by a\ntrained preference model. Optimising the IPO loss with such a stream of data\nbecomes then equivalent to finding the Nash equilibrium of the preference model\nthrough self-play. Building on this equivalence, we introduce the IPO-MD\nalgorithm that generates data with a mixture policy (between the online and\nreference policy) similarly as the general Nash-MD algorithm. We compare\nonline-IPO and IPO-MD to different online versions of existing losses on\npreference data such as DPO and SLiC on a summarisation task.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.08635v1",
    "published_date": "2024-03-13 15:47:26 UTC",
    "updated_date": "2024-03-13 15:47:26 UTC"
  },
  {
    "arxiv_id": "2403.08618v2",
    "title": "SAP: Corrective Machine Unlearning with Scaled Activation Projection for Label Noise Robustness",
    "authors": [
      "Sangamesh Kodge",
      "Deepak Ravikumar",
      "Gobinda Saha",
      "Kaushik Roy"
    ],
    "abstract": "Label corruption, where training samples are mislabeled due to non-expert\nannotation or adversarial attacks, significantly degrades model performance.\nAcquiring large, perfectly labeled datasets is costly, and retraining models\nfrom scratch is computationally expensive. To address this, we introduce Scaled\nActivation Projection (SAP), a novel SVD (Singular Value Decomposition)-based\ncorrective machine unlearning algorithm. SAP mitigates label noise by\nidentifying a small subset of trusted samples using cross-entropy loss and\nprojecting model weights onto a clean activation space estimated using SVD on\nthese trusted samples. This process suppresses the noise introduced in\nactivations due to the mislabeled samples. In our experiments, we demonstrate\nSAP's effectiveness on synthetic noise with different settings and real-world\nlabel noise. SAP applied to the CIFAR dataset with 25% synthetic corruption\nshow upto 6% generalization improvements. Additionally, SAP can improve the\ngeneralization over noise robust training approaches on CIFAR dataset by ~3.2%\non average. Further, we observe generalization improvements of 2.31% for a\nVision Transformer model trained on naturally corrupted Clothing1M.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.08618v2",
    "published_date": "2024-03-13 15:32:08 UTC",
    "updated_date": "2025-01-02 15:08:12 UTC"
  },
  {
    "arxiv_id": "2403.08613v1",
    "title": "Link Prediction for Social Networks using Representation Learning and Heuristic-based Features",
    "authors": [
      "Samarth Khanna",
      "Sree Bhattacharyya",
      "Sudipto Ghosh",
      "Kushagra Agarwal",
      "Asit Kumar Das"
    ],
    "abstract": "The exponential growth in scale and relevance of social networks enable them\nto provide expansive insights. Predicting missing links in social networks\nefficiently can help in various modern-day business applications ranging from\ngenerating recommendations to influence analysis. Several categories of\nsolutions exist for the same. Here, we explore various feature extraction\ntechniques to generate representations of nodes and edges in a social network\nthat allow us to predict missing links. We compare the results of using ten\nfeature extraction techniques categorized across Structural embeddings,\nNeighborhood-based embeddings, Graph Neural Networks, and Graph Heuristics,\nfollowed by modeling with ensemble classifiers and custom Neural Networks.\nFurther, we propose combining heuristic-based features and learned\nrepresentations that demonstrate improved performance for the link prediction\ntask on social network datasets. Using this method to generate accurate\nrecommendations for many applications is a matter of further study that appears\nvery promising. The code for all the experiments has been made public.",
    "categories": [
      "cs.SI",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.SI",
    "comment": "Accepted to the MAISoN Workshop at IJCAI 2023",
    "pdf_url": "http://arxiv.org/pdf/2403.08613v1",
    "published_date": "2024-03-13 15:23:55 UTC",
    "updated_date": "2024-03-13 15:23:55 UTC"
  },
  {
    "arxiv_id": "2403.08607v1",
    "title": "MedInsight: A Multi-Source Context Augmentation Framework for Generating Patient-Centric Medical Responses using Large Language Models",
    "authors": [
      "Subash Neupane",
      "Shaswata Mitra",
      "Sudip Mittal",
      "Noorbakhsh Amiri Golilarz",
      "Shahram Rahimi",
      "Amin Amirlatifi"
    ],
    "abstract": "Large Language Models (LLMs) have shown impressive capabilities in generating\nhuman-like responses. However, their lack of domain-specific knowledge limits\ntheir applicability in healthcare settings, where contextual and comprehensive\nresponses are vital. To address this challenge and enable the generation of\npatient-centric responses that are contextually relevant and comprehensive, we\npropose MedInsight:a novel retrieval augmented framework that augments LLM\ninputs (prompts) with relevant background information from multiple sources.\nMedInsight extracts pertinent details from the patient's medical record or\nconsultation transcript. It then integrates information from authoritative\nmedical textbooks and curated web resources based on the patient's health\nhistory and condition. By constructing an augmented context combining the\npatient's record with relevant medical knowledge, MedInsight generates\nenriched, patient-specific responses tailored for healthcare applications such\nas diagnosis, treatment recommendations, or patient education. Experiments on\nthe MTSamples dataset validate MedInsight's effectiveness in generating\ncontextually appropriate medical responses. Quantitative evaluation using the\nRagas metric and TruLens for answer similarity and answer correctness\ndemonstrates the model's efficacy. Furthermore, human evaluation studies\ninvolving Subject Matter Expert (SMEs) confirm MedInsight's utility, with\nmoderate inter-rater agreement on the relevance and correctness of the\ngenerated responses.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.08607v1",
    "published_date": "2024-03-13 15:20:30 UTC",
    "updated_date": "2024-03-13 15:20:30 UTC"
  },
  {
    "arxiv_id": "2403.08593v2",
    "title": "Call Me When Necessary: LLMs can Efficiently and Faithfully Reason over Structured Environments",
    "authors": [
      "Sitao Cheng",
      "Ziyuan Zhuang",
      "Yong Xu",
      "Fangkai Yang",
      "Chaoyun Zhang",
      "Xiaoting Qin",
      "Xiang Huang",
      "Ling Chen",
      "Qingwei Lin",
      "Dongmei Zhang",
      "Saravan Rajmohan",
      "Qi Zhang"
    ],
    "abstract": "Large Language Models (LLMs) have shown potential in reasoning over\nstructured environments, e.g., knowledge graph and table. Such tasks typically\nrequire multi-hop reasoning, i.e., match natural language utterance with\ninstances in the environment. Previous methods leverage LLMs to incrementally\nbuild a reasoning path, where the LLMs either invoke tools or pick up schemas\nby step-by-step interacting with the environment. We propose\nReasoning-Path-Editing (Readi), a novel framework where LLMs can efficiently\nand faithfully reason over structured environments. In Readi, LLMs initially\ngenerate a reasoning path given a query, and edit the path only when necessary.\nWe instantiate the path on structured environments and provide feedback to edit\nthe path if anything goes wrong. Experimental results on three KGQA and two\nTableQA datasets show the effectiveness of Readi, significantly surpassing\nprevious LLM-based methods (by 9.1% Hit@1 on WebQSP, 12.4% on MQA-3H and 9.5%\non WTQ), comparable with state-of-the-art fine-tuned methods (67% on CWQ and\n74.7% on WebQSP) and substantially boosting the vanilla LLMs (by 14.9% on CWQ).\nOur code will be available on https://aka.ms/readi.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted by ACL 2024 Findings. 21 pages, 7 figures, 17 tables",
    "pdf_url": "http://arxiv.org/pdf/2403.08593v2",
    "published_date": "2024-03-13 14:59:07 UTC",
    "updated_date": "2024-07-03 15:23:59 UTC"
  },
  {
    "arxiv_id": "2403.08843v1",
    "title": "Fuzzy Fault Trees Formalized",
    "authors": [
      "Thi Kim Nhung Dang",
      "Milan Lopuhaä-Zwakenberg",
      "Mariëlle Stoelinga"
    ],
    "abstract": "Fault tree analysis is a vital method of assessing safety risks. It helps to\nidentify potential causes of accidents, assess their likelihood and severity,\nand suggest preventive measures. Quantitative analysis of fault trees is often\ndone via the dependability metrics that compute the system's failure behaviour\nover time. However, the lack of precise data is a major obstacle to\nquantitative analysis, and so to reliability analysis. Fuzzy logic is a popular\nframework for dealing with ambiguous values and has applications in many\ndomains. A number of fuzzy approaches have been proposed to fault tree\nanalysis, but -- to the best of our knowledge -- none of them provide rigorous\ndefinitions or algorithms for computing fuzzy unreliability values. In this\npaper, we define a rigorous framework for fuzzy unreliability values. In\naddition, we provide a bottom-up algorithm to efficiently calculate fuzzy\nreliability for a system. The algorithm incorporates the concept of\n$\\alpha$-cuts method. That is, performing binary algebraic operations on\nintervals on horizontally discretised $\\alpha$-cut representations of fuzzy\nnumbers. The method preserves the nonlinearity of fuzzy unreliability. Finally,\nwe illustrate the results obtained from two case studies.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "14 pages",
    "pdf_url": "http://arxiv.org/pdf/2403.08843v1",
    "published_date": "2024-03-13 14:45:54 UTC",
    "updated_date": "2024-03-13 14:45:54 UTC"
  },
  {
    "arxiv_id": "2403.09735v1",
    "title": "A Sophisticated Framework for the Accurate Detection of Phishing Websites",
    "authors": [
      "Asif Newaz",
      "Farhan Shahriyar Haq",
      "Nadim Ahmed"
    ],
    "abstract": "Phishing is an increasingly sophisticated form of cyberattack that is\ninflicting huge financial damage to corporations throughout the globe while\nalso jeopardizing individuals' privacy. Attackers are constantly devising new\nmethods of launching such assaults and detecting them has become a daunting\ntask. Many different techniques have been suggested, each with its own pros and\ncons. While machine learning-based techniques have been most successful in\nidentifying such attacks, they continue to fall short in terms of performance\nand generalizability. This paper proposes a comprehensive methodology for\ndetecting phishing websites. The goal is to design a system that is capable of\naccurately distinguishing phishing websites from legitimate ones and provides\ngeneralized performance over a broad variety of datasets. A combination of\nfeature selection, greedy algorithm, cross-validation, and deep learning\nmethods have been utilized to construct a sophisticated stacking ensemble\nclassifier. Extensive experimentation on four different phishing datasets was\nconducted to evaluate the performance of the proposed technique. The proposed\nalgorithm outperformed the other existing phishing detection models obtaining\naccuracy of 97.49%, 98.23%, 97.48%, and 98.20% on dataset-1 (UCI Phishing\nWebsites Dataset), dataset-2 (Phishing Dataset for Machine Learning: Feature\nEvaluation), dataset-3 (Phishing Websites Dataset), and dataset-4 (Web page\nphishing detection), respectively. The high accuracy values obtained across all\ndatasets imply the models' generalizability and effectiveness in the accurate\nidentification of phishing websites.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.09735v1",
    "published_date": "2024-03-13 14:26:25 UTC",
    "updated_date": "2024-03-13 14:26:25 UTC"
  },
  {
    "arxiv_id": "2403.08564v3",
    "title": "Generalizing Fairness to Generative Language Models via Reformulation of Non-discrimination Criteria",
    "authors": [
      "Sara Sterlie",
      "Nina Weng",
      "Aasa Feragen"
    ],
    "abstract": "Generative AI, such as large language models, has undergone rapid development\nwithin recent years. As these models become increasingly available to the\npublic, concerns arise about perpetuating and amplifying harmful biases in\napplications. Gender stereotypes can be harmful and limiting for the\nindividuals they target, whether they consist of misrepresentation or\ndiscrimination. Recognizing gender bias as a pervasive societal construct, this\npaper studies how to uncover and quantify the presence of gender biases in\ngenerative language models. In particular, we derive generative AI analogues of\nthree well-known non-discrimination criteria from classification, namely\nindependence, separation and sufficiency. To demonstrate these criteria in\naction, we design prompts for each of the criteria with a focus on occupational\ngender stereotype, specifically utilizing the medical test to introduce the\nground truth in the generative AI context. Our results address the presence of\noccupational gender bias within such conversational language models.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.08564v3",
    "published_date": "2024-03-13 14:19:08 UTC",
    "updated_date": "2024-09-02 11:09:55 UTC"
  },
  {
    "arxiv_id": "2403.08562v1",
    "title": "Structural perspective on constraint-based learning of Markov networks",
    "authors": [
      "Tuukka Korhonen",
      "Fedor V. Fomin",
      "Pekka Parviainen"
    ],
    "abstract": "Markov networks are probabilistic graphical models that employ undirected\ngraphs to depict conditional independence relationships among variables. Our\nfocus lies in constraint-based structure learning, which entails learning the\nundirected graph from data through the execution of conditional independence\ntests. We establish theoretical limits concerning two critical aspects of\nconstraint-based learning of Markov networks: the number of tests and the sizes\nof the conditioning sets. These bounds uncover an exciting interplay between\nthe structural properties of the graph and the amount of tests required to\nlearn a Markov network. The starting point of our work is that the graph\nparameter maximum pairwise connectivity, $\\kappa$, that is, the maximum number\nof vertex-disjoint paths connecting a pair of vertices in the graph, is\nresponsible for the sizes of independence tests required to learn the graph. On\none hand, we show that at least one test with the size of the conditioning set\nat least $\\kappa$ is always necessary. On the other hand, we prove that any\ngraph can be learned by performing tests of size at most $\\kappa$. This\ncompletely resolves the question of the minimum size of conditioning sets\nrequired to learn the graph. When it comes to the number of tests, our upper\nbound on the sizes of conditioning sets implies that every $n$-vertex graph can\nbe learned by at most $n^{\\kappa}$ tests with conditioning sets of sizes at\nmost $\\kappa$. We show that for any upper bound $q$ on the sizes of the\nconditioning sets, there exist graphs with $O(n q)$ vertices that require at\nleast $n^{\\Omega(\\kappa)}$ tests to learn. This lower bound holds even when the\ntreewidth and the maximum degree of the graph are at most $\\kappa+2$. On the\npositive side, we prove that every graph of bounded treewidth can be learned by\na polynomial number of tests with conditioning sets of sizes at most $2\\kappa$.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.DM"
    ],
    "primary_category": "cs.LG",
    "comment": "AISTATS 2024",
    "pdf_url": "http://arxiv.org/pdf/2403.08562v1",
    "published_date": "2024-03-13 14:14:47 UTC",
    "updated_date": "2024-03-13 14:14:47 UTC"
  },
  {
    "arxiv_id": "2403.08556v2",
    "title": "SM4Depth: Seamless Monocular Metric Depth Estimation across Multiple Cameras and Scenes by One Model",
    "authors": [
      "Yihao Liu",
      "Feng Xue",
      "Anlong Ming",
      "Mingshuai Zhao",
      "Huadong Ma",
      "Nicu Sebe"
    ],
    "abstract": "In the last year, universal monocular metric depth estimation (universal\nMMDE) has gained considerable attention, serving as the foundation model for\nvarious multimedia tasks, such as video and image editing. Nonetheless, current\napproaches face challenges in maintaining consistent accuracy across diverse\nscenes without scene-specific parameters and pre-training, hindering the\npracticality of MMDE. Furthermore, these methods rely on extensive datasets\ncomprising millions, if not tens of millions, of data for training, leading to\nsignificant time and hardware expenses. This paper presents SM$^4$Depth, a\nmodel that seamlessly works for both indoor and outdoor scenes, without needing\nextensive training data and GPU clusters. Firstly, to obtain consistent depth\nacross diverse scenes, we propose a novel metric scale modeling, i.e.,\nvariation-based unnormalized depth bins. It reduces the ambiguity of the\nconventional metric bins and enables better adaptation to large depth gaps of\nscenes during training. Secondly, we propose a \"divide and conquer\" solution to\nreduce reliance on massive training data. Instead of estimating directly from\nthe vast solution space, the metric bins are estimated from multiple solution\nsub-spaces to reduce complexity. Additionally, we introduce an uncut depth\ndataset, BUPT Depth, to evaluate the depth accuracy and consistency across\nvarious indoor and outdoor scenes. Trained on a consumer-grade GPU using just\n150K RGB-D pairs, SM$^4$Depth achieves outstanding performance on the most\nnever-before-seen datasets, especially maintaining consistent accuracy across\nindoors and outdoors. The code can be found\nhttps://github.com/mRobotit/SM4Depth.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted by ACM MultiMedia 24, Project Page:\n  xuefeng-cvr.github.io/SM4Depth",
    "pdf_url": "http://arxiv.org/pdf/2403.08556v2",
    "published_date": "2024-03-13 14:08:25 UTC",
    "updated_date": "2024-08-15 03:30:39 UTC"
  },
  {
    "arxiv_id": "2403.14685v1",
    "title": "Cyclical Log Annealing as a Learning Rate Scheduler",
    "authors": [
      "Philip Naveen"
    ],
    "abstract": "A learning rate scheduler is a predefined set of instructions for varying\nsearch stepsizes during model training processes. This paper introduces a new\nlogarithmic method using harsh restarting of step sizes through stochastic\ngradient descent. Cyclical log annealing implements the restart pattern more\naggressively to maybe allow the usage of more greedy algorithms on the online\nconvex optimization framework. The algorithm was tested on the CIFAR-10 image\ndatasets, and seemed to perform analogously with cosine annealing on large\ntransformer-enhanced residual neural networks. Future experiments would involve\ntesting the scheduler in generative adversarial networks and finding the best\nparameters for the scheduler with more experiments.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.14685v1",
    "published_date": "2024-03-13 14:07:20 UTC",
    "updated_date": "2024-03-13 14:07:20 UTC"
  },
  {
    "arxiv_id": "2403.08554v1",
    "title": "Federated Knowledge Graph Unlearning via Diffusion Model",
    "authors": [
      "Bingchen Liu",
      "Yuanyuan Fang"
    ],
    "abstract": "Federated learning (FL) promotes the development and application of\nartificial intelligence technologies by enabling model sharing and\ncollaboration while safeguarding data privacy. Knowledge graph (KG) embedding\nrepresentation provides a foundation for knowledge reasoning and applications\nby mapping entities and relations into vector space. Federated KG embedding\nenables the utilization of knowledge from diverse client sources while\nsafeguarding the privacy of local data. However, due to demands such as privacy\nprotection and the need to adapt to dynamic data changes, investigations into\nmachine unlearning (MU) have been sparked. However, it is challenging to\nmaintain the performance of KG embedding models while forgetting the influence\nof specific forgotten data on the model. In this paper, we propose FedDM, a\nnovel framework tailored for machine unlearning in federated knowledge graphs.\nLeveraging diffusion models, we generate noisy data to sensibly mitigate the\ninfluence of specific knowledge on FL models while preserving the overall\nperformance concerning the remaining data. We conduct experimental evaluations\non benchmark datasets to assess the efficacy of the proposed model. Extensive\nexperiments demonstrate that FedDM yields promising results in knowledge\nforgetting.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.08554v1",
    "published_date": "2024-03-13 14:06:51 UTC",
    "updated_date": "2024-03-13 14:06:51 UTC"
  },
  {
    "arxiv_id": "2403.08551v5",
    "title": "GaussianImage: 1000 FPS Image Representation and Compression by 2D Gaussian Splatting",
    "authors": [
      "Xinjie Zhang",
      "Xingtong Ge",
      "Tongda Xu",
      "Dailan He",
      "Yan Wang",
      "Hongwei Qin",
      "Guo Lu",
      "Jing Geng",
      "Jun Zhang"
    ],
    "abstract": "Implicit neural representations (INRs) recently achieved great success in\nimage representation and compression, offering high visual quality and fast\nrendering speeds with 10-1000 FPS, assuming sufficient GPU resources are\navailable. However, this requirement often hinders their use on low-end devices\nwith limited memory. In response, we propose a groundbreaking paradigm of image\nrepresentation and compression by 2D Gaussian Splatting, named GaussianImage.\nWe first introduce 2D Gaussian to represent the image, where each Gaussian has\n8 parameters including position, covariance and color. Subsequently, we unveil\na novel rendering algorithm based on accumulated summation. Remarkably, our\nmethod with a minimum of 3$\\times$ lower GPU memory usage and 5$\\times$ faster\nfitting time not only rivals INRs (e.g., WIRE, I-NGP) in representation\nperformance, but also delivers a faster rendering speed of 1500-2000 FPS\nregardless of parameter size. Furthermore, we integrate existing vector\nquantization technique to build an image codec. Experimental results\ndemonstrate that our codec attains rate-distortion performance comparable to\ncompression-based INRs such as COIN and COIN++, while facilitating decoding\nspeeds of approximately 2000 FPS. Additionally, preliminary proof of concept\nshows that our codec surpasses COIN and COIN++ in performance when using\npartial bits-back coding. Code is available at\nhttps://github.com/Xinjie-Q/GaussianImage.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV",
      "cs.MM"
    ],
    "primary_category": "eess.IV",
    "comment": "Accepted by ECCV 2024. Project\n  Page:https://xingtongge.github.io/GaussianImage-page/ Code:\n  https://github.com/Xinjie-Q/GaussianImage",
    "pdf_url": "http://arxiv.org/pdf/2403.08551v5",
    "published_date": "2024-03-13 14:02:54 UTC",
    "updated_date": "2024-07-09 15:48:32 UTC"
  },
  {
    "arxiv_id": "2403.08536v1",
    "title": "HOLMES: HOLonym-MEronym based Semantic inspection for Convolutional Image Classifiers",
    "authors": [
      "Francesco Dibitonto",
      "Fabio Garcea",
      "André Panisson",
      "Alan Perotti",
      "Lia Morra"
    ],
    "abstract": "Convolutional Neural Networks (CNNs) are nowadays the model of choice in\nComputer Vision, thanks to their ability to automatize the feature extraction\nprocess in visual tasks. However, the knowledge acquired during training is\nfully subsymbolic, and hence difficult to understand and explain to end users.\nIn this paper, we propose a new technique called HOLMES (HOLonym-MEronym based\nSemantic inspection) that decomposes a label into a set of related concepts,\nand provides component-level explanations for an image classification model.\nSpecifically, HOLMES leverages ontologies, web scraping and transfer learning\nto automatically construct meronym (parts)-based detectors for a given holonym\n(class). Then, it produces heatmaps at the meronym level and finally, by\nprobing the holonym CNN with occluded images, it highlights the importance of\neach part on the classification output. Compared to state-of-the-art saliency\nmethods, HOLMES takes a step further and provides information about both where\nand what the holonym CNN is looking at, without relying on densely annotated\ndatasets and without forcing concepts to be associated to single computational\nunits. Extensive experimental evaluation on different categories of objects\n(animals, tools and vehicles) shows the feasibility of our approach. On\naverage, HOLMES explanations include at least two meronyms, and the ablation of\na single meronym roughly halves the holonym model confidence. The resulting\nheatmaps were quantitatively evaluated using the\ndeletion/insertion/preservation curves. All metrics were comparable to those\nachieved by GradCAM, while offering the advantage of further decomposing the\nheatmap in human-understandable concepts, thus highlighting both the relevance\nof meronyms to object classification, as well as HOLMES ability to capture it.\nThe code is available at https://github.com/FrancesC0de/HOLMES.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "This work has been accepted to be presented to The 1st World\n  Conference on eXplainable Artificial Intelligence (xAI 2023), July 26-28,\n  2023 - Lisboa, Portugal",
    "pdf_url": "http://arxiv.org/pdf/2403.08536v1",
    "published_date": "2024-03-13 13:51:02 UTC",
    "updated_date": "2024-03-13 13:51:02 UTC"
  },
  {
    "arxiv_id": "2403.08528v1",
    "title": "Pig aggression classification using CNN, Transformers and Recurrent Networks",
    "authors": [
      "Junior Silva Souza",
      "Eduardo Bedin",
      "Gabriel Toshio Hirokawa Higa",
      "Newton Loebens",
      "Hemerson Pistori"
    ],
    "abstract": "The development of techniques that can be used to analyze and detect animal\nbehavior is a crucial activity for the livestock sector, as it is possible to\nmonitor the stress and animal welfare and contributes to decision making in the\nfarm. Thus, the development of applications can assist breeders in making\ndecisions to improve production performance and reduce costs, once the animal\nbehavior is analyzed by humans and this can lead to susceptible errors and time\nconsumption. Aggressiveness in pigs is an example of behavior that is studied\nto reduce its impact through animal classification and identification. However,\nthis process is laborious and susceptible to errors, which can be reduced\nthrough automation by visually classifying videos captured in controlled\nenvironment. The captured videos can be used for training and, as a result, for\nclassification through computer vision and artificial intelligence, employing\nneural network techniques. The main techniques utilized in this study are\nvariants of transformers: STAM, TimeSformer, and ViViT, as well as techniques\nusing convolutions, such as ResNet3D2, Resnet(2+1)D, and CnnLstm. These\ntechniques were employed for pig video classification with the objective of\nidentifying aggressive and non-aggressive behaviors. In this work, various\ntechniques were compared to analyze the contribution of using transformers, in\naddition to the effectiveness of the convolution technique in video\nclassification. The performance was evaluated using accuracy, precision, and\nrecall. The TimerSformer technique showed the best results in video\nclassification, with median accuracy of 0.729.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.08528v1",
    "published_date": "2024-03-13 13:38:58 UTC",
    "updated_date": "2024-03-13 13:38:58 UTC"
  },
  {
    "arxiv_id": "2403.08505v5",
    "title": "CAMSIC: Content-aware Masked Image Modeling Transformer for Stereo Image Compression",
    "authors": [
      "Xinjie Zhang",
      "Shenyuan Gao",
      "Zhening Liu",
      "Jiawei Shao",
      "Xingtong Ge",
      "Dailan He",
      "Tongda Xu",
      "Yan Wang",
      "Jun Zhang"
    ],
    "abstract": "Existing learning-based stereo image codec adopt sophisticated transformation\nwith simple entropy models derived from single image codecs to encode latent\nrepresentations. However, those entropy models struggle to effectively capture\nthe spatial-disparity characteristics inherent in stereo images, which leads to\nsuboptimal rate-distortion results. In this paper, we propose a stereo image\ncompression framework, named CAMSIC. CAMSIC independently transforms each image\nto latent representation and employs a powerful decoder-free Transformer\nentropy model to capture both spatial and disparity dependencies, by\nintroducing a novel content-aware masked image modeling (MIM) technique. Our\ncontent-aware MIM facilitates efficient bidirectional interaction between prior\ninformation and estimated tokens, which naturally obviates the need for an\nextra Transformer decoder. Experiments show that our stereo image codec\nachieves state-of-the-art rate-distortion performance on two stereo image\ndatasets Cityscapes and InStereo2K with fast encoding and decoding speed. Code\nis available at https://github.com/Xinjie-Q/CAMSIC.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV",
      "cs.MM"
    ],
    "primary_category": "eess.IV",
    "comment": "Accepted by AAAI 2025",
    "pdf_url": "http://arxiv.org/pdf/2403.08505v5",
    "published_date": "2024-03-13 13:12:57 UTC",
    "updated_date": "2025-02-08 09:33:17 UTC"
  },
  {
    "arxiv_id": "2403.08502v1",
    "title": "Masked Generative Story Transformer with Character Guidance and Caption Augmentation",
    "authors": [
      "Christos Papadimitriou",
      "Giorgos Filandrianos",
      "Maria Lymperaiou",
      "Giorgos Stamou"
    ],
    "abstract": "Story Visualization (SV) is a challenging generative vision task, that\nrequires both visual quality and consistency between different frames in\ngenerated image sequences. Previous approaches either employ some kind of\nmemory mechanism to maintain context throughout an auto-regressive generation\nof the image sequence, or model the generation of the characters and their\nbackground separately, to improve the rendering of characters. On the contrary,\nwe embrace a completely parallel transformer-based approach, exclusively\nrelying on Cross-Attention with past and future captions to achieve\nconsistency. Additionally, we propose a Character Guidance technique to focus\non the generation of characters in an implicit manner, by forming a combination\nof text-conditional and character-conditional logits in the logit space. We\nalso employ a caption-augmentation technique, carried out by a Large Language\nModel (LLM), to enhance the robustness of our approach. The combination of\nthese methods culminates into state-of-the-art (SOTA) results over various\nmetrics in the most prominent SV benchmark (Pororo-SV), attained with\nconstraint resources while achieving superior computational complexity compared\nto previous arts. The validity of our quantitative results is supported by a\nhuman survey.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.08502v1",
    "published_date": "2024-03-13 13:10:20 UTC",
    "updated_date": "2024-03-13 13:10:20 UTC"
  },
  {
    "arxiv_id": "2403.08840v1",
    "title": "NoiseDiffusion: Correcting Noise for Image Interpolation with Diffusion Models beyond Spherical Linear Interpolation",
    "authors": [
      "PengFei Zheng",
      "Yonggang Zhang",
      "Zhen Fang",
      "Tongliang Liu",
      "Defu Lian",
      "Bo Han"
    ],
    "abstract": "Image interpolation based on diffusion models is promising in creating fresh\nand interesting images. Advanced interpolation methods mainly focus on\nspherical linear interpolation, where images are encoded into the noise space\nand then interpolated for denoising to images. However, existing methods face\nchallenges in effectively interpolating natural images (not generated by\ndiffusion models), thereby restricting their practical applicability. Our\nexperimental investigations reveal that these challenges stem from the\ninvalidity of the encoding noise, which may no longer obey the expected noise\ndistribution, e.g., a normal distribution. To address these challenges, we\npropose a novel approach to correct noise for image interpolation,\nNoiseDiffusion. Specifically, NoiseDiffusion approaches the invalid noise to\nthe expected distribution by introducing subtle Gaussian noise and introduces a\nconstraint to suppress noise with extreme values. In this context, promoting\nnoise validity contributes to mitigating image artifacts, but the constraint\nand introduced exogenous noise typically lead to a reduction in signal-to-noise\nratio, i.e., loss of original image information. Hence, NoiseDiffusion performs\ninterpolation within the noisy image space and injects raw images into these\nnoisy counterparts to address the challenge of information loss. Consequently,\nNoiseDiffusion enables us to interpolate natural images without causing\nartifacts or information loss, thus achieving the best interpolation results.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "ICLR 2024",
    "pdf_url": "http://arxiv.org/pdf/2403.08840v1",
    "published_date": "2024-03-13 12:32:25 UTC",
    "updated_date": "2024-03-13 12:32:25 UTC"
  },
  {
    "arxiv_id": "2403.08838v2",
    "title": "Predictive Clustering of Vessel Behavior Based on Hierarchical Trajectory Representation",
    "authors": [
      "Rui Zhang",
      "Hanyue Wu",
      "Zhenzhong Yin",
      "Zhu Xiao",
      "Yong Xiong",
      "Kezhong Liu"
    ],
    "abstract": "Vessel trajectory clustering, which aims to find similar trajectory patterns,\nhas been widely leveraged in overwater applications. Most traditional methods\nuse predefined rules and thresholds to identify discrete vessel behaviors. They\naim for high-quality clustering and conduct clustering on entire sequences,\nwhether the original trajectory or its sub-trajectories, failing to represent\ntheir evolution. To resolve this problem, we propose a Predictive Clustering of\nHierarchical Vessel Behavior (PC-HiV). PC-HiV first uses hierarchical\nrepresentations to transform every trajectory into a behavioral sequence. Then,\nit predicts evolution at each timestamp of the sequence based on the\nrepresentations. By applying predictive clustering and latent encoding, PC-HiV\nimproves clustering and predictions simultaneously. Experiments on real AIS\ndatasets demonstrate PC-HiV's superiority over existing methods, showcasing its\neffectiveness in capturing behavioral evolution discrepancies between vessel\ntypes (tramp vs. liner) and within emission control areas. Results show that\nour method outperforms NN-Kmeans and Robust DAA by 3.9% and 6.4% of the purity\nscore.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.08838v2",
    "published_date": "2024-03-13 12:05:02 UTC",
    "updated_date": "2024-03-15 06:22:16 UTC"
  },
  {
    "arxiv_id": "2403.08438v2",
    "title": "Reproducibility and Geometric Intrinsic Dimensionality: An Investigation on Graph Neural Network Research",
    "authors": [
      "Tobias Hille",
      "Maximilian Stubbemann",
      "Tom Hanika"
    ],
    "abstract": "Difficulties in replication and reproducibility of empirical evidences in\nmachine learning research have become a prominent topic in recent years.\nEnsuring that machine learning research results are sound and reliable requires\nreproducibility, which verifies the reliability of research findings using the\nsame code and data. This promotes open and accessible research, robust\nexperimental workflows, and the rapid integration of new findings. Evaluating\nthe degree to which research publications support these different aspects of\nreproducibility is one goal of the present work. For this we introduce an\nontology of reproducibility in machine learning and apply it to methods for\ngraph neural networks. Building on these efforts we turn towards another\ncritical challenge in machine learning, namely the curse of dimensionality,\nwhich poses challenges in data collection, representation, and analysis, making\nit harder to find representative data and impeding the training and inference\nprocesses. Using the closely linked concept of geometric intrinsic dimension we\ninvestigate to which extend the used machine learning models are influenced by\nthe intrinsic dimension of the data sets they are trained on.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "68T01 68T07 68T09 51F99",
      "I.2.6"
    ],
    "primary_category": "cs.LG",
    "comment": "39 pages, 9 figures",
    "pdf_url": "http://arxiv.org/pdf/2403.08438v2",
    "published_date": "2024-03-13 11:44:30 UTC",
    "updated_date": "2024-03-19 10:54:22 UTC"
  },
  {
    "arxiv_id": "2403.08430v1",
    "title": "Search-based Optimisation of LLM Learning Shots for Story Point Estimation",
    "authors": [
      "Vali Tawosi",
      "Salwa Alamir",
      "Xiaomo Liu"
    ],
    "abstract": "One of the ways Large Language Models (LLMs) are used to perform machine\nlearning tasks is to provide them with a few examples before asking them to\nproduce a prediction. This is a meta-learning process known as few-shot\nlearning. In this paper, we use available Search-Based methods to optimise the\nnumber and combination of examples that can improve an LLM's estimation\nperformance, when it is used to estimate story points for new agile tasks. Our\npreliminary results show that our SBSE technique improves the estimation\nperformance of the LLM by 59.34% on average (in terms of mean absolute error of\nthe estimation) over three datasets against a zero-shot setting.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "6 pages, Accepted at SSBSE'23 NIER Track",
    "pdf_url": "http://arxiv.org/pdf/2403.08430v1",
    "published_date": "2024-03-13 11:29:37 UTC",
    "updated_date": "2024-03-13 11:29:37 UTC"
  },
  {
    "arxiv_id": "2403.08429v1",
    "title": "Software Vulnerability and Functionality Assessment using LLMs",
    "authors": [
      "Rasmus Ingemann Tuffveson Jensen",
      "Vali Tawosi",
      "Salwa Alamir"
    ],
    "abstract": "While code review is central to the software development process, it can be\ntedious and expensive to carry out. In this paper, we investigate whether and\nhow Large Language Models (LLMs) can aid with code reviews. Our investigation\nfocuses on two tasks that we argue are fundamental to good reviews: (i)\nflagging code with security vulnerabilities and (ii) performing software\nfunctionality validation, i.e., ensuring that code meets its intended\nfunctionality. To test performance on both tasks, we use zero-shot and\nchain-of-thought prompting to obtain final ``approve or reject''\nrecommendations. As data, we employ seminal code generation datasets (HumanEval\nand MBPP) along with expert-written code snippets with security vulnerabilities\nfrom the Common Weakness Enumeration (CWE). Our experiments consider a mixture\nof three proprietary models from OpenAI and smaller open-source LLMs. We find\nthat the former outperforms the latter by a large margin. Motivated by\npromising results, we finally ask our models to provide detailed descriptions\nof security vulnerabilities. Results show that 36.7% of LLM-generated\ndescriptions can be associated with true CWE vulnerabilities.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "4 pages, accepted to NLBSE'24",
    "pdf_url": "http://arxiv.org/pdf/2403.08429v1",
    "published_date": "2024-03-13 11:29:13 UTC",
    "updated_date": "2024-03-13 11:29:13 UTC"
  },
  {
    "arxiv_id": "2403.08426v1",
    "title": "Language-Driven Visual Consensus for Zero-Shot Semantic Segmentation",
    "authors": [
      "Zicheng Zhang",
      "Tong Zhang",
      "Yi Zhu",
      "Jianzhuang Liu",
      "Xiaodan Liang",
      "QiXiang Ye",
      "Wei Ke"
    ],
    "abstract": "The pre-trained vision-language model, exemplified by CLIP, advances\nzero-shot semantic segmentation by aligning visual features with class\nembeddings through a transformer decoder to generate semantic masks. Despite\nits effectiveness, prevailing methods within this paradigm encounter\nchallenges, including overfitting on seen classes and small fragmentation in\nmasks. To mitigate these issues, we propose a Language-Driven Visual Consensus\n(LDVC) approach, fostering improved alignment of semantic and visual\ninformation.Specifically, we leverage class embeddings as anchors due to their\ndiscrete and abstract nature, steering vision features toward class embeddings.\nMoreover, to circumvent noisy alignments from the vision part due to its\nredundant nature, we introduce route attention into self-attention for finding\nvisual consensus, thereby enhancing semantic consistency within the same\nobject. Equipped with a vision-language prompting strategy, our approach\nsignificantly boosts the generalization capacity of segmentation models for\nunseen classes. Experimental results underscore the effectiveness of our\napproach, showcasing mIoU gains of 4.5 on the PASCAL VOC 2012 and 3.6 on the\nCOCO-Stuff 164k for unseen classes compared with the state-of-the-art methods.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.08426v1",
    "published_date": "2024-03-13 11:23:55 UTC",
    "updated_date": "2024-03-13 11:23:55 UTC"
  },
  {
    "arxiv_id": "2403.08425v3",
    "title": "Specification Overfitting in Artificial Intelligence",
    "authors": [
      "Benjamin Roth",
      "Pedro Henrique Luz de Araujo",
      "Yuxi Xia",
      "Saskia Kaltenbrunner",
      "Christoph Korab"
    ],
    "abstract": "Machine learning (ML) and artificial intelligence (AI) approaches are often\ncriticized for their inherent bias and for their lack of control,\naccountability, and transparency. Consequently, regulatory bodies struggle with\ncontaining this technology's potential negative side effects. High-level\nrequirements such as fairness and robustness need to be formalized into\nconcrete specification metrics, imperfect proxies that capture isolated aspects\nof the underlying requirements. Given possible trade-offs between different\nmetrics and their vulnerability to over-optimization, integrating specification\nmetrics in system development processes is not trivial. This paper defines\nspecification overfitting, a scenario where systems focus excessively on\nspecified metrics to the detriment of high-level requirements and task\nperformance. We present an extensive literature survey to categorize how\nresearchers propose, measure, and optimize specification metrics in several AI\nfields (e.g., natural language processing, computer vision, reinforcement\nlearning). Using a keyword-based search on papers from major AI conferences and\njournals between 2018 and mid-2023, we identify and analyze 74 papers that\npropose or optimize specification metrics. We find that although most papers\nimplicitly address specification overfitting (e.g., by reporting more than one\nspecification metric), they rarely discuss which role specification metrics\nshould play in system development or explicitly define the scope and\nassumptions behind metric formulations.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "41 pages, 2 figures. This version of the article has been accepted\n  for publication, after peer review but is not the Version of Record and does\n  not reflect post-acceptance improvements, or any corrections. The Version of\n  Record is available online at: https://doi.org/10.1007/s10462-024-11040-6",
    "pdf_url": "http://arxiv.org/pdf/2403.08425v3",
    "published_date": "2024-03-13 11:20:34 UTC",
    "updated_date": "2025-01-02 21:45:02 UTC"
  },
  {
    "arxiv_id": "2403.08424v2",
    "title": "Distract Large Language Models for Automatic Jailbreak Attack",
    "authors": [
      "Zeguan Xiao",
      "Yan Yang",
      "Guanhua Chen",
      "Yun Chen"
    ],
    "abstract": "Extensive efforts have been made before the public release of Large language\nmodels (LLMs) to align their behaviors with human values. However, even\nmeticulously aligned LLMs remain vulnerable to malicious manipulations such as\njailbreaking, leading to unintended behaviors. In this work, we propose a novel\nblack-box jailbreak framework for automated red teaming of LLMs. We designed\nmalicious content concealing and memory reframing with an iterative\noptimization algorithm to jailbreak LLMs, motivated by the research about the\ndistractibility and over-confidence phenomenon of LLMs. Extensive experiments\nof jailbreaking both open-source and proprietary LLMs demonstrate the\nsuperiority of our framework in terms of effectiveness, scalability and\ntransferability. We also evaluate the effectiveness of existing jailbreak\ndefense methods against our attack and highlight the crucial need to develop\nmore effective and practical defense strategies.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CR",
    "comment": "EMNLP 2024",
    "pdf_url": "http://arxiv.org/pdf/2403.08424v2",
    "published_date": "2024-03-13 11:16:43 UTC",
    "updated_date": "2024-09-30 14:25:39 UTC"
  },
  {
    "arxiv_id": "2403.08414v1",
    "title": "Causal Graph Neural Networks for Wildfire Danger Prediction",
    "authors": [
      "Shan Zhao",
      "Ioannis Prapas",
      "Ilektra Karasante",
      "Zhitong Xiong",
      "Ioannis Papoutsis",
      "Gustau Camps-Valls",
      "Xiao Xiang Zhu"
    ],
    "abstract": "Wildfire forecasting is notoriously hard due to the complex interplay of\ndifferent factors such as weather conditions, vegetation types and human\nactivities. Deep learning models show promise in dealing with this complexity\nby learning directly from data. However, to inform critical decision making, we\nargue that we need models that are right for the right reasons; that is, the\nimplicit rules learned should be grounded by the underlying processes driving\nwildfires. In that direction, we propose integrating causality with Graph\nNeural Networks (GNNs) that explicitly model the causal mechanism among complex\nvariables via graph learning. The causal adjacency matrix considers the\nsynergistic effect among variables and removes the spurious links from highly\ncorrelated impacts. Our methodology's effectiveness is demonstrated through\nsuperior performance forecasting wildfire patterns in the European boreal and\nmediterranean biome. The gain is especially prominent in a highly imbalanced\ndataset, showcasing an enhanced robustness of the model to adapt to regime\nshifts in functional relationships. Furthermore, SHAP values from our trained\nmodel further enhance our understanding of the model's inner workings.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted by ICLR 2024 Machine Learning for Remote Sensing (ML4RS)\n  Workshop",
    "pdf_url": "http://arxiv.org/pdf/2403.08414v1",
    "published_date": "2024-03-13 10:58:55 UTC",
    "updated_date": "2024-03-13 10:58:55 UTC"
  },
  {
    "arxiv_id": "2403.08386v1",
    "title": "Optimizing Risk-averse Human-AI Hybrid Teams",
    "authors": [
      "Andrew Fuchs",
      "Andrea Passarella",
      "Marco Conti"
    ],
    "abstract": "We anticipate increased instances of humans and AI systems working together\nin what we refer to as a hybrid team. The increase in collaboration is expected\nas AI systems gain proficiency and their adoption becomes more widespread.\nHowever, their behavior is not error-free, making hybrid teams a very suitable\nsolution. As such, we consider methods for improving performance for these\nteams of humans and AI systems. For hybrid teams, we will refer to both the\nhumans and AI systems as agents. To improve team performance over that seen for\nagents operating individually, we propose a manager which learns, through a\nstandard Reinforcement Learning scheme, how to best delegate, over time, the\nresponsibility of taking a decision to any of the agents. We further guide the\nmanager's learning so they also minimize how many changes in delegation are\nmade resulting from undesirable team behavior. We demonstrate the optimality of\nour manager's performance in several grid environments which include failure\nstates which terminate an episode and should be avoided. We perform our\nexperiments with teams of agents with varying degrees of acceptable risk, in\nthe form of proximity to a failure state, and measure the manager's ability to\nmake effective delegation decisions with respect to its own risk-based\nconstraints, then compare these to the optimal decisions. Our results show our\nmanager can successfully learn desirable delegations which result in team paths\nnear/exactly optimal with respect to path length and number of delegations.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.08386v1",
    "published_date": "2024-03-13 09:49:26 UTC",
    "updated_date": "2024-03-13 09:49:26 UTC"
  },
  {
    "arxiv_id": "2403.09734v2",
    "title": "Do Large Language Models Solve ARC Visual Analogies Like People Do?",
    "authors": [
      "Gustaw Opiełka",
      "Hannes Rosenbusch",
      "Veerle Vijverberg",
      "Claire E. Stevenson"
    ],
    "abstract": "The Abstraction Reasoning Corpus (ARC) is a visual analogical reasoning test\ndesigned for humans and machines (Chollet, 2019). We compared human and large\nlanguage model (LLM) performance on a new child-friendly set of ARC items.\nResults show that both children and adults outperform most LLMs on these tasks.\nError analysis revealed a similar \"fallback\" solution strategy in LLMs and\nyoung children, where part of the analogy is simply copied. In addition, we\nfound two other error types, one based on seemingly grasping key concepts\n(e.g., Inside-Outside) and the other based on simple combinations of analogy\ninput matrices. On the whole, \"concept\" errors were more common in humans, and\n\"matrix\" errors were more common in LLMs. This study sheds new light on LLM\nreasoning ability and the extent to which we can use error analyses and\ncomparisons with human development to understand how LLMs solve visual\nanalogies.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Changes (based on CogSci 2024 reviewers): - Shortened Intro - Added a\n  table summarizing children performance across age - Added Theoretical\n  discussion in the Discussion section - Corrected the naming of plots - Small\n  clarifications in the Methods section",
    "pdf_url": "http://arxiv.org/pdf/2403.09734v2",
    "published_date": "2024-03-13 09:48:13 UTC",
    "updated_date": "2024-05-13 11:20:23 UTC"
  },
  {
    "arxiv_id": "2403.08375v1",
    "title": "Translating between SQL Dialects for Cloud Migration",
    "authors": [
      "Ran Zmigrod",
      "Salwa Alamir",
      "Xiaomo Liu"
    ],
    "abstract": "Migrations of systems from on-site premises to the cloud has been a\nfundamental endeavor by many industrial institutions. A crucial component of\nsuch cloud migrations is the transition of databases to be hosted online. In\nthis work, we consider the difficulties of this migration for SQL databases.\nWhile SQL is one of the prominent methods for storing database procedures,\nthere are a plethora of different SQL dialects (e.g., MySQL, Postgres, etc.)\nwhich can complicate migrations when the on-premise SQL dialect differs to the\ndialect hosted on the cloud. Tools exist by common cloud provides such as AWS\nand Azure to aid in translating between dialects in order to mitigate the\nmajority of the difficulties. However, these tools do not successfully\ntranslate $100\\%$ of the code. Consequently, software engineers must manually\nconvert the remainder of the untranslated database. For large organizations,\nthis task quickly becomes intractable and so more innovative solutions are\nrequired. We consider this challenge a novel yet vital industrial research\nproblem for any large corporation that is considering cloud migrations.\nFurthermore, we introduce potential avenues of research to tackle this\nchallenge that have yielded promising preliminary results.",
    "categories": [
      "cs.DB",
      "cs.AI",
      "cs.CL",
      "cs.SE"
    ],
    "primary_category": "cs.DB",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.08375v1",
    "published_date": "2024-03-13 09:38:39 UTC",
    "updated_date": "2024-03-13 09:38:39 UTC"
  },
  {
    "arxiv_id": "2403.08370v3",
    "title": "SMART: Submodular Data Mixture Strategy for Instruction Tuning",
    "authors": [
      "H S V N S Kowndinya Renduchintala",
      "Sumit Bhatia",
      "Ganesh Ramakrishnan"
    ],
    "abstract": "Instruction Tuning involves finetuning a language model on a collection of\ninstruction-formatted datasets in order to enhance the generalizability of the\nmodel to unseen tasks. Studies have shown the importance of balancing different\ntask proportions during finetuning, but finding the right balance remains\nchallenging. Unfortunately, there's currently no systematic method beyond\nmanual tuning or relying on practitioners' intuition. In this paper, we\nintroduce SMART (Submodular data Mixture strAtegy for instRuction Tuning) - a\nnovel data mixture strategy which makes use of a submodular function to assign\nimportance scores to tasks which are then used to determine the mixture\nweights. Given a fine-tuning budget, SMART redistributes the budget among tasks\nand selects non-redundant samples from each task. Experimental results\ndemonstrate that SMART significantly outperforms traditional methods such as\nexamples proportional mixing and equal mixing. Furthermore, SMART facilitates\nthe creation of data mixtures based on a few representative subsets of tasks\nalone and through task pruning analysis, we reveal that in a limited budget\nsetting, allocating budget among a subset of representative tasks yields\nsuperior performance compared to distributing the budget among all tasks. The\ncode for reproducing our results is open-sourced at\nhttps://github.com/kowndinya-renduchintala/SMART.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.08370v3",
    "published_date": "2024-03-13 09:31:50 UTC",
    "updated_date": "2024-07-13 11:01:14 UTC"
  },
  {
    "arxiv_id": "2403.08364v1",
    "title": "Decoupled Federated Learning on Long-Tailed and Non-IID data with Feature Statistics",
    "authors": [
      "Zhuoxin Chen",
      "Zhenyu Wu",
      "Yang Ji"
    ],
    "abstract": "Federated learning is designed to enhance data security and privacy, but\nfaces challenges when dealing with heterogeneous data in long-tailed and\nnon-IID distributions. This paper explores an overlooked scenario where tail\nclasses are sparsely distributed over a few clients, causing the models trained\nwith these classes to have a lower probability of being selected during client\naggregation, leading to slower convergence rates and poorer model performance.\nTo address this issue, we propose a two-stage Decoupled Federated learning\nframework using Feature Statistics (DFL-FS). In the first stage, the server\nestimates the client's class coverage distributions through masked local\nfeature statistics clustering to select models for aggregation to accelerate\nconvergence and enhance feature learning without privacy leakage. In the second\nstage, DFL-FS employs federated feature regeneration based on global feature\nstatistics and utilizes resampling and weighted covariance to calibrate the\nglobal classifier to enhance the model's adaptability to long-tailed data\ndistributions. We conducted experiments on CIFAR10-LT and CIFAR100-LT datasets\nwith various long-tailed rates. The results demonstrate that our method\noutperforms state-of-the-art methods in both accuracy and convergence rate.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.08364v1",
    "published_date": "2024-03-13 09:24:59 UTC",
    "updated_date": "2024-03-13 09:24:59 UTC"
  },
  {
    "arxiv_id": "2403.08352v3",
    "title": "Data augmentation with automated machine learning: approaches and performance comparison with classical data augmentation methods",
    "authors": [
      "Alhassan Mumuni",
      "Fuseini Mumuni"
    ],
    "abstract": "Data augmentation is arguably the most important regularization technique\ncommonly used to improve generalization performance of machine learning models.\nIt primarily involves the application of appropriate data transformation\noperations to create new data samples with desired properties. Despite its\neffectiveness, the process is often challenging because of the time-consuming\ntrial and error procedures for creating and testing different candidate\naugmentations and their hyperparameters manually. State-of-the-art approaches\nare increasingly relying on automated machine learning (AutoML) principles.\nThis work presents a comprehensive survey of AutoML-based data augmentation\ntechniques. We discuss various approaches for accomplishing data augmentation\nwith AutoML, including data manipulation, data integration and data synthesis\ntechniques. The focus of this work is on image data augmentation methods.\nNonetheless, we cover other data modalities, especially in cases where the\nspecific data augmentations techniques being discussed are more suitable for\nthese other modalities. For instance, since automated data integration methods\nare more suitable for tabular data, we cover tabular data in the discussion of\ndata integration methods. The work also presents extensive discussion of\ntechniques for accomplishing each of the major subtasks of the image data\naugmentation process: search space design, hyperparameter optimization and\nmodel evaluation. Finally, we carried out an extensive comparison and analysis\nof the performance of automated data augmentation techniques and\nstate-of-the-art methods based on classical augmentation approaches. The\nresults show that AutoML methods for data augmentation currently outperform\nstate-of-the-art techniques based on conventional approaches.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV",
      "cs.NE"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.08352v3",
    "published_date": "2024-03-13 09:00:38 UTC",
    "updated_date": "2025-03-05 22:04:18 UTC"
  },
  {
    "arxiv_id": "2403.08337v2",
    "title": "LLM-Assisted Light: Leveraging Large Language Model Capabilities for Human-Mimetic Traffic Signal Control in Complex Urban Environments",
    "authors": [
      "Maonan Wang",
      "Aoyu Pang",
      "Yuheng Kan",
      "Man-On Pun",
      "Chung Shue Chen",
      "Bo Huang"
    ],
    "abstract": "Traffic congestion in metropolitan areas presents a formidable challenge with\nfar-reaching economic, environmental, and societal ramifications. Therefore,\neffective congestion management is imperative, with traffic signal control\n(TSC) systems being pivotal in this endeavor. Conventional TSC systems,\ndesigned upon rule-based algorithms or reinforcement learning (RL), frequently\nexhibit deficiencies in managing the complexities and variabilities of urban\ntraffic flows, constrained by their limited capacity for adaptation to\nunfamiliar scenarios. In response to these limitations, this work introduces an\ninnovative approach that integrates Large Language Models (LLMs) into TSC,\nharnessing their advanced reasoning and decision-making faculties.\nSpecifically, a hybrid framework that augments LLMs with a suite of perception\nand decision-making tools is proposed, facilitating the interrogation of both\nthe static and dynamic traffic information. This design places the LLM at the\ncenter of the decision-making process, combining external traffic data with\nestablished TSC methods. Moreover, a simulation platform is developed to\ncorroborate the efficacy of the proposed framework. The findings from our\nsimulations attest to the system's adeptness in adjusting to a multiplicity of\ntraffic environments without the need for additional training. Notably, in\ncases of Sensor Outage (SO), our approach surpasses conventional RL-based\nsystems by reducing the average waiting time by $20.4\\%$. This research\nsignifies a notable advance in TSC strategies and paves the way for the\nintegration of LLMs into real-world, dynamic scenarios, highlighting their\npotential to revolutionize traffic management. The related code is available at\nhttps://github.com/Traffic-Alpha/LLM-Assisted-Light.",
    "categories": [
      "eess.SY",
      "cs.AI",
      "cs.LG",
      "cs.SY"
    ],
    "primary_category": "eess.SY",
    "comment": "20 pages, 11 figures",
    "pdf_url": "http://arxiv.org/pdf/2403.08337v2",
    "published_date": "2024-03-13 08:41:55 UTC",
    "updated_date": "2024-06-12 14:53:58 UTC"
  },
  {
    "arxiv_id": "2403.08335v2",
    "title": "A Sparsity Principle for Partially Observable Causal Representation Learning",
    "authors": [
      "Danru Xu",
      "Dingling Yao",
      "Sébastien Lachapelle",
      "Perouz Taslakian",
      "Julius von Kügelgen",
      "Francesco Locatello",
      "Sara Magliacane"
    ],
    "abstract": "Causal representation learning aims at identifying high-level causal\nvariables from perceptual data. Most methods assume that all latent causal\nvariables are captured in the high-dimensional observations. We instead\nconsider a partially observed setting, in which each measurement only provides\ninformation about a subset of the underlying causal state. Prior work has\nstudied this setting with multiple domains or views, each depending on a fixed\nsubset of latents. Here, we focus on learning from unpaired observations from a\ndataset with an instance-dependent partial observability pattern. Our main\ncontribution is to establish two identifiability results for this setting: one\nfor linear mixing functions without parametric assumptions on the underlying\ncausal model, and one for piecewise linear mixing functions with Gaussian\nlatent causal variables. Based on these insights, we propose two methods for\nestimating the underlying causal variables by enforcing sparsity in the\ninferred representation. Experiments on different simulated datasets and\nestablished benchmarks highlight the effectiveness of our approach in\nrecovering the ground-truth latents.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "45 pages, 32 figures, 16 tables",
    "pdf_url": "http://arxiv.org/pdf/2403.08335v2",
    "published_date": "2024-03-13 08:40:49 UTC",
    "updated_date": "2024-06-15 13:06:08 UTC"
  },
  {
    "arxiv_id": "2403.08837v1",
    "title": "Cyclic Data Parallelism for Efficient Parallelism of Deep Neural Networks",
    "authors": [
      "Louis Fournier",
      "Edouard Oyallon"
    ],
    "abstract": "Training large deep learning models requires parallelization techniques to\nscale. In existing methods such as Data Parallelism or ZeRO-DP, micro-batches\nof data are processed in parallel, which creates two drawbacks: the total\nmemory required to store the model's activations peaks at the end of the\nforward pass, and gradients must be simultaneously averaged at the end of the\nbackpropagation step. We propose Cyclic Data Parallelism, a novel paradigm\nshifting the execution of the micro-batches from simultaneous to sequential,\nwith a uniform delay. At the cost of a slight gradient delay, the total memory\ntaken by activations is constant, and the gradient communications are balanced\nduring the training step. With Model Parallelism, our technique reduces the\nnumber of GPUs needed, by sharing GPUs across micro-batches. Within the ZeRO-DP\nframework, our technique allows communication of the model states with\npoint-to-point operations rather than a collective broadcast operation. We\nillustrate the strength of our approach on the CIFAR-10 and ImageNet datasets.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.DC",
      "cs.NE",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.08837v1",
    "published_date": "2024-03-13 08:39:21 UTC",
    "updated_date": "2024-03-13 08:39:21 UTC"
  },
  {
    "arxiv_id": "2403.08333v3",
    "title": "Fast Inference of Removal-Based Node Influence",
    "authors": [
      "Weikai Li",
      "Zhiping Xiao",
      "Xiao Luo",
      "Yizhou Sun"
    ],
    "abstract": "Graph neural networks (GNNs) are widely utilized to capture the information\nspreading patterns in graphs. While remarkable performance has been achieved,\nthere is a new trending topic of evaluating node influence. We propose a new\nmethod of evaluating node influence, which measures the prediction change of a\ntrained GNN model caused by removing a node. A real-world application is, \"In\nthe task of predicting Twitter accounts' polarity, had a particular account\nbeen removed, how would others' polarity change?\". We use the GNN as a\nsurrogate model whose prediction could simulate the change of nodes or edges\ncaused by node removal. Our target is to obtain the influence score for every\nnode, and a straightforward way is to alternately remove every node and apply\nthe trained GNN on the modified graph to generate new predictions. It is\nreliable but time-consuming, so we need an efficient method. The related lines\nof work, such as graph adversarial attack and counterfactual explanation,\ncannot directly satisfy our needs, since their problem settings are different.\nWe propose an efficient, intuitive, and effective method, NOde-Removal-based\nfAst GNN inference (NORA), which uses the gradient information to approximate\nthe node-removal influence. It only costs one forward propagation and one\nbackpropagation to approximate the influence score for all nodes. Extensive\nexperiments on six datasets and six GNN models verify the effectiveness of\nNORA. Our code is available at https://github.com/weikai-li/NORA.git.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Published in the Web Conference 2024",
    "pdf_url": "http://arxiv.org/pdf/2403.08333v3",
    "published_date": "2024-03-13 08:37:31 UTC",
    "updated_date": "2024-05-31 22:36:34 UTC"
  },
  {
    "arxiv_id": "2403.08332v1",
    "title": "Autoregressive Score Generation for Multi-trait Essay Scoring",
    "authors": [
      "Heejin Do",
      "Yunsu Kim",
      "Gary Geunbae Lee"
    ],
    "abstract": "Recently, encoder-only pre-trained models such as BERT have been successfully\napplied in automated essay scoring (AES) to predict a single overall score.\nHowever, studies have yet to explore these models in multi-trait AES, possibly\ndue to the inefficiency of replicating BERT-based models for each trait.\nBreaking away from the existing sole use of encoder, we propose an\nautoregressive prediction of multi-trait scores (ArTS), incorporating a\ndecoding process by leveraging the pre-trained T5. Unlike prior regression or\nclassification methods, we redefine AES as a score-generation task, allowing a\nsingle model to predict multiple scores. During decoding, the subsequent trait\nprediction can benefit by conditioning on the preceding trait scores.\nExperimental results proved the efficacy of ArTS, showing over 5% average\nimprovements in both prompts and traits.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted at EACL2024 Findings",
    "pdf_url": "http://arxiv.org/pdf/2403.08332v1",
    "published_date": "2024-03-13 08:34:53 UTC",
    "updated_date": "2024-03-13 08:34:53 UTC"
  },
  {
    "arxiv_id": "2403.08836v1",
    "title": "Structural Positional Encoding for knowledge integration in transformer-based medical process monitoring",
    "authors": [
      "Christopher Irwin",
      "Marco Dossena",
      "Giorgio Leonardi",
      "Stefania Montani"
    ],
    "abstract": "Predictive process monitoring is a process mining task aimed at forecasting\ninformation about a running process trace, such as the most correct next\nactivity to be executed. In medical domains, predictive process monitoring can\nprovide valuable decision support in atypical and nontrivial situations.\nDecision support and quality assessment in medicine cannot ignore domain\nknowledge, in order to be grounded on all the available information (which is\nnot limited to data) and to be really acceptable by end users.\n  In this paper, we propose a predictive process monitoring approach relying on\nthe use of a {\\em transformer}, a deep learning architecture based on the\nattention mechanism. A major contribution of our work lies in the incorporation\nof ontological domain-specific knowledge, carried out through a graph\npositional encoding technique. The paper presents and discusses the encouraging\nexperimental result we are collecting in the domain of stroke management.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.08836v1",
    "published_date": "2024-03-13 08:15:18 UTC",
    "updated_date": "2024-03-13 08:15:18 UTC"
  },
  {
    "arxiv_id": "2403.08835v1",
    "title": "Stacking-based deep neural network for player scouting in football 1",
    "authors": [
      "Simon Lacan"
    ],
    "abstract": "Datascouting is one of the most known data applications in professional\nsport, and specifically football. Its objective is to analyze huge database of\nplayers in order to detect high potentials that can be then individually\nconsidered by human scouts. In this paper, we propose a stacking-based deep\nlearning model to detect high potential football players. Applied on\nopen-source database, our model obtains significantly better results that\nclassical statistical methods.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.08835v1",
    "published_date": "2024-03-13 08:10:18 UTC",
    "updated_date": "2024-03-13 08:10:18 UTC"
  },
  {
    "arxiv_id": "2403.08834v1",
    "title": "Predictive Analysis of Tuberculosis Treatment Outcomes Using Machine Learning: A Karnataka TB Data Study at a Scale",
    "authors": [
      "SeshaSai Nath Chinagudaba",
      "Darshan Gera",
      "Krishna Kiran Vamsi Dasu",
      "Uma Shankar S",
      "Kiran K",
      "Anil Singarajpure",
      "Shivayogappa. U",
      "Somashekar N",
      "Vineet Kumar Chadda",
      "Sharath B N"
    ],
    "abstract": "Tuberculosis (TB) remains a global health threat, ranking among the leading\ncauses of mortality worldwide. In this context, machine learning (ML) has\nemerged as a transformative force, providing innovative solutions to the\ncomplexities associated with TB treatment.This study explores how machine\nlearning, especially with tabular data, can be used to predict Tuberculosis\n(TB) treatment outcomes more accurately. It transforms this prediction task\ninto a binary classification problem, generating risk scores from patient data\nsourced from NIKSHAY, India's national TB control program, which includes over\n500,000 patient records.\n  Data preprocessing is a critical component of the study, and the model\nachieved an recall of 98% and an AUC-ROC score of 0.95 on the validation set,\nwhich includes 20,000 patient records.We also explore the use of Natural\nLanguage Processing (NLP) for improved model learning. Our results,\ncorroborated by various metrics and ablation studies, validate the\neffectiveness of our approach. The study concludes by discussing the potential\nramifications of our research on TB eradication efforts and proposing potential\navenues for future work. This study marks a significant stride in the battle\nagainst TB, showcasing the potential of machine learning in healthcare.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.08834v1",
    "published_date": "2024-03-13 08:04:00 UTC",
    "updated_date": "2024-03-13 08:04:00 UTC"
  },
  {
    "arxiv_id": "2403.08319v2",
    "title": "Knowledge Conflicts for LLMs: A Survey",
    "authors": [
      "Rongwu Xu",
      "Zehan Qi",
      "Zhijiang Guo",
      "Cunxiang Wang",
      "Hongru Wang",
      "Yue Zhang",
      "Wei Xu"
    ],
    "abstract": "This survey provides an in-depth analysis of knowledge conflicts for large\nlanguage models (LLMs), highlighting the complex challenges they encounter when\nblending contextual and parametric knowledge. Our focus is on three categories\nof knowledge conflicts: context-memory, inter-context, and intra-memory\nconflict. These conflicts can significantly impact the trustworthiness and\nperformance of LLMs, especially in real-world applications where noise and\nmisinformation are common. By categorizing these conflicts, exploring the\ncauses, examining the behaviors of LLMs under such conflicts, and reviewing\navailable solutions, this survey aims to shed light on strategies for improving\nthe robustness of LLMs, thereby serving as a valuable resource for advancing\nresearch in this evolving area.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Our GitHub repo is available at\n  https://github.com/pillowsofwind/Knowledge-Conflicts-Survey",
    "pdf_url": "http://arxiv.org/pdf/2403.08319v2",
    "published_date": "2024-03-13 08:02:23 UTC",
    "updated_date": "2024-06-22 08:31:40 UTC"
  },
  {
    "arxiv_id": "2403.09733v1",
    "title": "OverleafCopilot: Empowering Academic Writing in Overleaf with Large Language Models",
    "authors": [
      "Haomin Wen",
      "Zhenjie Wei",
      "Yan Lin",
      "Jiyuan Wang",
      "Yuxuan Liang",
      "Huaiyu Wan"
    ],
    "abstract": "The rapid development of Large Language Models (LLMs) has facilitated a\nvariety of applications from different domains. In this technical report, we\nexplore the integration of LLMs and the popular academic writing tool,\nOverleaf, to enhance the efficiency and quality of academic writing. To achieve\nthe above goal, there are three challenges: i) including seamless interaction\nbetween Overleaf and LLMs, ii) establishing reliable communication with the LLM\nprovider, and iii) ensuring user privacy. To address these challenges, we\npresent OverleafCopilot, the first-ever tool (i.e., a browser extension) that\nseamlessly integrates LLMs and Overleaf, enabling researchers to leverage the\npower of LLMs while writing papers. Specifically, we first propose an effective\nframework to bridge LLMs and Overleaf. Then, we developed PromptGenius, a\nwebsite for researchers to easily find and share high-quality up-to-date\nprompts. Thirdly, we propose an agent command system to help researchers\nquickly build their customizable agents. OverleafCopilot\n(https://chromewebstore.google.com/detail/overleaf-copilot/eoadabdpninlhkkbhngoddfjianhlghb\n) has been on the Chrome Extension Store, which now serves thousands of\nresearchers. Additionally, the code of PromptGenius is released at\nhttps://github.com/wenhaomin/ChatGPT-PromptGenius. We believe our work has the\npotential to revolutionize academic writing practices, empowering researchers\nto produce higher-quality papers in less time.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.09733v1",
    "published_date": "2024-03-13 07:52:31 UTC",
    "updated_date": "2024-03-13 07:52:31 UTC"
  },
  {
    "arxiv_id": "2403.08312v3",
    "title": "StreamingDialogue: Prolonged Dialogue Learning via Long Context Compression with Minimal Losses",
    "authors": [
      "Jia-Nan Li",
      "Quan Tu",
      "Cunli Mao",
      "Zhengtao Yu",
      "Ji-Rong Wen",
      "Rui Yan"
    ],
    "abstract": "Standard Large Language Models (LLMs) struggle with handling dialogues with\nlong contexts due to efficiency and consistency issues. According to our\nobservation, dialogue contexts are highly structured, and the special token of\n\\textit{End-of-Utterance} (EoU) in dialogues has the potential to aggregate\ninformation. We refer to the EoU tokens as ``conversational attention sinks''\n(conv-attn sinks). Accordingly, we introduce StreamingDialogue, which\ncompresses long dialogue history into conv-attn sinks with minimal losses, and\nthus reduces computational complexity quadratically with the number of sinks\n(i.e., the number of utterances). Current LLMs already demonstrate the ability\nto handle long context window, e.g., a window size of 200K or more. To this\nend, by compressing utterances into EoUs, our method has the potential to\nhandle more than 200K of utterances, resulting in a prolonged dialogue\nlearning. In order to minimize information losses from reconstruction after\ncompression, we design two learning strategies of short-memory reconstruction\n(SMR) and long-memory reactivation (LMR). Our method outperforms strong\nbaselines in dialogue tasks and achieves a 4 $\\times$ speedup while reducing\nmemory usage by 18 $\\times$ compared to dense attention recomputation.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.08312v3",
    "published_date": "2024-03-13 07:44:14 UTC",
    "updated_date": "2024-11-04 09:17:45 UTC"
  },
  {
    "arxiv_id": "2403.08309v2",
    "title": "HRLAIF: Improvements in Helpfulness and Harmlessness in Open-domain Reinforcement Learning From AI Feedback",
    "authors": [
      "Ang Li",
      "Qiugen Xiao",
      "Peng Cao",
      "Jian Tang",
      "Yi Yuan",
      "Zijie Zhao",
      "Xiaoyuan Chen",
      "Liang Zhang",
      "Xiangyang Li",
      "Kaitong Yang",
      "Weidong Guo",
      "Yukang Gan",
      "Xu Yu",
      "Daniell Wang",
      "Ying Shan"
    ],
    "abstract": "Reinforcement Learning from AI Feedback (RLAIF) has the advantages of shorter\nannotation cycles and lower costs over Reinforcement Learning from Human\nFeedback (RLHF), making it highly efficient during the rapid strategy iteration\nperiods of large language model (LLM) training. Using ChatGPT as a labeler to\nprovide feedback on open-domain prompts in RLAIF training, we observe an\nincrease in human evaluators' preference win ratio for model responses, but a\ndecrease in evaluators' satisfaction rate. Analysis suggests that the decrease\nin satisfaction rate is mainly due to some responses becoming less helpful,\nparticularly in terms of correctness and truthfulness, highlighting practical\nlimitations of basic RLAIF. In this paper, we propose Hybrid Reinforcement\nLearning from AI Feedback (HRLAIF). This method enhances the accuracy of AI\nannotations for responses, making the model's helpfulness more robust in\ntraining process. Additionally, it employs AI for Red Teaming, further\nimproving the model's harmlessness. Human evaluation results show that HRLAIF\ninherits the ability of RLAIF to enhance human preference for outcomes at a low\ncost while also improving the satisfaction rate of responses. Compared to the\npolicy model before Reinforcement Learning (RL), it achieves an increase of\n2.08\\% in satisfaction rate, effectively addressing the issue of a decrease of\n4.58\\% in satisfaction rate after basic RLAIF.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "18 pages, 7 figures",
    "pdf_url": "http://arxiv.org/pdf/2403.08309v2",
    "published_date": "2024-03-13 07:38:20 UTC",
    "updated_date": "2024-03-14 04:24:41 UTC"
  },
  {
    "arxiv_id": "2405.00689v1",
    "title": "Anti-Jamming Path Planning Using GCN for Multi-UAV",
    "authors": [
      "Haechan Jeong"
    ],
    "abstract": "This paper addresses the increasing significance of UAVs (Unmanned Aerial\nVehicles) and the emergence of UAV swarms for collaborative operations in\nvarious domains. However, the effectiveness of UAV swarms can be severely\ncompromised by jamming technology, necessitating robust antijamming strategies.\nWhile existing methods such as frequency hopping and physical path planning\nhave been explored, there remains a gap in research on path planning for UAV\nswarms when the jammer's location is unknown. To address this, a novel\napproach, where UAV swarms leverage collective intelligence to predict jamming\nareas, evade them, and efficiently reach target destinations, is proposed. This\napproach utilizes Graph Convolutional Networks (GCN) to predict the location\nand intensity of jamming areas based on information gathered from each UAV. A\nmulti-agent control algorithm is then employed to disperse the UAV swarm, avoid\njamming, and regroup upon reaching the target. Through simulations, the\neffectiveness of the proposed method is demonstrated, showcasing accurate\nprediction of jamming areas and successful evasion through obstacle avoidance\nalgorithms, ultimately achieving the mission objective. Proposed method offers\nrobustness, scalability, and computational efficiency, making it applicable\nacross various scenarios where UAV swarms operate in potentially hostile\nenvironments.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.00689v1",
    "published_date": "2024-03-13 07:28:05 UTC",
    "updated_date": "2024-03-13 07:28:05 UTC"
  },
  {
    "arxiv_id": "2403.08299v1",
    "title": "AutoDev: Automated AI-Driven Development",
    "authors": [
      "Michele Tufano",
      "Anisha Agarwal",
      "Jinu Jang",
      "Roshanak Zilouchian Moghaddam",
      "Neel Sundaresan"
    ],
    "abstract": "The landscape of software development has witnessed a paradigm shift with the\nadvent of AI-powered assistants, exemplified by GitHub Copilot. However,\nexisting solutions are not leveraging all the potential capabilities available\nin an IDE such as building, testing, executing code, git operations, etc.\nTherefore, they are constrained by their limited capabilities, primarily\nfocusing on suggesting code snippets and file manipulation within a chat-based\ninterface. To fill this gap, we present AutoDev, a fully automated AI-driven\nsoftware development framework, designed for autonomous planning and execution\nof intricate software engineering tasks. AutoDev enables users to define\ncomplex software engineering objectives, which are assigned to AutoDev's\nautonomous AI Agents to achieve. These AI agents can perform diverse operations\non a codebase, including file editing, retrieval, build processes, execution,\ntesting, and git operations. They also have access to files, compiler output,\nbuild and testing logs, static analysis tools, and more. This enables the AI\nAgents to execute tasks in a fully automated manner with a comprehensive\nunderstanding of the contextual information required. Furthermore, AutoDev\nestablishes a secure development environment by confining all operations within\nDocker containers. This framework incorporates guardrails to ensure user\nprivacy and file security, allowing users to define specific permitted or\nrestricted commands and operations within AutoDev. In our evaluation, we tested\nAutoDev on the HumanEval dataset, obtaining promising results with 91.5% and\n87.8% of Pass@1 for code generation and test generation respectively,\ndemonstrating its effectiveness in automating software engineering tasks while\nmaintaining a secure and user-controlled development environment.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.08299v1",
    "published_date": "2024-03-13 07:12:03 UTC",
    "updated_date": "2024-03-13 07:12:03 UTC"
  },
  {
    "arxiv_id": "2403.08295v4",
    "title": "Gemma: Open Models Based on Gemini Research and Technology",
    "authors": [
      "Gemma Team",
      "Thomas Mesnard",
      "Cassidy Hardin",
      "Robert Dadashi",
      "Surya Bhupatiraju",
      "Shreya Pathak",
      "Laurent Sifre",
      "Morgane Rivière",
      "Mihir Sanjay Kale",
      "Juliette Love",
      "Pouya Tafti",
      "Léonard Hussenot",
      "Pier Giuseppe Sessa",
      "Aakanksha Chowdhery",
      "Adam Roberts",
      "Aditya Barua",
      "Alex Botev",
      "Alex Castro-Ros",
      "Ambrose Slone",
      "Amélie Héliou",
      "Andrea Tacchetti",
      "Anna Bulanova",
      "Antonia Paterson",
      "Beth Tsai",
      "Bobak Shahriari",
      "Charline Le Lan",
      "Christopher A. Choquette-Choo",
      "Clément Crepy",
      "Daniel Cer",
      "Daphne Ippolito",
      "David Reid",
      "Elena Buchatskaya",
      "Eric Ni",
      "Eric Noland",
      "Geng Yan",
      "George Tucker",
      "George-Christian Muraru",
      "Grigory Rozhdestvenskiy",
      "Henryk Michalewski",
      "Ian Tenney",
      "Ivan Grishchenko",
      "Jacob Austin",
      "James Keeling",
      "Jane Labanowski",
      "Jean-Baptiste Lespiau",
      "Jeff Stanway",
      "Jenny Brennan",
      "Jeremy Chen",
      "Johan Ferret",
      "Justin Chiu",
      "Justin Mao-Jones",
      "Katherine Lee",
      "Kathy Yu",
      "Katie Millican",
      "Lars Lowe Sjoesund",
      "Lisa Lee",
      "Lucas Dixon",
      "Machel Reid",
      "Maciej Mikuła",
      "Mateo Wirth",
      "Michael Sharman",
      "Nikolai Chinaev",
      "Nithum Thain",
      "Olivier Bachem",
      "Oscar Chang",
      "Oscar Wahltinez",
      "Paige Bailey",
      "Paul Michel",
      "Petko Yotov",
      "Rahma Chaabouni",
      "Ramona Comanescu",
      "Reena Jana",
      "Rohan Anil",
      "Ross McIlroy",
      "Ruibo Liu",
      "Ryan Mullins",
      "Samuel L Smith",
      "Sebastian Borgeaud",
      "Sertan Girgin",
      "Sholto Douglas",
      "Shree Pandya",
      "Siamak Shakeri",
      "Soham De",
      "Ted Klimenko",
      "Tom Hennigan",
      "Vlad Feinberg",
      "Wojciech Stokowiec",
      "Yu-hui Chen",
      "Zafarali Ahmed",
      "Zhitao Gong",
      "Tris Warkentin",
      "Ludovic Peran",
      "Minh Giang",
      "Clément Farabet",
      "Oriol Vinyals",
      "Jeff Dean",
      "Koray Kavukcuoglu",
      "Demis Hassabis",
      "Zoubin Ghahramani",
      "Douglas Eck",
      "Joelle Barral",
      "Fernando Pereira",
      "Eli Collins",
      "Armand Joulin",
      "Noah Fiedel",
      "Evan Senter",
      "Alek Andreev",
      "Kathleen Kenealy"
    ],
    "abstract": "This work introduces Gemma, a family of lightweight, state-of-the art open\nmodels built from the research and technology used to create Gemini models.\nGemma models demonstrate strong performance across academic benchmarks for\nlanguage understanding, reasoning, and safety. We release two sizes of models\n(2 billion and 7 billion parameters), and provide both pretrained and\nfine-tuned checkpoints. Gemma outperforms similarly sized open models on 11 out\nof 18 text-based tasks, and we present comprehensive evaluations of safety and\nresponsibility aspects of the models, alongside a detailed description of model\ndevelopment. We believe the responsible release of LLMs is critical for\nimproving the safety of frontier models, and for enabling the next wave of LLM\ninnovations.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.08295v4",
    "published_date": "2024-03-13 06:59:16 UTC",
    "updated_date": "2024-04-16 12:52:47 UTC"
  },
  {
    "arxiv_id": "2403.08293v3",
    "title": "Generative Pretrained Structured Transformers: Unsupervised Syntactic Language Models at Scale",
    "authors": [
      "Xiang Hu",
      "Pengyu Ji",
      "Qingyang Zhu",
      "Wei Wu",
      "Kewei Tu"
    ],
    "abstract": "A syntactic language model (SLM) incrementally generates a sentence with its\nsyntactic tree in a left-to-right manner. We present Generative Pretrained\nStructured Transformers (GPST), an unsupervised SLM at scale capable of being\npre-trained from scratch on raw texts with high parallelism. GPST circumvents\nthe limitations of previous SLMs such as relying on gold trees and sequential\ntraining. It consists of two components, a usual SLM supervised by a\nuni-directional language modeling loss, and an additional composition model,\nwhich induces syntactic parse trees and computes constituent representations,\nsupervised by a bi-directional language modeling loss. We propose a\nrepresentation surrogate to enable joint parallel training of the two models in\na hard-EM fashion. We pre-train GPST on OpenWebText, a corpus with $9$ billion\ntokens, and demonstrate the superiority of GPST over GPT-2 with a comparable\nsize in numerous tasks covering both language understanding and language\ngeneration. Meanwhile, GPST also significantly outperforms existing\nunsupervised SLMs on left-to-right grammar induction, while holding a\nsubstantial acceleration on training.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "accepted by ACL 2024",
    "pdf_url": "http://arxiv.org/pdf/2403.08293v3",
    "published_date": "2024-03-13 06:54:47 UTC",
    "updated_date": "2024-06-17 16:22:52 UTC"
  },
  {
    "arxiv_id": "2403.08292v1",
    "title": "Weak Collocation Regression for Inferring Stochastic Dynamics with Lévy Noise",
    "authors": [
      "Liya Guo",
      "Liwei Lu",
      "Zhijun Zeng",
      "Pipi Hu",
      "Yi Zhu"
    ],
    "abstract": "With the rapid increase of observational, experimental and simulated data for\nstochastic systems, tremendous efforts have been devoted to identifying\ngoverning laws underlying the evolution of these systems. Despite the broad\napplications of non-Gaussian fluctuations in numerous physical phenomena, the\ndata-driven approaches to extracting stochastic dynamics with L\\'{e}vy noise\nare relatively few. In this work, we propose a Weak Collocation Regression\n(WCR) to explicitly reveal unknown stochastic dynamical systems, i.e., the\nStochastic Differential Equation (SDE) with both $\\alpha$-stable L\\'{e}vy noise\nand Gaussian noise, from discrete aggregate data. This method utilizes the\nevolution equation of the probability distribution function, i.e., the\nFokker-Planck (FP) equation. With the weak form of the FP equation, the WCR\nconstructs a linear system of unknown parameters where all integrals are\nevaluated by Monte Carlo method with the observations. Then, the unknown\nparameters are obtained by a sparse linear regression. For a SDE with L\\'{e}vy\nnoise, the corresponding FP equation is a partial integro-differential equation\n(PIDE), which contains nonlocal terms, and is difficult to deal with. The weak\nform can avoid complicated multiple integrals. Our approach can simultaneously\ndistinguish mixed noise types, even in multi-dimensional problems. Numerical\nexperiments demonstrate that our method is accurate and computationally\nefficient.",
    "categories": [
      "math.NA",
      "cs.AI",
      "cs.NA",
      "math.DS"
    ],
    "primary_category": "math.NA",
    "comment": "19 pages, 5 figures, 10 tables",
    "pdf_url": "http://arxiv.org/pdf/2403.08292v1",
    "published_date": "2024-03-13 06:54:38 UTC",
    "updated_date": "2024-03-13 06:54:38 UTC"
  },
  {
    "arxiv_id": "2403.08291v3",
    "title": "CleanAgent: Automating Data Standardization with LLM-based Agents",
    "authors": [
      "Danrui Qi",
      "Zhengjie Miao",
      "Jiannan Wang"
    ],
    "abstract": "Data standardization is a crucial part of the data science life cycle. While\ntools like Pandas offer robust functionalities, their complexity and the manual\neffort required for customizing code to diverse column types pose significant\nchallenges. Although large language models (LLMs) like ChatGPT have shown\npromise in automating this process through natural language understanding and\ncode generation, it still demands expert-level programming knowledge and\ncontinuous interaction for prompt refinement. To solve these challenges, our\nkey idea is to propose a Python library with declarative, unified APIs for\nstandardizing different column types, simplifying the LLM's code generation\nwith concise API calls. We first propose Dataprep.Clean, a component of the\nDataprep Python Library, significantly reduces the coding complexity by\nenabling the standardization of specific column types with a single line of\ncode. Then, we introduce the CleanAgent framework integrating Dataprep.Clean\nand LLM-based agents to automate the data standardization process. With\nCleanAgent, data scientists only need to provide their requirements once,\nallowing for a hands-free process. To demonstrate the practical utility of\nCleanAgent, we developed a user-friendly web application, allowing attendees to\ninteract with it using real-world datasets.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.MA"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.08291v3",
    "published_date": "2024-03-13 06:54:15 UTC",
    "updated_date": "2025-03-07 19:01:29 UTC"
  },
  {
    "arxiv_id": "2403.10555v1",
    "title": "KARINA: An Efficient Deep Learning Model for Global Weather Forecast",
    "authors": [
      "Minjong Cheon",
      "Yo-Hwan Choi",
      "Seon-Yu Kang",
      "Yumi Choi",
      "Jeong-Gil Lee",
      "Daehyun Kang"
    ],
    "abstract": "Deep learning-based, data-driven models are gaining prevalence in climate\nresearch, particularly for global weather prediction. However, training the\nglobal weather data at high resolution requires massive computational\nresources. Therefore, we present a new model named KARINA to overcome the\nsubstantial computational demands typical of this field. This model achieves\nforecasting accuracy comparable to higher-resolution counterparts with\nsignificantly less computational resources, requiring only 4 NVIDIA A100 GPUs\nand less than 12 hours of training. KARINA combines ConvNext, SENet, and\nGeocyclic Padding to enhance weather forecasting at a 2.5{\\deg} resolution,\nwhich could filter out high-frequency noise. Geocyclic Padding preserves pixels\nat the lateral boundary of the input image, thereby maintaining atmospheric\nflow continuity in the spherical Earth. SENet dynamically improves feature\nresponse, advancing atmospheric process modeling, particularly in the vertical\ncolumn process as numerous channels. In this vein, KARINA sets new benchmarks\nin weather forecasting accuracy, surpassing existing models like the ECMWF S2S\nreforecasts at a lead time of up to 7 days. Remarkably, KARINA achieved\ncompetitive performance even when compared to the recently developed models\n(Pangu-Weather, GraphCast, ClimaX, and FourCastNet) trained with\nhigh-resolution data having 100 times larger pixels. Conclusively, KARINA\nsignificantly advances global weather forecasting by efficiently modeling\nEarth's atmosphere with improved accuracy and resource efficiency.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV",
      "physics.ao-ph"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.10555v1",
    "published_date": "2024-03-13 06:41:37 UTC",
    "updated_date": "2024-03-13 06:41:37 UTC"
  },
  {
    "arxiv_id": "2403.08281v4",
    "title": "Mastering Text, Code and Math Simultaneously via Fusing Highly Specialized Language Models",
    "authors": [
      "Ning Ding",
      "Yulin Chen",
      "Ganqu Cui",
      "Xingtai Lv",
      "Weilin Zhao",
      "Ruobing Xie",
      "Bowen Zhou",
      "Zhiyuan Liu",
      "Maosong Sun"
    ],
    "abstract": "Underlying data distributions of natural language, programming code, and\nmathematical symbols vary vastly, presenting a complex challenge for large\nlanguage models (LLMs) that strive to achieve high performance across all three\ndomains simultaneously. Achieving a very high level of proficiency for an LLM\nwithin a specific domain often requires extensive training with relevant\ncorpora, which is typically accompanied by a sacrifice in performance in other\ndomains. In this paper, we propose to fuse models that are already\nhighly-specialized directly. The proposed fusing framework, UltraFuser,\nconsists of three distinct specialists that are already sufficiently trained on\nlanguage, coding, and mathematics. A token-level gating mechanism is introduced\nto blend the specialists' outputs. A two-stage training strategy accompanied by\nbalanced sampling is designed to ensure stability. To effectively train the\nfused model, we further construct a high-quality supervised instruction tuning\ndataset, UltraChat 2, which includes text, code, and mathematical content. This\ndataset comprises approximately 300,000 instructions and covers a wide range of\ntopics in each domain. Experiments show that our model could simultaneously\nachieve mastery of the three crucial domains.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.08281v4",
    "published_date": "2024-03-13 06:18:48 UTC",
    "updated_date": "2024-03-26 09:29:51 UTC"
  },
  {
    "arxiv_id": "2403.08273v1",
    "title": "LiqD: A Dynamic Liquid Level Detection Model under Tricky Small Containers",
    "authors": [
      "Yukun Ma",
      "Zikun Mao"
    ],
    "abstract": "In daily life and industrial production, it is crucial to accurately detect\nchanges in liquid level in containers. Traditional contact measurement methods\nhave some limitations, while emerging non-contact image processing technology\nshows good application prospects. This paper proposes a container dynamic\nliquid level detection model based on U^2-Net. This model uses the SAM model to\ngenerate an initial data set, and then evaluates and filters out high-quality\npseudo-label images through the SemiReward framework to build an exclusive data\nset. The model uses U^2-Net to extract mask images of containers from the data\nset, and uses morphological processing to compensate for mask defects.\nSubsequently, the model calculates the grayscale difference between adjacent\nvideo frame images at the same position, segments the liquid level change area\nby setting a difference threshold, and finally uses a lightweight neural\nnetwork to classify the liquid level state. This approach not only mitigates\nthe impact of intricate surroundings, but also reduces the demand for training\ndata, showing strong robustness and versatility. A large number of experimental\nresults show that the proposed model can effectively detect the dynamic liquid\nlevel changes of the liquid in the container, providing a novel and efficient\nsolution for related fields.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "I.4.6; I.5.2"
    ],
    "primary_category": "cs.CV",
    "comment": "7pages, 7 Figures",
    "pdf_url": "http://arxiv.org/pdf/2403.08273v1",
    "published_date": "2024-03-13 05:53:25 UTC",
    "updated_date": "2024-03-13 05:53:25 UTC"
  },
  {
    "arxiv_id": "2403.08271v2",
    "title": "Efficient Prompt Tuning of Large Vision-Language Model for Fine-Grained Ship Classification",
    "authors": [
      "Long Lan",
      "Fengxiang Wang",
      "Xiangtao Zheng",
      "Zengmao Wang",
      "Xinwang Liu"
    ],
    "abstract": "Fine-grained ship classification in remote sensing (RS-FGSC) poses a\nsignificant challenge due to the high similarity between classes and the\nlimited availability of labeled data, limiting the effectiveness of traditional\nsupervised classification methods. Recent advancements in large pre-trained\nVision-Language Models (VLMs) have demonstrated impressive capabilities in\nfew-shot or zero-shot learning, particularly in understanding image content.\nThis study delves into harnessing the potential of VLMs to enhance\nclassification accuracy for unseen ship categories, which holds considerable\nsignificance in scenarios with restricted data due to cost or privacy\nconstraints. Directly fine-tuning VLMs for RS-FGSC often encounters the\nchallenge of overfitting the seen classes, resulting in suboptimal\ngeneralization to unseen classes, which highlights the difficulty in\ndifferentiating complex backgrounds and capturing distinct ship features. To\naddress these issues, we introduce a novel prompt tuning technique that employs\na hierarchical, multi-granularity prompt design. Our approach integrates remote\nsensing ship priors through bias terms, learned from a small trainable network.\nThis strategy enhances the model's generalization capabilities while improving\nits ability to discern intricate backgrounds and learn discriminative ship\nfeatures. Furthermore, we contribute to the field by introducing a\ncomprehensive dataset, FGSCM-52, significantly expanding existing datasets with\nmore extensive data and detailed annotations for less common ship classes.\nExtensive experimental evaluations demonstrate the superiority of our proposed\nmethod over current state-of-the-art techniques. The source code will be made\npublicly available.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "It has been accepted by TGRS",
    "pdf_url": "http://arxiv.org/pdf/2403.08271v2",
    "published_date": "2024-03-13 05:48:58 UTC",
    "updated_date": "2024-11-29 03:12:11 UTC"
  },
  {
    "arxiv_id": "2403.14683v1",
    "title": "A Moral Imperative: The Need for Continual Superalignment of Large Language Models",
    "authors": [
      "Gokul Puthumanaillam",
      "Manav Vora",
      "Pranay Thangeda",
      "Melkior Ornik"
    ],
    "abstract": "This paper examines the challenges associated with achieving life-long\nsuperalignment in AI systems, particularly large language models (LLMs).\nSuperalignment is a theoretical framework that aspires to ensure that\nsuperintelligent AI systems act in accordance with human values and goals.\nDespite its promising vision, we argue that achieving superalignment requires\nsubstantial changes in the current LLM architectures due to their inherent\nlimitations in comprehending and adapting to the dynamic nature of these human\nethics and evolving global scenarios. We dissect the challenges of encoding an\never-changing spectrum of human values into LLMs, highlighting the\ndiscrepancies between static AI models and the dynamic nature of human\nsocieties. To illustrate these challenges, we analyze two distinct examples:\none demonstrates a qualitative shift in human values, while the other presents\na quantifiable change. Through these examples, we illustrate how LLMs,\nconstrained by their training data, fail to align with contemporary human\nvalues and scenarios. The paper concludes by exploring potential strategies to\naddress and possibly mitigate these alignment discrepancies, suggesting a path\nforward in the pursuit of more adaptable and responsive AI systems.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.14683v1",
    "published_date": "2024-03-13 05:44:50 UTC",
    "updated_date": "2024-03-13 05:44:50 UTC"
  },
  {
    "arxiv_id": "2403.15426v2",
    "title": "CodingTeachLLM: Empowering LLM's Coding Ability via AST Prior Knowledge",
    "authors": [
      "Zhangquan Chen",
      "Chunjiang Liu",
      "Haobin Duan"
    ],
    "abstract": "In this paper, we introduce CodingTeachLLM, a large language model (LLM)\ndesigned for coding teaching. Specially, we aim to enhance the coding ability\nof LLM and lead it to better teaching mode in education context. Thus, we\npropose an end-to-end prior-based three-phases supervised fine-tuned model,\nwhich is proved more competitive than traditional fine-tuning method. More\nspecifically, our model realizes the structural disassembly and incremental\nguided output of educational knowledge. To this end, we robustify data\nclassification of three types via a sampler and overlap estimation neural\nnetwork, and inject the preprocessing datasets into pre-trained model in three\nbatches for LORA fine-tuning. Then, we design a prior module couples system\nprompt, vector databases, and abstract syntax tree task segmentation. Finally,\nthe compression method and regularization constraint are applied to the\nprior-based fine-tuned model, followed by text filter at the output end to\nobtain incremental guided results. Our model represents the first research\neffort to truly embody the tutor role with the features of abundant educational\nknowledge, step-by-step incremental guided outputs and non-disclosure of\nanswers. Extensive experiments report that our model also achieves\nstate-of-the-art in code abilities compared to open-source models, reaching an\nimpressive 75.10% on the HumanEval (@pass 1) benchmark. Additionally, our model\nmaintains strong conversational capabilities, with the 13B quantized version\nachieving scores of 56.34, 50.60, and 45.27 respectively on the MMLU, C-Eval,\nand AGIEval (5 shot) dialogue evaluation benchmarks.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "I.2.7"
    ],
    "primary_category": "cs.LG",
    "comment": "9 pages, 2 figures",
    "pdf_url": "http://arxiv.org/pdf/2403.15426v2",
    "published_date": "2024-03-13 05:38:39 UTC",
    "updated_date": "2025-04-01 03:53:53 UTC"
  },
  {
    "arxiv_id": "2403.08265v2",
    "title": "Random Search as a Baseline for Sparse Neural Network Architecture Search",
    "authors": [
      "Rezsa Farahani"
    ],
    "abstract": "Sparse neural networks have shown similar or better generalization\nperformance than their dense counterparts while having higher parameter\nefficiency. This has motivated a number of works to learn or search for high\nperforming sparse networks. While reports of task performance or efficiency\ngains are impressive, standard baselines are lacking leading to poor\ncomparability and unreliable reproducibility across methods. In this work, we\npropose Random Search as a baseline algorithm for finding good sparse\nconfigurations and study its performance. We apply Random Search on the node\nspace of an overparameterized network with the goal of finding better\ninitialized sparse sub-networks that are positioned more advantageously in the\nloss landscape. We record the post-training performances of the found sparse\nnetworks and at various levels of sparsity, and compare against both their\nfully connected parent networks and random sparse configurations at the same\nsparsity levels. First, we demonstrate performance at different levels of\nsparsity and highlight that a significant level of performance can still be\npreserved even when the network is highly sparse. Second, we observe that for\nthis sparse architecture search task, initialized sparse networks found by\nRandom Search neither perform better nor converge more efficiently than their\nrandom counterparts. Thus we conclude that Random Search may be viewed as a\nreasonable neutral baseline for sparsity search methods.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.NE",
      "I.2.8; I.5.1"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.08265v2",
    "published_date": "2024-03-13 05:32:13 UTC",
    "updated_date": "2024-03-14 05:18:08 UTC"
  },
  {
    "arxiv_id": "2403.08264v1",
    "title": "GPT, Ontology, and CAABAC: A Tripartite Personalized Access Control Model Anchored by Compliance, Context and Attribute",
    "authors": [
      "Raza Nowrozy",
      "Khandakar Ahmed",
      "Hua Wang"
    ],
    "abstract": "As digital healthcare evolves, the security of electronic health records\n(EHR) becomes increasingly crucial. This study presents the GPT-Onto-CAABAC\nframework, integrating Generative Pretrained Transformer (GPT), medical-legal\nontologies and Context-Aware Attribute-Based Access Control (CAABAC) to enhance\nEHR access security. Unlike traditional models, GPT-Onto-CAABAC dynamically\ninterprets policies and adapts to changing healthcare and legal environments,\noffering customized access control solutions. Through empirical evaluation,\nthis framework is shown to be effective in improving EHR security by accurately\naligning access decisions with complex regulatory and situational requirements.\nThe findings suggest its broader applicability in sectors where access control\nmust meet stringent compliance and adaptability standards.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.08264v1",
    "published_date": "2024-03-13 05:30:30 UTC",
    "updated_date": "2024-03-13 05:30:30 UTC"
  },
  {
    "arxiv_id": "2403.08261v1",
    "title": "CoroNetGAN: Controlled Pruning of GANs via Hypernetworks",
    "authors": [
      "Aman Kumar",
      "Khushboo Anand",
      "Shubham Mandloi",
      "Ashutosh Mishra",
      "Avinash Thakur",
      "Neeraj Kasera",
      "Prathosh A P"
    ],
    "abstract": "Generative Adversarial Networks (GANs) have proven to exhibit remarkable\nperformance and are widely used across many generative computer vision\napplications. However, the unprecedented demand for the deployment of GANs on\nresource-constrained edge devices still poses a challenge due to huge number of\nparameters involved in the generation process. This has led to focused\nattention on the area of compressing GANs. Most of the existing works use\nknowledge distillation with the overhead of teacher dependency. Moreover, there\nis no ability to control the degree of compression in these methods. Hence, we\npropose CoroNet-GAN for compressing GAN using the combined strength of\ndifferentiable pruning method via hypernetworks. The proposed method provides\nthe advantage of performing controllable compression while training along with\nreducing training time by a substantial factor. Experiments have been done on\nvarious conditional GAN architectures (Pix2Pix and CycleGAN) to signify the\neffectiveness of our approach on multiple benchmark datasets such as\nEdges-to-Shoes, Horse-to-Zebra and Summer-to-Winter. The results obtained\nillustrate that our approach succeeds to outperform the baselines on\nZebra-to-Horse and Summer-to-Winter achieving the best FID score of 32.3 and\n72.3 respectively, yielding high-fidelity images across all the datasets.\nAdditionally, our approach also outperforms the state-of-the-art methods in\nachieving better inference time on various smart-phone chipsets and data-types\nmaking it a feasible solution for deployment on edge devices.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "eess.IV"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.08261v1",
    "published_date": "2024-03-13 05:24:28 UTC",
    "updated_date": "2024-03-13 05:24:28 UTC"
  },
  {
    "arxiv_id": "2403.08833v1",
    "title": "TINA: Think, Interaction, and Action Framework for Zero-Shot Vision Language Navigation",
    "authors": [
      "Dingbang Li",
      "Wenzhou Chen",
      "Xin Lin"
    ],
    "abstract": "Zero-shot navigation is a critical challenge in Vision-Language Navigation\n(VLN) tasks, where the ability to adapt to unfamiliar instructions and to act\nin unknown environments is essential. Existing supervised learning-based\nmodels, trained using annotated data through reinforcement learning, exhibit\nlimitations in generalization capabilities. Large Language Models (LLMs), with\ntheir extensive knowledge and emergent reasoning abilities, present a potential\npathway for achieving zero-shot navigation. This paper presents a VLN agent\nbased on LLMs, exploring approaches to the zero-shot navigation problem. To\ncompensate for the shortcomings of LLMs in environmental perception, we propose\nthe Thinking, Interacting, and Action (TINA) framework. TINA enables the agent\nto scrutinize perceptual information and autonomously query key clues within\nthe environment through an introduced question-answering module, thereby\naligning instructions with specific perceptual data. The navigation agent's\nperceptual abilities are enhanced through the TINA framework, while the\nexplicit thought and query processes also improve the navigational procedure's\nexplainability and transparency. We evaluate the performance of our method on\nthe Room-to-Room dataset. The experiment results indicate that our approach\nimproves the navigation performance of LLM-based agents. Our approach also\noutperformed some supervised learning-based methods, highlighting its efficacy\nin zero-shot navigation.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.08833v1",
    "published_date": "2024-03-13 05:22:39 UTC",
    "updated_date": "2024-03-13 05:22:39 UTC"
  },
  {
    "arxiv_id": "2403.08251v4",
    "title": "Emergence of Social Norms in Generative Agent Societies: Principles and Architecture",
    "authors": [
      "Siyue Ren",
      "Zhiyao Cui",
      "Ruiqi Song",
      "Zhen Wang",
      "Shuyue Hu"
    ],
    "abstract": "Social norms play a crucial role in guiding agents towards understanding and\nadhering to standards of behavior, thus reducing social conflicts within\nmulti-agent systems (MASs). However, current LLM-based (or generative) MASs\nlack the capability to be normative. In this paper, we propose a novel\narchitecture, named CRSEC, to empower the emergence of social norms within\ngenerative MASs. Our architecture consists of four modules: Creation &\nRepresentation, Spreading, Evaluation, and Compliance. This addresses several\nimportant aspects of the emergent processes all in one: (i) where social norms\ncome from, (ii) how they are formally represented, (iii) how they spread\nthrough agents' communications and observations, (iv) how they are examined\nwith a sanity check and synthesized in the long term, and (v) how they are\nincorporated into agents' planning and actions. Our experiments deployed in the\nSmallville sandbox game environment demonstrate the capability of our\narchitecture to establish social norms and reduce social conflicts within\ngenerative MASs. The positive outcomes of our human evaluation, conducted with\n30 evaluators, further affirm the effectiveness of our approach. Our project\ncan be accessed via the following link: https://github.com/sxswz213/CRSEC.",
    "categories": [
      "cs.MA",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.MA",
    "comment": "Published as a conference paper at IJCAI 2024",
    "pdf_url": "http://arxiv.org/pdf/2403.08251v4",
    "published_date": "2024-03-13 05:08:10 UTC",
    "updated_date": "2024-08-30 04:14:45 UTC"
  },
  {
    "arxiv_id": "2403.08238v1",
    "title": "A Novel Feature Learning-based Bio-inspired Neural Network for Real-time Collision-free Rescue of Multi-Robot Systems",
    "authors": [
      "Junfei Li",
      "Simon X. Yang"
    ],
    "abstract": "Natural disasters and urban accidents drive the demand for rescue robots to\nprovide safer, faster, and more efficient rescue trajectories. In this paper, a\nfeature learning-based bio-inspired neural network (FLBBINN) is proposed to\nquickly generate a heuristic rescue path in complex and dynamic environments,\nas traditional approaches usually cannot provide a satisfactory solution to\nreal-time responses to sudden environmental changes. The neurodynamic model is\nincorporated into the feature learning method that can use environmental\ninformation to improve path planning strategies. Task assignment and\ncollision-free rescue trajectory are generated through robot poses and the\ndynamic landscape of neural activity. A dual-channel scale filter, a neural\nactivity channel, and a secondary distance fusion are employed to extract and\nfilter feature neurons. After completion of the feature learning process, a\nneurodynamics-based feature matrix is established to quickly generate the new\nheuristic rescue paths with parameter-driven topological adaptability. The\nproposed FLBBINN aims to reduce the computational complexity of the neural\nnetwork-based approach and enable the feature learning method to achieve\nreal-time responses to environmental changes. Several simulations and\nexperiments have been conducted to evaluate the performance of the proposed\nFLBBINN. The results show that the proposed FLBBINN would significantly improve\nthe speed, efficiency, and optimality for rescue operations.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.RO",
    "comment": "This paper is accepted to publish in IEEE Transactions on Industrial\n  Electronics",
    "pdf_url": "http://arxiv.org/pdf/2403.08238v1",
    "published_date": "2024-03-13 04:43:10 UTC",
    "updated_date": "2024-03-13 04:43:10 UTC"
  },
  {
    "arxiv_id": "2403.08222v2",
    "title": "Robust Decision Aggregation with Adversarial Experts",
    "authors": [
      "Yongkang Guo",
      "Yuqing Kong"
    ],
    "abstract": "We consider a robust aggregation problem in the presence of both truthful and\nadversarial experts. The truthful experts will report their private signals\ntruthfully, while the adversarial experts can report arbitrarily. We assume\nexperts are marginally symmetric in the sense that they share the same common\nprior and marginal posteriors. The rule maker needs to design an aggregator to\npredict the true world state from these experts' reports, without knowledge of\nthe underlying information structures or adversarial strategies. We aim to find\nthe optimal aggregator that outputs a forecast minimizing regret under the\nworst information structure and adversarial strategies. The regret is defined\nby the difference in expected loss between the aggregator and a benchmark who\naggregates optimally given the information structure and reports of truthful\nexperts.\n  We focus on binary states and reports. Under L1 loss, we show that the\ntruncated mean aggregator is optimal. When there are at most k adversaries,\nthis aggregator discards the k lowest and highest reported values and averages\nthe remaining ones. For L2 loss, the optimal aggregators are piecewise linear\nfunctions. All the optimalities hold when the ratio of adversaries is bounded\nabove by a value determined by the experts' priors and posteriors. The regret\nonly depends on the ratio of adversaries, not on their total number. For hard\naggregators that output a decision, we prove that a random version of the\ntruncated mean is optimal for both L1 and L2. This aggregator randomly follows\na remaining value after discarding the $k$ lowest and highest reported values.\nWe extend the hard aggregator to multi-state setting. We evaluate our\naggregators numerically in an ensemble learning task. We also obtain negative\nresults for general adversarial aggregation problems under broader information\nstructures and report spaces.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.08222v2",
    "published_date": "2024-03-13 03:47:08 UTC",
    "updated_date": "2025-02-06 02:49:16 UTC"
  },
  {
    "arxiv_id": "2405.18434v1",
    "title": "Modeling the Feedback of AI Price Estimations on Actual Market Values",
    "authors": [
      "Viorel Silaghi",
      "Zobaida Alssadi",
      "Ben Mathew",
      "Majed Alotaibi",
      "Ali Alqarni",
      "Marius Silaghi"
    ],
    "abstract": "Public availability of Artificial Intelligence generated information can\nchange the markets forever, and its factoring into economical dynamics may take\neconomists by surprise, out-dating models and schools of thought. Real estate\nhyper-inflation is not a new phenomenon but its consistent and almost\nmonotonous persistence over 12 years, coinciding with prominence of public\nestimation information from Zillow, a successful Mass Real Estate Estimator\n(MREE), could not escape unobserved. What we model is a repetitive theoretical\ngame between the MREE and the home owners, where each player has secret\ninformation and expertise. If the intention is to keep housing affordable and\nmaintain old American lifestyle with broad home-ownership, new challenges are\ndefined. Simulations show that a simple restriction of MREE-style price\nestimation availability to opt-in properties may help partially reduce feedback\nloop by acting on its likely causes, as suggested by experimental simulation\nmodels. The conjecture that the MREE pressure on real estate inflation rate is\ncorrelated with the absolute MREE estimation errors, which is logically\nexplainable, is then validated in simulations.",
    "categories": [
      "econ.GN",
      "cs.AI",
      "cs.CE",
      "cs.CY",
      "cs.GT",
      "q-fin.EC"
    ],
    "primary_category": "econ.GN",
    "comment": "On February 15, 2022 we uploaded in overleaf the first draft of this\n  paper under the name \"Public AI on house price estimations through Zillow may\n  influence a monotonic house price increase and inflation forever according to\n  simulations\", https://www.overleaf.com/read/yttcffkrhvjf\\#7120e1",
    "pdf_url": "http://arxiv.org/pdf/2405.18434v1",
    "published_date": "2024-03-13 03:44:13 UTC",
    "updated_date": "2024-03-13 03:44:13 UTC"
  },
  {
    "arxiv_id": "2403.10553v1",
    "title": "Learning to Watermark LLM-generated Text via Reinforcement Learning",
    "authors": [
      "Xiaojun Xu",
      "Yuanshun Yao",
      "Yang Liu"
    ],
    "abstract": "We study how to watermark LLM outputs, i.e. embedding algorithmically\ndetectable signals into LLM-generated text to track misuse. Unlike the current\nmainstream methods that work with a fixed LLM, we expand the watermark design\nspace by including the LLM tuning stage in the watermark pipeline. While prior\nworks focus on token-level watermark that embeds signals into the output, we\ndesign a model-level watermark that embeds signals into the LLM weights, and\nsuch signals can be detected by a paired detector. We propose a co-training\nframework based on reinforcement learning that iteratively (1) trains a\ndetector to detect the generated watermarked text and (2) tunes the LLM to\ngenerate text easily detectable by the detector while keeping its normal\nutility. We empirically show that our watermarks are more accurate, robust, and\nadaptable (to new attacks). It also allows watermarked model open-sourcing. In\naddition, if used together with alignment, the extra overhead introduced is low\n- only training an extra reward model (i.e. our detector). We hope our work can\nbring more effort into studying a broader watermark design that is not limited\nto working with a fixed LLM. We open-source the code:\nhttps://github.com/xiaojunxu/learning-to-watermark-llm .",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.10553v1",
    "published_date": "2024-03-13 03:43:39 UTC",
    "updated_date": "2024-03-13 03:43:39 UTC"
  },
  {
    "arxiv_id": "2403.08215v2",
    "title": "LIX: Implicitly Infusing Spatial Geometric Prior Knowledge into Visual Semantic Segmentation for Autonomous Driving",
    "authors": [
      "Sicen Guo",
      "Ziwei Long",
      "Zhiyuan Wu",
      "Qijun Chen",
      "Ioannis Pitas",
      "Rui Fan"
    ],
    "abstract": "Despite the impressive performance achieved by data-fusion networks with\nduplex encoders for visual semantic segmentation, they become ineffective when\nspatial geometric data are not available. Implicitly infusing the spatial\ngeometric prior knowledge acquired by a data-fusion teacher network into a\nsingle-modal student network is a practical, albeit less explored research\navenue. This article delves into this topic and resorts to knowledge\ndistillation approaches to address this problem. We introduce the Learning to\nInfuse ''X'' (LIX) framework, with novel contributions in both logit\ndistillation and feature distillation aspects. We present a mathematical proof\nthat underscores the limitation of using a single, fixed weight in decoupled\nknowledge distillation and introduce a logit-wise dynamic weight controller as\na solution to this issue. Furthermore, we develop an adaptively-recalibrated\nfeature distillation algorithm, including two novel techniques: feature\nrecalibration via kernel regression and in-depth feature consistency\nquantification via centered kernel alignment. Extensive experiments conducted\nwith intermediate-fusion and late-fusion networks across various public\ndatasets provide both quantitative and qualitative evaluations, demonstrating\nthe superior performance of our LIX framework when compared to other\nstate-of-the-art approaches.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "cs.RO"
    ],
    "primary_category": "cs.CV",
    "comment": "13 pages, 7 figures, 5 tables",
    "pdf_url": "http://arxiv.org/pdf/2403.08215v2",
    "published_date": "2024-03-13 03:24:36 UTC",
    "updated_date": "2025-03-14 09:24:22 UTC"
  },
  {
    "arxiv_id": "2403.08214v3",
    "title": "P2LHAP:Wearable sensor-based human activity recognition, segmentation and forecast through Patch-to-Label Seq2Seq Transformer",
    "authors": [
      "Shuangjian Li",
      "Tao Zhu",
      "Mingxing Nie",
      "Huansheng Ning",
      "Zhenyu Liu",
      "Liming Chen"
    ],
    "abstract": "Traditional deep learning methods struggle to simultaneously segment,\nrecognize, and forecast human activities from sensor data. This limits their\nusefulness in many fields such as healthcare and assisted living, where\nreal-time understanding of ongoing and upcoming activities is crucial. This\npaper introduces P2LHAP, a novel Patch-to-Label Seq2Seq framework that tackles\nall three tasks in a efficient single-task model. P2LHAP divides sensor data\nstreams into a sequence of \"patches\", served as input tokens, and outputs a\nsequence of patch-level activity labels including the predicted future\nactivities. A unique smoothing technique based on surrounding patch labels, is\nproposed to identify activity boundaries accurately. Additionally, P2LHAP\nlearns patch-level representation by sensor signal channel-independent\nTransformer encoders and decoders. All channels share embedding and Transformer\nweights across all sequences. Evaluated on three public datasets, P2LHAP\nsignificantly outperforms the state-of-the-art in all three tasks,\ndemonstrating its effectiveness and potential for real-world applications.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.08214v3",
    "published_date": "2024-03-13 03:23:50 UTC",
    "updated_date": "2024-09-21 14:53:15 UTC"
  },
  {
    "arxiv_id": "2403.10552v1",
    "title": "Training Self-localization Models for Unseen Unfamiliar Places via Teacher-to-Student Data-Free Knowledge Transfer",
    "authors": [
      "Kenta Tsukahara",
      "Kanji Tanaka",
      "Daiki Iwata"
    ],
    "abstract": "A typical assumption in state-of-the-art self-localization models is that an\nannotated training dataset is available in the target workspace. However, this\ndoes not always hold when a robot travels in a general open-world. This study\nintroduces a novel training scheme for open-world distributed robot systems. In\nour scheme, a robot (\"student\") can ask the other robots it meets at unfamiliar\nplaces (\"teachers\") for guidance. Specifically, a pseudo-training dataset is\nreconstructed from the teacher model and thereafter used for continual learning\nof the student model. Unlike typical knowledge transfer schemes, our scheme\nintroduces only minimal assumptions on the teacher model, such that it can\nhandle various types of open-set teachers, including uncooperative, untrainable\n(e.g., image retrieval engines), and blackbox teachers (i.e., data privacy).\nRather than relying on the availability of private data of teachers as in\nexisting methods, we propose to exploit an assumption that holds universally in\nself-localization tasks: \"The teacher model is a self-localization system\" and\nto reuse the self-localization system of a teacher as a sole accessible\ncommunication channel. We particularly focus on designing an excellent\nstudent/questioner whose interactions with teachers can yield effective\nquestion-and-answer sequences that can be used as pseudo-training datasets for\nthe student self-localization model. When applied to a generic recursive\nknowledge distillation scenario, our approach exhibited stable and consistent\nperformance improvement.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV",
      "cs.RO"
    ],
    "primary_category": "cs.LG",
    "comment": "7 pages, 3 figures, technical report",
    "pdf_url": "http://arxiv.org/pdf/2403.10552v1",
    "published_date": "2024-03-13 03:20:47 UTC",
    "updated_date": "2024-03-13 03:20:47 UTC"
  },
  {
    "arxiv_id": "2403.08211v3",
    "title": "Large Language Models are Contrastive Reasoners",
    "authors": [
      "Liang Yao"
    ],
    "abstract": "Prompting methods play a crucial role in enhancing the capabilities of\npre-trained large language models (LLMs). We explore how contrastive prompting\n(CP) significantly improves the ability of large language models to perform\ncomplex reasoning. We demonstrate that LLMs are decent contrastive reasoners by\nsimply adding \"Let's give a correct and a wrong answer.\" before LLMs provide\nanswers. Experiments on various large language models show that zero-shot\ncontrastive prompting improves the performance of standard zero-shot prompting\non a range of arithmetic, commonsense, and symbolic reasoning tasks without any\nhand-crafted few-shot examples, such as increasing the accuracy on GSM8K from\n35.9% to 88.8% and AQUA-RAT from 41.3% to 62.2% with the state-of-the-art GPT-4\nmodel. Our method not only surpasses zero-shot CoT and few-shot CoT in most\narithmetic and commonsense reasoning tasks but also can seamlessly integrate\nwith existing prompting methods, resulting in improved or comparable results\nwhen compared to state-of-the-art methods. Our code is available at\nhttps://github.com/yao8839836/cp",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.08211v3",
    "published_date": "2024-03-13 03:15:05 UTC",
    "updated_date": "2025-02-17 06:40:44 UTC"
  },
  {
    "arxiv_id": "2403.08199v3",
    "title": "Deep Submodular Peripteral Networks",
    "authors": [
      "Gantavya Bhatt",
      "Arnav Das",
      "Jeff Bilmes"
    ],
    "abstract": "Submodular functions, crucial for various applications, often lack practical\nlearning methods for their acquisition. Seemingly unrelated, learning a scaling\nfrom oracles offering graded pairwise preferences (GPC) is underexplored,\ndespite a rich history in psychometrics. In this paper, we introduce deep\nsubmodular peripteral networks (DSPNs), a novel parametric family of submodular\nfunctions, and methods for their training using a GPC-based strategy to connect\nand then tackle both of the above challenges. We introduce newly devised\nGPC-style ``peripteral'' loss which leverages numerically graded relationships\nbetween pairs of objects (sets in our case). Unlike traditional contrastive\nlearning, or RHLF preference ranking, our method utilizes graded comparisons,\nextracting more nuanced information than just binary-outcome comparisons, and\ncontrasts sets of any size (not just two). We also define a novel suite of\nautomatic sampling strategies for training, including active-learning inspired\nsubmodular feedback. We demonstrate DSPNs' efficacy in learning submodularity\nfrom a costly target submodular function and demonstrate its superiority both\nfor experimental design and online streaming applications.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted at NeurIPS 2024 as spotlight presentation",
    "pdf_url": "http://arxiv.org/pdf/2403.08199v3",
    "published_date": "2024-03-13 02:53:52 UTC",
    "updated_date": "2024-10-31 23:34:57 UTC"
  },
  {
    "arxiv_id": "2403.13002v4",
    "title": "AutoTRIZ: Automating Engineering Innovation with TRIZ and Large Language Models",
    "authors": [
      "Shuo Jiang",
      "Weifeng Li",
      "Yuping Qian",
      "Yangjun Zhang",
      "Jianxi Luo"
    ],
    "abstract": "Various ideation methods, such as morphological analysis and\ndesign-by-analogy, have been developed to aid creative problem-solving and\ninnovation. Among them, the Theory of Inventive Problem Solving (TRIZ) stands\nout as one of the best-known methods. However, the complexity of TRIZ and its\nreliance on users' knowledge, experience, and reasoning capabilities limit its\npracticality. To address this, we introduce AutoTRIZ, an artificial ideation\nsystem that integrates Large Language Models (LLMs) to automate and enhance the\nTRIZ methodology. By leveraging LLMs' vast pre-trained knowledge and advanced\nreasoning capabilities, AutoTRIZ offers a novel, generative, and interpretable\napproach to engineering innovation. AutoTRIZ takes a problem statement from the\nuser as its initial input, automatically conduct the TRIZ reasoning process and\ngenerates a structured solution report. We demonstrate and evaluate the\neffectiveness of AutoTRIZ through comparative experiments with textbook cases\nand a real-world application in the design of a Battery Thermal Management\nSystem (BTMS). Moreover, the proposed LLM-based framework holds the potential\nfor extension to automate other knowledge-based ideation methods, such as\nSCAMPER, Design Heuristics, and Design-by-Analogy, paving the way for a new era\nof AI-driven innovation tools.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.CL",
      "I.2.7; I.2.1"
    ],
    "primary_category": "cs.HC",
    "comment": "28 pages, 12 figures",
    "pdf_url": "http://arxiv.org/pdf/2403.13002v4",
    "published_date": "2024-03-13 02:53:36 UTC",
    "updated_date": "2025-03-24 12:10:38 UTC"
  },
  {
    "arxiv_id": "2403.08197v1",
    "title": "PAGE: Domain-Incremental Adaptation with Past-Agnostic Generative Replay for Smart Healthcare",
    "authors": [
      "Chia-Hao Li",
      "Niraj K. Jha"
    ],
    "abstract": "We propose PAGE, a domain-incremental adaptation strategy with past-agnostic\ngenerative replay for smart healthcare. PAGE enables generative replay without\nthe aid of any preserved data or information from prior domains. When adapting\nto a new domain, it exploits real data from the new distribution and the\ncurrent model to generate synthetic data that retain the learned knowledge of\nprevious domains. By replaying the synthetic data with the new real data during\ntraining, PAGE achieves a good balance between domain adaptation and knowledge\nretention. In addition, we incorporate an extended inductive conformal\nprediction (EICP) method into PAGE to produce a confidence score and a\ncredibility value for each detection result. This makes the predictions\ninterpretable and provides statistical guarantees for disease detection in\nsmart healthcare applications. We demonstrate PAGE's effectiveness in\ndomain-incremental disease detection with three distinct disease datasets\ncollected from commercially available WMSs. PAGE achieves highly competitive\nperformance against state-of-the-art with superior scalability, data privacy,\nand feasibility. Furthermore, PAGE can enable up to 75% reduction in clinical\nworkload with the help of EICP.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "30 pages, 7 figures. arXiv admin note: text overlap with\n  arXiv:2305.05738",
    "pdf_url": "http://arxiv.org/pdf/2403.08197v1",
    "published_date": "2024-03-13 02:44:33 UTC",
    "updated_date": "2024-03-13 02:44:33 UTC"
  },
  {
    "arxiv_id": "2403.09732v4",
    "title": "PET-SQL: A Prompt-Enhanced Two-Round Refinement of Text-to-SQL with Cross-consistency",
    "authors": [
      "Zhishuai Li",
      "Xiang Wang",
      "Jingjing Zhao",
      "Sun Yang",
      "Guoqing Du",
      "Xiaoru Hu",
      "Bin Zhang",
      "Yuxiao Ye",
      "Ziyue Li",
      "Rui Zhao",
      "Hangyu Mao"
    ],
    "abstract": "Recent advancements in Text-to-SQL (Text2SQL) emphasize stimulating the large\nlanguage models (LLM) on in-context learning, achieving significant results.\nNevertheless, they face challenges when dealing with verbose database\ninformation and complex user intentions. This paper presents a two-stage\nframework to enhance the performance of current LLM-based natural language to\nSQL systems. We first introduce a novel prompt representation, called\nreference-enhanced representation, which includes schema information and\nrandomly sampled cell values from tables to instruct LLMs in generating SQL\nqueries. Then, in the first stage, question-SQL pairs are retrieved as few-shot\ndemonstrations, prompting the LLM to generate a preliminary SQL (PreSQL). After\nthat, the mentioned entities in PreSQL are parsed to conduct schema linking,\nwhich can significantly compact the useful information. In the second stage,\nwith the linked schema, we simplify the prompt's schema information and\ninstruct the LLM to produce the final SQL. Finally, as the post-refinement\nmodule, we propose using cross-consistency across different LLMs rather than\nself-consistency within a particular LLM. Our methods achieve new SOTA results\non the Spider benchmark, with an execution accuracy of 87.6%.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.09732v4",
    "published_date": "2024-03-13 02:32:41 UTC",
    "updated_date": "2024-06-02 02:58:53 UTC"
  },
  {
    "arxiv_id": "2403.10550v1",
    "title": "Semi-Supervised Learning for Anomaly Traffic Detection via Bidirectional Normalizing Flows",
    "authors": [
      "Zhangxuan Dang",
      "Yu Zheng",
      "Xinglin Lin",
      "Chunlei Peng",
      "Qiuyu Chen",
      "Xinbo Gao"
    ],
    "abstract": "With the rapid development of the Internet, various types of anomaly traffic\nare threatening network security. We consider the problem of anomaly network\ntraffic detection and propose a three-stage anomaly detection framework using\nonly normal traffic. Our framework can generate pseudo anomaly samples without\nprior knowledge of anomalies to achieve the detection of anomaly data. Firstly,\nwe employ a reconstruction method to learn the deep representation of normal\nsamples. Secondly, these representations are normalized to a standard normal\ndistribution using a bidirectional flow module. To simulate anomaly samples, we\nadd noises to the normalized representations which are then passed through the\ngeneration direction of the bidirectional flow module. Finally, a simple\nclassifier is trained to differentiate the normal samples and pseudo anomaly\nsamples in the latent space. During inference, our framework requires only two\nmodules to detect anomalous samples, leading to a considerable reduction in\nmodel size. According to the experiments, our method achieves the state\nof-the-art results on the common benchmarking datasets of anomaly network\ntraffic detection. The code is given in the\nhttps://github.com/ZxuanDang/ATD-via-Flows.git",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.10550v1",
    "published_date": "2024-03-13 02:10:32 UTC",
    "updated_date": "2024-03-13 02:10:32 UTC"
  },
  {
    "arxiv_id": "2403.08174v1",
    "title": "Rethinking Loss Functions for Fact Verification",
    "authors": [
      "Yuta Mukobara",
      "Yutaro Shigeto",
      "Masashi Shimbo"
    ],
    "abstract": "We explore loss functions for fact verification in the FEVER shared task.\nWhile the cross-entropy loss is a standard objective for training verdict\npredictors, it fails to capture the heterogeneity among the FEVER verdict\nclasses. In this paper, we develop two task-specific objectives tailored to\nFEVER. Experimental results confirm that the proposed objective functions\noutperform the standard cross-entropy. Performance is further improved when\nthese objectives are combined with simple class weighting, which effectively\novercomes the imbalance in the training data. The souce code is available at\nhttps://github.com/yuta-mukobara/RLF-KGAT",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted to EACL 2024 (short paper). The souce code is available at\n  https://github.com/yuta-mukobara/RLF-KGAT",
    "pdf_url": "http://arxiv.org/pdf/2403.08174v1",
    "published_date": "2024-03-13 01:56:32 UTC",
    "updated_date": "2024-03-13 01:56:32 UTC"
  },
  {
    "arxiv_id": "2403.13001v1",
    "title": "Fundamental Components of Deep Learning: A category-theoretic approach",
    "authors": [
      "Bruno Gavranović"
    ],
    "abstract": "Deep learning, despite its remarkable achievements, is still a young field.\nLike the early stages of many scientific disciplines, it is marked by the\ndiscovery of new phenomena, ad-hoc design decisions, and the lack of a uniform\nand compositional mathematical foundation. From the intricacies of the\nimplementation of backpropagation, through a growing zoo of neural network\narchitectures, to the new and poorly understood phenomena such as double\ndescent, scaling laws or in-context learning, there are few unifying principles\nin deep learning. This thesis develops a novel mathematical foundation for deep\nlearning based on the language of category theory. We develop a new framework\nthat is a) end-to-end, b) unform, and c) not merely descriptive, but\nprescriptive, meaning it is amenable to direct implementation in programming\nlanguages with sufficient features. We also systematise many existing\napproaches, placing many existing constructions and concepts from the\nliterature under the same umbrella. In Part I we identify and model two main\nproperties of deep learning systems parametricity and bidirectionality by we\nexpand on the previously defined construction of actegories and Para to study\nthe former, and define weighted optics to study the latter. Combining them\nyields parametric weighted optics, a categorical model of artificial neural\nnetworks, and more. Part II justifies the abstractions from Part I, applying\nthem to model backpropagation, architectures, and supervised learning. We\nprovide a lens-theoretic axiomatisation of differentiation, covering not just\nsmooth spaces, but discrete settings of boolean circuits as well. We survey\nexisting, and develop new categorical models of neural network architectures.\nWe formalise the notion of optimisers and lastly, combine all the existing\nconcepts together, providing a uniform and compositional framework for\nsupervised learning.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "math.CT"
    ],
    "primary_category": "cs.LG",
    "comment": "PhD Thesis defended at University of Strathclyde",
    "pdf_url": "http://arxiv.org/pdf/2403.13001v1",
    "published_date": "2024-03-13 01:29:40 UTC",
    "updated_date": "2024-03-13 01:29:40 UTC"
  },
  {
    "arxiv_id": "2403.08161v1",
    "title": "LAFS: Landmark-based Facial Self-supervised Learning for Face Recognition",
    "authors": [
      "Zhonglin Sun",
      "Chen Feng",
      "Ioannis Patras",
      "Georgios Tzimiropoulos"
    ],
    "abstract": "In this work we focus on learning facial representations that can be adapted\nto train effective face recognition models, particularly in the absence of\nlabels. Firstly, compared with existing labelled face datasets, a vastly larger\nmagnitude of unlabeled faces exists in the real world. We explore the learning\nstrategy of these unlabeled facial images through self-supervised pretraining\nto transfer generalized face recognition performance. Moreover, motivated by\none recent finding, that is, the face saliency area is critical for face\nrecognition, in contrast to utilizing random cropped blocks of images for\nconstructing augmentations in pretraining, we utilize patches localized by\nextracted facial landmarks. This enables our method - namely LAndmark-based\nFacial Self-supervised learning LAFS), to learn key representation that is more\ncritical for face recognition. We also incorporate two landmark-specific\naugmentations which introduce more diversity of landmark information to further\nregularize the learning. With learned landmark-based facial representations, we\nfurther adapt the representation for face recognition with regularization\nmitigating variations in landmark positions. Our method achieves significant\nimprovement over the state-of-the-art on multiple face recognition benchmarks,\nespecially on more challenging few-shot scenarios.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "accepted to CVPR 2024",
    "pdf_url": "http://arxiv.org/pdf/2403.08161v1",
    "published_date": "2024-03-13 01:07:55 UTC",
    "updated_date": "2024-03-13 01:07:55 UTC"
  },
  {
    "arxiv_id": "2403.08153v2",
    "title": "The Runtime of Random Local Search on the Generalized Needle Problem",
    "authors": [
      "Benjamin Doerr",
      "Andrew James Kelley"
    ],
    "abstract": "In their recent work, C. Doerr and Krejca (Transactions on Evolutionary\nComputation, 2023) proved upper bounds on the expected runtime of the\nrandomized local search heuristic on generalized Needle functions. Based on\nthese upper bounds, they deduce in a not fully rigorous manner a drastic\ninfluence of the needle radius $k$ on the runtime.\n  In this short article, we add the missing lower bound necessary to determine\nthe influence of parameter $k$ on the runtime. To this aim, we derive an exact\ndescription of the expected runtime, which also significantly improves the\nupper bound given by C. Doerr and Krejca. We also describe asymptotic estimates\nof the expected runtime.",
    "categories": [
      "cs.NE",
      "cs.AI",
      "cs.DS"
    ],
    "primary_category": "cs.NE",
    "comment": "18 pages",
    "pdf_url": "http://arxiv.org/pdf/2403.08153v2",
    "published_date": "2024-03-13 00:30:47 UTC",
    "updated_date": "2024-03-20 00:18:40 UTC"
  },
  {
    "arxiv_id": "2403.08151v1",
    "title": "Measuring the Energy Consumption and Efficiency of Deep Neural Networks: An Empirical Analysis and Design Recommendations",
    "authors": [
      "Charles Edison Tripp",
      "Jordan Perr-Sauer",
      "Jamil Gafur",
      "Amabarish Nag",
      "Avi Purkayastha",
      "Sagi Zisman",
      "Erik A. Bensen"
    ],
    "abstract": "Addressing the so-called ``Red-AI'' trend of rising energy consumption by\nlarge-scale neural networks, this study investigates the actual energy\nconsumption, as measured by node-level watt-meters, of training various fully\nconnected neural network architectures. We introduce the BUTTER-E dataset, an\naugmentation to the BUTTER Empirical Deep Learning dataset, containing energy\nconsumption and performance data from 63,527 individual experimental runs\nspanning 30,582 distinct configurations: 13 datasets, 20 sizes (number of\ntrainable parameters), 8 network ``shapes'', and 14 depths on both CPU and GPU\nhardware collected using node-level watt-meters. This dataset reveals the\ncomplex relationship between dataset size, network structure, and energy use,\nand highlights the impact of cache effects. We propose a straightforward and\neffective energy model that accounts for network size, computing, and memory\nhierarchy. Our analysis also uncovers a surprising, hardware-mediated\nnon-linear relationship between energy efficiency and network design,\nchallenging the assumption that reducing the number of parameters or FLOPs is\nthe best way to achieve greater energy efficiency. Highlighting the need for\ncache-considerate algorithm development, we suggest a combined approach to\nenergy efficient network, algorithm, and hardware design. This work contributes\nto the fields of sustainable computing and Green AI, offering practical\nguidance for creating more energy-efficient neural networks and promoting\nsustainable AI.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.NE"
    ],
    "primary_category": "cs.LG",
    "comment": "25 pages, 8 figures, for associated dataset see\n  https://data.openei.org/submissions/5991",
    "pdf_url": "http://arxiv.org/pdf/2403.08151v1",
    "published_date": "2024-03-13 00:27:19 UTC",
    "updated_date": "2024-03-13 00:27:19 UTC"
  }
]