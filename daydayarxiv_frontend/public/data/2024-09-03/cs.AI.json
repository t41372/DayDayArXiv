{
  "date": "2024-09-03",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-09-03 的 arXiv 中文 TLDR 快报！今天 arXiv 更新了约 100 篇论文，主要聚焦 AI 模型优化（如 LLM 和扩散模型）、医疗图像处理、语音转换和机器人应用等领域，亮点包括开源混合专家模型 OLMoE（由 Allen Institute 团队发布）、高效代码预训练模型 Arctic-SnowCoder，以及机器人超声成像框架，这些论文展示了 AI 在实际应用中的潜力，并强调了数据质量和鲁棒性改进。\n\n下面，我将挑选并简要讨论几篇重要或有话题度的论文，先从高影响力或创新性强的入手，再快速掠过其他次要内容。每个条目列出论文标题（中文 + 英文），并聚焦核心贡献和发现。\n\n### 重点论文讨论\n\n**1. Coaching a Robotic Sonographer: Learning Robotic Ultrasound with Sparse Expert's Feedback（机器人超声引导：利用稀疏专家反馈学习机器人超声）**  \n这篇论文由 Juan Wachs 和 Richard Voyles 等学者主导，提出一个结合深度强化学习 (DRL) 和专家反馈的框架，用于机器人超声成像。核心贡献是使用 Soft Actor-Critic (SAC) 网络和部分可观测 Markov 决策过程 (POMDP) 模型，提高图像质量，实验显示学习率提升 25%，高质量图像获取率增加 74.5%。这为医疗 AI 带来实际应用潜力，解决操作者培训不足的问题。\n\n**2. Arctic-SnowCoder: Demystifying High-Quality Data in Code Pretraining（Arctic-SnowCoder：揭秘代码预训练中的高质量数据）**  \n作者 Yuxiang Wei 等开发了 Arctic-SnowCoder-1.3B 模型，通过三阶段数据精炼（一般预训练、高质量选择和合成数据）提升代码生成性能。关键发现是高质量数据（如 BERT-style 标注和 Llama-3.1 生成的合成数据）能显著提高模型在 BigCodeBench 等基准上的表现，超越同规模模型（如 Phi-1.5-1.3B）。这篇有话题度，强调数据分布与下游任务的匹配，对 LLM 预训练领域有启发。\n\n**3. TimeDiT: General-purpose Diffusion Transformers for Time Series Foundation Model（TimeDiT：通用扩散 Transformer 用于时间序列基础模型）**  \n论文由 Yan Liu 领导，引入 TimeDiT 模型，结合 Transformer 和扩散采样处理时间序列数据。核心创新是统一掩码机制和无微调编辑策略，处理缺失值和不确定性，在预测、插值和异常检测任务中表现出色。该模型桥接了通用和领域特定模型，实验证明其在 ICML 2024 相关基准上的有效性，是时间序列 AI 的重要进展。\n\n**4. OLMoE: Open Mixture-of-Experts Language Models（OLMoE：开源混合专家语言模型）**  \n由 Allen Institute 的团队（如 Noah A. Smith）发布，这篇论文开源了 OLMoE-1B-7B 模型，使用稀疏混合专家架构在 5 万亿 token 上预训练。关键发现是它在少量参数下超越更大模型（如 Llama2-13B），并在代码和日志中开源所有资源。该工作推动了高效 LLM 的开源生态，对 AI 社区有显著影响。\n\n**5. FastVoiceGrad: One-step Diffusion-Based Voice Conversion with Adversarial Conditional Diffusion Distillation（FastVoiceGrad：基于对抗条件扩散蒸馏的一步语音转换）**  \nTakuhiro Kaneko 等提出 FastVoiceGrad 模型，通过对抗条件扩散蒸馏实现一步语音转换，显著减少推理步骤。核心贡献是保持高质量语音转换，同时加速处理，实验显示其在语音质量和说话者相似度上优于多步方法。该论文在 Interspeech 2024 接受，适用于实时语音应用。\n\n其他论文数量较多，我将快速掠过次要或专业性强的部分，仅提炼关键点：\n- **医疗图像和生物学相关：** 如 \"Biochemical Prostate Cancer Recurrence Prediction: Thinking Fast & Slow\"（生化前列腺癌复发预测：快速与缓慢思考），使用两阶段多实例学习预测癌症复发，C-index 达 0.733，提升了诊断准确性；\"DepthCrafter: Generating Consistent Long Depth Sequences for Open-world Videos\"（DepthCrafter：生成一致的长深度序列），贡献了视频深度估计框架，支持下游任务。\n- **AI 优化和应用：** \"Broadening Access to Simulations for End-Users via Large Language Models\"（通过 LLM 扩展模拟访问），讨论 LLM 在模拟中的机会和挑战；\"Reinforcement Learning-enabled Satellite Constellation Reconfiguration\"（强化学习启用卫星星座重构），使用 DQN 和 PPO 优化卫星故障响应。\n- **语音和图像处理：** \"Speech Foundation Model Ensembles for the Controlled Singing Voice Deepfake Detection\"（语音基础模型集成用于控制歌声深度伪造检测），EER 低至 1.79%，提升了深度伪造检测；\"AllWeatherNet: Unified Image Enhancement for Autonomous Driving\"（AllWeatherNet：统一图像增强用于自动驾驶），改善了恶劣天气下的图像质量。\n- **其他领域：** 如 \"The Computational Mechanisms of Detached Mindfulness\"（分离正念的计算机制），探索正念的认知模型；\"NoiseAttack: An Evasive Sample-Specific Multi-Targeted Backdoor Attack\"（NoiseAttack：基于高斯噪声的逃避性后门攻击），揭示了 AI 安全漏洞。\n\n总之，今天的论文突出了 AI 在医疗、语音和模型优化中的创新应用，但也提醒了数据隐私和鲁棒性的挑战。感兴趣的读者可关注上述重点论文进行深入阅读！（共 100 篇，限于篇幅，未尽详述。）",
  "papers": [
    {
      "arxiv_id": "2409.02337v1",
      "title": "Coaching a Robotic Sonographer: Learning Robotic Ultrasound with Sparse Expert's Feedback",
      "title_zh": "指导机器人超声检查师：利用稀疏专家反馈学习机器人超声",
      "authors": [
        "Deepak Raina",
        "Mythra V. Balakuntala",
        "Byung Wook Kim",
        "Juan Wachs",
        "Richard Voyles"
      ],
      "abstract": "Ultrasound is widely employed for clinical intervention and diagnosis, due to\nits advantages of offering non-invasive, radiation-free, and real-time imaging.\nHowever, the accessibility of this dexterous procedure is limited due to the\nsubstantial training and expertise required of operators. The robotic\nultrasound (RUS) offers a viable solution to address this limitation;\nnonetheless, achieving human-level proficiency remains challenging. Learning\nfrom demonstrations (LfD) methods have been explored in RUS, which learns the\npolicy prior from a dataset of offline demonstrations to encode the mental\nmodel of the expert sonographer. However, active engagement of experts, i.e.\nCoaching, during the training of RUS has not been explored thus far. Coaching\nis known for enhancing efficiency and performance in human training. This paper\nproposes a coaching framework for RUS to amplify its performance. The framework\ncombines DRL (self-supervised practice) with sparse expert's feedback through\ncoaching. The DRL employs an off-policy Soft Actor-Critic (SAC) network, with a\nreward based on image quality rating. The coaching by experts is modeled as a\nPartially Observable Markov Decision Process (POMDP), which updates the policy\nparameters based on the correction by the expert. The validation study on\nphantoms showed that coaching increases the learning rate by $25\\%$ and the\nnumber of high-quality image acquisition by $74.5\\%$.",
      "tldr_zh": "这篇论文提出了一种Coaching框架，用于机器人超声 (RUS) 的学习，旨在通过稀疏专家反馈提升RUS的操作性能，以解决传统超声成像需要大量专业培训的限制。框架结合了DRL（深度强化学习）中的off-policy Soft Actor-Critic (SAC) 网络，以图像质量评分作为奖励，并将专家指导建模为Partially Observable Markov Decision Process (POMDP)，从而动态更新策略参数。实验结果显示，该框架在幻影验证中将学习率提高了25%，并将高质量图像获取数量增加了74.5%。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.RO",
      "comment": "Accepted in IEEE Transactions on Medical Robotics and Bionics (TMRB)\n  2024",
      "pdf_url": "http://arxiv.org/pdf/2409.02337v1",
      "published_date": "2024-09-03 23:52:33 UTC",
      "updated_date": "2024-09-03 23:52:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:54:03.791782"
    },
    {
      "arxiv_id": "2409.15290v1",
      "title": "Broadening Access to Simulations for End-Users via Large Language Models: Challenges and Opportunities",
      "title_zh": "通过大语言模型扩展最终用户对模拟的访问：挑战和机会",
      "authors": [
        "Philippe J. Giabbanelli",
        "Jose J. Padilla",
        "Ameeta Agrawal"
      ],
      "abstract": "Large Language Models (LLMs) are becoming ubiquitous to create intelligent\nvirtual assistants that assist users in interacting with a system, as\nexemplified in marketing. Although LLMs have been discussed in Modeling &\nSimulation (M&S), the community has focused on generating code or explaining\nresults. We examine the possibility of using LLMs to broaden access to\nsimulations, by enabling non-simulation end-users to ask what-if questions in\neveryday language. Specifically, we discuss the opportunities and challenges in\ndesigning such an end-to-end system, divided into three broad phases. First,\nassuming the general case in which several simulation models are available,\ntextual queries are mapped to the most relevant model. Second, if a mapping\ncannot be found, the query can be automatically reformulated and clarifying\nquestions can be generated. Finally, simulation results are produced and\ncontextualized for decision-making. Our vision for such system articulates\nlong-term research opportunities spanning M&S, LLMs, information retrieval, and\nethics.",
      "tldr_zh": "这篇论文探讨了如何利用 Large Language Models (LLMs) 拓宽终端用户对模拟系统的访问，允许非专业用户通过日常语言提出“假设性”问题。论文提出一个端到端系统，分为三个阶段：首先，将文本查询映射到最相关的 Modeling & Simulation (M&S) 模型；其次，如果映射失败，则自动重述查询并生成澄清问题；最后，生成并 contextualize 模拟结果以支持决策。该系统揭示了设计过程中的挑战和机会，包括跨领域研究如 M&S、LLMs、信息检索和伦理方面的长期潜力。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "To appear in proceedings of the 2024 Winter Simulation Conference",
      "pdf_url": "http://arxiv.org/pdf/2409.15290v1",
      "published_date": "2024-09-03 23:14:42 UTC",
      "updated_date": "2024-09-03 23:14:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:54:16.642114"
    },
    {
      "arxiv_id": "2409.02326v1",
      "title": "Arctic-SnowCoder: Demystifying High-Quality Data in Code Pretraining",
      "title_zh": "翻译失败",
      "authors": [
        "Yuxiang Wei",
        "Hojae Han",
        "Rajhans Samdani"
      ],
      "abstract": "Recent studies have been increasingly demonstrating that high-quality data is\ncrucial for effective pretraining of language models. However, the precise\ndefinition of \"high-quality\" remains underexplored. Focusing on the code\ndomain, we introduce Arctic-SnowCoder-1.3B, a data-efficient base code model\npretrained on 555B tokens through three phases of progressively refined data:\n(1) general pretraining with 500B standard-quality code tokens, preprocessed\nthrough basic filtering, deduplication, and decontamination, (2) continued\npretraining with 50B high-quality tokens, selected from phase one by a\nBERT-style quality annotator trained to distinguish good code from random data,\nusing positive examples drawn from high-quality code files, along with\ninstruction data from Magicoder and StarCoder2-Instruct, and (3) enhanced\npretraining with 5B synthetic data created by Llama-3.1-70B using phase two\ndata as seeds, adapting the Magicoder approach for pretraining. Despite being\ntrained on a limited dataset, Arctic-SnowCoder achieves state-of-the-art\nperformance on BigCodeBench, a coding benchmark focusing on practical and\nchallenging programming tasks, compared to similarly sized models trained on no\nmore than 1T tokens, outperforming Phi-1.5-1.3B by 36%. Across all evaluated\nbenchmarks, Arctic-SnowCoder-1.3B beats StarCoderBase-3B pretrained on 1T\ntokens. Additionally, it matches the performance of leading small base code\nmodels trained on trillions of tokens. For example, Arctic-SnowCoder-1.3B\nsurpasses StarCoder2-3B, pretrained on over 3.3T tokens, on HumanEval+, a\nbenchmark that evaluates function-level code generation, and remains\ncompetitive on BigCodeBench. Our evaluation presents a comprehensive analysis\njustifying various design choices for Arctic-SnowCoder. Most importantly, we\nfind that the key to high-quality data is its alignment with the distribution\nof downstream applications.",
      "tldr_zh": "本研究探讨了代码预训练中高质量数据的定义和重要性，引入了Arctic-SnowCoder-1.3B模型，该模型通过三个阶段的逐步精炼数据（包括500B标准质量tokens、50B高质量tokens和5B合成数据）在555B tokens上进行高效预训练。Arctic-SnowCoder采用BERT-style质量注释器和检索增强生成技术，结合Magicoder和StarCoder2-Instruct的数据来源，以优化代码生成性能。尽管数据集规模有限，该模型在BigCodeBench上超越类似规模的基线模型（如Phi-1.5-1.3B，提高36%），并在HumanEval+等基准上优于StarCoderBase-3B和StarCoder2-3B。研究的关键发现是，高质量数据的核心在于其与下游应用分布的匹配，从而提升了代码语言模型的实际效果。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.02326v1",
      "published_date": "2024-09-03 22:36:42 UTC",
      "updated_date": "2024-09-03 22:36:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:54:30.876612"
    },
    {
      "arxiv_id": "2409.02322v2",
      "title": "TimeDiT: General-purpose Diffusion Transformers for Time Series Foundation Model",
      "title_zh": "翻译失败",
      "authors": [
        "Defu Cao",
        "Wen Ye",
        "Yizhou Zhang",
        "Yan Liu"
      ],
      "abstract": "Foundation models, particularly Large Language Models (LLMs), have\nrevolutionized text and video processing, yet time series data presents\ndistinct challenges for such approaches due to domain-specific features such as\nmissing values, multi-resolution characteristics, etc. Furthermore, the\nde-facto autoregressive transformers tend to learn deterministic temporal\ndependencies within pre-trained data while overlooking inherent uncertainties\nand lacking integration of physical constraints. In this paper, we introduce\nTimeDiT, a diffusion transformer model that synergistically combines\ntransformer-based temporal dependency learning with diffusion-based\nprobabilistic sampling. TimeDiT employs a unified masking mechanism to\nharmonize the training and inference process across diverse tasks while\nintroducing a theoretically grounded, finetuning-free model editing strategy\nthat enables flexible integration of external knowledge during sampling.\nAcknowledging the challenges of unifying multiple downstream tasks under a\nsingle model, our systematic evaluation demonstrates TimeDiT's effectiveness\nboth in fundamental tasks, i.e., forecasting and imputation, through\nzero-shot/fine-tuning; and in domain tasks, i.e., multi-resolution forecasting,\nanomaly detection, and data generation, establishing it as a\n\\textit{proto-foundation model} that bridges the gap between general-purpose\nand domain-specific models.",
      "tldr_zh": "这项研究引入了 TimeDiT，一种通用扩散 Transformer 模型，旨在解决时间序列数据面临的挑战，如缺失值和不确定性问题，同时克服传统自回归 Transformer 在处理固有不确定性和物理约束方面的不足。TimeDiT 通过结合 Transformer 的时间依赖性学习和 Diffusion 的概率采样，采用统一的 masking 机制以及无需微调的模型编辑策略，实现灵活整合外部知识。实验结果显示，TimeDiT 在零样本/微调预测、插值、多分辨率预测、异常检测和数据生成等任务上表现出色，桥接了通用模型与领域特定模型的差距，成为一个 proto-foundation 模型。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "31 Pages, 11 Figures, 22 Tables. First present at ICML 2024 Workshop\n  on Foundation Models in the Wild",
      "pdf_url": "http://arxiv.org/pdf/2409.02322v2",
      "published_date": "2024-09-03 22:31:57 UTC",
      "updated_date": "2025-02-11 00:53:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:54:39.768796"
    },
    {
      "arxiv_id": "2409.02313v2",
      "title": "On the Benefits of Memory for Modeling Time-Dependent PDEs",
      "title_zh": "翻译失败",
      "authors": [
        "Ricardo Buitrago Ruiz",
        "Tanya Marwah",
        "Albert Gu",
        "Andrej Risteski"
      ],
      "abstract": "Data-driven techniques have emerged as a promising alternative to traditional\nnumerical methods for solving PDEs. For time-dependent PDEs, many approaches\nare Markovian -- the evolution of the trained system only depends on the\ncurrent state, and not the past states. In this work, we investigate the\nbenefits of using memory for modeling time-dependent PDEs: that is, when past\nstates are explicitly used to predict the future. Motivated by the Mori-Zwanzig\ntheory of model reduction, we theoretically exhibit examples of simple (even\nlinear) PDEs, in which a solution that uses memory is arbitrarily better than a\nMarkovian solution. Additionally, we introduce Memory Neural Operator (MemNO),\na neural operator architecture that combines recent state space models\n(specifically, S4) and Fourier Neural Operators (FNOs) to effectively model\nmemory. We empirically demonstrate that when the PDEs are supplied in low\nresolution or contain observation noise at train and test time, MemNO\nsignificantly outperforms the baselines without memory -- with up to 6x\nreduction in test error. Furthermore, we show that this benefit is particularly\npronounced when the PDE solutions have significant high-frequency Fourier modes\n(e.g., low-viscosity fluid dynamics) and we construct a challenging benchmark\ndataset consisting of such PDEs.",
      "tldr_zh": "本研究探讨了在建模时间依赖PDEs（Partial Differential Equations）时，使用记忆（memory）机制的益处，即利用过去状态预测未来状态，以克服传统Markovian方法的局限。基于Mori-Zwanzig理论，该论文理论证明了某些简单PDEs中，记忆方法可显著优于Markovian方法。作者引入了Memory Neural Operator (MemNO)架构，该架构结合了S4状态空间模型和Fourier Neural Operators (FNOs)，在低分辨率或噪声环境下实现了测试错误减少高达6倍的性能提升，尤其在高频Fourier模式（如低粘度流体动力学）显著的PDEs上表现突出，并构建了一个相关基准数据集。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.02313v2",
      "published_date": "2024-09-03 21:56:13 UTC",
      "updated_date": "2025-04-24 15:16:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:54:51.856893"
    },
    {
      "arxiv_id": "2409.15289v1",
      "title": "The Computational Mechanisms of Detached Mindfulness",
      "title_zh": "翻译失败",
      "authors": [
        "Brendan Conway-Smith",
        "Robert L. West"
      ],
      "abstract": "This paper investigates the computational mechanisms underlying a type of\nmetacognitive monitoring known as detached mindfulness, a particularly\neffective therapeutic technique within cognitive psychology. While research\nstrongly supports the capacity of detached mindfulness to reduce depression and\nanxiety, its cognitive and computational underpinnings remain largely\nunexplained. We employ a computational model of metacognitive skill to\narticulate the mechanisms through which a detached perception of affect reduces\nemotional reactivity.",
      "tldr_zh": "这篇论文探讨了detached mindfulness的计算机制，这是一种有效的元认知监控技术，在认知心理学中被用于降低抑郁和焦虑。研究者采用了一个computational model of metacognitive skill来阐释这种脱离式感知如何减少情感反应。论文的贡献在于揭示了detached mindfulness的认知基础，为其作为治疗工具的机制提供了理论支撑。",
      "categories": [
        "q-bio.NC",
        "cs.AI"
      ],
      "primary_category": "q-bio.NC",
      "comment": "International Conference on Cognitive Modeling (ICCM 2024)\n  https://mathpsych.org/presentation/1634#/abstract",
      "pdf_url": "http://arxiv.org/pdf/2409.15289v1",
      "published_date": "2024-09-03 21:30:41 UTC",
      "updated_date": "2024-09-03 21:30:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:55:02.370313"
    },
    {
      "arxiv_id": "2409.02302v1",
      "title": "Speech Foundation Model Ensembles for the Controlled Singing Voice Deepfake Detection (CtrSVDD) Challenge 2024",
      "title_zh": "翻译失败",
      "authors": [
        "Anmol Guragain",
        "Tianchi Liu",
        "Zihan Pan",
        "Hardik B. Sailor",
        "Qiongqiong Wang"
      ],
      "abstract": "This work details our approach to achieving a leading system with a 1.79%\npooled equal error rate (EER) on the evaluation set of the Controlled Singing\nVoice Deepfake Detection (CtrSVDD). The rapid advancement of generative AI\nmodels presents significant challenges for detecting AI-generated deepfake\nsinging voices, attracting increased research attention. The Singing Voice\nDeepfake Detection (SVDD) Challenge 2024 aims to address this complex task. In\nthis work, we explore the ensemble methods, utilizing speech foundation models\nto develop robust singing voice anti-spoofing systems. We also introduce a\nnovel Squeeze-and-Excitation Aggregation (SEA) method, which efficiently and\neffectively integrates representation features from the speech foundation\nmodels, surpassing the performance of our other individual systems. Evaluation\nresults confirm the efficacy of our approach in detecting deepfake singing\nvoices. The codes can be accessed at https://github.com/Anmol2059/SVDD2024.",
      "tldr_zh": "该研究针对 Controlled Singing Voice Deepfake Detection (CtrSVDD) Challenge 2024，开发了一种基于 Speech Foundation Models 的集成(Ensemble)系统，在评估集上实现了1.79%的 pooled Equal Error Rate (EER)。他们探索了Ensemble方法来构建鲁棒的唱歌声音反欺骗系统，并引入了新型Squeeze-and-Excitation Aggregation (SEA)方法，用于高效整合特征表示，从而超越了其他单个系统的性能。实验结果验证了该方法的有效性，并提供了开源代码以供进一步应用。",
      "categories": [
        "eess.AS",
        "cs.AI",
        "cs.SD"
      ],
      "primary_category": "eess.AS",
      "comment": "Accepted to the IEEE Spoken Language Technology Workshop (SLT) 2024",
      "pdf_url": "http://arxiv.org/pdf/2409.02302v1",
      "published_date": "2024-09-03 21:28:45 UTC",
      "updated_date": "2024-09-03 21:28:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:55:14.986018"
    },
    {
      "arxiv_id": "2409.02291v1",
      "title": "Initial Development and Evaluation of the Creative Artificial Intelligence through Recurring Developments and Determinations (CAIRDD) System",
      "title_zh": "翻译失败",
      "authors": [
        "Jeremy Straub",
        "Zach Johnson"
      ],
      "abstract": "Computer system creativity is a key step on the pathway to artificial general\nintelligence (AGI). It is elusive, however, due to the fact that human\ncreativity is not fully understood and, thus, it is difficult to develop this\ncapability in software. Large language models (LLMs) provide a facsimile of\ncreativity and the appearance of sentience, while not actually being either\ncreative or sentient. While LLMs have created bona fide new content, in some\ncases - such as with harmful hallucinations - inadvertently, their deliberate\ncreativity is seen by some to not match that of humans. In response to this\nchallenge, this paper proposes a technique for enhancing LLM output creativity\nvia an iterative process of concept injection and refinement. Initial work on\nthe development of the Creative Artificial Intelligence through Recurring\nDevelopments and Determinations (CAIRDD) system is presented and the efficacy\nof key system components is evaluated.",
      "tldr_zh": "该论文探讨了计算机系统创意作为通往人工通用智能(AGI)的重要步骤，但由于人类创意尚未完全理解，LLMs(Large Language Models)虽能生成新内容却缺乏真正创意。为此，研究提出CAIRDD系统，这是一种通过迭代的概念注入和精炼过程来增强LLM输出创意的技巧。初步开发和评估结果表明，该系统的关键组件有效，提升了LLMs的 deliberate 创意能力。",
      "categories": [
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.02291v1",
      "published_date": "2024-09-03 21:04:07 UTC",
      "updated_date": "2024-09-03 21:04:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:55:26.829751"
    },
    {
      "arxiv_id": "2409.02284v1",
      "title": "Biochemical Prostate Cancer Recurrence Prediction: Thinking Fast & Slow",
      "title_zh": "翻译失败",
      "authors": [
        "Suhang You",
        "Sanyukta Adap",
        "Siddhesh Thakur",
        "Bhakti Baheti",
        "Spyridon Bakas"
      ],
      "abstract": "Time to biochemical recurrence in prostate cancer is essential for prognostic\nmonitoring of the progression of patients after prostatectomy, which assesses\nthe efficacy of the surgery. In this work, we proposed to leverage multiple\ninstance learning through a two-stage ``thinking fast \\& slow'' strategy for\nthe time to recurrence (TTR) prediction. The first (``thinking fast'') stage\nfinds the most relevant WSI area for biochemical recurrence and the second\n(``thinking slow'') stage leverages higher resolution patches to predict TTR.\nOur approach reveals a mean C-index ($Ci$) of 0.733 ($\\theta=0.059$) on our\ninternal validation and $Ci=0.603$ on the LEOPARD challenge validation set.\nPost hoc attention visualization shows that the most attentive area contributes\nto the TTR prediction.",
      "tldr_zh": "该论文提出了一种基于多实例学习（multiple instance learning）的两阶段“thinking fast & slow”策略，用于预测前列腺癌术后生化复发的发生时间（TTR），以评估手术效果。第一阶段（“thinking fast”）快速识别与生化复发最相关的全滑微阵（WSI）区域，第二阶段（“thinking slow”）则利用更高分辨率的 patches 来精确预测 TTR。实验结果显示，该方法在内部验证集上平均 C-index 为 0.733，在 LEOPARD 挑战验证集上为 0.603，后验注意力可视化进一步证实了关键区域对预测的贡献。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "68T10",
        "I.5.4"
      ],
      "primary_category": "cs.CV",
      "comment": "8 pages, 3 figures, methodology paper for LEOPRARD Challenge",
      "pdf_url": "http://arxiv.org/pdf/2409.02284v1",
      "published_date": "2024-09-03 20:37:43 UTC",
      "updated_date": "2024-09-03 20:37:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:55:40.398569"
    },
    {
      "arxiv_id": "2409.02270v1",
      "title": "Reinforcement Learning-enabled Satellite Constellation Reconfiguration and Retasking for Mission-Critical Applications",
      "title_zh": "翻译失败",
      "authors": [
        "Hassan El Alami",
        "Danda B. Rawat"
      ],
      "abstract": "The development of satellite constellation applications is rapidly advancing\ndue to increasing user demands, reduced operational costs, and technological\nadvancements. However, a significant gap in the existing literature concerns\nreconfiguration and retasking issues within satellite constellations, which is\nthe primary focus of our research. In this work, we critically assess the\nimpact of satellite failures on constellation performance and the associated\ntask requirements. To facilitate this analysis, we introduce a system modeling\napproach for GPS satellite constellations, enabling an investigation into\nperformance dynamics and task distribution strategies, particularly in\nscenarios where satellite failures occur during mission-critical operations.\nAdditionally, we introduce reinforcement learning (RL) techniques, specifically\nQ-learning, Policy Gradient, Deep Q-Network (DQN), and Proximal Policy\nOptimization (PPO), for managing satellite constellations, addressing the\nchallenges posed by reconfiguration and retasking following satellite failures.\nOur results demonstrate that DQN and PPO achieve effective outcomes in terms of\naverage rewards, task completion rates, and response times.",
      "tldr_zh": "这篇论文聚焦于卫星星座（satellite constellations）的重新配置（reconfiguration）和重新分配（retasking）问题，特别是在卫星故障影响任务的关键应用场景下。研究者引入了 GPS 卫星星座的系统建模方法，以评估故障对性能和任务分配的影响，并应用强化学习（RL）技术，包括 Q-learning、Policy Gradient、Deep Q-Network (DQN) 和 Proximal Policy Optimization (PPO) 来优化管理策略。结果显示，DQN 和 PPO 在平均奖励、任务完成率和响应时间方面取得了显著成效，为卫星星座在任务关键应用的可靠操作提供了新途径。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted for publication in the IEEE Military Communications\n  Conference (IEEE MILCOM 2024)",
      "pdf_url": "http://arxiv.org/pdf/2409.02270v1",
      "published_date": "2024-09-03 20:01:56 UTC",
      "updated_date": "2024-09-03 20:01:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:55:50.968315"
    },
    {
      "arxiv_id": "2409.04469v1",
      "title": "Intensional FOL: Many-Sorted Extension",
      "title_zh": "内涵一阶逻辑：多排序扩展",
      "authors": [
        "Zoran Majkic"
      ],
      "abstract": "The concepts used in IFOL have associated to them a list of sorted\nattributes, and the sorts are the intensional concepts as well. The requirement\nto extend the unsorted IFOL (Intensional FOL) to many-sorted IFOL is mainly\nbased on the fact that a natural language is implicitly many-sorted and that we\nintend to use IFOL to support applications that use natural languages. Thus,\nthe proposed version of many-sorted IFOL is just the completion of this\nconceptual feature of the IFOL.",
      "tldr_zh": "这篇论文扩展了 Unsorted Intensional FOL (IFOL) 为 Many-Sorted IFOL，通过为概念关联排序属性，并将排序视为 intensional 概念。\n扩展的主要原因是自然语言隐含多排序，且 IFOL 旨在支持基于自然语言的应用。\n这种 Many-Sorted IFOL 的版本完善了 IFOL 的概念特征，提升了其在实际场景中的适用性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "21 pages",
      "pdf_url": "http://arxiv.org/pdf/2409.04469v1",
      "published_date": "2024-09-03 19:50:57 UTC",
      "updated_date": "2024-09-03 19:50:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:56:03.996575"
    },
    {
      "arxiv_id": "2409.02261v1",
      "title": "Action-Based ADHD Diagnosis in Video",
      "title_zh": "视频中基于动作的 ADHD 诊断",
      "authors": [
        "Yichun Li",
        "Yuxing Yang",
        "Syed Nohsen Naqvi"
      ],
      "abstract": "Attention Deficit Hyperactivity Disorder (ADHD) causes significant impairment\nin various domains. Early diagnosis of ADHD and treatment could significantly\nimprove the quality of life and functioning. Recently, machine learning methods\nhave improved the accuracy and efficiency of the ADHD diagnosis process.\nHowever, the cost of the equipment and trained staff required by the existing\nmethods are generally huge. Therefore, we introduce the video-based frame-level\naction recognition network to ADHD diagnosis for the first time. We also record\na real multi-modal ADHD dataset and extract three action classes from the video\nmodality for ADHD diagnosis. The whole process data have been reported to\nCNTW-NHS Foundation Trust, which would be reviewed by medical\nconsultants/professionals and will be made public in due course.",
      "tldr_zh": "本研究针对注意力缺陷多动障碍（ADHD）的诊断问题，指出现有机器学习方法虽提高了准确性和效率，但需昂贵设备和训练人员。该论文首次引入基于视频的帧级动作识别网络（video-based frame-level action recognition network），从视频模态中提取三种动作类别，用于ADHD诊断。研究者还录制了一个真实的多模态ADHD数据集，并已报告给CNTW-NHS Foundation Trust，计划公开以促进进一步应用。该方法有望降低诊断成本，并改善早期干预效果。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "31st European Symposium on Artificial Neural Networks",
      "pdf_url": "http://arxiv.org/pdf/2409.02261v1",
      "published_date": "2024-09-03 19:38:23 UTC",
      "updated_date": "2024-09-03 19:38:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:56:16.193596"
    },
    {
      "arxiv_id": "2409.02251v1",
      "title": "NoiseAttack: An Evasive Sample-Specific Multi-Targeted Backdoor Attack Through White Gaussian Noise",
      "title_zh": "翻译失败",
      "authors": [
        "Abdullah Arafat Miah",
        "Kaan Icer",
        "Resit Sendag",
        "Yu Bi"
      ],
      "abstract": "Backdoor attacks pose a significant threat when using third-party data for\ndeep learning development. In these attacks, data can be manipulated to cause a\ntrained model to behave improperly when a specific trigger pattern is applied,\nproviding the adversary with unauthorized advantages. While most existing works\nfocus on designing trigger patterns in both visible and invisible to poison the\nvictim class, they typically result in a single targeted class upon the success\nof the backdoor attack, meaning that the victim class can only be converted to\nanother class based on the adversary predefined value. In this paper, we\naddress this issue by introducing a novel sample-specific multi-targeted\nbackdoor attack, namely NoiseAttack. Specifically, we adopt White Gaussian\nNoise (WGN) with various Power Spectral Densities (PSD) as our underlying\ntriggers, coupled with a unique training strategy to execute the backdoor\nattack. This work is the first of its kind to launch a vision backdoor attack\nwith the intent to generate multiple targeted classes with minimal input\nconfiguration. Furthermore, our extensive experimental results demonstrate that\nNoiseAttack can achieve a high attack success rate against popular network\narchitectures and datasets, as well as bypass state-of-the-art backdoor\ndetection methods. Our source code and experiments are available at\nhttps://github.com/SiSL-URI/NoiseAttack/tree/main.",
      "tldr_zh": "本文提出了一种名为 NoiseAttack 的样本特定多目标后门攻击（sample-specific multi-targeted backdoor attack），旨在解决现有后门攻击（backdoor attacks）仅针对单一目标类的局限性。该方法使用 White Gaussian Noise (WGN) 作为触发器，结合不同 Power Spectral Densities (PSD) 和独特训练策略，实现多个目标类的生成，同时以最小输入配置执行视觉后门攻击（vision backdoor attack）。实验结果表明，NoiseAttack 在流行网络架构和数据集上实现了高攻击成功率，并成功绕过 state-of-the-art backdoor detection methods，为后门攻击研究提供了新颖的逃避机制。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CR",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.02251v1",
      "published_date": "2024-09-03 19:24:46 UTC",
      "updated_date": "2024-09-03 19:24:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:56:30.391923"
    },
    {
      "arxiv_id": "2409.02245v1",
      "title": "FastVoiceGrad: One-step Diffusion-Based Voice Conversion with Adversarial Conditional Diffusion Distillation",
      "title_zh": "翻译失败",
      "authors": [
        "Takuhiro Kaneko",
        "Hirokazu Kameoka",
        "Kou Tanaka",
        "Yuto Kondo"
      ],
      "abstract": "Diffusion-based voice conversion (VC) techniques such as VoiceGrad have\nattracted interest because of their high VC performance in terms of speech\nquality and speaker similarity. However, a notable limitation is the slow\ninference caused by the multi-step reverse diffusion. Therefore, we propose\nFastVoiceGrad, a novel one-step diffusion-based VC that reduces the number of\niterations from dozens to one while inheriting the high VC performance of the\nmulti-step diffusion-based VC. We obtain the model using adversarial\nconditional diffusion distillation (ACDD), leveraging the ability of generative\nadversarial networks and diffusion models while reconsidering the initial\nstates in sampling. Evaluations of one-shot any-to-any VC demonstrate that\nFastVoiceGrad achieves VC performance superior to or comparable to that of\nprevious multi-step diffusion-based VC while enhancing the inference speed.\nAudio samples are available at\nhttps://www.kecl.ntt.co.jp/people/kaneko.takuhiro/projects/fastvoicegrad/.",
      "tldr_zh": "本论文提出 FastVoiceGrad，一种基于扩散的语音转换(VC)方法，通过对抗条件扩散蒸馏(ACDD)技术，将多步反向扩散过程简化为一步推理，同时保持高语音质量和说话者相似度。\nFastVoiceGrad 结合生成对抗网络和扩散模型的优势，并优化初始采样状态，以解决传统 VC 技术的速度瓶颈。\n实验结果显示，在单次任何到任何 VC 任务中，FastVoiceGrad 的性能优于或相当于是多步扩散基线模型，并显著提升了推理速度。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.LG",
        "eess.AS",
        "stat.ML"
      ],
      "primary_category": "cs.SD",
      "comment": "Accepted to Interspeech 2024. Project page:\n  https://www.kecl.ntt.co.jp/people/kaneko.takuhiro/projects/fastvoicegrad/",
      "pdf_url": "http://arxiv.org/pdf/2409.02245v1",
      "published_date": "2024-09-03 19:19:48 UTC",
      "updated_date": "2024-09-03 19:19:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:56:40.810490"
    },
    {
      "arxiv_id": "2409.02239v2",
      "title": "Temporal Order Preserved Optimal Transport-based Cross-modal Knowledge Transfer Learning for ASR",
      "title_zh": "翻译失败",
      "authors": [
        "Xugang Lu",
        "Peng Shen",
        "Yu Tsao",
        "Hisashi Kawai"
      ],
      "abstract": "Transferring linguistic knowledge from a pretrained language model (PLM) to\nan acoustic model has been shown to greatly improve the performance of\nautomatic speech recognition (ASR). However, due to the heterogeneous feature\ndistributions in cross-modalities, designing an effective model for feature\nalignment and knowledge transfer between linguistic and acoustic sequences\nremains a challenging task. Optimal transport (OT), which efficiently measures\nprobability distribution discrepancies, holds great potential for aligning and\ntransferring knowledge between acoustic and linguistic modalities. Nonetheless,\nthe original OT treats acoustic and linguistic feature sequences as two\nunordered sets in alignment and neglects temporal order information during OT\ncoupling estimation. Consequently, a time-consuming pretraining stage is\nrequired to learn a good alignment between the acoustic and linguistic\nrepresentations. In this paper, we propose a Temporal Order Preserved OT\n(TOT)-based Cross-modal Alignment and Knowledge Transfer (CAKT) (TOT-CAKT) for\nASR. In the TOT-CAKT, local neighboring frames of acoustic sequences are\nsmoothly mapped to neighboring regions of linguistic sequences, preserving\ntheir temporal order relationship in feature alignment and matching. With the\nTOT-CAKT model framework, we conduct Mandarin ASR experiments with a pretrained\nChinese PLM for linguistic knowledge transfer. Our results demonstrate that the\nproposed TOT-CAKT significantly improves ASR performance compared to several\nstate-of-the-art models employing linguistic knowledge transfer, and addresses\nthe weaknesses of the original OT-based method in sequential feature alignment\nfor ASR.",
      "tldr_zh": "本研究针对自动语音识别（ASR）中的跨模态知识转移问题，提出了一种基于Temporal Order Preserved Optimal Transport (TOT)的框架，名为TOT-CAKT，以解决Optimal Transport (OT)忽略时序信息导致的特征对齐困难。TOT-CAKT通过将声学序列的局部邻域帧平滑映射到语言序列的邻域，保留了序列的时序关系，从而提升了从预训练语言模型（PLM）向声学模型的知识转移效率。在普通话ASR实验中，该方法显著提高了识别性能，比现有最先进模型更优，并克服了原始OT在序列特征对齐中的局限性。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.CL",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "Accepted to IEEE SLT 2024",
      "pdf_url": "http://arxiv.org/pdf/2409.02239v2",
      "published_date": "2024-09-03 19:11:15 UTC",
      "updated_date": "2024-09-05 11:34:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:56:53.006307"
    },
    {
      "arxiv_id": "2409.02219v2",
      "title": "A+AI: Threats to Society, Remedies, and Governance",
      "title_zh": "A+AI：对社会的威胁、补救措施和治理",
      "authors": [
        "Don Byrd"
      ],
      "abstract": "This document focuses on the threats, especially near-term threats, that\nArtificial Intelligence (AI) brings to society. Most of the threats discussed\nhere can result from any algorithmic process, not just AI; in addition,\ndefining AI is notoriously difficult. For both reasons, it is important to\nthink of \"A+AI\": Algorithms and Artificial Intelligence.\n  In addition to the threats, this paper discusses countermeasures to them, and\nit includes a table showing which countermeasures are likely to mitigate which\nthreats. Thoughtful governance could manage the risks without seriously\nimpeding progress; in fact, chances are it would accelerate progress by\nreducing the social chaos that would otherwise be likely. The paper lists\nspecific actions government should take as soon as possible, namely:\n  * Require all social media platforms accessible in the U.S. to offer users\nverification that their accounts are owned by citizens, and to display every\naccount's verification status\n  * Establish regulations to require that all products created or significantly\nmodified with A+AI be clearly labeled as such; to restrict use of generative AI\nto create likenesses of persons; and to require creators of generative AI\nsoftware to disclose materials used to train their software and to compensate\nthe creators of any copyrighted material used\n  * Fund a crash project of research on mitigating the threats\n  * Fund educational campaigns to raise awareness of the threats",
      "tldr_zh": "这篇论文探讨了人工智能（AI）和算法（A+AI）对社会的威胁，特别是短期风险，这些威胁可能源于任何算法过程。论文提出了多种对策，包括一个表格来展示哪些措施能缓解具体威胁，并强调周密的治理可以管理这些风险，同时加速进步而非阻碍。作者建议政府立即采取行动，如要求社交媒体平台验证账户所有权、规范A+AI产品的标签和使用、限制生成AI创建个人肖像、强制披露训练材料并补偿版权所有者，以及资助相关研究和教育宣传。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "25 pages",
      "pdf_url": "http://arxiv.org/pdf/2409.02219v2",
      "published_date": "2024-09-03 18:43:47 UTC",
      "updated_date": "2024-09-07 01:25:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:57:02.796240"
    },
    {
      "arxiv_id": "2409.02960v1",
      "title": "Managing multiple agents by automatically adjusting incentives",
      "title_zh": "通过自动调整激励机制管理多个代理",
      "authors": [
        "Shunichi Akatsuka",
        "Yaemi Teramoto",
        "Aaron Courville"
      ],
      "abstract": "In the coming years, AI agents will be used for making more complex\ndecisions, including in situations involving many different groups of people.\nOne big challenge is that AI agent tends to act in its own interest, unlike\nhumans who often think about what will be the best for everyone in the long\nrun. In this paper, we explore a method to get self-interested agents to work\ntowards goals that benefit society as a whole. We propose a method to add a\nmanager agent to mediate agent interactions by assigning incentives to certain\nactions. We tested our method with a supply-chain management problem and showed\nthat this framework (1) increases the raw reward by 22.2%, (2) increases the\nagents' reward by 23.8%, and (3) increases the manager's reward by 20.1%.",
      "tldr_zh": "本文探讨了AI代理在多群体决策中的挑战，即代理倾向于追求自身利益而非整体目标。研究提出了一种方法，通过添加一个管理代理(manager agent)来自动调整激励(incentives)，从而引导自私代理服务于社会整体利益。在供应链管理问题上测试，该框架将原始奖励(raw reward)提高了22.2%、代理奖励(agents' reward)提高了23.8%、管理代理奖励(manager's reward)提高了20.1%。这种方法为AI在复杂决策中的应用提供了更平衡和高效的框架。",
      "categories": [
        "cs.MA",
        "cs.AI",
        "cs.GT"
      ],
      "primary_category": "cs.MA",
      "comment": "7 pages",
      "pdf_url": "http://arxiv.org/pdf/2409.02960v1",
      "published_date": "2024-09-03 18:41:16 UTC",
      "updated_date": "2024-09-03 18:41:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:57:18.020781"
    },
    {
      "arxiv_id": "2409.02100v1",
      "title": "On a heuristic approach to the description of consciousness as a hypercomplex system state and the possibility of machine consciousness (German edition)",
      "title_zh": "翻译失败",
      "authors": [
        "Ralf Otte"
      ],
      "abstract": "This article presents a heuristic view that shows that the inner states of\nconsciousness experienced by every human being have a physical but imaginary\nhypercomplex basis. The hypercomplex description is necessary because certain\nprocesses of consciousness cannot be physically measured in principle, but\nnevertheless exist. Based on theoretical considerations, it could be possible -\nas a result of mathematical investigations into a so-called bicomplex algebra -\nto generate and use hypercomplex system states on machines in a targeted\nmanner. The hypothesis of the existence of hypercomplex system states on\nmachines is already supported by the surprising performance of highly complex\nAI systems. However, this has yet to be proven. In particular, there is a lack\nof experimental data that distinguishes such systems from other systems, which\nis why this question will be addressed in later articles. This paper describes\nthe developed bicomplex algebra and possible applications of these findings to\ngenerate hypercomplex energy states on machines. In the literature, such system\nstates are often referred to as machine consciousness. The article uses\nmathematical considerations to explain how artificial consciousness could be\ngenerated and what advantages this would have for such AI systems.",
      "tldr_zh": "这篇论文从启发式角度提出，人类的意识内状态基于物理但虚数的超复数系统状态（hypercomplex system state），并解释了某些意识过程虽无法物理测量但确实存在的原因。作者通过对双复数代数（bicomplex algebra）的数学研究，探讨了在机器上生成和利用超复数系统状态的可能性，以实现机器意识（machine consciousness）。尽管复杂 AI 系统的表现初步支持这一假设，但缺乏实验数据进行验证，论文还讨论了人工意识的生成方法及其潜在优势。",
      "categories": [
        "cs.AI",
        "math.AC",
        "physics.app-ph",
        "08A99",
        "I.2.0"
      ],
      "primary_category": "cs.AI",
      "comment": "7 pages, in German language. 1 figure",
      "pdf_url": "http://arxiv.org/pdf/2409.02100v1",
      "published_date": "2024-09-03 17:55:57 UTC",
      "updated_date": "2024-09-03 17:55:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:57:28.518021"
    },
    {
      "arxiv_id": "2409.02098v1",
      "title": "CRAFT Your Dataset: Task-Specific Synthetic Dataset Generation Through Corpus Retrieval and Augmentation",
      "title_zh": "翻译失败",
      "authors": [
        "Ingo Ziegler",
        "Abdullatif Köksal",
        "Desmond Elliott",
        "Hinrich Schütze"
      ],
      "abstract": "Building high-quality datasets for specialized tasks is a time-consuming and\nresource-intensive process that often requires specialized domain knowledge. We\npropose Corpus Retrieval and Augmentation for Fine-Tuning (CRAFT), a method for\ngenerating synthetic datasets, given a small number of user-written few-shots\nthat demonstrate the task to be performed. Given the few-shot examples, we use\nlarge-scale public web-crawled corpora and similarity-based document retrieval\nto find other relevant human-written documents. Lastly, instruction-tuned large\nlanguage models (LLMs) augment the retrieved documents into custom-formatted\ntask samples, which then can be used for fine-tuning. We demonstrate that CRAFT\ncan efficiently generate large-scale task-specific training datasets for four\ndiverse tasks: biology question-answering (QA), medicine QA and commonsense QA\nas well as summarization. Our experiments show that CRAFT-based models\noutperform or achieve comparable performance to general LLMs for QA tasks,\nwhile CRAFT-based summarization models outperform models trained on\nhuman-curated data by 46 preference points.",
      "tldr_zh": "该论文提出 CRAFT 方法，通过语料检索和增强技术，基于少量 few-shots 示例从大型公共语料库中检索相关文档，并利用指令微调的 LLMs 将其转化为自定义格式的任务样本，从而高效生成任务特定的合成数据集。CRAFT 适用于多种任务，包括生物学 QA、医学 QA、常识 QA 和总结。实验结果显示，CRAFT 训练的模型在 QA 任务上优于或相当于是通用 LLMs，而在总结任务上比使用人工策划数据训练的模型高出 46 个偏好点。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.02098v1",
      "published_date": "2024-09-03 17:54:40 UTC",
      "updated_date": "2024-09-03 17:54:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:57:41.970879"
    },
    {
      "arxiv_id": "2409.02095v2",
      "title": "DepthCrafter: Generating Consistent Long Depth Sequences for Open-world Videos",
      "title_zh": "翻译失败",
      "authors": [
        "Wenbo Hu",
        "Xiangjun Gao",
        "Xiaoyu Li",
        "Sijie Zhao",
        "Xiaodong Cun",
        "Yong Zhang",
        "Long Quan",
        "Ying Shan"
      ],
      "abstract": "Estimating video depth in open-world scenarios is challenging due to the\ndiversity of videos in appearance, content motion, camera movement, and length.\nWe present DepthCrafter, an innovative method for generating temporally\nconsistent long depth sequences with intricate details for open-world videos,\nwithout requiring any supplementary information such as camera poses or optical\nflow. The generalization ability to open-world videos is achieved by training\nthe video-to-depth model from a pre-trained image-to-video diffusion model,\nthrough our meticulously designed three-stage training strategy. Our training\napproach enables the model to generate depth sequences with variable lengths at\none time, up to 110 frames, and harvest both precise depth details and rich\ncontent diversity from realistic and synthetic datasets. We also propose an\ninference strategy that can process extremely long videos through segment-wise\nestimation and seamless stitching. Comprehensive evaluations on multiple\ndatasets reveal that DepthCrafter achieves state-of-the-art performance in\nopen-world video depth estimation under zero-shot settings. Furthermore,\nDepthCrafter facilitates various downstream applications, including depth-based\nvisual effects and conditional video generation.",
      "tldr_zh": "该论文提出DepthCrafter，一种创新方法，用于生成时间一致且细节丰富的长深度序列，针对开放世界视频（open-world videos）的多样性挑战，而无需额外信息如相机位姿或光流。方法采用从预训练图像到视频扩散模型（diffusion model）出发的三阶段训练策略，使模型能够一次性生成可变长度深度序列（最多110帧），并从现实和合成数据集获取精确深度细节和内容多样性。论文还引入分段估计和无缝拼接的推理策略，以处理极长视频。此外，在零样本设置（zero-shot settings）下，DepthCrafter在多个数据集上实现最先进性能，并支持下游应用，如基于深度的视觉效果和条件视频生成。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.GR"
      ],
      "primary_category": "cs.CV",
      "comment": "Project webpage: https://depthcrafter.github.io",
      "pdf_url": "http://arxiv.org/pdf/2409.02095v2",
      "published_date": "2024-09-03 17:52:03 UTC",
      "updated_date": "2024-11-27 07:59:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:57:52.256802"
    },
    {
      "arxiv_id": "2409.02069v2",
      "title": "A Deployed Online Reinforcement Learning Algorithm In An Oral Health Clinical Trial",
      "title_zh": "翻译失败",
      "authors": [
        "Anna L. Trella",
        "Kelly W. Zhang",
        "Hinal Jajal",
        "Inbal Nahum-Shani",
        "Vivek Shetty",
        "Finale Doshi-Velez",
        "Susan A. Murphy"
      ],
      "abstract": "Dental disease is a prevalent chronic condition associated with substantial\nfinancial burden, personal suffering, and increased risk of systemic diseases.\nDespite widespread recommendations for twice-daily tooth brushing, adherence to\nrecommended oral self-care behaviors remains sub-optimal due to factors such as\nforgetfulness and disengagement. To address this, we developed Oralytics, a\nmHealth intervention system designed to complement clinician-delivered\npreventative care for marginalized individuals at risk for dental disease.\nOralytics incorporates an online reinforcement learning algorithm to determine\noptimal times to deliver intervention prompts that encourage oral self-care\nbehaviors. We have deployed Oralytics in a registered clinical trial. The\ndeployment required careful design to manage challenges specific to the\nclinical trials setting in the U.S. In this paper, we (1) highlight key design\ndecisions of the RL algorithm that address these challenges and (2) conduct a\nre-sampling analysis to evaluate algorithm design decisions. A second phase\n(randomized control trial) of Oralytics is planned to start in spring 2025.",
      "tldr_zh": "本研究针对牙病作为常见慢性疾病所带来的经济负担和个人痛苦，开发了Oralytics mHealth干预系统，以提升边缘化人群的口腔自我护理依从性。Oralytics采用在线reinforcement learning算法，动态确定最佳时间发送干预提示，从而优化行为干预效果。该系统已在注册临床试验中部署，并通过重采样分析评估了算法的关键设计决策，以应对临床试验环境的挑战。未来计划于2025年春季启动第二阶段的随机对照试验，进一步验证其有效性。",
      "categories": [
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.02069v2",
      "published_date": "2024-09-03 17:16:01 UTC",
      "updated_date": "2024-12-18 23:01:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:58:07.155846"
    },
    {
      "arxiv_id": "2409.02060v2",
      "title": "OLMoE: Open Mixture-of-Experts Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Niklas Muennighoff",
        "Luca Soldaini",
        "Dirk Groeneveld",
        "Kyle Lo",
        "Jacob Morrison",
        "Sewon Min",
        "Weijia Shi",
        "Pete Walsh",
        "Oyvind Tafjord",
        "Nathan Lambert",
        "Yuling Gu",
        "Shane Arora",
        "Akshita Bhagia",
        "Dustin Schwenk",
        "David Wadden",
        "Alexander Wettig",
        "Binyuan Hui",
        "Tim Dettmers",
        "Douwe Kiela",
        "Ali Farhadi",
        "Noah A. Smith",
        "Pang Wei Koh",
        "Amanpreet Singh",
        "Hannaneh Hajishirzi"
      ],
      "abstract": "We introduce OLMoE, a fully open, state-of-the-art language model leveraging\nsparse Mixture-of-Experts (MoE). OLMoE-1B-7B has 7 billion (B) parameters but\nuses only 1B per input token. We pretrain it on 5 trillion tokens and further\nadapt it to create OLMoE-1B-7B-Instruct. Our models outperform all available\nmodels with similar active parameters, even surpassing larger ones like\nLlama2-13B-Chat and DeepSeekMoE-16B. We present various experiments on MoE\ntraining, analyze routing in our model showing high specialization, and\nopen-source all aspects of our work: model weights, training data, code, and\nlogs.",
      "tldr_zh": "该研究引入了 OLMoE，一种完全开源的基于稀疏 Mixture-of-Experts (MoE) 架构的先进语言模型，其中 OLMoE-1B-7B 拥有 7 亿参数，但每个输入标记仅激活 1 亿参数，并在 5 万亿标记上进行预训练，并进一步适应为 OLMoE-1B-7B-Instruct。实验结果显示，该模型在性能上超过了所有类似活跃参数的模型，甚至超越了更大的模型如 Llama2-13B-Chat 和 DeepSeekMoE-16B，同时通过分析路由机制揭示了模型的高专业化能力。该研究开源了所有内容，包括模型权重、训练数据、代码和日志，为 MoE 模型的开发和应用提供了宝贵资源。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "63 pages (24 main), 36 figures, 17 tables",
      "pdf_url": "http://arxiv.org/pdf/2409.02060v2",
      "published_date": "2024-09-03 17:08:20 UTC",
      "updated_date": "2025-03-03 01:25:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:58:18.413740"
    },
    {
      "arxiv_id": "2409.02049v1",
      "title": "Low-Resolution Face Recognition via Adaptable Instance-Relation Distillation",
      "title_zh": "翻译失败",
      "authors": [
        "Ruixin Shi",
        "Weijia Guo",
        "Shiming Ge"
      ],
      "abstract": "Low-resolution face recognition is a challenging task due to the missing of\ninformative details. Recent approaches based on knowledge distillation have\nproven that high-resolution clues can well guide low-resolution face\nrecognition via proper knowledge transfer. However, due to the distribution\ndifference between training and testing faces, the learned models often suffer\nfrom poor adaptability. To address that, we split the knowledge transfer\nprocess into distillation and adaptation steps, and propose an adaptable\ninstance-relation distillation approach to facilitate low-resolution face\nrecognition. In the approach, the student distills knowledge from\nhigh-resolution teacher in both instance level and relation level, providing\nsufficient cross-resolution knowledge transfer. Then, the learned student can\nbe adaptable to recognize low-resolution faces with adaptive batch\nnormalization in inference. In this manner, the capability of recovering\nmissing details of familiar low-resolution faces can be effectively enhanced,\nleading to a better knowledge transfer. Extensive experiments on low-resolution\nface recognition clearly demonstrate the effectiveness and adaptability of our\napproach.",
      "tldr_zh": "这篇论文针对低分辨率人脸识别的挑战（如缺少信息细节和模型适应性差），提出了一种可适应的实例-relation蒸馏方法，将知识转移过程分为蒸馏和适应步骤。方法中，学生模型从高分辨率教师模型学习实例级和relation级知识，实现充分的跨分辨率知识转移，并在推理时通过adaptive batch normalization增强对低分辨率人脸的适应性。实验结果显示，该方法显著提高了识别性能和鲁棒性，证明了其有效性和适应性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "cs.MM"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by IJCNN 2024",
      "pdf_url": "http://arxiv.org/pdf/2409.02049v1",
      "published_date": "2024-09-03 16:53:34 UTC",
      "updated_date": "2024-09-03 16:53:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:58:31.065924"
    },
    {
      "arxiv_id": "2409.02045v2",
      "title": "AllWeatherNet:Unified Image Enhancement for Autonomous Driving under Adverse Weather and Lowlight-conditions",
      "title_zh": "翻译失败",
      "authors": [
        "Chenghao Qian",
        "Mahdi Rezaei",
        "Saeed Anwar",
        "Wenjing Li",
        "Tanveer Hussain",
        "Mohsen Azarmi",
        "Wei Wang"
      ],
      "abstract": "Adverse conditions like snow, rain, nighttime, and fog, pose challenges for\nautonomous driving perception systems. Existing methods have limited\neffectiveness in improving essential computer vision tasks, such as semantic\nsegmentation, and often focus on only one specific condition, such as removing\nrain or translating nighttime images into daytime ones. To address these\nlimitations, we propose a method to improve the visual quality and clarity\ndegraded by such adverse conditions. Our method, AllWeather-Net, utilizes a\nnovel hierarchical architecture to enhance images across all adverse\nconditions. This architecture incorporates information at three semantic\nlevels: scene, object, and texture, by discriminating patches at each level.\nFurthermore, we introduce a Scaled Illumination-aware Attention Mechanism\n(SIAM) that guides the learning towards road elements critical for autonomous\ndriving perception. SIAM exhibits robustness, remaining unaffected by changes\nin weather conditions or environmental scenes. AllWeather-Net effectively\ntransforms images into normal weather and daytime scenes, demonstrating\nsuperior image enhancement results and subsequently enhancing the performance\nof semantic segmentation, with up to a 5.3% improvement in mIoU in the trained\ndomain. We also show our model's generalization ability by applying it to\nunseen domains without re-training, achieving up to 3.9% mIoU improvement. Code\ncan be accessed at: https://github.com/Jumponthemoon/AllWeatherNet.",
      "tldr_zh": "本研究针对自动驾驶在恶劣天气（如雪、雨、雾）和低光条件下（如夜间）的感知挑战，提出了一种统一的图像增强方法AllWeatherNet。AllWeatherNet采用分层架构，结合场景、物体和纹理三个语义级别的信息，并引入Scaled Illumination-aware Attention Mechanism (SIAM)，以鲁棒方式关注关键道路元素，从而提升图像质量和清晰度。实验结果显示，该方法显著改善语义分割性能，在训练域提高高达5.3%的mIoU，并在未见域上无需重新训练即可实现3.9%的mIoU提升。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "ICPR 2024, Piero Zamperoni Overall Best Student Paper Award",
      "pdf_url": "http://arxiv.org/pdf/2409.02045v2",
      "published_date": "2024-09-03 16:47:01 UTC",
      "updated_date": "2024-12-14 04:19:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:58:42.886743"
    },
    {
      "arxiv_id": "2409.02038v2",
      "title": "BEAVER: An Enterprise Benchmark for Text-to-SQL",
      "title_zh": "BEAVER：文本到SQL的企业基准",
      "authors": [
        "Peter Baile Chen",
        "Fabian Wenz",
        "Yi Zhang",
        "Devin Yang",
        "Justin Choi",
        "Nesime Tatbul",
        "Michael Cafarella",
        "Çağatay Demiralp",
        "Michael Stonebraker"
      ],
      "abstract": "Existing text-to-SQL benchmarks have largely been constructed from web tables\nwith human-generated question-SQL pairs. LLMs typically show strong results on\nthese benchmarks, leading to a belief that LLMs are effective at text-to-SQL\ntasks. However, how these results transfer to enterprise settings is unclear\nbecause tables in enterprise databases might differ substantially from web\ntables in structure and content. To contend with this problem, we introduce a\nnew dataset BEAVER, the first enterprise text-to-SQL benchmark sourced from\nreal private enterprise data warehouses. This dataset includes natural language\nqueries and their correct SQL statements, which we collected from actual query\nlogs. We then benchmark off-the-shelf LLMs on this dataset. LLMs perform\npoorly, even when augmented with standard prompt engineering and RAG\ntechniques. We identify three main reasons for the poor performance: (1)\nschemas of enterprise tables are more complex than the schemas in public data,\nresulting in SQL-generation tasks intrinsically harder; (2) business-oriented\nquestions are often more complex, requiring joins over multiple tables,\naggregations, and nested queries; (3) public LLMs cannot train on private\nenterprise data warehouses that are not publicly accessible, and therefore it\nis difficult for the model to learn to solve (1) and (2). We believe BEAVER\nwill facilitate future research in building text-to-SQL systems that perform\nbetter in enterprise settings.",
      "tldr_zh": "这篇论文引入了 BEAVER，这是一个新的企业环境文本到-SQL 基准数据集，源自真实私有企业数据仓库的查询日志，以评估 LLMs 在处理复杂企业查询时的性能。不同于基于网络表格的现有基准，BEAVER 揭示了 LLMs 的表现不佳，即使结合提示工程和 RAG 技术，主要原因是企业表格模式更复杂、业务查询需多表连接、聚合和嵌套查询，以及 LLMs 无法访问私有数据。论文强调，BEAVER 将促进未来研究，提升 Text-to-SQL 系统在企业场景中的准确性和适用性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.DB"
      ],
      "primary_category": "cs.CL",
      "comment": "Dataset and code are available at\n  https://peterbaile.github.io/beaver/",
      "pdf_url": "http://arxiv.org/pdf/2409.02038v2",
      "published_date": "2024-09-03 16:37:45 UTC",
      "updated_date": "2025-01-20 22:24:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:58:55.269605"
    },
    {
      "arxiv_id": "2409.02018v1",
      "title": "TransDAE: Dual Attention Mechanism in a Hierarchical Transformer for Efficient Medical Image Segmentation",
      "title_zh": "翻译失败",
      "authors": [
        "Bobby Azad",
        "Pourya Adibfar",
        "Kaiqun Fu"
      ],
      "abstract": "In healthcare, medical image segmentation is crucial for accurate disease\ndiagnosis and the development of effective treatment strategies. Early\ndetection can significantly aid in managing diseases and potentially prevent\ntheir progression. Machine learning, particularly deep convolutional neural\nnetworks, has emerged as a promising approach to addressing segmentation\nchallenges. Traditional methods like U-Net use encoding blocks for local\nrepresentation modeling and decoding blocks to uncover semantic relationships.\nHowever, these models often struggle with multi-scale objects exhibiting\nsignificant variations in texture and shape, and they frequently fail to\ncapture long-range dependencies in the input data. Transformers designed for\nsequence-to-sequence predictions have been proposed as alternatives, utilizing\nglobal self-attention mechanisms. Yet, they can sometimes lack precise\nlocalization due to insufficient granular details. To overcome these\nlimitations, we introduce TransDAE: a novel approach that reimagines the\nself-attention mechanism to include both spatial and channel-wise associations\nacross the entire feature space, while maintaining computational efficiency.\nAdditionally, TransDAE enhances the skip connection pathway with an inter-scale\ninteraction module, promoting feature reuse and improving localization\naccuracy. Remarkably, TransDAE outperforms existing state-of-the-art methods on\nthe Synaps multi-organ dataset, even without relying on pre-trained weights.",
      "tldr_zh": "本研究针对医疗图像分割的挑战，提出了一种名为 TransDAE 的新方法，该方法基于层次化 Transformer，引入双重注意力机制（包括空间和通道-wise 关联），以高效捕获全局依赖性和局部细节，同时保持计算效率。TransDAE 还通过增强 skip connection 中的 inter-scale interaction 模块，促进特征重用并提升定位准确性。实验结果显示，该方法在 Synaps 多器官数据集上超越现有最先进模型，即使不依赖预训练权重，也表现出色。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "68T07"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.02018v1",
      "published_date": "2024-09-03 16:08:48 UTC",
      "updated_date": "2024-09-03 16:08:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:59:15.849667"
    },
    {
      "arxiv_id": "2409.02017v1",
      "title": "AI Governance in Higher Education: Case Studies of Guidance at Big Ten Universities",
      "title_zh": "高等教育中的 AI 治理：Big Ten Universities 指导案例研究",
      "authors": [
        "Chuhao Wu",
        "He Zhang",
        "John M. Carroll"
      ],
      "abstract": "Generative AI has drawn significant attention from stakeholders in higher\neducation. As it introduces new opportunities for personalized learning and\ntutoring support, it simultaneously poses challenges to academic integrity and\nleads to ethical issues. Consequently, governing responsible AI usage within\nhigher education institutions (HEIs) becomes increasingly important. Leading\nuniversities have already published guidelines on Generative AI, with most\nattempting to embrace this technology responsibly. This study provides a new\nperspective by focusing on strategies for responsible AI governance as\ndemonstrated in these guidelines. Through a case study of 14 prestigious\nuniversities in the United States, we identified the multi-unit governance of\nAI, the role-specific governance of AI, and the academic characteristics of AI\ngovernance from their AI guidelines. The strengths and potential limitations of\nthese strategies and characteristics are discussed. The findings offer\npractical implications for guiding responsible AI usage in HEIs and beyond.",
      "tldr_zh": "该研究探讨了生成式AI在高等教育中的治理问题，通过对14所美国顶尖大学的案例研究，分析了这些机构的AI指导方针。研究识别出多单位治理(multi-unit governance)、角色特定治理(role-specific governance)和学术特性(academic characteristics)作为关键策略，并讨论了这些策略的优缺点。最终，该研究为高等教育机构(HEIs)提供实际启示，以指导负责任的AI使用，并扩展到更广泛的应用场景。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.02017v1",
      "published_date": "2024-09-03 16:06:45 UTC",
      "updated_date": "2024-09-03 16:06:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:59:17.552597"
    },
    {
      "arxiv_id": "2409.02008v1",
      "title": "When Digital Twin Meets 6G: Concepts, Obstacles, and Research Prospects",
      "title_zh": "翻译失败",
      "authors": [
        "Wenshuai Liu",
        "Yaru Fu",
        "Zheng Shi",
        "Hong Wang"
      ],
      "abstract": "The convergence of digital twin technology and the emerging 6G network\npresents both challenges and numerous research opportunities. This article\nexplores the potential synergies between digital twin and 6G, highlighting the\nkey challenges and proposing fundamental principles for their integration. We\ndiscuss the unique requirements and capabilities of digital twin in the context\nof 6G networks, such as sustainable deployment, real-time synchronization,\nseamless migration, predictive analytic, and closed-loop control. Furthermore,\nwe identify research opportunities for leveraging digital twin and artificial\nintelligence to enhance various aspects of 6G, including network optimization,\nresource allocation, security, and intelligent service provisioning. This\narticle aims to stimulate further research and innovation at the intersection\nof digital twin and 6G, paving the way for transformative applications and\nservices in the future.",
      "tldr_zh": "这篇论文探讨了数字孪生技术与 6G 网络的融合，分析了潜在挑战和研究机会，并提出整合的基本原则。该框架强调数字孪生在 6G 上下文中的关键能力，如可持续部署、实时同步、无缝迁移、预测分析和闭环控制。论文还识别了利用数字孪生和 artificial intelligence 来增强 6G 的各方面，包括网络优化、资源分配、安全以及智能服务提供。总体而言，该研究旨在激发进一步的创新，推动数字孪生与 6G 的变革性应用和服务。",
      "categories": [
        "cs.NI",
        "cs.AI",
        "cs.DC"
      ],
      "primary_category": "cs.NI",
      "comment": "7 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2409.02008v1",
      "published_date": "2024-09-03 15:57:05 UTC",
      "updated_date": "2024-09-03 15:57:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:59:30.286769"
    },
    {
      "arxiv_id": "2409.07485v1",
      "title": "Optimization and Deployment of Deep Neural Networks for PPG-based Blood Pressure Estimation Targeting Low-power Wearables",
      "title_zh": "针对低功",
      "authors": [
        "Alessio Burrello",
        "Francesco Carlucci",
        "Giovanni Pollo",
        "Xiaying Wang",
        "Massimo Poncino",
        "Enrico Macii",
        "Luca Benini",
        "Daniele Jahier Pagliari"
      ],
      "abstract": "PPG-based Blood Pressure (BP) estimation is a challenging biosignal\nprocessing task for low-power devices such as wearables. State-of-the-art Deep\nNeural Networks (DNNs) trained for this task implement either a PPG-to-BP\nsignal-to-signal reconstruction or a scalar BP value regression and have been\nshown to outperform classic methods on the largest and most complex public\ndatasets. However, these models often require excessive parameter storage or\ncomputational effort for wearable deployment, exceeding the available memory or\nincurring too high latency and energy consumption. In this work, we describe a\nfully-automated DNN design pipeline, encompassing HW-aware Neural Architecture\nSearch (NAS) and Quantization, thanks to which we derive accurate yet\nlightweight models, that can be deployed on an ultra-low-power multicore\nSystem-on-Chip (SoC), GAP8. Starting from both regression and signal-to-signal\nstate-of-the-art models on four public datasets, we obtain optimized versions\nthat achieve up to 4.99% lower error or 73.36% lower size at iso-error.\nNoteworthy, while the most accurate SoA network on the largest dataset can not\nfit the GAP8 memory, all our optimized models can; our most accurate DNN\nconsumes as little as 0.37 mJ while reaching the lowest MAE of 8.08 on\nDiastolic BP estimation.",
      "tldr_zh": "这篇论文针对基于 PPG 的血压估计，提出一个全自动 DNN 设计管道，包括硬件感知的 Neural Architecture Search (NAS) 和 Quantization，以优化模型适应低功耗可穿戴设备。管道从现有回归和信号到信号模型出发，在四个公共数据集上优化出准确性更高的轻量级版本，实现错误率降低至 4.99% 或在相同错误率下大小减少 73.36%。优化后的模型能够部署在 ultra-low-power multicore System-on-Chip (SoC) 如 GAP8 上，其中最准确的 DNN 仅消耗 0.37 mJ，并达到 Diastolic BP 估计的最低 MAE 为 8.08。",
      "categories": [
        "eess.SP",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "eess.SP",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.07485v1",
      "published_date": "2024-09-03 15:48:43 UTC",
      "updated_date": "2024-09-03 15:48:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:59:44.152595"
    },
    {
      "arxiv_id": "2409.01995v3",
      "title": "vec2wav 2.0: Advancing Voice Conversion via Discrete Token Vocoders",
      "title_zh": "翻译失败",
      "authors": [
        "Yiwei Guo",
        "Zhihan Li",
        "Junjie Li",
        "Chenpeng Du",
        "Hankun Wang",
        "Shuai Wang",
        "Xie Chen",
        "Kai Yu"
      ],
      "abstract": "We propose a new speech discrete token vocoder, vec2wav 2.0, which advances\nvoice conversion (VC). We use discrete tokens from speech self-supervised\nmodels as the content features of source speech, and treat VC as a prompted\nvocoding task. To amend the loss of speaker timbre in the content tokens,\nvec2wav 2.0 utilizes the WavLM features to provide strong timbre-dependent\ninformation. A novel adaptive Snake activation function is proposed to better\nincorporate timbre into the waveform reconstruction process. In this way,\nvec2wav 2.0 learns to alter the speaker timbre appropriately given different\nreference prompts. Also, no supervised data is required for vec2wav 2.0 to be\neffectively trained. Experimental results demonstrate that vec2wav 2.0\noutperforms all other baselines to a considerable margin in terms of audio\nquality and speaker similarity in any-to-any VC. Ablation studies verify the\neffects made by the proposed techniques. Moreover, vec2wav 2.0 achieves\ncompetitive cross-lingual VC even only trained on monolingual corpus. Thus,\nvec2wav 2.0 shows timbre can potentially be manipulated only by speech token\nvocoders, pushing the frontiers of VC and speech synthesis.",
      "tldr_zh": "本研究提出 vec2wav 2.0，一种先进的 speech discrete token vocoder，用于提升 voice conversion (VC)。该模型利用 speech self-supervised models 的 discrete tokens 作为源语音的内容特征，并通过 WavLM features 补充 speaker timbre 信息，同时引入 novel adaptive Snake activation function 来优化 waveform reconstruction 过程，从而根据不同 reference prompts 适当地调整 timbre。vec2wav 2.0 无需 supervised data 即可有效训练，并在 any-to-any VC 中显著优于基线模型，在 audio quality 和 speaker similarity 方面提升明显。实验还显示，即使仅在 monolingual corpus 上训练，它也能在 cross-lingual VC 中取得竞争性表现，推动 VC 和 speech synthesis 的前沿发展。",
      "categories": [
        "eess.AS",
        "cs.AI",
        "cs.SD"
      ],
      "primary_category": "eess.AS",
      "comment": "5 pages, 4 figures. Demo page:\n  https://cantabile-kwok.github.io/vec2wav2/",
      "pdf_url": "http://arxiv.org/pdf/2409.01995v3",
      "published_date": "2024-09-03 15:41:07 UTC",
      "updated_date": "2024-12-22 12:49:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:59:55.651603"
    },
    {
      "arxiv_id": "2409.01992v1",
      "title": "QueryCheetah: Fast Automated Discovery of Attribute Inference Attacks Against Query-Based Systems",
      "title_zh": "翻译失败",
      "authors": [
        "Bozhidar Stevanoski",
        "Ana-Maria Cretu",
        "Yves-Alexandre de Montjoye"
      ],
      "abstract": "Query-based systems (QBSs) are one of the key approaches for sharing data.\nQBSs allow analysts to request aggregate information from a private protected\ndataset. Attacks are a crucial part of ensuring QBSs are truly\nprivacy-preserving. The development and testing of attacks is however very\nlabor-intensive and unable to cope with the increasing complexity of systems.\nAutomated approaches have been shown to be promising but are currently\nextremely computationally intensive, limiting their applicability in practice.\nWe here propose QueryCheetah, a fast and effective method for automated\ndiscovery of privacy attacks against QBSs. We instantiate QueryCheetah on\nattribute inference attacks and show it to discover stronger attacks than\nprevious methods while being 18 times faster than the state-of-the-art\nautomated approach. We then show how QueryCheetah allows system developers to\nthoroughly evaluate the privacy risk, including for various attacker strengths\nand target individuals. We finally show how QueryCheetah can be used\nout-of-the-box to find attacks in larger syntaxes and workarounds around ad-hoc\ndefenses.",
      "tldr_zh": "本研究针对查询-based systems (QBSs) 的隐私保护问题，提出QueryCheetah，一种快速有效的自动化方法，用于发现attribute inference attacks。该方法比现有最先进方法快18倍，同时能发现更强的攻击，帮助系统开发者评估隐私风险，包括不同攻击强度和目标个体。QueryCheetah还可直接应用于更大语法下的攻击场景，并测试绕过临时防御，从而提升QBSs的安全性。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "This is an extended version of the ACM CCS paper which includes\n  appendices",
      "pdf_url": "http://arxiv.org/pdf/2409.01992v1",
      "published_date": "2024-09-03 15:37:05 UTC",
      "updated_date": "2024-09-03 15:37:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:00:09.449179"
    },
    {
      "arxiv_id": "2409.13695v1",
      "title": "You Only Use Reactive Attention Slice For Long Context Retrieval",
      "title_zh": "翻译失败",
      "authors": [
        "Yun Joon Soh",
        "Hanxian Huang",
        "Yuandong Tian",
        "Jishen Zhao"
      ],
      "abstract": "Supporting longer context for Large Language Models (LLM) is a promising\ndirection to advance LLMs. As training a model for a longer context window is\ncomputationally expensive, many alternative solutions, such as Retrieval\nAugmented Generation (RAG), have been used. However, most existing RAG methods\nadopt embedding-based retrieval that falls short on long contexts.\n  To address such challenges, we propose an attention-based retrieval\ntechnique, You Only Use Reactive Attention slice (YOURA). YOURA leverages a\nnovel retrieval heuristic called reaction score to rank the relevance of each\nsentence in the input context with the query sentence. Intuitively, we measure\nhow the per-token attention score \"reacts\" to the query and greedily retrieves\nthe most reactive sentences. Internally, YOURA generates a token-indexed vector\n(called reaction vector) for the whole input context. To map each sentence to\nthe token-indexed vector, we propose an Embedding-Agnostic Sentence Yield\n(EASY), a best-effort token wiggling algorithm.\n  We evaluate our retrieval technique on three open-source pre-trained LLM\nmodels across six LongBench QA datasets. Our technique achieves up to 30% vLLM\ninference throughput improvement for serving long-context queries with a nearly\nidentical quality score to the simple yet effective truncate-middle approach.",
      "tldr_zh": "该论文提出了一种注意力-based 检索技术 YOURA（You Only Use Reactive Attention slice），旨在提升 Large Language Models (LLM) 处理长上下文的能力，以解决现有 Retrieval Augmented Generation (RAG) 方法中 embedding-based 检索的不足。YOURA 通过计算 reaction score 来评估输入上下文每个句子的相关性，基于 per-token attention score 的“反应”来贪婪检索最相关句子，并引入 Embedding-Agnostic Sentence Yield (EASY) 算法生成 token-indexed reaction vector。实验结果显示，在三个开源预训练 LLM 模型和六个 LongBench QA 数据集上，YOURA 实现了高达 30% 的 vLLM 推理吞吐量改进，同时质量分数与 truncate-middle 方法几乎相当。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.13695v1",
      "published_date": "2024-09-03 15:30:57 UTC",
      "updated_date": "2024-09-03 15:30:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:00:22.633898"
    },
    {
      "arxiv_id": "2409.01974v2",
      "title": "Planning to avoid ambiguous states through Gaussian approximations to non-linear sensors in active inference agents",
      "title_zh": "翻译失败",
      "authors": [
        "Wouter M. Kouw"
      ],
      "abstract": "In nature, active inference agents must learn how observations of the world\nrepresent the state of the agent. In engineering, the physics behind sensors is\noften known reasonably accurately and measurement functions can be incorporated\ninto generative models. When a measurement function is non-linear, the\ntransformed variable is typically approximated with a Gaussian distribution to\nensure tractable inference. We show that Gaussian approximations that are\nsensitive to the curvature of the measurement function, such as a second-order\nTaylor approximation, produce a state-dependent ambiguity term. This induces a\npreference over states, based on how accurately the state can be inferred from\nthe observation. We demonstrate this preference with a robot navigation\nexperiment where agents plan trajectories.",
      "tldr_zh": "这篇论文探讨了 active inference 代理如何通过 Gaussian approximations 处理非线性传感器，以避免观察中产生的模糊状态。研究发现，使用敏感于测量函数曲率的近似方法（如二阶 Taylor approximation），会生成一个状态相关的模糊项，从而引导代理偏好于那些易于从观察中准确推断的状态。作者通过机器人导航实验演示了这一机制，展示了代理能够规划轨迹来优化状态的可推断性。",
      "categories": [
        "eess.SY",
        "cs.AI",
        "cs.RO",
        "cs.SY",
        "stat.ML"
      ],
      "primary_category": "eess.SY",
      "comment": "13 pages, 3 figures. Accepted to the International Workshop on Active\n  Inference 2024",
      "pdf_url": "http://arxiv.org/pdf/2409.01974v2",
      "published_date": "2024-09-03 15:17:16 UTC",
      "updated_date": "2024-09-18 20:11:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:00:33.106085"
    },
    {
      "arxiv_id": "2409.11411v1",
      "title": "AIvril: AI-Driven RTL Generation With Verification In-The-Loop",
      "title_zh": "翻译失败",
      "authors": [
        "Mubashir ul Islam",
        "Humza Sami",
        "Pierre-Emmanuel Gaillardon",
        "Valerio Tenace"
      ],
      "abstract": "Large Language Models (LLMs) are computational models capable of performing\ncomplex natural language processing tasks. Leveraging these capabilities, LLMs\nhold the potential to transform the entire hardware design stack, with\npredictions suggesting that front-end and back-end tasks could be fully\nautomated in the near future. Currently, LLMs show great promise in\nstreamlining Register Transfer Level (RTL) generation, enhancing efficiency,\nand accelerating innovation. However, their probabilistic nature makes them\nprone to inaccuracies - a significant drawback in RTL design, where reliability\nand precision are essential.\n  To address these challenges, this paper introduces AIvril, an advanced\nframework designed to enhance the accuracy and reliability of RTL-aware LLMs.\nAIvril employs a multi-agent, LLM-agnostic system for automatic syntax\ncorrection and functional verification, significantly reducing - and in many\ncases, completely eliminating - instances of erroneous code generation.\nExperimental results conducted on the VerilogEval-Human dataset show that our\nframework improves code quality by nearly 2x when compared to previous works,\nwhile achieving an 88.46% success rate in meeting verification objectives. This\nrepresents a critical step toward automating and optimizing hardware design\nworkflows, offering a more dependable methodology for AI-driven RTL design.",
      "tldr_zh": "本研究探讨了大型语言模型(LLMs)在寄存器传输级(RTL)生成中的应用潜力，但强调其概率性可能导致代码不准确问题。为解决此挑战，论文提出AIvril框架，这是一个多智能体、LLM-无关系统，通过自动语法修正和功能验证显著减少错误代码生成。在VerilogEval-Human数据集上的实验显示，AIvril将代码质量提高了近2倍，并实现了88.46%的验证成功率，从而为AI驱动的硬件设计工作流提供更可靠的自动化方法。",
      "categories": [
        "cs.AI",
        "cs.AR",
        "cs.CL",
        "cs.LG",
        "cs.MA"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.11411v1",
      "published_date": "2024-09-03 15:07:11 UTC",
      "updated_date": "2024-09-03 15:07:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:00:46.075935"
    },
    {
      "arxiv_id": "2409.01952v2",
      "title": "Exploiting the Vulnerability of Large Language Models via Defense-Aware Architectural Backdoor",
      "title_zh": "翻译失败",
      "authors": [
        "Abdullah Arafat Miah",
        "Yu Bi"
      ],
      "abstract": "Deep neural networks (DNNs) have long been recognized as vulnerable to\nbackdoor attacks. By providing poisoned training data in the fine-tuning\nprocess, the attacker can implant a backdoor into the victim model. This\nenables input samples meeting specific textual trigger patterns to be\nclassified as target labels of the attacker's choice. While such black-box\nattacks have been well explored in both computer vision and natural language\nprocessing (NLP), backdoor attacks relying on white-box attack philosophy have\nhardly been thoroughly investigated. In this paper, we take the first step to\nintroduce a new type of backdoor attack that conceals itself within the\nunderlying model architecture. Specifically, we propose to design separate\nbackdoor modules consisting of two functions: trigger detection and noise\ninjection. The add-on modules of model architecture layers can detect the\npresence of input trigger tokens and modify layer weights using Gaussian noise\nto disturb the feature distribution of the baseline model. We conduct extensive\nexperiments to evaluate our attack methods using two model architecture\nsettings on five different large language datasets. We demonstrate that the\ntraining-free architectural backdoor on a large language model poses a genuine\nthreat. Unlike the-state-of-art work, it can survive the rigorous fine-tuning\nand retraining process, as well as evade output probability-based defense\nmethods (i.e. BDDR). All the code and data is available\nhttps://github.com/SiSL-URI/Arch_Backdoor_LLM.",
      "tldr_zh": "本文提出了一种针对大型语言模型(LLMs)的防御感知架构后门攻击方法，通过在模型架构中植入独立的后门模块来规避传统黑盒攻击的局限性。攻击模块包括触发检测和噪声注入功能，使用高斯噪声修改层权重，以扰乱基线模型的特征分布，而无需毒化训练数据。实验在五个大型语言数据集和两种模型架构设置上进行，结果显示该攻击能经受细调和重训练过程，并成功规避基于输出概率的防御方法(如 BDDR)，证明其对LLMs的真实威胁。代码和数据已在GitHub上公开。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.AR"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.01952v2",
      "published_date": "2024-09-03 14:54:16 UTC",
      "updated_date": "2024-09-09 15:37:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:00:58.645917"
    },
    {
      "arxiv_id": "2409.01931v2",
      "title": "On the design space between molecular mechanics and machine learning force fields",
      "title_zh": "翻译失败",
      "authors": [
        "Yuanqing Wang",
        "Kenichiro Takaba",
        "Michael S. Chen",
        "Marcus Wieder",
        "Yuzhi Xu",
        "Tong Zhu",
        "John Z. H. Zhang",
        "Arnav Nagle",
        "Kuang Yu",
        "Xinyan Wang",
        "Daniel J. Cole",
        "Joshua A. Rackers",
        "Kyunghyun Cho",
        "Joe G. Greener",
        "Peter Eastman",
        "Stefano Martiniani",
        "Mark E. Tuckerman"
      ],
      "abstract": "A force field as accurate as quantum mechanics (QM) and as fast as molecular\nmechanics (MM), with which one can simulate a biomolecular system efficiently\nenough and meaningfully enough to get quantitative insights, is among the most\nardent dreams of biophysicists -- a dream, nevertheless, not to be fulfilled\nany time soon. Machine learning force fields (MLFFs) represent a meaningful\nendeavor towards this direction, where differentiable neural functions are\nparametrized to fit ab initio energies, and furthermore forces through\nautomatic differentiation. We argue that, as of now, the utility of the MLFF\nmodels is no longer bottlenecked by accuracy but primarily by their speed (as\nwell as stability and generalizability), as many recent variants, on limited\nchemical spaces, have long surpassed the chemical accuracy of $1$ kcal/mol --\nthe empirical threshold beyond which realistic chemical predictions are\npossible -- though still magnitudes slower than MM. Hoping to kindle\nexplorations and designs of faster, albeit perhaps slightly less accurate\nMLFFs, in this review, we focus our attention on the design space (the\nspeed-accuracy tradeoff) between MM and ML force fields. After a brief review\nof the building blocks of force fields of either kind, we discuss the desired\nproperties and challenges now faced by the force field development community,\nsurvey the efforts to make MM force fields more accurate and ML force fields\nfaster, envision what the next generation of MLFF might look like.",
      "tldr_zh": "本论文探讨了分子力学(MM)和机器学习力场(MLFFs)之间的设计空间，焦点在于速度与准确性的权衡，旨在实现既像量子力学(QM)一样精确又像MM一样快速的理想力场。作者指出，当前MLFFs已在有限化学空间超越1 kcal/mol的化学精度，但速度仍比MM慢几个数量级，从而成为其实际应用的瓶颈。论文回顾了两种力场的构建块，讨论了开发面临的挑战，并调查了提升MM准确性和MLFF速度的现有努力。最终，论文展望了下一代MLFF的潜在设计，以推动更高效的生物分子模拟。",
      "categories": [
        "physics.chem-ph",
        "cs.AI",
        "cs.LG",
        "physics.bio-ph",
        "physics.comp-ph"
      ],
      "primary_category": "physics.chem-ph",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.01931v2",
      "published_date": "2024-09-03 14:21:46 UTC",
      "updated_date": "2024-09-05 13:10:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:01:10.647900"
    },
    {
      "arxiv_id": "2409.01928v1",
      "title": "Comprehensive Equity Index (CEI): Definition and Application to Bias Evaluation in Biometrics",
      "title_zh": "翻译失败",
      "authors": [
        "Imanol Solano",
        "Alejandro Peña",
        "Aythami Morales",
        "Julian Fierrez",
        "Ruben Tolosana",
        "Francisco Zamora-Martinez",
        "Javier San Agustin"
      ],
      "abstract": "We present a novel metric designed, among other applications, to quantify\nbiased behaviors of machine learning models. As its core, the metric consists\nof a new similarity metric between score distributions that balances both their\ngeneral shapes and tails' probabilities. In that sense, our proposed metric may\nbe useful in many application areas. Here we focus on and apply it to the\noperational evaluation of face recognition systems, with special attention to\nquantifying demographic biases; an application where our metric is especially\nuseful. The topic of demographic bias and fairness in biometric recognition\nsystems has gained major attention in recent years. The usage of these systems\nhas spread in society, raising concerns about the extent to which these systems\ntreat different population groups. A relevant step to prevent and mitigate\ndemographic biases is first to detect and quantify them. Traditionally, two\napproaches have been studied to quantify differences between population groups\nin machine learning literature: 1) measuring differences in error rates, and 2)\nmeasuring differences in recognition score distributions. Our proposed\nComprehensive Equity Index (CEI) trade-offs both approaches combining both\nerrors from distribution tails and general distribution shapes. This new metric\nis well suited to real-world scenarios, as measured on NIST FRVT evaluations,\ninvolving high-performance systems and realistic face databases including a\nwide range of covariates and demographic groups. We first show the limitations\nof existing metrics to correctly assess the presence of biases in realistic\nsetups and then propose our new metric to tackle these limitations. We tested\nthe proposed metric with two state-of-the-art models and four widely used\ndatabases, showing its capacity to overcome the main flaws of previous bias\nmetrics.",
      "tldr_zh": "本研究提出了一种新指标 Comprehensive Equity Index (CEI)，旨在量化机器学习模型的偏见行为，特别是应用于生物识别系统中的人口统计学偏见评估。CEI 通过一个新的分数分布相似度度量，平衡了分布的整体形状和尾部概率，从而结合了传统方法的错误率差异和分布差异分析。实验在 NIST FRVT 评估中使用真实面部数据库和两款最先进模型，证明 CEI 克服了现有指标的局限性，并在高性能系统中更准确地检测和量化偏见。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted paper for the 27th International Conference on Pattern\n  Recognition (ICPR) 2024",
      "pdf_url": "http://arxiv.org/pdf/2409.01928v1",
      "published_date": "2024-09-03 14:19:38 UTC",
      "updated_date": "2024-09-03 14:19:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:01:20.818801"
    },
    {
      "arxiv_id": "2409.01927v1",
      "title": "From Grounding to Planning: Benchmarking Bottlenecks in Web Agents",
      "title_zh": "翻译失败",
      "authors": [
        "Segev Shlomov",
        "Ben wiesel",
        "Aviad Sela",
        "Ido Levy",
        "Liane Galanti",
        "Roy Abitbol"
      ],
      "abstract": "General web-based agents are increasingly essential for interacting with\ncomplex web environments, yet their performance in real-world web applications\nremains poor, yielding extremely low accuracy even with state-of-the-art\nfrontier models. We observe that these agents can be decomposed into two\nprimary components: Planning and Grounding. Yet, most existing research treats\nthese agents as black boxes, focusing on end-to-end evaluations which hinder\nmeaningful improvements. We sharpen the distinction between the planning and\ngrounding components and conduct a novel analysis by refining experiments on\nthe Mind2Web dataset. Our work proposes a new benchmark for each of the\ncomponents separately, identifying the bottlenecks and pain points that limit\nagent performance. Contrary to prevalent assumptions, our findings suggest that\ngrounding is not a significant bottleneck and can be effectively addressed with\ncurrent techniques. Instead, the primary challenge lies in the planning\ncomponent, which is the main source of performance degradation. Through this\nanalysis, we offer new insights and demonstrate practical suggestions for\nimproving the capabilities of web agents, paving the way for more reliable\nagents.",
      "tldr_zh": "该论文分析了网络代理（web agents）在复杂网络环境中的性能瓶颈，指出现有代理即使使用前沿模型也准确率极低。研究将代理分解为 Planning 和 Grounding 两个核心组件，并通过对 Mind2Web 数据集的细化实验，提出新的基准来单独评估每个组件。结果显示，Grounding 并非主要问题，可用现有技术有效解决，而 Planning 是性能下降的关键因素；论文据此提供实用建议，推动更可靠的网络代理发展。",
      "categories": [
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.01927v1",
      "published_date": "2024-09-03 14:17:09 UTC",
      "updated_date": "2024-09-03 14:17:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:01:31.989537"
    },
    {
      "arxiv_id": "2409.01914v1",
      "title": "GradINN: Gradient Informed Neural Network",
      "title_zh": "翻译失败",
      "authors": [
        "Filippo Aglietti",
        "Francesco Della Santa",
        "Andrea Piano",
        "Virginia Aglietti"
      ],
      "abstract": "We propose Gradient Informed Neural Networks (GradINNs), a methodology\ninspired by Physics Informed Neural Networks (PINNs) that can be used to\nefficiently approximate a wide range of physical systems for which the\nunderlying governing equations are completely unknown or cannot be defined, a\ncondition that is often met in complex engineering problems. GradINNs leverage\nprior beliefs about a system's gradient to constrain the predicted function's\ngradient across all input dimensions. This is achieved using two neural\nnetworks: one modeling the target function and an auxiliary network expressing\nprior beliefs, e.g., smoothness. A customized loss function enables training\nthe first network while enforcing gradient constraints derived from the\nauxiliary network. We demonstrate the advantages of GradINNs, particularly in\nlow-data regimes, on diverse problems spanning non time-dependent systems\n(Friedman function, Stokes Flow) and time-dependent systems (Lotka-Volterra,\nBurger's equation). Experimental results showcase strong performance compared\nto standard neural networks and PINN-like approaches across all tested\nscenarios.",
      "tldr_zh": "本研究提出Gradient Informed Neural Networks (GradINNs)，一种受Physics Informed Neural Networks (PINNs)启发的方法，用于高效逼近未知或无法定义的物理系统。GradINNs通过两个神经网络实现：一个用于建模目标函数，另一个表达梯度先验（如平滑性），并借助自定义损失函数强制执行梯度约束，从而在低数据条件下提升模型性能。实验结果显示，GradINNs在多种场景中表现出色，包括非时间依赖系统（如Friedman function和Stokes Flow）以及时间依赖系统（如Lotka-Volterra和Burger's equation），其表现优于标准神经网络和类似PINN方法。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.01914v1",
      "published_date": "2024-09-03 14:03:29 UTC",
      "updated_date": "2024-09-03 14:03:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:01:45.192002"
    },
    {
      "arxiv_id": "2409.01909v2",
      "title": "LUK: Empowering Log Understanding with Expert Knowledge from Large Language Models",
      "title_zh": "LUK：利用大型语言模型的专家知识增强日志理解",
      "authors": [
        "Lipeng Ma",
        "Weidong Yang",
        "Sihang Jiang",
        "Ben Fei",
        "Mingjie Zhou",
        "Shuhao Li",
        "Mingyu Zhao",
        "Bo Xu",
        "Yanghua Xiao"
      ],
      "abstract": "Logs play a critical role in providing essential information for system\nmonitoring and troubleshooting. Recently, with the success of pre-trained\nlanguage models (PLMs) and large language models (LLMs) in natural language\nprocessing (NLP), smaller PLMs (such as BERT) and LLMs (like GPT-4) have become\nthe current mainstream approaches for log analysis. Despite the remarkable\ncapabilities of LLMs, their higher cost and inefficient inference present\nsignificant challenges in leveraging the full potential of LLMs to analyze\nlogs. In contrast, smaller PLMs can be fine-tuned for specific tasks even with\nlimited computational resources, making them more practical. However, these\nsmaller PLMs face challenges in understanding logs comprehensively due to their\nlimited expert knowledge. To address the lack of expert knowledge and enhance\nlog understanding for smaller PLMs, this paper introduces a novel and practical\nknowledge enhancement framework, called LUK, which acquires expert knowledge\nfrom LLMs automatically and then enhances the smaller PLM for log analysis with\nthese expert knowledge. LUK can take full advantage of both types of models.\nSpecifically, we design a multi-expert collaboration framework based on LLMs\nwith different roles to acquire expert knowledge. In addition, we propose two\nnovel pre-training tasks to enhance the log pre-training with expert knowledge.\nLUK achieves state-of-the-art results on different log analysis tasks and\nextensive experiments demonstrate expert knowledge from LLMs can be utilized\nmore effectively to understand logs. Our source code and detailed experimental\ndata are available at https://github.com/LeaperOvO/LUK.",
      "tldr_zh": "本论文提出 LUK 框架，利用大型语言模型 (LLMs) 的专家知识来增强较小预训练语言模型 (PLMs) 在日志分析中的理解能力，以解决 PLMs 知识不足的问题。LUK 设计了一个基于 LLMs 的多专家协作框架，并引入两个新预训练任务，自动获取专家知识并整合到日志处理中。实验结果显示，LUK 在多种日志分析任务上实现了 state-of-the-art 性能，证明了这种知识增强方法能更有效地提升日志理解。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "Under review",
      "pdf_url": "http://arxiv.org/pdf/2409.01909v2",
      "published_date": "2024-09-03 13:58:34 UTC",
      "updated_date": "2025-01-31 05:51:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:01:58.677063"
    },
    {
      "arxiv_id": "2409.01903v1",
      "title": "A randomized simulation trial evaluating ABiMed, a clinical decision support system for medication reviews and polypharmacy management",
      "title_zh": "一个随机模拟试验，用于评估 ABiMed——一种用于药物审查和多药管理的临床决策支持系统",
      "authors": [
        "Abdelmalek Mouazer",
        "Sophie Dubois",
        "Romain Léguillon",
        "Nada Boudegzdame",
        "Thibaud Levrard",
        "Yoann Le Bars",
        "Christian Simon",
        "Brigitte Séroussi",
        "Julien Grosjean",
        "Romain Lelong",
        "Catherine Letord",
        "Stéfan Darmoni",
        "Karima Sedki",
        "Pierre Meneton",
        "Rosy Tsopra",
        "Hector Falcoff",
        "Jean-Baptiste Lamy"
      ],
      "abstract": "Background: Medication review is a structured interview of the patient,\nperformed by the pharmacist and aimed at optimizing drug treatments. In\npractice, medication review is a long and cognitively-demanding task that\nrequires specific knowledge. Clinical practice guidelines have been proposed,\nbut their application is tedious. Methods: We designed ABiMed, a clinical\ndecision support system for medication reviews, based on the implementation of\nthe STOPP/START v2 guidelines and on the visual presentation of aggregated drug\nknowledge using tables, graphs and flower glyphs. We evaluated ABiMed with 39\ncommunity pharmacists during a randomized simulation trial, each pharmacist\nperforming a medication review for two fictitious patients without ABiMed, and\ntwo others with ABiMed. We recorded the problems identified by the pharmacists,\nthe interventions proposed, the response time, the perceived usability and the\ncomments. Pharmacists' medication reviews were compared to an expert-designed\ngold standard. Results: With ABiMed, pharmacists found 1.6 times more relevant\ndrug-related problems during the medication review (p=1.1e-12) and proposed\nbetter interventions (p=9.8e-9), without needing more time (p=0.56). The System\nUsability Scale score is 82.7, which is ranked \"excellent\". In their comments,\npharmacists appreciated the visual aspect of ABiMed and its ability to compare\nthe current treatment with the proposed one. A multifactor analysis showed no\ndifference in the support offered by ABiMed according to the pharmacist's age\nor sex, in terms of percentage of problems identified or quality of the\nproposed interventions. Conclusions: The use of an intelligent and visual\nclinical decision support system can help pharmacists when they perform\nmedication reviews. Our main perspective is the validation of the system in\nclinical conditions.",
      "tldr_zh": "本研究评估了 ABiMed，一种基于 STOPP/START v2 指南的临床决策支持系统，用于药物审查和多药管理，通过表格、图表和花瓣图等视觉方式呈现药物知识。研究采用随机模拟试验，招募 39 名社区药剂师对虚构患者进行药物审查，比较使用和不使用 ABiMed 的表现。结果显示，使用 ABiMed 后，药剂师发现的相关药物问题增加了 1.6 倍，提出的干预措施更佳，且所需时间无显著差异（p=0.56），系统可用性得分达到 System Usability Scale 82.7（优秀级别）。此外，该系统对药剂师年龄和性别无显著影响，未来计划在临床条件下验证其效果。",
      "categories": [
        "cs.AI",
        "cs.HC",
        "J.3"
      ],
      "primary_category": "cs.AI",
      "comment": "8 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2409.01903v1",
      "published_date": "2024-09-03 13:50:59 UTC",
      "updated_date": "2024-09-03 13:50:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:02:14.682822"
    },
    {
      "arxiv_id": "2409.03715v1",
      "title": "Applications and Advances of Artificial Intelligence in Music Generation:A Review",
      "title_zh": "人工智能在音乐生成中的应用与进展：综述",
      "authors": [
        "Yanxu Chen",
        "Linshu Huang",
        "Tian Gou"
      ],
      "abstract": "In recent years, artificial intelligence (AI) has made significant progress\nin the field of music generation, driving innovation in music creation and\napplications. This paper provides a systematic review of the latest research\nadvancements in AI music generation, covering key technologies, models,\ndatasets, evaluation methods, and their practical applications across various\nfields. The main contributions of this review include: (1) presenting a\ncomprehensive summary framework that systematically categorizes and compares\ndifferent technological approaches, including symbolic generation, audio\ngeneration, and hybrid models, helping readers better understand the full\nspectrum of technologies in the field; (2) offering an extensive survey of\ncurrent literature, covering emerging topics such as multimodal datasets and\nemotion expression evaluation, providing a broad reference for related\nresearch; (3) conducting a detailed analysis of the practical impact of AI\nmusic generation in various application domains, particularly in real-time\ninteraction and interdisciplinary applications, offering new perspectives and\ninsights; (4) summarizing the existing challenges and limitations of music\nquality evaluation methods and proposing potential future research directions,\naiming to promote the standardization and broader adoption of evaluation\ntechniques. Through these innovative summaries and analyses, this paper serves\nas a comprehensive reference tool for researchers and practitioners in AI music\ngeneration, while also outlining future directions for the field.",
      "tldr_zh": "这篇论文对人工智能(AI)在音乐生成领域的应用和进展进行了系统综述，涵盖了关键技术、模型、数据集、评估方法以及在各种领域的实际应用。论文的主要贡献包括：提供一个全面框架来分类比较符号生成、音频生成和混合模型；调查当前文献，突出多模态数据集和情感表达评估等新兴话题；并分析AI音乐生成在实时交互和跨学科应用中的实际影响，同时总结现有挑战并提出未来研究方向。该综述为AI音乐生成的研究者和从业者提供了宝贵参考，促进了该领域的标准化和创新发展。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.03715v1",
      "published_date": "2024-09-03 13:50:55 UTC",
      "updated_date": "2024-09-03 13:50:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:02:24.298725"
    },
    {
      "arxiv_id": "2409.01901v1",
      "title": "3D-LEX v1.0: 3D Lexicons for American Sign Language and Sign Language of the Netherlands",
      "title_zh": "3D-LEX v1.0：美国手语和",
      "authors": [
        "Oline Ranum",
        "Gomer Otterspeer",
        "Jari I. Andersen",
        "Robert G. Belleman",
        "Floris Roelofsen"
      ],
      "abstract": "In this work, we present an efficient approach for capturing sign language in\n3D, introduce the 3D-LEX v1.0 dataset, and detail a method for semi-automatic\nannotation of phonetic properties. Our procedure integrates three motion\ncapture techniques encompassing high-resolution 3D poses, 3D handshapes, and\ndepth-aware facial features, and attains an average sampling rate of one sign\nevery 10 seconds. This includes the time for presenting a sign example,\nperforming and recording the sign, and archiving the capture. The 3D-LEX\ndataset includes 1,000 signs from American Sign Language and an additional\n1,000 signs from the Sign Language of the Netherlands. We showcase the dataset\nutility by presenting a simple method for generating handshape annotations\ndirectly from 3D-LEX. We produce handshape labels for 1,000 signs from American\nSign Language and evaluate the labels in a sign recognition task. The labels\nenhance gloss recognition accuracy by 5% over using no handshape annotations,\nand by 1% over expert annotations. Our motion capture data supports in-depth\nanalysis of sign features and facilitates the generation of 2D projections from\nany viewpoint. The 3D-LEX collection has been aligned with existing sign\nlanguage benchmarks and linguistic resources, to support studies in 3D-aware\nsign language processing.",
      "tldr_zh": "本文介绍了3D-LEX v1.0数据集，该数据集包含1000个American Sign Language和1000个Sign Language of the Netherlands的手语符号，并采用三种motion capture技术（包括高分辨率3D poses、3D handshapes和深度感知facial features）实现高效捕获，平均每10秒采样一个符号。研究提出了一种半自动标注phonetic properties的方法，并通过简单的手势标注生成技术，为American Sign Language的1000个符号提供了标签。实验结果显示，这些标签在符号识别任务中比无标注提高了5%的准确率，比专家标注提高了1%，并支持对符号特征的深入分析和3D-aware的手语处理研究。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.01901v1",
      "published_date": "2024-09-03 13:44:56 UTC",
      "updated_date": "2024-09-03 13:44:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:02:38.789572"
    },
    {
      "arxiv_id": "2409.01893v1",
      "title": "What are the Essential Factors in Crafting Effective Long Context Multi-Hop Instruction Datasets? Insights and Best Practices",
      "title_zh": "创建有效长上下文多跳指令",
      "authors": [
        "Zhi Chen",
        "Qiguang Chen",
        "Libo Qin",
        "Qipeng Guo",
        "Haijun Lv",
        "Yicheng Zou",
        "Wanxiang Che",
        "Hang Yan",
        "Kai Chen",
        "Dahua Lin"
      ],
      "abstract": "Recent advancements in large language models (LLMs) with extended context\nwindows have significantly improved tasks such as information extraction,\nquestion answering, and complex planning scenarios. In order to achieve success\nin long context tasks, a large amount of work has been done to enhance the long\ncontext capabilities of the model through synthetic data. Existing methods\ntypically utilize the Self-Instruct framework to generate instruction tuning\ndata for better long context capability improvement. However, our preliminary\nexperiments indicate that less than 35% of generated samples are multi-hop, and\nmore than 40% exhibit poor quality, limiting comprehensive understanding and\nfurther research. To improve the quality of synthetic data, we propose the\nMulti-agent Interactive Multi-hop Generation (MIMG) framework, incorporating a\nQuality Verification Agent, a Single-hop Question Generation Agent, a Multiple\nQuestion Sampling Strategy, and a Multi-hop Question Merger Agent. This\nframework improves the data quality, with the proportion of high-quality,\nmulti-hop, and diverse data exceeding 85%. Furthermore, we systematically\ninvestigate strategies for document selection, question merging, and validation\ntechniques through extensive experiments across various models. Our findings\nshow that our synthetic high-quality long-context instruction data\nsignificantly enhances model performance, even surpassing models trained on\nlarger amounts of human-annotated data. Our code is available at:\nhttps://github.com/WowCZ/LongMIT.",
      "tldr_zh": "这篇论文探讨了创建有效长上下文多跳指令数据集的关键因素，针对现有Self-Instruct框架生成的样本问题（如不到35%为多跳且超过40%质量差），提出Multi-agent Interactive Multi-hop Generation (MIMG)框架。该框架整合了Quality Verification Agent、Single-hop Question Generation Agent、Multiple Question Sampling Strategy和Multi-hop Question Merger Agent，提高了数据质量，使高质量、多跳和多样样本的比例超过85%。通过广泛实验，论文检验了文档选择、问题合并和验证策略，发现使用这些合成的高质量数据能显著提升LLMs的性能，甚至超越基于更大规模人工标注数据的模型训练效果。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Work in progress",
      "pdf_url": "http://arxiv.org/pdf/2409.01893v1",
      "published_date": "2024-09-03 13:30:00 UTC",
      "updated_date": "2024-09-03 13:30:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:02:48.364541"
    },
    {
      "arxiv_id": "2409.01876v3",
      "title": "CyberHost: Taming Audio-driven Avatar Diffusion Model with Region Codebook Attention",
      "title_zh": "翻译失败",
      "authors": [
        "Gaojie Lin",
        "Jianwen Jiang",
        "Chao Liang",
        "Tianyun Zhong",
        "Jiaqi Yang",
        "Yanbo Zheng"
      ],
      "abstract": "Diffusion-based video generation technology has advanced significantly,\ncatalyzing a proliferation of research in human animation. However, the\nmajority of these studies are confined to same-modality driving settings, with\ncross-modality human body animation remaining relatively underexplored. In this\npaper, we introduce, an end-to-end audio-driven human animation framework that\nensures hand integrity, identity consistency, and natural motion. The key\ndesign of CyberHost is the Region Codebook Attention mechanism, which improves\nthe generation quality of facial and hand animations by integrating\nfine-grained local features with learned motion pattern priors. Furthermore, we\nhave developed a suite of human-prior-guided training strategies, including\nbody movement map, hand clarity score, pose-aligned reference feature, and\nlocal enhancement supervision, to improve synthesis results. To our knowledge,\nCyberHost is the first end-to-end audio-driven human diffusion model capable of\nfacilitating zero-shot video generation within the scope of human body.\nExtensive experiments demonstrate that CyberHost surpasses previous works in\nboth quantitative and qualitative aspects.",
      "tldr_zh": "本研究提出CyberHost，一种端到端的音频驱动人类动画框架，利用Diffusion Model技术，确保手部完整性、身份一致性和自然动作。关键创新是Region Codebook Attention机制，通过整合细粒度的局部特征和学习到的运动模式先验，提升面部和手部动画的生成质量；此外，引入了body movement map、hand clarity score、pose-aligned reference feature和local enhancement supervision等人类先导训练策略，以优化合成结果。作为首个支持零样本视频生成的音频驱动人类扩散模型，CyberHost在定量和定性实验中均超越了现有工作。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "ICLR 2025 (Oral), Homepage: https://cyberhost.github.io/",
      "pdf_url": "http://arxiv.org/pdf/2409.01876v3",
      "published_date": "2024-09-03 13:19:31 UTC",
      "updated_date": "2025-04-05 05:31:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:02:58.906835"
    },
    {
      "arxiv_id": "2409.01872v1",
      "title": "Latent Distillation for Continual Object Detection at the Edge",
      "title_zh": "翻译失败",
      "authors": [
        "Francesco Pasti",
        "Marina Ceccon",
        "Davide Dalle Pezze",
        "Francesco Paissan",
        "Elisabetta Farella",
        "Gian Antonio Susto",
        "Nicola Bellotto"
      ],
      "abstract": "While numerous methods achieving remarkable performance exist in the Object\nDetection literature, addressing data distribution shifts remains challenging.\nContinual Learning (CL) offers solutions to this issue, enabling models to\nadapt to new data while maintaining performance on previous data. This is\nparticularly pertinent for edge devices, common in dynamic environments like\nautomotive and robotics. In this work, we address the memory and computation\nconstraints of edge devices in the Continual Learning for Object Detection\n(CLOD) scenario. Specifically, (i) we investigate the suitability of an\nopen-source, lightweight, and fast detector, namely NanoDet, for CLOD on edge\ndevices, improving upon larger architectures used in the literature. Moreover,\n(ii) we propose a novel CL method, called Latent Distillation~(LD), that\nreduces the number of operations and the memory required by state-of-the-art CL\napproaches without significantly compromising detection performance. Our\napproach is validated using the well-known VOC and COCO benchmarks, reducing\nthe distillation parameter overhead by 74\\% and the Floating Points\nOperations~(FLOPs) by 56\\% per model update compared to other distillation\nmethods.",
      "tldr_zh": "这篇论文针对对象检测中的数据分布变化，提出在边缘设备上应用Continual Learning (CL)的方法，以适应动态环境如汽车和机器人领域。作者评估了轻量级检测器NanoDet在Continual Learning for Object Detection (CLOD)场景中的适用性，并引入了新方法Latent Distillation (LD)，该方法通过减少操作数量和内存需求（如降低74%的蒸馏参数开销和56%的FLOPs），而不显著影响检测性能。在VOC和COCO基准测试中，LD展示了高效的模型更新能力，为边缘设备的资源约束场景提供了实用解决方案。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "ECCV workshops, Computational Aspects of Deep Learning (CADL) 2024",
      "pdf_url": "http://arxiv.org/pdf/2409.01872v1",
      "published_date": "2024-09-03 13:14:13 UTC",
      "updated_date": "2024-09-03 13:14:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:03:13.241878"
    },
    {
      "arxiv_id": "2409.01871v1",
      "title": "Real-Time Indoor Object Detection based on hybrid CNN-Transformer Approach",
      "title_zh": "基于混合 CNN-Transformer 方法的实时室内物体检测",
      "authors": [
        "Salah Eddine Laidoudi",
        "Madjid Maidi",
        "Samir Otmane"
      ],
      "abstract": "Real-time object detection in indoor settings is a challenging area of\ncomputer vision, faced with unique obstacles such as variable lighting and\ncomplex backgrounds. This field holds significant potential to revolutionize\napplications like augmented and mixed realities by enabling more seamless\ninteractions between digital content and the physical world. However, the\nscarcity of research specifically fitted to the intricacies of indoor\nenvironments has highlighted a clear gap in the literature. To address this,\nour study delves into the evaluation of existing datasets and computational\nmodels, leading to the creation of a refined dataset. This new dataset is\nderived from OpenImages v7, focusing exclusively on 32 indoor categories\nselected for their relevance to real-world applications. Alongside this, we\npresent an adaptation of a CNN detection model, incorporating an attention\nmechanism to enhance the model's ability to discern and prioritize critical\nfeatures within cluttered indoor scenes. Our findings demonstrate that this\napproach is not just competitive with existing state-of-the-art models in\naccuracy and speed but also opens new avenues for research and application in\nthe field of real-time indoor object detection.",
      "tldr_zh": "本研究针对室内实时物体检测的挑战（如可变照明和复杂背景），通过评估现有数据集和模型，创建了一个基于OpenImages v7的精炼数据集，专注于32个与现实应用相关的室内类别。研究提出了一种混合CNN-Transformer方法，将注意力机制融入CNN检测模型，以提升对杂乱场景中关键特征的识别能力。该方法在准确性和速度上与现有最先进模型竞争，并为增强现实和混合现实应用开辟新研究方向。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.01871v1",
      "published_date": "2024-09-03 13:14:08 UTC",
      "updated_date": "2024-09-03 13:14:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:03:23.715945"
    },
    {
      "arxiv_id": "2409.01864v1",
      "title": "The Role of Large Language Models in Musicology: Are We Ready to Trust the Machines?",
      "title_zh": "大型语言模型在音乐学中的作用：我们准备好信任机器了吗？",
      "authors": [
        "Pedro Ramoneda",
        "Emilia Parada-Cabaleiro",
        "Benno Weck",
        "Xavier Serra"
      ],
      "abstract": "In this work, we explore the use and reliability of Large Language Models\n(LLMs) in musicology. From a discussion with experts and students, we assess\nthe current acceptance and concerns regarding this, nowadays ubiquitous,\ntechnology. We aim to go one step further, proposing a semi-automatic method to\ncreate an initial benchmark using retrieval-augmented generation models and\nmultiple-choice question generation, validated by human experts. Our evaluation\non 400 human-validated questions shows that current vanilla LLMs are less\nreliable than retrieval augmented generation from music dictionaries. This\npaper suggests that the potential of LLMs in musicology requires musicology\ndriven research that can specialized LLMs by including accurate and reliable\ndomain knowledge.",
      "tldr_zh": "本文探讨大型语言模型（LLMs）在音乐学中的作用和可靠性，通过与专家和学生的讨论，评估了当前技术的接受度和担忧。研究提出一种半自动方法，利用检索增强生成（RAG）模型和多项选择题生成来创建初始基准，并由人类专家进行验证。在对400个问题进行的评估中，发现普通LLMs的可靠性低于基于音乐词典的RAG模型。论文强调，充分发挥LLMs在音乐学中的潜力，需要通过音乐学驱动的研究来开发专化的模型，并纳入准确的领域知识。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.CL",
        "cs.DL",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.01864v1",
      "published_date": "2024-09-03 13:05:38 UTC",
      "updated_date": "2024-09-03 13:05:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:03:37.133566"
    },
    {
      "arxiv_id": "2409.02958v1",
      "title": "Multi-Modal Adapter for Vision-Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Dominykas Seputis",
        "Serghei Mihailov",
        "Soham Chatterjee",
        "Zehao Xiao"
      ],
      "abstract": "Large pre-trained vision-language models, such as CLIP, have demonstrated\nstate-of-the-art performance across a wide range of image classification tasks,\nwithout requiring retraining. Few-shot CLIP is competitive with existing\nspecialized architectures that were trained on the downstream tasks. Recent\nresearch demonstrates that the performance of CLIP can be further improved\nusing lightweight adaptation approaches. However, previous methods adapt\ndifferent modalities of the CLIP model individually, ignoring the interactions\nand relationships between visual and textual representations. In this work, we\npropose Multi-Modal Adapter, an approach for Multi-Modal adaptation of CLIP.\nSpecifically, we add a trainable Multi-Head Attention layer that combines text\nand image features to produce an additive adaptation of both. Multi-Modal\nAdapter demonstrates improved generalizability, based on its performance on\nunseen classes compared to existing adaptation methods. We perform additional\nablations and investigations to validate and interpret the proposed approach.",
      "tldr_zh": "这篇论文针对视觉语言模型（如 CLIP）提出 Multi-Modal Adapter 方法，以改进其在图像分类任务中的适应性能。传统方法单独适应视觉和文本模态，而该方法通过添加一个可训练的多头注意力层（Multi-Head Attention）来结合文本和图像特征，实现模态间交互的优化。实验结果表明，Multi-Modal Adapter 在未见类别上的泛化能力优于现有方法，并通过消融实验验证了其有效性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.02958v1",
      "published_date": "2024-09-03 12:47:08 UTC",
      "updated_date": "2024-09-03 12:47:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:03:48.056980"
    },
    {
      "arxiv_id": "2409.02152v1",
      "title": "Fair Railway Network Design",
      "title_zh": "公平铁路网络设计",
      "authors": [
        "Zixu He",
        "Sirin Botan",
        "Jérôme Lang",
        "Abdallah Saffidine",
        "Florian Sikora",
        "Silas Workman"
      ],
      "abstract": "When designing a public transportation network in a country, one may want to\nminimise the sum of travel duration of all inhabitants. This corresponds to a\npurely utilitarian view and does not involve any fairness consideration, as the\nresulting network will typically benefit the capital city and/or large central\ncities while leaving some peripheral cities behind. On the other hand, a more\negalitarian view will allow some people to travel between peripheral cities\nwithout having to go through a central city. We define a model, propose\nalgorithms for computing solution networks, and report on experiments based on\nreal data.",
      "tldr_zh": "这篇论文探讨了铁路网络设计中的公平性问题，传统方法通过最小化所有居民的总旅行时间来优化网络，但往往偏向大城市（如首都），忽略了外围城市的连接需求。论文提出了一种更平等的模型，允许外围城市之间直接连接，而非必须经过中央城市。研究团队定义了相关算法，并基于真实数据进行了实验，以验证该模型的有效性。",
      "categories": [
        "cs.SI",
        "cs.AI"
      ],
      "primary_category": "cs.SI",
      "comment": "32 pages, 18 figures",
      "pdf_url": "http://arxiv.org/pdf/2409.02152v1",
      "published_date": "2024-09-03 12:13:05 UTC",
      "updated_date": "2024-09-03 12:13:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:03:59.286876"
    },
    {
      "arxiv_id": "2409.01815v1",
      "title": "Learning State-Dependent Policy Parametrizations for Dynamic Technician Routing with Rework",
      "title_zh": "翻译失败",
      "authors": [
        "Jonas Stein",
        "Florentin D Hildebrandt",
        "Barrett W Thomas",
        "Marlin W Ulmer"
      ],
      "abstract": "Home repair and installation services require technicians to visit customers\nand resolve tasks of different complexity. Technicians often have heterogeneous\nskills and working experiences. The geographical spread of customers makes\nachieving only perfect matches between technician skills and task requirements\nimpractical. Additionally, technicians are regularly absent due to sickness.\nWith non-perfect assignments regarding task requirement and technician skill,\nsome tasks may remain unresolved and require a revisit and rework. Companies\nseek to minimize customer inconvenience due to delay. We model the problem as a\nsequential decision process where, over a number of service days, customers\nrequest service while heterogeneously skilled technicians are routed to serve\ncustomers in the system. Each day, our policy iteratively builds tours by\nadding \"important\" customers. The importance bases on analytical considerations\nand is measured by respecting routing efficiency, urgency of service, and risk\nof rework in an integrated fashion. We propose a state-dependent balance of\nthese factors via reinforcement learning. A comprehensive study shows that\ntaking a few non-perfect assignments can be quite beneficial for the overall\nservice quality. We further demonstrate the value provided by a state-dependent\nparametrization.",
      "tldr_zh": "本论文研究了动态技术员路由问题，包括重做风险，针对家庭维修服务中技术员技能异质化、客户地理分布和缺勤等挑战。作者将问题建模为一个顺序决策过程，使用强化学习（reinforcement learning）来学习状态相关的政策参数化，该政策通过平衡路由效率、服务紧急性和重做风险来迭代构建每日服务路线。研究结果显示，接受部分非完美任务分配可以显著提升整体服务质量，并证明了状态依赖参数化的实际价值。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.01815v1",
      "published_date": "2024-09-03 11:56:58 UTC",
      "updated_date": "2024-09-03 11:56:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:04:12.899724"
    },
    {
      "arxiv_id": "2409.12182v2",
      "title": "LifeGPT: Topology-Agnostic Generative Pretrained Transformer Model for Cellular Automata",
      "title_zh": "翻译失败",
      "authors": [
        "Jaime A. Berkovich",
        "Markus J. Buehler"
      ],
      "abstract": "Conway's Game of Life (Life), a well known algorithm within the broader class\nof cellular automata (CA), exhibits complex emergent dynamics, with extreme\nsensitivity to initial conditions. Modeling and predicting such intricate\nbehavior without explicit knowledge of the system's underlying topology\npresents a significant challenge, motivating the development of algorithms that\ncan generalize across various grid configurations and boundary conditions. We\ndevelop a decoder-only generative pretrained transformer (GPT) model to solve\nthis problem, showing that our model can simulate Life on a toroidal grid with\nno prior knowledge on the size of the grid, or its periodic boundary conditions\n(LifeGPT). LifeGPT is topology-agnostic with respect to its training data and\nour results show that a GPT model is capable of capturing the deterministic\nrules of a Turing-complete system with near-perfect accuracy, given\nsufficiently diverse training data. We also introduce the idea of an\n`autoregressive autoregressor' to recursively implement Life using LifeGPT. Our\nresults pave the path towards true universal computation within a large\nlanguage model framework, synthesizing of mathematical analysis with natural\nlanguage processing, and probing AI systems for situational awareness about the\nevolution of such algorithms without ever having to compute them. Similar GPTs\ncould potentially solve inverse problems in multicellular self-assembly by\nextracting CA-compatible rulesets from real-world biological systems to create\nnew predictive models, which would have significant consequences for the fields\nof bioinspired materials, tissue engineering, and architected materials design.",
      "tldr_zh": "本文提出LifeGPT，一种拓扑无关的生成预训练Transformer模型，用于模拟细胞自动机（Cellular Automata），如Conway's Game of Life，而无需事先知道网格大小或边界条件。LifeGPT通过多样化的训练数据，捕捉了该Turing-complete系统的确定性规则，实现近乎完美的预测准确性，并引入“autoregressive autoregressor”概念来递归实现模拟。研究结果为在大型语言模型框架中实现通用计算铺平道路，并探索AI对算法演化的 situational awareness，同时潜在应用于生物领域，如从真实系统提取CA规则以预测多细胞自组装。",
      "categories": [
        "cs.AI",
        "cond-mat.mtrl-sci",
        "cond-mat.stat-mech",
        "math.DS"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.12182v2",
      "published_date": "2024-09-03 11:43:16 UTC",
      "updated_date": "2024-10-17 16:55:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:04:26.457238"
    },
    {
      "arxiv_id": "2409.01808v2",
      "title": "Dialogue You Can Trust: Human and AI Perspectives on Generated Conversations",
      "title_zh": "翻译失败",
      "authors": [
        "Ike Ebubechukwu",
        "Johane Takeuchi",
        "Antonello Ceravola",
        "Frank Joublin"
      ],
      "abstract": "As dialogue systems and chatbots increasingly integrate into everyday\ninteractions, the need for efficient and accurate evaluation methods becomes\nparamount. This study explores the comparative performance of human and AI\nassessments across a range of dialogue scenarios, focusing on seven key\nperformance indicators (KPIs): Coherence, Innovation, Concreteness, Goal\nContribution, Commonsense Contradiction, Incorrect Fact, and Redundancy.\nUtilizing the GPT-4o API, we generated a diverse dataset of conversations and\nconducted a two-part experimental analysis. In Experiment 1, we evaluated\nmulti-party conversations on Coherence, Innovation, Concreteness, and Goal\nContribution, revealing that GPT models align closely with human judgments.\nNotably, both human and AI evaluators exhibited a tendency towards binary\njudgment rather than linear scaling, highlighting a shared challenge in these\nassessments. Experiment 2 extended the work of Finch et al. (2023) by focusing\non dyadic dialogues and assessing Commonsense Contradiction, Incorrect Fact,\nand Redundancy. The results indicate that while GPT-4o demonstrates strong\nperformance in maintaining factual accuracy and commonsense reasoning, it still\nstruggles with reducing redundancy and self-contradiction. Our findings\nunderscore the potential of GPT models to closely replicate human evaluation in\ndialogue systems, while also pointing to areas for improvement. This research\noffers valuable insights for advancing the development and implementation of\nmore refined dialogue evaluation methodologies, contributing to the evolution\nof more effective and human-like AI communication tools.",
      "tldr_zh": "本研究比较了人类和 AI 在评估生成对话系统性能时的表现，焦点在于七个关键绩效指标（KPIs）：Coherence、Innovation、Concreteness、Goal Contribution、Commonsense Contradiction、Incorrect Fact 和 Redundancy。研究利用 GPT-4o API 生成多样化对话数据集，并通过两部分实验进行分析：实验 1 评估多方对话的四个 KPIs，发现 GPT 模型与人类判断高度一致，但两者均倾向于二元判断而非线性评估；实验 2 扩展 Finch et al. (2023) 的工作，评估双人对话的剩余三个 KPIs，结果显示 GPT-4o 在事实准确性和常识推理上表现出色，但仍存在冗余和自相矛盾的问题。该研究强调了 GPT 模型在对话评估中的潜力，同时指出了改进方向，为开发更精确的对话评估方法和更人性化的 AI 通信工具提供了宝贵见解。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "17 pages, 15 figures",
      "pdf_url": "http://arxiv.org/pdf/2409.01808v2",
      "published_date": "2024-09-03 11:40:38 UTC",
      "updated_date": "2024-09-10 13:33:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:04:38.919947"
    },
    {
      "arxiv_id": "2409.01806v1",
      "title": "LASP: Surveying the State-of-the-Art in Large Language Model-Assisted AI Planning",
      "title_zh": "翻译失败",
      "authors": [
        "Haoming Li",
        "Zhaoliang Chen",
        "Jonathan Zhang",
        "Fei Liu"
      ],
      "abstract": "Effective planning is essential for the success of any task, from organizing\na vacation to routing autonomous vehicles and developing corporate strategies.\nIt involves setting goals, formulating plans, and allocating resources to\nachieve them. LLMs are particularly well-suited for automated planning due to\ntheir strong capabilities in commonsense reasoning. They can deduce a sequence\nof actions needed to achieve a goal from a given state and identify an\neffective course of action. However, it is frequently observed that plans\ngenerated through direct prompting often fail upon execution. Our survey aims\nto highlight the existing challenges in planning with language models, focusing\non key areas such as embodied environments, optimal scheduling, competitive and\ncooperative games, task decomposition, reasoning, and planning. Through this\nstudy, we explore how LLMs transform AI planning and provide unique insights\ninto the future of LM-assisted planning.",
      "tldr_zh": "这篇论文LASP调查了大型语言模型（LLMs）在AI规划中的最新进展，强调了LLMs在常识推理方面的优势，使其适用于自动化规划，如目标设定、行动序列推导和资源分配。论文指出了直接提示生成的计划常在执行中失败，并聚焦于关键挑战领域，包括具身环境、最优调度、竞争与合作游戏、任务分解、推理和规划。最终，该研究探讨了LLMs如何革新AI规划，并为LLMs辅助规划的未来发展提供了宝贵见解。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.01806v1",
      "published_date": "2024-09-03 11:39:52 UTC",
      "updated_date": "2024-09-03 11:39:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:04:52.020824"
    },
    {
      "arxiv_id": "2409.01790v2",
      "title": "Training on the Benchmark Is Not All You Need",
      "title_zh": "在基准测试上训练并非全部所需",
      "authors": [
        "Shiwen Ni",
        "Xiangtao Kong",
        "Chengming Li",
        "Xiping Hu",
        "Ruifeng Xu",
        "Jia Zhu",
        "Min Yang"
      ],
      "abstract": "The success of Large Language Models (LLMs) relies heavily on the huge amount\nof pre-training data learned in the pre-training phase. The opacity of the\npre-training process and the training data causes the results of many benchmark\ntests to become unreliable. If any model has been trained on a benchmark test\nset, it can seriously hinder the health of the field. In order to automate and\nefficiently test the capabilities of large language models, numerous mainstream\nbenchmarks adopt a multiple-choice format. As the swapping of the contents of\nmultiple-choice options does not affect the meaning of the question itself, we\npropose a simple and effective data leakage detection method based on this\nproperty. Specifically, we shuffle the contents of the options in the data to\ngenerate the corresponding derived data sets, and then detect data leakage\nbased on the model's log probability distribution over the derived data sets.\nIf there is a maximum and outlier in the set of log probabilities, it indicates\nthat the data is leaked. Our method is able to work under gray-box conditions\nwithout access to model training data or weights, effectively identifying data\nleakage from benchmark test sets in model pre-training data, including both\nnormal scenarios and complex scenarios where options may have been shuffled\nintentionally or unintentionally. Through experiments based on two LLMs and\nbenchmark designs, we demonstrate the effectiveness of our method. In addition,\nwe evaluate the degree of data leakage of 35 mainstream open-source LLMs on\nfour benchmark datasets and give a ranking of the leaked LLMs for each\nbenchmark, and we find that the Qwen family of LLMs has the highest degree of\ndata leakage.",
      "tldr_zh": "本论文指出，大型语言模型 (LLMs) 的预训练数据不透明可能导致基准测试结果不可靠，尤其是如果模型已在基准测试集上训练过，会损害领域健康。作者提出了一种简单有效的检测方法：通过打乱多选题选项生成派生数据集，并基于模型的对数概率分布分析是否存在异常峰值来识别数据泄露，该方法可在灰盒条件下运作，无需访问模型训练数据或权重。实验验证了方法的有效性，并在35个开源LLMs上评估了四个基准数据集的泄露程度，结果显示Qwen系列LLMs的泄露程度最高，并提供了相应排名。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.01790v2",
      "published_date": "2024-09-03 11:09:44 UTC",
      "updated_date": "2025-02-28 02:40:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:05:01.133811"
    },
    {
      "arxiv_id": "2409.04465v1",
      "title": "Here's Charlie! Realising the Semantic Web vision of Agents in the age of LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Jesse Wright"
      ],
      "abstract": "This paper presents our research towards a near-term future in which legal\nentities, such as individuals and organisations can entrust semi-autonomous\nAI-driven agents to carry out online interactions on their behalf. The author's\nresearch concerns the development of semi-autonomous Web agents, which consult\nusers if and only if the system does not have sufficient context or confidence\nto proceed working autonomously. This creates a user-agent dialogue that allows\nthe user to teach the agent about the information sources they trust, their\ndata-sharing preferences, and their decision-making preferences. Ultimately,\nthis enables the user to maximise control over their data and decisions while\nretaining the convenience of using agents, including those driven by LLMs.\n  In view of developing near-term solutions, the research seeks to answer the\nquestion: \"How do we build a trustworthy and reliable network of\nsemi-autonomous agents which represent individuals and organisations on the\nWeb?\". After identifying key requirements, the paper presents a demo for a\nsample use case of a generic personal assistant. This is implemented using\n(Notation3) rules to enforce safety guarantees around belief, data sharing and\ndata usage and LLMs to allow natural language interaction with users and\nserendipitous dialogues between software agents.",
      "tldr_zh": "该论文探讨了在LLMs时代实现语义网(Semantic Web)愿景，即个人和组织使用半自治AI驱动代理进行在线互动。研究提出了一种代理系统，仅在缺乏足够上下文或信心时咨询用户，从而通过用户-代理对话教导代理关于可信信息源、数据共享偏好和决策偏好。最终目标是让用户最大化对数据和决策的控制，同时享受代理的便利。论文通过识别关键要求，并使用Notation3规则确保信念、数据共享和使用的安全保障，以及LLMs实现自然语言交互和代理间对话，演示了一个通用个人助理的样例用例。总的来说，这为构建可信赖的半自治代理网络提供了近期的可行框架。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "The 23rd International Semantic Web Conference, November 11--15,\n  2024, Hanover, MD - Posters and Demos track",
      "pdf_url": "http://arxiv.org/pdf/2409.04465v1",
      "published_date": "2024-09-03 10:32:47 UTC",
      "updated_date": "2024-09-03 10:32:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:05:12.519306"
    },
    {
      "arxiv_id": "2409.03793v3",
      "title": "Safeguarding AI Agents: Developing and Analyzing Safety Architectures",
      "title_zh": "保障 AI 代理：开发与分析安全架构",
      "authors": [
        "Ishaan Domkundwar",
        "Mukunda N S",
        "Ishaan Bhola",
        "Riddhik Kochhar"
      ],
      "abstract": "AI agents, specifically powered by large language models, have demonstrated\nexceptional capabilities in various applications where precision and efficacy\nare necessary. However, these agents come with inherent risks, including the\npotential for unsafe or biased actions, vulnerability to adversarial attacks,\nlack of transparency, and tendency to generate hallucinations. As AI agents\nbecome more prevalent in critical sectors of the industry, the implementation\nof effective safety protocols becomes increasingly important. This paper\naddresses the critical need for safety measures in AI systems, especially ones\nthat collaborate with human teams. We propose and evaluate three frameworks to\nenhance safety protocols in AI agent systems: an LLM-powered input-output\nfilter, a safety agent integrated within the system, and a hierarchical\ndelegation-based system with embedded safety checks. Our methodology involves\nimplementing these frameworks and testing them against a set of unsafe agentic\nuse cases, providing a comprehensive evaluation of their effectiveness in\nmitigating risks associated with AI agent deployment. We conclude that these\nframeworks can significantly strengthen the safety and security of AI agent\nsystems, minimizing potential harmful actions or outputs. Our work contributes\nto the ongoing effort to create safe and reliable AI applications, particularly\nin automated operations, and provides a foundation for developing robust\nguardrails to ensure the responsible use of AI agents in real-world\napplications.",
      "tldr_zh": "本论文探讨了AI代理（由大语言模型驱动）的安全风险，包括不安全行为、偏见、易受攻击和产生幻觉等问题，并强调了在关键行业中实施安全协议的必要性。研究提出三种框架来提升AI系统安全性：LLM-powered input-output filter、安全代理集成，以及带有嵌入安全检查的层次化委托系统。这些框架通过针对不安全用例的测试，证明了其在减少有害行为方面的有效性，最终为创建可靠的AI应用，特别是自动化操作，提供了一个坚实基础。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.03793v3",
      "published_date": "2024-09-03 10:14:51 UTC",
      "updated_date": "2025-02-28 22:26:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:05:25.951168"
    },
    {
      "arxiv_id": "2409.01754v1",
      "title": "Empirical evidence of Large Language Model's influence on human spoken communication",
      "title_zh": "翻译失败",
      "authors": [
        "Hiromu Yakura",
        "Ezequiel Lopez-Lopez",
        "Levin Brinkmann",
        "Ignacio Serna",
        "Prateek Gupta",
        "Iyad Rahwan"
      ],
      "abstract": "Artificial Intelligence (AI) agents now interact with billions of humans in\nnatural language, thanks to advances in Large Language Models (LLMs) like\nChatGPT. This raises the question of whether AI has the potential to shape a\nfundamental aspect of human culture: the way we speak. Recent analyses revealed\nthat scientific publications already exhibit evidence of AI-specific language.\nBut this evidence is inconclusive, since scientists may simply be using AI to\ncopy-edit their writing. To explore whether AI has influenced human spoken\ncommunication, we transcribed and analyzed about 280,000 English-language\nvideos of presentations, talks, and speeches from more than 20,000 YouTube\nchannels of academic institutions. We find a significant shift in the trend of\nword usage specific to words distinctively associated with ChatGPT following\nits release. These findings provide the first empirical evidence that humans\nincreasingly imitate LLMs in their spoken language. Our results raise societal\nand policy-relevant concerns about the potential of AI to unintentionally\nreduce linguistic diversity, or to be deliberately misused for mass\nmanipulation. They also highlight the need for further investigation into the\nfeedback loops between machine behavior and human culture.",
      "tldr_zh": "本研究通过转录并分析约28万段英语YouTube视频演讲（来自2万多个学术频道），考察Large Language Models (LLMs)如ChatGPT对人类口语的影响。结果显示，ChatGPT发布后，与其相关的词语使用趋势显著增加，这提供了首个实证证据，表明人类在口语中越来越模仿LLMs。这些发现引发社会和政策担忧，可能导致语言多样性减少或被用于大规模操纵，并强调需要进一步调查AI与人类文化之间的反馈循环。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.CL",
        "cs.HC"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.01754v1",
      "published_date": "2024-09-03 10:01:51 UTC",
      "updated_date": "2024-09-03 10:01:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:05:37.048627"
    },
    {
      "arxiv_id": "2409.02148v1",
      "title": "Optimal Power Grid Operations with Foundation Models",
      "title_zh": "翻译失败",
      "authors": [
        "Alban Puech",
        "Jonas Weiss",
        "Thomas Brunschwiler",
        "Hendrik F. Hamann"
      ],
      "abstract": "The energy transition, crucial for tackling the climate crisis, demands\nintegrating numerous distributed, renewable energy sources into existing grids.\nAlong with climate change and consumer behavioral changes, this leads to\nchanges and variability in generation and load patterns, introducing\nsignificant complexity and uncertainty into grid planning and operations. While\nthe industry has already started to exploit AI to overcome computational\nchallenges of established grid simulation tools, we propose the use of AI\nFoundation Models (FMs) and advances in Graph Neural Networks to efficiently\nexploit poorly available grid data for different downstream tasks, enhancing\ngrid operations. For capturing the grid's underlying physics, we believe that\nbuilding a self-supervised model learning the power flow dynamics is a critical\nfirst step towards developing an FM for the power grid. We show how this\napproach may close the gap between the industry needs and current grid analysis\ncapabilities, to bring the industry closer to optimal grid operation and\nplanning.",
      "tldr_zh": "本文提出利用 AI Foundation Models (FMs) 和 Graph Neural Networks (GNNs) 来优化电力网格操作，应对能源转型带来的分布式可再生能源整合、气候变化及消费者行为变化所引发的复杂性和不确定性。通过构建自监督模型学习电力流动动态，该方法能高效利用有限的电网数据，支持各种下游任务。实验表明，这种方法有望填补行业需求与当前分析能力的差距，推动更高效的电网规划和操作。",
      "categories": [
        "eess.SY",
        "cs.AI",
        "cs.LG",
        "cs.SY",
        "math.OC"
      ],
      "primary_category": "eess.SY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.02148v1",
      "published_date": "2024-09-03 09:06:13 UTC",
      "updated_date": "2024-09-03 09:06:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:05:49.417280"
    },
    {
      "arxiv_id": "2409.01713v2",
      "title": "Interpreting Outliers in Time Series Data through Decoding Autoencoder",
      "title_zh": "通过解码自动编码器解释时间序列数据中的异常值",
      "authors": [
        "Patrick Knab",
        "Sascha Marton",
        "Christian Bartelt",
        "Robert Fuder"
      ],
      "abstract": "Outlier detection is a crucial analytical tool in various fields. In critical\nsystems like manufacturing, malfunctioning outlier detection can be costly and\nsafety-critical. Therefore, there is a significant need for explainable\nartificial intelligence (XAI) when deploying opaque models in such\nenvironments. This study focuses on manufacturing time series data from a\nGerman automotive supply industry. We utilize autoencoders to compress the\nentire time series and then apply anomaly detection techniques to its latent\nfeatures. For outlier interpretation, we (i) adopt widely used XAI techniques\nto the autoencoder's encoder. Additionally, (ii) we propose AEE, Aggregated\nExplanatory Ensemble, a novel approach that fuses explanations of multiple XAI\ntechniques into a single, more expressive interpretation. For evaluation of\nexplanations, (iii) we propose a technique to measure the quality of encoder\nexplanations quantitatively. Furthermore, we qualitatively assess the\neffectiveness of outlier explanations with domain expertise.",
      "tldr_zh": "这篇论文针对制造业时间序列数据，提出一种基于 autoencoders 的异常检测方法，以解决不透明模型在关键系统中的解释需求。研究方法包括将常见的 XAI（可解释人工智能）技术应用于 autoencoder 的编码器，并引入 AEE（Aggregated Explanatory Ensemble）——一种将多个 XAI 技术融合成更具表现力的解释框架。论文还贡献了量化评估编码器解释质量的新技术，并通过领域专家的定性评估验证了异常解释的有效性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "14 pages, 8 figures, accepted at TempXAI @ ECML-PKDD, published in\n  CEUR Workshop Proceedings, Vol. 3761. https://ceur-ws.org/Vol-3761/paper3.pdf",
      "pdf_url": "http://arxiv.org/pdf/2409.01713v2",
      "published_date": "2024-09-03 08:52:21 UTC",
      "updated_date": "2025-02-03 10:56:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:06:02.211191"
    },
    {
      "arxiv_id": "2409.01695v1",
      "title": "USTC-KXDIGIT System Description for ASVspoof5 Challenge",
      "title_zh": "翻译失败",
      "authors": [
        "Yihao Chen",
        "Haochen Wu",
        "Nan Jiang",
        "Xiang Xia",
        "Qing Gu",
        "Yunqi Hao",
        "Pengfei Cai",
        "Yu Guan",
        "Jialong Wang",
        "Weilin Xie",
        "Lei Fang",
        "Sian Fang",
        "Yan Song",
        "Wu Guo",
        "Lin Liu",
        "Minqiang Xu"
      ],
      "abstract": "This paper describes the USTC-KXDIGIT system submitted to the ASVspoof5\nChallenge for Track 1 (speech deepfake detection) and Track 2 (spoofing-robust\nautomatic speaker verification, SASV). Track 1 showcases a diverse range of\ntechnical qualities from potential processing algorithms and includes both open\nand closed conditions. For these conditions, our system consists of a cascade\nof a frontend feature extractor and a back-end classifier. We focus on\nextensive embedding engineering and enhancing the generalization of the\nback-end classifier model. Specifically, the embedding engineering is based on\nhand-crafted features and speech representations from a self-supervised model,\nused for closed and open conditions, respectively. To detect spoof attacks\nunder various adversarial conditions, we trained multiple systems on an\naugmented training set. Additionally, we used voice conversion technology to\nsynthesize fake audio from genuine audio in the training set to enrich the\nsynthesis algorithms. To leverage the complementary information learned by\ndifferent model architectures, we employed activation ensemble and fused scores\nfrom different systems to obtain the final decision score for spoof detection.\nDuring the evaluation phase, the proposed methods achieved 0.3948 minDCF and\n14.33% EER in the close condition, and 0.0750 minDCF and 2.59% EER in the open\ncondition, demonstrating the robustness of our submitted systems under\nadversarial conditions. In Track 2, we continued using the CM system from Track\n1 and fused it with a CNN-based ASV system. This approach achieved 0.2814\nmin-aDCF in the closed condition and 0.0756 min-aDCF in the open condition,\nshowcasing superior performance in the SASV system.",
      "tldr_zh": "本论文介绍了USTC-KXDIGIT系统，提交给ASVspoof5挑战赛的Track 1（语音深度伪造检测）和Track 2（spoofing-robust自动说话者验证，SASV），旨在提升语音欺骗检测的鲁棒性。系统采用前端特征提取器和后端分类器，结合手工特征、self-supervised模型的语音表示、增强训练集以及语音转换技术合成假音频，并通过激活集成和分数融合来整合多系统信息以提高泛化能力。在Track 1实验中，封闭条件下minDCF为0.3948和EER为14.33%，开放条件下minDCF为0.0750和EER为2.59%；在Track 2中，通过融合CNN-based ASV系统，封闭条件下min-aDCF为0.2814，开放条件下为0.0756，展示了系统的出色性能。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "ASVspoof5 workshop paper",
      "pdf_url": "http://arxiv.org/pdf/2409.01695v1",
      "published_date": "2024-09-03 08:28:58 UTC",
      "updated_date": "2024-09-03 08:28:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:06:18.674285"
    },
    {
      "arxiv_id": "2409.12979v1",
      "title": "Can we only use guideline instead of shot in prompt?",
      "title_zh": "翻译失败",
      "authors": [
        "Jiaxiang Chen",
        "Song Wang",
        "Zhucong Li",
        "Wayne Xiong",
        "Lizhen Qu",
        "Zenglin Xu",
        "Yuan Qi"
      ],
      "abstract": "Currently, prompting techniques can be mainly divided into two\ncategories:1)shot method implicitly inspires the model to answer the question\nby mimicing the steps in the given example, e.g., the few-shot CoT. 2)\nGuideline method explicitly instructs the model to reason by following\nguidelines, which contains succinct and concise task-specific knowledge. Shot\nmethod is prone to difficulties in terms of selection of shots type, the number\nof shots, and the design of the reasoning steps, so a question arises: can we\nonly use guideline instead of shot in the prompt? To this end, we propose the\nFGT framework to automatically learn task-specific guidelines from dataset\nconsisting of Feedback, Guideline, and Tree-gather agents. First, the feedback\nagent is designed to evaluate the outcomes, both right and wrong, of each Q&A\nto gather insights guiding more effective optimization strategies. Next, the\nguideline agent is tasked with deriving guidelines from each piece of feedback\nand storing them in local memory. Lastly, the tree-gather agent aggregates all\nguidelines hierarchically through a tree structure, ultimately obtaining all\nunduplicated guidelines from a global perspective. In addition, we induce the\nmodel to generate intermediate processes to ensure the reasoning consistent\nwith the guidelines. Experimental results demonstrate that our approach\nachieves superior performance across multiple tasks, thereby highlighting the\neffectiveness of using the guidelines in prompt.",
      "tldr_zh": "该研究探讨了是否能用指导性提示(guideline method)取代示例提示(shot method)，以避免后者在选择示例类型、数量和设计步骤等方面的难题。作者提出FGT框架，通过Feedback agent评估Q&A结果、Guideline agent从反馈中提取并存储任务特定指导方针，以及Tree-gather agent通过树结构层次化聚合全局去重指导方针，来自动学习优化提示。实验结果显示，FGT框架在多个任务上表现出色，证明了仅使用guideline在提示中能实现更有效的推理性能。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.12979v1",
      "published_date": "2024-09-03 08:14:55 UTC",
      "updated_date": "2024-09-03 08:14:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:06:29.313891"
    },
    {
      "arxiv_id": "2409.01688v3",
      "title": "Differentially Private Kernel Density Estimation",
      "title_zh": "差分隐私核密度估计",
      "authors": [
        "Erzhi Liu",
        "Jerry Yao-Chieh Hu",
        "Alex Reneau",
        "Zhao Song",
        "Han Liu"
      ],
      "abstract": "We introduce a refined differentially private (DP) data structure for kernel\ndensity estimation (KDE), offering not only improved privacy-utility tradeoff\nbut also better efficiency over prior results. Specifically, we study the\nmathematical problem: given a similarity function $f$ (or DP KDE) and a private\ndataset $X \\subset \\mathbb{R}^d$, our goal is to preprocess $X$ so that for any\nquery $y\\in\\mathbb{R}^d$, we approximate $\\sum_{x \\in X} f(x, y)$ in a\ndifferentially private fashion. The best previous algorithm for $f(x,y) =\\| x -\ny \\|_1$ is the node-contaminated balanced binary tree by [Backurs, Lin,\nMahabadi, Silwal, and Tarnawski, ICLR 2024]. Their algorithm requires $O(nd)$\nspace and time for preprocessing with $n=|X|$. For any query point, the query\ntime is $d \\log n$, with an error guarantee of $(1+\\alpha)$-approximation and\n$\\epsilon^{-1} \\alpha^{-0.5} d^{1.5} R \\log^{1.5} n$.\n  In this paper, we improve the best previous result [Backurs, Lin, Mahabadi,\nSilwal, and Tarnawski, ICLR 2024] in three aspects:\n  - We reduce query time by a factor of $\\alpha^{-1} \\log n$.\n  - We improve the approximation ratio from $\\alpha$ to 1.\n  - We reduce the error dependence by a factor of $\\alpha^{-0.5}$.\n  From a technical perspective, our method of constructing the search tree\ndiffers from previous work [Backurs, Lin, Mahabadi, Silwal, and Tarnawski, ICLR\n2024]. In prior work, for each query, the answer is split into $\\alpha^{-1}\n\\log n$ numbers, each derived from the summation of $\\log n$ values in interval\ntree countings. In contrast, we construct the tree differently, splitting the\nanswer into $\\log n$ numbers, where each is a smart combination of two distance\nvalues, two counting values, and $y$ itself. We believe our tree structure may\nbe of independent interest.",
      "tldr_zh": "该论文提出了一种改进的差分隐私（DP）数据结构，用于核密度估计（KDE），旨在优化隐私-实用性权衡和计算效率。针对给定相似函数f和私有数据集X，研究开发了一种新预处理方法，能在查询点y时近似计算∑f(x, y)，并将查询时间减少因子α^{-1} log n，同时将近似比从(1+α)提升至1，并降低错误依赖因子α^{-0.5}。通过构建一种新型搜索树结构，将答案拆分为log n个智能组合的数字（包括两个距离值、两个计数值和y本身），该结构不仅提高了性能，还可能具有独立的研究价值。",
      "categories": [
        "cs.DS",
        "cs.AI",
        "cs.LG",
        "stat.ML"
      ],
      "primary_category": "cs.DS",
      "comment": "v2: Appendix added. v3: Numerical validations added",
      "pdf_url": "http://arxiv.org/pdf/2409.01688v3",
      "published_date": "2024-09-03 08:01:19 UTC",
      "updated_date": "2025-03-24 00:13:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:06:39.489030"
    },
    {
      "arxiv_id": "2409.01679v2",
      "title": "Adaptive Explicit Knowledge Transfer for Knowledge Distillation",
      "title_zh": "自适应显式知识转移用于知识蒸馏",
      "authors": [
        "Hyungkeun Park",
        "Jong-Seok Lee"
      ],
      "abstract": "Logit-based knowledge distillation (KD) for classification is cost-efficient\ncompared to feature-based KD but often subject to inferior performance.\nRecently, it was shown that the performance of logit-based KD can be improved\nby effectively delivering the probability distribution for the non-target\nclasses from the teacher model, which is known as `implicit (dark) knowledge',\nto the student model. Through gradient analysis, we first show that this\nactually has an effect of adaptively controlling the learning of implicit\nknowledge. Then, we propose a new loss that enables the student to learn\nexplicit knowledge (i.e., the teacher's confidence about the target class)\nalong with implicit knowledge in an adaptive manner. Furthermore, we propose to\nseparate the classification and distillation tasks for effective distillation\nand inter-class relationship modeling. Experimental results demonstrate that\nthe proposed method, called adaptive explicit knowledge transfer (AEKT) method,\nachieves improved performance compared to the state-of-the-art KD methods on\nthe CIFAR-100 and ImageNet datasets.",
      "tldr_zh": "本论文针对基于 logit 的知识蒸馏（KD）方法，虽然高效但性能较差的问题，通过梯度分析揭示了传递隐式知识（教师模型对非目标类的概率分布）能自适应地控制知识学习。作者提出了一种新的自适应显式知识转移（AEKT）方法，包括一个损失函数，用于让学生模型同时自适应地学习显式知识（教师对目标类的置信度）和隐式知识，并将分类任务与蒸馏任务分离，以提升蒸馏效率和类间关系建模。实验结果显示，AEKT 在 CIFAR-100 和 ImageNet 数据集上比现有最先进 KD 方法取得了更好的性能。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "19 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2409.01679v2",
      "published_date": "2024-09-03 07:42:59 UTC",
      "updated_date": "2024-09-05 07:44:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:06:52.636527"
    },
    {
      "arxiv_id": "2409.01676v1",
      "title": "Classifier-Free Diffusion-Based Weakly-Supervised Approach for Health Indicator Derivation in Rotating Machines: Advancing Early Fault Detection and Condition Monitoring",
      "title_zh": "无分类器基于扩散的弱监督方法，用于旋转机器健康指标推导：推进早期故障检测和状态监测",
      "authors": [
        "Wenyang Hu",
        "Gaetan Frusque",
        "Tianyang Wang",
        "Fulei Chu",
        "Olga Fink"
      ],
      "abstract": "Deriving health indicators of rotating machines is crucial for their\nmaintenance. However, this process is challenging for the prevalent adopted\nintelligent methods since they may take the whole data distributions, not only\nintroducing noise interference but also lacking the explainability. To address\nthese issues, we propose a diffusion-based weakly-supervised approach for\nderiving health indicators of rotating machines, enabling early fault detection\nand continuous monitoring of condition evolution. This approach relies on a\nclassifier-free diffusion model trained using healthy samples and a few\nanomalies. This model generates healthy samples. and by comparing the\ndifferences between the original samples and the generated ones in the envelope\nspectrum, we construct an anomaly map that clearly identifies faults. Health\nindicators are then derived, which can explain the fault types and mitigate\nnoise interference. Comparative studies on two cases demonstrate that the\nproposed method offers superior health monitoring effectiveness and robustness\ncompared to baseline models.",
      "tldr_zh": "本研究提出了一种基于 classifier-free diffusion 模型的弱监督方法，用于从旋转机械中提取健康指标，以提升早期故障检测和条件监测能力。该方法仅使用健康样本和少量异常样本训练模型，生成健康样本并通过比较原始样本与生成样本在包络谱中的差异，构建异常地图来识别故障类型并减少噪声干扰。与传统方法相比，这种弱监督策略提高了解释性和鲁棒性。在两个实际案例的比较研究中，该方法显示出比基线模型更优异的健康监测效果和稳定性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "eess.SP"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.01676v1",
      "published_date": "2024-09-03 07:41:55 UTC",
      "updated_date": "2024-09-03 07:41:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:07:02.982070"
    },
    {
      "arxiv_id": "2409.02145v1",
      "title": "A Multimodal Object-level Contrast Learning Method for Cancer Survival Risk Prediction",
      "title_zh": "一种多模态对象级对比学习方法用于癌症生存风险预测",
      "authors": [
        "Zekang Yang",
        "Hong Liu",
        "Xiangdong Wang"
      ],
      "abstract": "Computer-aided cancer survival risk prediction plays an important role in the\ntimely treatment of patients. This is a challenging weakly supervised ordinal\nregression task associated with multiple clinical factors involved such as\npathological images, genomic data and etc. In this paper, we propose a new\ntraining method, multimodal object-level contrast learning, for cancer survival\nrisk prediction. First, we construct contrast learning pairs based on the\nsurvival risk relationship among the samples in the training sample set. Then\nwe introduce the object-level contrast learning method to train the survival\nrisk predictor. We further extend it to the multimodal scenario by applying\ncross-modal constrast. Considering the heterogeneity of pathological images and\ngenomics data, we construct a multimodal survival risk predictor employing\nattention-based and self-normalizing based nerural network respectively.\nFinally, the survival risk predictor trained by our proposed method outperforms\nstate-of-the-art methods on two public multimodal cancer datasets for survival\nrisk prediction.",
      "tldr_zh": "该论文提出了一种多模态对象-level contrast learning方法，用于计算机辅助癌症生存风险预测，这是一个涉及弱监督序数回归的挑战性任务，整合了病理图像、基因组数据等临床因素。首先，方法通过基于样本生存风险关系的对比学习对构建，并引入对象-level contrast learning来训练预测器，同时扩展到多模态场景使用跨模态对比。针对病理图像和基因组数据的异质性，论文构建了基于注意力机制和自归一化神经网络的多模态生存风险预测器。实验结果显示，该方法在两个公共多模态癌症数据集上优于最先进方法，显著提升了预测性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.02145v1",
      "published_date": "2024-09-03 07:36:34 UTC",
      "updated_date": "2024-09-03 07:36:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:07:15.776754"
    },
    {
      "arxiv_id": "2409.01672v2",
      "title": "Enhancing Fine-Grained Visual Recognition in the Low-Data Regime Through Feature Magnitude Regularization",
      "title_zh": "翻译失败",
      "authors": [
        "Avraham Chapman",
        "Haiming Xu",
        "Lingqiao Liu"
      ],
      "abstract": "Training a fine-grained image recognition model with limited data presents a\nsignificant challenge, as the subtle differences between categories may not be\neasily discernible amidst distracting noise patterns. One commonly employed\nstrategy is to leverage pretrained neural networks, which can generate\neffective feature representations for constructing an image classification\nmodel with a restricted dataset. However, these pretrained neural networks are\ntypically trained for different tasks than the fine-grained visual recognition\n(FGVR) task at hand, which can lead to the extraction of less relevant\nfeatures. Moreover, in the context of building FGVR models with limited data,\nthese irrelevant features can dominate the training process, overshadowing more\nuseful, generalizable discriminative features. Our research has identified a\nsurprisingly simple solution to this challenge: we introduce a regularization\ntechnique to ensure that the magnitudes of the extracted features are evenly\ndistributed. This regularization is achieved by maximizing the uniformity of\nfeature magnitude distribution, measured through the entropy of the normalized\nfeatures. The motivation behind this regularization is to remove bias in\nfeature magnitudes from pretrained models, where some features may be more\nprominent and, consequently, more likely to be used for classification.\nAdditionally, we have developed a dynamic weighting mechanism to adjust the\nstrength of this regularization throughout the learning process. Despite its\napparent simplicity, our approach has demonstrated significant performance\nimprovements across various fine-grained visual recognition datasets.",
      "tldr_zh": "这篇论文针对低数据环境下细粒度图像识别（Fine-Grained Visual Recognition, FGVR）的挑战，提出了一种特征幅度正则化技术，以确保从预训练神经网络提取的特征幅度均匀分布，从而减少无关特征的干扰。方法通过最大化归一化特征的熵来实现这一正则化，并引入动态加权机制来调整训练过程中的正则化强度。该技术显著提升了模型在各种FGVR数据集上的性能，证明了其简单有效的潜力。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.01672v2",
      "published_date": "2024-09-03 07:32:46 UTC",
      "updated_date": "2024-09-07 05:36:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:07:28.095559"
    },
    {
      "arxiv_id": "2409.04464v2",
      "title": "Leveraging Large Language Models for Solving Rare MIP Challenges",
      "title_zh": "利用大型语言模型解决稀有混合整数规划挑战",
      "authors": [
        "Teng Wang",
        "Wing-Yin Yu",
        "Ruifeng She",
        "Wenhan Yang",
        "Taijie Chen",
        "Jianping Zhang"
      ],
      "abstract": "Mixed Integer Programming (MIP) has been extensively applied in areas\nrequiring mathematical solvers to address complex instances within tight time\nconstraints. However, as the problem scale increases, the complexity of model\nformulation and finding feasible solutions escalates significantly. In\ncontrast, the model-building cost for end-to-end models, such as large language\nmodels (LLMs), remains largely unaffected by problem scale due to their pattern\nrecognition capabilities. While LLMs, like GPT-4, without fine-tuning, can\nhandle some traditional medium-scale MIP problems, they struggle with uncommon\nor highly specialized MIP scenarios. Fine-tuning LLMs can yield some feasible\nsolutions for medium-scale MIP instances, but these models typically fail to\nexplore diverse solutions when constrained by a low and constant temperature,\nlimiting their performance. In this paper, we propose and evaluate a\nrecursively dynamic temperature method integrated with a chain-of-thought\napproach. Our findings show that starting with a high temperature and gradually\nlowering it leads to better feasible solutions compared to other dynamic\ntemperature strategies. Additionally, by comparing results generated by the LLM\nwith those from Gurobi, we demonstrate that the LLM can produce solutions that\ncomplement traditional solvers by accelerating the pruning process and\nimproving overall efficiency.",
      "tldr_zh": "这篇论文探讨了利用大语言模型（LLMs）解决混合整数规划（MIP）的罕见挑战，强调了LLMs在处理复杂大规模问题时的优势，同时指出了未经微调的LLMs在专业场景下的局限性。作者提出了一种递归动态温度方法，结合chain-of-thought策略，通过从高温度逐渐降低来探索更多样化的可行解决方案。实验结果显示，该方法优于其他动态温度策略，且LLMs生成的解决方案能与传统求解器如Gurobi互补，加速剪枝过程并提升整体效率。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG",
        "math.OC"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.04464v2",
      "published_date": "2024-09-03 07:25:01 UTC",
      "updated_date": "2024-09-18 07:43:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:07:41.386829"
    },
    {
      "arxiv_id": "2409.01668v3",
      "title": "Pureformer-VC: Non-parallel One-Shot Voice Conversion with Pure Transformer Blocks and Triplet Discriminative Training",
      "title_zh": "翻译失败",
      "authors": [
        "Wenhan Yao",
        "Zedong Xing",
        "Xiarun Chen",
        "Jia Liu",
        "Yongqiang He",
        "Weiping Wen"
      ],
      "abstract": "One-shot voice conversion(VC) aims to change the timbre of any source speech\nto match that of the target speaker with only one speech sample. Existing style\ntransfer-based VC methods relied on speech representation disentanglement and\nsuffered from accurately and independently encoding each speech component and\nrecomposing back to converted speech effectively. To tackle this, we proposed\nPureformer-VC, which utilizes Conformer blocks to build a disentangled encoder,\nand Zipformer blocks to build a style transfer decoder as the generator. In the\ndecoder, we used effective styleformer blocks to integrate speaker\ncharacteristics effectively into the generated speech. The models used the\ngenerative VAE loss for encoding components and triplet loss for unsupervised\ndiscriminative training. We applied the styleformer method to Zipformer's\nshared weights for style transfer. The experimental results show that the\nproposed model achieves comparable subjective scores and exhibits improvements\nin objective metrics compared to existing methods in a one-shot voice\nconversion scenario.",
      "tldr_zh": "本论文提出 Pureformer-VC 模型，用于非平行 One-shot voice conversion，仅需一个语音样本即可将源语音音色转换为目标说话者。模型采用 Conformer 块构建分离编码器、Zipformer 块构建风格转移解码器，并通过 styleformer 块有效整合说话者特征，同时使用生成 VAE 损失和 Triplet loss 进行无监督判别训练。实验结果表明，Pureformer-VC 在主观分数上与现有方法相当，并在客观指标上表现出显著改善。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "our paper is rejected",
      "pdf_url": "http://arxiv.org/pdf/2409.01668v3",
      "published_date": "2024-09-03 07:21:19 UTC",
      "updated_date": "2024-11-25 01:35:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:07:52.519996"
    },
    {
      "arxiv_id": "2409.01652v2",
      "title": "ReKep: Spatio-Temporal Reasoning of Relational Keypoint Constraints for Robotic Manipulation",
      "title_zh": "翻译失败",
      "authors": [
        "Wenlong Huang",
        "Chen Wang",
        "Yunzhu Li",
        "Ruohan Zhang",
        "Li Fei-Fei"
      ],
      "abstract": "Representing robotic manipulation tasks as constraints that associate the\nrobot and the environment is a promising way to encode desired robot behaviors.\nHowever, it remains unclear how to formulate the constraints such that they are\n1) versatile to diverse tasks, 2) free of manual labeling, and 3) optimizable\nby off-the-shelf solvers to produce robot actions in real-time. In this work,\nwe introduce Relational Keypoint Constraints (ReKep), a visually-grounded\nrepresentation for constraints in robotic manipulation. Specifically, ReKep is\nexpressed as Python functions mapping a set of 3D keypoints in the environment\nto a numerical cost. We demonstrate that by representing a manipulation task as\na sequence of Relational Keypoint Constraints, we can employ a hierarchical\noptimization procedure to solve for robot actions (represented by a sequence of\nend-effector poses in SE(3)) with a perception-action loop at a real-time\nfrequency. Furthermore, in order to circumvent the need for manual\nspecification of ReKep for each new task, we devise an automated procedure that\nleverages large vision models and vision-language models to produce ReKep from\nfree-form language instructions and RGB-D observations. We present system\nimplementations on a wheeled single-arm platform and a stationary dual-arm\nplatform that can perform a large variety of manipulation tasks, featuring\nmulti-stage, in-the-wild, bimanual, and reactive behaviors, all without\ntask-specific data or environment models. Website at\nhttps://rekep-robot.github.io/.",
      "tldr_zh": "该论文提出了 Relational Keypoint Constraints (ReKep)，一种基于视觉的约束表示，用于机器人操作任务，能够灵活适应多样化场景并避免手动标注。ReKep 通过 Python 函数将环境中的 3D 关键点映射为数值成本，并结合分层优化过程（如求解端效应器位姿序列 in SE(3)）实现实时感知-动作循环。作者开发了自动化方法，利用大型视觉模型和视觉语言模型，从自由形式语言指令及 RGB-D 观察生成 ReKep。实验在轮式单臂和固定双臂平台上展示了系统的多阶段、野外、双臂和反应性操作能力，无需任务特定数据或环境模型。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.01652v2",
      "published_date": "2024-09-03 06:45:22 UTC",
      "updated_date": "2024-11-12 04:33:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:08:05.476955"
    },
    {
      "arxiv_id": "2409.07482v1",
      "title": "VSLLaVA: a pipeline of large multimodal foundation model for industrial vibration signal analysis",
      "title_zh": "VSLLaVA",
      "authors": [
        "Qi Li",
        "Jinfeng Huang",
        "Hongliang He",
        "Xinran Zhang",
        "Feibin Zhang",
        "Zhaoye Qin",
        "Fulei Chu"
      ],
      "abstract": "Large multimodal foundation models have been extensively utilized for image\nrecognition tasks guided by instructions, yet there remains a scarcity of\ndomain expertise in industrial vibration signal analysis. This paper presents a\npipeline named VSLLaVA that leverages a large language model to integrate\nexpert knowledge for identification of signal parameters and diagnosis of\nfaults. Within this pipeline, we first introduce an expert rule-assisted signal\ngenerator. The generator merges signal provided by vibration analysis experts\nwith domain-specific parameter identification and fault diagnosis\nquestion-answer pairs to build signal-question-answer triplets. Then we use\nthese triplets to apply low-rank adaptation methods for fine-tuning the linear\nlayers of the Contrastive Language-Image Pretraining (CLIP) and large language\nmodel, injecting multimodal signal processing knowledge. Finally, the\nfine-tuned model is assessed through the combined efforts of large language\nmodel and expert rules to evaluate answer accuracy and relevance, which\nshowcases enhanced performance in identifying, analyzing various signal\nparameters, and diagnosing faults. These enhancements indicate the potential of\nthis pipeline to build a foundational model for future industrial signal\nanalysis and monitoring.",
      "tldr_zh": "该论文提出VSLLaVA，一种基于大型多模态基础模型的管道，用于工业振动信号分析，通过整合专家知识来提升信号参数识别和故障诊断能力。具体而言，该管道首先利用专家规则辅助信号生成器构建信号-问题-答案三元组，然后通过低-rank adaptation方法微调CLIP和大型语言模型的线性层，以注入多模态信号处理知识。实验评估显示，VSLLaVA在识别、分析信号参数和诊断故障方面表现出色，展示了其在未来工业信号分析和监测中构建基础模型的潜力。",
      "categories": [
        "eess.SP",
        "cs.AI"
      ],
      "primary_category": "eess.SP",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.07482v1",
      "published_date": "2024-09-03 06:21:26 UTC",
      "updated_date": "2024-09-03 06:21:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:08:20.402823"
    },
    {
      "arxiv_id": "2409.01635v1",
      "title": "PMLBmini: A Tabular Classification Benchmark Suite for Data-Scarce Applications",
      "title_zh": "翻译失败",
      "authors": [
        "Ricardo Knauer",
        "Marvin Grimm",
        "Erik Rodner"
      ],
      "abstract": "In practice, we are often faced with small-sized tabular data. However,\ncurrent tabular benchmarks are not geared towards data-scarce applications,\nmaking it very difficult to derive meaningful conclusions from empirical\ncomparisons. We introduce PMLBmini, a tabular benchmark suite of 44 binary\nclassification datasets with sample sizes $\\leq$ 500. We use our suite to\nthoroughly evaluate current automated machine learning (AutoML) frameworks,\noff-the-shelf tabular deep neural networks, as well as classical linear models\nin the low-data regime. Our analysis reveals that state-of-the-art AutoML and\ndeep learning approaches often fail to appreciably outperform even a simple\nlogistic regression baseline, but we also identify scenarios where AutoML and\ndeep learning methods are indeed reasonable to apply. Our benchmark suite,\navailable on https://github.com/RicardoKnauer/TabMini , allows researchers and\npractitioners to analyze their own methods and challenge their data efficiency.",
      "tldr_zh": "本文引入了 PMLBmini，这是一个针对数据稀缺应用的表格分类基准套件，包含 44 个样本大小不超过 500 的二元分类数据集，用于评估机器学习方法在低数据场景下的表现。研究者使用该套件比较了当前的 AutoML 框架、现成表格深度神经网络以及经典线性模型，如 logistic regression。结果显示，先进的 AutoML 和深度学习方法通常无法显著优于简单基线，但在特定场景下仍显示出优势。该基准套件可从 GitHub 获取，帮助研究者和从业者评估方法的 data efficiency。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "AutoML 2024 Workshop Track",
      "pdf_url": "http://arxiv.org/pdf/2409.01635v1",
      "published_date": "2024-09-03 06:13:03 UTC",
      "updated_date": "2024-09-03 06:13:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:08:32.196199"
    },
    {
      "arxiv_id": "2409.01633v3",
      "title": "Dreaming is All You Need",
      "title_zh": "翻译失败",
      "authors": [
        "Mingze Ni",
        "Wei Liu"
      ],
      "abstract": "In classification tasks, achieving a harmonious balance between exploration\nand precision is of paramount importance. To this end, this research introduces\ntwo novel deep learning models, SleepNet and DreamNet, to strike this balance.\nSleepNet seamlessly integrates supervised learning with unsupervised ``sleep\"\nstages using pre-trained encoder models. Dedicated neurons within SleepNet are\nembedded in these unsupervised features, forming intermittent ``sleep\" blocks\nthat facilitate exploratory learning. Building upon the foundation of SleepNet,\nDreamNet employs full encoder-decoder frameworks to reconstruct the hidden\nstates, mimicking the human \"dreaming\" process. This reconstruction process\nenables further exploration and refinement of the learned representations.\nMoreover, the principle ideas of our SleepNet and DreamNet are generic and can\nbe applied to both computer vision and natural language processing downstream\ntasks. Through extensive empirical evaluations on diverse image and text\ndatasets, SleepNet and DreanNet have demonstrated superior performance compared\nto state-of-the-art models, showcasing the strengths of unsupervised\nexploration and supervised precision afforded by our innovative approaches.",
      "tldr_zh": "该研究提出两种新型深度学习模型，SleepNet 和 DreamNet，用于分类任务，以平衡探索性和精确性。SleepNet 整合监督学习与无监督的“sleep”阶段，利用预训练编码器和专用神经元构建“sleep”块，促进探索性学习；DreamNet 则在 SleepNet 基础上采用全编码器-解码器框架重建隐藏状态，模拟人类“dreaming”过程，进一步精炼表示。两者均可泛化应用于计算机视觉和自然语言处理任务；实验结果显示，在多种图像和文本数据集上，SleepNet 和 DreamNet 超越了最先进模型，突显了无监督探索与监督精确性的优势。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.01633v3",
      "published_date": "2024-09-03 06:04:39 UTC",
      "updated_date": "2024-09-15 12:17:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:08:43.132245"
    },
    {
      "arxiv_id": "2409.15512v2",
      "title": "PixelBytes: Catching Unified Embedding for Multimodal Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Fabien Furfaro"
      ],
      "abstract": "This report introduces PixelBytes Embedding, a novel approach for unified\nmultimodal representation learning. Our method captures diverse inputs in a\nsingle, cohesive representation, enabling emergent properties for multimodal\nsequence generation, particularly for text and pixelated images. Inspired by\nstate-of-the-art sequence models such as Image Transformers, PixelCNN, and\nMamba-Bytes, PixelBytes aims to address the challenges of integrating different\ndata types. We explore various model architectures, including Recurrent Neural\nNetworks (RNNs), State Space Models (SSMs), and Attention-based models,\nfocusing on bidirectional processing and our innovative PxBy embedding\ntechnique. Our experiments, conducted on a specialized PixelBytes Pok{\\'e}mon\ndataset, demonstrate that bidirectional sequence models with PxBy embedding and\nconvolutional layers can generate coherent multimodal sequences. This work\ncontributes to the advancement of integrated AI models capable of understanding\nand generating multimodal data in a unified manner.",
      "tldr_zh": "本研究提出 PixelBytes Embedding，一种创新的多模态表示学习方法，用于在单一统一表示中捕捉文本和像素化图像等多样输入，从而实现多模态序列生成。方法受 Image Transformers、PixelCNN 和 Mamba-Bytes 等模型启发，探索 RNNs、SSMs 和 Attention-based 模型的架构，结合双向处理和 PxBy embedding 技术来解决不同数据类型整合的挑战。在 PixelBytes Pok{\\'e}mon 数据集上的实验显示，使用 PxBy embedding 和卷积层的双向序列模型能生成连贯的多模态序列，为开发集成 AI 模型提供重要进展，使其能够统一理解和生成多模态数据。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "This article is an earlier version of my work arXiv:2410.01820\n  \"PixelBytes: Catching Unified Representation for Multimodal Generation.\"",
      "pdf_url": "http://arxiv.org/pdf/2409.15512v2",
      "published_date": "2024-09-03 06:02:02 UTC",
      "updated_date": "2024-10-21 18:57:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:08:56.569967"
    },
    {
      "arxiv_id": "2409.01630v1",
      "title": "SafeEmbodAI: a Safety Framework for Mobile Robots in Embodied AI Systems",
      "title_zh": "SafeEmbodAI：针对具身AI系统中移动机器人的安全框架",
      "authors": [
        "Wenxiao Zhang",
        "Xiangrui Kong",
        "Thomas Braunl",
        "Jin B. Hong"
      ],
      "abstract": "Embodied AI systems, including AI-powered robots that autonomously interact\nwith the physical world, stand to be significantly advanced by Large Language\nModels (LLMs), which enable robots to better understand complex language\ncommands and perform advanced tasks with enhanced comprehension and\nadaptability, highlighting their potential to improve embodied AI capabilities.\nHowever, this advancement also introduces safety challenges, particularly in\nrobotic navigation tasks. Improper safety management can lead to failures in\ncomplex environments and make the system vulnerable to malicious command\ninjections, resulting in unsafe behaviours such as detours or collisions. To\naddress these issues, we propose \\textit{SafeEmbodAI}, a safety framework for\nintegrating mobile robots into embodied AI systems. \\textit{SafeEmbodAI}\nincorporates secure prompting, state management, and safety validation\nmechanisms to secure and assist LLMs in reasoning through multi-modal data and\nvalidating responses. We designed a metric to evaluate mission-oriented\nexploration, and evaluations in simulated environments demonstrate that our\nframework effectively mitigates threats from malicious commands and improves\nperformance in various environment settings, ensuring the safety of embodied AI\nsystems. Notably, In complex environments with mixed obstacles, our method\ndemonstrates a significant performance increase of 267\\% compared to the\nbaseline in attack scenarios, highlighting its robustness in challenging\nconditions.",
      "tldr_zh": "这篇论文提出 SafeEmbodAI 框架，用于提升 Embodied AI 系统中的移动机器人安全，解决 Large Language Models (LLMs) 在处理复杂语言命令时可能引发的导航失败和恶意命令注入问题。框架整合 secure prompting、state management 和 safety validation 机制，帮助 LLMs 安全地处理多模态数据并验证响应，同时设计了一个评估任务导向探索的指标。在模拟环境中，SafeEmbodAI 在复杂障碍混合场景下比基线模型性能提升 267%，有效缓解安全威胁并提高系统鲁棒性。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.ET"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.01630v1",
      "published_date": "2024-09-03 05:56:50 UTC",
      "updated_date": "2024-09-03 05:56:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:09:07.871823"
    },
    {
      "arxiv_id": "2409.01622v1",
      "title": "T1-contrast Enhanced MRI Generation from Multi-parametric MRI for Glioma Patients with Latent Tumor Conditioning",
      "title_zh": "翻译失败",
      "authors": [
        "Zach Eidex",
        "Mojtaba Safari",
        "Richard L. J. Qiu",
        "David S. Yu",
        "Hui-Kuo Shu",
        "Hui Mao",
        "Xiaofeng Yang"
      ],
      "abstract": "Objective: Gadolinium-based contrast agents (GBCAs) are commonly used in MRI\nscans of patients with gliomas to enhance brain tumor characterization using\nT1-weighted (T1W) MRI. However, there is growing concern about GBCA toxicity.\nThis study develops a deep-learning framework to generate T1-postcontrast (T1C)\nfrom pre-contrast multiparametric MRI. Approach: We propose the tumor-aware\nvision transformer (TA-ViT) model that predicts high-quality T1C images. The\npredicted tumor region is significantly improved (P < .001) by conditioning the\ntransformer layers from predicted segmentation maps through adaptive layer norm\nzero mechanism. The predicted segmentation maps were generated with the\nmulti-parametric residual (MPR) ViT model and transformed into a latent space\nto produce compressed, feature-rich representations. The TA-ViT model predicted\nT1C MRI images of 501 glioma cases. Selected patients were split into training\n(N=400), validation (N=50), and test (N=51) sets. Main Results: Both\nqualitative and quantitative results demonstrate that the TA-ViT model performs\nsuperior against the benchmark MRP-ViT model. Our method produces synthetic T1C\nMRI with high soft tissue contrast and more accurately reconstructs both the\ntumor and whole brain volumes. The synthesized T1C images achieved remarkable\nimprovements in both tumor and healthy tissue regions compared to the MRP-ViT\nmodel. For healthy tissue and tumor regions, the results were as follows: NMSE:\n8.53 +/- 4.61E-4; PSNR: 31.2 +/- 2.2; NCC: 0.908 +/- .041 and NMSE: 1.22 +/-\n1.27E-4, PSNR: 41.3 +/- 4.7, and NCC: 0.879 +/- 0.042, respectively.\nSignificance: The proposed method generates synthetic T1C images that closely\nresemble real T1C images. Future development and application of this approach\nmay enable contrast-agent-free MRI for brain tumor patients, eliminating the\nrisk of GBCA toxicity and simplifying the MRI scan protocol.",
      "tldr_zh": "本研究针对胶质瘤患者MRI扫描中Gadolinium-based contrast agents (GBCAs)的潜在毒性风险，开发了一种深度学习框架，使用多参数MRI生成T1-postcontrast (T1C)图像。研究提出tumor-aware vision transformer (TA-ViT)模型，通过从预测的分割地图（如由multi-parametric residual (MPR) ViT模型生成的）获取潜在空间特征，并应用adaptive layer norm zero机制，来显著改善肿瘤区域的图像预测质量。实验在501个胶质瘤病例上进行，结果显示TA-ViT模型在定性和定量指标（如NMSE: 8.53 +/- 4.61E-4, PSNR: 31.2 +/- 2.2, NCC: 0.908 +/- 0.041）上优于基准MPR-ViT模型，实现了更准确的肿瘤和大脑重建。该方法有望实现无对比剂MRI扫描，减少GBCA毒性并简化扫描协议。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "arXiv admin note: text overlap with arXiv:2407.02616",
      "pdf_url": "http://arxiv.org/pdf/2409.01622v1",
      "published_date": "2024-09-03 05:45:37 UTC",
      "updated_date": "2024-09-03 05:45:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:09:21.410591"
    },
    {
      "arxiv_id": "2409.01612v1",
      "title": "Lexicographic optimization-based approaches to learning a representative model for multi-criteria sorting with non-monotonic criteria",
      "title_zh": "翻译失败",
      "authors": [
        "Zhen Zhang",
        "Zhuolin Li",
        "Wenyu Yu"
      ],
      "abstract": "Deriving a representative model using value function-based methods from the\nperspective of preference disaggregation has emerged as a prominent and growing\ntopic in multi-criteria sorting (MCS) problems. A noteworthy observation is\nthat many existing approaches to learning a representative model for MCS\nproblems traditionally assume the monotonicity of criteria, which may not\nalways align with the complexities found in real-world MCS scenarios.\nConsequently, this paper proposes some approaches to learning a representative\nmodel for MCS problems with non-monotonic criteria through the integration of\nthe threshold-based value-driven sorting procedure. To do so, we first define\nsome transformation functions to map the marginal values and category\nthresholds into a UTA-like functional space. Subsequently, we construct\nconstraint sets to model non-monotonic criteria in MCS problems and develop\noptimization models to check and rectify the inconsistency of the decision\nmaker's assignment example preference information. By simultaneously\nconsidering the complexity and discriminative power of the models, two distinct\nlexicographic optimization-based approaches are developed to derive a\nrepresentative model for MCS problems with non-monotonic criteria. Eventually,\nwe offer an illustrative example and conduct comprehensive simulation\nexperiments to elaborate the feasibility and validity of the proposed\napproaches.",
      "tldr_zh": "本论文针对多标准排序（multi-criteria sorting, MCS）问题，提出基于词典优化（lexicographic optimization）的创新方法，以处理标准非单调（non-monotonic criteria）的实际挑战，克服传统方法的假设限制。研究首先定义转换函数将边际值和类别阈值映射到类似UTA的功能空间，并构建约束集来建模非单调标准，同时开发优化模型来检测和修正决策者偏好信息的矛盾。随后，通过两种不同的词典优化方法，论文同时考虑模型的复杂性和区分能力，学习出代表性模型。实验结果包括一个示例和全面模拟验证，证明了这些方法的可靠性和有效性。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "45 pages, 12 figures",
      "pdf_url": "http://arxiv.org/pdf/2409.01612v1",
      "published_date": "2024-09-03 05:29:05 UTC",
      "updated_date": "2024-09-03 05:29:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:09:31.522428"
    },
    {
      "arxiv_id": "2409.01610v1",
      "title": "Decompose the model: Mechanistic interpretability in image models with Generalized Integrated Gradients (GIG)",
      "title_zh": "翻译失败",
      "authors": [
        "Yearim Kim",
        "Sangyu Han",
        "Sangbum Han",
        "Nojun Kwak"
      ],
      "abstract": "In the field of eXplainable AI (XAI) in language models, the progression from\nlocal explanations of individual decisions to global explanations with\nhigh-level concepts has laid the groundwork for mechanistic interpretability,\nwhich aims to decode the exact operations. However, this paradigm has not been\nadequately explored in image models, where existing methods have primarily\nfocused on class-specific interpretations. This paper introduces a novel\napproach to systematically trace the entire pathway from input through all\nintermediate layers to the final output within the whole dataset. We utilize\nPointwise Feature Vectors (PFVs) and Effective Receptive Fields (ERFs) to\ndecompose model embeddings into interpretable Concept Vectors. Then, we\ncalculate the relevance between concept vectors with our Generalized Integrated\nGradients (GIG), enabling a comprehensive, dataset-wide analysis of model\nbehavior. We validate our method of concept extraction and concept attribution\nin both qualitative and quantitative evaluations. Our approach advances the\nunderstanding of semantic significance within image models, offering a holistic\nview of their operational mechanics.",
      "tldr_zh": "该论文探讨了图像模型中机械解释性（mechanistic interpretability）的应用，填补了现有方法主要聚焦于特定类别的解释而忽略全局分析的空白。研究引入了一种新方法，使用 Pointwise Feature Vectors (PFVs) 和 Effective Receptive Fields (ERFs) 来分解模型嵌入成可解释的 Concept Vectors，并通过 Generalized Integrated Gradients (GIG) 计算概念向量之间的相关性，实现对整个数据集从输入到输出的系统性追踪。定性和定量评估验证了该方法的有效性，提升了对图像模型语义意义和整体操作机制的理解，为 eXplainable AI (XAI) 在视觉领域的进展提供了新视角。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.01610v1",
      "published_date": "2024-09-03 05:19:35 UTC",
      "updated_date": "2024-09-03 05:19:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:09:44.520765"
    },
    {
      "arxiv_id": "2409.01605v1",
      "title": "Laser: Parameter-Efficient LLM Bi-Tuning for Sequential Recommendation with Collaborative Information",
      "title_zh": "翻译失败",
      "authors": [
        "Xinyu Zhang",
        "Linmei Hu",
        "Luhao Zhang",
        "Dandan Song",
        "Heyan Huang",
        "Liqiang Nie"
      ],
      "abstract": "Sequential recommender systems are essential for discerning user preferences\nfrom historical interactions and facilitating targeted recommendations. Recent\ninnovations employing Large Language Models (LLMs) have advanced the field by\nencoding item semantics, yet they often necessitate substantial parameter\ntuning and are resource-demanding. Moreover, these works fails to consider the\ndiverse characteristics of different types of users and thus diminishes the\nrecommendation accuracy. In this paper, we propose a parameter-efficient Large\nLanguage Model Bi-Tuning framework for sequential recommendation with\ncollaborative information (Laser). Specifically, Bi-Tuning works by inserting\ntrainable virtual tokens at both the prefix and suffix of the input sequence\nand freezing the LLM parameters, thus optimizing the LLM for the sequential\nrecommendation. In our Laser, the prefix is utilized to incorporate user-item\ncollaborative information and adapt the LLM to the recommendation task, while\nthe suffix converts the output embeddings of the LLM from the language space to\nthe recommendation space for the follow-up item recommendation. Furthermore, to\ncapture the characteristics of different types of users when integrating the\ncollaborative information via the prefix, we introduce M-Former, a lightweight\nMoE-based querying transformer that uses a set of query experts to integrate\ndiverse user-specific collaborative information encoded by frozen ID-based\nsequential recommender systems, significantly improving the accuracy of\nrecommendations. Extensive experiments on real-world datasets demonstrate that\nLaser can parameter-efficiently adapt LLMs to effective recommender systems,\nsignificantly outperforming state-of-the-art methods.",
      "tldr_zh": "该论文提出 Laser 框架，一种参数高效的 LLM Bi-Tuning 方法，用于顺序推荐系统，以整合用户-项协作信息并解决传统方法对不同用户类型考虑不足的问题。具体地，Bi-Tuning 通过在输入序列的前缀插入协作信息以适应推荐任务，并在后缀转换输出嵌入到推荐空间，同时引入 M-Former，一种轻量级基于 MoE 的查询变换器，来捕捉用户特定特征并提升准确性。实验在真实数据集上表明，Laser 显著优于现有方法，实现高效的 LLM 适应和推荐性能提升。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "11 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2409.01605v1",
      "published_date": "2024-09-03 04:55:03 UTC",
      "updated_date": "2024-09-03 04:55:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:09:57.800872"
    },
    {
      "arxiv_id": "2409.01596v2",
      "title": "Synthesizing Late-Stage Contrast Enhancement in Breast MRI: A Comprehensive Pipeline Leveraging Temporal Contrast Enhancement Dynamics",
      "title_zh": "翻译失败",
      "authors": [
        "Ruben D. Fonnegra",
        "Maria Liliana Hernández",
        "Juan C. Caicedo",
        "Gloria M. Díaz"
      ],
      "abstract": "Dynamic contrast-enhanced magnetic resonance imaging (DCE-MRI) is essential\nfor breast cancer diagnosis due to its ability to characterize tissue through\ncontrast agent kinetics. However, traditional DCE-MRI protocols require\nmultiple imaging phases, including early and late post-contrast acquisitions,\nleading to prolonged scan times, patient discomfort, motion artifacts, high\ncosts, and limited accessibility. To overcome these limitations, this study\npresents a pipeline for synthesizing late-phase DCE-MRI images from early-phase\ndata, replicating the time-intensity (TI) curve behavior in enhanced regions\nwhile maintaining visual fidelity across the entire image. The proposed\napproach introduces a novel loss function, Time Intensity Loss (TI-loss),\nleveraging the temporal behavior of contrast agents to guide the training of a\ngenerative model. Additionally, a new normalization strategy, TI-norm,\npreserves the contrast enhancement pattern across multiple image sequences at\nvarious timestamps, addressing limitations of conventional normalization\nmethods. Two metrics are proposed to evaluate image quality: the Contrast Agent\nPattern Score ($\\mathcal{CP}_{s}$), which validates enhancement patterns in\nannotated regions, and the Average Difference in Enhancement ($\\mathcal{ED}$),\nmeasuring differences between real and generated enhancements. Using a public\nDCE-MRI dataset with 1.5T and 3T scanners, the proposed method demonstrates\naccurate synthesis of late-phase images that outperform existing models in\nreplicating the TI curve's behavior in regions of interest while preserving\noverall image quality. This advancement shows a potential to optimize DCE-MRI\nprotocols by reducing scanning time without compromising diagnostic accuracy,\nand bringing generative models closer to practical implementation in clinical\nscenarios to enhance efficiency in breast cancer imaging.",
      "tldr_zh": "该研究针对动态对比增强磁共振成像(DCE-MRI)存在的扫描时间长、患者不适等问题，提出一个综合管道，用于从早期阶段数据合成晚期阶段图像，从而复制时间强度(TI)曲线行为并保持图像视觉保真。管道引入了新型损失函数Time Intensity Loss (TI-loss)来指导生成模型训练，以及新的归一化策略TI-norm，以处理多个图像序列的对比增强模式，并提出了评估指标Contrast Agent Pattern Score ($\\mathcal{CP}_{s}$)和Average Difference in Enhancement ($\\mathcal{ED}$)来验证合成图像质量。实验在公共DCE-MRI数据集上显示，该方法在复制增强区域的TI曲线行为和整体图像质量方面优于现有模型。最终，这有望优化DCE-MRI协议，减少扫描时间而不降低乳腺癌诊断准确性，推动生成模型在临床中的实际应用。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.01596v2",
      "published_date": "2024-09-03 04:31:49 UTC",
      "updated_date": "2025-01-24 21:21:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:10:08.174839"
    },
    {
      "arxiv_id": "2409.01588v2",
      "title": "Large-scale Urban Facility Location Selection with Knowledge-informed Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Hongyuan Su",
        "Yu Zheng",
        "Jingtao Ding",
        "Depeng Jin",
        "Yong Li"
      ],
      "abstract": "The facility location problem (FLP) is a classical combinatorial optimization\nchallenge aimed at strategically laying out facilities to maximize their\naccessibility. In this paper, we propose a reinforcement learning method\ntailored to solve large-scale urban FLP, capable of producing near-optimal\nsolutions at superfast inference speed. We distill the essential swap operation\nfrom local search, and simulate it by intelligently selecting edges on a graph\nof urban regions, guided by a knowledge-informed graph neural network, thus\nsidestepping the need for heavy computation of local search. Extensive\nexperiments on four US cities with different geospatial conditions demonstrate\nthat our approach can achieve comparable performance to commercial solvers with\nless than 5\\% accessibility loss, while displaying up to 1000 times speedup. We\ndeploy our model as an online geospatial application at\nhttps://huggingface.co/spaces/randommmm/MFLP.",
      "tldr_zh": "该论文针对设施位置问题（FLP）这一经典组合优化问题，提出了一种基于知识驱动强化学习的方法，用于大规模城市设施布局，以最大化可访问性。该方法通过提炼局部搜索中的交换操作，并在城市区域图上使用知识-informed图神经网络智能选择边，从而模拟优化过程，避免了繁重计算。实验在四个美国城市中显示，该方法与商业求解器性能相当，仅损失不到5%的可访问性，但推理速度提高了1000倍，并已部署为在线地理空间应用。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CY",
        "68T20"
      ],
      "primary_category": "cs.LG",
      "comment": "Sigspatial2024",
      "pdf_url": "http://arxiv.org/pdf/2409.01588v2",
      "published_date": "2024-09-03 04:04:40 UTC",
      "updated_date": "2024-09-06 08:16:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:10:21.604800"
    },
    {
      "arxiv_id": "2409.01586v4",
      "title": "Booster: Tackling Harmful Fine-tuning for Large Language Models via Attenuating Harmful Perturbation",
      "title_zh": "翻译失败",
      "authors": [
        "Tiansheng Huang",
        "Sihao Hu",
        "Fatih Ilhan",
        "Selim Furkan Tekin",
        "Ling Liu"
      ],
      "abstract": "Harmful fine-tuning attack poses serious safety concerns for large language\nmodels' fine-tuning-as-a-service. While existing defenses have been proposed to\nmitigate the issue, their performances are still far away from satisfactory,\nand the root cause of the problem has not been fully recovered. To this end, we\nin this paper show that harmful perturbation over the model weights could be a\nprobable cause of alignment-broken. In order to attenuate the negative impact\nof harmful perturbation, we propose an alignment-stage solution, dubbed\nBooster. Technically, along with the original alignment loss, we append a loss\nregularizer in the alignment stage's optimization. The regularizer ensures that\nthe model's harmful loss reduction after the simulated harmful perturbation is\nattenuated, thereby mitigating the subsequent fine-tuning risk. Empirical\nresults show that Booster can effectively reduce the harmful score of the\nfine-tuned models while maintaining the performance of downstream tasks. Our\ncode is available at https://github.com/git-disl/Booster.",
      "tldr_zh": "该论文针对大语言模型（Large Language Models）的有害微调攻击问题，提出了一种名为Booster的防御方法，通过削弱有害扰动（Harmful Perturbation）来维护模型对齐性。Booster在对齐阶段的优化中，除了原有对齐损失，还添加了一个损失正则化器，确保模拟有害扰动后模型的有害损失减少被抑制，从而降低后续微调风险。实验结果显示，Booster能有效减少微调模型的有害分数，同时保持下游任务的性能，并提供了开源代码支持。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.01586v4",
      "published_date": "2024-09-03 03:59:22 UTC",
      "updated_date": "2025-03-17 17:17:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:10:33.048837"
    },
    {
      "arxiv_id": "2409.01581v1",
      "title": "GaussianPU: A Hybrid 2D-3D Upsampling Framework for Enhancing Color Point Clouds via 3D Gaussian Splatting",
      "title_zh": "翻译失败",
      "authors": [
        "Zixuan Guo",
        "Yifan Xie",
        "Weijing Xie",
        "Peng Huang",
        "Fei Ma",
        "Fei Richard Yu"
      ],
      "abstract": "Dense colored point clouds enhance visual perception and are of significant\nvalue in various robotic applications. However, existing learning-based point\ncloud upsampling methods are constrained by computational resources and batch\nprocessing strategies, which often require subdividing point clouds into\nsmaller patches, leading to distortions that degrade perceptual quality. To\naddress this challenge, we propose a novel 2D-3D hybrid colored point cloud\nupsampling framework (GaussianPU) based on 3D Gaussian Splatting (3DGS) for\nrobotic perception. This approach leverages 3DGS to bridge 3D point clouds with\ntheir 2D rendered images in robot vision systems. A dual scale rendered image\nrestoration network transforms sparse point cloud renderings into dense\nrepresentations, which are then input into 3DGS along with precise robot camera\nposes and interpolated sparse point clouds to reconstruct dense 3D point\nclouds. We have made a series of enhancements to the vanilla 3DGS, enabling\nprecise control over the number of points and significantly boosting the\nquality of the upsampled point cloud for robotic scene understanding. Our\nframework supports processing entire point clouds on a single consumer-grade\nGPU, such as the NVIDIA GeForce RTX 3090, eliminating the need for segmentation\nand thus producing high-quality, dense colored point clouds with millions of\npoints for robot navigation and manipulation tasks. Extensive experimental\nresults on generating million-level point cloud data validate the effectiveness\nof our method, substantially improving the quality of colored point clouds and\ndemonstrating significant potential for applications involving large-scale\npoint clouds in autonomous robotics and human-robot interaction scenarios.",
      "tldr_zh": "本研究提出GaussianPU，一种基于3D Gaussian Splatting (3DGS)的2D-3D混合上采样框架，用于提升彩色点云的质量，以支持机器人感知应用。该框架通过双尺度渲染图像恢复网络，将稀疏点云渲染转化为密集表示，并结合机器人相机位姿和插值稀疏点云，实现对整个点云的精确重建，同时对原3DGS进行增强以精确控制点数和提升质量。相比传统方法，GaussianPU能在单台消费级GPU（如NVIDIA GeForce RTX 3090）上处理完整点云，无需分割；实验结果显示，该方法在百万级点云数据上显著提高了彩色点云的质量，具有广阔潜力应用于机器人导航、操作和人机交互场景。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "7 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2409.01581v1",
      "published_date": "2024-09-03 03:35:04 UTC",
      "updated_date": "2024-09-03 03:35:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:10:46.519630"
    },
    {
      "arxiv_id": "2409.13694v3",
      "title": "Multi-Source Knowledge Pruning for Retrieval-Augmented Generation: A Benchmark and Empirical Study",
      "title_zh": "翻译失败",
      "authors": [
        "Shuo Yu",
        "Mingyue Cheng",
        "Jiqian Yang",
        "Jie Ouyang",
        "Yucong Luo",
        "Chenyi Lei",
        "Qi Liu",
        "Enhong Chen"
      ],
      "abstract": "Retrieval-augmented generation (RAG) is increasingly recognized as an\neffective approach to mitigating the hallucination of large language models\n(LLMs) through the integration of external knowledge. While numerous efforts,\nmost studies focus on a single type of external knowledge source. In contrast,\nmost real-world applications involve diverse knowledge from various sources, a\nscenario that has been relatively underexplored. The main dilemma is the lack\nof a suitable dataset incorporating multiple knowledge sources and\npre-exploration of the associated issues. To address these challenges, we\nstandardize a benchmark dataset that combines structured and unstructured\nknowledge across diverse and complementary domains. Building upon the dataset,\nwe identify the limitations of existing methods under such conditions.\nTherefore, we develop PruningRAG, a plug-and-play RAG framework that uses\nmulti-granularity pruning strategies to more effectively incorporate relevant\ncontext and mitigate the negative impact of misleading information. Extensive\nexperimental results demonstrate superior performance of PruningRAG and our\ninsightful findings are also reported. Our dataset and code are publicly\navailable\\footnote{https://github.com/USTCAGI/PruningRAG}.",
      "tldr_zh": "这篇论文探讨了Retrieval-Augmented Generation (RAG) 在整合多来源外部知识时的挑战，旨在减少大型语言模型 (LLMs) 的幻觉问题，但现有研究多限于单一知识来源。作者构建了一个标准化基准数据集，结合了结构化和非结构化知识，涵盖多样领域，以填补这一空白。论文提出了PruningRAG框架，通过多粒度修剪策略有效整合相关上下文并减少误导信息的影响，实验结果显示其性能优于基线模型，并公开了数据集和代码以促进进一步研究。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.CL",
      "comment": "12 pages, 9 figures;",
      "pdf_url": "http://arxiv.org/pdf/2409.13694v3",
      "published_date": "2024-09-03 03:31:37 UTC",
      "updated_date": "2025-02-16 11:07:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:10:59.888052"
    },
    {
      "arxiv_id": "2409.01579v1",
      "title": "AdaComp: Extractive Context Compression with Adaptive Predictor for Retrieval-Augmented Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Qianchi Zhang",
        "Hainan Zhang",
        "Liang Pang",
        "Hongwei Zheng",
        "Zhiming Zheng"
      ],
      "abstract": "Retrieved documents containing noise will hinder RAG from detecting answer\nclues and make the inference process slow and expensive. Therefore, context\ncompression is necessary to enhance its accuracy and efficiency. Existing\ncontext compression methods use extractive or generative models to retain the\nmost query-relevant sentences or apply the information bottleneck theory to\npreserve sufficient information. However, these methods may face issues such as\nover-compression or high computational costs. We observe that the retriever\noften ranks relevant documents at the top, but the exact number of documents\nneeded to answer the query is uncertain due to the impact of query complexity\nand retrieval quality: complex queries like multi-hop questions may require\nretaining more documents than simpler queries, and a low-quality retrieval may\nneed to rely on more documents to generate accurate outputs. Therefore,\ndetermining the minimum number of required documents (compression rate) is\nstill a challenge for RAG. In this paper, we introduce AdaComp, a low-cost\nextractive context compression method that adaptively determines the\ncompression rate based on both query complexity and retrieval quality.\nSpecifically, we first annotate the minimum top-k documents necessary for the\nRAG system to answer the current query as the compression rate and then\nconstruct triplets of the query, retrieved documents, and its compression rate.\nThen, we use this triplet dataset to train a compression-rate predictor.\nExperiments on three QA datasets and one conversational Muiti-doc QA dataset\nshow that AdaComp significantly reduces inference costs while maintaining\nperformance nearly identical to uncompressed models, achieving a balance\nbetween efficiency and performance.",
      "tldr_zh": "该论文提出AdaComp，一种提取式上下文压缩方法，针对Retrieval-Augmented Large Language Models (RAG)中检索文档噪声导致的准确性和效率问题，通过自适应预测器根据查询复杂度和检索质量动态确定压缩率。AdaComp首先标注最小top-k文档作为压缩率，并构建查询、检索文档和压缩率的triplets数据集来训练预测器，从而避免现有方法的过度压缩或高计算成本。在三个QA数据集和一个对话式多文档QA数据集上的实验显示，AdaComp显著降低了推理成本，同时保持了与未压缩模型几乎相同的性能。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "8 pages, 5 figures, code available at\n  https://anonymous.4open.science/r/AdaComp-8C0C/",
      "pdf_url": "http://arxiv.org/pdf/2409.01579v1",
      "published_date": "2024-09-03 03:25:59 UTC",
      "updated_date": "2024-09-03 03:25:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:11:11.101730"
    },
    {
      "arxiv_id": "2409.01573v2",
      "title": "Improving Apple Object Detection with Occlusion-Enhanced Distillation",
      "title_zh": "翻译失败",
      "authors": [
        "Liang Geng"
      ],
      "abstract": "Apples growing in natural environments often face severe visual obstructions\nfrom leaves and branches. This significantly increases the risk of false\ndetections in object detection tasks, thereby escalating the challenge.\nAddressing this issue, we introduce a technique called \"Occlusion-Enhanced\nDistillation\" (OED). This approach utilizes occlusion information to regularize\nthe learning of semantically aligned features on occluded datasets and employs\nExponential Moving Average (EMA) to enhance training stability. Specifically,\nwe first design an occlusion-enhanced dataset that integrates Grounding DINO\nand SAM methods to extract occluding elements such as leaves and branches from\neach sample, creating occlusion examples that reflect the natural growth state\nof fruits. Additionally, we propose a multi-scale knowledge distillation\nstrategy, where the student network uses images with increased occlusions as\ninputs, while the teacher network employs images without natural occlusions.\nThrough this setup, the strategy guides the student network to learn from the\nteacher across scales of semantic and local features alignment, effectively\nnarrowing the feature distance between occluded and non-occluded targets and\nenhancing the robustness of object detection. Lastly, to improve the stability\nof the student network, we introduce the EMA strategy, which aids the student\nnetwork in learning more generalized feature expressions that are less affected\nby the noise of individual image occlusions. Our method significantly\noutperforms current state-of-the-art techniques through extensive comparative\nexperiments.",
      "tldr_zh": "本论文针对苹果在自然环境中被叶子和树枝遮挡导致的物体检测错误问题，提出了一种Occlusion-Enhanced Distillation (OED)技术，利用遮挡信息规范语义对齐特征的学习，并通过Exponential Moving Average (EMA)提升训练稳定性。具体方法包括构建一个基于Grounding DINO和SAM的遮挡增强数据集，以及多尺度知识蒸馏策略，让学生网络从教师网络学习遮挡和非遮挡目标之间的特征差异，从而提高检测鲁棒性。实验结果显示，该方法在广泛比较中显著优于当前最先进技术。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.01573v2",
      "published_date": "2024-09-03 03:11:48 UTC",
      "updated_date": "2024-10-30 02:36:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:11:23.104097"
    },
    {
      "arxiv_id": "2409.01572v1",
      "title": "LSSF-Net: Lightweight Segmentation with Self-Awareness, Spatial Attention, and Focal Modulation",
      "title_zh": "翻译失败",
      "authors": [
        "Hamza Farooq",
        "Zuhair Zafar",
        "Ahsan Saadat",
        "Tariq M Khan",
        "Shahzaib Iqbal",
        "Imran Razzak"
      ],
      "abstract": "Accurate segmentation of skin lesions within dermoscopic images plays a\ncrucial role in the timely identification of skin cancer for computer-aided\ndiagnosis on mobile platforms. However, varying shapes of the lesions, lack of\ndefined edges, and the presence of obstructions such as hair strands and marker\ncolors make this challenge more complex. \\textcolor{red}Additionally, skin\nlesions often exhibit subtle variations in texture and color that are difficult\nto differentiate from surrounding healthy skin, necessitating models that can\ncapture both fine-grained details and broader contextual information.\nCurrently, melanoma segmentation models are commonly based on fully connected\nnetworks and U-Nets. However, these models often struggle with capturing the\ncomplex and varied characteristics of skin lesions, such as the presence of\nindistinct boundaries and diverse lesion appearances, which can lead to\nsuboptimal segmentation performance.To address these challenges, we propose a\nnovel lightweight network specifically designed for skin lesion segmentation\nutilizing mobile devices, featuring a minimal number of learnable parameters\n(only 0.8 million). This network comprises an encoder-decoder architecture that\nincorporates conformer-based focal modulation attention, self-aware local and\nglobal spatial attention, and split channel-shuffle. The efficacy of our model\nhas been evaluated on four well-established benchmark datasets for skin lesion\nsegmentation: ISIC 2016, ISIC 2017, ISIC 2018, and PH2. Empirical findings\nsubstantiate its state-of-the-art performance, notably reflected in a high\nJaccard index.",
      "tldr_zh": "该论文提出LSSF-Net，一种轻量级网络，针对皮肤病变分割的挑战（如病变形状多样、边缘模糊以及干扰因素），旨在提升移动设备上的计算机辅助诊断性能。该网络采用编码器-解码器架构，整合了基于Conformer的focal modulation attention、自aware局部和全局spatial attention，以及split channel-shuffle机制，仅需0.8百万可学习参数，以捕捉细粒度和 broader contextual信息。实验在ISIC 2016、2017、2018和PH2基准数据集上验证了其state-of-the-art性能，尤其在Jaccard index上表现出色。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.01572v1",
      "published_date": "2024-09-03 03:06:32 UTC",
      "updated_date": "2024-09-03 03:06:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:11:34.857253"
    },
    {
      "arxiv_id": "2409.01560v1",
      "title": "Blocks as Probes: Dissecting Categorization Ability of Large Multimodal Models",
      "title_zh": "翻译失败",
      "authors": [
        "Bin Fu",
        "Qiyang Wan",
        "Jialin Li",
        "Ruiping Wang",
        "Xilin Chen"
      ],
      "abstract": "Categorization, a core cognitive ability in humans that organizes objects\nbased on common features, is essential to cognitive science as well as computer\nvision. To evaluate the categorization ability of visual AI models, various\nproxy tasks on recognition from datasets to open world scenarios have been\nproposed. Recent development of Large Multimodal Models (LMMs) has demonstrated\nimpressive results in high-level visual tasks, such as visual question\nanswering, video temporal reasoning, etc., utilizing the advanced architectures\nand large-scale multimodal instruction tuning. Previous researchers have\ndeveloped holistic benchmarks to measure the high-level visual capability of\nLMMs, but there is still a lack of pure and in-depth quantitative evaluation of\nthe most fundamental categorization ability. According to the research on human\ncognitive process, categorization can be seen as including two parts: category\nlearning and category use. Inspired by this, we propose a novel, challenging,\nand efficient benchmark based on composite blocks, called ComBo, which provides\na disentangled evaluation framework and covers the entire categorization\nprocess from learning to use. By analyzing the results of multiple evaluation\ntasks, we find that although LMMs exhibit acceptable generalization ability in\nlearning new categories, there are still gaps compared to humans in many ways,\nsuch as fine-grained perception of spatial relationship and abstract category\nunderstanding. Through the study of categorization, we can provide inspiration\nfor the further development of LMMs in terms of interpretability and\ngeneralization.",
      "tldr_zh": "本文研究了 Large Multimodal Models (LMMs) 的核心分类能力，通过提出一个基于复合块的新基准 ComBo，对其进行解耦评估。ComBo 框架涵盖了分类过程的两个关键部分：类别学习和类别使用，旨在提供纯净且深入的量化评估。实验结果显示，LMMs 在学习新类别方面表现出可接受的泛化能力，但与人类相比，在细粒度空间关系感知和抽象类别理解上存在显著差距。该研究为提升 LMMs 的可解释性和泛化能力提供了重要启发。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "39 pages, 28 figures, 4 tables. Accepted at The 35th British Machine\n  Vision Conference (BMVC 2024). Project page at\n  https://fubin29.github.io/Blocks-as-Probes/",
      "pdf_url": "http://arxiv.org/pdf/2409.01560v1",
      "published_date": "2024-09-03 02:55:36 UTC",
      "updated_date": "2024-09-03 02:55:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:11:47.452988"
    },
    {
      "arxiv_id": "2409.01556v2",
      "title": "Benchmarking Cognitive Domains for LLMs: Insights from Taiwanese Hakka Culture",
      "title_zh": "翻译失败",
      "authors": [
        "Chen-Chi Chang",
        "Ching-Yuan Chen",
        "Hung-Shin Lee",
        "Chih-Cheng Lee"
      ],
      "abstract": "This study introduces a comprehensive benchmark designed to evaluate the\nperformance of large language models (LLMs) in understanding and processing\ncultural knowledge, with a specific focus on Hakka culture as a case study.\nLeveraging Bloom's Taxonomy, the study develops a multi-dimensional framework\nthat systematically assesses LLMs across six cognitive domains: Remembering,\nUnderstanding, Applying, Analyzing, Evaluating, and Creating. This benchmark\nextends beyond traditional single-dimensional evaluations by providing a deeper\nanalysis of LLMs' abilities to handle culturally specific content, ranging from\nbasic recall of facts to higher-order cognitive tasks such as creative\nsynthesis. Additionally, the study integrates Retrieval-Augmented Generation\n(RAG) technology to address the challenges of minority cultural knowledge\nrepresentation in LLMs, demonstrating how RAG enhances the models' performance\nby dynamically incorporating relevant external information. The results\nhighlight the effectiveness of RAG in improving accuracy across all cognitive\ndomains, particularly in tasks requiring precise retrieval and application of\ncultural knowledge. However, the findings also reveal the limitations of RAG in\ncreative tasks, underscoring the need for further optimization. This benchmark\nprovides a robust tool for evaluating and comparing LLMs in culturally diverse\ncontexts, offering valuable insights for future research and development in\nAI-driven cultural knowledge preservation and dissemination.",
      "tldr_zh": "这篇论文引入了一个全面基准，使用 Bloom's Taxonomy 框架评估大型语言模型 (LLMs) 在处理文化知识方面的性能，以台湾客家文化作为案例研究。该基准涵盖六个认知领域：Remembering, Understanding, Applying, Analyzing, Evaluating 和 Creating，超越传统评估，提供从基本事实回忆到高级创意合成的多维分析。通过整合 Retrieval-Augmented Generation (RAG) 技术，研究展示了 RAG 如何提升 LLMs 在少数民族文化知识检索和应用中的准确性，但也揭示了其在创造性任务中的局限性，为 AI 在文化多样化语境中的开发和知识保存提供了宝贵见解。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to O-COCOSDA 2024",
      "pdf_url": "http://arxiv.org/pdf/2409.01556v2",
      "published_date": "2024-09-03 02:50:04 UTC",
      "updated_date": "2024-09-25 00:31:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:12:01.107141"
    },
    {
      "arxiv_id": "2409.01555v1",
      "title": "EA-RAS: Towards Efficient and Accurate End-to-End Reconstruction of Anatomical Skeleton",
      "title_zh": "翻译失败",
      "authors": [
        "Zhiheng Peng",
        "Kai Zhao",
        "Xiaoran Chen",
        "Li Ma",
        "Siyu Xia",
        "Changjie Fan",
        "Weijian Shang",
        "Wei Jing"
      ],
      "abstract": "Efficient, accurate and low-cost estimation of human skeletal information is\ncrucial for a range of applications such as biology education and\nhuman-computer interaction. However, current simple skeleton models, which are\ntypically based on 2D-3D joint points, fall short in terms of anatomical\nfidelity, restricting their utility in fields. On the other hand, more complex\nmodels while anatomically precise, are hindered by sophisticate multi-stage\nprocessing and the need for extra data like skin meshes, making them unsuitable\nfor real-time applications. To this end, we propose the EA-RAS (Towards\nEfficient and Accurate End-to-End Reconstruction of Anatomical Skeleton), a\nsingle-stage, lightweight, and plug-and-play anatomical skeleton estimator that\ncan provide real-time, accurate anatomically realistic skeletons with arbitrary\npose using only a single RGB image input. Additionally, EA-RAS estimates the\nconventional human-mesh model explicitly, which not only enhances the\nfunctionality but also leverages the outside skin information by integrating\nfeatures into the inside skeleton modeling process. In this work, we also\ndevelop a progressive training strategy and integrated it with an enhanced\noptimization process, enabling the network to obtain initial weights using only\na small skin dataset and achieve self-supervision in skeleton reconstruction.\nBesides, we also provide an optional lightweight post-processing optimization\nstrategy to further improve accuracy for scenarios that prioritize precision\nover real-time processing. The experiments demonstrated that our regression\nmethod is over 800 times faster than existing methods, meeting real-time\nrequirements. Additionally, the post-processing optimization strategy provided\ncan enhance reconstruction accuracy by over 50% and achieve a speed increase of\nmore than 7 times.",
      "tldr_zh": "本文提出 EA-RAS，一种高效且准确的端到端解剖骨骼重建方法，使用单个 RGB 图像作为输入，实现实时生成精确的解剖真实骨骼模型，同时显式估计常规人体网格模型以增强功能。EA-RAS 采用单阶段轻量级设计、渐进式训练策略和增强优化过程，从小型皮肤数据集获取初始权重，实现骨骼重建的自监督学习，并提供可选后处理优化以进一步提升准确性。实验结果显示，该方法比现有方法快 800 倍，后处理策略可提高重建准确性 50% 以上，同时加速 7 倍，适用于实时应用如生物教育和人机交互。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "13 pages,15 figures",
      "pdf_url": "http://arxiv.org/pdf/2409.01555v1",
      "published_date": "2024-09-03 02:46:28 UTC",
      "updated_date": "2024-09-03 02:46:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:12:11.211916"
    },
    {
      "arxiv_id": "2409.01552v1",
      "title": "Self-Instructed Derived Prompt Generation Meets In-Context Learning: Unlocking New Potential of Black-Box LLMs",
      "title_zh": "自指导的派生提示生成遇见上下文学习：释放黑箱大语言模型的新潜力",
      "authors": [
        "Zhuo Li",
        "Yuhao Du",
        "Jinpeng Hu",
        "Xiang Wan",
        "Anningzhe Gao"
      ],
      "abstract": "Large language models (LLMs) have shown success in generating high-quality\nresponses. In order to achieve better alignment with LLMs with human\npreference, various works are proposed based on specific optimization process,\nwhich, however, is not suitable to Black-Box LLMs like GPT-4, due to\ninaccessible parameters. In Black-Box LLMs case, their performance is highly\ndependent on the quality of the provided prompts. Existing methods to enhance\nresponse quality often involve a prompt refinement model, yet these approaches\npotentially suffer from semantic inconsistencies between the refined and\noriginal prompts, and typically overlook the relationship between them. To\naddress these challenges, we introduce a self-instructed in-context learning\nframework that empowers LLMs to deliver more effective responses by generating\nreliable derived prompts to construct informative contextual environments. Our\napproach incorporates a self-instructed reinforcement learning mechanism,\nenabling direct interaction with the response model during derived prompt\ngeneration for better alignment. We then formulate querying as an in-context\nlearning task, using responses from LLMs combined with the derived prompts to\nestablish a contextual demonstration for the original prompt. This strategy\nensures alignment with the original query, reduces discrepancies from refined\nprompts, and maximizes the LLMs' in-context learning capability. Extensive\nexperiments demonstrate that the proposed method not only generates more\nreliable derived prompts but also significantly enhances LLMs' ability to\ndeliver more effective responses, including Black-Box models such as GPT-4.",
      "tldr_zh": "这篇论文针对 Black-Box LLMs（如 GPT-4）的提示优化挑战，提出了一种自指令的 In-Context Learning 框架，通过生成可靠的 derived prompts 来构建信息丰富的上下文环境，从而提升模型响应质量。该框架整合自指令强化学习机制，让 LLMs 在生成派生提示时直接与响应模型互动，确保与原查询语义对齐，并减少提示不一致问题。实验结果显示，该方法不仅产生更可靠的 derived prompts，还显著提高了 Black-Box LLMs 的响应效果。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.01552v1",
      "published_date": "2024-09-03 02:42:39 UTC",
      "updated_date": "2024-09-03 02:42:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:12:27.406873"
    },
    {
      "arxiv_id": "2409.01548v3",
      "title": "VoxHakka: A Dialectally Diverse Multi-speaker Text-to-Speech System for Taiwanese Hakka",
      "title_zh": "翻译失败",
      "authors": [
        "Li-Wei Chen",
        "Hung-Shin Lee",
        "Chen-Chi Chang"
      ],
      "abstract": "This paper introduces VoxHakka, a text-to-speech (TTS) system designed for\nTaiwanese Hakka, a critically under-resourced language spoken in Taiwan.\nLeveraging the YourTTS framework, VoxHakka achieves high naturalness and\naccuracy and low real-time factor in speech synthesis while supporting six\ndistinct Hakka dialects. This is achieved by training the model with\ndialect-specific data, allowing for the generation of speaker-aware Hakka\nspeech. To address the scarcity of publicly available Hakka speech corpora, we\nemployed a cost-effective approach utilizing a web scraping pipeline coupled\nwith automatic speech recognition (ASR)-based data cleaning techniques. This\nprocess ensured the acquisition of a high-quality, multi-speaker, multi-dialect\ndataset suitable for TTS training. Subjective listening tests conducted using\ncomparative mean opinion scores (CMOS) demonstrate that VoxHakka significantly\noutperforms existing publicly available Hakka TTS systems in terms of\npronunciation accuracy, tone correctness, and overall naturalness. This work\nrepresents a significant advancement in Hakka language technology and provides\na valuable resource for language preservation and revitalization efforts.",
      "tldr_zh": "本文介绍了 VoxHakka，一种基于 YourTTS 框架的多说话者 TTS 系统，针对资源匮乏的台湾客家话，支持六种方言，并实现了高自然度、准确性和低实时因子。作者通过网络爬虫管道结合 ASR 基于数据清洗技术，构建了高质量的多说话者、多方言数据集，以解决数据稀缺问题。主观 CMOS 听力测试显示，VoxHakka 在发音准确性、音调正确性和整体自然度上显著优于现有公开客家 TTS 系统。该工作推动了客家语言技术的发展，并为语言保存和复兴提供了宝贵资源。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.CL",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "Accepted to O-COCOSDA 2024",
      "pdf_url": "http://arxiv.org/pdf/2409.01548v3",
      "published_date": "2024-09-03 02:37:34 UTC",
      "updated_date": "2024-10-02 02:25:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:12:39.174089"
    },
    {
      "arxiv_id": "2409.01545v1",
      "title": "Effective Noise-aware Data Simulation for Domain-adaptive Speech Enhancement Leveraging Dynamic Stochastic Perturbation",
      "title_zh": "翻译失败",
      "authors": [
        "Chien-Chun Wang",
        "Li-Wei Chen",
        "Hung-Shin Lee",
        "Berlin Chen",
        "Hsin-Min Wang"
      ],
      "abstract": "Cross-domain speech enhancement (SE) is often faced with severe challenges\ndue to the scarcity of noise and background information in an unseen target\ndomain, leading to a mismatch between training and test conditions. This study\nputs forward a novel data simulation method to address this issue, leveraging\nnoise-extractive techniques and generative adversarial networks (GANs) with\nonly limited target noisy speech data. Notably, our method employs a noise\nencoder to extract noise embeddings from target-domain data. These embeddings\naptly guide the generator to synthesize utterances acoustically fitted to the\ntarget domain while authentically preserving the phonetic content of the input\nclean speech. Furthermore, we introduce the notion of dynamic stochastic\nperturbation, which can inject controlled perturbations into the noise\nembeddings during inference, thereby enabling the model to generalize well to\nunseen noise conditions. Experiments on the VoiceBank-DEMAND benchmark dataset\ndemonstrate that our domain-adaptive SE method outperforms an existing strong\nbaseline based on data simulation.",
      "tldr_zh": "该研究针对跨域语音增强（speech enhancement）中的噪声和背景信息稀缺问题，提出了一种有效的噪声感知数据模拟方法，利用噪声编码器从有限的目标域噪声语音数据中提取噪声嵌入，并结合 GANs 生成器合成适合目标域的语音，同时保留输入干净语音的语音内容。  \n此外，该方法引入 dynamic stochastic perturbation 技术，在推理过程中向噪声嵌入注入受控随机扰动，从而提升模型对未见噪声条件的泛化能力。  \n实验结果显示，在 VoiceBank-DEMAND 数据集上，该域适应语音增强方法优于现有的基于数据模拟的强基线。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.CL",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "Accepted to IEEE SLT 2024",
      "pdf_url": "http://arxiv.org/pdf/2409.01545v1",
      "published_date": "2024-09-03 02:29:01 UTC",
      "updated_date": "2024-09-03 02:29:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:12:49.946909"
    },
    {
      "arxiv_id": "2409.01540v1",
      "title": "Long-Range Biometric Identification in Real World Scenarios: A Comprehensive Evaluation Framework Based on Missions",
      "title_zh": "翻译失败",
      "authors": [
        "Deniz Aykac",
        "Joel Brogan",
        "Nell Barber",
        "Ryan Shivers",
        "Bob Zhang",
        "Dallas Sacca",
        "Ryan Tipton",
        "Gavin Jager",
        "Austin Garret",
        "Matthew Love",
        "Jim Goddard",
        "David Cornett III",
        "David S. Bolme"
      ],
      "abstract": "The considerable body of data available for evaluating biometric recognition\nsystems in Research and Development (R\\&D) environments has contributed to the\nincreasingly common problem of target performance mismatch. Biometric\nalgorithms are frequently tested against data that may not reflect the real\nworld applications they target. From a Testing and Evaluation (T\\&E)\nstandpoint, this domain mismatch causes difficulty assessing when improvements\nin State-of-the-Art (SOTA) research actually translate to improved applied\noutcomes. This problem can be addressed with thoughtful preparation of data and\nexperimental methods to reflect specific use-cases and scenarios.\n  To that end, this paper evaluates research solutions for identifying\nindividuals at ranges and altitudes, which could support various application\nareas such as counterterrorism, protection of critical infrastructure\nfacilities, military force protection, and border security. We address\nchallenges including image quality issues and reliance on face recognition as\nthe sole biometric modality. By fusing face and body features, we propose\ndeveloping robust biometric systems for effective long-range identification\nfrom both the ground and steep pitch angles. Preliminary results show promising\nprogress in whole-body recognition. This paper presents these early findings\nand discusses potential future directions for advancing long-range biometric\nidentification systems based on mission-driven metrics.",
      "tldr_zh": "这篇论文探讨了生物识别系统在真实场景中的评估挑战，特别是 R&D 环境数据与实际应用不匹配导致的目标性能偏差问题。作者提出一个基于任务的全面评估框架，针对远距离和高空识别（如反恐和边境安全），通过融合面部和身体特征来解决图像质量问题和单一模态（如面部识别）的局限性。初步结果显示，全身识别取得了有前景的进展，并为基于任务驱动指标的未来生物识别系统发展提供了潜在方向。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.01540v1",
      "published_date": "2024-09-03 02:17:36 UTC",
      "updated_date": "2024-09-03 02:17:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:13:02.510836"
    },
    {
      "arxiv_id": "2409.01534v1",
      "title": "Think Twice Before Recognizing: Large Multimodal Models for General Fine-grained Traffic Sign Recognition",
      "title_zh": "翻译失败",
      "authors": [
        "Yaozong Gan",
        "Guang Li",
        "Ren Togo",
        "Keisuke Maeda",
        "Takahiro Ogawa",
        "Miki Haseyama"
      ],
      "abstract": "We propose a new strategy called think twice before recognizing to improve\nfine-grained traffic sign recognition (TSR). Fine-grained TSR in the wild is\ndifficult due to the complex road conditions, and existing approaches\nparticularly struggle with cross-country TSR when data is lacking. Our strategy\nachieves effective fine-grained TSR by stimulating the multiple-thinking\ncapability of large multimodal models (LMM). We introduce context,\ncharacteristic, and differential descriptions to design multiple thinking\nprocesses for the LMM. The context descriptions with center coordinate prompt\noptimization help the LMM to locate the target traffic sign in the original\nroad images containing multiple traffic signs and filter irrelevant answers\nthrough the proposed prior traffic sign hypothesis. The characteristic\ndescription is based on few-shot in-context learning of template traffic signs,\nwhich decreases the cross-domain difference and enhances the fine-grained\nrecognition capability of the LMM. The differential descriptions of similar\ntraffic signs optimize the multimodal thinking capability of the LMM. The\nproposed method is independent of training data and requires only simple and\nuniform instructions. We conducted extensive experiments on three benchmark\ndatasets and two real-world datasets from different countries, and the proposed\nmethod achieves state-of-the-art TSR results on all five datasets.",
      "tldr_zh": "这篇论文提出了一种名为“think twice before recognizing”的新策略，利用大型多模态模型 (Large Multimodal Models, LMM) 来提升细粒度交通标志识别 (fine-grained TSR)，特别针对复杂路况和数据缺乏的跨国家场景。策略通过上下文描述（包括中心坐标提示优化和先验交通标志假设）、特征描述（基于少样本上下文学习减少跨域差异）和差异描述（优化类似标志的多模态思考能力）来激发 LMM 的多重思考过程。该方法无需依赖训练数据，仅需简单指令，并在三个基准数据集和两个真实世界数据集上实现了最先进的结果。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.MM"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.01534v1",
      "published_date": "2024-09-03 02:08:47 UTC",
      "updated_date": "2024-09-03 02:08:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:13:14.987881"
    },
    {
      "arxiv_id": "2409.01532v1",
      "title": "Improving Robustness of Spectrogram Classifiers with Neural Stochastic Differential Equations",
      "title_zh": "翻译失败",
      "authors": [
        "Joel Brogan",
        "Olivera Kotevska",
        "Anibely Torres",
        "Sumit Jha",
        "Mark Adams"
      ],
      "abstract": "Signal analysis and classification is fraught with high levels of noise and\nperturbation. Computer-vision-based deep learning models applied to\nspectrograms have proven useful in the field of signal classification and\ndetection; however, these methods aren't designed to handle the low\nsignal-to-noise ratios inherent within non-vision signal processing tasks.\nWhile they are powerful, they are currently not the method of choice in the\ninherently noisy and dynamic critical infrastructure domain, such as smart-grid\nsensing, anomaly detection, and non-intrusive load monitoring.",
      "tldr_zh": "本论文针对信号分析和分类中高噪声及扰动的挑战，探讨了使用 Neural Stochastic Differential Equations 来提升 Spectrogram Classifiers 的鲁棒性。现有基于计算机视觉的深度学习模型虽适用于频谱图处理，但无法有效应对低信噪比任务，导致在关键基础设施领域（如智能电网传感、异常检测和非入侵负载监控）应用有限。通过引入神经随机微分方程，该方法改善了模型在动态噪声环境中的性能，为更可靠的信号分类和检测提供了新途径。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.01532v1",
      "published_date": "2024-09-03 02:03:50 UTC",
      "updated_date": "2024-09-03 02:03:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:13:25.753801"
    },
    {
      "arxiv_id": "2409.01531v1",
      "title": "On the Design Space Between Transformers and Recursive Neural Nets",
      "title_zh": "Transformer 与递归神经网络之间的设计空间",
      "authors": [
        "Jishnu Ray Chowdhury",
        "Cornelia Caragea"
      ],
      "abstract": "In this paper, we study two classes of models, Recursive Neural Networks\n(RvNNs) and Transformers, and show that a tight connection between them emerges\nfrom the recent development of two recent models - Continuous Recursive Neural\nNetworks (CRvNN) and Neural Data Routers (NDR). On one hand, CRvNN pushes the\nboundaries of traditional RvNN, relaxing its discrete structure-wise\ncomposition and ends up with a Transformer-like structure. On the other hand,\nNDR constrains the original Transformer to induce better structural inductive\nbias, ending up with a model that is close to CRvNN. Both models, CRvNN and\nNDR, show strong performance in algorithmic tasks and generalization in which\nsimpler forms of RvNNs and Transformers fail. We explore these \"bridge\" models\nin the design space between RvNNs and Transformers, formalize their tight\nconnections, discuss their limitations, and propose ideas for future research.",
      "tldr_zh": "这篇论文探讨了 Recursive Neural Networks (RvNNs) 和 Transformers 之间的设计空间，重点通过 Continuous Recursive Neural Networks (CRvNN) 和 Neural Data Routers (NDR) 揭示了两者的紧密联系。CRvNN 放宽了传统 RvNN 的离散结构，使其更接近 Transformer 的形式，而 NDR 则对 Transformer 施加约束以引入更好的结构化偏差。实验结果显示，CRvNN 和 NDR 在算法任务和泛化能力上表现出色，优于简单形式的 RvNNs 和 Transformers，论文还形式化了这些连接、讨论了局限性，并提出了未来研究方向。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.01531v1",
      "published_date": "2024-09-03 02:03:35 UTC",
      "updated_date": "2024-09-03 02:03:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:13:38.310052"
    },
    {
      "arxiv_id": "2409.01524v2",
      "title": "S^3cMath: Spontaneous Step-level Self-correction Makes Large Language Models Better Mathematical Reasoners",
      "title_zh": "S^3cMath：自发步级自我修正使大语言模型成为更好的数学推理器",
      "authors": [
        "Yuchen Yan",
        "Jin Jiang",
        "Yang Liu",
        "Yixin Cao",
        "Xin Xu",
        "Mengdi Zhang",
        "Xunliang Cai",
        "Jian Shao"
      ],
      "abstract": "Self-correction is a novel method that can stimulate the potential reasoning\nabilities of large language models (LLMs). It involves detecting and correcting\nerrors during the inference process when LLMs solve reasoning problems.\nHowever, recent works do not regard self-correction as a spontaneous and\nintrinsic capability of LLMs. Instead, such correction is achieved through\npost-hoc generation, external knowledge introduction, multi-model\ncollaboration, and similar techniques. In this paper, we propose a series of\nmathematical LLMs called S$^3$c-Math, which are able to perform Spontaneous\nStep-level Self-correction for Mathematical reasoning. This capability helps\nLLMs to recognize whether their ongoing inference tends to contain errors and\nsimultaneously correct these errors to produce a more reliable response. We\nproposed a method, which employs a step-level sampling approach to construct\nstep-wise self-correction data for achieving such ability. Additionally, we\nimplement a training strategy that uses above constructed data to equip LLMs\nwith spontaneous step-level self-correction capacities. Our data and methods\nhave been demonstrated to be effective across various foundation LLMs,\nconsistently showing significant progress in evaluations on GSM8K, MATH, and\nother mathematical benchmarks. To the best of our knowledge, we are the first\nto introduce the spontaneous step-level self-correction ability of LLMs in\nmathematical reasoning.",
      "tldr_zh": "本论文提出 S^3c-Math 系列模型，通过自发的步级自校正（Spontaneous Step-level Self-correction）能力，提升 Large Language Models (LLMs) 在数学推理中的性能。该方法采用步级采样构建自校正数据，并实施专属训练策略，使 LLMs 能够在推理过程中自动检测并纠正错误。实验结果显示，S^3c-Math 在 GSM8K、MATH 等数学基准上表现出显著进步，是首创在数学推理中实现这种自发自校正能力的作品。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.01524v2",
      "published_date": "2024-09-03 01:40:21 UTC",
      "updated_date": "2025-02-20 02:20:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:13:50.048204"
    },
    {
      "arxiv_id": "2409.01514v1",
      "title": "From Data to Insights: A Covariate Analysis of the IARPA BRIAR Dataset for Multimodal Biometric Recognition Algorithms at Altitude and Range",
      "title_zh": "翻译失败",
      "authors": [
        "David S. Bolme",
        "Deniz Aykac",
        "Ryan Shivers",
        "Joel Brogan",
        "Nell Barber",
        "Bob Zhang",
        "Laura Davies",
        "David Cornett III"
      ],
      "abstract": "This paper examines covariate effects on fused whole body biometrics\nperformance in the IARPA BRIAR dataset, specifically focusing on UAV platforms,\nelevated positions, and distances up to 1000 meters. The dataset includes\noutdoor videos compared with indoor images and controlled gait recordings.\nNormalized raw fusion scores relate directly to predicted false accept rates\n(FAR), offering an intuitive means for interpreting model results. A linear\nmodel is developed to predict biometric algorithm scores, analyzing their\nperformance to identify the most influential covariates on accuracy at altitude\nand range. Weather factors like temperature, wind speed, solar loading, and\nturbulence are also investigated in this analysis. The study found that\nresolution and camera distance best predicted accuracy and findings can guide\nfuture research and development efforts in long-range/elevated/UAV biometrics\nand support the creation of more reliable and robust systems for national\nsecurity and other critical domains.",
      "tldr_zh": "本研究分析了IARPA BRIAR数据集中的协变量（covariates）对多模态生物识别算法性能的影响，重点关注UAV平台、高空位置和最远1000米的距离，包括室外视频与室内图像的比较。研究采用归一化原始融合分数来预测假接受率（FAR），并开发了一个线性模型来评估算法分数及其与准确性的关系，同时考察了天气因素如温度、风速、太阳辐射和湍流。结果显示，分辨率和相机距离是预测准确性的最重要因素，这些发现将指导未来长距离/高空/UAV生物识别系统的研发，提升其可靠性和鲁棒性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.01514v1",
      "published_date": "2024-09-03 00:58:50 UTC",
      "updated_date": "2024-09-03 00:58:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:14:02.693741"
    },
    {
      "arxiv_id": "2409.12973v1",
      "title": "The Era of Foundation Models in Medical Imaging is Approaching : A Scoping Review of the Clinical Value of Large-Scale Generative AI Applications in Radiology",
      "title_zh": "翻译失败",
      "authors": [
        "Inwoo Seo",
        "Eunkyoung Bae",
        "Joo-Young Jeon",
        "Young-Sang Yoon",
        "Jiho Cha"
      ],
      "abstract": "Social problems stemming from the shortage of radiologists are intensifying,\nand artificial intelligence is being highlighted as a potential solution.\nRecently emerging large-scale generative AI has expanded from large language\nmodels (LLMs) to multi-modal models, showing potential to revolutionize the\nentire process of medical imaging. However, comprehensive reviews on their\ndevelopment status and future challenges are currently lacking. This scoping\nreview systematically organizes existing literature on the clinical value of\nlarge-scale generative AI applications by following PCC guidelines. A\nsystematic search was conducted across four databases: PubMed, EMbase,\nIEEE-Xplore, and Google Scholar, and 15 studies meeting the inclusion/exclusion\ncriteria set by the researchers were reviewed. Most of these studies focused on\nimproving the efficiency of report generation in specific parts of the\ninterpretation process or on translating reports to aid patient understanding,\nwith the latest studies extending to AI applications performing direct\ninterpretations. All studies were quantitatively evaluated by clinicians, with\nmost utilizing LLMs and only three employing multi-modal models. Both LLMs and\nmulti-modal models showed excellent results in specific areas, but none yet\noutperformed radiologists in diagnostic performance. Most studies utilized GPT,\nwith few using models specialized for the medical imaging domain. This study\nprovides insights into the current state and limitations of large-scale\ngenerative AI-based applications in the medical imaging field, offering\nfoundational data and suggesting that the era of medical imaging foundation\nmodels is on the horizon, which may fundamentally transform clinical practice\nin the near future.",
      "tldr_zh": "这篇综述探讨了大型生成式AI在放射学中的临床价值，系统分析了15个相关研究，这些研究主要聚焦于提升报告生成效率、报告翻译以辅助患者理解，以及直接解释应用。作者遵循PCC指南，从PubMed、EMbase、IEEE-Xplore和Google Scholar等数据库筛选文献，发现LLMs（如GPT）和multi-modal models在特定领域表现出色，但诊断性能仍未超过放射学家。总体而言，该研究揭示了当前AI应用的局限性，并预测医疗成像foundation models的时代即将到来，可能根本性变革临床实践。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "25 pages,3 figures, 4 tables, submitted to NPJ imaging",
      "pdf_url": "http://arxiv.org/pdf/2409.12973v1",
      "published_date": "2024-09-03 00:48:50 UTC",
      "updated_date": "2024-09-03 00:48:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:14:14.633568"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 100,
  "processed_papers_count": 100,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-19T21:14:44.238986"
}