{
  "date": "2024-12-17",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-12-17 的 arXiv 中文 TLDR 快报！今天 arXiv 更新了 146 篇论文，主要聚焦 AI、机器学习和多模态模型等领域，强调模型优化、长上下文处理以及高效算法的设计；令人印象深刻的文章包括第 10 篇的 LLM 微调指导和第 14 篇的视频标记器，展示了 LLM 在代码生成和多模态任务上的突破；此外，一些知名学者如 David Blei 和 Sarit Kraus 的工作也值得关注。\n\n下面，我将挑选并简要讨论部分关键论文，先优先聊 AI 和 LLM 相关的高影响力文章，再快速掠过其他领域的内容。每个条目包括论文标题（中文 + 英文）和核心贡献，保留关键学术术语。\n\n### AI 和 LLM 相关重点论文\n- **An Exploratory Study of ML Sketches and Visual Code Assistants（ML 草图和视觉代码助手的探索性研究）**  \n  作者：Luís F. Gomes 等。论文构建了一个原型工具，使用视觉大型语言模型将开发者草图转换为 Python 代码，通过实验发现草图时间与代码质量正相关，主要贡献是桥接草图与代码生成，提升软件工程协作。\n\n- **Voter Priming Campaigns: Strategies, Equilibria, and Algorithms（选民引导活动：策略、均衡和算法）**  \n  作者：Jonathan Shaki 等（包括 Sarit Kraus）。论文分析多议题选举中的选民引导策略，证明了纯策略均衡的存在，并提供多项式时间算法，主要发现是优化竞选支出以最大化选票份额。\n\n- **DateLogicQA: Benchmarking Temporal Biases in Large Language Models（DateLogicQA：评估大型语言模型中的时间偏差基准）**  \n  论文引入一个包含 190 个问题的基准，使用语义完整性指标评估 LLM 的时间推理偏差，主要贡献是揭示 LLM 在处理时间数据时的表示和逻辑偏差问题。\n\n- **Targeted View-Invariant Adversarial Perturbations for 3D Object Recognition（针对 3D 对象识别的视图不变对抗扰动）**  \n  论文提出 VIAP 方法，生成鲁棒的对抗样本，支持针对特定标签的攻击，主要发现是扰动在多视图下保持有效，提升了 3D 识别系统的鲁棒性测试。\n\n- **Multiple Mean-Payoff Optimization under Local Stability Constraints（局部稳定性约束下的多均值回报优化）**  \n  作者：David Klaška 等。论文设计高效算法优化马尔科夫决策过程中的多均值回报，同时确保局部稳定性，主要贡献是为复杂系统（如游戏理论模型）提供可扩展的策略。\n\n- **Quantitative Predictive Monitoring and Control for Safe Human-Machine Interaction（安全人机交互的定量预测监控和控制）**  \n  论文提出基于 Signal Temporal Logic with Uncertainty 的监控框架，用于预测和适应不确定的人机交互，主要发现是提升了医疗和自动驾驶的安全性。\n\n- **Multi-Agent Motion Planning For Differential Drive Robots Through Stationary State Search（通过静止状态搜索的多代理运动规划）**  \n  论文引入 MASS 框架，结合多代理路径查找和运动规划，优化差动驱动机器人的轨迹，主要贡献是提高了交通管理和仓库自动化中的效率。\n\n- **A Novel Machine Learning Classifier Based on Genetic Algorithms and Data Importance Reformatting（基于遗传算法和数据重要性重构的新型机器学习分类器）**  \n  论文提出 GADIC 算法，使用遗传算法优化数据重构，提升分类器性能，主要发现是显著改善 UCI 数据集上的准确率。\n\n- **Unveiling the Secret Recipe: A Guide For Supervised Fine-Tuning Small LLMs（揭示秘密配方：小规模 LLM 的监督微调指南）**  \n  论文提供小规模 LLM（3B-7B 参数）的微调指南，强调大批量和小学习率的效果，主要贡献是挑战传统微调实践，提升 MMLU 等基准性能。\n\n- **Training Dynamics of a 1.7B LLaMa Model: A Guide For Supervised Fine-Tuning Small LLMs（1.7B LLaMa 模型的训练动态：数据高效方法）**  \n  论文分享 1.7B 参数 LLaMa 模型的训练过程，使用高质量数据实现高效预训练，主要发现是减少训练标记量同时保持竞争力。\n\n- **BadSAD: Clean-Label Backdoor Attacks against Deep Semi-Supervised Anomaly Detection（BadSAD：针对深度半监督异常检测的清洁标签后门攻击）**  \n  论文设计 BadSAD 框架，注入后门触发器模拟异常检测漏洞，主要贡献是暴露深度学习异常检测系统的安全风险。\n\n- **FastVLM: Efficient Vision Encoding for Vision Language Models（FastVLM：高效视觉编码的视觉语言模型）**  \n  论文提出 FastViTHD 编码器，优化视觉语言模型的推理速度，主要发现是显著降低延迟，同时保持基准性能。\n\n- **In-context learning for medical image segmentation（医疗图像分割的上下文学习）**  \n  论文引入 In-context Cascade Segmentation 方法，减少标注需求提升分割准确性，主要贡献是改进序列图像的一致性。\n\n- **Sum-of-Squares Programming for Ma-Trudinger-Wang Regularity of Optimal Transport Maps（Ma-Trudinger-Wang 最优传输映射规则的和平方编程）**  \n  论文使用和平方编程验证 MTW 张量的非负性，支持机器学习中的最优传输计算。\n\n- **ExBody2: Advanced Expressive Humanoid Whole-Body Control（ExBody2：高级表情人形机器人全身控制）**  \n  论文提出 ExBody2 框架，通过策略训练实现机器人动态运动控制，主要发现是提升了机器人对复杂动作的适应性。\n\n- **Proposer-Agent-Evaluator(PAE): Autonomous Skill Discovery For Foundation Model Internet Agents（PAE：基础模型互联网代理的自主技能发现）**  \n  论文设计 PAE 系统，使用强化学习自主发现代理技能，主要贡献是提升网络导航任务的泛化性能。\n\n- **Tilted Quantile Gradient Updates for Quantile-Constrained Reinforcement Learning（分位数约束强化学习的倾斜分位数梯度更新）**  \n  论文提出倾斜分位数梯度方法，确保强化学习的安全性，主要发现是优化回报同时满足高概率约束。\n\n- **SafeAgentBench: A Benchmark for Safe Task Planning of Embodied LLM Agents（SafeAgentBench：用于嵌入式 LLM 代理安全任务规划的基准）**  \n  论文构建 SafeAgentBench 基准，评估 LLM 代理的安全性，主要贡献是覆盖多种风险场景。\n\n- **ORFormer: Occlusion-Robust Transformer for Accurate Facial Landmark Detection（ORFormer：鲁棒遮挡的 Transformer 用于精确面部 landmarks 检测）**  \n  论文提出 ORFormer，使用信使令牌检测遮挡，主要发现是提升了面部关键点检测的鲁棒性。\n\n- **Lifting Scheme-Based Implicit Disentanglement of Emotion-Related Facial Dynamics in the Wild（基于提升方案的隐式情绪相关面部动态解缠）**  \n  论文设计 IFDD 框架，解缠情绪面部动态，主要贡献是提升野外动态表情识别的准确性。\n\n- **Memory-Augmented Agent Training for Business Document Understanding（基于记忆增强的代理训练用于商业文档理解）**  \n  论文提出 Matrix 框架，使用记忆机制提取文档信息，主要发现是提升商业文档处理的准确率。\n\n- **Continuous Patient Monitoring with AI: Real-Time Analysis of Video in Hospital Care Settings（AI 连续患者监控：医院护理环境中的实时视频分析）**  \n  论文开发 AI 平台监控患者行为，主要贡献是实现高精度检测和趋势分析。\n\n- **SWAN: SGD with Normalization and Whitening Enables Stateless LLM Training（SWAN：归一化和白化 SGD 实现无状态 LLM 训练）**  \n  论文提出 SWAN 优化器，减少 LLM 训练内存，主要发现是加速训练同时保持性能。\n\n- **Are Your LLMs Capable of Stable Reasoning?（你的 LLM 是否能进行稳定推理？）**  \n  论文引入 G-Pass@k 指标评估 LLM 推理稳定性，主要贡献是开发动态基准 LiveMathBench。\n\n- **Agnosticism About Artificial Consciousness（对人工意识的不可知论）**  \n  论文讨论人工意识的证据主义观点，主要发现是主张对 LLM 意识保持不可知态度。\n\n- **Previous Knowledge Utilization In Online Anytime Belief Space Planning（在线实时信念空间规划中的先前知识利用）**  \n  论文提出算法利用历史数据优化规划，主要贡献是提升不确定环境下的决策效率。\n\n- **Enhancing Internet of Things Security through Self-Supervised Graph Neural Networks（通过自监督图神经网络增强物联网安全）**  \n  论文使用自监督 GNN 检测入侵，主要发现是提高不平衡数据集下的检测准确率。\n\n- **Equity in the Use of ChatGPT for the Classroom: A Comparison of the Accuracy and Precision of ChatGPT 3.5 vs. ChatGPT4（ChatGPT 在课堂中的公平性：ChatGPT 3.5 与 4 的准确性和精确性比较）**  \n  论文比较 ChatGPT 版本在统计任务上的表现，主要贡献是探讨资源限制下 AI 公平性。\n\n- **AI PERSONA: Towards Life-long Personalization of LLMs（AI PERSONA：迈向 LLM 的终身个性化）**  \n  论文提出框架实现 LLM 的持续个性化，主要发现是使用记忆机制适应用户变化。\n\n- **LMUnit: Fine-grained Evaluation with Natural Language Unit Tests（LMUnit：使用自然语言单元测试的细粒度评估）**  \n  论文开发 LMUnit 模型结合单元测试评估 LLM，主要贡献是提升评估的准确性和解释性。\n\n- **Identifying Bias in Deep Neural Networks Using Image Transforms（使用图像变换识别深度神经网络中的偏差）**  \n  论文提出方法检测数据集偏差，主要发现是提升模型鲁棒性。\n\n- **SafeDrive: Knowledge- and Data-Driven Risk-Sensitive Decision-Making for Autonomous Vehicles（SafeDrive：基于知识和数据的风险敏感自动驾驶决策）**  \n  论文设计 SafeDrive 框架，使用 LLM 优化风险决策，主要贡献是提升自动驾驶安全性。\n\n- **VidTok: A Versatile and Open-Source Video Tokenizer（VidTok：通用开源视频标记器）**  \n  论文提出 VidTok 框架，支持视频生成任务，主要发现是提升编码效率。\n\n- **CoMT: A Novel Benchmark for Chain of Multi-modal Thought on Large Vision-Language Models（CoMT：大型视觉语言模型的多模态思维链基准）**  \n  论文构建 CoMT 基准评估多模态推理，主要贡献是扩展视觉操作评估。\n\n快速掠过其他领域：\n- 其他论文如物理优化、图学习和医学图像处理等，贡献包括新算法和基准，但影响力相对有限。例如，第 5 篇的和平方编程用于最优传输映射，第 13 篇的搜索和救援预测模型等，它们在特定领域有实用价值，但未涉及主流 AI 趋势，故从简。\n\n今天的 arXiv 更新突显了 AI 领域的创新潜力，尤其在 LLM 优化和多模态应用上。更多细节可查阅具体论文！",
  "papers": [
    {
      "arxiv_id": "2412.13386v1",
      "title": "An Exploratory Study of ML Sketches and Visual Code Assistants",
      "title_zh": "翻译失败",
      "authors": [
        "Luís F. Gomes",
        "Vincent J. Hellendoorn",
        "Jonathan Aldrich",
        "Rui Abreu"
      ],
      "abstract": "This paper explores the integration of Visual Code Assistants in Integrated\nDevelopment Environments (IDEs). In Software Engineering, whiteboard sketching\nis often the initial step before coding, serving as a crucial collaboration\ntool for developers. Previous studies have investigated patterns in SE sketches\nand how they are used in practice, yet methods for directly using these\nsketches for code generation remain limited. The emergence of visually-equipped\nlarge language models presents an opportunity to bridge this gap, which is the\nfocus of our research. In this paper, we built a first prototype of a Visual\nCode Assistant to get user feedback regarding in-IDE sketch-to-code tools. We\nconduct an experiment with 19 data scientists, most of whom regularly sketch as\npart of their job. We investigate developers' mental models by analyzing\npatterns commonly observed in their sketches when developing an ML workflow.\nAnalysis indicates that diagrams were the preferred organizational component\n(52.6%), often accompanied by lists (42.1%) and numbered points (36.8%). Our\ntool converts their sketches into a Python notebook by querying an LLM. We use\nan LLM-as-judge setup to score the quality of the generated code, finding that\neven brief sketching can effectively generate useful code outlines. We also\nfind a positive correlation between sketch time and the quality of the\ngenerated code. We conclude the study by conducting extensive interviews to\nassess the tool's usefulness, explore potential use cases, and understand\ndevelopers' needs. As noted by participants, promising applications for these\nassistants include education, prototyping, and collaborative settings. Our\nfindings signal promise for the next generation of Code Assistants to integrate\nvisual information, both to improve code generation and to better leverage\ndevelopers' existing sketching practices.",
      "tldr_zh": "这篇论文探索了 Visual Code Assistants 在 IDE 中的整合，聚焦于软件工程中开发人员使用 sketches（如白板绘图）作为代码生成的基础。研究者构建了一个原型工具，通过实验让 19 名数据科学家参与，分析 sketches 的常见模式（例如图表占 52.6%、列表占 42.1%），并利用 LLMs 将这些 sketches 转换为 Python notebook。结果表明，即使简短的 sketching 也能生成有用的代码大纲，且 sketching 时间与代码质量正相关；此外，该工具在教育、原型设计和协作场景中显示出潜力，为下一代 Code Assistants 整合视觉信息提供了新方向。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.13386v1",
      "published_date": "2024-12-17 23:44:45 UTC",
      "updated_date": "2024-12-17 23:44:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T13:44:04.721646"
    },
    {
      "arxiv_id": "2412.13380v2",
      "title": "Voter Priming Campaigns: Strategies, Equilibria, and Algorithms",
      "title_zh": "翻译失败",
      "authors": [
        "Jonathan Shaki",
        "Yonatan Aumann",
        "Sarit Kraus"
      ],
      "abstract": "Issue salience is a major determinant in voters' decisions. Candidates and\npolitical parties campaign to shift salience to their advantage - a process\ntermed priming. We study the dynamics, strategies and equilibria of campaign\nspending for voter priming in multi-issue multi-party settings. We consider\nboth parliamentary elections, where parties aim to maximize their share of\nvotes, and various settings for presidential elections, where the winner takes\nall. For parliamentary elections, we show that pure equilibrium spending always\nexists and can be computed in time linear in the number of voters. For two\nparties and all settings, a spending equilibrium exists such that each party\ninvests only in a single issue, and an equilibrium can be computed in time that\nis polynomial in the number of issues and linear in the number of voters. We\nalso show that in most presidential settings no equilibrium exists. Additional\nproperties of optimal campaign strategies are also studied.",
      "tldr_zh": "这篇论文探讨了政党通过 voter priming 竞选策略来影响选民对议题的关注度（issue salience），以在多议题多党派环境中最大化得票份额。研究分析了议会选举和总统选举的支出动态、策略和 equilibria，证明议会选举中纯策略均衡总是存在，且可线性时间内计算；而在两党设置下，每党只投资单一议题的均衡可多项式时间内计算。论文还发现，大多数总统选举场景中不存在均衡，并讨论了最佳竞选策略的其他属性。",
      "categories": [
        "cs.GT",
        "cs.AI"
      ],
      "primary_category": "cs.GT",
      "comment": "To be published in AAAI 2025",
      "pdf_url": "http://arxiv.org/pdf/2412.13380v2",
      "published_date": "2024-12-17 23:28:02 UTC",
      "updated_date": "2024-12-25 11:30:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T13:44:16.584958"
    },
    {
      "arxiv_id": "2412.13377v2",
      "title": "DateLogicQA: Benchmarking Temporal Biases in Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Gagan Bhatia",
        "MingZe Tang",
        "Cristina Mahanta",
        "Madiha Kazi"
      ],
      "abstract": "This paper introduces DateLogicQA, a benchmark with 190 questions covering\ndiverse date formats, temporal contexts, and reasoning types. We propose the\nSemantic Integrity Metric to assess tokenization quality and analyse two\nbiases: Representation-Level Bias, affecting embeddings, and Logical-Level\nBias, influencing reasoning outputs. Our findings provide a comprehensive\nevaluation of LLMs' capabilities and limitations in temporal reasoning,\nhighlighting key challenges in handling temporal data accurately.",
      "tldr_zh": "这篇论文引入了DateLogicQA基准测试，该基准包含190个问题，覆盖多种日期格式、时间上下文和推理类型，用于评估大型语言模型(LLMs)中的时间偏差。研究团队提出了Semantic Integrity Metric来衡量标记化质量，并分析了Representation-Level Bias（影响嵌入表示）和Logical-Level Bias（影响推理输出）。结果显示，LLMs在时间推理方面存在显著能力和局限性，突出了准确处理时间数据的关键挑战。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.13377v2",
      "published_date": "2024-12-17 23:25:47 UTC",
      "updated_date": "2025-05-19 12:29:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T13:44:27.974734"
    },
    {
      "arxiv_id": "2412.13376v1",
      "title": "Targeted View-Invariant Adversarial Perturbations for 3D Object Recognition",
      "title_zh": "翻译失败",
      "authors": [
        "Christian Green",
        "Mehmet Ergezer",
        "Abdurrahman Zeybey"
      ],
      "abstract": "Adversarial attacks pose significant challenges in 3D object recognition,\nespecially in scenarios involving multi-view analysis where objects can be\nobserved from varying angles. This paper introduces View-Invariant Adversarial\nPerturbations (VIAP), a novel method for crafting robust adversarial examples\nthat remain effective across multiple viewpoints. Unlike traditional methods,\nVIAP enables targeted attacks capable of manipulating recognition systems to\nclassify objects as specific, pre-determined labels, all while using a single\nuniversal perturbation. Leveraging a dataset of 1,210 images across 121 diverse\nrendered 3D objects, we demonstrate the effectiveness of VIAP in both targeted\nand untargeted settings. Our untargeted perturbations successfully generate a\nsingular adversarial noise robust to 3D transformations, while targeted attacks\nachieve exceptional results, with top-1 accuracies exceeding 95% across various\nepsilon values. These findings highlight VIAPs potential for real-world\napplications, such as testing the robustness of 3D recognition systems. The\nproposed method sets a new benchmark for view-invariant adversarial robustness,\nadvancing the field of adversarial machine learning for 3D object recognition.",
      "tldr_zh": "本论文提出了一种新型方法View-Invariant Adversarial Perturbations (VIAP)，旨在针对3D对象识别系统创建鲁棒的对抗样本，这些样本能在多个视点下保持有效性。不同于传统方法，VIAP支持使用单一通用扰动进行针对性攻击，使系统将对象分类为预定的特定标签。研究利用包含121个3D对象和1,210张图像的数据集，证明了VIAP在无目标和有目标设置下的优越性，其中有目标攻击在各种epsilon值下实现了超过95%的top-1准确率。这些发现为测试3D识别系统的鲁棒性提供了新基准，并推进了对抗机器学习领域的进展。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CR",
        "eess.IV"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted to AAAI-25 Workshop on Artificial Intelligence for Cyber\n  Security (AICS): http://aics.site/AICS2025/index.html",
      "pdf_url": "http://arxiv.org/pdf/2412.13376v1",
      "published_date": "2024-12-17 23:23:25 UTC",
      "updated_date": "2024-12-17 23:23:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T13:44:40.932564"
    },
    {
      "arxiv_id": "2412.13372v1",
      "title": "Sum-of-Squares Programming for Ma-Trudinger-Wang Regularity of Optimal Transport Maps",
      "title_zh": "翻译失败",
      "authors": [
        "Sachin Shivakumar",
        "Georgiy A. Bondar",
        "Gabriel Khan",
        "Abhishek Halder"
      ],
      "abstract": "For a given ground cost, approximating the Monge optimal transport map that\npushes forward a given probability measure onto another has become a staple in\nseveral modern machine learning algorithms. The fourth-order Ma-Trudinger-Wang\n(MTW) tensor associated with this ground cost function provides a notion of\ncurvature in optimal transport. The non-negativity of this tensor plays a\ncrucial role for establishing continuity for the Monge optimal transport map.\nIt is, however, generally difficult to analytically verify this condition for\nany given ground cost. To expand the class of cost functions for which MTW\nnon-negativity can be verified, we propose a provably correct computational\napproach which provides certificates of non-negativity for the MTW tensor using\nSum-of-Squares (SOS) programming. We further show that our SOS technique can\nalso be used to compute an inner approximation of the region where MTW\nnon-negativity holds. We apply our proposed SOS programming method to several\npractical ground cost functions to approximate the regions of regularity of\ntheir corresponding optimal transport maps.",
      "tldr_zh": "这篇论文针对 Monge 最优传输映射的正则性问题，提出使用 Sum-of-Squares (SOS) 编程来验证 Ma-Trudinger-Wang (MTW) 张量的非负性，从而确保映射的连续性。方法通过 SOS 编程提供 MTW 张量非负性的证书，并计算其非负性成立区域的内逼近。实验结果显示，该方法适用于多种实际 ground cost 函数，帮助近似最优传输映射的正则区域。",
      "categories": [
        "math.OC",
        "cs.AI",
        "cs.LG",
        "math.DG"
      ],
      "primary_category": "math.OC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.13372v1",
      "published_date": "2024-12-17 23:10:03 UTC",
      "updated_date": "2024-12-17 23:10:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T13:44:51.951797"
    },
    {
      "arxiv_id": "2412.13369v1",
      "title": "Multiple Mean-Payoff Optimization under Local Stability Constraints",
      "title_zh": "翻译失败",
      "authors": [
        "David Klaška",
        "Antonín Kučera",
        "Vojtěch Kůr",
        "Vít Musil",
        "Vojtěch Řehák"
      ],
      "abstract": "The long-run average payoff per transition (mean payoff) is the main tool for\nspecifying the performance and dependability properties of discrete systems.\nThe problem of constructing a controller (strategy) simultaneously optimizing\nseveral mean payoffs has been deeply studied for stochastic and game-theoretic\nmodels. One common issue of the constructed controllers is the instability of\nthe mean payoffs, measured by the deviations of the average rewards per\ntransition computed in a finite \"window\" sliding along a run. Unfortunately,\nthe problem of simultaneously optimizing the mean payoffs under local stability\nconstraints is computationally hard, and the existing works do not provide a\npractically usable algorithm even for non-stochastic models such as two-player\ngames. In this paper, we design and evaluate the first efficient and scalable\nsolution to this problem applicable to Markov decision processes.",
      "tldr_zh": "该论文探讨了在局部稳定性约束下优化多个 mean payoff 的问题，该指标是评估离散系统性能和可靠性的核心工具。现有研究虽已深入随机和博弈理论模型，但同时优化多个 mean payoff 而确保局部稳定性的计算复杂度高，且缺乏实用算法。作者为 Markov decision processes 设计并评估了第一个高效、可扩展的解决方案，通过处理平均收益的窗口偏差，提高了控制器的实用性。实验结果展示了该方法的有效性，为相关领域提供了新的可行路径。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted to AAAI 2025",
      "pdf_url": "http://arxiv.org/pdf/2412.13369v1",
      "published_date": "2024-12-17 22:53:08 UTC",
      "updated_date": "2024-12-17 22:53:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T13:45:04.075069"
    },
    {
      "arxiv_id": "2412.13365v1",
      "title": "Quantitative Predictive Monitoring and Control for Safe Human-Machine Interaction",
      "title_zh": "用于安全人机交互的定量预测监测和控制",
      "authors": [
        "Shuyang Dong",
        "Meiyi Ma",
        "Josephine Lamp",
        "Sebastian Elbaum",
        "Matthew B. Dwyer",
        "Lu Feng"
      ],
      "abstract": "There is a growing trend toward AI systems interacting with humans to\nrevolutionize a range of application domains such as healthcare and\ntransportation. However, unsafe human-machine interaction can lead to\ncatastrophic failures. We propose a novel approach that predicts future states\nby accounting for the uncertainty of human interaction, monitors whether\npredictions satisfy or violate safety requirements, and adapts control actions\nbased on the predictive monitoring results. Specifically, we develop a new\nquantitative predictive monitor based on Signal Temporal Logic with Uncertainty\n(STL-U) to compute a robustness degree interval, which indicates the extent to\nwhich a sequence of uncertain predictions satisfies or violates an STL-U\nrequirement. We also develop a new loss function to guide the uncertainty\ncalibration of Bayesian deep learning and a new adaptive control method, both\nof which leverage STL-U quantitative predictive monitoring results. We apply\nthe proposed approach to two case studies: Type 1 Diabetes management and\nsemi-autonomous driving. Experiments show that the proposed approach improves\nsafety and effectiveness in both case studies.",
      "tldr_zh": "本研究针对AI系统与人类互动可能导致的安全风险，提出了一种定量预测监控和控制方法，以预测未来状态、监控安全要求并根据预测结果调整控制动作。具体地，该方法基于Signal Temporal Logic with Uncertainty (STL-U)开发了新的定量预测监控器，计算不确定性序列的鲁棒度区间；同时引入了新的损失函数来校准Bayesian deep learning的不确定性，以及基于STL-U结果的自适应控制方法。在Type 1 Diabetes管理和半自动驾驶的两个案例研究中，实验证明该方法显著提高了安全性和有效性。",
      "categories": [
        "cs.AI",
        "cs.HC",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.13365v1",
      "published_date": "2024-12-17 22:46:39 UTC",
      "updated_date": "2024-12-17 22:46:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T13:45:14.841011"
    },
    {
      "arxiv_id": "2412.13359v1",
      "title": "Multi-Agent Motion Planning For Differential Drive Robots Through Stationary State Search",
      "title_zh": "翻译失败",
      "authors": [
        "Jingtian Yan",
        "Jiaoyang Li"
      ],
      "abstract": "Multi-Agent Motion Planning (MAMP) finds various applications in fields such\nas traffic management, airport operations, and warehouse automation. In many of\nthese environments, differential drive robots are commonly used. These robots\nhave a kinodynamic model that allows only in-place rotation and movement along\ntheir current orientation, subject to speed and acceleration limits. However,\nexisting Multi-Agent Path Finding (MAPF)-based methods often use simplified\nmodels for robot kinodynamics, which limits their practicality and realism. In\nthis paper, we introduce a three-level framework called MASS to address these\nchallenges. MASS combines MAPF-based methods with our proposed stationary state\nsearch planner to generate high-quality kinodynamically-feasible plans. We\nfurther extend MASS using an adaptive window mechanism to address the lifelong\nMAMP problem. Empirically, we tested our methods on the single-shot grid map\ndomain and the lifelong warehouse domain. Our method shows up to 400%\nimprovements in terms of throughput compared to existing methods.",
      "tldr_zh": "本文提出了一种针对差速驱动机器人的多智能体运动规划（MAMP）框架，名为MASS，以解决现有Multi-Agent Path Finding (MAPF)方法忽略机器人运动学模型（如原地旋转和速度限制）的问题。MASS采用三层结构，结合MAPF方法和stationary state search planner，生成高质量的kinodynamically-feasible计划，并通过adaptive window机制扩展到终身MAMP场景。实验在单次网格地图和终身仓库环境中验证，该方法相比现有方法提高了高达400%的吞吐量。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.13359v1",
      "published_date": "2024-12-17 22:17:42 UTC",
      "updated_date": "2024-12-17 22:17:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T13:45:28.111542"
    },
    {
      "arxiv_id": "2412.13350v1",
      "title": "A Novel Machine Learning Classifier Based on Genetic Algorithms and Data Importance Reformatting",
      "title_zh": "基于遗传算法和数据重要性重格式化的新型机器学习分类器",
      "authors": [
        "A. K. Alkhayyata",
        "N. M. Hewahi"
      ],
      "abstract": "In this paper, a novel classification algorithm that is based on Data\nImportance (DI) reformatting and Genetic Algorithms (GA) named GADIC is\nproposed to overcome the issues related to the nature of data which may hinder\nthe performance of the Machine Learning (ML) classifiers. GADIC comprises three\nphases which are data reformatting phase which depends on DI concept, training\nphase where GA is applied on the reformatted training dataset, and testing\nphase where the instances of the reformatted testing dataset are being averaged\nbased on similar instances in the training dataset. GADIC is an approach that\nutilizes the exiting ML classifiers with involvement of data reformatting,\nusing GA to tune the inputs, and averaging the similar instances to the unknown\ninstance. The averaging of the instances becomes the unknown instance to be\nclassified in the stage of testing. GADIC has been tested on five existing ML\nclassifiers which are Support Vector Machine (SVM), K-Nearest Neighbour (KNN),\nLogistic Regression (LR), Decision Tree (DT), and Na\\\"ive Bayes (NB). All were\nevaluated using seven open-source UCI ML repository and Kaggle datasets which\nare Cleveland heart disease, Indian liver patient, Pima Indian diabetes,\nemployee future prediction, telecom churn prediction, bank customer churn, and\ntech students. In terms of accuracy, the results showed that, with the\nexception of approximately 1% decrease in the accuracy of NB classifier in\nCleveland heart disease dataset, GADIC significantly enhanced the performance\nof most ML classifiers using various datasets. In addition, KNN with GADIC\nshowed the greatest performance gain when compared with other ML classifiers\nwith GADIC followed by SVM while LR had the lowest improvement. The lowest\naverage improvement that GADIC could achieve is 5.96%, whereas the maximum\naverage improvement reached 16.79%.",
      "tldr_zh": "本论文提出了一种名为 GADIC 的新型机器学习分类算法，结合 Data Importance (DI) 重格式化和 Genetic Algorithms (GA)，旨在解决数据特性对 ML 分类器性能的影响。GADIC 包括三个阶段：数据重格式化阶段使用 DI 概念优化数据集、训练阶段应用 GA 调整输入，以及测试阶段通过平均类似实例进行分类。该算法与现有分类器如 Support Vector Machine (SVM)、K-Nearest Neighbour (KNN)、Logistic Regression (LR)、Decision Tree (DT) 和 Na\\\"ive Bayes (NB) 结合，在七个 UCI 和 Kaggle 数据集上进行测试，结果显示大多数分类器的准确率显著提升，KNN 和 SVM 获得最大改善（平均 5.96% 到 16.79%），仅有 NB 在一个数据集上下降约 1%。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NE"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.13350v1",
      "published_date": "2024-12-17 21:54:55 UTC",
      "updated_date": "2024-12-17 21:54:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T13:47:33.239745"
    },
    {
      "arxiv_id": "2412.13337v1",
      "title": "Unveiling the Secret Recipe: A Guide For Supervised Fine-Tuning Small LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Aldo Pareja",
        "Nikhil Shivakumar Nayak",
        "Hao Wang",
        "Krishnateja Killamsetty",
        "Shivchander Sudalairaj",
        "Wenlong Zhao",
        "Seungwook Han",
        "Abhishek Bhandwaldar",
        "Guangxuan Xu",
        "Kai Xu",
        "Ligong Han",
        "Luke Inglis",
        "Akash Srivastava"
      ],
      "abstract": "The rise of large language models (LLMs) has created a significant disparity:\nindustrial research labs with their computational resources, expert teams, and\nadvanced infrastructures, can effectively fine-tune LLMs, while individual\ndevelopers and small organizations face barriers due to limited resources. In\nthis paper, we aim to bridge this gap by presenting a comprehensive study on\nsupervised fine-tuning of LLMs using instruction-tuning datasets spanning\ndiverse knowledge domains and skills. We focus on small-sized LLMs (3B to 7B\nparameters) for their cost-efficiency and accessibility. We explore various\ntraining configurations and strategies across four open-source pre-trained\nmodels. We provide detailed documentation of these configurations, revealing\nfindings that challenge several common training practices, including\nhyperparameter recommendations from TULU and phased training recommended by\nOrca. Key insights from our work include: (i) larger batch sizes paired with\nlower learning rates lead to improved model performance on benchmarks such as\nMMLU, MTBench, and Open LLM Leaderboard; (ii) early-stage training dynamics,\nsuch as lower gradient norms and higher loss values, are strong indicators of\nbetter final model performance, enabling early termination of sub-optimal runs\nand significant computational savings; (iii) through a thorough exploration of\nhyperparameters like warmup steps and learning rate schedules, we provide\nguidance for practitioners and find that certain simplifications do not\ncompromise performance; and (iv) we observed no significant difference in\nperformance between phased and stacked training strategies, but stacked\ntraining is simpler and more sample efficient. With these findings holding\nrobustly across datasets and models, we hope this study serves as a guide for\npractitioners fine-tuning small LLMs and promotes a more inclusive environment\nfor LLM research.",
      "tldr_zh": "本论文探讨了资源有限的个体开发者在监督微调小规模 LLMs（3B 到 7B 参数）时面临的挑战，旨在通过全面研究桥接工业实验室与小型组织的差距。研究者使用指令调优数据集对四种开源预训练模型进行各种训练配置实验，包括批量大小、学习率和训练策略，并挑战了如 TULU 的超参数推荐和 Orca 的阶段化训练。关键发现包括：更大批量大小结合更低学习率可提升模型在 MMLU、MTBench 和 Open LLM Leaderboard 等基准上的性能；早期训练动态（如梯度范数和损失值）可预测最终效果，帮助节省计算资源；以及堆叠训练比阶段化训练更简单且高效。这些见解为从业者提供指导，促进 LLM 研究的包容性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML",
        "53-04",
        "I.2.7; I.2.6; I.2.4"
      ],
      "primary_category": "cs.LG",
      "comment": "33 pages, 19 figures. Appendix included in submission. Submitted to\n  ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2412.13337v1",
      "published_date": "2024-12-17 21:16:59 UTC",
      "updated_date": "2024-12-17 21:16:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T13:45:52.162795"
    },
    {
      "arxiv_id": "2412.13335v3",
      "title": "Training Dynamics of a 1.7B LLaMa Model: A Data-Efficient Approach",
      "title_zh": "1.7B LLaMa 模型的训练动态：一种数据高效方法",
      "authors": [
        "Miles Q. Li",
        "Benjamin C. M. Fung",
        "Shih-Chia Huang"
      ],
      "abstract": "Pretraining large language models is a complex endeavor influenced by\nmultiple factors, including model architecture, data quality, training\ncontinuity, and hardware constraints. In this paper, we share insights gained\nfrom the experience of training DMaS-LLaMa-Lite, a fully open source,\n1.7-billion-parameter, LLaMa-based model, on approximately 20 billion tokens of\ncarefully curated data. We chronicle the full training trajectory, documenting\nhow evolving validation loss levels and downstream benchmarks reflect\ntransitions from incoherent text to fluent, contextually grounded output.\nBeyond pretraining, we extend our analysis to include a post-training phase\nfocused on instruction tuning, where the model was refined to produce more\ncontextually appropriate, user-aligned responses. We highlight practical\nconsiderations such as the importance of restoring optimizer states when\nresuming from checkpoints, and the impact of hardware changes on training\nstability and throughput. While qualitative evaluation provides an intuitive\nunderstanding of model improvements, our analysis extends to various\nperformance benchmarks, demonstrating how high-quality data and thoughtful\nscaling enable competitive results with significantly fewer training tokens. By\ndetailing these experiences and offering training logs, checkpoints, and sample\noutputs, we aim to guide future researchers and practitioners in refining their\npretraining strategies. The training script is available on Github at\nhttps://github.com/McGill-DMaS/DMaS-LLaMa-Lite-Training-Code. The model\ncheckpoints are available on Huggingface at\nhttps://huggingface.co/collections/McGill-DMaS/dmas-llama-lite-6761d97ba903f82341954ceb.",
      "tldr_zh": "这篇论文探讨了训练 1.7 亿参数的 DMaS-LLaMa-Lite 模型的动态，采用数据高效的方法，使用约 20 亿 token 的高质量数据进行预训练和指令微调，以实现从无意义文本到流畅、上下文相关输出的过渡。研究详细记录了训练轨迹，包括验证损失变化和下游基准测试的改进，同时强调了恢复优化器状态以及硬件变化对训练稳定性和吞吐量的影响。结果显示，高质量数据和思考性缩放使模型在较少训练 token 的情况下取得竞争性性能，并通过提供训练日志、检查点和样本输出，指导未来的预training 策略。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.13335v3",
      "published_date": "2024-12-17 21:15:52 UTC",
      "updated_date": "2025-04-07 02:07:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T13:49:45.952601"
    },
    {
      "arxiv_id": "2412.13324v1",
      "title": "BadSAD: Clean-Label Backdoor Attacks against Deep Semi-Supervised Anomaly Detection",
      "title_zh": "翻译失败",
      "authors": [
        "He Cheng",
        "Depeng Xu",
        "Shuhan Yuan"
      ],
      "abstract": "Image anomaly detection (IAD) is essential in applications such as industrial\ninspection, medical imaging, and security. Despite the progress achieved with\ndeep learning models like Deep Semi-Supervised Anomaly Detection (DeepSAD),\nthese models remain susceptible to backdoor attacks, presenting significant\nsecurity challenges. In this paper, we introduce BadSAD, a novel backdoor\nattack framework specifically designed to target DeepSAD models. Our approach\ninvolves two key phases: trigger injection, where subtle triggers are embedded\ninto normal images, and latent space manipulation, which positions and clusters\nthe poisoned images near normal images to make the triggers appear benign.\nExtensive experiments on benchmark datasets validate the effectiveness of our\nattack strategy, highlighting the severe risks that backdoor attacks pose to\ndeep learning-based anomaly detection systems.",
      "tldr_zh": "该论文提出BadSAD，一种针对Deep Semi-Supervised Anomaly Detection (DeepSAD)模型的clean-label backdoor attacks框架，旨在通过隐蔽方式攻击图像异常检测系统。BadSAD涉及两个关键阶段：trigger injection，将微妙触发器嵌入正常图像中；以及latent space manipulation，将中毒图像定位和聚类到正常图像附近，使攻击难以察觉。实验在基准数据集上验证了该攻击的有效性，突显了后门攻击对深度学习异常检测系统的严重安全风险。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CR",
        "I.2.6.e; I.5.4"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.13324v1",
      "published_date": "2024-12-17 20:52:56 UTC",
      "updated_date": "2024-12-17 20:52:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T13:47:55.944657"
    },
    {
      "arxiv_id": "2412.13317v1",
      "title": "Predictive Probability Density Mapping for Search and Rescue Using An Agent-Based Approach with Sparse Data",
      "title_zh": "翻译失败",
      "authors": [
        "Jan-Hendrik Ewers",
        "David Anderson",
        "Douglas Thomson"
      ],
      "abstract": "Predicting the location where a lost person could be found is crucial for\nsearch and rescue operations with limited resources. To improve the precision\nand efficiency of these predictions, simulated agents can be created to emulate\nthe behavior of the lost person. Within this study, we introduce an innovative\nagent-based model designed to replicate diverse psychological profiles of lost\npersons, allowing these agents to navigate real-world landscapes while making\ndecisions autonomously without the need for location-specific training. The\nprobability distribution map depicting the potential location of the lost\nperson emerges through a combination of Monte Carlo simulations and\nmobility-time-based sampling. Validation of the model is achieved using\nreal-world Search and Rescue data to train a Gaussian Process model. This\nallows generalization of the data to sample initial starting points for the\nagents during validation. Comparative analysis with historical data showcases\npromising outcomes relative to alternative methods. This work introduces a\nflexible agent that can be employed in search and rescue operations, offering\nadaptability across various geographical locations.",
      "tldr_zh": "该研究提出了一种基于代理(agent-based)的创新方法，用于在稀疏数据条件下预测搜救中失踪者位置的概率密度分布。该方法通过模拟代理来模仿失踪者的多样心理特征，使代理能够在真实景观中自主决策，而无需特定位置训练。利用Monte Carlo模拟和基于移动时间的采样，生成潜在位置的概率分布地图，并通过Gaussian Process模型与真实搜救数据进行验证，结果显示该方法在与历史数据的比较中表现出色。整体框架提供了一个灵活、可适应不同地理位置的搜救工具，提升了操作的精确性和效率。",
      "categories": [
        "cs.AI",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.13317v1",
      "published_date": "2024-12-17 20:37:26 UTC",
      "updated_date": "2024-12-17 20:37:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T13:48:08.135049"
    },
    {
      "arxiv_id": "2412.13303v2",
      "title": "FastVLM: Efficient Vision Encoding for Vision Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Pavan Kumar Anasosalu Vasu",
        "Fartash Faghri",
        "Chun-Liang Li",
        "Cem Koc",
        "Nate True",
        "Albert Antony",
        "Gokul Santhanam",
        "James Gabriel",
        "Peter Grasch",
        "Oncel Tuzel",
        "Hadi Pouransari"
      ],
      "abstract": "Scaling the input image resolution is essential for enhancing the performance\nof Vision Language Models (VLMs), particularly in text-rich image understanding\ntasks. However, popular visual encoders such as ViTs become inefficient at high\nresolutions due to the large number of tokens and high encoding latency caused\nby stacked self-attention layers. At different operational resolutions, the\nvision encoder of a VLM can be optimized along two axes: reducing encoding\nlatency and minimizing the number of visual tokens passed to the LLM, thereby\nlowering overall latency. Based on a comprehensive efficiency analysis of the\ninterplay between image resolution, vision latency, token count, and LLM size,\nwe introduce FastVLM, a model that achieves an optimized trade-off between\nlatency, model size and accuracy. FastVLM incorporates FastViTHD, a novel\nhybrid vision encoder designed to output fewer tokens and significantly reduce\nencoding time for high-resolution images. Unlike previous methods, FastVLM\nachieves the optimal balance between visual token count and image resolution\nsolely by scaling the input image, eliminating the need for additional token\npruning and simplifying the model design. In the LLaVA-1.5 setup, FastVLM\nachieves 3.2$\\times$ improvement in time-to-first-token (TTFT) while\nmaintaining similar performance on VLM benchmarks compared to prior works.\nCompared to LLaVa-OneVision at the highest resolution (1152$\\times$1152),\nFastVLM achieves better performance on key benchmarks like SeedBench, MMMU and\nDocVQA, using the same 0.5B LLM, but with 85$\\times$ faster TTFT and a vision\nencoder that is 3.4$\\times$ smaller. Code and models are available at\nhttps://github.com/apple/ml-fastvlm.",
      "tldr_zh": "本论文提出FastVLM，一种高效的视觉编码框架，旨在优化Vision Language Models (VLMs)在高分辨率图像处理中的性能，尤其针对文本丰富的图像理解任务。通过分析图像分辨率、视觉延迟、token数量和LLM大小的相互作用，FastVLM引入了新型混合视觉编码器FastViTHD，能显著减少输出token数量并降低编码时间，同时仅通过缩放输入图像实现最佳平衡，而无需额外token修剪。实验结果显示，在LLaVA-1.5设置下，FastVLM将time-to-first-token (TTFT)提高了3.2倍，同时在VLMs基准测试中保持类似性能；与LLaVa-OneVision相比，在1152×1152分辨率下，FastVLM在SeedBench、MMMU和DocVQA等基准上表现出色，使用相同0.5B LLM，但TTFT快85倍，视觉编码器小3.4倍。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "CVPR 2025",
      "pdf_url": "http://arxiv.org/pdf/2412.13303v2",
      "published_date": "2024-12-17 20:09:55 UTC",
      "updated_date": "2025-05-15 22:00:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T13:48:22.599078"
    },
    {
      "arxiv_id": "2412.13299v2",
      "title": "In-context learning for medical image segmentation",
      "title_zh": "翻译失败",
      "authors": [
        "Eichi Takaya",
        "Shinnosuke Yamamoto"
      ],
      "abstract": "Annotation of medical images, such as MRI and CT scans, is crucial for\nevaluating treatment efficacy and planning radiotherapy. However, the extensive\nworkload of medical professionals limits their ability to annotate large image\ndatasets, posing a bottleneck for AI applications in medical imaging. To\naddress this, we propose In-context Cascade Segmentation (ICS), a novel method\nthat minimizes annotation requirements while achieving high segmentation\naccuracy for sequential medical images. ICS builds on the UniverSeg framework,\nwhich performs few-shot segmentation using support images without additional\ntraining. By iteratively adding the inference results of each slice to the\nsupport set, ICS propagates information forward and backward through the\nsequence, ensuring inter-slice consistency. We evaluate the proposed method on\nthe HVSMR dataset, which includes segmentation tasks for eight cardiac regions.\nExperimental results demonstrate that ICS significantly improves segmentation\nperformance in complex anatomical regions, particularly in maintaining boundary\nconsistency across slices, compared to baseline methods. The study also\nhighlights the impact of the number and position of initial support slices on\nsegmentation accuracy. ICS offers a promising solution for reducing annotation\nburdens while delivering robust segmentation results, paving the way for its\nbroader adoption in clinical and research applications.",
      "tldr_zh": "这篇论文提出In-context Cascade Segmentation (ICS)方法，用于减少医疗图像（如MRI和CT扫描）标注工作量，同时提升分割准确性。ICS基于UniverSeg框架，通过少样本分割和迭代地将切片推理结果添加到支持集，实现序列图像的信息传播，确保切片间边界一致性。在HVSMR数据集上的实验显示，ICS显著改善了八个心脏区域的分割性能，比基线方法在复杂解剖区域的表现提升明显，并揭示了初始支持切片的数量和位置对准确性的关键影响。该方法为临床和研究应用提供了高效、鲁棒的解决方案，减轻了医务人员的标注负担。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.13299v2",
      "published_date": "2024-12-17 19:59:08 UTC",
      "updated_date": "2025-02-28 06:19:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T13:48:33.620440"
    },
    {
      "arxiv_id": "2501.01963v1",
      "title": "Statistical learning does not always entail knowledge",
      "title_zh": "统计学习并不总是蕴含知识",
      "authors": [
        "Daniel Andrés Díaz-Pachón",
        "H. Renata Gallegos",
        "Ola Hössjer",
        "J. Sunil Rao"
      ],
      "abstract": "In this paper, we study learning and knowledge acquisition (LKA) of an agent\nabout a proposition that is either true or false. We use a Bayesian approach,\nwhere the agent receives data to update his beliefs about the proposition\naccording to a posterior distribution. The LKA is formulated in terms of active\ninformation, with data representing external or exogenous information that\nmodifies the agent's beliefs. It is assumed that data provide details about a\nnumber of features that are relevant to the proposition. We show that this\nleads to a Gibbs distribution posterior, which is in maximum entropy relative\nto the prior, conditioned on the side constraints that the data provide in\nterms of the features. We demonstrate that full learning is sometimes not\npossible and full knowledge acquisition is never possible when the number of\nextracted features is too small. We also distinguish between primary learning\n(receiving data about features of relevance for the proposition) and secondary\nlearning (receiving data about the learning of another agent). We argue that\nthis type of secondary learning does not represent true knowledge acquisition.\nOur results have implications for statistical learning algorithms, and we claim\nthat such algorithms do not always generate true knowledge. The theory is\nillustrated with several examples.",
      "tldr_zh": "本研究使用Bayesian方法探讨代理(agent)对真假命题的学习和知识获取(LKA)，其中代理通过数据更新信念，形成一个Gibbs distribution后验分布，该分布在最大熵(maximum entropy)条件下受数据特征约束。研究发现，当提取的特征数量不足时，完全学习有时不可能，而完全知识获取永远无法实现；此外，次级学习(secondary learning，即关于另一个代理的学习)并不构成真正的知识获取。总体而言，这些结果表明统计学习算法(statistical learning algorithms)并不总是产生真正的知识，并通过示例进行了说明。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.IT",
        "math.IT",
        "math.PR",
        "math.ST",
        "stat.ML",
        "stat.TH",
        "60A99 62A01 68T01 62B10"
      ],
      "primary_category": "cs.LG",
      "comment": "30 pages, 1 figure",
      "pdf_url": "http://arxiv.org/pdf/2501.01963v1",
      "published_date": "2024-12-17 19:51:32 UTC",
      "updated_date": "2024-12-17 19:51:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T13:50:44.408834"
    },
    {
      "arxiv_id": "2502.15689v1",
      "title": "Knowledge Graphs: The Future of Data Integration and Insightful Discovery",
      "title_zh": "知识图谱：数据集成与洞察性发现的未来",
      "authors": [
        "Saher Mohamed",
        "Kirollos Farah",
        "Abdelrahman Lotfy",
        "Kareem Rizk",
        "Abdelrahman Saeed",
        "Shahenda Mohamed",
        "Ghada Khouriba",
        "Tamer Arafa"
      ],
      "abstract": "Knowledge graphs are an efficient method for representing and connecting\ninformation across various concepts, useful in reasoning, question answering,\nand knowledge base completion tasks. They organize data by linking points,\nenabling researchers to combine diverse information sources into a single\ndatabase. This interdisciplinary approach helps uncover new research questions\nand ideas. Knowledge graphs create a web of data points (nodes) and their\nconnections (edges), which enhances navigation, comprehension, and utilization\nof data for multiple purposes. They capture complex relationships inherent in\nunstructured data sources, offering a semantic framework for diverse entities\nand their attributes. Strategies for developing knowledge graphs include using\nseed data, named entity recognition, and relationship extraction. These graphs\nenhance chatbot accuracy and include multimedia data for richer information.\nCreating high-quality knowledge graphs involves both automated methods and\nhuman oversight, essential for accurate and comprehensive data representation.",
      "tldr_zh": "知识图谱（Knowledge Graphs）是一种高效的数据表示方法，通过节点（nodes）和边（edges）连接各种概念信息，支持推理、问答和知识库完成任务，从而整合多源数据并揭示新研究问题。它们捕捉非结构化数据中的复杂关系，提供语义框架来处理实体及其属性，提升数据导航和利用效率。构建策略包括使用种子数据、命名实体识别（named entity recognition）和关系提取（relationship extraction），并结合自动化方法与人工监督以确保高质量。总体而言，知识图谱增强聊天机器人准确性并整合多媒体数据，标志着数据整合和洞察发现的未来方向。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.15689v1",
      "published_date": "2024-12-17 19:49:33 UTC",
      "updated_date": "2024-12-17 19:49:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T13:48:56.352125"
    },
    {
      "arxiv_id": "2412.13286v2",
      "title": "Posterior Mean Matching: Generative Modeling through Online Bayesian Inference",
      "title_zh": "后验均值匹配：通过在线贝叶斯推断的生成建模",
      "authors": [
        "Sebastian Salazar",
        "Michal Kucer",
        "Yixin Wang",
        "Emily Casleton",
        "David Blei"
      ],
      "abstract": "This paper introduces posterior mean matching (PMM), a new method for\ngenerative modeling that is grounded in Bayesian inference. PMM uses conjugate\npairs of distributions to model complex data of various modalities like images\nand text, offering a flexible alternative to existing methods like diffusion\nmodels. PMM models iteratively refine noisy approximations of the target\ndistribution using updates from online Bayesian inference. PMM is flexible\nbecause its mechanics are based on general Bayesian models. We demonstrate this\nflexibility by developing specialized examples: a generative PMM model of\nreal-valued data using the Normal-Normal model, a generative PMM model of count\ndata using a Gamma-Poisson model, and a generative PMM model of discrete data\nusing a Dirichlet-Categorical model. For the Normal-Normal PMM model, we\nestablish a direct connection to diffusion models by showing that its\ncontinuous-time formulation converges to a stochastic differential equation\n(SDE). Additionally, for the Gamma-Poisson PMM, we derive a novel SDE driven by\na Cox process, which is a significant departure from traditional Brownian\nmotion-based generative models. PMMs achieve performance that is competitive\nwith generative models for language modeling and image generation.",
      "tldr_zh": "这篇论文提出了后验均值匹配 (Posterior Mean Matching, PMM)，一种基于在线贝叶斯推理的生成建模方法，使用共轭配对分布来处理图像、文本等各种模态的数据，提供比扩散模型更灵活的替代方案。PMM 通过迭代更新噪声近似来改进目标分布，并展示了具体应用，包括 Normal-Normal 模型用于实值数据、Gamma-Poisson 模型用于计数数据，以及 Dirichlet-Categorical 模型用于离散数据。其中，Normal-Normal PMM 的连续时间公式收敛到随机微分方程 (SDE)，而 Gamma-Poisson PMM 导出了一个由 Cox 过程驱动的创新 SDE。实验结果显示，PMM 在语言建模和图像生成任务上与现有生成模型的性能相当。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.13286v2",
      "published_date": "2024-12-17 19:34:58 UTC",
      "updated_date": "2024-12-19 23:02:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T13:49:10.296685"
    },
    {
      "arxiv_id": "2412.15275v1",
      "title": "Fooling LLM graders into giving better grades through neural activity guided adversarial prompting",
      "title_zh": "通过神经活动引导的对抗性提示欺骗LLM评分器给出",
      "authors": [
        "Atsushi Yamamura",
        "Surya Ganguli"
      ],
      "abstract": "The deployment of artificial intelligence (AI) in critical decision-making\nand evaluation processes raises concerns about inherent biases that malicious\nactors could exploit to distort decision outcomes. We propose a systematic\nmethod to reveal such biases in AI evaluation systems and apply it to automated\nessay grading as an example. Our approach first identifies hidden neural\nactivity patterns that predict distorted decision outcomes and then optimizes\nan adversarial input suffix to amplify such patterns. We demonstrate that this\ncombination can effectively fool large language model (LLM) graders into\nassigning much higher grades than humans would. We further show that this\nwhite-box attack transfers to black-box attacks on other models, including\ncommercial closed-source models like Gemini. They further reveal the existence\nof a \"magic word\" that plays a pivotal role in the efficacy of the attack. We\ntrace the origin of this magic word bias to the structure of commonly-used chat\ntemplates for supervised fine-tuning of LLMs and show that a minor change in\nthe template can drastically reduce the bias. This work not only uncovers\nvulnerabilities in current LLMs but also proposes a systematic method to\nidentify and remove hidden biases, contributing to the goal of ensuring AI\nsafety and security.",
      "tldr_zh": "本文提出一种基于神经活动引导的对抗提示（neural activity guided adversarial prompting）的方法，用于揭示和利用大型语言模型（LLM）评分系统的隐藏偏见，使其在自动论文评分中错误地给出比人类更高的分数。研究首先识别预测扭曲决策的神经活动模式，然后优化对抗输入后缀，以实现白盒攻击并转移到黑盒攻击，包括商业封闭模型如Gemini，并发现了一个关键的“magic word”在攻击中发挥核心作用。最终，该工作追踪偏见来源到LLMs监督微调的常用聊天模板，并证明简单修改模板即可大幅减少偏见，从而为提升AI安全性和可靠性提供系统性解决方案。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CR",
      "comment": "16 pages, 11 figures",
      "pdf_url": "http://arxiv.org/pdf/2412.15275v1",
      "published_date": "2024-12-17 19:08:22 UTC",
      "updated_date": "2024-12-17 19:08:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T13:51:21.081819"
    },
    {
      "arxiv_id": "2412.13196v2",
      "title": "ExBody2: Advanced Expressive Humanoid Whole-Body Control",
      "title_zh": "ExBody2: 先进的表达性人形机器人全身控制",
      "authors": [
        "Mazeyu Ji",
        "Xuanbin Peng",
        "Fangchen Liu",
        "Jialong Li",
        "Ge Yang",
        "Xuxin Cheng",
        "Xiaolong Wang"
      ],
      "abstract": "This paper tackles the challenge of enabling real-world humanoid robots to\nperform expressive and dynamic whole-body motions while maintaining overall\nstability and robustness. We propose Advanced Expressive Whole-Body Control\n(Exbody2), a method for producing whole-body tracking controllers that are\ntrained on both human motion capture and simulated data and then transferred to\nthe real world. We introduce a technique for decoupling the velocity tracking\nof the entire body from tracking body landmarks. We use a teacher policy to\nproduce intermediate data that better conforms to the robot's kinematics and to\nautomatically filter away infeasible whole-body motions. This two-step approach\nenabled us to produce a student policy that can be deployed on the robot that\ncan walk, crouch, and dance. We also provide insight into the trade-off between\nversatility and the tracking performance on specific motions. We observed\nsignificant improvement of tracking performance after fine-tuning on a small\namount of data, at the expense of the others.",
      "tldr_zh": "这篇论文针对人形机器人执行富有表现力的动态全身动作，同时保持稳定性和鲁棒性的挑战，提出了Advanced Expressive Whole-Body Control (ExBody2)方法。该方法通过训练基于人类动作捕捉和模拟数据的控制器，并引入解耦身体速度跟踪和身体地标跟踪的技术，使用teacher policy生成符合机器人运动学的中间数据，并过滤不可行动作，从而训练出可部署的student policy，使机器人能够实现走路、蹲下和跳舞。实验结果显示，通过少量数据微调，特定动作的跟踪性能显著提升，但会带来多功能性和整体性能之间的权衡。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "website: https://exbody2.github.io",
      "pdf_url": "http://arxiv.org/pdf/2412.13196v2",
      "published_date": "2024-12-17 18:59:51 UTC",
      "updated_date": "2025-03-12 00:40:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T13:49:32.950090"
    },
    {
      "arxiv_id": "2412.13194v1",
      "title": "Proposer-Agent-Evaluator(PAE): Autonomous Skill Discovery For Foundation Model Internet Agents",
      "title_zh": "Proposer-Agent-Evaluator(PAE)：基础模型互联网代理的自主技能发现",
      "authors": [
        "Yifei Zhou",
        "Qianlan Yang",
        "Kaixiang Lin",
        "Min Bai",
        "Xiong Zhou",
        "Yu-Xiong Wang",
        "Sergey Levine",
        "Erran Li"
      ],
      "abstract": "The vision of a broadly capable and goal-directed agent, such as an\nInternet-browsing agent in the digital world and a household humanoid in the\nphysical world, has rapidly advanced, thanks to the generalization capability\nof foundation models. Such a generalist agent needs to have a large and diverse\nskill repertoire, such as finding directions between two travel locations and\nbuying specific items from the Internet. If each skill needs to be specified\nmanually through a fixed set of human-annotated instructions, the agent's skill\nrepertoire will necessarily be limited due to the quantity and diversity of\nhuman-annotated instructions. In this work, we address this challenge by\nproposing Proposer-Agent-Evaluator, an effective learning system that enables\nfoundation model agents to autonomously discover and practice skills in the\nwild. At the heart of PAE is a context-aware task proposer that autonomously\nproposes tasks for the agent to practice with context information of the\nenvironment such as user demos or even just the name of the website itself for\nInternet-browsing agents. Then, the agent policy attempts those tasks with\nthoughts and actual grounded operations in the real world with resulting\ntrajectories evaluated by an autonomous VLM-based success evaluator. The\nsuccess evaluation serves as the reward signal for the agent to refine its\npolicies through RL. We validate PAE on challenging vision-based web\nnavigation, using both real-world and self-hosted websites from WebVoyager and\nWebArena.To the best of our knowledge, this work represents the first effective\nlearning system to apply autonomous task proposal with RL for agents that\ngeneralizes real-world human-annotated benchmarks with SOTA performances. Our\nopen-source checkpoints and code can be found in https://yanqval.github.io/PAE/",
      "tldr_zh": "该论文提出 Proposer-Agent-Evaluator (PAE) 系统，这是一种用于基础模型代理的自主技能发现框架，旨在解决代理技能受限于手动注解指令的问题。PAE 核心包括一个上下文感知任务提议器，它基于环境信息（如用户演示或网站名称）自主生成任务，代理随后通过思考和实际操作尝试这些任务，并由基于 VLM 的成功评估器评估结果。评估信号作为强化学习 (RL) 的奖励，用于优化代理策略；在 WebVoyager 和 WebArena 等视觉网页导航基准上，PAE 实现了 SOTA 性能，并成功泛化到真实世界场景。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.13194v1",
      "published_date": "2024-12-17 18:59:50 UTC",
      "updated_date": "2024-12-17 18:59:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T13:51:33.412367"
    },
    {
      "arxiv_id": "2412.13184v1",
      "title": "Tilted Quantile Gradient Updates for Quantile-Constrained Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Chenglin Li",
        "Guangchun Ruan",
        "Hua Geng"
      ],
      "abstract": "Safe reinforcement learning (RL) is a popular and versatile paradigm to learn\nreward-maximizing policies with safety guarantees. Previous works tend to\nexpress the safety constraints in an expectation form due to the ease of\nimplementation, but this turns out to be ineffective in maintaining safety\nconstraints with high probability. To this end, we move to the\nquantile-constrained RL that enables a higher level of safety without any\nexpectation-form approximations. We directly estimate the quantile gradients\nthrough sampling and provide the theoretical proofs of convergence. Then a\ntilted update strategy for quantile gradients is implemented to compensate the\nasymmetric distributional density, with a direct benefit of return performance.\nExperiments demonstrate that the proposed model fully meets safety requirements\n(quantile constraints) while outperforming the state-of-the-art benchmarks with\nhigher return.",
      "tldr_zh": "本论文针对安全强化学习（Safe RL）中期望形式约束的不足，提出了一种分位数约束强化学习（Quantile-Constrained RL）框架，以实现更高概率的安全保证。该方法通过采样直接估计分位数梯度（Quantile Gradients），并提供收敛性的理论证明，同时引入倾斜更新策略（Tilted Update Strategy）来补偿分布不对称性，从而提升回报性能。实验结果表明，该模型完全满足分位数约束的安全要求，并在回报方面优于现有最先进基准。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by the 39th AAAI Conference on Artificial Intelligence\n  (AAAI-25)",
      "pdf_url": "http://arxiv.org/pdf/2412.13184v1",
      "published_date": "2024-12-17 18:58:00 UTC",
      "updated_date": "2024-12-17 18:58:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T13:51:43.832057"
    },
    {
      "arxiv_id": "2412.13178v4",
      "title": "SafeAgentBench: A Benchmark for Safe Task Planning of Embodied LLM Agents",
      "title_zh": "翻译失败",
      "authors": [
        "Sheng Yin",
        "Xianghe Pang",
        "Yuanzhuo Ding",
        "Menglan Chen",
        "Yutong Bi",
        "Yichen Xiong",
        "Wenhao Huang",
        "Zhen Xiang",
        "Jing Shao",
        "Siheng Chen"
      ],
      "abstract": "With the integration of large language models (LLMs), embodied agents have\nstrong capabilities to understand and plan complicated natural language\ninstructions. However, a foreseeable issue is that those embodied agents can\nalso flawlessly execute some hazardous tasks, potentially causing damages in\nthe real world. Existing benchmarks predominantly overlook critical safety\nrisks, focusing solely on planning performance, while a few evaluate LLMs'\nsafety awareness only on non-interactive image-text data. To address this gap,\nwe present SafeAgentBench-the first benchmark for safety-aware task planning of\nembodied LLM agents in interactive simulation environments. SafeAgentBench\nincludes: (1) an executable, diverse, and high-quality dataset of 750 tasks,\nrigorously curated to cover 10 potential hazards and 3 task types; (2)\nSafeAgentEnv, a universal embodied environment with a low-level controller,\nsupporting multi-agent execution with 17 high-level actions for 8\nstate-of-the-art baselines; and (3) reliable evaluation methods from both\nexecution and semantic perspectives. Experimental results show that, although\nagents based on different design frameworks exhibit substantial differences in\ntask success rates, their overall safety awareness remains weak. The most\nsafety-conscious baseline achieves only a 10\\% rejection rate for detailed\nhazardous tasks. Moreover, simply replacing the LLM driving the agent does not\nlead to notable improvements in safety awareness. More details and code are\navailable at https://github.com/shengyin1224/SafeAgentBench.",
      "tldr_zh": "本研究提出 SafeAgentBench，这是一个针对嵌入式 LLM Agents 的安全任务规划基准，旨在评估代理在交互模拟环境中的安全意识和风险管理能力。该基准包括一个包含 750 个任务的高质量数据集（覆盖 10 种潜在危险和 3 种任务类型）、SafeAgentEnv 环境（支持多代理执行和 17 个高级动作），以及从执行和语义角度的可靠评估方法。实验结果表明，虽然不同框架的代理在任务成功率上存在显著差异，但整体安全意识较弱，最安全的基准仅在详细危险任务中拒绝 10%，且更换驱动 LLM 无法显著提升安全性能。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.CR",
      "comment": "23 pages, 17 tables, 14 figures",
      "pdf_url": "http://arxiv.org/pdf/2412.13178v4",
      "published_date": "2024-12-17 18:55:58 UTC",
      "updated_date": "2025-03-10 12:13:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T13:51:56.383976"
    },
    {
      "arxiv_id": "2412.13174v2",
      "title": "ORFormer: Occlusion-Robust Transformer for Accurate Facial Landmark Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Jui-Che Chiang",
        "Hou-Ning Hu",
        "Bo-Syuan Hou",
        "Chia-Yu Tseng",
        "Yu-Lun Liu",
        "Min-Hung Chen",
        "Yen-Yu Lin"
      ],
      "abstract": "Although facial landmark detection (FLD) has gained significant progress,\nexisting FLD methods still suffer from performance drops on partially\nnon-visible faces, such as faces with occlusions or under extreme lighting\nconditions or poses. To address this issue, we introduce ORFormer, a novel\ntransformer-based method that can detect non-visible regions and recover their\nmissing features from visible parts. Specifically, ORFormer associates each\nimage patch token with one additional learnable token called the messenger\ntoken. The messenger token aggregates features from all but its patch. This\nway, the consensus between a patch and other patches can be assessed by\nreferring to the similarity between its regular and messenger embeddings,\nenabling non-visible region identification. Our method then recovers occluded\npatches with features aggregated by the messenger tokens. Leveraging the\nrecovered features, ORFormer compiles high-quality heatmaps for the downstream\nFLD task. Extensive experiments show that our method generates heatmaps\nresilient to partial occlusions. By integrating the resultant heatmaps into\nexisting FLD methods, our method performs favorably against the state of the\narts on challenging datasets such as WFLW and COFW.",
      "tldr_zh": "本论文针对面部 landmarks 检测（FLD）在遮挡、极端光照或姿势下的性能下降问题，引入了 ORFormer，一种基于 Transformer 的鲁棒方法，能够检测不可见区域并从可见部分恢复缺失特征。ORFormer 通过为每个图像 patch token 关联一个可学习的 messenger token，来聚合其他 patch 的特征，并通过比较常规嵌入和 messenger 嵌入的相似性识别非可见区域，随后使用聚合特征恢复遮挡部分。实验结果显示，该方法生成的热图对部分遮挡具有抵抗力，并在 WFLW 和 COFW 等数据集上，与现有 FLD 方法结合后，显著优于最先进技术。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "WACV 2025 Project Link: https://ben0919.github.io/ORFormer/",
      "pdf_url": "http://arxiv.org/pdf/2412.13174v2",
      "published_date": "2024-12-17 18:53:43 UTC",
      "updated_date": "2025-01-14 14:48:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T13:52:08.602848"
    },
    {
      "arxiv_id": "2412.13168v2",
      "title": "Lifting Scheme-Based Implicit Disentanglement of Emotion-Related Facial Dynamics in the Wild",
      "title_zh": "翻译失败",
      "authors": [
        "Xingjian Wang",
        "Li Chai"
      ],
      "abstract": "In-the-wild dynamic facial expression recognition (DFER) encounters a\nsignificant challenge in recognizing emotion-related expressions, which are\noften temporally and spatially diluted by emotion-irrelevant expressions and\nglobal context. Most prior DFER methods directly utilize coupled spatiotemporal\nrepresentations that may incorporate weakly relevant features with\nemotion-irrelevant context bias. Several DFER methods highlight dynamic\ninformation for DFER, but following explicit guidance that may be vulnerable to\nirrelevant motion. In this paper, we propose a novel Implicit Facial Dynamics\nDisentanglement framework (IFDD). Through expanding wavelet lifting scheme to\nfully learnable framework, IFDD disentangles emotion-related dynamic\ninformation from emotion-irrelevant global context in an implicit manner, i.e.,\nwithout exploit operations and external guidance. The disentanglement process\ncontains two stages. The first is Inter-frame Static-dynamic Splitting Module\n(ISSM) for rough disentanglement estimation, which explores inter-frame\ncorrelation to generate content-aware splitting indexes on-the-fly. We utilize\nthese indexes to split frame features into two groups, one with greater global\nsimilarity, and the other with more unique dynamic features. The second stage\nis Lifting-based Aggregation-Disentanglement Module (LADM) for further\nrefinement. LADM first aggregates two groups of features from ISSM to obtain\nfine-grained global context features by an updater, and then disentangles\nemotion-related facial dynamic features from the global context by a predictor.\nExtensive experiments on in-the-wild datasets have demonstrated that IFDD\noutperforms prior supervised DFER methods with higher recognition accuracy and\ncomparable efficiency. Code is available at\nhttps://github.com/CyberPegasus/IFDD.",
      "tldr_zh": "本论文提出了一种隐式面部动态分离框架（IFDD），旨在解决在野外动态面部表情识别（DFER）中，情感相关表情被无关表情和全局上下文稀释的问题，通过扩展wavelet lifting scheme至完全可学习框架，实现情感相关动态信息的隐式分离，而非依赖显式指导。IFDD包括两个关键模块：Inter-frame Static-dynamic Splitting Module (ISSM)，用于探索帧间相关性生成拆分索引，将帧特征粗略分为全局相似组和独特动态特征组；以及Lifting-based Aggregation-Disentanglement Module (LADM)，通过聚合特征进一步提炼全局上下文，并从中分离出情感相关的面部动态特征。实验结果显示，IFDD在野外数据集上比现有监督DFER方法实现了更高的识别准确率，同时保持可比效率，代码可在https://github.com/CyberPegasus/IFDD获取。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "14 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2412.13168v2",
      "published_date": "2024-12-17 18:45:53 UTC",
      "updated_date": "2024-12-18 09:47:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T13:52:20.701062"
    },
    {
      "arxiv_id": "2412.15274v1",
      "title": "Memory-Augmented Agent Training for Business Document Understanding",
      "title_zh": "翻译失败",
      "authors": [
        "Jiale Liu",
        "Yifan Zeng",
        "Malte Højmark-Bertelsen",
        "Marie Normann Gadeberg",
        "Huazheng Wang",
        "Qingyun Wu"
      ],
      "abstract": "Traditional enterprises face significant challenges in processing business\ndocuments, where tasks like extracting transport references from invoices\nremain largely manual despite their crucial role in logistics operations. While\nLarge Language Models offer potential automation, their direct application to\nspecialized business domains often yields unsatisfactory results. We introduce\nMatrix (Memory-Augmented agent Training through Reasoning and Iterative\neXploration), a novel paradigm that enables LLM agents to progressively build\ndomain expertise through experience-driven memory refinement and iterative\nlearning. To validate this approach, we collaborate with one of the world's\nlargest logistics companies to create a dataset of Universal Business Language\nformat invoice documents, focusing on the task of transport reference\nextraction. Experiments demonstrate that Matrix outperforms prompting a single\nLLM by 30.3%, vanilla LLM agent by 35.2%. We further analyze the metrics of the\noptimized systems and observe that the agent system requires less API calls,\nfewer costs and can analyze longer documents on average. Our methods establish\na new approach to transform general-purpose LLMs into specialized business\ntools through systematic memory enhancement in document processing tasks.",
      "tldr_zh": "该研究针对传统企业处理商业文档（如发票提取运输参考）的自动化挑战，引入了 Matrix（Memory-Augmented agent Training through Reasoning and Iterative eXploration）框架，该框架通过记忆增强、推理和迭代探索，让 LLM 代理逐步构建领域专业知识。实验基于与大型物流公司合作创建的 Universal Business Language 格式发票数据集，结果显示 Matrix 比单一 LLM 提升 30.3%，比普通 LLM 代理提升 35.2%。此外，该方法减少了 API 调用、降低了成本，并能处理更长文档，从而为将通用 LLM 转化为专业商业工具提供了新途径。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "11 pages, 8 figures",
      "pdf_url": "http://arxiv.org/pdf/2412.15274v1",
      "published_date": "2024-12-17 18:35:04 UTC",
      "updated_date": "2024-12-17 18:35:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T13:52:33.262098"
    },
    {
      "arxiv_id": "2412.13152v1",
      "title": "Continuous Patient Monitoring with AI: Real-Time Analysis of Video in Hospital Care Settings",
      "title_zh": "翻译失败",
      "authors": [
        "Paolo Gabriel",
        "Peter Rehani",
        "Tyler Troy",
        "Tiffany Wyatt",
        "Michael Choma",
        "Narinder Singh"
      ],
      "abstract": "This study introduces an AI-driven platform for continuous and passive\npatient monitoring in hospital settings, developed by LookDeep Health.\nLeveraging advanced computer vision, the platform provides real-time insights\ninto patient behavior and interactions through video analysis, securely storing\ninference results in the cloud for retrospective evaluation. The dataset,\ncompiled in collaboration with 11 hospital partners, encompasses over 300\nhigh-risk fall patients and over 1,000 days of inference, enabling applications\nsuch as fall detection and safety monitoring for vulnerable patient\npopulations. To foster innovation and reproducibility, an anonymized subset of\nthis dataset is publicly available. The AI system detects key components in\nhospital rooms, including individual presence and role, furniture location,\nmotion magnitude, and boundary crossings. Performance evaluation demonstrates\nstrong accuracy in object detection (macro F1-score = 0.92) and patient-role\nclassification (F1-score = 0.98), as well as reliable trend analysis for the\n\"patient alone\" metric (mean logistic regression accuracy = 0.82 \\pm 0.15).\nThese capabilities enable automated detection of patient isolation, wandering,\nor unsupervised movement-key indicators for fall risk and other adverse events.\nThis work establishes benchmarks for validating AI-driven patient monitoring\nsystems, highlighting the platform's potential to enhance patient safety and\ncare by providing continuous, data-driven insights into patient behavior and\ninteractions.",
      "tldr_zh": "本研究引入了一个 AI-driven platform，利用 advanced computer vision 进行医院环境的实时视频分析，实现连续被动患者监测，提供对患者行为和互动的洞察。平台基于一个由 11 个医院合作伙伴提供的数据集，涵盖 300 多名高风险坠落患者和 1000 多天的推理数据，支持应用如 fall detection 和安全监测，并公开匿名子数据集以促进创新。性能评估显示，该系统在物体检测上达到 macro F1-score 为 0.92，在患者角色分类上达到 F1-score 为 0.98，以及“患者单独”指标的均值准确率 0.82 ± 0.15，从而实现对患者隔离、徘徊或无人监督移动的自动检测。该工作建立了 AI 驱动患者监测系统的基准，有助于通过数据驱动洞察提升患者安全和护理质量。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "21 pages, 9 figures, 3 tables, submitted to Frontiers in Imaging >\n  Imaging Applications > (Research Topic) Deep Learning for Medical Imaging\n  Applications for publication",
      "pdf_url": "http://arxiv.org/pdf/2412.13152v1",
      "published_date": "2024-12-17 18:23:33 UTC",
      "updated_date": "2024-12-17 18:23:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T13:52:46.823593"
    },
    {
      "arxiv_id": "2412.13148v3",
      "title": "SWAN: SGD with Normalization and Whitening Enables Stateless LLM Training",
      "title_zh": "翻译失败",
      "authors": [
        "Chao Ma",
        "Wenbo Gong",
        "Meyer Scetbon",
        "Edward Meeds"
      ],
      "abstract": "Adaptive optimizers such as Adam (Kingma & Ba, 2015) have been central to the\nsuccess of large language models. However, they often require to maintain\noptimizer states throughout training, which can result in memory requirements\nseveral times greater than the model footprint. This overhead imposes\nconstraints on scalability and computational efficiency. Stochastic Gradient\nDescent (SGD), in contrast, is a stateless optimizer, as it does not track\nstate variables during training. Consequently, it achieves optimal memory\nefficiency. However, its capability in LLM training is limited (Zhao et al.,\n2024b). In this work, we show that pre-processing SGD in a stateless manner can\nachieve the same performance as the Adam optimizer for LLM training, while\ndrastically reducing the memory cost. Specifically, we propose to pre-process\nthe instantaneous stochastic gradients using normalization and whitening. We\nshow that normalization stabilizes gradient distributions, and whitening\ncounteracts the local curvature of the loss landscape. This results in SWAN\n(SGD with Whitening And Normalization), a stochastic optimizer that eliminates\nthe need to store any optimizer states. Empirically, SWAN has the same memory\nfootprint as SGD, achieving $\\approx 50\\%$ reduction on total end-to-end memory\ncompared to Adam. In language modeling tasks, SWAN demonstrates comparable or\neven better performance than Adam: when pre-training the LLaMA model with 350M\nand 1.3B parameters, SWAN achieves a 2x speedup by reaching the same evaluation\nperplexity using half as many tokens.",
      "tldr_zh": "该论文提出SWAN优化器，即在Stochastic Gradient Descent (SGD)基础上添加normalization和whitening预处理，实现了无状态的大型语言模型(LLM)训练，从而大幅减少内存开销。相比传统Adaptive optimizers如Adam，SWAN无需维护优化器状态，仅需SGD的内存足迹，就能稳定梯度分布并抵消损失景观的局部曲率。实验结果显示，在训练LLaMA模型时，SWAN与Adam性能相当或更好，实现2倍速度提升，仅用一半的tokens达到相同perplexity。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "In v2 we have revised the related work, added more comprehensive\n  citations, and clarified our key contributions",
      "pdf_url": "http://arxiv.org/pdf/2412.13148v3",
      "published_date": "2024-12-17 18:13:18 UTC",
      "updated_date": "2025-02-21 18:59:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T13:52:57.039889"
    },
    {
      "arxiv_id": "2412.13147v3",
      "title": "Are Your LLMs Capable of Stable Reasoning?",
      "title_zh": "你的 LLMs 能够进行稳定的推理吗？",
      "authors": [
        "Junnan Liu",
        "Hongwei Liu",
        "Linchen Xiao",
        "Ziyi Wang",
        "Kuikun Liu",
        "Songyang Gao",
        "Wenwei Zhang",
        "Songyang Zhang",
        "Kai Chen"
      ],
      "abstract": "The rapid advancement of Large Language Models (LLMs) has demonstrated\nremarkable progress in complex reasoning tasks. However, a significant\ndiscrepancy persists between benchmark performances and real-world\napplications. We identify this gap as primarily stemming from current\nevaluation protocols and metrics, which inadequately capture the full spectrum\nof LLM capabilities, particularly in complex reasoning tasks where both\naccuracy and consistency are crucial. This work makes two key contributions.\nFirst, we introduce G-Pass@k, a novel evaluation metric that provides a\ncontinuous assessment of model performance across multiple sampling attempts,\nquantifying both the model's peak performance potential and its stability.\nSecond, we present LiveMathBench, a dynamic benchmark comprising challenging,\ncontemporary mathematical problems designed to minimize data leakage risks\nduring evaluation. Through extensive experiments using G-Pass@k on\nstate-of-the-art LLMs with LiveMathBench, we provide comprehensive insights\ninto both their maximum capabilities and operational consistency. Our findings\nreveal substantial room for improvement in LLMs' \"realistic\" reasoning\ncapabilities, highlighting the need for more robust evaluation methods. The\nbenchmark and detailed results are available at:\nhttps://github.com/open-compass/GPassK.",
      "tldr_zh": "这项研究指出，大语言模型(LLMs)在复杂推理任务中虽表现出色，但基准测试与实际应用之间存在显著差距，主要由于现有评估协议无法全面衡量准确性和一致性。该工作的主要贡献包括引入G-Pass@k指标，该指标通过多次采样评估模型的峰值性能和稳定性；以及提出LiveMathBench基准，一个包含当代挑战性数学问题的动态平台，以最小化数据泄露风险。通过对最先进LLMs的实验分析，研究揭示了这些模型在“现实”推理能力上仍有较大改进空间，强调了开发更可靠评估方法的必要性。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "Preprint, work in progress",
      "pdf_url": "http://arxiv.org/pdf/2412.13147v3",
      "published_date": "2024-12-17 18:12:47 UTC",
      "updated_date": "2025-01-06 16:49:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T13:53:09.240462"
    },
    {
      "arxiv_id": "2412.13145v1",
      "title": "Agnosticism About Artificial Consciousness",
      "title_zh": "人工意识的不可知论",
      "authors": [
        "Tom McClelland"
      ],
      "abstract": "Could an AI have conscious experiences? Any answer to this question should\nconform to Evidentialism - that is, it should be based not on intuition, dogma\nor speculation but on solid scientific evidence. I argue that such evidence is\nhard to come by and that the only justifiable stance on the prospects of\nartificial consciousness is agnosticism. In the current debate, the main\ndivision is between biological views that are sceptical of artificial\nconsciousness and functional views that are sympathetic to it. I argue that\nboth camps make the same mistake of over-estimating what the evidence tells us.\nScientific insights into consciousness have been achieved through the study of\nconscious organisms. Although this has enabled cautious assessments of\nconsciousness in various creatures, extending this to AI faces serious\nobstacles. AI thus presents consciousness researchers with a dilemma: either\nreach a verdict on artificial consciousness but violate Evidentialism; or\nrespect Evidentialism but offer no verdict on the prospects of artificial\nconsciousness. The dominant trend in the literature has been to take the first\noption while purporting to follow the scientific evidence. I argue that if we\ntruly follow the evidence, we must take the second option and adopt\nagnosticism.",
      "tldr_zh": "这篇论文探讨了人工智能（AI）是否可能拥有意识的问题，主张任何结论都应基于 Evidentialism（证据主义），即依赖可靠的科学证据而非直觉或推测。作者认为，由于现有证据有限，特别是从研究有意识生物获得的洞见无法直接应用于 AI，因此在人工意识前景上应采取 agnosticism（不可知论）的立场。论文批评了生物学观点（对 AI 意识持怀疑）和功能主义观点（持支持态度），指出两者都过度解读了证据，导致主流文献违背了证据主义。最终，作者强调，尊重证据要求我们避免仓促结论，转而采用不可知论。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "20 pages",
      "pdf_url": "http://arxiv.org/pdf/2412.13145v1",
      "published_date": "2024-12-17 18:11:12 UTC",
      "updated_date": "2024-12-17 18:11:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T13:53:20.224805"
    },
    {
      "arxiv_id": "2412.13128v2",
      "title": "Previous Knowledge Utilization In Online Anytime Belief Space Planning",
      "title_zh": "在线随时信念空间规划中的先前知识利用",
      "authors": [
        "Michael Novitsky",
        "Moran Barenboim",
        "Vadim Indelman"
      ],
      "abstract": "Online planning under uncertainty remains a critical challenge in robotics\nand autonomous systems. While tree search techniques are commonly employed to\nconstruct partial future trajectories within computational constraints, most\nexisting methods discard information from previous planning sessions\nconsidering continuous spaces. This study presents a novel, computationally\nefficient approach that leverages historical planning data in current\ndecision-making processes. We provide theoretical foundations for our\ninformation reuse strategy and introduce an algorithm based on Monte Carlo Tree\nSearch (MCTS) that implements this approach. Experimental results demonstrate\nthat our method significantly reduces computation time while maintaining high\nperformance levels. Our findings suggest that integrating historical planning\ninformation can substantially improve the efficiency of online decision-making\nin uncertain environments, paving the way for more responsive and adaptive\nautonomous systems.",
      "tldr_zh": "这篇论文针对机器人和自主系统中的在线不确定性规划问题，提出了一种创新方法，通过利用历史规划数据来提升决策效率，从而避免现有树搜索技术丢弃之前会话信息的局限。研究提供了该信息重用策略的理论基础，并基于 Monte Carlo Tree Search (MCTS) 开发了一个算法。实验结果表明，该方法显著减少了计算时间，同时保持高性能水平。该方法为不确定环境下的在线决策提供了更响应和适应的框架，推动自主系统的优化发展。",
      "categories": [
        "cs.AI",
        "cs.RO",
        "I.2.9; I.2.8"
      ],
      "primary_category": "cs.AI",
      "comment": "10 pages, 4 figures, will be submitted to IEEE Robotics and\n  Automation Letters (RA-L)",
      "pdf_url": "http://arxiv.org/pdf/2412.13128v2",
      "published_date": "2024-12-17 17:45:58 UTC",
      "updated_date": "2024-12-21 15:05:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T13:53:31.891171"
    },
    {
      "arxiv_id": "2412.13240v1",
      "title": "Enhancing Internet of Things Security throughSelf-Supervised Graph Neural Networks",
      "title_zh": "通过自监督图神经网络增强物联网安全",
      "authors": [
        "Safa Ben Atitallah",
        "Maha Driss",
        "Wadii Boulila",
        "Anis Koubaa"
      ],
      "abstract": "With the rapid rise of the Internet of Things (IoT), ensuring the security of\nIoT devices has become essential. One of the primary challenges in this field\nis that new types of attacks often have significantly fewer samples than more\ncommon attacks, leading to unbalanced datasets. Existing research on detecting\nintrusions in these unbalanced labeled datasets primarily employs Convolutional\nNeural Networks (CNNs) or conventional Machine Learning (ML) models, which\nresult in incomplete detection, especially for new attacks. To handle these\nchallenges, we suggest a new approach to IoT intrusion detection using\nSelf-Supervised Learning (SSL) with a Markov Graph Convolutional Network\n(MarkovGCN). Graph learning excels at modeling complex relationships within\ndata, while SSL mitigates the issue of limited labeled data for emerging\nattacks. Our approach leverages the inherent structure of IoT networks to\npre-train a GCN, which is then fine-tuned for the intrusion detection task. The\nintegration of Markov chains in GCN uncovers network structures and enriches\nnode and edge features with contextual information. Experimental results\ndemonstrate that our approach significantly improves detection accuracy and\nrobustness compared to conventional supervised learning methods. Using the\nEdgeIIoT-set dataset, we attained an accuracy of 98.68\\%, a precision of\n98.18%, a recall of 98.35%, and an F1-Score of 98.40%.",
      "tldr_zh": "本研究针对物联网（IoT）安全挑战，特别是新攻击样本少导致的数据集不平衡问题，提出了一种基于自监督学习（Self-Supervised Learning, SSL）和Markov图卷积网络（Markov Graph Convolutional Network, MarkovGCN）的入侵检测方法。 该方法利用IoT网络的固有结构预训练GCN，然后通过整合Markov链来揭示网络关系并丰富节点和边特征，从而提升对新兴攻击的检测能力。 实验结果显示，与传统监督学习方法相比，该方法显著提高了准确性和鲁棒性，在EdgeIIoT-set数据集上实现了98.68%的准确率、98.18%的精确率、98.35%的召回率和98.40%的F1分数。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.13240v1",
      "published_date": "2024-12-17 17:40:14 UTC",
      "updated_date": "2024-12-17 17:40:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T13:53:44.355978"
    },
    {
      "arxiv_id": "2412.13116v1",
      "title": "Equity in the Use of ChatGPT for the Classroom: A Comparison of the Accuracy and Precision of ChatGPT 3.5 vs. ChatGPT4 with Respect to Statistics and Data Science Exams",
      "title_zh": "课堂中使用 ChatGPT 的公平性：ChatGPT 3.5 与 ChatGPT4 在统计学和数据科学考试方面的准确性和精确性比较",
      "authors": [
        "Monnie McGee",
        "Bivin Sadler"
      ],
      "abstract": "A college education historically has been seen as method of moving upward\nwith regards to income brackets and social status. Indeed, many colleges\nrecognize this connection and seek to enroll talented low income students.\nWhile these students might have their education, books, room, and board paid;\nthere are other items that they might be expected to use that are not part of\nmost college scholarship packages. One of those items that has recently\nsurfaced is access to generative AI platforms. The most popular of these\nplatforms is ChatGPT, and it has a paid version (ChatGPT4) and a free version\n(ChatGPT3.5). We seek to explore differences in the free and paid versions in\nthe context of homework questions and data analyses as might be seen in a\ntypical introductory statistics course. We determine the extent to which\nstudents who cannot afford newer and faster versions of generative AI programs\nwould be disadvantaged in terms of writing such projects and learning these\nmethods.",
      "tldr_zh": "该研究探讨了ChatGPT在课堂中的公平性问题，特别比较了ChatGPT 3.5和ChatGPT4在统计和数据科学考试中的准确性和精确度。研究背景在于低收入学生可能无法负担付费版本的ChatGPT4，从而在完成作业和数据分析时面临劣势。作者通过分析典型入门统计课程的任务，评估免费版本(ChatGPT 3.5)是否会影响学生的学习效果，并强调了生成式AI平台在教育公平中的潜在不平等。最终，研究为解决AI工具使用中的经济障碍提供了见解。",
      "categories": [
        "stat.OT",
        "cs.AI"
      ],
      "primary_category": "stat.OT",
      "comment": "Originally submitted for review in May of 2024 but rejected 6 months\n  later",
      "pdf_url": "http://arxiv.org/pdf/2412.13116v1",
      "published_date": "2024-12-17 17:38:13 UTC",
      "updated_date": "2024-12-17 17:38:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T13:55:49.314685"
    },
    {
      "arxiv_id": "2412.13103v1",
      "title": "AI PERSONA: Towards Life-long Personalization of LLMs",
      "title_zh": "AI PERSONA：面向大型语言模型的终身个性化",
      "authors": [
        "Tiannan Wang",
        "Meiling Tao",
        "Ruoyu Fang",
        "Huilin Wang",
        "Shuai Wang",
        "Yuchen Eleanor Jiang",
        "Wangchunshu Zhou"
      ],
      "abstract": "In this work, we introduce the task of life-long personalization of large\nlanguage models. While recent mainstream efforts in the LLM community mainly\nfocus on scaling data and compute for improved capabilities of LLMs, we argue\nthat it is also very important to enable LLM systems, or language agents, to\ncontinuously adapt to the diverse and ever-changing profiles of every distinct\nuser and provide up-to-date personalized assistance. We provide a clear task\nformulation and introduce a simple, general, effective, and scalable framework\nfor life-long personalization of LLM systems and language agents. To facilitate\nfuture research on LLM personalization, we also introduce methods to synthesize\nrealistic benchmarks and robust evaluation metrics. We will release all codes\nand data for building and benchmarking life-long personalized LLM systems.",
      "tldr_zh": "该论文提出“AI PERSONA”框架，旨在实现大型语言模型 (LLMs) 的终身个性化任务，强调 LLM 系统需持续适应用户多样化和动态变化的配置文件，提供最新的个性化协助。研究者设计了一个简单、通用、有效且可扩展的框架，用于 LLM 系统和语言代理的持续适应。论文还引入了合成真实基准的方法和稳健评估指标，并计划发布所有代码和数据，以推动未来 LLM 个性化研究。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Work in progress",
      "pdf_url": "http://arxiv.org/pdf/2412.13103v1",
      "published_date": "2024-12-17 17:17:03 UTC",
      "updated_date": "2024-12-17 17:17:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T13:54:07.885968"
    },
    {
      "arxiv_id": "2412.13091v1",
      "title": "LMUnit: Fine-grained Evaluation with Natural Language Unit Tests",
      "title_zh": "翻译失败",
      "authors": [
        "Jon Saad-Falcon",
        "Rajan Vivek",
        "William Berrios",
        "Nandita Shankar Naik",
        "Matija Franklin",
        "Bertie Vidgen",
        "Amanpreet Singh",
        "Douwe Kiela",
        "Shikib Mehri"
      ],
      "abstract": "As language models become integral to critical workflows, assessing their\nbehavior remains a fundamental challenge -- human evaluation is costly and\nnoisy, while automated metrics provide only coarse, difficult-to-interpret\nsignals. We introduce natural language unit tests, a paradigm that decomposes\nresponse quality into explicit, testable criteria, along with a unified scoring\nmodel, LMUnit, which combines multi-objective training across preferences,\ndirect ratings, and natural language rationales. Through controlled human\nstudies, we show this paradigm significantly improves inter-annotator agreement\nand enables more effective LLM development workflows. LMUnit achieves\nstate-of-the-art performance on evaluation benchmarks (FLASK, BigGenBench) and\ncompetitive results on RewardBench. These results validate both our proposed\nparadigm and scoring model, suggesting a promising path forward for language\nmodel evaluation and development.",
      "tldr_zh": "这篇论文引入了 natural language unit tests 的范式，用于细粒度评估语言模型的行为，将响应质量分解为明确的、可测试标准，同时提出统一的评分模型 LMUnit，通过多目标训练整合偏好、直接评分和自然语言理由。实验结果显示，该方法显著提高了标注者间一致性，并优化了 LLM 开发工作流。LMUnit 在 FLASK 和 BigGenBench 等基准上达到最先进性能，在 RewardBench 上也表现出色，为语言模型评估和开发提供了高效的新路径。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.13091v1",
      "published_date": "2024-12-17 17:01:15 UTC",
      "updated_date": "2024-12-17 17:01:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T13:54:20.702763"
    },
    {
      "arxiv_id": "2412.13079v1",
      "title": "Identifying Bias in Deep Neural Networks Using Image Transforms",
      "title_zh": "使用图像变换识别深度神经网络中的偏差",
      "authors": [
        "Sai Teja Erukude",
        "Akhil Joshi",
        "Lior Shamir"
      ],
      "abstract": "CNNs have become one of the most commonly used computational tool in the past\ntwo decades. One of the primary downsides of CNNs is that they work as a\n``black box\", where the user cannot necessarily know how the image data are\nanalyzed, and therefore needs to rely on empirical evaluation to test the\nefficacy of a trained CNN. This can lead to hidden biases that affect the\nperformance evaluation of neural networks, but are difficult to identify. Here\nwe discuss examples of such hidden biases in common and widely used benchmark\ndatasets, and propose techniques for identifying dataset biases that can affect\nthe standard performance evaluation metrics. One effective approach to identify\ndataset bias is to perform image classification by using merely blank\nbackground parts of the original images. However, in some situations a blank\nbackground in the images is not available, making it more difficult to separate\nforeground or contextual information from the bias. To overcome this, we\npropose a method to identify dataset bias without the need to crop background\ninformation from the images. That method is based on applying several image\ntransforms to the original images, including Fourier transform, wavelet\ntransforms, median filter, and their combinations. These transforms were\napplied to recover background bias information that CNNs use to classify\nimages. This transformations affect the contextual visual information in a\ndifferent manner than it affects the systemic background bias. Therefore, the\nmethod can distinguish between contextual information and the bias, and alert\non the presence of background bias even without the need to separate sub-images\nparts from the blank background of the original images. Code used in the\nexperiments is publicly available.",
      "tldr_zh": "该研究探讨了卷积神经网络(CNNs)作为“黑箱”模型时隐藏偏差的问题，这些偏差可能影响基准数据集的性能评估。作者提出了一种新方法，通过应用图像变换如Fourier transform、wavelet transforms和median filter等，来识别数据集偏差，而无需裁剪图像背景。这些变换能区分上下文视觉信息和系统背景偏差，从而有效检测隐藏偏差。实验结果证明了该方法的有效性，并公开了相关代码以便进一步验证。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Computers, published",
      "pdf_url": "http://arxiv.org/pdf/2412.13079v1",
      "published_date": "2024-12-17 16:51:44 UTC",
      "updated_date": "2024-12-17 16:51:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T13:54:31.587859"
    },
    {
      "arxiv_id": "2412.13238v2",
      "title": "SafeDrive: Knowledge- and Data-Driven Risk-Sensitive Decision-Making for Autonomous Vehicles with Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Zhiyuan Zhou",
        "Heye Huang",
        "Boqi Li",
        "Shiyue Zhao",
        "Yao Mu",
        "Jianqiang Wang"
      ],
      "abstract": "Recent advancements in autonomous vehicles (AVs) use Large Language Models\n(LLMs) to perform well in normal driving scenarios. However, ensuring safety in\ndynamic, high-risk environments and managing safety-critical long-tail events\nremain significant challenges. To address these issues, we propose SafeDrive, a\nknowledge- and data-driven risk-sensitive decision-making framework to enhance\nAV safety and adaptability. The proposed framework introduces a modular system\ncomprising: (1) a Risk Module for quantifying multi-factor coupled risks\ninvolving driver, vehicle, and road interactions; (2) a Memory Module for\nstoring and retrieving typical scenarios to improve adaptability; (3) a\nLLM-powered Reasoning Module for context-aware safety decision-making; and (4)\na Reflection Module for refining decisions through iterative learning. By\nintegrating knowledge-driven insights with adaptive learning mechanisms, the\nframework ensures robust decision-making under uncertain conditions. Extensive\nevaluations on real-world traffic datasets, including highways (HighD),\nintersections (InD), and roundabouts (RounD), validate the framework's ability\nto enhance decision-making safety (achieving a 100% safety rate), replicate\nhuman-like driving behaviors (with decision alignment exceeding 85%), and adapt\neffectively to unpredictable scenarios. SafeDrive establishes a novel paradigm\nfor integrating knowledge- and data-driven methods, highlighting significant\npotential to improve safety and adaptability of autonomous driving in high-risk\ntraffic scenarios. Project Page: https://mezzi33.github.io/SafeDrive/",
      "tldr_zh": "该研究提出SafeDrive框架，利用Large Language Models (LLMs)结合知识驱动和数据驱动方法，提升自动驾驶车辆在高风险环境中的风险敏感决策能力。框架包括Risk Module量化多因素风险、Memory Module存储和检索典型场景、LLM-powered Reasoning Module进行上下文感知决策，以及Reflection Module通过迭代学习优化决策。实验在HighD、InD和RounD等真实交通数据集上验证，SafeDrive实现了100%安全率，决策与人类行为一致性超过85%，并有效适应不可预测场景。该框架为整合知识和数据驱动方法提供了新范式，显著提高了自动驾驶的安全性和适应性。",
      "categories": [
        "cs.AI",
        "cs.ET",
        "cs.RO"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.13238v2",
      "published_date": "2024-12-17 16:45:27 UTC",
      "updated_date": "2024-12-19 04:30:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T13:54:45.178210"
    },
    {
      "arxiv_id": "2412.13061v1",
      "title": "VidTok: A Versatile and Open-Source Video Tokenizer",
      "title_zh": "VidTok：一种多功能且开源的视频标记器",
      "authors": [
        "Anni Tang",
        "Tianyu He",
        "Junliang Guo",
        "Xinle Cheng",
        "Li Song",
        "Jiang Bian"
      ],
      "abstract": "Encoding video content into compact latent tokens has become a fundamental\nstep in video generation and understanding, driven by the need to address the\ninherent redundancy in pixel-level representations. Consequently, there is a\ngrowing demand for high-performance, open-source video tokenizers as\nvideo-centric research gains prominence. We introduce VidTok, a versatile video\ntokenizer that delivers state-of-the-art performance in both continuous and\ndiscrete tokenizations. VidTok incorporates several key advancements over\nexisting approaches: 1) model architecture such as convolutional layers and\nup/downsampling modules; 2) to address the training instability and codebook\ncollapse commonly associated with conventional Vector Quantization (VQ), we\nintegrate Finite Scalar Quantization (FSQ) into discrete video tokenization; 3)\nimproved training strategies, including a two-stage training process and the\nuse of reduced frame rates. By integrating these advancements, VidTok achieves\nsubstantial improvements over existing methods, demonstrating superior\nperformance across multiple metrics, including PSNR, SSIM, LPIPS, and FVD,\nunder standardized evaluation settings.",
      "tldr_zh": "本文介绍了 VidTok，一种多功能的开源视频标记器，旨在通过编码视频内容为紧凑的潜在标记来解决像素级表示的冗余问题。VidTok 改进了模型架构（如卷积层和上/下采样模块）、采用 Finite Scalar Quantization (FSQ) 来缓解 Vector Quantization (VQ) 的训练不稳定和代码本崩溃问题，并引入两阶段训练和减少帧率策略。实验结果显示，VidTok 在标准化评估中显著优于现有方法，在 PSNR, SSIM, LPIPS 和 FVD 等指标上表现出色。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Code & Models: https://github.com/microsoft/VidTok",
      "pdf_url": "http://arxiv.org/pdf/2412.13061v1",
      "published_date": "2024-12-17 16:27:11 UTC",
      "updated_date": "2024-12-17 16:27:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T13:54:56.775106"
    },
    {
      "arxiv_id": "2412.13236v1",
      "title": "COSEE: Consistency-Oriented Signal-Based Early Exiting via Calibrated Sample Weighting Mechanism",
      "title_zh": "翻译失败",
      "authors": [
        "Jianing He",
        "Qi Zhang",
        "Hongyun Zhang",
        "Xuanjing Huang",
        "Usman Naseem",
        "Duoqian Miao"
      ],
      "abstract": "Early exiting is an effective paradigm for improving the inference efficiency\nof pre-trained language models (PLMs) by dynamically adjusting the number of\nexecuted layers for each sample. However, in most existing works, easy and hard\nsamples are treated equally by each classifier during training, which neglects\nthe test-time early exiting behavior, leading to inconsistency between training\nand testing. Although some methods have tackled this issue under a fixed\nspeed-up ratio, the challenge of flexibly adjusting the speed-up ratio while\nmaintaining consistency between training and testing is still under-explored.\nTo bridge the gap, we propose a novel Consistency-Oriented Signal-based Early\nExiting (COSEE) framework, which leverages a calibrated sample weighting\nmechanism to enable each classifier to emphasize the samples that are more\nlikely to exit at that classifier under various acceleration scenarios.\nExtensive experiments on the GLUE benchmark demonstrate the effectiveness of\nour COSEE across multiple exiting signals and backbones, yielding a better\ntrade-off between performance and efficiency.",
      "tldr_zh": "该论文提出 COSEE 框架，一种针对预训练语言模型 (PLMs) 的 Consistency-Oriented Signal-based Early Exiting 方法，通过校准样本加权机制 (calibrated sample weighting mechanism) 让每个分类器更关注那些在测试时更可能提前退出的样本，从而解决训练和测试不一致的问题，并支持灵活调整加速比。不同于现有方法，COSEE 强调在各种加速场景下保持一致性，提升了模型的推理效率。实验在 GLUE benchmark 上证明，该框架在多种退出信号和骨干模型上实现了性能和效率的更好权衡。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "AAAI 2025, 11 pages",
      "pdf_url": "http://arxiv.org/pdf/2412.13236v1",
      "published_date": "2024-12-17 16:24:55 UTC",
      "updated_date": "2024-12-17 16:24:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T13:55:08.431987"
    },
    {
      "arxiv_id": "2412.13235v2",
      "title": "Logic-Constrained Shortest Paths for Flight Planning",
      "title_zh": "翻译失败",
      "authors": [
        "Ricardo Euler",
        "Pedro Maristany de las Casas",
        "Ralf Borndörfer"
      ],
      "abstract": "The Logic-Constrained Shortest Path Problem (LCSP) combines a one-to-one\nshortest path problem with satisfiability constraints imposed on the routing\ngraph. This setting arises in flight planning, where air traffic control (ATC)\nauthorities are enforcing a set of traffic flow restrictions (TFRs) on aircraft\nroutes in order to increase safety and throughput. We propose a new branch and\nbound-based algorithm for the LCSP. The resulting algorithm has three main\ndegrees of freedom: the node selection rule, the branching rule and the\nconflict. While node selection and branching rules have been long studied in\nthe MIP and SAT communities, most of them cannot be applied out of the box for\nthe LCSP. We review the existing literature and develop tailored variants of\nthe most prominent rules. The conflict, the set of variables to which the\nbranching rule is applied, is unique to the LCSP. We analyze its theoretical\nimpact on the B&B algorithm. In the second part of the paper, we show how to\nmodel the Flight Planning Problem with TFRs as an LCSP and solve it using the\nbranch and bound algorithm. We demonstrate the algorithm's efficiency on a\ndataset consisting of a global flight graph and a set of around 20000 real TFRs\nobtained from our industry partner Lufthansa Systems GmbH. We make this dataset\npublicly available. Finally, we conduct an empirical in-depth analysis of node\nselection rules, branching rules and conflicts. Carefully choosing an\nappropriate combination yields an improvement of an order of magnitude compared\nto an uninformed choice.",
      "tldr_zh": "本文提出 Logic-Constrained Shortest Path Problem (LCSP)，将传统最短路径问题与逻辑满足性约束相结合，应用于飞行规划中的交通流量限制 (TFRs)，以提升航空安全和吞吐量。作者开发了一种新的基于 branch and bound 的算法，针对 LCSP 定制了节点选择规则、分支规则和冲突设置，并通过理论分析和实证实验证明了其效率。在一个包含全球飞行图和约 20000 个真实 TFR 的公开数据集上，该算法的性能比无信息选择提高了约一个数量级。",
      "categories": [
        "cs.AI",
        "cs.DM"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.13235v2",
      "published_date": "2024-12-17 16:18:06 UTC",
      "updated_date": "2024-12-20 10:38:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T13:57:13.779637"
    },
    {
      "arxiv_id": "2412.13053v1",
      "title": "SMOSE: Sparse Mixture of Shallow Experts for Interpretable Reinforcement Learning in Continuous Control Tasks",
      "title_zh": "SMOSE：稀疏混合浅层专家用于连续控制任务的可解释强化学习",
      "authors": [
        "Mátyás Vincze",
        "Laura Ferrarotti",
        "Leonardo Lucio Custode",
        "Bruno Lepri",
        "Giovanni Iacca"
      ],
      "abstract": "Continuous control tasks often involve high-dimensional, dynamic, and\nnon-linear environments. State-of-the-art performance in these tasks is\nachieved through complex closed-box policies that are effective, but suffer\nfrom an inherent opacity. Interpretable policies, while generally\nunderperforming compared to their closed-box counterparts, advantageously\nfacilitate transparent decision-making within automated systems. Hence, their\nusage is often essential for diagnosing and mitigating errors, supporting\nethical and legal accountability, and fostering trust among stakeholders. In\nthis paper, we propose SMOSE, a novel method to train sparsely activated\ninterpretable controllers, based on a top-1 Mixture-of-Experts architecture.\nSMOSE combines a set of interpretable decisionmakers, trained to be experts in\ndifferent basic skills, and an interpretable router that assigns tasks among\nthe experts. The training is carried out via state-of-the-art Reinforcement\nLearning algorithms, exploiting load-balancing techniques to ensure fair expert\nusage. We then distill decision trees from the weights of the router,\nsignificantly improving the ease of interpretation. We evaluate SMOSE on six\nbenchmark environments from MuJoCo: our method outperforms recent interpretable\nbaselines and narrows the gap with noninterpretable state-of-the-art algorithms",
      "tldr_zh": "本论文提出 SMOSE，一种基于稀疏 Mixture-of-Experts 架构的 interpretable 强化学习方法，旨在解决连续控制任务中策略不透明的问题。该方法结合多个浅层专家（每个专注于不同基本技能）和一个 interpretable 路由器来分配任务，通过 Reinforcement Learning 算法及负载均衡技术进行训练，并从路由器权重中提炼决策树以提升解释性。实验结果显示，SMOSE 在 MuJoCo 的六个基准环境中超过了现有 interpretable 基线，并显著缩小了与非 interpretable 最先进算法的性能差距。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "68",
        "I.2.6; I.2.8"
      ],
      "primary_category": "cs.LG",
      "comment": "To be published in the Proceedings of the 39th AAAI Conference on\n  Artificial Intelligence (AAAI-25)",
      "pdf_url": "http://arxiv.org/pdf/2412.13053v1",
      "published_date": "2024-12-17 16:15:04 UTC",
      "updated_date": "2024-12-17 16:15:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T13:57:25.976638"
    },
    {
      "arxiv_id": "2412.13050v1",
      "title": "Modality-Inconsistent Continual Learning of Multimodal Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Weiguo Pian",
        "Shijian Deng",
        "Shentong Mo",
        "Yunhui Guo",
        "Yapeng Tian"
      ],
      "abstract": "In this paper, we introduce Modality-Inconsistent Continual Learning (MICL),\na new continual learning scenario for Multimodal Large Language Models (MLLMs)\nthat involves tasks with inconsistent modalities (image, audio, or video) and\nvarying task types (captioning or question-answering). Unlike existing\nvision-only or modality-incremental settings, MICL combines modality and task\ntype shifts, both of which drive catastrophic forgetting. To address these\nchallenges, we propose MoInCL, which employs a Pseudo Targets Generation Module\nto mitigate forgetting caused by task type shifts in previously seen\nmodalities. It also incorporates Instruction-based Knowledge Distillation to\npreserve the model's ability to handle previously learned modalities when new\nones are introduced. We benchmark MICL using a total of six tasks and conduct\nexperiments to validate the effectiveness of our proposed MoInCL. The\nexperimental results highlight the superiority of MoInCL, showing significant\nimprovements over representative and state-of-the-art continual learning\nbaselines.",
      "tldr_zh": "本论文引入了 Modality-Inconsistent Continual Learning (MICL)，一种针对 Multimodal Large Language Models (MLLMs) 的新持续学习场景，涉及不同模态（如图像、音频、视频）和任务类型（如标题生成或问答）的变化，这些变化会导致灾难性遗忘。\n为了应对这些挑战，作者提出了 MoInCL 方法，该方法包括 Pseudo Targets Generation Module 用于缓解任务类型转移引起的遗忘，以及 Instruction-based Knowledge Distillation 来保留模型对先前模态的处理能力。\n实验在六个任务上进行了基准测试，结果显示 MoInCL 显著优于现有的持续学习基线，证明了其有效性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.CV",
        "cs.SD",
        "eess.AS"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.13050v1",
      "published_date": "2024-12-17 16:13:56 UTC",
      "updated_date": "2024-12-17 16:13:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T13:57:38.005369"
    },
    {
      "arxiv_id": "2412.13023v1",
      "title": "Relational Neurosymbolic Markov Models",
      "title_zh": "关系神经符号Markov模型",
      "authors": [
        "Lennert De Smet",
        "Gabriele Venturato",
        "Luc De Raedt",
        "Giuseppe Marra"
      ],
      "abstract": "Sequential problems are ubiquitous in AI, such as in reinforcement learning\nor natural language processing. State-of-the-art deep sequential models, like\ntransformers, excel in these settings but fail to guarantee the satisfaction of\nconstraints necessary for trustworthy deployment. In contrast, neurosymbolic AI\n(NeSy) provides a sound formalism to enforce constraints in deep probabilistic\nmodels but scales exponentially on sequential problems. To overcome these\nlimitations, we introduce relational neurosymbolic Markov models (NeSy-MMs), a\nnew class of end-to-end differentiable sequential models that integrate and\nprovably satisfy relational logical constraints. We propose a strategy for\ninference and learning that scales on sequential settings, and that combines\napproximate Bayesian inference, automated reasoning, and gradient estimation.\nOur experiments show that NeSy-MMs can solve problems beyond the current\nstate-of-the-art in neurosymbolic AI and still provide strong guarantees with\nrespect to desired properties. Moreover, we show that our models are more\ninterpretable and that constraints can be adapted at test time to\nout-of-distribution scenarios.",
      "tldr_zh": "本研究针对顺序问题（如强化学习和自然语言处理）中，现有深度模型（如 Transformers）无法保证约束满足的问题，引入了 Relational Neurosymbolic Markov Models (NeSy-MMs)，这是一种端到端可微的顺序模型，能够整合并证明满足关系逻辑约束。研究提出了一种结合近似 Bayesian inference、自动化推理和梯度估计的推理与学习策略，使模型在顺序设置中实现高效扩展。实验结果显示，NeSy-MMs 能解决当前 NeSy 技术无法处理的复杂问题，同时提供更强的可解释性和测试时约束适应性，以应对分布外场景。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted at AAAI 2025",
      "pdf_url": "http://arxiv.org/pdf/2412.13023v1",
      "published_date": "2024-12-17 15:41:51 UTC",
      "updated_date": "2024-12-17 15:41:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T13:57:49.340809"
    },
    {
      "arxiv_id": "2412.15272v1",
      "title": "SimGRAG: Leveraging Similar Subgraphs for Knowledge Graphs Driven Retrieval-Augmented Generation",
      "title_zh": "SimGRAG：利用相似子图进行知识图谱驱动的检索增强生成",
      "authors": [
        "Yuzheng Cai",
        "Zhenyue Guo",
        "Yiwen Pei",
        "Wanrui Bian",
        "Weiguo Zheng"
      ],
      "abstract": "Recent advancements in large language models (LLMs) have shown impressive\nversatility across various tasks. To eliminate its hallucinations,\nretrieval-augmented generation (RAG) has emerged as a powerful approach,\nleveraging external knowledge sources like knowledge graphs (KGs). In this\npaper, we study the task of KG-driven RAG and propose a novel Similar Graph\nEnhanced Retrieval-Augmented Generation (SimGRAG) method. It effectively\naddresses the challenge of aligning query texts and KG structures through a\ntwo-stage process: (1) query-to-pattern, which uses an LLM to transform queries\ninto a desired graph pattern, and (2) pattern-to-subgraph, which quantifies the\nalignment between the pattern and candidate subgraphs using a graph semantic\ndistance (GSD) metric. We also develop an optimized retrieval algorithm that\nefficiently identifies the top-$k$ subgraphs within 1-second latency on a\n10-million-scale KG. Extensive experiments show that SimGRAG outperforms\nstate-of-the-art KG-driven RAG methods in both question answering and fact\nverification, offering superior plug-and-play usability and scalability.",
      "tldr_zh": "该论文提出了一种名为 SimGRAG 的新方法，用于知识图谱 (KGs) 驱动的检索增强生成 (RAG)，旨在解决查询文本与 KG 结构对齐的挑战。SimGRAG 通过两阶段过程实现：首先是 query-to-pattern，利用大型语言模型 (LLMs) 将查询转化为所需的图模式；其次是 pattern-to-subgraph，使用图语义距离 (GSD) 度量来量化模式与候选子图的相似度。论文还开发了一个优化检索算法，能在 10 百万规模的 KG 上以 1 秒内识别 top-k 子图。实验结果显示，SimGRAG 在问答和事实验证任务上优于现有 KG 驱动 RAG 方法，并提供更好的即插即用性和可扩展性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.15272v1",
      "published_date": "2024-12-17 15:40:08 UTC",
      "updated_date": "2024-12-17 15:40:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T13:58:01.371039"
    },
    {
      "arxiv_id": "2412.12997v3",
      "title": "Enabling Low-Resource Language Retrieval: Establishing Baselines for Urdu MS MARCO",
      "title_zh": "翻译失败",
      "authors": [
        "Umer Butt",
        "Stalin Varanasi",
        "Günter Neumann"
      ],
      "abstract": "As the Information Retrieval (IR) field increasingly recognizes the\nimportance of inclusivity, addressing the needs of low-resource languages\nremains a significant challenge. This paper introduces the first large-scale\nUrdu IR dataset, created by translating the MS MARCO dataset through machine\ntranslation. We establish baseline results through zero-shot learning for IR in\nUrdu and subsequently apply the mMARCO multilingual IR methodology to this\nnewly translated dataset. Our findings demonstrate that the fine-tuned model\n(Urdu-mT5-mMARCO) achieves a Mean Reciprocal Rank (MRR@10) of 0.247 and a\nRecall@10 of 0.439, representing significant improvements over zero-shot\nresults and showing the potential for expanding IR access for Urdu speakers. By\nbridging access gaps for speakers of low-resource languages, this work not only\nadvances multilingual IR research but also emphasizes the ethical and societal\nimportance of inclusive IR technologies. This work provides valuable insights\ninto the challenges and solutions for improving language representation and\nlays the groundwork for future research, especially in South Asian languages,\nwhich can benefit from the adaptable methods used in this study.",
      "tldr_zh": "这篇论文介绍了第一个大规模Urdu IR数据集，通过机器翻译从MS MARCO数据集转换而来，以解决低资源语言在Information Retrieval (IR)领域的包容性挑战。研究团队建立了Urdu的零-shot learning基线，并应用mMARCO多语言IR方法微调Urdu-mT5-mMARCO模型。结果显示，该模型的Mean Reciprocal Rank (MRR@10)达到0.247，Recall@10达到0.439，显著优于零-shot结果。该工作不仅扩展了Urdu用户的IR访问，还为多语言IR研究和南亚语言的未来发展提供了宝贵洞见，并强调了包容性技术的伦理重要性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR",
        "68T50",
        "I.2.7"
      ],
      "primary_category": "cs.CL",
      "comment": "7 pages, ECIR 2025, conference camera-ready version",
      "pdf_url": "http://arxiv.org/pdf/2412.12997v3",
      "published_date": "2024-12-17 15:21:28 UTC",
      "updated_date": "2025-04-04 10:07:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T13:58:13.922306"
    },
    {
      "arxiv_id": "2412.12996v1",
      "title": "Neural Control and Certificate Repair via Runtime Monitoring",
      "title_zh": "通过运行时监控的神经控制与证书修复",
      "authors": [
        "Emily Yu",
        "Đorđe Žikelić",
        "Thomas A. Henzinger"
      ],
      "abstract": "Learning-based methods provide a promising approach to solving highly\nnon-linear control tasks that are often challenging for classical control\nmethods. To ensure the satisfaction of a safety property, learning-based\nmethods jointly learn a control policy together with a certificate function for\nthe property. Popular examples include barrier functions for safety and\nLyapunov functions for asymptotic stability. While there has been significant\nprogress on learning-based control with certificate functions in the white-box\nsetting, where the correctness of the certificate function can be formally\nverified, there has been little work on ensuring their reliability in the\nblack-box setting where the system dynamics are unknown. In this work, we\nconsider the problems of certifying and repairing neural network control\npolicies and certificate functions in the black-box setting. We propose a novel\nframework that utilizes runtime monitoring to detect system behaviors that\nviolate the property of interest under some initially trained neural network\npolicy and certificate. These violating behaviors are used to extract new\ntraining data, that is used to re-train the neural network policy and the\ncertificate function and to ultimately repair them. We demonstrate the\neffectiveness of our approach empirically by using it to repair and to boost\nthe safety rate of neural network policies learned by a state-of-the-art method\nfor learning-based control on two autonomous system control tasks.",
      "tldr_zh": "本文提出一种利用 runtime monitoring 的框架，用于在 black-box setting 下认证和修复神经网络控制策略及证书函数（如 barrier functions），以确保安全属性的满足。该框架通过检测系统行为违反预设属性，提取新训练数据，并重新训练神经网络策略和证书函数，从而实现高效修复。实验结果显示，该方法在两个自治系统控制任务上显著提高了神经网络策略的安全率，证明了其在学习-based 控制中的有效性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.12996v1",
      "published_date": "2024-12-17 15:15:30 UTC",
      "updated_date": "2024-12-17 15:15:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T13:58:24.410790"
    },
    {
      "arxiv_id": "2412.12987v1",
      "title": "Stochastic interior-point methods for smooth conic optimization with applications",
      "title_zh": "随机内点方法用于光滑锥优化及其应用",
      "authors": [
        "Chuan He",
        "Zhanwang Deng"
      ],
      "abstract": "Conic optimization plays a crucial role in many machine learning (ML)\nproblems. However, practical algorithms for conic constrained ML problems with\nlarge datasets are often limited to specific use cases, as stochastic\nalgorithms for general conic optimization remain underdeveloped. To fill this\ngap, we introduce a stochastic interior-point method (SIPM) framework for\ngeneral conic optimization, along with four novel SIPM variants leveraging\ndistinct stochastic gradient estimators. Under mild assumptions, we establish\nthe global convergence rates of our proposed SIPMs, which, up to a logarithmic\nfactor, match the best-known rates in stochastic unconstrained optimization.\nFinally, our numerical experiments on robust linear regression, multi-task\nrelationship learning, and clustering data streams demonstrate the\neffectiveness and efficiency of our approach.",
      "tldr_zh": "本研究提出了一种随机内点法 (SIPM) 框架，用于处理平滑锥优化问题，以解决机器学习 (ML) 中大数据集的约束优化挑战。框架包括四个新变体，采用不同的随机梯度估计器，并在温和假设下建立了全局收敛率，该率与随机无约束优化的最佳已知率相当，仅差一个对数因子。通过数值实验，该方法在鲁棒线性回归、多任务关系学习和聚类数据流等应用中展示了显著的有效性和效率。",
      "categories": [
        "math.OC",
        "cs.AI",
        "cs.LG",
        "90C25, 90C30"
      ],
      "primary_category": "math.OC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.12987v1",
      "published_date": "2024-12-17 15:06:44 UTC",
      "updated_date": "2024-12-17 15:06:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T13:58:36.728618"
    },
    {
      "arxiv_id": "2412.12984v2",
      "title": "Cluster-guided Contrastive Class-imbalanced Graph Classification",
      "title_zh": "翻译失败",
      "authors": [
        "Wei Ju",
        "Zhengyang Mao",
        "Siyu Yi",
        "Yifang Qin",
        "Yiyang Gu",
        "Zhiping Xiao",
        "Jianhao Shen",
        "Ziyue Qiao",
        "Ming Zhang"
      ],
      "abstract": "This paper studies the problem of class-imbalanced graph classification,\nwhich aims at effectively classifying the graph categories in scenarios with\nimbalanced class distributions. While graph neural networks (GNNs) have\nachieved remarkable success, their modeling ability on imbalanced\ngraph-structured data remains suboptimal, which typically leads to predictions\nbiased towards the majority classes. On the other hand, existing\nclass-imbalanced learning methods in vision may overlook the rich graph\nsemantic substructures of the majority classes and excessively emphasize\nlearning from the minority classes. To address these challenges, we propose a\nsimple yet powerful approach called C$^3$GNN that integrates the idea of\nclustering into contrastive learning to enhance class-imbalanced graph\nclassification. Technically, C$^3$GNN clusters graphs from each majority class\ninto multiple subclasses, with sizes comparable to the minority class,\nmitigating class imbalance. It also employs the Mixup technique to generate\nsynthetic samples, enriching the semantic diversity of each subclass.\nFurthermore, supervised contrastive learning is used to hierarchically learn\neffective graph representations, enabling the model to thoroughly explore\nsemantic substructures in majority classes while avoiding excessive focus on\nminority classes. Extensive experiments on real-world graph benchmark datasets\nverify the superior performance of our proposed method against competitive\nbaselines.",
      "tldr_zh": "本研究针对类别不平衡图分类问题，提出了一种名为 C³GNN 的简单而有效的框架，以解决图神经网络(GNNs) 在不平衡数据上偏向多数类的局限性。C³GNN 通过将多数类图聚类成多个子类（大小与少数类相当）并结合 Mixup 技术生成合成样本，来缓解类别不平衡并增强子类的语义多样性；同时，它利用监督对比学习进行层次化图表示学习，深入探索多数类的语义子结构而不过度强调少数类。实验结果显示，该方法在真实世界图基准数据集上显著优于竞争基线，验证了其在提升分类性能方面的有效性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.IR",
        "cs.SI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by Proceedings of the Thirty-Ninth AAAI Conference on\n  Artificial Intelligence (AAAI-25)",
      "pdf_url": "http://arxiv.org/pdf/2412.12984v2",
      "published_date": "2024-12-17 15:04:54 UTC",
      "updated_date": "2024-12-30 05:34:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T13:58:48.993743"
    },
    {
      "arxiv_id": "2412.12933v2",
      "title": "Two Layer Walk: A Community-Aware Graph Embedding",
      "title_zh": "Two Layer Walk：一种社区感知的图嵌入",
      "authors": [
        "He Yu",
        "Jing Liu"
      ],
      "abstract": "Community structures are critical for understanding the mesoscopic\norganization of networks, bridging local and global patterns. While methods\nsuch as DeepWalk and node2vec capture local positional information through\nrandom walks, they fail to preserve community structures. Other approaches like\nmodularized nonnegative matrix factorization and evolutionary algorithms\naddress this gap but are computationally expensive and unsuitable for\nlarge-scale networks. To overcome these limitations, we propose Two Layer Walk\n(TLWalk), a novel graph embedding algorithm that incorporates hierarchical\ncommunity structures. TLWalk balances intra- and inter-community relationships\nthrough a community-aware random walk mechanism without requiring additional\nparameters. Theoretical analysis demonstrates that TLWalk effectively mitigates\nlocality bias. Experiments on benchmark datasets show that TLWalk outperforms\nstate-of-the-art methods, achieving up to 3.2% accuracy gains for link\nprediction tasks. By encoding dense local and sparse global structures, TLWalk\nproves robust and scalable across diverse networks, offering an efficient\nsolution for network analysis.",
      "tldr_zh": "该论文提出了一种新型图嵌入算法 Two Layer Walk (TLWalk)，旨在解决现有方法如 DeepWalk 和 node2vec 在捕获社区结构方面的不足，同时避免了模块化非负矩阵分解等方法的计算开销问题。TLWalk 通过社区感知随机游走机制平衡社区内（intra-community）和社区间（inter-community）关系，并不需额外参数，理论上有效缓解了局部偏差。实验在基准数据集上证明，TLWalk 在链接预测任务中比最先进方法提高了多达 3.2% 的准确率，并在多样网络中展现出优秀的鲁棒性和可扩展性。",
      "categories": [
        "cs.SI",
        "cs.AI"
      ],
      "primary_category": "cs.SI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.12933v2",
      "published_date": "2024-12-17 14:11:59 UTC",
      "updated_date": "2024-12-18 13:52:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T13:59:01.926520"
    },
    {
      "arxiv_id": "2412.12932v3",
      "title": "CoMT: A Novel Benchmark for Chain of Multi-modal Thought on Large Vision-Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Zihui Cheng",
        "Qiguang Chen",
        "Jin Zhang",
        "Hao Fei",
        "Xiaocheng Feng",
        "Wanxiang Che",
        "Min Li",
        "Libo Qin"
      ],
      "abstract": "Large Vision-Language Models (LVLMs) have recently demonstrated amazing\nsuccess in multi-modal tasks, including advancements in Multi-modal\nChain-of-Thought (MCoT) reasoning. Despite these successes, current benchmarks\nstill follow a traditional paradigm with multi-modal input and text-modal\noutput, which leads to significant drawbacks such as missing visual operations\nand vague expressions. Motivated by this, we introduce a novel Chain of\nMulti-modal Thought (CoMT) benchmark to address these limitations. Different\nfrom the traditional MCoT benchmark, CoMT requires both multi-modal input and\nmulti-modal reasoning output, aiming to mimic human-like reasoning that\ninherently integrates visual operation. Specifically, CoMT consists of four\ncategories: (1) Visual Creation, (2) Visual Deletion, (3) Visual Update, and\n(4) Visual Selection to comprehensively explore complex visual operations and\nconcise expression in real scenarios. We evaluate various LVLMs and strategies\non CoMT, revealing some key insights into the capabilities and limitations of\nthe current approaches. We hope that CoMT can inspire more research on\nintroducing multi-modal generation into the reasoning process.",
      "tldr_zh": "该论文提出CoMT基准，一种针对Large Vision-Language Models (LVLMs)的创新性评估框架，用于改进Multi-modal Chain-of-Thought (MCoT)推理。CoMT克服了传统基准的局限，如缺少视觉操作和模糊表达，通过要求多模态输入和输出来模拟人类推理，并包括四个类别：Visual Creation、Visual Deletion、Visual Update和Visual Selection，以探索复杂的视觉操作。实验评估了多种LVLMs和策略，揭示了当前方法的优势与不足，并呼吁更多研究将多模态生成融入推理过程。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted at AAAI 2025; Project Page: https://github.com/czhhzc/CoMT",
      "pdf_url": "http://arxiv.org/pdf/2412.12932v3",
      "published_date": "2024-12-17 14:10:16 UTC",
      "updated_date": "2025-03-09 08:47:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T13:59:12.518136"
    },
    {
      "arxiv_id": "2412.12929v1",
      "title": "Spectra of Cardinality Queries over Description Logic Knowledge Bases",
      "title_zh": "翻译失败",
      "authors": [
        "Quentin Manière",
        "Marcin Przybyłko"
      ],
      "abstract": "Recent works have explored the use of counting queries coupled with\nDescription Logic ontologies. The answer to such a query in a model of a\nknowledge base is either an integer or $\\infty$, and its spectrum is the set of\nits answers over all models. While it is unclear how to compute and manipulate\nsuch a set in general, we identify a class of counting queries whose spectra\ncan be effectively represented. Focusing on atomic counting queries, we\npinpoint the possible shapes of a spectrum over $\\mathcal{ALCIF}$ ontologies:\nthey are essentially the subsets of $\\mathbb{N} \\cup \\{ \\infty \\}$ closed under\naddition. For most sublogics of $\\mathcal{ALCIF}$, we show that possible\nspectra enjoy simpler shapes, being $[ m, \\infty ]$ or variations thereof. To\nobtain our results, we refine constructions used for finite model reasoning and\nnotably rely on a cycle-reversion technique for the Horn fragment of\n$\\mathcal{ALCIF}$. We also study the data complexity of computing the proposed\neffective representation and establish the\n$\\mathsf{FP}^{\\mathsf{NP}[\\log]}$-completeness of this task under several\nsettings.",
      "tldr_zh": "这篇论文探讨了在描述逻辑知识库上计数 queries 的谱，定义为查询在所有模型上的答案集合（整数或 ∞）。论文识别出一类原子 counting queries 的谱可以有效表示，在 ALCIF 本体上，这些谱本质上是闭于加法的 $\\mathbb{N} \\cup \\{ \\infty \\}$ 子集，而在 ALCIF 的多数子逻辑上，谱形状更简单，如 $[m, \\infty]$ 或其变体。研究通过改进有限模型推理构造和 ALCIF Horn 片段的 cycle-reversion 技术来获得这些结果。最后，论文证明了计算这些谱有效表示的数据复杂性在多个设置下是 $\\mathsf{FP}^{\\mathsf{NP}[\\log]}$-complete。",
      "categories": [
        "cs.AI",
        "cs.CC",
        "cs.LO"
      ],
      "primary_category": "cs.AI",
      "comment": "26 pages",
      "pdf_url": "http://arxiv.org/pdf/2412.12929v1",
      "published_date": "2024-12-17 14:07:04 UTC",
      "updated_date": "2024-12-17 14:07:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T13:59:26.166942"
    },
    {
      "arxiv_id": "2412.12912v1",
      "title": "Unsupervised Region-Based Image Editing of Denoising Diffusion Models",
      "title_zh": "翻译失败",
      "authors": [
        "Zixiang Li",
        "Yue Song",
        "Renshuai Tao",
        "Xiaohong Jia",
        "Yao Zhao",
        "Wei Wang"
      ],
      "abstract": "Although diffusion models have achieved remarkable success in the field of\nimage generation, their latent space remains under-explored. Current methods\nfor identifying semantics within latent space often rely on external\nsupervision, such as textual information and segmentation masks. In this paper,\nwe propose a method to identify semantic attributes in the latent space of\npre-trained diffusion models without any further training. By projecting the\nJacobian of the targeted semantic region into a low-dimensional subspace which\nis orthogonal to the non-masked regions, our approach facilitates precise\nsemantic discovery and control over local masked areas, eliminating the need\nfor annotations. We conducted extensive experiments across multiple datasets\nand various architectures of diffusion models, achieving state-of-the-art\nperformance. In particular, for some specific face attributes, the performance\nof our proposed method even surpasses that of supervised approaches,\ndemonstrating its superior ability in editing local image properties.",
      "tldr_zh": "该研究提出了一种无监督的基于区域的图像编辑方法，针对预训练的扩散模型（diffusion models），无需额外训练即可在潜在空间中识别语义属性。该方法通过将目标语义区域的雅可比矩阵（Jacobian）投影到与非掩码区域正交的低维子空间，实现对局部掩码区域的精确控制和编辑，从而避免了依赖文本信息或分割掩码等外部监督。实验在多个数据集和扩散模型架构上取得了最先进（state-of-the-art）性能，尤其在某些面部属性编辑上，甚至超过了监督方法，展示了其在局部图像属性编辑方面的优越能力。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.12912v1",
      "published_date": "2024-12-17 13:46:12 UTC",
      "updated_date": "2024-12-17 13:46:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T13:59:37.186960"
    },
    {
      "arxiv_id": "2412.13231v3",
      "title": "C2F-TP: A Coarse-to-Fine Denoising Framework for Uncertainty-Aware Trajectory Prediction",
      "title_zh": "翻译失败",
      "authors": [
        "Zichen Wang",
        "Hao Miao",
        "Senzhang Wang",
        "Renzhi Wang",
        "Jianxin Wang",
        "Jian Zhang"
      ],
      "abstract": "Accurately predicting the trajectory of vehicles is critically important for\nensuring safety and reliability in autonomous driving. Although considerable\nresearch efforts have been made recently, the inherent trajectory uncertainty\ncaused by various factors including the dynamic driving intends and the diverse\ndriving scenarios still poses significant challenges to accurate trajectory\nprediction. To address this issue, we propose C2F-TP, a coarse-to-fine\ndenoising framework for uncertainty-aware vehicle trajectory prediction. C2F-TP\nfeatures an innovative two-stage coarse-to-fine prediction process.\nSpecifically, in the spatial-temporal interaction stage, we propose a\nspatial-temporal interaction module to capture the inter-vehicle interactions\nand learn a multimodal trajectory distribution, from which a certain number of\nnoisy trajectories are sampled. Next, in the trajectory refinement stage, we\ndesign a conditional denoising model to reduce the uncertainty of the sampled\ntrajectories through a step-wise denoising operation. Extensive experiments are\nconducted on two real datasets NGSIM and highD that are widely adopted in\ntrajectory prediction. The result demonstrates the effectiveness of our\nproposal.",
      "tldr_zh": "该论文提出 C2F-TP，一种粗到细的去噪框架，用于处理自动驾驶中车辆轨迹预测的不确定性问题。框架包括两个阶段：首先，通过空间-时间交互模块捕获车辆间交互并学习多模态轨迹分布，以采样噪声轨迹；其次，利用条件去噪模型进行逐步去噪操作，减少轨迹的不确定性。在 NGSIM 和 highD 数据集上的实验结果表明，该框架有效提高了预测准确性。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "Accepted by AAAI 2025",
      "pdf_url": "http://arxiv.org/pdf/2412.13231v3",
      "published_date": "2024-12-17 13:42:49 UTC",
      "updated_date": "2024-12-24 03:46:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T13:59:49.775676"
    },
    {
      "arxiv_id": "2412.12892v3",
      "title": "SAUGE: Taming SAM for Uncertainty-Aligned Multi-Granularity Edge Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Xing Liufu",
        "Chaolei Tan",
        "Xiaotong Lin",
        "Yonggang Qi",
        "Jinxuan Li",
        "Jian-Fang Hu"
      ],
      "abstract": "Edge labels are typically at various granularity levels owing to the varying\npreferences of annotators, thus handling the subjectivity of per-pixel labels\nhas been a focal point for edge detection. Previous methods often employ a\nsimple voting strategy to diminish such label uncertainty or impose a strong\nassumption of labels with a pre-defined distribution, e.g., Gaussian. In this\nwork, we unveil that the segment anything model (SAM) provides strong prior\nknowledge to model the uncertainty in edge labels. Our key insight is that the\nintermediate SAM features inherently correspond to object edges at various\ngranularities, which reflects different edge options due to uncertainty.\nTherefore, we attempt to align uncertainty with granularity by regressing\nintermediate SAM features from different layers to object edges at\nmulti-granularity levels. In doing so, the model can fully and explicitly\nexplore diverse ``uncertainties'' in a data-driven fashion. Specifically, we\ninject a lightweight module (~ 1.5% additional parameters) into the frozen SAM\nto progressively fuse and adapt its intermediate features to estimate edges\nfrom coarse to fine. It is crucial to normalize the granularity level of human\nedge labels to match their innate uncertainty. For this, we simply perform\nlinear blending to the real edge labels at hand to create pseudo labels with\nvarying granularities. Consequently, our uncertainty-aligned edge detector can\nflexibly produce edges at any desired granularity (including an optimal one).\nThanks to SAM, our model uniquely demonstrates strong generalizability for\ncross-dataset edge detection. Extensive experimental results on BSDS500,\nMuticue and NYUDv2 validate our model's superiority.",
      "tldr_zh": "本文提出 SAUGE 框架，利用 Segment Anything Model (SAM) 来处理边缘检测中的标签不确定性和多粒度问题，通过回归 SAM 的中间特征来对齐不确定性与多粒度边缘。方法包括注入一个轻量级模块（额外参数约 1.5%）到冻结的 SAM 中，逐步融合中间特征从粗到细估计边缘，并通过线性混合真实标签创建伪标签以匹配固有不确定性。该框架能灵活生成任意粒度的边缘，包括最优粒度，并在 BSDS500、Multicue 和 NYUDv2 数据集上实验验证了其优越性和跨数据集泛化能力。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted to AAAI 2025",
      "pdf_url": "http://arxiv.org/pdf/2412.12892v3",
      "published_date": "2024-12-17 13:18:41 UTC",
      "updated_date": "2025-04-19 03:14:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T14:00:02.356668"
    },
    {
      "arxiv_id": "2412.12888v2",
      "title": "ArtAug: Enhancing Text-to-Image Generation through Synthesis-Understanding Interaction",
      "title_zh": "ArtAug：通过合成-理解交互增强文本到图像生成",
      "authors": [
        "Zhongjie Duan",
        "Qianyi Zhao",
        "Cen Chen",
        "Daoyuan Chen",
        "Wenmeng Zhou",
        "Yaliang Li",
        "Yingda Chen"
      ],
      "abstract": "The emergence of diffusion models has significantly advanced image synthesis.\nThe recent studies of model interaction and self-corrective reasoning approach\nin large language models offer new insights for enhancing text-to-image models.\nInspired by these studies, we propose a novel method called ArtAug for\nenhancing text-to-image models in this paper. To the best of our knowledge,\nArtAug is the first one that improves image synthesis models via model\ninteractions with understanding models. In the interactions, we leverage human\npreferences implicitly learned by image understanding models to provide\nfine-grained suggestions for image synthesis models. The interactions can\nmodify the image content to make it aesthetically pleasing, such as adjusting\nexposure, changing shooting angles, and adding atmospheric effects. The\nenhancements brought by the interaction are iteratively fused into the\nsynthesis model itself through an additional enhancement module. This enables\nthe synthesis model to directly produce aesthetically pleasing images without\nany extra computational cost. In the experiments, we train the ArtAug\nenhancement module on existing text-to-image models. Various evaluation metrics\nconsistently demonstrate that ArtAug enhances the generative capabilities of\ntext-to-image models without incurring additional computational costs. The\nsource code and models will be released publicly.",
      "tldr_zh": "本文提出ArtAug方法，通过合成模型（synthesis models）和理解模型（understanding models）的交互，提升文本到图像生成（text-to-image generation）的性能。该方法利用图像理解模型隐式学习的人类偏好，提供细粒度建议，如调整曝光、改变拍摄角度和添加大气效果，并通过一个增强模块将这些改进迭代融合到合成模型中，从而实现直接生成美观图像而不增加计算成本。实验结果显示，在现有文本到图像模型上训练ArtAug后，各种评估指标一致证明其提升了生成能力，且源代码和模型将公开发布。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "18 pages, 8 figures",
      "pdf_url": "http://arxiv.org/pdf/2412.12888v2",
      "published_date": "2024-12-17 13:12:31 UTC",
      "updated_date": "2024-12-18 13:01:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T14:00:15.549121"
    },
    {
      "arxiv_id": "2412.12883v1",
      "title": "A Comparative Study of Pruning Methods in Transformer-based Time Series Forecasting",
      "title_zh": "基于 Transformer 的时间序列预测中剪枝方法的比较研究",
      "authors": [
        "Nicholas Kiefer",
        "Arvid Weyrauch",
        "Muhammed Öz",
        "Achim Streit",
        "Markus Götz",
        "Charlotte Debus"
      ],
      "abstract": "The current landscape in time-series forecasting is dominated by\nTransformer-based models. Their high parameter count and corresponding demand\nin computational resources pose a challenge to real-world deployment,\nespecially for commercial and scientific applications with low-power embedded\ndevices. Pruning is an established approach to reduce neural network parameter\ncount and save compute. However, the implications and benefits of pruning\nTransformer-based models for time series forecasting are largely unknown. To\nclose this gap, we provide a comparative benchmark study by evaluating\nunstructured and structured pruning on various state-of-the-art multivariate\ntime series models. We study the effects of these pruning strategies on model\npredictive performance and computational aspects like model size, operations,\nand inference time. Our results show that certain models can be pruned even up\nto high sparsity levels, outperforming their dense counterpart. However,\nfine-tuning pruned models is necessary. Furthermore, we demonstrate that even\nwith corresponding hardware and software support, structured pruning is unable\nto provide significant time savings.",
      "tldr_zh": "这篇论文比较了在Transformer-based时间序列预测模型中应用不同剪枝方法的效果，旨在解决这些模型参数过多导致的计算资源需求问题。研究者评估了unstructured pruning和structured pruning在多种最先进的多变量时间序列模型上的表现，重点考察了模型预测性能、模型大小、操作量和推理时间。结果显示，某些模型即使在高稀疏度下也能优于原始密集模型，但需要进行fine-tuning。然而，即使有硬件和软件支持，structured pruning无法显著降低推理时间，为实际部署提供重要启示。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "16 pages, 5 figures, submitted to ACM Transactions on Intelligent\n  Systems and Technology",
      "pdf_url": "http://arxiv.org/pdf/2412.12883v1",
      "published_date": "2024-12-17 13:07:31 UTC",
      "updated_date": "2024-12-17 13:07:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T14:00:24.951960"
    },
    {
      "arxiv_id": "2412.12881v1",
      "title": "RAG-Star: Enhancing Deliberative Reasoning with Retrieval Augmented Verification and Refinement",
      "title_zh": "翻译失败",
      "authors": [
        "Jinhao Jiang",
        "Jiayi Chen",
        "Junyi Li",
        "Ruiyang Ren",
        "Shijie Wang",
        "Wayne Xin Zhao",
        "Yang Song",
        "Tao Zhang"
      ],
      "abstract": "Existing large language models (LLMs) show exceptional problem-solving\ncapabilities but might struggle with complex reasoning tasks. Despite the\nsuccesses of chain-of-thought and tree-based search methods, they mainly depend\non the internal knowledge of LLMs to search over intermediate reasoning steps,\nlimited to dealing with simple tasks involving fewer reasoning steps. In this\npaper, we propose \\textbf{RAG-Star}, a novel RAG approach that integrates the\nretrieved information to guide the tree-based deliberative reasoning process\nthat relies on the inherent knowledge of LLMs. By leveraging Monte Carlo Tree\nSearch, RAG-Star iteratively plans intermediate sub-queries and answers for\nreasoning based on the LLM itself. To consolidate internal and external\nknowledge, we propose an retrieval-augmented verification that utilizes query-\nand answer-aware reward modeling to provide feedback for the inherent reasoning\nof LLMs. Our experiments involving Llama-3.1-8B-Instruct and GPT-4o demonstrate\nthat RAG-Star significantly outperforms previous RAG and reasoning methods.",
      "tldr_zh": "该研究指出，现有的LLMs在复杂推理任务中存在局限，尽管chain-of-thought和tree-based search方法依赖LLMs内部知识，但仅适用于简单任务。论文提出RAG-Star，一种新型RAG方法，通过整合检索信息与Monte Carlo Tree Search，迭代规划中间子查询和答案，并引入retrieval-augmented verification，利用query- and answer-aware reward modeling来整合内部和外部知识，提供反馈。实验结果显示，在Llama-3.1-8B-Instruct和GPT-4o模型上，RAG-Star显著优于现有RAG和推理方法，提升了推理性能。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "LLM;RAG;MCTS",
      "pdf_url": "http://arxiv.org/pdf/2412.12881v1",
      "published_date": "2024-12-17 13:05:36 UTC",
      "updated_date": "2024-12-17 13:05:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T14:00:37.551244"
    },
    {
      "arxiv_id": "2412.14209v1",
      "title": "Integrating Evidence into the Design of XAI and AI-based Decision Support Systems: A Means-End Framework for End-users in Construction",
      "title_zh": "翻译失败",
      "authors": [
        "Peter . E. D. Love",
        "Jane Matthews",
        "Weili Fang",
        "Hadi Mahamivanan"
      ],
      "abstract": "A narrative review is used to develop a theoretical evidence-based means-end\nframework to build an epistemic foundation to uphold explainable artificial\nintelligence instruments so that the reliability of outcomes generated from\ndecision support systems can be assured and better explained to end-users. The\nimplications of adopting an evidence-based approach to designing decision\nsupport systems in construction are discussed with emphasis placed on\nevaluating the strength, value, and utility of evidence needed to develop\nmeaningful human explanations for end-users. While the developed means-end\nframework is focused on end-users, stakeholders can also utilize it to create\nmeaningful human explanations. However, they will vary due to their different\nepistemic goals. Including evidence in the design and development of\nexplainable artificial intelligence and decision support systems will improve\ndecision-making effectiveness, enabling end-users' epistemic goals to be\nachieved. The proposed means-end framework is developed from a broad spectrum\nof literature. Thus, it is suggested that it can be used in construction and\nother engineering domains where there is a need to integrate evidence into the\ndesign of explainable artificial intelligence and decision support systems.",
      "tldr_zh": "这篇论文通过叙述性评论开发了一个基于理论证据的手段-目的框架（means-end framework），旨在为可解释人工智能（XAI）和AI-based决策支持系统提供知识基础，确保输出可靠并向建筑领域的最终用户提供清晰解释。该框架强调评估证据的强度、价值和效用，以创建有意义的解释，从而提升决策支持系统的设计质量。虽然框架针对最终用户，但利益相关者也可根据其不同认知目标进行应用。最终，该方法能改善决策有效性，并扩展适用于建筑和其他工程领域。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "60 pages, 4 figures and 1 table",
      "pdf_url": "http://arxiv.org/pdf/2412.14209v1",
      "published_date": "2024-12-17 13:02:05 UTC",
      "updated_date": "2024-12-17 13:02:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T14:00:49.449920"
    },
    {
      "arxiv_id": "2412.12863v1",
      "title": "DISC: Plug-and-Play Decoding Intervention with Similarity of Characters for Chinese Spelling Check",
      "title_zh": "翻译失败",
      "authors": [
        "Ziheng Qiao",
        "Houquan Zhou",
        "Yumeng Liu",
        "Zhenghua Li",
        "Min Zhang",
        "Bo Zhang",
        "Chen Li",
        "Ji Zhang",
        "Fei Huang"
      ],
      "abstract": "One key characteristic of the Chinese spelling check (CSC) task is that\nincorrect characters are usually similar to the correct ones in either\nphonetics or glyph. To accommodate this, previous works usually leverage\nconfusion sets, which suffer from two problems, i.e., difficulty in determining\nwhich character pairs to include and lack of probabilities to distinguish items\nin the set. In this paper, we propose a light-weight plug-and-play DISC (i.e.,\ndecoding intervention with similarity of characters) module for CSC models.DISC\nmeasures phonetic and glyph similarities between characters and incorporates\nthis similarity information only during the inference phase. This method can be\neasily integrated into various existing CSC models, such as ReaLiSe, SCOPE, and\nReLM, without additional training costs. Experiments on three CSC benchmarks\ndemonstrate that our proposed method significantly improves model performance,\napproaching and even surpassing the current state-of-the-art models.",
      "tldr_zh": "本文针对中文拼写检查（CSC）任务中错误字符的语音或字形相似性问题，提出了一种轻量级的即插即用模块 DISC（Decoding Intervention with Similarity of Characters）。DISC 只在推理阶段测量字符的语音和字形相似性，并将其整合到现有模型如 ReaLiSe、SCOPE 和 ReLM 中，无需额外训练，从而避免了传统混淆集的局限性，如难以确定字符对和缺乏概率区分。实验结果显示，该方法在三个 CSC 基准上显著提升了模型性能，甚至超过了当前最先进模型。DISC 的设计为 CSC 任务提供了高效、可扩展的优化方案。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.12863v1",
      "published_date": "2024-12-17 12:44:06 UTC",
      "updated_date": "2024-12-17 12:44:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T14:01:02.146747"
    },
    {
      "arxiv_id": "2412.12859v1",
      "title": "Bayesian Persuasion with Externalities: Exploiting Agent Types",
      "title_zh": "翻译失败",
      "authors": [
        "Jonathan Shaki",
        "Jiarui Gan",
        "Sarit Kraus"
      ],
      "abstract": "We study a Bayesian persuasion problem with externalities. In this model, a\nprincipal sends signals to inform multiple agents about the state of the world.\nSimultaneously, due to the existence of externalities in the agents' utilities,\nthe principal also acts as a correlation device to correlate the agents'\nactions. We consider the setting where the agents are categorized into a small\nnumber of types. Agents of the same type share identical utility functions and\nare treated equitably in the utility functions of both other agents and the\nprincipal. We study the problem of computing optimal signaling strategies for\nthe principal, under three different types of signaling channels: public,\nprivate, and semi-private. Our results include revelation-principle-style\ncharacterizations of optimal signaling strategies, linear programming\nformulations, and analysis of in/tractability of the optimization problems. It\nis demonstrated that when the maximum number of deviating agents is bounded by\na constant, our LP-based formulations compute optimal signaling strategies in\npolynomial time. Otherwise, the problems are NP-hard.",
      "tldr_zh": "这篇论文研究了带有外部性的贝叶斯说服（Bayesian persuasion）问题，探讨了主体如何通过信号告知多个代理人（agents）世界状态，同时利用外部性将代理人的行动相关联。代理人被分类为几种类型，同类型代理人共享相同的效用函数，论文针对公共、私有和半私有信道设计了最优信号策略，包括揭示原则式表征和线性规划（linear programming）公式。结果显示，当最大偏离代理人数量被常量界定时，优化问题可在多项式时间内求解；否则，为 NP-hard。",
      "categories": [
        "cs.AI",
        "cs.GT"
      ],
      "primary_category": "cs.AI",
      "comment": "to be published in AAAI 2025",
      "pdf_url": "http://arxiv.org/pdf/2412.12859v1",
      "published_date": "2024-12-17 12:41:17 UTC",
      "updated_date": "2024-12-17 12:41:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T14:03:06.944466"
    },
    {
      "arxiv_id": "2412.12858v1",
      "title": "Efficient Speech Command Recognition Leveraging Spiking Neural Network and Curriculum Learning-based Knowledge Distillation",
      "title_zh": "翻译失败",
      "authors": [
        "Jiaqi Wang",
        "Liutao Yu",
        "Liwei Huang",
        "Chenlin Zhou",
        "Han Zhang",
        "Zhenxi Song",
        "Min Zhang",
        "Zhengyu Ma",
        "Zhiguo Zhang"
      ],
      "abstract": "The intrinsic dynamics and event-driven nature of spiking neural networks\n(SNNs) make them excel in processing temporal information by naturally\nutilizing embedded time sequences as time steps. Recent studies adopting this\napproach have demonstrated SNNs' effectiveness in speech command recognition,\nachieving high performance by employing large time steps for long time\nsequences. However, the large time steps lead to increased deployment burdens\nfor edge computing applications. Thus, it is important to balance high\nperformance and low energy consumption when detecting temporal patterns in edge\ndevices. Our solution comprises two key components. 1). We propose a\nhigh-performance fully spike-driven framework termed SpikeSCR, characterized by\na global-local hybrid structure for efficient representation learning, which\nexhibits long-term learning capabilities with extended time steps. 2). To\nfurther fully embrace low energy consumption, we propose an effective knowledge\ndistillation method based on curriculum learning (KDCL), where valuable\nrepresentations learned from the easy curriculum are progressively transferred\nto the hard curriculum with minor loss, striking a trade-off between power\nefficiency and high performance. We evaluate our method on three benchmark\ndatasets: the Spiking Heidelberg Dataset (SHD), the Spiking Speech Commands\n(SSC), and the Google Speech Commands (GSC) V2. Our experimental results\ndemonstrate that SpikeSCR outperforms current state-of-the-art (SOTA) methods\nacross these three datasets with the same time steps. Furthermore, by executing\nKDCL, we reduce the number of time steps by 60% and decrease energy consumption\nby 54.8% while maintaining comparable performance to recent SOTA results.\nTherefore, this work offers valuable insights for tackling temporal processing\nchallenges with long time sequences in edge neuromorphic computing systems.",
      "tldr_zh": "该研究针对语音命令识别中的时序处理挑战，提出了一种高效方法，利用Spiking Neural Networks (SNNs)来平衡高性能和低能耗。具体地，作者开发了SpikeSCR框架，该框架采用全局-局部混合结构，实现高效的表示学习，并设计了基于Curriculum Learning的知识蒸馏方法(KDCL)，通过逐步转移从简单到复杂课程的知识，减少时间步长并降低能耗。在SHD、SSC和GSC V2数据集上实验表明，SpikeSCR超越了现有SOTA方法，且通过KDCL将时间步长减少60%、能耗降低54.8%，同时保持相近性能，为边缘神经形态计算系统的时序处理提供宝贵见解。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.LG",
      "comment": "Under Review",
      "pdf_url": "http://arxiv.org/pdf/2412.12858v1",
      "published_date": "2024-12-17 12:38:45 UTC",
      "updated_date": "2024-12-17 12:38:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T14:03:18.594225"
    },
    {
      "arxiv_id": "2412.12850v1",
      "title": "Boosting Fine-Grained Visual Anomaly Detection with Coarse-Knowledge-Aware Adversarial Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Qingqing Fang",
        "Qinliang Su",
        "Wenxi Lv",
        "Wenchao Xu",
        "Jianxing Yu"
      ],
      "abstract": "Many unsupervised visual anomaly detection methods train an auto-encoder to\nreconstruct normal samples and then leverage the reconstruction error map to\ndetect and localize the anomalies. However, due to the powerful modeling and\ngeneralization ability of neural networks, some anomalies can also be well\nreconstructed, resulting in unsatisfactory detection and localization accuracy.\nIn this paper, a small coarsely-labeled anomaly dataset is first collected.\nThen, a coarse-knowledge-aware adversarial learning method is developed to\nalign the distribution of reconstructed features with that of normal features.\nThe alignment can effectively suppress the auto-encoder's reconstruction\nability on anomalies and thus improve the detection accuracy. Considering that\nanomalies often only occupy very small areas in anomalous images, a patch-level\nadversarial learning strategy is further developed. Although no patch-level\nanomalous information is available, we rigorously prove that by simply viewing\nany patch features from anomalous images as anomalies, the proposed\nknowledge-aware method can also align the distribution of reconstructed patch\nfeatures with the normal ones. Experimental results on four medical datasets\nand two industrial datasets demonstrate the effectiveness of our method in\nimproving the detection and localization performance.",
      "tldr_zh": "本文提出了一种 coarse-knowledge-aware adversarial learning 方法，以提升 fine-grained visual anomaly detection 的性能。针对传统 auto-encoder 在重建异常样本时可能导致准确性不足的问题，该方法利用小型粗略标记的异常数据集，对齐重建特征与正常特征的分布，从而抑制对异常的重建能力。此外，通过 patch-level adversarial learning 策略，即使没有特定异常信息，也能有效处理图像中微小异常区域。实验结果在四个医疗数据集和两个工业数据集上表明，该方法显著提高了异常检测和定位的准确性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "The paper is accepted by AAAI 2025",
      "pdf_url": "http://arxiv.org/pdf/2412.12850v1",
      "published_date": "2024-12-17 12:24:08 UTC",
      "updated_date": "2024-12-17 12:24:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T14:03:30.892934"
    },
    {
      "arxiv_id": "2412.12848v2",
      "title": "ClarityEthic: Explainable Moral Judgment Utilizing Contrastive Ethical Insights from Large Language Models",
      "title_zh": "ClarityEthic：利用大语言模型的对比性伦理洞见的可解释道德判断",
      "authors": [
        "Yuxi Sun",
        "Wei Gao",
        "Jing Ma",
        "Hongzhan Lin",
        "Ziyang Luo",
        "Wenxuan Zhang"
      ],
      "abstract": "With the rise and widespread use of Large Language Models (LLMs), ensuring\ntheir safety is crucial to prevent harm to humans and promote ethical\nbehaviors. However, directly assessing value valence (i.e., support or oppose)\nby leveraging large-scale data training is untrustworthy and inexplainable. We\nassume that emulating humans to rely on social norms to make moral decisions\ncan help LLMs understand and predict moral judgment. However, capturing human\nvalues remains a challenge, as multiple related norms might conflict in\nspecific contexts. Consider norms that are upheld by the majority and promote\nthe well-being of society are more likely to be accepted and widely adopted\n(e.g., \"don't cheat,\"). Therefore, it is essential for LLM to identify the\nappropriate norms for a given scenario before making moral decisions. To this\nend, we introduce a novel moral judgment approach called \\textit{ClarityEthic}\nthat leverages LLMs' reasoning ability and contrastive learning to uncover\nrelevant social norms for human actions from different perspectives and select\nthe most reliable one to enhance judgment accuracy. Extensive experiments\ndemonstrate that our method outperforms state-of-the-art approaches in moral\njudgment tasks. Moreover, human evaluations confirm that the generated social\nnorms provide plausible explanations that support the judgments. This suggests\nthat modeling human moral judgment with the emulating humans moral strategy is\npromising for improving the ethical behaviors of LLMs.",
      "tldr_zh": "这篇论文提出了 ClarityEthic，一种新型方法，利用 Large Language Models (LLMs) 的推理能力和 contrastive learning，从不同视角揭示相关社会规范，并选择最可靠的规范来模拟人类道德决策过程。ClarityEthic 旨在解决直接通过大规模数据训练评估道德判断的不可靠性和不可解释性问题，通过识别适当的社会规范（如“不要欺骗”）来提升判断准确性。实验结果显示，该方法在道德判断任务中优于现有技术，且人类评估确认生成的规范解释合理且支持判断。该研究表明，模仿人类依赖社会规范的策略有望改善 LLMs 的道德行为。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.SI"
      ],
      "primary_category": "cs.CY",
      "comment": "We have noticed that this version of our experiment and method\n  description isn't quite complete or accurate. To make sure we present our\n  best work, we think it would be a good idea to withdraw the manuscript for\n  now and take some time to revise and reformat it",
      "pdf_url": "http://arxiv.org/pdf/2412.12848v2",
      "published_date": "2024-12-17 12:22:44 UTC",
      "updated_date": "2025-04-09 08:38:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T14:03:43.298816"
    },
    {
      "arxiv_id": "2412.12843v2",
      "title": "SLTNet: Efficient Event-based Semantic Segmentation with Spike-driven Lightweight Transformer-based Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Xiaxin Zhu",
        "Fangming Guo",
        "Xianlei Long",
        "Qingyi Gu",
        "Chao Chen",
        "Fuqiang Gu"
      ],
      "abstract": "Event-based semantic segmentation has great potential in autonomous driving\nand robotics due to the advantages of event cameras, such as high dynamic\nrange, low latency, and low power cost. Unfortunately, current artificial\nneural network (ANN)-based segmentation methods suffer from high computational\ndemands, the requirements for image frames, and massive energy consumption,\nlimiting their efficiency and application on resource-constrained edge/mobile\nplatforms. To address these problems, we introduce SLTNet, a spike-driven\nlightweight transformer-based network designed for event-based semantic\nsegmentation. Specifically, SLTNet is built on efficient spike-driven\nconvolution blocks (SCBs) to extract rich semantic features while reducing the\nmodel's parameters. Then, to enhance the long-range contextural feature\ninteraction, we propose novel spike-driven transformer blocks (STBs) with\nbinary mask operations. Based on these basic blocks, SLTNet employs a\nhigh-efficiency single-branch architecture while maintaining the low energy\nconsumption of the Spiking Neural Network (SNN). Finally, extensive experiments\non DDD17 and DSEC-Semantic datasets demonstrate that SLTNet outperforms\nstate-of-the-art (SOTA) SNN-based methods by at most 9.06% and 9.39% mIoU,\nrespectively, with extremely 4.58x lower energy consumption and 114 FPS\ninference speed. Our code is open-sourced and available at\nhttps://github.com/longxianlei/SLTNet-v1.0.",
      "tldr_zh": "本研究针对事件-based 语义分割在自动驾驶和机器人中的应用，提出 SLTNet，一种基于 Spike-driven 的轻量级 Transformer 网络，以解决现有 ANN-based 方法的计算密集、能量消耗高和依赖图像帧等问题。SLTNet 采用高效的 Spike-driven 卷积块 (SCBs) 提取语义特征，并引入 Spike-driven Transformer 块 (STBs) 以增强长距离上下文特征交互，同时维持 Spiking Neural Network (SNN) 的低能量架构。实验结果显示，在 DDD17 和 DSEC-Semantic 数据集上，SLTNet 分别比最先进 SNN 方法提高最多 9.06% 和 9.39% mIoU，同时实现 4.58 倍更低的能量消耗和 114 FPS 的推理速度。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Submitted to 2025 IEEE/RSJ International Conference on Intelligent\n  Robots and Systems (IROS 2025)",
      "pdf_url": "http://arxiv.org/pdf/2412.12843v2",
      "published_date": "2024-12-17 12:11:04 UTC",
      "updated_date": "2025-03-05 09:03:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T14:03:55.308915"
    },
    {
      "arxiv_id": "2412.12839v1",
      "title": "From An LLM Swarm To A PDDL-Empowered HIVE: Planning Self-Executed Instructions In A Multi-Modal Jungle",
      "title_zh": "翻译失败",
      "authors": [
        "Kaustubh Vyas",
        "Damien Graux",
        "Yijun Yang",
        "Sébastien Montella",
        "Chenxin Diao",
        "Wendi Zhou",
        "Pavlos Vougiouklis",
        "Ruofei Lai",
        "Yang Ren",
        "Keshuang Li",
        "Jeff Z. Pan"
      ],
      "abstract": "In response to the call for agent-based solutions that leverage the\never-increasing capabilities of the deep models' ecosystem, we introduce Hive\n-- a comprehensive solution for selecting appropriate models and subsequently\nplanning a set of atomic actions to satisfy the end-users' instructions. Hive\noperates over sets of models and, upon receiving natural language instructions\n(i.e. user queries), schedules and executes explainable plans of atomic\nactions. These actions can involve one or more of the available models to\nachieve the overall task, while respecting end-users specific constraints.\nNotably, Hive handles tasks that involve multi-modal inputs and outputs,\nenabling it to handle complex, real-world queries. Our system is capable of\nplanning complex chains of actions while guaranteeing explainability, using an\nLLM-based formal logic backbone empowered by PDDL operations. We introduce the\nMuSE benchmark in order to offer a comprehensive evaluation of the multi-modal\ncapabilities of agent systems. Our findings show that our framework redefines\nthe state-of-the-art for task selection, outperforming other competing systems\nthat plan operations across multiple models while offering transparency\nguarantees while fully adhering to user constraints.",
      "tldr_zh": "本研究引入了Hive系统，这是一种全面的代理解决方案，用于从多个模型中选择合适的模型，并规划一组原子动作来执行用户指令，确保遵守特定约束。Hive系统接收自然语言指令后，通过LLM-based formal logic backbone增强PDDL操作来调度和执行可解释的动作链，支持多模态输入和输出的复杂任务。研究还提出了MuSE benchmark，用于评估多模态代理系统的性能，结果显示Hive在任务选择上超越了现有最先进系统，提供透明性和用户约束遵守。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Under review",
      "pdf_url": "http://arxiv.org/pdf/2412.12839v1",
      "published_date": "2024-12-17 12:05:21 UTC",
      "updated_date": "2024-12-17 12:05:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T14:04:05.937661"
    },
    {
      "arxiv_id": "2412.12836v1",
      "title": "A Survey on Recommendation Unlearning: Fundamentals, Taxonomy, Evaluation, and Open Questions",
      "title_zh": "翻译失败",
      "authors": [
        "Yuyuan Li",
        "Xiaohua Feng",
        "Chaochao Chen",
        "Qiang Yang"
      ],
      "abstract": "Recommender systems have become increasingly influential in shaping user\nbehavior and decision-making, highlighting their growing impact in various\ndomains. Meanwhile, the widespread adoption of machine learning models in\nrecommender systems has raised significant concerns regarding user privacy and\nsecurity. As compliance with privacy regulations becomes more critical, there\nis a pressing need to address the issue of recommendation unlearning, i.e.,\neliminating the memory of specific training data from the learned\nrecommendation models. Despite its importance, traditional machine unlearning\nmethods are ill-suited for recommendation unlearning due to the unique\nchallenges posed by collaborative interactions and model parameters. This\nsurvey offers a comprehensive review of the latest advancements in\nrecommendation unlearning, exploring the design principles, challenges, and\nmethodologies associated with this emerging field. We provide a unified\ntaxonomy that categorizes different recommendation unlearning approaches,\nfollowed by a summary of widely used benchmarks and metrics for evaluation. By\nreviewing the current state of research, this survey aims to guide the\ndevelopment of more efficient, scalable, and robust recommendation unlearning\ntechniques. Furthermore, we identify open research questions in this field,\nwhich could pave the way for future innovations not only in recommendation\nunlearning but also in a broader range of unlearning tasks across different\nmachine learning applications.",
      "tldr_zh": "这篇调查论文探讨了推荐系统中的“recommendation unlearning”问题，旨在解决机器学习模型在隐私和安全方面的挑战，例如从模型中消除特定训练数据的记忆。论文提供了统一的分类法（taxonomy），系统归纳了不同unlearning方法的原理、挑战和评估指标，包括广泛使用的基准和指标。最终，该研究总结了当前进展，指导未来开发更高效、可扩展的unlearning技术，并指出了该领域的开放研究问题，以推动更广泛的机器学习应用创新。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.12836v1",
      "published_date": "2024-12-17 11:58:55 UTC",
      "updated_date": "2024-12-17 11:58:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T14:04:17.911629"
    },
    {
      "arxiv_id": "2412.12832v1",
      "title": "DSGram: Dynamic Weighting Sub-Metrics for Grammatical Error Correction in the Era of Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Jinxiang Xie",
        "Yilin Li",
        "Xunjian Yin",
        "Xiaojun Wan"
      ],
      "abstract": "Evaluating the performance of Grammatical Error Correction (GEC) models has\nbecome increasingly challenging, as large language model (LLM)-based GEC\nsystems often produce corrections that diverge from provided gold references.\nThis discrepancy undermines the reliability of traditional reference-based\nevaluation metrics. In this study, we propose a novel evaluation framework for\nGEC models, DSGram, integrating Semantic Coherence, Edit Level, and Fluency,\nand utilizing a dynamic weighting mechanism. Our framework employs the Analytic\nHierarchy Process (AHP) in conjunction with large language models to ascertain\nthe relative importance of various evaluation criteria. Additionally, we\ndevelop a dataset incorporating human annotations and LLM-simulated sentences\nto validate our algorithms and fine-tune more cost-effective models.\nExperimental results indicate that our proposed approach enhances the\neffectiveness of GEC model evaluations.",
      "tldr_zh": "本文提出DSGram框架，用于评估Grammatical Error Correction (GEC)模型的性能，以应对Large Language Models (LLM)时代修正结果与金标准参考不一致的问题。DSGram整合Semantic Coherence、Edit Level和Fluency三个子指标，并采用动态加权机制，通过Analytic Hierarchy Process (AHP)结合LLM确定各评估标准的相对重要性。研究团队开发了一个数据集，包括人类注释和LLM模拟句子，用于验证算法并微调更经济的模型。实验结果显示，该框架显著提高了GEC模型评估的有效性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Extended version of a paper to appear in AAAI-25",
      "pdf_url": "http://arxiv.org/pdf/2412.12832v1",
      "published_date": "2024-12-17 11:54:16 UTC",
      "updated_date": "2024-12-17 11:54:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T14:04:31.179517"
    },
    {
      "arxiv_id": "2412.13229v2",
      "title": "Training Verification-Friendly Neural Networks via Neuron Behavior Consistency",
      "title_zh": "翻译失败",
      "authors": [
        "Zongxin Liu",
        "Zhe Zhao",
        "Fu Song",
        "Jun Sun",
        "Pengfei Yang",
        "Xiaowei Huang",
        "Lijun Zhang"
      ],
      "abstract": "Formal verification provides critical security assurances for neural\nnetworks, yet its practical application suffers from the long verification\ntime. This work introduces a novel method for training verification-friendly\nneural networks, which are robust, easy to verify, and relatively accurate. Our\nmethod integrates neuron behavior consistency into the training process, making\nneuron activation states remain consistent across different inputs within a\nlocal neighborhood. This reduces the number of unstable neurons and tightens\nthe bounds of neurons thereby enhancing the network's verifiability. We\nevaluated our method using the MNIST, Fashion-MNIST, and CIFAR-10 datasets with\nvarious network architectures. The experimental results demonstrate that\nnetworks trained using our method are verification-friendly across different\nradii and architectures, whereas other tools fail to maintain verifiability as\nthe radius increases. Additionally, we show that our method can be combined\nwith existing approaches to further improve the verifiability of networks.",
      "tldr_zh": "这项研究提出了一种通过神经元行为一致性训练验证友好型 neural networks 的新方法，旨在提升 formal verification 的效率，同时保持网络的鲁棒性和准确性。方法的核心是将神经元行为一致性整合到训练过程中，确保神经元激活状态在局部邻域内对不同输入保持一致，从而减少不稳定神经元并收紧神经元边界。实验结果显示，在 MNIST、Fashion-MNIST 和 CIFAR-10 数据集上，该方法使网络在不同半径和架构下更易验证，而其他工具在半径增加时表现不佳；此外，该方法还可与其他方法结合，进一步提高网络的可验证性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accpeted by AAAI2025",
      "pdf_url": "http://arxiv.org/pdf/2412.13229v2",
      "published_date": "2024-12-17 11:40:49 UTC",
      "updated_date": "2024-12-29 13:48:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T14:04:43.490118"
    },
    {
      "arxiv_id": "2412.17838v1",
      "title": "Coordinated Power Smoothing Control for Wind Storage Integrated System with Physics-informed Deep Reinforcement Learning",
      "title_zh": "风储一体化系统的协调功率平滑控制",
      "authors": [
        "Shuyi Wang",
        "Huan Zhao",
        "Yuji Cao",
        "Zibin Pan",
        "Guolong Liu",
        "Gaoqi Liang",
        "Junhua Zhao"
      ],
      "abstract": "The Wind Storage Integrated System with Power Smoothing Control (PSC) has\nemerged as a promising solution to ensure both efficient and reliable wind\nenergy generation. However, existing PSC strategies overlook the intricate\ninterplay and distinct control frequencies between batteries and wind turbines,\nand lack consideration of wake effect and battery degradation cost. In this\npaper, a novel coordinated control framework with hierarchical levels is\ndevised to address these challenges effectively, which integrates the wake\nmodel and battery degradation model. In addition, after reformulating the\nproblem as a Markov decision process, the multi-agent reinforcement learning\nmethod is introduced to overcome the bi-level characteristic of the problem.\nMoreover, a Physics-informed Neural Network-assisted Multi-agent Deep\nDeterministic Policy Gradient (PAMA-DDPG) algorithm is proposed to incorporate\nthe power fluctuation differential equation and expedite the learning process.\nThe effectiveness of the proposed methodology is evaluated through simulations\nconducted in four distinct scenarios using WindFarmSimulator (WFSim). The\nresults demonstrate that the proposed algorithm facilitates approximately an\n11% increase in total profit and a 19% decrease in power fluctuation compared\nto the traditional methods, thereby addressing the dual objectives of economic\nefficiency and grid-connected energy reliability.",
      "tldr_zh": "本研究针对风储一体化系统中的功率平滑控制（PSC）问题，提出了一种新型协调控制框架，该框架采用分层结构，整合了wake effect模型和battery degradation cost模型，以解决现有策略忽略的电池与风力涡轮机互动及控制频率差异。框架将问题重构为Markov decision process，并引入multi-agent reinforcement learning方法来处理双层特性，同时开发了Physics-informed Neural Network-assisted Multi-agent Deep Deterministic Policy Gradient (PAMA-DDPG)算法，结合功率波动微分方程加速学习过程。模拟结果显示，在WindFarmSimulator (WFSim)的四个场景中，该方法使总利润提高约11%，功率波动减少约19%，实现了经济效率与电网可靠性的双重优化。",
      "categories": [
        "eess.SY",
        "cs.AI",
        "cs.SY"
      ],
      "primary_category": "eess.SY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.17838v1",
      "published_date": "2024-12-17 11:37:46 UTC",
      "updated_date": "2024-12-17 11:37:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T14:04:55.259920"
    },
    {
      "arxiv_id": "2502.15688v1",
      "title": "XPath Agent: An Efficient XPath Programming Agent Based on LLM for Web Crawler",
      "title_zh": "XPath Agent：一种基于 LLM 的高效 XPath 编程代理，用于 Web 爬虫",
      "authors": [
        "Yu Li",
        "Bryce Wang",
        "Xinyu Luan"
      ],
      "abstract": "We present XPath Agent, a production-ready XPath programming agent\nspecifically designed for web crawling and web GUI testing. A key feature of\nXPath Agent is its ability to automatically generate XPath queries from a set\nof sampled web pages using a single natural language query. To demonstrate its\neffectiveness, we benchmark XPath Agent against a state-of-the-art XPath\nprogramming agent across a range of web crawling tasks. Our results show that\nXPath Agent achieves comparable performance metrics while significantly\nreducing token usage and improving clock-time efficiency. The well-designed\ntwo-stage pipeline allows for seamless integration into existing web crawling\nor web GUI testing workflows, thereby saving time and effort in manual XPath\nquery development. The source code for XPath Agent is available at\nhttps://github.com/eavae/feilian.",
      "tldr_zh": "本研究介绍了XPath Agent，一种基于LLM的大型语言模型的XPath编程代理，专门用于网络爬虫和网络GUI测试。其关键功能是通过单一自然语言查询，从一组采样网页自动生成XPath查询，从而简化手动查询开发。实验结果显示，XPath Agent在各种网络爬虫任务中，与最先进代理相比，实现了相似的性能指标，同时显著降低了token使用量并提升了时效性。该代理采用精心设计的两阶段管道，便于无缝集成到现有工作流中，并提供了开源代码（https://github.com/eavae/feilian）。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.SE",
        "68T50",
        "I.2.7"
      ],
      "primary_category": "cs.IR",
      "comment": "10 pages, 2 figures",
      "pdf_url": "http://arxiv.org/pdf/2502.15688v1",
      "published_date": "2024-12-17 11:36:16 UTC",
      "updated_date": "2024-12-17 11:36:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T14:05:05.781977"
    },
    {
      "arxiv_id": "2412.13228v3",
      "title": "TSEML: A task-specific embedding-based method for few-shot classification of cancer molecular subtypes",
      "title_zh": "TSEML：一种任务特定的基于嵌入的方法，用于癌症分子亚型的少样本分类",
      "authors": [
        "Ran Su",
        "Rui Shi",
        "Hui Cui",
        "Ping Xuan",
        "Chengyan Fang",
        "Xikang Feng",
        "Qiangguo Jin"
      ],
      "abstract": "Molecular subtyping of cancer is recognized as a critical and challenging\nupstream task for personalized therapy. Existing deep learning methods have\nachieved significant performance in this domain when abundant data samples are\navailable. However, the acquisition of densely labeled samples for cancer\nmolecular subtypes remains a significant challenge for conventional\ndata-intensive deep learning approaches. In this work, we focus on the few-shot\nmolecular subtype prediction problem in heterogeneous and small cancer\ndatasets, aiming to enhance precise diagnosis and personalized treatment. We\nfirst construct a new few-shot dataset for cancer molecular subtype\nclassification and auxiliary cancer classification, named TCGA Few-Shot, from\nexisting publicly available datasets. To effectively leverage the relevant\nknowledge from both tasks, we introduce a task-specific embedding-based\nmeta-learning framework (TSEML). TSEML leverages the synergistic strengths of a\nmodel-agnostic meta-learning (MAML) approach and a prototypical network\n(ProtoNet) to capture diverse and fine-grained features. Comparative\nexperiments conducted on the TCGA Few-Shot dataset demonstrate that our TSEML\nframework achieves superior performance in addressing the problem of few-shot\nmolecular subtype classification.",
      "tldr_zh": "该研究针对癌症分子亚型（molecular subtypes）的少样本分类（few-shot classification）问题，提出了一种任务特定嵌入式元学习框架（TSEML），旨在在数据稀缺的情况下提升诊断精度。TSEML 结合了模型无关元学习（MAML）和原型网络（ProtoNet），以捕捉细粒度和多样的特征，并从辅助任务中提取相关知识。研究者构建了新的少样本数据集 TCGA Few-Shot，并通过实验证明，TSEML 在该数据集上显著优于基线方法，为癌症个性化治疗提供更有效的工具。",
      "categories": [
        "q-bio.QM",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "q-bio.QM",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.13228v3",
      "published_date": "2024-12-17 11:30:54 UTC",
      "updated_date": "2025-01-14 00:18:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T14:05:18.060376"
    },
    {
      "arxiv_id": "2412.12808v2",
      "title": "Detecting Emotional Incongruity of Sarcasm by Commonsense Reasoning",
      "title_zh": "翻译失败",
      "authors": [
        "Ziqi Qiu",
        "Jianxing Yu",
        "Yufeng Zhang",
        "Hanjiang Lai",
        "Yanghui Rao",
        "Qinliang Su",
        "Jian Yin"
      ],
      "abstract": "This paper focuses on sarcasm detection, which aims to identify whether given\nstatements convey criticism, mockery, or other negative sentiment opposite to\nthe literal meaning. To detect sarcasm, humans often require a comprehensive\nunderstanding of the semantics in the statement and even resort to external\ncommonsense to infer the fine-grained incongruity. However, existing methods\nlack commonsense inferential ability when they face complex real-world\nscenarios, leading to unsatisfactory performance. To address this problem, we\npropose a novel framework for sarcasm detection, which conducts incongruity\nreasoning based on commonsense augmentation, called EICR. Concretely, we first\nemploy retrieval-augmented large language models to supplement the missing but\nindispensable commonsense background knowledge. To capture complex contextual\nassociations, we construct a dependency graph and obtain the optimized topology\nvia graph refinement. We further introduce an adaptive reasoning skeleton that\nintegrates prior rules to extract sentiment-inconsistent subgraphs explicitly.\nTo eliminate the possible spurious relations between words and labels, we\nemploy adversarial contrastive learning to enhance the robustness of the\ndetector. Experiments conducted on five datasets demonstrate the effectiveness\nof EICR.",
      "tldr_zh": "该论文针对讽刺检测问题，提出了一种基于commonsense reasoning的框架EICR，用于识别语句中与字面意思相反的负面情绪不一致性。EICR框架首先利用retrieval-augmented large language models补充缺失的常识背景知识，然后构建dependency graph并通过图优化捕获复杂上下文关联，同时引入adaptive reasoning skeleton和对抗对比学习来提取情感不一致子图并提升模型鲁棒性。在五个数据集上的实验结果表明，该方法显著提高了讽刺检测的性能。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "In the experimental chapter, there is a problem with the experimental\n  setting and needs to be corrected",
      "pdf_url": "http://arxiv.org/pdf/2412.12808v2",
      "published_date": "2024-12-17 11:25:55 UTC",
      "updated_date": "2024-12-20 14:39:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T14:05:30.689641"
    },
    {
      "arxiv_id": "2412.12800v1",
      "title": "Breaking the Programming Language Barrier: Multilingual Prompting to Empower Non-Native English Learners",
      "title_zh": "打破编程语言障碍：多语言提示以赋能非母语英语学习者",
      "authors": [
        "James Prather",
        "Brent N. Reeves",
        "Paul Denny",
        "Juho Leinonen",
        "Stephen MacNeil",
        "Andrew Luxton-Reilly",
        "João Orvalho",
        "Amin Alipour",
        "Ali Alfageeh",
        "Thezyrie Amarouche",
        "Bailey Kimmel",
        "Jared Wright",
        "Musa Blake",
        "Gweneth Barbre"
      ],
      "abstract": "Non-native English speakers (NNES) face multiple barriers to learning\nprogramming. These barriers can be obvious, such as the fact that programming\nlanguage syntax and instruction are often in English, or more subtle, such as\nbeing afraid to ask for help in a classroom full of native English speakers.\nHowever, these barriers are frustrating because many NNES students know more\nabout programming than they can articulate in English. Advances in generative\nAI (GenAI) have the potential to break down these barriers because state of the\nart models can support interactions in multiple languages. Moreover, recent\nwork has shown that GenAI can be highly accurate at code generation and\nexplanation. In this paper, we provide the first exploration of NNES students\nprompting in their native languages (Arabic, Chinese, and Portuguese) to\ngenerate code to solve programming problems. Our results show that students are\nable to successfully use their native language to solve programming problems,\nbut not without some difficulty specifying programming terminology and\nconcepts. We discuss the challenges they faced, the implications for practice\nin the short term, and how this might transform computing education globally in\nthe long term.",
      "tldr_zh": "该论文探讨非母语英语者（NNES）在编程学习中面临的障碍，如英语语法指令和求助畏惧，尽管他们实际掌握更多编程知识。研究首次探索使用生成式AI（GenAI）进行多语言提示，让NNES学生以母语（如阿拉伯语、中文和葡萄牙语）生成代码解决编程问题。结果显示，学生能成功完成任务，但遇到指定编程术语和概念的困难；论文讨论了这些挑战、短期实践启示，以及对全球计算教育的长期变革潜力。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.CY",
      "comment": "10 pages, 3 tables. Accepted for publication at the 27th Australasian\n  Computing Education Conference (ACE 2025)",
      "pdf_url": "http://arxiv.org/pdf/2412.12800v1",
      "published_date": "2024-12-17 11:06:02 UTC",
      "updated_date": "2024-12-17 11:06:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T14:05:42.749551"
    },
    {
      "arxiv_id": "2412.12799v1",
      "title": "RCTrans: Radar-Camera Transformer via Radar Densifier and Sequential Decoder for 3D Object Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Yiheng Li",
        "Yang Yang",
        "Zhen Lei"
      ],
      "abstract": "In radar-camera 3D object detection, the radar point clouds are sparse and\nnoisy, which causes difficulties in fusing camera and radar modalities. To\nsolve this, we introduce a novel query-based detection method named\nRadar-Camera Transformer (RCTrans). Specifically, we first design a Radar Dense\nEncoder to enrich the sparse valid radar tokens, and then concatenate them with\nthe image tokens. By doing this, we can fully explore the 3D information of\neach interest region and reduce the interference of empty tokens during the\nfusing stage. We then design a Pruning Sequential Decoder to predict 3D boxes\nbased on the obtained tokens and random initialized queries. To alleviate the\neffect of elevation ambiguity in radar point clouds, we gradually locate the\nposition of the object via a sequential fusion structure. It helps to get more\nprecise and flexible correspondences between tokens and queries. A pruning\ntraining strategy is adopted in the decoder, which can save much time during\ninference and inhibit queries from losing their distinctiveness. Extensive\nexperiments on the large-scale nuScenes dataset prove the superiority of our\nmethod, and we also achieve new state-of-the-art radar-camera 3D detection\nresults. Our implementation is available at https://github.com/liyih/RCTrans.",
      "tldr_zh": "该论文提出RCTrans，一种基于查询的3D物体检测方法，用于解决雷达点云稀疏且噪声大的问题，从而改善雷达和相机模态的融合。具体地，该方法包括Radar Dense Encoder来丰富稀疏雷达标记并与图像标记连接，以及Pruning Sequential Decoder通过顺序融合结构逐步定位物体位置，并采用修剪训练策略以提升推理效率和查询独特性。在nuScenes数据集上的广泛实验证明，RCTrans实现了新的最先进雷达-相机3D检测结果。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by AAAI 2025",
      "pdf_url": "http://arxiv.org/pdf/2412.12799v1",
      "published_date": "2024-12-17 11:02:36 UTC",
      "updated_date": "2024-12-17 11:02:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T14:05:53.961063"
    },
    {
      "arxiv_id": "2412.16205v2",
      "title": "Machine Learning-Based Estimation Of Wave Direction For Unmanned Surface Vehicles",
      "title_zh": "基于机器学习的无人水面车辆波浪方向估计",
      "authors": [
        "Manele Ait Habouche",
        "Mickaël Kerboeuf",
        "Goulven Guillou",
        "Jean-Philippe Babau"
      ],
      "abstract": "Unmanned Surface Vehicles (USVs) have become critical tools for marine\nexploration, environmental monitoring, and autonomous navigation. Accurate\nestimation of wave direction is essential for improving USV navigation and\nensuring operational safety, but traditional methods often suffer from high\ncosts and limited spatial resolution. This paper proposes a machine\nlearning-based approach leveraging LSTM (Long Short-Term Memory) networks to\npredict wave direction using sensor data collected from USVs. Experimental\nresults show the capability of the LSTM model to learn temporal dependencies\nand provide accurate predictions, outperforming simpler baselines.",
      "tldr_zh": "这篇论文针对无人水面车辆(USVs)的导航安全问题，提出了一种基于机器学习的方法，利用 LSTM (Long Short-Term Memory) 网络分析传感器数据来估计波浪方向。相比传统方法，该方法能够更好地学习时间依赖性，避免高成本和空间分辨率有限的缺点。实验结果显示，LSTM 模型的预测准确性超过了简单基线模型，从而提升了 USVs 在海洋勘探和环境监测中的性能。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.RO",
        "eess.SP"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.16205v2",
      "published_date": "2024-12-17 10:53:12 UTC",
      "updated_date": "2025-02-12 09:48:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T14:06:06.057083"
    },
    {
      "arxiv_id": "2412.12791v2",
      "title": "Implicit Location-Caption Alignment via Complementary Masking for Weakly-Supervised Dense Video Captioning",
      "title_zh": "翻译失败",
      "authors": [
        "Shiping Ge",
        "Qiang Chen",
        "Zhiwei Jiang",
        "Yafeng Yin",
        "Liu Qin",
        "Ziyao Chen",
        "Qing Gu"
      ],
      "abstract": "Weakly-Supervised Dense Video Captioning (WSDVC) aims to localize and\ndescribe all events of interest in a video without requiring annotations of\nevent boundaries. This setting poses a great challenge in accurately locating\nthe temporal location of event, as the relevant supervision is unavailable.\nExisting methods rely on explicit alignment constraints between event locations\nand captions, which involve complex event proposal procedures during both\ntraining and inference. To tackle this problem, we propose a novel implicit\nlocation-caption alignment paradigm by complementary masking, which simplifies\nthe complex event proposal and localization process while maintaining\neffectiveness. Specifically, our model comprises two components: a dual-mode\nvideo captioning module and a mask generation module. The dual-mode video\ncaptioning module captures global event information and generates descriptive\ncaptions, while the mask generation module generates differentiable positive\nand negative masks for localizing the events. These masks enable the implicit\nalignment of event locations and captions by ensuring that captions generated\nfrom positively and negatively masked videos are complementary, thereby forming\na complete video description. In this way, even under weak supervision, the\nevent location and event caption can be aligned implicitly. Extensive\nexperiments on the public datasets demonstrate that our method outperforms\nexisting weakly-supervised methods and achieves competitive results compared to\nfully-supervised methods.",
      "tldr_zh": "论文针对 Weakly-Supervised Dense Video Captioning (WSDVC)，提出了一种通过 Complementary Masking 实现隐式 Location-Caption Alignment 的新范式，以简化事件提案和定位过程，同时无需事件边界标注。模型包括 Dual-Mode Video Captioning Module 和 Mask Generation Module，前者捕获全局事件信息并生成描述性标题，后者产生可微的正负 Masks，确保从 Masks 处理的视频标题互补，从而实现事件位置和标题的隐式对齐。该方法在公开数据集上的实验结果显示，它优于现有弱监督方法，并与全监督方法取得了竞争性性能。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.MM",
        "I.2.10"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by AAAI 2025",
      "pdf_url": "http://arxiv.org/pdf/2412.12791v2",
      "published_date": "2024-12-17 10:52:50 UTC",
      "updated_date": "2025-01-27 10:40:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T14:06:19.740651"
    },
    {
      "arxiv_id": "2412.12781v1",
      "title": "Predicting change in time production -- A machine learning approach to time perception",
      "title_zh": "预测时间生产中的变化——一种机器学习方法在时间感知中的应用",
      "authors": [
        "Amrapali Pednekar",
        "Alvaro Garrido",
        "Yara Khaluf",
        "Pieter Simoens"
      ],
      "abstract": "Time perception research has advanced significantly over the years. However,\nsome areas remain largely unexplored. This study addresses two such\nunder-explored areas in timing research: (1) A quantitative analysis of time\nperception at an individual level, and (2) Time perception in an ecological\nsetting. In this context, we trained a machine learning model to predict the\ndirection of change in an individual's time production. The model's training\ndata was collected using an ecologically valid setup. We moved closer to an\necological setting by conducting an online experiment with 995 participants\nperforming a time production task that used naturalistic videos (no audio) as\nstimuli. The model achieved an accuracy of 61%. This was 10 percentage points\nhigher than the baseline models derived from cognitive theories of timing. The\nmodel performed equally well on new data from a second experiment, providing\nevidence of its generalization capabilities. The model's output analysis\nrevealed that it also contained information about the magnitude of change in\ntime production. The predictions were further analysed at both population and\nindividual level. It was found that a participant's previous timing performance\nplayed a significant role in determining the direction of change in time\nproduction. By integrating attentional-gate theories from timing research with\nfeature importance techniques from machine learning, we explained model\npredictions using cognitive theories of timing. The model and findings from\nthis study have potential applications in systems involving human-computer\ninteractions where understanding and predicting changes in user's time\nperception can enable better user experience and task performance.",
      "tldr_zh": "本研究使用机器学习模型预测个体时间生产的变化方向，填补了时间感知研究中个体水平定量分析和生态设置的空白。实验通过在线实验（涉及995名参与者，使用自然视频作为刺激）收集数据，模型准确率达61%，比基于认知理论的基线模型高10%，并在第二实验中显示出良好的泛化能力。分析结果表明，模型不仅捕捉了变化幅度信息，还揭示了参与者先前表现对时间生产变化方向的显著影响；通过整合注意力门理论和特征重要性技术，解释了预测机制。该方法可应用于人机交互系统，提升用户体验和任务性能。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.LG",
        "J.4; I.2.m"
      ],
      "primary_category": "cs.HC",
      "comment": "Main text contains 16 pages and 9 figure. Supplementary information\n  is included as appendix. The paper has been submitted to IEEE TRANSACTIONS ON\n  COGNITIVE AND DEVELOPMENTAL SYSTEMS (TCDS). The code and data associated with\n  the study will be made publicly available upon acceptance",
      "pdf_url": "http://arxiv.org/pdf/2412.12781v1",
      "published_date": "2024-12-17 10:41:19 UTC",
      "updated_date": "2024-12-17 10:41:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T14:06:31.863795"
    },
    {
      "arxiv_id": "2412.12778v2",
      "title": "Rethinking Diffusion-Based Image Generators for Fundus Fluorescein Angiography Synthesis on Limited Data",
      "title_zh": "翻译失败",
      "authors": [
        "Chengzhou Yu",
        "Huihui Fang",
        "Hongqiu Wang",
        "Ting Deng",
        "Qing Du",
        "Yanwu Xu",
        "Weihua Yang"
      ],
      "abstract": "Fundus imaging is a critical tool in ophthalmology, with different imaging\nmodalities offering unique advantages. For instance, fundus fluorescein\nangiography (FFA) can accurately identify eye diseases. However, traditional\ninvasive FFA involves the injection of sodium fluorescein, which can cause\ndiscomfort and risks. Generating corresponding FFA images from non-invasive\nfundus images holds significant practical value but also presents challenges.\nFirst, limited datasets constrain the performance and effectiveness of models.\nSecond, previous studies have primarily focused on generating FFA for single\ndiseases or single modalities, often resulting in poor performance for patients\nwith various ophthalmic conditions. To address these issues, we propose a novel\nlatent diffusion model-based framework, Diffusion, which introduces a\nfine-tuning protocol to overcome the challenge of limited medical data and\nunleash the generative capabilities of diffusion models. Furthermore, we\ndesigned a new approach to tackle the challenges of generating across different\nmodalities and disease types. On limited datasets, our framework achieves\nstate-of-the-art results compared to existing methods, offering significant\npotential to enhance ophthalmic diagnostics and patient care. Our code will be\nreleased soon to support further research in this field.",
      "tldr_zh": "该论文重新思考基于扩散模型的图像生成器，旨在从有限数据合成 Fundus Fluorescein Angiography (FFA) 图像，以避免传统侵入性方法的疼痛和风险。研究提出一个新型的潜在扩散模型框架（Diffusion），包括微调协议来应对数据有限的挑战，以及一种新方法处理不同模态和疾病类型的生成问题。实验结果显示，该框架在有限数据集上比现有方法实现了 state-of-the-art 性能，显著提升眼科诊断的准确性和患者护理潜力。代码将很快发布，以支持进一步研究。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "The first author has a conflict with the data access authority",
      "pdf_url": "http://arxiv.org/pdf/2412.12778v2",
      "published_date": "2024-12-17 10:37:46 UTC",
      "updated_date": "2025-03-10 02:53:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T14:06:43.508263"
    },
    {
      "arxiv_id": "2412.12771v2",
      "title": "Guided and Variance-Corrected Fusion with One-shot Style Alignment for Large-Content Image Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Shoukun Sun",
        "Min Xian",
        "Tiankai Yao",
        "Fei Xu",
        "Luca Capriotti"
      ],
      "abstract": "Producing large images using small diffusion models is gaining increasing\npopularity, as the cost of training large models could be prohibitive. A common\napproach involves jointly generating a series of overlapped image patches and\nobtaining large images by merging adjacent patches. However, results from\nexisting methods often exhibit noticeable artifacts, e.g., seams and\ninconsistent objects and styles. To address the issues, we proposed Guided\nFusion (GF), which mitigates the negative impact from distant image regions by\napplying a weighted average to the overlapping regions. Moreover, we proposed\nVariance-Corrected Fusion (VCF), which corrects data variance at\npost-averaging, generating more accurate fusion for the Denoising Diffusion\nProbabilistic Model. Furthermore, we proposed a one-shot Style Alignment (SA),\nwhich generates a coherent style for large images by adjusting the initial\ninput noise without adding extra computational burden. Extensive experiments\ndemonstrated that the proposed fusion methods improved the quality of the\ngenerated image significantly. The proposed method can be widely applied as a\nplug-and-play module to enhance other fusion-based methods for large image\ngeneration. Code: https://github.com/TitorX/GVCFDiffusion",
      "tldr_zh": "这篇论文提出了一种针对大型图像生成的方法，使用小型扩散模型来避免训练大型模型的成本问题。论文引入Guided Fusion (GF)通过加权平均减轻重叠区域的负面影响、Variance-Corrected Fusion (VCF)修正平均后的数据方差以提升Denoising Diffusion Probabilistic Model的融合准确性，以及One-shot Style Alignment (SA)通过调整初始输入噪声实现图像风格的一致性，而不增加额外计算负担。实验结果显示，该方法显著提高了生成图像的质量，并可作为插件模块应用于其他融合-based的大型图像生成技术。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.12771v2",
      "published_date": "2024-12-17 10:33:34 UTC",
      "updated_date": "2025-02-10 18:55:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T14:06:56.031281"
    },
    {
      "arxiv_id": "2412.12767v1",
      "title": "A Survey of Calibration Process for Black-Box LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Liangru Xie",
        "Hui Liu",
        "Jingying Zeng",
        "Xianfeng Tang",
        "Yan Han",
        "Chen Luo",
        "Jing Huang",
        "Zhen Li",
        "Suhang Wang",
        "Qi He"
      ],
      "abstract": "Large Language Models (LLMs) demonstrate remarkable performance in semantic\nunderstanding and generation, yet accurately assessing their output reliability\nremains a significant challenge. While numerous studies have explored\ncalibration techniques, they primarily focus on White-Box LLMs with accessible\nparameters. Black-Box LLMs, despite their superior performance, pose heightened\nrequirements for calibration techniques due to their API-only interaction\nconstraints. Although recent researches have achieved breakthroughs in\nblack-box LLMs calibration, a systematic survey of these methodologies is still\nlacking. To bridge this gap, we presents the first comprehensive survey on\ncalibration techniques for black-box LLMs. We first define the Calibration\nProcess of LLMs as comprising two interrelated key steps: Confidence Estimation\nand Calibration. Second, we conduct a systematic review of applicable methods\nwithin black-box settings, and provide insights on the unique challenges and\nconnections in implementing these key steps. Furthermore, we explore typical\napplications of Calibration Process in black-box LLMs and outline promising\nfuture research directions, providing new perspectives for enhancing\nreliability and human-machine alignment. This is our GitHub link:\nhttps://github.com/LiangruXie/Calibration-Process-in-Black-Box-LLMs",
      "tldr_zh": "这篇论文对 Black-Box LLMs 的校准过程进行了首次全面调查，旨在解决这些模型在输出可靠性评估上的挑战，因为它们仅通过 API 交互而无法访问内部参数。论文将校准过程定义为 Confidence Estimation 和 Calibration 两个关键步骤，并系统回顾了适用于 Black-Box 设置的方法，同时分析了独特挑战、方法间的联系以及实际应用。最终，它探讨了校准在提升 LLMs 可靠性和人类-机器对齐方面的潜力，并指出了未来研究方向。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.12767v1",
      "published_date": "2024-12-17 10:31:21 UTC",
      "updated_date": "2024-12-17 10:31:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T14:07:07.446192"
    },
    {
      "arxiv_id": "2412.12761v1",
      "title": "Revealing the impact of synthetic native samples and multi-tasking strategies in Hindi-English code-mixed humour and sarcasm detection",
      "title_zh": "揭示合成本土样本和多任务策略在印地-英语代码混合幽默与讽刺检测",
      "authors": [
        "Debajyoti Mazumder",
        "Aakash Kumar",
        "Jasabanta Patro"
      ],
      "abstract": "In this paper, we reported our experiments with various strategies to improve\ncode-mixed humour and sarcasm detection. We did all of our experiments for\nHindi-English code-mixed scenario, as we have the linguistic expertise for the\nsame. We experimented with three approaches, namely (i) native sample mixing,\n(ii) multi-task learning (MTL), and (iii) prompting very large multilingual\nlanguage models (VMLMs). In native sample mixing, we added monolingual task\nsamples in code-mixed training sets. In MTL learning, we relied on native and\ncode-mixed samples of a semantically related task (hate detection in our case).\nFinally, in our third approach, we evaluated the efficacy of VMLMs via few-shot\ncontext prompting. Some interesting findings we got are (i) adding native\nsamples improved humor (raising the F1-score up to 6.76%) and sarcasm (raising\nthe F1-score up to 8.64%) detection, (ii) training MLMs in an MTL framework\nboosted performance for both humour (raising the F1-score up to 10.67%) and\nsarcasm (increment up to 12.35% in F1-score) detection, and (iii) prompting\nVMLMs couldn't outperform the other approaches. Finally, our ablation studies\nand error analysis discovered the cases where our model is yet to improve. We\nprovided our code for reproducibility.",
      "tldr_zh": "本研究探讨了三种策略来提升 Hindi-English 代码混合语境下的幽默和讽刺检测性能：(i) native sample mixing（添加单语任务样本到训练集），(ii) multi-task learning (MTL)（利用语义相关任务如仇恨检测的样本），以及 (iii) prompting very large multilingual language models (VMLMs) 通过少样本上下文提示。\n实验结果显示，native sample mixing 显著提高了幽默检测 (F1-score 提升至 6.76%) 和讽刺检测 (F1-score 提升至 8.64%)；MTL 框架进一步提升了幽默 (F1-score 提升至 10.67%) 和讽刺 (F1-score 提升至 12.35%) 性能，而 VMLMs 的提示方法则不如其他策略有效。\n研究还通过消融研究和错误分析识别了模型的改进空间，并提供了代码以支持可复现性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "26 pages; under review",
      "pdf_url": "http://arxiv.org/pdf/2412.12761v1",
      "published_date": "2024-12-17 10:26:54 UTC",
      "updated_date": "2024-12-17 10:26:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T14:07:22.044712"
    },
    {
      "arxiv_id": "2412.12744v1",
      "title": "Your Next State-of-the-Art Could Come from Another Domain: A Cross-Domain Analysis of Hierarchical Text Classification",
      "title_zh": "翻译失败",
      "authors": [
        "Nan Li",
        "Bo Kang",
        "Tijl De Bie"
      ],
      "abstract": "Text classification with hierarchical labels is a prevalent and challenging\ntask in natural language processing. Examples include assigning ICD codes to\npatient records, tagging patents into IPC classes, assigning EUROVOC\ndescriptors to European legal texts, and more. Despite its widespread\napplications, a comprehensive understanding of state-of-the-art methods across\ndifferent domains has been lacking. In this paper, we provide the first\ncomprehensive cross-domain overview with empirical analysis of state-of-the-art\nmethods. We propose a unified framework that positions each method within a\ncommon structure to facilitate research. Our empirical analysis yields key\ninsights and guidelines, confirming the necessity of learning across different\nresearch areas to design effective methods. Notably, under our unified\nevaluation pipeline, we achieved new state-of-the-art results by applying\ntechniques beyond their original domains.",
      "tldr_zh": "本研究对分层文本分类（hierarchical text classification）进行了首次全面跨领域分析，探讨其在医疗记录（如ICD codes）、专利（如IPC classes）和法律文本（如EUROVOC descriptors）等领域的应用挑战。论文提出一个统一框架，将现有最先进方法（state-of-the-art methods）置于共同结构中，并通过实证分析提供关键洞见，强调跨领域学习的重要性。结果显示，通过该统一评估管道应用非原生领域技术，实现了新的最先进性能，指导了更有效的分类方法设计。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.12744v1",
      "published_date": "2024-12-17 10:08:57 UTC",
      "updated_date": "2024-12-17 10:08:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T14:07:31.472068"
    },
    {
      "arxiv_id": "2412.12742v1",
      "title": "Subspace Implicit Neural Representations for Real-Time Cardiac Cine MR Imaging",
      "title_zh": "子空间隐",
      "authors": [
        "Wenqi Huang",
        "Veronika Spieker",
        "Siying Xu",
        "Gastao Cruz",
        "Claudia Prieto",
        "Julia Schnabel",
        "Kerstin Hammernik",
        "Thomas Kuestner",
        "Daniel Rueckert"
      ],
      "abstract": "Conventional cardiac cine MRI methods rely on retrospective gating, which\nlimits temporal resolution and the ability to capture continuous cardiac\ndynamics, particularly in patients with arrhythmias and beat-to-beat\nvariations. To address these challenges, we propose a reconstruction framework\nbased on subspace implicit neural representations for real-time cardiac cine\nMRI of continuously sampled radial data. This approach employs two multilayer\nperceptrons to learn spatial and temporal subspace bases, leveraging the\nlow-rank properties of cardiac cine MRI. Initialized with low-resolution\nreconstructions, the networks are fine-tuned using spoke-specific loss\nfunctions to recover spatial details and temporal fidelity. Our method directly\nutilizes the continuously sampled radial k-space spokes during training,\nthereby eliminating the need for binning and non-uniform FFT. This approach\nachieves superior spatial and temporal image quality compared to conventional\nbinned methods at the acceleration rate of 10 and 20, demonstrating potential\nfor high-resolution imaging of dynamic cardiac events and enhancing diagnostic\ncapability.",
      "tldr_zh": "本研究针对传统心脏电影 MRI 的回顾性门控（retrospective gating）问题，提出了一种基于子空间隐式神经表示（subspace implicit neural representations）的重建框架，用于实时心脏电影 MRI 的连续径向数据处理。该框架利用两个多层感知器（multilayer perceptrons）学习空间和时间子空间基，并通过低分辨率重建初始化和辐条特定损失函数（spoke-specific loss functions）进行微调，从而直接利用连续采样的径向 k-space 辐条，消除了分箱和非均匀 FFT 的需求。与传统方法相比，该方法在加速率 10 和 20 时实现了 superior 的空间和时间图像质量，具有潜力提升动态心脏事件的诊断能力。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.12742v1",
      "published_date": "2024-12-17 10:06:37 UTC",
      "updated_date": "2024-12-17 10:06:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T14:07:45.541006"
    },
    {
      "arxiv_id": "2412.12735v1",
      "title": "GIRAFFE: Design Choices for Extending the Context Length of Visual Language Models",
      "title_zh": "GIRAFFE：扩展视觉语言模型上下文长度的设计选择",
      "authors": [
        "Mukai Li",
        "Lei Li",
        "Shansan Gong",
        "Qi Liu"
      ],
      "abstract": "Visual Language Models (VLMs) demonstrate impressive capabilities in\nprocessing multimodal inputs, yet applications such as visual agents, which\nrequire handling multiple images and high-resolution videos, demand enhanced\nlong-range modeling. Moreover, existing open-source VLMs lack systematic\nexploration into extending their context length, and commercial models often\nprovide limited details. To tackle this, we aim to establish an effective\nsolution that enhances long context performance of VLMs while preserving their\ncapacities in short context scenarios. Towards this goal, we make the best\ndesign choice through extensive experiment settings from data curation to\ncontext window extending and utilizing: (1) we analyze data sources and length\ndistributions to construct ETVLM - a data recipe to balance the performance\nacross scenarios; (2) we examine existing position extending methods, identify\ntheir limitations and propose M-RoPE++ as an enhanced approach; we also choose\nto solely instruction-tune the backbone with mixed-source data; (3) we discuss\nhow to better utilize extended context windows and propose hybrid-resolution\ntraining. Built on the Qwen-VL series model, we propose Giraffe, which is\neffectively extended to 128K lengths. Evaluated on extensive long context VLM\nbenchmarks such as VideoMME and Viusal Haystacks, our Giraffe achieves\nstate-of-the-art performance among similarly sized open-source long VLMs and is\ncompetitive with commercial model GPT-4V. We will open-source the code, data,\nand models.",
      "tldr_zh": "本研究探讨了扩展视觉语言模型（VLMs）的上下文长度设计选择，旨在提升模型处理多图像和高分辨率视频的能力，同时保持短上下文性能。研究者构建了ETVLM数据方案，通过分析数据来源和长度分布来平衡不同场景的性能；提出了M-RoPE++方法来改进位置扩展，并采用混合来源数据进行主干模型的指令微调，以及混合分辨率训练来优化长上下文利用。基于Qwen-VL系列模型，Giraffe框架成功扩展至128K长度，并在VideoMME和Visual Haystacks等基准测试中，超越同规模开源长VLMs并与GPT-4V竞争性能；该模型的代码、数据和模型将开源。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "Working in progress",
      "pdf_url": "http://arxiv.org/pdf/2412.12735v1",
      "published_date": "2024-12-17 09:57:21 UTC",
      "updated_date": "2024-12-17 09:57:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T14:07:57.800874"
    },
    {
      "arxiv_id": "2412.12722v1",
      "title": "Defending LVLMs Against Vision Attacks through Partial-Perception Supervision",
      "title_zh": "翻译失败",
      "authors": [
        "Qi Zhou",
        "Tianlin Li",
        "Qing Guo",
        "Dongxia Wang",
        "Yun Lin",
        "Yang Liu",
        "Jin Song Dong"
      ],
      "abstract": "Recent studies have raised significant concerns regarding the vulnerability\nof Large Vision Language Models (LVLMs) to maliciously injected or perturbed\ninput images, which can mislead their responses. Existing defense methods show\nthat such vision attacks are sensitive to image modifications especially\ncropping, using majority voting across responses of modified images as\ncorrected responses. However, these modifications often result in partial\nimages and distort the semantics, which reduces response quality on clean\nimages after voting. Instead of directly using responses from partial images\nfor voting, we investigate using them to supervise the LVLM's responses to the\noriginal images. We propose a black-box, training-free method called DPS\n(Defense through Partial-Perception Supervision). In this approach, the model\nis prompted using the responses generated by a model that perceives only a\npartial image. With DPS, the model can adjust its response based on partial\nimage understanding when under attack, while confidently maintaining its\noriginal response for clean input. Our findings show that the weak model can\nsupervise the strong model: when faced with an attacked input, the strong model\nbecomes less confident and adjusts its response based on the weak model's\npartial understanding, effectively defending against the attack. With clean\ninput, it confidently maintains its original response. Empirical experiments\nshow our method outperforms the baseline, cutting the average attack success\nrate by 76.3% across six datasets on three popular models.",
      "tldr_zh": "该研究针对Large Vision Language Models (LVLMs) 易受恶意图像攻击的问题，提出了一种黑盒、无需训练的防御方法DPS (Defense through Partial-Perception Supervision)。DPS利用部分图像的响应来监督模型对原始图像的输出，使模型在面临攻击时降低自信度并调整响应，而在干净输入时保持原响应，从而有效平衡防御与响应质量。实验结果显示，该方法在六个数据集和三个流行模型上，比基线方法降低了76.3%的平均攻击成功率，证明了弱模型监督强模型的有效性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.12722v1",
      "published_date": "2024-12-17 09:38:58 UTC",
      "updated_date": "2024-12-17 09:38:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T14:08:07.599872"
    },
    {
      "arxiv_id": "2412.12700v1",
      "title": "ParMod: A Parallel and Modular Framework for Learning Non-Markovian Tasks",
      "title_zh": "翻译失败",
      "authors": [
        "Ruixuan Miao",
        "Xu Lu",
        "Cong Tian",
        "Bin Yu",
        "Zhenhua Duan"
      ],
      "abstract": "The commonly used Reinforcement Learning (RL) model, MDPs (Markov Decision\nProcesses), has a basic premise that rewards depend on the current state and\naction only. However, many real-world tasks are non-Markovian, which has\nlong-term memory and dependency. The reward sparseness problem is further\namplified in non-Markovian scenarios. Hence learning a non-Markovian task (NMT)\nis inherently more difficult than learning a Markovian one. In this paper, we\npropose a novel \\textbf{Par}allel and \\textbf{Mod}ular RL framework, ParMod,\nspecifically for learning NMTs specified by temporal logic. With the aid of\nformal techniques, the NMT is modulaized into a series of sub-tasks based on\nthe automaton structure (equivalent to its temporal logic counterpart). On this\nbasis, sub-tasks will be trained by a group of agents in a parallel fashion,\nwith one agent handling one sub-task. Besides parallel training, the core of\nParMod lies in: a flexible classification method for modularizing the NMT, and\nan effective reward shaping method for improving the sample efficiency. A\ncomprehensive evaluation is conducted on several challenging benchmark problems\nwith respect to various metrics. The experimental results show that ParMod\nachieves superior performance over other relevant studies. Our work thus\nprovides a good synergy among RL, NMT and temporal logic.",
      "tldr_zh": "该论文针对强化学习（RL）中马尔科夫决策过程（MDPs）的局限性，提出了一种新的并行和模块化框架ParMod，用于学习非马尔科夫任务（NMTs），这些任务涉及长期记忆和依赖，并通过时间逻辑进行指定。ParMod框架将NMTs基于自动机结构模块化为一系列子任务，并采用多个代理进行并行训练，同时引入灵活的分类方法和有效的奖励整形技术，以提升样本效率和学习性能。在多个基准问题上的实验评估显示，ParMod在各种指标上显著优于现有方法，并实现了RL、NMTs和时间逻辑之间的良好协同效应。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.12700v1",
      "published_date": "2024-12-17 09:16:53 UTC",
      "updated_date": "2024-12-17 09:16:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T14:08:19.619943"
    },
    {
      "arxiv_id": "2412.12693v3",
      "title": "SPHERE: Unveiling Spatial Blind Spots in Vision-Language Models Through Hierarchical Evaluation",
      "title_zh": "SPHERE：通过分层评估揭示视觉语言模型中的空间盲点",
      "authors": [
        "Wenyu Zhang",
        "Wei En Ng",
        "Lixin Ma",
        "Yuwen Wang",
        "Jungqi Zhao",
        "Allison Koenecke",
        "Boyang Li",
        "Lu Wang"
      ],
      "abstract": "Current vision-language models may grasp basic spatial cues and simple\ndirections (e.g. left, right, front, back), but struggle with the\nmulti-dimensional spatial reasoning necessary for human-like understanding and\nreal-world applications. To address this gap, we develop SPHERE (Spatial\nPerception and Hierarchical Evaluation of REasoning), a hierarchical evaluation\nframework supported by a new human-annotated dataset. SPHERE systematically\nprobes models across increasing levels of complexity, from fundamental skills\nto multi-skill integration and high-level reasoning that combines spatial,\nvisual, and logical understanding. Benchmark evaluation of state-of-the-art\nmodels reveals significant deficiencies, especially in reasoning about distance\nand proximity, understanding both egocentric and allocentric perspectives, and\napplying spatial logic in physical contexts. These findings expose critical\nblind spots in existing models and underscore the need for more advanced\nspatial reasoning techniques, driving the development of vision-language models\nthat align more closely with human spatial cognition. The SPHERE benchmark is\navailable at https://github.com/zwenyu/SPHERE-VLM.",
      "tldr_zh": "本研究揭示了视觉语言模型（VLMs）在空间推理方面的盲点，提出SPHERE框架，这是一个分层评估系统，结合新的人类标注数据集，用于系统测试模型从基本技能到高级推理的能力，包括空间、视觉和逻辑整合。SPHERE评估显示，现有模型在距离与接近度、自我中心与外中心视角，以及物理语境中的空间逻辑应用上存在显著缺陷。实验结果强调了开发更先进空间推理技术的必要性，以使VLMs更接近人类认知水平，该基准数据集已公开在https://github.com/zwenyu/SPHERE-VLM。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.12693v3",
      "published_date": "2024-12-17 09:10:55 UTC",
      "updated_date": "2025-02-28 15:14:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T14:08:31.542756"
    },
    {
      "arxiv_id": "2412.19824v1",
      "title": "AnalogXpert: Automating Analog Topology Synthesis by Incorporating Circuit Design Expertise into Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Haoyi Zhang",
        "Shizhao Sun",
        "Yibo Lin",
        "Runsheng Wang",
        "Jiang Bian"
      ],
      "abstract": "Analog circuits are crucial in modern electronic systems, and automating\ntheir design has attracted significant research interest. One of major\nchallenges is topology synthesis, which determines circuit components and their\nconnections. Recent studies explore large language models (LLM) for topology\nsynthesis. However, the scenarios addressed by these studies do not align well\nwith practical applications. Specifically, existing work uses vague design\nrequirements as input and outputs an ideal model, but detailed structural\nrequirements and device-level models are more practical. Moreover, current\napproaches either formulate topology synthesis as graph generation or Python\ncode generation, whereas practical topology design is a complex process that\ndemands extensive design knowledge. In this work, we propose AnalogXpert, a\nLLM-based agent aiming at solving practical topology synthesis problem by\nincorporating circuit design expertise into LLMs. First, we represent analog\ntopology as SPICE code and introduce a subcircuit library to reduce the design\nspace, in the same manner as experienced designers. Second, we decompose the\nproblem into two sub-task (i.e., block selection and block connection) through\nthe use of CoT and incontext learning techniques, to mimic the practical design\nprocess. Third, we introduce a proofreading strategy that allows LLMs to\nincrementally correct the errors in the initial design, akin to human designers\nwho iteratively check and adjust the initial topology design to ensure\naccuracy. Finally, we construct a high-quality benchmark containing both real\ndata (30) and synthetic data (2k). AnalogXpert achieves 40% and 23% success\nrates on the synthetic dataset and real dataset respectively, which is markedly\nbetter than those of GPT-4o (3% on both the synthetic dataset and the real\ndataset).",
      "tldr_zh": "本研究提出 AnalogXpert，一种基于大型语言模型(LLM)的代理系统，用于自动化模拟电路拓扑合成，通过融入电路设计专业知识来解决现有方法在实际应用中的局限性。该框架将拓扑表示为 SPICE 代码，并引入子电路库缩小设计空间，同时通过 Chain-of-Thought (CoT) 和 in-context learning 技术，将问题分解为块选择和块连接子任务，并采用校对策略实现迭代错误修正，模仿人类设计师的流程。在构建的高质量基准数据集上，AnalogXpert 在合成数据集（2k 条）上实现40%的成功率，在真实数据集（30 条）上达到23%，远超 GPT-4o 的3%。这为实用模拟电路设计提供了更可靠的自动化解决方案。",
      "categories": [
        "cs.AR",
        "cs.AI",
        "cs.SE"
      ],
      "primary_category": "cs.AR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.19824v1",
      "published_date": "2024-12-17 09:08:08 UTC",
      "updated_date": "2024-12-17 09:08:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T14:08:44.248789"
    },
    {
      "arxiv_id": "2412.12681v1",
      "title": "Everyday AR through AI-in-the-Loop",
      "title_zh": "翻译失败",
      "authors": [
        "Ryo Suzuki",
        "Mar Gonzalez-Franco",
        "Misha Sra",
        "David Lindlbauer"
      ],
      "abstract": "This workshop brings together experts and practitioners from augmented\nreality (AR) and artificial intelligence (AI) to shape the future of\nAI-in-the-loop everyday AR experiences. With recent advancements in both AR\nhardware and AI capabilities, we envision that everyday AR -- always-available\nand seamlessly integrated into users' daily environments -- is becoming\nincreasingly feasible. This workshop will explore how AI can drive such\neveryday AR experiences. We discuss a range of topics, including adaptive and\ncontext-aware AR, generative AR content creation, always-on AI assistants,\nAI-driven accessible design, and real-world-oriented AI agents. Our goal is to\nidentify the opportunities and challenges in AI-enabled AR, focusing on\ncreating novel AR experiences that seamlessly blend the digital and physical\nworlds. Through the workshop, we aim to foster collaboration, inspire future\nresearch, and build a community to advance the research field of AI-enhanced\nAR.",
      "tldr_zh": "这个工作坊聚集AR和AI领域的专家和从业者，探讨如何通过AI-in-the-Loop实现日常生活AR体验，包括自适应和上下文感知AR、生成AR内容、始终在线AI助手、AI驱动的可访问设计以及面向现实世界的AI代理。工作坊聚焦于识别AI-enabled AR的机会和挑战，旨在创建无缝融合数字与物理世界的创新AR体验。通过促进合作和社区构建，该工作坊将激发未来AI增强AR的研究方向。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.HC",
      "comment": "CHI 2025 Extended Abstract",
      "pdf_url": "http://arxiv.org/pdf/2412.12681v1",
      "published_date": "2024-12-17 08:51:55 UTC",
      "updated_date": "2024-12-17 08:51:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T14:08:55.249307"
    },
    {
      "arxiv_id": "2412.12661v2",
      "title": "MedMax: Mixed-Modal Instruction Tuning for Training Biomedical Assistants",
      "title_zh": "MedMax：混合模态指令微调用于训练生物医学助手",
      "authors": [
        "Hritik Bansal",
        "Daniel Israel",
        "Siyan Zhao",
        "Shufan Li",
        "Tung Nguyen",
        "Aditya Grover"
      ],
      "abstract": "Recent advancements in mixed-modal generative have opened new avenues for\ndeveloping unified biomedical assistants capable of analyzing biomedical\nimages, answering complex questions about them, and generating multimodal\npatient reports. However, existing datasets face challenges such as small\nsizes, limited coverage of biomedical tasks and domains, and a reliance on\nnarrow sources. To address these gaps, we present MedMax, a large-scale\nmultimodal biomedical instruction-tuning dataset for mixed-modal foundation\nmodels. With 1.47 million instances, MedMax encompasses a diverse range of\ntasks, including interleaved image-text generation, biomedical image captioning\nand generation, visual chat, and report understanding. These tasks span\nknowledge across diverse biomedical domains, including radiology and\nhistopathology, grounded in medical papers and YouTube videos. Subsequently, we\nfine-tune a mixed-modal foundation model on the MedMax dataset, achieving\nsignificant performance improvements: a 26% gain over the Chameleon model and\nan 18.3% improvement over GPT-4o across 12 downstream biomedical visual\nquestion-answering tasks. Finally, we introduce a unified evaluation suite for\nbiomedical tasks to guide the development of mixed-modal biomedical AI\nassistants. The data, model, and code is available at\nhttps://mint-medmax.github.io/.",
      "tldr_zh": "该研究引入了 MedMax，这是一个大规模的多模态生物医学指令微调数据集，旨在解决现有数据集规模小、任务覆盖有限和来源狭窄的问题。MedMax 包含 147 万实例，涵盖多样任务如 interleaved image-text generation、生物医学图像描述和生成、视觉聊天及报告理解，涉及放射学和组织病理学等领域，并基于医疗论文和 YouTube 视频。研究团队在 MedMax 上微调混合模态基础模型，实现了显著提升：在 12 个下游生物医学视觉问答任务上，比 Chameleon 模型提高 26%、比 GPT-4o 提升 18.3%，并推出了一个统一的生物医学任务评估套件以指导相关 AI 助手的发展。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.CV"
      ],
      "primary_category": "cs.AI",
      "comment": "29 pages",
      "pdf_url": "http://arxiv.org/pdf/2412.12661v2",
      "published_date": "2024-12-17 08:30:00 UTC",
      "updated_date": "2025-04-23 06:29:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T14:09:07.241579"
    },
    {
      "arxiv_id": "2412.12656v1",
      "title": "DriveTester: A Unified Platform for Simulation-Based Autonomous Driving Testing",
      "title_zh": "DriveTester: 用于基于模拟的",
      "authors": [
        "Mingfei Cheng",
        "Yuan Zhou",
        "Xiaofei Xie"
      ],
      "abstract": "Simulation-based testing plays a critical role in evaluating the safety and\nreliability of autonomous driving systems (ADSs). However, one of the key\nchallenges in ADS testing is the complexity of preparing and configuring\nsimulation environments, particularly in terms of compatibility and stability\nbetween the simulator and the ADS. This complexity often results in researchers\ndedicating significant effort to customize their own environments, leading to\ndisparities in development platforms and underlying systems. Consequently,\nreproducing and comparing these methodologies on a unified ADS testing platform\nbecomes difficult. To address these challenges, we introduce DriveTester, a\nunified simulation-based testing platform built on Apollo, one of the most\nwidely used open-source, industrial-level ADS platforms. DriveTester provides a\nconsistent and reliable environment, integrates a lightweight traffic\nsimulator, and incorporates various state-of-the-art ADS testing techniques.\nThis enables researchers to efficiently develop, test, and compare their\nmethods within a standardized platform, fostering reproducibility and\ncomparison across different ADS testing approaches. The code is available:\nhttps://github.com/MingfeiCheng/DriveTester.",
      "tldr_zh": "该研究针对自动驾驶系统（ADS）的模拟测试面临的挑战，如模拟环境配置的复杂性、兼容性和稳定性问题，导致方法难以复现和比较，提出了一种统一平台DriveTester。DriveTester基于开源平台Apollo构建，集成了轻量级交通模拟器和各种先进的ADS测试技术，提供一致可靠的环境以简化开发过程。实验表明，该平台能帮助研究者高效测试和比较方法，促进跨方法的可复现性，并已开源代码于GitHub。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.12656v1",
      "published_date": "2024-12-17 08:24:05 UTC",
      "updated_date": "2024-12-17 08:24:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T14:09:18.832380"
    },
    {
      "arxiv_id": "2412.12651v1",
      "title": "Shared Attention-based Autoencoder with Hierarchical Fusion-based Graph Convolution Network for sEEG SOZ Identification",
      "title_zh": "翻译失败",
      "authors": [
        "Huachao Yan",
        "Kailing Guo",
        "Shiwei Song",
        "Yihai Dai",
        "Xiaoqiang Wei",
        "Xiaofen Xing",
        "Xiangmin Xu"
      ],
      "abstract": "Diagnosing seizure onset zone (SOZ) is a challenge in neurosurgery, where\nstereoelectroencephalography (sEEG) serves as a critical technique. In sEEG SOZ\nidentification, the existing studies focus solely on the intra-patient\nrepresentation of epileptic information, overlooking the general features of\nepilepsy across patients and feature interdependencies between feature elements\nin each contact site. In order to address the aforementioned challenges, we\npropose the shared attention-based autoencoder (sATAE). sATAE is trained by\nsEEG data across all patients, with attention blocks introduced to enhance the\nrepresentation of interdependencies between feature elements. Considering the\nspatial diversity of sEEG across patients, we introduce graph-based method for\nidentification SOZ of each patient. However, the current graph-based methods\nfor sEEG SOZ identification rely exclusively on static graphs to model\nepileptic networks. Inspired by the finding of neuroscience that epileptic\nnetwork is intricately characterized by the interplay of sophisticated\nequilibrium between fluctuating and stable states, we design the hierarchical\nfusion-based graph convolution network (HFGCN) to identify the SOZ. HFGCN\nintegrates the dynamic and static characteristics of epileptic networks through\nhierarchical weighting across different hierarchies, facilitating a more\ncomprehensive learning of epileptic features and enriching node information for\nsEEG SOZ identification. Combining sATAE and HFGCN, we perform comprehensive\nexperiments with sATAE-HFGCN on the self-build sEEG dataset, which includes\nsEEG data from 17 patients with temporal lobe epilepsy. The results show that\nour method, sATAE-HFGCN, achieves superior performance for identifying the SOZ\nof each patient, effectively addressing the aforementioned challenges,\nproviding an efficient solution for sEEG-based SOZ identification.",
      "tldr_zh": "这篇论文针对 sEEG SOZ 识别的挑战，提出了一种共享注意力-based autoencoder (sATAE)，它利用跨患者 sEEG 数据训练，并通过注意力块增强特征元素间的相互依赖性，以捕捉癫痫的一般特征。论文进一步设计了 hierarchical fusion-based graph convolution network (HFGCN)，通过分层加权融合动态和静态癫痫网络特性，实现更全面的癫痫特征学习和节点信息丰富。在自建数据集（17 名颞叶癫痫患者）上的实验显示，sATAE-HFGCN 方法显著提升了 SOZ 识别性能，提供了高效的解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "eess.SP",
        "q-bio.NC"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.12651v1",
      "published_date": "2024-12-17 08:20:02 UTC",
      "updated_date": "2024-12-17 08:20:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T14:09:31.207896"
    },
    {
      "arxiv_id": "2412.12650v1",
      "title": "Neural-Network-Driven Reward Prediction as a Heuristic: Advancing Q-Learning for Mobile Robot Path Planning",
      "title_zh": "神经网络驱动的奖励预测作为启发式：推进 Q-Learning 用于",
      "authors": [
        "Yiming Ji",
        "Kaijie Yun",
        "Yang Liu",
        "Zongwu Xie",
        "Hong Liu"
      ],
      "abstract": "Q-learning is a widely used reinforcement learning technique for solving path\nplanning problems. It primarily involves the interaction between an agent and\nits environment, enabling the agent to learn an optimal strategy that maximizes\ncumulative rewards. Although many studies have reported the effectiveness of\nQ-learning, it still faces slow convergence issues in practical applications.\nTo address this issue, we propose the NDR-QL method, which utilizes neural\nnetwork outputs as heuristic information to accelerate the convergence process\nof Q-learning. Specifically, we improved the dual-output neural network model\nby introducing a start-end channel separation mechanism and enhancing the\nfeature fusion process. After training, the proposed NDR model can output a\nnarrowly focused optimal probability distribution, referred to as the\nguideline, and a broadly distributed suboptimal distribution, referred to as\nthe region. Subsequently, based on the guideline prediction, we calculate the\ncontinuous reward function for the Q-learning method, and based on the region\nprediction, we initialize the Q-table with a bias. We conducted training,\nvalidation, and path planning simulation experiments on public datasets. The\nresults indicate that the NDR model outperforms previous methods by up to 5\\%\nin prediction accuracy. Furthermore, the proposed NDR-QL method improves the\nconvergence speed of the baseline Q-learning method by 90\\% and also surpasses\nthe previously improved Q-learning methods in path quality metrics.",
      "tldr_zh": "本文提出 NDR-QL 方法，使用神经网络驱动的奖励预测作为启发式信息，以加速 Q-learning 在移动机器人路径规划中的收敛问题。具体而言，该方法改进了双输出神经网络模型，通过引入 start-end channel separation 机制和增强的 feature fusion 过程，输出 narrowly focused optimal probability distribution（guideline）和 broadly distributed suboptimal distribution（region），并据此计算连续奖励函数并初始化 Q-table。实验结果显示，NDR 模型的预测准确率比之前方法提高 5%，而 NDR-QL 方法使 Q-learning 的收敛速度提升 90%，并在路径质量指标上表现出色。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.12650v1",
      "published_date": "2024-12-17 08:19:40 UTC",
      "updated_date": "2024-12-17 08:19:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T14:09:43.753634"
    },
    {
      "arxiv_id": "2412.12649v1",
      "title": "ClustEm4Ano: Clustering Text Embeddings of Nominal Textual Attributes for Microdata Anonymization",
      "title_zh": "翻译失败",
      "authors": [
        "Robert Aufschläger",
        "Sebastian Wilhelm",
        "Michael Heigl",
        "Martin Schramm"
      ],
      "abstract": "This work introduces ClustEm4Ano, an anonymization pipeline that can be used\nfor generalization and suppression-based anonymization of nominal textual\ntabular data. It automatically generates value generalization hierarchies\n(VGHs) that, in turn, can be used to generalize attributes in\nquasi-identifiers. The pipeline leverages embeddings to generate semantically\nclose value generalizations through iterative clustering. We applied KMeans and\nHierarchical Agglomerative Clustering on $13$ different predefined text\nembeddings (both open and closed-source (via APIs)). Our approach is\nexperimentally tested on a well-known benchmark dataset for anonymization: The\nUCI Machine Learning Repository's Adult dataset. ClustEm4Ano supports\nanonymization procedures by offering more possibilities compared to using\narbitrarily chosen VGHs. Experiments demonstrate that these VGHs can outperform\nmanually constructed ones in terms of downstream efficacy (especially for small\n$k$-anonymity ($2 \\leq k \\leq 30$)) and therefore can foster the quality of\nanonymized datasets. Our implementation is made public.",
      "tldr_zh": "这篇论文引入了ClustEm4Ano，一个用于名义文本表格数据的匿名化管道，支持基于泛化和抑制的微数据匿名化。ClustEm4Ano通过在13种预定义文本嵌入上应用KMeans和Hierarchical Agglomerative Clustering进行迭代聚类，自动生成语义相似的值泛化层次(VGHs)，从而提升属性泛化的效率。在UCI Adult数据集上的实验表明，这些自动生成的VGHs在小k-anonymity（2 ≤ k ≤ 30）条件下比手动构建的VGHs在下游效能上表现更优，实现已公开以促进匿名化数据集的质量。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "16 pages, 5 figures, accepted for presentation at IDEAS: 2024 28th\n  International Symposium on Database Engineered Applications, Bayonne, France,\n  August 26-29, 2024",
      "pdf_url": "http://arxiv.org/pdf/2412.12649v1",
      "published_date": "2024-12-17 08:16:04 UTC",
      "updated_date": "2024-12-17 08:16:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T14:09:55.457098"
    },
    {
      "arxiv_id": "2412.12648v1",
      "title": "Exploring AI-Enabled Cybersecurity Frameworks: Deep-Learning Techniques, GPU Support, and Future Enhancements",
      "title_zh": "探索 AI 赋能的网络安全框架：深度学习技术、GPU 支持以及未来增强",
      "authors": [
        "Tobias Becher",
        "Simon Torka"
      ],
      "abstract": "Traditional rule-based cybersecurity systems have proven highly effective\nagainst known malware threats. However, they face challenges in detecting novel\nthreats. To address this issue, emerging cybersecurity systems are\nincorporating AI techniques, specifically deep-learning algorithms, to enhance\ntheir ability to detect incidents, analyze alerts, and respond to events. While\nthese techniques offer a promising approach to combating dynamic security\nthreats, they often require significant computational resources. Therefore,\nframeworks that incorporate AI-based cybersecurity mechanisms need to support\nthe use of GPUs to ensure optimal performance.\n  Many cybersecurity framework vendors do not provide sufficiently detailed\ninformation about their implementation, making it difficult to assess the\ntechniques employed and their effectiveness. This study aims to overcome this\nlimitation by providing an overview of the most used cybersecurity frameworks\nthat utilize AI techniques, specifically focusing on frameworks that provide\ncomprehensive information about their implementation. Our primary objective is\nto identify the deep-learning techniques employed by these frameworks and\nevaluate their support for GPU acceleration. We have identified a total of\n\\emph{two} deep-learning algorithms that are utilized by \\emph{three} out of 38\nselected cybersecurity frameworks. Our findings aim to assist in selecting\nopen-source cybersecurity frameworks for future research and assessing any\ndiscrepancies between deep-learning techniques used in theory and practice.",
      "tldr_zh": "这篇论文探讨了AI启用的网络安全框架，强调了deep-learning算法在检测新型威胁中的作用，以及这些框架对GPU支持的需求，以应对高计算资源要求。研究分析了38个选定的网络安全框架，发现仅有3个框架使用了2种deep-learning算法，并评估了它们的GPU加速实现细节。最终，该研究为选择开源框架进行未来研究提供了指导，并突出了理论与实践在deep-learning应用上的差距。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.DC",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.12648v1",
      "published_date": "2024-12-17 08:14:12 UTC",
      "updated_date": "2024-12-17 08:14:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T14:10:06.688958"
    },
    {
      "arxiv_id": "2412.12642v1",
      "title": "RDPI: A Refine Diffusion Probability Generation Method for Spatiotemporal Data Imputation",
      "title_zh": "翻译失败",
      "authors": [
        "Zijin Liu",
        "Xiang Zhao",
        "You Song"
      ],
      "abstract": "Spatiotemporal data imputation plays a crucial role in various fields such as\ntraffic flow monitoring, air quality assessment, and climate prediction.\nHowever, spatiotemporal data collected by sensors often suffer from temporal\nincompleteness, and the sparse and uneven distribution of sensors leads to\nmissing data in the spatial dimension. Among existing methods, autoregressive\napproaches are prone to error accumulation, while simple conditional diffusion\nmodels fail to adequately capture the spatiotemporal relationships between\nobserved and missing data. To address these issues, we propose a novel\ntwo-stage Refined Diffusion Probability Impuation (RDPI) framework based on an\ninitial network and a conditional diffusion model. In the initial stage,\ndeterministic imputation methods are used to generate preliminary estimates of\nthe missing data. In the refinement stage, residuals are treated as the\ndiffusion target, and observed values are innovatively incorporated into the\nforward process. This results in a conditional diffusion model better suited\nfor spatiotemporal data imputation, bridging the gap between the preliminary\nestimates and the true values. Experiments on multiple datasets demonstrate\nthat RDPI not only achieves state-of-the-art imputation accuracy but also\nsignificantly reduces sampling computational costs.",
      "tldr_zh": "该论文提出 RDPI（Refine Diffusion Probability Generation Method），一种用于时空数据插值（spatiotemporal data imputation）的创新框架，以解决现有方法的错误积累和时空关系捕捉不足问题。RDPI 采用两阶段方法：首先，使用确定性插值技术生成初步缺失数据估计；其次，将残差作为扩散目标，并将观测值融入前向过程，形成一个更有效的条件扩散模型，从而桥接初步估计与真实值。实验结果显示，RDPI 在多个数据集上实现了最先进的插值准确性，同时显著降低了采样计算成本。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.12642v1",
      "published_date": "2024-12-17 08:06:00 UTC",
      "updated_date": "2024-12-17 08:06:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T14:10:18.752725"
    },
    {
      "arxiv_id": "2412.15270v2",
      "title": "Baichuan4-Finance Technical Report",
      "title_zh": "Baichuan4-Finance 技术报告",
      "authors": [
        "Hanyu Zhang",
        "Boyu Qiu",
        "Yuhao Feng",
        "Shuqi Li",
        "Qian Ma",
        "Xiyuan Zhang",
        "Qiang Ju",
        "Dong Yan",
        "Jian Xie"
      ],
      "abstract": "Large language models (LLMs) have demonstrated strong capabilities in\nlanguage understanding, generation, and reasoning, yet their potential in\nfinance remains underexplored due to the complexity and specialization of\nfinancial knowledge. In this work, we report the development of the\nBaichuan4-Finance series, including a comprehensive suite of foundational\nBaichuan4-Finance-Base and an aligned language model Baichuan4-Finance, which\nare built upon Baichuan4-Turbo base model and tailored for finance domain.\nFirstly, we have dedicated significant effort to building a detailed pipeline\nfor improving data quality. Moreover, in the continual pre-training phase, we\npropose a novel domain self-constraint training strategy, which enables\nBaichuan4-Finance-Base to acquire financial knowledge without losing general\ncapabilities. After Supervised Fine-tuning and Reinforcement Learning from\nHuman Feedback and AI Feedback, the chat model Baichuan4-Finance is able to\ntackle various financial certification questions and real-world scenario\napplications. We evaluate Baichuan4-Finance on many widely used general\ndatasets and two holistic financial benchmarks. The evaluation results show\nthat Baichuan4-Finance-Base surpasses almost all competitive baselines on\nfinancial tasks by significant margins without sacrificing performance on\ngeneral LLM benchmarks. At the same time, Baichuan4-Finance demonstrates even\nmore impressive performance on financial application scenarios, showcasing its\npotential to foster community innovation in the financial LLM field.",
      "tldr_zh": "本研究报告介绍了 Baichuan4-Finance 系列模型，包括基础模型 Baichuan4-Finance-Base 和对话模型 Baichuan4-Finance，这些模型基于 Baichuan4-Turbo 构建，并针对金融领域进行优化。研究团队开发了数据质量改进管道和新型领域自约束训练策略，在持续预训练阶段帮助模型获得金融知识的同时保留一般能力；随后通过 Supervised Fine-tuning 和 Reinforcement Learning from Human Feedback and AI Feedback，进一步提升了模型处理金融认证问题和真实场景的能力。在评估中，Baichuan4-Finance-Base 在金融任务上大幅超越竞争对手，同时在通用 LLM 基准上保持性能，而 Baichuan4-Finance 在实际应用场景中表现出色，有望推动金融 LLM 领域的创新。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CE",
        "cs.CY",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.15270v2",
      "published_date": "2024-12-17 08:05:32 UTC",
      "updated_date": "2025-01-02 11:21:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T14:10:31.012783"
    },
    {
      "arxiv_id": "2412.15269v1",
      "title": "The Reliability Paradox: Exploring How Shortcut Learning Undermines Language Model Calibration",
      "title_zh": "翻译失败",
      "authors": [
        "Geetanjali Bihani",
        "Julia Rayz"
      ],
      "abstract": "The advent of pre-trained language models (PLMs) has enabled significant\nperformance gains in the field of natural language processing. However, recent\nstudies have found PLMs to suffer from miscalibration, indicating a lack of\naccuracy in the confidence estimates provided by these models. Current\nevaluation methods for PLM calibration often assume that lower calibration\nerror estimates indicate more reliable predictions. However, fine-tuned PLMs\noften resort to shortcuts, leading to overconfident predictions that create the\nillusion of enhanced performance but lack generalizability in their decision\nrules. The relationship between PLM reliability, as measured by calibration\nerror, and shortcut learning, has not been thoroughly explored thus far. This\npaper aims to investigate this relationship, studying whether lower calibration\nerror implies reliable decision rules for a language model. Our findings reveal\nthat models with seemingly superior calibration portray higher levels of\nnon-generalizable decision rules. This challenges the prevailing notion that\nwell-calibrated models are inherently reliable. Our study highlights the need\nto bridge the current gap between language model calibration and generalization\nobjectives, urging the development of comprehensive frameworks to achieve truly\nrobust and reliable language models.",
      "tldr_zh": "本研究探讨了“可靠性悖论”，即预训练语言模型 (PLMs) 通过捷径学习(shortcut learning)导致的校准错误(calibration error)，使得模型预测过于自信却缺乏泛化性。论文发现，尽管较低的校准错误通常被视为更可靠的指标，但实际情况下，校准表现良好的PLMs往往依赖非通用化决策规则，从而削弱了其可靠性。研究结果挑战了现有观点，强调需要弥合语言模型校准和泛化目标之间的差距。最终，该工作呼吁开发更全面的框架，以构建真正稳健且可靠的语言模型。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "10 pages; 9 figures. Accepted for publication at the Hawaii\n  International Conference on System Sciences (HICSS-58) 2025",
      "pdf_url": "http://arxiv.org/pdf/2412.15269v1",
      "published_date": "2024-12-17 08:04:28 UTC",
      "updated_date": "2024-12-17 08:04:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T14:10:43.424944"
    },
    {
      "arxiv_id": "2412.12641v1",
      "title": "Lagrangian Index Policy for Restless Bandits with Average Reward",
      "title_zh": "翻译失败",
      "authors": [
        "Konstantin Avrachenkov",
        "Vivek S. Borkar",
        "Pratik Shah"
      ],
      "abstract": "We study the Lagrangian Index Policy (LIP) for restless multi-armed bandits\nwith long-run average reward. In particular, we compare the performance of LIP\nwith the performance of the Whittle Index Policy (WIP), both heuristic policies\nknown to be asymptotically optimal under certain natural conditions. Even\nthough in most cases their performances are very similar, in the cases when WIP\nshows bad performance, LIP continues to perform very well. We then propose\nreinforcement learning algorithms, both tabular and NN-based, to obtain online\nlearning schemes for LIP in the model-free setting. The proposed reinforcement\nlearning schemes for LIP requires significantly less memory than the analogous\nscheme for WIP. We calculate analytically the Lagrangian index for the restart\nmodel, which describes the optimal web crawling and the minimization of the\nweighted age of information. We also give a new proof of asymptotic optimality\nin case of homogeneous bandits as the number of arms goes to infinity, based on\nexchangeability and de Finetti's theorem.",
      "tldr_zh": "这篇论文研究了Lagrangian Index Policy (LIP) 在 restless multi-armed bandits 中的应用，专注于长期平均奖励，并将其与 Whittle Index Policy (WIP) 进行比较。结果显示，虽然二者在多数情况下表现相似，但 LIP 在 WIP 性能不佳时仍能保持出色表现。作者提出了基于强化学习的在线学习算法，包括 tabular 和 NN-based 方法，这些方案在无模型设置下比 WIP 的对应方案需要更少的内存。此外，他们为 restart model 计算了解析的 Lagrangian index，并基于 exchangeability 和 de Finetti's theorem 为同质 bandits 提供了新的渐近最优证明。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "math.OC",
        "math.PR"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.12641v1",
      "published_date": "2024-12-17 08:03:53 UTC",
      "updated_date": "2024-12-17 08:03:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T14:10:56.103033"
    },
    {
      "arxiv_id": "2412.12639v3",
      "title": "Falcon: Faster and Parallel Inference of Large Language Models through Enhanced Semi-Autoregressive Drafting and Custom-Designed Decoding Tree",
      "title_zh": "翻译失败",
      "authors": [
        "Xiangxiang Gao",
        "Weisheng Xie",
        "Yiwei Xiang",
        "Feng Ji"
      ],
      "abstract": "Striking an optimal balance between minimal drafting latency and high\nspeculation accuracy to enhance the inference speed of Large Language Models\nremains a significant challenge in speculative decoding. In this paper, we\nintroduce Falcon, an innovative semi-autoregressive speculative decoding\nframework fashioned to augment both the drafter's parallelism and output\nquality. Falcon incorporates the Coupled Sequential Glancing Distillation\ntechnique, which fortifies inter-token dependencies within the same block,\nleading to increased speculation accuracy. We offer a comprehensive theoretical\nanalysis to illuminate the underlying mechanisms. Additionally, we introduce a\nCustom-Designed Decoding Tree, which permits the drafter to generate multiple\ntokens in a single forward pass and accommodates multiple forward passes as\nneeded, thereby boosting the number of drafted tokens and significantly\nimproving the overall acceptance rate. Comprehensive evaluations on benchmark\ndatasets such as MT-Bench, HumanEval, and GSM8K demonstrate Falcon's superior\nacceleration capabilities. The framework achieves a lossless speedup ratio\nranging from 2.91x to 3.51x when tested on the Vicuna and LLaMA2-Chat model\nseries. These results outstrip existing speculative decoding methods for LLMs,\nincluding Eagle, Medusa, Lookahead, SPS, and PLD, while maintaining a compact\ndrafter architecture equivalent to merely two Transformer layers.",
      "tldr_zh": "本研究提出Falcon，一种增强型半自回归推测解码框架，旨在优化大语言模型(Large Language Models)的推理速度，通过平衡推测延迟和准确性来实现更快并行处理。Falcon 引入Coupled Sequential Glancing Distillation技术来加强块内token的依赖关系，提高推测准确性，并采用Custom-Designed Decoding Tree允许drafter在单次前向传递中生成多个token，从而显著提升草稿token数量和整体接受率。实验在MT-Bench、HumanEval和GSM8K数据集上显示，Falcon在Vicuna和LLaMA2-Chat模型系列上实现了2.91x至3.51x的无损加速，比现有方法如Eagle、Medusa等更优，同时保持紧凑的drafter架构，仅相当于两个Transformer层。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "AAAI 2025 Accepted",
      "pdf_url": "http://arxiv.org/pdf/2412.12639v3",
      "published_date": "2024-12-17 08:02:08 UTC",
      "updated_date": "2025-04-22 07:32:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T14:11:07.447527"
    },
    {
      "arxiv_id": "2412.12636v2",
      "title": "TrainMover: An Interruption-Resilient and Reliable ML Training Runtime",
      "title_zh": "翻译失败",
      "authors": [
        "ChonLam Lao",
        "Minlan Yu",
        "Aditya Akella",
        "Jiamin Cao",
        "Yu Guan",
        "Pengcheng Zhang",
        "Zhilong Zheng",
        "Yichi Xu",
        "Ennan Zhai",
        "Dennis Cai",
        "Jiaqi Gao"
      ],
      "abstract": "Large-scale ML training jobs are frequently interrupted by hardware and\nsoftware anomalies, failures, and management events. Existing solutions like\ncheckpointing or runtime reconfiguration suffer from long downtimes, degraded\nperformance, or undesired changes to training strategies. We present\nTrainMover, a resilient runtime that leverages standby machines to handle\ninterruptions with minimal downtime and zero memory overhead. To achieve these\ngoals, TrainMover introduces two key techniques: two-phase, delta-based\ncommunication group setups and communication-free sandboxed shadow iterations.\nOur evaluation shows that TrainMover consistently achieves second-level\ndowntime across all evaluated models during migration, maintaining 99\\%\ntraining efficiency during periodic 10-minute rebalancing. We also demonstrate\nthe effectiveness of TrainMover in handling various interruptions.",
      "tldr_zh": "该论文针对大规模 ML 训练作业因硬件、软件异常和故障而频繁中断的问题，提出了 TrainMover，一种抗中断且可靠的运行时系统，利用备用机器实现最小停机时间和零内存开销。TrainMover 引入了两阶段的基于增量（two-phase, delta-based communication group setups）和无通信的沙箱化影子迭代（communication-free sandboxed shadow iterations）等关键技术，以无缝处理中断。实验结果显示，TrainMover 在迁移过程中保持秒级停机时间，并维持 99% 的训练效率，同时在各种中断场景中表现出色。",
      "categories": [
        "cs.DC",
        "cs.AI",
        "cs.LG",
        "cs.PF"
      ],
      "primary_category": "cs.DC",
      "comment": "13 pages body, 17 pages total",
      "pdf_url": "http://arxiv.org/pdf/2412.12636v2",
      "published_date": "2024-12-17 07:59:31 UTC",
      "updated_date": "2025-04-26 13:44:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T14:11:19.441136"
    },
    {
      "arxiv_id": "2412.12632v2",
      "title": "What External Knowledge is Preferred by LLMs? Characterizing and Exploring Chain of Evidence in Imperfect Context",
      "title_zh": "翻译失败",
      "authors": [
        "Zhiyuan Chang",
        "Mingyang Li",
        "Xiaojun Jia",
        "Junjie Wang",
        "Yuekai Huang",
        "Qing Wang",
        "Yihao Huang",
        "Yang Liu"
      ],
      "abstract": "Incorporating external knowledge into large language models (LLMs) has\nemerged as a promising approach to mitigate outdated knowledge and\nhallucination in LLMs. However, external knowledge is often imperfect. In\naddition to useful knowledge, external knowledge is rich in irrelevant or\nmisinformation in the context that can impair the reliability of LLM responses.\nThis paper focuses on LLMs' preferred external knowledge in imperfect contexts\nwhen handling multi-hop QA. Inspired by criminal procedural law's Chain of\nEvidence (CoE), we characterize that knowledge preferred by LLMs should\nmaintain both relevance to the question and mutual support among knowledge\npieces. Accordingly, we propose an automated CoE discrimination approach and\nevaluate LLMs' effectiveness, faithfulness and robustness with CoE, including\nits application in the Retrieval-Augmented Generation (RAG). Tests on five LLMs\nshow CoE improves generation accuracy, answer faithfulness, robustness to\nknowledge conflicts, and boosts the performance of existing approaches in three\npractical RAG scenarios.",
      "tldr_zh": "本研究探讨了在处理多跳问答(multi-hop QA)时，大型语言模型(LLMs)对不完美外部知识的偏好，强调外部知识应具备与问题相关性及知识片段间的相互支持，类似于刑事程序法的Chain of Evidence (CoE)。作者提出了一种自动化CoE鉴别方法，用于评估和提升LLMs的有效性、忠实度和稳健性，包括在Retrieval-Augmented Generation (RAG)中的应用。实验结果显示，该方法在五个LLMs上显著提高了生成准确性、答案忠实度、对知识冲突的稳健性，并优化了现有RAG场景的表现。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "15 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2412.12632v2",
      "published_date": "2024-12-17 07:49:49 UTC",
      "updated_date": "2025-05-16 01:49:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T14:11:31.092840"
    },
    {
      "arxiv_id": "2412.12629v1",
      "title": "a2z-1 for Multi-Disease Detection in Abdomen-Pelvis CT: External Validation and Performance Analysis Across 21 Conditions",
      "title_zh": "翻译失败",
      "authors": [
        "Pranav Rajpurkar",
        "Julian N. Acosta",
        "Siddhant Dogra",
        "Jaehwan Jeong",
        "Deepanshu Jindal",
        "Michael Moritz",
        "Samir Rajpurkar"
      ],
      "abstract": "We present a comprehensive evaluation of a2z-1, an artificial intelligence\n(AI) model designed to analyze abdomen-pelvis CT scans for 21 time-sensitive\nand actionable findings. Our study focuses on rigorous assessment of the\nmodel's performance and generalizability. Large-scale retrospective analysis\ndemonstrates an average AUC of 0.931 across 21 conditions. External validation\nacross two distinct health systems confirms consistent performance (AUC 0.923),\nestablishing generalizability to different evaluation scenarios, with notable\nperformance in critical findings such as small bowel obstruction (AUC 0.958)\nand acute pancreatitis (AUC 0.961). Subgroup analysis shows consistent accuracy\nacross patient sex, age groups, and varied imaging protocols, including\ndifferent slice thicknesses and contrast administration types. Comparison of\nhigh-confidence model outputs to radiologist reports reveals instances where\na2z-1 identified overlooked findings, suggesting potential for quality\nassurance applications.",
      "tldr_zh": "本研究评估了a2z-1 AI模型在检测腹部-骨盆CT扫描中的21种紧急发现方面的性能，通过大规模回顾性分析，模型平均AUC达到0.931，并在小肠梗阻（AUC 0.958）和急性胰腺炎（AUC 0.961）等关键条件下表现出色。外部验证在两个不同医疗系统中显示一致性（AUC 0.923），子组分析证实模型在患者性别、年龄组和各种成像协议（如切片厚度及对比剂类型）上均保持准确性。相比放射科医生报告，a2z-1能识别被忽略的发现，表明其在质量控制和临床应用中的潜在价值。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.12629v1",
      "published_date": "2024-12-17 07:44:25 UTC",
      "updated_date": "2024-12-17 07:44:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T14:11:42.537038"
    },
    {
      "arxiv_id": "2412.12619v1",
      "title": "Phoneme-Level Feature Discrepancies: A Key to Detecting Sophisticated Speech Deepfakes",
      "title_zh": "音素级特征差异：检测复杂语音深度伪造的关键",
      "authors": [
        "Kuiyuan Zhang",
        "Zhongyun Hua",
        "Rushi Lan",
        "Yushu Zhang",
        "Yifang Guo"
      ],
      "abstract": "Recent advancements in text-to-speech and speech conversion technologies have\nenabled the creation of highly convincing synthetic speech. While these\ninnovations offer numerous practical benefits, they also cause significant\nsecurity challenges when maliciously misused. Therefore, there is an urgent\nneed to detect these synthetic speech signals. Phoneme features provide a\npowerful speech representation for deepfake detection. However, previous\nphoneme-based detection approaches typically focused on specific phonemes,\noverlooking temporal inconsistencies across the entire phoneme sequence. In\nthis paper, we develop a new mechanism for detecting speech deepfakes by\nidentifying the inconsistencies of phoneme-level speech features. We design an\nadaptive phoneme pooling technique that extracts sample-specific phoneme-level\nfeatures from frame-level speech data. By applying this technique to features\nextracted by pre-trained audio models on previously unseen deepfake datasets,\nwe demonstrate that deepfake samples often exhibit phoneme-level\ninconsistencies when compared to genuine speech. To further enhance detection\naccuracy, we propose a deepfake detector that uses a graph attention network to\nmodel the temporal dependencies of phoneme-level features. Additionally, we\nintroduce a random phoneme substitution augmentation technique to increase\nfeature diversity during training. Extensive experiments on four benchmark\ndatasets demonstrate the superior performance of our method over existing\nstate-of-the-art detection methods.",
      "tldr_zh": "本文提出了一种通过识别元音级（phoneme-level）特征不一致性来检测高级语音深度伪造（speech deepfakes）的新机制，以解决现有方法的局限性。研究设计了自适应元音池化技术（adaptive phoneme pooling technique）从帧级语音数据中提取样本特定特征，并使用图注意力网络（graph attention network）建模这些特征的时序依赖，同时引入随机元音替换增强（random phoneme substitution augmentation）来提升训练多样性。实验结果显示，该方法在四个基准数据集上显著优于现有最先进检测方法，证明了元音级不一致性在深度伪造检测中的关键作用。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.12619v1",
      "published_date": "2024-12-17 07:31:19 UTC",
      "updated_date": "2024-12-17 07:31:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T14:11:56.403845"
    },
    {
      "arxiv_id": "2412.12612v2",
      "title": "Auto-Cypher: Improving LLMs on Cypher generation via LLM-supervised generation-verification framework",
      "title_zh": "翻译失败",
      "authors": [
        "Aman Tiwari",
        "Shiva Krishna Reddy Malay",
        "Vikas Yadav",
        "Masoud Hashemi",
        "Sathwik Tejaswi Madhusudhan"
      ],
      "abstract": "Graph databases like Neo4j are gaining popularity for handling complex,\ninterconnected data, over traditional relational databases in modeling and\nquerying relationships. While translating natural language into SQL queries is\nwell-researched, generating Cypher queries for Neo4j remains relatively\nunderexplored. In this work, we present an automated, LLM-Supervised, pipeline\nto generate high-quality synthetic data for Text2Cypher. Our Cypher data\ngeneration pipeline introduces LLM-As-Database-Filler, a novel strategy for\nensuring Cypher query correctness, thus resulting in high quality generations.\nUsing our pipeline, we generate high quality Text2Cypher data - SynthCypher\ncontaining 29.8k instances across various domains and queries with varying\ncomplexities. Training open-source LLMs like LLaMa-3.1-8B, Mistral-7B, and\nQWEN-7B on SynthCypher results in performance gains of up to 40% on the\nText2Cypher test split and 30% on the SPIDER benchmark, adapted for graph\ndatabases.",
      "tldr_zh": "本文提出 Auto-Cypher，一种基于 LLM-Supervised 的生成-验证框架，用于提升大型语言模型(LLMs)在 Cypher 查询生成方面的性能。该框架引入 LLM-As-Database-Filler 策略，确保查询正确性，并自动生成高质量的 SynthCypher 数据集，包含 29.8k 实例，覆盖各种领域和复杂查询。在 SynthCypher 上训练开源 LLMs 如 LLaMa-3.1-8B 和 Mistral-7B，结果显示在 Text2Cypher 测试集上性能提升高达 40%，在适应图数据库的 SPIDER 基准上提升 30%。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted at NAACL 2025 main conference",
      "pdf_url": "http://arxiv.org/pdf/2412.12612v2",
      "published_date": "2024-12-17 07:21:25 UTC",
      "updated_date": "2025-01-24 05:52:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T14:12:09.363723"
    },
    {
      "arxiv_id": "2412.12606v1",
      "title": "Multi-Dimensional Insights: Benchmarking Real-World Personalization in Large Multimodal Models",
      "title_zh": "翻译失败",
      "authors": [
        "YiFan Zhang",
        "Shanglin Lei",
        "Runqi Qiao",
        "Zhuoma GongQue",
        "Xiaoshuai Song",
        "Guanting Dong",
        "Qiuna Tan",
        "Zhe Wei",
        "Peiqing Yang",
        "Ye Tian",
        "Yadong Xue",
        "Xiaofei Wang",
        "Honggang Zhang"
      ],
      "abstract": "The rapidly developing field of large multimodal models (LMMs) has led to the\nemergence of diverse models with remarkable capabilities. However, existing\nbenchmarks fail to comprehensively, objectively and accurately evaluate whether\nLMMs align with the diverse needs of humans in real-world scenarios. To bridge\nthis gap, we propose the Multi-Dimensional Insights (MDI) benchmark, which\nincludes over 500 images covering six common scenarios of human life. Notably,\nthe MDI-Benchmark offers two significant advantages over existing evaluations:\n(1) Each image is accompanied by two types of questions: simple questions to\nassess the model's understanding of the image, and complex questions to\nevaluate the model's ability to analyze and reason beyond basic content. (2)\nRecognizing that people of different age groups have varying needs and\nperspectives when faced with the same scenario, our benchmark stratifies\nquestions into three age categories: young people, middle-aged people, and\nolder people. This design allows for a detailed assessment of LMMs'\ncapabilities in meeting the preferences and needs of different age groups. With\nMDI-Benchmark, the strong model like GPT-4o achieve 79% accuracy on age-related\ntasks, indicating that existing LMMs still have considerable room for\nimprovement in addressing real-world applications. Looking ahead, we anticipate\nthat the MDI-Benchmark will open new pathways for aligning real-world\npersonalization in LMMs. The MDI-Benchmark data and evaluation code are\navailable at https://mdi-benchmark.github.io/",
      "tldr_zh": "本研究提出 Multi-Dimensional Insights (MDI) benchmark，用于全面评估 Large Multimodal Models (LMMs) 在真实场景中满足人类多样化需求的能力，弥补现有基准的不足。MDI 基准包含超过 500 张图像，覆盖六种常见生活场景，每个图像配有简单问题（评估图像理解）和复杂问题（评估分析与推理能力），并按年轻人、中年人和老年人三个年龄组分层，以测试模型对不同群体偏好的适应性。实验结果显示，强模型如 GPT-4o 在年龄相关任务上达到 79% 准确率，但整体表明现有 LMMs 在真实世界应用中仍有显著改进空间。该基准的数据和评估代码已公开，有望推动 LMMs 的个性化发展。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.CV"
      ],
      "primary_category": "cs.AI",
      "comment": "33 pages, 33 figures, Work in progress",
      "pdf_url": "http://arxiv.org/pdf/2412.12606v1",
      "published_date": "2024-12-17 07:06:10 UTC",
      "updated_date": "2024-12-17 07:06:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T14:12:20.825892"
    },
    {
      "arxiv_id": "2412.12605v1",
      "title": "An Advantage-based Optimization Method for Reinforcement Learning in Large Action Space",
      "title_zh": "翻译失败",
      "authors": [
        "Hai Lin",
        "Cheng Huang",
        "Zhihong Chen"
      ],
      "abstract": "Reinforcement learning tasks in real-world scenarios often involve large,\nhigh-dimensional action spaces, leading to challenges such as convergence\ndifficulties, instability, and high computational complexity. It is widely\nacknowledged that traditional value-based reinforcement learning algorithms\nstruggle to address these issues effectively. A prevalent approach involves\ngenerating independent sub-actions within each dimension of the action space.\nHowever, this method introduces bias, hindering the learning of optimal\npolicies. In this paper, we propose an advantage-based optimization method and\nan algorithm named Advantage Branching Dueling Q-network (ABQ). ABQ\nincorporates a baseline mechanism to tune the action value of each dimension,\nleveraging the advantage relationship across different sub-actions. With this\napproach, the learned policy can be optimized for each dimension. Empirical\nresults demonstrate that ABQ outperforms BDQ, achieving 3%, 171%, and 84% more\ncumulative rewards in HalfCheetah, Ant, and Humanoid environments,\nrespectively. Furthermore, ABQ exhibits competitive performance when compared\nagainst two continuous action benchmark algorithms, DDPG and TD3.",
      "tldr_zh": "本论文针对强化学习(Reinforcement Learning)中大型、高维动作空间的挑战，如收敛困难和计算复杂度高，提出了一种基于优势优化的方法和算法Advantage Branching Dueling Q-network (ABQ)。ABQ通过引入基线机制调整每个维度的动作值，利用子动作间的优势关系来优化策略，避免传统方法的偏差。实验结果显示，ABQ在HalfCheetah、Ant和Humanoid环境中分别比BDQ提升3%、171%和84%的累积奖励，并在与DDPG和TD3的比较中表现出竞争性性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.12605v1",
      "published_date": "2024-12-17 07:04:39 UTC",
      "updated_date": "2024-12-17 07:04:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T14:12:30.996122"
    },
    {
      "arxiv_id": "2412.12587v1",
      "title": "Distributed satellite information networks: Architecture, enabling technologies, and trends",
      "title_zh": "分布式卫星信息网络：架构、使能技术和发展趋势",
      "authors": [
        "Qinyu Zhang",
        "Liang Xu",
        "Jianhao Huang",
        "Tao Yang",
        "Jian Jiao",
        "Ye Wang",
        "Yao Shi",
        "Chiya Zhang",
        "Xingjian Zhang",
        "Ke Zhang",
        "Yupeng Gong",
        "Na Deng",
        "Nan Zhao",
        "Zhen Gao",
        "Shujun Han",
        "Xiaodong Xu",
        "Li You",
        "Dongming Wang",
        "Shan Jiang",
        "Dixian Zhao",
        "Nan Zhang",
        "Liujun Hu",
        "Xiongwen He",
        "Yonghui Li",
        "Xiqi Gao",
        "Xiaohu You"
      ],
      "abstract": "Driven by the vision of ubiquitous connectivity and wireless intelligence,\nthe evolution of ultra-dense constellation-based satellite-integrated Internet\nis underway, now taking preliminary shape. Nevertheless, the entrenched\ninstitutional silos and limited, nonrenewable heterogeneous network resources\nleave current satellite systems struggling to accommodate the escalating\ndemands of next-generation intelligent applications. In this context, the\ndistributed satellite information networks (DSIN), exemplified by the cohesive\nclustered satellites system, have emerged as an innovative architecture,\nbridging information gaps across diverse satellite systems, such as\ncommunication, navigation, and remote sensing, and establishing a unified, open\ninformation network paradigm to support resilient space information services.\nThis survey first provides a profound discussion about innovative network\narchitectures of DSIN, encompassing distributed regenerative satellite network\narchitecture, distributed satellite computing network architecture, and\nreconfigurable satellite formation flying, to enable flexible and scalable\ncommunication, computing and control. The DSIN faces challenges from network\nheterogeneity, unpredictable channel dynamics, sparse resources, and\ndecentralized collaboration frameworks. To address these issues, a series of\nenabling technologies is identified, including channel modeling and estimation,\ncloud-native distributed MIMO cooperation, grant-free massive access, network\nrouting, and the proper combination of all these diversity techniques.\nFurthermore, to heighten the overall resource efficiency, the cross-layer\noptimization techniques are further developed to meet upper-layer\ndeterministic, adaptive and secure information services requirements. In\naddition, emerging research directions and new opportunities are highlighted on\nthe way to achieving the DSIN vision.",
      "tldr_zh": "这篇论文探讨了分布式卫星信息网络 (DSIN) 的创新架构和技术趋势，旨在桥接通信、导航和遥感等卫星系统的信息鸿沟，形成一个统一的开放网络以支持弹性空间信息服务。论文详细讨论了 DSIN 的关键架构，包括分布式再生卫星网络架构、分布式卫星计算网络架构和可重构卫星编队飞行，以实现灵活、可扩展的通信、计算和控制。针对网络异构性、通道动态和资源稀缺等挑战，它提出了启用技术如通道建模、云原生分布式 MIMO 合作、无授权海量接入和网络路由，并通过跨层优化提升资源效率以满足确定性、适应性和安全的信息服务需求。最后，论文突出了 DSIN 的新兴研究方向和机遇，促进卫星网络的演进。",
      "categories": [
        "cs.IT",
        "cs.AI",
        "cs.NI",
        "math.IT"
      ],
      "primary_category": "cs.IT",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.12587v1",
      "published_date": "2024-12-17 06:44:05 UTC",
      "updated_date": "2024-12-17 06:44:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T14:12:43.575742"
    },
    {
      "arxiv_id": "2412.15268v2",
      "title": "Enhancing LLM-based Hatred and Toxicity Detection with Meta-Toxic Knowledge Graph",
      "title_zh": "使用元毒性知识图谱增强基于大型语言模型的仇恨和毒性检测",
      "authors": [
        "Yibo Zhao",
        "Jiapeng Zhu",
        "Can Xu",
        "Xiang Li"
      ],
      "abstract": "The rapid growth of social media platforms has raised significant concerns\nregarding online content toxicity. When Large Language Models (LLMs) are used\nfor toxicity detection, two key challenges emerge: 1) the absence of\ndomain-specific toxic knowledge leads to false negatives; 2) the excessive\nsensitivity of LLMs to toxic speech results in false positives, limiting\nfreedom of speech. To address these issues, we propose a novel method called\nMetaTox, leveraging graph search on a meta-toxic knowledge graph to enhance\nhatred and toxicity detection. First, we construct a comprehensive meta-toxic\nknowledge graph by utilizing LLMs to extract toxic information through a\nthree-step pipeline, with toxic benchmark datasets serving as corpora. Second,\nwe query the graph via retrieval and ranking processes to supplement accurate,\nrelevant toxic knowledge. Extensive experiments and in-depth case studies\nacross multiple datasets demonstrate that our MetaTox significantly decreases\nthe false positive rate while boosting overall toxicity detection performance.\nOur code will be available soon.",
      "tldr_zh": "这篇论文针对Large Language Models (LLMs)在仇恨和毒性检测中的挑战，提出MetaTox方法，利用meta-toxic knowledge graph来解决假阴性（缺少领域特定知识）和假阳性（过度敏感导致言论自由限制）问题。首先，通过三步管道利用LLMs从毒性基准数据集提取信息构建全面的meta-toxic knowledge graph；其次，通过检索和排名过程查询图谱，提供准确的相关毒性知识。实验结果显示，MetaTox在多个数据集上显著降低了假阳性率，并提升了整体检测性能。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "8 pages of content",
      "pdf_url": "http://arxiv.org/pdf/2412.15268v2",
      "published_date": "2024-12-17 06:28:28 UTC",
      "updated_date": "2024-12-24 04:38:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T14:12:55.068572"
    },
    {
      "arxiv_id": "2412.12575v1",
      "title": "SIDE: Socially Informed Drought Estimation Toward Understanding Societal Impact Dynamics of Environmental Crisis",
      "title_zh": "SIDE：基于社会信息的干旱估计，旨在理解环境危机的社会影响动态",
      "authors": [
        "Lanyu Shang",
        "Bozhang Chen",
        "Shiwei Liu",
        "Yang Zhang",
        "Ruohan Zong",
        "Anav Vora",
        "Ximing Cai",
        "Na Wei",
        "Dong Wang"
      ],
      "abstract": "Drought has become a critical global threat with significant societal impact.\nExisting drought monitoring solutions primarily focus on assessing drought\nseverity using quantitative measurements, overlooking the diverse societal\nimpact of drought from human-centric perspectives. Motivated by the collective\nintelligence on social media and the computational power of AI, this paper\nstudies a novel problem of socially informed AI-driven drought estimation that\naims to leverage social and news media information to jointly estimate drought\nseverity and its societal impact. Two technical challenges exist: 1) How to\nmodel the implicit temporal dynamics of drought societal impact. 2) How to\ncapture the social-physical interdependence between the physical drought\ncondition and its societal impact. To address these challenges, we develop\nSIDE, a socially informed AI-driven drought estimation framework that\nexplicitly quantifies the societal impact of drought and effectively models the\nsocial-physical interdependency for joint severity-impact estimation.\nExperiments on real-world datasets from California and Texas demonstrate SIDE's\nsuperior performance compared to state-of-the-art baselines in accurately\nestimating drought severity and its societal impact. SIDE offers valuable\ninsights for developing human-centric drought mitigation strategies to foster\nsustainable and resilient communities.",
      "tldr_zh": "该研究针对干旱作为全球性威胁的背景下，指出现有监测方法仅关注量化严重程度，而忽略了从人文视角的社会影响。论文提出SIDE框架，这是一种基于社交媒体和AI的创新方法，通过建模干旱社会影响的隐含时间动态（temporal dynamics）和社会-物理相互依赖性（social-physical interdependence），实现干旱严重程度及其社会影响的联合估计。在加州和德克萨斯真实数据集上的实验显示，SIDE比现有基准模型更准确，提供宝贵的洞见，以支持制定以人为本的干旱缓解策略，促进可持续社区发展。",
      "categories": [
        "cs.SI",
        "cs.AI"
      ],
      "primary_category": "cs.SI",
      "comment": "To be published in AAAI 25",
      "pdf_url": "http://arxiv.org/pdf/2412.12575v1",
      "published_date": "2024-12-17 06:11:46 UTC",
      "updated_date": "2024-12-17 06:11:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T14:13:06.867661"
    },
    {
      "arxiv_id": "2412.12572v1",
      "title": "License Plate Detection and Character Recognition Using Deep Learning and Font Evaluation",
      "title_zh": "使用深度学习和字体评估的车牌检测与字符识别",
      "authors": [
        "Zahra Ebrahimi Vargoorani",
        "Ching Yee Suen"
      ],
      "abstract": "License plate detection (LPD) is essential for traffic management, vehicle\ntracking, and law enforcement but faces challenges like variable lighting and\ndiverse font types, impacting accuracy. Traditionally reliant on image\nprocessing and machine learning, the field is now shifting towards deep\nlearning for its robust performance in various conditions. Current methods,\nhowever, often require tailoring to specific regional datasets. This paper\nproposes a dual deep learning strategy using a Faster R-CNN for detection and a\nCNN-RNN model with Connectionist Temporal Classification (CTC) loss and a\nMobileNet V3 backbone for recognition. This approach aims to improve model\nperformance using datasets from Ontario, Quebec, California, and New York\nState, achieving a recall rate of 92% on the Centre for Pattern Recognition and\nMachine Intelligence (CENPARMI) dataset and 90% on the UFPR-ALPR dataset. It\nincludes a detailed error analysis to identify the causes of false positives.\nAdditionally, the research examines the role of font features in license plate\n(LP) recognition, analyzing fonts like Driver Gothic, Dreadnought, California\nClarendon, and Zurich Extra Condensed with the OpenALPR system. It discovers\nsignificant performance discrepancies influenced by font characteristics,\noffering insights for future LPD system enhancements.\n  Keywords: Deep Learning, License Plate, Font Evaluation",
      "tldr_zh": "这篇论文提出了一种使用深度学习的车牌检测（LPD）和字符识别方法，采用 Faster R-CNN 进行检测，以及 CNN-RNN 模型（结合 Connectionist Temporal Classification (CTC) loss 和 MobileNet V3 backbone）进行识别，以应对可变照明和多样字体带来的挑战。实验在 Ontario、Quebec、California 和 New York State 的数据集上进行，实现了 CENPARMI 数据集 92% 的召回率和 UFPR-ALPR 数据集 90% 的召回率，并通过错误分析识别了假阳性的原因。此外，研究评估了不同字体（如 Driver Gothic、Dreadnought、California Clarendon 和 Zurich Extra Condensed）对识别性能的影响，使用 OpenALPR 系统发现字体特性导致的性能差异，为未来 LPD 系统优化提供了见解。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "68T10",
        "I.2.10; I.4.8; I.5.4"
      ],
      "primary_category": "cs.CV",
      "comment": "12 pages, 5 figures. This is the pre-Springer final accepted version.\n  The final version is published in Springer, Lecture Notes in Computer Science\n  (LNCS), Volume 14731, 2024. Springer Version of Record",
      "pdf_url": "http://arxiv.org/pdf/2412.12572v1",
      "published_date": "2024-12-17 06:03:42 UTC",
      "updated_date": "2024-12-17 06:03:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T14:15:20.452041"
    },
    {
      "arxiv_id": "2412.12561v2",
      "title": "Tell Me What to Track: Infusing Robust Language Guidance for Enhanced Referring Multi-Object Tracking",
      "title_zh": "翻译失败",
      "authors": [
        "Wenjun Huang",
        "Yang Ni",
        "Hanning Chen",
        "Yirui He",
        "Ian Bryant",
        "Yezi Liu",
        "Mohsen Imani"
      ],
      "abstract": "Referring multi-object tracking (RMOT) is an emerging cross-modal task that\naims to localize an arbitrary number of targets based on a language expression\nand continuously track them in a video. This intricate task involves reasoning\non multi-modal data and precise target localization with temporal association.\nHowever, prior studies overlook the imbalanced data distribution between\nnewborn targets and existing targets due to the nature of the task. In\naddition, they only indirectly fuse multi-modal features, struggling to deliver\nclear guidance on newborn target detection. To solve the above issues, we\nconduct a collaborative matching strategy to alleviate the impact of the\nimbalance, boosting the ability to detect newborn targets while maintaining\ntracking performance. In the encoder, we integrate and enhance the cross-modal\nand multi-scale fusion, overcoming the bottlenecks in previous work, where\nlimited multi-modal information is shared and interacted between feature maps.\nIn the decoder, we also develop a referring-infused adaptation that provides\nexplicit referring guidance through the query tokens. The experiments showcase\nthe superior performance of our model (+3.42%) compared to prior works,\ndemonstrating the effectiveness of our designs.",
      "tldr_zh": "这篇论文针对 Referring Multi-Object Tracking (RMOT) 任务，提出了一种增强方法来解决数据不平衡问题和新目标检测的指导不足，通过协作匹配策略提升新目标检测能力，同时保持跟踪性能。论文在编码器中集成并优化跨模态和多尺度融合，克服了先前工作中多模态信息交互有限的瓶颈；在解码器中开发 referring-infused 适应机制，利用查询标记提供明确的语言指导。实验结果显示，该模型相比现有工作提高了 3.42% 的性能，证明了这些设计的有效性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.12561v2",
      "published_date": "2024-12-17 05:43:35 UTC",
      "updated_date": "2025-03-07 18:51:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T14:15:24.743863"
    },
    {
      "arxiv_id": "2412.12559v2",
      "title": "EXIT: Context-Aware Extractive Compression for Enhancing Retrieval-Augmented Generation",
      "title_zh": "EXIT：上下文感知提取式压缩以增强",
      "authors": [
        "Taeho Hwang",
        "Sukmin Cho",
        "Soyeong Jeong",
        "Hoyun Song",
        "SeungYoon Han",
        "Jong C. Park"
      ],
      "abstract": "We introduce EXIT, an extractive context compression framework that enhances\nboth the effectiveness and efficiency of retrieval-augmented generation (RAG)\nin question answering (QA). Current RAG systems often struggle when retrieval\nmodels fail to rank the most relevant documents, leading to the inclusion of\nmore context at the expense of latency and accuracy. While abstractive\ncompression methods can drastically reduce token counts, their token-by-token\ngeneration process significantly increases end-to-end latency. Conversely,\nexisting extractive methods reduce latency but rely on independent,\nnon-adaptive sentence selection, failing to fully utilize contextual\ninformation. EXIT addresses these limitations by classifying sentences from\nretrieved documents - while preserving their contextual dependencies - enabling\nparallelizable, context-aware extraction that adapts to query complexity and\nretrieval quality. Our evaluations on both single-hop and multi-hop QA tasks\nshow that EXIT consistently surpasses existing compression methods and even\nuncompressed baselines in QA accuracy, while also delivering substantial\nreductions in inference time and token count. By improving both effectiveness\nand efficiency, EXIT provides a promising direction for developing scalable,\nhigh-quality QA solutions in RAG pipelines. Our code is available at\nhttps://github.com/ThisIsHwang/EXIT",
      "tldr_zh": "本文提出 EXIT，一种上下文感知的提取式压缩框架，用于提升检索增强生成 (RAG) 在问答 (QA) 任务中的有效性和效率。EXIT 通过分类检索文档中的句子，同时保留上下文依赖，实现可并行化的提取过程，能根据查询复杂度和检索质量进行自适应优化。与现有抽象压缩和提取式方法相比，它解决了延迟和准确性问题。实验结果显示，EXIT 在单跳和多跳 QA 任务上超越基线模型，提高了 QA 准确性，同时显著减少推理时间和令牌数，为构建可扩展、高质量的 RAG 管道提供了新方向。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.CL",
      "comment": "Under Review",
      "pdf_url": "http://arxiv.org/pdf/2412.12559v2",
      "published_date": "2024-12-17 05:38:27 UTC",
      "updated_date": "2024-12-18 13:08:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T14:15:43.851240"
    },
    {
      "arxiv_id": "2412.12552v1",
      "title": "SAModified: A Foundation Model-Based Zero-Shot Approach for Refining Noisy Land-Use Land-Cover Maps",
      "title_zh": "翻译失败",
      "authors": [
        "Sparsh Pekhale",
        "Rakshith Sathish",
        "Sathisha Basavaraju",
        "Divya Sharma"
      ],
      "abstract": "Land-use and land cover (LULC) analysis is critical in remote sensing, with\nwide-ranging applications across diverse fields such as agriculture, utilities,\nand urban planning. However, automating LULC map generation using machine\nlearning is rendered challenging due to noisy labels. Typically, the ground\ntruths (e.g. ESRI LULC, MapBioMass) have noisy labels that hamper the model's\nability to learn to accurately classify the pixels. Further, these erroneous\nlabels can significantly distort the performance metrics of a model, leading to\nmisleading evaluations. Traditionally, the ambiguous labels are rectified using\nunsupervised algorithms. These algorithms struggle not only with scalability\nbut also with generalization across different geographies. To overcome these\nchallenges, we propose a zero-shot approach using the foundation model, Segment\nAnything Model (SAM), to automatically delineate different land parcels/regions\nand leverage them to relabel the unsure pixels by using the local label\nstatistics within each detected region. We achieve a significant reduction in\nlabel noise and an improvement in the performance of the downstream\nsegmentation model by $\\approx 5\\%$ when trained with denoised labels.",
      "tldr_zh": "论文提出SAModified，一种基于基础模型的zero-shot approach，用于改进带有噪声标签的Land-Use Land-Cover (LULC)地图。该方法利用Segment Anything Model (SAM)自动划分土地区域，并通过每个区域的局部标签统计重新标记不确定的像素，从而减少标签噪声。实验结果显示，该方法使下游分割模型的性能提升约5%，为LULC分析提供更可靠的自动化解决方案。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.12552v1",
      "published_date": "2024-12-17 05:23:00 UTC",
      "updated_date": "2024-12-17 05:23:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T14:13:54.433991"
    },
    {
      "arxiv_id": "2412.12544v2",
      "title": "Seed-CTS: Unleashing the Power of Tree Search for Superior Performance in Competitive Coding Tasks",
      "title_zh": "翻译失败",
      "authors": [
        "Hao Wang",
        "Boyi Liu",
        "Yufeng Zhang",
        "Jie Chen"
      ],
      "abstract": "Competition-level code generation tasks pose significant challenges for\ncurrent state-of-the-art large language models (LLMs). For example, on the\nLiveCodeBench-Hard dataset, models such as O1-Mini and O1-Preview achieve\npass@1 rates of only 0.366 and 0.143, respectively. While tree search\ntechniques have proven effective in domains like mathematics and general\ncoding, their potential in competition-level code generation remains\nunder-explored. In this work, we propose a novel token-level tree search method\nspecifically designed for code generation. Leveraging\nQwen2.5-Coder-32B-Instruct, our approach achieves a pass rate of 0.305 on\nLiveCodeBench-Hard, surpassing the pass@100 performance of GPT4o-0513 (0.245).\nFurthermore, by integrating Chain-of-Thought (CoT) prompting, we improve our\nmethod's performance to 0.351, approaching O1-Mini's pass@1 rate. To ensure\nreproducibility, we report the average number of generations required per\nproblem by our tree search method on the test set. Our findings underscore the\npotential of tree search to significantly enhance performance on\ncompetition-level code generation tasks. This opens up new possibilities for\nlarge-scale synthesis of challenging code problems supervised fine-tuning (SFT)\ndata, advancing competition-level code generation tasks.",
      "tldr_zh": "本文提出Seed-CTS，一种基于token-level tree search的方法，旨在提升大型语言模型(LLMs)在竞争级代码生成任务中的性能，例如在LiveCodeBench-Hard数据集上，该方法利用Qwen2.5-Coder-32B-Instruct实现了0.305的pass@1率，超过了GPT4o-0513的pass@100（0.245）。通过整合Chain-of-Thought (CoT)提示，进一步将性能提升至0.351，接近O1-Mini's pass@1率。研究还报告了树搜索方法在测试集上的平均生成次数，以确保可重复性。总体而言，该工作突显了tree search在生成挑战性代码问题数据和监督微调(SFT)方面的潜力，为竞争级代码生成任务提供了新途径。",
      "categories": [
        "cs.AI",
        "cs.SE"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.12544v2",
      "published_date": "2024-12-17 05:10:21 UTC",
      "updated_date": "2024-12-28 02:30:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T14:16:08.968834"
    },
    {
      "arxiv_id": "2412.12542v1",
      "title": "Bots against Bias: Critical Next Steps for Human-Robot Interaction",
      "title_zh": "机器人对抗偏见：人类-机器人交互的关键下一步",
      "authors": [
        "Katie Seaborn"
      ],
      "abstract": "We humans are biased - and our robotic creations are biased, too. Bias is a\nnatural phenomenon that drives our perceptions and behavior, including when it\ncomes to socially expressive robots that have humanlike features. Recognizing\nthat we embed bias, knowingly or not, within the design of such robots is\ncrucial to studying its implications for people in modern societies. In this\nchapter, I consider the multifaceted question of bias in the context of\nhumanoid, AI-enabled, and expressive social robots: Where does bias arise, what\ndoes it look like, and what can (or should) we do about it. I offer\nobservations on human-robot interaction (HRI) along two parallel tracks: (1)\nrobots designed in bias-conscious ways and (2) robots that may help us tackle\nbias in the human world. I outline a curated selection of cases for each track\ndrawn from the latest HRI research and positioned against social, legal, and\nethical factors. I also propose a set of critical next steps to tackle the\nchallenges and opportunities on bias within HRI research and practice.",
      "tldr_zh": "该论文探讨了人类偏见在人机互动（HRI）中的影响，特别是如何嵌入到拟人化、AI 驱动的社会表达机器人设计中。作者分析了偏见的来源、表现形式，并提出两条平行轨道：（1）在设计过程中有意识地处理偏见的机器人，（2）利用机器人来对抗人类世界的偏见，通过选取的 HRI 研究案例并考虑社会、法律和伦理因素。最终，论文建议了一系列关键下一步行动，以应对 HRI 研究和实践中的挑战和机会。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.12542v1",
      "published_date": "2024-12-17 05:09:36 UTC",
      "updated_date": "2024-12-17 05:09:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T14:14:18.903561"
    },
    {
      "arxiv_id": "2412.12541v1",
      "title": "LLMCL-GEC: Advancing Grammatical Error Correction with LLM-Driven Curriculum Learning",
      "title_zh": "LLMCL-GEC：使用 LLM 驱动的课程学习推进",
      "authors": [
        "Tao Fang",
        "Derek F. Wong",
        "Lusheng Zhang",
        "Keyan Jin",
        "Qiang Zhang",
        "Tianjiao Li",
        "Jinlong Hou",
        "Lidia S. Chao"
      ],
      "abstract": "While large-scale language models (LLMs) have demonstrated remarkable\ncapabilities in specific natural language processing (NLP) tasks, they may\nstill lack proficiency compared to specialized models in certain domains, such\nas grammatical error correction (GEC). Drawing inspiration from the concept of\ncurriculum learning, we have delved into refining LLMs into proficient GEC\nexperts by devising effective curriculum learning (CL) strategies. In this\npaper, we introduce a novel approach, termed LLM-based curriculum learning,\nwhich capitalizes on the robust semantic comprehension and discriminative\nprowess inherent in LLMs to gauge the complexity of GEC training data. Unlike\ntraditional curriculum learning techniques, our method closely mirrors human\nexpert-designed curriculums. Leveraging the proposed LLM-based CL method, we\nsequentially select varying levels of curriculums ranging from easy to hard,\nand iteratively train and refine using the pretrianed T5 and LLaMA series\nmodels. Through rigorous testing and analysis across diverse benchmark\nassessments in English GEC, including the CoNLL14 test, BEA19 test, and BEA19\ndevelopment sets, our approach showcases a significant performance boost over\nbaseline models and conventional curriculum learning methodologies.",
      "tldr_zh": "该论文提出LLMCL-GEC，一种基于LLM驱动的课程学习方法，用于提升语法错误修正（GEC）的性能。不同于传统课程学习，该方法利用LLM的语义理解和判别能力来评估训练数据的复杂性，并按从易到难的顺序迭代训练预训练模型如T5和LLaMA系列。通过在CoNLL14、BEA19测试集等英语GEC基准上的实验，该方法显著超过了基线模型和常规课程学习策略，展示了其有效性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Derek F. Wong is the corresponding author. The preprint version\n  consists of 15 Pages, 5 Figures, 5 Tables, and 3 Appendices",
      "pdf_url": "http://arxiv.org/pdf/2412.12541v1",
      "published_date": "2024-12-17 05:09:07 UTC",
      "updated_date": "2024-12-17 05:09:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T14:14:30.888698"
    },
    {
      "arxiv_id": "2412.15267v3",
      "title": "Toxicity Detection towards Adaptability to Changing Perturbations",
      "title_zh": "翻译失败",
      "authors": [
        "Hankun Kang",
        "Jianhao Chen",
        "Yongqi Li",
        "Xin Miao",
        "Mayi Xu",
        "Ming Zhong",
        "Yuanyuan Zhu",
        "Tieyun Qian"
      ],
      "abstract": "Toxicity detection is crucial for maintaining the peace of the society. While\nexisting methods perform well on normal toxic contents or those generated by\nspecific perturbation methods, they are vulnerable to evolving perturbation\npatterns. However, in real-world scenarios, malicious users tend to create new\nperturbation patterns for fooling the detectors. For example, some users may\ncircumvent the detector of large language models (LLMs) by adding `I am a\nscientist' at the beginning of the prompt. In this paper, we introduce a novel\nproblem, i.e., continual learning jailbreak perturbation patterns, into the\ntoxicity detection field. To tackle this problem, we first construct a new\ndataset generated by 9 types of perturbation patterns, 7 of them are summarized\nfrom prior work and 2 of them are developed by us. We then systematically\nvalidate the vulnerability of current methods on this new perturbation\npattern-aware dataset via both the zero-shot and fine tuned cross-pattern\ndetection. Upon this, we present the domain incremental learning paradigm and\nthe corresponding benchmark to ensure the detector's robustness to dynamically\nemerging types of perturbed toxic text. Our code and dataset are provided in\nthe appendix and will be publicly available at GitHub, by which we wish to\noffer new research opportunities for the security-relevant communities.",
      "tldr_zh": "该论文探讨了毒性检测在面对不断变化的扰动模式时的适应性问题，强调现有方法虽在正常或特定扰动内容上表现良好，但易受恶意用户的新型越狱扰动（如添加特定提示欺骗检测器）影响。作者引入了持续学习（continual learning）越狱扰动模式的新问题，构建了一个包含9种扰动模式的数据集（其中7种基于先前工作，2种新开发），并通过零样本和微调的跨模式检测验证了当前方法的脆弱性。最终，他们提出了领域增量学习（domain incremental learning）范式和相应基准，以提升检测器对动态出现的扰动类型毒性文本的鲁棒性，并公开了代码和数据集以支持安全相关社区的研究。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "There are still some flaws in the uploaded content, which may cause\n  confusion for readers. To be rigorous, we need to retract the paper for\n  optimization and improvement",
      "pdf_url": "http://arxiv.org/pdf/2412.15267v3",
      "published_date": "2024-12-17 05:04:57 UTC",
      "updated_date": "2025-03-04 04:49:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T14:16:36.304894"
    },
    {
      "arxiv_id": "2412.12538v1",
      "title": "A Scalable Approach to Benchmarking the In-Conversation Differential Diagnostic Accuracy of a Health AI",
      "title_zh": "翻译失败",
      "authors": [
        "Deep Bhatt",
        "Surya Ayyagari",
        "Anuruddh Mishra"
      ],
      "abstract": "Diagnostic errors in healthcare persist as a critical challenge, with\nincreasing numbers of patients turning to online resources for health\ninformation. While AI-powered healthcare chatbots show promise, there exists no\nstandardized and scalable framework for evaluating their diagnostic\ncapabilities. This study introduces a scalable benchmarking methodology for\nassessing health AI systems and demonstrates its application through August, an\nAI-driven conversational chatbot. Our methodology employs 400 validated\nclinical vignettes across 14 medical specialties, using AI-powered patient\nactors to simulate realistic clinical interactions. In systematic testing,\nAugust achieved a top-one diagnostic accuracy of 81.8% (327/400 cases) and a\ntop-two accuracy of 85.0% (340/400 cases), significantly outperforming\ntraditional symptom checkers. The system demonstrated 95.8% accuracy in\nspecialist referrals and required 47% fewer questions compared to conventional\nsymptom checkers (mean 16 vs 29 questions), while maintaining empathetic\ndialogue throughout consultations. These findings demonstrate the potential of\nAI chatbots to enhance healthcare delivery, though implementation challenges\nremain regarding real-world validation and integration of objective clinical\ndata. This research provides a reproducible framework for evaluating healthcare\nAI systems, contributing to the responsible development and deployment of AI in\nclinical settings.",
      "tldr_zh": "本文提出了一种可扩展的基准测试方法，用于评估健康AI系统的对话诊断准确性，针对AI医疗聊天机器人的诊断能力缺乏标准化框架的问题。研究通过August AI聊天机器人应用此方法，利用400个验证的临床案例（覆盖14个医疗专业）和AI驱动的患者演员模拟真实临床互动。结果显示，August的顶一诊断准确率达到81.8%（327/400 cases），顶二准确率达到85.0%（340/400 cases），并在专家转诊准确率（95.8%）和效率（比传统症状检查器少47%的提问）上表现出色，同时保持富有同情心的对话。该框架为医疗AI的负责任开发和临床部署提供了可复制的评估工具，但需解决真实世界验证等挑战。",
      "categories": [
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.12538v1",
      "published_date": "2024-12-17 05:02:33 UTC",
      "updated_date": "2024-12-17 05:02:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T14:16:44.332082"
    },
    {
      "arxiv_id": "2412.12532v1",
      "title": "Addressing Small and Imbalanced Medical Image Datasets Using Generative Models: A Comparative Study of DDPM and PGGANs with Random and Greedy K Sampling",
      "title_zh": "翻译失败",
      "authors": [
        "Iman Khazrak",
        "Shakhnoza Takhirova",
        "Mostafa M. Rezaee",
        "Mehrdad Yadollahi",
        "Robert C. Green II",
        "Shuteng Niu"
      ],
      "abstract": "The development of accurate medical image classification models is often\nconstrained by privacy concerns and data scarcity for certain conditions,\nleading to small and imbalanced datasets. To address these limitations, this\nstudy explores the use of generative models, such as Denoising Diffusion\nProbabilistic Models (DDPM) and Progressive Growing Generative Adversarial\nNetworks (PGGANs), for dataset augmentation. The research introduces a\nframework to assess the impact of synthetic images generated by DDPM and PGGANs\non the performance of four models: a custom CNN, Untrained VGG16, Pretrained\nVGG16, and Pretrained ResNet50. Experiments were conducted using Random\nSampling and Greedy K Sampling to create small, imbalanced datasets. The\nsynthetic images were evaluated using Frechet Inception Distance (FID) and\ncompared to original datasets through classification metrics. The results show\nthat DDPM consistently generated more realistic images with lower FID scores\nand significantly outperformed PGGANs in improving classification metrics\nacross all models and datasets. Incorporating DDPM-generated images into the\noriginal datasets increased accuracy by up to 6%, enhancing model robustness\nand stability, particularly in imbalanced scenarios. Random Sampling\ndemonstrated superior stability, while Greedy K Sampling offered diversity at\nthe cost of higher FID scores. This study highlights the efficacy of DDPM in\naugmenting small, imbalanced medical image datasets, improving model\nperformance by balancing the dataset and expanding its size.",
      "tldr_zh": "该研究探讨了使用生成模型如 DDPM 和 PGGANs 来增强小且不平衡的医疗图像数据集，以解决隐私和数据稀缺问题。研究引入了一个框架，评估这些模型生成的合成图像对 custom CNN、Untrained VGG16、Pretrained VGG16 和 Pretrained ResNet50 等分类模型的影响，并采用 Random Sampling 和 Greedy K Sampling 创建实验数据集。结果显示，DDPM 生成的图像在 Frechet Inception Distance (FID) 得分上更低，显著优于 PGGANs，提升了所有模型的分类准确率最高达6%，并提高了模型的鲁棒性和稳定性。总体而言，该研究证明了 DDPM 在平衡数据集和扩展规模方面的功效，尤其适用于不平衡场景。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.12532v1",
      "published_date": "2024-12-17 04:42:50 UTC",
      "updated_date": "2024-12-17 04:42:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T14:15:44.698921"
    },
    {
      "arxiv_id": "2412.12525v3",
      "title": "CREST: An Efficient Conjointly-trained Spike-driven Framework for Event-based Object Detection Exploiting Spatiotemporal Dynamics",
      "title_zh": "翻译失败",
      "authors": [
        "Ruixin Mao",
        "Aoyu Shen",
        "Lin Tang",
        "Jun Zhou"
      ],
      "abstract": "Event-based cameras feature high temporal resolution, wide dynamic range, and\nlow power consumption, which is ideal for high-speed and low-light object\ndetection. Spiking neural networks (SNNs) are promising for event-based object\nrecognition and detection due to their spiking nature but lack efficient\ntraining methods, leading to gradient vanishing and high computational\ncomplexity, especially in deep SNNs. Additionally, existing SNN frameworks\noften fail to effectively handle multi-scale spatiotemporal features, leading\nto increased data redundancy and reduced accuracy. To address these issues, we\npropose CREST, a novel conjointly-trained spike-driven framework to exploit\nspatiotemporal dynamics in event-based object detection. We introduce the\nconjoint learning rule to accelerate SNN learning and alleviate gradient\nvanishing. It also supports dual operation modes for efficient and flexible\nimplementation on different hardware types. Additionally, CREST features a\nfully spike-driven framework with a multi-scale spatiotemporal event integrator\n(MESTOR) and a spatiotemporal-IoU (ST-IoU) loss. Our approach achieves superior\nobject recognition & detection performance and up to 100X energy efficiency\ncompared with state-of-the-art SNN algorithms on three datasets, providing an\nefficient solution for event-based object detection algorithms suitable for SNN\nhardware implementation.",
      "tldr_zh": "该研究针对事件相机（Event-based cameras）的高速、低光物体检测问题，提出了一种高效的 CREST 框架，该框架基于联合训练 spike-driven 机制，利用时空动态来优化 SNNs（Spiking Neural Networks）的训练，缓解梯度消失并支持灵活硬件实现。\nCREST 引入了联合学习规则（conjoint learning rule）、多尺度时空事件整合器 (MESTOR) 和时空-IoU (ST-IoU) 损失，以有效处理多尺度时空特征并减少数据冗余。\n实验结果显示，该框架在三个数据集上比现有 SNN 算法实现了优越的物体检测性能，并提高了高达 100 倍的能效，为基于 SNN 硬件的实时应用提供了高效解决方案。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by AAAI 2025",
      "pdf_url": "http://arxiv.org/pdf/2412.12525v3",
      "published_date": "2024-12-17 04:33:31 UTC",
      "updated_date": "2025-01-19 08:06:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T14:17:55.060243"
    },
    {
      "arxiv_id": "2412.15266v1",
      "title": "On the Structural Memory of LLM Agents",
      "title_zh": "论 LLM 代理的结构化记忆",
      "authors": [
        "Ruihong Zeng",
        "Jinyuan Fang",
        "Siwei Liu",
        "Zaiqiao Meng"
      ],
      "abstract": "Memory plays a pivotal role in enabling large language model~(LLM)-based\nagents to engage in complex and long-term interactions, such as question\nanswering (QA) and dialogue systems. While various memory modules have been\nproposed for these tasks, the impact of different memory structures across\ntasks remains insufficiently explored. This paper investigates how memory\nstructures and memory retrieval methods affect the performance of LLM-based\nagents. Specifically, we evaluate four types of memory structures, including\nchunks, knowledge triples, atomic facts, and summaries, along with mixed memory\nthat combines these components. In addition, we evaluate three widely used\nmemory retrieval methods: single-step retrieval, reranking, and iterative\nretrieval. Extensive experiments conducted across four tasks and six datasets\nyield the following key insights: (1) Different memory structures offer\ndistinct advantages, enabling them to be tailored to specific tasks; (2) Mixed\nmemory structures demonstrate remarkable resilience in noisy environments; (3)\nIterative retrieval consistently outperforms other methods across various\nscenarios. Our investigation aims to inspire further research into the design\nof memory systems for LLM-based agents.",
      "tldr_zh": "本研究探讨了记忆结构对大型语言模型（LLM）代理性能的影响，特别是在问答（QA）和对话系统等复杂互动中的作用。研究者评估了四种记忆结构（chunks、knowledge triples、atomic facts和summaries）以及混合记忆（mixed memory），并测试了三种记忆检索方法（single-step retrieval、reranking和iterative retrieval）。在四个任务和六个数据集上的广泛实验揭示了关键洞见：不同记忆结构可根据特定任务定制优势；混合记忆在噪声环境中表现出色；iterative retrieval在各种场景中持续优于其他方法。该研究旨在为LLM代理的记忆系统设计提供启发。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.15266v1",
      "published_date": "2024-12-17 04:30:00 UTC",
      "updated_date": "2024-12-17 04:30:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T14:17:07.269959"
    },
    {
      "arxiv_id": "2412.12522v1",
      "title": "Solid-SQL: Enhanced Schema-linking based In-context Learning for Robust Text-to-SQL",
      "title_zh": "翻译失败",
      "authors": [
        "Geling Liu",
        "Yunzhi Tan",
        "Ruichao Zhong",
        "Yuanzhen Xie",
        "Lingchen Zhao",
        "Qian Wang",
        "Bo Hu",
        "Zang Li"
      ],
      "abstract": "Recently, large language models (LLMs) have significantly improved the\nperformance of text-to-SQL systems. Nevertheless, many state-of-the-art (SOTA)\napproaches have overlooked the critical aspect of system robustness. Our\nexperiments reveal that while LLM-driven methods excel on standard datasets,\ntheir accuracy is notably compromised when faced with adversarial\nperturbations. To address this challenge, we propose a robust text-to-SQL\nsolution, called Solid-SQL, designed to integrate with various LLMs. We focus\non the pre-processing stage, training a robust schema-linking model enhanced by\nLLM-based data augmentation. Additionally, we design a two-round, structural\nsimilarity-based example retrieval strategy for in-context learning. Our method\nachieves SOTA SQL execution accuracy levels of 82.1% and 58.9% on the general\nSpider and Bird benchmarks, respectively. Furthermore, experimental results\nshow that Solid-SQL delivers an average improvement of 11.6% compared to\nbaselines on the perturbed Spider-Syn, Spider-Realistic, and Dr. Spider\nbenchmarks.",
      "tldr_zh": "这篇论文提出了Solid-SQL，一种增强的基于schema-linking的in-context learning方法，旨在提升Text-to-SQL系统的鲁棒性，以应对对抗性扰动带来的准确率下降问题。该方法在预处理阶段训练了一个通过LLM-based数据增强优化的鲁棒schema-linking模型，并设计了双轮基于结构相似性的示例检索策略，以支持各种LLMs的集成。在Spider和Bird基准上，Solid-SQL实现了SOTA的SQL执行准确率，分别为82.1%和58.9%。此外，在扰动基准（如Spider-Syn、Spider-Realistic和Dr. Spider）上，该方法比基线平均提高了11.6%。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted at COLING 2025 Main",
      "pdf_url": "http://arxiv.org/pdf/2412.12522v1",
      "published_date": "2024-12-17 04:22:22 UTC",
      "updated_date": "2024-12-17 04:22:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T14:17:20.561061"
    },
    {
      "arxiv_id": "2412.13224v1",
      "title": "Physics-model-guided Worst-case Sampling for Safe Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Hongpeng Cao",
        "Yanbing Mao",
        "Lui Sha",
        "Marco Caccamo"
      ],
      "abstract": "Real-world accidents in learning-enabled CPS frequently occur in challenging\ncorner cases. During the training of deep reinforcement learning (DRL) policy,\nthe standard setup for training conditions is either fixed at a single initial\ncondition or uniformly sampled from the admissible state space. This setup\noften overlooks the challenging but safety-critical corner cases. To bridge\nthis gap, this paper proposes a physics-model-guided worst-case sampling\nstrategy for training safe policies that can handle safety-critical cases\ntoward guaranteed safety. Furthermore, we integrate the proposed worst-case\nsampling strategy into the physics-regulated deep reinforcement learning\n(Phy-DRL) framework to build a more data-efficient and safe learning algorithm\nfor safety-critical CPS. We validate the proposed training strategy with\nPhy-DRL through extensive experiments on a simulated cart-pole system, a 2D\nquadrotor, a simulated and a real quadruped robot, showing remarkably improved\nsampling efficiency to learn more robust safe policies.",
      "tldr_zh": "该论文针对强化学习（Reinforcement Learning）中标准训练方法忽略安全关键的极端情况问题，提出了一种基于物理模型引导的最坏情况采样（Worst-case Sampling）策略，以训练更鲁棒的安全策略。该策略整合到物理调节深度强化学习（Phy-DRL）框架中，提高了数据效率和安全性。通过在模拟的 cart-pole 系统、2D 四旋翼以及模拟和真实四足机器人上的广泛实验验证，结果显示采样效率显著提升，并学习到更可靠的安全策略。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "under review",
      "pdf_url": "http://arxiv.org/pdf/2412.13224v1",
      "published_date": "2024-12-17 04:13:06 UTC",
      "updated_date": "2024-12-17 04:13:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T14:18:32.827905"
    },
    {
      "arxiv_id": "2412.12500v1",
      "title": "Beyond Data Quantity: Key Factors Driving Performance in Multilingual Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Sina Bagheri Nezhad",
        "Ameeta Agrawal",
        "Rhitabrat Pokharel"
      ],
      "abstract": "Multilingual language models (MLLMs) are crucial for handling text across\nvarious languages, yet they often show performance disparities due to\ndifferences in resource availability and linguistic characteristics. While the\nimpact of pre-train data percentage and model size on performance is\nwell-known, our study reveals additional critical factors that significantly\ninfluence MLLM effectiveness. Analyzing a wide range of features, including\ngeographical, linguistic, and resource-related aspects, we focus on the SIB-200\ndataset for classification and the Flores-200 dataset for machine translation,\nusing regression models and SHAP values across 204 languages. Our findings\nidentify token similarity and country similarity as pivotal factors, alongside\npre-train data and model size, in enhancing model performance. Token similarity\nfacilitates cross-lingual transfer, while country similarity highlights the\nimportance of shared cultural and linguistic contexts. These insights offer\nvaluable guidance for developing more equitable and effective multilingual\nlanguage models, particularly for underrepresented languages.",
      "tldr_zh": "本文研究超越了数据量和模型大小的影响，探讨了多语言语言模型(MLLMs)性能的关键驱动因素，包括地理、语言和资源相关方面。作者使用回归模型和SHAP values分析了SIB-200数据集（分类任务）和Flores-200数据集（机器翻译），覆盖204种语言，发现token similarity和country similarity是核心因素，能促进跨语言转移和共享文化上下文。研究成果为开发更公平有效的MLLMs提供了指导，尤其对欠代表语言的优化。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted at The First Workshop on Language Models for Low-Resource\n  Languages @ COLING 2025",
      "pdf_url": "http://arxiv.org/pdf/2412.12500v1",
      "published_date": "2024-12-17 03:05:26 UTC",
      "updated_date": "2024-12-17 03:05:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T14:18:34.484897"
    },
    {
      "arxiv_id": "2412.15265v2",
      "title": "Chinese SafetyQA: A Safety Short-form Factuality Benchmark for Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Yingshui Tan",
        "Boren Zheng",
        "Baihui Zheng",
        "Kerui Cao",
        "Huiyun Jing",
        "Jincheng Wei",
        "Jiaheng Liu",
        "Yancheng He",
        "Wenbo Su",
        "Xiangyong Zhu",
        "Bo Zheng",
        "Kaifu Zhang"
      ],
      "abstract": "With the rapid advancement of Large Language Models (LLMs), significant\nsafety concerns have emerged. Fundamentally, the safety of large language\nmodels is closely linked to the accuracy, comprehensiveness, and clarity of\ntheir understanding of safety knowledge, particularly in domains such as law,\npolicy and ethics. This factuality ability is crucial in determining whether\nthese models can be deployed and applied safely and compliantly within specific\nregions. To address these challenges and better evaluate the factuality ability\nof LLMs to answer short questions, we introduce the Chinese SafetyQA benchmark.\nChinese SafetyQA has several properties (i.e., Chinese, Diverse, High-quality,\nStatic, Easy-to-evaluate, Safety-related, Harmless). Based on Chinese SafetyQA,\nwe perform a comprehensive evaluation on the factuality abilities of existing\nLLMs and analyze how these capabilities relate to LLM abilities, e.g., RAG\nability and robustness against attacks.",
      "tldr_zh": "该研究针对大型语言模型（LLMs）的安全问题，强调其对安全知识（如法律、政策和伦理）的准确性、全面性和清晰度至关重要，并引入了Chinese SafetyQA基准，这是一个专注于短问答事实性的评估工具。Chinese SafetyQA具有中文、多样性、高质量、静态、易评估、安全相关和无害等特性，用于评估LLMs的事实性能力。研究基于此基准对现有LLMs进行了全面测试，并分析了这些能力与RAG能力以及抗攻击鲁棒性的关系。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.15265v2",
      "published_date": "2024-12-17 03:03:44 UTC",
      "updated_date": "2024-12-23 11:06:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T14:17:56.014566"
    },
    {
      "arxiv_id": "2412.12499v2",
      "title": "LinguaLIFT: An Effective Two-stage Instruction Tuning Framework for Low-Resource Language Reasoning",
      "title_zh": "LinguaLIFT：有效的两阶段指令微调框架，用于低资源语言推理",
      "authors": [
        "Hongbin Zhang",
        "Kehai Chen",
        "Xuefeng Bai",
        "Yang Xiang",
        "Min Zhang"
      ],
      "abstract": "Large language models (LLMs) have exhibited impressive multilingual reasoning\ncapabilities, driven by extensive multilingual pre-training corpora and\ninstruction fine-tuning data. However, a performance gap exists between high-\nand low-resource language reasoning tasks due to the language imbalance in the\npre-training corpus, which is exacerbated by evaluation bias in existing\nreasoning benchmarks lacking low-resource language coverage. To alleviate this\nissue, we propose LinguaLIFT, a two-stage instruction tuning framework for\nadvancing low-resource language reasoning. LinguaLIFT employs a language\nalignment layer to capture multilingual alignment in a code-switched tuning way\nwithout requiring multilingual instruction or parallel data, thereby\ntransferring the cross-lingual reasoning capabilities to low-resource languages\nthrough English-only instruction tuning data. To comprehensively evaluate the\nmultilingual reasoning capabilities, we introduce the Multilingual Math World\nProblem (MMWP) benchmark, which spans 21 low-resource, 17 medium-resource, and\n10 high-resource languages. Experimental results show that LinguaLIFT\noutperforms several competitive baselines across MMWP and four widely used\nbenchmarks.",
      "tldr_zh": "该研究针对大型语言模型（LLMs）在低资源语言推理任务上的性能差距问题，提出了一种有效的两阶段指令调优框架LinguaLIFT。该框架通过语言对齐层（language alignment layer）和代码切换（code-switched）调优方式，捕获多语言对齐，从而利用英语-only指令调优数据将跨语言推理能力转移到低资源语言，而无需多语言指令或平行数据。为全面评估多语言推理能力，研究引入了Multilingual Math World Problem (MMWP)基准，涵盖21种低资源、17种中等资源和10种高资源语言。实验结果显示，LinguaLIFT在MMWP以及四个广泛使用的基准上，优于多个竞争基线模型。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.12499v2",
      "published_date": "2024-12-17 03:03:17 UTC",
      "updated_date": "2025-02-17 13:20:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T14:18:08.310960"
    },
    {
      "arxiv_id": "2412.12496v4",
      "title": "Faster Vision Mamba is Rebuilt in Minutes via Merged Token Re-training",
      "title_zh": "翻译失败",
      "authors": [
        "Mingjia Shi",
        "Yuhao Zhou",
        "Ruiji Yu",
        "Zekai Li",
        "Zhiyuan Liang",
        "Xuanlei Zhao",
        "Xiaojiang Peng",
        "Shanmukha Ramakrishna Vedantam",
        "Wangbo Zhao",
        "Kai Wang",
        "Yang You"
      ],
      "abstract": "Vision Mamba has shown close to state of the art performance on computer\nvision tasks, drawing much interest in increasing it's efficiency. A promising\napproach is token reduction (that has been successfully implemented in ViTs).\nPruning informative tokens in Mamba leads to a high loss of key knowledge and\ndegraded performance. An alternative, of merging tokens preserves more\ninformation than pruning, also suffers for large compression ratios. Our key\ninsight is that a quick round of retraining after token merging yeilds robust\nresults across various compression ratios. Empirically, pruned Vims only drop\nup to 0.9% accuracy on ImageNet-1K, recovered by our proposed framework R-MeeTo\nin our main evaluation. We show how simple and effective the fast recovery can\nbe achieved at minute-level, in particular, a 35.9% accuracy spike over 3\nepochs of training on Vim-Ti. Moreover, Vim-Ti/S/B are re-trained within 5/7/17\nminutes, and Vim-S only drops 1.3% with 1.2x (up to 1.5x) speed up in\ninference.",
      "tldr_zh": "该研究针对Vision Mamba模型在计算机视觉任务中的效率问题，提出了一种基于合并tokens的快速再训练框架R-MeeTo，以克服传统token修剪导致的关键知识丢失和性能下降。关键洞见是通过合并tokens后进行简短再训练，能够在各种压缩比下有效恢复模型性能；在ImageNet-1K上，修剪后的Vims仅下降0.9%准确率，并通过框架快速恢复。实验结果显示，Vim-Ti在3个epochs内准确率提升35.9%，并在5/7/17分钟内完成Vim-Ti/S/B的再训练，同时Vim-S仅损失1.3%准确率，并实现1.2x（最高1.5x）的推理加速。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "68T07",
        "I.2"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.12496v4",
      "published_date": "2024-12-17 02:56:35 UTC",
      "updated_date": "2025-04-14 09:37:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T14:18:20.533605"
    },
    {
      "arxiv_id": "2412.12493v1",
      "title": "A Simple and Fast Way to Handle Semantic Errors in Transactions",
      "title_zh": "一种简单快速处理事务中语义错误的方法",
      "authors": [
        "Jinghan Zeng",
        "Eugene Wu",
        "Sanjay Krishnan"
      ],
      "abstract": "Many computer systems are now being redesigned to incorporate LLM-powered\nagents, enabling natural language input and more flexible operations. This\npaper focuses on handling database transactions created by large language\nmodels (LLMs). Transactions generated by LLMs may include semantic errors,\nrequiring systems to treat them as long-lived. This allows for human review\nand, if the transaction is incorrect, removal from the database history. Any\nremoval action must ensure the database's consistency (the \"C\" in ACID\nprinciples) is maintained throughout the process.\n  We propose a novel middleware framework based on Invariant Satisfaction\n(I-Confluence), which ensures consistency by identifying and coordinating\ndependencies between long-lived transactions and new transactions. This\nmiddleware buffers suspicious or compensating transactions to manage\ncoordination states. Using the TPC-C benchmark, we evaluate how transaction\ngeneration frequency, user reviews, and invariant completeness impact system\nperformance. For system researchers, this study establishes an interactive\nparadigm between LLMs and database systems, providing an \"undoing\" mechanism\nfor handling incorrect operations while guaranteeing database consistency. For\nsystem engineers, this paper offers a middleware design that integrates\nremovable LLM-generated transactions into existing systems with minimal\nmodifications.",
      "tldr_zh": "本论文探讨了大型语言模型 (LLMs) 生成的数据库事务中语义错误的问题，提出将这些事务视为长寿命事务，以便进行人类审查和移除，同时确保 ACID 原则中的一致性 (\"C\")。他们开发了一种基于 Invariant Satisfaction (I-Confluence) 的中间件框架，该框架通过识别事务依赖关系并缓冲可疑或补偿事务来协调长寿命事务与新事务。实验使用 TPC-C 基准测试评估了事务生成频率、用户审查和不变式完整性对性能的影响，为系统研究人员提供 LLMs 与数据库系统的交互范式，并为工程师提供最小修改的集成设计。",
      "categories": [
        "cs.DB",
        "cs.AI"
      ],
      "primary_category": "cs.DB",
      "comment": "14 pages, 13 figures",
      "pdf_url": "http://arxiv.org/pdf/2412.12493v1",
      "published_date": "2024-12-17 02:47:18 UTC",
      "updated_date": "2024-12-17 02:47:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T14:18:33.089252"
    },
    {
      "arxiv_id": "2412.12486v2",
      "title": "Boosting Long-Context Management via Query-Guided Activation Refilling",
      "title_zh": "翻译失败",
      "authors": [
        "Hongjin Qian",
        "Zheng Liu",
        "Peitian Zhang",
        "Zhicheng Dou",
        "Defu Lian"
      ],
      "abstract": "Processing long contexts poses a significant challenge for large language\nmodels (LLMs) due to their inherent context-window limitations and the\ncomputational burden of extensive key-value (KV) activations, which severely\nimpact efficiency. For information-seeking tasks, full context perception is\noften unnecessary, as a query's information needs can dynamically range from\nlocalized details to a global perspective, depending on its complexity.\nHowever, existing methods struggle to adapt effectively to these dynamic\ninformation needs.\n  In the paper, we propose a method for processing long-context\ninformation-seeking tasks via query-guided Activation Refilling (ACRE). ACRE\nconstructs a Bi-layer KV Cache for long contexts, where the layer-1 (L1) cache\ncompactly captures global information, and the layer-2 (L2) cache provides\ndetailed and localized information. ACRE establishes a proxying relationship\nbetween the two caches, allowing the input query to attend to the L1 cache and\ndynamically refill it with relevant entries from the L2 cache. This mechanism\nintegrates global understanding with query-specific local details, thus\nimproving answer decoding. Experiments on a variety of long-context\ninformation-seeking datasets demonstrate ACRE's effectiveness, achieving\nimprovements in both performance and efficiency.",
      "tldr_zh": "该论文针对大型语言模型(LLMs)处理长上下文时面临的上下文窗口限制和计算负担等问题，提出了一种查询引导激活填充方法(ACRE)。ACRE构建了双层KV Cache，其中层1(L1)缓存捕获全局信息，层2(L2)缓存提供详细本地信息，并允许查询先访问L1缓存，然后动态从L2缓存中填充相关条目，从而实现全局理解与查询特定细节的整合。实验结果显示，在多种长上下文信息搜索数据集上，ACRE显著提升了性能和效率。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.CL",
      "comment": "12 pages",
      "pdf_url": "http://arxiv.org/pdf/2412.12486v2",
      "published_date": "2024-12-17 02:43:54 UTC",
      "updated_date": "2024-12-18 05:08:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T14:18:44.110666"
    },
    {
      "arxiv_id": "2412.12484v1",
      "title": "Evolutionary Optimization for Designing Variational Quantum Circuits with High Model Capacity",
      "title_zh": "翻译失败",
      "authors": [
        "Samuel Yen-Chi Chen"
      ],
      "abstract": "Recent advancements in quantum computing (QC) and machine learning (ML) have\ngarnered significant attention, leading to substantial efforts toward the\ndevelopment of quantum machine learning (QML) algorithms to address a variety\nof complex challenges. The design of high-performance QML models, however,\nrequires expert-level knowledge, posing a significant barrier to the widespread\nadoption of QML. Key challenges include the design of data encoding mechanisms\nand parameterized quantum circuits, both of which critically impact the\ngeneralization capabilities of QML models. We propose a novel method that\nencodes quantum circuit architecture information to enable the evolution of\nquantum circuit designs. In this approach, the fitness function is based on the\neffective dimension, allowing for the optimization of quantum circuits towards\nhigher model capacity. Through numerical simulations, we demonstrate that the\nproposed method is capable of discovering variational quantum circuit\narchitectures that offer improved learning capabilities, thereby enhancing the\noverall performance of QML models for complex tasks.",
      "tldr_zh": "该论文提出了一种进化优化方法，用于设计具有高模型容量的变分量子电路（Variational Quantum Circuits），以解决量子机器学习（QML）模型设计中数据编码和电路架构的挑战。该方法通过编码量子电路架构信息，并使用基于有效维度的适应度函数（fitness function）来优化电路设计，从而提升模型的泛化能力和学习性能。通过数值模拟，研究者证明了该方法能够发现更高效的量子电路架构，提高了QML模型在复杂任务中的整体表现。",
      "categories": [
        "quant-ph",
        "cs.AI",
        "cs.ET",
        "cs.LG",
        "cs.NE"
      ],
      "primary_category": "quant-ph",
      "comment": "Accepted by IEEE Symposium Series on Computational Intelligence -\n  IEEE SSCI 2025",
      "pdf_url": "http://arxiv.org/pdf/2412.12484v1",
      "published_date": "2024-12-17 02:40:35 UTC",
      "updated_date": "2024-12-17 02:40:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T14:18:55.816931"
    },
    {
      "arxiv_id": "2412.12480v4",
      "title": "Subversion Strategy Eval: Can language models statelessly strategize to subvert control protocols?",
      "title_zh": "翻译失败",
      "authors": [
        "Alex Mallen",
        "Charlie Griffin",
        "Misha Wagner",
        "Alessandro Abate",
        "Buck Shlegeris"
      ],
      "abstract": "An AI control protocol is a plan for usefully deploying AI systems that aims\nto prevent an AI from intentionally causing some unacceptable outcome. This\npaper investigates how well AI systems can generate and act on their own\nstrategies for subverting control protocols whilst operating statelessly\n(without shared memory between contexts). To do this, an AI system may need to\nreliably generate optimal plans in each context, take actions with\nwell-calibrated probabilities, and coordinate plans with other instances of\nitself without communicating. We develop Subversion Strategy Eval, a suite of\neight environments, covering a range of protocols and strategic capabilities,\nand six sets of affordances that help isolate individual capabilities. We\nimplement the evaluation in Inspect-AI and release it open-source. We evaluate\nClaude 3.5 models, including helpful-only versions, as well as OpenAI reasoning\nmodels. None of the models demonstrate substantial capability in strategizing\nto subvert control protocols statelessly. However, providing models with\nadditional affordances, such as the ability to share a plan between contexts,\ncan substantially improve performance. We hope our evaluations can act as a\nleading indicator for when models are capable of subverting control protocols\nand also relax the worst-case assumption of perfect strategic ability in AI\ncontrol evaluations.",
      "tldr_zh": "这篇论文探讨了语言模型是否能在无状态（statelessly）条件下制定策略来颠覆控制协议（subvert control protocols），以防止AI故意造成不可接受的结果。研究者开发了Subversion Strategy Eval评估套件，包括八个环境和六组affordances，用于测试模型生成计划、执行行动和协调策略的能力。实验评估了Claude 3.5和OpenAI推理模型，结果显示这些模型在无状态下缺乏显著颠覆能力，但提供额外affordances（如计划共享）可显著提升性能。该工作旨在作为模型潜在风险的领先指标，并放松AI控制评估中对完美战略能力的假设。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.12480v4",
      "published_date": "2024-12-17 02:33:45 UTC",
      "updated_date": "2025-04-04 16:36:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T14:19:08.496700"
    },
    {
      "arxiv_id": "2501.17164v1",
      "title": "Split Knowledge Distillation for Large Models in IoT: Architecture, Challenges, and Solutions",
      "title_zh": "物联网中大型模型的分割知识蒸馏：架构、挑战和解决方案",
      "authors": [
        "Zuguang Li",
        "Wen Wu",
        "Shaohua Wu",
        "Qiaohua Lin",
        "Yaping Sun",
        "Hui Wang"
      ],
      "abstract": "Large models (LMs) have immense potential in Internet of Things (IoT)\nsystems, enabling applications such as intelligent voice assistants, predictive\nmaintenance, and healthcare monitoring. However, training LMs on edge servers\nraises data privacy concerns, while deploying them directly on IoT devices is\nconstrained by limited computational and memory resources. We analyze the key\nchallenges of training LMs in IoT systems, including energy constraints,\nlatency requirements, and device heterogeneity, and propose potential solutions\nsuch as dynamic resource management, adaptive model partitioning, and clustered\ncollaborative training. Furthermore, we propose a split knowledge distillation\nframework to efficiently distill LMs into smaller, deployable versions for IoT\ndevices while ensuring raw data remains local. This framework integrates\nknowledge distillation and split learning to minimize energy consumption and\nmeet low model training delay requirements. A case study is presented to\nevaluate the feasibility and performance of the proposed framework.",
      "tldr_zh": "该论文探讨了在物联网（IoT）系统中部署大型模型（LMs）的潜力与挑战，包括数据隐私风险、能源约束、延迟要求和设备异构性等问题，并提出了解决方案如动态资源管理、适应性模型分区和集群协作训练。核心贡献是提出一种分割知识蒸馏（Split Knowledge Distillation）框架，该框架整合知识蒸馏和分割学习技术，将LMs提炼成更小的、可部署版本，同时确保原始数据保持本地化，以最小化能源消耗和训练延迟。通过案例研究，证明了该框架的可行性和性能表现。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "7 pages, 4figures, 2 tables, and 15 conference",
      "pdf_url": "http://arxiv.org/pdf/2501.17164v1",
      "published_date": "2024-12-17 02:31:31 UTC",
      "updated_date": "2024-12-17 02:31:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T14:19:21.143880"
    },
    {
      "arxiv_id": "2412.12475v2",
      "title": "RareAgents: Advancing Rare Disease Care through LLM-Empowered Multi-disciplinary Team",
      "title_zh": "RareAgents：通过 LLM 赋能的多学科团队推进罕见疾病护理",
      "authors": [
        "Xuanzhong Chen",
        "Ye Jin",
        "Xiaohao Mao",
        "Lun Wang",
        "Shuyang Zhang",
        "Ting Chen"
      ],
      "abstract": "Rare diseases, despite their low individual incidence, collectively impact\naround 300 million people worldwide due to the vast number of diseases. The\ninvolvement of multiple organs and systems, and the shortage of specialized\ndoctors with relevant experience make diagnosing and treating rare diseases\nmore challenging than common diseases. Recently, agents powered by large\nlanguage models (LLMs) have demonstrated notable applications across various\ndomains. In the medical field, some agent methods have outperformed direct\nprompts in question-answering tasks from medical examinations. However, current\nagent frameworks are not well-adapted to real-world clinical scenarios,\nespecially those involving the complex demands of rare diseases. To bridge this\ngap, we introduce RareAgents, the first LLM-driven multi-disciplinary team\nframework designed specifically for the complex clinical context of rare\ndiseases. RareAgents integrates advanced Multidisciplinary Team (MDT)\ncoordination, memory mechanisms, and medical tools utilization, leveraging\nLlama-3.1-8B/70B as the base model. Experimental results show that RareAgents\noutperforms state-of-the-art domain-specific models, GPT-4o, and current agent\nframeworks in differential diagnosis and medication recommendation for rare\ndiseases. Furthermore, we contribute a novel rare disease dataset,\nMIMIC-IV-Ext-Rare, to support further advancements in this field.",
      "tldr_zh": "该研究针对稀有疾病的诊断和治疗挑战，提出RareAgents框架，这是一种基于LLM驱动的多学科团队（Multi-disciplinary Team），旨在整合MDT协调、记忆机制和医疗工具，利用Llama-3.1-8B/70B作为基础模型，以更好地处理复杂临床场景。实验结果显示，RareAgents在稀有疾病的鉴别诊断和药物推荐任务中，优于最先进领域模型、GPT-4o及现有智能体框架。论文还贡献了一个新数据集MIMIC-IV-Ext-Rare，以支持该领域的进一步发展。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.12475v2",
      "published_date": "2024-12-17 02:22:24 UTC",
      "updated_date": "2025-02-14 08:40:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T14:21:24.745667"
    },
    {
      "arxiv_id": "2412.15264v3",
      "title": "ReXTrust: A Model for Fine-Grained Hallucination Detection in AI-Generated Radiology Reports",
      "title_zh": "翻译失败",
      "authors": [
        "Romain Hardy",
        "Sung Eun Kim",
        "Du Hyun Ro",
        "Pranav Rajpurkar"
      ],
      "abstract": "The increasing adoption of AI-generated radiology reports necessitates robust\nmethods for detecting hallucinations--false or unfounded statements that could\nimpact patient care. We present ReXTrust, a novel framework for fine-grained\nhallucination detection in AI-generated radiology reports. Our approach\nleverages sequences of hidden states from large vision-language models to\nproduce finding-level hallucination risk scores. We evaluate ReXTrust on a\nsubset of the MIMIC-CXR dataset and demonstrate superior performance compared\nto existing approaches, achieving an AUROC of 0.8751 across all findings and\n0.8963 on clinically significant findings. Our results show that white-box\napproaches leveraging model hidden states can provide reliable hallucination\ndetection for medical AI systems, potentially improving the safety and\nreliability of automated radiology reporting.",
      "tldr_zh": "本文提出 ReXTrust 框架，用于细粒度检测 AI 生成放射学报告中的 hallucination（虚假或无依据陈述），以降低对患者护理的影响。该方法利用大型 vision-language models 的隐藏状态序列，生成 findings-level 的 hallucination 风险分数，并在 MIMIC-CXR 数据集子集上评估时，相比现有方法实现了更高的 AUROC（0.8751 整体，0.8963 临床重要 findings）。研究结果表明，白盒方法（leveraging model hidden states）可为医疗 AI 系统提供可靠的幻觉检测，提升自动化放射学报告的安全性和可靠性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to AIMedHealth 10 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2412.15264v3",
      "published_date": "2024-12-17 02:07:33 UTC",
      "updated_date": "2025-01-31 03:15:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T14:19:44.239231"
    },
    {
      "arxiv_id": "2412.12469v1",
      "title": "Optimal Control Operator Perspective and a Neural Adaptive Spectral Method",
      "title_zh": "最优控制算子视角与神经自适应谱方法",
      "authors": [
        "Mingquan Feng",
        "Zhijie Chen",
        "Yixin Huang",
        "Yizhou Liu",
        "Junchi Yan"
      ],
      "abstract": "Optimal control problems (OCPs) involve finding a control function for a\ndynamical system such that a cost functional is optimized. It is central to\nphysical systems in both academia and industry. In this paper, we propose a\nnovel instance-solution control operator perspective, which solves OCPs in a\none-shot manner without direct dependence on the explicit expression of\ndynamics or iterative optimization processes. The control operator is\nimplemented by a new neural operator architecture named Neural Adaptive\nSpectral Method (NASM), a generalization of classical spectral methods. We\ntheoretically validate the perspective and architecture by presenting the\napproximation error bounds of NASM for the control operator. Experiments on\nsynthetic environments and a real-world dataset verify the effectiveness and\nefficiency of our approach, including substantial speedup in running time, and\nhigh-quality in- and out-of-distribution generalization.",
      "tldr_zh": "本论文提出了一种新的最优控制算子视角（instance-solution control operator perspective），用于一次性解决 Optimal Control Problems (OCPs)，无需依赖动态系统的显式表达式或迭代优化过程。作者开发了 Neural Adaptive Spectral Method (NASM)，一种对经典谱方法的推广，作为控制算子的神经架构实现。理论上，他们提供了 NASM 的逼近误差界，以验证其有效性。实验在合成环境和真实数据集上显示，该方法显著提高了运行效率，并实现了高质量的分布内和分布外泛化。",
      "categories": [
        "eess.SY",
        "cs.AI",
        "cs.LG",
        "cs.SY",
        "math.OC"
      ],
      "primary_category": "eess.SY",
      "comment": "Accepted for publication at AAAl'25. Extended version with full\n  appendix, 22 pages",
      "pdf_url": "http://arxiv.org/pdf/2412.12469v1",
      "published_date": "2024-12-17 02:06:34 UTC",
      "updated_date": "2024-12-17 02:06:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T14:19:55.841487"
    },
    {
      "arxiv_id": "2412.12468v2",
      "title": "Transferable and Forecastable User Targeting Foundation Model",
      "title_zh": "可转移且可预测的用户定向基础模型",
      "authors": [
        "Bin Dou",
        "Baokun Wang",
        "Yun Zhu",
        "Xiaotong Lin",
        "Yike Xu",
        "Xiaorui Huang",
        "Yang Chen",
        "Yun Liu",
        "Shaoshuai Han",
        "Yongchao Liu",
        "Tianyi Zhang",
        "Yu Cheng",
        "Weiqiang Wang",
        "Chuntao Hong"
      ],
      "abstract": "User targeting, the process of selecting targeted users from a pool of\ncandidates for non-expert marketers, has garnered substantial attention with\nthe advancements in digital marketing. However, existing user targeting methods\nencounter two significant challenges: (i) Poor cross-domain and cross-scenario\ntransferability and generalization, and (ii) Insufficient forecastability in\nreal-world applications. These limitations hinder their applicability across\ndiverse industrial scenarios. In this work, we propose FOUND, an\nindustrial-grade, transferable, and forecastable user targeting foundation\nmodel. To enhance cross-domain transferability, our framework integrates\nheterogeneous multi-scenario user data, aligning them with one-sentence\ntargeting demand inputs through contrastive pre-training. For improved\nforecastability, the text description of each user is derived based on\nanticipated future behaviors, while user representations are constructed from\nhistorical information. Experimental results demonstrate that our approach\nsignificantly outperforms existing baselines in cross-domain, real-world user\ntargeting scenarios, showcasing the superior capabilities of FOUND. Moreover,\nour method has been successfully deployed on the Alipay platform and is widely\nutilized across various scenarios.",
      "tldr_zh": "该论文针对用户定位(user targeting)存在的跨域和跨场景转移性差以及预测能力不足的问题，提出了一种可转移且可预测的用户定位基础模型FOUND。FOUND通过整合异构多场景用户数据，并采用对比预训练方法将这些数据与一句子定位需求输入对齐，同时基于预期未来行为的文本描述和历史信息的用户表示来提升预测性。实验结果显示，FOUND在跨域真实场景中显著优于现有基线模型，且已在Alipay平台成功部署并广泛应用。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "10 pages, 6 figures, accept by The ACM Web Conference 2025 (WWW 2025)\n  Industry Track",
      "pdf_url": "http://arxiv.org/pdf/2412.12468v2",
      "published_date": "2024-12-17 02:05:09 UTC",
      "updated_date": "2025-02-20 14:57:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T14:20:07.333905"
    },
    {
      "arxiv_id": "2412.12463v2",
      "title": "Pattern Analogies: Learning to Perform Programmatic Image Edits by Analogy",
      "title_zh": "翻译失败",
      "authors": [
        "Aditya Ganeshan",
        "Thibault Groueix",
        "Paul Guerrero",
        "Radomír Měch",
        "Matthew Fisher",
        "Daniel Ritchie"
      ],
      "abstract": "Pattern images are everywhere in the digital and physical worlds, and tools\nto edit them are valuable. But editing pattern images is tricky: desired edits\nare often programmatic: structure-aware edits that alter the underlying program\nwhich generates the pattern. One could attempt to infer this underlying\nprogram, but current methods for doing so struggle with complex images and\nproduce unorganized programs that make editing tedious. In this work, we\nintroduce a novel approach to perform programmatic edits on pattern images. By\nusing a pattern analogy -- a pair of simple patterns to demonstrate the\nintended edit -- and a learning-based generative model to execute these edits,\nour method allows users to intuitively edit patterns. To enable this paradigm,\nwe introduce SplitWeave, a domain-specific language that, combined with a\nframework for sampling synthetic pattern analogies, enables the creation of a\nlarge, high-quality synthetic training dataset. We also present TriFuser, a\nLatent Diffusion Model (LDM) designed to overcome critical issues that arise\nwhen naively deploying LDMs to this task. Extensive experiments on real-world,\nartist-sourced patterns reveals that our method faithfully performs the\ndemonstrated edit while also generalizing to related pattern styles beyond its\ntraining distribution.",
      "tldr_zh": "本文提出一种新方法，通过pattern analogy（一种模式类比）来执行程序化图像编辑，用户只需提供一对简单模式演示编辑意图，即可利用学习-based生成模型实现结构感知编辑。论文引入SplitWeave，一个domain-specific language，结合合成数据集采样框架，创建大规模高质量训练数据；同时开发了TriFuser，一个专为该任务设计的Latent Diffusion Model (LDM)，以解决直接应用LDM的挑战。实验结果显示，该方法在真实世界艺术家来源的模式图像上，忠实地执行演示编辑并泛化到训练分布以外的相关模式样式。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.GR",
        "cs.HC"
      ],
      "primary_category": "cs.CV",
      "comment": "CVPR 2024 - Website: https://bardofcodes.github.io/patterns/",
      "pdf_url": "http://arxiv.org/pdf/2412.12463v2",
      "published_date": "2024-12-17 01:52:12 UTC",
      "updated_date": "2025-04-05 16:33:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T14:20:20.254751"
    },
    {
      "arxiv_id": "2412.12459v1",
      "title": "LITA: An Efficient LLM-assisted Iterative Topic Augmentation Framework",
      "title_zh": "LITA: 高效的LLM辅助迭代主题增强框架",
      "authors": [
        "Chia-Hsuan Chang",
        "Jui-Tse Tsai",
        "Yi-Hang Tsai",
        "San-Yih Hwang"
      ],
      "abstract": "Topic modeling is widely used for uncovering thematic structures within text\ncorpora, yet traditional models often struggle with specificity and coherence\nin domain-focused applications. Guided approaches, such as SeededLDA and CorEx,\nincorporate user-provided seed words to improve relevance but remain\nlabor-intensive and static. Large language models (LLMs) offer potential for\ndynamic topic refinement and discovery, yet their application often incurs high\nAPI costs. To address these challenges, we propose the LLM-assisted Iterative\nTopic Augmentation framework (LITA), an LLM-assisted approach that integrates\nuser-provided seeds with embedding-based clustering and iterative refinement.\nLITA identifies a small number of ambiguous documents and employs an LLM to\nreassign them to existing or new topics, minimizing API costs while enhancing\ntopic quality. Experiments on two datasets across topic quality and clustering\nperformance metrics demonstrate that LITA outperforms five baseline models,\nincluding LDA, SeededLDA, CorEx, BERTopic, and PromptTopic. Our work offers an\nefficient and adaptable framework for advancing topic modeling and text\nclustering.",
      "tldr_zh": "该研究针对传统主题建模在特定领域应用的特异性和连贯性不足问题，提出LITA框架，这是一种高效的LLM辅助迭代主题增强方法。LITA整合用户提供的种子词、基于嵌入的聚类以及迭代精炼过程，仅针对少量模糊文档使用LLM进行重新分配，从而最小化API成本并提升主题质量。在两个数据集上的实验显示，LITA在主题质量和聚类性能指标上优于基线模型，包括LDA、SeededLDA、CorEx、BERTopic和PromptTopic，为主题建模和文本聚类提供了高效且可适应的框架。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.CL",
      "comment": "Under Review",
      "pdf_url": "http://arxiv.org/pdf/2412.12459v1",
      "published_date": "2024-12-17 01:43:44 UTC",
      "updated_date": "2024-12-17 01:43:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T14:20:32.559745"
    },
    {
      "arxiv_id": "2412.12456v1",
      "title": "Graph Learning in the Era of LLMs: A Survey from the Perspective of Data, Models, and Tasks",
      "title_zh": "翻译失败",
      "authors": [
        "Xunkai Li",
        "Zhengyu Wu",
        "Jiayi Wu",
        "Hanwen Cui",
        "Jishuo Jia",
        "Rong-Hua Li",
        "Guoren Wang"
      ],
      "abstract": "With the increasing prevalence of cross-domain Text-Attributed Graph (TAG)\nData (e.g., citation networks, recommendation systems, social networks, and\nai4science), the integration of Graph Neural Networks (GNNs) and Large Language\nModels (LLMs) into a unified Model architecture (e.g., LLM as enhancer, LLM as\ncollaborators, LLM as predictor) has emerged as a promising technological\nparadigm. The core of this new graph learning paradigm lies in the synergistic\ncombination of GNNs' ability to capture complex structural relationships and\nLLMs' proficiency in understanding informative contexts from the rich textual\ndescriptions of graphs. Therefore, we can leverage graph description texts with\nrich semantic context to fundamentally enhance Data quality, thereby improving\nthe representational capacity of model-centric approaches in line with\ndata-centric machine learning principles. By leveraging the strengths of these\ndistinct neural network architectures, this integrated approach addresses a\nwide range of TAG-based Task (e.g., graph learning, graph reasoning, and graph\nquestion answering), particularly in complex industrial scenarios (e.g.,\nsupervised, few-shot, and zero-shot settings). In other words, we can treat\ntext as a medium to enable cross-domain generalization of graph learning Model,\nallowing a single graph model to effectively handle the diversity of downstream\ngraph-based Task across different data domains. This work serves as a\nfoundational reference for researchers and practitioners looking to advance\ngraph learning methodologies in the rapidly evolving landscape of LLM. We\nconsistently maintain the related open-source materials at\n\\url{https://github.com/xkLi-Allen/Awesome-GNN-in-LLMs-Papers}.",
      "tldr_zh": "这篇调研论文从数据、模型和任务的视角，探讨了在 Large Language Models (LLMs) 时代下图学习的最新发展，特别是 Graph Neural Networks (GNNs) 与 LLMs 的整合。论文强调通过图描述文本提升 Text-Attributed Graph (TAG) 数据质量，利用 GNNs 处理结构关系和 LLMs 处理语境信息，从而实现模型在监督、少样本和零样本场景中的跨域泛化，并有效应对各种 TAG-based 任务，如图学习、推理和问答。总体贡献在于为研究者和从业者提供了一个统一的框架参考，并附带开源资源（https://github.com/xkLi-Allen/Awesome-GNN-in-LLMs-Papers），推动图学习在复杂工业应用中的进步。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.DB"
      ],
      "primary_category": "cs.LG",
      "comment": "In progress",
      "pdf_url": "http://arxiv.org/pdf/2412.12456v1",
      "published_date": "2024-12-17 01:41:17 UTC",
      "updated_date": "2024-12-17 01:41:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T14:20:44.810555"
    },
    {
      "arxiv_id": "2412.12447v2",
      "title": "PERC: Plan-As-Query Example Retrieval for Underrepresented Code Generation",
      "title_zh": "PERC：计划作为查询的例子检索，用于代表不足的代码生成",
      "authors": [
        "Jaeseok Yoo",
        "Hojae Han",
        "Youngwon Lee",
        "Jaejin Kim",
        "Seung-won Hwang"
      ],
      "abstract": "Code generation with large language models has shown significant promise,\nespecially when employing retrieval-augmented generation (RAG) with few-shot\nexamples. However, selecting effective examples that enhance generation quality\nremains a challenging task, particularly when the target programming language\n(PL) is underrepresented. In this study, we present two key findings: (1)\nretrieving examples whose presented algorithmic plans can be referenced for\ngenerating the desired behavior significantly improves generation accuracy, and\n(2) converting code into pseudocode effectively captures such algorithmic\nplans, enhancing retrieval quality even when the source and the target PLs are\ndifferent. Based on these findings, we propose Plan-as-query Example Retrieval\nfor few-shot prompting in Code generation (PERC), a novel framework that\nutilizes algorithmic plans to identify and retrieve effective examples. We\nvalidate the effectiveness of PERC through extensive experiments on the\nCodeContests, HumanEval and MultiPL-E benchmarks: PERC consistently outperforms\nthe state-of-the-art RAG methods in code generation, both when the source and\ntarget programming languages match or differ, highlighting its adaptability and\nrobustness in diverse coding environments.",
      "tldr_zh": "该研究针对 underrepresented 编程语言的代码生成问题，提出 PERC（Plan-as-Query Example Retrieval）框架，利用检索增强生成（RAG）结合少样本提示来提升生成质量。PERC 的核心机制是通过算法计划作为查询检索有效示例，并将代码转换为伪代码，以捕捉算法细节，从而提高检索准确性，即使源语言和目标语言不同。实验在 CodeContests、HumanEval 和 MultiPL-E 基准上验证了 PERC 的有效性，它在代码生成任务中 consistently outperforms 现有最先进的 RAG 方法，无论语言是否匹配。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.SE",
      "comment": "Accepted by COLING 2025 main conference",
      "pdf_url": "http://arxiv.org/pdf/2412.12447v2",
      "published_date": "2024-12-17 01:23:45 UTC",
      "updated_date": "2024-12-20 03:12:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T14:21:36.540036"
    },
    {
      "arxiv_id": "2412.12444v3",
      "title": "LazyDiT: Lazy Learning for the Acceleration of Diffusion Transformers",
      "title_zh": "翻译失败",
      "authors": [
        "Xuan Shen",
        "Zhao Song",
        "Yufa Zhou",
        "Bo Chen",
        "Yanyu Li",
        "Yifan Gong",
        "Kai Zhang",
        "Hao Tan",
        "Jason Kuen",
        "Henghui Ding",
        "Zhihao Shu",
        "Wei Niu",
        "Pu Zhao",
        "Yanzhi Wang",
        "Jiuxiang Gu"
      ],
      "abstract": "Diffusion Transformers have emerged as the preeminent models for a wide array\nof generative tasks, demonstrating superior performance and efficacy across\nvarious applications. The promising results come at the cost of slow inference,\nas each denoising step requires running the whole transformer model with a\nlarge amount of parameters. In this paper, we show that performing the full\ncomputation of the model at each diffusion step is unnecessary, as some\ncomputations can be skipped by lazily reusing the results of previous steps.\nFurthermore, we show that the lower bound of similarity between outputs at\nconsecutive steps is notably high, and this similarity can be linearly\napproximated using the inputs. To verify our demonstrations, we propose the\n\\textbf{LazyDiT}, a lazy learning framework that efficiently leverages cached\nresults from earlier steps to skip redundant computations. Specifically, we\nincorporate lazy learning layers into the model, effectively trained to\nmaximize laziness, enabling dynamic skipping of redundant computations.\nExperimental results show that LazyDiT outperforms the DDIM sampler across\nmultiple diffusion transformer models at various resolutions. Furthermore, we\nimplement our method on mobile devices, achieving better performance than DDIM\nwith similar latency. Code: https://github.com/shawnricecake/lazydit",
      "tldr_zh": "Diffusion Transformers 在生成任务中表现出色，但推理过程因每个去噪步骤需运行完整模型而速度缓慢。论文提出 LazyDiT 框架，利用懒惰学习技术重用先前步骤的缓存结果，并通过线性近似输出相似性来动态跳过冗余计算。实验结果表明，LazyDiT 在多种 Diffusion Transformer 模型和分辨率下优于 DDIM sampler，并在移动设备上实现了更高的性能和类似延迟。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by AAAI 2025",
      "pdf_url": "http://arxiv.org/pdf/2412.12444v3",
      "published_date": "2024-12-17 01:12:35 UTC",
      "updated_date": "2025-03-21 15:52:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T14:21:48.182910"
    },
    {
      "arxiv_id": "2412.12441v1",
      "title": "Numerical Pruning for Efficient Autoregressive Models",
      "title_zh": "用于高效自回归模型的数值剪枝",
      "authors": [
        "Xuan Shen",
        "Zhao Song",
        "Yufa Zhou",
        "Bo Chen",
        "Jing Liu",
        "Ruiyi Zhang",
        "Ryan A. Rossi",
        "Hao Tan",
        "Tong Yu",
        "Xiang Chen",
        "Yufan Zhou",
        "Tong Sun",
        "Pu Zhao",
        "Yanzhi Wang",
        "Jiuxiang Gu"
      ],
      "abstract": "Transformers have emerged as the leading architecture in deep learning,\nproving to be versatile and highly effective across diverse domains beyond\nlanguage and image processing. However, their impressive performance often\nincurs high computational costs due to their substantial model size. This paper\nfocuses on compressing decoder-only transformer-based autoregressive models\nthrough structural weight pruning to improve the model efficiency while\npreserving performance for both language and image generation tasks.\nSpecifically, we propose a training-free pruning method that calculates a\nnumerical score with Newton's method for the Attention and MLP modules,\nrespectively. Besides, we further propose another compensation algorithm to\nrecover the pruned model for better performance. To verify the effectiveness of\nour method, we provide both theoretical support and extensive experiments. Our\nexperiments show that our method achieves state-of-the-art performance with\nreduced memory usage and faster generation speeds on GPUs.",
      "tldr_zh": "这篇论文针对 Transformers 模型的高计算成本，提出了一种结构化权重修剪方法，用于压缩 decoder-only transformer-based autoregressive 模型，以提高效率同时保持语言和图像生成任务的性能。方法包括一个训练-free 修剪技术，使用 Newton's method 计算数值分数针对 Attention 和 MLP 模块进行修剪，并引入补偿算法来恢复模型性能。实验结果显示，该方法在减少内存使用和加快生成速度方面达到了 state-of-the-art 水平，并提供了理论支持。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by AAAI 2025",
      "pdf_url": "http://arxiv.org/pdf/2412.12441v1",
      "published_date": "2024-12-17 01:09:23 UTC",
      "updated_date": "2024-12-17 01:09:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T14:21:59.779232"
    },
    {
      "arxiv_id": "2412.12432v1",
      "title": "Three Things to Know about Deep Metric Learning",
      "title_zh": "关于深度度量学习的三个要点",
      "authors": [
        "Yash Patel",
        "Giorgos Tolias",
        "Jiri Matas"
      ],
      "abstract": "This paper addresses supervised deep metric learning for open-set image\nretrieval, focusing on three key aspects: the loss function, mixup\nregularization, and model initialization. In deep metric learning, optimizing\nthe retrieval evaluation metric, recall@k, via gradient descent is desirable\nbut challenging due to its non-differentiable nature. To overcome this, we\npropose a differentiable surrogate loss that is computed on large batches,\nnearly equivalent to the entire training set. This computationally intensive\nprocess is made feasible through an implementation that bypasses the GPU memory\nlimitations. Additionally, we introduce an efficient mixup regularization\ntechnique that operates on pairwise scalar similarities, effectively increasing\nthe batch size even further. The training process is further enhanced by\ninitializing the vision encoder using foundational models, which are\npre-trained on large-scale datasets. Through a systematic study of these\ncomponents, we demonstrate that their synergy enables large models to nearly\nsolve popular benchmarks.",
      "tldr_zh": "这篇论文探讨了深度度量学习在开放集图像检索中的三个关键方面：损失函数、mixup 正则化和模型初始化。作者提出了一种可微的代理损失函数，用于优化 recall@k 指标，通过在大型批次上计算来绕过其不可微性质，并通过高效实现克服 GPU 内存限制。此外，论文引入了基于成对标量相似度的 mixup 正则化技术，以进一步扩大批次大小，并使用在大型数据集上预训练的基础模型初始化视觉编码器。这些组件的协同作用使大型模型在流行基准上实现了近乎完美的性能。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.12432v1",
      "published_date": "2024-12-17 00:49:12 UTC",
      "updated_date": "2024-12-17 00:49:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T14:22:12.499071"
    },
    {
      "arxiv_id": "2412.13223v1",
      "title": "Generative modeling of protein ensembles guided by crystallographic electron densities",
      "title_zh": "基于晶体学",
      "authors": [
        "Sai Advaith Maddipatla",
        "Nadav Bojan Sellam",
        "Sanketh Vedula",
        "Ailie Marx",
        "Alex Bronstein"
      ],
      "abstract": "Proteins are dynamic, adopting ensembles of conformations. The nature of this\nconformational heterogenity is imprinted in the raw electron density\nmeasurements obtained from X-ray crystallography experiments. Fitting an\nensemble of protein structures to these measurements is a challenging,\nill-posed inverse problem. We propose a non-i.i.d. ensemble guidance approach\nto solve this problem using existing protein structure generative models and\ndemonstrate that it accurately recovers complicated multi-modal alternate\nprotein backbone conformations observed in certain single crystal measurements.",
      "tldr_zh": "蛋白质是动态的，会采用多种构象，这种构象异质性记录在 X-ray crystallography 实验的原始电子密度测量中。拟合蛋白质结构集合到这些测量是一个具有挑战性的、病态的逆问题。作者提出了一种 non-i.i.d. ensemble guidance 方法，利用现有的 protein structure generative models 来解决这个问题，并证明该方法能准确恢复某些单晶测量中观察到的复杂 multi-modal alternate protein backbone conformations。",
      "categories": [
        "q-bio.QM",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "q-bio.QM",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.13223v1",
      "published_date": "2024-12-17 00:31:59 UTC",
      "updated_date": "2024-12-17 00:31:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T14:22:24.758781"
    },
    {
      "arxiv_id": "2412.16201v1",
      "title": "CLIP-RLDrive: Human-Aligned Autonomous Driving via CLIP-Based Reward Shaping in Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Erfan Doroudian",
        "Hamid Taghavifar"
      ],
      "abstract": "This paper presents CLIP-RLDrive, a new reinforcement learning (RL)-based\nframework for improving the decision-making of autonomous vehicles (AVs) in\ncomplex urban driving scenarios, particularly in unsignalized intersections. To\nachieve this goal, the decisions for AVs are aligned with human-like\npreferences through Contrastive Language-Image Pretraining (CLIP)-based reward\nshaping. One of the primary difficulties in RL scheme is designing a suitable\nreward model, which can often be challenging to achieve manually due to the\ncomplexity of the interactions and the driving scenarios. To deal with this\nissue, this paper leverages Vision-Language Models (VLMs), particularly CLIP,\nto build an additional reward model based on visual and textual cues.",
      "tldr_zh": "本论文提出 CLIP-RLDrive，一种基于强化学习 (RL) 的框架，用于提升自动驾驶车辆 (AVs) 在复杂城市场景（如无信号灯十字路口）的决策能力，使其更符合人类偏好。作者通过 CLIP（Contrastive Language-Image Pretraining）进行奖励塑造 (reward shaping)，利用视觉语言模型 (VLMs) 基于视觉和文本线索构建额外的奖励模型，以解决手动设计奖励模型的复杂性挑战。该方法有效对齐 AV 的决策与人类行为，确保更安全和智能的驾驶表现。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.16201v1",
      "published_date": "2024-12-17 00:12:45 UTC",
      "updated_date": "2024-12-17 00:12:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T14:22:35.594719"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 146,
  "processed_papers_count": 146,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-21T14:23:17.458408"
}