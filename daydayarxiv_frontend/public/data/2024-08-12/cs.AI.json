{
  "date": "2024-08-12",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-08-12 的 arXiv 中文 TLDR 快报！\n\n今天 arXiv 的论文主要聚焦于 AI 模型优化、多模态处理、机器学习应用以及科学计算等领域，其中 \"The AI Scientist\" 论文最为令人印象深刻，由知名学者 Jeff Clune 和 David Ha 等人发布，探讨了大型语言模型在自动科学发现中的潜力；其他亮点包括多模态视觉代理基准和量子梯度激活映射等创新方法。\n\n下面，我将挑选并简要讨论部分关键论文，先从重要性和话题度高的入手（如 AI 代理和多模态模型），再快速掠过其他领域的内容。限于篇幅，我会优先突出核心贡献和发现，并合并相关主题。\n\n### AI 代理与自动决策模型\n- **The AI Scientist: Towards Fully Automated Open-Ended Scientific Discovery（The AI Scientist: 迈向完全自动化的开放式科学发现）**  \n  作者包括 Jeff Clune 和 David Ha，这篇论文提出一个框架，让大型语言模型自主生成研究想法、执行实验并撰写论文。核心贡献是通过端到端流程实现科学发现自动化，实验显示其在机器学习子领域（如扩散模型）中生成高质量论文，成本低于 15 美元，标志着 AI 在科研领域的重大进步。\n\n- **Towards Autonomous Agents: Adaptive-planning, Reasoning, and Acting in Language Models（Towards Autonomous Agents: 语言模型的自适应规划、推理和行动）**  \n  这篇论文开发了一种基于 Gemma-2-9B 模型的自校正算法，使代理在文本游戏环境中自主解决问题。主要发现是，通过自校正机制，模型能在失败后改进策略，成功完成部分任务，展示了语言模型在自主代理中的潜力。\n\n- **VisualAgentBench: Towards Large Multimodal Models as Visual Foundation Agents（VisualAgentBench: 迈向多模态大型模型作为视觉基础代理）**  \n  作者团队包括 Yu Su 和 Jie Tang，这篇论文引入一个基准数据集和框架，用于训练多模态模型处理视觉任务。核心贡献是通过混合方法构建轨迹训练集，提升模型在 Embodied 和 GUI 任务中的性能，实验显示其在多场景下表现出色，推动了视觉代理的通用化。\n\n- **Can We Rely on LLM Agents to Draft Long-Horizon Plans?（我们能依赖 LLM 代理来制定长期计划吗？）**  \n  这篇论文使用 TravelPlanner 基准测试 LLM 代理的规划鲁棒性。主要发现是，LLM 在长上下文和噪声环境中表现不佳，但通过 Feedback-Aware Fine-Tuning（FAFT）方法显著提升性能，强调了细调在实际规划中的重要性。\n\n### 多模态和生成模型\n- **Space-LLaVA: a Vision-Language Model Adapted to Extraterrestrial Applications（Space-LLaVA: 适应外太空应用的视觉-语言模型）**  \n  作者包括 Marco Pavone，这篇论文细调 LLaVA 模型以处理外太空数据。核心贡献是使用合成数据集提升模型在行星任务中的零样本性能，实验证明其在空间机器人应用中更鲁棒，填补了太空领域的 AI 空白。\n\n- **BI-MDRG: Bridging Image History in Multimodal Dialogue Response Generation（BI-MDRG: 在多模态对话响应生成中桥接图像历史）**  \n  这篇论文提出一个框架，使用时序提示嵌入改善多模态对话模型。核心发现是，模型能生成更相关和一致的响应，实验在基准数据集上提升了文本和图像输出质量，适用于复杂对话场景。\n\n- **FLEURS-R: A Restored Multilingual Speech Corpus for Generation Tasks（FLEURS-R: 用于生成任务的修复多语言语音语料库）**  \n  这篇论文扩展了 FLEURS 数据集，通过语音修复模型 Miipher 提升音频质量。主要贡献是为低资源语言的语音生成任务提供新资源，实验显示其在 TTS 等任务中显著改善性能。\n\n### 机器学习优化与应用\n- **Quantum Gradient Class Activation Map for Model Interpretability（量子梯度类激活映射用于模型可解释性）**  \n  这篇论文结合量子电路和激活映射，提出 QGrad-CAM 方法。核心贡献是通过量子-经典混合框架提升模型解释性，实验在图像和语音数据集上生成更细粒度的视觉解释，展示了量子机器学习在可解释 AI 中的潜力。\n\n- **Spacetime E(n)-Transformer: Equivariant Attention for Spatio-temporal Graphs（Spacetime E(n)-Transformer: 用于时空图的等变注意力机制）**  \n  这篇论文设计了一个 E(n)-等变 Transformer 架构，用于时空图数据处理。核心发现是，该模型在物理系统中（如带电 N 体问题） outperform 传统方法，证明了等变偏置在动态建模中的优势。\n\n- **Audit-LLM: Multi-Agent Collaboration for Log-based Insider Threat Detection（Audit-LLM: 用于基于日志的内部威胁检测的多代理协作）**  \n  这篇论文使用多代理 LLM 框架检测内部威胁。核心贡献是通过证据-based 辩论机制提升检测准确性和解释性，实验在公共数据集上达到 SOTA 性能，适用于安全领域。\n\n### 其他领域快速掠过\n其他论文涉及生物信息学、交通预测和语音处理等领域，但影响力相对较小，仅快速总结几点：\n- **PhaGO: Protein function annotation for bacteriophages（PhaGO: 针对噬菌体的蛋白功能注释）**（第35篇）：利用 Transformer 捕捉基因组上下文，提升蛋白功能注释准确性，适用于微生物生态研究。\n- **Med42-v2: A Suite of Clinical LLMs（Med42-v2: 临床大型语言模型套件）**（第33篇）：基于 Llama3 构建的医疗模型，优化了临床查询响应，实验显示在医疗基准上超越 GPT-4。\n- **Large Investment Model（大型投资模型）**（第63篇）：将 LLM 应用于量化投资，核心是端到端学习全球信号模式，提升投资策略泛化性。\n- 其余如交通预测的 Multi-View Neural Differential Equations（第8篇）和语音增强的 Audio Enhancement（第19篇）等，贡献在于特定领域优化，但未见重大突破，仅提供技术改进。\n\n总之，今天的 arXiv 更新突显了 AI 领域的创新活力，尤其在代理和多模态模型上。感兴趣的读者可关注 \"The AI Scientist\" 等论文，探索 AI 在科学和实际应用中的潜力。更多细节请查阅 arXiv！",
  "papers": [
    {
      "arxiv_id": "2408.06527v2",
      "title": "Rethinking the Alignment of Psychotherapy Dialogue Generation with Motivational Interviewing Strategies",
      "title_zh": "翻译失败",
      "authors": [
        "Xin Sun",
        "Xiao Tang",
        "Abdallah El Ali",
        "Zhuying Li",
        "Pengjie Ren",
        "Jan de Wit",
        "Jiahuan Pei",
        "Jos A. Bosch"
      ],
      "abstract": "Recent advancements in large language models (LLMs) have shown promise in\ngenerating psychotherapeutic dialogues, particularly in the context of\nmotivational interviewing (MI). However, the inherent lack of transparency in\nLLM outputs presents significant challenges given the sensitive nature of\npsychotherapy. Applying MI strategies, a set of MI skills, to generate more\ncontrollable therapeutic-adherent conversations with explainability provides a\npossible solution. In this work, we explore the alignment of LLMs with MI\nstrategies by first prompting the LLMs to predict the appropriate strategies as\nreasoning and then utilizing these strategies to guide the subsequent dialogue\ngeneration. We seek to investigate whether such alignment leads to more\ncontrollable and explainable generations. Multiple experiments including\nautomatic and human evaluations are conducted to validate the effectiveness of\nMI strategies in aligning psychotherapy dialogue generation. Our findings\ndemonstrate the potential of LLMs in producing strategically aligned dialogues\nand suggest directions for practical applications in psychotherapeutic\nsettings.",
      "tldr_zh": "该研究重新审视大型语言模型 (LLMs) 在生成心理治疗对话时的与动机性访谈 (MI) 策略的 alignment问题，旨在解决LLMs输出缺乏透明度的挑战。方法包括先提示LLMs预测合适的MI策略作为推理过程，然后利用这些策略指导后续对话生成，以实现更可控和可解释的对话。实验通过自动和人工评估验证了这一方法的有效性，结果表明LLMs能够产生策略对齐的对话，并为心理治疗实际应用提供潜在方向。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.06527v2",
      "published_date": "2024-08-12 23:19:02 UTC",
      "updated_date": "2024-12-17 16:44:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:36:34.978901"
    },
    {
      "arxiv_id": "2408.06512v1",
      "title": "Learned Ranking Function: From Short-term Behavior Predictions to Long-term User Satisfaction",
      "title_zh": "翻译失败",
      "authors": [
        "Yi Wu",
        "Daryl Chang",
        "Jennifer She",
        "Zhe Zhao",
        "Li Wei",
        "Lukasz Heldt"
      ],
      "abstract": "We present the Learned Ranking Function (LRF), a system that takes short-term\nuser-item behavior predictions as input and outputs a slate of recommendations\nthat directly optimizes for long-term user satisfaction. Most previous work is\nbased on optimizing the hyperparameters of a heuristic function. We propose to\nmodel the problem directly as a slate optimization problem with the objective\nof maximizing long-term user satisfaction. We also develop a novel constraint\noptimization algorithm that stabilizes objective trade-offs for multi-objective\noptimization. We evaluate our approach with live experiments and describe its\ndeployment on YouTube.",
      "tldr_zh": "本文提出 Learned Ranking Function (LRF)，一个系统将短期用户-物品行为预测作为输入，生成优化长期用户满意度的推荐列表，从而直接解决多目标优化问题。不同于以往基于启发式函数超参数优化的方法，LRF 将问题建模为 slate optimization 问题，并开发了一个新型约束优化算法来稳定多目标间的权衡。通过实时实验评估，LRF 在 YouTube 上成功部署，展示了其在提升用户满意度方面的实际效果。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.LG",
      "comment": "RecSys 24",
      "pdf_url": "http://arxiv.org/pdf/2408.06512v1",
      "published_date": "2024-08-12 22:02:39 UTC",
      "updated_date": "2024-08-12 22:02:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:36:46.653089"
    },
    {
      "arxiv_id": "2408.06509v1",
      "title": "Fooling SHAP with Output Shuffling Attacks",
      "title_zh": "翻译失败",
      "authors": [
        "Jun Yuan",
        "Aritra Dasgupta"
      ],
      "abstract": "Explainable AI~(XAI) methods such as SHAP can help discover feature\nattributions in black-box models. If the method reveals a significant\nattribution from a ``protected feature'' (e.g., gender, race) on the model\noutput, the model is considered unfair. However, adversarial attacks can\nsubvert the detection of XAI methods. Previous approaches to constructing such\nan adversarial model require access to underlying data distribution, which may\nnot be possible in many practical scenarios. We relax this constraint and\npropose a novel family of attacks, called shuffling attacks, that are\ndata-agnostic. The proposed attack strategies can adapt any trained machine\nlearning model to fool Shapley value-based explanations. We prove that Shapley\nvalues cannot detect shuffling attacks. However, algorithms that estimate\nShapley values, such as linear SHAP and SHAP, can detect these attacks with\nvarying degrees of effectiveness. We demonstrate the efficacy of the attack\nstrategies by comparing the performance of linear SHAP and SHAP using\nreal-world datasets.",
      "tldr_zh": "本研究提出了一种数据无关的攻击方法，称为 shuffling attacks，用于欺骗基于 Shapley values 的可解释 AI (XAI) 解释工具，如 SHAP。这些攻击可以适应任何训练好的机器学习模型，通过输出 shuffling 策略隐藏模型对受保护特征（如性别、种族）的归因，从而规避不公平检测。作者证明了 Shapley values 理论上无法识别这些攻击，而实际算法如 linear SHAP 和 SHAP 只能在不同程度上检测它们。在真实数据集上的实验结果显示，该攻击策略有效，突显了 XAI 方法的潜在漏洞。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.06509v1",
      "published_date": "2024-08-12 21:57:18 UTC",
      "updated_date": "2024-08-12 21:57:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:37:01.392277"
    },
    {
      "arxiv_id": "2408.06507v1",
      "title": "Benchmarking tree species classification from proximally-sensed laser scanning data: introducing the FOR-species20K dataset",
      "title_zh": "基于近距离感知激光扫描数据的树种分类基准测试：介绍 FOR-species20K 数据集",
      "authors": [
        "Stefano Puliti",
        "Emily R. Lines",
        "Jana Müllerová",
        "Julian Frey",
        "Zoe Schindler",
        "Adrian Straker",
        "Matthew J. Allen",
        "Lukas Winiwarter",
        "Nataliia Rehush",
        "Hristina Hristova",
        "Brent Murray",
        "Kim Calders",
        "Louise Terryn",
        "Nicholas Coops",
        "Bernhard Höfle",
        "Samuli Junttila",
        "Martin Krůček",
        "Grzegorz Krok",
        "Kamil Král",
        "Shaun R. Levick",
        "Linda Luck",
        "Azim Missarov",
        "Martin Mokroš",
        "Harry J. F. Owen",
        "Krzysztof Stereńczak",
        "Timo P. Pitkänen",
        "Nicola Puletti",
        "Ninni Saarinen",
        "Chris Hopkinson",
        "Chiara Torresan",
        "Enrico Tomelleri",
        "Hannah Weiser",
        "Rasmus Astrup"
      ],
      "abstract": "Proximally-sensed laser scanning offers significant potential for automated\nforest data capture, but challenges remain in automatically identifying tree\nspecies without additional ground data. Deep learning (DL) shows promise for\nautomation, yet progress is slowed by the lack of large, diverse, openly\navailable labeled datasets of single tree point clouds. This has impacted the\nrobustness of DL models and the ability to establish best practices for species\nclassification.\n  To overcome these challenges, the FOR-species20K benchmark dataset was\ncreated, comprising over 20,000 tree point clouds from 33 species, captured\nusing terrestrial (TLS), mobile (MLS), and drone laser scanning (ULS) across\nvarious European forests, with some data from other regions. This dataset\nenables the benchmarking of DL models for tree species classification,\nincluding both point cloud-based (PointNet++, MinkNet, MLP-Mixer, DGCNNs) and\nmulti-view image-based methods (SimpleView, DetailView, YOLOv5).\n  2D image-based models generally performed better (average OA = 0.77) than 3D\npoint cloud-based models (average OA = 0.72), with consistent results across\ndifferent scanning platforms and sensors. The top model, DetailView, was\nparticularly robust, handling data imbalances well and generalizing effectively\nacross tree sizes.\n  The FOR-species20K dataset, available at https://zenodo.org/records/13255198,\nis a key resource for developing and benchmarking DL models for tree species\nclassification using laser scanning data, providing a foundation for future\nadvancements in the field.",
      "tldr_zh": "该研究介绍了 FOR-species20K 数据集，这是一个包含超过 20,000 个树点云数据的基准数据集，用于评估基于 Deep Learning (DL) 的树种分类模型。数据集涵盖 33 个树种，采用陆基激光扫描 (TLS)、移动激光扫描 (MLS) 和无人机激光扫描 (ULS) 等技术，采集自欧洲及其他地区的森林，以解决缺乏大型开放标注数据集的挑战。研究基准测试了多种 DL 模型，包括基于点云的 (PointNet++, MinkNet, MLP-Mixer, DGCNNs) 和基于多视图图像的 (SimpleView, DetailView, YOLOv5) 方法，结果显示 2D 图像-based 模型的平均 Overall Accuracy (OA) 为 0.77，高于 3D 点云-based 模型的 0.72，且 DetailView 模型在处理数据不平衡和泛化方面表现出色。该数据集可从 https://zenodo.org/records/13255198 获取，将为未来激光扫描树种分类研究提供重要基础。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.06507v1",
      "published_date": "2024-08-12 21:47:15 UTC",
      "updated_date": "2024-08-12 21:47:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:37:14.830933"
    },
    {
      "arxiv_id": "2408.06503v2",
      "title": "Enhancing Heterogeneous Multi-Agent Cooperation in Decentralized MARL via GNN-driven Intrinsic Rewards",
      "title_zh": "通过 GNN 驱动的内在奖励增强去中心化 MARL 中的异构多智能体合作",
      "authors": [
        "Jahir Sadik Monon",
        "Deeparghya Dutta Barua",
        "Md. Mosaddek Khan"
      ],
      "abstract": "Multi-agent Reinforcement Learning (MARL) is emerging as a key framework for\nvarious sequential decision-making and control tasks. Unlike their single-agent\ncounterparts, multi-agent systems necessitate successful cooperation among the\nagents. The deployment of these systems in real-world scenarios often requires\ndecentralized training, a diverse set of agents, and learning from infrequent\nenvironmental reward signals. These challenges become more pronounced under\npartial observability and the lack of prior knowledge about agent\nheterogeneity. While notable studies use intrinsic motivation (IM) to address\nreward sparsity or cooperation in decentralized settings, those dealing with\nheterogeneity typically assume centralized training, parameter sharing, and\nagent indexing. To overcome these limitations, we propose the CoHet algorithm,\nwhich utilizes a novel Graph Neural Network (GNN) based intrinsic motivation to\nfacilitate the learning of heterogeneous agent policies in decentralized\nsettings, under the challenges of partial observability and reward sparsity.\nEvaluation of CoHet in the Multi-agent Particle Environment (MPE) and\nVectorized Multi-Agent Simulator (VMAS) benchmarks demonstrates superior\nperformance compared to the state-of-the-art in a range of cooperative\nmulti-agent scenarios. Our research is supplemented by an analysis of the\nimpact of the agent dynamics model on the intrinsic motivation module, insights\ninto the performance of different CoHet variants, and its robustness to an\nincreasing number of heterogeneous agents.",
      "tldr_zh": "该研究针对多智能体强化学习（MARL）中的异构代理合作问题，提出了一种名为 CoHet 的算法，以解决去中心化训练、部分可观察性和奖励稀疏性的挑战。CoHet 利用基于 Graph Neural Network (GNN) 的内在动机（intrinsic motivation）模块，帮助代理在分散环境中学习高效策略，从而提升合作效率。在 Multi-agent Particle Environment (MPE) 和 Vectorized Multi-Agent Simulator (VMAS) 基准测试中，CoHet 表现出优于现有方法的性能，并通过分析代理动态模型的影响和不同变体的鲁棒性，证明了其在扩展异构代理场景中的适用性。",
      "categories": [
        "cs.MA",
        "cs.AI",
        "cs.RO",
        "I.2.6; I.2.9; I.2.11"
      ],
      "primary_category": "cs.MA",
      "comment": "9 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2408.06503v2",
      "published_date": "2024-08-12 21:38:40 UTC",
      "updated_date": "2024-10-15 02:18:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:37:33.080860"
    },
    {
      "arxiv_id": "2408.06484v1",
      "title": "Cross-Lingual Conversational Speech Summarization with Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Max Nelson",
        "Shannon Wotherspoon",
        "Francis Keith",
        "William Hartmann",
        "Matthew Snover"
      ],
      "abstract": "Cross-lingual conversational speech summarization is an important problem,\nbut suffers from a dearth of resources. While transcriptions exist for a number\nof languages, translated conversational speech is rare and datasets containing\nsummaries are non-existent. We build upon the existing Fisher and Callhome\nSpanish-English Speech Translation corpus by supplementing the translations\nwith summaries. The summaries are generated using GPT-4 from the reference\ntranslations and are treated as ground truth. The task is to generate similar\nsummaries in the presence of transcription and translation errors. We build a\nbaseline cascade-based system using open-source speech recognition and machine\ntranslation models. We test a range of LLMs for summarization and analyze the\nimpact of transcription and translation errors. Adapting the Mistral-7B model\nfor this task performs significantly better than off-the-shelf models and\nmatches the performance of GPT-4.",
      "tldr_zh": "该研究解决了跨语言对话语音摘要(Cross-Lingual Conversational Speech Summarization)资源匮乏的问题，通过在Fisher和Callhome Spanish-English Speech Translation语料库基础上添加GPT-4生成的摘要作为ground truth数据集。作者构建了一个基线级联系统，使用开源语音识别和机器翻译模型来处理转录和翻译错误，并测试多种Large Language Models(LLMs)进行摘要生成。结果显示，适应后的Mistral-7B模型在性能上显著优于现成模型，并与GPT-4相当，证明了其在错误处理中的有效性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.06484v1",
      "published_date": "2024-08-12 20:40:46 UTC",
      "updated_date": "2024-08-12 20:40:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:37:34.562723"
    },
    {
      "arxiv_id": "2408.06458v2",
      "title": "Towards Autonomous Agents: Adaptive-planning, Reasoning, and Acting in Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Abhishek Dutta",
        "Yen-Che Hsiao"
      ],
      "abstract": "We propose a novel in-context learning algorithm for building autonomous\ndecision-making language agents. The language agent continuously attempts to\nsolve the same task by self-correcting each time the task fails. Our selected\nlanguage agent demonstrates the ability to solve tasks in a text-based game\nenvironment. Our results show that the gemma-2-9b-it language model, using our\nproposed method, can successfully complete two of six tasks that failed in the\nfirst attempt. This highlights the effectiveness of our approach in enhancing\nthe problem-solving capabilities of a single language model through\nself-correction, paving the way for more advanced autonomous agents. The code\nis publicly available at\nhttps://github.com/YenCheHsiao/AutonomousLLMAgentwithAdaptingPlanning.",
      "tldr_zh": "本研究提出了一种新型 in-context learning 算法，用于构建自主决策的语言代理，该代理通过自我修正机制在任务失败后不断尝试解决问题。\n在文本游戏环境中，gemma-2-9b-it 语言模型应用该方法后，成功完成了最初失败的六个任务中的两个。\n这项工作展示了自我修正策略在提升语言模型的规划、推理和行动能力方面的有效性，并为更先进的自主代理的发展奠定基础。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.06458v2",
      "published_date": "2024-08-12 19:18:05 UTC",
      "updated_date": "2024-11-04 21:04:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:37:50.682231"
    },
    {
      "arxiv_id": "2408.06445v1",
      "title": "Multi-View Neural Differential Equations for Continuous-Time Stream Data in Long-Term Traffic Forecasting",
      "title_zh": "多视图神经微分方程用于长期交通预测中的连续时间流",
      "authors": [
        "Zibo Liu",
        "Zhe Jiang",
        "Shigang Chen"
      ],
      "abstract": "Long-term traffic flow forecasting plays a crucial role in intelligent\ntransportation as it allows traffic managers to adjust their decisions in\nadvance. However, the problem is challenging due to spatio-temporal\ncorrelations and complex dynamic patterns in continuous-time stream data.\nNeural Differential Equations (NDEs) are among the state-of-the-art methods for\nlearning continuous-time traffic dynamics. However, the traditional NDE models\nface issues in long-term traffic forecasting due to failures in capturing\ndelayed traffic patterns, dynamic edge (location-to-location correlation)\npatterns, and abrupt trend patterns. To fill this gap, we propose a new NDE\narchitecture called Multi-View Neural Differential Equations. Our model\ncaptures current states, delayed states, and trends in different state\nvariables (views) by learning latent multiple representations within Neural\nDifferential Equations. Extensive experiments conducted on several real-world\ntraffic datasets demonstrate that our proposed method outperforms the\nstate-of-the-art and achieves superior prediction accuracy for long-term\nforecasting and robustness with noisy or missing inputs.",
      "tldr_zh": "长期交通流量预测在智能交通中至关重要，因为它能帮助管理者提前调整决策，但面临时空相关性和复杂动态模式的挑战。传统 Neural Differential Equations (NDEs) 在处理延迟交通模式、动态边模式（位置间相关性）和突发趋势模式时存在不足。为此，本文提出 Multi-View Neural Differential Equations 模型，通过在 NDEs 中学习潜在的多重表示，捕捉不同状态变量（视图）中的当前状态、延迟状态和趋势。实验结果显示，该方法在多个真实世界交通数据集上优于最先进方法，在长期预测准确性和对噪声或缺失输入的鲁棒性方面表现出色。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.06445v1",
      "published_date": "2024-08-12 18:49:02 UTC",
      "updated_date": "2024-08-12 18:49:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:38:00.816872"
    },
    {
      "arxiv_id": "2408.06423v3",
      "title": "Evaluating LLMs on Entity Disambiguation in Tables",
      "title_zh": "翻译失败",
      "authors": [
        "Federico Belotti",
        "Fabio Dadda",
        "Marco Cremaschi",
        "Roberto Avogadro",
        "Matteo Palmonari"
      ],
      "abstract": "Tables are crucial containers of information, but understanding their meaning\nmay be challenging. Over the years, there has been a surge in interest in\ndata-driven approaches based on deep learning that have increasingly been\ncombined with heuristic-based ones. In the last period, the advent of\n\\acf{llms} has led to a new category of approaches for table annotation.\nHowever, these approaches have not been consistently evaluated on a common\nground, making evaluation and comparison difficult. This work proposes an\nextensive evaluation of four STI SOTA approaches: Alligator (formerly s-elbat),\nDagobah, TURL, and TableLlama; the first two belong to the family of\nheuristic-based algorithms, while the others are respectively encoder-only and\ndecoder-only Large Language Models (LLMs). We also include in the evaluation\nboth GPT-4o and GPT-4o-mini, since they excel in various public benchmarks. The\nprimary objective is to measure the ability of these approaches to solve the\nentity disambiguation task with respect to both the performance achieved on a\ncommon-ground evaluation setting and the computational and cost requirements\ninvolved, with the ultimate aim of charting new research paths in the field.",
      "tldr_zh": "本研究评估了大型语言模型(LLMs)在表格实体消歧(Entity Disambiguation)任务中的性能，针对传统启发式方法和新兴LLMs方法进行了全面比较。论文选取了四种SOTA方法（Alligator、Dagobah、TURL和TableLlama）以及GPT-4o和GPT-4o-mini，在统一评估设置下测试了它们的准确性、计算成本和效率。结果显示，这些方法在性能上存在显著差异，为未来表格注解研究指明了新方向，并强调了平衡性能与资源需求的必要性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "13 pages, 6 figures; fixed avg. accuracy-over-price plot for GPT\n  families, fixed typos in table referencing, added evaluation and inference\n  subsubsection",
      "pdf_url": "http://arxiv.org/pdf/2408.06423v3",
      "published_date": "2024-08-12 18:01:50 UTC",
      "updated_date": "2024-10-31 18:43:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:38:10.348760"
    },
    {
      "arxiv_id": "2408.06335v1",
      "title": "LOLgorithm: Integrating Semantic,Syntactic and Contextual Elements for Humor Classification",
      "title_zh": "LOLgorithm：整合语义、句法和语境元素用于幽",
      "authors": [
        "Tanisha Khurana",
        "Kaushik Pillalamarri",
        "Vikram Pande",
        "Munindar Singh"
      ],
      "abstract": "This paper explores humor detection through a linguistic lens, prioritizing\nsyntactic, semantic, and contextual features over computational methods in\nNatural Language Processing. We categorize features into syntactic, semantic,\nand contextual dimensions, including lexicons, structural statistics, Word2Vec,\nWordNet, and phonetic style. Our proposed model, Colbert, utilizes BERT\nembeddings and parallel hidden layers to capture sentence congruity. By\ncombining syntactic, semantic, and contextual features, we train Colbert for\nhumor detection. Feature engineering examines essential syntactic and semantic\nfeatures alongside BERT embeddings. SHAP interpretations and decision trees\nidentify influential features, revealing that a holistic approach improves\nhumor detection accuracy on unseen data. Integrating linguistic cues from\ndifferent dimensions enhances the model's ability to understand humor\ncomplexity beyond traditional computational methods.",
      "tldr_zh": "本论文提出LOLgorithm框架，通过整合Semantic、Syntactic和Contextual元素来提升幽默分类的准确性，优先考虑语言学特征而非单纯的NLP计算方法。模型Colbert利用BERT embeddings和并行隐藏层捕捉句子一致性，并结合特征工程（如lexicons、structural statistics、Word2Vec、WordNet和phonetic style）进行训练，同时采用SHAP解释和决策树识别关键影响特征。结果显示，这种整体方法显著提高了对未知数据的幽默检测性能，超越传统方法更好地理解幽默的复杂性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.06335v1",
      "published_date": "2024-08-12 17:52:11 UTC",
      "updated_date": "2024-08-12 17:52:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:38:24.680722"
    },
    {
      "arxiv_id": "2408.06327v1",
      "title": "VisualAgentBench: Towards Large Multimodal Models as Visual Foundation Agents",
      "title_zh": "翻译失败",
      "authors": [
        "Xiao Liu",
        "Tianjie Zhang",
        "Yu Gu",
        "Iat Long Iong",
        "Yifan Xu",
        "Xixuan Song",
        "Shudan Zhang",
        "Hanyu Lai",
        "Xinyi Liu",
        "Hanlin Zhao",
        "Jiadai Sun",
        "Xinyue Yang",
        "Yu Yang",
        "Zehan Qi",
        "Shuntian Yao",
        "Xueqiao Sun",
        "Siyi Cheng",
        "Qinkai Zheng",
        "Hao Yu",
        "Hanchen Zhang",
        "Wenyi Hong",
        "Ming Ding",
        "Lihang Pan",
        "Xiaotao Gu",
        "Aohan Zeng",
        "Zhengxiao Du",
        "Chan Hee Song",
        "Yu Su",
        "Yuxiao Dong",
        "Jie Tang"
      ],
      "abstract": "Large Multimodal Models (LMMs) have ushered in a new era in artificial\nintelligence, merging capabilities in both language and vision to form highly\ncapable Visual Foundation Agents. These agents are postulated to excel across a\nmyriad of tasks, potentially approaching general artificial intelligence.\nHowever, existing benchmarks fail to sufficiently challenge or showcase the\nfull potential of LMMs in complex, real-world environments. To address this\ngap, we introduce VisualAgentBench (VAB), a comprehensive and pioneering\nbenchmark specifically designed to train and evaluate LMMs as visual foundation\nagents across diverse scenarios, including Embodied, Graphical User Interface,\nand Visual Design, with tasks formulated to probe the depth of LMMs'\nunderstanding and interaction capabilities. Through rigorous testing across\nnine proprietary LMM APIs and eight open models, we demonstrate the\nconsiderable yet still developing agent capabilities of these models.\nAdditionally, VAB constructs a trajectory training set constructed through\nhybrid methods including Program-based Solvers, LMM Agent Bootstrapping, and\nHuman Demonstrations, promoting substantial performance improvements in LMMs\nthrough behavior cloning. Our work not only aims to benchmark existing models\nbut also provides a solid foundation for future development into visual\nfoundation agents. Code, train \\& test data, and part of fine-tuned open LMMs\nare available at \\url{https://github.com/THUDM/VisualAgentBench}.",
      "tldr_zh": "本研究引入了VisualAgentBench (VAB)，一个全面基准，用于训练和评估Large Multimodal Models (LMMs) 作为视觉基础代理，旨在填补现有基准在复杂真实环境中的不足。VAB涵盖Embodied、Graphical User Interface 和Visual Design 等多样场景，通过混合方法构建轨迹训练集，包括Program-based Solvers、LMM Agent Bootstrapping 和Human Demonstrations，并通过行为克隆显著提升LMMs的性能。实验测试了九个专有LMM API和八个开源模型，结果显示这些模型的代理能力虽有进步，但仍有发展空间；论文同时提供代码、数据和部分微调模型以支持未来研究。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.CV"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.06327v1",
      "published_date": "2024-08-12 17:44:17 UTC",
      "updated_date": "2024-08-12 17:44:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:38:39.584021"
    },
    {
      "arxiv_id": "2408.06318v1",
      "title": "Can We Rely on LLM Agents to Draft Long-Horizon Plans? Let's Take TravelPlanner as an Example",
      "title_zh": "我们能依赖 LLM 代理来起草长远规划吗？让我们以 TravelPlanner 为例",
      "authors": [
        "Yanan Chen",
        "Ali Pesaranghader",
        "Tanmana Sadhu",
        "Dong Hoon Yi"
      ],
      "abstract": "Large language models (LLMs) have brought autonomous agents closer to\nartificial general intelligence (AGI) due to their promising generalization and\nemergent capabilities. There is, however, a lack of studies on how LLM-based\nagents behave, why they could potentially fail, and how to improve them,\nparticularly in demanding real-world planning tasks. In this paper, as an\neffort to fill the gap, we present our study using a realistic benchmark,\nTravelPlanner, where an agent must meet multiple constraints to generate\naccurate plans. We leverage this benchmark to address four key research\nquestions: (1) are LLM agents robust enough to lengthy and noisy contexts when\nit comes to reasoning and planning? (2) can few-shot prompting adversely impact\nthe performance of LLM agents in scenarios with long context? (3) can we rely\non refinement to improve plans, and (4) can fine-tuning LLMs with both positive\nand negative feedback lead to further improvement? Our comprehensive\nexperiments indicate that, firstly, LLMs often fail to attend to crucial parts\nof a long context, despite their ability to handle extensive reference\ninformation and few-shot examples; secondly, they still struggle with analyzing\nthe long plans and cannot provide accurate feedback for refinement; thirdly, we\npropose Feedback-Aware Fine-Tuning (FAFT), which leverages both positive and\nnegative feedback, resulting in substantial gains over Supervised Fine-Tuning\n(SFT). Our findings offer in-depth insights to the community on various aspects\nrelated to real-world planning applications.",
      "tldr_zh": "本研究探讨大型语言模型 (LLMs) 作为自主代理在制定长时段计划时的可靠性和局限性，以 TravelPlanner 基准为例，评估 LLMs 在处理长而嘈杂上下文时的表现。论文针对四个关键问题进行实验，发现 LLMs 常忽略关键信息，少样本提示 (few-shot prompting) 可能负面影响表现，且计划精炼方法效果有限。作者提出 Feedback-Aware Fine-Tuning (FAFT) 技术，通过整合正负反馈显著提升性能，相比 Supervised Fine-Tuning (SFT) 获得实质性改进，并为现实规划应用提供深入见解。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "13 pages, 2 figures, 4 tables",
      "pdf_url": "http://arxiv.org/pdf/2408.06318v1",
      "published_date": "2024-08-12 17:39:01 UTC",
      "updated_date": "2024-08-12 17:39:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:38:51.272815"
    },
    {
      "arxiv_id": "2408.06316v1",
      "title": "Body Transformer: Leveraging Robot Embodiment for Policy Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Carmelo Sferrazza",
        "Dun-Ming Huang",
        "Fangchen Liu",
        "Jongmin Lee",
        "Pieter Abbeel"
      ],
      "abstract": "In recent years, the transformer architecture has become the de facto\nstandard for machine learning algorithms applied to natural language processing\nand computer vision. Despite notable evidence of successful deployment of this\narchitecture in the context of robot learning, we claim that vanilla\ntransformers do not fully exploit the structure of the robot learning problem.\nTherefore, we propose Body Transformer (BoT), an architecture that leverages\nthe robot embodiment by providing an inductive bias that guides the learning\nprocess. We represent the robot body as a graph of sensors and actuators, and\nrely on masked attention to pool information throughout the architecture. The\nresulting architecture outperforms the vanilla transformer, as well as the\nclassical multilayer perceptron, in terms of task completion, scaling\nproperties, and computational efficiency when representing either imitation or\nreinforcement learning policies. Additional material including the open-source\ncode is available at https://sferrazza.cc/bot_site.",
      "tldr_zh": "该研究指出，传统的Transformer架构在机器人学习中未能充分利用机器人实体结构，因此提出Body Transformer (BoT)架构，通过提供归纳偏差(inductive bias)来引导学习过程。具体而言，BoT将机器人身体表示为传感器和执行器的图，并使用masked attention机制聚合信息，从而提升策略学习效率。实验结果显示，BoT在任务完成、扩展性能和计算效率上优于vanilla transformer和多层感知器(multilayer perceptron)，适用于模仿学习(imitation learning)和强化学习(reinforcement learning policies)场景，并提供了开源代码支持。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.06316v1",
      "published_date": "2024-08-12 17:31:28 UTC",
      "updated_date": "2024-08-12 17:31:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:39:01.035153"
    },
    {
      "arxiv_id": "2408.06310v2",
      "title": "OWL2Vec4OA: Tailoring Knowledge Graph Embeddings for Ontology Alignment",
      "title_zh": "OWL2Vec4OA：为本体对齐定制知识图谱嵌入",
      "authors": [
        "Sevinj Teymurova",
        "Ernesto Jiménez-Ruiz",
        "Tillman Weyde",
        "Jiaoyan Chen"
      ],
      "abstract": "Ontology alignment is integral to achieving semantic interoperability as the\nnumber of available ontologies covering intersecting domains is increasing.\nThis paper proposes OWL2Vec4OA, an extension of the ontology embedding system\nOWL2Vec*. While OWL2Vec* has emerged as a powerful technique for ontology\nembedding, it currently lacks a mechanism to tailor the embedding to the\nontology alignment task. OWL2Vec4OA incorporates edge confidence values from\nseed mappings to guide the random walk strategy. We present the theoretical\nfoundations, implementation details, and experimental evaluation of our\nproposed extension, demonstrating its potential effectiveness for ontology\nalignment tasks.",
      "tldr_zh": "本论文提出 OWL2Vec4OA，这是一种针对本体对齐（Ontology Alignment）任务的知识图嵌入（Knowledge Graph Embeddings）扩展方法，基于 OWL2Vec* 的框架。OWL2Vec4OA 通过整合种子映射的边置信值来指导随机游走（Random Walk）策略，从而更好地适应本体对齐的需求。论文详细阐述了其理论基础、实现细节，并通过实验评估证明了该方法的潜在有效性，在提升本体对齐性能方面表现出色。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted to the 6th Knowledge Graph and Semantic Web Conference",
      "pdf_url": "http://arxiv.org/pdf/2408.06310v2",
      "published_date": "2024-08-12 17:24:19 UTC",
      "updated_date": "2024-10-23 09:59:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:39:12.641814"
    },
    {
      "arxiv_id": "2408.06292v3",
      "title": "The AI Scientist: Towards Fully Automated Open-Ended Scientific Discovery",
      "title_zh": "The AI Scientist：朝向完全自动化的开放式科学发现",
      "authors": [
        "Chris Lu",
        "Cong Lu",
        "Robert Tjarko Lange",
        "Jakob Foerster",
        "Jeff Clune",
        "David Ha"
      ],
      "abstract": "One of the grand challenges of artificial general intelligence is developing\nagents capable of conducting scientific research and discovering new knowledge.\nWhile frontier models have already been used as aides to human scientists, e.g.\nfor brainstorming ideas, writing code, or prediction tasks, they still conduct\nonly a small part of the scientific process. This paper presents the first\ncomprehensive framework for fully automatic scientific discovery, enabling\nfrontier large language models to perform research independently and\ncommunicate their findings. We introduce The AI Scientist, which generates\nnovel research ideas, writes code, executes experiments, visualizes results,\ndescribes its findings by writing a full scientific paper, and then runs a\nsimulated review process for evaluation. In principle, this process can be\nrepeated to iteratively develop ideas in an open-ended fashion, acting like the\nhuman scientific community. We demonstrate its versatility by applying it to\nthree distinct subfields of machine learning: diffusion modeling,\ntransformer-based language modeling, and learning dynamics. Each idea is\nimplemented and developed into a full paper at a cost of less than $15 per\npaper. To evaluate the generated papers, we design and validate an automated\nreviewer, which we show achieves near-human performance in evaluating paper\nscores. The AI Scientist can produce papers that exceed the acceptance\nthreshold at a top machine learning conference as judged by our automated\nreviewer. This approach signifies the beginning of a new era in scientific\ndiscovery in machine learning: bringing the transformative benefits of AI\nagents to the entire research process of AI itself, and taking us closer to a\nworld where endless affordable creativity and innovation can be unleashed on\nthe world's most challenging problems. Our code is open-sourced at\nhttps://github.com/SakanaAI/AI-Scientist",
      "tldr_zh": "这篇论文提出了 The AI Scientist 框架，这是一个全面的自动化系统，旨在让大型语言模型(large language models)独立进行科学发现，包括生成研究想法、编写代码、执行实验、可视化结果、撰写完整论文以及模拟审稿过程。框架支持开放式迭代发展，并应用于机器学习的子领域如扩散建模(diffusion modeling)、基于变换器的语言建模(transformer-based language modeling)和学习动态(learning dynamics)，每个生成的论文成本低于15美元。通过设计的自动化审稿人(automated reviewer)，其性能接近人类水平，生成的论文可超过顶级机器学习会议的接受阈值。该框架标志着AI在科学研究中的新纪元，推动低成本创新解决全球挑战。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.06292v3",
      "published_date": "2024-08-12 16:58:11 UTC",
      "updated_date": "2024-09-01 00:41:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:39:26.918517"
    },
    {
      "arxiv_id": "2408.06285v1",
      "title": "Synthetic Patient-Physician Dialogue Generation from Clinical Notes Using LLM",
      "title_zh": "翻译失败",
      "authors": [
        "Trisha Das",
        "Dina Albassam",
        "Jimeng Sun"
      ],
      "abstract": "Medical dialogue systems (MDS) enhance patient-physician communication,\nimprove healthcare accessibility, and reduce costs. However, acquiring suitable\ndata to train these systems poses significant challenges. Privacy concerns\nprevent the use of real conversations, necessitating synthetic alternatives.\nSynthetic dialogue generation from publicly available clinical notes offers a\npromising solution to this issue, providing realistic data while safeguarding\nprivacy. Our approach, SynDial, uses a single LLM iteratively with zero-shot\nprompting and a feedback loop to generate and refine high-quality synthetic\ndialogues. The feedback consists of weighted evaluation scores for similarity\nand extractiveness. The iterative process ensures dialogues meet predefined\nthresholds, achieving superior extractiveness as a result of the feedback loop.\nAdditionally, evaluation shows that the generated dialogues excel in factuality\nmetric compared to the baselines and has comparable diversity scores with GPT4.",
      "tldr_zh": "该研究提出 SynDial 方法，使用 LLM 从临床笔记生成合成患者-医师对话，以解决医疗对话系统（MDS）数据获取的隐私问题。方法采用零-shot prompting 和反馈循环，基于相似性和提取性的加权评估分数进行迭代生成和精炼，确保对话达到预定义质量阈值。实验结果表明，生成的对话在事实性指标上优于基线模型，并在多样性方面与 GPT-4 相当，从而为训练 MDS 提供高效的隐私保护数据。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.06285v1",
      "published_date": "2024-08-12 16:49:22 UTC",
      "updated_date": "2024-08-12 16:49:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:39:38.538824"
    },
    {
      "arxiv_id": "2408.06281v1",
      "title": "MovieSum: An Abstractive Summarization Dataset for Movie Screenplays",
      "title_zh": "MovieSum: 电影剧本抽象式摘要生成数据集",
      "authors": [
        "Rohit Saxena",
        "Frank Keller"
      ],
      "abstract": "Movie screenplay summarization is challenging, as it requires an\nunderstanding of long input contexts and various elements unique to movies.\nLarge language models have shown significant advancements in document\nsummarization, but they often struggle with processing long input contexts.\nFurthermore, while television transcripts have received attention in recent\nstudies, movie screenplay summarization remains underexplored. To stimulate\nresearch in this area, we present a new dataset, MovieSum, for abstractive\nsummarization of movie screenplays. This dataset comprises 2200 movie\nscreenplays accompanied by their Wikipedia plot summaries. We manually\nformatted the movie screenplays to represent their structural elements.\nCompared to existing datasets, MovieSum possesses several distinctive features:\n(1) It includes movie screenplays, which are longer than scripts of TV\nepisodes. (2) It is twice the size of previous movie screenplay datasets. (3)\nIt provides metadata with IMDb IDs to facilitate access to additional external\nknowledge. We also show the results of recently released large language models\napplied to summarization on our dataset to provide a detailed baseline.",
      "tldr_zh": "本论文介绍了MovieSum数据集，用于电影剧本的抽象总结(abstractive summarization)，以解决大语言模型(large language models)处理长输入上下文和电影独有元素时的挑战。数据集包含2200部电影剧本及其维基百科情节总结，并通过手动格式化突出结构元素，其特点包括剧本长度更长、规模是现有数据集的两倍，并提供IMDb ID元数据以便访问外部知识。论文还评估了最近发布的大语言模型在MovieSum上的总结性能，作为详细基准，促进该领域的进一步研究。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "ACL 2024 Findings",
      "pdf_url": "http://arxiv.org/pdf/2408.06281v1",
      "published_date": "2024-08-12 16:43:09 UTC",
      "updated_date": "2024-08-12 16:43:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:40:00.771984"
    },
    {
      "arxiv_id": "2408.06266v5",
      "title": "Anchored Preference Optimization and Contrastive Revisions: Addressing Underspecification in Alignment",
      "title_zh": "翻译失败",
      "authors": [
        "Karel D'Oosterlinck",
        "Winnie Xu",
        "Chris Develder",
        "Thomas Demeester",
        "Amanpreet Singh",
        "Christopher Potts",
        "Douwe Kiela",
        "Shikib Mehri"
      ],
      "abstract": "Large Language Models (LLMs) are often aligned using contrastive alignment\nobjectives and preference pair datasets. The interaction between model, paired\ndata, and objective makes alignment a complicated procedure, sometimes\nproducing subpar results. We study this and find that (i) preference data gives\na better learning signal when the underlying responses are contrastive, and\n(ii) alignment objectives lead to better performance when they specify more\ncontrol over the model during training. Based on these insights, we introduce\nContrastive Learning from AI Revisions (CLAIR), a data-creation method which\nleads to more contrastive preference pairs, and Anchored Preference\nOptimization (APO), a controllable and more stable alignment objective. We\nalign Llama-3-8B-Instruct using various comparable datasets and alignment\nobjectives and measure MixEval-Hard scores, which correlate highly with human\njudgments. The CLAIR preferences lead to the strongest performance out of all\ndatasets, and APO consistently outperforms less controllable objectives. Our\nbest model, trained on 32K CLAIR preferences with APO, improves\nLlama-3-8B-Instruct by 7.65%, closing the gap with GPT4-turbo by 45%. Our code\nis available at https://github.com/ContextualAI/CLAIR_and_APO.",
      "tldr_zh": "本研究探讨了大型语言模型(LLMs)使用对比对齐目标和偏好对数据集进行对齐时存在的不足，发现偏好数据在响应对比时提供更有效的学习信号，而对齐目标在提供更多控制时能提升性能。基于此，作者引入了Contrastive Learning from AI Revisions (CLAIR)方法来生成更对比的偏好对，以及Anchored Preference Optimization (APO)作为一种更可控且稳定的对齐目标。实验结果显示，使用32K CLAIR偏好对和APO训练的Llama-3-8B-Instruct模型比原模型提高了7.65%的MixEval-Hard分数，并将与GPT4-turbo的差距缩小了45%。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.06266v5",
      "published_date": "2024-08-12 16:24:51 UTC",
      "updated_date": "2024-09-14 23:09:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:40:03.002996"
    },
    {
      "arxiv_id": "2408.06264v1",
      "title": "Audio Enhancement for Computer Audition -- An Iterative Training Paradigm Using Sample Importance",
      "title_zh": "音频增强用于计算机听觉——一个使用样本重要性的迭代训练范式",
      "authors": [
        "Manuel Milling",
        "Shuo Liu",
        "Andreas Triantafyllopoulos",
        "Ilhan Aslan",
        "Björn W. Schuller"
      ],
      "abstract": "Neural network models for audio tasks, such as automatic speech recognition\n(ASR) and acoustic scene classification (ASC), are susceptible to noise\ncontamination for real-life applications. To improve audio quality, an\nenhancement module, which can be developed independently, is explicitly used at\nthe front-end of the target audio applications. In this paper, we present an\nend-to-end learning solution to jointly optimise the models for audio\nenhancement (AE) and the subsequent applications. To guide the optimisation of\nthe AE module towards a target application, and especially to overcome\ndifficult samples, we make use of the sample-wise performance measure as an\nindication of sample importance. In experiments, we consider four\nrepresentative applications to evaluate our training paradigm, i.e., ASR,\nspeech command recognition (SCR), speech emotion recognition (SER), and ASC.\nThese applications are associated with speech and non-speech tasks concerning\nsemantic and non-semantic features, transient and global information, and the\nexperimental results indicate that our proposed approach can considerably boost\nthe noise robustness of the models, especially at low signal-to-noise ratios\n(SNRs), for a wide range of computer audition tasks in everyday-life noisy\nenvironments.",
      "tldr_zh": "本文提出一种迭代训练范式，使用样本重要性来联合优化音频增强(AE)模块和目标音频应用模型，旨在提升神经网络在噪声环境下的鲁棒性。方法通过样本级性能指标指导AE模块的优化，特别是针对困难样本，以更好地服务于ASR（自动语音识别）、SCR（语音命令识别）、SER（语音情感识别）和ASC（声学场景分类）等任务。实验结果显示，该方法显著提高了模型在低信噪比(SNR)条件下的性能，适用于日常噪声环境中的各种计算机听觉任务。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.06264v1",
      "published_date": "2024-08-12 16:23:58 UTC",
      "updated_date": "2024-08-12 16:23:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:40:23.815990"
    },
    {
      "arxiv_id": "2408.06261v3",
      "title": "Open-Source Molecular Processing Pipeline for Generating Molecules",
      "title_zh": "翻译失败",
      "authors": [
        "V Shreyas",
        "Jose Siguenza",
        "Karan Bania",
        "Bharath Ramsundar"
      ],
      "abstract": "Generative models for molecules have shown considerable promise for use in\ncomputational chemistry, but remain difficult to use for non-experts. For this\nreason, we introduce open-source infrastructure for easily building generative\nmolecular models into the widely used DeepChem [Ramsundar et al., 2019] library\nwith the aim of creating a robust and reusable molecular generation pipeline.\nIn particular, we add high quality PyTorch [Paszke et al., 2019]\nimplementations of the Molecular Generative Adversarial Networks (MolGAN) [Cao\nand Kipf, 2022] and Normalizing Flows [Papamakarios et al., 2021]. Our\nimplementations show strong performance comparable with past work [Kuznetsov\nand Polykovskiy, 2021, Cao and Kipf, 2022].",
      "tldr_zh": "这篇论文针对分子生成模型在计算化学中的应用难题，引入了开源基础设施，将生成模型整合到 DeepChem 库中，以简化非专家的使用。研究团队添加了 MolGAN 和 Normalizing Flows 的高质量 PyTorch 实现，这些模型构建了一个鲁棒且可重用的分子生成管道。实验结果显示，这些实现的表现与现有工作相当，证明了其有效性和可靠性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "q-bio.BM"
      ],
      "primary_category": "cs.LG",
      "comment": "Presented at the Molecular Machine Learning Conference 2024 (MoML\n  2024), BayLearn 2024 and the Machine Learning and Physical Sciences (ML4PS)\n  Workshop at NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2408.06261v3",
      "published_date": "2024-08-12 16:21:29 UTC",
      "updated_date": "2024-11-28 20:40:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:40:25.504544"
    },
    {
      "arxiv_id": "2408.06257v3",
      "title": "Reciprocal Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Julian Rodemann",
        "Christoph Jansen",
        "Georg Schollmeyer"
      ],
      "abstract": "We demonstrate that a wide array of machine learning algorithms are specific\ninstances of one single paradigm: reciprocal learning. These instances range\nfrom active learning over multi-armed bandits to self-training. We show that\nall these algorithms do not only learn parameters from data but also vice\nversa: They iteratively alter training data in a way that depends on the\ncurrent model fit. We introduce reciprocal learning as a generalization of\nthese algorithms using the language of decision theory. This allows us to study\nunder what conditions they converge. The key is to guarantee that reciprocal\nlearning contracts such that the Banach fixed-point theorem applies. In this\nway, we find that reciprocal learning algorithms converge at linear rates to an\napproximately optimal model under relatively mild assumptions on the loss\nfunction, if their predictions are probabilistic and the sample adaption is\nboth non-greedy and either randomized or regularized. We interpret these\nfindings and provide corollaries that relate them to specific active learning,\nself-training, and bandit algorithms.",
      "tldr_zh": "这篇论文提出reciprocal learning作为一种统一的机器学习范式，将active learning、多臂老虎机(multi-armed bandits)和self-training等算法视为其具体实例，这些算法不仅从数据中学习参数，还根据当前模型拟合迭代修改训练数据。作者使用决策理论对reciprocal learning进行泛化，并分析其收敛条件，强调需满足收缩性质以应用Banach fixed-point theorem。研究发现，如果预测是概率性的、样本适应是非贪婪的且随机化或正则化，那么这些算法在相对温和的损失函数假设下，以线性速率收敛到一个近似最优模型。该工作为理解和改进这些算法提供了重要理论基础。",
      "categories": [
        "stat.ML",
        "cs.AI",
        "cs.LG",
        "68T37, 68T05, 68W25"
      ],
      "primary_category": "stat.ML",
      "comment": "Accepted at NeurIPS 2024. v2: fixed typos, added future work. v3:\n  changed def. 4 and proof of thm. 4, added illustrations",
      "pdf_url": "http://arxiv.org/pdf/2408.06257v3",
      "published_date": "2024-08-12 16:14:52 UTC",
      "updated_date": "2024-11-01 20:48:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:40:39.195879"
    },
    {
      "arxiv_id": "2408.06240v4",
      "title": "Decentralized Health Intelligence Network (DHIN)",
      "title_zh": "去中心化健康智能网络 (DHIN)",
      "authors": [
        "Abraham Nash"
      ],
      "abstract": "Decentralized Health Intelligence Network (DHIN) extends the Decentralized\nIntelligence Network (DIN) framework to address challenges in healthcare data\nsovereignty and AI utilization. Building upon DIN's core principles, DHIN\nintroduces healthcare-specific components to tackle data fragmentation across\nproviders and institutions, establishing a sovereign architecture for\nhealthcare provision. It facilitates effective AI utilization by overcoming\nbarriers to accessing diverse health data sources. This comprehensive framework\nleverages: 1) self-sovereign identity architecture coupled with a personal\nhealth record (PHR), extending DIN's personal data stores concept to ensure\nhealth data sovereignty; 2) a scalable federated learning (FL) protocol\nimplemented on a public blockchain for decentralized AI training in healthcare,\ntailored for medical data; and 3) a scalable, trustless rewards mechanism\nadapted from DIN to incentivize participation in healthcare AI development.\nDHIN operates on a public blockchain with an immutable record, ensuring that no\nentity can control access to health data or determine financial benefits. It\nsupports effective AI training while allowing patients to maintain control over\ntheir health data, benefit financially, and contribute to a decentralized\necosystem. Unique to DHIN, patients receive rewards in digital wallets as an\nincentive to opt into the FL protocol, with a long-term roadmap to fund\ndecentralized insurance solutions. This approach introduces a novel,\nself-financed healthcare model that adapts to individual needs, complements\nexisting systems, and redefines universal coverage, showcasing how DIN\nprinciples can transform healthcare data management and AI utilization while\nempowering patients.",
      "tldr_zh": "该研究提出Decentralized Health Intelligence Network (DHIN)，作为Decentralized Intelligence Network (DIN)的扩展，旨在解决医疗保健领域的数据主权和AI利用挑战，通过建立去中心化架构应对数据碎片化问题。DHIN的关键组件包括：自主权身份架构结合personal health record (PHR)以确保数据主权、可扩展的federated learning (FL)协议在public blockchain上实现去中心化AI训练，以及无信任的奖励机制激励参与。最终，该框架赋予患者对健康数据的控制权和财务收益，构建了一个新型的自融资医疗模型，补充现有系统并推动医疗AI生态的可持续发展。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CY",
        "cs.DC",
        "cs.ET"
      ],
      "primary_category": "cs.CR",
      "comment": "13 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2408.06240v4",
      "published_date": "2024-08-12 15:47:26 UTC",
      "updated_date": "2024-09-04 17:57:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:40:53.336921"
    },
    {
      "arxiv_id": "2408.06227v1",
      "title": "FLEURS-R: A Restored Multilingual Speech Corpus for Generation Tasks",
      "title_zh": "翻译失败",
      "authors": [
        "Min Ma",
        "Yuma Koizumi",
        "Shigeki Karita",
        "Heiga Zen",
        "Jason Riesa",
        "Haruko Ishikawa",
        "Michiel Bacchiani"
      ],
      "abstract": "This paper introduces FLEURS-R, a speech restoration applied version of the\nFew-shot Learning Evaluation of Universal Representations of Speech (FLEURS)\ncorpus. FLEURS-R maintains an N-way parallel speech corpus in 102 languages as\nFLEURS, with improved audio quality and fidelity by applying the speech\nrestoration model Miipher. The aim of FLEURS-R is to advance speech technology\nin more languages and catalyze research including text-to-speech (TTS) and\nother speech generation tasks in low-resource languages. Comprehensive\nevaluations with the restored speech and TTS baseline models trained from the\nnew corpus show that the new corpus obtained significantly improved speech\nquality while maintaining the semantic contents of the speech. The corpus is\npublicly released via Hugging Face.",
      "tldr_zh": "本论文引入了 FLEURS-R，这是一个基于原始 FLEURS 语料库的改进版本，通过应用 Miipher 语音修复模型，提升了 102 种语言的语音质量和保真度。FLEURS-R 旨在推动低资源语言的语音技术发展，支持 text-to-speech (TTS) 等生成任务的研究。实验评估显示，使用新语料库训练的 TTS 基线模型显著提高了语音质量，同时保留了语义内容；该语料库已通过 Hugging Face 公开发布。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.SD",
        "eess.AS"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.06227v1",
      "published_date": "2024-08-12 15:28:51 UTC",
      "updated_date": "2024-08-12 15:28:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:41:01.603585"
    },
    {
      "arxiv_id": "2408.06226v2",
      "title": "A Large-Scale Study of Model Integration in ML-Enabled Software Systems",
      "title_zh": "大规模模型集成",
      "authors": [
        "Yorick Sens",
        "Henriette Knopp",
        "Sven Peldszus",
        "Thorsten Berger"
      ],
      "abstract": "The rise of machine learning (ML) and its integration into software systems\nhas drastically changed development practices. While software engineering\ntraditionally focused on manually created code artifacts with dedicated\nprocesses and architectures, ML-enabled systems require additional data-science\nmethods and tools to create ML artifacts -- especially ML models and training\ndata. However, integrating models into systems, and managing the many different\nartifacts involved, is far from trivial. ML-enabled systems can easily have\nmultiple ML models that interact with each other and with traditional code in\nintricate ways. Unfortunately, while challenges and practices of building\nML-enabled systems have been studied, little is known about the characteristics\nof real-world ML-enabled systems beyond isolated examples. Improving\nengineering processes and architectures for ML-enabled systems requires\nimproving the empirical understanding of these systems. We present a\nlarge-scale study of 2,928 open-source ML-enabled software systems. We\nclassified and analyzed them to determine system characteristics, model and\ncode reuse practices, and architectural aspects of integrating ML models. Our\nfindings show that these systems still mainly consist of traditional source\ncode, and that ML model reuse through code duplication or pre-trained models is\ncommon. We also identified different ML integration patterns and related\nimplementation practices. We hope that our results help improve practices for\nintegrating ML models, bringing data science and software engineering closer\ntogether.",
      "tldr_zh": "本研究对 2,928 个开源 ML-Enabled 软件系统进行了大规模实证分析，探讨了机器学习 (ML) 模型的整合特征、代码和模型重用实践，以及架构方面的问题。研究发现，这些系统仍以传统源代码为主，ML 模型重用（如通过代码复制或预训练模型）非常常见，同时识别了多种 ML 整合模式和相关实现实践。主要贡献在于揭示了 ML 整合的实际挑战，并为改善工程流程、促进数据科学与软件工程的融合提供了宝贵见解。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.SE",
      "comment": "Accepted at International Conference on Software Engineering (ICSE)\n  2025",
      "pdf_url": "http://arxiv.org/pdf/2408.06226v2",
      "published_date": "2024-08-12 15:28:40 UTC",
      "updated_date": "2025-02-24 15:02:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:41:15.872843"
    },
    {
      "arxiv_id": "2408.06223v3",
      "title": "On Effects of Steering Latent Representation for Large Language Model Unlearning",
      "title_zh": "翻译失败",
      "authors": [
        "Dang Huu-Tien",
        "Trung-Tin Pham",
        "Hoang Thanh-Tung",
        "Naoya Inoue"
      ],
      "abstract": "Representation Misdirection for Unlearning (RMU), which steers model\nrepresentation in the intermediate layer to a target random representation, is\nan effective method for large language model (LLM) unlearning. Despite its high\nperformance, the underlying cause and explanation remain underexplored. In this\npaper, we theoretically demonstrate that steering forget representations in the\nintermediate layer reduces token confidence, causing LLMs to generate wrong or\nnonsense responses. We investigate how the coefficient influences the alignment\nof forget-sample representations with the random direction and hint at the\noptimal coefficient values for effective unlearning across different network\nlayers. We show that RMU unlearned models are robust against adversarial\njailbreak attacks. Furthermore, our empirical analysis shows that RMU is less\neffective when applied to the middle and later layers in LLMs. To resolve this\ndrawback, we propose Adaptive RMU--a simple yet effective alternative method\nthat makes unlearning effective with most layers. Extensive experiments\ndemonstrate that Adaptive RMU significantly improves the unlearning performance\ncompared to prior art while incurring no additional computational cost.",
      "tldr_zh": "该论文探讨了 Representation Misdirection for Unlearning (RMU) 方法，该技术通过在大型语言模型 (LLM) 的中间层引导表示到随机表示，从而实现有效模型遗忘。研究理论证明，这种引导会降低令牌置信度，导致模型生成错误或无意义响应，并分析了系数对遗忘效果的影响，同时证明 RMU 对对抗性越狱攻击具有鲁棒性。论文发现 RMU 在中间和后期层效果较差，因此提出 Adaptive RMU 作为改进方案，该方法无需额外计算成本即可显著提升遗忘性能。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted at AAAI-25 Main Technical Track",
      "pdf_url": "http://arxiv.org/pdf/2408.06223v3",
      "published_date": "2024-08-12 15:24:50 UTC",
      "updated_date": "2025-02-06 02:25:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:41:26.533936"
    },
    {
      "arxiv_id": "2408.07100v1",
      "title": "Pattern-Matching Dynamic Memory Network for Dual-Mode Traffic Prediction",
      "title_zh": "模式匹配动态记忆网络用于双模式交通预测",
      "authors": [
        "Wenchao Weng",
        "Mei Wu",
        "Hanyu Jiang",
        "Wanzeng Kong",
        "Xiangjie Kong",
        "Feng Xia"
      ],
      "abstract": "In recent years, deep learning has increasingly gained attention in the field\nof traffic prediction. Existing traffic prediction models often rely on GCNs or\nattention mechanisms with O(N^2) complexity to dynamically extract traffic node\nfeatures, which lack efficiency and are not lightweight. Additionally, these\nmodels typically only utilize historical data for prediction, without\nconsidering the impact of the target information on the prediction. To address\nthese issues, we propose a Pattern-Matching Dynamic Memory Network (PM-DMNet).\nPM-DMNet employs a novel dynamic memory network to capture traffic pattern\nfeatures with only O(N) complexity, significantly reducing computational\noverhead while achieving excellent performance. The PM-DMNet also introduces\ntwo prediction methods: Recursive Multi-step Prediction (RMP) and Parallel\nMulti-step Prediction (PMP), which leverage the time features of the prediction\ntargets to assist in the forecasting process. Furthermore, a transfer attention\nmechanism is integrated into PMP, transforming historical data features to\nbetter align with the predicted target states, thereby capturing trend changes\nmore accurately and reducing errors. Extensive experiments demonstrate the\nsuperiority of the proposed model over existing benchmarks. The source codes\nare available at: https://github.com/wengwenchao123/PM-DMNet.",
      "tldr_zh": "本文提出 Pattern-Matching Dynamic Memory Network (PM-DMNet) 用于双模式交通预测，以解决现有模型依赖 GCNs 或 attention 机制导致的 O(N^2) 复杂度问题，并忽略预测目标信息的影响。PM-DMNet 采用新型动态记忆网络，仅以 O(N) 复杂度高效捕获交通模式特征，同时引入 Recursive Multi-step Prediction (RMP) 和 Parallel Multi-step Prediction (PMP) 方法，利用预测目标的时间特征辅助预测过程。此外，PMP 整合 transfer attention 机制，将历史数据特征转化为与目标状态更匹配的形式，提高趋势捕获准确性和减少错误。实验结果表明，PM-DMNet 在基准测试中表现出色。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.07100v1",
      "published_date": "2024-08-12 15:12:30 UTC",
      "updated_date": "2024-08-12 15:12:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:41:51.024925"
    },
    {
      "arxiv_id": "2408.06202v2",
      "title": "Strategy Game-Playing with Size-Constrained State Abstraction",
      "title_zh": "翻译失败",
      "authors": [
        "Linjie Xu",
        "Diego Perez-Liebana",
        "Alexander Dockhorn"
      ],
      "abstract": "Playing strategy games is a challenging problem for artificial intelligence\n(AI). One of the major challenges is the large search space due to a diverse\nset of game components. In recent works, state abstraction has been applied to\nsearch-based game AI and has brought significant performance improvements.\nState abstraction techniques rely on reducing the search space, e.g., by\naggregating similar states. However, the application of these abstractions is\nhindered because the quality of an abstraction is difficult to evaluate.\nPrevious works hence abandon the abstraction in the middle of the search to not\nbias the search to a local optimum. This mechanism introduces a hyper-parameter\nto decide the time to abandon the current state abstraction. In this work, we\npropose a size-constrained state abstraction (SCSA), an approach that limits\nthe maximum number of nodes being grouped together. We found that with SCSA,\nthe abstraction is not required to be abandoned. Our empirical results on $3$\nstrategy games show that the SCSA agent outperforms the previous methods and\nyields robust performance over different games. Codes are open-sourced at\nhttps://github.com/GAIGResearch/Stratega.",
      "tldr_zh": "本研究针对策略游戏在人工智能(AI)中的挑战，即巨大的搜索空间，提出了一种size-constrained state abstraction (SCSA)方法。该方法通过限制节点的最大分组数量，避免了传统state abstraction在搜索过程中需放弃抽象的缺点，从而简化了参数调整。实验结果显示，SCSA代理在3个策略游戏上比现有方法性能更优，并展现出稳健的跨游戏适应性。代码已开源在GitHub。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "8 pages, published in Proceedings of the Conference on Games 2024,\n  codes are open-sourced at https://github.com/GAIGResearch/Stratega",
      "pdf_url": "http://arxiv.org/pdf/2408.06202v2",
      "published_date": "2024-08-12 14:50:18 UTC",
      "updated_date": "2025-02-15 11:10:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:42:00.911349"
    },
    {
      "arxiv_id": "2408.06199v1",
      "title": "Dynamic Blocked Clause Elimination for Projected Model Counting",
      "title_zh": "动态阻塞子句消除用于投影模型计数",
      "authors": [
        "Jean-Marie Lagniez",
        "Pierre Marquis",
        "Armin Biere"
      ],
      "abstract": "In this paper, we explore the application of blocked clause elimination for\nprojected model counting. This is the problem of determining the number of\nmodels ||\\exists X.{\\Sigma}|| of a propositional formula {\\Sigma} after\neliminating a given set X of variables existentially. Although blocked clause\nelimination is a well-known technique for SAT solving, its direct application\nto model counting is challenging as in general it changes the number of models.\nHowever, we demonstrate, by focusing on projected variables during the blocked\nclause search, that blocked clause elimination can be leveraged while\npreserving the correct model count. To take advantage of blocked clause\nelimination in an efficient way during model counting, a novel data structure\nand associated algorithms are introduced. Our proposed approach is implemented\nin the model counter d4. Our experiments demonstrate the computational benefits\nof our new method of blocked clause elimination for projected model counting.",
      "tldr_zh": "本文提出了一种动态阻塞子句消除(blocked clause elimination)技术，用于投影模型计数(projected model counting)，即计算命题公式Σ在消除指定变量集X后的模型数量。作者通过聚焦于投影变量进行阻塞子句搜索，确保了模型计数的准确性，同时引入了新数据结构和相关算法来高效实现这一过程。该方法在模型计数器d4中得到应用，实验结果表明其显著提高了计算性能。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "LIPIcs, Volume 305, SAT 2024",
      "pdf_url": "http://arxiv.org/pdf/2408.06199v1",
      "published_date": "2024-08-12 14:49:12 UTC",
      "updated_date": "2024-08-12 14:49:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:42:02.150299"
    },
    {
      "arxiv_id": "2408.15268v3",
      "title": "Anomaly Detection in Time Series of EDFA Pump Currents to Monitor Degeneration Processes using Fuzzy Clustering",
      "title_zh": "使用模糊聚类对 EDFA 泵浦电流时间序列进行异常检测以监测退化过程",
      "authors": [
        "Dominic Schneider",
        "Lutz Rapp",
        "Christoph Ament"
      ],
      "abstract": "This article proposes a novel fuzzy clustering based anomaly detection method\nfor pump current time series of EDFA systems. The proposed change detection\nframework (CDF) strategically combines the advantages of entropy analysis (EA)\nand principle component analysis (PCA) with fuzzy clustering procedures. In the\nframework, EA is applied for dynamic selection of features for reduction of the\nfeature space and increase of computational performance. Furthermore, PCA is\nutilized to extract features from the raw feature space to enable\ngeneralization capability of the subsequent fuzzy clustering procedures. Three\ndifferent fuzzy clustering methods, more precisely the fuzzy clustering\nalgorithm, a probabilistic clustering algorithm and a possibilistic clustering\nalgorithm are evaluated for performance and generalization. Hence, the proposed\nframework has the innovative feature to detect changes in pump current time\nseries at an early stage for arbitrary points of operation, compared to\nstate-of-the-art predefined alarms in commercially used EDFAs. Moreover, the\napproach is implemented and tested using experimental data. In addition, the\nproposed framework enables further approaches of applying decentralized\npredictive maintenance for optical fiber networks.",
      "tldr_zh": "这篇论文提出了一种基于模糊聚类(fuzzy clustering)的异常检测方法，用于监测 EDFA 系统泵电流时间序列的退化过程。框架名为 Change Detection Framework (CDF)，它结合熵分析(EA)动态选择特征以减少特征空间并提升计算性能，以及主成分分析(PCA)提取特征以提高后续模糊聚类算法的泛化能力。论文评估了三种模糊聚类方法，包括模糊聚类算法(fuzzy clustering algorithm)、概率聚类算法(probabilistic clustering algorithm)和可能性聚类算法(possibilistic clustering algorithm)，并通过实验数据验证，该框架能早于现有商业 EDFA 的预定义警报检测异常变化，从而支持光纤网络的去中心化预测性维护(decentralized predictive maintenance)。",
      "categories": [
        "eess.SP",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "eess.SP",
      "comment": "6 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2408.15268v3",
      "published_date": "2024-08-12 14:23:42 UTC",
      "updated_date": "2025-04-29 12:14:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:42:15.752141"
    },
    {
      "arxiv_id": "2408.08328v1",
      "title": "Unleash The Power of Pre-Trained Language Models for Irregularly Sampled Time Series",
      "title_zh": "释放预训练语言模型的潜力，用于不规则采样时间序列",
      "authors": [
        "Weijia Zhang",
        "Chenlong Yin",
        "Hao Liu",
        "Hui Xiong"
      ],
      "abstract": "Pre-trained Language Models (PLMs), such as ChatGPT, have significantly\nadvanced the field of natural language processing. This progress has inspired a\nseries of innovative studies that explore the adaptation of PLMs to time series\nanalysis, intending to create a unified foundation model that addresses various\ntime series analytical tasks. However, these efforts predominantly focus on\nRegularly Sampled Time Series (RSTS), neglecting the unique challenges posed by\nIrregularly Sampled Time Series (ISTS), which are characterized by non-uniform\nsampling intervals and prevalent missing data. To bridge this gap, this work\nexplores the potential of PLMs for ISTS analysis. We begin by investigating the\neffect of various methods for representing ISTS, aiming to maximize the\nefficacy of PLMs in this under-explored area. Furthermore, we present a unified\nPLM-based framework, ISTS-PLM, which integrates time-aware and variable-aware\nPLMs tailored for comprehensive intra and inter-time series modeling and\nincludes a learnable input embedding layer and a task-specific output layer to\ntackle diverse ISTS analytical tasks. Extensive experiments on a comprehensive\nbenchmark demonstrate that the ISTS-PLM, utilizing a simple yet effective\nseries-based representation for ISTS, consistently achieves state-of-the-art\nperformance across various analytical tasks, such as classification,\ninterpolation, and extrapolation, as well as few-shot and zero-shot learning\nscenarios, spanning scientific domains like healthcare and biomechanics.",
      "tldr_zh": "这篇论文探讨了如何将 Pre-Trained Language Models (PLMs) 应用于 Irregularly Sampled Time Series (ISTS)，以解决现有方法忽略的非均匀采样和缺失数据挑战。作者提出一个统一的框架 ISTS-PLM，该框架整合了时间感知和变量感知 PLMs，用于全面的内部和内部时间序列建模，并包括可学习的输入嵌入层和任务特定输出层，以处理多种 ISTS 分析任务。在广泛基准测试中，ISTS-PLM 使用简单有效的序列表示方法，在分类、插值、外推等任务上实现了最先进性能，尤其在少样本和零样本学习场景中表现出色，涵盖医疗和生物力学等领域。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "stat.AP"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.08328v1",
      "published_date": "2024-08-12 14:22:14 UTC",
      "updated_date": "2024-08-12 14:22:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:42:28.656919"
    },
    {
      "arxiv_id": "2408.06163v1",
      "title": "ACCELERATION: Sequentially-scanning DECT Imaging Using High Temporal Resolution Image Reconstruction And Temporal Extrapolation",
      "title_zh": "ACCELERATION：使用高时间分辨率图像重建和时间外推的顺序扫描 DECT 成像",
      "authors": [
        "Qiaoxin Li",
        "Dong Liang",
        "Yinsheng Li"
      ],
      "abstract": "Dual-energy computed tomography (DECT) has been widely used to obtain\nquantitative elemental composition of imaged subjects for personalized and\nprecise medical diagnosis. Compared with existing high-end DECT leveraging\nadvanced X-ray source and/or detector technologies, the use of the\nsequentially-scanning data acquisition scheme to implement DECT may make\nbroader impact on clinical practice because this scheme requires no specialized\nhardware designs. However, since the concentration of iodinated contrast agent\nin the imaged subject varies over time, sequentially-scanned data sets acquired\nat two tube potentials are temporally inconsistent. As existing material\ndecomposition approaches for DECT assume that the data sets acquired at two\ntube potentials are temporally consistent, the violation of this assumption\nresults in inaccurate quantification accuracy of iodine concentration. In this\nwork, we developed a technique to achieve sequentially-scanning DECT imaging\nusing high temporal resolution image reconstruction and temporal extrapolation,\nACCELERATION in short, to address the technical challenge induced by temporal\ninconsistency of sequentially-scanned data sets and improve iodine\nquantification accuracy in sequentially-scanning DECT. ACCELERATION has been\nvalidated and evaluated using numerical simulation data sets generated from\nclinical human subject exams. Results demonstrated the improvement of iodine\nquantification accuracy using ACCELERATION.",
      "tldr_zh": "这篇论文针对顺序扫描双能计算机断层扫描（DECT）成像中，由于碘化对比剂浓度随时间变化导致的数据时间不一致问题，提出了ACCELERATION技术。该技术结合高时间分辨率图像重建和时间外推方法，解决了现有材料分解方法的假设限制，提高了碘浓度的量化准确性。实验结果显示，通过使用从临床人类受试者检查生成的数值模拟数据，ACCELERATION显著提升了DECT的成像性能，为无需专业硬件的临床应用提供了更可靠的解决方案。",
      "categories": [
        "physics.med-ph",
        "cs.AI",
        "cs.CV",
        "physics.ins-det"
      ],
      "primary_category": "physics.med-ph",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.06163v1",
      "published_date": "2024-08-12 14:03:17 UTC",
      "updated_date": "2024-08-12 14:03:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:42:44.888862"
    },
    {
      "arxiv_id": "2408.06152v2",
      "title": "Palantir: Towards Efficient Super Resolution for Ultra-high-definition Live Streaming",
      "title_zh": "翻译失败",
      "authors": [
        "Xinqi Jin",
        "Zhui Zhu",
        "Xikai Sun",
        "Fan Dang",
        "Jiangchuan Liu",
        "Jingao Xu",
        "Kebin Liu",
        "Xinlei Chen",
        "Yunhao Liu"
      ],
      "abstract": "Neural enhancement through super-resolution (SR) deep neural networks (DNNs)\nopens up new possibilities for ultra-high-definition (UHD) live streaming over\nexisting encoding and networking infrastructure. Yet, the heavy SR DNN\ninference overhead leads to severe deployment challenges. To reduce the\noverhead, existing systems propose to apply DNN-based SR only on carefully\nselected anchor frames while upscaling non-anchor frames via the lightweight\nreusing-based SR approach. However, frame-level scheduling is coarse-grained\nand fails to deliver optimal efficiency. In this work, we propose Palantir, the\nfirst neural-enhanced UHD live streaming system with fine-grained patch-level\nscheduling. Two novel techniques are incorporated into Palantir to select the\nmost beneficial anchor patches and support latency-sensitive UHD live streaming\napplications. Firstly, under the guidance of our pioneering and theoretical\nanalysis, Palantir constructs a directed acyclic graph (DAG) for lightweight\nyet accurate SR quality estimation under any possible anchor patch set.\nSecondly, to further optimize the scheduling latency, Palantir improves\nparallelizability by refactoring the computation subprocedure of the estimation\nprocess into a sparse matrix-matrix multiplication operation.\n  The evaluation results suggest that Palantir incurs a negligible scheduling\nlatency accounting for less than 5.7% of the end-to-end latency requirement.\nWhen compared to the naive method of applying DNN-based SR on all the frames,\nPalantir can reduce the SR DNN inference overhead by 20 times (or 60 times)\nwhile preserving 54.0-82.6% (or 32.8-64.0%) of the quality gain. When compared\nto the state-of-the-art real-time frame-level scheduling strategy, Palantir can\nreduce the SR DNN inference overhead by 80.1% at most (and 38.4% on average)\nwithout sacrificing the video quality.",
      "tldr_zh": "这篇论文提出了 Palantir，一种高效的超分辨率（SR）系统，针对超高清（UHD）直播流，旨在通过细粒度的 patch-level 调度减少 DNN 推理开销。Palantir 引入了两个关键技术：构建有向无环图（DAG）来精确估计 SR 质量并选择最优锚补丁，以及将计算过程重构为稀疏矩阵-矩阵乘法以优化延迟和并行性。实验结果显示，Palantir 的调度延迟不到端到端延迟的 5.7%，相较于全帧 DNN SR 方法，可将推理开销降低 20 倍（或 60 倍）同时保留 54.0-82.6% 的质量提升，并相较于最先进帧级调度策略减少最多 80.1% 开销而不牺牲视频质量。",
      "categories": [
        "cs.MM",
        "cs.AI",
        "cs.CV",
        "cs.NI"
      ],
      "primary_category": "cs.MM",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.06152v2",
      "published_date": "2024-08-12 13:48:06 UTC",
      "updated_date": "2024-08-31 12:32:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:43:06.078874"
    },
    {
      "arxiv_id": "2408.06142v1",
      "title": "Med42-v2: A Suite of Clinical LLMs",
      "title_zh": "Med42-v2：临床大型语言模型套件",
      "authors": [
        "Clément Christophe",
        "Praveen K Kanithi",
        "Tathagata Raha",
        "Shadab Khan",
        "Marco AF Pimentel"
      ],
      "abstract": "Med42-v2 introduces a suite of clinical large language models (LLMs) designed\nto address the limitations of generic models in healthcare settings. These\nmodels are built on Llama3 architecture and fine-tuned using specialized\nclinical data. They underwent multi-stage preference alignment to effectively\nrespond to natural prompts. While generic models are often preference-aligned\nto avoid answering clinical queries as a precaution, Med42-v2 is specifically\ntrained to overcome this limitation, enabling its use in clinical settings.\nMed42-v2 models demonstrate superior performance compared to the original\nLlama3 models in both 8B and 70B parameter configurations and GPT-4 across\nvarious medical benchmarks. These LLMs are developed to understand clinical\nqueries, perform reasoning tasks, and provide valuable assistance in clinical\nenvironments. The models are now publicly available at\n\\href{https://huggingface.co/m42-health}{https://huggingface.co/m42-health}.",
      "tldr_zh": "Med42-v2 是一个基于 Llama3 架构的临床大型语言模型 (LLMs) 套件，旨在解决通用模型在医疗环境中的局限性，如避免回答临床查询。模型通过使用专业临床数据进行微调，并采用多阶段偏好对齐技术，使其能够有效处理自然提示并理解临床查询。实验结果显示，Med42-v2 在 8B 和 70B 参数配置上，比原 Llama3 模型和 GPT-4 在各种医疗基准上表现出色，提供更可靠的临床辅助支持。该模型现已在 Hugging Face 上公开可用。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.06142v1",
      "published_date": "2024-08-12 13:37:31 UTC",
      "updated_date": "2024-08-12 13:37:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:43:04.561751"
    },
    {
      "arxiv_id": "2408.06121v3",
      "title": "A Methodological Report on Anomaly Detection on Dynamic Knowledge Graphs",
      "title_zh": "动态知识图",
      "authors": [
        "Xiaohua Lu",
        "Leshanshui Yang"
      ],
      "abstract": "In this paper, we explore different approaches to anomaly detection on\ndynamic knowledge graphs, specifically in a Micro-services environment for\nKubernetes applications. Our approach explores three dynamic knowledge graph\nrepresentations: sequential data, hierarchical data and inter-service\ndependency data, with each representation incorporating increasingly complex\nstructural information of dynamic knowledge graph. Different machine learning\nand deep learning models are tested on these representations. We empirically\nanalyse their performance and propose an approach based on ensemble learning of\nthese models. Our approach significantly outperforms the baseline on the ISWC\n2024 Dynamic Knowledge Graph Anomaly Detection dataset, providing a robust\nsolution for anomaly detection in dynamic complex data.",
      "tldr_zh": "本论文探讨了在动态知识图谱（dynamic knowledge graphs）上进行异常检测的方法，针对 Kubernetes 应用的微服务环境。研究者探索了三种表示形式：sequential data、hierarchical data 和 inter-service dependency data，并测试了多种 machine learning 和 deep learning models 的性能。最终，通过实证分析和基于这些模型的 ensemble learning 策略，该方法在 ISWC 2024 Dynamic Knowledge Graph Anomaly Detection 数据集上显著优于基线，提供了一个稳健的异常检测解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.06121v3",
      "published_date": "2024-08-12 13:03:34 UTC",
      "updated_date": "2024-11-11 01:49:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:43:18.461705"
    },
    {
      "arxiv_id": "2408.06402v2",
      "title": "PhaGO: Protein function annotation for bacteriophages by integrating the genomic context",
      "title_zh": "翻译失败",
      "authors": [
        "Jiaojiao Guan",
        "Yongxin Ji",
        "Cheng Peng",
        "Wei Zou",
        "Xubo Tang",
        "Jiayu Shang",
        "Yanni Sun"
      ],
      "abstract": "Bacteriophages are viruses that target bacteria, playing a crucial role in\nmicrobial ecology. Phage proteins are important in understanding phage biology,\nsuch as virus infection, replication, and evolution. Although a large number of\nnew phages have been identified via metagenomic sequencing, many of them have\nlimited protein function annotation. Accurate function annotation of phage\nproteins presents several challenges, including their inherent diversity and\nthe scarcity of annotated ones. Existing tools have yet to fully leverage the\nunique properties of phages in annotating protein functions. In this work, we\npropose a new protein function annotation tool for phages by leveraging the\nmodular genomic structure of phage genomes. By employing embeddings from the\nlatest protein foundation models and Transformer to capture contextual\ninformation between proteins in phage genomes, PhaGO surpasses state-of-the-art\nmethods in annotating diverged proteins and proteins with uncommon functions by\n6.78% and 13.05% improvement, respectively. PhaGO can annotate proteins lacking\nhomology search results, which is critical for characterizing the rapidly\naccumulating phage genomes. We demonstrate the utility of PhaGO by identifying\n688 potential holins in phages, which exhibit high structural conservation with\nknown holins. The results show the potential of PhaGO to extend our\nunderstanding of newly discovered phages.",
      "tldr_zh": "本文提出PhaGO，一种新型工具，用于细菌噬菌体(bacteriophages)的蛋白质功能注释，通过整合基因组上下文来解决现有方法的局限性。PhaGO 利用蛋白质基础模型的嵌入和 Transformer 捕捉基因组中蛋白质之间的模块化结构信息，从而提升注释准确性。实验结果显示，与最先进方法相比，PhaGO 在注释发散蛋白和具有不常见功能的蛋白上分别提高了6.78%和13.05%，并能处理缺乏同源搜索结果的蛋白质。最终，PhaGO 通过识别688个潜在 holins 并展示其结构保守性，扩展了对新发现噬菌体的理解。",
      "categories": [
        "q-bio.QM",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "q-bio.QM",
      "comment": "17 pages,6 figures",
      "pdf_url": "http://arxiv.org/pdf/2408.06402v2",
      "published_date": "2024-08-12 13:02:38 UTC",
      "updated_date": "2024-08-17 13:46:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:43:31.662341"
    },
    {
      "arxiv_id": "2408.06101v1",
      "title": "Generalization capabilities of MeshGraphNets to unseen geometries for fluid dynamics",
      "title_zh": "翻译失败",
      "authors": [
        "Robin Schmöcker",
        "Alexander Henkes",
        "Julian Roth",
        "Thomas Wick"
      ],
      "abstract": "This works investigates the generalization capabilities of MeshGraphNets\n(MGN) [Pfaff et al. Learning Mesh-Based Simulation with Graph Networks. ICML\n2021] to unseen geometries for fluid dynamics, e.g. predicting the flow around\na new obstacle that was not part of the training data. For this purpose, we\ncreate a new benchmark dataset for data-driven computational fluid dynamics\n(CFD) which extends DeepMind's flow around a cylinder dataset by including\ndifferent shapes and multiple objects. We then use this new dataset to extend\nthe generalization experiments conducted by DeepMind on MGNs by testing how\nwell an MGN can generalize to different shapes. In our numerical tests, we show\nthat MGNs can sometimes generalize well to various shapes by training on a\ndataset of one obstacle shape and testing on a dataset of another obstacle\nshape.",
      "tldr_zh": "本研究调查了 MeshGraphNets (MGN) 在流体动力学中对未见几何形状的泛化能力，例如预测训练数据中未包含的新障碍物周围的流动。研究者创建了一个新的基准数据集，扩展了 DeepMind 的气缸周围流动数据集，加入了不同形状和多个物体，以支持数据驱动的计算流体动力学 (CFD) 实验。在实验中，他们训练 MGN 于一种障碍物形状的数据，然后测试其在另一种形状上的表现，结果显示 MGN 有时能良好地泛化到各种形状。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NA",
        "math.NA",
        "physics.flu-dyn"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.06101v1",
      "published_date": "2024-08-12 12:32:15 UTC",
      "updated_date": "2024-08-12 12:32:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:43:41.983879"
    },
    {
      "arxiv_id": "2408.07099v1",
      "title": "Bearing Fault Diagnosis using Graph Sampling and Aggregation Network",
      "title_zh": "翻译失败",
      "authors": [
        "Jiaying Chen",
        "Xusheng Du",
        "Yurong Qian",
        "Gwanggil Jeon"
      ],
      "abstract": "Bearing fault diagnosis technology has a wide range of practical applications\nin industrial production, energy and other fields. Timely and accurate\ndetection of bearing faults plays an important role in preventing catastrophic\naccidents and ensuring product quality. Traditional signal analysis techniques\nand deep learning-based fault detection algorithms do not take into account the\nintricate correlation between signals, making it difficult to further improve\ndetection accuracy. To address this problem, we introduced Graph Sampling and\nAggregation (GraphSAGE) network and proposed GraphSAGE-based Bearing fault\nDiagnosis (GSABFD) algorithm. The original vibration signal is firstly sliced\nthrough a fixed size non-overlapping sliding window, and the sliced data is\nfeature transformed using signal analysis methods; then correlations are\nconstructed for the transformed vibration signal and further transformed into\nvertices in the graph; then the GraphSAGE network is used for training; finally\nthe fault level of the object is calculated in the output layer of the network.\nThe proposed algorithm is compared with five advanced algorithms in a\nreal-world public dataset for experiments, and the results show that the GSABFD\nalgorithm improves the AUC value by 5% compared with the next best algorithm.",
      "tldr_zh": "这篇论文针对轴承故障诊断中信号之间复杂相关性被忽略的问题，提出了一种基于 GraphSAGE 网络的 GSABFD 算法，以提升检测准确率。算法首先通过固定大小的非重叠滑动窗口切片振动信号，并使用信号分析方法进行特征转换，然后构建图结构将信号相关性转化为顶点，并采用 GraphSAGE 网络进行训练和故障级别输出。实验结果显示，在真实公共数据集上，GSABFD 算法的 AUC 值比其他五种先进算法提高了 5%。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "eess.SP"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.07099v1",
      "published_date": "2024-08-12 12:32:03 UTC",
      "updated_date": "2024-08-12 12:32:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:43:53.778863"
    },
    {
      "arxiv_id": "2408.07098v1",
      "title": "QTypeMix: Enhancing Multi-Agent Cooperative Strategies through Heterogeneous and Homogeneous Value Decomposition",
      "title_zh": "翻译失败",
      "authors": [
        "Songchen Fu",
        "Shaojing Zhao",
        "Ta Li",
        "YongHong Yan"
      ],
      "abstract": "In multi-agent cooperative tasks, the presence of heterogeneous agents is\nfamiliar. Compared to cooperation among homogeneous agents, collaboration\nrequires considering the best-suited sub-tasks for each agent. However, the\noperation of multi-agent systems often involves a large amount of complex\ninteraction information, making it more challenging to learn heterogeneous\nstrategies. Related multi-agent reinforcement learning methods sometimes use\ngrouping mechanisms to form smaller cooperative groups or leverage prior domain\nknowledge to learn strategies for different roles. In contrast, agents should\nlearn deeper role features without relying on additional information.\nTherefore, we propose QTypeMix, which divides the value decomposition process\ninto homogeneous and heterogeneous stages. QTypeMix learns to extract type\nfeatures from local historical observations through the TE loss. In addition,\nwe introduce advanced network structures containing attention mechanisms and\nhypernets to enhance the representation capability and achieve the value\ndecomposition process. The results of testing the proposed method on 14 maps\nfrom SMAC and SMACv2 show that QTypeMix achieves state-of-the-art performance\nin tasks of varying difficulty.",
      "tldr_zh": "该研究提出 QTypeMix 方法，通过异质(homogeneous) 和同质(heterogeneous) 价值分解(value decomposition) 提升多智能体合作策略，旨在帮助代理从本地历史观察中学习角色特征，而无需依赖额外信息。QTypeMix 将价值分解过程分为同质和异质阶段，使用 TE loss 提取类型特征，并引入包含 attention mechanisms 和 hypernets 的先进网络结构来增强表示能力。实验结果显示，在 SMAC 和 SMACv2 的 14 个地图上，该方法在不同难度任务中取得了 state-of-the-art 性能。",
      "categories": [
        "cs.MA",
        "cs.AI",
        "I.2.6; I.2.11"
      ],
      "primary_category": "cs.MA",
      "comment": "16 pages, 8 figures",
      "pdf_url": "http://arxiv.org/pdf/2408.07098v1",
      "published_date": "2024-08-12 12:27:58 UTC",
      "updated_date": "2024-08-12 12:27:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:44:05.938699"
    },
    {
      "arxiv_id": "2408.06087v1",
      "title": "Building Decision Making Models Through Language Model Regime",
      "title_zh": "通过语言模型框架构建决策模型",
      "authors": [
        "Yu Zhang",
        "Haoxiang Liu",
        "Feijun Jiang",
        "Weihua Luo",
        "Kaifu Zhang"
      ],
      "abstract": "We propose a novel approach for decision making problems leveraging the\ngeneralization capabilities of large language models (LLMs). Traditional\nmethods such as expert systems, planning algorithms, and reinforcement learning\noften exhibit limited generalization, typically requiring the training of new\nmodels for each unique task. In contrast, LLMs demonstrate remarkable success\nin generalizing across varied language tasks, inspiring a new strategy for\ntraining decision making models. Our approach, referred to as \"Learning then\nUsing\" (LTU), entails a two-stage process. Initially, the \\textit{learning}\nphase develops a robust foundational decision making model by integrating\ndiverse knowledge from various domains and decision making contexts. The\nsubsequent \\textit{using} phase refines this foundation model for specific\ndecision making scenarios. Distinct from other studies that employ LLMs for\ndecision making through supervised learning, our LTU method embraces a\nversatile training methodology that combines broad pre-training with targeted\nfine-tuning. Experiments in e-commerce domains such as advertising and search\noptimization have shown that LTU approach outperforms traditional supervised\nlearning regimes in decision making capabilities and generalization. The LTU\napproach is the first practical training architecture for both single-step and\nmulti-step decision making tasks combined with LLMs, which can be applied\nbeyond game and robot domains. It provides a robust and adaptable framework for\ndecision making, enhances the effectiveness and flexibility of various systems\nin tackling various challenges.",
      "tldr_zh": "本文提出了一种名为“Learning then Using”（LTU）的方法，利用大型语言模型（LLMs）的泛化能力来解决决策问题，与传统方法如专家系统和强化学习相比，它避免了为每个任务重新训练模型的局限性。LTU 采用两阶段过程：首先通过整合多领域知识进行广泛预训练，构建基础决策模型；然后针对特定场景进行细调，以提升适应性。实验在电商领域（如广告和搜索优化）中显示，LTU 优于传统监督学习方法，在决策能力和泛化性能上表现出显著优势。该方法是首个结合 LLMs 的实用训练架构，可应用于单步和多步决策任务，并扩展到游戏和机器人领域以外的场景。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.06087v1",
      "published_date": "2024-08-12 12:04:14 UTC",
      "updated_date": "2024-08-12 12:04:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:44:18.862416"
    },
    {
      "arxiv_id": "2408.06069v1",
      "title": "Fully Bayesian Differential Gaussian Processes through Stochastic Differential Equations",
      "title_zh": "翻译失败",
      "authors": [
        "Jian Xu",
        "Zhiqi Lin",
        "Min Chen",
        "Junmei Yang",
        "Delu Zeng",
        "John Paisley"
      ],
      "abstract": "Traditional deep Gaussian processes model the data evolution using a discrete\nhierarchy, whereas differential Gaussian processes (DIFFGPs) represent the\nevolution as an infinitely deep Gaussian process. However, prior DIFFGP methods\noften overlook the uncertainty of kernel hyperparameters and assume them to be\nfixed and time-invariant, failing to leverage the unique synergy between\ncontinuous-time models and approximate inference. In this work, we propose a\nfully Bayesian approach that treats the kernel hyperparameters as random\nvariables and constructs coupled stochastic differential equations (SDEs) to\nlearn their posterior distribution and that of inducing points. By\nincorporating estimation uncertainty on hyperparameters, our method enhances\nthe model's flexibility and adaptability to complex dynamics. Additionally, our\napproach provides a time-varying, comprehensive, and realistic posterior\napproximation through coupling variables using SDE methods. Experimental\nresults demonstrate the advantages of our method over traditional approaches,\nshowcasing its superior performance in terms of flexibility, accuracy, and\nother metrics. Our work opens up exciting research avenues for advancing\nBayesian inference and offers a powerful modeling tool for continuous-time\nGaussian processes.",
      "tldr_zh": "该论文提出了一种完全贝叶斯方法，通过随机微分方程（SDEs）来处理差分高斯过程（DIFFGPs），将核超参数视为随机变量并构建耦合 SDEs 以学习其后验分布以及诱导点的后验分布。相比传统方法，该方法纳入了超参数的不确定性，提升了模型的灵活性和对复杂动态的适应性，并提供了一个时间变化的全面后验近似。实验结果表明，该方法在灵活性、准确性和其他指标上优于现有方法，为推进贝叶斯推理和连续时间高斯过程（Gaussian Processes）建模开辟了新途径。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.06069v1",
      "published_date": "2024-08-12 11:41:07 UTC",
      "updated_date": "2024-08-12 11:41:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:44:31.245846"
    },
    {
      "arxiv_id": "2408.06068v1",
      "title": "Online Optimization of Curriculum Learning Schedules using Evolutionary Optimization",
      "title_zh": "翻译失败",
      "authors": [
        "Mohit Jiwatode",
        "Leon Schlecht",
        "Alexander Dockhorn"
      ],
      "abstract": "We propose RHEA CL, which combines Curriculum Learning (CL) with Rolling\nHorizon Evolutionary Algorithms (RHEA) to automatically produce effective\ncurricula during the training of a reinforcement learning agent. RHEA CL\noptimizes a population of curricula, using an evolutionary algorithm, and\nselects the best-performing curriculum as the starting point for the next\ntraining epoch. Performance evaluations are conducted after every curriculum\nstep in all environments. We evaluate the algorithm on the \\textit{DoorKey} and\n\\textit{DynamicObstacles} environments within the Minigrid framework. It\ndemonstrates adaptability and consistent improvement, particularly in the early\nstages, while reaching a stable performance later that is capable of\noutperforming other curriculum learners. In comparison to other curriculum\nschedules, RHEA CL has been shown to yield performance improvements for the\nfinal Reinforcement learning (RL) agent at the cost of additional evaluation\nduring training.",
      "tldr_zh": "该论文提出 RHEA CL 方法，将 Curriculum Learning (CL) 与 Rolling Horizon Evolutionary Algorithms (RHEA) 结合，用于自动优化强化学习代理的训练课程表。RHEA CL 通过进化算法优化一组课程表，并在每个训练周期选择表现最佳的作为起点，同时在所有环境中每步后进行性能评估。该方法在 Minigrid 框架的 DoorKey 和 DynamicObstacles 环境中表现出色，尤其在早期阶段实现快速改进，最终达到稳定性能并优于其他课程学习方法，尽管这需要额外的评估开销来提升最终 Reinforcement Learning (RL) 代理的表现。",
      "categories": [
        "cs.AI",
        "cs.NE"
      ],
      "primary_category": "cs.AI",
      "comment": "8 pages including abstract, to be published in the Proceedings of the\n  IEEE Conference on Games 2024",
      "pdf_url": "http://arxiv.org/pdf/2408.06068v1",
      "published_date": "2024-08-12 11:39:50 UTC",
      "updated_date": "2024-08-12 11:39:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:44:44.711297"
    },
    {
      "arxiv_id": "2408.08902v1",
      "title": "Audit-LLM: Multi-Agent Collaboration for Log-based Insider Threat Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Chengyu Song",
        "Linru Ma",
        "Jianming Zheng",
        "Jinzhi Liao",
        "Hongyu Kuang",
        "Lin Yang"
      ],
      "abstract": "Log-based insider threat detection (ITD) detects malicious user activities by\nauditing log entries. Recently, large language models (LLMs) with strong common\nsense knowledge have emerged in the domain of ITD. Nevertheless, diverse\nactivity types and overlong log files pose a significant challenge for LLMs in\ndirectly discerning malicious ones within myriads of normal activities.\nFurthermore, the faithfulness hallucination issue from LLMs aggravates its\napplication difficulty in ITD, as the generated conclusion may not align with\nuser commands and activity context. In response to these challenges, we\nintroduce Audit-LLM, a multi-agent log-based insider threat detection framework\ncomprising three collaborative agents: (i) the Decomposer agent, breaking down\nthe complex ITD task into manageable sub-tasks using Chain-of-Thought (COT)\nreasoning;(ii) the Tool Builder agent, creating reusable tools for sub-tasks to\novercome context length limitations in LLMs; and (iii) the Executor agent,\ngenerating the final detection conclusion by invoking constructed tools. To\nenhance conclusion accuracy, we propose a pair-wise Evidence-based Multi-agent\nDebate (EMAD) mechanism, where two independent Executors iteratively refine\ntheir conclusions through reasoning exchange to reach a consensus.\nComprehensive experiments conducted on three publicly available ITD\ndatasets-CERT r4.2, CERT r5.2, and PicoDomain-demonstrate the superiority of\nour method over existing baselines and show that the proposed EMAD\nsignificantly improves the faithfulness of explanations generated by LLMs.",
      "tldr_zh": "本研究提出Audit-LLM，一种基于多智能体协作的框架，用于日志-based insider threat detection (ITD)，旨在解决大型语言模型 (LLMs) 在处理多样活动类型、过长日志和幻觉问题（faithfulness hallucination）时的挑战。框架包括三个代理：Decomposer agent 使用 Chain-of-Thought (COT) 推理将复杂任务分解为子任务；Tool Builder agent 创建可重用工具以克服 LLMs 的上下文长度限制；Executor agent 通过调用这些工具生成最终检测结论。为提升准确性，该框架引入 Evidence-based Multi-agent Debate (EMAD) 机制，让两个 Executor 代理通过迭代推理交换来完善结论并达成共识。在三个公开数据集（CERT r4.2、CERT r5.2 和 PicoDomain）上的实验显示，Audit-LLM 优于现有基线方法，并显著提高了 LLMs 生成解释的可靠性。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "12 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2408.08902v1",
      "published_date": "2024-08-12 11:33:45 UTC",
      "updated_date": "2024-08-12 11:33:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:44:57.336854"
    },
    {
      "arxiv_id": "2408.06065v1",
      "title": "An Investigation Into Explainable Audio Hate Speech Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Jinmyeong An",
        "Wonjun Lee",
        "Yejin Jeon",
        "Jungseul Ok",
        "Yunsu Kim",
        "Gary Geunbae Lee"
      ],
      "abstract": "Research on hate speech has predominantly revolved around detection and\ninterpretation from textual inputs, leaving verbal content largely unexplored.\nWhile there has been limited exploration into hate speech detection within\nverbal acoustic speech inputs, the aspect of interpretability has been\noverlooked. Therefore, we introduce a new task of explainable audio hate speech\ndetection. Specifically, we aim to identify the precise time intervals,\nreferred to as audio frame-level rationales, which serve as evidence for hate\nspeech classification. Towards this end, we propose two different approaches:\ncascading and End-to-End (E2E). The cascading approach initially converts audio\nto transcripts, identifies hate speech within these transcripts, and\nsubsequently locates the corresponding audio time frames. Conversely, the E2E\napproach processes audio utterances directly, which allows it to pinpoint hate\nspeech within specific time frames. Additionally, due to the lack of\nexplainable audio hate speech datasets that include audio frame-level\nrationales, we curated a synthetic audio dataset to train our models. We\nfurther validated these models on actual human speech utterances and found that\nthe E2E approach outperforms the cascading method in terms of the audio frame\nIntersection over Union (IoU) metric. Furthermore, we observed that including\nframe-level rationales significantly enhances hate speech detection accuracy\nfor the E2E approach.\n  \\textbf{Disclaimer} The reader may encounter content of an offensive or\nhateful nature. However, given the nature of the work, this cannot be avoided.",
      "tldr_zh": "本研究调查了可解释音频仇恨言论检测（Explainable Audio Hate Speech Detection），填补了现有研究对音频输入的忽视，提出识别音频帧级理据（audio frame-level rationales）的全新任务，以提供仇恨言论分类的证据时间间隔。研究团队开发了两种方法：Cascading 方式（先将音频转录为文本、检测文本仇恨并映射回音频帧）和 End-to-End (E2E) 方式（直接处理音频以定位仇恨帧），并创建了一个合成音频数据集用于模型训练。实验结果显示，E2E 方法在音频帧 Intersection over Union (IoU) 指标上优于 Cascading 方法，且加入帧级理据显著提升了仇恨言论检测的准确率。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.SD",
        "eess.AS"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to SIGDIAL 2024",
      "pdf_url": "http://arxiv.org/pdf/2408.06065v1",
      "published_date": "2024-08-12 11:32:34 UTC",
      "updated_date": "2024-08-12 11:32:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:45:09.162590"
    },
    {
      "arxiv_id": "2408.06051v2",
      "title": "Perceptual Similarity for Measuring Decision-Making Style and Policy Diversity in Games",
      "title_zh": "感知相似性用于测量游戏中的决策风格和策略多样性",
      "authors": [
        "Chiu-Chou Lin",
        "Wei-Chen Chiu",
        "I-Chen Wu"
      ],
      "abstract": "Defining and measuring decision-making styles, also known as playstyles, is\ncrucial in gaming, where these styles reflect a broad spectrum of individuality\nand diversity. However, finding a universally applicable measure for these\nstyles poses a challenge. Building on Playstyle Distance, the first\nunsupervised metric to measure playstyle similarity based on game screens and\nraw actions, we introduce three enhancements to increase accuracy: multiscale\nanalysis with varied state granularity, a perceptual kernel rooted in\npsychology, and the utilization of the intersection-over-union method for\nefficient evaluation. These innovations not only advance measurement precision\nbut also offer insights into human cognition of similarity. Across two racing\ngames and seven Atari games, our techniques significantly improve the precision\nof zero-shot playstyle classification, achieving an accuracy exceeding 90\npercent with fewer than 512 observation-action pairs, which is less than half\nan episode of these games. Furthermore, our experiments with 2048 and Go\ndemonstrate the potential of discrete playstyle measures in puzzle and board\ngames. We also develop an algorithm for assessing decision-making diversity\nusing these measures. Our findings improve the measurement of end-to-end game\nanalysis and the evolution of artificial intelligence for diverse playstyles.",
      "tldr_zh": "本文提出了一种基于感知相似性的方法，用于测量游戏中的决策风格（playstyles）和策略多样性（policy diversity）。构建于 Playstyle Distance 基础上，该方法引入 multiscale analysis、多尺度分析、perceptual kernel、感知内核和 intersection-over-union method、交并比方法等增强技术，提高了测量精度并揭示了人类认知相似性的洞见。在多个游戏测试中（如赛车和 Atari 游戏），该方法实现了零样本 playstyle 分类准确率超过90%，并扩展到益智游戏如2048和围棋。最终，该研究开发了决策多样性评估算法，提升了端到端游戏分析和AI适应多样化playstyles的能力。",
      "categories": [
        "cs.AI",
        "cs.IR",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "TMLR 08/2024 https://openreview.net/forum?id=30C9AWBW49",
      "pdf_url": "http://arxiv.org/pdf/2408.06051v2",
      "published_date": "2024-08-12 10:55:42 UTC",
      "updated_date": "2024-08-30 03:19:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:45:22.082904"
    },
    {
      "arxiv_id": "2408.06042v1",
      "title": "Understanding Byzantine Robustness in Federated Learning with A Black-box Server",
      "title_zh": "翻译失败",
      "authors": [
        "Fangyuan Zhao",
        "Yuexiang Xie",
        "Xuebin Ren",
        "Bolin Ding",
        "Shusen Yang",
        "Yaliang Li"
      ],
      "abstract": "Federated learning (FL) becomes vulnerable to Byzantine attacks where some of\nparticipators tend to damage the utility or discourage the convergence of the\nlearned model via sending their malicious model updates. Previous works propose\nto apply robust rules to aggregate updates from participators against different\ntypes of Byzantine attacks, while at the same time, attackers can further\ndesign advanced Byzantine attack algorithms targeting specific aggregation rule\nwhen it is known. In practice, FL systems can involve a black-box server that\nmakes the adopted aggregation rule inaccessible to participants, which can\nnaturally defend or weaken some Byzantine attacks. In this paper, we provide an\nin-depth understanding on the Byzantine robustness of the FL system with a\nblack-box server. Our investigation demonstrates the improved Byzantine\nrobustness of a black-box server employing a dynamic defense strategy. We\nprovide both empirical evidence and theoretical analysis to reveal that the\nblack-box server can mitigate the worst-case attack impact from a maximum level\nto an expectation level, which is attributed to the inherent inaccessibility\nand randomness offered by a black-box server.The source code is available at\nhttps://github.com/alibaba/FederatedScope/tree/Byzantine_attack_defense to\npromote further research in the community.",
      "tldr_zh": "该论文探讨了在联邦学习（Federated Learning, FL）中，使用黑-box服务器如何提升对Byzantine attacks的鲁棒性，这些攻击通过发送恶意模型更新来破坏模型效用或收敛。研究通过经验证据和理论分析，证明黑-box服务器的不可访问性和随机性可以将攻击影响从最坏情况降至期望水平，并采用动态防御策略来缓解攻击。结果显示，这种方法显著提高了FL系统的Byzantine鲁棒性，为进一步研究提供了开源代码支持。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "We have released code on\n  https://github.com/alibaba/FederatedScope/tree/Byzantine_attack_defense",
      "pdf_url": "http://arxiv.org/pdf/2408.06042v1",
      "published_date": "2024-08-12 10:18:24 UTC",
      "updated_date": "2024-08-12 10:18:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:45:31.672961"
    },
    {
      "arxiv_id": "2408.06039v1",
      "title": "Spacetime $E(n)$-Transformer: Equivariant Attention for Spatio-temporal Graphs",
      "title_zh": "翻译失败",
      "authors": [
        "Sergio G. Charles"
      ],
      "abstract": "We introduce an $E(n)$-equivariant Transformer architecture for\nspatio-temporal graph data. By imposing rotation, translation, and permutation\nequivariance inductive biases in both space and time, we show that the\nSpacetime $E(n)$-Transformer (SET) outperforms purely spatial and temporal\nmodels without symmetry-preserving properties. We benchmark SET against said\nmodels on the charged $N$-body problem, a simple physical system with complex\ndynamics. While existing spatio-temporal graph neural networks focus on\nsequential modeling, we empirically demonstrate that leveraging underlying\ndomain symmetries yields considerable improvements for modeling dynamical\nsystems on graphs.",
      "tldr_zh": "我们提出Spacetime $E(n)$-Transformer (SET)，这是一种针对时空图数据的$E(n)$-equivariant Transformer架构，通过在空间和时间上施加旋转、平移和置换等变性归纳偏差来提升模型性能。在带电N体问题等基准测试中，SET显著优于纯空间或时间模型，展示了利用底层域对称性对复杂动态系统的建模带来的改进。该框架强调了在时空图神经网络中融入对称性属性，能够有效改善顺序建模的局限性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.06039v1",
      "published_date": "2024-08-12 10:13:45 UTC",
      "updated_date": "2024-08-12 10:13:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:45:44.989288"
    },
    {
      "arxiv_id": "2408.06036v1",
      "title": "Peaking into the Black-box: Prediction Intervals Give Insight into Data-driven Quadrotor Model Reliability",
      "title_zh": "翻译失败",
      "authors": [
        "Jasper van Beers",
        "Coen de Visser"
      ],
      "abstract": "Ensuring the reliability and validity of data-driven quadrotor model\npredictions is essential for their accepted and practical use. This is\nespecially true for grey- and black-box models wherein the mapping of inputs to\npredictions is not transparent and subsequent reliability notoriously difficult\nto ascertain. Nonetheless, such techniques are frequently and successfully used\nto identify quadrotor models. Prediction intervals (PIs) may be employed to\nprovide insight into the consistency and accuracy of model predictions. This\npaper estimates such PIs for polynomial and Artificial Neural Network (ANN)\nquadrotor aerodynamic models. Two existing ANN PI estimation techniques - the\nbootstrap method and the quality driven method - are validated numerically for\nquadrotor aerodynamic models using an existing high-fidelity quadrotor\nsimulation. Quadrotor aerodynamic models are then identified on real quadrotor\nflight data to demonstrate their utility and explore their sensitivity to model\ninterpolation and extrapolation. It is found that the ANN-based PIs widen\nconsiderably when extrapolating and remain constant, or shrink, when\ninterpolating. While this behaviour also occurs for the polynomial PIs, it is\nof lower magnitude. The estimated PIs establish probabilistic bounds within\nwhich the quadrotor model outputs will likely lie, subject to modelling and\nmeasurement uncertainties that are reflected through the PI widths.",
      "tldr_zh": "本研究探讨了数据驱动的四旋翼无人机（quadrotor）模型的可靠性和有效性，特别针对灰盒和黑盒模型的不透明问题，通过 Prediction Intervals (PIs) 来评估模型预测的一致性和准确性。论文比较了多项式模型和 Artificial Neural Network (ANN) 空气动力学模型，使用 bootstrap method 和 quality driven method 在高保真模拟和真实飞行数据上进行验证。结果显示，ANN-based PIs 在模型外推时显著变宽，而在插值时保持不变或缩小，与多项式 PIs 的变化幅度相比更剧烈。这些发现为建立模型输出的概率边界提供了洞见，帮助量化建模和测量不确定性，从而提升自主系统设计的可靠性。",
      "categories": [
        "eess.SY",
        "cs.AI",
        "cs.SY"
      ],
      "primary_category": "eess.SY",
      "comment": "Presented at AIAA SciTech Forum 2023 in National Harbor, MD, USA",
      "pdf_url": "http://arxiv.org/pdf/2408.06036v1",
      "published_date": "2024-08-12 09:57:00 UTC",
      "updated_date": "2024-08-12 09:57:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:46:00.183725"
    },
    {
      "arxiv_id": "2408.06022v1",
      "title": "Controlling Surprisal in Music Generation via Information Content Curve Matching",
      "title_zh": "翻译失败",
      "authors": [
        "Mathias Rose Bjare",
        "Stefan Lattner",
        "Gerhard Widmer"
      ],
      "abstract": "In recent years, the quality and public interest in music generation systems\nhave grown, encouraging research into various ways to control these systems. We\npropose a novel method for controlling surprisal in music generation using\nsequence models. To achieve this goal, we define a metric called Instantaneous\nInformation Content (IIC). The IIC serves as a proxy function for the perceived\nmusical surprisal (as estimated from a probabilistic model) and can be\ncalculated at any point within a music piece. This enables the comparison of\nsurprisal across different musical content even if the musical events occur in\nirregular time intervals. We use beam search to generate musical material whose\nIIC curve closely approximates a given target IIC. We experimentally show that\nthe IIC correlates with harmonic and rhythmic complexity and note density. The\ncorrelation decreases with the length of the musical context used for\nestimating the IIC. Finally, we conduct a qualitative user study to test if\nhuman listeners can identify the IIC curves that have been used as targets when\ngenerating the respective musical material. We provide code for creating IIC\ninterpolations and IIC visualizations on https://github.com/muthissar/iic.",
      "tldr_zh": "这篇论文提出了一种通过信息内容曲线匹配来控制音乐生成中惊喜度（surprisal）的新方法，定义了 Instantaneous Information Content (IIC) 作为音乐惊喜度的代理指标，以处理不规则时间间隔的音乐事件。研究使用 beam search 生成音乐，使其 IIC 曲线接近预设目标曲线。实验结果显示，IIC 与和声、节奏复杂度和音符密度高度相关，但相关性随音乐上下文长度减少。最后，用户研究验证了人类听众能够识别基于不同 IIC 曲线的音乐，并提供了相关代码以供进一步应用。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.CL",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "8 pages, 4 figures, 2 tables, accepted at the 25th Int. Society for\n  Music Information Retrieval Conf., San Francisco, USA, 2024",
      "pdf_url": "http://arxiv.org/pdf/2408.06022v1",
      "published_date": "2024-08-12 09:21:41 UTC",
      "updated_date": "2024-08-12 09:21:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:46:08.742709"
    },
    {
      "arxiv_id": "2408.06018v1",
      "title": "Uncertainty-Informed Volume Visualization using Implicit Neural Representation",
      "title_zh": "翻译失败",
      "authors": [
        "Shanu Saklani",
        "Chitwan Goel",
        "Shrey Bansal",
        "Zhe Wang",
        "Soumya Dutta",
        "Tushar M. Athawale",
        "David Pugmire",
        "Christopher R. Johnson"
      ],
      "abstract": "The increasing adoption of Deep Neural Networks (DNNs) has led to their\napplication in many challenging scientific visualization tasks. While advanced\nDNNs offer impressive generalization capabilities, understanding factors such\nas model prediction quality, robustness, and uncertainty is crucial. These\ninsights can enable domain scientists to make informed decisions about their\ndata. However, DNNs inherently lack ability to estimate prediction uncertainty,\nnecessitating new research to construct robust uncertainty-aware visualization\ntechniques tailored for various visualization tasks. In this work, we propose\nuncertainty-aware implicit neural representations to model scalar field data\nsets effectively and comprehensively study the efficacy and benefits of\nestimated uncertainty information for volume visualization tasks. We evaluate\nthe effectiveness of two principled deep uncertainty estimation techniques: (1)\nDeep Ensemble and (2) Monte Carlo Dropout (MCDropout). These techniques enable\nuncertainty-informed volume visualization in scalar field data sets. Our\nextensive exploration across multiple data sets demonstrates that\nuncertainty-aware models produce informative volume visualization results.\nMoreover, integrating prediction uncertainty enhances the trustworthiness of\nour DNN model, making it suitable for robustly analyzing and visualizing\nreal-world scientific volumetric data sets.",
      "tldr_zh": "该研究探讨了深度神经网络 (DNNs) 在科学可视化任务中的应用，强调了理解模型预测质量、鲁棒性和不确定性的重要性，以帮助领域科学家做出明智决策。论文提出了一种不确定性感知的隐式神经表示 (Implicit Neural Representation) 方法，用于有效建模标量场数据，并评估了两种不确定性估计技术：Deep Ensemble 和 Monte Carlo Dropout (MCDropout)。通过在多个数据集上的广泛实验，结果显示，这种不确定性感知方法能生成信息丰富的体积可视化结果，并提升模型的可信度，适用于真实世界的科学体积数据分析。",
      "categories": [
        "cs.GR",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.GR",
      "comment": "To appear in IEEE Workshop on Uncertainty Visualization in\n  conjunction with IEEE VIS 2024, Florida, USA",
      "pdf_url": "http://arxiv.org/pdf/2408.06018v1",
      "published_date": "2024-08-12 09:14:23 UTC",
      "updated_date": "2024-08-12 09:14:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:46:19.808743"
    },
    {
      "arxiv_id": "2408.05992v2",
      "title": "Transfer learning of state-based potential games for process optimization in decentralized manufacturing systems",
      "title_zh": "翻译失败",
      "authors": [
        "Steve Yuwono",
        "Dorothea Schwung",
        "Andreas Schwung"
      ],
      "abstract": "This paper presents a novel transfer learning approach in state-based\npotential games (TL-SbPGs) for enhancing distributed self-optimization in\nmanufacturing systems. The approach focuses on the practical relevant\nindustrial setting where sharing and transferring gained knowledge among\nsimilar-behaved players improves the self-learning mechanism in large-scale\nsystems. With TL-SbPGs, the gained knowledge can be reused by other players to\noptimize their policies, thereby improving the learning outcomes of the players\nand accelerating the learning process. To accomplish this goal, we develop\ntransfer learning concepts and similarity criteria for players, which offer two\ndistinct settings: (a) predefined similarities between players and (b)\ndynamically inferred similarities between players during training. We formally\nprove the applicability of the SbPG framework in transfer learning.\nAdditionally, we introduce an efficient method to determine the optimal timing\nand weighting of the transfer learning procedure during the training phase.\nThrough experiments on a laboratory-scale testbed, we demonstrate that TL-SbPGs\nsignificantly boost production efficiency while reducing power consumption of\nthe production schedules while also outperforming native SbPGs.",
      "tldr_zh": "本研究提出了一种基于转移学习（transfer learning）的状态-based potential games（TL-SbPGs）方法，用于提升分散制造系统的分布式自优化。通过开发玩家（players）间的相似性标准，包括预定义和动态推断设置，该方法允许知识在类似行为玩家之间共享，从而加速学习过程并优化策略。研究正式证明了SbPG框架在转移学习中的适用性，并引入了确定转移学习时机和权重的有效方法。实验结果显示，TL-SbPGs在实验室规模测试中显著提高了生产效率，同时降低了功率消耗，并优于原生SbPGs。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.GT"
      ],
      "primary_category": "cs.LG",
      "comment": "This revised pre-print was submitted to Computers in Industry on\n  October 11, 2024",
      "pdf_url": "http://arxiv.org/pdf/2408.05992v2",
      "published_date": "2024-08-12 08:40:20 UTC",
      "updated_date": "2024-10-11 09:41:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:46:31.669837"
    },
    {
      "arxiv_id": "2408.06397v1",
      "title": "Distributed Stackelberg Strategies in State-based Potential Games for Autonomous Decentralized Learning Manufacturing Systems",
      "title_zh": "翻译失败",
      "authors": [
        "Steve Yuwono",
        "Dorothea Schwung",
        "Andreas Schwung"
      ],
      "abstract": "This article describes a novel game structure for autonomously optimizing\ndecentralized manufacturing systems with multi-objective optimization\nchallenges, namely Distributed Stackelberg Strategies in State-Based Potential\nGames (DS2-SbPG). DS2-SbPG integrates potential games and Stackelberg games,\nwhich improves the cooperative trade-off capabilities of potential games and\nthe multi-objective optimization handling by Stackelberg games. Notably, all\ntraining procedures remain conducted in a fully distributed manner. DS2-SbPG\noffers a promising solution to finding optimal trade-offs between objectives by\neliminating the complexities of setting up combined objective optimization\nfunctions for individual players in self-learning domains, particularly in\nreal-world industrial settings with diverse and numerous objectives between the\nsub-systems. We further prove that DS2-SbPG constitutes a dynamic potential\ngame that results in corresponding converge guarantees. Experimental validation\nconducted on a laboratory-scale testbed highlights the efficacy of DS2-SbPG and\nits two variants, such as DS2-SbPG for single-leader-follower and Stack\nDS2-SbPG for multi-leader-follower. The results show significant reductions in\npower consumption and improvements in overall performance, which signals the\npotential of DS2-SbPG in real-world applications.",
      "tldr_zh": "这篇论文提出了一种新型游戏结构——Distributed Stackelberg Strategies in State-Based Potential Games (DS2-SbPG)，用于优化自治分散制造系统的多目标优化挑战。该框架整合了 potential games 的合作权衡能力和 Stackelberg games 的多目标处理能力，所有训练过程均采用完全分布式方式，以简化工业环境中子系统的目标优化复杂性。论文证明了 DS2-SbPG 作为动态 potential game 的收敛保证，并在实验室测试台上验证其变体，实现了显著的功率消耗减少和整体性能提升。",
      "categories": [
        "cs.GT",
        "cs.AI",
        "cs.LG",
        "cs.MA"
      ],
      "primary_category": "cs.GT",
      "comment": "This pre-print was submitted to IEEE Transactions on Systems, Man,\n  and Cybernetics: Systems on July 31, 2024",
      "pdf_url": "http://arxiv.org/pdf/2408.06397v1",
      "published_date": "2024-08-12 08:24:54 UTC",
      "updated_date": "2024-08-12 08:24:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:46:54.994704"
    },
    {
      "arxiv_id": "2408.07097v1",
      "title": "Attention Please: What Transformer Models Really Learn for Process Prediction",
      "title_zh": "翻译失败",
      "authors": [
        "Martin Käppel",
        "Lars Ackermann",
        "Stefan Jablonski",
        "Simon Härtl"
      ],
      "abstract": "Predictive process monitoring aims to support the execution of a process\nduring runtime with various predictions about the further evolution of a\nprocess instance. In the last years a plethora of deep learning architectures\nhave been established as state-of-the-art for different prediction targets,\namong others the transformer architecture. The transformer architecture is\nequipped with a powerful attention mechanism, assigning attention scores to\neach input part that allows to prioritize most relevant information leading to\nmore accurate and contextual output. However, deep learning models largely\nrepresent a black box, i.e., their reasoning or decision-making process cannot\nbe understood in detail. This paper examines whether the attention scores of a\ntransformer based next-activity prediction model can serve as an explanation\nfor its decision-making. We find that attention scores in next-activity\nprediction models can serve as explainers and exploit this fact in two proposed\ngraph-based explanation approaches. The gained insights could inspire future\nwork on the improvement of predictive business process models as well as\nenabling a neural network based mining of process models from event logs.",
      "tldr_zh": "这篇论文探讨了Transformer模型在预测过程监控中的注意力机制（attention scores），旨在揭示这些模型在过程预测（如下一个活动预测）中真正学习的内容。研究发现，注意力分数可以作为模型决策的解释器，并基于此提出了两种基于图的解释方法，以提升模型的可解释性。最终，这些见解有助于改进预测业务过程模型，并启发从事件日志中利用神经网络挖掘过程模型。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "68T07, 68T01, 68U35",
        "H.4.2; I.2.1; I.2.6"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.07097v1",
      "published_date": "2024-08-12 08:20:38 UTC",
      "updated_date": "2024-08-12 08:20:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:46:59.912833"
    },
    {
      "arxiv_id": "2408.06396v1",
      "title": "Design Proteins Using Large Language Models: Enhancements and Comparative Analyses",
      "title_zh": "使用大型语言模型设计蛋白质：增强与比较分析",
      "authors": [
        "Kamyar Zeinalipour",
        "Neda Jamshidi",
        "Monica Bianchini",
        "Marco Maggini",
        "Marco Gori"
      ],
      "abstract": "Pre-trained LLMs have demonstrated substantial capabilities across a range of\nconventional natural language processing (NLP) tasks, such as summarization and\nentity recognition. In this paper, we explore the application of LLMs in the\ngeneration of high-quality protein sequences. Specifically, we adopt a suite of\npre-trained LLMs, including Mistral-7B1, Llama-2-7B2, Llama-3-8B3, and\ngemma-7B4, to produce valid protein sequences. All of these models are publicly\navailable.5 Unlike previous work in this field, our approach utilizes a\nrelatively small dataset comprising 42,000 distinct human protein sequences. We\nretrain these models to process protein-related data, ensuring the generation\nof biologically feasible protein structures. Our findings demonstrate that even\nwith limited data, the adapted models exhibit efficiency comparable to\nestablished protein-focused models such as ProGen varieties, ProtGPT2, and\nProLLaMA, which were trained on millions of protein sequences. To validate and\nquantify the performance of our models, we conduct comparative analyses\nemploying standard metrics such as pLDDT, RMSD, TM-score, and REU. Furthermore,\nwe commit to making the trained versions of all four models publicly available,\nfostering greater transparency and collaboration in the field of computational\nbiology.",
      "tldr_zh": "本研究探讨了使用大型语言模型（LLMs）如 Mistral-7B、Llama-2-7B、Llama-3-8B 和 gemma-7B 生成高质量蛋白质序列的方法，仅基于一个包含42,000个独特人类蛋白质序列的小数据集对这些模型进行重新训练，以确保生成生物上可行的蛋白结构。结果显示，这些适应后的模型在效率上与专门的蛋白质模型（如 ProGen varieties、ProtGPT2 和 ProLLaMA）相当，尽管训练数据有限。研究通过标准指标（pLDDT、RMSD、TM-score 和 REU）进行比较分析，并承诺公开训练后的模型，以推动计算生物学的透明度和合作。",
      "categories": [
        "q-bio.QM",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "q-bio.QM",
      "comment": "This paper has been accepted for presentation at Language and\n  Molecules ACL 2024",
      "pdf_url": "http://arxiv.org/pdf/2408.06396v1",
      "published_date": "2024-08-12 08:17:27 UTC",
      "updated_date": "2024-08-12 08:17:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:47:08.950896"
    },
    {
      "arxiv_id": "2408.05982v2",
      "title": "Exploring and Learning Structure: Active Inference Approach in Navigational Agents",
      "title_zh": "探索和学习结构：Active Inference 方法在导航代理中的应用",
      "authors": [
        "Daria de Tinguy",
        "Tim Verbelen",
        "Bart Dhoedt"
      ],
      "abstract": "Drawing inspiration from animal navigation strategies, we introduce a novel\ncomputational model for navigation and mapping, rooted in biologically inspired\nprinciples. Animals exhibit remarkable navigation abilities by efficiently\nusing memory, imagination, and strategic decision-making to navigate complex\nand aliased environments. Building on these insights, we integrate traditional\ncognitive mapping approaches with an Active Inference Framework (AIF) to learn\nan environment structure in a few steps. Through the incorporation of\ntopological mapping for long-term memory and AIF for navigation planning and\nstructure learning, our model can dynamically apprehend environmental\nstructures and expand its internal map with predicted beliefs during\nexploration. Comparative experiments with the Clone-Structured Graph (CSCG)\nmodel highlight our model's ability to rapidly learn environmental structures\nin a single episode, with minimal navigation overlap. this is achieved without\nprior knowledge of the dimensions of the environment or the type of\nobservations, showcasing its robustness and effectiveness in navigating\nambiguous environments.",
      "tldr_zh": "这篇论文从动物导航策略中汲取灵感，提出了一种新的计算模型，将传统的认知映射方法与 Active Inference Framework (AIF) 整合，用于导航代理快速学习环境结构。该模型通过拓扑映射处理长期记忆，并利用 AIF 进行导航规划和动态结构学习，能够在少数步骤中扩展内部地图，而无需预先知道环境维度或观察类型。与 Clone-Structured Graph (CSCG) 模型相比，实验结果显示该模型在单次情节中显著减少导航重叠，提升了在模糊环境中的鲁棒性。",
      "categories": [
        "cs.AI",
        "cs.NE",
        "cs.RO"
      ],
      "primary_category": "cs.AI",
      "comment": "IWAI workshop 2024",
      "pdf_url": "http://arxiv.org/pdf/2408.05982v2",
      "published_date": "2024-08-12 08:17:14 UTC",
      "updated_date": "2024-09-02 08:48:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:47:20.784632"
    },
    {
      "arxiv_id": "2408.05966v2",
      "title": "Freehand Sketch Generation from Mechanical Components",
      "title_zh": "从机械部件生成自由手绘草图",
      "authors": [
        "Zhichao Liao",
        "Di Huang",
        "Heming Fang",
        "Yue Ma",
        "Fengyuan Piao",
        "Xinghui Li",
        "Long Zeng",
        "Pingfa Feng"
      ],
      "abstract": "Drawing freehand sketches of mechanical components on multimedia devices for\nAI-based engineering modeling has become a new trend. However, its development\nis being impeded because existing works cannot produce suitable sketches for\ndata-driven research. These works either generate sketches lacking a freehand\nstyle or utilize generative models not originally designed for this task\nresulting in poor effectiveness. To address this issue, we design a two-stage\ngenerative framework mimicking the human sketching behavior pattern, called\nMSFormer, which is the first time to produce humanoid freehand sketches\ntailored for mechanical components. The first stage employs Open CASCADE\ntechnology to obtain multi-view contour sketches from mechanical components,\nfiltering perturbing signals for the ensuing generation process. Meanwhile, we\ndesign a view selector to simulate viewpoint selection tasks during human\nsketching for picking out information-rich sketches. The second stage\ntranslates contour sketches into freehand sketches by a transformer-based\ngenerator. To retain essential modeling features as much as possible and\nrationalize stroke distribution, we introduce a novel edge-constraint stroke\ninitialization. Furthermore, we utilize a CLIP vision encoder and a new loss\nfunction incorporating the Hausdorff distance to enhance the generalizability\nand robustness of the model. Extensive experiments demonstrate that our\napproach achieves state-of-the-art performance for generating freehand sketches\nin the mechanical domain. Project page: https://mcfreeskegen.github.io .",
      "tldr_zh": "该论文提出了 MSFormer，一种两阶段生成框架，旨在从机械组件生成模仿人类行为的自由手绘草图，以解决现有方法缺乏自由手绘风格或生成效果不佳的问题。第一阶段利用 Open CASCADE 技术获取多视图轮廓草图，并设计视图选择器过滤干扰信号和选择信息丰富的视图；第二阶段通过 Transformer-based 生成器将轮廓草图转化为自由手绘草图，引入 edge-constraint stroke initialization 和结合 CLIP 视觉编码器与 Hausdorff distance 损失函数，提升模型的泛化性和鲁棒性。实验结果表明，该方法在机械领域实现了 state-of-the-art 性能，为 AI 驱动的工程建模提供高质量数据支持。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.GR",
        "cs.MM"
      ],
      "primary_category": "cs.CV",
      "comment": "Published at ACM Multimedia (ACM MM) 2024",
      "pdf_url": "http://arxiv.org/pdf/2408.05966v2",
      "published_date": "2024-08-12 07:44:19 UTC",
      "updated_date": "2024-08-21 10:28:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:47:33.505966"
    },
    {
      "arxiv_id": "2408.05960v1",
      "title": "Match Point AI: A Novel AI Framework for Evaluating Data-Driven Tennis Strategies",
      "title_zh": "Match Point AI：用于评估数据驱动网球策略的新颖AI框架",
      "authors": [
        "Carlo Nübel",
        "Alexander Dockhorn",
        "Sanaz Mostaghim"
      ],
      "abstract": "Many works in the domain of artificial intelligence in games focus on board\nor video games due to the ease of reimplementing their mechanics.\nDecision-making problems in real-world sports share many similarities to such\ndomains. Nevertheless, not many frameworks on sports games exist. In this\npaper, we present the tennis match simulation environment \\textit{Match Point\nAI}, in which different agents can compete against real-world data-driven bot\nstrategies. Next to presenting the framework, we highlight its capabilities by\nillustrating, how MCTS can be used in Match Point AI to optimize the shot\ndirection selection problem in tennis. While the framework will be extended in\nthe future, first experiments already reveal that generated shot-by-shot data\nof simulated tennis matches show realistic characteristics when compared to\nreal-world data. At the same time, reasonable shot placement strategies emerge,\nwhich share similarities to the ones found in real-world tennis matches.",
      "tldr_zh": "本论文提出了一种新型 AI 框架 Match Point AI，用于评估数据驱动的网球策略，通过模拟网球比赛环境让不同代理与基于真实数据的机器人策略竞争。框架的关键功能包括利用 MCTS (Monte Carlo Tree Search) 优化击球方向选择问题，从而解决真实体育决策的挑战。实验结果表明，模拟生成的击球数据与真实世界数据具有相似特性，并产生了合理的策略，与实际网球比赛策略相符。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "4 pages, 1 page abstract, short paper, to be published in Proceedings\n  of the IEEE Conference on Games 2024",
      "pdf_url": "http://arxiv.org/pdf/2408.05960v1",
      "published_date": "2024-08-12 07:22:46 UTC",
      "updated_date": "2024-08-12 07:22:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:47:43.739773"
    },
    {
      "arxiv_id": "2408.05959v1",
      "title": "Markov Senior -- Learning Markov Junior Grammars to Generate User-specified Content",
      "title_zh": "翻译失败",
      "authors": [
        "Mehmet Kayra Oğuz",
        "Alexander Dockhorn"
      ],
      "abstract": "Markov Junior is a probabilistic programming language used for procedural\ncontent generation across various domains. However, its reliance on manually\ncrafted and tuned probabilistic rule sets, also called grammars, presents a\nsignificant bottleneck, diverging from approaches that allow rule learning from\nexamples. In this paper, we propose a novel solution to this challenge by\nintroducing a genetic programming-based optimization framework for learning\nhierarchical rule sets automatically. Our proposed method ``Markov Senior''\nfocuses on extracting positional and distance relations from single input\nsamples to construct probabilistic rules to be used by Markov Junior. Using a\nKullback-Leibler divergence-based fitness measure, we search for grammars to\ngenerate content that is coherent with the given sample. To enhance\nscalability, we introduce a divide-and-conquer strategy that enables the\nefficient generation of large-scale content. We validate our approach through\nexperiments in generating image-based content and Super Mario levels,\ndemonstrating its flexibility and effectiveness. In this way, ``Markov Senior''\nallows for the wider application of Markov Junior for tasks in which an example\nmay be available, but the design of a generative rule set is infeasible.",
      "tldr_zh": "这篇论文提出了Markov Senior，一种基于genetic programming的优化框架，用于自动学习Markov Junior的层次化grammars，从而解决其依赖手动规则集的瓶颈问题。方法从单个输入样本中提取位置和距离关系，构建概率规则，并采用Kullback-Leibler divergence作为fitness measure来搜索生成与样本一致的内容。同时，引入divide-and-conquer策略以提升大规模内容生成的效率和可扩展性。通过在图像生成和Super Mario关卡上的实验，论文证明了Markov Senior的有效性和灵活性，使Markov Junior能更广泛应用于有样本但规则设计不现实的任务。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "8 pages, to be published in the Proceedings of the IEEE Conference on\n  Games 2024, demo implementation can be found here:\n  https://github.com/ADockhorn/MarkovSenior",
      "pdf_url": "http://arxiv.org/pdf/2408.05959v1",
      "published_date": "2024-08-12 07:22:33 UTC",
      "updated_date": "2024-08-12 07:22:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:47:57.787098"
    },
    {
      "arxiv_id": "2408.05950v2",
      "title": "Robust online reconstruction of continuous-time signals from a lean spike train ensemble code",
      "title_zh": "翻译失败",
      "authors": [
        "Anik Chattopadhyay",
        "Arunava Banerjee"
      ],
      "abstract": "Sensory stimuli in animals are encoded into spike trains by neurons, offering\nadvantages such as sparsity, energy efficiency, and high temporal resolution.\nThis paper presents a signal processing framework that deterministically\nencodes continuous-time signals into biologically feasible spike trains, and\naddresses the questions about representable signal classes and reconstruction\nbounds. The framework considers encoding of a signal through spike trains\ngenerated by an ensemble of neurons using a convolve-then-threshold mechanism\nwith various convolution kernels. A closed-form solution to the inverse\nproblem, from spike trains to signal reconstruction, is derived in the Hilbert\nspace of shifted kernel functions, ensuring sparse representation of a\ngeneralized Finite Rate of Innovation (FRI) class of signals. Additionally,\ninspired by real-time processing in biological systems, an efficient iterative\nversion of the optimal reconstruction is formulated that considers only a\nfinite window of past spikes, ensuring robustness of the technique to\nill-conditioned encoding; convergence guarantees of the windowed reconstruction\nto the optimal solution are then provided. Experiments on a large audio dataset\ndemonstrate excellent reconstruction accuracy at spike rates as low as\none-fifth of the Nyquist rate, while showing clear competitive advantage in\ncomparison to state-of-the-art sparse coding techniques in the low spike rate\nregime.",
      "tldr_zh": "本文提出一个信号处理框架，用于将连续时间信号确定性地编码成生物可行的 spike trains，并探讨可表示的信号类别（如广义 Finite Rate of Innovation (FRI) 类信号）和重建边界。该框架采用一组神经元的 convolve-then-threshold 机制生成 spike trains，并在 Hilbert space 中推导了从 spike trains 到信号的闭式重建解，同时开发了一个高效的迭代窗口重建方法，以实现实时处理并确保对 ill-conditioned 编码的鲁棒性。实验结果显示，在一个大型音频数据集上，该方法在低 spike rate（如低于 Nyquist rate 的五分之一）下实现了优秀的重建准确性，并明显优于现有稀疏编码技术。",
      "categories": [
        "cs.NE",
        "cs.AI",
        "cs.SD",
        "eess.AS"
      ],
      "primary_category": "cs.NE",
      "comment": "22 pages, including a 9-page appendix, 8 figures. A GitHub link to\n  the project implementation is embedded in the paper",
      "pdf_url": "http://arxiv.org/pdf/2408.05950v2",
      "published_date": "2024-08-12 06:55:51 UTC",
      "updated_date": "2024-08-14 16:43:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:48:11.873170"
    },
    {
      "arxiv_id": "2408.05941v1",
      "title": "Multimodal Large Language Models for Phishing Webpage Detection and Identification",
      "title_zh": "多模态大语言模型用于钓鱼网页检测和",
      "authors": [
        "Jehyun Lee",
        "Peiyuan Lim",
        "Bryan Hooi",
        "Dinil Mon Divakaran"
      ],
      "abstract": "To address the challenging problem of detecting phishing webpages,\nresearchers have developed numerous solutions, in particular those based on\nmachine learning (ML) algorithms. Among these, brand-based phishing detection\nthat uses models from Computer Vision to detect if a given webpage is imitating\na well-known brand has received widespread attention. However, such models are\ncostly and difficult to maintain, as they need to be retrained with labeled\ndataset that has to be regularly and continuously collected. Besides, they also\nneed to maintain a good reference list of well-known websites and related\nmeta-data for effective performance.\n  In this work, we take steps to study the efficacy of large language models\n(LLMs), in particular the multimodal LLMs, in detecting phishing webpages.\nGiven that the LLMs are pretrained on a large corpus of data, we aim to make\nuse of their understanding of different aspects of a webpage (logo, theme,\nfavicon, etc.) to identify the brand of a given webpage and compare the\nidentified brand with the domain name in the URL to detect a phishing attack.\nWe propose a two-phase system employing LLMs in both phases: the first phase\nfocuses on brand identification, while the second verifies the domain. We carry\nout comprehensive evaluations on a newly collected dataset. Our experiments\nshow that the LLM-based system achieves a high detection rate at high\nprecision; importantly, it also provides interpretable evidence for the\ndecisions. Our system also performs significantly better than a\nstate-of-the-art brand-based phishing detection system while demonstrating\nrobustness against two known adversarial attacks.",
      "tldr_zh": "这篇论文探讨了使用 Multimodal Large Language Models (LLMs) 来检测和识别钓鱼网页的问题，旨在解决传统机器学习方法（如品牌-based 检测）的成本高和维护难等问题。研究提出一个两阶段系统：第一阶段利用 LLMs 分析网页元素（如 logo、主题和 favicon）来识别品牌，第二阶段将识别的品牌与 URL 中的域名进行比较，以检测潜在的钓鱼攻击。该系统在新收集的数据集上进行评估，显示出高检测率和高精确度，同时提供可解释的决策证据，并比现有最先进系统更具鲁棒性，对已知对抗攻击表现出色。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "To appear in eCrime 2024",
      "pdf_url": "http://arxiv.org/pdf/2408.05941v1",
      "published_date": "2024-08-12 06:36:08 UTC",
      "updated_date": "2024-08-12 06:36:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:48:21.071817"
    },
    {
      "arxiv_id": "2408.05940v2",
      "title": "Spb3DTracker: A Robust LiDAR-Based Person Tracker for Noisy Environment",
      "title_zh": "翻译失败",
      "authors": [
        "Eunsoo Im",
        "Changhyun Jee",
        "Jung Kwon Lee"
      ],
      "abstract": "Person detection and tracking (PDT) has seen significant advancements with 2D\ncamera-based systems in the autonomous vehicle field, leading to widespread\nadoption of these algorithms. However, growing privacy concerns have recently\nemerged as a major issue, prompting a shift towards LiDAR-based PDT as a viable\nalternative. Within this domain, \"Tracking-by-Detection\" (TBD) has become a\nprominent methodology. Despite its effectiveness, LiDAR-based PDT has not yet\nachieved the same level of performance as camera-based PDT. This paper examines\nkey components of the LiDAR-based PDT framework, including detection\npost-processing, data association, motion modeling, and lifecycle management.\nBuilding upon these insights, we introduce SpbTrack, a robust person tracker\ndesigned for diverse environments. Our method achieves superior performance on\nnoisy datasets and state-of-the-art results on KITTI Dataset benchmarks and\ncustom office indoor dataset among LiDAR-based trackers.",
      "tldr_zh": "这篇论文探讨了人检测和跟踪(PDT)从2D相机系统转向LiDAR-based系统的转变，以应对日益严重的隐私问题，但LiDAR-based PDT的性能仍落后于相机系统。作者分析了LiDAR-based PDT的关键组件，包括检测后处理、数据关联、运动建模和生命周期管理，并提出Spb3DTracker，一种针对多样化环境的鲁棒跟踪器。该方法在嘈杂数据集上实现了卓越性能，并在KITTI Dataset基准测试以及自定义办公室室内数据集上达到了LiDAR-based跟踪器的State-of-the-Art结果。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "17 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2408.05940v2",
      "published_date": "2024-08-12 06:33:38 UTC",
      "updated_date": "2024-08-13 05:18:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:48:33.334946"
    },
    {
      "arxiv_id": "2408.05933v1",
      "title": "Optimizing RAG Techniques for Automotive Industry PDF Chatbots: A Case Study with Locally Deployed Ollama Models",
      "title_zh": "翻译失败",
      "authors": [
        "Fei Liu",
        "Zejun Kang",
        "Xing Han"
      ],
      "abstract": "With the growing demand for offline PDF chatbots in automotive industrial\nproduction environments, optimizing the deployment of large language models\n(LLMs) in local, low-performance settings has become increasingly important.\nThis study focuses on enhancing Retrieval-Augmented Generation (RAG) techniques\nfor processing complex automotive industry documents using locally deployed\nOllama models. Based on the Langchain framework, we propose a multi-dimensional\noptimization approach for Ollama's local RAG implementation. Our method\naddresses key challenges in automotive document processing, including\nmulti-column layouts and technical specifications. We introduce improvements in\nPDF processing, retrieval mechanisms, and context compression, tailored to the\nunique characteristics of automotive industry documents. Additionally, we\ndesign custom classes supporting embedding pipelines and an agent supporting\nself-RAG based on LangGraph best practices. To evaluate our approach, we\nconstructed a proprietary dataset comprising typical automotive industry\ndocuments, including technical reports and corporate regulations. We compared\nour optimized RAG model and self-RAG agent against a naive RAG baseline across\nthree datasets: our automotive industry dataset, QReCC, and CoQA. Results\ndemonstrate significant improvements in context precision, context recall,\nanswer relevancy, and faithfulness, with particularly notable performance on\nthe automotive industry dataset. Our optimization scheme provides an effective\nsolution for deploying local RAG systems in the automotive sector, addressing\nthe specific needs of PDF chatbots in industrial production environments. This\nresearch has important implications for advancing information processing and\nintelligent production in the automotive industry.",
      "tldr_zh": "这篇论文针对汽车工业生产环境的离线 PDF 聊天机器人，优化了 Retrieval-Augmented Generation (RAG) 技术，使用本地部署的 Ollama 模型。研究基于 Langchain 框架，提出多维优化方法，包括改进 PDF 处理（如处理多列布局）、检索机制和上下文压缩，并设计自定义类支持嵌入管道和基于 LangGraph 的自 RAG 代理。实验使用专有汽车行业数据集（包括技术报告和公司法规）与其他数据集（如 QReCC 和 CoQA）进行评估，结果显示优化模型在上下文精确性、召回率、答案相关性和忠实度上显著提升，尤其在汽车数据集上提高了性能。该优化方案为汽车行业的本地 RAG 系统部署提供了有效解决方案，提升了信息处理和智能生产水平。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.05933v1",
      "published_date": "2024-08-12 06:16:37 UTC",
      "updated_date": "2024-08-12 06:16:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:48:48.251271"
    },
    {
      "arxiv_id": "2408.05926v1",
      "title": "BI-MDRG: Bridging Image History in Multimodal Dialogue Response Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Hee Suk Yoon",
        "Eunseop Yoon",
        "Joshua Tian Jin Tee",
        "Kang Zhang",
        "Yu-Jung Heo",
        "Du-Seong Chang",
        "Chang D. Yoo"
      ],
      "abstract": "Multimodal Dialogue Response Generation (MDRG) is a recently proposed task\nwhere the model needs to generate responses in texts, images, or a blend of\nboth based on the dialogue context. Due to the lack of a large-scale dataset\nspecifically for this task and the benefits of leveraging powerful pre-trained\nmodels, previous work relies on the text modality as an intermediary step for\nboth the image input and output of the model rather than adopting an end-to-end\napproach. However, this approach can overlook crucial information about the\nimage, hindering 1) image-grounded text response and 2) consistency of objects\nin the image response. In this paper, we propose BI-MDRG that bridges the\nresponse generation path such that the image history information is utilized\nfor enhanced relevance of text responses to the image content and the\nconsistency of objects in sequential image responses. Through extensive\nexperiments on the multimodal dialogue benchmark dataset, we show that BI-MDRG\ncan effectively increase the quality of multimodal dialogue. Additionally,\nrecognizing the gap in benchmark datasets for evaluating the image consistency\nin multimodal dialogue, we have created a curated set of 300 dialogues\nannotated to track object consistency across conversations.",
      "tldr_zh": "本论文提出 BI-MDRG 方法，用于提升 Multimodal Dialogue Response Generation (MDRG)，通过桥接图像历史信息来解决现有方法忽略图像细节的问题，从而提高文本响应的图像相关性和图像响应的对象一致性。BI-MDRG 采用端到端生成路径，利用图像历史增强对话上下文的相关性，并在多模态对话基准数据集上进行广泛实验，证明其有效性。论文还创建了一个包含 300 个标注对话的自定义数据集，用于评估图像一致性benchmark。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "cs.MM"
      ],
      "primary_category": "cs.AI",
      "comment": "ECCV 2024",
      "pdf_url": "http://arxiv.org/pdf/2408.05926v1",
      "published_date": "2024-08-12 05:22:42 UTC",
      "updated_date": "2024-08-12 05:22:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:48:59.171897"
    },
    {
      "arxiv_id": "2408.10255v2",
      "title": "Large Investment Model",
      "title_zh": "翻译失败",
      "authors": [
        "Jian Guo",
        "Heung-Yeung Shum"
      ],
      "abstract": "Traditional quantitative investment research is encountering diminishing\nreturns alongside rising labor and time costs. To overcome these challenges, we\nintroduce the Large Investment Model (LIM), a novel research paradigm designed\nto enhance both performance and efficiency at scale. LIM employs end-to-end\nlearning and universal modeling to create an upstream foundation model capable\nof autonomously learning comprehensive signal patterns from diverse financial\ndata spanning multiple exchanges, instruments, and frequencies. These \"global\npatterns\" are subsequently transferred to downstream strategy modeling,\noptimizing performance for specific tasks. We detail the system architecture\ndesign of LIM, address the technical challenges inherent in this approach, and\noutline potential directions for future research. The advantages of LIM are\ndemonstrated through a series of numerical experiments on cross-instrument\nprediction for commodity futures trading, leveraging insights from stock\nmarkets.",
      "tldr_zh": "本研究提出 Large Investment Model (LIM)，一个创新的投资研究范式，旨在解决传统量化投资的收益递减和成本上升问题，通过端到端学习和通用建模从多源金融数据中自动学习全面的“global patterns”。LIM 的系统架构将这些全局模式转移到下游策略建模中，优化特定任务的性能，并处理相关技术挑战。实验结果显示，在商品期货交易的跨工具预测任务上，LIM 显著提升了表现，为未来投资研究提供了新方向。",
      "categories": [
        "q-fin.ST",
        "cs.AI",
        "q-fin.CP"
      ],
      "primary_category": "q-fin.ST",
      "comment": "20 pages, 10 figures, 2 tables",
      "pdf_url": "http://arxiv.org/pdf/2408.10255v2",
      "published_date": "2024-08-12 05:15:13 UTC",
      "updated_date": "2024-08-22 07:57:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:49:09.600087"
    },
    {
      "arxiv_id": "2408.05924v2",
      "title": "Space-LLaVA: a Vision-Language Model Adapted to Extraterrestrial Applications",
      "title_zh": "翻译失败",
      "authors": [
        "Matthew Foutter",
        "Daniele Gammelli",
        "Justin Kruger",
        "Ethan Foss",
        "Praneet Bhoj",
        "Tommaso Guffanti",
        "Simone D'Amico",
        "Marco Pavone"
      ],
      "abstract": "Foundation Models (FMs), e.g., large language models, possess attributes of\nintelligence which offer promise to endow a robot with the contextual\nunderstanding necessary to navigate complex, unstructured tasks in the wild. We\nsee three core challenges in the future of space robotics that motivate\nbuilding an FM for the space robotics community: 1) Scalability of\nground-in-the-loop operations; 2) Generalizing prior knowledge to novel\nenvironments; and 3) Multi-modality in tasks and sensor data. As a first-step\ntowards a space foundation model, we programmatically augment three\nextraterrestrial databases with fine-grained language annotations inspired by\nthe sensory reasoning necessary to e.g., identify a site of scientific interest\non Mars, building a synthetic dataset of visual-question-answer and visual\ninstruction-following tuples. We fine-tune a pre-trained LLaVA 13B checkpoint\non our augmented dataset to adapt a Vision-Language Model (VLM) to the visual\nsemantic features in an extraterrestrial environment, demonstrating FMs as a\ntool for specialization and enhancing a VLM's zero-shot performance on unseen\ntask types in comparison to state-of-the-art VLMs. Ablation studies show that\nfine-tuning the language backbone and vision-language adapter in concert is key\nto facilitate adaption while a small percentage, e.g., 20%, of the pre-training\ndata can be used to safeguard against catastrophic forgetting.",
      "tldr_zh": "这篇论文提出了 Space-LLaVA，一种针对外星应用（如太空机器人）的 Vision-Language Model (VLM)，旨在解决 Foundation Models 在可扩展性、知识泛化和多模态任务中的核心挑战。研究者通过程序化增强三个外星数据库，创建了包含视觉-问题-答案和视觉指令遵循元组的合成数据集，并在此基础上微调预训练的 LLaVA 13B 模型，以适应外星环境的视觉语义特征。实验结果显示，Space-LLaVA 在零-shot performance 上优于现有最先进 VLM，同时消融研究证明，联合微调语言骨干和视觉语言适配器是关键，同时使用少量预训练数据可避免灾难性遗忘。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "Accepted to IEEE Aerospace Conference, 23 pages, 18 figures, 3 tables",
      "pdf_url": "http://arxiv.org/pdf/2408.05924v2",
      "published_date": "2024-08-12 05:07:24 UTC",
      "updated_date": "2025-01-18 19:33:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:49:25.163242"
    },
    {
      "arxiv_id": "2408.05920v3",
      "title": "Urban Region Pre-training and Prompting: A Graph-based Approach",
      "title_zh": "城市区域预训练与提示：一种基于图的方法",
      "authors": [
        "Jiahui Jin",
        "Yifan Song",
        "Dong Kan",
        "Haojia Zhu",
        "Xiangguo Sun",
        "Zhicheng Li",
        "Xigang Sun",
        "Jinghui Zhang"
      ],
      "abstract": "Urban region representation is crucial for various urban downstream tasks.\nHowever, despite the proliferation of methods and their success, acquiring\ngeneral urban region knowledge and adapting to different tasks remains\nchallenging. Previous work often neglects the spatial structures and functional\nlayouts between entities, limiting their ability to capture transferable\nknowledge across regions. Further, these methods struggle to adapt effectively\nto specific downstream tasks, as they do not adequately address the unique\nfeatures and relationships required for different downstream tasks. In this\npaper, we propose a $\\textbf{G}$raph-based $\\textbf{U}$rban $\\textbf{R}$egion\n$\\textbf{P}$re-training and $\\textbf{P}$rompting framework ($\\textbf{GURPP}$)\nfor region representation learning. Specifically, we first construct an urban\nregion graph that integrates detailed spatial entity data for more effective\nurban region representation. Then, we develop a subgraph-centric urban region\npre-training model to capture the heterogeneous and transferable patterns of\ninteractions among entities. To further enhance the adaptability of these\nembeddings to different tasks, we design two graph-based prompting methods to\nincorporate explicit/hidden task knowledge. Extensive experiments on various\nurban region prediction tasks and different cities demonstrate the superior\nperformance of our GURPP framework.",
      "tldr_zh": "该论文提出了一种基于图的框架 GURPP，用于城市区域表示学习，旨在解决现有方法忽略实体间空间结构和功能布局，导致知识转移和任务适应性不足的问题。具体而言，GURPP 首先构建整合详细空间实体数据的城市区域图，然后开发以子图为中心的预训练模型来捕获实体间异构和可转移的交互模式，并设计两种图-based 提示方法融入显式或隐式任务知识，以提升模型的适应性。实验在多种城市区域预测任务和不同城市上验证了 GURPP 的优越性能。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.05920v3",
      "published_date": "2024-08-12 05:00:23 UTC",
      "updated_date": "2024-08-26 11:41:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:49:34.453720"
    },
    {
      "arxiv_id": "2408.05917v1",
      "title": "Inverse design of Non-parameterized Ventilated Acoustic Resonator via Variational Autoencoder with Acoustic Response-encoded Latent Space",
      "title_zh": "通过带有声学响应编码潜在空间的变分自编码器进行非参数化通风声学谐振器的逆向设计",
      "authors": [
        "Min Woo Cho",
        "Seok Hyeon Hwang",
        "Jun-Young Jang",
        "Jin Yeong Song",
        "Sun-kwang Hwang",
        "Kyoung Je Cha",
        "Dong Yong Park",
        "Kyungjun Song",
        "Sang Min Park"
      ],
      "abstract": "Ventilated acoustic resonator(VAR), a type of acoustic metamaterial, emerge\nas an alternative for sound attenuation in environments that require\nventilation, owing to its excellent low-frequency attenuation performance and\nflexible shape adaptability. However, due to the non-linear acoustic responses\nof VARs, the VAR designs are generally obtained within a limited parametrized\ndesign space, and the design relies on the iteration of the numerical\nsimulation which consumes a considerable amount of computational time and\nresources. This paper proposes an acoustic response-encoded variational\nautoencoder (AR-VAE), a novel variational autoencoder-based generative design\nmodel for the efficient and accurate inverse design of VAR even with\nnon-parametrized designs. The AR-VAE matches the high-dimensional acoustic\nresponse with the VAR cross-section image in the dimension-reduced latent\nspace, which enables the AR-VAE to generate various non-parametrized VAR\ncross-section images with the target acoustic response. AR-VAE generates\nnon-parameterized VARs from target acoustic responses, which show a 25-fold\nreduction in mean squared error compared to conventional deep learning-based\nparameter searching methods while exhibiting lower average mean squared error\nand peak frequency variance. By combining the inverse-designed VARs by AR-VAE,\nmulti-cavity VAR was devised for broadband and multitarget peak frequency\nattenuation. The proposed design method presents a new approach for structural\ninverse-design with a high-dimensional non-linear physical response.",
      "tldr_zh": "该论文针对通风声学谐振器（Ventilated Acoustic Resonator, VAR）的设计挑战，提出了一种基于变分自编码器（Variational Autoencoder, VAE）的创新模型——声学响应编码变分自编码器（AR-VAE），以实现高效的反向设计，即使是非参数化设计。AR-VAE 通过在降维的潜在空间中匹配高维声学响应与VAR横截面图像，生成满足目标响应的各种非参数化结构。实验结果显示，该方法与传统深度学习参数搜索相比，均方误差降低了25倍，并展现出更低的平均均方误差和峰频方差；此外，通过结合AR-VAE设计的多腔VAR，实现宽带和多目标峰频衰减，为高维非线性物理响应的结构反向设计提供新途径。",
      "categories": [
        "cs.CE",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.05917v1",
      "published_date": "2024-08-12 04:43:40 UTC",
      "updated_date": "2024-08-12 04:43:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:49:47.312393"
    },
    {
      "arxiv_id": "2408.05911v1",
      "title": "A New Pipeline For Generating Instruction Dataset via RAG and Self Fine-Tuning",
      "title_zh": "翻译失败",
      "authors": [
        "Chih-Wei Song",
        "Yu-Kai Lee",
        "Yin-Te Tsai"
      ],
      "abstract": "With the rapid development of large language models in recent years, there\nhas been an increasing demand for domain-specific Agents that can cater to the\nunique needs of enterprises and organizations. Unlike general models, which\nstrive for broad coverage, these specialized Agents rely on focused datasets\ntailored to their intended applications. This research proposes a pipeline that\nleverages the power of LLMs and the Retrieval-Augmented Generation related\nframework to construct high-quality instruction datasets for fine-tuning on\nspecific domains using custom document collections. By ingesting\ndomain-specific documents, the pipeline generates relevant and contextually\nappropriate instructions, thus effectively creating a comprehensive dataset for\nfine-tuning LLMs on the target domain. This approach overcomes the limitations\nof traditional dataset creation methods, which often rely on manual curation or\nweb-scraping techniques that may introduce noise and irrelevant data. Notably,\nour pipeline offers a dynamic solution that can quickly adapt to updates or\nmodifications in the domain-specific document collection, eliminating the need\nfor complete retraining. Additionally, it addresses the challenge of data\nscarcity by enabling the generation of instruction datasets from a limited set\nof initial documents, rendering it suitable for unpopular or specialized\ndomains where comprehensive datasets are scarce. As a case study, we apply this\napproach to the domain of psychiatry, a field requiring specialized knowledge\nand sensitive handling of patient information. The resulting fine-tuned LLM\ndemonstrates showcases the viability of the proposed approach and underscores\nits potential for widespread adoption across various industries and domains\nwhere tailored, accurate, and contextually relevant language models are\nindispensable.",
      "tldr_zh": "这篇论文提出了一种新管道，利用大型语言模型（LLMs）和检索增强生成（RAG）框架，通过摄取领域特定文档来生成高质量指令数据集，从而实现针对特定领域的自微调（Self Fine-Tuning）。该方法解决了传统数据集创建的痛点，如手动整理引入的噪声和数据稀缺问题，并提供动态适应性，能快速响应文档更新而不需完全重新训练。作为案例研究，在精神病学领域应用后，微调后的LLM展示了显著的性能提升，证明了该管道在专业领域的可行性和广泛潜力。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "5 pages, SCA 2024: The 7th IEEE International Workshop on Smart\n  Computing & Applications",
      "pdf_url": "http://arxiv.org/pdf/2408.05911v1",
      "published_date": "2024-08-12 03:52:11 UTC",
      "updated_date": "2024-08-12 03:52:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:49:58.753930"
    },
    {
      "arxiv_id": "2408.05905v2",
      "title": "Weakly Supervised Video Anomaly Detection and Localization with Spatio-Temporal Prompts",
      "title_zh": "基于时空提示的弱监督视频异常检测和定位",
      "authors": [
        "Peng Wu",
        "Xuerong Zhou",
        "Guansong Pang",
        "Zhiwei Yang",
        "Qingsen Yan",
        "Peng Wang",
        "Yanning Zhang"
      ],
      "abstract": "Current weakly supervised video anomaly detection (WSVAD) task aims to\nachieve frame-level anomalous event detection with only coarse video-level\nannotations available. Existing works typically involve extracting global\nfeatures from full-resolution video frames and training frame-level classifiers\nto detect anomalies in the temporal dimension. However, most anomalous events\ntend to occur in localized spatial regions rather than the entire video frames,\nwhich implies existing frame-level feature based works may be misled by the\ndominant background information and lack the interpretation of the detected\nanomalies. To address this dilemma, this paper introduces a novel method called\nSTPrompt that learns spatio-temporal prompt embeddings for weakly supervised\nvideo anomaly detection and localization (WSVADL) based on pre-trained\nvision-language models (VLMs). Our proposed method employs a two-stream network\nstructure, with one stream focusing on the temporal dimension and the other\nprimarily on the spatial dimension. By leveraging the learned knowledge from\npre-trained VLMs and incorporating natural motion priors from raw videos, our\nmodel learns prompt embeddings that are aligned with spatio-temporal regions of\nvideos (e.g., patches of individual frames) for identify specific local regions\nof anomalies, enabling accurate video anomaly detection while mitigating the\ninfluence of background information. Without relying on detailed\nspatio-temporal annotations or auxiliary object detection/tracking, our method\nachieves state-of-the-art performance on three public benchmarks for the WSVADL\ntask.",
      "tldr_zh": "这篇论文针对弱监督视频异常检测和定位(WSVADL)任务，提出了一种名为STPrompt的方法，利用预训练视觉语言模型(VLMs)学习spatio-temporal prompts嵌入，以解决现有方法因忽略局部空间区域而受背景信息误导的问题。STPrompt采用双流网络结构，一个流关注时间维度，另一个流主要处理空间维度，并结合原始视频的自然运动先验，实现对异常区域的精确识别和定位。实验结果表明，该方法在三个公共基准上达到了state-of-the-art性能，而无需依赖详细的时空标注或辅助对象检测/跟踪。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by ACMMM2024",
      "pdf_url": "http://arxiv.org/pdf/2408.05905v2",
      "published_date": "2024-08-12 03:31:29 UTC",
      "updated_date": "2024-08-13 13:55:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:50:11.005717"
    },
    {
      "arxiv_id": "2408.13122v1",
      "title": "Semantic Variational Bayes Based on a Semantic Information Theory for Solving Latent Variables",
      "title_zh": "翻译失败",
      "authors": [
        "Chenguang Lu"
      ],
      "abstract": "The Variational Bayesian method (VB) is used to solve the probability\ndistributions of latent variables with the minimum free energy criterion. This\ncriterion is not easy to understand, and the computation is complex. For these\nreasons, this paper proposes the Semantic Variational Bayes' method (SVB). The\nSemantic Information Theory the author previously proposed extends the\nrate-distortion function R(D) to the rate-fidelity function R(G), where R is\nthe minimum mutual information for given semantic mutual information G. SVB\ncame from the parameter solution of R(G), where the variational and iterative\nmethods originated from Shannon et al.'s research on the rate-distortion\nfunction. The constraint functions SVB uses include likelihood, truth,\nmembership, similarity, and distortion functions. SVB uses the maximum\ninformation efficiency (G/R) criterion, including the maximum semantic\ninformation criterion for optimizing model parameters and the minimum mutual\ninformation criterion for optimizing the Shannon channel. For the same tasks,\nSVB is computationally simpler than VB. The computational experiments in the\npaper include 1) using a mixture model as an example to show that the mixture\nmodel converges as G/R increases; 2) demonstrating the application of SVB in\ndata compression with a group of error ranges as the constraint; 3)\nillustrating how the semantic information measure and SVB can be used for\nmaximum entropy control and reinforcement learning in control tasks with given\nrange constraints, providing numerical evidence for balancing control's\npurposiveness and efficiency. Further research is needed to apply SVB to neural\nnetworks and deep learning.",
      "tldr_zh": "本研究提出了一种新的方法 Semantic Variational Bayes (SVB)，基于作者之前的 Semantic Information Theory，用于解决隐变量的概率分布问题，以取代传统 Variational Bayesian (VB) 方法的复杂性和不易理解性。SVB 通过扩展 rate-distortion function R(D) 到 rate-fidelity function R(G)，利用约束函数如 likelihood、truth、membership、similarity 和 distortion functions，并采用最大信息效率 (G/R) 准则，包括最大 semantic information 和最小 mutual information，实现参数优化和简化计算。实验结果显示，SVB 在混合模型中随 G/R 增加而收敛、在数据压缩任务中有效处理误差范围约束，并在最大熵控制和强化学习中平衡了目的性和效率；未来需进一步应用于神经网络和深度学习。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.IT",
        "math.IT",
        "94A17, 94A15, 68T05, 62F15, 68P30, 68T27, 68T50, 30B42",
        "H.1.1; I.1.2; I.2.6; I.2.8; I.2.4; E.4; G.1.6"
      ],
      "primary_category": "cs.LG",
      "comment": "21 pages, 7 figures, 39 references",
      "pdf_url": "http://arxiv.org/pdf/2408.13122v1",
      "published_date": "2024-08-12 03:23:53 UTC",
      "updated_date": "2024-08-12 03:23:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:50:22.856946"
    },
    {
      "arxiv_id": "2408.05899v1",
      "title": "Quantum Gradient Class Activation Map for Model Interpretability",
      "title_zh": "量子梯度类激活图用于模型可解释性",
      "authors": [
        "Hsin-Yi Lin",
        "Huan-Hsin Tseng",
        "Samuel Yen-Chi Chen",
        "Shinjae Yoo"
      ],
      "abstract": "Quantum machine learning (QML) has recently made significant advancements in\nvarious topics. Despite the successes, the safety and interpretability of QML\napplications have not been thoroughly investigated. This work proposes using\nVariational Quantum Circuits (VQCs) for activation mapping to enhance model\ntransparency, introducing the Quantum Gradient Class Activation Map\n(QGrad-CAM). This hybrid quantum-classical computing framework leverages both\nquantum and classical strengths and gives access to the derivation of an\nexplicit formula of feature map importance. Experimental results demonstrate\nsignificant, fine-grained, class-discriminative visual explanations generated\nacross both image and speech datasets.",
      "tldr_zh": "该研究针对量子机器学习(QML)的安全性和可解释性问题，提出了一种基于Variational Quantum Circuits (VQCs)的激活映射方法，引入Quantum Gradient Class Activation Map (QGrad-CAM)。该框架结合量子和经典计算优势，导出特征映射重要性的显式公式，从而提升模型透明度。实验结果表明，QGrad-CAM在图像和语音数据集上生成了显著的、细粒度的、类别区分的视觉解释。",
      "categories": [
        "quant-ph",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "quant-ph",
      "comment": "Submitted to IEEE SiPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2408.05899v1",
      "published_date": "2024-08-12 02:45:58 UTC",
      "updated_date": "2024-08-12 02:45:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:50:33.796916"
    },
    {
      "arxiv_id": "2408.05888v1",
      "title": "Integrative Approaches in Cybersecurity and AI",
      "title_zh": "网络安全与人工智能的整合方法",
      "authors": [
        "Marwan Omar"
      ],
      "abstract": "In recent years, the convergence of cybersecurity, artificial intelligence\n(AI), and data management has emerged as a critical area of research, driven by\nthe increasing complexity and interdependence of modern technological\necosystems. This paper provides a comprehensive review and analysis of\nintegrative approaches that harness AI techniques to enhance cybersecurity\nframeworks and optimize data management practices. By exploring the synergies\nbetween these domains, we identify key trends, challenges, and future\ndirections that hold the potential to revolutionize the way organizations\nprotect, analyze, and leverage their data. Our findings highlight the necessity\nof cross-disciplinary strategies that incorporate AI-driven automation,\nreal-time threat detection, and advanced data analytics to build more resilient\nand adaptive security architectures.",
      "tldr_zh": "这篇论文审视了网络安全、AI和数据管理的融合，提供了全面的审视和分析，探讨了利用AI技术增强网络安全框架并优化数据管理实践的整合方法。研究识别了关键趋势、挑战和未来方向，强调了跨学科策略的重要性，包括AI-driven automation、real-time threat detection和advanced data analytics，以构建更坚韧且适应性的安全架构。通过这些发现，论文为组织保护、分析和利用数据提供了革命性的潜在路径。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.05888v1",
      "published_date": "2024-08-12 01:37:06 UTC",
      "updated_date": "2024-08-12 01:37:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:50:48.743707"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 71,
  "processed_papers_count": 71,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-19T14:51:14.562975"
}