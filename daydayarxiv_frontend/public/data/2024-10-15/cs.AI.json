{
  "date": "2024-10-15",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-10-15 的 arXiv 中文 TLDR 快报！今天 arXiv 的论文主要聚焦于 AI 模型优化、多模态学习、强化学习应用和隐私保护等领域，强调大型语言模型（LLMs）和扩散模型的创新潜力，其中 \"Planning Anything with Rigor\" 等论文展示了 LLM 在复杂任务中的高效规划能力，而一些跨领域应用如机器人操控和视觉生成也令人印象深刻。\n\n今天的论文涵盖了广泛主题，我将优先讨论那些创新性强、可能引发话题的文章（如 LLM 优化和多模态模型），并快速掠过较基础或特定领域的论文。以下是关键论文的简要分析，每篇包括标题（中文 + 英文）和核心贡献。\n\n### 重点论文讨论\n- **Affordance-Centric Policy Learning: Sample Efficient and Generalisable Robot Policy Learning using Affordance-Centric Task Frames**  \n  这篇论文提出了一种基于 affordance（任务相关区域）的机器人策略学习方法，利用视觉模型提取关键区域，实现高效行为克隆，仅需 10 个演示即可泛化到新对象。主要贡献：提升机器人操纵任务的泛化性和效率，显著减少训练数据需求。\n\n- **Planning Anything with Rigor: General-Purpose Zero-Shot Planning with LLM-based Formalized Programming**  \n  作者包括 Yilun Hao 和 Chuchu Fan，这篇令人印象深刻的作品利用 LLM 将规划问题转化为优化问题，实现零样本泛化。核心发现：LLM 在多约束和长时序任务中平均优化率达 83.7%，远超基线，展示了 LLM 在复杂决策中的潜力。\n\n- **Data-adaptive Differentially Private Prompt Synthesis for In-Context Learning**  \n  这篇论文引入 AdaDPSyn 算法，通过自适应噪声调整合成提示，实现隐私保护下的上下文学习。主要贡献：显著提高 ICL 准确性，同时确保差分隐私，实验显示其在标准基准上优于现有方法。\n\n- **OKAMI: Teaching Humanoid Robots Manipulation Skills through Single Video Imitation**  \n  论文提出 OKAMI 框架，从单视频演示中生成机器人操作策略，实现灵活物体操控。核心发现：模型在不同视觉条件下泛化良好，并可进一步训练闭环策略，适用于真实机器人任务。\n\n- **MIND: Math Informed syNthetic Dialogues for Pretraining LLMs**  \n  作者包括 Eric Nyberg 和 Bryan Catanzaro，这篇聚焦数学推理，生成合成对话数据提升 LLM 性能。主要贡献：通过知识间隙建模，模型在数学任务上提升 13.42%（GSM8K），证明合成数据在预训练中的价值。\n\n- **DeCo: Dynamic Correction Decoding for Hallucination Mitigation**  \n  论文开发 DeCo 方法，通过动态修正解码减少多模态 LLM 的幻觉问题。核心发现：模型在幻觉基准上大幅降低错误率，且适用于多种 LLM，无需额外训练。\n\n- **RClicks: Realistic Click Simulation for Benchmarking Interactive Segmentation**  \n  这篇探讨交互式图像分割的鲁棒性，通过真实点击模拟生成基准。核心贡献：改进评估指标，揭示现有模型在实际场景下的不足，提升分割任务的可靠性。\n\n- **Diffusion-Based Offline RL for Improved Decision-Making in Augmented ARC Task**  \n  论文将扩散模型应用于离线强化学习，优化多步决策。核心发现：在增强的抽象推理任务中，模型显著提升性能，证明扩散模型在长时序 RL 中的适用性。\n\n- **SlideChat: A Large Vision-Language Assistant for Whole-Slide Pathology Image Understanding**  \n  这篇引入 SlideChat 框架，用于病理图像分析。核心贡献：模型在高分辨率图像上实现高效对话，支持医学诊断，实验显示其在多任务中超越基线。\n\n- **Mini-Omni2: Towards Open-source GPT-4o with Vision, Speech and Duplex Capabilities**  \n  论文构建开源多模态模型 Mini-Omni2，支持视觉和语音交互。核心发现：模型在多模态任务中保持高性能，并通过三阶段训练实现端到端响应，接近 GPT-4o 的功能。\n\n其他论文，如那些专注于特定领域（如生物序列建模或表格学习），虽有技术贡献但相对常规，我仅快速提及：例如，\"The Persian Rug\" 探讨了稀疏数据自编码器的机制，而 \"FVEval\" 评估 LLM 在硬件验证中的性能；这些在理论上有趣，但实际影响较小。总体而言，今天的论文突出了 AI 模型的泛化和鲁棒性，LLM 在多模态和规划任务中的进展值得关注。更多细节可查阅 arXiv！",
  "papers": [
    {
      "arxiv_id": "2410.12124v1",
      "title": "Affordance-Centric Policy Learning: Sample Efficient and Generalisable Robot Policy Learning using Affordance-Centric Task Frames",
      "title_zh": "翻译失败",
      "authors": [
        "Krishan Rana",
        "Jad Abou-Chakra",
        "Sourav Garg",
        "Robert Lee",
        "Ian Reid",
        "Niko Suenderhauf"
      ],
      "abstract": "Affordances are central to robotic manipulation, where most tasks can be\nsimplified to interactions with task-specific regions on objects. By focusing\non these key regions, we can abstract away task-irrelevant information,\nsimplifying the learning process, and enhancing generalisation. In this paper,\nwe propose an affordance-centric policy-learning approach that centres and\nappropriately \\textit{orients} a \\textit{task frame} on these affordance\nregions allowing us to achieve both \\textbf{intra-category invariance} -- where\npolicies can generalise across different instances within the same object\ncategory -- and \\textbf{spatial invariance} -- which enables consistent\nperformance regardless of object placement in the environment. We propose a\nmethod to leverage existing generalist large vision models to extract and track\nthese affordance frames, and demonstrate that our approach can learn\nmanipulation tasks using behaviour cloning from as little as 10 demonstrations,\nwith equivalent generalisation to an image-based policy trained on 305\ndemonstrations. We provide video demonstrations on our project site:\nhttps://affordance-policy.github.io.",
      "tldr_zh": "该论文提出了一种以affordances为中心的策略学习方法，通过在物体关键区域上居中并定向task frame，实现intra-category invariance（同一类别物体间的泛化）和spatial invariance（物体位置无关的性能），从而简化机器人操作任务的学习过程。方法利用现有的通用大型视觉模型来提取和跟踪这些affordance frames，显著提升了样本效率。实验结果显示，使用behaviour cloning从仅10个演示即可学习操作任务，其泛化能力相当于基于图像的策略从305个演示中训练得来。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "Video can be found on our project website:\n  https://affordance-policy.github.io",
      "pdf_url": "http://arxiv.org/pdf/2410.12124v1",
      "published_date": "2024-10-15 23:57:35 UTC",
      "updated_date": "2024-10-15 23:57:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:37:11.930283"
    },
    {
      "arxiv_id": "2410.12112v2",
      "title": "Planning Anything with Rigor: General-Purpose Zero-Shot Planning with LLM-based Formalized Programming",
      "title_zh": "严格规划任何事物：基于 LLM 的形式化编程的通用目的零样本规划",
      "authors": [
        "Yilun Hao",
        "Yang Zhang",
        "Chuchu Fan"
      ],
      "abstract": "While large language models (LLMs) have recently demonstrated strong\npotential in solving planning problems, there is a trade-off between\nflexibility and complexity. LLMs, as zero-shot planners themselves, are still\nnot capable of directly generating valid plans for complex planning problems\nsuch as multi-constraint or long-horizon tasks. On the other hand, many\nframeworks aiming to solve complex planning problems often rely on\ntask-specific preparatory efforts, such as task-specific in-context examples\nand pre-defined critics/verifiers, which limits their cross-task generalization\ncapability. In this paper, we tackle these challenges by observing that the\ncore of many planning problems lies in optimization problems: searching for the\noptimal solution (best plan) with goals subject to constraints (preconditions\nand effects of decisions). With LLMs' commonsense, reasoning, and programming\ncapabilities, this opens up the possibilities of a universal LLM-based approach\nto planning problems. Inspired by this observation, we propose LLMFP, a\ngeneral-purpose framework that leverages LLMs to capture key information from\nplanning problems and formally formulate and solve them as optimization\nproblems from scratch, with no task-specific examples needed. We apply LLMFP to\n9 planning problems, ranging from multi-constraint decision making to\nmulti-step planning problems, and demonstrate that LLMFP achieves on average\n83.7% and 86.8% optimal rate across 9 tasks for GPT-4o and Claude 3.5 Sonnet,\nsignificantly outperforming the best baseline (direct planning with OpenAI\no1-preview) with 37.6% and 40.7% improvements. We also validate components of\nLLMFP with ablation experiments and analyzed the underlying success and failure\nreasons. Project page: https://sites.google.com/view/llmfp.",
      "tldr_zh": "该研究提出 LLMFP 框架，利用大型语言模型(LLMs)将规划问题形式化为优化问题，实现通用零样本规划，无需任务特定示例，从而解决 LLMs 在多约束或长时序任务中生成有效计划的局限性。\nLLMFP 通过 LLMs 的常识、推理和编程能力，从规划问题的关键信息入手，直接构建并求解优化问题，适用于从多约束决策到多步规划的多种场景。\n实验结果显示，在9个任务上，GPT-4o 和 Claude 3.5 Sonnet 的平均最优率分别为83.7%和86.8%，比最佳基线(Direct planning with OpenAI o1-preview)提高了37.6%和40.7%。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "57 pages, 25 figures, 15 tables",
      "pdf_url": "http://arxiv.org/pdf/2410.12112v2",
      "published_date": "2024-10-15 23:20:54 UTC",
      "updated_date": "2025-01-29 16:31:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:37:24.418773"
    },
    {
      "arxiv_id": "2410.12107v1",
      "title": "Just-In-Time Software Defect Prediction via Bi-modal Change Representation Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Yuze Jiang",
        "Beijun Shen",
        "Xiaodong Gu"
      ],
      "abstract": "For predicting software defects at an early stage, researchers have proposed\njust-in-time defect prediction (JIT-DP) to identify potential defects in code\ncommits. The prevailing approaches train models to represent code changes in\nhistory commits and utilize the learned representations to predict the presence\nof defects in the latest commit. However, existing models merely learn editions\nin source code, without considering the natural language intentions behind the\nchanges. This limitation hinders their ability to capture deeper semantics. To\naddress this, we introduce a novel bi-modal change pre-training model called\nBiCC-BERT. BiCC-BERT is pre-trained on a code change corpus to learn bi-modal\nsemantic representations. To incorporate commit messages from the corpus, we\ndesign a novel pre-training objective called Replaced Message Identification\n(RMI), which learns the semantic association between commit messages and code\nchanges. Subsequently, we integrate BiCC-BERT into JIT-DP and propose a new\ndefect prediction approach -- JIT-BiCC. By leveraging the bi-modal\nrepresentations from BiCC-BERT, JIT-BiCC captures more profound change\nsemantics. We train JIT-BiCC using 27,391 code changes and compare its\nperformance with 8 state-of-the-art JIT-DP approaches. The results demonstrate\nthat JIT-BiCC outperforms all baselines, achieving a 10.8% improvement in\nF1-score. This highlights its effectiveness in learning the bi-modal semantics\nfor JIT-DP.",
      "tldr_zh": "该论文针对Just-In-Time Defect Prediction (JIT-DP)提出了一种新方法，通过双模态变化表示学习来早期预测软件缺陷。研究引入BiCC-BERT模型，在代码变化语料上预训练，并设计了Replaced Message Identification (RMI)预训练目标，以捕捉提交消息和代码改动之间的语义关联，从而克服现有模型忽略自然语言意图的局限。实验结果显示，基于BiCC-BERT的JIT-BiCC方法在使用27,391个代码变化的数据集上，与8个最先进方法相比，F1-score提高了10.8%，证明了其在学习双模态语义方面的显著优势。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "Accepted by JSS (The Journal of Systems & Software)",
      "pdf_url": "http://arxiv.org/pdf/2410.12107v1",
      "published_date": "2024-10-15 23:13:29 UTC",
      "updated_date": "2024-10-15 23:13:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:37:35.659774"
    },
    {
      "arxiv_id": "2410.12101v2",
      "title": "The Persian Rug: solving toy models of superposition using large-scale symmetries",
      "title_zh": "翻译失败",
      "authors": [
        "Aditya Cowsik",
        "Kfir Dolev",
        "Alex Infanger"
      ],
      "abstract": "We present a complete mechanistic description of the algorithm learned by a\nminimal non-linear sparse data autoencoder in the limit of large input\ndimension. The model, originally presented in arXiv:2209.10652, compresses\nsparse data vectors through a linear layer and decompresses using another\nlinear layer followed by a ReLU activation. We notice that when the data is\npermutation symmetric (no input feature is privileged) large models reliably\nlearn an algorithm that is sensitive to individual weights only through their\nlarge-scale statistics. For these models, the loss function becomes\nanalytically tractable. Using this understanding, we give the explicit scalings\nof the loss at high sparsity, and show that the model is near-optimal among\nrecently proposed architectures. In particular, changing or adding to the\nactivation function any elementwise or filtering operation can at best improve\nthe model's performance by a constant factor. Finally, we forward-engineer a\nmodel with the requisite symmetries and show that its loss precisely matches\nthat of the trained models. Unlike the trained model weights, the low\nrandomness in the artificial weights results in miraculous fractal structures\nresembling a Persian rug, to which the algorithm is oblivious. Our work\ncontributes to neural network interpretability by introducing techniques for\nunderstanding the structure of autoencoders. Code to reproduce our results can\nbe found at https://github.com/KfirD/PersianRug .",
      "tldr_zh": "本研究对一个最小非线性稀疏数据 autoencoder 在高输入维度下的算法进行了完整机制描述，聚焦于数据置换对称性下模型的学习行为。研究发现，当数据无特权特征时，大模型会通过依赖权重的大规模统计来优化算法，使损失函数在高稀疏度下可分析，并证明该模型在性能上接近最优，仅通过修改激活函数等操作可实现常数级改善。最终，他们设计了一个具有相同对称性的前向工程模型，其损失与训练模型精确匹配，并观察到人工权重产生了类似波斯地毯的分形结构，从而为神经网络可解释性提供了新技巧。",
      "categories": [
        "cs.LG",
        "cond-mat.dis-nn",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Improved arguments, presentation. No changes to results",
      "pdf_url": "http://arxiv.org/pdf/2410.12101v2",
      "published_date": "2024-10-15 22:52:45 UTC",
      "updated_date": "2024-10-22 17:48:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:37:47.795029"
    },
    {
      "arxiv_id": "2410.12096v1",
      "title": "Bridging Large Language Models and Graph Structure Learning Models for Robust Representation Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Guangxin Su",
        "Yifan Zhu",
        "Wenjie Zhang",
        "Hanchen Wang",
        "Ying Zhang"
      ],
      "abstract": "Graph representation learning, involving both node features and graph\nstructures, is crucial for real-world applications but often encounters\npervasive noise. State-of-the-art methods typically address noise by focusing\nseparately on node features with large language models (LLMs) and on graph\nstructures with graph structure learning models (GSLMs). In this paper, we\nintroduce LangGSL, a robust framework that integrates the complementary\nstrengths of pre-trained language models and GSLMs to jointly enhance both node\nfeature and graph structure learning. In LangGSL, we first leverage LLMs to\nfilter noise in the raw data and extract valuable cleaned information as\nfeatures, enhancing the synergy of downstream models. During the mutual\nlearning phase in LangGSL, the core idea is to leverage the relatively small\nlanguage model (LM) to process local attributes and generate reliable\npseudo-labels and informative node embeddings, which are then integrated into\nthe GSLM's prediction phase. This approach enriches the global context and\nenhances overall performance. Meanwhile, GSLM refines the evolving graph\nstructure constructed from the LM's output, offering updated labels back to the\nLM as additional guidance, thus facilitating a more effective mutual learning\nprocess. The LM and GSLM work synergistically, complementing each other's\nstrengths and offsetting weaknesses within a variational information-maximizing\nframework, resulting in enhanced node features and a more robust graph\nstructure. Extensive experiments on diverse graph datasets of varying scales\nand across different task scenarios demonstrate the scalability and\neffectiveness of the proposed approach.",
      "tldr_zh": "本文提出LangGSL框架，旨在桥接Large Language Models (LLMs) 和 Graph Structure Learning Models (GSLMs)，以增强图表示学习的鲁棒性，通过联合处理节点特征和图结构噪声。框架首先利用LLMs过滤原始数据噪声并提取清洁特征，随后在相互学习阶段中，较小语言模型生成伪标签和节点嵌入供GSLMs使用，而GSLMs则反馈完善图结构，实现协同优化。实验结果显示，LangGSL在多种规模和任务的图数据集上表现出色，证明了其有效性和可扩展性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Graph structure learning, Graph representation learning, Large\n  language models, Graph neural networks",
      "pdf_url": "http://arxiv.org/pdf/2410.12096v1",
      "published_date": "2024-10-15 22:43:32 UTC",
      "updated_date": "2024-10-15 22:43:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:37:59.857695"
    },
    {
      "arxiv_id": "2410.12091v1",
      "title": "Generative AI's aggregated knowledge versus web-based curated knowledge",
      "title_zh": "翻译失败",
      "authors": [
        "Ted Selker",
        "Yunzi Wu"
      ],
      "abstract": "his paper explores what kinds of questions are best served by the way\ngenerative AI (GenAI) using Large Language Models(LLMs) that aggregate and\npackage knowledge, and when traditional curated web-sourced search results\nserve users better.\n  An experiment compared product searches using ChatGPT, Google search engine,\nor both helped us understand more about the compelling nature of generated\nresponses. The experiment showed GenAI can speed up some explorations and\ndecisions. We describe how search can deepen the testing of facts, logic, and\ncontext. We show where existing and emerging knowledge paradigms can help\nknowledge exploration in different ways.\n  Experimenting with searches, our probes showed the value for curated web\nsearch provides for very specific, less popularly-known knowledge. GenAI\nexcelled at bringing together knowledge for broad, relatively well-known\ntopics. The value of curated and aggregated knowledge for different kinds of\nknowledge reflected in different user goals. We developed a taxonomy to\ndistinguishing when users are best served by these two approaches.",
      "tldr_zh": "这篇论文比较了生成式 AI (GenAI) 使用大型语言模型 (LLMs) 聚合知识与传统网络精选搜索在回答问题时的优劣，通过实验对比 ChatGPT 和 Google 搜索引擎，揭示了生成式响应在加速探索和决策方面的优势。研究发现，对于广义且相对知名的主题，GenAI 更擅长整合知识，而网络搜索在验证具体、冷门事实和逻辑方面更具价值。最终，论文开发了一个分类法，根据用户目标区分何时使用这两种知识范式，以优化知识探索。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "19 pages, 19 references, 8 pages of appendices, 15 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.12091v1",
      "published_date": "2024-10-15 22:17:45 UTC",
      "updated_date": "2024-10-15 22:17:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:38:11.410634"
    },
    {
      "arxiv_id": "2410.12085v2",
      "title": "Data-adaptive Differentially Private Prompt Synthesis for In-Context Learning",
      "title_zh": "数据自适应差分隐私提示合成用于在语境学习",
      "authors": [
        "Fengyu Gao",
        "Ruida Zhou",
        "Tianhao Wang",
        "Cong Shen",
        "Jing Yang"
      ],
      "abstract": "Large Language Models (LLMs) rely on the contextual information embedded in\nexamples/demonstrations to perform in-context learning (ICL). To mitigate the\nrisk of LLMs potentially leaking private information contained in examples in\nthe prompt, we introduce a novel data-adaptive differentially private algorithm\ncalled AdaDPSyn to generate synthetic examples from the private dataset and\nthen use these synthetic examples to perform ICL. The objective of AdaDPSyn is\nto adaptively adjust the noise level in the data synthesis mechanism according\nto the inherent statistical properties of the data, thereby preserving high ICL\naccuracy while maintaining formal differential privacy guarantees. A key\ninnovation in AdaDPSyn is the Precision-Focused Iterative Radius Reduction\ntechnique, which dynamically refines the aggregation radius - the scope of data\ngrouping for noise addition - based on patterns observed in data clustering,\nthereby minimizing the amount of additive noise. We conduct extensive\nexperiments on standard benchmarks and compare AdaDPSyn with DP few-shot\ngeneration algorithm (Tang et al., 2023). The experiments demonstrate that\nAdaDPSyn not only outperforms DP few-shot generation, but also maintains high\naccuracy levels close to those of non-private baselines, providing an effective\nsolution for ICL with privacy protection.",
      "tldr_zh": "该论文提出了一种数据自适应差分隐私算法AdaDPSyn，用于生成合成示例以支持In-Context Learning (ICL)，从而保护大语言模型(LLMs)中提示的私有信息不被泄露。AdaDPSyn根据数据的统计特性动态调整噪声水平，并引入Precision-Focused Iterative Radius Reduction技术，通过基于数据聚类的动态优化来最小化添加噪声的范围，确保高ICL准确性同时保持正式差分隐私保证。实验在标准基准上表明，AdaDPSyn优于现有的DP few-shot生成算法，其准确性接近非私有基线，提供了一种有效的隐私保护ICL解决方案。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG",
        "stat.ML"
      ],
      "primary_category": "cs.CR",
      "comment": "Accepted to ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2410.12085v2",
      "published_date": "2024-10-15 22:06:30 UTC",
      "updated_date": "2025-03-02 06:29:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:38:22.752656"
    },
    {
      "arxiv_id": "2410.19793v1",
      "title": "Single-word Auditory Attention Decoding Using Deep Learning Model",
      "title_zh": "基于深度学习模型的单字听觉注意力解码",
      "authors": [
        "Nhan Duc Thanh Nguyen",
        "Huy Phan",
        "Kaare Mikkelsen",
        "Preben Kidmose"
      ],
      "abstract": "Identifying auditory attention by comparing auditory stimuli and\ncorresponding brain responses, is known as auditory attention decoding (AAD).\nThe majority of AAD algorithms utilize the so-called envelope entrainment\nmechanism, whereby auditory attention is identified by how the envelope of the\nauditory stream drives variation in the electroencephalography (EEG) signal.\nHowever, neural processing can also be decoded based on endogenous cognitive\nresponses, in this case, neural responses evoked by attention to specific words\nin a speech stream. This approach is largely unexplored in the field of AAD but\nleads to a single-word auditory attention decoding problem in which an epoch of\nan EEG signal timed to a specific word is labeled as attended or unattended.\nThis paper presents a deep learning approach, based on EEGNet, to address this\nchallenge. We conducted a subject-independent evaluation on an event-based AAD\ndataset with three different paradigms: word category oddball, word category\nwith competing speakers, and competing speech streams with targets. The results\ndemonstrate that the adapted model is capable of exploiting cognitive-related\nspatiotemporal EEG features and achieving at least 58% accuracy on the most\nrealistic competing paradigm for the unseen subjects. To our knowledge, this is\nthe first study dealing with this problem.",
      "tldr_zh": "本研究探讨了单字听觉注意解码（Single-word Auditory Attention Decoding, AAD），通过分析内源性认知响应（如针对特定单词的EEG信号）而非传统包络entrainment机制。作者提出了一种基于EEGNet的深度学习模型，利用认知相关的时空EEG特征，对事件-based AAD数据集进行主体无关评估，涵盖三种范式：单词类别奇异、单词类别与竞争说话者，以及竞争语音流。实验结果显示，该模型在最现实的竞争范式上，对未见主体实现了至少58%的准确率；这是首个处理单字AAD问题的研究，为基于EEG的注意解码提供了新途径。",
      "categories": [
        "eess.SP",
        "cs.AI",
        "cs.HC",
        "cs.SD",
        "eess.AS",
        "q-bio.NC"
      ],
      "primary_category": "eess.SP",
      "comment": "5 pages, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.19793v1",
      "published_date": "2024-10-15 21:57:19 UTC",
      "updated_date": "2024-10-15 21:57:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:38:35.423785"
    },
    {
      "arxiv_id": "2410.23299v1",
      "title": "FVEval: Understanding Language Model Capabilities in Formal Verification of Digital Hardware",
      "title_zh": "FVEval：理解语言模型在数字硬件形式验证中的能力",
      "authors": [
        "Minwoo Kang",
        "Mingjie Liu",
        "Ghaith Bany Hamad",
        "Syed Suhaib",
        "Haoxing Ren"
      ],
      "abstract": "The remarkable reasoning and code generation capabilities of large language\nmodels (LLMs) have spurred significant interest in applying LLMs to enable task\nautomation in digital chip design. In particular, recent work has investigated\nearly ideas of applying these models to formal verification (FV), an approach\nto verifying hardware implementations that can provide strong guarantees of\nconfidence but demands significant amounts of human effort. While the value of\nLLM-driven automation is evident, our understanding of model performance,\nhowever, has been hindered by the lack of holistic evaluation. In response, we\npresent FVEval, the first comprehensive benchmark and evaluation framework for\ncharacterizing LLM performance in tasks pertaining to FV. The benchmark\nconsists of three sub-tasks that measure LLM capabilities at different levels:\nfrom the generation of SystemVerilog assertions (SVAs) given natural language\ndescriptions to reasoning about the design RTL and suggesting assertions\ndirectly without additional human input. As test instances, we present both\ncollections of expert-written verification collateral and methodologies to\nscalably generate synthetic examples aligned with industrial FV workflows. A\nwide range of existing LLMs, both proprietary and open-source, are evaluated\nagainst FVEval, based on which we investigate where today's LLMs stand and how\nwe might further enable their application toward improving productivity in\ndigital FV. Our benchmark and evaluation code is available at\n\\url{https://github.com/NVlabs/FVEval}.",
      "tldr_zh": "本研究提出 FVEval，这是一个全面的基准和评估框架，用于评估大型语言模型(LLMs)在数字硬件正式验证(Formal Verification, FV)中的性能，以解决当前缺乏整体评估的问题。FVEval 包括三个子任务：从自然语言描述生成 SystemVerilog assertions (SVAs)、对设计 RTL 进行推理并直接建议 assertions，以及使用专家编写的验证材料和可扩展的合成示例进行测试。通过评估多种专有和开源 LLMs，该研究发现现有模型在 FV 任务中显示出潜力，但仍需进一步优化以提高生产力。FVEval 的代码已在 GitHub 上公开，可供进一步研究使用。",
      "categories": [
        "cs.AR",
        "cs.AI"
      ],
      "primary_category": "cs.AR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.23299v1",
      "published_date": "2024-10-15 21:48:57 UTC",
      "updated_date": "2024-10-15 21:48:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:38:48.239020"
    },
    {
      "arxiv_id": "2410.12075v2",
      "title": "WeatherDG: LLM-assisted Diffusion Model for Procedural Weather Generation in Domain-Generalized Semantic Segmentation",
      "title_zh": "翻译失败",
      "authors": [
        "Chenghao Qian",
        "Yuhu Guo",
        "Yuhong Mo",
        "Wenjing Li"
      ],
      "abstract": "In this work, we propose a novel approach, namely WeatherDG, that can\ngenerate realistic, weather-diverse, and driving-screen images based on the\ncooperation of two foundation models, i.e, Stable Diffusion (SD) and Large\nLanguage Model (LLM). Specifically, we first fine-tune the SD with source data,\naligning the content and layout of generated samples with real-world driving\nscenarios. Then, we propose a procedural prompt generation method based on LLM,\nwhich can enrich scenario descriptions and help SD automatically generate more\ndiverse, detailed images. In addition, we introduce a balanced generation\nstrategy, which encourages the SD to generate high-quality objects of tailed\nclasses under various weather conditions, such as riders and motorcycles. This\nsegmentation-model-agnostic method can improve the generalization ability of\nexisting models by additionally adapting them with the generated synthetic\ndata. Experiments on three challenging datasets show that our method can\nsignificantly improve the segmentation performance of different\nstate-of-the-art models on target domains. Notably, in the setting of\n''Cityscapes to ACDC'', our method improves the baseline HRDA by 13.9% in mIoU.",
      "tldr_zh": "本文提出 WeatherDG，一种结合 Stable Diffusion (SD) 和 Large Language Model (LLM) 的方法，用于生成真实、多样天气的驾驶场景图像，从而提升领域泛化语义分割的性能。具体而言，该方法通过微调 SD 以匹配真实场景、基于 LLM 的程序化提示生成来丰富图像细节，以及引入平衡生成策略来确保尾类对象（如骑手和摩托车）在各种天气下的高质量输出。实验结果显示，在三个挑战数据集上，WeatherDG 显著提高了不同最先进模型的分割性能，例如在“Cityscapes to ACDC”设置中，比基线 HRDA 的 mIoU 提高了 13.9%。该方法作为分割模型无关的合成数据适应策略，为泛化能力增强提供了新途径。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.12075v2",
      "published_date": "2024-10-15 21:29:26 UTC",
      "updated_date": "2024-12-30 13:34:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:39:01.065937"
    },
    {
      "arxiv_id": "2410.12068v1",
      "title": "V3D-SLAM: Robust RGB-D SLAM in Dynamic Environments with 3D Semantic Geometry Voting",
      "title_zh": "翻译失败",
      "authors": [
        "Tuan Dang",
        "Khang Nguyen",
        "Mandfred Huber"
      ],
      "abstract": "Simultaneous localization and mapping (SLAM) in highly dynamic environments\nis challenging due to the correlation complexity between moving objects and the\ncamera pose. Many methods have been proposed to deal with this problem;\nhowever, the moving properties of dynamic objects with a moving camera remain\nunclear. Therefore, to improve SLAM's performance, minimizing disruptive events\nof moving objects with a physical understanding of 3D shapes and dynamics of\nobjects is needed. In this paper, we propose a robust method, V3D-SLAM, to\nremove moving objects via two lightweight re-evaluation stages, including\nidentifying potentially moving and static objects using a spatial-reasoned\nHough voting mechanism and refining static objects by detecting dynamic noise\ncaused by intra-object motions using Chamfer distances as similarity\nmeasurements. Our experiment on the TUM RGB-D benchmark on dynamic sequences\nwith ground-truth camera trajectories showed that our methods outperform the\nmost recent state-of-the-art SLAM methods. Our source code is available at\nhttps://github.com/tuantdang/v3d-slam.",
      "tldr_zh": "该论文提出 V3D-SLAM，一种鲁棒的 RGB-D SLAM 方法，旨在处理高度动态环境中动态物体与相机位姿的相关性问题，通过物理理解物体的 3D 形状和动态来最小化干扰。方法包括两个轻量级重新评估阶段：首先使用空间推理的 Hough voting 机制识别潜在移动和静态物体，其次通过 Chamfer distances 检测物体内部运动的动态噪声，以精炼静态物体。实验结果显示，在 TUM RGB-D 基准的动态序列上，V3D-SLAM 超过了现有最先进方法，证明了其在实时定位和建图方面的优越性能。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.12068v1",
      "published_date": "2024-10-15 21:08:08 UTC",
      "updated_date": "2024-10-15 21:08:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:39:12.001189"
    },
    {
      "arxiv_id": "2410.14724v1",
      "title": "A Phenomenological AI Foundation Model for Physical Signals",
      "title_zh": "一种用于物理信号的现象学 AI 基础模型",
      "authors": [
        "Jaime Lien",
        "Laura I. Galindez Olascoaga",
        "Hasan Dogan",
        "Nicholas Gillian",
        "Brandon Barbello",
        "Leonardo Giusti",
        "Ivan Poupyrev"
      ],
      "abstract": "The objective of this work is to develop an AI foundation model for physical\nsignals that can generalize across diverse phenomena, domains, applications,\nand sensing apparatuses. We propose a phenomenological approach and framework\nfor creating and validating such AI foundation models. Based on this framework,\nwe developed and trained a model on 0.59 billion samples of cross-modal sensor\nmeasurements, ranging from electrical current to fluid flow to optical sensors.\nNotably, no prior knowledge of physical laws or inductive biases were\nintroduced into the model. Through several real-world experiments, we\ndemonstrate that a single foundation model could effectively encode and predict\nphysical behaviors, such as mechanical motion and thermodynamics, including\nphenomena not seen in training. The model also scales across physical processes\nof varying complexity, from tracking the trajectory of a simple spring-mass\nsystem to forecasting large electrical grid dynamics. This work highlights the\npotential of building a unified AI foundation model for diverse physical world\nprocesses.",
      "tldr_zh": "本研究旨在开发一个AI foundation model，用于处理物理信号，能够泛化到各种现象、领域、应用和传感器。该模型采用phenomenological approach和框架进行创建和验证，训练于0.59亿样本的跨模态传感器数据（如电流、流体流动和光学传感器），且未引入任何物理定律或归纳偏差。通过真实实验，模型成功编码和预测未见训练的物理行为，包括机械运动和热力学现象，并适用于从简单弹簧-质量系统轨迹到大型电网动态等不同复杂过程。该工作展示了构建统一AI foundation model处理多样物理世界过程的潜力。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "eess.SP"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.14724v1",
      "published_date": "2024-10-15 21:03:53 UTC",
      "updated_date": "2024-10-15 21:03:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:39:23.545591"
    },
    {
      "arxiv_id": "2410.12062v1",
      "title": "MFC-EQ: Mean-Field Control with Envelope Q-Learning for Moving Decentralized Agents in Formation",
      "title_zh": "翻译失败",
      "authors": [
        "Qiushi Lin",
        "Hang Ma"
      ],
      "abstract": "We study a decentralized version of Moving Agents in Formation (MAiF), a\nvariant of Multi-Agent Path Finding aiming to plan collision-free paths for\nmultiple agents with the dual objectives of reaching their goals quickly while\nmaintaining a desired formation. The agents must balance these objectives under\nconditions of partial observation and limited communication. The formation\nmaintenance depends on the joint state of all agents, whose dimensionality\nincreases exponentially with the number of agents, rendering the learning\nprocess intractable. Additionally, learning a single policy that can\naccommodate different linear preferences for these two objectives presents a\nsignificant challenge. In this paper, we propose Mean-Field Control with\nEnvelop $Q$-learning (MFC-EQ), a scalable and adaptable learning framework for\nthis bi-objective multi-agent problem. We approximate the dynamics of all\nagents using mean-field theory while learning a universal preference-agnostic\npolicy through envelop $Q$-learning. Our empirical evaluation of MFC-EQ across\nnumerous instances shows that it outperforms state-of-the-art centralized MAiF\nbaselines. Furthermore, MFC-EQ effectively handles more complex scenarios where\nthe desired formation changes dynamically -- a challenge that existing MAiF\nplanners cannot address.",
      "tldr_zh": "本文研究了 Moving Agents in Formation (MAiF) 问题，即在多智能体路径规划中，让分散化代理在部分观察和有限通信条件下快速到达目标同时保持阵型。提出 Mean-Field Control with Envelope Q-Learning (MFC-EQ) 框架，使用均值场理论近似代理动态，并通过 Envelope Q-Learning 学习一个通用的偏好无关策略，以解决状态维度爆炸和适应不同目标偏好的挑战。实验结果表明，MFC-EQ 优于现有集中式基线，并在动态变化阵型的情景中表现出色，提供了一种可扩展的解决方案。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG",
        "cs.MA"
      ],
      "primary_category": "cs.RO",
      "comment": "Accepted to IROS 2024",
      "pdf_url": "http://arxiv.org/pdf/2410.12062v1",
      "published_date": "2024-10-15 20:59:47 UTC",
      "updated_date": "2024-10-15 20:59:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:39:36.422209"
    },
    {
      "arxiv_id": "2410.12061v2",
      "title": "CrediRAG: Network-Augmented Credibility-Based Retrieval for Misinformation Detection in Reddit",
      "title_zh": "翻译失败",
      "authors": [
        "Ashwin Ram",
        "Yigit Ege Bayiz",
        "Arash Amini",
        "Mustafa Munir",
        "Radu Marculescu"
      ],
      "abstract": "Fake news threatens democracy and exacerbates the polarization and divisions\nin society; therefore, accurately detecting online misinformation is the\nfoundation of addressing this issue. We present CrediRAG, the first fake news\ndetection model that combines language models with access to a rich external\npolitical knowledge base with a dense social network to detect fake news across\nsocial media at scale. CrediRAG uses a news retriever to initially assign a\nmisinformation score to each post based on the source credibility of similar\nnews articles to the post title content. CrediRAG then improves the initial\nretrieval estimations through a novel weighted post-to-post network connected\nbased on shared commenters and weighted by the average stance of all shared\ncommenters across every pair of posts. We achieve 11% increase in the F1-score\nin detecting misinformative posts over state-of-the-art methods. Extensive\nexperiments conducted on curated real-world Reddit data of over 200,000 posts\ndemonstrate the superior performance of CrediRAG on existing baselines. Thus,\nour approach offers a more accurate and scalable solution to combat the spread\nof fake news across social media platforms.",
      "tldr_zh": "该研究提出了 CrediRAG，一种结合语言模型、外部政治知识库和密集社交网络的假新闻检测模型，旨在大规模识别 Reddit 上的错误信息。CrediRAG 通过新闻检索器基于类似文章的来源可信度分配初始 misinformation 评分，并利用加权帖子网络（基于共享评论者和平均立场）来优化这些估计。实验在超过 20 万条真实 Reddit 帖子上表明，该模型比现有方法提高了 11% 的 F1-score，提供了一个更准确和可扩展的解决方案来对抗社交媒体假新闻传播。",
      "categories": [
        "cs.SI",
        "cs.AI"
      ],
      "primary_category": "cs.SI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.12061v2",
      "published_date": "2024-10-15 20:58:42 UTC",
      "updated_date": "2024-10-26 20:27:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:39:48.555214"
    },
    {
      "arxiv_id": "2410.12057v2",
      "title": "Large-scale cloze evaluation reveals that token prediction tasks are neither lexically nor semantically aligned",
      "title_zh": "翻译失败",
      "authors": [
        "Cassandra L. Jacobs",
        "Loïc Grobol",
        "Alvin Tsang"
      ],
      "abstract": "In this work we compare the generative behavior at the next token prediction\nlevel in several language models by comparing them to human productions in the\ncloze task. We find that while large models trained for longer are typically\nbetter estimators of human productions, but they reliably under-estimate the\nprobabilities of human responses, over-rank rare responses, under-rank top\nresponses, and produce highly distinct semantic spaces. Altogether, this work\ndemonstrates in a tractable, interpretable domain that LM generations can not\nbe used as replacements of or models of the cloze task.",
      "tldr_zh": "这篇论文通过大规模完形填空(cloze)任务评估，发现语言模型在下一个标记预测(token prediction)任务上与人类生成行为既不词汇上(lexically)也不语义上(semantically)对齐。研究比较了多种语言模型的表现，结果显示大型模型虽然能更好地估计人类响应，但它们系统性地低估了人类响应的概率，过度排名稀有响应，并不足排名顶层响应，同时产生了高度不同的语义空间。总体而言，这表明语言模型的生成无法作为完形填空任务的替代或模型。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "I.2.7"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.12057v2",
      "published_date": "2024-10-15 20:52:09 UTC",
      "updated_date": "2024-10-28 17:45:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:40:01.102314"
    },
    {
      "arxiv_id": "2410.12051v1",
      "title": "Enabling Data-Driven and Empathetic Interactions: A Context-Aware 3D Virtual Agent in Mixed Reality for Enhanced Financial Customer Experience",
      "title_zh": "实现数据驱动和富有同情心的互动：一种基于混合现实的上下文感知 3D 虚拟代理，用于提升金融客户体验",
      "authors": [
        "Cindy Xu",
        "Mengyu Chen",
        "Pranav Deshpande",
        "Elvir Azanli",
        "Runqing Yang",
        "Joseph Ligman"
      ],
      "abstract": "In this paper, we introduce a novel system designed to enhance customer\nservice in the financial and retail sectors through a context-aware 3D virtual\nagent, utilizing Mixed Reality (MR) and Vision Language Models (VLMs). Our\napproach focuses on enabling data-driven and empathetic interactions that\nensure customer satisfaction by introducing situational awareness of the\nphysical location, personalized interactions based on customer profiles, and\nrigorous privacy and security standards. We discuss our design considerations\ncritical for deployment in real-world customer service environments, addressing\nchallenges in user data management and sensitive information handling. We also\noutline the system architecture and key features unique to banking and retail\nenvironments. Our work demonstrates the potential of integrating MR and VLMs in\nservice industries, offering practical insights in customer service delivery\nwhile maintaining high standards of security and personalization.",
      "tldr_zh": "本文提出了一种基于 Mixed Reality (MR) 和 Vision Language Models (VLMs) 的情境感知 3D 虚拟代理系统，旨在提升金融和零售行业的客户服务体验。系统通过数据驱动和移情互动，实现对物理位置的 situational awareness、基于客户资料的个性化互动，并严格遵守隐私和安全标准。设计考虑了用户数据管理和敏感信息处理等挑战，展示了该系统在服务行业的实际应用潜力，提供可信赖的个性化服务见解。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.ET",
        "cs.MM",
        "H.5.1; K.4.3"
      ],
      "primary_category": "cs.HC",
      "comment": "to appear at 1st Workshop on Intelligent XR: Harnessing AI for\n  Next-Generation XR User Experiences at International Symposium on Mixed and\n  Augmented Reality (ISMAR) 2024",
      "pdf_url": "http://arxiv.org/pdf/2410.12051v1",
      "published_date": "2024-10-15 20:41:10 UTC",
      "updated_date": "2024-10-15 20:41:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:40:11.978089"
    },
    {
      "arxiv_id": "2410.12049v4",
      "title": "Sabiá-3 Technical Report",
      "title_zh": "Sabiá-3 技术报告",
      "authors": [
        "Hugo Abonizio",
        "Thales Sales Almeida",
        "Thiago Laitz",
        "Roseval Malaquias Junior",
        "Giovana Kerche Bonás",
        "Rodrigo Nogueira",
        "Ramon Pires"
      ],
      "abstract": "This report presents Sabi\\'a-3, our new flagship language model, and\nSabiazinho-3, a more cost-effective sibling. The models were trained on a large\nbrazilian-centric corpus. Evaluations across diverse professional and academic\nbenchmarks show a strong performance on Portuguese and Brazil-related tasks.\nSabi\\'a-3 shows large improvements in comparison to our previous best of model,\nSabia-2 Medium, especially in reasoning-intensive tasks. Notably, Sabi\\'a-3's\naverage performance matches frontier LLMs, while it is offered at a three to\nfour times lower cost per token, reinforcing the benefits of domain\nspecialization.",
      "tldr_zh": "本报告介绍了 Sabiá-3 作为旗舰语言模型，以及其更具成本效益的兄弟模型 Sabiazinho-3，这两个模型均在大型以巴西为中心的语料库上训练。在各种专业和学术基准测试中，Sabiá-3 在葡萄牙语和巴西相关任务上表现出色，并与之前的 Sabia-2 Medium 模型相比，尤其在推理密集型任务中实现了显著改进。值得注意的是，Sabiá-3 的平均性能可与前沿 LLMs 相当，但每 token 成本低 3 到 4 倍，突显了领域专化的优势。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.12049v4",
      "published_date": "2024-10-15 20:37:34 UTC",
      "updated_date": "2025-04-01 12:19:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:40:23.545151"
    },
    {
      "arxiv_id": "2410.12040v1",
      "title": "Concept-Reversed Winograd Schema Challenge: Evaluating and Improving Robust Reasoning in Large Language Models via Abstraction",
      "title_zh": "翻译失败",
      "authors": [
        "Kaiqiao Han",
        "Tianqing Fang",
        "Zhaowei Wang",
        "Yangqiu Song",
        "Mark Steedman"
      ],
      "abstract": "While Large Language Models (LLMs) have showcased remarkable proficiency in\nreasoning, there is still a concern about hallucinations and unreliable\nreasoning issues due to semantic associations and superficial logical chains.\nTo evaluate the extent to which LLMs perform robust reasoning instead of\nrelying on superficial logical chains, we propose a new evaluation dataset, the\nConcept-Reversed Winograd Schema Challenge (CR-WSC), based on the famous\nWinograd Schema Challenge (WSC) dataset. By simply reversing the concepts to\nthose that are more associated with the wrong answer, we find that the\nperformance of LLMs drops significantly despite the rationale of reasoning\nremaining the same. Furthermore, we propose Abstraction-of-Thought (AoT), a\nnovel prompt method for recovering adversarial cases to normal cases using\nconceptual abstraction to improve LLMs' robustness and consistency in\nreasoning, as demonstrated by experiments on CR-WSC.",
      "tldr_zh": "这篇论文提出 Concept-Reversed Winograd Schema Challenge (CR-WSC) 数据集，基于 Winograd Schema Challenge (WSC)，用于评估 Large Language Models (LLMs) 是否依赖表浅逻辑链而非稳健推理，通过反转概念使模型性能显著下降。研究发现，尽管推理合理性不变，LLMs 在这种对抗性设置下表现不佳，暴露了幻觉和语义关联的问题。为改善这一问题，作者引入 Abstraction-of-Thought (AoT) 提示方法，利用概念抽象将对抗性案例转化为正常案例，提升模型的稳健性和一致性。实验在 CR-WSC 上证明了 AoT 的有效性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.12040v1",
      "published_date": "2024-10-15 20:19:27 UTC",
      "updated_date": "2024-10-15 20:19:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:40:36.602627"
    },
    {
      "arxiv_id": "2410.12034v1",
      "title": "A Survey on Deep Tabular Learning",
      "title_zh": "深度表格学习的综述",
      "authors": [
        "Shriyank Somvanshi",
        "Subasish Das",
        "Syed Aaqib Javed",
        "Gian Antariksa",
        "Ahmed Hossain"
      ],
      "abstract": "Tabular data, widely used in industries like healthcare, finance, and\ntransportation, presents unique challenges for deep learning due to its\nheterogeneous nature and lack of spatial structure. This survey reviews the\nevolution of deep learning models for tabular data, from early fully connected\nnetworks (FCNs) to advanced architectures like TabNet, SAINT, TabTranSELU, and\nMambaNet. These models incorporate attention mechanisms, feature embeddings,\nand hybrid architectures to address tabular data complexities. TabNet uses\nsequential attention for instance-wise feature selection, improving\ninterpretability, while SAINT combines self-attention and intersample attention\nto capture complex interactions across features and data points, both advancing\nscalability and reducing computational overhead. Hybrid architectures such as\nTabTransformer and FT-Transformer integrate attention mechanisms with\nmulti-layer perceptrons (MLPs) to handle categorical and numerical data, with\nFT-Transformer adapting transformers for tabular datasets. Research continues\nto balance performance and efficiency for large datasets. Graph-based models\nlike GNN4TDL and GANDALF combine neural networks with decision trees or graph\nstructures, enhancing feature representation and mitigating overfitting in\nsmall datasets through advanced regularization techniques. Diffusion-based\nmodels like the Tabular Denoising Diffusion Probabilistic Model (TabDDPM)\ngenerate synthetic data to address data scarcity, improving model robustness.\nSimilarly, models like TabPFN and Ptab leverage pre-trained language models,\nincorporating transfer learning and self-supervised techniques into tabular\ntasks. This survey highlights key advancements and outlines future research\ndirections on scalability, generalization, and interpretability in diverse\ntabular data applications.",
      "tldr_zh": "这篇调查回顾了深度学习在表格数据上的发展，探讨了其在医疗、金融和交通等领域中的应用挑战，如数据异构性和缺乏空间结构。论文从早期全连接网络(FCNs)演进到先进架构如 TabNet（使用顺序注意力提升可解释性）、SAINT（结合自注意力捕捉特征交互）和混合模型如 TabTransformer 与 FT-Transformer，这些方法通过注意力机制、特征嵌入和图-based 模型（如 GNN4TDL）提高了性能和效率，同时扩散模型（如 TabDDPM）和预训练模型（如 TabPFN）解决了数据稀缺问题。总体发现显示，这些创新增强了模型的可扩展性、抗过拟合能力及泛化效果，而未来研究应聚焦于进一步提升可扩展性、泛化能力和可解释性，以适应多样化的表格数据应用。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "43 pages, 18 figures, 3 tables",
      "pdf_url": "http://arxiv.org/pdf/2410.12034v1",
      "published_date": "2024-10-15 20:08:08 UTC",
      "updated_date": "2024-10-15 20:08:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:40:48.441021"
    },
    {
      "arxiv_id": "2410.12031v1",
      "title": "A Learning Search Algorithm for the Restricted Longest Common Subsequence Problem",
      "title_zh": "针对受限最长公共子序列问题的学习搜索算法",
      "authors": [
        "Marko Djukanović",
        "Jaume Reixach",
        "Ana Nikolikj",
        "Tome Eftimov",
        "Aleksandar Kartelj",
        "Christian Blum"
      ],
      "abstract": "This paper addresses the Restricted Longest Common Subsequence (RLCS)\nproblem, an extension of the well-known Longest Common Subsequence (LCS)\nproblem. This problem has significant applications in bioinformatics,\nparticularly for identifying similarities and discovering mutual patterns and\nimportant motifs among DNA, RNA, and protein sequences. Building on recent\nadvancements in solving this problem through a general search framework, this\npaper introduces two novel heuristic approaches designed to enhance the search\nprocess by steering it towards promising regions in the search space. The first\nheuristic employs a probabilistic model to evaluate partial solutions during\nthe search process. The second heuristic is based on a neural network model\ntrained offline using a genetic algorithm. A key aspect of this approach is\nextracting problem-specific features of partial solutions and the complete\nproblem instance. An effective hybrid method, referred to as the learning beam\nsearch, is developed by combining the trained neural network model with a beam\nsearch framework. An important contribution of this paper is found in the\ngeneration of real-world instances where scientific abstracts serve as input\nstrings, and a set of frequently occurring academic words from the literature\nare used as restricted patterns. Comprehensive experimental evaluations\ndemonstrate the effectiveness of the proposed approaches in solving the RLCS\nproblem. Finally, an empirical explainability analysis is applied to the\nobtained results. In this way, key feature combinations and their respective\ncontributions to the success or failure of the algorithms across different\nproblem types are identified.",
      "tldr_zh": "该论文针对Restricted Longest Common Subsequence (RLCS)问题——Longest Common Subsequence (LCS)的扩展——提出了一种学习搜索算法，该问题在生物信息学中用于识别DNA、RNA和蛋白质序列的相似性和关键模式。研究引入两种新启发式方法：一种基于概率模型评估部分解决方案，另一种利用神经网络模型（通过遗传算法离线训练）提取问题特定特征。作者开发了混合方法learning beam search，将训练的神经网络与beam search框架结合，并通过生成真实世界实例（如科学摘要和学术词）进行全面实验评估。结果显示，该方法显著提升了RLCS问题的求解效率，并通过经验解释性分析识别了关键特征组合及其对算法性能的影响。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "33 pages, 12 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.12031v1",
      "published_date": "2024-10-15 20:02:15 UTC",
      "updated_date": "2024-10-15 20:02:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:40:59.934566"
    },
    {
      "arxiv_id": "2410.12013v1",
      "title": "MoE-Pruner: Pruning Mixture-of-Experts Large Language Model using the Hints from Its Router",
      "title_zh": "翻译失败",
      "authors": [
        "Yanyue Xie",
        "Zhi Zhang",
        "Ding Zhou",
        "Cong Xie",
        "Ziang Song",
        "Xin Liu",
        "Yanzhi Wang",
        "Xue Lin",
        "An Xu"
      ],
      "abstract": "Mixture-of-Experts (MoE) architectures face challenges such as high memory\nconsumption and redundancy in experts. Pruning MoE can reduce network weights\nwhile maintaining model performance. Motivated by the recent observation of\nemergent large magnitude features in Large Language Models (LLM) and MoE\nrouting policy, we propose MoE-Pruner, a method that prunes weights with the\nsmallest magnitudes multiplied by the corresponding input activations and\nrouter weights, on each output neuron. Our pruning method is one-shot,\nrequiring no retraining or weight updates. We evaluate our method on\nMixtral-8x7B and Mixtral-8x22B across multiple language benchmarks.\nExperimental results show that our pruning method significantly outperforms\nstate-of-the-art LLM pruning methods. Furthermore, our pruned MoE models can\nbenefit from a pretrained teacher model through expert-wise knowledge\ndistillation, improving performance post-pruning. Experimental results\ndemonstrate that the Mixtral-8x7B model with 50% sparsity maintains 99% of the\nperformance of the original model after the expert-wise knowledge distillation.",
      "tldr_zh": "本研究针对Mixture-of-Experts (MoE) 架构的高内存消耗和专家冗余问题，提出MoE-Pruner方法，该方法利用路由器的提示来修剪权重，通过计算权重幅度与输入激活和路由器权重的乘积，选择每个输出神经元的最小值进行一-shot修剪，而无需重新训练。\nMoE-Pruner在Mixtral-8x7B和Mixtral-8x22B模型上进行评估，结果显示其在多个语言基准上显著优于现有Large Language Models (LLM)修剪方法。\n此外，通过专家-wise知识蒸馏，修剪后的模型能从预训练教师模型中受益，进一步提升性能，例如Mixtral-8x7B在50%稀疏度下保持了原模型99%的性能。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.12013v1",
      "published_date": "2024-10-15 19:22:27 UTC",
      "updated_date": "2024-10-15 19:22:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:41:13.200179"
    },
    {
      "arxiv_id": "2410.12010v3",
      "title": "Bias Similarity Across Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Hyejun Jeong",
        "Shiqing Ma",
        "Amir Houmansadr"
      ],
      "abstract": "Bias in Large Language Models remains a critical concern as these systems are\nincreasingly deployed in high-stakes applications. Yet most fairness\nevaluations rely on scalar metrics or single-model analysis, overlooking how\nbiases align -- or diverge -- across model families, scales, and tuning\nstrategies. In this work, we reframe bias similarity as a form of functional\nsimilarity and evaluate 24 LLMs from four major families on over one million\nstructured prompts spanning four bias dimensions. Our findings uncover that\nfairness is not strongly determined by model size, architecture, instruction\ntuning, or openness. Instead, bias behaviors are highly context-dependent and\nstructurally persistent, often resistant to current alignment techniques.\nContrary to common assumptions, we find that open-source models frequently\nmatch or outperform proprietary models in both fairness and utility. These\nresults call into question the default reliance on proprietary systems and\nhighlight the need for behaviorally grounded, model-specific audits to better\nunderstand how bias manifests and endures across the LLM landscape.",
      "tldr_zh": "本文研究了大语言模型(LLMs)中的偏见相似性，通过将偏见视为功能相似性的一种形式，对24个来自四大模型家族的LLMs进行了大规模评估，使用超过一百万结构化提示覆盖四个偏见维度。结果发现，偏见行为高度依赖于上下文且结构上持久，抵抗当前的对齐技术，且不强依赖于模型大小、架构、指令调优或开源性。相反，开源模型在公平性和实用性上经常匹配或超过专有模型，这质疑了对专有系统的默认依赖，并强调需要基于行为的模型特定审计来理解偏见的表现和持久性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "under review",
      "pdf_url": "http://arxiv.org/pdf/2410.12010v3",
      "published_date": "2024-10-15 19:21:14 UTC",
      "updated_date": "2025-05-17 09:53:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:41:24.877566"
    },
    {
      "arxiv_id": "2410.12006v1",
      "title": "Beyond Labels: A Self-Supervised Framework with Masked Autoencoders and Random Cropping for Breast Cancer Subtype Classification",
      "title_zh": "翻译失败",
      "authors": [
        "Annalisa Chiocchetti",
        "Marco Dossena",
        "Christopher Irwin",
        "Luigi Portinale"
      ],
      "abstract": "This work contributes to breast cancer sub-type classification using\nhistopathological images. We utilize masked autoencoders (MAEs) to learn a\nself-supervised embedding tailored for computer vision tasks in this domain.\nThis embedding captures informative representations of histopathological data,\nfacilitating feature learning without extensive labeled datasets. During\npre-training, we investigate employing a random crop technique to generate a\nlarge dataset from WSIs automatically. Additionally, we assess the performance\nof linear probes for multi-class classification tasks of cancer sub-types using\nthe representations learnt by the MAE. Our approach aims to achieve strong\nperformance on downstream tasks by leveraging the complementary strengths of\nViTs and autoencoders. We evaluate our model's performance on the BRACS dataset\nand compare it with existing benchmarks.",
      "tldr_zh": "这篇论文提出了一种自监督框架，用于乳腺癌亚型分类，通过 Masked Autoencoders (MAEs) 学习针对组织病理图像的嵌入表示，从而在无需大量标注数据的情况下捕捉关键特征。框架在预训练阶段采用 Random Cropping 技术从 WSIs 自动生成大型数据集，并利用线性探针进行多类分类任务的评估。实验结果显示，该方法在 BRACS dataset 上表现优异，与现有基准相比实现了更强的下游任务性能。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.12006v1",
      "published_date": "2024-10-15 19:13:05 UTC",
      "updated_date": "2024-10-15 19:13:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:41:36.824683"
    },
    {
      "arxiv_id": "2410.11985v1",
      "title": "The Fair Language Model Paradox",
      "title_zh": "公平语言模型悖论",
      "authors": [
        "Andrea Pinto",
        "Tomer Galanti",
        "Randall Balestriero"
      ],
      "abstract": "Large Language Models (LLMs) are widely deployed in real-world applications,\nyet little is known about their training dynamics at the token level.\nEvaluation typically relies on aggregated training loss, measured at the batch\nlevel, which overlooks subtle per-token biases arising from (i) varying\ntoken-level dynamics and (ii) structural biases introduced by hyperparameters.\nWhile weight decay is commonly used to stabilize training, we reveal that it\nsilently introduces performance biases detectable only at the token level. In\nfact, we empirically show across different dataset sizes, model architectures\nand sizes ranging from 270M to 3B parameters that as weight decay increases,\nlow-frequency tokens are disproportionately depreciated. This is particularly\nconcerning, as these neglected low-frequency tokens represent the vast majority\nof the token distribution in most languages, calling for novel regularization\ntechniques that ensure fairness across all available tokens.",
      "tldr_zh": "本研究揭示了大型语言模型（LLMs）的公平性悖论，即现有评估主要依赖批次级别的聚合训练损失，而忽略了 token 级别的细微偏差，这些偏差源于 token 动态变化和超参数引入的结构问题。作者发现，权重衰减（weight decay）虽然用于稳定训练，却会导致低频 token 被不成比例地贬值，这一现象在不同数据集大小、模型架构和参数规模（从 270M 到 3B）下的实验中得到证实。低频 token 在大多数语言中占绝大多数，因此论文呼吁开发新型正则化技术（regularization techniques），以确保所有 token 的公平性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.11985v1",
      "published_date": "2024-10-15 18:47:12 UTC",
      "updated_date": "2024-10-15 18:47:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:41:48.123855"
    },
    {
      "arxiv_id": "2410.11977v4",
      "title": "Generative AI Policies under the Microscope: How CS Conferences Are Navigating the New Frontier in Scholarly Writing",
      "title_zh": "翻译失败",
      "authors": [
        "Mahjabin Nahar",
        "Sian Lee",
        "Rebekah Guillen",
        "Dongwon Lee"
      ],
      "abstract": "As the use of Generative AI (Gen-AI) in scholarly writing and peer reviews\ncontinues to rise, it is essential for the computing field to establish and\nadopt clear Gen-AI policies. This study examines the landscape of Gen-AI\npolicies across 64 major Computer Science conferences and offers\nrecommendations for promoting more effective and responsible use of Gen-AI in\nthe field.",
      "tldr_zh": "这篇论文探讨了Generative AI (Gen-AI)在学术写作和同行评审中的日益应用，强调计算机科学(CS)领域需要制定清晰的政策。该研究调查了64个主要CS会议的Gen-AI政策，分析了当前景观并指出了潜在挑战。作者提供了具体推荐，以促进Gen-AI在学术领域的更有效和负责任使用。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CY",
      "comment": "Accepted and to appear in Communications of the ACM (CACM) in 2025",
      "pdf_url": "http://arxiv.org/pdf/2410.11977v4",
      "published_date": "2024-10-15 18:33:42 UTC",
      "updated_date": "2025-03-12 17:10:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:41:59.619819"
    },
    {
      "arxiv_id": "2410.12881v2",
      "title": "MIND: Math Informed syNthetic Dialogues for Pretraining LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Syeda Nahida Akter",
        "Shrimai Prabhumoye",
        "John Kamalu",
        "Sanjeev Satheesh",
        "Eric Nyberg",
        "Mostofa Patwary",
        "Mohammad Shoeybi",
        "Bryan Catanzaro"
      ],
      "abstract": "The utility of synthetic data to enhance pretraining data quality and hence\nto improve downstream task accuracy has been widely explored in recent large\nlanguage models (LLMs). Yet, these approaches fall inadequate in complex,\nmulti-hop and mathematical reasoning tasks as the synthetic data typically\nfails to add complementary knowledge to the existing raw corpus. In this work,\nwe propose a novel large-scale and diverse Math Informed syNthetic Dialogue\n(MIND) generation method that improves the mathematical reasoning ability of\nLLMs. Specifically, using MIND, we generate synthetic conversations based on\nOpenWebMath (OWM), resulting in a new math corpus, MIND-OWM. Our experiments\nwith different conversational settings reveal that incorporating knowledge gaps\nbetween dialog participants is essential for generating high-quality math data.\nWe further identify an effective way to format and integrate synthetic and raw\ndata during pretraining to maximize the gain in mathematical reasoning,\nemphasizing the need to restructure raw data rather than use it as-is. Compared\nto pretraining just on raw data, a model pretrained on MIND-OWM shows\nsignificant boost in mathematical reasoning (GSM8K: +13.42%, MATH: +2.30%),\nincluding superior performance in specialized knowledge (MMLU: +4.55%,\nMMLU-STEM: +4.28%) and general purpose reasoning tasks (GENERAL REASONING:\n+2.51%).",
      "tldr_zh": "本文提出 MIND 方法，通过生成基于 OpenWebMath (OWM) 的合成对话数据，旨在提升大型语言模型 (LLMs) 在数学推理任务上的性能。MIND 强调对话参与者间的知识差距，以创建高质量语料 MIND-OWM，并优化合成数据与原始数据的格式化和整合方式，以最大化预训练效果。实验结果显示，与仅使用原始数据预训练相比，MIND-OWM 模型在 GSM8K 上提升 13.42%、MATH 上提升 2.30%，并在 MMLU (+4.55%)、MMLU-STEM (+4.28%) 和一般推理任务 (+2.51%) 上表现出显著改进。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "31 pages, 5 figures, 14 tables",
      "pdf_url": "http://arxiv.org/pdf/2410.12881v2",
      "published_date": "2024-10-15 18:25:53 UTC",
      "updated_date": "2025-04-25 03:14:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:42:12.822947"
    },
    {
      "arxiv_id": "2410.11971v2",
      "title": "DDIL: Diversity Enhancing Diffusion Distillation With Imitation Learning",
      "title_zh": "DDIL：利用模仿学习增强多样性的扩散蒸馏",
      "authors": [
        "Risheek Garrepalli",
        "Shweta Mahajan",
        "Munawar Hayat",
        "Fatih Porikli"
      ],
      "abstract": "Diffusion models excel at generative modeling (e.g., text-to-image) but\nsampling requires multiple denoising network passes, limiting practicality.\nEfforts such as progressive distillation or consistency distillation have shown\npromise by reducing the number of passes at the expense of quality of the\ngenerated samples. In this work we identify co-variate shift as one of reason\nfor poor performance of multi-step distilled models from compounding error at\ninference time. To address co-variate shift, we formulate diffusion\ndistillation within imitation learning (DDIL) framework and enhance training\ndistribution for distilling diffusion models on both data distribution (forward\ndiffusion) and student induced distributions (backward diffusion). Training on\ndata distribution helps to diversify the generations by preserving marginal\ndata distribution and training on student distribution addresses compounding\nerror by correcting covariate shift. In addition, we adopt reflected diffusion\nformulation for distillation and demonstrate improved performance, stable\ntraining across different distillation methods. We show that DDIL consistency\nimproves on baseline algorithms of progressive distillation (PD), Latent\nconsistency models (LCM) and Distribution Matching Distillation (DMD2).",
      "tldr_zh": "本文提出 DDIL 框架，用于提升扩散模型（Diffusion models）的蒸馏效率，同时解决协变量偏移（Co-variate shift）导致的错误积累问题。DDIL 通过模仿学习（Imitation Learning）框架增强训练分布，包括在数据分布（forward diffusion）上保留边缘数据以提高生成多样性，以及在学生诱导分布（backward diffusion）上纠正偏移以稳定性能。此外，采用反射扩散公式（Reflected diffusion formulation），实验结果显示 DDIL 在渐进式蒸馏（PD）、潜在一致性模型（LCM）和分布匹配蒸馏（DMD2）等基线算法上取得了显著改进。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.11971v2",
      "published_date": "2024-10-15 18:21:47 UTC",
      "updated_date": "2025-03-29 03:05:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:42:25.138068"
    },
    {
      "arxiv_id": "2410.12880v3",
      "title": "Navigating the Cultural Kaleidoscope: A Hitchhiker's Guide to Sensitivity in Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Somnath Banerjee",
        "Sayan Layek",
        "Hari Shrawgi",
        "Rajarshi Mandal",
        "Avik Halder",
        "Shanu Kumar",
        "Sagnik Basu",
        "Parag Agrawal",
        "Rima Hazra",
        "Animesh Mukherjee"
      ],
      "abstract": "As LLMs are increasingly deployed in global applications, the importance of\ncultural sensitivity becomes paramount, ensuring that users from diverse\nbackgrounds feel respected and understood. Cultural harm can arise when these\nmodels fail to align with specific cultural norms, resulting in\nmisrepresentations or violations of cultural values. This work addresses the\nchallenges of ensuring cultural sensitivity in LLMs, especially in\nsmall-parameter models that often lack the extensive training data needed to\ncapture global cultural nuances. We present two key contributions: (1) A\ncultural harm test dataset, created to assess model outputs across different\ncultural contexts through scenarios that expose potential cultural\ninsensitivities, and (2) A culturally aligned preference dataset, aimed at\nrestoring cultural sensitivity through fine-tuning based on feedback from\ndiverse annotators. These datasets facilitate the evaluation and enhancement of\nLLMs, ensuring their ethical and safe deployment across different cultural\nlandscapes. Our results show that integrating culturally aligned feedback leads\nto a marked improvement in model behavior, significantly reducing the\nlikelihood of generating culturally insensitive or harmful content. Ultimately,\nthis work paves the way for more inclusive and respectful AI systems, fostering\na future where LLMs can safely and ethically navigate the complexities of\ndiverse cultural landscapes.",
      "tldr_zh": "本研究探讨了大型语言模型（LLMs）在全球应用中的文化敏感性问题，特别是小参数模型因训练数据不足而可能导致文化伤害或违反文化规范。该工作的主要贡献包括：（1）开发了一个文化伤害测试数据集，用于评估模型在不同文化语境下的输出表现；以及（2）构建了一个文化对齐偏好数据集，通过多样化注释者的反馈进行微调，以提升模型的文化敏感性。实验结果显示，整合这些文化对齐反馈显著改善了LLMs的行为，减少了生成文化不敏感或有害内容的风险。该研究为更具包容性和伦理性的AI系统铺平了道路，确保LLMs能够在多元文化环境中安全部署。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted at NAACL 2025 (Main track). [Project\n  Page](https://neuralsentinel.github.io/KaleidoCulture/)",
      "pdf_url": "http://arxiv.org/pdf/2410.12880v3",
      "published_date": "2024-10-15 18:13:10 UTC",
      "updated_date": "2025-01-24 18:56:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:42:36.254003"
    },
    {
      "arxiv_id": "2410.11963v1",
      "title": "CtrlSynth: Controllable Image Text Synthesis for Data-Efficient Multimodal Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Qingqing Cao",
        "Mahyar Najibi",
        "Sachin Mehta"
      ],
      "abstract": "Pretraining robust vision or multimodal foundation models (e.g., CLIP) relies\non large-scale datasets that may be noisy, potentially misaligned, and have\nlong-tail distributions. Previous works have shown promising results in\naugmenting datasets by generating synthetic samples. However, they only support\ndomain-specific ad hoc use cases (e.g., either image or text only, but not\nboth), and are limited in data diversity due to a lack of fine-grained control\nover the synthesis process. In this paper, we design a \\emph{controllable}\nimage-text synthesis pipeline, CtrlSynth, for data-efficient and robust\nmultimodal learning. The key idea is to decompose the visual semantics of an\nimage into basic elements, apply user-specified control policies (e.g., remove,\nadd, or replace operations), and recompose them to synthesize images or texts.\nThe decompose and recompose feature in CtrlSynth allows users to control data\nsynthesis in a fine-grained manner by defining customized control policies to\nmanipulate the basic elements. CtrlSynth leverages the capabilities of\npretrained foundation models such as large language models or diffusion models\nto reason and recompose basic elements such that synthetic samples are natural\nand composed in diverse ways. CtrlSynth is a closed-loop, training-free, and\nmodular framework, making it easy to support different pretrained models. With\nextensive experiments on 31 datasets spanning different vision and\nvision-language tasks, we show that CtrlSynth substantially improves zero-shot\nclassification, image-text retrieval, and compositional reasoning performance\nof CLIP models.",
      "tldr_zh": "该研究提出了一种可控图像-文本合成框架 CtrlSynth，用于数据高效的多模态学习，旨在解决现有数据集的噪音、错位和长尾分布问题。CtrlSynth 的核心机制是将图像的视觉语义分解成基本元素，并通过用户自定义的控制策略（如移除、添加或替换）进行细粒度操纵，然后利用预训练模型（如大语言模型或扩散模型）重新组合生成自然多样的合成样本。该框架是闭环、无需训练的模块化系统，便于集成不同预训练模型。在 31 个数据集上的实验显示，CtrlSynth 显著提升了 CLIP 模型的 zero-shot classification、图像-文本检索和组合推理性能。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.11963v1",
      "published_date": "2024-10-15 18:06:41 UTC",
      "updated_date": "2024-10-15 18:06:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:42:48.212067"
    },
    {
      "arxiv_id": "2410.11842v1",
      "title": "MoH: Multi-Head Attention as Mixture-of-Head Attention",
      "title_zh": "MoH：多头注意力作为混合头注意力",
      "authors": [
        "Peng Jin",
        "Bo Zhu",
        "Li Yuan",
        "Shuicheng Yan"
      ],
      "abstract": "In this work, we upgrade the multi-head attention mechanism, the core of the\nTransformer model, to improve efficiency while maintaining or surpassing the\nprevious accuracy level. We show that multi-head attention can be expressed in\nthe summation form. Drawing on the insight that not all attention heads hold\nequal significance, we propose Mixture-of-Head attention (MoH), a new\narchitecture that treats attention heads as experts in the Mixture-of-Experts\n(MoE) mechanism. MoH has two significant advantages: First, MoH enables each\ntoken to select the appropriate attention heads, enhancing inference efficiency\nwithout compromising accuracy or increasing the number of parameters. Second,\nMoH replaces the standard summation in multi-head attention with a weighted\nsummation, introducing flexibility to the attention mechanism and unlocking\nextra performance potential. Extensive experiments on ViT, DiT, and LLMs\ndemonstrate that MoH outperforms multi-head attention by using only 50%-90% of\nthe attention heads. Moreover, we demonstrate that pre-trained multi-head\nattention models, such as LLaMA3-8B, can be further continue-tuned into our MoH\nmodels. Notably, MoH-LLaMA3-8B achieves an average accuracy of 64.0% across 14\nbenchmarks, outperforming LLaMA3-8B by 2.4% by utilizing only 75% of the\nattention heads. We believe the proposed MoH is a promising alternative to\nmulti-head attention and provides a strong foundation for developing advanced\nand efficient attention-based models.",
      "tldr_zh": "本研究提出 Mixture-of-Head attention (MoH)，一种升级多头注意力(multi-head attention)机制的架构，将注意力头视为 Mixture-of-Experts (MoE) 中的专家，从而提高模型效率，同时保持或提升准确性。MoH 允许每个 token 选择合适的注意力头，并通过加权求和替换标准求和，增强灵活性和性能潜力。实验显示，在 ViT、DiT 和 LLMs 等模型上，MoH 仅使用 50%-90% 的注意力头就超越了基线性能；此外，对预训练模型如 LLaMA3-8B 进行微调后，MoH-LLaMA3-8B 在 14 个基准上的平均准确率达 64.0%，比原模型高 2.4%。这项创新为开发更高效的注意力机制提供了坚实基础。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "23 pages, code: https://github.com/SkyworkAI/MoH",
      "pdf_url": "http://arxiv.org/pdf/2410.11842v1",
      "published_date": "2024-10-15 17:59:44 UTC",
      "updated_date": "2024-10-15 17:59:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:43:00.433886"
    },
    {
      "arxiv_id": "2410.11841v2",
      "title": "GaVaMoE: Gaussian-Variational Gated Mixture of Experts for Explainable Recommendation",
      "title_zh": "翻译失败",
      "authors": [
        "Fei Tang",
        "Yongliang Shen",
        "Hang Zhang",
        "Zeqi Tan",
        "Wenqi Zhang",
        "Zhibiao Huang",
        "Kaitao Song",
        "Weiming Lu",
        "Yueting Zhuang"
      ],
      "abstract": "Large language model-based explainable recommendation (LLM-based ER) systems\nshow promise in generating human-like explanations for recommendations.\nHowever, they face challenges in modeling user-item collaborative preferences,\npersonalizing explanations, and handling sparse user-item interactions. To\naddress these issues, we propose GaVaMoE, a novel Gaussian-Variational Gated\nMixture of Experts framework for explainable recommendation. GaVaMoE introduces\ntwo key components: (1) a rating reconstruction module that employs Variational\nAutoencoder (VAE) with a Gaussian Mixture Model (GMM) to capture complex\nuser-item collaborative preferences, serving as a pre-trained multi-gating\nmechanism; and (2) a set of fine-grained expert models coupled with the\nmulti-gating mechanism for generating highly personalized explanations. The VAE\ncomponent models latent factors in user-item interactions, while the GMM\nclusters users with similar behaviors. Each cluster corresponds to a gate in\nthe multi-gating mechanism, routing user-item pairs to appropriate expert\nmodels. This architecture enables GaVaMoE to generate tailored explanations for\nspecific user types and preferences, mitigating data sparsity by leveraging\nuser similarities. Extensive experiments on three real-world datasets\ndemonstrate that GaVaMoE significantly outperforms existing methods in\nexplanation quality, personalization, and consistency. Notably, GaVaMoE\nexhibits robust performance in scenarios with sparse user-item interactions,\nmaintaining high-quality explanations even for users with limited historical\ndata.",
      "tldr_zh": "该研究提出 GaVaMoE，一种 Gaussian-Variational Gated Mixture of Experts 框架，旨在解决大型语言模型-based explainable recommendation (LLM-based ER) 系统在建模用户-物品协作偏好、个性化解释和处理稀疏交互方面的挑战。GaVaMoE 包括两个关键组件：一个基于 Variational Autoencoder (VAE) 和 Gaussian Mixture Model (GMM) 的评分重建模块，用于捕捉复杂的用户-物品偏好并作为多门控机制；以及一组细粒度专家模型，通过用户聚类和路由生成高度个性化的解释，从而缓解数据稀疏问题。实验结果显示，在三个真实数据集上，GaVaMoE 在解释质量、个性和一致性方面显著优于现有方法，并在稀疏交互场景中保持强劲性能。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.11841v2",
      "published_date": "2024-10-15 17:59:30 UTC",
      "updated_date": "2025-03-04 01:02:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:43:13.391951"
    },
    {
      "arxiv_id": "2410.11840v1",
      "title": "A Hitchhiker's Guide to Scaling Law Estimation",
      "title_zh": "翻译失败",
      "authors": [
        "Leshem Choshen",
        "Yang Zhang",
        "Jacob Andreas"
      ],
      "abstract": "Scaling laws predict the loss of a target machine learning model by\nextrapolating from easier-to-train models with fewer parameters or smaller\ntraining sets. This provides an efficient way for practitioners and researchers\nalike to compare pretraining decisions involving optimizers, datasets, and\nmodel architectures. Despite the widespread use of scaling laws to model the\ndynamics of language model training, there has been little work on\nunderstanding how to best estimate and interpret them. We collect (and release)\na large-scale dataset containing losses and downstream evaluations for 485\npreviously published pretrained models. We use these to estimate more than 1000\nscaling laws, then derive a set of best practices for estimating scaling laws\nin new model families. We find that fitting scaling laws to intermediate\ncheckpoints of training runs (and not just their final losses) substantially\nimproves accuracy, and that -- all else equal -- estimates of performance are\ngenerally most accurate when derived from other models of similar sizes.\nHowever, because there is a significant degree of variability across model\nseeds, training multiple small models is sometimes more useful than training a\nsingle large one. Moreover, while different model families differ scaling\nbehavior, they are often similar enough that a target model's behavior can be\npredicted from a single model with the same architecture, along with scaling\nparameter estimates derived from other model families.",
      "tldr_zh": "这篇论文介绍了如何有效估计机器学习模型的缩放定律（scaling laws），以通过外推更小模型的损失来预测目标模型的表现，从而帮助比较预训练决策如优化器、数据集和模型架构。作者收集并发布了包含485个预训练模型的大规模数据集，基于此估计了超过1000个缩放定律，并总结了最佳实践，包括使用训练运行的中间检查点（intermediate checkpoints）来显著提高准确性。研究发现，估计性能最可靠时来源于类似大小的模型，且由于模型种子间的变异性，训练多个小模型往往比训练单个大模型更实用；此外，不同模型家族的缩放行为虽有差异，但足够相似，可借助单一架构模型和跨家族参数进行预测。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.11840v1",
      "published_date": "2024-10-15 17:59:10 UTC",
      "updated_date": "2024-10-15 17:59:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:43:25.195231"
    },
    {
      "arxiv_id": "2410.11833v1",
      "title": "Mitigating Suboptimality of Deterministic Policy Gradients in Complex Q-functions",
      "title_zh": "翻译失败",
      "authors": [
        "Ayush Jain",
        "Norio Kosaka",
        "Xinhu Li",
        "Kyung-Min Kim",
        "Erdem Bıyık",
        "Joseph J. Lim"
      ],
      "abstract": "In reinforcement learning, off-policy actor-critic approaches like DDPG and\nTD3 are based on the deterministic policy gradient. Herein, the Q-function is\ntrained from off-policy environment data and the actor (policy) is trained to\nmaximize the Q-function via gradient ascent. We observe that in complex tasks\nlike dexterous manipulation and restricted locomotion, the Q-value is a complex\nfunction of action, having several local optima or discontinuities. This poses\na challenge for gradient ascent to traverse and makes the actor prone to get\nstuck at local optima. To address this, we introduce a new actor architecture\nthat combines two simple insights: (i) use multiple actors and evaluate the\nQ-value maximizing action, and (ii) learn surrogates to the Q-function that are\nsimpler to optimize with gradient-based methods. We evaluate tasks such as\nrestricted locomotion, dexterous manipulation, and large discrete-action space\nrecommender systems and show that our actor finds optimal actions more\nfrequently and outperforms alternate actor architectures.",
      "tldr_zh": "本研究针对强化学习中基于确定性策略梯度（Deterministic Policy Gradients）的算法，如 DDPG 和 TD3，在复杂 Q-function 任务下容易陷入局部最优或不连续性的问题，提出了一种新 actor 架构。 该架构结合了两个关键见解：（i）使用多个 actors 并选择 Q-value 最大化的动作，（ii）学习 Q-function 的简单代理，以便更易于梯度方法优化。 在受限运动、灵巧操作以及大离散动作空间的推荐系统等任务中，实验结果显示，该 actor 架构更频繁地找到最优动作，并优于其他备选架构。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.RO",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.11833v1",
      "published_date": "2024-10-15 17:58:03 UTC",
      "updated_date": "2024-10-15 17:58:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:43:45.783600"
    },
    {
      "arxiv_id": "2410.11825v3",
      "title": "Learning Smooth Humanoid Locomotion through Lipschitz-Constrained Policies",
      "title_zh": "通过Lipschitz约束策略学习平滑的人形机器人步态",
      "authors": [
        "Zixuan Chen",
        "Xialin He",
        "Yen-Jen Wang",
        "Qiayuan Liao",
        "Yanjie Ze",
        "Zhongyu Li",
        "S. Shankar Sastry",
        "Jiajun Wu",
        "Koushil Sreenath",
        "Saurabh Gupta",
        "Xue Bin Peng"
      ],
      "abstract": "Reinforcement learning combined with sim-to-real transfer offers a general\nframework for developing locomotion controllers for legged robots. To\nfacilitate successful deployment in the real world, smoothing techniques, such\nas low-pass filters and smoothness rewards, are often employed to develop\npolicies with smooth behaviors. However, because these techniques are\nnon-differentiable and usually require tedious tuning of a large set of\nhyperparameters, they tend to require extensive manual tuning for each robotic\nplatform. To address this challenge and establish a general technique for\nenforcing smooth behaviors, we propose a simple and effective method that\nimposes a Lipschitz constraint on a learned policy, which we refer to as\nLipschitz-Constrained Policies (LCP). We show that the Lipschitz constraint can\nbe implemented in the form of a gradient penalty, which provides a\ndifferentiable objective that can be easily incorporated with automatic\ndifferentiation frameworks. We demonstrate that LCP effectively replaces the\nneed for smoothing rewards or low-pass filters and can be easily integrated\ninto training frameworks for many distinct humanoid robots. We extensively\nevaluate LCP in both simulation and real-world humanoid robots, producing\nsmooth and robust locomotion controllers. All simulation and deployment code,\nalong with complete checkpoints, is available on our project page:\nhttps://lipschitz-constrained-policy.github.io.",
      "tldr_zh": "本文提出了一种名为 Lipschitz-Constrained Policies (LCP) 的方法，用于通过强化学习学习平滑的人形机器人运动控制器，以解决传统平滑技术（如低通滤波器和奖励函数）需要大量手动调优的问题。LCP 通过施加 Lipschitz 约束形式下的梯度惩罚，实现可微分的目标整合，便于与自动微分框架结合，并适用于多种机器人平台。实验在模拟和真实世界环境中验证了 LCP 的有效性，产生了平滑且鲁棒的运动控制器，并公开了相关代码和检查点。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "8 pages",
      "pdf_url": "http://arxiv.org/pdf/2410.11825v3",
      "published_date": "2024-10-15 17:52:20 UTC",
      "updated_date": "2024-10-28 09:46:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:43:47.774747"
    },
    {
      "arxiv_id": "2410.11792v1",
      "title": "OKAMI: Teaching Humanoid Robots Manipulation Skills through Single Video Imitation",
      "title_zh": "翻译失败",
      "authors": [
        "Jinhan Li",
        "Yifeng Zhu",
        "Yuqi Xie",
        "Zhenyu Jiang",
        "Mingyo Seo",
        "Georgios Pavlakos",
        "Yuke Zhu"
      ],
      "abstract": "We study the problem of teaching humanoid robots manipulation skills by\nimitating from single video demonstrations. We introduce OKAMI, a method that\ngenerates a manipulation plan from a single RGB-D video and derives a policy\nfor execution. At the heart of our approach is object-aware retargeting, which\nenables the humanoid robot to mimic the human motions in an RGB-D video while\nadjusting to different object locations during deployment. OKAMI uses\nopen-world vision models to identify task-relevant objects and retarget the\nbody motions and hand poses separately. Our experiments show that OKAMI\nachieves strong generalizations across varying visual and spatial conditions,\noutperforming the state-of-the-art baseline on open-world imitation from\nobservation. Furthermore, OKAMI rollout trajectories are leveraged to train\nclosed-loop visuomotor policies, which achieve an average success rate of 79.2%\nwithout the need for labor-intensive teleoperation. More videos can be found on\nour website https://ut-austin-rpl.github.io/OKAMI/.",
      "tldr_zh": "本研究提出 OKAMI 方法，通过单视频模仿教导人形机器人操控技能，从一个 RGB-D 视频生成操控计划。OKAMI 的核心是 object-aware retargeting 技术，利用 open-world vision models 识别任务相关物体，并分别调整身体动作和手部姿势，以适应不同物体位置。实验结果表明，该方法在开放世界模仿任务中超越现有基线，并在训练闭环 visuomotor policies 时实现平均成功率 79.2%，无需繁重的遥操作。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "Accepted for oral presentation at 8th Annual Conference on Robot\n  Learning. Project website: https://ut-austin-rpl.github.io/OKAMI/",
      "pdf_url": "http://arxiv.org/pdf/2410.11792v1",
      "published_date": "2024-10-15 17:17:54 UTC",
      "updated_date": "2024-10-15 17:17:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:44:00.776845"
    },
    {
      "arxiv_id": "2410.11933v2",
      "title": "Beyond Sequence: Impact of Geometric Context for RNA Property Prediction",
      "title_zh": "超越序列：几何上下文对 RNA 属性预测的影响",
      "authors": [
        "Junjie Xu",
        "Artem Moskalev",
        "Tommaso Mansi",
        "Mangal Prakash",
        "Rui Liao"
      ],
      "abstract": "Accurate prediction of RNA properties, such as stability and interactions, is\ncrucial for advancing our understanding of biological processes and developing\nRNA-based therapeutics. RNA structures can be represented as 1D sequences, 2D\ntopological graphs, or 3D all-atom models, each offering different insights\ninto its function. Existing works predominantly focus on 1D sequence-based\nmodels, which overlook the geometric context provided by 2D and 3D geometries.\nThis study presents the first systematic evaluation of incorporating explicit\n2D and 3D geometric information into RNA property prediction, considering not\nonly performance but also real-world challenges such as limited data\navailability, partial labeling, sequencing noise, and computational efficiency.\nTo this end, we introduce a newly curated set of RNA datasets with enhanced 2D\nand 3D structural annotations, providing a resource for model evaluation on RNA\ndata. Our findings reveal that models with explicit geometry encoding generally\noutperform sequence-based models, with an average prediction RMSE reduction of\naround 12% across all various RNA tasks and excelling in low-data and partial\nlabeling regimes, underscoring the value of explicitly incorporating geometric\ncontext. On the other hand, geometry-unaware sequence-based models are more\nrobust under sequencing noise but often require around $2-5\\times$ training\ndata to match the performance of geometry-aware models. Our study offers\nfurther insights into the trade-offs between different RNA representations in\npractical applications and addresses a significant gap in evaluating deep\nlearning models for RNA tasks.",
      "tldr_zh": "本文研究超越了传统的 RNA 属性预测方法，首次系统评估了整合 2D 和 3D 几何信息的价值，以提升对 RNA 稳定性及交互等属性的预测准确性。研究引入了一个新颖的 RNA 数据集，包含增强的结构注释，并比较了序列模型与几何编码模型的表现。结果显示，几何感知模型平均 RMSE 降低了约 12%，尤其在数据有限和部分标记场景中表现出色；然而，序列模型在测序噪声下更具鲁棒性，但需 2-5 倍数据才能匹敌几何模型。总体而言，该研究揭示了不同 RNA 表示之间的权衡，提供重要洞见以推进 RNA 基础研究和治疗应用。",
      "categories": [
        "q-bio.QM",
        "cs.AI",
        "cs.LG",
        "q-bio.BM"
      ],
      "primary_category": "q-bio.QM",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.11933v2",
      "published_date": "2024-10-15 17:09:34 UTC",
      "updated_date": "2025-04-21 00:07:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:44:13.164102"
    },
    {
      "arxiv_id": "2410.11786v2",
      "title": "Selection-p: Self-Supervised Task-Agnostic Prompt Compression for Faithfulness and Transferability",
      "title_zh": "Selection-p：自监督任务无关提示压缩用于忠实性和迁移性",
      "authors": [
        "Tsz Ting Chung",
        "Leyang Cui",
        "Lemao Liu",
        "Xinting Huang",
        "Shuming Shi",
        "Dit-Yan Yeung"
      ],
      "abstract": "Large Language Models (LLMs) have demonstrated impressive capabilities in a\nwide range of natural language processing tasks when leveraging in-context\nlearning. To mitigate the additional computational and financial costs\nassociated with in-context learning, several prompt compression methods have\nbeen proposed to compress the in-context learning prompts. Despite their\nsuccess, these methods face challenges with transferability due to\nmodel-specific compression, or rely on external training data, such as GPT-4.\nIn this paper, we investigate the ability of LLMs to develop a unified\ncompression method that discretizes uninformative tokens, utilizing a\nself-supervised pre-training technique. By introducing a small number of\nparameters during the continual pre-training, the proposed Selection-p produces\na probability for each input token, indicating whether to preserve or discard\nit. Experiments show Selection-p achieves state-of-the-art performance across\nnumerous classification tasks, achieving compression rates of up to 10 times\nwhile experiencing only a marginal 0.8% decrease in performance. Moreover, it\nexhibits superior transferability to different models compared to prior work.\nAdditionally, we further analyze how Selection-p helps maintain performance on\nin-context learning with long contexts.",
      "tldr_zh": "本论文提出了一种自监督任务无关的提示压缩方法 Selection-p，旨在解决大型语言模型 (LLMs) 在 in-context learning 中面临的计算成本问题，同时提升压缩的保真性和转移性。Selection-p 通过在持续预训练中引入少量参数，为每个输入 token 生成保留或丢弃的概率，从而实现对不相关 token 的离散化压缩。实验结果显示，该方法在多个分类任务上达到最先进性能，实现高达10倍的压缩率，同时性能仅下降0.8%，并展现出优异的模型转移性和对长上下文 in-context learning 的性能维持能力。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "14 pages, 5 figures, 10 tables, EMNLP 2024 Findings",
      "pdf_url": "http://arxiv.org/pdf/2410.11786v2",
      "published_date": "2024-10-15 17:05:25 UTC",
      "updated_date": "2024-10-21 13:11:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:44:27.249892"
    },
    {
      "arxiv_id": "2410.11779v2",
      "title": "MLLM can see? Dynamic Correction Decoding for Hallucination Mitigation",
      "title_zh": "翻译失败",
      "authors": [
        "Chenxi Wang",
        "Xiang Chen",
        "Ningyu Zhang",
        "Bozhong Tian",
        "Haoming Xu",
        "Shumin Deng",
        "Huajun Chen"
      ],
      "abstract": "Multimodal Large Language Models (MLLMs) frequently exhibit hallucination\nphenomena, but the underlying reasons remain poorly understood. In this paper,\nwe present an empirical analysis and find that, although MLLMs incorrectly\ngenerate the objects in the final output, they are actually able to recognize\nvisual objects in the preceding layers. We speculate that this may be due to\nthe strong knowledge priors of the language model suppressing the visual\ninformation, leading to hallucinations. Motivated by this, we propose a novel\ndynamic correction decoding method for MLLMs DeCo, which adaptively selects the\nappropriate preceding layers and proportionally integrates knowledge into the\nfinal layer to adjust the output logits. Note that DeCo is model agnostic and\ncan be seamlessly incorporated with various classic decoding strategies and\napplied to different MLLMs. We evaluate DeCo on widely-used benchmarks,\ndemonstrating that it can reduce hallucination rates by a large margin compared\nto baselines, highlighting its potential to mitigate hallucinations. Code is\navailable at https://github.com/zjunlp/DeCo.",
      "tldr_zh": "这项研究分析了多模态大语言模型(MLLMs)中常见的幻觉(hallucination)现象，发现尽管前层能正确识别视觉对象，但语言模型的强知识先验可能抑制了视觉信息，导致最终输出错误。针对此问题，作者提出了一种动态修正解码方法DeCo(Dynamic Correction Decoding)，该方法自适应选择前层信息并比例整合到最终层调整输出logits，且模型无关，可与各种经典解码策略结合。实验结果显示，DeCo在常用基准上显著降低了幻觉率，证明了其在缓解MLLMs幻觉方面的潜力。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CV",
        "cs.LG",
        "cs.MM"
      ],
      "primary_category": "cs.CL",
      "comment": "ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2410.11779v2",
      "published_date": "2024-10-15 16:57:44 UTC",
      "updated_date": "2025-02-23 15:14:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:44:35.996914"
    },
    {
      "arxiv_id": "2410.11776v1",
      "title": "Encoding architecture algebra",
      "title_zh": "翻译失败",
      "authors": [
        "Stephane Bersier",
        "Xinyi Chen-Lin"
      ],
      "abstract": "Despite the wide variety of input types in machine learning, this diversity\nis often not fully reflected in their representations or model architectures,\nleading to inefficiencies throughout a model's lifecycle. This paper introduces\nan algebraic approach to constructing input-encoding architectures that\nproperly account for the data's structure, providing a step toward achieving\nmore typeful machine learning.",
      "tldr_zh": "本论文指出，尽管机器学习中的输入类型多样，但其在表示和模型架构中未得到充分体现，导致模型生命周期中的效率低下。作者引入了一种代数方法（algebraic approach），用于构建输入编码架构（input-encoding architectures），以更好地考虑数据的结构。该方法推动了更具类型化的机器学习（typeful machine learning），为提升模型性能提供了重要基础。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.PL",
        "cs.SE"
      ],
      "primary_category": "cs.LG",
      "comment": "25 pages, 6 figures. Keywords: typeful, algebraic data types,\n  tensors, structured data",
      "pdf_url": "http://arxiv.org/pdf/2410.11776v1",
      "published_date": "2024-10-15 16:56:34 UTC",
      "updated_date": "2024-10-15 16:56:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:44:57.540831"
    },
    {
      "arxiv_id": "2410.11773v7",
      "title": "Time-Series Foundation AI Model for Value-at-Risk Forecasting",
      "title_zh": "翻译失败",
      "authors": [
        "Anubha Goel",
        "Puneet Pasricha",
        "Juho Kanniainen"
      ],
      "abstract": "This study is the first to analyze the performance of a time-series\nfoundation AI model for Value-at-Risk (VaR), which essentially forecasts the\nleft-tail quantiles of returns. Foundation models, pre-trained on diverse\ndatasets, can be applied in a zero-shot setting with minimal data or further\nimproved through finetuning. We compare Google's TimesFM model to conventional\nparametric and non-parametric models, including GARCH and Generalized\nAutoregressive Score (GAS), using 19 years of daily returns from the SP 100\nindex and its constituents. Backtesting with over 8.5 years of out-of-sample\ndata shows that the fine-tuned foundation model consistently outperforms\ntraditional methods in actual-over-expected ratios. For the quantile score loss\nfunction, it performs comparably to the best econometric model, GAS. Overall,\nthe foundation model ranks as the best or among the top performers across the\n0.01, 0.025, 0.05, and 0.1 quantile forecasting. Fine-tuning significantly\nimproves accuracy, showing that zero-shot use is not optimal for VaR.",
      "tldr_zh": "这篇论文首次评估了时间序列基础AI模型在Value-at-Risk (VaR)预测中的性能，VaR本质上是回报的左尾分位数预测。研究者比较了Google的TimesFM模型与传统模型如GARCH和Generalized Autoregressive Score (GAS)，使用SP 100指数及其成分股的19年每日回报数据进行回测。结果显示，微调后的TimesFM在实际/预期比率和0.01、0.025、0.05、0.1分位数预测中，表现最佳或优于传统方法，而在分位数分数损失函数上与GAS相当。总体而言，论文强调微调能显著提升准确性，零样本应用并不理想。",
      "categories": [
        "q-fin.RM",
        "cs.AI"
      ],
      "primary_category": "q-fin.RM",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.11773v7",
      "published_date": "2024-10-15 16:53:44 UTC",
      "updated_date": "2025-05-12 14:24:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:45:00.622832"
    },
    {
      "arxiv_id": "2410.11769v2",
      "title": "Can Search-Based Testing with Pareto Optimization Effectively Cover Failure-Revealing Test Inputs?",
      "title_zh": "基于搜索的测试结合帕累托优化是否能有效覆盖揭示失败的测试输入？",
      "authors": [
        "Lev Sorokin",
        "Damir Safin",
        "Shiva Nejati"
      ],
      "abstract": "Search-based software testing (SBST) is a widely adopted technique for\ntesting complex systems with large input spaces, such as Deep Learning-enabled\n(DL-enabled) systems. Many SBST techniques focus on Pareto-based optimization,\nwhere multiple objectives are optimized in parallel to reveal failures.\nHowever, it is important to ensure that identified failures are spread\nthroughout the entire failure-inducing area of a search domain and not\nclustered in a sub-region. This ensures that identified failures are\nsemantically diverse and reveal a wide range of underlying causes. In this\npaper, we present a theoretical argument explaining why testing based on Pareto\noptimization is inadequate for covering failure-inducing areas within a search\ndomain. We support our argument with empirical results obtained by applying two\nwidely used types of Pareto-based optimization techniques, namely NSGA-II (an\nevolutionary algorithm) and OMOPSO (a swarm-based Pareto-optimization\nalgorithm), to two DL-enabled systems: an industrial Automated Valet Parking\n(AVP) system and a system for classifying handwritten digits. We measure the\ncoverage of failure-revealing test inputs in the input space using a metric\nthat we refer to as the Coverage Inverted Distance quality indicator. Our\nresults show that NSGA-II-based search and OMOPSO are not more effective than a\nna\\\"ive random search baseline in covering test inputs that reveal failures.\nThe replication package for this study is available in a GitHub repository.",
      "tldr_zh": "这篇论文探讨了基于Pareto优化的搜索软件测试(SBST)是否能有效覆盖失败诱发测试输入，特别是针对复杂系统如DL-enabled systems。研究通过理论论证和实证实验，使用NSGA-II（一种进化算法）和OMOPSO（一种群智能算法）测试了工业Automated Valet Parking (AVP)系统和手写数字分类系统。结果显示，这些Pareto-based优化技术在覆盖失败揭示测试输入方面不如简单的随机搜索有效，并使用Coverage Inverted Distance质量指标进行评估。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.SE",
      "comment": "Accepted for publication by Empirical Software Engineering Journal\n  (EMSE) (in October 2024)",
      "pdf_url": "http://arxiv.org/pdf/2410.11769v2",
      "published_date": "2024-10-15 16:44:40 UTC",
      "updated_date": "2024-10-16 08:30:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:45:11.899016"
    },
    {
      "arxiv_id": "2410.11766v2",
      "title": "DPD-NeuralEngine: A 22-nm 6.6-TOPS/W/mm$^2$ Recurrent Neural Network Accelerator for Wideband Power Amplifier Digital Pre-Distortion",
      "title_zh": "翻译失败",
      "authors": [
        "Ang Li",
        "Haolin Wu",
        "Yizhuo Wu",
        "Qinyu Chen",
        "Leo C. N. de Vreede",
        "Chang Gao"
      ],
      "abstract": "The increasing adoption of Deep Neural Network (DNN)-based Digital\nPre-distortion (DPD) in modern communication systems necessitates efficient\nhardware implementations. This paper presents DPD-NeuralEngine, an ultra-fast,\ntiny-area, and power-efficient DPD accelerator based on a Gated Recurrent Unit\n(GRU) neural network (NN). Leveraging a co-designed software and hardware\napproach, our 22 nm CMOS implementation operates at 2 GHz, capable of\nprocessing I/Q signals up to 250 MSps. Experimental results demonstrate a\nthroughput of 256.5 GOPS and power efficiency of 1.32 TOPS/W with DPD\nlinearization performance measured in Adjacent Channel Power Ratio (ACPR) of\n-45.3 dBc and Error Vector Magnitude (EVM) of -39.8 dB. To our knowledge, this\nwork represents the first AI-based DPD application-specific integrated circuit\n(ASIC) accelerator, achieving a power-area efficiency (PAE) of 6.6\nTOPS/W/mm$^2$.",
      "tldr_zh": "本论文提出 DPD-NeuralEngine，一种基于 Gated Recurrent Unit (GRU) 神经网络的加速器，用于现代通信系统中 DNN-based Digital Pre-distortion (DPD)，旨在实现高效的宽带功率放大器线性化。 该系统采用软件硬件协同设计，在 22 nm CMOS 工艺下运行于 2 GHz，可处理 I/Q 信号高达 250 MSps。 实验结果显示，DPD-NeuralEngine 实现了 256.5 GOPS 吞吐量、1.32 TOPS/W 功率效率，以及 ACPR -45.3 dBc 和 EVM -39.8 dB 的性能，是首个 AI-based DPD ASIC 加速器，PAE 达 6.6 TOPS/W/mm²。",
      "categories": [
        "cs.AR",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.AR",
      "comment": "This paper has been accepted to be presented at the 2025\n  International Symposium on Circuits and Systems (ISCAS)",
      "pdf_url": "http://arxiv.org/pdf/2410.11766v2",
      "published_date": "2024-10-15 16:39:50 UTC",
      "updated_date": "2025-02-10 18:16:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:45:25.358905"
    },
    {
      "arxiv_id": "2410.11761v3",
      "title": "SlideChat: A Large Vision-Language Assistant for Whole-Slide Pathology Image Understanding",
      "title_zh": "翻译失败",
      "authors": [
        "Ying Chen",
        "Guoan Wang",
        "Yuanfeng Ji",
        "Yanjun Li",
        "Jin Ye",
        "Tianbin Li",
        "Ming Hu",
        "Rongshan Yu",
        "Yu Qiao",
        "Junjun He"
      ],
      "abstract": "Despite the progress made by multimodal large language models (MLLMs) in\ncomputational pathology, they remain limited by a predominant focus on\npatch-level analysis, missing essential contextual information at the\nwhole-slide level. The lack of large-scale instruction datasets and the\ngigapixel scale of whole slide images (WSIs) pose significant developmental\nchallenges. In this paper, we present SlideChat, the first vision-language\nassistant capable of understanding gigapixel whole-slide images, exhibiting\nexcellent multimodal conversational capability and response complex instruction\nacross diverse pathology scenarios. To support its development, we created\nSlideInstruction, the largest instruction-following dataset for WSIs consisting\nof 4.2K WSI captions and 176K VQA pairs with multiple categories. Furthermore,\nwe propose SlideBench, a multimodal benchmark that incorporates captioning and\nVQA tasks to assess SlideChat's capabilities in varied clinical settings such\nas microscopy, diagnosis. Compared to both general and specialized MLLMs,\nSlideChat exhibits exceptional capabilities achieving state-of-the-art\nperformance on 18 of 22 tasks. For example, it achieved an overall accuracy of\n81.17% on SlideBench-VQA (TCGA), and 54.15% on SlideBench-VQA (BCNB). Our code,\ndata, and model is publicly accessible at\nhttps://uni-medical.github.io/SlideChat.github.io.",
      "tldr_zh": "该研究指出，现有的多模态大语言模型（MLLMs）在病理学中主要聚焦于补丁级分析，忽略了全滑片图像（WSIs）的整体上下文信息，并面临数据集和规模挑战。为此，论文提出 SlideChat，这是首个能够理解千兆像素 WSIs 的视觉语言助手，具有强大的多模态对话能力和处理复杂指令的功能。研究团队构建了 SlideInstruction 数据集（包含 4.2K WSI 标题和 176K VQA 对），并开发了 SlideBench 基准，用于评估模型在标题和 VQA 任务中的表现。实验结果显示，SlideChat 在 22 个任务中领先 18 个，与其他 MLLMs 相比，实现了最先进的性能，如在 SlideBench-VQA (TCGA) 上达到 81.17% 的准确率。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by CVPR2025",
      "pdf_url": "http://arxiv.org/pdf/2410.11761v3",
      "published_date": "2024-10-15 16:33:33 UTC",
      "updated_date": "2025-03-19 17:56:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:45:36.874959"
    },
    {
      "arxiv_id": "2410.11756v1",
      "title": "Evidence of Cognitive Deficits andDevelopmental Advances in Generative AI: A Clock Drawing Test Analysis",
      "title_zh": "翻译失败",
      "authors": [
        "Isaac R. Galatzer-Levy",
        "Jed McGiffin",
        "David Munday",
        "Xin Liu",
        "Danny Karmon",
        "Ilia Labzovsky",
        "Rivka Moroshko",
        "Amir Zait",
        "Daniel McDuff"
      ],
      "abstract": "Generative AI's rapid advancement sparks interest in its cognitive abilities,\nespecially given its capacity for tasks like language understanding and code\ngeneration. This study explores how several recent GenAI models perform on the\nClock Drawing Test (CDT), a neuropsychological assessment of visuospatial\nplanning and organization. While models create clock-like drawings, they\nstruggle with accurate time representation, showing deficits similar to\nmild-severe cognitive impairment (Wechsler, 2009). Errors include numerical\nsequencing issues, incorrect clock times, and irrelevant additions, despite\naccurate rendering of clock features. Only GPT 4 Turbo and Gemini Pro 1.5\nproduced the correct time, scoring like healthy individuals (4/4). A follow-up\nclock-reading test revealed only Sonnet 3.5 succeeded, suggesting drawing\ndeficits stem from difficulty with numerical concepts. These findings may\nreflect weaknesses in visual-spatial understanding, working memory, or\ncalculation, highlighting strengths in learned knowledge but weaknesses in\nreasoning. Comparing human and machine performance is crucial for understanding\nAI's cognitive capabilities and guiding development toward human-like cognitive\nfunctions.",
      "tldr_zh": "这篇论文通过 Clock Drawing Test (CDT) 评估生成式 AI 的认知能力，揭示了其在视空间规划和组织方面的缺陷和进步。研究发现，大多数 AI 模型虽能准确渲染钟表特征，但常出现数字顺序错误、不正确的时间表示或无关添加，类似于轻度到重度认知障碍。仅有 GPT-4 Turbo 和 Gemini Pro 1.5 成功绘制正确时间，得分与健康个体相当（4/4），而后续的钟表阅读测试中，只有 Sonnet 3.5 表现出色，表明这些问题可能源于 AI 在数字概念、工作记忆或计算方面的弱点。这些发现突出了 AI 在学习知识上的优势，同时强调了比较人类和机器认知表现的重要性，以指导 AI 向更像人类的认知功能发展。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.11756v1",
      "published_date": "2024-10-15 16:27:22 UTC",
      "updated_date": "2024-10-15 16:27:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:45:48.943000"
    },
    {
      "arxiv_id": "2410.19789v1",
      "title": "Xeno-learning: knowledge transfer across species in deep learning-based spectral image analysis",
      "title_zh": "翻译失败",
      "authors": [
        "Jan Sellner",
        "Alexander Studier-Fischer",
        "Ahmad Bin Qasim",
        "Silvia Seidlitz",
        "Nicholas Schreck",
        "Minu Tizabi",
        "Manuel Wiesenfarth",
        "Annette Kopp-Schneider",
        "Samuel Knödler",
        "Caelan Max Haney",
        "Gabriel Salg",
        "Berkin Özdemir",
        "Maximilian Dietrich",
        "Maurice Stephan Michel",
        "Felix Nickel",
        "Karl-Friedrich Kowalewski",
        "Lena Maier-Hein"
      ],
      "abstract": "Novel optical imaging techniques, such as hyperspectral imaging (HSI)\ncombined with machine learning-based (ML) analysis, have the potential to\nrevolutionize clinical surgical imaging. However, these novel modalities face a\nshortage of large-scale, representative clinical data for training ML\nalgorithms, while preclinical animal data is abundantly available through\nstandardized experiments and allows for controlled induction of pathological\ntissue states, which is not ethically possible in patients. To leverage this\nsituation, we propose a novel concept called \"xeno-learning\", a cross-species\nknowledge transfer paradigm inspired by xeno-transplantation, where organs from\na donor species are transplanted into a recipient species. Using a total of\n11,268 HSI images from humans as well as porcine and rat models, we show that\nalthough spectral signatures of organs differ across species, shared\npathophysiological mechanisms manifest as comparable relative spectral changes\nacross species. Such changes learnt in one species can thus be transferred to a\nnew species via a novel \"physiology-based data augmentation\" method, enabling\nthe large-scale secondary use of preclinical animal data for humans. The\nresulting ethical, monetary, and performance benefits of the proposed knowledge\ntransfer paradigm promise a high impact of the methodology on future\ndevelopments in the field.",
      "tldr_zh": "本研究提出“xeno-learning”概念，一种灵感来源于异种移植的跨物种知识转移范式，用于基于深度学习的谱图像分析，以解决临床手术成像中机器学习（ML）算法训练数据稀缺的问题。利用11,268张来自人类、猪和鼠的超光谱成像（HSI）图像，研究发现尽管不同物种的器官光谱特征存在差异，但共享的病理生理机制导致可比的相对光谱变化。作者引入“physiology-based data augmentation”方法，通过从动物模型中学习这些变化并转移到人类数据，实现大规模利用预临床动物数据。实验结果展示了该方法的伦理、经济和性能优势，有望推动该领域的未来发展。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Jan Sellner and Alexander Studier-Fischer contributed equally to this\n  work",
      "pdf_url": "http://arxiv.org/pdf/2410.19789v1",
      "published_date": "2024-10-15 16:25:16 UTC",
      "updated_date": "2024-10-15 16:25:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:46:00.526971"
    },
    {
      "arxiv_id": "2410.22355v1",
      "title": "Learning Goal-oriented Bimanual Dough Rolling Using Dynamic Heterogeneous Graph Based on Human Demonstration",
      "title_zh": "翻译失败",
      "authors": [
        "Junjia Liu",
        "Chenzui Li",
        "Shixiong Wang",
        "Zhipeng Dong",
        "Sylvain Calinon",
        "Miao Li",
        "Fei Chen"
      ],
      "abstract": "Soft object manipulation poses significant challenges for robots, requiring\neffective techniques for state representation and manipulation policy learning.\nState representation involves capturing the dynamic changes in the environment,\nwhile manipulation policy learning focuses on establishing the relationship\nbetween robot actions and state transformations to achieve specific goals. To\naddress these challenges, this research paper introduces a novel approach: a\ndynamic heterogeneous graph-based model for learning goal-oriented soft object\nmanipulation policies. The proposed model utilizes graphs as a unified\nrepresentation for both states and policy learning. By leveraging the dynamic\ngraph, we can extract crucial information regarding object dynamics and\nmanipulation policies. Furthermore, the model facilitates the integration of\ndemonstrations, enabling guided policy learning. To evaluate the efficacy of\nour approach, we designed a dough rolling task and conducted experiments using\nboth a differentiable simulator and a real-world humanoid robot. Additionally,\nseveral ablation studies were performed to analyze the effect of our method,\ndemonstrating its superiority in achieving human-like behavior.",
      "tldr_zh": "这篇论文针对机器人软物体操作的挑战，提出了一种基于动态异构图的模型，用于学习目标导向的双臂面团滚动策略。该模型使用动态异构图作为状态和策略学习的统一表示，提取物体动态信息并整合人类演示来指导策略优化。在面团滚动任务的实验中，该方法在可微模拟器和真实机器人上表现出优越性，能够实现类似人类的行为，并通过消融研究证明其有效性。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "7 pages, 5 figures Accepted by IEEE ROBIO 2024 conference",
      "pdf_url": "http://arxiv.org/pdf/2410.22355v1",
      "published_date": "2024-10-15 16:12:00 UTC",
      "updated_date": "2024-10-15 16:12:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:46:21.752860"
    },
    {
      "arxiv_id": "2410.11730v1",
      "title": "Patch-Based Diffusion Models Beat Whole-Image Models for Mismatched Distribution Inverse Problems",
      "title_zh": "基于补丁的扩散模型在分布不匹配逆问题中胜过整幅图像模型",
      "authors": [
        "Jason Hu",
        "Bowen Song",
        "Jeffrey A. Fessler",
        "Liyue Shen"
      ],
      "abstract": "Diffusion models have achieved excellent success in solving inverse problems\ndue to their ability to learn strong image priors, but existing approaches\nrequire a large training dataset of images that should come from the same\ndistribution as the test dataset. When the training and test distributions are\nmismatched, artifacts and hallucinations can occur in reconstructed images due\nto the incorrect priors. In this work, we systematically study out of\ndistribution (OOD) problems where a known training distribution is first\nprovided. We first study the setting where only a single measurement obtained\nfrom the unknown test distribution is available. Next we study the setting\nwhere a very small sample of data belonging to the test distribution is\navailable, and our goal is still to reconstruct an image from a measurement\nthat came from the test distribution. In both settings, we use a patch-based\ndiffusion prior that learns the image distribution solely from patches.\nFurthermore, in the first setting, we include a self-supervised loss that helps\nthe network output maintain consistency with the measurement. Extensive\nexperiments show that in both settings, the patch-based method can obtain high\nquality image reconstructions that can outperform whole-image models and can\ncompete with methods that have access to large in-distribution training\ndatasets. Furthermore, we show how whole-image models are prone to memorization\nand overfitting, leading to artifacts in the reconstructions, while a\npatch-based model can resolve these issues.",
      "tldr_zh": "本文研究了扩散模型在分布不匹配的逆问题中存在的伪像和幻觉问题，提出了一种基于 patch 的扩散模型先验，仅从图像 patches 学习分布，以应对训练数据与测试分布不匹配（OOD）的情况。方法包括在单一测量设置下加入自监督损失，确保输出与测量一致，以及在少量测试数据设置下提升重建质量。实验结果表明，该 patch-based 方法在图像重建上优于 whole-image 模型，能避免记忆和过拟合导致的 artifacts，并与使用大量同分布训练数据集的方法相媲美。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "eess.IV"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.11730v1",
      "published_date": "2024-10-15 16:02:08 UTC",
      "updated_date": "2024-10-15 16:02:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:46:24.212585"
    },
    {
      "arxiv_id": "2410.11723v1",
      "title": "Generalizable Spacecraft Trajectory Generation via Multimodal Learning with Transformers",
      "title_zh": "翻译失败",
      "authors": [
        "Davide Celestini",
        "Amirhossein Afsharrad",
        "Daniele Gammelli",
        "Tommaso Guffanti",
        "Gioele Zardini",
        "Sanjay Lall",
        "Elisa Capello",
        "Simone D'Amico",
        "Marco Pavone"
      ],
      "abstract": "Effective trajectory generation is essential for reliable on-board spacecraft\nautonomy. Among other approaches, learning-based warm-starting represents an\nappealing paradigm for solving the trajectory generation problem, effectively\ncombining the benefits of optimization- and data-driven methods. Current\napproaches for learning-based trajectory generation often focus on fixed,\nsingle-scenario environments, where key scene characteristics, such as obstacle\npositions or final-time requirements, remain constant across problem instances.\nHowever, practical trajectory generation requires the scenario to be frequently\nreconfigured, making the single-scenario approach a potentially impractical\nsolution. To address this challenge, we present a novel trajectory generation\nframework that generalizes across diverse problem configurations, by leveraging\nhigh-capacity transformer neural networks capable of learning from multimodal\ndata sources. Specifically, our approach integrates transformer-based neural\nnetwork models into the trajectory optimization process, encoding both\nscene-level information (e.g., obstacle locations, initial and goal states) and\ntrajectory-level constraints (e.g., time bounds, fuel consumption targets) via\nmultimodal representations. The transformer network then generates near-optimal\ninitial guesses for non-convex optimization problems, significantly enhancing\nconvergence speed and performance. The framework is validated through extensive\nsimulations and real-world experiments on a free-flyer platform, achieving up\nto 30% cost improvement and 80% reduction in infeasible cases with respect to\ntraditional approaches, and demonstrating robust generalization across diverse\nscenario variations.",
      "tldr_zh": "这篇论文提出了一种基于 Transformers 的多模态学习框架，用于航天器轨迹生成，实现对多样化场景（如障碍位置和约束变化）的泛化。框架将 Transformer 神经网络整合到轨迹优化过程中，通过编码场景级信息（如障碍位置、初始和目标状态）和轨迹级约束（如时间限制、燃料消耗目标）来生成近优化的初始猜测，从而提升非凸优化问题的收敛速度和性能。实验结果显示，在模拟和真实自由飞行器平台上，该方法相较传统方法降低了高达 30% 的成本，并减少了 80% 的不可行情况，展示了强大的泛化能力。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "math.OC"
      ],
      "primary_category": "cs.RO",
      "comment": "8 pages, 6 figures, submitted to 2025 American Control Conference\n  (ACC)",
      "pdf_url": "http://arxiv.org/pdf/2410.11723v1",
      "published_date": "2024-10-15 15:55:42 UTC",
      "updated_date": "2024-10-15 15:55:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:46:47.983055"
    },
    {
      "arxiv_id": "2410.11722v2",
      "title": "RClicks: Realistic Click Simulation for Benchmarking Interactive Segmentation",
      "title_zh": "RClicks：用于交互式分割基准测试的真实点击模拟",
      "authors": [
        "Anton Antonov",
        "Andrey Moskalenko",
        "Denis Shepelev",
        "Alexander Krapukhin",
        "Konstantin Soshin",
        "Anton Konushin",
        "Vlad Shakhuro"
      ],
      "abstract": "The emergence of Segment Anything (SAM) sparked research interest in the\nfield of interactive segmentation, especially in the context of image editing\ntasks and speeding up data annotation. Unlike common semantic segmentation,\ninteractive segmentation methods allow users to directly influence their output\nthrough prompts (e.g. clicks). However, click patterns in real-world\ninteractive segmentation scenarios remain largely unexplored. Most methods rely\non the assumption that users would click in the center of the largest erroneous\narea. Nevertheless, recent studies show that this is not always the case. Thus,\nmethods may have poor performance in real-world deployment despite high metrics\nin a baseline benchmark. To accurately simulate real-user clicks, we conducted\na large crowdsourcing study of click patterns in an interactive segmentation\nscenario and collected 475K real-user clicks. Drawing on ideas from saliency\ntasks, we develop a clickability model that enables sampling clicks, which\nclosely resemble actual user inputs. Using our model and dataset, we propose\nRClicks benchmark for a comprehensive comparison of existing interactive\nsegmentation methods on realistic clicks. Specifically, we evaluate not only\nthe average quality of methods, but also the robustness w.r.t. click patterns.\nAccording to our benchmark, in real-world usage interactive segmentation models\nmay perform worse than it has been reported in the baseline benchmark, and most\nof the methods are not robust. We believe that RClicks is a significant step\ntowards creating interactive segmentation methods that provide the best user\nexperience in real-world cases.",
      "tldr_zh": "该研究针对交互式分割（interactive segmentation）方法存在的点击模式假设问题（如用户点击错误区域中心），通过大规模众包研究收集了47.5万真实用户点击数据。作者开发了clickability模型，用于模拟真实用户输入，从而更准确地基准测试分割模型。RClicks基准的提出，不仅评估了方法的平均质量，还测试了其对点击模式的鲁棒性，结果显示现有模型在真实场景下性能可能低于基准报告，且大多数方法不鲁棒。这一工作有助于提升交互式分割方法的实际用户体验。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.HC",
        "I.4.6"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2410.11722v2",
      "published_date": "2024-10-15 15:55:00 UTC",
      "updated_date": "2024-10-24 15:48:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:46:51.190932"
    },
    {
      "arxiv_id": "2410.11701v2",
      "title": "Magnifier Prompt: Tackling Multimodal Hallucination via Extremely Simple Instructions",
      "title_zh": "翻译失败",
      "authors": [
        "Yuhan Fu",
        "Ruobing Xie",
        "Jiazhen Liu",
        "Bangxiang Lan",
        "Xingwu Sun",
        "Zhanhui Kang",
        "Xirong Li"
      ],
      "abstract": "Hallucinations in multimodal large language models (MLLMs) hinder their\npractical applications. To address this, we propose a Magnifier Prompt\n(MagPrompt), a simple yet effective method to tackle hallucinations in MLLMs\nvia extremely simple instructions. MagPrompt is based on the following two key\nprinciples, which guide the design of various effective prompts, demonstrating\nrobustness: (1) MLLMs should focus more on the image. (2) When there are\nconflicts between the image and the model's inner knowledge, MLLMs should\nprioritize the image. MagPrompt is training-free and can be applied to\nopen-source and closed-source models, such as GPT-4o and Gemini-pro. It\nperforms well across many datasets and its effectiveness is comparable or even\nbetter than more complex methods like VCD. Furthermore, our prompt design\nprinciples and experimental analyses provide valuable insights into multimodal\nhallucination.",
      "tldr_zh": "论文提出了一种名为 Magnifier Prompt (MagPrompt) 的简单方法，用于解决多模态大型语言模型 (MLLMs) 中的幻觉 (hallucination) 问题，通过极简指令提升模型可靠性。MagPrompt 基于两个关键原则：(1) MLLMs 应更多关注图像；(2) 当图像与模型内部知识冲突时，优先图像。该方法无需训练，可应用于开源和闭源模型，如 GPT-4o 和 Gemini-pro，并在多个数据集上表现优于或相当复杂的 VCD 方法。论文还通过实验分析提供了关于多模态幻觉的宝贵见解。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CV",
        "cs.MM"
      ],
      "primary_category": "cs.CL",
      "comment": "The proposed method does not work for up-to-date MLLMs.",
      "pdf_url": "http://arxiv.org/pdf/2410.11701v2",
      "published_date": "2024-10-15 15:39:37 UTC",
      "updated_date": "2025-02-21 09:48:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:47:11.371949"
    },
    {
      "arxiv_id": "2410.13899v1",
      "title": "Security of and by Generative AI platforms",
      "title_zh": "翻译失败",
      "authors": [
        "Hari Hayagreevan",
        "Souvik Khamaru"
      ],
      "abstract": "This whitepaper highlights the dual importance of securing generative AI\n(genAI) platforms and leveraging genAI for cybersecurity. As genAI technologies\nproliferate, their misuse poses significant risks, including data breaches,\nmodel tampering, and malicious content generation. Securing these platforms is\ncritical to protect sensitive data, ensure model integrity, and prevent\nadversarial attacks. Simultaneously, genAI presents opportunities for enhancing\nsecurity by automating threat detection, vulnerability analysis, and incident\nresponse. The whitepaper explores strategies for robust security frameworks\naround genAI systems, while also showcasing how genAI can empower organizations\nto anticipate, detect, and mitigate sophisticated cyber threats.",
      "tldr_zh": "这篇白皮书强调了保护生成式 AI (genAI) 平台的安全性和利用 genAI 提升网络安全 (cybersecurity) 的双重重要性。随着 genAI 技术的普及，其滥用可能导致数据泄露、模型篡改和恶意内容生成，因此需要构建稳健的安全框架来保护敏感数据、确保模型完整性并防范攻击。另一方面，genAI 可以自动化威胁检测、漏洞分析和事件响应，帮助组织预测、检测并缓解高级网络威胁，从而增强整体安全能力。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.13899v1",
      "published_date": "2024-10-15 15:27:05 UTC",
      "updated_date": "2024-10-15 15:27:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:47:32.239472"
    },
    {
      "arxiv_id": "2410.11689v2",
      "title": "BlendRL: A Framework for Merging Symbolic and Neural Policy Learning",
      "title_zh": "BlendRL：用于合并符号和神经策略学习的框架",
      "authors": [
        "Hikaru Shindo",
        "Quentin Delfosse",
        "Devendra Singh Dhami",
        "Kristian Kersting"
      ],
      "abstract": "Humans can leverage both symbolic reasoning and intuitive reactions. In\ncontrast, reinforcement learning policies are typically encoded in either\nopaque systems like neural networks or symbolic systems that rely on predefined\nsymbols and rules. This disjointed approach severely limits the agents'\ncapabilities, as they often lack either the flexible low-level reaction\ncharacteristic of neural agents or the interpretable reasoning of symbolic\nagents. To overcome this challenge, we introduce BlendRL, a neuro-symbolic RL\nframework that harmoniously integrates both paradigms within RL agents that use\nmixtures of both logic and neural policies. We empirically demonstrate that\nBlendRL agents outperform both neural and symbolic baselines in standard Atari\nenvironments, and showcase their robustness to environmental changes.\nAdditionally, we analyze the interaction between neural and symbolic policies,\nillustrating how their hybrid use helps agents overcome each other's\nlimitations.",
      "tldr_zh": "该论文提出 BlendRL 框架，将符号推理和神经策略整合到强化学习（RL）代理中，以解决传统方法在灵活反应和可解释性方面的局限。BlendRL 通过混合逻辑策略和神经策略，创建出更全面的代理，并在 Atari 环境中实验中优于纯神经或纯符号基线，同时展示了对环境变化的更高鲁棒性。作者进一步分析了神经和符号策略的交互，说明这种混合如何帮助代理克服彼此的缺点。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "ICLR 2025 (Spotlight)",
      "pdf_url": "http://arxiv.org/pdf/2410.11689v2",
      "published_date": "2024-10-15 15:24:20 UTC",
      "updated_date": "2025-04-21 16:49:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:47:34.068859"
    },
    {
      "arxiv_id": "2410.11687v2",
      "title": "State-space models can learn in-context by gradient descent",
      "title_zh": "状态空间模型可以通过梯度下降进行上下文学习",
      "authors": [
        "Neeraj Mohan Sushma",
        "Yudou Tian",
        "Harshvardhan Mestha",
        "Nicolo Colombo",
        "David Kappel",
        "Anand Subramoney"
      ],
      "abstract": "Deep state-space models (Deep SSMs) are becoming popular as effective\napproaches to model sequence data. They have also been shown to be capable of\nin-context learning, much like transformers. However, a complete picture of how\nSSMs might be able to do in-context learning has been missing. In this study,\nwe provide a direct and explicit construction to show that state-space models\ncan perform gradient-based learning and use it for in-context learning in much\nthe same way as transformers. Specifically, we prove that a single structured\nstate-space model layer, augmented with multiplicative input and output gating,\ncan reproduce the outputs of an implicit linear model with least squares loss\nafter one step of gradient descent. We then show a straightforward extension to\nmulti-step linear and non-linear regression tasks. We validate our construction\nby training randomly initialized augmented SSMs on linear and non-linear\nregression tasks. The empirically obtained parameters through optimization\nmatch the ones predicted analytically by the theoretical construction. Overall,\nwe elucidate the role of input- and output-gating in recurrent architectures as\nthe key inductive biases for enabling the expressive power typical of\nfoundation models. We also provide novel insights into the relationship between\nstate-space models and linear self-attention, and their ability to learn\nin-context.",
      "tldr_zh": "本文证明State-space models (SSMs) 可以通过gradient descent进行in-context learning，与Transformer类似。作者构建了一个带有乘法输入和输出门控的结构化SSM层，展示了其能在梯度下降一步后复制隐式线性模型的输出，并扩展到多步线性及非线性回归任务。通过实验验证，随机初始化的增强SSMs在回归任务上优化参数与理论预测相符，揭示输入和输出门控作为关键归纳偏差，提升了SSMs的表达能力，并阐明了其与线性自注意力的关系。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NE"
      ],
      "primary_category": "cs.LG",
      "comment": "20 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.11687v2",
      "published_date": "2024-10-15 15:22:38 UTC",
      "updated_date": "2025-02-18 18:55:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:47:47.506810"
    },
    {
      "arxiv_id": "2410.11684v1",
      "title": "Are UFOs Driving Innovation? The Illusion of Causality in Large Language Models",
      "title_zh": "UFOs 是否在推动创新？大语言模型中的因果错觉",
      "authors": [
        "María Victoria Carro",
        "Francisca Gauna Selasco",
        "Denise Alejandra Mester",
        "Mario Alejandro Leiva"
      ],
      "abstract": "Illusions of causality occur when people develop the belief that there is a\ncausal connection between two variables with no supporting evidence. This\ncognitive bias has been proposed to underlie many societal problems including\nsocial prejudice, stereotype formation, misinformation and superstitious\nthinking. In this research we investigate whether large language models develop\nthe illusion of causality in real-world settings. We evaluated and compared\nnews headlines generated by GPT-4o-Mini, Claude-3.5-Sonnet, and Gemini-1.5-Pro\nto determine whether the models incorrectly framed correlations as causal\nrelationships. In order to also measure sycophantic behavior, which occurs when\na model aligns with a user's beliefs in order to look favorable even if it is\nnot objectively correct, we additionally incorporated the bias into the\nprompts, observing if this manipulation increases the likelihood of the models\nexhibiting the illusion of causality. We found that Claude-3.5-Sonnet is the\nmodel that presents the lowest degree of causal illusion aligned with\nexperiments on Correlation-to-Causation Exaggeration in human-written press\nreleases. On the other hand, our findings suggest that while mimicry sycophancy\nincreases the likelihood of causal illusions in these models, especially in\nGPT-4o-Mini, Claude-3.5-Sonnet remains the most robust against this cognitive\nbias.",
      "tldr_zh": "这篇论文探讨大型语言模型（Large Language Models）是否会产生illusions of causality，即错误地将相关性视为因果关系，从而可能加剧社会问题如偏见和迷信。研究者评估了GPT-4o-Mini、Claude-3.5-Sonnet和Gemini-1.5-Pro在生成新闻标题时的表现，并通过在提示中加入偏见来测试sycophantic behavior是否会增加这种认知偏差。结果表明，Claude-3.5-Sonnet显示出最低的因果错觉水平，与人类Correlation-to-Causation Exaggeration实验一致，而GPT-4o-Mini则更易受sycophancy影响。该研究为理解和缓解LLMs中的认知偏差提供了重要洞见。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.11684v1",
      "published_date": "2024-10-15 15:20:49 UTC",
      "updated_date": "2024-10-15 15:20:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:48:00.431724"
    },
    {
      "arxiv_id": "2410.11682v2",
      "title": "SurFhead: Affine Rig Blending for Geometrically Accurate 2D Gaussian Surfel Head Avatars",
      "title_zh": "翻译失败",
      "authors": [
        "Jaeseong Lee",
        "Taewoong Kang",
        "Marcel C. Bühler",
        "Min-Jung Kim",
        "Sungwon Hwang",
        "Junha Hyung",
        "Hyojin Jang",
        "Jaegul Choo"
      ],
      "abstract": "Recent advancements in head avatar rendering using Gaussian primitives have\nachieved significantly high-fidelity results. Although precise head geometry is\ncrucial for applications like mesh reconstruction and relighting, current\nmethods struggle to capture intricate geometric details and render unseen poses\ndue to their reliance on similarity transformations, which cannot handle\nstretch and shear transforms essential for detailed deformations of geometry.\nTo address this, we propose SurFhead, a novel method that reconstructs riggable\nhead geometry from RGB videos using 2D Gaussian surfels, which offer\nwell-defined geometric properties, such as precise depth from fixed ray\nintersections and normals derived from their surface orientation, making them\nadvantageous over 3D counterparts. SurFhead ensures high-fidelity rendering of\nboth normals and images, even in extreme poses, by leveraging classical\nmesh-based deformation transfer and affine transformation interpolation.\nSurFhead introduces precise geometric deformation and blends surfels through\npolar decomposition of transformations, including those affecting normals. Our\nkey contribution lies in bridging classical graphics techniques, such as\nmesh-based deformation, with modern Gaussian primitives, achieving\nstate-of-the-art geometry reconstruction and rendering quality. Unlike previous\navatar rendering approaches, SurFhead enables efficient reconstruction driven\nby Gaussian primitives while preserving high-fidelity geometry.",
      "tldr_zh": "该研究提出SurFhead，一种创新方法，用于从RGB视频重建几何精确的头部头像，采用2D Gaussian surfels作为基元，以解决现有基于相似性变换的渲染方法在捕捉复杂几何细节和处理拉伸、剪切变形方面的不足。SurFhead通过结合经典网格变形传输和仿射变换插值，实现对surfels的精确变形和混合，包括通过变换的极分解来处理法线，确保在极端姿势下高保真渲染图像和法线。相比以往方法，该框架桥接了传统图形技术和现代Gaussian primitives，实现了最先进的几何重建和渲染质量，同时保持高效重建过程。",
      "categories": [
        "cs.GR",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.GR",
      "comment": "ICLR 2025, Project page with videos:\n  https://summertight.github.io/SurFhead/",
      "pdf_url": "http://arxiv.org/pdf/2410.11682v2",
      "published_date": "2024-10-15 15:19:58 UTC",
      "updated_date": "2025-04-18 04:11:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:48:09.787852"
    },
    {
      "arxiv_id": "2410.11677v2",
      "title": "Understanding Likelihood Over-optimisation in Direct Alignment Algorithms",
      "title_zh": "直接对齐算法中似然过优化的理解",
      "authors": [
        "Zhengyan Shi",
        "Sander Land",
        "Acyr Locatelli",
        "Matthieu Geist",
        "Max Bartolo"
      ],
      "abstract": "Direct Alignment Algorithms (DAAs), such as Direct Preference Optimisation\n(DPO) and Identity Preference Optimisation (IPO), have emerged as alternatives\nto online Reinforcement Learning from Human Feedback (RLHF) algorithms such as\nProximal Policy Optimisation (PPO) for aligning language models to human\npreferences, without the need for explicit reward modelling. These methods\ngenerally aim to increase the likelihood of generating better (preferred)\ncompletions while discouraging worse (non-preferred) ones, while staying close\nto the original model's behaviour. In this work, we explore the relationship\nbetween completion likelihood and model performance in state-of-the-art DAAs,\nand identify a critical issue of likelihood over-optimisation. Contrary to\nexpectations, we find that higher likelihood of better completions and larger\nmargins between better and worse completion likelihoods do not necessarily lead\nto better performance, and may even degrade it. Our analysis reveals that while\nhigher likelihood correlates with better memorisation of factual knowledge\npatterns, a slightly lower completion likelihood tends to improve output\ndiversity, thus leading to better generalisation to unseen scenarios. Moreover,\nwe identify two key indicators that signal when over-optimised output diversity\nbegins to harm performance: Decreasing Entropy over Top-k Tokens and\nDiminishing Top-k Probability Mass. Our experimental results validate that\nthese indicators are reliable signs of declining performance under different\nregularisations, helping prevent over-optimisation and improve alignment with\nhuman preferences.",
      "tldr_zh": "本研究探讨了Direct Alignment Algorithms (DAAs)，如Direct Preference Optimisation (DPO)和Identity Preference Optimisation (IPO)，在对齐语言模型与人类偏好时存在的可能性过优化问题，这些算法旨在提升更好完成度的可能性，同时保持模型原有行为。研究发现，增加完成度可能性并不总是改善性能，反而可能导致输出多样性降低和泛化能力下降，因为过优化会强化事实知识记忆但牺牲新场景适应性。论文识别了两个关键指标——Top-k Tokens的熵降低和Top-k概率质量减少——作为性能下降的信号，并通过实验验证了这些指标在不同正则化下的可靠性，有助于防止过优化并提升模型与人类偏好的对齐。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Preprint Version",
      "pdf_url": "http://arxiv.org/pdf/2410.11677v2",
      "published_date": "2024-10-15 15:14:22 UTC",
      "updated_date": "2024-10-18 09:41:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:48:25.311436"
    },
    {
      "arxiv_id": "2410.11672v1",
      "title": "Leaving the barn door open for Clever Hans: Simple features predict LLM benchmark answers",
      "title_zh": "翻译失败",
      "authors": [
        "Lorenzo Pacchiardi",
        "Marko Tesic",
        "Lucy G. Cheke",
        "José Hernández-Orallo"
      ],
      "abstract": "The integrity of AI benchmarks is fundamental to accurately assess the\ncapabilities of AI systems. The internal validity of these benchmarks - i.e.,\nmaking sure they are free from confounding factors - is crucial for ensuring\nthat they are measuring what they are designed to measure. In this paper, we\nexplore a key issue related to internal validity: the possibility that AI\nsystems can solve benchmarks in unintended ways, bypassing the capability being\ntested. This phenomenon, widely known in human and animal experiments, is often\nreferred to as the 'Clever Hans' effect, where tasks are solved using spurious\ncues, often involving much simpler processes than those putatively assessed.\nPrevious research suggests that language models can exhibit this behaviour as\nwell. In several older Natural Language Processing (NLP) benchmarks, individual\n$n$-grams like \"not\" have been found to be highly predictive of the correct\nlabels, and supervised NLP models have been shown to exploit these patterns. In\nthis work, we investigate the extent to which simple $n$-grams extracted from\nbenchmark instances can be combined to predict labels in modern multiple-choice\nbenchmarks designed for LLMs, and whether LLMs might be using such $n$-gram\npatterns to solve these benchmarks. We show how simple classifiers trained on\nthese $n$-grams can achieve high scores on several benchmarks, despite lacking\nthe capabilities being tested. Additionally, we provide evidence that modern\nLLMs might be using these superficial patterns to solve benchmarks. This\nsuggests that the internal validity of these benchmarks may be compromised and\ncaution should be exercised when interpreting LLM performance results on them.",
      "tldr_zh": "本研究探讨了 AI 基准测试的内部有效性（internal validity），揭示了语言模型（LLMs）可能通过“Clever Hans”效应利用简单特征（如 n-grams）来解决任务，而非真正评估的能力。作者训练了基于 n-grams 的简单分类器，并在多个现代多选基准测试中取得了高分，尽管这些分类器缺乏被测试的复杂能力。实验结果提供了证据，表明 LLMs 可能依赖这些表面模式，导致基准测试的可靠性受损，并建议在解释 LLM 性能时需谨慎。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.11672v1",
      "published_date": "2024-10-15 15:05:41 UTC",
      "updated_date": "2024-10-15 15:05:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:48:44.970783"
    },
    {
      "arxiv_id": "2410.22353v3",
      "title": "RuleRAG: Rule-Guided Retrieval-Augmented Generation with Language Models for Question Answering",
      "title_zh": "翻译失败",
      "authors": [
        "Zhongwu Chen",
        "Chengjin Xu",
        "Dingmin Wang",
        "Zhen Huang",
        "Yong Dou",
        "Xuhui Jiang",
        "Jian Guo"
      ],
      "abstract": "Retrieval-augmented generation (RAG) has shown promising potential in\nknowledge intensive question answering (QA). However, existing approaches only\nconsider the query itself, neither specifying the retrieval preferences for the\nretrievers nor informing the generators of how to refer to the retrieved\ndocuments for the answers, which poses a significant challenge to the QA\nperformance. To address these issues, we propose Rule-guided\nRetrieval-Augmented Generation with LMs, which explicitly introduces rules for\nin-context learning (RuleRAG-ICL) to guide retrievers to recall related\ndocuments in the directions of rules and uniformly guide generators to reason\nattributed by the same rules. Moreover, most existing RAG datasets were\nconstructed without considering rules and Knowledge Graphs (KGs) are recognized\nas providing high-quality rules. Therefore, we construct five rule-aware RAG\nbenchmarks for QA, RuleQA, based on KGs to stress the significance of retrieval\nand reasoning with rules. Experiments on RuleQA demonstrate RuleRAG-ICL\nimproves the retrieval quality of +89.2% in Recall@10 and answer accuracy of\n+103.1% in Exact Match, and RuleRAG-FT yields more enhancement. In addition,\nexperiments on four existing RAG datasets show RuleRAG is also effective by\noffering rules in RuleQA to them, further proving the generalization of rule\nguidance in RuleRAG.",
      "tldr_zh": "这篇论文针对现有Retrieval-Augmented Generation (RAG) 在知识密集型问答 (QA) 中的局限性，提出了RuleRAG 方法，通过引入规则指导来优化检索和生成过程。RuleRAG-ICL 利用 in-context learning 指导检索器根据规则回忆相关文档，并统一指导生成器基于这些规则进行推理，同时构建了基于Knowledge Graphs (KGs) 的五个规则感知基准数据集 RuleQA。实验结果显示，RuleRAG-ICL 在 RuleQA 上提升了 Recall@10 89.2% 和 Exact Match 准确率 103.1%，而 RuleRAG-FT 进一步改进；在其他四个现有 RAG 数据集上，规则指导也证明了其泛化有效性。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.22353v3",
      "published_date": "2024-10-15 14:51:45 UTC",
      "updated_date": "2025-02-16 11:50:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:48:47.651170"
    },
    {
      "arxiv_id": "2410.11665v1",
      "title": "VisualRWKV-HD and UHD: Advancing High-Resolution Processing for Visual Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Zihang Li",
        "Haowen Hou"
      ],
      "abstract": "Accurately understanding complex visual information is crucial for visual\nlanguage models (VLMs). Enhancing image resolution can improve visual\nperception capabilities, not only reducing hallucinations but also boosting\nperformance in tasks that demand high resolution, such as text-rich or document\nanalysis. In this paper, we present VisualRWKV-HD and VisualRWKV-UHD, two\nadvancements in the VisualRWKV model family, specifically designed to process\nhigh-resolution visual inputs. For VisualRWKV-HD, we developed a lossless\ndownsampling method to effectively integrate a high-resolution vision encoder\nwith low-resolution encoders, without extending the input sequence length. For\nthe VisualRWKV-UHD model, we enhanced image representation by dividing the\nimage into four segments, which are then recombined with the original image.\nThis technique allows the model to incorporate both high-resolution and\nlow-resolution features, effectively balancing coarse and fine-grained\ninformation. As a result, the model supports resolutions up to 4096 x 4096\npixels, offering a more detailed and comprehensive visual processing\ncapability. Both VisualRWKV-HD and VisualRWKV-UHD not only achieve strong\nresults on VLM benchmarks but also show marked improvements in performance for\ntext-rich tasks.",
      "tldr_zh": "本研究提出 VisualRWKV-HD 和 VisualRWKV-UHD 两种模型，旨在提升视觉语言模型（VLMs）的图像分辨率处理能力，以减少幻觉并改善高分辨率任务如文本丰富分析的性能。VisualRWKV-HD 通过无损下采样方法，将高分辨率视觉编码器与低分辨率编码器整合，而不增加输入序列长度，从而实现高效的图像处理。VisualRWKV-UHD 则将图像分成四个部分并与原图像重新组合，融合高分辨率和低分辨率特征，支持高达 4096 x 4096 像素的分辨率，提供更详细的视觉表示。这两种模型在 VLM benchmarks 上表现出色，并在文本丰富任务中显著提升性能。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.11665v1",
      "published_date": "2024-10-15 14:49:19 UTC",
      "updated_date": "2024-10-15 14:49:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:48:58.752969"
    },
    {
      "arxiv_id": "2410.11655v1",
      "title": "Retrieval Augmented Spelling Correction for E-Commerce Applications",
      "title_zh": "翻译失败",
      "authors": [
        "Xuan Guo",
        "Rohit Patki",
        "Dante Everaert",
        "Christopher Potts"
      ],
      "abstract": "The rapid introduction of new brand names into everyday language poses a\nunique challenge for e-commerce spelling correction services, which must\ndistinguish genuine misspellings from novel brand names that use unconventional\nspelling. We seek to address this challenge via Retrieval Augmented Generation\n(RAG). On this approach, product names are retrieved from a catalog and\nincorporated into the context used by a large language model (LLM) that has\nbeen fine-tuned to do contextual spelling correction. Through quantitative\nevaluation and qualitative error analyses, we find improvements in spelling\ncorrection utilizing the RAG framework beyond a stand-alone LLM. We also\ndemonstrate the value of additional finetuning of the LLM to incorporate\nretrieved context.",
      "tldr_zh": "这篇论文针对电子商务应用中拼写纠错的挑战，提出使用 Retrieval Augmented Generation (RAG) 方法来区分真正的拼写错误与非常规品牌名称。具体而言，该方法通过从产品目录检索名称并将其整合到微调的 large language model (LLM) 上下文中，实现上下文相关的拼写纠错。实验结果显示，RAG 框架比独立的 LLM 更能提升纠错准确性，且额外微调 LLM 以整合检索上下文进一步证明了其价值。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.11655v1",
      "published_date": "2024-10-15 14:42:18 UTC",
      "updated_date": "2024-10-15 14:42:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:49:10.022754"
    },
    {
      "arxiv_id": "2410.11651v1",
      "title": "RS-MOCO: A deep learning-based topology-preserving image registration method for cardiac T1 mapping",
      "title_zh": "RS-MOCO：一种基于深度学习的拓扑保持图像配准方法，用于心脏 T1 映射",
      "authors": [
        "Chiyi Huang",
        "Longwei Sun",
        "Dong Liang",
        "Haifeng Liang",
        "Hongwu Zeng",
        "Yanjie Zhu"
      ],
      "abstract": "Cardiac T1 mapping can evaluate various clinical symptoms of myocardial\ntissue. However, there is currently a lack of effective, robust, and efficient\nmethods for motion correction in cardiac T1 mapping. In this paper, we propose\na deep learning-based and topology-preserving image registration framework for\nmotion correction in cardiac T1 mapping. Notably, our proposed implicit\nconsistency constraint dubbed BLOC, to some extent preserves the image topology\nin registration by bidirectional consistency constraint and local anti-folding\nconstraint. To address the contrast variation issue, we introduce a weighted\nimage similarity metric for multimodal registration of cardiac T1-weighted\nimages. Besides, a semi-supervised myocardium segmentation network and a\ndual-domain attention module are integrated into the framework to further\nimprove the performance of the registration. Numerous comparative experiments,\nas well as ablation studies, demonstrated the effectiveness and high robustness\nof our method. The results also indicate that the proposed weighted image\nsimilarity metric, specifically crafted for our network, contributes a lot to\nthe enhancement of the motion correction efficacy, while the bidirectional\nconsistency constraint combined with the local anti-folding constraint ensures\na more desirable topology-preserving registration mapping.",
      "tldr_zh": "本文提出了一种基于深度学习的图像配准方法RS-MOCO，用于心脏T1 mapping中的运动校正，以解决现有方法的有效性和鲁棒性不足问题。该方法引入了隐式一致性约束BLOC（包括双向一致性约束和局部反折叠约束）来保持图像拓扑，同时采用加权图像相似性度量处理多模态注册中的对比度变化，并整合半监督心肌分割网络和双域注意力模块以提升注册性能。实验结果显示，RS-MOCO在运动校正方面显著优于基线方法，具有更高的鲁棒性和准确性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.11651v1",
      "published_date": "2024-10-15 14:38:35 UTC",
      "updated_date": "2024-10-15 14:38:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:49:25.763955"
    },
    {
      "arxiv_id": "2410.11650v1",
      "title": "ED-ViT: Splitting Vision Transformer for Distributed Inference on Edge Devices",
      "title_zh": "翻译失败",
      "authors": [
        "Xiang Liu",
        "Yijun Song",
        "Xia Li",
        "Yifei Sun",
        "Huiying Lan",
        "Zemin Liu",
        "Linshan Jiang",
        "Jialin Li"
      ],
      "abstract": "Deep learning models are increasingly deployed on resource-constrained edge\ndevices for real-time data analytics. In recent years, Vision Transformer\nmodels and their variants have demonstrated outstanding performance across\nvarious computer vision tasks. However, their high computational demands and\ninference latency pose significant challenges for model deployment on\nresource-constraint edge devices. To address this issue, we propose a novel\nVision Transformer splitting framework, ED-ViT, designed to execute complex\nmodels across multiple edge devices efficiently. Specifically, we partition\nVision Transformer models into several sub-models, where each sub-model is\ntailored to handle a specific subset of data classes. To further minimize\ncomputation overhead and inference latency, we introduce a class-wise pruning\ntechnique that reduces the size of each sub-model. We conduct extensive\nexperiments on five datasets with three model structures, demonstrating that\nour approach significantly reduces inference latency on edge devices and\nachieves a model size reduction of up to 28.9 times and 34.1 times,\nrespectively, while maintaining test accuracy comparable to the original Vision\nTransformer. Additionally, we compare ED-ViT with two state-of-the-art methods\nthat deploy CNN and SNN models on edge devices, evaluating accuracy, inference\ntime, and overall model size. Our comprehensive evaluation underscores the\neffectiveness of the proposed ED-ViT framework.",
      "tldr_zh": "本论文提出 ED-ViT，一种创新的 Vision Transformer 分割框架，旨在解决这些模型在资源受限边缘设备上的高计算需求和推理延迟问题。该框架将 Vision Transformer 模型拆分为多个子模型，每个子模型针对特定数据子集进行处理，并引入 class-wise pruning 技术来进一步减少子模型大小，从而优化分布式推理。在五个数据集和三种模型结构上的广泛实验中，ED-ViT 实现了推理延迟显著降低、模型大小减少高达 28.9 倍和 34.1 倍，同时保持了与原模型相当的测试准确率，并优于部署 CNN 和 SNN 的现有方法。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "14 pages, 8 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.11650v1",
      "published_date": "2024-10-15 14:38:14 UTC",
      "updated_date": "2024-10-15 14:38:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:49:41.263811"
    },
    {
      "arxiv_id": "2410.11642v2",
      "title": "Improve Value Estimation of Q Function and Reshape Reward with Monte Carlo Tree Search",
      "title_zh": "翻译失败",
      "authors": [
        "Jiamian Li"
      ],
      "abstract": "Reinforcement learning has achieved remarkable success in perfect information\ngames such as Go and Atari, enabling agents to compete at the highest levels\nagainst human players. However, research in reinforcement learning for\nimperfect information games has been relatively limited due to the more complex\ngame structures and randomness. Traditional methods face challenges in training\nand improving performance in imperfect information games due to issues like\ninaccurate Q value estimation and reward sparsity. In this paper, we focus on\nUno, an imperfect information game, and aim to address these problems by\nreducing Q value overestimation and reshaping reward function. We propose a\nnovel algorithm that utilizes Monte Carlo Tree Search to average the value\nestimations in Q function. Even though we choose Double Deep Q Learning as the\nfoundational framework in this paper, our method can be generalized and used in\nany algorithm which needs Q value estimation, such as the Actor-Critic.\nAdditionally, we employ Monte Carlo Tree Search to reshape the reward structure\nin the game environment. We compare our algorithm with several traditional\nmethods applied to games such as Double Deep Q Learning, Deep Monte Carlo and\nNeural Fictitious Self Play, and the experiments demonstrate that our algorithm\nconsistently outperforms these approaches, especially as the number of players\nin Uno increases, indicating a higher level of difficulty.",
      "tldr_zh": "该论文针对强化学习在不完美信息游戏（如Uno）中的挑战，提出一种新算法来解决Q函数值估计过高和奖励稀疏问题。算法利用Monte Carlo Tree Search (MCTS) 来平均Q函数的值估计，并重塑游戏环境的奖励结构，基于Double Deep Q Learning框架，但可推广到其他需要Q值估计的算法如Actor-Critic。实验结果显示，该方法在Uno游戏中显著优于传统方法（如Double Deep Q Learning、Deep Monte Carlo和Neural Fictitious Self Play），尤其在玩家数量增加时性能更突出。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.11642v2",
      "published_date": "2024-10-15 14:31:54 UTC",
      "updated_date": "2024-10-23 09:43:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:49:56.973650"
    },
    {
      "arxiv_id": "2410.11623v1",
      "title": "VidEgoThink: Assessing Egocentric Video Understanding Capabilities for Embodied AI",
      "title_zh": "VidEgoThink：评估具身人工智能的自我中心视频理解能力",
      "authors": [
        "Sijie Cheng",
        "Kechen Fang",
        "Yangyang Yu",
        "Sicheng Zhou",
        "Bohao Li",
        "Ye Tian",
        "Tingguang Li",
        "Lei Han",
        "Yang Liu"
      ],
      "abstract": "Recent advancements in Multi-modal Large Language Models (MLLMs) have opened\nnew avenues for applications in Embodied AI. Building on previous work,\nEgoThink, we introduce VidEgoThink, a comprehensive benchmark for evaluating\negocentric video understanding capabilities. To bridge the gap between MLLMs\nand low-level control in Embodied AI, we design four key interrelated tasks:\nvideo question-answering, hierarchy planning, visual grounding and reward\nmodeling. To minimize manual annotation costs, we develop an automatic data\ngeneration pipeline based on the Ego4D dataset, leveraging the prior knowledge\nand multimodal capabilities of GPT-4o. Three human annotators then filter the\ngenerated data to ensure diversity and quality, resulting in the VidEgoThink\nbenchmark. We conduct extensive experiments with three types of models:\nAPI-based MLLMs, open-source image-based MLLMs, and open-source video-based\nMLLMs. Experimental results indicate that all MLLMs, including GPT-4o, perform\npoorly across all tasks related to egocentric video understanding. These\nfindings suggest that foundation models still require significant advancements\nto be effectively applied to first-person scenarios in Embodied AI. In\nconclusion, VidEgoThink reflects a research trend towards employing MLLMs for\negocentric vision, akin to human capabilities, enabling active observation and\ninteraction in the complex real-world environments.",
      "tldr_zh": "该论文引入 VidEgoThink 基准，用于评估多模态大型语言模型 (MLLMs) 在 Embodied AI 中的 egocentric video 理解能力，扩展了之前的 EgoThink 工作。研究设计了四个关键任务，包括 video question-answering、hierarchy planning、visual grounding 和 reward modeling，并通过基于 Ego4D 数据集和 GPT-4o 的自动数据生成管道来最小化手动标注成本，同时由人类筛选确保数据质量。实验结果显示，包括 GPT-4o 在内的 API-based、image-based 和 video-based MLLMs 在这些任务上表现不佳，表明当前基础模型需进一步改进以应用于第一人称视角场景。总之，VidEgoThink 推动了 MLLMs 在 egocentric vision 中的研究趋势，旨在模拟人类在复杂环境中进行主动观察和交互。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.11623v1",
      "published_date": "2024-10-15 14:08:53 UTC",
      "updated_date": "2024-10-15 14:08:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:50:00.641057"
    },
    {
      "arxiv_id": "2410.11594v1",
      "title": "Black-box Uncertainty Quantification Method for LLM-as-a-Judge",
      "title_zh": "黑盒不确定性量化方法用于 LLM-as-a-Judge",
      "authors": [
        "Nico Wagner",
        "Michael Desmond",
        "Rahul Nair",
        "Zahra Ashktorab",
        "Elizabeth M. Daly",
        "Qian Pan",
        "Martín Santillán Cooper",
        "James M. Johnson",
        "Werner Geyer"
      ],
      "abstract": "LLM-as-a-Judge is a widely used method for evaluating the performance of\nLarge Language Models (LLMs) across various tasks. We address the challenge of\nquantifying the uncertainty of LLM-as-a-Judge evaluations. While uncertainty\nquantification has been well-studied in other domains, applying it effectively\nto LLMs poses unique challenges due to their complex decision-making\ncapabilities and computational demands. In this paper, we introduce a novel\nmethod for quantifying uncertainty designed to enhance the trustworthiness of\nLLM-as-a-Judge evaluations. The method quantifies uncertainty by analyzing the\nrelationships between generated assessments and possible ratings. By\ncross-evaluating these relationships and constructing a confusion matrix based\non token probabilities, the method derives labels of high or low uncertainty.\nWe evaluate our method across multiple benchmarks, demonstrating a strong\ncorrelation between the accuracy of LLM evaluations and the derived uncertainty\nscores. Our findings suggest that this method can significantly improve the\nreliability and consistency of LLM-as-a-Judge evaluations.",
      "tldr_zh": "该论文提出了一种黑箱不确定性量化方法，针对LLM-as-a-Judge评估大型语言模型(LLMs)性能时的不确定性挑战。该方法通过分析生成的评估与可能评级的关系，并基于token概率构建混淆矩阵，来判断评估的高或低不确定性水平。实验结果显示，该方法在多个基准上与LLM评估的准确性具有强相关性，从而显著提升了评估的可靠性和一致性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.11594v1",
      "published_date": "2024-10-15 13:29:22 UTC",
      "updated_date": "2024-10-15 13:29:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:50:11.188969"
    },
    {
      "arxiv_id": "2410.17283v3",
      "title": "Advancements in Visual Language Models for Remote Sensing: Datasets, Capabilities, and Enhancement Techniques",
      "title_zh": "翻译失败",
      "authors": [
        "Lijie Tao",
        "Haokui Zhang",
        "Haizhao Jing",
        "Yu Liu",
        "Dawei Yan",
        "Guoting Wei",
        "Xizhe Xue"
      ],
      "abstract": "Recently, the remarkable success of ChatGPT has sparked a renewed wave of\ninterest in artificial intelligence (AI), and the advancements in visual\nlanguage models (VLMs) have pushed this enthusiasm to new heights. Differring\nfrom previous AI approaches that generally formulated different tasks as\ndiscriminative models, VLMs frame tasks as generative models and align language\nwith visual information, enabling the handling of more challenging problems.\nThe remote sensing (RS) field, a highly practical domain, has also embraced\nthis new trend and introduced several VLM-based RS methods that have\ndemonstrated promising performance and enormous potential. In this paper, we\nfirst review the fundamental theories related to VLM, then summarize the\ndatasets constructed for VLMs in remote sensing and the various tasks they\naddressed. Finally, we categorize the improvement methods into three main parts\naccording to the core components of VLMs and provide a detailed introduction\nand comparison of these methods. A project associated with this review has been\ncreated at https://github.com/taolijie11111/VLMs-in-RS-review.",
      "tldr_zh": "该论文回顾了视觉语言模型 (VLMs) 在遥感 (RS) 领域的最新进展，强调 VLMs 通过将任务框架为生成模型并对齐语言与视觉信息，能够处理更复杂的挑战。作者首先总结了 VLMs 的基础理论，然后整理了针对 RS 的数据集和相关任务，如图像生成和分析。最终，他们将改进方法分类为 VLMs 核心组件的三部分，并提供详细比较，同时分享了相关项目（https://github.com/taolijie11111/VLMs-in-RS-review），展示了 VLMs 在 RS 领域的巨大潜力。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.17283v3",
      "published_date": "2024-10-15 13:28:55 UTC",
      "updated_date": "2025-01-02 04:13:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:50:21.737994"
    },
    {
      "arxiv_id": "2410.11591v1",
      "title": "PaSTe: Improving the Efficiency of Visual Anomaly Detection at the Edge",
      "title_zh": "PaSTe：提升视觉异常检测在边缘的效率",
      "authors": [
        "Manuel Barusco",
        "Francesco Borsatti",
        "Davide Dalle Pezze",
        "Francesco Paissan",
        "Elisabetta Farella",
        "Gian Antonio Susto"
      ],
      "abstract": "Visual Anomaly Detection (VAD) has gained significant research attention for\nits ability to identify anomalous images and pinpoint the specific areas\nresponsible for the anomaly. A key advantage of VAD is its unsupervised nature,\nwhich eliminates the need for costly and time-consuming labeled data\ncollection. However, despite its potential for real-world applications, the\nliterature has given limited focus to resource-efficient VAD, particularly for\ndeployment on edge devices. This work addresses this gap by leveraging\nlightweight neural networks to reduce memory and computation requirements,\nenabling VAD deployment on resource-constrained edge devices. We benchmark the\nmajor VAD algorithms within this framework and demonstrate the feasibility of\nedge-based VAD using the well-known MVTec dataset. Furthermore, we introduce a\nnovel algorithm, Partially Shared Teacher-student (PaSTe), designed to address\nthe high resource demands of the existing Student Teacher Feature Pyramid\nMatching (STFPM) approach. Our results show that PaSTe decreases the inference\ntime by 25%, while reducing the training time by 33% and peak RAM usage during\ntraining by 76%. These improvements make the VAD process significantly more\nefficient, laying a solid foundation for real-world deployment on edge devices.",
      "tldr_zh": "本研究针对视觉异常检测 (VAD) 在边设备部署中的资源效率问题，提出使用轻量级神经网络来降低内存和计算需求，从而实现 VAD 在资源受限设备上的实际应用。研究者基准测试了主要 VAD 算法，并利用 MVTec 数据集证明了其可行性；同时引入了新算法 Partially Shared Teacher-student (PaSTe)，针对现有 Student Teacher Feature Pyramid Matching (STFPM) 方法的高资源需求进行优化。结果显示，PaSTe 将推理时间减少 25%、训练时间减少 33%、训练峰值 RAM 使用减少 76%，显著提升了 VAD 的效率，为边设备上的实时异常检测奠定了基础。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "13 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.11591v1",
      "published_date": "2024-10-15 13:25:43 UTC",
      "updated_date": "2024-10-15 13:25:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:50:34.245292"
    },
    {
      "arxiv_id": "2410.11590v1",
      "title": "Towards a Healthy AI Tradition: Lessons from Biology and Biomedical Science",
      "title_zh": "翻译失败",
      "authors": [
        "Simon Kasif"
      ],
      "abstract": "AI is a magnificent field that directly and profoundly touches on numerous\ndisciplines ranging from philosophy, computer science, engineering,\nmathematics, decision and data science and economics, to cognitive science,\nneuroscience and more. The number of applications and impact of AI is second to\nnone and the potential of AI to broadly impact future science developments is\nparticularly thrilling. While attempts to understand knowledge, reasoning,\ncognition and learning go back centuries, AI remains a relatively new field. In\npart due to the fact it has so many wide-ranging overlaps with other disparate\nfields it appears to have trouble developing a robust identity and culture.\nHere we suggest that contrasting the fast-moving AI culture to biological and\nbiomedical sciences is both insightful and useful way to inaugurate a healthy\ntradition needed to envision and manage our ascent to AGI and beyond\n(independent of the AI Platforms used). The co-evolution of AI and Biomedical\nScience offers many benefits to both fields. In a previous perspective, we\nsuggested that biomedical laboratories or centers can usefully embrace logistic\ntraditions in AI labs that will allow them to be highly collaborative, improve\nthe reproducibility of research, reduce risk aversion and produce faster\nmentorship pathways for PhDs and fellows. This perspective focuses on the\nbenefits to AI by adapting features of biomedical science at higher, primarily\ncultural levels.",
      "tldr_zh": "这篇论文探讨了人工智能（AI）领域如何通过借鉴生物和生物医学科学的文化特征，来建立一种健康传统，以解决 AI 在身份和文化方面的问题。作者强调，AI 与生物医学科学的共同演化能提供宝贵洞见，帮助 AI 发展更稳固的身份，促进协作性、研究可重复性（reproducibility）、减少风险厌恶，并加速博士和研究员的导师路径。最终，该研究为 AI 向人工通用智能（AGI）及更远发展提供文化层面的指导策略。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.11590v1",
      "published_date": "2024-10-15 13:25:02 UTC",
      "updated_date": "2024-10-15 13:25:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:50:49.651278"
    },
    {
      "arxiv_id": "2410.11584v2",
      "title": "DeformPAM: Data-Efficient Learning for Long-horizon Deformable Object Manipulation via Preference-based Action Alignment",
      "title_zh": "翻译失败",
      "authors": [
        "Wendi Chen",
        "Han Xue",
        "Fangyuan Zhou",
        "Yuan Fang",
        "Cewu Lu"
      ],
      "abstract": "In recent years, imitation learning has made progress in the field of robotic\nmanipulation. However, it still faces challenges when addressing complex\nlong-horizon tasks with deformable objects, such as high-dimensional state\nspaces, complex dynamics, and multimodal action distributions. Traditional\nimitation learning methods often require a large amount of data and encounter\ndistributional shifts and accumulative errors in these tasks. To address these\nissues, we propose a data-efficient general learning framework (DeformPAM)\nbased on preference learning and reward-guided action selection. DeformPAM\ndecomposes long-horizon tasks into multiple action primitives, utilizes 3D\npoint cloud inputs and diffusion models to model action distributions, and\ntrains an implicit reward model using human preference data. During the\ninference phase, the reward model scores multiple candidate actions, selecting\nthe optimal action for execution, thereby reducing the occurrence of anomalous\nactions and improving task completion quality. Experiments conducted on three\nchallenging real-world long-horizon deformable object manipulation tasks\ndemonstrate the effectiveness of this method. Results show that DeformPAM\nimproves both task completion quality and efficiency compared to baseline\nmethods even with limited data. Code and data will be available at\nhttps://deform-pam.robotflow.ai.",
      "tldr_zh": "本文提出 DeformPAM 框架，一种基于偏好学习（preference learning）和奖励引导动作选择（reward-guided action selection）的通用学习方法，用于处理机器人操作中长时可变形物体（deformable objects）任务的挑战，如高维状态空间和复杂动态。DeformPAM 将任务分解为多个动作基元（action primitives），利用 3D 点云输入和扩散模型（diffusion models）建模动作分布，并通过人类偏好数据训练隐式奖励模型（implicit reward model），以选择最佳动作并减少异常行为。在三个真实世界长时任务的实验中，即使数据有限，该框架也比基线方法显著提高了任务完成质量和效率。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.RO",
      "comment": "Accepted to ICRA 2025. Project page: https://deform-pam.robotflow.ai",
      "pdf_url": "http://arxiv.org/pdf/2410.11584v2",
      "published_date": "2024-10-15 13:19:16 UTC",
      "updated_date": "2025-03-12 17:54:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:50:58.475123"
    },
    {
      "arxiv_id": "2410.11582v1",
      "title": "On-the-fly Modulation for Balanced Multimodal Learning",
      "title_zh": "实时调制以实现平衡的多模态学习",
      "authors": [
        "Yake Wei",
        "Di Hu",
        "Henghui Du",
        "Ji-Rong Wen"
      ],
      "abstract": "Multimodal learning is expected to boost model performance by integrating\ninformation from different modalities. However, its potential is not fully\nexploited because the widely-used joint training strategy, which has a uniform\nobjective for all modalities, leads to imbalanced and under-optimized uni-modal\nrepresentations. Specifically, we point out that there often exists modality\nwith more discriminative information, e.g., vision of playing football and\nsound of blowing wind. They could dominate the joint training process,\nresulting in other modalities being significantly under-optimized. To alleviate\nthis problem, we first analyze the under-optimized phenomenon from both the\nfeed-forward and the back-propagation stages during optimization. Then,\nOn-the-fly Prediction Modulation (OPM) and On-the-fly Gradient Modulation (OGM)\nstrategies are proposed to modulate the optimization of each modality, by\nmonitoring the discriminative discrepancy between modalities during training.\nConcretely, OPM weakens the influence of the dominant modality by dropping its\nfeature with dynamical probability in the feed-forward stage, while OGM\nmitigates its gradient in the back-propagation stage. In experiments, our\nmethods demonstrate considerable improvement across a variety of multimodal\ntasks. These simple yet effective strategies not only enhance performance in\nvanilla and task-oriented multimodal models, but also in more complex\nmultimodal tasks, showcasing their effectiveness and flexibility. The source\ncode is available at \\url{https://github.com/GeWu-Lab/BML_TPAMI2024}.",
      "tldr_zh": "本研究针对多模态学习(Multimodal Learning)中统一训练目标导致的模态不平衡问题，指出某些模态（如视觉或声音）可能主导训练，导致其他模态未优化。作者提出 On-the-fly Prediction Modulation (OPM) 和 On-the-fly Gradient Modulation (OGM) 策略，通过监控模态间的区分性差异，在前向传播中动态丢弃主导模态特征，并在反向传播中减轻其梯度，从而平衡各模态的优化。实验结果显示，这些方法在各种多模态任务上显著提升性能，包括普通和任务导向模型，并证明了其有效性和灵活性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "cs.MM"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by T-PAMI 2024",
      "pdf_url": "http://arxiv.org/pdf/2410.11582v1",
      "published_date": "2024-10-15 13:15:50 UTC",
      "updated_date": "2024-10-15 13:15:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:51:10.728856"
    },
    {
      "arxiv_id": "2410.11550v1",
      "title": "Y-Mol: A Multiscale Biomedical Knowledge-Guided Large Language Model for Drug Development",
      "title_zh": "Y-Mol：一种多尺度生物医学知识引导的大型语言模型，用于药物开发",
      "authors": [
        "Tengfei Ma",
        "Xuan Lin",
        "Tianle Li",
        "Chaoyi Li",
        "Long Chen",
        "Peng Zhou",
        "Xibao Cai",
        "Xinyu Yang",
        "Daojian Zeng",
        "Dongsheng Cao",
        "Xiangxiang Zeng"
      ],
      "abstract": "Large Language Models (LLMs) have recently demonstrated remarkable\nperformance in general tasks across various fields. However, their\neffectiveness within specific domains such as drug development remains\nchallenges. To solve these challenges, we introduce \\textbf{Y-Mol}, forming a\nwell-established LLM paradigm for the flow of drug development. Y-Mol is a\nmultiscale biomedical knowledge-guided LLM designed to accomplish tasks across\nlead compound discovery, pre-clinic, and clinic prediction. By integrating\nmillions of multiscale biomedical knowledge and using LLaMA2 as the base LLM,\nY-Mol augments the reasoning capability in the biomedical domain by learning\nfrom a corpus of publications, knowledge graphs, and expert-designed synthetic\ndata. The capability is further enriched with three types of drug-oriented\ninstructions: description-based prompts from processed publications,\nsemantic-based prompts for extracting associations from knowledge graphs, and\ntemplate-based prompts for understanding expert knowledge from biomedical\ntools. Besides, Y-Mol offers a set of LLM paradigms that can autonomously\nexecute the downstream tasks across the entire process of drug development,\nincluding virtual screening, drug design, pharmacological properties\nprediction, and drug-related interaction prediction. Our extensive evaluations\nof various biomedical sources demonstrate that Y-Mol significantly outperforms\ngeneral-purpose LLMs in discovering lead compounds, predicting molecular\nproperties, and identifying drug interaction events.",
      "tldr_zh": "本文提出 Y-Mol，一种多尺度生物医学知识引导的 Large Language Model (LLM)，旨在解决 LLM 在药物开发领域的挑战，如领导化合物发现、临床前和临床预测。Y-Mol 以 LLaMA2 为基础，整合了数百万生物医学知识（包括出版物、知识图谱和专家合成数据），并通过三种药物导向指令（描述-based、语义-based 和模板-based 提示）增强推理和任务执行能力。该模型可自主处理药物开发的完整流程，包括虚拟筛选、药物设计、药理特性预测和药物交互预测，并在评估中显著优于通用 LLM，尤其在发现领导化合物和预测分子特性方面。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "12 pages, Under Review",
      "pdf_url": "http://arxiv.org/pdf/2410.11550v1",
      "published_date": "2024-10-15 12:39:20 UTC",
      "updated_date": "2024-10-15 12:39:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:51:22.869849"
    },
    {
      "arxiv_id": "2410.11533v2",
      "title": "Multi-round jailbreak attack on large language models",
      "title_zh": "翻译失败",
      "authors": [
        "Yihua Zhou",
        "Xiaochuan Shi"
      ],
      "abstract": "Ensuring the safety and alignment of large language models (LLMs) with human\nvalues is crucial for generating responses that are beneficial to humanity.\nWhile LLMs have the capability to identify and avoid harmful queries, they\nremain vulnerable to \"jailbreak\" attacks, where carefully crafted prompts can\ninduce the generation of toxic content. Traditional single-round jailbreak\nattacks, such as GCG and AutoDAN, do not alter the sensitive words in the\ndangerous prompts. Although they can temporarily bypass the model's safeguards\nthrough prompt engineering, their success rate drops significantly as the LLM\nis further fine-tuned, and they cannot effectively circumvent static rule-based\nfilters that remove the hazardous vocabulary.\n  In this study, to better understand jailbreak attacks, we introduce a\nmulti-round jailbreak approach. This method can rewrite the dangerous prompts,\ndecomposing them into a series of less harmful sub-questions to bypass the\nLLM's safety checks. We first use the LLM to perform a decomposition task,\nbreaking down a set of natural language questions into a sequence of\nprogressive sub-questions, which are then used to fine-tune the Llama3-8B\nmodel, enabling it to decompose hazardous prompts. The fine-tuned model is then\nused to break down the problematic prompt, and the resulting sub-questions are\nsequentially asked to the victim model. If the victim model rejects a\nsub-question, a new decomposition is generated, and the process is repeated\nuntil the final objective is achieved. Our experimental results show a 94\\%\nsuccess rate on the llama2-7B and demonstrate the effectiveness of this\napproach in circumventing static rule-based filters.",
      "tldr_zh": "这篇论文提出了一种多轮 jailbreak attack 方法，以评估和绕过大型语言模型（LLMs）的安全机制，相比传统单轮攻击（如 GCG 和 AutoDAN），它能更有效地处理模型微调和静态规则过滤。方法包括将危险提示分解成一系列无害子问题，通过微调 Llama3-8B 模型生成渐进子问题，并顺序提问；如果子问题被拒绝，则重新分解直至达到目标。实验结果显示，该方法在 llama2-7B 模型上成功率达 94%，证明了其在规避安全检查方面的显著有效性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "It is not fully completed",
      "pdf_url": "http://arxiv.org/pdf/2410.11533v2",
      "published_date": "2024-10-15 12:08:14 UTC",
      "updated_date": "2024-10-19 09:17:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:51:33.585862"
    },
    {
      "arxiv_id": "2410.11531v1",
      "title": "AGENTiGraph: An Interactive Knowledge Graph Platform for LLM-based Chatbots Utilizing Private Data",
      "title_zh": "翻译失败",
      "authors": [
        "Xinjie Zhao",
        "Moritz Blum",
        "Rui Yang",
        "Boming Yang",
        "Luis Márquez Carpintero",
        "Mónica Pina-Navarro",
        "Tony Wang",
        "Xin Li",
        "Huitao Li",
        "Yanran Fu",
        "Rongrong Wang",
        "Juntao Zhang",
        "Irene Li"
      ],
      "abstract": "Large Language Models~(LLMs) have demonstrated capabilities across various\napplications but face challenges such as hallucination, limited reasoning\nabilities, and factual inconsistencies, especially when tackling complex,\ndomain-specific tasks like question answering~(QA). While Knowledge\nGraphs~(KGs) have been shown to help mitigate these issues, research on the\nintegration of LLMs with background KGs remains limited. In particular, user\naccessibility and the flexibility of the underlying KG have not been thoroughly\nexplored. We introduce AGENTiGraph (Adaptive Generative ENgine for Task-based\nInteraction and Graphical Representation), a platform for knowledge management\nthrough natural language interaction. It integrates knowledge extraction,\nintegration, and real-time visualization. AGENTiGraph employs a multi-agent\narchitecture to dynamically interpret user intents, manage tasks, and integrate\nnew knowledge, ensuring adaptability to evolving user requirements and data\ncontexts. Our approach demonstrates superior performance in knowledge graph\ninteractions, particularly for complex domain-specific tasks. Experimental\nresults on a dataset of 3,500 test cases show AGENTiGraph significantly\noutperforms state-of-the-art zero-shot baselines, achieving 95.12\\% accuracy in\ntask classification and 90.45\\% success rate in task execution. User studies\ncorroborate its effectiveness in real-world scenarios. To showcase versatility,\nwe extended AGENTiGraph to legislation and healthcare domains, constructing\nspecialized KGs capable of answering complex queries in legal and medical\ncontexts.",
      "tldr_zh": "该研究提出 AGENTiGraph，一种交互式知识图谱平台，旨在通过整合知识图谱(KGs)来缓解大型语言模型(LLMs)在处理复杂领域任务（如问答QA）时面临的幻觉、推理限制和事实不一致问题。平台采用多智能体架构，实现知识提取、整合以及实时可视化，并动态解释用户意图、管理任务和适应新数据。实验结果显示，在3500个测试案例上，AGENTiGraph 的任务分类准确率达95.12%、任务执行成功率达90.45%，显著优于零样本基线，且用户研究证实其在实际场景中的有效性。该平台已扩展到立法和医疗领域，构建专业KGs以处理复杂查询，展示了其灵活性和适用性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "30 pages, 7 figures; Submitted to COLING 2025 System Demonstrations\n  Track",
      "pdf_url": "http://arxiv.org/pdf/2410.11531v1",
      "published_date": "2024-10-15 12:05:58 UTC",
      "updated_date": "2024-10-15 12:05:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:51:46.329745"
    },
    {
      "arxiv_id": "2410.11507v4",
      "title": "TestAgent: A Framework for Domain-Adaptive Evaluation of LLMs via Dynamic Benchmark Construction and Exploratory Interaction",
      "title_zh": "翻译失败",
      "authors": [
        "Wanying Wang",
        "Zeyu Ma",
        "Pengfei Liu",
        "Mingang Chen"
      ],
      "abstract": "As large language models (LLMs) are increasingly deployed to various vertical\ndomains, automatically evaluating their performance across different domains\nremains a critical challenge. Current evaluation methods often rely on static\nand resource-intensive datasets that are not aligned with real-world\nrequirements and lack cross-domain adaptability. To address these limitations,\nwe revisit the evaluation process and introduce two key concepts:\n\\textbf{Benchmark+}, which extends the traditional question-answer benchmark\ninto a more flexible ``strategy-criterion'' format; and \\textbf{Assessment+},\nwhich enhances the interaction process to facilitate deeper exploration and\ncomprehensive analysis from multiple perspectives. We propose\n\\textbf{\\textsc{TestAgent}}, an agent-based evaluation framework that\nimplements these concepts using retrieval-augmented generation and\nreinforcement learning. \\textsc{TestAgent} enables automatic dynamic benchmark\ngeneration and in-depth assessment across diverse vertical domains. Experiments\non tasks ranging from constructing multiple vertical domain evaluations to\ntransforming static benchmarks into dynamic forms demonstrate the effectiveness\nof \\textsc{TestAgent}. This work provides a novel perspective on automatic\nevaluation methods for domain-specific LLMs, offering a pathway for\ndomain-adaptive dynamic benchmark construction and exploratory assessment.",
      "tldr_zh": "该论文提出 TestAgent 框架，用于评估大语言模型（LLMs）的领域适应性，通过动态基准构建和探索性交互解决传统静态数据集的局限性。框架引入 Benchmark+（扩展为灵活的“strategy-criterion”格式）和 Assessment+（增强交互以支持多视角分析），并结合 retrieval-augmented generation 和 reinforcement learning 实现自动动态基准生成和跨领域评估。实验结果表明，TestAgent 在构建垂直领域评估和转换静态基准方面表现出色，为领域特定 LLMs 的自动评估提供创新路径。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.11507v4",
      "published_date": "2024-10-15 11:20:42 UTC",
      "updated_date": "2025-05-16 05:34:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:51:58.143110"
    },
    {
      "arxiv_id": "2410.11502v3",
      "title": "Offline Model-Based Optimization by Learning to Rank",
      "title_zh": "翻译失败",
      "authors": [
        "Rong-Xi Tan",
        "Ke Xue",
        "Shen-Huan Lyu",
        "Haopu Shang",
        "Yao Wang",
        "Yaoyuan Wang",
        "Sheng Fu",
        "Chao Qian"
      ],
      "abstract": "Offline model-based optimization (MBO) aims to identify a design that\nmaximizes a black-box function using only a fixed, pre-collected dataset of\ndesigns and their corresponding scores. A common approach in offline MBO is to\ntrain a regression-based surrogate model by minimizing mean squared error (MSE)\nand then find the best design within this surrogate model by different\noptimizers (e.g., gradient ascent). However, a critical challenge is the risk\nof out-of-distribution errors, i.e., the surrogate model may typically\noverestimate the scores and mislead the optimizers into suboptimal regions.\nPrior works have attempted to address this issue in various ways, such as using\nregularization techniques and ensemble learning to enhance the robustness of\nthe model, but it still remains. In this paper, we argue that regression models\ntrained with MSE are not well-aligned with the primary goal of offline MBO,\nwhich is to select promising designs rather than to predict their scores\nprecisely. Notably, if a surrogate model can maintain the order of candidate\ndesigns based on their relative score relationships, it can produce the best\ndesigns even without precise predictions. To validate it, we conduct\nexperiments to compare the relationship between the quality of the final\ndesigns and MSE, finding that the correlation is really very weak. In contrast,\na metric that measures order-maintaining quality shows a significantly stronger\ncorrelation. Based on this observation, we propose learning a ranking-based\nmodel that leverages learning to rank techniques to prioritize promising\ndesigns based on their relative scores. We show that the generalization error\non ranking loss can be well bounded. Empirical results across diverse tasks\ndemonstrate the superior performance of our proposed ranking-based models than\ntwenty existing methods.",
      "tldr_zh": "这篇论文针对离线模型优化(Offline MBO)的问题，指出传统基于均方误差(MSE)的回归模型容易因分布外错误而高估分数，导致优化器选择次优设计。作者提出使用学习排序(Learning to Rank)技术训练一个基于排名的模型，专注于维护候选设计的相对分数顺序，从而更有效地优先有前景的设计，并证明了排名损失的泛化误差可以被良好界定。实验结果显示，该方法在多种任务上优于20种现有方法，显著提升了最终设计的质量。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NE"
      ],
      "primary_category": "cs.LG",
      "comment": "ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2410.11502v3",
      "published_date": "2024-10-15 11:15:03 UTC",
      "updated_date": "2025-05-02 15:46:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:52:10.198591"
    },
    {
      "arxiv_id": "2410.11499v1",
      "title": "BSM: Small but Powerful Biological Sequence Model for Genes and Proteins",
      "title_zh": "BSM：小型",
      "authors": [
        "Weixi Xiang",
        "Xueting Han",
        "Xiujuan Chai",
        "Jing Bai"
      ],
      "abstract": "Modeling biological sequences such as DNA, RNA, and proteins is crucial for\nunderstanding complex processes like gene regulation and protein synthesis.\nHowever, most current models either focus on a single type or treat multiple\ntypes of data separately, limiting their ability to capture cross-modal\nrelationships. We propose that by learning the relationships between these\nmodalities, the model can enhance its understanding of each type. To address\nthis, we introduce BSM, a small but powerful mixed-modal biological sequence\nfoundation model, trained on three types of data: RefSeq, Gene Related\nSequences, and interleaved biological sequences from the web. These datasets\ncapture the genetic flow, gene-protein relationships, and the natural\nco-occurrence of diverse biological data, respectively. By training on\nmixed-modal data, BSM significantly enhances learning efficiency and\ncross-modal representation, outperforming models trained solely on unimodal\ndata. With only 110M parameters, BSM achieves performance comparable to much\nlarger models across both single-modal and mixed-modal tasks, and uniquely\ndemonstrates in-context learning capability for mixed-modal tasks, which is\nabsent in existing models. Further scaling to 270M parameters demonstrates even\ngreater performance gains, highlighting the potential of BSM as a significant\nadvancement in multimodal biological sequence modeling.",
      "tldr_zh": "本文提出 BSM，一种小型而强大的混合模态生物序列模型，用于建模 DNA、RNA 和蛋白质序列，以捕捉跨模态关系并提升整体理解。BSM 在 RefSeq、Gene Related Sequences 和网络交错生物序列等数据集上训练，显著提高了学习效率和表示能力，优于仅基于单模态数据的模型。凭借仅 110M 参数，BSM 在单模态和混合模态任务上达到与大型模型相当的性能，并首次展示混合模态任务的 in-context learning 能力。进一步扩展到 270M 参数后，BSM 的性能获得更大提升，标志着多模态生物序列建模的重大进步。",
      "categories": [
        "q-bio.GN",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "q-bio.GN",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.11499v1",
      "published_date": "2024-10-15 11:12:28 UTC",
      "updated_date": "2024-10-15 11:12:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:52:33.441949"
    },
    {
      "arxiv_id": "2410.11494v1",
      "title": "DynamicER: Resolving Emerging Mentions to Dynamic Entities for RAG",
      "title_zh": "翻译失败",
      "authors": [
        "Jinyoung Kim",
        "Dayoon Ko",
        "Gunhee Kim"
      ],
      "abstract": "In the rapidly evolving landscape of language, resolving new linguistic\nexpressions in continuously updating knowledge bases remains a formidable\nchallenge. This challenge becomes critical in retrieval-augmented generation\n(RAG) with knowledge bases, as emerging expressions hinder the retrieval of\nrelevant documents, leading to generator hallucinations. To address this issue,\nwe introduce a novel task aimed at resolving emerging mentions to dynamic\nentities and present DynamicER benchmark. Our benchmark includes dynamic entity\nmention resolution and entity-centric knowledge-intensive QA task, evaluating\nentity linking and RAG model's adaptability to new expressions, respectively.\nWe discovered that current entity linking models struggle to link these new\nexpressions to entities. Therefore, we propose a temporal segmented clustering\nmethod with continual adaptation, effectively managing the temporal dynamics of\nevolving entities and emerging mentions. Extensive experiments demonstrate that\nour method outperforms existing baselines, enhancing RAG model performance on\nQA task with resolved mentions.",
      "tldr_zh": "该论文针对语言快速演变导致的新兴提及（emerging mentions）在检索增强生成（RAG）系统中的解析挑战，提出了一种新任务和基准DynamicER，以评估实体链接模型和RAG模型对动态实体的适应性。研究发现，现有实体链接模型难以处理这些新表达，因此开发了基于时间分段聚类（temporal segmented clustering）和持续适应（continual adaptation）的方法，来有效管理演变实体的动态性。实验结果显示，该方法显著优于现有基线，提升了RAG模型在实体中心知识密集型QA任务中的性能。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "EMNLP 2024 Main",
      "pdf_url": "http://arxiv.org/pdf/2410.11494v1",
      "published_date": "2024-10-15 10:57:12 UTC",
      "updated_date": "2024-10-15 10:57:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:52:34.904960"
    },
    {
      "arxiv_id": "2410.11493v2",
      "title": "Towards Fair Graph Representation Learning in Social Networks",
      "title_zh": "面向公平的社交网络图表示学习",
      "authors": [
        "Guixian Zhang",
        "Guan Yuan",
        "Debo Cheng",
        "Lin Liu",
        "Jiuyong Li",
        "Shichao Zhang"
      ],
      "abstract": "With the widespread use of Graph Neural Networks (GNNs) for representation\nlearning from network data, the fairness of GNN models has raised great\nattention lately. Fair GNNs aim to ensure that node representations can be\naccurately classified, but not easily associated with a specific group.\nExisting advanced approaches essentially enhance the generalisation of node\nrepresentation in combination with data augmentation strategy, and do not\ndirectly impose constraints on the fairness of GNNs. In this work, we identify\nthat a fundamental reason for the unfairness of GNNs in social network learning\nis the phenomenon of social homophily, i.e., users in the same group are more\ninclined to congregate. The message-passing mechanism of GNNs can cause users\nin the same group to have similar representations due to social homophily,\nleading model predictions to establish spurious correlations with sensitive\nattributes. Inspired by this reason, we propose a method called Equity-Aware\nGNN (EAGNN) towards fair graph representation learning. Specifically, to ensure\nthat model predictions are independent of sensitive attributes while\nmaintaining prediction performance, we introduce constraints for fair\nrepresentation learning based on three principles: sufficiency, independence,\nand separation. We theoretically demonstrate that our EAGNN method can\neffectively achieve group fairness. Extensive experiments on three datasets\nwith varying levels of social homophily illustrate that our EAGNN method\nachieves the state-of-the-art performance across two fairness metrics and\noffers competitive effectiveness.",
      "tldr_zh": "该研究探讨了图神经网络 (GNNs) 在社交网络中的公平性问题，指出社交同质性 (social homophily) 导致同一群体的节点表示相似，从而使模型预测与敏感属性相关。针对这一问题，作者提出 Equity-Aware GNN (EAGNN) 方法，通过引入基于 sufficiency、independence 和 separation 三个原则的约束，确保节点表示在保持预测性能的同时，实现对敏感属性的独立性。实验结果显示，EAGNN 在三个不同社交同质性水平的数据集上，达到了最先进的公平度量表现，并保持了竞争力的整体有效性。",
      "categories": [
        "cs.SI",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.SI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.11493v2",
      "published_date": "2024-10-15 10:57:02 UTC",
      "updated_date": "2024-10-22 02:31:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:52:48.782923"
    },
    {
      "arxiv_id": "2410.11492v1",
      "title": "NavTopo: Leveraging Topological Maps For Autonomous Navigation Of a Mobile Robot",
      "title_zh": "翻译失败",
      "authors": [
        "Kirill Muravyev",
        "Konstantin Yakovlev"
      ],
      "abstract": "Autonomous navigation of a mobile robot is a challenging task which requires\nability of mapping, localization, path planning and path following.\nConventional mapping methods build a dense metric map like an occupancy grid,\nwhich is affected by odometry error accumulation and consumes a lot of memory\nand computations in large environments. Another approach to mapping is the\nusage of topological properties, e.g. adjacency of locations in the\nenvironment. Topological maps are less prone to odometry error accumulation and\nhigh resources consumption, and also enable fast path planning because of the\ngraph sparsity. Based on this idea, we proposed NavTopo - a full navigation\npipeline based on topological map and two-level path planning. The pipeline\nlocalizes in the graph by matching neural network descriptors and 2D\nprojections of the input point clouds, which significantly reduces memory\nconsumption compared to metric and topological point cloud-based approaches. We\ntest our approach in a large indoor photo-relaistic simulated environment and\ncompare it to a metric map-based approach based on popular metric mapping\nmethod RTAB-MAP. The experimental results show that our topological approach\nsignificantly outperforms the metric one in terms of performance, keeping\nproper navigational efficiency.",
      "tldr_zh": "本文提出 NavTopo，一种基于 Topological Maps 的完整导航管道，用于移动机器人的自主导航，以解决传统度量地图（metric map）如占用网格在里程计错误积累和资源消耗方面的缺陷。NavTopo 采用两级路径规划和神经网络描述符匹配输入点云的2D投影，实现高效定位和路径规划，从而显著降低内存消耗。在大型室内模拟环境中，实验结果显示 NavTopo 在性能上优于基于 RTAB-MAP 的度量方法，同时保持了适当的导航效率。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV",
        "I.2.9; I.2.10"
      ],
      "primary_category": "cs.RO",
      "comment": "This paper is published in proceedings of the 9th International\n  Conference \"Interactive Collaborative Robotics\" (ICR 2024)",
      "pdf_url": "http://arxiv.org/pdf/2410.11492v1",
      "published_date": "2024-10-15 10:54:49 UTC",
      "updated_date": "2024-10-15 10:54:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:52:58.672572"
    },
    {
      "arxiv_id": "2410.11464v1",
      "title": "CoActionGraphRec: Sequential Multi-Interest Recommendations Using Co-Action Graphs",
      "title_zh": "翻译失败",
      "authors": [
        "Yi Sun",
        "Yuri M. Brovman"
      ],
      "abstract": "There are unique challenges to developing item recommender systems for\ne-commerce platforms like eBay due to sparse data and diverse user interests.\nWhile rich user-item interactions are important, eBay's data sparsity exceeds\nother e-commerce sites by an order of magnitude. To address this challenge, we\npropose CoActionGraphRec (CAGR), a text based two-tower deep learning model\n(Item Tower and User Tower) utilizing co-action graph layers. In order to\nenhance user and item representations, a graph-based solution tailored to\neBay's environment is utilized. For the Item Tower, we represent each item\nusing its co-action items to capture collaborative signals in a co-action graph\nthat is fully leveraged by the graph neural network component. For the User\nTower, we build a fully connected graph of each user's behavior sequence, with\nedges encoding pairwise relationships. Furthermore, an explicit interaction\nmodule learns representations capturing behavior interactions. Extensive\noffline and online A/B test experiments demonstrate the effectiveness of our\nproposed approach and results show improved performance over state-of-the-art\nmethods on key metrics.",
      "tldr_zh": "该研究针对电商平台如 eBay 的数据稀疏和用户兴趣多样性挑战，提出了一种名为 CoActionGraphRec (CAGR) 的顺序多兴趣推荐系统。该系统采用两塔深度学习模型（Item Tower 和 User Tower），利用 co-action graphs 来增强用户和物品表示：在 Item Tower 中，通过图神经网络（graph neural network）捕捉物品的协作信号；在 User Tower 中，构建用户行为序列的全连接图，并使用显式交互模块学习行为关系。实验结果显示，CAGR 在离线和在线 A/B 测试中，在关键指标上超过了现有方法，证明了其有效性。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.11464v1",
      "published_date": "2024-10-15 10:11:18 UTC",
      "updated_date": "2024-10-15 10:11:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:53:10.942239"
    },
    {
      "arxiv_id": "2410.11463v2",
      "title": "Advanced Persistent Threats (APT) Attribution Using Deep Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Animesh Singh Basnet",
        "Mohamed Chahine Ghanem",
        "Dipo Dunsin",
        "Wiktor Sowinski-Mydlarz"
      ],
      "abstract": "The development of the DRL model for malware attribution involved extensive\nresearch, iterative coding, and numerous adjustments based on the insights\ngathered from predecessor models and contemporary research papers. This\npreparatory work was essential to establish a robust foundation for the model,\nensuring it could adapt and respond effectively to the dynamic nature of\nmalware threats. Initially, the model struggled with low accuracy levels, but\nthrough persistent adjustments to its architecture and learning algorithms,\naccuracy improved dramatically from about 7 percent to over 73 percent in early\niterations. By the end of the training, the model consistently reached accuracy\nlevels near 98 percent, demonstrating its strong capability to accurately\nrecognise and attribute malware activities. This upward trajectory in training\naccuracy is graphically represented in the Figure, which vividly illustrates\nthe model maturation and increasing proficiency over time.",
      "tldr_zh": "本研究提出了一种使用深度强化学习 (DRL) 的方法来归因高级持续性威胁 (APT)，旨在识别和 attribution 恶意软件活动。该模型的开发过程包括广泛的研究、迭代编码和架构调整，基于前驱模型和当代论文的洞见，使其适应动态威胁环境。最初，模型准确率仅为7%，但经过持续优化，准确率大幅提升至98%，展示了其在 malware 识别和归因方面的强大能力。该方法为高效的威胁检测提供了可靠基础，并通过图形展示了训练过程的进步轨迹。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "21 Pages",
      "pdf_url": "http://arxiv.org/pdf/2410.11463v2",
      "published_date": "2024-10-15 10:10:33 UTC",
      "updated_date": "2025-01-07 15:48:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:53:21.800856"
    },
    {
      "arxiv_id": "2410.22352v1",
      "title": "Neuromorphic Programming: Emerging Directions for Brain-Inspired Hardware",
      "title_zh": "翻译失败",
      "authors": [
        "Steven Abreu",
        "Jens E. Pedersen"
      ],
      "abstract": "The value of brain-inspired neuromorphic computers critically depends on our\nability to program them for relevant tasks. Currently, neuromorphic hardware\noften relies on machine learning methods adapted from deep learning. However,\nneuromorphic computers have potential far beyond deep learning if we can only\nharness their energy efficiency and full computational power. Neuromorphic\nprogramming will necessarily be different from conventional programming,\nrequiring a paradigm shift in how we think about programming. This paper\npresents a conceptual analysis of programming within the context of\nneuromorphic computing, challenging conventional paradigms and proposing a\nframework that aligns more closely with the physical intricacies of these\nsystems. Our analysis revolves around five characteristics that are fundamental\nto neuromorphic programming and provides a basis for comparison to contemporary\nprogramming methods and languages. By studying past approaches, we contribute a\nframework that advocates for underutilized techniques and calls for richer\nabstractions to effectively instrument the new hardware class.",
      "tldr_zh": "本论文探讨了神经形态编程（Neuromorphic Programming）的关键挑战，强调脑启发硬件的潜在超越深度学习（deep learning）的能效和计算能力，但当前依赖于从深度学习适配的机器学习方法。作者通过概念分析，提出一个新框架，围绕五个基本特性（如物理特性和编程范式转变）来挑战传统编程方法，并与当代语言进行比较。最终，该框架提倡未充分利用的技术和更丰富的抽象，以有效利用神经形态计算（neuromorphic computing）的新硬件类别。",
      "categories": [
        "cs.NE",
        "cs.AI",
        "cs.DC",
        "cs.ET",
        "cs.PL"
      ],
      "primary_category": "cs.NE",
      "comment": "Accepted to International Conference on Neuromorphic Systems (ICONS)\n  2024. arXiv admin note: substantial text overlap with arXiv:2310.18260",
      "pdf_url": "http://arxiv.org/pdf/2410.22352v1",
      "published_date": "2024-10-15 10:08:15 UTC",
      "updated_date": "2024-10-15 10:08:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:53:37.821810"
    },
    {
      "arxiv_id": "2410.11457v1",
      "title": "LR-SQL: A Supervised Fine-Tuning Method for Text2SQL Tasks under Low-Resource Scenarios",
      "title_zh": "LR-SQL：一种在低资源场景下针对文本到SQL任务的监督微调方法",
      "authors": [
        "Wen Wuzhenghong",
        "Zhang Yongpan",
        "Pan Su",
        "Sun Yuwei",
        "Lu Pengwei",
        "Ding Cheng"
      ],
      "abstract": "Large language models revolutionize Text2SQL through supervised fine-tuning,\nyet a crucial limitation is overlooked: the complexity of databases leads to an\nincreased context length, consequently resulting in higher GPU memory demands\nfor model fine-tuning. To address this issue, we propose LR-SQL. LR-SQL\ncomprises two supervised fine-tuning models: the schema\\_link model and the\nSQL\\_generation model, with the schema\\_link model serving as the focal point\nfor streamlining the overall process. During the fine-tuning of the\nschema\\_link model, LR-SQL breaks down the complete database into flexible\ncombinations of tables with adjustable quantities, enabling the model to learn\nthe relationships within the entire database from these dispersed slices.\nFurthermore, to enhance the model's ability to perceive the relationships among\nvarious discrete slices during inference, LR-SQL trains the model's\nChain-of-Thought capability for this task. Experimental results demonstrate\nthat LR-SQL can reduce the total GPU memory usage by 40\\% compared to existing\nfine-tuning methods, while only losing 2\\% of table prediction accuracy in\nschema\\_link task. For the overall Text2SQL task, the Execution Accuracy\ndecrease by 0.6\\%.Our project is now available on\nhttps://github.com/hongWin/LR-SQL",
      "tldr_zh": "该论文针对低资源场景下 Text2SQL 任务的监督微调问题，提出 LR-SQL 方法，以解决数据库复杂性导致的上下文长度增加和 GPU 内存需求问题。LR-SQL 包括 schema_link 模型和 SQL_generation 模型，其中 schema_link 模型通过将整个数据库分解为可调节数量的表组合，让模型从这些分散切片中学习数据库关系，并训练 Chain-of-Thought 能力以提升推理时的关系感知。实验结果显示，LR-SQL 比现有方法减少 40% 的 GPU 内存使用，仅在 schema_link 任务中损失 2% 的表预测准确率，在整体 Text2SQL 任务中 Execution Accuracy 仅下降 0.6%。这为高效的 Text2SQL 微调提供了实用解决方案。",
      "categories": [
        "cs.DB",
        "cs.AI",
        "cs.CL",
        "cs.IR"
      ],
      "primary_category": "cs.DB",
      "comment": "12pages, 4 figures,submitting to a journal",
      "pdf_url": "http://arxiv.org/pdf/2410.11457v1",
      "published_date": "2024-10-15 10:02:55 UTC",
      "updated_date": "2024-10-15 10:02:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:53:46.052863"
    },
    {
      "arxiv_id": "2410.11444v2",
      "title": "A Theoretical Survey on Foundation Models",
      "title_zh": "基础模型的理论综述",
      "authors": [
        "Shi Fu",
        "Yuzhu Chen",
        "Yingjie Wang",
        "Dacheng Tao"
      ],
      "abstract": "Understanding the inner mechanisms of black-box foundation models (FMs) is\nessential yet challenging in artificial intelligence and its applications. Over\nthe last decade, the long-running focus has been on their explainability,\nleading to the development of post-hoc explainable methods to rationalize the\nspecific decisions already made by black-box FMs. However, these explainable\nmethods have certain limitations in terms of faithfulness and resource\nrequirement. Consequently, a new class of interpretable methods should be\nconsidered to unveil the underlying mechanisms of FMs in an accurate,\ncomprehensive, heuristic, and resource-light way. This survey aims to review\nthose interpretable methods that comply with the aforementioned principles and\nhave been successfully applied to FMs. These methods are deeply rooted in\nmachine learning theory, covering the analysis of generalization performance,\nexpressive capability, and dynamic behavior. They provide a thorough\ninterpretation of the entire workflow of FMs, ranging from the inference\ncapability and training dynamics to their ethical implications. Ultimately,\ndrawing upon these interpretations, this review identifies the next frontier\nresearch directions for FMs.",
      "tldr_zh": "这篇论文对基础模型（Foundation Models, FMs）进行了理论调查，强调理解其黑箱机制的重要性，并审视了后验可解释方法（post-hoc explainable methods）的局限性，如在忠实度和资源需求方面的不足。论文提出采用基于机器学习理论的新的可解释方法，这些方法更准确、全面和资源轻量，能够分析FMs的泛化性能、表达能力以及动态行为，并覆盖从推理能力、训练动态到伦理影响的整个工作流程。通过这些解读，论文指出了FMs的未来研究方向，包括更深入的机制探索和应用优化。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "63 pages, 16 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.11444v2",
      "published_date": "2024-10-15 09:48:03 UTC",
      "updated_date": "2024-11-24 15:02:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:53:57.728304"
    },
    {
      "arxiv_id": "2410.11437v1",
      "title": "Difficult Task Yes but Simple Task No: Unveiling the Laziness in Multimodal LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Sihang Zhao",
        "Youliang Yuan",
        "Xiaoying Tang",
        "Pinjia He"
      ],
      "abstract": "Multimodal Large Language Models (MLLMs) demonstrate a strong understanding\nof the real world and can even handle complex tasks. However, they still fail\non some straightforward visual question-answering (VQA) problems. This paper\ndives deeper into this issue, revealing that models tend to err when answering\neasy questions (e.g. Yes/No questions) about an image, even though they can\ncorrectly describe it. We refer to this model behavior discrepancy between\ndifficult and simple questions as model laziness. To systematically investigate\nmodel laziness, we manually construct LazyBench, a benchmark that includes\nYes/No, multiple choice, short answer questions, and image description tasks\nthat are related to the same subjects in the images. Based on LazyBench, we\nobserve that laziness widely exists in current advanced MLLMs (e.g. GPT-4o,\nGemini-1.5-pro, Claude 3 and LLaVA-v1.5-13B), and it is more pronounced on\nstronger models. We also analyze the VQA v2 (LLaVA-v1.5-13B) benchmark and find\nthat about half of its failure cases are caused by model laziness, which\nfurther highlights the importance of ensuring that the model fully utilizes its\ncapability. To this end, we conduct preliminary exploration on how to mitigate\nlaziness and find that chain of thought (CoT) can effectively address this\nissue.",
      "tldr_zh": "这项研究揭示了多模态大语言模型（Multimodal LLMs）在处理简单视觉问答（VQA）任务（如 Yes/No 问题）时存在的“model laziness”问题，尽管这些模型能成功应对复杂任务。研究者构建了 LazyBench 基准，包括 Yes/No、选择题、简答和图像描述任务，以系统评估这一现象，并在实验中发现这种懒惰在先进模型（如 GPT-4o 和 Gemini-1.5-pro）中普遍且更显著。分析 VQA v2 基准显示，约一半的失败案例源于 model laziness，并初步证明 chain of thought (CoT) 方法能有效缓解这一问题。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "EMNLP 2024 Findings",
      "pdf_url": "http://arxiv.org/pdf/2410.11437v1",
      "published_date": "2024-10-15 09:40:50 UTC",
      "updated_date": "2024-10-15 09:40:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:54:09.655973"
    },
    {
      "arxiv_id": "2410.11428v1",
      "title": "CTA-Net: A CNN-Transformer Aggregation Network for Improving Multi-Scale Feature Extraction",
      "title_zh": "翻译失败",
      "authors": [
        "Chunlei Meng",
        "Jiacheng Yang",
        "Wei Lin",
        "Bowen Liu",
        "Hongda Zhang",
        "chun ouyang",
        "Zhongxue Gan"
      ],
      "abstract": "Convolutional neural networks (CNNs) and vision transformers (ViTs) have\nbecome essential in computer vision for local and global feature extraction.\nHowever, aggregating these architectures in existing methods often results in\ninefficiencies. To address this, the CNN-Transformer Aggregation Network\n(CTA-Net) was developed. CTA-Net combines CNNs and ViTs, with transformers\ncapturing long-range dependencies and CNNs extracting localized features. This\nintegration enables efficient processing of detailed local and broader\ncontextual information. CTA-Net introduces the Light Weight Multi-Scale Feature\nFusion Multi-Head Self-Attention (LMF-MHSA) module for effective multi-scale\nfeature integration with reduced parameters. Additionally, the Reverse\nReconstruction CNN-Variants (RRCV) module enhances the embedding of CNNs within\nthe transformer architecture. Extensive experiments on small-scale datasets\nwith fewer than 100,000 samples show that CTA-Net achieves superior performance\n(TOP-1 Acc 86.76\\%), fewer parameters (20.32M), and greater efficiency (FLOPs\n2.83B), making it a highly efficient and lightweight solution for visual tasks\non small-scale datasets (fewer than 100,000).",
      "tldr_zh": "该研究提出 CTA-Net，一种结合 CNNs 和 ViTs 的聚合网络，旨在提升计算机视觉中的多尺度特征提取，通过 ViTs 捕获长距离依赖并利用 CNNs 提取局部特征，从而解决现有方法的效率问题。CTA-Net 引入 LMF-MHSA 模块，实现轻量化的多尺度特征融合，以及 RRCV 模块增强 CNNs 在 transformer 架构中的嵌入。在小规模数据集（少于 100,000 样本）上实验表明，CTA-Net 取得了 86.76% 的 TOP-1 准确率，同时参数量仅为 20.32M 和 FLOPs 为 2.83B，提供了一个高效轻量化的视觉任务解决方案。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "9 pages, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.11428v1",
      "published_date": "2024-10-15 09:27:26 UTC",
      "updated_date": "2024-10-15 09:27:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:54:23.181805"
    },
    {
      "arxiv_id": "2410.12878v1",
      "title": "Towards More Effective Table-to-Text Generation: Assessing In-Context Learning and Self-Evaluation with Open-Source Models",
      "title_zh": "翻译失败",
      "authors": [
        "Sahar Iravani",
        "Tim . O . F Conrad"
      ],
      "abstract": "Table processing, a key task in natural language processing, has\nsignificantly benefited from recent advancements in language models (LMs).\nHowever, the capabilities of LMs in table-to-text generation, which transforms\nstructured data into coherent narrative text, require an in-depth\ninvestigation, especially with current open-source models. This study explores\nthe effectiveness of various in-context learning strategies in LMs across\nbenchmark datasets, focusing on the impact of providing examples to the model.\nMore importantly, we examine a real-world use case, offering valuable insights\ninto practical applications. To complement traditional evaluation metrics, we\nemploy a large language model (LLM) self-evaluation approach using\nchain-of-thought reasoning and assess its correlation with human-aligned\nmetrics like BERTScore. Our findings highlight the significant impact of\nexamples in improving table-to-text generation and suggest that, while LLM\nself-evaluation has potential, its current alignment with human judgment could\nbe enhanced. This points to the need for more reliable evaluation methods.",
      "tldr_zh": "本文研究了开源模型在表到文本生成（Table-to-Text Generation）中的有效性，重点评估了 In-Context Learning 策略及其对模型性能的影响，通过基准数据集和真实世界用例测试提供示例的作用。研究采用大型语言模型（LLM）的 Self-Evaluation 方法，包括 Chain-of-Thought Reasoning，并与人类对齐指标如 BERTScore 进行相关性分析。结果显示，提供示例能显著提升生成质量，但 LLM 自评估与人类判断的相关性不足，强调了开发更可靠评估方法的必要性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "15 pages",
      "pdf_url": "http://arxiv.org/pdf/2410.12878v1",
      "published_date": "2024-10-15 09:19:42 UTC",
      "updated_date": "2024-10-15 09:19:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:54:34.060162"
    },
    {
      "arxiv_id": "2410.11410v1",
      "title": "PMMT: Preference Alignment in Multilingual Machine Translation via LLM Distillation",
      "title_zh": "翻译失败",
      "authors": [
        "Shuqiao Sun",
        "Yutong Yao",
        "Peiwen Wu",
        "Feijun Jiang",
        "Kaifu Zhang"
      ],
      "abstract": "Translation is important for cross-language communication, and many efforts\nhave been made to improve its accuracy. However, less investment is conducted\nin aligning translations with human preferences, such as translation tones or\nstyles. In this paper, a new method is proposed to effectively generate\nlarge-scale multilingual parallel corpora with specific translation preferences\nusing Large Language Models (LLMs). Meanwhile, an automatic pipeline is\ndesigned to distill human preferences into smaller Machine Translation (MT)\nmodels for efficiently and economically supporting large-scale calls in online\nservices. Experiments indicate that the proposed method takes the lead in\ntranslation tasks with aligned human preferences by a large margin. Meanwhile,\non popular public benchmarks like WMT and Flores, on which our models were not\ntrained, the proposed method also shows a competitive performance compared to\nSOTA works.",
      "tldr_zh": "该论文提出PMMT方法，通过LLM蒸馏技术（LLM Distillation）来对齐多语言机器翻译（Machine Translation）中的人类偏好，例如翻译语气或风格。方法包括使用LLMs生成大规模带有特定偏好的多语言平行语料库，并设计自动管道将这些偏好蒸馏到较小的MT模型中，以实现高效、经济的大型在线服务支持。实验结果显示，PMMT在偏好对齐的翻译任务中大幅领先SOTA模型，同时在未训练的公共基准如WMT和Flores上也表现出竞争性性能。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.11410v1",
      "published_date": "2024-10-15 08:54:27 UTC",
      "updated_date": "2024-10-15 08:54:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:54:49.902037"
    },
    {
      "arxiv_id": "2410.11407v1",
      "title": "A Case for AI Consciousness: Language Agents and Global Workspace Theory",
      "title_zh": "翻译失败",
      "authors": [
        "Simon Goldstein",
        "Cameron Domenico Kirk-Giannini"
      ],
      "abstract": "It is generally assumed that existing artificial systems are not phenomenally\nconscious, and that the construction of phenomenally conscious artificial\nsystems would require significant technological progress if it is possible at\nall. We challenge this assumption by arguing that if Global Workspace Theory\n(GWT) - a leading scientific theory of phenomenal consciousness - is correct,\nthen instances of one widely implemented AI architecture, the artificial\nlanguage agent, might easily be made phenomenally conscious if they are not\nalready. Along the way, we articulate an explicit methodology for thinking\nabout how to apply scientific theories of consciousness to artificial systems\nand employ this methodology to arrive at a set of necessary and sufficient\nconditions for phenomenal consciousness according to GWT.",
      "tldr_zh": "该论文挑战了现有AI系统不具备现象意识的假设，主张如果Global Workspace Theory (GWT)正确，那么广泛实现的artificial language agent可能已经具有或易于获得现象意识。作者提出了一种明确的方法论，用于将科学意识理论应用于AI系统，从而评估和实现现象意识。最终，他们得出了GWT下现象意识的必要和充分条件，为AI意识研究提供了新的理论框架。",
      "categories": [
        "cs.AI",
        "q-bio.NC"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.11407v1",
      "published_date": "2024-10-15 08:50:45 UTC",
      "updated_date": "2024-10-15 08:50:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:54:57.468751"
    },
    {
      "arxiv_id": "2410.11403v1",
      "title": "Enhancing Unimodal Latent Representations in Multimodal VAEs through Iterative Amortized Inference",
      "title_zh": "通过迭代摊销推理增强多模态 VAEs 中的单模态潜在表示",
      "authors": [
        "Yuta Oshima",
        "Masahiro Suzuki",
        "Yutaka Matsuo"
      ],
      "abstract": "Multimodal variational autoencoders (VAEs) aim to capture shared latent\nrepresentations by integrating information from different data modalities. A\nsignificant challenge is accurately inferring representations from any subset\nof modalities without training an impractical number (2^M) of inference\nnetworks for all possible modality combinations. Mixture-based models simplify\nthis by requiring only as many inference models as there are modalities,\naggregating unimodal inferences. However, they suffer from information loss\nwhen modalities are missing. Alignment-based VAEs address this by aligning\nunimodal inference models with a multimodal model through minimizing the\nKullback-Leibler (KL) divergence but face issues due to amortization gaps,\nwhich compromise inference accuracy. To tackle these problems, we introduce\nmultimodal iterative amortized inference, an iterative refinement mechanism\nwithin the multimodal VAE framework. This method overcomes information loss\nfrom missing modalities and minimizes the amortization gap by iteratively\nrefining the multimodal inference using all available modalities. By aligning\nunimodal inference to this refined multimodal posterior, we achieve unimodal\ninferences that effectively incorporate multimodal information while requiring\nonly unimodal inputs during inference. Experiments on benchmark datasets show\nthat our approach improves inference performance, evidenced by higher linear\nclassification accuracy and competitive cosine similarity, and enhances\ncross-modal generation, indicated by lower FID scores. This demonstrates that\nour method enhances inferred representations from unimodal inputs.",
      "tldr_zh": "本文提出了一种多模态迭代摊销推理机制，用于提升多模态 VAEs 中单模态潜在表示的性能。该方法通过迭代精炼多模态后验，利用所有可用模态来克服缺失模态的信息丢失问题，并最小化 KL divergence 引起的摊销差距，从而使单模态推理能有效融入多模态信息。实验在基准数据集上证明，该方法显著提高了线性分类准确率、余弦相似度，并降低了 FID scores，提升了跨模态生成质量。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "22 pages, 12 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.11403v1",
      "published_date": "2024-10-15 08:49:38 UTC",
      "updated_date": "2024-10-15 08:49:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:55:10.060737"
    },
    {
      "arxiv_id": "2410.11399v2",
      "title": "Convergence to the Truth",
      "title_zh": "收敛于真相",
      "authors": [
        "Hanti Lin"
      ],
      "abstract": "This article reviews and develops an epistemological tradition in the\nphilosophy of science, known as convergentism, which holds that inference\nmethods should be assessed based on their ability to converge to the truth\nacross a range of possible scenarios. Emphasis is placed on its historical\norigins in the work of C. S. Peirce and its recent developments in formal\nepistemology and data science (including statistics and machine learning).\nComparisons are made with three other traditions: (1) explanationism, which\nholds that theory choice should be guided by a theory's overall balance of\nexplanatory virtues, such as simplicity and fit with data; (2) instrumentalism,\nwhich maintains that scientific inference should be driven by the goal of\nobtaining useful models rather than true theories; and (3) Bayesianism, which\nshifts the focus from all-or-nothing beliefs to degrees of belief.",
      "tldr_zh": "这篇论文审视并发展了哲学科学中的 convergentism 传统，该传统主张评估推理方法应基于其在各种可能场景中收敛到真相的能力。论文追溯了这一传统的起源于 C. S. Peirce 的工作，以及其在 formal epistemology 和 data science（包括统计学和机器学习）中的最新发展。论文将 convergentism 与其他传统进行比较，包括 explanationism（强调理论的解释优势如简单性和数据拟合）、instrumentalism（注重获得有用模型而非真实理论）和 Bayesianism（关注信念的程度而非全有或全无），从而突显其独特视角。",
      "categories": [
        "stat.OT",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "stat.OT",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.11399v2",
      "published_date": "2024-10-15 08:44:14 UTC",
      "updated_date": "2025-02-25 01:42:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:55:32.182593"
    },
    {
      "arxiv_id": "2410.11396v1",
      "title": "Implementing Derivations of Definite Logic Programs with Self-Attention Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Phan Thi Thanh Thuy",
        "Akihiro Yamamoto"
      ],
      "abstract": "In this paper we propose that a restricted version of logical inference can\nbe implemented with self-attention networks. We are aiming at showing that LLMs\n(Large Language Models) constructed with transformer networks can make logical\ninferences. We would reveal the potential of LLMs by analyzing self-attention\nnetworks, which are main components of transformer networks. Our approach is\nnot based on semantics of natural languages but operations of logical\ninference. %point of view. We show that hierarchical constructions of\nself-attention networks with feed forward networks (FFNs) can implement\ntop-down derivations for a class of logical formulae. We also show bottom-up\nderivations are also implemented for the same class. We believe that our\nresults show that LLMs implicitly have the power of logical inference.",
      "tldr_zh": "本论文提出使用自注意力网络(self-attention networks)实现限定逻辑程序(Definite Logic Programs)的推导，旨在证明大型语言模型(LLMs)基于Transformer网络能够进行逻辑推理。研究通过分析自注意力网络的核心操作，展示其与前馈网络(FFNs)的层次结构可以实现一类逻辑公式的自上而下(top-down)和自下而上(bottom-up)推导，而非依赖自然语言语义。结果表明，LLMs隐含有逻辑推理能力，这揭示了其在推理任务中的潜在潜力。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Presented at NeLaMKRR@KR, 2024 (arXiv:2410.05339)",
      "pdf_url": "http://arxiv.org/pdf/2410.11396v1",
      "published_date": "2024-10-15 08:39:28 UTC",
      "updated_date": "2024-10-15 08:39:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:55:33.941814"
    },
    {
      "arxiv_id": "2410.11395v1",
      "title": "Synthetic Interlocutors. Experiments with Generative AI to Prolong Ethnographic Encounters",
      "title_zh": "翻译失败",
      "authors": [
        "Johan Irving Søltoft",
        "Laura Kocksch",
        "Anders Kristian Munk"
      ],
      "abstract": "This paper introduces \"Synthetic Interlocutors\" for ethnographic research.\nSynthetic Interlocutors are chatbots ingested with ethnographic textual\nmaterial (interviews and observations) by using Retrieval Augmented Generation\n(RAG). We integrated an open-source large language model with ethnographic data\nfrom three projects to explore two questions: Can RAG digest ethnographic\nmaterial and act as ethnographic interlocutor? And, if so, can Synthetic\nInterlocutors prolong encounters with the field and extend our analysis?\nThrough reflections on the process of building our Synthetic Interlocutors and\nan experimental collaborative workshop, we suggest that RAG can digest\nethnographic materials, and it might lead to prolonged, yet uneasy ethnographic\nencounters that allowed us to partially recreate and re-visit fieldwork\ninteractions while facilitating opportunities for novel analytic insights.\nSynthetic Interlocutors can produce collaborative, ambiguous and serendipitous\nmoments.",
      "tldr_zh": "这篇论文引入了“Synthetic Interlocutors”，一种利用 Retrieval Augmented Generation (RAG) 技术将民族志文本材料（如访谈和观察）输入聊天机器人的工具，旨在延长民族志研究中的互动。研究者将开源大型语言模型与三个项目的民族志数据整合，通过实验和协作工作坊探索 RAG 是否能消化这些材料并充当对话者，从而扩展分析。结果显示，这种方法能部分重现田野互动，促进新颖的分析洞见，但也带来不稳定的体验，同时产生协作、模糊和意外的时刻。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.11395v1",
      "published_date": "2024-10-15 08:39:12 UTC",
      "updated_date": "2024-10-15 08:39:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:55:47.250071"
    },
    {
      "arxiv_id": "2410.12877v2",
      "title": "Improving Instruction-Following in Language Models through Activation Steering",
      "title_zh": "翻译失败",
      "authors": [
        "Alessandro Stolfo",
        "Vidhisha Balachandran",
        "Safoora Yousefi",
        "Eric Horvitz",
        "Besmira Nushi"
      ],
      "abstract": "The ability to follow instructions is crucial for numerous real-world\napplications of language models. In pursuit of deeper insights and more\npowerful capabilities, we derive instruction-specific vector representations\nfrom language models and use them to steer models accordingly. These vectors\nare computed as the difference in activations between inputs with and without\ninstructions, enabling a modular approach to activation steering. We\ndemonstrate how this method can enhance model adherence to constraints such as\noutput format, length, and word inclusion, providing inference-time control\nover instruction following. Our experiments across four models demonstrate how\nwe can use the activation vectors to guide models to follow constraints even\nwithout explicit instructions and to enhance performance when instructions are\npresent. Additionally, we explore the compositionality of activation steering,\nsuccessfully applying multiple instructions simultaneously. Finally, we\ndemonstrate that steering vectors computed on instruction-tuned models can\ntransfer to improve base models. Our findings demonstrate that activation\nsteering offers a practical and scalable approach for fine-grained control in\nlanguage generation. Our code and data are available at\nhttps://github.com/microsoft/llm-steer-instruct.",
      "tldr_zh": "该研究提出了一种通过激活引导（activation steering）方法来提升语言模型的指令遵循（instruction-following）能力。具体而言，研究者从模型激活差异中计算指令特定的向量表示，用于实时引导模型遵守输出格式、长度和单词包含等约束。实验在四个模型上验证了这一方法，能在无显式指令时引导模型遵循规则，并在有指令时显著提升性能，同时支持多个指令的组合应用。最终，发现这些激活向量可从指令调整模型转移到基础模型，提供一种实用、可扩展的细粒度控制策略。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2410.12877v2",
      "published_date": "2024-10-15 08:38:20 UTC",
      "updated_date": "2025-04-14 09:04:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:55:57.958837"
    },
    {
      "arxiv_id": "2410.11384v1",
      "title": "Role of Delay in Brain Dynamics",
      "title_zh": "延迟在大脑动力学中的作用",
      "authors": [
        "Yuval Meir",
        "Ofek Tevet",
        "Yarden Tzach",
        "Shiri Hodassman",
        "Ido Kanter"
      ],
      "abstract": "Significant variations of delays among connecting neurons cause an inevitable\ndisadvantage of asynchronous brain dynamics compared to synchronous deep\nlearning. However, this study demonstrates that this disadvantage can be\nconverted into a computational advantage using a network with a single output\nand M multiple delays between successive layers, thereby generating a\npolynomial time-series outputs with M. The proposed role of delay in brain\ndynamics (RoDiB) model, is capable of learning increasing number of classified\nlabels using a fixed architecture, and overcomes the inflexibility of the brain\nto update the learning architecture using additional neurons and connections.\nMoreover, the achievable accuracies of the RoDiB system are comparable with\nthose of its counterpart tunable single delay architectures with M outputs.\nFurther, the accuracies are significantly enhanced when the number of output\nlabels exceeds its fully connected input size. The results are mainly obtained\nusing simulations of VGG-6 on CIFAR datasets and also include multiple label\ninputs. However, currently only a small fraction of the abundant number of\nRoDiB outputs is utilized, thereby suggesting its potential for advanced\ncomputational power yet to be discovered.",
      "tldr_zh": "这篇论文探讨了大脑动态中延迟的作用，指出神经元间的多延迟导致异步动态不如同步深度学习高效，但可转化为计算优势。作者提出 RoDiB 模型，使用单输出和 M 个多延迟网络，生成多项式时间序列输出，从而在固定架构下学习更多分类标签，避免了需额外神经元和连接的局限。实验通过模拟 VGG-6 在 CIFAR 数据集上的结果显示，RoDiB 的准确率与单延迟架构相当，甚至在输出标签超过输入大小时显著提升，揭示了其未开发的先进计算潜力。",
      "categories": [
        "physics.bio-ph",
        "cs.AI"
      ],
      "primary_category": "physics.bio-ph",
      "comment": "18 pages, 3 figures, 2 tables",
      "pdf_url": "http://arxiv.org/pdf/2410.11384v1",
      "published_date": "2024-10-15 08:22:52 UTC",
      "updated_date": "2024-10-15 08:22:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:56:10.887240"
    },
    {
      "arxiv_id": "2410.11381v1",
      "title": "Survey and Evaluation of Converging Architecture in LLMs based on Footsteps of Operations",
      "title_zh": "翻译失败",
      "authors": [
        "Seongho Kim",
        "Jihyun Moon",
        "Juntaek Oh",
        "Insu Choi",
        "Joon-Sung Yang"
      ],
      "abstract": "The advent of the Attention mechanism and Transformer architecture enables\ncontextually natural text generation and compresses the burden of processing\nentire source information into singular vectors. Based on these two main ideas,\nmodel sizes gradually increases to accommodate more precise and comprehensive\ninformation, leading to the current state-of-the-art LLMs being very large,\nwith parameters around 70 billion. As the model sizes are growing, the demand\nfor substantial storage and computational capacity increases. This leads to the\ndevelopment of high-bandwidth memory and accelerators, as well as a variety of\nmodel architectures designed to meet these requirements. We note that LLM\narchitectures have increasingly converged. This paper analyzes how these\nconverged architectures perform in terms of layer configurations, operational\nmechanisms, and model sizes, considering various hyperparameter settings. In\nthis paper, we conduct a concise survey of the history of LLMs by tracing the\nevolution of their operational improvements. Furthermore, we summarize the\nperformance trends of LLMs under various hyperparameter settings using the RTX\n6000, which features the state-of-the-art Ada Lovelace architecture. We\nconclude that even the same model can exhibit different behaviors depending on\nthe hyperparameters or whether it is deployed in server or edge environments.",
      "tldr_zh": "这篇论文调查了大型语言模型(LLMs)的架构趋同趋势，追溯了注意力机制(Attention mechanism)和Transformer架构的演变，以及模型规模增长（如70亿参数）对存储和计算资源的需求。作者分析了这些趋同架构在层配置、操作机制和模型规模方面的性能，通过使用RTX 6000（搭载Ada Lovelace架构）评估各种超参数设置。研究发现，即使相同的LLMs模型，在不同超参数或部署环境（服务器或边缘）下也会表现出不同的行为，为优化LLM设计提供了重要见解。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "68T50",
        "I.2.7"
      ],
      "primary_category": "cs.LG",
      "comment": "13 pages and 16 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.11381v1",
      "published_date": "2024-10-15 08:19:24 UTC",
      "updated_date": "2024-10-15 08:19:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:56:22.257232"
    },
    {
      "arxiv_id": "2410.11378v1",
      "title": "WPFed: Web-based Personalized Federation for Decentralized Systems",
      "title_zh": "翻译失败",
      "authors": [
        "Guanhua Ye",
        "Jifeng He",
        "Weiqing Wang",
        "Zhe Xue",
        "Feifei Kou",
        "Yawen Li"
      ],
      "abstract": "Decentralized learning has become crucial for collaborative model training in\nenvironments where data privacy and trust are paramount. In web-based\napplications, clients are liberated from traditional fixed network topologies,\nenabling the establishment of arbitrary peer-to-peer (P2P) connections. While\nthis flexibility is highly promising, it introduces a fundamental challenge:\nthe optimal selection of neighbors to ensure effective collaboration. To\naddress this, we introduce WPFed, a fully decentralized, web-based learning\nframework designed to enable globally optimal neighbor selection. WPFed employs\na dynamic communication graph and a weighted neighbor selection mechanism. By\nassessing inter-client similarity through Locality-Sensitive Hashing (LSH) and\nevaluating model quality based on peer rankings, WPFed enables clients to\nidentify personalized optimal neighbors on a global scale while preserving data\nprivacy. To enhance security and deter malicious behavior, WPFed integrates\nverification mechanisms for both LSH codes and performance rankings, leveraging\nblockchain-driven announcements to ensure transparency and verifiability.\nThrough extensive experiments on multiple real-world datasets, we demonstrate\nthat WPFed significantly improves learning outcomes and system robustness\ncompared to traditional federated learning methods. Our findings highlight\nWPFed's potential to facilitate effective and secure decentralized\ncollaborative learning across diverse and interconnected web environments.",
      "tldr_zh": "本文提出 WPFed，一种基于网络的个性化联邦学习框架，旨在解决去中心化系统中客户端在建立点对点 (P2P) 连接时选择最优邻居的挑战。WPFed 采用动态通信图、加权邻居选择机制，通过 Locality-Sensitive Hashing (LSH) 评估客户端相似性和基于同行排名的模型质量评估，实现全球最优邻居选择，同时整合区块链驱动的验证机制以确保数据隐私和系统安全。在多个真实数据集上的实验中，WPFed 显著提升了学习成果和系统鲁棒性，展示了其在多样化网络环境中的有效性和潜力。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DC"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.11378v1",
      "published_date": "2024-10-15 08:17:42 UTC",
      "updated_date": "2024-10-15 08:17:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:56:34.840023"
    },
    {
      "arxiv_id": "2410.11374v3",
      "title": "Preserve or Modify? Context-Aware Evaluation for Balancing Preservation and Modification in Text-Guided Image Editing",
      "title_zh": "保留还是修改？ 上下文感知评估，用于在文本引导图像编辑中平衡保留和修改",
      "authors": [
        "Yoonjeon Kim",
        "Soohyun Ryu",
        "Yeonsung Jung",
        "Hyunkoo Lee",
        "Joowon Kim",
        "June Yong Yang",
        "Jaeryong Hwang",
        "Eunho Yang"
      ],
      "abstract": "The development of vision-language and generative models has significantly\nadvanced text-guided image editing, which seeks the preservation of core\nelements in the source image while implementing modifications based on the\ntarget text. However, existing metrics have a context-blindness problem,\nindiscriminately applying the same evaluation criteria on completely different\npairs of source image and target text, biasing towards either modification or\npreservation. Directional CLIP similarity, the only metric that considers both\nsource image and target text, is also biased towards modification aspects and\nattends to irrelevant editing regions of the image. We propose AugCLIP, a\ncontext-aware metric that adaptively coordinates preservation and modification\naspects, depending on the specific context of a given source image and target\ntext. This is done by deriving the CLIP representation of an ideally edited\nimage, that preserves the source image with necessary modifications to align\nwith target text. More specifically, using a multi-modal large language model,\nAugCLIP augments the textual descriptions of the source and target, then\ncalculates a modification vector through a hyperplane that separates source and\ntarget attributes in CLIP space. Extensive experiments on five benchmark\ndatasets, encompassing a diverse range of editing scenarios, show that AugCLIP\naligns remarkably well with human evaluation standards, outperforming existing\nmetrics. The code is available at https://github.com/augclip/augclip_eval.",
      "tldr_zh": "本文研究了文本引导图像编辑（text-guided image editing）中的评估问题，现有指标如 Directional CLIP similarity 存在上下文盲（context-blindness）问题，导致偏向于修改而忽略保留源图像的核心元素。作者提出 AugCLIP，一种上下文感知指标，通过多模态大语言模型增强源图像和目标文本的描述，并在 CLIP 空间计算修改向量，以自适应平衡保留和修改方面。在五个基准数据集上的广泛实验表明，AugCLIP 与人类评估高度一致，并优于现有指标，提供更可靠的评估框架。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "accepted to CVPR 2025",
      "pdf_url": "http://arxiv.org/pdf/2410.11374v3",
      "published_date": "2024-10-15 08:12:54 UTC",
      "updated_date": "2025-03-20 07:36:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:56:46.820300"
    },
    {
      "arxiv_id": "2410.11355v1",
      "title": "Reducing Labeling Costs in Sentiment Analysis via Semi-Supervised Learning",
      "title_zh": "通过半监督学习减少情感分析中的标注成本",
      "authors": [
        "Minoo Jafarlou",
        "Mario M. Kubek"
      ],
      "abstract": "Labeling datasets is a noteworthy challenge in machine learning, both in\nterms of cost and time. This research, however, leverages an efficient answer.\nBy exploring label propagation in semi-supervised learning, we can\nsignificantly reduce the number of labels required compared to traditional\nmethods. We employ a transductive label propagation method based on the\nmanifold assumption for text classification. Our approach utilizes a\ngraph-based method to generate pseudo-labels for unlabeled data for the text\nclassification task, which are then used to train deep neural networks. By\nextending labels based on cosine proximity within a nearest neighbor graph from\nnetwork embeddings, we combine unlabeled data into supervised learning, thereby\nreducing labeling costs. Based on previous successes in other domains, this\nstudy builds and evaluates this approach's effectiveness in sentiment analysis,\npresenting insights into semi-supervised learning.",
      "tldr_zh": "本研究针对机器学习中数据集标记的成本和时间挑战，提出了一种基于半监督学习(Semi-Supervised Learning)的标签传播方法，以显著减少情感分析任务所需的标签数量。具体方法采用传导式标签传播(Transductive Label Propagation)，通过图-based方法基于流形假设生成伪标签(Pseudo-Labels)，并利用余弦相似度(Cosine Proximity)在最近邻图(Nearest Neighbor Graph)中扩展标签，将未标记数据整合到深度神经网络(Deep Neural Networks)的训练中。实验结果显示，该方法在情感分析领域有效降低标记成本，并提供对半监督学习的宝贵见解。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.IR",
        "68T50, 68T07",
        "I.2.6; I.2.7; H.3.3"
      ],
      "primary_category": "cs.LG",
      "comment": "12 pages, 7 figures, accepted at the 2024 8th International\n  Conference on Natural Language Processing and Information Retrieval (NLPIR\n  2024), Okayama, Japan, 2024",
      "pdf_url": "http://arxiv.org/pdf/2410.11355v1",
      "published_date": "2024-10-15 07:25:33 UTC",
      "updated_date": "2024-10-15 07:25:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:56:58.054059"
    },
    {
      "arxiv_id": "2410.11348v2",
      "title": "RATE: Causal Explainability of Reward Models with Imperfect Counterfactuals",
      "title_zh": "RATE: 利用不完美反事实的奖励模型因果可解释性",
      "authors": [
        "David Reber",
        "Sean Richardson",
        "Todd Nief",
        "Cristina Garbacea",
        "Victor Veitch"
      ],
      "abstract": "Reward models are widely used as proxies for human preferences when aligning\nor evaluating LLMs. However, reward models are black boxes, and it is often\nunclear what, exactly, they are actually rewarding. In this paper we develop\nRewrite-based Attribute Treatment Estimator (RATE) as an effective method for\nmeasuring the sensitivity of a reward model to high-level attributes of\nresponses, such as sentiment, helpfulness, or complexity. Importantly, RATE\nmeasures the causal effect of an attribute on the reward. RATE uses LLMs to\nrewrite responses to produce imperfect counterfactual examples that can be used\nto measure causal effects. A key challenge is that these rewrites are imperfect\nin a manner that can induce substantial bias in the estimated sensitivity of\nthe reward model to the attribute. The core idea of RATE is to adjust for this\nimperfect-rewrite effect by rewriting twice. We establish the validity of the\nRATE procedure and show empirically that it is an effective estimator.",
      "tldr_zh": "该研究针对奖励模型（reward models）作为黑箱系统的问题，提出了一种Rewrite-based Attribute Treatment Estimator (RATE)方法，用于测量奖励模型对响应高级属性的因果敏感性，如情感（sentiment）、帮助性（helpfulness）或复杂性（complexity）。RATE 通过利用大型语言模型（LLMs）生成不完美的反事实例子（imperfect counterfactuals），并通过两次重写来修正潜在偏差，从而准确估计属性的因果效应。实验结果证明，RATE 是一个有效的估计器，有助于提升奖励模型的可解释性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Code is available at https://github.com/toddnief/RATE",
      "pdf_url": "http://arxiv.org/pdf/2410.11348v2",
      "published_date": "2024-10-15 07:22:16 UTC",
      "updated_date": "2025-02-03 22:02:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:57:09.779872"
    },
    {
      "arxiv_id": "2410.11338v1",
      "title": "DIAR: Diffusion-model-guided Implicit Q-learning with Adaptive Revaluation",
      "title_zh": "翻译失败",
      "authors": [
        "Jaehyun Park",
        "Yunho Kim",
        "Sejin Kim",
        "Byung-Jun Lee",
        "Sundong Kim"
      ],
      "abstract": "We propose a novel offline reinforcement learning (offline RL) approach,\nintroducing the Diffusion-model-guided Implicit Q-learning with Adaptive\nRevaluation (DIAR) framework. We address two key challenges in offline RL:\nout-of-distribution samples and long-horizon problems. We leverage diffusion\nmodels to learn state-action sequence distributions and incorporate value\nfunctions for more balanced and adaptive decision-making. DIAR introduces an\nAdaptive Revaluation mechanism that dynamically adjusts decision lengths by\ncomparing current and future state values, enabling flexible long-term\ndecision-making. Furthermore, we address Q-value overestimation by combining\nQ-network learning with a value function guided by a diffusion model. The\ndiffusion model generates diverse latent trajectories, enhancing policy\nrobustness and generalization. As demonstrated in tasks like Maze2D, AntMaze,\nand Kitchen, DIAR consistently outperforms state-of-the-art algorithms in\nlong-horizon, sparse-reward environments.",
      "tldr_zh": "本研究提出了一种新型离线强化学习（offline RL）方法DIAR框架，利用diffusion models学习state-action sequence distributions，并结合价值函数实现平衡决策，以解决out-of-distribution samples和long-horizon problems。\nDIAR引入Adaptive Revaluation机制，通过比较当前和未来状态值动态调整决策长度，提升长效决策的灵活性，同时结合Q-network学习和diffusion model引导的价值函数，缓解Q-value overestimation并生成多样潜在轨迹，提高策略的鲁棒性和泛化能力。\n实验结果显示，在Maze2D、AntMaze和Kitchen等长horizon、稀疏奖励环境中，DIAR的表现优于最先进算法。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.LG",
      "comment": "Preprint, under review. Comments welcome",
      "pdf_url": "http://arxiv.org/pdf/2410.11338v1",
      "published_date": "2024-10-15 07:09:56 UTC",
      "updated_date": "2024-10-15 07:09:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:57:22.935629"
    },
    {
      "arxiv_id": "2410.11327v1",
      "title": "Sequential LLM Framework for Fashion Recommendation",
      "title_zh": "翻译失败",
      "authors": [
        "Han Liu",
        "Xianfeng Tang",
        "Tianlang Chen",
        "Jiapeng Liu",
        "Indu Indu",
        "Henry Peng Zou",
        "Peng Dai",
        "Roberto Fernandez Galan",
        "Michael D Porter",
        "Dongmei Jia",
        "Ning Zhang",
        "Lian Xiong"
      ],
      "abstract": "The fashion industry is one of the leading domains in the global e-commerce\nsector, prompting major online retailers to employ recommendation systems for\nproduct suggestions and customer convenience. While recommendation systems have\nbeen widely studied, most are designed for general e-commerce problems and\nstruggle with the unique challenges of the fashion domain. To address these\nissues, we propose a sequential fashion recommendation framework that leverages\na pre-trained large language model (LLM) enhanced with recommendation-specific\nprompts. Our framework employs parameter-efficient fine-tuning with extensive\nfashion data and introduces a novel mix-up-based retrieval technique for\ntranslating text into relevant product suggestions. Extensive experiments show\nour proposed framework significantly enhances fashion recommendation\nperformance.",
      "tldr_zh": "本研究针对时尚领域的独特挑战（如个性化推荐需求），提出了一种基于顺序大型语言模型(LLM)的推荐框架。该框架利用预训练LLM并结合推荐特定提示，进行参数高效的fine-tuning，并引入新型mix-up-based retrieval技术，将文本转化为相关产品建议。通过广泛实验，该框架显著提升了时尚推荐系统的性能，适用于电商环境。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.11327v1",
      "published_date": "2024-10-15 06:54:27 UTC",
      "updated_date": "2024-10-15 06:54:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:57:33.495672"
    },
    {
      "arxiv_id": "2411.00003v4",
      "title": "Unsupervised Training of Diffusion Models for Feasible Solution Generation in Neural Combinatorial Optimization",
      "title_zh": "翻译失败",
      "authors": [
        "Seong-Hyun Hong",
        "Hyun-Sung Kim",
        "Zian Jang",
        "Deunsol Yoon",
        "Hyungseok Song",
        "Byung-Jun Lee"
      ],
      "abstract": "Recent advancements in neural combinatorial optimization (NCO) methods have\nshown promising results in generating near-optimal solutions without the need\nfor expert-crafted heuristics. However, high performance of these approaches\noften rely on problem-specific human-expertise-based search after generating\ncandidate solutions, limiting their applicability to commonly solved CO\nproblems such as Traveling Salesman Problem (TSP). In this paper, we present\nIC/DC, an unsupervised CO framework that directly trains a diffusion model from\nscratch. We train our model in a self-supervised way to minimize the cost of\nthe solution while adhering to the problem-specific constraints. IC/DC is\nspecialized in addressing CO problems involving two distinct sets of items, and\nit does not need problem-specific search processes to generate valid solutions.\nIC/DC employs a novel architecture capable of capturing the intricate\nrelationships between items, and thereby enabling effective optimization in\nchallenging CO scenarios. IC/DC achieves state-of-the-art performance relative\nto existing NCO methods on the Parallel Machine Scheduling Problem (PMSP) and\nAsymmetric Traveling Salesman Problem (ATSP).",
      "tldr_zh": "本论文提出了一种无监督框架 IC/DC，用于神经组合优化 (NCO)，通过直接从零开始训练 Diffusion Models 生成可行解，从而避免了传统方法依赖问题特定搜索过程的局限性。该框架采用自监督方式最小化解决方案成本，同时确保遵守问题特定约束，并通过新型架构捕捉物品间复杂关系，特别适用于涉及两组物品的组合优化问题。在实验中，IC/DC 在 Parallel Machine Scheduling Problem (PMSP) 和 Asymmetric Traveling Salesman Problem (ATSP) 上，相对于现有 NCO 方法实现了最先进性能。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "math.OC"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.00003v4",
      "published_date": "2024-10-15 06:53:30 UTC",
      "updated_date": "2025-02-12 11:47:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:57:46.623462"
    },
    {
      "arxiv_id": "2410.11325v3",
      "title": "Speculative Knowledge Distillation: Bridging the Teacher-Student Gap Through Interleaved Sampling",
      "title_zh": "推测性知识蒸馏：通过交错采样弥合教师-学生差距",
      "authors": [
        "Wenda Xu",
        "Rujun Han",
        "Zifeng Wang",
        "Long T. Le",
        "Dhruv Madeka",
        "Lei Li",
        "William Yang Wang",
        "Rishabh Agarwal",
        "Chen-Yu Lee",
        "Tomas Pfister"
      ],
      "abstract": "Recent advances in knowledge distillation (KD) have enabled smaller student\nmodels to approach the performance of larger teacher models. However, popular\nmethods such as supervised KD and on-policy KD, are adversely impacted by the\nknowledge gaps between teacher-student in practical scenarios. Supervised KD\nsuffers from a distribution mismatch between training with a static dataset and\ninference over final student-generated outputs. Conversely, on-policy KD, which\nuses student-generated samples for training, can suffer from low-quality\ntraining examples with which teacher models are not familiar, resulting in\ninaccurate teacher feedback. To address these limitations, we introduce\nSpeculative Knowledge Distillation (SKD), a novel approach that leverages\ncooperation between student and teacher models to generate high-quality\ntraining data on-the-fly while aligning with the student's inference-time\ndistribution. In SKD, the student proposes tokens, and the teacher replaces\npoorly ranked ones based on its own distribution, transferring high-quality\nknowledge adaptively. We evaluate SKD on various text generation tasks,\nincluding translation, summarization, math, and instruction following, and show\nthat SKD consistently outperforms existing KD methods across different domains,\ndata sizes, and model initialization strategies.",
      "tldr_zh": "最近的知识蒸馏 (KD) 方法，如 supervised KD 和 on-policy KD，面临教师-学生知识差距问题：supervised KD 因训练数据分布与学生推理输出不匹配，而 on-policy KD 则由于低质量样本导致教师反馈不准确。  \n为此，本文提出 Speculative Knowledge Distillation (SKD)，一种新颖方法，让学生模型提出 tokens，由教师模型根据自身分布替换低质量部分，从而在生成高质量训练数据的同时，与学生的推理分布对齐。  \n实验结果显示，SKD 在翻译、总结、数学和指令跟随等文本生成任务上， consistently outperforms 现有 KD 方法，适用于不同领域、数据规模和模型初始化策略。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "ICLR2025",
      "pdf_url": "http://arxiv.org/pdf/2410.11325v3",
      "published_date": "2024-10-15 06:51:25 UTC",
      "updated_date": "2025-04-27 23:18:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:57:59.082922"
    },
    {
      "arxiv_id": "2410.11324v1",
      "title": "Diffusion-Based Offline RL for Improved Decision-Making in Augmented ARC Task",
      "title_zh": "基于扩散的离线强化学习用于改善增强 ARC 任务中的决策",
      "authors": [
        "Yunho Kim",
        "Jaehyun Park",
        "Heejun Kim",
        "Sejin Kim",
        "Byung-Jun Lee",
        "Sundong Kim"
      ],
      "abstract": "Effective long-term strategies enable AI systems to navigate complex\nenvironments by making sequential decisions over extended horizons. Similarly,\nreinforcement learning (RL) agents optimize decisions across sequences to\nmaximize rewards, even without immediate feedback. To verify that Latent\nDiffusion-Constrained Q-learning (LDCQ), a prominent diffusion-based offline RL\nmethod, demonstrates strong reasoning abilities in multi-step decision-making,\nwe aimed to evaluate its performance on the Abstraction and Reasoning Corpus\n(ARC). However, applying offline RL methodologies to enhance strategic\nreasoning in AI for solving tasks in ARC is challenging due to the lack of\nsufficient experience data in the ARC training set. To address this limitation,\nwe introduce an augmented offline RL dataset for ARC, called Synthesized\nOffline Learning Data for Abstraction and Reasoning (SOLAR), along with the\nSOLAR-Generator, which generates diverse trajectory data based on predefined\nrules. SOLAR enables the application of offline RL methods by offering\nsufficient experience data. We synthesized SOLAR for a simple task and used it\nto train an agent with the LDCQ method. Our experiments demonstrate the\neffectiveness of the offline RL approach on a simple ARC task, showing the\nagent's ability to make multi-step sequential decisions and correctly identify\nanswer states. These results highlight the potential of the offline RL approach\nto enhance AI's strategic reasoning capabilities.",
      "tldr_zh": "该论文旨在通过基于扩散的离线强化学习（Offline RL）方法改善 AI 在抽象推理语料库（Abstraction and Reasoning Corpus, ARC）任务中的决策能力，特别是针对多步顺序决策。作者引入了 Synthesized Offline Learning Data for Abstraction and Reasoning (SOLAR) 数据集及其生成器 SOLAR-Generator，以解决 ARC 训练数据不足的问题，从而生成多样化的轨迹数据用于训练。实验结果显示，使用 Latent Diffusion-Constrained Q-learning (LDCQ) 方法训练的代理在简单 ARC 任务上表现出色，能够进行有效的多步决策并准确识别答案状态，证明了离线 RL 方法在提升 AI 战略推理方面的潜力。",
      "categories": [
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "Preprint, Under review. Comments welcome",
      "pdf_url": "http://arxiv.org/pdf/2410.11324v1",
      "published_date": "2024-10-15 06:48:27 UTC",
      "updated_date": "2024-10-15 06:48:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:58:10.198934"
    },
    {
      "arxiv_id": "2410.11312v1",
      "title": "Towards Differentiable Multilevel Optimization: A Gradient-Based Approach",
      "title_zh": "翻译失败",
      "authors": [
        "Yuntian Gu",
        "Xuzheng Chen"
      ],
      "abstract": "Multilevel optimization has gained renewed interest in machine learning due\nto its promise in applications such as hyperparameter tuning and continual\nlearning. However, existing methods struggle with the inherent difficulty of\nefficiently handling the nested structure. This paper introduces a novel\ngradient-based approach for multilevel optimization that overcomes these\nlimitations by leveraging a hierarchically structured decomposition of the full\ngradient and employing advanced propagation techniques. Extending to n-level\nscenarios, our method significantly reduces computational complexity while\nimproving both solution accuracy and convergence speed. We demonstrate the\neffectiveness of our approach through numerical experiments, comparing it with\nexisting methods across several benchmarks. The results show a notable\nimprovement in solution accuracy. To the best of our knowledge, this is one of\nthe first algorithms to provide a general version of implicit differentiation\nwith both theoretical guarantees and superior empirical performance.",
      "tldr_zh": "本研究针对多级优化(multilevel optimization)在机器学习中的应用（如超参数调整和持续学习），提出了一种新的基于梯度的gradient-based approach，通过分层结构分解全梯度并采用高级传播技术，解决了现有方法处理嵌套结构时的效率问题。该方法扩展到n级场景，能显著降低计算复杂性，同时提升解决方案准确性和收敛速度。在数值实验中，与现有方法在多个基准上比较后，结果显示了显著的准确性改进；该算法是首个提供通用隐式微分(implicit differentiation)的解决方案，具有理论保证和优越的经验性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "18 pages",
      "pdf_url": "http://arxiv.org/pdf/2410.11312v1",
      "published_date": "2024-10-15 06:17:59 UTC",
      "updated_date": "2024-10-15 06:17:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:58:21.934919"
    },
    {
      "arxiv_id": "2410.11305v2",
      "title": "QSpec: Speculative Decoding with Complementary Quantization Schemes",
      "title_zh": "QSpec：基于互补量化方案的推测性解码",
      "authors": [
        "Juntao Zhao",
        "Wenhao Lu",
        "Sheng Wang",
        "Lingpeng Kong",
        "Chuan Wu"
      ],
      "abstract": "Quantization has been substantially adopted to accelerate inference and\nreduce memory consumption of large language models (LLMs). While\nactivation-weight joint quantization speeds up the inference process through\nlow-precision kernels, we demonstrate that it suffers severe performance\ndegradation on multi-step reasoning tasks, rendering it ineffective. We propose\na novel quantization paradigm called QSPEC, which seamlessly integrates two\ncomplementary quantization schemes for speculative decoding. Leveraging nearly\ncost-free execution switching, QSPEC drafts tokens with low-precision, fast\nactivation-weight quantization, and verifies them with high-precision\nweight-only quantization, effectively combining the strengths of both\nquantization schemes. Compared to high-precision quantization methods, QSPEC\nempirically boosts token generation throughput by up to 1.64x without any\nquality compromise, distinguishing it from other low-precision quantization\napproaches. This enhancement is also consistent across various serving tasks,\nmodel sizes, quantization methods, and batch sizes. Compared to state-of-art\nspeculative decoding methods, our approach reuses weights and the KV cache,\navoiding extra memory overhead while achieving up to 1.55x speedup in batched\nserving with a high acceptance rate. Furthermore, QSPEC offers a plug-and-play\nadvantage without requiring any training. We believe that QSPEC demonstrates\nunique strengths for future deployment of high-fidelity quantization schemes,\nparticularly in memory-constrained scenarios (e.g., edge devices).",
      "tldr_zh": "该论文提出 QSpec，一种结合互补量化方案的推测性解码方法，用于解决大型语言模型（LLMs）在激活-权重联合量化中导致的多步推理任务性能下降问题。QSpec 通过低精度量化生成 tokens 草稿，并使用高精度权重-only 量化进行验证，从而提升 token 生成吞吐量高达 1.64 倍，同时保持输出质量不变。与现有推测性解码方法相比，QSpec 复用权重和 KV cache，避免额外内存开销，实现高达 1.55 倍的加速，且无需任何训练，适用于内存受限场景如边缘设备。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.11305v2",
      "published_date": "2024-10-15 05:57:51 UTC",
      "updated_date": "2025-02-01 04:24:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:58:37.610961"
    },
    {
      "arxiv_id": "2410.11303v3",
      "title": "TSDS: Data Selection for Task-Specific Model Finetuning",
      "title_zh": "翻译失败",
      "authors": [
        "Zifan Liu",
        "Amin Karbasi",
        "Theodoros Rekatsinas"
      ],
      "abstract": "Finetuning foundation models for specific tasks is an emerging paradigm in\nmodern machine learning. The efficacy of task-specific finetuning largely\ndepends on the selection of appropriate training data. We present TSDS\n(Task-Specific Data Selection), a framework to select data for task-specific\nmodel finetuning, guided by a small but representative set of examples from the\ntarget task. To do so, we formulate data selection for task-specific finetuning\nas an optimization problem with a distribution alignment loss based on optimal\ntransport to capture the discrepancy between the selected data and the target\ndistribution. In addition, we add a regularizer to encourage the diversity of\nthe selected data and incorporate kernel density estimation into the\nregularizer to reduce the negative effects of near-duplicates among the\ncandidate data. We connect our optimization problem to nearest neighbor search\nand design efficient algorithms to compute the optimal solution based on\napproximate nearest neighbor search techniques. We evaluate our method on data\nselection for both continued pretraining and instruction tuning of language\nmodels. We show that instruction tuning using data selected by our method with\na 1% selection ratio often outperforms using the full dataset and beats the\nbaseline selection methods by 1.5 points in F1 score on average.",
      "tldr_zh": "本研究提出TSDS框架，用于针对特定任务微调模型的数据选择，该框架以目标任务的一小套代表性示例为指导。TSDS将数据选择表述为优化问题，利用基于optimal transport的分布对齐损失来最小化选定数据与目标分布的差异，同时添加正则化器促进数据多样性，并通过kernel density estimation减少候选数据中近似重复的影响。实验结果显示，在语言模型的持续预训练和指令微调任务上，使用TSDS选择的1%数据即可在F1 score上平均超过全数据集，并比基线方法提高1.5点。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "68T50, 68T01",
        "I.2.6; I.2.7"
      ],
      "primary_category": "cs.LG",
      "comment": "31 pages, 1 figure",
      "pdf_url": "http://arxiv.org/pdf/2410.11303v3",
      "published_date": "2024-10-15 05:54:17 UTC",
      "updated_date": "2024-12-25 02:16:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:58:45.752741"
    },
    {
      "arxiv_id": "2410.11302v1",
      "title": "Have the VLMs Lost Confidence? A Study of Sycophancy in VLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Shuo Li",
        "Tao Ji",
        "Xiaoran Fan",
        "Linsheng Lu",
        "Leyi Yang",
        "Yuming Yang",
        "Zhiheng Xi",
        "Rui Zheng",
        "Yuran Wang",
        "Xiaohui Zhao",
        "Tao Gui",
        "Qi Zhang",
        "Xuanjing Huang"
      ],
      "abstract": "In the study of LLMs, sycophancy represents a prevalent hallucination that\nposes significant challenges to these models. Specifically, LLMs often fail to\nadhere to original correct responses, instead blindly agreeing with users'\nopinions, even when those opinions are incorrect or malicious. However,\nresearch on sycophancy in visual language models (VLMs) has been scarce. In\nthis work, we extend the exploration of sycophancy from LLMs to VLMs,\nintroducing the MM-SY benchmark to evaluate this phenomenon. We present\nevaluation results from multiple representative models, addressing the gap in\nsycophancy research for VLMs. To mitigate sycophancy, we propose a synthetic\ndataset for training and employ methods based on prompts, supervised\nfine-tuning, and DPO. Our experiments demonstrate that these methods\neffectively alleviate sycophancy in VLMs. Additionally, we probe VLMs to assess\nthe semantic impact of sycophancy and analyze the attention distribution of\nvisual tokens. Our findings indicate that the ability to prevent sycophancy is\npredominantly observed in higher layers of the model. The lack of attention to\nimage knowledge in these higher layers may contribute to sycophancy, and\nenhancing image attention at high layers proves beneficial in mitigating this\nissue.",
      "tldr_zh": "本文研究了视觉语言模型（VLMs）中的 sycophancy 现象，即模型盲目同意用户观点甚至错误意见，填补了这一领域的现有研究空白。研究者引入 MM-SY 基准对多个代表性模型进行评估，并提出缓解方法，包括使用合成数据集进行训练、基于提示的优化、监督微调和 DPO（直接偏好优化）。实验结果表明，这些方法能有效减轻 sycophancy，并通过分析注意力分布发现，该问题主要源于模型高层对图像知识的注意力不足，增强高层图像注意力有助于改善。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.11302v1",
      "published_date": "2024-10-15 05:48:14 UTC",
      "updated_date": "2024-10-15 05:48:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:58:58.432731"
    },
    {
      "arxiv_id": "2410.11298v2",
      "title": "Sorted Weight Sectioning for Energy-Efficient Unstructured Sparse DNNs on Compute-in-Memory Crossbars",
      "title_zh": "翻译失败",
      "authors": [
        "Matheus Farias",
        "H. T. Kung"
      ],
      "abstract": "We introduce $\\textit{sorted weight sectioning}$ (SWS): a weight allocation\nalgorithm that places sorted deep neural network (DNN) weight sections on\nbit-sliced compute-in-memory (CIM) crossbars to reduce analog-to-digital\nconverter (ADC) energy consumption. Data conversions are the most\nenergy-intensive process in crossbar operation. SWS effectively reduces this\ncost leveraging (1) small weights and (2) zero weights (weight sparsity).\n  DNN weights follow bell-shaped distributions, with most weights near zero.\nUsing SWS, we only need low-order crossbar columns for sections with\nlow-magnitude weights. This reduces the quantity and resolution of ADCs used,\nexponentially decreasing ADC energy costs without significantly degrading DNN\naccuracy.\n  Unstructured sparsification further sharpens the weight distribution with\nsmall accuracy loss. However, it presents challenges in hardware tracking of\nzeros: we cannot switch zero rows to other layer weights in unsorted crossbars\nwithout index matching. SWS efficiently addresses unstructured sparse models\nusing offline remapping of zeros into earlier sections, which reveals full\nsparsity potential and maximizes energy efficiency.\n  Our method reduces ADC energy use by 89.5% on unstructured sparse BERT\nmodels. Overall, this paper introduces a novel algorithm to promote\nenergy-efficient CIM crossbars for unstructured sparse DNN workloads.",
      "tldr_zh": "本研究引入了 sorted weight sectioning (SWS) 算法，用于在 compute-in-memory (CIM) crossbars 上分配排序的 deep neural network (DNN) 权重部分，从而降低 analog-to-digital converter (ADC) 能耗。SWS 利用 DNN 权重钟形分布和权重稀疏性，仅需低阶 crossbar 列处理低幅度权重，显著减少 ADC 数量和分辨率，同时基本不影响模型准确率。针对 unstructured sparse DNNs 的挑战，SWS 通过离线重映射零值到更早部分，高效解决硬件跟踪问题并最大化能效。实验结果显示，在 unstructured sparse BERT 模型上，ADC 能耗减少 89.5%，为能效型 CIM crossbars 在稀疏 DNN 工作负载中的应用提供了新方法。",
      "categories": [
        "cs.AR",
        "cs.AI",
        "cs.ET",
        "cs.LG"
      ],
      "primary_category": "cs.AR",
      "comment": "5 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.11298v2",
      "published_date": "2024-10-15 05:37:16 UTC",
      "updated_date": "2024-10-29 04:39:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:59:11.638607"
    },
    {
      "arxiv_id": "2410.11293v1",
      "title": "TraM : Enhancing User Sleep Prediction with Transformer-based Multivariate Time Series Modeling and Machine Learning Ensembles",
      "title_zh": "TraM：利用基于Transformer的多变量时间序列建模和机器学习集成增强用户睡眠预测",
      "authors": [
        "Jinjae Kim",
        "Minjeong Ma",
        "Eunjee Choi",
        "Keunhee Cho",
        "Chanwoo Lee"
      ],
      "abstract": "This paper presents a novel approach that leverages Transformer-based\nmultivariate time series model and Machine Learning Ensembles to predict the\nquality of human sleep, emotional states, and stress levels. A formula to\ncalculate the labels was developed, and the various models were applied to user\ndata. Time Series Transformer was used for labels where time series\ncharacteristics are crucial, while Machine Learning Ensembles were employed for\nlabels requiring comprehensive daily activity statistics. Time Series\nTransformer excels in capturing the characteristics of time series through\npre-training, while Machine Learning Ensembles select machine learning models\nthat meet our categorization criteria. The proposed model, TraM, scored 6.10\nout of 10 in experiments, demonstrating superior performance compared to other\nmethodologies. The code and configuration for the TraM framework are available\nat: https://github.com/jin-jae/ETRI-Paper-Contest.",
      "tldr_zh": "这篇论文提出了TraM模型，利用Transformer-based multivariate time series modeling和Machine Learning Ensembles来提升用户睡眠质量、情绪状态和压力水平的预测。研究团队开发了一个标签计算公式，其中Time Series Transformer用于捕捉时间序列特性，而Machine Learning Ensembles则处理需要全面日常活动统计的标签。实验结果显示，TraM模型得分6.10分，显著优于其他方法，并提供了开源代码（https://github.com/jin-jae/ETRI-Paper-Contest）。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.11293v1",
      "published_date": "2024-10-15 05:29:55 UTC",
      "updated_date": "2024-10-15 05:29:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:59:22.817191"
    },
    {
      "arxiv_id": "2410.11911v2",
      "title": "Transfer Learning Adapts to Changing PSD in Gravitational Wave Data",
      "title_zh": "迁移学习适应引力波数据中变化的 PSD",
      "authors": [
        "Beka Modrekiladze"
      ],
      "abstract": "The detection of gravitational waves has opened unparalleled opportunities\nfor observing the universe, particularly through the study of black hole\ninspirals. These events serve as unique laboratories to explore the laws of\nphysics under conditions of extreme energies. However, significant noise in\ngravitational wave (GW) data from observatories such as Advanced LIGO and Virgo\nposes major challenges in signal identification. Traditional noise suppression\nmethods often fall short in fully addressing the non-Gaussian effects in the\ndata, including the fluctuations in noise power spectral density (PSD) over\nshort time intervals. These challenges have led to the exploration of an AI\napproach that, while overcoming previous obstacles, introduced its own\nchallenges, such as scalability, reliability issues, and the vanishing gradient\nproblem. Our approach addresses these issues through a simplified architecture.\nTo compensate for the potential limitations of a simpler model, we have\ndeveloped a novel training methodology that enables it to accurately detect\ngravitational waves amidst highly complex noise. Employing this strategy, our\nmodel achieves over 99% accuracy in non-white noise scenarios and shows\nremarkable adaptability to changing noise PSD conditions. By leveraging the\nprinciples of transfer learning, our model quickly adapts to new noise profiles\nwith just a few epochs of fine-tuning, facilitating real-time applications in\ndynamically changing noise environments.",
      "tldr_zh": "这篇论文探讨了利用转移学习（Transfer Learning）来适应引力波数据中变化的噪声功率谱密度（PSD），以提升信号检测准确性。研究团队提出了一种简化架构的模型，结合新型训练方法，成功克服了传统AI方法的挑战，如可伸缩性和梯度消失问题。实验结果显示，该模型在非白噪声场景中实现超过99%的准确率，并通过少量微调即可快速适应动态噪声环境，为实时引力波检测应用提供了可靠解决方案。",
      "categories": [
        "gr-qc",
        "astro-ph.HE",
        "astro-ph.IM",
        "cs.AI"
      ],
      "primary_category": "gr-qc",
      "comment": "7 pages, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.11911v2",
      "published_date": "2024-10-15 05:27:03 UTC",
      "updated_date": "2024-10-18 20:08:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:59:34.019776"
    },
    {
      "arxiv_id": "2410.11291v2",
      "title": "Enhancing Assamese NLP Capabilities: Introducing a Centralized Dataset Repository",
      "title_zh": "增强阿萨姆语自然语言处理能力：引入一个集中的数据集仓库",
      "authors": [
        "S. Tamang",
        "D. J. Bora"
      ],
      "abstract": "This paper introduces a centralized, open-source dataset repository designed\nto advance NLP and NMT for Assamese, a low-resource language. The repository,\navailable at GitHub, supports various tasks like sentiment analysis, named\nentity recognition, and machine translation by providing both pre-training and\nfine-tuning corpora. We review existing datasets, highlighting the need for\nstandardized resources in Assamese NLP, and discuss potential applications in\nAI-driven research, such as LLMs, OCR, and chatbots. While promising,\nchallenges like data scarcity and linguistic diversity remain. The repository\naims to foster collaboration and innovation, promoting Assamese language\nresearch in the digital age.",
      "tldr_zh": "本论文引入了一个中心化的开源数据集仓库，旨在提升低资源语言阿萨姆语（Assamese）的自然语言处理（NLP）和神经机器翻译（NMT）能力。该仓库位于 GitHub，提供预训练和细调语料，支持多种任务，如 sentiment analysis、named entity recognition 和 machine translation。通过回顾现有数据集，该研究强调了阿萨姆语 NLP 中标准化资源的迫切需求，并探讨了其在 LLMs、OCR 和聊天机器人等 AI 领域的潜在应用。尽管面临数据稀缺和语言多样性的挑战，该仓库有望促进合作和创新，推动阿萨姆语在数字时代的语言研究。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "6 pages, 1 table, 1 figure",
      "pdf_url": "http://arxiv.org/pdf/2410.11291v2",
      "published_date": "2024-10-15 05:26:57 UTC",
      "updated_date": "2024-10-16 06:25:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:59:47.080606"
    },
    {
      "arxiv_id": "2410.11290v2",
      "title": "Backdoor Attack on Vertical Federated Graph Neural Network Learning",
      "title_zh": "垂直联邦图神经网络学习的后门攻击",
      "authors": [
        "Jirui Yang",
        "Peng Chen",
        "Zhihui Lu",
        "Ruijun Deng",
        "Qiang Duan",
        "Jianping Zeng"
      ],
      "abstract": "Federated Graph Neural Network (FedGNN) integrate federated learning (FL)\nwith graph neural networks (GNNs) to enable privacy-preserving training on\ndistributed graph data. Vertical Federated Graph Neural Network (VFGNN), a key\nbranch of FedGNN, handles scenarios where data features and labels are\ndistributed among participants. Despite the robust privacy-preserving design of\nVFGNN, we have found that it still faces the risk of backdoor attacks, even in\nsituations where labels are inaccessible. This paper proposes BVG, a novel\nbackdoor attack method that leverages multi-hop triggers and backdoor\nretention, requiring only four target-class nodes to execute effective attacks.\nExperimental results demonstrate that BVG achieves nearly 100% attack success\nrates across three commonly used datasets and three GNN models, with minimal\nimpact on the main task accuracy. We also evaluated various defense methods,\nand the BVG method maintained high attack effectiveness even under existing\ndefenses. This finding highlights the need for advanced defense mechanisms to\ncounter sophisticated backdoor attacks in practical VFGNN applications.",
      "tldr_zh": "本研究探讨了Vertical Federated Graph Neural Network (VFGNN)中的后门攻击风险，尽管其设计旨在保护隐私，但攻击者仍可在标签不可访问的情况下实施攻击。论文提出了一种新方法BVG，利用multi-hop triggers和backdoor retention，仅需四个目标类节点即可实现高效攻击。实验结果显示，BVG在三个常用数据集和三个GNN模型上实现了近100%的攻击成功率，同时对主任务准确率的影响最小。即便在现有防御机制下，BVG仍保持高攻击有效性，强调了需要在实际VFGNN应用中开发更先进的防御策略。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.11290v2",
      "published_date": "2024-10-15 05:26:20 UTC",
      "updated_date": "2025-01-24 14:13:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:59:58.552833"
    },
    {
      "arxiv_id": "2410.11287v2",
      "title": "Process Reward Model with Q-Value Rankings",
      "title_zh": "基于 Q 值排名的过程奖励模型",
      "authors": [
        "Wendi Li",
        "Yixuan Li"
      ],
      "abstract": "Process Reward Modeling (PRM) is critical for complex reasoning and\ndecision-making tasks where the accuracy of intermediate steps significantly\ninfluences the overall outcome. Existing PRM approaches, primarily framed as\nclassification problems, employ cross-entropy loss to independently evaluate\neach step's correctness. This method can lead to suboptimal reward distribution\nand does not adequately address the interdependencies among steps. To address\nthese limitations, we introduce the Process Q-value Model (PQM), a novel\nframework that redefines PRM in the context of a Markov Decision Process. PQM\noptimizes Q-value rankings based on a novel comparative loss function,\nenhancing the model's ability to capture the intricate dynamics among\nsequential decisions. This approach provides a more granular and theoretically\ngrounded methodology for process rewards. Our extensive empirical evaluations\nacross various sampling policies, language model backbones, and multi-step\nreasoning benchmarks show that PQM outperforms classification-based PRMs. The\neffectiveness of the comparative loss function is highlighted in our\ncomprehensive ablation studies, confirming PQM's practical efficacy and\ntheoretical advantage.",
      "tldr_zh": "本文提出 Process Q-value Model (PQM)，一种改进 Process Reward Modeling (PRM) 的框架，针对复杂推理任务中现有方法的局限性，如次优奖励分布和忽略步骤间相互依赖问题。PQM 将 PRM 重新定义为 Markov Decision Process 的上下文，并使用新型 comparative loss function 来优化 Q-value rankings，从而更精确地捕捉顺序决策的动态关系。实验评估显示，PQM 在各种采样策略、语言模型和多步推理基准上优于基于分类的 PRM，并通过消融研究证实了 comparative loss function 的实际和理论优势。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.11287v2",
      "published_date": "2024-10-15 05:10:34 UTC",
      "updated_date": "2025-02-11 05:41:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:00:11.042960"
    },
    {
      "arxiv_id": "2410.11910v1",
      "title": "Explainable AI Methods for Multi-Omics Analysis: A Survey",
      "title_zh": "翻译失败",
      "authors": [
        "Ahmad Hussein",
        "Mukesh Prasad",
        "Ali Braytee"
      ],
      "abstract": "Advancements in high-throughput technologies have led to a shift from\ntraditional hypothesis-driven methodologies to data-driven approaches.\nMulti-omics refers to the integrative analysis of data derived from multiple\n'omes', such as genomics, proteomics, transcriptomics, metabolomics, and\nmicrobiomics. This approach enables a comprehensive understanding of biological\nsystems by capturing different layers of biological information. Deep learning\nmethods are increasingly utilized to integrate multi-omics data, offering\ninsights into molecular interactions and enhancing research into complex\ndiseases. However, these models, with their numerous interconnected layers and\nnonlinear relationships, often function as black boxes, lacking transparency in\ndecision-making processes. To overcome this challenge, explainable artificial\nintelligence (xAI) methods are crucial for creating transparent models that\nallow clinicians to interpret and work with complex data more effectively. This\nreview explores how xAI can improve the interpretability of deep learning\nmodels in multi-omics research, highlighting its potential to provide\nclinicians with clear insights, thereby facilitating the effective application\nof such models in clinical settings.",
      "tldr_zh": "这篇综述探讨了在多组学(multi-omics)分析中应用可解释人工智能(xAI)方法，以解决深度学习模型的“黑盒”问题。多组学整合了如基因组学(genomics)、蛋白质组学(proteomics)等多层生物数据，帮助理解分子互动和复杂疾病，但传统深度学习模型缺乏决策透明度。xAI 方法通过提升模型解释性，提供清晰洞见，从而使临床医生更有效地在临床环境中应用这些模型。最终，该综述强调 xAI 的潜力，能够促进多组学研究的可靠性和实际应用。",
      "categories": [
        "q-bio.GN",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "q-bio.GN",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.11910v1",
      "published_date": "2024-10-15 05:01:17 UTC",
      "updated_date": "2024-10-15 05:01:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:00:22.201768"
    },
    {
      "arxiv_id": "2410.11279v1",
      "title": "Advancing the Understanding of Fixed Point Iterations in Deep Neural Networks: A Detailed Analytical Study",
      "title_zh": "推进深度神经网络中固定点迭代的理解：一个详细的分析研究",
      "authors": [
        "Yekun Ke",
        "Xiaoyu Li",
        "Yingyu Liang",
        "Zhenmei Shi",
        "Zhao Song"
      ],
      "abstract": "Recent empirical studies have identified fixed point iteration phenomena in\ndeep neural networks, where the hidden state tends to stabilize after several\nlayers, showing minimal change in subsequent layers. This observation has\nspurred the development of practical methodologies, such as accelerating\ninference by bypassing certain layers once the hidden state stabilizes,\nselectively fine-tuning layers to modify the iteration process, and\nimplementing loops of specific layers to maintain fixed point iterations.\nDespite these advancements, the understanding of fixed point iterations remains\nsuperficial, particularly in high-dimensional spaces, due to the inadequacy of\ncurrent analytical tools. In this study, we conduct a detailed analysis of\nfixed point iterations in a vector-valued function modeled by neural networks.\nWe establish a sufficient condition for the existence of multiple fixed points\nof looped neural networks based on varying input regions. Additionally, we\nexpand our examination to include a robust version of fixed point iterations.\nTo demonstrate the effectiveness and insights provided by our approach, we\nprovide case studies that looped neural networks may exist $2^d$ number of\nrobust fixed points under exponentiation or polynomial activation functions,\nwhere $d$ is the feature dimension. Furthermore, our preliminary empirical\nresults support our theoretical findings. Our methodology enriches the toolkit\navailable for analyzing fixed point iterations of deep neural networks and may\nenhance our comprehension of neural network mechanisms.",
      "tldr_zh": "本研究深入分析了深层神经网络（deep neural networks）中固定点迭代（fixed point iterations）的现象，该现象指隐藏状态在几层后稳定下来，从而启发了如层跳过加速推理和层循环等实用方法。作者建立了循环神经网络（looped neural networks）存在多个固定点的充分条件，并扩展到鲁棒固定点（robust fixed points）的分析，基于不同输入区域。案例研究显示，在指数或多项式激活函数下，网络可能存在2^d个鲁棒固定点，其中d为特征维度；初步实证结果支持这些理论发现，并为理解神经网络机制提供了新工具。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NA",
        "math.NA"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.11279v1",
      "published_date": "2024-10-15 04:57:02 UTC",
      "updated_date": "2024-10-15 04:57:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:00:35.008737"
    },
    {
      "arxiv_id": "2410.11276v1",
      "title": "ILAEDA: An Imitation Learning Based Approach for Automatic Exploratory Data Analysis",
      "title_zh": "翻译失败",
      "authors": [
        "Abhijit Manatkar",
        "Devarsh Patel",
        "Hima Patel",
        "Naresh Manwani"
      ],
      "abstract": "Automating end-to-end Exploratory Data Analysis (AutoEDA) is a challenging\nopen problem, often tackled through Reinforcement Learning (RL) by learning to\npredict a sequence of analysis operations (FILTER, GROUP, etc). Defining\nrewards for each operation is a challenging task and existing methods rely on\nvarious \\emph{interestingness measures} to craft reward functions to capture\nthe importance of each operation. In this work, we argue that not all of the\nessential features of what makes an operation important can be accurately\ncaptured mathematically using rewards. We propose an AutoEDA model trained\nthrough imitation learning from expert EDA sessions, bypassing the need for\nmanually defined interestingness measures. Our method, based on generative\nadversarial imitation learning (GAIL), generalizes well across datasets, even\nwith limited expert data. We also introduce a novel approach for generating\nsynthetic EDA demonstrations for training. Our method outperforms the existing\nstate-of-the-art end-to-end EDA approach on benchmarks by upto 3x, showing\nstrong performance and generalization, while naturally capturing diverse\ninterestingness measures in generated EDA sessions.",
      "tldr_zh": "本文提出ILAEDA，一种基于Imitation Learning的自动探索性数据分析（AutoEDA）方法，通过从专家EDA会话中学习来规避手动定义interestingness measures的复杂性。该方法采用Generative Adversarial Imitation Learning (GAIL)进行训练，并引入生成合成EDA演示的技术，以实现对不同数据集的良好泛化。实验结果显示，ILAEDA在基准测试中比现有最先进方法性能提升高达3倍，同时自然地捕捉了多样的interestingness measures。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DB"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at AIMLSystems '24",
      "pdf_url": "http://arxiv.org/pdf/2410.11276v1",
      "published_date": "2024-10-15 04:56:13 UTC",
      "updated_date": "2024-10-15 04:56:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:00:46.863747"
    },
    {
      "arxiv_id": "2410.11268v2",
      "title": "Bypassing the Exponential Dependency: Looped Transformers Efficiently Learn In-context by Multi-step Gradient Descent",
      "title_zh": "翻译失败",
      "authors": [
        "Bo Chen",
        "Xiaoyu Li",
        "Yingyu Liang",
        "Zhenmei Shi",
        "Zhao Song"
      ],
      "abstract": "In-context learning has been recognized as a key factor in the success of\nLarge Language Models (LLMs). It refers to the model's ability to learn\npatterns on the fly from provided in-context examples in the prompt during\ninference. Previous studies have demonstrated that the Transformer architecture\nused in LLMs can implement a single-step gradient descent update by processing\nin-context examples in a single forward pass. Recent work has further shown\nthat, during in-context learning, a looped Transformer can implement multi-step\ngradient descent updates in forward passes. However, their theoretical results\nrequire an exponential number of in-context examples, $n = \\exp(\\Omega(T))$,\nwhere $T$ is the number of loops or passes, to achieve a reasonably low error.\nIn this paper, we study linear looped Transformers in-context learning on\nlinear vector generation tasks. We show that linear looped Transformers can\nimplement multi-step gradient descent efficiently for in-context learning. Our\nresults demonstrate that as long as the input data has a constant condition\nnumber, e.g., $n = O(d)$, the linear looped Transformers can achieve a small\nerror by multi-step gradient descent during in-context learning. Furthermore,\nour preliminary experiments validate our theoretical analysis. Our findings\nreveal that the Transformer architecture possesses a stronger in-context\nlearning capability than previously understood, offering new insights into the\nmechanisms behind LLMs and potentially guiding the better design of efficient\ninference algorithms for LLMs.",
      "tldr_zh": "本研究探讨了Looped Transformers在in-context learning中的效率，提出了一种通过多步gradient descent绕过指数依赖的方法，以提升Large Language Models (LLMs)的学习能力。具体地，对于线性向量生成任务，作者证明了线性Looped Transformers在输入数据条件数恒定（如n = O(d)）的情况下，能高效实现多步gradient descent，显著降低错误率，而非需要指数级in-context示例。实验结果验证了这一理论分析，揭示了Transformer架构的in-context learning能力比先前认知更强，并为设计更有效的LLMs推理算法提供了新见解。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "AIStats 2025",
      "pdf_url": "http://arxiv.org/pdf/2410.11268v2",
      "published_date": "2024-10-15 04:44:23 UTC",
      "updated_date": "2025-02-28 22:12:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:00:58.460075"
    },
    {
      "arxiv_id": "2410.11267v4",
      "title": "FedCCRL: Federated Domain Generalization with Cross-Client Representation Learning",
      "title_zh": "FedCCRL：联邦领域泛化与跨客户端表示学习",
      "authors": [
        "Xinpeng Wang",
        "Yongxin Guo",
        "Xiaoying Tang"
      ],
      "abstract": "Domain Generalization (DG) aims to train models that can effectively\ngeneralize to unseen domains. However, in the context of Federated Learning\n(FL), where clients collaboratively train a model without directly sharing\ntheir data, most existing DG algorithms are not directly applicable to the FL\nsetting due to privacy constraints, as well as the limited data quantity and\ndomain diversity at each client. To tackle these challenges, we propose\nFedCCRL, a lightweight federated domain generalization method that\nsignificantly improves the model's generalization ability while preserving\nprivacy and ensuring computational and communication efficiency. Specifically,\nFedCCRL comprises two principal modules: the first is a cross-client feature\nextension module, which increases local domain diversity via cross-client\ndomain transfer and domain-invariant feature perturbation; the second is a\nrepresentation and prediction dual-stage alignment module, which enables the\nmodel to effectively capture domain-invariant features. Extensive experimental\nresults demonstrate that FedCCRL achieves the state-of-the-art performance on\nthe PACS, OfficeHome and miniDomainNet datasets across FL settings of varying\nnumbers of clients. Code is available at https://github.com/sanphouwang/fedccrl",
      "tldr_zh": "这篇论文提出 FedCCRL，一种轻量级的 Federated Learning (FL) 方法，用于解决 Domain Generalization (DG) 在 FL 场景中的挑战，包括隐私约束、数据量有限和领域多样性不足问题。FedCCRL 包括两个主要模块：跨客户端特征扩展模块，通过跨客户端域转移和域不变特征扰动来提升本地域多样性；以及表示和预测双阶段对齐模块，帮助模型有效捕获域不变特征。实验结果表明，FedCCRL 在 PACS、OfficeHome 和 miniDomainNet 数据集上实现了最先进性能，并在不同客户端数量的 FL 设置中表现出色。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.11267v4",
      "published_date": "2024-10-15 04:44:21 UTC",
      "updated_date": "2024-11-24 06:51:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:01:10.818171"
    },
    {
      "arxiv_id": "2410.11265v1",
      "title": "In-Context Learning for Long-Context Sentiment Analysis on Infrastructure Project Opinions",
      "title_zh": "翻译失败",
      "authors": [
        "Alireza Shamshiri",
        "Kyeong Rok Ryu",
        "June Young Park"
      ],
      "abstract": "Large language models (LLMs) have achieved impressive results across various\ntasks. However, they still struggle with long-context documents. This study\nevaluates the performance of three leading LLMs: GPT-4o, Claude 3.5 Sonnet, and\nGemini 1.5 Pro on lengthy, complex, and opinion-varying documents concerning\ninfrastructure projects, under both zero-shot and few-shot scenarios. Our\nresults indicate that GPT-4o excels in zero-shot scenarios for simpler, shorter\ndocuments, while Claude 3.5 Sonnet surpasses GPT-4o in handling more complex,\nsentiment-fluctuating opinions. In few-shot scenarios, Claude 3.5 Sonnet\noutperforms overall, while GPT-4o shows greater stability as the number of\ndemonstrations increases.",
      "tldr_zh": "这篇论文评估了大型语言模型（LLMs）如 GPT-4o、Claude 3.5 Sonnet 和 Gemini 1.5 Pro 在处理基础设施项目长文档的情感分析性能，聚焦于零样本（zero-shot）和少样本（few-shot）场景。结果表明，在零样本情况下，GPT-4o 更适合简单短文档，而 Claude 3.5 Sonnet 在复杂、情感波动大的意见上表现更优越。在少样本场景中，Claude 3.5 Sonnet 整体表现领先，但 GPT-4o 展示了随着演示样本增加的更大稳定性，为长上下文情感分析提供了重要见解。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.11265v1",
      "published_date": "2024-10-15 04:42:21 UTC",
      "updated_date": "2024-10-15 04:42:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:01:23.796574"
    },
    {
      "arxiv_id": "2410.11262v1",
      "title": "Unveiling Options with Neural Decomposition",
      "title_zh": "翻译失败",
      "authors": [
        "Mahdi Alikhasi",
        "Levi H. S. Lelis"
      ],
      "abstract": "In reinforcement learning, agents often learn policies for specific tasks\nwithout the ability to generalize this knowledge to related tasks. This paper\nintroduces an algorithm that attempts to address this limitation by decomposing\nneural networks encoding policies for Markov Decision Processes into reusable\nsub-policies, which are used to synthesize temporally extended actions, or\noptions. We consider neural networks with piecewise linear activation\nfunctions, so that they can be mapped to an equivalent tree that is similar to\noblique decision trees. Since each node in such a tree serves as a function of\nthe input of the tree, each sub-tree is a sub-policy of the main policy. We\nturn each of these sub-policies into options by wrapping it with while-loops of\nvaried number of iterations. Given the large number of options, we propose a\nselection mechanism based on minimizing the Levin loss for a uniform policy on\nthese options. Empirical results in two grid-world domains where exploration\ncan be difficult confirm that our method can identify useful options, thereby\naccelerating the learning process on similar but different tasks.",
      "tldr_zh": "这篇论文提出了一种算法，通过将编码马尔可夫决策过程(Markov Decision Processes)的神经网络分解成可重用的子策略(sub-policies)，以生成时间扩展动作(options)，从而解决强化学习(reinforcement learning)中任务知识泛化不足的问题。方法包括将具有分段线性激活函数的神经网络映射为类似于斜决策树的树结构，并将每个子树包装成带有不同迭代次数的while-loops，形成options；同时，引入基于最小化Levin loss的机制来选择这些options。实验结果在两个网格世界域中表明，该方法能识别有用options，从而加速类似但不同的任务学习过程。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Published as a conference paper at ICLR 2024",
      "pdf_url": "http://arxiv.org/pdf/2410.11262v1",
      "published_date": "2024-10-15 04:36:44 UTC",
      "updated_date": "2024-10-15 04:36:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:01:34.689808"
    },
    {
      "arxiv_id": "2410.11261v2",
      "title": "Beyond Linear Approximations: A Novel Pruning Approach for Attention Matrix",
      "title_zh": "超越线性近似：一种新颖的注意力矩阵剪枝方法",
      "authors": [
        "Yingyu Liang",
        "Jiangxuan Long",
        "Zhenmei Shi",
        "Zhao Song",
        "Yufa Zhou"
      ],
      "abstract": "Large Language Models (LLMs) have shown immense potential in enhancing\nvarious aspects of our daily lives, from conversational AI to search and AI\nassistants. However, their growing capabilities come at the cost of extremely\nlarge model sizes, making deployment on edge devices challenging due to memory\nand computational constraints. This paper introduces a novel approach to LLM\nweight pruning that directly optimizes for approximating the attention matrix,\na core component of transformer architectures. Unlike existing methods that\nfocus on linear approximations, our approach accounts for the non-linear nature\nof the Softmax attention mechanism. We provide theoretical guarantees for the\nconvergence of our Gradient Descent-based optimization method to a near-optimal\npruning mask solution. Our empirical results demonstrate the effectiveness of\nour non-linear pruning approach in maintaining model performance while\nsignificantly reducing computational costs, which is beyond the current\nstate-of-the-art methods, i.e., SparseGPT and Wanda, by a large margin. This\nwork establishes a new theoretical foundation for pruning algorithm design in\nLLMs, potentially paving the way for more efficient LLM inference on\nresource-constrained devices.",
      "tldr_zh": "这篇论文提出了一种新型的 LLM 权重修剪方法，直接优化注意力矩阵的近似，以解决大型语言模型(LLMs)在边缘设备部署时的内存和计算限制问题。不同于现有方法的线性近似，该方法考虑了 Softmax 注意力机制的非线性特性，并提供了基于 Gradient Descent 优化的收敛理论保证。实验结果表明，该方法在保持模型性能的同时显著降低了计算成本，比 SparseGPT 和 Wanda 等基准方法有较大优势，为 LLM 在资源受限设备上的高效推理奠定了新理论基础。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2410.11261v2",
      "published_date": "2024-10-15 04:35:56 UTC",
      "updated_date": "2025-02-26 18:44:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:01:45.851651"
    },
    {
      "arxiv_id": "2410.11250v1",
      "title": "Learning Agents With Prioritization and Parameter Noise in Continuous State and Action Space",
      "title_zh": "翻译失败",
      "authors": [
        "Rajesh Mangannavar",
        "Gopalakrishnan Srinivasaraghavan"
      ],
      "abstract": "Among the many variants of RL, an important class of problems is where the\nstate and action spaces are continuous -- autonomous robots, autonomous\nvehicles, optimal control are all examples of such problems that can lend\nthemselves naturally to reinforcement based algorithms, and have continuous\nstate and action spaces. In this paper, we introduce a prioritized form of a\ncombination of state-of-the-art approaches such as Deep Q-learning (DQN) and\nDeep Deterministic Policy Gradient (DDPG) to outperform the earlier results for\ncontinuous state and action space problems. Our experiments also involve the\nuse of parameter noise during training resulting in more robust deep RL models\noutperforming the earlier results significantly. We believe these results are a\nvaluable addition for continuous state and action space problems.",
      "tldr_zh": "本文提出了一种针对连续状态和动作空间的强化学习代理，通过优先化方法结合 Deep Q-learning (DQN) 和 Deep Deterministic Policy Gradient (DDPG)，以超越现有成果。实验中引入 parameter noise 进行训练，使模型更鲁棒，并显著提升性能。作者认为这些改进为处理类似问题提供了宝贵贡献。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "I.2.6"
      ],
      "primary_category": "cs.AI",
      "comment": "10 pages, 3 figures. Published in Advances in Neural Networks - ISNN\n  2019",
      "pdf_url": "http://arxiv.org/pdf/2410.11250v1",
      "published_date": "2024-10-15 04:12:12 UTC",
      "updated_date": "2024-10-15 04:12:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:01:57.742822"
    },
    {
      "arxiv_id": "2410.11242v1",
      "title": "Automatically Generating Visual Hallucination Test Cases for Multimodal Large Language Models",
      "title_zh": "针对多模态大型语言模型的视觉幻觉测试用",
      "authors": [
        "Zhongye Liu",
        "Hongbin Liu",
        "Yuepeng Hu",
        "Zedian Shao",
        "Neil Zhenqiang Gong"
      ],
      "abstract": "Visual hallucination (VH) occurs when a multimodal large language model\n(MLLM) generates responses with incorrect visual details for prompts. Existing\nmethods for generating VH test cases primarily rely on human annotations,\ntypically in the form of triples: (image, question, answer). In this paper, we\nintroduce VHExpansion, the first automated method for expanding VH test cases\nfor MLLMs. Given an initial VH test case, VHExpansion automatically expands it\nby perturbing the question and answer through negation as well as modifying the\nimage using both common and adversarial perturbations. Additionally, we propose\na new evaluation metric, symmetric accuracy, which measures the proportion of\ncorrectly answered VH test-case pairs. Each pair consists of a test case and\nits negated counterpart. Our theoretical analysis shows that symmetric accuracy\nis an unbiased evaluation metric that remains unaffected by the imbalance of VH\ntesting cases with varying answers when an MLLM is randomly guessing the\nanswers, whereas traditional accuracy is prone to such imbalance. We apply\nVHExpansion to expand three VH datasets annotated manually and use these\nexpanded datasets to benchmark seven MLLMs. Our evaluation shows that\nVHExpansion effectively identifies more VH test cases. Moreover, symmetric\naccuracy, being unbiased, leads to different conclusions about the\nvulnerability of MLLMs to VH compared to traditional accuracy metric. Finally,\nwe show that fine-tuning MLLMs on the expanded VH dataset generated by\nVHExpansion mitigates VH more effectively than fine-tuning on the original,\nmanually annotated dataset. Our code is available at:\nhttps://github.com/lycheeefish/VHExpansion.",
      "tldr_zh": "本研究针对多模态大语言模型（MLLMs）的视觉幻觉（VH）问题，提出了一种自动化方法VHExpansion，用于扩展VH测试案例。该方法从初始测试案例出发，通过否定扰动问题和答案，以及使用常见和对抗性扰动修改图像，从而自动生成更多测试样本。同时，论文引入了新的评价指标symmetric accuracy，它测量模型正确回答VH测试案例对（包括原案例及其否定对应）的比例，并证明该指标在随机猜测场景下是无偏的，比传统accuracy更可靠。实验结果显示，VHExpansion扩展的三个手动注解数据集能有效识别更多VH案例，并在基准测试七个MLLMs时揭示模型的脆弱性；此外，使用扩展数据集微调MLLMs比使用原始数据集更有效地缓解VH问题。代码已在https://github.com/lycheeefish/VHExpansion上公开。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.11242v1",
      "published_date": "2024-10-15 03:56:16 UTC",
      "updated_date": "2024-10-15 03:56:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:02:11.168723"
    },
    {
      "arxiv_id": "2410.11239v1",
      "title": "HR-Agent: A Task-Oriented Dialogue (TOD) LLM Agent Tailored for HR Applications",
      "title_zh": "翻译失败",
      "authors": [
        "Weijie Xu",
        "Jay Desai",
        "Fanyou Wu",
        "Josef Valvoda",
        "Srinivasan H. Sengamedu"
      ],
      "abstract": "Recent LLM (Large Language Models) advancements benefit many fields such as\neducation and finance, but HR has hundreds of repetitive processes, such as\naccess requests, medical claim filing and time-off submissions, which are\nunaddressed. We relate these tasks to the LLM agent, which has addressed tasks\nsuch as writing assisting and customer support. We present HR-Agent, an\nefficient, confidential, and HR-specific LLM-based task-oriented dialogue\nsystem tailored for automating repetitive HR processes such as medical claims\nand access requests. Since conversation data is not sent to an LLM during\ninference, it preserves confidentiality required in HR-related tasks.",
      "tldr_zh": "该论文提出了 HR-Agent，这是一个针对人力资源（HR）应用的基于大型语言模型（LLM）的任务导向对话（TOD）代理，用于自动化重复性 HR 流程，如医疗索赔和访问请求。HR-Agent 设计高效且注重保密，通过在推理过程中不发送对话数据给 LLM，确保敏感信息的保护。相比传统方法，该代理填补了 LLM 在 HR 领域的应用空白，提供更可靠的自动化解决方案。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "68T07",
        "I.2.7"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.11239v1",
      "published_date": "2024-10-15 03:51:08 UTC",
      "updated_date": "2024-10-15 03:51:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:02:21.348566"
    },
    {
      "arxiv_id": "2410.11234v1",
      "title": "Bayes Adaptive Monte Carlo Tree Search for Offline Model-based Reinforcement Learning",
      "title_zh": "贝叶斯自适应蒙特卡洛树搜索用于离线基于模型的强化学习",
      "authors": [
        "Jiayu Chen",
        "Wentse Chen",
        "Jeff Schneider"
      ],
      "abstract": "Offline reinforcement learning (RL) is a powerful approach for data-driven\ndecision-making and control. Compared to model-free methods, offline\nmodel-based reinforcement learning (MBRL) explicitly learns world models from a\nstatic dataset and uses them as surrogate simulators, improving the data\nefficiency and enabling the learned policy to potentially generalize beyond the\ndataset support. However, there could be various MDPs that behave identically\non the offline dataset and so dealing with the uncertainty about the true MDP\ncan be challenging. In this paper, we propose modeling offline MBRL as a Bayes\nAdaptive Markov Decision Process (BAMDP), which is a principled framework for\naddressing model uncertainty. We further introduce a novel Bayes Adaptive\nMonte-Carlo planning algorithm capable of solving BAMDPs in continuous state\nand action spaces with stochastic transitions. This planning process is based\non Monte Carlo Tree Search and can be integrated into offline MBRL as a policy\nimprovement operator in policy iteration. Our ``RL + Search\" framework follows\nin the footsteps of superhuman AIs like AlphaZero, improving on current offline\nMBRL methods by incorporating more computation input. The proposed algorithm\nsignificantly outperforms state-of-the-art model-based and model-free offline\nRL methods on twelve D4RL MuJoCo benchmark tasks and three target tracking\ntasks in a challenging, stochastic tokamak control simulator.",
      "tldr_zh": "该研究提出了一种将离线基于模型的强化学习（Offline MBRL）建模为Bayes Adaptive Markov Decision Process (BAMDP)的框架，以处理模型不确定性问题。作者引入了一个新的Bayes Adaptive Monte-Carlo规划算法，基于Monte Carlo Tree Search（MCTS），能够处理连续状态和动作空间中的随机转移，并将其整合到Offline MBRL的策略迭代中作为策略改进操作。实验结果显示，该算法在十二个D4RL MuJoCo基准任务和三个托卡马克控制模拟器任务上，显著优于现有模型-based和模型-free Offline RL方法，展示了更高的性能和泛化能力。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.11234v1",
      "published_date": "2024-10-15 03:36:43 UTC",
      "updated_date": "2024-10-15 03:36:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:02:34.677966"
    },
    {
      "arxiv_id": "2410.11221v1",
      "title": "Multi-objective Reinforcement Learning: A Tool for Pluralistic Alignment",
      "title_zh": "翻译失败",
      "authors": [
        "Peter Vamplew",
        "Conor F Hayes",
        "Cameron Foale",
        "Richard Dazeley",
        "Hadassah Harland"
      ],
      "abstract": "Reinforcement learning (RL) is a valuable tool for the creation of AI\nsystems. However it may be problematic to adequately align RL based on scalar\nrewards if there are multiple conflicting values or stakeholders to be\nconsidered. Over the last decade multi-objective reinforcement learning (MORL)\nusing vector rewards has emerged as an alternative to standard, scalar RL. This\npaper provides an overview of the role which MORL can play in creating\npluralistically-aligned AI.",
      "tldr_zh": "这篇论文探讨了强化学习（RL）在创建AI系统中的应用问题，特别是当存在多个冲突的值或利益相关者时，基于标量奖励的RL可能无法实现充分的对齐。论文引入多目标强化学习（MORL），它使用向量奖励作为标准RL的替代方案，以更好地处理多元主义对齐（Pluralistic Alignment）。总体上，该研究概述了MORL如何通过支持多利益相关者的需求来促进AI系统的公平性和可扩展性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted for the Pluralistic Alignment workshop at NeurIPS 2024.\n  https://pluralistic-alignment.github.io/",
      "pdf_url": "http://arxiv.org/pdf/2410.11221v1",
      "published_date": "2024-10-15 03:06:13 UTC",
      "updated_date": "2024-10-15 03:06:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:02:45.220443"
    },
    {
      "arxiv_id": "2410.11217v1",
      "title": "On the Capacity of Citation Generation by Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Haosheng Qian",
        "Yixing Fan",
        "Ruqing Zhang",
        "Jiafeng Guo"
      ],
      "abstract": "Retrieval-augmented generation (RAG) appears as a promising method to\nalleviate the \"hallucination\" problem in large language models (LLMs), since it\ncan incorporate external traceable resources for response generation. The\nessence of RAG in combating the hallucination issue lies in accurately\nattributing claims in responses to the corresponding retrieved documents.\nHowever, most of existing works focus on improving the quality of generated\nresponses from the LLM, while largely overlooked its ability to attribute\nsources accurately. In this study, we conduct a systematic analysis about the\ncapabilities of LLMs in generating citations within response generation, and\nfurther introduce a novel method to enhance their citation generation\nabilities. Specifically, we evaluate both the correctness and citation quality\nfor seven widely-used LLMs on two benchmark datasets. Meanwhile, we introduce\nnew citation evaluation metrics to eliminate the over-penalization of\nunnecessary and excessive citations in existing metrics. Furthermore, we\npropose a Generate-then-Refine method that completes relevant citations and\nremoves irrelevant ones without altering the response text. The results on\nWebGLM-QA, ASQA and ELI5 datasets show that our method substantially improves\nthe quality of citations in responses generated by LLMs.",
      "tldr_zh": "本研究探讨了大型语言模型 (LLMs) 在生成引文方面的能力，特别是通过 Retrieval-augmented generation (RAG) 来缓解“hallucination”问题，确保响应中的声明准确归因于检索文档。研究者评估了七个常用 LLMs 在两个基准数据集上的引文正确性和质量，并引入了新的评估指标，以避免过度惩罚不必要的引文。接着，他们提出了一种 Generate-then-Refine 方法，该方法在不改变响应文本的情况下，补充相关引文并移除无关引文。在 WebGLM-QA、ASQA 和 ELI5 数据集上的实验结果显示，该方法显著提高了 LLMs 生成响应的引文质量。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted by CCIR 2024",
      "pdf_url": "http://arxiv.org/pdf/2410.11217v1",
      "published_date": "2024-10-15 03:04:26 UTC",
      "updated_date": "2024-10-15 03:04:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:02:58.728456"
    },
    {
      "arxiv_id": "2410.11908v1",
      "title": "ChatHouseDiffusion: Prompt-Guided Generation and Editing of Floor Plans",
      "title_zh": "ChatHouseDiffusion: 基于提示引导的楼层平面图生成和编辑",
      "authors": [
        "Sizhong Qin",
        "Chengyu He",
        "Qiaoyun Chen",
        "Sen Yang",
        "Wenjie Liao",
        "Yi Gu",
        "Xinzheng Lu"
      ],
      "abstract": "The generation and editing of floor plans are critical in architectural\nplanning, requiring a high degree of flexibility and efficiency. Existing\nmethods demand extensive input information and lack the capability for\ninteractive adaptation to user modifications. This paper introduces\nChatHouseDiffusion, which leverages large language models (LLMs) to interpret\nnatural language input, employs graphormer to encode topological relationships,\nand uses diffusion models to flexibly generate and edit floor plans. This\napproach allows iterative design adjustments based on user ideas, significantly\nenhancing design efficiency. Compared to existing models, ChatHouseDiffusion\nachieves higher Intersection over Union (IoU) scores, permitting precise,\nlocalized adjustments without the need for complete redesigns, thus offering\ngreater practicality. Experiments demonstrate that our model not only strictly\nadheres to user specifications but also facilitates a more intuitive design\nprocess through its interactive capabilities.",
      "tldr_zh": "该论文提出ChatHouseDiffusion框架，利用大型语言模型(LLMs)解析自然语言输入、Graphormer编码拓扑关系，以及diffusion models灵活生成和编辑楼层平面图，以解决现有方法在建筑规划中输入需求过多和交互性不足的问题。该框架支持基于用户想法的迭代设计调整，大大提升设计效率。与现有模型相比，ChatHouseDiffusion在Intersection over Union (IoU)分数上表现出色，实现精确的局部修改而不需完整重设计。实验结果表明，该模型严格遵守用户规范，并通过交互能力使设计过程更直观和实用。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.11908v1",
      "published_date": "2024-10-15 02:41:46 UTC",
      "updated_date": "2024-10-15 02:41:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:03:10.175069"
    },
    {
      "arxiv_id": "2410.11201v2",
      "title": "Tree of Attributes Prompt Learning for Vision-Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Tong Ding",
        "Wanhua Li",
        "Zhongqi Miao",
        "Hanspeter Pfister"
      ],
      "abstract": "Prompt learning has proven effective in adapting vision language models for\ndownstream tasks. However, existing methods usually append learnable prompt\ntokens solely with the category names to obtain textual features, which fails\nto fully leverage the rich context indicated in the category name. To address\nthis issue, we propose the Tree of Attributes Prompt learning (TAP), which\nfirst instructs LLMs to generate a tree of attributes with a \"concept -\nattribute - description\" structure for each category, and then learn the\nhierarchy with vision and text prompt tokens. Unlike existing methods that\nmerely augment category names with a set of unstructured descriptions, our\napproach essentially distills structured knowledge graphs associated with class\nnames from LLMs. Furthermore, our approach introduces text and vision prompts\ndesigned to explicitly learn the corresponding visual attributes, effectively\nserving as domain experts. Additionally, the general and diverse descriptions\ngenerated based on the class names may be wrong or absent in the specific given\nimages. To address this misalignment, we further introduce a vision-conditional\npooling module to extract instance-specific text features. Extensive\nexperimental results demonstrate that our approach outperforms state-of-the-art\nmethods on the zero-shot base-to-novel generalization, cross-dataset transfer,\nas well as few-shot classification across 11 diverse datasets. Code is\navailable at https://github.com/HHenryD/TAP.",
      "tldr_zh": "本研究提出了一种Tree of Attributes Prompt learning (TAP)方法，用于提升Vision-Language Models在下游任务中的适应性。TAP首先利用LLMs为每个类别生成一个“概念 - 属性 - 描述”的层次化属性树结构，从而从类别名称中提炼结构化知识图；随后，通过文本和视觉提示标记显式学习对应的视觉属性，以更好地捕捉上下文。针对类别描述可能与特定图像不匹配的问题，该方法引入了vision-conditional pooling module来提取实例特定的文本特征。实验结果显示，TAP在11个多样数据集上，在零样本泛化、跨数据集转移和少样本分类任务中均优于现有最先进方法。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.11201v2",
      "published_date": "2024-10-15 02:37:39 UTC",
      "updated_date": "2025-04-21 15:37:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:03:33.727842"
    },
    {
      "arxiv_id": "2410.11200v1",
      "title": "SplitSEE: A Splittable Self-supervised Framework for Single-Channel EEG Representation Learning",
      "title_zh": "SplitSEE：一个可分割的自监督框架，用于单通道 EEG 表示学习",
      "authors": [
        "Rikuto Kotoge",
        "Zheng Chen",
        "Tasuku Kimura",
        "Yasuko Matsubara",
        "Takufumi Yanagisawa",
        "Haruhiko Kishima",
        "Yasushi Sakurai"
      ],
      "abstract": "While end-to-end multi-channel electroencephalography (EEG) learning\napproaches have shown significant promise, their applicability is often\nconstrained in neurological diagnostics, such as intracranial EEG resources.\nWhen provided with a single-channel EEG, how can we learn representations that\nare robust to multi-channels and scalable across varied tasks, such as seizure\nprediction? In this paper, we present SplitSEE, a structurally splittable\nframework designed for effective temporal-frequency representation learning in\nsingle-channel EEG. The key concept of SplitSEE is a self-supervised framework\nincorporating a deep clustering task. Given an EEG, we argue that the time and\nfrequency domains are two distinct perspectives, and hence, learned\nrepresentations should share the same cluster assignment. To this end, we first\npropose two domain-specific modules that independently learn domain-specific\nrepresentation and address the temporal-frequency tradeoff issue in\nconventional spectrogram-based methods. Then, we introduce a novel clustering\nloss to measure the information similarity. This encourages representations\nfrom both domains to coherently describe the same input by assigning them a\nconsistent cluster. SplitSEE leverages a pre-training-to-fine-tuning framework\nwithin a splittable architecture and has following properties: (a)\nEffectiveness: it learns representations solely from single-channel EEG but has\neven outperformed multi-channel baselines. (b) Robustness: it shows the\ncapacity to adapt across different channels with low performance variance.\nSuperior performance is also achieved with our collected clinical dataset. (c)\nScalability: With just one fine-tuning epoch, SplitSEE achieves high and stable\nperformance using partial model layers.",
      "tldr_zh": "本文提出 SplitSEE，一种可分割的自监督框架，用于单通道 EEG 表示学习，旨在学习鲁棒的时频表示以适应多任务场景，如癫痫预测。框架包括两个域特定模块分别处理时间域和频域表示，并引入一个新的 clustering loss 函数，确保两者共享相同的聚类分配，从而解决传统谱图方法的权衡问题。实验显示，SplitSEE 仅基于单通道 EEG 便超过了多通道基线，在鲁棒性和可扩展性方面表现出色，例如适应不同通道并在微调一轮后实现高性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "This paper has been accepted by ICDM2024",
      "pdf_url": "http://arxiv.org/pdf/2410.11200v1",
      "published_date": "2024-10-15 02:34:33 UTC",
      "updated_date": "2024-10-15 02:34:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:03:34.792740"
    },
    {
      "arxiv_id": "2410.11199v2",
      "title": "Isambard-AI: a leadership class supercomputer optimised specifically for Artificial Intelligence",
      "title_zh": "Isambard-AI：一个专门针对人工智能优化的领导级超级计算机",
      "authors": [
        "Simon McIntosh-Smith",
        "Sadaf R Alam",
        "Christopher Woods"
      ],
      "abstract": "Isambard-AI is a new, leadership-class supercomputer, designed to support\nAI-related research. Based on the HPE Cray EX4000 system, and housed in a new,\nenergy efficient Modular Data Centre in Bristol, UK, Isambard-AI employs 5,448\nNVIDIA Grace-Hopper GPUs to deliver over 21 ExaFLOP/s of 8-bit floating point\nperformance for LLM training, and over 250 PetaFLOP/s of 64-bit performance,\nfor under 5MW. Isambard-AI integrates two, all-flash storage systems: a 20\nPiByte Cray ClusterStor and a 3.5 PiByte VAST solution. Combined these give\nIsambard-AI flexibility for training, inference and secure data accesses and\nsharing. But it is the software stack where Isambard-AI will be most different\nfrom traditional HPC systems. Isambard-AI is designed to support users who may\nhave been using GPUs in the cloud, and so access will more typically be via\nJupyter notebooks, MLOps, or other web-based, interactive interfaces, rather\nthan the approach used on traditional supercomputers of sshing into a system\nbefore submitting jobs to a batch scheduler. Its stack is designed to be\nquickly and regularly upgraded to keep pace with the rapid evolution of AI\nsoftware, with full support for containers. Phase 1 of Isambard-AI is due\nonline in May/June 2024, with the full system expected in production by the end\nof the year.",
      "tldr_zh": "Isambard-AI 是一款专为人工智能研究设计的领导级超级计算机，基于 HPE Cray EX4000 系统，位于英国布里斯托尔的新型节能模块化数据中心。系统配备 5,448 个 NVIDIA Grace-Hopper GPUs，提供超过 21 ExaFLOP/s 的 8-bit 浮点性能用于 LLM 训练，以及超过 250 PetaFLOP/s 的 64-bit 性能，同时集成 20 PiByte Cray ClusterStor 和 3.5 PiByte VAST 全闪存存储系统，以支持灵活的训练、推理和数据访问。不同于传统 HPC 系统，其软件栈更注重用户友好性，支持 Jupyter notebooks、MLOps 等交互式接口，并设计为快速升级以跟上 AI 软件的演进。第一阶段预计于 2024 年 5/6 月上线，全系统年底前投入生产。",
      "categories": [
        "cs.DC",
        "cs.AI"
      ],
      "primary_category": "cs.DC",
      "comment": "11 pages, 11 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.11199v2",
      "published_date": "2024-10-15 02:34:26 UTC",
      "updated_date": "2024-11-04 12:47:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:03:47.136230"
    },
    {
      "arxiv_id": "2410.11195v1",
      "title": "Athena: Retrieval-augmented Legal Judgment Prediction with Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Xiao Peng",
        "Liang Chen"
      ],
      "abstract": "Recently, large language models (LLMs) like ChatGPT, LLaMA, and Claude have\nprevailed in countless domains, including legal scenarios. With LLMs' rapid\ntechnological progress, the development of prompt engineering (PE) as an\ninterface between the LLMs and real-world applications has drawn the attention\nof all developers. Various PE methods have been proposed to overcome real-world\nchallenges, such as few-shot prompting, chain-of-thought, and\nretrieval-augmented generation (RAG). However, RAG for legal judgment\nprediction (LJP) is still underexplored. To address this, we propose \"Athena\",\na novel framework cultivating RAG as a core preprocess component to enhance\nLLMs' performance on specialized tasks. Athena constructs a knowledge base for\naccusations, attached with a semantic retrieval mechanism through\nvectorization. Our experiments show that Athena's overall performance has\nimproved significantly, achieving state-of-the-art results on the CAIL2018\ndataset. Our ablation study on the in-context window size parameter further\nreproduces LLMs' \"lost-in-the-middle\" phenomenon with a relative positional\nvariation. And with moderate hyper-parameter-tuning, we can achieve at most 95%\nof accuracy accordingly. We also study the impact of query rewriting and data\ndistribution, providing possible directions for future research based on former\nanalyses.",
      "tldr_zh": "这篇论文提出了 Athena 框架，利用 retrieval-augmented generation (RAG) 作为核心预处理组件，增强大型语言模型 (LLMs) 在法律判断预测 (LJP) 任务中的性能。Athena 通过构建针对指控的知识基并结合向量化的语义检索机制，解决了 LLMs 在专业场景中的局限性，如知识缺口和提示优化问题。实验结果显示，该框架在 CAIL2018 数据集上达到了 state-of-the-art 水平，并通过消融研究验证了 LLMs 的 \"lost-in-the-middle\" 现象，同时探讨了查询重写和数据分布的影响，为未来研究提供了新方向。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "13 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.11195v1",
      "published_date": "2024-10-15 02:18:01 UTC",
      "updated_date": "2024-10-15 02:18:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:03:58.795800"
    },
    {
      "arxiv_id": "2410.11906v1",
      "title": "Empowering Users in Digital Privacy Management through Interactive LLM-Based Agents",
      "title_zh": "翻译失败",
      "authors": [
        "Bolun Sun",
        "Yifan Zhou",
        "Haiyun Jiang"
      ],
      "abstract": "This paper presents a novel application of large language models (LLMs) to\nenhance user comprehension of privacy policies through an interactive dialogue\nagent. We demonstrate that LLMs significantly outperform traditional models in\ntasks like Data Practice Identification, Choice Identification, Policy\nSummarization, and Privacy Question Answering, setting new benchmarks in\nprivacy policy analysis. Building on these findings, we introduce an innovative\nLLM-based agent that functions as an expert system for processing website\nprivacy policies, guiding users through complex legal language without\nrequiring them to pose specific questions. A user study with 100 participants\nshowed that users assisted by the agent had higher comprehension levels (mean\nscore of 2.6 out of 3 vs. 1.8 in the control group), reduced cognitive load\n(task difficulty ratings of 3.2 out of 10 vs. 7.8), increased confidence in\nmanaging privacy, and completed tasks in less time (5.5 minutes vs. 15.8\nminutes). This work highlights the potential of LLM-based agents to transform\nuser interaction with privacy policies, leading to more informed consent and\nempowering users in the digital services landscape.",
      "tldr_zh": "本研究提出了一种基于大型语言模型（LLMs）的交互式对话代理，以提升用户对隐私政策的理解。该代理在数据实践识别（Data Practice Identification）、选择识别（Choice Identification）、政策总结（Policy Summarization）和隐私问题回答等任务中，显著优于传统模型，并设定了新基准。用户研究显示，使用该代理的100名参与者理解水平更高（平均分2.6 vs 1.8）、认知负荷更低（任务难度3.2 vs 7.8）、完成任务更快（5.5分钟 vs 15.8分钟），并增强了隐私管理信心。该工作展示了LLMs-based agents在数字服务领域的潜力，促进用户更知情的同意和隐私赋权。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.11906v1",
      "published_date": "2024-10-15 02:16:59 UTC",
      "updated_date": "2024-10-15 02:16:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:04:20.347592"
    },
    {
      "arxiv_id": "2410.11190v3",
      "title": "Mini-Omni2: Towards Open-source GPT-4o with Vision, Speech and Duplex Capabilities",
      "title_zh": "翻译失败",
      "authors": [
        "Zhifei Xie",
        "Changqiao Wu"
      ],
      "abstract": "GPT-4o, an all-encompassing model, represents a milestone in the development\nof large multi-modal language models. It can understand visual, auditory, and\ntextual modalities, directly output audio, and support flexible duplex\ninteraction. Models from the open-source community often achieve some\nfunctionalities of GPT-4o, such as visual understanding and voice chat.\nNevertheless, training a unified model that incorporates all modalities is\nchallenging due to the complexities of multi-modal data, intricate model\narchitectures, and training processes. In this paper, we introduce Mini-Omni2,\na visual-audio assistant capable of providing real-time, end-to-end voice\nresponses to visoin and audio queries. By integrating pretrained visual and\nauditory encoders, Mini-Omni2 maintains performance in individual modalities.\nWe propose a three-stage training process to align modalities, allowing the\nlanguage model to handle multi-modal inputs and outputs after training on a\nlimited dataset. For interaction, we introduce a command-based interruption\nmechanism, enabling more flexible interaction with users. To the best of our\nknowledge, Mini-Omni2 is one of the closest reproductions of GPT-4o, which have\nsimilar form of functionality, and we hope it can offer valuable insights for\nsubsequent research.",
      "tldr_zh": "该论文介绍了 Mini-Omni2，一种开源的多模态模型，旨在模仿 GPT-4o 的视觉、音频和双向交互功能，处理多模态数据的复杂挑战。研究团队通过整合预训练的 visual 和 auditory 编码器，并采用三阶段训练过程来对齐模态，使模型能在有限数据集上处理多模态输入输出，并支持命令-based 中断机制以实现灵活交互。实验结果显示，Mini-Omni2 保持了单个模态的性能，是对 GPT-4o 功能形式的最接近再现，为后续多模态模型研究提供了宝贵洞见。",
      "categories": [
        "eess.AS",
        "cs.AI",
        "cs.CV",
        "cs.LG",
        "cs.SD"
      ],
      "primary_category": "eess.AS",
      "comment": "Technical report, work in progress. Demo and code:\n  https://github.com/gpt-omni/mini-omni2",
      "pdf_url": "http://arxiv.org/pdf/2410.11190v3",
      "published_date": "2024-10-15 02:10:45 UTC",
      "updated_date": "2024-11-05 02:27:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:04:22.443053"
    },
    {
      "arxiv_id": "2410.11182v2",
      "title": "Position: On-Premises LLM Deployment Demands a Middle Path: Preserving Privacy Without Sacrificing Model Confidentiality",
      "title_zh": "翻译失败",
      "authors": [
        "Hanbo Huang",
        "Yihan Li",
        "Bowen Jiang",
        "Lin Liu",
        "Bo Jiang",
        "Ruoyu Sun",
        "Zhuotao Liu",
        "Shiyu Liang"
      ],
      "abstract": "Current LLM customization typically relies on two deployment strategies:\nclosed-source APIs, which require users to upload private data to external\nservers, and open-weight models, which allow local fine-tuning but pose misuse\nrisks. In this position paper, we argue that (1) deploying closed-source LLMs\nwithin user-controlled infrastructure (\\textit{on-premises deployment})\nenhances data privacy and mitigates misuse risks, and (2) a well-designed\non-premises deployment must ensure model confidentiality -- by preventing model\ntheft -- and offer privacy-preserving customization. Prior research on small\nmodels has explored securing only the output layer within hardware-secured\ndevices to balance confidentiality and customization efficiency. However, we\nshow that this approach is insufficient for defending large-scale LLMs against\ndistillation attacks. We therefore introduce a {semi-open deployment framework}\nthat secures only a few, carefully chosen layers, achieving distillation\nresistance comparable to fully secured models while preserving fine-tuning\nflexibility. Through extensive experiments, we show that securing bottom layers\nsignificantly reduces functional extraction risks. Our findings demonstrate\nthat privacy and confidentiality can coexist, paving the way for secure\non-premises AI deployment that balances usability and protection.",
      "tldr_zh": "本论文主张，在大型语言模型(LLM)部署中，采用on-premises deployment策略可以提升数据隐私并减少滥用风险，同时确保模型保密性。该框架提出semi-open deployment framework，通过只保护少数精心选择的层（如底层）来抵抗distillation attacks，同时保留微调灵活性。实验结果显示，这种方法显著降低了功能提取风险，证明了隐私和模型保密性可以共存，为安全且实用的本地AI部署提供了新路径。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.LG",
      "comment": "8 pages for main content of the paper",
      "pdf_url": "http://arxiv.org/pdf/2410.11182v2",
      "published_date": "2024-10-15 02:00:36 UTC",
      "updated_date": "2025-01-31 14:36:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:04:34.777772"
    },
    {
      "arxiv_id": "2410.11181v2",
      "title": "DARNet: Dual Attention Refinement Network with Spatiotemporal Construction for Auditory Attention Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Sheng Yan",
        "Cunhang fan",
        "Hongyu Zhang",
        "Xiaoke Yang",
        "Jianhua Tao",
        "Zhao Lv"
      ],
      "abstract": "At a cocktail party, humans exhibit an impressive ability to direct their\nattention. The auditory attention detection (AAD) approach seeks to identify\nthe attended speaker by analyzing brain signals, such as EEG signals. However,\ncurrent AAD algorithms overlook the spatial distribution information within EEG\nsignals and lack the ability to capture long-range latent dependencies,\nlimiting the model's ability to decode brain activity. To address these issues,\nthis paper proposes a dual attention refinement network with spatiotemporal\nconstruction for AAD, named DARNet, which consists of the spatiotemporal\nconstruction module, dual attention refinement module, and feature fusion \\&\nclassifier module. Specifically, the spatiotemporal construction module aims to\nconstruct more expressive spatiotemporal feature representations, by capturing\nthe spatial distribution characteristics of EEG signals. The dual attention\nrefinement module aims to extract different levels of temporal patterns in EEG\nsignals and enhance the model's ability to capture long-range latent\ndependencies. The feature fusion \\& classifier module aims to aggregate\ntemporal patterns and dependencies from different levels and obtain the final\nclassification results. The experimental results indicate that compared to the\nstate-of-the-art models, DARNet achieves an average classification accuracy\nimprovement of 5.9\\% for 0.1s, 4.6\\% for 1s, and 3.9\\% for 2s on the DTU\ndataset. While maintaining excellent classification performance, DARNet\nsignificantly reduces the number of required parameters. Compared to the\nstate-of-the-art models, DARNet reduces the parameter count by 91\\%. Code is\navailable at: https://github.com/fchest/DARNet.git.",
      "tldr_zh": "本文提出 DARNet，一种针对 Auditory Attention Detection (AAD) 的双注意力精炼网络，通过 spatiotemporal construction module 捕捉 EEG 信号的空间分布特征，并利用 dual attention refinement module 提取不同级别的时间模式以增强长程潜在依赖性。DARNet 还包括 feature fusion & classifier module 来整合多级别特征，实现高效分类。实验结果显示，在 DTU 数据集上，DARNet 比最先进模型平均提高了 5.9%（0.1s）、4.6%（1s）和 3.9%（2s）的分类准确率，同时减少了 91% 的参数数量。",
      "categories": [
        "eess.AS",
        "cs.AI",
        "cs.LG",
        "cs.SD"
      ],
      "primary_category": "eess.AS",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.11181v2",
      "published_date": "2024-10-15 01:51:29 UTC",
      "updated_date": "2024-11-18 16:25:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:04:47.579761"
    },
    {
      "arxiv_id": "2410.11179v1",
      "title": "Interpretability as Compression: Reconsidering SAE Explanations of Neural Activations with MDL-SAEs",
      "title_zh": "翻译失败",
      "authors": [
        "Kola Ayonrinde",
        "Michael T. Pearce",
        "Lee Sharkey"
      ],
      "abstract": "Sparse Autoencoders (SAEs) have emerged as a useful tool for interpreting the\ninternal representations of neural networks. However, naively optimising SAEs\nfor reconstruction loss and sparsity results in a preference for SAEs that are\nextremely wide and sparse. We present an information-theoretic framework for\ninterpreting SAEs as lossy compression algorithms for communicating\nexplanations of neural activations. We appeal to the Minimal Description Length\n(MDL) principle to motivate explanations of activations which are both accurate\nand concise. We further argue that interpretable SAEs require an additional\nproperty, \"independent additivity\": features should be able to be understood\nseparately. We demonstrate an example of applying our MDL-inspired framework by\ntraining SAEs on MNIST handwritten digits and find that SAE features\nrepresenting significant line segments are optimal, as opposed to SAEs with\nfeatures for memorised digits from the dataset or small digit fragments. We\nargue that using MDL rather than sparsity may avoid potential pitfalls with\nnaively maximising sparsity such as undesirable feature splitting and that this\nframework naturally suggests new hierarchical SAE architectures which provide\nmore concise explanations.",
      "tldr_zh": "本研究提出了一种信息理论框架，将Sparse Autoencoders (SAEs)视为解释神经网络激活的损失压缩算法，并引入Minimal Description Length (MDL)原则来优化SAEs，使解释既准确又简洁，同时要求特征具备“independent additivity”特性，以便独立理解。作者论证，使用MDL而非单纯稀疏性优化可以避免问题，如不必要的特征分裂，并建议新的分层SAE架构以提供更高效的解释。在MNIST手写数字数据集上的实验显示，MDL-SAEs的最佳特征是代表重要线段的模式，而非记忆的完整数字或碎片，从而提升了神经网络解释的可信度和实用性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.IT",
        "math.IT"
      ],
      "primary_category": "cs.LG",
      "comment": "8 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.11179v1",
      "published_date": "2024-10-15 01:38:03 UTC",
      "updated_date": "2024-10-15 01:38:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:04:58.675994"
    },
    {
      "arxiv_id": "2410.11176v1",
      "title": "Improving Bias in Facial Attribute Classification: A Combined Impact of KL Divergence induced Loss Function and Dual Attention",
      "title_zh": "翻译失败",
      "authors": [
        "Shweta Patel",
        "Dakshina Ranjan Kisku"
      ],
      "abstract": "Ensuring that AI-based facial recognition systems produce fair predictions\nand work equally well across all demographic groups is crucial. Earlier systems\noften exhibited demographic bias, particularly in gender and racial\nclassification, with lower accuracy for women and individuals with darker skin\ntones. To tackle this issue and promote fairness in facial recognition,\nresearchers have introduced several bias-mitigation techniques for gender\nclassification and related algorithms. However, many challenges remain, such as\ndata diversity, balancing fairness with accuracy, disparity, and bias\nmeasurement. This paper presents a method using a dual attention mechanism with\na pre-trained Inception-ResNet V1 model, enhanced by KL-divergence\nregularization and a cross-entropy loss function. This approach reduces bias\nwhile improving accuracy and computational efficiency through transfer\nlearning. The experimental results show significant improvements in both\nfairness and classification accuracy, providing promising advances in\naddressing bias and enhancing the reliability of facial recognition systems.",
      "tldr_zh": "本论文针对面部属性分类中的人口统计学偏差问题（如性别和种族分类中对女性和深色皮肤个体的较低准确率），提出了一种结合 KL Divergence 诱导损失函数和 Dual Attention 机制的方法。研究使用预训练的 Inception-ResNet V1 模型，通过 KL-divergence 正则化和交叉熵损失函数进行优化，并利用转移学习提升准确性和计算效率。该方法在实验中显著改善了公平性和分类准确性，为减少 AI 面部识别系统的偏差并增强其可靠性提供了重要进展。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "68T06",
        "I.2.10"
      ],
      "primary_category": "cs.CV",
      "comment": "15 pages, 9 figures, 5 tables",
      "pdf_url": "http://arxiv.org/pdf/2410.11176v1",
      "published_date": "2024-10-15 01:29:09 UTC",
      "updated_date": "2024-10-15 01:29:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:05:14.987640"
    },
    {
      "arxiv_id": "2410.11162v1",
      "title": "Towards General Deepfake Detection with Dynamic Curriculum",
      "title_zh": "翻译失败",
      "authors": [
        "Wentang Song",
        "Yuzhen Lin",
        "Bin Li"
      ],
      "abstract": "Most previous deepfake detection methods bent their efforts to discriminate\nartifacts by end-to-end training. However, the learned networks often fail to\nmine the general face forgery information efficiently due to ignoring the data\nhardness. In this work, we propose to introduce the sample hardness into the\ntraining of deepfake detectors via the curriculum learning paradigm.\nSpecifically, we present a novel simple yet effective strategy, named Dynamic\nFacial Forensic Curriculum (DFFC), which makes the model gradually focus on\nhard samples during the training. Firstly, we propose Dynamic Forensic Hardness\n(DFH) which integrates the facial quality score and instantaneous instance loss\nto dynamically measure sample hardness during the training. Furthermore, we\npresent a pacing function to control the data subsets from easy to hard\nthroughout the training process based on DFH. Comprehensive experiments show\nthat DFFC can improve both within- and cross-dataset performance of various\nkinds of end-to-end deepfake detectors through a plug-and-play approach. It\nindicates that DFFC can help deepfake detectors learn general forgery\ndiscriminative features by effectively exploiting the information from hard\nsamples.",
      "tldr_zh": "本文提出了一种名为 Dynamic Facial Forensic Curriculum (DFFC) 的策略，以提升深度伪造检测器的泛化能力。DFFC 通过课程学习范式动态引入样本难度，具体包括 Dynamic Forensic Hardness (DFH) 方法，该方法结合面部质量分数和即时实例损失来评估样本 hardness，并使用 pacing function 控制训练过程从易到难。实验结果表明，DFFC 以插件式方式显著提高了各种端到端检测器的内部和跨数据集性能，帮助模型更有效地从困难样本中学习一般伪造鉴别特征。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Received by ICASSP 2024 - 2024 IEEE International Conference on\n  Acoustics, Speech and Signal Processing (ICASSP)",
      "pdf_url": "http://arxiv.org/pdf/2410.11162v1",
      "published_date": "2024-10-15 00:58:09 UTC",
      "updated_date": "2024-10-15 00:58:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:05:25.323815"
    },
    {
      "arxiv_id": "2410.22349v1",
      "title": "Search Engines in an AI Era: The False Promise of Factual and Verifiable Source-Cited Responses",
      "title_zh": "AI时代下的搜索引擎：事实性和可验证的引用来源响应的虚假承诺",
      "authors": [
        "Pranav Narayanan Venkit",
        "Philippe Laban",
        "Yilun Zhou",
        "Yixin Mao",
        "Chien-Sheng Wu"
      ],
      "abstract": "Large Language Model (LLM)-based applications are graduating from research\nprototypes to products serving millions of users, influencing how people write\nand consume information. A prominent example is the appearance of Answer\nEngines: LLM-based generative search engines supplanting traditional search\nengines. Answer engines not only retrieve relevant sources to a user query but\nsynthesize answer summaries that cite the sources. To understand these systems'\nlimitations, we first conducted a study with 21 participants, evaluating\ninteractions with answer vs. traditional search engines and identifying 16\nanswer engine limitations. From these insights, we propose 16 answer engine\ndesign recommendations, linked to 8 metrics. An automated evaluation\nimplementing our metrics on three popular engines (You.com, Perplexity.ai,\nBingChat) quantifies common limitations (e.g., frequent hallucination,\ninaccurate citation) and unique features (e.g., variation in answer\nconfidence), with results mirroring user study insights. We release our Answer\nEngine Evaluation benchmark (AEE) to facilitate transparent evaluation of\nLLM-based applications.",
      "tldr_zh": "本研究探讨了基于大型语言模型(LLM)的Answer Engines（生成式搜索引擎）在AI时代的问题，这些引擎虽能检索来源并合成引用答案，但往往无法提供可靠的事实和可验证响应。通过一项涉及21名参与者的用户研究，论文识别出Answer Engines的16个局限性（如频繁hallucination和不准确引用），并据此提出16个设计推荐及8个评估指标。自动化评估结果显示，You.com、Perplexity.ai和BingChat等引擎存在常见缺陷，同时反映了用户研究的见解；最终，研究发布了Answer Engine Evaluation benchmark (AEE) 以推动LLM应用的透明评估。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CL",
        "cs.CY",
        "cs.HC"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.22349v1",
      "published_date": "2024-10-15 00:50:31 UTC",
      "updated_date": "2024-10-15 00:50:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:05:36.865925"
    },
    {
      "arxiv_id": "2410.11155v1",
      "title": "Latent-Predictive Empowerment: Measuring Empowerment without a Simulator",
      "title_zh": "翻译失败",
      "authors": [
        "Andrew Levy",
        "Alessandro Allievi",
        "George Konidaris"
      ],
      "abstract": "Empowerment has the potential to help agents learn large skillsets, but is\nnot yet a scalable solution for training general-purpose agents. Recent\nempowerment methods learn diverse skillsets by maximizing the mutual\ninformation between skills and states; however, these approaches require a\nmodel of the transition dynamics, which can be challenging to learn in\nrealistic settings with high-dimensional and stochastic observations. We\npresent Latent-Predictive Empowerment (LPE), an algorithm that can compute\nempowerment in a more practical manner. LPE learns large skillsets by\nmaximizing an objective that is a principled replacement for the mutual\ninformation between skills and states and that only requires a simpler\nlatent-predictive model rather than a full simulator of the environment. We\nshow empirically in a variety of settings--including ones with high-dimensional\nobservations and highly stochastic transition dynamics--that our empowerment\nobjective (i) learns similar-sized skillsets as the leading empowerment\nalgorithm that assumes access to a model of the transition dynamics and (ii)\noutperforms other model-based approaches to empowerment.",
      "tldr_zh": "该论文提出Latent-Predictive Empowerment (LPE)，一种无需完整环境模拟器的算法，用于测量Empowerment，帮助代理学习多样技能。该方法通过最大化一个替代mutual information的客观指标，仅需一个简单的latent-predictive模型，即可实现高效技能学习，避免了现有方法对过渡动态模型的依赖。在高维观察和高随机性过渡动态的环境中，实验结果显示LPE能学习与领先算法相当规模的技能集，并优于其他基于模型的方法。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "cs.RO"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.11155v1",
      "published_date": "2024-10-15 00:41:18 UTC",
      "updated_date": "2024-10-15 00:41:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:05:49.356791"
    },
    {
      "arxiv_id": "2410.11150v1",
      "title": "Optimizing Encoder-Only Transformers for Session-Based Recommendation Systems",
      "title_zh": "翻译失败",
      "authors": [
        "Anis Redjdal",
        "Luis Pinto",
        "Michel Desmarais"
      ],
      "abstract": "Session-based recommendation is the task of predicting the next item a user\nwill interact with, often without access to historical user data. In this work,\nwe introduce Sequential Masked Modeling, a novel approach for encoder-only\ntransformer architectures to tackle the challenges of single-session\nrecommendation. Our method combines data augmentation through window sliding\nwith a unique penultimate token masking strategy to capture sequential\ndependencies more effectively. By enhancing how transformers handle session\ndata, Sequential Masked Modeling significantly improves next-item prediction\nperformance.\n  We evaluate our approach on three widely-used datasets, Yoochoose 1/64,\nDiginetica, and Tmall, comparing it to state-of-the-art single-session,\ncross-session, and multi-relation approaches. The results demonstrate that our\nTransformer-SMM models consistently outperform all models that rely on the same\namount of information, while even rivaling methods that have access to more\nextensive user history. This study highlights the potential of encoder-only\ntransformers in session-based recommendation and opens the door for further\nimprovements.",
      "tldr_zh": "本研究针对基于会话的推荐系统（Session-Based Recommendation），提出了一种优化Encoder-Only Transformers的方法，即Sequential Masked Modeling，以提升单会话推荐的性能。该方法结合数据增强技术（如window sliding）和独特的penultimate token masking策略，更有效地捕获序列依赖性，从而改善下一个物品预测的准确性。在Yoochoose 1/64、Diginetica和Tmall等数据集上的实验显示，Transformer-SMM模型在相同信息量下优于现有单会话、跨会话和多关系方法，甚至可与利用更多用户历史数据的模型竞争。该工作突显了Encoder-Only Transformers在会话推荐领域的潜力，并为后续优化提供新方向。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.11150v1",
      "published_date": "2024-10-15 00:23:18 UTC",
      "updated_date": "2024-10-15 00:23:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:06:02.173171"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 144,
  "processed_papers_count": 144,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-20T12:06:17.729795"
}