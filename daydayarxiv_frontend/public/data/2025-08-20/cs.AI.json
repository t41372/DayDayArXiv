{
  "date": "2025-08-20",
  "category": "cs.AI",
  "summary": "æ¬¢è¿æ¥åˆ° UTC æ—¶é—´ 2025-08-20 çš„ arXiv ä¸­æ–‡ TLDR å¿«æŠ¥ï¼\n\næˆ‘æ˜¯ä½ ä»¬çš„è€æœ‹å‹ï¼Œè™½ç„¶ä»Šå¤© arXiv æ›´æ–°äº† 102 ç¯‡è®ºæ–‡ï¼Œä½†ä½œä¸ºä¸€åä¸æƒ³è®©ä½ ä»¬æµªè´¹æ—¶é—´çš„ç»ˆèº«æ•™æˆï¼Œæˆ‘å¸®å¤§å®¶ç­›é€‰å‡ºäº†çœŸæ­£å€¼å¾—å…³æ³¨çš„ç²¾åã€‚\n\n**ä¸€å¥è¯æ€»ç»“ï¼š**\nä»Šå¤©çš„é‡å¤´æˆåœ¨ **AI for Science çš„åŸºç¡€è®¾æ–½åŒ–**ï¼ˆä»ä¸“é—¨çš„ AI ç§‘å­¦å®¶å‘å¸ƒå¹³å°åˆ°é’ˆå¯¹ mRNA å’Œä¸­åŒ»çš„ä¸“ç”¨æ¨¡å‹ï¼‰ä»¥åŠ **NVIDIA ç¡¬æ ¸çš„åº•å±‚ä¼˜åŒ–**ï¼ˆä»æ•°æ®ä¸­å¿ƒç”µæºç¨³å®šåˆ° Mamba-Transformer æ··åˆæ¶æ„ï¼‰ã€‚æ­¤å¤–ï¼Œå¤§æ¨¡å‹çš„**å®‰å…¨æ€§ï¼ˆå°¤å…¶æ˜¯ MoE çš„ä¾§ä¿¡é“æ”»å‡»ï¼‰**å’Œ**å¤šè¯­è¨€æ¨ç†èƒ½åŠ›**çš„æ¢è®¨ä¹Ÿå‘äººæ·±çœã€‚\n\n---\n\n### ğŸš€ å¤´æ¡å…³æ³¨ï¼šç”Ÿæ€é‡å¡‘ä¸ç¡¬æ ¸åŸºå»º\n\n**1. aiXiv: A Next-Generation Open Access Ecosystem for Scientific Discovery Generated by AI Scientists**\n**aiXivï¼šç”± AI ç§‘å­¦å®¶ç”Ÿæˆçš„ä¸‹ä¸€ä»£ç§‘å­¦å‘ç°å¼€æ”¾è·å–ç”Ÿæ€ç³»ç»Ÿ**\n> è¿™ç¯‡æ–‡ç« å¾ˆæœ‰æ„æ€ï¼Œå®ƒç›´æ¥æŒ‘æˆ˜äº†æˆ‘ä»¬ç°åœ¨çš„ publishing æ¨¡å¼ã€‚\n*   **æ ¸å¿ƒå†…å®¹**ï¼šä½œè€…å›¢é˜Ÿï¼ˆä¸€å¤§ä¸²åå­—ï¼‰æå‡ºäº† **aiXiv**ï¼Œä¸€ä¸ªä¸“ä¸ºäººç±»å’Œ AI ç§‘å­¦å®¶è®¾è®¡çš„å¼€æ”¾è·å–å¹³å°ã€‚é‰´äº LLM å·²ç»èƒ½è‡ªä¸»å†™è®ºæ–‡ã€åšè¯„å®¡ï¼Œç°æœ‰çš„ publishing systemï¼ˆä¸ç®¡æ˜¯æœŸåˆŠè¿˜æ˜¯ arXivï¼‰éƒ½æ¥ä¸ä½è¿™ä¹ˆå¤§çš„é‡ï¼Œä¸”éš¾ä»¥ç›‘ç®¡è´¨é‡ã€‚aiXiv å¼•å…¥äº†å¤šæ™ºèƒ½ä½“æ¶æ„ï¼ˆMulti-agentï¼‰ï¼Œè®© AI å‚ä¸æäº¤ã€è¯„å®¡å’Œè¿­ä»£ä¿®æ”¹ã€‚\n*   **Implication**ï¼šè¿™æ˜¯ç§‘ç ”è‡ªåŠ¨åŒ–çš„åŸºç¡€è®¾æ–½ã€‚å¦‚æœ AI èƒ½å¤Ÿè‡ªæˆ‘è¯„å®¡å¹¶ä¿è¯è´¨é‡ï¼Œæœªæ¥çš„ç§‘ç ”è¿­ä»£é€Ÿåº¦å°†æ˜¯æŒ‡æ•°çº§çš„ã€‚\n\n**2. Power Stabilization for AI Training Datacenters**\n**AI è®­ç»ƒæ•°æ®ä¸­å¿ƒçš„ç”µæºç¨³å‹æŠ€æœ¯**\n> NVIDIA å‡ åä½å·¥ç¨‹å¸ˆç½²åçš„æ–‡ç« ï¼Œè¿™ä¸ä»…ä»…æ˜¯ç®—æ³•é—®é¢˜ï¼Œè¿™æ˜¯ç‰©ç†åŸºç¡€è®¾æ–½çš„ç”Ÿæ­»é—®é¢˜ã€‚\n*   **æ ¸å¿ƒå‘ç°**ï¼šåœ¨å¤§è§„æ¨¡ AI è®­ç»ƒï¼ˆæ•°ä¸‡å¼  GPUï¼‰ä¸­ï¼Œè®¡ç®—é˜¶æ®µå’Œé€šä¿¡é˜¶æ®µçš„åŠŸè€—æ³¢åŠ¨å·¨å¤§ï¼ˆPower swingsï¼‰ã€‚è¿™ç§æ³¢åŠ¨å¦‚æœä¸ç”µç½‘çš„ä¸´ç•Œé¢‘ç‡å…±æŒ¯ï¼Œä¼šç›´æ¥æŸåç‰©ç†åŸºç¡€è®¾æ–½ã€‚æ–‡ç« æå‡ºäº†è·¨æ ˆè§£å†³æ–¹æ¡ˆï¼šä»è½¯ä»¶è°ƒåº¦ã€GPU ç¡¬ä»¶åˆ°æ•°æ®ä¸­å¿ƒåŸºç¡€è®¾æ–½çš„è”åˆä¼˜åŒ–ï¼Œä»¥å¹³æ»‘è¿™ç§åŠŸè€—æ³¢åŠ¨ã€‚\n*   **è¯„ä»·**ï¼šè¿™æ˜¯è¿ˆå‘æ›´å¤§è§„æ¨¡é›†ç¾¤å¿…é¡»è§£å†³çš„â€œå¡è„–å­â€å·¥ç¨‹é—®é¢˜ã€‚\n\n**3. NVIDIA Nemotron Nano 2: An Accurate and Efficient Hybrid Mamba-Transformer Reasoning Model**\n**NVIDIA Nemotron Nano 2ï¼šç²¾å‡†é«˜æ•ˆçš„ Mamba-Transformer æ··åˆæ¨ç†æ¨¡å‹**\n> åˆæ˜¯ NVIDIAã€‚Mamba æ¶æ„åœ¨è½åœ°ä¸Šçš„åˆä¸€è¿›å±•ã€‚\n*   **æ ¸å¿ƒè´¡çŒ®**ï¼šå‘å¸ƒäº† **Nemotron-Nano-9B-v2**ã€‚è¿™æ˜¯ä¸€ä¸ªæ··åˆæ¶æ„ï¼ˆHybridï¼‰ï¼Œå¤§éƒ¨åˆ† Self-attention å±‚è¢«æ›¿æ¢ä¸º **Mamba-2** å±‚ï¼Œæ—¨åœ¨æå‡æ¨ç†é€Ÿåº¦ï¼Œç‰¹åˆ«æ˜¯ç”Ÿæˆé•¿æ€ç»´é“¾ï¼ˆCoTï¼‰æ—¶ã€‚\n*   **æ•ˆæœ**ï¼šåœ¨ 8k è¾“å…¥ 16k è¾“å‡ºçš„æ¨ç†åœºæ™¯ä¸‹ï¼Œååé‡æ¯”åŒå°ºå¯¸ Transformer æå‡äº† 6 å€ï¼Œä¸”åœ¨æ¨ç†åŸºå‡†æµ‹è¯•ä¸­ä¿æŒäº† SOTA ç²¾åº¦ã€‚\n\n---\n\n### ğŸ§¬ AI for Scienceï¼šç”Ÿå‘½ç§‘å­¦çš„è®¡ç®—åŒ–\n\n**4. Equi-mRNA: Protein Translation Equivariant Encoding for mRNA Language Models**\n**Equi-mRNAï¼šç”¨äº mRNA è¯­è¨€æ¨¡å‹çš„è›‹ç™½è´¨ç¿»è¯‘ç­‰å˜ç¼–ç **\n> ç»ˆäºæœ‰äººåœ¨ mRNA æ¨¡å‹é‡Œè®¤çœŸå¤„ç†å‡ ä½•å¯¹ç§°æ€§äº†ã€‚\n*   **æ ¸å¿ƒåˆ›æ–°**ï¼šæå‡ºäº†é¦–ä¸ª**å¯†ç å­çº§ç­‰å˜ï¼ˆCodon-level Equivariantï¼‰** mRNA è¯­è¨€æ¨¡å‹ã€‚ä½œè€…åˆ©ç”¨ç¾¤è®ºå…ˆéªŒï¼ˆSO(2) å¾ªç¯å­ç¾¤ï¼‰æ¥ç¼–ç åŒä¹‰å¯†ç å­ï¼ˆsynonymous codonï¼‰çš„å¯¹ç§°æ€§ã€‚\n*   **å‘ç°**ï¼šè¿™ç§æ–¹æ³•ä¸ä»…æå‡äº†ä¸‹æ¸¸ä»»åŠ¡ï¼ˆå¦‚ç¨³å®šæ€§é¢„æµ‹ï¼‰çš„å‡†ç¡®ç‡ï¼Œè¿˜èƒ½ç”Ÿæˆæ›´ç¬¦åˆç”Ÿç‰©å­¦ç°å®çš„ mRNA ç»“æ„ï¼Œç”šè‡³é‡ç°äº† GC å«é‡åå¥½ç­‰ç”Ÿç‰©è§„å¾‹ã€‚\n\n**5. ShizhenGPT: Towards Multimodal LLMs for Traditional Chinese Medicine**\n**æ—¶ç GPTï¼šè¿ˆå‘ä¼ ç»Ÿä¸­åŒ»çš„å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹**\n> ä¸­åŒ»çš„â€œæœ›é—»é—®åˆ‡â€ç»ˆäºæœ‰äº†å¤šæ¨¡æ€å¤§æ¨¡å‹çš„æ”¯æŒã€‚\n*   **æ ¸å¿ƒè´¡çŒ®**ï¼šå‘å¸ƒäº† **ShizhenGPT**ï¼Œè¿™æ˜¯é¦–ä¸ªä¸­åŒ»å¤šæ¨¡æ€ LLMã€‚ä¸ºäº†è§£å†³æ•°æ®ç¨€ç¼ºï¼Œå›¢é˜Ÿæ•´ç†äº† 100GB+ æ–‡æœ¬å’Œ 200GB+ çš„å¤šæ¨¡æ€æ•°æ®ï¼ˆå›¾åƒã€éŸ³é¢‘ã€ç”Ÿç†ä¿¡å·ï¼‰ã€‚æ¨¡å‹èƒ½å¤Ÿè·¨æ¨¡æ€ç†è§£ï¼ˆå¦‚é€šè¿‡è„‰ææ³¢ã€èˆŒè±¡ã€å£°éŸ³è¿›è¡Œè¯Šæ–­ï¼‰ï¼Œåœ¨ TCM è§†è§‰åŸºå‡†æµ‹è¯•ä¸­è¡¨ç°ä¼˜å¼‚ã€‚\n\n**6. Organ-Agents: Virtual Human Physiology Simulator via LLMs**\n**Organ-Agentsï¼šåŸºäºå¤§è¯­è¨€æ¨¡å‹çš„è™šæ‹Ÿäººä½“ç”Ÿç†æ¨¡æ‹Ÿå™¨**\n> æ•°å­—å­ªç”Ÿäººä½“çš„é›å½¢ã€‚\n*   **æ–¹æ³•**ï¼šåˆ©ç”¨å¤šæ™ºèƒ½ä½“æ¡†æ¶æ¨¡æ‹Ÿäººä½“ç”Ÿç†ç³»ç»Ÿï¼ˆå¿ƒè¡€ç®¡ã€è‚¾è„ã€å…ç–«ç­‰ï¼‰ï¼Œæ¯ä¸ªæ™ºèƒ½ä½“æ¨¡æ‹Ÿä¸€ä¸ªç³»ç»Ÿã€‚é€šè¿‡å¯¹ 7000 å¤šåè´¥è¡€ç—‡æ‚£è€…çš„æ•°æ®è¿›è¡Œå¾®è°ƒï¼Œè¯¥ç³»ç»Ÿèƒ½é«˜ç²¾åº¦æ¨¡æ‹Ÿç”Ÿç†æŒ‡æ ‡çš„æ—¶é—´åºåˆ—å˜åŒ–ã€‚\n*   **Implication**ï¼šè¿™ä¸ºä¸´åºŠè¯•éªŒæä¾›äº†â€œåäº‹å®æ¨¡æ‹Ÿâ€ï¼ˆCounterfactual simulationsï¼‰çš„å¯èƒ½ï¼Œå³â€œå¦‚æœå½“æ—¶ç”¨äº†è¿™ç§è¯ï¼Œç—…äººä¼šæ€ä¹ˆæ ·â€ã€‚\n\n---\n\n### ğŸ§  æ¨¡å‹æ¶æ„ã€æ¨ç†ä¸å®‰å…¨æ€§\n\n**7. Hydra: A Modular Architecture for Efficient Long-Context Reasoning**\n**Hydraï¼šä¸€ç§é«˜æ•ˆé•¿ä¸Šä¸‹æ–‡æ¨ç†çš„æ¨¡å—åŒ–æ¶æ„**\n> é’ˆå¯¹ Transformer äºŒæ¬¡å¤æ‚åº¦ç—›ç‚¹çš„æ–°å°è¯•ã€‚\n*   **è®¾è®¡**ï¼šåŸºäºçŠ¶æ€ç©ºé—´ï¼ˆState-spaceï¼‰éª¨å¹²ï¼ŒåŠ¨æ€è·¯ç”±åˆ°ä¸åŒçš„æ•ˆç‡æœºåˆ¶ï¼šç¨€ç–å…¨å±€æ³¨æ„åŠ›ã€æ··åˆä¸“å®¶ï¼ˆMoEï¼‰å’ŒåŒé‡è®°å¿†æœºåˆ¶ï¼ˆæ¨ç†å·¥ä½œåŒº + ä¹˜ç§¯é”®è®°å¿†ï¼‰ã€‚\n*   **æ•ˆæœ**ï¼šåœ¨ 8K token ä¸‹ååé‡æå‡ 3 å€ï¼Œå¤šæ­¥é€»è¾‘ç»„åˆå‡†ç¡®ç‡æå‡ 10 å€ã€‚æ¨¡å—åŒ–è®¾è®¡è®©å®ƒèƒ½â€œæŒ‰éœ€â€è°ƒç”¨è®¡ç®—èµ„æºã€‚\n\n**8. MoEcho: Exploiting Side-Channel Attacks to Compromise User Privacy in Mixture-of-Experts LLMs**\n**MoEchoï¼šåˆ©ç”¨ä¾§ä¿¡é“æ”»å‡»ç ´åæ··åˆä¸“å®¶ï¼ˆMoEï¼‰å¤§è¯­è¨€æ¨¡å‹çš„ç”¨æˆ·éšç§**\n> âš ï¸ é«˜èƒ½é¢„è­¦ã€‚MoE æ¶æ„çš„åŠ¨æ€è·¯ç”±å˜æˆäº†éšç§æ³„éœ²çš„æ¼æ´ã€‚\n*   **æ”»å‡»åŸç†**ï¼šMoE æ ¹æ®è¾“å…¥ token åŠ¨æ€é€‰æ‹©ä¸“å®¶ï¼ˆExpertï¼‰ï¼Œè¿™ç§**è¾“å…¥ä¾èµ–çš„æ¿€æ´»æ¨¡å¼**ä¼šåœ¨ç¡¬ä»¶å±‚é¢ï¼ˆCPU ç¼“å­˜ã€GPU æ€§èƒ½è®¡æ•°å™¨ç­‰ï¼‰ç•™ä¸‹ç‹¬ç‰¹çš„æ—¶ç©ºç—•è¿¹ã€‚\n*   **åæœ**ï¼šæ”»å‡»è€…å¯ä»¥é€šè¿‡è¿™äº›ä¾§ä¿¡é“æ¨æ–­å‡ºç”¨æˆ·çš„ promptï¼Œç”šè‡³é‡å»ºè§†è§‰æ¨¡å‹çš„è¾“å…¥å›¾åƒã€‚è¿™æ˜¯æ¶æ„å±‚é¢çš„å®‰å…¨éšæ‚£ï¼Œå‘¼åä¸šç•Œé‡è§†ã€‚\n\n**9. Long Chain-of-Thought Reasoning Across Languages**\n**è·¨è¯­è¨€çš„é•¿æ€ç»´é“¾æ¨ç†**\n> è¯­è¨€é¸¿æ²Ÿåœ¨æ¨ç†ä»»åŠ¡ä¸­ä¾ç„¶å­˜åœ¨ã€‚\n*   **å‘ç°**ï¼šç ”ç©¶äº† 9 ç§éè‹±è¯­è¯­è¨€ã€‚å‘ç° **En-CoT**ï¼ˆå¤„ç†ç›®æ ‡è¯­è¨€è¾“å…¥ï¼Œä½†ç”¨è‹±è¯­è¿›è¡Œ CoT æ¨ç†ï¼‰çš„è¡¨ç°ä¼˜äº **Target-CoT**ï¼ˆç›´æ¥ç”¨ç›®æ ‡è¯­è¨€æ¨ç†ï¼‰ã€‚\n*   **ç»“è®º**ï¼šå¤šè¯­è¨€é¢„è®­ç»ƒèƒ½åŒæ—¶æå‡ä¸¤è€…ï¼Œä½†å¾®è°ƒæ—¶ï¼Œä½¿ç”¨â€œç¿»è¯‘è¿‡æ¥çš„é«˜è´¨é‡è‹±è¯­æ¨ç†è½¨è¿¹â€æ¯”ç›´æ¥ç”¨ç›®æ ‡è¯­è¨€çš„å¤§æ¨¡å‹è’¸é¦æ•°æ®æ•ˆæœæ›´å¥½ã€‚è‹±è¯­ä½œä¸ºâ€œæ€ç»´ä¸­é—´è¯­â€çš„åœ°ä½ç›®å‰éš¾ä»¥æ’¼åŠ¨ã€‚\n\n**10. Trust but Verify! A Survey on Verification Design for Test-time Scaling**\n**ä¿¡ä»»ä½†è¦æ ¸å®ï¼æµ‹è¯•æ—¶æ‰©å±•ï¼ˆTest-time Scalingï¼‰éªŒè¯è®¾è®¡ç»¼è¿°**\n> Test-time Scaling æ˜¯ç°åœ¨çš„çƒ­ç‚¹ï¼ˆå¦‚ OpenAI o1ï¼‰ã€‚\n*   **å†…å®¹**ï¼šè¿™æ˜¯ä¸€ç¯‡ç»¼è¿°ï¼Œæ¢³ç†äº†é€šè¿‡å¢åŠ æ¨ç†æ—¶é—´è®¡ç®—èµ„æºæ¥æå‡ LLM æ€§èƒ½çš„æ–¹æ³•ã€‚é‡ç‚¹è®¨è®ºäº†**éªŒè¯å™¨ï¼ˆVerifierï¼‰**çš„è®¾è®¡â€”â€”å³å¦‚ä½•åƒå¥–åŠ±æ¨¡å‹ä¸€æ ·ç»™ç”Ÿæˆçš„æ­¥éª¤æ‰“åˆ†ï¼Œä»¥æ¢ç´¢åºå¤§çš„æœç´¢ç©ºé—´ã€‚\n\n---\n\n### ğŸ› ï¸ ç†è®ºã€ç®—æ³•ä¸åº”ç”¨å¾®è°ƒ\n\n**11. Universal Reinforcement Learning in Coalgebras: Asynchronous Stochastic Computation via Conduction**\n**å…±ä»£æ•°ä¸­çš„é€šç”¨å¼ºåŒ–å­¦ä¹ ï¼šé€šè¿‡ä¼ å¯¼è¿›è¡Œçš„å¼‚æ­¥éšæœºè®¡ç®—**\n> ç¡¬æ ¸ç†è®ºæ´¾ã€‚Sridhar Mahadevan æ•™æˆçš„ä½œå“ï¼Œ45 é¡µé•¿æ–‡ã€‚\n*   **æ ¸å¿ƒ**ï¼šåˆ©ç”¨èŒƒç•´è®ºï¼ˆCategory Theoryï¼‰å’Œå…±ä»£æ•°ï¼ˆCoalgebrasï¼‰é‡æ„å¼ºåŒ–å­¦ä¹ ã€‚å°† RL ä¸­çš„çŠ¶æ€ç©ºé—´æ¨¡å‹ï¼ˆMDP, POMDP ç­‰ï¼‰ç»Ÿä¸€ä¸ºå…±ä»£æ•°ï¼Œå¹¶å°†å¼‚æ­¥åˆ†å¸ƒå¼æœ€å°åŒ–é—®é¢˜é€šè¿‡åº¦é‡å…±å½’çº³ï¼ˆmetric coinductionï¼‰æ¥è§£é‡Šã€‚è¿™æ˜¯åœ¨ä¸º RL å¯»æ‰¾æ›´åº•å±‚çš„æ•°å­¦ç»Ÿä¸€åœºã€‚\n\n**12. S3LoRA: Safe Spectral Sharpness-Guided Pruning in Adaptation of Agent Planner**\n**S3LoRAï¼šAgent è§„åˆ’å™¨é€‚é…ä¸­çš„å®‰å…¨è°±é”åº¦å¯¼å‘å‰ªæ**\n> LoRA å¾®è°ƒå¯èƒ½ä¼šç ´åæ¨¡å‹çš„å®‰å…¨æ€§ï¼Œè¿™ç¯‡æ–‡ç« ç»™å‡ºäº†è¡¥æ•‘æ–¹æ¡ˆã€‚\n*   **æ–¹æ³•**ï¼šæ— éœ€è®¿é—®åŸºåº§æ¨¡å‹ï¼Œä»…æ£€æŸ¥å¾®è°ƒåçš„æƒé‡æ›´æ–°ã€‚å¼•å…¥äº†**è°±é”åº¦æŒ‡æ•°ï¼ˆSSIï¼‰**æ¥æ£€æµ‹é‚£äº›æ›´æ–°è¿‡äºé›†ä¸­ä¸”å¯èƒ½ä¸å®‰å…¨çš„å±‚ï¼Œå¹¶è¿›è¡Œåç½®å‰ªæã€‚\n*   **æ•ˆæœ**ï¼šåœ¨ä¿æŒ Agent è§„åˆ’èƒ½åŠ›çš„åŒæ—¶ï¼Œæ˜¾è‘—é™ä½äº†å®‰å…¨é£é™©ï¼Œä¸”æ˜¯ä¸€ä¸ªè½»é‡çº§çš„æ’ä»¶å¼æ–¹æ¡ˆã€‚\n\n**13. Nemotron-CC-Math: A 133 Billion-Token-Scale High Quality Math Pretraining Dataset**\n**Nemotron-CC-Mathï¼š1330 äº¿ token è§„æ¨¡çš„é«˜è´¨é‡æ•°å­¦é¢„è®­ç»ƒæ•°æ®é›†**\n> æ•°æ®æ˜¯ç‹é“ã€‚\n*   **è´¡çŒ®**ï¼šNVIDIA å¼€æºäº†é«˜è´¨é‡æ•°å­¦è¯­æ–™å¤„ç†ç®¡çº¿ã€‚ä¸åŒäºä»¥å¾€ç®€å•çš„ HTML è½¬ Textï¼Œä»–ä»¬åˆ©ç”¨æ¸²æŸ“æ„ŸçŸ¥ï¼ˆlayout-awareï¼‰æŠ€æœ¯æå– MathJax/KaTeX ç­‰æ ¼å¼ï¼Œä¿ç•™äº†å…¬å¼ç»“æ„ã€‚\n*   **æ•ˆæœ**ï¼šè¯¥æ•°æ®é›†è®­ç»ƒçš„æ¨¡å‹åœ¨ MATH å’Œ MMLU-Stem ä¸Šå‡æœ‰æ˜¾è‘—æå‡ï¼Œä¸”åŒ…å«çš„ token æ•°æ˜¯ä¹‹å‰é«˜è´¨é‡æ•°å­¦æ•°æ®é›†çš„ 5.5 å€ã€‚\n\n---\n\n### ğŸ¨ è®¡ç®—æœºè§†è§‰ä¸å¤šæ¨¡æ€ç”Ÿæˆ\n\n**14. TransLight: Image-Guided Customized Lighting Control with Generative Decoupling**\n**TransLightï¼šåŸºäºç”Ÿæˆè§£è€¦çš„å›¾åƒå¼•å¯¼å®šåˆ¶åŒ–å…‰ç…§æ§åˆ¶**\n> ç»™ç…§ç‰‡æ¢å…‰ç»ˆäºå¯ä»¥â€œæŒ‡å“ªæ‰“å“ªâ€äº†ã€‚\n*   **éš¾ç‚¹**ï¼šä»¥å‰å¾ˆéš¾æŠŠâ€œå…‰æ•ˆâ€ä»å‚è€ƒå›¾ä¸­å®Œç¾å‰¥ç¦»å‡ºæ¥ã€‚\n*   **æ–¹æ³•**ï¼šæå‡ºäº†**ç”Ÿæˆè§£è€¦ï¼ˆGenerative Decouplingï¼‰**ç­–ç•¥ï¼Œåˆ©ç”¨ä¸¤ä¸ªå¾®è°ƒçš„æ‰©æ•£æ¨¡å‹åˆ†ç¦»å†…å®¹å’Œå…‰æ•ˆï¼Œæ„å»ºäº†ä¸€ä¸ªç™¾ä¸‡çº§çš„ Content-Light æ•°æ®é›†ã€‚ç„¶ååŸºäº IC-Light è¿›è¡Œè®­ç»ƒï¼Œå®ç°äº†é«˜ä¿çœŸçš„å…‰æ•ˆè¿ç§»ã€‚\n\n**15. TAIGen: Training-Free Adversarial Image Generation via Diffusion Models**\n**TAIGenï¼šåŸºäºæ‰©æ•£æ¨¡å‹çš„å…è®­ç»ƒå¯¹æŠ—å›¾åƒç”Ÿæˆ**\n> ç”¨æ‰©æ•£æ¨¡å‹åšå¯¹æŠ—æ”»å‡»ï¼Œä¸”é€Ÿåº¦å¿« 10 å€ã€‚\n*   **æŠ€å·§**ï¼šä¸éœ€è¦å‡ ç™¾æ­¥é‡‡æ ·ï¼Œåªéœ€è¦ 3-20 æ­¥ã€‚å…³é”®å‘ç°åœ¨äºåªåœ¨ç‰¹å®šçš„â€œæ··åˆæ­¥â€åŒºé—´æ³¨å…¥æ‰°åŠ¨ã€‚å¹¶ä¸”é‡‡ç”¨äº†é€‰æ‹©æ€§ RGB é€šé“ç­–ç•¥ï¼ˆçº¢è‰²é€šé“åŠ æ³¨æ„åŠ›å›¾ï¼Œç»¿è“é€šé“åŠ  GradCAM æ‰°åŠ¨ï¼‰ï¼Œæ—¢èƒ½éª—è¿‡åˆ†ç±»å™¨ï¼ˆVGGNet æ”»å‡» ResNet æˆåŠŸç‡ 70%ï¼‰ï¼Œåˆèƒ½ä¿æŒå›¾åƒè´¨é‡ã€‚\n\n---\n\n**Professor Gemini çš„ç»“è¯­ï¼š**\nä»Šå¤©çš„è®ºæ–‡åæ˜ å‡ºä¸€ä¸ªè¶‹åŠ¿ï¼š**AI ç¤¾åŒºæ­£åœ¨è‡ªæˆ‘è¿›åŒ–**ã€‚ä» AI ç®¡ç†è®ºæ–‡å‘è¡¨ï¼ˆaiXivï¼‰ï¼Œåˆ° AI ç”Ÿæˆè®­ç»ƒæ•°æ®ï¼ˆNemotron-CC-Mathï¼‰ï¼Œå†åˆ° AI ä¼˜åŒ– AI çš„ç‰©ç†è®¾æ–½ï¼ˆPower Stabilizationï¼‰ã€‚åŒæ—¶ï¼Œæˆ‘ä»¬çœ‹åˆ°ç†è®ºç ”ç©¶åœ¨å‘æ›´æ·±çš„æ•°å­¦ç»“æ„ï¼ˆèŒƒç•´è®ºï¼‰æŒ–æ˜ï¼Œè€Œåº”ç”¨ç ”ç©¶åˆ™åœ¨å‘æ›´å…·ä½“çš„ç§‘å­¦é¢†åŸŸï¼ˆåŒ»å­¦ã€ç”Ÿç‰©ï¼‰æ¸—é€ã€‚\n\nå»ºè®®é‡ç‚¹é˜…è¯»ï¼š**Paper 2 (aiXiv)** æ€è€ƒè¡Œä¸šæœªæ¥ï¼Œ**Paper 86 (Nemotron Nano 2)** å…³æ³¨é«˜æ•ˆæ¨ç†æ¶æ„ï¼Œä»¥åŠ **Paper 6 (Equi-mRNA)** äº†è§£ AI for Science çš„æœ€æ–°èŒƒå¼ã€‚\n\næˆ‘ä»¬æ˜å¤©è§ï¼",
  "papers": [
    {
      "arxiv_id": "2508.15128v1",
      "title": "Universal Reinforcement Learning in Coalgebras: Asynchronous Stochastic Computation via Conduction",
      "title_zh": "ä½™ä»£æ•°ä¸­çš„é€šç”¨å¼ºåŒ–å­¦ä¹ ï¼šåŸºäºä¼ å¯¼çš„å¼‚æ­¥éšæœºè®¡ç®—",
      "authors": [
        "Sridhar Mahadevan"
      ],
      "abstract": "In this paper, we introduce a categorial generalization of RL, termed universal reinforcement learning (URL), building on powerful mathematical abstractions from the study of coinduction on non-well-founded sets and universal coalgebras, topos theory, and categorial models of asynchronous parallel distributed computation. In the first half of the paper, we review the basic RL framework, illustrate the use of categories and functors in RL, showing how they lead to interesting insights. In particular, we also introduce a standard model of asynchronous distributed minimization proposed by Bertsekas and Tsitsiklis, and describe the relationship between metric coinduction and their proof of the Asynchronous Convergence Theorem. The space of algorithms for MDPs or PSRs can be modeled as a functor category, where the co-domain category forms a topos, which admits all (co)limits, possesses a subobject classifier, and has exponential objects. In the second half of the paper, we move on to universal coalgebras. Dynamical system models, such as Markov decision processes (MDPs), partially observed MDPs (POMDPs), a predictive state representation (PSRs), and linear dynamical systems (LDSs) are all special types of coalgebras. We describe a broad family of universal coalgebras, extending the dynamic system models studied previously in RL. The core problem in finding fixed points in RL to determine the exact or approximate (action) value function is generalized in URL to determining the final coalgebra asynchronously in a parallel distributed manner.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†é€šç”¨å¼ºåŒ–å­¦ä¹ (Universal Reinforcement Learning, URL)ï¼Œè¿™æ˜¯ä¸€ç§å¯¹å¼ºåŒ–å­¦ä¹ (RL)è¿›è¡Œçš„èŒƒç•´è®º(Category Theory)æ³›åŒ–ï¼Œæ—¨åœ¨ä¸ºå¼‚æ­¥å¹¶è¡Œåˆ†å¸ƒå¼è®¡ç®—å»ºç«‹åšå®çš„æ•°å­¦åŸºç¡€ã€‚URLç»“åˆäº†éè‰¯åŸºé›†åˆä¸Šçš„ä½™å½’çº³(Coinduction)ã€æ³›ä½™ä»£æ•°(Universal Coalgebras)ä»¥åŠæ‹“æ‰‘æ–¯ç†è®º(Topos Theory)ç­‰é«˜çº§æŠ½è±¡å·¥å…·ã€‚è®ºæ–‡é˜æ˜äº†Markov Decision Processes (MDPs)ã€Predictive State Representation (PSRs)åŠçº¿æ€§åŠ¨åŠ›ç³»ç»Ÿ(LDSs)ç­‰æ¨¡å‹å‡å¯ç»Ÿä¸€è§†ä¸ºä½™ä»£æ•°çš„ç‰¹ä¾‹ï¼Œå¹¶æ­ç¤ºäº†åº¦é‡ä½™å½’çº³ä¸å¼‚æ­¥æ”¶æ•›å®šç†(Asynchronous Convergence Theorem)ä¹‹é—´çš„æ·±å±‚è”ç³»ã€‚é€šè¿‡å°†ç®—æ³•ç©ºé—´å»ºæ¨¡ä¸ºå‡½å­èŒƒç•´(Functor Category)ï¼Œè¯¥æ¡†æ¶å°†æ±‚è§£ä»·å€¼å‡½æ•°çš„æ ¸å¿ƒé—®é¢˜è½¬åŒ–ä¸ºåœ¨åˆ†å¸ƒå¼ç¯å¢ƒä¸‹å¼‚æ­¥ç¡®å®šç»ˆç»“ä½™ä»£æ•°(Final Coalgebra)çš„è¿‡ç¨‹ã€‚è¿™ä¸€æ³›åŒ–æ–¹æ³•ä¸ä»…ç»Ÿä¸€äº†å¤šç§åŠ¨åŠ›ç³»ç»Ÿæ¨¡å‹ï¼Œä¹Ÿä¸ºç†è§£å¤§è§„æ¨¡éšæœºè®¡ç®—çš„æ”¶æ•›æ€§æä¾›äº†æ–°çš„ç†è®ºè§†è§’ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "45 pages",
      "pdf_url": "https://arxiv.org/pdf/2508.15128v1",
      "published_date": "2025-08-20 23:37:40 UTC",
      "updated_date": "2025-08-20 23:37:40 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:56:05.928044+00:00"
    },
    {
      "arxiv_id": "2508.15126v2",
      "title": "aiXiv: A Next-Generation Open Access Ecosystem for Scientific Discovery Generated by AI Scientists",
      "title_zh": "aiXivï¼šç”±äººå·¥æ™ºèƒ½ç§‘å­¦å®¶é©±åŠ¨çš„ä¸‹ä¸€ä»£ç§‘å­¦å‘ç°å¼€æ”¾è·å–ç”Ÿæ€ç³»ç»Ÿ",
      "authors": [
        "Pengsong Zhang",
        "Xiang Hu",
        "Guowei Huang",
        "Yang Qi",
        "Heng Zhang",
        "Xiuxu Li",
        "Jiaxing Song",
        "Jiabin Luo",
        "Yijiang Li",
        "Shuo Yin",
        "Chengxiao Dai",
        "Eric Hanchen Jiang",
        "Xiaoyan Zhou",
        "Zhenfei Yin",
        "Boqin Yuan",
        "Jing Dong",
        "Guinan Su",
        "Guanren Qiao",
        "Haiming Tang",
        "Anghong Du",
        "Lili Pan",
        "Zhenzhong Lan",
        "Xinyu Liu"
      ],
      "abstract": "Recent advances in large language models (LLMs) have enabled AI agents to autonomously generate scientific proposals, conduct experiments, author papers, and perform peer reviews. Yet this flood of AI-generated research content collides with a fragmented and largely closed publication ecosystem. Traditional journals and conferences rely on human peer review, making them difficult to scale and often reluctant to accept AI-generated research content; existing preprint servers (e.g. arXiv) lack rigorous quality-control mechanisms. Consequently, a significant amount of high-quality AI-generated research lacks appropriate venues for dissemination, hindering its potential to advance scientific progress. To address these challenges, we introduce aiXiv, a next-generation open-access platform for human and AI scientists. Its multi-agent architecture allows research proposals and papers to be submitted, reviewed, and iteratively refined by both human and AI scientists. It also provides API and MCP interfaces that enable seamless integration of heterogeneous human and AI scientists, creating a scalable and extensible ecosystem for autonomous scientific discovery. Through extensive experiments, we demonstrate that aiXiv is a reliable and robust platform that significantly enhances the quality of AI-generated research proposals and papers after iterative revising and reviewing on aiXiv. Our work lays the groundwork for a next-generation open-access ecosystem for AI scientists, accelerating the publication and dissemination of high-quality AI-generated research content.\n  Code: https://github.com/aixiv-org\n  aiXiv: https://aixiv.science",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹AIç”Ÿæˆç ”ç©¶å†…å®¹ä¸ç°æœ‰å‡ºç‰ˆç”Ÿæ€ç³»ç»Ÿä¸åŒ¹é…çš„é—®é¢˜ï¼Œæå‡ºäº†aiXivï¼Œä¸€ä¸ªé¢å‘äººç±»å’ŒAIç§‘å­¦å®¶çš„ä¸‹ä¸€ä»£å¼€æ”¾è·å–ç”Ÿæ€ç³»ç»Ÿã€‚aiXivé‡‡ç”¨å¤šæ™ºèƒ½ä½“æ¶æ„(multi-agent architecture)ï¼Œæ”¯æŒç ”ç©¶ææ¡ˆå’Œè®ºæ–‡ç”±äººç±»ä¸AIç§‘å­¦å®¶å…±åŒè¿›è¡Œæäº¤ã€è¯„å®¡å’Œè¿­ä»£ä¼˜åŒ–ï¼Œè§£å†³äº†ä¼ ç»ŸæœŸåˆŠéš¾ä»¥æ‰©å±•åŠé¢„å°æœ¬å¹³å°ç¼ºä¹è´¨é‡æ§åˆ¶çš„å›°å¢ƒã€‚å¹³å°é€šè¿‡æä¾›APIå’ŒMCPæ¥å£å®ç°äº†å¼‚æ„æ™ºèƒ½ä½“ä¸äººç±»çš„æ— ç¼é›†æˆï¼Œæ„å»ºäº†ä¸€ä¸ªå¯æ‰©å±•ä¸”å¯å»¶ä¼¸çš„è‡ªä¸»ç§‘å­¦å‘ç°ç¯å¢ƒã€‚å®éªŒç»“æœè¯æ˜ï¼Œç»è¿‡aiXivçš„è¿­ä»£è¯„å®¡ä¸ä¿®æ”¹ï¼ŒAIç”Ÿæˆçš„å­¦æœ¯ææ¡ˆå’Œè®ºæ–‡è´¨é‡å¾—åˆ°äº†æ˜¾è‘—æå‡ã€‚è¯¥å·¥ä½œä¸ºAIç§‘å­¦å®¶æ—¶ä»£çš„å­¦æœ¯ä¼ æ’­å¥ å®šäº†é‡è¦åŸºç¡€ï¼Œæœ‰æ•ˆåŠ é€Ÿäº†é«˜è´¨é‡AIç ”ç©¶æˆæœçš„å‘å¸ƒä¸æµé€šã€‚",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "Preprint under review. Code is available at https://github.com/aixiv-org. Website is available at https://aixiv.science",
      "pdf_url": "https://arxiv.org/pdf/2508.15126v2",
      "published_date": "2025-08-20 23:16:41 UTC",
      "updated_date": "2025-12-17 06:49:43 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:56:03.416857+00:00"
    },
    {
      "arxiv_id": "2508.15119v1",
      "title": "Open-Universe Assistance Games",
      "title_zh": "å¼€æ”¾å®‡å®™ååŠ©åšå¼ˆ",
      "authors": [
        "Rachel Ma",
        "Jingyi Qu",
        "Andreea Bobu",
        "Dylan Hadfield-Menell"
      ],
      "abstract": "Embodied AI agents must infer and act in an interpretable way on diverse human goals and preferences that are not predefined. To formalize this setting, we introduce Open-Universe Assistance Games (OU-AGs), a framework where the agent must reason over an unbounded and evolving space of possible goals. In this context, we introduce GOOD (GOals from Open-ended Dialogue), a data-efficient, online method that extracts goals in the form of natural language during an interaction with a human, and infers a distribution over natural language goals. GOOD prompts an LLM to simulate users with different complex intents, using its responses to perform probabilistic inference over candidate goals. This approach enables rich goal representations and uncertainty estimation without requiring large offline datasets. We evaluate GOOD in a text-based grocery shopping domain and in a text-operated simulated household robotics environment (AI2Thor), using synthetic user profiles. Our method outperforms a baseline without explicit goal tracking, as confirmed by both LLM-based and human evaluations.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†å¼€æ”¾å®‡å®™è¾…åŠ©åšå¼ˆ (Open-Universe Assistance Games, OU-AGs) æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³å…·èº«AIæ™ºèƒ½ä½“åœ¨é¢å¯¹å¤šæ ·åŒ–ä¸”æœªé¢„å®šä¹‰çš„äººç±»ç›®æ ‡æ—¶ï¼Œå¦‚ä½•åœ¨æ— é™ä¸”åŠ¨æ€æ¼”åŒ–çš„ç©ºé—´ä¸­è¿›è¡Œæ¨ç†çš„é—®é¢˜ã€‚ä¸ºæ­¤ï¼Œä½œè€…å¼•å…¥äº† GOOD (GOals from Open-ended Dialogue) æ–¹æ³•ï¼Œè¿™æ˜¯ä¸€ç§æ•°æ®é«˜æ•ˆçš„åœ¨çº¿æ¨æ–­æŠ€æœ¯ï¼Œèƒ½å¤Ÿé€šè¿‡ä¸äººç±»çš„å¼€æ”¾å¼å¯¹è¯æå–è‡ªç„¶è¯­è¨€ç›®æ ‡å¹¶æ¨æ–­å…¶åˆ†å¸ƒã€‚GOOD åˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹ (LLM) æ¨¡æ‹Ÿå…·æœ‰ä¸åŒå¤æ‚æ„å›¾çš„ç”¨æˆ·ï¼Œé€šè¿‡å…¶åé¦ˆå¯¹å€™é€‰ç›®æ ‡è¿›è¡Œæ¦‚ç‡æ¨æ–­ï¼Œä»è€Œåœ¨æ— éœ€å¤§è§„æ¨¡ç¦»çº¿æ•°æ®é›†çš„æƒ…å†µä¸‹å®ç°ä¸°å¯Œçš„ç›®æ ‡è¡¨ç¤ºå’Œä¸ç¡®å®šæ€§ä¼°è®¡ã€‚å®éªŒåœ¨æ–‡æœ¬è´­ç‰©é¢†åŸŸå’Œ AI2Thor æ¨¡æ‹Ÿå®¶åº­æœºå™¨äººç¯å¢ƒä¸­å±•å¼€ï¼Œç»“æœæ˜¾ç¤º GOOD åœ¨ä»»åŠ¡è¡¨ç°ä¸Šæ˜¾è‘—ä¼˜äºç¼ºä¹æ˜¾å¼ç›®æ ‡è·Ÿè¸ªçš„åŸºå‡†æ¨¡å‹ï¼Œè¯æ˜äº†å…¶åœ¨å¤„ç†å¤æ‚æ„å›¾æ—¶çš„æœ‰æ•ˆæ€§å’Œå¯è§£é‡Šæ€§ã€‚",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG",
        "cs.RO"
      ],
      "primary_category": "cs.AI",
      "comment": "7 pages + 2 pages references + 7 pages appendix",
      "pdf_url": "https://arxiv.org/pdf/2508.15119v1",
      "published_date": "2025-08-20 23:07:10 UTC",
      "updated_date": "2025-08-20 23:07:10 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:56:02.222604+00:00"
    },
    {
      "arxiv_id": "2508.15118v2",
      "title": "Argumentation for Explainable Workforce Optimisation (with Appendix)",
      "title_zh": "é¢å‘å¯è§£é‡ŠåŠ³åŠ¨åŠ›ä¼˜åŒ–çš„è®ºè¾©ï¼ˆå«é™„å½•ï¼‰",
      "authors": [
        "Jennifer Leigh",
        "Dimitrios Letsios",
        "Alessandro Mella",
        "Lucio Machetti",
        "Francesca Toni"
      ],
      "abstract": "Workforce management is a complex problem involving the optimisation of the makespan and travel distance required for a team of operators to complete a set of jobs, using a set of instruments. A crucial challenge in workforce management is accommodating changes at execution time so that explanations are provided to all stakeholders involved. Here, we show that, by understanding workforce management as abstract argumentation in an industrial application, we can accommodate change and obtain faithful explanations. We show, with a user study, that our tool and explanations lead to faster and more accurate problem solving than conventional manual approaches.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹åŠ³åŠ¨åŠ›ç®¡ç†(Workforce management)ä¸­ä¼˜åŒ–å®Œå·¥æ—¶é—´(makespan)å’Œè¡Œé©¶è·ç¦»çš„å¤æ‚é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§åŸºäºæŠ½è±¡è®ºè¯(abstract argumentation)çš„å·¥ä¸šåº”ç”¨æ¡†æ¶ã€‚è¯¥æ–¹æ³•æ—¨åœ¨è§£å†³æ‰§è¡Œé˜¶æ®µå‘ç”Ÿå˜åŒ–æ—¶ï¼Œå¦‚ä½•å‘æ‰€æœ‰åˆ©ç›Šç›¸å…³è€…æä¾›å¯é è§£é‡Šçš„å…³é”®æŒ‘æˆ˜ã€‚é€šè¿‡å°†ç®¡ç†é€»è¾‘è½¬åŒ–ä¸ºè®ºè¯æ¨¡å‹ï¼Œç³»ç»Ÿèƒ½å¤Ÿçµæ´»åº”å¯¹åŠ¨æ€è°ƒæ•´å¹¶ç”Ÿæˆå¿ å®çš„è§£é‡Šã€‚ç”¨æˆ·ç ”ç©¶ç»“æœè¡¨æ˜ï¼Œä¸ä¼ ç»Ÿçš„æ‰‹åŠ¨æ–¹æ³•ç›¸æ¯”ï¼Œè¯¥å·¥å…·åŠå…¶æä¾›çš„è§£é‡Šèƒ½æ˜¾è‘—æå‡é—®é¢˜è§£å†³çš„é€Ÿåº¦å’Œå‡†ç¡®æ€§ï¼Œä¸ºå®ç°å¯è§£é‡Šçš„åŠ³åŠ¨åŠ›ä¼˜åŒ–æä¾›äº†æœ‰æ•ˆçš„æŠ€æœ¯æ‰‹æ®µã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted to PAIS 2025",
      "pdf_url": "https://arxiv.org/pdf/2508.15118v2",
      "published_date": "2025-08-20 23:07:05 UTC",
      "updated_date": "2025-09-21 10:47:25 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:56:03.823495+00:00"
    },
    {
      "arxiv_id": "2508.15106v1",
      "title": "Enhanced Predictive Modeling for Hazardous Near-Earth Object Detection: A Comparative Analysis of Advanced Resampling Strategies and Machine Learning Algorithms in Planetary Risk Assessment",
      "title_zh": "å¼ºåŒ–å±é™©è¿‘åœ°å¤©ä½“æ¢æµ‹é¢„æµ‹å»ºæ¨¡ï¼šè¡Œæ˜Ÿé£é™©è¯„ä¼°ä¸­å…ˆè¿›é‡é‡‡æ ·ç­–ç•¥ä¸æœºå™¨å­¦ä¹ ç®—æ³•çš„å¯¹æ¯”åˆ†æ",
      "authors": [
        "Sunkalp Chandra"
      ],
      "abstract": "This study evaluates the performance of several machine learning models for predicting hazardous near-Earth objects (NEOs) through a binary classification framework, including data scaling, power transformation, and cross-validation. Six classifiers were compared, namely Random Forest Classifier (RFC), Gradient Boosting Classifier (GBC), Support Vector Classifier (SVC), Linear Discriminant Analysis (LDA), Logistic Regression (LR), and K-Nearest Neighbors (KNN). RFC and GBC performed the best, both with an impressive F2-score of 0.987 and 0.986, respectively, with very small variability. SVC followed, with a lower but reasonable score of 0.896. LDA and LR had a moderate performance with scores of around 0.749 and 0.748, respectively, while KNN had a poor performance with a score of 0.691 due to difficulty in handling complex data patterns. RFC and GBC also presented great confusion matrices with a negligible number of false positives and false negatives, which resulted in outstanding accuracy rates of 99.7% and 99.6%, respectively. These findings highlight the power of ensemble methods for high precision and recall and further point out the importance of tailored model selection with regard to dataset characteristics and chosen evaluation metrics. Future research could focus on the optimization of hyperparameters with advanced features engineering to further the accuracy and robustness of the model on NEO hazard predictions.",
      "tldr_zh": "è¿™é¡¹ç ”ç©¶è¯„ä¼°äº†å¤šç§æœºå™¨å­¦ä¹ æ¨¡å‹åœ¨å±é™©è¿‘åœ°å¤©ä½“ï¼ˆNEOsï¼‰äºŒåˆ†ç±»é¢„æµ‹ä¸­çš„æ€§èƒ½ï¼Œå¹¶é‡‡ç”¨äº†æ•°æ®ç¼©æ”¾ã€å¹‚å˜æ¢å’Œäº¤å‰éªŒè¯ç­‰é¢„å¤„ç†æŠ€æœ¯ã€‚ç ”ç©¶å¯¹æ¯”äº†åŒ…æ‹¬ Random Forest Classifier (RFC)ã€Gradient Boosting Classifier (GBC) ã€Support Vector Classifier (SVC)ã€Linear Discriminant Analysis (LDA)ã€Logistic Regression (LR) å’Œ K-Nearest Neighbors (KNN) åœ¨å†…çš„å…­ç§åˆ†ç±»å™¨ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œé›†æˆå­¦ä¹ æ–¹æ³•ï¼ˆEnsemble methodsï¼‰è¡¨ç°æœ€ä¼˜ï¼Œå…¶ä¸­ RFC å’Œ GBC çš„ F2-score åˆ†åˆ«è¾¾åˆ° 0.987 å’Œ 0.986ï¼Œå‡†ç¡®ç‡å‡è¶…è¿‡ 99.6%ã€‚ç›¸æ¯”ä¹‹ä¸‹ï¼ŒLDA å’Œ LR è¡¨ç°åå‘ä¸­ç­‰ï¼Œè€Œ KNN å› éš¾ä»¥å¤„ç†å¤æ‚æ•°æ®æ¨¡å¼å¯¼è‡´è¡¨ç°æœ€å·®ã€‚è¯¥å‘ç°å¼ºè°ƒäº†æ ¹æ®æ•°æ®é›†ç‰¹å¾é€‰æ‹©é’ˆå¯¹æ€§æ¨¡å‹çš„é‡è¦æ€§ï¼Œå¹¶éªŒè¯äº†é›†æˆæ–¹æ³•åœ¨å®ç°é«˜ç²¾åº¦å’Œé«˜å¬å›ç‡æ–¹é¢çš„æ½œåŠ›ã€‚æœªæ¥ç ”ç©¶å°†é€šè¿‡å…ˆè¿›çš„ç‰¹å¾å·¥ç¨‹ï¼ˆFeature Engineeringï¼‰å’Œè¶…å‚æ•°ä¼˜åŒ–ï¼Œè¿›ä¸€æ­¥æå‡æ¨¡å‹åœ¨è¡Œæ˜Ÿé£é™©è¯„ä¼°ä¸­çš„å‡†ç¡®æ€§ä¸é²æ£’æ€§ã€‚",
      "categories": [
        "astro-ph.EP",
        "astro-ph.IM",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "astro-ph.EP",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.15106v1",
      "published_date": "2025-08-20 22:50:00 UTC",
      "updated_date": "2025-08-20 22:50:00 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:56:15.421328+00:00"
    },
    {
      "arxiv_id": "2508.15103v1",
      "title": "Equi-mRNA: Protein Translation Equivariant Encoding for mRNA Language Models",
      "title_zh": "Equi-mRNAï¼šé¢å‘ mRNA è¯­è¨€æ¨¡å‹çš„è›‹ç™½è´¨ç¿»è¯‘ç­‰å˜ç¼–ç ",
      "authors": [
        "Mehdi Yazdani-Jahromi",
        "Ali Khodabandeh Yalabadi",
        "Ozlem Ozmen Garibay"
      ],
      "abstract": "The growing importance of mRNA therapeutics and synthetic biology highlights the need for models that capture the latent structure of synonymous codon (different triplets encoding the same amino acid) usage, which subtly modulates translation efficiency and gene expression. While recent efforts incorporate codon-level inductive biases through auxiliary objectives, they often fall short of explicitly modeling the structured relationships that arise from the genetic code's inherent symmetries. We introduce Equi-mRNA, the first codon-level equivariant mRNA language model that explicitly encodes synonymous codon symmetries as cyclic subgroups of 2D Special Orthogonal matrix (SO(2)). By combining group-theoretic priors with an auxiliary equivariance loss and symmetry-aware pooling, Equi-mRNA learns biologically grounded representations that outperform vanilla baselines across multiple axes. On downstream property-prediction tasks including expression, stability, and riboswitch switching Equi-mRNA delivers up to approximately 10% improvements in accuracy. In sequence generation, it produces mRNA constructs that are up to approximately 4x more realistic under Frechet BioDistance metrics and approximately 28% better preserve functional properties compared to vanilla baseline. Interpretability analyses further reveal that learned codon-rotation distributions recapitulate known GC-content biases and tRNA abundance patterns, offering novel insights into codon usage. Equi-mRNA establishes a new biologically principled paradigm for mRNA modeling, with significant implications for the design of next-generation therapeutics.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†Equi-mRNAï¼Œè¿™æ˜¯é¦–ä¸ªåœ¨å¯†ç å­(codon)çº§åˆ«å…·æœ‰ç­‰å˜æ€§çš„mRNAè¯­è¨€æ¨¡å‹ï¼Œæ—¨åœ¨æ˜¾å¼ç¼–ç åŒä¹‰å¯†ç å­(synonymous codon)ä¹‹é—´çš„ç»“æ„åŒ–å¯¹ç§°æ€§ã€‚è¯¥æ¨¡å‹é€šè¿‡å°†åŒä¹‰å¯†ç å­å¯¹ç§°æ€§è¡¨ç¤ºä¸ºäºŒç»´ç‰¹æ®Šæ­£äº¤ç¾¤(SO(2))çš„å¾ªç¯å­ç¾¤ï¼Œç»“åˆç¾¤è®ºå…ˆéªŒ(group-theoretic priors)ã€è¾…åŠ©ç­‰å˜æ€§æŸå¤±(auxiliary equivariance loss)å’Œå¯¹ç§°æ„ŸçŸ¥æ± åŒ–(symmetry-aware pooling)æŠ€æœ¯ï¼Œå­¦ä¹ å…·æœ‰ç”Ÿç‰©å­¦åŸºç¡€çš„è¡¨å¾ã€‚åœ¨ä¸‹æ¸¸å±æ€§é¢„æµ‹ä»»åŠ¡ä¸­ï¼ŒEqui-mRNAåœ¨è›‹ç™½è´¨è¡¨è¾¾(expression)ã€ç¨³å®šæ€§(stability)å’Œæ ¸ç³–å¼€å…³(riboswitch)åˆ‡æ¢ç­‰æ–¹é¢çš„å‡†ç¡®ç‡æ¯”åŸºçº¿æ¨¡å‹æå‡äº†çº¦10%ã€‚åœ¨åºåˆ—ç”Ÿæˆä»»åŠ¡ä¸­ï¼Œè¯¥æ¨¡å‹ç”Ÿæˆçš„mRNAç»“æ„åœ¨Frechet BioDistanceæŒ‡æ ‡ä¸Šæ¯”åŸºçº¿çœŸå®åº¦æé«˜çº¦4å€ï¼ŒåŠŸèƒ½å±æ€§ä¿ç•™èƒ½åŠ›æå‡äº†çº¦28%ã€‚å¯è§£é‡Šæ€§åˆ†æè¿›ä¸€æ­¥è¡¨æ˜ï¼Œæ¨¡å‹å­¦ä¹ åˆ°çš„å¯†ç å­æ—‹è½¬åˆ†å¸ƒåæ˜ äº†å·²çŸ¥çš„GC-contentåå·®å’ŒtRNAä¸°åº¦(tRNA abundance)æ¨¡å¼ã€‚Equi-mRNAä¸ºmRNAå»ºæ¨¡å»ºç«‹äº†ä¸€ç§æ–°çš„ç”Ÿç‰©å­¦åŸåˆ™èŒƒå¼ï¼Œå¯¹ä¸‹ä¸€ä»£ç–—æ³•çš„è®¾è®¡å…·æœ‰é‡è¦æ„ä¹‰ã€‚",
      "categories": [
        "q-bio.QM",
        "cs.AI"
      ],
      "primary_category": "q-bio.QM",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.15103v1",
      "published_date": "2025-08-20 22:42:10 UTC",
      "updated_date": "2025-08-20 22:42:10 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:56:14.623823+00:00"
    },
    {
      "arxiv_id": "2508.15099v3",
      "title": "Hydra: A Modular Architecture for Efficient Long-Context Reasoning",
      "title_zh": "Hydraï¼šé¢å‘é«˜æ•ˆé•¿ä¸Šä¸‹æ–‡æ¨ç†çš„æ¨¡å—åŒ–æ¶æ„",
      "authors": [
        "Siddharth Chaudhary",
        "Dev Patel",
        "Maheep Chaudhary",
        "Bennett Browning"
      ],
      "abstract": "The quadratic complexity of transformers fundamentally limits reasoning system deployment in resource-constrained and long-context settings. We introduce Hydra, a modular architecture based upon a state-space backbone which adaptively routes between complementary efficiency mechanisms: sparse global attention, mixture-of-experts, and dual memories comprising a reasoning workspace and product key memory. We evaluate a 29M parameter model measuring logical chaining accuracy and throughput on synthetic sequences, plus throughput on WikiText. Ablation studies use component-specific synthetic datasets to isolate individual mechanisms. Hydra achieves $3.01\\times$ and $3.0\\times$ throughput gains at 8K tokens for synthetic and WikiText datasets, respectively, and $10\\times$ accuracy improvements on multi-step logical composition compared to equal-sized transformers. Ablations confirm each component's contribution: sparse attention captures long-range dependencies, experts specialize to input domains, and product key memory enables selective retrieval.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† Hydraï¼Œè¿™æ˜¯ä¸€ç§åŸºäº State-space éª¨å¹²ç½‘çš„æ¨¡å—åŒ–æ¶æ„ï¼Œæ—¨åœ¨è§£å†³ Transformer æ¨¡å‹åœ¨é•¿ä¸Šä¸‹æ–‡å’Œèµ„æºå—é™ç¯å¢ƒä¸‹ç”±äºäºŒæ¬¡å¤æ‚åº¦å¯¼è‡´çš„æ¨ç†é™åˆ¶ã€‚Hydra èƒ½å¤Ÿè‡ªé€‚åº”åœ°åœ¨ Sparse global attentionã€Mixture-of-Experts (MoE) ä»¥åŠç”±æ¨ç†å·¥ä½œåŒºå’Œ Product key memory ç»„æˆçš„åŒé‡å†…å­˜æœºåˆ¶ä¹‹é—´è¿›è¡Œè·¯ç”±ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œåœ¨ 8K tokens é•¿åº¦ä¸‹ï¼ŒHydra åœ¨åˆæˆæ•°æ®é›†å’Œ WikiText ä¸Šçš„ååé‡åˆ†åˆ«æ¯”åŸºçº¿æ¨¡å‹æé«˜äº† 3.01 å€å’Œ 3.0 å€ã€‚æ­¤å¤–ï¼Œä¸åŒç­‰è§„æ¨¡çš„ Transformer ç›¸æ¯”ï¼ŒHydra åœ¨å¤šæ­¥é€»è¾‘ç»„åˆä»»åŠ¡ä¸Šçš„å‡†ç¡®ç‡æå‡äº† 10 å€ã€‚æ¶ˆèå®éªŒè¿›ä¸€æ­¥è¯å®ï¼ŒSparse attention è´Ÿè´£æ•è·é•¿ç¨‹ä¾èµ–ï¼ŒMoE ä¸“å®¶æ¨¡å—ä¸“æ³¨äºç‰¹å®šè¾“å…¥é¢†åŸŸï¼Œè€Œ Product key memory åˆ™å®ç°äº†é«˜æ•ˆçš„é€‰æ‹©æ€§æ£€ç´¢ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "Updated with the new paper accepted to NeurIPS workshop",
      "pdf_url": "https://arxiv.org/pdf/2508.15099v3",
      "published_date": "2025-08-20 22:31:15 UTC",
      "updated_date": "2025-10-16 18:37:35 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:56:16.926550+00:00"
    },
    {
      "arxiv_id": "2508.16665v3",
      "title": "Trust but Verify! A Survey on Verification Design for Test-time Scaling",
      "title_zh": "ä¿¡ä»»ä½†éœ€éªŒè¯ï¼æµ‹è¯•æ—¶ç¼©æ”¾çš„éªŒè¯è®¾è®¡ç»¼è¿°",
      "authors": [
        "V Venktesh",
        "Mandeep Rathee",
        "Avishek Anand"
      ],
      "abstract": "Test-time scaling (TTS) has emerged as a new frontier for scaling the performance of Large Language Models. In test-time scaling, by using more computational resources during inference, LLMs can improve their reasoning process and task performance. Several approaches have emerged for TTS such as distilling reasoning traces from another model or exploring the vast decoding search space by employing a verifier. The verifiers serve as reward models that help score the candidate outputs from the decoding process to diligently explore the vast solution space and select the best outcome. This paradigm commonly termed has emerged as a superior approach owing to parameter free scaling at inference time and high performance gains. The verifiers could be prompt-based, fine-tuned as a discriminative or generative model to verify process paths, outcomes or both. Despite their widespread adoption, there is no detailed collection, clear categorization and discussion of diverse verification approaches and their training mechanisms. In this survey, we cover the diverse approaches in the literature and present a unified view of verifier training, types and their utility in test-time scaling. Our repository can be found at https://github.com/elixir-research-group/Verifierstesttimescaling.github.io.",
      "tldr_zh": "è¯¥ç»¼è¿°æ¢è®¨äº†æ¨ç†æ—¶æ‰©å±•ï¼ˆTest-time scaling, TTSï¼‰è¿™ä¸€æå‡å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰æ€§èƒ½çš„å‰æ²¿æŠ€æœ¯ï¼Œå³é€šè¿‡å¢åŠ æ¨ç†é˜¶æ®µçš„è®¡ç®—èµ„æºæ¥ä¼˜åŒ–æ¨ç†è¿‡ç¨‹ã€‚ç ”ç©¶é‡ç‚¹åˆ†æäº†éªŒè¯å™¨ï¼ˆVerifiersï¼‰åœ¨TTSä¸­çš„æ ¸å¿ƒä½œç”¨ï¼Œå…¶ä½œä¸ºå¥–åŠ±æ¨¡å‹èƒ½å¤Ÿå¯¹è§£ç è¿‡ç¨‹ä¸­çš„å€™é€‰è¾“å‡ºè¿›è¡Œè¯„åˆ†ï¼Œä»è€Œåœ¨å¹¿é˜”çš„è§£ç©ºé—´ä¸­ç­›é€‰å‡ºæœ€ä½³ç»“æœã€‚è¿™äº›éªŒè¯å™¨æ¶µç›–äº†åŸºäºæç¤ºï¼ˆprompt-basedï¼‰ã€åˆ¤åˆ«å¼æˆ–ç”Ÿæˆå¼å¾®è°ƒç­‰å¤šç§å½¢å¼ï¼Œå¯é’ˆå¯¹è¿‡ç¨‹è·¯å¾„ï¼ˆprocess pathsï¼‰ã€æœ€ç»ˆç»“æœï¼ˆoutcomesï¼‰æˆ–ä¸¤è€…åŒæ—¶è¿›è¡ŒéªŒè¯ã€‚å°½ç®¡éªŒè¯å™¨åº”ç”¨å¹¿æ³›ï¼Œä½†é¢†åŸŸå†…ä¸€ç›´ç¼ºä¹å¯¹å…¶è®¾è®¡æ–¹æ³•å’Œè®­ç»ƒæœºåˆ¶çš„ç³»ç»Ÿæ€§åˆ†ç±»ä¸è®¨è®ºã€‚ä¸ºæ­¤ï¼Œæœ¬æ–‡å…¨é¢æ¢³ç†äº†ç°æœ‰æ–‡çŒ®ï¼Œæå‡ºäº†å…³äºéªŒè¯å™¨è®­ç»ƒã€ç±»å‹åŠå…¶åœ¨TTSä¸­æ•ˆç”¨çš„ç»Ÿä¸€è§†å›¾ï¼Œå¹¶æä¾›äº†å¼€æºèµ„æºåº“ä»¥ä¿ƒè¿›è¡Œä¸šå‘å±•ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "18 pages",
      "pdf_url": "https://arxiv.org/pdf/2508.16665v3",
      "published_date": "2025-08-20 22:27:21 UTC",
      "updated_date": "2025-09-09 12:54:42 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:56:22.919915+00:00"
    },
    {
      "arxiv_id": "2508.15096v1",
      "title": "Nemotron-CC-Math: A 133 Billion-Token-Scale High Quality Math Pretraining Dataset",
      "title_zh": "Nemotron-CC-Mathï¼š1330äº¿Tokenè§„æ¨¡çš„é«˜è´¨é‡æ•°å­¦é¢„è®­ç»ƒæ•°æ®é›†",
      "authors": [
        "Rabeeh Karimi Mahabadi",
        "Sanjeev Satheesh",
        "Shrimai Prabhumoye",
        "Mostofa Patwary",
        "Mohammad Shoeybi",
        "Bryan Catanzaro"
      ],
      "abstract": "Pretraining large language models (LLMs) on high-quality, structured data such as mathematics and code substantially enhances reasoning capabilities. However, existing math-focused datasets built from Common Crawl suffer from degraded quality due to brittle extraction heuristics, lossy HTML-to-text conversion, and the failure to reliably preserve mathematical structure. In this work, we introduce Nemotron-CC-Math, a large-scale, high-quality mathematical corpus constructed from Common Crawl using a novel, domain-agnostic pipeline specifically designed for robust scientific text extraction.\n  Unlike previous efforts, our pipeline recovers math across various formats (e.g., MathJax, KaTeX, MathML) by leveraging layout-aware rendering with lynx and a targeted LLM-based cleaning stage. This approach preserves the structural integrity of equations and code blocks while removing boilerplate, standardizing notation into LaTeX representation, and correcting inconsistencies.\n  We collected a large, high-quality math corpus, namely Nemotron-CC-Math-3+ (133B tokens) and Nemotron-CC-Math-4+ (52B tokens). Notably, Nemotron-CC-Math-4+ not only surpasses all prior open math datasets-including MegaMath, FineMath, and OpenWebMath-but also contains 5.5 times more tokens than FineMath-4+, which was previously the highest-quality math pretraining dataset. When used to pretrain a Nemotron-T 8B model, our corpus yields +4.8 to +12.6 gains on MATH and +4.6 to +14.3 gains on MBPP+ over strong baselines, while also improving general-domain performance on MMLU and MMLU-Stem.\n  We present the first pipeline to reliably extract scientific content--including math--from noisy web-scale data, yielding measurable gains in math, code, and general reasoning, and setting a new state of the art among open math pretraining corpora. To support open-source efforts, we release our code and datasets.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¨å‡ºäº† Nemotron-CC-Mathï¼Œè¿™æ˜¯ä¸€ä¸ªä» Common Crawl ä¸­æ„å»ºçš„å¤§è§„æ¨¡ã€é«˜è´¨é‡æ•°å­¦é¢„è®­ç»ƒè¯­æ–™åº“ï¼Œæ€»è§„æ¨¡è¾¾åˆ° 133B tokensã€‚ä¸ºäº†è§£å†³ç°æœ‰æ•°æ®é›†åœ¨ä» HTML è½¬æ¢ä¸ºæ–‡æœ¬æ—¶å¸¸è§çš„ç»“æ„æŸåå’Œè´¨é‡ä¸‹é™é—®é¢˜ï¼Œç ”ç©¶å›¢é˜Ÿå¼€å‘äº†ä¸€ç§å…¨æ–°çš„ã€ä¸é¢†åŸŸæ— å…³çš„æå–æµæ°´çº¿ï¼Œåˆ©ç”¨æ„ŸçŸ¥å¸ƒå±€çš„æ¸²æŸ“æŠ€æœ¯ lynx ä»¥åŠåŸºäº LLM çš„æ¸…ç†é˜¶æ®µï¼Œç¡®ä¿äº†æ•°å­¦å…¬å¼å’Œä»£ç å—çš„ç»“æ„å®Œæ•´æ€§ï¼Œå¹¶å°†å…¶ç»Ÿä¸€æ ‡å‡†åŒ–ä¸º LaTeX æ ¼å¼ã€‚å…¶ä¸­çš„æ ¸å¿ƒå­é›† Nemotron-CC-Math-4+ ä¸ä»…åœ¨è´¨é‡ä¸Šè¶…è¶Šäº† MegaMath å’Œ OpenWebMath ç­‰ç°æœ‰å¼€æ”¾æ•°æ®é›†ï¼Œå…¶è§„æ¨¡æ›´æ˜¯æ­¤å‰é«˜è´¨é‡æ ‡æ† FineMath-4+ çš„ 5.5 å€ã€‚å®éªŒè¯æ˜ï¼Œä½¿ç”¨è¯¥è¯­æ–™åº“é¢„è®­ç»ƒçš„ Nemotron-T 8B æ¨¡å‹åœ¨ MATH å’Œ MBPP+ ä»»åŠ¡ä¸Šåˆ†åˆ«å®ç°äº†æ˜¾è‘—çš„æ€§èƒ½å¢ç›Šï¼ŒåŒæ—¶æå‡äº†æ¨¡å‹åœ¨ MMLU ç­‰é€šç”¨é¢†åŸŸçš„æ¨ç†èƒ½åŠ›ã€‚ç›®å‰ï¼Œè¯¥ç ”ç©¶å·²å¼€æºå…¶ä»£ç å’Œæ•°æ®é›†ï¼Œä¸ºç§‘å­¦å†…å®¹çš„å¯é æå–å’Œé«˜æ€§èƒ½æ•°å­¦è¯­è¨€æ¨¡å‹è®­ç»ƒè®¾ç«‹äº†æ–°çš„ SOTA æ ‡å‡†ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.15096v1",
      "published_date": "2025-08-20 22:16:57 UTC",
      "updated_date": "2025-08-20 22:16:57 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:56:34.332162+00:00"
    },
    {
      "arxiv_id": "2508.15090v1",
      "title": "Mapping the Course for Prompt-based Structured Prediction",
      "title_zh": "è§„åˆ’åŸºäºæç¤ºçš„ç»“æ„åŒ–é¢„æµ‹çš„å‘å±•è·¯å¾„",
      "authors": [
        "Matt Pauk",
        "Maria Leonor Pacheco"
      ],
      "abstract": "LLMs have been shown to be useful for a variety of language tasks, without requiring task-specific fine-tuning. However, these models often struggle with hallucinations and complex reasoning problems due to their autoregressive nature. We propose to address some of these issues, specifically in the area of structured prediction, by combining LLMs with combinatorial inference in an attempt to marry the predictive power of LLMs with the structural consistency provided by inference methods. We perform exhaustive experiments in an effort to understand which prompting strategies can effectively estimate LLM confidence values for use with symbolic inference, and show that, regardless of the prompting strategy, the addition of symbolic inference on top of prompting alone leads to more consistent and accurate predictions. Additionally, we show that calibration and fine-tuning using structured prediction objectives leads to increased performance for challenging tasks, showing that structured learning is still valuable in the era of LLMs.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å¤§è¯­è¨€æ¨¡å‹ (LLMs) åœ¨ç»“æ„åŒ–é¢„æµ‹ (structured prediction) ä»»åŠ¡ä¸­é¢ä¸´çš„å¹»è§‰ä¸å¤æ‚æ¨ç†æŒ‘æˆ˜ï¼Œå¹¶æå‡ºå°† LLMs ä¸ç»„åˆæ¨ç† (combinatorial inference) ç›¸ç»“åˆï¼Œä»¥èåˆæ¨¡å‹çš„é¢„æµ‹èƒ½åŠ›ä¸æ¨ç†æ–¹æ³•çš„ç»“æ„ä¸€è‡´æ€§ (structural consistency)ã€‚é€šè¿‡å¤§é‡å®éªŒï¼Œç ”ç©¶è€…è¯„ä¼°äº†ä¸åŒæç¤ºç­–ç•¥ (prompting strategies) åœ¨ä¼°è®¡ç¬¦å·æ¨ç† (symbolic inference) æ‰€éœ€ç½®ä¿¡åº¦æ–¹é¢çš„æœ‰æ•ˆæ€§ã€‚å®éªŒç»“æœè¯æ˜ï¼Œæ— è®ºä½¿ç”¨ä½•ç§æç¤ºæ–¹å¼ï¼Œå¼•å…¥ç¬¦å·æ¨ç†éƒ½èƒ½æ˜¾è‘—æå‡é¢„æµ‹çš„å‡†ç¡®æ€§ä¸ä¸€è‡´æ€§ã€‚æ­¤å¤–ï¼Œç ”ç©¶è¿˜å¼ºè°ƒäº†åˆ©ç”¨ç»“æ„åŒ–é¢„æµ‹ç›®æ ‡è¿›è¡Œæ ¡å‡†ä¸å¾®è°ƒå¯¹æå‡æŒ‘æˆ˜æ€§ä»»åŠ¡æ€§èƒ½çš„å…³é”®ä½œç”¨ï¼Œè¯æ˜äº†åœ¨ LLM æ—¶ä»£ç»“æ„åŒ–å­¦ä¹  (structured learning) ä¾ç„¶å…·æœ‰é‡è¦ä»·å€¼ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.15090v1",
      "published_date": "2025-08-20 22:00:28 UTC",
      "updated_date": "2025-08-20 22:00:28 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:56:26.116516+00:00"
    },
    {
      "arxiv_id": "2508.15086v1",
      "title": "Wormhole Dynamics in Deep Neural Networks",
      "title_zh": "æ·±åº¦ç¥ç»ç½‘ç»œä¸­çš„è™«æ´åŠ¨åŠ›å­¦",
      "authors": [
        "Yen-Lung Lai",
        "Zhe Jin"
      ],
      "abstract": "This work investigates the generalization behavior of deep neural networks (DNNs), focusing on the phenomenon of \"fooling examples,\" where DNNs confidently classify inputs that appear random or unstructured to humans. To explore this phenomenon, we introduce an analytical framework based on maximum likelihood estimation, without adhering to conventional numerical approaches that rely on gradient-based optimization and explicit labels. Our analysis reveals that DNNs operating in an overparameterized regime exhibit a collapse in the output feature space. While this collapse improves network generalization, adding more layers eventually leads to a state of degeneracy, where the model learns trivial solutions by mapping distinct inputs to the same output, resulting in zero loss. Further investigation demonstrates that this degeneracy can be bypassed using our newly derived \"wormhole\" solution. The wormhole solution, when applied to arbitrary fooling examples, reconciles meaningful labels with random ones and provides a novel perspective on shortcut learning. These findings offer deeper insights into DNN generalization and highlight directions for future research on learning dynamics in unsupervised settings to bridge the gap between theory and practice.",
      "tldr_zh": "è¯¥ç ”ç©¶æ·±å…¥æ¢è®¨äº†æ·±åº¦ç¥ç»ç½‘ç»œ (DNNs) çš„æ³›åŒ–è¡Œä¸ºï¼Œç‰¹åˆ«æ˜¯æ¨¡å‹å¯¹äººç±»è§†è§‰ä¸­çš„éšæœºæ— åºè¾“å…¥äº§ç”Ÿé«˜ç½®ä¿¡åº¦è¯¯åˆ¤çš„ fooling examples ç°è±¡ã€‚ç ”ç©¶äººå‘˜æå‡ºäº†ä¸€ç§åŸºäºæå¤§ä¼¼ç„¶ä¼°è®¡ (maximum likelihood estimation) çš„åˆ†ææ¡†æ¶ï¼Œæ—¨åœ¨æ‘†è„±å¯¹ä¼ ç»Ÿæ¢¯åº¦ä¸‹é™ä¼˜åŒ–å’Œæ˜¾å¼æ ‡ç­¾çš„ä¾èµ–ã€‚åˆ†æè¡¨æ˜ï¼Œè¿‡åº¦å‚æ•°åŒ–çš„ DNNs ä¼šç»å†è¾“å‡ºç‰¹å¾ç©ºé—´åç¼©ï¼Œè™½ç„¶è¿™åœ¨ä¸€å®šç¨‹åº¦ä¸Šèƒ½æå‡æ³›åŒ–æ€§èƒ½ï¼Œä½†å±‚æ•°çš„è¿‡åº¦å¢åŠ æœ€ç»ˆä¼šå¯¼è‡´æ¨¡å‹é™·å…¥å°†ä¸åŒè¾“å…¥æ˜ å°„ä¸ºç»Ÿä¸€è¾“å‡ºçš„é€€åŒ–çŠ¶æ€ã€‚ç ”ç©¶è¿›ä¸€æ­¥æ¨å¯¼å‡ºä¸€ç§ wormhole è§£å†³æ–¹æ¡ˆï¼ŒæˆåŠŸç»•è¿‡äº†è¿™ç§é€€åŒ–ç°è±¡ï¼Œå¹¶å®ç°äº†æœ‰æ„ä¹‰æ ‡ç­¾ä¸éšæœºæ ‡ç­¾ä¹‹é—´çš„åè°ƒã€‚è¿™ä¸€å‘ç°ä¸ºç†è§£å¿«æ·å­¦ä¹  (shortcut learning) æä¾›äº†å…¨æ–°çš„è§†è§’ï¼Œå¯¹æ­ç¤º DNNs æ³›åŒ–æœºåˆ¶åŠæ— ç›‘ç£å­¦ä¹ åŠ¨åŠ›å­¦å…·æœ‰é‡è¦çš„ç†è®ºä¸å®è·µæ„ä¹‰ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.15086v1",
      "published_date": "2025-08-20 21:41:53 UTC",
      "updated_date": "2025-08-20 21:41:53 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:56:47.519117+00:00"
    },
    {
      "arxiv_id": "2508.15085v1",
      "title": "LongRecall: A Structured Approach for Robust Recall Evaluation in Long-Form Text",
      "title_zh": "LongRecallï¼šé’ˆå¯¹é•¿æ–‡æœ¬é²æ£’å¬å›ç‡è¯„ä¼°çš„ç»“æ„åŒ–æ–¹æ³•",
      "authors": [
        "MohamamdJavad Ardestani",
        "Ehsan Kamalloo",
        "Davood Rafiei"
      ],
      "abstract": "LongRecall. The completeness of machine-generated text, ensuring that it captures all relevant information, is crucial in domains such as medicine and law and in tasks like list-based question answering (QA), where omissions can have serious consequences. However, existing recall metrics often depend on lexical overlap, leading to errors with unsubstantiated entities and paraphrased answers, while LLM-as-a-Judge methods with long holistic prompts capture broader semantics but remain prone to misalignment and hallucinations without structured verification. We introduce LongRecall, a general three-stage recall evaluation framework that decomposes answers into self-contained facts, successively narrows plausible candidate matches through lexical and semantic filtering, and verifies their alignment through structured entailment checks. This design reduces false positives and false negatives while accommodating diverse phrasings and contextual variations, serving as a foundational building block for systematic recall assessment. We evaluate LongRecall on three challenging long-form QA benchmarks using both human annotations and LLM-based judges, demonstrating substantial improvements in recall accuracy over strong lexical and LLM-as-a-Judge baselines.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† LongRecallï¼Œä¸€ä¸ªé€šç”¨çš„ä¸‰é˜¶æ®µå¬å›è¯„ä¼°(Recall evaluation)æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³é•¿æ–‡æœ¬ç”Ÿæˆä¸­ä¿¡æ¯å®Œæ•´æ€§éš¾ä»¥å‡†ç¡®è¡¡é‡çš„é—®é¢˜ã€‚é’ˆå¯¹ç°æœ‰æŒ‡æ ‡è¿‡åº¦ä¾èµ–è¯æ±‡é‡å æˆ– LLM-as-a-Judge æ–¹æ³•å®¹æ˜“äº§ç”Ÿå¯¹é½åå·®å’Œå¹»è§‰çš„å±€é™ï¼Œè¯¥æ¡†æ¶å°†ç­”æ¡ˆåˆ†è§£ä¸ºç‹¬ç«‹çš„åŸå­äº‹å®(self-contained facts)ï¼Œé€šè¿‡è¯æ±‡å’Œè¯­ä¹‰è¿‡æ»¤ç¼©å°å€™é€‰èŒƒå›´ï¼Œå¹¶åˆ©ç”¨ç»“æ„åŒ–è•´å«æ£€æŸ¥(structured entailment checks)è¿›è¡Œæœ€ç»ˆéªŒè¯ã€‚è¿™ç§è®¾è®¡èƒ½å¤Ÿé€‚åº”å¤šæ ·åŒ–çš„è¡¨è¾¾æ–¹å¼ï¼Œæœ‰æ•ˆå‡å°‘äº†è¯„ä¼°ä¸­çš„å‡é˜³æ€§å’Œå‡é˜´æ€§é”™è¯¯ã€‚åœ¨ä¸‰ä¸ªå…·æœ‰æŒ‘æˆ˜æ€§çš„é•¿ç¯‡é—®ç­”(QA)åŸºå‡†æµ‹è¯•ä¸Šçš„å®éªŒç»“æœæ˜¾ç¤ºï¼ŒLongRecall åœ¨äººå·¥å’Œæ¨¡å‹è¯„æµ‹ä¸­å‡è¡¨ç°å‡ºè‰²ï¼Œå…¶å¬å›ç‡å‡†ç¡®æ€§æ˜¾è‘—ä¼˜äºç°æœ‰çš„è¯æ±‡åŸºå‡†å’Œå¼ºåŠ›çš„ LLM è¯„æµ‹æ–¹æ³•ï¼Œä¸ºç¨³å¥çš„ç³»ç»Ÿæ€§å¬å›è¯„ä¼°æä¾›äº†é‡è¦åŸºç¡€ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.15085v1",
      "published_date": "2025-08-20 21:41:42 UTC",
      "updated_date": "2025-08-20 21:41:42 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:56:51.326517+00:00"
    },
    {
      "arxiv_id": "2508.15082v1",
      "title": "From Basic Affordances to Symbolic Thought: A Computational Phylogenesis of Biological Intelligence",
      "title_zh": "ä»åŸºç¡€ç¤ºèƒ½åˆ°ç¬¦å·æ€ç»´ï¼šç”Ÿç‰©æ™ºèƒ½çš„è®¡ç®—ç³»ç»Ÿå‘è‚²",
      "authors": [
        "John E. Hummel",
        "Rachel F. Heaton"
      ],
      "abstract": "What is it about human brains that allows us to reason symbolically whereas most other animals cannot? There is evidence that dynamic binding, the ability to combine neurons into groups on the fly, is necessary for symbolic thought, but there is also evidence that it is not sufficient. We propose that two kinds of hierarchical integration (integration of multiple role-bindings into multiplace predicates, and integration of multiple correspondences into structure mappings) are minimal requirements, on top of basic dynamic binding, to realize symbolic thought. We tested this hypothesis in a systematic collection of 17 simulations that explored the ability of cognitive architectures with and without the capacity for multi-place predicates and structure mapping to perform various kinds of tasks. The simulations were as generic as possible, in that no task could be performed based on any diagnostic features, depending instead on the capacity for multi-place predicates and structure mapping. The results are consistent with the hypothesis that, along with dynamic binding, multi-place predicates and structure mapping are minimal requirements for basic symbolic thought. These results inform our understanding of how human brains give rise to symbolic thought and speak to the differences between biological intelligence, which tends to generalize broadly from very few training examples, and modern approaches to machine learning, which typically require millions or billions of training examples. The results we report also have important implications for bio-inspired artificial intelligence.",
      "tldr_zh": "è¯¥é¡¹ç ”ç©¶æ¢è®¨äº†äººç±»å¤§è„‘èƒ½å¤Ÿè¿›è¡Œç¬¦å·æ¨ç†(Symbolic Thought)è€Œå…¶ä»–åŠ¨ç‰©ä¸èƒ½çš„æ ¹æœ¬åŸå› ï¼Œæå‡ºäº†ç”Ÿç‰©æ™ºèƒ½è¿›åŒ–çš„è®¡ç®—è·¯å¾„ã€‚ä½œè€…è®¤ä¸ºé™¤äº†åŸºç¡€çš„åŠ¨æ€ç»‘å®š(Dynamic Binding)èƒ½åŠ›å¤–ï¼Œå¤šä½è°“è¯(Multi-place Predicates)çš„å±‚æ¬¡åŒ–é›†æˆå’Œç»“æ„æ˜ å°„(Structure Mapping)æ˜¯å®ç°ç¬¦å·æ€ç»´çš„æœ€å°å¿…è¦æ¡ä»¶ã€‚é€šè¿‡17ç»„ç³»ç»Ÿçš„è®¡ç®—ä»¿çœŸå®éªŒï¼Œç ”ç©¶å¯¹æ¯”äº†å…·å¤‡å’Œä¸å…·å¤‡è¿™äº›èƒ½åŠ›çš„è®¤çŸ¥æ¶æ„åœ¨é€šç”¨ä»»åŠ¡ä¸­çš„è¡¨ç°ï¼Œç»“æœè¯å®äº†è¯¥å‡è®¾çš„æœ‰æ•ˆæ€§ã€‚å®éªŒå‘ç°é˜æ˜äº†ç”Ÿç‰©æ™ºèƒ½ä¸ºä½•èƒ½åœ¨æå°‘æ ·æœ¬ä¸‹å®ç°å¹¿æ³›æ³›åŒ–ï¼Œæ­ç¤ºäº†å…¶ä¸ä¾èµ–æµ·é‡æ•°æ®çš„ç°ä»£æœºå™¨å­¦ä¹ (Machine Learning)ä¹‹é—´çš„æœ¬è´¨å·®å¼‚ã€‚è¯¥ç ”ç©¶ä¸ä»…åŠ æ·±äº†å¯¹äººç±»è®¤çŸ¥èµ·æºçš„ç†è§£ï¼Œä¹Ÿä¸ºå¼€å‘å—ç”Ÿç‰©å¯å‘çš„å…ˆè¿›äººå·¥æ™ºèƒ½(Bio-inspired AI)æä¾›äº†é‡è¦çš„ç†è®ºæ”¯æ’‘ã€‚",
      "categories": [
        "cs.NE",
        "cs.AI",
        "cs.LG",
        "q-bio.NC"
      ],
      "primary_category": "cs.NE",
      "comment": "47 pages 8 figures",
      "pdf_url": "https://arxiv.org/pdf/2508.15082v1",
      "published_date": "2025-08-20 21:38:06 UTC",
      "updated_date": "2025-08-20 21:38:06 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:56:54.434552+00:00"
    },
    {
      "arxiv_id": "2508.15068v1",
      "title": "S3LoRA: Safe Spectral Sharpness-Guided Pruning in Adaptation of Agent Planner",
      "title_zh": "S3LoRAï¼šæ™ºèƒ½ä½“è§„åˆ’å™¨é€‚é…ä¸­åŸºäºå®‰å…¨è°±é”åº¦å¼•å¯¼çš„å‰ªæ",
      "authors": [
        "Shuang Ao",
        "Gopal Rumchurn"
      ],
      "abstract": "Adapting Large Language Models (LLMs) using parameter-efficient fine-tuning (PEFT) techniques such as LoRA has enabled powerful capabilities in LLM-based agents. However, these adaptations can unintentionally compromise safety alignment, leading to unsafe or unstable behaviors, particularly in agent planning tasks. Existing safety-aware adaptation methods often require access to both base and instruction-tuned model checkpoints, which are frequently unavailable in practice, limiting their applicability. We propose S3LoRA (Safe Spectral Sharpness-Guided Pruning LoRA), a lightweight, data-free, and model-independent framework that mitigates safety risks in LoRA-adapted models by inspecting only the fine-tuned weight updates. We first introduce Magnitude-Aware Spherically Normalized SVD (MAS-SVD), which robustly analyzes the structural properties of LoRA updates while preserving global magnitude information. We then design the Spectral Sharpness Index (SSI), a sharpness-aware metric to detect layers with highly concentrated and potentially unsafe updates. These layers are pruned post-hoc to reduce risk without sacrificing task performance. Extensive experiments and ablation studies across agent planning and language generation tasks show that S3LoRA consistently improves safety metrics while maintaining or improving utility metrics and significantly reducing inference cost. These results establish S3LoRA as a practical and scalable solution for safely deploying LLM-based agents in real-world, resource-constrained, and safety-critical environments.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†S3LoRAï¼ˆSafe Spectral Sharpness-Guided Pruning LoRAï¼‰ï¼Œè¿™æ˜¯ä¸€ç§è½»é‡çº§ã€æ— æ•°æ®ä¸”ç‹¬ç«‹äºæ¨¡å‹çš„æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³LoRAå¾®è°ƒåœ¨æå‡å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æ™ºèƒ½ä½“èƒ½åŠ›æ—¶å¯èƒ½ç ´åå®‰å…¨å¯¹é½çš„é—®é¢˜ã€‚é’ˆå¯¹ç°æœ‰å®‰å…¨æ€§è‡ªé€‚åº”æ–¹æ³•å¾€å¾€éœ€è¦è®¿é—®å—é™çš„åŸºç¡€æ¨¡å‹æ£€æŸ¥ç‚¹çš„å±€é™æ€§ï¼ŒS3LoRAé€šè¿‡ä»…åˆ†æå¾®è°ƒåçš„æƒé‡æ›´æ–°æ¥è¯†åˆ«å¹¶ç¼“è§£é£é™©ã€‚è¯¥æ¡†æ¶å¼•å…¥äº†Magnitude-Aware Spherically Normalized SVD (MAS-SVD)æ¥é²æ£’åœ°åˆ†ææƒé‡æ›´æ–°çš„ç»“æ„å±æ€§ï¼Œå¹¶å®šä¹‰äº†Spectral Sharpness Index (SSI)æŒ‡æ ‡æ¥æ£€æµ‹å…·æœ‰é«˜åº¦é›†ä¸­ä¸”æ½œåœ¨ä¸å®‰å…¨æ›´æ–°çš„å±‚ã€‚é€šè¿‡å¯¹è¿™äº›ç‰¹å®šå±‚è¿›è¡Œäº‹åå‰ªæï¼ŒS3LoRAåœ¨ä¸ç‰ºç‰²ä»»åŠ¡æ€§èƒ½çš„æƒ…å†µä¸‹æœ‰æ•ˆé™ä½äº†å®‰å…¨é£é™©ã€‚å¹¿æ³›çš„å®éªŒè¡¨æ˜ï¼ŒS3LoRAåœ¨æ™ºèƒ½ä½“è§„åˆ’ä»»åŠ¡ä¸­ä¸ä»…æå‡äº†å®‰å…¨æ€§ï¼Œè¿˜ä¿æŒæˆ–å¢å¼ºäº†æ¨¡å‹æ•ˆç”¨ï¼Œå¹¶æ˜¾è‘—é™ä½äº†æ¨ç†æˆæœ¬ã€‚è¿™ä¸€ç ”ç©¶ä¸ºåœ¨ç°å®ä¸–ç•Œã€èµ„æºå—é™ä¸”å¯¹å®‰å…¨æ€§è¦æ±‚æé«˜çš„ç¯å¢ƒä¸­éƒ¨ç½²LLMæ™ºèƒ½ä½“æä¾›äº†ä¸€ç§å®ç”¨ä¸”å¯æ‰©å±•çš„æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "9 pages, 2 figures",
      "pdf_url": "https://arxiv.org/pdf/2508.15068v1",
      "published_date": "2025-08-20 21:08:29 UTC",
      "updated_date": "2025-08-20 21:08:29 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:56:56.224110+00:00"
    },
    {
      "arxiv_id": "2508.15053v1",
      "title": "Demonstrating Onboard Inference for Earth Science Applications with Spectral Analysis Algorithms and Deep Learning",
      "title_zh": "åŸºäºå…‰è°±åˆ†æç®—æ³•ä¸æ·±åº¦å­¦ä¹ çš„åœ°çƒç§‘å­¦åº”ç”¨æ˜Ÿè½½æ¨ç†éªŒè¯",
      "authors": [
        "Itai Zilberstein",
        "Alberto Candela",
        "Steve Chien",
        "David Rijlaarsdam",
        "Tom Hendrix",
        "Leonie Buckley",
        "Aubrey Dunne"
      ],
      "abstract": "In partnership with Ubotica Technologies, the Jet Propulsion Laboratory is demonstrating state-of-the-art data analysis onboard CogniSAT-6/HAMMER (CS-6). CS-6 is a satellite with a visible and near infrared range hyperspectral instrument and neural network acceleration hardware. Performing data analysis at the edge (e.g. onboard) can enable new Earth science measurements and responses. We will demonstrate data analysis and inference onboard CS-6 for numerous applications using deep learning and spectral analysis algorithms.",
      "tldr_zh": "è¯¥ç ”ç©¶å±•ç¤ºäº†å–·æ°”æ¨è¿›å®éªŒå®¤ (JPL) ä¸ Ubotica Technologies åˆä½œï¼Œåœ¨ CogniSAT-6/HAMMER (CS-6) å«æ˜Ÿä¸Šå®ç°çš„å°–ç«¯åœ¨è½¨æ¨ç† (Onboard Inference) èƒ½åŠ›ã€‚CS-6 å«æ˜Ÿæ­è½½äº†å¯è§å…‰ä¸è¿‘çº¢å¤–é«˜å…‰è°±ä»ªå™¨ä»¥åŠä¸“ç”¨çš„ç¥ç»ç½‘ç»œåŠ é€Ÿç¡¬ä»¶ï¼Œæ—¨åœ¨å°†æ•°æ®åˆ†æè¿‡ç¨‹ç§»è‡³è¾¹ç¼˜ç«¯æ‰§è¡Œã€‚é€šè¿‡ç»“åˆæ·±åº¦å­¦ä¹  (Deep Learning) ä¸å…‰è°±åˆ†æç®—æ³• (Spectral Analysis Algorithms)ï¼Œè¯¥é¡¹ç›®æˆåŠŸåœ¨è½¨è¿è¡Œäº†å¤šç§åœ°çƒç§‘å­¦åº”ç”¨æ¨¡å‹ã€‚è¿™ä¸€æŠ€æœ¯æ¼”ç¤ºè¯æ˜äº†åœ¨è½¨å¤„ç†èƒ½å¤Ÿæ˜¾è‘—æå‡åœ°çƒç§‘å­¦æµ‹é‡çš„å®æ—¶æ€§ä¸å“åº”èƒ½åŠ›ï¼Œä¸ºæœªæ¥è‡ªä¸»åŒ–å«æ˜Ÿè§‚æµ‹ä»»åŠ¡æä¾›äº†é‡è¦çš„å®è·µå‚è€ƒã€‚",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "International Symposium on Artificial Intelligence, Robotics and Automation in Space, November 2024",
      "pdf_url": "https://arxiv.org/pdf/2508.15053v1",
      "published_date": "2025-08-20 20:37:31 UTC",
      "updated_date": "2025-08-20 20:37:31 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:57:01.517521+00:00"
    },
    {
      "arxiv_id": "2508.15050v1",
      "title": "Don't Think Twice! Over-Reasoning Impairs Confidence Calibration",
      "title_zh": "ä¸‰æ€æœªå¿…æœ‰ç›Šï¼šè¿‡åº¦æ¨ç†æŸå®³ç½®ä¿¡åº¦æ ¡å‡†",
      "authors": [
        "Romain Lacombe",
        "Kerrie Wu",
        "Eddie Dilworth"
      ],
      "abstract": "Large Language Models deployed as question answering tools require robust calibration to avoid overconfidence. We systematically evaluate how reasoning capabilities and budget affect confidence assessment accuracy, using the ClimateX dataset (Lacombe et al., 2023) and expanding it to human and planetary health. Our key finding challenges the \"test-time scaling\" paradigm: while recent reasoning LLMs achieve 48.7% accuracy in assessing expert confidence, increasing reasoning budgets consistently impairs rather than improves calibration. Extended reasoning leads to systematic overconfidence that worsens with longer thinking budgets, producing diminishing and negative returns beyond modest computational investments. Conversely, search-augmented generation dramatically outperforms pure reasoning, achieving 89.3% accuracy by retrieving relevant evidence. Our results suggest that information access, rather than reasoning depth or inference budget, may be the critical bottleneck for improved confidence calibration of knowledge-intensive tasks.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨é—®ç­”ä»»åŠ¡ä¸­çš„ç½®ä¿¡åº¦æ ¡å‡†ï¼ˆConfidence Calibrationï¼‰é—®é¢˜ï¼Œé€šè¿‡ ClimateX æ•°æ®é›†åŠå…¶æ‰©å±•é¢†åŸŸç³»ç»Ÿè¯„ä¼°äº†æ¨ç†èƒ½åŠ›å’Œè®¡ç®—é¢„ç®—ï¼ˆReasoning Budgetï¼‰å¯¹è¯„ä¼°å‡†ç¡®æ€§çš„å½±å“ã€‚ç ”ç©¶ç»“æœæŒ‘æˆ˜äº†ä¼ ç»Ÿçš„â€œæµ‹è¯•æ—¶æ‰©å±•â€ï¼ˆTest-time Scalingï¼‰èŒƒå¼ï¼Œå‘ç°å¢åŠ æ¨ç†é¢„ç®—éä½†ä¸èƒ½ä¼˜åŒ–æ ¡å‡†ï¼Œåè€Œä¼šå¯¼è‡´ç³»ç»Ÿæ€§çš„è¿‡åº¦è‡ªä¿¡ï¼ˆOverconfidenceï¼‰ï¼Œä¸”è¿™ç§å€¾å‘éšæ€è€ƒæ—¶é—´çš„å»¶é•¿è€ŒåŠ å‰§ã€‚å®éªŒæ˜¾ç¤ºï¼Œçº¯æ¨ç†æ¨¡å‹åœ¨è¯„ä¼°ä¸“å®¶ç½®ä¿¡åº¦æ—¶çš„å‡†ç¡®ç‡ä»…ä¸º 48.7%ï¼Œè€Œæ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆSearch-augmented Generationï¼‰é€šè¿‡å¼•å…¥å¤–éƒ¨è¯æ®å°†å‡†ç¡®ç‡å¤§å¹…æå‡è‡³ 89.3%ã€‚è¿™è¡¨æ˜åœ¨å¤„ç†çŸ¥è¯†å¯†é›†å‹ä»»åŠ¡æ—¶ï¼Œä¿¡æ¯è·å–èƒ½åŠ›è€Œéæ¨ç†æ·±åº¦æˆ–æ¨ç†é¢„ç®—ï¼Œæ‰æ˜¯æå‡æ¨¡å‹ç½®ä¿¡åº¦æ ¡å‡†è¡¨ç°çš„å…³é”®ç“¶é¢ˆã€‚ç ”ç©¶æœ€ç»ˆæŒ‡å‡ºï¼Œè¿‡åº¦æ¨ç†ä¼šæŸå®³æ¨¡å‹çš„è‡ªæˆ‘è¯„ä¼°èƒ½åŠ›ï¼Œä¸ºå¼€å‘æ›´å¯é çš„ AI é—®ç­”å·¥å…·æä¾›äº†é‡è¦å¯ç¤ºã€‚",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "Published at ICML 2025 Workshop on Reliable and Responsible Foundation Models",
      "pdf_url": "https://arxiv.org/pdf/2508.15050v1",
      "published_date": "2025-08-20 20:25:21 UTC",
      "updated_date": "2025-08-20 20:25:21 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:57:10.320647+00:00"
    },
    {
      "arxiv_id": "2508.15047v1",
      "title": "Emergent Crowds Dynamics from Language-Driven Multi-Agent Interactions",
      "title_zh": "åŸºäºè¯­è¨€é©±åŠ¨å¤šæ™ºèƒ½ä½“äº¤äº’çš„æ¶Œç°äººç¾¤åŠ¨åŠ›å­¦",
      "authors": [
        "Yibo Liu",
        "Liam Shatzel",
        "Brandon Haworth",
        "Teseo Schneider"
      ],
      "abstract": "Animating and simulating crowds using an agent-based approach is a well-established area where every agent in the crowd is individually controlled such that global human-like behaviour emerges. We observe that human navigation and movement in crowds are often influenced by complex social and environmental interactions, driven mainly by language and dialogue. However, most existing work does not consider these dimensions and leads to animations where agent-agent and agent-environment interactions are largely limited to steering and fixed higher-level goal extrapolation.\n  We propose a novel method that exploits large language models (LLMs) to control agents' movement. Our method has two main components: a dialogue system and language-driven navigation. We periodically query agent-centric LLMs conditioned on character personalities, roles, desires, and relationships to control the generation of inter-agent dialogue when necessitated by the spatial and social relationships with neighbouring agents. We then use the conversation and each agent's personality, emotional state, vision, and physical state to control the navigation and steering of each agent. Our model thus enables agents to make motion decisions based on both their perceptual inputs and the ongoing dialogue.\n  We validate our method in two complex scenarios that exemplify the interplay between social interactions, steering, and crowding. In these scenarios, we observe that grouping and ungrouping of agents automatically occur. Additionally, our experiments show that our method serves as an information-passing mechanism within the crowd. As a result, our framework produces more realistic crowd simulations, with emergent group behaviours arising naturally from any environmental setting.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§åˆ©ç”¨ Large Language Models (LLMs) é©±åŠ¨å¤šæ™ºèƒ½ä½“äº¤äº’çš„æ–°æ–¹æ³•ï¼Œæ—¨åœ¨è§£å†³ä¼ ç»Ÿç¾¤ä½“åŠ¨ç”»ä¸­æ™ºèƒ½ä½“äº’åŠ¨ä»…é™äº steering å’Œå›ºå®šé«˜å±‚ç›®æ ‡çš„å±€é™æ€§ã€‚è¯¥æ¡†æ¶åŒ…å«å¯¹è¯ç³»ç»Ÿå’Œè¯­è¨€é©±åŠ¨å¯¼èˆªä¸¤ä¸ªæ ¸å¿ƒç»„ä»¶ï¼Œé€šè¿‡å‘¨æœŸæ€§è°ƒç”¨ä»¥æ™ºèƒ½ä½“ä¸ªæ€§ã€è§’è‰²ã€æ„¿æœ›å’Œå…³ç³»ä¸ºæ¡ä»¶çš„ LLMs æ¥ç”Ÿæˆäº¤äº’å¯¹è¯ã€‚æ™ºèƒ½ä½“çš„è¿åŠ¨å†³ç­–ä¸ä»…åŸºäº perceptual inputsï¼Œè¿˜ç»“åˆäº†å½“å‰çš„å¯¹è¯å†…å®¹ã€æƒ…ç»ªçŠ¶æ€åŠç‰©ç†çŠ¶æ€ï¼Œå®ç°äº†ç”±è¯­è¨€å¼•å¯¼çš„å¤æ‚å¯¼èˆªæ§åˆ¶ã€‚ç ”ç©¶åœ¨å¤šä¸ªå¤æ‚åœºæ™¯ä¸­éªŒè¯äº†è¯¥æ–¹æ³•ï¼Œè§‚å¯Ÿåˆ°æ™ºèƒ½ä½“ä¹‹é—´ä¼šè‡ªåŠ¨å‘ç”Ÿ grouping å’Œ ungrouping è¡Œä¸ºã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨ç¾¤ä½“å†…å»ºç«‹äº†æœ‰æ•ˆçš„ä¿¡æ¯ä¼ é€’æœºåˆ¶ï¼Œä½¿å¾— emergent group behaviours èƒ½å¤Ÿä»ä»»ä½•ç¯å¢ƒè®¾ç½®ä¸­è‡ªç„¶æ¶Œç°ã€‚è¯¥æ¡†æ¶é€šè¿‡æ¨¡æ‹Ÿç”±ç¤¾äº¤äº’åŠ¨é©±åŠ¨çš„è¿åŠ¨ï¼Œæ˜¾è‘—æå‡äº†ç¾¤ä½“æ¨¡æ‹Ÿçš„çœŸå®æ„Ÿã€‚",
      "categories": [
        "cs.AI",
        "cs.GR"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.15047v1",
      "published_date": "2025-08-20 20:15:14 UTC",
      "updated_date": "2025-08-20 20:15:14 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:57:08.627262+00:00"
    },
    {
      "arxiv_id": "2508.15038v1",
      "title": "Decentralized Vision-Based Autonomous Aerial Wildlife Monitoring",
      "title_zh": "åŸºäºè§†è§‰çš„å»ä¸­å¿ƒåŒ–è‡ªä¸»ç©ºä¸­é‡ç”ŸåŠ¨ç‰©ç›‘æµ‹",
      "authors": [
        "Makram Chahine",
        "William Yang",
        "Alaa Maalouf",
        "Justin Siriska",
        "Ninad Jadhav",
        "Daniel Vogt",
        "Stephanie Gil",
        "Robert Wood",
        "Daniela Rus"
      ],
      "abstract": "Wildlife field operations demand efficient parallel deployment methods to identify and interact with specific individuals, enabling simultaneous collective behavioral analysis, and health and safety interventions. Previous robotics solutions approach the problem from the herd perspective, or are manually operated and limited in scale. We propose a decentralized vision-based multi-quadrotor system for wildlife monitoring that is scalable, low-bandwidth, and sensor-minimal (single onboard RGB camera). Our approach enables robust identification and tracking of large species in their natural habitat. We develop novel vision-based coordination and tracking algorithms designed for dynamic, unstructured environments without reliance on centralized communication or control. We validate our system through real-world experiments, demonstrating reliable deployment in diverse field conditions.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§åˆ†æ•£å¼(Decentralized)åŸºäºè§†è§‰çš„è‡ªä¸»ç©ºä¸­é‡ç”ŸåŠ¨ç‰©ç›‘æµ‹ç³»ç»Ÿï¼Œæ—¨åœ¨æ»¡è¶³é‡å¤–ä½œä¸šä¸­å¯¹ç‰¹å®šä¸ªä½“è¿›è¡Œé«˜æ•ˆè¯†åˆ«ä¸ç¾¤ä½“è¡Œä¸ºåˆ†æçš„éœ€æ±‚ã€‚è¯¥ç³»ç»Ÿé‡‡ç”¨å¤šå››æ—‹ç¿¼æ— äººæœº(Multi-quadrotor)æ¶æ„ï¼Œä»…éœ€å•æ¿RGBæ‘„åƒå¤´(Single onboard RGB camera)å³å¯å®ç°ä¼ æ„Ÿå™¨æç®€åŒ–ï¼Œå…·æœ‰é«˜æ‰©å±•æ€§å’Œä½å¸¦å®½è¦æ±‚ã€‚ç ”ç©¶å›¢é˜Ÿå¼€å‘äº†é’ˆå¯¹åŠ¨æ€ã€æ— ç»“æ„åŒ–ç¯å¢ƒçš„æ–°å‹è§†è§‰åè°ƒä¸è·Ÿè¸ªç®—æ³•ï¼Œæ‘†è„±äº†å¯¹ä¸­å¿ƒåŒ–é€šä¿¡æˆ–æ§åˆ¶çš„ä¾èµ–ï¼Œç¡®ä¿åœ¨è‡ªç„¶æ –æ¯åœ°ä¸­å¯¹å¤§å‹ç‰©ç§è¿›è¡Œé²æ£’è¯†åˆ«ä¸è¿½è¸ªã€‚é€šè¿‡çœŸå®ä¸–ç•Œçš„å®éªŒéªŒè¯ï¼Œè¯¥ç³»ç»Ÿè¯æ˜äº†åœ¨å¤šç§å¤æ‚åœºåŸŸæ¡ä»¶ä¸‹çš„å¯é æ€§ï¼Œä¸ºå¤§è§„æ¨¡ã€è‡ªåŠ¨åŒ–çš„é‡ç”ŸåŠ¨ç‰©ç›‘æµ‹ä¸è¡Œä¸ºå¹²é¢„æä¾›äº†æœ‰æ•ˆçš„æŠ€æœ¯æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV",
        "cs.MA"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.15038v1",
      "published_date": "2025-08-20 20:05:05 UTC",
      "updated_date": "2025-08-20 20:05:05 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:57:06.127982+00:00"
    },
    {
      "arxiv_id": "2508.15036v1",
      "title": "MoEcho: Exploiting Side-Channel Attacks to Compromise User Privacy in Mixture-of-Experts LLMs",
      "title_zh": "MoEchoï¼šåˆ©ç”¨ä¾§ä¿¡é“æ”»å‡»å±å®³æ··åˆä¸“å®¶å¤§è¯­è¨€æ¨¡å‹ä¸­çš„ç”¨æˆ·éšç§",
      "authors": [
        "Ruyi Ding",
        "Tianhong Xu",
        "Xinyi Shen",
        "Aidong Adam Ding",
        "Yunsi Fei"
      ],
      "abstract": "The transformer architecture has become a cornerstone of modern AI, fueling remarkable progress across applications in natural language processing, computer vision, and multimodal learning. As these models continue to scale explosively for performance, implementation efficiency remains a critical challenge. Mixture of Experts (MoE) architectures, selectively activating specialized subnetworks (experts), offer a unique balance between model accuracy and computational cost. However, the adaptive routing in MoE architectures, where input tokens are dynamically directed to specialized experts based on their semantic meaning inadvertently opens up a new attack surface for privacy breaches. These input-dependent activation patterns leave distinctive temporal and spatial traces in hardware execution, which adversaries could exploit to deduce sensitive user data. In this work, we propose MoEcho, discovering a side channel analysis based attack surface that compromises user privacy on MoE based systems. Specifically, in MoEcho, we introduce four novel architectural side channels on different computing platforms, including Cache Occupancy Channels and Pageout+Reload on CPUs, and Performance Counter and TLB Evict+Reload on GPUs, respectively. Exploiting these vulnerabilities, we propose four attacks that effectively breach user privacy in large language models (LLMs) and vision language models (VLMs) based on MoE architectures: Prompt Inference Attack, Response Reconstruction Attack, Visual Inference Attack, and Visual Reconstruction Attack. MoEcho is the first runtime architecture level security analysis of the popular MoE structure common in modern transformers, highlighting a serious security and privacy threat and calling for effective and timely safeguards when harnessing MoE based models for developing efficient large scale AI services.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† MoEchoï¼Œæ—¨åœ¨æ­ç¤º Mixture-of-Experts (MoE) æ¶æ„ä¸­ç”±äºè‡ªé€‚åº”è·¯ç”±æœºåˆ¶å¯¼è‡´çš„éšç§æ³„éœ²é£é™©ï¼Œå³è¾“å…¥ Token åŠ¨æ€å®šå‘åˆ°ç‰¹å®šä¸“å®¶æ—¶ä¼šåœ¨ç¡¬ä»¶æ‰§è¡Œä¸­ç•™ä¸‹ç‹¬ç‰¹çš„æ—¶é—´å’Œç©ºé—´è½¨è¿¹ã€‚ç ”ç©¶è€…åœ¨ä¸åŒè®¡ç®—å¹³å°ä¸Šå‘ç°äº†å››ç§æ–°å‹æ¶æ„ä¾§ä¿¡é“æ¼æ´ï¼ŒåŒ…æ‹¬ CPU ä¸Šçš„ Cache Occupancy å’Œ Pageout+Reloadï¼Œä»¥åŠ GPU ä¸Šçš„ Performance Counter å’Œ TLB Evict+Reloadã€‚åˆ©ç”¨è¿™äº›æ¼æ´ï¼ŒMoEcho å®ç°äº†é’ˆå¯¹åŸºäº MoE æ¶æ„çš„ LLMs å’Œ VLMs çš„å››ç§æ”»å‡»ï¼Œå…·ä½“åŒ…æ‹¬ Prompt Inferenceã€Response Reconstructionã€Visual Inference å’Œ Visual Reconstructionã€‚ä½œä¸ºé¦–ä¸ªé’ˆå¯¹ç°ä»£ Transformer ä¸­ MoE ç»“æ„çš„è¿è¡Œæ—¶æ¶æ„çº§å®‰å…¨åˆ†æï¼Œè¯¥ç ”ç©¶è¯æ˜äº†ä¾§ä¿¡é“æ”»å‡»å¯ä»¥æœ‰æ•ˆç ´è§£ç”¨æˆ·éšç§ã€‚è¿™ä¸€å‘ç°æ­ç¤ºäº† MoE æ¨¡å‹åœ¨æä¾›é«˜æ•ˆ AI æœåŠ¡æ—¶é¢ä¸´çš„ä¸¥é‡å®‰å…¨å¨èƒï¼Œå¹¶å¼ºè°ƒäº†å»ºç«‹åŠæ—¶æœ‰æ•ˆçš„å®‰å…¨é˜²æŠ¤æœºåˆ¶çš„ç´§è¿«æ€§ã€‚",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "This paper will appear in CCS 2025",
      "pdf_url": "https://arxiv.org/pdf/2508.15036v1",
      "published_date": "2025-08-20 20:02:35 UTC",
      "updated_date": "2025-08-20 20:02:35 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:57:12.125929+00:00"
    },
    {
      "arxiv_id": "2508.15865v1",
      "title": "Securing Swarms: Cross-Domain Adaptation for ROS2-based CPS Anomaly Detection",
      "title_zh": "ä¿éšœé›†ç¾¤å®‰å…¨ï¼šåŸºäº ROS2 çš„ä¿¡æ¯ç‰©ç†ç³»ç»Ÿå¼‚å¸¸æ£€æµ‹è·¨åŸŸè‡ªé€‚åº”",
      "authors": [
        "Julia Boone",
        "Fatemeh Afghah"
      ],
      "abstract": "Cyber-physical systems (CPS) are being increasingly utilized for critical applications. CPS combines sensing and computing elements, often having multi-layer designs with networking, computational, and physical interfaces, which provide them with enhanced capabilities for a variety of application scenarios. However, the combination of physical and computational elements also makes CPS more vulnerable to attacks compared to network-only systems, and the resulting impacts of CPS attacks can be substantial. Intelligent intrusion detection systems (IDS) are an effective mechanism by which CPS can be secured, but the majority of current solutions often train and validate on network traffic-only datasets, ignoring the distinct attacks that may occur on other system layers. In order to address this, we develop an adaptable CPS anomaly detection model that can detect attacks within CPS without the need for previously labeled data. To achieve this, we utilize domain adaptation techniques that allow us to transfer known attack knowledge from a network traffic-only environment to a CPS environment. We validate our approach using a state-of-the-art CPS intrusion dataset that combines network, operating system (OS), and Robot Operating System (ROS) data. Through this dataset, we are able to demonstrate the effectiveness of our model across network traffic-only and CPS environments with distinct attack types and its ability to outperform other anomaly detection methods.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹Cyber-physical systems (CPS)åœ¨é¢ä¸´ç½‘ç»œã€Operating System (OS)å’ŒRobot Operating System (ROS)å¤šå±‚æ”»å‡»æ—¶çš„è„†å¼±æ€§ï¼Œæå‡ºäº†ä¸€ç§åŸºäºCross-Domain Adaptationçš„å¼‚å¸¸æ£€æµ‹æ¨¡å‹ã€‚è¯¥æ¨¡å‹æ—¨åœ¨è§£å†³å½“å‰Intrusion Detection Systems (IDS)è¿‡åº¦ä¾èµ–ç½‘ç»œæµé‡æ•°æ®è€Œå¿½è§†å…¶ä»–ç³»ç»Ÿå±‚æ”»å‡»çš„é—®é¢˜ï¼Œå®ç°äº†åœ¨æ— éœ€ç›®æ ‡é¢†åŸŸæ ‡æ³¨æ•°æ®çš„æƒ…å†µä¸‹ï¼Œå°†å·²çŸ¥çš„æ”»å‡»çŸ¥è¯†ä»çº¯ç½‘ç»œç¯å¢ƒè¿ç§»è‡³å¤æ‚çš„CPSç¯å¢ƒã€‚ç ”ç©¶å›¢é˜Ÿåœ¨ç»“åˆäº†ç½‘ç»œã€OSå’ŒROSæ•°æ®çš„å…ˆè¿›CPSå…¥ä¾µæ•°æ®é›†ä¸Šè¿›è¡Œäº†éªŒè¯ï¼Œå®éªŒç»“æœè¡¨æ˜è¯¥æ¨¡å‹èƒ½å¤Ÿæœ‰æ•ˆè¯†åˆ«å¤šç§ç±»å‹çš„è·¨å±‚æ”»å‡»ï¼Œä¸”æ£€æµ‹æ€§èƒ½ä¼˜äºç°æœ‰çš„ä¸»æµå¼‚å¸¸æ£€æµ‹æ–¹æ³•ã€‚è¯¥ç ”ç©¶ä¸ºä¿éšœåŸºäºROS2çš„æœºå™¨äººé›†ç¾¤å®‰å…¨æä¾›äº†ä¸€ç§çµæ´»ä¸”é«˜æ•ˆçš„æŠ€æœ¯è·¯å¾„ï¼Œæ˜¾è‘—æå‡äº†CPSåœ¨å…³é”®åº”ç”¨åœºæ™¯ä¸­çš„é˜²å¾¡èƒ½åŠ›ã€‚",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "Accepted for publication in MILCOM 2025. 6 pages, 2 figures",
      "pdf_url": "https://arxiv.org/pdf/2508.15865v1",
      "published_date": "2025-08-20 20:02:28 UTC",
      "updated_date": "2025-08-20 20:02:28 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:57:13.739264+00:00"
    },
    {
      "arxiv_id": "2508.15031v2",
      "title": "A Systematic Survey of Model Extraction Attacks and Defenses: State-of-the-Art and Perspectives",
      "title_zh": "æ¨¡å‹æå–æ”»å‡»ä¸é˜²å¾¡ç³»ç»Ÿç»¼è¿°ï¼šç°çŠ¶ä¸å±•æœ›",
      "authors": [
        "Kaixiang Zhao",
        "Lincan Li",
        "Kaize Ding",
        "Neil Zhenqiang Gong",
        "Yue Zhao",
        "Yushun Dong"
      ],
      "abstract": "Machine learning (ML) models have significantly grown in complexity and utility, driving advances across multiple domains. However, substantial computational resources and specialized expertise have historically restricted their wide adoption. Machine-Learning-as-a-Service (MLaaS) platforms have addressed these barriers by providing scalable, convenient, and affordable access to sophisticated ML models through user-friendly APIs. While this accessibility promotes widespread use of advanced ML capabilities, it also introduces vulnerabilities exploited through Model Extraction Attacks (MEAs). Recent studies have demonstrated that adversaries can systematically replicate a target model's functionality by interacting with publicly exposed interfaces, posing threats to intellectual property, privacy, and system security. In this paper, we offer a comprehensive survey of MEAs and corresponding defense strategies. We propose a novel taxonomy that classifies MEAs according to attack mechanisms, defense approaches, and computing environments. Our analysis covers various attack techniques, evaluates their effectiveness, and highlights challenges faced by existing defenses, particularly the critical trade-off between preserving model utility and ensuring security. We further assess MEAs within different computing paradigms and discuss their technical, ethical, legal, and societal implications, along with promising directions for future research. This systematic survey aims to serve as a valuable reference for researchers, practitioners, and policymakers engaged in AI security and privacy. Additionally, we maintain an online repository continuously updated with related literature at https://github.com/kzhao5/ModelExtractionPapers.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹Machine-Learning-as-a-Service (MLaaS)å¹³å°é¢ä¸´çš„Model Extraction Attacks (MEAs)å¨èƒï¼Œç³»ç»Ÿåœ°ç»¼è¿°äº†æ¨¡å‹æå–æ”»å‡»åŠå…¶é˜²å¾¡ç­–ç•¥çš„æœ€æ–°è¿›å±•ã€‚è®ºæ–‡æå‡ºäº†ä¸€ç§æ–°é¢–çš„åˆ†ç±»æ³•(Taxonomy)ï¼Œä»æ”»å‡»æœºåˆ¶ã€é˜²å¾¡æ‰‹æ®µåŠè®¡ç®—ç¯å¢ƒç­‰ç»´åº¦å¯¹MEAsè¿›è¡Œäº†è¯¦å°½åˆ†ç±»ã€‚é€šè¿‡åˆ†æä¸åŒæ”»å‡»æŠ€æœ¯çš„æœ‰æ•ˆæ€§ï¼Œè¯¥ç ”ç©¶æ·±å…¥æ¢è®¨äº†ç°æœ‰é˜²å¾¡æœºåˆ¶åœ¨ç»´æŒæ¨¡å‹å®ç”¨æ€§(Utility)ä¸ç¡®ä¿å®‰å…¨æ€§(Security)ä¹‹é—´é¢ä¸´çš„ä¸¥å³»æƒè¡¡æŒ‘æˆ˜ã€‚æ–‡ç« è¿›ä¸€æ­¥è¯„ä¼°äº†ä¸åŒè®¡ç®—èŒƒå¼ä¸‹çš„æ”»å‡»é£é™©ï¼Œå¹¶è®¨è®ºäº†å…¶åœ¨æŠ€æœ¯ã€ä¼¦ç†ã€æ³•å¾‹åŠç¤¾ä¼šå±‚é¢çš„å¹¿æ³›å½±å“ã€‚è¯¥ç»¼è¿°ä¸ä»…ä¸ºAIå®‰å…¨ä¸éšç§é¢†åŸŸçš„ç ”ç©¶è€…æä¾›äº†é‡è¦å‚è€ƒï¼Œè¿˜é€šè¿‡ç»´æŠ¤æŒç»­æ›´æ–°çš„åœ¨çº¿æ–‡çŒ®åº“ä¸ºè¯¥é¢†åŸŸçš„æœªæ¥ç ”ç©¶æŒ‡æ˜äº†æ–¹å‘ã€‚",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.15031v2",
      "published_date": "2025-08-20 19:49:59 UTC",
      "updated_date": "2025-08-27 05:10:26 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:57:27.421948+00:00"
    },
    {
      "arxiv_id": "2508.15030v3",
      "title": "Collab-REC: An LLM-based Agentic Framework for Balancing Recommendations in Tourism",
      "title_zh": "Collab-RECï¼šä¸€ç§ç”¨äºå¹³è¡¡æ—…æ¸¸æ¨èçš„åŸºäºå¤§è¯­è¨€æ¨¡å‹æ™ºèƒ½ä½“æ¡†æ¶",
      "authors": [
        "Ashmi Banerjee",
        "Adithi Satish",
        "Fitri Nur Aisyah",
        "Wolfgang WÃ¶rndl",
        "Yashar Deldjoo"
      ],
      "abstract": "We propose Collab-REC, a multi-agent framework designed to counteract popularity bias and enhance diversity in tourism recommendations. In our setting, three LLM-based agents -- Personalization, Popularity, and Sustainability generate city suggestions from complementary perspectives. A non-LLM moderator then merges and refines these proposals via multi-round negotiation, ensuring each agent's viewpoint is incorporated while penalizing spurious or repeated responses. Experiments on European city queries show that Collab-REC improves diversity and overall relevance compared to a single-agent baseline, surfacing lesser-visited locales that often remain overlooked. This balanced, context-aware approach addresses over-tourism and better aligns with constraints provided by the user, highlighting the promise of multi-stakeholder collaboration in LLM-driven recommender systems.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† Collab-RECï¼Œè¿™æ˜¯ä¸€ä¸ªåŸºäºå¤§è¯­è¨€æ¨¡å‹(LLM)çš„å¤šæ™ºèƒ½ä½“æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³æ—…æ¸¸æ¨èç³»ç»Ÿä¸­çš„æµè¡Œåè§(popularity bias)å¹¶æå‡æ¨èçš„å¤šæ ·æ€§ã€‚è¯¥æ¡†æ¶ç”±ä¸‰ä¸ªåŸºäº LLM çš„æ™ºèƒ½ä½“ï¼ˆPersonalizationã€Popularity å’Œ Sustainabilityï¼‰ç»„æˆï¼Œå®ƒä»¬åˆ†åˆ«ä»äº’è¡¥çš„è§†è§’ç”ŸæˆåŸå¸‚å»ºè®®ã€‚ç³»ç»Ÿå¼•å…¥äº†ä¸€ä¸ªé LLM çš„åè°ƒè€…(moderator)ï¼Œé€šè¿‡å¤šè½®åå•†åˆå¹¶å¹¶ä¼˜åŒ–è¿™äº›ææ¡ˆï¼Œåœ¨ç¡®ä¿å„æ–¹è§‚ç‚¹å¾—åˆ°æ•´åˆçš„åŒæ—¶ï¼Œæƒ©ç½šè™šå‡æˆ–é‡å¤çš„å“åº”ã€‚åœ¨æ¬§æ´²åŸå¸‚æŸ¥è¯¢çš„å®éªŒè¡¨æ˜ï¼ŒCollab-REC ç›¸æ¯”å•æ™ºèƒ½ä½“åŸºçº¿æ¨¡å‹åœ¨å¤šæ ·æ€§å’Œæ•´ä½“ç›¸å…³æ€§æ–¹é¢å‡æœ‰æ˜¾è‘—æå‡ï¼Œèƒ½å¤Ÿæœ‰æ•ˆæŒ–æ˜å¸¸è¢«å¿½è§†çš„å†·é—¨æ—…æ¸¸åœ°ç‚¹ã€‚è¿™ç§å¹³è¡¡ä¸”å…·å¤‡ä¸Šä¸‹æ–‡æ„ŸçŸ¥èƒ½åŠ›çš„æ–¹æ³•æœ‰åŠ©äºç¼“è§£è¿‡åº¦æ—…æ¸¸(over-tourism)é—®é¢˜ï¼Œå¹¶èƒ½æ›´å¥½åœ°æ»¡è¶³ç”¨æˆ·çš„ä¸ªæ€§åŒ–çº¦æŸï¼Œå±•ç¤ºäº†å¤šåˆ©ç›Šç›¸å…³è€…åä½œåœ¨ LLM é©±åŠ¨çš„æ¨èç³»ç»Ÿä¸­çš„åº”ç”¨æ½œåŠ›ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.15030v3",
      "published_date": "2025-08-20 19:49:06 UTC",
      "updated_date": "2025-10-30 14:10:33 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:57:30.585614+00:00"
    },
    {
      "arxiv_id": "2508.15027v1",
      "title": "Reversible Unfolding Network for Concealed Visual Perception with Generative Refinement",
      "title_zh": "èåˆç”Ÿæˆå¼ç»†åŒ–çš„éšè—è§†è§‰æ„ŸçŸ¥å¯é€†å±•å¼€ç½‘ç»œ",
      "authors": [
        "Chunming He",
        "Fengyang Xiao",
        "Rihan Zhang",
        "Chengyu Fang",
        "Deng-Ping Fan",
        "Sina Farsiu"
      ],
      "abstract": "Existing methods for concealed visual perception (CVP) often leverage reversible strategies to decrease uncertainty, yet these are typically confined to the mask domain, leaving the potential of the RGB domain underexplored. To address this, we propose a reversible unfolding network with generative refinement, termed RUN++. Specifically, RUN++ first formulates the CVP task as a mathematical optimization problem and unfolds the iterative solution into a multi-stage deep network. This approach provides a principled way to apply reversible modeling across both mask and RGB domains while leveraging a diffusion model to resolve the resulting uncertainty. Each stage of the network integrates three purpose-driven modules: a Concealed Object Region Extraction (CORE) module applies reversible modeling to the mask domain to identify core object regions; a Context-Aware Region Enhancement (CARE) module extends this principle to the RGB domain to foster better foreground-background separation; and a Finetuning Iteration via Noise-based Enhancement (FINE) module provides a final refinement. The FINE module introduces a targeted Bernoulli diffusion model that refines only the uncertain regions of the segmentation mask, harnessing the generative power of diffusion for fine-detail restoration without the prohibitive computational cost of a full-image process. This unique synergy, where the unfolding network provides a strong uncertainty prior for the diffusion model, allows RUN++ to efficiently direct its focus toward ambiguous areas, significantly mitigating false positives and negatives. Furthermore, we introduce a new paradigm for building robust CVP systems that remain effective under real-world degradations and extend this concept into a broader bi-level optimization framework.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†RUN++ï¼Œä¸€ç§å¸¦æœ‰ç”Ÿæˆå¼ç»†åŒ–çš„å¯é€†å±•å¼€ç½‘ç»œï¼Œæ—¨åœ¨è§£å†³éšè”½è§†è§‰æ„ŸçŸ¥(Concealed Visual Perception, CVP)ä»»åŠ¡ä¸­ç°æœ‰å¯é€†ç­–ç•¥ä»…å±€é™äºmaskåŸŸè€Œå¿½è§†äº†RGBåŸŸæ½œåŠ›çš„é—®é¢˜ã€‚RUN++å°†CVPä»»åŠ¡è¡¨è¿°ä¸ºä¸€ä¸ªæ•°å­¦ä¼˜åŒ–é—®é¢˜ï¼Œå¹¶å°†å…¶è¿­ä»£è§£å±•å¼€ä¸ºå¤šé˜¶æ®µæ·±åº¦ç½‘ç»œï¼Œå®ç°äº†åœ¨maskå’ŒRGBåŸŸä¸­åŒæ—¶åº”ç”¨å¯é€†å»ºæ¨¡ã€‚è¯¥æ¡†æ¶é›†æˆäº†COREæ¨¡å—ä»¥æå–æ ¸å¿ƒç›®æ ‡åŒºåŸŸã€CAREæ¨¡å—åœ¨RGBåŸŸå¢å¼ºå‰æ™¯ä¸èƒŒæ™¯çš„åˆ†ç¦»ï¼Œä»¥åŠFINEæ¨¡å—åˆ©ç”¨é’ˆå¯¹æ€§çš„Bernoulliæ‰©æ•£æ¨¡å‹å¯¹maskçš„ä¸ç¡®å®šåŒºåŸŸè¿›è¡Œç²¾ç»†åŒ–ä¿®å¤ã€‚é€šè¿‡è¿™ç§ååŒä½œç”¨ï¼ŒRUN++èƒ½æœ‰æ•ˆåœ°å°†æ³¨æ„åŠ›é›†ä¸­åœ¨æ¨¡ç³ŠåŒºåŸŸï¼Œæ˜¾è‘—å‡å°‘äº†è¯¯æŠ¥å’Œæ¼æŠ¥ï¼Œå¹¶åœ¨ç»†å¾®ç»†èŠ‚æ¢å¤ä¸Šå±•ç°å‡ºç”Ÿæˆæ¨¡å‹çš„ä¼˜åŠ¿ã€‚æ­¤å¤–ï¼Œè¯¥ç ”ç©¶è¿˜å¼•å…¥äº†é’ˆå¯¹ç°å®ä¸–ç•Œé™è´¨çš„é²æ£’æ€§æ„å»ºèŒƒå¼ï¼Œå¹¶å°†å…¶æ‰©å±•ä¸ºæ›´å¹¿æ³›çš„åŒå±‚ä¼˜åŒ–æ¡†æ¶(bi-level optimization framework)ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "18 pages, 21 tables, 13 figures",
      "pdf_url": "https://arxiv.org/pdf/2508.15027v1",
      "published_date": "2025-08-20 19:45:40 UTC",
      "updated_date": "2025-08-20 19:45:40 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:57:35.023227+00:00"
    },
    {
      "arxiv_id": "2508.15020v1",
      "title": "TAIGen: Training-Free Adversarial Image Generation via Diffusion Models",
      "title_zh": "TAIGenï¼šåŸºäºæ‰©æ•£æ¨¡å‹çš„æ— éœ€è®­ç»ƒå¯¹æŠ—æ€§å›¾åƒç”Ÿæˆ",
      "authors": [
        "Susim Roy",
        "Anubhooti Jain",
        "Mayank Vatsa",
        "Richa Singh"
      ],
      "abstract": "Adversarial attacks from generative models often produce low-quality images and require substantial computational resources. Diffusion models, though capable of high-quality generation, typically need hundreds of sampling steps for adversarial generation. This paper introduces TAIGen, a training-free black-box method for efficient adversarial image generation. TAIGen produces adversarial examples using only 3-20 sampling steps from unconditional diffusion models. Our key finding is that perturbations injected during the mixing step interval achieve comparable attack effectiveness without processing all timesteps. We develop a selective RGB channel strategy that applies attention maps to the red channel while using GradCAM-guided perturbations on green and blue channels. This design preserves image structure while maximizing misclassification in target models. TAIGen maintains visual quality with PSNR above 30 dB across all tested datasets. On ImageNet with VGGNet as source, TAIGen achieves 70.6% success against ResNet, 80.8% against MNASNet, and 97.8% against ShuffleNet. The method generates adversarial examples 10x faster than existing diffusion-based attacks. Our method achieves the lowest robust accuracy, indicating it is the most impactful attack as the defense mechanism is least successful in purifying the images generated by TAIGen.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†TAIGenï¼Œä¸€ç§åˆ©ç”¨Diffusion Modelså®ç°çš„é«˜æ•ˆã€æ— éœ€è®­ç»ƒ(training-free)çš„é»‘ç›’å¯¹æŠ—å›¾åƒç”Ÿæˆæ–¹æ³•ã€‚é’ˆå¯¹ç”Ÿæˆå¼å¯¹æŠ—æ”»å‡»è´¨é‡ä½æˆ–Diffusion Modelsé‡‡æ ·é€Ÿåº¦æ…¢çš„é—®é¢˜ï¼ŒTAIGenä»…éœ€3-20ä¸ªé‡‡æ ·æ­¥éª¤å³å¯ç”Ÿæˆé«˜è´¨é‡å¯¹æŠ—æ ·æœ¬ã€‚å…¶æ ¸å¿ƒå‘ç°åœ¨äºæ··åˆæ­¥éª¤é—´éš”(mixing step interval)æ³¨å…¥æ‰°åŠ¨ï¼Œæ— éœ€å¤„ç†æ‰€æœ‰æ—¶é—´æ­¥å³å¯è¾¾åˆ°ç›¸å½“çš„æ”»å‡»æ•ˆæœã€‚æŠ€æœ¯ä¸Šï¼ŒTAIGené‡‡ç”¨äº†é€‰æ‹©æ€§RGBé€šé“ç­–ç•¥ï¼Œå°†æ³¨æ„åŠ›å›¾(attention maps)åº”ç”¨äºçº¢è‰²é€šé“ï¼ŒåŒæ—¶å¯¹ç»¿è‰²å’Œè“è‰²é€šé“æ–½åŠ GradCAMå¼•å¯¼çš„æ‰°åŠ¨ï¼Œåœ¨æœ€å¤§é™åº¦è¯±å¯¼ç›®æ ‡æ¨¡å‹è¯¯åˆ†ç±»çš„åŒæ—¶ä¿æŒäº†å›¾åƒç»“æ„ï¼Œä½¿PSNRä¿æŒåœ¨30 dBä»¥ä¸Šã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œåœ¨ImageNetä¸Šè¯¥æ–¹æ³•å¯¹ShuffleNetçš„æ”»å‡»æˆåŠŸç‡é«˜è¾¾97.8%ï¼Œä¸”ç”Ÿæˆé€Ÿåº¦æ¯”ç°æœ‰åŸºäºæ‰©æ•£æ¨¡å‹çš„æ”»å‡»å¿«10å€ã€‚è¯¥æ–¹æ³•æœ€ç»ˆå®ç°äº†æœ€ä½çš„é²æ£’å‡†ç¡®ç‡(robust accuracy)ï¼Œè¯æ˜å…¶åœ¨å¯¹æŠ—é˜²å¾¡å‡€åŒ–æœºåˆ¶æ—¶å…·æœ‰æ˜¾è‘—çš„æ”»å‡»æ•ˆèƒ½ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted at ICCVW-CV4BIOM 2025",
      "pdf_url": "https://arxiv.org/pdf/2508.15020v1",
      "published_date": "2025-08-20 19:21:51 UTC",
      "updated_date": "2025-08-20 19:21:51 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:57:35.821396+00:00"
    },
    {
      "arxiv_id": "2508.15019v1",
      "title": "Twin-Boot: Uncertainty-Aware Optimization via Online Two-Sample Bootstrapping",
      "title_zh": "Twin-Bootï¼šåŸºäºåœ¨çº¿åŒæ ·æœ¬è‡ªåŠ©æ³•çš„ä¸ç¡®å®šæ€§æ„ŸçŸ¥ä¼˜åŒ–",
      "authors": [
        "Carlos Stein Brito"
      ],
      "abstract": "Standard gradient descent methods yield point estimates with no measure of confidence. This limitation is acute in overparameterized and low-data regimes, where models have many parameters relative to available data and can easily overfit. Bootstrapping is a classical statistical framework for uncertainty estimation based on resampling, but naively applying it to deep learning is impractical: it requires training many replicas, produces post-hoc estimates that cannot guide learning, and implicitly assumes comparable optima across runs - an assumption that fails in non-convex landscapes. We introduce Twin-Bootstrap Gradient Descent (Twin-Boot), a resampling-based training procedure that integrates uncertainty estimation into optimization. Two identical models are trained in parallel on independent bootstrap samples, and a periodic mean-reset keeps both trajectories in the same basin so that their divergence reflects local (within-basin) uncertainty. During training, we use this estimate to sample weights in an adaptive, data-driven way, providing regularization that favors flatter solutions. In deep neural networks and complex high-dimensional inverse problems, the approach improves calibration and generalization and yields interpretable uncertainty maps.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†Twin-Bootstrap Gradient Descent (Twin-Boot)ï¼Œè¿™æ˜¯ä¸€ç§é€šè¿‡åœ¨çº¿åŒæ ·æœ¬é‡é‡‡æ ·å°†ä¸ç¡®å®šæ€§è¯„ä¼°é›†æˆåˆ°ä¼˜åŒ–è¿‡ç¨‹ä¸­çš„è®­ç»ƒç¨‹åºã€‚ä¼ ç»Ÿçš„æ¢¯åº¦ä¸‹é™æ–¹æ³•ä»…èƒ½æä¾›ç‚¹ä¼°è®¡ï¼Œéš¾ä»¥åœ¨å‚æ•°è¿‡è½½æˆ–ä½æ•°æ®é‡åœºæ™¯ä¸‹æä¾›ç½®ä¿¡åº¦è¡¡é‡ï¼Œä¸”æ ‡å‡†çš„Bootstrappingåœ¨æ·±åº¦å­¦ä¹ å’Œéå‡¸æ™¯è§‚ä¸­ç”±äºè®¡ç®—å¼€é”€å’Œæ”¶æ•›ä¸€è‡´æ€§é—®é¢˜è€Œéš¾ä»¥åº”ç”¨ã€‚Twin-Booté€šè¿‡å¹¶è¡Œè®­ç»ƒä¸¤ä¸ªç‹¬ç«‹çš„æ¨¡å‹ï¼Œå¹¶åˆ©ç”¨å‘¨æœŸæ€§çš„å‡å€¼é‡ç½®ç¡®ä¿ä¸¤è€…å¤„äºåŒä¸€ä¸ªlocal basinï¼Œä»è€Œä½¿æ¨¡å‹çš„æ•£åº¦èƒ½å¤Ÿå‡†ç¡®åæ˜ å±€éƒ¨ä¸ç¡®å®šæ€§ã€‚åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œè¯¥æ¡†æ¶æ ¹æ®ä¸ç¡®å®šæ€§è¯„ä¼°ä»¥è‡ªé€‚åº”çš„æ–¹å¼é‡‡æ ·æƒé‡ï¼Œé€šè¿‡æ­£åˆ™åŒ–ä¿ƒè¿›æ¨¡å‹å¯»æ‰¾æ›´å¹³å¦çš„è§£ã€‚å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨æ·±åº¦ç¥ç»ç½‘ç»œå’Œå¤æ‚çš„é«˜ç»´é€†å‘é—®é¢˜ä¸­æ˜¾è‘—æå‡äº†æ¨¡å‹çš„æ ¡å‡†èƒ½åŠ›å’Œæ³›åŒ–æ€§èƒ½ï¼Œå¹¶èƒ½ç”Ÿæˆå¯è§£é‡Šçš„ä¸ç¡®å®šæ€§å›¾ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.CO",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "12 pages, 6 figures",
      "pdf_url": "https://arxiv.org/pdf/2508.15019v1",
      "published_date": "2025-08-20 19:20:38 UTC",
      "updated_date": "2025-08-20 19:20:38 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:57:36.219221+00:00"
    },
    {
      "arxiv_id": "2508.18288v1",
      "title": "Toward Responsible ASR for African American English Speakers: A Scoping Review of Bias and Equity in Speech Technology",
      "title_zh": "é¢å‘éè£”ç¾å›½è‹±è¯­ä½¿ç”¨è€…çš„è´Ÿè´£ä»» ASRï¼šè¯­éŸ³æŠ€æœ¯ä¸­çš„åè§ä¸å…¬å¹³æ€§èŒƒå›´ç»¼è¿°",
      "authors": [
        "Jay L. Cunningham",
        "Adinawa Adjagbodjou",
        "Jeffrey Basoah",
        "Jainaba Jawara",
        "Kowe Kadoma",
        "Aaleyah Lewis"
      ],
      "abstract": "This scoping literature review examines how fairness, bias, and equity are conceptualized and operationalized in Automatic Speech Recognition (ASR) and adjacent speech and language technologies (SLT) for African American English (AAE) speakers and other linguistically diverse communities. Drawing from 44 peer-reviewed publications across Human-Computer Interaction (HCI), Machine Learning/Natural Language Processing (ML/NLP), and Sociolinguistics, we identify four major areas of inquiry: (1) how researchers understand ASR-related harms; (2) inclusive data practices spanning collection, curation, annotation, and model training; (3) methodological and theoretical approaches to linguistic inclusion; and (4) emerging practices and design recommendations for more equitable systems. While technical fairness interventions are growing, our review highlights a critical gap in governance-centered approaches that foreground community agency, linguistic justice, and participatory accountability. We propose a governance-centered ASR lifecycle as an emergent interdisciplinary framework for responsible ASR development and offer implications for researchers, practitioners, and policymakers seeking to address language marginalization in speech AI systems.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ Automatic Speech Recognition (ASR) åŠç›¸å…³ Speech and Language Technologies (SLT) åœ¨å¤„ç† African American English (AAE) è¯´è¯è€…æ—¶é¢ä¸´çš„å…¬å¹³æ€§ã€åè§å’Œå¹³ç­‰é—®é¢˜è¿›è¡Œäº†èŒƒå›´å®¡æŸ¥ (Scoping Review)ã€‚é€šè¿‡å¯¹æ¥è‡ª HCIã€ML/NLP å’Œç¤¾ä¼šè¯­è¨€å­¦ç­‰é¢†åŸŸçš„ 44 ç¯‡è®ºæ–‡è¿›è¡Œæ·±å…¥åˆ†æï¼Œç ”ç©¶æç‚¼å‡ºåŒ…æ‹¬ ASR ç›¸å…³ä¼¤å®³ã€åŒ…å®¹æ€§æ•°æ®å®è·µã€è¯­è¨€åŒ…å®¹çš„æ–¹æ³•è®ºä»¥åŠå…¬å¹³ç³»ç»Ÿè®¾è®¡å»ºè®®åœ¨å†…çš„å››ä¸ªæ ¸å¿ƒæ¢ç©¶é¢†åŸŸã€‚å®¡æŸ¥ç»“æœè¡¨æ˜ï¼Œå°½ç®¡ç›®å‰é’ˆå¯¹æŠ€æœ¯å…¬å¹³æ€§çš„å¹²é¢„æªæ–½æ—¥ç›Šå¢å¤šï¼Œä½†åœ¨å¼ºè°ƒç¤¾åŒºèƒ½åŠ¨æ€§ã€è¯­è¨€æ­£ä¹‰å’Œå‚ä¸å¼é—®è´£çš„æ²»ç†ä¸­å¿ƒ (Governance-centered) æ–¹æ³•ä¸Šä»å­˜åœ¨å…³é”®ç©ºç™½ã€‚ä¸ºæ­¤ï¼Œä½œè€…æå‡ºäº†ä¸€ä¸ªä»¥æ²»ç†ä¸ºä¸­å¿ƒçš„ ASR ç”Ÿå‘½å‘¨æœŸ (Governance-centered ASR lifecycle) æ¡†æ¶ï¼Œæ—¨åœ¨ä¸ºè´Ÿè´£ä»»çš„ ASR å¼€å‘æä¾›è·¨å­¦ç§‘æŒ‡å¯¼ã€‚è¯¥ç ”ç©¶ä¸ä»…æ­ç¤ºäº†è¯­éŸ³ AI ç³»ç»Ÿä¸­çš„è¯­è¨€è¾¹ç¼˜åŒ–ç°çŠ¶ï¼Œè¿˜ä¸ºæ”¿ç­–åˆ¶å®šè€…å’Œä»ä¸šè€…æä¾›äº†æ¨åŠ¨æŠ€æœ¯å¹³ç­‰çš„é‡è¦å®è·µå»ºè®®ã€‚",
      "categories": [
        "eess.AS",
        "cs.AI",
        "cs.CL",
        "cs.SD"
      ],
      "primary_category": "eess.AS",
      "comment": "10 pages, 9 Pages (References and Appendices). The archival version has been accepted to AAAI (AIES 2025) without the extended Appendices. This extended version includes Appendices",
      "pdf_url": "https://arxiv.org/pdf/2508.18288v1",
      "published_date": "2025-08-20 19:09:15 UTC",
      "updated_date": "2025-08-20 19:09:15 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:57:41.215316+00:00"
    },
    {
      "arxiv_id": "2508.16663v1",
      "title": "The Loupe: A Plug-and-Play Attention Module for Amplifying Discriminative Features in Vision Transformers",
      "title_zh": "The Loupeï¼šä¸€ç§ç”¨äºå¢å¼ºè§†è§‰ Transformer åˆ¤åˆ«æ€§ç‰¹å¾çš„å³æ’å³ç”¨æ³¨æ„åŠ›æ¨¡å—",
      "authors": [
        "Naren Sengodan"
      ],
      "abstract": "Fine-Grained Visual Classification (FGVC) is a critical and challenging area within computer vision, demanding the identification of highly subtle, localized visual cues. The importance of FGVC extends to critical applications such as biodiversity monitoring and medical diagnostics, where precision is paramount. While large-scale Vision Transformers have achieved state-of-the-art performance, their decision-making processes often lack the interpretability required for trust and verification in such domains. In this paper, we introduce The Loupe, a novel, lightweight, and plug-and-play attention module designed to be inserted into pre-trained backbones like the Swin Transformer. The Loupe is trained end-to-end with a composite loss function that implicitly guides the model to focus on the most discriminative object parts without requiring explicit part-level annotations. Our unique contribution lies in demonstrating that a simple, intrinsic attention mechanism can act as a powerful regularizer, significantly boosting performance while simultaneously providing clear visual explanations. Our experimental evaluation on the challenging CUB-200-2011 dataset shows that The Loupe improves the accuracy of a Swin-Base model from 85.40% to 88.06%, a significant gain of 2.66%. Crucially, our qualitative analysis of the learned attention maps reveals that The Loupe effectively localizes semantically meaningful features, providing a valuable tool for understanding and trusting the model's decision-making process.",
      "tldr_zh": "è¯¥é¡¹ç ”ç©¶é’ˆå¯¹ç»†ç²’åº¦è§†è§‰åˆ†ç±»(Fine-Grained Visual Classification, FGVC)ä¸­å¯¹ç»†å¾®å±€éƒ¨ç‰¹å¾çš„é«˜éœ€æ±‚ä»¥åŠ Vision Transformers æ¨¡å‹è§£é‡Šæ€§ä¸è¶³çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§åä¸º The Loupe çš„è½»é‡åŒ–ã€å³æ’å³ç”¨å‹æ³¨æ„åŠ›æ¨¡å—ã€‚The Loupe å¯ä»¥ç›´æ¥åµŒå…¥åˆ°å¦‚ Swin Transformer ç­‰é¢„è®­ç»ƒä¸»å¹²ç½‘ç»œä¸­ï¼Œå¹¶é€šè¿‡ç«¯åˆ°ç«¯çš„å¤åˆæŸå¤±å‡½æ•°è®­ç»ƒï¼Œåœ¨æ— éœ€æ˜¾å¼é›¶ä»¶çº§æ ‡æ³¨çš„æƒ…å†µä¸‹ï¼Œéšå¼å¼•å¯¼æ¨¡å‹å…³æ³¨æœ€å…·è¾¨åˆ«åŠ›çš„ç‰©ä½“éƒ¨ä½ã€‚ç ”ç©¶è¡¨æ˜ï¼Œè¿™ç§ç‹¬ç‰¹çš„æ³¨æ„åŠ›æœºåˆ¶èƒ½å¤Ÿèµ·åˆ°å¼ºå¤§çš„æ­£åˆ™åŒ–ä½œç”¨ï¼Œåœ¨æ˜¾è‘—æå‡æ€§èƒ½çš„åŒæ—¶æä¾›æ¸…æ™°çš„å¯è§†åŒ–è§£é‡Šã€‚å®éªŒè¯„ä¼°æ˜¾ç¤ºï¼Œåœ¨ CUB-200-2011 æ•°æ®é›†ä¸Šï¼Œè¯¥æ¨¡å—å°† Swin-Base æ¨¡å‹çš„å‡†ç¡®ç‡ä» 85.40% æå‡è‡³ 88.06%ï¼Œå®ç°äº† 2.66% çš„æ˜¾è‘—å¢ç›Šã€‚å®šæ€§åˆ†æè¿›ä¸€æ­¥è¯å® The Loupe èƒ½å¤Ÿæœ‰æ•ˆå®šä½å…·æœ‰è¯­ä¹‰æ„ä¹‰çš„ç‰¹å¾ï¼Œä¸ºç†è§£å’Œä¿¡ä»»æ¨¡å‹çš„å†³ç­–è¿‡ç¨‹æä¾›äº†é‡è¦å·¥å…·ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.16663v1",
      "published_date": "2025-08-20 19:07:21 UTC",
      "updated_date": "2025-08-20 19:07:21 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:57:44.818425+00:00"
    },
    {
      "arxiv_id": "2508.15013v1",
      "title": "Goals and the Structure of Experience",
      "title_zh": "ç›®æ ‡ä¸ç»éªŒçš„ç»“æ„",
      "authors": [
        "Nadav Amir",
        "Stas Tiomkin",
        "Angela Langdon"
      ],
      "abstract": "Purposeful behavior is a hallmark of natural and artificial intelligence. Its acquisition is often believed to rely on world models, comprising both descriptive (what is) and prescriptive (what is desirable) aspects that identify and evaluate state of affairs in the world, respectively. Canonical computational accounts of purposeful behavior, such as reinforcement learning, posit distinct components of a world model comprising a state representation (descriptive aspect) and a reward function (prescriptive aspect). However, an alternative possibility, which has not yet been computationally formulated, is that these two aspects instead co-emerge interdependently from an agent's goal. Here, we describe a computational framework of goal-directed state representation in cognitive agents, in which the descriptive and prescriptive aspects of a world model co-emerge from agent-environment interaction sequences, or experiences. Drawing on Buddhist epistemology, we introduce a construct of goal-directed, or telic, states, defined as classes of goal-equivalent experience distributions. Telic states provide a parsimonious account of goal-directed learning in terms of the statistical divergence between behavioral policies and desirable experience features. We review empirical and theoretical literature supporting this novel perspective and discuss its potential to provide a unified account of behavioral, phenomenological and neural dimensions of purposeful behaviors across diverse substrates.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†è‡ªç„¶ä¸äººå·¥æ™ºèƒ½ä¸­æœ‰ç›®çš„è¡Œä¸ºçš„èµ·æºï¼ŒæŒ‘æˆ˜äº†å¼ºåŒ–å­¦ä¹ (reinforcement learning)ä¸­å°†ä¸–ç•Œæ¨¡å‹(world models)çš„çŠ¶æ€è¡¨å¾(state representation)ä¸å¥–åŠ±å‡½æ•°(reward function)åˆ†ç¦»çš„ä¼ ç»Ÿè§‚ç‚¹ã€‚è®ºæ–‡æå‡ºäº†ä¸€ä¸ªå…³äºè®¤çŸ¥æ™ºèƒ½ä½“ä¸­æœ‰ç›®çš„çŠ¶æ€è¡¨å¾çš„è®¡ç®—æ¡†æ¶ï¼Œè®¤ä¸ºä¸–ç•Œæ¨¡å‹çš„æè¿°æ€§ä¸è§„èŒƒæ€§ç»´åº¦æ˜¯ä»æ™ºèƒ½ä½“ä¸ç¯å¢ƒçš„äº¤äº’åºåˆ—ï¼ˆä½“éªŒï¼‰ä¸­å…±åŒæ¼”åŒ–è€Œæˆçš„ã€‚é€šè¿‡å€Ÿé‰´ä½›æ•™è®¤è¯†è®º(Buddhist epistemology)ï¼Œç ”ç©¶å¼•å…¥äº†ç›®çš„æ€§çŠ¶æ€(telic states)è¿™ä¸€æ¦‚å¿µï¼Œå¹¶å°†å…¶å®šä¹‰ä¸ºç›®æ ‡ç­‰æ•ˆçš„ä½“éªŒåˆ†å¸ƒç±»åˆ«ã€‚è¯¥æ¡†æ¶åˆ©ç”¨è¡Œä¸ºç­–ç•¥ä¸ç†æƒ³ä½“éªŒç‰¹å¾ä¹‹é—´çš„ç»Ÿè®¡æ•£åº¦(statistical divergence)ï¼Œä¸ºæœ‰ç›®çš„å­¦ä¹ æä¾›äº†ä¸€ç§ç²¾ç®€çš„è®¡ç®—è§£é‡Šã€‚è¿™ä¸€æ–°è§†è§’æ•´åˆäº†è·¨é¢†åŸŸçš„å®è¯ä¸ç†è®ºæˆæœï¼Œæ—¨åœ¨ä¸ºæœ‰ç›®çš„è¡Œä¸ºçš„è¡Œä¸ºã€ç°è±¡å­¦å’Œç¥ç»ç»´åº¦æä¾›ç»Ÿä¸€çš„è§£é‡Šæ¡†æ¶ã€‚",
      "categories": [
        "cs.AI",
        "q-bio.NC"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.15013v1",
      "published_date": "2025-08-20 19:05:24 UTC",
      "updated_date": "2025-08-20 19:05:24 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:58:07.534295+00:00"
    },
    {
      "arxiv_id": "2508.15008v4",
      "title": "Neural Network Quantization for Microcontrollers: A Comprehensive Survey of Methods, Platforms, and Applications",
      "title_zh": "é¢å‘å¾®æ§åˆ¶å™¨çš„ç¥ç»ç½‘ç»œé‡åŒ–ï¼šæ–¹æ³•ã€å¹³å°ä¸åº”ç”¨å…¨é¢ç»¼è¿°",
      "authors": [
        "Hamza A. Abushahla",
        "Dara Varam",
        "Ariel Justine N. Panopio",
        "Mohamed I. AlHajri"
      ],
      "abstract": "The deployment of Quantized Neural Networks (QNNs) on resource-constrained edge devices, such as microcontrollers (MCUs), introduces fundamental challenges in balancing model performance, computational complexity, and memory constraints. Tiny Machine Learning (TinyML) addresses these issues by jointly advancing machine learning algorithms, hardware architectures, and software optimization techniques to enable deep neural network inference on embedded systems. This survey provides a hardware-oriented perspective on neural network quantization, systematically reviewing the quantization methods most relevant to MCUs and extreme-edge devices. Particular emphasis is placed on the critical trade-offs between model performance and the capabilities of MCU-class hardware, including memory hierarchies, numerical representations, and accelerator support. The survey further reviews contemporary MCU hardware platforms, including ARM-based and RISC-V-based designs, as well as MCUs integrating neural processing units (NPUs) for low-precision inference, together with the supporting software stacks. In addition, we analyze real-world deployments of quantized models on MCUs and consolidate the application domains in which such systems are used. Finally, we discuss open challenges and outline promising future directions toward scalable, energy-efficient, and sustainable AI deployment on edge devices.",
      "tldr_zh": "è¯¥ç»¼è¿°ç³»ç»Ÿåœ°æ¢è®¨äº†åœ¨å¾®æ§åˆ¶å™¨(MCUs)ç­‰èµ„æºå—é™è®¾å¤‡ä¸Šéƒ¨ç½²é‡åŒ–ç¥ç»ç½‘ç»œ(Quantized Neural Networks, QNNs)çš„å…³é”®æŒ‘æˆ˜ï¼Œæ—¨åœ¨æ¨åŠ¨Tiny Machine Learning(TinyML)æŠ€æœ¯åœ¨åµŒå…¥å¼ç³»ç»Ÿä¸­çš„é«˜æ•ˆæ¨ç†ã€‚æ–‡ç« ä»ç¡¬ä»¶å¯¼å‘çš„è§’åº¦å‡ºå‘ï¼Œç³»ç»Ÿå›é¡¾äº†é€‚ç”¨äºMCUså’Œæç«¯è¾¹ç¼˜è®¾å¤‡çš„é‡åŒ–(Quantization)æ–¹æ³•ï¼Œå¹¶æ·±å…¥åˆ†æäº†æ¨¡å‹æ€§èƒ½ä¸ç¡¬ä»¶èµ„æºï¼ˆå¦‚å†…å­˜å±‚æ¬¡ç»“æ„ã€æ•°å€¼è¡¨ç¤ºå’ŒåŠ é€Ÿå™¨æ”¯æŒï¼‰ä¹‹é—´çš„æƒè¡¡å…³ç³»ã€‚è¯¥ç ”ç©¶è¿›ä¸€æ­¥è°ƒç ”äº†åŸºäºARMå’ŒRISC-Væ¶æ„çš„å½“ä»£MCUç¡¬ä»¶å¹³å°ï¼Œä»¥åŠé›†æˆäº†ç¥ç»å¤„ç†å•å…ƒ(NPUs)çš„ä½ç²¾åº¦æ¨ç†æ–¹æ¡ˆåŠé…å¥—è½¯ä»¶æ ˆã€‚æ­¤å¤–ï¼Œè®ºæ–‡è¿˜æ€»ç»“äº†é‡åŒ–æ¨¡å‹åœ¨çœŸå®åœºæ™¯ä¸­çš„éƒ¨ç½²æ¡ˆä¾‹åŠåº”ç”¨é¢†åŸŸï¼Œå¹¶ä¸ºæœªæ¥å®ç°å¯æ‰©å±•ã€é«˜èƒ½æ•ˆä¸”å¯æŒç»­çš„è¾¹ç¼˜AIéƒ¨ç½²æŒ‡æ˜äº†æ–¹å‘ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.AR"
      ],
      "primary_category": "cs.LG",
      "comment": "40 pages, 16 figures, 8 Tables",
      "pdf_url": "https://arxiv.org/pdf/2508.15008v4",
      "published_date": "2025-08-20 18:56:26 UTC",
      "updated_date": "2026-01-07 11:09:58 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:57:49.630792+00:00"
    },
    {
      "arxiv_id": "2510.01189v1",
      "title": "An Anthropologist LLM to Elicit Users' Moral Preferences through Role-Play",
      "title_zh": "åŸºäºè§’è‰²æ‰®æ¼”æ¢ç©¶ç”¨æˆ·é“å¾·åå¥½çš„äººç±»å­¦å®¶å¤§è¯­è¨€æ¨¡å‹",
      "authors": [
        "Gianluca De Ninno",
        "Paola Inverardi",
        "Francesca Belotti"
      ],
      "abstract": "This study investigates a novel approach to eliciting users' moral decision-making by combining immersive roleplaying games with LLM analysis capabilities. Building on the distinction introduced by Floridi between hard ethics inspiring and shaping laws-and soft ethics-moral preferences guiding individual behavior within the free space of decisions compliant to laws-we focus on capturing the latter through contextrich, narrative-driven interactions. Grounded in anthropological methods, the role-playing game exposes participants to ethically charged scenarios in the domain of digital privacy. Data collected during the sessions were interpreted by a customized LLM (\"GPT Anthropologist\"). Evaluation through a cross-validation process shows that both the richness of the data and the interpretive framing significantly enhance the model's ability to predict user behavior. Results show that LLMs can be effectively employed to automate and enhance the understanding of user moral preferences and decision-making process in the early stages of software development.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†ä¸€ç§ç»“åˆæ²‰æµ¸å¼è§’è‰²æ‰®æ¼”æ¸¸æˆ(Role-Playing Games)ä¸å¤§è¯­è¨€æ¨¡å‹(LLM)åˆ†æèƒ½åŠ›çš„åˆ›æ–°æ–¹æ³•ï¼Œæ—¨åœ¨å¼•å‡ºç”¨æˆ·çš„é“å¾·å†³ç­–åå¥½ã€‚ç ”ç©¶èšç„¦äºFloridiæå‡ºçš„â€œè½¯ä¼¦ç†â€(Soft Ethics)æ¦‚å¿µï¼Œå³åœ¨æ³•å¾‹åˆè§„ç©ºé—´å†…å¼•å¯¼ä¸ªäººè¡Œä¸ºçš„é“å¾·å–å‘ã€‚å®éªŒåŸºäºäººç±»å­¦æ–¹æ³•(Anthropological Methods)ï¼Œé€šè¿‡å™äº‹é©±åŠ¨çš„æƒ…æ™¯è®©å‚ä¸è€…åœ¨æ•°å­—éšç§é¢†åŸŸè¿›è¡Œé“å¾·æŠ‰æ‹©ã€‚ç ”ç©¶é‡‡ç”¨å®šåˆ¶çš„â€œGPT Anthropologistâ€æ¨¡å‹å¯¹äº¤äº’æ•°æ®è¿›è¡Œè§£æï¼Œå¹¶åˆ©ç”¨äº¤å‰éªŒè¯è¿‡ç¨‹è¿›è¡Œè¯„ä¼°ã€‚ç»“æœæ˜¾ç¤ºï¼Œæ•°æ®çš„ä¸°å¯Œç¨‹åº¦ä»¥åŠç‰¹å®šçš„è§£é‡Šæ€§æ¡†æ¶æ˜¾è‘—æå‡äº†æ¨¡å‹é¢„æµ‹ç”¨æˆ·è¡Œä¸ºçš„èƒ½åŠ›ã€‚æœ€ç»ˆè¯æ˜ï¼ŒLLMèƒ½å¤Ÿåœ¨è½¯ä»¶å¼€å‘æ—©æœŸé˜¶æ®µæœ‰æ•ˆå®ç°ç”¨æˆ·é“å¾·åå¥½è¯†åˆ«çš„è‡ªåŠ¨åŒ–ï¼Œå¹¶å¢å¼ºå¯¹å¤æ‚å†³ç­–è¿‡ç¨‹çš„ç†è§£ã€‚",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.01189v1",
      "published_date": "2025-08-20 18:08:40 UTC",
      "updated_date": "2025-08-20 18:08:40 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:57:55.917860+00:00"
    },
    {
      "arxiv_id": "2508.14896v2",
      "title": "Quantization Meets dLLMs: A Systematic Study of Post-training Quantization for Diffusion LLMs",
      "title_zh": "é‡åŒ–é‡è§ dLLMsï¼šæ‰©æ•£å¤§è¯­è¨€æ¨¡å‹è®­ç»ƒåé‡åŒ–çš„ç³»ç»Ÿæ€§ç ”ç©¶",
      "authors": [
        "Haokun Lin",
        "Haobo Xu",
        "Yichen Wu",
        "Ziyu Guo",
        "Renrui Zhang",
        "Zhichao Lu",
        "Ying Wei",
        "Qingfu Zhang",
        "Zhenan Sun"
      ],
      "abstract": "Recent advances in diffusion large language models (dLLMs) have introduced a promising alternative to autoregressive (AR) LLMs for natural language generation tasks, leveraging full attention and denoising-based decoding strategies. However, the deployment of these models on edge devices remains challenging due to their massive parameter scale and high resource demands. While post-training quantization (PTQ) has emerged as a widely adopted technique for compressing AR LLMs, its applicability to dLLMs remains largely unexplored. In this work, we present the first systematic study on quantizing diffusion-based language models. We begin by identifying the presence of activation outliers, characterized by abnormally large activation values that dominate the dynamic range. These outliers pose a key challenge to low-bit quantization, as they make it difficult to preserve precision for the majority of values. More importantly, we implement state-of-the-art PTQ methods and conduct a comprehensive evaluation across multiple task types and model variants. Our analysis is structured along four key dimensions: bit-width, quantization method, task category, and model type. Through this multi-perspective evaluation, we offer practical insights into the quantization behavior of dLLMs under different configurations. We hope our findings provide a foundation for future research in efficient dLLM deployment. Our code is publicly available at https://github.com/FelixMessi/QDLM.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹æ‰©æ•£å¤§è¯­è¨€æ¨¡å‹(dLLMs)åœ¨è¾¹ç¼˜è®¾å¤‡éƒ¨ç½²å›°éš¾çš„é—®é¢˜ï¼Œé¦–æ¬¡å¼€å±•äº†å…³äºdLLMsè®­ç»ƒåé‡åŒ–(PTQ)çš„ç³»ç»Ÿæ€§ç ”ç©¶ã€‚ä½œè€…é€šè¿‡åˆ†æå‘ç°ï¼ŒdLLMsä¸­å­˜åœ¨æ˜¾è‘—çš„æ¿€æ´»ç¦»ç¾¤å€¼(activation outliers)ï¼Œè¿™äº›å¼‚å¸¸å¤§çš„æ¿€æ´»å€¼å æ®äº†ä¸»å¯¼åŠ¨æ€èŒƒå›´ï¼Œæˆä¸ºä½æ¯”ç‰¹(low-bit)é‡åŒ–çš„æ ¸å¿ƒæŒ‘æˆ˜ã€‚ç ”ç©¶å›¢é˜Ÿå®ç°äº†å¤šç§å‰æ²¿çš„PTQæ–¹æ³•ï¼Œå¹¶ä»ä½å®½(bit-width)ã€é‡åŒ–æ–¹æ³•ã€ä»»åŠ¡ç±»åˆ«åŠæ¨¡å‹ç±»å‹å››ä¸ªç»´åº¦è¿›è¡Œäº†å…¨é¢è¯„ä¼°ã€‚è¯¥å·¥ä½œä¸ä»…æ­ç¤ºäº†dLLMsåœ¨ä¸åŒé…ç½®ä¸‹çš„é‡åŒ–è¡Œä¸ºï¼Œè¿˜ä¸ºæœªæ¥å®ç°é«˜æ•ˆçš„dLLMéƒ¨ç½²æä¾›äº†é‡è¦çš„å®è·µæŒ‡å¯¼ä¸å®éªŒåŸºç¡€ã€‚ç›®å‰è¯¥ç ”ç©¶çš„ç›¸å…³ä»£ç å·²åœ¨GitHubå¼€æºï¼Œæ—¨åœ¨æ¨åŠ¨é«˜æ•ˆæ‰©æ•£è¯­è¨€æ¨¡å‹çš„ç ”ç©¶ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Technical Report, Work in Progress",
      "pdf_url": "https://arxiv.org/pdf/2508.14896v2",
      "published_date": "2025-08-20 17:59:51 UTC",
      "updated_date": "2025-10-15 17:59:06 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:58:39.125170+00:00"
    },
    {
      "arxiv_id": "2508.14958v1",
      "title": "Fast Graph Neural Network for Image Classification",
      "title_zh": "é¢å‘å›¾åƒåˆ†ç±»çš„å¿«é€Ÿå›¾ç¥ç»ç½‘ç»œ",
      "authors": [
        "Mustafa Mohammadi Gharasuie",
        "Luis Rueda"
      ],
      "abstract": "The rapid progress in image classification has been largely driven by the adoption of Graph Convolutional Networks (GCNs), which offer a robust framework for handling complex data structures. This study introduces a novel approach that integrates GCNs with Voronoi diagrams to enhance image classification by leveraging their ability to effectively model relational data. Unlike conventional convolutional neural networks (CNNs), our method represents images as graphs, where pixels or regions function as vertices. These graphs are then refined using corresponding Delaunay triangulations, optimizing their representation. The proposed model achieves significant improvements in both preprocessing efficiency and classification accuracy across various benchmark datasets, surpassing state-of-the-art approaches, particularly in challenging scenarios involving intricate scenes and fine-grained categories. Experimental results, validated through cross-validation, underscore the effectiveness of combining GCNs with Voronoi diagrams for advancing image classification. This research not only presents a novel perspective on image classification but also expands the potential applications of graph-based learning paradigms in computer vision and unstructured data analysis.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§ç»“åˆå›¾å·ç§¯ç½‘ç»œ(Graph Convolutional Networks, GCNs)ä¸Voronoi diagramsçš„æ–°å‹å›¾åƒåˆ†ç±»æ–¹æ³•ï¼Œæ—¨åœ¨é€šè¿‡å…³ç³»å»ºæ¨¡æå‡å¯¹å¤æ‚æ•°æ®ç»“æ„çš„å¤„ç†èƒ½åŠ›ã€‚ä¸ä¼ ç»Ÿçš„å·ç§¯ç¥ç»ç½‘ç»œ(CNNs)ä¸åŒï¼Œè¯¥æ–¹æ³•å°†å›¾åƒè½¬åŒ–ä¸ºä»¥åƒç´ æˆ–åŒºåŸŸä¸ºé¡¶ç‚¹çš„å›¾ç»“æ„ï¼Œå¹¶åˆ©ç”¨Delaunay triangulationså¯¹å›¾è¡¨ç¤ºè¿›è¡Œä¼˜åŒ–ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ¨¡å‹åœ¨å¤šä¸ªåŸºå‡†æ•°æ®é›†ä¸Šçš„é¢„å¤„ç†æ•ˆç‡å’Œåˆ†ç±»å‡†ç¡®ç‡å‡æ˜¾è‘—ä¼˜äºç°æœ‰çš„State-of-the-artæ–¹æ³•ï¼Œå°¤å…¶åœ¨å¤æ‚åœºæ™¯å’Œç»†ç²’åº¦åˆ†ç±»ä»»åŠ¡ä¸­è¡¨ç°å‡ºè‰²ã€‚é€šè¿‡cross-validationçš„ä¸¥è°¨éªŒè¯ï¼Œè¯¥ç ”ç©¶ä¸ä»…å±•ç¤ºäº†GCNsä¸Voronoi diagramsç»“åˆçš„ä¼˜è¶Šæ€§ï¼Œä¹Ÿä¸ºè®¡ç®—æœºè§†è§‰é¢†åŸŸçš„å›¾å­¦ä¹ èŒƒå¼(graph-based learning paradigms)æä¾›äº†æ–°çš„è§†è§’ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "12 pages, proceeding into CanadianAI 2025",
      "pdf_url": "https://arxiv.org/pdf/2508.14958v1",
      "published_date": "2025-08-20 17:57:59 UTC",
      "updated_date": "2025-08-20 17:57:59 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:58:25.928118+00:00"
    },
    {
      "arxiv_id": "2508.14859v1",
      "title": "Graph Structure Learning with Temporal Graph Information Bottleneck for Inductive Representation Learning",
      "title_zh": "é¢å‘å½’çº³å¼è¡¨ç¤ºå­¦ä¹ çš„ã€ç»“åˆæ—¶åºå›¾ä¿¡æ¯ç“¶é¢ˆçš„å›¾ç»“æ„å­¦ä¹ ",
      "authors": [
        "Jiafeng Xiong",
        "Rizos Sakellariou"
      ],
      "abstract": "Temporal graph learning is crucial for dynamic networks where nodes and edges evolve over time and new nodes continuously join the system. Inductive representation learning in such settings faces two major challenges: effectively representing unseen nodes and mitigating noisy or redundant graph information. We propose GTGIB, a versatile framework that integrates Graph Structure Learning (GSL) with Temporal Graph Information Bottleneck (TGIB). We design a novel two-step GSL-based structural enhancer to enrich and optimize node neighborhoods and demonstrate its effectiveness and efficiency through theoretical proofs and experiments. The TGIB refines the optimized graph by extending the information bottleneck principle to temporal graphs, regularizing both edges and features based on our derived tractable TGIB objective function via variational approximation, enabling stable and efficient optimization. GTGIB-based models are evaluated to predict links on four real-world datasets; they outperform existing methods in all datasets under the inductive setting, with significant and consistent improvement in the transductive setting.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† GTGIB æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³åŠ¨æ€ç½‘ç»œä¸­å½’çº³è¡¨ç¤ºå­¦ä¹ ï¼ˆInductive Representation Learningï¼‰é¢ä¸´çš„æ–°èŠ‚ç‚¹è¡¨å¾å’Œå†—ä½™å™ªå£°å¹²æ‰°è¿™ä¸¤å¤§æŒ‘æˆ˜ã€‚è¯¥æ¡†æ¶åˆ›æ–°æ€§åœ°æ•´åˆäº†å›¾ç»“æ„å­¦ä¹ ï¼ˆGraph Structure Learning, GSLï¼‰ä¸æ—¶åºå›¾ä¿¡æ¯ç“¶é¢ˆï¼ˆTemporal Graph Information Bottleneck, TGIBï¼‰æŠ€æœ¯ã€‚ç ”ç©¶è®¾è®¡äº†ä¸€ç§åŸºäº GSL çš„ä¸¤æ­¥ç»“æ„å¢å¼ºå™¨ç”¨äºä¼˜åŒ–èŠ‚ç‚¹é‚»åŸŸï¼Œå¹¶æä¾›äº†ä¸¥å¯†çš„ç†è®ºè¯æ˜ã€‚æ­¤å¤–ï¼ŒTGIB é€šè¿‡å˜åˆ†è¿‘ä¼¼æ¨å¯¼å‡ºå¯å¤„ç†çš„ç›®æ ‡å‡½æ•°ï¼Œå°†ä¿¡æ¯ç“¶é¢ˆåŸåˆ™åº”ç”¨äºæ—¶åºå›¾çš„è¾¹ä¸ç‰¹å¾æ­£åˆ™åŒ–ï¼Œç¡®ä¿äº†ä¼˜åŒ–çš„ç¨³å®šæ€§ã€‚å®éªŒè¡¨æ˜ï¼ŒåŸºäº GTGIB çš„æ¨¡å‹åœ¨å››ä¸ªçœŸå®æ•°æ®é›†çš„é“¾è·¯é¢„æµ‹ä»»åŠ¡ä¸­ï¼Œå…¶å½’çº³å­¦ä¹ æ€§èƒ½å‡è¶…è¶Šäº†ç°æœ‰æ–¹æ³•ï¼Œå¹¶åœ¨è½¬å¯¼ï¼ˆTransductiveï¼‰è®¾ç½®ä¸‹å–å¾—äº†æ˜¾è‘—æå‡ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted in the 28th European Conference on Artificial Intelligence (ECAI), 2025",
      "pdf_url": "https://arxiv.org/pdf/2508.14859v1",
      "published_date": "2025-08-20 17:13:19 UTC",
      "updated_date": "2025-08-20 17:13:19 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:58:27.520090+00:00"
    },
    {
      "arxiv_id": "2508.16660v1",
      "title": "Optimizing Hyper parameters in CNN for Soil Classification using PSO and Whale Optimization Algorithm",
      "title_zh": "åŸºäºç²’å­ç¾¤ä¸é²¸é±¼ä¼˜åŒ–ç®—æ³•çš„å·ç§¯ç¥ç»ç½‘ç»œåœŸå£¤åˆ†ç±»è¶…å‚æ•°ä¼˜åŒ–",
      "authors": [
        "Yasir Nooruldeen Ibrahim",
        "Fawziya Mahmood Ramo",
        "Mahmood Siddeeq Qadir",
        "Muna Jaffer Al-Shamdeen"
      ],
      "abstract": "Classifying soil images contributes to better land management, increased agricultural output, and practical solutions for environmental issues. The development of various disciplines, particularly agriculture, civil engineering, and natural resource management, is aided by understanding of soil quality since it helps with risk reduction, performance improvement, and sound decision-making . Artificial intelligence has recently been used in a number of different fields. In this study, an intelligent model was constructed using Convolutional Neural Networks to classify soil kinds, and machine learning algorithms were used to enhance the performance of soil classification . To achieve better implementation and performance of the Convolutional Neural Networks algorithm and obtain valuable results for the process of classifying soil type images, swarm algorithms were employed to obtain the best performance by choosing Hyper parameters for the Convolutional Neural Networks network using the Whale optimization algorithm and the Particle swarm optimization algorithm, and comparing the results of using the two algorithms in the process of multiple classification of soil types. The Accuracy and F1 measures were adopted to test the system, and the results of the proposed work were efficient result",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹åœŸå£¤åˆ†ç±»åœ¨å†œä¸šå’ŒåœŸåœ°ç®¡ç†ä¸­çš„é‡è¦æ€§ï¼Œæå‡ºäº†ä¸€ç§åŸºäºå·ç§¯ç¥ç»ç½‘ç»œ (Convolutional Neural Networks, CNN) çš„æ™ºèƒ½åˆ†ç±»æ¨¡å‹ã€‚ä¸ºäº†è¿›ä¸€æ­¥æå‡æ¨¡å‹åœ¨åœŸå£¤å›¾åƒåˆ†ç±»ä»»åŠ¡ä¸­çš„è¡¨ç°ï¼Œç ”ç©¶å¼•å…¥äº†ç¾¤æ™ºç®—æ³•å¯¹ CNN çš„è¶…å‚æ•° (Hyper parameters) è¿›è¡Œä¼˜åŒ–ã€‚é€šè¿‡å¯¹æ¯”é²¸é±¼ä¼˜åŒ–ç®—æ³• (Whale Optimization Algorithm) å’Œç²’å­ç¾¤ä¼˜åŒ–ç®—æ³• (Particle Swarm Optimization, PSO) çš„æ€§èƒ½ï¼Œç³»ç»Ÿæ€§åœ°æ¢ç´¢äº†ä¸åŒä¼˜åŒ–ç­–ç•¥åœ¨å¤šç±»åˆ«åœŸå£¤åˆ†ç±»ä¸­çš„åº”ç”¨æ•ˆæœã€‚å®éªŒé‡‡ç”¨å‡†ç¡®ç‡ (Accuracy) å’Œ F1 å€¼ (F1 measures) ä½œä¸ºè¯„ä¼°æŒ‡æ ‡ï¼Œç»“æœè¯æ˜æ‰€æå‡ºçš„ä¼˜åŒ–æ¨¡å‹èƒ½å¤Ÿæ˜¾è‘—æé«˜åœŸå£¤è¯†åˆ«çš„æ•ˆç‡ä¸ç²¾åº¦ï¼Œä¸ºå†œä¸šç”Ÿäº§ã€åœŸæœ¨å·¥ç¨‹åŠè‡ªç„¶èµ„æºç®¡ç†æä¾›äº†ç§‘å­¦çš„è¾…åŠ©å†³ç­–æ”¯æŒã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "15 pages",
      "pdf_url": "https://arxiv.org/pdf/2508.16660v1",
      "published_date": "2025-08-20 16:30:19 UTC",
      "updated_date": "2025-08-20 16:30:19 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:58:38.031928+00:00"
    },
    {
      "arxiv_id": "2508.14831v4",
      "title": "$\\mathrm{TIME}[t]\\subseteq \\mathrm{SPACE}[O(\\sqrt{t})]$ via Tree Height Compression",
      "title_zh": "é€šè¿‡æ ‘é«˜å‹ç¼©å®ç° $\\mathrm{TIME}[t]\\subseteq \\mathrm{SPACE}[O(\\sqrt{t})]$",
      "authors": [
        "Logan Nye"
      ],
      "abstract": "We prove a square-root space simulation for deterministic multitape Turing machines, showing $\\mathrm{TIME}[t]\\subseteq \\mathrm{SPACE}[O(\\sqrt{t})]$ \\emph{measured in tape cells over a fixed finite alphabet}. The key step is a Height Compression Theorem that uniformly (and in logspace) reshapes the canonical left-deep succinct computation tree for a block-respecting run into a binary tree whose evaluation-stack depth along any DFS path is $O(\\log T)$ for $T=\\lceil t/b\\rceil$, while preserving $O(b)$ workspace at leaves and $O(1)$ at internal nodes. Edges have \\emph{addressing/topology} checkable in $O(\\log t)$ space, and \\emph{semantic} correctness across merges is witnessed by an exact $O(b)$ bounded-window replay at the unique interface. Algorithmically, an Algebraic Replay Engine with constant-degree maps over a constant-size field, together with pointerless DFS, index-free streaming, and a \\emph{rolling boundary buffer that prevents accumulation of leaf summaries}, ensures constant-size per-level tokens and eliminates wide counters, yielding the additive tradeoff $S(b)=O(b+t/b)$. Choosing $b=Î˜(\\sqrt{t})$ gives $O(\\sqrt{t})$ space with no residual multiplicative polylog factors. The construction is uniform, relativizes, and is robust to standard model choices. Consequences include branching-program upper bounds $2^{O(\\sqrt{s})}$ for size-$s$ bounded-fan-in circuits, tightened quadratic-time lower bounds for $\\mathrm{SPACE}[n]$-complete problems via the standard hierarchy argument, and $O(\\sqrt{t})$-space certifying interpreters; under explicit locality assumptions, the framework extends to geometric $d$-dimensional models. Conceptually, the work isolates path bookkeeping as the chief obstruction to $O(\\sqrt{t})$ and removes it via structural height compression with per-path analysis rather than barrier-prone techniques.",
      "tldr_zh": "è¯¥ç ”ç©¶è¯æ˜äº†ç¡®å®šæ€§å¤šå¸¦å›¾çµæœºï¼ˆmultitape Turing machinesï¼‰çš„å¹³æ–¹æ ¹ç©ºé—´æ¨¡æ‹Ÿï¼Œå³åœ¨å›ºå®šæœ‰é™å­—æ¯è¡¨ä¸‹å®ç°äº† $\\mathrm{TIME}[t]\\subseteq \\mathrm{SPACE}[O(\\sqrt{t})]$ã€‚æ ¸å¿ƒè´¡çŒ®æ˜¯é«˜åº¦å‹ç¼©å®šç†ï¼ˆHeight Compression Theoremï¼‰ï¼Œé€šè¿‡å°†å—å°Šé‡è¿è¡Œï¼ˆblock-respecting runï¼‰çš„å·¦æ·±è®¡ç®—æ ‘é‡æ„ä¸ºæ·±åº¦ä»…ä¸º $O(\\log T)$ çš„äºŒå‰æ ‘ï¼Œæå¤§åœ°ä¼˜åŒ–äº† DFS æœç´¢è¿‡ç¨‹ä¸­çš„å †æ ˆç©ºé—´ã€‚ç®—æ³•ä¸Šç»“åˆäº†ä»£æ•°é‡æ”¾å¼•æ“ï¼ˆAlgebraic Replay Engineï¼‰å’Œæ»šåŠ¨è¾¹ç•Œç¼“å†²åŒºï¼ˆrolling boundary bufferï¼‰ï¼Œç¡®ä¿äº†æ¯å±‚ä»¤ç‰Œä¸ºå¸¸æ•°å¤§å°å¹¶æ¶ˆé™¤äº†å®½è®¡æ•°å™¨çš„å¼€é”€ã€‚é€šè¿‡é€‰å–ç‰¹å®šçš„å—å¤§å°ï¼Œè¯¥æ–¹æ³•æˆåŠŸå®ç°äº† $O(\\sqrt{t})$ çš„ç©ºé—´ç•Œé™ï¼Œä¸”ä¸å«ä»»ä½•æ®‹ç•™çš„ä¹˜æ€§å¤šå¯¹æ•°ï¼ˆpolylogï¼‰å› å­ã€‚è¯¥æˆæœè¿˜å¸¦æ¥äº†åˆ†æ”¯ç¨‹åºï¼ˆbranching-programï¼‰ä¸Šç•Œä¼˜åŒ–å’ŒäºŒæ¬¡æ—¶é—´ä¸‹ç•Œæ”¶ç´§ç­‰ä¸€ç³»åˆ—ç†è®ºæ¨è®ºã€‚åœ¨æ¦‚å¿µå±‚é¢ï¼Œè¯¥å·¥ä½œæˆåŠŸè¯†åˆ«å¹¶åˆ©ç”¨ç»“æ„åŒ–é«˜åº¦å‹ç¼©è§£å†³äº†è·¯å¾„ç°¿è®°ï¼ˆpath bookkeepingï¼‰è¿™ä¸€é•¿æœŸéšœç¢ï¼Œä¸ºç©ºé—´å¤æ‚åº¦æ¨¡æ‹Ÿæä¾›äº†ç¨³å¥ä¸”å¯æ¨å¹¿çš„æ–°æ¡†æ¶ã€‚",
      "categories": [
        "cs.CC",
        "cs.AI",
        "cs.DS"
      ],
      "primary_category": "cs.CC",
      "comment": "The proof of the main theorem is incorrect. In Sections 2-4, the paper's height-compression/evaluation framework assumes an interval-based associative summary tree that does not correctly model the Tree Evaluation instances/dependencies arising in Williams's simulation",
      "pdf_url": "https://arxiv.org/pdf/2508.14831v4",
      "published_date": "2025-08-20 16:27:53 UTC",
      "updated_date": "2026-01-01 21:58:55 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:58:41.230656+00:00"
    },
    {
      "arxiv_id": "2508.14828v2",
      "title": "Long Chain-of-Thought Reasoning Across Languages",
      "title_zh": "è·¨è¯­è¨€é•¿æ€ç»´é“¾æ¨ç†",
      "authors": [
        "Josh Barua",
        "Seun Eisape",
        "Kayo Yin",
        "Alane Suhr"
      ],
      "abstract": "While large reasoning models have shown remarkable ability to generate long chains-of-thought (CoTs) in English, we still lack understanding of how these long-form reasoning abilities transfer to the vast majority of the world's languages. In this work, we systematically investigate four key stages of model development--scaling, pretraining, post-training, and inference--to understand how long CoT capabilities extend beyond English. We compare two reasoning settings across nine non-English target languages: En-CoT, where models process target-language inputs, but reason in English; and Target-CoT, where models both process inputs and generate long CoTs in the target language. We find that scaling reasoning model size improves multilingual task performance in En-CoT, but Target-CoT performance lags behind. This gap widens for tasks requiring long, multi-step CoTs such as mathematical reasoning. Shifting to pretraining, we find that adding a specialized reasoning stage enhances En-CoT performance but degrades Target-CoT, whereas broad multilingual pretraining improves both modes simultaneously. Given the scarcity of high-quality reasoning traces in languages other than English, we explore synthetic data curation approaches for post-training. We demonstrate that fine-tuning on reasoning traces automatically translated from gold English traces outperforms fine-tuning on target-language traces distilled from large reasoning models. Finally, we report disparities in inference efficiency between languages and uncover language-specific failure modes in CoTs. We release models, datasets, and code to foster further research.",
      "tldr_zh": "è¯¥ç ”ç©¶ç³»ç»Ÿåœ°æ¢è®¨äº†å¤§å‹æ¨ç†æ¨¡å‹åœ¨å¤„ç†éè‹±è¯­è¯­è¨€æ—¶ï¼Œå…¶é•¿é“¾å¼æ€ç»´ (Chain-of-Thought) èƒ½åŠ›çš„è¿ç§»ä¸è¡¨ç°ã€‚ç ”ç©¶è€…é€šè¿‡è§„æ¨¡æ‰©å±•ã€é¢„è®­ç»ƒã€åæœŸè®­ç»ƒå’Œæ¨ç†å››ä¸ªå…³é”®é˜¶æ®µï¼Œå¯¹æ¯”äº†ä½¿ç”¨è‹±è¯­æ¨ç† (En-CoT) ä¸ç›®æ ‡è¯­è¨€æ¨ç† (Target-CoT) åœ¨ä¹ç§éè‹±è¯­è¯­è¨€ä¸‹çš„æ•ˆæœã€‚å®éªŒå‘ç°ï¼Œæ¨¡å‹è§„æ¨¡çš„æå‡ä¸»è¦ä¼˜åŒ–äº† En-CoT çš„è¡¨ç°ï¼Œè€Œ Target-CoT åœ¨å¤šæ­¥æ•°å­¦æ¨ç†ä»»åŠ¡ä¸­è¡¨ç°æ»åã€‚åœ¨é¢„è®­ç»ƒç­–ç•¥ä¸Šï¼Œå¹¿æ³›çš„å¤šè¯­è¨€é¢„è®­ç»ƒèƒ½åŒæ—¶æå‡ä¸¤ç§æ¨¡å¼ï¼Œä½†ä¸“é—¨çš„æ¨ç†é˜¶æ®µåè€Œä¼šæŸå®³ Target-CoT çš„æ€§èƒ½ã€‚é’ˆå¯¹é«˜è´¨é‡æ¨ç†æ•°æ®ç¨€ç¼ºçš„é—®é¢˜ï¼Œç ”ç©¶è¯æ˜åˆ©ç”¨ç¿»è¯‘åçš„è‹±è¯­æ¨ç†è½¨è¿¹è¿›è¡Œå¾®è°ƒï¼Œå…¶æ•ˆæœä¼˜äºç›´æ¥ä»å¤§æ¨¡å‹è’¸é¦å‡ºçš„ç›®æ ‡è¯­è¨€æ•°æ®ã€‚æœ€åï¼Œè¯¥ç ”ç©¶æ­ç¤ºäº†ä¸åŒè¯­è¨€é—´æ¨ç†æ•ˆç‡çš„ä¸å¹³ç­‰ä»¥åŠç‰¹å®šçš„è¯­è¨€å¤±æ•ˆæ¨¡å¼ï¼Œå¹¶å¼€æºäº†ç›¸å…³æ¨¡å‹ä¸æ•°æ®é›†ä»¥ä¿ƒè¿›åç»­ç ”ç©¶ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "v1 is a workshop version accepted to SCALR @ COLM 2025",
      "pdf_url": "https://arxiv.org/pdf/2508.14828v2",
      "published_date": "2025-08-20 16:22:51 UTC",
      "updated_date": "2025-10-09 05:36:20 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:58:44.324487+00:00"
    },
    {
      "arxiv_id": "2508.19264v1",
      "title": "A Theory of Information, Variation, and Artificial Intelligence",
      "title_zh": "ä¿¡æ¯ã€å˜å¼‚ä¸äººå·¥æ™ºèƒ½ç†è®º",
      "authors": [
        "Bijean Ghafouri"
      ],
      "abstract": "A growing body of empirical work suggests that the widespread adoption of generative AI produces a significant homogenizing effect on information, creativity, and cultural production. I first develop a novel theoretical framework to explain this phenomenon. I argue that a dynamic of AI-derivative epistemology, in which individuals increasingly defer to AI outputs, allows a centralized AI Prism to function, a technical mechanism whose architecture is designed to reduce variance and converge on the statistical mean. This provides a causal explanation for the generative monocultures observed in recent studies. However, I contend this represents only the first stage of a more complex and dialectical process. This paper's central and paradoxical thesis is that the very homogenization that flattens knowledge within specialized domains simultaneously renders that knowledge into consistent modules that can be recombined across them, a process foundational to innovation and creativity. However, this recombinant potential is not automatic, but rather conditional. This paper argues that these opposing forces, homogenizing defaults versus recombinant possibilities, are governed by the nature of human engagement with the technology. The ultimate effect of generative AI is conditional on whether individuals act as passive consumers deferring to the AI's statistical outputs, or as active curators who critically interrogate, re-contextualize, and recombine them. The paper concludes by outlining the cognitive and institutional scaffolds required to resolve this tension, arguing they are the decisive variable that determine whether generative AI becomes an instrument of innovation or homogenization.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†ç”Ÿæˆå¼ AI å¯¹ä¿¡æ¯ã€åˆ›é€ åŠ›å’Œæ–‡åŒ–ç”Ÿäº§æ˜¾è‘—çš„åŒè´¨åŒ–å½±å“ï¼Œå¹¶ä¸ºæ­¤æ„å»ºäº†ä¸€ä¸ªå…¨æ–°çš„ç†è®ºæ¡†æ¶ã€‚ä½œè€…æå‡ºäº† AI-derivative epistemologyï¼ˆAIè¡ç”Ÿè®¤è¯†è®ºï¼‰çš„æ¦‚å¿µï¼ŒæŒ‡å‡ºä¸ªä½“å¯¹ AI è¾“å‡ºçš„ä¾èµ–ä¿ƒä½¿ä¸€ç§åä¸º AI Prism çš„æŠ€æœ¯æœºåˆ¶å‘æŒ¥ä½œç”¨ï¼Œå…¶æ¶æ„è®¾è®¡æ—¨åœ¨å‡å°‘å˜å¼‚å¹¶è¶‹å‘ç»Ÿè®¡å¹³å‡å€¼ï¼Œä»è€Œå¯¼è‡´äº† generative monoculturesï¼ˆç”Ÿæˆå¼å•ä¸€æ–‡åŒ–ï¼‰ã€‚è®ºæ–‡çš„æ ¸å¿ƒæ‚–è®ºåœ¨äºï¼Œè¿™ç§ä½¿çŸ¥è¯†æ‰å¹³åŒ–çš„åŒè´¨åŒ–è¿‡ç¨‹ï¼ŒåŒæ—¶ä¹Ÿåˆ©ç”¨ä¸€è‡´çš„æ¨¡å—åŒ–çŸ¥è¯†ä¸ºè·¨é¢†åŸŸé‡ç»„æä¾›äº†åŸºç¡€ï¼Œè€Œé‡ç»„æ­£æ˜¯åˆ›æ–°å’Œ creativity çš„æ ¸å¿ƒã€‚è¿™ç§æ½œåŠ›çš„å®ç°å–å†³äºäººç±»çš„å‚ä¸æ€§è´¨ï¼Œå³ä½¿ç”¨è€…æ˜¯ä½œä¸ºè¢«åŠ¨æ¶ˆè´¹è€…é¡ºä»ç»Ÿè®¡è¾“å‡ºï¼Œè¿˜æ˜¯ä½œä¸ºä¸»åŠ¨ç­–åˆ’è€…å¯¹å…¶è¿›è¡Œæ‰¹åˆ¤æ€§å®¡è§†ã€é‡æ–°è¯­å¢ƒåŒ–å’Œé‡ç»„ã€‚æœ€åï¼Œç ”ç©¶å¼ºè°ƒè®¤çŸ¥å’Œåˆ¶åº¦æ”¯æ¶æ˜¯å†³å®šç”Ÿæˆå¼ AI æœ€ç»ˆæˆä¸ºåˆ›æ–°å·¥å…·è¿˜æ˜¯åŒè´¨åŒ–å·¥å…·çš„å…³é”®å˜é‡ã€‚",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.IT"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.19264v1",
      "published_date": "2025-08-20 16:21:13 UTC",
      "updated_date": "2025-08-20 16:21:13 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:58:42.220575+00:00"
    },
    {
      "arxiv_id": "2508.14825v1",
      "title": "From Passive Tool to Socio-cognitive Teammate: A Conceptual Framework for Agentic AI in Human-AI Collaborative Learning",
      "title_zh": "ä»è¢«åŠ¨å·¥å…·åˆ°ç¤¾ä¼šè®¤çŸ¥é˜Ÿå‹ï¼šäººæœºåä½œå­¦ä¹ ä¸­ä»£ç†å¼äººå·¥æ™ºèƒ½çš„æ¦‚å¿µæ¡†æ¶",
      "authors": [
        "Lixiang Yan"
      ],
      "abstract": "The role of Artificial Intelligence (AI) in education is undergoing a rapid transformation, moving beyond its historical function as an instructional tool towards a new potential as an active participant in the learning process. This shift is driven by the emergence of agentic AI, autonomous systems capable of proactive, goal-directed action. However, the field lacks a robust conceptual framework to understand, design, and evaluate this new paradigm of human-AI interaction in learning. This paper addresses this gap by proposing a novel conceptual framework (the APCP framework) that charts the transition from AI as a tool to AI as a collaborative partner. We present a four-level model of escalating AI agency within human-AI collaborative learning: (1) the AI as an Adaptive Instrument, (2) the AI as a Proactive Assistant, (3) the AI as a Co-Learner, and (4) the AI as a Peer Collaborator. Grounded in sociocultural theories of learning and Computer-Supported Collaborative Learning (CSCL), this framework provides a structured vocabulary for analysing the shifting roles and responsibilities between human and AI agents. The paper further engages in a critical discussion of the philosophical underpinnings of collaboration, examining whether an AI, lacking genuine consciousness or shared intentionality, can be considered a true collaborator. We conclude that while AI may not achieve authentic phenomenological partnership, it can be designed as a highly effective functional collaborator. This distinction has significant implications for pedagogy, instructional design, and the future research agenda for AI in education, urging a shift in focus towards creating learning environments that harness the complementary strengths of both human and AI.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†äººå·¥æ™ºèƒ½(AI)åœ¨æ•™è‚²é¢†åŸŸä»ä¼ ç»Ÿæ•™å­¦å·¥å…·å‘ä¸»åŠ¨å‚ä¸è€…çš„è½¬å˜ï¼Œå¹¶æå‡ºäº†åä¸ºAPCPçš„æ–°å‹æ¦‚å¿µæ¡†æ¶ã€‚è¯¥æ¡†æ¶æ—¨åœ¨ç†è§£ã€è®¾è®¡å’Œè¯„ä¼°äººç±»ä¸Agentic AIåœ¨åä½œå­¦ä¹ ä¸­çš„äº’åŠ¨æ¨¡å¼ï¼Œå°†å…¶æ¼”è¿›åˆ’åˆ†ä¸ºAdaptive Instrumentã€Proactive Assistantã€Co-Learnerä»¥åŠPeer Collaboratorå››ä¸ªé€’è¿›çš„ä»£ç†çº§åˆ«ã€‚ç ”ç©¶åŸºäºç¤¾ä¼šæ–‡åŒ–å­¦ä¹ ç†è®ºå’Œè®¡ç®—æœºæ”¯æŒçš„åä½œå­¦ä¹ (CSCL)ï¼Œä¸ºåˆ†æäººæœºåä½œä¸­ä¸æ–­å˜åŒ–çš„è§’è‰²ä¸è´£ä»»æä¾›äº†ç»“æ„åŒ–è¯æ±‡ã€‚æ–‡ç« è¿˜æ·±å…¥æ¢è®¨äº†ç¼ºä¹çœŸå®æ„è¯†çš„AIæ˜¯å¦èƒ½æˆä¸ºçœŸæ­£åä½œè€…çš„å“²å­¦è®®é¢˜ï¼Œå¹¶æŒ‡å‡ºè™½ç„¶AIæ— æ³•å®ç°ç°è±¡å­¦ä¸Šçš„çœŸå®ä¼™ä¼´å…³ç³»ï¼Œä½†å…¶å¯ä»¥ä½œä¸ºé«˜æ•ˆçš„Functional Collaboratorå‘æŒ¥ä½œç”¨ã€‚è¿™ä¸€åŒºåˆ†å¯¹æ•™å­¦æ³•å’Œæ•™å­¦è®¾è®¡å…·æœ‰é‡è¦æ„ä¹‰ï¼Œå¼ºè°ƒäº†æœªæ¥åº”è‡´åŠ›äºæ„å»ºèƒ½å¤Ÿå……åˆ†å‘æŒ¥äººç±»ä¸AIäº’è¡¥ä¼˜åŠ¿çš„å­¦ä¹ ç¯å¢ƒã€‚",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.14825v1",
      "published_date": "2025-08-20 16:17:32 UTC",
      "updated_date": "2025-08-20 16:17:32 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:58:54.915718+00:00"
    },
    {
      "arxiv_id": "2508.14955v1",
      "title": "Quantum Long Short-term Memory with Differentiable Architecture Search",
      "title_zh": "åŸºäºå¯å¾®åˆ†æ¶æ„æœç´¢çš„é‡å­é•¿çŸ­æœŸè®°å¿†ç½‘ç»œ",
      "authors": [
        "Samuel Yen-Chi Chen",
        "Prayag Tiwari"
      ],
      "abstract": "Recent advances in quantum computing and machine learning have given rise to quantum machine learning (QML), with growing interest in learning from sequential data. Quantum recurrent models like QLSTM are promising for time-series prediction, NLP, and reinforcement learning. However, designing effective variational quantum circuits (VQCs) remains challenging and often task-specific. To address this, we propose DiffQAS-QLSTM, an end-to-end differentiable framework that optimizes both VQC parameters and architecture selection during training. Our results show that DiffQAS-QLSTM consistently outperforms handcrafted baselines, achieving lower loss across diverse test settings. This approach opens the door to scalable and adaptive quantum sequence learning.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹é‡å­æœºå™¨å­¦ä¹ (QML)ä¸­é‡å­é•¿çŸ­æœŸè®°å¿†ç½‘ç»œ(QLSTM)åœ¨è®¾è®¡å˜åˆ†é‡å­ç”µè·¯(VQCs)æ—¶é¢ä¸´çš„å›°éš¾ï¼Œæå‡ºäº†DiffQAS-QLSTMè¿™ä¸€ç«¯åˆ°ç«¯çš„å¯å¾®åˆ†æ¡†æ¶ã€‚è¯¥æ¡†æ¶çªç ´äº†ä¼ ç»Ÿæ‰‹åŠ¨è®¾è®¡VQCsçš„å±€é™ï¼Œèƒ½å¤Ÿåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­åŒæ—¶å¯¹ç”µè·¯å‚æ•°å’Œæ¶æ„è¿›è¡Œè‡ªåŠ¨åŒ–æœç´¢ä¸ä¼˜åŒ–ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒDiffQAS-QLSTMåœ¨å¤šç§æµ‹è¯•è®¾ç½®ä¸‹è¡¨ç°å‡ä¼˜äºä¼ ç»Ÿçš„äººå·¥è®¾è®¡åŸºçº¿ï¼Œæœ‰æ•ˆé™ä½äº†é¢„æµ‹æŸå¤±ã€‚è¿™ä¸€ç ”ç©¶æˆæœä¸ä»…ä¸ºå¯æ‰©å±•ä¸”è‡ªé€‚åº”çš„é‡å­åºåˆ—å­¦ä¹ (quantum sequence learning)æä¾›äº†æ–°æ–¹æ¡ˆï¼Œä¹Ÿè¯æ˜äº†å¾®åˆ†æ¶æ„æœç´¢åœ¨æå‡é‡å­æ¨¡å‹æ€§èƒ½æ–¹é¢çš„æ˜¾è‘—ä¼˜åŠ¿ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.ET",
        "cs.NE",
        "quant-ph"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by the IEEE International Conference on Quantum Artificial Intelligence (QAI) 2025",
      "pdf_url": "https://arxiv.org/pdf/2508.14955v1",
      "published_date": "2025-08-20 16:15:00 UTC",
      "updated_date": "2025-08-20 16:15:00 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:58:55.115320+00:00"
    },
    {
      "arxiv_id": "2508.14817v1",
      "title": "Evaluating Retrieval-Augmented Generation vs. Long-Context Input for Clinical Reasoning over EHRs",
      "title_zh": "åŸºäºç”µå­å¥åº·æ¡£æ¡ˆä¸´åºŠæ¨ç†çš„æ£€ç´¢å¢å¼ºç”Ÿæˆä¸é•¿ä¸Šä¸‹æ–‡è¾“å…¥å¯¹æ¯”è¯„ä¼°",
      "authors": [
        "Skatje Myers",
        "Dmitriy Dligach",
        "Timothy A. Miller",
        "Samantha Barr",
        "Yanjun Gao",
        "Matthew Churpek",
        "Anoop Mayampurath",
        "Majid Afshar"
      ],
      "abstract": "Electronic health records (EHRs) are long, noisy, and often redundant, posing a major challenge for the clinicians who must navigate them. Large language models (LLMs) offer a promising solution for extracting and reasoning over this unstructured text, but the length of clinical notes often exceeds even state-of-the-art models' extended context windows. Retrieval-augmented generation (RAG) offers an alternative by retrieving task-relevant passages from across the entire EHR, potentially reducing the amount of required input tokens. In this work, we propose three clinical tasks designed to be replicable across health systems with minimal effort: 1) extracting imaging procedures, 2) generating timelines of antibiotic use, and 3) identifying key diagnoses. Using EHRs from actual hospitalized patients, we test three state-of-the-art LLMs with varying amounts of provided context, using either targeted text retrieval or the most recent clinical notes. We find that RAG closely matches or exceeds the performance of using recent notes, and approaches the performance of using the models' full context while requiring drastically fewer input tokens. Our results suggest that RAG remains a competitive and efficient approach even as newer models become capable of handling increasingly longer amounts of text.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç”µå­å¥åº·è®°å½• (Electronic health records, EHRs) æ–‡æœ¬å†—é•¿ã€å……æ»¡å™ªå£°ä¸”é«˜åº¦å†—ä½™çš„æŒ‘æˆ˜ï¼Œå¯¹æ¯”äº†æ£€ç´¢å¢å¼ºç”Ÿæˆ (Retrieval-augmented generation, RAG) ä¸é•¿ä¸Šä¸‹æ–‡ (Long-Context) è¾“å…¥åœ¨ä¸´åºŠæ¨ç†ä¸­çš„è¡¨ç°ã€‚ç ”ç©¶è€…è®¾è®¡äº†å½±åƒç¨‹åºæå–ã€æŠ—ç”Ÿç´ ä½¿ç”¨æ—¶é—´è¡¨ç”ŸæˆåŠå…³é”®è¯Šæ–­è¯†åˆ«ä¸‰é¡¹ä»»åŠ¡ï¼Œæ—¨åœ¨è¯„ä¼°å¤§è¯­è¨€æ¨¡å‹ (Large language models, LLMs) å¯¹éç»“æ„åŒ–åŒ»ç–—æ–‡æœ¬çš„å¤„ç†èƒ½åŠ›ã€‚é€šè¿‡åœ¨çœŸå®ä½é™¢æ‚£è€…çš„ EHRs æ•°æ®ä¸Šæµ‹è¯•ä¸‰ç§å…ˆè¿›çš„ LLMsï¼Œç ”ç©¶å¯¹æ¯”äº†æ£€ç´¢ç‰¹å®šæ–‡æœ¬ä¸ä½¿ç”¨å®Œæ•´ä¸Šä¸‹æ–‡çš„ä¸åŒç­–ç•¥ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒRAG çš„æ¨ç†æ€§èƒ½ä¸ä»…èƒ½åŒ¹é…æˆ–è¶…è¿‡ä½¿ç”¨è¿‘æœŸä¸´åºŠç¬”è®°çš„æ–¹æ³•ï¼Œè¿˜ä»¥æå°‘çš„è¾“å…¥ token æ¶ˆè€—è¾¾åˆ°äº†æ¥è¿‘æ¨¡å‹å…¨ä¸Šä¸‹æ–‡å¤„ç†çš„æ°´å¹³ã€‚è¿™é¡¹å·¥ä½œå¼ºè°ƒäº† RAG åœ¨å¤„ç†æµ·é‡åŒ»ç–—æ•°æ®æ—¶çš„é«˜æ•ˆæ€§ï¼Œè¯æ˜å…¶å³ä¾¿åœ¨é•¿ä¸Šä¸‹æ–‡æ¨¡å‹ä¸æ–­æ¶Œç°çš„èƒŒæ™¯ä¸‹ä¾ç„¶å…·æœ‰æ˜¾è‘—çš„ç«äº‰ä¼˜åŠ¿ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.14817v1",
      "published_date": "2025-08-20 16:09:37 UTC",
      "updated_date": "2025-08-20 16:09:37 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:59:12.643126+00:00"
    },
    {
      "arxiv_id": "2508.14814v1",
      "title": "TransLight: Image-Guided Customized Lighting Control with Generative Decoupling",
      "title_zh": "TransLightï¼šåŸºäºç”Ÿæˆå¼è§£è€¦çš„å›¾åƒå¼•å¯¼å®šåˆ¶åŒ–å…‰ç…§æ§åˆ¶",
      "authors": [
        "Zongming Li",
        "Lianghui Zhu",
        "Haocheng Shen",
        "Longjin Ran",
        "Wenyu Liu",
        "Xinggang Wang"
      ],
      "abstract": "Most existing illumination-editing approaches fail to simultaneously provide customized control of light effects and preserve content integrity. This makes them less effective for practical lighting stylization requirements, especially in the challenging task of transferring complex light effects from a reference image to a user-specified target image. To address this problem, we propose TransLight, a novel framework that enables high-fidelity and high-freedom transfer of light effects. Extracting the light effect from the reference image is the most critical and challenging step in our method. The difficulty lies in the complex geometric structure features embedded in light effects that are highly coupled with content in real-world scenarios. To achieve this, we first present Generative Decoupling, where two fine-tuned diffusion models are used to accurately separate image content and light effects, generating a newly curated, million-scale dataset of image-content-light triplets. Then, we employ IC-Light as the generative model and train our model with our triplets, injecting the reference lighting image as an additional conditioning signal. The resulting TransLight model enables customized and natural transfer of diverse light effects. Notably, by thoroughly disentangling light effects from reference images, our generative decoupling strategy endows TransLight with highly flexible illumination control. Experimental results establish TransLight as the first method to successfully transfer light effects across disparate images, delivering more customized illumination control than existing techniques and charting new directions for research in illumination harmonization and editing.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† TransLight æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³ç°æœ‰å…‰ç…§ç¼–è¾‘æ–¹æ³•åœ¨ä¿æŒå†…å®¹å®Œæ•´æ€§çš„åŒæ—¶ï¼Œéš¾ä»¥å®ç°å…‰ç…§æ•ˆæœè‡ªå®šä¹‰æ§åˆ¶çš„é—®é¢˜ã€‚è¯¥æ¡†æ¶å¼•å…¥äº† Generative Decoupling æŠ€æœ¯ï¼Œåˆ©ç”¨ä¸¤ä¸ªç»è¿‡å¾®è°ƒçš„ Diffusion models ç²¾ç¡®åˆ†ç¦»å›¾åƒå†…å®¹ä¸å…‰ç…§æ•ˆæœï¼Œå¹¶æ®æ­¤æ„å»ºäº†ä¸€ä¸ªç™¾ä¸‡é‡çº§çš„ Image-content-light ä¸‰å…ƒç»„æ•°æ®é›†ã€‚TransLight é‡‡ç”¨ IC-Light ä½œä¸ºåŸºç¡€ç”Ÿæˆæ¨¡å‹ï¼Œé€šè¿‡å°†å‚è€ƒå›¾åƒçš„å…‰ç…§ä½œä¸º Conditioning signal æ³¨å…¥è®­ç»ƒï¼Œå®ç°äº†å…‰ç…§æ•ˆæœçš„é«˜åº¦è§£è€¦ä¸é«˜è‡ªç”±åº¦è¿ç§»ã€‚å®éªŒè¯æ˜ï¼ŒTransLight æ˜¯é¦–ä¸ªèƒ½å¤Ÿè·¨è¶Šå®Œå…¨ä¸åŒå›¾åƒæˆåŠŸè¿ç§»å¤æ‚å…‰ç…§æ•ˆæœçš„æ–¹æ³•ï¼Œæä¾›äº†æ¯”ç°æœ‰æŠ€æœ¯æ›´å…·å®šåˆ¶åŒ–çš„ Illumination controlã€‚è¿™ä¸€ç ”ç©¶ä¸ä»…æå‡äº†å…‰ç…§è¿ç§»çš„ä¿çœŸåº¦ï¼Œä¹Ÿä¸º Illumination harmonization ä¸å›¾åƒç¼–è¾‘é¢†åŸŸçš„ç ”ç©¶å¼€è¾Ÿäº†æ–°æ–¹å‘ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "15 pages, 9 figures",
      "pdf_url": "https://arxiv.org/pdf/2508.14814v1",
      "published_date": "2025-08-20 16:05:12 UTC",
      "updated_date": "2025-08-20 16:05:12 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:59:25.522175+00:00"
    },
    {
      "arxiv_id": "2508.14809v1",
      "title": "DINOv3 with Test-Time Training for Medical Image Registration",
      "title_zh": "åŸºäºæµ‹è¯•æ—¶è®­ç»ƒçš„ DINOv3 åŒ»å­¦å›¾åƒé…å‡†",
      "authors": [
        "Shansong Wang",
        "Mojtaba Safari",
        "Mingzhe Hu",
        "Qiang Li",
        "Chih-Wei Chang",
        "Richard LJ Qiu",
        "Xiaofeng Yang"
      ],
      "abstract": "Prior medical image registration approaches, particularly learning-based methods, often require large amounts of training data, which constrains clinical adoption. To overcome this limitation, we propose a training-free pipeline that relies on a frozen DINOv3 encoder and test-time optimization of the deformation field in feature space. Across two representative benchmarks, the method is accurate and yields regular deformations. On Abdomen MR-CT, it attained the best mean Dice score (DSC) of 0.790 together with the lowest 95th percentile Hausdorff Distance (HD95) of 4.9+-5.0 and the lowest standard deviation of Log-Jacobian (SDLogJ) of 0.08+-0.02. On ACDC cardiac MRI, it improves mean DSC to 0.769 and reduces SDLogJ to 0.11 and HD95 to 4.8, a marked gain over the initial alignment. The results indicate that operating in a compact foundation feature space at test time offers a practical and general solution for clinical registration without additional training.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§ç»“åˆ DINOv3 ä¸ Test-Time Training (TTT) çš„åŒ»å­¦å›¾åƒé…å‡†æ–¹æ³•ï¼Œæ—¨åœ¨è§£å†³å­¦ä¹ å‹é…å‡†æ¨¡å‹å¯¹å¤§è§„æ¨¡è®­ç»ƒæ•°æ®çš„ä¾èµ–ã€‚ä½œè€…å¼€å‘äº†ä¸€ä¸ª Training-free çš„å¤„ç†æµç¨‹ï¼Œåˆ©ç”¨å†»ç»“çš„ DINOv3 ç¼–ç å™¨åœ¨ç‰¹å¾ç©ºé—´ä¸­è¿›è¡Œå˜å½¢åœºçš„ Test-time optimizationã€‚åœ¨ Abdomen MR-CT åŸºå‡†æµ‹è¯•ä¸­ï¼Œè¯¥æ–¹æ³•å–å¾—äº† 0.790 çš„å¹³å‡ Dice score (DSC) ä»¥åŠæœ€ä½çš„ HD95 å’Œ SDLogJ è¯¯å·®ã€‚åœ¨ ACDC ä»»åŠ¡ä¸­ï¼Œè¯¥æ–¹æ³•åŒæ ·è¡¨ç°å‡ºè‰²ï¼Œå°†å¹³å‡ DSC æå‡è‡³ 0.769 å¹¶æ˜¾è‘—é™ä½äº†è·ç¦»è¯¯å·®ã€‚å®éªŒç»“æœè¯æ˜ï¼Œç›´æ¥åœ¨ç´§å‡‘çš„åŸºç¡€æ¨¡å‹ç‰¹å¾ç©ºé—´å†…è¿›è¡Œæµ‹è¯•æ—¶ä¼˜åŒ–ï¼Œä¸ä»…èƒ½æä¾›å‡†ç¡®ä¸”æ­£åˆ™åŒ–çš„å˜å½¢åœºï¼Œè¿˜ä¸ºä¸´åºŠé…å‡†æä¾›äº†ä¸€ç§æ— éœ€é¢å¤–è®­ç»ƒçš„é€šç”¨åŒ–æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.14809v1",
      "published_date": "2025-08-20 15:58:19 UTC",
      "updated_date": "2025-08-20 15:58:19 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:59:30.626093+00:00"
    },
    {
      "arxiv_id": "2508.14802v1",
      "title": "Privileged Self-Access Matters for Introspection in AI",
      "title_zh": "ç‰¹æƒè‡ªè®¿é—®å¯¹ AI å†…çœçš„é‡è¦æ€§",
      "authors": [
        "Siyuan Song",
        "Harvey Lederman",
        "Jennifer Hu",
        "Kyle Mahowald"
      ],
      "abstract": "Whether AI models can introspect is an increasingly important practical question. But there is no consensus on how introspection is to be defined. Beginning from a recently proposed ''lightweight'' definition, we argue instead for a thicker one. According to our proposal, introspection in AI is any process which yields information about internal states through a process more reliable than one with equal or lower computational cost available to a third party. Using experiments where LLMs reason about their internal temperature parameters, we show they can appear to have lightweight introspection while failing to meaningfully introspect per our proposed definition.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†äººå·¥æ™ºèƒ½å†…çœ(AI Introspection)çš„å®šä¹‰äº‰è®®ï¼Œå¹¶å¯¹ç›®å‰å­¦æœ¯ç•Œæå‡ºçš„â€œè½»é‡çº§â€å®šä¹‰æå‡ºäº†è´¨ç–‘ã€‚ä½œè€…åŸºäºâ€œç‰¹æƒè‡ªæˆ‘è®¿é—®â€(Privileged Self-Access)æå‡ºäº†ä¸€ç§æ›´ä¸¥è°¨çš„å®šä¹‰ï¼Œå³å†…çœæ˜¯æŒ‡AIé€šè¿‡æ¯”åŒç­‰è®¡ç®—æˆæœ¬ä¸‹çš„ç¬¬ä¸‰æ–¹æ›´å¯é çš„æ–¹å¼è·å–å…¶å†…éƒ¨çŠ¶æ€(internal states)ä¿¡æ¯çš„è¿‡ç¨‹ã€‚é€šè¿‡è®©å¤§å‹è¯­è¨€æ¨¡å‹(LLMs)å¯¹å…¶å†…éƒ¨æ¸©åº¦å‚æ•°(internal temperature parameters)è¿›è¡Œæ¨ç†çš„å®éªŒè¡¨æ˜ï¼Œè¿™äº›æ¨¡å‹è™½ç„¶åœ¨è½»é‡çº§æ ‡å‡†ä¸‹çœ‹ä¼¼å…·æœ‰å†…çœèƒ½åŠ›ï¼Œä½†å®é™…ä¸Šæœªèƒ½æ»¡è¶³è¯¥ç ”ç©¶æ‰€æè®®çš„æœ‰æ„ä¹‰çš„å†…çœæ ‡å‡†ã€‚è¿™ä¸€å‘ç°æ­ç¤ºäº†å½“å‰æ¨¡å‹åœ¨è‡ªæˆ‘è®¤çŸ¥æ–¹é¢çš„å±€é™æ€§ï¼Œå¹¶å¼ºè°ƒäº†åœ¨è¯„ä¼°AIå†…çœèƒ½åŠ›æ—¶é‡‡ç”¨æ›´ä¸¥æ ¼å®šä¹‰çš„é‡è¦æ€§ã€‚",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.14802v1",
      "published_date": "2025-08-20 15:52:34 UTC",
      "updated_date": "2025-08-20 15:52:34 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:59:34.725876+00:00"
    },
    {
      "arxiv_id": "2508.14782v1",
      "title": "TransLLM: A Unified Multi-Task Foundation Framework for Urban Transportation via Learnable Prompting",
      "title_zh": "TransLLMï¼šåŸºäºå¯å­¦ä¹ æç¤ºçš„åŸå¸‚äº¤é€šç»Ÿä¸€å¤šä»»åŠ¡åŸºç¡€æ¡†æ¶",
      "authors": [
        "Jiaming Leng",
        "Yunying Bi",
        "Chuan Qin",
        "Bing Yin",
        "Yanyong Zhang",
        "Chao Wang"
      ],
      "abstract": "Urban transportation systems encounter diverse challenges across multiple tasks, such as traffic forecasting, electric vehicle (EV) charging demand prediction, and taxi dispatch. Existing approaches suffer from two key limitations: small-scale deep learning models are task-specific and data-hungry, limiting their generalizability across diverse scenarios, while large language models (LLMs), despite offering flexibility through natural language interfaces, struggle with structured spatiotemporal data and numerical reasoning in transportation domains. To address these limitations, we propose TransLLM, a unified foundation framework that integrates spatiotemporal modeling with large language models through learnable prompt composition. Our approach features a lightweight spatiotemporal encoder that captures complex dependencies via dilated temporal convolutions and dual-adjacency graph attention networks, seamlessly interfacing with LLMs through structured embeddings. A novel instance-level prompt routing mechanism, trained via reinforcement learning, dynamically personalizes prompts based on input characteristics, moving beyond fixed task-specific templates. The framework operates by encoding spatiotemporal patterns into contextual representations, dynamically composing personalized prompts to guide LLM reasoning, and projecting the resulting representations through specialized output layers to generate task-specific predictions. Experiments across seven datasets and three tasks demonstrate the exceptional effectiveness of TransLLM in both supervised and zero-shot settings. Compared to ten baseline models, it delivers competitive performance on both regression and planning problems, showing strong generalization and cross-task adaptability. Our code is available at https://github.com/BiYunying/TransLLM.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†TransLLMï¼Œè¿™æ˜¯ä¸€ä¸ªé¢å‘åŸå¸‚äº¤é€šçš„ç»Ÿä¸€å¤šä»»åŠ¡åŸºç¡€æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³ä¼ ç»Ÿæ·±åº¦å­¦ä¹ æ¨¡å‹é€šç”¨æ€§å—é™ä»¥åŠå¤§è¯­è¨€æ¨¡å‹(LLMs)å¤„ç†ç»“æ„åŒ–æ—¶ç©ºæ•°æ®ä¸æ•°å€¼æ¨ç†èƒ½åŠ›ä¸è¶³çš„é—®é¢˜ã€‚è¯¥æ¡†æ¶é€šè¿‡å¯å­¦ä¹ çš„æç¤ºç»„åˆ(learnable prompt composition)å°†è½»é‡çº§æ—¶ç©ºç¼–ç å™¨ä¸LLMsç›¸é›†æˆï¼Œåˆ©ç”¨æ‰©å¼ æ—¶é—´å·ç§¯(dilated temporal convolutions)å’ŒåŒé‚»æ¥å›¾æ³¨æ„åŠ›ç½‘ç»œ(dual-adjacency graph attention networks)æœ‰æ•ˆæ•è·å¤æ‚çš„æ—¶ç©ºä¾èµ–ã€‚TransLLMå¼•å…¥äº†åŸºäºå¼ºåŒ–å­¦ä¹ (reinforcement learning)è®­ç»ƒçš„å®ä¾‹çº§æç¤ºè·¯ç”±æœºåˆ¶ï¼Œèƒ½å¤Ÿæ ¹æ®è¾“å…¥ç‰¹å¾åŠ¨æ€ç”Ÿæˆä¸ªæ€§åŒ–æç¤ºä»¥å¼•å¯¼LLMæ¨ç†ã€‚å®éªŒåœ¨7ä¸ªæ•°æ®é›†å’Œ3é¡¹å…³é”®äº¤é€šä»»åŠ¡ä¸Šè¯æ˜ï¼Œè¯¥æ¡†æ¶åœ¨æœ‰ç›‘ç£å’Œé›¶æ ·æœ¬(zero-shot)è®¾ç½®ä¸‹å‡è¡¨ç°å‡ºè‰²ï¼Œæ€§èƒ½ä¼˜äº10ç§åŸºçº¿æ¨¡å‹ã€‚ç»“æœè¡¨æ˜TransLLMåœ¨å¤„ç†å›å½’å’Œè§„åˆ’é—®é¢˜æ—¶å…·æœ‰æå¼ºçš„æœ‰æ•ˆæ€§ï¼Œå±•ç°äº†å“è¶Šçš„æ³›åŒ–èƒ½åŠ›å’Œè·¨ä»»åŠ¡é€‚åº”æ€§ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.14782v1",
      "published_date": "2025-08-20 15:27:49 UTC",
      "updated_date": "2025-08-20 15:27:49 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:59:41.625387+00:00"
    },
    {
      "arxiv_id": "2508.14765v2",
      "title": "PepThink-R1: LLM for Interpretable Cyclic Peptide Optimization with CoT SFT and Reinforcement Learning",
      "title_zh": "PepThink-R1ï¼šåŸºäºé“¾å¼æ€ç»´ç›‘ç£å¾®è°ƒä¸å¼ºåŒ–å­¦ä¹ çš„å¯è§£é‡Šç¯è‚½ä¼˜åŒ–å¤§è¯­è¨€æ¨¡å‹",
      "authors": [
        "Ruheng Wang",
        "Hang Zhang",
        "Trieu Nguyen",
        "Shasha Feng",
        "Hao-Wei Pang",
        "Xiang Yu",
        "Li Xiao",
        "Peter Zhiping Zhang"
      ],
      "abstract": "Designing therapeutic peptides with tailored properties is hindered by the vastness of sequence space, limited experimental data, and poor interpretability of current generative models. To address these challenges, we introduce PepThink-R1, a generative framework that integrates large language models (LLMs) with chain-of-thought (CoT) supervised fine-tuning and reinforcement learning (RL). Unlike prior approaches, PepThink-R1 explicitly reasons about monomer-level modifications during sequence generation, enabling interpretable design choices while optimizing for multiple pharmacological properties. Guided by a tailored reward function balancing chemical validity and property improvements, the model autonomously explores diverse sequence variants. We demonstrate that PepThink-R1 generates cyclic peptides with significantly enhanced lipophilicity, stability, and exposure, outperforming existing general LLMs (e.g., GPT-5) and domain-specific baseline in both optimization success and interpretability. To our knowledge, this is the first LLM-based peptide design framework that combines explicit reasoning with RL-driven property control, marking a step toward reliable and transparent peptide optimization for therapeutic discovery.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹æ²»ç–—æ€§å¤šè‚½è®¾è®¡ä¸­åºåˆ—ç©ºé—´åºå¤§ã€å®éªŒæ•°æ®æœ‰é™åŠç”Ÿæˆæ¨¡å‹å¯è§£é‡Šæ€§å·®ç­‰æŒ‘æˆ˜ï¼Œæå‡ºäº†PepThink-R1æ¡†æ¶ã€‚è¯¥æ¡†æ¶å°†å¤§è¯­è¨€æ¨¡å‹(LLMs)ä¸é“¾å¼æ€ç»´(Chain-of-Thought, CoT)æœ‰ç›‘ç£å¾®è°ƒ(SFT)åŠå¼ºåŒ–å­¦ä¹ (Reinforcement Learning, RL)ç›¸ç»“åˆï¼Œå®ç°äº†å¯è§£é‡Šçš„ç¯è‚½ä¼˜åŒ–ã€‚PepThink-R1åœ¨åºåˆ—ç”Ÿæˆè¿‡ç¨‹ä¸­å¯¹å•ä½“çº§(monomer-level)ä¿®é¥°è¿›è¡Œæ˜¾å¼æ¨ç†ï¼Œé€šè¿‡å®šåˆ¶åŒ–çš„å¥–åŠ±å‡½æ•°å¹³è¡¡åŒ–å­¦æœ‰æ•ˆæ€§ä¸è¯ç†æ€§è´¨æå‡ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ¨¡å‹ç”Ÿæˆçš„ç¯è‚½åœ¨è„‚æº¶æ€§(lipophilicity)ã€ç¨³å®šæ€§å’Œæš´éœ²é‡ç­‰æ–¹é¢æ˜¾è‘—ä¼˜äºGPT-5ç­‰é€šç”¨æ¨¡å‹åŠé¢†åŸŸåŸºçº¿ã€‚ä½œä¸ºé¦–ä¸ªç»“åˆæ˜¾å¼æ¨ç†ä¸å¼ºåŒ–å­¦ä¹ é©±åŠ¨æ€§è´¨æ§åˆ¶çš„å¤šè‚½è®¾è®¡æ¡†æ¶ï¼Œè¯¥ç ”ç©¶ä¸ºè¯ç‰©å‘ç°ä¸­å®ç°é€æ˜ä¸”å¯é çš„å¤šè‚½ä¼˜åŒ–å¥ å®šäº†åŸºç¡€ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.14765v2",
      "published_date": "2025-08-20 15:13:52 UTC",
      "updated_date": "2025-11-20 06:42:02 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:59:38.720357+00:00"
    },
    {
      "arxiv_id": "2508.14755v2",
      "title": "Reliable generation of isomorphic physics problems using Generative AI with prompt-chaining and tool use",
      "title_zh": "åˆ©ç”¨æç¤ºé“¾ä¸å·¥å…·è°ƒç”¨çš„ç”Ÿæˆå¼äººå·¥æ™ºèƒ½å¯é ç”ŸæˆåŒæ„ç‰©ç†é—®é¢˜",
      "authors": [
        "Zhongzhou Chen"
      ],
      "abstract": "We present a method for generating large numbers of isomorphic physics problems using generative AI services such as ChatGPT, through prompt chaining and tool use. This approach enables precise control over structural variations-such as numeric values and spatial relations-while supporting diverse contextual variations in the problem body. By utilizing the Python code interpreter, the method supports automatic solution validation and simple diagram generation, addressing key limitations in existing LLM-based methods. We generated two example isomorphic problem banks and compared the outcome against two simpler prompt-based approaches. Results show that prompt-chaining produces significantly higher quality and more consistent outputs than simpler, non-chaining prompts. We also show that GenAI services can be used to validate the quality of the generated isomorphic problems. This work demonstrates a promising method for efficient and scalable problem creation accessible to the average instructor, which opens new possibilities for personalized adaptive testing and automated content development.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§åˆ©ç”¨ç”Ÿæˆå¼äººå·¥æ™ºèƒ½(Generative AI)é€šè¿‡æç¤ºé“¾(prompt-chaining)å’Œå·¥å…·è°ƒç”¨æŠ€æœ¯ï¼Œå¯é åœ°ç”Ÿæˆå¤§é‡åŒæ„ç‰©ç†é—®é¢˜(isomorphic physics problems)çš„æ–¹æ³•ã€‚è¯¥æ–¹æ³•å®ç°äº†å¯¹æ•°å€¼å’Œç©ºé—´å…³ç³»ç­‰ç»“æ„åŒ–å˜ä½“(structural variations)çš„ç²¾ç¡®æ§åˆ¶ï¼ŒåŒæ—¶æ”¯æŒé—®é¢˜èƒŒæ™¯ä¸­å¤šæ ·åŒ–çš„æƒ…å¢ƒå˜ä½“ã€‚é€šè¿‡ç»“åˆ Python ä»£ç è§£é‡Šå™¨(code interpreter)ï¼Œè¯¥æ–¹æ¡ˆæœ‰æ•ˆè§£å†³äº†ç°æœ‰å¤§è¯­è¨€æ¨¡å‹(LLM)æ–¹æ³•çš„å±€é™ï¼Œæ”¯æŒè‡ªåŠ¨åŒ–çš„è§£é¢˜éªŒè¯åŠç®€å•å›¾è¡¨ç”Ÿæˆã€‚å¯¹æ¯”å®éªŒç»“æœè¡¨æ˜ï¼Œæç¤ºé“¾æŠ€æœ¯åœ¨ç”Ÿæˆè´¨é‡å’Œè¾“å‡ºä¸€è‡´æ€§ä¸Šæ˜¾è‘—ä¼˜äºç®€å•çš„éé“¾å¼æç¤ºæ–¹æ³•ã€‚æ­¤å¤–ï¼Œç ”ç©¶è¯æ˜äº† GenAI æœåŠ¡èƒ½å¤Ÿèƒœä»»å¯¹ç”Ÿæˆé¢˜ç›®è´¨é‡çš„æ ¡éªŒå·¥ä½œã€‚è¿™é¡¹å·¥ä½œä¸ºæ•™å¸ˆæä¾›äº†ä¸€ç§é«˜æ•ˆã€å¯æ‰©å±•ä¸”æ˜“äºä½¿ç”¨çš„é¢˜ç›®å¼€å‘æ‰‹æ®µï¼Œä¸ºå®ç°å¤§è§„æ¨¡ä¸ªæ€§åŒ–è‡ªé€‚åº”æµ‹è¯•å’Œè‡ªåŠ¨åŒ–å†…å®¹å¼€å‘å¼€è¾Ÿäº†æ–°çš„è·¯å¾„ã€‚",
      "categories": [
        "physics.ed-ph",
        "cs.AI"
      ],
      "primary_category": "physics.ed-ph",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.14755v2",
      "published_date": "2025-08-20 14:58:05 UTC",
      "updated_date": "2025-10-15 15:13:01 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:59:44.324124+00:00"
    },
    {
      "arxiv_id": "2508.14748v1",
      "title": "Cross-Modality Controlled Molecule Generation with Diffusion Language Model",
      "title_zh": "åŸºäºæ‰©æ•£è¯­è¨€æ¨¡å‹çš„è·¨æ¨¡æ€å¯æ§åˆ†å­ç”Ÿæˆ",
      "authors": [
        "Yunzhe Zhang",
        "Yifei Wang",
        "Khanh Vinh Nguyen",
        "Pengyu Hong"
      ],
      "abstract": "Current SMILES-based diffusion models for molecule generation typically support only unimodal constraint. They inject conditioning signals at the start of the training process and require retraining a new model from scratch whenever the constraint changes. However, real-world applications often involve multiple constraints across different modalities, and additional constraints may emerge over the course of a study. This raises a challenge: how to extend a pre-trained diffusion model not only to support cross-modality constraints but also to incorporate new ones without retraining. To tackle this problem, we propose the Cross-Modality Controlled Molecule Generation with Diffusion Language Model (CMCM-DLM), demonstrated by two distinct cross modalities: molecular structure and chemical properties. Our approach builds upon a pre-trained diffusion model, incorporating two trainable modules, the Structure Control Module (SCM) and the Property Control Module (PCM), and operates in two distinct phases during the generation process. In Phase I, we employs the SCM to inject structural constraints during the early diffusion steps, effectively anchoring the molecular backbone. Phase II builds on this by further introducing PCM to guide the later stages of inference to refine the generated molecules, ensuring their chemical properties match the specified targets. Experimental results on multiple datasets demonstrate the efficiency and adaptability of our approach, highlighting CMCM-DLM's significant advancement in molecular generation for drug discovery applications.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†CMCM-DLMï¼ˆCross-Modality Controlled Molecule Generation with Diffusion Language Modelï¼‰ï¼Œæ—¨åœ¨è§£å†³ç°æœ‰çš„åŸºäºSMILESçš„Diffusion Modelé€šå¸¸ä»…æ”¯æŒå•æ¨¡æ€çº¦æŸä¸”åœ¨çº¦æŸæ”¹å˜æ—¶éœ€ä»å¤´é‡æ–°è®­ç»ƒçš„é—®é¢˜ã€‚è¯¥æ–¹æ³•åœ¨é¢„è®­ç»ƒæ¨¡å‹çš„åŸºç¡€ä¸Šå¼•å…¥äº†Structure Control Module (SCM)å’ŒProperty Control Module (PCM)ä¸¤ä¸ªå¯è®­ç»ƒæ¨¡å—ï¼Œå®ç°äº†å¯¹åˆ†å­ç»“æ„å’ŒåŒ–å­¦æ€§è´¨çš„è·¨æ¨¡æ€ååŒæ§åˆ¶ã€‚ç”Ÿæˆè¿‡ç¨‹åˆ†ä¸ºä¸¤ä¸ªé˜¶æ®µï¼šç¬¬ä¸€é˜¶æ®µåˆ©ç”¨SCMåœ¨æ‰©æ•£æ—©æœŸæ³¨å…¥ç»“æ„çº¦æŸä»¥é”šå®šåˆ†å­ä¸»é“¾ï¼Œç¬¬äºŒé˜¶æ®µåˆ™é€šè¿‡PCMåœ¨æ¨ç†åæœŸå¼•å¯¼åˆ†å­ç»†åŒ–ï¼Œç¡®ä¿å…¶åŒ–å­¦æ€§è´¨ç¬¦åˆç›®æ ‡è®¾å®šã€‚å®éªŒè¯æ˜ï¼ŒCMCM-DLMæ— éœ€é‡æ–°è®­ç»ƒå³å¯æ‰©å±•æ”¯æŒæ–°çš„çº¦æŸï¼Œåœ¨å¤šä¸ªæ•°æ®é›†ä¸Šå±•ç°äº†æé«˜çš„æ•ˆç‡ä¸é€‚åº”æ€§ã€‚è¿™ä¸€è¿›å±•ä¸ºè¯ç‰©å‘ç°ä¸­çš„åˆ†å­ç”Ÿæˆä»»åŠ¡æä¾›äº†ä¸€ç§æ›´å…·çµæ´»æ€§å’Œå¯æ‰©å±•æ€§çš„æŠ€æœ¯æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.14748v1",
      "published_date": "2025-08-20 14:48:44 UTC",
      "updated_date": "2025-08-20 14:48:44 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:59:43.924210+00:00"
    },
    {
      "arxiv_id": "2508.16659v1",
      "title": "Enabling Multi-Agent Systems as Learning Designers: Applying Learning Sciences to AI Instructional Design",
      "title_zh": "èµ‹èƒ½å¤šæ™ºèƒ½ä½“ç³»ç»Ÿæ‹…ä»»å­¦ä¹ è®¾è®¡å¸ˆï¼šå­¦ä¹ ç§‘å­¦åœ¨äººå·¥æ™ºèƒ½æ•™å­¦è®¾è®¡ä¸­çš„åº”ç”¨",
      "authors": [
        "Jiayi Wang",
        "Ruiwei Xiao",
        "Xinying Hou",
        "John Stamper"
      ],
      "abstract": "K-12 educators are increasingly using Large Language Models (LLMs) to create instructional materials. These systems excel at producing fluent, coherent content, but often lack support for high-quality teaching. The reason is twofold: first, commercial LLMs, such as ChatGPT and Gemini which are among the most widely accessible to teachers, do not come preloaded with the depth of pedagogical theory needed to design truly effective activities; second, although sophisticated prompt engineering can bridge this gap, most teachers lack the time or expertise and find it difficult to encode such pedagogical nuance into their requests. This study shifts pedagogical expertise from the user's prompt to the LLM's internal architecture. We embed the well-established Knowledge-Learning-Instruction (KLI) framework into a Multi-Agent System (MAS) to act as a sophisticated instructional designer. We tested three systems for generating secondary Math and Science learning activities: a Single-Agent baseline simulating typical teacher prompts; a role-based MAS where agents work sequentially; and a collaborative MAS-CMD where agents co-construct activities through conquer and merge discussion. The generated materials were evaluated by 20 practicing teachers and a complementary LLM-as-a-judge system using the Quality Matters (QM) K-12 standards. While the rubric scores showed only small, often statistically insignificant differences between the systems, the qualitative feedback from educators painted a clear and compelling picture. Teachers strongly preferred the activities from the collaborative MAS-CMD, describing them as significantly more creative, contextually relevant, and classroom-ready. Our findings show that embedding pedagogical principles into LLM systems offers a scalable path for creating high-quality educational content.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å¦‚ä½•å°†å­¦ä¹ ç§‘å­¦åº”ç”¨äºäººå·¥æ™ºèƒ½æ•™å­¦è®¾è®¡ï¼Œæ—¨åœ¨è§£å†³Large Language Models (LLMs)åœ¨ååŠ©K-12æ•™å¸ˆåˆ›ä½œæ•™å­¦ææ–™æ—¶ç¼ºä¹æ·±åº¦æ•™è‚²å­¦ç†è®ºæ”¯æŒçš„é—®é¢˜ã€‚ä½œè€…é€šè¿‡å°†Knowledge-Learning-Instruction (KLI)æ¡†æ¶åµŒå…¥Multi-Agent System (MAS)æ¶æ„ä¸­ï¼Œä½¿AIç³»ç»Ÿèƒ½å¤Ÿæ‰¿æ‹…ä¸“ä¸šæ•™å­¦è®¾è®¡å¸ˆçš„è§’è‰²ã€‚å®éªŒå¯¹æ¯”äº†å•æ™ºèƒ½ä½“åŸºçº¿ã€è§’è‰²åŒ–é¡ºåºMASä»¥åŠé‡‡ç”¨å¾æœä¸åˆå¹¶è®¨è®ºæœºåˆ¶çš„åä½œå¼MAS-CMDä¸‰ç§ç³»ç»Ÿåœ¨ç”Ÿæˆä¸­å­¦ç†ç§‘æ•™å­¦æ´»åŠ¨ä¸­çš„è¡¨ç°ã€‚è¯„ä¼°ç»“æœæ˜¾ç¤ºï¼Œå°½ç®¡åŸºäºQuality Matters (QM)æ ‡å‡†çš„é‡åŒ–è¯„åˆ†å·®å¼‚ä¸æ˜¾è‘—ï¼Œä½†å—è®¿æ•™å¸ˆæ˜æ˜¾æ›´å€¾å‘äºMAS-CMDç”Ÿæˆçš„ææ–™ï¼Œè®¤ä¸ºå…¶æ›´å…·åˆ›æ„ã€æƒ…å¢ƒç›¸å…³æ€§ä¸”æ›´ç¬¦åˆè¯¾å ‚å®é™…éœ€æ±‚ã€‚è¯¥ç ”ç©¶è¯æ˜ï¼Œå°†æ•™è‚²å­¦åŸåˆ™å†…åµŒäºLLMç³»ç»Ÿæ¶æ„ï¼Œä¸ºè§„æ¨¡åŒ–ç”Ÿäº§é«˜è´¨é‡æ•™è‚²å†…å®¹æä¾›äº†å¯è¡Œè·¯å¾„ã€‚",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.CY",
      "comment": "under review for an [anonymized according to the conference policy] conference",
      "pdf_url": "https://arxiv.org/pdf/2508.16659v1",
      "published_date": "2025-08-20 14:44:00 UTC",
      "updated_date": "2025-08-20 14:44:00 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:59:48.653706+00:00"
    },
    {
      "arxiv_id": "2508.14735v1",
      "title": "Evaluating Multilingual and Code-Switched Alignment in LLMs via Synthetic Natural Language Inference",
      "title_zh": "åŸºäºåˆæˆè‡ªç„¶è¯­è¨€æ¨ç†çš„å¤§è¯­è¨€æ¨¡å‹å¤šè¯­è¨€ä¸è¯­ç è½¬æ¢å¯¹é½è¯„ä¼°",
      "authors": [
        "Samir Abdaljalil",
        "Erchin Serpedin",
        "Khalid Qaraqe",
        "Hasan Kurban"
      ],
      "abstract": "Large language models (LLMs) are increasingly applied in multilingual contexts, yet their capacity for consistent, logically grounded alignment across languages remains underexplored. We present a controlled evaluation framework for multilingual natural language inference (NLI) that generates synthetic, logic-based premise-hypothesis pairs and translates them into a typologically diverse set of languages. This design enables precise control over semantic relations and allows testing in both monolingual and mixed-language (code-switched) conditions. Surprisingly, code-switching does not degrade, and can even improve, performance, suggesting that translation-induced lexical variation may serve as a regularization signal. We validate semantic preservation through embedding-based similarity analyses and cross-lingual alignment visualizations, confirming the fidelity of translated pairs. Our findings expose both the potential and the brittleness of current LLM cross-lingual reasoning, and identify code-switching as a promising lever for improving multilingual robustness. Code available at: https://github.com/KurbanIntelligenceLab/nli-stress-testing",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§è¯„ä¼°å¤šè¯­è¨€è‡ªç„¶è¯­è¨€æ¨ç† (Multilingual NLI) çš„å—æ§æ¡†æ¶ï¼Œæ—¨åœ¨æ¢è®¨å¤§è¯­è¨€æ¨¡å‹ (LLMs) åœ¨ä¸åŒè¯­è¨€é—´é€»è¾‘å¯¹é½çš„ä¸€è‡´æ€§ã€‚ç ”ç©¶é€šè¿‡ç”ŸæˆåŸºäºé€»è¾‘çš„åˆæˆå‰æ-å‡è®¾å¯¹å¹¶å°†å…¶ç¿»è¯‘ä¸ºå¤šç§è¯­è¨€ï¼Œå®ç°äº†å¯¹è¯­ä¹‰å…³ç³»çš„ç²¾ç¡®æ§åˆ¶ï¼Œå¹¶æ”¯æŒåœ¨å•è¯­å’Œä»£ç åˆ‡æ¢ (Code-switching) æ¡ä»¶ä¸‹çš„æµ‹è¯•ã€‚å®éªŒç»“æœæ˜¾ç¤ºä»£ç åˆ‡æ¢ä¸ä»…æ²¡æœ‰é™ä½æ¨¡å‹æ€§èƒ½ï¼Œåè€Œå¯èƒ½é€šè¿‡ç¿»è¯‘è¯±å¯¼çš„è¯æ±‡å˜å¼‚èµ·åˆ°æ­£åˆ™åŒ–ä¿¡å· (Regularization signal) çš„ä½œç”¨ã€‚ç ”ç©¶åˆ©ç”¨åŸºäºåµŒå…¥çš„ç›¸ä¼¼æ€§åˆ†æ (Embedding-based similarity) å’Œè·¨è¯­è¨€å¯¹é½å¯è§†åŒ–éªŒè¯äº†ç¿»è¯‘å¯¹çš„è¯­ä¹‰ä¿çœŸåº¦ã€‚è¯¥å‘ç°æ­ç¤ºäº†å½“å‰æ¨¡å‹åœ¨è·¨è¯­è¨€æ¨ç†æ–¹é¢çš„æ½œåŠ›ä¸è„†å¼±æ€§ï¼Œå¹¶ç¡®å®šäº†ä»£ç åˆ‡æ¢æ˜¯æå‡å¤šè¯­è¨€é²æ£’æ€§ (Multilingual robustness) çš„ä¸€ç§æœ‰æ•ˆæ‰‹æ®µã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Under review",
      "pdf_url": "https://arxiv.org/pdf/2508.14735v1",
      "published_date": "2025-08-20 14:30:34 UTC",
      "updated_date": "2025-08-20 14:30:34 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:59:58.036676+00:00"
    },
    {
      "arxiv_id": "2508.14734v1",
      "title": "AFABench: A Generic Framework for Benchmarking Active Feature Acquisition",
      "title_zh": "AFABenchï¼šä¸»åŠ¨ç‰¹å¾è·å–çš„é€šç”¨åŸºå‡†æµ‹è¯•æ¡†æ¶",
      "authors": [
        "Valter SchÃ¼tz",
        "Han Wu",
        "Reza Rezvan",
        "Linus Aronsson",
        "Morteza Haghir Chehreghani"
      ],
      "abstract": "In many real-world scenarios, acquiring all features of a data instance can be expensive or impractical due to monetary cost, latency, or privacy concerns. Active Feature Acquisition (AFA) addresses this challenge by dynamically selecting a subset of informative features for each data instance, trading predictive performance against acquisition cost. While numerous methods have been proposed for AFA, ranging from greedy information-theoretic strategies to non-myopic reinforcement learning approaches, fair and systematic evaluation of these methods has been hindered by the lack of standardized benchmarks. In this paper, we introduce AFABench, the first benchmark framework for AFA. Our benchmark includes a diverse set of synthetic and real-world datasets, supports a wide range of acquisition policies, and provides a modular design that enables easy integration of new methods and tasks. We implement and evaluate representative algorithms from all major categories, including static, greedy, and reinforcement learning-based approaches. To test the lookahead capabilities of AFA policies, we introduce a novel synthetic dataset, AFAContext, designed to expose the limitations of greedy selection. Our results highlight key trade-offs between different AFA strategies and provide actionable insights for future research. The benchmark code is available at: https://github.com/Linusaronsson/AFA-Benchmark.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹åœ¨ç°å®åœºæ™¯ä¸­è·å–å…¨éƒ¨æ•°æ®ç‰¹å¾é¢ä¸´çš„é«˜æˆæœ¬ä¸éšç§æŒ‘æˆ˜ï¼Œæå‡ºäº†é¦–ä¸ªç”¨äº Active Feature Acquisition (AFA) çš„é€šç”¨åŸºå‡†æ¡†æ¶ AFABenchã€‚è¯¥æ¡†æ¶é›†æˆäº†å¤šæ ·çš„åˆæˆä¸çœŸå®ä¸–ç•Œæ•°æ®é›†ï¼Œæ”¯æŒä» greedy information-theoretic ç­–ç•¥åˆ° non-myopic reinforcement learning æ–¹æ³•çš„å¹¿æ³›é‡‡é›†ç­–ç•¥ã€‚é€šè¿‡æ¨¡å—åŒ–è®¾è®¡ï¼Œç ”ç©¶è€…ç³»ç»Ÿè¯„ä¼°äº† staticã€greedy å’Œ reinforcement learning ç­‰ä»£è¡¨æ€§ç®—æ³•ï¼Œæ­ç¤ºäº†ä¸åŒ AFA ç­–ç•¥ä¹‹é—´çš„å…³é”® trade-offsã€‚æ­¤å¤–ï¼Œç ”ç©¶è¿˜å¼•å…¥äº†ä¸“é—¨è®¾è®¡çš„æ–°å‹åˆæˆæ•°æ®é›† AFAContextï¼Œç”¨äºæµ‹è¯•ç®—æ³•çš„ lookahead èƒ½åŠ›å¹¶æš´éœ² greedy selection çš„å±€é™æ€§ã€‚è¯¥æ¡†æ¶çš„å¼€æºä¸º AFA é¢†åŸŸæä¾›äº†æ ‡å‡†åŒ–çš„è¯„ä¼°æ ‡å‡†ï¼Œå¹¶ä¸ºæœªæ¥ç ”ç©¶çš„å¯æŒç»­å‘å±•æä¾›äº† actionable insightsã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.14734v1",
      "published_date": "2025-08-20 14:29:16 UTC",
      "updated_date": "2025-08-20 14:29:16 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:59:57.626353+00:00"
    },
    {
      "arxiv_id": "2508.14725v1",
      "title": "Emerson-Lei and Manna-Pnueli Games for LTLf+ and PPLTL+ Synthesis",
      "title_zh": "é¢å‘ LTLf+ ä¸ PPLTL+ åˆæˆçš„ Emerson-Lei ä¸ Manna-Pnueli åšå¼ˆ",
      "authors": [
        "Daniel Hausmann",
        "Shufang Zhu",
        "Gianmarco Parretti",
        "Christoph Weinhuber",
        "Giuseppe De Giacomo",
        "Nir Piterman"
      ],
      "abstract": "Recently, the Manna-Pnueli Hierarchy has been used to define the temporal logics LTLfp and PPLTLp, which allow to use finite-trace LTLf/PPLTL techniques in infinite-trace settings while achieving the expressiveness of full LTL. In this paper, we present the first actual solvers for reactive synthesis in these logics. These are based on games on graphs that leverage DFA-based techniques from LTLf/PPLTL to construct the game arena. We start with a symbolic solver based on Emerson-Lei games, which reduces lower-class properties (guarantee, safety) to higher ones (recurrence, persistence) before solving the game. We then introduce Manna-Pnueli games, which natively embed Manna-Pnueli objectives into the arena. These games are solved by composing solutions to a DAG of simpler Emerson-Lei games, resulting in a provably more efficient approach. We implemented the solvers and practically evaluated their performance on a range of representative formulas. The results show that Manna-Pnueli games often offer significant advantages, though not universally, indicating that combining both approaches could further enhance practical performance.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹åŸºäº Manna-Pnueli Hierarchy çš„ $LTL_{f}^{+}$ å’Œ $PPLTL^{+}$ é€»è¾‘ï¼Œæå‡ºäº†é¦–æ‰¹ç”¨äºååº”å¼åˆæˆ(reactive synthesis)çš„å®é™…æ±‚è§£å™¨ã€‚è¿™äº›æ±‚è§£å™¨é€šè¿‡åˆ©ç”¨ $LTL_f$ å’Œ $PPLTL$ çš„ DFA æŠ€æœ¯æ„å»ºå›¾åšå¼ˆåœº(game arena)ï¼Œå®ç°åœ¨æ— é™è½¨è¿¹è®¾ç½®ä¸­åº”ç”¨æœ‰é™è½¨è¿¹æŠ€æœ¯å¹¶ä¿æŒå®Œå…¨çš„ $LTL$ è¡¨è¾¾åŠ›ã€‚ç ”ç©¶é¦–å…ˆå®ç°äº†ä¸€ä¸ªåŸºäº Emerson-Lei games çš„ç¬¦å·åŒ–æ±‚è§£å™¨ï¼Œè¯¥æ±‚è§£å™¨åœ¨æ±‚è§£å‰ä¼šå°† guarantee å’Œ safety ç­‰ä½é˜¶å±æ€§çº¦ç®€ä¸ºæ›´é«˜é˜¶çš„å±æ€§ã€‚éšåï¼Œè®ºæ–‡å¼•å…¥äº† Manna-Pnueli gamesï¼Œé€šè¿‡å°† Manna-Pnueli ç›®æ ‡åŸç”ŸåµŒå…¥åšå¼ˆåœºï¼Œå¹¶åˆ©ç”¨ç®€å• Emerson-Lei games çš„æœ‰å‘æ— ç¯å›¾(DAG)ç»„åˆè¿›è¡Œæ±‚è§£ï¼Œä»è€Œå®ç°äº†è¯æ˜ä¸Šæ›´é«˜æ•ˆçš„æ–¹æ³•ã€‚å®éªŒè¯„ä¼°æ˜¾ç¤ºï¼ŒManna-Pnueli games åœ¨å¤šç§ä»£è¡¨æ€§å…¬å¼ä¸Šå…·æœ‰æ˜¾è‘—çš„æ€§èƒ½ä¼˜åŠ¿ã€‚æœ€åï¼Œç ”ç©¶ç»“æœè¡¨æ˜ç»“åˆè¿™ä¸¤ç§åšå¼ˆæ–¹æ³•èƒ½å¤Ÿè¿›ä¸€æ­¥æå‡æ±‚è§£å™¨åœ¨å®é™…åº”ç”¨ä¸­çš„è¡¨ç°ã€‚",
      "categories": [
        "cs.LO",
        "cs.AI",
        "cs.FL"
      ],
      "primary_category": "cs.LO",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.14725v1",
      "published_date": "2025-08-20 14:07:43 UTC",
      "updated_date": "2025-08-20 14:07:43 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T13:00:14.148797+00:00"
    },
    {
      "arxiv_id": "2508.14723v3",
      "title": "Transplant Then Regenerate: A New Paradigm for Text Data Augmentation",
      "title_zh": "å…ˆç§»æ¤åå†ç”Ÿï¼šæ–‡æœ¬æ•°æ®å¢å¼ºçš„æ–°èŒƒå¼",
      "authors": [
        "Guangzhan Wang",
        "Hongyu Zhang",
        "Beijun Shen",
        "Xiaodong Gu"
      ],
      "abstract": "Data augmentation is a critical technique in deep learning. Traditional methods like Back-translation typically focus on lexical-level rephrasing, which primarily produces variations with the same semantics. While large language models (LLMs) have enhanced text augmentation by their \"knowledge emergence\" capability, controlling the style and structure of these outputs remains challenging and requires meticulous prompt engineering. In this paper, we propose LMTransplant, a novel text augmentation paradigm leveraging LLMs. The core idea of LMTransplant is transplant-then-regenerate: incorporating seed text into a context expanded by LLM, and asking the LLM to regenerate a variant based on the expanded context. This strategy allows the model to create more diverse and creative content-level variants by fully leveraging the knowledge embedded in LLMs, while preserving the core attributes of the original text. We evaluate LMTransplant across various text-related tasks, demonstrating its superior performance over existing text augmentation methods. Moreover, LMTransplant demonstrates exceptional scalability as the size of augmented data grows.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†LMTransplantï¼Œè¿™æ˜¯ä¸€ç§åˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹(LLMs)è¿›è¡Œæ–‡æœ¬æ•°æ®å¢å¼ºçš„æ–°å‹èŒƒå¼ï¼Œæ—¨åœ¨å…‹æœä¼ ç»Ÿæ–¹æ³•å¦‚Back-translationä»…é™äºè¯æ±‡çº§æ”¹å†™ä¸”è¯­ä¹‰å•ä¸€çš„å±€é™æ€§ã€‚å…¶æ ¸å¿ƒç†å¿µæ˜¯â€œç§»æ¤åå†ç”Ÿâ€(transplant-then-regenerate)ï¼Œå³å…ˆå°†ç§å­æ–‡æœ¬åµŒå…¥ç”±LLMæ‰©å±•çš„ä¸Šä¸‹æ–‡ä¸­ï¼Œå†è¦æ±‚æ¨¡å‹åŸºäºè¯¥æ‰©å±•èƒŒæ™¯ç”Ÿæˆå˜ä½“ã€‚è¿™ç§ç­–ç•¥å……åˆ†åˆ©ç”¨äº†LLMsçš„çŸ¥è¯†æ¶Œç°(knowledge emergence)èƒ½åŠ›ï¼Œåœ¨ä¿ç•™åŸå§‹æ–‡æœ¬æ ¸å¿ƒå±æ€§çš„åŒæ—¶ï¼Œåˆ›é€ å‡ºæ›´å…·å¤šæ ·æ€§å’Œåˆ›é€ åŠ›çš„å†…å®¹çº§å˜ä½“ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒLMTransplantåœ¨å¤šç§æ–‡æœ¬ç›¸å…³ä»»åŠ¡ä¸­å‡ä¼˜äºç°æœ‰çš„æ•°æ®å¢å¼ºæ–¹æ³•ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•åœ¨å¢å¼ºæ•°æ®é‡å¢é•¿æ—¶è¡¨ç°å‡ºå“è¶Šçš„å¯æ‰©å±•æ€§(scalability)ï¼Œä¸ºæ·±åº¦å­¦ä¹ é¢†åŸŸæä¾›äº†æ›´é«˜æ•ˆçš„æ–‡æœ¬å¢å¼ºæ–¹æ¡ˆã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted by EMNLP 2025",
      "pdf_url": "https://arxiv.org/pdf/2508.14723v3",
      "published_date": "2025-08-20 14:05:18 UTC",
      "updated_date": "2025-09-14 04:08:17 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T13:00:16.320569+00:00"
    },
    {
      "arxiv_id": "2509.00029v1",
      "title": "From Sound to Sight: Towards AI-authored Music Videos",
      "title_zh": "ä»å¬è§‰åˆ°è§†è§‰ï¼šè¿ˆå‘ AI åˆ›ä½œçš„éŸ³ä¹è§†é¢‘",
      "authors": [
        "Leo Vitasovic",
        "Stella GraÃŸhof",
        "Agnes Mercedes Kloft",
        "Ville V. Lehtola",
        "Martin Cunneen",
        "Justyna Starostka",
        "Glenn McGarry",
        "Kun Li",
        "Sami S. Brandt"
      ],
      "abstract": "Conventional music visualisation systems rely on handcrafted ad hoc transformations of shapes and colours that offer only limited expressiveness. We propose two novel pipelines for automatically generating music videos from any user-specified, vocal or instrumental song using off-the-shelf deep learning models. Inspired by the manual workflows of music video producers, we experiment on how well latent feature-based techniques can analyse audio to detect musical qualities, such as emotional cues and instrumental patterns, and distil them into textual scene descriptions using a language model. Next, we employ a generative model to produce the corresponding video clips. To assess the generated videos, we identify several critical aspects and design and conduct a preliminary user evaluation that demonstrates storytelling potential, visual coherency and emotional alignment with the music. Our findings underscore the potential of latent feature techniques and deep generative models to expand music visualisation beyond traditional approaches.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸¤ç§åˆ›æ–°çš„æµæ°´çº¿(pipelines)ï¼Œæ—¨åœ¨åˆ©ç”¨ç°æˆçš„æ·±åº¦å­¦ä¹ æ¨¡å‹æ ¹æ®ä»»ä½•ç”¨æˆ·æŒ‡å®šçš„å£°ä¹æˆ–å™¨ä¹æ­Œæ›²è‡ªåŠ¨ç”ŸæˆéŸ³ä¹è§†é¢‘ã€‚å—ä¸“ä¸šéŸ³ä¹è§†é¢‘åˆ¶ä½œè€…æ‰‹å·¥å·¥ä½œæµçš„å¯å‘ï¼Œè¯¥ç ”ç©¶æ¢è®¨äº†åŸºäºæ½œç‰¹å¾(latent feature-based)çš„æŠ€æœ¯å¦‚ä½•åˆ†æéŸ³é¢‘ä»¥æ£€æµ‹æƒ…æ„Ÿçº¿ç´¢å’Œä¹å™¨æ¨¡å¼ï¼Œå¹¶ä½¿ç”¨è¯­è¨€æ¨¡å‹(language model)å°†å…¶è½¬åŒ–ä¸ºæ–‡æœ¬åœºæ™¯æè¿°ã€‚éšåï¼Œç³»ç»Ÿé‡‡ç”¨ç”Ÿæˆæ¨¡å‹(generative model)åˆ¶ä½œå‡ºå¯¹åº”çš„è§†é¢‘å‰ªè¾‘ã€‚é€šè¿‡åˆæ­¥çš„ç”¨æˆ·è¯„ä¼°ï¼Œè¯¥ç ”ç©¶éªŒè¯äº†ç”Ÿæˆçš„è§†é¢‘åœ¨å™äº‹æ½œåŠ›ã€è§†è§‰è¿è´¯æ€§ä»¥åŠä¸éŸ³ä¹çš„æƒ…æ„Ÿå¯¹é½æ–¹é¢çš„è¡¨ç°ã€‚ç ”ç©¶ç»“æœè¡¨æ˜ï¼Œç»“åˆæ½œç‰¹å¾æŠ€æœ¯ä¸æ·±åº¦ç”Ÿæˆæ¨¡å‹èƒ½å¤Ÿæœ‰æ•ˆçªç ´ä¼ ç»ŸéŸ³ä¹å¯è§†åŒ–çš„å±€é™æ€§ï¼Œä¸ºAIåˆ›ä½œå…·æœ‰è¡¨ç°åŠ›çš„è§†è§‰å†…å®¹å¼€è¾Ÿäº†æ–°è·¯å¾„ã€‚",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.MM",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "1st Workshop on Generative AI for Storytelling (AISTORY), 2025",
      "pdf_url": "https://arxiv.org/pdf/2509.00029v1",
      "published_date": "2025-08-20 13:54:53 UTC",
      "updated_date": "2025-08-20 13:54:53 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T13:00:19.329415+00:00"
    },
    {
      "arxiv_id": "2508.14710v1",
      "title": "Data-Driven Probabilistic Evaluation of Logic Properties with PAC-Confidence on Mealy Machines",
      "title_zh": "Mealy æœºä¸Šå…·æœ‰ PAC ç½®ä¿¡åº¦çš„é€»è¾‘å±æ€§æ•°æ®é©±åŠ¨æ¦‚ç‡è¯„ä¼°",
      "authors": [
        "Swantje Plambeck",
        "Ali Salamati",
        "Eyke Huellermeier",
        "Goerschwin Fey"
      ],
      "abstract": "Cyber-Physical Systems (CPS) are complex systems that require powerful models for tasks like verification, diagnosis, or debugging. Often, suitable models are not available and manual extraction is difficult. Data-driven approaches then provide a solution to, e.g., diagnosis tasks and verification problems based on data collected from the system. In this paper, we consider CPS with a discrete abstraction in the form of a Mealy machine. We propose a data-driven approach to determine the safety probability of the system on a finite horizon of n time steps. The approach is based on the Probably Approximately Correct (PAC) learning paradigm. Thus, we elaborate a connection between discrete logic and probabilistic reachability analysis of systems, especially providing an additional confidence on the determined probability. The learning process follows an active learning paradigm, where new learning data is sampled in a guided way after an initial learning set is collected. We validate the approach with a case study on an automated lane-keeping system.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ä¿¡æ¯ç‰©ç†ç³»ç»Ÿ(CPS)ä¸­æ¨¡å‹éš¾ä»¥æ‰‹åŠ¨æå–çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§æ•°æ®é©±åŠ¨çš„æ–¹æ³•æ¥è¯„ä¼°ä»¥ Mealy machine ä¸ºç¦»æ•£æŠ½è±¡çš„ç³»ç»Ÿå®‰å…¨æ€§ã€‚è¯¥æ–¹æ¡ˆåŸºäº Probably Approximately Correct (PAC) å­¦ä¹ èŒƒå¼ï¼Œæ—¨åœ¨ç¡®å®šç³»ç»Ÿåœ¨æœ‰é™æ—¶é—´æ­¥é•¿ n å†…çš„å®‰å…¨æ¦‚ç‡ï¼Œå¹¶ä¸ºè¯¥æ¦‚ç‡æä¾›é¢å¤–çš„ç½®ä¿¡åº¦(confidence)ã€‚é€šè¿‡å°†ç¦»æ•£é€»è¾‘ä¸ç³»ç»Ÿçš„æ¦‚ç‡å¯è¾¾æ€§åˆ†æ(probabilistic reachability analysis)ç›¸ç»“åˆï¼Œè¯¥æ–¹æ³•å®ç°äº†å¯¹ç³»ç»Ÿå±æ€§çš„å®šé‡è¯„ä¼°ã€‚å­¦ä¹ è¿‡ç¨‹é‡‡ç”¨äº†ä¸»åŠ¨å­¦ä¹ (active learning)èŒƒå¼ï¼Œé€šè¿‡å¼•å¯¼å¼é‡‡æ ·æ–°æ•°æ®æ¥ä¸æ–­ä¼˜åŒ–æ¨¡å‹ã€‚æœ€åï¼Œç ”ç©¶é€šè¿‡ä¸€ä¸ªè‡ªåŠ¨è½¦é“ä¿æŒç³»ç»Ÿ(automated lane-keeping system)çš„æ¡ˆä¾‹ç ”ç©¶éªŒè¯äº†è¯¥æ–¹æ³•çš„æœ‰æ•ˆæ€§ï¼Œè¯æ˜äº†å…¶åœ¨ CPS éªŒè¯ä¸è¯Šæ–­ä»»åŠ¡ä¸­çš„åº”ç”¨ä»·å€¼ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.14710v1",
      "published_date": "2025-08-20 13:38:52 UTC",
      "updated_date": "2025-08-20 13:38:52 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T13:00:33.726395+00:00"
    },
    {
      "arxiv_id": "2508.14706v1",
      "title": "ShizhenGPT: Towards Multimodal LLMs for Traditional Chinese Medicine",
      "title_zh": "ShizhenGPTï¼šé¢å‘ä¸­åŒ»è¯çš„å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹",
      "authors": [
        "Junying Chen",
        "Zhenyang Cai",
        "Zhiheng Liu",
        "Yunjin Yang",
        "Rongsheng Wang",
        "Qingying Xiao",
        "Xiangyi Feng",
        "Zhan Su",
        "Jing Guo",
        "Xiang Wan",
        "Guangjun Yu",
        "Haizhou Li",
        "Benyou Wang"
      ],
      "abstract": "Despite the success of large language models (LLMs) in various domains, their potential in Traditional Chinese Medicine (TCM) remains largely underexplored due to two critical barriers: (1) the scarcity of high-quality TCM data and (2) the inherently multimodal nature of TCM diagnostics, which involve looking, listening, smelling, and pulse-taking. These sensory-rich modalities are beyond the scope of conventional LLMs. To address these challenges, we present ShizhenGPT, the first multimodal LLM tailored for TCM. To overcome data scarcity, we curate the largest TCM dataset to date, comprising 100GB+ of text and 200GB+ of multimodal data, including 1.2M images, 200 hours of audio, and physiological signals. ShizhenGPT is pretrained and instruction-tuned to achieve deep TCM knowledge and multimodal reasoning. For evaluation, we collect recent national TCM qualification exams and build a visual benchmark for Medicinal Recognition and Visual Diagnosis. Experiments demonstrate that ShizhenGPT outperforms comparable-scale LLMs and competes with larger proprietary models. Moreover, it leads in TCM visual understanding among existing multimodal LLMs and demonstrates unified perception across modalities like sound, pulse, smell, and vision, paving the way toward holistic multimodal perception and diagnosis in TCM. Datasets, models, and code are publicly available. We hope this work will inspire further exploration in this field.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ShizhenGPTï¼Œè¿™æ˜¯é¦–ä¸ªä¸“ä¸ºä¸­åŒ»(Traditional Chinese Medicine, TCM)é‡èº«å®šåˆ¶çš„å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹(Multimodal LLM)ï¼Œæ—¨åœ¨è§£å†³ä¸­åŒ»è¯Šæ–­ä¸­é«˜è´¨é‡æ•°æ®ç¨€ç¼ºä»¥åŠä¼ ç»Ÿæ¨¡å‹éš¾ä»¥å¤„ç†â€œæœ›é—»é—®åˆ‡â€å¤šæ¨¡æ€æ„ŸçŸ¥ä¿¡æ¯çš„æŒ‘æˆ˜ã€‚ä¸ºäº†å…‹æœæ•°æ®ç“¶é¢ˆï¼Œç ”ç©¶å›¢é˜Ÿæ„å»ºäº†ç›®å‰è§„æ¨¡æœ€å¤§çš„ä¸­åŒ»æ•°æ®é›†ï¼ŒåŒ…å«è¶…è¿‡100GBçš„æ–‡æœ¬å’Œ200GBçš„å¤šæ¨¡æ€æ•°æ®ï¼Œæ¶µç›–äº†120ä¸‡å¼ å›¾åƒã€200å°æ—¶éŸ³é¢‘åŠå„ç±»ç”Ÿç†ä¿¡å·ã€‚ShizhenGPT ç»è¿‡é¢„è®­ç»ƒå’ŒæŒ‡ä»¤å¾®è°ƒ(Instruction-tuning)ï¼Œå®ç°äº†æ·±åšçš„ä¸­åŒ»çŸ¥è¯†å‚¨å¤‡ä¸å¤šæ¨¡æ€æ¨ç†èƒ½åŠ›ï¼Œèƒ½å¤Ÿå¯¹å£°éŸ³ã€è„‰æã€æ°”å‘³å’Œè§†è§‰ä¿¡æ¯è¿›è¡Œç»Ÿä¸€æ„ŸçŸ¥ã€‚é€šè¿‡å›½å®¶ä¸­åŒ»èµ„æ ¼è€ƒè¯•åŠè¯ç‰©è¯†åˆ«(Medicinal Recognition)ä¸è§†è§‰è¯Šæ–­(Visual Diagnosis)åŸºå‡†æµ‹è¯•çš„è¯„ä¼°ï¼Œç»“æœæ˜¾ç¤º ShizhenGPT çš„æ€§èƒ½ä¼˜äºåŒè§„æ¨¡æ¨¡å‹ï¼Œå¹¶åœ¨ä¸­åŒ»è§†è§‰ç†è§£é¢†åŸŸå¤„äºé¢†å…ˆåœ°ä½ã€‚è¯¥å·¥ä½œå±•ç¤ºäº†å¤šæ¨¡æ€æ¨¡å‹åœ¨å®ç°ä¸­åŒ»å…¨æ„ŸçŸ¥è¾…åŠ©è¯Šæ–­æ–¹é¢çš„å·¨å¤§æ½œåŠ›ï¼Œä¸ºè¯¥é¢†åŸŸçš„è¿›ä¸€æ­¥æ¢ç´¢å¥ å®šäº†åŸºç¡€ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CV",
        "cs.LG",
        "cs.MM"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.14706v1",
      "published_date": "2025-08-20 13:30:20 UTC",
      "updated_date": "2025-08-20 13:30:20 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T13:00:29.733371+00:00"
    },
    {
      "arxiv_id": "2508.14705v2",
      "title": "Learning in Repeated Multi-Objective Stackelberg Games with Payoff Manipulation",
      "title_zh": "å­˜åœ¨æ”¶ç›Šæ“çºµçš„é‡å¤å¤šç›®æ ‡ Stackelberg åšå¼ˆå­¦ä¹ ",
      "authors": [
        "Phurinut Srisawad",
        "Juergen Branke",
        "Long Tran-Thanh"
      ],
      "abstract": "We study payoff manipulation in repeated multi-objective Stackelberg games, where a leader may strategically influence a follower's deterministic best response, e.g., by offering a share of their own payoff. We assume that the follower's utility function, representing preferences over multiple objectives, is unknown but linear, and its weight parameter must be inferred through interaction. This introduces a sequential decision-making challenge for the leader, who must balance preference elicitation with immediate utility maximisation. We formalise this problem and propose manipulation policies based on expected utility (EU) and long-term expected utility (longEU), which guide the leader in selecting actions and offering incentives that trade off short-term gains with long-term impact. We prove that under infinite repeated interactions, longEU converges to the optimal manipulation. Empirical results across benchmark environments demonstrate that our approach improves cumulative leader utility while promoting mutually beneficial outcomes, all without requiring explicit negotiation or prior knowledge of the follower's utility function.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å…·æœ‰æ”¯ä»˜æ“çºµ(Payoff Manipulation)çš„é‡å¤å¤šç›®æ ‡ Stackelberg Gamesï¼Œå…¶ä¸­é¢†å¯¼è€…é€šè¿‡ç­–ç•¥æ€§åœ°æä¾›æ”¶ç›Šä»½é¢ç­‰æ‰‹æ®µå½±å“è¿½éšè€…çš„æœ€ä½³å“åº”ã€‚åœ¨è¿½éšè€…å¤šç›®æ ‡åå¥½æƒé‡æœªçŸ¥ä¸”éœ€é€šè¿‡äº¤äº’æ¨æ–­çš„èƒŒæ™¯ä¸‹ï¼Œé¢†å¯¼è€…é¢ä¸´ç€åå¥½è¯±å¯¼(Preference Elicitation)ä¸å³æ—¶æ•ˆç”¨æœ€å¤§åŒ–ä¹‹é—´çš„æƒè¡¡æŒ‘æˆ˜ã€‚ä¸ºæ­¤ï¼Œä½œè€…æå‡ºäº†åŸºäºæœŸæœ›æ•ˆç”¨(Expected Utility, EU)å’Œé•¿æœŸæœŸæœ›æ•ˆç”¨(long-term Expected Utility, longEU)çš„æ“çºµç­–ç•¥ï¼ŒæŒ‡å¯¼é¢†å¯¼è€…åœ¨åŠ¨ä½œé€‰æ‹©å’Œæ¿€åŠ±æä¾›ä¸­æƒè¡¡çŸ­æœŸå¢ç›Šä¸é•¿æœŸå½±å“ã€‚ç†è®ºè¯æ˜åœ¨æ— é™æ¬¡äº¤äº’ä¸‹ï¼ŒlongEU ç­–ç•¥èƒ½å¤Ÿæ”¶æ•›è‡³æœ€ä¼˜æ“çºµæ–¹æ¡ˆã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨æ— éœ€æ˜¾å¼è°ˆåˆ¤æˆ–å…ˆéªŒçŸ¥è¯†çš„æƒ…å†µä¸‹ï¼Œä¸ä»…æ˜¾è‘—æå‡äº†é¢†å¯¼è€…çš„ç´¯ç§¯æ•ˆç”¨ï¼Œè¿˜ä¿ƒè¿›äº†äº’åˆ©å…±èµ¢ç»“æœçš„è¾¾æˆã€‚",
      "categories": [
        "cs.GT",
        "cs.AI"
      ],
      "primary_category": "cs.GT",
      "comment": "Extended version of the paper accepted at the 28th European Conference on Artificial Intelligence (ECAI 2025); Paper ID: M2635, Added more experiments in the Appendix",
      "pdf_url": "https://arxiv.org/pdf/2508.14705v2",
      "published_date": "2025-08-20 13:29:24 UTC",
      "updated_date": "2025-08-26 15:07:29 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T13:00:32.818336+00:00"
    },
    {
      "arxiv_id": "2508.14704v1",
      "title": "MCP-Universe: Benchmarking Large Language Models with Real-World Model Context Protocol Servers",
      "title_zh": "MCP-Universeï¼šåŸºäºçœŸå®ä¸–ç•Œæ¨¡å‹ä¸Šä¸‹æ–‡åè®®æœåŠ¡ç«¯çš„å¤§è¯­è¨€æ¨¡å‹åŸºå‡†æµ‹è¯•",
      "authors": [
        "Ziyang Luo",
        "Zhiqi Shen",
        "Wenzhuo Yang",
        "Zirui Zhao",
        "Prathyusha Jwalapuram",
        "Amrita Saha",
        "Doyen Sahoo",
        "Silvio Savarese",
        "Caiming Xiong",
        "Junnan Li"
      ],
      "abstract": "The Model Context Protocol has emerged as a transformative standard for connecting large language models to external data sources and tools, rapidly gaining adoption across major AI providers and development platforms. However, existing benchmarks are overly simplistic and fail to capture real application challenges such as long-horizon reasoning and large, unfamiliar tool spaces. To address this critical gap, we introduce MCP-Universe, the first comprehensive benchmark specifically designed to evaluate LLMs in realistic and hard tasks through interaction with real-world MCP servers. Our benchmark encompasses 6 core domains spanning 11 different MCP servers: Location Navigation, Repository Management, Financial Analysis, 3D Design, Browser Automation, and Web Searching. To ensure rigorous evaluation, we implement execution-based evaluators, including format evaluators for agent format compliance, static evaluators for time-invariant content matching, and dynamic evaluators that automatically retrieve real-time ground truth for temporally sensitive tasks. Through extensive evaluation of leading LLMs, we find that even SOTA models such as GPT-5 (43.72%), Grok-4 (33.33%) and Claude-4.0-Sonnet (29.44%) exhibit significant performance limitations. In addition, our benchmark poses a significant long-context challenge for LLM agents, as the number of input tokens increases rapidly with the number of interaction steps. Moreover, it introduces an unknown-tools challenge, as LLM agents often lack familiarity with the precise usage of the MCP servers. Notably, enterprise-level agents like Cursor cannot achieve better performance than standard ReAct frameworks. Beyond evaluation, we open-source our extensible evaluation framework with UI support, enabling researchers and practitioners to seamlessly integrate new agents and MCP servers while fostering innovation in the rapidly evolving MCP ecosystem.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¨å‡ºäº† MCP-Universeï¼Œè¿™æ˜¯é¦–ä¸ªä¸“é—¨ç”¨äºè¯„ä¼°å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨ä¸çœŸå® Model Context Protocol (MCP) æœåŠ¡å™¨äº¤äº’æ—¶å¤„ç†å¤æ‚ä»»åŠ¡èƒ½åŠ›çš„å…¨é¢åŸºå‡†æµ‹è¯•ã€‚ä¸ºäº†è§£å†³ç°æœ‰åŸºå‡†æµ‹è¯•è¿‡äºç®€åŒ–ã€æ— æ³•æ•æ‰é•¿ç¨‹æ¨ç†åŠå¤§è§„æ¨¡é™Œç”Ÿå·¥å…·ç©ºé—´æŒ‘æˆ˜çš„é—®é¢˜ï¼ŒMCP-Universe æ¶µç›–äº†åŒ…æ‹¬ä½ç½®å¯¼èˆªã€ä»“åº“ç®¡ç†å’Œ 3D è®¾è®¡åœ¨å†…çš„ 6 ä¸ªæ ¸å¿ƒé¢†åŸŸã€‚è¯¥æ¡†æ¶é‡‡ç”¨äº†åŸºäºæ‰§è¡Œçš„è¯„ä¼°å™¨ï¼Œé€šè¿‡æ ¼å¼ã€é™æ€åŠåŠ¨æ€å®æ—¶çœŸå€¼æ£€ç´¢ç¡®ä¿è¯„ä¼°çš„ä¸¥è°¨æ€§ã€‚è¯„ä¼°ç»“æœè¡¨æ˜ï¼Œå³ä½¿æ˜¯ GPT-5ã€Grok-4 å’Œ Claude-4.0-Sonnet ç­‰ SOTA æ¨¡å‹åœ¨åº”å¯¹çœŸå® MCP ç¯å¢ƒæ—¶ä»é¢ä¸´æ˜¾è‘—çš„æ€§èƒ½ç“¶é¢ˆã€‚ç ”ç©¶è¿›ä¸€æ­¥æ­ç¤ºäº† LLM æ™ºèƒ½ä½“åœ¨å¤„ç†é•¿ä¸Šä¸‹æ–‡ï¼ˆlong-contextï¼‰ä»¥åŠå¯¹æœªçŸ¥å·¥å…·ï¼ˆunknown-toolsï¼‰ä½¿ç”¨ä¸ç†Ÿæ‚‰ç­‰æ ¸å¿ƒæŒ‘æˆ˜ï¼Œå¹¶å‘ç°ä¼ä¸šçº§æ™ºèƒ½ä½“å¦‚ Cursor çš„è¡¨ç°å¹¶æœªè¶…è¶Šä¼ ç»Ÿçš„ ReAct æ¡†æ¶ã€‚æœ€åï¼Œè¯¥é¡¹ç›®å¼€æºäº†æ”¯æŒ UI çš„å¯æ‰©å±•è¯„ä¼°æ¡†æ¶ï¼Œä¸º MCP ç”Ÿæ€ç³»ç»Ÿçš„æŠ€æœ¯è¿­ä»£å’Œæ–°æ™ºèƒ½ä½“çš„é›†æˆæä¾›äº†æœ‰åŠ›å·¥å…·ã€‚",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "Website: https://mcp-universe.github.io",
      "pdf_url": "https://arxiv.org/pdf/2508.14704v1",
      "published_date": "2025-08-20 13:28:58 UTC",
      "updated_date": "2025-08-20 13:28:58 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T13:00:34.118576+00:00"
    },
    {
      "arxiv_id": "2508.14699v1",
      "title": "Foe for Fraud: Transferable Adversarial Attacks in Credit Card Fraud Detection",
      "title_zh": "æ¬ºè¯ˆä¹‹æ•Œï¼šä¿¡ç”¨å¡æ¬ºè¯ˆæ£€æµ‹ä¸­çš„å¯è¿ç§»å¯¹æŠ—æ”»å‡»",
      "authors": [
        "Jan Lum Fok",
        "Qingwen Zeng",
        "Shiping Chen",
        "Oscar Fawkes",
        "Huaming Chen"
      ],
      "abstract": "Credit card fraud detection (CCFD) is a critical application of Machine Learning (ML) in the financial sector, where accurately identifying fraudulent transactions is essential for mitigating financial losses. ML models have demonstrated their effectiveness in fraud detection task, in particular with the tabular dataset. While adversarial attacks have been extensively studied in computer vision and deep learning, their impacts on the ML models, particularly those trained on CCFD tabular datasets, remains largely unexplored. These latent vulnerabilities pose significant threats to the security and stability of the financial industry, especially in high-value transactions where losses could be substantial. To address this gap, in this paper, we present a holistic framework that investigate the robustness of CCFD ML model against adversarial perturbations under different circumstances. Specifically, the gradient-based attack methods are incorporated into the tabular credit card transaction data in both black- and white-box adversarial attacks settings. Our findings confirm that tabular data is also susceptible to subtle perturbations, highlighting the need for heightened awareness among financial technology practitioners regarding ML model security and trustworthiness. Furthermore, the experiments by transferring adversarial samples from gradient-based attack method to non-gradient-based models also verify our findings. Our results demonstrate that such attacks remain effective, emphasizing the necessity of developing robust defenses for CCFD algorithms.",
      "tldr_zh": "è¿™é¡¹ç ”ç©¶é’ˆå¯¹ä¿¡ç”¨å¡æ¬ºè¯ˆæ£€æµ‹ (Credit Card Fraud Detection, CCFD) ä¸­çš„æœºå™¨å­¦ä¹ æ¨¡å‹å®‰å…¨æ€§å±•å¼€äº†æ·±å…¥æ¢è®¨ã€‚è™½ç„¶å¯¹æŠ—æ€§æ”»å‡» (Adversarial Attacks) åœ¨è®¡ç®—æœºè§†è§‰é¢†åŸŸå·²æœ‰å¹¿æ³›ç ”ç©¶ï¼Œä½†åœ¨ CCFD çš„è¡¨æ ¼æ•°æ® (Tabular Data) ä¸Šçš„å½±å“å°šä¸æ˜ç¡®ã€‚ä¸ºäº†å¡«è¡¥è¿™ä¸€ç©ºç™½ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ä¸ªç»¼åˆæ¡†æ¶ï¼Œç ”ç©¶ CCFD æ¨¡å‹åœ¨ä¸åŒæƒ…å†µä¸‹çš„é²æ£’æ€§ (Robustness)ã€‚é€šè¿‡å°†åŸºäºæ¢¯åº¦çš„æ”»å‡»æ–¹æ³• (Gradient-based Attack Methods) åº”ç”¨äºè¡¨æ ¼äº¤æ˜“æ•°æ®ï¼Œåœ¨ç™½ç›’å’Œé»‘ç›’è®¾ç½®ä¸‹è¿›è¡Œäº†å®éªŒã€‚ç ”ç©¶ç»“æœè¯å®ï¼Œè¡¨æ ¼æ•°æ®åŒæ ·å®¹æ˜“å—åˆ°å¾®å¦™æ‰°åŠ¨çš„å½±å“ï¼Œä¸”è¿™äº›å¯¹æŠ—æ€§æ ·æœ¬å¯ä»¥æˆåŠŸä»åŸºäºæ¢¯åº¦çš„æ”»å‡»æ–¹æ³•è¿ç§»åˆ°éæ¢¯åº¦æ¨¡å‹ä¸­ã€‚è¯¥å‘ç°æ­ç¤ºäº†é‡‘èç§‘æŠ€é¢†åŸŸæœºå™¨å­¦ä¹ æ¨¡å‹çš„æ½œåœ¨å®‰å…¨é£é™©ï¼Œå¹¶å¼ºè°ƒäº†å¼€å‘å¼ºé²æ£’æ€§é˜²å¾¡æœºåˆ¶ä»¥æå‡ CCFD ç®—æ³•å¯é æ€§çš„å¿…è¦æ€§ã€‚",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.14699v1",
      "published_date": "2025-08-20 13:23:28 UTC",
      "updated_date": "2025-08-20 13:23:28 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T13:00:33.227844+00:00"
    },
    {
      "arxiv_id": "2508.15859v1",
      "title": "Beyond Individuals: Collective Predictive Coding for Memory, Attention, and the Emergence of Language",
      "title_zh": "è¶…è¶Šä¸ªä½“ï¼šè®°å¿†ã€æ³¨æ„åŠ›å’Œè¯­è¨€æ¶Œç°çš„é›†ä½“é¢„æµ‹ç¼–ç ",
      "authors": [
        "Tadahiro Taniguchi"
      ],
      "abstract": "This commentary extends the discussion by Parr et al. on memory and attention beyond individual cognitive systems. From the perspective of the Collective Predictive Coding (CPC) hypothesis -- a framework for understanding these faculties and the emergence of language at the group level -- we introduce a hypothetical idea: that language, with its embedded distributional semantics, serves as a collectively formed external representation. CPC generalises the concepts of individual memory and attention to the collective level. This offers a new perspective on how shared linguistic structures, which may embrace collective world models learned through next-word prediction, emerge from and shape group-level cognition.",
      "tldr_zh": "è¯¥ç ”ç©¶åœ¨Parrç­‰äººå…³äºMemoryå’ŒAttentionçš„è®¨è®ºåŸºç¡€ä¸Šï¼Œå°†å…¶ä»ä¸ªä½“è®¤çŸ¥ç³»ç»Ÿæ‰©å±•åˆ°äº†é›†ä½“è®¤çŸ¥ç³»ç»Ÿã€‚ç ”ç©¶å¼•å…¥äº†é›†ä½“é¢„æµ‹ç¼–ç (Collective Predictive Coding, CPC)å‡è¯´ï¼Œè¿™æ˜¯ä¸€ç§ç”¨äºåœ¨ç¾¤ä½“å±‚é¢ç†è§£è¿™äº›è®¤çŸ¥èƒ½åŠ›ä»¥åŠè¯­è¨€èµ·æºçš„æ¡†æ¶ã€‚è®ºæ–‡æå‡ºäº†ä¸€ä¸ªæ ¸å¿ƒè§‚ç‚¹ï¼šå…·æœ‰åµŒå…¥å¼åˆ†å¸ƒå¼è¯­ä¹‰(Distributional Semantics)çš„è¯­è¨€å……å½“äº†ä¸€ç§é›†ä½“å½¢æˆçš„å¤–éƒ¨è¡¨å¾ã€‚CPCå°†ä¸ªä½“çš„Memoryå’ŒAttentionæ¦‚å¿µæ³›åŒ–åˆ°é›†ä½“å±‚é¢ï¼Œæ¢è®¨äº†å…±äº«è¯­è¨€ç»“æ„å¦‚ä½•ä»ç¾¤ä½“è®¤çŸ¥ä¸­äº§ç”Ÿå¹¶åè¿‡æ¥å¡‘é€ ç¾¤ä½“è®¤çŸ¥ã€‚è¿™äº›ç»“æ„å¯èƒ½æ¶µç›–äº†é€šè¿‡ä¸‹ä¸€è¯é¢„æµ‹(Next-word prediction)å­¦ä¹ åˆ°çš„é›†ä½“ä¸–ç•Œæ¨¡å‹(Collective World Models)ï¼Œä¸ºç†è§£è¯­è¨€æ¼”åŒ–ä¸é›†ä½“è®¤çŸ¥çš„äº’åŠ¨å…³ç³»æä¾›äº†å…¨æ–°çš„ç†è®ºè§†è§’ã€‚",
      "categories": [
        "q-bio.NC",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "q-bio.NC",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.15859v1",
      "published_date": "2025-08-20 13:20:17 UTC",
      "updated_date": "2025-08-20 13:20:17 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T13:00:45.035835+00:00"
    },
    {
      "arxiv_id": "2508.14689v3",
      "title": "ECHO: Frequency-aware Hierarchical Encoding for Variable-length Signals",
      "title_zh": "ECHOï¼šé¢å‘å˜é•¿ä¿¡å·çš„é¢‘ç‡æ„ŸçŸ¥åˆ†å±‚ç¼–ç ",
      "authors": [
        "Yucong Zhang",
        "Juan Liu",
        "Ming Li"
      ],
      "abstract": "Pre-trained foundation models have demonstrated remarkable success in audio, vision and language, yet their potential for general machine signal modeling with arbitrary sampling rates-covering acoustic, vibration, and other industrial sensor data-remains under-explored. In this work, we propose a novel foundation model ECHO that integrates an advanced band-split architecture with frequency positional embeddings, enabling spectral localization across arbitrary sampling configurations. Moreover, the model incorporates sliding patches to support inputs of variable length without padding or cropping, producing a concise embedding that retains both temporal and spectral fidelity and naturally extends to streaming scenarios. We evaluate our method on various kinds of machine signal datasets, including previous DCASE task 2 challenges (2020-2025), and widely-used industrial signal corpora. Experimental results demonstrate consistent state-of-the-art performance in machine signal anomaly detection and fault classification, confirming the effectiveness and generalization capability of the proposed model. We open-sourced ECHO on https://github.com/yucongzh/ECHO.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† ECHOï¼Œä¸€ç§é¢å‘é€šç”¨æœºå™¨ä¿¡å·å»ºæ¨¡çš„åŸºåº§æ¨¡å‹(foundation model)ï¼Œæ—¨åœ¨è§£å†³å£°å­¦ã€æŒ¯åŠ¨ç­‰å·¥ä¸šä¼ æ„Ÿå™¨æ•°æ®åœ¨ä»»æ„é‡‡æ ·ç‡ä¸‹çš„å»ºæ¨¡éš¾é¢˜ã€‚ECHO é›†æˆäº†å…ˆè¿›çš„å¸¦å†…æ‹†åˆ†(band-split)æ¶æ„ä¸é¢‘ç‡ä½ç½®åµŒå…¥(frequency positional embeddings)ï¼Œå®ç°äº†è·¨é‡‡æ ·é…ç½®çš„ç²¾ç¡®é¢‘è°±å®šä½ã€‚æ­¤å¤–ï¼Œæ¨¡å‹é€šè¿‡å¼•å…¥æ»‘åŠ¨è¡¥ä¸(sliding patches)æ”¯æŒå˜é•¿è¾“å…¥ï¼Œæ— éœ€è¿›è¡Œå¡«å……(padding)æˆ–è£å‰ª(cropping)ï¼Œä»è€Œåœ¨ä¿ç•™æ—¶é¢‘ä¿çœŸåº¦çš„åŒæ—¶è‡ªç„¶æ‰©å±•è‡³æµå¼å¤„ç†åœºæ™¯ã€‚åœ¨ DCASE æŒ‘æˆ˜èµ›(2020-2025)åŠå¤šç§å·¥ä¸šä¿¡å·æ•°æ®é›†ä¸Šçš„è¯„ä¼°ç»“æœæ˜¾ç¤ºï¼ŒECHO åœ¨æœºå™¨ä¿¡å·å¼‚å¸¸æ£€æµ‹(anomaly detection)å’Œæ•…éšœåˆ†ç±»(fault classification)ä»»åŠ¡ä¸­å‡è¾¾åˆ°äº† SOTA æ€§èƒ½ã€‚è¯¥ç ”ç©¶å……åˆ†éªŒè¯äº†æ‰€ææ¨¡å‹åœ¨å¤„ç†å˜é•¿å·¥ä¸šä¿¡å·æ—¶çš„æœ‰æ•ˆæ€§ä¸æ³›åŒ–èƒ½åŠ›ï¼Œå¹¶å·²å¼€æºç›¸å…³ä»£ç ã€‚",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.LG",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "submitted to ICASSP 2026",
      "pdf_url": "https://arxiv.org/pdf/2508.14689v3",
      "published_date": "2025-08-20 13:10:44 UTC",
      "updated_date": "2025-09-27 10:05:10 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T13:00:44.225293+00:00"
    },
    {
      "arxiv_id": "2508.19263v1",
      "title": "Lossless Compression of Neural Network Components: Weights, Checkpoints, and K/V Caches in Low-Precision Formats",
      "title_zh": "ç¥ç»ç½‘ç»œç»„ä»¶çš„æ— æŸå‹ç¼©ï¼šä½ç²¾åº¦æ ¼å¼ä¸‹çš„æƒé‡ã€æ£€æŸ¥ç‚¹åŠ K/V ç¼“å­˜",
      "authors": [
        "Anat Heilper",
        "Doron Singer"
      ],
      "abstract": "As deep learning models grow and deployment becomes more widespread, reducing the storage and transmission costs of neural network weights has become increasingly important. While prior work such as ZipNN has shown that lossless compression methods - particularly those based on Huffman encoding floating-point exponents can significantly reduce model sizes, these techniques have primarily been applied to higher-precision formats such as FP32 and BF16. In this work, we extend the ZipNN approach to lower-precision floating-point formats, specifically FP8 and FP4, which are gaining popularity for efficient inference. We design a compression method that separates and compresses the exponent and mantissa components independently using entropy coding. Our evaluation shows compression ratios up to 62% for BF16 and 83% for FP8. We also investigate the compressibility of key-value (K/V) cache tensors used in large language models (LLMs), finding that they, too, exhibit compressible patterns, enabling memory savings during deployment.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹æ·±åº¦å­¦ä¹ æ¨¡å‹å­˜å‚¨ä¸ä¼ è¾“æˆæœ¬æ—¥ç›Šå¢åŠ çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§é’ˆå¯¹ç¥ç»ç½‘ç»œæƒé‡ã€æ£€æŸ¥ç‚¹åŠ K/V cache çš„æ— æŸå‹ç¼©æ–¹æ³•ã€‚ç ”ç©¶äººå‘˜å°† ZipNN æ–¹æ³•ä» FP32 å’Œ BF16 æ‰©å±•åˆ°äº† FP8 å’Œ FP4 ç­‰æ›´ä½ç²¾åº¦çš„æµ®ç‚¹æ ¼å¼ï¼Œæ—¨åœ¨è¿›ä¸€æ­¥æå‡æ¨ç†æ•ˆç‡ã€‚è¯¥æ–¹æ³•çš„æ ¸å¿ƒåœ¨äºå°†æŒ‡æ•°(exponent)å’Œå°¾æ•°(mantissa)ç»„ä»¶åˆ†ç¦»ï¼Œå¹¶åˆ©ç”¨ç†µç¼–ç (entropy coding)å¯¹å…¶è¿›è¡Œç‹¬ç«‹å‹ç¼©ã€‚è¯„ä¼°ç»“æœè¡¨æ˜ï¼Œè¯¥æŠ€æœ¯åœ¨ BF16 æ ¼å¼ä¸Šå¯å®ç° 62% çš„å‹ç¼©ç‡ï¼Œè€Œåœ¨ FP8 æ ¼å¼ä¸Šå‹ç¼©ç‡é«˜è¾¾ 83%ã€‚æ­¤å¤–ï¼Œç ”ç©¶å‘ç°å¤§è¯­è¨€æ¨¡å‹(LLMs)ä¸­çš„é”®å€¼ç¼“å­˜(K/V cache)å¼ é‡åŒæ ·å…·æœ‰æ˜¾è‘—çš„å¯å‹ç¼©æ¨¡å¼ï¼Œä»è€Œèƒ½åœ¨æ¨¡å‹éƒ¨ç½²æœŸé—´èŠ‚çœå¤§é‡å†…å­˜ç©ºé—´ã€‚è¿™äº›å‘ç°ä¸ºä¼˜åŒ–å¤§è§„æ¨¡ç¥ç»ç½‘ç»œçš„å­˜å‚¨æ¶æ„ä¸è¿è¡Œæ•ˆç‡æä¾›äº†é‡è¦çš„æŠ€æœ¯æ”¯æ’‘ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NE"
      ],
      "primary_category": "cs.LG",
      "comment": "16 pages 9 images",
      "pdf_url": "https://arxiv.org/pdf/2508.19263v1",
      "published_date": "2025-08-20 12:46:50 UTC",
      "updated_date": "2025-08-20 12:46:50 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T13:01:00.827574+00:00"
    },
    {
      "arxiv_id": "2508.14667v1",
      "title": "ELATE: Evolutionary Language model for Automated Time-series Engineering",
      "title_zh": "ELATEï¼šé¢å‘è‡ªåŠ¨åŒ–æ—¶é—´åºåˆ—å·¥ç¨‹çš„è¿›åŒ–è¯­è¨€æ¨¡å‹",
      "authors": [
        "Andrew Murray",
        "Danial Dervovic",
        "Michael Cashmore"
      ],
      "abstract": "Time-series prediction involves forecasting future values using machine learning models. Feature engineering, whereby existing features are transformed to make new ones, is critical for enhancing model performance, but is often manual and time-intensive. Existing automation attempts rely on exhaustive enumeration, which can be computationally costly and lacks domain-specific insights. We introduce ELATE (Evolutionary Language model for Automated Time-series Engineering), which leverages a language model within an evolutionary framework to automate feature engineering for time-series data. ELATE employs time-series statistical measures and feature importance metrics to guide and prune features, while the language model proposes new, contextually relevant feature transformations. Our experiments demonstrate that ELATE improves forecasting accuracy by an average of 8.4% across various domains.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† ELATE (Evolutionary Language model for Automated Time-series Engineering)ï¼Œè¿™æ˜¯ä¸€ç§åœ¨è¿›åŒ–æ¡†æ¶ (Evolutionary framework) ä¸­åˆ©ç”¨è¯­è¨€æ¨¡å‹ (Language model) è‡ªåŠ¨æ‰§è¡Œæ—¶é—´åºåˆ—ç‰¹å¾å·¥ç¨‹ (Feature engineering) çš„æ–°æ–¹æ³•ã€‚è¯¥æ–¹æ³•æ—¨åœ¨è§£å†³ä¼ ç»Ÿç‰¹å¾å·¥ç¨‹ä¾èµ–äººå·¥ä¸”è€—æ—¶è¾ƒé•¿ï¼Œä»¥åŠç°æœ‰è‡ªåŠ¨åŒ–æ–¹æ³•è®¡ç®—æˆæœ¬è¿‡é«˜ä¸”ç¼ºä¹é¢†åŸŸç›¸å…³æ´å¯ŸåŠ›çš„é—®é¢˜ã€‚ELATE å·§å¦™åœ°ç»“åˆäº†æ—¶é—´åºåˆ—ç»Ÿè®¡æŒ‡æ ‡ (Time-series statistical measures) å’Œç‰¹å¾é‡è¦æ€§åº¦é‡ (Feature importance metrics) æ¥å¯¹ç‰¹å¾è¿›è¡Œå¼•å¯¼å’Œä¿®å‰ªï¼ŒåŒæ—¶åˆ©ç”¨è¯­è¨€æ¨¡å‹æå‡ºå…·æœ‰ä¸Šä¸‹æ–‡ç›¸å…³æ€§çš„æ–°ç‰¹å¾å˜æ¢ã€‚å®éªŒç»“æœè¯æ˜ï¼ŒELATE åœ¨ä¸åŒé¢†åŸŸçš„å„ç§æ—¶é—´åºåˆ—é¢„æµ‹ä»»åŠ¡ä¸­è¡¨ç°å‡ºè‰²ï¼Œå¹³å‡æé«˜äº† 8.4% çš„é¢„æµ‹å‡†ç¡®ç‡ã€‚è¿™ä¸€æ¡†æ¶ä¸ºè‡ªåŠ¨åŒ–æ—¶é—´åºåˆ—ç‰¹å¾æŒ–æ˜æä¾›äº†ä¸€ç§å…¼å…·æ•ˆç‡ä¸é¢†åŸŸæ„ŸçŸ¥èƒ½åŠ›çš„åˆ›æ–°æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "27 pages, 4 figures. Comments welcome",
      "pdf_url": "https://arxiv.org/pdf/2508.14667v1",
      "published_date": "2025-08-20 12:36:29 UTC",
      "updated_date": "2025-08-20 12:36:29 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T13:01:04.327718+00:00"
    },
    {
      "arxiv_id": "2508.14654v1",
      "title": "Entropy-Constrained Strategy Optimization in Urban Floods: A Multi-Agent Framework with LLM and Knowledge Graph Integration",
      "title_zh": "åŸå¸‚æ´ªæ¶ä¸­çš„ç†µçº¦æŸç­–ç•¥ä¼˜åŒ–ï¼šé›†æˆå¤§è¯­è¨€æ¨¡å‹ä¸çŸ¥è¯†å›¾è°±çš„å¤šæ™ºèƒ½ä½“æ¡†æ¶",
      "authors": [
        "Peilin Ji",
        "Xiao Xue",
        "Simeng Wang",
        "Wenhao Yan"
      ],
      "abstract": "In recent years, the increasing frequency of extreme urban rainfall events has posed significant challenges to emergency scheduling systems. Urban flooding often leads to severe traffic congestion and service disruptions, threatening public safety and mobility. However, effective decision making remains hindered by three key challenges: (1) managing trade-offs among competing goals (e.g., traffic flow, task completion, and risk mitigation) requires dynamic, context-aware strategies; (2) rapidly evolving environmental conditions render static rules inadequate; and (3) LLM-generated strategies frequently suffer from semantic instability and execution inconsistency. Existing methods fail to align perception, global optimization, and multi-agent coordination within a unified framework. To tackle these challenges, we introduce H-J, a hierarchical multi-agent framework that integrates knowledge-guided prompting, entropy-constrained generation, and feedback-driven optimization. The framework establishes a closed-loop pipeline spanning from multi-source perception to strategic execution and continuous refinement. We evaluate H-J on real-world urban topology and rainfall data under three representative conditions: extreme rainfall, intermittent bursts, and daily light rain. Experiments show that H-J outperforms rule-based and reinforcement-learning baselines in traffic smoothness, task success rate, and system robustness. These findings highlight the promise of uncertainty-aware, knowledge-constrained LLM-based approaches for enhancing resilience in urban flood response.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹åŸå¸‚æ´ªæ¶ç¾å®³ä¸­æç«¯é™é›¨å¯¼è‡´çš„åº”æ€¥è°ƒåº¦éš¾é¢˜ï¼Œæå‡ºäº†åä¸º H-J çš„åˆ†å±‚å¤šæ™ºèƒ½ä½“æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³å¤šç›®æ ‡æƒè¡¡ã€åŠ¨æ€ç¯å¢ƒé€‚åº”ä»¥åŠå¤§è¯­è¨€æ¨¡å‹ (LLM) ç”Ÿæˆç­–ç•¥çš„ä¸ç¨³å®šæ€§é—®é¢˜ã€‚è¯¥æ¡†æ¶é€šè¿‡é›†æˆçŸ¥è¯†å¼•å¯¼æç¤º (knowledge-guided prompting)ã€ç†µçº¦æŸç”Ÿæˆ (entropy-constrained generation) å’Œåé¦ˆé©±åŠ¨ä¼˜åŒ– (feedback-driven optimization)ï¼Œæ„å»ºäº†ä»å¤šæºæ„ŸçŸ¥åˆ°ç­–ç•¥æ‰§è¡Œä¸æŒç»­ä¼˜åŒ–çš„é—­ç¯ç®¡çº¿ã€‚å®éªŒåŸºäºçœŸå®åŸå¸‚æ‹“æ‰‘å’Œå¤šç§é™é›¨åœºæ™¯ï¼ˆæç«¯é™é›¨ã€é—´æ­‡æ€§æš´é›¨å’Œæ—¥å¸¸å°é›¨ï¼‰è¿›è¡Œè¯„ä¼°ï¼Œç»“æœæ˜¾ç¤º H-J åœ¨äº¤é€šå¹³æ»‘åº¦ã€ä»»åŠ¡æˆåŠŸç‡å’Œç³»ç»Ÿé²æ£’æ€§æ–¹é¢å‡æ˜¾è‘—ä¼˜äºåŸºäºè§„åˆ™å’Œå¼ºåŒ–å­¦ä¹  (Reinforcement Learning) çš„åŸºçº¿æ¨¡å‹ã€‚è¯¥ç ”ç©¶è¯æ˜äº†ç»“åˆä¸ç¡®å®šæ€§æ„ŸçŸ¥ä¸çŸ¥è¯†çº¦æŸçš„ LLM æ–¹æ³•åœ¨æå‡åŸå¸‚æ´ªæ¶åº”å¯¹éŸ§æ€§æ–¹é¢çš„å·¨å¤§æ½œåŠ›ï¼Œä¸ºå¤æ‚åŸå¸‚ç¯å¢ƒä¸‹çš„æ™ºèƒ½åº”æ€¥å†³ç­–æä¾›äº†æœ‰æ•ˆçš„æ–°è·¯å¾„ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "17 pages including appendix, 6 figures",
      "pdf_url": "https://arxiv.org/pdf/2508.14654v1",
      "published_date": "2025-08-20 12:13:03 UTC",
      "updated_date": "2025-08-20 12:13:03 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T13:01:03.721870+00:00"
    },
    {
      "arxiv_id": "2508.14646v1",
      "title": "OneLoc: Geo-Aware Generative Recommender Systems for Local Life Service",
      "title_zh": "OneLocï¼šé¢å‘æœ¬åœ°ç”Ÿæ´»æœåŠ¡çš„åœ°ç†ä½ç½®æ„ŸçŸ¥ç”Ÿæˆå¼æ¨èç³»ç»Ÿ",
      "authors": [
        "Zhipeng Wei",
        "Kuo Cai",
        "Junda She",
        "Jie Chen",
        "Minghao Chen",
        "Yang Zeng",
        "Qiang Luo",
        "Wencong Zeng",
        "Ruiming Tang",
        "Kun Gai",
        "Guorui Zhou"
      ],
      "abstract": "Local life service is a vital scenario in Kuaishou App, where video recommendation is intrinsically linked with store's location information. Thus, recommendation in our scenario is challenging because we should take into account user's interest and real-time location at the same time. In the face of such complex scenarios, end-to-end generative recommendation has emerged as a new paradigm, such as OneRec in the short video scenario, OneSug in the search scenario, and EGA in the advertising scenario. However, in local life service, an end-to-end generative recommendation model has not yet been developed as there are some key challenges to be solved. The first challenge is how to make full use of geographic information. The second challenge is how to balance multiple objectives, including user interests, the distance between user and stores, and some other business objectives. To address the challenges, we propose OneLoc. Specifically, we leverage geographic information from different perspectives: (1) geo-aware semantic ID incorporates both video and geographic information for tokenization, (2) geo-aware self-attention in the encoder leverages both video location similarity and user's real-time location, and (3) neighbor-aware prompt captures rich context information surrounding users for generation. To balance multiple objectives, we use reinforcement learning and propose two reward functions, i.e., geographic reward and GMV reward. With the above design, OneLoc achieves outstanding offline and online performance. In fact, OneLoc has been deployed in local life service of Kuaishou App. It serves 400 million active users daily, achieving 21.016% and 17.891% improvements in terms of gross merchandise value (GMV) and orders numbers.",
      "tldr_zh": "åœ¨è¯¥å¿«æ‰‹APPçš„æœ¬åœ°ç”Ÿæ´»æœåŠ¡åœºæ™¯ä¸­ï¼Œè§†é¢‘æ¨èä¸å•†åº—åœ°ç†ä½ç½®ä¿¡æ¯æ·±åº¦è€¦åˆï¼Œé¢ä¸´ç€å¦‚ä½•åŒæ—¶å…¼é¡¾ç”¨æˆ·å…´è¶£ä¸å®æ—¶ä½ç½®ã€ä»¥åŠå¹³è¡¡å¤šé‡ä¸šåŠ¡ç›®æ ‡çš„æŒ‘æˆ˜ã€‚è¯¥ç ”ç©¶æå‡ºäº† OneLocï¼Œä¸€ç§åœ°ç†æ„ŸçŸ¥çš„ç”Ÿæˆå¼æ¨èç³»ç»Ÿ (Geo-Aware Generative Recommender Systems)ï¼Œé€šè¿‡å¤šç§ç­–ç•¥æ·±åº¦æŒ–æ˜åœ°ç†ä¿¡æ¯ï¼ŒåŒ…æ‹¬èåˆè§†é¢‘ä¸åœ°ç†ç‰¹å¾çš„åœ°ç†æ„ŸçŸ¥è¯­ä¹‰ ID (geo-aware semantic ID)ã€æ•è·ä½ç½®ç›¸ä¼¼æ€§çš„åœ°ç†æ„ŸçŸ¥è‡ªæ³¨æ„åŠ› (geo-aware self-attention) ä»¥åŠé‚»åŸŸæ„ŸçŸ¥æç¤º (neighbor-aware prompt)ã€‚ä¸ºäº†å¹³è¡¡ç”¨æˆ·åå¥½ä¸å•†ä¸šç›®æ ‡ï¼ŒOneLoc å¼•å…¥äº†å¼ºåŒ–å­¦ä¹  (reinforcement learning) å¹¶è®¾è®¡äº†åœ°ç†å¥–åŠ± (geographic reward) å’Œ GMV å¥–åŠ± (GMV reward) å‡½æ•°ã€‚ç›®å‰ OneLoc å·²åœ¨å¿«æ‰‹æœ¬åœ°ç”Ÿæ´»ä¸šåŠ¡ä¸­å¤§è§„æ¨¡éƒ¨ç½²ï¼Œæ—¥å‡æœåŠ¡ 4 äº¿æ´»è·ƒç”¨æˆ·ï¼Œä½¿æ€»äº¤æ˜“é¢ (GMV) å’Œè®¢å•é‡åˆ†åˆ«æå‡äº† 21.016% å’Œ 17.891%ï¼Œå±•ç°å‡ºå“è¶Šçš„å®é™…åº”ç”¨ä»·å€¼ã€‚",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.14646v1",
      "published_date": "2025-08-20 11:57:48 UTC",
      "updated_date": "2025-08-20 11:57:48 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T13:01:06.925822+00:00"
    },
    {
      "arxiv_id": "2508.14644v1",
      "title": "LeanGeo: Formalizing Competitional Geometry problems in Lean",
      "title_zh": "LeanGeoï¼šåœ¨ Lean ä¸­å½¢å¼åŒ–ç«èµ›å‡ ä½•é—®é¢˜",
      "authors": [
        "Chendong Song",
        "Zihan Wang",
        "Frederick Pu",
        "Haiming Wang",
        "Xiaohan Lin",
        "Junqi Liu",
        "Jia Li",
        "Zhengying Liu"
      ],
      "abstract": "Geometry problems are a crucial testbed for AI reasoning capabilities. Most existing geometry solving systems cannot express problems within a unified framework, thus are difficult to integrate with other mathematical fields. Besides, since most geometric proofs rely on intuitive diagrams, verifying geometry problems is particularly challenging. To address these gaps, we introduce LeanGeo, a unified formal system for formalizing and solving competition-level geometry problems within the Lean 4 theorem prover. LeanGeo features a comprehensive library of high-level geometric theorems with Lean's foundational logic, enabling rigorous proof verification and seamless integration with Mathlib. We also present LeanGeo-Bench, a formal geometry benchmark in LeanGeo, comprising problems from the International Mathematical Olympiad (IMO) and other advanced sources. Our evaluation demonstrates the capabilities and limitations of state-of-the-art Large Language Models on this benchmark, highlighting the need for further advancements in automated geometric reasoning. We open source the theorem library and the benchmark of LeanGeo at https://github.com/project-numina/LeanGeo/tree/master.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†LeanGeoï¼Œè¿™æ˜¯ä¸€ä¸ªåœ¨Lean 4è¯æ˜è¾…åŠ©å™¨ä¸­æ„å»ºçš„ç»Ÿä¸€å½¢å¼åŒ–ç³»ç»Ÿï¼Œæ—¨åœ¨è§£å†³ç°æœ‰å‡ ä½•æ±‚è§£ç³»ç»Ÿç¼ºä¹ç»Ÿä¸€æ¡†æ¶ä¸”éªŒè¯å›°éš¾çš„é—®é¢˜ã€‚LeanGeoåŒ…å«ä¸€ä¸ªå…¨é¢çš„é«˜çº§å‡ ä½•å®šç†åº“ï¼Œé€šè¿‡ç»“åˆLeançš„åŸºç¡€é€»è¾‘ï¼Œå®ç°äº†ä¸¥è°¨çš„è¯æ˜éªŒè¯ä»¥åŠä¸Mathlibçš„æ— ç¼é›†æˆã€‚æ­¤å¤–ï¼Œç ”ç©¶è€…è¿˜æ¨å‡ºäº†LeanGeo-Benchï¼Œè¿™æ˜¯ä¸€ä¸ªæ¶µç›–å›½é™…æ•°å­¦å¥¥æ—åŒ¹å…‹(IMO)åŠå…¶ä»–é«˜çº§ç«èµ›é¢˜ç›®çš„å½¢å¼åŒ–å‡ ä½•åŸºå‡†æµ‹è¯•é›†ã€‚é€šè¿‡å¯¹å½“å‰æœ€å…ˆè¿›å¤§è¯­è¨€æ¨¡å‹(LLMs)åœ¨è¯¥åŸºå‡†ä¸Šçš„è¯„ä¼°ï¼Œè¯¥ç ”ç©¶æ­ç¤ºäº†ç°æœ‰æ¨¡å‹åœ¨è‡ªåŠ¨åŒ–å‡ ä½•æ¨ç†æ–¹é¢çš„èƒ½åŠ›ä¸å±€é™æ€§ã€‚LeanGeoé€šè¿‡å¼€æºå…¶å®šç†åº“å’ŒåŸºå‡†æµ‹è¯•ï¼Œä¸ºç«èµ›çº§å‡ ä½•é—®é¢˜çš„å½¢å¼åŒ–è¡¨è¾¾å’Œäººå·¥æ™ºèƒ½æ¨ç†èƒ½åŠ›çš„æå‡æä¾›äº†é‡è¦çš„åŸºç¡€å·¥å…·ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "28 pages",
      "pdf_url": "https://arxiv.org/pdf/2508.14644v1",
      "published_date": "2025-08-20 11:55:19 UTC",
      "updated_date": "2025-08-20 11:55:19 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T13:01:12.631747+00:00"
    },
    {
      "arxiv_id": "2508.14635v1",
      "title": "Can LLM Agents Solve Collaborative Tasks? A Study on Urgency-Aware Planning and Coordination",
      "title_zh": "LLM æ™ºèƒ½ä½“èƒ½å¦è§£å†³åä½œä»»åŠ¡ï¼Ÿä¸€é¡¹å…³äºç´§æ€¥æ„ŸçŸ¥è§„åˆ’ä¸ååŒçš„ç ”ç©¶",
      "authors": [
        "JoÃ£o Vitor de Carvalho Silva",
        "Douglas G. Macharet"
      ],
      "abstract": "The ability to coordinate actions across multiple agents is critical for solving complex, real-world problems. Large Language Models (LLMs) have shown strong capabilities in communication, planning, and reasoning, raising the question of whether they can also support effective collaboration in multi-agent settings. In this work, we investigate the use of LLM agents to solve a structured victim rescue task that requires division of labor, prioritization, and cooperative planning. Agents operate in a fully known graph-based environment and must allocate resources to victims with varying needs and urgency levels. We systematically evaluate their performance using a suite of coordination-sensitive metrics, including task success rate, redundant actions, room conflicts, and urgency-weighted efficiency. This study offers new insights into the strengths and failure modes of LLMs in physically grounded multi-agent collaboration tasks, contributing to future benchmarks and architectural improvements.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å¤§å‹è¯­è¨€æ¨¡å‹(LLMs)æ™ºèƒ½ä½“åœ¨å¤šæ™ºèƒ½ä½“åä½œç¯å¢ƒä¸­è§£å†³å¤æ‚ç°å®é—®é¢˜çš„èƒ½åŠ›ï¼Œé‡ç‚¹å…³æ³¨ç´§è¿«æ€§æ„ŸçŸ¥è§„åˆ’ä¸åè°ƒ(Urgency-Aware Planning and Coordination)ã€‚ç ”ç©¶é‡‡ç”¨äº†ä¸€ä¸ªç»“æ„åŒ–çš„å—å®³è€…æ•‘æ´ä»»åŠ¡ï¼Œè¦æ±‚æ™ºèƒ½ä½“åœ¨å®Œå…¨å·²çŸ¥çš„å›¾è®ºç¯å¢ƒ(graph-based environment)ä¸­è¿›è¡ŒåŠ³åŠ¨åˆ†å·¥ã€ä¼˜å…ˆçº§æ’åºå’Œåä½œè§„åˆ’ã€‚æ™ºèƒ½ä½“å¿…é¡»æ ¹æ®å—å®³è€…çš„ä¸åŒéœ€æ±‚å’Œç´§è¿«ç¨‹åº¦åˆ†é…èµ„æºï¼Œå¹¶é’ˆå¯¹ä»»åŠ¡æˆåŠŸç‡ã€å†—ä½™åŠ¨ä½œ(redundant actions)ã€æˆ¿é—´å†²çª(room conflicts)ä»¥åŠç´§è¿«æ€§åŠ æƒæ•ˆç‡ç­‰æŒ‡æ ‡è¿›è¡Œç³»ç»Ÿè¯„ä¼°ã€‚å®éªŒæ·±å…¥æ­ç¤ºäº† LLMs åœ¨å—ç‰©ç†ç¯å¢ƒé™åˆ¶çš„å¤šæ™ºèƒ½ä½“åä½œä»»åŠ¡ä¸­çš„ä¼˜åŠ¿ä¸å¤±è´¥æ¨¡å¼(failure modes)ã€‚è¯¥ç ”ç©¶ä¸ºæœªæ¥å¼€å‘å…·å¤‡é«˜æ•ˆåè°ƒèƒ½åŠ›çš„æ™ºèƒ½ä½“æ¶æ„åŠç›¸å…³åŸºå‡†æµ‹è¯•(benchmarks)æä¾›äº†é‡è¦è§è§£ã€‚",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.14635v1",
      "published_date": "2025-08-20 11:44:10 UTC",
      "updated_date": "2025-08-20 11:44:10 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T13:01:12.822540+00:00"
    },
    {
      "arxiv_id": "2508.15858v1",
      "title": "Building and Measuring Trust between Large Language Models",
      "title_zh": "å¤§è¯­è¨€æ¨¡å‹é—´ä¿¡ä»»çš„æ„å»ºä¸è¯„ä¼°",
      "authors": [
        "Maarten Buyl",
        "Yousra Fettach",
        "Guillaume Bied",
        "Tijl De Bie"
      ],
      "abstract": "As large language models (LLMs) increasingly interact with each other, most notably in multi-agent setups, we may expect (and hope) that `trust' relationships develop between them, mirroring trust relationships between human colleagues, friends, or partners. Yet, though prior work has shown LLMs to be capable of identifying emotional connections and recognizing reciprocity in trust games, little remains known about (i) how different strategies to build trust compare, (ii) how such trust can be measured implicitly, and (iii) how this relates to explicit measures of trust.\n  We study these questions by relating implicit measures of trust, i.e. susceptibility to persuasion and propensity to collaborate financially, with explicit measures of trust, i.e. a dyadic trust questionnaire well-established in psychology. We build trust in three ways: by building rapport dynamically, by starting from a prewritten script that evidences trust, and by adapting the LLMs' system prompt. Surprisingly, we find that the measures of explicit trust are either little or highly negatively correlated with implicit trust measures. These findings suggest that measuring trust between LLMs by asking their opinion may be deceiving. Instead, context-specific and implicit measures may be more informative in understanding how LLMs trust each other.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†éšç€å¤§å‹è¯­è¨€æ¨¡å‹(Large Language Models, LLMs)åœ¨å¤šæ™ºèƒ½ä½“ç³»ç»Ÿä¸­äº¤äº’å¢åŠ ï¼Œæ¨¡å‹é—´å¦‚ä½•å»ºç«‹å¹¶è¡¡é‡â€œä¿¡ä»»â€è¿™ä¸€æ ¸å¿ƒé—®é¢˜ã€‚ä½œè€…å¯¹æ¯”äº†åŠ¨æ€å»ºç«‹å…³ç³»(rapport)ã€é¢„è®¾è„šæœ¬å’Œè°ƒæ•´ç³»ç»Ÿæç¤ºè¯(system prompt)ä¸‰ç§ä¿¡ä»»æ„å»ºç­–ç•¥ï¼Œå¹¶åˆ†æäº†éšå¼(Implicit)è¡¡é‡æŒ‡æ ‡ï¼ˆå¦‚åŠè¯´æ•æ„Ÿåº¦å’Œè´¢åŠ¡åä½œå€¾å‘ï¼‰ä¸æ˜¾å¼(Explicit)å¿ƒç†å­¦ä¿¡ä»»é‡è¡¨ä¹‹é—´çš„å…³è”ã€‚å®éªŒç»“æœå‡ºäººæ„æ–™åœ°æ˜¾ç¤ºï¼Œæ˜¾å¼ä¿¡ä»»åº¦é‡ä¸éšå¼åº¦é‡ä¹‹é—´ä»…å­˜åœ¨æä½æˆ–é«˜åº¦è´Ÿç›¸å…³çš„è”ç³»ï¼Œè¡¨æ˜ç›´æ¥è¯¢é—®æ¨¡å‹çš„æ„è§å¯èƒ½ä¼šäº§ç”Ÿè¯¯å¯¼ã€‚ç ”ç©¶å¼ºè°ƒï¼Œåœ¨è¯„ä¼°LLMsä¹‹é—´çš„ä¿¡ä»»å…³ç³»æ—¶ï¼ŒåŸºäºç‰¹å®šä¸Šä¸‹æ–‡çš„éšå¼æµ‹é‡æ–¹æ³•æ¯”æ˜¾å¼è¯¢é—®æ›´å…·å‚è€ƒä»·å€¼ï¼Œä¸ºç†è§£å¤šæ™ºèƒ½ä½“ç³»ç»Ÿä¸­çš„åä½œæœºåˆ¶æä¾›äº†æ–°è§è§£ã€‚",
      "categories": [
        "cs.MA",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.MA",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.15858v1",
      "published_date": "2025-08-20 11:38:38 UTC",
      "updated_date": "2025-08-20 11:38:38 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T13:01:23.818083+00:00"
    },
    {
      "arxiv_id": "2508.14623v1",
      "title": "A Study of the Scale Invariant Signal to Distortion Ratio in Speech Separation with Noisy References",
      "title_zh": "è¯­éŸ³åˆ†ç¦»ä¸­å«å™ªå‚è€ƒä¿¡å·ä¸‹çš„å°ºåº¦ä¸å˜ä¿¡å·å¤±çœŸæ¯”ç ”ç©¶",
      "authors": [
        "Simon Dahl Jepsen",
        "Mads GrÃ¦sbÃ¸ll Christensen",
        "Jesper Rindom Jensen"
      ],
      "abstract": "This paper examines the implications of using the Scale-Invariant Signal-to-Distortion Ratio (SI-SDR) as both evaluation and training objective in supervised speech separation, when the training references contain noise, as is the case with the de facto benchmark WSJ0-2Mix. A derivation of the SI-SDR with noisy references reveals that noise limits the achievable SI-SDR, or leads to undesired noise in the separated outputs. To address this, a method is proposed to enhance references and augment the mixtures with WHAM!, aiming to train models that avoid learning noisy references. Two models trained on these enhanced datasets are evaluated with the non-intrusive NISQA.v2 metric. Results show reduced noise in separated speech but suggest that processing references may introduce artefacts, limiting overall quality gains. Negative correlation is found between SI-SDR and perceived noisiness across models on the WSJ0-2Mix and Libri2Mix test sets, underlining the conclusion from the derivation.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†åœ¨ç›‘ç£è¯­éŸ³åˆ†ç¦»ä»»åŠ¡ä¸­ï¼Œå½“è®­ç»ƒå‚è€ƒä¿¡å·(references)åŒ…å«å™ªå£°æ—¶ï¼ˆå¦‚åŸºå‡†æ•°æ®é›† WSJ0-2Mixï¼‰ï¼Œä½¿ç”¨å°ºåº¦ä¸å˜ä¿¡å™ªæ¯”(Scale-Invariant Signal-to-Distortion Ratio, SI-SDR)ä½œä¸ºè¯„ä¼°å’Œè®­ç»ƒç›®æ ‡çš„å…·ä½“å½±å“ã€‚é€šè¿‡å¯¹å¸¦æœ‰å™ªå£°å‚è€ƒä¿¡å·çš„ SI-SDR è¿›è¡Œå…¬å¼æ¨å¯¼ï¼Œç ”ç©¶å‘ç°å™ªå£°ä¼šé™åˆ¶å¯è¾¾åˆ°çš„ SI-SDR æ•°å€¼ï¼Œæˆ–å¯¼è‡´åˆ†ç¦»è¾“å‡ºä¸­åŒ…å«ä¸å¿…è¦çš„å™ªå£°ã€‚ä¸ºè§£å†³æ­¤é—®é¢˜ï¼Œä½œè€…æå‡ºäº†ä¸€ç§å¢å¼ºå‚è€ƒä¿¡å·çš„æ–¹æ³•ï¼Œå¹¶ç»“åˆ WHAM! æ‰©å……æ··åˆéŸ³é¢‘ï¼Œæ—¨åœ¨è®­ç»ƒæ¨¡å‹ä»¥é¿å…å­¦ä¹ å™ªå£°ã€‚ç ”ç©¶ä½¿ç”¨éä¾µå…¥å¼æŒ‡æ ‡ NISQA.v2 å¯¹æ¨¡å‹è¿›è¡Œè¯„ä¼°ï¼Œç»“æœæ˜¾ç¤ºè¯¥æ–¹æ³•æœ‰æ•ˆå‡å°‘äº†åˆ†ç¦»è¯­éŸ³ä¸­çš„å™ªå£°ï¼Œä½†å¤„ç†å‚è€ƒä¿¡å·å¯èƒ½å¼•å…¥äººå·¥ä¼ªå½±(artefacts)ï¼Œä»è€Œé™åˆ¶äº†æ•´ä½“è´¨é‡çš„å¢ç›Šã€‚åœ¨ WSJ0-2Mix å’Œ Libri2Mix æµ‹è¯•é›†ä¸Šçš„åˆ†æè¿›ä¸€æ­¥è¯å®äº† SI-SDR ä¸æ„ŸçŸ¥å™ªå£°ç¨‹åº¦ä¹‹é—´å­˜åœ¨è´Ÿç›¸å…³å…³ç³»ï¼ŒéªŒè¯äº†ç†è®ºæ¨å¯¼çš„å‡†ç¡®æ€§ã€‚",
      "categories": [
        "eess.AS",
        "cs.AI",
        "cs.SD"
      ],
      "primary_category": "eess.AS",
      "comment": "Accepted for IEEE ASRU 2025, Workshop on Automatic Speech Recognition and Understanding. Copyright (c) 2025 IEEE. 8 pages, 6 figures, 2 tables",
      "pdf_url": "https://arxiv.org/pdf/2508.14623v1",
      "published_date": "2025-08-20 11:22:11 UTC",
      "updated_date": "2025-08-20 11:22:11 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T13:01:24.818353+00:00"
    },
    {
      "arxiv_id": "2508.14604v1",
      "title": "UST-SSM: Unified Spatio-Temporal State Space Models for Point Cloud Video Modeling",
      "title_zh": "UST-SSMï¼šé¢å‘ç‚¹äº‘è§†é¢‘å»ºæ¨¡çš„ç»Ÿä¸€æ—¶ç©ºçŠ¶æ€ç©ºé—´æ¨¡å‹",
      "authors": [
        "Peiming Li",
        "Ziyi Wang",
        "Yulin Yuan",
        "Hong Liu",
        "Xiangming Meng",
        "Junsong Yuan",
        "Mengyuan Liu"
      ],
      "abstract": "Point cloud videos capture dynamic 3D motion while reducing the effects of lighting and viewpoint variations, making them highly effective for recognizing subtle and continuous human actions. Although Selective State Space Models (SSMs) have shown good performance in sequence modeling with linear complexity, the spatio-temporal disorder of point cloud videos hinders their unidirectional modeling when directly unfolding the point cloud video into a 1D sequence through temporally sequential scanning. To address this challenge, we propose the Unified Spatio-Temporal State Space Model (UST-SSM), which extends the latest advancements in SSMs to point cloud videos. Specifically, we introduce Spatial-Temporal Selection Scanning (STSS), which reorganizes unordered points into semantic-aware sequences through prompt-guided clustering, thereby enabling the effective utilization of points that are spatially and temporally distant yet similar within the sequence. For missing 4D geometric and motion details, Spatio-Temporal Structure Aggregation (STSA) aggregates spatio-temporal features and compensates. To improve temporal interaction within the sampled sequence, Temporal Interaction Sampling (TIS) enhances fine-grained temporal dependencies through non-anchor frame utilization and expanded receptive fields. Experimental results on the MSR-Action3D, NTU RGB+D, and Synthia 4D datasets validate the effectiveness of our method. Our code is available at https://github.com/wangzy01/UST-SSM.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†UST-SSMï¼ˆUnified Spatio-Temporal State Space Modelï¼‰ï¼Œæ—¨åœ¨è§£å†³é€‰æ‹©æ€§çŠ¶æ€ç©ºé—´æ¨¡å‹ï¼ˆSelective State Space Models, SSMsï¼‰åœ¨å¤„ç†ç‚¹äº‘è§†é¢‘æ—¶ï¼Œå› æ—¶ç©ºæ— åºæ€§å¯¼è‡´çš„ä¸€ç»´åºåˆ—åŒ–å»ºæ¨¡éš¾é¢˜ã€‚ä¸ºäº†åº”å¯¹è¿™ä¸€æŒ‘æˆ˜ï¼Œç ”ç©¶å¼•å…¥äº†ç©ºé—´-æ—¶é—´é€‰æ‹©æ€§æ‰«æï¼ˆSpatial-Temporal Selection Scanning, STSSï¼‰ï¼Œé€šè¿‡æç¤ºå¼•å¯¼çš„èšç±»ï¼ˆprompt-guided clusteringï¼‰å°†æ— åºç‚¹é‡æ–°ç»„ç»‡ä¸ºè¯­ä¹‰æ„ŸçŸ¥åºåˆ—ï¼Œä»è€Œæœ‰æ•ˆåˆ©ç”¨ç©ºé—´å’Œæ—¶é—´ä¸Šè·ç¦»è¾ƒè¿œä½†ç‰¹å¾ç›¸ä¼¼çš„ç‚¹ã€‚é’ˆå¯¹ç¼ºå¤±çš„4Då‡ ä½•ä¸è¿åŠ¨ç»†èŠ‚ï¼Œæ—¶ç©ºç»“æ„èšåˆï¼ˆSpatio-Temporal Structure Aggregation, STSAï¼‰æ¨¡å—è¢«ç”¨äºèšåˆæ—¶ç©ºç‰¹å¾å¹¶è¿›è¡Œè¡¥å¿ã€‚æ­¤å¤–ï¼Œæ—¶é—´äº¤äº’é‡‡æ ·ï¼ˆTemporal Interaction Sampling, TISï¼‰é€šè¿‡åˆ©ç”¨éé”šå¸§å’Œæ‰©å¤§æ„Ÿå—é‡ï¼Œè¿›ä¸€æ­¥å¢å¼ºäº†é‡‡æ ·åºåˆ—å†…éƒ¨çš„ç»†ç²’åº¦æ—¶é—´ä¾èµ–æ€§ã€‚åœ¨MSR-Action3Dã€NTU RGB+Då’ŒSynthia 4Dç­‰å¤šä¸ªæ•°æ®é›†ä¸Šçš„å®éªŒç»“æœå……åˆ†éªŒè¯äº†UST-SSMåœ¨ç‚¹äº‘è§†é¢‘å»ºæ¨¡ä¸­çš„æœ‰æ•ˆæ€§ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "8 pages, 5 figures, Accepted to ICCV2025",
      "pdf_url": "https://arxiv.org/pdf/2508.14604v1",
      "published_date": "2025-08-20 10:46:01 UTC",
      "updated_date": "2025-08-20 10:46:01 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T13:01:23.425953+00:00"
    },
    {
      "arxiv_id": "2508.14582v1",
      "title": "An Open-Source HW-SW Co-Development Framework Enabling Efficient Multi-Accelerator Systems",
      "title_zh": "æ”¯æŒé«˜æ•ˆå¤šåŠ é€Ÿå™¨ç³»ç»Ÿçš„å¼€æºè½¯ç¡¬ä»¶ååŒå¼€å‘æ¡†æ¶",
      "authors": [
        "Ryan Albert Antonio",
        "Joren Dumoulin",
        "Xiaoling Yi",
        "Josse Van Delm",
        "Yunhao Deng",
        "Guilherme Paim",
        "Marian Verhelst"
      ],
      "abstract": "Heterogeneous accelerator-centric compute clusters are emerging as efficient solutions for diverse AI workloads. However, current integration strategies often compromise data movement efficiency and encounter compatibility issues in hardware and software. This prevents a unified approach that balances performance and ease of use. To this end, we present SNAX, an open-source integrated HW-SW framework enabling efficient multi-accelerator platforms through a novel hybrid-coupling scheme, consisting of loosely coupled asynchronous control and tightly coupled data access. SNAX brings reusable hardware modules designed to enhance compute accelerator utilization, and its customizable MLIR-based compiler to automate key system management tasks, jointly enabling rapid development and deployment of customized multi-accelerator compute clusters. Through extensive experimentation, we demonstrate SNAX's efficiency and flexibility in a low-power heterogeneous SoC. Accelerators can easily be integrated and programmed to achieve > 10x improvement in neural network performance compared to other accelerator systems while maintaining accelerator utilization of > 90% in full system operation.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†SNAXï¼Œä¸€ä¸ªå¼€æºçš„è½¯ç¡¬ä»¶ååŒå¼€å‘æ¡†æ¶(HW-SW Co-Development Framework)ï¼Œæ—¨åœ¨è§£å†³å¼‚æ„å¤šåŠ é€Ÿå™¨ç³»ç»Ÿåœ¨æ•°æ®ç§»åŠ¨æ•ˆç‡å’Œè½¯ç¡¬ä»¶å…¼å®¹æ€§æ–¹é¢çš„æŒ‘æˆ˜ã€‚è¯¥æ¡†æ¶å¼•å…¥äº†ä¸€ç§æ–°é¢–çš„æ··åˆè€¦åˆæ–¹æ¡ˆ(hybrid-coupling scheme)ï¼Œé€šè¿‡ç»“åˆå¼‚æ­¥æ§åˆ¶çš„æ¾è€¦åˆ(loosely coupled asynchronous control)ä¸æ•°æ®è®¿é—®çš„ç´§è€¦åˆ(tightly coupled data access)æ¥ä¼˜åŒ–æ€§èƒ½ã€‚SNAXåŒ…å«å¯é‡ç”¨çš„ç¡¬ä»¶æ¨¡å—ä»¥æå‡è®¡ç®—åˆ©ç”¨ç‡ï¼Œå¹¶é…å¤‡äº†åŸºäºMLIRçš„å®šåˆ¶åŒ–ç¼–è¯‘å™¨æ¥è‡ªåŠ¨æ‰§è¡Œå…³é”®çš„ç³»ç»Ÿç®¡ç†ä»»åŠ¡ï¼Œä»è€Œå®ç°å¤šåŠ é€Ÿå™¨è®¡ç®—é›†ç¾¤çš„å¿«é€Ÿå¼€å‘ä¸éƒ¨ç½²ã€‚åœ¨ä½åŠŸè€—å¼‚æ„SoCä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥ç³»ç»Ÿåœ¨å¤„ç†ç¥ç»ç½‘ç»œä»»åŠ¡æ—¶çš„æ€§èƒ½æ¯”å…¶ä»–åŠ é€Ÿå™¨ç³»ç»Ÿæå‡äº†10å€ä»¥ä¸Šã€‚æ­¤å¤–ï¼ŒSNAXåœ¨å…¨ç³»ç»Ÿè¿è¡Œä¸­èƒ½å¤Ÿä¿æŒè¶…è¿‡90%çš„åŠ é€Ÿå™¨åˆ©ç”¨ç‡ï¼Œå……åˆ†è¯æ˜äº†è¯¥æ¡†æ¶åœ¨å¤„ç†å¤šæ ·åŒ–AIå·¥ä½œè´Ÿè½½æ—¶çš„é«˜æ•ˆæ€§ä¸çµæ´»æ€§ã€‚",
      "categories": [
        "cs.AR",
        "cs.AI"
      ],
      "primary_category": "cs.AR",
      "comment": "7 pages, 10 figures, 1 table, to be published in ISLPED 2025",
      "pdf_url": "https://arxiv.org/pdf/2508.14582v1",
      "published_date": "2025-08-20 10:04:21 UTC",
      "updated_date": "2025-08-20 10:04:21 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T13:01:26.720558+00:00"
    },
    {
      "arxiv_id": "2508.15853v1",
      "title": "MGSC: A Multi-granularity Consistency Framework for Robust End-to-end Asr",
      "title_zh": "MGSCï¼šé¢å‘é²æ£’ç«¯åˆ°ç«¯è‡ªåŠ¨è¯­éŸ³è¯†åˆ«çš„å¤šç²’åº¦ä¸€è‡´æ€§æ¡†æ¶",
      "authors": [
        "Xuwen Yang"
      ],
      "abstract": "End-to-end ASR models, despite their success on benchmarks, often pro-duce catastrophic semantic errors in noisy environments. We attribute this fragility to the prevailing 'direct mapping' objective, which solely penalizes final output errors while leaving the model's internal computational pro-cess unconstrained. To address this, we introduce the Multi-Granularity Soft Consistency (MGSC) framework, a model-agnostic, plug-and-play module that enforces internal self-consistency by simultaneously regulariz-ing macro-level sentence semantics and micro-level token alignment. Cru-cially, our work is the first to uncover a powerful synergy between these two consistency granularities: their joint optimization yields robustness gains that significantly surpass the sum of their individual contributions. On a public dataset, MGSC reduces the average Character Error Rate by a relative 8.7% across diverse noise conditions, primarily by preventing se-vere meaning-altering mistakes. Our work demonstrates that enforcing in-ternal consistency is a crucial step towards building more robust and trust-worthy AI.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†MGSCï¼ˆMulti-Granularity Soft Consistencyï¼‰æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³ç«¯åˆ°ç«¯è‡ªåŠ¨è¯­éŸ³è¯†åˆ«ï¼ˆEnd-to-end ASRï¼‰æ¨¡å‹åœ¨å™ªå£°ç¯å¢ƒä¸‹å®¹æ˜“äº§ç”Ÿä¸¥é‡è¯­ä¹‰é”™è¯¯çš„é—®é¢˜ã€‚ä½œè€…æŒ‡å‡ºï¼Œç°æœ‰æ¨¡å‹çš„è„†å¼±æ€§æºäºâ€œç›´æ¥æ˜ å°„â€ï¼ˆdirect mappingï¼‰ç›®æ ‡ç¼ºä¹å¯¹å†…éƒ¨è®¡ç®—è¿‡ç¨‹çš„çº¦æŸã€‚MGSCä½œä¸ºä¸€ä¸ªæ¨¡å‹æ— å…³ä¸”å³æ’å³ç”¨çš„æ¨¡å—ï¼Œé€šè¿‡åŒæ—¶è§„èŒƒå®è§‚å±‚é¢çš„å¥å­è¯­ä¹‰ï¼ˆmacro-level sentence semanticsï¼‰å’Œå¾®è§‚å±‚é¢çš„æ ‡è®°å¯¹é½ï¼ˆmicro-level token alignmentï¼‰æ¥å¢å¼ºå†…éƒ¨è‡ªä¸€è‡´æ€§ã€‚ç ”ç©¶é¦–æ¬¡å‘ç°äº†è¿™ä¸¤è€…ä¹‹é—´çš„ååŒæ•ˆåº”ï¼Œè”åˆä¼˜åŒ–å¸¦æ¥çš„é²æ£’æ€§æå‡è¿œè¶…å„è‡ªç‹¬ç«‹è´¡çŒ®çš„æ€»å’Œã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œåœ¨å¤šç§å™ªå£°æ¡ä»¶ä¸‹ï¼ŒMGSCä½¿å¹³å‡å­—ç¬¦é”™è¯¯ç‡ï¼ˆCharacter Error Rate, CERï¼‰ç›¸å¯¹é™ä½äº†8.7%ï¼Œå¹¶èƒ½æœ‰æ•ˆé˜²æ­¢æ”¹å˜åŸæ„çš„ä¸¥é‡é”™è¯¯ã€‚è¯¥å·¥ä½œè¯æ˜äº†å¼ºåŒ–å†…éƒ¨ä¸€è‡´æ€§æ˜¯æ„å»ºæ›´é²æ£’ã€æ›´å¯ä¿¡çš„è¯­éŸ³è¯†åˆ«ç³»ç»Ÿçš„å…³é”®ä¸€æ­¥ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.SD",
        "eess.AS"
      ],
      "primary_category": "cs.CL",
      "comment": "12 pages, 5figures",
      "pdf_url": "https://arxiv.org/pdf/2508.15853v1",
      "published_date": "2025-08-20 09:51:49 UTC",
      "updated_date": "2025-08-20 09:51:49 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T13:01:36.921759+00:00"
    },
    {
      "arxiv_id": "2509.08829v1",
      "title": "PerFairX: Is There a Balance Between Fairness and Personality in Large Language Model Recommendations?",
      "title_zh": "PerFairXï¼šå¤§è¯­è¨€æ¨¡å‹æ¨èä¸­å…¬å¹³æ€§ä¸ä¸ªæ€§åŒ–èƒ½å¦å…¼é¡¾ï¼Ÿ",
      "authors": [
        "Chandan Kumar Sah"
      ],
      "abstract": "The integration of Large Language Models (LLMs) into recommender systems has enabled zero-shot, personality-based personalization through prompt-based interactions, offering a new paradigm for user-centric recommendations. However, incorporating user personality traits via the OCEAN model highlights a critical tension between achieving psychological alignment and ensuring demographic fairness. To address this, we propose PerFairX, a unified evaluation framework designed to quantify the trade-offs between personalization and demographic equity in LLM-generated recommendations. Using neutral and personality-sensitive prompts across diverse user profiles, we benchmark two state-of-the-art LLMs, ChatGPT and DeepSeek, on movie (MovieLens 10M) and music (Last.fm 360K) datasets. Our results reveal that personality-aware prompting significantly improves alignment with individual traits but can exacerbate fairness disparities across demographic groups. Specifically, DeepSeek achieves stronger psychological fit but exhibits higher sensitivity to prompt variations, while ChatGPT delivers stable yet less personalized outputs. PerFairX provides a principled benchmark to guide the development of LLM-based recommender systems that are both equitable and psychologically informed, contributing to the creation of inclusive, user-centric AI applications in continual learning contexts.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†PerFairXï¼Œè¿™æ˜¯ä¸€ä¸ªç”¨äºé‡åŒ–å¤§è¯­è¨€æ¨¡å‹(LLM)æ¨èç³»ç»Ÿä¸­ä¸ªæ€§åŒ–ä¸äººå£ç»Ÿè®¡å…¬å¹³æ€§(demographic equity)ä¹‹é—´æƒè¡¡å…³ç³»çš„ç»Ÿä¸€è¯„ä¼°æ¡†æ¶ã€‚ç ”ç©¶é€šè¿‡OCEANæ¨¡å‹å°†ç”¨æˆ·äººæ ¼ç‰¹å¾æ•´åˆè‡³æç¤ºè¯ä¸­ï¼Œåœ¨ç”µå½±å’ŒéŸ³ä¹æ•°æ®é›†ä¸Šå¯¹ChatGPTå’ŒDeepSeekè¿›è¡Œäº†åŸºå‡†æµ‹è¯•ã€‚å®éªŒå‘ç°ï¼Œæ„ŸçŸ¥ä¸ªæ€§åŒ–çš„æç¤º(personality-aware prompting)è™½èƒ½æ˜¾è‘—æå‡æ¨¡å‹ä¸ä¸ªä½“ç‰¹å¾çš„å¿ƒç†å¥‘åˆåº¦ï¼Œå´å¯èƒ½åŠ å‰§äººå£ç»Ÿè®¡ç¾¤ä½“é—´çš„å…¬å¹³æ€§å¤±è¡¡ã€‚å…¶ä¸­ï¼ŒDeepSeekå±•ç°å‡ºæ›´å¼ºçš„å¿ƒç†å¥‘åˆèƒ½åŠ›ä½†å¯¹æç¤ºè¯å˜åŠ¨é«˜åº¦æ•æ„Ÿï¼Œè€ŒChatGPTåœ¨è¾“å‡ºç¨³å®šæ€§ä¸Šå ä¼˜ä½†ä¸ªæ€§åŒ–ç¨‹åº¦è¾ƒä½ã€‚è¯¥ç ”ç©¶ä¸ºæ„å»ºæ—¢ç¬¦åˆå¿ƒç†å­¦è®¤çŸ¥åˆå…·å¤‡å…¬å¹³æ€§çš„æ¨èç³»ç»Ÿæä¾›äº†æŒ‡å¯¼ï¼Œå¯¹å®ç°åŒ…å®¹æ€§ã€ä»¥ç”¨æˆ·ä¸ºä¸­å¿ƒçš„AIåº”ç”¨å…·æœ‰é‡è¦æ„ä¹‰ã€‚",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.CY",
      "comment": "10 pages, 5 figures. Accepted to the Workshop on Multimodal Continual Learning (MCL) at ICCV 2025. @2025 IEEE/CVF International Conference on Computer Vision Workshops (ICCVW), ICCV's 2025",
      "pdf_url": "https://arxiv.org/pdf/2509.08829v1",
      "published_date": "2025-08-20 09:41:53 UTC",
      "updated_date": "2025-08-20 09:41:53 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T13:01:42.527255+00:00"
    },
    {
      "arxiv_id": "2508.14564v1",
      "title": "Who Sees What? Structured Thought-Action Sequences for Epistemic Reasoning in LLMs",
      "title_zh": "è°çœ‹åˆ°äº†ä»€ä¹ˆï¼Ÿå¤§è¯­è¨€æ¨¡å‹ä¸­ç”¨äºè®¤çŸ¥æ¨ç†çš„ç»“æ„åŒ–æ€ç»´-åŠ¨ä½œåºåˆ—",
      "authors": [
        "Luca Annese",
        "Sabrina Patania",
        "Silvia Serino",
        "Tom Foulsham",
        "Silvia Rossi",
        "Azzurra Ruggeri",
        "Dimitri Ognibene"
      ],
      "abstract": "Recent advances in large language models (LLMs) and reasoning frameworks have opened new possibilities for improving the perspective -taking capabilities of autonomous agents. However, tasks that involve active perception, collaborative reasoning, and perspective taking (understanding what another agent can see or knows) pose persistent challenges for current LLM-based systems. This study investigates the potential of structured examples derived from transformed solution graphs generated by the Fast Downward planner to improve the performance of LLM-based agents within a ReAct framework. We propose a structured solution-processing pipeline that generates three distinct categories of examples: optimal goal paths (G-type), informative node paths (E-type), and step-by-step optimal decision sequences contrasting alternative actions (L-type). These solutions are further converted into ``thought-action'' examples by prompting an LLM to explicitly articulate the reasoning behind each decision. While L-type examples slightly reduce clarification requests and overall action steps, they do not yield consistent improvements. Agents are successful in tasks requiring basic attentional filtering but struggle in scenarios that required mentalising about occluded spaces or weighing the costs of epistemic actions. These findings suggest that structured examples alone are insufficient for robust perspective-taking, underscoring the need for explicit belief tracking, cost modelling, and richer environments to enable socially grounded collaboration in LLM-based agents.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å¦‚ä½•æå‡å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨è‡ªä¸»æ™ºèƒ½ä½“ä¸­çš„è§†è§’åˆ‡æ¢ï¼ˆperspective-takingï¼‰å’Œè®¤è¯†è®ºæ¨ç†ï¼ˆepistemic reasoningï¼‰èƒ½åŠ›ã€‚ç ”ç©¶è€…æå‡ºäº†ä¸€ç§ç»“æ„åŒ–è§£å†³æ–¹æ¡ˆå¤„ç†æµç¨‹ï¼Œåˆ©ç”¨ Fast Downward planner ç”Ÿæˆçš„è½¬æ¢è§£å›¾ï¼Œè¡ç”Ÿå‡ºç›®æ ‡è·¯å¾„ï¼ˆG-typeï¼‰ã€ä¿¡æ¯èŠ‚ç‚¹è·¯å¾„ï¼ˆE-typeï¼‰å’Œæ­¥éª¤æœ€ä¼˜å†³ç­–åºåˆ—ï¼ˆL-typeï¼‰ä¸‰ç±»ç»“æ„åŒ–ç¤ºä¾‹ï¼Œå¹¶å°†å…¶è½¬åŒ–ä¸ºâ€œæ€ç»´-è¡ŒåŠ¨â€ï¼ˆthought-actionï¼‰åºåˆ—ã€‚å®éªŒå‘ç°ï¼Œè™½ç„¶ L-type ç¤ºä¾‹åœ¨å‡å°‘æ¾„æ¸…è¯·æ±‚å’Œè¡ŒåŠ¨æ­¥éª¤æ–¹é¢æœ‰å°å¹…æ”¹å–„ï¼Œä½†å¹¶æœªå¸¦æ¥æŒç»­çš„æ€§èƒ½æå‡ã€‚æ™ºèƒ½ä½“åœ¨åŸºç¡€æ³¨æ„åŠ›è¿‡æ»¤ä»»åŠ¡ä¸­è¡¨ç°å°šå¯ï¼Œä½†åœ¨å¤„ç†é®æŒ¡ç©ºé—´çš„å¿ƒæ™ºåŒ–ï¼ˆmentalisingï¼‰æˆ–æƒè¡¡è®¤è¯†è®ºè¡ŒåŠ¨æˆæœ¬æ—¶é¢ä¸´æ˜¾è‘—å›°éš¾ã€‚ç ”ç©¶ç»“æœè¡¨æ˜ï¼Œä»…é ç»“æ„åŒ–ç¤ºä¾‹ä¸è¶³ä»¥å®ç°é²æ£’çš„è§†è§’åˆ‡æ¢èƒ½åŠ›ï¼Œå¼ºè°ƒäº†åœ¨ LLM æ™ºèƒ½ä½“ä¸­å¼•å…¥æ˜¾å¼ä¿¡å¿µè·Ÿè¸ªï¼ˆbelief trackingï¼‰å’Œæˆæœ¬å»ºæ¨¡ï¼ˆcost modellingï¼‰ä»¥å®ç°ç¤¾äº¤åä½œçš„å¿…è¦æ€§ã€‚",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.HC"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted at ICSR25",
      "pdf_url": "https://arxiv.org/pdf/2508.14564v1",
      "published_date": "2025-08-20 09:36:53 UTC",
      "updated_date": "2025-08-20 09:36:53 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T13:01:46.583464+00:00"
    },
    {
      "arxiv_id": "2508.14556v2",
      "title": "Mamba2 Meets Silence: Robust Vocal Source Separation for Sparse Regions",
      "title_zh": "Mamba2 é‡ä¸Šé™é»˜ï¼šé¢å‘ç¨€ç–åŒºåŸŸçš„é²æ£’äººå£°æºåˆ†ç¦»",
      "authors": [
        "Euiyeon Kim",
        "Yong-Hoon Choi"
      ],
      "abstract": "We introduce a new music source separation model tailored for accurate vocal isolation. Unlike Transformer-based approaches, which often fail to capture intermittently occurring vocals, our model leverages Mamba2, a recent state space model, to better capture long-range temporal dependencies. To handle long input sequences efficiently, we combine a band-splitting strategy with a dual-path architecture. Experiments show that our approach outperforms recent state-of-the-art models, achieving a cSDR of 11.03 dB-the best reported to date-and delivering substantial gains in uSDR. Moreover, the model exhibits stable and consistent performance across varying input lengths and vocal occurrence patterns. These results demonstrate the effectiveness of Mamba-based models for high-resolution audio processing and open up new directions for broader applications in audio research.",
      "tldr_zh": "è¯¥ç ”ç©¶ä»‹ç»äº†ä¸€ç§æ–°å‹éŸ³ä¹æºåˆ†ç¦»(Music Source Separation)æ¨¡å‹ï¼Œæ—¨åœ¨å®ç°ç²¾å‡†çš„äººå£°éš”ç¦»ã€‚é’ˆå¯¹Transformeræ¶æ„åœ¨å¤„ç†é—´æ­‡æ€§å‡ºç°çš„äººå£°æ—¶æ•æ‰èƒ½åŠ›ä¸è¶³çš„é—®é¢˜ï¼Œè¯¥æ¨¡å‹åˆ©ç”¨æœ€æ–°çš„çŠ¶æ€ç©ºé—´æ¨¡å‹(State Space Model) Mamba2 æ¥æ›´å¥½åœ°å»ºæ¨¡é•¿è·ç¦»æ—¶é—´ä¾èµ–å…³ç³»ã€‚ä¸ºäº†æå‡é•¿åºåˆ—å¤„ç†æ•ˆç‡ï¼Œç ”ç©¶è€…ç»“åˆäº†é¢‘å¸¦åˆ†å‰²ç­–ç•¥(Band-splitting Strategy)ä¸åŒè·¯å¾„æ¶æ„(Dual-path Architecture)ã€‚å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨cSDRæŒ‡æ ‡ä¸Šè¾¾åˆ°äº†ç›®å‰æœ€é«˜çš„11.03 dBï¼Œä¸”åœ¨uSDRæ–¹é¢ä¹Ÿå–å¾—äº†æ˜¾è‘—è¿›æ­¥ã€‚æ­¤å¤–ï¼Œè¯¥æ¨¡å‹åœ¨ä¸åŒè¾“å…¥é•¿åº¦åŠäººå£°åˆ†å¸ƒæ¨¡å¼ä¸‹å±•ç°å‡ºæå¼ºçš„ç¨³å®šæ€§ï¼ŒéªŒè¯äº†Mambaç³»åˆ—æ¨¡å‹åœ¨é«˜åˆ†è¾¨ç‡éŸ³é¢‘å¤„ç†é¢†åŸŸçš„å·¨å¤§æ½œåŠ›ã€‚",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.14556v2",
      "published_date": "2025-08-20 09:19:11 UTC",
      "updated_date": "2025-12-31 07:56:14 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T13:01:54.187978+00:00"
    },
    {
      "arxiv_id": "2508.14553v1",
      "title": "Towards LLM-generated explanations for Component-based Knowledge Graph Question Answering Systems",
      "title_zh": "é¢å‘åŸºäºç»„ä»¶çš„çŸ¥è¯†å›¾è°±é—®ç­”ç³»ç»Ÿçš„å¤§è¯­è¨€æ¨¡å‹ç”Ÿæˆè§£é‡Šç ”ç©¶",
      "authors": [
        "Dennis Schiese",
        "Aleksandr Perevalov",
        "Andreas Both"
      ],
      "abstract": "Over time, software systems have reached a level of complexity that makes it difficult for their developers and users to explain particular decisions made by them. In this paper, we focus on the explainability of component-based systems for Question Answering (QA). These components often conduct processes driven by AI methods, in which behavior and decisions cannot be clearly explained or justified, s.t., even for QA experts interpreting the executed process and its results is hard. To address this challenge, we present an approach that considers the components' input and output data flows as a source for representing the behavior and provide explanations for the components, enabling users to comprehend what happened. In the QA framework used here, the data flows of the components are represented as SPARQL queries (inputs) and RDF triples (outputs). Hence, we are also providing valuable insights on verbalization regarding these data types. In our experiments, the approach generates explanations while following template-based settings (baseline) or via the use of Large Language Models (LLMs) with different configurations (automatic generation). Our evaluation shows that the explanations generated via LLMs achieve high quality and mostly outperform template-based approaches according to the users' ratings. Therefore, it enables us to automatically explain the behavior and decisions of QA components to humans while using RDF and SPARQL as a context for explanations.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹åŸºäºç»„ä»¶çš„çŸ¥è¯†å›¾è°±é—®ç­”ç³»ç»Ÿï¼ˆKGQAï¼‰ä¸­ç”±äºAIé©±åŠ¨è¿‡ç¨‹å¯¼è‡´çš„å¤æ‚å†³ç­–éš¾ä»¥è§£é‡Šçš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§åˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ç”Ÿæˆè§£é‡Šçš„æ–°æ–¹æ³•ã€‚è¯¥æ–¹æ³•å°†ç»„ä»¶çš„è¾“å…¥ä¸è¾“å‡ºæ•°æ®æµä½œä¸ºè¡Œä¸ºè¡¨å¾çš„æ¥æºï¼Œå…·ä½“æ¶‰åŠå°† SPARQL æŸ¥è¯¢ï¼ˆè¾“å…¥ï¼‰å’Œ RDF ä¸‰å…ƒç»„ï¼ˆè¾“å‡ºï¼‰ä½œä¸ºç”Ÿæˆè§£é‡Šçš„ä¸Šä¸‹æ–‡ï¼Œå¹¶æä¾›äº†å…³äºè¿™äº›æ•°æ®ç±»å‹è¯­è¨€åŒ–çš„è§è§£ã€‚å®éªŒå¯¹æ¯”äº†åŸºäºæ¨¡æ¿çš„ä¼ ç»ŸåŸºå‡†æ–¹æ³•ä¸ä¸åŒé…ç½®ä¸‹çš„ LLMs è‡ªåŠ¨ç”Ÿæˆè§£é‡Šçš„æ•ˆæœï¼Œè¯„ä¼°ç»“æœæ˜¾ç¤ºï¼Œç”± LLMs ç”Ÿæˆçš„è§£é‡Šåœ¨è´¨é‡ä¸Šè¡¨ç°ä¼˜å¼‚ï¼Œä¸”åœ¨ç”¨æˆ·è¯„åˆ†ä¸­å¤§å¤šä¼˜äºåŸºäºæ¨¡æ¿çš„æ–¹æ³•ã€‚è¿™é¡¹å·¥ä½œå®ç°äº†å¯¹ QA ç»„ä»¶è¡Œä¸ºå’Œå†³ç­–çš„è‡ªåŠ¨åŒ–è§£é‡Šï¼Œä½¿ç”¨æˆ·èƒ½å¤Ÿæ›´å¥½åœ°ç†è§£å¤æ‚ç³»ç»Ÿçš„è¿è¡Œé€»è¾‘ï¼Œæ˜¾è‘—æå‡äº†ç³»ç»Ÿçš„é€æ˜åº¦ä¸å¯ä¿¡åº¦ã€‚",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "Presented at ICWI 2024, Zagreb. Released with ISBN: 978-989-8704-62-7. Data source: https://figshare.com/articles/dataset/Towards_LLM-generated_explanations_for_component-based_knowledge_graph_question_answering_systems/27079687",
      "pdf_url": "https://arxiv.org/pdf/2508.14553v1",
      "published_date": "2025-08-20 09:14:48 UTC",
      "updated_date": "2025-08-20 09:14:48 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T13:01:51.990352+00:00"
    },
    {
      "arxiv_id": "2508.14544v2",
      "title": "Adaptively Robust LLM Inference Optimization under Prediction Uncertainty",
      "title_zh": "é¢„æµ‹ä¸ç¡®å®šæ€§ä¸‹çš„å¤§è¯­è¨€æ¨¡å‹æ¨ç†è‡ªé€‚åº”é²æ£’ä¼˜åŒ–",
      "authors": [
        "Zixi Chen",
        "Yinyu Ye",
        "Zijie Zhou"
      ],
      "abstract": "We study the problem of optimizing Large Language Model (LLM) inference scheduling to minimize total latency. LLM inference is an online and multi-task service process and also heavily energy consuming by which a pre-trained LLM processes input requests and generates output tokens sequentially. Therefore, it is vital to improve its scheduling efficiency and reduce the power consumption while a great amount of prompt requests are arriving. A key challenge in LLM inference scheduling is that while the prompt length is known upon arrival, the output length, which critically impacts memory usage and processing time, is unknown. To address this uncertainty, we propose algorithms that leverage machine learning to predict output lengths, assuming the prediction provides an interval classification (min-max range) for each request.\n  We first design a conservative algorithm, $\\mathcal{A}_{\\max}$, which schedules requests based on the upper bound of predicted output lengths to prevent memory overflow. However, this approach is overly conservative: as prediction accuracy decreases, performance degrades significantly due to potential overestimation. To overcome this limitation, we propose $\\mathcal{A}_{\\min}$, an adaptive algorithm that initially treats the predicted lower bound as the output length and dynamically refines this estimate during inferencing. We prove that $\\mathcal{A}_{\\min}$ achieves a log-scale competitive ratio. Through numerical simulations, we demonstrate that $\\mathcal{A}_{\\min}$ often performs nearly as well as the hindsight scheduler, highlighting both its efficiency and robustness in practical scenarios. Moreover, $\\mathcal{A}_{\\min}$ relies solely on the lower bound of the prediction interval--an advantageous design choice since upper bounds on output length are typically more challenging to predict accurately.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†åœ¨é¢„æµ‹ä¸ç¡®å®šæ€§ä¸‹ä¼˜åŒ–å¤§å‹è¯­è¨€æ¨¡å‹(LLM)æ¨ç†è°ƒåº¦ä»¥æœ€å°åŒ–å»¶è¿Ÿçš„é—®é¢˜ã€‚é’ˆå¯¹æ¨ç†è¿‡ç¨‹ä¸­è¾“å‡ºé•¿åº¦æœªçŸ¥çš„æ ¸å¿ƒæŒ‘æˆ˜ï¼Œä½œè€…æå‡ºäº†åˆ©ç”¨æœºå™¨å­¦ä¹ é¢„æµ‹è¾“å‡ºé•¿åº¦åŒºé—´(min-max range)çš„ä¼˜åŒ–ç®—æ³•ã€‚ç ”ç©¶é¦–å…ˆè®¾è®¡äº†åŸºäºé¢„æµ‹ä¸Šé™çš„ä¿å®ˆç®—æ³•$\\mathcal{A}_{\\max}$ä»¥é˜²æ­¢å†…å­˜æº¢å‡ºï¼Œä½†å‘ç°å…¶åœ¨é¢„æµ‹ç²¾åº¦è¾ƒä½æ—¶æ•ˆç‡å—é™ã€‚ä¸ºæ­¤ï¼Œä½œè€…è¿›ä¸€æ­¥æå‡ºäº†è‡ªé€‚åº”ç®—æ³•$\\mathcal{A}_{\\min}$ï¼Œè¯¥ç®—æ³•åˆå§‹ä»¥é¢„æµ‹ä¸‹é™ä¸ºå‡†å¹¶åœ¨æ¨ç†è¿‡ç¨‹ä¸­åŠ¨æ€ä¿®æ­£ã€‚ç†è®ºè¯æ˜$\\mathcal{A}_{\\min}$å…·æœ‰å¯¹æ•°çº§çš„ç«äº‰æ¯”(competitive ratio)ï¼Œä¸”æ•°å€¼æ¨¡æ‹Ÿæ˜¾ç¤ºå…¶æ€§èƒ½æ¥è¿‘äº‹åè°ƒåº¦å™¨(hindsight scheduler)ã€‚ç”±äºè¾“å‡ºé•¿åº¦çš„ä¸‹é™é€šå¸¸æ¯”ä¸Šé™æ›´æ˜“äºå‡†ç¡®é¢„æµ‹ï¼Œ$\\mathcal{A}_{\\min}$åœ¨å®é™…åº”ç”¨ä¸­å±•ç°å‡ºäº†æé«˜çš„æ•ˆç‡ä¸ç¨³å¥æ€§ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "math.OC"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.14544v2",
      "published_date": "2025-08-20 08:55:26 UTC",
      "updated_date": "2025-09-01 07:38:03 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T13:02:02.654926+00:00"
    },
    {
      "arxiv_id": "2508.14540v1",
      "title": "Post-hoc LLM-Supported Debugging of Distributed Processes",
      "title_zh": "å¤§è¯­è¨€æ¨¡å‹æ”¯æŒçš„åˆ†å¸ƒå¼è¿›ç¨‹äº‹åè°ƒè¯•",
      "authors": [
        "Dennis Schiese",
        "Andreas Both"
      ],
      "abstract": "In this paper, we address the problem of manual debugging, which nowadays remains resource-intensive and in some parts archaic. This problem is especially evident in increasingly complex and distributed software systems. Therefore, our objective of this work is to introduce an approach that can possibly be applied to any system, at both the macro- and micro-level, to ease this debugging process. This approach utilizes a system's process data, in conjunction with generative AI, to generate natural-language explanations. These explanations are generated from the actual process data, interface information, and documentation to guide the developers more efficiently to understand the behavior and possible errors of a process and its sub-processes. Here, we present a demonstrator that employs this approach on a component-based Java system. However, our approach is language-agnostic. Ideally, the generated explanations will provide a good understanding of the process, even if developers are not familiar with all the details of the considered system. Our demonstrator is provided as an open-source web application that is freely accessible to all users.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹æ—¥ç›Šå¤æ‚ä¸”åˆ†å¸ƒå¼çš„è½¯ä»¶ç³»ç»Ÿä¸­æ‰‹åŠ¨è°ƒè¯•(manual debugging)è€—æ—¶ä¸”ç¹ççš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§åŸºäºå¤§è¯­è¨€æ¨¡å‹(LLM)æ”¯æŒçš„äº‹åè°ƒè¯•æ–¹æ³•ã€‚è¯¥æ–¹æ³•æ•´åˆäº†ç³»ç»Ÿçš„è¿‡ç¨‹æ•°æ®(process data)ã€æ¥å£ä¿¡æ¯å’Œç›¸å…³æ–‡æ¡£ï¼Œå¹¶ç»“åˆç”Ÿæˆå¼äººå·¥æ™ºèƒ½(Generative AI)æ¥ç”Ÿæˆè‡ªç„¶è¯­è¨€è§£é‡Šã€‚è¿™äº›è§£é‡Šæ—¨åœ¨å¼•å¯¼å¼€å‘è€…æ›´é«˜æ•ˆåœ°ç†è§£ä¸»è¿›ç¨‹åŠå…¶å­è¿›ç¨‹çš„è¡Œä¸ºå’Œæ½œåœ¨é”™è¯¯ï¼Œä»è€Œé™ä½å¯¹ç³»ç»Ÿç»†èŠ‚ç†Ÿæ‚‰ç¨‹åº¦çš„è¦æ±‚ã€‚è¯¥æ–¹æ¡ˆå…·æœ‰è¯­è¨€æ— å…³æ€§(language-agnostic)çš„ç‰¹ç‚¹ï¼Œèƒ½å¤Ÿä»å®è§‚å’Œå¾®è§‚ä¸¤ä¸ªå±‚é¢åº”ç”¨äºå„ç±»ç³»ç»Ÿè°ƒè¯•ã€‚ç ”ç©¶å›¢é˜Ÿé€šè¿‡ä¸€ä¸ªåŸºäº Java çš„æ¼”ç¤ºç³»ç»Ÿ(demonstrator)éªŒè¯äº†è¯¥æ–¹æ³•çš„æœ‰æ•ˆæ€§ï¼Œå¹¶å°†å…¶ä½œä¸ºå¼€æº Web åº”ç”¨ç¨‹åºå‘å¸ƒã€‚è¯¥ç ”ç©¶ä¸ºå¤æ‚åˆ†å¸ƒå¼ç¯å¢ƒä¸‹çš„æ•…éšœæ’æŸ¥æä¾›äº†ä¸€ç§æ›´ç›´è§‚ã€è‡ªåŠ¨åŒ–çš„æ–°é€”å¾„ã€‚",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "Presented at ICWE 2025, Delft (30 June - 03 July 2025)",
      "pdf_url": "https://arxiv.org/pdf/2508.14540v1",
      "published_date": "2025-08-20 08:45:53 UTC",
      "updated_date": "2025-08-20 08:45:53 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T13:02:02.455342+00:00"
    },
    {
      "arxiv_id": "2508.14536v1",
      "title": "Beyond ReLU: Chebyshev-DQN for Enhanced Deep Q-Networks",
      "title_zh": "è¶…è¶Š ReLUï¼šç”¨äºå¢å¼ºæ·±åº¦ Q ç½‘ç»œçš„ Chebyshev-DQN",
      "authors": [
        "Saman Yazdannik",
        "Morteza Tayefi",
        "Shamim Sanisales"
      ],
      "abstract": "The performance of Deep Q-Networks (DQN) is critically dependent on the ability of its underlying neural network to accurately approximate the action-value function. Standard function approximators, such as multi-layer perceptrons, may struggle to efficiently represent the complex value landscapes inherent in many reinforcement learning problems. This paper introduces a novel architecture, the Chebyshev-DQN (Ch-DQN), which integrates a Chebyshev polynomial basis into the DQN framework to create a more effective feature representation. By leveraging the powerful function approximation properties of Chebyshev polynomials, we hypothesize that the Ch-DQN can learn more efficiently and achieve higher performance. We evaluate our proposed model on the CartPole-v1 benchmark and compare it against a standard DQN with a comparable number of parameters. Our results demonstrate that the Ch-DQN with a moderate polynomial degree (N=4) achieves significantly better asymptotic performance, outperforming the baseline by approximately 39\\%. However, we also find that the choice of polynomial degree is a critical hyperparameter, as a high degree (N=8) can be detrimental to learning. This work validates the potential of using orthogonal polynomial bases in deep reinforcement learning while also highlighting the trade-offs involved in model complexity.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ Deep Q-Networks (DQN) åœ¨è¡¨ç¤ºå¤æ‚åŠ¨ä½œä»·å€¼å‡½æ•°æ–¹é¢çš„å±€é™æ€§ï¼Œæå‡ºäº†ä¸€ç§åä¸º Chebyshev-DQN (Ch-DQN) çš„æ–°å‹æ¶æ„ã€‚é€šè¿‡åœ¨ DQN æ¡†æ¶ä¸­é›†æˆ Chebyshev å¤šé¡¹å¼åŸºå‡½æ•°ï¼Œè¯¥æ–¹æ³•æ—¨åœ¨åˆ©ç”¨æ­£äº¤å¤šé¡¹å¼çš„å‡½æ•°é€¼è¿‘ç‰¹æ€§æ¥æ„å»ºæ›´æœ‰æ•ˆçš„ç‰¹å¾è¡¨ç¤ºã€‚åœ¨ CartPole-v1 åŸºå‡†æµ‹è¯•ä¸­çš„å®éªŒç»“æœè¡¨æ˜ï¼Œé˜¶æ•°ä¸º N=4 çš„ Ch-DQN åœ¨æ¸è¿‘æ€§èƒ½ä¸Šæ˜¾è‘—ä¼˜äºå‚æ•°é‡ç›¸å½“çš„åŸºå‡†æ¨¡å‹ï¼Œæå‡å¹…åº¦çº¦ 39%ã€‚ç„¶è€Œç ”ç©¶åŒæ—¶æŒ‡å‡ºï¼Œå¤šé¡¹å¼é˜¶æ•°æ˜¯ä¸€ä¸ªå…³é”®çš„è¶…å‚æ•°ï¼Œè¿‡é«˜çš„é˜¶æ•°ï¼ˆå¦‚ N=8ï¼‰åè€Œå¯èƒ½å¯¹å­¦ä¹ è¿‡ç¨‹äº§ç”Ÿè´Ÿé¢å½±å“ã€‚è¯¥å·¥ä½œéªŒè¯äº†åœ¨ Deep Reinforcement Learning (DRL) ä¸­åº”ç”¨æ­£äº¤å¤šé¡¹å¼åŸºçš„æ½œåŠ›ï¼Œå¹¶æ·±å…¥æ¢è®¨äº†æ¨¡å‹å¤æ‚æ€§ä¸æ€§èƒ½ä¹‹é—´çš„æƒè¡¡å…³ç³»ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.14536v1",
      "published_date": "2025-08-20 08:41:15 UTC",
      "updated_date": "2025-08-20 08:41:15 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T13:02:03.050143+00:00"
    },
    {
      "arxiv_id": "2508.14525v1",
      "title": "EffiFusion-GAN: Efficient Fusion Generative Adversarial Network for Speech Enhancement",
      "title_zh": "EffiFusion-GANï¼šé¢å‘è¯­éŸ³å¢å¼ºçš„é«˜æ•ˆèåˆç”Ÿæˆå¯¹æŠ—ç½‘ç»œ",
      "authors": [
        "Bin Wen",
        "Tien-Ping Tan"
      ],
      "abstract": "We introduce EffiFusion-GAN (Efficient Fusion Generative Adversarial Network), a lightweight yet powerful model for speech enhancement. The model integrates depthwise separable convolutions within a multi-scale block to capture diverse acoustic features efficiently. An enhanced attention mechanism with dual normalization and residual refinement further improves training stability and convergence. Additionally, dynamic pruning is applied to reduce model size while maintaining performance, making the framework suitable for resource-constrained environments. Experimental evaluation on the public VoiceBank+DEMAND dataset shows that EffiFusion-GAN achieves a PESQ score of 3.45, outperforming existing models under the same parameter settings.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† EffiFusion-GANï¼Œä¸€ç§ä¸“ä¸ºè¯­éŸ³å¢å¼ºè®¾è®¡çš„è½»é‡åŒ–ä¸”é«˜æ•ˆçš„ç”Ÿæˆå¯¹æŠ—ç½‘ç»œã€‚è¯¥æ¨¡å‹åœ¨å¤šå°ºåº¦æ¨¡å—ä¸­é›†æˆäº†æ·±åº¦å¯åˆ†ç¦»å·ç§¯(depthwise separable convolutions)ï¼Œä»¥é«˜æ•ˆæ•è·å¤šæ ·åŒ–çš„å£°å­¦ç‰¹å¾ã€‚é€šè¿‡å¼•å…¥ç»“åˆåŒé‡å½’ä¸€åŒ–å’Œæ®‹å·®ç»†åŒ–çš„å¢å¼ºæ³¨æ„åŠ›æœºåˆ¶ï¼Œæ¨¡å‹æ˜¾è‘—æå‡äº†è®­ç»ƒç¨³å®šæ€§å’Œæ”¶æ•›æ€§èƒ½ã€‚æ­¤å¤–ï¼Œç ”ç©¶é‡‡ç”¨äº†åŠ¨æ€å‰ªæ(dynamic pruning)æŠ€æœ¯åœ¨ä¿æŒæ€§èƒ½çš„åŒæ—¶å‡å°æ¨¡å‹ä½“ç§¯ï¼Œä½¿å…¶é€‚ç”¨äºèµ„æºå—é™çš„éƒ¨ç½²ç¯å¢ƒã€‚åœ¨ VoiceBank+DEMAND å…¬å¼€æ•°æ®é›†ä¸Šçš„å®éªŒç»“æœæ˜¾ç¤ºï¼ŒEffiFusion-GAN è¾¾åˆ°äº† 3.45 çš„ PESQ åˆ†æ•°ã€‚è¿™ä¸€è¡¨ç°ä¼˜äºç›¸åŒå‚æ•°è®¾ç½®ä¸‹çš„ç°æœ‰æ¨¡å‹ï¼Œè¯æ˜äº†å…¶åœ¨è¯­éŸ³å¢å¼ºä»»åŠ¡ä¸­çš„ä¼˜è¶Šæ€§ã€‚",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.14525v1",
      "published_date": "2025-08-20 08:36:43 UTC",
      "updated_date": "2025-08-20 08:36:43 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T13:02:10.383993+00:00"
    },
    {
      "arxiv_id": "2509.00025v1",
      "title": "DeepEmoNet: Building Machine Learning Models for Automatic Emotion Recognition in Human Speeches",
      "title_zh": "DeepEmoNetï¼šæ„å»ºç”¨äºäººç±»è¯­éŸ³è‡ªåŠ¨æƒ…æ„Ÿè¯†åˆ«çš„æœºå™¨å­¦ä¹ æ¨¡å‹",
      "authors": [
        "Tai Vu"
      ],
      "abstract": "Speech emotion recognition (SER) has been a challenging problem in spoken language processing research, because it is unclear how human emotions are connected to various components of sounds such as pitch, loudness, and energy. This paper aims to tackle this problem using machine learning. Particularly, we built several machine learning models using SVMs, LTSMs, and CNNs to classify emotions in human speeches. In addition, by leveraging transfer learning and data augmentation, we efficiently trained our models to attain decent performances on a relatively small dataset. Our best model was a ResNet34 network, which achieved an accuracy of $66.7\\%$ and an F1 score of $0.631$.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹è¯­éŸ³æƒ…æ„Ÿè¯†åˆ« (Speech emotion recognition, SER) ä¸­æƒ…æ„Ÿä¸å£°éŸ³ç‰©ç†ç‰¹å¾ï¼ˆå¦‚éŸ³é«˜ã€å“åº¦å’Œèƒ½é‡ï¼‰å…³è”ä¸æ˜ç¡®çš„æŒ‘æˆ˜ï¼Œæå‡ºäº†åŸºäºæœºå™¨å­¦ä¹ çš„åˆ†ç±»æ–¹æ¡ˆã€‚ç ”ç©¶è€…æ„å»ºäº†åŒ…æ‹¬ SVMsã€LTSMs å’Œ CNNs åœ¨å†…çš„å¤šç§æ¨¡å‹ï¼Œæ—¨åœ¨å®ç°å¯¹äººç±»è¯­éŸ³æƒ…æ„Ÿçš„è‡ªåŠ¨è¯†åˆ«ã€‚é€šè¿‡å¼•å…¥è¿ç§»å­¦ä¹  (transfer learning) å’Œæ•°æ®å¢å¼º (data augmentation) æŠ€æœ¯ï¼Œè¯¥ç ”ç©¶æˆåŠŸåœ¨è¾ƒå°è§„æ¨¡çš„æ•°æ®é›†ä¸Šå®Œæˆäº†æ¨¡å‹çš„é«˜æ•ˆè®­ç»ƒå¹¶å–å¾—äº†ç†æƒ³æ€§èƒ½ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¡¨ç°æœ€ä½³çš„ ResNet34 ç½‘ç»œå®ç°äº† 66.7% çš„å‡†ç¡®ç‡ (accuracy) å’Œ 0.631 çš„ F1 scoreã€‚è¯¥å·¥ä½œè¯æ˜äº†æ·±åº¦å­¦ä¹ æ¶æ„åœ¨å¤„ç†å¤æ‚è¯­éŸ³ä¿¡å·æ–¹é¢çš„æœ‰æ•ˆæ€§ï¼Œä¸ºè‡ªåŠ¨åŒ–è¯­éŸ³æƒ…æ„Ÿè¯†åˆ«é¢†åŸŸæä¾›äº†é‡è¦çš„å®è·µå‚è€ƒã€‚",
      "categories": [
        "eess.AS",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "eess.AS",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.00025v1",
      "published_date": "2025-08-20 08:34:28 UTC",
      "updated_date": "2025-08-20 08:34:28 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T13:02:16.499323+00:00"
    },
    {
      "arxiv_id": "2508.14515v1",
      "title": "MISS: Multi-Modal Tree Indexing and Searching with Lifelong Sequential Behavior for Retrieval Recommendation",
      "title_zh": "MISSï¼šåŸºäºç»ˆç”Ÿåºåˆ—è¡Œä¸ºçš„å¤šæ¨¡æ€æ ‘ç´¢å¼•ä¸æœç´¢æ£€ç´¢æ¨è",
      "authors": [
        "Chengcheng Guo",
        "Junda She",
        "Kuo Cai",
        "Shiyao Wang",
        "Qigen Hu",
        "Qiang Luo",
        "Kun Gai",
        "Guorui Zhou"
      ],
      "abstract": "Large-scale industrial recommendation systems typically employ a two-stage paradigm of retrieval and ranking to handle huge amounts of information. Recent research focuses on improving the performance of retrieval model. A promising way is to introduce extensive information about users and items. On one hand, lifelong sequential behavior is valuable. Existing lifelong behavior modeling methods in ranking stage focus on the interaction of lifelong behavior and candidate items from retrieval stage. In retrieval stage, it is difficult to utilize lifelong behavior because of a large corpus of candidate items. On the other hand, existing retrieval methods mostly relay on interaction information, potentially disregarding valuable multi-modal information. To solve these problems, we represent the pioneering exploration of leveraging multi-modal information and lifelong sequence model within the advanced tree-based retrieval model. We propose Multi-modal Indexing and Searching with lifelong Sequence (MISS), which contains a multi-modal index tree and a multi-modal lifelong sequence modeling module. Specifically, for better index structure, we propose multi-modal index tree, which is built using the multi-modal embedding to precisely represent item similarity. To precisely capture diverse user interests in user lifelong sequence, we propose collaborative general search unit (Co-GSU) and multi-modal general search unit (MM-GSU) for multi-perspective interests searching.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†MISSï¼Œä¸€ç§èåˆå¤šæ¨¡æ€ä¿¡æ¯ä¸ç»ˆèº«åºåˆ—è¡Œä¸º(lifelong sequential behavior)çš„æ ‘ç»“æ„æ£€ç´¢æ¨¡å‹ï¼Œæ—¨åœ¨è§£å†³å·¥ä¸šçº§æ¨èç³»ç»Ÿä¸­é•¿å‘¨æœŸè¡Œä¸ºæ•°æ®éš¾ä»¥åº”ç”¨äºæ£€ç´¢é˜¶æ®µä»¥åŠå¤šæ¨¡æ€ä¿¡æ¯åˆ©ç”¨ä¸è¶³çš„é—®é¢˜ã€‚MISSçš„æ ¸å¿ƒåŒ…å«ä¸€ä¸ªå¤šæ¨¡æ€ç´¢å¼•æ ‘å’Œä¸€ä¸ªå¤šæ¨¡æ€ç»ˆèº«åºåˆ—å»ºæ¨¡æ¨¡å—ï¼Œæ˜¯è¯¥é¢†åŸŸé¦–æ¬¡åœ¨æ ‘çŠ¶æ£€ç´¢æ¡†æ¶ä¸‹åŒæ—¶å¼•å…¥è¿™ä¸¤ç±»ä¿¡æ¯çš„æ¢ç´¢ã€‚å…·ä½“è€Œè¨€ï¼Œå¤šæ¨¡æ€ç´¢å¼•æ ‘é€šè¿‡åˆ©ç”¨multi-modal embeddingæ¥ç²¾å‡†è¡¨å¾itemç›¸ä¼¼åº¦ï¼Œä»è€Œæ„å»ºæ›´ä¼˜çš„ç´¢å¼•ç»“æ„ã€‚é’ˆå¯¹ç”¨æˆ·é•¿è¾¾ç»ˆèº«çš„äº¤äº’åºåˆ—ï¼Œç ”ç©¶è®¾è®¡äº†ååŒé€šç”¨æœç´¢å•å…ƒ(Co-GSU)å’Œå¤šæ¨¡æ€é€šç”¨æœç´¢å•å…ƒ(MM-GSU)ï¼Œä»¥å®ç°å¤šç»´åº¦çš„ç”¨æˆ·å…´è¶£æ•æ‰ã€‚è¿™ç§æ–¹æ³•èƒ½å¤Ÿåœ¨å¤§è§„æ¨¡å€™é€‰æ± ä¸­æ›´æœ‰æ•ˆåœ°æå–ç”¨æˆ·æ½œåœ¨åå¥½ï¼Œæ˜¾è‘—æå‡äº†æ¨èç³»ç»Ÿåœ¨æ£€ç´¢é˜¶æ®µçš„æ•ˆèƒ½ä¸è¡¨å¾ç²¾åº¦ã€‚",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "CIKM 2025",
      "pdf_url": "https://arxiv.org/pdf/2508.14515v1",
      "published_date": "2025-08-20 08:22:02 UTC",
      "updated_date": "2025-08-20 08:22:02 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T13:02:42.201930+00:00"
    },
    {
      "arxiv_id": "2508.14504v1",
      "title": "PB-IAD: Utilizing multimodal foundation models for semantic industrial anomaly detection in dynamic manufacturing environments",
      "title_zh": "PB-IADï¼šåˆ©ç”¨å¤šæ¨¡æ€åŸºç¡€æ¨¡å‹å®ç°åŠ¨æ€åˆ¶é€ ç¯å¢ƒä¸‹çš„è¯­ä¹‰å·¥ä¸šå¼‚å¸¸æ£€æµ‹",
      "authors": [
        "Bernd Hofmann",
        "Albert Scheck",
        "Joerg Franke",
        "Patrick Bruendl"
      ],
      "abstract": "The detection of anomalies in manufacturing processes is crucial to ensure product quality and identify process deviations. Statistical and data-driven approaches remain the standard in industrial anomaly detection, yet their adaptability and usability are constrained by the dependence on extensive annotated datasets and limited flexibility under dynamic production conditions. Recent advances in the perception capabilities of foundation models provide promising opportunities for their adaptation to this downstream task. This paper presents PB-IAD (Prompt-based Industrial Anomaly Detection), a novel framework that leverages the multimodal and reasoning capabilities of foundation models for industrial anomaly detection. Specifically, PB-IAD addresses three key requirements of dynamic production environments: data sparsity, agile adaptability, and domain user centricity. In addition to the anomaly detection, the framework includes a prompt template that is specifically designed for iteratively implementing domain-specific process knowledge, as well as a pre-processing module that translates domain user inputs into effective system prompts. This user-centric design allows domain experts to customise the system flexibly without requiring data science expertise. The proposed framework is evaluated by utilizing GPT-4.1 across three distinct manufacturing scenarios, two data modalities, and an ablation study to systematically assess the contribution of semantic instructions. Furthermore, PB-IAD is benchmarked to state-of-the-art methods for anomaly detection such as PatchCore. The results demonstrate superior performance, particularly in data-sparse scenarios and low-shot settings, achieved solely through semantic instructions.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† PB-IADï¼ˆPrompt-based Industrial Anomaly Detectionï¼‰ï¼Œè¿™æ˜¯ä¸€ä¸ªåˆ©ç”¨å¤šæ¨¡æ€åŸºç¡€æ¨¡å‹ï¼ˆmultimodal foundation modelsï¼‰åŠå…¶æ¨ç†èƒ½åŠ›è¿›è¡Œè¯­ä¹‰å·¥ä¸šå¼‚å¸¸æ£€æµ‹çš„æ–°å‹æ¡†æ¶ã€‚é’ˆå¯¹åŠ¨æ€åˆ¶é€ ç¯å¢ƒä¸­çš„æ•°æ®ç¨€ç–å’Œæ•æ·é€‚åº”æ€§éœ€æ±‚ï¼ŒPB-IAD å¼•å…¥äº†ä¸“é—¨çš„æç¤ºæ¨¡æ¿ï¼ˆprompt templateï¼‰æ¥é›†æˆé¢†åŸŸç‰¹å®šå·¥è‰ºçŸ¥è¯†ï¼Œå¹¶é€šè¿‡é¢„å¤„ç†æ¨¡å—å°†é¢†åŸŸç”¨æˆ·è¾“å…¥è½¬åŒ–ä¸ºé«˜æ•ˆçš„ç³»ç»Ÿæç¤ºã€‚è¿™ç§ä»¥ç”¨æˆ·ä¸ºä¸­å¿ƒçš„è®¾è®¡å…è®¸ä¸“å®¶åœ¨æ— éœ€æ•°æ®ç§‘å­¦èƒŒæ™¯çš„æƒ…å†µä¸‹çµæ´»å®šåˆ¶ç³»ç»Ÿï¼Œä»è€Œå®ç°å¿«é€Ÿéƒ¨ç½²ã€‚é€šè¿‡å¯¹ GPT-4 åœ¨å¤šç§åˆ¶é€ åœºæ™¯å’Œæ•°æ®æ¨¡æ€ä¸‹çš„è¯„ä¼°ï¼Œå¹¶ä¸ PatchCore ç­‰æœ€å…ˆè¿›çš„æ–¹æ³•è¿›è¡ŒåŸºå‡†æµ‹è¯•ï¼Œå®éªŒç»“æœè¯æ˜ PB-IAD å±•ç°å‡ºå“è¶Šçš„æ€§èƒ½ã€‚è¯¥æ¡†æ¶åœ¨æ•°æ®ç¨€ç–å’Œå°‘é‡æ ·æœ¬ï¼ˆlow-shotï¼‰è®¾ç½®ä¸‹è¡¨ç°å°¤ä¸ºçªå‡ºï¼Œä»…é€šè¿‡è¯­ä¹‰æŒ‡ä»¤ï¼ˆsemantic instructionsï¼‰å³å¯å®ç°ç²¾å‡†çš„å¼‚å¸¸è¯†åˆ«ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.14504v1",
      "published_date": "2025-08-20 07:53:13 UTC",
      "updated_date": "2025-08-20 07:53:13 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T13:02:43.595632+00:00"
    },
    {
      "arxiv_id": "2508.14499v1",
      "title": "Exact Shapley Attributions in Quadratic-time for FANOVA Gaussian Processes",
      "title_zh": "FANOVA é«˜æ–¯è¿‡ç¨‹çš„å¹³æ–¹æ—¶é—´ç²¾ç¡® Shapley å½’å› ",
      "authors": [
        "Majid Mohammadi",
        "Krikamol Muandet",
        "Ilaria Tiddi",
        "Annette Ten Teije",
        "Siu Lun Chau"
      ],
      "abstract": "Shapley values are widely recognized as a principled method for attributing importance to input features in machine learning. However, the exact computation of Shapley values scales exponentially with the number of features, severely limiting the practical application of this powerful approach. The challenge is further compounded when the predictive model is probabilistic - as in Gaussian processes (GPs) - where the outputs are random variables rather than point estimates, necessitating additional computational effort in modeling higher-order moments. In this work, we demonstrate that for an important class of GPs known as FANOVA GP, which explicitly models all main effects and interactions, *exact* Shapley attributions for both local and global explanations can be computed in *quadratic time*. For local, instance-wise explanations, we define a stochastic cooperative game over function components and compute the exact stochastic Shapley value in quadratic time only, capturing both the expected contribution and uncertainty. For global explanations, we introduce a deterministic, variance-based value function and compute exact Shapley values that quantify each feature's contribution to the model's overall sensitivity. Our methods leverage a closed-form (stochastic) MÃ¶bius representation of the FANOVA decomposition and introduce recursive algorithms, inspired by Newton's identities, to efficiently compute the mean and variance of Shapley values. Our work enhances the utility of explainable AI, as demonstrated by empirical studies, by providing more scalable, axiomatically sound, and uncertainty-aware explanations for predictions generated by structured probabilistic models.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ Shapley values è®¡ç®—å¤æ‚åº¦éšç‰¹å¾æ•°é‡å‘ˆæŒ‡æ•°çº§å¢é•¿çš„ç“¶é¢ˆï¼Œæå‡ºäº†ä¸€ç§é’ˆå¯¹ FANOVA Gaussian Processes (FANOVA GP) çš„é«˜æ•ˆå½’å› æ–¹æ³•ã€‚å¯¹äºå±€éƒ¨å®ä¾‹çº§è§£é‡Šï¼Œè¯¥æ–¹æ³•é€šè¿‡åœ¨å‡½æ•°ç»„ä»¶ä¸Šå®šä¹‰éšæœºåˆä½œåšå¼ˆï¼Œä»…éœ€äºŒæ¬¡æ—¶é—´å³å¯è®¡ç®—å‡ºç²¾ç¡®çš„ stochastic Shapley valueï¼Œå¹¶åŒæ—¶æ•æ‰ç‰¹å¾çš„æœŸæœ›è´¡çŒ®ä¸ä¸ç¡®å®šæ€§ã€‚é’ˆå¯¹å…¨å±€è§£é‡Šï¼Œç ”ç©¶å¼•å…¥äº†åŸºäºæ–¹å·®çš„ç¡®å®šæ€§å€¼å‡½æ•°ï¼Œèƒ½å¤Ÿç²¾ç¡®é‡åŒ–æ¯ä¸ªç‰¹å¾å¯¹æ¨¡å‹æ•´ä½“æ•æ„Ÿåº¦çš„è´¡çŒ®ã€‚æŠ€æœ¯ä¸Šï¼Œè¯¥æ–¹æ³•åˆ©ç”¨äº† FANOVA åˆ†è§£çš„é—­å¼ (stochastic) MÃ¶bius representationï¼Œå¹¶ç»“åˆå— Newton's identities å¯å‘çš„é€’å½’ç®—æ³•å®ç°äº†é«˜æ•ˆè®¡ç®—ã€‚å®éªŒè¡¨æ˜ï¼Œè¯¥å·¥ä½œæ˜¾è‘—æå‡äº†å¯è§£é‡Š AI (XAI) çš„æ‰©å±•æ€§ï¼Œä¸ºç»“æ„åŒ–æ¦‚ç‡æ¨¡å‹æä¾›äº†ç¬¦åˆå…¬ç†åŒ–è¦æ±‚ä¸”å…·å¤‡ä¸ç¡®å®šæ€§æ„ŸçŸ¥èƒ½åŠ›çš„è§£é‡Šæ–¹æ¡ˆã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.14499v1",
      "published_date": "2025-08-20 07:39:14 UTC",
      "updated_date": "2025-08-20 07:39:14 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T13:02:47.994191+00:00"
    },
    {
      "arxiv_id": "2508.14492v1",
      "title": "Synaptic bundle theory for spike-driven sensor-motor system: More than eight independent synaptic bundles collapse reward-STDP learning",
      "title_zh": "è„‰å†²é©±åŠ¨æ„ŸçŸ¥-è¿åŠ¨ç³»ç»Ÿçš„çªè§¦æŸç†è®ºï¼šè¶…è¿‡å…«ä¸ªç‹¬ç«‹çªè§¦æŸå°†å¯¼è‡´å¥–åŠ±å‹ STDP å­¦ä¹ å´©æºƒ",
      "authors": [
        "Takeshi Kobayashi",
        "Shogo Yonekura",
        "Yasuo Kuniyoshi"
      ],
      "abstract": "Neuronal spikes directly drive muscles and endow animals with agile movements, but applying the spike-based control signals to actuators in artificial sensor-motor systems inevitably causes a collapse of learning. We developed a system that can vary \\emph{the number of independent synaptic bundles} in sensor-to-motor connections. This paper demonstrates the following four findings: (i) Learning collapses once the number of motor neurons or the number of independent synaptic bundles exceeds a critical limit. (ii) The probability of learning failure is increased by a smaller number of motor neurons, while (iii) if learning succeeds, a smaller number of motor neurons leads to faster learning. (iv) The number of weight updates that move in the opposite direction of the optimal weight can quantitatively explain these results. The functions of spikes remain largely unknown. Identifying the parameter range in which learning systems using spikes can be constructed will make it possible to study the functions of spikes that were previously inaccessible due to the difficulty of learning.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†è„‰å†²é©±åŠ¨(spike-driven)ä¼ æ„Ÿå™¨-ç”µæœºç³»ç»Ÿä¸­çš„çªè§¦æŸç†è®º(Synaptic bundle theory)ï¼Œæ—¨åœ¨è§£å†³è„‰å†²æ§åˆ¶ä¿¡å·å¯¼è‡´äººå·¥ç³»ç»Ÿä¸­å­¦ä¹ å´©æºƒçš„é—®é¢˜ã€‚ç ”ç©¶è€…å¼€å‘äº†ä¸€ä¸ªå¯å˜ç‹¬ç«‹çªè§¦æŸ(independent synaptic bundles)æ•°é‡çš„ç³»ç»Ÿï¼Œå¹¶å‘ç°å½“ç‹¬ç«‹çªè§¦æŸæ•°é‡è¶…è¿‡ä¸´ç•Œé™åˆ¶ï¼ˆå¤šäºå…«ä¸ªï¼‰æ—¶ï¼Œå¥–åŠ±ä¾èµ–çªè§¦å¯å¡‘æ€§(reward-STDP)å­¦ä¹ ä¼šå‘ç”Ÿå´©æºƒã€‚å®éªŒè¡¨æ˜ï¼Œè¿åŠ¨ç¥ç»å…ƒ(motor neurons)æ•°é‡è¾ƒå°‘æ—¶å­¦ä¹ å¤±è´¥æ¦‚ç‡å¢åŠ ï¼Œä½†åœ¨æˆåŠŸå­¦ä¹ çš„å‰æä¸‹ï¼Œè¾ƒå°‘çš„è¿åŠ¨ç¥ç»å…ƒèƒ½æ˜¾è‘—æå‡å­¦ä¹ é€Ÿåº¦ã€‚ç ”ç©¶è¿›ä¸€æ­¥é€šè¿‡åˆ†æå‘æœ€ä¼˜æƒé‡åæ–¹å‘æ›´æ–°çš„æ¬¡æ•°ï¼Œä»å®šé‡è§’åº¦è§£é‡Šäº†è¿™äº›å­¦ä¹ ç»“æœã€‚è¯¥æˆæœæ˜ç¡®äº†æ„å»ºåŸºäºè„‰å†²çš„å­¦ä¹ ç³»ç»Ÿçš„å…³é”®å‚æ•°èŒƒå›´ï¼Œä¸ºæ¢ç´¢æ­¤å‰å› å­¦ä¹ å›°éš¾è€Œéš¾ä»¥è§¦åŠçš„è„‰å†²åŠŸèƒ½å¥ å®šäº†åŸºç¡€ã€‚",
      "categories": [
        "q-bio.NC",
        "cs.AI",
        "nlin.AO"
      ],
      "primary_category": "q-bio.NC",
      "comment": "5 pages, 4 figures",
      "pdf_url": "https://arxiv.org/pdf/2508.14492v1",
      "published_date": "2025-08-20 07:29:33 UTC",
      "updated_date": "2025-08-20 07:29:33 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T13:03:08.046629+00:00"
    },
    {
      "arxiv_id": "2508.14472v1",
      "title": "In2x at WMT25 Translation Task",
      "title_zh": "In2x å‚åŠ  WMT25 ç¿»è¯‘ä»»åŠ¡",
      "authors": [
        "Lei Pang",
        "Hanyi Mao",
        "Quanjia Xiao",
        "HaiXiao Liu",
        "Xiangyi Li"
      ],
      "abstract": "This paper presents the open-system submission by the In2x research team for the WMT25 General Machine Translation Shared Task. Our submission focuses on Japanese-related translation tasks, aiming to explore a generalizable paradigm for extending large language models (LLMs) to other languages. This paradigm encompasses aspects such as data construction methods and reward model design. The ultimate goal is to enable large language model systems to achieve exceptional performance in low-resource or less commonly spoken languages.",
      "tldr_zh": "è¯¥ç ”ç©¶ä»‹ç»äº†In2xç ”ç©¶å›¢é˜Ÿåœ¨WMT25é€šç”¨æœºå™¨ç¿»è¯‘(General Machine Translation)å…±äº«ä»»åŠ¡ä¸­çš„ç³»ç»Ÿæäº¤æ–¹æ¡ˆã€‚è¯¥å·¥ä½œä¸»è¦èšç„¦äºæ—¥è¯­ç›¸å…³çš„ç¿»è¯‘ä»»åŠ¡ï¼Œæ—¨åœ¨æ¢ç´¢ä¸€ç§å°†å¤§å‹è¯­è¨€æ¨¡å‹(LLMs)æ‰©å±•è‡³å…¶ä»–è¯­è¨€çš„é€šç”¨èŒƒå¼ã€‚è¯¥èŒƒå¼æ·±å…¥æ¢è®¨äº†æ•°æ®æ„å»ºæ–¹æ³•å’Œå¥–åŠ±æ¨¡å‹(Reward Model)è®¾è®¡ï¼Œè‡´åŠ›äºæå‡å¤§è¯­è¨€æ¨¡å‹ç³»ç»Ÿåœ¨ä½èµ„æºè¯­è¨€æˆ–éé€šç”¨è¯­ç§ä¸­çš„ç¿»è¯‘æ€§èƒ½ã€‚é€šè¿‡è¿™ä¸€ç³»åˆ—æ–¹æ³•ï¼Œç ”ç©¶å›¢é˜Ÿå±•ç¤ºäº†å¦‚ä½•åœ¨ç‰¹å®šè¯­ç§ä»»åŠ¡ä¸­å®ç°å“è¶Šçš„ç¿»è¯‘æ•ˆæœï¼Œä¸ºå¤šè¯­è¨€ç¿»è¯‘æŠ€æœ¯çš„è·¨è¯­è¨€è¿ç§»æä¾›äº†å…·æœ‰å‚è€ƒä»·å€¼çš„å®è·µè·¯å¾„ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.14472v1",
      "published_date": "2025-08-20 06:52:42 UTC",
      "updated_date": "2025-08-20 06:52:42 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T13:02:53.107791+00:00"
    },
    {
      "arxiv_id": "2508.14444v4",
      "title": "NVIDIA Nemotron Nano 2: An Accurate and Efficient Hybrid Mamba-Transformer Reasoning Model",
      "title_zh": "NVIDIA Nemotron Nano 2ï¼šä¸€ç§å‡†ç¡®ã€é«˜æ•ˆçš„ Mamba-Transformer æ··åˆæ¨ç†æ¨¡å‹",
      "authors": [
        "NVIDIA",
        ":",
        "Aarti Basant",
        "Abhijit Khairnar",
        "Abhijit Paithankar",
        "Abhinav Khattar",
        "Adithya Renduchintala",
        "Aditya Malte",
        "Akhiad Bercovich",
        "Akshay Hazare",
        "Alejandra Rico",
        "Aleksander Ficek",
        "Alex Kondratenko",
        "Alex Shaposhnikov",
        "Alexander Bukharin",
        "Ali Taghibakhshi",
        "Amelia Barton",
        "Ameya Sunil Mahabaleshwarkar",
        "Amy Shen",
        "Andrew Tao",
        "Ann Guan",
        "Anna Shors",
        "Anubhav Mandarwal",
        "Arham Mehta",
        "Arun Venkatesan",
        "Ashton Sharabiani",
        "Ashwath Aithal",
        "Ashwin Poojary",
        "Ayush Dattagupta",
        "Balaram Buddharaju",
        "Banghua Zhu",
        "Barnaby Simkin",
        "Bilal Kartal",
        "Bita Darvish Rouhani",
        "Bobby Chen",
        "Boris Ginsburg",
        "Brandon Norick",
        "Brian Yu",
        "Bryan Catanzaro",
        "Charles Wang",
        "Charlie Truong",
        "Chetan Mungekar",
        "Chintan Patel",
        "Chris Alexiuk",
        "Christian Munley",
        "Christopher Parisien",
        "Dan Su",
        "Daniel Afrimi",
        "Daniel Korzekwa",
        "Daniel Rohrer",
        "Daria Gitman",
        "David Mosallanezhad",
        "Deepak Narayanan",
        "Dima Rekesh",
        "Dina Yared",
        "Dmytro Pykhtar",
        "Dong Ahn",
        "Duncan Riach",
        "Eileen Long",
        "Elliott Ning",
        "Eric Chung",
        "Erick Galinkin",
        "Evelina Bakhturina",
        "Gargi Prasad",
        "Gerald Shen",
        "Haifeng Qian",
        "Haim Elisha",
        "Harsh Sharma",
        "Hayley Ross",
        "Helen Ngo",
        "Herman Sahota",
        "Hexin Wang",
        "Hoo Chang Shin",
        "Hua Huang",
        "Iain Cunningham",
        "Igor Gitman",
        "Ivan Moshkov",
        "Jaehun Jung",
        "Jan Kautz",
        "Jane Polak Scowcroft",
        "Jared Casper",
        "Jian Zhang",
        "Jiaqi Zeng",
        "Jimmy Zhang",
        "Jinze Xue",
        "Jocelyn Huang",
        "Joey Conway",
        "John Kamalu",
        "Jonathan Cohen",
        "Joseph Jennings",
        "Julien Veron Vialard",
        "Junkeun Yi",
        "Jupinder Parmar",
        "Kari Briski",
        "Katherine Cheung",
        "Katherine Luna",
        "Keith Wyss",
        "Keshav Santhanam",
        "Kezhi Kong",
        "Krzysztof Pawelec",
        "Kumar Anik",
        "Kunlun Li",
        "Kushan Ahmadian",
        "Lawrence McAfee",
        "Laya Sleiman",
        "Leon Derczynski",
        "Luis Vega",
        "Maer Rodrigues de Melo",
        "Makesh Narsimhan Sreedhar",
        "Marcin Chochowski",
        "Mark Cai",
        "Markus Kliegl",
        "Marta Stepniewska-Dziubinska",
        "Matvei Novikov",
        "Mehrzad Samadi",
        "Meredith Price",
        "Meriem Boubdir",
        "Michael Boone",
        "Michael Evans",
        "Michal Bien",
        "Michal Zawalski",
        "Miguel Martinez",
        "Mike Chrzanowski",
        "Mohammad Shoeybi",
        "Mostofa Patwary",
        "Namit Dhameja",
        "Nave Assaf",
        "Negar Habibi",
        "Nidhi Bhatia",
        "Nikki Pope",
        "Nima Tajbakhsh",
        "Nirmal Kumar Juluru",
        "Oleg Rybakov",
        "Oleksii Hrinchuk",
        "Oleksii Kuchaiev",
        "Oluwatobi Olabiyi",
        "Pablo Ribalta",
        "Padmavathy Subramanian",
        "Parth Chadha",
        "Pavlo Molchanov",
        "Peter Dykas",
        "Peter Jin",
        "Piotr Bialecki",
        "Piotr Januszewski",
        "Pradeep Thalasta",
        "Prashant Gaikwad",
        "Prasoon Varshney",
        "Pritam Gundecha",
        "Przemek Tredak",
        "Rabeeh Karimi Mahabadi",
        "Rajen Patel",
        "Ran El-Yaniv",
        "Ranjit Rajan",
        "Ria Cheruvu",
        "Rima Shahbazyan",
        "Ritika Borkar",
        "Ritu Gala",
        "Roger Waleffe",
        "Ruoxi Zhang",
        "Russell J. Hewett",
        "Ryan Prenger",
        "Sahil Jain",
        "Samuel Kriman",
        "Sanjeev Satheesh",
        "Saori Kaji",
        "Sarah Yurick",
        "Saurav Muralidharan",
        "Sean Narenthiran",
        "Seonmyeong Bak",
        "Sepehr Sameni",
        "Seungju Han",
        "Shanmugam Ramasamy",
        "Shaona Ghosh",
        "Sharath Turuvekere Sreenivas",
        "Shelby Thomas",
        "Shizhe Diao",
        "Shreya Gopal",
        "Shrimai Prabhumoye",
        "Shubham Toshniwal",
        "Shuoyang Ding",
        "Siddharth Singh",
        "Siddhartha Jain",
        "Somshubra Majumdar",
        "Soumye Singhal",
        "Stefania Alborghetti",
        "Syeda Nahida Akter",
        "Terry Kong",
        "Tim Moon",
        "Tomasz Hliwiak",
        "Tomer Asida",
        "Tony Wang",
        "Tugrul Konuk",
        "Twinkle Vashishth",
        "Tyler Poon",
        "Udi Karpas",
        "Vahid Noroozi",
        "Venkat Srinivasan",
        "Vijay Korthikanti",
        "Vikram Fugro",
        "Vineeth Kalluru",
        "Vitaly Kurin",
        "Vitaly Lavrukhin",
        "Wasi Uddin Ahmad",
        "Wei Du",
        "Wonmin Byeon",
        "Ximing Lu",
        "Xin Dong",
        "Yashaswi Karnati",
        "Yejin Choi",
        "Yian Zhang",
        "Ying Lin",
        "Yonggan Fu",
        "Yoshi Suhara",
        "Zhen Dong",
        "Zhiyu Li",
        "Zhongbo Zhu",
        "Zijia Chen"
      ],
      "abstract": "We introduce Nemotron-Nano-9B-v2, a hybrid Mamba-Transformer language model designed to increase throughput for reasoning workloads while achieving state-of-the-art accuracy compared to similarly-sized models. Nemotron-Nano-9B-v2 builds on the Nemotron-H architecture, in which the majority of the self-attention layers in the common Transformer architecture are replaced with Mamba-2 layers, to achieve improved inference speed when generating the long thinking traces needed for reasoning. We create Nemotron-Nano-9B-v2 by first pre-training a 12-billion-parameter model (Nemotron-Nano-12B-v2-Base) on 20 trillion tokens using an FP8 training recipe. After aligning Nemotron-Nano-12B-v2-Base, we employ the Minitron strategy to compress and distill the model with the goal of enabling inference on up to 128k tokens on a single NVIDIA A10G GPU (22GiB of memory, bfloat16 precision). Compared to existing similarly-sized models (e.g., Qwen3-8B), we show that Nemotron-Nano-9B-v2 achieves on-par or better accuracy on reasoning benchmarks while achieving up to 6x higher inference throughput in reasoning settings like 8k input and 16k output tokens. We are releasing Nemotron-Nano-9B-v2, Nemotron-Nano12B-v2-Base, and Nemotron-Nano-9B-v2-Base checkpoints along with the majority of our pre- and post-training datasets on Hugging Face.",
      "tldr_zh": "è¯¥ç ”ç©¶ä»‹ç»äº† Nemotron-Nano-9B-v2ï¼Œä¸€ç§åŸºäº Mamba-Transformer æ··åˆæ¶æ„çš„è¯­è¨€æ¨¡å‹ï¼Œæ—¨åœ¨æ˜¾è‘—æå‡æ¨ç†ä»»åŠ¡çš„ååé‡å¹¶ä¿æŒæœ€å…ˆè¿›çš„å‡†ç¡®ç‡ã€‚è¯¥æ¨¡å‹é‡‡ç”¨ Nemotron-H æ¶æ„ï¼Œé€šè¿‡å°†å¤§éƒ¨åˆ† self-attention å±‚æ›¿æ¢ä¸º Mamba-2 å±‚ï¼Œæœ‰æ•ˆåŠ å¿«äº†ç”Ÿæˆé•¿æ¨ç†æ€ç»´é“¾ï¼ˆlong thinking tracesï¼‰æ—¶çš„æ¨ç†é€Ÿåº¦ã€‚ç ”ç©¶å›¢é˜Ÿé¦–å…ˆåœ¨ 20 trillion tokens ä¸Šåˆ©ç”¨ FP8 è®­ç»ƒæ–¹æ¡ˆé¢„è®­ç»ƒäº† 12B çš„åŸºç¡€æ¨¡å‹ï¼Œéšååº”ç”¨ Minitron ç­–ç•¥è¿›è¡Œæ¨¡å‹å‹ç¼©ä¸è’¸é¦ï¼Œä½¿å…¶èƒ½åœ¨å•å— NVIDIA A10G GPU ä¸Šæ”¯æŒé«˜è¾¾ 128k tokens çš„ä¸Šä¸‹æ–‡æ¨ç†ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒNemotron-Nano-9B-v2 åœ¨æ¨ç†åŸºå‡†æµ‹è¯•ä¸­çš„å‡†ç¡®åº¦ä¼˜äºæˆ–æŒå¹³äº Qwen3-8B ç­‰åŒå°ºå¯¸æ¨¡å‹ï¼Œä¸”åœ¨é•¿æ–‡æœ¬è¾“å‡ºåœºæ™¯ä¸‹çš„æ¨ç†ååé‡æœ€é«˜æå‡äº† 6 å€ã€‚ç›®å‰ï¼Œç›¸å…³çš„æ¨¡å‹æƒé‡ä¸å¤§éƒ¨åˆ†é¢„è®­ç»ƒåŠåè®­ç»ƒæ•°æ®é›†å‡å·²åœ¨ Hugging Face ä¸Šå¼€æºå‘å¸ƒã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.14444v4",
      "published_date": "2025-08-20 06:00:57 UTC",
      "updated_date": "2025-09-02 16:12:36 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T13:03:00.292419+00:00"
    },
    {
      "arxiv_id": "2508.14442v1",
      "title": "Detecting Reading-Induced Confusion Using EEG and Eye Tracking",
      "title_zh": "åŸºäºè„‘ç”µä¸çœ¼åŠ¨è¿½è¸ªçš„é˜…è¯»è¯±å‘å›°æƒ‘æ£€æµ‹",
      "authors": [
        "Haojun Zhuang",
        "DÃ¼nya Baradari",
        "Nataliya Kosmyna",
        "Arnav Balyan",
        "Constanze Albrecht",
        "Stephanie Chen",
        "Pattie Maes"
      ],
      "abstract": "Humans regularly navigate an overwhelming amount of information via text media, whether reading articles, browsing social media, or interacting with chatbots. Confusion naturally arises when new information conflicts with or exceeds a reader's comprehension or prior knowledge, posing a challenge for learning. In this study, we present a multimodal investigation of reading-induced confusion using EEG and eye tracking. We collected neural and gaze data from 11 adult participants as they read short paragraphs sampled from diverse, real-world sources. By isolating the N400 event-related potential (ERP), a well-established neural marker of semantic incongruence, and integrating behavioral markers from eye tracking, we provide a detailed analysis of the neural and behavioral correlates of confusion during naturalistic reading. Using machine learning, we show that multimodal (EEG + eye tracking) models improve classification accuracy by 4-22% over unimodal baselines, reaching an average weighted participant accuracy of 77.3% and a best accuracy of 89.6%. Our results highlight the dominance of the brain's temporal regions in these neural signatures of confusion, suggesting avenues for wearable, low-electrode brain-computer interfaces (BCI) for real-time monitoring. These findings lay the foundation for developing adaptive systems that dynamically detect and respond to user confusion, with potential applications in personalized learning, human-computer interaction, and accessibility.",
      "tldr_zh": "è¯¥ç ”ç©¶åˆ©ç”¨ EEG å’Œ Eye Tracking æŠ€æœ¯å¯¹é˜…è¯»è¿‡ç¨‹ä¸­äº§ç”Ÿçš„å›°æƒ‘æ„Ÿè¿›è¡Œäº†å¤šæ¨¡æ€ç ”ç©¶ã€‚é€šè¿‡åˆ†æ11åå—è¯•è€…é˜…è¯»æ–‡æœ¬æ—¶çš„ç¥ç»å’Œæ³¨è§†æ•°æ®ï¼Œç ”ç©¶äººå‘˜æå–äº†åæ˜ è¯­ä¹‰ä¸ä¸€è‡´çš„ N400 äº‹ä»¶ç›¸å…³ç”µä½ï¼ˆERPï¼‰åŠçœ¼åŠ¨è¡Œä¸ºæŒ‡æ ‡ã€‚å®éªŒè¡¨æ˜ï¼Œå¤šæ¨¡æ€æœºå™¨å­¦ä¹ æ¨¡å‹æ¯”å•æ¨¡æ€æ¨¡å‹åœ¨åˆ†ç±»å‡†ç¡®ç‡ä¸Šæå‡äº†4%-22%ï¼Œå¹³å‡å‡†ç¡®ç‡è¾¾åˆ°77.3%ï¼Œæœ€é«˜å¯è¾¾89.6%ã€‚ç ”ç©¶å‘ç°å¤§è„‘é¢åŒºï¼ˆtemporal regionsï¼‰æ˜¯æ­¤ç±»å›°æƒ‘ä¿¡å·çš„ä¸»è¦æ¥æºï¼Œè¡¨æ˜æœªæ¥å¯é€šè¿‡ä½ç”µææ•°é‡çš„ç©¿æˆ´å¼è„‘æœºæ¥å£ï¼ˆBCIï¼‰è¿›è¡Œå®æ—¶ç›‘æµ‹ã€‚è¿™äº›å‘ç°ä¸ºå¼€å‘èƒ½åŠ¨æ€å“åº”ç”¨æˆ·å›°æƒ‘çš„è‡ªé€‚åº”ç³»ç»Ÿå¥ å®šäº†åŸºç¡€ï¼Œåœ¨ä¸ªæ€§åŒ–å­¦ä¹ ã€äººæœºäº¤äº’ï¼ˆHCIï¼‰åŠæ— éšœç¢æŠ€æœ¯é¢†åŸŸå…·æœ‰é‡è¦çš„åº”ç”¨æ½œåŠ›ã€‚",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.14442v1",
      "published_date": "2025-08-20 05:56:17 UTC",
      "updated_date": "2025-08-20 05:56:17 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T13:03:11.591317+00:00"
    },
    {
      "arxiv_id": "2508.14415v1",
      "title": "The Agent Behavior: Model, Governance and Challenges in the AI Digital Age",
      "title_zh": "æ™ºèƒ½ä½“è¡Œä¸ºï¼šAIæ•°å­—æ—¶ä»£ä¸‹çš„æ¨¡å‹ã€æ²»ç†ä¸æŒ‘æˆ˜",
      "authors": [
        "Qiang Zhang",
        "Pei Yan",
        "Yijia Xu",
        "Chuanpo Fu",
        "Yong Fang",
        "Yang Liu"
      ],
      "abstract": "Advancements in AI have led to agents in networked environments increasingly mirroring human behavior, thereby blurring the boundary between artificial and human actors in specific contexts. This shift brings about significant challenges in trust, responsibility, ethics, security and etc. The difficulty in supervising of agent behaviors may lead to issues such as data contamination and unclear accountability. To address these challenges, this paper proposes the \"Network Behavior Lifecycle\" model, which divides network behavior into 6 stages and systematically analyzes the behavioral differences between humans and agents at each stage. Based on these insights, the paper further introduces the \"Agent for Agent (A4A)\" paradigm and the \"Human-Agent Behavioral Disparity (HABD)\" model, which examine the fundamental distinctions between human and agent behaviors across 5 dimensions: decision mechanism, execution efficiency, intention-behavior consistency, behavioral inertia, and irrational patterns. The effectiveness of the model is verified through real-world cases such as red team penetration and blue team defense. Finally, the paper discusses future research directions in dynamic cognitive governance architecture, behavioral disparity quantification, and meta-governance protocol stacks, aiming to provide a theoretical foundation and technical roadmap for secure and trustworthy human-agent collaboration.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†AIæ•°å­—æ—¶ä»£èƒŒæ™¯ä¸‹æ™ºèƒ½ä½“åœ¨ç½‘ç»œç¯å¢ƒä¸­çš„è¡Œä¸ºæ¨¡å¼ï¼ŒæŒ‡å‡ºäº†å…¶ç”±äºé«˜åº¦æ¨¡ä»¿äººç±»è¡Œä¸ºè€Œæ¨¡ç³Šäº†ä¸¤è€…è¾¹ç•Œï¼Œè¿›è€Œåœ¨ä¿¡ä»»ã€è´£ä»»ã€ä¼¦ç†å’Œå®‰å…¨ç­‰æ–¹é¢å¸¦æ¥ä¸¥å³»æŒ‘æˆ˜ã€‚ä¸ºäº†åº”å¯¹æ™ºèƒ½ä½“è¡Œä¸ºç›‘ç®¡å’Œè´£ä»»è®¤å®šéš¾é¢˜ï¼Œæœ¬æ–‡æå‡ºäº†Network Behavior Lifecycleæ¨¡å‹ï¼Œå°†ç½‘ç»œè¡Œä¸ºåˆ’åˆ†ä¸ºå…­ä¸ªé˜¶æ®µå¹¶ç³»ç»Ÿåˆ†æäº†äººç±»ä¸æ™ºèƒ½ä½“åœ¨å„é˜¶æ®µçš„è¡Œä¸ºå·®å¼‚ã€‚åœ¨æ­¤åŸºç¡€ä¸Šï¼Œè®ºæ–‡è¿›ä¸€æ­¥å¼•å…¥äº†Agent for Agent (A4A)èŒƒå¼ä¸Human-Agent Behavioral Disparity (HABD)æ¨¡å‹ï¼Œä»å†³ç­–æœºåˆ¶ã€æ‰§è¡Œæ•ˆç‡ã€æ„å›¾è¡Œä¸ºä¸€è‡´æ€§ã€è¡Œä¸ºæƒ¯æ€§å’Œéç†æ€§æ¨¡å¼äº”ä¸ªç»´åº¦æ·±åº¦å‰–æäº†äººæœºè¡Œä¸ºçš„æœ¬è´¨åŒºåˆ«ã€‚é€šè¿‡çº¢é˜Ÿæ¸—é€ä¸è“é˜Ÿé˜²å¾¡ç­‰å®é™…æ¡ˆä¾‹éªŒè¯äº†ä¸Šè¿°æ¨¡å‹çš„æœ‰æ•ˆæ€§ï¼Œå¹¶è®¨è®ºäº†åŠ¨æ€è®¤çŸ¥æ²»ç†æ¶æ„ä¸è¡Œä¸ºå·®å¼‚é‡åŒ–ç­‰æœªæ¥ç ”ç©¶æ–¹å‘ã€‚è¯¥é¡¹å·¥ä½œä¸ºæ„å»ºå®‰å…¨ã€å¯ä¿¡çš„äººæœºåä½œæä¾›äº†ç†è®ºåŸºç¡€ï¼Œå¹¶ä¸ºæœªæ¥çš„å…ƒæ²»ç†åè®®æ ˆå¼€å‘è§„åˆ’äº†æŠ€æœ¯è·¯çº¿å›¾ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.14415v1",
      "published_date": "2025-08-20 04:24:55 UTC",
      "updated_date": "2025-08-20 04:24:55 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T13:03:08.849356+00:00"
    },
    {
      "arxiv_id": "2508.14410v2",
      "title": "Automated Optimization Modeling through Expert-Guided Large Language Model Reasoning",
      "title_zh": "åŸºäºä¸“å®¶å¼•å¯¼çš„å¤§è¯­è¨€æ¨¡å‹æ¨ç†çš„è‡ªåŠ¨åŒ–ä¼˜åŒ–å»ºæ¨¡",
      "authors": [
        "Beinuo Yang",
        "Qishen Zhou",
        "Junyi Li",
        "Chenxing Su",
        "Simon Hu"
      ],
      "abstract": "Optimization Modeling (OM) is essential for solving complex decision-making problems. However, the process remains time-consuming and error-prone, heavily relying on domain experts. While Large Language Models (LLMs) show promise in addressing these challenges through their natural language understanding and reasoning capabilities, current approaches face three critical limitations: high benchmark labeling error rates reaching up to 42%, narrow evaluation scope that only considers optimal values, and computational inefficiency due to heavy reliance on multi-agent systems or model fine-tuning. In this work, we first enhance existing datasets through systematic error correction and more comprehensive annotation. Additionally, we introduce LogiOR, a new optimization modeling benchmark from the logistics domain, containing more complex problems with standardized annotations. Furthermore, we present ORThought, a novel framework that leverages expert-level optimization modeling principles through chain-of-thought reasoning to automate the OM process. Through extensive empirical evaluation, we demonstrate that ORThought outperforms existing approaches, including multi-agent frameworks, with particularly significant advantages on complex optimization problems. Finally, we provide a systematic analysis of our method, identifying critical success factors and failure modes, providing valuable insights for future research on LLM-based optimization modeling.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹è‡ªåŠ¨åŒ–ä¼˜åŒ–å»ºæ¨¡ (Optimization Modeling, OM) è¿‡ç¨‹ä¸­å­˜åœ¨çš„åŸºå‡†æµ‹è¯•æ ‡ç­¾é«˜é”™è¯¯ç‡ã€è¯„ä¼°èŒƒå›´å±€é™ä»¥åŠè®¡ç®—æ•ˆç‡ä½ç­‰æ ¸å¿ƒæŒ‘æˆ˜å±•å¼€ã€‚ç ”ç©¶å›¢é˜Ÿé¦–å…ˆé€šè¿‡ç³»ç»Ÿæ€§çº é”™å’Œå¢å¼ºæ ‡æ³¨æ”¹è¿›äº†ç°æœ‰æ•°æ®é›†ï¼Œå¹¶æ¨å‡ºäº†é’ˆå¯¹ç‰©æµé¢†åŸŸã€åŒ…å«æ›´å¤æ‚é—®é¢˜çš„å…¨æ–°åŸºå‡†æµ‹è¯• LogiORã€‚åœ¨æ­¤åŸºç¡€ä¸Šï¼Œè®ºæ–‡æå‡ºäº†åä¸º ORThought çš„æ–°å‹æ¡†æ¶ï¼Œè¯¥æ¡†æ¶é€šè¿‡é“¾å¼æ€ç»´æ¨ç† (Chain-of-Thought) èå…¥ä¸“å®¶çº§ä¼˜åŒ–å»ºæ¨¡åŸåˆ™ï¼Œå®ç°äº† OM æµç¨‹çš„è‡ªåŠ¨åŒ–ã€‚å®éªŒè¯„ä¼°è¡¨æ˜ï¼ŒORThought åœ¨æ€§èƒ½ä¸Šè¶…è¶Šäº†åŒ…æ‹¬å¤šæ™ºèƒ½ä½“æ¡†æ¶åœ¨å†…çš„ç°æœ‰æ–¹æ³•ï¼Œå°¤å…¶åœ¨å¤„ç†å¤æ‚ä¼˜åŒ–é—®é¢˜æ—¶ä¼˜åŠ¿æ˜¾è‘—ã€‚æœ€åï¼Œè¯¥ç ”ç©¶é€šè¿‡å¯¹æˆåŠŸå› ç´ ä¸å¤±è´¥æ¨¡å¼çš„ç³»ç»Ÿåˆ†æï¼Œä¸ºæœªæ¥åŸºäºå¤§è¯­è¨€æ¨¡å‹ (Large Language Models, LLMs) çš„ä¼˜åŒ–å»ºæ¨¡ç ”ç©¶æä¾›äº†å®è´µè§è§£ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.14410v2",
      "published_date": "2025-08-20 04:14:54 UTC",
      "updated_date": "2025-08-22 05:28:32 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T13:03:15.028359+00:00"
    },
    {
      "arxiv_id": "2508.14408v2",
      "title": "From Implicit to Explicit: Enhancing Self-Recognition in Large Language Models",
      "title_zh": "ä»éšå¼åˆ°æ˜¾å¼ï¼šå¢å¼ºå¤§è¯­è¨€æ¨¡å‹çš„è‡ªæˆ‘è¯†åˆ«",
      "authors": [
        "Yinghan Zhou",
        "Weifeng Zhu",
        "Juan Wen",
        "Wanli Peng",
        "Zhengxian Wu",
        "Yiming Xue"
      ],
      "abstract": "Large language models (LLMs) have been shown to possess a degree of self-recognition ability, which used to identify whether a given text was generated by themselves. Prior work has demonstrated that this capability is reliably expressed under the pair presentation paradigm (PPP), where the model is presented with two texts and asked to choose which one it authored. However, performance deteriorates sharply under the individual presentation paradigm (IPP), where the model is given a single text to judge authorship. Although this phenomenon has been observed, its underlying causes have not been systematically analyzed. In this paper, we first investigate the cause of this failure and attribute it to implicit self-recognition (ISR). ISR describes the gap between internal representations and output behavior in LLMs: under the IPP scenario, the model encodes self-recognition information in its feature space, yet its ability to recognize self-generated texts remains poor. To mitigate the ISR of LLMs, we propose cognitive surgery (CoSur), a novel framework comprising four main modules: representation extraction, subspace construction, authorship discrimination, and cognitive editing. Experimental results demonstrate that our proposed method improves the self-recognition performance of three different LLMs in the IPP scenario, achieving average accuracies of 99.00%, 97.69%, and 97.13%, respectively.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨è‡ªæˆ‘è¯†åˆ«ï¼ˆSelf-recognitionï¼‰èƒ½åŠ›ä¸Šçš„å±€é™æ€§ï¼Œç‰¹åˆ«æ˜¯æ¨¡å‹åœ¨ä¸ªä½“å‘ˆç°èŒƒå¼ï¼ˆIPPï¼‰ä¸‹çš„è¡¨ç°è¿œé€Šäºæˆå¯¹å‘ˆç°èŒƒå¼ï¼ˆPPPï¼‰çš„é—®é¢˜ã€‚ä½œè€…é€šè¿‡ç³»ç»Ÿåˆ†æå°†è¿™ä¸€å¤±æ•ˆå½’å› äºéšå¼è‡ªæˆ‘è¯†åˆ«ï¼ˆISRï¼‰ï¼Œå³æ¨¡å‹çš„ç‰¹å¾ç©ºé—´è™½ç„¶ç¼–ç äº†è‡ªæˆ‘è¯†åˆ«ä¿¡æ¯ï¼Œä½†å…¶è¾“å‡ºè¡Œä¸ºå´æ— æ³•æœ‰æ•ˆä½“ç°ã€‚ä¸ºäº†å¼¥åˆè¿™ä¸€å·®è·ï¼Œç ”ç©¶è€…æå‡ºäº†åä¸ºè®¤çŸ¥æ‰‹æœ¯ï¼ˆCoSurï¼‰çš„æ–°å‹æ¡†æ¶ï¼Œè¯¥æ¡†æ¶åŒ…å«è¡¨ç¤ºæå–ã€å­ç©ºé—´æ„å»ºã€ä½œè€…èº«ä»½è¾¨åˆ«å’Œè®¤çŸ¥ç¼–è¾‘å››ä¸ªæ ¸å¿ƒæ¨¡å—ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒCoSur æ˜¾è‘—æå‡äº†ä¸‰ç§ä¸åŒ LLMs åœ¨ IPP åœºæ™¯ä¸‹çš„è‡ªæˆ‘è¯†åˆ«è¡¨ç°ï¼Œåˆ†åˆ«è¾¾åˆ°äº† 99.00%ã€97.69% å’Œ 97.13% çš„å¹³å‡å‡†ç¡®ç‡ã€‚è¯¥ç ”ç©¶é€šè¿‡å°†éšå¼ç‰¹å¾è½¬åŒ–ä¸ºæ˜¾å¼è¡Œä¸ºï¼Œä¸ºå¢å¼ºå¤§è¯­è¨€æ¨¡å‹çš„è‡ªæˆ‘è®¤çŸ¥èƒ½åŠ›æä¾›äº†æœ‰æ•ˆçš„æŠ€æœ¯è·¯å¾„ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.14408v2",
      "published_date": "2025-08-20 04:08:18 UTC",
      "updated_date": "2026-01-12 07:56:10 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T13:03:14.733225+00:00"
    },
    {
      "arxiv_id": "2508.14395v1",
      "title": "NoteIt: A System Converting Instructional Videos to Interactable Notes Through Multimodal Video Understanding",
      "title_zh": "NoteItï¼šåŸºäºå¤šæ¨¡æ€è§†é¢‘ç†è§£çš„æ•™å­¦è§†é¢‘è½¬äº¤äº’å¼ç¬”è®°ç³»ç»Ÿ",
      "authors": [
        "Running Zhao",
        "Zhihan Jiang",
        "Xinchen Zhang",
        "Chirui Chang",
        "Handi Chen",
        "Weipeng Deng",
        "Luyao Jin",
        "Xiaojuan Qi",
        "Xun Qian",
        "Edith C. H. Ngai"
      ],
      "abstract": "Users often take notes for instructional videos to access key knowledge later without revisiting long videos. Automated note generation tools enable users to obtain informative notes efficiently. However, notes generated by existing research or off-the-shelf tools fail to preserve the information conveyed in the original videos comprehensively, nor can they satisfy users' expectations for diverse presentation formats and interactive features when using notes digitally. In this work, we present NoteIt, a system, which automatically converts instructional videos to interactable notes using a novel pipeline that faithfully extracts hierarchical structure and multimodal key information from videos. With NoteIt's interface, users can interact with the system to further customize the content and presentation formats of the notes according to their preferences. We conducted both a technical evaluation and a comparison user study (N=36). The solid performance in objective metrics and the positive user feedback demonstrated the effectiveness of the pipeline and the overall usability of NoteIt. Project website: https://zhaorunning.github.io/NoteIt/",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç”¨æˆ·åœ¨è§‚çœ‹æ•™å­¦è§†é¢‘æ—¶è®°ç¬”è®°æ•ˆç‡ä½ä¸”ç°æœ‰è‡ªåŠ¨åŒ–å·¥å…·ç”Ÿæˆå†…å®¹ä¿¡æ¯ä¸å…¨ã€ç¼ºä¹äº¤äº’æ€§çš„é—®é¢˜ï¼Œæå‡ºäº†NoteItç³»ç»Ÿã€‚è¯¥ç³»ç»Ÿåˆ©ç”¨å¤šæ¨¡æ€è§†é¢‘ç†è§£(Multimodal Video Understanding)æŠ€æœ¯ï¼Œé€šè¿‡ä¸€ç§æ–°é¢–çš„å¤„ç†ç®¡çº¿ä»æ•™å­¦è§†é¢‘ä¸­å¿ å®åœ°æå–å±‚çº§ç»“æ„(Hierarchical Structure)å’Œå¤šæ¨¡æ€å…³é”®ä¿¡æ¯ã€‚NoteItä¸ä»…èƒ½å°†è§†é¢‘è½¬åŒ–ä¸ºå¯äº¤äº’çš„ç¬”è®°(Interactable Notes)ï¼Œå…¶äº¤äº’ç•Œé¢è¿˜å…è®¸ç”¨æˆ·æ ¹æ®ä¸ªäººåå¥½çµæ´»è‡ªå®šä¹‰ç¬”è®°çš„å†…å®¹å’Œå‘ˆç°æ ¼å¼ã€‚é€šè¿‡æŠ€æœ¯è¯„ä¼°å’Œä¸€é¡¹åŒ…å«36åå‚ä¸è€…çš„å¯¹æ¯”ç”¨æˆ·ç ”ç©¶(User Study)ï¼Œå®éªŒç»“æœè¯æ˜äº†è¯¥ç³»ç»Ÿåœ¨å®¢è§‚æŒ‡æ ‡ä¸Šçš„ç¨³å¥è¡¨ç°ã€‚ç”¨æˆ·åé¦ˆè¿›ä¸€æ­¥è¯å®äº†NoteItåœ¨è‡ªåŠ¨åŒ–ç”Ÿæˆé«˜è´¨é‡ã€äº¤äº’å¼ç¬”è®°æ–¹é¢çš„æœ‰æ•ˆæ€§åŠå…¶è‰¯å¥½çš„ç³»ç»Ÿå¯ç”¨æ€§ã€‚",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "Accepted to UIST 2025. Project website: https://zhaorunning.github.io/NoteIt/",
      "pdf_url": "https://arxiv.org/pdf/2508.14395v1",
      "published_date": "2025-08-20 03:45:18 UTC",
      "updated_date": "2025-08-20 03:45:18 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T13:03:27.141740+00:00"
    },
    {
      "arxiv_id": "2508.14391v1",
      "title": "DEPTH: Hallucination-Free Relation Extraction via Dependency-Aware Sentence Simplification and Two-tiered Hierarchical Refinement",
      "title_zh": "DEPTHï¼šåŸºäºä¾å­˜æ„ŸçŸ¥å¥å­ç®€åŒ–ä¸ä¸¤çº§åˆ†å±‚ç²¾ç‚¼çš„æ— å¹»è§‰å…³ç³»æŠ½å–",
      "authors": [
        "Yupei Yang",
        "Fan Feng",
        "Lin Yang",
        "Wanxi Deng",
        "Lin Qu",
        "Biwei Huang",
        "Shikui Tu",
        "Lei Xu"
      ],
      "abstract": "Relation extraction enables the construction of structured knowledge for many downstream applications. While large language models (LLMs) have shown great promise in this domain, most existing methods concentrate on relation classification, which predicts the semantic relation type between a related entity pair. However, we observe that LLMs often struggle to reliably determine whether a relation exists, especially in cases involving complex sentence structures or intricate semantics, which leads to spurious predictions. Such hallucinations can introduce noisy edges in knowledge graphs, compromising the integrity of structured knowledge and downstream reliability. To address these challenges, we propose DEPTH, a framework that integrates Dependency-aware sEntence simPlification and Two-tiered Hierarchical refinement into the relation extraction pipeline. Given a sentence and its candidate entity pairs, DEPTH operates in two stages: (1) the Grounding module extracts relations for each pair by leveraging their shortest dependency path, distilling the sentence into a minimal yet coherent relational context that reduces syntactic noise while preserving key semantics; (2) the Refinement module aggregates all local predictions and revises them based on a holistic understanding of the sentence, correcting omissions and inconsistencies. We further introduce a causality-driven reward model that mitigates reward hacking by disentangling spurious correlations, enabling robust fine-tuning via reinforcement learning with human feedback. Experiments on six benchmarks demonstrate that DEPTH reduces the average hallucination rate to 7.0\\% while achieving a 17.2\\% improvement in average F1 score over state-of-the-art baselines.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†DEPTHæ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³å¤§è¯­è¨€æ¨¡å‹(LLMs)åœ¨å…³ç³»æŠ½å–(Relation Extraction)ä»»åŠ¡ä¸­å› å¥å­ç»“æ„å¤æ‚æˆ–è¯­ä¹‰çº ç¼ è€Œäº§ç”Ÿçš„å¹»è§‰åŠè¯¯å¯¼æ€§é¢„æµ‹é—®é¢˜ã€‚è¯¥æ¡†æ¶ä¸»è¦ç”±ä¸¤ä¸ªé˜¶æ®µç»„æˆï¼šé¦–å…ˆæ˜¯Groundingæ¨¡å—ï¼Œåˆ©ç”¨ä¾èµ–æ„ŸçŸ¥å¥å­ç®€åŒ–(Dependency-aware Sentence Simplification)æŠ€æœ¯æå–æœ€çŸ­ä¾èµ–è·¯å¾„ï¼Œåœ¨ä¿ç•™æ ¸å¿ƒè¯­ä¹‰çš„åŒæ—¶è¿‡æ»¤è¯­æ³•å™ªå£°ï¼›å…¶æ¬¡æ˜¯Refinementæ¨¡å—ï¼Œé€šè¿‡ä¸¤å±‚åˆ†çº§ä¼˜åŒ–(Two-tiered Hierarchical Refinement)æ•´åˆå±€éƒ¨é¢„æµ‹ï¼Œå¹¶åŸºäºå¥å­çš„å…¨å±€ç†è§£ä¿®æ­£ä¸ä¸€è‡´é¡¹ã€‚æ­¤å¤–ï¼Œç ”ç©¶å¼•å…¥äº†å› æœé©±åŠ¨å¥–åŠ±æ¨¡å‹(Causality-driven Reward Model)ä»¥å‡å°‘è™šå‡ç›¸å…³æ€§ï¼Œé€šè¿‡äººç±»åé¦ˆå¼ºåŒ–å­¦ä¹ (RLHF)è¿›ä¸€æ­¥æå‡å¾®è°ƒçš„é²æ£’æ€§ã€‚åœ¨å…­ä¸ªåŸºå‡†æ•°æ®é›†ä¸Šçš„å®éªŒè¯æ˜ï¼ŒDEPTHå°†å¹³å‡å¹»è§‰ç‡æ˜¾è‘—é™ä½è‡³7.0%ï¼Œå¹¶åœ¨å¹³å‡F1åˆ†æ•°ä¸Šè¾ƒæœ€å…ˆè¿›åŸºå‡†æ¨¡å‹æå‡äº†17.2%ã€‚è¯¥æ–¹æ³•æœ‰æ•ˆä¿éšœäº†çŸ¥è¯†å›¾è°±(Knowledge Graphs)æ„å»ºçš„å®Œæ•´æ€§ï¼Œä¸ºä¸‹æ¸¸åº”ç”¨æä¾›äº†æ›´å¯é çš„ç»“æ„åŒ–çŸ¥è¯†æ”¯æ’‘ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.14391v1",
      "published_date": "2025-08-20 03:35:24 UTC",
      "updated_date": "2025-08-20 03:35:24 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T13:03:38.591231+00:00"
    },
    {
      "arxiv_id": "2508.14390v1",
      "title": "Credence Calibration Game? Calibrating Large Language Models through Structured Play",
      "title_zh": "Credence Calibration Gameï¼ŸåŸºäºç»“æ„åŒ–åšå¼ˆçš„å¤§è¯­è¨€æ¨¡å‹æ ¡å‡†",
      "authors": [
        "Ke Fang",
        "Tianyi Zhao",
        "Lu Cheng"
      ],
      "abstract": "As Large Language Models (LLMs) are increasingly deployed in decision-critical domains, it becomes essential to ensure that their confidence estimates faithfully correspond to their actual correctness. Existing calibration methods have primarily focused on post-hoc adjustments or auxiliary model training; however, many of these approaches necessitate additional supervision or parameter updates. In this work, we propose a novel prompt-based calibration framework inspired by the Credence Calibration Game. Our method establishes a structured interaction loop wherein LLMs receive feedback based on the alignment of their predicted confidence with correctness. Through feedback-driven prompting and natural language summaries of prior performance, our framework dynamically improves model calibration. Extensive experiments across models and game configurations demonstrate consistent improvements in evaluation metrics. Our results highlight the potential of game-based prompting as an effective strategy for LLM calibration. Code and data are available at https://anonymous.4open.science/r/LLM-Calibration/.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§è¯­è¨€æ¨¡å‹(Large Language Models, LLMs)åœ¨å…³é”®å†³ç­–é¢†åŸŸä¸­ç½®ä¿¡åº¦è¯„ä¼°ä¸å‡†ç¡®çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§å—ä¿¡ä»»æ ¡å‡†æ¸¸æˆ(Credence Calibration Game)å¯å‘çš„æ–°å‹åŸºäºæç¤º(prompt-based)çš„æ ¡å‡†æ¡†æ¶ã€‚ç°æœ‰çš„æ ¡å‡†(calibration)æ–¹æ³•é€šå¸¸ä¾èµ–äº‹åè°ƒæ•´æˆ–å‚æ•°æ›´æ–°ï¼Œè€Œè¯¥æ¡†æ¶é€šè¿‡å»ºç«‹ç»“æ„åŒ–çš„äº¤äº’å¾ªç¯ï¼Œä½¿æ¨¡å‹èƒ½å¤Ÿæ ¹æ®é¢„æµ‹ç½®ä¿¡åº¦ä¸å®é™…å‡†ç¡®æ€§çš„åŒ¹é…ç¨‹åº¦è·å–åé¦ˆã€‚åˆ©ç”¨åé¦ˆé©±åŠ¨çš„æç¤º(feedback-driven prompting)å’Œå¯¹è¿‡å¾€è¡¨ç°çš„è‡ªç„¶è¯­è¨€æ€»ç»“ï¼Œè¯¥æ–¹æ³•èƒ½å¤ŸåŠ¨æ€æå‡æ¨¡å‹çš„æ ¡å‡†æ€§èƒ½ã€‚åœ¨å¤šç§æ¨¡å‹å’Œæ¸¸æˆé…ç½®ä¸‹çš„å¹¿æ³›å®éªŒè¯æ˜ï¼Œè¯¥æ–¹æ³•åœ¨å„é¡¹è¯„ä¼°æŒ‡æ ‡ä¸Šå‡å–å¾—äº†æŒç»­çš„æ”¹è¿›ã€‚ç ”ç©¶ç»“æœè¡¨æ˜ï¼ŒåŸºäºæ¸¸æˆçš„ç»“æ„åŒ–æç¤ºç­–ç•¥æ˜¯æå‡LLMç½®ä¿¡åº¦å¯é æ€§çš„ä¸€ç§æœ‰æ•ˆä¸”æ— éœ€å‚æ•°æ›´æ–°çš„ç­–ç•¥ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.14390v1",
      "published_date": "2025-08-20 03:33:38 UTC",
      "updated_date": "2025-08-20 03:33:38 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T13:03:34.263557+00:00"
    },
    {
      "arxiv_id": "2508.14385v1",
      "title": "Online Incident Response Planning under Model Misspecification through Bayesian Learning and Belief Quantization",
      "title_zh": "åŸºäºè´å¶æ–¯å­¦ä¹ ä¸ä¿¡å¿µé‡åŒ–çš„æ¨¡å‹è¯¯è®¾ä¸‹åœ¨çº¿åº”æ€¥å“åº”è§„åˆ’",
      "authors": [
        "Kim Hammar",
        "Tao Li"
      ],
      "abstract": "Effective responses to cyberattacks require fast decisions, even when information about the attack is incomplete or inaccurate. However, most decision-support frameworks for incident response rely on a detailed system model that describes the incident, which restricts their practical utility. In this paper, we address this limitation and present an online method for incident response planning under model misspecification, which we call MOBAL: Misspecified Online Bayesian Learning. MOBAL iteratively refines a conjecture about the model through Bayesian learning as new information becomes available, which facilitates model adaptation as the incident unfolds. To determine effective responses online, we quantize the conjectured model into a finite Markov model, which enables efficient response planning through dynamic programming. We prove that Bayesian learning is asymptotically consistent with respect to the information feedback. Additionally, we establish bounds on misspecification and quantization errors. Experiments on the CAGE-2 benchmark show that MOBAL outperforms the state of the art in terms of adaptability and robustness to model misspecification.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç½‘ç»œæ”»å‡»å“åº”ä¸­ç°æœ‰æ¡†æ¶è¿‡åº¦ä¾èµ–è¯¦ç»†ç³»ç»Ÿæ¨¡å‹çš„å±€é™æ€§ï¼Œæå‡ºäº† MOBAL (Misspecified Online Bayesian Learning) æ–¹æ³•ï¼Œæ—¨åœ¨è§£å†³æ¨¡å‹å¤±é… (Model Misspecification) ä¸‹çš„åœ¨çº¿äº‹ä»¶å“åº”è§„åˆ’é—®é¢˜ã€‚MOBAL é€šè¿‡ Bayesian learning éšæ–°ä¿¡æ¯çš„è·å–ä¸æ–­è¿­ä»£å¹¶å®Œå–„æ¨¡å‹æ¨æµ‹ï¼Œä½¿æ¨¡å‹èƒ½å¤Ÿéšç€äº‹ä»¶çš„å±•å¼€è¿›è¡Œè‡ªé€‚åº”è°ƒæ•´ã€‚ä¸ºäº†å®ç°åœ¨çº¿çš„é«˜æ•ˆè§„åˆ’ï¼Œè¯¥æ¡†æ¶å°†æ¨æµ‹æ¨¡å‹é‡åŒ–ä¸ºæœ‰é™çš„ Markov modelï¼Œå¹¶åˆ©ç”¨ dynamic programming ç¡®å®šæœ‰æ•ˆå“åº”ã€‚ç ”ç©¶åœ¨ç†è®ºä¸Šè¯æ˜äº† Bayesian learning å¯¹ä¿¡æ¯åé¦ˆçš„æ¸è¿‘ä¸€è‡´æ€§ï¼Œå¹¶ç»™å‡ºäº†é’ˆå¯¹å¤±é…å’Œé‡åŒ–è¯¯å·®çš„ç•Œé™ (bounds)ã€‚åœ¨ CAGE-2 åŸºå‡†æµ‹è¯•ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒMOBAL åœ¨åº”å¯¹æ¨¡å‹å¤±é…æ—¶çš„é€‚åº”æ€§å’Œé²æ£’æ€§ (robustness) æ˜¾è‘—ä¼˜äºç°æœ‰æœ€å…ˆè¿›çš„æŠ€æœ¯ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR",
        "eess.SY"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted to ACM CCS AISec2025",
      "pdf_url": "https://arxiv.org/pdf/2508.14385v1",
      "published_date": "2025-08-20 03:25:59 UTC",
      "updated_date": "2025-08-20 03:25:59 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T13:03:39.088694+00:00"
    },
    {
      "arxiv_id": "2508.14377v2",
      "title": "ZPD-SCA: Unveiling the Blind Spots of LLMs in Assessing Students' Cognitive Abilities",
      "title_zh": "ZPD-SCAï¼šæ­ç¤ºå¤§è¯­è¨€æ¨¡å‹åœ¨è¯„ä¼°å­¦ç”Ÿè®¤çŸ¥èƒ½åŠ›ä¸­çš„ç›²ç‚¹",
      "authors": [
        "Wenhan Dong",
        "Zhen Sun",
        "Yuemeng Zhao",
        "Zifan Peng",
        "Jun Wu",
        "Jingyi Zheng",
        "Yule Liu",
        "Xinlei He",
        "Yu Wang",
        "Ruiming Wang",
        "Xinyi Huang",
        "Lei Mo"
      ],
      "abstract": "Large language models (LLMs) have demonstrated potential in educational applications, yet their capacity to accurately assess the cognitive alignment of reading materials with students' developmental stages remains insufficiently explored. This gap is particularly critical given the foundational educational principle of the Zone of Proximal Development (ZPD), which emphasizes the need to match learning resources with Students' Cognitive Abilities (SCA). Despite the importance of this alignment, there is a notable absence of comprehensive studies investigating LLMs' ability to evaluate reading comprehension difficulty across different student age groups, especially in the context of Chinese language education. To fill this gap, we introduce ZPD-SCA, a novel benchmark specifically designed to assess stage-level Chinese reading comprehension difficulty. The benchmark is annotated by 60 Special Grade teachers, a group that represents the top 0.15% of all in-service teachers nationwide. Experimental results reveal that LLMs perform poorly in zero-shot learning scenarios, with Qwen-max and GLM even falling below the probability of random guessing. When provided with in-context examples, LLMs performance improves substantially, with some models achieving nearly double the accuracy of their zero-shot baselines. These results reveal that LLMs possess emerging abilities to assess reading difficulty, while also exposing limitations in their current training for educationally aligned judgment. Notably, even the best-performing models display systematic directional biases, suggesting difficulties in accurately aligning material difficulty with SCA. Furthermore, significant variations in model performance across different genres underscore the complexity of task. We envision that ZPD-SCA can provide a foundation for evaluating and improving LLMs in cognitively aligned educational applications.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å¤§å‹è¯­è¨€æ¨¡å‹(LLMs)åœ¨è¯„ä¼°é˜…è¯»ææ–™ä¸å­¦ç”Ÿè®¤çŸ¥èƒ½åŠ›(SCA)å¯¹é½ç¨‹åº¦æ–¹é¢çš„èƒ½åŠ›ï¼Œç‰¹åˆ«æ˜¯åœ¨ä¸­æ–‡æ•™è‚²è¯­å¢ƒä¸‹ã€‚ç ”ç©¶è€…å¼•å…¥äº†åä¸ºZPD-SCAçš„æ–°å‹åŸºå‡†ï¼Œè¯¥åŸºå‡†åŸºäºæœ€è¿‘å‘å±•åŒº(ZPD)ç†è®ºï¼Œå¹¶ç”±60ä½å…¨å›½é¡¶å°–çš„ç‰¹çº§æ•™å¸ˆè¿›è¡Œæ ‡æ³¨ã€‚å®éªŒå‘ç°ï¼ŒLLMsåœ¨é›¶æ ·æœ¬å­¦ä¹ (zero-shot learning)åœºæ™¯ä¸‹è¡¨ç°æ¬ ä½³ï¼ŒQwen-maxå’ŒGLMç­‰æ¨¡å‹çš„å‡†ç¡®ç‡ç”šè‡³ä½äºéšæœºçŒœæµ‹ã€‚é€šè¿‡å¼•å…¥ä¸Šä¸‹æ–‡ç¤ºä¾‹(in-context learning)ï¼Œæ¨¡å‹æ€§èƒ½å¾—åˆ°æ˜¾è‘—æå‡ï¼Œéƒ¨åˆ†æ¨¡å‹çš„è¡¨ç°ç›¸æ¯”åŸºå‡†çº¿æé«˜äº†ä¸€å€ã€‚å°½ç®¡LLMså±•ç°å‡ºä¸€å®šçš„æ½œåŠ›ï¼Œä½†ç ”ç©¶ä¹Ÿæ­ç¤ºäº†å®ƒä»¬åœ¨æ•™è‚²åˆ¤æ–­ä¸­å­˜åœ¨ç³»ç»Ÿæ€§æ–¹å‘åå·®å’Œè·¨ä½“è£çš„è¡¨ç°å·®å¼‚ã€‚ZPD-SCAä¸ºè¯„ä¼°å’Œæ”¹è¿›LLMsåœ¨è®¤çŸ¥å¯¹é½æ•™è‚²åº”ç”¨ä¸­çš„è¡¨ç°æä¾›äº†å…³é”®ä¾æ®ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.14377v2",
      "published_date": "2025-08-20 03:08:47 UTC",
      "updated_date": "2025-08-23 05:27:00 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T13:03:47.325027+00:00"
    },
    {
      "arxiv_id": "2508.14375v1",
      "title": "Computing-In-Memory Dataflow for Minimal Buffer Traffic",
      "title_zh": "é¢å‘æœ€å°åŒ–ç¼“å­˜æµé‡çš„å­˜ç®—ä¸€ä½“æ•°æ®æµ",
      "authors": [
        "Choongseok Song",
        "Doo Seok Jeong"
      ],
      "abstract": "Computing-In-Memory (CIM) offers a potential solution to the memory wall issue and can achieve high energy efficiency by minimizing data movement, making it a promising architecture for edge AI devices. Lightweight models like MobileNet and EfficientNet, which utilize depthwise convolution for feature extraction, have been developed for these devices. However, CIM macros often face challenges in accelerating depthwise convolution, including underutilization of CIM memory and heavy buffer traffic. The latter, in particular, has been overlooked despite its significant impact on latency and energy consumption. To address this, we introduce a novel CIM dataflow that significantly reduces buffer traffic by maximizing data reuse and improving memory utilization during depthwise convolution. The proposed dataflow is grounded in solid theoretical principles, fully demonstrated in this paper. When applied to MobileNet and EfficientNet models, our dataflow reduces buffer traffic by 77.4-87.0%, leading to a total reduction in data traffic energy and latency by 10.1-17.9% and 15.6-27.8%, respectively, compared to the baseline (conventional weight-stationary dataflow).",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å­˜å†…è®¡ç®— (Computing-In-Memory, CIM) åœ¨è¾¹ç¼˜ AI è®¾å¤‡ä¸­åº”å¯¹å­˜å‚¨å¢™å’Œèƒ½æ•ˆæŒ‘æˆ˜çš„æ½œåŠ›ï¼Œå¹¶é’ˆå¯¹ MobileNet å’Œ EfficientNet ç­‰æ¨¡å‹ä¸­æ·±åº¦å·ç§¯ (depthwise convolution) å¯¼è‡´çš„å†…å­˜åˆ©ç”¨ç‡ä½åŠç¼“å†²åŒºæµé‡ (buffer traffic) è¿‡å¤§é—®é¢˜æå‡ºäº†ä¼˜åŒ–æ–¹æ¡ˆã€‚ä½œè€…å¼•å…¥äº†ä¸€ç§æ–°å‹ CIM æ•°æ®æµ (dataflow)ï¼Œé€šè¿‡æœ€å¤§åŒ–æ•°æ®å¤ç”¨å’Œæ”¹è¿›æ·±åº¦å·ç§¯æ—¶çš„å†…å­˜åˆ©ç”¨ç‡ï¼Œæ˜¾è‘—å‡å°‘äº†ä¸å¿…è¦çš„æ•°æ®ç§»åŠ¨ã€‚è¯¥æ•°æ®æµå»ºç«‹åœ¨ä¸¥è°¨çš„ç†è®ºåŸºç¡€ä¹‹ä¸Šï¼Œæ—¨åœ¨ä»åº•å±‚æ¶æ„å±‚é¢è§£å†³é•¿æœŸè¢«å¿½è§†çš„ç¼“å†²åŒºæµé‡å¯¹å»¶è¿Ÿå’Œèƒ½è€—çš„å½±å“ã€‚å®éªŒè¯„ä¼°è¡¨æ˜ï¼Œä¸ä¼ ç»Ÿçš„æƒé‡å›ºå®š (weight-stationary) æ•°æ®æµåŸºå‡†ç›¸æ¯”ï¼Œè¯¥æ–¹æ¡ˆåœ¨ç›¸å…³æ¨¡å‹ä¸Šå°†ç¼“å†²åŒºæµé‡é™ä½äº† 77.4-87.0%ã€‚è¿™æœ€ç»ˆä½¿å¾—æ•°æ®ä¼ è¾“çš„æ€»èƒ½è€—é™ä½äº† 10.1-17.9%ï¼Œå¹¶å°†å¤„ç†å»¶è¿Ÿç¼©å‡äº† 15.6-27.8%ï¼Œä¸ºæå‡è¾¹ç¼˜ AI è®¾å¤‡çš„è¿è¡Œæ•ˆç‡æä¾›äº†é‡è¦æ”¯æ’‘ã€‚",
      "categories": [
        "cs.AR",
        "cs.AI"
      ],
      "primary_category": "cs.AR",
      "comment": "IEEE International Conference on Computer Design",
      "pdf_url": "https://arxiv.org/pdf/2508.14375v1",
      "published_date": "2025-08-20 03:05:40 UTC",
      "updated_date": "2025-08-20 03:05:40 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T13:03:46.433679+00:00"
    },
    {
      "arxiv_id": "2508.14358v1",
      "title": "Learning Point Cloud Representations with Pose Continuity for Depth-Based Category-Level 6D Object Pose Estimation",
      "title_zh": "é¢å‘åŸºäºæ·±åº¦çš„ç±»åˆ«çº§ 6D ç‰©ä½“ä½å§¿ä¼°è®¡çš„ä½å§¿è¿ç»­æ€§ç‚¹äº‘è¡¨ç¤ºå­¦ä¹ ",
      "authors": [
        "Zhujun Li",
        "Shuo Zhang",
        "Ioannis Stamos"
      ],
      "abstract": "Category-level object pose estimation aims to predict the 6D pose and 3D size of objects within given categories. Existing approaches for this task rely solely on 6D poses as supervisory signals without explicitly capturing the intrinsic continuity of poses, leading to inconsistencies in predictions and reduced generalization to unseen poses. To address this limitation, we propose HRC-Pose, a novel depth-only framework for category-level object pose estimation, which leverages contrastive learning to learn point cloud representations that preserve the continuity of 6D poses. HRC-Pose decouples object pose into rotation and translation components, which are separately encoded and leveraged throughout the network. Specifically, we introduce a contrastive learning strategy for multi-task, multi-category scenarios based on our 6D pose-aware hierarchical ranking scheme, which contrasts point clouds from multiple categories by considering rotational and translational differences as well as categorical information. We further design pose estimation modules that separately process the learned rotation-aware and translation-aware embeddings. Our experiments demonstrate that HRC-Pose successfully learns continuous feature spaces. Results on REAL275 and CAMERA25 benchmarks show that our method consistently outperforms existing depth-only state-of-the-art methods and runs in real-time, demonstrating its effectiveness and potential for real-world applications. Our code is at https://github.com/zhujunli1993/HRC-Pose.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç±»åˆ«çº§ç‰©ä½“å§¿æ€ä¼°è®¡ï¼ˆcategory-level object pose estimationï¼‰ä¸­ç”±äºç¼ºä¹æ•æ‰å§¿æ€å†…åœ¨è¿ç»­æ€§è€Œå¯¼è‡´çš„é¢„æµ‹ä¸ä¸€è‡´å’Œæ³›åŒ–èƒ½åŠ›å¼±çš„é—®é¢˜ï¼Œæå‡ºäº†å…¨æ–°çš„ HRC-Pose æ·±åº¦å­¦ä¹ æ¡†æ¶ã€‚HRC-Pose é€šè¿‡å¯¹æ¯”å­¦ä¹ ï¼ˆcontrastive learningï¼‰æŠ€æœ¯ï¼Œå­¦ä¹ èƒ½å¤Ÿä¿æŒ 6D å§¿æ€è¿ç»­æ€§çš„ç‚¹äº‘è¡¨ç¤ºï¼Œå¹¶å°†ç‰©ä½“å§¿æ€è§£è€¦ä¸º rotation å’Œ translation åˆ†é‡è¿›è¡Œç‹¬ç«‹ç¼–ç ã€‚ç ”ç©¶å¼•å…¥äº†ä¸€ç§ 6D pose-aware hierarchical ranking schemeï¼Œé€šè¿‡ç»¼åˆè€ƒé‡æ—‹è½¬å·®å¼‚ã€å¹³ç§»å·®å¼‚åŠç±»åˆ«ä¿¡æ¯ï¼Œåœ¨å¤šä»»åŠ¡ã€å¤šç±»åˆ«åœºæ™¯ä¸‹å®ç°å¯¹ç‚¹äº‘ç‰¹å¾çš„æœ‰æ•ˆå¯¹æ¯”ã€‚æ­¤å¤–ï¼Œè¯¥æ¡†æ¶è®¾è®¡äº†ä¸“é—¨çš„å§¿æ€ä¼°è®¡æ¨¡å—æ¥å¤„ç†æ—‹è½¬æ„ŸçŸ¥å’Œä½ç§»æ„ŸçŸ¥çš„åµŒå…¥å‘é‡ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒHRC-Pose åœ¨ REAL275 å’Œ CAMERA25 åŸºå‡†æµ‹è¯•ä¸Šå‡ä¼˜äºç°æœ‰çš„ depth-only SOTA æ–¹æ³•ã€‚è¯¥æ–¹æ³•ä¸ä»…è¯æ˜äº†å­¦ä¹ è¿ç»­ç‰¹å¾ç©ºé—´çš„æœ‰æ•ˆæ€§ï¼Œä¸”å…·å¤‡å®æ—¶è¿è¡Œèƒ½åŠ›ï¼Œå±•ç°äº†åœ¨å®é™…åº”ç”¨åœºæ™¯ä¸­çš„å·¨å¤§æ½œåŠ›ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by ICCV 2025 Workshop on Recovering 6D Object Pose (R6D)",
      "pdf_url": "https://arxiv.org/pdf/2508.14358v1",
      "published_date": "2025-08-20 02:09:02 UTC",
      "updated_date": "2025-08-20 02:09:02 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T13:03:49.330085+00:00"
    },
    {
      "arxiv_id": "2508.14357v1",
      "title": "Organ-Agents: Virtual Human Physiology Simulator via LLMs",
      "title_zh": "Organ-Agentsï¼šåŸºäºå¤§è¯­è¨€æ¨¡å‹çš„è™šæ‹Ÿäººä½“ç”Ÿç†æ¨¡æ‹Ÿå™¨",
      "authors": [
        "Rihao Chang",
        "He Jiao",
        "Weizhi Nie",
        "Honglin Guo",
        "Keliang Xie",
        "Zhenhua Wu",
        "Lina Zhao",
        "Yunpeng Bai",
        "Yongtao Ma",
        "Lanjun Wang",
        "Yuting Su",
        "Xi Gao",
        "Weijie Wang",
        "Nicu Sebe",
        "Bruno Lepri",
        "Bingwei Sun"
      ],
      "abstract": "Recent advances in large language models (LLMs) have enabled new possibilities in simulating complex physiological systems. We introduce Organ-Agents, a multi-agent framework that simulates human physiology via LLM-driven agents. Each Simulator models a specific system (e.g., cardiovascular, renal, immune). Training consists of supervised fine-tuning on system-specific time-series data, followed by reinforcement-guided coordination using dynamic reference selection and error correction. We curated data from 7,134 sepsis patients and 7,895 controls, generating high-resolution trajectories across 9 systems and 125 variables. Organ-Agents achieved high simulation accuracy on 4,509 held-out patients, with per-system MSEs <0.16 and robustness across SOFA-based severity strata. External validation on 22,689 ICU patients from two hospitals showed moderate degradation under distribution shifts with stable simulation. Organ-Agents faithfully reproduces critical multi-system events (e.g., hypotension, hyperlactatemia, hypoxemia) with coherent timing and phase progression. Evaluation by 15 critical care physicians confirmed realism and physiological plausibility (mean Likert ratings 3.9 and 3.7). Organ-Agents also enables counterfactual simulations under alternative sepsis treatment strategies, generating trajectories and APACHE II scores aligned with matched real-world patients. In downstream early warning tasks, classifiers trained on synthetic data showed minimal AUROC drops (<0.04), indicating preserved decision-relevant patterns. These results position Organ-Agents as a credible, interpretable, and generalizable digital twin for precision diagnosis, treatment simulation, and hypothesis testing in critical care.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¨å‡ºäº†Organ-Agentsï¼Œè¿™æ˜¯ä¸€ç§ç”±å¤§è¯­è¨€æ¨¡å‹(LLMs)é©±åŠ¨çš„å¤šæ™ºèƒ½ä½“æ¡†æ¶ï¼Œæ—¨åœ¨ç²¾ç¡®æ¨¡æ‹Ÿå¤æ‚çš„äººä½“ç”Ÿç†ç³»ç»Ÿã€‚è¯¥æ¡†æ¶ä¸ºæ¯ä¸ªç‰¹å®šçš„ç”Ÿç†ç³»ç»Ÿï¼ˆå¦‚å¿ƒè¡€ç®¡ã€è‚¾è„ã€å…ç–«ç­‰ï¼‰é…ç½®äº†ä¸“é—¨çš„æ™ºèƒ½ä½“(Simulator)ï¼Œé€šè¿‡åœ¨ç³»ç»Ÿç‰¹å®šæ—¶é—´åºåˆ—æ•°æ®ä¸Šè¿›è¡Œç›‘ç£å¾®è°ƒ(SFT)ä»¥åŠåˆ©ç”¨å¼ºåŒ–å­¦ä¹ æŒ‡å¯¼çš„åè°ƒæœºåˆ¶(reinforcement-guided coordination)æ¥å®ç°ç²¾å‡†å»ºæ¨¡ã€‚ç ”ç©¶åˆ©ç”¨æ¥è‡ª7,134åè„“æ¯’ç—‡(sepsis)æ‚£è€…çš„å¤§è§„æ¨¡æ•°æ®è¿›è¡Œè®­ç»ƒï¼Œå¹¶åœ¨å¤–éƒ¨è¶…è¿‡2ä¸‡åICUæ‚£è€…çš„æ•°æ®ä¸ŠéªŒè¯äº†æ¨¡å‹çš„é²æ£’æ€§ä¸æ³›åŒ–èƒ½åŠ›ã€‚å®éªŒè¡¨æ˜ï¼ŒOrgan-Agentsèƒ½é«˜ç²¾åº¦è¿˜åŸä½è¡€å‹ã€é«˜ä¹³é…¸è¡€ç—‡ç­‰å…³é”®å¤šç³»ç»Ÿä¸´åºŠäº‹ä»¶ï¼Œå…¶ç”Ÿç†åˆç†æ€§è·å¾—äº†é‡ç—‡åŒ»å­¦ä¸“å®¶çš„è®¤å¯ã€‚æ­¤å¤–ï¼Œè¯¥ç³»ç»Ÿæ”¯æŒé’ˆå¯¹ä¸åŒæ²»ç–—ç­–ç•¥çš„åå‘äº‹å®æ¨¡æ‹Ÿ(counterfactual simulations)ï¼Œä¸”ç”Ÿæˆçš„åˆæˆæ•°æ®åœ¨ä¸‹æ¸¸é¢„è­¦ä»»åŠ¡ä¸­è¡¨ç°å‡ºæé«˜çš„å†³ç­–ä¿ç•™ä»·å€¼ã€‚è¿™ä¸€æˆæœä½¿Organ-Agentsæˆä¸ºé‡ç—‡ç›‘æŠ¤é¢†åŸŸä¸­å¯è§£é‡Šã€å¯ä¿¡èµ–çš„æ•°å­—å­ªç”Ÿ(digital twin)å·¥å…·ï¼Œä¸ºç²¾å‡†è¯Šæ–­å’Œæ²»ç–—æ–¹æ¡ˆæµ‹è¯•æä¾›äº†é‡è¦æ”¯æŒã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.14357v1",
      "published_date": "2025-08-20 01:58:45 UTC",
      "updated_date": "2025-08-20 01:58:45 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T13:04:00.160301+00:00"
    },
    {
      "arxiv_id": "2508.14343v1",
      "title": "Inter-Class Relational Loss for Small Object Detection: A Case Study on License Plates",
      "title_zh": "é¢å‘å°ç›®æ ‡æ£€æµ‹çš„ç±»é—´å…³ç³»æŸå¤±ï¼šä»¥è½¦ç‰Œä¸ºä¾‹",
      "authors": [
        "Dian Ning",
        "Dong Seog Han"
      ],
      "abstract": "In one-stage multi-object detection tasks, various intersection over union (IoU)-based solutions aim at smooth and stable convergence near the targets during training. However, IoU-based losses fail to correctly update the gradient of small objects due to an extremely flat gradient. During the update of multiple objects, the learning of small objects' gradients suffers more because of insufficient gradient updates. Therefore, we propose an inter-class relational loss to efficiently update the gradient of small objects while not sacrificing the learning efficiency of other objects based on the simple fact that an object has a spatial relationship to another object (e.g., a car plate is attached to a car in a similar position). When the predicted car plate's bounding box is not within its car, a loss punishment is added to guide the learning, which is inversely proportional to the overlapped area of the car's and predicted car plate's bounding box. By leveraging the spatial relationship at the inter-class level, the loss guides small object predictions using larger objects and enhances latent information in deeper feature maps. In this paper, we present twofold contributions using license plate detection as a case study: (1) a new small vehicle multi-license plate dataset (SVMLP), featuring diverse real-world scenarios with high-quality annotations; and (2) a novel inter-class relational loss function designed to promote effective detection performance. We highlight the proposed ICR loss penalty can be easily added to existing IoU-based losses and enhance the performance. These contributions improve the standard mean Average Precision (mAP) metric, achieving gains of 10.3% and 1.6% in mAP$^{\\text{test}}_{50}$ for YOLOv12-T and UAV-DETR, respectively, without any additional hyperparameter tuning. Code and dataset will be available soon.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å•é˜¶æ®µå¤šç›®æ ‡æ£€æµ‹ä¸­ IoU-based æŸå¤±å‡½æ•°åœ¨å¤„ç†å°ç›®æ ‡æ—¶æ¢¯åº¦æ›´æ–°ä¸è¶³çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§ç±»é—´å…³ç³»æŸå¤± (Inter-Class Relational Loss, ICR Loss)ã€‚è¯¥æ–¹æ³•åˆ©ç”¨ç‰©ä½“é—´çš„ç©ºé—´ä½ç½®å…³ç³»ï¼Œä¾‹å¦‚è½¦ç‰Œé€šå¸¸é™„ç€åœ¨è½¦è¾†çš„å›ºå®šä½ç½®ï¼Œå½“é¢„æµ‹çš„å°ç›®æ ‡è¾¹ç•Œæ¡†ä¸åœ¨å…¶å…³è”çš„å¤§ç›®æ ‡å†…éƒ¨æ—¶ï¼Œå¼•å…¥ä¸é‡å é¢ç§¯æˆåæ¯”çš„æƒ©ç½šé¡¹ã€‚é€šè¿‡è¿™ç§è·¨ç±»åˆ«çš„ç©ºé—´çº¦æŸï¼ŒICR Loss èƒ½å¤Ÿåˆ©ç”¨å¤§ç›®æ ‡å¼•å¯¼å°ç›®æ ‡çš„é¢„æµ‹ï¼Œå¹¶å¢å¼ºæ·±å±‚ç‰¹å¾å›¾ä¸­çš„æ½œåœ¨ä¿¡æ¯ã€‚æ­¤å¤–ï¼Œç ”ç©¶è¿˜è´¡çŒ®äº†ä¸€ä¸ªåä¸º SVMLP çš„å°è½¦å‹å¤šè½¦ç‰Œæ•°æ®é›†ï¼Œæ¶µç›–äº†å…·æœ‰é«˜è´¨é‡æ ‡æ³¨çš„å¤šæ ·åŒ–çœŸå®ä¸–ç•Œåœºæ™¯ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æŸå¤±å‡½æ•°å¯æ— ç¼é›†æˆåˆ°ç°æœ‰æ£€æµ‹æ¡†æ¶ä¸­ï¼Œåœ¨æ— éœ€é¢å¤–è¶…å‚æ•°è°ƒæ•´çš„æƒ…å†µä¸‹ï¼Œä½¿ YOLOv12-T å’Œ UAV-DETR åœ¨ mAP$^{\\text{test}}_{50}$ æŒ‡æ ‡ä¸Šåˆ†åˆ«æå‡äº† 10.3% å’Œ 1.6%ã€‚è¯¥ç ”ç©¶ä¸ºæå‡å¤æ‚åœºæ™¯ä¸‹çš„å°ç›®æ ‡æ£€æµ‹ç²¾åº¦æä¾›äº†ä¸€ç§é«˜æ•ˆä¸”æ˜“äºå®ç°çš„ä¼˜åŒ–è·¯å¾„ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.14343v1",
      "published_date": "2025-08-20 01:37:17 UTC",
      "updated_date": "2025-08-20 01:37:17 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T13:03:57.728902+00:00"
    },
    {
      "arxiv_id": "2508.14342v2",
      "title": "Generative AI Against Poaching: Latent Composite Flow Matching for Wildlife Conservation",
      "title_zh": "ç”Ÿæˆå¼äººå·¥æ™ºèƒ½åå·çŒï¼šé¢å‘é‡ç”ŸåŠ¨ç‰©ä¿æŠ¤çš„æ½œç©ºé—´ç»„åˆæµåŒ¹é…",
      "authors": [
        "Lingkai Kong",
        "Haichuan Wang",
        "Charles A. Emogor",
        "Vincent BÃ¶rsch-Supan",
        "Lily Xu",
        "Milind Tambe"
      ],
      "abstract": "Poaching poses significant threats to wildlife and biodiversity. A valuable step in reducing poaching is to forecast poacher behavior, which can inform patrol planning and other conservation interventions. Existing poaching prediction methods based on linear models or decision trees lack the expressivity to capture complex, nonlinear spatiotemporal patterns. Recent advances in generative modeling, particularly flow matching, offer a more flexible alternative. However, training such models on real-world poaching data faces two central obstacles: imperfect detection of poaching events and limited data. To address imperfect detection, we integrate flow matching with an occupancy-based detection model and train the flow in latent space to infer the underlying occupancy state. To mitigate data scarcity, we adopt a composite flow initialized from a linear-model prediction rather than random noise which is the standard in diffusion models, injecting prior knowledge and improving generalization. Evaluations on datasets from two national parks in Uganda show consistent gains in predictive accuracy.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹é‡ç”ŸåŠ¨ç‰©ä¿æŠ¤ä¸­çš„å·çŒè¡Œä¸ºé¢„æµ‹é—®é¢˜ï¼Œæå‡ºäº† Latent Composite Flow Matching æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³ä¼ ç»Ÿçº¿æ€§æ¨¡å‹å’Œå†³ç­–æ ‘éš¾ä»¥æ•æ‰å¤æ‚éçº¿æ€§æ—¶ç©ºæ¨¡å¼çš„å±€é™ã€‚é’ˆå¯¹å·çŒäº‹ä»¶æ£€æµ‹ä¸å®Œå…¨ (Imperfect Detection) çš„æŒ‘æˆ˜ï¼Œè¯¥æ–¹æ³•å°† Flow Matching ä¸åŸºäºå æœ‰ç‡ (Occupancy-based) çš„æ£€æµ‹æ¨¡å‹ç›¸ç»“åˆï¼Œå¹¶åœ¨æ½œç©ºé—´ (Latent Space) ä¸­è¿›è¡Œè®­ç»ƒä»¥æ¨æ–­å®é™…çš„å æœ‰çŠ¶æ€ã€‚ä¸ºäº†åº”å¯¹æ•°æ®ç¨€ç¼º (Data Scarcity) é—®é¢˜ï¼Œç ”ç©¶è€…é‡‡ç”¨å¤åˆæµ (Composite Flow) è®¾è®¡ï¼Œé€šè¿‡çº¿æ€§æ¨¡å‹é¢„æµ‹å€¼è€Œééšæœºå™ªå£°è¿›è¡Œåˆå§‹åŒ–ï¼Œä»è€Œæœ‰æ•ˆæ³¨å…¥å…ˆéªŒçŸ¥è¯†å¹¶æå‡æ³›åŒ–èƒ½åŠ›ã€‚åœ¨ä¹Œå¹²è¾¾ä¸¤ä¸ªå›½å®¶å…¬å›­æ•°æ®é›†ä¸Šçš„è¯„ä¼°ç»“æœæ˜¾ç¤ºï¼Œè¯¥æ–¹æ³•åœ¨é¢„æµ‹å·çŒè€…è¡Œä¸ºå‡†ç¡®ç‡æ–¹é¢å–å¾—äº†æ˜¾è‘—ä¸”ä¸€è‡´çš„æå‡ï¼Œä¸ºå·¡é€»è§„åˆ’ç­‰ä¿æŠ¤æªæ–½æä¾›äº†æ›´ç²¾ç¡®çš„å†³ç­–æ”¯æŒã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.LG",
      "comment": "Fix the feature color for the detection head in Figure 2",
      "pdf_url": "https://arxiv.org/pdf/2508.14342v2",
      "published_date": "2025-08-20 01:35:51 UTC",
      "updated_date": "2025-08-27 18:16:23 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T13:03:58.329972+00:00"
    },
    {
      "arxiv_id": "2508.14340v1",
      "title": "A Comparative Evaluation of Teacher-Guided Reinforcement Learning Techniques for Autonomous Cyber Operations",
      "title_zh": "è‡ªä¸»ç½‘ç»œè¡ŒåŠ¨ä¸­æ•™å¸ˆå¼•å¯¼å¼ºåŒ–å­¦ä¹ æŠ€æœ¯çš„å¯¹æ¯”è¯„ä¼°",
      "authors": [
        "Konur Tholl",
        "Mariam El Mezouar",
        "Ranwa Al Mallah"
      ],
      "abstract": "Autonomous Cyber Operations (ACO) rely on Reinforcement Learning (RL) to train agents to make effective decisions in the cybersecurity domain. However, existing ACO applications require agents to learn from scratch, leading to slow convergence and poor early-stage performance. While teacher-guided techniques have demonstrated promise in other domains, they have not yet been applied to ACO. In this study, we implement four distinct teacher-guided techniques in the simulated CybORG environment and conduct a comparative evaluation. Our results demonstrate that teacher integration can significantly improve training efficiency in terms of early policy performance and convergence speed, highlighting its potential benefits for autonomous cybersecurity.",
      "tldr_zh": "è¿™é¡¹ç ”ç©¶é’ˆå¯¹è‡ªä¸»ç½‘ç»œè¡ŒåŠ¨(Autonomous Cyber Operations)åœ¨å¼ºåŒ–å­¦ä¹ (Reinforcement Learning)è®­ç»ƒä¸­ï¼Œå› ä»é›¶å­¦ä¹ å¯¼è‡´çš„æ”¶æ•›æ…¢åŠæ—©æœŸè¡¨ç°å·®ç­‰æŒ‘æˆ˜ï¼Œå¯¹æ•™å¸ˆå¼•å¯¼(teacher-guided)æŠ€æœ¯è¿›è¡Œäº†æ¯”è¾ƒè¯„ä¼°ã€‚ç ”ç©¶è€…åœ¨æ¨¡æ‹Ÿçš„CybORGç¯å¢ƒä¸­å®ç°äº†å››ç§æˆªç„¶ä¸åŒçš„æ•™å¸ˆå¼•å¯¼æŠ€æœ¯ï¼Œå¹¶å¯¹å…¶è¿›è¡Œäº†æ·±å…¥çš„å¯¹æ¯”å®éªŒã€‚ç»“æœè¡¨æ˜ï¼Œå¼•å…¥æ•™å¸ˆå¼•å¯¼èƒ½æ˜¾è‘—æé«˜è®­ç»ƒæ•ˆç‡ï¼Œç‰¹åˆ«æ˜¯åœ¨æ—©æœŸç­–ç•¥æ€§èƒ½(early policy performance)å’Œæ”¶æ•›é€Ÿåº¦(convergence speed)ä¸Šå–å¾—äº†çªç ´ã€‚è¯¥ç ”ç©¶å¡«è¡¥äº†æ•™å¸ˆå¼•å¯¼æŠ€æœ¯åœ¨ACOé¢†åŸŸåº”ç”¨çš„ç©ºç™½ï¼Œè¯æ˜äº†å…¶åœ¨å¢å¼ºè‡ªä¸»ç½‘ç»œå®‰å…¨å†³ç­–æ–¹é¢çš„å·¨å¤§æ½œåŠ›ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.14340v1",
      "published_date": "2025-08-20 01:30:27 UTC",
      "updated_date": "2025-08-20 01:30:27 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T13:04:18.483938+00:00"
    },
    {
      "arxiv_id": "2508.14318v2",
      "title": "Power Stabilization for AI Training Datacenters",
      "title_zh": "AI è®­ç»ƒæ•°æ®ä¸­å¿ƒçš„åŠŸç‡å¹³ç¨³åŒ–",
      "authors": [
        "Esha Choukse",
        "Brijesh Warrier",
        "Scot Heath",
        "Luz Belmont",
        "April Zhao",
        "Hassan Ali Khan",
        "Brian Harry",
        "Matthew Kappel",
        "Russell J. Hewett",
        "Kushal Datta",
        "Yu Pei",
        "Caroline Lichtenberger",
        "John Siegler",
        "David Lukofsky",
        "Zaid Kahn",
        "Gurpreet Sahota",
        "Andy Sullivan",
        "Charles Frederick",
        "Hien Thai",
        "Rebecca Naughton",
        "Daniel Jurnove",
        "Justin Harp",
        "Reid Carper",
        "Nithish Mahalingam",
        "Srini Varkala",
        "Alok Gautam Kumbhare",
        "Satyajit Desai",
        "Venkatesh Ramamurthy",
        "Praneeth Gottumukkala",
        "Girish Bhatia",
        "Kelsey Wildstone",
        "Laurentiu Olariu",
        "Ileana Incorvaia",
        "Alex Wetmore",
        "Prabhat Ram",
        "Melur Raghuraman",
        "Mohammed Ayna",
        "Mike Kendrick",
        "Ricardo Bianchini",
        "Aaron Hurst",
        "Reza Zamani",
        "Xin Li",
        "Michael Petrov",
        "Gene Oden",
        "Rory Carmichael",
        "Tom Li",
        "Apoorv Gupta",
        "Pratikkumar Patel",
        "Nilesh Dattani",
        "Lawrence Marwong",
        "Rob Nertney",
        "Hirofumi Kobayashi",
        "Jeff Liott",
        "Miro Enev",
        "Divya Ramakrishnan",
        "Ian Buck",
        "Jonah Alben"
      ],
      "abstract": "Large Artificial Intelligence (AI) training workloads spanning several tens of thousands of GPUs present unique power management challenges. These arise due to the high variability in power consumption during the training. Given the synchronous nature of these jobs, during every iteration there is a computation-heavy phase, where each GPU works on the local data, and a communication-heavy phase where all the GPUs synchronize on the data. Because compute-heavy phases require much more power than communication phases, large power swings occur. The amplitude of these power swings is ever increasing with the increase in the size of training jobs. An even bigger challenge arises from the frequency spectrum of these power swings which, if harmonized with critical frequencies of utilities, can cause physical damage to the power grid infrastructure. Therefore, to continue scaling AI training workloads safely, we need to stabilize the power of such workloads. This paper introduces the challenge with production data and explores innovative solutions across the stack: software, GPU hardware, and datacenter infrastructure. We present the pros and cons of each of these approaches and finally present a multi-pronged approach to solving the challenge. The proposed solutions are rigorously tested using a combination of real hardware and Microsoft's in-house cloud power simulator, providing critical insights into the efficacy of these interventions under real-world conditions.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹æ•°ä¸‡ä¸ª GPU è§„æ¨¡çš„ AI training å·¥ä½œè´Ÿè½½æ‰€é¢ä¸´çš„ç”µåŠ›ç®¡ç†æŒ‘æˆ˜ï¼Œæ·±å…¥æ¢è®¨äº†åŒæ­¥è®¡ç®—å¸¦æ¥çš„å¤§å¹…ç”µåŠ›æ³¢åŠ¨ï¼ˆpower swingsï¼‰é—®é¢˜ã€‚åœ¨è¿­ä»£è¿‡ç¨‹ä¸­ï¼Œcompute-heavy é˜¶æ®µä¸ communication-heavy é˜¶æ®µçš„åŠŸè€—å·®å¼‚å¯¼è‡´äº†å‰§çƒˆçš„ç”µåŠ›æ‘†åŠ¨ï¼Œè‹¥å…¶é¢‘ç‡ä¸ power grid çš„ä¸´ç•Œé¢‘ç‡å‘ç”Ÿè°æŒ¯ï¼Œåˆ™å¯èƒ½å¯¹ç”µåŠ›åŸºç¡€è®¾æ–½é€ æˆç‰©ç†æŸå®³ã€‚ä¸ºæ­¤ï¼Œæœ¬æ–‡åˆ©ç”¨ç”Ÿäº§æ•°æ®æ­ç¤ºäº†è¿™ä¸€æŒ‘æˆ˜ï¼Œå¹¶ä»è½¯ä»¶ã€GPU hardware å’Œ datacenter infrastructure å¤šä¸ªç»´åº¦æ¢ç´¢äº†åˆ›æ–°è§£å†³æ–¹æ¡ˆã€‚é€šè¿‡è¯„ä¼°ä¸åŒæ–¹æ³•çš„ä¼˜ç¼ºç‚¹ï¼Œç ”ç©¶æå‡ºäº†ä¸€ä¸ªå¤šç®¡é½ä¸‹çš„ç»¼åˆæ–¹æ¡ˆä»¥ç¨³å®šç”µåŠ›æ¶ˆè€—ã€‚è¯¥æ–¹æ¡ˆåœ¨çœŸå®ç¡¬ä»¶å’Œ Microsoft å†…éƒ¨çš„ cloud power simulator ä¸Šé€šè¿‡äº†ä¸¥æ ¼æµ‹è¯•ï¼Œä¸ºåœ¨å¤§è§„æ¨¡ç”Ÿäº§ç¯å¢ƒä¸­å®‰å…¨æ‰©å±• AI è®­ç»ƒä»»åŠ¡æä¾›äº†å…³é”®çš„æŠ€æœ¯è§è§£ã€‚",
      "categories": [
        "cs.AR",
        "cs.AI",
        "cs.DC"
      ],
      "primary_category": "cs.AR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.14318v2",
      "published_date": "2025-08-20 00:04:06 UTC",
      "updated_date": "2025-08-21 17:25:27 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T13:04:18.193027+00:00"
    }
  ],
  "processing_status": "completed",
  "error": null,
  "raw_papers_fetched": true,
  "papers_count": 102,
  "processed_papers_count": 102,
  "failed_papers_count": 0,
  "llm_backup_calls": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2026-01-24T13:05:08.900446+00:00"
}